- en: Chapter 3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章
- en: Fundamentals of Deep Learning
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习基础
- en: Throughout the book, when studying how to apply Bayesian methods and extensions
    to neural networks, we will encounter different neural network architectures and
    applications. This chapter will provide an introduction to common architecture
    types, thus laying the foundation for introducing Bayesian extensions to these
    architectures later on. We will also review some of the limitations of such common
    neural network architectures, in particular their tendency to produce overconfident
    outputs and their susceptibility to adversarial manipulation of inputs. By the
    end of this chapter, you should have a good understanding of deep neural network
    basics and know how to implement the most common neural network architecture types
    in code. This will help you follow the code examples found in later sections.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在全书中，当我们学习如何将贝叶斯方法及其扩展应用于神经网络时，将会遇到不同的神经网络架构和应用。 本章将介绍常见架构类型，为稍后将贝叶斯扩展引入这些架构打下基础。我们还将回顾这些常见神经网络架构的一些局限性，特别是它们产生过度自信输出的倾向以及它们容易受到对抗性输入操控的影响。到本章结束时，您应该能够充分理解深度神经网络的基础知识，并知道如何用代码实现最常见的神经网络架构类型。这将帮助您跟上后续章节中的代码示例。
- en: 'The content will be covered in the following sections:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 内容将在以下章节中讨论：
- en: Introducing the multi-layer perceptron
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍多层感知机
- en: Reviewing neural network architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审查神经网络架构
- en: Understanding the problem with typical neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解典型神经网络的问题
- en: 3.1 Technical requirements
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 技术要求
- en: 'To complete the practical tasks in this chapter, you will need a Python 3.8
    environment with the `pandas` and `scikit-learn` stack and the following additional
    Python packages installed:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的实践任务，您需要一个 Python 3.8 环境，并安装 `pandas` 和 `scikit-learn` 堆栈，以及以下额外的 Python
    包：
- en: TensorFlow 2.0
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 2.0
- en: Matplotlib plotting library
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 绘图库
- en: 'All of the code for this book can be found on the GitHub repository for the
    book: [https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的所有代码都可以在本书的 GitHub 仓库中找到：[https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference)。
- en: 3.2 Introducing the multi-layer perceptron
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 介绍多层感知机
- en: Deep neural networks are at the core of the deep learning revolution. The aim
    of this section is to introduce basic concepts and building blocks for deep neural
    networks. To get started, we will review the components of the **multi-layer perceptron**
    (**MLP**) and implement it using the `TensorFlow` framework. This will serve as
    the foundation for other code examples in the book. If you are already familiar
    with neural networks and know how to implement them in code, feel free to jump
    ahead to the *Understanding* *the problem with typical NNs* section, where we
    cover the limitations of deep neural networks. This chapter focuses on architectural
    building blocks and principles and does not cover learning rules and gradients.
    If you require additional background information for those topics, we recommend
    Sebastian Raschka’s excellent *Python Machine Learning* book from Packt Publishing
    (in particular, [*Chapter 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian*
    *Inference*](CH2.xhtml#x1-250002)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络是深度学习革命的核心。本节的目的是介绍深度神经网络的基本概念和构建块。首先，我们将回顾**多层感知机**（**MLP**）的组成部分，并使用
    `TensorFlow` 框架实现它。这将作为本书中其他代码示例的基础。如果您已经熟悉神经网络，并知道如何用代码实现它们，可以跳过，直接进入*理解典型神经网络的问题*部分，我们将在那里讨论深度神经网络的局限性。本章专注于架构构建块和原理，而不涉及学习规则和梯度。如果您需要更多关于这些主题的背景信息，我们推荐
    Packt 出版社的 Sebastian Raschka 所著的优秀书籍 *Python Machine Learning*（特别是 [*第二章*](CH2.xhtml#x1-250002)，[*贝叶斯推断基础*](CH2.xhtml#x1-250002)）。
- en: The MLP is a feed-forward, fully connected neural network. Feed-forward means
    that the information in an MLP is only passed in one direction, from the input
    to the output layers; there are no backward connections. Fully connected means
    that each neuron is connected to all the neurons in the previous layer. To understand
    these concepts a bit better, let’s have a look at *Figure*  [3.1](#x1-37007r1),
    which gives a diagrammatic overview of an MLP. In this example, the MLP has an
    **input layer** with three neurons (shown in red), two **hidden layers** with
    four neurons each (shown in blue), and one **output layer** with a single output
    node (shown in green). Imagine, for example, that we wanted to build a model that
    predicts housing prices in London. In this example, the three input neurons would
    represent values of three input features of our model, such as distance from the
    city centre, floor area, and the construction year of the house. As indicated
    by the black connections in the figure, these input values are then passed to
    and aggregated by each of the neurons of the first hidden layer. The values of
    these neurons are then, in turn, passed to and aggregated by the neurons in the
    second hidden layer and, finally, the output neuron, which will represent the
    house value predicted by our model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MLP 是一种前馈型全连接神经网络。前馈型意味着信息在 MLP 中仅在一个方向上传递，从输入层传递到输出层；没有反馈连接。全连接意味着每个神经元与前一层的所有神经元都有连接。为了更好地理解这些概念，让我们看一下*图*
    [3.1](#x1-37007r1)，它提供了 MLP 的示意图。在这个例子中，MLP 拥有一个包含三个神经元的**输入层**（红色表示），两个包含四个神经元的**隐藏层**（蓝色表示），以及一个包含单个输出节点的**输出层**（绿色表示）。例如，假设我们想要建立一个预测伦敦房价的模型。在这个例子中，三个输入神经元将代表模型的三个输入特征的值，如距离市中心的距离、房屋的楼面面积以及房屋的建造年份。如图中的黑色连接所示，这些输入值会传递到并被第一隐藏层的每个神经元汇总。然后，这些神经元的值会传递到并被第二隐藏层的神经元汇总，最后传递到输出神经元，该神经元将表示我们模型预测的房屋价值。
- en: '![PIC](img/file54.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file54.png)'
- en: 'Figure 3.1: Diagram of a multi-layer perceptron'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：多层感知机的示意图
- en: 'What does it mean exactly for a neuron to aggregate values? To understand this
    a bit better, let’s focus on a single neuron and the operations that it performs
    on the values that are passed to it. In *Figure* [*3.2*](#x1-37013r2), we have
    taken the network shown in *Figure* [*3.1*](#x1-37007r1) (left panel) and zoomed
    in on the first neuron in the first hidden layer and the neurons that pass values
    to it (central panel). In the right panel of the figure, we have slightly rearranged
    the neurons and have named the input neurons *x*[1], *x*[2], and *x*[3]. We have
    also made the connections explicit, by naming the weights associated with them
    *w*[1], *w*[2], and *w*[3], respectively. From the right panel in the figure,
    we can see that an artificial neuron performs two essential operations:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元聚合值究竟是什么意思？为了更好地理解这一点，让我们关注单个神经元及其对传递给它的值执行的操作。在*图* [*3.2*](#x1-37013r2)中，我们展示了*图*
    [*3.1*](#x1-37007r1)（左侧面板），并放大了第一隐藏层中的第一个神经元及其接收输入的神经元（中间面板）。在图的右面板中，我们略微重新排列了神经元，并将输入神经元命名为
    *x*[1]、*x*[2] 和 *x*[3]。我们还明确标出了它们的连接，并分别将与之相关的权重命名为 *w*[1]、*w*[2] 和 *w*[3]。从图的右面板可以看到，一个人工神经元执行两个基本操作：
- en: First, it takes a weighted average over its inputs (indicated by the Σ).
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，它对输入进行加权平均（由 Σ 表示）。
- en: Second, it takes the output of the first step and applies a non-linearity to
    it (indicated by the *σ*. Note that this does not indicate the standard deviation,
    which is what we’ll use *σ* for throughout most of the book), such as a sigmoid
    function, for example.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，它对第一步的输出应用非线性函数（由 *σ* 表示。请注意，这里 *σ* 并不表示标准差——在本书的大部分内容中我们将使用 *σ* 表示标准差），例如使用
    sigmoid 函数。
- en: The first operation can be exdivssed more formally as *z* = ∑ [*n*=1]³*x*[*n*]*w*[*n*].
    The second operation can be exdivssed as *a* = *σ*(*z*) = ![ 1 1+e−-z](img/file55.jpg).
    The activation value of the neuron *a* = *σ*(*z*) is then passed to the neurons
    in the second hidden layer, where the same operations are repeated.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个操作可以更正式地表示为 *z* = ∑ [*n*=1]³ *x*[*n*] *w*[*n*]。第二个操作可以表示为 *a* = *σ*(*z*)
    = ![ 1 1+e−-z](img/file55.jpg)。神经元的激活值 *a* = *σ*(*z*) 然后会传递给第二隐藏层中的神经元，重复相同的操作。
- en: '![PIC](img/file56.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file56.png)'
- en: 'Figure 3.2: Aggregation and transformation performed by an artificial neuron
    in a neural network'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：人工神经元在神经网络中的聚合与变换
- en: 'Now that we have reviewed the different parts of an MLP model, let’s implement
    one in TensorFlow. First, we need to import all the necessary functions. These
    include `Sequential` to build a feed-forward model such as MLP, `Input` to build
    the input layer, and `Dense` to build a fully-connected layer:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了MLP模型的不同部分，接下来让我们在TensorFlow中实现一个。首先，我们需要导入所有必要的函数。这些包括`Sequential`，用于构建像MLP这样的前馈模型，`Input`，用于构建输入层，以及`Dense`，用于构建全连接层：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Equipped with these tools, implementing the MLP is a simple matter of chaining
    `Input` and `Dense` layers in the right order and with the right number of neurons:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 配备了这些工具，实现MLP就变得简单了，只需按正确的顺序和正确的神经元数量链接`Input`层和`Dense`层：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The aggregation in terms of weighted averaging is automatically handled by TensorFlow
    when using the `Dense` layer object. Furthermore, implementing an activation function
    becomes a simple matter of passing the name of the desired function to the `activation`
    parameter of the Dense layer (`sigmoid` in the preceding example).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 加权平均的聚合操作在使用`Dense`层对象时，由TensorFlow自动处理。此外，实现激活函数也变得非常简单，只需将所需函数的名称传递给`Dense`层的`activation`参数（如前面示例中的`sigmoid`）。
- en: Before we turn to other neural network architectures besides the MLP, a side
    note on the word *deep*. A neural network is considered deep if it has more than
    one hidden layer. The MLP shown previously, for example, has two hidden layers
    and can be considered a deep neural network. It is possible to add more and more
    hidden layers, creating very deep neural network architectures. Training such
    deep architectures comes with its own set of challenges and the science (or art)
    of training such deep architectures is called **deep learning** (**DL**).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们转向MLP以外的其他神经网络架构之前，先谈一下“*深度*”这个词。一个神经网络被认为是深度的，如果它有多个隐藏层。例如，前面展示的MLP有两个隐藏层，可以视为一个深度神经网络。你可以添加更多的隐藏层，构建非常深的神经网络架构。训练这种深度架构有其自身的一套挑战，训练这类深度架构的科学（或艺术）被称为**深度学习**（**DL**）。
- en: In the next section, we’ll learn about some of the common deep neural network
    architectures and in the section thereafter, we will look at the practical challenges
    that come with them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将了解一些常见的深度神经网络架构，而在随后的章节中，我们将探讨与这些架构相关的实际挑战。
- en: 3.3 Reviewing neural network architectures
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 回顾神经网络架构
- en: In the previous section, we saw how to implement a fully-connected network in
    the form of an MLP. While such networks were very popular in the early days of
    deep learning, over the years, machine learning researchers have developed more
    sophisticated architectures that work more successfully by including domain-specific
    knowledge (such as computer vision or **Natural Language** **Processing** (**NLP**)).
    In this section, we will review some of the most common of these neural network
    architectures, including **Convolutional Neural** **Networks** (**CNNs**) and
    **Recurrent Neural Networks** (**RNNs**), as well as attention mechanisms and
    transformers.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到如何实现一个以MLP形式的全连接网络。虽然这种网络在深度学习的早期非常流行，但随着时间的推移，机器学习研究人员开发了更为复杂的架构，通过包含领域特定的知识（如计算机视觉或**自然语言处理**（**NLP**））来取得更好的效果。在这一节中，我们将回顾一些最常见的神经网络架构，包括**卷积神经网络**（**CNNs**）和**递归神经网络**（**RNNs**），以及注意力机制和变换器。
- en: 3.3.1 Exploring CNNs
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.1 探索CNNs
- en: When looking back at the example of trying to predict London housing prices
    with an MLP model, the input features we used (distance to the city centre, floor
    area, and construction year of the house) were still ”hand-engineered,” meaning
    that a human looked at the problem and decided which inputs might be relevant
    to the model when making price predictions. What might such input features look
    like if we were trying to build a model that takes in images as input and tries
    to predict which object is shown in the image? One breakthrough moment for deep
    learning was the realization that neural networks can directly learn and extract
    the most useful features for a task from the raw data – in the case of visual
    object classification, these features are learned directly from the pixels in
    the image.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们尝试使用MLP模型预测伦敦房价的例子，我们所使用的输入特征（距离市中心的距离、房屋的楼面面积以及建造年份）仍然是“手工设计”的，这意味着人类会根据问题来判断哪些输入可能与模型的价格预测相关。如果我们要构建一个模型，输入是图像并尝试预测图像中展示的对象，那些输入特征可能是什么样的呢？深度学习的一个突破性时刻是认识到神经网络可以直接从原始数据中学习并提取任务所需的最有用特征——在视觉对象分类的情况下，这些特征是直接从图像的像素中学习得到的。
- en: What would a neural network architecture need to look like if we wanted to extract
    the most relevant input features from an image for an object classification task?
    When trying to answer this question, early machine learning researchers turned
    to mammalian brains. Object classification is a task that our visual system performs
    relatively effortlessly. One observation that inspired the development of CNNs
    was that the visual cortex responsible for object recognition in mammals implements
    a hierarchy of feature extractors that work with increasingly large receptive
    fields. A **receptive** **field** is the area in the image that a biological neuron
    responds to. The neurons at the early layers of the visual cortex respond to relatively
    small regions of an image only, while neurons in layers higher up the hierarchy
    respond to areas that cover large parts (or even the entirety) of an input image.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要从图像中提取最相关的输入特征用于物体分类任务，那么神经网络架构需要是什么样的呢？在尝试回答这个问题时，早期的机器学习研究者转向了哺乳动物的大脑。物体分类是我们的视觉系统相对轻松完成的任务。启发CNN发展的一个观察是，负责物体识别的哺乳动物视觉皮层实现了一个特征提取器的层级结构，这些提取器具有越来越大的感受野。**感受**
    **野**是生物神经元对图像中的区域的响应范围。视觉皮层早期层的神经元仅响应图像的相对小区域，而高层神经元则响应覆盖较大部分（甚至整个）输入图像的区域。
- en: Inspired by the cortical hierarchy in the brain, CNNs implement a hierarchy
    of feature extractors with artificial neurons higher up in the hierarchy having
    larger receptive fields. To understand how that works, let’s look at how CNNs
    build features based on input images. *Figure* [*3.3*](#x1-39005r3) shows an early
    convolutional layer in a CNN operating on the input image (shown on the left)
    to extract features into a feature map (shown on the right). You can imagine the
    feature map as a matrix with *n* rows and *m* columns and every feature in the
    feature map as a scalar value. The example highlights two instances where the
    convolutional layer operates on different local regions of the image. In the first
    instance, the feature in the feature map receives input from the face of the kitten.
    In the second instance, the feature receives inputs from the kitten’s right paw.
    The final feature map will be the result of repeating this same operation over
    all regions of the input image, sliding a kernel from left to right and from top
    to bottom to fill all the values in the feature map.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 受大脑皮层层级结构的启发，CNN实现了特征提取器的层级结构，其中高层的人工神经元具有更大的感受野。为了理解这个是如何工作的，让我们看一下CNN如何基于输入图像构建特征。*图*
    [*3.3*](#x1-39005r3)展示了CNN中早期的卷积层如何对输入图像（左侧所示）进行操作，将特征提取到特征图中（右侧所示）。你可以将特征图想象成一个具有*n*行和*m*列的矩阵，特征图中的每个特征都是一个标量值。这个例子突出了卷积层在图像不同局部区域操作的两个实例。在第一个实例中，特征图中的特征接收来自小猫脸部的输入。在第二个实例中，特征接收来自小猫右爪的输入。最终的特征图将是将这个相同操作在输入图像的所有区域重复进行的结果，通过从左到右、从上到下滑动一个卷积核来填充特征图中的所有值。
- en: '![PIC](img/file57.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file57.png)'
- en: 'Figure 3.3: Building a feature map from the input image'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：从输入图像构建特征图
- en: What does such a single operation look like numerically? This is illustrated
    in *Figure* [*3.4*](#x1-39007r4).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的单一操作在数值上是什么样的呢？这在*图* [*3.4*](#x1-39007r4)中有说明。
- en: '![PIC](img/file58.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file58.png)'
- en: 'Figure 3.4: Numerical operations performed by convolutional layer'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：卷积层执行的数值操作
- en: 'Here, we have zoomed in on one part of the input image and made its pixel values
    explicit (left side). You can imagine that the kernel (shown in the middle) slides
    over the input image step by step. In the step that is shown in the figure, the
    kernel is operating on the upper-left corner of the input image (highlighted in
    red). Given the values in the input image and the kernel values, the final value
    in the feature map (**28** in the example) is obtained via weighted averaging:
    each value in the input image is weighted by the corresponding value in the kernel,
    which yields 9 ∗ 0 + 3 ∗ 1 + 1 ∗ 0 + 4 ∗ 0 + 8 ∗ 2 + 5 ∗ 0 + 5 ∗ 1 + 2 ∗ 1 + 2
    ∗ 1 = 28.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们放大了输入图像的一部分，并明确了其像素值（左侧）。你可以想象，卷积核（如图中所示）一步一步地滑过输入图像。在图中显示的这一步，卷积核正在操作输入图像的左上角（以红色高亮）。给定输入图像的值和卷积核的值，特征图中的最终值（示例中的**28**）是通过加权平均得到的：输入图像中的每个值都由对应的卷积核值加权，从而得到
    9 ∗ 0 + 3 ∗ 1 + 1 ∗ 0 + 4 ∗ 0 + 8 ∗ 2 + 5 ∗ 0 + 5 ∗ 1 + 2 ∗ 1 + 2 ∗ 1 = 28。
- en: Slightly more formally, let us denote the input image by *x* and the kernel
    by *w*. Convolution in a CNN can then be exdivssed as *z* = ∑ [*i*=1]^(*n*) ∑
    [*j*=1]^(*m*)*x*[*i,j*]*w*[*i,j*]. This is usually followed by a non-linearity,
    *a* = *σ*(*z*), just like for the MLP. *σ* could be the sigmoid function introduced
    previously, but a more popular choice for CNNs is the **Rectified Linear Unit**
    (**ReLU**), which is defined as *ReLU*(*z*) = *max*(0*,z*).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 稍微正式一点，我们用*x*表示输入图像，*w*表示卷积核。卷积神经网络中的卷积操作可以表示为*z* = ∑ [*i*=1]^(*n*) ∑ [*j*=1]^(*m*)*x*[*i,j*]*w*[*i,j*]。通常，这之后会有一个非线性操作，*a*
    = *σ*(*z*)，就像多层感知机（MLP）中一样。*σ*可以是之前介绍的sigmoid函数，但卷积神经网络（CNN）中更常用的选择是**修正线性单元**（**ReLU**），其定义为*ReLU*(*z*)
    = *max*(0*,z*)。
- en: In modern CNNs, many of these convolutional layers will be stacked on top of
    each other, such that the feature map that forms the output of one convolutional
    layer will serve as the input (image) for the next convolutional layer, and so
    forth. Putting convolutional layers in sequence like this allows the CNN to build
    more and more abstract feature representations. When studying feature maps at
    different positions of the hierarchy, it was shown by Matthew Zeiler et al. (see
    *Further reading*) that feature maps at early convolutional layers often show
    edges and simple textures, while feature maps at later convolutional layers show
    more complex patterns and parts of objects. Similar to the visual cortical hierarchy,
    neurons in later convolutional layers will tend to have larger receptive fields
    because they accumulate input from several earlier neurons, which in turn receive
    inputs from different local regions of the image.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代CNN中，许多这些卷积层会堆叠在一起，使得一个卷积层的输出特征图将作为下一个卷积层的输入（图像），如此往复。将卷积层按顺序排列，这使得CNN能够构建越来越抽象的特征表示。在研究层级中不同位置的特征图时，Matthew
    Zeiler等人（见*进一步阅读*）发现，早期卷积层的特征图通常显示边缘和简单纹理，而后期卷积层的特征图则展示了更复杂的图案和物体部件。类似于视觉皮层的层级结构，后期卷积层中的神经元倾向于具有更大的感受野，因为它们从多个早期神经元接收输入，而这些神经元又从图像的不同局部区域接收输入。
- en: 'The number of convolutional layers that are stacked on top of each other will
    determine the depth of a CNN: the more layers, the deeper the network. Another
    important dimension for a CNN is its width, which is determined by the number
    of convolutional kernels per layer. You can imagine that we can apply more than
    one kernel at a given convolutional layer, which will result in additional feature
    maps – one for every additional kernel. In this case, the kernels in the subsequent
    convolutional layer will need to be three-dimensional in order to handle the multitude
    of feature maps in the input, where the third dimension of the kernel will be
    determined by the number of incoming feature maps.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠在一起的卷积层的数量决定了卷积神经网络（CNN）的深度：层数越多，网络越深。另一个重要的维度是CNN的宽度，这由每层的卷积核数量决定。你可以想象，在某一卷积层上，我们可以应用多个卷积核，这将导致额外的特征图——每增加一个卷积核，就增加一张特征图。在这种情况下，后续卷积层中的卷积核需要是三维的，以处理输入中多个特征图，其中卷积核的第三维由输入特征图的数量决定。
- en: Along with convolutional layers, another common building block for CNNs is **pooling
    layers**, in particular **mean-pooling** and **max-pooling** layers. The function
    of these layers is to sub-sample the input, which reduces the input size of the
    image and thus the subsequent number of parameters needed in the network (and
    thus reduces the computational load and memory footprint).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与卷积层一起，CNN（卷积神经网络）的另一个常见组成部分是**池化层**，特别是**均值池化**和**最大池化**层。这些层的作用是对输入进行子采样，从而减小图像的输入尺寸，进而减少网络中所需的参数数量（也减少了计算负担和内存占用）。
- en: How do pooling layers operate? In *Figure* [*3.5*](#x1-39017r5), we see both
    a mean-pooling (left) and max-pooling (right) layer in operation. We see that,
    like convolutional layers, they operate on local regions of the input. The operations
    they perform are straightforward – either they take the mean or the maximum of
    the pixel values in their receptive field.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层是如何工作的？在*图* [*3.5*](#x1-39017r5)中，我们看到均值池化（左）和最大池化（右）层的工作过程。我们可以看到，像卷积层一样，它们对输入的局部区域进行操作。它们执行的操作非常简单——要么取接收区域内像素值的均值，要么取最大值。
- en: '![PIC](img/file59.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file59.png)'
- en: 'Figure 3.5: Numerical operations performed by pooling layers'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3.5: 池化层执行的数值操作'
- en: In addition to computational and memory considerations, another advantage of
    pooling layers is that they can make the network more robust to small variations
    in the input. Imagine, for example, one of the input pixel values in the example
    changed to 0\. This will either affect the output very little (mean-pooling layer)
    or not at all (max-pooling layer).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 除了计算和内存方面的考虑外，池化层的另一个优点是它们可以使网络对输入的小变化更具鲁棒性。例如，假设示例中的一个输入像素值发生了变化，变为0。这将对输出产生很小的影响（均值池化层）或根本没有影响（最大池化层）。
- en: 'Now that we have reviewed the essential operations, let’s implement a CNN in
    TensorFlow. Importing all the necessary functions includes the already familiar
    `Sequential` function to build a feed-forward model as well as the `Dense` layer.
    In addition, this time, we also import `Conv2D` for convolution and `MaxPooling2D`
    for max-pooling. With these tools, we can implement a CNN by chaining these layer
    functions in the right order:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了基本操作，接下来我们将在TensorFlow中实现一个CNN。导入所有必要的函数，包括我们已经熟悉的`Sequential`函数，用于构建前馈模型，以及`Dense`层。此外，这次我们还导入了`Conv2D`用于卷积，`MaxPooling2D`用于最大池化。有了这些工具，我们可以通过按照正确顺序链接这些层函数来实现一个CNN：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We have built a CNN by chaining a convolutional layer with 32 kernels, followed
    by a max-pooling operation, followed by a convolutional layer with 64 kernels,
    and another max-pooling operation. In the end, we add two `Dense` layers. The
    final `Dense` layer will serve to match the number of output neurons to the number
    of classes in a classification problem. In the preceding example, that number
    is `10`. Our network is now ready for us to train.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过将一个包含32个核的卷积层与一个最大池化操作串联起来，接着是一个包含64个核的卷积层，再加上另一个最大池化操作，最终添加了两个`Dense`层，构建了一个CNN。最终的`Dense`层将用于将输出神经元的数量与分类问题中的类别数量匹配。在前面的示例中，类别数量是`10`。我们的网络现在已经准备好进行训练。
- en: 'CNNs have become crucial for a broad variety of problems, forming a key component
    in systems designed for a whole range of problems, from self-driving cars through
    to medical imaging. They also provided a foundation for other important neural
    network architectures, such as **graph convolutional** **networks** (**GCNs**).
    But the field of deep learning wasn’t able to dominate the world of machine learning
    with CNNs alone. In the next section, we’ll learn about another important architecture:
    the recurrent neural network, an invaluable method for processing sequential data.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: CNN已经成为解决各种问题的关键工具，成为从自动驾驶汽车到医学影像等广泛问题中系统的关键组成部分。它们还为其他重要的神经网络架构提供了基础，例如**图卷积**
    **网络**（**GCNs**）。然而，仅凭CNN，深度学习领域还无法主导机器学习的世界。在接下来的部分，我们将学习另一种重要架构：循环神经网络（RNN），这是一种处理序列数据的宝贵方法。
- en: 3.3.2 Exploring RNNs
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 探索RNN（循环神经网络）
- en: 'The neural networks that we have seen so far are what we call feedforward networks:
    each layer of the network feeds into the next layer of the network; there is no
    cycle. Moreover, the convolutional neural networks we looked at receive a single
    input (an image) and output a single output: a label or a score for that label.
    But there are many cases in which we are working with something more complex than
    a single input, single output task. In this section, we will focus on a family
    of models called **recurrent neural networks** (**RNNs**), which focus on processing
    sequences of inputs, with some also producing sequential outputs.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所见到的神经网络是我们所称之为前馈网络的类型：网络的每一层都将信息传递给下一层；没有循环。此外，我们看到的卷积神经网络接受一个单一的输入（图像）并输出一个单一的结果：一个标签或该标签的评分。但在许多情况下，我们处理的任务比单一输入、单一输出任务更为复杂。在本节中，我们将重点介绍一类模型，称为**递归神经网络**（**RNN**），它们专注于处理输入序列，有些还会生成顺序输出。
- en: 'A typical example of an RNN task is machine translation. For example, translating
    the English sentence, ”the apple is green,” to French. For such a task to work,
    a network needs to consider the relationship between the inputs we feed it. Another
    task could be video classification, where we need to look at different frames
    of a video to classify the content of the video. An RNN processes an input one
    step at a time, where every time step can be denoted as [*t*]. At every time step,
    the model computes a hidden state *h*[*t*] and an output *y*[*t*]. But to compute
    *h*[*t*], the model does not only receive the input *x*[*t*] but also the hidden
    state at the previous time step *h*[*t*−1]. For a single time step, a vanilla
    RNN thus computes the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: RNN任务的典型例子是机器翻译。例如，将英文句子“the apple is green”翻译成法语。为了使这类任务有效，网络需要考虑我们输入之间的关系。另一个任务可能是视频分类，其中我们需要查看视频的不同帧，以分类视频的内容。RNN逐步处理每个输入，其中每个时间步可以表示为
    [*t*]。在每个时间步，模型计算一个隐藏状态 *h*[*t*] 和一个输出 *y*[*t*]。但是为了计算 *h*[*t*]，模型不仅接收输入 *x*[*t*]，还接收前一个时间步的隐藏状态
    *h*[*t*−1]。对于单个时间步，标准RNN计算如下：
- en: '![ht = f(Wxxt + Whht− 1 + b) ](img/file60.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![ht = f(Wxxt + Whht− 1 + b)](img/file60.jpg)'
- en: 'Where:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*W*[*x*] are the weights of the RNN for the input *x*[*t*]'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*W*[*x*] 是RNN中输入 *x*[*t*] 的权重'
- en: '*W*[*h*] are the weights for the hidden layer output from the previous time
    step *h*[*t*−1]'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*W*[*h*] 是来自前一个时间步 *h*[*t*−1] 的隐藏层输出的权重'
- en: '*b* is the bias term'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b* 是偏置项'
- en: '*f* is an activation function – in a vanilla RNN a *tanh* activation function'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f* 是激活函数——在一个标准的RNN中，使用的是 *tanh* 激活函数'
- en: This way, at every time step, the model also has awareness of what happened
    at previous time steps because of the additional input *h*[*t*−1].
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，在每个时间步，模型也能感知到前一个时间步发生了什么，因为有了额外的输入 *h*[*t*−1]。
- en: 'We can visualize the flow of an RNN as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下可视化RNN的流程：
- en: '![PIC](img/file61.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file61.png)'
- en: 'Figure 3.6: Example of an RNN'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：RNN 示例
- en: We can see that we need an initial hidden state as well at time step zero. This
    is usually just a vector of zeros.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在时间步零时，我们还需要一个初始的隐藏状态。通常这只是一个全零向量。
- en: 'One important variant of a vanilla neural network is a **sequence-to-sequence**
    (**seq2seq**) neural network, a popular paradigm in machine translation. The idea
    of this network is, as the name suggests, to take a sequence as input and output
    another sequence. Importantly, both sequences do not have to be of the same length.
    This enables the architecture to translate sentences in a more flexible way, which
    is crucial as different languages do not use the same number of words in sentences
    with the same meaning. This flexibility is achieved with an encoder-decoder architecture.
    This means that we will have two parts of our NN: an initial part that encodes
    the input up until a single weight (many inputs encoded to one hidden vector)
    matrix that is then used as input for the decoder of the network to produce multiple
    outputs (one input to many outputs). The encoder and the decoder have separate
    weight matrices. For a model with two inputs and two outputs, this can be visualized
    as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的神经网络变体是**序列到序列**（**seq2seq**）神经网络，这是一种在机器翻译中非常流行的范式。正如其名字所示，这种网络的思路是将一个序列作为输入，并输出另一个序列。重要的是，这两个序列不需要是相同长度的。这使得该架构能够以更加灵活的方式进行句子翻译，这一点至关重要，因为不同语言在表达相同意思的句子时使用的单词数量可能不同。这种灵活性是通过编码器-解码器架构来实现的。这意味着我们的神经网络将有两个部分：一个初始部分将输入编码成一个单一的权重矩阵（多个输入被编码成一个隐藏向量），然后该矩阵作为解码器的输入，解码器根据它来生成多个输出（一个输入对应多个输出）。编码器和解码器有各自独立的权重矩阵。对于一个有两个输入和两个输出的模型，效果可以通过如下方式可视化：
- en: '![PIC](img/file62.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file62.png)'
- en: 'Figure 3.7: Example of a sequence-to-sequence network'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：序列到序列网络的示例
- en: In this figure *w*[*e*] are the weights of the encoder and *w*[*d*] are the
    weights of the decoder. We can see that compared to our RNN, we now have a new
    hidden state of the decoder *s*[0] and we can also observe *c*, which is a context
    vector. In standard sequence-to-sequence models, *c* is equal to the hidden state
    at the end of the encoder, whereas *s*[0], the initial hidden state of the encoder,
    is typically computed with one or more feedforward layers. The context vector
    is an additional input to each part of the decoder; it allows each part to use
    the information of the encoder.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图中，*w*[*e*]是编码器的权重，*w*[*d*]是解码器的权重。我们可以看到，与我们的RNN相比，我们现在有了解码器的新隐藏状态 *s*[0]，并且我们还可以看到
    *c*，这是一个上下文向量。在标准的序列到序列模型中，*c* 等于编码器结束时的隐藏状态，而 *s*[0]，编码器的初始隐藏状态，通常是通过一个或多个前馈层来计算的。上下文向量是解码器每一部分的额外输入；它允许解码器的每一部分使用编码器的信息。
- en: 3.3.3 Attention mechanisms
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.3 注意力机制
- en: 'Although recurrent neural network models can be powerful, they have an important
    disadvantage: all information that the encoder can give to the decoder has to
    be in the hidden bottleneck layer – the hidden input state that the decoder receives
    at the start. That is fine for short sentences, but you can imagine that this
    becomes more difficult when we want to translate an entire paragraph or a very
    long sentence. We simply cannot expect that a single vector contains all information
    that is required to translate a long sentence. This downside is solved by a mechanism
    called attention. Later on, we will generalize the concept of attention, but let
    us first see how attention can be applied in the context of a seq2seq model.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管递归神经网络模型（RNN）可能非常强大，但它们有一个重要的缺点：编码器传递给解码器的所有信息必须都在隐藏瓶颈层中——即解码器在开始时接收到的隐藏输入状态。这对于短句子来说是没问题的，但可以想象，当我们想要翻译整个段落或非常长的句子时，这就变得更加困难。我们不能指望一个单一的向量能包含翻译长句子所需的所有信息。这个缺点通过一个叫做“注意力机制”的方法得到了解决。稍后我们将会对注意力机制的概念进行概括，但首先让我们看看在seq2seq模型的上下文中，注意力机制是如何应用的。
- en: 'Attention allows the decoder of a seq2seq model to ”attend” to hidden states
    of the encoder according to some attention weights. This means that instead of
    having to rely on the bottleneck layer to translate the input, the decoder can
    go back to each hidden state of the encoder and decide how much information it
    wants to use. This is done via a context vector at every time step of the decoder
    that now functions as a probability vector, determining how much weight to give
    to each of the hidden states of the encoder. We can think of attention in this
    context as the following sequence for every time step of the decoder:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制允许 seq2seq 模型的解码器根据某些注意力权重“关注”编码器的隐藏状态。这意味着解码器不再仅依赖瓶颈层来翻译输入，而是可以回溯到编码器的每个隐藏状态，并决定它希望使用多少信息。这是通过在解码器的每个时间步使用一个上下文向量来实现的，这个上下文向量现在充当概率向量，决定给予编码器每个隐藏状态的权重。我们可以将注意力机制在这个上下文中理解为在每个解码器时间步的以下序列：
- en: '*e*[*t,i*] = *f*(*s*[*t*−1]*,h*[*i*]) computes *alignment scores* for every
    hidden state of the encoder. This computation can be an MLP for every hidden state
    of the encoder, taking as input the current hidden state of the decoder *s*[*t*−1],
    and *h*[*i*] the hidden states of the encoder.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*e*[*t,i*] = *f*(*s*[*t*−1]*,h*[*i*]) 计算每个编码器隐藏状态的 *alignment scores*。这个计算可以是一个多层感知机（MLP），针对编码器的每个隐藏状态，输入为解码器当前的隐藏状态
    *s*[*t*−1]，以及编码器的隐藏状态 *h*[*i*]。'
- en: '*e*[*t,i*] gives us alignment scores; they tell us something about the relation
    of every hidden state in the encoder and a single hidden state of the decoder.
    But the output of *f* is a scalar, which makes it impossible to compare different
    alignment scores. That is why we then take the softmax over all alignment scores
    to get a probability vector; attention weights: *a*[*t,i*] = *softmax*(*e*[*t,i*]).
    These weights are now values between 0 and 1 and tell us, for a single hidden
    state in the decoder, how much weight to give to every hidden state of the decoder.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*e*[*t,i*] 给出了我们对齐分数；它们告诉我们编码器每个隐藏状态与解码器一个隐藏状态之间的关系。但 *f* 的输出是一个标量，这使得比较不同的对齐分数变得不可能。这就是为什么我们随后对所有对齐分数进行
    softmax 操作，以获得一个概率向量；注意力权重：*a*[*t,i*] = *softmax*(*e*[*t,i*])。这些权重现在是介于 0 和 1
    之间的数值，告诉我们对于解码器的单个隐藏状态，应该给予编码器每个隐藏状态多少权重。'
- en: With our attention weights, we now take a weighted average of the hidden states
    of the encoder. This produces the context vector *c*[1], which can be used for
    the first time step of the decoder.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过我们的注意力权重，我们现在对编码器的隐藏状态进行加权平均。这生成了上下文向量 *c*[1]，它可以用于解码器的第一个时间步。
- en: 'Because this mechanism computes attention weights for every time step of the
    decoder, the model is now much more flexible: at every time step, it knows how
    much weight to give to each part of the encoder. Moreover, because we are using
    an MLP here to compute the attention weights, this mechanism can be trained end
    to end.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个机制计算了解码器每个时间步的注意力权重，模型现在变得更加灵活：在每个时间步，它知道应该给予编码器每个部分多少权重。此外，由于我们在这里使用的是多层感知机（MLP）来计算注意力权重，这个机制可以端到端地训练。
- en: 'This tells you a way to use attention in a sequence-to-sequence model. But
    the attention mechanism can be generalized to make it even more powerful. This
    generalization is used as a building block in the most powerful neural network
    applications you see today. It uses three main components:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉你如何在序列到序列模型中使用注意力。但注意力机制可以被泛化，使其更加强大。这种泛化是如今最强大的神经网络应用中的构建块。它使用三个主要组件：
- en: Queries, denoted as *Q*. You can think of these as the hidden states of the
    decoder.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询，记作 *Q*。你可以将其视为解码器的隐藏状态。
- en: Keys, denoted as *K*. You can think of the keys as the hidden state of the inputs
    *h*[*i*].
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键，记作 *K*。你可以将键视为输入的隐藏状态 *h*[*i*]。
- en: Values, denoted as *V* . In the standard attention mechanism, these are the
    same as the keys, but just separated as a separate value.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值，记作 *V*。在标准的注意力机制中，值与键相同，但被分开作为独立的值。
- en: Together, the queries, keys, and values form the attention mechanism in the
    form of
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 查询、键和值共同构成了注意力机制，形式为
- en: '![ QKT Attention (Q, K, V) = softmax (-√---)V dk ](img/file63.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![ QKT 注意力 (Q, K, V) = softmax (-√---)V dk ](img/file63.jpg)'
- en: 'We can distinguish three generalizations:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以区分出三种泛化：
- en: 'Using an MLP to compute the attention weights is a relatively heavy operation
    for every time step. Instead, we can use something more lightweight that allows
    us to compute the attention weights for every hidden state of the decoder much
    faster: we use a scaled dot product of the hidden state of the decoder and the
    hidden states of the encoder. We scale the dot product by the square root of the
    dimension of *K*:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MLP计算注意力权重对于每个时间步来说是一个相对繁重的操作。相反，我们可以使用一种更轻量的方式，使我们能够更快速地为解码器的每个隐状态计算注意力权重：我们使用解码器隐状态与编码器隐状态的缩放点积。我们通过*K*的维度的平方根来缩放点积：
- en: '![ T Q√K--- dk ](img/file64.jpg)'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ T Q√K--- dk ](img/file64.jpg)'
- en: 'This is because of two reasons:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是由于两个原因：
- en: The softmax operation can lead to extreme values – values very close to zero
    and very close to one. This makes the optimization process more difficult. By
    scaling the dot product, we avoid this issue.
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: softmax操作可能导致极端值——接近零和接近一的值。这使得优化过程更加困难。通过缩放点积，我们避免了这个问题。
- en: The attention mechanism takes the dot product of vectors with a high dimension.
    This causes the dot product to be very large. By scaling the dot product, we counteract
    this tendency.
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意力机制对高维向量计算点积。这导致点积值非常大。通过缩放点积，我们可以抵消这种趋势。
- en: We use the input vectors separately – we separate them as keys and values in
    different input streams. This gives the model more flexibility to handle them
    in different ways. Both are learnable matrices, so the model can optimize both
    in different ways.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们分别使用输入向量——将它们分别作为键和值，在不同的输入流中。这使得模型可以更灵活地以不同的方式处理它们。两者都是可学习的矩阵，因此模型可以以不同的方式优化它们。
- en: Attention takes a set of inputs as the query vector. This is more computationally
    efficient; instead of computing the dot product for every single query vector,
    we can do this for all of them at once.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意力机制将一组输入作为查询向量。这种做法在计算上更高效；我们不需要为每一个查询向量单独计算点积，而是可以一次性计算所有查询向量。
- en: 'These three generalizations make attention a very widely applicable algorithm.
    You see it in most of today’s most performant models, some of the best image classification
    models – large language models that generate very realistic text or text-to-image
    models that can create the most beautiful and creative images. Because of the
    wide use of the attention mechanism, it is easily available in TensorFlow and
    other deep learning libraries. In TensorFlow, you can use attention like so:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种概括使得注意力成为一种非常广泛应用的算法。你可以在今天大多数表现最好的模型中看到它，包括一些最佳的图像分类模型——生成非常逼真文本的大型语言模型，或者能够创造最美丽、最具创意图像的文本到图像模型。由于注意力机制的广泛应用，它在TensorFlow等深度学习库中非常容易使用。在TensorFlow中，你可以这样使用注意力机制：
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'And it can be called with our query, key, and value:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以通过我们的查询（query）、键（key）和值（value）来调用：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the preceding sections, we discussed some important building blocks of neural
    networks; we discussed the basic MLP, the concept of convolution, recurrent neural
    networks, and attention. There are other components we did not discuss here, and
    even more variants and combinations of the components we discussed. If you want
    to know more about these building blocks, refer to the reading list at the end
    of this chapter. There are excellent resources available in case you want to dive
    deeper into neural network architectures and components.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了神经网络的一些重要构建模块；我们讨论了基本的MLP、卷积的概念、递归神经网络和注意力机制。还有其他一些我们未在此讨论的组件，以及更多我们讨论过的组件的变种和组合。如果你想了解更多关于这些构建模块的内容，请参考本章末尾的阅读列表。如果你想深入研究神经网络架构和组件，有许多优秀的资源可以参考。
- en: 3.4 Understanding the problem with typical neural networks
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4 理解典型神经网络中的问题
- en: The deep neural networks we discussed in previous sections are extremely powerful
    and, paired with appropriate training data, have enabled big strides in machine
    perception. In machine vision, convolutional neural networks enable us to classify
    images, locate objects in images, segment images into different segments or instances,
    and even to generate entirely novel images. In natural language processing, recurrent
    neural networks and transformers have allowed us to classify text, to recognize
    speech, to generate novel text or, as reviewed previously, to translate between
    two different languages.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前几节中讨论的深度神经网络非常强大，配合适当的训练数据，推动了机器感知领域的巨大进步。在机器视觉中，卷积神经网络使我们能够对图像进行分类、定位图像中的物体、将图像分割成不同的区域或实例，甚至生成全新的图像。在自然语言处理方面，循环神经网络和变压器使我们能够对文本进行分类、识别语音、生成新文本，或者如前所述，在两种语言之间进行翻译。
- en: 'However, these standard types of neural network models also have several limitations.
    In this section, we will explore some of these limitations. We will look at the
    following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些标准类型的神经网络模型也有若干限制。在本节中，我们将探讨这些限制中的一些。我们将着眼于以下几个方面：
- en: How the prediction scores of such neural network models can be overconfident
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这样的神经网络模型的预测得分如何会过于自信
- en: How such models can produce very confident predictions on OOD data
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这样的模型如何能在 OOD 数据上产生非常自信的预测
- en: How tiny, imperceptible changes in an input image can cause a model to make
    completely wrong predictions
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微小、几乎不可察觉的输入图像变化如何导致模型做出完全错误的预测
- en: 3.4.1 Uncalibrated and overconfident predictions
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.1 未校准和过于自信的预测
- en: One problem with modern vanilla neural networks is that they often produce outputs
    that are not well-calibrated. This means that the confidence scores produced by
    these networks no longer represent their empirical correctness. To understand
    better what that means, let’s look at the reliability plot for the ideally-calibrated
    network that is shown in *Figure* [*3.8*](#x1-43002r8).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现代普通神经网络的一个问题是，它们往往会产生未经过良好校准的输出。这意味着这些网络产生的置信度得分不再代表它们的经验正确性。为了更好地理解这意味着什么，我们来看一下理想校准网络的可靠性图，如
    *图* [*3.8*](#x1-43002r8) 所示。
- en: '![PIC](img/file65.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file65.png)'
- en: 'Figure 3.8: Reliability plot for a well-calibrated neural network. The empirically
    determined (”actual”) accuracy is consistent with the prediction values output
    by the network'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8：良好校准的神经网络的可靠性图。经验确定的（"实际"）准确性与网络输出的预测值一致
- en: As you can see, the reliability plot shows accuracy (on the *y* axis) as a function
    of confidence (on the *x* axis). The basic idea is that, for a well-calibrated
    network, the output (or confidence) score associated with a prediction should
    match its empirical correctness. Here, empirical correctness is defined as the
    accuracy of a group of samples that all share similar output values and, for that
    reason, are grouped into the same bin in the reliability plot. So, for example,
    for the group of samples that all were assigned an output score between 0.7 and
    0.8, the expectation, for a well-calibrated network, would be that 75% of these
    predictions should be correct.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，可靠性图展示了准确性（在 *y* 轴上）作为置信度（在 *x* 轴上）的函数。基本的思路是，对于一个经过良好校准的网络，预测结果（或置信度）所关联的得分应该与其经验正确性相匹配。这里，经验正确性被定义为一组具有相似输出值的样本的准确性，因此，这些样本会被分到可靠性图中的同一组。因此，例如，对于所有输出得分在
    0.7 和 0.8 之间的样本组，一个经过良好校准的网络的期望是，其中 75% 的预测应该是正确的。
- en: To make this idea a bit more formal, let’s imagine that we have a dataset **X**
    with **N** data samples. Each data sample **x** has a corresponding target label
    **y**. In a classification setting, we would have *y*, which represents the membership
    to one in *K* classes. To obtain a reliability plot, we would use a neural network
    model to run inference over the entire dataset **X** to obtain an output score
    *ŷ* per sample **x**. We would then use the output scores to assign each data
    sample to a bin *m* in the reliability plot. In the preceding figure, we have
    opted for *M* = 10 bins. *B*[*m*] would be the set of indices of samples that
    fall into bin *m*. Finally, we would measure and plot the average accuracy of
    the predictions for all the samples in a given bin, which is defined as *acc*(*B*[*m*])
    = ![-1-- |Bm |](img/file66.jpg)∑ [*i*∈*B*[m]]1(*ŷ*[*i*] = *y*[*i*]).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个想法更加正式，我们假设有一个数据集**X**，其中包含**N**个数据样本。每个数据样本**x**都有一个对应的目标标签**y**。在分类问题中，我们会有*y*，它表示属于*K*个类别中的一个。为了获得可靠性图，我们将使用神经网络模型对整个数据集**X**进行推理，并为每个样本**x**获得一个输出分数*ŷ*。然后，我们将使用输出分数将每个数据样本分配到可靠性图中的一个*
    m *区间。在前面的图中，我们选择了*M* = 10个区间。*B*[*m*]将是落入区间*m*的样本的索引集合。最后，我们将测量并绘制每个区间内所有样本预测的平均准确度，定义为*acc*(*B*[*m*])
    = ![-1-- |Bm |](img/file66.jpg)∑ [*i*∈*B*[m]]1(*ŷ*[*i*] = *y*[*i*])。
- en: In the case of a well-calibrated network, the average accuracy of the samples
    in a given bin should match the confidence values of that bin. In the preceding
    figure, we can see, for example, that for samples that fell in the bin for output
    scores between 0.2 and 0.3, we observed a matching average accuracy of 0.25\.
    Now let’s see what happens in the case of an uncalibrated network that is over-confident
    in its predictions. Figure  [3.9](#x1-43004r9) illustrates this scenario, which
    is representative of the behavior shown by many modern vanilla neural network
    architectures.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个经过良好校准的网络，给定区间内样本的平均准确度应该与该区间的置信度值匹配。在前面的图中，我们可以看到，例如，对于落在输出分数在0.2到0.3之间的区间的样本，我们观察到的平均准确度为0.25。现在，让我们看看在一个对预测过度自信的未经校准的网络中会发生什么情况。图[3.9](#x1-43004r9)展示了这种情况，这是许多现代原始神经网络架构所表现的行为的典型代表。
- en: '![PIC](img/file67.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file67.png)'
- en: 'Figure 3.9: Reliability plot for an overconfident neural network. The ”actual”
    empirically determined accuracy (purple bars) is consistently below the accuracy
    suggested by the prediction values of the network (pink bars and gray dashed line)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9：过度自信神经网络的可靠性图。由经验确定的“实际”准确度（紫色条）始终低于网络预测值（粉色条和灰色虚线）所建议的准确度。
- en: We can observe that for all the bins, the observed (”actual”) accuracy for the
    samples in the bin is below the accuracy that is expected based on the output
    score of the samples. This is the exdivssion of over-confident predictions. The
    network’s output makes us believe that it has a high degree of confidence in its
    predictions, while in reality the actual performance does not match up.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，对于所有的区间，区间内样本的实际准确度低于基于样本输出分数所期望的准确度。这就是过度自信预测的表现。网络的输出让我们相信它对预测具有很高的信心，而实际上，实际表现并不符合预期。
- en: Over-confident predictions can be very problematic in safety- and mission-critical
    applications, such as medical decision making, self-driving cars, and legal or
    financial decisions. Networks with overconfident predictions will lack the ability
    to indicate to us humans (or other networks) when they are likely to be wrong.
    This lack of awareness can become dangerous, for example, when a network is used
    to help decide whether a defendant should be granted bail or not. Assume a network
    is presented with a defendant’s data (such as past convictions, age, education
    level) and predicts with 95% confidence score that bail should not be granted.
    presented with this output, a judge might falsely think that the model can be
    trusted and base their verdict largely on the model’s output. By contrast, calibrated
    confidence outputs can indicate to what degree we can trust the model’s output.
    If the model is uncertain, this indicates that there is something about the input
    data that isn’t well represented in the model’s training data – indicating that
    the model is more likely to make a mistake. Thus, well-calibrated uncertainties
    allow us to decide whether to incorporate the model’s predictions in our decision
    making, or whether to ignore the model entirely.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 过度自信的预测在安全和任务关键应用中可能非常有问题，例如医学决策、自驾车以及法律或财务决策。具有过度自信预测的网络将缺乏向我们人类（或其他网络）指示它们何时可能出错的能力。这种缺乏意识可能变得危险，例如，当一个网络被用来帮助决定被告是否应该被允许保释时。假设一个网络接收到被告的数据（如过去的定罪记录、年龄、教育水平），并以95%的置信度预测不应允许保释。基于这个输出，法官可能错误地认为该模型可以信任，并主要根据模型的输出作出裁决。相比之下，经过校准的置信度输出可以表明我们可以多大程度上信任模型的输出。如果模型不确定，这表明输入数据中有一些在模型的训练数据中没有得到很好的表示——这表明模型更可能出错。因此，良好校准的不确定性使我们能够决定是否将模型的预测纳入我们的决策中，或是否完全忽略模型。
- en: 'Drawing and inspecting reliability plots is useful for visualizing calibration
    in a few neural networks. However, sometimes we want to compare the calibration
    performance across several neural networks, possibly each network using more than
    one configuration. In such cases where we need to compare many networks and settings,
    it is useful to summarize the calibration of a neural network in a scalar statistic.
    The **Expected Calibration Error** (**ECE**) represents such a summary statistic.
    For every bin in the reliability plot, it measures the difference between the
    observed accuracy, *acc*(*B*[*m*]), and the accuracy we would have expected based
    on the output score of the samples, *conf*(*B*[*m*]), which is defined as ![-1--
    |Bm |](img/file68.jpg)∑ [*i*∈*B*[m]]*ŷ*. Then, it takes a weighted average across
    all bins, where the weight for each bin is determined by the number of samples
    in the bin:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制和检查可靠性图表对于可视化一些神经网络的校准非常有用。然而，有时我们希望比较多个神经网络的校准性能，可能每个网络都使用了多个配置。在需要比较多个网络和设置的情况下，将神经网络的校准总结为一个标量统计量是很有用的。**期望校准误差**（**ECE**）就是这样的总结统计量。对于可靠性图表中的每个区间，它衡量观察到的准确度
    *acc*(*B*[*m*]) 和基于样本输出得分的预期准确度 *conf*(*B*[*m*]) 之间的差异，定义为 ![-1-- |Bm |](img/file68.jpg)∑
    [*i*∈*B*[m]]*ŷ*。然后，它对所有区间进行加权平均，其中每个区间的权重由该区间中的样本数决定：
- en: '![ M∑ ECE = |Bm-||acc(Bm ) − conf(Bm )| m=1 n ](img/file69.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![ M∑ ECE = |Bm-||acc(Bm ) − conf(Bm )| m=1 n ](img/file69.jpg)'
- en: This provides a first introduction to ECE and how it is measured. We will revisit
    ECE in more detail in [*Chapter 8*](CH8.xhtml#x1-1320008), [*Applying Bayesian
    Deep Learning*](CH8.xhtml#x1-1320008) by providing a code implementation as part
    of the *Revealing dataset shift with Bayesian* *methods* case study.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这为ECE的初步介绍以及如何衡量它提供了一个开端。我们将在[*第8章*](CH8.xhtml#x1-1320008)中详细回顾ECE，章节中将提供一个代码实现，作为*通过贝叶斯方法揭示数据集偏移*案例研究的一部分。
- en: In the case of a perfectly calibrated neural network output, the *ECE* would
    be zero. The more uncalibrated a neural network is, the larger *ECE* would become.
    Let us look at some of the reasons for which neural networks are poorly calibrated
    and overconfident.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个完全校准的神经网络输出情况下，*ECE*将为零。神经网络的校准程度越差，*ECE*将越大。让我们来看看神经网络校准差和过度自信的几个原因。
- en: 'One reason is that the softmax function, which is usually the last operation
    of a classification network, uses the exponential function to make sure that all
    values are positive:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一个原因是，softmax函数通常是分类网络的最后一个操作，它使用指数函数确保所有值都是正数：
- en: '![ zi σ(⃗z)i = ∑--e----- Kj=1ezj ](img/file70.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![ zi σ(⃗z)i = ∑--e----- Kj=1ezj ](img/file70.jpg)'
- en: The result of this is that small changes of the input to the softmax function
    can lead to substantial changes in its output.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，输入到 softmax 函数的微小变化会导致其输出发生显著变化。
- en: Another reason for overconfidence is the increased model capacity of modern
    deep neural networks (Chuan Guo, et al. (2017)). Neural network architectures
    have become deeper (more layers) and wider (more neurons per layer) over the years.
    Such deep and wide neural networks have high variance and can very flexibly fit
    large amounts of input data. When experimenting with either the number of layers
    for a neural network or the number of filters per layer, Chuan Guo et al. observed
    that mis-calibration (and thus overconfidence) becomes worse with deeper and wider
    architectures. They also found that using batch normalization or training with
    less weight decay had a negative impact on calibration. These observations point
    to the conclusion that increased model capacity for modern deep neural network
    contributes to their overconfidence.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个导致过度自信的原因是现代深度神经网络增加了模型的容量（Chuan Guo 等人，2017）。随着时间的推移，神经网络架构变得更深（更多的层）和更宽（每层更多的神经元）。这样的深度和宽度的神经网络具有较高的方差，能够非常灵活地拟合大量的输入数据。当实验调整神经网络的层数或每层的滤波器数量时，Chuan
    Guo 等人观察到，随着网络架构的加深和加宽，错误的校准（从而导致过度自信）会变得更严重。他们还发现，使用批量归一化或训练时减少权重衰减会对校准产生负面影响。这些观察结果表明，现代深度神经网络的模型容量增加是其过度自信的原因之一。
- en: Finally, overconfident estimates can result from choosing particular neural
    network components. It has been shown, for example, that fully-connected networks
    that use ReLU functions lead to continuous piecewise affine classifiers ([**?**]).
    This, in turn, implies that it is always possible to find input samples for which
    the ReLU network will produce high-confidence outputs. This holds even for input
    samples that are unlike the training data, for which generalization performance
    might be poor and we would thus expect lower confidence outputs. Such arbitrarily
    high confidence predictions also apply to convolutional networks that use either
    max- or mean-pooling following the convolutional layers, or any other network
    that results in a piecewise affine classifier function.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，过度自信的估计可能源于选择特定的神经网络组件。例如，已经证明，使用 ReLU 函数的全连接网络会导致连续分段仿射分类器（[**?**]）。这反过来意味着，总是可以找到一些输入样本，使得
    ReLU 网络会产生高度自信的输出。即使对于那些与训练数据不同的输入样本，这一结果依然成立，尽管此时网络的泛化性能可能较差，因此我们期望得到较低自信度的输出。这种任意高自信度的预测同样适用于使用最大池化或平均池化的卷积网络，或任何其他会导致分段仿射分类器函数的网络。
- en: The problem is inherent to such neural network architectures and can only be
    addressed by changing the architecture itself ([**?**]).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题是这种神经网络架构固有的，只能通过改变架构本身来解决（[**?**]）。
- en: 3.4.2 Predictions on out-of-distribution data
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.2 在分布外数据上的预测
- en: 'Now that we have seen that models can be overconfident and therefore uncalibrated,
    let’s look at another problem of neural networks. Neural networks are typically
    trained under the assumption that our test and train data are drawn from the same
    distribution. In practice, however, that is not always the case. The data that
    a model sees when it is deployed in the real world can change. We call these changes
    dataset shifts and they are typically divided into three categories:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了模型可能会过度自信，因此未经过校准，我们再来看一个神经网络的问题。神经网络通常在假设测试数据和训练数据来自同一分布的前提下进行训练。然而，实际上，情况并非总是如此。当一个模型在真实世界中部署时，它所看到的数据可能会发生变化。我们称这些变化为数据集偏移，通常将其分为三类：
- en: '**Covariate shift**: The feature distribution *p*(*x*) changes while *p*(*y*|*x*)
    is fixed'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协变量偏移**：特征分布 *p*(*x*) 发生变化，而 *p*(*y*|*x*) 保持不变'
- en: '**Open-set recognition**: New labels appear at test time'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放集识别**：测试时会出现新标签'
- en: '**Label shift**: The distribution of labels *p*(*y*) changes while *p*(*x*|*y*)
    is fixed'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签偏移**：标签分布 *p*(*y*) 发生变化，而 *p*(*x*|*y*) 保持不变'
- en: 'Examples of the preceding items include the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前述项目的示例：
- en: 'Covariate shift: A model is trained to recognize faces. The training data consists
    of faces of mostly young people. The model at test time sees faces of all ages.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协变量偏移：模型被训练用于识别面孔。训练数据主要由年轻人的面孔组成。在测试时，模型看到的是各个年龄段的面孔。
- en: 'Open-set recognition: A model is trained to classify a limited number of dog
    breeds. At test time, the model sees more dog breeds than present in the training
    dataset.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开集识别：模型被训练来分类有限数量的犬种。在测试时，模型会看到比训练数据集中更多的犬种。
- en: 'Label shift: A model is trained to predict different diseases, of which some
    are very rare at the time of training. However, over time, the frequency of a
    rare disease changes and it becomes one of the most frequently seen diseases at
    test time.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签偏移：一个模型被训练来预测不同的疾病，其中一些疾病在训练时非常罕见。然而，随着时间的推移，这些罕见疾病的发生频率发生变化，并且在测试时它们成为最常见的疾病之一。
- en: '![PIC](img/file71.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file71.png)'
- en: 'Figure 3.10: The training data distribution and data in the real world mostly
    overlap, but we cannot expect our model to perform well on the out-of-distribution
    points in the top right of the figure.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10：训练数据分布与实际世界中的数据大多数重合，但我们不能期望模型在图中右上角的分布外点上表现良好。
- en: 'As a result of these changes, a model might be less performant when deployed
    in the real world if it is confronted with data that was not drawn from the same
    distribution as the training data. How likely a model is to be confronted with
    out-of-distribution data depends very much on the environment in which the model
    is deployed: some environments are more static (lower chance of out-of-distribution
    data), while others are more dynamic (higher chance of out-of-distribution data).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些变化，当模型在实际环境中部署时，如果遇到的数据显示与训练数据分布不同，模型的表现可能会降低。模型面临分布外数据的可能性在很大程度上取决于模型部署的环境：有些环境较为静态（较低的分布外数据出现概率），而其他环境则较为动态（较高的分布外数据出现概率）。
- en: One reason for the problems of deep learning models with out-of-distribution
    data is that models often have a large number of parameters and can therefore
    memorize specific patterns and features of the training data instead of robust
    and meaningful representations of the data that reflect the underlying data distribution.
    When new data that looks slightly different from the training data presents itself
    at test time, the model does not actually have the ability to generalize and make
    the right prediction. One such example is an image of a cow (*Figure* [*3.11*](#x1-44008r11))
    on a beach, when cows in the training dataset happened to be on green grasslands.
    Models often use the context present in the data to make predictions.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型在处理分布外数据时的问题之一，是因为这些模型通常拥有大量的参数，因此可以记住训练数据中的特定模式和特征，而不是反映底层数据分布的稳健和有意义的表示。当测试时出现看起来与训练数据略有不同的新数据时，模型实际上并没有能力进行泛化并做出正确的预测。一个例子是海滩上的牛的图像（*图*
    [*3.11*](#x1-44008r11)），而训练数据集中的牛恰好是在绿色草地上。模型通常利用数据中的上下文来进行预测。
- en: '![PIC](img/file72.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file72.png)'
- en: 'Figure 3.11: An object in a different environment (here, a cow on a beach)
    can make it difficult for a model to recognize that the image contains the object'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11：在不同环境中的物体（这里是海滩上的牛）可能会使模型难以识别图像中包含该物体。
- en: Before we go over a practical example of how a simple model handles out-of-distribution
    data, let’s examine a few approaches that can highlight the problem of out-of-distribution
    data in typical neural networks. Ideally, we would like our model to exdivss high
    uncertainty when it encounters data that is different from the distribution it
    was trained on. If that is the case, out-of-distribution data will not be a big
    problem when a model is deployed in the real world. For example, in mission-critical
    systems where errors of a model are costly, there is often a certain confidence
    threshold that should be met before the prediction is trusted. If a model is well-calibrated
    and it assigns a low confidence score to out-of-distribution inputs, the business
    logic around the model can throw an exception and not use the model’s output.
    For example, a self-driving car can alert the driver that it should take over
    control or it can slow down to avoid an accident.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨如何通过一个简单模型处理分布外数据的实际例子之前，让我们先看看几种方法，这些方法可以突出典型神经网络中分布外数据的问题。理想情况下，我们希望模型在遇到与其训练数据分布不同的数据时，能够表现出较高的不确定性。如果是这样，分布外数据在模型部署到实际环境中时就不会是一个大问题。例如，在任务关键型系统中，模型错误的代价很高，因此通常会有一个置信度阈值，模型的预测必须达到该阈值才会被信任。如果一个模型经过良好的标定，并且对分布外输入赋予较低的置信度评分，那么围绕该模型的业务逻辑可以抛出异常并且不使用模型的输出。例如，自动驾驶汽车可以提醒司机接管控制，或者它可以减速以避免发生事故。
- en: However, common *neural networks do not know when they do not know*; they typically
    do not assign a low confidence score to out-of-distribution data.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，常见的*神经网络不知道自己什么时候不知道*；它们通常不会对外部分布数据赋予较低的置信度分数。
- en: 'An example of this is given in a Google paper titled *Can You Trust Your Model’s*
    *Uncertainty? Evaluating predictive Uncertainty Under Dataset Shift*. The paper
    shows that if you apply perturbations to a test dataset such as blur or noise,
    such that the images become more and more out-of-distribution, the accuracy of
    the model goes down. However, the confidence calibration of the model also decreases.
    This means that the scores of the model are not trustworthy anymore on out-of-distribution
    data: they do not accurately indicate the model’s confidence in its predictions.
    We will explore this behaviour ourselves in the *Revealing dataset shift with
    Bayesian methods* case study in [*Chapter 8*](CH8.xhtml#x1-1320008), [*Applying*
    *Bayesian Deep Learning*](CH8.xhtml#x1-1320008).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Google 论文《*你能信任你模型的不确定性吗？在数据集偏移下评估预测不确定性*》中给出了一个例子。论文表明，如果你对测试数据集应用模糊或噪声等扰动，使得图像变得越来越偏离分布，模型的准确度会下降。然而，模型的置信度校准也会下降。这意味着在外部分布数据上，模型的得分已经不再可信：它们无法准确反映模型对其预测的信心。我们将在[*第
    8 章*](CH8.xhtml#x1-1320008)的案例研究《通过贝叶斯方法揭示数据集偏移》中探索这一行为，[*应用* *贝叶斯深度学习*](CH8.xhtml#x1-1320008)。
- en: 'Another way to determine how a model handles out-of-distribution data is by
    feeding it data that is not just perturbed, but completely different from the
    dataset it was trained on. The procedure to measure the model’s out-of-distribution
    detection performance is then as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种确定模型如何处理外部分布数据的方法是输入与其训练数据集完全不同的数据，而不仅仅是扰动过的数据。衡量模型外部分布检测性能的过程如下：
- en: Train a model on an in-distribution dataset.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在内部分布数据集上训练一个模型。
- en: Save the confidence scores of the model on the in-distribution test set.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存模型在内部分布测试集上的置信度分数。
- en: Feed a completely different, out-of-distribution dataset to the model and save
    the corresponding confidence scores of the model.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型输入一个完全不同的外部分布数据集，并保存模型对应的置信度分数。
- en: 'Now, treat the scores from both datasets as scores from a binary problem: in-distribution
    or out-of-distribution. Compute binary metrics, such as the **area under the Receiver**
    **Operating Characteristic** (**AUROC**) curve or the area under the precision-recall
    curve.'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将来自两个数据集的得分视为二分类问题的得分：内部分布或外部分布。计算二分类指标，例如**接收者操作特征**（**AUROC**）曲线下的面积或精确度-召回曲线下的面积。
- en: This strategy tells you how well your model can separate in-distribution from
    out-of-distribution data. The assumption is that in-distribution data should always
    receive a higher confidence score than out-of-distribution data; in the ideal
    scenario, there is no overlap between the two distributions. In practice, however,
    this is not the case. Models do often give high confidence scores to out-of-distribution
    data. We will explore an example of this in the next section and a few solutions
    to this problem in later chapters.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个策略告诉你模型在多大程度上能够区分内部分布数据和外部分布数据。假设内部分布数据应该始终比外部分布数据获得更高的置信度分数；在理想情况下，两者之间没有重叠。然而，实际上情况并非如此。模型确实经常会给外部分布数据较高的置信度分数。我们将在下一节中探讨一个例子，并在后续章节中提出一些解决方案。
- en: 3.4.3 Example of confident, out-of-distribution predictions
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.3 自信的外部分布预测示例
- en: Let’s see how a vanilla neural net can produce confident predictions on out-of-distribution
    data. In this example, we will first train a model and then feed it out-of-distribution
    data. To keep things simple, we will use a dataset with different types of dogs
    and cats and build a binary classifier that predicts whether the image contains
    a dog or a cat.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个普通神经网络是如何对外部分布数据做出自信预测的。在这个例子中，我们首先训练一个模型，然后输入外部分布数据。为了简单起见，我们将使用一个包含不同种类狗和猫的数据集，并构建一个二分类器，预测图像中是狗还是猫。
- en: 'We first download our data:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先下载我们的数据：
- en: '[PRE5]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We then load our data into a dataframe:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据加载到数据框中：
- en: '[PRE6]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can then use scikit-learn’s `train_test_val()` function to create a training
    and validation set:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用 scikit-learn 的`train_test_val()`函数来创建训练集和验证集：
- en: '[PRE7]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We then create our train and validation data. Our `divprocess()` function loads
    our download image into memory and formats our label such that our model can process
    it. We use a batch size of 256 and an image size of 160x160 pixels:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建我们的训练和验证数据。我们的`divprocess()`函数将下载的图像加载到内存中，并格式化标签以便模型处理。我们使用256的批量大小和160x160像素的图像大小：
- en: '[PRE8]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can now create our model. To speed up learning, we can use transfer learning
    and start with a model that was pre-trained on ImageNet:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建我们的模型。为了加速学习，我们可以使用迁移学习，并从一个在ImageNet上预训练过的模型开始：
- en: '[PRE9]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Before we can train the model, we first need to compile it. Compiling simply
    means that we specify a loss function and an optimizer for the model and, optionally,
    add some metrics for monitoring during training. In the following code, we specify
    that the model should be trained using the binary cross-entropy loss and the Adam
    optimizer and that, during training, we want to monitor the model’s accuracy:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型之前，我们首先需要编译它。编译意味着我们为模型指定一个损失函数和一个优化器，并可选地添加一些用于训练期间监控的度量。在以下代码中，我们指定模型应该使用二元交叉熵损失和Adam优化器进行训练，并且在训练期间我们想要监控模型的准确性：
- en: '[PRE10]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Because of transfer learning, just fitting our model for three epochs leads
    to a validation accuracy of about 99 percent:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于迁移学习，仅训练模型三轮就能获得大约99%的验证准确率：
- en: '[PRE11]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s also test our model on the test set of this dataset. We first prepare
    our dataset:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在该数据集的测试集上测试我们的模型。我们首先准备好数据集：
- en: '[PRE12]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can then feed the dataset to our trained model. We obtain a test set accuracy
    of about 98.3 percent:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将数据集输入到训练好的模型中。我们获得了大约98.3%的测试集准确率：
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We now have a model that is pretty good at classifying cats and dogs. But what
    will happen if we give this model an image that is neither a cat or a dog? Ideally,
    the model should recognize that this image is not part of the data distribution
    and should output close to a uniform distribution. Let’s see if this actually
    happens in practice. We feed our model some images from the ImageNet dataset –
    the actual dataset that was used to pre-train our model. The ImageNet dataset
    is large. That is why we download a subset of the dataset: a dataset called Imagenette.
    This dataset contains just 10 out of the 1,000 classes of the original ImageNet
    dataset:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个能够很好地分类猫和狗的模型。但是如果我们给这个模型一个既不是猫也不是狗的图像，会发生什么呢？理想情况下，模型应该识别出该图像不属于数据分布的一部分，并应该输出接近均匀分布的结果。让我们看看在实际操作中是否真的发生了这种情况。我们将一些来自ImageNet数据集的图像输入到模型中——这是用于预训练我们模型的实际数据集。ImageNet数据集很大。这就是为什么我们下载了该数据集的一个子集：一个名为Imagenette的数据集。该数据集仅包含原始ImageNet数据集中的10个类别：
- en: '[PRE14]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We then take an image from the `parachute` class:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们从`parachute`类中选取一张图像：
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The image clearly does not contain a dog or a cat; it is obviously out-of-distribution:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 该图像显然不包含狗或猫；它显然是超出分布的：
- en: '![PIC](img/file73.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file73.png)'
- en: 'Figure 3.12: An image of a parachute from the ImageNet dataset'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：来自ImageNet数据集的降落伞图像
- en: 'We run the image through our model and print the score:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将图像通过我们的模型并打印分数：
- en: '[PRE16]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We can see that the model classifies the image of a parachute as a dog with
    more than 99% confidence.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，模型将降落伞图像分类为狗，且信心度超过99%。
- en: We can test the model’s performance on the ImageNet `parachute` class more systematically
    as well. Let’s run all the parachute images from the train split through the model
    and plot a histogram of the scores of the `dog` class.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以更系统地测试模型在ImageNet `parachute`类上的表现。让我们将所有来自训练集的降落伞图像通过模型，并绘制出`dog`类的分数直方图。
- en: 'We first create a small function to create special dataset with all the parachute
    images:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个小函数，用来创建包含所有降落伞图像的特定数据集：
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can then feed the dataset to our model and create a list of all the softmax
    scores related to the `dog` class:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将数据集输入到我们的模型，并创建与`dog`类相关的所有softmax分数列表：
- en: '[PRE18]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can then plot a histogram with these scores – this shows us the distribution
    of softmax scores:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用这些分数绘制直方图——这将显示softmax分数的分布：
- en: '[PRE19]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Ideally, we want these scores to be distributed close to 0.5 as the images
    in this dataset are neither dogs nor cats; the model should be very uncertain:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望这些分数分布接近0.5，因为该数据集中的图像既不是狗也不是猫；模型应该非常不确定：
- en: '![PIC](img/file74.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file74.png)'
- en: 'Figure 3.13: Distribution of softmax scores on the parachute dataset'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13：降落伞数据集的softmax分数分布
- en: However, we see something very different. More than 800 images are classified
    as a dog with at least 90% confidence. Our model clearly does not know how to
    handle out-of-distribution data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们看到的却是完全不同的情况。超过800张图像被错误分类为狗，且置信度至少为90%。我们的模型显然不知道如何处理分布外数据。
- en: 3.4.4 Susceptibility to adversarial manipulations
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.4 对对抗性操作的易感性
- en: 'One other vulnerability of most neural networks is that they are susceptible
    to adversarial attacks. Adversarial attacks, simply put, are ways to fool a deep
    learning system, most often in ways that would not fool humans. These attacks
    can be harmless or harmful. Here are some examples of adversarial attacks:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数神经网络的另一个脆弱性是它们容易受到对抗性攻击。简单来说，对抗性攻击是欺骗深度学习系统的方式，通常这些方式是人类不会被欺骗的。这些攻击可以是无害的也可以是有害的。以下是一些对抗性攻击的例子：
- en: A classifier can detect different types of animals. It classifies an image of
    a panda as a panda with 57.7% confidence. By slightly perturbing the image in
    a way that is invisible to humans, the image is now classified as a gibbon with
    93.3% confidence.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个分类器可以检测不同种类的动物。它将一张熊猫的图像以57.7%的置信度分类为熊猫。通过对图像进行微小扰动，使其对人类不可见，图像现在以93.3%的置信度被分类为长臂猿。
- en: A model can detect whether a movie recommendation is positive or negative. It
    classifies a given movie as negative. By changing a word that does not change
    the overall tone of the review, for example, from ”surprising” to ”astonishing,”
    the prediction of the model can change from a negative to a positive recommendation.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型可以检测电影推荐是正面还是负面。它将给定的电影分类为负面。通过改变一个不会改变整体评论基调的词汇，例如，将“surprising”改为“astonishing”，模型的预测可以从负面推荐变为正面推荐。
- en: A stop sign detector can detect stop signs. However, by putting a relatively
    small sticker on top of the stop sign, the model no longer recognises the stop
    sign.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止标志检测器可以检测停止标志。然而，通过在停止标志上贴一个相对较小的贴纸，模型就不再识别停止标志了。
- en: 'These examples show that there are different kinds of adversarial attacks.
    A useful way to categorize adversarial attacks, is by trying to determine how
    much information about the model is available to the human (or machine) attacking
    the model. An attacker can always feed an input to the model, but what the model
    returns or how the attacker can inspect the model varies. With this lens, we can
    see the following categories:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子表明，有不同种类的对抗性攻击。一种有用的对抗性攻击分类方法是，尝试确定攻击者对模型了解多少信息（无论是人类还是机器）。攻击者总是可以将输入传递给模型，但模型返回什么或者攻击者如何检查模型是不同的。通过这个视角，我们可以看到以下类别：
- en: '*Hard-label black box*: The attacker only has access to the labels resulting
    from feeding the model an input.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*硬标签黑盒*：攻击者只能访问通过向模型输入获得的标签。'
- en: '*Soft-label black box*: The attacker has access to the scores and the labels
    of the model.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*软标签黑盒*：攻击者可以访问模型的分数和标签。'
- en: '*White box* setting: The attacker has full access to the model. They can access
    the weights and can see the scores, the structure of the model, and so on.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*白盒*设置：攻击者可以完全访问模型。他们可以访问权重，查看分数、模型结构等。'
- en: You can imagine that these different settings make it more or less difficult
    to attack a model. If people who want to fool a model can only see the label resulting
    from an input, they cannot be sure that a small change of the input will lead
    to a difference in the model’s behavior as long as the label stays the same. This
    becomes easier when they have access to the model’s label and scores. They can
    then see if a change in the input increases or decreases the confidence of the
    model. As a result, they can more systematically try to change our input, in ways
    that decrease the model’s confidence in the label. This might make it possible
    to find a vulnerability of the model, given that there is enough time to change
    the input in an iterative fashion. Now, when someone has full access to the model
    (white box setting), finding a vulnerability might become even easier. They can
    now use more information to guide the change of the image, such as the gradient
    of the loss with respect to the input image.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象，这些不同的设置使得攻击模型的难易程度有所不同。如果想要欺骗模型的人只能看到输入的标签结果，他们无法确定输入的细微变化是否会导致模型行为的变化，只要标签保持不变。当他们可以访问模型的标签和得分时，这种情况就变得更加容易。他们就可以看到输入变化是否增加或减少了模型的置信度。结果，他们可以更系统地尝试以减少模型对标签的置信度的方式来改变我们的输入。这可能会让我们找到模型的脆弱性，前提是有足够的时间以迭代的方式来改变输入。现在，如果有人拥有模型的完全访问权限（白盒设置），那么找到脆弱性可能会变得更容易。因为他们可以使用更多的信息来引导图像的变化，比如输入图像的损失梯度。
- en: The amount of information available to an attacker is not the only way to distinguish
    between different kinds of adversarial attacks; there are many types of attacks.
    For example, in the context of attacks on vision models, some attacks are based
    on single-patch adjustments of an image (or even single pixels!) while other attacks
    will change an entire image. Some attacks are specific to a single model, some
    attacks can be applied to multiple models. We can also distinguish between attacks
    that digitally manipulate an image and attacks that can be applied in the real
    world to fool a model, or attacks that are visible by the human eye and attacks
    that are not. As a result of the wide variety of attacks, the research literature
    about this topic is still very active – there are always new ways to attack a
    model, and subsequently a need to find defenses for these attacks.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者可获得的信息量并不是区分不同类型对抗性攻击的唯一标准；攻击方式有很多种。例如，在针对视觉模型的攻击中，有些攻击基于对图像的单一补丁调整（甚至是单个像素！），而其他攻击则会改变整个图像。有些攻击特定于某个模型，有些攻击可以应用于多个模型。我们还可以区分那些通过数字方式操控图像的攻击和那些能够在现实世界中实施、欺骗模型的攻击，或者是那些人眼可见的攻击与不可见的攻击。由于攻击方式种类繁多，关于这个话题的研究文献依然非常活跃——总是有新的方法来攻击模型，进而也需要找到应对这些攻击的防御方法。
- en: 'In the section about out-of-distribution data, we trained a model to determine
    whether a given image is a cat or a dog. We saw that the classifier worked well:
    it achieved a test accuracy of about 98.3 percent. Is this model robust to adversarial
    attacks? Let’s create an attack to find out. We will use the **fast-gradient sign
    method** (**FGSM**) to slightly perturb an image of a dog and make the model think
    it is actually an image of a cat. The fast-gradient sign method was introduced
    in 2014 by Ian Goodfellow et al. and remains one of the most famous examples of
    an adversarial attack. This is probably because of its simplicity; we will see
    that we will only need a few lines of code to create such an attack. Moreover,
    the results of this attack are astounding – Goodfellow himself mentioned that
    he could not really believe the results when he first tested this attack and he
    had to verify that the perturbed, adversarial image he fed to the model was actually
    different from the original input image.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在关于分布外数据的章节中，我们训练了一个模型来判断给定的图像是猫还是狗。我们看到分类器的表现非常好：它的测试准确率大约为98.3%。这个模型对对抗性攻击是否具有鲁棒性？让我们创造一个攻击方法来验证一下。我们将使用**快速梯度符号方法**（**FGSM**）轻微扰动一张狗的图像，使得模型误认为它实际上是一张猫的图像。快速梯度符号方法是由Ian
    Goodfellow等人于2014年提出的，至今仍然是最著名的对抗性攻击之一。这可能是因为它的简单性；我们将看到，仅需几行代码就能创建这样的攻击。此外，这种攻击的结果令人震惊——Goodfellow本人提到，当他第一次测试这个攻击时，他简直不敢相信结果，甚至需要验证输入给模型的扰动图像确实与原始图像不同。
- en: 'To create an effective adversarial image, we have to make sure that the pixels
    in the image change – but only by so much that the change does not become apparent
    to the human eye. If we perturb the pixels in our image of a dog in such a way
    that the image now actually looks like a cat, then the model is not mistaken if
    it classifies that image as a cat. We make sure that we do not perturb the image
    too much by constraining the perturbation by the max norm – this essentially tells
    us that no pixel in the image can change by more than some amount *𝜖*:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建有效的对抗图像，我们必须确保图像中的像素发生变化——但变化的幅度不能大到以至于人眼能察觉。如果我们以某种方式扰动狗的图像，使得图像看起来像猫，那么如果模型将其分类为猫，模型并没有犯错。我们确保不会对图像进行过多扰动，通过最大范数约束来限制扰动——这基本上告诉我们图像中任何像素的变化不能超过某个量*𝜖*：
- en: '![∥˜x − x∥∞ ≤ 𝜖 ](img/file75.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![∥˜x − x∥∞ ≤ 𝜖 ](img/file75.jpg)'
- en: Where *x* is our perturbed image and *x* our original input image.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *x* 是我们的扰动图像，*x* 是我们原始的输入图像。
- en: 'Now, to create our adversarial example in the fast-gradient sign method, we
    use the gradient of the loss with respect to our input image to create a new image.
    Instead of minimizing the loss as we want to do in gradient descent, we now want
    to maximize the loss. Given our network weights *𝜃*, input *x*, label *y*, and
    *J* as a function to compute our loss, we can create an adversarial image by perturbing
    the image in the following way:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了使用快速梯度符号法创建我们的对抗样本，我们使用关于输入图像的损失梯度来创建新图像。与梯度下降法中最小化损失不同，我们现在想要最大化损失。给定我们的网络权重*𝜃*、输入*x*、标签*y*，以及用来计算损失的函数*J*，我们可以通过以下方式扰动图像来创建对抗图像：
- en: '![η = 𝜖sgn(∇xJ (𝜃,x,y)) ](img/file76.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![η = 𝜖sgn(∇xJ (𝜃,x,y)) ](img/file76.jpg)'
- en: 'In this equation, we compute the sign of the gradient of the loss with respect
    to the input, i.e. determine whether the gradient is positive (1), negative (-1)
    or 0\. The sign enforces the max norm constraint, and by multiplying it by epsilon,
    we make sure that our perturbations are small – computing the sign just tells
    us that if we want to add or subtract epsilon in order to perturb the image in
    a way that hurts the model’s performance on the image. *η* is now the perturbation
    that we want to add to our image:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，我们计算损失关于输入的梯度的符号，即确定梯度是正（1）、负（-1）还是 0。符号约束最大范数，通过将其乘以 epsilon，我们确保扰动很小——计算符号只是告诉我们，如果我们想通过加或减
    epsilon 来扰动图像，以便对模型的图像识别产生影响。*η* 就是我们要添加到图像中的扰动：
- en: '![˜x = x+ η ](img/file77.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![˜x = x+ η ](img/file77.jpg)'
- en: 'Let’s see what this looks like in Python. Given our trained network that classifies
    images as either dogs or cats, we can create a function that creates a perturbation
    that, when multiplied by epsilon and added to our image, creates an adversarial
    attack:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下在 Python 中的实现。给定我们已经训练好的网络，它可以将图像分类为狗或猫，我们可以创建一个函数，生成一个扰动，当它与 epsilon
    相乘并加到我们的图像上时，会形成一次对抗攻击：
- en: '[PRE20]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We then create a small function that runs an input image through our model
    and returns the confidence of the model that the image contains a dog:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建一个小函数，将输入图像通过我们的模型，并返回模型认为该图像包含狗的置信度：
- en: '[PRE21]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We download an image of a cat:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载了一张猫的图片：
- en: '[PRE22]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we pre-process it so we can feed it to our model. We set the label to
    0, which corresponds to the `cat` label:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们对图像进行预处理，以便将其输入到模型中。我们将标签设置为 0，对应于 `cat` 标签：
- en: '[PRE23]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can perturb our image:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以扰动我们的图像：
- en: '[PRE24]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s now get the confidence of the model that the original image is a cat,
    and the confidence of the model that the perturbed image is a dog:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们获取模型对原始图像为猫的置信度，以及模型对扰动图像为狗的置信度：
- en: '[PRE25]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'With this in place, we can create the following plot, showing the original
    image, the perturbation applied to the image, and the perturbed image:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个基础，我们可以创建以下图表，展示原始图像、施加在图像上的扰动以及扰动后的图像：
- en: '[PRE26]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '*Figure 3.14* shows both the original image and the perturbed image along with
    the model prediction for each image.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.14* 展示了原始图像和扰动图像，并显示了每张图像的模型预测结果。'
- en: '![PIC](img/file78.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file78.png)'
- en: 'Figure 3.14: Example of an adversarial attack'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14：对抗攻击的示例
- en: In *Figure* [*3.14*](#x1-46175r14), we can see that our model initially classifies
    the image as a cat, with a confidence of 100 percent. After we applied the perturbation
    (shown in the middle) to our initial cat image (shown on the left), our image
    (on the right) is now classified as a dog with 98.73 percent confidence, although
    the image visually looks the same as the original input image. We successfully
    created an adversarial attack that fools our model!
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图* [*3.14*](#x1-46175r14)中，我们可以看到，模型最初将图像分类为猫，置信度为100%。当我们对原始猫图像（左侧）应用扰动（中间显示）后，右侧的图像现在被分类为狗，置信度为98.73%，尽管该图像在视觉上看起来与原始输入图像相同。我们成功地创建了一个对抗性攻击，欺骗了我们的模型！
- en: 3.5 Summary
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.5 总结
- en: 'In this chapter, we have seen different types of common neural networks. First,
    we discussed the key building blocks of neural networks with a special focus on
    the multi-layer perceptron. Then we reviewed common neural network architectures:
    convolutional neural networks, recurrent neural networks, and the attention mechanism.
    All these components allow us to build very powerful deep learning models that
    can sometimes achieve super-human performance. However, in the second part of
    the chapter, we reviewed a few problems of neural networks. We discussed how they
    can be overconfident, and do not handle out-of-distribution data very well. We
    also saw how small, imperceptible changes to a neural network’s input can cause
    the model to make an incorrect prediction.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们介绍了几种常见的神经网络类型。首先，我们讨论了神经网络的关键构建块，特别关注了多层感知器。接着，我们回顾了常见的神经网络架构：卷积神经网络、递归神经网络和注意力机制。所有这些组件使我们能够构建非常强大的深度学习模型，这些模型有时可以达到超人类的表现。然而，在本章的第二部分，我们回顾了神经网络的一些问题。我们讨论了它们如何表现得过于自信，并且在处理分布外数据时表现不佳。我们还看到，神经网络输入的微小、不可察觉的变化可以导致模型做出错误的预测。
- en: In the next chapter, we will combine the concepts learned in this chapter and
    in [*Chapter 3*](#x1-350003), [*Fundamentals of Deep Learning*](#x1-350003), and
    discuss Bayesian deep learning, which has the potential to overcome some of the
    challenges of standard neural networks we have seen in this chapter.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将结合本章和[ *第3章*](#x1-350003)，[ *深度学习基础*](#x1-350003)中学到的概念，讨论贝叶斯深度学习，它有可能克服我们在本章中看到的标准神经网络的一些挑战。
- en: 3.6 Further reading
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.6 进一步阅读
- en: 'There are a lot of great resources to learn more about the essential building
    blocks of deep learning. Here are just a few popular resources that are a great
    start:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多优秀的资源可以帮助我们深入了解深度学习的基本构建块。以下是一些很好的起点资源：
- en: 'Nielsen, M.A., 2015\. *Neural networks* *and deep learning* (Vol. 25). San
    Francisco, CA, USA: Determination press., [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nielsen, M.A., 2015\. *神经网络与深度学习*（第25卷）。美国加州旧金山：Determination press。，[http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)。
- en: Chollet, F., 2021\. *Deep learning with Python*. Simon and Schuster.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chollet, F., 2021\. *Python深度学习*。Simon 和 Schuster。
- en: Raschka, S., 2015\. *Python Machine Learning*. Packt Publishing Ltd.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raschka, S., 2015\. *Python 机器学习*。Packt Publishing Ltd.
- en: Ng, Andrew, 2022, *Deep Learning Specialization*. Coursera.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ng, Andrew, 2022，*深度学习专业化*。Coursera。
- en: Johnson, Justin, 2019\. EECS 498-007 / 598-005, *Deep Learning for* *Computer
    Vision*. University of Michigan.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Johnson, Justin, 2019\. EECS 498-007 / 598-005, *深度学习与计算机视觉*。密歇根大学。
- en: 'To learn more about the problems of deep learning models, you can read some
    of the following resources:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于深度学习模型问题的内容，你可以阅读以下一些资源：
- en: 'Overconfidence and calibration:'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过度自信与校准：
- en: Guo, C., Pleiss, G., Sun, Y. and Weinberger, K.Q., 2017, July. *On calibration
    of modern neural networks*. In International conference on machine learning (pp.
    1321-1330). PMLR.
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo, C., Pleiss, G., Sun, Y. 和 Weinberger, K.Q., 2017年7月。*现代神经网络的校准*。在国际机器学习会议（第1321-1330页）。PMLR。
- en: Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
    J., Lakshminarayanan, B. and Snoek, J., 2019\. *Can you* *trust your model’s uncertainty?
    evaluating predictive uncertainty* *under dataset shift.* Advances in neural information
    processing systems, 32.
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
    J., Lakshminarayanan, B. 和 Snoek, J., 2019\. *你能信任模型的不确定性吗？评估数据集转移下的预测不确定性*。神经信息处理系统进展，32。
- en: 'Out-of-distribution detection:'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布外检测：
- en: Hendrycks, D. and Gimpel, K., 2016\. *A baseline for detecting* *misclassified
    and out-of-distribution examples in neural networks.* arXiv preprint arXiv:1610.02136.
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks, D. 和 Gimpel, K., 2016\. *神经网络中* *错误分类和分布外样本的检测基准*。arXiv 预印本 arXiv:1610.02136。
- en: Liang, S., Li, Y. and Srikant, R., 2017\. *Enhancing the reliability* *of out-of-distribution
    image detection in neural networks.* arXiv preprint arXiv:1706.02690.
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang, S., Li, Y. 和 Srikant, R., 2017\. *增强神经网络中分布外图像检测的可靠性。* arXiv 预印本 arXiv:1706.02690。
- en: Lee, K., Lee, K., Lee, H. and Shin, J., 2018\. *A simple* *unified framework
    for detecting out-of-distribution samples and* *adversarial attacks.* Advances
    in neural information processing systems, 31.
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee, K., Lee, K., Lee, H. 和 Shin, J., 2018\. *一个简单的* *统一框架用于检测分布外样本和* *对抗攻击。*
    神经信息处理系统进展，31。
- en: Fort, S., Ren, J. and Lakshminarayanan, B., 2021\. *Exploring* *the limits of
    out-of-distribution detection.* Advances in Neural Information Processing Systems,
    34, pp.7068-7081.
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fort, S., Ren, J. 和 Lakshminarayanan, B., 2021\. *探索* *分布外检测的极限*。神经信息处理系统进展，34，第7068-7081页。
- en: 'Adversarial attacks:'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗攻击：
- en: Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.
    and Fergus, R., 2013\. *Intriguing properties of* *neural networks*. arXiv preprint
    arXiv:1312.6199.
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.
    和 Fergus, R., 2013\. *神经网络的* *有趣特性*。arXiv 预印本 arXiv:1312.6199。
- en: Goodfellow, I.J., Shlens, J. and Szegedy, C., 2014\. *Explaining and* *harnessing
    adversarial examples*. arXiv preprint arXiv:1412.6572.
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow, I.J., Shlens, J. 和 Szegedy, C., 2014\. *解释和* *利用对抗样本*。arXiv 预印本
    arXiv:1412.6572。
- en: Nicholas Carlini, 2019\. *Adversarial Machine Learning Reading* *List* [https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html).
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nicholas Carlini, 2019\. *对抗性机器学习阅读* *列表* [https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html)。
- en: 'You can have a look at the following resources to dive deeper into the topics
    and experiments covered in this chapter:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看以下资源，以深入了解本章所涵盖的主题和实验：
- en: 'Jasper Snoek, MIT 6.S191: *Uncertainty in Deep Learning*, January 2022.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jasper Snoek, MIT 6.S191：*深度学习中的不确定性*，2022年1月。
- en: TensorFlow Core Tutorial, *Adversarial example using FGSM*.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 核心教程，*使用FGSM生成对抗样本*。
- en: Goodfellow, I.J., Shlens, J. and Szegedy, C., 2014\. *Explaining and* *harnessing
    adversarial examples*. arXiv preprint arXiv:1412.6572.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow, I.J., Shlens, J. 和 Szegedy, C., 2014\. *解释和* *利用对抗样本*。arXiv 预印本
    arXiv:1412.6572。
- en: Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of
    modern neural networks. In *International Conference on* *Machine Learning*, pages
    1321–1330\. PMLR, 2017.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuan Guo, Geoff Pleiss, Yu Sun 和 Kilian Q Weinberger. 现代神经网络的标定问题。发表于 *国际机器学习会议*，第1321-1330页。PMLR,
    2017。
- en: Stanford University School of Engineering, CS231N, *Lecture 16 —* *Adversarial
    Examples and Adversarial Training*.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯坦福大学工程学院，CS231N，*第16讲 —* *对抗样本与对抗训练*。
- en: Danilenka, Anastasiya, Maria Ganzha, Marcin Paprzycki, and Jacek Mańdziuk, 2022\.
    *Using adversarial images to improve outcomes of* *federated learning for non-IID
    data.* arXiv preprint arXiv:2206.08124.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Danilenka, Anastasiya, Maria Ganzha, Marcin Paprzycki 和 Jacek Mańdziuk, 2022\.
    *使用对抗图像改进非IID数据的* *联邦学习结果*。arXiv 预印本 arXiv:2206.08124。
- en: Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.
    and Fergus, R., 2013\. *Intriguing properties of neural* *networks*. arXiv preprint
    arXiv:1312.6199.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.
    和 Fergus, R., 2013\. *神经网络的* *有趣特性*。arXiv 预印本 arXiv:1312.6199。
- en: 'Sharma, A., Bian, Y., Munz, P. and Narayan, A., 2022\. *Adversarial* *Patch
    Attacks and Defences in Vision-Based Tasks: A Survey*. arXiv preprint arXiv:2206.08304.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma, A., Bian, Y., Munz, P. 和 Narayan, A., 2022\. *基于视觉任务的对抗性* *补丁攻击与防御：一项调查*。arXiv
    预印本 arXiv:2206.08304。
- en: Nicholas Carlini, 2019\. *Adversarial Machine Learning Reading List* [https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nicholas Carlini, 2019\. *对抗性机器学习阅读列表* [https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html)。
- en: Parkhi, O.M., Vedaldi, A., Zisserman, A. and Jawahar, C.V., 2012, June. *Cats
    and dogs*. In 2012 IEEE conference on computer vision and pattern recognition
    (pp. 3498-3505). IEEE. (Dataset cat vs dog).
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parkhi, O.M., Vedaldi, A., Zisserman, A. 和 Jawahar, C.V., 2012年6月。*猫与狗*。发表于2012年IEEE计算机视觉与模式识别大会（第3498-3505页）。IEEE。（数据集：猫与狗）。
- en: 'Deng, J., Dong, W., Socher, R., Li, L.J., Li, K. and Fei-Fei, L., 2009, June.
    *Imagenet: A large-scale hierarchical image database*. In 2009 IEEE conference
    on computer vision and pattern recognition (pp. 248-255). Ieee. (ImageNet dataset).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邓杰、董文、索彻、李俊杰、李凯和费菲，2009年6月。*Imagenet：一个大规模的层次化图像数据库*。发表于2009年IEEE计算机视觉与模式识别会议（第248-255页）。IEEE。（ImageNet数据集）。
- en: Matthew D Zeiler and Rob Fergus. *Visualizing and understanding* *convolutional
    networks*. In European conference on computer vision, pages 818–833\. Springer,
    2014.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马修·D·泽勒和罗布·费格斯。*可视化与理解* *卷积网络*。发表于欧洲计算机视觉会议，第818–833页。Springer，2014年。
