- en: Tips, Tricks, and the Road Ahead
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示、技巧与前进的道路
- en: In this book, we covered how to apply various deep learning networks to develop
    prediction and classification models. Several tips and tricks that we covered
    were unique to certain application areas and helped us arrive at better prediction
    or classification performance for the models that we developed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们介绍了如何应用各种深度学习网络来开发预测和分类模型。我们所介绍的一些技巧和方法是针对特定应用领域的，并帮助我们在开发的模型中实现更好的预测或分类性能。
- en: In this chapter, we will go over certain tips and tricks that will be very handy
    when you continue your journey of applying these methods to new data and different
    problems. We will cover four topics in total. Note that these approaches haven't
    been covered in the previous chapters, but we will make use of some of the examples
    from them to illustrate their use.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一些技巧和方法，这些方法在你将这些方法应用于新数据和不同问题时将非常有用。我们将涵盖四个主题。请注意，这些方法在之前的章节中没有介绍，但我们将利用其中的一些示例来说明它们的使用。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: TensorBoard for training performance visualization
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练性能可视化的 TensorBoard
- en: Visualizing deep network models with LIME
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LIME 可视化深度网络模型
- en: Visualizing model training with tfruns
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 tfruns 可视化模型训练
- en: Early stopping of network training
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络训练的提前停止
- en: TensorBoard for training performance visualization
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于训练性能可视化的 TensorBoard
- en: For visualizing deep network training performance, TensorBoard is a useful tool
    that is available as part of the TensorFlow package. We will rerun the deep network
    model that we used in [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml),
    *Deep Neural Networks for Multi-Class Classification*, where we used CTG data
    to develop a multi-class classification model for patients. For the code related
    to data processing, the model architecture, and compiling the model, you can refer
    to [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep Neural Networks
    for Multi-Class Classification*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可视化深度网络训练性能，TensorBoard 是一个有用的工具，作为 TensorFlow 包的一部分提供。我们将重新运行在[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)，*多类分类的深度神经网络*中使用的深度网络模型，在那里我们使用
    CTG 数据开发了一个用于患者的多类分类模型。有关数据处理、模型架构以及编译模型的代码，请参考[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)，*多类分类的深度神经网络*。
- en: 'The following is the code for `model_one` from [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep
    Neural Networks for Multi-Class Classification*:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是来自[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)，*多类分类的深度神经网络*的 `model_one`
    代码：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From the preceding code, we can observe the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以观察到以下内容：
- en: We have set a working directory, which will be the desktop where the results
    of training the model will be stored for visualization on TensorBoard.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经设置了一个工作目录，这将是存储训练模型结果并在 TensorBoard 上进行可视化的桌面。
- en: The model is fit using additional feature callbacks, where we use the `callback_tensorboard`
    function to store data in the `ctg/one` folder on the desktop for visualization
    later.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型使用额外的特征回调进行拟合，我们使用 `callback_tensorboard` 函数将数据存储在桌面的 `ctg/one` 文件夹中，以便稍后进行可视化。
- en: Note that the `ctg` directory is automatically created at the time of fitting
    the model.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意，`ctg` 目录在模型拟合时会自动创建。
- en: Finally, the `tensorboard` function is used for visualization using data stored
    in the `ctg/one` folder.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`tensorboard` 函数用于可视化存储在 `ctg/one` 文件夹中的数据。
- en: 'The following screenshot is of TensorBoard:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是 TensorBoard 的内容：
- en: '![](img/168b0adc-e8e8-4b73-8638-39038396e058.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/168b0adc-e8e8-4b73-8638-39038396e058.png)'
- en: The preceding screenshot shows the loss and accuracy plots for the training
    and validation data for 200 epochs. This was used for training the model. This
    visualization on TensorBoard is interactive in nature and provides the user with
    additional options so that they can explore and understand the model performance's
    during the training process.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图显示了训练和验证数据在200个周期中的损失和准确率图。这用于训练模型。TensorBoard上的这个可视化是交互式的，为用户提供了额外的选项，使他们可以在训练过程中探索和理解模型的表现。
- en: As we have seen in all the chapters in this book that have illustrated the use
    of various deep learning methods, improving the performance of a classification
    or prediction model involves extensive experimentation. To help with such experimentation,
    one of the key benefits of using a TensorBoard is that it allows model performance
    to be compared very easily using interactive visualization.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本书的所有章节中所看到的，所有介绍了各种深度学习方法的章节，都表明提高分类或预测模型的性能需要广泛的实验。为了帮助这种实验，一个使用TensorBoard的关键好处是，它允许通过交互式可视化非常轻松地比较模型的性能。
- en: 'We ran three more models from [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml),
    *Deep Neural Networks for Multi-Class Classification*, and stored model training
    data within subfolders `two`, `three`, and `four` of the `ctg` folder. Run the
    following code for TensorBoard visualization:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)“*多类分类的深度神经网络*”中运行了三个模型，并将模型训练数据存储在`ctg`文件夹的`two`、`three`和`four`子文件夹中。运行以下代码以进行TensorBoard可视化：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code creates TensorBoard visualizations for all four models.
    A screenshot of the resulting TensorBoard page is as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码为所有四个模型创建了TensorBoard可视化。以下是生成的TensorBoard页面的截图：
- en: '![](img/a6774e36-15d5-47be-acb2-9b3164f5ecee.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6774e36-15d5-47be-acb2-9b3164f5ecee.png)'
- en: 'The preceding visualization shows the loss and accuracy values for the training
    and validation data for all four models. The following are some observations that
    we can make about this plot:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上述可视化展示了所有四个模型的训练和验证数据的损失值和准确率。以下是我们可以从该图表中得出的几点观察：
- en: The results for the four models that were run are presented in different colors
    to allow us to quickly identify them and make comparisons.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行的四个模型的结果以不同的颜色呈现，便于我们快速识别并进行比较。
- en: The loss and accuracy values based on the validation data show higher variability
    in the results compared to what can be observed by the training data.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于验证数据的损失和准确率值比训练数据所显示的结果变化更大。
- en: An option to download any plot or related data is also provided.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还提供了下载任何图表或相关数据的选项。
- en: The ability to visualize different models with different parameter values can
    be useful when we're making choices about the type of architecture to use for
    the deep network, the number of epochs, the batch size, and other model-related
    attributes that are of interest. It can also provide us with directions for further
    experimentation if needed and help us compare current and past results.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化具有不同参数值的不同模型，在我们选择深度网络的架构类型、训练轮次、批次大小以及其他感兴趣的模型相关属性时非常有用。它还可以在需要时为我们提供进一步实验的方向，并帮助我们比较当前与过去的结果。
- en: Visualizing deep network models with LIME
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LIME进行深度网络模型可视化
- en: In the application examples that we've provided so far in this book, after we
    developed a classification or prediction deep network model, we carried out visualizations
    to view the overall performance of the models. These assessments are done using
    training and test data. The main idea behind such an assessment is to obtain an
    overall or global understanding of the model's performance. However, there are
    situations where we want to obtain a deeper understanding and also interpretations
    for a specific prediction. For example, we may be interested in understanding
    the main features or variables that have influenced a specific prediction in the
    test data. Such "local" interpretations are the focus of a package called **Local
    Interpretable Model-Agnostic Explanations**, or **LIME**. LIME can help provide
    deeper insights into each prediction.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们目前为止在本书中提供的应用示例中，开发分类或预测深度网络模型后，我们进行可视化以查看模型的整体表现。这些评估是使用训练数据和测试数据进行的。这种评估的主要目的是获得对模型表现的整体或全局理解。然而，有时我们希望获得更深入的理解，甚至是针对特定预测的解释。例如，我们可能会对理解哪些主要特征或变量影响了测试数据中的特定预测感兴趣。这样的“局部”解释是**局部可解释模型无关解释**（**LIME**）包的重点。LIME可以帮助我们深入了解每个预测。
- en: 'The code for carrying out visualization using LIME for the model we developed
    in Keras is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在Keras中进行LIME可视化的代码如下：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As shown in the preceding code, we use two functions to be able to use LIME
    with the Keras model. In the first function, we indicate that we will be working
    with a classification model. The second function obtains prediction probabilities.
    In this section, we will use `model_one` from [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep
    Neural Networks for Multi-Class Classification*. Then, we'll use the `lime` function
    with the training data, the model (that is, `model_one`), and specify the binning
    of continuous variables as `FALSE`. The resulting explainer is used with the `explain`
    function, where we will specify the number of labels to use as one and specify
    the number of most important features to use for each case as four. We specify
    the kernel width as 0.5\. We can also see that the first three patients in the
    test data have the class labeled as 0, indicating that they belong to the normal
    patient category. Similarly, the 4th and 5th patients in the test data have been
    labeled as 2, indicating that they belong to the pathological patient category.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，我们使用两个函数以便能在Keras模型中使用LIME。在第一个函数中，我们指明将处理的是分类模型。第二个函数用于获取预测概率。在这一部分，我们将使用[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)中的`model_one`，*深度神经网络与多分类问题*。然后，我们将使用`lime`函数与训练数据、模型（即`model_one`），并指定连续变量的分箱为`FALSE`。生成的解释器将与`explain`函数一起使用，在这里我们将指定使用一个标签，并指定每个病例使用四个最重要的特征。我们将核宽度指定为0.5。我们还可以看到，测试数据中的前三位患者被标记为0类，表示他们属于正常患者类别。同样，测试数据中的第4和第5位患者被标记为2类，表示他们属于病理患者类别。
- en: 'We obtained the following plot using `plot_features(explanation)`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过`plot_features(explanation)`获得了以下图表：
- en: '![](img/bbe08ddc-d37e-47b8-9e18-5da306e3e34c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbe08ddc-d37e-47b8-9e18-5da306e3e34c.png)'
- en: 'The preceding plot provides individual plots for the first five patients in
    the test data. Here are some of the observations that can be made from this plot:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图表提供了测试数据中前五位患者的个别图表。以下是从这个图表中可以做出的一些观察：
- en: All five patients have been correctly classified.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有五位患者都已被正确分类。
- en: The first three patients have been classified as belonging to a class labeled
    as 0, representing a normal patient.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前三位患者被归类为0类，代表正常患者。
- en: The remaining two patients are classified as belonging to a class labeled as
    2, representing a pathological patient.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剩余的两位患者被归类为2类，代表病理患者。
- en: The prediction probability for the first three cases is 0.97 or above and the
    prediction probability for the 4th and 5th patients is 0.72 and above.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前三例的预测概率为0.97或更高，而第4和第5位患者的预测概率为0.72或更高。
- en: This plot depicts the four most important features that have contributed to
    the specific classification of each patient.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该图表显示了对每位患者具体分类起到关键作用的四个最重要特征。
- en: Features with blue bars support the model's conclusion, whereas features with
    red bars contradict the model's conclusion for each patient.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有蓝色条形的特征支持模型的结论，而具有红色条形的特征则与模型的结论相矛盾。
- en: Higher values for the X8, X10, and X20 variables seem to have a higher influence
    on a patient being classified as pathological.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X8、X10和X20变量的较高值似乎对患者被分类为病理性具有更大的影响。
- en: Higher values for the X12 variable seems to influence a patient being classified
    as normal.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X12变量的较高值似乎影响患者被分类为正常。
- en: 'The following heatmap can be obtained using `plot_explanations(explanation)`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下热图可以通过`plot_explanations(explanation)`获得：
- en: '![](img/72a2ebcc-8dd6-4cb3-addb-f361fa0fcd95.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/72a2ebcc-8dd6-4cb3-addb-f361fa0fcd95.png)'
- en: 'We can make the following observations from the preceding heatmap:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从之前的热图中做出以下观察：
- en: The heatmap makes comparing the different variables for each patient easier
    and thus helps with interpretation.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 热图使得比较每位患者的不同变量变得更容易，从而有助于理解。
- en: It summarizes the results of the case, feature, and label combination and doesn't
    provide as much detail as the previous plot.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它总结了病例、特征和标签组合的结果，并不像前面的图那样提供详细信息。
- en: For class-X1, or patients labeled as normal (1, 2, and 3), all four features
    (X8, X10, X12, and X20) have very similar weights.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于X1类，或标记为正常的患者（1、2和3），所有四个特征（X8、X10、X12和X20）具有非常相似的权重。
- en: For class-X3, or patients labeled as pathological (4 and 5), once again, all
    four features (X8, X10, X13, and X20) have an approximately similar weight.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于X3类，或标记为病理的患者（第4和第5位），所有四个特征（X8、X10、X13和X20）具有大致相似的权重。
- en: Visualizing model training with tfruns
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`tfruns`可视化模型训练
- en: 'When we run a deep network model using Keras, we can make use of `tfruns` to
    visualize a loss and accuracy plot, as well as other model-related summaries.
    Although we can also obtain the plot and related summaries when required, the
    main advantage of using `tfruns` is that we can obtain them all in one place.
    We can make use of the following code to achieve this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用Keras运行深度网络模型时，可以使用`tfruns`来可视化损失和准确度图表，以及其他与模型相关的总结。尽管我们也可以在需要时获得图表和相关总结，但使用`tfruns`的主要优势在于我们可以将它们都集中在一个地方。我们可以使用以下代码来实现这一点：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the preceding code, the `R` file that''s being referenced contains the code
    to run `model_one` from [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep
    Neural Networks for Multi-Class Classification*. The `mlp_ctg.R` file may be stored
    on the computer when we run the code. As soon as we have run the code, the following
    interactive screen is automatically presented:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，引用的`R`文件包含了从[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)运行`model_one`的代码，*深度神经网络与多类分类*。当我们运行代码时，`mlp_ctg.R`文件可能会存储在计算机中。代码运行后，以下交互式屏幕会自动显示：
- en: '![](img/b1ad8926-326d-482f-bc21-a0938e178876.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1ad8926-326d-482f-bc21-a0938e178876.png)'
- en: 'The page shown in the preceding screenshot provides the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述屏幕截图中显示的页面提供了以下内容：
- en: An interactive plot of the loss and accuracy values for the training and validation
    data
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和验证数据的损失值和准确度值的交互式图表
- en: A model summary based on the model's architecture
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型架构的模型总结
- en: Information regarding the run, including the time it took to complete all epochs
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于运行的信息，包括完成所有纪元所需的时间
- en: A numeric summary in the form of accuracy and loss, based on the training and
    validation data
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于训练和验证数据的准确度和损失值的数字总结
- en: The samples that were used, the number of epochs, and the batch size that was
    specified
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用的样本、指定的纪元数以及批处理大小
- en: Early stopping of network training
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提前停止网络训练
- en: When training a network, we specify the number of epochs we need in advance,
    without knowing how many epochs will actually be needed. If we specify the number
    of epochs to be too few compared to what is actually required, we may have to
    train the network again by specifying more epochs. On the other hand, if we specify
    too many more epochs than what are actually needed, then this may lead to an overfitting
    situation and we may have to retrain the network by reducing the number of epochs.
    This trial and error approach can be very time-consuming for applications where
    each epoch takes a long time to complete. In such situations, we can make use
    of callbacks that can help stop the network training at a suitable time.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练网络时，我们事先指定所需的纪元数，而不知道实际需要多少纪元。如果我们指定的纪元数少于实际所需的纪元数，可能需要通过指定更多的纪元来重新训练网络。另一方面，如果我们指定的纪元数远超过实际需要的数目，则可能会导致过拟合情况，我们可能需要通过减少纪元数来重新训练网络。这种试错法对于每个纪元需要较长时间才能完成的应用来说可能非常耗时。在这种情况下，我们可以使用回调函数，帮助在合适的时机停止网络训练。
- en: 'To illustrate this problem, let''s develop a classification model with the
    CTG data from [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep Neural
    Networks for Multi-Class Classification*, using the following code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个问题，让我们使用以下代码，基于[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)中的CTG数据，*深度神经网络与多类分类*，开发一个分类模型：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the preceding code, we have specified the number of epochs as 50\. Once
    the training process is completed, we can plot the loss and accuracy values for
    the training and validation data, as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们已将纪元数指定为50。训练过程完成后，我们可以绘制训练和验证数据的损失值和准确度值，如下所示：
- en: '![](img/0c6c3241-00be-4b66-bf2c-429bd7d761f7.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c6c3241-00be-4b66-bf2c-429bd7d761f7.png)'
- en: 'From the preceding plot, we can observe the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以观察到以下内容：
- en: We can observe that the loss values for the validation data decrease initially
    for the first few epochs and then start to increase.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以观察到，验证数据的损失值最初在前几个纪元中下降，然后开始增加。
- en: The plot also shows that, after the first few epochs, the loss values for the
    training and validation data show divergence and tend to go in the opposite direction.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表还显示，在前几个纪元后，训练和验证数据的损失值开始出现分歧，并趋向于相反的方向。
- en: If we would like to stop the training process much earlier instead of waiting
    for all 50 epochs to be completed, then we can make use of the callback feature
    that's available in Keras.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们希望提前停止训练过程，而不是等待 50 个训练周期完成，我们可以使用 Keras 提供的回调功能。
- en: 'The following code includes the callback feature within the `fit` function
    at the time of training the network:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码在训练网络时包含了回调特性，位于 `fit` 函数中：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the preceding code, early stopping is included for callbacks:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，回调函数已包括在内，用于实现早期停止：
- en: The metric that we used for monitoring was validation loss values. Another metric
    that can be tried in this situation is validation accuracy since we are developing
    a classification model.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们用于监控的度量标准是验证损失值。另一种可以尝试的度量标准是验证准确率，因为我们正在开发一个分类模型。
- en: We have specified patience to be 10, which means that when there are no improvements
    for 10 epochs, the training process will be stopped automatically.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已将耐心值设定为 10，这意味着在 10 个训练周期没有改进时，训练过程将自动停止。
- en: 'The plot for the loss and accuracy are also useful in helping us decide on
    the appropriate values for patience. The following plot is for the loss and accuracy:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 损失值和准确率的图表同样有助于我们决定合适的耐心值。以下是损失值和准确率的图表：
- en: '![](img/2bff25de-803a-486c-b48f-da342857f91d.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bff25de-803a-486c-b48f-da342857f91d.png)'
- en: As we can see, this time, the training process didn't run for all 50 epochs
    and stopped as soon as there were no improvements in the loss values for 10 epochs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这次训练过程并没有运行完所有 50 个训练周期，而是在损失值连续 10 个周期没有改进时停止了。
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Developing classification and prediction models using deep learning networks
    involves extensive experimentation to arrive at models with high-quality performance.
    To help with this process, there are various methods that are very useful for
    visualizing and controlling network training. In this chapter, we went over four
    such useful methods. We saw that TensorBoard provides a tool that we can use to
    assess and compare model performance after training the network with different
    architectures and other changes in the model. The advantage of using TensorBoard
    lies in the fact that it brings all the necessary information together in one
    place in a user-friendly way. There are also situations where we want to understand
    how the main features or variables on a specific prediction are influenced when
    using a classification or prediction model. In such situations, we can visualize
    the impact that the main features will have using LIME.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习网络开发分类和预测模型涉及大量实验，以获得高质量的性能模型。为了帮助这个过程，有多种方法非常有助于可视化和控制网络训练。在本章中，我们介绍了四种非常有用的方法。我们看到，TensorBoard
    提供了一个工具，可以在训练网络时通过不同的架构和其他模型变化来评估和比较模型的性能。使用 TensorBoard 的优势在于它能够将所有必要的信息以用户友好的方式集中展示在一个地方。有时我们还希望了解在使用分类或预测模型时，特定预测中主要特征或变量是如何受到影响的。在这种情况下，我们可以使用
    LIME 来可视化主要特征的影响。
- en: Another useful tip that we illustrated in this chapter is visualization with
    the help of tfruns. When developing a deep network model, we come across various
    plots and summaries related to a specific model. Using tfruns, we can visualize
    all the information in one place with the help of an interactive screen. Another
    tip or trick that will be very useful in the journey ahead is the use of callbacks
    to automatically stop the training process when a suitable classification or prediction
    model has been developed. All the methods that were discussed in this chapter
    can be very useful for the journey ahead, especially when you're working on complex
    and challenging problems.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们介绍的另一个有用技巧是通过 tfruns 实现可视化。在开发深度网络模型时，我们会遇到与特定模型相关的各种图表和摘要。使用 tfruns，我们可以借助互动界面将所有信息可视化地展示在一个地方。另一个在接下来的旅程中非常有用的技巧是使用回调函数，当开发出合适的分类或预测模型时，自动停止训练过程。本章中讨论的所有方法对于接下来的工作都非常有帮助，特别是在你处理复杂且具有挑战性的问题时。
