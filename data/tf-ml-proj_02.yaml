- en: Using Machine Learning to Detect Exoplanets in Outer Space
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习检测外星行星
- en: In this chapter, we shall learn how to detect exoplanets in outer space using
    ensemble methods that are based on decision trees.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用基于决策树的集成方法来检测外星行星。
- en: Decision trees are a family of non-parametric supervised learning methods. In
    a decision tree algorithm, the data is divided into two partitions by using a
    simple rule. The rule is applied again and again to further partition the data,
    thus forming a tree of decisions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一类非参数的监督学习方法。在决策树算法中，数据通过使用一个简单规则被分为两个部分。这个规则被一遍遍应用，继续将数据划分，从而形成一棵决策树。
- en: Ensemble methods combine the learning from multiple learning algorithms to improve
    predictions and reduce errors. These ensembles are differentiated on the basis
    of what kind of learners they use and how they structure those learns in the ensemble.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法将多个学习算法的学习成果结合起来，以提高预测准确性并减少误差。这些集成方法根据它们使用的学习器种类以及如何在集成中结构化这些学习器而有所不同。
- en: The two most popular ensemble methods based on decision trees are known as gradient
    boosted trees and random forests.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 基于决策树的两种最流行的集成方法分别是梯度提升树和随机森林。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: What is a decision tree?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是决策树？
- en: Why we need ensembles?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们需要集成方法？
- en: Decision tree-based ensemble methods
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于决策树的集成方法
- en: Random forests
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Gradient boosting
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升
- en: Decision tree-based ensembles in TensorFlow
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于决策树的集成方法在TensorFlow中的应用
- en: Building a TensorFlow boosted tree model for exoplanet detection
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个用于外星行星检测的TensorFlow提升树模型
- en: The code from this chapter is available in Jupyter Notebook as `ch-02_Detecting_Explonaets_in_Outer_Space.ipynb`
    in the code bundle.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可在Jupyter Notebook中找到，文件名为 `ch-02_Detecting_Exoplanets_in_Outer_Space.ipynb`，包含在代码包中。
- en: What is a decision tree?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是决策树？
- en: Decision trees are a family of non-parametric supervised learning methods. In
    the decision tree algorithm, we start with the complete dataset and split it into
    two partitions based on a simple rule. The splitting continues until a specified
    criterion is met. The nodes at which the split is made are called interior nodes
    and the final endpoints are called terminal or leaf nodes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一类非参数的监督学习方法。在决策树算法中，我们从完整的数据集开始，并根据一个简单规则将其分为两部分。这个划分会持续进行，直到满足指定的标准为止。做出划分的节点称为内部节点，最终的端点称为终端节点或叶节点。
- en: 'As an example, let us look at the following tree:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我们来看以下这棵树：
- en: '![](img/3bba725c-c1a9-4574-bec6-5b2b904469b8.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3bba725c-c1a9-4574-bec6-5b2b904469b8.png)'
- en: 'Here, we are assuming that the exoplanet data has only two properties: **flux.1**
    and **flux.2**. First, we make a decision if **flux.1 > 400** and then divide
    the data into two partitions. Then we divide the data again based on **flux.2**
    feature, and that division decides whether the planet is an exoplanet or not.
    How did we decide that condition **flux.1 > 400**? We did not. This was just to demonstrate
    a decision tree. During the training phase, that''s what the model learns – the
    parameters of conditions that divide the data into partitions.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设外星行星数据只有两个特征：**flux.1** 和 **flux.2**。首先，我们根据条件 **flux.1 > 400** 做出决策，然后将数据分为两个部分。接着，我们基于
    **flux.2** 特征再次划分数据，这个划分决定了该行星是否为外星行星。我们是如何决定 **flux.1 > 400** 这个条件的呢？我们并没有。这只是用来演示决策树。在训练阶段，模型学习到的就是这些划分数据的条件参数。
- en: For classification problems, the decision tree has leaf nodes that shows the
    result as the discrete classification of the data and for regression problems,
    the leaf nodes show the results as a predicted number. Decision trees, thus, are
    also popularly known as **Classification and Regression Trees** (**CART**).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类问题，决策树的叶节点展示结果作为数据的离散分类；对于回归问题，叶节点展示结果作为预测的数值。因此，决策树也被广泛称为**分类与回归树**（**CART**）。
- en: Why do we need ensembles?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们需要集成方法？
- en: Decision trees are prone to overfitting training data and suffer from high variance,
    thus, providing poor predictions from new unseen data. However, using an ensemble
    of decision trees helps alleviate the shortcoming of using a single decision tree
    model. In an ensemble, many weak learners come together to create a strong learner.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树容易对训练数据过拟合，并且受到高方差的影响，因此，无法对新的未见数据做出良好的预测。然而，使用决策树集成可以缓解单一决策树模型的不足。在集成中，多个弱学习器联合起来形成一个强大的学习器。
- en: 'Among the many ways that we can combine decision trees to make ensembles, the
    two methods that have been popular due to their performance for predictive modeling
    are:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以将决策树组合成集成的多种方式中，由于在预测建模中的表现，以下两种方法是最受欢迎的：
- en: Gradient boosting (also known as gradient tree boosting)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升（也称为梯度树提升）
- en: Random decision trees (also known as random forests)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机决策树（也称为随机森林）
- en: Decision tree-based ensemble methods
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于决策树的集成方法
- en: 'In this section let us explore briefly two kinds of ensemble methods for decision
    trees: random forests and gradient boosting.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们简要探讨两种决策树集成方法：随机森林和梯度提升。
- en: Random forests
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林
- en: Random forests is a technique where you construct multiple trees, and then use
    those trees to learn the classification and regression models, but the results
    are aggregated from the trees to produce a final result.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种技术，其中你构建多棵树，然后使用这些树来学习分类和回归模型，但结果是通过聚合这些树的输出得出的，最终产生一个结果。
- en: '![](img/1ba7f1c9-51bf-4f83-b967-7041953cbb9c.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ba7f1c9-51bf-4f83-b967-7041953cbb9c.png)'
- en: Random forests are an ensemble of random, uncorrelated, and fully-grown decision
    trees. The decision trees used in the random forest model are fully grown, thus,
    having low bias and high variance. The trees are uncorrelated in nature, which
    results in a maximum decrease in the variance. By uncorrelated, we imply that
    each decision tree in the random forest is given a randomly selected subset of
    features and a randomly selected subset of the dataset for the selected features.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是由一组随机、无关且完全生长的决策树组成的集成模型。随机森林模型中使用的决策树是完全生长的，因此具有低偏差和高方差。这些树本质上是无关的，从而导致方差的最大减少。这里所说的无关，意味着随机森林中的每棵决策树都被分配到一个随机选择的特征子集，并且从该特征子集中随机选择一个数据子集。
- en: The original paper describing random forests is available at the following link: [https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 描述随机森林的原始论文可以通过以下链接获取：[https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)。
- en: The random forest technique does not reduce bias and as a result, has a slightly
    higher bias as compared to the individual trees in the ensemble.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林技术并不会减少偏差，因此与集成中的单棵决策树相比，具有稍高的偏差。
- en: Random forests were invented by Leo Breiman and have been trademarked by Leo
    Breiman and Adele Cutler. More information is available at the following link: [https://www.stat.berkeley.edu/~breiman/RandomForests](https://www.stat.berkeley.edu/~breiman/RandomForests).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是由Leo Breiman发明的，并且已由Leo Breiman和Adele Cutler注册商标。更多信息请访问以下链接：[https://www.stat.berkeley.edu/~breiman/RandomForests](https://www.stat.berkeley.edu/~breiman/RandomForests)。
- en: Intuitively, in the random forest model, a large number of decision trees are
    trained on different samples of data, that either fit or overfit. By averaging
    the individual decision trees, overfitting cancels out.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，在随机森林模型中，大量的决策树在不同的数据样本上进行训练，这些样本可能会拟合或过拟合。通过对个别决策树的结果取平均，过拟合会被消除。
- en: Random forests seem similar to bagging, aka bootstrap aggregating, but they
    are different. In bagging, a random sample with replacement is selected to train
    every tree in the ensemble. The tree is trained on all the features. In random
    forests, the features are also sampled randomly, and at each candidate that is
    split, a subset of features is used to train the model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林看起来与装袋（Bagging）类似，即自助聚合，但它们是不同的。在装袋中，每棵树的训练数据都是通过有放回的随机抽样来选择的，且树是基于所有特征进行训练的。在随机森林中，特征也是随机采样的，并且在每次候选分裂时，使用特征的子集来训练模型。
- en: For predicting values in case of regression problems, the random forest model
    averages the predictions from individual decision trees. For predicting classes
    in case of a classification problem, the random forest model takes a majority
    vote from the results of individual decision trees.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归问题中，随机森林模型通过对个别决策树的预测结果取平均来进行值的预测。在分类问题中，随机森林模型通过对个别决策树的结果进行多数投票来进行类的预测。
- en: An interesting explanation of random forests can be found at the following link: [https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/](https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林的有趣解释可以通过以下链接查看：[https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/](https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/)
- en: Gradient boosting
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升
- en: Gradient boosted trees are an ensemble of shallow trees (or weak learners).
    The shallow decision trees could be as small as a tree with just two leaves (also
    known as decision stump). The boosting methods help in reducing bias mainly but
    also help reduce variance slightly.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升树是浅层决策树（或弱学习器）的集成。浅层决策树可以小到只有两片叶子的树（也叫做决策桩）。提升方法主要帮助减少偏差，同时也能稍微减少方差。
- en: 'Original papers by Breiman and Friedman who developed the idea of gradient
    boosting are available at following links:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Breiman和Friedman的原始论文，提出了梯度提升的理念，可以通过以下链接查看：
- en: '*Prediction Games and Arcing Algorithms* by Breiman, L at [https://www.stat.berkeley.edu/~breiman/games.pdf](https://www.stat.berkeley.edu/~breiman/games.pdf)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Prediction Games and Arcing Algorithms* 由Breiman, L撰写，链接：[https://www.stat.berkeley.edu/~breiman/games.pdf](https://www.stat.berkeley.edu/~breiman/games.pdf)'
- en: '*Arcing The Edge *by Breiman, L at [http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf](http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Arcing The Edge* 由Breiman, L撰写，链接：[http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf](http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf)'
- en: '*Greedy Function Approximation: A Gradient Boosting Machine* by Friedman, J. H.
    at [http://statweb.stanford.edu/~jhf/ftp/trebst.pdf](http://statweb.stanford.edu/~jhf/ftp/trebst.pdf)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Greedy Function Approximation: A Gradient Boosting Machine* 由Friedman, J.
    H.撰写，链接：[http://statweb.stanford.edu/~jhf/ftp/trebst.pdf](http://statweb.stanford.edu/~jhf/ftp/trebst.pdf)'
- en: '*Stochastic Gradient Boosting* by Friedman, J. H. at [https://statweb.stanford.edu/~jhf/ftp/stobst.pdf](https://statweb.stanford.edu/~jhf/ftp/stobst.pdf)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Stochastic Gradient Boosting* 由Friedman, J. H.撰写，链接：[https://statweb.stanford.edu/~jhf/ftp/stobst.pdf](https://statweb.stanford.edu/~jhf/ftp/stobst.pdf)'
- en: Intuitively, in the gradient boosting model, the decision trees in the ensemble
    are trained in several iterations as shown in the following image. A new decision
    tree is added at each iteration. Every additional decision tree is trained to
    improve the trained ensemble model in previous iterations. This is different from
    the random forest model where each decision tree is trained independently from
    the other decision trees in the ensemble.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，在梯度提升模型中，集成中的决策树经过多次迭代训练，如下图所示。每次迭代都会增加一棵新的决策树。每一棵额外的决策树都是为了改进之前迭代中训练的集成模型。这与随机森林模型不同，后者中的每棵决策树都是独立训练的，不受其他决策树的影响。
- en: '![](img/1a5d0ce4-b378-4921-8df5-c88b5ae2297b.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a5d0ce4-b378-4921-8df5-c88b5ae2297b.png)'
- en: The gradient boosting model has lesser number of trees as compared to the random
    forests model but ends up with a very large number of hyperparameters that need
    to be tuned to get a decent gradient boosting model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与随机森林模型相比，梯度提升模型的树木数量较少，但最终会有大量需要调优的超参数，以获得一个合格的梯度提升模型。
- en: An interesting explanation of gradient boosting can be found at the following
    link: [http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 关于梯度提升的一个有趣解释，可以通过以下链接找到：[http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)。
- en: Decision tree-based ensembles in TensorFlow
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于决策树的集成在TensorFlow中的实现
- en: In this chapter, we shall use the gradient boosted trees and random forest implementation
    as pre-made estimators in TensorFlow from the Google TensorFlow team. Let us learn
    the details of their implementation in the upcoming sections.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用由Google TensorFlow团队提供的预先构建的梯度提升树和随机森林实现作为估算器。接下来的章节中我们将学习它们的实现细节。
- en: TensorForest Estimator
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorForest估算器
- en: TensorForest is a highly scalable implementation of random forests built by
    combining a variety of online HoeffdingTree algorithms with the extremely randomized
    approach.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: TensorForest是一个高度可扩展的随机森林实现，它通过结合各种在线HoeffdingTree算法与极度随机化方法构建而成。
- en: 'Google published the details of the TensorForest implementation in the following
    paper: *TensorForest: Scalable Random Forests on TensorFlow* by Thomas Colthurst,
    D. Sculley, Gibert Hendry, Zack Nado, presented at Machine Learning Systems Workshop
    at the Conference on **Neural Information Processing Systems** (**NIPS**) 2016\.
    The paper is available at the following link: [https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Google 在以下论文中发布了 TensorForest 实现的详细信息：*TensorForest：在 TensorFlow 上可扩展的随机森林*，由
    Thomas Colthurst、D. Sculley、Gibert Hendry、Zack Nado 撰写，并在 2016 年神经信息处理系统会议（**NIPS**）的机器学习系统研讨会上发布。该论文可以通过以下链接访问：[https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE)。
- en: 'TensorForest estimators are used to implementing the following algorithm:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: TensorForest 估算器用于实现以下算法：
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: More details of this algorithm implementation can be found in the TensorForest
    paper.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有关该算法实现的更多细节，请参考《TensorForest》论文。
- en: TensorFlow boosted trees estimator
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 增强树估算器
- en: '**TensorFlow Boosted Trees** (**TFBT**) is an improved scalable ensemble model
    built on top of generic gradient boosting trees.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow 增强树**（**TFBT**）是建立在通用梯度提升树之上的一种改进的可扩展集成模型。'
- en: Google published the details of the TensorFlow boosted trees implementation
    in the following paper: *A scalable TensorFlow based framework for gradient boosting* by
    Natalia Ponomareva, Soroush Radpour, Gilbert Hendry, Salem Haykal, Thomas Colthurst,
    Petr Mitrichev, Alexander Grushetsky, presented at the European Conference on
    Machine Learning and Principles and Practice of Knowledge Discovery in Databases
    (ECML PKDD) 2017\. The paper is available at the following link: [http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf](http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf)[.](http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Google 在以下论文中发布了 TensorFlow 增强树实现的详细信息：*一种可扩展的基于 TensorFlow 的梯度提升框架*，由 Natalia
    Ponomareva、Soroush Radpour、Gilbert Hendry、Salem Haykal、Thomas Colthurst、Petr Mitrichev、Alexander
    Grushetsky 撰写，并在 2017 年欧洲机器学习与数据库知识发现原理与实践会议（ECML PKDD）上发布。该论文可以通过以下链接访问：[http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf](http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf)。
- en: 'The gradient boosting algorithm is implemented by various libraries such as
    `sklearn`, `MLLib`, and `XGBoost`. TensorFlow''s implementation is different from
    these implementations as described in the following table extracted from the TFBT
    research paper:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升算法由 `sklearn`、`MLLib` 和 `XGBoost` 等各种库实现。TensorFlow 的实现与这些实现有所不同，具体内容可参考以下从
    TFBT 研究论文中提取的表格：
- en: '![](img/bce85b46-1f54-4c08-a435-80f5f5acee49.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bce85b46-1f54-4c08-a435-80f5f5acee49.png)'
- en: TFBT Research Paper from Google
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Google 的 TFBT 研究论文
- en: The TFBT model can be extended by writing custom loss functions in TensorFlow.
    The differentiation for these custom loss functions is automatically provided
    by TensorFlow.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: TFBT 模型可以通过在 TensorFlow 中编写自定义损失函数进行扩展。TensorFlow 会自动提供这些自定义损失函数的求导。
- en: Detecting exoplanets in outer space
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测外太空中的系外行星
- en: For the project explained in this chapter, we use the *Kepler labeled time series
    data* from Kaggle:[ https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/home](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/home).
    This dataset is derived mainly from the Campaign 3 observations of the mission
    by NASA's Kepler space telescope.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中解释的项目，我们使用来自 Kaggle 的 *Kepler 标记时间序列数据*：[https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/home](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/home)。该数据集主要来源于
    NASA 的 Kepler 太空望远镜对任务 3 期的观测数据。
- en: In the dataset, column 1 values are the labels and columns 2 to 3198 values
    are the flux values over time. The training set has 5087 data points, 37 confirmed
    exoplanets, and 5050 non-exoplanet stars. The test set has 570 data points, 5
    confirmed exoplanets, and 565 non-exoplanet stars.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中，第 1 列的值为标签，第 2 至 3198 列的值为随时间变化的通量值。训练集包含 5087 个数据点，其中 37 个为已确认的系外行星，5050
    个为非系外行星的恒星。测试集包含 570 个数据点，其中 5 个为已确认的系外行星，565 个为非系外行星的恒星。
- en: 'We will carry out the following steps to download, and then preprocess our
    data to create the train and test datasets:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行以下步骤来下载数据，并对数据进行预处理，以创建训练集和测试集：
- en: 'Download the dataset using the Kaggle API. The following code will be used
    for the same:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kaggle API 下载数据集。以下代码将用于实现这一目的：
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The folder contains the following two files:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 文件夹中包含以下两个文件：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Link the folder `datasets` to our home folder so we can access it from the
    `~/datasets/kaggle-kepler` path and then we define the folder path and list the
    contents of the folder through the Notebook to confirm if we have access to the
    data files through the Notebook:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文件夹`datasets`链接到我们的主文件夹，这样我们就可以通过`~/datasets/kaggle-kepler`路径访问它，然后在Notebook中定义文件夹路径并列出文件夹内容，以确认是否可以通过Notebook访问数据文件：
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We get the following output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了如下输出：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The ZIP file is just a leftover of the download process because the Kaggle API
    begins by downloading the ZIP file and then proceeds to unzip the contents in
    the same folder.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ZIP文件只是下载过程中的残留文件，因为Kaggle API首先下载ZIP文件，然后在同一文件夹中解压内容。
- en: 'We will then read the two `.csv` data files in the `pandas` DataFrames named `train` and `test` respectively:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将读取两个`.csv`数据文件，分别存储在名为`train`和`test`的`pandas`数据框中：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The first five lines of the `training` and `test data` look similar to the
    following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`training`和`test data`的前五行大致如下：'
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The training and test datasets have labels in the first column and 3197 features
    in the next columns. Now let us split the training and test data into labels and
    features with the following code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和测试数据集的标签位于第一列，接下来的列中有3197个特征。现在，我们使用以下代码将训练和测试数据拆分为标签和特征：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the preceding code, we subtract `1` from the labels, since the TFBT estimator
    assumes labels starting with numerical zero while the features in the datasets
    are numbers 1 and 2.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们从标签中减去`1`，因为TFBT估算器假设标签从数字零开始，而数据集中的特征是数字1和2。
- en: Now that we have the label and feature vectors for training and test data, let
    us build the boosted tree models.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了训练和测试数据的标签和特征向量，让我们来构建增强树模型。
- en: Building a TFBT model for exoplanet detection
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个用于外星行星探测的TFBT模型
- en: 'In this section, we shall build the gradient boosted trees model for detecting
    exoplanets using the Kepler dataset. Let us follow these steps in the Jupyter
    Notebook to build and train the exoplanet finder model:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建用于检测外星行星的梯度增强树模型，使用Kepler数据集。让我们按照以下步骤在Jupyter Notebook中构建并训练外星行星探测模型：
- en: 'We will save the names of all the features in a vector with the following code:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用以下代码将所有特征的名称保存到一个向量中：
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will then bucketize the feature columns into two buckets around the mean
    since the TFBT estimator only takes bucketed features with the following code:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将特征列根据均值分成两个桶，因为TFBT估算器只接受桶化后的特征，代码如下：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Since we only have numeric bucketized features and no other kinds of features,
    we store them in the `all_features` variable with the following code:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们只有数值型桶化特征，没有其他类型的特征，我们将它们存储在`all_features`变量中，代码如下：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will then define the batch size and create a function that will provide
    inputs from the label and feature vectors created from the training data. For
    creating this function we use a convenience function `tf.estimator.inputs.pandas_input_fn()` provided
    by TensorFlow. We will use the following code:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将定义批次大小，并创建一个函数，用于提供从训练数据中创建的标签和特征向量的输入。为创建这个函数，我们使用TensorFlow提供的便利函数`tf.estimator.inputs.pandas_input_fn()`，代码如下：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Similarly, we will create another data input function that would be used to
    evaluate the model from the test features and label vectors and name it `eval_input_fn` using
    the following code:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，我们将创建另一个数据输入函数，用于从测试特征和标签向量评估模型，并命名为`eval_input_fn`，使用以下代码：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We will define the number of trees to be created as `100` and the number of
    steps to be used for training as `100`. We also define the `BoostedTreeClassifier` as
    the `estimator` using the following code:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将定义要创建的树的数量为`100`，并将用于训练的步骤数定义为`100`。我们还将`BoostedTreeClassifier`定义为`estimator`，使用以下代码：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Since we are doing classification, hence we use the `BoostedTreesClassifier`,
    for regression problems where a value needs to be predicted, TensorFlow also has
    an `estimator` named `BoostedTreesRegressor`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在进行分类，因此使用`BoostedTreesClassifier`，对于需要预测值的回归问题，TensorFlow还有一个名为`BoostedTreesRegressor`的`estimator`。
- en: One of the parameters provided to the `estimator` function is `model_dir` that
    defines where the trained model would be stored. The estimators are built such
    that they look for the model in that folder in further invocations for using them
    for inference and prediction. We name the folder as `tfbtmodel` to save the model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 提供给`estimator`函数的参数之一是`model_dir`，它定义了训练后的模型存储位置。估计器的构建方式使得在后续调用时，它们会在该文件夹中查找模型，以便用于推理和预测。我们将文件夹命名为`tfbtmodel`来保存模型。
- en: We have used the minimum number of models to define the `BoostedTreesClassifier`.
    Please look up the definition of this estimator in the TensorFlow API documentation
    to find various other parameters that can be provided to further customize the
    estimator.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了最少数量的模型来定义`BoostedTreesClassifier`。请查阅TensorFlow API文档中该估计器的定义，了解可以提供的其他参数，以进一步自定义该估计器。
- en: 'The following output in the Jupyter Notebook describes the classifier estimator
    and its various settings:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook中的以下输出描述了分类器估计器及其各种设置：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Post this, we will train the model using the `train_input_fn` function that
    provides the exoplanets input data using 100 steps with the following code:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`train_input_fn`函数训练模型，使用100步的输入数据进行外行星数据的训练，代码如下：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The Jupyter Notebook shows the following output to indicate the training in
    progress:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook显示以下输出，表示训练正在进行：
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Use the `eval_input_fn` that provides batches from the `test` dataset to evaluate
    the model with the following code:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`eval_input_fn`，它提供来自`test`数据集的批次数据，以通过以下代码评估模型：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The Jupyter Notebook shows the following output as the progress of the evaluation:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook显示以下输出，表示评估的进展：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Note that during the evaluation the estimator loads the parameters saved in
    the checkpoint file:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在评估过程中，估计器会加载保存在检查点文件中的参数：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The results of the evaluation are stored in the `results` collection. Let us
    print each item in the `results` collection using the `for` loop in the following
    code:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估结果存储在`results`集合中。我们可以使用以下代码中的`for`循环打印`results`集合中的每一项：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The Notebook shows the following results:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Notebook显示以下结果：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: It is observed that we achieve an accuracy of almost 99% with the first model
    itself. This is because the estimators are prewritten with several optimizations
    and we did not need to set various values of hyperparameters ourselves. For some
    datasets, the default hyperparameter values in the estimators will work out of
    the box, but for other datasets, you will have to play with various inputs to
    the estimators.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到，我们在第一个模型中就达到了近99%的准确率。这是因为估计器已预先写入了多个优化选项，我们无需自己设置超参数的各个值。对于某些数据集，估计器中的默认超参数值可以直接使用，但对于其他数据集，您需要调整估计器的各种输入值。
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned what a decision tree is and two broad classes of
    creating ensembles from the decision trees. The ensembles we took a look at were
    random forests and gradient boosting trees.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们了解了什么是决策树，以及从决策树创建集成方法的两大类。我们关注的集成方法是随机森林和梯度提升树。
- en: We also learned about the Kepler dataset from Kaggle competitions. We used the
    Kepler dataset to build an exoplanet detection model using TensorFlow's prebuilt
    estimator for gradient boosting trees known as the `BoostedTreesClassifier`. The
    `BoostedTreesClassifier` estimator is part of the machine learning toolkit recently
    released by the TensorFlow team. As for now, the TensorFlow team is working on
    releasing prebuilt estimators based on **support vector machine** (**SVM**) and
    extreme random forests as part of the `tf.estimators` API.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解了Kaggle竞赛中的开普勒数据集。我们使用开普勒数据集构建了一个外行星检测模型，使用TensorFlow预构建的梯度提升树估计器`BoostedTreesClassifier`。`BoostedTreesClassifier`估计器是TensorFlow团队最近发布的机器学习工具包的一部分。目前，TensorFlow团队正在开发基于**支持向量机**（**SVM**）和极端随机森林的预构建估计器，并作为`tf.estimators`
    API的一部分发布。
- en: In the next chapter, we shall learn how to use TensorFlow in the browser using
    the `TensorFlow.js` API for sentiment analysis.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用浏览器中的`TensorFlow.js` API进行情感分析。
- en: Questions
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How is gradient boosting different from random forests?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升与随机森林有何不同？
- en: How can you improve the performance of random forests?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何提高随机森林的性能？
- en: How can you improve the performance of gradient boosting trees?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何提高梯度提升树的性能？
- en: How to ensure that gradient boosting trees and random forests do not overfit?
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何确保梯度提升树和随机森林不会过拟合？
- en: Modify the model in this chapter with different parameters such as the number
    of trees, batch size, number of epochs and number of steps and observe their effect
    on training time and different levels of accuracy.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改本章中的模型，使用不同的参数，如树的数量、批处理大小、训练周期数和步数，并观察它们对训练时间和不同准确度水平的影响。
- en: Further reading
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)'
- en: '[https://www.stat.berkeley.edu/~breiman/RandomForests](https://www.stat.berkeley.edu/~breiman/RandomForests)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.stat.berkeley.edu/~breiman/RandomForests](https://www.stat.berkeley.edu/~breiman/RandomForests)'
- en: '[https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)'
- en: '[https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/](https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/](https://machinelearning-blog.com/2018/02/06/the-random-forest-algorithm/)'
- en: '[http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)'
- en: '[https://www.stat.berkeley.edu/~breiman/games.pdf](https://www.stat.berkeley.edu/~breiman/games.pdf)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.stat.berkeley.edu/~breiman/games.pdf](https://www.stat.berkeley.edu/~breiman/games.pdf)'
- en: '[http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf](http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf](http://statistics.berkeley.edu/sites/default/files/tech-reports/486.pdf)'
- en: '[http://statweb.stanford.edu/~jhf/ftp/trebst.pdf](http://statweb.stanford.edu/~jhf/ftp/trebst.pdf)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://statweb.stanford.edu/~jhf/ftp/trebst.pdf](http://statweb.stanford.edu/~jhf/ftp/trebst.pdf)'
- en: '[https://statweb.stanford.edu/~jhf/ftp/stobst.pdf](https://statweb.stanford.edu/~jhf/ftp/stobst.pdf)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://statweb.stanford.edu/~jhf/ftp/stobst.pdf](https://statweb.stanford.edu/~jhf/ftp/stobst.pdf)'
- en: '[https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxtbHN5c25pcHMyMDE2fGd4OjFlNTRiOWU2OGM2YzA4MjE)'
- en: '[http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf](http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf](http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf)'
