- en: '*Chapter 15*: Classifying Documents and Setting up Human in the Loop for Active
    Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第15章*：文档分类及设置人类参与的主动学习'
- en: In the last chapter, we covered how you can use **Amazon Comprehend Custom Entity**
    to extract business entities from your documents, and we showed you how you can
    use humans in the loop with Amazon Augmented AI (A2I) to augment or improve entity
    predictions. Lastly, we showed you how you can retrain the Comprehend custom entity
    model with an augmented dataset to improve accuracy using Amazon A2I.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了如何使用**Amazon Comprehend 自定义实体**从文档中提取业务实体，并展示了如何结合 Amazon 增强型 AI（A2I）使用人工参与来增强或改进实体预测。最后，我们展示了如何通过使用增强数据集对
    Comprehend 自定义实体模型进行重新训练，以利用 Amazon A2I 提高准确性。
- en: In this chapter, we will talk about how you can use **Amazon Comprehend** custom
    classification to classify documents and then how you can set up active learning
    feedback with your custom classification model using Amazon A2I.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何使用**Amazon Comprehend** 自定义分类来分类文档，并介绍如何通过 Amazon A2I 设置主动学习反馈，以优化你的自定义分类模型。
- en: 'We will be covering the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Using comprehend custom classification with human in the loop for active learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用带有人工参与的 Comprehend 自定义分类进行主动学习
- en: Building the document classification workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建文档分类工作流
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need access to an AWS account. Please make sure to
    follow the instructions specified in the *Technical requirements* section in [*Chapter
    2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),*Introducing Amazon Textract*,
    to create your AWS account, and log in to the AWS Management Console before trying
    the steps in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要访问 AWS 账户。请确保按照 *技术要求* 部分中的说明，通过 [*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)，*介绍
    Amazon Textract*，创建你的 AWS 账户，并登录 AWS 管理控制台，然后再执行本章中的步骤。
- en: 'The Python code and sample datasets for setting up Comprehend custom classification
    with a human-in-the-loop solution are in the following link: [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2015](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2015).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 设置带有人工反馈环节的 Comprehend 自定义分类解决方案的 Python 代码和示例数据集请参考以下链接：[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2015](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2015)。
- en: Check out the following video to see the Code in Action at [https://bit.ly/3BiOjKt](https://bit.ly/3BiOjKt).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下视频，观看代码演示：[https://bit.ly/3BiOjKt](https://bit.ly/3BiOjKt)。
- en: Please use the instructions in the following sections along with the code in
    the repository to build the solution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下各节中的说明，并结合代码库中的代码来构建解决方案。
- en: Using Comprehend custom classification with human in the loop for active learning
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用带有人工参与的 Comprehend 自定义分类进行主动学习
- en: Amazon Comprehend provides the capability to classify the data using Amazon
    Comprehend AutoML and bring your own custom training dataset. You can easily accomplish
    a lot with the Amazon Comprehend custom classification feature as it requires
    fewer documents to train Comprehend AutoML models. You are spending less time
    labeling the dataset and then worrying about setting up infrastructure or choosing
    the right algorithm.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend 提供了使用 Amazon Comprehend AutoML 分类数据的能力，并允许你使用自定义训练数据集。利用 Amazon
    Comprehend 自定义分类功能，你可以轻松完成很多任务，因为它要求用于训练 Comprehend AutoML 模型的文档较少。这意味着你花费更少时间在标注数据集上，而不用担心设置基础设施或选择正确的算法。
- en: You can use Amazon Comprehend custom classification for a variety of use cases,
    such as classifying documents based on type, classifying news articles, or classifying
    movies based on type.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Amazon Comprehend 自定义分类处理各种用例，例如根据类型对文档进行分类、对新闻文章进行分类，或根据类型对电影进行分类。
- en: The fictitious company *LiveRight pvt ltd* wants to classify the documents submitted
    by the customers, such as whether the document submitted is an ID or a bank statement,
    even before analyzing the data inside the document. Moreover, if you are using
    a classification model to classify the documents based on the type of submitted
    document, you would also want to improve the accuracy of your predicted outcome
    in real time, based on the confidence score predicted by the Comprehend custom
    classification model. This is where humans in the loop with Amazon Augmented AI
    is going to help.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虚构公司*LiveRight pvt ltd*希望在分析文档内容之前，先对客户提交的文档进行分类，例如判断提交的文档是身份证明还是银行对账单。此外，如果你使用分类模型来根据提交的文档类型对文档进行分类，你也希望基于Amazon
    Comprehend自定义分类模型预测的置信度分数，在实时中提高预测结果的准确性。这时，结合亚马逊增强型人工智能（Amazon Augmented AI）的人机协作将发挥作用。
- en: We covered Amazon A2I in [*Chapter 13*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151),
    *Improving the Accuracy of Document Processing Workflows*. In this chapter, we
    will walk you through some reference architecture on how you can easily set up
    a custom classification model using Amazon Comprehend and have a feedback loop
    set up with Amazon A2I for active learning on your Comprehend custom model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[*第13章*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151)《提高文档处理工作流的准确性》中介绍了Amazon
    A2I。在本章中，我们将带你了解一些参考架构，说明如何使用Amazon Comprehend轻松设置自定义分类模型，并与Amazon A2I建立反馈回路，以便对你的Comprehend自定义模型进行主动学习。
- en: First, we will walk you through the following architecture on how you can train
    a custom classification model and create a real-time endpoint for inferencing
    or classifying documents in near real time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将带你了解如何训练一个自定义分类模型，并创建一个实时端点，用于近实时地推断或分类文档。
- en: '![Figure 15.1 – Comprehend custom classification training workflow'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.1 – Comprehend自定义分类训练工作流'
- en: '](img/B17528_15_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_15_01.jpg)'
- en: Figure 15.1 – Comprehend custom classification training workflow
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.1 – Comprehend自定义分类训练工作流
- en: 'This architecture walks through the following steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该架构包括以下步骤：
- en: Training documents, such as bank statements or pay stubs, are uploaded to Amazon
    S3.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练文档，如银行对账单或工资单，被上传到Amazon S3。
- en: Amazon Textract extracts text from these documents and then some post-processing
    is done to create a labeled training file for Comprehend custom classification
    training.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon Textract从这些文档中提取文本，然后进行一些后处理，创建一个标签化的训练文件，用于Comprehend自定义分类训练。
- en: Using the training file, an Amazon Comprehend job is created to classify documents,
    such as bank statements or pay stubs.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练文件，创建一个Amazon Comprehend作业来分类文档，如银行对账单或工资单。
- en: 'After training is completed, you have two options with Amazon Comprehend: either
    you can do batch inferencing on a batch of documents to classify them or you can
    create real-time endpoints. In the architecture, we are showing how you can set
    up a real-time endpoint to classify a document type.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练完成后，你可以选择使用Amazon Comprehend执行批量推断，将一批文档分类，或者创建实时端点。在这个架构中，我们展示了如何设置实时端点来分类文档类型。
- en: We are going to walk you through the preceding conceptual architecture using
    Jupyter Notebook and a few lines of Python code in the *Setting up to solve the
    use case* section.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*解决用例设置*部分通过Jupyter Notebook和几行Python代码，带你了解前述概念架构的实现。
- en: 'Now, we have a near real-time document classification endpoint. We will show
    you how you can set up humans in the loop with this Amazon Comprehend custom classification
    endpoint and set up a model retraining or active-learning loop to improve your
    model accuracy using the following architecture:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了一个近乎实时的文档分类端点。我们将展示如何使用这个Amazon Comprehend自定义分类端点设置人机协作，并通过以下架构建立模型重训练或主动学习循环，以提高模型的准确性：
- en: '![Figure 15.2 – Real-time classification with model retraining'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.2 – 通过模型重训练实现实时分类'
- en: '](img/B17528_15_02.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_15_02.jpg)'
- en: Figure 15.2 – Real-time classification with model retraining
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.2 – 通过模型重训练实现实时分类
- en: 'In this architecture, we will walk you through the following steps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个架构中，我们将带你完成以下步骤：
- en: '**Client application** sends the document to Amazon Textract.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**客户端应用程序**将文档发送给Amazon Textract。'
- en: '**Amazon Textract** extracts the data or text in real-time API and extracted
    data is passed on to the Amazon Comprehend real-time classifier endpoint.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Amazon Textract**实时提取数据或文本，并将提取的数据传递到Amazon Comprehend实时分类端点。'
- en: The Amazon Comprehend custom classification endpoint classifies this document
    type.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon Comprehend 自定义分类端点将对该文档类型进行分类。
- en: This classification endpoint is configured with Amazon A2I human in the loop.
    If the prediction of classification is **high confidence** based on your business
    threshold, which you can configure, the high-confidence predictions are directly
    sent to client applications.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该分类端点配置了 Amazon A2I 人工环节。如果分类预测的置信度**高**，根据您的业务阈值（您可以配置该阈值），则高置信度预测会直接发送到客户端应用程序。
- en: For low-confidence predictions, such as anything below the 95% confidence, the
    score predicted is low confidence for you. A human loop is created, and these
    predictions are sent for human review. Refer to [*Chapter 3*](B17528_03_Final_SB_ePub.xhtml#_idTextAnchor049),
    *Introducing Amazon Comprehend*, to understand what a confidence score is and
    Comprehend custom features.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于低置信度的预测，例如任何低于 95% 置信度的预测，预测的得分为低置信度。这时会创建一个人工环节，将这些预测发送给人工审核。请参考[*第 3 章*](B17528_03_Final_SB_ePub.xhtml#_idTextAnchor049)，*介绍
    Amazon Comprehend*，了解什么是置信度分数以及 Comprehend 的自定义功能。
- en: The augmented or corrected data from human labelers are saved in an Amazon S3
    bucket as a **JSON** file.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工标注者修正或增加的数据会以**JSON**文件的形式保存在 Amazon S3 存储桶中。
- en: This data is then combined with the original training dataset and the Amazon
    Comprehend custom model is retrained for active learning using human feedback.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，这些数据与原始训练数据集结合，并使用人工反馈对 Amazon Comprehend 自定义模型进行重新训练，以实现主动学习。
- en: We will walk you through *steps 1 to 6* using Jupyter Notebook in the *Setting
    up the use case section*. Feel free to combine the augmented classified labels
    with the original dataset and try retraining for your understanding. You can automate
    this architecture using step functions and Lambda functions. We will share with
    you the blogs that can help you set up this architecture using Lambda functions
    in the *Further reading* section.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将带您完成*第 1 至第 6 步*，使用 Jupyter Notebook 在*设置用例部分*。您可以自由地将增强的分类标签与原始数据集结合，尝试重新训练以加深理解。您还可以使用步骤函数和
    Lambda 函数自动化此架构。我们将在*进一步阅读*部分与您分享帮助您使用 Lambda 函数设置此架构的博客。
- en: In this section, we covered the architecture for both model training and retraining
    or active learning. Now, let's move on to the next section to see these concepts
    with code.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了模型训练和重新训练或主动学习的架构。接下来，让我们进入下一节，通过代码来展示这些概念。
- en: Building the document classification workflow
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建文档分类工作流
- en: In this section, we will get right down to action and start executing the tasks
    to build our solution. But first, there are prerequisites we will have to take
    care of.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将直接开始执行任务来构建我们的解决方案。但首先，我们需要处理一些前提条件。
- en: Setting up to solve the use case
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置以解决用例
- en: If you have not done so in the previous chapters, you will first have to create
    an Amazon SageMaker Jupyter notebook and set up `Chapter 15` folder, and open
    the `chapter15 classify documents with human in the loop.ipynb` notebook.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在前面的章节中还没有完成此操作，您需要先创建一个 Amazon SageMaker Jupyter 笔记本，并设置 `Chapter 15` 文件夹，打开
    `chapter15 classify documents with human in the loop.ipynb` 笔记本。
- en: Now, let's move to the next section to show you how you can set up the libraries
    and upload training data to Amazon S3 using this notebook.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入下一节，向您展示如何设置库并使用此笔记本将训练数据上传到 Amazon S3。
- en: Setting up and uploading sample documents to Amazon S3
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置并上传样本文档到 Amazon S3
- en: 'In this step, we will follow instructions to set up an S3 bucket and upload
    documents:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将按照说明设置一个 S3 存储桶并上传文档：
- en: Go to the notebook and run the cells below `boto 3` for setup.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到笔记本并运行以下 `boto 3` 单元格进行设置。
- en: 'Move on to the next cell and enter a bucket name to create an S3 bucket in
    your account. Make sure you add the current month and date in `MMDD` for `data_bucket`,
    as shown in the following code block, before executing this cell:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续到下一个单元格，输入一个存储桶名称，以在您的帐户中创建一个 S3 存储桶。在执行此单元格之前，请确保在 `data_bucket` 中添加当前月份和日期（格式为
    `MMDD`），如下面的代码块所示：
- en: '[PRE0]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now run the following cell to upload or copy a sample bank statement or pay
    stub image as a training file from your local notebook to the S3 bucket that you
    just created:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在运行以下单元格，将本地笔记本中的样本银行对账单或工资单图像上传或复制为训练文件，上传到您刚刚创建的 S3 存储桶：
- en: '[PRE1]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now run the next two cells in the notebook to list the training images we just
    copied in Amazon S3\. We created a function named `get_s3_bucket_items`. We are
    getting the image objects from S3 and saving them as images for Textract processing
    in future steps. Refer to the notebook to execute these steps.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在运行笔记本中的接下来的两个单元，以列出我们刚刚复制到 Amazon S3 中的训练图像。我们创建了一个名为`get_s3_bucket_items`的函数。我们从
    S3 获取图像对象，并将其保存为 Textract 处理的图像，供后续步骤使用。请参考笔记本执行这些步骤。
- en: 'Run the following step to define a path or local directory structure to store
    data extracted from Amazon Textract:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下步骤，定义一个路径或本地目录结构，以存储从 Amazon Textract 提取的数据：
- en: '[PRE2]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We've covered how to create an S3 bucket and we have loaded training data. Now,
    let's move on to the next section to extract text.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了如何创建 S3 存储桶并加载训练数据。接下来，让我们进入提取文本的下一部分。
- en: Extracting text from sample documents using Amazon Textract
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Amazon Textract 从示例文档中提取文本
- en: 'Go to the notebook and run the calls in **Step 2: Extract text from sample
    documents using Amazon Textract** to define a function using Amazon Textract to
    extract data from the sample images in Amazon S3\. We are using the DetectDocumentText
    sync API to do this extraction; you can also use *AsyncAPI* or *Textract batch
    APIs* to perform data extraction. Refer to [*Chapter 4*](B17528_04_Final_SB_ePub.xhtml#_idTextAnchor063),
    *Automating Document Processing Workflows*, to dive deep into these APIs:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 转到笔记本并运行**步骤 2：使用 Amazon Textract 从示例文档中提取文本**中的代码，定义一个函数，使用 Amazon Textract
    从 Amazon S3 中的示例图像提取数据。我们正在使用 DetectDocumentText 同步 API 进行提取；你也可以使用*异步 API*或*Textract
    批量 API*来执行数据提取。请参考[*第 4 章*](B17528_04_Final_SB_ePub.xhtml#_idTextAnchor063)，*自动化文档处理工作流*，深入了解这些
    API：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This function takes the *image's* path and returns the text and labels for the
    images.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接受*图片*的路径并返回图片中的文本和标签。
- en: 'Let''s call this function by passing the scanned document''s images by running
    the following cell in the notebook:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过运行笔记本中的以下单元，调用这个函数并传入扫描文档的图像：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding function extracts the data and saves it in the local directory
    structure you defined in the **Set up and Upload Sample Documents** step. The
    following is the output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数提取数据并将其保存在你在**设置并上传示例文档**步骤中定义的本地目录结构中。以下是输出结果：
- en: '![Figure 15.3 – Textract output'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.3 – Textract 输出'
- en: '](img/B17528_15_03.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_15_03.jpg)'
- en: Figure 15.3 – Textract output
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.3 – Textract 输出
- en: Now, we have extracted the text and associated labels, for example, *0* for
    a bank statement and *1* for pay stubs. Now, let's move to the next section for
    Comprehend training.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经提取了文本和相关标签，例如*0*代表银行对账单，*1*代表工资单。接下来，让我们进入 Comprehend 训练的下一部分。
- en: Creating an Amazon Comprehend classification training job
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 Amazon Comprehend 分类训练任务
- en: 'We have extracted the data and labels in the previous step from our sample
    of scanned documents in Amazon S3\. Now, let''s understand how to set up a Comprehend
    classification training job using **Step 3: Create Amazon Comprehend Classification
    training job** in the notebook:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一步中，我们已经从 Amazon S3 中的扫描文档样本提取了数据和标签。接下来，让我们了解如何使用**步骤 3：创建 Amazon Comprehend
    分类训练任务**在笔记本中设置 Comprehend 分类训练任务：
- en: 'We will first create a function to map the extracted data and labels into a
    pandas DataFrame so that we can convert that into a CSV training file in the next
    step. Run the following code to define the function, which takes the extracted
    data location and returns labels and text from it:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先创建一个函数，将提取的数据和标签映射到 pandas DataFrame，以便在下一步将其转换为 CSV 训练文件。运行以下代码来定义该函数，它接受提取的数据位置并返回其中的标签和文本：
- en: '[PRE5]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we will call the function we defined in the previous step by running the
    following cell:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将通过运行以下代码调用之前定义的函数：
- en: '[PRE6]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You will get a pandas DataFrame with labels and documents, shown as follows:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得一个包含标签和文档的 pandas DataFrame，内容如下所示：
- en: '![Figure 15.4 – Labeled training DataFrame'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 15.4 – 带标签的训练 DataFrame'
- en: '](img/B17528_15_04.jpg)'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_04.jpg)'
- en: Figure 15.4 – Labeled training DataFrame
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15.4 – 带标签的训练 DataFrame
- en: 'Now, we will save this DataFrame as a CSV and upload it to Amazon S3 using
    S3\. Put the `boto3` API object as the Comprehend training file for Amazon Comprehend
    training:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将把这个 DataFrame 保存为 CSV 文件，并使用 S3 上传到 Amazon S3。将`boto3` API 对象作为 Amazon
    Comprehend 训练文件进行训练：
- en: '[PRE7]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, go to the Amazon Comprehend console link (https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#classification)
    to create a classification job. Click on **Train Classifier**.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，访问 Amazon Comprehend 控制台链接（https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#classification）创建分类作业。点击
    **Train Classifier**。
- en: In `doc-classifier`, and in `1`, and scroll down to select `csv file`.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `doc-classifier` 中，选择 `1`，然后向下滚动选择 `csv 文件`。
- en: Important Note
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'We have the choice to add versions for Amazon Comprehend custom models. To
    learn more about this feature, refer to this link: [https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html](https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html).'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以为 Amazon Comprehend 自定义模型添加版本。要了解更多关于此功能的信息，请参考此链接：[https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html](https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html)。
- en: '![Figure 15.5 – Amazon Comprehend custom classification UI'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 15.5 – Amazon Comprehend 自定义分类 UI'
- en: '](img/B17528_15_05.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_05.jpg)'
- en: Figure 15.5 – Amazon Comprehend custom classification UI
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15.5 – Amazon Comprehend 自定义分类 UI
- en: For the training data location, browse to the `doc-processing-bucket-MMDD` S3
    bucket created in the `s3://doc-processing-bucket-MMDD/comprehend_train_data.csv`.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于训练数据位置，浏览到 `doc-processing-bucket-MMDD` S3 桶，该桶位于 `s3://doc-processing-bucket-MMDD/comprehend_train_data.csv`。
- en: For `Autosplit`, which means Amazon Comprehend will automatically split the
    test data for you. You also have the choice to tune your model by bringing your
    own test dataset here.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 `Autosplit`，这意味着 Amazon Comprehend 会自动为您拆分测试数据。您也可以选择通过提供自己的测试数据集来调整模型。
- en: For output data, enter the `s3://doc-processing-bucket-MMDD` S3 bucket.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于输出数据，请输入 `s3://doc-processing-bucket-MMDD` S3 桶。
- en: For access permissions, select `classifydoc` in **NameSuffix**.![Figure 15.6
    – Amazon Comprehend custom classification IAM setting
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于访问权限，在 **NameSuffix** 中选择 `classifydoc`。![图 15.6 – Amazon Comprehend 自定义分类
    IAM 设置
- en: '](img/B17528_15_06.jpg)'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_06.jpg)'
- en: Figure 15.6 – Amazon Comprehend custom classification IAM setting
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15.6 – Amazon Comprehend 自定义分类 IAM 设置
- en: Scroll down and click on the **Train Classifier** button to start training.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动并点击 **Train Classifier** 按钮开始训练。
- en: Important Note
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: This training will take 30 minutes to complete as we have a large number of
    documents to train with in this chapter. You can use this time to set up a private
    workforce for setting up humans in the loop, which we did in [*Chapter 13*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151),
    *Improving the Accuracy of Document Processing Workflows*.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此训练将花费 30 分钟完成，因为本章中我们有大量文档需要训练。您可以利用这段时间设置一个私人工作队伍，为设置人类参与环节做准备，正如我们在[*第 13
    章*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151)中所做的，*提高文档处理工作流的准确性*。
- en: Once your job is completed, move on to the next step.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的任务完成，继续进行下一步。
- en: Creating Amazon Comprehend real-time endpoints and testing a sample document
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 Amazon Comprehend 实时端点并测试示例文档
- en: 'In this section, we will show you how you can create a real-time endpoint with
    the trained model in the **AWS Management Console**. Comprehend uses the **Inference
    Unit** (**IU**) to analyze how many characters can be analyzed in real time per
    second. IU is a measure of the endpoint''s throughput. You can adjust the IU of
    an endpoint anytime. After creating the endpoint, we will then show you how you
    can call this endpoint to test a sample bank statement using the Jupyter Notebook:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何在**AWS 管理控制台**中使用训练后的模型创建实时端点。Comprehend 使用**推理单元**（**IU**）来分析每秒钟可以实时分析多少个字符。IU
    是端点吞吐量的度量。您可以随时调整端点的 IU。创建端点后，我们将展示如何使用 Jupyter Notebook 调用此端点来测试一个示例银行对账单：
- en: Go to this link, https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#endpoints,
    and click on **Create Endpoint.**
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问此链接，https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#endpoints，并点击
    **创建端点**。
- en: Enter `classify-doc` as the endpoint name, set `doc-classifier`, which we trained
    in the previous step, and set **Inference units** to **1**.![Figure 15.7 – Amazon
    Comprehend Create real-time endpoint UI
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `classify-doc` 作为端点名称，设置我们在上一步中训练的 `doc-classifier`，并将**推理单元**设置为 **1**。![图
    15.7 – Amazon Comprehend 创建实时端点 UI
- en: '](img/B17528_15_07.jpg)'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_07.jpg)'
- en: Figure 15.7 – Amazon Comprehend Create real-time endpoint UI
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15.7 – Amazon Comprehend 创建实时端点 UI
- en: Scroll down and select **I Acknowledge** and click on **Create Endpoint**.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动并选择 **I Acknowledge**，然后点击 **创建端点**。
- en: Delete this endpoint at the cleanup section in the notebook to avoid incurring
    a cost.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在笔记本的清理部分删除此端点，以避免产生费用。
- en: Now, copy the **ARN** of the endpoint, as shown in the next screenshot, and
    move to the Jupyter Notebook link:![Figure 15.8 – Comprehend custom classification
    endpoint ARN
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，复制下一张截图中显示的**ARN**，然后前往Jupyter Notebook链接：![图15.8 – Comprehend自定义分类终端节点ARN
- en: '](img/B17528_15_08.jpg)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_08.jpg)'
- en: Figure 15.8 – Comprehend custom classification endpoint ARN
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图15.8 – Comprehend自定义分类终端节点ARN
- en: 'In the notebook, enter the preceding copied endpoint arn in the notebook cell
    as follows:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本中，按如下方式将之前复制的终端节点ARN输入到笔记本单元格中：
- en: '[PRE8]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we will take a sample test document or any pay stub not used in training
    for real-time classification. Run the following code to see the sample pay statement:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用一个示例测试文档或任何未在训练中使用的薪资单进行实时分类。运行以下代码来查看示例薪资单：
- en: '[PRE9]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You will get the following output:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下输出：
- en: '![Figure 15.9 – Sample pay stub document'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图15.9 – 示例薪资单文档'
- en: '](img/B17528_15_09.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_09.jpg)'
- en: Figure 15.9 – Sample pay stub document
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图15.9 – 示例薪资单文档
- en: Run the next two cells in the notebook under **Extract Text from this sample
    doc using Textract** to extract text from this sample document.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**使用Textract从此示例文档提取文本**部分运行接下来的两个单元格，以提取此示例文档中的文本。
- en: 'Run the following cell, which calls a Comprehend ClassifyDocument API. This
    method takes the extracted text and custom classification endpoint and returns
    a response:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，它调用Comprehend的ClassifyDocument API。此方法将提取的文本和自定义分类终端节点传递给API，并返回一个响应：
- en: '[PRE10]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You will get the following response:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下响应：
- en: '![Figure 15.10 – ClassifyDocument response'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.10 – ClassifyDocument响应'
- en: '](img/B17528_15_10.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_15_10.jpg)'
- en: Figure 15.10 – ClassifyDocument response
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.10 – ClassifyDocument响应
- en: As per the response, the model endpoint has classified the document as a pay
    stub with 99% confidence. We tested this endpoint, so now let's move on to the
    next section to set up a human loop.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 根据响应，模型终端节点已经将文档分类为薪资单，置信度为99%。我们已经测试了这个终端节点，现在让我们进入下一部分，设置人工环路。
- en: Setting up active learning with a Comprehend real-time endpoint using human
    in the loop
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用实时终端节点和人工环路设置主动学习，结合Comprehend
- en: 'In this section, we are going to show you a custom integration with a Comprehend
    classifier endpoint, which you can invoke using the A2I StartHumanLoop API. You
    can pass any type of AI/ML prediction response to this API to trigger a human
    loop. In [*Chapter 13*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151), *Improving
    the Accuracy of Document Processing Workflows*, we showed you a native integration
    with the Textract Analyze document API by passing a human loop workflow ARN to
    the AnalyzeDocument API. Setting up a custom workflow includes the following steps:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向你展示如何与Comprehend分类终端节点进行自定义集成，你可以使用A2I StartHumanLoop API调用此集成。你可以将任何类型的AI/ML预测响应传递给此API来触发人工环路。在[*第13章*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151)中，*提高文档处理工作流的准确性*，我们通过将人工环路工作流ARN传递给AnalyzeDocument
    API，向你展示了与Textract Analyze文档API的原生集成。设置自定义工作流包括以下步骤：
- en: Create a **worker task template**.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个**工作任务模板**。
- en: Create a **human review workflow**.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个**人工审核工作流**。
- en: Create and start an A2I human loop.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建并启动A2I人工环路。
- en: Check the human loop status and start labeling.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查人工环路状态并开始标注。
- en: 'To get started, you need to create a private workforce and copy the private
    ARN in the *Environment setup* step in the Jupyter Notebook:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，你需要创建一个私人工作团队，并在Jupyter Notebook中的*环境设置*步骤中复制私人ARN：
- en: 'To create a private workforce, refer to the *Creating a private work team in
    AWS Console* section in [*Chapter 13*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151),
    *Improving the Accuracy of Document Processing Workflows*:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建一个私人工作团队，请参考[*第13章*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151)中的*在AWS控制台创建私人工作团队*部分，*提高文档处理工作流的准确性*：
- en: '[PRE11]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Run the next cell and move to the `Create worker task` template. This is the
    UI that the workers are going to view while labeling. We will show the prediction
    results in the UI and the original document data. We have used a pre-built classification
    template ([https://github.com/aws-samples/amazon-a2i-sample-task-uis/blob/master/text/document-classification.liquid.html](https://github.com/aws-samples/amazon-a2i-sample-task-uis/blob/master/text/document-classification.liquid.html))
    for this use case. Run the notebook cell to define the HTML template.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元并转到`创建工作任务`模板。这是工作人员在标注时将要查看的UI。我们将在UI中显示预测结果和原始文档数据。我们已经为此用例使用了一个预构建的分类模板（[https://github.com/aws-samples/amazon-a2i-sample-task-uis/blob/master/text/document-classification.liquid.html](https://github.com/aws-samples/amazon-a2i-sample-task-uis/blob/master/text/document-classification.liquid.html)）。运行笔记本单元来定义HTML模板。
- en: Important Note
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can create a custom UI HTML template based on what type of data you want
    to show to your labelers. For example, you can show the actual document on the
    right and entities highlighted on the left using custom UIs.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以根据希望向标注者展示的数据类型，创建自定义的UI HTML模板。例如，你可以在右侧显示实际文档，在左侧高亮显示实体，使用自定义UI。
- en: 'We have defined or chosen the HTML template in the preceding step, in which
    we will create a function to create a UI task using the `create_human_task_ui`
    API by running the following code:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在前一步中定义或选择了HTML模板，在此模板中，我们将通过运行以下代码，使用`create_human_task_ui` API创建一个UI任务：
- en: '[PRE12]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Run the next cell to invoke the function to create the UI task defined in the
    previous step. You will get a `human task arn` response.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元来调用前一步中定义的创建UI任务的函数。你将获得一个`human task arn`响应。
- en: 'Now, we will define a human review workflow. This human review workflow needs
    the private workforce you created, the UI template task you created, and a data
    bucket where you want the output of human review. We will use the `sagemaker.create_flow_definition`
    API to create a flow definition or human review workflow by running the following
    code:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将定义一个人工审核工作流。这个人工审核工作流需要你创建的私人劳动力、你创建的UI模板任务，以及你希望将人工审核输出保存到的数据桶。我们将使用`sagemaker.create_flow_definition`
    API，通过运行以下代码创建一个工作流定义或人工审核工作流：
- en: '[PRE13]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, we will get the response from the Comprehend custom classifier endpoint
    for the sample document for pay stubs on the sample data and parse this response
    for the human loop setup:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将从Comprehend自定义分类器端点获取工资单示例数据的响应，并解析此响应以设置人工循环：
- en: '[PRE14]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, using this preceding JSON response, we will set a confidence threshold.
    This `StartHumanloop` API needs the workflow ARN or flow definition ARN created
    in the previous step and the JSON response from the Comprehend classification
    to create a human loop. We are triggering this loop based on the confidence score
    threshold, as shown in the next code block:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用这个前面的JSON响应，我们将设置一个信心阈值。这个`StartHumanloop` API需要前一步创建的工作流ARN或流定义ARN以及Comprehend分类的JSON响应，以创建人工循环。我们将根据信心评分阈值触发这个循环，如下一个代码块所示：
- en: '[PRE15]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Important Note
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: The preceding condition states anything greater than 90% confidence from your
    model endpoint will trigger a loop. This threshold is for demo purposes and needs
    to be changed for real use cases, such as anything below 90% that would trigger
    a human loop.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的条件说明，任何大于90%信心的模型端点输出将触发一个循环。这个阈值仅用于演示目的，实际使用时需要更改，例如，低于90%时触发人工循环。
- en: 'Now, run the following code to get the link to your private work team to start
    labeling:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，运行以下代码以获取私人工作团队的链接，开始标注工作：
- en: '[PRE16]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You will get a link to the following A2I portal:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将获得以下A2I门户的链接：
- en: '![Figure 15.11 – Amazon A2I login console'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 15.11 – 亚马逊 A2I 登录控制台'
- en: '](img/B17528_15_11.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_11.jpg)'
- en: Figure 15.11 – Amazon A2I login console
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15.11 – 亚马逊 A2I 登录控制台
- en: Select **Task title** and click on **Start working**; you will be redirected
    to the classification task UI.![Figure 15.12 – Amazon A2I sample classification
    task UI
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**任务标题**并点击**开始工作**；你将被重定向到分类任务UI。![图 15.12 – 亚马逊 A2I 示例分类任务UI
- en: '](img/B17528_15_12.jpg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_15_12.jpg)'
- en: Figure 15.12 – Amazon A2I sample classification task UI
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15.12 – 亚马逊 A2I 示例分类任务UI
- en: Review the data on the left in the previous screenshot and classify it by selecting
    the **Pay Stubs** category, and then click **Submit**.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 查看前一截图左侧的数据，并通过选择**工资单**类别进行分类，然后点击**提交**。
- en: 'After submitting this classification task as a human reviewer, go back to the
    notebook and run the following code to get the completed tasks:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交此分类任务作为人工审查后，返回笔记本并运行以下代码，获取已完成的任务：
- en: '[PRE17]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we will review the human-reviewed results from completed human reviews,
    which are stored automatically as a JSON file in Amazon S3 by running the following
    code:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将审查从已完成的人工审查中获得的结果，这些结果会自动存储为JSON文件在Amazon S3中，你可以通过运行以下代码来查看：
- en: '[PRE18]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You get the following response:'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将收到以下响应：
- en: '![Figure 5.13 – Human-reviewed JSON response'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.13 – 人工审查的JSON响应'
- en: '](img/B17528_15_13.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_15_13.jpg)'
- en: Figure 5.13 – Human-reviewed JSON response
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 – 人工审查的JSON响应
- en: Using this data, you can augment or enrich your existing dataset used for training.
    Try combining this data with the Comprehend training data we created and try retraining
    your model to improve accuracy. We will point you to some blogs to accomplish
    this step in the *Further reading* section.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些数据，你可以扩展或丰富用于训练的现有数据集。试着将这些数据与我们创建的Comprehend训练数据结合，尝试重新训练你的模型以提高准确率。我们将在*进一步阅读*部分中提供一些博客链接，帮助你完成这一步。
- en: Important Note
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Please delete the model and the Comprehend endpoints created for the steps we
    did in this notebook.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 请删除我们在此笔记本中创建的模型和Comprehend端点。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered two things using a reference architecture as well
    as a code walkthrough. Firstly, we covered how you can extract data from various
    types of documents, such as pay stubs, bank statements, or identification cards
    using Amazon Textract. Then, we learned how you can perform some post-processing
    to create a labeled training file for Amazon Comprehend custom classification
    training.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们通过参考架构和代码演示讲解了两件事。首先，我们讲解了如何使用Amazon Textract从各种类型的文档中提取数据，如工资单、银行对账单或身份证。然后，我们学习了如何进行一些后处理操作，以创建用于Amazon
    Comprehend自定义分类训练的标签化训练文件。
- en: We showed you that even with 36 bank statement documents and 24 pay stubs as
    a training sample, you can achieve really good accuracy using Amazon Comprehend
    transfer-learning capabilities and AutoML with document or text classification.
    Obviously, the accuracy improves with more data.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们向你展示了，即使只有36份银行对账单和24份工资单作为训练样本，你也可以通过使用Amazon Comprehend的迁移学习能力和AutoML进行文档或文本分类，获得非常好的准确率。显然，随着数据量的增加，准确率会提高。
- en: Then, you learned how to set up a training job in the AWS Management Console
    and how to set up a real-time classification endpoint using the AWS Management
    Console.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，你学习了如何在AWS管理控制台中设置训练任务，以及如何在AWS管理控制台中设置实时分类端点。
- en: Secondly, you learned how you can set up humans in the loop with the real-time
    classification endpoint to review/verify and validate what the model has classified.
    We then also discussed how you can retrain your existing model by adding this
    data with your existing training data and set up a retraining or active-learning
    loop. Please refer to the *Further reading* section to automate this workflow
    using Lambda functions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，你学习了如何使用实时分类端点设置“人类在环”系统，以审查/验证和确认模型所分类的内容。我们还讨论了如何通过将这些数据与现有的训练数据一起添加，来重新训练现有的模型，并设置一个重新训练或主动学习循环。请参阅*进一步阅读*部分，了解如何使用Lambda函数自动化此工作流。
- en: In the next chapter, we will cover how you can improve the accuracy of **PDF
    batch processing** with Amazon Textract and humans in the loop. So, stay tuned!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何利用Amazon Textract和“人类在环”系统提高**PDF批量处理**的准确性。敬请期待！
- en: Further reading
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Active learning workflow for Amazon Comprehend custom classification models
    – Part 2*, *Shanthan Kesharaju, Joyson Neville Lewis, and Mona Mona* ([https://aws.amazon.com/blogs/machine-learning/active-learning-workflow-for-amazon-comprehend-custom-classification-part-2/)](https://aws.amazon.com/blogs/machine-learning/active-learning-workflow-for-amazon-comprehend-custom-classification-part-2/)%20)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Amazon Comprehend自定义分类模型的主动学习工作流 - 第2部分*，*Shanthan Kesharaju, Joyson Neville
    Lewis 和 Mona Mona* ([https://aws.amazon.com/blogs/machine-learning/active-learning-workflow-for-amazon-comprehend-custom-classification-part-2/)](https://aws.amazon.com/blogs/machine-learning/active-learning-workflow-for-amazon-comprehend-custom-classification-part-2/)%20)'
- en: '*Creating and Using Custom Classifiers (*[https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-document-classification.html](https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-document-classification.html))'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*创建和使用自定义分类器*（*[https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-document-classification.html](https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-document-classification.html)）'
