- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Data Versioning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据版本控制
- en: '**Data versioning** refers to the systematic tracking and management of different
    iterations of datasets used throughout the life cycle of model development, including
    pre-training, fine-tuning, evaluation, and deployment. It involves assigning unique
    identifiers to datasets or subsets thereof, capturing changes over time, and enabling
    reproducibility by ensuring that any specific model version can be linked back
    to the exact data version used.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据版本控制**指的是在整个模型开发生命周期中，包括预训练、微调、评估和部署过程中，对数据集的不同迭代进行系统跟踪和管理。它涉及为数据集或其子集分配唯一的标识符，记录随时间的变化，并通过确保任何特定模型版本都可以回溯到确切的数据版本来确保可重复性。'
- en: In this chapter, you’ll learn how to implement effective data versioning strategies
    for LLM development. For instance, when we want to add 10,000 new oncology research
    papers to a dataset, the system automatically creates a new dataset version. If
    the model performance then degrades, the dataset can instantly roll back to the
    previous verified dataset version, ensuring reproducibility and maintaining the
    integrity of the research process.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何为 LLM 开发实现有效的数据版本控制策略。例如，当我们想要将 10,000 篇新的肿瘤学研究论文添加到数据集中时，系统会自动创建一个新的数据集版本。如果模型性能随后下降，数据集可以立即回滚到之前经过验证的数据集版本，确保可重复性和维护研究过程的完整性。
- en: This design pattern transforms dataset management from a chaotic, manual process
    into a structured, trackable workflow in LLM model development.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设计模式将数据集管理从混乱的、手动的过程转变为 LLM 模型开发中的结构化、可追踪的工作流程。
- en: 'In this chapter, we’ll be covering the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding the need for data versioning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据版本控制的需求
- en: Data versioning strategies for large language datasets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言数据集的数据版本控制策略
- en: Tools for data versioning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据版本控制工具
- en: Integrating data versioning in training workflows
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据版本控制集成到训练工作流程中
- en: Version control for text corpora
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本语料库的版本控制
- en: Managing dataset variants and experiments
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理数据集变体和实验
- en: Best practices for data versioning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据版本控制的最佳实践
- en: Understanding the need for data versioning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据版本控制的需求
- en: Data versioning is particularly important in LLM projects due to the massive
    scale and complexity of language datasets. As an LLM engineer, you need to track
    changes in your datasets to ensure the reproducibility of your models and maintain
    a clear history of data modifications.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语言数据集的规模和复杂性巨大，数据版本控制对于 LLM 项目尤为重要。作为一名 LLM 工程师，您需要跟踪数据集中的变化，以确保模型的可重复性，并保持数据修改的清晰历史记录。
- en: 'Let’s start by implementing a basic data versioning system using Python:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用 Python 实现一个基本的数据版本控制系统开始：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This part of the `DatasetVersion` class initializes the basic structure for
    versioning your LLM datasets. It generates a unique hash for each version of the
    data and timestamps the version. The `_generate_hash` method creates a deterministic
    hash based on the sorted JSON representation of the data, ensuring that identical
    data always produces the same hash.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`DatasetVersion` 类的这一部分初始化了为您的 LLM 数据集进行版本控制的基本结构。它为每个数据版本生成一个唯一的哈希值，并标记版本的时间戳。`_generate_hash`
    方法基于数据的排序 JSON 表示创建一个确定性的哈希值，确保相同的数据总是产生相同的哈希值。'
- en: 'Now, let’s add the `save` and `load` methods for dataset versions:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为数据集版本添加 `save` 和 `load` 方法：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `save` method serializes the dataset version to a JSON file, including all
    relevant information. The `load` method is a class method that reconstructs a
    `DatasetVersion` instance from a saved file. This allows you to easily store and
    retrieve different versions of your dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`save` 方法将数据集版本序列化为 JSON 文件，包括所有相关信息。`load` 方法是一个类方法，它从保存的文件中重建一个 `DatasetVersion`
    实例。这使得您可以轻松地存储和检索数据集的不同版本。'
- en: Having discussed the need for data versioning, now let us outline key strategies
    for managing versioning in large language datasets to support traceability, reproducibility,
    and efficient storage.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了数据版本控制的需求之后，现在让我们概述管理大型语言数据集版本控制的关键策略，以支持可追溯性、可重复性和高效的存储。
- en: Data versioning strategies for large language datasets
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言数据集的数据版本控制策略
- en: Among the various strategies available for handling data versioning—such as
    snapshotting, content-addressable storage, and checksum-based tracking—this section
    focuses on the **delta-based system** due to its potential for minimizing storage
    costs when dealing with iterative updates in large language datasets. Delta-based
    versioning stores only the differences between dataset versions rather than duplicating
    entire files, making it particularly effective in scenarios involving frequent
    but minor changes. However, its effectiveness decreases when the dataset structure
    undergoes significant reformatting or involves binary files. Schema changes, column
    reordering, or file splitting can disrupt the delta mechanism, often necessitating
    a full dataset rewrite. Similarly, binary files, due to their opaque structure
    and compression, tend to change globally with even minor edits, limiting the advantage
    of delta-based storage. This approach is discussed here for its relevance in typical
    LLM workflows where data evolves gradually but remains largely text-based and
    structured.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理大型语言数据集的迭代更新时，由于可以最小化存储成本，本节重点介绍了**基于增量的系统**，因为它在处理数据版本管理时具有潜在优势。基于增量的版本管理只存储数据集版本之间的差异，而不是复制整个文件，这使得它在涉及频繁但微小的更改的场景中特别有效。然而，当数据集结构发生重大重新格式化或涉及二进制文件时，其有效性会降低。模式更改、列重排或文件拆分可能会破坏增量机制，通常需要完整数据集的重写。同样，由于二进制文件的结构不透明和压缩，即使是微小的编辑也会导致全局变化，限制了基于增量存储的优势。这种方法在此处讨论，因为它在典型的LLM工作流程中具有相关性，其中数据逐渐演变，但仍然主要基于文本和结构化。
- en: 'Here’s an example of how you might implement a delta-based versioning system:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个如何实现基于增量版本化系统的示例：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This part of the `DeltaDatasetVersion` class extends our previous `DatasetVersion`
    class to implement delta-based versioning. The `_compute_delta` method calculates
    the differences between the current version and a base version using Python’s
    `difflib`. This approach can significantly reduce storage requirements for large
    datasets by only storing the changes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`DeltaDatasetVersion`类的这部分扩展了我们的先前`DatasetVersion`类，以实现基于增量的版本管理。`_compute_delta`方法使用Python的`difflib`计算当前版本与基础版本之间的差异。这种方法可以通过仅存储更改来显著减少大型数据集的存储需求。'
- en: 'Now, let’s add methods to save and load these delta-based versions:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加保存和加载这些基于增量的版本的方法：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `save` method now stores only the delta and metadata, significantly reducing
    the file size of large datasets. The `load` method reconstructs the full dataset
    by applying the delta to the base version. This approach allows for the efficient
    storage and retrieval of multiple versions of large language datasets.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`save` 方法现在只存储增量数据和元数据，显著减少了大型数据集的文件大小。`load` 方法通过将增量应用于基础版本来重建完整数据集。这种方法允许高效地存储和检索大型语言数据集的多个版本。'
- en: Tools for data versioning
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据版本管理工具
- en: While custom solutions can be effective, there are also specialized tools designed
    for data versioning in machine learning projects. One such tool is **Data Version
    Control** (**DVC**), which integrates with Git and provides powerful features
    for managing large datasets and is widely used. DVC is an open-source tool that
    extends Git to manage large datasets and machine learning artifacts by storing
    data in external storage while tracking metadata in the Git repository. It enables
    reproducible pipelines, efficient data sharing, and experiment tracking, making
    it a popular choice for managing LLM datasets and training workflows.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然自定义解决方案可能有效，但还有专门为机器学习项目中的数据版本管理设计的工具。其中一个这样的工具是**数据版本控制**（**DVC**），它与Git集成，并为管理大型数据集和机器学习工件提供了强大的功能，并且被广泛使用。DVC是一个开源工具，它扩展了Git以管理大型数据集和机器学习工件，通过在外部存储中存储数据，同时在Git仓库中跟踪元数据。它使可重复的管道、高效的数据共享和实验跟踪成为可能，使其成为管理LLM数据集和训练工作流程的热门选择。
- en: Given the scale of LLM models, DVC’s versioning approach must carefully balance
    comprehensive tracking with computational efficiency, requiring intelligent checksum
    and metadata calculation strategies that minimize latency and processing overhead
    to prevent versioning from becoming a bottleneck in the model development workflow.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM模型规模庞大，DVC的版本化方法必须仔细平衡全面的跟踪与计算效率，需要智能的校验和元数据计算策略，以最小化延迟和处理开销，防止版本管理成为模型开发工作流程的瓶颈。
- en: 'Here’s an example of how you might use DVC in your LLM project:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个如何在您的LLM项目中使用DVC的示例：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This part of the script demonstrates how to initialize DVC, add a dataset to
    DVC tracking, and commit a new version of the dataset. DVC works alongside Git,
    allowing you to version your data in a similar way to how you version your code.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本部分演示了如何初始化 DVC，将数据集添加到 DVC 跟踪中，并提交数据集的新版本。DVC 与 Git 一起工作，允许你以与版本化代码类似的方式版本化你的数据。
- en: 'Similar to Git, DVC uses `init`, `add`, `commit`, and `push` commands. The
    following list briefly describes each command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Git 类似，DVC 使用 `init`、`add`、`commit` 和 `push` 命令。以下列表简要描述了每个命令：
- en: '`dvc init`: Initializes a new DVC project by creating a `.dvc` directory in
    your project and setting up the necessary metadata tracking infrastructure. This
    is analogous to `git init`, but specifically for data version control, preparing
    your project to track large datasets and model files.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dvc init`：通过在项目中创建 `.dvc` 目录并设置必要的元数据跟踪基础设施来初始化新的 DVC 项目。这类似于 `git init`，但专门用于数据版本控制，为跟踪大型数据集和模型文件准备你的项目。'
- en: '`dvc add`: Adds large data files to DVC tracking, creating a lightweight `.dvc`
    metadata file that contains a hash of the file. This command moves the actual
    data to a separate storage location while maintaining a reference in your Git
    repository, allowing you to version large files without bloating your Git repository.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dvc add`：将大型数据文件添加到 DVC 跟踪中，创建一个轻量级的 `.dvc` 元数据文件，其中包含文件的哈希值。此命令将实际数据移动到单独的存储位置，同时在你的
    Git 仓库中保持引用，允许你在不膨胀 Git 仓库的情况下对大型文件进行版本控制。'
- en: '`dvc commit`: Creates a snapshot of the current state of your tracked data
    files, similar to a Git commit but specifically for data files. This command helps
    you mark significant points in your data’s history and creates a clear record
    of when and how your datasets changed.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dvc commit`：创建当前跟踪数据文件的快照，类似于 Git 提交，但专门用于数据文件。此命令帮助你标记数据历史的显著点，并创建一个清晰记录，说明数据集何时以及如何更改。'
- en: '`dvc push`: Uploads your tracked data files to a remote storage location (such
    as cloud storage, network drive, or local external storage). This command ensures
    that your data versions are safely backed up and can be retrieved by other team
    members or across different development environments.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dvc push`：将你的跟踪数据文件上传到远程存储位置（如云存储、网络驱动器或本地外部存储）。此命令确保你的数据版本安全备份，并且可以被其他团队成员或不同开发环境检索。'
- en: 'Now, let’s add a function to push the dataset to remote storage:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加一个函数将数据集推送到远程存储：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `push_dataset_to_remote` function pushes both the DVC-tracked data and the
    Git repository to their respective remote storage locations. This allows you to
    store your large datasets separately from your code repository while maintaining
    version control for both.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`push_dataset_to_remote` 函数将 DVC 跟踪的数据和 Git 仓库推送到各自的远程存储位置。这允许你将大型数据集与代码仓库分开存储，同时保持对两者的版本控制。'
- en: Next, we will focus on integrating data versioning within the training workflow.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将专注于在训练工作流程中集成数据版本控制。
- en: Integrating data versioning in training workflows
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在训练工作流程中集成数据版本控制
- en: 'To make data versioning an integral part of your LLM training workflow, you
    need to incorporate version checking and logging into your training scripts. Here’s
    an example of how you might do this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要使数据版本控制成为你 LLM 训练工作流程的组成部分，你需要将版本检查和记录集成到你的训练脚本中。以下是一个示例，说明你可能如何做到这一点：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This code snippet shows how to incorporate dataset version information into
    your LLM training workflow. The `DatasetInfo` class encapsulates the essential
    version information, while the `load_dataset_info` function retrieves this information
    from a JSON file. The `train_llm` function demonstrates how to log the dataset
    version and metadata during training, ensuring that each trained model is associated
    with a specific version of the data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段展示了如何将数据集版本信息集成到你的 LLM 训练工作流程中。`DatasetInfo` 类封装了基本版本信息，而 `load_dataset_info`
    函数从 JSON 文件中检索这些信息。`train_llm` 函数演示了如何在训练期间记录数据集版本和元数据，确保每个训练模型都与特定版本的数据相关联。
- en: 'Here’s how you might use this in a training script:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练脚本中，你可能这样使用它：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: By integrating dataset version information into your training process, you enhance
    reproducibility and make it easier to track which version of the data was used
    for each trained model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将数据集版本信息集成到你的训练过程中，你增强了可重复性，并使跟踪每个训练模型使用的数据版本变得更容易。
- en: Version control for text corpora
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本语料库的版本控制
- en: 'When dealing with text corpora for LLM training, you often need to handle large
    collections of documents. Here’s an approach to version control for text corpora
    using a combination of file hashing and metadata tracking:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理用于LLM训练的文本语料库时，你经常需要处理大量文档。以下是一个使用文件哈希和元数据跟踪的组合方法来对文本语料库进行版本控制的方法：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This part of the code defines functions to hash individual files and generate
    a manifest of all files in a corpus directory. The manifest is a dictionary mapping
    relative file paths to their corresponding hash values, providing a snapshot of
    the entire corpus. The manifest file is important because it serves as a compact,
    reproducible fingerprint of the entire dataset, enabling quick integrity checks,
    facilitating version tracking, and allowing researchers to verify the exact state
    of their corpus across different environments or points in time without needing
    to store or transfer the entire large dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分代码定义了函数来对单个文件进行哈希处理并生成语料库目录中所有文件的清单。清单是一个将相对文件路径映射到其对应哈希值的字典，提供了整个语料库的快照。清单文件很重要，因为它作为整个数据集的紧凑、可重复的指纹，使得快速完整性检查、促进版本跟踪，并允许研究人员在不同的环境或时间点验证其语料库的确切状态，而无需存储或传输整个大型数据集。
- en: 'Now, let’s add a function to compare two manifests and identify changes:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加一个函数来比较两个清单并识别变化：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `compare_manifests` function identifies added, removed, and modified files
    between two versions of the corpus. This approach allows you to track changes
    in your text corpus efficiently, even when dealing with large numbers of files.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`compare_manifests` 函数识别语料库两个版本之间添加的、删除的和修改的文件。这种方法允许你有效地跟踪文本语料库中的变化，即使处理大量文件也是如此。'
- en: Managing dataset variants and experiments
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理数据集变体和实验
- en: 'In LLM development, you often need to manage multiple variants of your dataset
    for different experiments. Here’s a simple system for managing dataset variants:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM开发中，你经常需要管理数据集的多个变体以进行不同的实验。以下是一个简单的系统来管理数据集变体：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This part of the `DatasetVariantManager` class sets up the basic structure for
    managing dataset variants. It initializes the manager with a base path and loads
    existing variants from a JSON file, if available.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`DatasetVariantManager` 类的这一部分设置了管理数据集变体的基本结构。它使用基础路径初始化管理器，并在可用的情况下从JSON文件中加载现有变体。'
- en: 'Now, let’s add methods to create and retrieve variants:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加创建和检索变体的方法：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `create_variant` method allows you to create new dataset variants based
    on existing ones, specifying only the changes. The `get_variant` method retrieves
    a variant, applying all changes from its base variants recursively. This system
    allows you to efficiently manage and track different configurations of your dataset
    for various experiments.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_variant` 方法允许你根据现有数据集创建新的数据集变体，只需指定更改即可。`get_variant` 方法检索一个变体，递归地应用其基础变体的所有更改。这个系统允许你有效地管理和跟踪数据集的不同配置，以进行各种实验。'
- en: 'A clear and consistent naming convention is recommended for managing dataset
    variants in LLM development to ensure traceability, reproducibility, and clarity.
    Here is a suggested naming convention that balances readability and scalability
    for managing dataset variants:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM开发中管理数据集变体时，建议使用清晰和一致的名字约定，以确保可追溯性、可重复性和清晰性。以下是一个建议的名字约定，它平衡了可读性和可扩展性，用于管理数据集变体：
- en: '`<``base>_<modifier1>_<modifier2>_..._<description>`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`<``base>_<modifier1>_<modifier2>_..._<description>`'
- en: This format uses a **base name** to indicate the root dataset, followed by **modifiers**
    and optional descriptions to specify what changes or attributes differentiate
    the variant. Modifiers are concise and ordered hierarchically to reflect the transformation
    process.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此格式使用 **基础名称** 来指示根数据集，后跟 **修饰符** 和可选的描述来指定区分变体的变化或属性。修饰符简洁且按层次顺序排列，以反映转换过程。
- en: 'Let’s look at the key components closely:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看关键组件：
- en: '`base` or a descriptive name (e.g., `clean` or `raw`).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base` 或描述性名称（例如，`clean` 或 `raw`）。'
- en: '**Modifiers**: Sequential changes or transformations applied to the base. Each
    modifier reflects an aspect of the dataset such as size, language, or preprocessing
    applied.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修饰符**：应用于基础数据的顺序变化或转换。每个修饰符反映数据集的一个方面，例如大小、语言或应用的前处理。'
- en: '**Description**: An optional part that provides extra context or details about
    the changes, typically used for experiments.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**描述**：一个可选部分，提供关于更改的额外上下文或详细信息，通常用于实验。'
- en: Best practices for data versioning
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据版本化的最佳实践
- en: 'Over the years, I have gathered the following best practices:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，我收集了以下最佳实践：
- en: Use a dedicated data versioning tool such as DVC for large-scale projects.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大规模项目，使用专用的数据版本化工具，如DVC。
- en: Include dataset version information in your model metadata.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的模型元数据中包含数据集版本信息。
- en: Use delta-based versioning for large datasets to save storage space.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大型数据集，使用基于delta的版本化以节省存储空间。
- en: Implement regular backups of your versioned datasets.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期备份您的已版本化数据集。
- en: Use consistent naming conventions for dataset versions and variants.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为数据集版本和变体使用一致的命名约定。
- en: Integrate data versioning checks into your `dvc status` to verify no unexpected
    modifications have occurred, automatically comparing dataset checksums against
    approved versions, and blocking model training if any data discrepancies are detected.
    Key steps include creating a pre-training validation stage that compares current
    dataset versions with expected reference versions, automatically triggering alerts
    or stopping the pipeline if unverified data modifications are detected, and maintaining
    a comprehensive audit trail of dataset changes throughout the machine learning
    development process.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据版本检查集成到您的 `dvc status` 中，以验证是否发生了意外的修改，自动将数据集校验和与批准版本进行比较，并在检测到任何数据差异时阻止模型训练。关键步骤包括创建一个预训练验证阶段，比较当前数据集版本与预期参考版本，在检测到未经验证的数据修改时自动触发警报或停止管道，并在机器学习开发过程中维护数据集变化的全面审计记录。
- en: Summary
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored various aspects of data versioning for LLM development.
    We implemented basic versioning systems and delta-based versioning for large datasets.
    We examined tools such as DVC for more advanced versioning needs. We also looked
    at integrating data versioning into LLM training workflows, managing text corpora
    versions, and handling dataset variants for experiments.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了LLM开发中数据版本化的各个方面。我们实现了基本的版本化系统和针对大型数据集的基于delta的版本化。我们检查了DVC等工具以满足更高级的版本化需求。我们还探讨了将数据版本化集成到LLM训练工作流程中、管理文本语料库版本以及处理实验数据集变体的方法。
- en: Data versioning is a critical practice in LLM development, ensuring reproducibility,
    facilitating collaboration, and enabling robust model governance. By implementing
    these techniques and best practices, you can significantly improve the manageability
    and reliability of your LLM projects.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 数据版本化是LLM开发中的关键实践，确保可重复性、促进协作并使模型治理更加稳健。通过实施这些技术和最佳实践，您可以显著提高LLM项目的可管理性和可靠性。
- en: In the upcoming chapter, we’ll explore dataset annotation and labeling techniques
    specifically tailored for LLMs. In particular, we’ll cover strategies for efficient
    annotation, quality control measures, and methods for scaling annotation processes
    to meet the demands of large language datasets.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在即将到来的章节中，我们将探讨针对LLMs特别定制的数据集标注和标记技术。特别是，我们将介绍高效标注策略、质量控制措施以及将标注过程扩展以满足大型语言数据集需求的方法。
