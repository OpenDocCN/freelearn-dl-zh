- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: The Emergence of Risk-Averse Methodologies and Frameworks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 风险规避方法和框架的出现
- en: This chapter gives a detailed overview of defining and architecting ML defense
    frameworks that can protect data, ML models, and other necessary artifacts at
    different stages of ML training and evaluation pipelines. In this chapter, you
    will learn about different anonymization, encryption, and application-level privacy
    techniques, as well as hybrid security measures, that serve as the basis of ML
    model development for both centralized and distributed learning. In addition,
    you will also discover scenario-based defense techniques that can be applied to
    safeguard data and models to solve practical industry-grade ML use cases. The
    primary objective of this chapter is to explain the application of commonly used
    defense tools, libraries, and metrics available for large-scale ML SaaS platforms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细概述了定义和架构机器学习防御框架的方法，这些框架能够在机器学习训练和评估流程的不同阶段保护数据、机器学习模型及其他必要的人工制品。在本章中，您将了解不同的匿名化、加密和应用层隐私技术，以及作为机器学习模型开发基础的混合安全措施，这些措施适用于集中式和分布式学习。此外，您还将发现基于场景的防御技术，这些技术可以应用于保护数据和模型，以解决实际的行业级机器学习用例。本章的主要目标是解释大型机器学习SaaS平台上常用的防御工具、库和度量标准的应用。
- en: 'In this chapter, these topics will be covered in the following sections:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将通过以下各节介绍这些主题：
- en: Threat matrix and defense techniques
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 威胁矩阵和防御技术
- en: Anonymization and data encryption
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匿名化与数据加密
- en: '**Differential** **Privacy** (**DP**)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差分隐私** (**DP**)'
- en: Hybrid privacy methods and models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合隐私方法与模型
- en: Adversarial risk mitigation frameworks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗性风险缓解框架
- en: Further, with the use of `pysft`, `Pyhfel`, `secml` , `ml_privacy_meter`, `tensorflow_privacy`,
    `mia`, `diffprivlib`, and `foolbox`, we will see how to test model robustness
    against adversarial attacks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用`pysft`、`Pyhfel`、`secml`、`ml_privacy_meter`、`tensorflow_privacy`、`mia`、`diffprivlib`和`foolbox`，我们将看到如何测试模型对抗性攻击的鲁棒性。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires you to have Python 3.8 installed along with the Python
    packages listed here (with their installation commands), as well as Keras 2.7.0
    and TensorFlow 2.7.0:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求您安装Python 3.8，并且安装以下列出的Python包（以及其安装命令），同时还需安装Keras 2.7.0和TensorFlow 2.7.0：
- en: '`pip` `install adversarial-robustness-toolbox`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install adversarial-robustness-toolbox`'
- en: '`pip` `install syft==0.2.9`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install syft==0.2.9`'
- en: '`pip` `install Pyfhel`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install Pyfhel`'
- en: '`pip` `install secml`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install secml`'
- en: '`git` `clone https://github.com/privacytrustlab/ml_privacy_meter`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` `clone https://github.com/privacytrustlab/ml_privacy_meter`'
- en: '`pip install -r requirements.txt`, `pip` `install -e`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install -r requirements.txt`, `pip` `install -e`'
- en: '`pip` `install diffprivlib`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install diffprivlib`'
- en: '`pip` `install tensorflow-privacy`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install tensorflow-privacy`'
- en: '`pip` `install mia`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install mia`'
- en: '`pip` `install foolbox`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install foolbox`'
- en: Analyzing the threat matrix and defense techniques
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析威胁矩阵和防御技术
- en: 'In this section, let''s look at different defense techniques essential for
    enterprises to proactively manage threats related to adversarial attacks during
    the following stages:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨对企业而言，在以下阶段中主动管理与对抗性攻击相关的威胁所必需的各种防御技术：
- en: Initial research, planning, and system and model design/architecture phase
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始研究、规划和系统与模型设计/架构阶段
- en: ML model training and deployment
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型训练与部署
- en: ML model live in production
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型投入生产
- en: You will also get learn additional capabilities, expertise, and infrastructure
    that organizations need to invest in to have a foolproof defense system.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您还将学习到组织需要投资的其他能力、专业知识和基础设施，以建立一个万无一失的防御系统。
- en: Researching and planning during the system and model design/architecture phase
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统和模型设计/架构阶段的研究与规划
- en: This phase (*Figure 2**.1*) is related to all actions taken during model design,
    architectural planning, and conceptualization in which the adversary carries out
    preliminary investigations, searching to gain knowledge of the victim’s infrastructure,
    datasets, and models that will enable them to set up their own capabilities for
    initiating attacks on ML SaaS platforms.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此阶段（*图2.1*）与模型设计、架构规划和概念化期间采取的所有行动有关，在此期间，攻击者进行初步调查，试图获取有关受害者的基础设施、数据集和模型的信息，这些信息将使他们能够建立自己的能力，以便在机器学习SaaS平台上发起攻击。
- en: '![Figure 2.1 – Relevant attack stages during ML model design and development](img/Figure_2.01_B18681.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 机器学习模型设计和开发过程中的相关攻击阶段](img/Figure_2.01_B18681.jpg)'
- en: Figure 2.1 – Relevant attack stages during ML model design and development
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 在机器学习模型设计和开发过程中的相关攻击阶段
- en: We see here the large scope of the initial phase, where adversarial actions
    can be detrimental to our model and architecture conceptualization. Now, let's
    discuss the different steps adversaries take when trying to perform an attack.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，初期阶段的范围非常广泛，对手的行动可能对我们的模型和架构设计构成不利影响。现在，让我们讨论对手在尝试进行攻击时所采取的不同步骤。
- en: Reconnaissance
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 侦察
- en: '**Reconnaissance** is one of the early stages where an adversary actively or
    passively gathers information to use in later adversarial stages to enable **resource
    development**, execute **initial access**, or lead to the execution of continuous
    reconnaissance attempts. Some of the associated risks and mitigations of this
    stage are described in the following list. The best way for the victim to mitigate
    reconnaissance attempts is to minimize the availability of sensitive information
    to external entities and employ network content, network flow, file creation,
    and application log monitoring agents to detect and raise alarms if suspicious
    activity (such as bots or web crawling) is detected from a single IP source.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**侦察**是对手主动或被动地收集信息的早期阶段，收集的信息将在后续的对抗阶段中使用，以促进**资源开发**、执行**初步访问**或导致持续的侦察尝试。一些与此阶段相关的风险和缓解措施如下所述。受害者减轻侦察尝试的最佳方法是将敏感信息对外部实体的可用性降到最低，并采用网络内容、网络流量、文件创建和应用程序日志监控代理，以便在从单一IP源检测到可疑活动（如机器人或网站抓取）时发出警报。'
- en: 'Let''s now describe how reconnaissance can take place:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来描述侦察是如何进行的：
- en: '**Active scanning**: This step involves scanning operations by adversaries
    to gather information for targeting. Scanning and search operations (on websites/domains
    or open technical databases) may be carried out on victim infrastructure via network
    traffic (with network protocols such as ICMP) by probing mechanisms, or by collecting
    information through external remote services or public-facing applications.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主动扫描**：此步骤涉及对手通过扫描操作收集信息以进行目标定位。扫描和搜索操作（在网站/域名或开放技术数据库上）可能通过网络流量（如ICMP协议）在受害者基础设施上执行，或者通过外部远程服务或面向公众的应用程序收集信息。'
- en: '**Gather victim host/identity/organization information**: This step involves
    adversarial activity to gain information related to victims’ administrative data
    (e.g., name, assigned IP, functionality, IP ranges, domain names, etc.), configuration
    (e.g., operating system, language, etc.), names of divisions/departments, business
    operations, and the roles and responsibilities of major employees.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集受害者主机/身份/组织信息**：此步骤涉及对手活动，旨在获取与受害者的管理数据相关的信息（例如，姓名、分配的IP、功能、IP范围、域名等）、配置（例如，操作系统、语言等）、部门/部门名称、业务操作以及主要员工的角色和职责。'
- en: '`User-Agent` string HTTP/S fields) to automatically remove malicious links
    and attachments.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`User-Agent` 字符串 HTTP/S 字段）自动删除恶意链接和附件。'
- en: Using anti-spoofing mechanisms, providing restricted access to websites that
    have attachments (`.pdf`, `.docx`, `.exe`, `.pif`, `.cpl`, and so on), and enabling
    email authentication can enable protection against phishing activities.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用反欺骗机制、提供对附件（`.pdf`、`.docx`、`.exe`、`.pif`、`.cpl`等）的限制访问权限，并启用电子邮件身份验证，可以有效防止钓鱼活动。
- en: '**Search closed sources, open technical databases, websites and domains, and
    victim-owned websites**: These search operations by the adversary can help to
    retrieve confidential information from reputable private sources (such as databases,
    repositories, or paid subscriptions to feeds of technical/threat intelligence
    data). In addition, registrations of domains/certificates; network data/artifacts
    gathered from traffic and/or scans; business-, department-, and employee-related
    information from online sites; and social media can all help the attacker gather
    the information necessary for targeting.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索封闭源、开放技术数据库、网站和域名以及受害者拥有的网站**：对手进行的这些搜索操作有助于从信誉良好的私人源（如数据库、仓库或订阅技术/威胁情报数据的付费信息源）中检索机密信息。此外，域名/证书注册；通过流量和/或扫描收集的网络数据/痕迹；来自在线网站的业务、部门和员工相关信息；以及社交媒体等都可以帮助攻击者收集目标所需的信息。'
- en: Resource development
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资源开发
- en: '**Resource development** is another early phase of adversarial action, where
    adversaries engage themselves in creating resources to use in subsequent attack
    stages. Resources may be created, purchased, or stolen to target victims. Let''s
    examine this in more detail:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源开发**是对抗性行动的另一个早期阶段，在此阶段，攻击者致力于创建用于后续攻击阶段的资源。资源可以通过创建、购买或盗取来针对受害者。我们来更详细地分析这一点：'
- en: '**Public ML artifact retrieval**: This is an important action taken by adversaries
    to retrieve ML artifacts from public sources, cloud storage, public-facing services,
    and data repositories. These artifacts can reveal information related to the software
    stacks, libraries, algorithms, hyperparameters, and model architectures used to
    train, deploy, test, and evaluate ML models. Adversaries can use either the victim’s
    representative datasets or models to modify and craft the datasets and models
    and accordingly train proxy ML models tailored to offline attacks, without directly
    accessing the target model. The best control measures against this that can be
    adopted by organizations are the following:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公共机器学习模型获取**：这是对手从公共来源、云存储、面向公众的服务和数据仓库中获取机器学习模型（ML）工件的重要行为。这些工件可以揭示与用于训练、部署、测试和评估机器学习模型的软件堆栈、库、算法、超参数和模型架构相关的信息。对手可以利用受害者的代表性数据集或模型，修改并构建数据集和模型，从而训练适用于离线攻击的代理机器学习模型，而无需直接访问目标模型。组织可以采取的最佳控制措施包括以下几点：'
- en: Enabling multi-level security rules for the full protection of datasets, models,
    and artifacts by employing built-in multi-factor authentication schemes
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过采用内建的多因素认证方案，启用多层次安全规则以全面保护数据集、模型和工件
- en: Using cloud security rules and ACLs to provide restricted access to ML data
    and artifacts
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用云安全规则和访问控制列表（ACL）提供对机器学习数据和工件的受限访问
- en: '**Gathering adversarial ML attack implementation information**: Open source
    implementations of ML algorithms and adversarial attack code (such as CleverHans
    or ART ([https://researchain.net/archives/pdf/Technical-Report-On-The-Cleverhans-V2-1-0-Adversarial-Examples-Library-2906240](https://researchain.net/archives/pdf/Technical-Report-On-The-Cleverhans-V2-1-0-Adversarial-Examples-Library-2906240))
    and Foolbox ([https://arxiv.org/pdf/1707.04131.pdf](https://arxiv.org/pdf/1707.04131.pdf)))
    can be misused by attackers. As well as facilitating research, these open source
    tools can be used to carry out attacks against victims’ infrastructures. In this
    chapter, we give examples to demonstrate how ART and Foolbox can be used.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集对抗性机器学习攻击实现信息**：机器学习算法和对抗性攻击代码的开源实现（如CleverHans或ART（[https://researchain.net/archives/pdf/Technical-Report-On-The-Cleverhans-V2-1-0-Adversarial-Examples-Library-2906240](https://researchain.net/archives/pdf/Technical-Report-On-The-Cleverhans-V2-1-0-Adversarial-Examples-Library-2906240)）和Foolbox（[https://arxiv.org/pdf/1707.04131.pdf](https://arxiv.org/pdf/1707.04131.pdf)））可能被攻击者滥用。这些开源工具不仅促进研究，也可以被用来对受害者的基础设施发起攻击。在本章中，我们通过示例展示如何使用ART和Foolbox。'
- en: '**Gaining adversarial ML attack implementation expertise and capabilities**:
    After gaining information on open source attack tools, adversaries can deep dive
    into research papers and use their own ideas to craft their own attack models
    and start using them.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获得对抗性机器学习攻击实现专业知识和能力**：在获得开源攻击工具信息后，攻击者可以深入研究论文，运用自己的思路制作攻击模型并开始使用它们。'
- en: '**Acquiring infrastructure – attack development and staging workspaces**: In
    this phase, adversaries rely on the free compute resources available from major
    cloud providers (such as AWS, Google Cloud, Google Colaboratory, and Azure) to
    initiate attacks. The use of multiple workspaces can help them avoid detection.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取基础设施——攻击开发和部署工作空间**：在这一阶段，攻击者依赖于主要云服务提供商（如AWS、Google Cloud、Google Colaboratory和Azure）提供的免费计算资源来启动攻击。使用多个工作空间可以帮助他们避免被检测。'
- en: '**Publishing poisoned datasets and triggering poisoned data training**: This
    step involves creating poisoned datasets (by modifying source datasets, data,
    or its labels) and publishing these to compromise victims’ ML supply chains. The
    vulnerabilities embedded in these ML models using poisoned data are activated
    later and cannot easily be detected.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布毒化数据集并触发毒化数据训练**：此步骤涉及创建毒化数据集（通过修改源数据集、数据或其标签），并将其发布，以破坏受害者的机器学习供应链。这些使用毒化数据的机器学习模型中所嵌入的漏洞在之后会被激活，且不易被检测到。'
- en: 'Strategies that can be employed to protect against poison attacks include leveraging
    De-Pois (De-Pois: An Attack-Agnostic Defense against Data Poisoning Attacks :
    [https://arxiv.org/pdf/2105.03592.pdf](https://arxiv.org/pdf/2105.03592.pdf)),
    an attack-agnostic defense framework used to construct mimic models. This framework
    uses **Generative Adversarial Networks** (**GANs**) to enable the training of
    data with augmentations and the creation of models that behave similarly, in terms
    of outcome, to the original model. This model can detect the poisoned samples
    by evaluating prediction differences between the target model and the mimic model.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '防御中毒攻击的策略之一是利用De-Pois（De-Pois: 一种针对数据中毒攻击的攻击无关防御：[https://arxiv.org/pdf/2105.03592.pdf](https://arxiv.org/pdf/2105.03592.pdf)），这是一个用于构建模仿模型的攻击无关防御框架。该框架使用**生成对抗网络**（**GANs**）来训练带有增强数据的模型，并创建在结果上与原始模型行为相似的模型。通过评估目标模型和模仿模型之间的预测差异，该模型可以检测中毒样本。'
- en: 'In addition to generating defensive awareness of the aforementioned possible
    intrusions, enterprise-grade defense frameworks should take into consideration
    some of the following aspects of security bottlenecks and take appropriate remedial
    measures:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 除了增强对上述可能入侵的防御意识外，企业级防御框架应考虑一些安全瓶颈的方面，并采取适当的补救措施：
- en: '**Establishing accounts**: In this phase, external adversaries engage themselves
    in creating accounts to build a persona across different social media platforms,
    such as LinkedIn, as well as on GitHub, to impersonate real people. These personas
    can be used to accumulate public information, set up email accounts, and strengthen
    public profiles, which will aid in stealing information over the course of time.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建立账户**：在这个阶段，外部对手通过在不同的社交媒体平台上（如LinkedIn）以及GitHub上创建账户来建立虚假身份，冒充真实人物。这些虚假身份可以用于积累公开信息、设置电子邮件账户和强化公开个人资料，进而在一段时间内帮助窃取信息。'
- en: The best tactic to protect against such actions is to identify any suspicious
    activity of individuals who claim to work for the organization or have made connection
    requests to different organizational accounts.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 防止此类行为的最佳策略是识别任何声称为组织工作或已向不同组织账户发送连接请求的可疑活动。
- en: '**Obtaining capabilities**: Here, adversaries rely on stealing, purchasing,
    or freely downloading malware, licensed software, exploits, certificates, and
    information related to vulnerabilities. Mitigation actions include the following:'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取能力**：在此阶段，对手依赖于窃取、购买或免费下载恶意软件、许可软件、漏洞利用、证书和与漏洞相关的信息。缓解措施包括以下几点：'
- en: Carefully analyze and detect features and services that are easy to embed and
    can be associated with malware providers (such as compilers, debugging artifacts,
    code extracts, or any other offerings related to **Malware as a** **Service**
    (**MaaS**)).
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仔细分析和检测易于嵌入且与恶意软件提供者（如编译器、调试文档、代码片段或任何其他与**恶意软件即服务**（**MaaS**）相关的产品）相关的特征和服务。
- en: Malware repository scanning and feature identification can help to blacklist
    adversaries.
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恶意软件仓库扫描和特征识别有助于将对手列入黑名单。
- en: Now, let's discuss a defense strategy involving the use of the open source secml
    library ([https://secml.github.io/class6/](https://secml.github.io/class6/), a
    security evaluation framework) to build, explain, attack, and evaluate security
    using algorithms such as **Support Vector Machine** (**SVM**) and ClassifierRidge
    (a custom ML Ridge classifier). These types of classification algorithms can be
    used to detect malware in Android applications and explain ML classifier model's
    predicted outcomes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一种防御策略，该策略使用开源secml库（[https://secml.github.io/class6/](https://secml.github.io/class6/)，一个安全评估框架）来构建、解释、攻击和评估安全性，使用的算法包括**支持向量机**（**SVM**）和ClassifierRidge（一个自定义的ML
    Ridge分类器）。这些类型的分类算法可用于检测安卓应用中的恶意软件，并解释ML分类器模型的预测结果。
- en: 'In the following code snippet, we have loaded a toy dataset of Android applications,
    named `DrebinRed`. The loaded dataset consists of 12,000 benign and 550 malicious
    samples extracted from Drebin. On training (using a 0.5:0.5 train-test split)
    the dataset with SVM or the Ridge classifier, we observe the model has a 2% **False
    Positive Rate** (**FPR**) in correctly identifying the benign and malicious samples:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码片段中，我们加载了一个名为`DrebinRed`的Android应用程序玩具数据集。加载的数据集包含12,000个良性样本和550个恶意样本，这些样本来自Drebin。通过使用SVM或岭回归分类器对数据集进行训练（采用0.5:0.5的训练-测试划分），我们观察到模型在正确识别良性和恶意样本时的**假阳性率**（**FPR**）为2%：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following output snippet further illustrates the most significant components
    of the Android malware detector application. secml uses a `Gradient * Input` gradient-based
    explanation technique to explain the attributions of different points during the
    classification phase. The most important features (the top 5) and their relevance
    (in terms of percentage) help to explain each correct (not a part of the malware
    component) and corrupted sample, and even this approach/technique to explain attributions
    on sparse datasets:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出片段进一步说明了Android恶意软件检测器应用程序中最重要的组件。secml使用`Gradient * Input`基于梯度的解释技术来解释分类阶段不同点的归因。最重要的特征（前五名）及其相关性（以百分比表示）有助于解释每个正确（非恶意软件组件）和被污染的样本，甚至这种方法/技术可用于解释稀疏数据集上的归因。
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As ~25% of the relevance is attributed to five features, these features have
    a larger impact on the classifier being susceptible to adversarial evasion attacks.
    Leveraging this behavior of the malware detector, a gradient-based maximum-confidence
    evasion attack can be employed to generate adversarial samples against the classifier.
    This can trigger an L1-order sparse attack by changing one feature at a time to
    misclassify outputs as 1 instead of 0 and vice versa. We can trigger attacks such
    as the one demonstrated in the following code snippet, where feature addition
    works better to fool the malware classifier than feature removal. Removing features
    may remove other important components of the model, making it more difficult to
    misclassify. On the contrary, feature addition is an easy way to fool the model
    into classifying correct (benign components of the loaded dataset) samples as
    corrupted.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大约25%的相关性归因于五个特征，这些特征对分类器易受对抗性规避攻击的影响更大。利用恶意软件检测器的这一行为，可以采用基于梯度的最大置信度规避攻击来生成对抗样本，攻击该分类器。这可以通过一次改变一个特征来触发L1阶稀疏攻击，将输出错误分类为1而不是0，反之亦然。我们可以触发类似于以下代码片段中展示的攻击，其中特征添加比特征移除更能欺骗恶意软件分类器。移除特征可能会删除模型的其他重要组件，使得错误分类更难实现。相反，特征添加是一个轻松的方式，可以让模型将正确的（数据集中的良性部分）样本错误分类为被污染样本。
- en: 'After adding the adversarial samples, we can trigger the evasion attack with
    `classifier`, `distance`, and other parameters, as shown here:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 添加对抗样本后，我们可以使用`classifier`、`distance`以及其他参数触发规避攻击，如下所示：
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: secml determines the model robustness using a `epsvalue` varying between 0 and
    28 with a step size of `4`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: secml通过使用`epsvalue`（在0到28之间变化，步长为`4`）来确定模型的鲁棒性。
- en: 'To test the Android malware detector against a greater number of added features,
    we can run the evasion attack on the security evaluation method, as detailed in
    the following code snippet:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试Android恶意软件检测器在更多新增特征下的表现，我们可以对安全评估方法进行规避攻击，具体代码如下：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, let''s plot the SEC:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制SEC：
- en: 'The following code begins the process of getting the SEC:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码开始获取SEC的过程：
- en: '[PRE4]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, get the ROC threshold at which the detection rate should be computed:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，获取应计算检测率的ROC阈值：
- en: '[PRE5]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, use the convenience function to plot the SEC:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用方便的函数来绘制SEC：
- en: '[PRE6]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see how the SVM classifier is highly vulnerable to adversarial attacks,
    and particularly sensitive to attacks against the most impactful features. An
    attack can evade this classifier with a perturbation as small as eps (ε) = 0.1\.
    When we change it to have fewer than 10 features (which are the most important
    ones), half of the corrupted samples are misclassified as correct ones.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，SVM分类器对对抗性攻击非常脆弱，尤其是对攻击最具影响力的特征特别敏感。攻击可以通过一个像eps（ε）= 0.1这么小的扰动来规避该分类器。当我们将特征数减少到少于10个（这些是最重要的特征）时，半数的被污染样本被错误分类为正确样本。
- en: In the following figure, *Figure 2**.2*, the chart labeled **A** shows a detection
    rate of 97% with an FPRof 20\. While the detection rate falls with increasing
    epsilon (ε), we observe that the fall is very steep for the Ridge classifier (**C**),
    while it happens in a step fashion for SVM (**B**). As the fall is steeper for
    the Ridge classifier, it is not a better option than SVM, which will exhibit a
    lower FPR. Make sure to examine the **SECs** in the following graphs, which provide
    estimations of the detection rate (%) with ε. The SEC plots help us to conclude
    that the malware detector ceases to perform with increasing levels of adversarial
    perturbations.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，*图 2.2*，标记为**A**的图表显示了97%的检测率和20的FPR。当ε增大时，检测率会下降；然而，我们观察到，Ridge分类器（**C**）的下降非常陡峭，而SVM（**B**）则呈阶梯式下降。由于Ridge分类器的下降更陡峭，它并不是比SVM更好的选择，后者将表现出更低的FPR。请确保查看下图中的**SECs**，它们提供了随ε变化的检测率（%）的估算值。SEC图帮助我们得出结论，即随着对抗性扰动的增加，恶意软件检测器的表现停止。
- en: "![Figure 2.2 – Malware detection rate and SEC on SVM and \uFEFFthe Ridge classifier](img/Figure_2.02_B18681.jpg)"
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – SVM和Ridge分类器上的恶意软件检测率和SEC](img/Figure_2.02_B18681.jpg)'
- en: Figure 2.2 – Malware detection rate and SEC on SVM and the Ridge classifier
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – SVM和Ridge分类器上的恶意软件检测率和SEC
- en: '**Staging** refers to actions taken by adversaries to upload, install, and
    set up capabilities on infrastructures that were previously compromised or rented
    by them, to target victim networks. Such activities might include setting up web
    resources to exploit the victim’s browsing website (to steal confidential information)
    or uploading malware tools to initiate attacks on the victim’s network. There’s
    no prompt detection technique to avoid this; however, internet scanning tools
    may reveal the date and time of such attacks.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**阶段化**是指对手在之前被攻陷或租用的基础设施上进行上传、安装和设置功能，以便针对受害者网络进行攻击。这些活动可能包括设置网页资源以利用受害者的浏览网站（窃取机密信息）或上传恶意软件工具以启动对受害者网络的攻击。没有有效的检测技术可以避免这种情况；然而，互联网扫描工具可能会揭示这些攻击的日期和时间。'
- en: Initial access
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始访问
- en: Initial access helps an adversary to leverage security weaknesses on public-facing
    web servers and gain access to a network. This can occur in one of the early stages
    of development when the model design and the system architecture are still in
    the development phase. The primary steps to mitigate initial adversarial access
    include controlling the abuse of credentials via proper management of user account
    control, issuing valid accounts, enforcing privileged account management practices,
    defining organization password policies (such as the frequency of password changes),
    and having in place a systematic user training process and application developer
    guidance to restrict any illegitimate access to systems.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 初始访问帮助对手利用公共面向的网络服务器上的安全漏洞并获得对网络的访问权限。这可能发生在开发的早期阶段，当模型设计和系统架构仍处于开发阶段时。减轻初始对抗访问的主要步骤包括通过适当的用户账户管理控制凭证滥用，发放有效账户，执行特权账户管理实践，定义组织密码策略（例如密码更改的频率），并建立系统化的用户培训流程和应用开发者指导，以限制任何不正当的系统访问。
- en: 'Let''s now explore the different actions that can be taken by adversaries if
    they are successful in acquiring initial access:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来探讨一下，如果对手成功获得初始访问，他们可能采取的不同行动：
- en: '**Supply chain compromise**: In this step, adversaries compromise different
    components of a victim’s system (such as GPU hardware, data and its annotations,
    parts of the ML software stack, or the model) to carry out an attack. The attacker
    manipulates development tools, environments, code repositories, open source dependencies,
    and software update/distribution mechanisms; compromises system images; and replaces
    legitimate software (using different versions) to successfully compromise the
    victim’s systems. Organizations should mitigate tampering activities by employing
    techniques to verify distributed binaries (hash checking), along with using tools
    to scan malicious signatures and engaging in physical hardware inspection. Even
    using patch management processes and vulnerability scanning tools to scan dependencies,
    unnecessary features, components, and files can help prevent adversarial access
    by enforcing strong testing rules prior to deployment.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应链妥协**：在这一步骤中，攻击者会妥协受害者系统的不同组件（如GPU硬件、数据及其注释、机器学习软件栈的部分内容或模型），以进行攻击。攻击者操控开发工具、环境、代码库、开源依赖项和软件更新/分发机制；妥协系统镜像；并通过替换合法软件（使用不同版本）来成功妥协受害者的系统。组织应通过使用技术验证分发的二进制文件（哈希检查），结合使用扫描恶意签名的工具，并进行硬件实物检查来减少篡改活动。即使使用补丁管理流程和漏洞扫描工具扫描依赖项、不必要的功能、组件和文件，也有助于通过在部署前执行严格的测试规则来防止攻击者的访问。'
- en: '**Drive-by compromise**: This involves the exploitation of the victim’s browser
    (where the adversary may inject malicious code with JavaScript, iFrames, and cross-site
    scripting, or help to serve malicious ads) and application access tokens, and
    can be mitigated by doing the following:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**驱动式妥协**：这涉及到攻击受害者的浏览器（攻击者可能通过JavaScript、iFrames和跨站脚本注入恶意代码，或者协助投放恶意广告）和应用程序访问令牌，这可以通过以下方式减轻：'
- en: Using browser sandboxes, deploying virtualization measures, and applying micro-segmentation
    logic. We can limit attacks by isolating applications and web browsers by creating
    and defining zones in data centers and cloud environments (to isolate workloads).
    This is one of the strongest ways to limit network traffic and client-side exploitation.
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用浏览器沙箱、部署虚拟化措施以及应用微分段逻辑。我们可以通过在数据中心和云环境中创建和定义区域来隔离应用程序和网页浏览器（以隔离工作负载），从而限制攻击。这是限制网络流量和客户端利用的最有效方法之一。
- en: Employing defense tools such as **Enhanced Mitigation Experience Toolkit** (**EMET**),
    network intrusion detectors with SSL/TLS inspection, firewalls, proxies, ad blockers,
    and script-blocking extensions can help to control exploitation behavior, block
    bad domains and ads, and prevent the execution of JavaScript.
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**增强型缓解体验工具**（**EMET**）、具有SSL/TLS检测功能的网络入侵检测器、防火墙、代理服务器、广告拦截器以及脚本阻止扩展可以帮助控制利用行为，阻止恶意域名和广告，并防止JavaScript的执行。
- en: '**Exploit public-facing applications**: As this technique involves adversaries
    accessing, exploiting, and bringing down public-facing services such as databases,
    **Server Message Block** (**SMB**), and other applications with open sockets,
    the main remediation tasks lie with the security architects in designing and deploying
    application in isolation and sandboxing (limiting exploited targets’ access to
    other processes), web application firewalls, network segmentation (segmenting
    public interfaces on a demilitarized zone or a separate hosting infrastructure),
    and privileged account management (adhering to the principle of least privilege
    for accessing services) to limit attack traffic. In addition, regular software
    updates, patch management, vulnerability scanning tools, and application log and
    network flow monitoring tools (using deep packet inspection to discover artifacts
    of malicious traffic, such as SQL injection) can be used to detect improper input
    traffic and raise alerts.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用面向公众的应用程序**：由于这种技术涉及攻击者访问、利用并破坏面向公众的服务，如数据库、**服务器消息块**（**SMB**）以及其他具有开放套接字的应用程序，主要的修复任务在于安全架构师在设计和部署应用程序时进行隔离和沙箱化（限制被利用目标对其他进程的访问）、应用程序防火墙、网络分段（将公共接口分段到非军事区或单独的托管基础设施中）以及特权账户管理（遵循最小特权原则来访问服务），以限制攻击流量。此外，定期进行软件更新、补丁管理、漏洞扫描工具、应用程序日志和网络流量监控工具（使用深度数据包检查来发现恶意流量的痕迹，如SQL注入）可以用于检测不当的输入流量并发出警报。'
- en: '**External remote services**: This method involves adversaries discovering
    external-facing remote services, such as VPNs or Citrix, and finding routes to
    connect to internal enterprise network resources from these external locations.
    To alleviate such risks, security teams should be extra cautious:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部远程服务**：这种方法涉及对手发现面向外部的远程服务，如 VPN 或 Citrix，并找到从这些外部位置连接到内部企业网络资源的路径。为了减少这种风险，安全团队应格外小心：'
- en: Disable or block unnecessary remotely available services, limit access to resources
    over the network (by prompting the use of managed remote access systems such as
    VPNs), enable multi-factor authentication, and allow network segmentation (through
    the use of network proxies, gateways, and firewalls).
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用或阻止不必要的远程可用服务，限制通过网络访问资源（通过提示使用受管的远程访问系统，如 VPN），启用多因素认证，并允许网络分段（通过使用网络代理、网关和防火墙）。
- en: Facilitate log monitoring related to applications, session logons, and network
    traffic to detect authenticated sessions, discover unusual access patterns and
    times of operation, and assist in detecting adversarial behavior.
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进与应用程序、会话登录和网络流量相关的日志监控，以检测已认证会话，发现异常的访问模式和操作时间，并帮助检测对抗行为。
- en: '**Hardware additions**: Introducing additional computer accessories or hardware
    components in the network can permit adversaries to undertake passive network
    tapping, network traffic modification through adversary/man-in-the-middle attacks,
    keystroke injection, or kernel memory reading via **Direct Memory Access** (**DMA**).
    To avoid this, asset management systems should be used to do the following:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件添加**：在网络中引入额外的计算机配件或硬件组件，可能使对手进行被动网络监听、通过对抗者/中间人攻击修改网络流量、键盘注入或通过 **直接内存访问**
    (**DMA**) 读取内核内存。为了避免这种情况，应使用资产管理系统执行以下操作：'
- en: Limit access to resources over the network, limit installation of hardware,
    and employ hardware detectors or endpoint sensors to discover additions of USB,
    Thunderbolt, and other external device communication ports in the network.
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制通过网络访问资源，限制硬件安装，并使用硬件检测器或终端传感器来发现 USB、Thunderbolt 及其他外部设备通信端口在网络中的增加。
- en: Further, to safeguard adversarial copying operations on removable media, organization
    policies should forbid or restrict removable media.
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，为了保护对抗性复制操作在可移动介质上的行为，组织政策应禁止或限制可移动介质的使用。
- en: ML model access
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML 模型访问
- en: 'Adversaries may gain access to an ML model legitimately through four different
    techniques that we’ll examine in this section. The best mitigation strategy is
    to include sufficient security rules (cloud- and token-based authorization schemes)
    to enable authentic access to model APIs, ML services, physical environments,
    and ML models, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对手可能通过四种不同的技术合法地访问 ML 模型，我们将在本节中进行讨论。最好的缓解策略是包含足够的安全规则（基于云和令牌的授权方案），以便对模型 API、ML
    服务、物理环境和 ML 模型进行有效的访问授权，如下所述：
- en: '**Model inference API access**: This involves restricting adversary access
    through the use of APIs to discover the ML model''s ontology or family. The corresponding
    defense action is to limit the introduction of test data into the target systems
    by single agents to prevent issues related to evading ML models and eroding ML
    model integrity. As we saw in [*Chapter 1*](B18681_01.xhtml#_idTextAnchor014),
    there is a possibility of an evasion attack where attackers try to evade detection
    by hiding the content of spam and malware code. The same kind of attack is possible
    by using model inference APIs to misclassify examples (individual data samples)
    as legitimate.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型推理 API 访问**：这涉及通过使用 API 限制对手访问，以发现 ML 模型的本体或类型。相应的防御措施是通过单一代理限制测试数据的引入，以防止与逃避
    ML 模型和破坏 ML 模型完整性相关的问题。正如我们在 [*第一章*](B18681_01.xhtml#_idTextAnchor014) 中所看到的，存在一种逃避攻击的可能性，攻击者通过隐藏垃圾邮件和恶意软件代码的内容来逃避检测。通过使用模型推理
    API，也可以进行类似的攻击，将示例（单个数据样本）错误分类为合法的。'
- en: '**ML-enabled product or service limit**: This method limits indirect access
    to ML models to hide information related to the model’s inference from its logs
    and metadata. Indirect access can originate from any product or service built
    by adversaries to gain access to the victim’s ML model.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ML 启用的产品或服务限制**：这种方法限制间接访问 ML 模型，从而隐藏与模型推理相关的信息，如日志和元数据。间接访问可能来自任何由对手构建的产品或服务，用以访问受害者的
    ML 模型。'
- en: '**Physical environment access**: To eliminate the scope of adversarial attacks
    in data engineering pipelines, enable data validation checks across multiple layers
    of input data ingestion, preprocessing, and feature engineering.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物理环境访问**：为了消除数据工程管道中的对抗攻击范围，需要在多个层级的数据输入、预处理和特征工程中启用数据验证检查。'
- en: '**Full ML model access**: To prevent the adversary from gaining full access
    to the model, the best possible defense strategy is to incorporate privacy-preserving
    ML techniques for data aggregation and training to enable protection from adversarial
    white-box attacks. Otherwise, these attacks allow the adversary to gain complete
    information on the model''s architecture, parameters, and class ontology and exfiltrate
    the model to execute offline attacks once the model is running live with production
    data.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全的机器学习模型访问**：为了防止对手获得模型的完全访问权限，最佳的防御策略是结合隐私保护的机器学习技术进行数据聚合和训练，从而提供对抗白盒攻击的保护。否则，这些攻击使得对手能够完全掌握模型的架构、参数和类别本体，并在模型运行并使用生产数据时将模型外泄，进而执行离线攻击。'
- en: 'One of the preferred mechanisms for defending against white-box (model parameters)
    and black-box (output predictions) attacks is to train the model and evaluate
    the accuracy of the attacks. If we use **ML Privacy Meter** (a Python library
    that helps to quantify risk in ML models) prior to releasing models, we can test
    the models by initiating attacks and determine the model’s tendency to leak information.
    This helps us to act as adversaries and detect whether each data instance actually
    belongs to the required dataset. Training the model against such attacks can be
    accomplished in two ways:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 防御白盒（模型参数）和黑盒（输出预测）攻击的首选机制之一是训练模型并评估攻击的准确性。如果我们在发布模型之前使用**ML Privacy Meter**（一个帮助量化机器学习模型风险的
    Python 库），我们可以通过发起攻击来测试模型，并确定模型泄露信息的倾向。这有助于我们作为对手，检测每个数据实例是否确实属于所需数据集。对抗此类攻击的模型训练可以通过两种方式完成：
- en: '**White box**: By observing the model’s parameters when the model is deployed
    in an untrusted cloud or takes part as one of the participating models in a **Federated
    Learning** (**FL**) setup'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白盒**：通过观察模型的参数，当模型被部署在不受信任的云环境中或作为**联邦学习**（**FL**）设置中的参与模型之一时'
- en: '**Black box**: By fetching the model’s predictions from the output'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒**：通过从输出中获取模型的预测'
- en: During model training and evaluation, the attack accuracy is evaluated on a
    validation/test set. Moreover, the accuracy is only considered on the best-performing
    attack model of all attack models. In *Figure 2**.3*, we can see three plots that
    illustrate the probabilities (in the range of 0 to 1) of responses that actually
    respond to an attack based on membership status.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练和评估过程中，攻击的准确性在验证/测试集上进行评估。此外，只有在所有攻击模型中表现最佳的攻击模型上，准确性才被考虑。在*图 2.3*中，我们可以看到三张图表，展示了基于成员身份状态实际响应攻击的概率（范围为
    0 到 1）。
- en: '![Figure 2.3 – Overall privacy risk (left) and privacy risk for classes 24
    and 35 (center and right)](img/Figure_2.03_B18681.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3 – 整体隐私风险（左）和类 24 和 35 的隐私风险（中间和右）](img/Figure_2.03_B18681.jpg)'
- en: Figure 2.3 – Overall privacy risk (left) and privacy risk for classes 24 and
    35 (center and right)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 整体隐私风险（左）和类 24 和 35 的隐私风险（中间和右）
- en: 'With the following code, we are able to detect the trade-off between the model’s
    achieved accuracy (correct identification of members in the training dataset)
    and error (incorrect identification or false positives). The following code snippets
    show how to invoke attack models and verify the probability of each member getting
    discovered through an adversarial attack:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，我们能够检测模型实现的准确性（正确识别训练数据集中的成员）与错误（错误识别或假阳性）之间的权衡。以下代码片段展示了如何调用攻击模型并验证每个成员通过对抗攻击被发现的概率：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The method for starting the attack is shown as follows, where the first two
    parameters specify the target training model and target attack model, the third
    and fourth parameters denote the training and attack datasets, while the remaining
    parameters are used to specify layers, gradients, model name, and more:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 发起攻击的方法如下所示，其中前两个参数指定目标训练模型和目标攻击模型，第三和第四个参数表示训练数据集和攻击数据集，而其余的参数用于指定层、梯度、模型名称等：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In addition, we are also able to see the privacy risk histograms for each output
    class. While the first histogram shows that there is an increase in risk at every
    step for training data members, the privacy risk for class 24 is more uniformly
    distributed between 0.4 and 1.0\. On the other hand, the privacy risk for class
    35 is more skewed between 0.85 and 1.0 for most of the training members. The overall
    privacy risk histogram is an average aggregation of all privacy risk classes.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以看到每个输出类别的隐私风险直方图。第一个直方图显示，训练数据成员在每一步的风险都有所增加，而类别24的隐私风险在0.4到1.0之间分布得较为均匀。另一方面，类别35的隐私风险在大多数训练成员中更多地集中在0.85到1.0之间。整体隐私风险直方图是所有隐私风险类别的平均聚合。
- en: Model training and development
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练与开发
- en: This phase, as shown in *Figure 2**.4*, pertains to all actions during model
    training and deployment where the adversary has started to extract model and system
    parameters and constraints to their advantage, evading defense frameworks in the
    target environment and preparing the ground for continued attacks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图2.4*所示，本阶段涉及模型训练和部署过程中的所有操作，在此过程中，攻击者开始提取模型和系统参数及约束，利用这些参数逃避目标环境中的防御框架，并为持续攻击做好准备。
- en: '![Figure 2.4 – Different attack stages during model training and deployment](img/Figure_2.04_B18681.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 – 模型训练和部署过程中不同的攻击阶段](img/Figure_2.04_B18681.jpg)'
- en: Figure 2.4 – Different attack stages during model training and deployment
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 模型训练和部署过程中不同的攻击阶段
- en: Execution
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行
- en: Different command and script interpreters can be used by adversaries to execute
    commands, scripts, or binaries by embedding them as payloads to mislead and lure
    victims. Container administration commands and container deployments (with or
    without remote execution) can help adversaries to execute commands within a container
    and facilitate container deployment in an environment to evade defenses. Adversaries
    can also be prompted to schedule jobs for the recurrent execution of malicious
    code or force users to undertake specific actions (for example, opening a malicious
    file) to execute malicious code.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的命令和脚本解释器可以被对手用来执行命令、脚本或二进制文件，将其嵌入为有效载荷以误导和诱捕受害者。容器管理命令和容器部署（无论是否具有远程执行功能）可以帮助对手在容器内执行命令，并促进容器在环境中的部署，从而规避防御措施。对手还可以被诱使安排任务，定期执行恶意代码，或强迫用户执行特定操作（例如，打开恶意文件）来执行恶意代码。
- en: Execution can be accomplished in the following ways.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 执行可以通过以下方式完成。
- en: '**User execution – unsafe ML artifacts**: Adversaries may develop unsafe ML
    artifacts (without adhering to serialization principles) that can enable them
    to gain access and execute harmful artifacts.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户执行 – 不安全的机器学习工件**：对手可能会开发不安全的机器学习工件（未遵循序列化原则），这将使他们能够获取访问权限并执行有害工件。'
- en: '**Exploitation for client execution**: Adversaries may exploit vulnerabilities
    in client software by leveraging browser-based exploitations, inter-process communication,
    system services, and native APIs (and their hierarchy of interfaces) in their
    favor to enforce the execution of malicious content.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端执行的利用**：对手可能会通过利用浏览器漏洞、进程间通信、系统服务和本地API（及其接口层次结构），在客户端软件中利用漏洞，强制执行恶意内容。'
- en: '**Software deployment tools**: After gaining access to an enterprise’s third-party
    software, it becomes easier for adversaries to gain access to and wipe information
    from hard drives at all endpoints.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件部署工具**：在获得企业第三方软件的访问权限后，攻击者可以更轻松地访问并擦除所有端点硬盘上的信息。'
- en: 'In addition to the commonly used defense mechanisms that we examined in the
    first phase, defense strategies should focus on enforcing limits on harmful operations
    such as the following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们在第一阶段中检查的常用防御机制外，防御策略应侧重于对有害操作进行限制，例如以下几种：
- en: Limiting access to resources over the network (enabling authenticated local
    and secure port access to aid communication with APIs over TLS), privileged account
    management (not allowing containers or services to run as root), behavior prevention
    on endpoints, execution prevention (by using application control logic and tools
    such as Windows Defender Application Control and AppLocker, or software restriction
    policies), code signing, application isolation, and sandboxing.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制通过网络访问资源（启用身份验证的本地和安全端口访问，以帮助通过TLS与API进行通信），特权账户管理（不允许容器或服务以root身份运行），终端行为防止，执行防止（使用应用控制逻辑和工具，如Windows
    Defender应用控制和AppLocker，或软件限制策略），代码签名，应用隔离和沙箱化。
- en: When adopting system-level security measures, DevOps and security teams should
    wisely use and manage the operating system's configuration management (forcing
    scheduled tasks to run under authenticated accounts instead of allowing them to
    run under system services).
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在采取系统级安全措施时，DevOps和安全团队应明智地使用和管理操作系统的配置管理（强制计划任务以认证账户身份运行，而不是允许它们以系统服务身份运行）。
- en: Active Directory configuration to reinforce Group Policy enforcement to isolate
    and limit access to critical network elements.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Active Directory，以加强组策略执行，隔离并限制对关键网络元素的访问。
- en: To further curb execution operations practiced by adversaries, the following
    persistence actions should be enforced by system administrators to prevent unwanted
    intrusion.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步遏制对手的执行操作，系统管理员应强制实施以下持久化措施，以防止不必要的入侵。
- en: Persistence
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持久化
- en: 'Here is a list of the actions to prevent intrusion:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是防止入侵的操作列表：
- en: Preventing the execution of code that has not been downloaded from legitimate
    repositories (which means ensuring only non-vulnerable applications are allowed
    to have `setuid` and `setgid` bits set)
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止执行未从合法存储库下载的代码（这意味着确保只有没有漏洞的应用程序允许设置`setuid`和`setgid`位）
- en: Privileged account management (don't allow users to be unnecessarily added to
    the admin group)
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特权账户管理（不要允许用户不必要地加入管理员组）
- en: Restricting file and directory permissions
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制文件和目录权限
- en: Restricting library loading through permissions and audits
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过权限和审计限制库加载
- en: User account control (using the highest enforcement level, leaving no room for
    bypassing access control)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户账户控制（使用最高强制级别，消除绕过访问控制的可能性）
- en: Defense evasion
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 防御规避
- en: Defense evasion comprises all operations used by adversaries that enable them
    to evade detection and the existing security controls. Adversaries are powerful
    enough to break through the victim’s systems with the untrusted activities listed
    in *the* *following table:*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 防御规避包含对手用来逃避检测和现有安全控制的所有操作。对手足够强大，能够通过受害者系统突破并执行下表中列出的不受信任的活动：
- en: '| **Item** **No.** | **Mode of** **Defense Evasion** |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **项目** **编号** | **防御规避方式** |'
- en: '| --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | Uninstall/disable security software; elevate privilege rights; evade
    virtualizations/sandboxes; hide the presence of programs, files, network connections,
    services, and drivers; execute malicious code; practice reflective code loading
    into a process to conceal the execution of malicious payloads; obfuscate and encrypt
    code/data (use XSL files to embed scripts). |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 卸载/禁用安全软件；提升特权权限；规避虚拟化/沙箱；隐藏程序、文件、网络连接、服务和驱动程序的存在；执行恶意代码；将反射代码加载到进程中以掩盖恶意载荷的执行；模糊和加密代码/数据（使用XSL文件嵌入脚本）。
    |'
- en: '| 2 | Trusted processes can work in the adversaries’ favor to help them hide,
    conceal their malware, and manipulate feature artifacts in such a manner that
    they appear to be legitimate actions. Bypass and impair existing signature-based
    defenses by either running proxying execution of malicious code or deploying a
    new container image that has malware without any security, firewalls, network
    rules, access controls, or user limitations. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 受信任的进程可以帮助对手隐藏、掩盖恶意软件，并以使其看起来是合法操作的方式操纵特征伪影。通过运行恶意代码的代理执行或部署没有任何安全、火墙、网络规则、访问控制或用户限制的新容器镜像来绕过并削弱现有基于签名的防御。
    |'
- en: '| 3 | Carry out process or template injection; execute scripts to hijack code
    flow; modify authentication processes, cloud compute infrastructure, registries,
    system images, file and directory permissions, network boundary bridging (taking
    control of network boundary devices and allowing the passage of prohibited traffic),
    and Active Directory data (including credentials and keys) in the target environment.
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 执行进程或模板注入；执行脚本劫持代码流；修改身份验证过程、云计算基础设施、注册表、系统镜像、文件和目录权限、网络边界桥接（控制网络边界设备并允许禁止的流量通过），以及目标环境中的Active
    Directory数据（包括凭证和密钥）。 |'
- en: Table 2.1 – Different modes of ML model defense evasion
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.1 – 不同的机器学习模型防御规避模式
- en: 'As defense evasion relies on the abuse of system failures, stringent security
    measures should be put in place to close all loopholes. Most of the defensive
    tactics described previously apply here. In addition, prevention techniques that
    need greater attention are the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于防御规避依赖于系统故障的滥用，应采取严格的安全措施以堵塞所有漏洞。前述的大多数防御策略在此适用。此外，需要特别关注的预防技术包括以下内容：
- en: Deploying network monitoring tools to filter network traffic.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署网络监控工具以过滤网络流量。
- en: Deploying antivirus and antimalware detectors for monitoring.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署防病毒和反恶意软件检测器进行监控。
- en: Employing endpoint behavioral anomaly detection techniques to stop the retrieval
    and execution of malicious payloads.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用端点行为异常检测技术来阻止恶意载荷的获取和执行。
- en: Operating systems should be configured such that administrator accounts are
    not enumerated and do not reveal account names.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统应配置为不枚举管理员账户并不泄露账户名。
- en: When not in use, active macros and content should be removed from programs to
    mitigate risks arising from the execution of malicious payloads.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不使用时，应从程序中删除活动宏和内容，以减轻因执行恶意载荷而引发的风险。
- en: Unnecessary scripts should be blocked, passwords should be encrypted, and boot
    images of network devices should always be cryptographically signed.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应阻止不必要的脚本，密码应加密，网络设备的启动镜像应始终进行加密签名。
- en: Discovery
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现
- en: The discovery phase helps adversaries gain knowledge of the victim’s account,
    operating system, and configuration (as listed in *Table 2.2*) for systematic
    planning prior to invading the victim’s systems.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 发现阶段帮助对手了解受害者的账户、操作系统和配置（如*表 2.2*所列）以进行系统性规划，进而入侵受害者的系统。
- en: '| **Item No.** | **Discovery Mechanisms** |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| **项目编号** | **发现机制** |'
- en: '| --- | --- |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | Browser data (for information related to banking sites, interests, and
    social media), a list of open application windows, network information (configuration
    settings, such as IP and/or MAC addresses), programs, and services (peripheral
    devices, remote programs, and file folders) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 浏览器数据（与银行网站、兴趣和社交媒体相关的信息），打开的应用程序窗口列表，网络信息（配置设置，如IP和/或MAC地址）、程序和服务（外围设备、远程程序和文件夹）
    |'
- en: '| 2 | System (location, time, and owner), cloud infrastructure (instances,
    virtual machines, and snapshots, as well as storage and database services), dashboards,
    orchestration/container services, domain trust relationships, Group Policy settings
    (identifying paths for privilege escalation), and other information related to
    connection entry points |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 系统（位置、时间和所有者）、云基础设施（实例、虚拟机和快照，以及存储和数据库服务）、仪表板、编排/容器服务、域信任关系、组策略设置（识别特权升级路径），以及与连接入口点相关的其他信息
    |'
- en: '| 3 | Quickly altering the malware and disengaging from the victim’s system
    to hide the core functions of the implant |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 快速改变恶意软件并与受害者的系统断开连接，以隐藏植入物的核心功能 |'
- en: Table 2.2 – Different discovery mechanisms
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.2 – 不同的发现机制
- en: 'Due to adversarial pre-planning, the foremost defense steps include the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对手的预先规划，最初的防御步骤包括以下内容：
- en: Enable monitoring of all events together, without viewing any suspicious action
    in isolation. Sequential information discovery and collection are part of a larger
    attack plan, such as lateral data movement or data corruption.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用对所有事件的监控，避免将任何可疑行为单独查看。顺序的信息发现和收集是更大攻击计划的一部分，如横向数据移动或数据破坏。
- en: Discovery and proof collection (using screenshots and keyboard inputs), which
    could help in the process of reconciliation to justify acts of data stealing.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现和证据收集（使用屏幕截图和键盘输入），这有助于在数据窃取行为中进行调解以证明行为的正当性。
- en: Collection
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集
- en: After the discovery of data sources, an adversary will be enthusiastic to collect
    and steal (exfiltrate) confidential sensitive information either manually or through
    automated means. Common target sources include various drive types, removable
    media, browser sessions, audio, video, emails, cloud storage, and configuration.
    Other sources of information include repositories, local systems, network shared
    drives, screenshots, audio/video captures, and keyboard input.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在发现数据源之后，攻击者将热衷于手动或通过自动化手段收集和窃取（外泄）机密敏感信息。常见的目标来源包括各种驱动器类型、可移动介质、浏览器会话、音频、视频、电子邮件、云存储和配置。其他信息来源还包括代码库、本地系统、网络共享驱动器、截图、音视频捕获和键盘输入。
- en: ML model live in production
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习模型在生产环境中的应用
- en: This phase shown in *Figure 2**.5* relates to attacks performed on ML models
    and ML SaaS platforms at scale. Here, the adversary is fully equipped with full
    system-level information, data, and proxy models that are essential for them to
    execute attacks and impact the victim’s business operations.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 2.5*所示，这一阶段涉及对机器学习模型和机器学习SaaS平台的大规模攻击。在这里，攻击者完全掌握系统级信息、数据和代理模型，这些对执行攻击并影响受害者的业务操作至关重要。
- en: "![Figure 2.\uFEFF5 – Different attack stages when ML models are live in production](img/Figure_2.05_B18681.jpg)"
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – 当机器学习模型在生产环境中运行时的不同攻击阶段](img/Figure_2.05_B18681.jpg)'
- en: Figure 2.5 – Different attack stages when ML models are live in production
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 当机器学习模型在生产环境中运行时的不同攻击阶段
- en: This phase involves the manipulation, interruption, or destruction of data by
    adversaries to compromise system integrity and disrupt business operations. Attacks
    can range from data tampering activities to techniques involving crafting adversarial
    data, to restrict ML models from yielding the right predicted results.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段涉及攻击者操控、干扰或破坏数据，以破坏系统完整性并扰乱业务操作。攻击可以从数据篡改活动到涉及制造对抗性数据的技术，以限制机器学习模型无法提供正确预测结果。
- en: Staging ML model attacks
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 策划机器学习（ML）模型攻击
- en: 'Once the discovery and collection phases are over, the adversary leverages
    their new knowledge to plan and attack the system intelligently (online or offline)
    by training proxy models and triggering poisoned attacks by injecting adversarial
    inputs into target models. Target models act as important resources in staging
    attack operations:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发现和收集阶段完成，攻击者利用他们的新知识，通过训练代理模型并通过向目标模型注入对抗性输入来触发毒化攻击，从而智能地计划并攻击系统（在线或离线）。目标模型作为策划攻击操作的重要资源：
- en: '**Collecting ML artifacts**: Once the adversary has successfully gathered information
    on the ML artifacts that exist on the network, they may exfiltrate them for immediate
    use in staging an ML attack. To mitigate risks involving the collection of model
    artifacts, note the following:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集机器学习工件**：一旦攻击者成功收集了网络中存在的机器学习工件信息，他们可能会将其导出，以便立即在策划机器学习攻击时使用。为了减少与收集模型工件相关的风险，请注意以下事项：'
- en: The ML model training methodology should encompass all privacy-preserving techniques.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型训练方法应包括所有隐私保护技术。
- en: In addition, all ACL rules (of related microservices) and encryption logic should
    frequently be audited and revisited.
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，所有访问控制列表（ACL）规则（与相关微服务的ACL规则）和加密逻辑应定期审核和重新审视。
- en: '**Training proxy ML models**: Adversaries often train ML models to create proxy
    models and trigger attacks on the target models in a simulated manner. This offline
    simulation helps them to gain information from target models and validate and
    initiate attacks without any need for higher-level access rights or privileges.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练代理机器学习模型**：攻击者通常训练机器学习模型来创建代理模型，并以模拟的方式触发对目标模型的攻击。这种离线模拟帮助他们从目标模型中获取信息，并在没有更高级别访问权限或特权的情况下验证并发起攻击。'
- en: '**Replicating ML models**: Here, an adversary replicates the target model as
    a separate private model, where the target model’s inferences are recorded as
    labels for training the offline private version of the model. This kind of operation
    involves repeated queries to the victim’s model inference APIs. To throttle repeated
    requests from the same IP, defenders can use rate limiting and blacklist source
    IPs to limit such queries and consequently the number of inferences extracted.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复制机器学习模型**：在这一过程中，攻击者将目标模型复制为一个单独的私有模型，并将目标模型的推理结果记录为标签，用于训练离线私有版本的模型。这种操作涉及对受害者模型推理API的重复查询。为了限制来自同一IP的重复请求，防御者可以使用速率限制并将源IP列入黑名单，从而限制此类查询以及随之而来的推理次数。'
- en: '**Poisoning ML models**: Adversaries can generate poisoned models from the
    previous steps by injecting poisoned data for training or carefully retrieving
    the model inferences. In fact, poisoned models are a persistent artifact at the
    victim’s end that the adversary can use to their advantage to insert and trigger
    backdoor triggers with completely random patterns and locations to evade backdoor
    defense mechanisms, making it difficult for monitoring tools to detect issues
    and raise alerts.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**毒化ML模型**：对手可以通过注入毒化数据进行训练或仔细检索模型推理，从前述步骤中生成毒化模型。事实上，毒化模型是受害者端的持久性产物，对手可以利用这一点插入并触发具有完全随机模式和位置的后门触发器，规避后门防御机制，使监控工具难以检测问题并发出警报。'
- en: 'One mechanism of defense against poison attacks is to use spectral signatures
    ([https://proceedings.neurips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf](https://proceedings.neurips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf)),
    which should detect the deviations in average value created by the minority sub-population
    of poisoned inputs. This algorithm depends on the fact that the means of two sub-populations
    are fairly different in comparison to the overall variance of the populations,
    owing to the fact these two sub-populations show either the presence or absence
    of correctly labeled samples or corrupted samples. In such a scenario, one population
    sub-group containing mislabeled corrupted inputs can be identified using `SpectralSignature`
    defense employed on a Keras classifier, which returns a report (a dictionary containing
    an index of keys and values as the outlier score of suspected poisons) and `is_clean_lst`,
    denoting whether each data point in the training data is clean or poisoned:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 防御毒化攻击的一种机制是使用光谱特征（[https://proceedings.neurips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf](https://proceedings.neurips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf)），它应该能够检测由少数毒化输入子群体所造成的平均值偏差。该算法依赖于这样一个事实：两个子群体的均值与总体方差相比非常不同，因为这两个子群体展示了是否存在正确标记的样本或被破坏的样本。在这种情况下，可以使用`SpectralSignature`防御方法对Keras分类器进行应用，来识别一个包含错误标记的破坏性输入的子群体，它会返回一份报告（包含键值对索引的字典，作为怀疑毒化样本的异常得分）以及`is_clean_lst`，表示训练数据中的每个数据点是否为干净数据或毒化数据：
- en: '[PRE9]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Verifying attack**: This action helps an adversary to plan, prepare, and
    verify planned attacks based on the suitability of the time chosen and the availability
    of the victim’s physical or virtual environments. Mitigation strategies against
    this type of attack are difficult to implement as adversaries can leverage inference
    APIs with limited queries or create offline versions of the victim’s target model.
    This leads to increased API billing costs for the victim, as API costs are directly
    borne by them.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证攻击**：此行为帮助对手根据选择的时机和受害者物理或虚拟环境的可用性来计划、准备并验证计划中的攻击。针对这种攻击的缓解策略很难实施，因为对手可以利用有限查询次数的推理API，或者创建受害者目标模型的离线版本。这会导致受害者API账单费用增加，因为API费用直接由他们承担。'
- en: '**Crafting adversarial data**: Adversarial data that serves as input to ML
    models can be misclassified, increase energy consumption, or make the model prone
    to failure. White-box optimization, black-box optimization, black-box transfer,
    and manual modification are population algorithms that can help adversaries to
    generate input data samples to evade ML architecture. The key purpose of adversaries
    is to disrupt the ML models by challenging their integrity.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**制造对抗数据**：作为机器学习（ML）模型输入的对抗数据可能会被错误分类，增加能耗，或使模型容易失败。白盒优化、黑盒优化、黑盒迁移和手动修改是能够帮助对手生成输入数据样本以规避ML架构的流行算法。对手的关键目的是通过挑战ML模型的完整性来破坏其运行。'
- en: Command-and-control requests
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指挥和控制请求
- en: These operations help adversaries move one step closer to extracting useful
    information from the victim’s network, as listed in the following table.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作帮助对手更进一步从受害者的网络中提取有用信息，如下表所示。
- en: '| **Item No.** | **Modes of** **Control Operations** |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| **项目编号** | **控制操作模式** |'
- en: '| --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | Use removable media (for example, by initiating communication between
    the host and other compromised services on the target network), utilize uncommonly
    used port-protocol pairs, or deploy authenticated web services. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 使用可移动介质（例如，通过在主机和目标网络上的其他受损服务之间发起通信），利用不常用的端口-协议对，或部署认证的Web服务。 |'
- en: '| 2 | Mix the commands with existing traffic, encode/obfuscate the requests
    over encrypted/fallback (when the primary channel is inaccessible)/multi-stage
    obfuscation channels to trigger commands, and dynamically establish connections
    with the target infrastructures. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 将命令与现有流量混合，通过加密/回退（当主通道无法访问时）/多阶段混淆通道对请求进行编码/混淆，以触发命令，并与目标基础设施动态建立连接。
    |'
- en: Table 2.3 – Different modes of control operations
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.3 – 不同的控制操作模式
- en: 'However, the adversary is clever enough to do this in such a way that the existing
    defense strategies on the target network will not raise an alarm. Therefore, some
    appropriate defense techniques are as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，攻击者足够聪明，可以以一种方式进行操作，使得目标网络上的现有防御策略不会触发警报。因此，以下是一些适当的防御技术：
- en: Enabling the adoption of specially crafted adversarial protocol tunnels, hiding
    open ports through traffic signaling, and making use of proxies can help to avoid
    direct communication between a command-and-control server and the victim’s network.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用特别设计的对抗性协议隧道，通过流量信号隐藏开放端口，并利用代理来避免命令与控制服务器与受害者网络之间的直接通信。
- en: The use of different application- and network-level authentication and application
    sandboxing mechanisms, discussed previously, is highly recommended.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强烈建议使用前面讨论过的不同的应用层和网络层认证机制以及应用沙箱技术。
- en: Additionally, network segmentation by properly configuring firewalls for existing
    microservices, databases, and proxies to limit outgoing traffic is essential.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，通过适当配置防火墙来进行网络分段，以限制现有微服务、数据库和代理的外出流量是至关重要的。
- en: Only authorized ports and network gateways should be kept open for hosts to
    establish communication over these authorized interfaces.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只应为主机开放授权的端口和网络网关，以便主机通过这些授权接口建立通信。
- en: Exfiltration
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 外泄
- en: Data exfiltration can be carried out by adversaries (as listed in *Table 2.4*)
    over the network, after data collection, encryption, compression, and packaging.
    Data can be packaged and compressed to different-sized blocks before being transmitted
    out of the network using a command-and-control channel or alternative channel
    strategies.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集、加密、压缩和打包之后，攻击者可以通过网络进行外泄（如*表2.4*所列），数据可以被打包和压缩成不同大小的块，然后通过命令与控制通道或替代通道策略从网络中传输出去。
- en: '| **Item No.** | **Modes** **of Exfiltration** |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| **项目编号** | **外泄模式** |'
- en: '| 1 | Automated exfiltration (unauthorized transfer of information collection),
    exfiltration over alternate protocols (relying on different protocols, such as
    FTP, SMTP, HTTP/S, DNS, or SMB instead of the existing command-and-control channel),
    and exfiltration over an existing command-and-control channel (over time for defense
    evasion) |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 自动化外泄（未经授权的信息转移），通过替代协议进行外泄（依赖不同的协议，如FTP、SMTP、HTTP/S、DNS或SMB，而不是现有的命令与控制通道），以及通过现有的命令与控制通道进行外泄（随着时间推移以规避防御）
    |'
- en: '| 2 | Network medium (Wi-Fi connection, modem, cellular data connection, Bluetooth
    or another **Radio Frequency** (**RF**) channel, etc.) |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 网络媒介（Wi-Fi连接、调制解调器、移动数据连接、蓝牙或其他**射频**（**RF**）通道等） |'
- en: '| 3 | Physical medium (removable drive) or web service (SSL/TLS encryption)
    |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 物理媒介（可移动驱动器）或Web服务（SSL/TLS加密） |'
- en: '| 4 | Scheduled transfers that move data to cloud accounts |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 将数据转移到云账户的定时传输 |'
- en: Table 2.4 – Different modes of exfiltration
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.4 – 不同的外泄模式
- en: 'The most common and easiest ways to carry out exfiltration attacks are by doing
    the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 执行外泄攻击最常见且最简单的方式如下：
- en: '**Inferencing ML model APIs for exfiltration**: ML model inference API access
    is the primary means for adversaries to look for ways to exfiltrate/steal private
    information from the model’s inference APIs.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理机器学习模型API用于外泄**：机器学习模型推理API访问是攻击者寻找外泄/窃取私密信息的主要途径。'
- en: 'To mitigate exfiltration risks, the following defense actions are mandatory:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解外泄风险，以下防御措施是必需的：
- en: Private data should be trained using application-level privacy techniques or
    by making the best use of hybrid security measures (application- and transport-level
    security) to protect against leakage of **Personally Identifiable** **Information**
    (**PII**).
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该使用应用层隐私技术或最大化利用混合安全措施（应用层和传输层安全）来训练私密数据，以防止**个人可识别信息**（**PII**）泄露。
- en: '**Data Loss Prevention** (**DLP**) APIs can be used to detect and block the
    transfer of sensitive data over unencrypted protocols.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据丢失防护**（**DLP**）API可用于检测并阻止通过未加密协议传输敏感数据。'
- en: Network intrusion detection and prevention systems can be used with network
    signatures to monitor and block malware traffic.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络入侵检测与防御系统可以与网络签名结合使用，以监控并阻止恶意流量。
- en: Restricting web content access by using web proxies can help to minimize unauthorized
    external access.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用网络代理限制Web内容访问可以帮助最小化未经授权的外部访问。
- en: '**Evading ML models**: Adversaries can use traditional cyberattacks where adversarial
    actions can evade ML-based virus/malware detection.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规避机器学习模型**：对手可以使用传统的网络攻击，采取对抗性行动，避开基于机器学习的病毒/恶意软件检测。'
- en: '**Denial of Service (DDoS)**: Here, adversaries are driven by the objective
    to bring down ML systems in production by issuing a flood of requests. The requests
    may be computationally intensive, requiring large amounts of memory, GPU resources,
    and processing cycles, and can overload the productionized systems, which may
    become too slow to respond.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拒绝服务攻击（DDoS）**：在这种情况下，对手的目标是通过发起大量请求，使生产中的机器学习系统崩溃。这些请求可能计算密集，需消耗大量内存、GPU资源和处理周期，可能导致生产化系统过载，响应变得缓慢。'
- en: '**Spamming ML systems**:Here, the adversaries increase the number of predictions
    in the output by spamming the ML system with false and arbitrary data. This impacts
    the ML team at the victim’s organization, who end up spending extra time deducing
    the correct inferences from the data.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垃圾信息攻击机器学习系统**：在这种情况下，对手通过向机器学习系统发送虚假和任意数据，增加输出中的预测数量。这会影响受害者组织的机器学习团队，他们最终需要花费额外时间从数据中推导正确的推论。'
- en: '**Eroding ML model integrity**: Adversaries may degrade the target model’s
    performance with adversarial data inputs to erode confidence in the system over
    time. This can lead to the victim organization wasting time and money attempting
    to fix the system.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**侵蚀机器学习模型完整性**：对手可能通过对抗性数据输入降低目标模型的性能，从而逐渐侵蚀系统的可信度。这可能导致受害者组织浪费时间和金钱，试图修复系统。'
- en: '**Harvesting cost**: This is similar to a DDoS attack, where adversaries engage
    themselves in targeting the victim’s ML services to increase the compute and running
    costs by bombarding the system with false and specially crafted queries. Sponge
    examples are specially crafted adversarial inputs, designed to increase processing
    speed and energy consumption, which can degrade the overall performance of the
    victim’s systems.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源收割成本**：这类似于DDoS攻击，对手通过针对受害者的机器学习服务发起攻击，通过向系统发送虚假和特别设计的查询，增加计算和运行成本。海绵示例是特制的对抗性输入，旨在提高处理速度和能耗，从而降低受害者系统的整体性能。'
- en: '**ML IP theft**: Here, adversaries steal intellectual property from ML models,
    training and evaluation datasets, and their related artifacts with the objective
    of causing economic harm to the victim organization. This act enables adversaries
    to have unlimited access to their victim''s service free of cost, avoiding the
    MLaaS provider’s API charges.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习知识产权盗窃**：在这种情况下，对手从机器学习模型、训练和评估数据集及其相关工件中窃取知识产权，目的是对受害组织造成经济损害。这种行为使对手能够无限制地免费访问受害者的服务，避免机器学习即服务（MLaaS）提供者的API费用。'
- en: '**System breakdowns**: Other than the commonly used mechanisms, impact strategies
    (the third attack strategy shown in *Figure 2**.5)* are mainly targeted at systems
    in production and include a variety of irrecoverable data destruction mechanisms
    such as overwriting files and directories with random data, manipulating data,
    defacement, wiping data, corrupting firmware, large-scale data encryption on target
    systems to disrupt the availability of system and network resources, commands
    to stop the service, system shutdown/reboot, and resource hijacking with the objective
    of bringing down the victim’s system resources.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统崩溃**：除了一些常用机制外，影响策略（如*图2.5*中所示的第三种攻击策略）主要针对生产系统，包括各种不可恢复的数据销毁机制，如用随机数据覆盖文件和目录、篡改数据、篡改外观、清除数据、损坏固件、大规模加密目标系统上的数据，以干扰系统和网络资源的可用性，停止服务的命令、系统关机/重启以及资源劫持，目的是使受害者的系统资源崩溃。'
- en: 'The ideal way to mitigate risks related to impacts is to follow these best
    practices:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解与影响相关风险的理想方式是遵循以下最佳实践：
- en: Have a data backup process to protect against any data loss/modification attempts.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有数据备份流程，以防止任何数据丢失/修改尝试。
- en: Have model robustness test strategies in place by thoroughly testing ML models
    against sponge attacks.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定模型鲁棒性测试策略，通过彻底测试 ML 模型对海绵攻击的抵抗能力。
- en: Worst-case or low threshold boundaries to validate model robustness can also
    aid in detecting adversarial attacks, where system-level degradations in performance
    are a symptom of inputs from external sources not designed for the system.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最坏情况或低阈值边界用于验证模型的鲁棒性，也有助于检测对抗性攻击，其中系统性能的退化是外部来源输入的症状，这些输入并非为该系统设计。
- en: Up to now, we have discussed the attack threat matrix, which we first saw in
    [*Chapter 1*](B18681_01.xhtml#_idTextAnchor014), *Figure 1**.13*, and different
    defense mechanisms available for different types of adversarial attacks.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了攻击威胁矩阵，该矩阵首次出现在 [*第 1 章*](B18681_01.xhtml#_idTextAnchor014)，*图
    1.13* 中，以及针对不同类型对抗性攻击的不同防御机制。
- en: Now let's look into the data anonymization and encryption techniques available
    to protect sensitive data.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们研究用于保护敏感数据的数据匿名化和加密技术。
- en: Anonymization and data encryption
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 匿名化和数据加密
- en: Due to the possibility of different attacks and threats, organizations have
    become more responsible about safeguarding the data rights of their employees.
    The Data Breach Survey of 2019 revealed that 79% of CIOs were convinced that company
    data was put at risk in the previous year because of actions by their employees
    ([https://www.grcelearning.com/blog/cios-increasingly-concerned-about-insider-threats](https://www.grcelearning.com/blog/cios-increasingly-concerned-about-insider-threats)).
    The data security practices of as many as 61% of employees put the company at
    risk, which led organizations to adopt best practices related to data anonymization.
    Some of the practices that organizations should follow to comply with GDPR and
    other regulations will be discussed in this section.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可能遭遇不同的攻击和威胁，组织在保护员工数据权益方面变得更加负责任。2019 年的数据泄露调查显示，79% 的 CIO 认为公司数据在前一年因员工的行为而处于风险中（[https://www.grcelearning.com/blog/cios-increasingly-concerned-about-insider-threats](https://www.grcelearning.com/blog/cios-increasingly-concerned-about-insider-threats)）。多达
    61% 员工的数据安全做法使公司面临风险，这促使组织采纳与数据匿名化相关的最佳实践。本节将讨论组织应遵循的一些做法，以遵守 GDPR 和其他法规。
- en: Data anonymization or pseudo-anonymization needs to be carried out on PII, which
    mainly includes names, ages, **Social Security Numbers** (**SSNs**), credit card
    details, bank account numbers, salaries, mobile numbers, passwords, and security
    questions.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 数据匿名化或伪匿名化需要针对个人身份信息（PII）进行处理，主要包括姓名、年龄、**社会保障号码**（**SSNs**）、信用卡详情、银行账户号码、薪资、手机号码、密码和安全问题。
- en: In addition to this, company policy and database administrators can define extra
    processes before the application of anonymization techniques. Now, let's look
    at some of the most commonly used techniques for data anonymization.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，公司政策和数据库管理员可以在应用匿名化技术之前定义额外的过程。现在，让我们看看一些最常用的数据匿名化技术。
- en: Data masking
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据屏蔽
- en: 'This technique hides and protects the original data by generating mirrored
    versions of it at random and then shuffling it with the original version of the
    data. There are five primary types of masking measures that make it difficult
    for the attacker to decipher the original data:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术通过随机生成其镜像版本并与原始数据版本混合，来隐藏和保护原始数据。数据屏蔽有五种主要类型的措施，使攻击者难以解密原始数据：
- en: '**Deterministic data masking**: This process allows the replacement of any
    columnar value with a specific value in any location of the table – be it the
    same row, the same database/schema, or between instances/servers/database types.
    It takes into consideration similar settings to generate replacement global salt
    keys (these are cryptographic elements that hash the data for security; for example,
    a website’s cookies). For example, XYZ can be replaced with ABC.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确定性数据屏蔽**：此过程允许将任何列值替换为表中任何位置的特定值——无论是在相同的行、相同的数据库/模式，还是在不同的实例/服务器/数据库类型之间。它考虑了类似的设置来生成替代的全局盐密钥（这些是加密元素，用于对数据进行哈希处理以确保安全性；例如，网站的
    cookies）。例如，XYZ 可以替换为 ABC。'
- en: '**Dynamic Data Masking** (**DDM**): The objective of this masking technique
    is to mask real-time production-grade data such that live data streams are modified
    without the data generator/requestor having access to the sensitive data. It can
    be used by setting the central data masking policy to mask sensitive fields with
    full or partial masking functions, along with random masking for numeric data.
    It also finds heavy usage in simple transact SQL commands (one or more SQL commands
    grouped together, that can be committed to a database as a single logical unit
    or rollback) SQL commands (for example, on SQL Server 2016 (13.x) and Azure SQL
    Database). Now, let’s look at an example of how masking is done in Azure:'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态数据遮蔽** (**DDM**)：此遮蔽技术的目标是对实时生产级数据进行遮蔽，使得实时数据流被修改，同时数据生成者/请求者无法访问敏感数据。通过设置中央数据遮蔽策略，可以使用完整或部分遮蔽功能来遮蔽敏感字段，同时对数值数据进行随机遮蔽。它还广泛应用于简单的事务性SQL命令（一个或多个SQL命令组合在一起，可以作为单一逻辑单元提交到数据库或回滚）（例如，在SQL
    Server 2016（13.x）和Azure SQL数据库中）。现在，让我们来看一个在Azure中如何进行遮蔽的例子：'
- en: '[PRE10]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here, the `Email` method uses masking to expose only the first letter of an
    email address and the constant suffix `.com`, producing the following: [aXXX@XXXX.com](mailto:aXXX@XXXX.com).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`Email`方法使用遮蔽，只显示电子邮件地址的第一个字母和常量后缀`.com`，生成如下内容：[aXXX@XXXX.com](mailto:aXXX@XXXX.com)。
- en: However, dynamic masking cannot be applied to encrypted columns, file streams,
    `COLUMN_SET`, or computed columns that have no dependency on any other columns
    with a mask.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，动态遮蔽不能应用于加密列、文件流、`COLUMN_SET`或没有依赖其他列且没有遮蔽的计算列。
- en: '**On-the-fly data masking**: This process is common when data from development
    environments is masked without the use of a staging environment due to factors
    including insufficient extra space, or under the constraint that the data must
    be migrated to the target environment. This masking technique is used in Agile
    development processes where **Extract, Transform, Load** (**ETL**) is directly
    able to load the data into the target environment without creating backups and
    copies. However, the general recommendation is to refrain from using this technique
    widely (other than in the initial stages of the project) to avoid risks related
    to compliance and security issues.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**即时数据遮蔽**：当数据从开发环境被遮蔽，而没有使用暂存环境时，这一过程很常见，原因包括额外空间不足，或数据必须迁移到目标环境的限制。此遮蔽技术常用于敏捷开发流程中，其中**提取、转换、加载**
    (**ETL**) 能直接将数据加载到目标环境，而不需要创建备份和副本。然而，通常建议不要广泛使用此技术（除了在项目初期阶段），以避免与合规性和安全性问题相关的风险。'
- en: '`Julia Gee` to `NULL Fhjoweeww` and `andwb@yahoo.com` to `yjjfd@yahoo.com`
    respectively.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Julia Gee` 转为 `NULL Fhjoweeww`，`andwb@yahoo.com` 转为 `yjjfd@yahoo.com`。'
- en: '**Synthetic data**: Synthetic data is a data anonymization technique employed
    to preserve the statistical properties of the original dataset, with a considerable
    margin of variable privacy gain and unpredictable utility loss. The increased
    privacy provided by this method offers protection against privacy-related attacks
    and prevents the re-identification of individuals. The synthetic data generated
    from generative models (for example, using deep learning techniques to generate
    deep fakes, where synthetic data recreates fake images resembling the originals)
    ensures high utility by enabling similar inferences as the original data.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成数据**：合成数据是一种数据匿名化技术，旨在保持原始数据集的统计特性，同时在可变隐私增益和不可预测的效用损失之间保持较大幅度的平衡。通过此方法提供的隐私保护能够防止与隐私相关的攻击，并防止个人身份的重新识别。通过生成模型（例如，使用深度学习技术生成深度伪造，其中合成数据再现了类似原始图像的虚假图像）生成的合成数据，确保通过生成与原始数据相似的推理，保持高效用性。'
- en: Data swapping
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据交换
- en: 'This procedure shuffles and rearranges data to completely break the similarity
    between the original and the resultant datasets. There are three popular data-swapping
    techniques:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程通过打乱和重新排列数据，彻底打破原始数据集与结果数据集之间的相似性。有三种常用的数据交换技术：
- en: K-anonymity
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-匿名性
- en: L-diversity
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L-多样性
- en: T-closeness
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T-接近性
- en: The techniques can all be used to make the deanonymization of data difficult
    for any intruder.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术都可以用于使数据的去匿名化对任何入侵者变得困难。
- en: Data perturbation
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据扰动
- en: This data anonymization principle adds noise to numerical data in databases
    to ensure its confidentiality. The process of adding or multiplying random noise
    additive, multiplicative, or random noise (used in Gaussian or Laplace distribution)
    helps to distort data, protecting it from being parsed by an attacker.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据匿名化原则通过向数据库中的数值数据添加噪声，确保其机密性。添加或乘以随机噪声（加法噪声、乘法噪声，或使用高斯或拉普拉斯分布的随机噪声）有助于扭曲数据，从而保护其不被攻击者解析。
- en: Data generalization
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据泛化
- en: This method makes the data less identifiable by allowing you to remove certain
    ranges or portions of data (for example, outliers) from the database. One example
    is replacing `age 45 years` with `<= 45`, where the value is replaced by a wider
    range that is still semantically consistent. Data portioning of this type or attribute
    assignment to specific categories serves as a measure to generalize the data.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通过允许删除数据中的某些范围或部分（例如，异常值），使数据变得不容易识别。一个例子是将`年龄 45岁`替换为`<= 45`，其中该值被一个更广泛的范围所替代，且在语义上仍然一致。这种数据分区或将属性分配到特定类别的方式可以作为对数据进行泛化的措施。
- en: Broadly, generalization can be applied at the full domain level or to individual
    sub-domains. In the former, data transformation takes place for a generic domain
    or level of the hierarchy, while in the latter the level of generalization occurs
    on different subsets of the same domain.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 广义上，泛化可以应用于整个领域级别或单个子领域。在前者中，数据转换发生在通用领域或层次的级别上，而在后者中，泛化级别发生在同一领域的不同子集上。
- en: 'Generalization-based techniques can be further applied to categorical or discrete
    numeric attributes to keep them private. There are two primary means by which
    generalization can be applied: a *hierarchy-based approach* or a *partition-based
    approach* (where a structure or order of partition needs to be established on
    the data items, before running the partition scheme on continuous numerical attributes).
    The partition-based approach partitions the data items into ranges, while hierarchy-based
    generalization requires the existence of generalization hierarchies and can be
    used for categorical and discrete numeric attributes. Some of these generalization
    techniques are described in the following sections.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 基于泛化的技术可以进一步应用于分类或离散数值属性，以保持其私密性。泛化可以应用的主要方式有两种：*基于层次的方式*或*基于分区的方式*（其中需要在对连续数值属性进行分区方案之前，先对数据项建立分区的结构或顺序）。基于分区的方式将数据项分为不同范围，而基于层次的泛化要求存在泛化层次结构，可用于分类和离散数值属性。以下部分描述了这些泛化技术。
- en: K-anonymity
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K-匿名性
- en: Sweeney first proposed the K-anonymity principle, which can be used as a framework
    to evaluate algorithms that carry sensitive information ([https://epic.org/wp-content/uploads/privacy/reidentification/Sweeney_Article.pdf](https://epic.org/wp-content/uploads/privacy/reidentification/Sweeney_Article.pdf)).
    In the absence of K-anonymity, sensitive attributes can leak and reveal boundary
    limits from the information elements. The application of K-anonymity is aimed
    at transforming the protected elements (either by generalization or suppression)
    with the objective of safeguarding the dataset from the hands of an intruder.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: Sweeney首次提出了K-匿名性原则，这可以作为一个框架来评估涉及敏感信息的算法（[https://epic.org/wp-content/uploads/privacy/reidentification/Sweeney_Article.pdf](https://epic.org/wp-content/uploads/privacy/reidentification/Sweeney_Article.pdf)）。在缺乏K-匿名性的情况下，敏感属性可能泄露并揭示出信息元素的边界限制。K-匿名性的应用旨在通过泛化或抑制来转换保护元素，以确保数据集不被入侵者获取。
- en: K-anonymity ensures any generalized block consisting of an individual record
    cannot be differentiated from K-1 other individuals in terms of any set of quasi-identifiers
    (such as zip code, age, or gender). This anonymization principle helps protect
    against linkage attacks, as discussed in [*Chapter 1*](B18681_01.xhtml#_idTextAnchor014).
    We see that in a linkage attack, an attacker is able to reveal the identity of
    a victim (unique identification number, credit card number, or others) and combine
    this with other background information, such as a user's travel details like source,
    destination, and means of travel. This combined information can assist an adversary
    in tracking the user's entire whereabouts. For example, a value of 10 for K on
    the protected attributes of age, **SSN**, nationality, salary, and bank account
    details will produce a minimum of 10 different records for each combination of
    the defined attributes.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: K-匿名性确保任何由单个记录组成的概括性块，无法在任何一组准标识符（如邮政编码、年龄或性别）方面与K-1个其他个体区分开。这一匿名化原则有助于防范联结攻击，正如在[*第一章*](B18681_01.xhtml#_idTextAnchor014)中讨论的那样。我们看到，在联结攻击中，攻击者能够揭示受害者的身份（如唯一标识号码、信用卡号等），并将其与其他背景信息（如用户的旅行细节，包括出发地、目的地和交通工具）结合起来。这些组合信息可以帮助攻击者追踪用户的整个行踪。例如，针对年龄、**社会安全号码（SSN）**、国籍、薪资和银行账户等受保护属性，如果K值为10，则每种定义属性的组合将产生至少10条不同的记录。
- en: As *Figure 2**.6* illustrates, with K = 2, there are two records listed as Asian
    and two as Hispanic. We can see that an equivalent number of records are distributed
    with respect to sensitive attributes such as age and salary across the two races.
    *Figure 2**.6* provides a complete demonstration of an end-to- end pipeline, showing
    risk score assessments, information recognition, pseudonymization, and anonymization,
    to audit and store sensitive data.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图2.6*所示，当K=2时，记录中有两个为亚洲人，两个为西班牙裔。我们可以看到，在这两种种族中，与年龄和薪资等敏感属性相关的记录数量是相等的。*图2.6*展示了一个完整的端到端流程，显示了风险评分评估、信息识别、伪匿名化和匿名化过程，以便审计和存储敏感数据。
- en: "![Figure 2.\uFEFF6 – Different \uFEFFanonymity models – K-anonymity, L-diversity,\
    \ and T-closeness\uFEFF](img/Figure_2.06_B18681.jpg)"
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 不同的匿名性模型 – K-匿名性、L-多样性和T-接近性](img/Figure_2.06_B18681.jpg)'
- en: Figure 2.6 – Different anonymity models – K-anonymity, L-diversity, and T-closeness
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 不同的匿名性模型 – K-匿名性、L-多样性和T-接近性
- en: The limitation of this system is that if an adversary has any information about
    the victims beforehand (say, their age), then it would be much easier for them
    to identify other attributes, such as salary- and disease-related information.
    For example, a friend of Nancy's may know the age group and race to which she
    belongs, which would enable her friend to guess and retrieve her salary. The presence
    of homogeneous salary or age groups makes it possible for the adversary to derive
    sensitive information by the process of elimination or negative disclosure. It
    becomes easier for an adversary to initiate their attacks successfully and with
    high confidence. As a result, improvements for K-anonymity have been suggested
    to prevent background knowledge and homogeneity-based attacks.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统的局限性在于，如果攻击者事先掌握关于受害者的任何信息（例如，年龄），那么他们就更容易识别其他属性，如薪资和与疾病相关的信息。例如，南希的朋友可能知道她所属的年龄组和种族，这将使她的朋友能够猜测并获取她的薪水。相同薪资或年龄组的存在使得攻击者可以通过排除法或负面披露的过程推导出敏感信息。攻击者更容易成功发起攻击并充满信心。因此，已经提出了改进K-匿名性的方法，以防止基于背景知识和同质性的攻击。
- en: L-diversity
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: L-多样性
- en: The L-diversity principle (defined by Machanavajjhala et al.) was designed to
    handle the drawbacks of the K-anonymity algorithm to reduce the probability of
    homogeneity and background knowledge attacks. The L-diversity principle provides
    privacy where the data publisher is not aware of the knowledge that is possessed
    by the adversary. The fundamental idea behind L-diversity is the requirement that
    each group sees an equivalent of the sensitive values. The known information can
    be modeled as a probability distribution by applying Bayesian inferencing to reduce
    the granularity of the base data representation. The primary objective of generalization
    is to obtain different values for sensitive data that is evenly distributed.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: L-多样性原则（由Machanavajjhala等人定义）旨在处理K-匿名算法的缺点，以减少同质性和背景知识攻击的概率。L-多样性原则在数据发布者不了解攻击者所掌握的知识的情况下提供隐私保护。L-多样性的基本理念是要求每个组看到等同的敏感值。通过应用贝叶斯推理，已知信息可以被建模为概率分布，从而减少基础数据表示的粒度。泛化的主要目标是获得均匀分布的不同敏感数据值。
- en: The major limitation of this algorithm becomes visible when the distribution
    is skewed and fails to achieve an entropy of uniformly distributed L distinct
    sensitive values for each equivalence class. In such a case, the overall entropy
    level of the table drops, and the algorithm becomes non-functional and cannot
    offer sufficient protection.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据分布存在偏斜时，算法的主要限制便显现出来，无法实现每个等价类的L个不同敏感值的均匀分布的熵。在这种情况下，表格的整体熵水平下降，算法变得无法运行，无法提供足够的保护。
- en: Even though this algorithm takes into consideration the diversity of sensitive
    values within each group, it fails to constrain the value ranges and boundaries
    of the diverse groups. Given features with very close boundaries (say, salary
    > US $20,000 versus salary > US $30,000), the attacker can retrieve the salary
    information from the two equivalence classes (similar classes with close boundaries)
    that have different age groups.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管该算法考虑了每个组内敏感值的多样性，但它未能约束多样化组的值范围和边界。对于边界非常接近的特征（例如，薪资 > 2万美元与薪资 > 3万美元），攻击者可以从具有不同年龄组的两个等价类（具有相似边界的类）中检索薪资信息。
- en: T-closeness
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T-紧密性
- en: As K-anonymity and L-diversity together cannot safeguard against skewness and
    similarity attacks, T-closeness came into being to offer extra robustness to the
    anonymization framework. This principle states that the two distributions – one
    of which is the sensitive value distributions of any group (say, racial groups;
    Asian and Hispanic in our example in *Figure 2**.6*) and the other is the overall
    sensitive value distribution – cannot differ by more than a threshold of `t`.
    The distance metric used to evaluate the difference between the two distributions
    is the **Earth-Mover Distance** (**EMD**). It is computed using the possible set
    of sensitive attributes by evaluating the maximum distance between them. The metric
    gives a measurement between 0 and 1, in the space normalized to 1, with the intention
    of including the semantic closeness of attribute values in addition to the generalization
    of quasi-identifiers and the suppression of sensitive values.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 由于K-匿名性和L-多样性不能共同防范偏斜和相似性攻击，因此T-紧密性应运而生，以增强匿名化框架的稳健性。该原则指出，两个分布——其中一个是任何组的敏感值分布（例如，种族组；在我们示例中的*图2.6*中的亚洲人和西班牙裔人群），另一个是整体敏感值分布——它们之间的差异不能超过阈值`t`。用于评估两个分布之间差异的距离度量是**地球搬运工距离**（**EMD**）。它通过评估它们之间的最大距离来计算可能的敏感属性集合。该度量在0到1之间给出一个值，空间被归一化到1，旨在包括属性值的语义接近度，以及准标识符的泛化和敏感值的抑制。
- en: Though T-closeness can resolve the shortcomings of K-anonymity and L-diversity,
    by offering protection from homogeneity, background knowledge, skewness, and similarity
    attacks, it remains vulnerable to minimality and composition attacks. In the former,
    the attacker deduces the boundary condition or the minimality criteria beyond
    which the anonymized models (K-anonymity, L-diversity, and T-closeness) cannot
    provide sufficient protection against external threats. Using this information,
    the intruder can decipher sensitive information for some of the equivalence classes.
    In the second category of attack, the attacker exploits the availability of all
    different releases of anonymized datasets to integrate them into one single unit,
    where the unified dataset is used to breach individual privacy.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管**T-接近性**可以解决**K-匿名性**和**L-多样性**的缺点，通过提供免受同质性、背景知识、偏斜和相似性攻击的保护，但仍然容易受到最小性和组合攻击的影响。在前者中，攻击者推断出匿名化模型（K-匿名性、L-多样性和T-接近性）不能为外部威胁提供足够保护的边界条件或最小性标准。利用这些信息，入侵者可以解密部分等价类的敏感信息。在第二类攻击中，攻击者利用匿名化数据集所有不同版本的可用性将它们集成为一个单一单位，其中统一的数据集用于突破个人隐私。
- en: Among other, less popular anonymized models is the p-sensitive K-anonymity model,
    which ensures K-anonymity conditions on `p`. In addition, it also stops learning
    sensitive associations at the same time. We can denote an anonymity model as (∊,
    `m`) (with the frequency of sensitive attribute values ∊ remaining within the
    user-defined threshold in the equivalence classes). This was designed to protect
    sensitive numerical attributes from proximity breaches, where data boundaries
    are too close. This allows an attacker to gather information with high confidence
    that a sensitive attribute value falls in a specified interval.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他较不流行的匿名化模型中，有p-敏感K-匿名性模型，它确保在`p`上的K-匿名性条件。此外，它还同时阻止学习敏感关联。我们可以将匿名性模型表示为（∊，`m`）（敏感属性值频率∊在用户定义的等价类中保持在阈值内）。这设计用于保护敏感数值属性免受接近侵犯，其中数据边界过于接近，使攻击者能够以高信心收集到敏感属性值在指定区间内的信息。
- en: Encryption
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 加密
- en: Encryption of personal data is a methodology used to protect data from external
    sources and limit access to users who are not authorized to access it. Three major
    data encryption schemes of symmetric encryption, asymmetric encryption, and hybrid
    encryption can be employed for the purpose of key generation, registration, usage,
    storage, monitoring, rotation, and deletion.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 个人数据的加密是一种方法，用于保护数据免受外部来源的侵害，并限制未经授权的用户访问。可以使用对称加密、非对称加密和混合加密这三种主要的数据加密方案来进行密钥生成、注册、使用、存储、监视、旋转和删除。
- en: '**Symmetric encryption** techniques such as **Advanced Encryption Standard**
    (**AES**) are fast and can be accelerated by processors for bulk encryption purposes.
    This procedure is dependent on the pre-sharing/exchange of a single key between
    the client and the server to be used for encryption and decryption purposes. To
    provide support for integrity and authentication, a message authentication code
    can be added on top of this.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '**对称加密**技术，如**高级加密标准**（**AES**），速度快，并且可以通过处理器加速批量加密。此过程依赖于客户端和服务器之间预共享/交换的单个密钥，用于加密和解密目的。为了支持完整性和认证，可以在此基础上添加消息认证码。'
- en: '**Asymmetric encryption** schemes such as **Rivest**, **Shamir**, **Adleman**
    (**RSA**), **Digital Signature Algorithm** (**DSA**), and **Elliptic Curve Cryptograph**
    (**ECC**) use two keys, one public and the other private, and offer strong protection
    against adversaries. However, the procedure is slow and has limited applications
    for protecting data in ML systems. The communicating parties are responsible for
    secretly storing their private keys, while the public keys are shared. This happens
    over the following steps:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '**非对称加密**方案，如**Rivest**、**Shamir**、**Adleman**（**RSA**）、**数字签名算法**（**DSA**）和**椭圆曲线密码学**（**ECC**），使用两个密钥，一个公钥和一个私钥，并且对抗攻击的能力强大。然而，该过程速度较慢，对于在机器学习系统中保护数据的应用有限。通信各方负责秘密存储其私钥，而公钥则是共享的。这些步骤如下进行：'
- en: Using **Transport Layer Security** (**TLS**), the sender and receiver finalize
    the symmetric key (session key) that is used to encrypt data sent by the sender.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**传输层安全**（**TLS**），发送方和接收方最终确定用于加密发送数据的对称密钥（会话密钥）。
- en: The sender is responsible for encrypting the symmetric key with the receiver’s
    public key.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送方负责使用接收方的公钥对对称密钥进行加密。
- en: The symmetric key is decrypted by the receiver with their own private key.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对称密钥由接收者使用他们自己的私钥进行解密。
- en: Using the symmetric key, the data is decrypted by the receiver.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用对称密钥，接收者对数据进行解密。
- en: Now that we’ve had an overview of some encryption techniques, let's look at
    another level of abstraction process with pseudonymization, which further increases
    the difficulty for adversaries to break the encryption key.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经概述了一些加密技术，让我们看看假名化的另一个抽象层次的过程，它进一步增加了对手破解加密密钥的难度。
- en: Pseudonymization
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假名化
- en: This method helps to anonymize data while preserving accuracy in statistics
    and value. Different types of encryption and hashing techniques can be used for
    this process. PII information (quasi-identifiers) is encoded with pseudonyms and
    preserved separately, which allows the easy re-identification of the original
    data through the use of cross-references or identifiers. In contrast to the anonymization
    technique, this procedure prevents permanent data replacement using a substitution
    principle. Pseudonymization can also be used for the encryption and decryption
    of PII, where the original data is translated into ciphertext, which can be reversed
    with the relevant decryption key.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法有助于对数据进行匿名化，同时保持统计数据和数值的准确性。在此过程中可以使用不同类型的加密和哈希技术。个人身份信息（准标识符）被用假名编码并单独保存，这使得通过交叉引用或标识符容易重新识别原始数据。与匿名化技术相比，这个过程通过替代原则防止永久性的数据替换。假名化也可用于个人身份信息（PII）的加密与解密，其中原始数据被转换为密文，可以通过相关的解密密钥进行反向解密。
- en: The main disadvantage of this process is that when datasets contain billions
    or trillions of records, human review and re-assessment or re-identification becomes
    impossible. Moreover, when the most sensitive fields require precise values, we
    may miss potential sources of re-identification attacks due to the privacy-utility
    trade-off.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程的主要缺点是，当数据集包含数十亿或数万亿条记录时，人工审核和重新评估或重新识别变得不可能。此外，当最敏感的字段需要精确值时，由于隐私与效用的权衡，我们可能会错过潜在的重新识别攻击源。
- en: This process further allows vertical or horizontal distribution of PII (by storing
    it in some protected storage units) and maintaining a link between the identifiers.
    In a vertical data distribution system, pseudonymity is guaranteed by compartmentalizing
    individual data corresponding to different subsets of sensitive attributes in
    different sites. In a horizontal data distribution system, sites near user locations
    are responsible for storing data with the same sets of user attributes. One primary
    example of horizontal data distribution is health-related information, where data
    integration from different sources is a preliminary step to infer an individual’s
    health-related information.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程进一步允许PII的纵向或横向分发（通过将其存储在某些受保护的存储单元中），并保持标识符之间的联系。在纵向数据分发系统中，通过将不同敏感属性子集对应的个人数据分隔存储在不同地点来确保假名性。在横向数据分发系统中，靠近用户位置的站点负责存储具有相同用户属性集的数据。横向数据分发的一个主要例子是与健康相关的信息，在这种情况下，来自不同来源的数据整合是推断个体健康相关信息的初步步骤。
- en: 'Some common types of pseudonymization techniques are as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的假名化技术类型如下：
- en: '**Encryption with secret key**: PII can be encrypted and then decrypted by
    the owner using any of the symmetric or asymmetric encryption methods discussed
    in previous sections.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用秘密密钥加密**：个人身份信息（PII）可以使用前面讨论的对称或非对称加密方法进行加密，然后由所有者解密。'
- en: '**Hash function**: This function is applied to transform a dataset with variable
    feature attributes and data size to yield a fixed-size output. This method often
    runs the risk of revealing sensitive PII if the range of input values applied
    to the hash function is known beforehand. A better method of adding higher-order
    protection is to use a salted-hash function, which adds randomization and reduces
    the probability of an attacker retrieving the actual values.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**哈希函数**：该函数用于将具有可变特征属性和数据大小的数据集转换为固定大小的输出。此方法往往存在泄露敏感PII的风险，如果已知哈希函数应用的输入值范围。为了提供更高的保护，可以使用加盐哈希函数，这种方法通过添加随机化来减少攻击者获取实际值的可能性。'
- en: '**Hash function with secret stored key**: The hash function used for transformation
    is supplied with a secret key to the input, which further reduces the probability
    of an attacker being able to retrieve the actual data by replay attacks, where
    an attacker intercepts the network. The data owner will still be able to retrieve
    the data with the secret key, but for the attacker it becomes increasingly difficult
    to compute all sorts of permutations and generate the actual key used for encryption.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带有存储密钥的哈希函数**：用于转换的哈希函数将密钥作为输入，这进一步降低了攻击者通过重放攻击（即攻击者拦截网络）来恢复实际数据的概率。数据拥有者仍然可以使用密钥恢复数据，但对于攻击者来说，计算所有种类的排列并生成用于加密的实际密钥变得越来越困难。'
- en: '**Hash function with deletion of secret key**: This process involves the selection
    of a random number corresponding to every feature in the dataset to act as the
    pseudonym. Further, the correspondence table is deleted to reduce the probability
    of linkage attacks where an attacker can link the personal data of individuals
    from the dataset in question to other available datasets with other pseudonyms.
    It makes it even more difficult for an attacker to use all permutations for a
    non-existent secret key to replay the function and retrieve the original data.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带有删除密钥的哈希函数**：该过程涉及为数据集中的每个特征选择一个随机数字作为伪名。此外，关联表被删除，以减少链接攻击的概率，在这种攻击中，攻击者可以将数据集中的个人数据与其他可用数据集中的其他伪名进行关联。这使得攻击者更难使用所有可能的排列来重放该函数并恢复原始数据。'
- en: '**Tokenization**: This method of data encryption enables the conversion of
    sensitive data with a randomly generated token. It is widely prevalent in the
    payment card industry in credit cards, wallets, and other applications involving
    unique identifiers (PAN cards, driving licenses, SSNs, etc.). Organizations dealing
    with such secret identifiers often employ a tokenization service that is responsible
    for payment authorization by generating and validating a token based on users’
    identities. The generated token can then be stored and mapped in the database
    of the third-party service provider. The storage service reduces the risk of data
    loss by providing unlimited data retention capacity. The involvement of third-party
    providers helps to reduce issues related to **Payment Card Industry Data Security
    Standard** (**PCI** **DSS**) compliance.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**令牌化**：这种数据加密方法通过随机生成的令牌将敏感数据转换。这种方法在支付卡行业广泛应用于信用卡、钱包及其他涉及唯一标识符的应用（如PAN卡、驾驶证、社会安全号码等）。处理这些机密标识符的组织通常会使用一个令牌化服务，负责通过基于用户身份生成和验证令牌来进行支付授权。生成的令牌可以存储并映射在第三方服务提供商的数据库中。存储服务通过提供无限的数据保存能力来减少数据丢失的风险。第三方服务提供商的介入有助于减少与**支付卡行业数据安全标准**（**PCI**
    **DSS**）合规性相关的问题。'
- en: Homomorphic encryption
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同态加密
- en: '**Homomorphic encryption** (**HE**) has gained a lot of prominence in the data
    security industry, especially in the design of high-grade cloud security applications,
    owing to the amount of protection guaranteed by this technique. It relies on a
    probabilistic asymmetric algorithm and adds an extra protective layer where parties
    who do not own the encryption and decryption keys are unable to decipher the encrypted
    data. The primary advantage of this method over traditional encryption methodologies
    is that it allows cloud providers to process the already encrypted data without
    having to decrypt it first. The processed results are available in encrypted form
    to the owner, who can retrieve the processed results with a decryption key.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**同态加密**（**HE**）因其提供的保护程度，在数据安全行业中获得了广泛关注，尤其是在高端云安全应用的设计中。该技术依赖于概率性非对称算法，并增加了一层额外的保护层，使得没有加密和解密密钥的方无法解密加密数据。与传统加密方法相比，这种方法的主要优势在于，它允许云服务提供商处理已经加密的数据，而无需先解密。处理后的结果以加密形式提供给数据拥有者，后者可以使用解密密钥检索处理结果。'
- en: HE follows multiplicative laws of encryption and computation, where the order
    of encryption and computation can be interchanged. Any computation, when applied
    on datasets *a* and *b* after they have been encrypted individually as *E*(*a*)
    and *E*(*b*), yields the same result as it would have when encryption is applied
    to the computed result *E*(*a ** *b*).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 同态加密遵循乘法加密和计算规律，其中加密和计算的顺序可以互换。任何计算，当它应用于数据集 *a* 和 *b*，在它们被单独加密为 *E*(*a*) 和
    *E*(*b*) 后，都会得出与加密结果 *E*(*a ** *b*) 应用到计算结果时相同的结果。
- en: Hence, mathematically, *E*(*a * b*) = *E*(*a*) * *E*(*b*), where *E*(*a*) and
    *E*(*b*) refer to the encryptions applied to datasets *a* and *b,* respectively,
    and *E*(*a * b*) refers to the encryption applied on the resultant computations
    of *a* and *b*.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从数学角度来看，*E*(*a * b*) = *E*(*a*) * *E*(*b*)，其中 *E*(*a*) 和 *E*(*b*) 分别表示对数据集
    *a* 和 *b* 应用的加密，*E*(*a * b*) 则表示对 *a* 和 *b* 的计算结果应用的加密。
- en: As they are equal, the decrypted values of *E*(*a * b*) and *E*(*a*) * *E*(*b*)
    are also equal.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们是相等的，*E*(*a * b*) 和 *E*(*a*) * *E*(*b*) 的解密值也相等。
- en: '*Figure 2**.7* illustrates a use case of HE that helps to achieve anonymous
    data processing for (a) single users and (b) multiple users seeking to process
    their encrypted (using their public key) sensitive data on a cloud server. In
    the first case (a), the individuals can directly obtain decrypted results as computed,
    evaluated, and returned by the server. In the second case (b), the server can
    aggregate the individual data by stripping off the identity information, processing
    their encrypted data, inferring statistical information, and sending the inferred
    data back to a third-party source that is responsible for collecting the final
    derived outcome. The data received by the third-party source can then decrypt
    the data and obtain the inferred results.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.7* 说明了同态加密（HE）的一个应用场景，帮助实现匿名数据处理（a）单一用户和（b）多个用户在云服务器上处理他们加密（使用公钥加密）敏感数据的情况。在第一个案例（a）中，个体可以直接获得由服务器计算、评估并返回的解密结果。在第二个案例（b）中，服务器可以通过去除身份信息来聚合个体数据，处理它们的加密数据，推断出统计信息，并将推断的数据发送回负责收集最终结果的第三方来源。第三方来源接收到数据后可以解密并获取推断的结果。'
- en: "![Figure 2.\uFEFF7 – Single\uFEFF- or multi-party \uFEFFHE](img/Figure_2.07_B18681.jpg)"
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7 – 单方或多方同态加密（HE）](img/Figure_2.07_B18681.jpg)'
- en: Figure 2.7 – Single- or multi-party HE
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – 单方或多方同态加密（HE）
- en: Such multi-party agents using HE can be used to efficiently run electronic voting
    systems. Individual voters can use their public keys to encrypt their ballots
    and send them to the voting server. The cloud server makes use of homomorphic
    evaluation to run extra validity checks on encrypted ballots and compute an aggregated
    encrypted result. The computed encrypted result can be sent to the organizers,
    who can then decrypt and deduce the overall voting results without having any
    knowledge of how specific individuals cast their votes.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 使用同态加密（HE）的多方代理可以有效地运行电子投票系统。单个选民可以使用他们的公钥加密选票并将其发送到投票服务器。云服务器利用同态计算对加密的选票进行额外的有效性检查，并计算汇总的加密结果。计算出的加密结果可以发送给组织者，组织者可以解密并推导出整体投票结果，而无需了解具体选民如何投票。
- en: '*Figure 2**.8* demonstrates the change in approach to privacy using HE in comparison
    with traditional privacy approaches. In the traditional privacy mechanism, users
    were dependent on relevant cloud storage and its computation facility for data
    transmission, processing, and storage functionalities. The customers needed to
    establish added trust with the service provider, where the providers are not allowed
    to share private information with third parties without the customer’s consent.
    In the present day, HE-based privacy systems (for example, Microsoft’s SEAL platform)
    guarantee confidentiality with full protection of customer data in addition to
    encrypted storage and computation capabilities.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.8* 展示了使用同态加密（HE）与传统隐私保护方法相比，在隐私保护方法上的变化。在传统的隐私机制中，用户依赖于相关的云存储及其计算设施来进行数据传输、处理和存储功能。客户需要与服务提供商建立额外的信任关系，服务提供商不得在未经客户同意的情况下与第三方共享私人信息。如今，基于同态加密的隐私系统（例如微软的
    SEAL 平台）除了加密存储和计算能力外，还能确保完全保护客户数据的机密性。'
- en: "![Figure 2.\uFEFF8 – A diagram showing traditional encryption versus \uFEFF\
    HE](img/Figure_2.08_B18681.jpg)"
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8 – 显示传统加密与同态加密（HE）对比的示意图](img/Figure_2.08_B18681.jpg)'
- en: Figure 2.8 – A diagram showing traditional encryption versus HE
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – 显示传统加密与同态加密（HE）对比的示意图
- en: 'This methodology can also be efficiently used in the following areas of security
    involving cloud services:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法论还可以高效应用于以下涉及云服务的安全领域：
- en: Private storage and computation
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 私有存储与计算
- en: Private prediction services
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 私有预测服务
- en: Hosted private training
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 托管的私有培训
- en: Private set intersection
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 私有集合交集
- en: Secure collaborative computation
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全协同计算
- en: 'The following code demonstrates instantiating a `Pyfhel` object (with public
    and private keys) at the client end, with the generation and saving of public
    and private key pairs within the context. The `contextGen` function is used to
    generate an HE context based on input parameters. We save the public key along
    with the context:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了在客户端实例化一个`Pyfhel`对象（包括公钥和私钥），并在上下文中生成和保存公私钥对。`contextGen`函数用于根据输入参数生成一个同态加密上下文。我们将公钥与上下文一起保存：
- en: '[PRE11]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Then we try to decrypt the encrypted values (`a` and `b`) in the cloud using
    `PyCtxt`. But the decryption process fails in the cloud, as demonstrated in the
    output. The cloud server then applies the mean of the encrypted values and sends
    it back to the client. But the client successfully decrypts the results and can
    obtain the mean value (the mean of 1.5 and 2.5 is 2).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们尝试使用`PyCtxt`在云端解密加密值（`a`和`b`）。但如输出所示，解密过程在云端失败。随后，云服务器对加密值进行平均操作，并将其发送回客户端。客户端成功解密结果，并获得平均值（1.5和2.5的平均值是2）。
- en: 'The cloud server tries to decrypt and then apply a mathematical mean operation
    on the encrypted results sent by the client:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 云端服务器尝试解密并对客户端发送的加密结果进行数学平均操作：
- en: '[PRE12]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The cloud computes the mean value of the ciphertexts obtained in the previous
    steps:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 云端计算前一步得到的密文的平均值：
- en: '[PRE13]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The client loads and decrypts the result:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端加载并解密结果：
- en: '[PRE14]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This results in the following output:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成如下输出：
- en: '[PRE15]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Let’s see when this might be a useful technique.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这种技术何时可能派上用场。
- en: Applications of HE
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同态加密的应用
- en: 'HE finds widespread usage in scenarios where there is a demand for huge computational
    capacity for processing high volumes of sensitive data not available to users.
    Some useful practical applications are predictive and analytics use cases in genomics
    research, finance, healthcare, pharmaceuticals, government, insurance, manufacturing,
    and the oil and gas sector, as illustrated in the following list:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 同态加密广泛应用于需要强大计算能力来处理大量用户无法访问的敏感数据的场景。一些实际的应用包括基因组学研究、金融、医疗保健、制药、政府、保险、制造业和石油天然气行业的预测与分析案例，以下列表列出了这些应用：
- en: Leveraging cloud services for backtesting stock market trading strategies in
    such a manner that the data remains secure and private from external systems,
    including attackers and cloud operators
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用云服务进行股市交易策略的回测，以确保数据在外部系统（包括攻击者和云操作员）面前仍然安全私密
- en: Backtesting
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 回测
- en: Backtesting is a strategy that allows a trader to simulate a trading strategy
    using historical data to generate results and accordingly identify and analyze
    the risk and profitability before risking any actual capital.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 回测是一种策略，允许交易者利用历史数据模拟交易策略，生成结果并据此识别和分析风险与盈利性，从而在实际投资之前评估风险。
- en: ML applications related to fraud detection, automated claims processing, and
    threat intelligence
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与欺诈检测、自动理赔处理和威胁情报相关的机器学习应用
- en: ML-based SaaS platforms analyzing DNA with DNA sequencing classifiers to provide
    predictive insights to medical institutions and hospitals
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于机器学习的SaaS平台通过DNA测序分类器分析DNA，向医疗机构和医院提供预测性洞察
- en: ML-based SaaS platforms providing medical diagnosis, medical support systems
    such as healthcare bots, and preventive care
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于机器学习的SaaS平台提供医疗诊断、医疗支持系统（如健康护理机器人）以及预防性护理
- en: ML-based complex design and architectural patterns to innovate and run novel
    algorithms; they can also be used to run a mechanical structural analysis for
    the aerospace or construction industry
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于机器学习的复杂设计和架构模式，用于创新并运行新算法；还可以用于运行航空航天或建筑行业的机械结构分析
- en: Predictive platforms for running secure auctions
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行安全拍卖的预测平台
- en: However, there are certain limitations on the use of HE, such as encrypted search
    (returning search results to the query without learning about the response) on
    a database or spam-filtering encrypted emails. In the former scenario, it is not
    feasible for the server to determine the search query content, which would entail
    huge processing loads and costs on the server to perform a homomorphic evaluation
    of the entire search operation. In the case of spam filtering, the procedure can
    produce a list of encrypted messages as spam, which cannot be deleted unless the
    client is aware of the filtering criteria (for example, keywords) that qualify
    a message as spam.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，HE（同态加密）的使用存在一些限制，例如数据库上的加密搜索（返回搜索结果而不泄露查询内容）或垃圾邮件过滤加密邮件。在前一种情况下，服务器无法确定搜索查询的内容，这将使服务器进行同态评估整个搜索操作时产生巨大的处理负担和成本。在垃圾邮件过滤的情况下，程序可以生成加密消息列表作为垃圾邮件，但在客户端不知道过滤标准（例如关键词）来判定哪些邮件为垃圾邮件之前，这些垃圾邮件无法被删除。
- en: Secure Multi-Party Computation (MPC/SMPC)
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全多方计算（MPC/SMPC）
- en: This is a security technique used in ML to train private sensitive data and
    create risk-proof ML models. Here, the participating candidates are allowed to
    perform computations on private data and evaluate the private models of one participant
    with another participant’s private data.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在机器学习中用于训练私人敏感数据并创建防风险的机器学习模型的一种安全技术。在这里，参与者可以对私密数据进行计算，并用另一个参与者的私密数据来评估一个参与者的私密模型。
- en: This protocol works on the principle of secret sharing, where a dealer can share
    a secret *s* among *n* parties. This scheme can protect the secret from *t* or
    fewer participating candidates, and, at the same time, a subset of *t + 1* candidates
    can reconstruct the secret. The participating candidates obtain their shares in
    the output, which helps them to reconstruct the actual outputs through interpolation.
    If only a few selected candidates are configured to obtain their shares, participating
    candidates are also allowed to send shares to only relevant individuals. Let's
    now investigate some practical use cases where MPC was used to protect sensitive
    data.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 该协议基于秘密共享原理，其中一个分发者可以在 *n* 方之间共享一个秘密 *s*。该方案可以保护秘密免受 *t* 或更少参与者的泄露，同时，*t + 1*
    个参与者的子集可以重建该秘密。参与者会在输出中获得各自的份额，帮助他们通过插值重建实际输出。如果只配置了少数选定参与者来获得其份额，参与者也可以仅将份额发送给相关个体。现在，让我们来探讨一些实际的使用案例，其中使用
    MPC 来保护敏感数据。
- en: Google uses MPC to evaluate advertisement conversion rates by computing the
    privacy-preserving set intersection between those users viewing an ad and those
    who go on to purchase the product. Some organizations rely on threshold cryptography
    instead of legacy hardware for protecting cryptographic keys. Here, organizations
    depend on MPC for key generation, computation, and storage, instead of allowing
    individuals to hold private information.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: Google 使用 MPC 来评估广告转化率，通过计算展示广告的用户与最终购买产品的用户之间的隐私保护集交集。一些组织依赖门限密码学而非传统硬件来保护加密密钥。在这种情况下，组织依赖
    MPC 来进行密钥生成、计算和存储，而不是允许个人持有私密信息。
- en: 'This process helps organizations to protect keys from adversaries as the key
    shares are placed in different environments. What makes MPC most useful for big
    data and large-scale predictive systems is the following:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程有助于组织保护密钥免受对手的攻击，因为密钥份额被放置在不同的环境中。MPC 对大数据和大规模预测系统最有用的特点如下：
- en: Easy adaptability to cross-platform deployment models.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它能轻松适应跨平台部署模型。
- en: A multi-tenant MPC can run as a cloud-native **Key Management** **Service**
    (**KMS**).
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多租户的 MPC 可以作为云原生的**密钥管理** **服务** (**KMS**)运行。
- en: Can be functional across multiple clouds (for example, AWS, Google, and Azure)
    simultaneously to maximize security and availability.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在多个云平台（例如 AWS、Google 和 Azure）上同时运行，以最大化安全性和可用性。
- en: Supports hybrid cloud multi-site enterprise deployments.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持混合云多站点企业部署。
- en: Easy scalability.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于扩展。
- en: Sustained secure operations.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续的安全操作。
- en: "![Figure 2.\uFEFF9 – SMPC – A\uFEFF. Shamir’s secret sharing and B\uFEFF. Threshold\
    \ cryptography](img/Figure_2.09_B18681.jpg)"
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.9 – SMPC – A. Shamir 的秘密共享和 B. 门限密码学](img/Figure_2.09_B18681.jpg)'
- en: Figure 2.9 – SMPC – A. Shamir’s secret sharing and B. Threshold cryptography
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – SMPC – A. Shamir 的秘密共享和 B. 门限密码学
- en: 'The following code snippet demonstrates how to use the `mpyc` library to determine
    an aircraft’s location in a private manner using five sensors. Each sensor communicates
    using SMPC to share secrets for encrypting confidential information such as the
    location and time of arrival of the aircraft:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段演示了如何使用`mpyc`库，通过五个传感器以隐私方式确定飞机的位置。每个传感器使用SMPC通信，通过共享秘密来加密敏感信息，如飞机的位置信息和到达时间：
- en: '[PRE16]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Having understood different encryption methodologies used in multi-party communications
    and in the process of ML model training, let's try to understand how we can employ
    application-level privacy techniques during the training phase of a model.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了多方通信中使用的不同加密方法以及机器学习模型训练过程中使用的隐私保护技术后，接下来让我们探讨如何在模型的训练阶段应用应用层隐私技术。
- en: Differential Privacy (DP)
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 差分隐私（DP）
- en: DP is a popular application-level privacy-enabling framework used to protect
    private or sensitive data on large datasets. This method guarantees an almost
    identical output when a statistical query is executed on two nearly identical
    datasets that differ only by the presence or absence of one record.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私（DP）是一种流行的应用层隐私保护框架，用于保护大型数据集中的私密或敏感数据。当在两个几乎相同的数据集上执行统计查询时，该方法保证几乎相同的输出，这两个数据集只在一个记录的存在与否上有所不同。
- en: DP provides security against record linkage attacks by hiding the influence
    of any single record (for example, individual PII) or records of small groups
    of users in the predicted outcomes. The process of anonymization and protecting
    the availability of information related to the presence or absence of individual
    records in the data-training process is closely associated with the privacy of
    data against linkage attacks. The cumulative loss is defined as the *privacy budget*
    and is called **epsilon** (**ε**), which represents the quantifiable amount of
    privacy provided, where a low value signifies a high level of privacy. The loss
    is also associated with a decrease in utility (accuracy), and it is the task of
    the data scientist to arrive at an acceptable trade-off between the two.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私通过隐藏任何单一记录（例如，个人可识别信息（PII））或小群体用户记录对预测结果的影响，提供抵御记录连接攻击的安全性。数据训练过程中对个体记录存在与否的匿名化以及信息可用性的保护，与数据隐私和防止连接攻击密切相关。累积损失定义为*隐私预算*，也称为**ε**（**ε**），表示提供的隐私量，其中低值表示高隐私级别。损失还与效用（准确性）的下降相关，数据科学家的任务是找到两者之间的可接受平衡。
- en: '*Figure 2**.10* illustrates a **Stochastic Gradient Descent** (**SGD**)-enabled
    DP training process, the computation of the loss function, the addition of random
    noise, and the clipping of gradients in successive iterations. When examining
    the diagram, note the following:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.10* 展示了一个启用**随机梯度下降**（**SGD**）的差分隐私（DP）训练过程，损失函数的计算、随机噪声的添加以及梯度的裁剪在连续迭代中的过程。当查看该图时，请注意以下几点：'
- en: A randomly sampled set of data points has been used for training (from two different
    datasets, *D*1 and *D*2, both ∈ to *S*, and differing in only one record).
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用了从两个不同数据集（*D*1 和 *D*2，均∈ *S* 且仅在一条记录上有所不同）中随机抽取的数据点进行训练。
- en: The training error (or training loss) is computed from the model’s predicted
    output and the training labels in successive steps are then differentiated with
    respect to the model’s parameters.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练误差（或训练损失）是根据模型的预测输出和训练标签计算的，在后续步骤中，训练标签相对于模型参数进行求导。
- en: The process continues iteratively where the computed gradients (using SGD) are
    applied to the model’s parameters, taking into consideration the impact left by
    every point in the resultant gradient.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该过程是迭代进行的，计算出的梯度（使用SGD）应用于模型的参数，同时考虑到每个点在结果梯度中所留下的影响。
- en: The impact of every gradient is controlled by clipping (or bounding) the gradients.
    The certainty of inferring a point’s inclusion in the dataset is diminished through
    the process of randomization where noise is added to every data point.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个梯度的影响通过裁剪（或界定）梯度来控制。通过随机化过程，向每个数据点添加噪声，从而减少推断某个点是否包含在数据集中的确定性。
- en: Once the model converges, the final gradient is computed to derive the privacy
    estimate, such that *O*1 – *O*2 < ε.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦模型收敛，计算最终的梯度以推导隐私估计，使得*O*1 – *O*2 < ε。
- en: "![Figure 2.1\uFEFF0 – Training models with \uFEFFDP on two input datasets\uFEFF\
    , D1 and D2](img/Figure_2.10_B18681.jpg)"
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.10 – 在两个输入数据集 D1 和 D2 上使用差分隐私训练模型](img/Figure_2.10_B18681.jpg)'
- en: Figure 2.10 – Training models with DP on two input datasets, D1 and D2
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 使用差分隐私在两个输入数据集 D1 和 D2 上训练模型
- en: 'The following code snippet illustrates the necessary imports, including IBM’s
    `Diffprivlib`, used for training DP-based models. The first step involves having
    the necessary imports of libraries and fetching the `adult_income` dataset from
    the web, where for `X_train` we only use columns 0, 4, 10, 11, and 12, and for
    `y_train` we use the column specified as income <=50K or >50K:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了必要的导入，包括 IBM 的 `Diffprivlib`，用于训练基于差分隐私的模型。第一步是导入必要的库，并从网上获取 `adult_income`
    数据集，对于 `X_train`，我们只使用第 0、4、10、11 和 12 列，对于 `y_train`，我们使用标记为 income <=50K 或 >50K
    的列：
- en: '[PRE17]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The next code snippet illustrates how we can incorporate DP in different components
    of a pipeline such as `StandardScaler`, `PCA`, and `LogisticRegression`. The initial
    step involves scaling the feature attributes followed by dimensionality reduction
    and ML model classification.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个代码片段展示了如何在管道的不同组件中结合差分隐私，如 `StandardScaler`、`PCA` 和 `LogisticRegression`。初步步骤涉及缩放特征属性，然后进行降维和机器学习模型分类。
- en: 'The `data_norm` parameter quantifies the Laplace-distributed random noise that
    we added in order to yield a differentially private ML model. The `bounds` parameter
    defines the bounds of the data and takes in a tuple value as *min, max,* where
    these two entries represent scalars after being aggregated at a feature level.
    From *Figure 2**.11*, it is further evident that accuracy is oscillating, with
    ε ranging from 10-3 to 10-1.5, after which accuracy becomes stable. This observation
    reinforces our discovery that selecting an acceptable trade-off value between
    accuracy and utility is needed to add a higher privacy margin without compromising
    accuracy:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`data_norm` 参数量化了我们添加的拉普拉斯分布随机噪声，用于生成差分隐私的机器学习模型。`bounds` 参数定义了数据的边界，并以 *min,
    max* 的元组值作为输入，这两个值代表在特征级别聚合后的标量。从 *图 2.11* 中可以进一步看出，准确度在 ε 从 10^-3 到 10^-1.5 的范围内波动，此后准确度变得稳定。这一观察结果进一步强化了我们的发现：在不影响准确度的情况下，选择准确度与效用之间的可接受权衡值，以增加更高的隐私边际是必要的。'
- en: '[PRE18]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, when we plot the results, we get the following graph demonstrating the
    variation of accuracy with ε:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们绘制结果时，我们得到以下图表，展示了准确度与 ε 的变化关系：
- en: "![ Figure 2.1\uFEFF1 – A DP-enabled pipeline exhibiting \uFEFFthe accuracy\
    \ and privacy-budget (ε) trade-off](img/Figure_2.11_B18681.jpg)"
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.11 – 一个展示准确度和隐私预算（ε）权衡的差分隐私管道](img/Figure_2.11_B18681.jpg)'
- en: Figure 2.11 – A DP-enabled pipeline exhibiting the accuracy and privacy-budget
    (ε) trade-off
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 一个展示准确度和隐私预算（ε）权衡的差分隐私管道
- en: By now, we have understood how ε serves as an important metric to measure the
    expected privacy of a DP model. Now, let's try to understand the second most important
    metric, sensitivity.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经理解了 ε 作为衡量差分隐私（DP）模型期望隐私性的重要指标。现在，让我们尝试理解第二个最重要的指标——敏感性。
- en: Sensitivity
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 敏感性
- en: 'Sensitivity is deﬁned as the maximum inﬂuence exerted by a single data record
    on the differential private result in response to a numeric query. For any arbitrary
    function *f*, the sensitivity *∆f* of *f*, on *x* and *y*, two neighboring datasets,
    can be given as follows:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感性被定义为单个数据记录对响应数字查询的差分隐私结果产生的最大影响。对于任何任意的函数 *f*，在两个相邻数据集 *x* 和 *y* 上，*f* 的敏感性
    *∆f* 可以如下表示：
- en: Δ*f* = *max* { || *f*(*x*) – *f*(*y*) ||1 }, where ||.||1 represents the L1
    norm of a vector
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: Δ*f* = *max* { || *f*(*x*) – *f*(*y*) ||1 }，其中 ||.||1 表示向量的 L1 范数
- en: Properties of DP
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DP 的属性
- en: 'DP solutions possess essential properties of postprocessing:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私解决方案具有后处理的基本属性：
- en: Invariance/robustness
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不变性/鲁棒性
- en: Quantifiability
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可量化性
- en: Composition
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组合性
- en: The invariance/robustness of DP ensures additional computations executed on
    ε-DP solutions are also ε-DP. Additionally, the quantifiability property of DP
    allows the flexibility of being transparent (to the data scientist). Transparency
    reveals the exact quantity of noise/perturbation caused by the randomization process.
    This characteristic feature of DP algorithms gives them an extra edge over other
    traditional de-identification algorithms. The traditional algorithms hide the
    process by which the data was transformed, so data scientists cannot interpret
    and analyze the accuracy of such models. Further, with the composition property,
    it is possible to derive the amount of degradation in privacy by executing different
    DP algorithms on overlapping datasets. For example, two DP algorithms executed
    on ε1-DP and ε2-DP that overlap are DP private and given by (ε1+ε2)-DP.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: DP的不可变性/鲁棒性确保对ε-DP解决方案执行的额外计算也是ε-DP的。此外，DP的可量化特性使得其具有透明性的灵活性（对于数据科学家）。透明性揭示了随机化过程中噪声/扰动的确切数量。DP算法的这一特征使其在其他传统去标识化算法中具有额外的优势。传统算法隐藏了数据转换过程，因此数据科学家无法解释和分析这些模型的准确性。此外，借助合成特性，可以通过对重叠数据集执行不同的DP算法来推导隐私的降级量。例如，在ε1-DP和ε2-DP上执行的两个DP算法是DP私密的，其组合为(ε1+ε2)-DP。
- en: We have now become familiar with different privacy- and security-enabled measures
    that can be used during model training and inference. However, each of these methods
    has its own specific advantages, and the entire system can only get the full benefit
    from a hybrid security-enabled system.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经熟悉了在模型训练和推理过程中可以使用的各种隐私和安全措施。然而，这些方法各有其特定的优势，整个系统只有在混合安全支持的系统中才能充分发挥其效益。
- en: Hybrid privacy methods and models
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合隐私方法和模型
- en: '*Figure 2**.12* illustrates the integration of varying levels of the privacy
    components discussed in the previous sections to create a fully proofed privacy-preserving
    AI system. There are two different labels associated with **2** and **5**, where
    **2** and **5** denote access by model owners, while **2’** and **5’** denote
    access by adversaries where they craft adversarial data to steal important model
    information.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2**.12*展示了前面章节中讨论的不同隐私组件级别的集成，以创建一个完全经过验证的隐私保护AI系统。**2**和**5**与模型所有者的访问相关，而**2’**和**5’**则与对抗者的访问相关，他们通过构造对抗数据来窃取重要的模型信息。'
- en: The system can ingest data from multiple heterogeneous devices (**1** and **2**)
    before triggering different algorithmic training (**3**, **6**, and **8**). Such
    a hybrid system can ensure data and algorithm sovereignty, in addition to adhering
    to ethics, compliance, transparency, and the trustworthiness of applications.
    The main objective is to have a robust ethical defense framework in place that
    can protect a single data record from identity or **Membership Inference Attacks
    (MIAs)** by identifying its presence in the dataset (**2’**).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 系统可以从多个异构设备中摄取数据（**1**和**2**），然后触发不同的算法训练（**3**、**6**和**8**）。这种混合系统不仅可以确保数据和算法的主权，还可以遵守伦理、合规、透明性和应用程序的可信度。主要目标是建立一个强大的伦理防御框架，保护单个数据记录免受身份或**成员推断攻击（MIAs）**的影响，通过识别其在数据集中的存在（**2’**）。
- en: This is addressed by having a private AI unit that encompasses the task of adding
    application-level privacy through DP (during model training or post-model convergence),
    anonymization, and pseudonymization (*Figure 2**.12*) to protect the data. Here,
    the random noise and regularization added by DP algorithms (trained with SGD or
    private aggregation of teacher ensembles) can increase resilience against inversion
    attacks.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 这一问题通过拥有一个私有AI单元来解决，该单元负责通过DP（在模型训练过程中或模型收敛后）添加应用层隐私、匿名化和假名化（*图2**.12*）以保护数据。在这里，DP算法（使用SGD或教师集的私有聚合训练）的随机噪声和正则化可以增强抵御反转攻击的能力。
- en: As we studied previously, anonymization and pseudonymization still leave room
    for de-identification processes through feature re-derivation and re-identification
    (**2’**) where an attacker is able to break into look-up tables. Therefore, additional
    security measures need to be adopted to safeguard insecure storage.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所学，匿名化和假名化仍然为通过特征重新推导和重新识别（**2’**）提供了去标识化过程的空间，攻击者可以突破查找表。因此，需要采用额外的安全措施来保护不安全的存储。
- en: "![Figure 2.1\uFEFF2 – Application of different privacy measures in a hybrid\
    \ privacy framework](img/Figure_2.12_B18681.jpg)"
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: "![图 2.1\uFEFF2 – 在混合隐私框架中应用不同的隐私措施](img/Figure_2.12_B18681.jpg)"
- en: Figure 2.12 – Application of different privacy measures in a hybrid privacy
    framework
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – 在混合隐私框架中应用不同的隐私措施
- en: To safeguard lookup-table-related risks, AI research has concentrated on decentralization
    where remote execution becomes the central mechanism to train a global model.
    Locally trained ML models with their weights, parameters, and data (from mobile,
    **Internet of Things** (**IoT**), and **Internet of Medical Things** (**IoMT**)
    devices) are updated to a central repository to aggregate the model at a global
    level. However, the local model’s weights still run the risk of being corrupted
    by adversaries either by the modification of transmitted parameters through poisoning
    or model-inversion/reconstruction attacks (**5’**) where SMPC and HE can be employed
    to best tackle the existing threats.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保护查找表相关的风险，人工智能研究集中于去中心化，其中远程执行成为训练全球模型的核心机制。通过将本地训练的机器学习（ML）模型及其权重、参数和数据（来自移动设备、**物联网**（**IoT**）和**医疗物联网**（**IoMT**）设备）更新到中央库，从而在全球层面聚合模型。然而，本地模型的权重仍然面临被对手通过中毒或模型反演/重建攻击（**5'**）修改传输参数的风险，在这种情况下可以使用安全多方计算（SMPC）和同态加密（HE）来有效应对现有的威胁。
- en: The decentralized approach to data training in a federation topology is revolutionizing
    the privacy landscape in the AI industry as devices are able to retain their sovereignty
    while participating in the gossip strategy. The flexibility of joining in the
    training process (by limiting their continuous availability) to share model parameters
    with peer nodes helps devices to sustain battery life for longer durations. It
    gives a broader scope of application to this federated mode of training in addition
    to data and model governance capabilities, where the tracking/auditing of the
    times that each device sends model parameters, convergence, and performance metrics
    can be monitored.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦拓扑中的数据训练去中心化方法正在革命性地改变人工智能行业的隐私格局，因为设备在参与消息传递策略时能够保持主权。通过限制设备持续可用性，参与训练过程并与对等节点共享模型参数，帮助设备在较长时间内维持电池寿命。这不仅为这种联邦训练模式提供了更广泛的应用范围，还增强了数据和模型治理能力，其中可以监控每个设备发送模型参数的时间、收敛情况和性能指标。
- en: '**FL** carries the underlying risk of model parameters and PII being stolen
    or reconstructed by adversaries in the absence of encryption techniques, from
    the nodes and communicating interfaces. Hence, local algorithms need to be encrypted
    and securely aggregated where HE can be employed (with or without DP) to securely
    aggregate encrypted algorithms. Another viable risk arising from neural networks
    is their compressed representation. Such compressed formats are achieved by applying
    either one of the following mechanisms: pruning the convolutional layers, quantization,
    tensor decomposition, knowledge distillation, or a combination of all the stated
    methods.Without encryption, attackers will find it easy to execute model inversion
    or reconstruction attacks and retrieve confidential model parameters with high
    accuracy.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '**FL** 带来了在没有加密技术的情况下，模型参数和个人身份信息（PII）可能被对手从节点和通信接口中窃取或重建的潜在风险。因此，本地算法需要加密并安全地聚合，在这种情况下可以使用同态加密（HE）（有或没有差分隐私DP）来安全地聚合加密的算法。神经网络带来的另一个可行风险是它们的压缩表示。这种压缩格式是通过应用以下机制之一实现的：剪枝卷积层、量化、张量分解、知识蒸馏，或者是所有上述方法的组合。如果没有加密，攻击者将容易执行模型反演或重建攻击，并以高精度恢复机密的模型参数。'
- en: 'You can read more on knowledge distillation at *Knowledge Distillation: Principles,
    Algorithms, Applications*: [https://neptune.ai/blog/knowledge-distillation](https://neptune.ai/blog/knowledge-distillation)
    and about quantization at *Pruning and Quantization for Deep Neural Network Acceleration*:
    A Survey, [https://arxiv.org/pdf/2101.09671.pdf](https://arxiv.org/pdf/2101.09671.pdf)'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在*知识蒸馏：原理、算法、应用*中阅读更多关于知识蒸馏的内容：[https://neptune.ai/blog/knowledge-distillation](https://neptune.ai/blog/knowledge-distillation)，关于量化的内容请参阅*深度神经网络加速的剪枝与量化：综述*，[https://arxiv.org/pdf/2101.09671.pdf](https://arxiv.org/pdf/2101.09671.pdf)
- en: The solution is further extended to include secure multi-party computation to
    multiple participating entities where each of them receives a split of encrypted
    data to proceed with further processing. This decentralization approach removes
    the risk of complete data exposure or leakage to participating candidates, allowing
    data recovery only through the method of mutual consensus. SMC also works in semi-trusted
    and low-trust environments, but one of the requirements of this method is continuous
    data transfer between parties and the continuous online availability of devices,
    leading to additional communication overheads. This acts as a limitation on the
    reliability, redundancy, and scalability of the system, but can be overcome by
    designing appropriate sleep and wake cycles for devices, discussed more in [*Chapter
    11*](B18681_11.xhtml#_idTextAnchor232). Data scientists should employ a holistic
    approach, incorporating all the privacy measures discussed to validate the integrity
    and quality of predicted ML results.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 该解决方案进一步扩展，包含了安全的多方计算，涉及多个参与实体，每个实体接收加密数据的一部分，以便进行后续处理。这种去中心化的方法消除了完全数据暴露或泄漏的风险，只有通过互相一致的方法才能恢复数据。SMC也适用于半信任和低信任环境，但该方法的一个要求是各方之间持续的数据传输和设备的持续在线可用性，从而导致额外的通信开销。这对系统的可靠性、冗余性和可扩展性构成了限制，但可以通过为设备设计适当的休眠和唤醒周期来克服，更多内容将在[*第11章*](B18681_11.xhtml#_idTextAnchor232)中讨论。数据科学家应采用整体方法，结合所有讨论的隐私措施来验证预测的机器学习结果的完整性和质量。
- en: Adversarial risk mitigation frameworks
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗性风险缓解框架
- en: In this section, let's walk through some of the newly evolving risk mitigation
    frameworks concerning specific scenarios of input data distribution or model architecture
    when the model is used for training and serving. These frameworks are highly successful
    in curbing real-world attacks. One example is the identification of diseases where
    clinical datasets have been used to train the associated model. In such cases,
    an attacker can infer from a clinical record that a given patient has a specific
    disease with a high probability of success.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将讨论一些新兴的风险缓解框架，这些框架针对模型在训练和服务过程中使用时，输入数据分布或模型架构的特定场景。这些框架在遏制现实世界攻击方面取得了很大的成功。一个例子是疾病识别，其中临床数据集被用于训练相关模型。在这种情况下，攻击者可以通过临床记录推断出某个病人可能患有特定疾病，并且有较高的成功率。
- en: Let's now discuss how we can evaluate model risk for **MIAs**, where adversaries
    are able to copy the principal model functionality and trigger adversarial attacks.
    MIAs can be either black box or white box. In black-box attacks, the attacker
    knows only the model inputs and can only query the model’s predicted output label,
    whereas in white-box attacks, the attacker has knowledge of the model inputs,
    architecture, and model internals such as weights, biases, and other coefficient
    values.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论如何评估**MIA**的模型风险，其中对手能够复制主模型功能并触发对抗性攻击。MIA可以是黑盒攻击或白盒攻击。在黑盒攻击中，攻击者只知道模型输入，并且只能查询模型的预测输出标签；而在白盒攻击中，攻击者知道模型的输入、架构以及模型的内部信息，如权重、偏置和其他系数值。
- en: The goal of MIAs is to infer whether a given data record is in the target dataset.
    To construct the MIA model, a shadow training technique is applied to generate
    the ground truth for membership inference. *Figure 2**.13* shows an overview of
    MIAs.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: MIA（成员推断攻击）的目标是推测给定的数据记录是否属于目标数据集。为了构建MIA模型，采用影像训练技术生成成员推断的真实标签。*图 2**.13* 显示了MIA的概述。
- en: MIAs enable an attacker to determine the presence of a specific data point *z*
    in the training set of a target model *a*. When this attack takes place on a model
    trained with sensitive data, evaluating an individual’s presence in the dataset
    will expose confidential information to an attacker. MIAs achieve high performance
    on **Independent and** **Identically Distributed** data(**IID**), thereby completely
    ignoring the fact that data dependencies in training samples underestimate the
    attack performance. This suggests a new direction of research to evaluate vulnerabilities
    and devise defense techniques for correlated data to protect sensitive information.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: MIAs使攻击者能够确定目标模型*a*的训练集中是否存在特定数据点*z*。当这种攻击发生在使用敏感数据训练的模型上时，评估个体在数据集中的存在将暴露攻击者敏感的个人信息。MIAs在**独立同分布（IID）**数据上表现出色，完全忽视了训练样本中的数据依赖关系，这低估了攻击的表现。这表明，研究应朝着评估漏洞并为相关数据制定防御技术的方向发展，以保护敏感信息。
- en: Hence, there is a need for a risk mitigation technique that can evaluate and
    label ML models where such data dependencies exist (such as, for example, the
    effect of all members being from a specific health region (or hospital) and non-members
    from all other regions, or when both originate from the same source). To evaluate
    such associated risks, this framework could be used to access/test the model’s
    behavior under MIAs when data dependencies exist, and models are prone to correct
    membership inference outcomes. For example, with MIAs, the model is able predict
    whether people of the same racial background are likely to suffer from a disease.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，需要一种风险缓解技术，可以评估和标注存在此类数据依赖关系的机器学习模型（例如，所有成员来自某个特定健康区域（或医院），而非成员来自其他所有区域，或当两者都来自相同来源时）。为了评估这种关联风险，可以使用该框架来访问/测试模型在数据依赖关系存在且模型容易正确推断成员资格时的行为。例如，在MIAs的情况下，模型能够预测来自相同种族背景的人是否可能患有某种疾病。
- en: This risk assessment framework first uses public data to train a set of shadow
    models that can emulate/mimic the target model’s functionality. In the next step,
    an attack model is trained to reveal the membership status of a sample using outputs
    from the shadow models. Before the identification phase begins, the dataset can
    be split between members and non-members (for example, through a clustering algorithm).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 该风险评估框架首先使用公共数据训练一组影子模型，模仿/模拟目标模型的功能。在下一步中，训练一个攻击模型，利用影子模型的输出揭示样本的成员资格状态。在识别阶段开始之前，可以通过将数据集分为成员和非成员（例如，通过聚类算法）来进行划分。
- en: In the following code snippet, we have used the `adult_income` dataset to train
    a shadow model (80% training and 20% test data split) with a CNN. The shadow and
    attack models are trained using the same dataset after dividing the dataset equally
    between the two halves. The purpose of this framework is to measure the effectiveness
    of DP against MIAs. We can conduct MIAs on the best target models and evaluate
    the protection offered by DP for different values of privacy budget, noise multiple,
    and regularization.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码片段中，我们使用`adult_income`数据集来训练一个影子模型（80%用于训练，20%用于测试数据拆分），并采用CNN方法。影子模型和攻击模型使用相同的数据集，在将数据集平分成两部分后进行训练。这个框架的目的是衡量差分隐私（DP）对MIAs的有效性。我们可以在最佳目标模型上进行MIAs，并评估DP在不同隐私预算、噪声倍数和正则化值下提供的保护效果。
- en: "![Figure 2.13\uFEFF – Measuring model robustness against MIAs with DP-enabled\
    \ training](img/Figure_2.13_B18681.jpg)"
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.13 – 使用启用差分隐私（DP）训练的模型来衡量针对MIAs的模型鲁棒性](img/Figure_2.13_B18681.jpg)'
- en: Figure 2.13 – Measuring model robustness against MIAs with DP-enabled training
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – 使用启用差分隐私（DP）训练的模型来衡量针对MIAs的模型鲁棒性
- en: As illustrated in *Figure 2**.13*, the shadow model we employed here depends
    on the target model’s architecture and weights. Hence, having a white-box model
    attack in place makes our job easy, as the same architecture and hyperparameters
    can be reused from the target model. The shadow model is trained on the shadow
    dataset to follow the target model and generate the ground truth data required
    to train the attack model. The shadow model’s probability output is aggregated
    with the true labels to generate the attack dataset, where input to the attack
    dataset is labeled as `in` or `out` based on the condition of whether it is used
    to train the shadow model.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图2.13*所示，我们这里使用的影子模型依赖于目标模型的架构和权重。因此，拥有一个白盒模型攻击可以简化我们的工作，因为可以从目标模型中重用相同的架构和超参数。影子模型在影子数据集上训练，以跟踪目标模型并生成训练攻击模型所需的真实标签数据。影子模型的概率输出与真实标签结合，生成攻击数据集，其中攻击数据集的输入根据是否用于训练影子模型，标记为`in`或`out`。
- en: 'We get approximately 50% attack accuracy since the data source of the train
    and test sets remains the same. However, the attack accuracy would decrease if
    the private training dataset for the target model were not overlapping with the
    public dataset that trains the shadow model. This MIA attack model has been trained
    using `RandomForestClassifier`. Attack models could be executed to perform attacks
    *n* times:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练集和测试集的数据来源相同，因此攻击准确率大约为50%。但是，如果目标模型的私有训练数据集与训练影子模型的公共数据集不重叠，攻击准确率将会降低。这个MIA攻击模型已经使用`RandomForestClassifier`进行了训练。攻击模型可以执行多次攻击，执行次数为*n*：
- en: 'Our first step is to create an instance of a shadow model using the shadow
    dataset:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的第一步是使用影子数据集创建一个影子模型实例：
- en: '[PRE19]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the next step, we train the shadow models with the same parameters as the
    target model and generate the attack data:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，我们使用与目标模型相同的参数训练影子模型，并生成攻击数据：
- en: '[PRE20]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After training the shadow models, we train the attack model using `RandomForestClassifer`:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练完影子模型后，我们使用`RandomForestClassifier`训练攻击模型：
- en: '[PRE21]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The next step involves evaluating the success of the attack. To do so, we segregate
    the data points used in the training and those that were not present during training
    for both independent and target variables:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是评估攻击的成功与否。为此，我们将用于训练的数据点与未在训练中出现的数据点进行区分，并对独立变量和目标变量分别进行处理：
- en: '[PRE22]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The final step involves computing the attack accuracy of the attack test data
    by comparing the predicted outcomes of the attack model with the membership labels.
    The attack data is prepared in the expected format for `AttackModelBundle`:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是通过比较攻击模型的预测结果与成员标签，来计算攻击测试数据的攻击准确率。攻击数据已按照`AttackModelBundle`的预期格式进行准备：
- en: '[PRE23]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Both the models are trained with DP, with `DPKerasSGDOptimizer`, which is an
    optimizer built over `SGDOptimizer` for DP. `noise_multiplier` is a parameter
    supplied to the optimizer to control how much noise is sampled and added to gradients.
    The `steps` parameter represents the number of steps/epochs the optimizer takes
    over the training data, whereas the `l2_norm_clip` parameter provides a mechanism
    to tune the optimizer’s sensitivity to individual training points, by considering
    the maximum Euclidean norm of each individual gradient from the mini-batch:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个模型都是通过DP训练的，使用的是`DPKerasSGDOptimizer`，它是一个基于`SGDOptimizer`的优化器，用于DP。`noise_multiplier`是一个传递给优化器的参数，用来控制采样并添加到梯度中的噪声量。`steps`参数表示优化器在训练数据上执行的步数/训练轮数，而`l2_norm_clip`参数提供了一种机制，通过考虑每个mini-batch中单个梯度的最大欧几里得范数，来调节优化器对单个训练点的敏感度：
- en: '[PRE24]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The first step is to set the optimizer as shown in the previous code snippet.
    The next step is to compute a vector of per-example loss rather than its mean
    over a mini-batch. As demonstrated in the next code snippet, we compile the model
    loss with the model classifier using Keras:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一项任务是按照前面的代码片段设置优化器。接下来，我们计算每个样本的损失向量，而不是其在一个mini-batch中的平均值。如下一个代码片段所示，我们使用Keras将模型损失与模型分类器进行编译：
- en: '[PRE25]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The computation of epsilon is given in the next code snippet. The sampling probability
    is computed using `batch_size` and the inverse of the input data size (which is
    the delta) and is approximately 50,000 in the input dataset. The probability metric
    represents the probability of an individual training point being included in a
    mini-batch, which is then used with the noise multiplier to evaluate `rdp` and
    finally in the computation of epsilon. This is the final model metric that can
    be used to judge the privacy guarantee by considering how much the probability
    of a particular model output can vary by including (or removing) a single training
    record sample. The concept of micro-batches was introduced in `tensorflow_privacy`
    ([https://github.com/tensorflow/privacy](https://github.com/tensorflow/privacy))
    to facilitate faster processing by providing a degree of parallelism where gradients
    no longer remain to be clipped on a per-sample basis, but rather clipped at a
    micro-batch granularity.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: epsilon 的计算在下一个代码片段中给出。采样概率是使用 `batch_size` 和输入数据大小的倒数（即 delta）计算的，输入数据集中的大小约为
    50,000。概率指标表示单个训练点被包含在小批次中的概率，之后与噪声倍增器一起用于评估 `rdp`，最终用于计算 epsilon。这是可以用来判断隐私保障的最终模型指标，通过考虑单个训练记录样本的包含（或去除）如何影响特定模型输出的概率变化。微批次的概念是在
    `tensorflow_privacy` 中引入的（[https://github.com/tensorflow/privacy](https://github.com/tensorflow/privacy)），通过提供一定程度的并行性来促进更快的处理，在这种方式下，梯度不再按样本逐个裁剪，而是以微批次为粒度进行裁剪。
- en: 'This process can clip 32 gradients averaged over micro-batches, with each micro-batch
    having 8 data samples:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程可以对微批次中平均的32个梯度进行裁剪，每个微批次包含8个数据样本：
- en: '[PRE26]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '*Table 2.5* represents a study on epsilon, noise multipliers, and metrics from
    attack models. When the value of the noise multiplier increases, epsilon decreases,
    which means there is an increase in the privacy budget. Though most of the attack
    model metrics remain constant, a decrease of 1% in attack accuracy is noticed
    when epsilon decreases from 1.2203 to 0.3283, which reinforces the fact that higher
    privacy increases the robustness of the model to attacks (at least to some extent).
    The attack metrics also exhibit low precision and high recall, signifying the
    presence of more false positives (records that are identified to be coming from
    the training dataset, but they are not) and correct identification of the relevant
    record’s presence in the training dataset. However, models trained with DP are
    not strong enough to provide protection from MIAs, particularly when the data
    is correlated.'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 2.5* 展示了关于 epsilon、噪声倍增器和攻击模型指标的研究。当噪声倍增器的值增加时，epsilon 会减少，这意味着隐私预算会增加。尽管大多数攻击模型指标保持不变，但当
    epsilon 从 1.2203 减少到 0.3283 时，攻击准确率下降了 1%。这一点进一步证明了更高的隐私性增强了模型对攻击的鲁棒性（至少在某种程度上）。攻击指标还显示出低精度和高召回率，这意味着存在更多的假阳性（即被误认为来自训练数据集的记录，实际上并非如此）以及正确识别出相关记录在训练数据集中的存在。然而，使用差分隐私（DP）训练的模型仍然不足以抵御
    MIA（模型反向推断攻击），尤其是在数据相关时。'
- en: '| **Epsilon** | **Noise Multiplier** | **Attack Metrics** |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| **Epsilon** | **噪声倍增器** | **攻击指标** |'
- en: '| 1.2203 | 0.8 | Attack accuracy: 0.5023300438596491Precision: 0.5012701733413031Recall:
    0.9195449561403509 |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 1.2203 | 0.8 | 攻击准确率：0.5023300438596491 精度：0.5012701733413031 召回率：0.9195449561403509
    |'
- en: '| 0.6952 | 1.0 | Attack accuracy: 0.5006167763157895Precision: 0.5004499550044995Recall:
    0.6859923245614035 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 0.6952 | 1.0 | 攻击准确率：0.5006167763157895 精度：0.5004499550044995 召回率：0.6859923245614035
    |'
- en: '| 1.2203 | 1.2 | Attack accuracy: 0.5023300438596491Precision: 0.5012701733413031Recall:
    0.9195449561403509 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 1.2203 | 1.2 | 攻击准确率：0.5023300438596491 精度：0.5012701733413031 召回率：0.9195449561403509
    |'
- en: '| 0.3283 | 1.4 | Attack accuracy: 0.49828673245614036Precision: 0.4988314480695522Recall:
    0.731359649122807 |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 0.3283 | 1.4 | 攻击准确率：0.49828673245614036 精度：0.4988314480695522 召回率：0.731359649122807
    |'
- en: '| 0.2523 | 1.6 | Attack accuracy: 0.49828673245614036Precision: 0.49885352655232507Recall:
    0.7454769736842105 |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 0.2523 | 1.6 | 攻击准确率：0.49828673245614036 精度：0.49885352655232507 召回率：0.7454769736842105
    |'
- en: '| 0.20230 | 1.8 | Attack accuracy: 0.49897203947368424Precision: 0.49929158401813545Recall:
    0.7245065789473685 |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 0.20230 | 1.8 | 攻击准确率：0.49897203947368424 精度：0.49929158401813545 召回率：0.7245065789473685
    |'
- en: '| 0.16715 | 2.0 | Attack accuracy: 0.49780701754385964Precision: 0.49852643212377973Recall:
    0.7419133771929824 |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 0.16715 | 2.0 | 攻击准确率：0.49780701754385964 精度：0.49852643212377973 召回率：0.7419133771929824
    |'
- en: Table 2.5 – A table showing variation of epsilon and noise multiplier
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.5 – 显示 epsilon 和噪声倍增器变化的表格
- en: Model robustness
  id: totrans-416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型鲁棒性
- en: Model robustness is a measure of the model performance taking into account indistinguishable
    changes in the model inputs. Different perturbation techniques help us to compare
    and benchmark the ML models against their robustness metrics. The Python package
    **Foolbox** ([https://arxiv.org/pdf/1907.06291.pdf](https://arxiv.org/pdf/1907.06291.pdf))
    helps to determine model robustness by generating adversarial perturbations. This
    is built on the fact that the minimal perturbation that generates an adversarial
    sample when applied to any model input (such as an image) helps to quantify a
    model’s robustness to the pre-fed adversarial samples, and demonstrates a model’s
    susceptibility to adversarial attacks. The flexibility provided by the framework
    to apply hyperparameter tuning helps to evaluate the minimal adversarial perturbation,
    resulting in misclassification in the predicted class probabilities in the output.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的鲁棒性是衡量模型性能的标准之一，它考虑到模型输入中不可区分的变化。不同的扰动技术帮助我们比较和基准测试机器学习模型在鲁棒性指标上的表现。Python
    包 **Foolbox** ([https://arxiv.org/pdf/1907.06291.pdf](https://arxiv.org/pdf/1907.06291.pdf))
    通过生成对抗扰动来帮助确定模型的鲁棒性。这是基于一个事实，即当应用最小扰动生成对抗样本时（例如，图像），它有助于量化模型对预先输入的对抗样本的鲁棒性，并展示模型对对抗攻击的易受攻击性。该框架提供的灵活性使得超参数调整成为可能，从而帮助评估最小对抗扰动，导致输出中的预测类别概率发生误分类。
- en: 'To run different attacks using this toolbox, we need an input, its label, a
    model, the adversarial criterion, and a distance parameter that measures the length
    of a perturbation, called the *L*1 norm. We can also mix and match using the composite
    model feature, where the predictions of one model can be combined with the gradient
    of another model, allowing us to initiate non-differentiable models by leveraging
    gradient-based attacks. The tool provides several criteria outlined in the following
    list to initiate attacks where a given input and label can be considered adversarial:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用该工具箱进行不同的攻击，我们需要输入、标签、模型、对抗准则以及衡量扰动长度的距离参数，称为 *L*1 范数。我们还可以通过复合模型功能进行组合与匹配，其中一个模型的预测结果可以与另一个模型的梯度结合，从而允许我们通过利用基于梯度的攻击启动不可微分的模型。该工具提供了多个准则，用于启动攻击，在这些准则下，给定的输入和标签可以被视为对抗样本：
- en: '**Misclassification**: Wrong predicted class at model output'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Misclassification**：模型输出中错误的预测类别'
- en: '**TopKMisclassification**: Modification of adversarial inputs in such a way
    as to alter the original class so it is different from one of the top-k predicted
    classes'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TopKMisclassification**：修改对抗输入，以改变原始类别，使其与前k个预测类别之一不同'
- en: '**OriginalClassProbability**: Modification of adversarial inputs to alter the
    probability of the original class being below a specified threshold'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OriginalClassProbability**：修改对抗输入，使原始类别的概率低于指定的阈值'
- en: '**TargetedMisclassification**: Modification of adversarial inputs to make the
    predicted class appear as the target class'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TargetedMisclassification**：修改对抗输入，使得预测类别变为目标类别'
- en: '**TargetClassProbability**: Modification of adversarial inputs to increase
    the probability of a target class beyond a threshold value'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TargetClassProbability**：修改对抗输入，以增加目标类别的概率超过阈值'
- en: 'Now let''s study, with the following code snippet, the necessary imports that
    can trigger an adversarial attack on a PyTorch reset model:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过以下代码片段来研究必要的导入，这些导入可以触发对 PyTorch 重置模型的对抗攻击：
- en: '[PRE27]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After doing the necessary imports, let''s trigger the attack as follows:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成必要的导入后，让我们如下触发攻击：
- en: '[PRE28]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here, in the preceding example, we observe the following:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们观察到以下情况：
- en: We demonstrate a few attacks including **Fast Gradient Sign Method** (**FGSM**)
    (added noise for perturbation is on the same side as the gradient of the cost
    function)
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们展示了几种攻击，包括 **快速梯度符号方法** (**FGSM**)（扰动所加的噪声与成本函数的梯度同向）
- en: '**Linf projected gradient descent** (of the white-box variety with the attacker
    having access to the model gradient and being able to alter the code to evade
    ML-based detection systems)'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Linf 投影梯度下降**（白盒类型，攻击者可以访问模型梯度并能更改代码以规避基于机器学习的检测系统）'
- en: '**L-infinity basic iterative method** (where adversarial samples are generated
    by evaluating the absolute value difference between two images, returning the
    maximum distance over all pixels)'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L-infinity 基本迭代方法**（通过评估两个图像之间的绝对值差异生成对抗样本，返回所有像素中的最大距离）'
- en: '**AdditiveUniformNoiseAttack** and **DeepFoolAttack** (a fast gradient-based
    adversarial attack that considers the minimum distance to arrive at the class
    boundary by modifying the model classifier with a linear classifier) on a pre-trained
    ResNet model by varying the number of steps to perform the attack (as denoted
    by epsilon)'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AdditiveUniformNoiseAttack**和**DeepFoolAttack**（一种基于快速梯度的对抗攻击，通过修改模型分类器为线性分类器，考虑到最小距离以到达类边界）在预训练的ResNet模型上执行，改变执行攻击的步数（由epsilon表示）'
- en: 'Then, the preceding attacks are executed on a pre-trained ResNet model by varying
    the number of steps to perform the attack:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过改变执行攻击的步数，对预训练的ResNet模型执行上述攻击：
- en: '[PRE29]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The robust accuracy of the model can be evaluated as follows. This metric signifies
    the model''s accuracy when the attack is triggered on the best sample of the model:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的鲁棒准确性可以如下评估。该度量表示在对模型的最佳样本触发攻击时，模型的准确性：
- en: '[PRE30]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The results are printed as follows:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: "![Figure 2.1\uFEFF4 – Variation of the robust accuracy metric with different\
    \ attacks](img/Figure_2.14_B18681.jpg)"
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![图2.14 – 不同攻击下鲁棒准确率的变化](img/Figure_2.14_B18681.jpg)'
- en: Figure 2.14 – Variation of the robust accuracy metric with different attacks
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14 – 不同攻击下鲁棒准确率的变化
- en: Model robustness with constraints
  id: totrans-440
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带约束的模型鲁棒性
- en: Model robustness can be increased by training the model with adversarial perturbations
    and constraints. Adding domain constraints (just as in designing AI solutions
    of the network, such as intrusion detection systems) imposes extra restrictions
    and challenges on the adversary to maintain complex relationships between input
    features in order to trigger and realize an attack. Even though domain constraints
    limit adversarial capabilities to trigger an attack by generating perturbed samples,
    creating realistic (constraint-compliant) examples is often possible for adversaries.
    Research results suggest models gain robustness on being enforced with constraints
    (where the set of constrained variables is solved for optimization with a tractable
    linear program) that can cause the model accuracy to increase by 34%. Threat models
    designed with constraints properly assess realistic attack vectors and succeed
    in optimizing defensive performance.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用对抗扰动和约束来训练模型，可以增加模型的鲁棒性。添加领域约束（就像在设计网络的人工智能解决方案时一样，例如入侵检测系统）对对手施加了额外的限制和挑战，要求其维持输入特征之间的复杂关系，以便触发和实现攻击。尽管领域约束限制了对手通过生成扰动样本来触发攻击的能力，但对手通常仍然可以创建现实的（符合约束的）示例。研究结果表明，当模型被强制执行约束时（其中约束变量的集合通过可解的线性程序进行优化），模型的鲁棒性得到提升，准确率可提高34%。设计时考虑约束的威胁模型能够合理评估现实的攻击向量，并成功优化防御性能。
- en: One such relevant example is the defensive performance of AdvGAN- and FGSM-based
    mitigation ([https://www.hindawi.com/journals/scn/2021/9924684/](https://www.hindawi.com/journals/scn/2021/9924684/)),
    as shown in *Figure 2**.15*, where **A** has been trained without constraints
    and **B** has been trained with constraints.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 一个相关的例子是基于AdvGAN和FGSM的防御性能（[https://www.hindawi.com/journals/scn/2021/9924684/](https://www.hindawi.com/journals/scn/2021/9924684/)），如*图2.15*所示，其中**A**是没有约束训练的，而**B**是带约束训练的。
- en: "![Figure 2.\uFEFF15 – Model accuracy when trained with adversarial perturbations\
    \ A) without constraints and B) with constraints](img/Figure_2.15_B18681.jpg)"
  id: totrans-443
  prefs: []
  type: TYPE_IMG
  zh: '![图2.15 – 使用对抗扰动训练时的模型准确率 A) 无约束和 B) 有约束](img/Figure_2.15_B18681.jpg)'
- en: Figure 2.15 – Model accuracy when trained with adversarial perturbations A)
    without constraints and B) with constraints
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15 – 使用对抗扰动训练时的模型准确率 A) 无约束和 B) 有约束
- en: Model robustness metric
  id: totrans-445
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型鲁棒性度量
- en: FGSM, JSMA, DeepFool, and **Carlini and Wagner** (**CW**) attacks have been
    useful in generating adversarial examples and triggering adversarial attacks,
    causing the misclassification of predicted outputs. There has been rigorous research
    in the field of devising metrics to evaluate model robustness by feeding in adversarial
    inputs to train the neural network.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: FGSM、JSMA、DeepFool和**Carlini和Wagner**（**CW**）攻击在生成对抗样本和触发对抗攻击方面非常有效，导致预测输出的误分类。在为神经网络输入对抗性输入进行训练的过程中，评估模型鲁棒性的度量方法已经进行了严格的研究。
- en: This research led to suggestions for improved robustness metrics, and one metric
    called **Cross Lipschitz Extreme Value for nEtwork Robustness** (**CLEVER**) was
    proposed, which defines an approximate lower bound on the minimum distortion needed
    for an attack to succeed. This robustness metric is attack-agnostic (successful
    against powerful attacks on different types of classifiers and neural networks
    such as ResNet, Inceptionv3, and MobileNet). This was also found to work on continuously
    differentiable functions to a special class of non-differentiable functions –
    neural networks with ReLU activations. The CLEVER metric serves as a comparative
    technique for comparing different network designs and training procedures.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究提出了改进的鲁棒性度量方法，其中一个度量标准叫做**跨利普希茨极值网络鲁棒性**（**CLEVER**），它定义了攻击成功所需的最小失真度的近似下限。这个鲁棒性度量是与攻击无关的（即使是对不同类型的分类器和神经网络（如ResNet、Inceptionv3和MobileNet）进行强大攻击时，也能成功）。研究还发现它适用于连续可微函数到特殊类型的不可微函数——具有ReLU激活的神经网络。CLEVER度量作为比较不同网络设计和训练过程的技术手段。
- en: This algorithm at first generates *N* samples in a sphere around a given sample
    in an independent and uniform manner in each batch, out of a fixed total batch
    size. Then the gradient norm of each sample is computed and the maximum value
    of the gradient over those *N* samples is evaluated. The minimum value is used
    to determine the maximum likelihood, which is in turn used to retrieve the distributional
    parameters (reverse Weibull distribution) and maximizing the probability of these
    gradients.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法首先在每个批次中，以独立且均匀的方式生成位于给定样本周围的*N*个样本，批次总大小是固定的。然后计算每个样本的梯度范数，并评估这些*N*个样本中最大梯度值。最小值用于确定最大似然估计，进而用于检索分布参数（逆威布尔分布），并最大化这些梯度的概率。
- en: The average CLEVER scores are obtained for different target classes. A high
    CLEVER score means networks have better network robustness, in which minimal adversarial
    perturbation increases the *L*p norm to a higher value. This framework from IBM
    lays the foundation to build reliable systems without invoking specific adversarial
    attacks.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 对不同目标类别获得平均CLEVER得分。较高的CLEVER得分意味着网络具有更好的鲁棒性，其中最小的对抗扰动将*L*p范数提升到更高的值。IBM提出的这一框架为构建可靠系统奠定了基础，而不需要特定的对抗攻击。
- en: This CLEVER score can be used to evaluate the effectiveness of CNNs and help
    us to certify a neural network’s attack-resistance level. For example, in mission-critical
    applications (such as autonomous vehicles), the evaluation of classification robustness
    could increase human confidence and would serve as an important metric for compliance
    and ethics.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 这个CLEVER得分可以用来评估卷积神经网络（CNN）的有效性，并帮助我们验证神经网络的抗攻击能力。例如，在任务关键型应用（如自动驾驶车辆）中，分类鲁棒性的评估可以增加人类的信心，并作为合规性和伦理性的重要指标。
- en: If introducing adversarial perturbation impacted the accuracy of the recognition
    of traffic signs and led to a speed limit being misclassified, it would have a
    disastrous impact on humans. Hence, it becomes mandatory to evaluate the ML model
    against the right robustness metric before launching the model at scale. This
    metric introduced by IBM considers the network architectures of CNNs, including
    convolutional layers, max-pooling layers, batch normalization layers, and residual
    blocks, as well as general activation functions, and limits the perturbation of
    each pixel within a threshold margin to guarantee the network classification is
    not changed by any external attack. IBM research further assures that this metric
    derived from the input and output relations of each layer generates a matrix that
    is efficient to compute. *Figure 2**.16* illustrates the trade-offs associated
    with model robustness (as determined by the CLEVER score) and accuracy for 18
    different ImageNet models.Recent research produced a new defense framework named
    TRADES ([http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf](http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf))
    that optimizes the adversarial robustness to achieve a trade-off between accuracy
    and robustness, providing strong resilience against both black-box and white-box
    attacks.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 如果引入对抗扰动影响了交通标志识别的准确性，并导致限速标志被误分类，那么这将对人类产生灾难性的影响。因此，在大规模部署模型之前，必须评估机器学习模型在合适鲁棒性度量标准下的表现。IBM
    提出的这一度量标准考虑了 CNN 网络架构，包括卷积层、最大池化层、批归一化层和残差块，以及常见激活函数，并将每个像素的扰动限制在一个阈值范围内，以确保网络分类不受任何外部攻击的影响。IBM
    研究进一步确认，这一度量标准通过每一层输入和输出关系得出一个计算效率较高的矩阵。*图 2.16*展示了 18 个不同 ImageNet 模型的鲁棒性（由 CLEVER
    分数确定）与准确率之间的权衡。近期的研究提出了一个新的防御框架，名为 TRADES（[http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf](http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf)），它优化了对抗鲁棒性，在准确性和鲁棒性之间实现了权衡，为黑盒和白盒攻击提供了强大的抗干扰能力。
- en: 'It has been found that deep neural networks when trained with regularized input
    gradients become more robust, and interpretable. By gradient regularization, we
    mean how the addition of constraints controls the change in the gradient of the
    input features with respect to the loss function.Hence in addition to looking
    for the right trade-off between model accuracy and CLEVER score, we should also
    look for the right trade-off between model accuracy and interpretability. We should
    also be aware that the accuracy or predictive power of deep learning models is
    high, whereas interpretability orders of linear and generalized additive models
    are higher. In descending orders of magnitude, we can say this is the order of
    interpretability of models: linear models, generalized additive models, decision
    trees, SVMs, random forests, and neural networks.'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 研究发现，当深度神经网络通过正则化输入梯度进行训练时，它们变得更加鲁棒且易于解释。梯度正则化指的是通过添加约束来控制输入特征梯度相对于损失函数的变化。因此，除了寻找模型准确率和
    CLEVER 分数之间的最佳权衡外，我们还应寻找模型准确率和可解释性之间的最佳权衡。我们还应意识到，深度学习模型的准确性或预测能力较高，而线性模型和广义加法模型的可解释性则更强。按可解释性的大小顺序排列，我们可以这样说：线性模型、广义加法模型、决策树、支持向量机（SVM）、随机森林和神经网络。
- en: "![Figure 2.\uFEFF16 – Trade-off between a model’s CLEVER score (robustness)\
    \ and accuracy](img/Figure_2.16_B18681.jpg)"
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.16 – 模型 CLEVER 分数（鲁棒性）与准确率之间的权衡](img/Figure_2.16_B18681.jpg)'
- en: Figure 2.16 – Trade-off between a model’s CLEVER score (robustness) and accuracy
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.16 – 模型 CLEVER 分数（鲁棒性）与准确率之间的权衡
- en: Summary
  id: totrans-455
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter, we have learned about different defense practices for mitigating
    attacks in different stages of data and model life cycle management. We have talked
    about different cloud components, techniques, and measures that can be adopted
    for data anonymization, deanonymization, training ML algorithms with DP, and encrypted
    transfer methodologies. In reference to this, we took a deep dive into adversarial
    risk mitigation frameworks (especially open source deep learning-based frameworks)
    that can be used to test the robustness of ML models before deployment and exposing
    the ML model to public APIs. Leveraging the use of existing frameworks and designing
    new ones can offer resilience against semi-honest or dishonest participants/adversaries
    attempting to undermine AI models, systems, and services. In addition, we have
    also seen how decentralized data storage, FL, and efficient cryptographic and
    privacy measures serve as design choices for next-generation, high-potential,
    privacy-enabled systems.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经学习了关于在数据和模型生命周期管理的不同阶段中减轻攻击的不同防御实践。我们讨论了可以用于数据匿名化、去匿名化、使用差分隐私训练机器学习算法以及加密传输方法的不同云组件、技术和措施。在此基础上，我们深入探讨了对抗风险缓解框架（特别是基于开源深度学习的框架），这些框架可以在部署之前测试机器学习模型的健壮性，并将机器学习模型暴露给公共API。利用现有框架并设计新框架可以提供对抗试图破坏人工智能模型、系统和服务的半诚实或不诚实参与者/对手的韧性。此外，我们还看到了分散化数据存储、FL以及高效的加密和隐私措施如何作为下一代、潜力巨大的隐私启用系统的设计选择。
- en: In the following chapters, we will explore some of the defense pipeline creation
    methodologies, optimization strategies, and metrics, along with their ability
    to deduce trade-offs between accuracy, interpretability, fairness, bias, and privacy
    (the privacy-utility trade-off). All these important parameters serve as prerequisites
    to productionizing secure, private, auditable, and objectively designed trustworthy
    AI systems, enabling universal acceptance by both consumers and policy-makers.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探索一些防御管道创建方法、优化策略和指标，以及它们在权衡准确性、可解释性、公平性、偏见和隐私（隐私-效用权衡）方面的能力。所有这些重要参数作为生产安全、私密、可审计和客观设计的值得信赖的人工智能系统的先决条件，使其能够被消费者和决策者普遍接受。
- en: In the next chapter, we will understand the different laws and policies put
    in place that enforce the correct standards and best practices to build a fully
    ethics-compliant system.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将了解到实施正确标准和最佳实践的不同法律和政策，以构建完全符合伦理的系统。
- en: Further reading
  id: totrans-459
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Data masking*: *what it is, how it works, types, and best practices*, Cem
    Dilmegani:[https://research.aimultiple.com/data-masking/](https://research.aimultiple.com/data-masking/)'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据脱敏*: *它是什么，它如何工作，类型和最佳实践*, Cem Dilmegani:[https://research.aimultiple.com/data-masking/](https://research.aimultiple.com/data-masking/)'
- en: '*A Defense Framework for Privacy Risks in Remote Machine Learning Service,*
    Yang Bai, Yu Li, Mingchuang Xie, and Mingyu Fan:[https://www.hindawi.com/journals/scn/2021/9924684/](https://www.hindawi.com/journals/scn/2021/9924684/)'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*远程机器学习服务中隐私风险的防御框架,* 杨白, 余丽, 谢明创, 和樊明宇:[https://www.hindawi.com/journals/scn/2021/9924684/](https://www.hindawi.com/journals/scn/2021/9924684/)'
- en: '*A Study on k-anonymity, l-diversity, and t-closeness Techniques focusing Medical
    Data. 17,* Rajendran, Keerthana, Jayabalan, Manoj, and Rana, Muhammad Ehsan. (2017):[https://www.researchgate.net/publication/322330948_A_Study_on_k-anonymity_l-diversity_and_t-closeness_Techniques_focusing_Medical_Data](https://www.researchgate.net/publication/322330948_A_Study_on_k-anonymity_l-diversity_and_t-closeness_Techniques_focusing_Medical_Data)'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*关于k-匿名性、l-多样性和t-接近性技术在医疗数据中的研究. 17,* Rajendran, Keerthana, Jayabalan, Manoj,
    和Rana, Muhammad Ehsan. (2017):[https://www.researchgate.net/publication/322330948_A_Study_on_k-anonymity_l-diversity_and_t-closeness_Techniques_focusing_Medical_Data](https://www.researchgate.net/publication/322330948_A_Study_on_k-anonymity_l-diversity_and_t-closeness_Techniques_focusing_Medical_Data)'
- en: '*Dataprof - deterministic data* *masking*:[https://www.datprof.com/solutions/deterministic-data-masking/](https://www.datprof.com/solutions/deterministic-data-masking/.)'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Dataprof - 确定性数据* *脱敏*:[https://www.datprof.com/solutions/deterministic-data-masking/](https://www.datprof.com/solutions/deterministic-data-masking/.)'
- en: '*Study Of The Use Of Anonymity Models,* Carmen Marcano:[https://education.dellemc.com/content/dam/dell-emc/documents/en-us/2020KS_Marcano-Study_of_the_Use_of_Anonymity_Models.pdf](https://education.dellemc.com/content/dam/dell-emc/documents/en-us/2020KS_Marcano-Study_of_the_Use_of_Anonymity_Models.pdf)'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*匿名性模型的研究，* 卡门·马尔卡诺：[https://education.dellemc.com/content/dam/dell-emc/documents/en-us/2020KS_Marcano-Study_of_the_Use_of_Anonymity_Models.pdf](https://education.dellemc.com/content/dam/dell-emc/documents/en-us/2020KS_Marcano-Study_of_the_Use_of_Anonymity_Models.pdf)'
- en: '*Privacy Protection*: *p-Sensitive k-Anonymity Property. IEEE Computer Society.
    2006\. 94 - 94\. 10.1109/ICDEW.2006.116\.* Truta, T. M. & Vinay, Bindu. (2006):[https://www.researchgate.net/publication/4238176_Privacy_Protection_p-Sensitive_k-Anonymity_Property](https://www.researchgate.net/publication/4238176_Privacy_Protection_p-Sensitive_k-Anonymity_Property)'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*隐私保护*：*p-敏感k-匿名性属性。IEEE计算机学会，2006年，94-94，10.1109/ICDEW.2006.116\.* Truta,
    T. M. & Vinay, Bindu.（2006）：[https://www.researchgate.net/publication/4238176_Privacy_Protection_p-Sensitive_k-Anonymity_Property](https://www.researchgate.net/publication/4238176_Privacy_Protection_p-Sensitive_k-Anonymity_Property)'
- en: 'MITRE ATT&CK: [https://attack.mitre.org/#](https://attack.mitre.org/#)'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'MITRE ATT&CK: [https://attack.mitre.org/#](https://attack.mitre.org/#)'
- en: '*De-Pois*: *An Attack-Agnostic Defense against Data Poisoning Attacks. C*hen,
    J., Zhang, X., Zhang, R., Wang, C., & Liu, L. (2021):[https://arxiv.org/pdf/2105.03592.pdf](https://arxiv.org/pdf/2105.03592.pdf)'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*De-Pois*：*一种防止数据投毒攻击的抗攻击防御方法。C*hen, J., Zhang, X., Zhang, R., Wang, C., &
    Liu, L.（2021）：[https://arxiv.org/pdf/2105.03592.pdf](https://arxiv.org/pdf/2105.03592.pdf)'
- en: '*Designing Access with Differential Privacy*, Wood, Alexandra, Micah Altman,
    Kobbi Nissim, and Salil Vadhan. (2020): [https://admindatahandbook.mit.edu/book/v1.0/diffpriv.html](https://admindatahandbook.mit.edu/book/v1.0/diffpriv.html)'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设计带有差分隐私的访问控制，* Wood, Alexandra, Micah Altman, Kobbi Nissim, 和 Salil Vadhan.（2020）：[https://admindatahandbook.mit.edu/book/v1.0/diffpriv.html](https://admindatahandbook.mit.edu/book/v1.0/diffpriv.html)'
- en: '*Machine Learning with Differential Privacy in* *TensorFlow*:[http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html](http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html)'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*带有差分隐私的机器学习在* *TensorFlow*中：[http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html](http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html)'
- en: '*Guidelines for Anonymization &* *Pseudonymization*:[https://ispo.newschool.edu/guidelines/anonymization-pseudonymization/](https://ispo.newschool.edu/guidelines/anonymization-pseudonymization/)'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*匿名化与* *假名化* 指南：[https://ispo.newschool.edu/guidelines/anonymization-pseudonymization/](https://ispo.newschool.edu/guidelines/anonymization-pseudonymization/)'
- en: '*A Python Library for Secure and Explainable ML,* Melis, M. Demontis, A., Pintor,
    M. Sotgiu, A., Biggio, B.*secml*: [https://arxiv.org/pdf/1912.10013.pdf]( https://arxiv.org/pdf/1912.10013.pdf)'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于安全和可解释机器学习的Python库，* Melis, M. Demontis, A., Pintor, M. Sotgiu, A., Biggio,
    B.*secml*：[https://arxiv.org/pdf/1912.10013.pdf](https://arxiv.org/pdf/1912.10013.pdf)'
- en: '*Evaluating the Robustness of Neural Networks*: *An Extreme Value Theory Approach,*
    Weng, Tsui-Wei et al.: [https://openreview.net/pdf?id=BkUHlMZ0b](https://openreview.net/pdf?id=BkUHlMZ0b)'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*评估神经网络的鲁棒性*：*极值理论方法，* Weng, Tsui-Wei 等人：[https://openreview.net/pdf?id=BkUHlMZ0b](https://openreview.net/pdf?id=BkUHlMZ0b)'
- en: '*Foolbox*: *A Python toolbox to benchmark the robustness of machine learning
    models. Reliable ML in the Wild Workshop, 34th International Conference on ML,*
    J. Rauber, W. Brendel, and M. Bethge:[https://arxiv.org/pdf/1707.04131.pdf](https://arxiv.org/pdf/1707.04131.pdf)'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Foolbox*：*一个用于评估机器学习模型鲁棒性的Python工具箱。可靠机器学习在野外研讨会，34届国际机器学习会议，* J. Rauber,
    W. Brendel, 和 M. Bethge：[https://arxiv.org/pdf/1707.04131.pdf](https://arxiv.org/pdf/1707.04131.pdf)'
- en: '*On the Robustness of Domain Constraints. CCS ‘21*: *Proceedings of the 2021
    ACM SIGSAC Conference on Computer and Communications Security,* Ryan Sheatsley,
    Blaine Hoak, Eric Pauley, Yohan Beugin, Michael J. Weisman, and Patrick McDaniel:[https://arxiv.org/pdf/2105.08619.pdf](https://arxiv.org/pdf/2105.08619.pdf)'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*领域约束的鲁棒性。CCS ''21*: *2021年ACM SIGSAC计算机与通信安全会议论文集，* 瑞安·谢茨利，布莱恩·霍克，埃里克·保利，约翰·贝金，迈克尔·J·韦斯曼，帕特里克·麦克丹尼尔：[https://arxiv.org/pdf/2105.08619.pdf](https://arxiv.org/pdf/2105.08619.pdf)'
- en: 'L-Diversity: Privacy Beyond k-Anonymity, ASHWIN MACHANAVAJJHALA DANIEL KIFER
    JOHANNES GEHRKE, https://www.cs.rochester.edu/u/muthuv/ldiversity-TKDD.pdf'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L-多样性：超越k-匿名性的隐私保护，ASHWIN MACHANAVAJJHALA DANIEL KIFER JOHANNES GEHRKE，[https://www.cs.rochester.edu/u/muthuv/ldiversity-TKDD.pdf](https://www.cs.rochester.edu/u/muthuv/ldiversity-TKDD.pdf)
