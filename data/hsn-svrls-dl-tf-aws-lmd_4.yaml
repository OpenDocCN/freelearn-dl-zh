- en: Working with TensorFlow on AWS Lambda
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS Lambda 上使用 TensorFlow
- en: In this chapter, we will learn about the architecture of deploying TensorFlow
    with AWS, and we will deploy TensorFlow on AWS Lambda using the pre-existing pack
    and the serverless framework.We will also look into the various general issues
    with deploying the various Python frameworks on AWS Lambda and then cover all
    of the solutions to the same issues.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何在 AWS 上部署 TensorFlow 的架构，并通过预先存在的包和无服务器框架在 AWS Lambda 上部署 TensorFlow。我们还将探讨在
    AWS Lambda 上部署各种 Python 框架时的常见问题，并涵盖所有解决这些问题的方案。
- en: 'We will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Architecture of deploying TensorFlow with AWS Lambda
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS Lambda 部署 TensorFlow 的架构
- en: General issues with deploying Python frameworks on AWS Lambda
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AWS Lambda 上部署 Python 框架的常见问题
- en: Deploying TensorFlow on AWS Lambda using pre-existing pack
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预先存在的包在 AWS Lambda 上部署 TensorFlow
- en: Deploying TensorFlow using a serverless framework
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用无服务器框架部署 TensorFlow
- en: Technical Requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: AWS subscription
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 订阅
- en: Python 3.6
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.6
- en: AWS CLI
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS CLI
- en: Serverless framework
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器框架
- en: You can find all the codes at: [https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda](https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在以下位置找到所有代码：[https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda](https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda)
- en: Architecture of the deploying TensorFlow with AWS Lambda
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AWS Lambda 部署 TensorFlow 的架构
- en: In this section, we will learn about the architecture of deploying TensorFlow
    with AWS Lambda. One of the critical questions of deployment is about where to
    keep the retrained model that will be used within AWS Lambda.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用 AWS Lambda 部署 TensorFlow 的架构。部署的一个关键问题是，应该将重新训练的模型存放在哪里，以便在 AWS
    Lambda 中使用。
- en: 'There are the following three possible options:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有以下三种可能的选项：
- en: Keep the model within the deployment package alongside the code and libraries
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型与代码和库一起保存在部署包中
- en: Keep the model on the S3 bucket and unload it in AWS Lambda during execution
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型保存在 S3 存储桶中，并在执行时加载到 AWS Lambda 中
- en: Keep the model on the FTP or HTTP server and unload it into AWS Lambda during
    execution
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型保存在 FTP 或 HTTP 服务器上，并在执行时加载到 AWS Lambda 中
- en: Model within the deployment package
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署包中的模型
- en: This option means that the model is within the deployment package. The code
    will import it from a local filesystem. This option has its own pros and cons.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项意味着模型位于部署包中。代码将从本地文件系统中导入它。这个选项有自己的优缺点。
- en: Pros
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优点
- en: 'The advantages of the model within the deployment package are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在部署包中的优势如下：
- en: We will get a very good start speed for our deployment since there is no overhead
    on the loading model
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于没有加载模型的开销，我们的部署将有一个非常好的启动速度
- en: We will have a single package to start with
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将从一个单一的包开始
- en: We won't need any outside servers or AWS services as part of our deployment
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的部署不需要任何外部服务器或 AWS 服务
- en: Cons
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺点
- en: 'The disadvantages of the model within the deployment package are as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在部署包中的缺点如下：
- en: There is considerable limitation on the package size and it limits the possible
    size of our model
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包大小有相当大的限制，这限制了我们模型的可能大小
- en: In the case where you need to manage different versions of the model, it may
    be tricky to either keep them all in one package or deal with different versions
    of your package
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要管理模型的不同版本，可能很难将它们全部保存在一个包中，或者处理不同版本的包
- en: Model on the S3 bucket
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 存储桶中的模型
- en: This option means that we have to keep the model in the S3 bucket and unload
    it during AWS Lambda execution. This option is very limited in terms of package
    size.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项意味着我们必须将模型保存在 S3 存储桶中，并在 AWS Lambda 执行期间卸载它。此选项在包大小方面非常有限。
- en: Pros
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优点
- en: 'The advantages of the model on the S3 bucket are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在 S3 存储桶中的优势如下：
- en: At first glance, it will be limited to only 500 MB of usage, which is the maximum
    size of TMP folder on AWS Lambda, but it is actually possible to download the
    model directly into memory by passing this limit
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初看之下，使用会限制为 500 MB，这是 AWS Lambda 上 TMP 文件夹的最大大小，但实际上可以通过绕过此限制直接将模型下载到内存中
- en: It will be a lot easier to manage multiple models as you can use AWS Lambda
    environmental variables to procure equipment links to S3 bucket for each of the
    models that you want to use
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理多个模型会变得更容易，因为你可以使用 AWS Lambda 环境变量为每个你想要使用的模型提供与 S3 存储桶的设备链接。
- en: Cons
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺点
- en: 'The disadvantages of the model on the S3 bucket are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 存放在 S3 存储桶上的模型的缺点如下：
- en: We will get a slower start than in previous cases, since Lambda will need to
    download the model first
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的启动速度会比之前的案例慢，因为 Lambda 需要先下载模型。
- en: It should be noted that, though it happens only during cold start, during warm
    start, the model will already be in memory
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要注意的是，尽管这只在冷启动时发生，但在热启动时，模型已经在内存中。
- en: You will need to make the S3 bucket upload all of your models as a part of your
    deployment, and add logic for managing the different models within the code
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要将所有模型上传到 S3 存储桶，作为部署的一部分，并在代码中添加管理不同模型的逻辑。
- en: Model on the HTTP/FTP server
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存放在 HTTP/FTP 服务器上的模型
- en: This option is mostly useful for the case where you want to limit the use of
    AWS services, memory or integrate with services outside of AWS. The AWS Lambda
    downloads the model from HTTP or FTP server during deployment.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项主要适用于你希望限制 AWS 服务使用、内存或与 AWS 之外的服务进行集成的情况。在部署过程中，AWS Lambda 会从 HTTP 或 FTP
    服务器下载模型。
- en: Pros
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优点
- en: 'The advantages of the model on the HTTP/FTP server are as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 模型存放在 HTTP/FTP 服务器上的优点如下：
- en: You can use a number of publicly available services with models
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用多个公开可用的服务与模型进行交互。
- en: You don't have to update your model on S3 bucket or within the package
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你无需更新 S3 存储桶中的模型或包内的模型。
- en: Cons
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺点
- en: 'The disadvantages of the model on the HTTP/FTP server are as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 存放在 HTTP/FTP 服务器上的模型的缺点如下：
- en: It may be even slower than with the previous case, which is a downside of this
    model
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可能比前一个案例还要慢，这是该模型的一个缺点。
- en: Due to the slower time, you will need to make sure that the server is available
    from your location
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于较慢的时间，你需要确保服务器在你的地点是可用的。
- en: General issues with deploying Python frameworks on AWS Lambda
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS Lambda 上部署 Python 框架时的一般问题
- en: 'In this section, we will learn about AWS Lambda main limit, which is also known
    as the size of the package. The current limit for the Lambda deployment package
    is 50 MB. It is supposed to include libraries and code. There are two main libraries
    that we need to fit:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将了解 AWS Lambda 的主要限制，也就是包的大小。Lambda 部署包的当前限制是 50 MB。该包应包括库和代码。我们需要适配的两个主要库如下：
- en: TensorFlow
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: NumPy
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: These libraries are used for matrix calculations. As you may know, the libraries
    by themselves are pretty big and they just wouldn't work on AWS Lambda. As you
    have already seen in the previous section on deployment that when we deploy them
    through S3, we don't have this limitation, and we only have 250 MB limitation
    for the unzipped package. In this case to make it work, we need to reduce the
    size of the package.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库用于矩阵计算。如你所知，单独的这些库非常大，并且在 AWS Lambda 上无法正常运行。正如你在前一节部署中看到的，当我们通过 S3 部署时，我们没有这个限制，只需要面对解压包大小的
    250 MB 限制。在这种情况下，为了使其正常工作，我们需要减小包的大小。
- en: Solutions for issues with deploying Python frameworks on AWS Lambda
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决在 AWS Lambda 上部署 Python 框架的问题
- en: 'There are a number of ways as to how we can reduce the package size. Here are
    the solutions for the issues in question:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式可以减少包的大小。以下是针对这些问题的解决方案：
- en: We can compress the shared libraries; this usually enables us to get the best
    reduction of size.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以压缩共享库，通常这样能实现最佳的大小减少。
- en: We can remove the `.pyc` files as they do not influence the library work.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以删除 `.pyc` 文件，因为它们不会影响库的工作。
- en: Next, we can remove tests and visualization folders from the libraries as they
    are not useful in production.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们可以从库中删除测试和可视化文件夹，因为它们在生产环境中没有用处。
- en: Next, we can remove libraries that already exist on AWS Lambda.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们可以删除 AWS Lambda 上已经存在的库。
- en: Finally, we can check and remove the libraries that aren't used during execution,
    for example, wheel or PIP libraries.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们可以检查并删除执行过程中未使用的库，例如 wheel 或 PIP 库。
- en: Now, in the following code, there is the part that finds and compresses all
    shared libraries. Then, we find and delete all `.pyc` files.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在以下代码中，有一部分是查找并压缩所有共享库。然后，我们查找并删除所有 `.pyc` 文件。
- en: 'The following screenshot shows the commands for the preceding explanation:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了前面解释的命令：
- en: '![](img/20c2e405-bef7-4cf5-a70a-bcf2add76128.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20c2e405-bef7-4cf5-a70a-bcf2add76128.png)'
- en: Next, we need to delete libraries that won't be used during execution, such
    as `.pip` and `wheel`. Finally, we can also delete some folders from TensorFlow
    library.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要删除在执行过程中不会使用到的库，例如`.pip`和`wheel`。最后，我们还可以删除TensorFlow库中的一些文件夹。
- en: 'The following screenshot shows the different commands for the preceding explanation:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了前述说明中的不同命令：
- en: '![](img/b707219e-0514-45d0-ba06-2ae2ab8777fa.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b707219e-0514-45d0-ba06-2ae2ab8777fa.png)'
- en: The whole process of preparing a package for AWS Lambda can be done through
    Docker. You don't need to use it for the project we will create, but it is good
    to keep in mind how to prepare this kind of package.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 准备AWS Lambda的整个包过程可以通过Docker完成。虽然在我们将要创建的项目中你不需要使用它，但了解如何准备这类包是很有帮助的。
- en: 'To install Docker, you just need to run three comments in your comment line:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Docker，你只需要在命令行中运行三个命令：
- en: You need to get the latest Amazon Linux image on which we will run the script.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要获取最新的Amazon Linux镜像，我们将在该镜像上运行脚本。
- en: You need to start a Docker container with the managing output folder inside
    the container.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要启动一个Docker容器，并将管理输出文件夹放在容器内。
- en: 'You can run the script inside the container and it will assemble the package
    for you. The following screenshot displays all of the commands to install Docker:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以在容器内运行脚本，它将为你组装包。以下截图展示了安装Docker的所有命令：
- en: '![](img/5af485f9-ae76-479d-9a5a-3e4d5144bcf0.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5af485f9-ae76-479d-9a5a-3e4d5144bcf0.png)'
- en: Deploying TensorFlow on AWS Lambda using the pre-existing pack
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用现有的包在AWS Lambda上部署TensorFlow
- en: In this section, we will learn to deploy TensorFlow on AWS Lambda using the
    pre-existing pack. In the project files, we have model files that are also known
    as the model itself and files that enable us to translate model response through
    labels. In `Inception` folder and Lambda package, which is also known as the code
    and libraries in `lambdapack` folder.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用现有的包在AWS Lambda上部署TensorFlow。在项目文件中，我们有模型文件，这些文件也被称为模型本身，以及能够通过标签翻译模型响应的文件。在`Inception`文件夹和Lambda包中，后者也称为`lambdapack`文件夹中的代码和库。
- en: 'To run the code, we need to do the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行代码，我们需要执行以下步骤：
- en: We'll create S3 bucket where we will keep the model and upload the model itself
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将创建S3桶，存放模型并上传模型本身
- en: Then,we'll modify code for the specific bucket and add the created bucket name
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接着，我们将修改代码以适应特定的桶，并添加已创建的桶名称
- en: Lastly, we can package it and upload to add the AWS Lambda
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们可以将其打包并上传，以添加到AWS Lambda
- en: Now, we will create S3 bucket using the AWS Console and upload files there.
    We will open the code and add the bucket that we have just created. Then, let's
    package it and upload it to add AWS Lambda.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用AWS控制台创建S3桶并将文件上传到其中。我们将打开代码并添加刚创建的桶。然后，让我们打包它并上传到AWS Lambda。
- en: 'We will have to follow the given steps:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要按照以下步骤进行：
- en: 'We need to go to the S3 service and click Create bucket:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要前往S3服务并点击创建桶（Create bucket）：
- en: '![](img/b5a2b678-1b9c-4697-adbc-1135d167ae79.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b5a2b678-1b9c-4697-adbc-1135d167ae79.png)'
- en: 'Now, we can choose the bucket name:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以选择桶名称：
- en: '![](img/00a6f22d-931b-4cf4-b9ce-c845814d4794.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00a6f22d-931b-4cf4-b9ce-c845814d4794.png)'
- en: 'Once we have the bucket in place, we can upload files there. You just need
    to click Upload and then choose files. So, here we just upload the package with
    libraries, and it will start the upload process, along with the package itself.
    We will need to upload model files, which are present in the `Inception` folder:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们设置好桶（bucket），就可以将文件上传到其中。你只需要点击上传（Upload），然后选择文件。在这里，我们只需上传包含库的包，它将开始上传过程，以及包本身。我们还需要上传位于`Inception`文件夹中的模型文件：
- en: '![](img/f34cd6e4-a3e2-4a48-9398-4199e7a14df6.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f34cd6e4-a3e2-4a48-9398-4199e7a14df6.png)'
- en: 'You can see that now we have a package inside our S3 bucket:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以看到，现在我们的S3桶中已经有一个包：
- en: '![](img/682c7e5f-5f9c-4f88-905f-b0ad32720507.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/682c7e5f-5f9c-4f88-905f-b0ad32720507.png)'
- en: 'Now, we have to create the role for our AWS Lambda, which we can do from the
    IAM service:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须为我们的AWS Lambda创建角色，可以通过IAM服务来完成：
- en: '![](img/ae17137a-3ad4-4bef-87e2-301f05dec8dc.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae17137a-3ad4-4bef-87e2-301f05dec8dc.png)'
- en: 'We need to choose Lambda and click on Next: Permissions, which lies at the
    bottom-right of your screen:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '我们需要选择Lambda并点击右下角的“下一步：权限”（Next: Permissions）：'
- en: '![](img/588d2e5d-3f17-47ca-9e68-57637d30be29.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/588d2e5d-3f17-47ca-9e68-57637d30be29.png)'
- en: 'For simplicity, it is easier to choose administrator access and click on Next:
    Tags, which lies at the bottom-right of your screen. This would allow our Lambda
    to access all services. Usually in production, the role is limited to accessing
    only specific services. We will cover this when we work with serverless frameworks:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了简化操作，选择管理员访问并点击下一步：标签，位于屏幕的右下角。这将允许我们的 Lambda 访问所有服务。通常在生产环境中，角色的访问权限会限制为仅访问特定服务。我们将在使用无服务器框架时讨论这个问题：
- en: '![](img/5c6a709f-8ec2-48a7-9bf9-212c95d8eb07.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c6a709f-8ec2-48a7-9bf9-212c95d8eb07.png)'
- en: 'Create a role name: `lambdaAdminRole`, which will create the role in Lambda:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建角色名称：`lambdaAdminRole`，这将在 Lambda 中创建该角色：
- en: '![](img/193478df-a06a-41a1-93cd-c7d66ab776b9.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/193478df-a06a-41a1-93cd-c7d66ab776b9.png)'
- en: 'To create Lambda, navigate to Lambda function and create the function. Here,
    enter the name `testensorflolambda`, Runtime as Python 3.6\. For Roles, select
    Choose an existing role, and in Existing role, select `lambdaAdminRole`, then
    click on Create function at the bottom-right corner:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Lambda 函数，进入 Lambda 函数页面并创建该函数。在此处，输入名称`testensorflolambda`，运行环境选择 Python
    3.6。对于角色，选择选择一个现有角色，在现有角色中选择`lambdaAdminRole`，然后点击右下角的创建函数：
- en: '![](img/72181902-1d22-486f-9804-3251a600c875.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/72181902-1d22-486f-9804-3251a600c875.png)'
- en: '10\. After the function is created, we need to change the Handler to `index.handler`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 10\. 创建函数后，我们需要将 Handler 修改为`index.handler`：
- en: '![](img/b80f11de-8c3c-43c2-ba43-afb498cc4ae6.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b80f11de-8c3c-43c2-ba43-afb498cc4ae6.png)'
- en: 'On the same screen, scroll down and, in the Basic setting tab, add enough resources
    as presented in the following screenshot:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一页面，向下滚动，在基础设置标签页中，按照以下截图添加足够的资源：
- en: '![](img/aac2594e-7e37-4cd4-be1b-676607b34a82.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aac2594e-7e37-4cd4-be1b-676607b34a82.png)'
- en: 'Pass the link with the URL of our package (S3 bucekt) and click on Save in
    the top right corner:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 传递包含我们包（S3 存储桶）URL的链接，并点击右上角的保存：
- en: '![](img/ee4da3e6-39d0-4dc0-8790-13c716385262.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee4da3e6-39d0-4dc0-8790-13c716385262.png)'
- en: 'You can see the function is created. To test the function, click on the Test
    on the top- right corner:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以看到函数已经创建。为了测试该函数，点击右上角的测试按钮：
- en: '![](img/53e3a850-3fe8-4ae4-b926-85058b791050.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53e3a850-3fe8-4ae4-b926-85058b791050.png)'
- en: 'After the function is tested, it will successfully produce the following result:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试完函数后，它将成功生成以下结果：
- en: '![](img/9da215f9-adda-42eb-afd4-bba15ac46475.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9da215f9-adda-42eb-afd4-bba15ac46475.png)'
- en: Deploying TensorFlow using a serverless framework
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用无服务器框架部署 TensorFlow
- en: First, we will look at the project files. We have model files in the `Inception`
    folder, and Lambda code with `Serverless.yml`, the configuration file in the `Lambdapack`
    folder.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将查看项目文件。我们在`Inception`文件夹中有模型文件，在`Lambdapack`文件夹中有 Lambda 代码和配置文件`Serverless.yml`。
- en: 'The flow of deployment will be the same as in the previous section. One of
    the main differences will be that, instead of providing an AWS Lambda admin role,
    we will provide access to bucket by serverless CML file. The only thing we need
    to add is `bucketname`, and run the properties of access as shown:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 部署流程将与上一节相同。主要的不同之处在于，我们将通过无服务器 CML 文件提供对存储桶的访问权限，而不是提供 AWS Lambda 管理员角色。我们只需要添加`bucketname`，并按照如下所示运行访问属性：
- en: '![](img/410584be-c45d-4925-b33b-75144ce6eb88.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/410584be-c45d-4925-b33b-75144ce6eb88.png)'
- en: 'We will need to create an S3 bucket, upload files there, and then deploy AWS
    Lambda. We will create an S3 bucket and upload files from the command line: `aws
    s3 sync.s3://<bucket>/`.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个 S3 存储桶，将文件上传到其中，然后部署 AWS Lambda。我们将创建一个 S3 存储桶，并通过命令行上传文件：`aws s3 sync.s3://<bucket>/`。
- en: Creating a bucket
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建存储桶
- en: We will first need to create a bucket, then we will need to upload model files
    to the bucket, run serverless, and start the AWS Lambda.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要创建一个存储桶，然后将模型文件上传到存储桶，运行无服务器框架，并启动 AWS Lambda。
- en: Index.py
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Index.py
- en: 'Let''s look at the available files. We will look at the `index.py` file as
    shown:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下可用的文件。我们将查看`index.py`文件，如下所示：
- en: '[PRE0]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The main difference is that we run the code inside the `handler` function and
    we need to download the model files and image file from the S3 bucket:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的不同之处在于我们在`handler`函数内部运行代码，并且需要从 S3 存储桶下载模型文件和图像文件：
- en: '[PRE1]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Also, we can use one of the advantages of AWS Lambda. We can save model files
    as global variables. Basically, we can define session as a global variable. With
    these, if we start Lambda right after the previous Lambda was executed, all model
    files will be in the RAM memory:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以利用AWS Lambda的一个优势。我们可以将模型文件保存为全局变量。基本上，我们可以将会话定义为全局变量。通过这些，如果我们在上一个Lambda执行完毕后立即启动Lambda，所有模型文件将保存在RAM内存中：
- en: '[PRE2]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Serverless.yml
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Serverless.yml
- en: 'In the `Serverless.yml` file, we need to define access to the S3 bucket as
    that''s where we will keep our model. Other than that, it will look exactly as
    the previously mentioned serverless CML files for other Lambdas:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Serverless.yml`文件中，我们需要定义对S3桶的访问权限，因为我们将在那里存储模型。除此之外，它将与之前提到的其他Lambda的无服务器CML文件完全相同：
- en: '[PRE3]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Also, the we need `inputimage.jpg` image for the inception model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要`inputimage.jpg`图像来进行inception模型的处理。
- en: 'Let''s look at the files that we need to upload to S3 bucket:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看需要上传到S3桶的文件：
- en: '![](img/9bfbd63b-4255-4328-bb0d-41f3e314ff40.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9bfbd63b-4255-4328-bb0d-41f3e314ff40.png)'
- en: 'There are two very convenient commands; one allows us to create a bucket, and
    another allows us to easily upload files into the bucket:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个非常方便的命令，一个允许我们创建一个桶，另一个允许我们轻松地将文件上传到桶中：
- en: '`aws s3api create-bucket --bucket serverlessdeeplearning`'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws s3api create-bucket --bucket serverlessdeeplearning`'
- en: '`aws s3 sync . s3://serverlessdeeplearning/imagenet`'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws s3 sync . s3://serverlessdeeplearning/imagenet`'
- en: Since we already have model files in this bucket, there is no need to hold it
    now, but you can use this command to upload to your bucket. Next, we can return
    back to the folder with our function and run `serverless deploy` command.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经在此桶中有模型文件，因此现在不需要再保存它，但您可以使用此命令将文件上传到您的桶中。接下来，我们可以返回到包含我们函数的文件夹并运行`serverless
    deploy`命令。
- en: 'Now, we will invoke the function with the following command:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用以下命令调用函数：
- en: '[PRE4]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As you can see, it successfully recognized the image. Also, if we invoke the
    function one more time after that, it will work faster:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，它成功识别了图像。此外，如果我们再次调用该函数，它将运行得更快：
- en: '![](img/10ae6ce4-b240-4ed1-b05a-50de48fc9c4c.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10ae6ce4-b240-4ed1-b05a-50de48fc9c4c.png)'
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the architecture of the deploying TensorFlow
    with AWS Lambda, in which we covered the possible options of deploying TensorFlow
    with AWS Lambda along with each of its pros and cons. We also discussed the general
    issues with deploying Python frameworks in AWS Lambda along with its solutions.
    Lastly, we deployed TensorFlow on AWS Lambda using the pre-existing pack and using
    a serverless framework.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了使用AWS Lambda部署TensorFlow的架构，其中涵盖了使用AWS Lambda部署TensorFlow的各种选项，以及每个选项的优缺点。我们还讨论了在AWS
    Lambda中部署Python框架的一般问题及其解决方案。最后，我们使用现有的包和无服务器框架在AWS Lambda上部署了TensorFlow。
- en: In the next chapter, we'll  create deep learning API using AWS Lambda.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将使用AWS Lambda创建深度学习API。
