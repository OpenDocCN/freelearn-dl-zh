- en: Mass Customization of Client Lifetime Wealth
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 客户终身财富的大规模定制
- en: In the previous chapter, we learned how to manage the digital data of customers.
    We also covered the Open Bank Project and the Open Bank API. In addition, we learned
    about document layout analysis and looked at an example of projecting the cash
    flow for a typical household. Then, we looked at another example of how to track
    daily expenses using invoice entity recognition.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何管理客户的数字数据。我们还介绍了开放银行项目和开放银行API。此外，我们还学习了文档布局分析，并查看了一个投影典型家庭现金流的示例。然后，我们查看了另一个使用发票实体识别跟踪日常支出的示例。
- en: In this chapter, we will learn how to combine data from a survey for personal
    data analysis. We will learn techniques such as Neo4j, which is a graph database.
    We will build a chatbot to serve customers 24/7\. We will also learn how to predict
    customer responses using NLP and Neo4j with the help of an example. After this,
    we will learn how to use cypher languages to manipulate data from the Neo4j database.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何结合来自调查的数据进行个人数据分析。我们将学习Neo4j等技术，这是一个图数据库。我们将构建一个全天候为客户服务的聊天机器人。我们还将学习如何使用NLP和Neo4j预测客户响应，以一个示例为例。之后，我们将学习如何使用Cypher语言操作来自Neo4j数据库的数据。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Financial concepts of wealth instruments
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 财富工具的金融概念
- en: Ensemble learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成学习
- en: Predicting customer responses
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测客户的响应
- en: Building a chatbot to serve customers 24/7
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个全天候为客户服务的聊天机器人
- en: Knowledge management using NLP and graphs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自然语言处理（NLP）和图表进行知识管理
- en: Financial concepts of wealth instruments
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 财富工具的金融概念
- en: In this section, we will be answering a few questions asked by a consumer bank's
    marketers. Then, we will look at another important model development technique—ensemble
    learning—which will be useful in combining predictions from different models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将回答消费银行营销人员提出的一些问题。然后，我们将研究另一个重要的模型开发技术——集成学习，这在将不同模型的预测结合起来方面非常有用。
- en: 'Sources of wealth: asset, income, and gifted'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 财富的来源：资产、收入和天赋
- en: One of the most common tasks in retail banking customer analytics is to retrieve
    additional data that helps us to explain the customers' investment behavior and
    patterns. No doubt we will know the response of the customers, but the work of
    a model is to find out why they respond as they do. Surprisingly, there is a lot
    of aggregated information concerning the behaviors of individuals, such as census
    data. We can also find data from social media, where users use social media for
    authentication. The relevant social media information can then be chained together
    with individual-level transactional data that we observed internally in the organization.
    To explain individual banking behaviors, the most relevant supplementary data
    that we want is the information regarding their wealth.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 零售银行客户分析中最常见的任务之一是获取额外数据，以帮助解释客户的投资行为和模式。毫无疑问，我们将了解客户的响应，但模型的工作是找出他们为什么做出这样的响应。令人惊讶的是，关于个人行为的聚合信息有很多，例如人口普查数据。我们还可以从社交媒体获取数据，用户使用社交媒体进行身份验证。然后，可以将相关的社交媒体信息与我们在组织内部观察到的个人级交易数据进行链接。为了解释个人银行行为，我们最希望的相关补充数据是关于他们财富的信息。
- en: Customer life cycle
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户生命周期
- en: 'A typical life cycle involves three major phases—acquisition, cross-selling/upselling,
    and retention. The following diagram illustrates these three phases:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的生命周期包括三个主要阶段——获取、交叉销售/增值和保留。以下图表说明了这三个阶段：
- en: '![](img/f5254c6a-e008-4981-86d9-da80671bf861.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5254c6a-e008-4981-86d9-da80671bf861.png)'
- en: '**Acquisition** is when we start a commercial relationship with customers.
    Then, we move on to **cross-selling** and **upselling**. Cross-selling is about
    improving the number of products/services that are sold to the customer. Up-selling
    is about deepening the wallet share of the same product with the products/services.
    **Retention** is about keeping the relationship and is a defensive act by the
    bank to protect the relationship. Our first example (described in the following
    section) concerns cross-selling (if the customers do not have the product) and
    up-selling (if the customers own the product).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取**是我们开始与客户建立商业关系的时刻。然后，我们进入**交叉销售**和**向上销售**。交叉销售是提高向客户销售的产品/服务数量。向上销售是通过同一产品与其他产品/服务加深客户的资金份额。**保持**是指维持关系，这是银行保护关系的防御性举措。我们的第一个例子（将在后面的章节中描述）涉及交叉销售（如果客户没有该产品）和向上销售（如果客户拥有该产品）。'
- en: Ensemble learning
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成学习
- en: Ensemble learning is the boosting technique that helps us in improving the accuracy
    of the prediction. We will also learn how to use the graph database for knowledge
    storage. Knowledge storage is the current challenge in knowledge representation
    that can be used to empower AI for professional-grade financial services.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习是一种提升技术，可以帮助我们提高预测的准确性。我们还将学习如何使用图数据库进行知识存储。知识存储是当前知识表示中的挑战，可以用来增强人工智能在专业级金融服务中的应用。
- en: Ensemble learning is an approach that is used to summarize several models in
    order to give a more stable prediction. It was a very common approach before deep
    neural networks became popular. For completeness, we do not want to ignore this
    modeling technique in this very short book. In particular, we have used random
    forest, which means that we build lots of decision trees as a forest and we apply
    logic to cut down trees that have lower performance. Another approach would be
    combining the weaker model to generate a strong result, which is called the **boosting
    method**. We won't cover it here, but readers are encouraged to dig deeper in
    the scikit-learn documentation ([https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习是一种用于总结多个模型以提供更稳定预测的方法。在深度神经网络流行之前，这是非常常见的一种方法。为了完整性，我们不想忽视这种建模技术，即使这是一本非常简短的书。特别是，我们使用了随机森林，这意味着我们建立了大量的决策树作为森林，并应用逻辑来削减那些表现较差的树。另一种方法是将较弱的模型结合起来产生强大的结果，这被称为**提升方法**。我们在这里不详细讲解，但鼓励读者深入阅读 scikit-learn 文档（[https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)）。
- en: Knowledge retrieval via graph databases
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过图数据库进行知识检索
- en: To make a machine talk like a human in customer services, one of the key elements
    is the conversational component. When we engage in conversation, it is normal
    that human customers may not be able to provide the full amount of information
    required for processing. Humans can work with fuzziness. Humans can understand
    the context, and so can extrapolate meaning without the concepts being explicitly
    mentioned. Knowing that a machine can only solve definite problems while humans
    can work on fuzziness, it is the job of the machine to infer meaning from the
    knowledge map that it has for the customers. A graph database is used to serve
    this purpose.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要使机器在客户服务中像人类一样交流，其中一个关键要素是对话组件。当我们进行对话时，正常情况下人类客户可能无法提供处理所需的全部信息。人类能够应对模糊性。人类能够理解上下文，因此可以推断出意义，而无需明确提及概念。知道机器只能解决明确的问题，而人类能够处理模糊性，机器的任务是从它所拥有的知识图谱中推断出客户的意义。图数据库就是为此目的而使用的工具。
- en: Predict customer responses
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测客户响应
- en: So far, we have not talked about the day-to-day marketing activity of the bank.
    Now, we have finally come to look at how marketing prospects are determined. Even
    though each customer is unique, they are still handled by algorithms in the same
    way.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有讨论银行的日常营销活动。现在，我们终于来看看如何确定营销前景。尽管每个客户都是独特的，但他们仍然是通过算法以相同的方式处理的。
- en: In this example, you will assume the role of a data scientist tasked with the
    marketing of a term deposit product. We are going to train the model to predict
    the marketing campaign for the term deposit. Data pertaining to the bank's internal
    data regarding customers and their previous responses to the campaign is obtained
    from the Center for Machine Learning and Intelligent Systems ([https://archive.ics.uci.edu/ml/datasets/bank+marketing](https://archive.ics.uci.edu/ml/datasets/bank+marketing)),
    the Bren School of Information and Computer Science, and the University of California,
    Irvine. Survey information about personal wealth is obtained from the US Census
    Bureau ([https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html](https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html)),
    which serves as an augmentation to the bank's internal data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，你将扮演一名数据科学家的角色，负责推广定期存款产品。我们将训练模型来预测定期存款的营销活动。与银行内部客户数据及其对营销活动的历史响应相关的数据来自机器学习与智能系统中心（[https://archive.ics.uci.edu/ml/datasets/bank+marketing](https://archive.ics.uci.edu/ml/datasets/bank+marketing)）、布伦信息与计算机科学学院和加利福尼亚大学尔湾分校。有关个人财富的调查信息来自美国人口普查局（[https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html](https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html)），它作为对银行内部数据的补充。
- en: Solution
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'There are four steps to complete this example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此示例有四个步骤：
- en: 'We introduce random forest, which is a type of machine learning algorithm that
    utilizes ensemble learning, allowing predictions to be made by multiple models.
    The resulting model is a combination of the results from the multiple models.
    The following is the code snippet to import the required libraries and define
    the variables:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们引入了随机森林，它是一种机器学习算法，利用集成学习，使得可以通过多个模型进行预测。最终的模型是多个模型结果的组合。以下是导入所需库并定义变量的代码片段：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Census data provides information about the deposit and wealth of the age group
    placed in the bank. The following is the code snippet to handle census data:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人口普查数据提供了关于年龄段存款和财富的信息，这些数据被存储在银行中。以下是处理人口普查数据的代码片段：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We want to illustrate the mapping of one column''s data, using age to introduce
    wealth data. The following is the code snippet to combine census data with the
    bank''s data:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们希望通过使用年龄来引入财富数据，说明如何将一列数据映射。以下是将人口普查数据与银行数据结合的代码片段：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is the code snippet to train the model:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是训练模型的代码片段：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Congratulations! You have merged an external dataset with the internal dataset
    to augment our understanding of the customers.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经将外部数据集与内部数据集合并，增强了我们对客户的理解。
- en: Building a chatbot to service customers 24/7
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立一个24/7服务客户的聊天机器人
- en: 'When we interact with a robot, we expect it to understand and speak to us.
    The beauty of having a robot work for us is that it could serve us 24 hours a
    day throughout the week. Realistically, chatbots nowadays interact poorly with
    customers, and so we should try to break down the components of these chatbots
    to raise the bar to a higher standard. For an application-type development, you
    could use Google Assistant, Amazon''s Alexa, or IBM Watson. But for learning purposes,
    let''s break down the components and focus on the key challenges:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们与机器人互动时，我们期望它能够理解并与我们对话。机器人为我们工作的好处在于它可以24小时全天候为我们服务。实际上，现在的聊天机器人与客户的互动表现较差，因此我们应该尝试拆解这些聊天机器人的组成部分，并将其标准提高。对于应用类型的开发，你可以使用谷歌助手、亚马逊的Alexa或IBM的Watson。但为了学习目的，让我们拆解这些组成部分，并集中关注关键挑战：
- en: '![](img/f9437b12-bdce-4813-9521-471012ec8b4c.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9437b12-bdce-4813-9521-471012ec8b4c.png)'
- en: The chatbot performs two operations at a high level. One is to convert an input
    from voice to text, and another one is to translate an output from text to voice.
    Both of these operations involve extracting the entity and understanding the intent.
    In this example, the resulting text is an entity, whereas the meaning of the text
    is an intent. It represents a conversation between the service requester and the
    service provider. When faced with an incoming service request, the chatbot converts
    the voice instructions into text and adds context to the information received.
    Once the context building is done, the chatbot processes the information to generate
    the output in text format. The chatbot has to convert it into an audible voice
    output to be presented to the service requester. The whole scenario is explained
    in the preceding diagram.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人执行两个高级操作。一个是将语音输入转为文本，另一个是将文本输出转为语音。这两个操作都涉及提取实体和理解意图。在这个例子中，生成的文本是一个实体，而文本的意义则是意图。它代表了服务请求者和服务提供者之间的对话。当面对一个服务请求时，聊天机器人将语音指令转为文本，并为接收到的信息添加上下文。一旦上下文构建完成，聊天机器人就会处理这些信息并生成文本格式的输出。然后，聊天机器人必须将其转换为可听见的语音输出，呈现给服务请求者。整个场景在前面的图示中已做解释。
- en: Right now, let's focus on chat only, without worrying about voice recognition
    and utterance—that is, let's ignore voice to text and text to voice. In my opinion,
    since this task is machine- and memory-intensive, and the data is available in
    so many places, it is not for a start-up to work on this task; instead, we should
    leave it to a mainstream cloud provider with a strong infrastructure to deliver
    the service.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们只专注于聊天，不考虑语音识别和语音输出——也就是说，我们忽略语音转文本和文本转语音。在我看来，由于这个任务涉及大量的机器运算和内存消耗，而且数据在许多地方都可以获取，这个任务不适合初创公司去做；相反，我们应该将其交给具备强大基础设施的主流云服务提供商来提供服务。
- en: For text-only chat, the key focus should be on intent classification and entity
    extraction. While we have touched on entity extraction in the previous chapter,
    the input still needs to be classified before it is extracted. Intent classification
    works similarly to entity extraction, but treats the whole sentence as an entity
    for classification.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于仅文本聊天，关键的重点应放在意图分类和实体提取上。虽然我们在上一章中已提及实体提取，但输入仍然需要在提取之前进行分类。意图分类与实体提取的工作原理类似，但将整个句子作为一个实体进行分类。
- en: While it is very common to run a chatbot using ChatterBot or RasaNLU, we can
    break down the components to run from the bottom up.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用ChatterBot或RasaNLU来运行聊天机器人是非常常见的，但我们可以从下往上分解这些组件来运行。
- en: 'Let''s say that we are a simple bank that offers deposits and loans. We are
    building a simple chatbot that can serve existing customers only, and at the moment,
    we only have two customers, one called **abc** with a deposit account, and another
    called **bcd** with a loan account:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们是一个简单的银行，提供存款和贷款服务。我们正在构建一个只能为现有客户服务的简单聊天机器人，目前我们只有两个客户，一个叫做**abc**，拥有存款账户，另一个叫做**bcd**，拥有贷款账户：
- en: '![](img/fa9f65e9-f9a6-407c-ade7-46a8dbb18e8f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa9f65e9-f9a6-407c-ade7-46a8dbb18e8f.png)'
- en: Abc's deposit has an outstanding balance of 100 units and a pricing of 1, and
    bcd has an outstanding loan of 100 units and a pricing of 2.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: abc的存款余额为100个单位，定价为1，而bcd的贷款余额为100个单位，定价为2。
- en: Knowledge management using NLP and graphs
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自然语言处理和图谱进行知识管理
- en: Essentially, there are two ways for us to retrieve and update knowledge about
    our real world. One is to store the knowledge in vector space and read the file
    to our memory during runtime using programs such as Word2Vector and BERT. Another
    approach is to load the knowledge into a graph database, such as Neo4j, and retrieve
    and query the data. The strength and weakness of both approaches lies in speed
    and transparency. For high-speed subject classification, in-memory models fare
    better, but for tasks that require transparency, such as banking decisions, the
    updating of data requires full transparency and permanent record keeping. In these
    cases, we will use a graph database. However, like the example we briefly covered
    in [Chapter 7](d29ff3a8-3879-4d50-8795-a39bae5cc793.xhtml), *Sensing Market Sentiment
    for Algorithmic Marketing at Sell Side*, NLP is required to extract information
    from the document before we can store the information in graph format.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，我们有两种方法来检索和更新我们现实世界的知识。一种是将知识存储在向量空间中，并在运行时使用诸如 Word2Vector 和 BERT 等程序将文件读取到内存中。另一种方法是将知识加载到图数据库中，例如
    Neo4j，并检索和查询数据。这两种方法的优势和劣势在于速度和透明度。对于高速主题分类，内存模型表现更好，但对于需要透明度的任务，例如银行决策，数据更新需要完全透明和永久记录。在这些情况下，我们将使用图数据库。然而，就像我们在[第7章](d29ff3a8-3879-4d50-8795-a39bae5cc793.xhtml)中简要介绍的例子*Sensing
    Market Sentiment for Algorithmic Marketing at Sell Side*一样，需要使用 NLP 从文档中提取信息，然后才能将信息存储为图格式。
- en: Practical implementation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际实现
- en: 'The following are the steps to complete this example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完成此示例的步骤：
- en: 'Use the Cypher languages to import `csv` files into the database. We assume
    that the CSV file is dumped from the traditional SQL database. The following are
    the commands to be executed from the command line:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Cypher 语言将 `csv` 文件导入数据库。我们假设 CSV 文件是从传统 SQL 数据库中导出的。以下是从命令行执行的命令：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Open the browser and navigate to `http://localhost:7474/browser/`. Then, create
    a `username` and set a `password`. This will be executed only once:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开浏览器并导航至 `http://localhost:7474/browser/`。然后，创建一个 `username` 并设置一个 `password`。这将仅执行一次：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Delete all nodes:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除所有节点：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create customer data:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建客户数据：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create product data:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建产品数据：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Load the CSV file:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 CSV 文件：
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Match and return the data:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 匹配并返回数据：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Cypher is a language in itself; what we do is essentially create the product
    and customers. Then, we load another file that connects customers to products.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Cypher 本身是一种语言；我们所做的基本上是创建产品和客户。然后，我们加载另一个连接客户和产品的文件。
- en: 'We will connect to the `Neo4j` database that we just populated with data. The
    parameters follow the default setting. Please note the unique syntax of Cypher.
    In addition, the NLP model is loaded to be used for similarity analysis of the
    inputted instruction. The Cypher queries are stored in a dictionary. After the
    intent is read, the query string is retrieved. Then, we build the knowledge using
    the graph database:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将连接到刚刚填充数据的`Neo4j`数据库。参数遵循默认设置。请注意 Cypher 的独特语法。此外，加载了 NLP 模型以用于输入指令的相似性分析。Cypher
    查询存储在字典中。读取意图后，检索查询字符串。然后，我们使用图数据库构建知识：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Users should be authenticated and identified properly using the SQL database.
    For ease of illustration, we will use `GraphDatabase`, but it is quite clear that
    using `GraphDatabase` for authentication is not right because we want to store
    a huge amount of data with usernames and passwords in a dedicated table whose
    access rights we can set to fewer individuals than the total number of people
    on the database. The following is the code snippet to authenticate the user:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户应使用 SQL 数据库正确进行身份验证和标识。为了便于说明，我们将使用`GraphDatabase`，但显然使用`GraphDatabase`进行身份验证是不正确的，因为我们希望将大量数据与用户名和密码存储在专用表中，其访问权限设置为少于数据库上总人数的个体。以下是验证用户的代码片段：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Sentence intent and entity extraction utilizes spaCy on similarity analysis.
    Based on a pretrained word-to-vector model, the reserved words on intents and
    entities are compared with the inputted sentence to extract the relevant intent
    and entities. The model is overly simplified as readers are left with a lot of
    creative space to enhance the extraction works by using a better language model,
    such as BERT, on the assumption that we have made the relevant model to perform
    the relevant classification task.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 句子意图和实体提取利用spaCy进行相似性分析。基于预训练的词向量模型，意图和实体的保留词与输入的句子进行比较，以提取相关的意图和实体。该模型过于简化，读者有足够的创作空间，通过使用更好的语言模型，如BERT，来增强提取工作，假设我们已经制作了相关的模型来执行相关的分类任务。
- en: 'The following is the code snippet to extract entities and add intent:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是提取实体并添加意图的代码片段：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Cross-checking and further requesting missing information
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉检查并进一步请求缺失信息
- en: The program will continuously ask for intents, products, and attributes until
    all three pieces of information are clear to the program. Underneath the classification
    of each of these parameters, we deploy Word2vec for simplified classification.
    In fact, we can run a best-in-class topic classification model, such as BERT,
    to understand the languages and topics.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 程序将不断地请求意图、产品和属性，直到这三项信息对程序明确为止。在每个参数的分类下，我们使用Word2vec进行简化的分类。实际上，我们可以运行一个一流的话题分类模型，例如BERT，来理解语言和话题。
- en: 'The following is the code snippet to request missing information from the user:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是请求用户提供缺失信息的代码片段：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Extracting the answer
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提取答案
- en: 'When all information is filled in, the Cypher query will be executed and the
    information will be presented to the user. The following is the code snippet to
    extract the answer:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有信息填写完成后，将执行Cypher查询，信息将呈现给用户。以下是提取答案的代码片段：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Sample script of interactions
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交互样本脚本
- en: 'The following snippet shows the users'' output and input. It is meant to show
    that the NLU can indeed extract intent and entities using closely associated words,
    thanks to the spaCy dictionary that allows us to find similar words. The whole
    point of the example is to show that for decisions requiring complete information
    before they are made, the graph database allows us to manage the dialogue and
    follow up with the missing information before any instructions are executed to
    serve the user. This is a very important feature when it comes to making professional
    decisions where we need its rationale to be transparent to a high degree of accuracy,
    as far as the machine can understand the language. The following is a snippet
    of the sample conversation of the chatbot:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下片段展示了用户的输入和输出。它旨在展示NLU如何使用密切相关的词汇提取意图和实体，得益于spaCy字典使我们能够找到相似的词汇。这个示例的关键是展示，对于那些需要在做出决策之前获得完整信息的情况，图数据库允许我们管理对话并在执行任何指令以服务用户之前跟进缺失的信息。这在做出专业决策时非常重要，因为我们需要其推理过程对机器能够理解的语言具有较高的透明度和准确性。以下是聊天机器人的样本对话片段：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Congratulations! You have built a very simple chatbot that can show you the
    core functionality of chatbots.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经构建了一个非常简单的聊天机器人，它可以向你展示聊天机器人的核心功能。
- en: The example we are using is a very good echo of what we start with in commercial
    banking in terms of using borrowers' and depositors' data using reinforcement
    learning. Back then, the data was stored in variables at runtime. Right now, we
    have demonstrated another possibility for storing the data in graph data. Indeed,
    compared to the example in [Chapter 3](61949743-f7c3-4295-aaee-dab1d169d25c.xhtml), *Using
    Features and Reinforcement Learning to Automate Bank Financing,* the speed of
    reinforcement learning will be slower if we were to store data in a graph database
    rather than variables in a Python program. Therefore, we will use a graph database,
    but only for production and application levels when individual dialogues can tolerate
    some delay compared with a computation-intensive training phase.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的示例非常好地反映了我们在商业银行中使用借款人和存款人数据结合强化学习的起点。当时，数据是在运行时存储在变量中的。现在，我们展示了将数据存储在图形数据中的另一种可能性。事实上，与[第3章](61949743-f7c3-4295-aaee-dab1d169d25c.xhtml)中“*使用特征和强化学习来自动化银行融资*”的示例相比，如果我们将数据存储在图数据库中，而不是Python程序中的变量中，强化学习的速度会较慢。因此，我们将使用图数据库，但仅在生产和应用级别使用，当个别对话可以容忍相对于计算密集型训练阶段的延迟时。
- en: Summary
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about NLP and graph databases and we learned about
    the financial concepts that are required to analyze customer data. We also learned
    about an artificial intelligence technique called ensemble learning. We looked
    at an example where we predicted customer responses using natural language processing.
    Lastly, we built a chatbot to serve requests from customers 24/7\. These concepts
    are very powerful. NLP is capable of enabling programs to interpret languages
    that humans speak naturally. The graph database, on the other hand, is helpful
    in designing highly efficient algorithms.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了自然语言处理（NLP）和图数据库，并了解了分析客户数据所需的金融概念。我们还学习了一种名为集成学习的人工智能技术。我们通过一个例子来预测客户的响应，使用了自然语言处理技术。最后，我们构建了一个聊天机器人，能够24/7为客户提供服务。这些概念非常强大。NLP能够让程序理解人类自然使用的语言。而图数据库则有助于设计高效的算法。
- en: In the next chapter, we will learn about practical considerations to bear in
    mind when you want to build a model to solve your day-to-day challenges. In addition,
    we also want to look at the practical IT considerations when equipping data scientists
    with languages to interact with IT developers who put the algorithm to use in
    real life.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习在构建模型来解决日常挑战时需要考虑的实际因素。此外，我们还将讨论在为数据科学家提供与IT开发人员互动的语言时，涉及到的实际IT考虑因素，这些开发人员将算法应用到现实生活中。
