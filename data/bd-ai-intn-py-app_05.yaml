- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Vector Databases
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量数据库
- en: Sometimes, data is rich with information and has a well-defined structure. If
    you know what you want, then this data is straightforward to work with in a modern
    database system. However, you often don’t know exactly what you need. Without
    specific search terms or phrases, you may not receive optimal search results.
    For example, you might not know the brand or name of your picky pet’s favorite
    food. In such complex cases, traditional information search and retrieval methods
    can fall short.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据信息丰富且结构明确。如果你知道你需要什么，那么在现代数据库系统中处理这些数据就很简单。然而，你通常不知道确切需要什么。没有特定的搜索词或短语，你可能不会收到最佳搜索结果。例如，你可能不知道你挑剔的宠物最喜欢的食物的品牌或名称。在这种情况下，传统的信息搜索和检索方法可能无法满足需求。
- en: Modern AI research has given rise to a new class of methods that can encode
    the underlying semantic meaning of something instead of just its raw data. For
    example, AI models can understand that when you ask for `the new action movie
    with that one actor who was also in the movie with green falling numbers`, you’re
    asking for the latest *John Wick* film, which stars Keanu Reeves, who was also
    the star of *The* *Matrix* films.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现代AI研究催生了一类新的方法，可以编码某物背后的语义含义，而不仅仅是其原始数据。例如，AI模型可以理解，当你要求“那个演员也出演了带有绿色下落数字的电影的新动作片”时，你是在询问最新的*约翰·威克*电影，该片由基努·里维斯主演，他也是*黑客帝国*系列电影的主角。
- en: To achieve this result, these methods convert their inputs into a numerical
    format called a **vector embedding**. **Vector databases** provide a means to
    efficiently store, organize, and search these vector representations. This makes
    vector databases valuable tools for retrieval tasks, which are common in AI applications.
    In this chapter, you will learn about vector search, the key concepts and algorithms
    associated with it, and the significance of vector databases. By the end of this
    chapter, you will understand the workings of graph connectivity and its application
    in architecture patterns such as RAG. You will also understand the best practices
    for building vector search systems.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一结果，这些方法将它们的输入转换为一种称为**向量嵌入**的数值格式。**向量数据库**提供了一种有效存储、组织和搜索这些向量表示的方法。这使得向量数据库成为检索任务的宝贵工具，这在AI应用中很常见。在本章中，你将了解向量搜索、与之相关的关键概念和算法，以及向量数据库的重要性。到本章结束时，你将理解图连接性的工作原理及其在RAG等架构模式中的应用。你还将了解构建向量搜索系统的最佳实践。
- en: 'This chapter will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Vector embeddings and similarity
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量嵌入和相似度
- en: Nearest neighbor vector search
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近邻向量搜索
- en: The need for vector databases
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量数据库的需求
- en: Case studies and real-world applications
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 案例研究和实际应用
- en: Vector search best practices
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量搜索最佳实践
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: While not required, it may help to have some familiarity with graph data structures
    and operations. You may also want to know about the embedding models that are
    used to create vectors, which are discussed in more detail in [*Chapter 4*](B22495_04.xhtml#_idTextAnchor061),
    *Embedding Models*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不是必需的，但了解图数据结构和操作可能会有所帮助。你可能还想知道用于创建向量的嵌入模型，这些模型在[*第4章*](B22495_04.xhtml#_idTextAnchor061)“嵌入模型”中进行了更详细的讨论。
- en: What is a vector embedding?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是向量嵌入？
- en: At the most basic level, a **vector** is a list of numbers plus an implicit
    structure that determines how those numbers are defined and how you can compare
    them. The number of elements in a vector is the vector’s dimension.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本层面上，一个**向量**是一系列数字加上一个隐含的结构，该结构决定了这些数字的定义方式以及如何比较它们。向量中的元素数量是向量的维度。
- en: '`[year, make, model, color, mileage]`. These properties form a `[2000, Honda,
    Accord,` `Gold, 122000]`.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`[年份, 品牌, 型号, 颜色, 行驶里程]`。这些属性组成一个`[2000, 本田, Accord,` `金色, 122000]`。'
- en: This is a useful model for building intuition on how vectors can encode information.
    However, each element may not always correspond to a concrete idea with a numerable
    set of possible values. The vectors used in AI applications are more abstract
    and have significantly more dimensions. In a way, they smear concrete ideas across
    many dimensions and standardize to a single set of possible values for every dimension.
    For example, vectors from OpenAI’s `text-embedding-ada-002` model always have
    1,536 elements, and each element is a floating-point number between -1 and 1.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有用的模型，可以帮助您建立向量如何编码信息的直观理解。然而，每个元素并不总是对应于一个具有可数可能值的明确概念。在人工智能应用中使用的向量更加抽象，并且具有显著更多的维度。从某种意义上说，它们将具体概念分散到许多维度上，并将每个维度标准化为单一的可能值集合。例如，来自OpenAI的`text-embedding-ada-002`模型的向量总是有1,536个元素，每个元素是介于-1和1之间的浮点数。
- en: The vectors used in AI applications are the output of **embedding models**.
    These are **machine learning** (**ML**) models that are pre-trained to convert
    inputs, typically a string of text tokens, into vectors that encode the semantic
    meaning of the input. For humans, the many dimensions of these vectors are basically
    impossible to decipher. However, the embedding model learns an implicit meaning
    for every dimension during training and can reliably encode that meaning for its
    inputs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能应用中使用的向量是**嵌入模型**的输出。这些是**机器学习**（**ML**）模型，它们经过预训练，可以将输入（通常是文本标记的字符串）转换为编码输入语义意义的向量。对于人类来说，这些向量的许多维度基本上是无法解读的。然而，嵌入模型在训练过程中为每个维度学习一个隐含的意义，并且可以可靠地为它的输入编码这种意义。
- en: The exact structure of the vectors varies between embedding models, but a specific
    model always outputs vectors of the same size. To use a vector, it’s imperative
    to know which model created it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的具体结构在不同嵌入模型之间有所不同，但特定模型总是输出相同大小的向量。要使用向量，了解它是由哪个模型创建的是至关重要的。
- en: Vector similarity
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量相似度
- en: Beyond storing high-dimensional vector data, vector databases also support various
    operations that let you query and search for the vectors.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了存储高维向量数据外，向量数据库还支持各种操作，让您能够查询和搜索向量。
- en: The most common operation is **nearest neighbor search**, which returns a list
    of stored vectors that are most similar to an input query vector. Common search
    interfaces are familiar territory. For instance, e-commerce searches often prioritize
    products relevant to your query, even if they aren’t exact matches. Nearest neighbor
    search uses the semantic nature of embedding model vectors to make finding *similar*
    vectors the same as finding *relevant* results.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的操作是**最近邻搜索**，它返回与输入查询向量最相似的存储向量的列表。常见的搜索界面是熟悉的领域。例如，电子商务搜索通常会优先显示与您的查询相关的产品，即使它们不是完全匹配。最近邻搜索利用嵌入模型向量的语义特性，使得找到*相似*向量与找到*相关*结果相同。
- en: But what does it mean for two vectors to be similar? In short, similar vectors
    are close together, which you can measure as a distance. There are many ways to
    define **distance**, including some that become more relevant in higher dimensions.
    It’s not possible to visualize how distance works for high-dimensional vectors
    but it’s straightforward to see how the ideas work for small vectors and then
    scale them up.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但两个向量相似意味着什么呢？简而言之，相似的向量彼此靠近，这可以通过距离来衡量。有许多定义**距离**的方法，包括一些在更高维度中变得更加相关的定义。对于高维向量，无法可视化距离如何工作，但对于小向量，这些想法是显而易见的，然后可以将其扩展。
- en: 'If you think back to geometry class, you’ll remember that you can find the
    distance between two coordinate vectors using the distance formula. For example,
    2D coordinates such as `(x, y)` use the distance formula `distance(a, b) = sqrt((a_x
    - b_x)**2 + (a_y - b_y)**2)`. It also works for 3D coordinates, where the formula
    has another component for the extra dimension: `sqrt((a_x - b_x)**2 + (a_y - b_y)**2
    + (a_z - b_z)**2)`. This pattern generalizes to any number of dimensions and is
    referred to as the **Euclidean distance** between two *n*-dimensional points.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回想起几何课，您会记得您可以使用距离公式找到两个坐标向量之间的距离。例如，二维坐标（x, y）使用距离公式`distance(a, b) = sqrt((a_x
    - b_x)**2 + (a_y - b_y)**2)`。这也适用于三维坐标，其中公式有一个额外的维度分量：`sqrt((a_x - b_x)**2 + (a_y
    - b_y)**2 + (a_z - b_z)**2)`。这种模式可以推广到任何数量的维度，被称为两个*n*-维点之间的**欧几里得距离**。
- en: In theory, you can also use Euclidean distance to measure distances between
    high-dimensional vectors such as those used in AI applications. Practically, however,
    the usefulness of Euclidean distance breaks down as you continue to increase the
    number of dimensions. This pattern of intuitions and tools that work in small
    dimensions breaking down at higher dimensions is common and often referred to
    as the **curse** **of dimensionality**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，你也可以使用欧几里得距离来测量用于人工智能应用的高维向量之间的距离。实际上，然而，随着维数的增加，欧几里得距离的有用性会降低。这种在小维度上工作良好而在高维度上失效的直觉和工具模式很常见，通常被称为**维度诅咒**。
- en: Instead of Euclidean distance, most applications use a different distance metric
    called **cosine similarity**. Unlike Euclidean distance, which measures the space
    between the *tips* of two vectors, cosine similarity uses a different formula
    that measures the size of the angle between two vectors that share a common base.
    It effectively determines whether two vectors are identical, completely unrelated,
    or (most likely) somewhere in between in a mathematically precise way, as shown
    in *Figure 5**.1*. Similar vectors point in almost the same direction, unrelated
    vectors are orthogonal, and opposite vectors point in opposite directions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与欧几里得距离不同，大多数应用使用一种称为**余弦相似度**的不同距离度量。与测量两个向量**尖端**之间空间的欧几里得距离不同，余弦相似度使用不同的公式来测量共享相同基的两个向量之间的角度大小。它有效地以数学精确的方式确定两个向量是否相同、完全不相关，或者（最可能的情况）在两者之间，如图
    *图 5**.1* 所示。相似的向量几乎指向同一方向，不相关的向量是正交的，相反的向量指向相反的方向。
- en: '![](img/B22495_05_01.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_05_01.jpg)'
- en: 'Figure 5.1: A comparison of vector measurements'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：向量测量的比较
- en: Cosine similarity equips you with a tool to measure the distance between two
    vectors. Due to the nature of how vector embeddings carry semantic information,
    it’s also a tool to measure how related or relevant two vectors are to one another.
    If you extend this idea to more vectors, you can figure out how related a given
    vector is to any of the others and even rank them all by relevance. This is the
    core idea behind **vector** **search algorithms**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度为你提供了一个测量两个向量之间距离的工具。由于向量嵌入携带语义信息的本质，它也是一个测量两个向量之间相关度或相关性的工具。如果你将这个想法扩展到更多的向量，你可以找出给定向量与任何其他向量的相关性，甚至可以根据相关性对所有向量进行排名。这是**向量搜索算法**背后的核心思想。
- en: The process of comparing many vectors in this way brings its own complexity
    and challenges. To deal with them, search providers have developed various approaches
    to nearest neighbor search that balance trade-offs and optimize for different
    use cases. The next section will discuss two approaches to handle real search
    use cases.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式比较许多向量会带来其自身的复杂性和挑战。为了应对这些挑战，搜索提供商已经开发了各种最近邻搜索方法，以平衡权衡并针对不同的用例进行优化。下一节将讨论两种处理实际搜索用例的方法。
- en: Exact versus approximate search
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确搜索与近似搜索
- en: Sometimes, your use case requires that searches return only the true nearest
    neighbors. For example, think about an authentication app that stores biometric
    information about its users as embedded vectors so that they can identify themselves
    later. When they scan their fingerprint or face, the app creates a vector embedding
    of the scanned data and uses it as the query vector in a nearest neighbor search.
    An app like this should never misidentify the user as someone else with a similar
    fingerprint or face.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你的用例需要搜索只返回真正的最近邻。例如，想象一个存储用户生物识别信息（作为嵌入向量）的认证应用，以便他们以后可以识别自己。当他们扫描指纹或面部时，应用会创建扫描数据的向量嵌入，并将其用作最近邻搜索中的查询向量。这样的应用绝不应该将用户误识别为具有相似指纹或面部的人。
- en: This use case is perfect for an **exact nearest neighbor** (**ENN**) search,
    which guarantees that the search results are the best possible matches. This type
    of search must always return the closest matching stored vector and ensure that
    it appears before other similar but more distant matches.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种用例非常适合**精确最近邻**（**ENN**）搜索，它保证了搜索结果是最佳可能的匹配。此类搜索必须始终返回最近的匹配存储向量，并确保它出现在其他相似但更远的匹配之前。
- en: 'One straightforward approach is to brute-force the problem: calculate the distance
    between the query vector and every stored vector, then return a list of the results
    sorted from closest to farthest. By checking every vector, you can guarantee that
    the search results include precisely the most relevant vectors in order. While
    effective for small datasets, this method quickly becomes computationally expensive
    and time-consuming as the number of stored vectors increases. Some clever approaches
    can help exact search scale to larger datasets, such as using tree-based indexes
    to avoid calculating similarity for every vector. This makes exact search useful
    for some additional kinds of applications, but ultimately, the problem does not
    scale well and can take a long time on large datasets. In cases where exactness
    is required, you have to accept its constraints and find ways around them.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一种直接的方法是暴力解决问题：计算查询向量和每个存储向量的距离，然后返回一个按从近到远排序的结果列表。通过检查每个向量，你可以保证搜索结果精确地包含按顺序排列的最相关向量。虽然这种方法对小型数据集有效，但随着存储向量的数量增加，它很快就会变得计算成本高和时间消耗大。一些巧妙的方法可以帮助精确搜索扩展到更大的数据集，例如使用基于树的索引来避免为每个向量计算相似度。这使得精确搜索对某些额外的应用类型有用，但最终，这个问题扩展性不好，在大数据集上可能需要很长时间。在需要精确性的情况下，你必须接受其约束并找到绕过它们的方法。
- en: For other common cases, however, it is enough to know that your search results
    are *close enough* to be the best match. This use case is called an **approximate
    nearest neighbor** (**ANN**) search and is powerful enough for many everyday applications.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他常见情况，只要知道你的搜索结果足够接近以成为最佳匹配就足够了。这种用例被称为**近似最近邻**（**ANN**）搜索，并且对于许多日常应用来说足够强大。
- en: For example, if you search for `movies like Inception` in a recommendations
    app, you don’t need the results to include a specific movie. Rather, you probably
    just want a list of a few similar sci-fi thrillers with mind-bending plots. A
    list of results such as `["Minority Report", "Memento", "Shutter Island"]` is
    useful, even if it turns out that the movie *Interstellar* is technically a closer
    semantic match than any of the returned results.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你在一个推荐应用中搜索“像《盗梦空间》一样的电影”，你不需要结果中包含特定的电影。相反，你可能只是想要一份包含几部类似科幻惊悚片，具有令人费解情节的电影列表。即使电影《星际穿越》在技术上比返回的结果更接近语义匹配，但像“《少数派报告》、《记忆碎片》、《禁闭岛》”这样的结果列表也是有用的。
- en: The choice between exact and approximate search comes down to your application’s
    requirements. You may have strict requirements that necessitate an exact search.
    However, you may also have a use case where an exact search, while useful, is
    not necessary to provide value. Or it might not make sense to do an exact search
    at all. In the next section, you’ll learn how to evaluate search algorithms to
    help you determine your requirements.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 精确搜索和近似搜索的选择取决于你的应用需求。你可能对精确搜索有严格的要求。然而，你可能也有一个用例，其中精确搜索虽然有用，但不是提供价值所必需的。或者，可能根本不需要进行精确搜索。在下一节中，你将学习如何评估搜索算法，以帮助你确定你的需求。
- en: Measuring search
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索度量
- en: 'You can describe a search algorithm in terms of its precision, recall, and
    latency:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用精确度、召回率和延迟来描述搜索算法：
- en: '**Precision** measures how accurate the search results are. Precise searches
    try to return only matches that are relevant to the query and few, if any, irrelevant
    results.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**衡量搜索结果的准确性。精确搜索试图只返回与查询相关的匹配项，并且尽可能少地返回无关结果。'
- en: '**Recall** measures how complete the search results are. If a search returns
    a large fraction of all relevant results, then it has a high recall.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**衡量搜索结果的完整性。如果一个搜索返回了所有相关结果的大部分，那么它就有很高的召回率。'
- en: '**Latency** measures how long a search query takes from start to finish. Every
    search takes some amount of time to return results. The exact latency varies between
    searches but, on average, it’s a function of how many vectors are in the search
    space and your precision and recall requirements.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**衡量搜索查询从开始到结束所需的时间。每个搜索都需要一定的时间来返回结果。确切的延迟因搜索而异，但平均而言，它是搜索空间中向量的数量以及你的精确度和召回率要求的一个函数。'
- en: These factors are tightly coupled and require trade-offs that define the nature
    of nearest neighbor searches. For example, an ENN search has perfect precision
    and will include the most relevant results. However, to keep the latency reasonable,
    it might omit some relevant results if there are too many. Because it misses valid
    results, this search would have a relatively low recall. If the ENN search also
    required a high recall, then the search would have to run for longer to ensure
    that enough relevant results are included.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素紧密相连，需要权衡，这定义了最近邻搜索的性质。例如，一个最近邻搜索（ENN）具有完美的精度，并将包括最相关的结果。然而，为了保持延迟合理，如果结果太多，它可能会省略一些相关的结果。因为它错过了有效结果，这种搜索的召回率相对较低。如果ENN搜索还需要高召回率，那么搜索就需要运行更长的时间以确保包括足够的相关结果。
- en: In an ANN search, you can relax your precision requirements, which allows you
    to optimize the other factors instead. You can get more complete results by either
    allowing the search to take more time or by returning more results that potentially
    include false positives. If you can tolerate false positives, for example, by
    filtering them out after the search in your app, then you can use ANN to run fast
    searches that return highly relevant result sets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工神经网络（ANN）搜索中，你可以放宽精度要求，这让你可以优化其他因素。你可以通过允许搜索花费更多时间或返回更多可能包含假阳性的结果来获得更完整的结果。例如，如果你可以容忍假阳性，比如在应用中搜索后过滤掉它们，那么你可以使用ANN来运行快速搜索，返回高度相关的结果集。
- en: You should evaluate your application and determine its top priority regarding
    these factors. Then, you can choose the appropriate search operation and tune
    the algorithm until the other factors are appropriately balanced.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该评估你的应用并确定其对这些因素的最高优先级。然后，你可以选择合适的搜索操作并调整算法，直到其他因素得到适当的平衡。
- en: '**Tuning** a search algorithm involves modifying the configuration parameters
    that determine how it constructs and traverses its index data structure. To get
    a better feel for what that means, you’ll spend the next few sections going over
    the concepts and data structures used to enable vector search operations, starting
    with the idea of connectivity.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**调整**搜索算法涉及修改确定其如何构建和遍历其索引数据结构的配置参数。为了更好地理解这意味着什么，你将在接下来的几节中了解用于启用向量搜索操作的概念和数据结构，从连通性的想法开始。'
- en: Graph connectivity
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图连通性
- en: 'If you’ve ever used a city’s public transit network to get around, you may
    have wondered about how the city chose to put the train or bus stops where they
    did. There are many factors at play, but if you look at an ideal case, then you
    can boil the choice down to two related factors: **connectivity** and **latency**.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经使用过城市的公共交通网络来出行，你可能想知道城市是如何选择将火车站或公交车站放在那里的。有许多因素在起作用，但如果你看一个理想的情况，那么你可以将选择归结为两个相关的因素：**连通性**和**延迟**。
- en: Think about the experience of a train rider, let’s call her Alice, visiting
    her friend, Bob, across the city. It would be great if there was a stop right
    next to Bob’s house because, then, Alice could see him right after stepping off
    the train. Of course, you can’t put a train station in front of every house, and
    after a certain point, adding more stops would increase the average trip time.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 想想火车乘客的经历，我们称她为Alice，她要访问城市另一边的她的朋友Bob。如果有一个车站就在Bob的家旁边那会很好，因为这样Alice就可以在下车后立即看到他。当然，你不能在每座房子前都建一个火车站，并且在某个点上，增加更多的车站会增加平均旅行时间。
- en: Every time you change the number of stops or connections, you may affect how
    long it takes to get between any two destinations in the system. Typically, the
    job of planning where to place public transit stops is done with thought and consideration
    by knowledgeable civil engineers, city planners, and other stakeholders. The primary
    goal of a transit network is to take a rider to a stop that is relatively close
    to their true final destination in a reasonable amount of time. By understanding
    their goal and applying specific strategies, city planners try to connect distant
    parts of the city in a way that’s useful and efficient for transit riders.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 每次你更改车站或连接的数量，你可能会影响系统内任何两个目的地之间的旅行时间。通常，规划公共交通车站位置的工作是由知识渊博的土木工程师、城市规划师和其他利益相关者经过深思熟虑和考虑后完成的。公共交通网络的主要目标是，在合理的时间内将乘客带到相对接近他们真正最终目的地的车站。通过了解他们的目标并应用特定的策略，城市规划者试图以对公共交通乘客有用和高效的方式连接城市的偏远地区。
- en: Similarly, the goal of an ANN search is to find a vector that is close to a
    given query vector, also in a reasonable amount of time. If you were to take inspiration
    from transit planners, you could use this similarity to your advantage and design
    an effective ANN index.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，人工神经网络搜索的目标是在合理的时间内找到一个接近给定查询向量的向量。如果你能从交通规划者那里得到灵感，你可以利用这种相似性来设计一个有效的ANN索引。
- en: Navigable small worlds
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可导航小世界
- en: In essence, both transit planning and nearest neighbor search boil down to a
    problem of building and traversing a graph that trades off connectivity and latency.
    You can use an algorithm called **navigable small worlds** (**NSW**) to build
    such a graph. It takes in vectors one at a time and adds a node to the graph for
    each one. Each node can also have connections to other nodes, called **neighbors**,
    that are assigned during graph construction.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，无论是交通规划还是最近邻搜索，都归结为在连接性和延迟之间进行权衡的图构建和遍历问题。你可以使用一个称为**可导航小世界**（**NSW**）的算法来构建这样的图。它一次处理一个向量，并为每个向量在图中添加一个节点。每个节点也可以与其他节点（称为**邻居**）建立连接，这些连接在图构建过程中分配。
- en: The NSW algorithm is designed to balance how relevant a node’s immediate neighbors
    are with how connected the node is to the rest of the graph. It will mostly assign
    neighbors that are closely related to a node. However, it may also sometimes connect
    two less similar nodes that are relatively far apart on the graph. If you think
    about the transit example, this is like having a bus route that has several stops
    in the same neighborhood but that also runs downtown. Residents can easily get
    to their local destinations. If they need to go outside of the neighborhood, then
    they still have access to the rest of the city.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: NSW算法旨在平衡一个节点的直接邻居的相关性与该节点与图中其余部分的连接性。它将主要分配与节点紧密相关的邻居。然而，它有时也可能连接两个在图上相对较远的、不太相似的节点。如果你考虑交通示例，这就像有一个有几个在同一社区内的停靠站的公交车路线，但也通往市中心。居民可以轻松到达他们的本地目的地。如果他们需要去社区外，他们仍然可以访问整个城市。
- en: For an example of an NSW graph, refer to *Figure 5**.2*. Notice that each node
    is connected to a maximum of three neighbors and that, in general, nearby nodes
    are closely connected. Each node represents a vector and nodes connected with
    lines are neighbors. The highlighted connections show the path of a greedy nearest
    neighbor search.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有关NSW图的示例，请参阅*图5.2*。注意，每个节点最多与三个邻居连接，并且通常附近的节点连接紧密。每个节点代表一个向量，用线条连接的节点是邻居。高亮显示的连接显示了贪婪最近邻搜索的路径。
- en: '![](img/B22495_05_02.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_05_02.jpg)'
- en: 'Figure 5.2: An NSW graph'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：一个NSW图
- en: Once you’ve constructed an NSW graph of your vectors, you can use it as an index
    for ANN searches. You can start at a random node and use a search algorithm to
    follow the neighbor connections until you reach the nearest neighbor. This lets
    you limit your similarity comparison to only a subset of the total search space.
    For example, notice how the search path in *Figure 5**.2* arrives at the nearest
    neighbor without visiting every node in the graph.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你构建了你的向量的NSW图，你可以将其用作ANN搜索的索引。你可以从一个随机节点开始，并使用搜索算法跟随邻居连接，直到你到达最近邻。这让你可以将相似性比较限制在总搜索空间的一个子集。例如，注意*图5.2*中的搜索路径是如何到达最近邻而不访问图中的每个节点的。
- en: How to search a navigable small world
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何搜索可导航小世界
- en: The exact search algorithm that you use to traverse an NSW graph may vary and
    affect the behavior of the search as a whole. The most common algorithm is a simple
    **greedy search**, where at every step, you find and take the best immediate option
    with no regard to previous or future steps. For example, a greedy search of an
    NSW graph first randomly selects a node to start at and then measures to see how
    close the node is to the query vector. Then, it measures the distance to each
    of the node’s neighbors. If one of the neighbors is closer than the current node,
    then the search moves on to that node and continues with the same measure-and-compare
    process. Otherwise, the search is complete and the current node is an approximate
    nearest neighbor.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你用来遍历NSW图的精确搜索算法可能有所不同，并会影响搜索的整体行为。最常用的算法是简单的**贪婪搜索**，在每一步，你找到并选择最佳的直接选项，而不考虑之前的或未来的步骤。例如，NSW图的贪婪搜索首先随机选择一个节点开始，然后测量该节点与查询向量的接近程度。然后，它测量到每个邻居的距离。如果其中一个邻居比当前节点更近，则搜索转移到该节点，并继续进行测量和比较过程。否则，搜索完成，当前节点是一个近似的最近邻。
- en: In this basic example of NSW with greedy search, the definition of *approximate*
    is very broad and the search may return suboptimal results. This comes down to
    the nature of graph search, which, in this case, is designed to find a local minimum
    of the graph. This local minimum is not guaranteed to be the *global* minimum,
    which is what makes the search approximate rather than exact. A greedy search
    algorithm alone can return false positives if it settles on a local minimum that
    is too far from the global minimum.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基本示例中，使用贪婪搜索的 NSW，*近似*的定义非常广泛，搜索可能会返回次优结果。这归结于图搜索的本质，在这种情况下，它是设计用来找到图的局部最小值的。这个局部最小值不保证是*全局*最小值，这就是为什么搜索是近似的而不是精确的。如果贪婪搜索算法在一个远离全局最小值的局部最小值上定居，它单独返回可能会是错误阳性。
- en: You can partially guard against this by tuning the graph’s construction parameters.
    However, due to the dynamic nature of search queries and the underlying data being
    searched, you can’t entirely prevent false positive local minima from existing.
    Instead, you need to find a way to minimize their impact.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过调整图的构建参数来部分防止这种情况。然而，由于搜索查询的动态性和搜索的数据基础，你无法完全防止错误阳性局部最小值的存在。相反，你需要找到一种方法来最小化它们的影响。
- en: One way is to run the search multiple times, starting from different randomized
    entry nodes. This method, called **randomized retries**, collects multiple samples
    from the graph and returns the best result out of all the samples. You can also
    add additional machinery to the algorithm to make it more robust. A common architecture
    pairs the greedy search algorithm with a configurable **priority queue** that
    keeps a sorted list of the nearest neighbors the search has seen. If the search
    encounters a false positive local minimum, the queue lets it backtrack and explore
    other branches of the graph that might lead to a nearer neighbor.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是通过从不同的随机入口节点多次运行搜索。这种方法被称为**随机重试**，它从图中收集多个样本，并从所有样本中返回最佳结果。你还可以向算法中添加额外的机制，使其更加健壮。一种常见的架构是将贪婪搜索算法与一个可配置的**优先队列**配对，该队列保持搜索已看到的最近邻的排序列表。如果搜索遇到错误阳性局部最小值，队列允许它回溯并探索可能导致更近邻的其他图分支。
- en: The exact search method you use depends on the dataset and your goals. For example,
    randomized retries are easy to implement and can run in parallel. They are useful
    for subtle, exploratory searches that might match many local minima. However,
    their random nature makes them non-deterministic, and each retry does a full search,
    which can quickly scale your costs. Conversely, priority queues are deterministic
    and precise but are harder to implement and tune.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用的确切搜索方法取决于数据集和目标。例如，随机重试易于实现且可以并行运行。它们适用于可能匹配许多局部最小值的微妙、探索性搜索。然而，它们的随机性质使它们非确定性，并且每次重试都进行完整搜索，这可能会快速增加你的成本。相反，优先队列是确定性和精确的，但实现和调整起来更困难。
- en: With this information, you have the basis for a useful vector search index.
    You could stop building the index here and start searching. However, you will
    quickly find that there are issues with this approach, particularly as you scale
    the search space to sizes commonly seen in AI apps. Randomized retries have significant
    computational overhead, and you must do more of them as you scale your data set.
    A priority queue keeps a search from getting stuck in local minima but does not
    prevent it from meandering through many nodes on the way to its target.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些信息，你有了构建有用向量搜索索引的基础。你可以在这里停止构建索引并开始搜索。然而，你很快会发现这种方法存在问题，尤其是在将搜索空间扩展到在 AI
    应用中常见的规模时。随机重试具有显著的计算开销，并且随着数据集的扩展，你必须进行更多的搜索。优先队列可以防止搜索陷入局部最小值，但不会阻止它在到达目标的过程中经过许多节点。
- en: To address these issues, you need to go beyond a single NSW graph. In the next
    section, you will see how combining multiple NSW graphs together can circumvent
    meandering searches and make randomized retries less necessary.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，你需要超越单个 NSW 图。在下一节中，你将看到如何将多个 NSW 图组合起来，以绕过迂回搜索并使随机重试变得不那么必要。
- en: Hierarchical navigable small worlds
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层次化可导航的小世界
- en: Think back to Alice’s public transit experience. What if, instead of the same
    city, she and Bob lived in different cities on opposite sides of the country?
    Alice could, in theory, limit herself to public transit services by crisscrossing
    the nation via a series of trains, buses, taxis, and bike shares. This would obviously
    take a lot of time and require many stops along the way. That’s because transit
    networks are only effective at the scale of an individual city. Once you zoom
    out farther, you need a different system.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下爱丽丝的公共交通体验。如果她与鲍勃住在国家另一边的不同城市，会怎样？从理论上讲，她可以通过一系列火车、公共汽车、出租车和自行车共享服务穿越全国，从而限制自己使用公共交通服务。这显然会花费很多时间，并在沿途需要许多停靠点。这是因为交通网络仅在单个城市的规模上有效。一旦你放大到更远的范围，你需要一个不同的系统。
- en: Instead of just using transit, Alice could instead start at her city’s airport
    and fly to Bob’s city. Even if her trip included a layover and multiple flights,
    it would still probably be faster than using transit alone. Once she gets to Bob’s
    city, she can use the subway system to get from the airport to his neighborhood
    quickly and efficiently.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用交通方式，爱丽丝还可以从她所在城市的机场出发，飞往鲍勃所在的城市。即使她的旅行包括转机和多次航班，这仍然可能比仅使用交通方式更快。一旦她到达鲍勃所在的城市，她就可以使用地铁系统快速有效地从机场到达他的社区。
- en: 'Alice’s trip took place at two distinct levels. First, she started at the level
    of airports, where she was free to travel to any destination airport connected
    to her home airport. At this layer, she had direct access to many different cities,
    but that access was limited to only one location in each city: the airport. She
    used the airports to get closer to Bob without spending too much time planning
    her route and traveling. Once she got to the closest airport to Bob, she dropped
    down into the second layer and gained access to a transit network that could get
    her even closer to Bob.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 爱丽丝的旅行发生在两个不同的层面上。首先，她从机场层面开始，在这个层面上，她可以自由地前往与她的家乡机场相连的任何目的地机场。在这一层，她可以直接访问许多不同的城市，但这种访问仅限于每个城市的一个位置：机场。她利用机场来接近鲍勃，而不必花费太多时间规划路线和旅行。一旦她到达鲍勃最近的城市机场，她就会下降到第二层，并能够访问一个能够让她更接近鲍勃的换乘网络。
- en: This is basically the idea of **hierarchical navigable small worlds** (**HNSW**).
    You can create a hierarchy of layers where each layer is an NSW graph. For example,
    look at *Figure 5**.3* to see a typical HNSW graph structure. The top layer has
    relatively few nodes that are all fairly distant from one another and sparsely
    connected. Each lower layer has all the nodes of the layer above it plus additional
    nodes and connections that make the graph denser and more connected. In this chapter’s
    example, the distinction between transit nodes and airport nodes is a natural
    way to split the layers. The airports are the top layer and the next layer down
    includes both the airports and the transit stops.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上是**分层可导航小世界**（**HNSW**）的概念。你可以创建一个层级的层次结构，其中每一层都是一个NSW图。例如，查看*图5.3*以了解典型的HNSW图结构。顶层有相对较少的节点，它们彼此之间距离较远且连接稀疏。每一层都包含上一层的所有节点，以及额外的节点和连接，使图更密集、更连通。在本章的例子中，交通节点和机场节点之间的区别是分割层的一种自然方式。机场是顶层，下一层包括机场和交通站点。
- en: '![](img/B22495_05_03.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_05_03.jpg)'
- en: 'Figure 5.3: An HNSW graph structure'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：HNSW图结构
- en: An actual HNSW algorithm would decide the *top* layer for each vector probabilistically
    with a node that exists only in lower layers being more likely than one that also
    exists in higher layers. A search starts in the top layer by finding the node
    that’s nearest to the query vector. Then, it moves to the same node but in the
    next layer down and continues the search from there. This continues until it reaches
    the nearest neighbor on the final layer, at which point, the search is complete.
    In *Figure 5**.3*, the highlighted connections show the path of a greedy nearest
    neighbor search across multiple layers.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的HNSW算法会以概率决定每个向量的*顶层*，只有存在于较低层的节点比同时存在于较高层的节点更有可能。搜索从顶层开始，通过找到与查询向量最近的节点。然后，它移动到下一层相同的节点，并从那里继续搜索。这个过程一直持续到达到最接近的邻居在最终层，此时搜索完成。在*图5.3*中，高亮显示的连接显示了跨多个层进行贪婪最近邻搜索的路径。
- en: HNSW is the foundation of many modern vector search applications. It’s battle-tested
    and proven to give useful results in a reasonable amount of time. The algorithm
    is highly suited for ANN use cases with configurable parameters that put you in
    control of how your searches perform.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: HNSW 是许多现代向量搜索应用的基础。它经过实战检验，并证明能够在合理的时间内提供有用的结果。该算法非常适合用于具有可配置参数的 ANN 用例，这些参数让你能够控制搜索的表现。
- en: Now that you have an idea of the inner workings of vector search, you can see
    how it requires purpose-built logic and data structures. In the next section,
    you’ll learn how vector databases encapsulate all of the technical details in
    order to make vector search available to developers.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了向量搜索的内部工作原理，你可以看到它需要专门设计的逻辑和数据结构。在下一节中，你将了解向量数据库如何封装所有技术细节，以便让开发者能够使用向量搜索。
- en: The need for vector databases
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量数据库的需求
- en: Vectors carry deep semantic information and have many potential use cases that
    will make them increasingly common over the next few years. Working with them
    requires specific and complex operations that only process vector data. Additionally,
    the demand for search can often vary substantially from the demand for more structured
    database queries.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 向量携带深层次的语义信息，并且有许多潜在的应用场景，在未来几年内将变得越来越普遍。与它们一起工作需要特定的复杂操作，这些操作仅处理向量数据。此外，搜索需求往往与更结构化的数据库查询需求有显著差异。
- en: Together, these factors mean vector operations and traditional database workloads
    are largely independent. This gives rise to the concept of a vector database that’s
    designed specifically to handle vector data, indexes, and workloads. From a developer’s
    perspective, vector databases can take several forms.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素共同意味着向量操作和传统数据库工作负载在很大程度上是独立的。这导致了专门设计来处理向量数据、索引和工作负载的向量数据库的概念。从开发者的角度来看，向量数据库可以采取几种形式。
- en: The most basic is a **standalone product** that’s independent from other operational
    databases. This type of vector database has the freedom to focus solely on implementing
    and optimizing vector operations without considering other database operations.
    However, often, vector search applications require additional filtering or metadata
    and may perform more traditional database operations based on search results.
    These use cases require either multiple queries to different databases at runtime
    or an additional syncing layer that copies data from your operational database
    to the vector store.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的是一种**独立产品**，它独立于其他操作数据库。这种类型的向量数据库有自由专注于实现和优化向量操作，而不必考虑其他数据库操作。然而，通常，向量搜索应用程序需要额外的过滤或元数据，并且可能基于搜索结果执行更多传统数据库操作。这些用例需要运行时对多个数据库进行多次查询，或者需要一个额外的同步层，该层将数据从操作数据库复制到向量存储中。
- en: Alternatively, a vector database can be baked into an existing database or data
    service. For example, a **general-purpose database management system** might support
    vector search operations in its query language if you’ve defined the appropriate
    vector search index. This allows applications to piggyback off of the existing
    system’s features and access search within the same system. The vector database
    can be scaled and run independently within the system but exposed to the user
    along with traditional operations as part of a unified API. This couples your
    vector store to your existing database but leads to simpler and easier-to-maintain
    architectures.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，向量数据库可以集成到现有的数据库或数据服务中。例如，一个**通用数据库管理系统**可能在其查询语言中支持向量搜索操作，如果你已经定义了适当的向量搜索索引。这允许应用程序利用现有系统的功能，并在同一系统中进行搜索。向量数据库可以在系统中独立扩展和运行，但作为统一
    API 的一部分向用户公开，包括传统操作。这使你的向量存储与现有数据库耦合，但导致更简单、更容易维护的架构。
- en: Regardless of form, vector databases are a key tool in AI applications. They
    are purpose-built to store and query vector data. You can configure them to deliver
    optimal search results and power AI applications.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不论形式如何，向量数据库都是人工智能应用中的关键工具。它们专门设计用于存储和查询向量数据。你可以配置它们以提供最佳搜索结果并推动人工智能应用。
- en: The next section will cover some ways that vector search can be used to enhance
    ML and AI models, including during training, fine-tuning, and runtime. You’ll
    also learn how vector search itself enables AI applications without additional
    functions or models.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将介绍一些使用向量搜索来增强机器学习和人工智能模型的方法，包括在训练、微调和运行时。你还将了解向量搜索本身如何使人工智能应用成为可能，而无需额外的功能或模型。
- en: How vector search enhances AI models
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何向量搜索增强AI模型
- en: AI models encompass a broad class of data structures and techniques. ML forms
    the core of most modern vector-based AI models, aiming to “teach” computers to
    do specific tasks via a training process. In general, ML processes work by feeding
    a curated dataset to a base model that can detect and infer patterns from the
    data. Once a model has learned these patterns, it’s able to recreate or interpolate
    them to process new inputs. These techniques and models are ubiquitous in the
    world of AI and are the secret sauce that powers novel use cases.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型涵盖了一类广泛的数据结构和技术。机器学习（ML）构成了大多数现代基于向量的AI模型的核心，旨在通过训练过程“教导”计算机执行特定任务。一般来说，ML处理过程通过向一个基础模型提供精心挑选的数据集，该模型能够从数据中检测和推断模式。一旦模型学会了这些模式，它就能够重新创建或插值它们以处理新的输入。这些技术和模型在AI世界中无处不在，是推动新型用例的秘密配方。
- en: 'In general, ML training and AI applications can be split into two concerns,
    as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，ML训练和AI应用可以分为两个关注点，如下：
- en: '**Information retrieval** involves finding relevant information that’s useful
    as input to an AI process. Vector search is very well suited for this task. Embedding
    models can encode the semantics of a huge variety of inputs into a standard vector
    form. Then, you can use search to find matches for an equally huge range of inputs,
    both structured and unstructured.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息检索**涉及找到对AI过程有用的相关信息。向量搜索非常适合这项任务。嵌入模型可以将各种输入的语义编码成标准向量形式。然后，你可以使用搜索来找到与同样广泛的输入的匹配，包括结构化和非结构化输入。'
- en: '**Information synthesis** combines multiple pieces of information, possibly
    from different sources, into a coherent and useful result. This is the domain
    of GenAI models. These models can’t reliably find or generate true facts, but
    they can effectively process and reformat input information.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息综合**将多个信息片段，可能来自不同的来源，综合成一个连贯且有用的结果。这是生成式AI模型（GenAI）的领域。这些模型无法可靠地找到或生成真实事实，但它们可以有效地处理和重新格式化输入信息。'
- en: Vector search enhances ML and AI models by providing them with access to the
    most relevant data at every stage, from training to fine-tuning to runtime execution.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索通过在每个阶段（从训练到微调再到运行时执行）为ML和AI模型提供访问最相关数据的能力，增强了它们。
- en: During training, you can use a vector database to store and search your training
    data. You can design a process that finds the most relevant data from the corpus
    to use for each training task. For example, when training a language model for
    a specific domain such as medicine, you could use vector search to retrieve the
    most relevant chapters from medical textbooks for each training batch. This ensures
    that the model learns the most pertinent information without being distracted
    by noise.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，你可以使用向量数据库来存储和搜索你的训练数据。你可以设计一个过程，从语料库中找到与每个训练任务最相关的数据。例如，当训练一个特定领域（如医学）的语言模型时，你可以使用向量搜索来检索每个训练批次中最相关的医学教科书章节。这确保了模型学习到最相关的信息，而不会被噪声所干扰。
- en: You can apply the same idea during fine-tuning, which is essentially a secondary
    training stage on top of a more generic base model. For example, you could fine-tune
    the medicine language model to generate reports using a hospital system’s preferred
    style and structure. Vector search could help find human-written reports that
    are relevant to each training topic.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在微调阶段应用同样的想法，这本质上是在更通用的基础模型之上的一个次要训练阶段。例如，你可以微调医学语言模型，使其能够使用医院系统首选的风格和结构生成报告。向量搜索可以帮助找到与每个训练主题相关的由人类编写的报告。
- en: Whether your model is specialized or general purpose, you can customize its
    runtime behavior by modifying the inputs you give to it. Vector search can analyze
    raw input and find related information. Then, you can augment or refine the raw
    input to include the retrieved context. For example, you might maintain a vector
    database of rare diseases and search for anything that matches a user’s description
    in order to get a more tailored diagnosis.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 不论你的模型是专用型还是通用型，你都可以通过修改提供给它的输入来定制其运行时行为。向量搜索可以分析原始输入并找到相关信息。然后，你可以增强或细化原始输入，以包括检索到的上下文。例如，你可能会维护一个罕见疾病的向量数据库，并搜索任何与用户描述匹配的内容，以便获得更精确的诊断。
- en: AI applications come in many forms, but modern apps increasingly use a runtime
    customization approach to provide relevant context to generative transformer models.
    This architecture is the basis of a technique called **retrieval-augmented generation**
    (**RAG**), which you’ll learn about in greater depth in [*Chapter 8*](B22495_08.xhtml#_idTextAnchor180),
    *Implementing Vector Search in* *AI Applications*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能应用形式多样，但现代应用越来越多地采用运行时定制方法，为生成式变换器模型提供相关上下文。这种架构是**检索增强生成**（**RAG**）技术的基础，你将在[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*中深入了解。
- en: Up to this point, you’ve learned the theory and mechanics of vector databases
    and search operations. Next, you’ll look at some examples of real vector database
    use cases that highlight how vectors are the core of modern AI apps.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学习了向量数据库和搜索操作的理论和机制。接下来，你将查看一些真实的向量数据库用例示例，突出向量是现代AI应用的核心。
- en: Case studies and real-world applications
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究和实际应用
- en: Vector search is a powerful tool that enables you to build sophisticated systems
    for finding information based on its meaning, rather than just its exact words.
    By understanding the context and relationships between data points, vector search
    helps you retrieve highly relevant results. So far, you have learned about the
    different concepts involved with vector search and some of the different offerings
    that exist in the market, but how do businesses integrate vector search into their
    applications?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索是一个强大的工具，它使你能够构建基于信息意义而不是精确单词的复杂系统来查找信息。通过理解数据点之间的上下文和关系，向量搜索帮助你检索高度相关的结果。到目前为止，你已经了解了向量搜索涉及的不同概念以及市场上的一些不同产品，但企业如何将向量搜索集成到他们的应用程序中呢？
- en: 'In this section, you will explore three popular methods for leveraging vector
    search: semantic search, RAG, and **robotic process automation** (**RPA**). You
    will look at existing case studies of **MongoDB Atlas Vector Search** that fit
    into each of these buckets, and how these applications deliver value to the end
    user through more accurate search that wasn’t previously possible. Each of the
    following case studies was originally published as a part of the *Building AI
    with MongoDB* series of customer stories ([https://www.mongodb.com/resources/use-cases/artificial-intelligence?tck=blog-genai&section=resources&contentType=case-study](https://www.mongodb.com/resources/use-cases/artificial-intelligence?tck=blog-genai&section=resources&contentType=case-study)).
    These stories are presented here to showcase the variety of vector search use
    cases that can be built on the flexible, scalable, and multifaceted MongoDB Atlas
    platform.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将探索三种利用向量搜索的流行方法：语义搜索、RAG和**机器人流程自动化**（**RPA**）。你将查看适合每个这些类别的现有**MongoDB
    Atlas向量搜索**案例研究，以及这些应用如何通过更精确的搜索为最终用户提供价值，而这种搜索之前是不可能的。以下每个案例研究最初都是作为*用MongoDB构建AI*系列客户故事的一部分发布的（[https://www.mongodb.com/resources/use-cases/artificial-intelligence?tck=blog-genai&section=resources&contentType=case-study](https://www.mongodb.com/resources/use-cases/artificial-intelligence?tck=blog-genai&section=resources&contentType=case-study)）。这些故事在此处展示，以展示可以在灵活、可扩展和多功能的MongoDB
    Atlas平台上构建的向量搜索用例的多样性。
- en: Okta – natural language access request (semantic search)
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Okta – 自然语言访问请求（语义搜索）
- en: '**Okta**, one of the world''s leading identity security providers, uses a natural
    language RAG interface to allow users to easily request roles for new technologies
    in their organizations. They built a system called **Okta Inbox** using Atlas
    Vector Search and their own custom embedding model that makes it possible for
    users to map natural language queries to the right roles.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**Okta**，全球领先的身份安全提供商之一，使用自然语言RAG界面，允许用户轻松地在其组织中请求新技术角色。他们利用Atlas向量搜索和自己的定制嵌入模型构建了一个名为**Okta邮箱**的系统，使用户能够将自然语言查询映射到正确的角色。'
- en: '![](img/B22495_05_04.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_05_04.jpg)'
- en: 'Figure 5.4: Okta Inbox user request form'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：Okta邮箱用户请求表单
- en: This is an example of leveraging semantic search to solve a problem, where the
    embedding models trained by Okta’s data science team were capable of mapping natural
    language requests to the right user roles to be assigned.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个利用语义搜索解决问题的例子，其中Okta数据科学团队训练的嵌入模型能够将自然语言请求映射到应分配的正确用户角色。
- en: '![](img/B22495_05_05.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_05_05.jpg)'
- en: 'Figure 5.5: Okta Inbox administrator view'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5：Okta邮箱管理员视图
- en: These requests would get routed to a manager via Slack through an existing workflow.
    The end result is a simple user experience that makes identity management between
    both the requesters and the access managers much simpler, thus making the value
    proposition of Okta as an identity and access management solution even greater.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这些请求将通过现有的工作流程通过Slack路由给经理。最终结果是简单直观的用户体验，使得请求者和访问管理者之间的身份管理变得更为简单，从而使得Okta作为身份和访问管理解决方案的价值主张更加显著。
- en: Okta chose to use Atlas Vector Search to query these vectors since they were
    already using Atlas as their operational data store, and this provided a simplified
    developer experience. You can read more about this case study at [https://www.mongodb.com/solutions/customer-case-studies/okta](https://www.mongodb.com/solutions/customer-case-studies/okta).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Okta选择使用Atlas Vector Search查询这些向量，因为他们已经将Atlas作为他们的操作数据存储使用，这为开发者提供了简化的体验。您可以阅读更多关于此案例研究的资料[https://www.mongodb.com/solutions/customer-case-studies/okta](https://www.mongodb.com/solutions/customer-case-studies/okta)。
- en: One AI – language-based AI (RAG over business data)
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: One AI – 基于语言的AI（在业务数据上的RAG）
- en: '**One AI** provides verticalized AI agents and chatbots for different industries.
    These services allow detailed AI-assisted analysis to be performed over documents
    with applications in industries ranging from financial services and real estate
    to manufacturing and retail.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**One AI**为不同行业提供垂直化的AI代理和聊天机器人。这些服务允许对文档进行详细的AI辅助分析，这些应用范围从金融服务和房地产到制造业和零售业。'
- en: The chatbots offered by One AI are all built using the MongoDB Atlas platform,
    with over 150 million indexed documents from over 20 different internal services.
    One AI’s goal of bringing AI to everyday life is made feasible by simply adding
    a vector search index to the data that they store in Atlas and making it queryable
    via embedded natural language input.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: One AI提供的聊天机器人都是使用MongoDB Atlas平台构建的，拥有来自20多个不同内部服务的超过1.5亿个索引文档。One AI将AI带入日常生活的目标，通过简单地将向量搜索索引添加到他们在Atlas中存储的数据，并使其可通过嵌入式自然语言输入进行查询，变得可行。
- en: “A very common use case in language AI is creating vectors that represent language.
    The ability to have that vectorized language representation in the same database
    as other representations, which you can then access via a single query interface,
    solves a core problem for us as an API company.”
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: “在语言AI中一个非常常见的用例是创建代表语言的向量。能够在同一数据库中拥有这种向量化的语言表示，然后通过单个查询界面访问，这解决了我们作为API公司的一个核心问题。”
- en: —Amit Ben, CEO and founder of One AI
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ——Amit Ben，One AI的首席执行官和创始人
- en: This is a prime example of a multitenant RAG application, where data that is
    indexed and provided for one type of AI service provided by One AI might not be
    relevant to another service. As discussed later in this chapter, this is a common
    data modeling pattern that is easy to build within the Atlas platform. You can
    further read about this case study at [https://www.mongodb.com/solutions/customer-case-studies/one-ai-success-story](https://www.mongodb.com/solutions/customer-case-studies/one-ai-success-story).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个多租户RAG应用的典型案例，其中One AI提供的一种AI服务所索引和提供的数据可能对另一种服务不相关。正如本章后面所讨论的，这是一个在Atlas平台内易于构建的常见数据建模模式。您可以进一步阅读有关此案例研究的资料[https://www.mongodb.com/solutions/customer-case-studies/one-ai-success-story](https://www.mongodb.com/solutions/customer-case-studies/one-ai-success-story)。
- en: Novo Nordisk – automatic clinical study generation (advanced RAG/RPA)
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诺和诺德 – 自动临床研究生成（高级RAG/RPA）
- en: '**Novo Nordisk** is one of the world’s leading healthcare companies with a
    mission to defeat some of the world’s most serious chronic diseases such as diabetes.
    As a part of the process of getting new medicines approved and delivered to patients,
    they must generate a **clinical study report** (**CSR**). This is a detailed record
    of the methodology, execution, results, and analyses of a clinical trial and is
    meant as a critical source of truth for regulatory authorities and other stakeholders
    in the drug approval process.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**诺和诺德**是全球领先的医疗保健公司之一，其使命是战胜世界上一些最严重的慢性疾病，如糖尿病。作为获取新药批准并交付给患者过程的一部分，他们必须生成一份**临床研究报告**（**CSR**）。这是一份详细记录临床试验的方法、执行、结果和分析的文件，旨在作为监管机构和其他药物审批流程利益相关者的关键真实信息来源。'
- en: '![](img/B22495_05_06.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_05_06.jpg)'
- en: 'Figure 5.6: Example of a CSR'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6：CSR示例
- en: Typically, a CSR takes around 12 weeks to complete, but the content digitalization
    team at Novo Nordisk was able to build a tool using Atlas Vector Search to shorten
    this process to ten minutes. They built a RAG workflow called **NovoScribe** leveraging
    **Claude 3** and **ChatGPT** as their chat completion models, and **Titan** for
    text embedding hosted on the **Amazon Bedrock** service. They used MongoDB Atlas
    Vector Search as a knowledge base to serve relevant data to these models.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，CSR的完成需要大约12周，但诺和诺德的内容数字化团队能够利用Atlas Vector Search构建一个工具，将这个过程缩短到十分钟。他们构建了一个名为**NovoScribe**的RAG工作流程，利用**Claude
    3**和**ChatGPT**作为他们的聊天完成模型，以及托管在**Amazon Bedrock**服务上的**Titan**进行文本嵌入。他们使用MongoDB
    Atlas Vector Search作为知识库，为这些模型提供相关数据。
- en: Functionally, NovoScribe generates validated text using defined content rules
    and statistical outputs. Atlas Vector Search computes the similarity of each text
    snippet to the relevant statistics, which is then fed into a structured prompt
    to the LLM to produce a CSR that is ready for review by a subject-matter expert,
    including the lineage of all of the data presented.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从功能上讲，NovoScribe使用定义的内容规则和统计输出生成验证过的文本。Atlas Vector Search计算每个文本片段与相关统计数据的相似度，然后将其输入到结构化提示中，供LLM生成一个待专家审查的CSR，包括所有展示数据的来源。
- en: “What’s great about MongoDB Atlas is that we can store native vector embeddings
    of the report right alongside all of their associated text snippets and metadata.
    This means we can run really powerful and complex queries quickly. For each vector
    embedding we can filter on which source document it’s coming from, who wrote it,
    and when.”
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: “MongoDB Atlas的伟大之处在于，我们可以将报告的原生向量嵌入与其所有相关的文本片段和元数据一起存储。这意味着我们可以快速运行非常强大和复杂的查询。对于每个向量嵌入，我们可以过滤其来源的源文档、作者以及时间。”
- en: —Tobias Kröpelin, PhD, Novo Nordisk
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: —托比亚斯·克罗佩林博士，诺和诺德
- en: This project allowed Novo Nordisk to build an advanced clinical report generation
    system by intelligently arranging their data in the right format within MongoDB
    and defining a vector search index against it. They were allowed to go further
    with their data in more ways using novel embedding models and LLMs to dramatically
    improve the process of authoring CSRs as a result. You can read more about this
    case study at [https://www.mongodb.com/solutions/customer-case-studies/novo-nordisk](https://www.mongodb.com/solutions/customer-case-studies/novo-nordisk).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目使诺和诺德能够通过在MongoDB中智能地安排数据以正确的格式，并对其定义向量搜索索引，构建一个高级临床报告生成系统。他们能够以更多方式使用新颖的嵌入模型和LLM，利用这些模型显著提高编写CSR的过程。您可以在[https://www.mongodb.com/solutions/customer-case-studies/novo-nordisk](https://www.mongodb.com/solutions/customer-case-studies/novo-nordisk)了解更多关于这个案例研究的详情。
- en: Vector search best practices
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量搜索最佳实践
- en: This section covers the best practices for improving the accuracy of your vector
    search through intelligent data modeling, deployment model options, and considerations
    for prototype and production use cases. By following the guidance in this section,
    you will be more likely to improve the quality of your vector search results and
    operate your search system in a scalable, production-ready manner.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了通过智能数据建模、部署模型选项以及原型和实际应用案例的考虑来提高向量搜索准确性的最佳实践。通过遵循本节中的指导，您更有可能提高向量搜索结果的质量，并以可扩展、生产就绪的方式运行您的搜索系统。
- en: Data modeling
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据建模
- en: In the context of MongoDB, `$``vectorSearch` query.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在MongoDB的上下文中，`$vectorSearch`查询。
- en: One can broadly think about leveraging metadata as using documents to deliver
    the data back to the user, rather than vectors. Working with documents as the
    results of an aggregation stage means that different aggregation stages can be
    composed together to yield greater functionality than any one alone and can benefit
    from query optimization. This has been the bread and butter of the document model
    since MongoDB was invented, and it continues to be the case today in the age of
    GenAI applications.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 可以广泛地认为，利用元数据是将文档用作将数据返回给用户的方式，而不是向量。将文档作为聚合阶段的输出进行操作意味着不同的聚合阶段可以组合在一起，产生比单个阶段更大的功能，并可以从查询优化中受益。这自MongoDB发明以来一直是文档模型的精髓，在GenAI应用的时代依然如此。
- en: This section will dive deeper into the ways other data can be used prior to,
    alongside, and following vector search to improve the accuracy of your vector-based
    information retrieval system.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将深入探讨在向量搜索之前、期间和之后使用其他数据的方法，以提高您基于向量的信息检索系统的准确性。
- en: Filtering
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过滤
- en: The most basic yet most effective form of metadata usage is to limit the scope
    of the vector search by considering only vector data that meets a prefilter. This
    restricts the scope of valid documents to be considered, which, for selective
    filters (the most common kind of filter), increases accuracy and reduces query
    latency.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本且最有效的元数据使用形式是通过考虑仅满足预过滤条件的向量数据来限制向量搜索的范围。这限制了需要考虑的有效文档的范围，对于选择性过滤器（最常见的过滤器类型），这提高了准确性并减少了查询延迟。
- en: At query time, these prefilters can be considered as a part of a `$vectorSearch`
    query using a `$match` MQL semantic. This means that in addition to point filters
    such as `$eq`, the user can define range filters such as `$gt` or `$lt` to only
    search against documents that fit a range of values rather than matching a specific
    one. This can dramatically reduce the number of valid documents that need to be
    searched, reducing the amount of work that needs to be done and generally improving
    the accuracy of your search. `$match` filters can also leverage logical operators
    such as `$and` and `$or` to allow users to compose filters together and build
    more complex logic into their search applications.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询时，这些预过滤器可以作为使用`$match` MQL语义的`$vectorSearch`查询的一部分来考虑。这意味着除了点过滤器（如`$eq`）之外，用户还可以定义范围过滤器（如`$gt`或`$lt`），以仅针对符合一系列值的文档进行搜索，而不是匹配特定的一个。这可以显著减少需要搜索的有效文档数量，减少需要完成的工作量，并通常提高搜索的准确性。`$match`过滤器还可以利用逻辑运算符（如`$and`和`$or`），允许用户组合过滤器并构建更复杂的逻辑到他们的搜索应用中。
- en: Let’s look at two common types of filters, and when and how you might use them.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看两种常见的过滤器类型，以及何时以及如何使用它们。
- en: Dynamic filters
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 动态过滤器
- en: '**Dynamic filters** are pieces of metadata that vary based on the content of
    the search query. These can be attributes of the data, such as when a book was
    published or its price. They are typically selected by a user when executing their
    search along with their plain English query. Here is an example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**动态过滤器**是根据搜索查询的内容而变化的元数据片段。这些可以是数据的属性，例如一本书的出版时间或其价格。它们通常在用户执行搜索时与其普通英语查询一起选择。以下是一个示例：'
- en: '[PRE0]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Dynamic filters are most common when building a semantic search application
    since they are typically input by the user prior to executing a query within a
    search bar. This contrasts with a RAG interface, which is entirely natural language.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 动态过滤器在构建语义搜索应用时最常见，因为它们通常在用户在搜索栏中执行查询之前输入。这与完全基于自然语言的RAG界面形成对比。
- en: Static filters and multitenancy
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 静态过滤器和多租户
- en: There are cases where the filter is associated not with the body of the query,
    but by the user’s profile. The user may be querying data that is accessible only
    to their company but is stored in a multi tenanted fashion with many other tenants’
    data. In this case, the user ID or company ID that the user belongs to may be
    used to filter what results are searched against. For cases where there are a
    high number of tenants and few vectors, filters are the recommended approach for
    modeling data rather than storing many bits of data across multiple collections
    and indexes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，过滤器与查询的主体无关，而是与用户的个人资料相关。用户可能正在查询只能由他们公司访问的数据，但这些数据以多租户方式存储，与许多其他租户的数据一起存储。在这种情况下，用户所属的用户ID或公司ID可能被用来过滤搜索的结果。对于有大量租户和少量向量的情况，过滤器是建模数据的推荐方法，而不是在多个集合和索引中存储大量数据。
- en: It is recommended to set the `exact` flag to `true` in `$vectorSearch` when
    you have a high degree of variation between the number of vectors per tenant and
    a high number of tenants modeled within the same collection or index. This will
    lead to an exhaustive search performed in parallel on all segments corresponding
    to a vector index. In many cases, this will accelerate the search, given the high
    selectivity of the filter and the large number of potential vectors that would
    need to be searched and discarded while running a filtered HNSW search.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 建议在向量数与租户数之间存在高度差异，并且在同一集合或索引中建模了大量的租户时，在`$vectorSearch`中将`exact`标志设置为`true`。这将导致对所有对应于向量索引的所有段并行执行详尽的搜索。在许多情况下，由于过滤器的选择性和在执行过滤HNSW搜索时需要搜索和丢弃的大量潜在向量，这将加速搜索。
- en: Chunking
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分块处理
- en: In the context of RAG, an interesting analogy emerges. Just as chat models require
    intelligent prompt engineering, embedding models require intelligent chunking.
    **Intelligent chunking** requires finding the right level of context that can
    effectively be mapped to a search or natural language query. This may also be
    the right level of context to provide to the LLM, but as you’ll see later in the
    *Parent document retrieval* section, this is not a strict requirement if you intelligently
    model your data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RAG 的背景下，出现了一个有趣的类比。正如聊天模型需要智能提示工程一样，嵌入模型需要智能块化。**智能块化**需要找到能够有效映射到搜索或自然语言查询的正确上下文级别。这也可能是提供给
    LLM 的正确上下文级别，但正如你将在后面的 *父文档检索* 部分中看到的，如果你智能地建模你的数据，这并不是一个严格的要求。
- en: You will learn more about basic and advanced chunking strategies in [*Chapter
    8*](B22495_08.xhtml#_idTextAnchor180), *Implementing Vector Search in AI Applications*.
    For the sake of this section, let’s consider one basic chunking strategy, **fixed
    token count with overlap**, and how you can experiment to assess what works best
    on your own dataset.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在 [*第 8 章*](B22495_08.xhtml#_idTextAnchor180)，*在 AI 应用中实现向量搜索* 中了解更多关于基本和高级块化策略的内容。为了本节的目的，让我们考虑一种基本的块化策略，**具有重叠的固定标记计数**，以及你如何进行实验来评估在你的数据集上哪种效果最好。
- en: Fixed token count with overlap
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 具有重叠的固定标记计数
- en: A fixed token count with overlap, which is a common default in many RAG integration
    frameworks such as LangChain, splits unstructured data into chunks based on the
    specified maximum number of tokens per chunk and the desired overlap between chunks.
    This method is more granular than the whole-page ingestion method, and it allows
    for greater experimentation on your specific dataset. It doesn’t involve exploiting
    any structure within the unstructured data. This is a positive in terms of simplicity
    of development but can be a negative when sentences, paragraphs, or other boundaries
    demarcate semantic significance in a way you would want to model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 具有重叠的固定标记计数，这在许多 RAG 集成框架（如 LangChain）中是一个常见的默认设置，它根据每个块指定的最大标记数和块之间的期望重叠将非结构化数据分割成块。这种方法比全页摄入方法更细粒度，它允许你在你的特定数据集上进行更多的实验。它不涉及利用非结构化数据中的任何结构。这在开发简单性方面是一个优点，但当你想要建模的句子、段落或其他边界以某种方式界定语义意义时，这可能会成为一个缺点。
- en: 'This technique may be a good fit if you have little control over the source
    data or are working with unstructured data that doesn’t lend itself well to boundary
    chunking methods that leverage document structure, such as HTML tags, because
    this technique is compatible with any text format. *Figure 5**.7* shows an example
    with different colors indicating separate chunks and overlaps:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对源数据几乎没有控制权，或者正在处理不适合使用利用文档结构（如 HTML 标签）的边界块化方法的非结构化数据，这种技术可能是一个不错的选择，因为这种技术与任何文本格式兼容。*图
    5*.*7* 展示了一个示例，不同的颜色表示不同的块和重叠部分：
- en: '![](img/B22495_05_07.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_05_07.png)'
- en: 'Figure 5.7: An example of chunking based on fixed token count with overlap'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7：基于固定标记计数且存在重叠的块化示例
- en: Experimentation
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实验研究
- en: Evaluating which chunking strategy or embedding model works best for your use
    case requires curating judgment lists of documents along with the queries that
    you would expect to map to those documents. You would also want to play around
    with the different embedding models and chunking strategies that can be applied
    before embedding data to see which works best for your use case.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 评估哪种块化策略或嵌入模型最适合你的用例，需要整理文档的判断列表以及你预期映射到这些文档的查询。你还可以尝试不同的嵌入模型和块化策略，在嵌入数据之前看看哪种最适合你的用例。
- en: A given embedding model might perform better or worse with a fixed chunking
    strategy. You can more easily evaluate which combination of chunking and embedding
    models is best suited for your use case. You could have multiple versions of the
    same data, each split and processed differently. By comparing these versions,
    you can determine the optimal splitting method and embedding model for your specific
    search needs.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 给定的嵌入模型可能在使用固定的块化策略时表现更好或更差。你可以更容易地评估哪种块化和嵌入模型的组合最适合你的用例。你可以有多个相同数据的不同版本，每个版本都分割和处理的有所不同。通过比较这些版本，你可以确定最适合你特定搜索需求的最佳分割方法和嵌入模型。
- en: The best way to determine whether an embedding model is effectively mapping
    your documents to a sample query is to inspect the similarity score that is returned
    for a set of queried documents and see how well that aligns with what good responses
    might be for the actual question, as shown in *Table 5.1*.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 确定嵌入模型是否有效地将您的文档映射到样本查询的最佳方法是通过检查返回的一组查询文档的相似度得分，并查看它如何与实际问题的良好响应相匹配，如图*5.1*表所示。
- en: '| **Rank** | **Raw document** | **Embedding** | **Cosine similarity** |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| **排名** | **原始文档** | **嵌入** | **余弦相似度** |'
- en: '| 1 | “One of the main challenges of building software is managing complexity.”
    | [0.23, 0.45, …] | 0.901 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 1 | “构建软件的主要挑战之一是管理复杂性。” | [0.23, 0.45, …] | 0.901 |'
- en: '| 2 | “Deep modules provide deep functionality behind a simple interface” |
    [0.86, 0.34, …] | 0.874 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 2 | “深度模块在简单界面上提供了深层功能。” | [0.86, 0.34, …] | 0.874 |'
- en: '| 3 | “Software systems often grow in complexity due to evolving requirements.”
    | [0.46, 0.51, …] | 0.563 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 3 | “软件系统往往由于需求的演变而变得复杂。” | [0.46, 0.51, …] | 0.563 |'
- en: 'Table 5.1: Vector search results ranked by cosine similarity'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1：基于余弦相似度的向量搜索结果
- en: In the case of a fixed token count with overlap strategy, you will have to figure
    out the token count that you would like to start with. The 300–500 token range
    seems sufficient for experimentation in the information retrieval community.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定标记计数且重叠策略的情况下，您需要确定您希望开始的标记计数。在信息检索社区中，300-500个标记的范围似乎对于实验来说是足够的。
- en: Hybridization
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混合
- en: '**Hybridization** involves modeling multiple sources of relevance within a
    single document and jointly considering them alongside a single vector search
    at query time. This technique embodies the flexibility of the aggregation pipelines
    supported by MongoDB and allows for a great amount of experimentation and tuning
    of your search system leveraging vector search, lexical search, traditional database
    operators, geospatial queries, and more.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**混合**涉及在单个文档中建模多个相关来源，并在查询时联合考虑它们与单个向量搜索。这种技术体现了MongoDB支持的聚合管道的灵活性，并允许您利用向量搜索、词汇搜索、传统数据库运算符、地理空间查询等对您的搜索系统进行大量的实验和调整。'
- en: In the following sections, you will explore some of the more popular methods
    for hybridization, as well as some promising avenues of exploration that you might
    find relevant to your use case.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，您将探索一些混合方法中较为流行的技术，以及一些可能对您的用例相关的有希望的探索途径。
- en: Vector plus lexical
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量加词汇
- en: Vector search is a sound methodology for exploiting semantic similarity between
    a query and indexed document as defined by the capabilities of an embedding model.
    Lexical search systems such as **BM25**, which **Lucene** and, correspondingly,
    Atlas Search use, are helpful in a completely different way in that they index
    tokens directly and use a bag-of-words style approach that ranks a set of documents
    based on the query terms appearing in each document, regardless of their proximity
    within the document.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索是一种利用嵌入模型能力定义的查询与索引文档之间语义相似性的有效方法。像**BM25**这样的词汇搜索系统，**Lucene**和相应的Atlas
    Search使用，以完全不同的方式有帮助，因为它们直接索引标记并使用一种词袋风格的搜索方法，该方法根据每个文档中出现的查询词对文档集进行排序，而不管这些词在文档中的位置如何。
- en: Despite being based on an original probabilistic retrieval framework developed
    in the 1980s, this approach is still fairly good at mapping keywords in a query
    to keywords in a document, especially when that word is used outside the context
    of what an embedding model was trained on. Small datasets can contain tokens either
    not seen in the training dataset or with alternative meanings, as shown in *Figure
    5**.8*.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法基于20世纪80年代开发的原始概率检索框架，但它仍然相当擅长将查询中的关键词映射到文档中的关键词，尤其是在该词在嵌入模型训练的上下文之外使用时。小数据集可能包含训练数据集中未见过或具有不同含义的标记，如图*5.8*所示。
- en: '![](img/B22495_05_08.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_05_08.jpg)'
- en: 'Figure 5.8: Out-of-sample terms'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：样本外的术语
- en: Some vector search providers provide sparse vector search as an alternative
    to lexical search, which can be made to operate similarly but has been considered
    insufficient for customers’ purposes. It also lacks out-of-the-box support for
    many lexical search features, such as synonym lists, pagination, and faceting.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一些向量搜索提供商提供稀疏向量搜索作为词汇搜索的替代方案，它可以被配置得与词汇搜索类似，但被认为不足以满足客户的需求。它还缺乏对许多词汇搜索功能的即插即用支持，例如同义词列表、分页和细分。
- en: 'Smaller levels of context are good fits for embedding models, whereas broader
    levels can be well represented by keyword search. MongoDB allows users to experiment
    in this direction as much as possible, while also allowing the joint query pattern
    to be joined on a foreign key, rather than simply a document `_id`. This makes
    it possible to have windowing levels of representation for a given document that
    can be considered by different methodologies. The following code shows how some
    documents containing `paragraph_embeddings` can be indexed and queried using a
    vector search index, while other documents containing `full_page_content` can
    be indexed and queried using a text search index:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 较低级别的上下文非常适合嵌入模型，而较高级别的上下文则可以通过关键词搜索很好地表示。MongoDB 允许用户尽可能地在这一方向上进行实验，同时允许在非键（而非简单的文档
    `_id`）上联合查询模式。这使得可以为给定文档提供窗口级别的表示，这些表示可以通过不同的方法来考虑。以下代码展示了如何使用向量搜索索引对包含 `paragraph_embeddings`
    的某些文档进行索引和查询，而包含 `full_page_content` 的其他文档则可以使用文本搜索索引进行索引和查询：
- en: '[PRE1]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Jointly considering the result sets from the two queries shown in the preceding
    code is what you call **hybrid search** and can be done using the **reciprocal
    rank fusion method**, as shown at [https://www.mongodb.com/docs/atlas/atlas-search/tutorial/hybrid-search/](https://www.mongodb.com/docs/atlas/atlas-search/tutorial/hybrid-search/).
    In the future, Atlas Vector Search will offer support for dedicated stages that
    make combining result sets based on rank or score much simpler. However, the fundamental
    concepts will remain the same.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 联合考虑前面代码中显示的两个查询的结果集，这被称为**混合搜索**，可以使用**互逆排名融合方法**来实现，如[https://www.mongodb.com/docs/atlas/atlas-search/tutorial/hybrid-search/](https://www.mongodb.com/docs/atlas/atlas-search/tutorial/hybrid-search/)中所示。将来，Atlas
    Vector Search 将提供对专用阶段的支持，这使得基于排名或分数组合结果集变得更加简单。然而，基本概念将保持不变。
- en: Vector plus vector
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量加向量
- en: 'There might be multiple sources of vector relevance in your dataset that you
    would want to consider jointly, similar to how you might jointly consider paragraph
    embeddings and keyword relevance for a whole page. The secondary embedding field
    you are considering might be a derivative field, such as an LLM-generated chapter
    summary that is then embedded, or it could be an entirely different source of
    data. The following code shows a single document with a set of source fields that
    could be embedded and indexed using a vector search index:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的数据集中可能存在多个向量相关性来源，您可能希望联合考虑，类似于您可能联合考虑整个页面的段落嵌入和关键词相关性。您正在考虑的二级嵌入字段可能是一个派生字段，例如由
    LLM 生成的章节摘要然后嵌入的字段，或者它可能是一个完全不同的数据来源。以下代码展示了一个包含一组可以嵌入和索引使用向量搜索索引的源字段的单个文档：
- en: '[PRE2]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The results of independent `$vectorSearch` queries could be hybridized and fused
    using a similar pattern to the vector plus lexical search query pattern seen in
    the previous section and would allow for multiple sources of relevance to be used
    to find the most relevant document to a query.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 独立的 `$vectorSearch` 查询的结果可以采用与前面章节中看到的向量加词汇搜索查询模式相似的混合和融合模式，这将允许使用多个相关性来源来找到与查询最相关的文档。
- en: 'In e-commerce search use cases, it is common for a single item to have many
    sources of relevance that can be embedded and stored within the same document
    representing that item. These include the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在电子商务搜索用例中，单个项目通常有许多可以嵌入并存储在表示该项目的同一文档中的相关性来源。以下是一些例子：
- en: Product description
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品描述
- en: User reviews (and summaries of user reviews)
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户评论（以及用户评论的摘要）
- en: Product images
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品图片
- en: Each of these sources of relevance can be embedded and jointly considered using
    the same query pattern as one would use to jointly consider vector and lexical
    relevance.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些相关性的来源都可以通过相同的查询模式嵌入并共同考虑，这种查询模式就像人们用来共同考虑向量和词汇相关性的查询模式一样。
- en: Incorporating user feedback
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结合用户反馈
- en: '`$vectorSearch` and the `$sort` stage using the upvotes or downvotes as a proxy
    for user relevance.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`$vectorSearch` 和使用点赞或踩作为用户相关性的代理的 `$sort` 阶段。'
- en: '[PRE3]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is a very naive approach, but the principle behind it can be extended to
    allow for greater personalization of content where similar users are defined by
    similar interactions with different content, which is the basis for the popular
    recommendation system algorithm known as **collaborative filtering**.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的方法，但其背后的原理可以扩展，以允许对内容进行更个性化的定制，其中相似的用户通过他们对不同内容的相似互动来定义，这是流行推荐系统算法——**协同过滤**的基础。
- en: While it is still early days in terms of intelligently incorporating user feedback
    into your RAG application, the flexibility of the document model should allow
    for a rich amount of experimentation in this area as your search system, and how
    your users engage with it, evolves over time.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在将用户反馈智能地集成到您的RAG应用方面，尽管目前还处于早期阶段，但文档模型的灵活性应允许您在这个领域进行丰富的实验，随着您的搜索系统以及用户如何随着时间的推移与之互动而演变。
- en: Document lookups
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档查找
- en: Once you have a sorted result set of documents, possibly produced from multiple
    methodologies in an optimized manner, there are still additional operations that
    can be performed that might leverage relationships inherent within your data.
    With **document lookups**, some data may be easier to model outside of the document
    itself using a foreign lookup key to model tree structures within your data, such
    as hierarchies within documents, organizations, or some other taxonomy.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有一个排序的文档结果集，可能是通过多种方法以优化方式产生的，仍然可以进行一些额外的操作，这些操作可能利用您数据中固有的关系。通过**文档查找**，某些数据可能更容易使用外键查找键在文档外部进行建模，以在您的数据中建模树结构，例如文档内的层次结构、组织或某些其他分类法。
- en: Parent document retrieval
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 父文档检索
- en: '**Parent document retrieval** involves performing a vector search at one level
    of context, and then retrieving a document connected to the most relevant retrieved
    documents via a foreign key. This foreign key is usually a child-parent relationship,
    such as an embedded paragraph belonging to a specific page of a larger body of
    text, where that larger bit of context may be stored in another document completely.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**父文档检索**涉及在某一层上下文中执行向量搜索，然后通过外键检索与检索到的最相关文档相连的文档。这个外键通常是一个子父关系，例如属于更大文本体特定页面的嵌入段落，其中更大的上下文可能存储在另一份完全不同的文档中。'
- en: With this pattern, you can store only the embeddings at the lower level, and
    then look up a higher level of context containing a much larger amount of text.
    This may be useful if you find that the queries are more easily mapped semantically
    to a smaller amount of text, but the amount of data you want to serve to the user
    or an LLM is much larger, which is often the case. The following code example
    for hybridizing lexical and vector search is also an example of parent document
    retrieval, as vector embeddings are searched against to yield a full page of content
    to provide to the LLM. The foreign key is the `page_number`.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种模式，您只需在较低级别存储嵌入，然后查找包含大量文本的较高级别的上下文。如果您发现查询更容易将语义映射到更小的文本量，但您希望提供给用户或LLM的数据量很大，这可能很常见，这可能很有用。以下混合词汇和向量搜索的代码示例也是父文档检索的一个例子，因为向量嵌入被搜索以生成一整页内容提供给LLM。外键是`page_number`。
- en: '[PRE4]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: It’s important to note that like all other metadata, capturing relationships
    between MongoDB documents in this manner must be extracted at ingestion time.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，与所有其他元数据一样，以这种方式捕获MongoDB文档之间的关系必须在摄取时提取。
- en: Graph relationships
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 图关系
- en: You can exploit even more relationships between documents using the `$graphLookup`
    stage. This allows an arbitrary number of hops to be jumped from the results of
    `$vectorSearch`. If the customer’s data already contains relationships that can
    be traversed in a hierarchical manner, this is an immediate benefit to them.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`$graphLookup`阶段利用文档之间的更多关系。这允许从`$vectorSearch`的结果跳转到任意数量的跳数。如果客户的数据已经包含可以以分层方式遍历的关系，这将立即为他们带来好处。
- en: Just as you might define a relationship between a document and a page, you might
    recursively chunk a document into ever smaller chunks, relate each chunk to a
    parent document using a `parent_id` field, and embed those chunks. At query time,
    you could search against all of the chunks and recursively jump up all of the
    `parent_id` values to the desired level of resolution to provide to the LLM.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能定义文档和页面之间的关系一样，您可能递归地将文档分割成越来越小的块，使用`parent_id`字段将每个块与父文档相关联，并嵌入这些块。在查询时，您可以针对所有块进行搜索，并递归地跳转到所有`parent_id`值，以达到所需的解析级别，以提供给LLM。
- en: Deployment
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署
- en: Successfully deploying your AI application is the final hurdle. This section
    outlines various deployment options and provides guidance on estimating necessary
    resources to ensure optimal performance and scalability.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 成功部署您的AI应用是最后的障碍。本节概述了各种部署选项，并提供了关于估计所需资源以确保最佳性能和可扩展性的指导。
- en: Deployment options
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署选项
- en: The simplest deployment model for getting started with Atlas Vector Search is
    to define a search index definition within your existing cluster or a new cluster.
    This can be configured using **search index management commands** for paid tier
    clusters or the **UI/Atlas Administration API** for shared tier clusters.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Atlas 向量搜索，最简单的部署模型是在现有的集群或新集群中定义一个搜索索引定义。这可以通过付费层集群的**搜索索引管理命令**或共享层集群的**UI/Atlas
    管理API**进行配置。
- en: When you feel confident in your vector search use case and are ready for increased
    usage or increased scale of ingested data, it is recommended to move to dedicated
    search nodes. **Dedicated search resources** provide a robust and scalable platform
    for serving demanding search workloads.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在向量搜索用例中感到自信，并准备增加使用量或摄入数据的规模时，建议迁移到专用搜索节点。**专用搜索资源**提供了一个强大且可扩展的平台，用于处理需求较高的搜索工作负载。
- en: This will allow for high-availability vector search, more cost-effective resource
    utilization, and resource isolation from your core database in a way that is more
    practical for production workloads, as visualized in *Figure 5**.9*.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这将允许实现高可用性向量搜索，更有效的资源利用，以及从核心数据库中隔离资源，这对于生产工作负载来说更为实用，如图 *图 5.9* 所示。
- en: '![](img/B22495_05_09.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_05_09.jpg)'
- en: 'Figure 5.9: The benefits of dedicated search nodes'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9：专用搜索节点的优势
- en: Migrating to dedicated search nodes is a zero-downtime process that allows for
    your existing base cluster to continue to serve vector search queries as new resources
    are spun up and your indexes are built on them. Once that build process completes,
    `$vectorSearch` queries will be routed to your dedicated search nodes and the
    indexes on the original cluster will be deleted.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移到专用搜索节点是一个零停机时间的过程，允许你的现有基础集群在新的资源启动并在此之上构建索引的同时继续服务向量搜索查询。一旦构建过程完成，`$vectorSearch`查询将被路由到你的专用搜索节点，并且原始集群上的索引将被删除。
- en: 'Dedicated search nodes can be configured from the **Cluster Configuration UI**
    by following these steps:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过以下步骤从**集群配置UI**配置专用搜索节点：
- en: On the **Create New Cluster/Edit Configuration** page, change the radio button
    for **AWS or Google Cloud** for **Multi-cloud, multi-region & workload isolation**
    to enabled.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**创建新集群/编辑配置**页面，将**AWS 或 Google Cloud**的**多云、多区域和工作负载隔离**单选按钮切换到启用状态。
- en: Toggle the radio button for **Search Nodes for workload isolation** to enabled.
    Select the number of nodes in the textbox.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到**用于工作负载隔离的搜索节点**单选按钮以启用。在文本框中输入节点数量。
- en: Check the agreement box.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打勾同意框。
- en: Select the right node for your workload.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择适合你工作负载的正确节点。
- en: Click **Create cluster**.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建集群**。
- en: Resource requirements
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资源需求
- en: The current index type supported within Atlas Vector Search is HNSW, which is
    memory-resident. This means that you need approximately 3 KB of memory for every
    768d vector you plan on indexing, scaling linearly with the number and dimensionality
    of vectors.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Atlas 向量搜索中当前支持的索引类型是 HNSW，它是内存驻留的。这意味着你为每个计划索引的 768d 向量需要大约 3 KB 的内存，内存需求与向量的数量和维度成线性关系。
- en: If you expect your workload will have low query volume, it is recommended to
    select the cheapest option on `M` tier clusters that can allocate 50% of the available
    resources to storing the index in memory. When using dedicated search nodes, 90%
    of the available RAM can be used to host the index. Note that when using `M` tier
    clusters, the index will need to be warmed into the cache using representative
    queries. For dedicated search nodes, the index will be automatically loaded into
    the cache upon an index build.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你预计你的工作负载查询量较低，建议在`M`层集群中选择最便宜的选项，这些选项可以将 50% 的可用资源分配给存储索引到内存中。当使用专用搜索节点时，90%
    的可用 RAM 可以用于托管索引。请注意，当使用`M`层集群时，需要使用代表性查询将索引预热到缓存中。对于专用搜索节点，索引将在索引构建完成后自动加载到缓存中。
- en: If you expect your workload to have a high indexing or query concurrency, it
    is recommended to use dedicated search nodes with the high CPU option or to scale
    up the number of dedicated search nodes in your replica set. This will scale up
    the number of available vCPUs to serve the `$vectorSearch` queries in a round-robin
    fashion.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你预计你的工作负载将具有高索引或查询并发性，建议使用具有高CPU选项的专用搜索节点，或者增加副本集中的专用搜索节点数量。这将增加可用于服务`$vectorSearch`查询的
    vCPU 数量，并采用轮询方式。
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you explored a variety of concepts related to vector search.
    The chapter delved into how high-dimensional vectors produced from embedding models
    can be useful measures of semantic similarity among the unstructured data passed
    into those models. It examined the HNSW index and how it can be used to accelerate
    vector similarity comparisons between a query vector and many indexed vectors.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你探索了与向量搜索相关的各种概念。本章深入探讨了从嵌入模型中产生的高维向量如何成为衡量输入到这些模型的无结构数据语义相似度的有用度量。它还考察了HNSW索引及其如何用于加速查询向量和许多索引向量之间的向量相似度比较。
- en: The chapter then illustrated how this type of index can be applied in various
    real-world contexts by large organizations, including such architecture patterns
    as RAG, semantic search, and RPA. Finally, the chapter reviewed some of the best
    practices for building vector search systems within MongoDB Atlas, ranging from
    ingestion time considerations, such as metadata extraction, to deployment model
    considerations, such as dedicated search nodes.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本章随后展示了这种类型的索引如何被大组织应用于各种现实世界场景，包括如RAG、语义搜索和RPA等架构模式。最后，本章回顾了在MongoDB Atlas中构建向量搜索系统的最佳实践，从如元数据提取等摄入时间考虑，到如专用搜索节点等部署模型考虑。
- en: In the next chapter, you will discover the crucial aspects of designing AI/ML
    applications. You will learn how to effectively manage data storage, flow, freshness,
    and retention along with techniques to ensure robust security.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将了解设计AI/ML应用的关键方面。你将学习如何有效地管理数据存储、流动、新鲜度和保留，以及确保强大安全性的技术。
