- en: Revisiting Deep Learning Architecture and Techniques
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新审视深度学习架构和技术
- en: Deep learning is part of a broader machine learning and artificial intelligence
    field that uses artificial neural networks. One of the main advantages of deep
    learning methods is that they help to capture complex relationships and patterns
    contained in data. When the relationships and patterns are not very complex, traditional
    machine learning methods may work well. However, with the availability of technologies
    that help to generate and process more and more unstructured data, such as images,
    text, and videos, deep learning methods have become increasingly popular as they
    are almost a default choice to deal with such data. Computer vision and **natural
    language processing** (**NLP**) are two areas that are seeing interesting applications
    in a wide variety of fields, such as driverless cars, language translation, computer
    games, and even creating new artwork.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习和人工智能领域的一个分支，使用人工神经网络。深度学习方法的主要优势之一是能够捕捉数据中复杂的关系和模式。当关系和模式不那么复杂时，传统的机器学习方法可能会表现良好。然而，随着帮助生成和处理越来越多非结构化数据（如图像、文本和视频）的技术的出现，深度学习方法变得越来越流行，几乎成为处理这些数据的默认选择。计算机视觉和**自然语言处理**（**NLP**）是两个领域，正在广泛应用于许多不同的领域，如无人驾驶汽车、语言翻译、计算机游戏，甚至是创造新的艺术作品。
- en: Within the deep learning toolkit, we now have an increasing array of neural
    network techniques that can be applied to a specific type of task. For example,
    when developing image classification models, a special type of deep network called
    a **convolutional neural network** (**CNN**) has proved to be effective in capturing
    unique patterns that exist in image-related data. Similarly, another popular deep
    learning network called **recurrent neural networks** (**RNNs**) and its variants
    have been found useful in dealing with data involving sequences of words or integers.
    Another popular and interesting deep learning network called a **generative adversarial
    network** (**GAN**) has the capability to generate new images, speech, music,
    or artwork.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习工具包中，我们现在拥有越来越多可以应用于特定任务的神经网络技术。例如，在开发图像分类模型时，一种被称为**卷积神经网络**（**CNN**）的特殊深度网络已被证明在捕捉图像相关数据中的独特模式方面非常有效。类似地，另一种流行的深度学习网络叫做**递归神经网络**（**RNNs**）及其变种，在处理包含词语或整数序列的数据时被发现非常有用。还有一种非常有趣的深度学习网络叫做**生成对抗网络**（**GAN**），它具备生成新图像、语音、音乐或艺术作品的能力。
- en: In this book, we will use these and other popular deep learning networks using
    R software. Each chapter presents a complete example that has been specifically
    developed to run on a regular laptop or computer. The main idea is to avoid getting
    bogged down by a huge amount of data needing advanced computing resources at the
    first stage of applying deep learning methods. You will be able to go over all
    the steps using the illustrated examples in this book. The examples used also
    include the best practices for each topic, and you will find them useful. You
    will also find a hands-on and applied approach helpful in quickly seeing the big
    picture when trying to replicate these deep learning methods when faced with a
    new problem.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用这些以及其他流行的深度学习网络，使用R软件。每一章都展示了一个完整的示例，专门开发用于在普通的笔记本电脑或计算机上运行。主要的理念是避免在应用深度学习方法的初始阶段被大量需要高级计算资源的数据所困扰。你将能够通过书中展示的示例逐步理解所有步骤。所用示例还包括每个主题的最佳实践，你会发现它们非常有用。你还会发现，动手操作和应用方法有助于在面对新问题时，快速看到全貌并复现这些深度学习方法。
- en: 'This chapter provides an overview of the deep learning methods with R that
    are covered in this book. We will go over the following topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了本书中涵盖的R深度学习方法。我们将在本章中讨论以下主题：
- en: Deep learning with R
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《深度学习与R》
- en: The process of developing a deep network model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发深度网络模型的过程
- en: Popular deep learning techniques with R and RStudio
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R和RStudio的流行深度学习技术
- en: Deep learning with R
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《深度学习与R》
- en: We will start by looking at the popularity of deep learning networks and also
    take a look at a version of some of the important R packages used in this book.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从探讨深度学习网络的流行程度开始，并且了解一些本书中使用的重要R包的版本。
- en: Deep learning trend
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习趋势
- en: 'Deep learning techniques make use of neural network-based models and have seen
    increasing interest in the last few years.A Google trends website for the search
    term **deep learning** provides the following plot:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习技术使用基于神经网络的模型，近年来受到了越来越多的关注。Google趋势网站关于**深度学习**搜索词的图表如下所示：
- en: '![](img/e00aa45a-06c8-4f2b-8d54-bb32d931d475.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e00aa45a-06c8-4f2b-8d54-bb32d931d475.png)'
- en: The preceding plot has 100 as the peak popularity of a search term, and other
    numbers are relative to this highest point. It can be observed that the interest
    in the term **deep learning** has gradually increased in popularity since around
    2014\. For the last two years, it has enjoyed peak popularity. One of the reasons
    for the popularity of deep learning networks is the availability of the free and
    open source libraries, TensorFlow and Keras.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图表显示了一个搜索词的流行度最高为100，其他数字是相对于这一最高点的。可以观察到，自2014年左右以来，**深度学习**这个术语的兴趣逐渐上升，且在过去的两年中达到了流行的顶峰。深度学习网络流行的原因之一是开源免费库TensorFlow和Keras的可用性。
- en: Versions of key R packages used
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要R包版本
- en: 'In this book, we will use the Keras R package that uses TensorFlow as a backend
    for building deep learning networks. An output from a typical R session, used
    for the examples illustrated in this book, providing various version-related information,
    is provided in the following code:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将使用Keras R包，利用TensorFlow作为后端构建深度学习网络。下面的代码展示了一个典型的R会话输出，提供了与版本相关的各种信息，这些信息用于书中的示例：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As seen previously, for this book we have used the 3.6 version of R that was
    released in April 2019\. The nickname for this R version is Planting of a Tree.
    The version used for the Keras package is 2.2.4.1\. In addition, all the application
    examples illustrated in the book have been run on a Mac computer with 8 GB of
    RAM. The main reason for using this specification is that it will allow a reader
    to go through all the examples without needing advanced computing resources to
    get started with any deep learning network covered in the book.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本书使用的是2019年4月发布的R语言3.6版本，其别名为“Planting of a Tree”。用于Keras包的版本是2.2.4.1。此外，本书中所有应用示例均是在配备8GB内存的Mac计算机上运行的。使用此配置的主要原因是，它能让读者在不需要高级计算资源的情况下，顺利完成书中涉及的任何深度学习网络示例。
- en: In the next section, we will go over the process of developing a deep network
    model that is broken down into five general steps.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将详细讲解开发深度网络模型的过程，该过程分为五个一般步骤。
- en: Process of developing a deep network model
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度网络模型开发过程
- en: 'Developing a deep learning network model can be broken down into five key steps
    shown in the following flowchart:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 开发深度学习网络模型可以分为五个关键步骤，如下图所示：
- en: '![](img/5608bd8c-32f4-4d05-ad3d-42c2c0442a93.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5608bd8c-32f4-4d05-ad3d-42c2c0442a93.png)'
- en: Each step mentioned in the preceding flowchart can have varying requirements
    based on the type of data used, the type of deep learning network being developed,
    and also the main objective of developing a model. We will go over each step to
    develop a general idea about what is involved.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述流程图中提到的每个步骤，其要求可能会根据所使用的数据类型、开发的深度学习网络类型以及模型开发的主要目标而有所不同。我们将逐一讲解每个步骤，以帮助读者对所涉及的内容有一个总体的了解。
- en: Preparing the data for a deep network model
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备深度网络模型的数据
- en: Developing deep learning neural network models requires the variables to have
    a certain format. Independent variables may come with a varying scale, with some
    variable values in decimals and some other variables in thousands. Using such
    varying scales of variables is not very efficient when training a network. Before
    developing deep learning networks, we make changes such that the variables have
    similar scales. The process used for achieving this is called **normalization**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 开发深度学习神经网络模型要求变量具有一定的格式。自变量可能具有不同的尺度，有的变量值是小数，有的则是以千为单位。使用这种尺度不同的变量在训练网络时效率不高。在开发深度学习网络之前，我们会进行一些调整，使得变量具有相似的尺度。实现这一目标的过程称为**标准化**。
- en: Two commonly used methods for normalization are z-score normalization and min-max
    normalization. In z-score normalization, we subtract the mean from each value
    and divide it by the standard deviation. This transformation results in values
    that lie between -3 and +3 with a mean of 0 and a standard deviation of 1\. For
    a min-max normalization, we subtract the minimum value from each data point, and
    then divide it by the range. This transformation converts data to having values
    between zero and one.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 两种常用的标准化方法是z-score标准化和min-max标准化。在z-score标准化中，我们从每个值中减去均值，然后除以标准差。这种转换结果是数据值位于-3到+3之间，均值为0，标准差为1。而对于min-max标准化，我们从每个数据点中减去最小值，然后除以范围。这种转换将数据转换为0到1之间的值。
- en: 'As an example, see the following plots, where we have obtained 10,000 data
    points randomly from a normal distribution with a mean of 35 and a standard deviation
    of 5:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，请看以下图表，我们从一个均值为35，标准差为5的正态分布中随机获取了10,000个数据点：
- en: '![](img/9274ac87-fd1c-4e1a-8578-e5f9b3fbbe66.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9274ac87-fd1c-4e1a-8578-e5f9b3fbbe66.png)'
- en: From the preceding plots, we can observe that after z-score normalization, the
    data points mostly lie between -3 and +3\. Similarly, after min-max normalization,
    the range of values changes to data points between 0 and 1\. However, the overall
    pattern seen in the original data is retained after both types of normalization.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以观察到，经过z-score标准化后，数据点大多数位于-3到+3之间。同样，经过min-max标准化后，值的范围变为0到1之间。然而，两种标准化方法后，原始数据的整体模式得以保留。
- en: Another important step in preparing data when using a categorical response variable
    is to carry out one-hot encoding. One-hot encoding converts a categorical variable
    to a new binary format that has values containing either 0 or 1\. This is achieved
    very easily by using the `to_categorical()` function available in Keras.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用分类响应变量时，数据准备的另一个重要步骤是进行一热编码（one-hot encoding）。一热编码将分类变量转换为新的二进制格式，其中值为0或1。可以通过使用Keras中提供的`to_categorical()`函数轻松实现这一转换。
- en: 'Typically data processing steps for unstructured data, such as image or text,
    are more involved compared with a situation where we are dealing with structured
    data. In addition, the nature of data preparation steps can vary from one type
    of data to another. For example, the way we prepare image data for developing
    a deep learning classification model is likely to be very different from the way
    we prepare text data for developing a movie review sentiment classification model.
    However, one important thing to note is that before we can develop deep learning
    models from unstructured data, they need to be first converted into a structured
    format. An example of converting unstructured image data into a structured format
    is shown in the following screenshot, using a picture of the handwritten digit
    *five*:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，处理非结构化数据（如图像或文本）的数据处理步骤比处理结构化数据时更为复杂。此外，数据准备步骤的性质可能因数据类型而异。例如，为开发深度学习分类模型而准备图像数据的方式，很可能与为开发电影评论情感分类模型而准备文本数据的方式大不相同。然而，值得注意的一点是，在我们能够从非结构化数据开发深度学习模型之前，必须先将其转换为结构化格式。以下截图展示了如何将非结构化图像数据转换为结构化格式，使用的是手写数字*五*的图片：
- en: '![](img/95f65454-c5c4-4767-99a4-b9634f5c62aa.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95f65454-c5c4-4767-99a4-b9634f5c62aa.png)'
- en: As can be observed from the preceding screenshot, when we read an image file
    containing a black and white handwritten digit *five* with 28 x 28 dimensions
    in R, it gets converted to numbers in rows and columns, giving it a structured
    format. The right-hand side of the screenshot shows data with 28 rows and 28 columns.
    The numbers in the body of the table are pixel values that range from 0 to 255,
    where a value of zero represents the black color and 255 represents the white
    color in the picture. When developing deep learning models, we make use of some
    forms of such structured data that are derived from image data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的截图中可以观察到，当我们在R中读取一个包含手写数字*五*的黑白图像文件，尺寸为28 x 28时，它会被转换为行列中的数字，形成结构化格式。截图的右侧显示了具有28行和28列的数据。表格中的数字是像素值，范围从0到255，其中0表示黑色，255表示白色。在开发深度学习模型时，我们会使用一些从图像数据中派生的此类结构化数据。
- en: Once the data for developing the model is prepared in the required format, we
    can then develop the model architecture.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦为开发模型准备好的数据符合所需格式，我们就可以开发模型架构。
- en: Developing a deep learning model architecture
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发深度学习模型架构
- en: 'Developing the architecture of a model involves defining various items, such
    as the type and number of layers for the network, the type of activation function,
    the number of units or neurons to use in the network, and also providing the data-related
    input/output values. An example of specifying a simple sequential model architecture
    using Keras in R is shown in the following code:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 开发模型的架构涉及定义各种项目，如网络的层类型和数量、激活函数的类型、网络中使用的单元或神经元数量，以及提供与数据相关的输入/输出值。以下代码展示了如何在R中使用Keras指定一个简单的顺序模型架构：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that a sequential model allows us to develop models layer by layer. As
    seen from the preceding code, two layers of densely connected networks have been
    added as a part of the sequential model. Two important decisions while choosing
    a model architecture involve the number and type of layers and the type of activation
    function for a layer. The number and type of layers to use is guided by the nature
    and complexity of the data. For a fully connected network (also known as a multilayer
    perceptron), we can use a dense layer with the help of the `layer_dense` function
    available in Keras.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，顺序模型允许我们逐层开发模型。正如前面的代码所示，两个密集连接的网络层已被添加为顺序模型的一部分。选择模型架构时有两个重要决策，涉及层数和层的类型，以及激活函数的类型。使用多少层以及选择什么类型的层由数据的性质和复杂性决定。对于完全连接的网络（也称为多层感知器），我们可以使用Keras中的`layer_dense`函数来创建密集层。
- en: On the other hand, when working with image data, we are likely to use convolutional
    layers in the network, using the `layer_conv_2d` function. We will discuss more
    details about specific model architectures with examples in each chapter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在处理图像数据时，我们很可能会在网络中使用卷积层，利用`layer_conv_2d`函数。我们将在每一章中通过示例讨论更多关于特定模型架构的细节。
- en: 'There are different types of activation functions that are used in deep learning
    networks. A rectified linear unit, or `relu`, is a popular activation function
    used in hidden layers, and it uses a very simple calculation. If the input is
    negative, it returns a value of zero and, for everything else, there is no change
    to the original value. As an example, let''s look at the following code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习网络中使用了不同类型的激活函数。修正线性单元（`relu`）是一个流行的激活函数，通常用于隐藏层，并且它采用非常简单的计算方法。如果输入值为负数，则返回零；对于其他情况，则不改变原始值。举个例子，看看以下代码：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding code generates 10,000 random numbers from a normal distribution
    with a mean of two and a standard deviation of 10, and stores the results in `x`.
    And then negative values are changed to zero and stored in y. A histogram of x
    and a scatter plot for x and y are given in the following graphs:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了10,000个来自均值为2、标准差为10的正态分布的随机数，并将结果存储在`x`中。然后将负值更改为零并存储在y中。以下图表展示了x的直方图和x与y的散点图：
- en: '![](img/19566188-4019-4952-bcdc-d7ac1db23736.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/19566188-4019-4952-bcdc-d7ac1db23736.png)'
- en: It can be observed from the preceding histogram that x has values that are both
    positive and negative. The scatter plot, based on the original x values and the modified
    y value that is obtained after converting negative values to zero, visualizes
    the impact of the `relu` activation function. In the scatter plot, the data points
    to the left of x = 0 are flat and have a zero slope. The data points to the right
    of x = 0 have a perfect linear pattern with a slope of 1.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的直方图中可以观察到，x的值既有正数也有负数。基于原始的x值和通过将负值转换为零后得到的修改后的y值，散点图可视化了`relu`激活函数的影响。在散点图中，x
    = 0左侧的数据点是平坦的，具有零斜率。x = 0右侧的数据点呈现完美的线性模式，斜率为1。
- en: One of the main advantages of using the `relu` activation function is its simple
    calculation. For developing deep learning network models, this becomes an important
    factor as it helps to reduce computational cost. For many deep learning networks,
    a rectified linear unit is used as the default activation function.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`relu`激活函数的主要优势之一是其简单的计算方式。对于开发深度学习网络模型来说，这一点非常重要，因为它有助于减少计算成本。对于许多深度学习网络，修正线性单元（rectified
    linear unit）作为默认激活函数被广泛使用。
- en: 'Another popular activation function used for developing deep networks is `softmax`,
    which is usually used in the outer layer of the network. Let''s look at the following
    code to understand it better:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种用于开发深度网络的流行激活函数是`softmax`，通常用于网络的外层。让我们看一下以下代码，以更好地理解它：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the preceding code, we have taken a random sample of 1,000 values from a
    uniform distribution that lies between 1 and 5\. To use the `softmax` function,
    we can divide the exponential of each input value x by the sum of the exponential
    values of x. The resulting histogram, based on the x values, and the scatter plot
    of x and y values are shown in the following graphs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们从一个均匀分布中随机抽取了 1,000 个值，这些值介于 1 和 5 之间。为了使用 `softmax` 函数，我们可以将每个输入值
    x 的指数值除以所有 x 值指数的总和。根据 x 值生成的直方图以及 x 和 y 值的散点图如下所示：
- en: '![](img/e6669b6e-51a5-4f48-be04-36981b9cecd1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e6669b6e-51a5-4f48-be04-36981b9cecd1.png)'
- en: 'We can observe that the preceding histogram provides an approximate uniform
    pattern for the x values. The impact of the `softmax` function can be seen from
    the scatter plot where the output values now lie between 0 and 1\. This conversion
    is very useful for interpreting the results in terms of probabilities as the values
    now are as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到前面的直方图为 x 值提供了一个大致均匀的模式。可以从散点图中看到 `softmax` 函数的影响，此时输出值介于 0 和 1 之间。这种转换对于将结果以概率的形式进行解释非常有用，因为值现在如下所示：
- en: Lie between 0 and 1
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介于 0 和 1 之间
- en: The total of these probabilities is 1
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些概率的总和为 1
- en: This aspect of the `softmax` activation function, where results can be interpreted
    in terms of probabilities, makes it a popular choice when developing deep learning
    classification models. It works well whether we use it for image classification
    or text classification problems.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`softmax` 激活函数的这一方面，使得结果可以用概率的方式进行解释，因此在开发深度学习分类模型时，它成为了一个受欢迎的选择。无论是用于图像分类还是文本分类问题，它都表现良好。'
- en: Apart from these two activation functions, we also make use of others that may
    be more suitable for a specific deep leaning model.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两个激活函数，我们还使用其他可能更适合特定深度学习模型的激活函数。
- en: Once a model architecture to be used is specified, the next step is to compile
    the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦指定了要使用的模型架构，下一步就是编译模型。
- en: Compiling the model
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编译模型
- en: 'Compiling a model typically involves specifying the loss function, choosing
    an optimizer, and specifying the metrics to be used. These choices, however, depend
    on the type of problem that is being addressed. The following code is an example
    of R for compiling a deep learning binary classification model:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 编译模型通常涉及指定损失函数、选择优化器以及指定要使用的评估指标。然而，这些选择取决于所解决问题的类型。以下代码是一个使用 R 编译深度学习二元分类模型的示例：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding loss function specified is `binary_crossentropy`, which is used
    when the response variable has two classes. Binary cross-entropy can be calculated
    using the following formula:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 前面指定的损失函数是 `binary_crossentropy`，当响应变量具有两个类别时使用该函数。二元交叉熵可以使用以下公式计算：
- en: '![](img/46d4e0aa-51e4-44b7-b6b3-fe2a37dcd8c5.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46d4e0aa-51e4-44b7-b6b3-fe2a37dcd8c5.png)'
- en: 'In the preceding formula, y represents the actual class and `yhat` represents
    the prediction probability. Let''s consider two examples using the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述公式中，y 代表实际类别，`yhat` 代表预测概率。我们来看两个使用以下代码的示例：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As seen in `Example-1`, there are a total of six cases represented by y where
    the first three cases indicate the actual class to be 0, and the next three cases
    have the actual class as 1\. The prediction probabilities captured by `yhat` is
    the probability that a case belongs to category 1\. In `Example-1`, the `yhat`
    values correctly classify all six cases, and the average of all loss values is
    about 0.228\. In `Example-2`, the `yhat` values correctly classify only four cases,
    and the average of all loss values now increases to about 0.762\. The binary cross-entropy
    loss function in this way helps to assess the classification performance of a
    model. The lower the loss value is, the better the classification performance,
    and the higher the loss value is, the worse the classification performance of
    the model.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如 `Example-1` 所示，y 共有六种情况，其中前三种情况的实际类别为 0，接下来的三种情况的实际类别为 1。`yhat` 捕获的预测概率是某个案例属于类别
    1 的概率。在 `Example-1` 中，`yhat` 的值正确地分类了所有六个案例，所有损失值的平均值大约为 0.228。在 `Example-2` 中，`yhat`
    只正确分类了四个案例，所有损失值的平均值现在增加到大约 0.762。以这种方式，二元交叉熵损失函数有助于评估模型的分类性能。损失值越低，分类性能越好；损失值越高，模型的分类性能越差。
- en: There are various other loss functions that are used based on the type of problem
    for which the deep learning network is being developed. For classification models
    where the response variables have more than two classes, we make use of the `categorical_crossentropy`
    loss function. For regression problems with numeric response variables, the mean
    square error (`mse`) may be an appropriate loss function.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 根据深度学习网络开发的具体问题类型，还有各种其他损失函数。对于响应变量有多个类别的分类模型，我们使用`categorical_crossentropy`损失函数。对于具有数值型响应变量的回归问题，均方误差（`mse`）可能是一个合适的损失函数。
- en: When specifying an optimizer to be used by the model, `adam` is a popular choice
    for deep learning networks, giving good results in a wide variety of situations.
    Other commonly used optimizers include `rmsprop` and `adagrad`. When a deep learning
    network is being trained, the parameters of the network are modified based on
    feedback obtained from the loss function. How this modification of parameters
    takes place is based on which optimizer is used. The choice of a suitable optimizer
    is therefore important in arriving at a suitable model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在指定模型使用的优化器时，`adam`是深度学习网络中常用的优化器，能够在各种场景中取得良好的效果。其他常用的优化器还包括`rmsprop`和`adagrad`。当训练深度学习网络时，网络的参数会根据从损失函数得到的反馈进行调整。如何修改这些参数是基于所使用的优化器。因此，选择一个合适的优化器对于得到合适的模型至关重要。
- en: When compiling the model, we also specify a suitable metric that will be used
    for monitoring the training process. For classification problems, `accuracy` is
    a one of the most commonly used metrics. For regression problems, the mean absolute
    error is a commonly specified metric.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在编译模型时，我们还指定一个合适的度量标准，用于监控训练过程。对于分类问题，`accuracy`是最常用的度量标准之一。对于回归问题，均方误差是常用的度量标准。
- en: Once we compile a model, we are ready to fit it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们编译好模型，就可以开始拟合它了。
- en: Fitting the model
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合模型
- en: 'Fitting or training of the model is carried out with the help of data. An example
    of a code used for fitting a classification model is provided as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的拟合或训练是通过数据来进行的。下面是一个用于拟合分类模型的代码示例：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding code, fitting a model includes `training`, which is the data
    on independent variables, and `trainLabels`, which contain labels for the response
    variable. The number of epochs is specified to indicate the number of iterations
    of all samples in the training data that will be used during the training process.
    Batch size refers to the number of samples from the training data to be used,
    after which the model parameters will be updated. In addition, we also specify
    any validation split, where a 0.2 or 20% split means that the last 20% of samples
    from the training data will be kept separate from the training process to assess
    the model performance.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，拟合模型包括`training`，它是自变量的数据，以及`trainLabels`，它包含响应变量的标签。迭代次数通过指定epoch数来表明，在训练过程中将使用所有训练数据样本的迭代次数。批量大小指的是从训练数据中选取的样本数量，模型参数将在这些样本处理后被更新。此外，我们还可以指定验证集拆分，0.2或20%的拆分意味着将训练数据的最后20%样本与训练过程分开，用于评估模型的表现。
- en: When fitting a model, different layers in the network have a random initialization
    of weights. Due to this random initialization of network weights, if we fit a
    model again with the same data, same architecture, and same settings, we will
    get slightly different results. This will occur not only in a different session
    of R, but also in the same session when a model is trained again.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合模型时，网络中的不同层有随机初始化的权重。由于网络权重的随机初始化，如果我们用相同的数据、相同的架构和相同的设置重新拟合模型，我们将会得到略有不同的结果。这不仅会在不同的R会话中发生，甚至在同一会话中重新训练模型时也会发生。
- en: 'There are many situations where getting repeatable results is important. As
    an example, while publishing a deep learning-related article in a peer-reviewed
    international journal, you may need to generate more plots from the same model
    based on reviewer feedback. Another situation could be where a team working on
    the same project may like to share a model and also results with other members
    of the team. The easiest way to obtain the same results from the model is to save
    and then reload the model using the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，获取可重复的结果非常重要。例如，在向同行评审的国际期刊发布与深度学习相关的文章时，你可能需要根据审稿人的反馈从同一个模型生成更多的图表。另一个情况是，团队中的成员可能希望共享一个模型以及相关的结果。获得相同结果的最简单方法是通过以下代码保存并重新加载模型：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can save the model by specifying `filepath` and then reload when required.
    Saving a model allows us to obtain repeatable results when we use the model again.
    It also allows us to have a way to share the same model with others who can obtain
    exactly the same results, as well as helping in situations where each run takes
    a lot of time. Saving and reloading the model allows you to resume the training
    process when you train the model again.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过指定`filepath`来保存模型，并在需要时重新加载。保存模型使我们在再次使用该模型时能够获得可重复的结果。它还使我们能够与他人共享相同的模型，以便他们获得完全相同的结果，并且在每次运行耗时较长的情况下尤为有用。保存并重新加载模型还可以让你在再次训练模型时恢复训练过程。
- en: Once a model is fit, its performance can be assessed using both training and
    testing data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型拟合完成，可以使用训练数据和测试数据来评估其性能。
- en: Assessing the model performance
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: 'Assessing the performance of a deep learning classification model requires
    developing a confusion matrix that summarizes predictions for actual and predicted
    classes. Consider an example where a classification model is developed to classify
    graduate school applicants in one of two categories where class 0 refers to  applications
    that have not been accepted, and class 1 refers to accepted applications. An example
    of a confusion matrix for this situation explaining the key concepts is provided
    as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 评估深度学习分类模型的性能需要构建一个混淆矩阵，用以总结实际类别与预测类别之间的关系。假设有一个分类模型用于将研究生申请者分类为两个类别，其中类别0表示未被接受的申请，类别1表示被接受的申请。以下是该情况的混淆矩阵示例，用来解释关键概念：
- en: '![](img/884c53eb-52d9-44bd-acef-15d06693329f.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/884c53eb-52d9-44bd-acef-15d06693329f.png)'
- en: In the preceding confusion matrix, there are 208 applicants who were actually
    not accepted and the model also correctly predicts that they should not be accepted.
    This cell in the confusion matrix is also called the **true negative**. Similarly,
    there are 29 applicants who were actually accepted and the model also correctly
    predicts that they should be accepted. This cell in the confusion matrix is called
    the **true positive**. We also have cells with numbers indicating the incorrect
    classification of applicants by the model. There are 15 applicants who were actually
    not accepted, but the model incorrectly predicts that they should be accepted
    and this cell is called a **false negative**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的混淆矩阵中，有208名实际上未被接受的申请者，模型也正确地预测了他们不应被接受。该单元格在混淆矩阵中被称为**真负**。类似地，有29名实际上被接受的申请者，模型也正确地预测了他们应该被接受。该单元格在混淆矩阵中被称为**真正**。我们还可以看到一些单元格，其中包含模型对申请者错误分类的数字。有15名实际上未被接受的申请者，但模型错误地预测他们应该被接受，这个单元格称为**假负**。
- en: Another name for making an error when incorrectly classifying category 0 as
    belonging to category 1 is a type-1 error. Finally, there are 73 applicants that
    were actually accepted but the model incorrectly predicts them to belong to the
    not-accepted category, and this cell is called a **false positive**. Aanother
    name for such an incorrect classification is a type-2 error.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 错误地将类别0误分类为类别1被称为类型1错误。最后，有73名实际上被接受的申请者，但模型错误地将他们预测为未接受类别，这个单元格被称为**假正**。这种错误分类的另一种说法是类型2错误。
- en: From the confusion matrix, we can calculate the accuracy of the classification
    performance by adding numbers to the diagonal and dividing the numbers by the
    total. So, the accuracy based on the preceding matrix is (208+29)/(208+29+73+15),
    or 72.92%. Apart from the accuracy, we can also find out the model performance
    in correctly classifying each category. We can calculate the accuracy of correctly
    classifying category 1, also called sensitivity, as 29/(29+73), or 28.4%. Similarly,
    we can calculate the accuracy of correctly classifying category 0, also called
    specificity, as 208/(208+15), or 93.3%.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵中，我们可以通过将对角线上的数字相加并将其除以总数来计算分类性能的准确性。因此，基于前述矩阵的准确性为 (208+29)/(208+29+73+15)，即
    72.92%。除了准确性之外，我们还可以找出模型在正确分类每一类别上的表现。我们可以计算正确分类类别 1（也称为灵敏度）的准确性为 29/(29+73)，即
    28.4%。类似地，我们可以计算正确分类类别 0（也称为特异性）的准确性为 208/(208+15)，即 93.3%。
- en: Note, that the confusion matrix can be used when developing a classification
    model. However, other situations may call for other suitable ways of assessing
    the deep learning network.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，混淆矩阵可用于开发分类模型。然而，其他情况可能需要其他合适的方法来评估深度学习网络。
- en: We can now briefly go over the deep learning techniques covered in this book.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以简要回顾一下本书中涵盖的深度学习技术。
- en: Deep learning techniques with R and RStudio
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 R 和 RStudio 的深度学习技术
- en: 'The term **deep** in deep learning refers to a neural network model having
    several layers, and the learning takes place with the help of data. And based
    on the type of data used, deep learning may be categorized into two major categories,
    as shown in the following screenshot:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中的“**深度**”一词指的是神经网络模型具有多个层次，并且学习过程依赖于数据的帮助。根据所使用的数据类型，深度学习可以分为两大类，如下图所示：
- en: '![](img/0b572444-8411-43e4-be7e-7afff4434d3f.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b572444-8411-43e4-be7e-7afff4434d3f.png)'
- en: As shown in the preceding diagram, the type of data used for developing a deep
    neural network model can be of a structured or unstructured type. In [Chapter
    2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep Neural Networks for Multi-Class
    Classification*, we illustrate the use of a deep learning network for classification
    problems using structured data where the response variable is of the categorical
    type. In [Chapter 3](07c9aa4a-1c93-490a-bfcd-7c4bcde639d5.xhtml), *Deep Neural
    Networks for Regression*, we illustrate the use of a deep learning network for
    regression problems using structured data where the response is a continuous type
    of variable. Chapters 4 to 12 illustrate the use of deep learning networks for
    mainly two types of unstructured data that involve images and text. In chapters
    4 to 8, we provide application examples of some popular deep learning networks
    using image data, which is regarded as an unstructured type of data. Finally,
    in chapters 9 to 12, we cover some popular deep learning networks that are useful
    with text data, which is another major category within unstructured data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，用于开发深度神经网络模型的数据类型可以是结构化数据或非结构化数据。在[第二章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)《用于多类分类的深度神经网络》中，我们展示了使用结构化数据（响应变量为类别类型）来解决分类问题的深度学习网络。在[第三章](07c9aa4a-1c93-490a-bfcd-7c4bcde639d5.xhtml)《用于回归的深度神经网络》中，我们展示了使用结构化数据（响应变量为连续类型）来解决回归问题的深度学习网络。第四章至第十二章展示了深度学习网络在处理主要涉及图像和文本的两种非结构化数据类型中的应用。在第四章至第八章中，我们提供了一些使用图像数据的流行深度学习网络的应用示例，图像数据被视为一种非结构化数据类型。最后，在第九章至第十二章中，我们介绍了一些适用于文本数据的流行深度学习网络，文本数据是非结构化数据中的另一大类别。
- en: Now, let's briefly go over the examples and techniques covered in chapters 2
    to 12.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们简要回顾一下第二章至第十二章中涉及的示例和技术。
- en: Multi-class classification
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类分类
- en: There are many problems where the main objective is to develop a classification
    model that uses data to classify observations into two or more categories. For
    example, a patient may be classified as normal, suspect, or pathological based
    on the data on several variables. The deep learning network in this case will
    use data on several patients where the outcome is already available, and it will
    learn to classify a patient into one of the three categories.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 许多问题的主要目标是开发一个分类模型，使用数据将观察结果分类为两类或多类。例如，患者可以根据多个变量的数据被分类为正常、可疑或病理性。在这种情况下，深度学习网络将使用多个患者的数据（结果已知），并学习将患者分类为这三类之一。
- en: Another example of a classification problem could be where students send applications
    to a graduate school. An application from a student may be accepted or rejected
    based on variables such as GPA, GRE, and ranking of the school during their undergraduate
    degree. Another interesting example could be where student-related data is used
    for developing a model that helps to classify first-year students into those that
    are likely to stay with the current school and those who are likely to transfer
    to another school. A similar model can be developed to classify customers who
    are likely to stay with a business or switch to a competitor.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个分类问题的例子可能是学生向研究生院提交申请。学生的申请可能基于GPA、GRE成绩和本科学校排名等变量被接受或拒绝。另一个有趣的例子是，使用学生相关数据来开发一个模型，帮助将第一年学生分类为那些可能留在当前学校的学生和那些可能转学的学生。类似的模型也可以用来分类那些可能继续与某个企业合作或转向竞争对手的客户。
- en: One of the challenges involved while developing a classification model is that
    of class imbalance. For example, when dealing with medical data, the number of
    patients classified as normal may be much larger than the number of patients who
    are classified as pathological. Similarly, when applying to a graduate program
    at one of the top universities, it is very likely that the data contains a significantly
    higher number of cases where an applicant is not accepted. Deep network models
    are useful in addressing such concerns easily. The Keras library used in this
    book provides a user-friendly interface not only to address such issues easily, but
    also to help in obtaining suitable classification models with the help of fast
    experimentation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 开发分类模型时面临的挑战之一是类别不平衡。例如，在处理医疗数据时，被分类为正常的患者数量可能远大于被分类为病态的患者数量。类似地，在申请顶尖大学的研究生项目时，数据中很可能包含大量未被录取的申请者。深度网络模型在解决此类问题时非常有效。书中使用的Keras库提供了一个用户友好的界面，不仅可以轻松解决此类问题，还可以通过快速实验帮助获得合适的分类模型。
- en: In [Chapter 2](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml), *Deep Neural Networks
    for Multi-Class Classification*, we provide an illustration of a multi-class deep
    learning classification model using R.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml)，*多类分类的深度神经网络*中，我们通过使用R语言展示了一个多类深度学习分类模型。
- en: Regression problems
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归问题
- en: Structured data involving numeric response variables is classified as a regression
    problem. For example, the price of a house in a city may depend on variables such
    as the age of the house, the crime rate in the city, the number of rooms, and
    the property tax rate. Although statistical methods, such as multiple linear regression
    and elastic net regression, can also be useful for these situations, deep learning
    networks offer certain advantages. One of the main advantages of using neural
    networks in general is that they can capture non-linearity. Unlike statistical
    methods that require certain assumptions to be met before we can use them, neural
    network-based models are more flexible to use and do not require many assumptions
    to be fulfilled.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 包含数字响应变量的结构化数据被归类为回归问题。例如，一座城市中房屋的价格可能依赖于房屋的年龄、城市的犯罪率、房间数以及房产税率等变量。尽管统计方法，如多元线性回归和弹性网回归，在这些情况下也很有用，但深度学习网络具有一些优势。使用神经网络的主要优势之一是它们能够捕捉非线性。与需要满足特定假设条件才能使用的统计方法不同，基于神经网络的模型更加灵活，不需要满足太多假设条件即可使用。
- en: Many applications involving regression problems also call for identifying variables
    or features that have a significant impact on the response variable. However with
    deep learning networks, such feature engineering is inbuilt, and it doesn't call
    for any extra effort in extracting important features. One thing to note regarding
    deep learning networks is that the larger the dataset being used, the more effective
    the resulting prediction model will be. In [Chapter 3](07c9aa4a-1c93-490a-bfcd-7c4bcde639d5.xhtml),
    *Deep Neural Networks for Regression*, we provide an illustration of a deep learning
    regression model using R.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 许多涉及回归问题的应用程序也需要识别对响应变量有显著影响的变量或特征。然而，在深度学习网络中，这种特征工程是内建的，不需要额外的努力来提取重要特征。关于深度学习网络需要注意的一点是，所使用的数据集越大，最终的预测模型将会越有效。在[第3章](07c9aa4a-1c93-490a-bfcd-7c4bcde639d5.xhtml)，*回归问题的深度神经网络*中，我们通过使用R语言展示了一个深度学习回归模型。
- en: Image classification
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类
- en: Image data is classified as an unstructured type of data. One of the popular
    applications of deep learning networks involves developing image classification
    and recognition models. Image classification has various applications, such as
    face recognition on smartphones or on social media networks, classification of
    medical image data, classification of handwritten digits, and self-driving cars.
    Note that it is not possible to develop a classification model directly from unstructured
    data. The unstructured data needs to be first converted into a structured form
    before deep learning networks can be developed. For example, a black and white
    image may have dimensions of 21 x 21 and thus contain data on 441 (21 x 21) pixels.
    Once we convert an image into numbers representing all the pixels, it becomes
    feasible to develop image classification models. Although humans can classify
    a type of dress, a person, or certain object very easily, even when the images
    may have different sizes or orientation, training a computer to do so is a challenging
    task.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据被分类为非结构化数据类型。深度学习网络的一个流行应用是开发图像分类和识别模型。图像分类有许多应用，如智能手机或社交媒体网络上的面部识别、医学图像数据分类、手写数字分类以及自动驾驶汽车等。需要注意的是，无法直接从非结构化数据中开发分类模型。非结构化数据需要先转换为结构化形式，才能开发深度学习网络。例如，一张黑白图像的尺寸可能是21
    x 21，因此包含441（21 x 21）个像素的数据。一旦我们将图像转换为表示所有像素的数字，就可以开发图像分类模型。尽管人类可以非常容易地分类一种衣服、一个人或某个物体，即使图像的大小或方向不同，但训练计算机做同样的事情仍然是一个具有挑战性的任务。
- en: The Keras library provides several easy-to-use features for processing image
    data that helps in developing deep learning image classification networks. The
    effectiveness of having deep networks or neural networks with many layers especially
    comes to the fore when it comes to image recognition and classification problems.
    In [Chapter 4](356e6d56-329c-433e-8b3e-969453363ee9.xhtml), *Image Classification
    and Recognition*, we provide an illustration of applying a deep learning image
    classification model using R.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Keras库提供了多个易于使用的功能，用于处理图像数据，帮助开发深度学习图像分类网络。在涉及图像识别和分类问题时，拥有多层的深度网络或神经网络的有效性尤为突出。在[第4章](356e6d56-329c-433e-8b3e-969453363ee9.xhtml)，*图像分类与识别*中，我们提供了一个应用深度学习图像分类模型的示例，使用R语言进行演示。
- en: Convolutional neural networks
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Image classification tasks become challenging when the number of categories
    increases and images within a category show significant variability. Such situations
    also require a larger number of samples so that features inherent in each category
    can be captured more accurately by the classification model. For example, a fashion
    retailer may have a large variety of fashion items and may be interested in developing
    a classification model from the image data of such fashion items. A special type
    of deep network, called a **convolutional neural network** (**CNN**), has proven
    to be highly effective in situations that call for large scale image classification
    and recognition tasks. CNNs are the most popular networks for such applications
    and are regarded as the gold standard for large-scale image classification problems.
    These networks are capable of capturing various minute details in an image with
    the help of different types of layers in the network. In [Chapter 5](7285aaf1-8ca5-4f1d-95d8-057ce1fbf5f9.xhtml),
    *Image Classification Using Convolutional Neural Networks*, we provide an illustration
    of applying a CNN to image classification using R.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当类别数量增加且同一类别内的图像表现出显著变化时，图像分类任务变得具有挑战性。此类情况还需要更多的样本，以便分类模型能够更准确地捕捉到每个类别中的固有特征。例如，一家时尚零售商可能拥有大量种类的时尚商品，并且可能希望根据这些时尚商品的图像数据开发分类模型。一种特殊类型的深度网络，被称为**卷积神经网络**（**CNN**），已被证明在需要大规模图像分类和识别任务的情况下非常有效。CNN是这种应用中最流行的网络，并被认为是大规模图像分类问题的黄金标准。这些网络能够通过网络中的不同类型的层捕捉图像中的各种细节。在[第5章](7285aaf1-8ca5-4f1d-95d8-057ce1fbf5f9.xhtml)，*使用卷积神经网络进行图像分类*中，我们提供了一个应用CNN进行图像分类的示例，使用R语言进行演示。
- en: Autoencoders
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器
- en: Deep learning methods that involve classification and prediction models using
    data that has a response or a dependent variable are part of supervised deep learning
    methods. When working with structured or unstructured data, there are situations
    where the response variable is either not available or not used. Applications
    of deep learning networks that do not use a response variable are classified as
    unsupervised deep learning methods. For example, an application of deep learning
    may involve image data from which we want to extract important features in order
    to achieve dimension reduction. Another example involves handwritten images that
    contain unwanted noise and a deep network is used for denoising the images. In
    such situations, autoencoder networks have been found to be very useful for performing
    unsupervised deep learning tasks.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及使用具有响应变量或因变量的数据进行分类和预测模型的深度学习方法属于监督式深度学习方法。当处理结构化或非结构化数据时，有些情况下响应变量可能不可用或未被使用。那些不使用响应变量的深度学习网络应用被归类为无监督深度学习方法。例如，深度学习的一个应用可能是图像数据，我们希望从中提取重要特征以实现降维。另一个例子是包含不需要噪声的手写图像，深度网络用于去噪。在这种情况下，自编码网络被发现非常有用，能够执行无监督深度学习任务。
- en: Autoencoder neural networks make use of an encoder and decoder network. When
    the image data is passed through an encoder and the resulting dimension is lower
    than that of the original image, the network is forced to extract only the most
    important features from the input data. And then the decoder part of the network
    reconstructs the original data from whatever is available from the output of the
    encoder. In [Chapter 6](489413e8-85df-4912-b59a-bd119d93c967.xhtml), *Applying
    Autoencoder Neural Networks Using Keras*, we provide an illustration of applying
    an autoencoder neural network for dimension reduction, de-noising, and image correction
    when working with image data using R.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码神经网络使用编码器和解码器网络。当图像数据通过编码器传递，并且得到的维度低于原始图像时，网络就被迫从输入数据中提取最重要的特征。然后，网络的解码器部分根据编码器输出的内容重建原始数据。在[第
    6 章](489413e8-85df-4912-b59a-bd119d93c967.xhtml)，《使用 Keras 应用自编码神经网络》中，我们通过 R
    语言展示了如何应用自编码神经网络进行降维、去噪和图像修正。
- en: Transfer learning
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Developing deep learning classification models when the image data has several
    categories is a challenging task. It becomes even more challenging when the number
    of images available is limited. In such situations, it may be possible to take
    advantage of an existing model that has been developed with the help of a much
    larger dataset and reuse the patterns it has learned by customizing it for another
    classification task. This reuse of a pretrained deep network model for a new classification
    task is known as transfer learning.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像数据具有多个类别时，开发深度学习分类模型是一项具有挑战性的任务。当可用图像数量有限时，任务变得更加困难。在这种情况下，可以利用一个已使用大量数据集开发的现有模型，并通过定制它来处理另一个分类任务，从而重用它所学到的模式。这种将预训练深度网络模型用于新分类任务的方式称为迁移学习。
- en: The Keras library provides various pretrained models for image classification
    tasks that are trained using over a million images, and that capture reusable
    features that can be applied to similar but new data. Transferring what a pretrained
    model has learned from a large number of samples to a model that is being built
    with a much smaller sample size helps to save computational resources. In addition,
    use of the transfer learning approach can help to outperform a model that is built
    from scratch using a smaller dataset. In [Chapter 7](c316ef95-6026-4e25-9dd4-7e3a191721d0.xhtml), *Image
    Classification for Small Data Using Transfer Learning*, we cover transfer learning
    and illustrate the utilization of a pre trained deep learning image classification
    model using R.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 库提供了用于图像分类任务的各种预训练模型，这些模型是通过超过百万张图像训练得到的，能够捕捉可重用的特征，这些特征可以应用于类似但全新的数据。将一个预训练模型从大量样本中学到的知识转移到一个使用较小样本量构建的模型上，有助于节省计算资源。此外，使用迁移学习方法还可以帮助超越从零开始使用较小数据集构建的模型。在[第
    7 章](c316ef95-6026-4e25-9dd4-7e3a191721d0.xhtml)，《使用迁移学习进行小数据图像分类》中，我们介绍了迁移学习，并通过
    R 语言展示了如何利用预训练的深度学习图像分类模型。
- en: Generative adversarial networks
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: An article in The Verge (Reference: [https://www.theverge.com/2018/10/25/18023266/ai-art-portrait-christies-obvious-sold](https://www.theverge.com/2018/10/25/18023266/ai-art-portrait-christies-obvious-sold))
    reported that an artwork named *Portrait of Edmond Belamy* created using an artificial
    intelligence algorithm was sold for $432,500\. This artwork was estimated to sell
    for about $7,000 to $10,000\. The deep learning algorithm that was used to create
    this artwork is called a **generative adversarial network** (**GAN**). The unique
    attribute of generative adversarial networks is that two deep networks are made
    to compete against each other to generate something meaningful. The two networks
    that compete against each other and try to outsmart one another are called generator
    and discriminator networks.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 《The Verge》的一篇文章（参考：[https://www.theverge.com/2018/10/25/18023266/ai-art-portrait-christies-obvious-sold](https://www.theverge.com/2018/10/25/18023266/ai-art-portrait-christies-obvious-sold)）报道了一件名为*Portrait
    of Edmond Belamy*的艺术作品，这幅作品是使用人工智能算法创作的，最终以432,500美元的价格售出。该作品的预计售价大约为7,000到10,000美元。用于创作这幅作品的深度学习算法被称为**生成对抗网络**（**GAN**）。生成对抗网络的独特属性在于，它通过让两个深度网络相互竞争，生成有意义的东西。这两个相互竞争并试图超过对方的网络被称为生成器网络和判别器网络。
- en: Consider a situation where we want to generate new handwritten images of the
    digit *five*. A generative adversarial network in this case would involve a generator
    network that creates fake images of the handwritten digit *five* from simply random
    noise and sends it to a discriminator network. The fake images are mixed with
    genuine images and the discriminator network, which is trained to differentiate
    between real and fake images of the handwritten digit *five*, will try its best
    to successfully differentiate between real and fake images. These two networks
    are made to compete against each other until the generator network starts making
    realistic-looking fake images that the discriminator network finds increasingly
    difficult to differentiate between. In addition to image data, application of
    generative adversarial networks can be extended to generate new text or even new
    music. We will illustrate an application of a generative adversarial network to
    generate new images in [Chapter 8](7031c1cb-e20d-4e86-8667-393d0cceddca.xhtml), *Creating
    New Images Using Generative Adversarial Networks*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想生成新的手写数字*五*的图像。在这种情况下，生成对抗网络将涉及一个生成器网络，它从随机噪声中创建伪造的手写数字*五*图像，并将其发送给判别器网络。伪造的图像与真实图像混合，判别器网络会尽力区分手写数字*五*的真实和伪造图像。这两个网络将相互竞争，直到生成器网络开始生成看起来非常真实的伪造图像，而判别器网络逐渐变得难以区分真实和伪造图像。除了图像数据，生成对抗网络的应用还可以扩展到生成新的文本甚至新的音乐。在[第8章](7031c1cb-e20d-4e86-8667-393d0cceddca.xhtml)中，我们将演示生成对抗网络在生成新图像中的应用，*使用生成对抗网络创建新图像*。
- en: Deep network for text classification
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于文本分类的深度网络
- en: Text data has certain unique characteristics that makes it a very different
    type of unstructured data compared to image data. As mentioned earlier, unstructured
    data requires extra processing steps to arrive at a structured format that can
    be used for developing a deep learning classification network. One of the applications
    of deep learning with text data involves developing a deep neural network sentiment
    classification model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据具有一些独特的特点，使其成为与图像数据相比非常不同类型的非结构化数据。正如之前提到的，非结构化数据需要额外的处理步骤才能转化为可以用于开发深度学习分类网络的结构化格式。深度学习在文本数据中的应用之一是开发深度神经网络情感分类模型。
- en: To develop a sentiment classification model, labels capturing sentiment related
    to the text data are needed. For example, we may use text data on movie reviews
    and a related sentiment label (positive review or negative review) to develop
    a model that can be used to automate the process. Another example could be the
    development of a sentiment classification model using text data on tweets. Such
    a model can be useful in comparing sentiments contained in thousands of tweets
    or and after an important event. Examples of such events where sentiment classification
    models can be useful include sentiments contained in tweets before and after the
    release of a new smartphone by a company, and sentiments contained in tweets before
    and after the performance of a presidential candidate in a live debate. A deep
    network for a sentiment classification model using text data is illustrated in
    [Chapter 9](491ea3a8-47e9-48b4-8553-7387528c8594.xhtml), *Deep Networks for Text
    Classification*.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发情感分类模型，需要捕捉与文本数据相关的情感标签。例如，我们可以使用电影评论的文本数据和相关的情感标签（正面评论或负面评论）来开发一个可以自动化处理的模型。另一个例子是使用推文文本数据开发情感分类模型。这样的模型可以用于比较成千上万条推文中的情感，特别是在重大事件发生前后。例如，在公司发布新智能手机前后，或者总统候选人在现场辩论中的表现前后，推文中的情感分类模型都可以发挥重要作用。使用文本数据的情感分类模型的深度网络示例可以参考[第9章](491ea3a8-47e9-48b4-8553-7387528c8594.xhtml)，*用于文本分类的深度网络*。
- en: Recurrent neural networks
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: A unique characteristic of text data is the fact that the placement of words
    in a text sequence has some meaning. **Recurrent neural networks** (**RNNs**)
    are well suited to work with data involving such sequences. Recurrent networks
    allow output from the previous step to be passed as input to the following step.
    This process of feeding prior information at a step allows recurrent networks
    to have memory, which is very useful for dealing with data involving sequences.
    The name **recurrent** in RNN also comes from the fact that the output at a step
    depends on information from the previous step.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据的一个独特特点是，文本序列中单词的排列具有一定的意义。**循环神经网络**（**RNN**）非常适合处理涉及此类序列的数据。循环网络允许将前一步的输出作为输入传递到下一步。通过在每个步骤中传递先前的信息，循环网络可以具有记忆功能，这对于处理涉及序列的数据非常有用。RNN
    中的**循环**一词也来自于此，即每一步的输出依赖于前一步的信息。
- en: RNNs can be used to develop a sentiment classification model where the text
    data could be movie reviews, tweets, product reviews, and so on. Developing such
    a sentiment classification model will also need the labels that will be used for
    training the network. We go over steps for developing a recurrent neural network
    model for sentiment classification using R in [Chapter 10](acfbe36f-dae6-40ad-96b5-0b0e87ce0f8d.xhtml),
    *Text Classification Using Recurrent Neural Networks*.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 可以用来开发情感分类模型，其中文本数据可能是电影评论、推文、产品评论等。开发这样的情感分类模型还需要用于训练网络的标签。我们将在[第10章](acfbe36f-dae6-40ad-96b5-0b0e87ce0f8d.xhtml)中讲解如何使用
    R 开发一个情感分类的循环神经网络模型，*使用循环神经网络进行文本分类*。
- en: Long short-term memory network
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 长短期记忆网络
- en: '**Long short-term memory** (**LSTM**) networks are a special type of recurrent
    neural network. LSTM networks are useful when data regarding the sequence of words
    or integers has long-term dependencies. For example, two words that are important
    for correctly classifying sentiment contained in a movie review may be separated
    by many words in a long sentence. A sentiment classification model using a regular
    RNN will have difficulty capturing such long-term dependency between words. A
    regular RNN is useful when dependency between words or integers in a sequence
    is immediate or when two important words are next to each other.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**长短期记忆**（**LSTM**）网络是一种特殊类型的循环神经网络。当数据涉及单词或整数序列且具有长期依赖性时，LSTM 网络非常有用。例如，在一篇电影评论中，两个对于正确分类情感非常重要的单词可能被长句子中的许多单词所分隔。使用常规
    RNN 的情感分类模型将很难捕捉到单词之间的这种长期依赖关系。而常规 RNN 在单词或整数之间的依赖关系是即时的，或者两个重要的单词彼此相邻时，RNN 很有用。'
- en: Apart from sentiment classification, the application of LSTM networks can also
    be useful for speech recognition, language translation, anomaly detection, time
    series forecasting, answering questions, and so on. An application of an LSTM
    network for movie review sentiment classification is illustrated in [Chapter 11](da73d1c6-4377-4a8f-9bee-01262444f136.xhtml),
    *Text Classification Using Long Short-Term Memory Network*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 除了情感分类外，LSTM网络的应用还可以用于语音识别、语言翻译、异常检测、时间序列预测、问答等多个领域。在[第11章](da73d1c6-4377-4a8f-9bee-01262444f136.xhtml)中，介绍了一种用于电影评论情感分类的LSTM网络应用，*使用长短期记忆网络进行文本分类*。
- en: Convolutional recurrent networks
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积递归网络
- en: '**Convolutional neural networks** (**CNNs**) are useful for capturing high-level
    local features from the image or text data, and LSTM networks can capture long-term
    dependencies in the data involving sequences. When we use both CNNs and a recurrent
    network in the same model architecture, it is called a **convolutional recurrent
    neural network** (**CRNN**). As an example, if we consider data on articles and
    their authors, we may be interested in developing an author classification model
    where we can train a network to take text data containing an article as input
    and then help to make a prediction in terms of probability regarding the author.
    For this, we can first use a one-dimensional convolutional layer to extract important
    features from the data. These extracted features can then be passed to the LSTM
    recurrent layer to obtain the hidden long-term dependencies, which, in turn, are
    passed to a fully connected dense layer. This dense layer can then obtain the
    probability of correct authorship. CRNNs can also be applied to problems related
    to natural language processing, speech, and video. In [Chapter 12](be0c6dfc-045c-4698-b36d-74eca5e0a629.xhtml),
    *Text Classification Using Convolutional Recurrent Networks*, we illustrate the
    use of CRNNs for developing a model that can classify an author, based on articles
    written by them.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNNs**）用于从图像或文本数据中捕获高级局部特征，而LSTM网络则可以捕获涉及序列的长期依赖性数据。当我们在同一模型架构中同时使用CNN和递归网络时，称为**卷积递归神经网络**（**CRNN**）。例如，如果我们考虑文章及其作者的数据，我们可能希望开发一个作者分类模型，该模型可以训练一个网络以接受包含文章的文本数据作为输入，然后帮助预测关于作者的正确性的概率。为此，我们可以首先使用一维卷积层从数据中提取重要特征。然后，这些提取的特征可以传递到LSTM递归层以获取隐藏的长期依赖关系，这些依赖关系又传递到一个全连接的密集层。然后，这个密集层可以获得正确作者的概率。CRNN也可以应用于与自然语言处理、语音和视频相关的问题。在[第12章](be0c6dfc-045c-4698-b36d-74eca5e0a629.xhtml)中，*使用卷积递归网络进行文本分类*，我们说明了使用CRNN开发模型的示例，该模型可以根据作者撰写的文章对作者进行分类。'
- en: Tips, tricks, and best practices
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技巧、诀窍和最佳实践
- en: In this book, we provide an illustration of applying several popular deep learning
    methods using R. When working on more complex problems requiring the application
    of deep learning networks, the use of certain supporting tools may sometimes be
    very helpful. TensorFlow provides such a tool; it is called **TensorBoard** and
    is useful for visualizing deep network training performance, especially in situations
    that call for experimentation. Similarly, there is a package called **Local Interpretable
    Model-Agnostic Explanations** (**LIME**) that can help with visualization and
    interpretation of specific predictions. We also get many outputs, such as summaries
    and plots, when developing a deep network model. There is a package called **tfruns**
    that can help to keep everything in one place for easy reference. There is a callback
    feature in the Keras package that helps with stopping a network training at a
    suitable time. We will discuss all these tips, tricks, and best practices in [Chapter
    13](af4eb94d-f4fb-41df-9df8-797e4771484d.xhtml), *Tips, Tricks, and the Road Ahead*.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们展示了如何使用R语言应用几种流行的深度学习方法。在处理需要深度学习网络的更复杂问题时，使用特定的支持工具有时非常有帮助。TensorFlow提供了一个这样的工具；它称为**TensorBoard**，对于可视化深度网络训练性能特别有用，特别是在需要实验的情况下。类似地，有一个称为**局部可解释模型无关解释**（**LIME**）的包，可以帮助可视化和解释特定预测。在开发深度网络模型时，我们还会获得许多输出，例如摘要和图表。有一个叫做**tfruns**的包可以帮助将所有内容整理到一个地方方便参考。Keras包中还有一个回调功能，可以帮助在适当的时候停止网络训练。我们将在[第13章](af4eb94d-f4fb-41df-9df8-797e4771484d.xhtml)中讨论所有这些技巧、诀窍和最佳实践，*技巧、诀窍和前路*。
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning methods that make use of artificial neural networks have been
    increasing in popularity in recent years. A number of areas of application involving
    deep learning methods include driverless cars, image classification, natural language
    processing, and new image generation. We started this first chapter by looking
    at the popularity of the deep learning term as reported from a Google trend website.
    We described a general five-step process for applying deep learning methods and
    developed some broad ideas about details within each step. We then briefly looked
    at deep learning techniques covered in each chapter and situations in which they
    are applied, along with some best practices.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，利用人工神经网络的深度学习方法越来越受欢迎。深度学习方法的应用领域包括无人驾驶汽车、图像分类、自然语言处理和新图像生成等多个领域。我们在第一章开始时，通过查看来自谷歌趋势网站的深度学习相关热度数据，介绍了深度学习这一术语的流行程度。我们描述了应用深度学习方法的一般五步过程，并阐述了每一步骤中的一些基本概念。接着，我们简要介绍了每一章中所涉及的深度学习技术、它们的应用场景以及一些最佳实践。
- en: In the next chapter, we get started with an application example and illustrate
    steps for developing a deep network model for multi-class classification problems.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过一个应用示例开始，展示为多类别分类问题开发深度网络模型的步骤。
