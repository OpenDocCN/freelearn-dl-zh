- en: Building Deep Neural Networks for Binary Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建用于二分类的深度神经网络
- en: In this chapter, we are going to develop a **Deep Neural Network** (**DNN**)
    using the standard feedforward network architecture. We will add components and
    changes to the application while we progress through the recipes. Make sure to
    revisit [Chapter 1](f88b350b-16e2-425b-8425-4631187c7803.xhtml), *Introduction
    to Deep Learning in Java*, and [Chapter 2](6ac5dff5-cc98-4d52-bc59-1da01b2aeded.xhtml), *Data
    Extraction, Transformation, and Loading*, if you have not already done so. This
    is to ensure better understanding of the recipes in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用标准的前馈网络架构开发一个**深度神经网络**（**DNN**）。在我们逐步完成各个配方的过程中，我们会不断向应用程序添加组件和修改内容。如果你还没有阅读过，[第1章](f88b350b-16e2-425b-8425-4631187c7803.xhtml)，*Java
    深度学习简介*，以及[第2章](6ac5dff5-cc98-4d52-bc59-1da01b2aeded.xhtml)，*数据提取、转换和加载*，请确保回顾这些内容。这有助于更好地理解本章中的配方。
- en: We will take an example of a customer retention prediction for the demonstration
    of the standard feedforward network. This is a crucial real-world problem that
    every business wants to solve. Businesses would like to invest more in happy customers,
    who tend to stay customers for longer periods of time. At the same time, predictions
    of losing customers will make businesses focus more on decisions that encourage
    customers not to take their business elsewhere.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以客户保持预测为例，演示标准的前馈网络。这是一个至关重要的现实问题，每个企业都希望解决。企业希望在满意的客户身上投入更多资源，因为这些客户往往会成为长期客户。与此同时，预测流失客户有助于企业更加专注于做出能阻止客户流失的决策。
- en: Remember that a feedforward network doesn't really give you any hints about
    the actual features that decide the outcome. It just predicts whether a customer
    continues to patronize the organization or not. The actual feature signals are
    hidden, and it is left to the neural network to decide. If you want to record
    the actual feature signals that control the prediction outcome, then you could
    use an autoencoder for the task. Let's examine how to construct a feedforward
    network for our aforementioned use case.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，前馈网络实际上并不能提供有关决策结果的特征提示。它只会预测客户是否继续支持该组织。实际的特征信号是隐藏的，由神经网络来决定。如果你想记录那些控制预测结果的实际特征信号，可以使用自编码器来完成此任务。接下来，让我们来看一下如何为我们上述的用例构建一个前馈网络。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Extracting data from CSV input
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 CSV 输入提取数据
- en: Removing anomalies from the data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据中删除异常值
- en: Applying transformations to the data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据应用变换
- en: Designing input layers for the neural network model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为神经网络模型设计输入层
- en: Designing hidden layers for the neural network model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为神经网络模型设计隐藏层
- en: Designing output layers for the neural network model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为神经网络模型设计输出层
- en: Training and evaluating the neural network model for CSV data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 CSV 数据进行神经网络模型的训练和评估
- en: Deploying the neural network model and using it as an API
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署神经网络模型并将其用作 API
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Make sure the following requirements are satisfied:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 确保满足以下要求：
- en: JDK 8 is installed and added to `PATH`. Source code requires JDK 8 for execution.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JDK 8 已安装并添加到 `PATH`。源代码需要 JDK 8 来执行。
- en: Maven is installed/added to `PATH`. We use Maven to build the application JAR
    file afterward.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maven 已安装并添加到 `PATH`。我们稍后将使用 Maven 构建应用程序的 JAR 文件。
- en: Concrete implementation for the use case discussed in this chapter (Customer
    retention prediction) can be found at [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的具体用例（客户保持预测）的实现可以在[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java)找到。
- en: After cloning our GitHub repository, navigate to the `Java-Deep-Learning-Cookbook/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode` directory.
    Then import the `cookbookapp` project into your IDE as a Maven project by importing `pom.xml`.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆我们的 GitHub 仓库后，导航到 `Java-Deep-Learning-Cookbook/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode` 目录。然后，通过导入 `pom.xml` 将 `cookbookapp` 项目作为
    Maven 项目导入到你的 IDE 中。
- en: Dataset is already included in the `resources` directory (`Churn_Modelling.csv`)
    of the `cookbookapp` project.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集已包含在 `cookbookapp` 项目的 `resources` 目录中（`Churn_Modelling.csv`）。
- en: However, the dataset can be downloaded at [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling/downloads/bank-customer-churn-modeling.zip/1](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling/downloads/bank-customer-churn-modeling.zip/1).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据集可以在 [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling/downloads/bank-customer-churn-modeling.zip/1](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling/downloads/bank-customer-churn-modeling.zip/1)
    下载。
- en: Extracting data from CSV input
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 CSV 输入中提取数据
- en: '**ETL** (short for **Extract, Transform and Load**) is the first stage prior
    to network training. Customer churn data is in CSV format. We need to extract
    it and put it in a record reader object to process further. In this recipe, we
    extract the data from a CSV file.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**ETL**（即**提取、转换和加载**的缩写）是网络训练之前的第一阶段。客户流失数据是 CSV 格式的。我们需要提取它，并将其放入记录读取对象中以进一步处理。在这个食谱中，我们从
    CSV 文件中提取数据。'
- en: How to do it...
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create `CSVRecordReader` to hold customer churn data:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `CSVRecordReader` 来保存客户流失数据：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Add data to `CSVRecordReader`:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向 `CSVRecordReader` 添加数据：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How it works...
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The CSV data from the dataset has 14 features. Each row represents a customer/record,
    as shown in the following screenshot:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 来自数据集的 CSV 数据有 14 个特征。每一行代表一个客户/记录，如下图所示：
- en: '![](img/9530d8be-7666-495f-aafc-18676893e788.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9530d8be-7666-495f-aafc-18676893e788.png)'
- en: Our dataset is a CSV file containing 10,000 customer records, where each record
    is labeled as to whether the customer left the business or not. Columns 0 to 13
    represent input features. The 14^(th) column, `Exited`, indicates the label or
    prediction outcome. We're dealing with a supervised model, and each prediction
    is labeled with `0` or `1`, where `0` indicates a happy customer, and `1` indicates
    an unhappy customer who has left the business. The first row in the dataset is
    just feature labels, and we don't need them while processing the data. So, we
    have skipped the first line while we created the record reader instance in step
    1\. In step 1, `1` is the number of rows to be skipped on the dataset. Also, we
    have mentioned a comma delimiter (`,`) because we are using a CSV file. In step
    2, we used `FileSplit` to mention the customer churn dataset file. We can also
    deal with multiple dataset files using other `InputSplit` implementations, such
    as `CollectionInputSplit`, `NumberedFileInputSplit`, and so on.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集是一个包含 10,000 条客户记录的 CSV 文件，其中每条记录都有标签，指示客户是否离开了业务。第 0 至第 13 列表示输入特征。第
    14^(列)，`Exited`，表示标签或预测结果。我们正在处理一个监督学习模型，每个预测都被标记为 `0` 或 `1`，其中 `0` 表示满意的客户，`1`
    表示已离开的不满意客户。数据集的第一行仅为特征标签，在处理数据时我们不需要这些标签。因此，我们在第 1 步中创建记录读取器实例时跳过了第一行。在第 1 步中，`1`
    是需要跳过的行数。此外，我们提到了逗号分隔符（`,`），因为我们使用的是 CSV 文件。在第 2 步中，我们使用了 `FileSplit` 来指定客户流失数据集文件。我们还可以使用其他 `InputSplit` 实现来处理多个数据集文件，如 `CollectionInputSplit`、`NumberedFileInputSplit`
    等。
- en: Removing anomalies from the data
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据中移除异常值
- en: For supervised datasets, manual inspection works fine for datasets with fewer
    features. As the feature count goes high, manual inspection becomes impractical.
    We need to perform feature selection techniques, such as chi-square test, random
    forest, and so on, to deal with the volume of features. We can also use an autoencoder to
    narrow down the relevant features. Remember that each feature should have a fair
    contribution toward the prediction outcomes. So, we need to remove noise features
    from the raw dataset and keep everything else as is, including any uncertain features.
    In this recipe, we will walk through the steps to identify anomalies in the data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于监督数据集，手动检查对于特征较少的数据集效果很好。随着特征数量的增加，手动检查变得不切实际。我们需要执行特征选择技术，如卡方检验、随机森林等，来处理大量特征。我们还可以使用自编码器来缩小相关特征的范围。记住，每个特征都应该对预测结果有公平的贡献。因此，我们需要从原始数据集中移除噪声特征，并保持其他所有内容，包括任何不确定的特征。在这个食谱中，我们将演示识别数据中异常值的步骤。
- en: How to do it...
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Leave out all the noise features before training the neural network. Remove
    noise features at the schema transformation stage:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练神经网络之前，排除所有噪声特征。请在模式转换阶段移除噪声特征：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Identify the missing values using the DataVec analysis API:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用DataVec分析API识别缺失值：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Remove null values using a schema transformation:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模式转换移除空值：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Remove NaN values using a schema transformation:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模式转换移除NaN值：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'If you recall our customer churn dataset, there are 14 features:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得我们的客户流失数据集，它包含14个特征：
- en: '![](img/5dee1e86-791a-445c-9737-deaf4dca7527.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5dee1e86-791a-445c-9737-deaf4dca7527.png)'
- en: After performing step 1, you have 11 valid features remaining. The following
    marked features have zero significance on the prediction outcome. For example,
    the customer name doesn't influence whether a customer would leave the organization
    or not.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 执行第1步后，您将剩下11个有效特征。以下标记的特征对预测结果没有任何意义。例如，客户的名字并不会影响客户是否会离开公司。
- en: '![](img/40ca2a93-1976-4b5f-93b3-d99d95d8c993.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/40ca2a93-1976-4b5f-93b3-d99d95d8c993.png)'
- en: In the above screenshot, we have marked the features that are not required for
    the training. These features can be removed from the dataset as it doesn't have
    any impact on outcome.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述截图中，我们标出了不需要用于训练的特征。这些特征可以从数据集中删除，因为它们对结果没有影响。
- en: In step 1, we tagged the noise features (`RowNumber`, `Customerid`, and `Surname`)
    in our dataset for removal during the schema transformation process using the `removeColumns()` method.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1步中，我们使用`removeColumns()`方法在模式转换过程中标记了数据集中的噪声特征（`RowNumber`、`Customerid`和`Surname`）以供移除。
- en: The customer churn dataset used in this chapter has only 14 features. Also,
    the feature labels are meaningful. So, a manual inspection was just enough. In
    the case of a large number of features, you might need to consider using **PCA**
    (short for **Principal Component Analysis**), as explained in the previous chapter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使用的客户流失数据集只有14个特征。而且，这些特征标签是有意义的。因此，手动检查已经足够了。如果特征数量较多，您可能需要考虑使用**PCA**（即**主成分分析**），正如上一章所解释的那样。
- en: 'In step 2, we used the `AnalyzeLocal` utility class to find the missing values
    in the dataset by calling `analyzeQuality()`. You should see the following result
    when you print out the information in the `DataQualityAnalysis` object:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2步中，我们使用了`AnalyzeLocal`工具类，通过调用`analyzeQuality()`方法来查找数据集中的缺失值。当您打印出`DataQualityAnalysis`对象中的信息时，应该看到以下结果：
- en: '![](img/621c3773-9d43-498e-967a-efe1e0b9a104.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/621c3773-9d43-498e-967a-efe1e0b9a104.png)'
- en: As you can see in the preceding screenshot, each of the features is analyzed
    for its quality (in terms of invalid/missing data), and the count is displayed
    for us to decide if we need to normalize it further. Since all features appeared
    to be OK, we can proceed further.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前面的截图中所见，每个特征都对其质量进行了分析（以无效/缺失数据为标准），并显示了计数，以便我们判断是否需要进一步标准化。由于所有特征看起来都正常，我们可以继续进行下一步。
- en: There are two ways in which missing values can be handled. Either we remove
    the entire record or replace them with a value. In most cases, we don't remove
    records; instead, we replace them with a value to indicate absence. We can do
    it during the transformation process using `conditionalReplaceValueTransform()`
    or `conditionalReplaceValueTransformWithDefault()`. In step 3/4, we removed missing
    or invalid values from the dataset. Note that the feature needs to be known beforehand.
    We cannot check the whole set of features for this purpose. At the moment, DataVec
    doesn't support this functionality. You may perform step 2 to identify features
    that need attention.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值有两种方法。要么删除整个记录，要么用一个值替代。在大多数情况下，我们不会删除记录，而是用一个值来表示缺失。在转换过程中，我们可以使用`conditionalReplaceValueTransform()`或`conditionalReplaceValueTransformWithDefault()`来进行此操作。在第3/4步中，我们从数据集中移除了缺失或无效值。请注意，特征需要事先已知。我们不能检查所有特征以完成此操作。目前，DataVec不支持此功能。您可以执行第2步来识别需要注意的特征。
- en: There's more...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'We discussed earlier in this chapter how to use the `AnalyzeLocal` utility
    class to find out missing values. We can also perform extended data analysis using `AnalyzeLocal`.
    We can create a data analysis object that holds information on each column present
    in the dataset. It can be created by calling `analyze()`, as we discussed in the
    previous chapter. If you try to print out the information on the data analysis
    object, it will look like the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章前面讨论了如何使用`AnalyzeLocal`工具类找出缺失值。我们还可以使用`AnalyzeLocal`执行扩展的数据分析。我们可以创建一个数据分析对象，包含数据集中每一列的信息。通过调用`analyze()`可以创建该对象，正如我们在前一章中讨论的那样。如果你尝试打印出数据分析对象的信息，它将如下所示：
- en: '![](img/9107f6f7-a7c4-4830-9296-a068771ee108.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9107f6f7-a7c4-4830-9296-a068771ee108.png)'
- en: It will calculate the standard deviation, mean, and the min/max values for all
    the features in the dataset. The count of features is also calculated, which will
    be helpful toward identifying missing or invalid values in features.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 它将计算数据集中所有特征的标准差、均值以及最小/最大值。同时，还会计算特征的数量，这对于识别特征中的缺失或无效值非常有帮助。
- en: '![](img/8a761959-3786-4d70-a828-462ebf049e10.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a761959-3786-4d70-a828-462ebf049e10.png)'
- en: Both screenshots on the above indicate the data analysis results returned by
    calling `analyze()` method. For the customer churn dataset, we should have a total
    count of 10,000 for all features as the total number of records present in our
    dataset is 10,000.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 上面两个截图显示的是通过调用`analyze()`方法返回的数据分析结果。对于客户流失数据集，我们应该有10,000个特征总数，因为数据集中的记录总数为10,000。
- en: Applying transformations to the data
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对数据应用转换
- en: Data transformation is a crucial data normalization procedure that must be done
    before we feed the data to a neural network. We need to transform non-numeric
    features to numeric values and handle missing values. In this recipe, we will
    perform schema transformation, and create dataset iterators after transformation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换是一个至关重要的数据标准化过程，必须在将数据输入神经网络之前完成。我们需要将非数值特征转换为数值，并处理缺失值。在本食谱中，我们将执行模式转换，并在转换后创建数据集迭代器。
- en: How to do it...
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Add features and labels into the schema:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征和标签添加到模式中：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Identify and add categorical features to the schema:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别并将分类特征添加到模式中：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Remove noise features from the dataset:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中移除噪声特征：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Transform categorical variables:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换分类变量：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Apply one-hot encoding by calling `categoricalToOneHot()`:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`categoricalToOneHot()`应用独热编码：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Remove the correlation dependency on the `Geography` feature by calling `removeColumns()`:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`removeColumns()`移除`Geography`特征的相关依赖：
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we selected `France` as the correlation variable.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们选择了`France`作为相关变量。
- en: 'Extract the data and apply the transformation using `TransformProcessRecordReader`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`TransformProcessRecordReader`提取数据并应用转换：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create a dataset iterator to train/test:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据集迭代器以进行训练/测试：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Normalize the dataset:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规范化数据集：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Split the main dataset iterator to train and test iterators:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将主数据集迭代器拆分为训练和测试迭代器：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Generate train/test iterators from `DataSetIteratorSplitter`:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`DataSetIteratorSplitter`生成训练/测试迭代器：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How it works...
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: All features and labels need to be added to the schema as mentioned in step
    1 and step 2\. If we don't do that, then DataVec will throw runtime errors during
    data extraction/loading.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所有特征和标签需要按照第1步和第2步中提到的添加到模式中。如果我们没有这么做，DataVec将在数据提取/加载时抛出运行时错误。
- en: '![](img/73912ea2-ea7a-4786-ab3b-953c6202b743.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73912ea2-ea7a-4786-ab3b-953c6202b743.png)'
- en: In the preceding screenshot, the runtime exception is thrown by DataVec because
    of unmatched count of features. This will happen if we provide a different value
    for input neurons instead of the actual count of features in the dataset.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，运行时异常是由于DataVec引发的，原因是特征数量不匹配。如果我们为输入神经元提供的值与数据集中的实际特征数量不一致，就会发生这种情况。
- en: From the error description, it is clear that we have only added 13 features
    in the schema, which ended in a runtime error during execution. The first three
    features, named `Rownumber`, `Customerid`, and `Surname`, are to be added to the
    schema. Note that we need to tag these features in the schema, even though we
    found them to be noise features. You can also remove these features manually from
    the dataset. If you do that, you don't have to add them in the schema, and, thus,
    there is no need to handle them in the transformation stage
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从错误描述中可以看出，我们仅在模式中添加了13个特征，这导致在执行过程中发生了运行时错误。前三个特征，分别为`Rownumber`、`Customerid`和`Surname`，需要添加到模式中。请注意，尽管我们发现它们是噪声特征，但仍需要在模式中标记这些特征。你也可以手动从数据集中删除这些特征。如果你这么做，就不需要在模式中添加它们，因此也无需在转换阶段处理它们。
- en: For large datasets, you may add all features from the dataset to the schema,
    unless your analysis identifies them as noise. Similarly, we need to add the other
    feature variables such as `Age`, `Tenure`, `Balance`, `NumOfProducts`, `HasCrCard`, `IsActiveMember`, `EstimatedSalary`,
    and `Exited`. Note the variable types while adding them to schema. For example, `Balance` and `EstimatedSalary` have
    floating point precision, so consider their datatype as double and use `addColumnDouble()` to
    add them to schema.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型数据集，除非分析结果将其识别为噪声，否则可以将数据集中的所有特征添加到模式中。同样，我们需要将其他特征变量如`Age`、`Tenure`、`Balance`、`NumOfProducts`、`HasCrCard`、`IsActiveMember`、`EstimatedSalary`和`Exited`添加到模式中。添加它们时，请注意变量类型。例如，`Balance`和`EstimatedSalary`具有浮动点精度，因此考虑将它们的数据类型设为double，并使用`addColumnDouble()`将它们添加到模式中。
- en: We have two features named gender and geography that require special treatment.
    These two features are non-numeric and their feature values represent categorical
    values compared to other fields in the dataset. Any non-numeric features need
    to transform numeric values so that the neural network can perform statistical
    computations on feature values. In step 2, we added categorical variables to the
    schema using `addColumnCategorical()`. We need to specify the categorical values
    in a list, and `addColumnCategorical()` will tag the integer values based on the
    feature values mentioned. For example, the `Male` and `Female` values in the categorical
    variable `Gender` will be tagged as `0` and `1` respectively. In step 2, we added
    the possible values for the categorical variables in a list. If your dataset has
    any other unknown value present for a categorical variable (other than the ones
    mentioned in the schema), DataVec will throw an error during execution.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个特征，分别为gender和geography，需要特别处理。这两个特征是非数字型的，它们的特征值表示类别值，而不是数据集中其他字段的数值。任何非数字特征都需要转换为数值，以便神经网络能够对特征值进行统计计算。在步骤2中，我们使用`addColumnCategorical()`将类别变量添加到模式中。我们需要在列表中指定类别值，`addColumnCategorical()`将基于指定的特征值标记整数值。例如，类别变量`Gender`中的`Male`和`Female`值将分别被标记为`0`和`1`。在步骤2中，我们将类别变量的可能值添加到列表中。如果数据集中有其他未知类别值（与模式中提到的值不同），DataVec将在执行过程中抛出错误。
- en: In step 3, we marked the noise features for removal during the transformation
    process by calling `removeColumns()`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤3中，我们通过调用`removeColumns()`标记了需要在转换过程中移除的噪声特征。
- en: In step 4, we performed one-hot encoding for the `Geography` categorical variable.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤4中，我们对`Geography`类别变量进行了独热编码。
- en: '`Geography` has three categorical values, and hence it will take the 0, 1,
    and 2 values after the transformation. The ideal way of transforming non-numeric
    values is to convert them to a value of zero (0) and one (1). It would significantly
    ease the effort of the neural network. Also, the normal integer encoding is applicable
    only if there exists an ordinal relationship between the variables. The risk here
    is we''re assuming that there exists natural ordering between the variables. Such
    an assumption can result in the neural network showing unpredictable behavior.
    So, we have removed the correlation variable in step 6\. For the demonstration,
    we picked `France` as a correlation variable in step 6\. However, you can choose
    any one among the three categorical values. This is to remove any correlation
    dependency that affects neural network performance and stability. After step 6, the
    resultant schema for the `Geography` feature will look like the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`Geography`有三个分类值，因此在转换后它将采用0、1和2的值。转换非数值型值的理想方式是将它们转换为零（0）和一（1）的值。这将显著减轻神经网络的负担。此外，普通的整数编码仅在变量之间存在序数关系时适用。这里的风险在于，我们假设变量之间存在自然的顺序关系。这种假设可能会导致神经网络出现不可预测的行为。因此，我们在第6步中删除了相关变量。为了演示，我们在第6步中选择了`France`作为相关变量。但你可以从三个分类值中选择任何一个。这是为了消除任何影响神经网络性能和稳定性的相关性依赖。第6步后，`Geography`特征的最终模式将如下所示：'
- en: '![](img/7be56c83-76d3-420b-9f58-f2a314822f5b.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7be56c83-76d3-420b-9f58-f2a314822f5b.png)'
- en: 'In step 8, we created dataset iterators from the record reader objects. Here
    are the attributes for the `RecordReaderDataSetIterator` builder method and their
    respective roles:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在第8步中，我们从记录读取器对象创建了数据集迭代器。以下是`RecordReaderDataSetIterator`构建方法的属性及其各自的作用：
- en: '`labelIndex`: The index location in the CSV data where our labels (outcomes)
    are located.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labelIndex`：在CSV数据中标签（结果）所在的索引位置。'
- en: '`numClasses`: The number of labels (outcomes) from the dataset.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numClasses`：数据集中标签（结果）的数量。'
- en: '`batchSize`: The block of data that passes through the neural network. If you
    specify a batch size of 10 and there are 10,000 records, then there will be 1,000
    batches holding 10 records each.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batchSize`：通过神经网络的数据块。如果你指定了批量大小为10且有10,000条记录，那么将会有1,000个批次，每个批次包含10条记录。'
- en: Also, we have a binary classification problem here, and so we used the `classification()` method
    to specify the label index and number of labels.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们这里有一个二分类问题，因此我们使用了`classification()`方法来指定标签索引和标签数量。
- en: For some of the features in the dataset, you might observe huge differences
    in the feature value ranges. Some of the features have small numeric values, while
    some have very large numeric values. These large/small values can be interpreted
    in the wrong way by the neural network. Neural networks can falsely assign high/low
    priority to these features and that results in wrong or fluctuating predictions.
    In order to avoid this situation, we have to normalize the dataset before feeding
    it to the neural network. Hence we performed normalization as in step 9.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据集中的某些特征，你可能会观察到特征值范围之间的巨大差异。有些特征的数值较小，而有些特征的数值非常大。这些大/小数值可能会被神经网络误解。神经网络可能会错误地为这些特征分配高/低优先级，从而导致错误或波动的预测。为了避免这种情况，我们必须在将数据集输入到神经网络之前对其进行归一化。因此，我们在第9步中执行了归一化操作。
- en: In step 10, we used `DataSetIteratorSplitter` to split the main dataset for
    a training or test purpose.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10步中，我们使用`DataSetIteratorSplitter`将主数据集拆分用于训练或测试。
- en: 'The following are the parameters of `DataSetIteratorSplitter`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`DataSetIteratorSplitter`的参数：
- en: '`totalNoOfBatches`: If you specify a batch size of 10 for 10,000 records, then
    you need to specify 1,000 as the total number of batches.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`totalNoOfBatches`：如果你指定了10的批量大小并且有10,000条记录，那么需要指定1,000作为批次的总数。'
- en: '`ratio`: This is the ratio at which the splitter splits the iterator set. If
    you specify 0.8, then it means 80% of data will be used for training and the remaining
    20% will be used for testing/evaluation.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ratio`：这是分割器分割迭代器集的比例。如果你指定0.8，这意味着80%的数据将用于训练，剩余的20%将用于测试/评估。'
- en: Designing input layers for the neural network model
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为神经网络模型设计输入层
- en: Input layer design requires an understanding of how the data flows into the
    system. We have CSV data as input, and we need to inspect the features to decide
    on the input attributes. Layers are core components in neural network architecture.
    In this recipe, we will configure input layers for the neural network.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输入层设计需要理解数据如何流入系统。我们有CSV数据作为输入，需要检查特征来决定输入属性。层是神经网络架构的核心组件。在这个示例中，我们将为神经网络配置输入层。
- en: Getting ready
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We need to decide the number of input neurons before designing the input layer. It
    can be derived from the feature shape. For instance, we have 13 input features
    (excluding the label). But after applying the transformation, we have a total
    of 11 feature columns present in the dataset. Noise features are removed and categorical
    variables are transformed during the schema transformation. So, the final transformed
    data will have 11 input features. There are no specific requirements for outgoing
    neurons from the input layer. If we assign the wrong number of incoming neurons
    at the input layer, we may end up with a runtime error:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在设计输入层之前决定输入神经元的数量。它可以通过特征形状得出。例如，我们有13个输入特征（不包括标签）。但在应用变换后，我们的数据集总共有11个特征列。噪声特征被移除，类别变量在模式转换过程中被转化。因此，最终的转换数据将有11个输入特征。输入层的输出神经元没有特定要求。如果我们为输入层分配错误数量的输入神经元，可能会导致运行时错误：
- en: '![](img/c3ddc74c-a677-46b4-a5e1-c95d2beebdc4.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3ddc74c-a677-46b4-a5e1-c95d2beebdc4.png)'
- en: The DL4J error stack is pretty much self-explanatory as to the possible reason.
    It points out the exact layer where it needs a fix (`layer0`, in the preceding
    example).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: DL4J的错误堆栈几乎可以自解释可能的原因。它指明了需要修复的具体层（前面示例中的`layer0`）。
- en: How to do it...
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Define the neural network configuration using `MultiLayerConfiguration`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`MultiLayerConfiguration`定义神经网络配置：
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Define the input layer configuration using `DenseLayer`:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DenseLayer`定义输入层配置：
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We added layers to the network by calling the `layer()` method as mentioned
    in step 2\. Input layers are added using `DenseLayer`*. *Also, we need to add
    an activation function for the input layer. We specified the activation function
    by calling the `activation()` method. We discussed activation functions in [Chapter
    1](f88b350b-16e2-425b-8425-4631187c7803.xhtml), *Introduction to Deep Learning
    in Java*. You can use one of the available activation functions in DL4J to the `activation()` method.
    The most generic activation function used is `RELU`. Here are roles of other methods
    in layer design:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用`layer()`方法向网络中添加了层，如步骤2所述。输入层通过`DenseLayer`添加*。*此外，我们需要为输入层添加激活函数。我们通过调用`activation()`方法指定激活函数。我们在[第一章](f88b350b-16e2-425b-8425-4631187c7803.xhtml)中讨论了激活函数，*《Java深度学习简介》*。你可以使用DL4J中可用的激活函数之一来设置`activation()`方法。最常用的激活函数是`RELU`。以下是其他方法在层设计中的作用：
- en: '`nIn()`: This refers to the number of inputs for the layer. For an input layer,
    this is nothing but the number of input features.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nIn()`：这指的是该层的输入数量。对于输入层，它就是输入特征的数量。'
- en: '`nOut()`: This refers to number of outputs to next dense layer in neural network.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nOut()`：这指的是神经网络中到下一个全连接层的输出数量。'
- en: Designing hidden layers for the neural network model
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为神经网络模型设计隐藏层
- en: Hidden layers are the heart of a neural network. The actual decision process
    happens there. The design of the hidden layers is based on hitting a level beyond
    which a neural network cannot be optimized further. This level can be defined
    as the optimal number of hidden layers that produce optimal results.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏层是神经网络的核心。实际的决策过程发生在那里。隐藏层的设计是基于达到某个层次，超过这个层次，神经网络就无法再优化的水平。这个水平可以定义为产生最佳结果的最优隐藏层数量。
- en: Hidden layers are the place where the neural network transforms the inputs into
    a different format that the output layer can consume and use to make predictions.
    In this recipe, we will design hidden layers for a neural network.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏层是神经网络将输入转化为输出层能够使用并进行预测的不同格式的地方。在这个示例中，我们将为神经网络设计隐藏层。
- en: How to do it...
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Determine the incoming/outgoing connections. Set the following:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定输入/输出连接。设置如下：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Configure hidden layers using `DenseLayer`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DenseLayer`配置隐藏层：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: For step 1, if the neural network has only single hidden layer, then the number
    of neurons (inputs) in the hidden layer should be the same as the number of outgoing
    connections from the preceding layer. If you have multiple hidden layers, you
    will also need to confirm this for the preceding hidden layers.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步，如果神经网络只有一个隐藏层，那么隐藏层中的神经元（输入）的数量应该与前一层的输出连接数相同。如果你有多个隐藏层，你还需要确认前一层隐藏层的这一点。
- en: After you make sure that the number of input neurons are the same as number
    of the outgoing neurons in the preceding layer, you can create hidden layers using
    `DenseLayer`. In step 2, we used `DenseLayer` to create hidden layers for the input
    layers. In practice, we need to evaluate the model multiple times to understand
    the network performance. There's no constant layer configuration that works well
    for all the models. Also, `RELU` is the preferred activation function for hidden
    layers, due to its nonlinear nature.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在确保输入层的神经元数量与前一层的输出神经元数量相同后，你可以使用 `DenseLayer` 创建隐藏层。在第二步中，我们使用 `DenseLayer` 为输入层创建了隐藏层。实际上，我们需要多次评估模型，以了解网络的表现。没有一种常规的层配置适用于所有模型。同时，`RELU` 是隐藏层的首选激活函数，因为它具有非线性特性。
- en: Designing output layers for the neural network model
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为神经网络模型设计输出层
- en: Output layer design requires an understanding of the expected output. We have
    CSV data as input, and the output layer relies on the number of labels in the
    dataset. Output layers are the place where the actual prediction is formed based
    on the learning process that happened in the hidden layers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层设计需要理解期望的输出。我们的输入是CSV数据，输出层则依赖于数据集中的标签数量。输出层是根据隐藏层的学习过程形成实际预测的地方。
- en: In this recipe, we will design output layers for the neural network.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方案中，我们将为神经网络设计输出层。
- en: How to do it...
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Determine the incoming/outgoing connections. Set the following:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定输入/输出连接。设置以下内容：
- en: '[PRE21]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Configure the output layer for the neural network:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置神经网络的输出层：
- en: '[PRE22]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: For step 1, we need to make sure that `nOut()` for the preceding layer should
    have the same number of neurons as `nIn()` for the output layer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步，我们需要确保前一层的 `nOut()` 与输出层的 `nIn()` 拥有相同数量的神经元。
- en: So, `incomingConnectionCount` should be the same as `outgoingConnectionCount`
    from the preceding layer.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 所以， `incomingConnectionCount` 应该与前一层的 `outgoingConnectionCount` 相同。
- en: We discussed the `SOFTMAX` activation function earlier in [Chapter 1](f88b350b-16e2-425b-8425-4631187c7803.xhtml), *Introduction
    to Deep Learning in Java*. Our use case (customer churn) is an example for the
    binary classification model. We are looking for a probabilistic outcome, that
    is, the probability of a customer being labeled *happy* or *unhappy, *where `0`
    represents a happy customer and `1` represents an unhappy customer. This probability
    will be evaluated, and the neural network will train itself during the training
    process.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第一章](f88b350b-16e2-425b-8425-4631187c7803.xhtml)《*Java中的深度学习介绍*》中讨论过 `SOFTMAX` 激活函数。我们的使用案例（客户流失）是二分类模型的一个例子。我们希望得到一个概率性结果，也就是客户被标记为*开心*或*不开心*的概率，其中 `0` 代表开心的客户，`1` 代表不开心的客户。这个概率将被评估，神经网络将在训练过程中自我训练。
- en: The proper activation function at the output layer would be `SOFTMAX`. This
    is because we need the probability of the occurrence of labels and the probabilities
    should sum to 1\. `SOFTMAX` along with the log loss function produces good results
    for classification models. The introduction of `weightsArray` is to enforce a
    preference for a particular label among others in case of any data imbalance.
    In step 2, output layers are created using the `OutputLayer` class. The only difference
    is that `OutputLayer` expects an error function to calculate the error rate while
    making predictions. In our case, we used `LossMCXENT`, which is a multi-class
    cross entropy error function. Our customer churn example follows a binary classification
    model; however, we can still use this error function since we have two classes
    (labels) in our example. In step 2, `labelCount` would be 2.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层的适当激活函数是`SOFTMAX`。这是因为我们需要计算标签发生的概率，而这些概率的总和应该为1。`SOFTMAX`与对数损失函数一起，对于分类模型能够产生良好的结果。引入`weightsArray`是为了在数据不平衡的情况下强制优先选择某个标签。在步骤2中，输出层是通过`OutputLayer`类创建的。唯一的区别是，`OutputLayer`需要一个误差函数来计算预测时的错误率。在我们的例子中，我们使用了`LossMCXENT`，它是一个多类交叉熵误差函数。我们的客户流失示例遵循二分类模型；然而，由于我们的示例中有两个类（标签），因此仍然可以使用此误差函数。在步骤2中，`labelCount`将为2。
- en: Training and evaluating the neural network model for CSV data
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练并评估CSV数据的神经网络模型
- en: During the training process, the neural network learns to perform the expected
    task. For every iteration/epoch, the neural network will evaluate its training
    knowledge. Accordingly, it will re-iterate the layers with updated gradient values
    to minimize the error produced at the output layer. Also, note that labels (`0`
    and `1` ) are not uniformly distributed across the dataset. So, we might need
    to consider adding weights to the label that appears less in the dataset. This
    is highly recommended before we proceed with the actual training session. In this
    recipe, we will train the neural network and evaluate the resultant model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，神经网络学习执行预期任务。对于每次迭代/周期，神经网络都会评估其训练知识。因此，它会通过更新的梯度值重新迭代各个层，以最小化输出层产生的错误。此外，请注意，标签（`0`和`1`）在数据集中并不是均匀分布的。因此，我们可能需要考虑为在数据集中出现较少的标签添加权重。在实际的训练会话开始之前，强烈建议这样做。在这个例子中，我们将训练神经网络并评估结果模型。
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Create an array to assign weights to minor labels:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个数组为较少的标签分配权重：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Modify `OutPutLayer` to evenly balance the labels in the dataset:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`OutPutLayer`以均衡数据集中的标签：
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Initialize the neural network and add the training listeners:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化神经网络并添加训练监听器：
- en: '[PRE25]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Add the DL4J UI Maven dependency to analyze the training process:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加DL4J UI Maven依赖项以分析训练过程：
- en: '[PRE26]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Start the UI server and add temporary storage to store the model information:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动UI服务器并添加临时存储来存储模型信息：
- en: '[PRE27]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Replace `InMemoryStatsStorage` with `FileStatsStorage` (in case of memory restrictions):'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 用`FileStatsStorage`替换`InMemoryStatsStorage`（以应对内存限制）：
- en: '[PRE28]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Assign the temporary storage space to the UI server:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为UI服务器分配临时存储空间：
- en: '[PRE29]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Train the neural network by calling `fit()`:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`fit()`训练神经网络：
- en: '[PRE30]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Evaluate the model by calling `evaluate()`:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`evaluate()`来评估模型：
- en: '[PRE31]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works...
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: A neural network increases its efficiency when it improves its generalization
    power. A neural network should not just memorize a certain decision-making process
    in favor of a particular label. If it does, our outcomes will be biased and wrong.
    So, it is good to have a dataset where the labels are uniformly distributed. If
    they're not uniformly distributed, then we might have to adjust a few things while
    calculating the error rate. For this purpose, we introduced a `weightsArray` in
    step 1 and added to `OutputLayer` in step 2.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当神经网络提高其泛化能力时，它的效率会增加。神经网络不应该仅仅记住特定标签的决策过程。如果它这么做了，我们的结果将会有偏差并且是错误的。因此，最好使用标签均匀分布的数据集。如果标签不是均匀分布的，那么在计算错误率时我们可能需要调整一些东西。为此，我们在步骤1中引入了`weightsArray`，并在步骤2中将其添加到`OutputLayer`。
- en: For `weightsArray = {0.35, 0.65}`, the network gives more priority to the outcomes
    of `1` (customer unhappy). As we discussed earlier in this chapter, the `Exited` column
    represents the label. If we observe the dataset, it is evident that outcomes labeled `0` (customer
    happy) have more records in the dataset compared to `1`. Hence, we need to assign
    additional priority to `1` to evenly balance the dataset. Unless we do that, our
    neural network may over fit and will be biased toward the `1` label.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `weightsArray = {0.35, 0.65}`，网络更优先考虑 `1`（客户不满意）的结果。如本章前面讨论的，`Exited` 列代表标签。如果我们观察数据集，很明显标签为
    `0`（客户满意）的结果比 `1` 的记录更多。因此，我们需要给 `1` 分配额外的优先级，以便平衡数据集。否则，神经网络可能会过拟合，并且会偏向 `1`
    标签。
- en: In step 3, we added `ScoreIterationListener` to log the training process on
    the console. Note that `iterationCount` is the number of iterations in which it
    should log the network score. Remember, `iterationCount`is not the epoch. We say
    an epoch has happened when the entire dataset has traveled back and forth (backpropagation)
    once through the whole neural network.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 3 中，我们添加了 `ScoreIterationListener` 来记录训练过程的日志。请注意，`iterationCount` 是记录网络得分的迭代次数。记住，`iterationCount`
    不是**周期**。我们说一个周期已经完成，当整个数据集已经通过神经网络前后传递一次（反向传播）。
- en: 'In step 8, we used `dataSetIteratorSplitter` to obtain the training dataset
    iterator and trained our model on top of it. If you configured loggers properly,
    you should see the training instance is progressing as shown here:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 8 中，我们使用 `dataSetIteratorSplitter` 获取训练数据集的迭代器，并在其上训练我们的模型。如果你正确配置了日志记录器，你应该能够看到训练实例正在按以下方式进展：
- en: '![](img/5ecf204a-abe2-4e43-b91b-322a0cc52540.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ecf204a-abe2-4e43-b91b-322a0cc52540.png)'
- en: The score referred to in the screenshot is not the success rate; it is the error
    rate calculated by the error function for each iteration.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 截图中的得分并不是成功率，而是通过误差函数为每次迭代计算的误差率。
- en: 'We configured the DL4J **user interface** (**UI**) in step 4, 5, and 6. DL4J
    provides a UI to visualize the current network status and training progress in
    your browser (real-time monitoring). This will help further tuning the neural
    network training. `StatsListener` will be responsible for triggering the UI monitoring
    while the training starts. The port number for UI server is `9000`. While the
    training is in progress, hit the UI server at `localhost:9000`. We should be able
    to see something like the following:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在步骤 4、5 和 6 中配置了 DL4J **用户界面** (**UI**)。DL4J 提供了一个 UI，可以在浏览器中可视化当前网络状态和训练进度（实时监控）。这将有助于进一步调优神经网络的训练。`StatsListener`
    负责在训练开始时触发 UI 监控。UI 服务器的端口号为 `9000`。在训练进行时，可以访问 `localhost:9000` 以查看内容。我们应该能够看到如下内容：
- en: '![](img/17bebe0a-7847-4d9a-9bd1-2b548b788b06.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/17bebe0a-7847-4d9a-9bd1-2b548b788b06.png)'
- en: We can refer to the first graph seen in the Overview section for the Model Score analysis.
    The Iteration is plotted on the *x* axis, and the Model Score is on the *y *axis
    in the graph.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以参考**概览**部分中看到的第一张图来进行模型得分分析。图表中的 **x** 轴表示**迭代次数**，**y** 轴表示**模型得分**。
- en: 'We can also further expand our research on how the Activations, Gradients,
    and the Updates parameters performed during the training process by inspecting
    the parameter values plotted on graphs:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以进一步扩展研究，查看训练过程中**激活值**、**梯度**和**更新**参数的表现，可以通过检查图表中绘制的参数值来完成：
- en: '![](img/4c1035e0-e297-43a7-a888-ab4c9e8c935e.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4c1035e0-e297-43a7-a888-ab4c9e8c935e.png)'
- en: The *x* axis refers to the number of iterations in both the graphs. The *y* axis
    in the parameter update graph refers to the parameter update ratio, and the *y* axis
    in the activation/gradient graphs refers to the standard deviation.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中的 **x** 轴都表示迭代次数，**y** 轴在参数更新图表中表示参数更新比率，而在激活/梯度图表中则表示标准差。
- en: 'It is possible to have layer-wise analysis. We just need to click on the Model tab
    on the left sidebar and choose the layer of choice for further analysis:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以进行逐层分析。我们只需点击左侧边栏中的**模型**标签，并选择所需的层进行进一步分析：
- en: '![](img/77ed7dd4-5797-4cae-b87c-fd26f1bf72a2.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77ed7dd4-5797-4cae-b87c-fd26f1bf72a2.png)'
- en: 'For analysis of memory consumption and JVM, we can navigate to the System tab
    on the left sidebar:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 要分析内存消耗和 JVM 使用情况，我们可以在左侧边栏导航到**系统**标签：
- en: '![](img/5a7cc605-7c53-45af-8f80-4cb47ba58eec.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5a7cc605-7c53-45af-8f80-4cb47ba58eec.png)'
- en: 'We can also review the hardware/software metrics in detail at the same place:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以在同一位置详细查看硬件/软件的指标：
- en: '![](img/832323a4-3b9d-4ac1-bcdf-b02d2aaccb33.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/832323a4-3b9d-4ac1-bcdf-b02d2aaccb33.png)'
- en: This is very useful for benchmarking as well. As we can see, the memory consumption
    of the neural network is clearly marked and the JVM/off-heap memory consumption
    is mentioned in the UI to analyze how well the benchmarking is done.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于基准测试也非常有用。正如我们所见，神经网络的内存消耗被明确标出，JVM/堆外内存消耗也在UI中提到，以分析基准测试的执行情况。
- en: 'After step 8, evaluation results will be displayed on console:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 第8步后，评估结果将在控制台上显示：
- en: '![](img/67b76595-73b8-49a8-81b5-14b956783fda.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67b76595-73b8-49a8-81b5-14b956783fda.png)'
- en: In the above screenshot, the console shows various evaluation metrics by which
    the model is evaluated. We cannot rely on a specific metrics in all the cases;
    hence, it is good to evaluate the model against multiple metrics.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述截图中，控制台显示了评估模型的各种评估指标。我们不能在所有情况下仅依赖某一特定指标，因此，评估模型时最好考虑多个指标。
- en: Our model is showing an accuracy level of 85.75% at the moment. We have four
    different performance metrics, named accuracy, precision, recall, and F1 score.
    As you can see in the preceding screenshot, recall metrics are not so good, which
    means our model still has false negative cases. The F1 score is also significant
    here, since our dataset has an uneven proportion of output classes. We will not
    discuss these metrics in detail, since they are outside the scope of this book.
    Just remember that all these metrics are important for consideration, rather than
    just relying on accuracy alone. Of course, the evaluation trade-offs vary depending
    upon the problem. The current code has already been optimized. Hence, you will
    find almost stable accuracy from the evaluation metrics. For a well-trained network
    model, these performance metrics will have values close to `1`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型目前的准确率为85.75%。我们有四个不同的性能指标，分别是准确率、精确率、召回率和F1得分。正如你在前面的截图中看到的，召回率指标不太理想，这意味着我们的模型仍然有假阴性案例。F1得分在这里也很重要，因为我们的数据集具有不均衡的输出类别比例。我们不会详细讨论这些指标，因为它们超出了本书的范围。只要记住，所有这些指标都很重要，不能仅仅依赖准确率。当然，评估的权衡取决于具体问题。当前的代码已经经过优化，因此你会发现评估指标的准确率几乎稳定。对于一个训练良好的网络模型，这些性能指标的值将接近`1`。
- en: It is important to check how stable our evaluation metrics are. If we notice
    unstable evaluation metrics for unseen data, then we need to reconsider changes
    in the network configuration.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 检查我们评估指标的稳定性非常重要。如果我们注意到对于未见数据评估指标不稳定，那么我们需要重新考虑网络配置的变化。
- en: Activation functions on the output layer have influence on the stability of
    the outputs. Hence, a good understanding on output requirements will definitely
    save you a lot of time choosing an appropriate output function (loss function).
    We need to ensure stable predictive power from our neural network.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层的激活函数对输出的稳定性有影响。因此，充分理解输出要求肯定会在选择合适的输出函数（损失函数）时节省大量时间。我们需要确保神经网络具有稳定的预测能力。
- en: There's more...
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: Learning rate is one of the factors that decides the efficiency of the neural
    network. A high learning rate will diverge from the actual output, while a low
    learning rate will result in slow learning due to slow convergence. Neural network
    efficiency also depends on the weights that we assign to the neurons in every
    layer. Hence, a uniform distribution of weights during the early stages of training
    might help.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是决定神经网络效率的因素之一。高学习率会使输出偏离实际值，而低学习率则会导致由于收敛慢而学习过程缓慢。神经网络的效率还取决于我们在每一层中分配给神经元的权重。因此，在训练的早期阶段，权重的均匀分布可能会有所帮助。
- en: The most commonly followed approach is to introduce dropouts to the layers.
    This forces the neural network to ignore some of the neurons during the training
    process. This will effectively prevent the neural network from memorizing the
    prediction process. How do we find out if a network has memorized the results?
    Well, we just need to expose the network to new data. If your accuracy metrics
    become worse after that, then you've got a case of overfitting.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的方法是向各层引入丢弃法（dropout）。这迫使神经网络在训练过程中忽略一些神经元。这将有效防止神经网络记住预测过程。那么，如何判断一个网络是否记住了结果呢？其实，我们只需要将网络暴露于新数据。如果准确率指标变差，那么说明你遇到了过拟合问题。
- en: Another possibility for increasing the efficiency of the neural network (and
    thus reducing overfitting) is to try for L1/L2 regularization in the network layers.
    When we add L1/L2 regularization to network layers, it will add an extra penalty
    term to the error function. L1 penalizes with the sum of the absolute value of
    the weights in the neurons, while L2 penalizes using the sum of squares of the
    weights. L2 regularization will give much better predictions when the output variable
    is a function of all input features. However, L1 regularization is preferred when
    the dataset has outliers and if not all the attributes are contributing to predicting
    the output variable. In most cases, the major reason for overfitting is the issue
    of memorization. Also, if we drop too many neurons, it will eventually underfit
    the data. This means we lose more useful data than we need to.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 提高神经网络效率（从而减少过拟合）另一种可能性是尝试在网络层中使用L1/L2正则化。当我们向网络层添加L1/L2正则化时，它会在误差函数中增加一个额外的惩罚项。L1正则化通过惩罚神经元权重的绝对值之和，而L2正则化通过惩罚权重的平方和来实现。当输出变量是所有输入特征的函数时，L2正则化能给出更好的预测。然而，当数据集存在离群点，并且并非所有特征都对预测输出变量有贡献时，L1正则化更为优先。在大多数情况下，过拟合的主要原因是记忆化问题。此外，如果我们丢弃了过多的神经元，最终会导致欠拟合。这意味着我们丢失了比必要的更多有用数据。
- en: Note that the trade-off can vary depending on the different kinds of problems.
    Accuracy alone cannot ensure a good model performance every time. It is good to
    measure precision if we cannot afford the cost of a false positive prediction
    (such as in spam email detection). It is good to measure recall if we cannot afford
    the cost of a false negative prediction (such as in fraudulent transaction detection).
    The F1 score is optimal if there's an uneven distribution of the classes in the
    dataset. ROC curves are good to measure when there are approximately equal numbers
    of observations for each output class.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，权衡取舍可能会根据不同问题类型有所不同。仅靠准确度并不能确保每次都能得到良好的模型表现。如果我们不能承受假阳性预测的成本（例如垃圾邮件检测），则应评估精确度。如果我们不能承受假阴性预测的成本（例如欺诈交易检测），则应评估召回率。如果数据集中的类别分布不均，F1分数是最优的。ROC曲线适用于每个输出类别的观测值数量大致相等的情况。
- en: Once the evaluations are stable, we can check on the means to optimize the efficiency
    of the neural network. There are multiple methods to choose from. We can perform
    several training sessions to try to find out the optimal number of hidden layers,
    epochs, dropouts, and activation functions.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦评估稳定，我们可以检查如何优化神经网络的效率。有多种方法可以选择。我们可以进行几次训练会话，尝试找出最优的隐藏层数量、训练轮数、丢弃率和激活函数。
- en: 'The following screenshot points to various hyper parameters that can influence
    neural network efficiency:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图指向了可能影响神经网络效率的各种超参数：
- en: '![](img/7069f9da-c4bb-47a3-a704-6266367bfe9b.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7069f9da-c4bb-47a3-a704-6266367bfe9b.png)'
- en: Note that `dropOut(0.9)` means we ignore 10% of neurons during training.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`dropOut(0.9)`意味着我们在训练过程中忽略10%的神经元。
- en: 'Other attributes/methods in the screenshot are the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 截图中的其他属性/方法如下：
- en: '`weightInit()` : This is to specify how the weights are assigned neurons at
    each layer.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weightInit()`：用于指定如何为每一层的神经元分配权重。'
- en: '`updater()`: This is to specify the gradient updater configuration. `Adam`
    is a gradient update algorithm.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`updater()`：用于指定梯度更新器配置。`Adam`是一种梯度更新算法。'
- en: In [Chapter 12](0db31248-e40b-4479-9939-0baccb0e11d1.xhtml), *Benchmarking and
    Neural Network Optimization*, we will walk through an example of hyperparameter
    optimization to automatically find the optimal parameters for you. It simply performs
    multiple training sessions on our behalf to find the optimal values by a single
    program execution. You may refer to [Chapter 12](0db31248-e40b-4479-9939-0baccb0e11d1.xhtml), *Benchmarking
    and Neural Network Optimization,* if you're interested in applying benchmarks
    to the application.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第12章](0db31248-e40b-4479-9939-0baccb0e11d1.xhtml)，*基准测试与神经网络优化*中，我们将通过一个超参数优化的示例，自动为你找到最优参数。它仅通过一次程序执行，就代表我们进行了多次训练会话，以找到最优值。如果你对将基准测试应用到实际应用中感兴趣，可以参考[第12章](0db31248-e40b-4479-9939-0baccb0e11d1.xhtml)，*基准测试与神经网络优化*。
- en: Deploying the neural network model and using it as an API
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署神经网络模型并将其用作API
- en: After the training instance, we should be able to persist the model and then
    reuse its capabilities as an API. API access to the customer churn model will
    enable an external application to predict the customer retention. We will use
    Spring Boot, along with Thymeleaf, for the UI demonstration. We will deploy and
    run the application locally for the demonstration. In this recipe, we will create
    an API for a customer churn example.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练实例完成后，我们应该能够持久化模型，并且将其作为API重用。通过API访问客户流失模型，将允许外部应用程序预测客户保持率。我们将使用Spring
    Boot和Thymeleaf进行UI演示，并将应用程序本地部署和运行。在本教程中，我们将为客户流失示例创建一个API。
- en: Getting ready
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'As a prerequisite for API creation, you need to run the main example source
    code:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 作为创建API的前提条件，您需要运行主要的示例源代码：
- en: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java)'
- en: 'DL4J has a utility class called `ModelSerializer` to save and restore models. We
    have used **`ModelSerializer`** to persist the model to disk, as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: DL4J有一个名为`ModelSerializer`的工具类，用于保存和恢复模型。我们已经使用**`ModelSerializer`**将模型持久化到磁盘，具体如下：
- en: '[PRE32]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'For more information, refer to:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请参阅：
- en: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java#L124](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java#L124).'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java#L124](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java#L124)。'
- en: Also, note that we need to persist the normalizer preprocessor along with the
    model. Then we can reuse the same to normalize user inputs on the go. In the previously
    mentioned code, we persisted the normalizer by calling `addNormalizerToModel()`
    from `ModelSerializer`.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意，我们需要将归一化预处理器与模型一起持久化。然后，我们可以在运行时重新使用该归一化器来规范化用户输入。在前面提到的代码中，我们通过调用`addNormalizerToModel()`从`ModelSerializer`持久化了归一化器。
- en: 'You also need to be aware of the following input attributes to the `addNormalizerToModel()` method:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要注意`addNormalizerToModel()`方法的以下输入属性：
- en: '`multiLayerNetwork`: The model that the neural network was trained on'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multiLayerNetwork`：神经网络训练所使用的模型'
- en: '`dataNormalization`: The normalizer that we used for our training'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataNormalization`：我们用于训练的归一化器'
- en: 'Please refer to the following example for a concrete API implementation:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下示例来实现具体的API：
- en: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java)'
- en: In our API example, we restore the model file (model that was persisted before)
    to generate predictions.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的API示例中，我们恢复了模型文件（即之前持久化的模型），以生成预测。
- en: How to do it...
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create a method to generate a schema for the user input:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个方法，用于生成用户输入的架构：
- en: '[PRE33]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Create a `TransformProcess` from the schema:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从模式中创建`TransformProcess`：
- en: '[PRE34]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Load the data into a record reader instance:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据加载到记录读取器实例中：
- en: '[PRE35]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Restore the model using `ModelSerializer`:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ModelSerializer`恢复模型：
- en: '[PRE36]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create an iterator to traverse through the entire set of input records:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个迭代器来遍历整个输入记录集：
- en: '[PRE37]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Design an API function to generate output from user input:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计一个API函数来根据用户输入生成输出：
- en: '[PRE38]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: For a further example, see: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java ](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java)
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 更多示例，请见：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/api/CustomerRetentionPredictionApi.java)
- en: 'Build a shaded JAR of your DL4J API project by running the Maven command:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行Maven命令构建一个包含你DL4J API项目的阴影JAR：
- en: '[PRE39]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Run the Spring Boot project included in the source directory. Import the Maven
    project to your IDE: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/tree/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/tree/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j).
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行源目录中包含的Spring Boot项目。将Maven项目导入到你的IDE中：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/tree/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/tree/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j)。
- en: 'Add the following VM options in under run configurations:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行配置中添加以下VM选项：
- en: '[PRE40]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`PATH-TO-MODEL-FILE` is the location where you stored the actual model file.
    It can be on your local disk or in a cloud as well.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`PATH-TO-MODEL-FILE`是你存储实际模型文件的位置。它可以在本地磁盘或云端。'
- en: 'Then, run the `SpringDl4jApplication.java` file:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行`SpringDl4jApplication.java`文件：
- en: '![](img/6b90ef87-fda2-44ee-a975-7dfe1effeb85.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b90ef87-fda2-44ee-a975-7dfe1effeb85.png)'
- en: 'Test your Spring Boot app at `http://localhost:8080/`:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`http://localhost:8080/`上测试你的Spring Boot应用：
- en: '![](img/48d532f3-0671-4d86-b898-2595035b3407.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48d532f3-0671-4d86-b898-2595035b3407.png)'
- en: Verify the functionality by uploading an input CSV file.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过上传输入的CSV文件来验证功能。
- en: Use a sample CSV file to upload into the web application: **[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/resources/test.csv](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/resources/test.csv).**
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个示例CSV文件上传到Web应用：**[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/resources/test.csv](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/resources/test.csv)。**
- en: 'The prediction results will be displayed as shown here:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果将如下所示：
- en: '![](img/0ebc2020-8ab6-4743-baab-b22d16011c10.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ebc2020-8ab6-4743-baab-b22d16011c10.png)'
- en: How it works...
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We need to create an API to take the inputs from end users and generate the
    output. The end user will upload a CSV file with the inputs, and API returns the
    prediction output back to the user.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个API来接收终端用户的输入并生成输出。终端用户将上传一个包含输入的CSV文件，API则将预测结果返回给用户。
- en: In step 1, we added schema for the input data. User input should follow the
    schema structure in which we trained the model except that the `Exited` label
    is not added because that is the expected task for the trained model. In step
    2, we have created `TransformProcess` from `Schema` that was created in step 1.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1步中，我们为输入数据添加了模式。用户输入应该遵循我们训练模型时的模式结构，唯一的区别是`Exited`标签没有添加，因为那是训练模型需要预测的任务。在第2步中，我们根据第1步创建的`Schema`创建了`TransformProcess`。
- en: In step 3, we used `TransformProcess` from step 2 to create a record reader
    instance. This is to load the data from the dataset.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3步中，我们使用第2步中的`TransformProcess`创建了一个记录读取器实例。这样可以从数据集中加载数据。
- en: We expect the end users to upload batches of inputs to generate outcomes. So,
    an iterator needs to be created as per step 5 to traverse through the entire set
    of input records. We set the preprocessor for the iterator using the pretrained
    model from step 4\. Also, we used a `batchSize` value of `1`. If you have more
    input samples, you can specify a reasonable batch size.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预计最终用户会上传批量输入以生成结果。因此，需要按照第5步创建一个迭代器，以遍历所有输入记录集。我们使用第4步中的预训练模型来设置迭代器的预处理器。另外，我们使用了`batchSize`值为`1`。如果你有更多的输入样本，可以指定一个合理的批量大小。
- en: In step 6, we used a file path named `modelFilePath` to represent the model
    file location. We pass this as a command-line argument from the Spring application.
    Thereby you can configure your own custom path where the model file is persisted. After
    step 7, a shaded JAR with all DL4J dependencies will be created and saved in the
    local Maven repository. You can also view the JAR file in the project target repository.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在第6步中，我们使用名为`modelFilePath`的文件路径来表示模型文件的位置。我们将其作为命令行参数从Spring应用程序中传递。这样，你可以配置你自己的自定义路径，以保存模型文件。在第7步之后，将创建一个带阴影的JAR文件，包含所有DL4J依赖项，并保存在本地Maven仓库中。你也可以在项目的目标仓库中查看该JAR文件。
- en: 'Dependencies of customer retention API are added to the `pom.xml` file of the
    Spring Boot project, as shown here:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 客户留存API的依赖项已经添加到Spring Boot项目的`pom.xml`文件中，如下所示：
- en: '[PRE41]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Once you have created a shaded JAR for the API by following step 7, the Spring
    Boot project will be able to fetch the dependencies from your local repository.
    So, you need to build the API project first before importing the Spring Boot project.
    Also, make sure to add the model file path as a VM argument, as mentioned in step
    8.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦按照第7步创建了带阴影的JAR文件，Spring Boot项目将能够从本地仓库获取依赖项。因此，在导入Spring Boot项目之前，你需要先构建API项目。同时，确保像第8步中提到的那样，将模型文件路径添加为VM参数。
- en: 'In a nutshell, these are the steps required to run the use case:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，运行用例所需的步骤如下：
- en: 'Import and build the Customer Churn API project: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/)'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入并构建客户流失API项目：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/)
- en: Run the main example to train the model and persist the model file: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java)
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行主示例以训练模型并保存模型文件：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/src/main/java/com/javadeeplearningcookbook/examples/CustomerRetentionPredictionExample.java)
- en: Build the customer churn API project: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/tree/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp)
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建客户流失API项目：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp/.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/tree/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/cookbookapp)
- en: Run the Spring Boot project by running the Starter here (with the earlier mentioned
    VM arguments): [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j/src/main/java/com/springdl4j/springdl4j/SpringDl4jApplication.java.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j/src/main/java/com/springdl4j/springdl4j/SpringDl4jApplication.java)
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行此处的启动器来运行 Spring Boot 项目（使用之前提到的 VM 参数）：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j/src/main/java/com/springdl4j/springdl4j/SpringDl4jApplication.java.](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/03_Building_Deep_Neural_Networks_for_Binary_classification/sourceCode/spring-dl4j/src/main/java/com/springdl4j/springdl4j/SpringDl4jApplication.java)
