- en: '*Chapter 8*: Leveraging NLP to Monetize Your Media Content'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：利用自然语言处理（NLP）赚取您的媒体内容'
- en: As we have seen in this book so far, AI, and specifically NLP, has a wide range
    of uses in areas hitherto considered traditional IT spurred on by the rapid proliferation
    of data and the democratization of **machine learning** (**ML**) with cloud computing.
    In the previous chapter, we saw a cool example of how you can bring color to social
    media reviews and other forms of textual data by running voice of the customer
    analytics with sentiment detection. We saw how you can use AWS Glue to crawl raw
    data from Amazon S3, use Amazon Athena to interactively query this data, transform
    the raw data using PySpark ([http://spark.apache.org/docs/latest/api/python/index.html](http://spark.apache.org/docs/latest/api/python/index.html))
    in an AWS Glue job to call Amazon Comprehend APIs (which provide ready-made intelligence
    with pre-trained NLP models) to get sentiment analysis on the review, convert
    the data into Parquet, and partition it ([https://docs.aws.amazon.com/athena/latest/ug/partitions.html](https://docs.aws.amazon.com/athena/latest/ug/partitions.html))
    by sentiment to optimize analytics queries. In this chapter, we will change gears
    and look at a use case that has gained tremendous popularity in recent times due
    to the increased adoption of streaming media content, specifically how to monetize
    content.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本书中所见，人工智能（AI），特别是NLP，由于数据的快速增长和云计算下机器学习（ML）的民主化，已经在传统IT领域有了广泛的应用。在上一章中，我们看到了一个很酷的例子，通过运行客户语音分析和情感检测，可以为社交媒体评论和其他形式的文本数据增添色彩。我们看到如何使用AWS
    Glue从Amazon S3中抓取原始数据，使用Amazon Athena交互式查询这些数据，使用PySpark（[http://spark.apache.org/docs/latest/api/python/index.html](http://spark.apache.org/docs/latest/api/python/index.html)）在AWS
    Glue作业中转换原始数据，调用Amazon Comprehend API（提供预训练的NLP模型）对评论进行情感分析，将数据转换为Parquet格式，并按情感分区（[https://docs.aws.amazon.com/athena/latest/ug/partitions.html](https://docs.aws.amazon.com/athena/latest/ug/partitions.html)）以优化分析查询。在本章中，我们将转向关注一个因流媒体内容的广泛采用而在近年来广受欢迎的用例，具体来说是如何赚取内容。
- en: The gap between online advertising and print media advertising is ever widening.
    According to this article, [https://www.marketingcharts.com/advertising-trends-114887](https://www.marketingcharts.com/advertising-trends-114887),
    quoting a PwC outlook report on global entertainment and media ([https://www.pwc.com/outlook](https://www.pwc.com/outlook)),
    online advertising spend was estimated to be approximately $58 billion higher
    than TV advertising, and $100 billion higher than magazine and newspaper advertising
    in 2020 even with the COVID-19 pandemic considered.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 线上广告和平面媒体广告之间的差距越来越大。根据这篇文章，引用了PwC关于全球娱乐和媒体的展望报告（[https://www.pwc.com/outlook](https://www.pwc.com/outlook)），即使考虑到COVID-19大流行，线上广告支出在2020年估计比电视广告高出约580亿美元，比杂志和报纸广告高出1000亿美元。
- en: 'This, of course, is also driven by the increased usage of smart consumer devices
    and the explosion of the internet age consumer trends. Google Ads is one of the
    most popular ad-serving platforms today, accounting for 80% of Alphabet''s (the
    public holding company that owns Google) revenues, raking in $147 billion in 2020
    according to this article: [https://www.cnbc.com/2021/05/18/how-does-google-make-money-advertising-business-breakdown-.html](https://www.cnbc.com/2021/05/18/how-does-google-make-money-advertising-business-breakdown-.html).
    You read that right: online advertisements are indeed a big deal. So, when you
    are next thinking of posting that cool travel video or your recipe for an awesome
    chili con carne, you could actually be making money out of your content. You may
    ask, this is all great but how does NLP help in this case? Read on to find out!'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这也受智能消费设备的增加和互联网时代消费趋势爆炸性增长的推动。谷歌广告是今天最流行的广告发布平台之一，占据了Alphabet（拥有谷歌的上市控股公司）80%的收入，根据这篇文章在2020年赚取了1470亿美元：[https://www.cnbc.com/2021/05/18/how-does-google-make-money-advertising-business-breakdown-.html](https://www.cnbc.com/2021/05/18/how-does-google-make-money-advertising-business-breakdown-.html)。没错，你没看错：在线广告确实是一件大事。因此，当您考虑下一次发布那个很酷的旅行视频或您制作绝佳辣椒肉酱的食谱时，实际上您可能会从您的内容中赚钱。你可能会问，这一切很棒，但NLP在这种情况下如何帮助？继续阅读了解更多！
- en: 'The answer, as you probably already guessed, is context-based ad serving. Suppose
    you have an intelligent solution that could listen to the audio/text in your content,
    understand what is being discussed, identify topics that represent the context
    of the content, look up ads related to the topic, and stitch these ads back into
    your content seamlessly without having to train any ML models: wouldn''t that
    be swell? Yes, that''s exactly what we will be building now.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 答案，正如你可能已经猜到的，是基于上下文的广告投放。假设你有一个智能解决方案，可以监听内容中的音频/文本，理解讨论的内容，识别代表内容上下文的主题，查找与这些主题相关的广告，并将这些广告无缝地插入到你的内容中，而无需训练任何机器学习模型：那岂不是太棒了吗？是的，这正是我们现在要构建的内容。
- en: 'We will navigate through the following sections:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将浏览以下几个部分：
- en: Introducing the content monetization use case
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍内容变现用例
- en: Building the NLP solution for content monetization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建内容变现的NLP解决方案
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need access to an AWS account. Please make sure to
    follow the instructions specified in the *Technical requirements* section in [*Chapter
    2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing Amazon Textract*,
    to create your AWS account, and log in to the AWS Management Console before trying
    the steps in the *Building the NLP solution for content monetization* section.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章内容，您需要拥有一个AWS账户。请确保按照[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中*技术要求*部分的说明创建AWS账户，并在尝试*构建内容变现NLP解决方案*部分的步骤之前，登录AWS管理控制台。
- en: 'The Python code and sample datasets for our solution can be found here: [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2008](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2008).
    Please use the instructions in the following sections along with the code in the
    repository to build the solution.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决方案的Python代码和示例数据集可以在此处找到：[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2008](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2008)。请按照以下部分的说明以及代码库中的代码构建解决方案。
- en: Check out the following video to see the Code in Action at [https://bit.ly/317mcSh](https://bit.ly/317mcSh).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，观看代码的实际应用：[https://bit.ly/317mcSh](https://bit.ly/317mcSh)。
- en: Introducing the content monetization use case
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍内容变现用例
- en: We know NLP can help enhance the customer service experience and understand
    better what our customers are telling us. We will now use NLP to determine the
    context of our media content and stitch ads into the content relevant to that
    context. To illustrate our example, let's go back to our fictitious banking corporation
    called **LiveRight Holdings Private Limited**. LiveRight's management has decided
    they now need to expand to more geographies as they are seeing a lot of demand
    for their model of no-frills banking that cuts their operational costs and transfers
    the savings back to their customers. They have decided to hire you as their marketing
    technology architect, putting you in charge of all their content creation, but
    challenge you to devise a way for the content to pay for itself due to their low-cost
    policies. You come up with the idea of creating fun educational videos that show
    the latest trends in the intersection of banking and technology. There is a lot
    of demand for such videos since they are free to watch, you can intersperse them
    with ads to get monetary returns, and they serve to raise awareness of the bank
    in the process.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道NLP可以帮助提升客户服务体验，更好地理解客户的需求。现在，我们将使用NLP来确定媒体内容的上下文，并将相关广告无缝地插入到该内容中。为了说明我们的例子，让我们回到我们虚构的银行公司**LiveRight
    Holdings Private Limited**。LiveRight的管理层决定，他们现在需要扩展到更多的地区，因为他们看到对无繁琐银行服务模式的需求很大，这种模式通过减少运营成本将节省下来的资金转移给客户。他们决定聘请你作为他们的营销技术架构师，负责所有内容创作，同时挑战你找到一种方式让这些内容通过其低成本政策实现自我盈利。你提出了创建有趣的教育视频的想法，这些视频展示了银行与技术交汇的最新趋势。由于这些视频可以免费观看，你可以在其中穿插广告以获得收入，同时它们还能提高银行的知名度，因此有很大的需求。
- en: 'You have thought through the solution design and decide to use the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经思考过解决方案设计，并决定使用以下内容：
- en: '**AWS Elemental MediaConvert** ([https://aws.amazon.com/mediaconvert/](https://aws.amazon.com/mediaconvert/)),
    a managed video transcoding service that can convert and enhance your video content
    to multiple versions for broadcasting'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Elemental MediaConvert** ([https://aws.amazon.com/mediaconvert/](https://aws.amazon.com/mediaconvert/))，一种托管的视频转码服务，可以将您的视频内容转换并增强为多个广播版本。'
- en: '**Amazon Transcribe** ([https://aws.amazon.com/transcribe/](https://aws.amazon.com/transcribe/))
    to get a transcript of the video content'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Transcribe** ([https://aws.amazon.com/transcribe/](https://aws.amazon.com/transcribe/))
    用来获取视频内容的转录文本。'
- en: '**Amazon Comprehend** ([https://aws.amazon.com/comprehend/](https://aws.amazon.com/comprehend/))
    to leverage its pre-trained ML model for topic modeling to determine common themes
    in the textual content of the video that will, in turn, drive the ad selection
    process'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Comprehend** ([https://aws.amazon.com/comprehend/](https://aws.amazon.com/comprehend/))
    用来利用其预训练的机器学习模型进行主题建模，从视频的文本内容中确定常见主题，这些主题将推动广告选择过程。'
- en: '**AWS Elemental MediaTailor** ([https://aws.amazon.com/mediatailor/](https://aws.amazon.com/mediatailor/)),
    a managed service that can take as input media content, assemble this into an
    online channel delivery, and stitch ads onto the video content'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Elemental MediaTailor** ([https://aws.amazon.com/mediatailor/](https://aws.amazon.com/mediatailor/))，一种托管服务，可以接受媒体内容作为输入，将其组装成在线频道交付，并将广告插入到视频内容中。'
- en: 'The components of the solution we will build are as shown in the following
    figure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建的解决方案的组件如下图所示：
- en: '![Figure 8.1 – NLP solution build for content monetization](img/B17528_08_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 内容货币化的 NLP 解决方案构建](img/B17528_08_01.jpg)'
- en: Figure 8.1 – NLP solution build for content monetization
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 内容货币化的 NLP 解决方案构建
- en: We will be walking through this solution using the AWS Management Console ([https://aws.amazon.com/console/](https://aws.amazon.com/console/))
    and an Amazon SageMaker Jupyter notebook ([https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html)),
    which will allow us to review the code and results as we execute it step by step.
    If you do not have access to the AWS Management Console, please follow the detailed
    instructions in the *Technical requirements* section in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract,* of this book.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过 AWS 管理控制台 ([https://aws.amazon.com/console/](https://aws.amazon.com/console/))
    和 Amazon SageMaker Jupyter 笔记本 ([https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html))
    演示此解决方案，这将使我们能够在逐步执行时查看代码和结果。如果您没有访问 AWS 管理控制台的权限，请遵循本书中[*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)《介绍
    Amazon Textract》部分中的*技术要求*部分的详细说明。
- en: 'As a first step, we will look at the sample video file provided in the GitHub
    repository ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4)).
    The sample video is from a demonstration of AWS AI services for document processing.
    For a full version of this video, please refer to [https://www.youtube.com/watch?v=vBtxjXjr_HA](https://www.youtube.com/watch?v=vBtxjXjr_HA).
    We will upload this sample video to an S3 bucket:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们将查看 GitHub 仓库中提供的示例视频文件 ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4))。示例视频展示了
    AWS AI 服务在文档处理中的应用。有关该视频的完整版本，请参考 [https://www.youtube.com/watch?v=vBtxjXjr_HA](https://www.youtube.com/watch?v=vBtxjXjr_HA)。我们将把这个示例视频上传到
    S3 存储桶：
- en: After the video is loaded to the S3 bucket, we will use AWS Elemental MediaConvert
    to create the broadcast versions of our sample video content.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在视频加载到 S3 存储桶后，我们将使用 AWS Elemental MediaConvert 创建我们示例视频内容的广播版本。
- en: In parallel, we will open our Amazon SageMaker Jupyter notebook to run the code
    to create an Amazon Transcribe transcription job to convert the audio track from
    our sample video to text.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同时，我们将打开我们的 Amazon SageMaker Jupyter 笔记本来运行代码，创建一个 Amazon Transcribe 转录任务，将我们示例视频的音频轨道转换为文本。
- en: We will use Amazon Comprehend Topic Modeling to detect the topics from this
    text.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 Amazon Comprehend 主题建模来检测此文本中的主题。
- en: We will then use the sample URL from the `'cmsid'` and a video content ID referred
    by the tag `'vid'`, which we will populate to stitch in the ads specific to the
    topic we detected from the transcribed text in the previous step
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将使用来自 `'cmsid'` 的样本 URL 和由标签 `'vid'` 引用的视频内容 ID，这些内容将被填充以在前一步中从转录文本中检测到的主题特定广告。
- en: We will then create an Amazon CloudFront distribution for the output video files
    from the AWS Elemental MediaConvert job.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将为 AWS Elemental MediaConvert 作业的输出视频文件创建一个 Amazon CloudFront 分发。
- en: Finally, we will use **AWS Elemental MediaTailor** to create a new configuration
    for broadcast-grade streaming content, which will take our MediaConvert output
    files available via the CloudFront distribution and the ad decision server URL
    we modified in the previous step to create a new video file with the ads inserted.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将使用 **AWS Elemental MediaTailor** 创建一个新的配置，用于广播级流媒体内容，该配置将利用 CloudFront
    分发提供的 MediaConvert 输出文件以及我们在上一步中修改的广告决策服务器 URL 来创建一个新的插入广告的视频文件。
- en: In this section, we introduced the content monetization requirement we are trying
    to build with our NLP solution, reviewed the challenges faced by LiveRight, and
    looked at an overview of the solution we will build. In the next section, we will
    walk through the building of a solution step by step.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了我们试图构建的 NLP 解决方案中引入的内容货币化需求，审视了 LiveRight 面临的挑战，并查看了我们将构建的解决方案概述。在下一节中，我们将逐步介绍构建解决方案的过程。
- en: Building the NLP solution for content monetization
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为内容货币化构建 NLP 解决方案
- en: In the previous section, we introduced a requirement for content monetization,
    covered the architecture of the solution we will be building, and briefly walked
    through the solution components and workflow steps. In this section, we will start
    executing the tasks to build our solution. But first, there are prerequisites
    we will have to take care of.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们介绍了内容货币化的需求，涵盖了我们将构建的解决方案的架构，并简要地介绍了解决方案组件和工作流步骤。在本节中，我们将开始执行构建解决方案的任务。但首先，我们需要处理一些先决条件。
- en: Setting up to solve the use case
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置以解决使用案例
- en: 'If you have not done so in the previous chapters, you will as a prerequisite
    have to create an Amazon SageMaker Jupyter notebook instance and set up **Identity
    and Access Management** (**IAM**) permissions for that notebook role to access
    the AWS services we will use in this notebook. After that, you will need to clone
    the GitHub repository ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services)),
    create an Amazon S3 ([https://aws.amazon.com/s3/](https://aws.amazon.com/s3/))
    bucket, and provide the bucket name in the notebook to start execution. Please
    follow the next steps to complete these tasks before we can execute the cells
    from our notebook:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在之前的章节中尚未完成此操作，您需要先创建一个 Amazon SageMaker Jupyter 笔记本实例，并为该笔记本角色设置**身份和访问管理**（**IAM**）权限，以便访问我们在本笔记本中将使用的
    AWS 服务。之后，您需要克隆 GitHub 仓库（[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services)），创建一个
    Amazon S3（[https://aws.amazon.com/s3/](https://aws.amazon.com/s3/)）存储桶，并在笔记本中提供存储桶名称以开始执行。请按照接下来的步骤完成这些任务，然后我们可以执行笔记本中的代码单元格：
- en: Note
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please ensure you have completed the tasks mentioned in the *Technical requirements*
    section. If you have already created an Amazon SageMaker notebook instance and
    cloned the GitHub repository for the book in a previous chapter, you can skip
    some of these steps. Please go directly to the step where you open the notebook
    folder corresponding to this chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保您已完成 *技术要求* 部分中提到的任务。如果您已经在之前的章节中创建了 Amazon SageMaker 笔记本实例并克隆了书籍的 GitHub
    仓库，您可以跳过其中一些步骤。请直接转到打开与本章对应的笔记本文件夹的步骤。
- en: If not already done, follow the instructions documented in the *Creating an
    Amazon SageMaker Jupyter notebook instance* section in the *Setting up your AWS
    environment* section in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract,* to create your Jupyter notebook instance.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未完成，请按照 *创建 Amazon SageMaker Jupyter 笔记本实例* 部分中 *设置 AWS 环境* 部分中的[*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中记录的说明操作。介绍
    Amazon Textract 来创建您的 Jupyter 笔记本实例。
- en: IAM role permissions while creating Amazon SageMaker Jupyter notebooks
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建 Amazon SageMaker Jupyter 笔记本实例时的 IAM 角色权限
- en: Accept the default option for the IAM role at notebook creation time to allow
    access to any S3 bucket.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在创建 notebook 时，接受默认的 IAM 角色选项以允许访问任何 S3 桶。
- en: Once you create the notebook instance and its status is **InService**, click
    on **Open Jupyter** in the **Actions** menu for the notebook instance.![Figure
    8.2 – Opening the Jupyter notebook
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你创建了 notebook 实例，并且其状态为 **InService**，请点击 notebook 实例中的 **操作** 菜单下的 **打开 Jupyter**。![图
    8.2 – 打开 Jupyter notebook
- en: '](img/B17528_08_02.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_02.jpg)'
- en: Figure 8.2 – Opening the Jupyter notebook
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.2 – 打开 Jupyter notebook
- en: This will take you to the home folder of your notebook instance.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将带你进入 notebook 实例的主文件夹。
- en: Click on **New** as shown in the following figure and select **Terminal**:![Figure
    8.3 – Opening the terminal in the Jupyter notebook](img/B17528_08_03.jpg)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下图所示，点击 **新建** 并选择 **终端**：![图 8.3 – 在 Jupyter notebook 中打开终端](img/B17528_08_03.jpg)
- en: Figure 8.3 – Opening the terminal in the Jupyter notebook
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.3 – 在 Jupyter notebook 中打开终端
- en: In the terminal window, first type `cd SageMaker` and then type `git clone`
    [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services),
    as shown in the following screenshot. If you have already done this in the previous
    chapters, you don't have to clone the repository again.![Figure 8.4 – The git
    clone command
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端窗口中，首先输入`cd SageMaker`，然后输入`git clone` [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services)，如下面的截图所示。如果你在前面的章节中已经执行过此操作，则不必再次克隆该仓库。![图
    8.4 – git clone 命令
- en: '](img/B17528_08_04.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_04.jpg)'
- en: Figure 8.4 – The git clone command
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.4 – git clone 命令
- en: Now, exit the terminal window and go back to the home folder and you will see
    a folder called `Chapter 08`. Click the folder and you should see a notebook called
    `contextual-ad-marking-for-content-monetization-with-nlp-github.ipynb`.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，退出终端窗口，返回到主文件夹，你将看到一个名为 `Chapter 08` 的文件夹。点击该文件夹，你应该会看到一个名为 `contextual-ad-marking-for-content-monetization-with-nlp-github.ipynb`
    的 notebook。
- en: Open this notebook by clicking it.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击该 notebook 以打开它。
- en: Leave the notebook open for now. We will first execute the steps in the *Uploading
    the sample video and converting it for broadcast* section before executing the
    steps in the notebook.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 暂时保持 notebook 打开。我们将先执行 *上传示例视频并将其转换为广播格式* 部分中的步骤，然后再执行 notebook 中的步骤。
- en: Now that we have set up our notebook and cloned the repository, let's now add
    the permissions policies we need to successfully run our code sample.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了 notebook 并克隆了仓库，接下来让我们添加所需的权限策略，以成功运行我们的代码示例。
- en: Additional IAM prerequisites
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的 IAM 前提条件
- en: 'To run the notebook, we have to enable additional policies and also update
    the trust relationships for our SageMaker notebook role. Please complete the following
    steps to do this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行 notebook，我们必须启用额外的策略，并更新 SageMaker notebook 角色的信任关系。请按以下步骤操作：
- en: If not already done, please attach `ComprehendFullAccess` and `AmazonTranscribeFullAccess`
    policies to your Amazon SageMaker notebook IAM role. To execute this step, please
    refer to the *Changing IAM permissions and trust relationships for the Amazon
    SageMaker notebook execution role* in the *Setting up your AWS environment* section
    in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未完成，请将`ComprehendFullAccess`和`AmazonTranscribeFullAccess`策略附加到你的 Amazon SageMaker
    notebook IAM 角色上。要执行此步骤，请参考 *在[《第2章》](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中*，*介绍
    Amazon Textract* 部分中的 *更改 IAM 权限和信任关系*。
- en: 'Your SageMaker execution role should have access to S3 already. If not, add
    the following JSON statement as an inline policy. For instructions, please refer
    to the *Changing IAM permissions and trust relationships for the Amazon SageMaker
    notebook execution role* section in the *Setting up your AWS environment* section
    in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的 SageMaker 执行角色应该已经可以访问 S3。如果没有，请将以下 JSON 语句作为内联策略添加。有关说明，请参考 *在[《第2章》](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中*，*介绍
    Amazon Textract* 部分中的 *更改 IAM 权限和信任关系*：
- en: '[PRE0]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Finally, update the trust relationships. For instructions, please refer to
    the *Changing IAM permissions and trust relationships for the Amazon SageMaker
    notebook execution role* section in the *Setting up your AWS environment* section
    in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，更新信任关系。有关说明，请参考本书中[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)，*介绍Amazon
    Textract*部分中的*更改IAM权限和信任关系以执行Amazon SageMaker笔记本角色*小节。
- en: '[PRE1]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we have set up our notebook and set up the IAM role to run the walk-through
    notebook, in the next section, we will start with creating broadcast versions
    of our sample video.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了笔记本并配置了IAM角色来运行演练笔记本，在下一节中，我们将开始创建示例视频的广播版本。
- en: Uploading the sample video and converting it for broadcast
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传示例视频并将其转换为广播格式
- en: 'In this section we will create two S3 buckets and get the sample video uploaded
    for processing. Please execute the following steps:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将创建两个S3存储桶，并上传示例视频进行处理。请执行以下步骤：
- en: Navigate to our GitHub url - [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4)
    and click on the **Download** button at the right middle of the page to download
    the video file to your computer.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问我们的GitHub网址 - [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4)，点击页面右侧中间的**下载**按钮，将视频文件下载到计算机中。
- en: Now create two Amazon S3 buckets, one for our media input and the other for
    media output. Follow the instructions detailed in the *Creating an Amazon S3 bucket,
    a folder, and uploading objects* section in the *Setting up your AWS environment*
    section in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract,* of this book. Ensure that the block public access is on for
    both the buckets.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在创建两个Amazon S3存储桶，一个用于我们的媒体输入，另一个用于媒体输出。请参阅本书中[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)，*介绍Amazon
    Textract*部分中的*创建Amazon S3存储桶、文件夹和上传对象*小节的详细说明。确保两个存储桶的公共访问阻止功能已启用。
- en: In the Amazon S3 media input bucket, create a folder or prefix called `chapter8`.
    Within this folder, create a folder called `rawvideo`. Follow the instructions
    detailed in the *Creating an Amazon S3 bucket, a folder, and uploading objects*
    section in the *Setting up your AWS environment* section in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract*, of this book.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Amazon S3媒体输入存储桶中，创建一个名为`chapter8`的文件夹或前缀。在此文件夹内，创建一个名为`rawvideo`的文件夹。请参阅本书中[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)，*介绍Amazon
    Textract*部分中的*创建Amazon S3存储桶、文件夹和上传对象*小节的详细说明。
- en: Now upload the `bank-demo-prem-ranga.mp4` file into the `rawvideo` folder. So,
    within the S3 bucket, the video file should be present in the path `chapter8/rawvideo/bank-demo-prem-ranga.mp4`.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在将`bank-demo-prem-ranga.mp4`文件上传到`rawvideo`文件夹中。所以，在S3存储桶内，视频文件应位于路径`chapter8/rawvideo/bank-demo-prem-ranga.mp4`。
- en: Now, we will pivot to creating the broadcast version of the video using AWS
    Elemental MediaConvert. In the AWS Management Console, in the search bar at the
    top, type `Media`, select **AWS Elemental MediaConvert**, and in the console,
    click on **Get started**.![Figure 8.5 – AWS Elemental MediaConvert
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将转向使用AWS Elemental MediaConvert创建视频的广播版本。在AWS管理控制台中，在顶部的搜索框中输入`Media`，选择**AWS
    Elemental MediaConvert**，然后在控制台中点击**开始使用**。![图 8.5 – AWS Elemental MediaConvert
- en: '](img/B17528_08_05.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_05.jpg)'
- en: Figure 8.5 – AWS Elemental MediaConvert
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.5 – AWS Elemental MediaConvert
- en: In the `s3://<media-input-bucket>/chapter8/rawvideo/bank-demo-prem-ranga.mp4`.![Figure
    8.6 – Providing a job input file URL](img/B17528_08_06.jpg)
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`s3://<media-input-bucket>/chapter8/rawvideo/bank-demo-prem-ranga.mp4`。![图
    8.6 – 提供作业输入文件的URL](img/B17528_08_06.jpg)
- en: Figure 8.6 – Providing a job input file URL
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.6 – 提供作业输入文件的URL
- en: Now, click the **Add** button in **Output groups** in the left panel of the
    screen, select **Apple HLS** as the option in **Add output group**, and click
    **Select**. Output groups determine the types of content artifacts produced and
    on what devices they can be played.![Figure 8.7 – Adding an output group for the
    MediaConvert job
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击屏幕左侧面板中的 **添加** 按钮，在 **添加输出组** 中选择 **Apple HLS**，然后点击 **选择**。输出组决定了生成的内容文件类型以及它们可以在哪些设备上播放。![图
    8.7 – 为 MediaConvert 作业添加输出组](img/B17528_08_07.jpg)
- en: '](img/B17528_08_07.jpg)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_07.jpg)'
- en: Figure 8.7 – Adding an output group for the MediaConvert job
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.7 – 为 MediaConvert 作业添加输出组
- en: Now, let's fill in the Apple HLS group settings. Provide the custom group name
    as `HLS`. In `s3://<media-output-bucket>/bankdemo`. The AWS Elemental MediaConvert
    service will process the sample video file into Apple HLS content files for broadcasting.
    In `10` for `3` for **Minimum segment length (sec)**.![Figure 8.8 – Adding output
    group settings for the MediaConvert job](img/B17528_08_08.jpg)
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们填写 Apple HLS 输出组设置。提供自定义组名为 `HLS`。在 `s3://<media-output-bucket>/bankdemo`
    中，AWS Elemental MediaConvert 服务将处理示例视频文件并生成用于广播的 Apple HLS 内容文件。在 `10` 和 `3` 中填写
    **最小段长度（秒）**。![图 8.8 – 为 MediaConvert 作业添加输出组设置](img/B17528_08_08.jpg)
- en: Figure 8.8 – Adding output group settings for the MediaConvert job
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.8 – 为 MediaConvert 作业添加输出组设置
- en: Scroll down to `_720` for **Name modifier** for **Output 1**. Do *not* click
    on **Create** yet.![Figure 8.9 – Adding outputs for the MediaConvert job](img/B17528_08_09.jpg)
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到 **Output 1** 的 **名称修饰符** 中的 `_720`。*不要* 点击 **创建**。![图 8.9 – 为 MediaConvert
    作业添加输出](img/B17528_08_09.jpg)
- en: Figure 8.9 – Adding outputs for the MediaConvert job
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.9 – 为 MediaConvert 作业添加输出
- en: Now, click **Output 1**, as shown:![Figure 8.10 – Clicking Output 1
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击 **Output 1**，如下所示：![图 8.10 – 点击 Output 1
- en: '](img/B17528_08_10.jpg)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_10.jpg)'
- en: Figure 8.10 – Clicking Output 1
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.10 – 点击 Output 1
- en: As shown in the following screenshot, type `$dt$` for `1280` and `720`. Type
    `3000000` for **Bitrate (bits/s)**. Leave the rest of the fields as the default.![Figure
    8.11 – Modifying the output and encoding settings
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下图所示，在 `1280` 和 `720` 中输入 `$dt$`。在 **比特率（比特/秒）** 中输入 `3000000`。其他字段保持默认。![图
    8.11 – 修改输出和编码设置
- en: '](img/B17528_08_11.jpg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_11.jpg)'
- en: Figure 8.11 – Modifying the output and encoding settings
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.11 – 修改输出和编码设置
- en: On the left panel, under **Job settings**, click **AWS integration**. On the
    right, under **Service access**, for **Service role control**, select **Create
    a new service role, full permissions**. Accept the default name populated in **New
    role name**. Scroll down and click on **Create**.![Figure 8.12 – Adding service
    access for the MediaConvert job
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧面板中，点击 **作业设置** 下的 **AWS 集成**。在右侧的 **服务访问** 下，对于 **服务角色控制**，选择 **创建新的服务角色，完全权限**。接受
    **新角色名称** 中填充的默认名称。向下滚动并点击 **创建**。![图 8.12 – 为 MediaConvert 作业添加服务访问](img/B17528_08_12.jpg)
- en: '](img/B17528_08_12.jpg)'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_12.jpg)'
- en: Figure 8.12 – Adding service access for the MediaConvert job
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.12 – 为 MediaConvert 作业添加服务访问
- en: The job should complete in a couple of minutes. Click on the **Job ID** to review
    the summary view of the job, as shown in the following screenshot:![Figure 8.13
    – Job summary
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作业应在几分钟内完成。点击 **Job ID** 查看作业的摘要视图，如下图所示：![图 8.13 – 作业摘要
- en: '](img/B17528_08_13.jpg)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_13.jpg)'
- en: Figure 8.13 – Job summary
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.13 – 作业摘要
- en: 'Once the status shows `S3` in the search bar at the top of the screen and go
    to the S3 console. Under `bankdemo`, as shown in the following screenshot:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦状态显示 `S3`，在屏幕顶部的搜索栏中输入并进入 S3 控制台。在 `bankdemo` 下，如下图所示：
- en: '![Figure 8.14 – AWS Elemental MediaConvert Apple HLS output files'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.14 – AWS Elemental MediaConvert Apple HLS 输出文件'
- en: '](img/B17528_08_14.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_08_14.jpg)'
- en: Figure 8.14 – AWS Elemental MediaConvert Apple HLS output files
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – AWS Elemental MediaConvert Apple HLS 输出文件
- en: We have now successfully completed the steps required to convert our sample
    video file into broadcast-enabled output files, which is required for us to insert
    ads into the video. In the next section, we will run a transcription of the audio
    content from our video, run topic modeling, create the **VAST** ad tag URL required
    for ad insertion, and show how we can perform content monetization.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功完成了将示例视频文件转换为适合广播的输出文件的步骤，这对于我们将广告插入到视频中是必需的。在接下来的章节中，我们将进行视频音频内容的转录，执行主题建模，创建**VAST**广告标签
    URL 以供广告插入，并展示如何进行内容货币化。
- en: Running transcription, finding topics, and creating a VAST ad tag URL
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行转录、查找主题，并创建 VAST 广告标签 URL
- en: 'Open the notebook you cloned from the GitHub repository ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/contextual-ad-marking-for-content-monetization-with-nlp-github.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/contextual-ad-marking-for-content-monetization-with-nlp-github.ipynb))
    in the *Setting up to solve the use case* section and execute the cells step by
    step, as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 打开你从 GitHub 仓库克隆的笔记本([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/contextual-ad-marking-for-content-monetization-with-nlp-github.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/contextual-ad-marking-for-content-monetization-with-nlp-github.ipynb))，进入*设置以解决用例*部分，并按照以下步骤逐个执行单元格：
- en: Note
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please ensure you have executed the steps in the *Technical requirements*, *Setting
    up to solve the use case*, and *Uploading the sample video and converting it for
    broadcast* sections before you execute the cells in the notebook.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保在执行笔记本中的单元格之前，已经执行了*技术要求*、*设置以解决用例*和*上传示例视频并转换为广播格式*部分中的步骤。
- en: 'Execute the first three cells under the **Transcribe** section to ensure we
    have the libraries we need for the notebook. Note that in the first cell you are
    importing libraries, in the second cell you are creating folders needed for Topic
    Modeling, and in the third cell you are specifying the S3 bucket and prefix. You
    should have already created two S3 buckets prior to running this notebook, as
    mentioned in the *Uploading the sample video and converting it for broadcast*
    section. Please provide the media input bucket name in the line, type a prefix
    of your choice, or you can accept what is already provided in the notebook. In
    this cell, we also define the Python SDK handle for Amazon S3 using Boto3, an
    AWS SDK for Python development ([https://boto3.amazonaws.com/v1/documentation/api/latest/index.html](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)):'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行**转录**部分下的前三个单元格，确保我们已经拥有笔记本所需的库。注意，在第一个单元格中你导入了库，在第二个单元格中你创建了进行主题建模所需的文件夹，在第三个单元格中你指定了
    S3 存储桶和前缀。你应该已经在运行此笔记本之前创建了两个 S3 存储桶，正如在*上传示例视频并转换为广播格式*部分中提到的那样。在此行中，请提供媒体输入存储桶名称，输入你选择的前缀，或者你可以接受笔记本中已有的前缀。在此单元格中，我们还使用
    Boto3（AWS Python 开发 SDK）定义了 Amazon S3 的 Python SDK 句柄([https://boto3.amazonaws.com/v1/documentation/api/latest/index.html](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html))：
- en: '[PRE2]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Execute the next cell to define a method for running an Amazon Transcribe transcription
    job to convert the audio content of our sample video file to text. Note that we
    are setting MediaFormat as `mp4`. We will be using the original sample video file
    from the GitHub repository ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4))
    as the input for the transcription job:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行下一个单元格，以定义运行 Amazon Transcribe 转录任务的方法，将我们示例视频文件的音频内容转换为文本。请注意，我们将 MediaFormat
    设置为 `mp4`。我们将使用来自 GitHub 仓库的原始示例视频文件([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/bank-demo-prem-ranga.mp4))作为转录任务的输入：
- en: '[PRE3]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Provide a job name (a text string) for the transcription so we are able to
    identify this job down the line. Get the Boto3 handle for the Amazon Transcribe
    service, pass the S3 location of our sample video file we loaded in the media
    input S3 bucket, and call the `transcribe_file` method to run the transcription
    job:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一个转录任务名称（一个文本字符串），以便我们在后续过程中能够识别该任务。获取 Amazon Transcribe 服务的 Boto3 句柄，传入我们在媒体输入
    S3 存储桶中加载的示例视频文件的 S3 位置，并调用 `transcribe_file` 方法运行转录任务：
- en: '[PRE4]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, navigate to the AWS Management Console in a new tab, type `Amazon Transcribe`
    in the search bar at the top, and open the Amazon Transcribe console. Click on
    **Transcription jobs** in the left pane. You should see your transcription job
    with the job name you specified earlier. When the job completes, the status should
    change to **Complete**.![Figure 8.15 – Amazon Transcribe transcription job](img/B17528_08_15.jpg)
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在新的标签页中导航到 AWS 管理控制台，在顶部的搜索框中输入 `Amazon Transcribe`，并打开 Amazon Transcribe
    控制台。点击左侧面板中的**转录任务**。你应该能看到你之前指定的转录任务名称。当任务完成时，状态应该会变为**完成**。![图 8.15 – Amazon
    Transcribe 转录任务](img/B17528_08_15.jpg)
- en: Figure 8.15 – Amazon Transcribe transcription job
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.15 – Amazon Transcribe 转录任务
- en: 'Now come back to the notebook and execute the next cell to get the S3 location
    of the transcription results:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在回到笔记本并执行下一个单元，以获取转录结果的 S3 位置：
- en: '[PRE5]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will now execute the code cells in the `transcript.csv`) to convert the
    paragraph of text into individual lines (`transcript_formatted.csv`) to send as
    input to the Amazon Comprehend Topic Modeling job. Execute the code in the notebook
    cell as shown in the following code block:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将执行`transcript.csv`文件中的代码单元，目的是将段落文本转换为单独的行（`transcript_formatted.csv`），然后作为输入发送到
    Amazon Comprehend 主题建模任务中。请按照以下代码块中的示例执行笔记本中的代码：
- en: '[PRE6]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will run an Amazon Comprehend Topic Modeling job on this formatted CSV file
    to extract a set of topics that are applicable for our transcript. These topics
    represent and help us identify what the subject area or the theme for the related
    text is and represent the common set of words with the same contextual reference
    throughout the transcript. For more details, please refer to *Amazon Comprehend
    Topic Modeling*: [https://docs.aws.amazon.com/comprehend/latest/dg/topic-modeling.html](https://docs.aws.amazon.com/comprehend/latest/dg/topic-modeling.html).'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将对这个格式化的 CSV 文件运行一个 Amazon Comprehend 主题建模任务，提取一组适用于我们的转录内容的主题。这些主题代表并帮助我们识别相关文本的主题或领域，并表示在整个转录文本中具有相同上下文引用的共同单词集合。更多详情，请参阅*Amazon
    Comprehend 主题建模*：[https://docs.aws.amazon.com/comprehend/latest/dg/topic-modeling.html](https://docs.aws.amazon.com/comprehend/latest/dg/topic-modeling.html)。
- en: To get started, go to the AWS Management Console (please refer to *Technical
    requirements* in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract,* of this book if you don't have access to the AWS
    Management Console), type `Amazon Comprehend` in the `transcript_formatted.csv`
    file that we uploaded to S3 in preceding steps) in your *S3 bucket* in the `2`,
    as shown:![Figure 8.18 – Creating Topic Modeling job inputs 2
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始使用，请访问 AWS 管理控制台（如果您没有访问 AWS 管理控制台的权限，请参考本书中[*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)的*技术要求*，*介绍
    Amazon Textract*），在我们之前上传到 S3 的`transcript_formatted.csv`文件中，输入`Amazon Comprehend`，如图所示：![图
    8.18 – 创建主题建模任务输入 2
- en: '](img/B17528_08_18.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_18.jpg)'
- en: Figure 8.18 – Creating Topic Modeling job inputs 2
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.18 – 创建主题建模任务输入 2
- en: Provide the **Output data** S3 location, as shown (you can use the same S3 bucket
    you used for input), and then type a name suffix and click on **Create job**.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提供**输出数据**的 S3 位置，如图所示（你可以使用与输入相同的 S3 存储桶），然后输入一个名称后缀并点击**创建任务**。
- en: '![Figure 8.19 – Creating Topic Modeling job inputs 3'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.19 – 创建主题建模任务输入 3](img/B17528_08_19.jpg)'
- en: '](img/B17528_08_19.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_19.jpg)'
- en: Figure 8.19 – Creating Topic Modeling job inputs 3
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.19 – 创建主题建模任务输入 3
- en: You should see a **job submitted** status after the IAM role propagation is
    completed. After 30 minutes, the job status should change to **Completed**. Now
    click on the job name and copy the S3 link provided in the **Output data location**
    field and go back to your notebook. We will continue the steps in the notebook.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 IAM 角色传播完成后，您应该会看到**任务已提交**的状态。30 分钟后，任务状态应变为**已完成**。现在点击任务名称并复制**输出数据位置**字段中提供的
    S3 链接，然后返回笔记本。我们将继续在笔记本中的步骤。
- en: '![Figure 8.20 – Topic Modeling job completed](img/B17528_08_20.jpg)'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 8.20 – 主题建模任务已完成](img/B17528_08_20.jpg)'
- en: Figure 8.20 – Topic Modeling job completed
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.20 – 主题建模任务已完成
- en: We will now execute the cells in the `tpprefix` variable, specifically `<path-to-job-output-tar>`,
    with the string highlighted in bold from the S3 URI you copied shown in the following
    code block.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将执行` tpprefix` 变量中的代码单元，特别是从 S3 URI 中复制的字符串，代码块如下所示，并突出显示粗体部分。
- en: '[PRE7]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'for i,x in tt_df.iterrows():'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for i, x in tt_df.iterrows():'
- en: print(str(x['topic'])+":"+x['term']+":"+str (x['weight']))
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(str(x['topic'])+":"+x['term']+":"+str(x['weight']))
- en: '[PRE8]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: dt_df = dt_df.drop_duplicates(subset=['docname'])
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: dt_df = dt_df.drop_duplicates(subset=['docname'])
- en: '[PRE9]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ttdf_max = tt_df.groupby(['topic'], sort=False)['weight'].max()
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ttdf_max = tt_df.groupby(['topic'], sort=False)['weight'].max()
- en: '[PRE10]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: newtt_df = pd.DataFrame()
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: newtt_df = pd.DataFrame()
- en: 'for x in ttdf_max:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for x in ttdf_max:'
- en: newtt_df = newtt_df.append(tt_df.query('weight == @x'))
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: newtt_df = newtt_df.append(tt_df.query('weight == @x'))
- en: newtt_df = newtt_df.reset_index(drop=True)
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: newtt_df = newtt_df.reset_index(drop=True)
- en: newtt_df
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: newtt_df
- en: '[PRE11]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: adtopic = newtt_df.at[1,'term']
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: adtopic = newtt_df.at[1,'term']
- en: '[PRE12]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We will now use the topic to look up ad content and create a VAST ad tag URL
    that will be used as an input to insert ads into the broadcast video files we
    created using AWS Elemental MediaConvert. The authors have provided two sample
    CSV files containing content metadata for looking up ads. `ad-index.csv` ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/ad-index.csv](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/ad-index.csv))
    contains a list of topics as keys and sample `cmsid` and `vid` values. `cmsid`
    indicates the content management source ID in Google Ad Server, which is what
    we are using as the ad decision server for our example, and `vid` indicates the
    video content ID in Google Ad Server. `adserver.csv` ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv))
    contains the sample Google ad decision server URL that we need to modify in this
    step. For this example, we'll use the topic we discovered from our Topic Modeling
    job as the key to fetch `cmsid` and `vid`.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将使用主题查找广告内容，并创建一个VAST广告标签URL，该URL将作为输入用于将广告插入我们使用AWS Elemental MediaConvert创建的广播视频文件中。作者提供了两个包含广告查找内容元数据的示例CSV文件。`ad-index.csv`（[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/ad-index.csv](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/ad-index.csv)）包含作为键的主题列表和示例的`cmsid`与`vid`值。`cmsid`表示Google
    Ad Server中的内容管理源ID，它是我们作为广告决策服务器在示例中使用的内容，而`vid`表示Google Ad Server中的视频内容ID。`adserver.csv`（[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv)）包含我们在此步骤中需要修改的示例Google广告决策服务器URL。在此示例中，我们将使用从我们的主题建模任务中发现的主题作为键来获取`cmsid`和`vid`。
- en: 'We will then substitute these in the VAST ad marker URL before creating the
    AWS Elemental MediaTailor configuration. Execute the code cells as shown in the
    following code block:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们将在创建AWS Elemental MediaTailor配置之前，替换VAST广告标记URL中的这些值。按照以下代码块所示执行代码单元：
- en: '[PRE13]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'a.) Please note this is from the sample `ad-index.csv` file that the authors
    created for this demo. When you use this solution for your use case, you will
    need to create a Google Ads account to get the `cmsid` and `vid` values. For more
    details, please see this link: [https://support.google.com/admanager/topic/1184139?hl=en&ref_topic=7506089](https://support.google.com/admanager/topic/1184139?hl=en&ref_topic=7506089).'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a.) 请注意，这是来自作者为本次演示创建的示例`ad-index.csv`文件。当你在自己的使用场景中使用此解决方案时，你需要创建一个Google Ads账户以获取`cmsid`和`vid`值。更多详细信息，请查看此链接：[https://support.google.com/admanager/topic/1184139?hl=en&ref_topic=7506089](https://support.google.com/admanager/topic/1184139?hl=en&ref_topic=7506089)。
- en: 'b.) Run the code in the following snippet to select the `cmsid` and `vid` values
    based on our topic:'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b.) 运行以下代码片段，以根据我们的主题选择`cmsid`和`vid`值：
- en: '[PRE14]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'c.) We get the following response:'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c.) 我们得到以下响应：
- en: '[PRE15]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'd.) Now we will create the ad server URL to use with AWS Elemental MediaTailor.
    Let''s first copy the placeholder URL available in our GitHub repo ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv)),
    which has pre-roll, mid-roll, and post-roll segments filled in:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d.) 现在，我们将创建用于AWS Elemental MediaTailor的广告服务器URL。首先，从我们的GitHub仓库中复制可用的占位符URL（[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2008/media-content/adserver.csv)），其中已填充前滚、中滚和后滚广告段：
- en: '[PRE16]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'e.) We get the following response:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e.) 我们得到以下响应：
- en: '[PRE17]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ad_formattedurl = ''
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ad_formattedurl = ''
- en: 'for x in ad_rawurl:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于x在ad_rawurl中的每一项：
- en: 'if ''cmsid'' in x:'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果'x'中包含'cmsid'：
- en: x = advalue[1]
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: x = advalue[1]
- en: 'if ''vid'' in x:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果'x'中包含'vid'：
- en: x = advalue[2]
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: x = advalue[2]
- en: ad_formattedurl += x + '&'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ad_formattedurl += x + '&'
- en: ad_formattedurl = ad_formattedurl.rstrip('&')
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ad_formattedurl = ad_formattedurl.rstrip('&')
- en: ad_formattedurl
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ad_formattedurl
- en: '[PRE18]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '''https://pubads.g.doubleclick.net/gampad/ads?sz=640x480&iu=/124319096/external/ad_rule_samples&ciu_szs=300x250&ad_rule=1&impl=s&gdfp_req=1&env=vp&output=vmap&unviewed_position_start=1&cust_params=deployment%3Ddevsite%26sample_ar%3Dpremidpost&cmsid=176&vid=short_tencue&correlator=[avail.random]'''
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '''https://pubads.g.doubleclick.net/gampad/ads?sz=640x480&iu=/124319096/external/ad_rule_samples&ciu_szs=300x250&ad_rule=1&impl=s&gdfp_req=1&env=vp&output=vmap&unviewed_position_start=1&cust_params=deployment%3Ddevsite%26sample_ar%3Dpremidpost&cmsid=176&vid=short_tencue&correlator=[avail.random]'''
- en: '[PRE19]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Alright, that brings us to the end of this section. We successfully transcribed
    our sample video file using Amazon Transcribe, ran an Amazon Comprehend Topic
    Modeling job on the transcript, selected a topic, and stitched together an ad
    server VAST tag URL with the ad content ID corresponding to the topic. In the
    next section, we will use AWS Elemental MediaTailor to create new video output
    with the ad segments inserted, and we will test it by playing the video.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这一部分就到这里。我们成功地使用 Amazon Transcribe 转录了样本视频文件，对转录内容进行了 Amazon Comprehend 主题建模，选择了一个主题，并结合了广告服务器
    VAST 标签 URL 和与该主题对应的广告内容 ID。在下一部分，我们将使用 AWS Elemental MediaTailor 创建插入广告片段的新视频输出，并通过播放视频进行测试。
- en: Inserting ads and testing our video
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插入广告并测试我们的视频
- en: Before we can proceed forward, we need to create an Amazon CloudFront ([https://aws.amazon.com/cloudfront/](https://aws.amazon.com/cloudfront/))
    content delivery distribution for the video output files we transcoded with AWS
    Elemental MediaConvert in the *Uploading the sample video and converting it for
    broadcast* section.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，需要为我们在 *上传样本视频并将其转换为广播格式* 部分中使用 AWS Elemental MediaConvert 转码的视频输出文件创建一个
    Amazon CloudFront ([https://aws.amazon.com/cloudfront/](https://aws.amazon.com/cloudfront/))
    内容分发。
- en: 'Amazon CloudFront is a managed content delivery network that can be used for
    site hosting, APIs, and image, media, and video file delivery, with live or on-demand
    streaming formats, configured for global distribution or based on the selected
    price class. Please follow the next steps to set up the CloudFront distribution
    for your transcoded video files:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon CloudFront 是一个托管的内容分发网络，可用于站点托管、API 以及图像、媒体和视频文件的传输，支持实时或按需流媒体格式，可根据选择的价格类别配置全球分发。请按照以下步骤为转码后的视频文件设置
    CloudFront 分发：
- en: In the AWS Management Console, type `CloudFront` in the search bar at the top,
    and then select **Amazon CloudFront** and click **Create Distribution**.![Figure
    8.21 – Amazon CloudFront Create Distribution](img/B17528_08_21.jpg)
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 管理控制台中，在顶部的搜索框中输入 `CloudFront`，然后选择 **Amazon CloudFront** 并点击 **创建分发**。![图
    8.21 – Amazon CloudFront 创建分发](img/B17528_08_21.jpg)
- en: Figure 8.21 – Amazon CloudFront Create Distribution
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.21 – Amazon CloudFront 创建分发
- en: On the next page, click **Get Started** to proceed to the **Create Distribution**
    page. Please note there are multiple sections to be filled. In the **Origin Settings**
    part of the page, click the list box for **Origin Domain Name** and select the
    media output bucket that contains the video output files from the AWS Elemental
    MediaConvert job. Select **Yes** for **Restrict Bucket Access**, and select **Create
    a New Identity** for **Origin Access Identity**. Select **Yes, Update Bucket Policy**
    for **Grant Read Permissions on Bucket**.![Figure 8.22 – Origin Settings for Create
    Distribution in Amazon CloudFront
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，点击 **开始使用** 以继续进入 **创建分发** 页面。请注意，需要填写多个部分。在页面的 **源设置** 部分，点击 **源域名** 下拉框，选择包含来自
    AWS Elemental MediaConvert 作业的视频输出文件的媒体输出存储桶。对于 **限制存储桶访问** 选择 **是**，对于 **源访问身份**
    选择 **创建新身份**。对于 **授予存储桶读取权限**，选择 **是，更新存储桶策略**。![图 8.22 – Amazon CloudFront 创建分发的源设置](img/B17528_08_22.jpg)
- en: '](img/B17528_08_22.jpg)'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_22.jpg)'
- en: Figure 8.22 – Origin Settings for Create Distribution in Amazon CloudFront
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.22 – Amazon CloudFront 创建分发的源设置
- en: Scroll down to the **Default Cache Behavior Settings** area and change **Viewer
    Protocol Policy** to **Redirect HTTP to HTTPS**. For **Cache Policy**, click the
    list box and select **Managed-Elemental-MediaPackage**.![Figure 8.23 – Default
    Cache Behavior Settings](img/B17528_08_23.jpg)
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动到 **默认缓存行为设置** 区域，并将 **查看器协议策略** 改为 **重定向 HTTP 到 HTTPS**。在 **缓存策略** 中，点击下拉框并选择
    **Managed-Elemental-MediaPackage**。![图 8.23 – 默认缓存行为设置](img/B17528_08_23.jpg)
- en: Figure 8.23 – Default Cache Behavior Settings
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.23 – 默认缓存行为设置
- en: Scroll down to the **Distribution Settings** area and select the price class
    based on where you are located. Leave the rest of the settings as they are, scroll
    down, and click **Create Distribution**.![Figure 8.24 – Distribution Settings
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动到**分发设置**区域，选择根据你所在位置的价格等级。将其他设置保持不变，向下滚动并点击**创建分发**。![图 8.24 – 分发设置
- en: '](img/B17528_08_24.jpg)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_24.jpg)'
- en: Figure 8.24 – Distribution Settings
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.24 – 分发设置
- en: Once the distribution is created, the status will change to **Deployed** and
    the state will change to **Enabled**. Copy the value of the domain name from the
    distribution.![Figure 8.25 – Distribution is enabled](img/B17528_08_25.jpg)
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦分发创建完成，状态将变为**已部署**，并且状态会变为**启用**。复制从分发中得到的域名值。![图 8.25 – 分发已启用](img/B17528_08_25.jpg)
- en: Figure 8.25 – Distribution is enabled
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.25 – 分发已启用
- en: We will now use this distribution as a content source to create new video output
    with the ads inserted. In the AWS Management Console, type `MediaTailor` in the
    services search bar, and select it to go to the AWS Elemental MediaTailor console.
    Click **Create configuration** to get started.![Figure 8.26 – AWS Elemental MediaTailor
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将使用这个分发作为内容源，创建带有广告插入的新视频输出。在AWS管理控制台中，搜索框中输入`MediaTailor`，然后选择它以进入AWS Elemental
    MediaTailor控制台。点击**创建配置**开始。![图 8.26 – AWS Elemental MediaTailor
- en: '](img/B17528_08_26.jpg)'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_26.jpg)'
- en: Figure 8.26 – AWS Elemental MediaTailor
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.26 – AWS Elemental MediaTailor
- en: On the **Create configuration** page, under **Required settings**, provide an
    ad campaign name. In the **Content source** field, paste the Amazon CloudFront
    distribution domain name that you copied in the preceding steps. Finally, in the
    **Ad decision server** field, type the modified VAST ad tag URL you created in
    the last step of the *Running transcription, finding topics, and creating a VAST
    ad tag URL* section. Scroll down and click **Create configuration**.![Figure 8.27
    – Creating MediaTailor configuration](img/B17528_08_27.jpg)
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**创建配置**页面， 在**必需设置**下，提供广告活动名称。在**内容源**字段中，粘贴前面步骤中复制的Amazon CloudFront分发域名。最后，在**广告决策服务器**字段中，输入你在*运行转录、查找主题和创建VAST广告标签URL*部分最后一步中修改过的VAST广告标签URL。滚动到底部并点击**创建配置**。![图
    8.27 – 创建MediaTailor配置](img/B17528_08_27.jpg)
- en: Figure 8.27 – Creating MediaTailor configuration
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.27 – 创建MediaTailor配置
- en: The created configuration is displayed as shown in the following screenshot.
    Copy the HLS playback prefix as we need it in the next step.![Figure 8.28 – MediaTailor
    playback endpoint prefixes
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建的配置将如下面的截图所示。复制HLS播放前缀，因为我们在下一步中需要它。![图 8.28 – MediaTailor播放端点前缀
- en: '](img/B17528_08_28.jpg)'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_08_28.jpg)'
- en: Figure 8.28 – MediaTailor playback endpoint prefixes
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.28 – MediaTailor 播放端点前缀
- en: 'Download the VLC media player ([https://www.videolan.org/](https://www.videolan.org/))
    and open it. Click on `bankdemo.m3u8`. This is the manifest file for the MediaTailor
    video output with the ads inserted. The full URL should look as follows (this
    is an example representative URL): `https://<generated-hash-nr>.mediatailor.us-east-1.amazonaws.com/v1/master/<generated-hash-nr>/<chapter8-ad-campaign>/bankdemo.m3u8`.![Figure
    8.29 – Testing the video output using the VLC media player](img/B17528_08_29.jpg)'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载VLC媒体播放器（[https://www.videolan.org/](https://www.videolan.org/)）并打开它。点击`bankdemo.m3u8`。这是带有广告插入的MediaTailor视频输出的清单文件。完整的URL应如下所示（这是一个示例URL）：`https://<generated-hash-nr>.mediatailor.us-east-1.amazonaws.com/v1/master/<generated-hash-nr>/<chapter8-ad-campaign>/bankdemo.m3u8`。![图
    8.29 – 使用VLC媒体播放器测试视频输出](img/B17528_08_29.jpg)
- en: Figure 8.29 – Testing the video output using the VLC media player
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.29 – 使用VLC媒体播放器测试视频输出
- en: Click **Open**. The video will start playing momentarily. Please note it takes
    a couple of minutes for the ad insertion to reflect in the video. You should see
    a 10-second pre-roll, a 10-second mid-roll, and post-roll ad space in the video.
    Since we used the sample ad server URL, we don't see actual ads here, but once
    you register with an ad decision server, you can get the actual ad content included
    by following the steps in this solution.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**打开**。视频将很快开始播放。请注意，广告插入在视频中显示需要几分钟时间。你应该看到一个10秒的前滚广告、一个10秒的中滚广告，以及后滚广告空间。由于我们使用了示例广告服务器URL，这里不会显示实际广告，但一旦你通过广告决策服务器注册，你可以按照此方案中的步骤获得实际的广告内容。
- en: And that concludes the solution build for this chapter. Please refer to the
    *Further reading* section for more details on media content monetization with
    AWS AI and media services.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是本章的解决方案构建部分。有关使用AWS AI和媒体服务进行媒体内容货币化的更多详细信息，请参阅*进一步阅读*部分。
- en: Summary
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to build an intelligent solution for media content
    monetization using the AWS AI services Amazon Transcribe and Amazon Comprehend,
    the Amazon CloudFront content delivery network, and the AWS media services Elemental
    MediaConvert and Elemental MediaTailor by taking a sample MP4 video file. We covered
    all this by first transcoding it into Apple HLS output files using MediaConvert,
    then creating atranscription from the MP4 file using Amazon Transcribe, analyzing
    the transcript, and detecting topics using Amazon Comprehend Topic Modeling, creating
    a VAST ad decision server URL. We also covered creating a distribution for the
    transcoded video content using Amazon CloudFront and using this distribution and
    the ad decision server URL to insert ads into the transcoded video using MediaTailor.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们学习了如何利用AWS AI服务Amazon Transcribe和Amazon Comprehend、Amazon CloudFront内容分发网络以及AWS媒体服务Elemental
    MediaConvert和Elemental MediaTailor，构建一个用于媒体内容货币化的智能解决方案。我们以一个MP4视频文件为例，首先使用MediaConvert将其转码为Apple
    HLS输出文件，然后使用Amazon Transcribe从MP4文件中创建转录，分析转录内容，并通过Amazon Comprehend的主题建模检测主题，创建VAST广告决策服务器URL。我们还介绍了如何使用Amazon
    CloudFront为转码后的视频内容创建分发，并使用该分发和广告决策服务器URL，将广告插入转码后的视频中，使用MediaTailor进行操作。
- en: For our solution, we started by introducing the content monetization use case
    for LiveRight, the requirement for a cost-effective expansion resulting in using
    content to pay for content creation. We then designed an architecture that used
    AWS AI services, media services, and the content delivery network to assemble
    an end-to-end walk-through of how to monetize content in video files. We assumed
    that you, the reader, are the architect assigned to this project, and we reviewed
    an overview of the solution components along with an architectural illustration
    in *Figure 8.1*.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的解决方案，我们首先介绍了LiveRight的内容货币化用例，该用例需要通过使用内容来支付内容创作的费用，从而实现具有成本效益的扩展。然后我们设计了一个架构，使用了AWS
    AI服务、媒体服务和内容分发网络，构建了一个端到端的操作流程，展示如何在视频文件中实现内容货币化。我们假设你，作为读者，是被指派到这个项目的架构师，并且我们回顾了方案组件的概述，并附带了*图8.1*中的架构示意图。
- en: We then went through the prerequisites for the solution build, set up an Amazon
    SageMaker notebook instance, cloned our GitHub repository, and started executing
    the steps using the AWS Management Console and the code in the notebook based
    on instructions from this chapter.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接着我们回顾了解决方案构建的前提条件，设置了一个Amazon SageMaker笔记本实例，克隆了我们的GitHub仓库，并开始根据本章的说明，通过AWS管理控制台和笔记本中的代码执行步骤。
- en: In the next chapter, we will look at an important use case, metadata extraction,
    using named entity recognition. We will, as before, introduce the use case, discuss
    how to design the architecture, establish the prerequisites, and walk through
    in detail the various steps required to build the solution.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨一个重要的用例——使用命名实体识别进行元数据提取。我们将像之前一样，介绍这个用例，讨论如何设计架构，建立前提条件，并详细阐述构建解决方案所需的各种步骤。
- en: Further reading
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Monetizing your media workflows ([https://aws.amazon.com/media/resources/monetization/](https://aws.amazon.com/media/resources/monetization/))
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 媒体工作流货币化 ([https://aws.amazon.com/media/resources/monetization/](https://aws.amazon.com/media/resources/monetization/))
- en: '*Announcing AWS Media Intelligence Solutions* by Vasi Philozelligence-solutions/)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*宣布AWS媒体智能解决方案* by Vasi Philozelligence-solutions/)'
