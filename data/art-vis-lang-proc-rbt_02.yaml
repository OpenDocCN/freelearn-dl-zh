- en: '*Chapter 2*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第2章*'
- en: Introduction to Computer Vision
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉简介
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Explain the impact of artificial intelligence and computer vision
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释人工智能和计算机视觉的影响
- en: Deploy some of the basic computer vision algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署一些基本的计算机视觉算法
- en: Develop some of the basic machine learning algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一些基本的机器学习算法
- en: Construct your first neural network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建你的第一个神经网络
- en: This chapter covers an introduction to computer vision followed by a few important
    basic computer vision and machine learning algorithms.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了计算机视觉的基本概念，接着介绍了一些重要的计算机视觉和机器学习基本算法。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Artificial Intelligence** (**AI**) is changing everything. It tries to mimic
    human intelligence in order to achieve different tasks.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）正在改变一切。它试图模拟人类智能，以完成各种任务。'
- en: The section of AI that deals with images is called computer vision. Computer
    vision is an interdisciplinary scientific field that tries to mimic human eyes.
    It not only makes sense out of the pixels that are extracted from an image, but
    also gains a higher level of understanding from that specific image by performing
    automated tasks and using algorithms.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 处理图像的人工智能领域称为计算机视觉。计算机视觉是一个跨学科的科学领域，旨在模拟人类眼睛。它不仅从图像中提取像素并进行解读，还通过执行自动化任务和使用算法，从特定图像中获得更高层次的理解。
- en: Some of these algorithms are better at object recognition, recognizing faces,
    classifying images, editing images, and even generating images.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些算法在物体识别、人脸识别、图像分类、图像编辑，甚至图像生成方面表现更好。
- en: This chapter will begin with an introduction to computer vision, starting with
    some of the most basic algorithms and an exercise to put them into practice. Later,
    an introduction to machine learning will be given, starting from the most basic
    algorithms to neural networks, involving several exercises to strengthen the knowledge
    acquired.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将从计算机视觉的介绍开始，首先讲解一些最基本的算法，并通过练习将它们付诸实践。接着，会介绍机器学习的基本算法到神经网络的概念，并通过多个练习来巩固所学的知识。
- en: Basic Algorithms in Computer Vision
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机视觉中的基本算法
- en: In this topic, we will be addressing how images are formed. We will introduce
    a library that is very useful for performing computer vision tasks and we will
    learn about the workings of some of these tasks and algorithms and how to code
    them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论图像是如何形成的。我们将介绍一个非常有用的库，用于执行计算机视觉任务，并了解一些任务和算法的工作原理以及如何编码它们。
- en: Image Terminology
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像术语
- en: To understand computer vision, we first need to know how images work and how
    a computer interprets them.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解计算机视觉，我们首先需要了解图像是如何工作的以及计算机是如何解释它们的。
- en: 'A computer understands an image as a set of numbers grouped together. To be
    more specific, the image is seen as a two-dimensional array, a matrix that contains
    values from 0 to 255 (0 being for black and 255 for white in grayscale images)
    representing the values of the pixels of an image (**pixel values**), as shown
    in the following example:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机将图像理解为一组数字的集合。更具体地说，图像被视为一个二维数组，一个包含从 0 到 255（在灰度图像中，0 代表黑色，255 代表白色）值的矩阵，表示图像的像素值（**像素值**），如下例所示：
- en: '![Figure 2.1: Image representation without and with pixel values](img/C13550_02_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1：没有像素值和有像素值的图像表示](img/C13550_02_01.jpg)'
- en: 'Figure 2.1: Image representation without and with pixel values'
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.1：没有像素值和有像素值的图像表示
- en: In the image on the left-hand side, the number 3 is shown in a low resolution.
    On the right-hand side, the same image is shown along with the value of every
    pixel. As this value rises, a brighter color is shown, and if the value decreases,
    the color gets darker.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧的图像中，数字 3 以低分辨率显示。在右侧，显示了相同的图像，并附有每个像素的值。随着像素值的增加，颜色会变亮，而值减小时，颜色会变暗。
- en: This particular image is in grayscale, which means it is only a two-dimensional
    array of values from 0 to 255, but what about colored images? Colored images (or
    red/green/blue (RGB) images) have three layers of two-dimensional arrays stacked
    together. Every layer represents one color each and putting them all together
    forms a colored image.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像是灰度图像，这意味着它只是一个从 0 到 255 的二维数值数组，但彩色图像呢？彩色图像（或红/绿/蓝（RGB）图像）有三层二维数组堆叠在一起。每一层代表一种颜色，将它们组合在一起就形成了彩色图像。
- en: The preceding image has 14x14 pixels in its matrix. In grayscale, it is represented
    as 14x14x1, as it only has one matrix, and one channel. For the RGB format, the
    representation is 14x14x3 as it has 3 channels. From this, all that computers
    need to understand is that the images come from these pixels.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图像的矩阵大小为14x14像素。在灰度模式下，它表示为14x14x1，因为只有一个矩阵和一个通道。而对于RGB格式，它表示为14x14x3，因为有三个通道。从中计算机只需理解这些图像是由这些像素构成的。
- en: OpenCV
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCV
- en: OpenCV is an open source computer vision library that has C++, Python, and Java
    interfaces and supports Windows, Linux, macOS, iOS, and Android.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV是一个开源的计算机视觉库，支持C++、Python和Java接口，并且支持Windows、Linux、macOS、iOS和Android。
- en: For all the algorithms mentioned in this chapter, we will be using OpenCV. OpenCV
    helps us perform these algorithms using Python. If you want to practice one of
    these algorithms, we recommend using Google Colab. You will need to install Python
    3.5 or above, OpenCV, and NumPy to carry on with this chapter. To display them
    on our screens, we will use Matplotlib. Both of these are great libraries for
    AI.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中提到的所有算法，我们将使用OpenCV。OpenCV帮助我们通过Python实现这些算法。如果你想实践这些算法，建议使用Google Colab。你需要安装Python
    3.5或更高版本、OpenCV和NumPy，以便继续本章的内容。为了在屏幕上显示结果，我们将使用Matplotlib。这两个库都是人工智能领域的优秀工具。
- en: Basic Image Processing Algorithms
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本图像处理算法
- en: In order for a computer to understand an image, the image has to be processed
    first. There are many algorithms that can be used to process images and the output
    depends on the task at hand.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让计算机理解图像，首先必须对图像进行处理。处理图像的算法有很多种，输出的结果取决于具体任务的要求。
- en: 'Some of the most basic algorithms are:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最基本的算法包括：
- en: Thresholding
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阈值化
- en: Morphological transformations
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 形态学变换
- en: Blurring
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模糊
- en: Thresholding
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阈值化
- en: '**Thresholding** is commonly used to simplify how an image is visualized by
    both the computer and the user in order to make analysis easier. It is based on
    a value that the user sets and every pixel is converted to white or black depending
    on whether the value of every pixel is higher or lower than the set value. If
    the image is in grayscale, the output image will be white and black, but if you
    choose to keep the RGB format for your image, the threshold will be applied for
    every channel, which means it will still output a colored image.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**阈值化**通常用于简化计算机和用户对图像的可视化方式，以便更容易进行分析。它基于用户设置的一个值，每个像素的值根据是否高于或低于设定值，转换为白色或黑色。如果图像是灰度图，输出图像将是黑白图像，但如果你选择保持RGB格式，阈值将应用于每个通道，这意味着图像仍然是彩色的。'
- en: 'There are different methods for thresholding, and these are some of the most
    used ones:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以进行阈值化，以下是一些常用的阈值方法：
- en: '**Simple Thresholding:** If the pixel value is lower than the threshold set
    by the user, this pixel will be assigned a 0 value (black), or 255 (white). There
    are also different styles of thresholding within simple thresholding:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简单阈值化：**如果像素值低于用户设定的阈值，则该像素将被赋值为0（黑色）或255（白色）。简单阈值化中也有不同的阈值化方式：'
- en: Threshold binary
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值二进制
- en: Threshold binary inverted
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值二进制反转
- en: Truncate
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 截断
- en: Threshold to zero
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值设为零
- en: Threshold to zero inverted
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值设为零反转
- en: The different types of thresholds are shown in figure 2.2
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不同类型的阈值如图 2.2 所示
- en: '![Figure 2.2: Different types of thresholds](img/C13550_02_02.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.2：不同类型的阈值](img/C13550_02_02.jpg)'
- en: 'Figure 2.2: Different types of thresholds'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.2：不同类型的阈值
- en: Threshold binary inverted works like binary but the pixels that were black are
    white and vice versa. Global thresholding is another name given to binary thresholding
    under simple thresholding.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值二进制反转与二进制类似，但原本为黑色的像素变为白色，反之亦然。全局阈值化是简单阈值化下的另一种名称。
- en: Truncate shows the exact value of the threshold if the pixel is above the threshold
    and the pixel value.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 截断显示阈值以上的像素值和实际像素值。
- en: Threshold to zero outputs the pixel value (which is the actual value of the
    pixel) if the pixel value is above the threshold value, otherwise it will output
    a black image, whereas threshold to zero inverted does the exact opposite.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值设为零时，如果像素值高于阈值，它将输出该像素的实际值，否则输出黑色图像，而阈值设为零反转则正好相反。
- en: Note
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The threshold value can be modified depending on the image or what the user
    wants to achieve.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阈值值可以根据图像或用户的需求进行调整。
- en: '**Adaptive Thresholding**: Simple thresholding uses a global value as the threshold.
    If the image has different lighting conditions in some parts, the algorithm does
    not perform that well. In such cases, adaptive thresholding automatically guesses
    different threshold values for different regions within the image, giving us a
    better overall result with varying lighting conditions.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自适应阈值法**：简单阈值使用全局值作为阈值。如果图像某些部分的光照条件不同，算法的表现会比较差。在这种情况下，自适应阈值法会自动为图像的不同区域猜测不同的阈值，从而在不同光照条件下得到更好的整体效果。'
- en: 'There are two types of adaptive thresholding:'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自适应阈值有两种类型：
- en: Adaptive mean thresholding
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自适应均值阈值
- en: Adaptive Gaussian thresholding
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自适应高斯阈值
- en: The difference between the adaptive thresholding and simple thresholding is
    shown in figure 2.3
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自适应阈值与简单阈值的区别如图 2.3 所示
- en: '![Figure 2.3: Difference between adaptive thresholding and simple thresholding](img/C13550_02_03.jpg)'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.3：自适应阈值和简单阈值的区别](img/C13550_02_03.jpg)'
- en: 'Figure 2.3: Difference between adaptive thresholding and simple thresholding'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.3：自适应阈值与简单阈值的区别
- en: In adaptive mean thresholding, the threshold value is the mean of the neighborhood
    area, while in adaptive Gaussian thresholding, the threshold value is the weighted
    sum of the neighborhood values where weights are a Gaussian window.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在自适应均值阈值法中，阈值值是邻域区域的均值，而在自适应高斯阈值法中，阈值值是邻域值的加权和，其中权重是一个高斯窗口。
- en: '**Otsu''s Binarization:** In global thresholding, we used an arbitrary value
    to assign a threshold value. Consider a bimodal image (an image where the pixels
    are distributed over two dominant regions). How would you choose the correct value?
    Otsu''s binarization automatically calculates a threshold value from the image
    histogram for a bimodal image. An **image histogram** is a type of [histogram](https://en.wikipedia.org/wiki/Histogram)
    that acts as a [graphical representation](https://en.wikipedia.org/wiki/Graphical_representation)
    of the [tonal](https://en.wikipedia.org/wiki/Lightness_(color)) distribution in
    a [digital image](https://en.wikipedia.org/wiki/Digital_image):'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**大津二值化法**：在全局阈值法中，我们使用一个任意值作为阈值值。考虑一张双峰图像（像素分布在两个主要区域的图像）。你如何选择正确的阈值？大津二值化法会自动根据图像的直方图计算出适合双峰图像的阈值。**图像直方图**是一种[直方图](https://en.wikipedia.org/wiki/Histogram)，它作为[图形表示](https://en.wikipedia.org/wiki/Graphical_representation)显示了[色调](https://en.wikipedia.org/wiki/Lightness_(color))在[数字图像](https://en.wikipedia.org/wiki/Digital_image)中的分布：'
- en: '![Figure 2.4: Otsu’s thresholding](img/C13550_02_04.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4：大津阈值法](img/C13550_02_04.jpg)'
- en: 'Figure 2.4: Otsu''s thresholding'
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.4：大津阈值法
- en: 'Exercise 4: Applying Various Thresholds to an Image'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 4：将不同的阈值应用于图像
- en: NOTE
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'As we are training artificial neural networks on Google Colab, we should use
    the GPU that Google Colab provides us. In order to do that, we would have to go
    to `runtime > Change runtime type > Hardware accelerator: GPU > Save`.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '由于我们在 Google Colab 上训练人工神经网络，我们应该使用 Google Colab 提供的 GPU。为此，我们需要进入 `runtime
    > Change runtime type > Hardware accelerator: GPU > Save`。'
- en: All the exercises and activities will be primarily developed in Google Colab.
    It is recommended to keep a separate folder for different assignments, unless
    advised not to.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的练习和活动将主要在 Google Colab 中开发。除非另有指示，否则建议为不同的作业保持单独的文件夹。
- en: The `Dataset` folder is available on GitHub in the Lesson02 | Activity02 folder.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dataset` 文件夹可以在 GitHub 的 Lesson02 | Activity02 文件夹中找到。'
- en: 'In this exercise, we will be loading an image of a subway, to which we will
    apply thresholding:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将加载一张地铁图像，并应用阈值处理：
- en: Open up your Google Colab interface.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你的 Google Colab 界面。
- en: Create a folder for the book, download the `Dataset` folder from GitHub, and
    upload it in the folder.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个书籍文件夹，下载 GitHub 上的 `Dataset` 文件夹，并将其上传到该文件夹中。
- en: 'Import the drive and mount it as follows:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式导入驱动器并挂载：
- en: '[PRE0]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Every time you use a new collaborator, mount the drive to the desired folder.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每次使用新协作者时，都需要将驱动器挂载到所需文件夹中。
- en: 'Once you have mounted your drive for the first time, you will have to enter
    the authorization code that you would get by clicking on the URL given by Google
    and pressing the **Enter** key on your keyboard:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦你第一次挂载了驱动器，你将需要输入授权码，这个授权码可以通过点击 Google 提供的 URL 并按下键盘上的 **Enter** 键获得：
- en: '![Figure 2.5: Image displaying the Google Colab authorization step](img/C13550_02_05.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.5：显示 Google Colab 授权步骤的图像](img/C13550_02_05.jpg)'
- en: 'Figure 2.5: Image displaying the Google Colab authorization step'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.5：显示 Google Colab 授权步骤的图像
- en: 'Now that you have mounted the drive, you need to set the path of the directory:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经挂载了驱动器，需要设置目录的路径：
- en: '[PRE1]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The path mentioned in step 5 may change as per your folder setup on Google Drive.
    The path will always begin with `cd /content/drive/My Drive/`.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第 5 步中提到的路径可能会根据你在 Google Drive 上的文件夹设置发生变化。路径总是以`cd /content/drive/My Drive/`开头。
- en: The `Dataset` folder must be present in the path you are setting up.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Dataset` 文件夹必须出现在你设置的路径中。'
- en: 'Now you need to import the corresponding dependencies: OpenCV `cv2` and Matplotlib:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你需要导入相应的依赖：OpenCV `cv2` 和 Matplotlib：
- en: '[PRE2]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now type the code to load the `subway.jpg` image, which we are going to process
    in grayscale using OpenCV and show using Matplotlib:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在输入代码加载 `subway.jpg` 图像，我们将使用 OpenCV 对其进行灰度处理并使用 Matplotlib 显示：
- en: Note
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE3]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure 2.6: Result of plotting the loaded subway image](img/C13550_02_06.jpg)'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.6：绘制加载的地铁图像结果](img/C13550_02_06.jpg)'
- en: 'Figure 2.6: Result of plotting the loaded subway image'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.6：绘制加载的地铁图像结果
- en: Let's apply simple thresholding by using OpenCV methods.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过使用 OpenCV 方法应用简单的阈值化处理。
- en: 'The method for doing so in OpenCV is called **cv2.threshold** and it takes
    three parameters: **image** (grayscale), **threshold value** (used to classify
    the pixel values), and **maxVal**, which represents the value to be given if the
    pixel value is more than (sometimes less than) the threshold value:'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 OpenCV 中执行此操作的方法称为 **cv2.threshold**，它需要三个参数：**image**（灰度图像）、**threshold value**（用于分类像素值的阈值），以及
    **maxVal**，它表示当像素值大于（有时小于）阈值时所给出的值：
- en: '[PRE4]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure 2.7: Simple thresholding using OpenCV](img/C13550_02_07.jpg)'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.7：使用 OpenCV 进行简单阈值化](img/C13550_02_07.jpg)'
- en: 'Figure 2.7: Simple thresholding using OpenCV'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.7：使用 OpenCV 进行简单阈值化
- en: We are going to do the same with adaptive thresholding.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将对自适应阈值化做同样的操作。
- en: 'The method for doing so is **cv2.adaptiveThreshold** and it has three special
    input parameters and only one output argument. Adaptive method, block size (the
    size of the neighborhood area), and C (a constant that is subtracted from the
    mean or weighted mean calculated) are the inputs, whereas you only obtain the
    thresholded image as the output. This is unlike global thresholding, where there
    are two outputs:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 执行此操作的方法是 **cv2.adaptiveThreshold**，它有三个特殊的输入参数和一个输出参数。输入参数为自适应方法、块大小（邻域区域的大小）和
    C（从计算得到的均值或加权均值中减去的常数），而输出参数只有阈值化后的图像。这与全局阈值化不同，后者有两个输出：
- en: '[PRE5]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Figure 2.8: Adaptive thresholding using OpenCV](img/C13550_02_08.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.8：使用 OpenCV 进行自适应阈值化](img/C13550_02_08.jpg)'
- en: 'Figure 2.8: Adaptive thresholding using OpenCV'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.8：使用 OpenCV 进行自适应阈值化
- en: Finally, let's put Otsu's binarization into practice.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将 Otsu 二值化付诸实践。
- en: 'The method is the same as for simple thresholding, **cv2.threshold**, but with
    an extra flag, **cv2.THRESH_OTU**:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法与简单的阈值化相同，**cv2.threshold**，只是多了一个额外的标志，**cv2.THRESH_OTU**：
- en: '[PRE6]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Figure 2.9: Otsu’s binarization using OpenCV](img/C13550_02_09.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.9：使用 OpenCV 进行 Otsu 二值化](img/C13550_02_09.jpg)'
- en: 'Figure 2.9: Otsu''s binarization using OpenCV'
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.9：使用 OpenCV 进行 Otsu 二值化
- en: Now you are able to apply different thresholding transformations to any image.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以对任何图像应用不同的阈值化变换。
- en: Morphological Transformations
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 形态学变换
- en: 'A morphological transformation consists of a set of simple image operations
    based on an image shape, and they are usually used on binary images. They are
    commonly used to differentiate text from the background or any other shapes. They
    need two inputs, one being the original image, and the other is called the **structuring
    element** or **kernel**, which decides the nature of the operation. The **kernel**
    is usually a matrix that slides through the image, multiplying its values by the
    values of the pixels of the image. Two basic morphological operators are erosion
    and dilation. Their variant forms are opening and closing. The one that should
    be used depends on the task at hand:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 形态学变换由一组基于图像形状的简单图像操作组成，通常用于二值图像。它们通常用于区分文本与背景或其他形状。它们需要两个输入，一个是原始图像，另一个称为**结构元素**或**核**，它决定了操作的性质。**核**通常是一个矩阵，它在图像上滑动，将其值与图像像素的值相乘。两个基本的形态学操作是腐蚀和膨胀。它们的变体形式是开运算和闭运算。应该使用哪种操作取决于具体任务：
- en: '**Erosion**: When given a binary image, it shrinks the thickness by one pixel
    both on the interior and the exterior of the image, which is represented by white
    pixels. This method can be applied several times. It can be used for different
    reasons, depending on what you want to achieve, but normally it is used with dilation
    (which is explained in figure 2.10) in order to get rid of holes or noise. An
    example of erosion is shown here with the same digit, 3:'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**腐蚀**：对于给定的二值图像，它会将图像的厚度在内部和外部各收缩一个像素，这些像素由白色像素表示。此方法可以多次应用。根据你想要实现的目标，该方法可以用于不同的目的，但通常它与膨胀一起使用（如图2.10所示），用于去除孔洞或噪声。这里展示的是腐蚀的示例，数字是3：'
- en: '![Figure 2.10: Example of erosion](img/C13550_02_10.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10：腐蚀示例](img/C13550_02_10.jpg)'
- en: 'Figure 2.10: Example of erosion'
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.10：腐蚀示例
- en: '**Dilation**: This method does the opposite of erosion. It increases the thickness
    of the object in a binary image by one pixel both on the interior and the exterior.
    It can also be applied to an image several times. This method can be used for
    different reasons, depending on what you want to achieve, but normally it is implemented
    along with erosion in order to get rid of holes in an image or noise. An example
    of dilation is shown here (we have implemented dilation on the image several times):'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**膨胀**：该方法与腐蚀相反。它通过在二值图像的内部和外部各增加一个像素来增加物体的厚度。该方法也可以对图像多次应用。根据你想要实现的目标，这种方法可以用于不同的目的，但通常它与腐蚀结合使用，以去除图像中的孔洞或噪声。下面是膨胀的示例（我们已对图像应用了多次膨胀操作）：'
- en: '![Figure 2.11: Example of dilation](img/C13550_02_11.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图2.11：膨胀示例](img/C13550_02_11.jpg)'
- en: 'Figure 2.11: Example of dilation'
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.11：膨胀示例
- en: '**Opening**: This method performs erosion first, followed by dilation, and
    it is usually used for removing noise from an image.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开运算**：该方法首先进行腐蚀，然后进行膨胀，通常用于去除图像中的噪声。'
- en: '**Closing**: This algorithm does the opposite of opening, as it performs dilation
    first before erosion. It is usually used for removing holes within an object:'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**闭运算**：该算法与开运算相反，首先进行膨胀再进行腐蚀。它通常用于去除物体中的孔洞：'
- en: '![Figure 2.12: Examples of opening and closing](img/C13550_02_12.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图2.12：开运算和闭运算示例](img/C13550_02_12.jpg)'
- en: 'Figure 2.12: Examples of opening and closing'
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.12：开运算和闭运算示例
- en: As you can see, the opening method removes random noise from the image and the
    closing method works perfectly in fixing the small random holes within the image.
    In order to get rid of the holes of the output image from the opening method,
    a closing method could be applied.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，开运算方法可以去除图像中的随机噪声，而闭运算方法则能有效修复图像中的小随机孔洞。为了去除开运算输出图像中的孔洞，可以应用闭运算方法。
- en: There are more binary operations, but these are the basic ones.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更多的二值操作，但这些是基本操作。
- en: 'Exercise 5: Applying the Various Morphological Transformations to an Image'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习5：将各种形态学变换应用于图像
- en: 'In this exercise, we will be loading an image of a number, on which we will
    apply the morphological transformations that we have just learned about:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将加载一个数字图像，并对其应用我们刚刚学到的形态学变换：
- en: Open up your Google Colab interface.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你的Google Colab界面。
- en: 'Set the path of the directory:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置目录路径：
- en: '[PRE7]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The path mentioned in step 2 may change, as per your folder setup on Google
    Drive.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 步骤2中提到的路径可能会发生变化，具体取决于你在Google Drive上的文件夹设置。
- en: 'Import the OpenCV, Matplotlib, and NumPy libraries. NumPy here is the fundamental
    package for scientific computing with Python and will help us create the kernels
    applied:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入OpenCV、Matplotlib和NumPy库。NumPy是Python科学计算的基础包，将帮助我们创建应用的卷积核：
- en: '[PRE8]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now type the code to load the `Dataset/three.png` image, which we are going
    to process in grayscale using OpenCV and show using Matplotlib:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在输入代码，加载我们将使用OpenCV处理并通过Matplotlib显示的`Dataset/three.png`图像：
- en: Note
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE9]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Figure 2.13: Result of plotting the loaded image](img/C13550_02_13.jpg)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.13：加载图像的绘制结果](img/C13550_02_13.jpg)'
- en: 'Figure 2.13: Result of plotting the loaded image'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.13：加载图像的绘制结果
- en: Let's apply erosion by using OpenCV methods.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用OpenCV方法应用腐蚀操作。
- en: 'The method used here is **cv2.erode**, and it takes three parameters: the image,
    a kernel that slides through the image, and the number of iterations, which is
    the number of times that it is executed:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里使用的方法是**cv2.erode**，它有三个参数：图像、在图像上滑动的卷积核和迭代次数，表示执行的次数：
- en: '[PRE10]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Figure 2.14: Output of the erosion method using OpenCV](img/C13550_02_14.jpg)'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.14：使用OpenCV的腐蚀方法的输出结果](img/C13550_02_14.jpg)'
- en: 'Figure 2.14: Output of the erosion method using OpenCV'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.14：使用OpenCV的腐蚀方法的输出结果
- en: As we can see, the thickness of the figure has decreased.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，图形的厚度减少了。
- en: We are going to do the same with dilation.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将对膨胀进行相同的操作。
- en: 'The method used here is **cv2.dilate**, and it takes three parameters: the
    image, the kernel, and the number of iterations:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里使用的方法是**cv2.dilate**，它有三个参数：图像、内核和迭代次数：
- en: '[PRE11]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure 2.15: Output of the dilation method using OpenCV](img/C13550_02_15.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.15：使用OpenCV的膨胀方法的输出结果](img/C13550_02_15.jpg)'
- en: 'Figure 2.15: Output of the dilation method using OpenCV'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.15：使用OpenCV的膨胀方法的输出结果
- en: As we can see, the thickness of the figure has increased.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，图形的厚度增加了。
- en: Finally, let's put opening and closing into practice.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们把开运算和闭运算应用到实践中。
- en: 'The method used here is **cv2.morphologyEx**, and it takes three parameters:
    the image, the method applied, and the kernel:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里使用的方法是**cv2.morphologyEx**，它有三个参数：图像、应用的方法和内核：
- en: '[PRE12]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Figure 2.16: Output of the opening method (left) and closing method (right)
    using OpenCV](img/C13550_02_16.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.16：使用OpenCV的开运算方法（左）和闭运算方法（右）的输出结果](img/C13550_02_16.jpg)'
- en: 'Figure 2.16: Output of the opening method (left) and closing method (right)
    using OpenCV'
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.16：使用OpenCV的开运算方法（左）和闭运算方法（右）的输出结果
- en: Note
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The entire code file can be found on GitHub in the Lesson02 | Exercise05 folder.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 整个代码文件可以在GitHub的Lesson02 | Exercise05文件夹中找到。
- en: Blurring (Smoothing)
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模糊（平滑）
- en: 'Image blurring performs convolution over an image with a filter kernel, which
    in simpler terms is multiplying a matrix of specific values on every part of the
    image, in order to smooth it. It is useful for removing noise and edges:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图像模糊通过滤波器内核在图像上执行卷积，简而言之，就是在图像的每一部分上乘以特定值的矩阵，以平滑图像。它有助于去除噪声和边缘：
- en: '**Averaging**: In this method, we consider a box filter or kernel that takes
    the average of the pixels within the area of the kernel, replacing the central
    element by using convolution over the entire image.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值滤波**：在这种方法中，我们考虑一个盒子滤波器或内核，它计算内核区域内像素的平均值，通过卷积将中央元素替换为整个图像的平均值。'
- en: '**Gaussian Blurring**: The kernel applied here is Gaussian, instead of the
    box filter. It is used for removing Gaussian noise in a particular image.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高斯模糊**：这里应用的内核是高斯内核，而不是盒子滤波器。它用于去除图像中的高斯噪声。'
- en: '**Median Blurring**: Similar to averaging, but this one replaces the central
    element with the median value of the pixels of the kernel. It actually has a very
    good effect on salt-and-pepper noise (that is, visible black or white spots in
    an image).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中值模糊**：类似于均值滤波，但它用内核像素的中位数值替代中央元素。它对去除椒盐噪声（即图像中可见的黑白斑点）有很好的效果。'
- en: 'In Figure 2.17, we have applied the aforementioned methods:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 2.17 中，我们应用了上述方法：
- en: '![Figure 2.17: Result of comparing different blurring methods](img/C13550_02_17.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.17：不同模糊方法对比的结果](img/C13550_02_17.jpg)'
- en: 'Figure 2.17: Result of comparing different blurring methods'
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.17：不同模糊方法对比的结果
- en: There are many more algorithms that could be applied, but these are the most
    important ones.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他算法可以应用，但这些是最重要的。
- en: 'Exercise 6: Applying the Various Blurring Methods to an Image'
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 6：将各种模糊方法应用于图像
- en: 'In this exercise, we will be loading an image of a subway, to which we will
    apply the blurring method:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将加载一张地铁图像，并对其应用模糊方法：
- en: Open up your Google Colab interface.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你的Google Colab界面。
- en: 'Set the path of the directory:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置目录的路径：
- en: '[PRE13]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The path mentioned in step 2 may be different according to your folder setup
    on Google Drive.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第2步中提到的路径可能会根据你在Google Drive上的文件夹设置有所不同。
- en: 'Import the OpenCV, Matplotlib, and NumPy libraries:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入OpenCV、Matplotlib和NumPy库：
- en: '[PRE14]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Type the code to load the `Dataset/subway.png` image that we are going to process
    in grayscale using OpenCV and show it using Matplotlib:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入代码以加载我们将要处理的`Dataset/subway.png`图像，使用OpenCV将其转换为灰度图像，并用Matplotlib显示：
- en: Note
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE15]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Figure 2.18: Result of plotting the loaded subway image in RGB](img/C13550_02_18.jpg)'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.18：以RGB格式绘制加载的地铁图像的结果](img/C13550_02_18.jpg)'
- en: 'Figure 2.18: Result of plotting the loaded subway image in RGB'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.18：以RGB格式绘制加载的地铁图像的结果
- en: 'Let''s apply all the blurring methods:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们应用所有的模糊方法：
- en: 'The methods applied are **cv2.blur**, **cv2.GaussianBlur**, and **cv2.medianBlur**.
    All of them take an image as the first parameter. The first method takes only
    one argument, that is, the kernel. The second method takes the kernel and the
    standard deviation (sigmaX and sigmaY), and if both are given as zeros, they are
    calculated from the kernel size. The method mentioned last only takes one more
    argument, which is the kernel size:'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应用的方法有**cv2.blur**、**cv2.GaussianBlur**和**cv2.medianBlur**。它们都以图像作为第一个参数。第一种方法只接受一个参数，即内核。第二种方法需要内核和标准差（sigmaX
    和 sigmaY），如果这两个参数都为零，则根据内核大小计算。最后提到的方法只需再加一个参数，即内核大小：
- en: '[PRE16]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Figure 2.19: Blurring methods with OpenCV](img/C13550_02_19.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.19：使用 OpenCV 的模糊方法](img/C13550_02_19.jpg)'
- en: 'Figure 2.19: Blurring methods with OpenCV'
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.19：使用 OpenCV 的模糊方法
- en: Now you know how to apply several blurring techniques to any image.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道如何将几种模糊技术应用于任何图像。
- en: 'Exercise 7: Loading an Image and Applying the Learned Methods'
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7：加载图像并应用已学方法
- en: In this exercise, we will be loading an image of a number and we will apply
    the methods that we have learned so far.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将加载一张数字图像，并应用我们到目前为止学到的方法。
- en: Note
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The entire code is available on GitHub in the Lesson02 | Exercise07-09 folder.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 整个代码可以在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。
- en: Open up a new Google Colab interface, and mount your drive as mentioned in *Exercise
    4*, *Applying the Various Thresholds to an Image*, of this chapter.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Google Colab 界面，并按照本章*练习 4*中提到的方法，挂载你的 Google Drive。
- en: 'Set the path of the directory:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置目录的路径：
- en: '[PRE17]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The path mentioned in step 2 may be different according to your folder setup
    on Google Drive.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第 2 步中提到的路径可能根据你在 Google Drive 上的文件夹设置有所不同。
- en: 'Import the corresponding dependencies: NumPy, OpenCV, and Matplotlib:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相应的依赖项：NumPy、OpenCV 和 Matplotlib：
- en: '[PRE18]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Type the code to load the `Dataset/number.jpg` image, which we are going to
    process in grayscale using OpenCV and show using Matplotlib:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入代码加载 `Dataset/number.jpg` 图像，我们将使用 OpenCV 将其处理为灰度图像，并使用 Matplotlib 显示：
- en: Note
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE19]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Figure 2.20: Result of loading the image with the number](img/C13550_02_20.jpg)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.20：加载带数字的图像结果](img/C13550_02_20.jpg)'
- en: 'Figure 2.20: Result of loading the image with the number'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.20：加载带数字的图像结果
- en: If you want to recognize those digits using machine learning or any other algorithm,
    you need to simplify the visualization of them. Using thresholding seems to be
    the first logical step to proceed with this exercise. We have learned some thresholding
    methods, but the most commonly used one is Otsu's binarization, as it automatically
    calculates the threshold value without the user providing the details manually.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想使用机器学习或任何其他算法来识别这些数字，你需要简化它们的可视化。使用阈值处理似乎是进行此操作的第一步。我们已经学习了一些阈值处理方法，但最常用的就是大津二值化法，因为它能够自动计算阈值，而不需要用户手动提供细节。
- en: 'Apply Otsu''s binarization to the grayscale image and show it using Matplotlib:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对灰度图像应用大津二值化，并使用 Matplotlib 显示：
- en: '[PRE20]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Figure 2.21: Using Otsu’s binarization thresholding on the image](img/C13550_02_21.jpg)'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.21：在图像上使用大津二值化阈值处理](img/C13550_02_21.jpg)'
- en: 'Figure 2.21: Using Otsu''s binarization thresholding on the image'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.21：在图像上使用大津二值化阈值处理
- en: 'In order to get rid of the lines in the background, we need to do some morphological
    transformations. First, start by applying the closing method:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了去除背景中的线条，我们需要进行一些形态学变换。首先，从应用闭操作方法开始：
- en: '[PRE21]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Figure 2.22: Applying the closing method](img/C13550_02_22.jpg)'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.22：应用闭操作方法](img/C13550_02_22.jpg)'
- en: 'Figure 2.22: Applying the closing method'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.22：应用闭操作方法
- en: Note
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The lines in the background have been removed completely. Now a number prediction
    will be much easier.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 背景中的线条已经完全去除，现在数字的预测会更加容易。
- en: 'In order to fill the holes that are visible in these digits, we need to apply
    the opening method. Apply the opening method to the preceding image:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了填补这些数字中可见的空洞，我们需要应用开操作方法。对前面的图像应用开操作方法：
- en: '[PRE22]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Figure 2.23: Applying the opening method](img/C13550_02_23.jpg)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.23：应用开操作方法](img/C13550_02_23.jpg)'
- en: 'Figure 2.23: Applying the opening method'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.23：应用开操作方法
- en: 'There are still leftovers and imperfections around the digits. In order to
    remove these, a closing method with a bigger kernel would be the best choice.
    Now apply the corresponding method:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数字周围仍然有一些杂质和不完美的地方。为了去除这些，使用更大内核的闭操作方法会是最佳选择。现在应用相应的方法：
- en: '[PRE23]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Figure 2.24: Applying the closing method with a kernel of a bigger size](img/C13550_02_24.jpg)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.24: 使用更大大小的核应用闭运算方法](img/C13550_02_24.jpg)'
- en: 'Figure 2.24: Applying the closing method with a kernel of a bigger size'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 2.24: 使用更大大小的核应用闭运算方法'
- en: Depending on the classifier that you use to predict the digits or the conditions
    of the given image, some other algorithms would be applied.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据你用于预测数字的分类器或给定图像的条件，可能会应用其他算法。
- en: If you want to predict the numbers, you will need to predict them one by one.
    Thus, you should divide the numbers into smaller numbers.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想预测数字，你需要逐一进行预测。因此，你应该将数字分解为更小的数字。
- en: 'Thankfully, OpenCV has a method to do this, and it''s called **cv2.findContours**.
    In order to find contours, we need to invert blacks into whites. This piece of
    code is larger, but it is only required if you want to predict character by character:'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 幸运的是，OpenCV 有一个方法可以实现这一点，它叫做**cv2.findContours**。为了找到轮廓，我们需要将黑色反转为白色。这个代码块较大，但只有在你想要逐个字符进行预测时才需要使用：
- en: '[PRE24]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The entire code with added comments is available on GitHub in the Lesson02 |
    Exercise07-09 folder.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 带有注释的完整代码可在 GitHub 上的 Lesson02 | Exercise07-09 文件夹中找到。
- en: '![Figure 2.25: Extracted digits as the output](img/C13550_02_25.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.25: 提取的数字作为输出](img/C13550_02_25.jpg)'
- en: 'Figure 2.25: Extracted digits as the output'
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 2.25: 提取的数字作为输出'
- en: In the first part of the code, we are finding the **contours** of the image
    (the curve joining all the continuous points along the boundary and of the same
    color or intensity) to find every digit, which we then sort depending on the area
    of each contour (each digit).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码的第一部分，我们正在寻找图像的**轮廓**（连接所有边界上连续点的曲线，这些点的颜色或强度相同），以找到每个数字，之后我们根据每个轮廓（每个数字）的区域进行排序。
- en: After this, we loop over the contours, cropping the original image with the
    given contours, ending up with every number in a different image.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们遍历轮廓，使用给定的轮廓裁剪原始图像，最终将每个数字裁切成不同的图像。
- en: After this, we need to have all the images with the same shape, so we adapt
    the image to a given shape using NumPy and append the image to a list of images
    along with the X position.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要让所有的图像具有相同的形状，因此我们使用 NumPy 将图像调整为给定的形状，并将图像与 X 位置一起添加到图像列表中。
- en: Finally, we sort the list of images using the X position (from left to right,
    so they remain in order) and plot the results. We also save every single digit
    as an image so that we can use every digit separately afterward for any task we
    want.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们根据 X 位置对图像列表进行排序（从左到右，这样它们就保持顺序），并绘制结果。我们还将每个数字保存为单独的图像，以便之后可以单独使用每个数字进行任何任务。
- en: Congratulations! You have successfully processed an image with text in it, obtained
    the text, and extracted every single character, and now the magic of machine learning
    can begin.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经成功处理了一张包含文本的图像，提取出了文本并且分离了每个字符，现在机器学习的魔法可以开始了。
- en: Introduction to Machine Learning
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: '**Machine learning** (**ML**) is the science of making computers learn from
    data without stating any rules. ML is mostly based on models that are trained
    with a lot of data, such as images of digits or features of different objects,
    with their corresponding labels, such as the number of those digits or the type
    of the object. This is called **supervised learning**. There are other types of
    learning, such as **unsupervised learning** and **reinforcement learning**, but
    we will be focusing on supervised learning. The main difference between supervised
    learning and unsupervised learning is that the model learns clusters from the
    data (depending on how many clusters you specify), which are translated into classes.
    Reinforcement learning, on the other hand, is concerned with how software agents
    should take action in an environment in order to increase a reward that is given
    to the agent, which will be positive if the agent is performing the right actions
    and negative otherwise.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）是让计算机从数据中学习而不需要定义规则的科学。机器学习主要基于通过大量数据训练的模型，例如数字图像或不同物体的特征，并与它们相应的标签一起使用，如数字的数量或物体的类型。这被称为**有监督学习**。还有其他类型的学习，例如**无监督学习**和**强化学习**，但我们将重点关注有监督学习。监督学习和无监督学习的主要区别在于，模型从数据中学习聚类（具体的聚类数量取决于你指定的聚类数），这些聚类会被转化为类别。而强化学习则关注软件代理如何在环境中采取行动，以增加奖励，奖励在代理执行正确操作时为正，反之为负。'
- en: In this part of the chapter, we will gain an understanding of machine learning
    and check a variety of models and algorithms, going from the most basic models
    to explaining artificial neural networks.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的这一部分，我们将理解机器学习并检查各种模型和算法，从最基本的模型到解释人工神经网络。
- en: Decision Trees and Boosting Algorithms
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决策树和提升算法
- en: In this section, we will be explaining decision trees and boosting algorithms
    as some of the most basic machine learning algorithms.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解释决策树和提升算法作为最基本的机器学习算法之一。
- en: '**Bagging** (decision trees and random forests) and **boosting** (AdaBoost)
    will be explained in this topic.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**装袋**（决策树和随机森林）和**提升**（AdaBoost）将在本主题中进行解释。'
- en: 'Bagging:'
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 装袋：
- en: '**Decision trees** are perhaps the most basic machine learning algorithms,
    and are used for classification and regression, but on a basic level, they are
    used for teaching and performing tests.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树**或许是最基本的机器学习算法，用于分类和回归，但基本上主要用于教学和进行测试。'
- en: In a decision tree, every node represents an attribute of the data that is being
    trained on (whether something is true or false), where every branch (line between
    nodes) represents a decision (if something is true, go this way; otherwise, the
    other way) and every leaf represents a final outcome (if all conditions are fulfilled,
    it's a sunflower or a daisy).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在决策树中，每个节点表示正在训练的数据的属性（是否为真），每个分支（节点之间的线）表示一个决策（如果某事为真，则选择这个方向；否则，选择另一个方向），每个叶子表示最终的结果（如果所有条件满足，则是一朵向日葵或雏菊）。
- en: We are now going to use the Iris dataset. This dataset considers sepal width
    and length, along with petal width and length, in order to classify Iris flowers
    as setosa, versicolour, or virginica.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用鸢尾花数据集。该数据集考虑萼片宽度和长度以及花瓣宽度和长度，以便将鸢尾花分类为山鸢尾、变色鸢尾或维吉尼亚鸢尾。
- en: Note
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: 'The Iris dataset can be downloaded from scikit-learn using Python:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用Python从scikit-learn下载鸢尾花数据集：
- en: '[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)'
- en: Scikit-learn is a library that provides useful tools for data mining and data
    analysis.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn是一个提供数据挖掘和数据分析有用工具的库。
- en: 'The following flowchart shows the learning representation of a decision tree
    trained on this dataset. X represents features from the dataset, X0 being sepal
    length, X1 being sepal width, X2 being petal length, and X3 petal width. The ''value''
    tag is how many samples of each category fall into each node. We can see that,
    in the first step, the decision tree already distinguishes setosa from the other
    two by only considering the X2 feature, petal length:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的流程图显示了在这个数据集上训练的决策树的学习表示。X代表数据集中的特征，X0代表萼片长度，X1代表萼片宽度，X2代表花瓣长度，X3代表花瓣宽度。'value'标签表示每个类别的样本落入每个节点的数量。我们可以看到，在第一步中，决策树仅通过考虑X2特征，花瓣长度，就能区分setosa与其他两个类别：
- en: '![Figure 2.26: Graph of a decision tree for the Iris dataset](img/C13550_02_26.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图2.26：鸢尾花数据集的决策树图](img/C13550_02_26.jpg)'
- en: 'Figure 2.26: Graph of a decision tree for the Iris dataset'
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.26：鸢尾花数据集的决策树图
- en: 'Decision trees can be implemented in Python using only a couple of lines thanks
    to scikit-learn:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 由于scikit-learn，可以只用几行代码在Python中实现决策树：
- en: '[PRE25]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`x` and `y` are the features and the labels of the training set, respectively.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '`x`和`y`分别是训练集的特征和标签。'
- en: '`x`, apart from being only columns of data representing those lengths and widths,
    could also be every pixel of the image. In machine learning, when the input data
    is images, every pixel is treated as a feature.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`x`，除了仅代表这些长度和宽度的数据列，还可以是图像的每个像素。在机器学习中，当输入数据是图像时，每个像素被视为一个特征。'
- en: Decision trees are trained for one specific task or dataset and cannot be transferred
    to another similar problem. Nevertheless, several decision trees can be combined
    in order to create bigger models and learn how to generalize. These are called
    **random forests**.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是针对一个特定任务或数据集进行训练的，不能被转移到另一个类似的问题上。尽管如此，可以将多个决策树组合起来以创建更大的模型，并学习如何泛化。这些被称为**随机森林**。
- en: The name forest refers to an ensemble of many decision tree algorithms, following
    the **bagging** method, which states that the combination of several algorithms
    achieves the best result overall. The appearance of the word "random" refers to
    the randomness of the algorithm when selecting the features to take into account
    to split a node.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '"森林"这个名字指的是多种决策树算法的集合，遵循**袋装法**，即多个算法的组合能够取得最佳的整体结果。出现“随机”一词是因为该算法在选择特征来分割节点时具有随机性。'
- en: 'Thanks again to scikit-learn, we can implement the random forest algorithm
    with only a couple of lines, fairly similar to the previous lines:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 再次感谢scikit-learn，我们可以通过几行代码实现随机森林算法，代码与前面非常相似：
- en: '[PRE26]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`n_estimators` stands for the number of underlying decision trees. If you test
    the results with this method, the results will improve for sure.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_estimators`表示底层决策树的数量。如果你使用这个方法测试结果，结果一定会有所提高。'
- en: There are other methods that follow the **boosting** methodology as well. Boosting
    consists of algorithms called **weak learners** that are put together into a weighted
    sum and generate a strong learner, which gives an output. These weak learners
    are trained sequentially, meaning each one of them tries to solve the mistakes
    made by its predecessor.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他一些方法也遵循**提升法**的方法论。提升法包含了所谓的**弱学习器**，这些学习器被组合成加权和，从而生成一个强学习器，并给出输出。这些弱学习器是顺序训练的，也就是说，每个学习器都会尝试解决前一个学习器所犯的错误。
- en: There are many algorithms that use this approach. The most famous ones are AdaBoost,
    gradient boosting, and XGBoost. We are only going to look at AdaBoost as it is
    the most well known and easy to understand.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多算法使用这种方法，最著名的有AdaBoost、梯度提升和XGBoost。我们这里只看AdaBoost，因为它是最著名且最容易理解的。
- en: Boosting
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升法
- en: '**AdaBoost** puts together weak learners in order to form a strong learner.
    The name AdaBoost stands for adaptive boosting, which means that this strategy
    would weigh differently at each point in time. Those examples that are incorrectly
    classified in a single iteration, get a higher weight than the next iteration,
    and vice versa.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '**AdaBoost**将多个弱学习器组合在一起，形成一个强学习器。AdaBoost的名字代表自适应提升，意味着该策略在每个时刻的权重是不同的。在一次迭代中被错误分类的例子，会在下一次迭代中得到更高的权重，反之亦然。'
- en: 'The code for this method is as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的代码如下：
- en: '[PRE27]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`n_estimators` is the maximum number of estimators once boosting is completed.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_estimators`是提升完成后的最大估算器数量。'
- en: 'This method is initialized with a decision tree underneath; thus, the performance
    might not be as good as the random forest. But in order to make a better classifier,
    the random forest algorithm should be used instead:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法的初始化是基于决策树的，因此其性能可能不如随机森林。但为了构建一个更好的分类器，应该使用随机森林算法：
- en: '[PRE28]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Exercise 8: Predicting Numbers Using the Decision Tree, Random Forest, and
    AdaBoost Algorithms'
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习8：使用决策树、随机森林和AdaBoost算法预测数字
- en: In this exercise, we are going to use the digits obtained from the last exercise
    and the models that we have learned in this topic to correctly predict every number.
    To do that, we are going to extract several digits from some samples inside the
    `Dataset/numbers` folder, along with the MNIST dataset to have enough data, so
    the models learn properly. The MNIST dataset is a compound of handwritten digits,
    which go from 0 to 9 with a shape of 28 x 28 x 3, and it is mostly used for researchers
    to test their methods or to play around with. Nevertheless, it can help to predict
    some numbers even though they are not of the same kind. You can check out this
    dataset at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用上一练习中获得的数字和我们在本主题中学习到的模型来正确预测每个数字。为此，我们将从`Dataset/numbers`文件夹中的一些样本中提取几个数字，并结合MNIST数据集以获得足够的数据，从而使模型能够正确学习。MNIST数据集由手写数字组成，数字范围从0到9，形状为28
    x 28 x 3，主要供研究人员测试他们的方法或进行实验。然而，即使这些数字不完全相同，它也能帮助预测某些数字。你可以在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)查看这个数据集。
- en: As the installation of Keras requires TensorFlow, we propose to use Google Colab,
    which is just like a Jupyter notebook but with the difference that your system
    is not being used. Instead, a remote virtual machine is used and everything for
    machine learning and Python is already installed.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 由于安装Keras需要TensorFlow，我们建议使用Google Colab，它类似于Jupyter Notebook，不同之处在于，它不会占用你的本地系统资源，而是使用远程虚拟机，并且所有机器学习和Python相关的库已经预安装好了。
- en: 'Let''s begin the exercise:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始这个练习：
- en: Note
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: We will be continuing the code from Exercise 7, here in the same notebook.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本笔记本中继续从练习7的代码。
- en: Head to the interface on Google Colab, where you executed the code for *Exercise
    7*, *Loading an Image and Applying the Learned Methods.*
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 Google Colab 界面，在那里你执行了*练习7*，*加载图像并应用已学方法*。
- en: 'Import the libraries:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE29]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'We are setting the seed of the random method to 42, which is for reproducibility:
    all random steps have the same randomness and always give the same output. It
    could be set to any number that does not vary.'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将随机方法的种子设为42，以保证可重复性：所有随机步骤具有相同的随机性，始终给出相同的输出。它可以设定为任何不变的数字。
- en: 'Now we are going to import the MNIST dataset:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将导入 MNIST 数据集：
- en: '[PRE30]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the last line of the code, we are loading the data in `x_train`, which is
    the training set (60,000 examples of digits), `y_train`, which are the labels
    of those digits, `x_test`, which is the testing set, and `y_test`, which are the
    corresponding labels. These are in NumPy format.
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在代码的最后一行，我们加载了数据到`x_train`，即训练集（60,000个数字示例），`y_train`，即这些数字的标签，`x_test`，即测试集，和`y_test`，即相应的标签。这些数据是
    NumPy 格式的。
- en: 'Let''s show some of those digits using Matplotlib:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 Matplotlib 来展示其中一些数字：
- en: '[PRE31]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![Figure 2.27: MNIST dataset](img/C13550_02_27.jpg)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.27: MNIST 数据集](img/C13550_02_27.jpg)'
- en: 'Figure 2.27: MNIST dataset'
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 2.27: MNIST 数据集'
- en: Note
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: These digits do not look like the ones that we extracted in the previous exercise.
    In order to make the models properly predict the digits from the image processed
    in the first exercise, we will need to add some of those digits to this dataset.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些数字看起来和我们在上一个练习中提取的数字不同。为了使模型能够正确预测第一练习中处理过的图像中的数字，我们需要将一些这些数字添加到数据集中。
- en: 'Here''s the process for adding new digits that look like the ones we want to
    predict:'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是添加新数字的过程，这些数字看起来像我们想要预测的数字：
- en: Add a Dataset folder with subfolders numbered from 0 to 9 (already done).
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 添加一个包含从0到9编号的子文件夹的 Dataset 文件夹（已完成）。
- en: Get the code from the previous exercise.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 获取前一个练习中的代码。
- en: Use the code to extract all the digits from the images that are stored in '`Dataset/numbers/`'
    (already done).
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用代码提取存储在`'Dataset/numbers/'`中的所有数字（已完成）。
- en: Paste the generated digits to the corresponding folders with the name that corresponds
    to the digit generated (already done).
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将生成的数字粘贴到相应的文件夹中，文件夹名称与生成的数字对应（已完成）。
- en: Add those images to the original dataset (step 5 in this exercise).
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将这些图像添加到原始数据集中（此练习中的步骤5）。
- en: 'To add those images to your training set, these two methods should be declared:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将这些图像添加到训练集中，应该声明以下两个方法：
- en: '[PRE32]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The first method, `list_files()`, lists all the files within a folder with the
    specified extension, which in this case is `jpg`.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个方法，`list_files()`，列出文件夹中所有具有指定扩展名的文件，在本例中是`jpg`。
- en: In the main method, `load_images()`, we are loading the images from those folders,
    which are from the digit folder, with its corresponding label. If the maximum
    is different to –1, we establish a limit to the quantity that is loaded for every
    digit. We do this because there should be similar samples for every digit. Finally,
    we convert the lists to NumPy arrays.
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在主方法`load_images()`中，我们从这些文件夹中加载图像，这些图像来自数字文件夹，并附带相应的标签。如果最大值与-1不同，我们会设定一个加载每个数字的数量的限制。这样做是因为每个数字应有相似的样本。最后，我们将列表转换为
    NumPy 数组。
- en: 'Now we need to add these arrays to the training set so that our models can
    learn how to recognize the extracted digits:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要将这些数组添加到训练集中，以便我们的模型可以学习如何识别提取的数字：
- en: '[PRE33]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After adding those digits using the method declared in the preceding code,
    we concatenate those arrays to the sets created before the for loop mentioned:'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用前面代码中声明的方法添加这些数字后，我们将这些数组与前面创建的集合连接：
- en: '[PRE34]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After this, the `train_test_split` method from `sklearn` is used in order to
    separate those digits – 20% for testing and the rest for training:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之后，使用`sklearn`中的`train_test_split`方法将这些数字分开—20%用于测试，其余部分用于训练：
- en: '[PRE35]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Once done, we concatenate those to the original training and testing sets. We
    have printed the shape of x_train and x_test before and after so those extra 60
    digits can be seen. It goes from shape (60,000, 28, and 28) and (10,000, 28, and
    28) to shape (60,072, 28, and 28) and (10,018, 28, and 28).
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完成后，我们将这些数据与原始的训练集和测试集进行合并。我们在合并之前和之后打印了`x_train`和`x_test`的形状，因此可以看到那额外的60个数字。形状从(60,000,
    28, 28)和(10,000, 28, 28)变为(60,072, 28, 28)和(10,018, 28, 28)。
- en: 'For the models imported from sklearn that we are going to use in this exercise,
    we need to format the arrays to the shape (n samples and array), and now we have
    (n samples, array_height, and array_width):'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们将在本练习中使用的从sklearn导入的模型，我们需要将数组格式化为形状(n个样本和数组)，目前我们有的是(n个样本，数组高度和数组宽度)：
- en: '[PRE36]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We multiply the height and the width of the array in order to get the total
    length of the array, but only in one dimension: (28*28) = (784).'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将数组的高度和宽度相乘，以得到数组的总长度，但只在一个维度中： (28*28) = (784)。
- en: 'Now we are ready to feed the data into the models. We will start training a
    decision tree:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们准备将数据输入到模型中。我们将开始训练一个决策树：
- en: '[PRE37]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In order to see how well this model performs, metric accuracy is used. This
    represents the number of samples from `x_test` that have been predicted, which
    we have already imported from the `metrics` module and from sklearn. Now we will
    be using `accuracy_score()` from that module to calculate the accuracy of the
    model. We need to predict the results from `x_test` using the `predict()` function
    from the model and see whether the output matches the `y_test` labels:'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了查看该模型的表现，我们使用准确率作为度量指标。这表示已被预测的来自`x_test`的样本数，我们已经从`metrics`模块和sklearn导入了该模块。现在，我们将使用该模块中的`accuracy_score()`来计算模型的准确率。我们需要使用模型中的`predict()`函数预测来自`x_test`的结果，并查看输出是否与`y_test`标签匹配：
- en: '[PRE38]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: After that, the accuracy is calculated and printed. The resulting accuracy percentage
    is **87.92%**, which is not a bad result for a decision tree. It can be improved
    though.
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之后，计算并打印准确率。得到的准确率为**87.92%**，对于决策树来说，这并不是一个坏的结果，但它还是可以改进的。
- en: 'Let''s try the random forest algorithm:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试随机森林算法：
- en: '[PRE39]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Following the same methodology to calculate the accuracy, the accuracy obtained
    is **94.75%**, which is way better and could be classified as a good model.
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用相同的计算准确率的方法，得到的准确率是**94.75%**，这比之前的结果好多了，应该可以归类为一个好的模型。
- en: 'Now, we will try AdaBoost initialized with random forest:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将尝试使用初始化为随机森林的AdaBoost：
- en: '[PRE40]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The accuracy obtained using AdaBoost is **95.67%**. This algorithm takes much
    more time than the previous ones but gets better results.
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用AdaBoost获得的准确率为**95.67%**。这个算法比之前的算法花费更多的时间，但得到了更好的结果。
- en: 'We are now going to apply random forest to the digits that were obtained in
    the last exercise. We apply this algorithm because it takes much less time than
    AdaBoost and gives better results. Before checking the following code, you need
    to run the code from the exercise one for the image stored in the `Dataset/number.jpg`
    folder, which is the one used in the first exercise, and for the other two images
    that are extracted for testing in the `Dataset/testing/` folder. Once you have
    done that, you should have five images of digits in your directory for every image,
    ready to be loaded. Here''s the code:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将对上一个练习中获得的数字应用随机森林。我们选择这个算法是因为它比AdaBoost花费的时间要少得多，并且能提供更好的结果。在检查以下代码之前，你需要运行第一个练习中的代码，图像存储在`Dataset/number.jpg`文件夹中，这个图像是第一个练习使用的，还有从`Dataset/testing/`文件夹中提取的另外两张测试图像。完成这些后，你应该在你的目录中有五张数字图像，每张图像都可以加载。下面是代码：
- en: '[PRE41]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![Figure 2.28: Random forest prediction for the digits 1, 6, 2, 1, and 6](img/C13550_02_28.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![图2.28：随机森林对数字1、6、2、1和6的预测](img/C13550_02_28.jpg)'
- en: 'Figure 2.28: Random forest prediction for the digits 1, 6, 2, 1, and 6'
  id: totrans-317
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.28：随机森林对数字1、6、2、1和6的预测
- en: 'Here, we are applying the `predict()` function of the random forest model,
    passing every image to it. Random forest seems to perform pretty well, as it has
    predicted all of the numbers correctly. Let''s try another number that has not
    been used (there is a folder with some images for testing inside the `Dataset`
    folder):'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们应用了随机森林模型的`predict()`函数，将每个图像传递给它。随机森林似乎表现相当好，因为它正确预测了所有数字。让我们尝试另一个未使用过的数字（在`Dataset`文件夹内有一个文件夹包含一些测试图像）：
- en: '![Figure 2.29: Random forest prediction for the digits 1, 5, 8, 3, and 4](img/C13550_02_29.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![图2.29：随机森林对数字1、5、8、3和4的预测](img/C13550_02_29.jpg)'
- en: 'Figure 2.29: Random forest prediction for the digits 1, 5, 8, 3, and 4'
  id: totrans-320
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.29：随机森林对数字1、5、8、3和4的预测
- en: 'It is still performing well with the rest of the digits. Let''s try another
    number:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 它在其余数字上依然表现不错。让我们再尝试一个数字：
- en: '![Figure 2.30: Random forest prediction for the digits 1, 9, 4, 7, and 9](img/C13550_02_30.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![图2.30：随机森林对数字1、9、4、7和9的预测](img/C13550_02_30.jpg)'
- en: 'Figure 2.30: Random forest prediction for the digits 1, 9, 4, 7, and 9'
  id: totrans-323
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.30：随机森林对数字1、9、4、7和9的预测
- en: With the number 7, it seems to be having problems. It is probably because we
    have not introduced enough samples, and due to the simplicity of the model.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 数字 7 似乎存在问题。这可能是因为我们没有引入足够的样本，并且模型的简单性也导致了问题。
- en: Note
  id: totrans-325
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注释
- en: The entire code for this exercise is available on GitHub in the Lesson02 | Exercise07-09
    folder.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 本次练习的完整代码可以在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。
- en: Now, in the next topic, we are going to explore the world of artificial neural
    networks, which are far more capable of achieving these tasks.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在下一个主题中，我们将探索人工神经网络的世界，这些网络在完成这些任务时更为强大。
- en: Artificial Neural Networks (ANNs)
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工神经网络（ANNs）
- en: '**Artificial neural networks** **(ANNs)** are information processing systems
    that are modeled on and inspired by the human brain, which they try to mimic by
    learning how to recognize patterns in data. They accomplish tasks by having a
    well structured architecture. This architecture is composed of several small processing
    units called neurons, which are interconnected in order to solve major problems.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工神经网络**（**ANNs**）是模仿人脑并受其启发的信息处理系统，它们通过学习如何识别数据中的模式来模拟人脑。它们通过具有良好结构的架构来完成任务。该架构由多个小的处理单元（即神经元）组成，这些神经元通过相互连接来解决主要问题。'
- en: ANNs learn by having enough examples in the dataset that they are processing,
    and enough examples means thousands of examples, or even millions. The amount
    of data here can be a disadvantage, since if you do not have this data, you will
    have to create it yourself, and that means that you will probably need a lot of
    money to gather sufficient data.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（ANNs）通过处理数据集中足够的示例来进行学习，足够的示例意味着成千上万，甚至是数百万个示例。这里的数据量可能成为一个劣势，因为如果你没有这些数据，你将不得不自己创建，这意味着你可能需要大量资金来收集足够的数据。
- en: Another disadvantage of these algorithms is that they need to be trained on
    specific hardware and software. They are well trained on high-performance GPUs,
    which are expensive. You can still do certain things using a GPU that does not
    cost that much, but the data will take much longer to be trained. You also need
    to have specific software, such as **TensorFlow**, **Keras**, **PyTorch**, or
    **Fast.AI**. For this book, we will be using TensorFlow and Keras, which runs
    on top of TensorFlow.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法的另一个缺点是它们需要在特定的硬件和软件上进行训练。它们在高性能的 GPU 上训练效果最佳，而这些 GPU 价格昂贵。你仍然可以使用价格较低的
    GPU 做某些事情，但数据训练的时间会更长。你还需要特定的软件，如**TensorFlow**、**Keras**、**PyTorch** 或 **Fast.AI**。对于本书，我们将使用
    TensorFlow 和 Keras，它们运行在 TensorFlow 之上。
- en: 'These algorithms work by taking all of the data as input, in which the first
    layer of neurons acts as the input. After that, every entry is passed to the next
    layer of neurons, where these are multiplied by some value and processed by an
    activation function, which makes "decisions" and passes those values to the next
    layer. The layers in the middle of the network are called hidden layers. This
    process keeps going until the last layer, where the output is given. When introducing
    the MNIST images as input to the neural network, the end of the network should
    have 10 neurons, each neuron representing each digit, and if the neural network
    guesses that an image is a specific digit, then the corresponding neuron will
    be activated. The ANN checks whether it has succeeded for the decision, and if
    not, it performs a correction process called **backpropagation**, where every
    pass of the network is checked and corrected, adjusting the weights of the neurons.
    In Figure 2.31, backpropagation is shown:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法通过将所有数据作为输入来工作，其中第一层神经元作为输入层。之后，每个输入都会传递到下一层神经元，在那里它们会与某些值相乘，并通过激活函数进行处理，该函数做出“决策”并将这些值传递给下一层。网络中间的层被称为隐藏层。这个过程一直持续到最后一层，在那里输出结果。当将
    MNIST 图像作为输入引入神经网络时，网络的最后一层应该有 10 个神经元，每个神经元代表一个数字，如果神经网络猜测某个图像是特定的数字，那么对应的神经元将被激活。人工神经网络检查其决策是否成功，如果没有，它会执行一个叫做**反向传播**的修正过程，在该过程中每次通过网络时都会被检查和修正，调整神经元的权重。图
    2.31 展示了反向传播过程：
- en: '![Figure 2.31: Backpropagation process](img/C13550_02_31.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.31：反向传播过程](img/C13550_02_31.jpg)'
- en: 'Figure 2.31: Backpropagation process'
  id: totrans-334
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.31：反向传播过程
- en: 'Here is a graphical representation of an ANN:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个人工神经网络的图形表示：
- en: '![Figure 2.32: ANN architecture](img/C13550_02_32.jpg)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.32：ANN 架构](img/C13550_02_32.jpg)'
- en: 'Figure 2.32: ANN architecture'
  id: totrans-337
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.32：ANN 架构
- en: In the preceding diagram, we can see the neurons, which is where all the processing
    occurs, and the connections between them, which are the weights of the network.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们可以看到神经元，它们是所有处理发生的地方，以及它们之间的连接，它们是网络的权重。
- en: We are going to gain an understanding of how to create one of these neural networks,
    but first, we need to take a look at the data that we have.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将了解如何创建这些神经网络，但首先，我们需要查看我们所拥有的数据。
- en: In the previous exercise, we had the shapes (60,072 and 784) and (10,018 and
    784) as integer types, and 0 to 255 as pixel values, for training and testing,
    respectively. ANNs perform better and faster with **normalized data**, but what
    is that?
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的练习中，我们使用了形状为（60,072 和 784）以及（10,018 和 784）的整数类型，并且像素值为 0 到 255，分别用于训练和测试。人工神经网络（ANN）在使用**归一化数据**时表现得更好，速度也更快，但这到底是什么意思呢？
- en: 'Having normalized data means converting that 0-255 range of values to a range
    of 0-1\. The values must be adapted to fit between 0 and 1, which means they will
    be float numbers, because there is no other way to fit a higher range of numbers
    into a shorter range So, first we need to convert the data to a float and then
    normalize it. Here''s the code for doing so:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有归一化数据意味着将 0-255 范围的值转换为 0-1 的范围。这些值必须适应在 0 和 1 之间，这意味着它们将是浮动数字，因为没有其他方法可以将更大的数字范围压缩到较小的范围内。因此，首先我们需要将数据转换为浮动类型，然后进行归一化。以下是执行此操作的代码：
- en: '[PRE42]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: For the labels, we also need to change the format to one-hot encoding.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标签，我们也需要将格式转换为独热编码。
- en: 'In order to do that, we need to use a function from Keras, from its `utils`
    package (the name has changed to `np_utils`), called `to_categorical()`, which
    transforms the number of the digit of every label to **one-hot encoding**. Here''s
    the code:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要使用 Keras 中 `utils` 包（现已更名为 `np_utils`）中的一个函数 `to_categorical()`，该函数将每个标签的数字转换为**独热编码**。以下是代码：
- en: '[PRE43]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: If we print the first label of `y_train`, 5, and then we print the first value
    of `y_train` after the conversion, it will output [0\. 0\. 0\. 0\. 0\. 1\. 0\.
    0\. 0\. 0.]. This format puts a 1 in the sixth place of an array of 10 positions
    (because there are 10 numbers) for the number 5 (in the sixth place because the
    first one is for the 0, and not for the 1). Now we are ready to go ahead with
    the architecture of the neural network.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打印 `y_train` 的第一个标签 5，然后打印转换后的 `y_train` 的第一个值，它将输出 [0\. 0\. 0\. 0\. 0\.
    1\. 0\. 0\. 0\. 0.]。这种格式将在一个包含 10 个位置的数组的第六个位置放置 1（因为有 10 个数字），对应数字 5（第六个位置是为了
    0，而不是 1）。现在我们可以继续进行神经网络的架构设计了。
- en: For a basic neural network, dense layers (or **fully connected layers**) are
    employed. These neural networks are also called **fully connected neural networks**.
    These contain a series of neurons that represent the neurons of the human brain.
    They need an activation function to be specified. An activation function is a
    function that takes the input and calculates a weighted sum of it, adding a bias
    and deciding whether it should be activated or not (outputs 1 and 0, respectively).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个基础的神经网络，使用了密集层（或**全连接层**）。这些神经网络也被称为**全连接神经网络**。它们包含一系列神经元，代表人类大脑的神经元。它们需要指定一个激活函数。激活函数是一个对输入进行加权求和、加上偏置并决定是否激活的函数（分别输出
    1 或 0）。
- en: 'The two most used activation functions are sigmoid and ReLU, but ReLU has demonstrated
    better performance overall. They are represented on the following chart:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的激活函数是 Sigmoid 和 ReLU，但 ReLU 在整体上表现更好。它们在下图中表示：
- en: '![Figure 2.33: The sigmoid and ReLU functions](img/C13550_02_33.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.33：Sigmoid 和 ReLU 函数](img/C13550_02_33.jpg)'
- en: 'Figure 2.33: The sigmoid and ReLU functions'
  id: totrans-350
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.33：Sigmoid 和 ReLU 函数
- en: The sigmoid and ReLU functions calculate the weighted sum and add the bias.
    They then output a value depending on the value of that calculation. The sigmoid
    function will give different values depending on the value of the calculation,
    from 0 to 1\. But ReLU will give 0 for negative values or return the value of
    the calculation for positive values.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 和 ReLU 函数计算加权和并添加偏置。然后它们根据该计算的值输出一个值。Sigmoid 函数会根据计算结果的值给出不同的值，范围从 0
    到 1。而 ReLU 函数则对于负值输出 0，对于正值输出计算结果的值。
- en: Toward the end of a neural network, normally the **softmax** activation function
    takes place, which will output a non-probabilistic number for every class, which
    is higher for the class that has the highest chance of corresponding to the input
    image. There are other activation functions, but this one is the best for the
    output of a network for multi-classification problems.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络的最后，通常会使用 **softmax** 激活函数，它将为每个类别输出一个非概率数值，该数值对于最可能与输入图像匹配的类别来说会更高。还有其他激活函数，但对于多分类问题，softmax
    是最适合的输出函数。
- en: 'In **Keras**, a neural network could be coded as follows:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Keras**中，神经网络的代码如下：
- en: '[PRE44]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The model is created as `Sequential()` as the layers are created sequentially.
    First, we add a dense layer with 16 neurons and the shape of the input is passed
    so that the neural network knows the shape of the input. After which, the `ReLU`
    activation function is applied. We use this function because it generally gives
    good results. We stack another layer with eight neurons and the same activation
    function.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 模型创建为 `Sequential()`，因为层是按顺序创建的。首先，我们添加一个包含 16 个神经元的密集层，并传递输入的形状，以便神经网络知道输入的形状。接着，应用
    `ReLU` 激活函数。我们使用这个函数是因为它通常能给出很好的结果。然后，我们叠加另一个具有 8 个神经元且使用相同激活函数的层。
- en: At the end, we use the `Flatten` function to convert the array to one dimension
    and then the last dense layer is stacked, where the number of classes should represent
    the number of neurons (in this case, there would be 10 classes for the MNIST dataset).
    The softmax function is applied in order to get the results as a one-hot encoder,
    as we have mentioned before.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 `Flatten` 函数将数组转换为一维，然后叠加最后一个密集层，其中类别数应表示神经元的数量（在这种情况下，MNIST 数据集有 10
    个类别）。应用 softmax 函数，以便获得一热编码的结果，正如我们之前提到的。
- en: 'Now we have to compile the model. In order to do that, we use the `compile`
    method as follows:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要编译模型。为此，我们使用如下的 `compile` 方法：
- en: '[PRE45]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: We pass the loss function, which is used to calculate the error for the backpropagation
    process. For this problem, we will be using categorial cross-entropy as the loss
    function, as this is a categorical problem. The optimizer used is **Adadelta**,
    which performs very well in most situations. We establish accuracy as the main
    metric to be considered in the model.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传入损失函数，用于计算反向传播过程中的误差。对于这个问题，我们将使用分类交叉熵作为损失函数，因为这是一个分类问题。使用的优化器是**Adadelta**，它在大多数情况下表现很好。我们将准确率作为模型的主要评价指标。
- en: 'We are going to use what is called a callback in Keras. These are called in
    every epoch during training. We will be using the `Checkpoint` function in order
    to save our model with the best validation result on every epoch:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在 Keras 中的回调函数。这些函数在每个 epoch 训练过程中都会被调用。我们将使用 `Checkpoint` 函数，以便在每个 epoch
    上保存我们具有最佳验证结果的模型：
- en: '[PRE46]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The function to train this model is called `fit()` and is implemented as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练这个模型的函数叫做 `fit()`，其实现如下：
- en: '[PRE47]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We pass the training set with its labels, and we establish a batch size of 64
    (these are the images that are passed on every step of every epoch), out of which
    we choose to have 10 training epochs (on every epoch the data is processed). The
    validation set is also passed in order to see how the model performs on unseen
    data, and at the end, we set the callback that we created before.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传入训练集及其标签，并设置批次大小为 64（这些是每个 epoch 步骤中传递的图像），我们选择设置 10 次训练 epoch（每个 epoch 都会处理数据）。还传入验证集，以便查看模型在未见数据上的表现，最后，我们设置之前创建的回调函数。
- en: All these parameters have to be adjusted according to the problem that we are
    facing. In order to put all of this into practice, we are going to perform an
    exercise – the same exercise that we did with decision trees, but with neural
    networks.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些参数必须根据我们面临的问题进行调整。为了将这一切付诸实践，我们将进行一个练习——这是我们在决策树中做过的相同练习，但这次使用的是神经网络。
- en: 'Exercise 9: Building Your First Neural Network'
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 9：构建你的第一个神经网络
- en: Note
  id: totrans-367
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: We will be continuing the code from Exercise 8 here.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续在这里编写练习 8 中的代码。
- en: The entire code for this exercise can be found on GitHub in the Lesson02 | Exercise07-09
    folder.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的完整代码可以在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。
- en: Head to the interface on Google Colab where you executed the code for *Exercise
    8*, *Predicting Numbers Using the Decision Tree, Random Forest, and AdaBoost Algorithms*.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往你在 Google Colab 上执行 *练习 8*，*使用决策树、随机森林和 AdaBoost 算法预测数字* 的界面。
- en: 'Now import the packages from the Keras library:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在从Keras库导入所需的包：
- en: '[PRE48]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We normalize the data as we explained in this part of the chapter. We also
    declare the `input_shape` instance that will be passed to the neural network,
    and we print it:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按照本章中解释的方法对数据进行归一化处理。我们还声明了将传递给神经网络的`input_shape`实例，并打印出来：
- en: '[PRE49]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 2.34: Data output when passed for normalization using neural networks](img/C13550_02_34.jpg)'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.34：通过神经网络归一化处理后的数据输出](img/C13550_02_34.jpg)'
- en: 'Figure 2.34: Data output when passed for normalization using neural networks'
  id: totrans-377
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.34：通过神经网络归一化处理后的数据输出
- en: 'Now we are going to declare the model. The model that we built before was never
    going to perform well enough on this problem, so we have created a deeper model
    with more neurons and with a couple of new methods:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将声明模型。我们之前构建的模型在这个问题上表现并不理想，所以我们创建了一个更深的模型，增加了更多神经元，并加入了一些新的方法：
- en: '[PRE50]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We have added a `BatchNormalization()` method, which helps the network converge
    faster and may give better results overall.
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们添加了一个`BatchNormalization()`方法，它帮助网络更快地收敛，并可能整体上获得更好的结果。
- en: We have also added the `Dropout()` method, which helps the network to avoid
    **overfitting** (the accuracy of the training set is much higher than the accuracy
    of the validation set). It does that by disconnecting some neurons during training
    (0.2 -> 20% of neurons), which allows better generalization of the problem (better
    classification of unseen data).
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还添加了`Dropout()`方法，它帮助网络避免**过拟合**（训练集的准确率远高于验证集的准确率）。它通过在训练过程中断开一些神经元（0.2 ->
    20%的神经元），从而实现更好的问题泛化（更好地分类未见过的数据）。
- en: Furthermore, the number of neurons has increased drastically. Also, the number
    of layers has increased. The more layers and neurons are added, the deeper the
    understanding is and more complex features are learned.
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，神经元的数量大幅增加。层数也有所增加。随着层数和神经元的增加，理解会更深，学习到的特征也更复杂。
- en: 'Now we compile the model using categorical cross-entropy, as there are several
    classes, and we use Adadelta, which is great overall for these kinds of tasks.
    Also, we use accuracy as the main metric:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们使用分类交叉熵来编译模型，因为有多个类别，并且使用Adadelta，它在这些任务中表现非常好。同时，我们将准确率作为主要度量标准：
- en: '[PRE51]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let''s create the `Checkpoint` callback, where the model will be stored in
    the `Models` folder with the name `model.h5`. We will be using validation loss
    as the main method to be tracked and the model will be saved in its entirety:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建`Checkpoint`回调函数，其中模型将存储在`Models`文件夹中，文件名为`model.h5`。我们将使用验证损失作为主要的追踪方法，模型会被完整保存：
- en: '[PRE52]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Start to train the network with the `fit()` function, just like we explained
    before. We use 64 as the batch size, 10 epochs (which is enough as every epoch
    is going to last a very long time and between epochs it will not improve that
    much), and we will introduce the Checkpoint callback:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始使用`fit()`函数训练网络，就像我们之前解释的那样。我们使用64作为批次大小，10个epochs（足够了，因为每个epoch会持续很长时间，而且每个epoch之间的改善不会太大），并引入Checkpoint回调函数：
- en: '[PRE53]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This is going to take a while.
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将花费一些时间。
- en: 'The output should look like this:'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该是这样的：
- en: '![Figure 2.35: Neural network output](img/C13550_02_35.jpg)'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.35：神经网络输出](img/C13550_02_35.jpg)'
- en: 'Figure 2.35: Neural network output'
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.35：神经网络输出
- en: The final accuracy of the model corresponds to the last `val_acc`, which is
    **97.83%.** This is a better result than we got using AdaBoost or random forest.
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型的最终准确率对应于最后的`val_acc`，为**97.83%**。这个结果比我们使用AdaBoost或随机森林时获得的结果更好。
- en: 'Now let''s make some predictions:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们进行一些预测：
- en: '[PRE54]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The code looks similar to the code used in the last exercise but has some minor
    differences. One is that, as we changed the input format, we have to change the
    format of the input image too (float and normalize). The other is that the prediction
    is in one-hot encoding, so we use the `argmax()` NumPy function in order to get
    the position of the maximum value of the one-hot output vector, which would be
    the predicted digit.
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码与上一练习中使用的代码相似，但有一些细微的不同。其中之一是，由于我们更改了输入格式，我们也需要更改输入图像的格式（浮动和归一化）。另一个是预测采用了one-hot编码，因此我们使用`argmax()`的NumPy函数来获取one-hot输出向量中最大值的位置，这将是预测的数字。
- en: 'Let''s see the output of the last number that we tried using random forest:'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看看我们之前使用随机森林时尝试的最后一个数字的输出：
- en: '![Figure 2.36: Prediction of numbers using neural networks](img/C13550_02_36.jpg)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![图2.36：使用神经网络预测数字](img/C13550_02_36.jpg)'
- en: 'Figure 2.36: Prediction of numbers using neural networks'
  id: totrans-399
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.36：使用神经网络预测数字
- en: The output has been successful – even the 7 that the random forest model struggled
    with.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 预测已成功——即使是随机森林模型困难的7也分类成功。
- en: Note
  id: totrans-401
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The entire code can be found on GitHub in the Lesson02 | Exercise07-09 folder.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码可以在GitHub的Lesson02 | Exercise07-09文件夹中找到。
- en: If you try the other numbers, it will classify them all very well – it has learned
    how to.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试其他数字，它都会很好地分类——它已经学会了如何分类。
- en: Congratulations! You have built your first neural network and you have applied
    it to a real-world problem! Now you are ready to go through the activity for this
    chapter.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经构建了你的第一个神经网络，并将其应用于现实世界的问题！现在你可以继续进行本章的活动了。
- en: 'Activity 2: Classify 10 Types of Clothes from the Fashion-MNIST Database'
  id: totrans-405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动2：从Fashion-MNIST数据库中分类10种衣物类型
- en: 'Now you are going to face a similar problem to the previous one but with types
    of clothes. This database is very similar to the original MNIST. It has 60,000
    images – 28x28 in grayscale – for training and 10,000 for testing. You will have
    to follow the steps mentioned in the first exercise as this activity is not focused
    on the real world. You will have to put into practice the abilities learned in
    the last exercise by building a neural network on your own. For this, you will
    have to open a Google Colab notebook. The following steps will guide you in the
    right direction:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你将面临一个与之前类似的问题，但这次涉及的是衣物类型的分类。这个数据库与原始MNIST非常相似，包含60,000张28x28的灰度图像用于训练，10,000张用于测试。你需要按照第一个练习中的步骤进行，因为这个活动并不聚焦于现实世界。你将需要通过构建神经网络来实践在上一个练习中学到的能力。为此，你需要打开一个Google
    Colab笔记本。以下步骤将引导你朝着正确的方向前进：
- en: 'Load the dataset from Keras:'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Keras加载数据集：
- en: '[PRE55]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Note
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The data is preprocessed like MNIST, so the next steps should be similar to
    *Exercise 5*, *Applying the Various Morphological Transformations to an Image*.
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据已像MNIST一样预处理，因此接下来的步骤应该类似于*练习5*，*对图像应用各种形态学变换*。
- en: Import `random` and set the seed to 42\. Import `matplotlib` and plot five random
    samples of the dataset, just as we did in the last exercise.
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`random`并设置种子为42。导入`matplotlib`并绘制数据集中的五个随机样本，方法与上一个练习相同。
- en: Now normalize the data and reshape it to fit properly into the neural network
    and convert the labels to one-hot encoder.
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在对数据进行归一化，并重新调整其形状，以便适配神经网络，并将标签转换为one-hot编码。
- en: Start to build the architecture of the neural network by using dense layers.
    You have to build it inside a method that will return the model.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始构建神经网络的架构，使用全连接层。你需要在一个方法中构建它，该方法将返回模型。
- en: Note
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: We recommend starting off by building a very small, easy architecture and improving
    it by testing it with the given dataset.
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们建议从构建一个非常小且简单的架构开始，通过在给定数据集上进行测试来不断改进它。
- en: Compile the model with the appropriate parameters and start training the neural
    network.
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用合适的参数编译模型并开始训练神经网络。
- en: Once trained, we should make some predictions in order to test the model. We
    have uploaded some images into the same `testing` folder inside the `Dataset`
    folder of the last exercise. Make predictions using those images, just as we did
    in the last exercise.
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦训练完成，我们应该进行一些预测以测试模型。我们已经将一些图像上传到上一个练习的`Dataset`文件夹中的`testing`文件夹。使用这些图像进行预测，方法与上一个练习中相同。
- en: Note
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'You have to consider that the images that were fed into the neural network
    had a black background and the clothes were white, so you should make corresponding
    adjustments to make the image look like those. If needed, you should invert white
    as black and vice versa. NumPy has a method that does that: `image = np.invert(image)`.'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你需要考虑到输入神经网络的图像背景是黑色的，而衣物是白色的，因此你应该做相应的调整，以使图像看起来像这些图像。如果需要，应该将白色和黑色反转。NumPy有一个方法可以做到这一点：`image
    = np.invert(image)`。
- en: 'Check the results:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看结果：
- en: '![Figure 2.37: The output of the prediction is the index of the position in
    this list](img/C13550_02_37.jpg)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
  zh: '![图2.37：预测的输出是该列表中位置的索引](img/C13550_02_37.jpg)'
- en: 'Figure 2.37: The output of the prediction is the index of the position in this
    list'
  id: totrans-422
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.37：预测的输出是该列表中位置的索引
- en: Note
  id: totrans-423
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity is available on page 302.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第302页找到。
- en: Summary
  id: totrans-425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Computer vision is a big field within AI. By understanding this field, you can
    achieve results such as extracting information from an image or generating images
    that look just like they do in real life, for example. This chapter has covered
    image preprocessing for feature extraction using the OpenCV library, which allows
    easy training and prediction for machine learning models. Some basic machine learning
    models have also been covered, such as decision trees and boosting algorithms.
    These served as an introduction to machine learning and were mostly used to play
    around. Finally, neural networks were introduced and coded using Keras and TensorFlow
    as a backend. Normalization was explained and put into practice, along with dense
    layers, though convolutional layers are known to work better with images than
    dense layers do, and they will be explained later in the book.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是人工智能中的一个重要领域。通过理解这个领域，你可以实现一些目标，例如从图像中提取信息，或生成看起来与现实生活中一模一样的图像。本章介绍了使用OpenCV库进行图像预处理和特征提取的方法，借此可以轻松地训练和预测机器学习模型。还介绍了一些基础的机器学习模型，如决策树和提升算法。这些内容作为机器学习的入门，主要用于实验和玩耍。最后，介绍了神经网络，并使用Keras和TensorFlow作为后端进行编码。讲解了归一化并进行了实践操作，还涉及了全连接层，尽管卷积层比全连接层更适合处理图像，卷积层将在书的后续章节中讲解。
- en: Concepts for avoiding overfitting were also covered, and toward the end, we
    used the model to make predictions and put it into practice using real-world images.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 还介绍了避免过拟合的概念，最后我们使用该模型进行了预测，并通过真实世界的图像进行了实践操作。
- en: In the next chapter, the fundamentals of **natural language processing** (**NLP**)
    will be introduced, along with the most widely used techniques for extracting
    information from a corpus in order to create basic models for language prediction.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，将介绍**自然语言处理**（**NLP**）的基本概念，并展示一些最广泛使用的技术，这些技术用于从语料库中提取信息，以便创建语言预测的基本模型。
