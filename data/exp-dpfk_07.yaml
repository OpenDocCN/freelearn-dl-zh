- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Swapping the Face Back into the Video
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将人脸交换回视频
- en: In this chapter, we’ll complete the deepfake process by converting the videos
    to swap faces using the models trained in the last chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过使用上一章训练的模型将视频转换为交换人脸来完成deepfake过程。
- en: Conversion is the last step of deepfaking, and it is the part that actually
    puts the new face onto the existing video. This requires you to already have a
    video that you have fully processed through the extraction process in [*Chapter
    5*](B17535_05.xhtml#_idTextAnchor090), *Extracting Faces*, and uses a trained
    model from [*Chapter 6*](B17535_06.xhtml#_idTextAnchor107), *Training a* *Deepfake
    Model*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 转换是deepfake的最后一个步骤，这是将新人脸实际放置到现有视频中的部分。这要求你已经有了一个通过提取过程在[*第5章*](B17535_05.xhtml#_idTextAnchor090)，*提取人脸*中完全处理过的视频，并使用[*第6章*](B17535_06.xhtml#_idTextAnchor107)，*训练Deepfake模型*中训练好的模型。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Preparing to convert video
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备转换视频
- en: Getting hands-on with the convert code
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟悉转换代码
- en: Creating the video from images
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从图像创建视频
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you’ll need a `conda` environment setup. If you set this
    up in earlier chapters, the same `conda` environment will work fine. To get into
    the `conda` environment, you can run the following command:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要设置一个`conda`环境。如果你在早期章节中已经设置了这个环境，那么相同的`conda`环境将可以正常工作。要进入`conda`环境，你可以运行以下命令：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you have not created a `conda` environment to run the code, it’s recommended
    that you go to the Git repository and follow the instructions there. You can find
    the full repository at [https://github.com/PacktPublishing/Exploring-Deepfakes](https://github.com/PacktPublishing/Exploring-Deepfakes).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有创建`conda`环境来运行代码，建议你前往Git仓库并遵循那里的说明。你可以在这里找到完整的仓库[https://github.com/PacktPublishing/Exploring-Deepfakes](https://github.com/PacktPublishing/Exploring-Deepfakes)。
- en: Preparing to convert video
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备转换视频
- en: 'Conversion is not just a “one-and-done” script. It requires you to have turned
    a video into a series of frames and run `C5-face_detection.py` on those frames.
    This gets the data that you need for the conversion process in the right form.
    The conversion process will require the full extraction of every frame, as well
    as the `face_alignments.json` file that is generated by the extract process:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 转换不仅仅是一个“一次性的”脚本。它要求你将视频转换成一系列帧，并在这些帧上运行`C5-face_detection.py`。这会以正确的形式获取转换过程所需的数据。转换过程将需要提取每个帧的完整信息，以及由提取过程生成的`face_alignments.json`文件：
- en: '![Figure 7.1 – Example of a folder that has been extracted already. Note the
    face_images folder created by the extract process](img/B17535_07_001.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1 – 已提取的文件夹示例。注意由提取过程创建的`face_images`文件夹](img/B17535_07_001.jpg)'
- en: Figure 7.1 – Example of a folder that has been extracted already. Note the face_images
    folder created by the extract process
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 – 已提取的文件夹示例。注意由提取过程创建的`face_images`文件夹
- en: If you haven’t done the extract process on the video you want to convert, then
    you should go back to [*Chapter 5*](B17535_05.xhtml#_idTextAnchor090), *Extracting
    Faces*, and extract the video.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有对你想要转换的视频进行提取过程，那么你应该回到[*第5章*](B17535_05.xhtml#_idTextAnchor090)，*提取人脸*，并提取视频。
- en: We need to do this because this is how the model knows which faces to convert.
    AI can detect all faces in a frame but won’t know which ones should be swapped,
    meaning that all faces will be swapped. By running the extract process and cleaning
    out the faces we *don’t* want to swap from the folder of extracted faces, we can
    control which faces get swapped.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要这样做，因为这是模型知道要将哪些人脸进行转换的方式。AI可以检测帧中的所有人脸，但不知道哪些应该被交换，这意味着所有的人脸都会被交换。通过运行提取过程并从提取人脸的文件夹中清理掉我们不希望交换的人脸，我们可以控制哪些人脸会被交换。
- en: In addition, you would probably want to include the frames you’re going to convert
    in your training data, in what we call “fit training,” which makes sure your model
    has some experience with the exact frames you’re converting. To do this, go back
    to [*Chapter 6*](B17535_06.xhtml#_idTextAnchor107), *Training a Deepfake Model*,
    and point the “*A*” side of your model to the directory containing the frames
    you’re going to use to convert.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可能还想将你要转换的帧包含在你的训练数据中，我们称之为“拟合训练”，这确保你的模型对你要转换的确切帧有一些经验。为此，回到[*第6章*](B17535_06.xhtml#_idTextAnchor107)，*训练Deepfake模型*，并将你的模型的“*A*”侧指向包含你将要用于转换的帧的目录。
- en: Author’s note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注记
- en: If you’re interested in an “on the fly” conversion process that swaps all faces,
    you can check the exercises page at the end of this chapter, where we raise that
    exact question. In fact, every chapter in this section has a list of exercises
    for you to get your hands dirty and get the experience of writing your own code
    for deepfakes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣的是“即时”转换过程，该过程交换所有人脸，你可以在本章末尾的练习页面上查看，那里我们提出了那个确切的问题。实际上，本节中的每一章都有一个练习列表，供你亲自动手，编写自己的深度伪造代码以获得经验。
- en: Next, let’s look at the convert code.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看转换代码。
- en: Getting hands-on with the convert code
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亲自动手编写转换代码
- en: Like the rest of the chapters in this section, we’ll be going through the code
    line by line to talk about how it works and what it’s doing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 就像本节中其他章节的内容一样，我们将逐行分析代码，讨论其工作原理和所执行的操作。
- en: Initialization
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化
- en: 'Here we will initialize and prepare the code to run the convert process:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将初始化并准备代码以运行转换过程：
- en: 'Like all Python code, we’ll start with the imports:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像所有的 Python 代码一样，我们将从导入开始：
- en: '[PRE1]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These libraries are all ones we’ve already seen in previous chapters. This is
    because the conversion process is not really doing anything too different from
    what we’ve done before. We’ll see that as we go through the code to covert the
    face back into the original images.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库都是我们在前面的章节中已经见过的。这是因为转换过程实际上并没有做与我们之前所做太大的不同。当我们通过代码将人脸转换回原始图像时，我们会看到这一点。
- en: 'Next, we’ll check whether we’re running from the command line:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将检查我们是否从命令行运行：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This code doesn’t actually do anything but is a common way to set up a Python
    file to run when called. It allows you to import the script into other scripts
    without running those commands.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码实际上并没有做任何事情，但这是设置 Python 文件在调用时运行的常见方式。它允许你将脚本导入到其他脚本中而不运行那些命令。
- en: 'Next, we’ll parse the arguments for the script:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将解析脚本的参数：
- en: '[PRE3]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This code uses the standard `ArgumentParser` library from Python to parse command-line
    arguments. This lets us set defaults to some options and change them if we want:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用 Python 的标准 `ArgumentParser` 库来解析命令行参数。这让我们可以为某些选项设置默认值，并在需要时更改它们：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here we process the arguments, add the path to applicable variables, and pass
    these arguments to the `main()` function, which will actually process the conversion.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们处理参数，添加适用变量的路径，并将这些参数传递给 `main()` 函数，该函数将实际处理转换。
- en: We adjust the path variables to add in the default path. This lets us have JSON
    and export folders within subfolders of the data folder. Otherwise, each would
    have to be specified separately and could be in very different places. You are
    still able to specify a specific folder if you want, but the defaults help keep
    things organized.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调整路径变量以添加默认路径。这让我们可以在数据文件夹的子文件夹中拥有 JSON 和导出文件夹。否则，每个都必须单独指定，并且可能位于非常不同的位置。如果你想要指定特定的文件夹，你仍然可以这样做，但默认设置有助于保持事物组织有序。
- en: 'We now move back up to the start of the main function:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在回到主函数的开始部分：
- en: '[PRE5]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Again, this is just the main function that does the work. It doesn’t actually
    do anything except organize our code and allow us to keep things to a normal “pythonic”
    operation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这只是一个执行工作的主函数。它实际上并没有做任何事情，除了组织我们的代码并允许我们保持正常的“Pythonic”操作。
- en: 'Our next step is to make sure that the folders we’re going to write into exist:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的下一步是确保我们将要写入的文件夹存在：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This section checks the export path and ensures that it already exists, creating
    it if it doesn’t.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本节检查导出路径并确保它已经存在，如果不存在则创建它。
- en: Loading the AI
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载 AI
- en: 'The next step is to load the AI and put it onto the device that it needs to
    be on:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将 AI 加载到它需要运行的设备上：
- en: 'First, we check whether `cuda` is available and whether the CPU override was
    given:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们检查 `cuda` 是否可用以及是否给出了 CPU 覆盖：
- en: '[PRE7]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This code checks whether `cuda` is enabled in PyTorch, and if it is and the
    user hasn’t disabled it with a command line switch, and enables `cuda` for the
    rest of the code accordingly.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码检查 PyTorch 中是否启用了 `cuda`，如果是，并且用户没有通过命令行开关禁用它，那么将相应地启用 `cuda` 以供其余代码使用。
- en: 'Next, we build the AI models with the following code:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用以下代码构建 AI 模型：
- en: '[PRE8]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This code establishes the encoder and decoder. Unlike when we were training,
    we only need one decoder. This is because training requires both faces to be able
    to learn successfully, but once trained, we only need the decoder for the face
    we’re swapping in.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码建立编码器和解码器。与训练时不同，我们只需要一个解码器。这是因为训练需要两个面部才能成功学习，但一旦训练完成，我们只需要用于交换的面部的解码器。
- en: 'Loading model weights comes next:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载模型权重是下一步：
- en: '[PRE9]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This code loads the weights from the trained model. We first load the encoder
    weights. These are always the same, so they get pulled in from the `encoder.pth`
    file, which holds the trained weights for the encoder.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码从训练模型中加载权重。我们首先加载编码器权重。这些总是相同的，因此它们从 `encoder.pth` 文件中提取，该文件包含编码器的训练权重。
- en: For the decoder, by default, we want to load the “b” weights, which are stored
    in the `decoderb.pth` file, but you may want the “a” face to be swapped into the
    “b” image, so we included a command line switch that will load the “a” weights
    from the `decodera.pth` file instead. The weights work identically and correlate
    to the faces that were used to train originally. The exact order doesn’t matter
    since we included the `swap` flag, but only one direction could be default, so
    the “b” face onto the “a” image is the assumption unless overridden here.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于解码器，默认情况下，我们想要加载“b”权重，这些权重存储在 `decoderb.pth` 文件中，但你可能想要将“a”面部交换到“b”图像中，因此我们包含了一个命令行开关，该开关将从
    `decodera.pth` 文件中加载“a”权重。这些权重工作方式相同，并且与最初用于训练的面部相关联。由于我们包含了 `swap` 标志，所以确切的顺序并不重要，但只有一个方向可以是默认的，所以“b”面部到“a”图像的假设，除非在这里被覆盖。
- en: No matter which decoder is loaded, we first load the weights and then assign
    them to the state dictionary of the model. PyTorch handles all the specifics of
    getting the dictionary loaded as matrices and into a form ready to handle tensors.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 无论加载哪个解码器，我们首先加载权重，然后将它们分配给模型的状态字典。PyTorch 处理将字典加载为矩阵以及准备处理张量的所有具体细节。
- en: 'Next, we move the models to the GPU:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将模型移动到 GPU：
- en: '[PRE10]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If the device is set to `cuda`, we load the models onto the GPU. To do this,
    we tell PyTorch to use `cuda` on the models, which will handle the nitty-gritty
    of moving the models from the CPU to the GPU.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设备设置为 `cuda`，我们将模型加载到 GPU 上。为此，我们告诉 PyTorch 在模型上使用 `cuda`，这将处理将模型从 CPU 移动到
    GPU 的所有繁琐细节。
- en: Preparing data
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'Next, we need to get the data loaded and into a format that PyTorch expects:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要将数据加载到 PyTorch 期望的格式中：
- en: 'First, we load the alignment data from a file:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从文件中加载对齐数据：
- en: '[PRE11]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code loads the alignment data from the JSON file saved by the extract process.
    This file includes all the information that we need to be able to pull the face
    from the original image, convert it, and paste it back into the image. This uses
    the information from the extraction instead of doing it on the fly because that
    information is already generated when we created the training data, and re-using
    that data saves a lot of time as well as enables clean up and manual editing of
    the data.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码从提取过程中保存的 JSON 文件中加载对齐数据。此文件包含我们需要的所有信息，以便能够从原始图像中提取面部，将其转换，并将其粘贴回图像。这使用提取信息而不是即时执行，因为当创建训练数据时，该信息已经生成，重新使用这些数据可以节省大量时间，同时还可以实现数据的清理和手动编辑。
- en: You can specify the JSON file to load with the data for the image data that
    you’re converting, but, if left blank, the default locations will be looked at
    which, unless you changed it during extraction, should find the file.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以指定要加载的 JSON 文件，其中包含您正在转换的图像数据，但如果留空，则将检查默认位置，除非您在提取过程中更改了它，否则应该找到该文件。
- en: We use `json_tricks` again because of its very powerful handling of NumPy arrays,
    which automatically loads the arrays back into the correct datatype and matrix
    shape.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次使用 `json_tricks`，因为它对 NumPy 数组的处理非常强大，可以自动将数组加载回正确的数据类型和矩阵形状。
- en: Tip
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: While the inclusion or the description of tools that edit these alignments are
    outside the scope of this book, the Faceswap project does include advanced alignment
    modification tools, including an advanced “manual” tool that allows click-and-drag
    editing of landmarks and faces.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然编辑这些对齐工具的说明超出了本书的范围，但 Faceswap 项目确实包括高级对齐修改工具，包括一个高级的“手动”工具，该工具允许通过点击和拖动编辑地标和面部。
- en: 'The next step is to get a list of images to convert:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是获取要转换的图像列表：
- en: '[PRE12]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This code loads all the images from the folder and then filters the images by
    throwing out any that don’t exist in the alignment data we loaded from the JSON
    data file. This makes sure that we have all the information to convert the image
    since even if a new image were added to the folder, we would need to extract information
    to be able to convert the file anyway.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码从文件夹中加载所有图像，然后通过丢弃JSON数据文件中加载的对齐数据中不存在的任何图像来过滤图像。这确保了我们拥有转换图像所需的所有信息，因为即使文件夹中添加了新图像，我们也需要提取信息才能转换文件。
- en: The conversion loop
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换循环
- en: 'Here, we begin the loop that will go through each individual image one at a
    time to convert them:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们开始循环，逐个处理每个单独的图像以将它们转换：
- en: We’re now entering the loop and loading images.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在进入循环并加载图像。
- en: '[PRE13]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This code loads the image and prepares it for use. First, it gets the filename
    and extension into variables so we can use them again later. It then loads the
    file in **blue, green, red** (**BGR**) color order and converts it into a **red,
    green, blue** (**RGB**)-ordered image as expected by our AI. Then, it saves the
    width, height, and color channels into variables so we can use them again later.
    Finally, it creates a working copy of the output image so that we can swap any
    faces in that image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码加载图像并为其使用做准备。首先，它将文件名和扩展名存储到变量中，以便我们稍后再次使用。然后，它以**蓝、绿、红**（**BGR**）颜色顺序加载文件，并将其转换为AI期望的**红、绿、蓝**（**RGB**）顺序的图像。然后，它将宽度、高度和颜色通道存储到变量中，以便我们稍后再次使用。最后，它创建输出图像的工作副本，以便我们可以交换该图像中的任何面部。
- en: 'Next, we start another loop, this time for faces:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们开始另一个循环，这次是针对面部的：
- en: '[PRE14]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This loop will process each face that is found in the alignment file and swap
    the faces that are found in it.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此循环将处理对齐文件中找到的每个面部，并交换其中找到的面部。
- en: The first thing it does is pull the face from the frame using the pre-computed
    warp matrix that was saved in the alignment file. This matrix allows us to align
    the face and generate a 256x256 image of it.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先使用在对齐文件中保存的预计算变形矩阵从帧中提取面部。这个矩阵使我们能够对齐面部并生成一个256x256的图像。
- en: Next, we convert that face image into a tensor and move the channels into the
    order that PyTorch expects them. The first part of the tensor conversion is to
    convert from an integer range of 0–255 to a standard range of 0–1\. We do this
    by dividing by 255\. Then we use `permute` to reorder the matrix because PyTorch
    wants the channels to be first, while OpenCV has them last.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将面部图像转换为张量，并将通道移动到PyTorch期望的顺序。张量转换的第一部分是将0-255的整数范围转换为0-1的标准范围。我们通过除以255来实现这一点。然后我们使用`permute`重新排列矩阵，因为PyTorch希望通道首先出现，而OpenCV将它们放在最后。
- en: Next, we create a smaller 64x64 copy of the tensor, which is what we’ll actually
    feed into the model. Since we’re doing this one image at a time, we’re effectively
    working with a batch size of 1, but we need to use `unsqueeze` on the tensor to
    create the batch channel of the tensor. This just adds a new dimension of size
    1, which contains the image we want to convert.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建张量的一个较小的64x64副本，这是我们实际上要输入到模型中的。由于我们一次处理一张图像，我们实际上是在处理一个大小为1的批次，但我们需要在张量上使用`unsqueeze`来创建张量的批次通道。这仅仅添加了一个大小为1的新维度，其中包含我们想要转换的图像。
- en: Finally, if we are using `cuda`, we move the smaller aligned face tensor onto
    the GPU so that we can put it through the model there.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们使用`cuda`，我们将较小的对齐面部张量移动到GPU上，以便我们可以在那里通过模型。
- en: 'Then, we send the image through the AI:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将图像通过AI：
- en: '[PRE15]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code does the actual AI swapping, and it’s rather astonishing how small
    it is.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码执行实际的AI交换，它的大小相当令人惊讶。
- en: We start this section by telling PyTorch that we want to run the AI in this
    section without keeping track of gradients by using `torch.no_grad()`. We can
    save a lot of VRAM and run the conversion faster. This isn’t strictly necessary
    here, but it is a good habit to get into.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过使用`torch.no_grad()`告诉PyTorch，我们希望在这一点上运行AI而无需跟踪梯度。这样可以节省大量VRAM并加快转换速度。这在这里不是严格必要的，但养成这个习惯是好的。
- en: Next, we put the tensor containing the 64x64 face through the encoder and then
    the decoder to get a swapped face. The encoder’s output is fed straight into the
    decoder because we don’t need to do anything with the latent encoding.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将包含64x64面部的张量通过编码器，然后通过解码器来获取交换面部。编码器的输出直接输入到解码器，因为我们不需要对潜在编码做任何事情。
- en: 'Here, we apply the mask to the output:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将掩码应用于输出：
- en: '[PRE16]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We want to apply the mask so that we don’t swap a big square box of noise around
    the face. To do this, we will load the mask image and use it to cut out just the
    face from the swap.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望应用这个面具，这样我们就不至于在面部周围交换一个大的方形噪声区域。为此，我们将加载面具图像，并使用它来仅从交换中裁剪出面部。
- en: First, we resize the swapped face up to a 256x256 image. This is done because
    the mask is a 256x256 image, and applying it at a higher resolution helps to get
    the best detail on the edge instead of downscaling the mask to 64x64.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将交换的面部图像调整大小到256x256像素。这样做是因为面具是一个256x256像素的图像，以更高的分辨率应用它有助于在边缘获得最佳细节，而不是将面具下采样到64x64像素。
- en: 'Next, we load the mask image. To do this, we use the aligned face filename
    to generate the mask image filename. We then load that as a grayscale image using
    OpenCV’s image reader:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载面具图像。为此，我们使用对齐的面部文件名生成面具图像文件名。然后，我们使用OpenCV的图像读取器将其作为灰度图像加载：
- en: '![Figure 7.2 – An example of a mask image](img/B17535_07_002.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2 – 面具图像的一个示例](img/B17535_07_002.jpg)'
- en: Figure 7.2 – An example of a mask image
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 面具图像的一个示例
- en: That image is then converted into a tensor using a cutoff point where if a pixel
    of the grayscale mask image’s value is higher than 200 (in a range of 0-255),
    then treat it as a `1`; otherwise, treat it as a `0`. This gives us a clean binary
    mask where the `1` value is a face to swap and `0` is unimportant background.
    We can then use that mask to paste just the swapped face back into the original
    image.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，该图像被转换成一个张量，使用一个截止点，如果灰度面具图像的像素值高于200（在0-255的范围内），则将其视为`1`；否则，将其视为`0`。这给我们提供了一个干净的二进制面具，其中`1`值表示要交换的面部，而`0`表示不重要的背景。然后我们可以使用这个面具将交换的面部粘贴回原始图像。
- en: Finally, we apply the mask to the image. This is done by multiplying the output
    face by the mask and multiplying the original face by the inverse of the mask.
    Effectively, this combines the face from the swap result with the rest of the
    image being pulled from the pre-swapped aligned image.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将面具应用到图像上。这是通过将输出面部乘以面具，并将原始面部乘以面具的逆来完成的。实际上，这是将交换结果中的面部与从预交换对齐图像中提取的其余图像结合在一起。
- en: 'Next, we’ll put the face back in the original image:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将面部放回到原始图像中：
- en: '[PRE17]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This code section completes the face loop. To do this, we apply the face back
    to the output image.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码部分完成了面部循环。为此，我们将面部重新应用到输出图像上。
- en: First, we convert the face tensor back into a NumPy array that OpenCV can work
    with. To do this, we grab the first instance in the tensor; this effectively removes
    the batch size dimension. Then, we’ll use `permute` to move the channels back
    to the end of the matrix. We then have to multiply by 255 to get into the 0–255
    range of an integer. Finally, we convert the variable into an integer, making
    it usable in OpenCV as a proper image.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将面部张量转换回OpenCV可以处理的NumPy数组。为此，我们抓取张量中的第一个实例；这实际上移除了批处理大小维度。然后，我们将使用`permute`将通道移动到矩阵的末尾。然后我们必须乘以255以进入整数0-255的范围。最后，我们将变量转换为整数，使其在OpenCV中作为一个合适的图像使用。
- en: We then use OpenCV’s `cv2.warpAffine` with a couple of flags to copy the face
    back into the original image in its original orientation. The first flag we use
    is `cv2.BORDER_TRANSPARENT`, which makes it so that only the area of the smaller
    aligned face gets changed; the rest of the image is left as it was. Without that
    flag, the image would only include the replaced face square; the rest of the image
    would be black. The other flag we use is `cv2.WARP_INVERSE_MAP`, which tells `cv2.warpAffine`
    that we’re copying the image back into the original image instead of copying part
    of the original image out.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用OpenCV的`cv2.warpAffine`和一些标志将面部以原始方向复制回原始图像。我们使用的第一个标志是`cv2.BORDER_TRANSPARENT`，这使得只有较小的对齐面部区域被改变；其余图像保持不变。如果没有这个标志，图像将只包括替换的面部方块；其余图像将是黑色。我们使用的另一个标志是`cv2.WARP_INVERSE_MAP`，它告诉`cv2.warpAffine`我们正在将图像复制回原始图像，而不是复制原始图像的一部分。
- en: With those two flags, the aligned image of the face gets put back into the correct
    place of the original full-sized image. We do this with a copy of the original
    image so we can copy multiple faces onto the image if multiple faces were found.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个标志，对齐的面部图像被放回到原始全尺寸图像的正确位置。我们这样做是通过原始图像的一个副本来完成的，这样我们就可以在图像上复制多个面部，如果找到了多个面部。
- en: 'Finally, we output the new image with the faces swapped:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们输出带有面部交换的新图像：
- en: '[PRE18]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The last step of the image loop is to write the images in memory to separate
    image files. To do this, we first convert the images back into the BGR color order
    that OpenCV expects. Then we write the file out to the extract path using the
    same original filename with a PNG file type.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图像循环的最后一步是将图像写入内存中的单独图像文件。为此，我们首先将图像转换回OpenCV期望的BGR颜色顺序。然后，我们使用相同的原始文件名和PNG文件类型将文件写入提取路径。
- en: '![Figure 7.3 – Example of originals (top) and swaps (bottom) of Bryan (top
    left) and Matt (top right), the authors](img/B17535_07_003.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3 – 原图（顶部）和交换图（底部）示例，包括布赖恩（左上角）和马特（右上角），作者](img/B17535_07_003.jpg)'
- en: Figure 7.3 – Example of originals (top) and swaps (bottom) of Bryan (top left)
    and Matt (top right), the authors
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 原图（顶部）和交换图（底部）示例，包括布赖恩（左上角）和马特（右上角），作者
- en: Now that we’ve run the conversion on the frames, we need to turn the images
    back into a video. Let’s do that now.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对帧进行了转换，我们需要将图像转换回视频。让我们现在就做。
- en: Creating the video from images
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从图像创建视频
- en: 'The conversion code included produces swapped images, but if we want to create
    a video, we’ll need to combine the output into a video file. There are multiple
    options here, depending on what you want to include:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 包含的转换代码会产生交换图像，但如果我们想创建视频，我们需要将输出组合成视频文件。这里有多个选项，具体取决于你想要包含的内容：
- en: 'The following is for including just the images:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下仅包含图像：
- en: '[PRE19]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This command line will convert all the frames into a video with some default
    options. The `Output.mp4` file will include the frames but won’t include any audio
    and will be at a default frame rate of 25 frames per second. This will be close
    enough to accurate for videos that came from film sources, such as Blu-rays or
    DVDs. If the video looks too fast or too slow, then your frame rate is incorrect,
    and you should look at the next option instead to match the correct frame rate.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令行将使用一些默认选项将所有帧转换为视频。`Output.mp4`文件将包含帧，但不会包含任何音频，并且将以默认的每秒25帧的帧率。对于来自电影源的视频，如蓝光或DVD，这应该足够接近准确。如果视频看起来太快或太慢，那么你的帧率是不正确的，你应该查看下一个选项以匹配正确的帧率。
- en: 'Including the images at a specific frame rate:'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定帧率下包含图像：
- en: '[PRE20]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This command line will include the frames at a specific frame rate. The frame
    rate is something you’ll need to find yourself from your original video. One way
    to do it using `ffmpeg` is to run the following code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令行将包括特定帧率的帧。帧率是你需要从原始视频中自己找到的。使用`ffmpeg`的一种方法是运行以下代码：
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This will output a lot of information, most of which will not be useful to
    us. What we need to do is look for a line containing the “stream” information
    for the video. It will look something like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出大量信息，其中大部分对我们来说可能没有用。我们需要做的是寻找包含“流”信息的行。它看起来可能像这样：
- en: '[PRE22]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The important information here is where it says `59.32 fps`. In this case, we’d
    want to put the `59.32` into the framerate of the `ffmpeg` command.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这里重要的信息是它说`59.32 fps`。在这种情况下，我们想把`59.32`放入`ffmpeg`命令的帧率中。
- en: This option still won’t include any audio.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 此选项仍然不会包含任何音频。
- en: 'Including audio with the video:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在视频中包含音频：
- en: '[PRE23]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This command will convert the video while also copying over audio from the original
    video file. It’s important to use the exact same file for the audio to line up.
    If the audio doesn’t line up correctly, you may want to double-check the frame
    rate and the number of frames.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将在复制原始视频文件中的音频的同时转换视频。使用与音频完全相同的文件来对齐非常重要。如果音频没有正确对齐，你可能需要检查帧率和帧数。
- en: Summary
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we ran the convert process on a folder full of images, replacing
    the faces using a trained model. We also turned the images back into a video,
    including changes to account for frame rate and copying audio.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们在一个包含图像的文件夹上运行了转换过程，使用训练模型替换了人脸。我们还把图像转换回视频，包括对帧率和音频的更改。
- en: We started by going over how to prepare a video for conversion. The convert
    process requires data created by the extract process from [*Chapter 5*](B17535_05.xhtml#_idTextAnchor090),
    *Extracting Faces*, and a trained AI model from [*Chapter 6*](B17535_06.xhtml#_idTextAnchor107),
    *Training a Deepfake Model*. With all the parts from the previous chapters, we
    were ready to convert.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先介绍了如何准备视频进行转换。转换过程需要从[*第5章*](B17535_05.xhtml#_idTextAnchor090)，*提取人脸*，以及从[*第6章*](B17535_06.xhtml#_idTextAnchor107)，*训练深度伪造模型*中创建的数据和训练好的AI模型。有了前几章的所有部分，我们就准备好转换了。
- en: We then walked through the code for the conversion process. This involved looking
    at the initialization, where we covered getting the Python script ready to operate.
    We then loaded the AI models and got them set up to work on a GPU if we have one.
    Next, we got the data ready for us to convert the faces in each frame. Finally,
    we ran two nested loops, which processed every face in every frame, swapping them
    to the other face. This part gave us a folder filled with swapped faces.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后走过了转换过程的代码。这包括查看初始化部分，其中我们介绍了如何让Python脚本准备好运行。然后我们加载了AI模型，并在有GPU的情况下将它们设置好以在GPU上工作。接下来，我们准备好了数据，以便将每一帧中的面部进行转换。最后，我们运行了两个嵌套循环，处理了每一帧中的每一个面部，将它们交换到另一张面部。这一部分给我们留下了一个充满交换面部的文件夹。
- en: After that, we looked at some commands that took the folder of swapped face
    images and returned them into a video form, this involved taking every frame into
    the video, ensuring that the frame rate was correct, and the audio was copied
    if desired.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们查看了一些命令，这些命令将交换面部图像文件夹转换成视频格式，这包括将每一帧放入视频中，确保帧率正确，如果需要，则复制音频。
- en: In the next section, we’ll start looking into the potential future of deepfakes,
    with the next chapter looking at applying the techniques we’ve learned about deepfakes
    to solve other problems.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将开始探讨deepfakes的潜在未来，下一章将探讨将我们学到的deepfakes技术应用于解决其他问题。
- en: Exercises
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: We use the mask to cut out the swapped face from the rest of the image but then
    copy it over to the aligned face. This means that the areas of the aligned image
    that aren’t the face also get a lower resolution. One way to fix this would be
    to apply the mask to the original image instead of the aligned image. To do this,
    you’ll need to call `cv2.warpAffine` separately for the mask and the aligned image,
    then use the mask to get just the face copied over. You may want to view the documentation
    for OpenCV’s `warpAffine` at [https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html](https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html).
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用遮罩从图像中裁剪出交换的面部，并将其复制到对齐的面部上。这意味着对齐图像中不是面部区域的部分也会得到较低的分辨率。一种修复方法是将遮罩应用于原始图像而不是对齐图像。为此，您需要分别对遮罩和对齐图像调用`cv2.warpAffine`，然后使用遮罩仅复制面部。您可能想查看OpenCV的`warpAffine`文档，网址为[https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html](https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html)。
- en: Be sure to account for the fact that OpenCV’s documentation is based on the
    C++ implementation, and things can be a bit different in the Python library. The
    tutorial pages have a **Python** button that lets you switch the tutorial to using
    the Python libraries.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，OpenCV的文档基于C++实现，Python库中可能会有所不同。教程页面有一个**Python**按钮，可以切换教程以使用Python库。
- en: We rely on pre-extracted faces in order to convert. This is because a lot of
    the data is already processed in the extract process and is already available,
    allowing you to filter images/faces that you don’t want to be converted. But if
    you’re running a lot of videos or planning on running conversion on live video,
    it might make sense to allow conversion to run on the fly. To do this, you can
    combine the extract process with convert and run the extraction steps as needed
    before you convert. You can look at the code in `C5-extract.py` and add the appropriate
    parts to the convert process to enable it to work directly on the images.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们依赖于预先提取的面部来进行转换。这是因为大量数据已经在提取过程中被处理，并且已经可用，允许您过滤掉不需要转换的图像/面部。但是，如果您正在运行大量视频或计划在实时视频上进行转换，允许在运行时进行转换可能是有意义的。为此，您可以将提取过程与转换结合起来，并在转换之前按需运行提取步骤。您可以在`C5-extract.py`中查看代码，并将适当的部分添加到转换过程中，以使其能够直接在图像上工作。
- en: We operated the convert process entirely on images, but it’s actually possible
    for Python to work directly with video files. To do this, try installing and using
    a library such as PyAV from [https://github.com/PyAV-Org/PyAV](https://github.com/PyAV-Org/PyAV)
    to read and write directly to video files instead of images. Remember that you
    may need to account for audio data and frame rate in the output.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们完全在图像上操作转换过程，但实际上Python可以直接与视频文件工作。为此，尝试安装并使用PyAV库，网址为[https://github.com/PyAV-Org/PyAV](https://github.com/PyAV-Org/PyAV)，以直接读取和写入视频文件而不是图像。请记住，您可能需要考虑输出中的音频数据和帧率。
- en: One problem with the techniques used in this chapter is that the swapped-in
    face can look pretty obvious at the edges. This is because of a lack of color
    matching and edge blending. Both these techniques can improve the swap’s edges.
    There are a lot of color-matching techniques available; one option is histogram
    matching ([https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html](https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html)).
    You’ll need to match the RGB channels separately. Edge blending is usually done
    by blurring the mask; you can accomplish this by smoothing the mask image with
    OpenCV ([https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html)).
    This can dull the sharp edges of the swap.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章中使用的技术有一个问题是，替换进去的人脸在边缘处可能看起来相当明显。这是因为缺乏颜色匹配和边缘混合。这两种技术都可以改善替换的边缘。有许多颜色匹配技术可供选择；一个选项是直方图匹配
    ([https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html](https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html))。你需要分别匹配RGB通道。边缘混合通常是通过模糊蒙版来完成的；你可以通过使用OpenCV
    ([https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html))来平滑蒙版图像来实现这一点。这可以使替换的锐利边缘变得不那么明显。
- en: The results from our AI here are limited to just 64x64 pixels. There are newer
    models that go higher but are still limited heavily by available GPU memory and
    can take a lot longer to train. To get around this, you could run the output through
    an AI upscaler, such as ESRGAN ([https://github.com/xinntao/Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN)),
    or a face-specific restoration tool, such as GFP-GAN ([https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)).
    See if you can run the model’s output through these before returning the face
    to the original image to get a higher-quality result.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们这里AI的结果仅限于64x64像素。有更新的模型可以达到更高的分辨率，但仍然受到可用GPU内存的严重限制，并且训练时间会更长。为了解决这个问题，你可以在将人脸返回到原始图像之前，通过AI放大器，如ESRGAN
    ([https://github.com/xinntao/Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN))，或者专门用于人脸修复的工具，如GFP-GAN
    ([https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN))，来运行输出。看看你能否在将人脸返回到原始图像之前，通过这些模型来获得更高的质量结果。
- en: EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: EBSCOhost - 2023年11月27日 6:20 AM 打印。所有使用均受[https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)条款约束。
- en: 'Part 3: Where to Now?'
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：现在该往哪里去？
- en: Like all inventions, the development of deepfakes is just the beginning. Now
    that you know how deepfakes work, where can you take that knowledge and what can
    you do with it? You might be surprised at how flexible the techniques can be.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 就像所有发明一样，深度伪造的发展只是开始。现在你已经知道了深度伪造是如何工作的，你可以将这项知识应用到哪里，以及你可以用它做什么？你可能会对技术的灵活性感到惊讶。
- en: 'In this part, we’ll examine some hypothetical projects and how techniques in
    deepfakes could be used to make them easier, as well as solving complicated issues
    that might otherwise stump the average developer (you’re not one of those – after
    all, you bought this book!). Then, we’ll ask the ultimate question: what will
    the future bring? We’ll try to answer it by looking at where generative AI might
    go in the near future, including looking at the limitations and challenges that
    these AI technologies must overcome.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分，我们将探讨一些假设性的项目，以及如何利用深度伪造技术使它们更容易实现，同时解决可能让普通开发者感到棘手的复杂问题（你当然不是那种人——毕竟，你买了这本书！）。然后，我们将提出一个终极问题：未来会带来什么？我们将通过观察生成式AI在近期可能的发展方向来尝试回答这个问题，包括考虑这些AI技术必须克服的限制和挑战。
- en: 'This part comprises the following chapters:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 8*](B17535_08.xhtml#_idTextAnchor136), *Applying the Lessons of Deepfakes*'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B17535_08.xhtml#_idTextAnchor136)，*应用深度伪造的教训*'
- en: '[*Chapter 9*](B17535_09.xhtml#_idTextAnchor152), *The Future of Generative
    AI*'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B17535_09.xhtml#_idTextAnchor152)，*生成式AI的未来*'
- en: EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: EBSCOhost - 2023年11月27日 6:20 AM 打印。所有使用均受[https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)条款约束。
