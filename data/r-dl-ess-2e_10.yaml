- en: Running Deep Learning Models in the Cloud
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云端运行深度学习模型
- en: Up till now, we have only briefly discussed the hardware requirements for training
    deep learning models, as almost all of the examples in this book run on any modern
    computer. While you do not need a **GPU** (**Graphical Processing Unit**) based
    computer to run the examples in this book, there is no getting away from the fact
    that training complicated deep learning models requires a computer with a GPU.
    Even if you have a suitable GPU on your machine, installing the necessary software
    to train deep learning models using GPUs is not a trivial task. This section will
    briefly discuss how to install the necessary software to run deep learning models
    on GPUs and also discusses the advantages and disadvantages of using cloud computing
    for deep learning. We will use various cloud providers to create virtual instances
    or access services that will allow us to train deep learning models in the cloud.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只简要讨论了训练深度学习模型的硬件要求，因为本书中的几乎所有示例都可以在任何现代计算机上运行。虽然你不需要一台基于**GPU**（**图形处理单元**）的计算机来运行本书中的示例，但不可否认的是，训练复杂的深度学习模型需要一台带有GPU的计算机。即使你的计算机上有合适的GPU，安装必要的软件以便使用GPU训练深度学习模型也不是一件简单的事。本节将简要讨论如何安装必要的软件，以便在GPU上运行深度学习模型，并讨论使用云计算进行深度学习的优缺点。我们将使用各种云服务提供商创建虚拟实例或访问服务，从而使我们能够在云端训练深度学习模型。
- en: 'This chapter covers the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Setting up a local computer for deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置本地计算机以进行深度学习
- en: Using Amazon Web Services (AWS) for deep learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Amazon Web Services（AWS）进行深度学习
- en: Using Azure for deep learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Azure进行深度学习
- en: Using Google Cloud for deep learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google Cloud进行深度学习
- en: Using Paperspace for deep learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Paperspace进行深度学习
- en: Setting up a local computer for deep learning
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置本地计算机以进行深度学习
- en: At the time of writing this book, it is possible to purchase a computer with
    a GPU card suitable for deep learning for under $1,000. The current on-demand
    cost of the cheapest GPU computer on AWS is $0.90 per hour, which is equivalent
    to using the machine constantly for 46 days. So, if you are just starting with
    deep learning, cloud resources are the cheapest way to begin. Once you have learned
    the basics, then you may decide to get a GPU-based computer, but even then you
    may continue using cloud resources for deep learning. You have much more flexibility
    in the cloud. For example, in AWS, you can get a p3.16xlarge machine with 8 Tesla
    V100 GPU cards for an on-demand price of $24.48 per hour. An equivalent box is
    the DGX-1 from NVIDIA ([https://www.nvidia.com/en-us/data-center/dgx-1/](https://www.nvidia.com/en-us/data-center/dgx-1/)),
    which has 8 Tesla V100 GPU cards and costs $149,000!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，你可以购买一台适合深度学习的GPU计算机，价格低于$1,000。AWS上最便宜的GPU计算机的按需费用是每小时$0.90，相当于连续使用这台机器46天。因此，如果你刚开始接触深度学习，云资源是最便宜的起步方式。一旦你掌握了基础知识，你可能会决定购买一台基于GPU的计算机，但即便如此，你仍然可以继续使用云资源进行深度学习。云端提供了更多灵活性。例如，在AWS上，你可以以每小时$24.48的按需价格获得一台p3.16xlarge机器，配备8个Tesla
    V100 GPU卡。相当于NVIDIA的DGX-1（[https://www.nvidia.com/en-us/data-center/dgx-1/](https://www.nvidia.com/en-us/data-center/dgx-1/)），它配备了8个Tesla
    V100 GPU卡，价格为$149,000！
- en: 'If you are considering using your own computer for deep learning, then one
    of the following applies to you:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑使用自己的计算机进行深度学习，以下情况适用：
- en: You already have a computer that you can use with a suitable GPU processor
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你已经拥有一台带有合适GPU处理器的计算机
- en: You will buy a computer to build deep learning models
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将购买一台计算机来构建深度学习模型
- en: You will build a computer to build deep learning models
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将构建一台计算机来构建深度学习模型
- en: If you want to use your local computer for deep learning, you need a suitable
    GPU card, which must be from NVIDIA. The best way to check this is to go to the
    NVIDIA site and check if your graphics card is compatible with CUDA. CUDA is an
    application programming interface (API) that allows programs to use GPU for computing.
    You need to install CUDA to be able to use the GPU for deep learning. The current
    link to check if your graphics card is compatible with CUDA is [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在本地计算机上进行深度学习，你需要一张合适的GPU卡，并且必须是NVIDIA的。检查这一点的最好方法是访问NVIDIA官网，查看你的显卡是否与CUDA兼容。CUDA是一个应用程序编程接口（API），它允许程序使用GPU进行计算。你需要安装CUDA才能使用GPU进行深度学习。当前检查显卡是否兼容CUDA的链接是[https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)。
- en: While some companies sell machines that are designed specifically for deep learning,
    they are very expensive. I would not advise getting one of them if you are just
    beginning to, learn deep learning. Instead, I would recommend looking at buying
    a computer that is for high-end computer games. This computer should have an appropriate
    GPU card for deep learning. Again, check that the card is compatible with CUDA
    ([https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus))
    first.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些公司出售专门为深度学习设计的机器，但它们非常昂贵。如果你刚开始学习深度学习，我不建议购买这些机器。相反，我建议你考虑购买一台为高端电脑游戏设计的计算机。这台计算机应该配备适合深度学习的GPU卡。再强调一次，首先检查这张卡是否与CUDA兼容（[https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)）。
- en: A gaming computer for deep learning? It is not as strange as it seems. GPUs
    were developed to play high-end games on computers, not for deep learning. But
    a machine that is designed for games is likely to have a higher than usual specification,
    for example, an SSD drive, lots of (fast) RAM, and most importantly a GPU card.
    Early deep learning practitioners realized that the matrix operations involved
    in calculating 3D spaces were very similar to the matrix operations used in neural
    networks. NVIDIA released CUDA as an API so that other applications could use
    the GPU as a co-processor. Whether it was luck or foresight, NVIDIA became the
    de facto standard for GPU cards for deep learning and has seen its share price
    grow by 10 times in the past 3 years, largely because of the huge demand for GPU
    cards for artificial intelligence.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用于深度学习的游戏电脑？听起来似乎有点不寻常，但其实并不奇怪。GPU最初是为在计算机上进行高端游戏而开发的，而不是为了深度学习。但是，设计用于游戏的机器通常会有较高的配置，例如SSD硬盘、大量（快速的）RAM，最重要的是GPU卡。早期的深度学习从业者发现，计算3D空间中矩阵运算的过程与神经网络中使用的矩阵运算非常相似。NVIDIA发布了CUDA作为API，使其他应用程序能够将GPU作为协处理器使用。无论是运气还是前瞻性，NVIDIA成为了深度学习GPU卡的事实标准，并且其股价在过去三年增长了10倍，主要是因为人工智能对GPU卡的巨大需求。
- en: The third option is to build your own deep learning computer. If you are considering
    this option, then other than the GPU card, memory, and an SSD drive, you will
    also need to consider the power supply and the motherboard. You may need a bigger
    capacity power supply than what is in a standard computer because of the GPU card
    and fans. For the motherboard, you need to consider if the hardware interface
    between the motherboard and the GPU card may limit the data transfer – these are
    PCIe lanes. A GPU can use 16 PCIe lanes at full capacity. For expansion purposes,
    you may want a motherboard that supports 40 PCIe lanes so that you can support
    two GPU cards and an SSD drive simultaneously.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种选择是自己组装深度学习计算机。如果你考虑这个选项，除了GPU卡、内存和SSD硬盘之外，你还需要考虑电源和主板。由于GPU卡和风扇的原因，你可能需要比标准计算机更大功率的电源。至于主板，你需要考虑主板与GPU卡之间的硬件接口是否会限制数据传输——这些接口是PCIe通道。GPU可以在满负荷状态下使用16个PCIe通道。为了扩展，你可能希望选择一块支持40个PCIe通道的主板，这样你可以同时支持两张GPU卡和一个SSD硬盘。
- en: 'Before we move on to the rest of this chapter which discusses using cloud computing
    for deep learning, we should briefly discuss the performance of GPU cards in the
    cloud against what was used for this book. For this book, I used a GTX 1050 Ti
    which has 768 cores and 4 GB RAM. In my experience, the performance of this card
    is about the same as a **p2.xlarge** instance on AWS. I checked this by running
    two models on a local CPU (i5 processor), local GPU (GTX 1050 Ti), and AWS GPU
    (**p2.xlarge**). I ran the test on two models: the binary prediction task from
    [Chapter 4](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml), *Training Deep Prediction
    Models*, and the LeNet convolutional neural network from [Chapter 5](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml),
    *Image Classification Using Convolutional Neural Networks*. Both of these models
    were built using MXNet, and ran for 50 epochs:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论本章关于使用云计算进行深度学习的内容之前，应该简要讨论一下云中的GPU卡与本书中使用的GPU卡的性能对比。对于本书，我使用的是一块GTX
    1050 Ti，它有768个核心和4GB的内存。根据我的经验，这张卡的性能大致与AWS上的**p2.xlarge**实例相当。我通过在本地CPU（i5处理器）、本地GPU（GTX
    1050 Ti）和AWS GPU（**p2.xlarge**）上运行两个模型进行了测试。我测试了两个模型：来自[第4章](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml)的二分类预测任务，*训练深度预测模型*，以及来自[第5章](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml)的LeNet卷积神经网络，*使用卷积神经网络进行图像分类*。这两个模型都是使用MXNet构建的，并运行了50个周期：
- en: '![](img/99d7a3cf-186e-4501-86de-fc10925816ce.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99d7a3cf-186e-4501-86de-fc10925816ce.png)'
- en: 'Figure 10.1: Execution time in seconds for two deep learning networks on CPU,
    local GPU, and AWS GPU'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：两个深度学习网络在CPU、本地GPU和AWS GPU上的执行时间（秒）
- en: On my local machine, running the deep learning model for the binary prediction
    task on the GPU is about 20% faster than running on the CPU, and the AWS GPU machine
    is approximately 13% faster than the local GPU. However, there is a much bigger
    difference when running convolutional neural networks, training it on the local
    CPU is almost 16 times slower than training it on the local GPU. In turn, the
    AWS GPU is approximately 16% faster than the local GPU. These results are expected
    and mirror what I have seen in practice and other benchmarks on the web and show
    conclusively that for deep learning computer vision tasks, a GPU is a necessity.
    The GPU card on my local machine (GTX 1050 Ti) is probably the lowest specification
    GPU card you should use for deep learning. It currently costs under $200\. As
    a comparison, a high-end GPU card (GTX 1080 Ti) has 3,584 cores and 11 GB of RAM,
    and currently costs approx $700\. The GTX 1080 Ti is approximately 4-5 times faster
    than the GTX 1050 Ti.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的本地机器上，运行二进制预测任务的深度学习模型在GPU上比在CPU上快约20%，而AWS GPU机器比本地GPU快约13%。然而，在运行卷积神经网络时，使用本地CPU训练几乎比使用本地GPU慢16倍。反过来，AWS
    GPU比本地GPU快约16%。这些结果是预期的，并且与我在实践中看到的情况和其他网站上的基准测试相符，明确表明对于深度学习计算机视觉任务，GPU是必不可少的。我的本地机器上的GPU卡（GTX
    1050 Ti）可能是您应该用于深度学习的最低规格GPU卡。目前的价格不到$200。作为比较，高端GPU卡（GTX 1080 Ti）拥有3584个核心和11
    GB的内存，目前的价格约为$700。GTX 1080 Ti比GTX 1050 Ti快大约4-5倍。
- en: Why does the previous graph just look at AWS and not Azure, Google Cloud, and
    Paperspace? Why did I not benchmark all of them on performance and/or cost? I
    decided not to do so for a few reasons. Firstly, and most importantly, any recommendation
    would have been out of date after a few months—deep learning is very popular and
    the various cloud providers are changing their offerings and prices constantly.
    Another reason is that the examples in this book are relatively small and we are
    using the cheapest GPU instances. Therefore, any comparisons to production use
    cases would be misleading. Finally, when you are starting out, ease of use is
    probably more important than raw cost. All the examples in this book should run
    in under 1 hour in the cloud regardless of which provider you use, so arguing
    that one provider costs $0.55/hour and another costs $0.45/hour is not important.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么前面的图表只涉及AWS，而不涉及Azure、Google Cloud和Paperspace？为什么我没有对它们的性能和/或成本进行基准测试？我有几个理由决定不这样做。首先，也是最重要的是，任何推荐在几个月后就会过时——深度学习非常流行，各个云服务提供商不断更改其产品和价格。另一个原因是，本书中的示例相对较小，我们使用的是最便宜的GPU实例。因此，与生产用例的任何比较都可能误导。最后，当您刚开始时，易用性可能比原始成本更重要。本书中的所有示例在任何提供商的云中都应在1小时内运行，因此争论一个提供商每小时成本为$0.55和另一个为$0.45是不重要的。
- en: How do I know if my model is training on a GPU?
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我如何知道我的模型是在GPU上训练的？
- en: 'One question that many people starting in deep learning ask is, *how do I know
    if my model is training on a GPU?* Fortunately, whether you are using a cloud
    instance or your local machine, you can check if the deep learning model is being
    trained on the GPU or the CPU. There is a utility on the instance that shows the
    GPU''s activity. In Linux, you can type in the following command:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 许多刚开始深度学习的人会问一个问题，*我如何知道我的模型是在GPU上训练的？*幸运的是，无论您是使用云实例还是本地机器，您都可以检查深度学习模型是在GPU还是CPU上进行训练。实例上有一个工具可以显示GPU的活动。在Linux中，您可以输入以下命令：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In Windows, you can use the following command from a command prompt:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows中，您可以从命令提示符中使用以下命令：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will run a script that outputs diagnostic messages about the GPU on the
    computer. If your model is currently training on the GPU, the GPU utility will
    be high. In the following example, we can see that it is 75-78%. We can also see
    that the file called `rsession.exe` is using GPU memory. This confirms that the
    model is being trained on the GPU:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这将运行一个脚本，输出关于计算机GPU的诊断信息。如果您的模型当前正在GPU上训练，GPU实用程序将会很高。在下面的示例中，我们可以看到它为75-78%。我们还可以看到名为`rsession.exe`的文件正在使用GPU内存。这证实了模型正在GPU上训练：
- en: '![](img/53b61b85-9ce9-40d7-bdbc-48764803c6df.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53b61b85-9ce9-40d7-bdbc-48764803c6df.png)'
- en: Figure 10.2: nvidia-smi utility showing that the GPU card is at 75-85% utilization
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：nvidia-smi工具显示GPU卡的利用率为75-85%
- en: Using AWS for deep learning
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AWS进行深度学习
- en: '**AWS** is the biggest cloud provider, and so it deserves our attention. If
    you know how to use AWS and especially if you are familiar with spot requests,
    it can be a very cost-effective method to train complex deep learning models.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**AWS** 是最大的云服务提供商，因此它值得我们关注。如果你知道如何使用AWS，特别是如果你熟悉竞价请求，它可以是训练复杂深度学习模型的一种非常具有成本效益的方法。'
- en: A brief introduction to AWS
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS简介
- en: This section gives you a brief introduction to how AWS works. It describes EC2,
    AMIs, and how to create a virtual machine in the cloud. This will not be an exhaustive
    introduction to AWS – there are plenty of tutorials online that will guide you.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要介绍了AWS的工作原理。它描述了EC2、AMI以及如何在云中创建虚拟机。这不会是对AWS的详尽介绍——网上有很多教程可以指导你。
- en: AWS is a suite of cloud resources. Another term for it is **Infrastructure as
    a Service** (**IaaS**), as opposed to **Software as a Service** (**SaaS**) or
    **Platform as a Service** (**PaaS**). In IaaS, as opposed to SaaS or PaaS, you
    are supplied with infrastructure (hardware), and it is up to you to use it as
    you wish. This includes installing software and managing security and networking,
    although AWS take care of some aspects of security and networking. AWS has many
    services, but for deep learning, the one you will use is EC2, which is a virtual
    computing environment so that you can launch instances (virtual computers). You
    can control these virtual computers either through web interfaces or by remote
    logging into them to run commands from the shell. When you launch an EC2 instance,
    you can select the operating system (Ubuntu, Linux, Windows, and so on) and the
    type of machine you want.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: AWS是一套云资源。另一个术语是**基础设施即服务**（**IaaS**），与**软件即服务**（**SaaS**）或**平台即服务**（**PaaS**）不同。在IaaS中，与SaaS或PaaS不同，你获得的是基础设施（硬件），如何使用它取决于你。这包括安装软件和管理安全性与网络，尽管AWS会处理一些安全性和网络方面的内容。AWS提供了许多服务，但对于深度学习，你将使用的是EC2，它是一个虚拟计算环境，允许你启动实例（虚拟计算机）。你可以通过Web界面或远程登录它们来运行命令控制这些虚拟计算机。当你启动一个EC2实例时，可以选择操作系统（如Ubuntu、Linux、Windows等）以及你想要的机器类型。
- en: You can also select to use an **Amazon Machine Image** (**AMI**), which has
    software applications and libraries pre-installed on it. This is a good choice
    for deep learning as it means that you can start an EC2 instance with the deep
    learning libraries already installed and jump straight into deep learning.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以选择使用**Amazon机器镜像**（**AMI**），它已经预装了软件应用和库。这对于深度学习是一个不错的选择，因为这意味着你可以启动一个已安装深度学习库的EC2实例，直接开始深度学习。
- en: One other service you should be familiar with is S3, which is a form of persistent
    storage. A very useful practice that I suggest you to adopt is to consider your
    virtual machines as temporary resources and to keep your data and interim results
    in S3\. We will not discuss this in this chapter because it is an advanced topic.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该熟悉的另一个服务是S3，它是一种持久存储。我建议你采用的一个非常有用的做法是将你的虚拟机视为临时资源，并将数据和中间结果保存在S3中。我们在本章中不会讨论这个，因为它是一个高级话题。
- en: 'In the previous section, we stated that the current on-demand cost of the cheapest
    GPU computer on AWS is $0.90 per hour. *On-demand* is one way to use a virtual
    machine in AWS, but there are three different ways to rent a virtual machine in
    AWS:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们提到当前AWS上最便宜的GPU计算机的按需费用为每小时$0.90。*按需* 是一种使用AWS虚拟机的方式，但在AWS中有三种不同的方式来租用虚拟机：
- en: '**On-demand instances**: When you rent an instance as needed.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按需实例**：当你按需租用实例时。'
- en: '**Reserved instances**: When you commit to renting the machine for a certain
    period of time (usually 1-3 years). This is about 50% cheaper than on-demand instances.
    However you are committed to paying for the resource for the period of time.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预留实例**：当你承诺在一定时间内（通常为1-3年）租用机器时。这比按需实例便宜大约50%。然而，你需要承诺在这段时间内为资源付费。'
- en: '**Spot instances**: In order to deal with fluctuating demand, Amazon has spare
    computing capacity most of the time. You can bid for this unused capacity and,
    depending on the demand for that type of machine, you can usually get it cheaper
    than on-demand and reserved instances. However, once you have the machine, it
    is not guaranteed that you will keep it as long as you need – if the demand for
    the computer goes up, your computer may be terminated.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**现货实例**：为了应对需求波动，亚马逊大部分时间都有备用的计算资源。你可以竞标这些未使用的资源，通常你可以以比按需和保留实例便宜的价格获得它，具体价格取决于该类型机器的需求。然而，一旦你获得了这台机器，并不保证你会一直使用它——如果计算机需求增加，你的计算机可能会被终止。'
- en: Reserve instances are not useful for deep learning. The cost of renting the
    cheapest GPU machine for 1 year would be over $5,000, and you can buy a deep learning
    machine with better performance for much less. On-demand instances guarantee that
    you will have the resource as long as needed, but are expensive. Spot instances
    are an interesting and cost-effective method to use if you know how to use them
    correctly and plan for the chance that your computer will be terminated.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 保留实例对于深度学习并不实用。租用最便宜的GPU机器1年的费用将超过5000美元，而你可以花更少的钱买到性能更好的深度学习机器。按需实例保证你会在需要时拥有资源，但费用较高。如果你知道如何正确使用现货实例并计划好计算机可能会被终止的风险，它是一种有趣且成本效益高的使用方法。
- en: Typically, the spot price is about 30% of the on-demand price, so the savings
    are significant. Your bid is the maximum amount that you are willing to pay for
    the spot instances, the actual price depends on the market price, which is based
    on the demand.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，现货价格大约是按需价格的30%，所以节省的费用非常可观。你的竞标价格是你愿意为现货实例支付的最高金额，实际价格取决于市场价格，市场价格基于需求变化。
- en: Therefore, you should set your bid price higher; I recommend to set it at either
    51%, 76%, or 101% of the on-demand price. The extra 1% from 50%, 75%, and 100%
    is because, similar to any bidding market, humans anchor their bids to round numbers,
    so by avoiding this with an extra 1%, it can make a difference.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你应该将竞标价格设定得更高；我建议设定为按需价格的51%、76%或101%。额外的1%是因为，与任何竞标市场类似，人们习惯将竞标价格定为圆整的数字，通过加上1%的额外数值，可以避开这一惯性，从而可能产生不同的结果。
- en: The original use case for spot instances was for low-priority batch jobs. Companies
    used spot instances to the avail of themselves cheaper computing resources for
    long-running jobs that could be restarted in the event that they did not finish.
    An example might be running a secondary data ingestion process on data that was
    not critical to operations. However, the demand pattern for GPU based instances
    is different, possibly because of online data mining competitions such as Kaggle.
    Because GPU instances are not very common, demand spikes much more for GPU instances.
    This has led to some strange behavior in spot pricing, where the price that people
    bid for a spot instance can be 10x that of the on-demand price. People do this
    because they believe that this makes it unlikely that they will be outbid. There
    are cases where a p2.16xlarge has had a spot price of $144 per hour while the
    on-demand price is $14.40\. The people who set these bids do not want their machines
    to be terminated and believe that they will still pay less on average for spot
    instances than on-demand instances. This is not something I would encourage if
    you use spot instances as you can get a very nasty surprise if demand goes up!
    However, you should be aware of this pricing quirk – do not think that setting
    the bid price to just above the on-demand price guarantees that your machine will
    not be terminated.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现货实例最初的使用场景是低优先级的批处理任务。公司使用现货实例来节省计算资源，运行那些如果未能完成可以重新启动的长期任务。例如，可能是运行一个处理非关键操作数据的二次数据摄取过程。然而，基于GPU的实例的需求模式有所不同，可能是因为类似Kaggle这样的在线数据挖掘比赛。由于GPU实例并不常见，GPU实例的需求波动更大。这导致了现货定价中出现一些奇怪的现象，人们为现货实例竞标的价格可能是按需价格的10倍。人们之所以这样做，是因为他们认为这样不太可能被其他人超出出价。有时候，p2.16xlarge的现货价格为每小时144美元，而按需价格为14.40美元。那些设置这些竞标的人不希望自己的机器被终止，并认为即使他们出高价，平均下来使用现货实例仍然比按需实例便宜。如果你打算使用现货实例，我不推荐这种做法，因为如果需求突然上升，你可能会遇到非常大的意外！不过，你应该意识到这一定价怪癖——不要认为只要将竞标价格设定为略高于按需价格，就能保证你的机器不会被终止。
- en: 'AWS provides you help in setting up your spot request bid by providing pricing
    history charts that advise you on the on-demand price and the bid prices. In the
    following screenshot, we can see how the price has changed over the past 3 months
    for a particular region (us-east). There are 6 availability zones (us-east-1a
    to us-east-1f) and the current spot price of this instance type (**p2.16xlarge**)
    varies from $4.32-$14.40, while the on-demand price is $14.40:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 通过提供定价历史图表来帮助你设置竞价请求，图表会提供按需价格和竞价价格的建议。在下图中，我们可以看到某个特定区域（us-east）过去三个月的价格变化情况。该区域有
    6 个可用区（us-east-1a 到 us-east-1f），该实例类型（**p2.16xlarge**）的当前竞价价格在 4.32 美元至 14.40
    美元之间，而按需价格为 14.40 美元：
- en: '![](img/c2acf192-d7df-49ce-9267-f6ba038f9a7d.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2acf192-d7df-49ce-9267-f6ba038f9a7d.png)'
- en: 'Figure 10.3: Pricing history for spot bids for p2.16xlarge instance type'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3：p2.16xlarge 实例类型的竞价历史
- en: 'Looking at the preceding graph for this resource, I would consider the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 查看上述资源的图表后，我会考虑以下因素：
- en: I would use the availability zone **us-east-1a** if possible, as it has the
    lowest price volatility.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能，我会选择 **us-east-1a** 可用区，因为它的价格波动最小。
- en: I would set the price to $7.21 per hour, which is just over 50% of the on-demand
    price. I would probably only pay $4.32 per hour as it has been 1 month since the
    bid price in us-east-1a has gone over $4.32 per hour. Setting it at the higher
    price would make it less likely that my spot instance would be terminated.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我会将价格设置为每小时 7.21 美元，这只是按需价格的 50% 以上。由于自从 us-east-1a 区域的竞价价格超过每小时 4.32 美元已经过去一个月，我可能只会支付每小时
    4.32 美元。将价格设置为较高的金额会使得我的竞价实例被终止的可能性较小。
- en: '**Regions and availability zones:** AWS arranges its services in regions (**us-east1**,
    **eu-west1**, and so on). Currently, there are 18 different regions and in each
    region, there are multiple availability zones, which you can consider as physical
    data centers. For some use cases (for example, websites, disaster recovery, and
    so on) and regulatory requirements, regions and availability zones are important.
    For deep learning, they are not so important, as you can usually run your deep
    learning models at any location. The bid price for spot instances is different
    for regions/availability zones, and some resources are more expensive in some
    regions. You also need to be aware that there is a cost in transferring data between
    regions, so keep your data and instances in the same region.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**区域和可用区：** AWS 将其服务安排在不同的区域（**us-east1**、**eu-west1** 等）。目前，有 18 个不同的区域，并且每个区域中都有多个可用区，你可以将它们视为物理数据中心。对于一些使用案例（例如，网站、灾难恢复等）和合规要求，区域和可用区非常重要。对于深度学习来说，它们并不那么重要，因为你通常可以在任何位置运行深度学习模型。各个区域/可用区的竞价价格不同，某些资源在某些区域会更贵。你还需要注意，在不同区域之间转移数据是有成本的，所以最好将数据和实例保持在同一区域内。'
- en: Creating a deep learning GPU instance in AWS
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS 中创建深度学习 GPU 实例
- en: 'This section will use AWS to train a deep learning model from [Chapter 9](e0045e3c-8afd-4e59-be9f-29e652a9a8b1.xhtml), *Anomaly
    Detection and Recommendation Systems*. This will include setting up the machine,
    accessing the machine, downloading the data, and running the model. We are going
    to use a pre-built AWS AMI from RStudio that has TensorFlow and Keras already
    installed. For details on this AMI, go to this link: [https://aws.amazon.com/marketplace/pp/B0785SXYB2](https://aws.amazon.com/marketplace/pp/B0785SXYB2). You
    will need to sign up for an AWS account if you do not already have one at [https://portal.aws.amazon.com/billing/signup](https://portal.aws.amazon.com/billing/signup).
    Once you have signed up, follow these steps to create a virtual machine that has
    a GPU on AWS:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将使用 AWS 来训练 [第 9 章](e0045e3c-8afd-4e59-be9f-29e652a9a8b1.xhtml)《异常检测与推荐系统》中的深度学习模型。这将包括设置机器、访问机器、下载数据以及运行模型。我们将使用来自
    RStudio 的预构建 AWS AMI，里面已经安装了 TensorFlow 和 Keras。有关此 AMI 的详细信息，请访问此链接：[https://aws.amazon.com/marketplace/pp/B0785SXYB2](https://aws.amazon.com/marketplace/pp/B0785SXYB2)。如果你还没有
    AWS 账户，你需要在 [https://portal.aws.amazon.com/billing/signup](https://portal.aws.amazon.com/billing/signup)
    注册一个账户。一旦注册完成，请按照以下步骤在 AWS 上创建一个带有 GPU 的虚拟机：
- en: Note that when you set up an instance in AWS, you will be billed for as long
    as it is running! Always ensure that you shut down your instances, otherwise you
    will continue to be charged. Check the AWS console to ensure you have no running
    instances when you are finished using the virtual instance.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在 AWS 中设置实例时，实例运行期间会计费！务必确保关闭实例，否则你将继续被收费。在完成使用虚拟实例后，检查 AWS 控制台，确保没有正在运行的实例。
- en: 'Log in to the AWS console and select EC2\. You should see a screen similar
    to the following. This is the web interface for creating new virtual machines:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 AWS 控制台并选择 EC2。你应该会看到一个类似于以下的屏幕。这是创建新虚拟机器的 Web 界面：
- en: '![](img/aba67547-2b69-4a67-b9c5-a36d4b11a68b.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aba67547-2b69-4a67-b9c5-a36d4b11a68b.png)'
- en: 'Figure 10.4: AWS EC2 dashboard'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4：AWS EC2 仪表板
- en: Click on the launch instance button and the following page will load.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击启动实例按钮，以下页面将加载。
- en: Click **AWS Marketplace** on the left and in the search box type `rstudio` (see
    the following screenshot).
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧的**AWS Marketplace**，在搜索框中输入`rstudio`（参见以下截图）。
- en: 'Select **RStudio Server with Tensorflow-GPU for AWS**. Be aware that there
    is another option with the word **Pro **– this is a paid subscription with additional
    costs, so do not select this AMI:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**带有 Tensorflow-GPU 的 RStudio 服务器（适用于 AWS）**。请注意，还有另一个选项带有**Pro**字样——这是一个付费订阅，附加了额外费用，所以不要选择这个
    AMI：
- en: '![](img/aafcaf7a-2869-471c-acce-f673585f8536.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aafcaf7a-2869-471c-acce-f673585f8536.png)'
- en: Figure 10.5: AWS launch instance wizard, Step 1
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5：AWS 启动实例向导，第 1 步
- en: 'Once you click **Select**, the following screen may appear with some additional
    information on accessing the instance. Read the instructions carefully, as they
    may have changed from what''s shown in the screenshot that follows:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦点击**选择**，可能会出现以下屏幕，其中包含有关访问实例的附加信息。请仔细阅读说明，因为它们可能与以下屏幕截图中显示的内容有所不同：
- en: '![](img/d2ec8bac-a577-4bab-895c-35e7461b5a64.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d2ec8bac-a577-4bab-895c-35e7461b5a64.png)'
- en: Figure 10.6: RStudio AMI information
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6：RStudio AMI 信息
- en: 'When you click **Continue**, the following screen will appear for the machine
    type. It is vital to select a machine that has a GPU, so from the **Filter by:** option, select
    GPU compute and then select **p2.xlarge** from the list. Your options should look
    similar to the following screenshot:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你点击**继续**时，以下屏幕将出现，选择机器类型非常重要。一定要选择一个带有 GPU 的机器，所以在**按筛选条件：**选项中，选择 GPU 计算，然后从列表中选择**p2.xlarge**。你的选项应该与以下截图类似：
- en: '![](img/ed92abfe-bcc6-468b-98f1-e7c5c15ce603.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed92abfe-bcc6-468b-98f1-e7c5c15ce603.png)'
- en: Figure 10.7: AWS launch instance wizard, Step 2
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7：AWS 启动实例向导，第 2 步
- en: 'When you click Next, you will get to the following screen with various configuration
    options. The default options are OK, so just press Next again:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击下一步后，你将看到一个包含各种配置选项的屏幕。默认选项是可以的，所以只需再次点击下一步：
- en: '![](img/fd0097b8-c8c5-4039-ae0e-3eddc27cf31b.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd0097b8-c8c5-4039-ae0e-3eddc27cf31b.png)'
- en: Figure 10.8: AWS launch instance wizard, Step 3
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8：AWS 启动实例向导，第 3 步
- en: This screen allows you to change the storage options. You may need to add additional
    storage depending on the size of the data. Storage is relatively cheap, so I recommend
    going with 3x-5x the size of the input data.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此屏幕允许你更改存储选项。根据数据大小，你可能需要增加额外的存储。存储相对便宜，所以我建议选择输入数据大小的 3 倍到 5 倍的存储空间。
- en: 'Click **Next** to go to the following screenshot:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**以进入下一个截图：
- en: '![](img/286b5c73-eb73-4ac7-a270-878f3d9a958b.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/286b5c73-eb73-4ac7-a270-878f3d9a958b.png)'
- en: Figure 10.9: AWS launch instance wizard, Step 4
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9：AWS 启动实例向导，第 4 步
- en: 'The following screen is not important – tags are used to keep track of resources
    in AWS, but we do not need them. Click Next to go to the following screenshot:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下屏幕不重要——标签用于在 AWS 中跟踪资源，但我们不需要它们。点击下一步以进入下一个截图：
- en: '![](img/e25e132f-c0dd-4f66-b764-9cfa0554e48c.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e25e132f-c0dd-4f66-b764-9cfa0554e48c.png)'
- en: Figure 10.10: AWS launch instance wizard, step 5
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10：AWS 启动实例向导，第 5 步
- en: 'The following screenshot shows security options. AWS restricts access to instances,
    so you must open any needed ports. The defaults provided here allow access to
    port `22` (SSH) to access the shell and also for port `8787`, which is the web
    port that RStudio uses. Click Review and Launch to continue:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图显示了安全选项。AWS 限制了对实例的访问，因此你必须打开任何需要的端口。此处提供的默认选项允许访问端口`22`（SSH）以访问 shell，并且还允许访问端口`8787`，这是
    RStudio 使用的 Web 端口。点击审查并启动以继续：
- en: '![](img/cd54d2b2-35c6-45d5-9046-24345d306457.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd54d2b2-35c6-45d5-9046-24345d306457.png)'
- en: Figure 10.11: AWS launch instance wizard, Step 6
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11：AWS 启动实例向导，第 6 步
- en: The following screenshot will appear. Note the warning messages regarding security –
    in a production environment, you would probably want to address these.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图将会显示。注意关于安全性的警告信息——在生产环境中，你可能需要解决这些问题。
- en: 'Click the **Launch** button to continue:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**启动**按钮以继续：
- en: '![](img/157480e8-9d0b-44f5-b32f-6f5422d462e3.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/157480e8-9d0b-44f5-b32f-6f5422d462e3.png)'
- en: Figure 10.12: AWS launch instance wizard, Step 7
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12：AWS 启动实例向导，第7步
- en: 'You will be asked for a key pair. If you have not already created a key pair,
    then select the option to do so. Give it a descriptive name and press the Download
    Key Pair button. Then, click on Launch Instances:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统会要求你选择一个密钥对。如果你还没有创建密钥对，请选择相应的选项进行创建。给它起一个描述性的名字，然后点击下载密钥对按钮。之后，点击“启动实例”按钮：
- en: A key pair is used to access the instance using SSH. You should guard this very
    carefully, as if someone manages to get your private key, then they will be able
    to log in to any of your instances. You should delete your key pair occasionally
    and create a new one.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 密钥对用于通过SSH访问实例。你应该非常小心地保护这个密钥，因为如果有人获得了你的私钥，他们将能够登录到你的任何实例。你应该定期删除密钥对并创建一个新的。
- en: '![](img/ef21c0ea-5bf6-4899-9adc-fb34f76686bc.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef21c0ea-5bf6-4899-9adc-fb34f76686bc.png)'
- en: Figure 10.13: AWS launch instance wizard, select key pair
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13：AWS 启动实例向导，选择密钥对
- en: 'Once you have completed this, you can go back to the EC2 dashboard and you
    will see that you have 1 Running Instances. Click on that link to move on to the
    details of the instance:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成此操作后，你可以返回到EC2控制台，看到你有1个正在运行的实例。点击该链接查看实例的详细信息：
- en: '![](img/34bf01f9-062b-498b-85da-c69914e6fcdd.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/34bf01f9-062b-498b-85da-c69914e6fcdd.png)'
- en: Figure 10.14: AWS EC2 dashboard
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14：AWS EC2 控制台
- en: 'Here, you will see the details of the instance. In this case, the IP address
    is `34.227.109.123`. Also note down the instance ID that is highlighted, as this
    is the password that is used to connect to the RStudio instance:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，你将看到实例的详细信息。在本例中，IP地址是`34.227.109.123`。还需要记下被高亮显示的实例ID，因为这是用于连接到RStudio实例的密码：
- en: '![](img/27feac10-e148-43ce-8972-9e7784921555.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27feac10-e148-43ce-8972-9e7784921555.png)'
- en: Figure 10.15: AWS EC2 dashboard, instance details
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15：AWS EC2 控制台，实例详细信息
- en: Open another web page and browse to the IP address of your machine and add `:8787`
    to access the link. In my example, the link is `http://34.227.109.123:8787/`.
    Instructions for logging in are in *Figure 10.6*, that is, use rstudio-user as
    the username and the instance ID as the password. You should also consider changing
    the password as per the instructions.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开另一个网页，浏览到你机器的IP地址，并在后面加上`:8787`以访问该链接。在我的示例中，链接是`http://34.227.109.123:8787/`。登录的说明在*图10.6*中，即使用`rstudio-user`作为用户名，实例ID作为密码。你还应考虑按照说明更改密码。
- en: 'When you log in, you will see a familiar interface – it is similar to the RStudio
    desktop program. One difference you have is the **Upload** button on the bottom-right
    pane, which allows you to upload files. In the following example, I have uploaded
    the data and the script from [Chapter 9](e0045e3c-8afd-4e59-be9f-29e652a9a8b1.xhtml),
    *Anomaly Detection and Recommendation Systems*, for the Keras recommender example
    and ran it successfully:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，你将看到一个熟悉的界面——它类似于RStudio桌面程序。一个不同之处是你右下角的**上传**按钮，它允许你上传文件。在以下示例中，我已经上传了[第9章](e0045e3c-8afd-4e59-be9f-29e652a9a8b1.xhtml)的数据显示和脚本，*异常检测与推荐系统*，用于Keras推荐系统示例，并成功运行：
- en: '![](img/dc6290f6-e4d3-47ae-b27d-9f9571921105.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc6290f6-e4d3-47ae-b27d-9f9571921105.png)'
- en: 'Figure 10.16: Accessing deep learning instance in the cloud using RStudio Server'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16：通过RStudio Server访问云中的深度学习实例
- en: The web interface in RStudio is similar to using RStudio on your local computer.
    In *Figure 10.16*, you can see data files that I have uploaded (`recomend.csv`, `recomend40.csv`)
    and the R script in the Files in the bottom-left window. We can also see the code
    that was executed in the Console window in the bottom-left.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: RStudio的Web界面类似于在本地计算机上使用RStudio。在*图10.16*中，你可以看到我上传的数据显示文件（`recomend.csv`，`recomend40.csv`）以及位于左下窗口的文件中的R脚本。我们还可以看到在左下角控制台窗口中执行的代码。
- en: 'This finishes our example on how to set up a deep learning machine in AWS.
    Again, remember that you will be billed for as long as the computer is running.
    Ensure that your instances are terminated, otherwise you will continue to be charged.
    To do so, go back to the EC2 dashboard, find the instance, and click on the **Actions**
    button. A pop-up menu will appear, where you can select **Instance State** and
    then select **Terminate**:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了我们在AWS中如何设置深度学习机器的示例。再提醒一次，记得计算机运行时会计费。确保终止你的实例，否则你将继续被收费。为此，返回到EC2仪表板，找到实例，并点击**操作**按钮。会弹出一个菜单，选择**实例状态**，然后选择**终止**：
- en: '![](img/3d35019f-f470-4a97-86eb-31bb1b1048d4.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d35019f-f470-4a97-86eb-31bb1b1048d4.png)'
- en: 'Figure 10.17: Terminating the AWS instance'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17：终止AWS实例
- en: Creating a deep learning AMI in AWS
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在AWS中创建深度学习AMI
- en: In the previous example, we used an **Amazon Machine Image** (**AMI**) that
    was built by RStudio. In AWS, you can also create your own AMI's. When you create
    an AMI, you can install the software you want, load data onto it, and set it up
    as you wish. This section will show you how to use an AMI to use MXNet on AWS.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，我们使用了由RStudio构建的**Amazon Machine Image**（**AMI**）。在AWS中，你也可以创建自己的AMI。当你创建AMI时，可以安装所需的软件，将数据加载到AMI中，并按自己的需求进行设置。本节将向你展示如何使用AMI在AWS上使用MXNet。
- en: The first step in creating an AMI is to select the base image that you are going
    to use. We could start with a base image that just has the operating system installed,
    but instead we are going to use the **RStudio Server with Tensorflow-GPU for AWS** that
    we used previously and add the MXNet package to it.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建AMI的第一步是选择要使用的基础镜像。我们可以从只安装了操作系统的基础镜像开始，但我们将使用之前提到的**带有Tensorflow-GPU的RStudio
    Server for AWS**，并向其中添加MXNet包。
- en: The instructions to install MXNet were adapted from [https://mxnet.incubator.apache.org/install/index.html](https://mxnet.incubator.apache.org/install/index.html).
    The first step is to create the instance from the **RStudio Server with Tensorflow-GPU
    for AWS** AMI as per the previous section.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装MXNet的说明改编自[https://mxnet.incubator.apache.org/install/index.html](https://mxnet.incubator.apache.org/install/index.html)。第一步是按照前一节的说明，从**带有Tensorflow-GPU的RStudio
    Server for AWS** AMI创建实例。
- en: Once you have done this, you need to SSH into the machine. How you do this depends
    on the operating system on your own computer. For Linux and macOS, you can execute
    a local command on the shell, and in Windows you can use Putty.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成此步骤后，你需要SSH登录到机器。如何操作取决于你自己计算机的操作系统。对于Linux和macOS，你可以在shell中执行本地命令；在Windows上，你可以使用Putty。
- en: 'Once you have logged in to the machine, run the following command:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到机器后，运行以下命令：
- en: '[PRE2]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Add the following line to the end of this file and save the file:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下行添加到文件的末尾并保存文件：
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once you are back at the shell, run the following lines one by one:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到shell后，依次运行以下命令：
- en: '[PRE4]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The last command could take up to 2 hours to complete. Once it is done, run
    the last few lines:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个命令可能需要最多2小时才能完成。完成后，运行最后几行命令：
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The second line may take up to 30 minutes. The final line may return a warning
    about a missing file, which can be ignored.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行命令可能需要最多30分钟。最后一行可能会返回关于缺少文件的警告，可以忽略该警告。
- en: 'To test if everything installed correctly, go to the RStudio page for the instance
    and type in the following code:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要测试是否一切安装正确，访问该实例的RStudio页面并输入以下代码：
- en: '[PRE6]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should get the following output:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now go back to the EC2 dashboard, click on **Running Instances**, and select
    the machine in the list. Click on the **Action** button, select **Image** from
    the drop-down menu, and select **Create Image**. This is shown in the following
    screenshot:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在返回到EC2仪表板，点击**运行中的实例**，并在列表中选择该机器。点击**操作**按钮，从下拉菜单中选择**镜像**，然后选择**创建镜像**。如下图所示：
- en: '![](img/6e79acde-0322-4ea8-bd54-af931a923b29.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e79acde-0322-4ea8-bd54-af931a923b29.png)'
- en: Figure 10.18: Creating an AMI
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.18：创建AMI
- en: 'The image may take 15-20 minutes to complete. When it is done, click on AMIs
    on the left menu selection to show the list of AMIs associated with your account.
    You should see the AMI you just created. This AMI can then be used to create a
    new on-demand instance or a new spot instance. The following screenshot shows
    the menu option to create a spot instance for the AMI:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 镜像创建可能需要15-20分钟才能完成。完成后，点击左侧菜单中的AMI，显示与你账户关联的AMI列表。你应该能看到刚刚创建的AMI。该AMI可以用于创建新的按需实例或新的抢占实例。下图展示了为AMI创建抢占实例的菜单选项：
- en: '![](img/1a09ca79-e660-464f-84bc-71adffd561a9.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a09ca79-e660-464f-84bc-71adffd561a9.png)'
- en: Figure 10.19: Using an existing AMI for a spot request
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.19：使用现有的 AMI 创建 Spot 请求
- en: This AMI is now available so that you can create new deep learning instances.
    You should be aware that there is an ongoing cost in storing the AMI, even if
    you do not use it.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 AMI 现在可以使用，你可以创建新的深度学习实例。请注意，即使不使用它，存储 AMI 也会产生持续的费用。
- en: Using Azure for deep learning
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Azure 进行深度学习
- en: Azure is the brand name for Microsoft's cloud services. You can use Azure for
    deep learning and, similar to AWS, it provides deep learning virtual machines
    that is pre-configured with deep learning libraries installed. In this example,
    we are going to create a Windows instance that can be used for Keras or MXNet.
    This assumes that your local computer is also a Windows computer, as you will
    be using **Remote Desktop Protocol** (**RDP**) to access the cloud instance.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 是 Microsoft 云服务的品牌名。你可以使用 Azure 进行深度学习，类似于 AWS，它提供了预先配置了深度学习库的深度学习虚拟机。在这个示例中，我们将创建一个
    Windows 实例，可以用于 Keras 或 MXNet。假设你的本地计算机也是 Windows 系统，因为你将使用**远程桌面协议**（**RDP**）访问云实例。
- en: 'The first step is to create an account in Azure and then log in to Azure at
    [https://portal.azure.com](https://portal.azure.com). You will see a screenshot
    similar to the following. Click **Create a resource** and search for **Deep Learning
    Virtual Machine**:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是创建一个 Azure 账户，然后在 [https://portal.azure.com](https://portal.azure.com) 登录
    Azure。你将看到一个类似于下面的截图。点击**创建资源**并搜索**深度学习虚拟机**：
- en: '![](img/35fda232-a7e7-4c1c-99e6-a719b99d6798.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35fda232-a7e7-4c1c-99e6-a719b99d6798.png)'
- en: 'Figure 10.20: Azure portal website'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.20：Azure 门户网站
- en: 'When you select **Deep Learning Virtual Machine**, the following screen will
    appear. Click **Create**:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你选择**深度学习虚拟机**时，以下屏幕将显示。点击**创建**：
- en: '![](img/865011d0-1c63-4727-913d-39a08bc61ffd.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/865011d0-1c63-4727-913d-39a08bc61ffd.png)'
- en: 'Figure 10.21: Provisioning a deep learning instance on Azure, step 0'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.21：在 Azure 上部署深度学习实例，步骤 0
- en: You will now start a 4-step wizard to create the new instance.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你将开始一个 4 步向导来创建新实例。
- en: 'The first step (Basics), asks for some basic details. It is OK to enter the
    same values as I have done, but fill in the username and password carefully as
    you will need them later:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步（基础）要求提供一些基本信息。可以输入与我相同的值，但请小心填写用户名和密码，因为稍后会用到：
- en: '![](img/6b977cee-8553-449a-b482-efa7f5031dec.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b977cee-8553-449a-b482-efa7f5031dec.png)'
- en: 'Figure 10.22: Provisioning a deep learning instance on Azure, step 1'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.22：在 Azure 上部署深度学习实例，步骤 1
- en: 'For Step 2 (Settings), ensure that the virtual machine size is 1 x Standard
    NC6 (1 GPU), and click **OK** to continue:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 2 步（设置）中，确保虚拟机的大小为 1 x Standard NC6（1 GPU），然后点击**确定**继续：
- en: '![](img/4a27d0e4-b492-4566-8383-1d37646b48c3.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a27d0e4-b492-4566-8383-1d37646b48c3.png)'
- en: 'Figure 10.23: Provisioning a deep learning instance on Azure, step 2'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.23：在 Azure 上部署深度学习实例，步骤 2
- en: 'For Step 3 (Summary), there is a brief validation check. You may be told that
    your account does not have sufficient Compute/VM (cores/vCPUs) resources available,
    which is because Microsoft may have restricted your account when it was first
    created. Create a support ticket to increase your resources and try again. If
    you have passed this step, click **OK** to continue. You are now on the final
    step, so just click **Create**:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 3 步（摘要）中，有一个简短的验证检查。系统可能会提示你，账户没有足够的计算/虚拟机（核心/vCPU）资源，这是因为 Microsoft 在账户创建时可能对其进行了限制。你需要创建一个支持票，申请增加资源，然后再试。如果你通过了此步骤，点击**确定**继续。现在你进入了最后一步，只需点击**创建**：
- en: '![](img/55fb8721-62c1-4693-a074-b0b9c9a76f10.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/55fb8721-62c1-4693-a074-b0b9c9a76f10.png)'
- en: 'Figure 10.24: Provisioning a deep learning instance on Azure, Step 4'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.24：在 Azure 上部署深度学习实例，步骤 4
- en: 'You may have to wait 30-40 minutes until the resources are created. When this
    is complete, select **All resources** on the left and you will see that all of
    the objects have been created. The following screenshot shows an example of this.
    Click on the one where the type is **Virtual Machine**:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要等待 30-40 分钟，直到资源创建完成。完成后，选择左侧的**所有资源**，你会看到所有对象已经创建。以下截图显示了这一点。点击类型为**虚拟机**的项目：
- en: '![](img/b96b0b9e-f5db-449d-846f-c1013f799bd9.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b96b0b9e-f5db-449d-846f-c1013f799bd9.png)'
- en: 'Figure 10.25: List of currently provisioned resources on Azure'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.25：当前在 Azure 上部署的资源列表
- en: You will then see the following screenshot. Click on the **Connect** button
    on the top of the screen.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后你将看到以下截图。点击屏幕顶部的**连接**按钮。
- en: 'A pane will open up on the right and give you an option to **Download RDP File**.
    Click on that, and when the file is downloaded, double-click on it:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右侧将弹出一个面板，提供**下载 RDP 文件**的选项。点击该选项，当文件下载完毕后，双击它：
- en: '![](img/4f60bb8b-8e00-4906-b815-9940b5a28833.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f60bb8b-8e00-4906-b815-9940b5a28833.png)'
- en: 'Figure 10.26: Downloading the RDP file to connect to the cloud instance in
    Azure'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.26：下载 RDP 文件以连接到 Azure 中的云实例
- en: 'This should bring up a login window to connect to the cloud instance. Enter
    the username and password that you created in step 1 to connect to the instance.
    When you connect, you will see a desktop similar to the following screenshot:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该会弹出一个登录窗口，连接到云实例。输入你在第 1 步中创建的用户名和密码以连接到实例。连接后，你将看到一个类似于以下截图的桌面：
- en: '![](img/a0697b47-5d20-4e0c-b5f5-9f775c2e5cb5.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0697b47-5d20-4e0c-b5f5-9f775c2e5cb5.png)'
- en: 'Figure 10.27: The remote desktop of the deep learning instance (Azure)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.27：深度学习实例的远程桌面（Azure）
- en: 'Great! RStudio is already installed. Keras is already installed, so any Keras
    deep learning code you have will run. Let''s try and run some MXNet code. Open
    RStudio and run the following commands to install MXNet:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！RStudio 已经安装好。Keras 也已安装，因此你任何的 Keras 深度学习代码都可以运行。现在让我们尝试运行一些 MXNet 代码。打开
    RStudio 并运行以下命令来安装 MXNet：
- en: '[PRE8]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will not work on the version of R installed. If you want to use MXNet,
    you must download the latest version of R (3.5.1 at the time of writing) and install
    it. Unfortunately, this will disable Keras, so only do this if you want to use
    MXNet instead of Keras. Once you download R from https://cran.r-project.org/,
    then re-run the code above to install MXNet.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前安装的 R 版本中，这将无法工作。如果你想使用 MXNet，必须下载最新版本的 R（撰写本书时是 3.5.1 版本）并安装。不幸的是，这会禁用 Keras，因此只有在你希望使用
    MXNet 而不是 Keras 时才这样做。从 https://cran.r-project.org/ 下载 R 后，再重新运行上面的代码来安装 MXNet。
- en: 'Note: The software installed on these AMI''s change very frequently. Before
    installing any deep learning library, check the version of CUDA that is installed.
    You need to ensure that they deep learning library is compatible with the version
    of CUDA installed on the machine.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这些 AMI 上安装的软件频繁变动。在安装任何深度学习库之前，检查已安装的 CUDA 版本。你需要确保深度学习库与机器上已安装的 CUDA 版本兼容。
- en: Using Google Cloud for deep learning
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Google Cloud 进行深度学习
- en: Google Cloud also has GPU instances. At the time of writing this book, the price
    of an instance with an NVIDIA Tesla K80 GPU card (which is also the GPU card in
    an AWS p2.xlarge instance) is $0.45 per hour on-demand. This is significantly
    cheaper than the AWS on-demand price. Further details of Google Cloud's GPU instances
    are at [https://cloud.google.com/gpu/](https://cloud.google.com/gpu/). However,
    for Google Cloud, we are not going to use instances. Instead, we are going to
    use the Google Cloud Machine Learning Engine API to submit machine learning jobs
    to the cloud. One big advantage of this approach over provisioning virtual machines
    is that you only pay for the hardware resources that you use and do not have to
    worry about setting up and terminating instances. More details and pricing can
    be found at [https://cloud.google.com/ml-engine/pricing](https://cloud.google.com/ml-engine/pricing).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 也提供 GPU 实例。在撰写本书时，配备 NVIDIA Tesla K80 GPU 卡（这也是 AWS p2.xlarge 实例中的
    GPU 卡）的实例按需价格为每小时 $0.45。这比 AWS 的按需价格便宜得多。有关 Google Cloud GPU 实例的更多详情，请访问 [https://cloud.google.com/gpu/](https://cloud.google.com/gpu/)。然而，对于
    Google Cloud，我们将不使用实例，而是使用 Google Cloud Machine Learning Engine API 将机器学习任务提交到云中。与虚拟机配置相比，这种方法的一个大优势是你只需为所使用的硬件资源付费，而无需担心设置和终止实例。更多详情和定价信息可以在
    [https://cloud.google.com/ml-engine/pricing](https://cloud.google.com/ml-engine/pricing)
    查找到。
- en: 'Go through the following steps to sign up for Google Cloud and enable the API:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤注册 Google Cloud 并启用 API：
- en: Sign up for an account with Google Cloud.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注册 Google Cloud 账号。
- en: You need to login to the portal at [https://console.cloud.google.com](https://console.cloud.google.com)
    and enable the **Cloud Machine Learning Engine** API.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要登录到门户网站 [https://console.cloud.google.com](https://console.cloud.google.com)
    并启用**Cloud Machine Learning Engine** API。
- en: Select **APIs & Services** from the main menu and click on the **Enable APIs
    and services** button.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从主菜单中选择**APIs & Services**，然后点击**启用 API 和服务**按钮。
- en: The APIs are contained in groups. Select **View All** for the **Machine Learning**
    group, then select **Cloud Machine Learning Engine** and ensure that the API is
    enabled.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: API 按组进行分类。选择**查看全部**以查看**机器学习**组，然后选择**Cloud Machine Learning Engine**并确保该
    API 已启用。
- en: 'Once the API is enabled, execute the following code from RStudio:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 API 后，从 RStudio 执行以下代码：
- en: '[PRE9]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This should install the Google Cloud SDK, and you will asked to connect your
    Google account to the SDK. Then, you will be taken through a menu of options in
    the Terminal window. The first option is as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会安装 Google Cloud SDK，并要求您将 Google 账户连接到 SDK。然后，您将进入终端窗口中的一个选项菜单。第一个选项如下：
- en: '![](img/09b57ce1-eb63-4e33-a609-82a1d2fe641b.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09b57ce1-eb63-4e33-a609-82a1d2fe641b.png)'
- en: 'Figure 10.28: Accessing Google Cloud SDK from RStudio'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.28：从 RStudio 访问 Google Cloud SDK
- en: For now, do not create any new projects or configurations, just select the ones
    that already exist. Once you have linked your Google account to the Google SDK
    on your machine and enabled the services, you are ready to go. The Cloud Machine
    Learning Engine allows you to submit a job to Google Cloud without having to create
    any instances. All the files in the working folder (R scripts and data) will be
    zipped up and sent to Google Cloud as a package.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，暂时不要创建任何新的项目或配置，只需选择已经存在的项目。一旦将您的 Google 账户连接到机器上的 Google SDK 并启用了相关服务，您就可以开始使用了。Cloud
    Machine Learning Engine 允许您向 Google Cloud 提交作业，而无需创建任何实例。工作文件夹中的所有文件（R 脚本和数据）将被打包并发送到
    Google Cloud。
- en: 'For this example, I took a the recommendation file from the project in [Chapter
    8](49a1fa27-1130-4f86-966e-cc73444b88a2.xhtml), *Deep Learning models using TensorFlow
    in R*. I copied this file and the `keras_recommend.R` script into a new directory
    and created a new RStudio project in that directory. I then opened the project
    in RStudio. You can see these two files and the RStudio project file in the previous
    screenshot. Then, I executed the following line in RStudio to submit the deep
    learning job:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我从 [第 8 章](49a1fa27-1130-4f86-966e-cc73444b88a2.xhtml) 项目中获取了推荐文件，*使用
    TensorFlow 在 R 中的深度学习模型*。我将该文件和 `keras_recommend.R` 脚本复制到一个新目录，并在该目录中创建了一个新的 RStudio
    项目。然后，我在 RStudio 中打开该项目。您可以在前面的截图中看到这两个文件和 RStudio 项目文件。接着，我在 RStudio 中执行以下命令提交深度学习作业：
- en: '[PRE10]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This will collect the files within the current working directory and send them
    to the Cloud Machine Learning Engine. As the job is executed, some progress information
    will be sent back to RStudio. You can also monitor the activity on the console page
    on [https://console.cloud.google.com](https://console.cloud.google.com) by selecting **ML
    Engine** | **Jobs**. Here is a screenshot of this web page showing two finished
    jobs and one that was canceled:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这将收集当前工作目录中的文件，并将其发送到 Cloud Machine Learning Engine。在作业执行过程中，一些进度信息将返回到 RStudio。您还可以通过选择**ML
    Engine** | **Jobs**，在 [https://console.cloud.google.com](https://console.cloud.google.com)
    控制台页面上监控活动。以下是该网页的截图，显示了两个已完成的作业和一个已取消的作业：
- en: '![](img/8519af01-4cd4-4c31-b2c2-3a1d7d03a2f7.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8519af01-4cd4-4c31-b2c2-3a1d7d03a2f7.png)'
- en: 'Figure 10.29: The ML Engine/Jobs page on the Google Cloud Platform web page'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.29：Google Cloud Platform 网页上的 ML 引擎/作业页面
- en: 'When the job is finished, the logs will be downloaded to your local machine.
    A nice summary web page is automatically created showing statistics for the job,
    as shown in the following screenshot:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当作业完成时，日志将被下载到本地机器。一个漂亮的总结网页会自动生成，显示作业的统计信息，如以下截图所示：
- en: '![](img/cfd08ae4-afaa-4f7f-b71a-d07a60c1f1d8.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cfd08ae4-afaa-4f7f-b71a-d07a60c1f1d8.png)'
- en: 'Figure 10.30: Web summary page from the machine learning job'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.30：机器学习作业的网页总结页面
- en: 'We can see the graph showing the progress of the model during training, the
    model summary, some hyperparameters (**epochs**, **batch_size**, and so on), as
    well as the cost (**ml_units**). The web page also contains the output from the
    R script. Select **Output** from the menu to see it. In the following screenshot,
    we can see the R code and the output from that code:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到图表显示了模型在训练过程中的进度、模型摘要、一些超参数（**epochs**、**batch_size** 等），以及成本（**ml_units**）。该网页还包含来自
    R 脚本的输出。选择菜单中的**输出**以查看。在以下截图中，我们可以看到 R 代码及其输出：
- en: '![](img/ccfca405-fa9f-4dd7-b102-fe39f624f402.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ccfca405-fa9f-4dd7-b102-fe39f624f402.png)'
- en: 'Figure 10.31: Web summary page from the machine learning job showing the R
    code and output'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.31：显示 R 代码和输出的机器学习作业网页总结页面
- en: This is only a brief introduction to using the Google Cloud Machine Learning
    Engine. There is an excellent tutorial at [https://tensorflow.rstudio.com/tools/cloudml/articles/tuning.html](https://tensorflow.rstudio.com/tools/cloudml/articles/tuning.html) that
    explains how you can use this service for hyperparameter training. Using this
    service rather than cloud instances for hyperparameter training is simpler and
    probably cheaper than trying to manage it yourself using virtual instances. You
    do not have to monitor it and coordinate the different runs of the model training. More
    information on using this service is available at [https://tensorflow.rstudio.com/tools/cloudml/articles/getting_started.html](https://tensorflow.rstudio.com/tools/cloudml/articles/getting_started.html).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是使用Google云机器学习引擎的简要介绍。这里有一个出色的教程，您可以在[https://tensorflow.rstudio.com/tools/cloudml/articles/tuning.html](https://tensorflow.rstudio.com/tools/cloudml/articles/tuning.html)查看，它解释了如何使用此服务进行超参数训练。使用此服务进行超参数训练，比使用虚拟实例自己管理训练要简单得多，而且可能更加便宜。您不必监控它或协调模型训练的不同运行。有关如何使用此服务的更多信息，请访问[https://tensorflow.rstudio.com/tools/cloudml/articles/getting_started.html](https://tensorflow.rstudio.com/tools/cloudml/articles/getting_started.html)。
- en: Using Paperspace for deep learning
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Paperspace进行深度学习
- en: '**Paperspace** is another interesting way to perform deep learning in the cloud.
    It might be the easiest way to train deep learning models in the cloud. To set
    up a cloud instance with Paperspace, you can log in to their console, provision a
    new machine, and connect to it from your web browser:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**Paperspace**是另一种有趣的方式，可以在云中进行深度学习。它可能是训练深度学习模型最简单的云端方式。要使用Paperspace设置云实例，您可以登录他们的控制台，配置一个新机器，并通过您的网页浏览器连接到它：'
- en: 'Start by signing up for a Paperspace account, log in to the console, and go
    into the Virtual Machine section by selecting Core or Compute. Paperspace has
    an RStudio TensorFlow template with NVIDIA GPU libraries (CUDA 8.0 and cuDNN 6.0)
    already installed, along with the GPU version of TensorFlow and Keras for R. You
    will see this machine type when you select **Public Templates**, as shown in the
    following screenshot:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先注册Paperspace账号，登录控制台，通过选择核心或计算进入虚拟机部分。Paperspace提供了一个带有NVIDIA GPU库（CUDA 8.0和cuDNN
    6.0）以及GPU版本的TensorFlow和Keras for R的RStudio TensorFlow模板。您在选择**公共模板**时将看到这种机器类型，如下图所示：
- en: '![](img/e81d0c7e-1252-4cc6-9f55-da9d48ab433f.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e81d0c7e-1252-4cc6-9f55-da9d48ab433f.png)'
- en: 'Figure 10.32: Paperspace portal'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.32：Paperspace门户
- en: 'You will be given a choice of three GPU instances and the choice of pay by
    the hour or monthly. Select the cheapest option (currently P4000 at $0.40 per
    hour) and the hourly pricing. Scroll down to the bottom of the page and press
    the **Create** button. After a few minutes, your machine will be provisioned and
    you will be able to access it through your browser. An example of an RStudio Paperspace
    instance is shown as follows:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将可以选择三种GPU实例，并选择按小时或按月付费。请选择最便宜的选项（目前是P4000，按小时收费$0.40）和按小时计费。向下滚动页面底部，点击**创建**按钮。几分钟后，您的机器将被配置完毕，您将能够通过浏览器访问它。以下是一个RStudio
    Paperspace实例的示例：
- en: '![](img/5dac837c-ce96-4cea-ae66-14f848f46040.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5dac837c-ce96-4cea-ae66-14f848f46040.png)'
- en: 'Figure 10.33: Accessing the virtual machine''s desktop from a web page and
    running RStudio for a Paperspace instance'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.33：从网页访问虚拟机桌面并运行RStudio，适用于Paperspace实例
- en: 'By default, Keras is already installed, so you can go ahead and train deep
    learning models using Keras. However, we are also going to install MXNet on our
    instance:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Keras已经安装，因此您可以直接使用Keras训练深度学习模型。然而，我们还将要在实例中安装MXNet：
- en: 'The first step is to open RStudio and install a few packages. Execute the following
    commands from RStudio:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是打开RStudio并安装一些包。从RStudio执行以下命令：
- en: '[PRE11]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The next step is to access the Terminal (or shell) for the instance you just
    created. You can go back to the console page and do it from there. Alternatively,
    click on the circle target in the top right corner of the desktop (see the previous
    screenshot). This also gives you other options such as synchronizing copy-and-paste
    between your local computer and the VM.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是访问您刚刚创建的实例的终端（或Shell）。您可以返回控制台页面从那里操作。或者，点击桌面右上角的圆形目标（请参见前面的截图）。这还为您提供了其他选项，如同步本地计算机和虚拟机之间的复制粘贴。
- en: 'Once you have logged in to the Terminal for the instance, running the following
    commands will install MXNet:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录实例的终端后，运行以下命令将安装MXNet：
- en: '[PRE12]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You also need to add the following line to the end of the `.profile` file:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还需要将以下行添加到 `.profile` 文件的末尾：
- en: '[PRE13]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: When you are done, restart the instance. You now have a machine that can train
    Keras and MXNet deep learning models in the cloud. For more details on using RStudio
    in Paperspace, see [https://tensorflow.rstudio.com/tools/cloud_desktop_gpu.html](https://tensorflow.rstudio.com/tools/cloud_desktop_gpu.html).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，重新启动实例。现在你有了一台可以在云端训练 Keras 和 MXNet 深度学习模型的机器。有关如何在 Paperspace 中使用 RStudio
    的更多详细信息，请参见 [https://tensorflow.rstudio.com/tools/cloud_desktop_gpu.html](https://tensorflow.rstudio.com/tools/cloud_desktop_gpu.html)。
- en: Summary
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have covered a lot of options for training deep learning models in this chapter!
    We discussed options for running it locally and showed the importance of having
    a GPU card. We used the three main cloud providers to train deep learning models
    in R on the cloud. Cloud computing is a fantastic resource – we gave an example
    of a super-computer costing $149,000\. A few years ago, such a resource would
    have been out of reach for practically everyone, but now thanks to cloud computing,
    you can rent a machine like this on an hourly basis.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 本章已经涵盖了许多训练深度学习模型的选项！我们讨论了本地运行的选项，并展示了拥有 GPU 卡的重要性。我们使用了三大主流云服务提供商，在云端使用 R 来训练深度学习模型。云计算是一个极其出色的资源——我们举了一个超级计算机的例子，价值
    149,000 美元。几年前，这样的资源几乎是每个人都无法企及的，但现在得益于云计算，你可以按小时租用这样的机器。
- en: For AWS, Azure, and Paperspace, we installed MXNet on the cloud resources, giving
    us the option of which deep learning library to use. I encourage you to use the
    examples in the other chapters in this book and try all the different cloud providers
    here. It is amazing to think that you could do so and your total cost could be
    less than $10!
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 AWS、Azure 和 Paperspace，我们在云端资源上安装了 MXNet，这让我们可以选择使用哪种深度学习库。我鼓励你使用本书其他章节中的示例，并尝试这里的所有不同云服务提供商。想想看，能做到这一点，而且你的总费用可能还不到
    $10，真是令人惊叹！
- en: In the next and final chapter, we build an image classification solution from
    image files. We will demonstrate how to apply transfer learning, which allows
    you to adapt an existing model to a new dataset. We will show how to deploy a
    model to production using a REST API and briefly discuss Generative Adversarial
    Networks, reinforcement learning and provide some further resources if you wish
    to continue on your deep learning quest.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章也是最后一章，我们将基于图像文件构建图像分类解决方案。我们将展示如何应用迁移学习，这使得你可以将现有模型适应新的数据集。我们还将展示如何通过 REST
    API 部署模型到生产环境，并简要讨论生成对抗网络、强化学习，同时提供一些进一步的资源，以便你继续深入学习深度学习。
