- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: What is ChatGPT and What are LLMs?
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 ChatGPT，LLM 是什么？
- en: The world has been strongly influenced by the recent advancements in AI, especially
    **large language models** ( **LLMs** ) such as ChatGPT and Gemini (formerly Bard).
    We’ve witnessed stories such as OpenAI reaching one million users in five days,
    huge tech company lay-offs, history-revising image scandals, more tech companies
    getting multi-trillion dollar valuations (Microsoft and NVIDIA), a call for funding
    of $5–7 trillion for the next stage of technology, and talks of revolutions in
    how *everything* is done!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 最近 AI 领域的进展，尤其是 **大型语言模型**（**LLM**），如 ChatGPT 和 Gemini（前身为 Bard），对世界产生了强烈影响。我们见证了
    OpenAI 在五天内达成一百万用户、巨型科技公司裁员、历史修正图像丑闻、更多科技公司获得数万亿美元估值（微软和 NVIDIA）、为下一阶段技术筹集 5-7
    万亿美元资金的呼声，以及关于如何*一切*都将发生革命性变化的讨论！
- en: Yes, these are all because of new AI technologies, especially LLM tech.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这一切都归功于新的 AI 技术，尤其是 LLM 技术。
- en: 'LLMs are large in multiple ways: not just large training sets and large training
    costs but also large impacts on the world!'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 在多个方面都很庞大：不仅是大规模的训练集和高昂的训练成本，还有它们对世界的巨大影响！
- en: This book is about harnessing that power effectively, for your benefit, if you
    are a coder.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是关于如何有效地利用这些技术为你带来好处，特别是如果你是程序员的话。
- en: Coding has changed, and we must all keep up or else our skills will become redundant
    or outdated. In this book are tools needed by coders to quickly generate code
    and do it well, to comment, debug, document, and stay ethical and on the right
    side of the law.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 编程方式发生了变化，我们必须紧跟其后，否则我们的技能将变得过时或无用。本书提供了程序员需要的工具，以便快速生成代码并做到精良，同时进行注释、调试、文档编写，并保持道德和合法性。
- en: If you’re a programmer or coder, this is for you. Software, especially AI/machine
    learning, is changing everything at ever-accelerating rates, so you’ll have to
    learn this stuff quickly, and then use it to create and understand future technologies.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是程序员或开发人员，这部分内容适合你。软件，尤其是 AI/机器学习，正在以前所未有的速度改变一切，所以你必须快速学习这些知识，并利用它们来创造和理解未来的技术。
- en: I don’t want to delay you any longer, so let’s get into the first chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想再耽误你时间了，咱们进入第一章吧。
- en: In this chapter, we’ll cover some basics of ChatGPT, Gemini, and other LLMs,
    where they come from, who develops them, and what the architectures entail. We’ll
    introduce some organizations that use LLMs and their services. We’ll also briefly
    touch on some mathematics that go into LLMs. Lastly, we’ll check out some of the
    competition and applications of LLMs in the field.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍 ChatGPT、Gemini 和其他 LLM 的一些基础知识，讲解它们的来源、开发者以及架构的组成。我们还将介绍一些使用 LLM 的组织及其服务。我们也会简要提到
    LLM 所涉及的一些数学原理。最后，我们将了解 LLM 在该领域的竞争态势和应用。
- en: 'This chapter covers the following topics:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Introduction to LLMs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 入门
- en: Origins of LLMs
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 的起源
- en: Early LLMs
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 早期的 LLM
- en: Exploring modern LLMs
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索现代 LLM
- en: How transformers work
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变换器如何工作
- en: Applications of LLMs
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 的应用
- en: Introduction to LLMs
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 入门
- en: ChatGPT is an LLM. LLMs can be used to answer questions and generate emails,
    marketing materials, blogs, video scripts, code, and even books that look a lot
    like they’ve been written by humans. However, you probably want to know about
    the technology.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 是一个大型语言模型（LLM）。LLM 可以用来回答问题、生成电子邮件、营销材料、博客、视频脚本、代码，甚至看起来像是由人类编写的书籍。然而，你可能更想了解这项技术。
- en: Let’s start with what an LLM is.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 LLM 是什么开始讲起。
- en: LLMs are deep learning models, specifically, transformer networks or just “
    *transformers* .” Transformers certainly have transformed our culture!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 是深度学习模型，具体来说，是变换器网络（或简称“*变换器*”）。变换器无疑改变了我们的文化！
- en: An LLM is trained on huge amounts of text data, petabytes (thousands of terabytes)
    of data, and predicts the next word or words. Due to the way LLMs operate, they
    are not perfect at outputting text; they can give alternative facts, facts that
    are “hallucinated.”
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 在巨大的文本数据上进行训练，数据量达到千兆字节（即数千个千兆字节），并预测下一个单词或词组。由于 LLM 的工作方式，它们在输出文本时并不完美；它们可能给出替代事实，或是“虚构”的事实。
- en: ChatGPT is, as of the time of writing, the most popular and famous LLM, created
    and managed by OpenAI. OpenAI is a charity and a capped-profit organization based
    in San Francisco [ *OpenAI_LP* , *OpenAIStructure* ].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本文撰写时，ChatGPT 是最受欢迎和最著名的 LLM，由 OpenAI 创建并管理。OpenAI 是一家总部位于旧金山的慈善机构和有限利润组织
    [ *OpenAI_LP* , *OpenAIStructure* ]。
- en: ChatGPT is now widely used for multiple purposes by a huge number of people
    around the world. Of course, there’s GPT-4 and now GPT-4 Turbo, which are paid,
    more powerful, and do more things, as well as taking more text in prompts.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT现在被世界各地的许多人广泛用于多种目的。当然，还有GPT-4以及现在的GPT-4 Turbo，它们是付费的，功能更强大，能够做更多事情，并且可以处理更多的提示文本。
- en: 'It’s called ChatGPT: *Chat* because that’s what you do with it, it’s a chatbot,
    and **GPT** is the technology and stands for **generative pre-trained transformer**
    . We will get more into that in the *GPT* *lineage* subsection.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 它被称为ChatGPT：“*Chat*”是因为这就是你与它的互动方式，它是一个聊天机器人，而**GPT**是技术的名称，代表**生成预训练的Transformer**。我们将在*GPT*
    *传承*小节中进一步探讨这一点。
- en: 'A transformer is a type of neural network architecture, and a transformer is
    the basis of the most successful LLMs today (2024). GPT is a Generative Pre-trained
    Transformer. Gemini is a transformer [ *ChatGPT* , *Gemini* , *Menon* , *HuggingFace*
    ]. OpenAI’s GPT-4 is a remarkable advancement in the field of AI. This model,
    which is the fourth iteration of the GPT series, has introduced a new feature:
    the ability to generate images alongside text. This is a significant leap from
    its predecessors, which were primarily text-based models.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer是一种神经网络架构，也是当今最成功的LLMs的基础（2024年）。GPT是一个生成预训练的Transformer。Gemini是一个Transformer
    [*ChatGPT*，*Gemini*，*Menon*，*HuggingFace*]。OpenAI的GPT-4是人工智能领域的一个显著进步。这个模型是GPT系列的第四代，它引入了一个新功能：能够生成文本和图像。这是一个重大的飞跃，相比于其主要基于文本的前身。
- en: OpenAI also has an image generation AI, DALL-E, and an AI that can connect images
    and text and does image recognition, called CLIP ( *OpenAI_CLIP* ). The image
    generation capability of DALL-E is achieved by training the transformer model
    on image data. This means that the model has been exposed to a vast array of images
    during its training phase, enabling it to understand and generate visual content
    [ *OpenAI_DALL.E* ] .
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI还拥有一款图像生成AI——DALL-E，以及一款可以将图像与文本结合并进行图像识别的AI，叫做CLIP（*OpenAI_CLIP*）。DALL-E的图像生成能力是通过对图像数据训练Transformer模型实现的。这意味着，在训练过程中，模型接触到了大量的图像数据，从而使它能够理解并生成视觉内容
    [*OpenAI_DALL.E*]。
- en: Furthermore, since images can be sequenced to form videos, DALL.E can also be
    considered a video generator. This opens up a plethora of possibilities for content
    creation, ranging from static images to dynamic videos. It’s a testament to the
    versatility and power of transformer models, and a glimpse into the future of
    AI capabilities.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于图像可以按顺序排列形成视频，DALL-E也可以被视为一个视频生成器。这为内容创作开辟了无数可能性，从静态图像到动态视频。这证明了Transformer模型的多功能性和强大能力，展现了人工智能未来的潜力。
- en: In essence, tools from OpenAI are not just text generators but a comprehensive
    suite of content generators, capable of producing a diverse range of outputs.
    It’s called being **multi-modal** . This makes these tools invaluable in numerous
    applications, from content creation and graphic design to research and development.
    The evolution from GPT-3 to GPT-4 signifies a major milestone in AI development,
    pushing the boundaries of what AI models can achieve.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，OpenAI的工具不仅仅是文本生成器，而是一个综合的内容生成套件，能够生成各种输出。这被称为**多模态**。这使得这些工具在许多应用中都极具价值，从内容创作、图形设计到研究和开发。GPT-3到GPT-4的演变标志着人工智能发展的一个重要里程碑，推动了AI模型能够实现的边界。
- en: Origins of LLMs
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs的起源
- en: Earlier neural networks with their ability to read sentences and predict the
    next word could only read one word at a time and were called **recurrent neural
    networks** , ( **RNNs** ). RNNs attempted to mimic human-like sequential processing
    of words and sentences but faced challenges in handling long-term dependencies
    between words and sentences due to very limited memory capacity.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的神经网络凭借其读取句子并预测下一个词的能力，每次只能读取一个词，这些网络被称为**递归神经网络**（**RNNs**）。RNNs尝试模拟类似人类的按顺序处理单词和句子的方式，但由于内存容量有限，它们在处理单词和句子之间的长期依赖关系时面临着挑战。
- en: In 1925, the groundwork was laid by Wilhelm Lenz and Ernst Ising with their
    non-learning Ising model, considered an early RNN architecture [ *Brush* , *Gemini*
    ].
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 1925年，Wilhelm Lenz和Ernst Ising奠定了基础，提出了他们的非学习型Ising模型，被认为是早期的RNN架构 [*Brush*，*双子*]。
- en: In 1972, Shun’ichi Amari made this architecture adaptive, paving the way for
    learning RNNs. This work was later popularized by John Hopfield in 1982 [ *Amari*
    , *Gemini* ].
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 1972年，天谷俊一（Shun’ichi Amari）使这一架构具备适应性，为学习RNNs铺平了道路。这项工作在1982年由John Hopfield进一步推广
    [*天谷*，*双子*]。
- en: Due to this, there has been a fair amount of research to find ways to stretch
    this memory to include more text to get more context. RNNs are transformers. There
    are other transformers, including **LSTMs** , which are **long short-term memory**
    neural networks that are based on a more advanced version of RNNs, but we won’t
    go into that here [ *Brownlee_LLMs* , *Gemini* ]. LSTMs were invented by Hochreiter
    and Schmidhuber in 1997 [ *Wiki_LSTM* , *Hochreiter1997* ].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，已经有相当多的研究试图找到方法，扩大这种记忆以包括更多文本，以获得更多上下文。RNN是变压器。还有其他变压器，包括**LSTM**，即基于RNN的更高级版本的**长短期记忆**神经网络，但我们在此不再深入讨论
    [*Brownlee_LLMs*，*Gemini*]。LSTM由Hochreiter和Schmidhuber于1997年发明 [*Wiki_LSTM*，*Hochreiter1997*]。
- en: 'There is another network called the **convolutional neural network** ( **CNN**
    ). Without going into much detail, CNNs are very good at images and lead the world
    in image recognition and similar jobs. CNNs (or ConvNets) were invented in 1980
    by Kunihiko Fukushima and developed by Yann LeCun, but they only really became
    popular in the 2000s, when GPUs became available. Chellapilla *et al* . tested
    the speeds of training CNNs on CPUs and GPUs and found the network trained on
    GPUs 4.1 times faster [ *Fukushima1980* , *LeCun1989* , *Chellapilla2006* ]. Sometimes,
    your inventions take time to bear fruit, but keep inventing! CNNs use many layers
    or stages to do many different mathematical things to their inputs and try to
    look at them in different ways: different angles, with detail taken out (dropout
    layers), pooling nearby regions of each image, zeroing negative numbers, and other
    tricks.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个网络叫做**卷积神经网络**（**CNN**）。不多讲，CNN在图像处理方面非常出色，并引领着全球的图像识别等相关工作。CNN（或ConvNets）由Fukushima
    Kunihiko于1980年发明，并由Yann LeCun发展，但直到2000年代，随着GPU的出现，CNN才真正流行开来。Chellapilla *等人*测试了在CPU和GPU上训练CNN的速度，发现GPU训练速度比CPU快4.1倍
    [*Fukushima1980*，*LeCun1989*，*Chellapilla2006*]。有时，发明需要时间才能取得成果，但继续发明吧！CNN使用多个层或阶段对输入做许多不同的数学运算，并尝试从不同的角度来看待它们：不同的视角、去除细节（丢弃层）、对图像的邻近区域进行池化、将负数归零等技巧。
- en: What was needed was a model with some form of memory to remember and also generate
    sentences and longer pieces of writing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 需要的是一个具备某种记忆功能的模型，能够记住并生成句子和更长的写作内容。
- en: In 2017, Ashish Vaswani and others published a paper called *Attention Is All
    You Need* , [ *Vaswani* , *2017* ]. In this important paper, the transformer architecture
    was proposed based on attention mechanisms. In other words, this model didn’t
    use recurrence and convolutions, such as RNNs and CNNs. These methods have been
    very successful and popular AI architectures in their own right.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年，Ashish Vaswani等人发表了一篇名为*Attention Is All You Need*的论文，[*Vaswani*，*2017*]。在这篇重要的论文中，提出了基于注意力机制的Transformer架构。换句话说，这个模型没有使用递归和卷积，如RNN和CNN。这些方法本身已经是非常成功和流行的AI架构。
- en: Compared to RNNs and CNNs, Vaswani’s Transformer performed faster training and
    allowed for higher parallelizability.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与RNN和CNN相比，Vaswani的Transformer在训练速度上表现更快，并且支持更高的并行化。
- en: The Transformer was the benchmark for English-to-German translation and established
    a new state-of-the-art single model in the WMT 2014 English-to-French translation
    task. It also performed this feat after being trained for a small fraction of
    the training times of the next best existing models. Indeed, Transformers were
    a groundbreaking advancement in natural language processing [ *Vaswani* , *2017*
    ].
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer成为了英德翻译的基准，并在WMT 2014英法翻译任务中建立了新的单一模型技术。它还在训练时间远低于下一个最佳现有模型的情况下，完成了这一壮举。事实上，Transformer在自然语言处理领域是一次突破性的进展
    [*Vaswani*，*2017*]。
- en: Now that we have covered the origins of LLMs, we will check out some of the
    earliest LLMs that were created.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了LLM的起源，接下来我们将看看一些最早创建的LLM。
- en: Early LLMs
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 早期LLM
- en: 'There are many LLMs today and they can be put into a family tree; see *Figure
    1* *.1* . The figure shows the evolution from word2vec to the most advanced LLMs
    in 2023: GPT-4 and Gemini [ *Bard* ].'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 今天有许多LLM，它们可以被归类到一个家族树中；见*图1.1*。该图展示了从word2vec到2023年最先进的LLM：GPT-4和Gemini [*Bard*]的演变过程。
- en: '![Figure 1.1: Family tree of LLMs from word2vec to GPT-4 and Bard, from Yang2023
    with permission](img/B21009_01_1.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1：从word2vec到GPT-4和Bard的LLM家族树，来自Yang2023，已获许可](img/B21009_01_1.jpg)'
- en: 'Figure 1.1: Family tree of LLMs from word2vec to GPT-4 and Bard, from Yang2023
    with permission'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：从word2vec到GPT-4和Bard的LLM家族树，来自Yang2023，已获许可
- en: So, that’s all of them but, for now, we’ll look at the earlier LLMs that lead
    to the most advanced technologies today. We’ll start with GPT.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就是所有版本，但现在我们将关注那些早期的LLM，它们为今天最先进的技术奠定了基础。我们从GPT开始。
- en: GPT lineage
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT谱系
- en: The development of GPT is a constantly changing and iterative process, with
    each new model building upon the strengths and weaknesses of its ancestors. The
    GPT series, initiated by OpenAI, has undergone a great deal of evolution, leading
    to advancements in **natural language processing** ( **NLP** ) and understanding.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: GPT的发展是一个不断变化的迭代过程，每一个新模型都在前代的优势和不足上进行构建。由OpenAI发起的GPT系列经历了许多演变，推动了**自然语言处理**（**NLP**）和理解的进展。
- en: GPT-3, the third iteration, brought a significant leap in terms of size and
    complexity, with an impressive 175 billion parameters. This allowed it to generate
    pretty human-like text across a wide range of topics and subjects [ *Wiki_GPT3*
    , *ProjectPro* ].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次迭代的GPT-3带来了在规模和复杂性方面的重大飞跃，拥有令人印象深刻的1750亿个参数。这使得它能够在广泛的主题和学科上生成相当类人化的文本 [*Wiki_GPT3*
    , *ProjectPro* ]。
- en: As the GPT series progressed, OpenAI continued to refine and enhance the architecture.
    In subsequent iterations, GPT-4 and GPT-4 Turbo have further pushed back the boundaries
    of what these LLMs can achieve. The iterative development process focuses on increasing
    model size and improving fine-tuning capabilities, enabling more nuanced and contextually
    relevant outputs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 随着GPT系列的发展，OpenAI不断完善和增强架构。在后续的迭代中，GPT-4和GPT-4 Turbo进一步推动了这些LLM所能实现的边界。迭代开发过程着重于增加模型大小和提高微调能力，从而使输出更具细致性和语境相关性。
- en: Further to this, there are more modalities, such as GPT-4 with vision and text-to-speech.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有更多的模式，比如具有视觉和文本到语音功能的GPT-4。
- en: GPT model iteration is not solely about scaling up the number of parameters;
    it also involves addressing the limitations observed in earlier versions. Feedback
    from user interactions, research findings, and technological advancements contribute
    to the iterative nature of the GPT series. OpenAI is constantly working to reduce
    the amount of inaccurate information and incoherent outputs (hallucinations) that
    its chatbots produce. Also, each iteration of the chatbot takes on board the lessons
    learned from real-world applications and user feedback.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型的迭代不仅仅是通过增加参数数量来扩展；它还涉及解决早期版本中发现的局限性。用户互动、研究成果和技术进步的反馈有助于GPT系列的迭代特性。OpenAI始终致力于减少其聊天机器人生成的不准确信息和不连贯的输出（幻觉）。此外，每一次迭代都会吸取现实应用和用户反馈的经验教训。
- en: GPT models are trained and fine-tuned on very large, diverse datasets to make
    sure the chatbots can adapt to many different contexts, industries, and user requirements.
    The iterative development approach ensures that later GPT models are better equipped
    to understand and generate human-like text, making them extremely valuable tools
    for a huge number of applications, including content creation such as blogs, scripts
    for videos, and copywriting (writing the text in adverts) as well as conversational
    agents (chatbots and AI assistants).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型通过在非常大且多样化的数据集上进行训练和微调，以确保聊天机器人能够适应许多不同的语境、行业和用户需求。迭代开发方法确保了后续的GPT模型更能理解和生成类人文本，使其成为各种应用场景中极具价值的工具，包括内容创作（如博客、视频剧本、广告文案写作）以及对话型代理（聊天机器人和AI助手）。
- en: The way GPT models are developed iteratively shows OpenAI’s commitment to continuous
    improvement and innovation in the field of LLMs, allowing even more sophisticated
    and capable models to be built from these models in the future.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型的迭代开发方式展示了OpenAI在LLM领域持续改进和创新的承诺，这为未来基于这些模型构建更复杂、更强大的模型奠定了基础。
- en: 'Here are the dates for when the different versions of GPT were launched:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是不同版本的GPT发布的日期：
- en: GPT was first launched in June 2018
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT首次发布是在2018年6月
- en: GPT-2 was released in February 2019
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-2于2019年2月发布
- en: GPT-3 in 2020
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2020年的GPT-3
- en: GPT-3.5 in 2022/ChatGPT in November 2022
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2022年的GPT-3.5/2022年11月的ChatGPT
- en: There will be more on the GPT family later, in the *GPT-4 /GPT-4* *Turbo* section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPT家族的内容将在稍后的*GPT-4 /GPT-4* *Turbo*部分详细讨论。
- en: Here, we will detail the architecture of LLMs and how they operate.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将详细介绍LLM的架构以及它们的工作原理。
- en: BERT
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BERT
- en: To comprehend the roots and development of **Bidirectional Encoder Representations
    from Transformers** ( **BERT** ), we must know more about the intricate and fast-moving
    landscape of neural networks. Without hyperbole, BERT was a seriously important
    innovation in NLP, part of the ongoing evolution of AI. BERT was the state of
    the art for a wide range of NLP tasks in October 2018, when it was released [
    *Gemini* ]. This included question answering, sentiment analysis, and text summarization.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解**双向编码器表示法（来自变压器）**（**BERT**）的根源和发展，我们必须深入了解神经网络这一复杂且快速发展的领域。毫不夸张地说，BERT在NLP领域是一个非常重要的创新，代表了AI不断进化的一部分。BERT在2018年10月发布时，成为了广泛NLP任务的最前沿技术[*Gemini*]。这些任务包括问答、情感分析和文本摘要。
- en: BERT also paved the way for later R&D of LLMs; it played a pivotal role in LLM
    development. BERT, being open source, helped to speed up LLM advancement.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: BERT也为后来的LLM研发铺平了道路；它在LLM的发展中发挥了重要作用。由于BERT是开源的，它帮助加速了LLM的进展。
- en: BERT takes some of its DNA from RNNs (mentioned in the *Origins of LLMs* section),
    the neural nets that loop back on themselves to create a kind of memory, although
    rather limited memory.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: BERT从RNN（在*LLM的起源*部分提到的神经网络）中汲取了一些DNA，RNN通过自我循环创建某种记忆，尽管这种记忆相对有限。
- en: The invention of the first transformer architecture was key to the origin of
    BERT. The creation of BERT as a bidirectional encoder (these go backward and forward
    along a sentence) drew inspiration from the transformer’s attention-based mechanism,
    allowing it to capture contextual relationships between words in both directions
    within a sentence.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个变压器架构的发明是BERT起源的关键。作为双向编码器的BERT（这些编码器在句子中前后移动）受变压器注意力机制的启发，能够捕捉句子中单词之间的双向上下文关系。
- en: So, BERT’s attention is bidirectional (left-to-right and right-to-left context).
    At its creation, this was unique, and it enabled BERT to gain a more comprehensive
    understanding of nuanced language semantics.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，BERT的注意力是双向的（从左到右和从右到左的上下文）。在其创立之时，这种特性是独特的，它使得BERT能够更全面地理解语言的微妙语义。
- en: While BERT’s foundations are in transformer architecture, its characteristics
    have evolved with further research and development, though it is not currently
    in development. Each iteration of BERT refined and expanded its capabilities.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然BERT的基础是变压器架构，但随着进一步的研究与发展，其特性也不断演变，尽管目前并未处于开发阶段。BERT的每次迭代都在精炼和扩展其能力。
- en: The BERT LLM was a stage of the ongoing innovation in AI. BERT’s ability to
    understand language bidirectionally, drawing insights from both preceding and
    succeeding words, is part of the endeavors taken to achieve the creation of an
    AI with a sufficiently deep awareness of the intricacies of natural language.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: BERT LLM是AI持续创新的一部分。BERT理解语言的双向能力，从前后单词中汲取洞察，是为实现具有深刻自然语言理解的AI所做努力的一部分。
- en: "![Figure 1.2: Architecture of BERT, a bidirectional encoder (reprodu\uFEFF\
    ced from GeekCultureBERT)](img/B21009_01_2.jpg)"
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2：BERT架构，双向编码器（转载自GeekCultureBERT）](img/B21009_01_2.jpg)'
- en: 'Figure 1.2: Architecture of BERT, a bidirectional encoder (reprodu ced from
    GeekCultureBERT)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：BERT架构，双向编码器（转载自GeekCultureBERT）
- en: LaMDA
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LaMDA
- en: Understanding the ancestry of **Language Model for Dialogue Applications** (
    **LaMDA** ) involves tracing the roots of its architectural design and the evolutionary
    path it followed in the landscape of NLP. LaMDA, like its counterparts, emerges
    from a family of models that have collectively revolutionized how machines comprehend
    and generate human-like text.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 理解**对话应用语言模型**（**LaMDA**）的起源涉及追溯其架构设计的根源以及它在自然语言处理（NLP）领域的发展路径。LaMDA与其他模型一样，来自于一系列共同革新人类语言理解与生成方式的模型。
- en: RNNs, mentioned in this chapter’s first section, play a pivotal role in LaMDA’s
    family tree.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本章第一节提到的RNN在LaMDA的家族谱系中发挥着关键作用。
- en: The breakthrough came with the invention of transformer architectures, and LaMDA
    owes a significant debt to the transformative *Attention Is All You Need* paper
    [ *Vaswani* *2017* , *2023* ]. This paper laid the groundwork for a novel approach,
    moving away from sequential processing to a more parallelized and attention-based
    mechanism.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 突破性进展来自于变压器架构的发明，而LaMDA要感谢具有革命性的*Attention Is All You Need*论文[*Vaswani* *2017*，*2023*]。这篇论文为一种新方法奠定了基础，推动了从顺序处理转向更加并行化和基于注意力的机制。
- en: The LaMDA LLM inherits its core architecture from the transformer family and
    was developed by Google. These models learn very well how words in a sentence
    relate to each other. This allows a transformer to have a richer understanding
    of language. This change from using traditional processing in sequence was a paradigm
    shift in NLP, enabling LaMDA to more effectively grasp nuanced interactions and
    dependencies within texts.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LaMDA LLM从变压器家族继承了其核心架构，并由Google开发。这些模型非常擅长学习句子中词语之间的关系。这使得变压器能更丰富地理解语言。这一从传统的顺序处理转变为NLP中的范式转变，使得LaMDA能更有效地把握文本中微妙的交互和依赖关系。
- en: While the origins lie in the transformer architecture, LaMDA’s unique characteristics
    may have been fine-tuned and evolved through subsequent research and development
    efforts. LaMDA’s lineage is not just a linear progression but a family tree, a
    branching exploration of many possibilities, with each iteration refining and
    expanding its capabilities. In *Figure 1* *.1* , LaMDA is near ERNIE 3.0, Gopher,
    and PaLM on the right of the main, vertical blue branch.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然起源于变压器架构，但LaMDA的独特特性可能通过后续的研究和开发工作进行了精细调整和演进。LaMDA的血统不仅仅是线性的进展，而是一个家族树，是许多可能性的分支探索，每一次迭代都在完善和扩展其能力。在
    *Figure 1* *.1* 中，LaMDA位于主要垂直蓝色分支右侧的ERNIE 3.0、Gopher和PaLM附近。
- en: Simply put, LaMDA is a product of ongoing innovation and refinement in the field
    of AI, standing on the shoulders of earlier models and research breakthroughs.
    Its ability to comprehend and generate language is deeply rooted in an evolutionary
    process of learning from vast amounts of text data, mimicking the way humans process
    and understand language on a grand, digital scale.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，LaMDA是人工智能领域持续创新和精炼的产物，站在早期模型和研究突破的肩膀上。其理解和生成语言的能力深深扎根于从大量文本数据中学习的进化过程，模仿人类在大规模数字化环境中处理和理解语言的方式。
- en: LaM DA was launched in May 2021.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: LaMDA于2021年5月推出。
- en: LLaMA‘s family tree
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLaMA家族树
- en: LLaMA is the AI brainchild of Meta AI. It might not be one you’ve heard the
    most about but its lineage holds stories of innovation and evolution, tracing
    a fascinating path through the history of AI communication.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA是Meta AI的人工智能孩子。也许它不是你最常听说的，但其血统中充满了创新和进化的故事，穿越了AI沟通历史的一段迷人旅程。
- en: Like the other chatbot LLMs, LLaMA’s roots are also in transformer architectures.
    These models rely on intricate attention mechanisms, allowing them to analyze
    relationships between words, not just their sequence.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 像其他聊天机器人LLM一样，LLaMA的根源也在变压器架构中。这些模型依赖复杂的注意机制，使它们能够分析单词之间的关系，而不仅仅是它们的顺序。
- en: Trained on massive datasets of text and code, LLaMA learned to generate basic
    responses, translate languages, and even write different kinds of creative text
    formats.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在大量文本和代码数据集上训练后，LLaMA学会了生成基本的响应、翻译语言，甚至写不同类型的创意文本格式。
- en: However, like a newborn foal, their capabilities were limited. They stumbled
    with complex contexts, lacked common sense reasoning, and sometimes sputtered
    out nonsensical strings.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，就像一个新生的小马驹一样，它们的能力是有限的。它们在复杂语境中踉跄，缺乏常识推理，有时会发出不连贯的字符串。
- en: Yet their potential was undeniable. The ability to learn and adapt from data
    made them valuable tools for researchers. Meta AI nurtured these nascent models,
    carefully tweaking their architecture and feeding them richer datasets. They delved
    deeper into the understanding of human language, acquiring skills such as factual
    grounding, reasoning, and the ability to engage in multi-turn conversations (Wiki_llama).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们的潜力是不可否认的。从数据中学习和适应的能力使它们成为研究人员的宝贵工具。Meta AI精心培养这些新生模型，仔细调整它们的架构并提供更丰富的数据集。它们深入理解人类语言，掌握了事实基础、推理能力和参与多轮对话的能力（Wiki_llama）。
- en: 'The Llama family tree is not a linear progression but, rather, a family of
    multiple branches of exploration. Different versions explored specific avenues:
    Code Llama focused on code generation, while Megatron-Turing NLG 530 B was trained
    on filling in missing words, reading comprehension, and common-sense reasoning,
    among other things ( *CodeLlama 2023* , *Megatron-Turing 2022* ).'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Llama家族树不是线性的进展，而是多个探索分支的家族。不同版本探索了特定的途径：Code Llama专注于代码生成，而Megatron-Turing
    NLG 530 B则训练了填补缺失单词、阅读理解和常识推理等能力（ *CodeLlama 2023* , *Megatron-Turing 2022* ）。
- en: For an idea of how LLaMA fits into the evolutionary tree, see *Figure 1* *.1*
    at the top left of the vertical blue branch, near Bard ( *Gemini* ).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于LLaMA在进化树中的位置，可以参见左上角垂直蓝色分支上的*图1* *1.1*，靠近Bard（*Gemini*）。
- en: Each experiment, each successful leap forward, contributed valuable DNA to future
    generations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 每一次实验，每一次成功的进步，都为未来的世代贡献了宝贵的基因。
- en: Why the name *Megatron-Turing NLG 530 B* ? *Megatron* because it represents
    a powerful hardware and software framework. *Turing* to honor Alan Turing, the
    first AI researcher, and the originator of AI and ML. **NLG** stands for **natural
    language generation** , and it has 530 billion parameters.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么叫*Megatron-Turing NLG 530 B*？*Megatron*代表着强大的硬件和软件框架；*Turing*是为了向艾伦·图灵致敬，图灵是第一个AI研究者，也是人工智能和机器学习的奠基人。**NLG**代表**自然语言生成**，它拥有5300亿个参数。
- en: Meta AI continues to shepherd the Llama family, and the future promises more
    exciting developments.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Meta AI继续管理Llama家族，未来充满了更多激动人心的进展。
- en: Llama LLM was launched in February 2023, while Megatron-Turing NLG 530 B was
    released in January 2022.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Llama LLM于2023年2月发布，而Megatron-Turing NLG 530 B则在2022年1月发布。
- en: Now that we have covered the origins and explored the early stages of LLMs,
    let us fast-forward and talk about modern LLMs in the next section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了LLMs的起源并探索了其早期阶段，让我们快进到下一部分，谈一谈现代LLMs。
- en: Exploring modern LLMs
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索现代LLMs
- en: After the explosive take-off of ChatGPT in late 2022, with 1 million active
    users in 5 days and 100 million active users in January 2023 (about 2 months),
    2023 was a pretty hot year for LLMs, AI research, and the use of AI in general.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年底ChatGPT爆炸性起飞之后，仅用了5天就达到了100万活跃用户，2023年1月（大约两个月）活跃用户突破1亿，2023年对大语言模型（LLMs）、人工智能研究以及人工智能的广泛应用来说是一个非常火热的年份。
- en: Most tech companies have worked on their own LLMs or transformer models to use
    and make publicly available. Many companies, organizations, and individuals (students
    included) have used LLMs for a multitude of tasks. OpenAI keeps updating its GPT
    family and Google keeps updating its Bard version. Bard became Gemini in February
    2024, so all references to Bard have changed to Gemini. Many companies use ChatGPT
    or GPT-4 as the core of their offering, just creating a wrapper and selling it.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数科技公司都在开发自己的LLM或变压器模型，并将其公开使用。许多公司、组织和个人（包括学生）都已将LLM应用于各种任务。OpenAI不断更新其GPT家族，而Google则持续更新其Bard版本。Bard在2024年2月变更为Gemini，因此所有对Bard的引用都已更改为Gemini。许多公司将ChatGPT或GPT-4作为其产品的核心，仅仅创建一个外壳并进行销售。
- en: This might change as OpenAI keeps adding modalities (speech, image, etc.) to
    the GPTs and even a new marketplace platform where users can create and sell their
    own GPT agents right on OpenAI servers. This was launched in early January 2024
    to paid users ($20/month before VAT). We’ll cover some of the latest LLMs that
    companies have wor ked on in the following sections.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 随着OpenAI不断为GPTs添加新的模态（语音、图像等）以及一个新的市场平台，用户可以在OpenAI的服务器上创建并销售自己的GPT代理，未来可能会发生变化。该平台在2024年1月初推出，面向付费用户（每月$20，未含增值税）。我们将在接下来的章节中介绍一些公司正在开发的最新LLMs。
- en: GPT-4
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4
- en: GPT-4 Turbo, OpenAI’s latest hot chatbot, is another big upgrade. It’s the GPT-4
    you know, but on steroids, with 10 times more memory and a newfound understanding
    of images.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 Turbo，OpenAI最新的热聊机器人，是另一次重大升级。它是你所熟悉的GPT-4，但拥有了10倍的内存，并且对图像有了全新的理解。
- en: If GPT-4 was a gifted writer, GPT-4 Turbo is a multimedia polymath. It can not
    only spin captivating stories and poems but also decipher images, paint vivid
    digital landscapes, and even caption photos with witty remarks. Forget outdated
    information – Turbo’s knowledge base refreshes constantly, keeping it as sharp
    as a tack on current events.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果说GPT-4是一个天才作家，那么GPT-4 Turbo就是一个多媒体博学者。它不仅能编织引人入胜的故事和诗歌，还能解读图像、绘制生动的数字画面，甚至用机智的评论为照片配上字幕。忘掉过时的信息吧——Turbo的知识库不断更新，确保其在时事上保持如针锋般的敏锐。
- en: But it’s not just about flashy tricks. Turbo is a stickler for facts. It taps
    into external knowledge bases and employs sophisticated reasoning, ensuring its
    responses are accurate and reliable. Gone are the days of biased or misleading
    outputs – Turbo strives for truth and clarity, making it a trustworthy companion
    for learning and exploration.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 但它不仅仅是一些炫酷的技巧。Turbo是一个对事实极为挑剔的家伙。它能够访问外部知识库，并采用复杂的推理，确保其回答既准确又可靠。过去偏见或误导的输出已经成为历史——Turbo力求真理与清晰，是学习和探索过程中的可靠伙伴。
- en: The best part? OpenAI isn’t keeping this powerhouse locked away. They’ve crafted
    an API and developer tools, inviting programmers and innovators to customize Turbo
    for specific tasks and domains. This democratization of advanced language processing
    opens doors to a future where everyone, from artists to scientists, can harness
    the power of language models to create, analyze, and understand the world around
    them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最棒的部分？OpenAI 并没有将这个强大的技术封锁起来。他们制作了 API 和开发者工具，邀请程序员和创新者定制 Turbo 以应对特定的任务和领域。这种高级语言处理的民主化为未来开辟了大门，未来每个人，无论是艺术家还是科学家，都可以利用语言模型的力量创造、分析和理解周围的世界。
- en: GPT-4 Turbo is probably widely considered the pinnacle of technology at the
    moment, showing us the breathtaking potential of LLMs. It’s not just a language
    model; it’s a glimpse into a future where machines understand and interact with
    us like never before. So, buckle up! The future of language is here, and it’s
    powered by GPT-4 Turbo.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 Turbo 可能被广泛认为是目前科技的巅峰，向我们展示了 LLM 的惊人潜力。它不仅仅是一个语言模型；它是我们走向一个未来的前瞻，未来机器将以前所未有的方式理解并与我们互动。所以，系好安全带！语言的未来已经到来，而它的动力来自
    GPT-4 Turbo。
- en: GPT-4 was launched in March 2023 and GPT-4 Turbo in November 2023 ( *Wiki_GPT4*
    , *OpenAI_GPT4Turbo* , *Gemini* ).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 于 2023 年 3 月发布，GPT-4 Turbo 于 2023 年 11 月发布（*Wiki_GPT4*，*OpenAI_GPT4Turbo*，*Gemini*）。
- en: GPT-4o or GPT-4 omni was released in May 2024, and it can understand multiple
    formats of data. Omni is faster than previous models and can respond to speech
    in 0.32 seconds on average, similar to human response times, while Turbo takes
    about 5.4 seconds to respond in Voice Mode.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o 或 GPT-4 omni 于 2024 年 5 月发布，它可以理解多种格式的数据。Omni 比之前的模型更快，平均响应时间为 0.32 秒，类似于人类的反应时间，而
    Turbo 在语音模式下大约需要 5.4 秒响应。
- en: This is partially because, while Turbo takes in text, transcribed from the audio
    by a simple model, and a third model converts the text back into audio response,
    omni is a single model that understands audio, video, and text. The three models
    for Turbo are slower than omni and a lot of information is lost to GPT-4 Turbo
    due to transcription.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分是因为，尽管 Turbo 通过一个简单模型将音频转录为文本，再通过第三个模型将文本转回音频响应，而 omni 是一个理解音频、视频和文本的单一模型。Turbo
    的三个模型比 omni 更慢，而且由于转录，GPT-4 Turbo 会丢失很多信息。
- en: GPT-4o is much better than GPT-4 Turbo in non-English human languages.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o 在非英语人类语言处理方面远远优于 GPT-4 Turbo。
- en: The Omni API is also half the cost of Turbo ( *OpenAI-GPT-4o* )!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Omni API 的成本也仅为 Turbo 的一半（*OpenAI-GPT-4o*）！
- en: GPT-4o does very well on code generation versus Claude 3 Opus and Gemini 1.5
    Pro. Claude is moderate, Gemini is judged to be very good, and GPT-4o is excellent
    [ *encord* ].
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o 在代码生成方面表现非常出色，相较于 Claude 3 Opus 和 Gemini 1.5 Pro。Claude 表现中等，Gemini 被评为非常好，而
    GPT-4o 的表现则是优秀的 [*encord*]。
- en: GPT-4 architecture
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPT-4 架构
- en: OpenAI has not released details of the architecture and full details of GPT-4,
    proprietary information for now, but we can piece together elements from similar
    work.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 尚未公开 GPT-4 的架构和完整细节，作为专有信息暂时保密，但我们可以从类似的工作中拼凑出一些元素。
- en: GPT-4 has 1.75 trillion parameters (1.75 million million) ( *MotiveX_Gemini*
    ).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 拥有 1.75 万亿个参数（1.75 万百万）（*MotiveX_Gemini*）。
- en: 'The vision transformer will likely involve some encoder-decoder architecture:
    image and video inputs for the encoder, then the decoder will generate output
    such as text descriptions or captions as well as images ( *Gemini* ).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉 Transformer 很可能会采用某种编码器-解码器架构：图像和视频输入给编码器，然后解码器将生成输出，如文本描述或标题以及图像（*Gemini*）。
- en: It will have an attention mechanism because “attention is all you need.”
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 它将拥有一种注意力机制，因为“注意力就是你所需要的一切。”
- en: The vision components will probably multi-head to process various aspects of
    the input simultaneously. There should also be positional encoding, image pro-processing
    layers, and modality fusion.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉组件可能会采用多头机制来同时处理输入的各个方面。它应该还会有位置编码、图像预处理层和模态融合。
- en: Modality fusion is where the vision capabilities are combined with the faculties
    to process text. From this, it would need to generate a unified understanding
    of the inputs or the scene given to it.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 模态融合是指视觉能力与处理文本的能力相结合。从这个过程中，它需要生成对输入或场景的统一理解。
- en: So, GPT-4 can understand images, and it’s believed that it uses a combination
    of **Vision Transformer** ( **ViT** ) and Flamingo visual language models.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，GPT-4 能够理解图像，并且它被认为结合了 **Vision Transformer**（**ViT**）和 Flamingo 视觉语言模型。
- en: '*Figure 1* *.3* shows the architecture of ViT (reproduced from Wagh).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1* *.3* 显示了 ViT 的架构（转载自 Wagh）。'
- en: '![Figure 1.3: This is what the internal workings of ViT involve (reproduced
    from Wagh)](img/B21009_01_3.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3：这是ViT内部工作的图示（摘自Wagh）](img/B21009_01_3.jpg)'
- en: 'Figure 1.3: This is what the internal workings of ViT involve (reproduced from
    Wagh)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：这是ViT内部工作的图示（摘自Wagh）
- en: So, the inner workings of GPT-4 that handle vision processing likely involve
    visual transformers as shown in the preceding figure, along with the text processors
    in the *How an LLM processes a* *sentence* subsection.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，处理视觉处理的GPT-4内部工作很可能涉及到视觉转换器，正如前面的图示所示，以及在*LLM如何处理句子*子部分中的文本处理器。
- en: 'You can find out more about ViT here: [https://github.com/lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch)
    .'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里了解更多关于ViT的信息：[https://github.com/lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch)。
- en: LLaMA-2
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLaMA-2
- en: The latest official LLaMA, LLaMA-2, is capable of holding complicated conversations,
    generating various creative text formats, and even adapting its responses to specific
    user personalities.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最新的官方LLaMA，LLaMA-2，能够进行复杂对话，生成各种创意文本格式，甚至根据特定用户的个性调整其响应。
- en: 'OpenLLaMA is an open source version of LLaMA released by Open LM Research (
    *Watson 2023* , *OpenLMR* , *Gemini* ). OpenLLaMA has several versions, each trained
    on different datasets but the training process was very similar to the original
    LLaMA. Model weights can be found on the HuggingFace Hub and accessed without
    the need for any additional permission. The HuggingFace page for Open LLaMA is
    here: [https://huggingface.co/docs/transformers/en/model_doc/open-llama](https://huggingface.co/docs/transformers/en/model_doc/open-llama)
    .'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: OpenLLaMA是由Open LM Research发布的LLaMA的开源版本（*Watson 2023*，*OpenLMR*，*Gemini*）。
    OpenLLaMA有几个版本，每个版本都是基于不同数据集进行训练，但训练过程与原始LLaMA非常相似。模型权重可以在HuggingFace Hub上找到，并且无需任何额外权限即可访问。有关OpenLLaMA的HuggingFace页面在这里：[https://huggingface.co/docs/transformers/en/model_doc/open-llama](https://huggingface.co/docs/transformers/en/model_doc/open-llama)。
- en: OpenLLaMA models serve as benchmarks for LLM research. Their open source nature
    makes it possible to compare with other models. This is made easier because there
    are PyTorch and TensorFlow formats available.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenLLaMA模型作为LLM研究的基准。它们的开源性质使得可以与其他模型进行比较。这得益于提供的PyTorch和TensorFlow格式。
- en: LLaMA-2 was released in April 2023.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLaMA-2于2023年4月发布。
- en: OpenLLaMA was released in June 2023.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenLLaMA于2023年6月发布。
- en: In early 2024, the rumors are that LLaMA-3 will be released this year.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2024年初，有传言称LLaMA-3将在今年发布。
- en: Gemini (formerly Bard)
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gemini（前身为Bard）
- en: Google’s Gemini is a chatbot LLM with access to the internet and just requires
    a Google login. Technically, Gemini is the face and the brain is whatever Google
    slots in.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的Gemini是一个具有互联网访问权限的聊天机器人LLM，只需一个谷歌登录即可。从技术上讲，Gemini是面孔，而大脑则是谷歌插槽中的任何内容。
- en: Previously, Gemini was powered by PaLM 2.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，Gemini由PaLM 2驱动。
- en: 'As of writing (early February 2024), Bard was earlier powered by Gemini. There
    are three versions of Gemini: Nano, Pro, and Ultra. Nano is for mobile devices.
    As Bard is powered by Gemini Pro, the name changed to Gemini. There may soon be
    a paid version.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时（2024年初），Bard先前由Gemini供电。Gemini有三个版本：Nano、Pro和Ultra。Nano适用于移动设备。由于Bard由Gemini
    Pro供电，因此名称更改为Gemini。可能很快会有付费版本。
- en: Gemini was released in March 2023 ( *Wiki_Gemini* ).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini是在2023年3月发布的（*Wiki_Gemini*）。
- en: Gemini has 142.4 million u sers, 62.6% of which are in the USA ( *AnswerIQ*
    ).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini有1.424亿用户，其中62.6%位于美国（*AnswerIQ*）。
- en: The architecture of Gemini
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Gemini的架构
- en: Gemini is one of the LLMs and AIs developed and used by Google/Alphabet. Let’s
    take a peek under the hood to understand what makes Gemini tick!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini是Google/Alphabet开发和使用的LLM和AI之一。让我们来看看其内部运作，了解Gemini的工作原理！
- en: Gemini is trained on a vast library of the world’s books, articles, and internet
    chatter. 1.56 trillion words are in the Infiniset dataset of Google Gemini; that’s
    750 GB of data. Gemini has 137 billion parameters, which are the neural network
    weights (ChatGPT has 175 billion parameters/weights) ( *ProjectPro* ).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini是基于世界书籍、文章和互联网交流的庞大文库进行训练的。Google Gemini的Infiniset数据集中有1.56万亿字，即750 GB的数据。Gemini有1370亿参数，这些是神经网络的权重（ChatGPT有1750亿参数/权重）（*ProjectPro*）。
- en: In November 2023, Bard got an upgrade and started to be powered by Gemini, a
    new AI system ( *SkillLeapAI* ). Previously, Gemini was powered by LaMDA from
    March 2023, then PaLM 2 from May 2023.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年11月，Bard升级，并开始由新的AI系统Gemini（*SkillLeapAI*）提供支持。此前，Gemini由LaMDA从2023年3月起供电，然后是PaLM
    2从2023年5月起。
- en: There are three models, Gemini Nano, Gemini Pro, and Gemini Ultra. As of 19th
    January 2024, Gemini is powered by Gemini Ultra, which was launched in December
    2023.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个型号，分别是Gemini Nano、Gemini Pro和Gemini Ultra。截至2024年1月19日，Gemini由2023年12月发布的Gemini
    Ultra驱动。
- en: '*Figure 1* *.4* shows the architecture of Gemini ( *GeminiTeam* ).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1* *.4* 显示了Gemini的架构（ *GeminiTeam* ）。'
- en: '![Figure 1.4: Bard/Gemini architecture, from the DeepMind GeminiTeam (GeminiTeam)](img/B21009_01_4.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4：Bard/Gemini架构，来自DeepMind GeminiTeam (GeminiTeam)](img/B21009_01_4.jpg)'
- en: 'Figure 1.4: Bard/Gemini architecture, from the DeepMind GeminiTeam (GeminiTeam)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：Bard/Gemini架构，来自DeepMind GeminiTeam (GeminiTeam)
- en: Gemini can deal with combinations of text, images, audio, and video inputs,
    which are represented as different colors here. Outputs can be text and images
    combined.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini可以处理文本、图像、音频和视频输入的组合，在这里它们用不同的颜色表示。输出可以是文本和图像的结合。
- en: The transition to Gemini Ultra signifies a significant leap in Gemini’s capabilities,
    offering higher performance, greater efficiency, and a wider range of potential
    applications (Gemini). Bard/Gemini Ultra has a complex architecture that is like
    a sophisticated language processing factory, with each component playing a crucial
    role in understanding your questions and crafting the perfect response.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 向Gemini Ultra的过渡标志着Gemini能力的重大飞跃，提供了更高的性能、更大的效率和更广泛的潜在应用（Gemini）。Bard/Gemini
    Ultra有着复杂的架构，就像一个精密的语言处理工厂，每个组件在理解你的问题和制定完美回答方面都起着至关重要的作用。
- en: The key component is the transformer decoder, the brain of the operation. It
    analyzes the incoming text, dissecting each word’s meaning and its connection
    to others. It’s like a skilled translator, deciphering the message you send and
    preparing to respond fluently.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 关键组件是变压器解码器，它是整个操作的大脑。它分析输入的文本，剖析每个单词的含义及其与其他单词的关系。就像一位熟练的翻译员，解读你发送的信息，并准备流利地回应。
- en: The Gemini Ultra multimodal encoder can handle more than just text. Images,
    audio, and other data types can be processed, providing a richer context for the
    decoder. This allows Gemini to interpret complex situations, such as describing
    an image you send or composing music based on your mood.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini Ultra多模态编码器不仅能处理文本。图像、音频及其他数据类型也能被处理，从而为解码器提供更丰富的上下文。这使得Gemini能够理解复杂的情境，例如描述你发送的图像或根据你的情绪创作音乐。
- en: To polish the decoder’s output, pre-activation and post-activation transformers
    come into play. These additional layers refine and smoothen the response, ensuring
    it’s clear, grammatically correct, and reads like natural, human language. With
    less hallucination, the factual grounding module anchors its responses in the
    real world. Just like a reliable teacher, it ensures Gemini’s information is accurate
    and unbiased, grounding its creativity in a strong foundation of truth. Beyond
    basic understanding, Gemini Ultra also has reasoning abilities. It can answer
    complex questions, draw logical conclusions, and even solve problems.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化解码器的输出，预激活和后激活变压器起到了作用。这些额外的层次对响应进行了精炼和平滑处理，确保其清晰、语法正确，并且像自然语言一样流畅。通过减少幻觉现象，事实基础模块将其响应固定在现实世界中。就像一位可靠的老师，它确保Gemini提供的信息准确无误且不带偏见，并将其创造力建立在坚实的真实基础之上。除了基本的理解能力，Gemini
    Ultra还具备推理能力。它能回答复杂的问题，得出逻辑结论，甚至解决问题。
- en: The implementation that is Gemini also has a little link to Google to help users
    to fact-check its responses. At the bottom of the output, above the input window,
    Google enables you to double-check its response.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 实现Gemini的过程中还与Google有一些联系，帮助用户核实其回答。在输出的底部，输入框上方，Google允许你双重检查其响应。
- en: '![Figure 1.5: Gemini’s Google search button to fact-check the output it gives
    you](img/B21009_01_5.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5：Gemini的Google搜索按钮，用于核实其给出的输出](img/B21009_01_5.jpg)'
- en: 'Figure 1.5: Gemini’s Google search button to fact-check the output it gives
    you'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：Gemini的Google搜索按钮，用于核实其给出的输出。
- en: Click this and it says **Google search** and outputs some search results and
    a guide to what you’re seeing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 点击此按钮后，它会显示**Google搜索**，并输出一些搜索结果以及你所看到内容的指南。
- en: '![Figure 1.6: Google search based on its output](img/B21009_01_6.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6：基于其输出的Google搜索](img/B21009_01_6.jpg)'
- en: 'Figure 1.6: Google search based on its output'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：基于其输出的Google搜索
- en: '*Figure 1* *.7* shows what the highlighting means.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1* *.7* 显示了高亮部分的含义。'
- en: '![Figure 1.7: Understanding the results of the Google search to help fact-check](img/B21009_01_7.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7：理解Google搜索结果以帮助核实事实](img/B21009_01_7.jpg)'
- en: 'Figure 1.7: Understanding the results of the Google search to help fact-check'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：理解Google搜索的结果以帮助事实核查
- en: On your Gemini screen, you’ll see various passages highlighted in brown or green.
    The green-highlighted text has results agreeing, the brown-highlighted text doesn’t
    agree with the sources, and no highlight means not enough information to confirm.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的Gemini屏幕上，你会看到不同的段落被高亮显示为棕色或绿色。绿色高亮的文本与结果一致，棕色高亮的文本与源数据不一致，未高亮的文本表示信息不足以确认。
- en: This is just a simplified glimpse into Gemini Ultra’s architecture and functioning.
    With its massive parameter count, self-attention mechanisms, and fine-tuning capabilities,
    it’s a constantly evolving language maestro , pushing the boundaries of what LLMs
    can achieve.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是Gemini Ultra架构和功能的简化介绍。凭借其庞大的参数量、自注意力机制和微调能力，它是一个不断进化的语言大师，推动着LLM所能实现的极限。
- en: Amazon Olympus
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊奥林匹斯
- en: 'Amazon has developed an enormous new LLM. It’s a hulking beast, dwarfing even
    OpenAI’s GPT-4 in sheer size. But this isn’t just a power contest. Olympus aims
    for something more: a significant leap in coherence, reasoning, and factual accuracy.
    Their chatbot, Metis is powered by Olympus: [https://happyfutureai.com/amazons-metis-a-new-ai-chatbot-powered-by-olympus-llm/](https://happyfutureai.com/amazons-metis-a-new-ai-chatbot-powered-by-olympus-llm/)
    .'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊开发了一个庞大的新LLM。它是一个巨大的存在，甚至在规模上也压倒了OpenAI的GPT-4。但这不仅仅是实力的较量。奥林匹斯的目标是更远的目标：在连贯性、推理和事实准确性方面取得重大突破。他们的聊天机器人Metis由奥林匹斯提供支持：[https://happyfutureai.com/amazons-metis-a-new-ai-chatbot-powered-by-olympus-llm/](https://happyfutureai.com/amazons-metis-a-new-ai-chatbot-powered-by-olympus-llm/)。
- en: With no half-baked ideas, Olympus digs deep, thinks logically, and double-checks
    its facts before uttering a word. Amazon is purportedly working to reduce bias
    and misinformation. This LLM strives for high levels of wisdom and reliability.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 没有半吊子的想法，奥林匹斯深入思考、逻辑推理，并在说出任何话之前反复核实事实。亚马逊据说正在努力减少偏见和错误信息。这款LLM力求达到高水平的智慧和可靠性。
- en: It’s not just about bragging rights for Amazon. Olympus represents a potential
    turning point for language models.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅仅是亚马逊炫耀实力。奥林匹斯代表着语言模型的一个潜在转折点。
- en: The aim is to be able to tackle complex tasks with pinpoint accuracy, grasp
    subtle nuances of meaning, and engage in intelligent, fact-based conversations
    with other AI.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是能够以极高的准确性处理复杂的任务，抓住细微的意义差异，并与其他AI进行智能、基于事实的对话。
- en: Olympus will, hopefully, be a more thoughtful companion capable of deeper understanding
    and insightful exchange.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 希望奥林匹斯将成为一个更具思考性的伙伴，能够进行更深层次的理解和富有洞察力的交流。
- en: Olympus may not be ready to join your book club just yet, but its story is worth
    watching. Hopefully, Olympus will be a needed advancement for LLMs and not hallucinate,
    only producing truth and changing what LLMs can do.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 奥林匹斯可能还未准备好加入你的书籍俱乐部，但它的故事值得关注。希望奥林匹斯能成为LLM的必要进步，不会产生幻觉，只会产生真相，并改变LLM的功能。
- en: Amazon Olympus should have around two trillion parameters (weights and biases)
    ( *Life_Achritecture* ).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊奥林匹斯应该拥有大约两万亿个参数（权重和偏差）（*Life_Achritecture*）。
- en: Amazon Olympus is expected in the second half of 2024 but not much information
    has come out since November 2023.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊奥林匹斯预计将在2024年下半年发布，但自2023年11月以来，尚未公开太多信息。
- en: Now that we have introduced many of the modern LLMs, let’s look at how they
    work, including using an example piece of text.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了许多现代的LLM，让我们看看它们是如何工作的，包括通过一个示例文本。
- en: How Transformers work
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变换器是如何工作的
- en: 'Moving on to the general transformers, *Figure 1* *.8* shows the structure
    of a Transformer:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是一般的变换器，*图1.8*展示了一个变换器的结构：
- en: '![Figure 1.8: Architecture of a Transformer: an encoder for the inputs and
    a decoder for the outputs (reproduced from Zahere)](img/B21009_01_8.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图1.8：变换器架构：输入的编码器和输出的解码器（来自Zahere的复原）](img/B21009_01_8.jpg)'
- en: 'Figure 1.8: Architecture of a Transformer: an encoder for the inputs and a
    decoder for the outputs (reproduced from Zahere)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：变换器架构：输入的编码器和输出的解码器（来自Zahere的复原）
- en: You can see that it has an encoder and a decoder. The encoder learns the patterns
    in the data and the decoder tries to recreate them.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到它有一个编码器和一个解码器。编码器学习数据中的模式，解码器则试图重建这些模式。
- en: The encoder has multiple neural network layers. In transformers, each layer
    uses self-attention, allowing the encoder to understand how the different parts
    of the sentence fit together and understand the context.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器有多个神经网络层。在变换器中，每一层都使用自注意力机制，使得编码器能够理解句子的不同部分是如何组合的，从而理解上下文。
- en: 'Here is a quick version of the transformer process:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是变压器过程的简要版：
- en: 'Encoder network:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器网络：
- en: Uses multiple layers of neural networks.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用多层神经网络。
- en: Each layer employs self-attention to understand relationships between sentence
    parts and context.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每一层都使用自注意力来理解句子部分之间的关系和上下文。
- en: Creates a compressed representation of the input.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建输入的压缩表示。
- en: 'Decoder network:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码器网络：
- en: Utilizes the encoder’s representation for generating new outputs.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利用编码器的表示来生成新的输出。
- en: Employs multiple layers with cross-attention for information exchange with the
    encoder.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采用多层结构，并通过交叉注意力与编码器进行信息交换。
- en: Generates meaningful outputs such as translations, summaries, or answers based
    on input.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成有意义的输出，如翻译、总结或基于输入的答案。
- en: 'Encoder-decoder partnership:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器-解码器合作：
- en: Combined, they power the transformer for various tasks with high accuracy and
    flexibility.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它们结合在一起，为变压器提供高准确性和灵活性的各种任务处理能力。
- en: For example, Microsoft Bing leverages GPT-4, a transformer model, to understand
    user intent and context beyond keywords for delivering relevant search results.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，微软必应利用GPT-4这一变压器模型，理解用户的意图和上下文，不仅仅依靠关键词，从而提供相关的搜索结果。
- en: 'Beyond keywords:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 超越关键词：
- en: Bing transforms from a search engine to an AI-powered copilot using GPT-4.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 必应通过使用GPT-4从搜索引擎转变为AI驱动的副驾驶。
- en: It interprets questions and requests by analyzing context and intent, not just
    keywords.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它通过分析上下文和意图来解释问题和请求，而不仅仅是依赖关键词。
- en: For example, instead of only providing ingredient lists, it recommends personalized
    recipes considering dietary needs and skill levels.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，不仅提供食材列表，还根据饮食需求和技能水平推荐个性化的食谱。
- en: 'From links to understanding:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从链接到理解：
- en: Bing evolves beyond finding links to comprehending user needs and delivering
    relevant, helpful information .
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 必应不仅仅是寻找链接，而是能够理解用户需求并提供相关且有用的信息。
- en: Next is the detailed version of the Transformer process.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是变压器过程的详细版。
- en: How an LLM processes a piece of text
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM如何处理一段文本
- en: The encoder produces a compressed representation of the input. This allows the
    decoder to not only consider its own outputs but also look back at the encoder’s
    representation, which contains a representation of the whole input sequence for
    guidance. This is used by the decoder for each step of its output generation.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器生成输入的压缩表示。这使得解码器不仅可以考虑自身的输出，还可以回顾编码器的表示，其中包含整个输入序列的表示，用于指导解码器的每一步输出生成。
- en: The decoder uses output from the encoder to generate a new output sequence.
    Because of Transformers, modern LLMs can hold entire sentences or paragraphs in
    their attention, not just one word at a time like RNNs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器使用来自编码器的输出生成新的输出序列。得益于Transformers，现代大语言模型（LLM）可以在其注意力中处理整个句子或段落，而不仅仅是像RNN那样一次处理一个词。
- en: Again, this section has lots of layers but, this time, there is cross-attention.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这一部分包含很多层，但这一次有交叉注意力。
- en: This back-and-forth conversation between the decoder and the encoder’s compressed
    knowledge empowers the decoder to generate meaningful and relevant outputs, such
    as translating a sentence to another language, summarizing a paragraph, or answering
    a question based on the input.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器与编码器压缩后的知识之间的反复对话，使得解码器能够生成有意义且相关的输出，例如将一句话翻译成另一种语言、总结一段文字或根据输入回答问题。
- en: Together, the encoder and decoder form the powerhouse of the transformer, enabling
    it to perform a wide range of tasks with remarkable accuracy and flexibility.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器和解码器共同构成了变压器的强大动力，使其能够以卓越的准确性和灵活性执行各种任务。
- en: Microsoft’s Bing search engine uses GPT-4 to deliver more relevant search results,
    understanding your intent and context beyond just keywords.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的必应搜索引擎使用GPT-4来提供更相关的搜索结果，理解你的意图和上下文，而不仅仅是关键词。
- en: Bing has gone from a search engine to an AI-powered copilot with the help of
    GPT-4. This powerful language model acts as Bing’s brain, understanding your questions
    and requests not just through keywords, but by analyzing the context and intent.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 必应从一个搜索引擎转变为一个由GPT-4驱动的AI副驾驶。这种强大的语言模型作为必应的大脑，不仅仅通过关键词理解你的问题和请求，而是通过分析上下文和意图。
- en: You can, for example, ask for a recipe instead of just ingredients; GPT-4 scours
    the web, considers your dietary needs and skill level, and then presents a personalized
    selection. It’s like having a knowledgeable friend helping you navigate the vast
    ocean of information. So, Bing isn’t just about finding links anymore; it’s about
    understanding what you truly need and delivering it in a way that’s relevant and
    helpful ( [https://www.bing.com/](https://www.bing.com/) ).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以请求一个食谱，而不仅仅是食材；GPT-4 会在网上搜寻，考虑你的饮食需求和技能水平，然后呈现个性化的选择。这就像有一个知识丰富的朋友帮助你在浩瀚的信息海洋中导航。所以，Bing
    不仅仅是找链接了；它是在理解你真正需要什么，并以相关且有帮助的方式提供它（[https://www.bing.com/](https://www.bing.com/)）。
- en: 'The whole process of getting a paragraph into an LLM goes like this:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 将一段话输入到大型语言模型（LLM）中的整个过程如下：
- en: Cleaning
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清洗
- en: Tokenization
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分词
- en: 'Word-to-number conversion (words given indices: 1, 2, 3, 4…)'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词到数字转换（将词汇赋予索引：1、2、3、4……）
- en: Numbers are turned into vectors
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数字被转化为向量
- en: Contextual embedding
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上下文嵌入
- en: Context vectors are formed
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上下文向量被形成
- en: Attention vectors are formed and fed into final blocks
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意力向量被形成并输入到最后的块中
- en: Subsequent words are predicted
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随后的词语会被预测
- en: ( *ChatGPT* , *Gemini* , *Panuganty* , *Aakanksha* ).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: （*ChatGPT*，*Gemini*，*Panuganty*，*Aakanksha*）。
- en: With this framework in your subconscious, we can go through the details of the
    stages. When you pay for ChatGPT questions and answers (more for developers),
    you pay by thousands of tokens. Tokens are where the sentences are split up into
    words and punctuation or tokenized. Tokens are turned into numbers (indices) and
    those are put into vectors, as the maths happens more easily with vectors or context
    vectors. The attention layers show the model where to focus in each sentence,
    and the next word can be predicted.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在你潜意识中有了这个框架之后，我们可以详细讨论各个阶段。当你为 ChatGPT 提问并得到答案时（对于开发者来说更多），你是按成千上万个标记（tokens）来付费的。标记是将句子拆分成单词、标点符号或其他词汇的过程。标记被转换为数字（索引），然后放入向量中，因为使用向量或上下文向量进行数学运算更容易。注意力层会指示模型在每个句子中应聚焦的部分，从而预测下一个词。
- en: This process is needed to input the words and sentences into the transformer
    model to train it and to query it to get responses.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程是将词汇和句子输入到转换器模型中，以便训练和查询以获得响应。
- en: 'Before tokenization, the data (sentence, paragraph, etc.) would need to be
    cleaned and normalized: remove special characters, lowercase everything, and some
    other basic cleaning.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在分词之前，数据（句子、段落等）需要清洗和规范化：去除特殊字符，将所有内容转为小写，以及其他一些基本的清理操作。
- en: 'Here is an example of a paragraph for tokenization:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个需要分词处理的段落示例：
- en: “ *The game Fallout stands out as a distinctive and immersive gaming experience
    when compared to Fortnite. Fallout’s strength lies in its rich narrative, offering
    players a post-apocalyptic world filled with intricate storytelling, character
    development, and meaningful choices. Unlike Fortnite’s fast-paced battle royale
    format, Fallout provides a vast open-world exploration, encouraging players to
    delve into a detailed and atmospheric environment. The emphasis on role-playing
    and decision-making in Fallout adds layers of complexity, contributing to a more
    profound* *gaming engagement.* ”
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: “*游戏《辐射》在与《堡垒之夜》相比时，作为一种独特且沉浸式的游戏体验脱颖而出。《辐射》的优势在于其丰富的叙事，提供了一个充满复杂故事情节、角色发展和重要选择的后末日世界。与《堡垒之夜》的快节奏大逃杀模式不同，《辐射》提供了广阔的开放世界探索，鼓励玩家深入细致且富有氛围的环境。游戏中的角色扮演和决策制定的重视增添了多层次的复杂性，带来了更深刻的*
    *游戏沉浸感*。”
- en: 'Now, here is that same paragraph tokenized ( *ChatGPT* ):'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是经过分词处理的同一段文字（*ChatGPT*）：
- en: '[PRE0]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Sentences can be tokenized with **BertTokenizer** ( *Metzger* ):'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 句子可以通过 **BertTokenizer**（*Metzger*）进行分词：
- en: '[PRE1]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, a word becomes an index by word-to-number conversion:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过词到数字的转换，一个词变成一个索引：
- en: '[PRE2]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Indices become vectors, as defined by pre-trained representations of words
    that come from training on the huge datasets mentioned earlier. This comes from
    Word2Vec, GloVe or FastText, ELMo, or the all-famous BERTs:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 索引转化为向量，这是通过预训练的词表示来定义的，这些表示来自于在前面提到的巨大数据集上的训练。这些表示来自于 Word2Vec、GloVe 或 FastText、ELMo，或者著名的
    BERT：
- en: '**"The": [0.2, 0.8, -** **0.5, 0.3]**'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**"The": [0.2, 0.8, -** **0.5, 0.3]**'
- en: '**"game": [0.5, -0.7,** **0.1, 0.6]**'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**"game": [0.5, -0.7,** **0.1, 0.6]**'
- en: '**"Fallout": [0.9, 0.4, -** **0.2, -0.1]**'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**"Fallout": [0.9, 0.4, -** **0.2, -0.1]**'
- en: '**"stands": [-0.3, 0.6,** **0.7, -0.5]**'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**"stands": [-0.3, 0.6,** **0.7, -0.5]**'
- en: '**"out": [-0.7, 0.2, -** **0.4, 0.9]**'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**"out": [-0.7, 0.2, -** **0.4, 0.9]**'
- en: '**"as": [0.3, 0.1, -** **0.6, 0.4]**'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**"as": [0.3, 0.1, -** **0.6, 0.4]**'
- en: The size of the vectors depends on the number of dimensions of the model. The
    preceding model implies a four-dimensional model, which is very small, just for
    this simple explanation.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的大小取决于模型的维度数量。前面的模型暗示了一个四维模型，这个模型非常小，仅仅用于这个简单的解释。
- en: The model with only two dimensions might have **"woman"** in the context of
    **"man"** or **"fast"** in the context of **"slow"** .
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 只有两个维度的模型，可能会将**“女人”**放在**“男人”**的语境中，或者**“快”**放在**“慢”**的语境中。
- en: 'Next, we have contextual embedding: what is the environment of the word?'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有上下文嵌入：这个词的环境是什么？
- en: 'Here are some examples of the sort of thing that would happen:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些例子，展示了可能发生的情况：
- en: 'Sentence 1, *The game Fallout stands out...* : Embedding might emphasize aspects
    of distinctiveness and gaming experience'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 句子1，*游戏Fallout脱颖而出...* ：嵌入可能会强调独特性和游戏体验的方面
- en: 'Sentence 2, *Fallout’s strength lies in its rich narrative...* : Embedding
    might focus on storytelling and narrative elements'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 句子2，*Fallout的优势在于其丰富的叙事...* ：嵌入可能会集中在讲故事和叙事元素上
- en: 'Sentence 3, *Unlike Fortnite’s fast-paced format, Fallout provides...* : Embedding
    might highlight the contrast with another game and world exploration aspects'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 句子3，*与《堡垒之夜》快速节奏的玩法不同，Fallout提供了...* ：嵌入可能会突出与其他游戏的对比以及世界探索的方面
- en: 'As vectors, that would look like this:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 作为向量，它会像这样表示：
- en: 'The: [0.12, 0.34, 0.56, 0.21, -0.05, ..., 0.90] ( 300 values)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'The: [0.12, 0.34, 0.56, 0.21, -0.05, ..., 0.90] （300个值）'
- en: 'game: [0.78, 0.21, -0.45, 0.10, 0.83, ..., 0.68] ( 300 values)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游戏： [0.78, 0.21, -0.45, 0.10, 0.83, ..., 0.68] （300个值）
- en: 'Fallout: [0.90, -0.10, 0.05, 0.75, 0.43, ..., -0.22] ( 300 values)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fallout: [0.90, -0.10, 0.05, 0.75, 0.43, ..., -0.22] （300个值）'
- en: There are 300 dimensions because that enables the model to capture rather subtle
    semantic relationships but would also require more training data and computational
    resources.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 有300个维度，因为这能让模型捕捉到较为微妙的语义关系，但也需要更多的训练数据和计算资源。
- en: This could be done with only 50 dimensions if the dataset were small, and you
    didn’t want to spend a lot of time and money computing it all.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集很小，而且你不想花费大量的时间和金钱来计算所有内容，可以只用50个维度来完成。
- en: ChatGPT uses reinforcement learning from human feedback
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT使用来自人类反馈的强化学习
- en: ChatGPT stands out among other LLMs due to its ability to continuously improve
    through a process called **reinforcement learning from human feedback** ( **RLHF**
    ). This means it doesn’t just learn from massive datasets of text and code but
    also incorporates direct feedback from human users.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT在其他大语言模型（LLM）中脱颖而出，原因是它通过一种叫做**人类反馈强化学习**（**RLHF**）的过程不断改进。这意味着它不仅仅从大量的文本和代码数据集中学习，还融入了来自人类用户的直接反馈。
- en: When a new GPT model is trained (call it GPT-X for any GPT model), before being
    released to the public, users interact with GPT-X, asking questions or giving
    instructions. After receiving a response, they can express approval or disapproval
    through various methods, such as thumbs-up/down ratings or explicit feedback prompts.
    This valuable input directly affects how the GPT-X model refines its internal
    model, prioritizing responses that resonate with humans and minimizing those that
    miss the mark.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个新的GPT模型被训练（无论叫什么GPT-X），在发布给公众之前，用户会与GPT-X互动，提问或发出指令。在收到回复后，他们可以通过各种方式表示赞同或反对，例如点赞/点踩评分或明确的反馈提示。这些宝贵的输入直接影响GPT-X模型如何精炼其内部模型，优先回应符合人类需求的回答，减少那些偏离的回答。
- en: Think of it like training a puppy. Just as rewards encourage desired behaviors,
    positive feedback in RLHF reinforces helpful and accurate responses within GPT-X.
    Over time, through countless interactions and feedback loops, GPT-X fine-tunes
    its responses to be more informative, engaging, and aligned with human preferences.
    This human-in-the-loop approach sets GPT models apart, allowing them to adapt
    and learn dynamically, continuously evolving their capabilities based on real-world
    interactions.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 把它当作训练一只小狗。就像奖励鼓励期望的行为一样，强化学习中的正反馈会加强GPT-X中的有帮助且准确的响应。随着时间的推移，通过无数的互动和反馈循环，GPT-X不断微调其响应，使其更加有信息量、吸引人并符合人类的偏好。这种“人类在环”方法使得GPT模型与其他模型不同，它们能够动态适应和学习，基于现实世界的互动不断发展其能力。
- en: This is how the researchers and developers attempt to make the AI ethical and
    moral, according to their understanding of human morals, which will not agree
    with everybody, but do agree with common culture, including laws.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是研究人员和开发人员试图使人工智能具备伦理和道德的方法，依据他们对人类道德的理解，这种理解不会得到每个人的认同，但它符合普遍的文化，包括法律。
- en: Other people like to make sure uncensored LLMs exist that don’t encourage the
    politics of the LLM developers such as Californian tech companies.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 其他人则喜欢确保存在未经审查的LLMs，这些LLMs不会鼓励开发者所在地区（如加利福尼亚科技公司）所持的政治观点。
- en: This process should stop the AI from helping anybody to do anything violent/illegal,
    such as constructing weapons or illegally hacking into an organization’s website
    or servers.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程应该能阻止人工智能协助任何人做任何暴力/非法的事情，比如制造武器或非法入侵组织的网站或服务器。
- en: While the specifics of RLHF implementation remain proprietary, its impact is
    evident in ChatGPT’s ability to handle diverse conversation styles, generate different
    creative text formats, and provide informative answers. As RLHF technologies advance,
    we can expect LLMs such as ChatGPT to become even more adept at understanding
    and responding to human needs, blurring the lines between machine and human communication.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然RLHF（强化学习与人类反馈）实现的具体细节仍然是专有的，但其影响在于ChatGPT能够处理多样的对话风格、生成不同的创意文本格式并提供有用的答案。随着RLHF技术的发展，我们可以预期像ChatGPT这样的LLMs会在理解和回应人类需求方面变得更加得心应手，模糊机器与人类沟通之间的界限。
- en: LLMs are expensive
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）非常昂贵
- en: Many tech company players have been working to create and train their own LLMs
    or chatbots to ride this wave of innovation for money and control. LLMs of today,
    2024, require an enormous amount of training and this takes enormous piles of
    cash. OpenAI took funding of about $13 billion when Microsoft bought shares in
    OpenAI, and much of this was likely used on training the GPT family of LLMs on
    Microsoft’s own Azure cloud servers ( *Sanman* ).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 许多科技公司玩家一直在努力创建和训练自己的LLMs或聊天机器人，以借助这波创新浪潮赚取金钱并获取控制权。如今的LLMs（2024年）需要大量的训练，这需要巨额的资金。OpenAI在微软购买OpenAI股份时获得了大约130亿美元的资金，其中很大一部分可能用于在微软自己的Azure云服务器上训练GPT系列LLMs（*Sanman*）。
- en: Cash and cooling (energy) are required to train and run LLMs, so it’s a good
    thing deep learning models can be used to save energy and reduce pollution. DeepMind
    once saved Google data centers 40% of their cooling bill! They did this by developing
    a deep learning model that made suggestions for how to modify how the cooling
    systems worked. Later, the DeepMind model was set to just run the cooling systems
    directly [Hooper 2021 and DeepMind]. These Google data centers have their own
    dedicated power stations, so this is a lot of energy saved and money and pollution
    saved too!
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和运行LLMs需要现金和冷却（能源），因此，深度学习模型能够节省能源并减少污染是一件好事。DeepMind曾经帮助谷歌数据中心节省了40%的冷却费用！他们通过开发一个深度学习模型，提出了如何修改冷却系统运行方式的建议。后来，DeepMind模型直接控制冷却系统的运行[Hooper
    2021 和 DeepMind]。这些谷歌数据中心有自己的专用电站，因此节省了大量能源，同时也节省了金钱和减少了污染！
- en: Speaking of numbers and calculations, let’s briefly look at what classes of
    mathematics are involved in LLMs.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 说到数字和计算，让我们简要了解一下LLMs涉及哪些数学领域。
- en: A note on the mathematics of LLMs
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于LLMs数学的一点说明
- en: 'Getting into the mathematical center of LLMs can be a bit of work, but understanding
    their core principles reveals a lot about how the most powerful and widely used
    AIs today function. So, if you want to make these AI models and research them,
    the mathematics is very interesting:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 进入LLMs的数学核心可能有些复杂，但理解它们的核心原理能揭示许多当前最强大且广泛使用的人工智能是如何运作的。因此，如果你想构建这些AI模型并进行研究，数学非常有趣：
- en: '**Foundations in linear algebra** : The bedrock of LLMs lies in linear algebra,
    where matrices and vectors rule. Words are mapped to high-dimensional vectors,
    capturing their meanings and relationships within a vast semantic space. Each
    word is a point in a multi-dimensional space, with related words clustering closer
    together.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性代数基础**：LLMs的基石在于线性代数，其中矩阵和向量占主导地位。单词被映射到高维向量，捕捉它们在广阔语义空间中的意义和关系。每个单词都是多维空间中的一个点，相关的单词会聚集在一起。'
- en: '**Backpropagation and optimization** : Training LLMs requires massive datasets
    and sophisticated optimization algorithms. One powerful tool is backpropagation,
    a mathematical technique that calculates the error gradient – how much each parameter
    in the model contributes to the overall deviation from the desired output. By
    iteratively adjusting these parameters based on the error gradient, the LLM learns
    and improves its predictions.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向传播与优化**：训练LLMs需要庞大的数据集和复杂的优化算法。一个强大的工具是反向传播，这是一种数学技术，用于计算误差梯度——每个参数对模型输出偏差的贡献程度。通过根据误差梯度反复调整这些参数，LLMs能够学习并改进其预测。'
- en: '**Loss functions and metrics** : To evaluate the performance of an LLM, we
    need quantitative measures. Loss functions define how much the model’s output
    deviates from the desired outcome, while metrics such as accuracy, perplexity,
    and BLEU score assess its ability to generate fluent, contextually appropriate
    text:'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失函数和评估指标**：为了评估大语言模型（LLM）的性能，我们需要定量指标。损失函数定义了模型输出与期望结果之间的偏差，而像准确度、困惑度和 BLEU
    分数等指标则评估模型生成流畅且上下文适当的文本的能力。'
- en: '**BLEU score** stands for **Bilingual Evaluation Understudy score** , which
    is from translation but can be used as a way to compare AI-generated translations
    with reference translations. It can be calculated with the NLTK code library in
    Python using the **sentence_bleu()** function ( *Brownlee_BLEU* ).'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BLEU 分数**代表 **Bilingual Evaluation Understudy score**，源自翻译领域，但也可以作为一种方法来比较
    AI 生成的翻译与参考翻译。可以使用 Python 中的 NLTK 代码库，通过 **sentence_bleu()** 函数（*Brownlee_BLEU*）计算
    BLEU 分数。'
- en: '**Beyond basic maths** : The mathematics of LLMs extends far beyond these core
    principles. Techniques such as regularization, dropout, and gradient clipping
    help prevent overfitting and improve generalization. RNNs add memory capabilities,
    allowing the model to learn from longer sequences of data. The world of mathematics
    is constantly evolving, pushing the boundaries of what LLMs can achieve.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超越基础数学**：LLM 的数学远远超出了这些核心原理。技术如正则化、丢弃法和梯度裁剪有助于防止过拟合并提高泛化能力。RNN 增加了记忆能力，使模型能够从更长的序列中学习。数学的世界不断发展，推动
    LLM 能力的边界。'
- en: '**Transformers and attention** : This mathematical architecture forms the engine
    of modern LLMs. In Transformers, the mechanism for calculating attention scores
    involves dot products between query and key vectors. While in LSTMs, each time
    step acts as both *query* and *key* , Transformers separate these roles: The query
    originates from the current token’s representation, while the keys are derived
    from the value representations of all tokens in the sequence. This distinction
    helps to compute attention scores that indicate how significant or relevant each
    token is within its context. Transformers also use values, which are also derived
    from the word embeddings of all tokens, carrying the actual information from each
    token:'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformers 和注意力**：这种数学架构构成了现代 LLM 的引擎。在 Transformers 中，计算注意力分数的机制涉及查询向量和键向量之间的点积。而在
    LSTM 中，每个时间步既充当 *查询* 又充当 *键*，Transformers 则将这两个角色分开：查询来自当前词元的表示，而键来自序列中所有词元的值表示。这一区分有助于计算出注意力分数，指示每个词元在其上下文中的重要性或相关性。Transformers
    还使用值，它们也来自所有词元的词嵌入，携带每个词元的实际信息。'
- en: Let’s look at an example sentence, *The cat played with* *a ball* .
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让我们来看一个例句，*The cat played with* *a ball*。
- en: 'In a Transformer’s attention mechanism, the following applies:'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Transformer 的注意力机制中，适用以下规则：
- en: Words and their meanings are usually represented numerically using embeddings,
    such as Word2Vec or GloVe vectors
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词语及其意义通常使用嵌入表示为数值形式，如 Word2Vec 或 GloVe 向量。
- en: The query would be derived from the representation of the current token; let’s
    say it’s the word *played*
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询将来源于当前词元的表示；假设它是词 *played*。
- en: The keys are calculated from the value representations of all tokens in the
    sequence, so we’d have keys for *The* , *cat* , *played* , *with* , *a* , and
    *ball*
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键是从序列中所有词元的值表示计算出来的，因此我们会为 *The*、*cat*、*played*、*with*、*a* 和 *ball* 计算键。
- en: Then, each query would do a dot product with every key vector
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，每个查询将与每个键向量做点积。
- en: These dot products would then be used to calculate the attention scores
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些点积将用于计算注意力分数。
- en: Ultimately, this process helps highlight which words in the sequence are most
    relevant or important within context, enhancing the Transformer’s ability to understand
    text
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，这个过程有助于突出序列中哪些词在上下文中最相关或最重要，从而增强 Transformer 理解文本的能力。
- en: While the maths might seem daunting, it’s crucial to remember that it’s just
    a tool. The true power lies in how these algorithms are woven together to create
    models capable of remarkable feats of language processing. As mathematical models
    evolve and datasets grow, LLMs promise to push the boundaries of language, blurring
    the lines betwee n human and machine communication in ever-fascinating ways [
    Llama3, Gemini].
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数学可能看起来令人畏惧，但必须记住，它只是一个工具。真正的力量在于这些算法如何结合在一起，创造出能够实现语言处理奇迹的模型。随着数学模型的不断发展和数据集的增大，LLM
    有望突破语言的边界，以越来越迷人的方式模糊人类与机器交流之间的界限 [Llama3, Gemini]。
- en: Applications of LLMs
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM的应用
- en: 'The LLM revolution is reaching its virtual tentacles into every corner of life,
    from writing your college essay to generating personalized Coca-Cola ads and customer
    services. Here’s a quick peek into just 16 diverse applications:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: LLM革命正在将它的虚拟触角伸向生活的方方面面，从写大学论文到生成个性化的可口可乐广告和客户服务。以下是16个多样化应用的快速一瞥：
- en: '*DIYVA* : Designs stunning visuals and logos, making even the artistically
    challenged look like Picassos ( [https://diyva.life/](https://diyva.life/) ).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DIYVA* : 设计惊艳的视觉效果和标志，即使是艺术天赋较差的人也能看起来像毕加索（[https://diyva.life/](https://diyva.life/)）。'
- en: '*LimeWire* : Conjures up unique AI-generated artwork, turning your wildest
    creative visions into reality. Start here: [https://limewire.com/studio?referrer=ml736b1k7k](https://limewire.com/studio?referrer=ml736b1k7k)
    .'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LimeWire* : 创造独特的AI生成艺术作品，将你最疯狂的创意愿景变为现实。从这里开始：[https://limewire.com/studio?referrer=ml736b1k7k](https://limewire.com/studio?referrer=ml736b1k7k)。'
- en: '*Coca-Cola* : Creates targeted ad campaigns, crafting personalized marketing
    messages for each individual Coke-sipper ( [https://www.coca-cola.com/gb/en](https://www.coca-cola.com/gb/en)
    ).'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Coca-Cola* : 创建有针对性的广告活动，为每个可口可乐消费者量身定制个性化的营销信息（[https://www.coca-cola.com/gb/en](https://www.coca-cola.com/gb/en)）。'
- en: '*Slack* : Transcribes meetings and automatically summarizes key points, saving
    you precious time and attention ( [https://slack.com/intl/en-gb](https://slack.com/intl/en-gb)
    ).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Slack* : 转录会议并自动总结关键要点，节省宝贵的时间和精力（[https://slack.com/intl/en-gb](https://slack.com/intl/en-gb)）。'
- en: '*Octopus Energy* : Predicts your energy usage and suggests personalized plans,
    optimizing your home’s power with LLM intelligence ( [https://octopus.energy/](https://octopus.energy/)
    ).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Octopus Energy* : 预测你的能源使用并建议个性化的方案，通过LLM智能优化你家中的电力（[https://octopus.energy/](https://octopus.energy/)）。'
- en: '*Cheggmate* : Offers AI-powered tutoring tailored to each student’s specific
    needs, making learning more efficient and engaging ( [https://www.cheggmate.ai/](https://www.cheggmate.ai/)
    ).'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Cheggmate* : 提供AI驱动的辅导，针对每个学生的具体需求进行定制，使学习更加高效和有趣（[https://www.cheggmate.ai/](https://www.cheggmate.ai/)）。'
- en: '*Freshworks* : Automates customer service, analyzing chats and offering solutions
    before agents even blink ( [https://www.cheggmate.ai/](https://www.cheggmate.ai/)
    ).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Freshworks* : 自动化客户服务，分析聊天记录并在客服人员反应过来之前提供解决方案（[https://www.cheggmate.ai/](https://www.cheggmate.ai/)）。'
- en: '*Udacity* : Designs personalized learning paths, guiding you through the tech
    jungle with LLM-powered recommendations ( [https://www.udacity.com/](https://www.udacity.com/)
    ).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Udacity* : 设计个性化学习路径，带领你穿越技术丛林，借助LLM驱动的推荐（[https://www.udacity.com/](https://www.udacity.com/)）。'
- en: '*Zalando* : This European fashion retailer uses LLMs to generate personalized
    product recommendations based on user preferences and behavior ( [https://www.zalando.co.uk/](https://www.zalando.co.uk/)
    ).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Zalando* : 这家欧洲时尚零售商使用LLM根据用户的偏好和行为生成个性化的产品推荐（[https://www.zalando.co.uk/](https://www.zalando.co.uk/)）。'
- en: '*Headspace* : Headspace leverages LLMs to personalize guided meditations, adapting
    practices to your mood, sleep patterns, and personal goals ( [https://www.headspace.com/](https://www.headspace.com/)
    ).'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Headspace* : Headspace利用LLM个性化指导冥想，根据你的情绪、睡眠模式和个人目标调整冥想练习（[https://www.headspace.com/](https://www.headspace.com/)）。'
- en: '*Spotify* : Spotify’s Discover Weekly playlists and other personalized recommendations
    are generated by LLMs, analyzing your listening habits and music preferences to
    curate an ever-evolving soundtrack for your life ( [https://open.spotify.com/](https://open.spotify.com/)
    ).'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spotify* : Spotify的Discover Weekly播放列表和其他个性化推荐是由LLM生成的，通过分析你的听歌习惯和音乐偏好，为你的生活策划一条不断演变的背景音乐（[https://open.spotify.com/](https://open.spotify.com/)）。'
- en: '*Peloton* : Peloton’s AI coaches utilize LLMs to deliver dynamic real-time
    feedback during workouts, tailoring prompts and challenges to your individual
    performance and fitness goals ( [https://www.onepeloton.co.uk/](https://www.onepeloton.co.uk/)
    ).'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Peloton* : Peloton的AI教练利用LLM在锻炼过程中提供动态实时反馈，根据你的个人表现和健身目标调整提示和挑战（[https://www.onepeloton.co.uk/](https://www.onepeloton.co.uk/)）。'
- en: '*Baidu’s WenLan* : Helps Chinese businesses analyze customer reviews and personalize
    marketing campaigns; a local LLM giant ( [https://ir.baidu.com/company-overview](https://ir.baidu.com/company-overview)
    ).'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*百度的文澜* : 帮助中国企业分析客户评论并个性化营销活动；本地的LLM巨头（[https://ir.baidu.com/company-overview](https://ir.baidu.com/company-overview)）。'
- en: '*NVIDIA Megatron-Turing NLG* : Generates different creative text formats such
    as poems, code, scripts, and so on, pushing the boundaries of LLM expressiveness
    ( [https://gpt3demo.com/apps/mt-nlg-by-microsoft-and-nvidia-ai](https://gpt3demo.com/apps/mt-nlg-by-microsoft-and-nvidia-ai)
    ).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*NVIDIA Megatron-Turing NLG*：生成不同的创意文本格式，如诗歌、代码、剧本等，推动LLM表现力的边界（[https://gpt3demo.com/apps/mt-nlg-by-microsoft-and-nvidia-ai](https://gpt3demo.com/apps/mt-nlg-by-microsoft-and-nvidia-ai)）。'
- en: '*Grammarly* : This writing assistant uses LLMs to analyze your writing, offering
    real-time grammar and style suggestions for clearer, more impactful communication'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Grammarly*：这个写作助手使用LLM分析你的写作，为你提供实时的语法和风格建议，使你的沟通更加清晰、有影响力。'
- en: ( [https://app.grammarly.com/](https://app.grammarly.com/) ).
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （[https://app.grammarly.com/](https://app.grammarly.com/)）。
- en: '*DeepBrain AI:* Utilizes their own LLM, along with sophisticated animation
    and voice-sy nthesis techniques ( [https://www.deepbrain.io/aistudios?via=abtnews](https://www.deepbrain.io/aistudios?via=abtnews)
    ). ( *ForbesMarr* , *f6s* , *Gemini* .)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DeepBrain AI*：利用他们自己的LLM，结合先进的动画和语音合成技术（[https://www.deepbrain.io/aistudios?via=abtnews](https://www.deepbrain.io/aistudios?via=abtnews)）。(*ForbesMarr*，*f6s*，*Gemini*)。'
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we covered what ChatGPT is and what LLMs in general are, the
    origins of some widely used LLMs such as BERT, the GPT family, LlaMDA, LlaMA,
    and modern LLMs such as GPT-4 and Gemini. We looked at some architecture of LLMs
    and transformers. We had a go at fully processing a sentence in the way an LLM
    model would: tokenizing, Word2Vec contextual embedding, and more. We also touched
    on the types of mathematics involved and the applications of this fantastic technology
    deployed by companies.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们涵盖了ChatGPT是什么以及LLM一般是什么，一些广泛使用的LLM的起源，如BERT、GPT系列、LlaMDA、LlaMA，以及现代LLM如GPT-4和Gemini。我们查看了LLM和变换器的一些架构。我们尝试了以LLM模型的方式全面处理一个句子：分词、Word2Vec上下文嵌入等。我们还涉及了相关的数学类型及这项由公司部署的惊人技术的应用。
- en: Hopefully, you now understand the nature of LLMs such as ChatGPT/Gemini; understand
    the architectures of LLMs; understand some mathematics of LLMs; and are enlightened
    about competition in the field and how to teach LLMs to others.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你现在已经理解了像ChatGPT/Gemini这样的LLM的性质；理解了LLM的架构；理解了一些LLM的数学原理；并且对这一领域的竞争以及如何将LLM教授给他人有了启发。
- en: In [*Chapter 2*](B21009_02.xhtml#_idTextAnchor051) , we will look at the advantages
    of coding with L LMs, planning your LLM-powered coding, doing some coding with
    LLMs, and making it work for you.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第2章*](B21009_02.xhtml#_idTextAnchor051)中，我们将探讨使用LLM编码的优势、规划基于LLM的编码、与LLM一起进行编码以及如何使其为你所用。
- en: Bibliography
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Amari* : “ *Learning Patterns and Pattern Sequences by Self-Organizing Nets
    of Threshold Elements* ”, S. I. Amari [https://ieeexplore.ieee.org/document/1672070](https://ieeexplore.ieee.org/document/1672070)
    in IEEE Transactions on Computers, vol. C-21, no. 11, pp. 1197-1206, Nov. 1972,
    doi: 10.1109/T-C.1972.223477'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Amari*：“*通过自组织阈值元件网络学习模式与模式序列*”，S. I. Amari，[https://ieeexplore.ieee.org/document/1672070](https://ieeexplore.ieee.org/document/1672070)，发表于IEEE计算机学报，第C-21卷，第11期，第1197-1206页，1972年11月，DOI:
    10.1109/T-C.1972.223477'
- en: 'keywords: {Associative memory, brain model, concept formation, logic nets of
    threshold elements, self-organization, sequential recalling, stability of state
    transition}'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关键词：{联想记忆，大脑模型，概念形成，阈值元件的逻辑网络，自组织，顺序回忆，状态转换的稳定性}
- en: '*AnswerIQ* : “ *25+ Google Bard Statistics 2024 (Usage, Traffic & Cost)* ”,
    Paul Rogers: [https://www.answeriq.com/google-bard-statistics/](https://www.answeriq.com/google-bard-statistics/)
    6th Jan 2024'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AnswerIQ*：“*25+ Google Bard统计数据2024（使用量、流量和成本）*”，Paul Rogers：[https://www.answeriq.com/google-bard-statistics/](https://www.answeriq.com/google-bard-statistics/)
    2024年1月6日'
- en: '*Brownlee_LLMs* : “ *What are Large Language Models* ”, Adrian Tam: [https://machinelearningmastery.com/what-are-large-language-models/](https://machinelearningmastery.com/what-are-large-language-models/)'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Brownlee_LLMs*：“*什么是大型语言模型*”，Adrian Tam：[https://machinelearningmastery.com/what-are-large-language-models/](https://machinelearningmastery.com/what-are-large-language-models/)'
- en: '*Brownlee_BLEU* : “ *A Gentle Introduction to Calculating the BLEU Score for
    Text in Python* ”, Jason Brownlee, [https://machinelearningmastery.com/calculate-bleu-score-for-text-python/](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/
    )'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Brownlee_BLEU*：“*用Python计算BLEU得分的温和入门*”，Jason Brownlee，[https://machinelearningmastery.com/calculate-bleu-score-for-text-python/](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/)'
- en: '*Brush* : “ *History of the Lenz-Ising Model* ”, Stephen G. Brush, 1967, Reviews
    of Modern Physics. 39 (4): 883–893. [https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.39.883](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.39.883)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Brush* : “ *Lenz-Ising模型的历史* ”, Stephen G. Brush, 1967, 《现代物理评论》, 39 (4):
    883–893. [https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.39.883](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.39.883)'
- en: '*ChatGPT* :” *ChatGPT* ”, OpenAI, [https://chat.openai.com/](https://chat.openai.com/
    )'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ChatGPT* :” *ChatGPT* ”, OpenAI, [https://chat.openai.com/](https://chat.openai.com/
    )'
- en: '*Chellapilla2006* : “ *High Performance Convolutional Neural Networks for Document
    Processing* ”, Kumar Chellapilla; Sid Puri; Patrice Simard (2006). In Lorette,
    Guy (ed.). Tenth International Workshop on Frontiers in Handwriting Recognition.
    Suvisoft. Archived from the original on 2020-05-18. Retrieved 2016-03-14. [https://inria.hal.science/inria-00112631/document](https://inria.hal.science/inria-00112631/document
    )'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Chellapilla2006* : “ *高性能卷积神经网络用于文档处理* ”, Kumar Chellapilla; Sid Puri; Patrice
    Simard (2006). 见 Lorette, Guy (编.). 《第十届国际手写识别前沿研讨会》。Suvisoft. 2020年5月18日档案保存。2016年3月14日检索。[https://inria.hal.science/inria-00112631/document](https://inria.hal.science/inria-00112631/document
    )'
- en: '*CodeLlama* *2023* : “ *Introducing Code Llama, an AI Tool for Coding* ”, Meta,
    [https://about.fb.com/news/2023/08/code-llama-ai-for-coding/](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/
    )'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CodeLlama* *2023* : “ *推出Code Llama，一个用于编程的AI工具* ”, Meta, [https://about.fb.com/news/2023/08/code-llama-ai-for-coding/](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/
    )'
- en: '*DeepMind* : “ *DeepMind AI Reduces Google Data Centre Cooling Bill by 40%*
    ”, Richard Evans, Jim Gao: [https://deepmind.google/discover/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40/](https://deepmind.google/discover/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40/)'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DeepMind* : “ *DeepMind AI帮助谷歌数据中心降低40%的冷却费用* ”, Richard Evans, Jim Gao: [https://deepmind.google/discover/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40/](https://deepmind.google/discover/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40/)'
- en: '*encord* : “ *Stephen Oladele, GPT-4o vs. Gemini 1.5 Pro vs. Claude 3 Opus:
    Multimodal AI Model* *Comparison* ”, [https://encord.com/blog/gpt-4o-vs-gemini-vs-claude-3-opus/#:~:text=Code%20Generation%20Capability,GPT%2D4o%20in%20this%20domain](https://encord.com/blog/gpt-4o-vs-gemini-vs-claude-3-opus/#:~:text=Code%20Generation%20Capability,GPT%2D4o%20in%20this%20domain
    )'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*encord* : “ *Stephen Oladele, GPT-4o与Gemini 1.5 Pro与Claude 3 Opus：多模态AI模型*
    *对比* ”, [https://encord.com/blog/gpt-4o-vs-gemini-vs-claude-3-opus/#:~:text=Code%20Generation%20Capability,GPT%2D4o%20in%20this%20domain](https://encord.com/blog/gpt-4o-vs-gemini-vs-claude-3-opus/#:~:text=Code%20Generation%20Capability,GPT%2D4o%20in%20this%20domain
    )'
- en: '*ForbesMarr* : “ *10 Amazing Real-World Examples Of How Companies Are Using
    ChatGPT In 2023* ”, Bernard Marr: [https://www.forbes.com/sites/bernardmarr/2023/05/30/10-amazing-real-world-examples-of-how-companies-are-using-chatgpt-in-2023/?sh=3fe5f9601441](https://www.forbes.com/sites/bernardmarr/2023/05/30/10-amazing-real-world-examples-of-how-companies-are-using-chatgpt-in-2023/?sh=3fe5f9601441
    )'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ForbesMarr* : “ *2023年公司如何使用ChatGPT的10个惊人现实案例* ”, Bernard Marr: [https://www.forbes.com/sites/bernardmarr/2023/05/30/10-amazing-real-world-examples-of-how-companies-are-using-chatgpt-in-2023/?sh=3fe5f9601441](https://www.forbes.com/sites/bernardmarr/2023/05/30/10-amazing-real-world-examples-of-how-companies-are-using-chatgpt-in-2023/?sh=3fe5f9601441
    )'
- en: '*f62* : “ *100 top ChatGPT companies and startups in 2024* ”, f62: [https://www.f6s.com/companies/chatgpt/mo](https://www.f6s.com/companies/chatgpt/mo
    )'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f62* : “ *2024年100家顶级ChatGPT公司与初创企业* ”, f62: [https://www.f6s.com/companies/chatgpt/mo](https://www.f6s.com/companies/chatgpt/mo
    )'
- en: '*Fukushima1980* : “ *Neocognitron: A self-organizing neural network model for
    a mechanism of pattern recognition unaffected by shift in position* ”, Kunihiko
    Fukushima, J. Biological Cybernetics., [https://doi.org/10.1007/BF00344251](https://doi.org/10.1007/BF00344251)'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Fukushima1980* : “ *Neocognitron：一种自组织神经网络模型，用于不受位置变化影响的模式识别机制* ”, Kunihiko
    Fukushima, J. Biological Cybernetics., [https://doi.org/10.1007/BF00344251](https://doi.org/10.1007/BF00344251)'
- en: '*GeekCultureBERT* : “ *4 Crucial Things to Know about GPT-4: You should know
    these to use GPT-4* ”, Tirendaz AI, [https://medium.com/geekculture/an-overview-of-gpt-4-in-4-steps-867bb81b31e3](https://medium.com/geekculture/an-overview-of-gpt-4-in-4-steps-867bb81b31e3
    )'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GeekCultureBERT* : “ *关于GPT-4的4个关键要点：使用GPT-4时你需要了解的* ”, Tirendaz AI, [https://medium.com/geekculture/an-overview-of-gpt-4-in-4-steps-867bb81b31e3](https://medium.com/geekculture/an-overview-of-gpt-4-in-4-steps-867bb81b31e3
    )'
- en: '*Gemini* : “ *Gemini* ”, Google Research, [https://gemini.google.com/](https://gemini.google.com/)'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*双子星* : “ *双子星* ”, 谷歌研究, [https://gemini.google.com/](https://gemini.google.com/)'
- en: '*GeminiTeam* : “ *Gemini: A Family of Highly Capable Multimodal Models* ”,
    Gemini Team, Google, [https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf
    )'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GeminiTeam* : “*Gemini：一系列高度智能的多模态模型*”，Gemini Team，谷歌，[https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)'
- en: '*Hochreiter1997* : “ *Long Short-Term Memory* ”, Sepp Hochreiter, Sepp; Jürgen
    Schmidhuber, Jürgen (1997-11-01). Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735.
    PMID 9377276. S2CID 1915014. [https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltexthttps://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext](https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltexthttps://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext
    )'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Hochreiter1997* : “*长短期记忆*”，Sepp Hochreiter, Sepp；Jürgen Schmidhuber, Jürgen（1997-11-01）。神经计算。9（8）：1735–1780。doi:10.1162/neco.1997.9.8.1735。PMID
    9377276。S2CID 1915014。[https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltexthttps://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext](https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltexthttps://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext)'
- en: '*Hooper* : “ *How to Spend $1 trillion* ”, Rowan Hooper ( 2021), [https://www.goodreads.com/en/book/show/54823535](https://www.goodreads.com/en/book/show/54823535)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Hooper* : “*如何花费1万亿美元*”，Rowan Hooper（2021），[https://www.goodreads.com/en/book/show/54823535](https://www.goodreads.com/en/book/show/54823535)'
- en: '*HuggingFace* : “ *describeai/gemini* ”, Hugging Face, [https://huggingface.co/describeai/gemini](https://huggingface.co/describeai/gemini)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*HuggingFace* : “*describeai/gemini*”，Hugging Face，[https://huggingface.co/describeai/gemini](https://huggingface.co/describeai/gemini)'
- en: '*Investors.com* : “ *OpenAI Circus Continues As Ousted Chief Executive Returns
    As Boss* ”, Patrick Seitz: [https://www.investors.com/news/technology/microsoft-stock-rises-on-sam-altman-return-to-openai/](https://www.investors.com/news/technology/microsoft-stock-rises-on-sam-altman-return-to-openai/)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Investors.com* : “*OpenAI 的马戏团仍在继续，遭解职的首席执行官重返公司担任老板*”，Patrick Seitz：[https://www.investors.com/news/technology/microsoft-stock-rises-on-sam-altman-return-to-openai/](https://www.investors.com/news/technology/microsoft-stock-rises-on-sam-altman-return-to-openai/)'
- en: '*LeCun1989* : “ *Backpropagation Applied to Handwritten Zip Code Recognition*
    ”, Y. LeCun; B.J..S. Boser; J.S. Denker; D. Henderson; R.E. Howard; W. Hubbard;
    L.D. Jackel (1989) Advances in Neural Information Processing Systems, 1, 323-331.
    [https://doi.org/10.1162/neco.1989.1.4.541](https://doi.org/10.1162/neco.1989.1.4.541)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LeCun1989* : “*反向传播应用于手写邮政编码识别*”，Y. LeCun；B.J. Boser；J.S. Denker；D. Henderson；R.E.
    Howard；W. Hubbard；L.D. Jackel（1989）。神经信息处理系统进展，1，323-331。[https://doi.org/10.1162/neco.1989.1.4.541](https://doi.org/10.1162/neco.1989.1.4.541)'
- en: '*Life_Architecture* : “ *Amazon Olympus (large language model due 2024H2* )”,
    Alan D. Thompson, [https://lifearchitect.ai/olympus/](https://lifearchitect.ai/olympus/)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Life_Architecture* : “*亚马逊奥林匹斯（预计2024年下半年发布的大型语言模型）*”，Alan D. Thompson，[https://lifearchitect.ai/olympus/](https://lifearchitect.ai/olympus/)'
- en: '*Llama3* : “ *Llama3 8b* ”, Meta, **https://llama.meta.com/llama3/**'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Llama3* : “*Llama3 8b*”，Meta，**https://llama.meta.com/llama3/**'
- en: '*Mandlik* : “ *How GPT-4 Image Works* ?”, Sanman Mandlik, [https://sanmancreations.medium.com/how-gpt-4-image-works-4d7a87cf4497#:~:text=GPT%2D4%20Image%3A%20A%20Fusion,a%20pioneering%20advancement%20in%20AI](https://sanmancreations.medium.com/how-gpt-4-image-works-4d7a87cf4497#:~:text=GPT%2D4%20Image%3A%20A%20Fusion,a%20pioneering%20advancement%20in%20AI)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mandlik* : “*GPT-4 图像如何工作*？”，Sanman Mandlik，[https://sanmancreations.medium.com/how-gpt-4-image-works-4d7a87cf4497#:~:text=GPT%2D4%20Image%3A%20A%20Fusion,a%20pioneering%20advancement%20in%20AI](https://sanmancreations.medium.com/how-gpt-4-image-works-4d7a87cf4497#:~:text=GPT%2D4%20Image%3A%20A%20Fusion,a%20pioneering%20advancement%20in%20AI)'
- en: '*Megatron-Turing 2022* : “ *Using DeepSpeed and Megatron to Train Megatron-Turing
    NLG 530B, A Large-Scale Generative Language Model* ”, Shaden Smith; Mostofa Patwary;
    Brandon Norick; Patrick LeGresley; Samyam Rajbhandari; Jared Casper; Zhun Liu;
    Shrimai Prabhumoye; George Zerveas; Vijay Korthikanti; Elton Zhang; Rewon Child;
    Reza Yazdani Aminabadi; Julie Bernauer; Xia Song; Mohammad Shoeybi; Yuxiong He;
    Michael Houston; Saurabh Tiwary; Bryan Catanzaro: [https://arxiv.org/abs/2201.11990](https://arxiv.org/abs/2201.11990)'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Megatron-Turing 2022* : “*使用 DeepSpeed 和 Megatron 训练 Megatron-Turing NLG 530B，一个大规模生成性语言模型*”，Shaden
    Smith；Mostofa Patwary；Brandon Norick；Patrick LeGresley；Samyam Rajbhandari；Jared
    Casper；Zhun Liu；Shrimai Prabhumoye；George Zerveas；Vijay Korthikanti；Elton Zhang；Rewon
    Child；Reza Yazdani Aminabadi；Julie Bernauer；Xia Song；Mohammad Shoeybi；Yuxiong
    He；Michael Houston；Saurabh Tiwary；Bryan Catanzaro：[https://arxiv.org/abs/2201.11990](https://arxiv.org/abs/2201.11990)'
- en: '*Menon* : “ *Introduction to Large Language Models and the Transformer Architecture*
    ”, Pradeep Menon, [https://rpradeepmenon.medium.com/introduction-to-large-language-models-and-the-transformer-architecture-534408ed7e61](https://rpradeepmenon.medium.com/introduction-to-large-language-models-and-the-transformer-architecture-534408ed7e61)'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Menon* : “ *大型语言模型与变换器架构简介* ”, Pradeep Menon, [https://rpradeepmenon.medium.com/introduction-to-large-language-models-and-the-transformer-architecture-534408ed7e61](https://rpradeepmenon.medium.com/introduction-to-large-language-models-and-the-transformer-architecture-534408ed7e61)'
- en: '*Metzger* : “ *A Beginner’s Guide to Tokens, Vectors, and Embeddings in NLP*
    ”, Sascha Metzger, [https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037](mailto:https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037)'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Metzger* : “ *NLP中的标记、向量和嵌入：初学者指南* ”, Sascha Metzger, [https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037](mailto:https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037)'
- en: '*MotiveX_Gemini* : “ *Is GEMINI AI The Best? - SHOCKING Power (GPT-4 HUMBLED)*
    ”, MotiveX YouTube channel, [https://youtu.be/JvA9os8Oq20?t=144](https://youtu.be/JvA9os8Oq20?t=144)
    , 6 Feb 2024'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MotiveX_Gemini* : “ *GEMINI AI是最强的吗？- 震撼力（GPT-4的谦卑）* ”, MotiveX YouTube频道,
    [https://youtu.be/JvA9os8Oq20?t=144](https://youtu.be/JvA9os8Oq20?t=144) , 2024年2月6日'
- en: '*OpenAI_CLIP* : “ *CLIP: Connecting text and images* ”, OpenAI, [https://openai.com/index/clip/](https://openai.com/index/clip/)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI_CLIP* : “ *CLIP：连接文本与图像* ”, OpenAI, [https://openai.com/index/clip/](https://openai.com/index/clip/)'
- en: '*OpenAI_DALL.E* : “ *DALL.E: Creating images from text* ” OpenAI, [https://openai.com/index/dall-e/](https://openai.com/index/dall-e/)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI_DALL.E* : “ *DALL.E：从文本创建图像* ”, OpenAI, [https://openai.com/index/dall-e/](https://openai.com/index/dall-e/)'
- en: '*OpenAI-GPT-4o* : “ *Hello GPT-4o* ”, OpenAI, [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI-GPT-4o* : “ *Hello GPT-4o* ”, OpenAI, [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)'
- en: '*OpenAI_GPT4Turbo* : “ *New models and developer products announced at DevDay
    GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4
    Turbo with Vision, DALL·E 3 API, and more* ”, OpenAI, [https://openai.com/blog/new-models-and-developer-products-announced-at-devday](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI_GPT4Turbo* : “ *在DevDay上宣布的新模型和开发者产品：GPT-4 Turbo，128K上下文和更低价格，新助手API，带视觉的GPT-4
    Turbo，DALL·E 3 API等* ”, OpenAI, [https://openai.com/blog/new-models-and-developer-products-announced-at-devday](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)'
- en: '*OpenAI_LP* : “ *OpenAI LP* ”, OpenAI, [https://openai.com/index/openai-lp/](https://openai.com/index/openai-lp/)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI_LP* : “ *OpenAI LP* ”, OpenAI, [https://openai.com/index/openai-lp/](https://openai.com/index/openai-lp/)'
- en: '*OpenAIStructure* : “ *Our Structure* ”, OpenAI, [https://openai.com/our-structure/](https://openai.com/our-structure/)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAIStructure* : “ *我们的结构* ”, OpenAI, [https://openai.com/our-structure/](https://openai.com/our-structure/)'
- en: '*OpenLMR* : “ *OpenLLaMA: An Open Reproduction of LLaMA* ”, Xinyang (Young)
    Geng; Hao Liu; Martin, Jul, [https://github.com/openlm-research/open_llama](https://github.com/openlm-research/open_llama)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenLMR* : “ *OpenLLaMA：LLaMA的开放重现* ”, Xinyang (Young) Geng; Hao Liu; Martin,
    Jul, [https://github.com/openlm-research/open_llama](https://github.com/openlm-research/open_llama)'
- en: '*Panuganty* : “ *From Words to Vectors: Inside the LLM Transformer Architecture*
    ”, Harika Panuganty: [https://medium.com/@harikapanuganty/from-words-to-vectors-inside-the-llm-transformer-architecture-50275c354bc4](mailto:https://medium.com/@harikapanuganty/from-words-to-vectors-inside-the-llm-transformer-architecture-50275c354bc4)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Panuganty* : “ *从词语到向量：探索LLM变换器架构* ”, Harika Panuganty: [https://medium.com/@harikapanuganty/from-words-to-vectors-inside-the-llm-transformer-architecture-50275c354bc4](mailto:https://medium.com/@harikapanuganty/from-words-to-vectors-inside-the-llm-transformer-architecture-50275c354bc4)'
- en: '*Patil* : “ *Top 5 Pre-trained Word Embeddings* ”, Aakanksha Patil, [https://patil-aakanksha.medium.com/top-5-pre-trained-word-embeddings-20de114bc26](https://patil-aakanksha.medium.com/top-5-pre-trained-word-embeddings-20de114bc26)'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Patil* : “ *五大预训练词嵌入* ”, Aakanksha Patil, [https://patil-aakanksha.medium.com/top-5-pre-trained-word-embeddings-20de114bc26](https://patil-aakanksha.medium.com/top-5-pre-trained-word-embeddings-20de114bc26)'
- en: '*ProjectPro* : “ *ChatGPT vs Google BARD-Battle of the Large Language Models*
    ”, Manika, [https://www.projectpro.io/article/chatgpt-vs-google-bard/815](https://www.projectpro.io/article/chatgpt-vs-google-bard/815)'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ProjectPro* : “ *ChatGPT与Google BARD：大型语言模型之战* ”, Manika, [https://www.projectpro.io/article/chatgpt-vs-google-bard/815](https://www.projectpro.io/article/chatgpt-vs-google-bard/815)'
- en: '*SkillLeapAI* : “ *How to Use Google Gemini in Bard - Including new prompts*
    ”, Skill Leap AI YouTube channel, [https://www.youtube.com/watch?v=9qszKWO68wQ](https://www.youtube.com/watch?v=9qszKWO68wQ)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SkillLeapAI* ：“ *如何在Bard中使用Google Gemini——包括新的提示* ”, Skill Leap AI YouTube频道,
    [https://www.youtube.com/watch?v=9qszKWO68wQ](https://www.youtube.com/watch?v=9qszKWO68wQ)'
- en: '*Vaswani* : “ *Attention Is All You Need* ”, Ashish Vaswani; Noam Shazeer;
    Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N. Gomez; Lukasz Kaiser and Illia
    Polosukhin, [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Vaswani* ：“ *注意力机制：一切所需* ”, 阿希什·瓦斯瓦尼; 诺姆·沙泽尔; 妮基·帕尔马尔; 雅各布·乌兹科雷特; 利昂·琼斯; 艾丹·N·戈梅兹;
    卢卡什·凯泽和伊利亚·波洛苏金, [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
- en: '*Wagh* : “ *What’s new in GPT-4: An Overview of the GPT-4 Architecture and
    Capabilities of Next-Generation AI* ”, Amol Wagh, [https://medium.com/@amol-wagh/whats-new-in-gpt-4-an-overview-of-the-gpt-4-architecture-and-capabilities-of-next-generation-ai-900c445d5ffe](mailto:https://medium.com/@amol-wagh/whats-new-in-gpt-4-an-overview-of-the-gpt-4-architecture-and-capabilities-of-next-generation-ai-900c445d5ffe)'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wagh* ：“ *GPT-4的新特性：下一代AI的GPT-4架构和能力概述* ”, 阿莫尔·瓦赫, [https://medium.com/@amol-wagh/whats-new-in-gpt-4-an-overview-of-the-gpt-4-architecture-and-capabilities-of-next-generation-ai-900c445d5ffe](mailto:https://medium.com/@amol-wagh/whats-new-in-gpt-4-an-overview-of-the-gpt-4-architecture-and-capabilities-of-next-generation-ai-900c445d5ffe)'
- en: '*Watson 2023* : “Op *en Llama Unleashed: Revolutionizing AI for Business &*
    *Beyond!* [https://medium.com/nextgen-tech/open-llama-unleashed-revolutionizing-ai-for-business-beyond-18de67aa0b9d](https://medium.com/nextgen-tech/open-llama-unleashed-revolutionizing-ai-for-business-beyond-18de67aa0b9d)'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Watson 2023* ：“Op *en Llama Unleashed: 颠覆AI在商业及其之外的应用* ” [https://medium.com/nextgen-tech/open-llama-unleashed-revolutionizing-ai-for-business-beyond-18de67aa0b9d](https://medium.com/nextgen-tech/open-llama-unleashed-revolutionizing-ai-for-business-beyond-18de67aa0b9d)'
- en: '*Wiki_Gemini* : “ *Gemini (chatbot)* ”, Wikipedia, [https://en.wikipedia.org/wiki/Gemini_(chatbot)](https://en.wikipedia.org/wiki/Gemini_(chatbot))'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wiki_Gemini* ：“ *Gemini (聊天机器人)* ”, 维基百科, [https://en.wikipedia.org/wiki/Gemini_(chatbot)](https://en.wikipedia.org/wiki/Gemini_(chatbot))'
- en: '*Wiki_GPT3* : “ *GPT-3* ”, Wikipedia, [https://en.wikipedia.org/wiki/GPT-3](https://en.wikipedia.org/wiki/GPT-3)'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wiki_GPT3* ：“ *GPT-3* ”, 维基百科, [https://en.wikipedia.org/wiki/GPT-3](https://en.wikipedia.org/wiki/GPT-3)'
- en: '*Wiki_GPT4* : “ *GPT-4* ”, , Wikipedia, [https://en.wikipedia.org/wiki/GPT-4](https://en.wikipedia.org/wiki/GPT-4)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wiki_GPT4* ：“ *GPT-4* ”, 维基百科, [https://en.wikipedia.org/wiki/GPT-4](https://en.wikipedia.org/wiki/GPT-4)'
- en: '*Wiki_llama* : (2024), “ *LLaMA* ”, Wikipedia, **https://en.wikipedia.org/wiki/LLaMA**'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wiki_llama* ：(2024), “ *LLaMA* ”, 维基百科, **https://en.wikipedia.org/wiki/LLaMA**'
- en: '*Wiki_LSTM* : “ *Recurrent Neural Network* ”, Wikipedia, [https://en.wikipedia.org/wiki/Recurrent_neural_network#:~:text=Long%20short%2Dterm%20memory%20(LSTM,models%20in%20certain%20speech%20applications](https://en.wikipedia.org/wiki/Recurrent_neural_network#:~:text=Long%20short%2Dterm%20memory%20(LSTM,models%20in%20certain%20speech%20applications)'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wiki_LSTM* ：“ *递归神经网络* ”, 维基百科, [https://en.wikipedia.org/wiki/Recurrent_neural_network#:~:text=Long%20short%2Dterm%20memory%20(LSTM,models%20in%20certain%20speech%20applications](https://en.wikipedia.org/wiki/Recurrent_neural_network#:~:text=Long%20short%2Dterm%20memory%20(LSTM,models%20in%20certain%20speech%20applications)'
- en: '*Yang2023* : “ *Harnessing the Power of LLMs in Practice: A Survey on ChatGPT
    and Beyond* ”, Jingfeng Yang; Hongye Jin; Ruixiang Tang; Xiaotian Han; Qizhang
    Feng; Haoming Jiang; Bing Yin and Xia Hu, [https://arxiv.org/abs/2304.13712](https://arxiv.org/abs/2304.13712)'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Yang2023* ：“ *实践中利用LLMs的力量：ChatGPT及其以后的调查* ”, 杨敬峰; 金洪烨; 唐瑞翔; 韩晓天; 冯启章; 蒋昊明;
    殷冰和胡霞, [https://arxiv.org/abs/2304.13712](https://arxiv.org/abs/2304.13712)'
- en: '*Zahere* : “ *How ChatGPT Works: The Architectural Details You Need to Know*
    ”, Zahiruddin Tavargere, [https://zahere.com/how-chatgpt-works-the-architectural-details-you-need-to-know](https://zahere.com/how-chatgpt-works-the-architectural-details-you-need-to-know)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Zahere* ：“ *ChatGPT是如何工作的：你需要知道的架构细节* ”, 扎赫鲁丁·塔瓦尔吉, [https://zahere.com/how-chatgpt-works-the-architectural-details-you-need-to-know](https://zahere.com/how-chatgpt-works-the-architectural-details-you-need-to-know)'
