- en: 2\. Perceptrons
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 感知机
- en: This chapter describes an algorithm called a *perceptron*. Invented by the US
    researcher Frank Rosenblatt in 1957, it is from this traditional algorithm that
    neural networks (i.e., deep learning) originated and is thus a necessary first
    step to the more advanced study of both. This chapter will describe a perceptron
    and use one to solve easy problems. Throughout this process, you will familiarize
    yourself with the mechanics of perceptrons.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了一种叫做*感知机*的算法。它由美国研究员弗兰克·罗森布拉特于1957年发明，正是从这种传统算法中衍生出了神经网络（即深度学习），因此它是学习这两个领域更高阶知识的必要第一步。本章将介绍感知机，并利用感知机解决简单问题。在此过程中，你将熟悉感知机的基本原理。
- en: What Is a Perceptron?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是感知机？
- en: 'A perceptron receives multiple signals as inputs and outputs one signal. The
    "signal" here "flows" like an electric current or a river. In the same way that
    an electric current flows through a conductor and pushes electrons forward, the
    signal in a perceptron makes flow and transfers information. Unlike an electric
    current, the signal in a perceptron is binary: "Flow (1) or Do not flow (0)."
    In this book, 0 indicates "do not flow a signal" and 1 indicates "flow a signal."'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机接收多个信号作为输入，并输出一个信号。这里的“信号”像电流或河流一样“流动”。就像电流通过导体推动电子前进一样，感知机中的信号也会流动并传递信息。与电流不同的是，感知机中的信号是二进制的：“流动（1）或不流动（0）。”在本书中，0表示“不传递信号”，1表示“传递信号”。
- en: (In the interest of precision, note that the perceptron described in this chapter
    is more accurately called an "artificial neuron" or a "simple perceptron." Here,
    we will call it a "perceptron" because the basic processes are often the same.)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: （为了准确起见，注意本章描述的感知机更准确地应称为“人工神经元”或“简单感知机”。在这里，我们将其称为“感知机”，因为其基本过程通常是相同的。）
- en: '*Figure 2.1* shows an example of a perceptron that receives two signals as
    input:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.1* 显示了一个接收两个信号作为输入的感知机示例：'
- en: '![Figure 2.1: Perceptron with two inputs'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.1：带有两个输入的感知机'
- en: '](img/fig02_1.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_1.jpg)'
- en: 'Figure 2.1: Perceptron with two inputs'
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.1：带有两个输入的感知机
- en: '*x*1 and *x*2 are input signals, *y* is an output signal, and *w*1 and *w*2
    are weights (w is the initial letter of "weight"). The circle in the preceding
    diagram is called a "neuron" or a "node." When input signals are sent to a neuron,
    each of them is multiplied by its own weight (*w*1*x*1 and *w*2*x*2). The neuron
    sums the signals that it receives and outputs 1 when the sum exceeds a certain
    limit value. This is sometimes called "firing a neuron." Here, the limit value
    is called a **threshold** and is represented by the *θ* symbol.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*x*1 和 *x*2 是输入信号，*y* 是输出信号，*w*1 和 *w*2 是权重（w 是“权重”一词的首字母）。前面的图中的圆圈叫做“神经元”或“节点”。当输入信号传递到神经元时，每个信号都与其对应的权重相乘（*w*1
    *x*1 和 *w*2 *x*2）。神经元对接收到的信号进行求和，当和超过某一限制值时，它输出1。这有时被称为“激活神经元”。这里，限制值称为**阈值**，并由*θ*符号表示。'
- en: 'This is all about the operating principle of a perceptron. Equation (2.1) shows
    what we described here:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是感知机的工作原理。公式（2.1）展示了我们在此描述的内容：
- en: '| ![1](img/Firgure_2.1a.png) | (2.1) |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| ![1](img/Firgure_2.1a.png) | (2.1) |'
- en: A perceptron has a specific weight for each of multiple inputs, while the weight
    controls the importance of each signal. The larger the weight, the more important
    the signal for the weight.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机为多个输入中的每一个设置了特定的权重，权重控制每个信号的重要性。权重越大，信号对该权重的影响就越大。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: A weight is equivalent to electrical "resistance." Resistance is a parameter
    that measures the difficulty of passing an electric current. The smaller the resistance,
    the larger the current. Meanwhile, when the weight of a perceptron is larger,
    the signal that flows becomes larger. Both resistance and weight work in the same
    way in that they both control the difficulty (or ease) of passing a signal.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 权重相当于电气“电阻”。电阻是衡量电流通过难度的参数。电阻越小，电流越大。同时，当感知机的权重越大，流过的信号也越强。电阻和权重的作用方式相同，它们都控制信号通过的难易程度。
- en: Simple Logic Circuits
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单逻辑电路
- en: AND Gate
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与门
- en: 'The following are some easy problems that use a perceptron. We will look at
    logic circuits here. Let''s think about an AND gate first. An AND gate consists
    of two inputs and one output. The table of input and output signals in *Figure
    2.2* is called a "truth table." As shown in *Figure 2.2*, the AND gate outputs
    1 when two inputs are 1\. Otherwise, it outputs 0:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些使用感知机的简单问题。我们在这里讨论逻辑电路。让我们首先思考一个 AND 门。一个 AND 门由两个输入和一个输出组成。输入和输出信号的表格，如*图
    2.2*所示，称为“真值表”。如*图 2.2*所示，当两个输入为 1 时，AND 门输出 1，其他情况输出 0：
- en: '![Figure 2.2: Truth table of an AND gate'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.2：AND 门的真值表'
- en: '](img/fig02_2.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_2.jpg)'
- en: 'Figure 2.2: Truth table of an AND gate'
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.2：AND 门的真值表
- en: Now, we will use a perceptron to express this AND gate. We will determine the
    values of *w*1, *w*2, and *θ* so that they satisfy the truth table of *Figure
    2.2*. What values can we set to create a perceptron that satisfies the conditions
    of *Figure 2.2*?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用感知机来表示这个 AND 门。我们将确定 *w*1、*w*2 和 *θ* 的值，使它们满足*图 2.2*的真值表。我们可以设置什么值来创建一个符合*图
    2.2*条件的感知机？
- en: Actually, there is an infinite number of combinations of the parameters that
    satisfy *Figure 2.2*. For example, when (*w*1, *w*2, *θ*) = (0.5, 0.5, 0.7), the
    perceptron works as shown in *Figure 2.2*. (0.5, 0.5, 0.8) and (1.0, 1.0, 1.0)
    also satisfy the conditions of the AND gate. If these parameters are set, the
    sum of weighted signals exceeds the given threshold, *θ*, when both *x*1 and *x*2
    are 1.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，满足*图 2.2*的参数组合有无数种。例如，当（*w*1, *w*2, *θ*）=（0.5, 0.5, 0.7）时，感知机的工作方式如*图 2.2*所示。（0.5,
    0.5, 0.8）和（1.0, 1.0, 1.0）也满足 AND 门的条件。如果设置这些参数，当 *x*1 和 *x*2 都为 1 时，带权信号的总和超过给定的阈值*θ*。
- en: NAND and OR gates
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NAND 和 OR 门
- en: Now, let's look at a NAND gate. NAND means Not AND, and the output of the NAND
    gate is the opposite of the AND gate. As shown in the truth table provided in
    *Figure 2.3*, it outputs 0 when both *x*1 and *x*2 are 1\. Otherwise, it outputs
    1\. What combinations of parameters are available for a NAND gate?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一个 NAND 门。NAND 是 Not AND 的意思，NAND 门的输出是 AND 门的反面。如*图 2.3*提供的真值表所示，当
    *x*1 和 *x*2 都为 1 时，它输出 0，其他情况输出 1。NAND 门有哪些参数组合呢？
- en: '![Figure 2.3: Truth table of a NAND gate'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.3：NAND 门的真值表'
- en: '](img/fig02_3.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_3.jpg)'
- en: 'Figure 2.3: Truth table of a NAND gate'
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.3：NAND 门的真值表
- en: A combination of (*w*1, *w*2, *θ*) = (-0.5, -0.5, -0.7) can represent a NAND
    gate, and there is an infinite number of other combinations. In fact, you can
    build a NAND gate by inverting all the signs of the parameter values that build
    an AND gate.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一组组合（*w*1, *w*2, *θ*）=（-0.5, -0.5, -0.7）可以表示一个 NAND 门，实际上还有无数种其他组合。事实上，你可以通过反转构建
    AND 门的参数值的所有符号来构建一个 NAND 门。
- en: Now, let's look at an OR gate, as shown in *Figure 2.4*. This is a logic circuit
    that outputs 1 if at least one of the input signals is 1\. What parameters do
    you think we can set for the OR gate?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 OR 门，如*图 2.4*所示。这是一个逻辑电路，当至少一个输入信号为 1 时，它输出 1。你认为我们可以为 OR 门设置什么参数？
- en: '![Figure 2.4: Truth table of an OR gate'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4：OR 门的真值表'
- en: '](img/fig02_4.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_4.jpg)'
- en: 'Figure 2.4: Truth table of an OR gate'
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.4：OR 门的真值表
- en: Note
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: We are the ones that determine the perceptron parameters here—not a computer.
    While looking at the "training data," also known as a truth table, we considered
    (found) the parameter values manually. In machine learning problems, we have a
    computer determines the parameter values automatically. **Training** is the task
    that determines the appropriate parameters, and we consider the structure (model)
    of the perceptron and give training data to the computer.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们是决定感知机参数的人，而不是计算机。在查看“训练数据”时，也就是所谓的真值表，我们手动考虑（或找到）了参数值。在机器学习问题中，计算机会自动确定参数值。**训练**是决定合适参数的任务，我们考虑感知机的结构（模型），并将训练数据提供给计算机。
- en: As described previously, we can use a perceptron to build AND, NAND, and OR
    logic circuits. What is important here is that the structure of a perceptron is
    the same for all of the AND, NAND, and OR gates. The differences between the three
    gates lie in the parameter values (weights and thresholds). Just like a versatile
    actor plays a wide variety of characters, the perceptron of the same structure
    changes into AND, NAND, and OR when the parameter values are adjusted appropriately.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以使用感知器构建与门、非与门和或门逻辑电路。这里重要的是，感知器的结构对于与门、非与门和或门是相同的。三者之间的区别在于参数值（权重和阈值）。就像一个多才多艺的演员能够演绎各种角色一样，当适当调整参数值时，具有相同结构的感知器可以变成与门、非与门或或门。
- en: Implementing Perceptrons
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现感知器
- en: Easy Implementation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单实现
- en: 'Let''s implement the preceding logic circuits with Python. Here, we will define
    the AND function, which takes `x1` and `x2` as arguments:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 Python 实现前面的逻辑电路。在这里，我们将定义 AND 函数，接受`x1`和`x2`作为参数：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `w1`, `w2`, and `theta` parameters are initialized within the function.
    When the sum of the weighted inputs exceeds the threshold, it returns 1; otherwise,
    it returns 0\. Let''s check that the outputs are the same as the ones shown in
    *Figure 2.2*:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`w1`、`w2` 和 `theta` 参数在函数内部被初始化。当加权输入的总和超过阈值时，返回1；否则，返回0。让我们检查输出是否与*图 2.2*中所示的相同：'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The outputs are as we expected. With that, you have built an AND gate. Although
    you can use a similar procedure to build a NAND or OR gate, we will change the
    implementation a little.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如我们预期的那样。这样，你就构建了一个与门。尽管你可以使用类似的过程构建非与门或或门，但我们将稍微改变实现方式。
- en: Introducing Weights and Bias
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引入权重和偏置
- en: 'Although the preceding implementation of an AND gate is simple and easy to
    understand, we will change it to a different implementation for the subsequent
    sections, switching *θ* in equation (2.1) to -b and representing the behavior
    of the perceptron in equation (2.2):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的与门实现简单且易于理解，我们将在后续章节中将其改为不同的实现方式，将方程（2.1）中的*θ*替换为-b，并在方程（2.2）中表示感知器的行为：
- en: '| ![2](img/Figure_2.4a.png) | (2.2) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| ![2](img/Figure_2.4a.png) | (2.2) |'
- en: 'Although the notation of the symbols has changed, equations (2.1) and (2.2)
    represent exactly the same thing. Here, b is called a bias and *w*1 and *w*2 are
    called **weights**. As equation (2.2) shows, the perceptron sums the input signal
    values multiplied by the weights and the bias. It outputs 1 if the sum exceeds
    0, and outputs 0 otherwise. Now, let''s use NumPy to implement equation (2.2).
    We will use the Python interpreter to check the results one by one:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管符号的表示法已经发生变化，方程（2.1）和（2.2）表示的完全相同。这里，b 被称为偏置，而*w*1 和 *w*2 被称为**权重**。如方程（2.2）所示，感知器将输入信号值与权重相乘后加和，再加上偏置。如果和超过0，输出1，否则输出0。现在，让我们使用
    NumPy 实现方程（2.2）。我们将使用 Python 解释器逐一检查结果：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As shown in this example, when NumPy arrays are multiplied, each of their elements
    is multiplied if the two arrays have the same number of elements. Therefore, when
    calculating `w*x`, each element is multiplied, ([0, 1] * [0.5, 0.5] => [0, 0.5]).
    In `np.sum(w*x)`, each element is summed. When the bias is added to this weighted
    sum, the calculation of equation (2.2) is complete.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如此示例所示，当 NumPy 数组相乘时，如果两个数组的元素数量相同，它们的每个元素都会相乘。因此，在计算`w*x`时，每个元素都会相乘，（[0, 1]
    * [0.5, 0.5] => [0, 0.5]）。在`np.sum(w*x)`中，每个元素会被求和。当偏置被加到这个加权和时，方程（2.2）的计算就完成了。
- en: Implementation with Weights and Bias
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用权重和偏置的实现
- en: 'You can use weights and bias to implement an AND gate, as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用权重和偏置实现与门，如下所示：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, -*θ* is called the bias, *b*. Note that the bias works differently from
    the weights, *w*1, and *w*2\. Specifically, *w*1 and *w*2 work as parameters that
    control the importance of input signals, while the bias works as the parameter
    that adjusts the ease of firing—that is, how likely it is that the output signal
    is 1\. For example, if *b* is -0.1, the neuron fires when the weighted sum of
    the input signals exceeds 0.1\. On the other hand, if *b* is -20.0, the neuron
    fires only when the weighted sum of input signals exceeds 20.0\. Thus, the value
    of the bias determines how easily the neuron fires. Although *w*1 and *w*2 are
    called "weights" and *b* is called "bias," all the parameters (that is, *b*, *w*1,
    and *w*2) are sometimes called "weights," depending on the context.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，-*θ*称为偏置（bias），*b*。请注意，偏置与权重* w*1 和 *w*2的作用不同。具体来说，*w*1 和 *w*2 作为参数，控制输入信号的重要性，而偏置则作为调节神经元激活容易度的参数——即输出信号为1的可能性。例如，如果*b*是-0.1，当输入信号的加权和超过0.1时，神经元会触发。另一方面，如果*b*是-20.0，只有当输入信号的加权和超过20.0时，神经元才会触发。因此，偏置的值决定了神经元激活的难易程度。虽然*w*1
    和 *w*2 被称为“权重”，而*b* 被称为“偏置”，但在某些上下文中，所有这些参数（即*b*，*w*1 和 *w*2）有时统称为“权重”。
- en: Note
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注：
- en: The word "bias" also means "padding." It indicates that the output is increased
    if nothing is input (if the input is 0). Actually, if inputs *x*1 and *x*2 are
    0, the output is just the value of the bias when *b* + *w*1*x*1 + *w*2*x*2 is
    calculated in equation (2.2).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: “偏置”一词也有“填充”的意思。它表示如果没有输入（即输入为0），则输出会增加。实际上，如果输入*x*1和*x*2均为0，那么当计算公式(2.2)中的*b*
    + *w*1 *x*1 + *w*2 *x*2时，输出的值就是偏置的值。
- en: 'Now, let''s implement the NAND and OR gates:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们实现NAND和OR门：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As described in the previous section, the AND, NAND, and OR gates are the same
    in terms of structure for the perceptron and differ only in terms of the values
    of the weight parameters. When implementing the NAND and OR gates, only the values
    of the weights and bias are different from the AND gate.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一部分所述，AND、NAND和OR门在感知器的结构上是相同的，区别仅在于权重参数的值。在实现NAND和OR门时，唯一区别就是权重和偏置的值与AND门不同。
- en: Limitations of Perceptrons
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 感知器的局限性
- en: As described so far, we can use a perceptron to implement AND, NAND, and OR
    logic gates. In this next section, you will consider an XOR gate.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以使用感知器来实现AND、NAND和OR逻辑门。在接下来的部分，你将考虑如何实现XOR门。
- en: XOR Gate
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: XOR门
- en: An XOR gate is a gate circuit that is also called an *exclusive OR*. As shown
    in *Figure 2.5*, the output is 1 when either *x*1 or *x*2 is 1 ("exclusive" means
    "limited to only one person"). What should be the value of the weights to realize
    the XOR gate by using a perceptron?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: XOR门是一种门电路，也叫做*异或*门。如图2.5所示，当*x*1或*x*2其中之一为1时，输出为1（“exclusive”意味着“仅限于一个”）。为了利用感知器实现XOR门，权重应该取什么值呢？
- en: '![Figure 2.5: Truth table of an XOR gate'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.5：XOR门的真值表'
- en: '](img/fig02_5.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_5.jpg)'
- en: 'Figure 2.5: Truth table of an XOR gate'
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.5：XOR门的真值表
- en: In fact, we cannot build this XOR gate by using the perceptron that we have
    learned about so far. Why can we not build XOR even though we can build AND and
    OR gates?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，利用我们目前所学的感知器，无法构建这个XOR门。那么，为什么我们可以构建AND门和OR门，却不能构建XOR门呢？
- en: 'First, let''s examine the behavior of an OR gate visually. An OR gate satisfies
    the truth table in *Figure 2.5* when the weight parameters are (*b*, *w*1, *w*2)
    = (-0.5, 1.0, 1.0), for example. In this case, the perceptron is represented by
    equation (2.3):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们通过视觉方式检查OR门的行为。例如，当权重参数为(*b*, *w*1, *w*2) = (-0.5, 1.0, 1.0)时，OR门符合图2.5中的真值表。在这种情况下，感知器由公式(2.3)表示：
- en: '| ![3](img/Firgure_2.5a.png) | (2.3) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| ![3](img/Firgure_2.5a.png) | (2.3) |'
- en: 'The perceptron represented by equation (2.3) generates two areas that are divided
    by the straight line -0.5 + *x*1 + *x*2 = 0\. One of the areas divided by the
    straight line outputs 1, while the other outputs 0\. *Figure 2.6* shows this graphically:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由公式(2.3)表示的感知器生成了两个由直线-0.5 + *x*1 + *x*2 = 0分隔的区域。直线分隔出的一个区域输出1，另一个区域输出0。图2.6直观地展示了这一点：
- en: '![Figure 2.6: Visualizing a perceptron – the perceptron outputs 0 in the gray
    area, which satisfies the characteristics of an OR gate'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.6：可视化感知器——感知器在灰色区域输出0，这符合OR门的特性'
- en: '](img/fig02_6.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_6.jpg)'
- en: 'Figure 2.6: Visualizing a perceptron – the perceptron outputs 0 in the gray
    area, which satisfies the characteristics of an OR gate'
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.6：可视化感知器——感知器在灰色区域输出0，这符合OR门的特性
- en: An OR gate outputs 0 when (*x*1, *x*2) = (0, 0) and outputs 1 when (*x*1, *x*2)
    = (0, 1), (1, 0), and (1, 1). Here, a circle indicates 0, and a triangle indicates
    1\. To create an OR gate, we must divide between circles and triangles with a
    straight line. The straight line can actually divide four points correctly.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: OR门在(*x*1, *x*2) = (0, 0)时输出0，在(*x*1, *x*2) = (0, 1)、(1, 0)、(1, 1)时输出1。这里，圆圈表示0，三角形表示1。要创建一个OR门，我们必须用一条直线将圆圈和三角形分开。这条直线实际上可以正确地分割四个点。
- en: So, how about the case of an XOR gate? Can we create areas that divide between
    circles and triangles with a straight line, as in the case of an OR gate?
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，XOR门的情况如何呢？我们能像在OR门的情况下那样，用一条直线将圆圈和三角形分开吗？
- en: '![Figure 2.7: Circles and triangles indicate the outputs of an XOR gate.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.7：圆圈和三角形表示XOR门的输出。'
- en: '](img/fig02_7.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_7.jpg)'
- en: 'Figure 2.7: Circles and triangles indicate the outputs of an XOR gate.'
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.7：圆圈和三角形表示XOR门的输出。
- en: However hard you may be trying to solve this, you cannot divide between circles
    and triangles with a straight line. One straight line cannot divide them.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你多么努力地解决这个问题，你都无法用一条直线将圆圈和三角形分开。一条直线无法将它们分开。
- en: Linear and Nonlinear
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性与非线性
- en: You cannot divide between circles and triangles with a straight line. However,
    you can divide them if you can remove the restriction of a "straight line." For
    example, you can create the areas that divide between circles and triangles, as
    shown in *Figure 2.8*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你不能用一条直线将圆圈和三角形分开。然而，如果你能够去掉“直线”这一限制，就能做到分开。例如，你可以创建将圆圈和三角形分开的区域，如*图2.8*所示。
- en: 'The limit of a perceptron is that it can only represent the areas divided by
    a straight line. It cannot represent a curve, as shown in *Figure 2.8*. The areas
    divided by a curve in *Figure 2.8* are called *nonlinear* areas, while those divided
    by a straight line are called *linear* areas. The words *linear* and *nonlinear*
    are often used in machine learning. You can visualize them with *Figures 2.6*
    and *2.8*:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机的局限性在于它只能表示由直线分割的区域。它不能表示曲线，如*图2.8*所示。在*图2.8*中，由曲线分割的区域被称为*非线性*区域，而由直线分割的区域被称为*线性*区域。*线性*和*非线性*这两个词在机器学习中常常使用。你可以通过*图2.6*和*图2.8*来可视化它们：
- en: '![Figure 2.8: A curve can divide between circles and triangles'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.8：曲线可以将圆圈和三角形分开'
- en: '](img/fig02_8.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_8.jpg)'
- en: 'Figure 2.8: A curve can divide between circles and triangles'
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.8：曲线可以将圆圈和三角形分开
- en: Multilayer Perceptrons
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多层感知机
- en: Unfortunately, we cannot use a perceptron to represent an XOR gate. However,
    this is not terrible news. Actually, the merit of a perceptron lies in the fact
    that multiple layers of perceptrons can be stacked (the outline of this section
    is that multiple layers can represent XOR). We will look at the stacking layers
    later. Here, we can consider the problem of the XOR gate from another viewpoint.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们无法使用感知机表示XOR门。然而，这并不是什么坏消息。实际上，感知机的优点在于可以堆叠多个感知机层（本节的重点是多个层可以表示XOR）。稍后我们会讨论堆叠层的问题。在这里，我们可以从另一个角度考虑XOR门的问题。
- en: Combining the Existing Gates
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组合现有的门
- en: There are some methods we can follow to make an XOR gate. One of them is to
    combine the AND, NAND, and OR gates that we have created so far and wire them.
    Here, the AND, NAND, and OR gates are shown with symbols in *Figure 2.9*. The
    circle at the tip of the NAND gate in *Figure 2.9* indicates that an output has
    been reversed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取一些方法来制作XOR门。其中一种方法是将我们迄今为止创建的AND、NAND和OR门组合起来并接线。在这里，AND、NAND和OR门用*图2.9*中的符号表示。*图2.9*中NAND门顶端的圆圈表示输出已被反转。
- en: '![Figure 2.9: Symbols of the AND, NAND, and OR gates'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.9：AND、NAND和OR门的符号'
- en: '](img/fig02_9.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_9.jpg)'
- en: 'Figure 2.9: Symbols of the AND, NAND, and OR gates'
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.9：AND、NAND和OR门的符号
- en: 'Now, let''s think about how we can wire AND, NAND, and OR to create an XOR
    gate. Note that you can assign AND, NAND, or OR to each of the *?* symbols in
    *Figure 2.10* to complete an XOR gate:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们思考如何将AND、NAND和OR门接线以创建一个XOR门。请注意，你可以将AND、NAND或OR分别分配给*图2.10*中的每个*?*符号，以完成XOR门：
- en: '![Figure 2.10: Replace the "?" symbols with an AND, NAND, or OR gate to complete
    an XOR gate!'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.10：将“？”符号替换为AND、NAND或OR门，完成XOR门！'
- en: '](img/fig02_10.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_10.jpg)'
- en: 'Figure 2.10: Replace the "?" symbols with an AND, NAND, or OR gate to complete
    an XOR gate!'
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.10：将“？”符号替换为AND、NAND或OR门，完成XOR门！
- en: To be specific, the limitation of a perceptron described in the previous section
    is that a single layer of a perceptron cannot represent an XOR gate or divide
    nonlinear areas. Here, we will see that an XOR gate can be built by combining
    perceptrons (i.e., stacking layers).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，上一节中描述的感知器的限制是单层感知器无法表示 XOR 门或划分非线性区域。在这里，我们将看到通过组合感知器（即堆叠层）可以构建 XOR 门。
- en: 'The wiring in *Figure 2.11* can build an XOR gate. Here, *x*1 and *x*2 indicate
    input signals, while *y* indicates an output signal. *x*1 and *x*2 are the inputs
    to the NAND and OR gates, and the outputs of the NAND and OR gates are the inputs
    to the AND gate:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.11* 中的接线可以构建一个 XOR 门。这里，*x*1 和 *x*2 表示输入信号，而 *y* 表示输出信号。*x*1 和 *x*2 是
    NAND 和 OR 门的输入，而 NAND 和 OR 门的输出是 AND 门的输入：'
- en: '![Figure 2.11: A combination of the AND, NAND, and OR gates constructs an XOR
    gate'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.11：AND、NAND 和 OR 门的组合构建了一个 XOR 门'
- en: '](img/fig02_11.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_11.jpg)'
- en: 'Figure 2.11: A combination of the AND, NAND, and OR gates constructs an XOR
    gate'
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.11：AND、NAND 和 OR 门的组合构建了一个 XOR 门
- en: 'Let''s check that the wiring in *Figure 2.11* can really form an XOR gate.
    Assuming that the output of the NAND is *s*1 and that of the OR is *s*2, we will
    complete the truth table. *Figure 2.12* shows the results. When we look at *x*1,
    *x*2, and *y*, we can see that they represent the outputs of the XOR:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下*图 2.11*中的接线是否真的能够形成一个 XOR 门。假设 NAND 的输出是 *s*1，OR 的输出是 *s*2，我们将完成真值表。*图
    2.12* 显示了结果。当我们查看 *x*1、*x*2 和 *y* 时，可以看到它们代表了 XOR 的输出：
- en: '![Figure 2.12: Truth table of an XOR gate'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.12：XOR 门的真值表'
- en: '](img/fig02_12.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_12.jpg)'
- en: 'Figure 2.12: Truth table of an XOR gate'
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.12：XOR 门的真值表
- en: Implementing an XOR Gate
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现 XOR 门
- en: 'Now, we will use Python to implement the XOR gate represented by the wiring
    in *Figure 2.11*. By using the AND, NAND, and OR functions that we defined previously,
    we can implement this as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 Python 实现 *图 2.11* 中接线表示的 XOR 门。通过使用我们之前定义的 AND、NAND 和 OR 函数，我们可以如下实现：
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The XOR function outputs the results as expected:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: XOR 函数按预期输出结果：
- en: '[PRE6]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, we can build an XOR gate. After doing this, we will represent the XOR that
    we have just implemented with perceptrons (by showing neurons explicitly). *Figure
    2.13* shows this representation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以构建一个 XOR 门。完成后，我们将通过感知器（明确显示神经元）表示我们刚刚实现的 XOR。*图 2.13* 显示了这种表示。
- en: An XOR is a multilayer network, as shown in *Figure 2.13.* Here, we will call
    the leftmost column `Layer 0`, the next `Layer 1`, and the rightmost `Layer 2`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: XOR 是一个多层网络，如 *图 2.13* 所示。在这里，我们将称最左边一列为 `层 0`，接下来为 `层 1`，最右边为 `层 2`。
- en: 'The perceptron in *Figure 2.13* differs in shape from the AND and OR perceptrons
    we have looked at so far (*Figure 2.1*). The AND and OR perceptrons are single-layer,
    while the XOR perceptron is two-layer. A perceptron with multiple layers is sometimes
    called a **multilayered perceptron**:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.13* 中的感知器形状与我们之前看到的 AND 和 OR 感知器有所不同（*图 2.1*）。AND 和 OR 感知器是单层的，而 XOR 感知器是两层的。具有多层的感知器有时被称为**多层感知器**：'
- en: '![Figure 2.13: Representation of an XOR by perceptrons'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.13：感知器表示的 XOR'
- en: '](img/fig02_13.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig02_13.jpg)'
- en: 'Figure 2.13: Representation of an XOR by perceptrons'
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.13：感知器表示的 XOR
- en: Note
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注释
- en: Although the perceptron in *Figure 2.13* consists of three layers, we will call
    it a "two-layer perceptron" because only the two layers (between layers 0 and
    1 and between layers 1 and 2) have weight. Some literature calls the perceptron
    in *Figure 2.13* a "three-layer perceptron" because it consists of three layers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 *图 2.13* 中的感知器由三层组成，但我们将其称为“二层感知器”，因为只有两层（层 0 和层 1 之间、层 1 和层 2 之间）有权重。一些文献将
    *图 2.13* 中的感知器称为“三层感知器”，因为它由三层组成。
- en: 'A two-layer perceptron, as shown in *Figure 2.13*, sends and receives signals
    between the neurons in layers 0 and 1 and then between layers 1 and 2\. The following
    describes this behavior in more detail:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 2.13* 所示，二层感知器在层 0 和层 1 之间以及层 1 和层 2 之间传递信号。以下将更详细地描述这种行为：
- en: Two neurons in layer 0 receive input signals and send signals to the neurons
    in layer 1.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 层 0 中的两个神经元接收输入信号并将信号传递给层 1 中的神经元。
- en: The neurons in layer 1 send signals to the neuron in layer 2, which outputs
    y.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 层 1 中的神经元将信号传递给层 2 中的神经元，层 2 的神经元输出 y。
- en: The behavior of this two-layer perceptron can be compared to an assembly through
    a pipeline. The worker on the first level (or first layer) works on the "component"
    that arrives and passes it to the worker on the second level (the second layer)
    when the task is finished. The worker in the second layer works on the "component"
    that was received from the worker in the first layer to complete and ship (output)
    it.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个两层感知机的行为可以与通过管道的组装过程进行比较。第一层（或第一层的工作者）处理到达的“组件”，并在完成任务后将其传递给第二层（第二层的工作者）。第二层的工作者处理从第一层工作者接收到的“组件”，完成并输出（交付）它。
- en: Thus, the perceptrons in an XOR gate "pass components" between workers. This
    two-layer structure enables perceptrons to build an XOR gate. This can be interpreted
    as "what cannot be achieved with a single-layer perceptron can be achieved by
    adding one layer." Perceptrons can provide a more flexible representation by stacking
    layers (deepening layers).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，XOR 门中的感知机会在工作者之间“传递组件”。这种两层结构使得感知机能够构建 XOR 门。这可以解释为“单层感知机无法实现的事情，可以通过添加一层来实现”。通过堆叠层（加深层数），感知机能够提供更灵活的表示。
- en: From NAND to a Computer
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 NAND 到计算机
- en: Multilayer perceptrons can create more complicated circuits than those we have
    examined so far. For example, an adder circuit that add numbers can be created
    with perceptrons. An encoder that converts a binary number into a decimal number
    and a circuit that outputs 1 when certain conditions are met (circuit for parity
    checks) can be represented with perceptrons. As a matter of fact, we can even
    use perceptrons to represent a computer.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知机可以创建比我们到目前为止所研究的电路更复杂的电路。例如，一个能够加法运算的加法器电路可以通过感知机来创建。一个将二进制数转换为十进制数的编码器，以及一个在满足特定条件时输出
    1 的电路（奇偶校验电路）也可以通过感知机来表示。事实上，我们甚至可以用感知机来表示一个计算机。
- en: A computer is a machine that processes information. When it receives input,
    a computer processes it in a certain way and outputs the result. Processing in
    a certain way means that both a computer and a perceptron have inputs and outputs
    and calculate them based on fixed rules.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机是一种处理信息的机器。当它接收到输入时，计算机会以某种方式处理这些输入并输出结果。以某种方式处理意味着计算机和感知机都有输入和输出，并根据固定的规则对其进行计算。
- en: Although it seems that a computer conducts very complicated processes inside
    it, in fact (surprisingly), a combination of NAND gates can reproduce what a computer
    does. The surprising fact that NAND gates are all we need to create a computer
    means that perceptrons can also represent a computer because a NAND gate can itself
    be made with perceptrons. Simply put, if we can create a computer by combining
    NAND gates, we can also represent one by combining only perceptrons (a combination
    of perceptrons can be represented as one multilayer perceptron).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看起来计算机内部执行的是非常复杂的过程，但实际上（令人惊讶的是），一组 NAND 门就可以复现计算机的功能。令人惊讶的事实是，NAND 门是构建计算机所需的全部元件，这意味着感知机也可以代表一个计算机，因为
    NAND 门本身就可以用感知机来构造。简而言之，如果我们可以通过组合 NAND 门来创建一个计算机，那么我们也可以通过仅仅组合感知机来表示一个计算机（感知机的组合可以表示为一个多层感知机）。
- en: Note
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注释
- en: 'You may find it hard to believe that a combination of NAND gates can create
    a computer. If you are interested in this topic, *The Elements of Computing Systems:
    Building a Modern Computer from First Principles* (The MIT Press) is recommended.
    This book aims to understand computers deeply. Under the motto "From NANDs to
    Tetris," it uses NANDs to create a computer that runs Tetris. If you read this
    book, you will realize that computers can be created from simple elements—that
    is, NANDs.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会觉得很难相信一组 NAND 门可以创建一个计算机。如果你对这个话题感兴趣，推荐阅读《计算机系统的元素：从基本原理构建现代计算机》（MIT出版社）。这本书旨在深入理解计算机。在“从
    NAND 到俄罗斯方块”的口号下，它通过 NAND 门创建一个能够运行俄罗斯方块的计算机。如果你阅读这本书，你会意识到计算机是可以由简单的元素——也就是 NAND
    门构建的。
- en: Thus, multilayer perceptrons can achieve as complicated a representation as
    creating a computer. So, what perceptron structure can represent a computer? How
    many layers are needed to create a computer?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，多层感知机能够实现像构建计算机一样复杂的表示。那么，哪种感知机结构可以表示一个计算机呢？构建一个计算机需要多少层呢？
- en: The answer is that, theoretically, a computer can be created with two-layer
    perceptrons. It has been proven that any function can be represented with two-layer
    perceptrons (to be accurate, when an activation function is a nonlinear sigmoid
    function – refer to the next chapter for details). However, it will be a very
    laborious job to create a computer by specifying the appropriate weights in a
    structure of two-layer perceptrons. Actually, to start from low-level components
    such as NANDs to create a computer, creating the required components (modules)
    step by step is natural—starting from AND and OR gates and proceeding to half
    adders and full adders, **arithmetic and logic units** (**ALUs**), and a CPU.
    Therefore, creating a structure of many layers is a natural way when representing
    a computer with perceptrons.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是，理论上，计算机可以通过两层感知机来创建。已经证明，任何函数都可以通过两层感知机来表示（准确地说，当激活函数是非线性的 Sigmoid 函数时——具体细节见下一章）。然而，通过指定合适的权重来在两层感知机结构中创建计算机将是一项非常繁重的工作。实际上，从低级组件（如
    NAND 门）开始创建计算机，逐步创建所需的组件（模块）是很自然的——从与门（AND）和或门（OR）开始，进而到半加器和全加器，**算术逻辑单元**（**ALU**），以及中央处理器（CPU）。因此，使用感知机表示计算机时，创建多层结构是很自然的方式。
- en: Although we will not create a computer in this book, please keep in mind that
    multilayer perceptrons enable nonlinear representations and that they can, in
    principle, represent what a computer does.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本书中我们不会创建计算机，但请记住，多层感知机能够实现非线性表示，并且原则上它们能够表示计算机所做的事情。
- en: Summary
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小结
- en: 'In this chapter, we covered perceptrons. The perceptron is a very simple algorithm,
    so you should be able to understand how it works quickly. The perceptron is the
    basis of a neural network, which we will learn about in the next chapter. These
    points may be summed up in the following list:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们讲解了感知机。感知机是一个非常简单的算法，你应该能够很快理解它的工作原理。感知机是神经网络的基础，下一章我们将学习神经网络。这些要点可以总结为以下列表：
- en: A perceptron is an algorithm with inputs and outputs. When it receives a certain
    input, it outputs a fixed value.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知机是一种具有输入和输出的算法。当它接收到某个输入时，会输出一个固定值。
- en: A perceptron has "weight" and "bias" parameters.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知机有“权重”和“偏置”参数。
- en: You can use perceptrons to represent logic circuits such as AND and OR gates.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用感知机表示诸如与门（AND）和或门（OR）这样的逻辑电路。
- en: An XOR gate cannot be represented with a single-layer perceptron.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XOR 门不能通过单层感知机表示。
- en: A two-layer perceptron can be used to represent an XOR gate.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两层感知机可以用来表示 XOR 门。
- en: A single-layer perceptron can only represent linear areas, while a multilayer
    perceptron can represent nonlinear areas.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单层感知机只能表示线性区域，而多层感知机可以表示非线性区域。
- en: Multilayer perceptrons can represent a computer (theoretically).
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多层感知机理论上可以表示计算机。
