- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Playing with Grammar
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 撒播语法
- en: Grammar is one of the main building blocks of language. Each human language,
    and programming language for that matter, has a set of rules that every person
    speaking it must follow, otherwise risking not being understood. These grammatical
    rules can be uncovered using NLP and are useful for extracting data from sentences.
    For example, using information about the grammatical structure of text, we can
    parse out subjects, objects, and relations between different entities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 语法是语言的主要构建块之一。每种人类语言，以及编程语言，都有一个规则集，每个使用它的人都必须遵守，否则可能会不被理解。这些语法规则可以通过NLP揭示，并且对于从句子中提取数据很有用。例如，使用关于文本语法结构的信息，我们可以解析出主语、宾语以及不同实体之间的关系。
- en: 'In this chapter, you will learn how to use different packages to reveal the
    grammatical structure of words and sentences, as well as extract certain parts
    of sentences. These are the topics covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何使用不同的包来揭示单词和句子的语法结构，以及提取句子的某些部分。本章涵盖以下主题：
- en: Counting nouns – plural and singular nouns
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计数名词——复数和单数名词
- en: Getting the dependency parse
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取依存句法分析
- en: Extracting noun chunks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取名词短语
- en: Extracting the subjects and objects of the sentence
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取句子的主语和宾语
- en: Finding patterns in text using grammatical information
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用语法信息在文本中寻找模式
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Please follow the installation requirements given in [*Chapter 1*](B18411_01.xhtml#_idTextAnchor013)
    to run the notebooks in this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照[*第1章*](B18411_01.xhtml#_idTextAnchor013)中给出的安装要求运行本章中的笔记本。
- en: Counting nouns – plural and singular nouns
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计数名词——复数和单数名词
- en: 'In this recipe, we will do two things: determine whether a noun is plural or
    singular and turn plural nouns into singular, and vice versa.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将做两件事：确定一个名词是复数还是单数，并将复数名词转换为单数，反之亦然。
- en: You might need these two things for a variety of tasks. For example, you might
    want to count the word statistics, and for that, you most likely need to count
    the singular and plural nouns together. In order to count the plural nouns together
    with singular ones, you need a way to recognize that a word is plural or singular.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要这两样东西来完成各种任务。例如，你可能想要统计单词统计信息，为此，你很可能需要一起计算单数和复数名词。为了将复数名词与单数名词一起计数，你需要一种方法来识别一个单词是复数还是单数。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To determine whether a noun is singular or plural, we will use `spaCy` via
    two different methods: by looking at the difference between the lemma and the
    actual word and by looking at the `morph` attribute. To inflect these nouns, or
    turn singular nouns into plural or vice versa we will use the `textblob` package.
    We will also see how to determine the noun’s number using GPT-3 through the OpenAI
    API. The code for this section is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/Chapter02).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定一个名词是单数还是复数，我们将通过两种不同的方法使用`spaCy`：通过查看词元和实际单词之间的差异，以及通过查看`morph`属性。为了屈折这些名词，或将单数名词转换为复数或反之亦然，我们将使用`textblob`包。我们还将了解如何通过OpenAI
    API使用GPT-3确定名词的数量。本节代码位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/Chapter02)。
- en: How to do it…
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We will first use `spaCy`’s lemma information to infer whether a noun is singular
    or plural. Then, we will use the `morph` attribute of `Token` objects. We will
    then create a function that uses one of those methods. Finally, we will use GPT-3.5
    to find out the number of nouns:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用`spaCy`的词元信息来推断一个名词是单数还是复数。然后，我们将使用`Token`对象的`morph`属性。然后，我们将创建一个函数，使用这些方法之一。最后，我们将使用GPT-3.5来确定名词的数量：
- en: 'Run the code in the file and language utility notebooks. If you run into an
    error saying that the small or large models do not exist, you need to open the
    **lang_utils.ipynb** file, uncomment, and run the statement that downloads the
    model:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件和语言实用工具笔记本中的代码。如果你遇到一个错误，说小或大模型不存在，你需要打开**lang_utils.ipynb**文件，取消注释，并运行下载模型的语句：
- en: '[PRE0]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Initialize the **text** variable and process it using the **spaCy** small model
    to get the resulting **Doc** object:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化**text**变量，并使用**spaCy**小型模型进行处理，以获取结果**Doc**对象：
- en: '[PRE1]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this step, we loop through the **Doc** object. For each token in the object,
    we check whether it’s a noun and whether the lemma is the same as the word itself.
    Since the lemma is the basic form of the word, if the lemma is different from
    the word, that token is plural:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们遍历 **Doc** 对象。对于对象中的每个标记，我们检查它是否是名词，以及词元是否与单词本身相同。由于词元是单词的基本形式，如果词元与单词不同，则该标记是复数：
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The result should be as follows:'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的：
- en: '[PRE3]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we will check the number of a noun using a different method: the **morph**
    features of a **Token** object. The **morph** features are the morphological features
    of a word, such as number, case, and so on. Since we know that token **3** is
    a noun, we directly access the **morph** features and get the **Number** to get
    the same result as previously:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用不同的方法来检查名词的数量：**Token** 对象的 **morph** 特征。**morph** 特征是单词的形态学特征，如数量、格等。由于我们知道标记
    **3** 是一个名词，我们直接访问 **morph** 特征并获取 **Number** 以获得之前相同的结果：
- en: '[PRE4]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is the result:'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是结果：
- en: '[PRE5]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this step, we prepare to define a function that returns a tuple, **(noun,
    number)**. In order to better encode the noun number, we use an **Enum** class
    that assigns numbers to different values. We assign **1** to singular and **2**
    to plural. Once we create the class, we can directly refer to the noun number
    variables as **Noun_number.SINGULAR** and **Noun_number.PLURAL**:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们准备定义一个返回元组 **(noun, number)** 的函数。为了更好地编码名词数量，我们使用一个 **Enum** 类，将不同的值分配给数字。我们将
    **1** 分配给单数，将 **2** 分配给复数。一旦创建了这个类，我们就可以直接引用名词数量变量为 **Noun_number.SINGULAR** 和
    **Noun_number.PLURAL**：
- en: '[PRE6]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this step, we define the function. It takes as input the text, the **spaCy**
    model, and the method of determining the noun number. The two methods are **lemma**
    and **morph**, the same two methods we used in *steps 3* and *4*, respectively.
    The function outputs a list of tuples, each of the format **(<noun text>, <noun
    number>)**, where the noun number is expressed using the **Noun_number** class
    defined in *step 5*:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们定义了一个函数。该函数接受文本、**spaCy** 模型以及确定名词数量的方法作为输入。这两种方法是 **lemma** 和 **morph**，分别与我们之前在
    *步骤 3* 和 *步骤 4* 中使用的相同两种方法。该函数输出一个元组列表，每个元组的格式为 **(名词文本, 名词数量**)，其中名词数量使用在 *步骤
    5* 中定义的 **Noun_number** 类表示：
- en: '[PRE7]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can use the preceding function and see its performance with different **spaCy**
    models. In this step, we use the small **spaCy** model with the function we just
    defined. Using both methods, we see that the **spaCy** model gets the number of
    the irregular noun **geese** incorrectly:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用前面的函数并查看它在不同的 **spaCy** 模型上的性能。在这一步，我们使用我们刚刚定义的函数和小的 **spaCy** 模型。使用两种方法，我们看到
    **spaCy** 模型错误地获取了不规则名词 **geese** 的数量：
- en: '[PRE8]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The result should be as follows:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的：
- en: '[PRE9]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, let’s do the same using the large model. If you have not yet downloaded
    the large model, do so by running the first line. Otherwise, you can comment it
    out. Here, we see that although the **morph** method still incorrectly assigns
    singular to **geese**, the **lemma** method provides the correct answer:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用大型模型做同样的事情。如果您尚未下载大型模型，请通过运行第一行来下载。否则，您可以将其注释掉。在这里，我们看到尽管 **morph**
    方法仍然错误地将 **geese** 分配为单数，但 **lemma** 方法提供了正确的答案：
- en: '[PRE10]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The result should be as follows:'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的：
- en: '[PRE11]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s now use GPT-3.5 to get the noun number. In the results, we see that GPT-3.5
    gives us an identical result and correctly identifies both the number for **geese**
    and the number for **road**:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用 GPT-3.5 来获取名词数量。在结果中，我们看到 GPT-3.5 给出了相同的结果，并且正确地识别了 **geese** 和 **road**
    的数量：
- en: '[PRE12]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The result should be as follows:'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的：
- en: '[PRE13]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: There’s more…
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'We can also change the nouns from plural to singular, and vice versa. We will
    use the `textblob` package for that. The package should be installed automatically
    via the Poetry environment:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将名词从复数变为单数，反之亦然。我们将使用 `textblob` 包来完成这项工作。该包应通过 Poetry 环境自动安装：
- en: 'Import the **TextBlob** class from the package:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从包中导入 **TextBlob** 类：
- en: '[PRE14]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Initialize a list of text variables and process them using the **TextBlob**
    class via a list comprehension:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个文本变量列表，并通过列表推导式使用 **TextBlob** 类进行处理：
- en: '[PRE15]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Use the **pluralize** function of the object to get the plural. This function
    returns a list and we access its first element. Print the result:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用对象的 **pluralize** 函数来获取复数。此函数返回一个列表，我们访问其第一个元素。打印结果：
- en: '[PRE16]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The result should be as follows:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的：
- en: '[PRE17]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we will do the reverse. We use the preceding **plurals** list to turn
    the plural nouns into **TextBlob** objects:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将进行相反的操作。我们使用前面的 **复数** 列表将复数名词转换为 **TextBlob** 对象：
- en: '[PRE18]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Turn the nouns into singular using the **singularize** function and print:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **singularize** 函数将名词转换为单数并打印：
- en: '[PRE19]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The result should be the same as the list we started with in *step 2*:'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该与我们在 *步骤 2* 中开始时的列表相同：
- en: '[PRE20]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Getting the dependency parse
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取依存句法分析
- en: A dependency parse is a tool that shows dependencies in a sentence. For example,
    in the sentence *The cat wore a hat*, the root of the sentence is the verb, *wore*,
    and both the subject, *the cat*, and the object, *a hat*, are dependents. The
    dependency parse can be very useful in many NLP tasks since it shows the grammatical
    structure of the sentence, with the subject, the main verb, the object, and so
    on. It can then be used in downstream processing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 依存句法分析是一种显示句子中依存关系的工具。例如，在句子 *The cat wore a hat* 中，句子的根是动词，*wore*，而主语，*the
    cat*，和宾语，*a hat*，都是依存词。依存句法分析在许多 NLP 任务中非常有用，因为它显示了句子的语法结构，包括主语、主要动词、宾语等。然后它可以用于下游处理。
- en: The `spaCy` NLP engine does the dependency parse as part of its overall analysis.
    The dependency parse tags explain the role of each word in the sentence. `ROOT`
    is the main word that all other words depend on, usually the verb.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`spaCy` NLP 引擎将其整体分析的一部分作为依存句法分析。依存句法分析标签解释了句子中每个词的作用。`ROOT` 是所有其他词都依赖的词，通常是动词。'
- en: Getting ready
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: We will use `spaCy` to create the dependency parse. The required packages are
    part of the Poetry environment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `spaCy` 来创建依存句法分析。所需的包是 Poetry 环境的一部分。
- en: How to do it…
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'We will take a few sentences from the `sherlock_holmes1.txt` file to illustrate
    the dependency parse. The steps are as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 `sherlock_holmes1.txt` 文件中选取几句话来展示依存句法分析。步骤如下：
- en: 'Run the file and language utility notebooks:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件和语言实用工具笔记本：
- en: '[PRE21]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Define the sentence we will be parsing:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们将要分析的句子：
- en: '[PRE22]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define a function that will print the word, its grammatical function embedded
    in the **dep_** attribute, and the explanation of that attribute. The **dep_**
    attribute of the **Token** object shows the grammatical function of the word in
    the sentence:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，该函数将打印出词、其嵌入在 **dep_** 属性中的语法功能以及该属性的说明。**Token** 对象的 **dep_** 属性显示了词在句子中的语法功能：
- en: '[PRE23]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, let’s use this function on the first sentence in our list. We can see
    that the verb **heard** is the **ROOT** word of the sentence, with all other words
    depending on it:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将此函数应用于我们列表中的第一句话。我们可以看到动词 **heard** 是句子的 **ROOT** 词，所有其他词都依赖于它：
- en: '[PRE24]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The result should be as follows:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该如下所示：
- en: '[PRE25]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To explore the dependency parse structure, we can use the attributes of the
    **Token** class. Using the **ancestors** and **children** attributes, we can get
    the tokens that this token depends on and the tokens that depend on it, respectively.
    The function to print the ancestors is as follows:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要探索依存句法分析结构，我们可以使用 **Token** 类的属性。使用 **ancestors** 和 **children** 属性，我们可以获取此标记所依赖的标记和依赖于它的标记，分别。打印祖先的函数如下：
- en: '[PRE26]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, let’s use this function on the first sentence in our list:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将此函数应用于我们列表中的第一句话：
- en: '[PRE27]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The output will be as follows. In the result, we see that `heard` has no ancestors
    since it is the main word in the sentence. All other words depend on it, and in
    fact, contain `heard` in their ancestor lists.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示。在结果中，我们看到 `heard` 没有祖先，因为它是在句子中的主要词。所有其他词都依赖于它，实际上，它们的祖先列表中都包含 `heard`。
- en: 'The dependency chain can be seen by following the ancestor links for each word.
    For example, if we look at the word `name`, we see that its ancestors are `under`,
    `mention`, and `heard`. The immediate parent of `name` is `under`, the parent
    of `under` is `mention`, and the parent of `mention` is `heard`. A dependency
    chain will always lead to the root, or the main word, of the sentence:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过跟踪每个词的祖先链接，可以看到依存链。例如，如果我们查看单词 `name`，我们看到它的祖先是 `under`、`mention` 和 `heard`。`name`
    的直接父词是 `under`，`under` 的父词是 `mention`，`mention` 的父词是 `heard`。依存链始终会引导到句子的根，或主要词：
- en: '[PRE28]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To see all the children, use the following function. This function prints out
    each word and the words that depend on it, its **children**:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看所有子词，请使用以下函数。此函数打印出每个词及其依赖于它的词，其 **children**：
- en: '[PRE29]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, let’s use this function on the first sentence in our list:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将此函数应用于我们列表中的第一句话：
- en: '[PRE30]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The result should be as follows. Now, the word `heard` has a list of words
    that depend on it since it is the main word in the sentence:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的。现在，单词 `heard` 有一个依赖它的单词列表，因为它在句子中是主词：
- en: '[PRE31]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can also see left and right children in separate lists. In the following
    function, we print the children as two separate lists, left and right. This can
    be useful when doing grammatical transformations in the sentence:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以在单独的列表中看到左右子节点。在以下函数中，我们将子节点打印为两个单独的列表，左和右。这在进行句子语法转换时可能很有用：
- en: '[PRE32]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let’s use this function on the first sentence in our list:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用这个函数处理我们列表中的第一句话：
- en: '[PRE33]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The result should be as follows:'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的：
- en: '[PRE34]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We can also see the subtree that the token is in by using this function:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以通过使用此函数看到标记所在的子树：
- en: '[PRE35]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let’s use this function on the first sentence in our list:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用这个函数处理我们列表中的第一句话：
- en: '[PRE36]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The result should be as follows. From the subtrees that each word is part of,
    we can see the grammatical phrases that appear in the sentence, such as the `any
    other name`, and the `under any` `other name`:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应该是这样的。从每个单词所属的子树中，我们可以看到句子中出现的语法短语，如 `any other name` 和 `under any other
    name`：
- en: '[PRE37]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: See also
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The dependency parse can be visualized graphically using the `displaCy` package,
    which is part of `spaCy`. Please see [*Chapter*](B18411_08.xhtml#_idTextAnchor205)
    *7*, *Visualizing Text Data*, for a detailed recipe on how to do the visualization.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `displaCy` 包图形化地可视化依存句法，它是 `spaCy` 的一部分。请参阅 [*第7章*](B18411_08.xhtml#_idTextAnchor205)
    *可视化文本数据*，了解如何进行可视化的详细食谱。
- en: Extracting noun chunks
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取名词短语
- en: Noun chunks are known in linguistics as noun phrases. They represent nouns and
    any words that depend on and accompany nouns. For example, in the sentence *The
    big red apple fell on the scared cat*, the noun chunks are *the big red apple*
    and *the scared cat*. Extracting these noun chunks is instrumental to many other
    downstream NLP tasks, such as named entity recognition and processing entities
    and relations between them. In this recipe, we will explore how to extract named
    entities from a text.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在语言学中，名词短语被称为名词短语。它们代表名词以及任何依赖和伴随名词的单词。例如，在句子 *The big red apple fell on the
    scared cat* 中，名词短语是 *the big red apple* 和 *the scared cat*。提取这些名词短语对于许多其他下游自然语言处理任务至关重要，例如命名实体识别以及处理实体及其关系。在本食谱中，我们将探讨如何从文本中提取命名实体。
- en: Getting ready
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the `spaCy` package, which has a function for extracting noun chunks,
    and the text from the `sherlock_holmes_1.txt` file as an example.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `spaCy` 包，它有一个用于提取名词短语的函数，以及 `sherlock_holmes_1.txt` 文件中的文本作为示例。
- en: How to do it…
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Use the following steps to get the noun chunks from a text:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下步骤从文本中获取名词短语：
- en: 'Run the file and language utility notebooks:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件和语言实用工具笔记本：
- en: '[PRE38]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Define the function that will print out the noun chunks. The noun chunks are
    contained in the **doc.noun_chunks** class variable:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，该函数将打印出名词短语。名词短语包含在 **doc.noun_chunks** 类变量中：
- en: '[PRE39]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Read the text from the **sherlock_holmes_1.txt** file and use the function
    on the resulting text:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 **sherlock_holmes_1.txt** 文件中读取文本并使用该函数处理结果文本：
- en: '[PRE40]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This is the partial result. See the output of the notebook at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter02/noun_chunks_2.3.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter02/noun_chunks_2.3.ipynb)
    for the full printout. The function gets the pronouns, nouns, and noun phrases
    that are in the text correctly:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是部分结果。请参阅笔记本的输出[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter02/noun_chunks_2.3.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter02/noun_chunks_2.3.ipynb)，以获取完整打印输出。该函数正确地获取了文本中的代词、名词和名词短语：
- en: '[PRE41]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: There’s more…
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容…
- en: Noun chunks are `spaCy` `Span` objects and have all their properties. See the
    official documentation at [https://spacy.io/api/token](https://spacy.io/api/token).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 名词短语是 `spaCy` `Span` 对象，并具有所有属性。请参阅官方文档[https://spacy.io/api/token](https://spacy.io/api/token)。
- en: 'Let’s explore some properties of noun chunks:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索名词短语的一些属性：
- en: 'We will define a function that will print out the different properties of noun
    chunks. It will print the text of the noun chunk, its start and end indices within
    the **Doc** object, the sentence it belongs to (useful when there is more than
    one sentence), the root of the noun chunk (its main word), and the chunk’s similarity
    to the word **emotions**. Finally, it will print out the similarity of the whole
    input sentence to **emotions**:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将定义一个函数，该函数将打印出名词短语的不同属性。它将打印出名词短语的文本，它在 **Doc** 对象中的起始和结束索引，它所属的句子（当有多个句子时很有用），名词短语的根（其主要单词），以及该短语与单词
    **emotions** 的相似度。最后，它将打印出整个输入句子与 **emotions** 的相似度：
- en: '[PRE42]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Set the sentence to **All emotions, and that one particularly, were abhorrent
    to his cold, precise but admirably** **balanced mind**:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将句子设置为 **All emotions, and that one particularly, were abhorrent to his cold,
    precise but admirably** **balanced mind**：
- en: '[PRE43]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Use the **explore_properties** function on the sentence using the small model:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用小模型上的 **explore_properties** 函数：
- en: '[PRE44]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This is the result:'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE45]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You will also see a warning message similar to this one due to the fact that
    the small model does not ship with word vectors of its own:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还会看到类似这样的警告消息，因为小模型没有自己的词向量：
- en: '[PRE46]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now, let’s apply the same function to the same sentence with the large model:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将相同的函数应用于使用大型模型的同一句子：
- en: '[PRE47]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The large model does come with its own word vectors and does not result in
    a warning:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大型模型确实包含自己的词向量，不会产生警告：
- en: '[PRE48]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We see that the similarity of the `All emotions` noun chunk is high in relation
    to the word `emotions`, as compared to the similarity of the `his cold, precise
    but admirably balanced mind` noun chunk.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们看到，与 `his cold, precise but admirably balanced mind` 这个名词短语相比，`All emotions`
    这个名词短语与单词 `emotions` 的相似度较高。
- en: Important note
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: A larger **spaCy** model, such as **en_core_web_lg**, takes up more space but
    is more precise.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更大的 **spaCy** 模型，如 **en_core_web_lg**，占用更多空间但更精确。
- en: See also
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The topic of semantic similarity will be explored in more detail in [*Chapter
    3*](B18411_03.xhtml#_idTextAnchor067).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 语义相似性的主题将在 [*第3章*](B18411_03.xhtml#_idTextAnchor067) 中更详细地探讨。
- en: Extracting subjects and objects of the sentence
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取句子的主语和宾语
- en: Sometimes, we might need to find the subject and direct objects of the sentence,
    and that is easily accomplished with the `spaCy` package.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能需要找到句子的主语和直接宾语，而使用 `spaCy` 包件可以轻松完成。
- en: Getting ready
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will be using the dependency tags from `spaCy` to find subjects and objects.
    The code uses the `spaCy` engine to parse the sentence. Then, the subject function
    loops through the tokens, and if the dependency tag contains `subj`, it returns
    that token’s subtree, a `Span` object. There are different subject tags, including
    `nsubj` for regular subjects and `nsubjpass` for subjects of passive sentences,
    thus we want to look for both.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `spaCy` 的依赖标签来查找主语和宾语。代码使用 `spaCy` 引擎解析句子。然后，主语函数遍历标记，如果依赖标签包含 `subj`，则返回该标记的子树，一个
    `Span` 对象。存在不同的主语标签，包括 `nsubj` 用于普通主语和 `nsubjpass` 用于被动句的主语，因此我们希望寻找两者。
- en: How to do it…
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We will use the `subtree` attribute of tokens to find the complete noun chunk
    that is the subject or direct object of the verb (see the *Getting the dependency
    parse* recipe). We will define functions to find the subject, direct object, dative
    phrase, and prepositional phrases:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用标记的 `subtree` 属性来找到完整的名词短语，它是动词的主语或直接宾语（参见 *获取依赖分析* 菜谱）。我们将定义函数来查找主语、直接宾语、宾语从句和介词短语：
- en: 'Run the file and language utility notebooks:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件和语言实用工具笔记本：
- en: '[PRE49]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We will use two functions to find the subject and the direct object of the
    sentence. These functions will loop through the tokens and return the subtree
    that contains the token with **subj** or **dobj** in the dependency tag, respectively.
    Here is the subject function. It looks for the token that has a dependency tag
    that contains **subj** and then returns the subtree that contains that token.
    There are several subject dependency tags, including **nsubj** and **nsubjpass**
    (for the subject of a passive sentence), so we look for the most general pattern:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用两个函数来找到句子的主语和直接宾语。这些函数将遍历标记并分别返回包含 **subj** 或 **dobj** 依赖标签的标记的子树。以下是主语函数。它寻找具有包含
    **subj** 依赖标签的标记，然后返回包含该标记的子树。存在几个主语依赖标签，包括 **nsubj** 和 **nsubjpass**（被动句的主语），因此我们寻找最一般的模式：
- en: '[PRE50]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Here is the direct object function. It works similarly to **get_subject_phrase**
    but looks for the **dobj** dependency tag instead of a tag that contains **subj**.
    If the sentence does not have a direct object, it will return **None**:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里是直接宾语函数。它的工作方式与**get_subject_phrase**类似，但寻找的是**dobj**依赖标签，而不是包含**subj**的标签。如果句子没有直接宾语，它将返回**None**：
- en: '[PRE51]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Assign a list of sentences to a variable, loop through them, and use the preceding
    functions to print out their subjects and objects:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将句子列表分配给一个变量，遍历它们，并使用前面的函数打印出它们的主题和宾语：
- en: '[PRE52]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The result will be as follows. Since the first sentence does not have a direct
    object, `None` is printed out. For the sentence `The big black cat stared at the
    small dog`, the subject is `the big black cat` and there is no direct object (`the
    small dog` is the object of the preposition `at`). For the sentence `Jane watched
    her brother in the evenings`, the subject is `Jane` and the direct object is `her
    brother`. In the sentence `Laura gave Sam a very interesting book`, the subject
    is `Laura` and the direct object is `a very` `interesting book`:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果将如下所示。由于第一个句子没有直接宾语，将打印出`None`。对于句子`The big black cat stared at the small
    dog`，主语是`the big black cat`，没有直接宾语（`the small dog`是介词`at`的宾语）。对于句子`Jane watched
    her brother in the evenings`，主语是`Jane`，直接宾语是`her brother`。在句子`Laura gave Sam a
    very interesting book`中，主语是`Laura`，直接宾语是`a very interesting book`：
- en: '[PRE53]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: There’s more…
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'We can look for other objects, for example, the dative objects of verbs such
    as *give* and objects of prepositional phrases. The functions will look very similar,
    with the main difference being the dependency tags: `dative` for the dative object
    function, and `pobj` for the prepositional object function. The prepositional
    object function will return a list since there can be more than one prepositional
    phrase in a sentence:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以寻找其他宾语，例如，动词如*give*的宾格宾语和介词短语宾语。这些函数看起来非常相似，主要区别在于依赖标签：宾格宾语函数的标签是`dative`，介词宾语函数的标签是`pobj`。介词宾语函数将返回一个列表，因为一个句子中可能有多个介词短语：
- en: 'The dative object function checks the tokens for the **dative** tag. It returns
    **None** if there are no dative objects:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 宾格宾语函数检查标记的**宾格**标签。如果没有宾格宾语，则返回**None**：
- en: '[PRE54]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can also combine the subject, object, and dative functions into one with
    an argument that specifies which object to look for:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以将主题、宾语和宾格函数组合成一个，通过一个参数指定要查找哪种宾语：
- en: '[PRE55]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Let us now define a sentence with a dative object and run the function for
    all three types of phrases:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们定义一个带有宾格宾语的句子，并运行所有三种短语类型的函数：
- en: '[PRE56]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The result will be as follows. The dative object is `Sam`:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果将如下所示。宾格宾语是`Sam`：
- en: '[PRE57]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Here is the prepositional object function. It returns a list of objects of
    prepositions, which will be empty if there are none:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里是介词宾语函数。它返回介词宾语的列表，如果没有，则列表为空：
- en: '[PRE58]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Let’s define a list of sentences and run the two functions on them:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个句子列表，并在它们上运行这两个函数：
- en: '[PRE59]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The result will be as follows:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果将如下所示：
- en: '[PRE60]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: There is one prepositional phrase in each sentence. In the sentence `The big
    black cat stared at the small dog`, it is `at the small dog`, and in the sentence
    `Jane watched her brother in the evenings`, it is `in` `the evenings`.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个句子中都有一个介词短语。在句子`The big black cat stared at the small dog`中是`at the small
    dog`，在句子`Jane watched her brother in the evenings`中是`in the evenings`。
- en: It is left as an exercise for you to find the actual prepositional phrases with
    prepositions intact instead of just the noun phrases that are dependent on these
    prepositions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 请将实际带有介词的介词短语而不是仅依赖于这些介词的名词短语找出来，这留作练习：
- en: Finding patterns in text using grammatical information
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用语法信息在文本中查找模式
- en: In this section, we will use the `spaCy` `Matcher` object to find patterns in
    the text. We will use the grammatical properties of the words to create these
    patterns. For example, we might be looking for verb phrases instead of noun phrases.
    We can specify grammatical patterns to match verb phrases.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用`spaCy` `Matcher`对象在文本中查找模式。我们将使用单词的语法属性来创建这些模式。例如，我们可能正在寻找动词短语而不是名词短语。我们可以指定语法模式来匹配动词短语。
- en: Getting ready
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will be using the `spaCy` `Matcher` object to specify and find patterns.
    It can match different properties, not just grammatical. You can find out more
    in the documentation at [https://spacy.io/usage/rule-based-matching/](https://spacy.io/usage/rule-based-matching/).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `spaCy` 的 `Matcher` 对象来指定和查找模式。它可以匹配不同的属性，而不仅仅是语法。你可以在[https://spacy.io/usage/rule-based-matching/](https://spacy.io/usage/rule-based-matching/)的文档中了解更多信息。
- en: How to do it…
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Your steps should be formatted like so:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你的步骤应该格式化如下：
- en: 'Run the file and language utility notebooks:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件和语言实用工具笔记本：
- en: '[PRE61]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Import the **Matcher** object and initialize it. We need to put in the vocabulary
    object, which is the same as the vocabulary of the model we will be using to process
    the text:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 **Matcher** 对象并初始化它。我们需要放入词汇对象，这与我们将用于处理文本的模型的词汇相同：
- en: '[PRE62]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Create a list of patterns and add them to the matcher. Each pattern is a list
    of dictionaries, where each dictionary describes a token. In our patterns, we
    only specify the part of speech for each token. We then add these patterns to
    the **Matcher** object. The patterns we will be using are a verb by itself (for
    example, *paints*), an auxiliary followed by a verb (for example, **was observing**),
    an auxiliary followed by an adjective (for example, **were late**), and an auxiliary
    followed by a verb and a preposition (for example, **were staring at**). This
    is not an exhaustive list; feel free to come up with other examples:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个模式列表并将其添加到匹配器中。每个模式是一个字典列表，其中每个字典描述一个标记。在我们的模式中，我们只为每个标记指定词性。然后我们将这些模式添加到
    **Matcher** 对象中。我们将使用的模式是一个单独的动词（例如，*paints*），一个助动词后面跟一个动词（例如，**was observing**），一个助动词后面跟一个形容词（例如，**were
    late**），以及一个助动词后面跟一个动词和一个介词（例如，**were staring at**）。这不是一个详尽的列表；请随意提出其他示例：
- en: '[PRE63]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Read in the small part of the *Sherlock Holmes* text and process it using the
    small model:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在小部分 *福尔摩斯* 文本中阅读并使用小模型进行处理：
- en: '[PRE64]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now, we find the matches using the **Matcher** object and the processed text.
    We then loop through the matches and print out the match ID, the string ID (the
    identifier of the pattern), the start and end of the match, and the text of the
    match:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用 **Matcher** 对象和已处理文本来查找匹配项。然后我们遍历匹配项，打印出匹配ID、字符串ID（模式的标识符）、匹配的开始和结束位置以及匹配文本：
- en: '[PRE65]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The result will be as follows:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果将如下所示：
- en: '[PRE66]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The code finds some of the verb phrases in the text. Sometimes, it finds a partial
    match that is part of another match. Weeding out these partial matches is left
    as an exercise.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 代码在文本中找到了一些动词短语。有时，它找到一个部分匹配，它是另一个匹配的一部分。清除这些部分匹配被留作练习。
- en: See also
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'We can use other attributes apart from parts of speech. It is possible to match
    on the text itself, its length, whether it is alphanumeric, the punctuation, the
    word’s case, the `dep_` and `morph` attributes, lemma, entity type, and others.
    It is also possible to use regular expressions on the patterns. For more information,
    see the spaCy documentation: [https://spacy.io/usage/rule-based-matching](https://spacy.io/usage/rule-based-matching).'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用除了词性以外的其他属性。可以基于文本本身、其长度、是否为字母数字、标点符号、单词的大小写、`dep_` 和 `morph` 属性、词元、实体类型等来匹配。还可以在模式上使用正则表达式。更多详细信息，请参阅
    spaCy 文档：[https://spacy.io/usage/rule-based-matching](https://spacy.io/usage/rule-based-matching)。
