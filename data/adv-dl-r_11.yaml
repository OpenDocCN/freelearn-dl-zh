- en: Creating New Images Using Generative Adversarial Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成对抗网络创建新图像
- en: This chapter illustrates the application of **generative adversarial networks**
    (**GANs**) for generating new images using a practical example. So far in this
    book, using image data, we have illustrated the use of deep networks for image
    classification tasks. However, in this chapter, we will explore an interesting
    and popular approach that helps create new images. Generative adversarial networks
    have been applied for generating new images, improving image quality, and generating
    new text and new music. Another interesting application of GANs is in the area
    of anomaly detection. Here, a GAN is trained to generate data that is considered
    normal. When this network is used for reconstructing data that is considered not
    normal or anomalous, the differences in results can help us detect the presence
    of an anomaly. We will look at an example of generating new images in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章通过一个实际示例说明了**生成对抗网络**（**GANs**）在生成新图像中的应用。到目前为止，本书通过图像数据展示了深度网络在图像分类任务中的应用。然而，在本章中，我们将探索一种有趣且流行的方法，帮助我们创造新图像。生成对抗网络已被应用于生成新图像、改善图像质量、生成新文本和新音乐。GAN的另一个有趣应用是在异常检测领域。在这种情况下，训练一个GAN以生成被认为是正常的数据。当这个网络被用于重建被认为不正常或异常的数据时，结果中的差异可以帮助我们检测到异常的存在。本章将通过生成新图像的示例来探讨这一应用。
- en: 'More specifically, in this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，本章将涵盖以下主题：
- en: Generative adversarial network overview
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络概述
- en: Processing MNIST image data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理MNIST图像数据
- en: Developing the generator network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发生成器网络
- en: Developing the discriminator network
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发判别器网络
- en: Training the network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练网络
- en: Reviewing results
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估结果
- en: Performance optimization tips and best practices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能优化提示和最佳实践
- en: Generative adversarial network overview
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络概述
- en: 'GANs make use of two networks:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: GAN利用两种网络：
- en: Generator network
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器网络
- en: Discriminator network
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器网络
- en: 'For the generator network, noisy data, which is usually random numbers that
    have been generated from a standard normal distribution are provided as input.
    A flow chart showing an overview of a generative adversarial network is as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生成器网络，输入的是噪声数据，这通常是从标准正态分布中生成的随机数。下面是展示生成对抗网络概述的流程图：
- en: '![](img/02dd32ee-b66b-462b-9b75-8fc5ec56a546.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02dd32ee-b66b-462b-9b75-8fc5ec56a546.png)'
- en: As indicated in the preceding flowchart, the generator network uses noisy data
    as input and tries to create an image that we can label as fake. These fake images,
    along with the labels representing them as fake, are provided as input to the
    discriminator network. Along with the labeled fake images, we can also provide
    real images with labels as input to the discriminator network.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的流程图所示，生成器网络使用噪声数据作为输入，并试图创建我们可以标记为假的图像。这些假图像及其标记为假的标签将作为输入提供给判别器网络。除了带标签的假图像，我们还可以提供带标签的真实图像作为输入给判别器网络。
- en: During the training process, the discriminator network tries to differentiate
    between a fake image created by the generator network and a real image. While
    developing a generative adversarial network, this process continues so that a
    generator network tries its best to generate an image that a discriminator network
    cannot classify as fake. At the same time, the discriminator network gets better
    and better at correctly discriminating between a fake and a real image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，判别器网络尝试区分生成器网络创建的假图像和真实图像。在开发生成对抗网络的过程中，这一过程会持续进行，使得生成器网络尽最大努力生成判别器网络无法判断为假的图像。同时，判别器网络也会越来越擅长正确区分真假图像。
- en: Success is achieved when the generator network learns to consistently produce
    images that are not available in the training data and the discriminator network
    is unable to classify them as fake. For the real images in this chapter, we will
    make use of MNIST train data that contains images of handwritten digits.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当生成器网络学会一致地产生训练数据中没有的图像，而判别器网络无法将其分类为假图像时，就算成功。在本章的真实图像中，我们将使用包含手写数字图像的MNIST训练数据。
- en: In the upcoming sections, we will illustrate the steps we need to follow in
    order to develop a generative adversarial network for the handwritten digit five,
    which is available in the MNIST data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将阐明开发生成对抗网络的步骤，目标是生成手写数字五，数据来自于 MNIST 数据集。
- en: Processing MNIST image data
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理 MNIST 图像数据
- en: 'In this section, will use the Keras library, which also includes MNIST data.
    We will also make use of the EBImage library, which is useful for processing image
    data. MNIST data contains handwritten images from 0 to 9\. Let''s take a look
    at the following code to understand this data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Keras 库，Keras 库中也包括了 MNIST 数据。我们还将使用 EBImage 库，它对于处理图像数据非常有用。MNIST
    数据包含了从 0 到 9 的手写图像。让我们来看一下以下代码，以便更好地理解这些数据：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From the preceding code, we can make the following observations:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以做出以下观察：
- en: Looking at the structure of this data, we can see that there are 60,000 images
    in the training data and 10,000 images in the test data.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从这些数据的结构来看，我们可以看到训练数据中有 60,000 张图像，测试数据中有 10,000 张图像。
- en: These handwritten images are 28 x 28 in size and are black and white in color.
    This means that there's one channel.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些手写图像的尺寸是 28 x 28，且是黑白图像。这意味着它们只有一个通道。
- en: In this chapter, we will only make use of digit five from the training data
    for training the generative adversarial network and for generating new images
    of digit five.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只会使用训练数据中的数字五来训练生成对抗网络，并生成新的数字五图像。
- en: Digit five from the training data
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据中的数字五
- en: 'Although a generative adversarial network can be developed to generate all
    10 digits, for someone just getting started, it is advisable to get started with
    just one digit. Let''s take a look at the following code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以开发一个生成对抗网络来生成所有 10 个数字，但对于刚开始的人来说，建议先从一个数字开始。让我们来看一下以下代码：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As seen in the preceding code, we are selecting images that contain digit five
    and are saving them in `trainx`. The structure of `trainx` shows us that there
    are 5,421 such images and they all have dimensions of 28 x 28\. The summary function
    shows that the values in `trainx` range from 0 to 255\. The first 64 images of
    the handwritten digit five from the train data can be seen in the following image:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，我们选择了包含数字五的图像，并将它们保存在`trainx`中。`trainx`的结构告诉我们，那里有 5,421 张这样的图像，且它们的尺寸为
    28 x 28。总结函数显示，`trainx`中的值范围从 0 到 255。以下图像展示了训练数据中手写数字五的前 64 张图像：
- en: '![](img/b27ce764-d851-46b1-a947-b51b206bc129.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b27ce764-d851-46b1-a947-b51b206bc129.png)'
- en: These handwritten images show a high amount of variability. Such variability
    is expected since different people have different handwriting styles. Although
    most of these digits are clearly written and easy to recognize, there are some
    that are somewhat less clear.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些手写图像显示出高度的变化性。这种变化性是预期中的，因为不同的人有不同的书写风格。虽然大多数数字书写清晰，易于识别，但也有一些不太清楚。
- en: Data processing
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理
- en: 'To prepare our data for the steps that follow, we''ll reshape `trainx` so that
    its dimensions are 5,421 x 28 x 28 x 1, as shown in the following code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备接下来的步骤，我们将重塑`trainx`，使其维度变为 5,421 x 28 x 28 x 1，代码如下所示：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we also divide the values in `trainx` by 255 to obtain a range of values
    between 0 and 1\. With the data processed in the required format, we can move
    on and develop the architecture for the generator network.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还将`trainx`中的值除以 255，得到一个值范围在 0 到 1 之间的数据。数据处理成所需格式后，我们可以继续开发生成器网络的架构。
- en: Developing the generator network
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发生成器网络
- en: The generator network will be used for generating fake images from data that's
    provided in the form of noise. In this section, we will develop the architecture
    of the generator network and look at the parameters that are involved by summarizing
    the network.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络将用于从噪声形式提供的数据中生成假图像。在这一部分，我们将开发生成器网络的架构，并通过总结网络来看相关参数。
- en: Network architecture
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络架构
- en: 'Let''s take a look at the code for developing the generator network architecture:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下开发生成器网络架构的代码：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the preceding code, we can observe the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以观察到以下内容：
- en: We have specified height (h), width (w), number of channels (c), and the latent
    dimension (l) as 28, 28, 1, and 28, respectively.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已指定高度（h）、宽度（w）、通道数（c）和潜在维度（l）分别为 28、28、1 和 28。
- en: We have specified the input shape for the generator input (gi) as 28\. At the
    time of training, the generator network will be provided an input of 28 random
    numbers that have been obtained from a standard normal distribution which is simply
    noise.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经为生成器输入（gi）指定了输入形状为 28。在训练时，生成器网络将提供一个包含 28 个从标准正态分布中获得的随机数的输入，这些数值仅仅是噪声。
- en: Next, we have specified the architecture for the generator network's output
    (go).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们已经为生成器网络的输出（go）指定了架构。
- en: The last layer is a convolutional 2D layer with a `tanh` activation function.
    In the last layer, we have set the filter as 1 since we will not be using color
    images.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一层是一个卷积 2D 层，激活函数为 `tanh`。在最后一层，我们将滤波器设置为 1，因为我们不使用彩色图像。
- en: Note that `layer_conv_2d_transpose` is required to be 28 x 28 in size.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意，`layer_conv_2d_transpose` 的大小要求为 28 x 28。
- en: The output dimensions from the generator output will be 28 x 28 x 1.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器输出的维度将是 28 x 28 x 1。
- en: The other values that were used, such as the number of filters, `kernel_size`,
    or strides can be experimented with later if you wish to explore improving the
    results.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他使用的值，比如滤波器数量、`kernel_size` 或步幅等，可以稍后进行实验，如果你愿意探索改进结果。
- en: '`gi` and `go` are used for the generator network (g).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gi` 和 `go` 用于生成器网络（g）。'
- en: Now, let's look at the summary of this network.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下这个网络的总结。
- en: Summary of the generator network
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成器网络的总结
- en: 'A summary of the generator network is as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络的总结如下：
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The summary of the generator network shows the output's shape and the number
    of parameters for each layer. Note that the final output shape is 28 x 28 x 1\.
    The fake images that will be generated will have these dimensions. Overall, for
    this network, we have 224,737 parameters.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络的总结显示了输出的形状和每一层的参数数量。请注意，最终的输出形状是 28 x 28 x 1。生成的假图像将具有这些维度。总体而言，该网络有 224,737
    个参数。
- en: Now that we've specified the structure of the generator network, we can develop
    the architecture for the discriminator network.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经指定了生成器网络的结构，接下来可以开发鉴别器网络的架构。
- en: Developing the discriminator network
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发鉴别器网络
- en: The discriminator network will be used for classifying fake and real images.
    The architecture and summary of the network will be discussed in this section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器网络将用于分类真假图像。本节将讨论该网络的架构和总结。
- en: Architecture
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构
- en: 'The code that''s used for developing the discriminator network architecture
    is as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 开发鉴别器网络架构所用的代码如下：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'From the preceding code, we can observe the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以观察到以下几点：
- en: We provided an input shape (di) with h = 28, w = 28, and c = 1\. This is the
    dimension of fake and real images that will be used at the time of training the
    network.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为输入形状（di）提供了 h = 28，w = 28 和 c = 1。这是训练网络时使用的假图像和真实图像的维度。
- en: In the last layer of the discriminator output (do), we have specified the activation
    function as `sigmoid` and the units as 1, since an image is differentiated as
    either real or fake.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在鉴别器输出的最后一层（do）中，我们将激活函数指定为 `sigmoid`，单位数设置为 1，因为图像要么被判定为真实，要么被判定为假。
- en: '`di` and `do` are used for the discriminator network model (d).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`di` 和 `do` 用于鉴别器网络模型（d）。'
- en: Summary of the discriminator network
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 鉴别器网络的总结
- en: 'The summary of the discriminator network shows the output shape and number
    of parameters for each layer:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器网络的总结显示了每一层的输出形状和参数数量：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, the output of the first layer is 28 x 28 x 1 in size, which matches the
    dimensions of the fake and real images. The total number of parameters is 41,089.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，第一层的输出是 28 x 28 x 1 的大小，这与假图像和真实图像的维度相匹配。总参数量为 41,089。
- en: 'Now, we can compile the discriminator network model using the following code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下代码编译鉴别器网络模型：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we have compiled the discriminator network using the `rmsprop` optimizer.
    For the loss, we have specified `binary_crossentropy`.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们已经使用 `rmsprop` 优化器编译了鉴别器网络。对于损失，我们指定了 `binary_crossentropy`。
- en: 'Next, we freeze the weight of the discriminator network. Note that we freeze
    these weights after compiling the discriminator network so that it applies them
    to the `gan` model only:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们冻结鉴别器网络的权重。请注意，我们在编译鉴别器网络后冻结这些权重，以便它们仅应用于 `gan` 模型：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, the generative adversarial network's output (gano) uses the generator
    network and the discriminator network with frozen weights. The generative adversarial
    network (gan) is based on `gani` and `gano`. The network is then compiled with
    the `rmsprop` optimizer and with the loss specified as `binary_crossentropy`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，生成对抗网络的输出（gano）使用了生成器网络和权重被冻结的判别器网络。生成对抗网络（gan）是基于`gani`和`gano`的。然后，使用`rmsprop`优化器编译网络，并将损失函数指定为`binary_crossentropy`。
- en: Now, we are ready to train the network.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备好训练网络了。
- en: Training the network
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络训练
- en: In this section, we will out training of the network. While training the network,
    we will save fake images and store loss values to review the training progress.
    They will help us assess the effectiveness of the network when creating realistic
    fake images.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将进行网络训练。在训练过程中，我们将保存假图像并存储损失值，以便回顾训练进展。它们将帮助我们评估网络在生成逼真假图像时的效果。
- en: Initial setup for saving fake images and loss values
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于保存假图像和损失值的初始设置
- en: 'We will start by specifying a few things that we will need for the training
    process. Let''s take a look at the following code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从指定一些训练过程所需的内容开始。让我们看一下以下代码：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'From the preceding code, we can observe the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以观察到以下几点：
- en: We will use a batch size (b) of 50.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用50的批量大小（b）。
- en: We will save fake images in the `FakeImages` directory, which is created on
    the desktop of our computer.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在桌面上创建的`FakeImages`目录中保存假图像。
- en: We will also make use of discriminator loss values (dloss) and GAN loss values
    (gloss), which are initialized with `NULL`.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还将使用判别器损失值（dloss）和GAN损失值（gloss），这两个值都初始化为`NULL`。
- en: Training process
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练过程
- en: 'Next, we will train the model. Here, we will be using 100 iterations. Let''s
    go over the code for this, which has been summarized into five points:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将训练模型。这里，我们将使用100次迭代。让我们来看一下这段代码，它已经总结成五个要点：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the preceding code, we can observe the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以观察到以下几点：
- en: We start by simulating random data points from the standard normal distribution
    and the save results as noise. Then, we use the generator network `g` to create
    fake images from this data containing random noise. Note that `noise` is 50 x
    28 in size and that `fake` is 50 x 28 x 28 x 1 in size and contains 50 fake images
    in each iteration.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先模拟来自标准正态分布的随机数据点，并将结果保存为噪声。然后，我们使用生成器网络`g`从包含随机噪声的数据中生成假图像。注意，`noise`的尺寸为50
    x 28，而`fake`的尺寸为50 x 28 x 28 x 1，并且在每次迭代中包含50张假图像。
- en: We update the values of start and stop based on the batch size. For the first
    iteration, start and stop have values of 1 and 50, respectively. For the second
    iteration, start and stop have values of 51 and 100, respectively. Similarly,
    for the 100th iteration, start and stop have values of 4,951 and 5,000, respectively.
    Since `trainx`, which contains the handwritten digit five, has more than 5,000
    images, none of the images are repeated during these 100 iterations. Thus, in
    each iteration, 50 real images are selected and stored in `real`, which is 50
    x 28 x 28 in size. We use reshape to change the dimensions to 50 x 28 x 28 x 1,
    so that they match the dimensions of the fake images.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们根据批量大小更新start和stop的值。在第一次迭代中，start和stop的值分别为1和50；在第二次迭代中，start和stop的值分别为51和100。同样，在第100次迭代中，start和stop的值分别为4,951和5,000。由于包含手写数字5的`trainx`包含超过5,000张图像，因此在这100次迭代中没有任何图像会被重复。因此，在每次迭代中，都会选择50张真实图像并存储在`real`中，`real`的尺寸为50
    x 28 x 28。我们使用reshape来改变其尺寸为50 x 28 x 28 x 1，以便与假图像的尺寸匹配。
- en: Then, we create an empty array called `both` that's 100 x 28 x 28 x 1 in size
    to store real and fake image data. The first 50 images in `both` contain fake
    data while the next 50 images contain real images. We also generate 50 random
    numbers between 0.9 and 1 using uniform distribution to use as labels for fake
    images and similar random numbers between 0 and 0.1 to use as labels for real
    images. Note that we do not use 0 to represent real and 1 to represent fake images
    and instead introduce some randomness or noise. Artificially introducing some
    noise in the values of labels helps at the time of training the network.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建了一个名为`both`的空数组，大小为100 x 28 x 28 x 1，用于存储真实和伪造的图像数据。`both`中的前50张图像包含伪造数据，而接下来的50张图像包含真实图像。我们还生成了50个介于0.9和1之间的随机数，使用均匀分布来作为伪造图像的标签，并生成50个介于0和0.1之间的随机数，作为真实图像的标签。请注意，我们没有使用0代表真实图像，1代表伪造图像，而是引入了一些随机性或噪声。在训练网络时，人工引入标签值中的噪声有助于提升效果。
- en: We train the discriminator network using image data contained in `both` and
    the correct category information contained in `labels`. We also store the discriminator
    loss values in `dloss` for all 100 iterations. If the discriminator network learns
    to do well in classifying fake and real images, then this loss value will be low.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`both`中包含的图像数据和`labels`中包含的正确类别信息来训练判别器网络。我们还将判别器的损失值保存在`dloss`中，记录所有100次迭代的结果。如果判别器网络能够很好地分类伪造图像和真实图像，那么这个损失值将会较低。
- en: We try to fool the network by labeling the noise containing random values between
    0 and 0.1, which we had used for real images. The resulting loss values are stored
    in `gloss` for all 100 iterations. If the network learns to do well in presenting
    fake images and makes the network classify them as real, then this loss value
    will be low.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们尝试通过将包含介于0和0.1之间的随机值的噪声标记为真实图像来欺骗网络。这些产生的损失值会保存在`gloss`中，记录所有100次迭代的结果。如果网络能够很好地展示伪造图像并将其分类为真实图像，那么这个损失值将会较低。
- en: We save the first fake image from each of the 100 iterations so that we can
    review it and observe the impact of the training process.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们保存了每100次迭代中的第一张伪造图像，以便我们可以回顾并观察训练过程的影响。
- en: Note that, usually, the training process for generative adversarial networks
    requires a significant amount of computational resources. However, the example
    we are using here is meant to quickly illustrate how this process works and complete
    the training process in a reasonable amount of time. For 100 iterations and a
    computer with 8 GB of RAM, it should take less than a minute to run all the code.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，通常生成对抗网络的训练过程需要大量的计算资源。然而，我们这里使用的示例旨在快速展示这个过程是如何工作的，并在合理的时间内完成训练过程。在100次迭代和8
    GB RAM的计算机上，运行所有代码应该不到一分钟。
- en: Reviewing results
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查结果
- en: In this section, we will review the network losses that were obtained from 100
    iterations. We will also take a look at the progress of using fake images from
    iteration 1 to 100.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾从100次迭代中获得的网络损失值。我们还将查看从第一次到第100次迭代中使用伪造图像的进展。
- en: Discriminator and GAN losses
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别器和GAN损失
- en: 'The discriminator and GAN loss values that were obtained from our 100 iterations
    can be plotted as follows. The discriminator loss is based on the loss values
    for the fake and real images:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从100次迭代中获得的判别器和GAN损失值可以绘制如下图。判别器损失基于伪造图像和真实图像的损失值：
- en: '![](img/92ead08f-6541-4a19-8d5c-04d2fb0da7ea.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92ead08f-6541-4a19-8d5c-04d2fb0da7ea.png)'
- en: 'From the preceding plot, we can make the following observations:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以做出以下观察：
- en: The loss values for the discriminator network and the GAN show high variability
    during the first 20 iterations. This variability is an outcome of the learning
    process.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器网络和GAN的损失值在前20次迭代中显示出较大的波动。这种波动是学习过程的结果。
- en: The discriminator and generator networks are competing against each other and
    trying to do better than one another. When one network performs better, it is
    at the cost of the other network. This is the reason why, if `dloss` and `gloss`
    were plotted on a scatter plot, we would expect to see some amount of negative
    correlation between them. The correlation is not expected to be perfectly negative,
    but the overall pattern is expected to indicate a negative relationship. In the
    long run, both loss values are expected to converge.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器和生成器网络相互竞争，并努力做得比对方更好。当一个网络表现更好时，往往是以另一个网络的代价为前提。这也是为什么，如果将`dloss`和`gloss`绘制在散点图上，我们会期望看到它们之间有一定的负相关关系。虽然这种相关性不一定是完全负相关，但整体模式应该显示出负相关的关系。从长远来看，两个损失值预计会趋于收敛。
- en: The loss values that were obtained from the GAN show higher fluctuations compared
    to the loss values that are obtained from the discriminator network.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从GAN获得的损失值波动比从判别器网络获得的损失值更大。
- en: After about 50 iterations, we notice that the discriminator loss values show
    a small but gradual increase. This suggests that the discriminator network is
    finding it increasingly difficult to differentiate between the real and fake images
    that are being generated by the generator network.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在约50次迭代后，我们注意到判别器的损失值出现了小幅但逐渐增加的趋势。这表明，判别器网络在区分由生成器网络生成的真实与假图像时变得越来越困难。
- en: Note that an increase in loss values is not necessarily a negative outcome.
    In this case, this is positive feedback and it indicates that pitting the generator
    network against the discriminator network is yielding results. This means that
    the generator network is able to create fake images that increasingly look like
    real images and helps us achieve our main objective.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意，损失值的增加不一定是负面结果。在这种情况下，这是积极反馈，表明将生成器网络与判别器网络对抗的方式正在产生效果。这意味着生成器网络能够生成越来越像真实图像的假图像，并帮助我们实现主要目标。
- en: Fake images
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假图像
- en: 'We will use the following code to read fake images and then plot them:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码读取假图像并进行绘制：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the preceding code, we have made use of the EBImage library to process fake
    image data. We have read all 100 images that are saved in the `FakeImages` directory.
    Now, we can plot all the images in a 10 x 10 grid, as shown in the following image:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们利用EBImage库来处理假图像数据。我们读取了保存在`FakeImages`目录中的所有100张图像。现在，我们可以将所有图像绘制成一个10
    x 10的网格，如下图所示：
- en: '![](img/c9b410e9-63fd-494b-8546-e948b8536f4e.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9b410e9-63fd-494b-8546-e948b8536f4e.png)'
- en: 'In the preceding image, the first fake image from each of the 100 iterations
    is shown. From this, we can make the following observations:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，展示了每次100次迭代中的第一张假图像。从中我们可以做出以下观察：
- en: The first ten images in the first row represent the first 10 iterations.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一行的前十张图像代表了前10次迭代。
- en: The first image simply reflects random noise. As we reach 10 iterations, the
    image begins to capture the essence of the handwritten digit five.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一张图像仅仅反映了随机噪声。当迭代达到第10次时，图像开始捕捉到手写数字“5”的本质。
- en: By the time the network training goes through iterations 91 to 100, digit five
    becomes visually more clear.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当网络训练经过第91到第100次迭代时，数字“5”变得更加清晰可见。
- en: In the next section, we will carry out an experiment by making some changes
    in the network and observing its impact on the network's training process.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将通过在网络中进行一些更改并观察其对网络训练过程的影响来进行实验。
- en: Performance optimization tips and best practices
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能优化技巧和最佳实践
- en: In this section, we will carry out an experiment by inserting an additional
    convolutional layer into the generator network, as well as in the discriminator
    network. Through this experiment, we will convey performance optimization tips
    and best practices.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将通过在生成器网络和判别器网络中插入额外的卷积层来进行实验。通过这个实验，我们将传达性能优化技巧和最佳实践。
- en: Changes in the generator and discriminator network
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成器和判别器网络的变化
- en: 'The changes in the generator network are shown in the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络中的变化如下代码所示：
- en: '[PRE12]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we can see that, in the generator network, we are adding the `layer_conv_2d`
    and `layer_activation_leaky_relu` layers just before the last layer. The total
    number of parameters for the generator network has increased to 276,801.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，在生成器网络中，我们在倒数第二层之前添加了`layer_conv_2d`和`layer_activation_leaky_relu`层。生成器网络的参数总数已增加到276,801。
- en: 'The changes in the discriminator network are shown in the following code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器网络的变化如下代码所示：
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we have added the `layer_conv_2d` and `layer_activation_leaky_relu` layers
    before the flattening layer in the discriminator network. The number of parameters
    in the discriminator network has increased to 148,866\. We have kept everything
    else the same and then trained the network again for 100 iterations.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在判别器网络的展平层之前添加了`layer_conv_2d`和`layer_activation_leaky_relu`层。判别器网络中的参数数量已增加到148,866个。我们保持其他一切不变，然后再次训练该网络100次迭代。
- en: Now, we can assess the impact of these changes.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以评估这些变化的影响。
- en: Impact of these changes on the results
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这些变化对结果的影响
- en: 'The discriminator and GAN loss values for 100 iterations can be plotted as
    follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器和GAN的损失值可以绘制成如下图表：
- en: '![](img/f0b7934c-683d-488a-b9de-b4375b35f698.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0b7934c-683d-488a-b9de-b4375b35f698.png)'
- en: 'From the preceding plot, we can observe the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以观察到以下几点：
- en: By increasing the number of layers, the fluctuation in the loss values for the
    discriminator and GAN network has reduced compared to the results we obtained
    earlier.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过增加层数，判别器和GAN网络的损失值波动比我们之前获得的结果减少了。
- en: The spikes or high loss values that have been observed for some of the iterations
    indicate the corresponding network struggling, while competing against the other
    network.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些迭代中观察到的峰值或高损失值表明，相应的网络在与另一个网络对抗时遇到困难。
- en: The variability in the GAN loss values continues to be higher compared to those
    for discriminator network-related loss.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与判别器网络相关的损失相比，GAN损失值的波动性仍然较高。
- en: 'The following plot is of the first fake image in each of the 100 iterations:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了每100次迭代中的第一张假图像：
- en: '![](img/6ea51275-7d28-4f89-ae28-e8054420bf78.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ea51275-7d28-4f89-ae28-e8054420bf78.png)'
- en: 'From the preceding images, we can observe the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图像中，我们可以观察到以下几点：
- en: With additional convolutional layers in the generator and discriminator networks,
    the network begins to generate images replicating the handwritten digit five much
    earlier.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成器和判别器网络中增加了卷积层后，网络开始更早生成出类似手写数字五的图像。
- en: In the previous network, fake images that consistently looked like handwritten
    digit five did not appear until about 70-80 iterations.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在之前的网络中，直到大约70-80次迭代时，才会出现始终看起来像手写数字五的假图像。
- en: Due to the use of additional layers, we can see the digit five being formed
    more or less consistently after about 20-30 iterations, which suggests an improvement.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于使用了额外的层，我们可以看到数字五在大约20-30次迭代后开始一致地形成，这表明有所改进。
- en: Next, we will try to use this network to generate another handwritten digit.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将尝试使用该网络生成另一张手写数字。
- en: Generating a handwritten image of digit eight
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成手写数字八的图像
- en: 'In this experiment, we will make use of the same network architecture as the
    previous one. However, we will use it for generating a handwritten image of digit
    eight. The discriminator and GAN loss values for 100 iterations for this experiment
    can be plotted as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本实验中，我们将使用与之前相同的网络架构。然而，我们将使用它来生成手写数字八的图像。该实验中100次迭代的判别器和GAN损失值可以绘制如下图表：
- en: '![](img/69db0b7a-6a39-40c3-906a-54311552e074.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/69db0b7a-6a39-40c3-906a-54311552e074.png)'
- en: 'From the preceding plot, we can make the following observations:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以得出以下观察：
- en: The discriminator and GAN loss values show variability that tends to reduce
    as the number of iterations goes from 1 to 100.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器和GAN的损失值显示出波动性，并且这种波动性随着迭代次数从1到100的增加而逐渐减小。
- en: High spikes at certain intervals for the GAN loss are diminishing as the network's
    training proceeds.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着网络训练的进行，GAN损失值在某些间隔中的高峰逐渐减少。
- en: 'A plot of the first fake image from each iteration is as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每次迭代中的第一张假图像的图表如下：
- en: '![](img/28729cfc-3050-4fc5-bfcc-bd9a0f23691e.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/28729cfc-3050-4fc5-bfcc-bd9a0f23691e.png)'
- en: Compared to digit five, digit eight takes more iterations before it starts to
    form a recognizable pattern.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与数字五相比，数字八在开始形成可识别的模式之前需要更多的迭代次数。
- en: 'In this section, we experimented with additional convolutional layers in the
    generator and the discriminator networks. Due to this, we can make the following
    observations:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们在生成器和判别器网络中实验了额外的卷积层。因此，我们可以得出以下观察：
- en: Additional convolutional layers seem to have a positive impact on the generation
    of fake images that began to look like handwritten images of digit five much quicker.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的卷积层似乎对更快生成类似手写数字五的假图像有积极影响。
- en: Although the results for the data that we referred to in this chapter were decent,
    for other data, we may have to make other changes to the model architecture.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管本章参考的数据结果还算不错，但对于其他数据，我们可能需要对模型架构进行其他更改。
- en: We also used the network with the same architecture to generate realistic-looking
    fake images of handwritten digit eight. It was observed that, for digit eight,
    it took more iterations of training the network before a recognizable pattern
    started to emerge.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还使用了相同架构的网络来生成看起来逼真的手写数字八的假图片。观察到，对于数字八，需要更多的训练迭代才能开始出现可识别的模式。
- en: Note that a network for generating all 10 handwritten digits at the same time
    can be more complex and is likely to require many more iterations.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意，一次生成所有10个手写数字的网络可能会更复杂，可能需要更多的迭代次数。
- en: Similarly, if we have color images that have significantly larger dimensions
    than 28 x 28, which is what we used for this chapter, we will need more computational
    resources and the task will be even more challenging.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似地，如果我们有颜色图像的尺寸显著大于我们在本章中使用的28 x 28，我们将需要更多的计算资源，任务也将更具挑战性。
- en: Summary
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: 'In this chapter, we used a generative adversarial network to illustrate how
    to generate images of a single handwritten digit. Generative adversarial networks
    make use of two networks: generator and discriminator networks. Generator networks
    create fake images from data containing random noise, while discriminator networks
    are trained to differentiate between fake images and real images. These two networks
    compete against each other so that realistic-looking fake images can be created.
    Although in this chapter we provided an example of using a generative adversarial
    network to generate new images, these networks are also known to have applications
    in generating new text or new music, as well as in anomaly detection.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用生成对抗网络演示了如何生成单个手写数字的图像。生成对抗网络利用两个网络：生成器和鉴别器网络。生成器网络从包含随机噪声的数据中创建假图像，而鉴别器网络则训练用于区分假图像和真实图像。这两个网络相互竞争，以便创建逼真的假图像。尽管本章提供了使用生成对抗网络生成新图像的示例，但这些网络也被知道在生成新文本或新音乐以及异常检测方面有应用。
- en: In this section, we went over various deep learning networks that are useful
    for dealing with image data. In the next section, we will go over deep learning
    networks for natural language processing.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了用于处理图像数据的各种深度学习网络。在下一节中，我们将介绍用于自然语言处理的深度学习网络。
