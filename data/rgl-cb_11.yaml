- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Regularization in Computer Vision – Synthetic Image Generation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉中的正则化 – 合成图像生成
- en: 'This chapter will focus on the techniques and methods used to generate synthetic
    images for data augmentation. Having diverse data is often one of the most efficient
    ways to regularize computer vision models. Many approaches allow us to generate
    synthetic images; from simple tricks such as image flipping to new image creation
    using generative models. Several techniques will be explored in this chapter,
    including the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点介绍用于生成合成图像进行数据增强的技术和方法。拥有多样化的数据通常是正则化计算机视觉模型的最有效方法之一。许多方法可以帮助我们生成合成图像；从简单的技巧如图像翻转，到使用生成模型创建新图像。本章将探讨几种技术，包括以下内容：
- en: Image augmentation with Albumentations
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Albumentations 进行图像增强
- en: Creating synthetic images for object detection – training an object detection
    model with only synthetic data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建合成图像用于目标检测 – 仅使用合成数据训练目标检测模型
- en: Real-time style transfer – training a model for real-time style transfer based
    on Stable Diffusion, a powerful generative model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时风格迁移 – 基于 Stable Diffusion（一个强大的生成模型）训练实时风格迁移模型
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will train several deep learning models and generate images.
    We will need the following libraries:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将训练几个深度学习模型并生成图像。我们将需要以下库：
- en: NumPy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: Matplotlib
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib
- en: Albumentations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Albumentations
- en: Pytorch
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pytorch
- en: torchvision
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: torchvision
- en: ultralytics
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ultralytics
- en: Applying image augmentation with Albumentations
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Albumentations 应用图像增强
- en: More often than not, in **machine learning** (**ML**), data is crucial to getting
    better performances of models. Computer vision is no exception, and data augmentation
    with images can be easily taken to another level.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **机器学习**（**ML**）中，数据对于提高模型的性能至关重要。计算机视觉也不例外，图像数据增强可以轻松提升到另一个层次。
- en: Indeed, it is possible to easily augment an image, for example, by mirroring
    it, as shown in *Figure 11**.1*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，轻松增强图像是可能的，例如，通过镜像操作，如 *图 11.1* 所示。
- en: '![Figure 11.1 – On the left, the original picture of my dog, and on the right,
    a mirrored picture of my dog](img/B19629_11_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 左侧是我狗的原始照片，右侧是我狗的镜像照片](img/B19629_11_01.jpg)'
- en: Figure 11.1 – On the left, the original picture of my dog, and on the right,
    a mirrored picture of my dog
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 左侧是我狗的原始照片，右侧是我狗的镜像照片
- en: 'However, beyond this, many more types of augmentation are possible and can
    be divided into two main categories: pixel-level and spatial-level transformations.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，除此之外，还有更多类型的增强方法，这些方法可以分为两大类：像素级和空间级变换。
- en: Let's discuss both of these in the following sections.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将讨论这两种方法。
- en: Spatial-level augmentation
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空间级增强
- en: 'The mirroring is an example of spatial-level augmentation; however, much more
    than simple mirroring can be done. For example, see the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像操作是空间级增强的一个例子；然而，除了简单的镜像操作，还可以做更多的变换。例如，见以下内容：
- en: '**Shifting**: Shifting an image in a certain direction'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平移**：将图像平移到某个方向'
- en: '**Shearing**: Add shearing to an image'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**剪切**：对图像进行剪切变换'
- en: '**Cropping**: Cropping only part of an image'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**裁剪**：只裁剪图像的一部分'
- en: '**Rotating**: Applying rotation to an image'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旋转**：对图像进行旋转'
- en: '**Transposing**: Transposing an image (in other words, applying both vertical
    and horizontal flipping)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转置**：对图像进行转置（换句话说，应用垂直和水平翻转）'
- en: '**Perspective**: Applying a 4-point perspective to an image'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透视**：对图像应用四点透视'
- en: 'As we can see, there are a lot of possibilities in spatial-level augmentation.
    *Figure 11**.2* shows some examples of these possibilities on a given image and
    displays some of the possible artifacts: black borders on the shifted image and
    mirror padding on the rotated image.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，空间级增强有许多可能性。*图 11.2* 展示了在给定图像上这些可能性的一些例子，并显示了一些可能出现的伪影：平移图像时的黑色边框和旋转图像时的镜像填充。
- en: '![Figure 11.2 – The original image (top left) and five different augmentations
    (note that some artifacts may appear, such as black borders)](img/B19629_11_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – 原始图像（左上角）和五种不同的增强方式（请注意，某些伪影可能会出现，如黑色边框）](img/B19629_11_02.jpg)'
- en: Figure 11.2 – The original image (top left) and five different augmentations
    (note that some artifacts may appear, such as black borders)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 原始图像（左上角）和五种不同的增强方式（请注意，某些伪影可能会出现，如黑色边框）
- en: Pixel-level augmentation
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 像素级增强
- en: Another type of augmentation is at the pixel level and can be as useful as spatial-level
    augmentation. A simple example could be to change the brightness and contrast
    level of an image so that a model can be more robust in various lighting conditions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种增强方式是像素级增强，和空间级增强一样有用。一个简单的例子可能是改变图像的亮度和对比度，使得模型能在不同的光照条件下更具鲁棒性。
- en: 'A non-exhaustive list of pixel-level augmentation is the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些像素级增强的非详尽列表：
- en: '**Brightness**: Modify the brightness'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**亮度**：修改亮度'
- en: '**Contrast**: Modify the contrast'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对比度**：修改对比度'
- en: '**Blurring**: Blur the image'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模糊**：模糊图像'
- en: '**HSV**: Randomly modify the **hue**, **saturation**, and **value** of the
    image'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HSV**：随机修改图像的**色相**、**饱和度**和**明度**'
- en: '**Color conversion**: Convert the image into black and white or sepia'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色转换**：将图像转换为黑白或褐色调'
- en: '**Noise**: Add noise to the image'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**噪声**：向图像添加噪声'
- en: 'There are many possibilities, and this can make a huge difference in model
    robustness. A few examples of the results of these augmentations are shown in
    the following figure:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这里有许多可能性，这些变化可能大大提升模型的鲁棒性。以下图示展示了这些增强的一些结果：
- en: '![Figure 11.3 – An original image (top left) and several pixel-level augmentations](img/B19629_11_03.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.3 – 原始图像（左上）和几种像素级增强](img/B19629_11_03.jpg)'
- en: Figure 11.3 – An original image (top left) and several pixel-level augmentations
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 原始图像（左上）和几种像素级增强
- en: As we can see, using both pixel-level and spatial-level transformations, it
    is fairly easy to augment a single image into 5 or 10 images. Moreover, these
    augmentations can sometimes be composed together for more diversity. Of course,
    it does not replace a real, large, and diverse dataset, but image augmentation
    is usually cheaper than collecting data and allows us to get real boosts in model
    performance.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，使用像素级和空间级转换，我们可以很容易地将一张图像增强成5到10张图像。此外，这些增强有时可以组合起来以获得更多的多样性。当然，它无法替代一个真实的大型多样化数据集，但图像增强通常比收集数据便宜，并且能够显著提升模型性能。
- en: Albumentations
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Albumentations
- en: Of course, we do not have to reimplement all of these image augmentations manually.
    Several libraries for image augmentation exist, and Albumentations is arguably
    the most complete, free, and open source solution on the market. As we will see
    in this recipe, the Albumentations library allows powerful image augmentations
    with just a few lines of code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们不必手动重新实现所有这些图像增强。现在有很多图像增强的库，Albumentations无疑是市场上最完整、最自由、开源的解决方案。正如我们在这个教程中所见，Albumentations库只需要几行代码就能实现强大的图像增强。
- en: Getting started
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始
- en: 'In this recipe, we will apply image augmentation to a simple challenge: classifying
    cats and dogs.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将应用图像增强来解决一个简单的挑战：分类猫和狗。
- en: 'We first need to download and prepare the dataset. The dataset, originally
    proposed by Microsoft, is made of 12,491 cat pictures and 12,470 dog pictures.
    It can be downloaded with the Kaggle API with the following command-line operation:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要下载并准备数据集。这个数据集最初由微软提出，包含12,491张猫的图片和12,470张狗的图片。可以通过Kaggle API使用以下命令行操作进行下载：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will download a folder named `kagglecatsanddogs_3367a`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这将下载一个名为`kagglecatsanddogs_3367a`的文件夹。
- en: 'Unfortunately, the dataset is not yet split into train and test sets. The following
    code will split it into 80% train and 20% test sets:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，数据集尚未拆分为训练集和测试集。以下代码将把它拆分为80%的训练集和20%的测试集：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will create subfolders of `train` and `test`, so that the `kagglecatsanddogs_3367a`
    folder tree now looks like the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建`train`和`test`子文件夹，因此`kagglecatsanddogs_3367a`文件夹结构现在如下所示：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will now be able to efficiently train and evaluate a model against this dataset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将能够高效地训练和评估一个针对该数据集的模型。
- en: 'The required libraries can be installed with the following command line:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的库可以通过以下命令行安装：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How to do it…
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We will now train a MobileNet V3 network on the train dataset and evaluate
    it against the test dataset. Then, we will add image augmentation using Albumentations
    in order to improve the performance of the model:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在训练数据集上训练一个MobileNet V3网络，并在测试数据集上进行评估。然后，我们将使用Albumentations添加图像增强，以提高模型的性能：
- en: 'First, import the needed libraries:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入所需的库：
- en: '`matplotlib` for display and visualization'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`用于显示和可视化'
- en: '`numpy` for data manipulation'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`用于数据处理'
- en: '`Pillow` for image loading'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pillow`用于图像加载'
- en: '`glob` for folder parsing'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glob`用于文件夹解析'
- en: '`torch` and `torchvision` for the model training and related `util` instances'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch`和`torchvision`用于模型训练及相关`util`实例'
- en: 'Here are the `import` statements:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`import`语句：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we implement the `DogsAndCats` dataset class. It takes the following
    arguments:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们实现`DogsAndCats`数据集类。它接受以下参数：
- en: '`cats_folder`: The path to the folder containing the cat pictures'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cats_folder`：包含猫咪图片的文件夹路径'
- en: '`dogs_folder`: The path to the folder containing the dog pictures'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dogs_folder`：包含狗狗图片的文件夹路径'
- en: '`transform`: The transformation to apply to images (for example, resizing,
    converting into tensors, and so on...)'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform`：应用于图像的转换（例如，调整大小、转换为张量等）'
- en: '`augment`: To apply image augmentation, as we will do in the second part of
    this recipe'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`augment`：应用图像增强，如我们将在本节后半部分做的那样'
- en: 'Here is the code for the implementation:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是实现的代码：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This class is rather simple: the constructor collects all the paths of the
    images and defines the labels accordingly. The getter simply loads an image, optionally
    applies image augmentation, and returns the image as `tensor` with its associated
    label.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类相当简单：构造函数收集所有图像路径，并相应地定义标签。获取器简单地加载图像， optionally应用图像增强，并返回带有相关标签的`tensor`形式的图像。
- en: 'Then, we instantiate the transformation class. Here, we compose three transformations:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们实例化转换类。在这里，我们组合了三个转换：
- en: Tensor conversion
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张量转换
- en: Resizing to 224x224 images since not all images are the same size
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于并非所有图像的大小都相同，因此将图像调整为224x224大小
- en: Normalization of the image input
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像输入的标准化
- en: 'Here is the code for it:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的代码：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we create a few useful variables, such as the batch size, device, and
    number of epochs:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一些有用的变量，例如批量大小、设备和周期数：
- en: '[PRE7]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Instantiate the datasets and data loaders. Reusing the train and test folders
    prepared earlier in the *Getting ready* subsection, we can now easily create our
    two loaders. They both use the same transformation:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化数据集和数据加载器。重用*准备工作*小节中提前准备好的训练和测试文件夹，我们现在可以轻松创建两个加载器。它们都使用相同的转换：
- en: '[PRE11]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we display a few images along with their labels so that we get a glimpse
    at the dataset using the following code:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用以下代码展示一些图像及其标签，以便浏览数据集：
- en: '[PRE25]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here are the images:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图像：
- en: '![Figure 11.4 – A sample of images from the dataset](img/B19629_11_04.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – 数据集中的图像样本](img/B19629_11_04.jpg)'
- en: Figure 11.4 – A sample of images from the dataset
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 数据集中的图像样本
- en: As we can see in the figure, this is a dataset made up of regular images of
    dogs and cats in various contexts, sometimes with humans in the pictures too.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，这是一个由各种场景下的狗和猫的常规图像组成的数据集，有时图片中也包含人类。
- en: 'Now, we implement the `Classifier` class. We will reuse the existing `mobilenet_v3_small`
    implementation provided in `pytorch` and simply add an output layer with one unit
    and a sigmoid activation function, shown as follows:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们实现`Classifier`类。我们将重用在`pytorch`中提供的现有`mobilenet_v3_small`实现，并仅添加一个具有一个单元和sigmoid激活函数的输出层，如下所示：
- en: '[PRE35]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Next, we instantiate the model:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们实例化模型：
- en: '[PRE44]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Then, instantiate the loss function as the binary cross-entropy loss, well
    suited to binary classification. Here we instantiate the Adam optimizer:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，实例化损失函数为二元交叉熵损失，这非常适合二分类问题。接下来，我们实例化Adam优化器：
- en: '[PRE46]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Then, train the model for 20 epochs and store the outputs. To do so, we use
    the `train_model` function, which trains the input model for a given number of
    epochs and with a given dataset. It returns the loss and accuracy for the training
    and test set for each epoch. This function is available in the GitHub repository
    ([https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb](https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb)),
    and is typical code for binary classification training, as we used in previous
    chapters:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，训练模型20个周期并存储输出。为此，我们使用`train_model`函数，该函数在给定的周期数和数据集上训练输入模型。它返回每个周期的训练集和测试集的损失和准确率。此函数可以在GitHub仓库中找到（[https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb](https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb)），这是二分类训练的典型代码，如我们在前几章中使用的那样：
- en: '[PRE49]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Finally, display the loss and accuracy as a function of the epoch:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将损失和准确率作为周期的函数进行显示：
- en: '[PRE55]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Here are the plots for it:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是它的图示：
- en: '![Figure 11.5 – Binary cross-entropy loss (top) and accuracy (bottom) as a
    function of the epoch for both train and test sets with no augmentation (the loss
    and accuracy are suggesting overfitting while the test accuracy plateaus at around
    88%)](img/B19629_11_05.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图11.5 – 二进制交叉熵损失（顶部）和准确度（底部）作为训练和测试集的周期函数，无增强（损失和准确度表明过拟合，测试准确度在约88%时达到平台期）](img/B19629_11_05.jpg)'
- en: Figure 11.5 – Binary cross-entropy loss (top) and accuracy (bottom) as a function
    of the epoch for both train and test sets with no augmentation (the loss and accuracy
    are suggesting overfitting while the test accuracy plateaus at around 88%)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 – 二进制交叉熵损失（顶部）和准确度（底部）作为训练和测试集的周期函数，无增强（损失和准确度表明过拟合，测试准确度在约88%时达到平台期）
- en: As we can see, the test accuracy seems to reach a plateau after roughly 10 epochs,
    with a peak accuracy of around 88%. The train accuracy gets as high as 98%, suggesting
    strong overfitting on the train set.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，测试准确度似乎在大约10个周期后达到了平台期，峰值准确度约为88%。训练准确度达到了98%，这表明在训练集上存在强烈的过拟合现象。
- en: Training with image augmentation
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用图像增强进行训练
- en: 'Let’s now redo the same exercise with image augmentation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用图像增强重新做同样的练习：
- en: 'First, we need to implement the desired image augmentation. Using the same
    pattern as with the transformations in `pytorch`, using Albumentations, we can
    instantiate a `Compose` class with a list of augmentations. In our case, we use
    the following augmentations:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要实现所需的图像增强。使用与`pytorch`中变换相同的模式，借助Albumentations，我们可以实例化一个包含增强列表的`Compose`类。在我们的例子中，我们使用以下增强方法：
- en: '`HorizontalFlip`: This involves basic mirroring, occurring with a 50% probability,
    meaning 50% of the images will be randomly mirrored'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HorizontalFlip`：这涉及基本的镜像操作，发生的概率为50%，意味着50%的图像会被随机镜像'
- en: '`Rotate`: This will randomly rotate an image in the range of [-90, 90] degrees
    (this range can be modified) with a probability of 50%'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Rotate`：这将以50%的概率随机旋转图像，旋转范围为[-90, 90]度（此范围可修改）'
- en: '`RandomBrightnessContrast`: This will randomly change the brightness and contrast
    of the image with a probability of 20%'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RandomBrightnessContrast`：这将以20%的概率随机改变图像的亮度和对比度'
- en: 'Here are the instantiations:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是实例化的代码：
- en: '[PRE68]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Then, instantiate a new, augmented training set and training data loader. To
    do so, we simply have to provide our `augment` object as an argument of the `DogsAndCats`
    class:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，实例化一个新的增强训练集和训练数据加载器。为此，我们只需将`augment`对象作为`DogsAndCats`类的参数提供即可：
- en: '[PRE69]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Note
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We do not apply augmentation to the test set since we need to be able to compare
    the performances to the results without augmentation. Besides that, it would be
    useless to augment the test set, unless you are using Test Time Augmentation (see
    the *There’s more…* section for more about it).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不对测试集应用增强，因为我们需要能够将增强结果与未增强的结果进行比较。此外，除非使用测试时间增强（有关更多信息，请参见*更多…*部分），否则增强测试集是没有意义的。
- en: 'Then, display a few images from this new, augmented dataset as follows:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，按如下方式显示该新增强数据集中的一些图像：
- en: '[PRE78]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Here are the images:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是图像：
- en: '![Figure 11.6 – Example of augmented images (some have been rotated, some have
    been mirrored and some have modified brightness and contrast)](img/B19629_11_06.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图11.6 – 增强图像示例（有些已旋转，有些已镜像，还有些亮度和对比度已被修改）](img/B19629_11_06.jpg)'
- en: Figure 11.6 – Example of augmented images (some have been rotated, some have
    been mirrored and some have modified brightness and contrast)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 – 增强图像示例（有些已旋转，有些已镜像，还有些亮度和对比度已被修改）
- en: As we can see, some images seem now rotated. Besides, some images are also mirrored
    and have a modified brightness and contrast, efficiently improving the diversity
    of the dataset.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，某些图像现在似乎被旋转了。此外，某些图像还被镜像并且亮度与对比度发生了变化，有效地提高了数据集的多样性。
- en: 'Then, we instantiate the model and the optimizer:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们实例化模型和优化器：
- en: '[PRE79]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Next, train the model on this new training set while keeping the same test
    set and store the output losses and metrics:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在这个新的训练集上训练模型，同时保持相同的测试集，并记录输出的损失和指标：
- en: '[PRE83]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Note
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In this recipe, we are doing augmentation online, meaning that every time we
    load a new batch of images, we randomly apply augmentation to these images; consequently,
    at each epoch, we may train from differently augmented images.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们在线进行增强，意味着每次加载新的图像批次时，我们都会随机应用增强；因此，在每个周期中，我们可能会从不同增强的图像中训练。
- en: 'Another approach is to augment data offline: we preprocess and augment the
    dataset, store the augmented images, and then only train the model on this data.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是离线增强数据：我们对数据集进行预处理和增强，存储增强后的图像，然后只在这些数据上训练模型。
- en: 'Both approaches have pros and cons: offline augmentation allows us to augment
    images only once but requires more storage space, while online preprocessing may
    take more time to train but does not require any extra storage.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法各有优缺点：离线增强允许我们只增强一次图像，但需要更多的存储空间，而在线预处理可能需要更多时间来训练，但不需要额外的存储。
- en: 'Now finally, we plot the results: the loss and accuracy for both the training
    and test sets. Here is the code for that:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，最后，我们绘制结果：训练集和测试集的损失与准确率。以下是相应的代码：
- en: '[PRE89]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Here are the plots:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是图示：
- en: '![Figure 11.7 – Loss and accuracy for the augmented dataset](img/B19629_11_07.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图11.7 – 增强数据集的损失与准确率](img/B19629_11_07.jpg)'
- en: Figure 11.7 – Loss and accuracy for the augmented dataset
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 – 增强数据集的损失与准确率
- en: As you can see in the preceding figure, compared to the regular dataset, not
    only is the overfitting almost totally removed but the accuracy also climbs up
    to more than 91%, compared to 88% previously.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在前面的图示中看到的，与常规数据集相比，过拟合几乎完全消除，并且准确率也提高到了超过91%，而之前为88%。
- en: 'Thanks to this rather simple image augmentation, we could get the accuracy
    to climb from 88% to 91%, while reducing overfitting: the train set now has the
    same performances as the test set.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了这个相当简单的图像增强，我们将准确率从88%提升到91%，同时减少了过拟合：训练集的表现现在和测试集一样。
- en: There’s more…
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: While we used augmentation for training, there is a method that takes advantage
    of image augmentation at test time to improve the performances of models. This
    is sometimes called **Test** **Time Augmentation**.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们使用了增强来进行训练，但有一种方法可以在测试时利用图像增强来提高模型的表现，这有时被称为**测试时增强**。
- en: 'The idea is simple: compute model inference on several, augmented images, and
    compute the final prediction with a majority vote.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法很简单：对多个增强过的图像进行模型推理，并通过多数投票计算最终预测。
- en: 'Let’s take a simple example. Assuming we have an input image that must be classified
    with our trained dogs and cats model, we augment this input image with mirroring
    and with brightness and contrast, so that we have three images:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简单的例子。假设我们有一张输入图像，必须使用我们训练好的狗猫模型进行分类，我们通过镜像以及调整亮度和对比度对这张输入图像进行增强，从而得到三张图像：
- en: '**Image 1**: The original image'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像 1**：原始图像'
- en: '**Image 2**: The mirrored image'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像 2**：镜像图像'
- en: '**Image 3**: The image with modified brightness and contrast'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像 3**：调整亮度和对比度后的图像'
- en: 'We will now compute model inference on those three images, getting the following
    predictions:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将在这三张图像上进行模型推理，得到以下预测结果：
- en: '**Image 1** **prediction**: Cat'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像 1** **预测**：猫'
- en: '**Image 2** **prediction**: Cat'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像 2** **预测**：猫'
- en: '**Image 3** **prediction**: Dog'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像 3** **预测**：狗'
- en: We can now compute a majority vote by choosing the most represented predicted
    class, resulting in a cat class prediction.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过选择最多代表的预测类别来计算多数投票，从而得出猫类的预测结果。
- en: Note
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In practice, we would most likely use a soft majority vote, averaging the predicted
    probabilities (either for binary or multiclass classification), but the concept
    remains the same.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们很可能使用软多数投票法，通过对预测的概率（无论是二分类还是多分类）进行平均来进行预测，但概念是一样的。
- en: Test Time Augmentation is commonly used in competitions and can indeed improve
    the performance of the model for no added training cost. In a production environment
    though, where the inference cost is key, this method is rarely used.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 测试时增强（Test Time Augmentation）在竞赛中常常使用，确实可以在不增加训练成本的情况下提高模型的表现。然而，在生产环境中，推理成本至关重要，因此这种方法很少使用。
- en: See also
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'In this recipe, we used Albumentations for a simple classification task, but
    it can be used for much more than that: it allows us to perform image augmentation
    for object detection, instance segmentation, semantic segmentation, landmarks,
    and so on.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，我们使用了Albumentations来进行简单的分类任务，但它可以用于更多的场景：它允许我们进行目标检测、实例分割、语义分割、地标检测等图像增强。
- en: 'To know more about how to use it fully, have a look at the well-written documentation,
    with many working examples here: https://albumentations.ai/docs/.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何充分使用它，请查看编写得很好的文档，其中有许多工作示例，网址如下：https://albumentations.ai/docs/。
- en: Creating synthetic images for object detection
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建用于目标检测的合成图像
- en: For some projects, you may have so little data that the only thing you can do
    is use this data in the test set. In some rare cases, it is possible to create
    a synthetic dataset to create a robust enough model and test it against the small,
    real test set.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些项目，数据量可能非常少，以至于你只能使用这些数据作为测试集。在某些罕见情况下，可以创建合成数据集，训练一个足够强大的模型，并使用小型真实测试集对其进行测试。
- en: 'This is what we will do in this recipe: we have a small test set of pictures
    of QR codes, and we want to build an object detection model for the detection
    of QR codes. All we have as a train set is a set of generated QR codes and downloaded
    images collected on open image websites such as unsplash.com.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在这个食谱中要做的：我们有一个小型的二维码图片测试集，我们希望为二维码的检测构建一个目标检测模型。作为训练集，我们只有一组生成的二维码和从如 unsplash.com
    等开放图像网站下载的图片。
- en: Getting started
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始入门
- en: 'Download and unzip the dataset from https://www.kaggle.com/datasets/vincentv/qr-detection-yolo
    with the following command line:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令行从 https://www.kaggle.com/datasets/vincentv/qr-detection-yolo 下载并解压数据集：
- en: '[PRE102]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'This dataset is made up of the following folder architecture:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集由以下文件夹结构组成：
- en: '[PRE103]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'It is made up of three folders:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 它由三个文件夹组成：
- en: '**The train set**: Only generated QR codes with no context'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**：仅包含没有上下文的生成二维码'
- en: '**The test set**: Pictures of QR codes in various contexts and environments'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**：在不同环境和场景中的二维码图片'
- en: '**Background images**: Random images of context such as stores'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**背景图片**：如商店等场景的随机图像'
- en: The goal is to use the data in the train set and the background images to generate
    realistic synthetic images to train a model on and only then to evaluate the model
    against the test set, made of real images.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是使用训练集中的数据和背景图像生成逼真的合成图像，以训练模型，然后再在由真实图像组成的测试集上评估模型。
- en: 'For this recipe, the needed libraries can be installed with the following command
    line:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，所需的库可以通过以下命令行安装：
- en: '[PRE104]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: How to do it…
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Let’s divide this recipe into three parts:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个食谱分成三部分：
- en: First, we will explore the dataset and implement a few helper functions.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将探索数据集并实现一些辅助函数。
- en: The second part is about generating synthetic data using QR codes and background
    images.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二部分是关于使用二维码和背景图片生成合成数据的。
- en: The last part is about training a YOLO model on the generated data and evaluating
    this model.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一部分是关于在生成的数据上训练YOLO模型并评估该模型。
- en: Let us understand each of these in the following sections.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的章节中了解每个部分。
- en: Exploring the dataset
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据集
- en: 'Let’s start by creating a few helper functions and use them to display a few
    images of the train and test sets:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一些辅助函数开始，并使用它们显示训练集和测试集中的一些图像：
- en: 'Import the following libraries:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库：
- en: '`glob` for listing files'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glob` 用于列出文件'
- en: '`os` for making a directory in which to store the created synthetic images'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os` 用于创建存储生成合成图像的目录'
- en: '`albumentations` for data augmentation'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albumentations` 用于数据增强'
- en: '`cv2` for image manipulation'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2` 用于图像处理'
- en: '`matplotlib` for display'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib` 用于显示'
- en: '`numpy` for various data manipulation'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy` 用于各种数据处理'
- en: '`YOLO` for the model'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YOLO` 用于模型'
- en: 'Here are the imports:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这是导入的库：
- en: '[PRE105]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Let’s implement a `read_labels` helper function, which will read the text file
    with the YOLO labels and return them as a list:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个 `read_labels` 辅助函数，它将读取YOLO标签的文本文件并将其作为列表返回：
- en: '[PRE106]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Now let’s implement a `plot_labels` helper function, which will reuse the previous
    `read_labels` function, read a few images and corresponding labels, and display
    these images with the bounding boxes:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们实现一个 `plot_labels` 辅助函数，它将重用之前的 `read_labels` 函数，读取一些图像及其相应标签，并显示这些带有边界框的图像：
- en: '[PRE116]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'Now, display a set of images from the train set and their bounding boxes with
    the following code:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码显示训练集中的一组图像及其边界框：
- en: '[PRE142]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: 'Here are a few sample images in the form of QR codes:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些二维码形式的示例图像：
- en: '![Figure 11.8 – A few samples from the train set with the associated labels
    (this dataset is only made up of generated QR codes on a white background)](img/B19629_11_08.jpg)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![图11.8 – 来自训练集的一些样本及其标签（该数据集仅由白色背景上的生成二维码组成）](img/B19629_11_08.jpg)'
- en: Figure 11.8 – A few samples from the train set with the associated labels (this
    dataset is only made up of generated QR codes on a white background)
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8 – 来自训练集的一些样本及其标签（该数据集仅由白色背景上的生成二维码组成）
- en: As explained, the train set is only made up of generated QR codes of various
    sizes on a white background with no more context.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，训练集仅由各种大小的生成二维码组成，背景是白色的，没有更多上下文。
- en: 'Let’s now display a few images from the test set with the following code:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码显示一些来自测试集的图像：
- en: '[PRE144]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE145]'
- en: 'Here are the resulting images:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是生成的图像：
- en: '![Figure 11.9 – A few examples from the test set, made of real-world images
    of QR codes](img/B19629_11_09.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.9 – 测试集中一些示例，由真实世界的二维码图像组成](img/B19629_11_09.jpg)'
- en: Figure 11.9 – A few examples from the test set, made of real-world images of
    QR codes
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 – 测试集中一些示例，由真实世界的二维码图像组成
- en: The test set contains more complex, real examples of QR codes, and is much more
    challenging.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集包含更复杂、真实的二维码示例，挑战性更大。
- en: Generating a synthetic dataset from background images
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从背景图像生成合成数据集
- en: 'In this part, we will now generate a dataset of realistic, synthetic data.
    To do so, we will use the images of the QR codes from the training set as well
    as a set of background images. Here are the steps:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将生成一个逼真的合成数据集。为此，我们将使用训练集中的二维码图像以及一组背景图像。步骤如下：
- en: 'Let’s now generate a synthetic dataset using two ingredients:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用两种材料生成一个合成数据集：
- en: Real background images
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实背景图像
- en: Numerically generated QR codes
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字生成的二维码
- en: 'For that, we will use a rather long and complex function, `generate_synthetic_background_image_with_tag`,
    which does the following:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用一个相当长且复杂的函数，`generate_synthetic_background_image_with_tag`，它执行以下操作：
- en: Picks a random background image in the given folder
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从给定文件夹中随机选择一个背景图像
- en: Picks a random QR code image in the given folder
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从给定文件夹中随机选择一个二维码图像
- en: Augments the picked QR code
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增强选定的二维码
- en: Randomly inserts the augmented QR code into the background image
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机将增强的二维码插入背景图像中
- en: Applies a little more augmentation to the newly created image
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对新创建的图像应用更多增强
- en: Stores the generated image and the corresponding labels in YOLO format
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将生成的图像及其相应的标签以 YOLO 格式存储
- en: 'The code that does this is available in the GitHub repository and is too long
    to be displayed here, so we will only display its signature and docstring here.
    However, you are strongly encouraged to have a look at it and to play with it.
    The code can be found here:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此操作的代码可以在 GitHub 仓库中找到，代码较长，无法在这里显示，因此我们只展示它的签名和文档字符串。不过，我们强烈建议你查看并进行尝试。代码可在此找到：
- en: https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb
- en: '[PRE146]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: Note
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This function does this generation as many times as we want and provides a few
    other features; feel free to have a close look at it and update it.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数会根据需求多次执行此生成，并提供一些其他功能；请随时深入查看并更新它。
- en: 'We can now use this function to generate 3,000 images by calling the `generate_synthetic_background_image_with_tag`
    function (3,000 is a rather arbitrary choice; feel free to generate fewer images
    or more images). This may take a few minutes. The generated images and their associated
    labels will be stored in the `QR-detection-yolo/generated_qr_code_images/` folder,
    which will be created if it does not exist:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用这个函数通过调用 `generate_synthetic_background_image_with_tag` 来生成 3,000 张图像（3,000
    是一个相当任意的选择，可以根据需要生成更多或更少的图像）。这可能需要几分钟。生成的图像及其相关标签将存储在 `QR-detection-yolo/generated_qr_code_images/`
    文件夹中，如果该文件夹不存在，将自动创建：
- en: '[PRE147]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '[PRE153]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE153]'
- en: 'Let’s have a look at a few examples of generated images with the following
    code:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下代码查看一些生成图像的示例：
- en: '[PRE154]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: 'Here are the images:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这些图像：
- en: '![Figure 11.10 – Examples of synthetically created images, made of background
    images and generated QR codes with various image augmentations](img/B19629_11_10.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.10 – 合成创建的图像示例，由背景图像和生成的二维码与各种图像增强组合而成](img/B19629_11_10.jpg)'
- en: Figure 11.10 – Examples of synthetically created images, made of background
    images and generated QR codes with various image augmentations
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 – 合成创建的图像示例，由背景图像和生成的二维码与各种图像增强组合而成
- en: As we can see, some images are simple augmented QR codes with no background
    context, as is possible due to the generating function. This can be tweaked with
    the `background_proba` argument.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，有些图像只是简单的增强二维码，没有背景，这得益于生成函数的作用。可以通过`background_proba`参数调整这一点。
- en: Model training
  id: totrans-355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'We can now start the model training part: we will train a YOLO model on the
    3,000 images generated in the previous step and evaluate this model against the
    test set. Here are the steps:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始模型训练部分：我们将用前一步生成的 3,000 张图像训练一个 YOLO 模型，并在测试集上评估该模型。以下是步骤：
- en: 'First, instantiate a YOLO model with pre-trained weights as follows:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，按照以下方式实例化一个带有预训练权重的 YOLO 模型：
- en: '[PRE155]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: Note
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You may have `FileNotFoundError` because of an incorrect dataset path. A `config`
    file in `~/.config/Ultralytics/settings.yaml` has a previous path. A quick and
    harmless fix is to simply delete this file; a new one will then be automatically
    generated.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会遇到 `FileNotFoundError` 错误，这是由于数据集路径不正确导致的。`~/.config/Ultralytics/settings.yaml`
    中的 `config` 文件存有以前的路径。一个快速且无害的解决办法是简单地删除这个文件；一个新的文件将会自动生成。
- en: 'Then, we need to create a `.yaml` file, `data_qr_generated.yaml`, with the
    following content:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要创建一个 `.yaml` 文件 `data_qr_generated.yaml`，其内容如下：
- en: '[PRE157]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '[PRE158]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE160]'
- en: 'This `.yaml` file can be used to train the model on our dataset, on `50 epochs`.
    We also specify the initial learning rate to be 0.001 with `lr0=0.001` because
    the default learning rate (0.01) is rather large for fine-tuning a pre-trained
    model in our case:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个 `.yaml` 文件可以用来在我们的数据集上训练模型，训练周期为 `50 epochs`。我们还指定了初始学习率为 0.001 (`lr0=0.001`)，因为默认的学习率（0.01）对于微调预训练模型来说过大：
- en: '[PRE161]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE163]'
- en: Results should be stored in the created folder, `runs/detect/generated_qrcode`.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该保存在创建的文件夹 `runs/detect/generated_qrcode` 中。
- en: 'Before having a look at the results, let’s implement a `plot_results_one_image`
    helper function to display the output of the model, as follows:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在查看结果之前，我们先实现一个 `plot_results_one_image` 辅助函数，以显示模型的输出，代码如下：
- en: '[PRE164]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: '[PRE166]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '[PRE167]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: '[PRE169]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '[PRE170]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE171]'
- en: '[PRE172]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: '[PRE173]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '[PRE179]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '[PRE182]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: 'We can then reload the best weights and compute the inference and display the
    results on an image from the test set:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以重新加载最佳权重，计算推理，并在测试集中的一张图像上显示结果：
- en: '[PRE184]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE185]'
- en: '[PRE186]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE186]'
- en: '[PRE187]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: '[PRE188]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '[PRE189]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: 'Here are the results:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![Figure 11.11 – Examples of results of the YOLO model trained on synthetic
    data (even though the model is not perfect, is it capable of detecting QR codes
    in rather complex and various situations)](img/B19629_11_11.jpg)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.11 – 训练于合成数据的 YOLO 模型结果示例（尽管模型并不完美，但它能够在相当复杂和多样的情况下检测二维码）](img/B19629_11_11.jpg)'
- en: Figure 11.11 – Examples of results of the YOLO model trained on synthetic data
    (even though the model is not perfect, is it capable of detecting QR codes in
    rather complex and various situations)
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11 – 训练于合成数据的 YOLO 模型结果示例（尽管模型并不完美，但它能够在相当复杂和多样的情况下检测二维码）
- en: As we can see, the model is not working perfectly yet but still manages to get
    QR codes in several complex situations. However, in a few cases, such as with
    really small QR codes, bad-quality images, or highly deformed QR codes, the model
    does not seem to perform well.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，模型仍然没有完全发挥作用，但仍能在多个复杂场景中识别二维码。然而，在一些情况下，例如二维码非常小、图像质量差或二维码严重变形时，模型似乎表现不佳。
- en: 'Finally, we can visualize the losses and other metrics generated by the YOLO
    library:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以可视化 YOLO 库生成的损失值和其他指标：
- en: '[PRE190]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '[PRE191]'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '[PRE192]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: 'Here are the losses:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是损失值：
- en: '![Figure 11.12 – Metrics computed by the YOLO library](img/B19629_11_12.jpg)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.12 – YOLO 库计算的指标](img/B19629_11_12.jpg)'
- en: Figure 11.12 – Metrics computed by the YOLO library
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12 – YOLO 库计算的指标
- en: In agreement with the displayed results for a few images, the metrics are not
    perfect, with a mAP50 around 75% only.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 根据显示的几张图像结果，指标并不完美，mAP50 仅为 75% 左右。
- en: This could probably be improved by adding more well-chosen image augmentation.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加更多精心挑选的图像增强，可能会有所改进。
- en: There’s more…
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: There are more techniques for generating images with labels even if we don’t
    have any real data in the first place. In this recipe, we only used background
    images, generated QR codes, and augmentations, but it is possible to use generative
    models to generate even more data.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们一开始没有任何真实数据，仍然有更多生成带标签图像的技术。在本教程中，我们仅使用了背景图像、生成的二维码和增强方法，但也可以使用生成模型来生成更多数据。
- en: 'Let’s see how to do this with DALL-E, a model proposed by OpenAI:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 OpenAI 提出的 DALL-E 模型来实现：
- en: 'First, we can import the required libraries. The `openai` library can be installed
    with `pip` `install openai`:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们可以导入所需的库。可以使用 `pip install openai` 安装 `openai` 库：
- en: '[PRE193]'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '[PRE195]'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: Note
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You need to create your own API key by creating your own account on openai.com.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要通过在 openai.com 创建自己的帐户来生成自己的 API 密钥。
- en: 'Let’s now create a helper function that converts the bounding boxes and the
    image into a mask since we want to complete outside of the bounding box:'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来创建一个辅助函数，将边界框和图像转换为掩膜，因为我们希望在边界框外部进行填充：
- en: '[PRE198]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '[PRE199]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE200]'
- en: '[PRE201]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE202]'
- en: '[PRE203]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE203]'
- en: '[PRE204]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE204]'
- en: '[PRE205]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE205]'
- en: '[PRE206]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE206]'
- en: '[PRE207]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '[PRE208]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '[PRE209]'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: '[PRE210]'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: '[PRE211]'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: '[PRE212]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '[PRE213]'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '[PRE214]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '[PRE215]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: '[PRE216]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE216]'
- en: 'We can now compute a mask and display the result side by side with the original
    image as follows:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以计算掩膜，并将结果与原始图像并排显示，方法如下：
- en: '[PRE217]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE217]'
- en: '[PRE218]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE218]'
- en: '[PRE219]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE219]'
- en: '[PRE220]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE220]'
- en: '[PRE221]'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE221]'
- en: '[PRE222]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE222]'
- en: '[PRE223]'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE223]'
- en: '[PRE224]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE224]'
- en: '[PRE225]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE225]'
- en: '[PRE226]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE226]'
- en: '[PRE227]'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE227]'
- en: '[PRE228]'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE228]'
- en: 'Here are the results:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是结果：
- en: '![Figure 11.13 – An original image on the left, and the associated masked image
    to be used for data generation on the right](img/B19629_11_13.jpg)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.13 – 左侧是原始图像，右侧是用于数据生成的相关掩膜图像](img/B19629_11_13.jpg)'
- en: Figure 11.13 – An original image on the left, and the associated masked image
    to be used for data generation on the right
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.13 – 左侧是原始图像，右侧是用于数据生成的相关掩膜图像
- en: Note
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We keep a margin for the masked image so that when calling DALL-E 2, it has
    a sense of the surroundings. If we provide only a QR code and white surroundings
    in the mask, the result may not be good enough.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保留掩膜图像的边缘，以便调用 DALL-E 2 时，它能够感知周围环境。如果我们只提供一个二维码和白色背景的掩膜，结果可能不尽如人意。
- en: 'We can now query the OpenAI model DALL-E 2 to fill around this QR code and
    generate a new image using the `create_edit` method from the `openai` library.
    The function requires the following few parameters:'
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以查询 OpenAI 模型 DALL-E 2，通过 `openai` 库中的 `create_edit` 方法来填充这个二维码并生成新图像。该功能需要以下几个参数：
- en: The input image (in PNG format, less than 4 MB)
  id: totrans-463
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像（PNG 格式，小于 4 MB）
- en: The input mask (in PNG format and less than 4 MB too)
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入掩膜（同样是 PNG 格式且小于 4 MB）
- en: A prompt describing what the expected output image is
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述期望输出图像的提示
- en: The number of images to generate
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的图像数量
- en: The output size in pixels (either 256x256, 512x512, or 1,024x1,024)
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出图像的像素大小（可以是 256x256、512x512 或 1,024x1,024）
- en: 'Let’s now query DALL-E on our image, and then display the original and the
    generated images side by side:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来查询 DALL-E，显示原始图像和生成图像并排显示：
- en: '[PRE229]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE229]'
- en: 'Here is how the images appear:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是图像的显示效果：
- en: '![Figure 11.14 – The original image on the left, and the generated image using
    DALL-E 2 on the right](img/B19629_11_14.jpg)'
  id: totrans-471
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.14 – 左侧是原始图像，右侧是使用 DALL-E 2 生成的图像](img/B19629_11_14.jpg)'
- en: Figure 11.14 – The original image on the left, and the generated image using
    DALL-E 2 on the right
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.14 – 左侧是原始图像，右侧是使用 DALL-E 2 生成的图像
- en: As we can see in *Figure 11**.14*, using this technique allows us to create
    more realistic images that can easily be used for training. These created images
    can also be augmented using Albumentations.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 *图 11.14* 中看到的，使用这种技术能够创建更逼真的图像，这些图像可以轻松用于训练。这些创建的图像还可以通过 Albumentations
    进行增强。
- en: Note
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: There are a few drawbacks though. The generated image is of size 512x512, meaning
    the bounding box coordinates have to be converted (this can be done using Albumentations)
    and the generated image is not always good and requires a visual check.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法也有一些缺点。生成的图像大小为 512x512，这意味着边界框坐标需要转换（这可以通过 Albumentations 完成），而且生成的图像不总是很完美，需要进行视觉检查。
- en: 'We can also create variations of a given image using the `create_variation`
    function. This function is simpler to use and requires similar input arguments:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用 `create_variation` 函数创建给定图像的变化。这种方法更简单，且需要类似的输入参数：
- en: The input image (still a PNG image smaller than 4 MB)
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像（仍然是小于 4 MB 的 PNG 图像）
- en: The number of varied images to generate
  id: totrans-478
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的变化图像数量
- en: The output image size in pixels (again, either 256x256, 512x512, or 1,024x1,024)
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出图像的像素大小（同样可以是 256x256、512x512 或 1,024x1,024）
- en: 'Here is the code for this:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是这段代码：
- en: '[PRE230]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE230]'
- en: 'Here is the output:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 11.15 – The original image (left) and the generated variation using
    DALL-E (right)](img/B19629_11_15.jpg)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.15 – 左侧是原始图像，右侧是使用 DALL-E 生成的变化图像](img/B19629_11_15.jpg)'
- en: Figure 11.15 – The original image (left) and the generated variation using DALL-E
    (right)
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.15 – 左侧是原始图像，右侧是使用 DALL-E 生成的变化图像
- en: 'The result presented in the preceding figure is pretty good: we can see a meeting
    room in the background and a QR code in the foreground, just like in the original
    image. However, this data would not be easy to use unless we labeled it manually
    since we have no certainty the QR code will be at the same location (even if we
    resize the bounding box coordinates). Still, using such models can be of great
    help for other use cases, such as classification.'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图中展示的结果相当不错：我们可以看到背景中的会议室和前景中的二维码，就像原始图像一样。然而，除非我们手动标注这些数据，否则它可能不容易使用，因为我们无法确定二维码是否会出现在相同的位置（即使我们调整了边界框坐标）。尽管如此，使用这样的模型对于其他用例（如分类）仍然是非常有帮助的。
- en: See also
  id: totrans-486
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'The list of train parameters available with YOLOv8: https://docs.ultralytics.com/modes/train/'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLOv8 可用的训练参数列表：https://docs.ultralytics.com/modes/train/
- en: 'The DALL-E API documentation: https://platform.openai.com/docs/guides/images/usage'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DALL-E API 文档：https://platform.openai.com/docs/guides/images/usage
- en: Implementing real-time style transfer
  id: totrans-489
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现实时风格迁移
- en: 'In this recipe, we will build our own lightweight style transfer model based
    on the U-Net architecture. To do so, we will use a dataset generated using Stable
    Diffusion (see more next about what Stable Diffusion is). This can be seen as
    a kind of knowledge distillation: we will use the data generated by a large, teacher
    model (Stable Diffusion, which weighs several gigabytes) to train a small, student
    model (here, a U-Net++ of less than 30 MBs). This is a funny way to use generative
    models to create data, but the concepts developed here can be used in many other
    applications: some will be proposed in the *There’s more…* section, along with
    guidance on creating your own style transfer dataset using Stable Diffusion. But
    before that, let’s give some context about style transfer.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将基于 U-Net 架构构建我们自己的轻量级风格迁移模型。为此，我们将使用一个通过稳定扩散生成的数据集（稍后将详细介绍稳定扩散是什么）。这可以看作是一种知识蒸馏：我们将使用一个大型教师模型（稳定扩散，体积达到几个千兆字节）生成的数据来训练一个小型学生模型（这里是一个不到
    30 MB 的 U-Net++）。这是一种有趣的方式，利用生成模型创建数据，但这里发展出的概念可以用于许多其他应用：其中一些将在*更多内容...*部分中提出，并提供如何使用稳定扩散创建自己的风格迁移数据集的指导。
    在此之前，让我们先了解一下风格迁移的背景。
- en: 'Style transfer is a famous and fun use of deep learning, allowing us to change
    the style of a given image into another style. Many examples exist, such as Mona
    Lisa in Van Gogh’s Starry Night style, as represented in the following figure:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 风格迁移是深度学习中的一个著名且有趣的应用，它允许我们将给定图像的风格转换为另一种风格。许多例子存在，比如《蒙娜丽莎》以梵高的《星夜》风格呈现，如下图所示：
- en: '![Figure 11.16 – Mona Lisa in the Starry Night style](img/B19629_11_16.jpg)'
  id: totrans-492
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.16 – 《蒙娜丽莎》以《星夜》风格呈现](img/B19629_11_16.jpg)'
- en: Figure 11.16 – Mona Lisa in the Starry Night style
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.16 – 《蒙娜丽莎》以《星夜》风格呈现
- en: Until recently, style transfer was mostly performed using **Generative Adversarial
    Networks** (**GANs**), which are quite hard to train properly.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，风格迁移大多是使用**生成对抗网络**（**GANs**）进行的，而这些网络通常很难正确训练。
- en: It is now simpler than ever to apply style transfer to images, using pre-trained
    models based on Stable Diffusion. Unfortunately, Stable Diffusion is a large and
    complex model that sometimes requires several seconds to generate a single image
    on a recent graphics card.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用基于稳定扩散的预训练模型应用风格迁移比以往任何时候都要简单。不幸的是，稳定扩散是一个庞大而复杂的模型，有时在最新的图形卡上生成一张图像可能需要几秒钟的时间。
- en: In this recipe, we will train a U-Net-like model allowing for real-time transfer
    learning on any device. To accomplish this, we will employ a form of knowledge
    distillation. Specifically, we will train the U-net model using Stable Diffusion
    data and incorporate a VGG perceptual loss for that purpose.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将训练一个类似于 U-Net 的模型，允许在任何设备上进行实时迁移学习。为此，我们将采用一种知识蒸馏的方式。具体而言，我们将使用稳定扩散数据来训练
    U-Net 模型，并为此目的加入 VGG 感知损失。
- en: Note
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '**VGG** stands for **Visual Geometry Group**, the name of the Oxford team who
    proposed this deep learning model architecture. It is a standard deep learning
    model in Computer Vision.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '**VGG** 代表 **视觉几何组**，这是提出这一深度学习模型架构的牛津团队的名称。它是计算机视觉中的标准深度学习模型。'
- en: 'Before moving on to the recipe, let’s have a look at two important concepts
    for this recipe:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续进行食谱之前，让我们先看一下本食谱中的两个重要概念：
- en: Stable Diffusion
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稳定扩散
- en: Perceptual loss
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知损失
- en: Stable Diffusion
  id: totrans-502
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散
- en: Stable Diffusion is a complex and powerful model, allowing us to use image and
    text prompts to generate new images.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散是一个复杂而强大的模型，允许我们通过图像和文本提示生成新图像。
- en: '![Figure 11.17 – Architecture diagram of Stable Diffusion](img/B19629_11_17.jpg)'
  id: totrans-504
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.17 – 稳定扩散的架构图](img/B19629_11_17.jpg)'
- en: Figure 11.17 – Architecture diagram of Stable Diffusion
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.17 – 稳定扩散的架构图
- en: 'As we can see from the preceding figure, the way Stable Diffusion is trained
    can be summarized, with simplifications, as follows:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图可以看出，稳定扩散的训练方式可以简化总结如下：
- en: 'Diffusion is gradually applied **T** times to an input image **Z**: this is
    like adding random noise to the input image'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对输入图像 **Z** 进行 **T** 次扩散：这就像是向输入图像添加随机噪声
- en: These diffused images are passed through a denoising U-Net model
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些扩散的图像被传入去噪 U-Net 模型
- en: A condition is optionally added, such as a descriptive text or another image
    prompt, as an embedding
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选择添加一个条件，如描述性文本或另一个图像提示，作为嵌入
- en: The model is trained to output the input image
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型被训练用于输出输入图像
- en: 'Once a model is well trained, it can be used for inference by skipping the
    first part as follows:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，就可以通过跳过如下第一部分来进行推断：
- en: Given a seed, a random image is generated and given as input to the denoising
    U-Net
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个种子，生成一个随机图像并将其作为输入提供给去噪 U-Net
- en: 'An input prompt is added as condition: it can be text or an input image, for
    example'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加输入提示作为条件：它可以是文本或输入图像，例如
- en: 'An output image is then generated: this is the final result'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后生成输出图像：这就是最终结果
- en: Although this is a simplistic explanation of how it works, it allows us to get
    a general understanding of what it does and what are the expected inputs to generate
    a new image.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这只是一个简单的工作原理解释，但它使我们能够大致了解它的工作方式以及生成新图像的预期输入是什么。
- en: Perceptual loss
  id: totrans-516
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 感知损失
- en: Perceptual loss has been proposed to train a model to learn about perceptual
    features in an image. It was developed specifically for style transfer and allows
    you to focus not only on the pixel-to-pixel content itself but also on the style
    of the image.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 感知损失被提出用来训练模型以学习图像中的感知特征。它是专门为风格迁移开发的，允许你不仅关注像素到像素的内容本身，还关注图像的风格。
- en: 'It takes two images as input: the model prediction and the label image, and
    it is commonly based on a VGG neural network pre-trained on the ImageNet dataset
    or any similar generic image dataset.'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 它接受两幅图像作为输入：模型预测和标签图像，通常基于一个在 ImageNet 数据集或任何类似通用图像数据集上预训练的 VGG 神经网络。
- en: 'More specifically, for both images (for example, the model prediction and the
    label), the following computations are made:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，对于两幅图像（例如，模型预测和标签），进行以下计算：
- en: The feedforward computation of the VGG model is applied to each image
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VGG 模型的前馈计算应用于每个图像
- en: The outputs after each block of the VGG model are stored, allowing us to get
    more and more specific features with deeper blocks
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个 VGG 模型块后的输出被存储，这使我们能够通过更深的块获得越来越具体的特征
- en: Note
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: In a deep neural network, the first layers are commonly about learning generic
    features and shapes, while the deepest layers are about learning more specific
    features. The perceptual loss takes advantage of this property.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度神经网络中，前几层通常用于学习通用特征和形状，而最深的层则用于学习更具体的特征。感知损失利用了这一特性。
- en: 'Using these stored computations, perceptual loss is finally computed as the
    sum of the following values:'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些存储的计算，最终感知损失被计算为以下值的总和：
- en: 'The differences (for example, L1 or L2 norm) between the computations for each
    block output: These can be represented as the feature reconstruction loss and
    will focus on image features.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个块输出计算之间的差异（例如 L1 或 L2 范数）：这些可以表示为特征重建损失，并将关注图像特征。
- en: 'The differences between the Gram matrices of the computations for each block
    output: These can be represented as the style reconstruction loss and will focus
    on the image’s style.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个块输出计算的 Gram 矩阵之间的差异：这些可以表示为风格重建损失，并且将关注于图像的风格。
- en: Note
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: A Gram matrix of a given set of vectors is made by computing the dot product
    of each pair of vectors and then arranging the results into a matrix. It can be
    seen as a similarity or a correlation between the given vectors.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组向量的 Gram 矩阵通过计算每对向量的点积并将结果排列成矩阵来构造。它可以看作是给定向量之间的相似性或相关性。
- en: At the end, minimizing this perceptual loss should allow us to apply a style
    from a given image to another, as we will see in this recipe.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，最小化这个感知损失应该允许我们将给定图像的风格应用到另一张图像上，正如我们将在本食谱中看到的那样。
- en: Getting started
  id: totrans-530
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入门
- en: 'You can download the full dataset that I created for this recipe on Kaggle
    with the following command line:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下命令行从 Kaggle 下载我为这个配方创建的完整数据集：
- en: '[PRE231]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE231]'
- en: 'You then have the following folder architecture:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你将拥有以下文件夹架构：
- en: '[PRE232]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE232]'
- en: This is a rather small dataset, but it should allow us to get good enough performances
    to show the potential of this technique.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当小的数据集，但它应该足够展示该技术的潜力，能够获得良好的表现。
- en: For more about how to create such a dataset using ControlNet yourself, have
    a look at the *There’s* *more…* subsection.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用 ControlNet 自行创建这样的数据集，请查看 *There’s* *more…* 子章节。
- en: 'The libraries needed for this recipe can be installed with the following command
    line:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方所需的库可以通过以下命令行安装：
- en: '[PRE233]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE233]'
- en: How to do it…
  id: totrans-539
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Here are the steps for this recipe:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个配方的步骤：
- en: 'Import the required libraries:'
  id: totrans-541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '`matplotlib` for visualization'
  id: totrans-542
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib` 用于可视化'
- en: '`numpy` for manipulation'
  id: totrans-543
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy` 用于操作'
- en: Several `torch` and `torchvision` modules
  id: totrans-544
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几个 `torch` 和 `torchvision` 模块
- en: '`segmentation models pytorch` for the model'
  id: totrans-545
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation models pytorch` 用于模型'
- en: '`albumentations` for image augmentation'
  id: totrans-546
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`albumentations` 用于图像增强'
- en: 'Here is the code for it:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的代码：
- en: '[PRE234]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE234]'
- en: 'Implement `AnimeStyleDataset`, allowing us to load the dataset. Note that we
    use the `ReplayCompose` tool from `Albumentations`, allowing us to apply the exact
    same image augmentation to the image and the associated label:'
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现 `AnimeStyleDataset`，允许我们加载数据集。请注意，我们使用了 `Albumentations` 中的 `ReplayCompose`
    工具，允许我们对图像和相关标签应用完全相同的图像增强：
- en: '[PRE235]'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE235]'
- en: '[PRE236]'
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE236]'
- en: '[PRE237]'
  id: totrans-552
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE237]'
- en: '[PRE238]'
  id: totrans-553
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE238]'
- en: '[PRE239]'
  id: totrans-554
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE239]'
- en: '[PRE240]'
  id: totrans-555
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE240]'
- en: '[PRE241]'
  id: totrans-556
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE241]'
- en: '[PRE242]'
  id: totrans-557
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE242]'
- en: '[PRE243]'
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE243]'
- en: '[PRE244]'
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE244]'
- en: '[PRE245]'
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE245]'
- en: '[PRE246]'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE246]'
- en: '[PRE247]'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE247]'
- en: '[PRE248]'
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE248]'
- en: '[PRE249]'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE249]'
- en: '[PRE250]'
  id: totrans-565
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE250]'
- en: '[PRE251]'
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE251]'
- en: '[PRE252]'
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE252]'
- en: '[PRE253]'
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE253]'
- en: '[PRE254]'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE254]'
- en: '[PRE255]'
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE255]'
- en: '[PRE256]'
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE256]'
- en: '[PRE257]'
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE257]'
- en: 'Instantiate the augmentation, which is a composition of the following transformations:'
  id: totrans-573
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化增强，这是以下变换的组合：
- en: '`Resize`'
  id: totrans-574
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Resize`'
- en: A horizontal flip with a probability of 50%
  id: totrans-575
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以 50% 的概率进行水平翻转
- en: '`ShiftScaleRotate`, allowing us to randomly add geometrical variety'
  id: totrans-576
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ShiftScaleRotate`，允许我们随机增加几何变化'
- en: '`RandomBrightnessContrast`, allowing us to add variety to the light'
  id: totrans-577
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RandomBrightnessContrast`，允许我们增加光照变化'
- en: '`RandomCropFromBorders`, which will randomly crop the borders of the images'
  id: totrans-578
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RandomCropFromBorders`，它将随机裁剪图片的边缘'
- en: 'Here is the code for it:'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的代码：
- en: '[PRE258]'
  id: totrans-580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE258]'
- en: 'Instantiate the transformation, allowing us to convert the torch tensors and
    rescale the pixel values. Also, define the batch size and the device as follows:'
  id: totrans-581
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化变换，允许我们转换 torch 张量并重新缩放像素值。同时，定义批量大小和设备，如下所示：
- en: '[PRE259]'
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE259]'
- en: '[PRE260]'
  id: totrans-583
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE260]'
- en: '[PRE261]'
  id: totrans-584
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE261]'
- en: '[PRE262]'
  id: totrans-585
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE262]'
- en: '[PRE263]'
  id: totrans-586
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE263]'
- en: '[PRE264]'
  id: totrans-587
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE264]'
- en: '[PRE265]'
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE265]'
- en: '[PRE266]'
  id: totrans-589
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE266]'
- en: '[PRE267]'
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE267]'
- en: '[PRE268]'
  id: totrans-591
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE268]'
- en: Note
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Here, we use the mean and standard deviation rescaling specific to the ImageNet
    dataset because the VGG perceptual loss (see ahead) is trained on this specific
    set of values. Also, the batch size may need to be adjusted depending on your
    hardware specifications, especially the memory of your graphics processing unit.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了特定于 ImageNet 数据集的均值和标准差重缩放，因为 VGG 感知损失（见下文）是在这一特定值集上训练的。此外，批量大小可能需要根据你的硬件规格进行调整，尤其是图形处理单元的内存。
- en: 'Instantiate the datasets and data loaders, providing the train and test folders.
    Note that we apply augmentation to the train set only:'
  id: totrans-594
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化数据集和数据加载器，提供训练集和测试集文件夹。请注意，我们只对训练集应用增强：
- en: '[PRE269]'
  id: totrans-595
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE269]'
- en: '[PRE270]'
  id: totrans-596
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE270]'
- en: '[PRE271]'
  id: totrans-597
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE271]'
- en: '[PRE272]'
  id: totrans-598
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE272]'
- en: '[PRE273]'
  id: totrans-599
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE273]'
- en: '[PRE274]'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE274]'
- en: '[PRE275]'
  id: totrans-601
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE275]'
- en: '[PRE276]'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE276]'
- en: '[PRE277]'
  id: totrans-603
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE277]'
- en: '[PRE278]'
  id: totrans-604
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE278]'
- en: '[PRE279]'
  id: totrans-605
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE279]'
- en: '[PRE280]'
  id: totrans-606
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE280]'
- en: '[PRE281]'
  id: totrans-607
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE281]'
- en: '[PRE282]'
  id: totrans-608
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE282]'
- en: '[PRE283]'
  id: totrans-609
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE283]'
- en: 'Display a few images along with their labels so that we have a glimpse at the
    dataset. For that, we first need a helper `unnormalize` function to rescale the
    images’ values to the range [0, 1]:'
  id: totrans-610
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示几张图像及其标签，以便我们快速了解数据集。为此，我们首先需要一个辅助的 `unnormalize` 函数，将图像的值重新缩放到 [0, 1] 范围：
- en: '[PRE284]'
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '[PRE285]'
  id: totrans-612
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE285]'
- en: '[PRE286]'
  id: totrans-613
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE286]'
- en: '[PRE287]'
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE287]'
- en: '[PRE288]'
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE288]'
- en: '[PRE289]'
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '[PRE290]'
  id: totrans-617
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE290]'
- en: '[PRE291]'
  id: totrans-618
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE291]'
- en: '[PRE292]'
  id: totrans-619
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE292]'
- en: '[PRE293]'
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE293]'
- en: '[PRE294]'
  id: totrans-621
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE294]'
- en: '[PRE295]'
  id: totrans-622
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE295]'
- en: '[PRE296]'
  id: totrans-623
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE296]'
- en: '[PRE297]'
  id: totrans-624
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE297]'
- en: '[PRE298]'
  id: totrans-625
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE298]'
- en: '[PRE299]'
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE299]'
- en: 'Here are the results:'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是结果：
- en: '![Figure 11.18 – A set of four images with their associated anime labels](img/B19629_11_18.jpg)'
  id: totrans-628
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.18 – 一组四张图片及其相关的动漫标签](img/B19629_11_18.jpg)'
- en: Figure 11.18 – A set of four images with their associated anime labels
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.18 – 一组四张图片及其相关的动漫标签
- en: As we can see in the preceding figure, the dataset is made up of images of faces,
    and the labels are the equivalent pictures with some drawing and anime style applied.
    These images were generated using Stable Diffusion and ControlNet; see how to
    do that yourself in the *There’s* *more…* section.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，数据集由面部图像组成，标签是应用了绘画和动漫风格的相应图片。这些图片是使用 Stable Diffusion 和 ControlNet 生成的；请参阅
    *There’s* *more…* 部分了解如何自行完成此操作。
- en: 'Now we instantiate the model class. Here, we reuse the existing `mobilenetv3_large_100`
    implementation provided in the SMP library with U-Net++ architecture. We specify
    the input and output channels to be `3`, using the `in_channels` and `n_classes`
    parameters respectively. We also reuse `imagenet` weights for the encoder. Here
    is the code:'
  id: totrans-631
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们实例化模型类。在这里，我们重用了SMP库中提供的带有U-Net++架构的现有`mobilenetv3_large_100`实现。我们分别使用`in_channels`和`n_classes`参数，指定输入和输出通道为`3`。我们还重用了`imagenet`的编码器权重。以下是代码：
- en: '[PRE300]'
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE300]'
- en: '[PRE301]'
  id: totrans-633
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE301]'
- en: '[PRE302]'
  id: totrans-634
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE302]'
- en: '[PRE303]'
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE303]'
- en: '[PRE304]'
  id: totrans-636
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE304]'
- en: '[PRE305]'
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE305]'
- en: '[PRE306]'
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE306]'
- en: Note
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more about the SMP library, refer to the *Semantic segmentation using transfer
    learning* recipe of [*Chapter 10*](B19629_10.xhtml#_idTextAnchor255).
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 关于SMP库的更多信息，请参考[*第10章*](B19629_10.xhtml#_idTextAnchor255)中的*语义分割与迁移学习*章节。
- en: 'Now, we implement the VGG perceptual loss as follows:'
  id: totrans-641
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们实现VGG感知损失如下：
- en: '[PRE307]'
  id: totrans-642
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE307]'
- en: '[PRE308]'
  id: totrans-643
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE308]'
- en: '[PRE309]'
  id: totrans-644
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE309]'
- en: '[PRE310]'
  id: totrans-645
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE310]'
- en: '[PRE311]'
  id: totrans-646
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE311]'
- en: '[PRE312]'
  id: totrans-647
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE312]'
- en: '[PRE313]'
  id: totrans-648
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE313]'
- en: '[PRE314]'
  id: totrans-649
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE314]'
- en: '[PRE315]'
  id: totrans-650
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE315]'
- en: '[PRE316]'
  id: totrans-651
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE316]'
- en: '[PRE317]'
  id: totrans-652
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE317]'
- en: '[PRE318]'
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE318]'
- en: '[PRE319]'
  id: totrans-654
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE319]'
- en: '[PRE320]'
  id: totrans-655
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE320]'
- en: '[PRE321]'
  id: totrans-656
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE321]'
- en: '[PRE322]'
  id: totrans-657
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE322]'
- en: '[PRE323]'
  id: totrans-658
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE323]'
- en: '[PRE324]'
  id: totrans-659
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE324]'
- en: '[PRE325]'
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE325]'
- en: '[PRE326]'
  id: totrans-661
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE326]'
- en: '[PRE327]'
  id: totrans-662
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE327]'
- en: '[PRE328]'
  id: totrans-663
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE328]'
- en: '[PRE329]'
  id: totrans-664
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE329]'
- en: '[PRE330]'
  id: totrans-665
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE330]'
- en: '[PRE331]'
  id: totrans-666
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE331]'
- en: '[PRE332]'
  id: totrans-667
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE332]'
- en: '[PRE333]'
  id: totrans-668
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE333]'
- en: '[PRE334]'
  id: totrans-669
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE334]'
- en: '[PRE335]'
  id: totrans-670
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE335]'
- en: '[PRE336]'
  id: totrans-671
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE336]'
- en: '[PRE337]'
  id: totrans-672
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE337]'
- en: '[PRE338]'
  id: totrans-673
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE338]'
- en: '[PRE339]'
  id: totrans-674
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE339]'
- en: '[PRE340]'
  id: totrans-675
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE340]'
- en: '[PRE341]'
  id: totrans-676
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE341]'
- en: '[PRE342]'
  id: totrans-677
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE342]'
- en: '[PRE343]'
  id: totrans-678
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE343]'
- en: '[PRE344]'
  id: totrans-679
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE344]'
- en: '[PRE345]'
  id: totrans-680
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE345]'
- en: 'In this implementation, we have two methods:'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 在此实现中，我们有两个方法：
- en: The `init` function, defining all the blocks and setting them as non-trainable
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init`函数，定义所有模块并将其设置为不可训练'
- en: The `forward` function, resizing the image to 224x224 (the original VGG input
    shape) and computing the loss for each block
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forward`函数，将图像调整为224x224（原始VGG输入形状），并计算每个模块的损失'
- en: 'Next, we define the optimizer, an exponential learning rate scheduler, and
    the VGG loss, as well as the weights of the style and content loss:'
  id: totrans-684
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义优化器、指数学习率调度器、VGG损失以及风格和内容损失的权重：
- en: '[PRE346]'
  id: totrans-685
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE346]'
- en: '[PRE347]'
  id: totrans-686
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE347]'
- en: '[PRE348]'
  id: totrans-687
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE348]'
- en: '[PRE349]'
  id: totrans-688
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE349]'
- en: '[PRE350]'
  id: totrans-689
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE350]'
- en: '[PRE351]'
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE351]'
- en: Note
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The style loss (that is, the VGG perceptual loss) is by default much larger
    than the content loss (that is, the L1 loss). So, here we counterbalance that
    by applying a low weight to the style loss.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 风格损失（即VGG感知损失）通常远大于内容损失（即L1损失）。因此，在这里，我们通过对风格损失施加较低的权重来进行平衡。
- en: 'Train the model over 50 epochs and store the losses for the train and test
    sets. To do so, let’s use the `train_style_transfer` function available in the
    GitHub repository ([https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb](https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb)):'
  id: totrans-693
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在50个epoch内训练模型，并存储训练集和测试集的损失。为此，我们可以使用GitHub仓库中提供的`train_style_transfer`函数（[https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb](https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_11/chapter_11.ipynb)）：
- en: '[PRE352]'
  id: totrans-694
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE352]'
- en: '[PRE353]'
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE353]'
- en: '[PRE354]'
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE354]'
- en: '[PRE355]'
  id: totrans-697
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE355]'
- en: '[PRE356]'
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE356]'
- en: '[PRE357]'
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE357]'
- en: '[PRE358]'
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE358]'
- en: '[PRE359]'
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE359]'
- en: '[PRE360]'
  id: totrans-702
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE360]'
- en: '[PRE361]'
  id: totrans-703
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE361]'
- en: Note
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'This function is a typical training loop as we implemented many times already.
    The only difference is the loss computation, which is computed as follows:'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数是一个典型的训练循环，和我们已经实现过多次的训练过程相似。唯一的区别是损失计算，计算方法如下：
- en: '`style_loss =` `vgg_loss(outputs, labels)`'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: '`style_loss =` `vgg_loss(outputs, labels)`'
- en: '`content_loss =` `torch.nn.functional.l1_loss(outputs, labels)`'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: '`content_loss =` `torch.nn.functional.l1_loss(outputs, labels)`'
- en: '`loss = style_loss_weight*style_loss +` `content_loss_weight*content_loss`'
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: '`loss = style_loss_weight*style_loss +` `content_loss_weight*content_loss`'
- en: 'Plot the loss as a function of the epoch for the train and test sets:'
  id: totrans-709
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将损失图作为epoch的函数绘制，分别对应训练集和测试集：
- en: '[PRE362]'
  id: totrans-710
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE362]'
- en: '[PRE363]'
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE363]'
- en: '[PRE364]'
  id: totrans-712
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE364]'
- en: '[PRE365]'
  id: totrans-713
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE365]'
- en: '[PRE366]'
  id: totrans-714
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE366]'
- en: '[PRE367]'
  id: totrans-715
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE367]'
- en: 'Here are the results:'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是结果：
- en: '![Figure 11.19 – Train and test losses as a function of the epoch for the style
    transfer network](img/B19629_11_19.jpg)'
  id: totrans-717
  prefs: []
  type: TYPE_IMG
  zh: '![图11.19 – 风格转移网络的训练和测试损失随epoch的变化](img/B19629_11_19.jpg)'
- en: Figure 11.19 – Train and test losses as a function of the epoch for the style
    transfer network
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.19 – 风格转移网络的训练和测试损失随epoch的变化
- en: As we can see in the preceding figure, the model is learning but tends to overfit
    slightly as the test loss does not decrease significantly anymore after about
    40 epochs.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，模型在学习，但随着测试损失在大约40个epoch后不再显著下降，似乎有轻微的过拟合。
- en: 'Finally, test the trained model on a bunch of images in the test set and display
    the results:'
  id: totrans-720
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在测试集的一组图像上测试训练好的模型，并展示结果：
- en: '[PRE368]'
  id: totrans-721
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE368]'
- en: '[PRE369]'
  id: totrans-722
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE369]'
- en: '[PRE370]'
  id: totrans-723
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE370]'
- en: '[PRE371]'
  id: totrans-724
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE371]'
- en: '[PRE372]'
  id: totrans-725
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE372]'
- en: '[PRE373]'
  id: totrans-726
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE373]'
- en: '[PRE374]'
  id: totrans-727
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE374]'
- en: '[PRE375]'
  id: totrans-728
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE375]'
- en: '[PRE376]'
  id: totrans-729
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE376]'
- en: '[PRE377]'
  id: totrans-730
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE377]'
- en: '[PRE378]'
  id: totrans-731
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE378]'
- en: '[PRE379]'
  id: totrans-732
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE379]'
- en: '[PRE380]'
  id: totrans-733
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE380]'
- en: 'Here are the results displayed:'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是显示的结果：
- en: '![Figure 11.20 – A few images and their predicted transferred style](img/B19629_11_20.jpg)'
  id: totrans-735
  prefs: []
  type: TYPE_IMG
  zh: '![图11.20 – 一些图像及其预测的风格转移效果](img/B19629_11_20.jpg)'
- en: Figure 11.20 – A few images and their predicted transferred style
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.20 – 一些图像及其预测的风格转移效果
- en: As we can see in the preceding figure, the model manages to transfer some of
    the style, by giving a smooth skin and sometimes coloring the hair. It is not
    perfect though, as the output images seem to be too bright.
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，模型成功地转移了一些风格，通过平滑皮肤并有时给头发上色。尽管如此，效果并不完美，因为输出图像看起来过于明亮。
- en: It is likely that by fine-tuning the loss weights and other hyperparameters,
    it would be possible to achieve better results.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 通过微调损失权重和其他超参数，可能可以获得更好的结果。
- en: There’s more…
  id: totrans-739
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: While this recipe showed how to use generative models such as Stable Diffusion
    to create new data in a fun way, it is possible to use it in many other applications.
    Let’s see here how to use Stable Diffusion to create your own style transfer dataset,
    as well as a few other possible applications.
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本配方展示了如何使用生成模型（如 Stable Diffusion）以有趣的方式创建新数据，但它也可以应用于许多其他场景。让我们看看如何使用 Stable
    Diffusion 创建自己的风格迁移数据集，以及一些其他可能的应用。
- en: 'As mentioned earlier, Stable Diffusion allows us to create realistic and creative
    images based on input prompts. Unfortunately, on its own, it cannot effectively
    apply a style to a given image without compromising the original image’s details
    (for example, the face shape, etc.). To do so, we can use another model based
    on Stable Diffusion: ControlNet.'
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Stable Diffusion 使我们能够基于输入提示创建逼真且富有创意的图像。不幸的是，单独使用它时，无法有效地将风格应用于给定图像而不妥协原始图像的细节（例如，面部形状等）。为此，我们可以使用基于
    Stable Diffusion 的另一个模型：ControlNet。
- en: 'ControlNet works like Stable Diffusion: it takes input prompts and generates
    output images. However, unlike Stable Diffusion, ControlNet will take control
    information as input, allowing us to specifically generate data based on a control
    image: this is exactly what was done to create the dataset of this recipe, efficiently
    adding a drawing style to faces while keeping the overall facial features.'
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 的工作原理类似于 Stable Diffusion：它接收输入提示并生成输出图像。然而，与 Stable Diffusion 不同，ControlNet
    会将控制信息作为输入，使我们能够根据控制图像特定地生成数据：这正是创建此配方数据集时所做的，通过有效地为面部添加绘画风格，同时保持整体面部特征。
- en: 'The control information can take many forms, such as the following:'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 控制信息可以有多种形式，例如：
- en: Image contours with Canny edges or Hough lines, allowing us to perform realistic
    and limitless image augmentation for image classification
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Canny 边缘或 Hough 线的图像轮廓，允许我们为图像分类执行逼真且无限的图像增强
- en: Depth estimation, allowing us to efficiently generate background images
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度估计，允许我们高效生成背景图像
- en: Semantic segmentation, allowing image augmentation for semantic segmentation
    tasks
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语义分割，允许对语义分割任务进行图像增强
- en: Pose estimation, generating more images with people in a given pose, which can
    be useful for object detection, semantic segmentation, and more
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姿态估计，生成具有特定姿势的人物图像，这对目标检测、语义分割等非常有用
- en: Much more, such as scribbles and normal maps
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有更多内容，比如涂鸦和法线图
- en: Note
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: The Canny edge detector and Hough line transform are typical image processing
    algorithms, allowing us to detect edges and straight lines in images, respectively.
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: Canny 边缘检测器和 Hough 线变换是典型的图像处理算法，分别允许我们检测图像中的边缘和直线。
- en: 'As a concrete example, in the following figure, using an input image and the
    computed Canny edges as input, as well as a text prompt such as *A realistic cute
    shiba inu in a fluffy basket*, ControlNet allows us to generate a new image really
    close to the first one. Refer to the following figure:'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个具体的例子，在下图中，使用输入图像和计算出的 Canny 边缘作为输入，再加上类似 *A realistic cute shiba inu in
    a fluffy basket* 的文本提示，ControlNet 使我们能够生成一个非常接近第一张图像的新图像。请参考下图：
- en: '![Figure 11.21 – On the left, the input image; at the center, the computed
    Canny edges; and on the right, the generated image with ControlNet and the prompt
    “A realistic cute shiba inu in a fluffy basket”](img/B19629_11_21.jpg)'
  id: totrans-752
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.21 – 左侧是输入图像；中间是计算出的 Canny 边缘；右侧是使用 ControlNet 和提示语“A realistic cute
    shiba inu in a fluffy basket”生成的图像](img/B19629_11_21.jpg)'
- en: Figure 11.21 – On the left, the input image; at the center, the computed Canny
    edges; and on the right, the generated image with ControlNet and the prompt “A
    realistic cute shiba inu in a fluffy basket”
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.21 – 左侧是输入图像；中间是计算出的 Canny 边缘；右侧是使用 ControlNet 和提示语“A realistic cute shiba
    inu in a fluffy basket”生成的图像
- en: 'There are several ways to install and use ControlNet, but the official repository
    can be installed with the following commands:'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以安装和使用 ControlNet，但可以使用以下命令安装官方库：
- en: '[PRE381]'
  id: totrans-755
  prefs: []
  type: TYPE_PRE
  zh: '[PRE381]'
- en: 'From there, you have to download the models specifically for your needs, available
    on HuggingFace. For example, you can download the Canny model with the following
    command:'
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，你需要根据自己的需求下载特定的模型，这些模型可以在 HuggingFace 上找到。例如，你可以使用以下命令下载 Canny 模型：
- en: '[PRE382]'
  id: totrans-757
  prefs: []
  type: TYPE_PRE
  zh: '[PRE382]'
- en: Note
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: The downloaded file is more than 6 GB, so this might take time.
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的文件超过 6 GB，因此可能需要一些时间。
- en: Finally, you can launch ControlNet UI with the following command line, `python
    gradio_canny2image.py`, and then follow the instructions by going to the created
    localhost, `http://0.0.0.0:7860`.
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以通过以下命令启动 ControlNet UI，`python gradio_canny2image.py`，然后按照提示访问创建的本地地址，`http://0.0.0.0:7860`。
- en: Using ControlNet and Stable Diffusion, given a powerful enough computer, you
    can now generate almost limitless new images, allowing you to train really robust
    and well-regularized models for computer vision.
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ControlNet 和 Stable Diffusion，在拥有足够强大计算机的情况下，你现在可以生成几乎无限的新图像，使你能够训练出真正强大且规范化良好的计算机视觉模型。
- en: See also
  id: totrans-762
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Paper on the U-Net++ architecture: https://arxiv.org/abs/1807.10165'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于 U-Net++ 架构的论文：[https://arxiv.org/abs/1807.10165](https://arxiv.org/abs/1807.10165)
- en: 'More about neural style transfer: https://en.wikipedia.org/wiki/Neural_style_transfer'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多关于神经风格迁移的内容：[https://en.wikipedia.org/wiki/Neural_style_transfer](https://en.wikipedia.org/wiki/Neural_style_transfer)
- en: 'The Wikipedia page about Stable Diffusion: https://en.wikipedia.org/wiki/Stable_Diffusion'
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于稳定扩散（Stable Diffusion）的维基百科页面：[https://en.wikipedia.org/wiki/Stable_Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion)
- en: 'The paper on perceptual loss: https://arxiv.org/pdf/1603.08155.pdf'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于感知损失（Perceptual Loss）的论文：[https://arxiv.org/pdf/1603.08155.pdf](https://arxiv.org/pdf/1603.08155.pdf)
- en: This recipe was inspired by https://medium.com/@JMangia/optimize-a-face-to-cartoon-style-transfer-model-trained-quickly-on-small-style-dataset-and-50594126e792
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个配方灵感来自于 [https://medium.com/@JMangia/optimize-a-face-to-cartoon-style-transfer-model-trained-quickly-on-small-style-dataset-and-50594126e792](https://medium.com/@JMangia/optimize-a-face-to-cartoon-style-transfer-model-trained-quickly-on-small-style-dataset-and-50594126e792)
- en: 'The official ControlNet repository: https://github.com/lllyasviel/ControlNet'
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方 ControlNet 仓库：[https://github.com/lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet)
- en: 'An advanced way of using ControlNet, allowing us to compose several models:
    https://github.com/Mikubill/sd-webui-controlnet'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种高级的使用 ControlNet 的方式，允许我们组合多个模型：[https://github.com/Mikubill/sd-webui-controlnet](https://github.com/Mikubill/sd-webui-controlnet)
- en: 'The Wikipedia page about the Canny edge detector: [https://en.wikipedia.org/wiki/Canny_edge_detector](https://en.wikipedia.org/wiki/Canny_edge_detector)'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于 Canny 边缘检测器的维基百科页面：[https://en.wikipedia.org/wiki/Canny_edge_detector](https://en.wikipedia.org/wiki/Canny_edge_detector)
