- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Classification with TensorFlow
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 进行分类
- en: In the last chapter, we covered linear regression with TensorFlow, where we
    looked at both simple and multiple linear regression; we also explored various
    metrics for evaluating regression models. We concluded the chapter with a real-world
    use case, where we built a salary prediction model, and we used this to predict
    the salaries of new employees based on a set of features. In this chapter, we
    will continue with modeling in TensorFlow – this time, by exploring classification
    problems with TensorFlow.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讲解了 TensorFlow 中的线性回归，其中我们讨论了简单线性回归和多元线性回归；同时我们还探索了评估回归模型的各种指标。我们以一个实际用例结束了这一章，其中我们构建了一个薪资预测模型，并使用该模型根据一组特征预测新员工的薪资。在本章中，我们将继续使用
    TensorFlow 进行建模——这一次，我们将探索使用 TensorFlow 进行分类问题的处理。
- en: We will start by looking at the concept of classification modeling, after which
    we will examine the various evaluation metrics for classification modeling and
    how we can apply them to various use cases. We will look at binary, multi-class,
    and multi-label classification modeling. Finally, we will walk through a case
    study, putting all we have learned into practice by building a binary classification
    model to predict whether a student will drop out of university or not.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从分类建模的概念开始，然后探讨分类建模的各种评估指标，以及如何将它们应用于不同的用例。我们将讨论二分类、多分类和多标签分类建模。最后，我们将通过一个案例研究，实践我们所学的知识，构建一个二分类模型来预测学生是否会辍学。
- en: By the end of this chapter, you should clearly understand what classification
    modeling in machine learning is and also be able to differentiate between binary,
    multi-class, and multi-label classification problems. You will be familiar with
    how to build, compile, train, predict, and evaluate classification models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该清楚地理解机器学习中的分类建模是什么，并且能够区分二分类、多分类和多标签分类问题。你将熟悉如何构建、编译、训练、预测和评估分类模型。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Classification with TensorFlow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 进行分类
- en: A student dropout prediction
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学生辍学预测
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will use Google Colab to run the coding exercise, and you
    will need to install Python >= 3.8.0, along with the following packages, which
    can be installed using the `pip` `install` command:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 Google Colab 来运行编码练习，你需要安装 Python >= 3.8.0，并安装以下包，使用 `pip` `install`
    命令进行安装：
- en: '`tensorflow >=` `2.7.0`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow >=` `2.7.0`'
- en: '`tensorflow-datasets ==` `4.4.0`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow-datasets ==` `4.4.0`'
- en: '`Pillow ==` `8.4.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pillow ==` `8.4.0`'
- en: '`pandas ==` `1.3.4`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas ==` `1.3.4`'
- en: '`numpy ==` `1.21.4`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy ==` `1.21.4`'
- en: '`scipy ==` `1.7.3`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scipy ==` `1.7.3`'
- en: 'The code bundle for this book is available at the following GitHub link: [https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate).
    Solutions to all the exercises can also be found at this link.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包可通过以下 GitHub 链接获取：[https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate)。所有练习的解决方案也可以在该链接中找到。
- en: Classification with TensorFlow
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 进行分类
- en: In [*Chapter 1*](B18118_01.xhtml#_idTextAnchor014), *Introduction to Machine
    Learning*, we talked about supervised learning and briefly talked about classification
    modeling. Classification modeling involves predicting classes in our target variable.
    When the classes we try to predict are binary (for example, trying to predict
    whether a pet is either a dog or a cat, whether an email is spam or not, or whether
    a patient has cancer or not), this type of classification scenario is referred
    to as **binary classification**.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第一章*](B18118_01.xhtml#_idTextAnchor014)，*机器学习简介*中，我们讨论了监督学习，并简要介绍了分类建模。分类建模涉及预测目标变量中的类别。当我们试图预测的类别是二分类时（例如，预测宠物是狗还是猫，邮件是否为垃圾邮件，或病人是否患有癌症），这种分类场景被称为**二分类**。
- en: Then again, we may be faced with a problem where we want to build an ML model
    to predict the different breeds of dogs. In this case, we have more than two classes,
    so this type of classification is called **multi-class classification**. Just
    like binary classification problems, in multi-class classification, our target
    variable can only belong to one class out of multiple classes – our model will
    select either a bulldog, a German shepherd, or a pit bull. Here, the classes are
    *mutually exclusive*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们可能面临这样的问题，我们想要构建一个机器学习模型来预测不同品种的狗。在这种情况下，我们有多个类别，因此这种类型的分类被称为**多类分类**。就像二元分类问题一样，在多类分类中，我们的目标变量只能属于多个类别中的一个
    – 我们的模型将选择斗牛犬、德国牧羊犬或斗牛犬。在这里，类别是*互斥的*。
- en: 'Imagine that you are building a movie classifier, and you want to classifier
    a blockbuster movie such as *Avengers: Endgame*. This movie belongs to the action,
    adventure, superhero, epic, fantasy, and science fiction genres. From the movie’s
    label, we can see that our target variable belongs to more than one genre; hence,
    this type of classification is called **multi-label classification**, where the
    output class has more than one target label.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在构建一个电影分类器，你想要分类一部如*复仇者联盟：终局之战*这样的大片。这部电影属于动作、冒险、超级英雄、史诗、奇幻和科幻类别。从电影的标签中，我们可以看到我们的目标变量属于多个流派；因此，这种类型的分类被称为**多标签分类**，其中输出类别有多个目标标签。
- en: Unlike in multi-class classification, where each example can only belong to
    one class, in multi-label classification, each example can belong to multiple
    labels.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 不像多类分类，每个例子只能属于一个类别，而在多标签分类中，每个例子可以属于多个标签。
- en: Unlike binary and multi-class, where each example can only belong to one class,
    in multi-label classification, each example can belong to multiple classes, just
    like the *Avengers* movie. Now that we have looked at the three main types of
    classification problems, the next question is, how do we evaluate classification
    models? What are the key metrics we need to look out for? Let us look at this
    now and understand what they mean and how to best apply them to various classification
    problems.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 不像二元和多类分类，每个例子只能属于一个类别，在多标签分类中，每个例子可以属于多个类别，就像*复仇者联盟*电影一样。现在我们已经看过三种主要的分类问题类型，下一个问题是，我们如何评估分类模型？我们需要关注哪些关键指标？现在让我们来看一下并理解它们的含义以及如何最好地应用它们到各种分类问题中。
- en: Evaluating classification models
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: Unlike regression problems, where we have numeric values in our target variable,
    in classification modeling, we have established that our output is classes. Hence,
    we cannot use the same metrics we used to evaluate our regression models in [*Chapter
    3*](B18118_03.xhtml#_idTextAnchor065), *Linear Regression with TensorFlow*, since
    our output is not continuous numerical values but classes. For a classification
    problem, let’s say we build a spam filtering system to classify a client’s emails.
    The client has 250 emails that are not spam and another 250 emails that are spam.
    Using our spam filtering model, we are able to correctly flag 230 spam messages
    and also correctly identify 220 non-spam messages as not spam.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归问题不同，在回归模型中，我们的目标变量是数值型的，而在分类建模中，我们已经确定输出是类别。因此，我们不能使用用于评估回归模型的相同指标在[*第 3
    章*](B18118_03.xhtml#_idTextAnchor065)，*TensorFlow 中的线性回归*中使用，因为我们的输出不是连续的数值，而是类别。对于分类问题，比如我们建立一个垃圾邮件过滤系统来分类客户的电子邮件。客户有
    250 封非垃圾邮件和另外 250 封垃圾邮件。使用我们的垃圾邮件过滤模型，我们能够正确标记 230 封垃圾邮件并且正确识别 220 封非垃圾邮件。
- en: When our spam filter correctly identifies a spam message as spam (which is what
    we want), we call this a **true positive**, and when the model misclassifies a
    spam message as not spam, this is called a **false negative**. In a case where
    the model correctly identifies a non-spam email as not spam, this is called a
    **true negative**; however, we occasionally find important emails in our spam
    folder, and these messages were wrongly filtered as spam when they were not. This
    scenario is called a **false positive**. We can now use these details to evaluate
    the performance of our spam-filtering model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的垃圾邮件过滤器正确将一个垃圾邮件标记为垃圾邮件（这正是我们想要的），我们称之为**真正例**；当模型错误地将一个垃圾邮件误分类为非垃圾邮件时，这被称为**假负例**。在模型正确将非垃圾邮件识别为非垃圾邮件的情况下，这称为**真负例**；然而，我们偶尔会在我们的垃圾邮件文件夹中找到重要的邮件，这些邮件在被错误地归类为垃圾邮件时并不是垃圾。这种情况被称为**假正例**。现在我们可以使用这些细节来评估我们的垃圾邮件过滤模型的性能。
- en: 'Let us list the important details we now know:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们列出我们现在知道的重要细节：
- en: '**Total spam messages**: 250 samples'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垃圾邮件总数**：250个样本'
- en: '**Correctly predicted spam messages (true positives)**: 230 samples'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正确预测的垃圾邮件（真正例）**：230个样本'
- en: '**Wrongly predicted spam messages (false negatives or a type 2 error)**: 20
    samples'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误预测的垃圾邮件（假阴性或类型 2 错误）**：20个样本'
- en: '**Total non-spam messages**: 250 samples'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非垃圾邮件总数**：250个样本'
- en: '**Correctly predicted non-spam messages (true negatives)**: 220 samples'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正确预测的非垃圾邮件（真负例）**：220个样本'
- en: '**Wrongly predicted spam messages (false positive or a type 1 error)**: 30
    samples'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误预测的垃圾邮件（假阳性或类型 1 错误）**：30个样本'
- en: Now that we have gathered the key details, let us now use them to learn how
    to evaluate classification models. To do this, we will have to talk about the
    confusion matrix next.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经收集了关键细节，接下来让我们使用这些信息来学习如何评估分类模型。为此，我们接下来将讨论混淆矩阵。
- en: Confusion matrix
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: The **confusion matrix** is an error matrix that displays the performance of
    a classification model in a tabular form, containing both the true values and
    the predicted values, as illustrated in *Figure 4**.1*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**是一个错误矩阵，它以表格形式展示分类模型的表现，包含真实值和预测值，如*图 4.1*所示。'
- en: '![Figure 4.1 – The confusion matrix](img/B18118_04_001.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 混淆矩阵](img/B18118_04_001.jpg)'
- en: Figure 4.1 – The confusion matrix
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 混淆矩阵
- en: Using the confusion matrix, we can calculate various classification evaluation
    metrics such as accuracy, precision, recall, and F1 score. In the confusion matrix,
    we can see the predicted class at the top, showing emails predicted as spam in
    the first column and those predicted as not spam in the second column, while the
    rows show us the true values. Here, we can see in the first row the true spam
    class and the true not-spam class. When we put it all together, we can see the
    true values and the wrong prediction in a tabular fashion, which gives us a quick
    view of the model and its performance across both classes. Let’s use these details
    to compute key performance metrics for our model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用混淆矩阵，我们可以计算各种分类评估指标，如准确率、精确度、召回率和F1分数。在混淆矩阵中，我们可以看到预测类别位于顶部，第一列显示预测为垃圾邮件的邮件，第二列显示预测为非垃圾邮件的邮件，而行则展示真实值。在这里，我们可以看到第一行显示的是真实的垃圾邮件类别和真实的非垃圾邮件类别。当我们将所有这些信息整合在一起时，我们可以以表格的形式看到真实值和错误预测，这为我们提供了模型及其在两类之间的表现的快速视图。让我们使用这些细节来计算模型的关键性能指标。
- en: '**Accuracy** is quite intuitive, as it is the sum of the correctly predicted
    labels over the total available data. We can represent this with the following
    equation:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率**是非常直观的，它是正确预测标签的总和与可用数据总数之比。我们可以用以下方程式表示：'
- en: Accuracy =  TP + TN _______________  (TP + FP + TN + FN)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率 =  TP + TN  _______________  (TP + FP + TN + FN)
- en: 'Let’s add our values and see what our accuracy will look like:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加我们的数值，看看我们的准确率是多少：
- en: Accuracy =  230 + 220  ________________  (230 + 30 + 220 + 20)  = 0.90
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率 =  230 + 220   ________________  (230 + 30 + 220 + 20)  = 0.90
- en: We get an accuracy of 90%. This is potentially exciting, but let us be more
    realistic with our data. When it comes to spam emails, we will likely have more
    legitimate emails than spam emails coming into our mailbox.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了90%的准确率。这可能令人兴奋，但让我们用更现实的数据来看待它。当涉及到垃圾邮件时，我们的邮箱中可能会收到更多合法邮件，而不是垃圾邮件。
- en: 'Let’s imagine we have another client, B, with 500 emails, made up of the following
    details:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有另一个客户B，拥有500封邮件，具体细节如下：
- en: '**Total spam messages**: 40 samples'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垃圾邮件总数**：40个样本'
- en: '**Correctly predicted spam messages (true positives)**: 20 samples'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正确预测的垃圾邮件（真正例）**：20个样本'
- en: '**Wrongly predicted spam messages (false negatives or a type 2 error)**: 20
    samples'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误预测的垃圾邮件（假阴性或类型 2 错误）**：20个样本'
- en: '**Total non-spam messages**: 460 samples'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非垃圾邮件总数**：460个样本'
- en: '**Correctly predicted non-spam messages (true negatives)**: 430 samples'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正确预测的非垃圾邮件（真负例）**：430个样本'
- en: '**Wrongly predicted spam messages (false positive or a type 1 error)**: 30
    samples'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误预测的垃圾邮件（假阳性或类型 1 错误）**：30个样本'
- en: 'If we compute the accuracy for client B, we have:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们计算客户B的准确率，结果为：
- en: Accuracy =  20 + 430 ______________  20 + 30 + 430 + 20  = 0.90
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率 =  20 + 430   ______________  20 + 30 + 430 + 20  = 0.90
- en: Again, we arrive at an accuracy of 90 percent, yet our model could only predict
    50 percent of the spam emails as spam. This shows us that accuracy may not always
    be the best measure, especially when we deal with a use case made up of imbalanced
    data such as email classification, fraud detection, or disease detection.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 再次计算，我们得到了90%的准确率，但模型只能将50%的垃圾邮件正确预测为垃圾邮件。这表明，准确率可能并不是最佳的衡量标准，尤其是在处理像电子邮件分类、欺诈检测或疾病检测这类不平衡数据的使用案例时。
- en: 'To get a better sense of how our model is doing, we will now turn our attention
    to precision and recall. Referring back to *Figure 4**.2*, the ratio of the true
    positive to the positive class in the ground truth is called *sensitivity* or
    *recall*, or the *true positive rate* in ML lingo, and it is represented by the
    following equation:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解我们的模型表现，我们现在将关注精确度和召回率。回顾*图 4.2*，实际正类与正类的比例被称为*敏感性*或*召回率*，在机器学习术语中也称为*真实正例率*，它通过以下公式表示：
- en: Recall =  TP _ (TP + FN)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率 =  TP _ (TP + FN)
- en: 'Whereas *precision* is the ratio of the true positive to the positive class
    predicted by the model, and we also represent it as an equation:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度*是模型预测的正类与实际正类的比例，我们也可以用一个公式表示它：'
- en: Precision =  TP _ (TP + FP)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度 =  TP _ (TP + FP)
- en: 'Using client B, let us calculate our model’s performance using precision and
    recall:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用客户B，我们来计算模型的精确度和召回率：
- en: Precision for case study 2 =  20 _ (20 + 30)  = 0.4
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 案例研究 2 的精确度 =  20 _ (20 + 30)  = 0.4
- en: Recall for case study 2 =  20 _ (20 + 20)  = 0.5
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 案例研究 2 的召回率 =  20 _ (20 + 20)  = 0.5
- en: 'Now, we can see how badly our model is, although it has a high accuracy on
    the entirety of the data. Another important metric that we will come across for
    classification tasks is the F1 score. The *F1 score* combines recall and precision,
    and we arrive at it by computing the harmonic mean of precision and recall:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到尽管模型在整体数据上的准确率较高，但其表现却不尽如人意。另一个我们会遇到的重要指标是 F1 分数。*F1 分数*结合了召回率和精确度，我们通过计算精确度和召回率的调和均值来得到它：
- en: F1 Score = 2 *  precision * recall  _____________  (precision + recall)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数 = 2 *  精确度 * 召回率  _____________  (精确度 + 召回率)
- en: 'Let us calculate the F1 score for the second case study:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来计算第二个案例研究的 F1 分数：
- en: F1 Score = 2 *  0.4 * 0.5 _ (0.4 + 0.5)  = 0.44
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数 = 2 *  0.4 * 0.5 _ (0.4 + 0.5)  = 0.44
- en: From our evaluation of Client B’s emails using our spam-filtering model, we
    now know we need to build a more effective model, one with much better precision
    and recall for our target class. However, achieving high precision and recall
    may not always be possible. In such a scenario, we are left with a trade-off,
    which is known as the *precision/recall trade-off*. In the case of detecting spam
    emails, we know clients are unlikely to switch to a different service provider
    should a few spam messages find their way into their inbox; however, they will
    be upset if they fail to find important messages in their inbox. In this instance,
    we will aim to achieve a higher recall. Conversely, let’s say we build an early
    cancer detection system, where our focus will be on achieving high precision to
    minimize false positives. It is important to note that precision and recall are
    not mutually exclusive, and we can achieve both high precision and recall with
    a well-tuned model in many instances.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用我们的垃圾邮件过滤模型评估客户B的电子邮件，我们现在知道需要构建一个更有效的模型，一个对目标类别具有更高精确度和召回率的模型。然而，达到高精确度和召回率并非总是可能的。在这种情况下，我们面临一个权衡，这就是所谓的*精确度/召回率权衡*。在检测垃圾邮件的情况下，我们知道如果一些垃圾邮件进入收件箱，客户不太可能换用其他服务提供商；然而，如果他们未能在收件箱中找到重要邮件，他们会感到不满。在这种情况下，我们将致力于实现更高的召回率。相反，假设我们构建了一个早期癌症检测系统，重点将放在提高精确度，以减少假阳性。需要注意的是，精确度和召回率并非互斥的，在许多情况下，我们可以通过调优模型来同时实现高精确度和高召回率。
- en: We have now covered some important classification metrics. Now, let us look
    at a case study (a student dropout prediction) where we will build and evaluate
    our classification models using different modules from TensorFlow and scikit-learn.
    Let’s jump in.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了一些重要的分类指标。接下来，我们来看一个案例研究（学生辍学预测），在其中我们将使用 TensorFlow 和 scikit-learn
    的不同模块来构建和评估分类模型。让我们开始吧。
- en: A student dropout prediction
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学生辍学预测
- en: In [*Chapter 3*](B18118_03.xhtml#_idTextAnchor065), *Linear Regression with
    TensorFlow*, you began your journey using TensorFlow to build a salary prediction
    model. Your boss was impressed, and now that you are fully settled in the data
    team, your manager wants you to work with a new client. Your job is to help them
    build a model that will predict whether a student will drop out of university
    or not, as this will help them support such students, thus preventing them from
    dropping out of school. Your manager has given you authorization and the task
    is now yours. For this task, historical data was made available to you by your
    client. Just like in [*Chapter 3*](B18118_03.xhtml#_idTextAnchor065), *Linear
    Regression with TensorFlow*, you had a rewarding chat with the client, and you
    identified the task as a binary classification problem. Let’s open the notebook
    labeled `Classification with TensorFlow` from the GitHub repository and get started.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第3章*](B18118_03.xhtml#_idTextAnchor065)《使用 TensorFlow 进行线性回归》中，你开始使用 TensorFlow
    构建薪资预测模型的旅程。你的老板印象深刻，现在你已经完全融入数据团队，经理希望你为一个新客户工作。你的任务是帮助他们构建一个模型，预测学生是否会辍学，这将帮助他们支持这些学生，从而防止他们辍学。经理已经授权你，并且这个任务现在属于你。为了完成这个任务，客户向你提供了历史数据。就像在[*第3章*](B18118_03.xhtml#_idTextAnchor065)《使用
    TensorFlow 进行线性回归》中一样，你与客户进行了富有成效的交流，并将任务识别为一个二分类问题。让我们打开 GitHub 仓库中标记为`Classification
    with TensorFlow`的笔记本，开始吧。
- en: Loading the data
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Let’s start by loading the historical data that we received from our client:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从加载客户提供的历史数据开始：
- en: 'We will start by importing the TensorFlow libraries that we will use to execute
    our task:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先导入用于执行任务的 TensorFlow 库：
- en: '[PRE0]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After running the code, we can see the version of TensorFlow we will use. In
    my case, it’s 2.8.0 at the time of writing. You will most likely have a newer
    version, but it should work just as well:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，我们可以看到将使用的 TensorFlow 版本。在我写这篇文章时，它是 2.8.0。你很可能会有一个更新的版本，但它应该同样可以正常工作：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then, we will import some additional libraries that will help us simplify our
    workflow.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将导入一些额外的库，帮助我们简化工作流程。
- en: '[PRE7]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We previously discussed most of the libraries that we will use here, except
    for the last line of the code block, which we will use to import the confusion
    matrix and classification report from the scikit-learn library. We will use these
    functions to evaluate our model’s performance. If you are unclear about the other
    libraries, refer to [*Chapter 3*](B18118_03.xhtml#_idTextAnchor065), *Linear Regression
    with TensorFlow*, before proceeding with this case study.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过大部分将在这里使用的库，除了代码块的最后一行，它将用来从 scikit-learn 库中导入混淆矩阵和分类报告。我们将使用这些函数来评估模型的性能。如果你不清楚其他库的用法，可以参考[*第3章*](B18118_03.xhtml#_idTextAnchor065)《使用
    TensorFlow 进行线性回归》来了解，之后再继续本案例的学习。
- en: 'Now that we have loaded all the necessary libraries, let us make a DataFrame
    for easy processing:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经加载了所有必要的库，让我们创建一个 DataFrame 以便于处理：
- en: '[PRE19]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: When we run the code, if everything works as expected, we should get the first
    five rows of our dataset.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，如果一切正常，应该会显示数据集的前五行。
- en: '![Figure 4.2 – A DataFrame showing the first five rows of our dataset](img/B18118_04_002.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 显示数据集前五行的 DataFrame](img/B18118_04_002.jpg)'
- en: Figure 4.2 – A DataFrame showing the first five rows of our dataset
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 显示数据集前五行的 DataFrame
- en: From the output, we can see that our data is made up of numerical and categorical
    columns. Each of the rows represents a student. Upon inspection, we can see that
    we have 12 columns, namely, `Student ID`, `Student Name`, `Library`, `Resources`,
    `Finance`, `Scholarships`, `Study Time`, `Study Group`, `GPA`, `Test`, `Assignment`,
    and `Graduated`. To efficiently model our data, we need to do some data preparation,
    so let’s start with some exploratory data analysis and see what we can find.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们可以看到数据由数值型和类别型列组成。每一行代表一个学生。经过检查，我们发现有 12 列，分别是：`学生 ID`、`学生姓名`、`图书馆`、`资源`、`财务`、`奖学金`、`学习时间`、`学习小组`、`GPA`、`测试`、`作业`、`毕业`。为了高效地建模我们的数据，我们需要进行一些数据准备工作，因此让我们开始一些探索性数据分析，看看能发现什么。
- en: Exploratory data analysis
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: 'Perform the following steps to explore and analyze the data:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以探索和分析数据：
- en: We will begin the exploratory data analysis process using the `df.info()` function
    to check for `NULL` values as well as the data types in our dataset, as shown
    in *Figure 4**.3*.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`df.info()`函数开始探索性数据分析过程，以检查数据集中的`NULL`值以及数据类型，如*图 4.3*所示。
- en: '![Figure 4.3 – Information about our dataset](img/B18118_04_003.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 我们数据集的信息](img/B18118_04_003.jpg)'
- en: Figure 4.3 – Information about our dataset
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 我们数据集的信息
- en: The good news is that we have no missing values in our dataset, and yes, we
    will work with a much larger dataset than in our regression task. Here, we have
    25,000 data points representing students’ data collected from the university.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，我们的数据集没有缺失值，是的，我们将处理一个比回归任务中更大的数据集。在这里，我们有25,000个数据点，代表从大学收集的学生数据。
- en: 'The next step is to drop the irrelevant columns. By inspecting the available
    columns, we drop the `student ID` and `student name` columns, as these columns
    should have no impact on whether a student will graduate or not. Let’s do that
    here, using the `drop` function from pandas:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是删除无关的列。通过检查可用的列，我们删除了`学生 ID`和`学生姓名`列，因为这些列对学生是否毕业没有影响。我们在这里使用pandas的`drop`函数来完成这一操作：
- en: '[PRE22]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Next, let us use the `describe` function to generate key statistics of our dataset,
    as this will give us a sense of our data, as shown in *Figure 4**.4*.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们使用`describe`函数生成数据集的关键统计信息，因为这将帮助我们了解数据集的情况，如*图 4.4*所示。
- en: '![Figure 4.4 – The summary statistics of the numerical columns](img/B18118_04_004.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 数值列的摘要统计](img/B18118_04_004.jpg)'
- en: Figure 4.4 – The summary statistics of the numerical columns
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 数值列的摘要统计
- en: From *Figure 4**.4*, we can see that the mean GPA is `3.00`, the lowest GPA
    is `1.00`, and the highest GPA is `5.00`. Both the `Tes`t and `Assignment` columns
    have a minimum score of 5 and a maximum score of 15\. However, we have no sense
    of the distribution of our target column, as it is a categorical column; we will
    fix that shortly.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 4.4*中，我们可以看到平均GPA为`3.00`，最低GPA为`1.00`，最高GPA为`5.00`。`测试`和`作业`列的最低分为5，最高分为15。然而，我们对目标列的分布没有明确的了解，因为它是一个分类列；我们稍后会解决这个问题。
- en: 'Now, let us make a histogram plot of our categorical target variable:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为分类目标变量绘制一个直方图：
- en: '[PRE23]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Running this code produces the plot shown in *Figure 4**.5*. Here, we use `matplotlib`
    to plot the `Graduated` column, and we can see almost 17,500 students who successfully
    graduated and roughly 7,500 students who failed to graduate. Of course, it is
    only logical to expect a larger number of students will graduate. In ML terms,
    we have on our plate an unbalanced dataset. However, the good part is that we
    still have enough samples to train our model from the minority class. Anyway,
    don’t take my word for it; shortly, we will train our models after we complete
    the data preparation steps.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码会生成*图 4.5*所示的图表。在这里，我们使用`matplotlib`绘制`毕业`列，结果显示大约有17,500名成功毕业的学生，而大约有7,500名未能毕业的学生。当然，合理的预期是更多的学生会毕业。从机器学习的角度来看，我们处理的是一个不平衡的数据集。然而，幸运的是，我们仍然拥有足够的样本来训练来自少数类的模型。无论如何，不要只听我的话；稍后，我们将在完成数据准备步骤后训练我们的模型。
- en: '![Figure 4.5 – Summary statistics of the numeric columns](img/B18118_04_005.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – 数值列的摘要统计](img/B18118_04_005.jpg)'
- en: Figure 4.5 – Summary statistics of the numeric columns
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 数值列的摘要统计
- en: 'There are more plots in our notebook to explore, but we will keep it simple,
    since our main goal in this book is to focus on building models with TensorFlow.
    However, let’s look at one of the very important plots:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的笔记本中还有更多图表可以探索，但我们会保持简洁，因为本书的主要目标是专注于使用TensorFlow构建模型。不过，让我们看一下一个非常重要的图表：
- en: '[PRE25]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here, we create a scatterplot using `seaborn`, showing the `Library` column
    on the *x* axis and `GPA` on the *y* axis, and we use the `Graduate` column to
    color our data points, as shown in *Figure 4**.6*.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`seaborn`绘制一个散点图，显示`图书馆`列在*x*轴上，`GPA`在*y*轴上，并使用`毕业`列来为数据点着色，如*图 4.6*所示。
- en: '![Figure 4.6 – Library versus GPA](img/B18118_04_006.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 图书馆与 GPA](img/B18118_04_006.jpg)'
- en: Figure 4.6 – Library versus GPA
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 图书馆与 GPA
- en: 'From this plot, we can see that there is a good number of students with a GPA
    above 3.50 who graduated. However, don’t assume that everyone above a 3.50 GPA
    in the `Average`, `Good`, and `Excellent` columns graduated. In fact, let’s check
    this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图表中，我们可以看到有相当一部分GPA高于3.50的学生已经毕业。然而，不要认为在`平均`、`良好`和`优秀`列中，所有GPA高于3.50的学生都已经毕业。事实上，让我们来验证一下：
- en: '[PRE30]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: When we run this code, we get the total number of students who have a GPA of
    3.50 or over and dropped out. In total, we have 76 students who dropped out. Remember,
    our plot covers 25,000 data points, so don’t be surprised if you did not find
    these data points in the plot in *Figure 4**.6*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这段代码时，它返回了 GPA 在 3.50 及以上且辍学的学生总数。总共有 76 名辍学学生。记住，我们的图表覆盖了 25,000 个数据点，所以如果你在*图
    4.6*的图中没有找到这些数据点，不要惊讶。
- en: Now, let us proceed to prepare our data for modeling.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续准备数据进行建模。
- en: Data preprocessing
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'In [*Chapter 3*](B18118_03.xhtml#_idTextAnchor065), *Linear Regression with
    TensorFlow*, we emphasized the need to put our data in the right form, handle
    missing data, drop irrelevant features, convert categorical values to numeric
    values, and so on. We will continue in that spirit here:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 3 章*](B18118_03.xhtml#_idTextAnchor065)，《使用 TensorFlow 的线性回归》中，我们强调了将数据放入正确形式、处理缺失数据、删除不相关特征、将分类值转换为数值型等的必要性。我们将在这里继续沿着这个思路进行：
- en: 'Let us start by converting our labels to numerical values:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从将标签转换为数值型开始：
- en: '[PRE31]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, we assign a value of `1` to students who graduated and a value of `0`
    to students who dropped out.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将值为`1`赋给毕业的学生，将值为`0`赋给辍学的学生。
- en: 'Now, let us examine the correlation between our numerical data and our target
    variable using the `corr()` function:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`corr()`函数检查我们的数值数据与目标变量之间的相关性：
- en: '[PRE34]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: When we run the code, we get the correlation table shown in *Figure 4**.7*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们会得到*图 4.7*所示的相关性表。
- en: '![Figure 4.7 – Correlation table for our dataset](img/B18118_04_007.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 我们数据集的相关性表](img/B18118_04_007.jpg)'
- en: Figure 4.7 – Correlation table for our dataset
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 我们数据集的相关性表
- en: From the highlighted column, we can see that `GPA` has the strongest correlation
    with the `Graduated` column.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 从高亮的列中，我们可以看到`GPA`与`Graduated`列的相关性最强。
- en: 'Now, let us convert our categorical variables to numerical values. We will
    stick to using dummy variables to one-hot encode our categorical variables:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将分类变量转换为数值型变量。我们将继续使用虚拟变量（dummy variables）对分类变量进行独热编码（one-hot encoding）：
- en: '[PRE35]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Here, we drop the first column to avoid the dummy variable trap. When we run
    the code, we get a new DataFrame, as shown in *Figure 4**.8*.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们删除了第一列，以避免虚拟变量陷阱。当我们运行代码时，我们会得到一个新的 DataFrame，如*图 4.8*所示。
- en: '![Figure 4.8 – A DataFrame after one-hot encoding](img/B18118_04_008.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 独热编码后的 DataFrame](img/B18118_04_008.jpg)'
- en: Figure 4.8 – A DataFrame after one-hot encoding
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 独热编码后的 DataFrame
- en: 'Now that we have the attributes in numerical form, let’s see how correlated
    they are with our target variable:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经将特征转化为数值形式，接下来让我们看看它们与目标变量的相关性：
- en: '[PRE38]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Once we run the code, it returns the correlation of all the columns with the
    target variable, as shown in *Figure 4**.9*. Our initial numerical variables are
    still the leading correlation values.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行代码，它会返回所有列与目标变量的相关性，如*图 4.9*所示。我们的初始数值变量仍然是相关性最高的变量。
- en: '![Figure 4.9 – A correlation of the attributes with the target column](img/B18118_04_009.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – 特征与目标列的相关性](img/B18118_04_009.jpg)'
- en: Figure 4.9 – A correlation of the attributes with the target column
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 特征与目标列的相关性
- en: 'We have successfully converted our data into numerical values, so let us proceed
    to split the data into attributes (`X`) and a target (`y`):'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经成功将数据转换为数值型变量，接下来我们将数据拆分为特征（`X`）和目标变量（`y`）：
- en: '[PRE41]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Don’t forget that we need to normalize our data. So, we bring all the attributes
    to scale for our modeling process:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 别忘了，我们需要对数据进行归一化处理。因此，我们将所有特征缩放到相同的尺度，以便于建模过程：
- en: '[PRE44]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Again, we use `MinMaxScaler` from the scikit-learn library, after which we
    split our data into training and testing sets. For training, we use 80 percent
    of our data, and we keep 20 percent as our holdout data to test our model’s generalization
    capability. We set a random state to 10 to ensure that we can reproduce the same
    data split:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们使用来自 scikit-learn 库的`MinMaxScaler`，然后将数据分为训练集和测试集。在训练中，我们使用 80% 的数据，保留
    20% 作为测试数据，以测试模型的泛化能力。我们设置随机种子为 10，以确保能够复现相同的数据划分：
- en: '[PRE50]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Now we are done with data preparation, let us proceed to model building with
    TensorFlow.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备工作已经完成，让我们继续用 TensorFlow 构建模型。
- en: Model building
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型构建
- en: To build our model, we will start by creating a neural network architecture;
    here, we will use the sequential API to define the number of layers we want to
    connect sequentially. As shown in *Figure 4**.10*, we have only the input and
    output layers. Unlike in [*Chapter 3*](B18118_03.xhtml#_idTextAnchor065), *Linear
    Regression with TensorFlow*, where we predicted numeric values, our output layer
    here has only one neuron because we are dealing with a binary classification problem.
    For the output layer, the activation function used depends on the task at hand.
    When we deal with a binary classification task, we typically use the *sigmoid
    activation function*; for multi-class classification problems, we commonly use
    the *softmax activation function*; and when dealing with multi-label classification,
    we commonly use sigmoid as our activation function.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们的模型，我们将首先创建一个神经网络架构；在这里，我们将使用顺序 API 来定义我们希望顺序连接的层数。如*图 4.10*所示，我们只有输入层和输出层。与在[*第3章*](B18118_03.xhtml#_idTextAnchor065)《使用
    TensorFlow 进行线性回归》中预测数值不同，我们的输出层只有一个神经元，因为我们正在处理一个二分类问题。对于输出层，所使用的激活函数取决于当前的任务。当我们处理二分类任务时，通常使用*sigmoid
    激活函数*；对于多分类问题，我们通常使用*softmax 激活函数*；而在处理多标签分类问题时，我们通常使用 sigmoid 作为激活函数。
- en: '![Figure 4.10 – Creating a classification model in TensorFlow](img/B18118_04_010.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – 在 TensorFlow 中创建分类模型](img/B18118_04_010.jpg)'
- en: Figure 4.10 – Creating a classification model in TensorFlow
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 在 TensorFlow 中创建分类模型
- en: 'Let us proceed to compile our model. We will use *binary cross entropy* for
    our loss function when we deal with binary classification and *categorical cross
    entropy* or *sparse categorical cross entropy* when we deal with multi-class classification
    problems. In [*Chapter 5*](B18118_05.xhtml#_idTextAnchor105), *Image Classification
    with Neural Networks*, our discussion will deep-dive into activation functions
    and more, as we continue to build our understanding and application of neural
    networks:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续编译我们的模型。当我们处理二分类问题时，我们将使用*二元交叉熵*作为损失函数，而处理多分类问题时，我们将使用*类别交叉熵*或*稀疏类别交叉熵*。在[*第5章*](B18118_05.xhtml#_idTextAnchor105)《使用神经网络进行图像分类》中，我们将深入讨论激活函数等内容，随着我们继续构建对神经网络的理解和应用：
- en: '[PRE51]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Next, let us compile our model. Here, we will use accuracy as our evaluation
    metric. We will also look at other classification metrics, which we discussed
    earlier when we begin evaluating our model’s performance on test data. After we
    compile our model, the next step is to fit our model. In [*Chapter 1*](B18118_01.xhtml#_idTextAnchor014),
    *Introduction to Machine Learning*, we talked about training, validation, and
    test splits. Since we will deal with a much larger dataset, let’s use a validation
    set to assess our model’s performance at the end of each epoch, allowing us to
    monitor how our model performs on unseen data before we test it out on the hold-out
    test set. We set our `validation_split` argument to `0.2`; this signifies that
    we will use 20 percent of our training data for validation during the training
    process, which will run for 40 epochs:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们编译我们的模型。在这里，我们将使用准确率作为评估指标。我们还将查看其他分类指标，这些指标我们在之前讨论过，当我们开始评估模型在测试数据上的表现时会用到。编译模型后，下一步是拟合我们的模型。在[*第1章*](B18118_01.xhtml#_idTextAnchor014)《机器学习简介》中，我们谈到了训练、验证和测试数据的划分。由于我们将处理一个更大的数据集，接下来我们将使用验证集来评估模型在每个周期结束时的表现，这样我们可以在对保留的测试集进行测试之前，监控模型在未见数据上的表现。我们将`validation_split`参数设置为`0.2`；这意味着我们将在训练过程中使用20%的训练数据作为验证数据，总共进行40个周期：
- en: '[PRE52]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In *Figure 4**.11*, we can see the last five epochs of our model’s output:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 4.11*中，我们可以看到模型输出的最后五个周期：
- en: '![Figure 4.11 – Model training (the last five epochs)](img/B18118_04_011.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.11 – 模型训练（最后五个周期）](img/B18118_04_011.jpg)'
- en: Figure 4.11 – Model training (the last five epochs)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – 模型训练（最后五个周期）
- en: 'The model reaches a training accuracy of 99.35% and a validation accuracy of
    99.33%. Using just two layers and three simple steps in less than five minutes,
    we have arrived at almost 100 percent accuracy on both training and validation
    data. These results are impressive, yes; however, it is important to know this
    isn’t always the case, especially when we work with more complex datasets. They
    may require more complex architectures and longer training times to achieve good
    results. We will see this in *Section 2* of this book, where we will work with
    images. Before we proceed to evaluate our model, let us look at our model’s architecture
    using the `summary` function:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型达到了99.35%的训练准确率和99.33%的验证准确率。仅用了两层和三个简单的步骤，在不到五分钟的时间里，我们就在训练和验证数据上达到了接近100%的准确率。这些结果确实令人印象深刻；然而，需要知道的是，这并不总是如此，特别是当我们处理更复杂的数据集时。它们可能需要更复杂的架构和更长的训练时间才能取得良好的结果。在本书的*第2节*中，我们将处理图像数据。继续评估我们的模型之前，让我们通过`summary`函数查看一下模型的架构：
- en: '[PRE53]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'When we run this line of code, we generate the model’s architecture:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这行代码时，我们生成了模型的架构：
- en: '[PRE54]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The output shape shows us that the first `dense` layer (input layer) has 16
    neurons and 256 params, since we passed in 16 attributes (16 columns x 16 neurons
    = 256 params), while the `dense_1` layer (the output layer) has 1 neuron and 17
    params (17 columns x 1 neuron = 17 params). The total params are 273 and all the
    params are trainable, so we have 273 here, which means there will be zero non-trainable
    params. Now that we are done with model building, let’s shift our attention to
    evaluating our model. How well will it perform on the test data?
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 输出形状告诉我们，第一层`dense`层（输入层）有16个神经元和256个参数，因为我们传入了16个属性（16列 x 16个神经元 = 256个参数），而`dense_1`层（输出层）有1个神经元和17个参数（17列
    x 1个神经元 = 17个参数）。总参数数为273，且所有参数都是可训练的，所以这里的参数为273，这意味着没有非训练参数。现在我们完成了模型构建，让我们将注意力转向评估模型。它在测试数据上表现如何？
- en: Classification performance evaluation
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类性能评估
- en: 'To evaluate our model in TensorFlow, all we need is one line of code – using
    the `evaluate` function on our model:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在TensorFlow中评估我们的模型，我们只需要一行代码——使用`evaluate`函数来评估我们的模型：
- en: '[PRE55]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We then generate our model’s performance on our holdout data:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在保留数据上生成模型的性能：
- en: '[PRE56]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We arrive at an accuracy of 99.44% on our test data. This is good; however,
    let us look at the other classification metrics we talked about earlier in this
    chapter:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在测试数据上得到了99.44%的准确率。这是不错的结果；然而，让我们看看本章早些时候提到的其他分类指标：
- en: '[PRE57]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We generate our model’s prediction on the test data. Then, we convert the probabilities
    using the `np.round()` function and convert the data type to integers. Then, we
    create a pandas DataFrame, after which we generate the number of the misclassified
    labels in our DataFrame. In our case, the model misclassified 28 out of 5,000
    data points in our test set. Now, we will generate a confusion matrix and classification
    reports to evaluate our model:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在测试数据上生成模型的预测结果。然后，我们使用`np.round()`函数将概率值进行四舍五入，并将数据类型转换为整数。接着，我们创建一个pandas
    DataFrame，然后生成DataFrame中被误分类的标签数量。在我们的案例中，模型错误地分类了测试集中5,000个数据点中的28个。现在，我们将生成一个混淆矩阵和分类报告来评估我们的模型：
- en: '[PRE58]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Running this code generates the confusion matrix shown in *Figure 4**.12*.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码将生成*图4.12*所示的混淆矩阵。
- en: '![Figure 4.12 – A confusion matrix for our student dropout model](img/B18118_04_012.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – 我们学生退学模型的混淆矩阵](img/B18118_04_012.jpg)'
- en: Figure 4.12 – A confusion matrix for our student dropout model
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – 我们学生退学模型的混淆矩阵
- en: The horizontal arrows point in the direction of the true values, while the vertical
    arrows are in the direction of the predicted labels. Our ground truth had (5 +
    3,498) = 3,503 students in the graduated class, and our model predicted (3498
    + 23) = 3,521 in our graduate class. Meanwhile, in the dropout class, our model
    predicted (5 + 1474) = 1,479 students dropped out, as against the ground truth
    (1,474 + 23) = 1497\. From *Figure 4**.14*, we can see that the model wrongly
    predicted that 23 students who dropped out were graduates and 5 students who graduated
    were dropouts.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 水平箭头指向真实值的方向，而垂直箭头指向预测标签的方向。我们的真实情况是有(5 + 3,498) = 3,503名学生毕业，而模型预测的毕业生人数是(3,498
    + 23) = 3,521。同时，在退学类别中，模型预测了(5 + 1,474) = 1,479名学生退学，而真实情况是(1,474 + 23) = 1,497。从*图4.14*中我们可以看到，模型错误地预测了23名退学的学生是毕业生，以及5名毕业生是退学生。
- en: 'Next, let us print out our classification report:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们打印出我们的分类报告：
- en: '[PRE59]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Now that we have printed out our classification report, as shown in *Figure
    4**.15*, we can see our model’s precision, recall, and F1 score across both classes
    in our dataset, as well as the macro and weighted averages.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经打印出了我们的分类报告，如*图 4.15*所示，我们可以看到模型在数据集中的两个类别中的精确率、召回率和 F1 分数，以及宏观和加权平均值。
- en: '![Figure 4.13 – The classification report](img/B18118_04_013.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – 分类报告](img/B18118_04_013.jpg)'
- en: Figure 4.13 – The classification report
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 分类报告
- en: From the highlighted details in *Figure 4**.13*, we can see the model’s precision,
    recall, and F1 score. We have come a long way; this is a good result. If we wish
    to improve our result, we can try more experiments. Also, error analysis is very
    useful to help us understand misclassified data. We can drill down into the misclassified
    students, trying to understand patterns or common characteristics in cases the
    model failed to predict correctly. This can lead to further insights or help us
    identify issues regarding our data quality, among other possibilities. However,
    we will not delve into error analysis here. You have done a good job and achieved
    good results in both classes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 4.13*中的突出细节，我们可以看到模型的精确率、召回率和 F1 分数。我们已经走了很长一段路；这是一个不错的结果。如果我们希望改进结果，可以尝试更多实验。此外，错误分析非常有助于帮助我们理解错误分类的数据。我们可以深入分析误分类的学生，尝试理解模型未能正确预测的案例中的模式或共同特征。这可以带来进一步的见解，或帮助我们识别与数据质量相关的问题，等等。然而，我们在这里不会深入探讨错误分析。你已经做得很好，在两个类别中都取得了不错的结果。
- en: 'Now, let’s save the model and present it to the manager using the `save` function:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `save` 函数保存模型并展示给经理：
- en: '[PRE60]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: We have completed our task, and we have a near-perfect model.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了任务，并且得到了一个近乎完美的模型。
- en: Now, you should be able to build a real-world classifier with TensorFlow for
    structured data problems, using what you learned from our case study in this chapter.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该能够使用 TensorFlow 为结构化数据问题构建一个实际的分类器，并运用本章案例研究中学到的知识。
- en: Summary
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小结
- en: In this chapter, we discussed classification modeling and looked at the main
    types of classification problems. We also discussed the main types of metrics
    for the evaluation of classification models and how to best apply them to real-world
    use cases. Then, we looked at a real-world use case, where we learned how to build,
    compile, and train a classification model with TensorFlow for a binary classification
    problem.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了分类建模，并了解了主要的分类问题类型。我们还讨论了评估分类模型的主要指标类型，以及如何将它们最佳地应用于实际使用案例。然后，我们看了一个实际使用案例，在该案例中，我们学习了如何使用
    TensorFlow 构建、编译和训练一个用于二分类问题的分类模型。
- en: Finally, we learned, hands-on, how to evaluate our classification models. We
    have now completed the first section of this book. Get ready for the next sections,
    where we will see the power of TensorFlow in its full glory as we work on unstructured
    data (image and text data).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过实践学习了如何评估我们的分类模型。现在，我们已经完成了本书的第一部分。准备好迎接接下来的章节，在那里我们将看到 TensorFlow 在处理非结构化数据（图像和文本数据）时的强大功能。
- en: Questions
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Let’s test what we learned in this chapter.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下本章所学的内容。
- en: What is classification modeling?
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是分类建模？
- en: What is the difference between multi-class and multi-label classification problems?
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多分类和多标签分类问题之间有什么区别？
- en: You work for a streaming company offering interesting children content. Which
    metrics, between precision and recall, will you focus on improving, and why?
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你在一家提供有趣儿童内容的流媒体公司工作。在精确率和召回率之间，你会重点改进哪个指标，为什么？
- en: Your company is building a loan prediction system to offer loans to clients.
    Which metrics, between precision and recall, will you focus on improving, and
    why?
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的公司正在构建一个贷款预测系统，用来为客户提供贷款。在精确率和召回率之间，你会重点改进哪个指标，为什么？
- en: Further reading
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more, you can check out the following resources:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解更多内容，可以查看以下资源：
- en: 'Amr, T., 2020\. *Hands-On Machine Learning with scikit-learn and Scientific
    Python Toolkits*. [S.l.]: Packt Publishing.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Amr, T., 2020\. *使用 scikit-learn 和科学 Python 工具包进行机器学习实战*。[S.l.]: Packt 出版社。'
- en: Beger, A., 2016\. *Precision-Recall Curves*. *SSRN* *Electronic Journal*.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beger, A., 2016\. *精确率-召回率曲线*。*SSRN* *电子期刊*。
- en: Raschka, S. and Mirjalili, V., 2019\. *Python Machine Learning – Third Edition*.
    Packt Publishing.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raschka, S. 和 Mirjalili, V., 2019\. *Python 机器学习 – 第三版*。Packt 出版社。
- en: '*TensorFlow* *guide*: [https://www.TensorFlow.org/guide](https://www.TensorFlow.org/guide).'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow* *指南*：[https://www.TensorFlow.org/guide](https://www.TensorFlow.org/guide)。'
- en: Part 2 – Image Classification with TensorFlow
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2部分 – 使用 TensorFlow 进行图像分类
- en: In this part, you will learn to build both binary and multiclass image classifiers
    with **convolutional neural networks** (**CNNs**), understand how to improve the
    model’s performance by tuning the hyperparameters, and how to handle the problem
    of overfitting. By the end, you should be comfortable with building real world
    image classifiers using transfer learning.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分内容中，您将学习使用**卷积神经网络**（**CNNs**）构建二元和多类图像分类器，了解如何通过调整超参数来提高模型性能，以及如何处理过拟合问题。到最后，您将能够使用迁移学习构建真实世界的图像分类器。
- en: 'This section comprises the following chapters:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 5*](B18118_05.xhtml#_idTextAnchor105), *Image Classification With
    Neural Networks*'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B18118_05.xhtml#_idTextAnchor105)，*使用神经网络进行图像分类*'
- en: '[*Chapter 6*](B18118_06.xhtml#_idTextAnchor129), *Improving the Model*'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B18118_06.xhtml#_idTextAnchor129)，*改进模型*'
- en: '[*Chapter 7*](B18118_07.xhtml#_idTextAnchor146), *Image Classification with
    Convolutional Neural Networks*'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B18118_07.xhtml#_idTextAnchor146)，*使用卷积神经网络进行图像分类*'
- en: '[*Chapter 8*](B18118_08.xhtml#_idTextAnchor186), *Handling Overfitting*'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B18118_08.xhtml#_idTextAnchor186)，*处理过拟合*'
- en: '[*Chapter 9*](B18118_09.xhtml#_idTextAnchor210), *Transfer Learning*'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B18118_09.xhtml#_idTextAnchor210)，*迁移学习*'
