- en: '*Chapter 8*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*'
- en: Object Recognition to Guide a Robot Using CNNs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CNN进行物体识别以引导机器人
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够：
- en: Explain how object recognition works
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释物体识别是如何工作的
- en: Build a network capable of recognizing objects
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个能够识别物体的网络
- en: Build an object recognition system
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个物体识别系统
- en: This chapter covers how object recognition works by building a network that
    would be capable of recognizing objects based on a video.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何通过构建一个能够基于视频识别物体的网络来实现物体识别。
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Object recognition** is an area of computer vision where a robot is capable
    of detecting objects in an environment using a camera or sensor that is capable
    of extracting images of the robot''s surroundings. From these images, software
    detects an object within every image and then recognizes the type of object. Machines
    are capable of recognizing objects from an image or a video captured by the robot''s
    sensors. This allows the robot to be aware of their environment.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**物体识别**是计算机视觉的一个领域，在这个领域中，机器人能够使用相机或传感器检测环境中的物体，传感器能够提取机器人周围环境的图像。从这些图像中，软件能够检测出每一张图像中的物体，并识别物体的种类。机器能够识别由机器人传感器捕捉的图像或视频中的物体。这使得机器人能够意识到它们的环境。'
- en: If a robot can recognize its environment and obtain this information using object
    recognition, it will be able to perform more complex tasks, such as grabbing objects
    or moving around in an environment. In *Chapter 9*, *Computer Vision for Robotics*,
    we will look at a robot performing these tasks in a virtual environment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果机器人能够识别其环境并利用物体识别获取这些信息，它将能够执行更复杂的任务，例如抓取物体或在环境中移动。在*第9章*，*机器人视觉*中，我们将看到一个机器人在虚拟环境中执行这些任务。
- en: The task to be performed here is to detect specific objects within an image
    and recognize those objects. This type of computer vision problem is a bit different
    from the ones that we have looked at earlier in this book. In order to recognize
    a specific object, we have seen that labeling those objects and training a convolutional
    neural network, which was covered in *Chapter 5*, *Convolutional Neural Networks
    for Computer Vision*, which would work fine, but what about detecting these objects
    in the first place?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里要执行的任务是检测图像中的特定物体并识别这些物体。这种类型的计算机视觉问题与本书前面讨论的有所不同。为了识别特定物体，我们已经看到，标注这些物体并训练一个卷积神经网络（在*第5章*，*计算机视觉中的卷积神经网络*中已经介绍过），这种方法效果很好，但如果首先要检测这些物体呢？
- en: Previously, we learned that objects we want to recognize have to be labeled
    with the corresponding class they belong to. Hence, in order to detect those objects
    within an image, a rectangle-shaped bounding box has to be drawn around them so
    that their location in the image is properly located. The neural network will
    then predict the bounding boxes and the label of those objects.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们学习了要识别的物体必须标注上它们所属的相应类别。因此，为了在图像中检测到这些物体，必须在它们周围绘制一个矩形边界框，以便准确定位它们在图像中的位置。神经网络将预测这些物体的边界框及其标签。
- en: Labeling objects with bounding boxes is a tedious, tough task, so we are not
    going to show the process for labeling the images in a dataset with bounding boxes,
    or the process for training a neural network to recognize and detect those objects.
    Nevertheless, there is a library called `labelImg`, which you can access in this
    GitHub repository:﷟ [https://github.com/tzutalin/labelImg](https://github.com/tzutalin/labelImg).
    This allows you to create bounding boxes for every object within an image. Once
    you have the bounding boxes created, which in terms of data are known as coordinates,
    you can train a neural network to predict the bounding boxes and the corresponding
    label for every object within an image.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 用边界框标注物体是一个繁琐且艰难的任务，因此我们不会展示如何为数据集中的图像标注边界框，或如何训练神经网络来识别和检测这些物体。然而，有一个名为`labelImg`的库，你可以在这个GitHub仓库中找到：[https://github.com/tzutalin/labelImg](https://github.com/tzutalin/labelImg)。这个工具可以让你为每个图像中的物体创建边界框。一旦你创建了这些边界框，数据上称之为坐标，你就可以训练一个神经网络来预测图像中每个物体的边界框及相应的标签。
- en: In this chapter, we will be using state-of-the-art methods of the YOLO network,
    which are ready to use and will save you from having to build your own algorithm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用最先进的YOLO网络方法，这些方法已经准备好使用，能够节省你自己编写算法的时间。
- en: Multiple Object Recognition and Detection
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多物体识别与检测
- en: Multiple object recognition and detection involves detecting and recognizing
    several objects within an image. This task involves labeling every single object
    with a bounding box and then recognizing the type of that object.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 多物体识别与检测涉及在一张图像中检测和识别多个物体。这个任务包括用边界框标注每个物体，然后识别该物体的类型。
- en: Because of this, there are many available pre-trained models that detect a lot
    of objects. The neural network called **YOLO** is one of the best models for this
    specific task and works in real time. YOLO will be explained in depth in the next
    chapter for the development of the simulator for the robot.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，市面上有许多预训练的模型可以检测各种物体。名为**YOLO**的神经网络是最适合此任务的模型之一，并且能够实时工作。YOLO将在下一章中详细讲解，用于机器人模拟器的开发。
- en: 'For this chapter, the YOLO network that we want to use is trained to recognize
    and detect 80 different classes. These classes are:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，YOLO网络将训练用于识别和检测80种不同的类别。这些类别包括：
- en: person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic
    light, fire hydrant, stop_sign, parking meter, bench, bird, cat, dog, horse, sheep,
    cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase,
    frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard,
    surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana,
    apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair,
    couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard,
    cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors,
    teddy bear, hair dryer, toothbrush.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 人、脚踏车、汽车、摩托车、飞机、公交车、火车、卡车、船、交通信号灯、消防栓、停车标志、停车计时器、长椅、鸟、猫、狗、马、羊、牛、大象、熊、斑马、长颈鹿、背包、雨伞、手提包、领带、手提箱、飞盘、滑雪板、单板滑雪、运动球、风筝、棒球棒、棒球手套、滑板、冲浪板、网球拍、瓶子、酒杯、杯子、叉子、刀子、勺子、碗、香蕉、苹果、三明治、橙子、西兰花、胡萝卜、热狗、比萨饼、甜甜圈、蛋糕、椅子、沙发、盆栽、床、餐桌、厕所、电视、笔记本电脑、鼠标、遥控器、键盘、手机、微波炉、烤箱、烤面包机、水槽、冰箱、书、时钟、花瓶、剪刀、泰迪熊、吹风机、牙刷。
- en: 'In Figure 8.1, you can see a sample of a street where people, cars, and buses
    have been detected using YOLO:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.1中，您可以看到一个街道场景，YOLO已检测到其中的行人、汽车和公交车：
- en: '![Figure 8.1: YOLO detection sample](img/C13550_08_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1：YOLO检测示例](img/C13550_08_01.jpg)'
- en: 'Figure 8.1: YOLO detection sample'
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.1：YOLO检测示例
- en: In this topic, we are going to build a multiple object recognition and detection
    system for static images.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本主题中，我们将构建一个针对静态图像的多物体识别与检测系统。
- en: First, we are going to do so using an OpenCV module called **DNN** (Deep Neural
    Network), which involves a few lines of code. Later on, we will use a library
    called **ImageAI**, which does the same but with less than 10 lines of code and
    will allow you to choose the specific objects you want to detect and recognize.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用一个名为**DNN**（深度神经网络）的OpenCV模块，它只需要几行代码。稍后，我们将使用一个叫做**ImageAI**的库，它能完成相同的任务，但代码量少于10行，并且让你选择具体要检测和识别的物体。
- en: In order to implement YOLO with OpenCV, you will need to import the image using
    OpenCV, just like we covered in other chapters of this book.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在OpenCV中实现YOLO，您需要像本书其他章节一样，使用OpenCV导入图像。
- en: 'Exercise 24: Building Your First Multiple Object Detection and Recognition
    Algorithm'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习24：构建您的第一个多物体检测与识别算法
- en: Note
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: We are going to use a Google Colab notebook as this task does not involve training
    an algorithm, but rather using one.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Google Colab笔记本进行此任务，因为它不涉及训练算法，而是使用现成的算法。
- en: 'In this exercise, we are going to implement a multiple object detection and
    recognition system using YOLO and OpenCV. We are going to code a detector and
    a recognizer system that takes an image as input and detects and recognizes objects
    within that image, then outputs the image with those detections drawn:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用YOLO和OpenCV实现一个多物体检测与识别系统。我们将编写一个检测器和识别系统，输入一张图像，检测并识别图像中的物体，然后输出带有这些检测框的图像：
- en: Open up your Google Colab interface.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您的Google Colab界面。
- en: 'Import the following libraries:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库：
- en: '[PRE0]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To input an image to this network, we need to use the `blobFromImage` method:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将图像输入到该网络中，我们需要使用`blobFromImage`方法：
- en: Note
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE1]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We need to load the classes of the dataset, which for YOLO are stored in `Models/yolov3.txt`,
    which you can find in `Chapter 8/Models` on GitHub. We read the classes like this:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要加载数据集的类别，对于YOLO，这些类别存储在`Models/yolov3.txt`中，你可以在GitHub的`Chapter 8/Models`中找到。我们像这样读取类别：
- en: '[PRE2]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Generate different colors for different classes:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为不同的类别生成不同的颜色：
- en: '[PRE3]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Read the pre-trained model and the config file:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取预训练模型和配置文件：
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create an input blob:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建输入blob：
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Set the input blob for the network:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置网络的输入blob：
- en: '[PRE6]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In order to declare the network, we use the `readNet` method from the `Models/yolov3.weights`,
    which is the weights of the network, and `Models/yolov3.cfg`, which is the architecture
    of the model:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了声明网络，我们使用`Models/yolov3.weights`（网络的权重）和`Models/yolov3.cfg`（模型的架构）中的`readNet`方法：
- en: Note
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The method, class, weight, and architecture files can be found on GitHub in
    the `Lesson08/Models/` folder.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法、类别、权重和架构文件可以在GitHub的`Lesson08/Models/`文件夹中找到。
- en: Now that we have set this up, the only thing that is left in order to recognize
    and detect all the objects within an image is to run and execute the code, which
    is explained next.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经完成了设置，接下来只需要运行并执行代码，这样就能识别并检测图像中的所有物体，下面会详细解释如何操作。
- en: 'In order to get the output layers of the network, we declare the method mentioned
    in the following code and then run the interface to obtain the array of output
    layers, which contains several detections:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了获取网络的输出层，我们声明以下代码中提到的方法，然后运行接口以获得输出层的数组，该数组包含多个检测结果：
- en: '[PRE7]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a function to draw a bounding box around the detected object with the
    class name:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，在检测到的物体周围画一个带有类别名称的边界框：
- en: '[PRE8]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Execute the code:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行代码：
- en: '[PRE9]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '''outs'' is an array of predictions. Later on in the exercise, we will see
    that we have to loop this array in order to get the bounding boxes and the confidences
    of each detection, along with the type of class.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '''outs''是一个预测数组。稍后的操作中，我们将看到需要遍历该数组以获取每个检测结果的边界框、置信度和类别类型。'
- en: 'Object detection algorithms often detect one object several times and that
    is a problem. This problem can be solved by using **non-max suppression**, which
    deletes the bounding boxes for every object with less confidence (the probability
    of the object being in the predicted class), after which the only bounding boxes
    that will remain are the ones with the highest confidence. After detecting the
    bounding boxes and the confidences, and declaring the corresponding thresholds,
    this algorithm can be run as follows:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 物体检测算法常常会对一个物体进行多次检测，这是一个问题。可以通过使用**非最大抑制**（non-max suppression）来解决这个问题，该方法会删除置信度较低的物体的边界框（即预测为该类别的概率较低），最终只保留置信度最高的边界框。在检测到边界框和置信度，并声明相应的阈值后，可以按如下方式运行该算法：
- en: 'This step is one of the most important ones. Here, we are going to gather the
    confidence from every detection of every output layer (every object detected),
    the class ID, and the bounding boxes, but we''ll ignore detections with a confidence
    of less than 50%:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一步是最重要的步骤之一。在这里，我们将收集每个输出层的每次检测的置信度（即每个被检测到的物体）、类别ID和边界框，但我们会忽略置信度低于50%的检测：
- en: '[PRE10]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'For each detection from each output layer, get the confidence, the class ID,
    and bounding box params, and ignore weak detections (confidence < 0.5):'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个输出层的每次检测，获取置信度、类别ID和边界框参数，忽略置信度较低的检测（置信度 < 0.5）：
- en: '[PRE11]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We loop over the list of indexes and use the method that we declared for printing
    to print every bounding box, every label, and every confidence on the input image:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们遍历索引列表，使用我们声明的方法打印每个边界框、标签和每个检测的置信度：
- en: '[PRE12]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, we show and save the resulting image. OpenCV has a method for showing
    it also; there is no need to use Matplotlib:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们展示并保存结果图像。OpenCV也有一个方法可以显示图像，因此不需要使用Matplotlib：
- en: '[PRE13]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 8.2: YOLO detection sample](img/C13550_08_02.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图8.2：YOLO检测示例](img/C13550_08_02.jpg)'
- en: 'Figure 8.2: YOLO detection sample'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.2：YOLO检测示例
- en: Finally, we have to draw the bounding boxes, its classes, and the confidence.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们需要绘制边界框、类别和置信度。
- en: 'Now let''s try some other examples using the steps mentioned previously. You
    can find the images in the `Dataset/obj-det/` folder. The outputs will be as shown
    in Figure 8.3:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们尝试使用前面提到的步骤做一些其他的示例。你可以在`Dataset/obj-det/`文件夹中找到图像，输出结果将如图8.3所示：
- en: '![](img/Image52926.jpg)![Figure 8.3: YOLO detection sample](img/Image52947.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image52926.jpg)![图8.3：YOLO检测示例](img/Image52947.jpg)'
- en: 'Figure 8.3: YOLO detection sample'
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.3：YOLO检测示例
- en: ImageAI
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ImageAI
- en: There is another way to achieve this easily. You could use the **ImageAI** library,
    which is capable of performing object detection and recognition with a few lines
    of code.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种更简单的方法可以实现这一目标。你可以使用**ImageAI**库，它能够通过几行代码进行物体检测和识别。
- en: 'The link to the GitHub repository for this library can be found here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该库的GitHub仓库链接可以在这里找到：
- en: '[https://github.com/OlafenwaMoses/ImageAI](https://github.com/OlafenwaMoses/ImageAI)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OlafenwaMoses/ImageAI](https://github.com/OlafenwaMoses/ImageAI)'
- en: 'In order to install this library, you can do so by using pip with the following
    command:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装这个库，你可以通过以下命令使用pip进行安装：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To use this library, we need to import one class:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个库时，我们需要导入一个类：
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We import the `ObjectDetection` class, which will work as a neural network.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入`ObjectDetection`类，它将作为神经网络工作。
- en: 'Afterward, we declare the object of the class that is going to make the predictions:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们声明将要进行预测的类对象：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The model that we are going to use has to be declared. For this library, we
    only get to use three models: RetinaNet, YOLOV3, and TinyYOLOV3\. YOLOV3 is the
    same model we used before and has moderate performance and accuracy with a moderate
    detection time.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的模型必须声明。对于这个库，我们只能使用三种模型：RetinaNet、YOLOV3和TinyYOLOV3。YOLOV3是我们之前使用的相同模型，具有中等的性能和准确性，检测时间也适中。
- en: As for RetinaNet, it has higher performance and accuracy but a longer detection
    time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 至于RetinaNet，它具有更高的性能和准确性，但检测时间较长。
- en: TinyYOLOV3 is optimized for speed and has moderate performance and accuracy
    but a much faster detection time. This model will be used in the next topic because
    of its speed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: TinyYOLOV3经过优化，注重速度，具有中等的性能和准确性，但检测时间更快。由于其速度，本模型将在下一个主题中使用。
- en: 'You only have to change a couple of lines of code in order to get to work with
    any of these models. For YOLOV3, these lines are needed:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要修改几行代码，就能让这些模型中的任何一个工作。对于YOLOV3，需要以下几行代码：
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `.h5` file contains the weights and the architecture for the YOLOV3 neural
    network.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`.h5`文件包含了YOLOV3神经网络的权重和架构。'
- en: 'To run the inference and get the corresponding detections, only a line of code
    is needed:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行推理并获取相应的检测结果，只需一行代码：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What this line does is take an image as input and detect the bounding boxes
    of the objects in the image and their classes. It outputs a new image drawn with
    those detections, as well as a list of the detected objects.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码的作用是将一张图像作为输入，检测图像中物体的边界框及其类别。它输出一张标记了这些检测结果的新图像，并列出检测到的物体。
- en: 'Let''s see how it detects the `sample.jpg` image that we used in the last exercise:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下它如何检测我们在上一个练习中使用的`sample.jpg`图像：
- en: '![Figure 8.4: ImageAI YOLOV3 image detection](img/Image52955.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4：ImageAI YOLOV3图像检测](img/Image52955.jpg)'
- en: 'Figure 8.4: ImageAI YOLOV3 image detection'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.4：ImageAI YOLOV3图像检测
- en: ImageAI also allows you to customize which objects you want to recognize. By
    default, it is also capable of detecting the same classes as YOLO, which is built
    using OpenCV, that is the 80 classes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ImageAI还允许你定制要识别的物体。默认情况下，它也能够检测与YOLO相同的80个类别，这些类别是基于OpenCV构建的。
- en: 'You can customize it to only detect the objects that you want by passing an
    object as a parameter called `CustomObjects`, where you specify which objects
    you want the model to detect. Also, the method from the detector for recognizing
    those objects changes from `detectObjectsFromImage()` to `detectCustomObjectsFromImage()`.
    It is used like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过传递一个名为`CustomObjects`的参数来定制只检测你想要的物体，在该参数中，你指定模型要检测哪些物体。此外，检测器的方法也会从`detectObjectsFromImage()`改为`detectCustomObjectsFromImage()`。用法如下：
- en: '[PRE19]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Figure 8.5: ImageAI YOLOV3 custom image detection](img/C13550_08_05.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图8.5：ImageAI YOLOV3自定义图像检测](img/C13550_08_05.jpg)'
- en: 'Figure 8.5: ImageAI YOLOV3 custom image detection'
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.5：ImageAI YOLOV3自定义图像检测
- en: Multiple Object Recognition and Detection in Video
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频中的多物体识别和检测
- en: Multiple object recognition and detection in static images sounds amazing, but
    what about detecting and recognizing objects in a video?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 静态图像中的多物体识别和检测听起来很棒，那么在视频中检测和识别物体如何呢？
- en: You can download any video from the internet and try to detect and recognize
    all the objects that show up in the video.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从互联网下载任何视频，尝试检测和识别视频中出现的所有物体。
- en: The process to follow would be to get every frame of the video and for every
    frame, detect the corresponding objects and their labels.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的处理流程是获取视频的每一帧，并且对于每一帧，检测相应的物体及其标签。
- en: 'Declare the corresponding libraries first:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先声明相应的库：
- en: '[PRE20]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The `imageai` library contains an object that allows the user to apply object
    detection and recognition to the video:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`imageai`库包含一个对象，允许用户对视频进行物体检测与识别：'
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We need V`ideoObjectDetection` so that we can detect objects in video. Moreover,
    Matplotlib is needed to show the detection process for every frame:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`VideoObjectDetection`，这样我们才能在视频中检测物体。此外，Matplotlib也需要用于显示每一帧的检测过程：
- en: '![Figure 8.6: ImageAI one-frame object detection process](img/C13550_08_06.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图8.6：ImageAI单帧物体检测过程](img/C13550_08_06.jpg)'
- en: 'Figure 8.6: ImageAI one-frame object detection process'
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.6：ImageAI单帧物体检测过程
- en: 'Now we will first need to load the model. You can decide what model to load,
    depending on the speed you need the video to be processed at, with the precision
    required. YOLOV3 is in the middle, between RetinaNet and TinyYOLOV3, RetinaNet
    being the most precise but the slowest and TinyYOLOV3 the least precise but the
    fastest. We are going to stick to the YOLOV3 model but feel free to use the other
    two. The declaration after declaring the video object detection is the same as
    in the last topic:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们首先需要加载模型。你可以根据视频处理的速度需求和所需精度来决定加载哪个模型。YOLOV3位于RetinaNet和TinyYOLOV3之间，RetinaNet精度最高但速度最慢，而TinyYOLOV3精度最低但速度最快。我们将使用YOLOV3模型，但你也可以自由选择其他两个模型。在声明视频物体检测之后，声明方式与上一个主题相同：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Before running the video detector, we need to declare a function that will be
    applied to every frame processed. This function does not perform the detection
    algorithm, but it handles the detection process for every frame. And why do we
    have to handle the output of every frame after the object detection process? That
    is because we want to show the detection process frame by frame using Matplotlib..
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行视频检测器之前，我们需要声明一个将在每一帧处理后应用的函数。这个函数不执行检测算法，但它处理每一帧的检测过程。为什么我们要处理每一帧的输出？那是因为我们希望使用Matplotlib逐帧展示检测过程。
- en: 'Before declaring that method, we need to declare the colors that the objects
    will be printed on:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在声明该方法之前，我们需要声明物体将在其上显示的颜色：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now we are going to declare the method applied to every frame:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将声明应用于每一帧的方法：
- en: '[PRE24]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'First, as shown, the function is declared and the number of the frame, the
    array of detections, the number of occurrences of every object detected, and the
    frame are passed to it. Also, we declare the corresponding variables that we are
    going to use to print all the detections on every frame:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如图所示，声明函数，并传入帧号、检测数组、每个检测物体的出现次数和帧。我们还声明了相应的变量，用于在每一帧上打印所有检测结果：
- en: '[PRE25]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In this loop, the objects and their corresponding occurrences are stored. The
    colors that represent every object are also stored:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个循环中，存储了物体及其相应的出现次数。同时也存储了代表每个物体的颜色：
- en: '[PRE26]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In this last piece of code, two plots are printed for every frame: one showing
    the image with the corresponding detections and the other with a chart containing
    the number of occurrences of every object detected and its percentage of the total
    of occurrences.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，每一帧会打印两个图：一个显示带有相应检测结果的图像，另一个是包含每个检测物体出现次数及其在总次数中占比的图表。
- en: This output is shown in Figure 8.6.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出显示在图8.6中。
- en: 'In the last cell, in order to execute the video detector, we write this couple
    of lines of code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个单元格中，为了执行视频检测器，我们写了这几行代码：
- en: '[PRE27]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The first line initializes the Matplotlib plot.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行初始化Matplotlib绘图。
- en: 'The second line starts the video detection. The arguments passed to the function
    are as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行开始视频检测。传递给函数的参数如下：
- en: '`input_file_path`: The input video path'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_file_path`：输入视频路径'
- en: '`output_file_path`: The output video path'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_file_path`：输出视频路径'
- en: '`frames_per_second`: Frames per second of the output video'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frames_per_second`：输出视频的帧率'
- en: '`per_frame_function`: The callback function after every process of detecting
    objects within a frame'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`per_frame_function`：每处理完一帧进行物体检测后的回调函数'
- en: '`minimum_percentage_probability`: The minimum probability value threshold,
    where only detections with the highest confidence are considered'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minimum_percentage_probability`：最低概率值阈值，只有检测到的物体具有最高置信度时才会被考虑'
- en: '`return_detected_frame`: If set to True, the callback function receives the
    frame as a parameter'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_detected_frame`：如果设置为True，回调函数将接收该帧作为参数。'
- en: '`log_progress`: If set to True, the process is logged in the console'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_progress`：如果设置为True，过程将在控制台中记录。'
- en: 'Activity 8: Multiple Object Detection and Recognition in Video'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动8：视频中的多物体检测与识别
- en: 'In this activity, we are going to process a video frame by frame, detecting
    all possible objects within every frame and saving the output video to disk:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们将逐帧处理视频，检测每一帧中的所有可能物体，并将输出视频保存到磁盘：
- en: Note
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The video we will be using for this activity is uploaded on GitHub, in the
    `Dataset/videos/street.mp4` folder:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用于此活动的视频已上传到GitHub，在`Dataset/videos/street.mp4`文件夹中：
- en: 'Url : [https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics/blob/master/Lesson08/Dataset/videos/street.mp4](https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics/blob/master/Lesson08/Dataset/videos/street.mp4)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 链接：[https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics/blob/master/Lesson08/Dataset/videos/street.mp4](https://github.com/PacktPublishing/Artificial-Vision-and-Language-Processing-for-Robotics/blob/master/Lesson08/Dataset/videos/street.mp4)
- en: Open a Google Colab notebook, mount the disk, and navigate to where chapter
    8 is located.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Google Colab笔记本，挂载磁盘，并导航到第8章所在的位置。
- en: 'Install the library in the notebook, as it is not preinstalled, by using this
    command:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本中安装此库，因为它未预安装，可以使用以下命令：
- en: '[PRE28]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Import the necessary libraries for the development of this activity and set
    `matplotlib`.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入本活动开发所需的库并设置`matplotlib`。
- en: Declare the model that you are going to use for detecting and recognizing objects.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明你将用于检测和识别物体的模型。
- en: Note
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can find that information here:[https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/VIDEO.md](https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/VIDEO.md)
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在这里找到相关信息：[https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/VIDEO.md](https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/VIDEO.md)
- en: Also note that all models are stored in the `Models` folder.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同时注意，所有模型都存储在`Models`文件夹中。
- en: Declare the callback method that is going to be called after every frame is
    processed.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明将在每帧处理后调用的回调方法。
- en: Run Matplotlib and the video detection processes on the `street.mp4` video that
    is inside the `Dataset/videos/` folder. You can also try out the `park.mp4` video,
    which is in the same directory.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Dataset/videos/`文件夹中的`street.mp4`视频上运行Matplotlib和视频检测过程。你也可以尝试在同一目录中的`park.mp4`视频。
- en: Note
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity is available on page 326.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可在第326页找到。
- en: Summary
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Object recognition and detection is capable of identifying several objects within
    an image, to draw bounding boxes around those objects and predict the types of
    object they are.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 物体识别与检测能够识别图像中的多个物体，围绕这些物体绘制边框并预测它们的类型。
- en: The process of labeling the bounding boxes and their labels has been explained,
    but not in depth, due to the huge process required. Instead, we used state-of-the-art
    models to recognize and detect those objects.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 标签框及其标签的标注过程已被解释过，但由于过程庞大，未做深入讲解。相反，我们使用了最先进的模型来识别和检测这些物体。
- en: YOLOV3 was the main model used in this chapter. OpenCV was used to explain how
    to run an object detection pipeline using its DNN module. ImageAI, an alternative
    library for object detection and recognition, has shown its potential for writing
    an object detection pipeline with a few lines and easy object customization.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOV3是本章使用的主要模型。OpenCV用于解释如何使用其DNN模块运行物体检测管道。ImageAI，作为一种物体检测与识别的替代库，展示了用几行代码写物体检测管道并进行轻松定制的潜力。
- en: Finally, the ImageAI object detection pipeline was put into practice by using
    a video, where every frame obtained from the video was passed through that pipeline
    to detect and identify objects from those frames and show them using Matplotlib.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过使用视频，实践了ImageAI物体检测管道，将视频中的每一帧传递通过该管道，检测和识别帧中的物体，并使用Matplotlib显示它们。
