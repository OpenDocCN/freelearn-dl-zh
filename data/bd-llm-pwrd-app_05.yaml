- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Embedding LLMs within Your Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在您的应用中嵌入 LLMs
- en: This chapter kickstarts the hands-on portions of this book, focusing on how
    we can **leverage large language models** (**LLMs**) to build powerful AI applications.
    In fact, LLMs have introduced a whole new paradigm in software development, paving
    the way for new families of applications that have the peculiarity of making the
    communication between the user and the machine smooth and conversational. Plus,
    those models enhanced existing applications, such as chatbots and recommendation
    systems, with their unique reasoning capabilities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章启动了本书的实践部分，重点关注我们如何利用大型语言模型（LLMs）来构建强大的 AI 应用。实际上，LLMs 为软件开发引入了一个全新的范式，为具有用户与机器之间通信流畅和对话式特点的新一代应用铺平了道路。此外，这些模型还增强了现有的应用，如聊天机器人和推荐系统，并赋予了它们独特的推理能力。
- en: Developing LLM-powered applications is becoming a key factor for enterprises
    to keep themselves competitive in the market, and this leads to the spreading
    of new libraries and frameworks that make it easier to embed LLMs within applications.
    Some examples are Semantic Kernel, Haystack, LlamaIndex, and LangChain. In this
    chapter, we are going to cover LangChain and use its modules to build hands-on
    examples. By the end of this chapter, you will have the technical foundations
    to start developing your LLM-powered applications using LangChain and open-source
    Hugging Face models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 开发由大型语言模型（LLM）驱动的应用正成为企业保持市场竞争力的关键因素，这也导致了新的库和框架的传播，使得在应用中嵌入 LLM 变得更加容易。一些例子包括
    Semantic Kernel、Haystack、LlamaIndex 和 LangChain。在本章中，我们将介绍 LangChain 并使用其模块构建实际示例。到本章结束时，你将拥有使用
    LangChain 和开源 Hugging Face 模型开始开发你的 LLM 驱动应用的必要技术基础。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: A brief note about LangChain
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于 LangChain 的简要说明
- en: Getting started with LangChain
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用 LangChain
- en: Working with LLMs via the Hugging Face Hub
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Hugging Face Hub 与 LLMs 一起工作
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete the hands-on sections of this chapter, the following prerequisites
    are needed:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的实践部分，需要以下先决条件：
- en: A Hugging Face account and user access token.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Hugging Face 账户和用户访问令牌。
- en: An OpenAI account and user access token.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 OpenAI 账户和用户访问令牌。
- en: Python 3.7.1 or later version.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7.1 或更高版本。
- en: 'Python packages: Make sure to have the following Python packages installed:
    `langchain`, `python-dotenv`, `huggingface_hub`, `google-search-results`, `faiss`,
    and `tiktoken`. Those can be easily installed via `pip install` in your terminal.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 包：请确保已安装以下 Python 包：`langchain`、`python-dotenv`、`huggingface_hub`、`google-search-results`、`faiss`
    和 `tiktoken`。这些包可以通过在终端中使用 `pip install` 命令轻松安装。
- en: You can find all the code and examples used in this chapter in the book’s GitHub
    repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的 GitHub 仓库 [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)
    中找到本章中使用的所有代码和示例。
- en: A brief note about LangChain
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于 LangChain 的简要说明
- en: Just as generative AI has evolved so rapidly over the last year, so has LangChain.
    In the months between the writing of this book and its publication, the AI orchestrator
    has gone through massive changes. The most remarkable traces back to January 2024,
    when the first stable version of LangChain was released, introducing a new organization
    of packages and libraries.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如生成式 AI 在过去一年中发展如此迅速一样，LangChain 也同样如此。在这本书写作和出版之间的几个月里，AI 调度器经历了巨大的变化。最显著的变化发生在
    2024 年 1 月，当时 LangChain 的第一个稳定版本发布，引入了新的包和库的组织方式。
- en: 'It consists of the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 它包括以下内容：
- en: A core backbone where all the abstractions and runtime logic are stored
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个核心骨干，其中存储了所有抽象和运行时逻辑
- en: A layer of third-party integrations and components
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一层第三方集成和组件
- en: A set of pre-built architectures and templates to leverage
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一套预构建的架构和模板以供利用
- en: A serving layer to consume chains as APIs
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个服务层，用于将链作为 API 消费
- en: An observability layer to monitor your applications in the development, testing,
    and production stages
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可观测层，用于监控应用在开发、测试和生产阶段的表现
- en: You can look at the architecture in greater detail at [https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction)
    中更详细地查看架构。
- en: 'There are three packages you can install to start using LangChain:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以安装以下三个包来开始使用 LangChain：
- en: '`langchain-core`: This contains the base abstractions and runtime for the whole
    LangChain ecosystem.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-core`：这个包包含整个LangChain生态系统的基本抽象和运行时。'
- en: '`langchain-experimental`: This holds experimental LangChain code, intended
    for research and experimental uses.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-experimental`：这个包包含实验性的LangChain代码，旨在用于研究和实验。'
- en: '`langchain-community`: This contains all third-party integrations.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-community`：这个包包含所有第三方集成。'
- en: 'On top of that, there are three additional packages that we’re not going to
    cover in this book, yet can be leveraged to monitor and maintain your LangChain
    applications:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有三个额外的包，我们在这本书中不会涉及，但可以用来监控和维护您的LangChain应用程序：
- en: '`langserve`: LangServe is a tool that lets you deploy **LangChain runnables
    and chains** as a REST API, making it easier to integrate LangChain applications
    into production environments.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langserve`：LangServe是一个工具，让您可以将**LangChain可运行的和链**作为REST API部署，这使得将LangChain应用程序集成到生产环境中变得更加容易。'
- en: '`langsmith`: Think of LangSmith as an **innovative testing framework** for
    evaluating language models and AI applications. It helps visualize inputs and
    outputs at each step in the chain, aiding understanding and intuition during development.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langsmith`：将LangSmith视为一个**创新的测试框架**，用于评估语言模型和AI应用程序。它有助于在链的每个步骤中可视化输入和输出，有助于开发过程中的理解和直觉。'
- en: '`langchain-cli`: The **official command-line interface** for LangChain, it
    facilitates interactions with LangChain projects, including template usage and
    quickstarts.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-cli`：LangChain的**官方命令行界面**，它简化了与LangChain项目（包括模板使用和快速入门）的交互。'
- en: Last but not least, LangChain introduced the **LangChain Expression Language**
    (**LCEL**) to enhance the efficiency and flexibility of text processing tasks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，LangChain引入了**LangChain表达式语言**（**LCEL**）来提高文本处理任务的效率和灵活性。
- en: 'Key features of LCEL include:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LCEL的关键特性包括：
- en: '**Streaming asynchronous support**: This allows for the efficient handling
    of data streams.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流式异步支持**：这允许高效地处理数据流。'
- en: '**Batch support**: This enables processing data in batches.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量支持**：这使能够批量处理数据。'
- en: '**Parallel execution**: This enhances performance by executing tasks concurrently.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行执行**：通过并发执行任务来提高性能。'
- en: '**Retries and fallbacks**: This ensures robustness by handling failures gracefully.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重试和回退**：通过优雅地处理失败来确保鲁棒性。'
- en: '**Dynamically routing logic**: This allows logic flow based on input and output.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态路由逻辑**：这允许根据输入和输出进行逻辑流。'
- en: '**Message history**: This keeps track of interactions for context-aware processing.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息历史记录**：这跟踪交互以实现上下文感知处理。'
- en: We are not going to cover LCEL in this book; however, all the code samples can
    be converted into LCEL if you want to speed up your development and leverage its
    native integration with the end-to-end LangChain development stack.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这本书中不会涉及LCEL；然而，如果您想加快开发速度并利用其与端到端LangChain开发堆栈的本地集成，所有代码示例都可以转换为LCEL。
- en: '**Important note**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: Before we start working with LangChain, it is important to note that all packages
    are versioned slightly differently, yet all releases are cut with high frequency
    by a maintainer with a clearer communication strategy for breaking changes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用LangChain之前，重要的是要注意，所有包的版本略有不同，但所有版本都是由维护者以更清晰的策略发布，以处理重大更改。
- en: In the upcoming chapters, you will see some packages that have been moved, for
    example, to the `experimental` package, meaning that they are more prone to experimental
    uses. Similarly, some third-party integrations have been moved to the `community`
    package.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在即将到来的章节中，您将看到一些已经移动的包，例如移动到`experimental`包，这意味着它们更倾向于实验性使用。同样，一些第三方集成已经移动到`community`包。
- en: Starting from the next section, we are going to cover the backbone concepts
    – such as memory, VectorDB, and agents – that remain solid in the LangChain framework
    and, more generally, in the landscape of LLM development.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从下一节开始，我们将介绍核心概念——例如内存、VectorDB和代理——这些在LangChain框架中以及更广泛的LLM开发领域中都是稳固的。
- en: Getting started with LangChain
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain入门
- en: As introduced in *Chapter 2*, LangChain is a lightweight framework meant to
    make it easier to integrate and orchestrate LLMs and their components within applications.
    It is mainly Python based, yet it recently extended its support to JavaScript
    and TypeScript.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如*第二章*中所述，LangChain是一个轻量级的框架，旨在简化将LLM及其组件集成和编排到应用程序中的过程。它主要基于Python，但最近已扩展其支持到JavaScript和TypeScript。
- en: 'In addition to LLM integration (which we will cover in an upcoming dedicated
    section), we saw that LangChain offers the following main components:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 除了LLM集成（我们将在即将到来的专门章节中介绍）之外，我们还看到LangChain提供了以下主要组件：
- en: Models and prompt templates
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型和提示模板
- en: Data connections
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据连接
- en: Memory
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存
- en: Chains
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链
- en: Agents
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理
- en: 'These components are illustrated in the following diagram:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件在下图中进行了说明：
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_05_01.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成](img/B21714_05_01.png)'
- en: 'Figure 5.1: LangChain’s components'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：LangChain的组件
- en: The next sections will take a deep dive into each of these components.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的章节将深入探讨这些组件的每一个。
- en: Models and prompts
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型和提示
- en: LangChain offers more than 50 integrations with third-party vendors and platforms,
    including **OpenAI**, Azure OpenAI, Databricks, and MosaicML, as well as the integration
    with the Hugging Face Hub and the world of open-source LLMs. In *Part 2* of this
    book, we will be trying various LLMs, both proprietary and open-source, and leveraging
    LangChain’s integrations.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain与超过50个第三方供应商和平台进行了集成，包括**OpenAI**、Azure OpenAI、Databricks和MosaicML，以及与Hugging
    Face Hub和开源LLM世界的集成。在本书的*第2部分*中，我们将尝试各种LLM，包括专有和开源的，并利用LangChain的集成。
- en: 'Just to provide an example, let’s see how easy it is to consume the OpenAI
    GPT-3 model (you can retrieve your OpenAI API key at [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 只为了提供一个例子，让我们看看消费OpenAI GPT-3模型有多容易（你可以在[https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)获取你的OpenAI
    API密钥）：
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is the corresponding output:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的输出：
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Note**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: While running examples with LLMs, the output will vary at each run, due to the
    stochasticity of the models themselves. If you want to reduce the margin of variations
    in your output, you can make your model more “deterministic” by tuning the temperature
    hyperparameter. This parameter ranges from 0 (deterministic) to 1 (stochastic).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用LLM运行示例时，输出将在每次运行中变化，这是由于模型本身的随机性。如果你想减少输出变化的范围，你可以通过调整温度超参数来使你的模型更加“确定”。此参数的范围从0（确定）到1（随机）。
- en: By default, the **OpenAI** module uses the `gpt-3.5-turbo-instruct` as a model.
    You can specify the model you want to use by passing the model’s name as a parameter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，**OpenAI**模块使用`gpt-3.5-turbo-instruct`作为模型。你可以通过传递模型名称作为参数来指定你想要使用的模型。
- en: 'As said previously, we will dive deeper into LLMs in the next section; so,
    for now, let’s focus on prompts. There are two main components related to LLM
    prompts and prompts design/engineering:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将在下一节中深入探讨LLM；因此，现在让我们专注于提示。与LLM提示和提示设计/工程相关的有两个主要组件：
- en: '**Prompt templates**: A prompt template is a component that defines how to
    generate a prompt for a language model. It can include variables, placeholders,
    prefixes, suffixes, and other elements that can be customized according to the
    data and the task.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示模板**：提示模板是一个组件，用于定义如何为语言模型生成提示。它可以包括变量、占位符、前缀、后缀以及其他可以根据数据和任务定制的元素。'
- en: 'For example, suppose you want to use a language model to generate a translation
    from one language to another. You can use a prompt template like this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想使用语言模型将一种语言翻译成另一种语言。你可以使用如下提示模板：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`{sentence}` is a variable that will be replaced by the actual text. `Translation
    in {language}:` is a prefix that indicates the task and the expected output format.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`{sentence}`是一个变量，将被实际文本替换。`翻译成{语言}：`是一个前缀，表示任务和期望的输出格式。'
- en: 'You can easily implement this template as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以轻松地按照以下方式实现此模板：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the output:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Generally speaking, prompt templates tend to be agnostic with respect to the
    LLM you might decide to use, and it is adaptable to both completion and chat models.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，提示模板对可能决定使用的LLM通常是中立的，并且可以适应完成和聊天模型。
- en: '**Definition**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: A completion model is a type of LLM that takes a text input and generates a
    text output, which is called a completion. The completion model tries to continue
    the prompt in a coherent and relevant way, according to the task and the data
    it was trained on. For example, a completion model can generate summaries, translations,
    stories, code, lyrics, and more, depending on the prompt.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 完成模型是一种LLM，它接收文本输入并生成文本输出，这被称为完成。完成模型试图根据任务和它所训练的数据，以连贯和相关的的方式进行提示的延续。例如，完成模型可以生成摘要、翻译、故事、代码、歌词等，具体取决于提示。
- en: A chat model is a special kind of completion model that is designed to generate
    conversational responses. A chat model takes a list of messages as input, where
    each message has a role (either system, user, or assistant) and content. The chat
    model tries to generate a new message for the assistant role, based on the previous
    messages and the system instruction.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天模型是一种特殊的完成模型，旨在生成对话式响应。聊天模型接收一系列消息作为输入，其中每个消息都有一个角色（系统、用户或助手）和内容。聊天模型试图根据之前的消息和系统指令为助手角色生成一条新消息。
- en: The main difference between completion and chat models is that completion models
    expect a single text input as a prompt, while chat models expect a list of messages
    as input.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 完成模型和聊天模型之间的主要区别在于，完成模型期望一个单独的文本输入作为提示，而聊天模型期望一个消息列表作为输入。
- en: '**Example selector**: An example selector is a component in LangChain that
    allows you to choose which examples to include in a prompt for a language model.
    A prompt is a text input that guides the language model to produce a desired output.
    Examples are pairs of inputs and outputs that demonstrate the task and the format
    of the output as follows:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例选择器**：示例选择器是LangChain中的一个组件，允许你选择要包含在语言模型提示中的示例。提示是一个文本输入，它指导语言模型产生期望的输出。示例是输入和输出的配对，展示了任务和输出格式的如下：'
- en: '[PRE5]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The idea recalls the concept of few-shot learning we covered in *Chapter 1*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法让人想起了我们在*第一章*中讨论的少样本学习概念。
- en: LangChain offers the example selector class called `BaseExampleSelector` that
    you can import and modify as you wish. You can find the API reference at [https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/](https://platform.openai.com/account/api-keys).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了一个名为`BaseExampleSelector`的示例选择器类，你可以按需导入和修改。你可以在[https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/](https://platform.openai.com/account/api-keys)找到API参考。
- en: Data connections
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据连接
- en: Data connections refer to the building blocks needed to retrieve the additional
    non-parametric knowledge we want to provide the model with.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据连接指的是构建所需以检索我们希望提供给模型的额外非参数化知识的构建块。
- en: 'The idea is to cover the typical flow of incorporating user-specific data into
    applications that are made of five main blocks, as illustrated in the following
    figure:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 想法是涵盖将用户特定数据融入由五个主要块组成的应用程序中的典型流程，如下面的图所示：
- en: '![data_connection_diagram](img/B21714_05_02.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![data_connection_diagram](img/B21714_05_02.png)'
- en: 'Figure 5.2: Incorporating user-specific knowledge into LLMs (source: [https://python.langchain.com/docs/modules/data_connection/](https://python.langchain.com/docs/modules/data_connection/))'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：将用户特定知识融入LLM（来源：[https://python.langchain.com/docs/modules/data_connection/](https://python.langchain.com/docs/modules/data_connection/))
- en: 'Those blocks are addressed with the following LangChain tools:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些块使用以下LangChain工具进行操作：
- en: '**Document loaders**: They are in charge of loading documents from different
    sources such as CSV, file directory, HTML, JSON, Markdown, and PDF. Document loaders
    expose a `.load` method for loading data as documents from a configured source.
    The output is a `Document` object that contains a piece of text and associated
    metadata.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档加载器**：它们负责从不同的来源（如CSV、文件目录、HTML、JSON、Markdown和PDF）加载文档。文档加载器提供了一个`.load`方法，用于从配置的源加载数据作为文档。输出是一个包含文本和相关元数据的`Document`对象。'
- en: 'For example, let’s consider a sample CSV file to be loaded (you can find the
    whole code in the book’s GitHub repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，让我们考虑一个要加载的样本CSV文件（你可以在本书的GitHub仓库中找到完整的代码：[https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)):'
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the output:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Document transformers**: After importing your documents, it’s common to modify
    them to better match your needs. A basic instance of this is breaking down a lengthy
    document into smaller chunks that fit your model’s context window. Within LangChain,
    there are various pre-built document transformers available called **text splitters**.
    The idea of text splitters is to make it easier to split documents into chunks
    that are semantically related so that we do not lose context or relevant information.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档转换器**：在导入您的文档后，通常需要修改它们以更好地满足您的需求。一个基本的例子是将一个冗长的文档拆分成适合您模型上下文窗口的小块。在LangChain中，有各种预构建的文档转换器可用，称为**文本拆分器**。文本拆分器的想法是使将文档拆分成语义相关的块变得更容易，这样我们就不会丢失上下文或相关信息。'
- en: With text splitters, you can decide how to split the text (for example, by character,
    heading, token, and so on) and how to measure the length of the chunk (for example,
    by number of characters).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用文本拆分器，您可以决定如何拆分文本（例如，按字符、标题、标记等）以及如何衡量块长度（例如，按字符数）。
- en: 'For example, let’s split a document using the `RecursiveCharacterTextSplitter`
    module, which operates at a character level. For this purpose, we will be using
    a `.txt` file about mountains (you can find the whole code in the book’s GitHub
    repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们使用`RecursiveCharacterTextSplitter`模块拆分文档，该模块在字符级别上操作。为此，我们将使用关于山脉的`.txt`文件（您可以在本书的GitHub仓库[https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)中找到整个代码）：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, `chunk_size` refers to the number of characters in each chunk while `chunk_overlap`
    represents the number of characters overlapping between successive chunks. Here
    is the output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`chunk_size`指的是每个块中的字符数，而`chunk_overlap`表示连续块之间重叠的字符数。以下是输出结果：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Text embedding models**: In *Chapter 1*, in the *Under the hood of an LLM*
    section, we introduced the concept of embedding as a way to represent words, subwords,
    or characters in a continuous vector space.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本嵌入模型**：在*第一章*的*LLM内部结构*部分，我们介绍了嵌入的概念，作为在连续向量空间中表示单词、子词或字符的方法。'
- en: Embeddings are the key step in incorporating non-parametric knowledge into LLMs.
    In fact, once properly stored in a VectorDB (which will be covered in the next
    section), they become the non-parametric knowledge against which we can measure
    the distance of a user’s query.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入是将非参数知识纳入LLM的关键步骤。实际上，一旦在VectorDB（将在下一节中介绍）中正确存储，它们就成为了我们可以用来衡量用户查询距离的非参数知识。
- en: To get started with embedding, you will need an embedding model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用嵌入，您需要一个嵌入模型。
- en: Then, LangChain offers the `Embedding` class with two main modules, which address
    the embedding of, respectively, the non-parametric knowledge (multiple input text)
    and the user query (single input text).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，LangChain提供了`Embedding`类，包含两个主要模块，分别处理非参数知识（多个输入文本）和用户查询（单个输入文本）的嵌入。
- en: 'For example, let’s consider the embeddings using the **OpenAI** embedding model
    `text-embedding-ada-002` (for more details about OpenAI embedding models, you
    can refer to the official documentation at [https://platform.openai.com/docs/guides/embeddings/what-are-embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑使用**OpenAI**的嵌入模型`text-embedding-ada-002`（有关OpenAI嵌入模型的更多详细信息，您可以参考官方文档[https://platform.openai.com/docs/guides/embeddings/what-are-embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)）的嵌入：
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is the output:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出结果：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Once we have both documents and the query embedded, the next step will be to
    compute the similarity between the two elements and retrieve the most suitable
    information from the document embedding. We will see the details of this when
    talking about vector stores.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将文档和查询嵌入，下一步将是计算这两个元素之间的相似度，并从文档嵌入中检索最合适的信息。当谈到向量存储时，我们将看到这个过程的细节。
- en: '**Vector stores**: A vector store (or VectorDB) is a type of database that
    can store and search over unstructured data, such as text, images, audio, or video,
    by using embeddings. By using embeddings, vector stores can perform a fast and
    accurate similarity search, which means finding the most relevant data for a given
    query.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量存储**：向量存储（或向量数据库）是一种可以存储和搜索非结构化数据（如文本、图像、音频或视频）的数据库类型，它通过使用嵌入来实现。通过使用嵌入，向量存储可以执行快速且准确的相似度搜索，这意味着为给定的查询找到最相关的数据。'
- en: '**Definition**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Similarity is a measure of how close or related two vectors are in a vector
    space. In the context of LLMs, vectors are numerical representations of sentences,
    words, or documents that capture their semantic meaning, and the distance between
    those vectors should be representative of their semantic similarity.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度是衡量两个向量在向量空间中接近程度或相关性的度量。在LLM的上下文中，向量是句子的、单词或文档的数值表示，它们捕捉了它们的语义意义，这些向量之间的距离应该代表它们的语义相似度。
- en: There are different ways to measure similarity between vectors, and while working
    with LLMs, one of the most popular measures in use is cosine similarity.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 测量向量之间相似性的方法有很多，而在与LLM一起工作时，最常用的度量之一是余弦相似度。
- en: This is the cosine of the angle between two vectors in a multidimensional space.
    It is computed as the dot product of the vectors divided by the product of their
    lengths. Cosine similarity is insensitive to scale and location, and it ranges
    from -1 to 1, where 1 means identical, 0 means orthogonal, and -1 means opposite.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是多维空间中两个向量之间角度的余弦值。它是通过向量的点积除以它们长度的乘积来计算的。余弦相似度对规模和位置不敏感，其范围从-1到1，其中1表示相同，0表示正交，-1表示相反。
- en: The following is an illustration of the typical flow while using a vector store.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在使用向量存储时的典型流程图示。
- en: '![vector store diagram](img/B21714_05_03.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![向量存储图](img/B21714_05_03.png)'
- en: 'Figure 5.3: Sample architecture of a vector store (source: [https://python.langchain.com/docs/modules/data_connection/vectorstores/](https://python.langchain.com/docs/modules/data_connection/vectorstores/))'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：向量存储的示例架构（来源：[https://python.langchain.com/docs/modules/data_connection/vectorstores/](https://python.langchain.com/docs/modules/data_connection/vectorstores/))
- en: LangChain offers more than 40 integrations with third-party vector stores. Some
    examples are **Facebook AI Similarity Search** (**FAISS**), Elasticsearch, MongoDB
    Atlas, and Azure Search. For an exhaustive list and descriptions of all the integrations,
    you can check the official documentation at [https://python.langchain.com/docs/integrations/vectorstores/](https://python.langchain.com/docs/integrations/vectorstores/).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了与第三方向量存储超过40种集成。一些例子包括**Facebook AI Similarity Search**（**FAISS**）、Elasticsearch、MongoDB
    Atlas和Azure Search。要查看所有集成的完整列表和描述，您可以查看官方文档：[https://python.langchain.com/docs/integrations/vectorstores/](https://python.langchain.com/docs/integrations/vectorstores/).
- en: 'As an example, let’s leverage the FAISS vector store, which has been developed
    by Meta AI research for efficient similarity search and clustering of dense vectors.
    We are going to leverage the same `dialogue.txt` file saved in the previous section:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们利用由Meta AI研究开发的FAISS向量存储，它用于高效地搜索和聚类密集向量。我们将利用上一节中保存的相同的`dialogue.txt`文件：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we’ve embedded and saved the non-parametric knowledge, let’s also
    embed a user’s query so that it can be used to search the most similar text chunk
    using cosine similarity as a measure:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经嵌入并保存了非参数化知识，让我们也嵌入一个用户的查询，以便可以使用余弦相似度作为度量来搜索最相似的文字片段：
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following is the output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, the output is the piece of text that is more likely to contain
    the answer to the question. In an end-to-end scenario, it will be used as context
    to the LLM to generate a conversational response.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，输出的是更可能包含问题答案的文字片段。在端到端场景中，它将被用作LLM的上下文以生成对话式响应。
- en: '**Retrievers**: A retriever is a component in LangChain that can return documents
    relevant to an unstructured query, such as a natural language question or a keyword.
    A retriever does not need to store the documents itself, but only to retrieve
    them from a source. A retriever can use different methods to find relevant documents,
    such as keyword matching, semantic search, or ranking algorithms.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索器**：在LangChain中，检索器是一个可以返回与无结构查询（如自然语言问题或关键词）相关的文档的组件。检索器不需要自己存储文档，只需从源中检索它们。检索器可以使用不同的方法来查找相关文档，例如关键词匹配、语义搜索或排名算法。'
- en: The difference between a retriever and a vector store is that a retriever is
    more general and flexible than a vector store. A retriever can use any method
    to find relevant documents, while a vector store relies on embeddings and similarity
    metrics. A retriever can also use different sources of documents, such as web
    pages, databases, or files, while a vector store needs to store the data itself.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器和向量存储之间的区别在于，检索器比向量存储更通用和灵活。检索器可以使用任何方法来查找相关文档，而向量存储依赖于嵌入和相似性度量。检索器还可以使用不同的文档来源，如网页、数据库或文件，而向量存储需要存储数据本身。
- en: However, a vector store can also be used as the backbone of a retriever if the
    data is embedded and indexed by a vector store. In that case, the retriever can
    use the vector store to perform a similarity search over the embedded data and
    return the most relevant documents. This is one of the main types of retrievers
    in LangChain, and it is called a vector store retriever.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果数据被嵌入并由向量存储索引，向量存储也可以用作检索器的骨干。在这种情况下，检索器可以使用向量存储在嵌入数据上执行相似性搜索，并返回最相关的文档。这是LangChain中检索器的主要类型之一，被称为向量存储检索器。
- en: 'For example, let’s consider the FAISS vector store we previously initialized
    and “mount” a retriever on top of that:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑我们之前初始化并“安装”在之上的FAISS向量存储：
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here is the output:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Overall, data connection modules offer a plethora of integrations and pre-built
    templates that make it easier to manage the flow of your LLM-powered application.
    We will see some concrete applications of these building blocks in the upcoming
    chapters, but in the next section, we are going to take a deep dive into another
    one of LangChain’s main components.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，数据连接模块提供了大量的集成和预构建模板，使管理您由LLM驱动的应用程序的流程变得更加容易。我们将在接下来的章节中看到这些构建块的一些具体应用，但在下一节中，我们将深入探讨LangChain的另一个主要组件。
- en: Memory
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记忆
- en: In the context of LLM-powered applications, memory allows the application to
    keep references to user interactions, both in the short and long term. For example,
    let’s consider the well-known ChatGPT. While interacting with the application,
    you have the possibility to ask follow-up questions referencing previous interactions
    without explicitly telling the model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM驱动的应用程序的背景下，内存允许应用程序在短期和长期内保持对用户交互的引用。例如，让我们考虑广为人知的ChatGPT。在与应用程序交互时，您有提出后续问题的可能性，这些后续问题引用了之前的交互，而无需明确告诉模型。
- en: Plus, all conversations are saved into threads, so that, if you want to follow
    up on a previous conversation, you can re-open the thread without providing ChatGPT
    with all the contexts. This is made possible thanks to ChatGPT’s ability to store
    users’ interactions into a memory variable and use this memory as context while
    addressing follow-up questions.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，所有对话都保存到线程中，这样，如果你想跟进之前的对话，你可以重新打开线程，而无需向ChatGPT提供所有上下文。这得益于ChatGPT能够将用户的交互存储到内存变量中，并在回答后续问题时使用这些记忆作为上下文。
- en: LangChain offers several modules for designing your memory system within your
    applications, enabling it with both reading and writing skills.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain为设计您在应用程序中的内存系统提供了几个模块，使其具备读取和写入的能力。
- en: The first step to do with your memory system is to actually store your human
    interactions somewhere. To do so, you can leverage numerous built-in memory integrations
    with third-party providers, including Redis, Cassandra, and Postgres.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您的内存系统的第一步是将您与人类的交互实际存储在某处。为此，您可以利用与第三方提供商（包括Redis、Cassandra和Postgres）的众多内置内存集成。
- en: 'Then, when it comes to defining how to query your memory system, there are
    various memory types you can leverage:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当涉及到定义如何查询您的内存系统时，您可以利用各种内存类型：
- en: '**Conversation buffer memory**: This is the “plain vanilla” memory type available
    in LangChain. It allows you to store your chat messages and extract them in a
    variable.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话缓冲区内存**：这是LangChain中可用的“普通香草”内存类型。它允许您存储您的聊天消息并在变量中提取它们。'
- en: '**Conversation buffer window memory**: It is identical to the previous one,
    with the only difference being allowing a sliding window over only *K* interactions
    so that you can manage longer chat history over time.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话缓冲区窗口内存**：它与前面的类型相同，唯一的区别是只允许在只有*K*次交互上进行滑动窗口，这样您就可以随着时间的推移管理更长的聊天历史。'
- en: '**Entity memory**: Entity memory is a feature of LangChain that allows the
    language model to remember given facts about specific entities in a conversation.
    An entity is a person, place, thing, or concept that can be identified and distinguished
    from others. For example, in the sentence “Deven and Sam are working on a hackathon
    in Italy,” Deven and Sam are entities (person), as well as hackathon (thing) and
    Italy (place).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实体内存**：实体内存是LangChain的一个功能，允许语言模型记住会话中特定实体的给定事实。实体是一个可以识别并与其他区分开的人、地点、事物或概念。例如，在句子“Deven和Sam正在意大利参加黑客马拉松”中，Deven和Sam是实体（人），以及黑客马拉松（事物）和意大利（地点）。'
- en: Entity memory works by extracting information on entities from the input text
    using an LLM. It then builds up its knowledge about that entity over time by storing
    the extracted facts in a memory store. The memory store can be accessed and updated
    by the language model whenever it needs to recall or learn new information about
    an entity.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 实体内存通过使用LLM从输入文本中提取有关实体的信息来工作。然后，它通过在内存存储中存储提取的事实来随着时间的推移建立对该实体的知识。内存存储可以在语言模型需要回忆或学习有关实体的新信息时被访问和更新。
- en: '**Conversation knowledge graph memory**: This type of memory uses a knowledge
    graph to recreate memory.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会话知识图谱内存**：这种类型的内存使用知识图谱来重建记忆。'
- en: '**Definition**'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**定义**'
- en: A knowledge graph is a way of representing and organizing knowledge in a graph
    structure, where nodes are entities and edges are relationships between them.
    A knowledge graph can store and integrate data from various sources, and encode
    the semantics and context of the data. A knowledge graph can also support various
    tasks, such as search, question answering, reasoning, and generation.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 知识图谱是一种以图结构表示和组织知识的方式，其中节点是实体，边是它们之间的关系。知识图谱可以存储和整合来自各种来源的数据，并编码数据的语义和上下文。知识图谱还可以支持各种任务，如搜索、问答、推理和生成。
- en: Another example of a knowledge graph is DBpedia, which is a community project
    that extracts structured data from Wikipedia and makes it available on the web.
    DBpedia covers topics such as geography, music, sports, and films, and provides
    links to other datasets like GeoNames and WordNet.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一个知识图谱的例子是DBpedia，这是一个社区项目，从维基百科中提取结构化数据并将其发布在网络上。DBpedia涵盖了地理、音乐、体育和电影等主题，并提供到其他数据集（如GeoNames和WordNet）的链接。
- en: You can use this type of memory to save the input and output of each conversation
    turn as knowledge triplets (such as subject, predicate, and object) and then use
    them to generate relevant and consistent responses based on the current context.
    You can also query the knowledge graph to get the current entities or the history
    of the conversation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这种类型的内存将每个会话轮次的输入和输出保存为知识三元组（如主语、谓语和宾语），然后根据当前上下文使用它们生成相关且一致的反应。您还可以查询知识图谱以获取当前实体或会话的历史。
- en: '**Conversation summary memory**: When it comes to longer conversations to be
    stored, this type of memory can be very useful, since it creates a summary of
    the conversation over time (leveraging an LLM).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会话摘要内存**：当涉及到要存储的较长的会话时，这种类型的内存非常有用，因为它随着时间的推移创建会话的摘要（利用LLM）。'
- en: '**Conversation summary buffer memory**: This type of memory combines the ideas
    behind buffer memory and conversation summary memory. It keeps a buffer of recent
    interactions in memory, but rather than just completely flushing old interactions
    (as occurs for the conversation buffer memory) it compiles them into a summary
    and uses both.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会话摘要缓冲内存**：这种类型的内存结合了缓冲内存和会话摘要内存背后的思想。它在内存中保留最近交互的缓冲，但与仅完全清除旧交互（如会话缓冲内存中发生的情况）不同，它将它们编译成摘要并使用它们。'
- en: '**Conversation token buffer memory**: It is similar to the previous one, with
    the difference that, to determine when to start summarizing the interactions,
    this type of memory uses token lengths rather than the number of interactions
    (as occurs in summary buffer memory).'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会话标记缓冲内存**：它与前面的一种类似，但不同之处在于，为了确定何时开始总结交互，这种类型的内存使用标记长度而不是交互次数（如摘要缓冲内存中发生的情况）。'
- en: '**Vector store-backed memory**: This type of memory leverages the concepts
    of embeddings and vector stores previously covered. It is different from all the
    previous memories since it stores interactions as vectors, and then retrieves
    the top *K* most similar texts every time it is queried, using a retriever.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于向量存储的内存**：这种类型的内存利用了之前介绍的嵌入和向量存储的概念。它与所有之前的内存不同，因为它将交互存储为向量，并在每次查询时使用检索器检索最相似的
    *K* 个文本。'
- en: 'LangChain provides specific modules for each of those memory types. Let’s consider
    an example with the conversation summary memory, where we will also need an LLM
    to generate the summary of the interactions:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain为每种内存类型提供了特定的模块。让我们以会话摘要内存为例，我们将还需要一个LLM来生成交互的摘要：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here is the output:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, the memory summarized the conversation, leveraging the **OpenAI**
    LLM we initialized.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，内存总结了对话，利用了我们初始化的**OpenAI** LLM。
- en: There is no recipe to define which memory to use within your applications; however,
    there are some scenarios that might be particularly suitable for specific memories.
    For example, a knowledge graph memory is useful for applications that need to
    access information from a large and diverse corpus of data and generate responses
    based on semantic relationships, while a conversation summary buffer memory could
    be suitable for creating conversational agents that can maintain a coherent and
    consistent context over multiple turns, while also being able to compress and
    summarize the previous dialogue history.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的应用程序中，没有固定的食谱来定义使用哪种内存；然而，有一些场景可能特别适合特定的内存。例如，知识图谱内存对于需要从大量且多样化的数据集中获取信息并基于语义关系生成响应的应用程序很有用，而会话摘要缓冲区内存可能适合创建能够在多个回合中保持连贯和一致上下文的对话代理，同时还能压缩和总结之前的对话历史。
- en: Chains
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 链
- en: Chains are predetermined sequences of actions and calls to LLMs that make it
    easier to build complex applications that require combining LLMs with each other
    or with other components.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 链是由预定义的动作序列和对LLM的调用组成的，这使得构建需要将LLM相互结合或与其他组件结合的复杂应用程序变得更加容易。
- en: 'LangChain offers four main types of chain to get started with:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了四种主要类型的链以供开始使用：
- en: '**LLMChain**: This is the most common type of chain. It consists of a prompt
    template, an LLM, and an optional **output parser**.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMChain**：这是最常见的链类型。它由一个提示模板、一个LLM和一个可选的**输出解析器**组成。'
- en: '**Definition**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: 'An output parser is a component that helps structure language model responses.
    It is a class that implements two main methods: `get_format_instructions` and
    `parse.` The `get_format_instructions` method returns a string containing instructions
    for how the output of a language model should be formatted. The `parse` method
    takes in a string (assumed to be the response from a language model) and parses
    it into some structure, such as a dictionary, a list, or a custom object.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 输出解析器是一个帮助结构化语言模型响应的组件。它是一个实现了两个主要方法的类：`get_format_instructions`和`parse`。`get_format_instructions`方法返回一个包含如何格式化语言模型输出的指令的字符串。`parse`方法接收一个字符串（假设是来自语言模型的响应）并将其解析为某种结构，例如字典、列表或自定义对象。
- en: This chain takes multiple input variables, uses `PromptTemplate` to format them
    into a prompt, passes it to the model, and then uses `OutputParser` (if provided)
    to parse the output of the LLM into a final format.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 此链接受多个输入变量，使用`PromptTemplate`将它们格式化为提示，将其传递给模型，然后使用（如果提供）`OutputParser`将LLM的输出解析为最终格式。
- en: 'For example, let’s retrieve the prompt template we built in the previous section:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们检索我们在上一节中构建的提示模板：
- en: '[PRE19]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let’s put it into an LLMChain:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将其放入一个LLMChain中：
- en: '[PRE20]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here is the output:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE21]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**RouterChain**: This is a type of chain that allows you to route the input
    variables to different chains based on some conditions. You can specify the conditions
    as functions or expressions that return a Boolean value. You can also specify
    the default chain to use if none of the conditions are met.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RouterChain**：这是一种允许您根据某些条件将输入变量路由到不同链的链类型。您可以指定条件为返回布尔值的函数或表达式。您还可以指定在没有任何条件满足时使用的默认链。'
- en: 'For example, you can use this chain to create a chatbot that can handle different
    types of requests, such as planning an itinerary or booking a restaurant reservation.
    To achieve this goal, you might want to differentiate two different prompts, depending
    on the type of query the user will make:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以使用这个链来创建一个能够处理不同类型请求的聊天机器人，比如规划行程或预订餐厅。为了实现这个目标，你可能需要根据用户将要提出的查询类型区分两个不同的提示：
- en: '[PRE22]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Thanks to RouterChain, we can build a chain that is able to activate a different
    prompt depending on the user’s query. I won’t post the whole code here (you can
    find the notebook on the book’s GitHub at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)),
    but you can see a sample output of how the chain reacts to two different user’s
    queries:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了路由链（RouterChain），我们可以构建一个能够根据用户的查询激活不同提示的链。我不会在这里发布整个代码（你可以在书的GitHub上找到笔记本[https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_05.xhtml)），但你可以看到链如何对两个不同的用户查询做出反应的示例输出：
- en: '[PRE23]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here is the output:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出结果：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here it is with a second query:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是第二个查询的结果：
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here is the output:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出结果：
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '**SequentialChain**: This is a type of chain that allows you to execute multiple
    chains in a sequence. You can specify the order of the chains and how they pass
    their outputs to the next chain. The simplest module of a sequential chain, takes
    by default the output of one chain as the input of the next chain. However, you
    can also use a more complex module to have more flexibility to set input and output
    among chains.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序链（SequentialChain**）：这是一种允许你按顺序执行多个链的链。你可以指定链的顺序以及它们如何将输出传递给下一个链。顺序链的最简单模块默认情况下将一个链的输出作为下一个链的输入。然而，你也可以使用更复杂的模块来在链之间设置更灵活的输入和输出。'
- en: 'As an example, let’s consider an AI system that is meant to first generate
    a joke on a given topic, and then translate it in to another language. To do so,
    we will first create two chains:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑一个旨在首先在一个给定主题上生成一个笑话，然后将其翻译成另一种语言的AI系统。为此，我们首先创建两个链：
- en: '[PRE27]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, let’s combine them using the `SimpleSequentialChain` module:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`SimpleSequentialChain`模块将它们结合起来：
- en: '[PRE28]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here is the output:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出结果：
- en: '[PRE29]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**TransformationChain**: This is a type of chain that allows you to transform
    the input variables or the output of another chain using some functions or expressions.
    You can specify the transformation as a function that takes the input or output
    as an argument and returns a new value, as well as specify the output format of
    the chain.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换链（TransformationChain**）：这是一种允许你使用某些函数或表达式来转换输入变量或另一个链的输出的链。你可以指定转换为一个函数，该函数接受输入或输出作为参数并返回一个新值，以及指定链的输出格式。'
- en: 'For example, let’s say we want to summarize a text, but before that, we want
    to rename one of the protagonists of the story (a cat) as “Silvester the Cat.”
    As a sample text, I asked Bing Chat to generate a story about cats and dogs (you
    can find the whole `.txt` file in the GitHub repository of this book):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要总结一段文本，但在那之前，我们想要将故事中的一个主角（一只猫）重命名为“Silvester the Cat”。作为一个示例文本，我要求Bing
    Chat生成一个关于猫和狗的故事（你可以在本书的GitHub仓库中找到整个`.txt`文件）：
- en: '[PRE30]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As you can see, we’ve combined a simple sequential chain with a transformation
    chain, where we set as a transformation function the `rename_cat` function (you
    can see the whole code in the GitHub repository).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们已经将一个简单的顺序链和一个转换链结合起来，我们将`rename_cat`函数（你可以在GitHub仓库中看到整个代码）设置为转换函数。
- en: 'The output is the following:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Overall, LangChain chains are a powerful way to combine different language
    models and tasks into a single workflow. Chains are flexible, scalable, and easy
    to use, and they enable users to leverage the power of language models for various
    purposes and domains. Starting from the next chapter, we are going to see chains
    in action in concrete use cases, but before getting there, we need to cover the
    last component of LangChain: agents.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，LangChain链是结合不同语言模型和任务到单一工作流程的强大方式。链是灵活的、可扩展的，并且易于使用，它们使用户能够利用语言模型在各个目的和领域发挥其力量。从下一章开始，我们将看到链在实际用例中的具体应用，但在到达那里之前，我们需要介绍LangChain的最后一个组件：代理。
- en: Agents
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理
- en: 'Agents are entities that drive decision-making within LLM-powered applications.
    They have access to a suite of tools and can decide which tool to call based on
    the user input and the context. Agents are dynamic and adaptive, meaning that
    they can change or adjust their actions based on the situation or the goal: in
    fact, while in a chain, the sequence of actions is hardcoded, in agents, the LLM
    is used as the reasoning engine with the goal of planning and executing the right
    actions in the right order.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是驱动 LLM 驱动的应用程序中决策的实体。它们可以访问一系列工具，并根据用户输入和上下文决定调用哪个工具。代理是动态和自适应的，这意味着它们可以根据情况或目标改变或调整其行为：实际上，在链中，动作序列是硬编码的，而在代理中，LLM
    被用作推理引擎，目的是按正确的顺序规划和执行正确的动作。
- en: A core concept while talking about agents is that of tools. In fact, an agent
    might be good at planning all the right actions to fulfill a user’s query, but
    what if it cannot actually execute them, since it is missing information or executive
    power? For example, imagine I want to build an agent that is capable of answering
    my questions by searching the web. By itself, the agent has no access to the web,
    so I need to provide it with this tool. I will do so by using SerpApi (the Google
    Search API) integration provided by LangChain (you can retrieve your API key at
    [https://serpapi.com/dashboard](https://serpapi.com/dashboard)).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论代理时的一个核心概念是工具的概念。事实上，一个代理可能擅长规划所有正确的动作来满足用户的查询，但它可能无法实际执行它们，因为它缺少信息或执行权力？例如，想象我想构建一个能够通过搜索网络来回答我问题的代理。仅凭自身，代理无法访问网络，因此我需要提供这个工具。我将通过使用
    LangChain 提供的 SerpApi（谷歌搜索 API）集成来实现这一点（你可以在 [https://serpapi.com/dashboard](https://serpapi.com/dashboard)
    获取你的 API 密钥）。
- en: 'Let’s see it in Python:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用 Python 看看：
- en: '[PRE32]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following is the output:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是其输出：
- en: '[PRE33]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Note that, while initializing my agent, I set the agent type as `ZERO_SHOT_REACT_DESCRIPTION`.
    This is one of the configurations we can pick and, specifically, it configures
    the agent to decide which tool to pick based solely on the tool’s description
    with a ReAct approach:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在初始化我的代理时，我将代理类型设置为 `ZERO_SHOT_REACT_DESCRIPTION`。这是我们可以选择的配置之一，具体来说，它配置代理仅根据工具的描述使用
    ReAct 方法来决定选择哪个工具：
- en: '**Definition**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: 'The ReAct approach is a way of using LLMs to solve various language reasoning
    and decision-making tasks. It was introduced in the paper *ReAct: Synergizing
    Reasoning and Acting in Language Models* by Shunyu Yao et al., back in October
    2022.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 'ReAct 方法是使用 LLM 解决各种语言推理和决策任务的一种方式。它是在 2022 年 10 月由 Shunyu Yao 等人撰写的论文 *ReAct:
    Synergizing Reasoning and Acting in Language Models* 中引入的。'
- en: The ReAct approach prompts LLMs to generate both verbal reasoning traces and
    text actions in an interleaved manner, allowing for greater synergy between the
    two. Reasoning traces help the model to plan, track, and update its actions, as
    well as handle exceptions. Actions allow the model to interact with external sources,
    such as knowledge bases or environments, to gather additional information.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct 方法以交错的方式提示 LLM 生成口头推理痕迹和文本动作，从而在两者之间实现更大的协同作用。推理痕迹有助于模型规划、跟踪和更新其动作，以及处理异常。动作允许模型与外部来源，如知识库或环境，交互以收集更多信息。
- en: 'On top of this configuration, LangChain also offers the following types of
    agents:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配置之上，LangChain 还提供了以下类型的代理：
- en: '**Structured input ReAct**: This is an agent type that uses the ReAct framework
    to generate natural language responses based on structured input data. The agent
    can handle different types of input data, such as tables, lists, or key-value
    pairs. The agent uses a language model and a prompt to generate responses that
    are informative, concise, and coherent.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化输入 ReAct**: 这是一个使用 ReAct 框架根据结构化输入数据生成自然语言响应的代理类型。代理可以处理不同类型的输入数据，例如表格、列表或键值对。代理使用语言模型和提示来生成信息丰富、简洁且连贯的响应。'
- en: '**OpenAI Functions**: This is an agent type that uses the OpenAI Functions
    API to access various language models and tools from OpenAI. The agent can use
    different functions, such as GPT-3, Codex, DALL-E, CLIP, or ImageGPT. The agent
    uses a language model and a prompt to generate requests to the OpenAI Functions
    API and parse the responses.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenAI Functions**: 这是一个使用 OpenAI Functions API 访问 OpenAI 的各种语言模型和工具的代理类型。代理可以使用不同的功能，例如
    GPT-3、Codex、DALL-E、CLIP 或 ImageGPT。代理使用语言模型和提示来生成对 OpenAI Functions API 的请求并解析响应。'
- en: '**Conversational**: This is an agent type that uses a language model to engage
    in natural language conversations with the user. The agent can handle different
    types of conversational tasks, such as chit-chat, question answering, or task
    completion. The agent uses a language model and a prompt to generate responses
    that are relevant, fluent, and engaging.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话式**：这是一种使用语言模型与用户进行自然语言对话的代理类型。代理可以处理不同类型的对话任务，如闲聊、问答或任务完成。代理使用语言模型和提示来生成相关、流畅且引人入胜的响应。'
- en: '**Self ask with search**: This is an agent type that uses a language model
    to generate questions for itself and then search for answers on the web. The agent
    can use this technique to learn new information or test its own knowledge.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自问自答**：这是一种使用语言模型为自己生成问题，然后在网络上搜索答案的代理类型。代理可以使用这种技术来学习新信息或测试自己的知识。'
- en: '**ReAct document store**: This is an agent type that uses the ReAct framework
    to generate natural language responses based on documents stored in a database.
    The agent can handle different types of documents, such as news articles, blog
    posts, or research papers.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReAct文档存储**：这是一种使用ReAct框架根据存储在数据库中的文档生成自然语言响应的代理类型。代理可以处理不同类型的文档，如新闻文章、博客文章或研究论文。'
- en: '**Plan-and-execute agents**: This is an experimental agent type that uses a
    language model to choose a sequence of actions to take based on the user’s input
    and a goal. The agent can use different tools or models to execute the actions
    it chooses. The agent uses a language model and a prompt to generate plans and
    actions and then uses `AgentExecutor` to run them.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计划与执行代理**：这是一种实验性代理类型，它使用语言模型根据用户的输入和目标选择一系列动作。代理可以使用不同的工具或模型来执行其选择的动作。代理使用语言模型和提示来生成计划和动作，然后使用`AgentExecutor`来运行它们。'
- en: LangChain agents are pivotal whenever you want to let your LLMs interact with
    the external world. Plus, it is interesting to see how agents leverage LLMs not
    only to retrieve and generate responses, but also as reasoning engines to plan
    an optimized sequence of actions.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain代理在您希望让您的LLMs与外部世界交互时至关重要。此外，观察代理如何利用LLMs不仅用于检索和生成响应，还作为推理引擎来规划一系列优化的动作顺序，这很有趣。
- en: Together with all the LangChain components covered in this section, agents can
    be the core of LLM-powered applications, as we will see in the next chapters.
    In the next section, we are going to shift toward the world of open-source LLMs,
    introducing the Hugging Face Hub and its native integration with LangChain.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 与本节中涵盖的所有LangChain组件一起，代理可以是LLM驱动应用程序的核心，正如我们将在下一章中看到的那样。在下一节中，我们将转向开源LLMs的世界，介绍Hugging
    Face Hub及其与LangChain的原生集成。
- en: Working with LLMs via the Hugging Face Hub
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Hugging Face Hub使用LLMs
- en: Now that we are familiar with LangChain components, it is time to start using
    our LLMs. If you want to use open-source LLMs, leveraging the Hugging Face Hub
    integration is extremely versatile. In fact, with just one access token you can
    leverage all the open-source LLMs available in Hugging Face’s repositories.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了LangChain组件，是时候开始使用我们的LLMs了。如果您想使用开源LLMs，利用Hugging Face Hub集成非常灵活。实际上，只需一个访问令牌，您就可以利用Hugging
    Face存储库中所有可用的开源LLMs。
- en: As it is a non-production scenario, I will be using the free Inference API;
    however, if you are meant to build production-ready applications, you can easily
    scale to the Inference Endpoint, which grants you a dedicated and fully managed
    infrastructure to host and consume your LLMs.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个非生产场景，我将使用免费的推理API；然而，如果您打算构建生产就绪的应用程序，您可以轻松扩展到推理端点，这为您提供了专用且完全管理的基础设施来托管和消费您的LLMs。
- en: So, let’s see how to start integrating LangChain with the Hugging Face Hub.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们看看如何开始将LangChain与Hugging Face Hub集成。
- en: Create a Hugging Face user access token
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建Hugging Face用户访问令牌
- en: 'To access the free Inference API, you will need a user access token, the credential
    that allows you to run the service. The following are the steps to activate the
    user access token:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问免费的推理API，您需要一个用户访问令牌，这是允许您运行服务的凭证。以下激活用户访问令牌的步骤：
- en: '**Create a Hugging Face account**: You can create a Hugging Face account for
    free at [https://huggingface.co/join](https://huggingface.co/join).'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建Hugging Face账户**：您可以在[https://huggingface.co/join](https://huggingface.co/join)免费创建Hugging
    Face账户。'
- en: '**Retrieve your user access token**: Once you have your account, go to the
    upper-right corner of your profile and go to **Settings** | **Access Tokens**.
    From that tab, you will be able to copy your secret token and use it to access
    Hugging Face models.'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索您的用户访问令牌**：一旦您有了账户，请转到您的个人资料右上角，转到 **设置** | **访问令牌**。从该选项卡，您将能够复制您的秘密令牌并使用它来访问
    Hugging Face 模型。'
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_05_04.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  自动生成的描述](img/B21714_05_04.png)'
- en: 'Figure 5.4: Retrieving access tokens from the Hugging Face account (source:
    [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4：从 Hugging Face 账户检索访问令牌（来源：[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
- en: '**Set permissions**: Access tokens enable users, applications, and notebooks
    to perform specific actions based on their assigned roles. There are two available
    roles:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置权限**：访问令牌使用户、应用程序和笔记本能够根据其分配的角色执行特定操作。有两种可用的角色：'
- en: '**Read:** This allows tokens to provide read access to repositories you have
    permission to read. This includes public and private repositories owned by you
    or your organization. This role is suitable for tasks like downloading private
    models or inference.'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读取权限**：这允许令牌提供读取权限到您有读取权限的仓库。这包括您或您组织拥有的公共和私有仓库。此角色适用于下载私有模型或推理等任务。'
- en: '**Write:** In addition to read access, tokens with this role grant write access
    to repositories where you have writing privileges. This token is useful for activities
    like training models or updating model cards.'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**写入权限**：除了读取权限外，具有此角色的令牌还授予您对您有写入权限的仓库的写入权限。此令牌对于训练模型或更新模型卡片等活动很有用。'
- en: In our series of use cases, we will keep a write permission on our token.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的用例系列中，我们将保持对令牌的写入权限。
- en: '**Managing your user access token**: Within your profile, you can create and
    manage multiple access tokens, so that you can also differentiate permissions.
    To create a new token, you can click on the **New token** button:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**管理您的用户访问令牌**：在您的个人资料中，您可以创建和管理多个访问令牌，这样您也可以区分权限。要创建新的令牌，您可以点击 **新建令牌** 按钮：'
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_05_05.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  自动生成的描述](img/B21714_05_05.png)'
- en: 'Figure 5.5: Creating a new token'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5：创建新的令牌
- en: 'Finally, at any time, you can delete or refresh your token under the **Manage**
    button:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在任何时候，您都可以在 **管理** 按钮下删除或刷新您的令牌：
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_05_06.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  自动生成的描述](img/B21714_05_06.png)'
- en: 'Figure 5.6: Managing tokens'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6：管理令牌
- en: It is important not to leak your token, and a good practice is to periodically
    regenerate it.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是不要泄露您的令牌，一个良好的做法是定期重新生成它。
- en: Storing your secrets in an .env file
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 `.env` 文件中存储您的秘密
- en: With our user access token generated in the previous section, we have the first
    secret to be managed.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中生成的用户访问令牌，我们有了第一个需要管理的秘密。
- en: '**Definition**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Secrets are data that needs to be protected from unauthorized access, such as
    passwords, tokens, keys, and credentials. Secrets are used to authenticate and
    authorize requests to API endpoints, as well as to encrypt and decrypt sensitive
    data.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密是需要保护免受未经授权访问的数据，例如密码、令牌、密钥和凭证。秘密用于验证和授权对 API 端点的请求，以及加密和解密敏感数据。
- en: Throughout this hands-on portion of the book, we will keep all our secrets within
    an `.env` file.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的动手实践部分，我们将把所有秘密都保存在 `.env` 文件中。
- en: 'Storing Python secrets in an `.env` file is a common practice to enhance security
    and maintainability in projects. To do this, create a file named `.env` in your
    project directory and list your sensitive information as key-value pairs: in our
    scenario, we will have `HUGGINGFACEHUB_API_TOKEN="your_user_access_token"`. This
    file should be added to your project’s `.gitignore` to prevent accidental exposure.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `.env` 文件中存储 Python 秘密是提高项目安全性和可维护性的常见做法。为此，在您的项目目录中创建一个名为 `.env` 的文件，并将您的敏感信息作为键值对列出：在我们的场景中，我们将有
    `HUGGINGFACEHUB_API_TOKEN="your_user_access_token"`。此文件应添加到您的项目 `.gitignore` 文件中，以防止意外泄露。
- en: To access these secrets in your Python code, use the `python-dotenv` library
    to load the `.env` file’s values as environment variables. You can easily install
    it in your terminal via `pip install python-dotenv`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的 Python 代码中访问这些秘密，请使用 `python-dotenv` 库将 `.env` 文件中的值加载为环境变量。您可以通过在终端中运行
    `pip install python-dotenv` 来轻松安装它。
- en: This approach keeps sensitive data separate from your code base and helps ensure
    that confidential information remains confidential throughout the development
    and deployment processes.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将敏感数据与您的代码库分开，有助于确保在整个开发和部署过程中，机密信息保持机密。
- en: 'Here, you can see an example of how to retrieve your access token and set it
    as an environmental variable:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到一个如何检索您的访问令牌并将其设置为环境变量的示例：
- en: '[PRE34]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Note that, by default, `load_dotenv` will look for the `.env` file in the current
    working directory; however, you can also specify the path to your secrets file:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，`load_dotenv`将在当前工作目录中查找`.env`文件；但是，您也可以指定您的机密文件路径：
- en: '[PRE35]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Now that we have all the ingredients to start coding, it is time to try out
    some open-source LLMs.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了开始编码的所有原料，是时候尝试一些开源LLM了。
- en: Start using open-source LLMs
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用开源LLM
- en: 'The nice thing about the Hugging Face Hub integration is that you can navigate
    its portal and decide, within the model catalog, what to use. Models are also
    clustered per category (**Computer Vision**, **Natural Language Processing**,
    **Audio**, and so on) and, within each category, per capability (within **Natural
    Language Processing**, we have summarization, classification, Q&A, and so on),
    as shown in the following screenshot:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face Hub集成的优点在于，您可以导航其门户，在模型目录中决定使用什么。模型也按类别（**计算机视觉**、**自然语言处理**、**音频**等）和每个类别内的能力（在**自然语言处理**中，我们有摘要、分类、问答等）进行分组，如下面的截图所示：
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_05_07.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图的自动生成描述](img/B21714_05_07.png)'
- en: 'Figure 5.7: Home page of Hugging Face’s model catalog'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7：Hugging Face模型目录的首页
- en: 'Since we are interested in LLMs, we will focus on the text generation category.
    For this first experiment, let’s try Falcon LLM-7B:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们对LLM感兴趣，我们将专注于文本生成类别。在这个第一次实验中，让我们尝试Falcon LLM-7B：
- en: '[PRE36]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here is the corresponding output:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是相应的输出：
- en: '[PRE37]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As you can see, with just a few lines of code, we integrated an LLM from the
    Hugging Face Hub. With analogous code, you can test and consume all the LLMs available
    in the Hub.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，仅用几行代码，我们就从Hugging Face Hub集成了LLM。使用类似的代码，您可以测试和消费Hub中可用的所有LLM。
- en: Note that, throughout this book, we will be leveraging specific models for each
    application, both proprietary and open source. However, the idea is that you can
    use the model you prefer by simply initializing it as the main LLM and running
    the code as it is, simply changing the LangChain LLM integration. This is one
    of the main advantages of LLM-powered applications since you don’t have to change
    the whole code to adapt to different LLMs.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在本书中，我们将针对每个应用利用特定的模型，无论是专有模型还是开源模型。然而，想法是您可以通过简单地将其初始化为主LLM并按原样运行代码，只需更改LangChain
    LLM集成，就可以使用您偏好的模型。这是LLM驱动应用程序的主要优势之一，因为您不需要更改整个代码来适应不同的LLM。
- en: Summary
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we dove deeper into the fundamentals of LangChain, since it
    will be the AI orchestrator used in the upcoming chapters: we got familiar with
    LangChain components such as memory, agents, chains, and prompt templates. We
    also covered how to start integrating LangChain with the Hugging Face Hub and
    its model catalog, and how to use the available LLMs and start embedding them
    into your code.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们更深入地探讨了LangChain的基础知识，因为它是将在后续章节中使用的AI编排器：我们熟悉了LangChain组件，如内存、代理、链和提示模板。我们还介绍了如何开始将LangChain与Hugging
    Face Hub及其模型目录集成，以及如何使用可用的LLM并将它们嵌入到您的代码中。
- en: From now on, we will look at a series of concrete end-to-end use cases, starting
    from a semantic Q&A search app, which we are going to develop in the next chapter.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将探讨一系列具体的端到端用例，从语义问答搜索应用开始，这是我们将在下一章中开发的。
- en: References
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: LangChain’s integration with OpenAI – [https://python.langchain.com/docs/integrations/llms/openai](https://python.langchain.com/docs/integrations/llms/openai)
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain与OpenAI的集成 - [https://python.langchain.com/docs/integrations/llms/openai](https://python.langchain.com/docs/integrations/llms/openai)
- en: LangChain’s prompt templates – [https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain的提示模板 - [https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/)
- en: LangChain’s vector stores – [https://python.langchain.com/docs/integrations/vectorstores/](https://python.langchain.com/docs/integrations/vectorstores/)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain 的向量存储 – [https://python.langchain.com/docs/integrations/vectorstores/](https://python.langchain.com/docs/integrations/vectorstores/)
- en: FAISS index – [https://faiss.ai/](https://faiss.ai/)
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FAISS 索引 – [https://faiss.ai/](https://faiss.ai/)
- en: LangChain’s chains – [https://python.langchain.com/docs/modules/chains/](https://python.langchain.com/docs/modules/chains/)
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain 的链 – [https://python.langchain.com/docs/modules/chains/](https://python.langchain.com/docs/modules/chains/)
- en: ReAct approach – [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReAct 方法 – [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
- en: LangChain’s agents – [https://python.langchain.com/docs/modules/agents/agent_types/](https://python.langchain.com/docs/modules/agents/agent_types/)
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain 的代理 – [https://python.langchain.com/docs/modules/agents/agent_types/](https://python.langchain.com/docs/modules/agents/agent_types/)
- en: Hugging Face documentation – [https://huggingface.co/docs](https://huggingface.co/docs)
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hugging Face 文档 – [https://huggingface.co/docs](https://huggingface.co/docs)
- en: LangChain Expression Language (LCEL) – [https://python.langchain.com/docs/expression_language/](https://python.langchain.com/docs/expression_language/)
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain 表达式语言 (LCEL) – [https://python.langchain.com/docs/expression_language/](https://python.langchain.com/docs/expression_language/)
- en: LangChain stable version – [https://blog.langchain.dev/langchain-v0-1-0/](https://blog.langchain.dev/langchain-v0-1-0/)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain 稳定版本 – [https://blog.langchain.dev/langchain-v0-1-0/](https://blog.langchain.dev/langchain-v0-1-0/)
- en: Join our community on Discord
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/llm](https://packt.link/llm)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/llm](https://packt.link/llm)'
- en: '![](img/QR_Code214329708533108046.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code214329708533108046.png)'
