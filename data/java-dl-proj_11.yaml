- en: Discussion, Current Trends, and Outlook
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论、当前趋势和展望
- en: Deep neural networks being at the core of **deep learning** (**DL**) allow computational
    models that are composed of multiple processing layers to learn representations
    of data with multiple levels of abstraction. These methods have dramatically improved
    the state-of-the-art stuff in speech recognition, multimedia (image/audio/video)
    analytics, NLP, image processing and segmentation, visual object recognition,
    object detection, and many other domains in life sciences, such as cancer genomics,
    drug discovery, personalized medicine, and biomedical imaging.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络作为**深度学习**（**DL**）的核心，使得由多个处理层组成的计算模型能够学习数据的多层次抽象表示。这些方法极大地提升了语音识别、多媒体（图像/音频/视频）分析、自然语言处理、图像处理与分割、视觉物体识别、物体检测以及许多生命科学领域（如癌症基因组学、药物发现、个性化医学和生物医学影像）的前沿技术。
- en: Throughout this book, we have seen how to use JVM-based DL libraries to develop
    some applications covering these areas. I confess that some projects were not
    so comprehensive and cannot be deployed commercially but need some extra effort.
    Nonetheless, showing how to deploy such models was not within the scope of this
    book. However, at least these should provide us with some core insights.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们展示了如何使用基于JVM的深度学习库来开发涵盖这些领域的应用程序。我承认，某些项目并不那么全面，无法商业化部署，但需要一些额外的努力。尽管如此，展示如何部署这些模型并不在本书的范围之内。然而，至少这些项目为我们提供了一些核心的见解。
- en: 'Now that we''ve come to the end of our little journey of deep learning with
    different Java libraries, it is time to wrap up everything. But before that, in
    this chapter, we''ll discuss the completed projects and some abstract takeaways.
    Then we''ll provide some suggestions for improvement. Additionally, we''ll cover
    some extension guidelines for other real-life deep learning projects. In summary,
    the following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经结束了这段关于使用不同Java库进行深度学习的小旅程，是时候总结一切了。但在此之前，在本章中，我们将讨论已完成的项目和一些抽象的收获。接着，我们会提出一些改进建议。此外，我们还将涵盖其他实际深度学习项目的扩展指南。总的来说，本章将覆盖以下内容：
- en: Discussions on projects, outlook, future improvement, and extension
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对项目的讨论、展望、未来改进与扩展
- en: Current trends on supervised and unsupervised deep learning algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前监督学习与无监督学习深度学习算法的趋势
- en: Frequently asked questions (FAQs)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见问题解答（FAQ）
- en: Discussion and outlook
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论与展望
- en: Throughout this book, we have covered 10 end-to-end projects. We started our
    journey with an introduction to deep learning and finished at a factorization-machine
    based movie recommendation system project. In this section, we'll briefly review
    these projects, discuss potential limitations, and provide some future directions
    toward improvement and extension.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们涵盖了10个端到端的项目。从深度学习的介绍开始，到基于因式分解机的电影推荐系统项目结束。在这一部分，我们将简要回顾这些项目，讨论潜在的局限性，并提供一些未来的改进和扩展方向。
- en: Discussion on the completed projects
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对已完成项目的讨论
- en: 'In between, we tried to cover several real-life projects from diverse domains
    such as healthcare, sentiment analysis in NLP, transfer learning, image and video
    classification, distributed deep learning and training, reinforcement learning,
    online trading, and real-life object detection from video. These are outlined
    as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们尽力涵盖了多个来自不同领域的实际项目，如医疗保健、自然语言处理中的情感分析、迁移学习、图像和视频分类、分布式深度学习与训练、强化学习、在线交易以及视频中的实际物体检测。具体如下：
- en: Titanic survival prediction using MLP and LSTM networks
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MLP和LSTM网络进行泰坦尼克号生还预测
- en: Cancer types prediction using recurrent type networks
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用递归网络进行癌症类型预测
- en: Multi-label Image classification using convolutional neural networks
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积神经网络进行多标签图像分类
- en: Sentiment analysis using Word2Vec and LSTM network
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Word2Vec和LSTM网络进行情感分析
- en: Image classification using transfer learning
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用迁移学习进行图像分类
- en: Real-time object detection using YOLO, JavaCV, and DL4J
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用YOLO、JavaCV和DL4J进行实时物体检测
- en: Stock price prediction using the LSTM network
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LSTM网络进行股票价格预测
- en: Distributed deep learning for video classification using convolutional LSTM
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积LSTM进行视频分类的分布式深度学习
- en: Using deep reinforcement learning for a GridWorld game
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用深度强化学习进行GridWorld游戏
- en: Developing a movie recommendation system using factorization machines
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用因式分解机开发电影推荐系统
- en: Now we will discuss the pros, cons, and future directions for improving these
    projects for possible extension.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将讨论改进这些项目以进行可能扩展的优缺点和未来方向。
- en: Titanic survival prediction using MLP and LSTM networks
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 泰坦尼克号生存预测使用MLP和LSTM网络
- en: In this project, our main goal was to get familiar with Apache Spark ML library,
    followed by a basic introduction to machine learning, deep learning their types,
    architectures, and frameworks.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们的主要目标是熟悉Apache Spark ML库，然后基本介绍机器学习、深度学习它们的类型、架构和框架。
- en: We could not achieve higher accuracy. Then, in [Chapter 2](e27fb252-7892-4659-81e2-2289de8ce570.xhtml),
    *Cancer Types Prediction Using Recurrent Type Networks*, we revisited the same
    project but using a robust recurrent LSTM network, which shows higher accuracy.
    The takeaway was learning how to prepare the dataset by considering most of the
    features and feeding into Spark and a DL4J-based MLP classifier.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法获得更高的准确性。然后，在[第2章](e27fb252-7892-4659-81e2-2289de8ce570.xhtml)，*使用递归类型网络进行癌症类型预测*，我们重新审视了同一个项目，但是使用了一个强大的递归LSTM网络，显示了更高的准确性。要点是学习如何通过考虑大多数特征来准备数据集，并将其馈送到基于Spark和DL4J的MLP分类器中。
- en: In addition, this dataset is not so high dimensional, so applying DL methods
    is not a good idea. Therefore, I would recommend using other tree ensembles such
    as random forest and gradient-boosted trees for modeling and deployment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这个数据集并不是很高维，所以应用深度学习方法并不是一个好主意。因此，我建议使用其他树集成方法，如随机森林和梯度提升树进行建模和部署。
- en: Cancer type prediction using recurrent type networks
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 癌症类型预测使用递归类型网络
- en: We solved an interesting project, where we successfully classified cancer patients
    based on cancer types. For this, we used the LSTM network. We used a very high-dimensional
    gene expression dataset. We converted the dataset into sequence format and trained
    the LSTM net for each sample per time step.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决了一个有趣的项目，在这个项目中，我们成功地根据癌症类型对癌症患者进行了分类。为此，我们使用了LSTM网络。我们使用了一个非常高维的基因表达数据集。我们将数据集转换为序列格式，并为每个样本的每个时间步训练了LSTM网络。
- en: This project also shows the robustness of deep architecture such as LSTM, demonstrating
    that even without applying dimensionality reduction, the model can handle a very
    high-dimensional dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目还展示了深度结构如LSTM的稳健性，证明即使没有应用降维，该模型也可以处理非常高维的数据集。
- en: One of the potential limitations of this approach was that we considered only
    a gene expression dataset, so it cannot be deployed for a real-life prognosis
    and diagnosis, whereas other datasets such as **Copy Number Variation** (**CNV**),
    DNA methylation, and survival-related clinical outcomes, have to be considered
    as well. Nonetheless, domain expertise from biomedical engineers and doctors is
    needed to come up with an integrated solution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法的潜在限制之一是我们仅考虑了基因表达数据集，因此无法用于现实生活的预后和诊断，而其他数据集如**拷贝数变异**（**CNV**）、DNA甲基化和与生存相关的临床结果必须考虑在内。尽管如此，需要来自生物医学工程师和医生的领域专业知识，以提出一个集成解决方案。
- en: Finally, the takeaway is that at least it shows how to handle at least one type
    of cancer genomics dataset. Therefore, the same techniques can be applied to other
    data types too. Then, a multimodal network has to be developed by taking the input
    from domain experts before deploying, such as an AI expert system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，要点是至少显示了如何处理至少一种癌症基因组数据集。因此，同样的技术也可以应用于其他数据类型。然后，在部署之前，必须通过获取来自领域专家的输入，例如AI专家系统，来开发一个多模态网络。
- en: Image classification using convolutional neural networks
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积神经网络进行图像分类
- en: In this project, we saw how to solve a multi-label image classification problem.
    We used real Yelp images. Then we trained a CNN to predict the classes for each
    tagged image. In this project, the most challenging part was feature engineering,
    as we had to deal with not only images but also different tags and metadata. Unfortunately,
    we could not achieve very high accuracy.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们看到了如何解决多标签图像分类问题。我们使用了真实的Yelp图像。然后，我们训练了一个CNN来预测每个标记图像的类别。在这个项目中，最具挑战性的部分是特征工程，因为我们不仅要处理图像，还要处理不同的标签和元数据。不幸的是，我们无法达到非常高的准确性。
- en: The takeaway would be that similar approaches can be applied to solve other
    image datasets having multi-labels. Yet, a multiclass classification problem can
    be solved with minimal effort as well. All you need is to prepare the dataset
    such that a CNN-based model can consume it. Apart from this outlook, the project
    in [Chapter 5](2d4fc6f2-3753-456c-8774-3f41dbe13cfb.xhtml), *Image Classification
    using Transfer Learning,* can be extended to solve similar problems.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 关键收获是，类似的方法可以应用于解决具有多标签的其他图像数据集。然而，一个多分类问题也可以以最小的努力解决。你所需要做的就是准备数据集，使得基于CNN的模型能够处理它。除了这个前景外，[第5章](2d4fc6f2-3753-456c-8774-3f41dbe13cfb.xhtml)中的项目《使用迁移学习进行图像分类》可以扩展到解决类似问题。
- en: Sentiment analysis using Word2Vec and the LSTM network
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Word2Vec和LSTM网络进行情感分析
- en: In this project, we saw how to develop a sentiment analysis application using
    Word2Vec and LSTM. We also discussed how to convert unstructured texts into neural
    word embedding, and later on transform them into the sequence form required to
    train the LSTM network. Then we trained LSTM with the sequence of the corresponding
    texts at each time step.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们展示了如何使用Word2Vec和LSTM开发情感分析应用程序。我们还讨论了如何将非结构化文本转换为神经词嵌入，并进一步将其转换为训练LSTM网络所需的序列形式。接着，我们使用每个时间步长对应文本的序列训练LSTM。
- en: This project also addressed a binary classification problem with very high accuracy.
    In the same line, this application can be extended for classifying other problems,
    such as spam versus ham for messages and email, and movie or product reviews.
    Finally, in the FAQ section, we discussed how to solve the same problem with CNN,
    which can achieve similar accuracy to LSTM.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目还解决了一个二分类问题，并取得了非常高的准确性。同样，这个应用可以扩展到分类其他问题，例如垃圾邮件与非垃圾邮件分类、电影或产品评论分类。最后，在常见问题解答（FAQ）部分，我们讨论了如何使用CNN解决相同的问题，这同样可以达到与LSTM类似的准确性。
- en: Image classification using transfer learning
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用迁移学习进行图像分类
- en: In this chapter, we solved an interesting dog versus cat classification problem
    using the transfer learning technique. We used a pre-trained VGG16 model and its
    weights, and subsequently we fine-tuned the training with a real-life cat versus
    dog dataset from Kaggle.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用迁移学习技术解决了一个有趣的猫与狗分类问题。我们使用了一个预训练的VGG16模型及其权重，随后用Kaggle提供的实际猫狗数据集对训练进行了微调。
- en: Once the training was completed, we saved the trained model for model persistence
    and later reuse. We saw that the trained model could successfully detect and differentiate
    between cat and dog images with very different sizes, quality, and shapes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，我们保存了训练好的模型以实现模型持久化并进行后续重用。我们看到，训练过的模型能够成功地检测并区分猫和狗的图像，无论它们的大小、质量和形状差异多大。
- en: The trained model/classifier can be used to solve cat versus dog problems in
    real life. Finally, the lesson was that this similar technique with minimal efforts,
    can be extended and used to solve similar image classification problems; this
    applies for both binary and multiclass classification problems.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练好的模型/分类器可以用来解决现实生活中的猫与狗问题。最后，收获是，这种类似的技术只需最小的努力，就可以扩展并用于解决类似的图像分类问题；这适用于二分类和多分类问题。
- en: Real-time object detection using YOLO, JavaCV, and DL4J
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用YOLO、JavaCV和DL4J进行实时物体检测
- en: In this project, we again used the transfer learning technique to solve another
    interesting problem, which is real-time object detection from video clips. We
    used a pre-trained YOLOv2 model, JavaCV, and DL4J libraries to solve this problem.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们再次使用了迁移学习技术来解决另一个有趣的问题，即从视频片段中进行实时物体检测。我们使用了预训练的YOLOv2模型、JavaCV和DL4J库来解决这个问题。
- en: As stated in the chapter, we extended the image recognition idea to solve this
    problem. That is, our technique generates video frames as images and then recognizes
    objects from the frame using the bounding box approach. The takeaway is that although
    we used a video clip to show the evaluation, it still showed very good accuracy.
    And from the provided demo, anyone can observe that most of the objects in the
    clip were accurately identified. Thus, a similar technique, can be extended for
    real-time object detection.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章所述，我们将图像识别理念扩展以解决这个问题。也就是说，我们的技术将视频帧作为图像生成，然后使用边界框方法从帧中识别物体。要点是，尽管我们使用了一个视频片段来展示评估，但它仍然显示出非常高的准确性。从提供的演示中，任何人都可以观察到视频中的大多数物体都被准确识别。因此，类似的技术可以扩展到实时物体检测。
- en: In this regard, we saw some tips to collect real-time videos from a webcam or
    video camera (or even a mobile phone) and feed them into our YOLOv2 model using
    the JavaCV library.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，我们看到了一些收集实时视频的技巧，可以通过网络摄像头、视频摄像机（甚至是手机）收集视频，并通过JavaCV库将它们输入到我们的YOLOv2模型中。
- en: Stock price prediction using LSTM network
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LSTM网络进行股票价格预测
- en: 'In this project, we saw how to develop a demo project for predicting the stock
    prices for five categories: OPEN, CLOSE, LOW, HIGH, and VOLUME. However, this
    result also lacks the actual signal; all your network has to do is produce a value
    similar to the last input of the price.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们展示了如何开发一个预测股票价格的示范项目，预测五个类别的股票价格：开盘价（OPEN）、收盘价（CLOSE）、最低价（LOW）、最高价（HIGH）和交易量（VOLUME）。然而，这个结果也缺乏实际的信号；你的网络所做的只是生成一个类似于上一输入价格的值。
- en: If we took your prediction as the input for the next prediction, we saw that
    the results were quite bad. I know there are some serious drawbacks of this approach.
    Nevertheless, we had not used enough data, which potentially limits the performance
    of such a model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将你的预测结果作为下一个预测的输入，我们发现结果非常糟糕。我知道这种方法有一些严重的缺点。不过，我们没有使用足够的数据，这可能限制了这种模型的表现。
- en: Knowing the drawback of this project, the biggest takeaway is extending Bitcoin
    or another cryptocurrency price prediction. As suggested in the FAQ section, historical
    Bitcoin data can be downloaded from Kaggle. Then, similar feature engineering
    as we used in this project can be used to prepare the sequence dataset. Nevertheless,
    CNN-based approaches can be used too.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 了解了这个项目的缺点后，最大的收获是将比特币或其他加密货币的价格预测扩展到更广泛的范围。正如在FAQ部分所建议的，可以从Kaggle下载历史比特币数据。然后，可以使用与本项目类似的特征工程来准备序列数据集。不过，也可以使用基于CNN的方法。
- en: Distributed deep learning – video classification using a convolutional-LSTM
    network
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式深度学习——使用卷积-LSTM网络进行视频分类
- en: In this project, we developed a complete deep learning application that classifies
    a large collection of a video dataset from the UCF101 dataset. We applied a combined
    CNN-LSTM network with **deeplearning4j** (**DL4J**) that overcame the limitations
    of standalone CNN or RNN **Long Short-Term Memory** (**LSTM**) networks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们开发了一个完整的深度学习应用程序，用于分类来自UCF101数据集的大量视频数据集。我们应用了结合CNN和LSTM的网络，利用**deeplearning4j**（**DL4J**），克服了单独使用CNN或RNN
    **长短期记忆**（**LSTM**）网络的局限性。
- en: Finally, we saw how to perform training in both a parallel and distributed manner
    across multiple devices (CPUs and GPUs) on AWS EC2 AMI 9.0\. We performed parallel
    and distributed training on a `p2.8xlarge` instance with 8 GPUs, 32 computing
    cores, and 488 GB of RAM.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了如何在AWS EC2 AMI 9.0实例上跨多个设备（包括CPU和GPU）进行并行和分布式训练。我们在一个`p2.8xlarge`实例上进行并行和分布式训练，该实例配备了8个GPU、32个计算核心和488
    GB的RAM。
- en: One of the greatest takeaways from this chapter was that this end-to-end project
    can be treated as a primer for human activity recognition from video. Secondly,
    we did not achieve high accuracy because we had not trained the model with all
    the available video clips.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的一个重要收获是，这个端到端项目可以作为从视频中进行人类活动识别的入门项目。其次，我们没有取得高准确度，因为我们没有使用所有可用的视频片段来训练模型。
- en: Therefore, having the network trained with the a full video dataset and hyperparameter
    tuning definitely increases accuracy. In that case, deploying the improved model
    is commercially possible. Finally, if you want to make the training even faster,
    configuring a Hadoop cluster and distributing the training on both GPUs and Spark
    is possible.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用完整的视频数据集对网络进行训练，并进行超参数调优，肯定能够提高准确性。在这种情况下，部署改进后的模型是商业上可行的。最后，如果你想让训练更快，可以配置一个Hadoop集群，将训练分布到GPU和Spark上。
- en: Using deep reinforcement learning for GridWorld
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度强化学习进行GridWorld训练
- en: In this project, we saw how to develop a demo GridWorld game using DL4J and
    Neural QLearning, which acts as the Q function. We also provided some basic theoretical
    background for developing DQN to play a GridWorld game. However, we did not develop
    a module for visualizing the moves of the agent for the entire episodes. I confess
    that it was the biggest drawback of this project. However, I discussed some improvements
    in the FAQ section.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们展示了如何使用DL4J和神经网络Q学习（Neural QLearning）开发一个示范性的GridWorld游戏，Q函数在其中起到了重要作用。我们还提供了一些基本的理论背景，帮助开发DQN来玩GridWorld游戏。然而，我们没有开发一个模块来可视化智能体在整个过程中所做的动作。我承认，这是这个项目的最大缺点。不过，我在FAQ部分讨论了一些改进的建议。
- en: The takeaway from this project is extending this application with a visualization
    model or even developing other RL-based games, such as Doom and ALE would be a
    good idea. Secondly and finally, we can also think of developing another interesting
    RL project for online trading.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个项目中得到的启示是，将这个应用扩展为可视化模型，或者甚至开发其他基于强化学习的游戏，比如《毁灭战士》和ALE，将是一个不错的想法。其次，最后，我们也可以考虑开发另一个有趣的在线交易强化学习项目。
- en: Movie recommender system using factorization machines
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用因式分解机的电影推荐系统
- en: In this project, we saw how to develop a movie recommendation system using factorization
    machines (FMs) that are a set of algorithms that enhance the performance of linear
    models by incorporating second-order feature interactions that are absent in matrix
    factorization algorithms in a supervised way.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们展示了如何使用因式分解机（FMs）开发电影推荐系统。因式分解机是一组算法，通过引入矩阵分解算法中缺失的二阶特征交互，以监督方式增强线性模型的性能。
- en: Nevertheless, we saw some theoretical background of recommendation systems using
    matrix factorization and collaborative filtering before diving the project implementation
    using RankSys library-based FMs. This project not only covered movie-rating prediction
    by individual users but also discussed ranking predictions. Consequently, we used
    FM for predicting rankings for movies too.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在深入使用基于RankSys库的因式分解机（FMs）实现项目之前，我们了解了一些推荐系统的理论背景，包括矩阵分解和协同过滤。这个项目不仅涵盖了单个用户的电影评分预测，还讨论了排名预测。因此，我们还使用了因式分解机来预测电影的排名。
- en: However, the potential limitation is that this library is not scalable and well
    structured, I would say. Therefore, trying Python-based FM libraries would be
    a better idea. Finally, the biggest takeaway is extending this application with
    Python-based FM libraries for even larger movie datasets from MovieLens or IMDb,
    which is recommended.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个库的潜在限制是，它不具备良好的可扩展性和结构性。我的建议是尝试基于Python的因式分解机库，这样会更好。最后，最大的收获是将这个应用扩展到使用Python-based
    FM库，从MovieLens或IMDb等更大的电影数据集，这一点是推荐的。
- en: Current trends and outlook
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前趋势与展望
- en: As a researcher, I work as a **Program Committee** (**PC**) member for conferences
    such as WWW'2018, ISWC'2018, ESWC'2017/2018, and ESWC SemDeep'2018 international
    workshops. Apart from these, I am also a guest editor for International Semantic
    Web Journal, Journal of Cloud Computing, and Briefings in Bioinformatics.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名研究人员，我在多个会议中担任**程序委员会**（**PC**）成员，如WWW'2018、ISWC'2018、ESWC'2017/2018和ESWC
    SemDeep'2018国际研讨会。除此之外，我还担任《国际语义网期刊》、《云计算期刊》和《生物信息学简报》的客座编辑。
- en: While reviewing numerous papers for these conferences and journals, I found
    that researchers have not limited themselves to developing emerging use cases
    and analytical solutions using original RNN, CNN, DBN or autoencoders. They are
    coming up with ideas across new architectures by combining them for diverse domains.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在审阅了许多会议和期刊的论文后，我发现研究人员并没有局限于使用原始的RNN、CNN、DBN或自编码器来开发新兴的应用案例和分析解决方案。他们通过将这些架构组合起来，提出了跨领域的创新思路。
- en: Current trends
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前趋势
- en: 'As discussed in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning*, researchers have recently proposed so many emergent
    DL architectures. These include not only improving CNN/RNN and their variants
    but also some other special types of architecture: **Deep SpatioTemporal Neural
    Networks** (**DST-NNs**), **Multi-Dimensional Recurrent Neural Networks** (**MD-RNNs**),
    **Convolutional AutoEncoders** (**CAEs**), deep embedding clustering, and so on.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[第1章](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml)中讨论的，*深度学习入门*，研究人员最近提出了许多新兴的深度学习架构。这些架构不仅包括改进CNN/RNN及其变种，还包括一些其他特殊类型的架构：**深度时空神经网络**（**DST-NNs**）、**多维循环神经网络**（**MD-RNNs**）、**卷积自编码器**（**CAEs**）、深度嵌入聚类等。
- en: Nevertheless, there are a few more emerging networks, such as CapsNets, which
    is an improved version of a CNN designed to remove the drawbacks of regular CNNs
    as proposed by Hinton et al. Then we have residual neural networks for image recognition
    and **Generative Adversarial Networks** (**GANs**) for simple image generation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仍然有一些新兴的网络，如CapsNets，这是Hinton等人提出的CNN改进版，旨在消除常规CNN的缺点。接下来是用于图像识别的残差神经网络和用于简单图像生成的**生成对抗网络**（**GANs**）。
- en: Apart from these trends and use cases, different deep and emerging architectures
    are being used in multimedia analytics; computer vision (especially semantic image
    segmentation); anomaly detection from IoT, image, and network traffic; neural
    machine translation for NLP; and integration of knowledge graphs with neural networks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些趋势和应用场景，深度学习的不同新兴架构正在被应用于多媒体分析、计算机视觉（特别是语义图像分割）、物联网、图像和网络流量中的异常检测、自然语言处理中的神经机器翻译以及知识图谱与神经网络的集成。
- en: Outlook on emergent DL architectures
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新兴深度学习架构的前景
- en: In this subsection, we'll discuss some emergent architectures and their variants,
    focusing on some use cases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将讨论一些新兴架构及其变体，重点介绍一些应用场景。
- en: Residual neural networks
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 残差神经网络
- en: 'Because of the millions of billions of hyperparameters and other practical
    aspects associated with them, it is difficult to train deep neural networks. To
    overcome this limitation, Kaiming He et al. (see [https://arxiv.org/abs/1512.03385v1](https://arxiv.org/abs/1512.03385v1))
    proposed a **residual learning framework** (**RNN**) to ease the training of networks
    that are substantially deeper than those used previously. Now, according to the
    original paper:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于与它们相关的数百万亿的超参数以及其他实际问题，训练深度神经网络变得非常困难。为了解决这个问题，何凯明等人（详见 [https://arxiv.org/abs/1512.03385v1](https://arxiv.org/abs/1512.03385v1)）提出了**残差学习框架**（**RNN**），以简化比以往更深层的网络的训练。现在，根据原始论文：
- en: '"In this network setting, instead of hoping each stack of layers directly fits
    a desired underlying mapping, we explicitly let these layers fit a residual mapping.
    The original mapping is recast into F(x)+x. We hypothesize that it is easier to
    optimize the residual mapping than to optimize the original, unreferenced mapping.
    To the extreme, if an identity mapping were optimal, it would be easier to push
    the residual to zero than to fit an identity mapping by a stack of nonlinear layers."'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: “在这个网络设置中，我们不是期望每一层堆叠直接拟合一个期望的底层映射，而是明确地让这些层拟合一个残差映射。原始映射被重新表述为F(x)+x。我们假设，优化残差映射比优化原始的、未引用的映射更容易。极端情况下，如果恒等映射是最优的，那么将残差推向零比通过堆叠非线性层拟合恒等映射要容易得多。”
- en: This way, RNNs are easier to optimize and can gain accuracy from considerably
    increased depth compared to other DNN architectures. The downside is that building
    a network by simply stacking residual blocks inevitably limits its optimization
    ability. To overcome this limitation, Ke Zhang et al. also proposed using a multilevel
    residual networks (see at [https://arxiv.org/abs/1608.02908](https://arxiv.org/abs/1608.02908)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，RNN比其他深度神经网络架构更容易优化，并且可以从显著增加的深度中获得更高的准确性。缺点是，通过简单地堆叠残差块来构建网络，难免会限制其优化能力。为了解决这个问题，张科等人还提出了使用多层残差网络（详见
    [https://arxiv.org/abs/1608.02908](https://arxiv.org/abs/1608.02908)）。
- en: 'Consequently, residual networks are in use to solve many emerging use cases,
    including:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，残差网络被应用于解决许多新兴的应用场景，包括：
- en: '*Skeleton-Based Action Recognition with Spatial Reasoning and Temporal Stack
    Learning* (see more at [https://arxiv.org/pdf/1805.02335](https://arxiv.org/pdf/1805.02335)).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于骨架的动作识别，结合空间推理和时间堆栈学习*（更多信息见 [https://arxiv.org/pdf/1805.02335](https://arxiv.org/pdf/1805.02335)）。'
- en: Recently, Yuan et al. proposed *Hyperspectral Image Denoising Employing a Spatial-Spectral
    Deep Residual Convolutional Neural Network* (see [https://arxiv.org/pdf/1806.00183](https://arxiv.org/pdf/1806.00183)).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近，袁等人提出了*基于空间-光谱深度残差卷积神经网络的高光谱图像去噪*（详见 [https://arxiv.org/pdf/1806.00183](https://arxiv.org/pdf/1806.00183)）。
- en: '*A Dynamic Model for Traffic Flow Prediction Using Improved DRN* (see more
    at [https://arxiv.org/pdf/1805.00868](https://arxiv.org/pdf/1805.00868))'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用改进的DRN进行交通流量预测的动态模型*（更多信息见 [https://arxiv.org/pdf/1805.00868](https://arxiv.org/pdf/1805.00868)）'
- en: '*Classification of simulated radio signals using Wide Residual Networks for
    use in the search for extra-terrestrial intelligence* (see more at [https://arxiv.org/pdf/1803.08624](https://arxiv.org/pdf/1803.08624))'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用宽残差网络分类模拟的无线电信号，以用于寻找外星智能*（更多信息见 [https://arxiv.org/pdf/1803.08624](https://arxiv.org/pdf/1803.08624)）'
- en: GANs
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）
- en: GANs are deep neural net architectures that consist of two networks pitted against
    each other (hence the name adversarial). Ian Goodfellow et al. introduced GANs
    in a paper (see more at [https://arxiv.org/abs/1406.2661v1](https://arxiv.org/abs/1406.2661v1)).
    GAN is one of the best research outcomes in AI that can learn to mimic any distribution
    of data. This is such that a trained GAN can be deployed to create worlds similar
    to our own, especially for images, music, speech, or prose.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是由两网络相互对抗组成的深度神经网络架构（因此得名“对抗”）。Ian Goodfellow等人首次在论文中介绍了GAN（详细内容请见[https://arxiv.org/abs/1406.2661v1](https://arxiv.org/abs/1406.2661v1)）。GAN是AI领域最好的研究成果之一，它可以学习模仿任何数据分布。训练好的GAN可以用于创建与我们世界相似的虚拟世界，特别是图像、音乐、语音或散文等方面。
- en: 'Although the original GAN paper targeted simple image generation such as DCGAN,
    BEGAN, and so on, people are extending the idea for font generation, anime character
    generation, interactive image generation, text-to-image generation, 2D object
    generation, human pose estimation, and so on. A few concrete research-oriented
    use cases as outlined as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原始的GAN论文主要针对简单的图像生成（如DCGAN、BEGAN等），但人们正在将这一理念扩展到字体生成、动漫角色生成、互动图像生成、文本到图像生成、2D物体生成、人体姿态估计等领域。以下是一些具体的研究导向应用案例：
- en: For generating an image sequence from the description with LSTM (see more at
    [https://arxiv.org/pdf/1806.03027](https://arxiv.org/pdf/1806.03027))
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用LSTM从描述中生成图像序列（详细内容请见[https://arxiv.org/pdf/1806.03027](https://arxiv.org/pdf/1806.03027)） '
- en: Generative adversarial networks for **electroencephalographic** (**EEG**) brain
    signals (see more at [https://arxiv.org/pdf/1806.01875](https://arxiv.org/pdf/1806.01875))
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于**脑电图**（**EEG**）脑信号的生成对抗网络（详细内容请见[https://arxiv.org/pdf/1806.01875](https://arxiv.org/pdf/1806.01875)）
- en: For natural language generation for electronic health records (see more at [https://arxiv.org/pdf/1806.01353](https://arxiv.org/pdf/1806.01353))
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于电子健康记录的自然语言生成（详细内容请见[https://arxiv.org/pdf/1806.01353](https://arxiv.org/pdf/1806.01353)）
- en: For chest X-ray segmentation (see more at [https://arxiv.org/pdf/1806.00600](https://arxiv.org/pdf/1806.00600))
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于胸部X光分割（详细内容请见[https://arxiv.org/pdf/1806.00600](https://arxiv.org/pdf/1806.00600)）
- en: Capsule networks (CapsNet)
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 胶囊网络（CapsNet）
- en: As discussed in [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting
    Started with Deep Learning*, CNNs perform well at classifying good quality images.
    However, if the images have rotation, tilt, or any other different orientation,
    CNNs give very poor performance. Even the pooling operation in CNNs cannot help
    much with positional invariance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第一章](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml)所述，*深入学习入门*，CNN在分类优质图像方面表现良好。然而，如果图像有旋转、倾斜或其他不同的方向，CNN的表现会非常差。即使是CNN中的池化操作，在位置不变性方面也帮助有限。
- en: To overcome the this limitation of CNN, Geoffrey Hinton et al. come up with
    a ground breaking idea called **CapsuleNetworks (CapsNet)** that are particularly
    good at handling different types of visual stimulus and encoding things such as
    pose (position, size, and orientation), deformation, velocity, albedo, hue, texture.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服CNN的局限性，Geoffrey Hinton等人提出了一种突破性思路，称为**胶囊网络（CapsNet）**，它特别擅长处理不同类型的视觉刺激，并能编码诸如姿势（位置、大小和方向）、形变、速度、反射率、色调、纹理等信息。
- en: In a regular DNN, we keep on adding layers (more layers means a deeper network).
    In CapsNet, the idea is to add more layers inside a single layer. This way, a
    CapsNet is a nested set of neural layers. In CapsNet, the limitation of max-pooling
    layer is overcome and replaced with **routing by agreement (RBA)** to capture
    low-level visual information.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规的DNN中，我们不断增加层数（更多的层意味着更深的网络）。而在CapsNet中，思路是将更多的层添加到单一层内。通过这种方式，CapsNet是一个嵌套的神经网络层集合。在CapsNet中，最大池化层的局限性被克服，并用**基于协议的路由（RBA）**替代，以捕获低层次的视觉信息。
- en: 'Unfortunately, the original paper is too theoretical. Therefore, researchers
    are trying to extend the idea of CapsNet for different AI and data science projects
    including image classification, GAN improvement and at improving RL-based gaming
    experience. A few example use cases are listed as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，原始论文过于理论化。因此，研究人员正试图将CapsNet的理念扩展到不同的AI和数据科学项目中，包括图像分类、GAN改进以及改善基于强化学习的游戏体验。以下是一些示例应用案例：
- en: '*Object Localization and Motion Transfer learning with Capsules* (see [https://arxiv.org/pdf/1805.07706](https://arxiv.org/pdf/1805.07706))'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用胶囊进行目标定位和运动迁移学习*（详细内容请见[https://arxiv.org/pdf/1805.07706](https://arxiv.org/pdf/1805.07706)）'
- en: '*An attention-based Bi-GRU-CapsNet model for hypernymy detection between compound
    entities* (see more at [https://arxiv.org/pdf/1805.04827](https://arxiv.org/pdf/1805.04827))'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一种基于注意力的Bi-GRU-CapsNet模型用于复合实体之间的上位词检测*（详情见[https://arxiv.org/pdf/1805.04827](https://arxiv.org/pdf/1805.04827)）'
- en: '*Brain Tumor Type Classification via Capsule Networks* (see more at [https://arxiv.org/pdf/1802.10200](https://arxiv.org/pdf/1802.10200))'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过胶囊网络进行脑肿瘤类型分类*（详情见[https://arxiv.org/pdf/1802.10200](https://arxiv.org/pdf/1802.10200)）'
- en: '*CapsuleGAN: Generative Adversarial Capsule Network* (see more at [https://arxiv.org/pdf/1802.06167](https://arxiv.org/pdf/1802.06167))'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CapsuleGAN: 生成对抗胶囊网络*（详情见[https://arxiv.org/pdf/1802.06167](https://arxiv.org/pdf/1802.06167)）'
- en: '*Deep Reinforcement Learning using Capsules in Advanced Game Environments*
    (see more at [https://arxiv.org/pdf/1801.09597](https://arxiv.org/pdf/1801.09597))'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用胶囊网络的深度强化学习在高级游戏环境中的应用*（详情见[https://arxiv.org/pdf/1801.09597](https://arxiv.org/pdf/1801.09597)）'
- en: Apart from these emerging architectures, people are trying to use GAN architectures
    for image synthesis using CapsNet (see [https://arxiv.org/pdf/1806.03796](https://arxiv.org/pdf/1806.03796)).
    Researchers have also used adversarial autoencoders for speech-based emotion recognition
    (see [https://arxiv.org/pdf/1806.02146](https://arxiv.org/pdf/1806.02146)). Finally,
    I would suggest readers to know the recent trends in artificial intelligence,
    machine learning, and deep learning from [https://arxiv.org/list/cs.AI/recent](https://arxiv.org/list/cs.AI/recent).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些新兴的架构外，研究人员还尝试使用GAN架构通过CapsNet进行图像合成（见[https://arxiv.org/pdf/1806.03796](https://arxiv.org/pdf/1806.03796)）。此外，研究人员还使用了对抗性自编码器进行基于语音的情感识别（见[https://arxiv.org/pdf/1806.02146](https://arxiv.org/pdf/1806.02146)）。最后，我建议读者通过[https://arxiv.org/list/cs.AI/recent](https://arxiv.org/list/cs.AI/recent)了解人工智能、机器学习和深度学习的最新趋势。
- en: Semantic image segmentation
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语义图像分割
- en: Image segmentation is the way to partition an image into several coherent parts,
    but *without* any attempt at understanding what these parts represent. Semantic
    segmentation, on the other hand, attempts to partition the image into semantically
    meaningful parts and to classify each part into one of the predetermined classes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分割是将图像划分为若干个连贯部分的方法，但*并不*尝试理解这些部分代表什么。语义分割则试图将图像划分为语义上有意义的部分，并将每个部分分类到预定的类别中。
- en: Such semantic segmentation of raw brain images into gray matter, white matter,
    and cerebrospinal fluid helps classify them based on the segmented areas. Deep-learning-based
    techniques are being in use and very successful such as **Stacked Denoising Autoencoders**
    (**SDAE**).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这种将原始脑部图像分割成灰质、白质和脑脊液的语义分割有助于根据分割区域对其进行分类。基于深度学习的技术，如**堆叠去噪自编码器**（**SDAE**），已被成功应用。
- en: Nevertheless, the recurrent-based fully convolutional network is being in use
    for semantic segmentation of high-resolution remote sensing images (see more at
    [https://arxiv.org/pdf/1805.02091](https://arxiv.org/pdf/1805.02091)). This types
    of image segmentation are being in use in emerging use cases such as Pelvic MRImage
    analysis, object detection for self-driving cars, geospatial image classification
    (see [http://www.semantic-web-journal.net/system/files/swj1862.pdf](http://www.semantic-web-journal.net/system/files/swj1862.pdf)),
    and many more.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，基于循环的全卷积网络正在被用于高分辨率遥感图像的语义分割（详情见[https://arxiv.org/pdf/1805.02091](https://arxiv.org/pdf/1805.02091)）。这类图像分割技术已被应用于新兴领域，如盆腔磁共振成像分析、自动驾驶汽车的物体检测、地理空间图像分类（见[http://www.semantic-web-journal.net/system/files/swj1862.pdf](http://www.semantic-web-journal.net/system/files/swj1862.pdf)）等。
- en: Deep learning for clustering analysis
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在聚类分析中的应用
- en: Clustering analysis is one of the most widely used data-driven task. To date,
    existing clustering analysis techniques use classical clustering algorithms such
    as k-means, bisecting k-means, or the Gaussian mixture model. In particular, the
    k-means clustering algorithm and its several variants have been proposed to address
    issues with higher-dimensional input spaces.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析是最广泛使用的数据驱动任务之一。迄今为止，现有的聚类分析技术采用了经典的聚类算法，如k-means、二分k-means或高斯混合模型。特别是，k-means聚类算法及其多个变体已被提出，以解决高维输入空间中的问题。
- en: However, they are fundamentally limited to linear embedding. Hence, they cannot
    model nonlinear relationships. Nevertheless, fine-tuning in these approaches is
    based on only cluster assignment hardening loss. Therefore, a fine-grained clustering
    accuracy cannot be achieved.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们本质上限于线性嵌入。因此，它们无法建模非线性关系。然而，这些方法中的微调仅基于聚类分配硬化损失。因此，无法实现细粒度的聚类准确性。
- en: In short, relatively less research has focused on deep-learning-based representation
    learning and clustering analysis. However, the quality of k-means is dependent
    on the data distribution. Deep architecture can help the model learn a mapping
    from the data space to a lower-dimensional feature space in which it iteratively
    optimizes a clustering objective.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，针对基于深度学习的表示学习和聚类分析的研究相对较少。然而，k-means的质量依赖于数据分布。深度架构可以帮助模型从数据空间学习到映射到低维特征空间，在该空间中，它反复优化聚类目标。
- en: 'Considering these limitations and motivations, researchers have come up with
    deep-learning-based clustering techniques for clustering very-high-dimensional
    data and nonlinear objects. In these approaches, k-means is incorporated with
    deep architectures, where both the clustering-assignment-hardening loss (from
    k-means) and reconstruction loss (from DNN) are optimized simultaneously. These
    approaches include:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些限制和动机，研究人员提出了基于深度学习的聚类技术，用于聚类非常高维的数据和非线性对象。在这些方法中，k-means与深度架构相结合，其中同时优化聚类分配硬化损失（来自k-means）和重构损失（来自DNN）。这些方法包括：
- en: '*Unsupervised Deep Embedding for Clustering Analysis* by Xie et al. ( see [https://arxiv.org/pdf/1511.06335.pdf](https://arxiv.org/pdf/1511.06335.pdf))'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无监督深度嵌入聚类分析*，由Xie等人撰写（参见[https://arxiv.org/pdf/1511.06335.pdf](https://arxiv.org/pdf/1511.06335.pdf)）'
- en: '*Neural Networks-based Clustering using Pairwise Constraints* by Hsu et al.
    (see more at [https://arxiv.org/abs/1511.06321](https://arxiv.org/abs/1511.06321))'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于神经网络的聚类，使用成对约束*，由Hsu等人撰写（参见更多内容：[https://arxiv.org/abs/1511.06321](https://arxiv.org/abs/1511.06321)）'
- en: '*Discriminatively Boosted Clustering (DBC)* by Liu et al. (see more at [http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf](http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf))'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*判别性增强聚类（DBC）*，由Liu等人撰写（参见更多内容：[http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf](http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf)）'
- en: '*Clustering with Deep Learning: Taxonomy and New Methods* by Elie et al. (see
    more at [https://arxiv.org/abs/1801.07648](https://arxiv.org/abs/1801.07648))'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习聚类：分类与新方法*，由Elie等人撰写（参见更多内容：[https://arxiv.org/abs/1801.07648](https://arxiv.org/abs/1801.07648)）'
- en: '*Recurrent Deep Embedding Networks for Genotype Clustering and Ethnicity Prediction*
    by Karim et al. (see more at [https://arxiv.org/pdf/1805.12218.pdf](https://arxiv.org/pdf/1805.12218.pdf))'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于基因型聚类和种族预测的递归深度嵌入网络*，由Karim等人撰写（参见更多内容：[https://arxiv.org/pdf/1805.12218.pdf](https://arxiv.org/pdf/1805.12218.pdf)）'
- en: Frequently asked questions (FAQs)
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见问题（FAQ）
- en: 'We have analyzed the completed projects and looked at recent trends. Based
    on these, there might be several questions in your mind. In this section, I will
    try to devise some such questions and provide sample answers:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经分析了完成的项目并观察了近期趋势。基于这些，可能会有一些问题出现在你脑海中。在这一节中，我将尝试设计一些这样的问答，并提供示例答案：
- en: In this chapter, we argued that using GAN, we could solve many research problems.
    Is there any GAN implementation in DL4J?
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们认为，利用GAN，我们可以解决许多研究问题。在DL4J中有GAN的实现吗？
- en: In this chapter, we argued that using CapsNet is a better idea for handling
    images having different shapes and orientation. Is there any implementation for
    CapsNet in DL4J?
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们认为，使用CapsNet处理具有不同形状和方向的图像是一个更好的选择。在DL4J中有CapsNet的实现吗？
- en: In [Chapter 1](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml), *Getting Started
    with Deep Learning*, we discussed DBNs and restricted Boltzmann machines as their
    basic building blocks. However, we have not used DBNs in any of the completed
    projects. What is the reason for this?
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[第1章](fba163f0-88c0-4278-a4a1-df5389cc3a10.xhtml)，*深度学习入门*中，我们讨论了DBN和限制玻尔兹曼机作为其基本构建块。然而，在任何已完成的项目中，我们都没有使用DBN。这是什么原因呢？
- en: In this chapter, we argued that using unsupervised anomaly detection from IoT
    sensor data or images is an emerging research use case. Are there any examples
    of this in DL4J?
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们认为，利用来自物联网传感器数据或图像的无监督异常检测是一个新兴的研究应用场景。在DL4J中有这方面的例子吗？
- en: Are there any examples of developing recommendation engines with DL4J?
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在DL4J中，有没有开发推荐引擎的例子？
- en: Considering the fact that smartphones nowadays are very powerful, can we develop
    image/object detection applications on a smartphone?
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到如今智能手机非常强大，我们可以在智能手机上开发图像/物体检测应用吗？
- en: How could I wrap-up a deep learning application as a web app?
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将深度学习应用打包成一个网页应用？
- en: I am having issues while running the projects. In addition, I am experiencing
    issues while configuring the development environment (for example, on Eclipse/IntelliJ
    IDEA and configuring CUDA/CuDNN). What can I do?
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行项目时遇到了一些问题。此外，我在配置开发环境时也遇到困难（例如，在 Eclipse/IntelliJ IDEA 上配置 CUDA/CuDNN）。我该怎么办？
- en: Answers to questions
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题答案
- en: '**Answer** **to question 1**: There is an inactive issue on this. Interested
    readers can look at [https://github.com/deeplearning4j/deeplearning4j/issues/1737](https://github.com/deeplearning4j/deeplearning4j/issues/1737)
    to know the current update. However, the discussion loop is not very active.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 1 的答案**：这方面存在一个未解决的问题。感兴趣的读者可以查看[https://github.com/deeplearning4j/deeplearning4j/issues/1737](https://github.com/deeplearning4j/deeplearning4j/issues/1737)来了解当前的更新情况。然而，讨论的热度不是很高。'
- en: '**Answer** **to question 2**: As far as I know, there is no CapsNet implementation
    in DL4J. Also, I didn''t see any open discussion/issues on this topic. I asked
    in the DL4j Gitter channel but nobody replied.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 2 的答案**：据我所知，DL4J 中没有 CapsNet 的实现。而且，我没有看到这个话题有任何公开的讨论或问题。我在 DL4J Gitter
    频道提问了，但没有人回复。'
- en: '**Answer to question 3**: Both unsupervised pre-training and supervised fine-tuning
    can be performed using DBN. That means this probabilistic network is an intelligent
    choice if we do not have enough labeled data but still want to perform NN-based
    training.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 3 的答案**：无监督预训练和有监督微调都可以使用 DBN 来进行。这意味着，如果我们没有足够的标记数据，但仍然希望进行基于神经网络的训练，这种概率网络是一个明智的选择。'
- en: '**Answer** **to question 4**: Yes, there is an example of anomaly detection
    using a variational autoencoder with reconstruction probability for MNIST data.
    Take a look at DL4J examples at [https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection](https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection).
    However, this example can be extended for other datasets too.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 4 的答案**：是的，使用变分自编码器和重建概率进行异常检测的示例已经有了，适用于 MNIST 数据。可以查看 DL4J 示例：[https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection](https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection)。不过，这个示例也可以扩展到其他数据集。'
- en: '**Answer to question 5**: There is an example for well-dressed recommendation
    engine in this link [https://deeplearning4j.org/welldressed-recommendation-engine](https://deeplearning4j.org/welldressed-recommendation-engine).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 5 的答案**：这个链接中有一个推荐引擎的实例，适用于Well-Dressed推荐：[https://deeplearning4j.org/welldressed-recommendation-engine](https://deeplearning4j.org/welldressed-recommendation-engine)。'
- en: '**Answer to question 6**: Deep learning and neural networks can be deployed
    in Android devices too. For more information, refer to [https://deeplearning4j.org/android](https://deeplearning4j.org/android).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 6 的答案**：深度学习和神经网络也可以部署在 Android 设备上。更多信息，请参考[https://deeplearning4j.org/android](https://deeplearning4j.org/android)。'
- en: '**Answer to question 7**: Once the NN is trained, the network can be used for
    inference, or making predictions about the data it sees. Inference happens to
    be a much less compute-intensive process. Then, Spring Boot or another framework
    can be used to wrap up the application as a web app. See some guidelines at [https://deeplearning4j.org/build_vgg_webapp](https://deeplearning4j.org/build_vgg_webapp).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 7 的答案**：一旦神经网络训练完成，网络就可以用于推理，或者说是对它看到的数据进行预测。推理过程通常计算量较小。然后，可以使用 Spring
    Boot 或其他框架将应用打包成一个网页应用。可以参考一些指南：[https://deeplearning4j.org/build_vgg_webapp](https://deeplearning4j.org/build_vgg_webapp)。'
- en: '**Answer to question 8**: You should follow the instructions I provided in
    the chapters. In addition, the code of this book is available on GitHub, so feel
    free to PR or create new issues and I will try to fix them as soon as possible.
    About any new issues, you can ask through the DL4J Gitter live channel at [https://gitter.im/deeplearning4j/deeplearning4j](https://gitter.im/deeplearning4j/deeplearning4j).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 8 的答案**：你应该按照我在章节中提供的指示操作。此外，本书的代码可以在 GitHub 上找到，你可以自由提交 PR 或创建新的问题，我会尽快修复它们。关于任何新的问题，你可以通过
    DL4J Gitter 实时频道提出：[https://gitter.im/deeplearning4j/deeplearning4j](https://gitter.im/deeplearning4j/deeplearning4j)。'
