- en: Deep Belief Networking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度置信网络
- en: A **deep belief network** (**DBN**) is a class of deep neural network, composed
    of multiple layers of hidden units, with connections between the layers; where
    a DBN differs is these hidden units don't interact with other units within each
    layer. A DBN can learn to probabilistically reconstruct its input without supervision,
    when trained, using a set of training datasets. It is a joint (multivariate) distributions
    over large numbers of random variables that interact with each other. These representations
    sit at the intersection of statistics and computer science, relying on concepts
    from probability theory, graph algorithms, machine learning, and more.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度置信网络**（**DBN**）是一种深度神经网络，由多层隐藏单元组成，各层之间存在连接；DBN 的不同之处在于这些隐藏单元在每层内不会与其他单元交互。DBN
    可以在没有监督的情况下，使用训练数据集进行训练，学习概率性地重建其输入。它是对大量相互作用的随机变量的联合（多变量）分布。这些表示位于统计学和计算机科学的交集处，依赖于概率论、图算法、机器学习等概念。'
- en: The layers act as feature detectors. After the training step, a DBN can be trained
    with supervision to perform classification.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 各层充当特征检测器。训练步骤完成后，DBN 可以通过监督训练来进行分类。
- en: 'We will be covering the following chapters in the chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这一章节中涵盖以下内容：
- en: Understanding deep belief networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度置信网络
- en: Model training
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练
- en: Predicting the label
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测标签
- en: Finding the accuracy of the model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找模型的准确率
- en: DBN implementation for the MNIST dataset
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MNIST 数据集的 DBN 实现
- en: Effect of the number of neurons in an RBM Layer in a DBN
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RBM 层中神经元数量对 DBN 的影响
- en: DBNs with two RBM layers
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有两个 RBM 层的 DBN
- en: Classifying the NotMNIST dataset with a DBN
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 DBN 对 NotMNIST 数据集进行分类
- en: Understanding deep belief networks
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度置信网络
- en: DBNs can be considered a composition of simple, unsupervised networks such as
    **Restricted Boltzmann machines** (**RBMs**) or autoencoders; in these, each subnetwork's
    hidden layer serves as the visible layer for the next. An RBM is an undirected,
    generative model with an input layer (which is visible) and a hidden layer, with connections
    between the layers but not within layers. This topology leads to a fast, layer-by-layer,
    unsupervised training procedure. Contrastive divergence is applied to each subnetwork,
    starting from the lowest pair of layers (the lowest visible layer is a training
    set).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: DBN 可以看作是简单无监督网络的组合，如 **限制玻尔兹曼机**（**RBM**）或自编码器；在这些网络中，每个子网络的隐藏层作为下一个子网络的可见层。RBM
    是一种无向生成模型，具有一个输入层（可见）和一个隐藏层，层之间存在连接，但层内没有连接。这种拓扑结构使得逐层的无监督训练过程变得快速。对每个子网络应用对比散度，从最低层对开始（最低可见层为训练集）。
- en: DBNs are trained (greedily), one layer at a time, which makes it one of the
    first effective deep learning algorithms. There are many implementations and uses
    of DBNs in real-life applications and scenarios; we will be looking at using a
    DBN to classify MNIST and NotMNIST datasets.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: DBN 是逐层训练（贪婪式）进行的，这使其成为最早有效的深度学习算法之一。DBN 在现实应用和场景中有许多实现和用途；我们将研究如何使用 DBN 对 MNIST
    和 NotMNIST 数据集进行分类。
- en: DBN implementation
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DBN 实现
- en: 'This class instantiates the Restricted Boltzmann machines (RBN) layers and
    the cost functions. The **DeepBeliefNetwork** class is itself a subclass of the **Model**:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该类实例化了限制玻尔兹曼机（RBN）层和成本函数。**DeepBeliefNetwork** 类本身是 **Model** 类的子类：
- en: '![](img/70002aa2-1334-419c-818a-23a3a0021660.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70002aa2-1334-419c-818a-23a3a0021660.png)'
- en: Class initialization
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类初始化
- en: 'In DBN initialization, the `Model` class''s initialization method `__init__(self,
    name)` is called. The `Model` class references the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DBN 初始化时，调用 `Model` 类的初始化方法 `__init__(self, name)`。`Model` 类引用了以下内容：
- en: '**Input data**: `self.input_data`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入数据**: `self.input_data`'
- en: '**Input labels**: `self.input_labels`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入标签**: `self.input_labels`'
- en: '**Cost**: `` `self.cost` ``'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**: `` `self.cost` ``'
- en: '**Number of nodes in final layer**: `self.layer_nodes`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终层中的节点数量**: `self.layer_nodes`'
- en: '**TensorFlow session**: `self.tf_session`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow 会话**: `self.tf_session`'
- en: '**TensorFlow graph**: `self.tf_graph= tf.graph`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow 图**: `self.tf_graph = tf.graph`'
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Other variables that are defined are the loss functions, which should be one
    of the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 定义的其他变量是损失函数，应为以下之一：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Code Listing for **DeepBeliefNetwork** class is given below. The `__init__()`
    function is shown in the following code. Here all the variables, such as array
    of parameters for each RBM layer are specified. We are also making a call to the `__init__()`
    function of `SupervisedModel`, which is the super class for the `DeepBeliefNetwork`
    class.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**DeepBeliefNetwork** 类的代码列表如下所示。`__init__()`函数在下面的代码中显示。在这里，所有变量（例如每个RBM层的参数数组）都已指定。我们还调用了`SupervisedModel`的`__init__()`函数，`SupervisedModel`是`DeepBeliefNetwork`类的父类。'
- en: 'Two important parameters to initialize are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化时有两个重要的参数：
- en: '`self.rbms = []`: Array of `RBM` class instances'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`self.rbms = []`：`RBM`类实例的数组'
- en: '`self.rbm_graphs = []`: An array `tf.Graph` for each of those RBMs'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`self.rbm_graphs = []`：每个RBM的`tf.Graph`数组'
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Notice how RBM layers are constructed from the `rbm_layers` array:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，RBM层是如何从`rbm_layers`数组中构建的：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: RBM class
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBM类
- en: 'For each RBM layer, an **RBM** class is initialized. This class extends the
    **UnsupervisedModel** and **Model** classes:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个RBM层，都会初始化一个**RBM**类。这个类扩展了**UnsupervisedModel**和**Model**类：
- en: '![](img/c37de519-b528-4c0c-a841-a2b242ad02ec.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c37de519-b528-4c0c-a841-a2b242ad02ec.png)'
- en: 'Details of the **RBM** class `__init__(..)` function are specified in the following
    code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**RBM**类的`__init__(..)`函数的详细信息在以下代码中指定：'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the `rbm` graphs are initialized they are appended to the the TensorFlow
    graph:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`rbm`图初始化完成，它们会被附加到TensorFlow图中：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Pretraining the DBN
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练DBN
- en: 'In this section, we look at how a DBN is pretrained:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将查看如何预训练DBN：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This in turn calls `SupervisedModel.pretrain_procedure(..)`, which takes the
    following parameters:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这将进一步调用`SupervisedModel.pretrain_procedure(..)`，该函数接受以下参数：
- en: '`layer_objs`: A list of model objects (autoencoders or RBMs)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_objs`：模型对象的列表（自编码器或RBM）'
- en: '`layer_graphs`: A list of model `tf.Graph` objects'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_graphs`：模型`tf.Graph`对象的列表'
- en: '`set_params_func`: The function used to set the parameters after pretraining'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`set_params_func`：预训练后用于设置参数的函数'
- en: '`train_set`: The training set'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_set`：训练集'
- en: '`validation_set`: The validation set'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validation_set`：验证集'
- en: 'This function returns data encoded by the last layer:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回由最后一层编码的数据：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This in turn calls `self._pretrain_layer_and_gen_feed(...)`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这将进一步调用`self._pretrain_layer_and_gen_feed(...)`：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Inside the preceding function, each `layer_obj` is called **iteratively**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的函数中，每个`layer_obj`都会**迭代**调用。
- en: Model training
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'Model training is implemented in the `fit(..)` method. It takes the following
    parameters:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练在`fit(..)`方法中实现。它接受以下参数：
- en: '`train_X`: `array_like, shape (n_samples, n_features)`, Training data'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_X`：`array_like, shape (n_samples, n_features)`，训练数据'
- en: '`train_Y`: `array_like, shape (n_samples, n_classes)`, Training labels'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_Y`：`array_like, shape (n_samples, n_classes)`，训练标签'
- en: '`val_X`: `array_like, shape (N, n_features) optional, (default = None)`, Validation
    data'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`val_X`：`array_like, shape (N, n_features) optional, (default = None)`，验证数据'
- en: '`val_Y`: `array_like, shape (N, n_classes) optional, (default = None)`, Validation
    labels'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`val_Y`：`array_like, shape (N, n_classes) optional, (default = None)`，验证标签'
- en: '`graph`: `tf.Graph, optional (default = None)`, TensorFlow Graph object'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`graph`：`tf.Graph`，可选（默认为None），TensorFlow图对象'
- en: Next, we look at the implementation of `fit(...)` function where the model is
    trained and saved in the model path specified by `model_path`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看`fit(...)`函数的实现，其中模型会在由`model_path`指定的路径中训练并保存。
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Predicting the label
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测标签
- en: 'Prediction of the label can be made by calling the following method:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 预测标签可以通过调用以下方法来完成：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Finding the accuracy of the model
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找模型的准确度
- en: 'Accuracy of the model is found by computing mean accuracy over the test set.
    It is implemented in the following method:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的准确度是通过计算测试集的平均准确度来得到的。它在以下方法中实现：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here, the parameters are as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，参数如下：
- en: '`test_X`: `array_like, shape (n_samples, n_features)`, Test data'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_X`：`array_like, shape (n_samples, n_features)`，测试数据'
- en: '`test_Y`: `array_like, shape (n_samples, n_features)`, Test labels'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_Y`：`array_like, shape (n_samples, n_features)`，测试标签'
- en: '`return float`: mean accuracy over the test set'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return float`：测试集的平均准确度'
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the next section, we will look at how DBN implementation can be used on the
    MNIST dataset.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看看如何在MNIST数据集上使用DBN实现。
- en: DBN implementation for the MNIST dataset
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MNIST数据集的DBN实现
- en: Let's look at how the DBN class implemented earlier is used for the MNIST dataset.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下之前实现的DBN类如何用于MNIST数据集。
- en: Loading the dataset
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据集
- en: 'First, we load the dataset from `idx3` and `idx1` formats into test, train,
    and validation sets. We need to import TensorFlow common utilities that are defined
    in the common module explained here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将数据集从`idx3`和`idx1`格式加载到测试集、训练集和验证集中。我们需要导入在这里说明的common模块中定义的TensorFlow常用工具：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can find details about `load_mnist_dataset()` in the following code listing.
    As `mode=''supervised''` is set, the train, test, and validation labels are returned:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下代码清单中找到有关`load_mnist_dataset()`的详细信息。由于设置了`mode='supervised'`，因此会返回训练集、测试集和验证集的标签：
- en: '[PRE15]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Input parameters for a DBN with 256-Neuron RBM layers
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有256神经元RBM层的DBN输入参数
- en: 'We will initialize various parameters that are needed by the DBN class defined
    earlier:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将初始化DBN类所需的各种参数：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once the parameters are defined, let''s run the DBN network on the MNIST dataset:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了参数，让我们在MNIST数据集上运行DBN网络：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Output for a DBN with 256-neuron RBN layers
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有256神经元RBM层的DBN输出
- en: 'The output of the preceding listing shows the test set''s accuracy:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的清单输出显示了测试集的准确度：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Overall accuracy and Test set accuracy is quite low. With the increase in number
    of iterations it improves. Let us run same sample with 20 epochs
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 总体准确度和测试集准确度都相对较低。随着迭代次数的增加，它们有所提升。让我们使用20个epoch重新运行相同的示例
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As can be seen the reconstruction loss has come down and the Test set accuracy
    has improved by 20% to  0.10339999944
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，重构损失下降了，测试集的准确度提高了20%，达到了0.10339999944
- en: Let us increase the number of Epochs to 40\. Output is shown below
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将Epoch数量增加到40。输出如下所示：
- en: '[PRE20]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Effect of the number of neurons in an RBM layer in a DBN
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBM层中神经元数量对DBN的影响
- en: 'Let''s look at how changing the number of neurons in an RBM layer affects the
    test set''s accuracy:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看更改RBM层中神经元数量如何影响测试集的准确度：
- en: An RBM layer with 512 neurons
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个包含512个神经元的RBM层
- en: 'The following is the output of a DBN with 512 neurons in an RBM layer. The
    reconstruction loss has come down and the test set''s accuracy has come down as
    well:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个包含512个神经元的RBM层的DBN输出。重构损失下降了，测试集的准确度也下降了：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Notice how the accuracy and test set accuracy both have come down. This means
    increasing the number of neurons doesn't necessarily improve the accuracy.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，准确度和测试集准确度都下降了。这意味着增加神经元的数量并不一定能提高准确度。
- en: An RBM layer with 128 neurons
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个包含128个神经元的RBM层
- en: 'A 128-neuron RBM layer leads to higher test set accuracy but a lower overall
    accuracy:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 128神经元的RBM层导致测试集准确度更高，但整体准确度较低：
- en: '[PRE22]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Comparing the accuracy metrics
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较准确度指标
- en: 'As we have trained the neural network with multiple neuron numbers in RBM layers,
    let''s compare metrics:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经用多个神经元数量的RBM层训练了神经网络，现在来比较一下这些指标：
- en: '![](img/23687400-5515-410c-9181-711d9e3fd7da.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/23687400-5515-410c-9181-711d9e3fd7da.png)'
- en: Reconstruction loss reduces as a function of the number of neurons, as shown
    in the preceding figure.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，重构损失随着神经元数量的增加而减少。
- en: '![](img/d7959b46-15cd-4b5f-8821-6404fa591c3a.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d7959b46-15cd-4b5f-8821-6404fa591c3a.png)'
- en: The test set accuracy peaks for 256 neurons and then comes down.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集的准确度在256个神经元时达到峰值，然后下降。
- en: DBNs with two RBM layers
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有两个RBM层的DBN
- en: 'In this section, we will create a DBN with two RBM layers and run it on the
    MNIST dataset. We will modify the input parameters for the `DeepBeliefNetwork(..)`
    class:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个具有两个RBM层的DBN，并在MNIST数据集上运行。我们将修改`DeepBeliefNetwork(..)`类的输入参数：
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Notice that some of the parameters have two elements for array so we need to
    specify these parameters for two layers:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，某些参数是数组形式，因此我们需要为两个层指定这些参数：
- en: '`rbm_layers = [256, 256]`: Number of neurons in each RBM layer'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rbm_layers = [256, 256]`：每个RBM层中的神经元数量'
- en: '`rbm_learning_rate = [0.001, 0001]`: Learning rate for each RBM layer'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rbm_learning_rate = [0.001, 0001]`：每个RBM层的学习率'
- en: '`rbm_num_epochs = [5, 5]`: Number of epochs in each layer'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rbm_num_epochs = [5, 5]`：每层的Epoch数量'
- en: '`rbm_batch_size= [32, 32]`: Batch size for each RBM layer'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rbm_batch_size= [32, 32]`：每个RBM层的批次大小'
- en: 'Let''s look at the DBN initialization and the training of the model:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看DBN初始化和模型训练：
- en: '[PRE24]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Test the model:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 测试模型：
- en: '[PRE27]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The complete code listing can be found at:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码清单可以在这里找到：
- en: '[https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_mnist_two_layers.py](https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_mnist_two_layers.py).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_mnist_two_layers.py](https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_mnist_two_layers.py)'
- en: 'The following is the output of the preceding listing:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面列表的输出：
- en: '[PRE28]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As can be seen from the preceding listing, the test set accuracy is better than
    the single RBM layer DBN.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的列表中可以看出，测试集的准确率优于单层RBM的DBN。
- en: Classifying the NotMNIST dataset with a DBN
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DBN分类NotMNIST数据集
- en: Let's look at the NotMNIST dataset, which we explored in [Chapter 2](c373e64c-90d3-4676-96fa-cf67e652c25b.xhtml),
    *Deep Feedforward Networks*, in the *Implementing feedforward networks* section
    with images, and see how our DBN works for that dataset.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看NotMNIST数据集，之前我们在[第2章](c373e64c-90d3-4676-96fa-cf67e652c25b.xhtml)的*深度前馈网络*部分中已经探讨过，并附带了图像，看看我们的DBN如何在该数据集上工作。
- en: 'We will leverage the same pickle file, `notMNIST.pickle`, created in [Chapter
    2](c373e64c-90d3-4676-96fa-cf67e652c25b.xhtml), *Deep Feedforward Networks*. The
    initialization parameters and imports are listed here:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用在[第2章](c373e64c-90d3-4676-96fa-cf67e652c25b.xhtml)的*深度前馈网络*部分中创建的相同pickle文件，`notMNIST.pickle`。初始化参数和导入的库如下所示：
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Implementation remains more or less similar to the MNIST dataset. The main
    implementation listing is given here:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 实现方法与MNIST数据集大致相同。主要实现代码如下：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The complete code listing can be found at:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码列表可以在以下位置找到：
- en: '[https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_nomnist.py](https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_nomnist.py).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_nomnist.py](https://github.com/ml-resources/neuralnetwork-programming/blob/ed1/ch08/implementation/boltzmann/run_dbn_nomnist.py)。'
- en: 'The output of the preceding listing will point the performance of our model
    for the NotMNIST dataset:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 前面列表的输出将展示我们模型在NotMNIST数据集上的表现：
- en: '[PRE31]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As can be seen, this network performed much better than the MNIST dataset.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，该网络在NotMNIST数据集上的表现远超MNIST数据集。
- en: Summary
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored DBNs and looked at how these could be used to build
    classification pipelines using one or more RBM layers. We looked at various parameters
    within the RBM layer and their effects on accuracy, reconstruction loss, and test
    set accuracy. We also looked at single layer and multilayer DBNs using one or
    more RBMs.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了DBN，并研究了如何利用这些模型通过一个或多个RBM层来构建分类管道。我们考察了RBM层中的各个参数及其对准确率、重构损失和测试集准确率的影响。我们还看了单层和多层DBN，使用一个或多个RBM。
- en: In the next chapter we look at Generative models and how they differ from discriminative
    models.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨生成模型，并讨论它们与判别模型的区别。
