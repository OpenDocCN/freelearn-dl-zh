- en: Predicting Fire Department Calls with Spark ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark ML预测消防部门呼叫
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Downloading the San Francisco fire department calls dataset
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载旧金山消防部门呼叫数据集
- en: Identifying the target variable of the logistic regression model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定逻辑回归模型的目标变量
- en: Preparing feature variables for the logistic regression model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为逻辑回归模型准备特征变量
- en: Applying the logistic regression model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用逻辑回归模型
- en: Evaluating the accuracy of the logistic regression model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估逻辑回归模型的准确性
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Classification models are a popular way to predict a defined categorical outcome.
    We use outputs from classification models all the time. Anytime we go to see a
    movie in a theatre, we are interested to know whether the film is considered correct?
    One of the most popular classification models in the data science community is
    a logistic regression. The logistic regression model produces a response that
    is activated by a sigmoid function. The sigmoid function uses the inputs from
    the model and produces an output that is between 0 and 1\. That output is usually
    in a form of a probability score. Many deep learning models are also used for
    classification purposes. It is common to find logistic regression models performed
    in conjunction with deep learning models to help establish a baseline in which
    deep learning models are measured against. The sigmoid activation function is
    one of many activation functions that are also used in deep neural networks within
    deep learning to produce a probability output. We will utilize the built-in machine
    learning libraries within Spark to build a logistic regression model that will
    predict whether an incoming call to the San Francisco Fire department is actually
    related to a fire, rather than another incident.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型是预测定义的类别结果的常用方法。我们经常使用分类模型的输出。每当我们去电影院看电影时，我们都关心电影是否符合预期？数据科学领域中最常用的分类模型之一是逻辑回归。逻辑回归模型产生一个由sigmoid函数激活的响应。sigmoid函数使用模型的输入，并产生一个介于0和1之间的输出。这个输出通常是一个概率分数。许多深度学习模型也用于分类目的。常见的是，逻辑回归模型与深度学习模型一起使用，以帮助建立基准，以此为基础来评估深度学习模型。sigmoid激活函数是深度神经网络中使用的多种激活函数之一，在深度学习中用于产生概率输出。我们将利用Spark中的内置机器学习库来构建一个逻辑回归模型，预测旧金山消防部门的来电是否与火灾有关，而不是其他事件。
- en: Downloading the San Francisco fire department calls dataset
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载旧金山消防部门呼叫数据集
- en: 'The City of San Francisco does a great job of collecting fire department calls
    for services across their area. As it states on their website, each record includes
    the call number, incident number, address, unit identifier, call type, and disposition.
    The official website containing San Francisco fire department call data can be
    found at the following link:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 旧金山市在收集辖区内消防部门的呼叫服务方面做得非常好。正如他们网站上所述，每条记录都包含呼叫号、事件号、地址、单位标识符、呼叫类型和处置方式。包含旧金山消防部门呼叫数据的官方网站可以通过以下链接访问：
- en: '[https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)'
- en: 'There is some general information regarding the dataset with regards to the
    number of columns and rows, seen in the following screenshot:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有关数据集的一些常规信息，包含列和行的数量，如下图所示：
- en: '![](img/fc1781db-55cb-4a5e-b3a3-b822a672bbf1.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc1781db-55cb-4a5e-b3a3-b822a672bbf1.png)'
- en: This current dataset, updated on 3/26/2018, has roughly 4.61 M rows and 34 columns.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集最后更新于2018年3月26日，包含大约460万个数据行和34个列。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The dataset is available in a `.csv` file and can be downloaded locally on to
    your machine, where it can then be imported into Spark.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以`.csv`格式提供，可以下载到本地计算机上，然后导入Spark中。
- en: How to do it...
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: This section will walk through the steps to download and import the `.csv` file
    to our Jupyter notebook.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何下载并导入`.csv`文件到我们的Jupyter notebook中。
- en: 'Download the dataset from the website by selecting Export and then CSV, as
    seen in the following screenshot:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从网站下载数据集，通过选择“导出”然后选择CSV，如下图所示：
- en: '![](img/b1f89e2e-1edf-4936-bb0e-090ddf5bdb0d.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1f89e2e-1edf-4936-bb0e-090ddf5bdb0d.png)'
- en: If not already the case, name the downloaded dataset `Fire_Department_Calls_for_Service.csv`
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未这样做，请将下载的数据集命名为 `Fire_Department_Calls_for_Service.csv`
- en: 'Save the dataset to any local directory, although ideally it should be saved
    to the same folder that contains the Spark notebook that will be used in this
    chapter, as seen in the following screenshot:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集保存到任何本地目录中，理想情况下，它应该保存在与本章中使用的 Spark 笔记本相同的文件夹中，如下图所示：
- en: '![](img/f4654852-1dd6-4f0f-8b99-9d28a57a58cc.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f4654852-1dd6-4f0f-8b99-9d28a57a58cc.png)'
- en: 'Once the dataset has been saved to the same directory as the notebook, execute
    the following `pyspark` script to import the dataset into Spark and create a dataframe
    called `df`:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据集保存到与笔记本相同的目录中，执行以下 `pyspark` 脚本，将数据集导入到 Spark 中，并创建一个名为 `df` 的数据框：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The dataset is saved to the same directory that houses the Jupyter notebook
    for ease of import into the Spark session.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集被保存到与 Jupyter 笔记本相同的目录中，便于导入到 Spark 会话中。
- en: A local `pyspark` session is initialized by importing `SparkSession` from `pyspark.sql`.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从 `pyspark.sql` 导入 `SparkSession`，初始化本地 `pyspark` 会话。
- en: A dataframe, `df`, is created by reading in the CSV file with the options `header
    = 'true'` and `inferschema = 'true'`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过读取 CSV 文件并使用 `header = 'true'` 和 `inferschema = 'true'` 选项，创建一个名为 `df` 的数据框。
- en: 'Finally, it is always ideal to run a script to show the data that has been
    imported into Spark through the dataframe to confirm that the data has made its
    way through. The outcome of the script, showing the first two rows of the dataset
    from the San Francisco fire department calls, can be seen in the following screenshot:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，理想情况下，始终运行一个脚本，显示已通过数据框导入 Spark 的数据，以确认数据已成功加载。脚本的结果，显示了旧金山消防部门来电数据集的前两行，如下图所示：
- en: '![](img/bf42a5ae-52b0-4108-9588-afb2deacfb74.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf42a5ae-52b0-4108-9588-afb2deacfb74.png)'
- en: Please note that as we read the file into spark, we are using `.load()` to pull
    the `.csv` file into the Jupyter notebook. This is fine for our purposes as we
    are using a local cluster, but would not work if we were leveraging a cluster
    from Hadoop.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当我们将文件读取到 Spark 时，我们使用 `.load()` 将 `.csv` 文件导入到 Jupyter 笔记本中。对于我们的目的，这种方式是可以的，因为我们使用的是本地集群，但如果我们使用
    Hadoop 的集群，这种方法将不可行。
- en: There's more...
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'The dataset is accompanied by a data dictionary that defines the headers for
    each of the 34 columns. This data dictionary can be accessed from the same website
    through the following link:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集附带一个数据字典，定义了34列中每一列的标题。可以通过以下链接从同一网站访问该数据字典：
- en: '[https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx](https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx](https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx)'
- en: See also
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'The San Francisco government website allows for online visualization of the
    data, which can be used to do some quick data profiling. The visualization application
    can be accessed on the website by selecting the Visualize dropdown, as seen in
    the following screenshot:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 旧金山政府网站允许在线可视化数据，可以用来快速进行数据分析。通过选择网站上的“可视化”下拉菜单，可以访问该可视化应用程序，如下图所示：
- en: '![](img/5c564a36-8237-41fc-901c-1d15b50f97c3.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c564a36-8237-41fc-901c-1d15b50f97c3.png)'
- en: Identifying the target variable of the logistic regression model
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定逻辑回归模型的目标变量
- en: A logistic regression model operates as a classification algorithm aiming to
    predict a binary outcome. In this section, we will specify the best column within
    the dataset to predict whether an incoming call to the operator is related to
    fire or non-fire incidents.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型作为一种分类算法，旨在预测二元结果。在本节中，我们将指定数据集中最合适的列，用于预测接收到的来电是否与火灾或非火灾事件有关。
- en: Getting ready
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will visualize many of the data points in this section, which will require
    the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中我们将可视化许多数据点，这将需要以下内容：
- en: Ensuring that `matplotlib` is installed by executing `pip install matplotlib`
    at the command line.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在命令行执行 `pip install matplotlib`，确保已安装 `matplotlib`。
- en: Running `import matplotlib.pyplot as plt` as well as ensuring graphs are viewed
    within cells by running `%matplotlib inline`.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`import matplotlib.pyplot as plt`，并通过运行`%matplotlib inline`确保图表能够在单元格中显示。
- en: Additionally, there will be some manipulation of functions within `pyspark.sql`
    that requires `importing functions as F`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`pyspark.sql`中的一些函数也需要进行操作，这需要`importing functions as F`。
- en: How to do it...
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section will walk through visualizing the data from the San Francisco Fire
    Department.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将演示如何可视化来自旧金山消防部门的数据。
- en: 'Execute the following script to get a cursory identification of the unique
    values in the `Call Type Group` column:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，以获取`Call Type Group`列中唯一值的初步识别：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There are five main categories:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有五个主要类别：
- en: '`Alarm`.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`报警`。'
- en: '`Potentially Life-threatening`.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`潜在生命威胁`。'
- en: '`Non Life-threatening`.'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`非生命威胁`。'
- en: '`Fire`.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`火灾`。'
- en: '`null`.'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`null`。'
- en: 'Unfortunately, one of those categories is `null` values. It would be useful
    to get a row count of each unique value to identify how many null values there
    are in the dataset. Execute the following script to generate a row count of each
    unique value for the column `Call Type Group`:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不幸的是，其中一个类别是`null`值。获取每个唯一值的行计数，将有助于确定数据集中的`null`值数量。执行以下脚本生成`Call Type Group`列中每个唯一值的行计数：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Unfortunately, there are over 2.8 M rows of data that do not have a `Call Type
    Group` associated with them. That is over 60 percent of the available rows of
    4.6 M. Execute the following script to view the imbalance of null values in a
    bar chart:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不幸的是，超过280万行数据没有与`Call Type Group`关联的值。这占总可用数据（460万行）的60%以上。执行以下脚本，以查看空值不平衡的条形图：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Another indicator may need to be chosen to determine a target variable. Instead,
    we can profile `Call Type` to identify calls associated with fire versus all other
    calls. Execute the following script to profile `Call Type`:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能需要选择另一个指标来确定目标变量。相反，我们可以分析`Call Type`，以识别与火灾相关的呼叫与其他所有呼叫的区别。执行以下脚本来分析`Call
    Type`：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'There do not appear to be any `null` values, as there were with `Call Type
    Group`. There are 32 unique categories for `Call Type`; therefore, it will be
    used as the target variable for fire incidents. Execute the following script to
    tag the columns containing `Fire` in`Call Type`:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与`Call Type Group`不同，似乎没有任何`null`值。`Call Type`共有32个独特类别；因此，它将作为火灾事件的目标变量。执行以下脚本，标记`Call
    Type`中包含`Fire`的列：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the following script to retrieve the distinct counts of `Fire Indicator`:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，以检索`Fire Indicator`的不同计数：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Execute the following script to add the `Fire Indicator` column to the original
    dataframe, `df`:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，将`Fire Indicator`列添加到原始数据框`df`中：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, add the `fireIndicator` column has to the dataframe, `df`, and confirm
    by executing the following script:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将`fireIndicator`列添加到数据框`df`中，并通过执行以下脚本确认：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'One of the key steps to building a successful logistic regression model is
    establishing a binary target variable that will be used as the prediction outcome.
    This section walks through the logic behind selecting our target variable:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 构建成功的逻辑回归模型的关键步骤之一是确定一个二元目标变量，该变量将用于预测结果。本节将讲解如何选择我们的目标变量：
- en: 'Data profiling of potential target columns is performed by identifying the
    unique column values of `Call Type Group`. We can view the unique values of the
    `Call Type Group` column, as seen in the following screenshot:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过识别`Call Type Group`列的唯一值，进行潜在目标列的数据分析。我们可以查看`Call Type Group`列中的唯一值，如以下截图所示：
- en: '![](img/d3ade658-22c0-4fa4-9a1d-ebae6ad1ecdc.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3ade658-22c0-4fa4-9a1d-ebae6ad1ecdc.png)'
- en: The goal is to identify whether there are any missing values within the `Call
    Type Group` column and what can be done with those missing values. Sometimes,
    the missing values in the columns can just be dropped, and other times they are
    manipulated to populate values.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标是识别`Call Type Group`列中是否存在缺失值，以及如何处理这些缺失值。有时，列中的缺失值可以直接删除，而其他时候则需要进行处理以填充这些值。
- en: 'The following screenshot shows how many null values are present:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图显示了有多少`null`值：
- en: '![](img/bca41dd4-acd7-4c95-971a-543d5a0dcbed.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bca41dd4-acd7-4c95-971a-543d5a0dcbed.png)'
- en: 'Additionally, we can also plot how many `null` values are present to get a
    better visual sense of the abundance of values, as seen in the following screenshot:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们还可以绘制`null`值的数量，以更直观地了解值的分布情况，如以下截图所示：
- en: '![](img/8834a412-6660-40fe-92be-abf4bcf63aa6.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8834a412-6660-40fe-92be-abf4bcf63aa6.png)'
- en: Since there are over 2.8 M rows that are missing from `Call Type Group`, as
    seen in the `df.groupBy` script as well as the bar chart, it doesn't make sense
    to drop all of those values, as that is over 60 percent of the total row count
    from the dataset. Therefore, another column will need to be chosen as the target
    indicator.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于在`Call Type Group`中有超过280万行缺失数据，如`df.groupBy`脚本和条形图所示，删除这些值没有意义，因为它们占数据集中总行数的60%以上。因此，需要选择另一个列作为目标指标。
- en: 'While profiling the `Call Type` column, we find that there aren''t any null
    rows in the 32 unique possible values. This makes `Call Type` a better candidate
    for the target variable for the logistic regression model. The following is a
    screenshot of the `Call Type` column profiled:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在分析`Call Type`列时，我们发现32个唯一的可能值中没有空值。这使得`Call Type`成为逻辑回归模型的一个更好的目标变量。以下是`Call
    Type`列分析的截图：
- en: '![](img/1977a0ab-f4a3-4174-9ea1-ff28ba2df5dc.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1977a0ab-f4a3-4174-9ea1-ff28ba2df5dc.png)'
- en: 'Since logistic regression works best when there is a binary outcome, a new
    column is created using the `withColumn()` operator in the `df` dataframe to capture
    an indicator (0 or 1) as to whether a call is affiliated with a fire-related incident
    or a non-fire-related incident. The new column is called `fireIndicator` and can
    be seen in the following screenshot:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于逻辑回归在二元结果下效果最佳，因此在`df`数据框中使用`withColumn()`操作符创建了一个新列，用于表示某个呼叫是否与火灾相关事件有关（0或1）。这个新列名为`fireIndicator`，可以在以下截图中看到：
- en: '![](img/580f9ef9-2299-4aae-8164-c174ba2c31db.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/580f9ef9-2299-4aae-8164-c174ba2c31db.png)'
- en: 'We can identify how prevalent fire calls are compared to the rest of the calls
    by doing a `groupBy().count()`, as seen in the following screenshot:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过执行`groupBy().count()`来识别火灾呼叫与其他呼叫的普遍程度，如下图所示：
- en: '![](img/d0b58340-59f9-418d-8d1b-cc62349a62e5.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0b58340-59f9-418d-8d1b-cc62349a62e5.png)'
- en: 'It is best practice to confirm that the new column has been attached to the
    existing dataframe by executing the `printSchema()` script of the newly modified
    dataframe. The output of the new schema can be seen in the following screenshot:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最佳实践是在执行新修改数据框的`printSchema()`脚本后确认新列已经附加到现有数据框中。新架构的输出可以在以下截图中看到：
- en: '![](img/b34b4286-dfcf-4827-a2a3-4ce95aeea7ff.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b34b4286-dfcf-4827-a2a3-4ce95aeea7ff.png)'
- en: There's more...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'There were a couple of column manipulations done with the `pyspark.sql` module
    in this section. The `withColumn()` operator returns a new dataframe or modifies
    an existing dataframe by adding a new column or modifies an existing column of
    the same name. This is not to be confused with the `withColumnRenamed()` operator,
    which also returns a new dataframe, but by modifying the name of an existing column
    to a new column. Finally, we needed to perform some logical operations to convert
    values associated with `Fire` to 0 and without `Fire` to 1\. This required using
    the `pyspark.sql.functions` module and incorporating the `where` function as an
    equivalent to a case statement used in SQL. The function created a case statement
    equation using the following syntax:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，使用了`pyspark.sql`模块进行了一些列操作。`withColumn()`操作符通过添加一个新列或修改现有的同名列来返回一个新的数据框或修改现有的数据框。这个操作符不应与`withColumnRenamed()`操作符混淆，后者同样返回一个新的数据框，但通过修改现有列的名称来更改为新列。最后，我们需要执行一些逻辑操作，将与`Fire`相关的值转换为0，而没有`Fire`的转换为1。这需要使用`pyspark.sql.functions`模块，并结合`where`函数，相当于SQL中的`case`语句。这个函数通过以下语法创建了一个`case`语句公式：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The outcome of the new dataset for both columns, `Call Type` and `fireIndicator`,
    appear as the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 新数据集的结果中，`Call Type`和`fireIndicator`两列的内容如下所示：
- en: '![](img/7f49b4cf-6efd-4c04-ab4f-df0623e76d72.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7f49b4cf-6efd-4c04-ab4f-df0623e76d72.png)'
- en: See also
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'In order to learn more about the `pyspark.sql` module available within Spark,
    visit the following website:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解有关Spark中`pyspark.sql`模块的更多信息，请访问以下网站：
- en: '[http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html](http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html](http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html)'
- en: Preparing feature variables for the logistic regression model
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备逻辑回归模型的特征变量
- en: In the previous section, we identified our target variable that will be used
    as our predictor for fire calls in our logistic regression model. This section
    will focus on identifying all of the features that will best help the model identify
    what the target should be. This is known as **feature selection**.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们确定了将用于预测火灾报警的目标变量，并将其用于逻辑回归模型。本节将重点介绍如何识别所有有助于模型确定目标变量的特征。这就是所谓的**特征选择**。
- en: Getting ready
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: This section will require importing `StringIndexer` from `pyspark.ml.feature`.
    In order to ensure proper feature selection, we will need to map string columns
    to columns of indices. This will help generate distinct numeric values for categorical
    variables that will provide ease of computation for the machine learning model
    to ingest the independent variables used to predict the target outcome.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将需要从`pyspark.ml.feature`导入`StringIndexer`。为了确保正确的特征选择，我们需要将字符串类型的列映射为索引列。这将帮助为分类变量生成不同的数字值，便于机器学习模型处理独立变量，从而预测目标结果。
- en: How to do it...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section will walk through the steps to prepare the feature variables for
    our model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何为我们的模型准备特征变量的步骤。
- en: 'Execute the following script to update the dataframe, `df`, by only selecting
    the fields that are independent of any fire indicators:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，以仅选择与任何火灾指标无关的字段，从而更新数据框`df`：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The next step is to identify any null values within the dataframe and remove
    them if they exist. Execute the following script to identify the row count with
    any null values:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是识别数据框中是否有空值，如果存在则将其删除。执行以下脚本以识别包含空值的行数：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'There are 16,551 rows with missing values. Execute the following script to
    update the dataframe to remove all rows with null values:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有16,551行包含缺失值。执行以下脚本以更新数据框，删除所有包含空值的行：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Execute the following script to retrieve the updated target count of `fireIndicator`:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以检索更新后的`fireIndicator`目标计数：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Import the `StringIndexer` class from `pyspark.ml.feature` to assign numeric
    values to each categorical variable for the features, as seen in the following
    script:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`pyspark.ml.feature`导入`StringIndexer`类，为每个分类变量分配数值，如下脚本所示：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a Python list for all the feature variables that will be used in the
    model using the following script:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本创建一个包含所有将用于模型的特征变量的Python列表：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Execute the following script to specify the output column format, `outputcol`,
    that will be `stringIndexed` from the list of features from the input column,
    `inputcol`:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以指定输出列格式`outputcol`，该列将通过从输入列`inputcol`中的特征列表进行`stringIndexed`来生成：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Execute the following script to create a `model` that will be used to `fit`
    the input columns and produce the newly defined output columns to the existing
    dataframe, `df`:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以创建一个`model`，该模型将用于`拟合`输入列，并将新定义的输出列添加到现有的数据框`df`：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Execute the following script to define a final selection of the features in
    the dataframe, `df`, that will be used for the model:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本以定义数据框`df`中最终选择的特征，这些特征将用于模型：
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section will explain the logic behind the steps in preparing the feature
    variables for our model.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释准备特征变量步骤背后的逻辑。
- en: 'Only the indicators in the dataframe that are truly independent of an indication
    of fire are selected to contribute to the logistic regression model that will
    predict the outcome. The reason this is performed is to remove any potential bias
    in the dataset that may already reveal the outcome of the prediction. This minimizes
    human interaction with the final outcome. The output of the updated dataframe
    can be seen in the following screenshot:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有数据框中真正与火灾指示无关的指标才会被选择用来构建预测结果的逻辑回归模型。这样做的原因是为了去除数据集中的潜在偏差，这些偏差可能已经揭示了预测的结果。这样可以最大限度地减少人为干预对最终结果的影响。更新后的数据框输出可以在以下截图中查看：
- en: '![](img/9f0de7d8-271d-4563-960e-425ba8cbba19.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f0de7d8-271d-4563-960e-425ba8cbba19.png)'
- en: Please note that the column `Neighborhooods - Analysis of Boundaries` is originally
    misspelled from the data we extract. We will continue to use the misspelling for
    the rest of the chapter for continuity purposes. However, the column name can
    be renamed using the `withColumnRenamed()` function in Spark.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`Neighborhooods - Analysis of Boundaries` 列最初是在我们提取的数据中拼写错误的。为了保持一致性，我们将继续使用错误拼写，直到本章结束。然而，可以通过
    Spark 中的 `withColumnRenamed()` 函数将列名重命名。
- en: 'The final selection of columns are chosen as the following:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终选择的列如下所示：
- en: '`fireIndicator`'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`火警指示器`'
- en: '`Zipcode of Incident`'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`事件的邮政编码`'
- en: '`Battalion`'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`营`'
- en: '`Station Area`'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`站点区域`'
- en: '`Box`'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`箱`'
- en: '`Number of Alarms`'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`警报次数`'
- en: '`Unit sequence in call dispatch`'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`呼叫调度中的单元序列`'
- en: '`Neighborhooods - Analysis Boundaries`'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Neighborhooods - Analysis Boundaries`'
- en: '`Fire Prevention District`'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`消防预防区`'
- en: '`Supervisor District`'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`监管区`'
- en: These columns are selected to avoid data leakage in our modeling. Data leakage
    is common in modeling and can lead to invalid predictive models because it can
    incorporate features that are directly a result of the outcome we are trying to
    predict. Ideally, we wish to incorporate features that are truly independent of
    the outcome. There are several columns that appeared to be leaky and, hence, are
    removed from our dataframe and model.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些列被选择是为了避免在建模中出现数据泄漏。数据泄漏在建模中很常见，它可能导致无效的预测模型，因为它可能包括那些直接影响我们要预测的结果的特征。理想情况下，我们希望使用与结果真正独立的特征。有几个列看起来存在泄漏，因此它们被从我们的数据框和模型中移除。
- en: 'All rows with missing or null values are identified and removed in order to
    get the very best performance out of the model without overstating or understating
    key features. An inventory of the rows with missing values can be calculated and
    shown to be 16,551, as seen in the following script:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有缺失或为空的行都会被识别并移除，以便从模型中获得最佳性能，而不夸大或低估关键特征。可以计算并显示缺失值的行数，结果为16,551，如以下脚本所示：
- en: '![](img/9df0dab7-e80a-4d5c-84fc-67811558ce32.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9df0dab7-e80a-4d5c-84fc-67811558ce32.png)'
- en: 'We can get a look at the frequency of calls that are fire-related versus those
    that are not, as seen in the following screenshot:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看火灾相关的呼叫频率与非火灾呼叫的比较，以下截图展示了这一情况：
- en: '![](img/32117958-6e01-4ba3-9c54-bf04129c5181.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32117958-6e01-4ba3-9c54-bf04129c5181.png)'
- en: '`StringIndexer` is imported to help convert several of the categorical or string
    features into numerical values for ease of computation within the logistic regression
    model. The input of the features needs to be in a vector or array format, which
    is ideal for numeric values. A list of all the features that will be used in the
    model can be seen in the following screenshot:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`StringIndexer` 被导入以帮助将多个类别或字符串特征转换为数值，以便在逻辑回归模型中进行计算。特征的输入需要是向量或数组格式，这对数值型数据是理想的。以下截图显示了将用于模型的所有特征列表：'
- en: '![](img/cb62409e-94dc-4357-a5ac-e7127ff20596.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cb62409e-94dc-4357-a5ac-e7127ff20596.png)'
- en: 'An indexer is built for each of the categorical variables specifying the input
    (`inputCol`) and output (`outputCol`) columns that will be used in the model. Each
    column in the dataframe is adjusted or transformed to rebuild a new output with
    the updated indexing, ranging from 0 to the maximum value of the unique count
    of that specific column. The new column is appended with `_Index` at the end.
    While the updated column is created, the original column is still available in
    the dataframe, as seen in the following screenshot:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个类别变量构建一个索引器，指定模型中将使用的输入列（`inputCol`）和输出列（`outputCol`）。数据框中的每一列都经过调整或转换，重建一个新的输出，并使用更新后的索引，范围从
    0 到该列的唯一值的最大计数。新的列在末尾添加了 `_Index`。在创建更新后的列时，原始列仍然保留在数据框中，如以下截图所示：
- en: '![](img/df67a60c-19da-4691-9903-e81d215ad749.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df67a60c-19da-4691-9903-e81d215ad749.png)'
- en: 'We can look at one of the newly created columns and compare it with the original
    to see how the strings have been converted to numeric categories. The following
    screenshot shows how `Neighborhooods - Analysis Boundaries` compares with `Neighborhooods -
    Analysis Boundaries_Index`:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看其中一个新创建的列，并将其与原始列进行比较，看看字符串是如何被转换为数值类别的。以下截图展示了 `Neighborhooods - Analysis
    Boundaries` 和 `Neighborhooods - Analysis Boundaries_Index` 的比较：
- en: '![](img/5b9432fe-0906-4632-808a-fd882682c1c5.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b9432fe-0906-4632-808a-fd882682c1c5.png)'
- en: The dataframe is then trimmed down to incorporate only the numerical values
    and remove the original categorical variables that were transformed. The non-numerical
    values no longer serve a purpose from a modeling perspective and are dropped from
    the dataframe.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，数据框被裁剪，只保留数值型数据，并去除已经转换的原始类别变量。从建模的角度来看，非数值型数据不再起作用，因此被从数据框中删除。
- en: 'The new columns are printed out to confirm that each value type of the dataframe
    is either double precision or integer, as seen in the following screenshot:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新列已打印出来，以确认数据框中每个值的类型是双精度或整数，如下图所示：
- en: '![](img/61837070-2d38-48e9-92a3-e09a8984a90d.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61837070-2d38-48e9-92a3-e09a8984a90d.png)'
- en: There's more...
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'A final look at the newly modified dataframe will reveal only numerical values,
    as seen in the following screenshot:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后查看经过修改的数据框，您会发现它只包含数值型数据，如下图所示：
- en: '![](img/9c63a287-61af-4a3f-a311-d051054791e1.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9c63a287-61af-4a3f-a311-d051054791e1.png)'
- en: See also
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: In order to learn more about `StringIndexer`, visit the following website: [https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer](https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`StringIndexer`的信息，请访问以下网站：[https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer](https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer)。
- en: Applying the logistic regression model
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用逻辑回归模型
- en: The stage is now set to apply the model to the dataframe.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经为将模型应用到数据框做好准备。
- en: Getting ready
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'This section will focus on applying a very common classification model called
    **logistic regression**, which will involve importing some of the following from
    Spark:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍应用一种非常常见的分类模型——**逻辑回归**，这将涉及从Spark中导入以下一些内容：
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How to do it...
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section will walk through the steps of applying our model and evaluating
    the results.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将逐步介绍应用模型和评估结果的过程。
- en: 'Execute the following script to lump all of the feature variables in the dataframe
    in a list called `features`:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，将数据框中的所有特征变量放入一个名为`features`的列表中：
- en: '[PRE20]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Execute the following to import `VectorAssembler` and configure the fields
    that will be assigned to the feature vector by assigning the `inputCols` and `outputCol`:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下操作以导入`VectorAssembler`并配置将分配给特征向量的字段，通过指定`inputCols`和`outputCol`：
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Execute the following script to apply `VectorAssembler` to the dataframe with
    the `transform` function:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，使用`transform`函数将`VectorAssembler`应用到数据框中：
- en: '[PRE22]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Modify the dataframe to remove all of the columns except for `fireIndicator`
    and `features`, as seen in the following script:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改数据框，移除除`fireIndicator`和`features`之外的所有列，如下脚本所示：
- en: '[PRE23]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Modify the dataframe to rename `fireIndicator` to `label`, as seen in the following
    script:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改数据框，将`fireIndicator`重命名为`label`，如下脚本所示：
- en: '[PRE24]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Split the entire dataframe, `df`, into training and test sets in a 75:25 ratio,
    with a random seed set as `12345`, as seen in the following script:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将整个数据框`df`按75:25的比例拆分为训练集和测试集，并设置随机种子为`12345`，如下脚本所示：
- en: '[PRE25]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Import the `LogisticRegression` library from `pyspark.ml.classification` and
    configure to incorporate the `label` and `features` from the dataframe, and then
    fit on the training dataset, `trainDF`, as seen in the following script:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`pyspark.ml.classification`导入`LogisticRegression`库，并配置以从数据框中引入`label`和`features`，然后在训练数据集`trainDF`上进行拟合，如下脚本所示：
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Transform the test dataframe, `testDF`, to apply the logistic regression model.
    The new dataframe with the scores from the prediction is called `df_predicted`,
    as seen in the following script:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换测试数据框`testDF`，应用逻辑回归模型。新的数据框包含预测结果的分数，命名为`df_predicted`，如下脚本所示：
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains the logic behind the steps in applying our model and evaluating
    the results.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释应用模型和评估结果步骤背后的逻辑。
- en: Classification models work best when all of the features are combined in a single
    vector for training purposes. Therefore, we begin the vectorization process by
    collecting all of the features into a single list called `features`. Since our
    label is the first column of the dataframe, we exclude it and pull in every column
    after as a feature column or feature variable.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类模型在将所有特征合并为一个单一向量进行训练时效果最佳。因此，我们通过将所有特征收集到一个名为`features`的单一列表中，开始向量化过程。由于我们的标签是数据框的第一列，因此我们将其排除，并将之后的每一列作为特征列或特征变量。
- en: The vectorization process continues by converting all of the variables from
    the `features` list into a single vector output to a column called `features`.
    This process requires importing `VectorAssembler` from `pyspark.ml.feature`.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向量化过程继续进行，将`features`列表中的所有变量转换为一个输出到`features`列的单一向量。这个过程需要从`pyspark.ml.feature`导入`VectorAssembler`。
- en: 'Applying `VectorAssembler` transforms the dataframe by creating a newly added
    column called `features`, as seen in the following screenshot:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用`VectorAssembler`会通过创建一个名为`features`的新列来转换数据框，具体见下图：
- en: '![](img/dfe3ef28-1df5-4b4a-b749-2b9483542ed9.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dfe3ef28-1df5-4b4a-b749-2b9483542ed9.png)'
- en: At this point, the only columns that are necessary for us to use in the model
    are the label column, `fireIndicator`, and the `features` column. All of the other
    columns can be dropped from the dataframe as they will no longer be needed for
    modeling purposes.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，模型中唯一需要使用的列是标签列`fireIndicator`和`features`列。其他所有列可以从数据框中删除，因为它们在建模过程中不再需要。
- en: 'Additionally, to help with the logistic regression model, we will change the
    column called `fireIndicator` to `label`. The output of the `df.show()` script
    can be seen in the following screenshot with the newly renamed columns:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，为了帮助逻辑回归模型，我们将把名为`fireIndicator`的列更名为`label`。`df.show()`脚本的输出可以在以下截图中看到，其中包括新重命名的列：
- en: '![](img/313f52f6-30e8-4e7a-a968-ff5152d5c2a9.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/313f52f6-30e8-4e7a-a968-ff5152d5c2a9.png)'
- en: 'In order to minimize overfitting the model, the dataframe will be split into
    a testing and training dataset to fit the model on the training dataset, `trainDF`,
    and test it on the testing dataset, `testDF`. A random seed of `12345` is set
    to keep the randomness consistent each time the cell is executed. We can identify
    the row counts for the data split, as seen in the following screenshot:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了减少过拟合，数据框将被拆分为测试数据集和训练数据集，以便在训练数据集`trainDF`上训练模型，并在测试数据集`testDF`上进行测试。设置了一个随机种子`12345`，以确保每次执行该单元时随机性的一致性。我们可以在以下截图中看到数据拆分的行数：
- en: '![](img/2d20098a-229b-4a3b-9e7e-d3d6d4efa513.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d20098a-229b-4a3b-9e7e-d3d6d4efa513.png)'
- en: A logistic regression model, `LogisticRegression`, is then imported from `pyspark.ml.classification`
    and configured to input the appropriate column names from the dataframe associated
    with the features and the label. Additionally, the logistic regression model is
    assigned to a variable called `logreg` that is then fit to train our data set,
    `trainDF`.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，从`pyspark.ml.classification`导入逻辑回归模型`LogisticRegression`，并配置以输入数据框中与特征和标签相关的列名。此外，逻辑回归模型会被分配给一个名为`logreg`的变量，接着对我们的数据集`trainDF`进行训练。
- en: 'A new dataframe, `predicted_df`, is created based on the transformation of
    the test dataframe, `testDF`, once the logistic regression model is scored on
    it. The model creates three additional columns for `predicted_df`, based on the
    scoring. The three additional columns are `rawPrediction`, `probability`, and
    `prediction`, as seen in the following screenshot:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个新的数据框`predicted_df`，基于对测试数据框`testDF`的变换，逻辑回归模型对其评分后，该模型为`predicted_df`创建了三个额外的列。根据评分，额外的三个列是`rawPrediction`、`probability`和`prediction`，具体见下图：
- en: '![](img/889efec5-2794-45f2-af1d-f0fe21429c79.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/889efec5-2794-45f2-af1d-f0fe21429c79.png)'
- en: 'Finally, the new columns in `df_predicted` can be profiled, as seen in the
    following screenshot:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，可以对`df_predicted`中的新列进行分析，具体见下图：
- en: '![](img/8181ca5d-64f1-45b0-9b82-d487ad69dc1d.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8181ca5d-64f1-45b0-9b82-d487ad69dc1d.png)'
- en: There's more...
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One important thing to keep in mind because it may initially come off as being
    counter-intuitive is that our probability threshold is set at 50 percent in our
    dataframe. Any call with a probability of 0.500 and above is given a prediction
    of 0.0 and any call with a probability of less than 0.500 is given a prediction of
    1.0\. This was set during the pipeline development process and as long as we are
    aware of what the threshold is along with how the prediction is allocated, we
    are in good shape.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 有一件重要的事情需要记住，因为它最初可能看起来有些直觉不合常理，那就是我们的概率阈值在数据框中设置为50%。任何概率大于或等于0.500的调用都会被预测为0.0，而任何概率小于0.500的调用则会被预测为1.0。这个设置是在管道开发过程中完成的，只要我们知道阈值是什么，并且了解预测是如何分配的，我们就能很好地应对。
- en: See also
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about `VectorAssembler`, visit the following website:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`VectorAssembler`的信息，请访问以下网站：
- en: '[https://spark.apache.org/docs/latest/ml-features.html#vectorassembler](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/ml-features.html#vectorassembler](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)'
- en: Evaluating the accuracy of the logistic regression model
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估逻辑回归模型的准确性
- en: We are now ready to evaluate the performance of predicting whether a call was
    correctly classified as a fire incident.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好评估预测是否正确分类为火灾事件的性能。
- en: Getting ready
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'We will perform the model analysis which will require importing the following:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进行模型分析，这需要导入以下内容：
- en: '`from sklearn import metrics`'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from sklearn import metrics`'
- en: How to do it...
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section walks through the steps to evaluate the model performance.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讲解了评估模型性能的步骤。
- en: 'Create a confusion matrix using the `.crosstab()` function, as seen in the
    following script:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.crosstab()`函数创建混淆矩阵，如以下脚本所示：
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Import `metrics` from `sklearn` to help measure accuracy using the following
    script:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn`导入`metrics`模块来帮助使用以下脚本测量准确性：
- en: '[PRE29]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create two variables for the `actual` and `predicted` columns from the dataframe
    that will be used to measure accuracy, using the following script:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别代表数据框中的`actual`和`predicted`列，这些列将用于衡量准确性，使用以下脚本：
- en: '[PRE30]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Compute the accuracy prediction score using the following script:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本计算准确率预测分数：
- en: '[PRE31]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works...
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the model performance is evaluated.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何评估模型的性能。
- en: 'In order to compute the accuracy of our model, it is important to be able to
    identify how accurate our predictions were. Often, this is best visualized using
    a confusion matrix cross table that shows correct and incorrect prediction scores.
    We create a confusion matrix using the `crosstab()` function off the `df_predicted` dataframe
    that shows us we have 964,980 true negative predictions for labels that are 0
    and we have 48,034 true positive predictions for labels that are 1, as seen in
    the following screenshot:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算模型的准确率，重要的是能够识别我们的预测有多准确。通常，使用混淆矩阵交叉表来可视化这一点，它展示了正确和错误的预测分数。我们使用`df_predicted`数据框中的`crosstab()`函数创建了一个混淆矩阵，显示我们有964,980个负类正确预测（标签为0），以及48,034个正类正确预测（标签为1），如下图所示：
- en: '![](img/3b89bb6d-d661-4cec-92ba-d02a0849e8e4.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b89bb6d-d661-4cec-92ba-d02a0849e8e4.png)'
- en: We know from earlier in this section that there are a total of 1,145,589 rows
    from the `testDF` dataframe; therefore, we can calculate the accuracy of the model
    using the following formula: *(TP + TN) / Total*. The accuracy would then be 88.4
    percent.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从本节前面的内容我们知道，`testDF`数据框总共有1,145,589行；因此，我们可以使用以下公式计算模型的准确性：*(TP + TN) / 总数*。准确率为88.4%。
- en: It is important to note that not all false scores are created equal. For example,
    it is more detrimental to classify a call as not relating to fire and ultimately
    have it be related to fire than vice-versa from a fire safety perspective. This
    is referred to as a false negative. There is a metric that accounts for a **false
    negative** (**FN**), known as **recall**.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要注意，并非所有的假分数都具有相同的意义。例如，从火灾安全的角度来看，将一次通话错误地归类为与火灾无关，而实际上它与火灾有关，比将其错误地归类为火灾事件要更为严重。这种情况称为假阴性。为了衡量假阴性（**FN**），有一个叫做**召回率**的指标。
- en: While we can work out the accuracy manually, as seen in the last step, it is
    ideal to have the accuracy automatically calculated. This can be easily performed
    by importing `sklearn.metrics`, which is a module that is commonly used for scoring
    and model evaluation.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然我们可以像最后一步那样手动计算准确率，但最好能够自动计算准确率。这可以通过导入`sklearn.metrics`模块轻松实现，它是一个常用于评分和模型评估的模块。
- en: '`sklearn.metrics` takes in two parameters, the actual results that we have
    for labels and the predicted values we derived from the logistic regression model.
    Therefore, two variables are created, `actual` and `predicted`, and an accuracy
    score is calculated using the `accuracy_score()` function, as seen in the following
    screenshot:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sklearn.metrics`接受两个参数：我们用于标签的实际结果和从逻辑回归模型中得出的预测值。因此，创建了两个变量，`actual`和`predicted`，并使用`accuracy_score()`函数计算准确率，如下图所示：'
- en: '![](img/3370b494-009d-495f-80ee-685f447efd81.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3370b494-009d-495f-80ee-685f447efd81.png)'
- en: The accuracy score is the same as we calculated manually, 88.4 percent.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确率与我们手动计算的结果相同，为88.4%。
- en: There's more...
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'We now know that our model was able to accurately predict whether a call coming
    in is related to fire or not at a rate of 88.4 percent. At first, this may sound
    like a strong prediction; however, it''s always important to compare this to a
    baseline score where every call was predicted as a non-fire call. The predicted
    dataframe, `df_predicted`, had the following breakdown of labels `1` and `0`,
    as seen in the following screenshot:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道我们的模型能够以88.4%的准确率准确预测来电是否与火灾相关。乍一听，这似乎是一个强有力的预测；然而，始终需要将其与基准得分进行比较，其中每个电话都被预测为非火灾电话。预测的数据框架`df_predicted`中标签`1`和`0`的分布情况如下图所示：
- en: '![](img/6db3def2-822e-4727-bcf2-3ed64295f3a9.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6db3def2-822e-4727-bcf2-3ed64295f3a9.png)'
- en: 'We can run some statistics on that same dataframe to get the mean of label
    occurrences of value `1` using the `df_predicted.describe(''label'').show()` script.
    The output of that script can be seen in the following screenshot:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在同一个数据框架上运行一些统计信息，使用`df_predicted.describe('label').show()`脚本来计算标签值`1`的均值。该脚本的输出可以在下面的截图中看到：
- en: '![](img/66f86b60-b8b9-4a6e-a447-a40fbde76ba4.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/66f86b60-b8b9-4a6e-a447-a40fbde76ba4.png)'
- en: A base model has a prediction value of `1` at a rate of 14.94 percent, or in
    other words, it has a prediction rate of *100 - 14.94* percent, which is 85.06
    percent for a value of 0\. Therefore, since 85.06 percent is less than the model
    prediction rate of 88.4 percent, this model provides an improvement over a blind
    guess as to whether a call is fire-related or not.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基础模型在预测值为`1`时的预测率为14.94%，换句话说，它的预测率为*100 - 14.94*%，即为0时的预测率为85.06%。因此，由于85.06%小于模型预测率88.4%，该模型相比于盲目猜测（是否为火灾相关的电话）提供了更好的改进。
- en: See also
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about accuracy vs. precision, visit the following website:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于准确度与精确度的知识，请访问以下网站：
- en: '[https://www.mathsisfun.com/accuracy-precision.html](https://www.mathsisfun.com/accuracy-precision.html)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.mathsisfun.com/accuracy-precision.html](https://www.mathsisfun.com/accuracy-precision.html)'
