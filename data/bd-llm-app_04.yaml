- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Prompt Engineering
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程
- en: In *Chapter 2*, we introduced the concept of prompt engineering as the process
    of designing and optimizing prompts – the text input that guides the behavior
    of a **large language model** (**LLM**) – for LLMs for a wide variety of applications
    and research topics. Since prompts have a massive impact on LLM performance, prompt
    engineering is a crucial activity while designing LLM-powered applications. In
    fact, there are several techniques that can be implemented not only to refine
    your LLM’s responses but also to reduce risks associated with hallucination and
    bias.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 2 章* 中，我们介绍了提示工程的概念，即设计并优化用于指导 **大型语言模型**（**LLM**）行为的文本输入——提示——的过程，以适用于广泛的
    LLM 应用和研究主题。由于提示对 LLM 性能有巨大影响，提示工程在设计基于 LLM 的应用程序时是一项关键活动。实际上，有一些技术不仅可以完善你的 LLM
    的响应，还可以减少与幻觉和偏差相关的风险。
- en: In this chapter, we are going to cover the emerging techniques in the field
    of prompt engineering, starting from basic approaches up to advanced frameworks.
    By the end of this chapter, you will have the foundations to build functional
    and solid prompts for your LLM-powered applications, which will also be relevant
    in the upcoming chapters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨提示工程领域的新兴技术，从基本方法到高级框架。到本章结束时，你将具备构建功能强大且稳固的提示的基础，这些提示对于你的基于 LLM 的应用程序也将在后续章节中适用。
- en: 'We will go through the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨以下主题：
- en: Introduction to prompt engineering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程简介
- en: Basic principles of prompt engineering
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程的原理
- en: Advanced techniques of prompt engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程的先进技术
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete the tasks in this chapter, you will require the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的任务，你需要以下条件：
- en: OpenAI account and API
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 账户和 API
- en: Python 3.7.1 or later version
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7.1 或更高版本
- en: You can find all the code and examples in the book’s GitHub repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_04.xhtml).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的 GitHub 仓库中找到所有代码和示例：[https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_04.xhtml)。
- en: What is prompt engineering?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: A prompt is a text input that guides the behavior of an LLM to generate a text
    output.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是一种文本输入，它指导大型语言模型（LLM）生成文本输出。
- en: Prompt engineering is the process of designing effective prompts that elicit
    high-quality and relevant output from LLMs. Prompt engineering requires creativity,
    understanding of the LLM, and precision.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是一个设计有效提示的过程，这些提示可以从 LLM 中激发出高质量和相关的输出。提示工程需要创造力、对 LLM 的理解以及精确性。
- en: 'The following figure shows an example of how a well-written prompt can instruct
    the same model to perform three different tasks:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了如何通过一个精心编写的提示来指导同一个模型执行三个不同的任务：
- en: '![](img/B21714_04_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21714_04_01.png)'
- en: 'Figure 4.1: Example of prompt engineering to specialize LLMs'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：提示工程示例，用于专门化大型语言模型（LLM）
- en: As you might imagine, the prompt becomes one of the key elements for an LLM-powered
    application’s success. As such, it is pivotal to invest time and resources in
    this step, following some best practices and principles that we are going to cover
    in the next sections.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，提示成为了一个基于 LLM 的应用程序成功的关键要素之一。因此，投入时间和资源在这一步至关重要，我们需要遵循一些最佳实践和原则，这些将在接下来的章节中介绍。
- en: Principles of prompt engineering
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程的原理
- en: Generally speaking, there are no fixed rules to obtain the “perfect” prompt
    since there are too many variables to be taken into account (the type of model
    used, the goal of the application, the supporting infrastructure, and so on).
    Nevertheless, there are some clear principles that have proven to produce positive
    effects if incorporated into the prompt. Let’s examine some of them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，没有固定的规则可以获得“完美”的提示，因为需要考虑的变量太多（使用的模型类型、应用程序的目标、支持的基础设施等）。尽管如此，有一些明确的原理，如果融入提示中，已被证明会产生积极的效果。让我们考察其中的一些。
- en: Clear instructions
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清晰的指令
- en: 'The principle of giving clear instructions is to provide the model with enough
    information and guidance to perform the task correctly and efficiently. Clear
    instructions should include the following elements:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 明确指令的原则是向模型提供足够的信息和指导，以便正确且高效地完成任务。清晰的指令应包括以下要素：
- en: The goal or objective of the task, such as “write a poem” or “summarize an article”
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的目标或目的，例如“写一首诗”或“总结一篇文章”
- en: The format or structure of the expected output, such as “use four lines with
    rhyming words” or “use bullet points with no more than 10 words each”
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期输出的格式或结构，例如“使用四行押韵的词”或“使用每项不超过10个单词的项目符号”
- en: The constraints or limitations of the task, such as “do not use any profanity”
    or “do not copy any text from the source”
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的约束或限制，例如“不要使用任何粗俗的语言”或“不要复制任何来自源文本的文本”
- en: The context or background of the task, such as “the poem is about autumn” or
    “the article is from a scientific journal”
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的上下文或背景，例如“这首诗是关于秋天的”或“这篇文章来自科学期刊”
- en: 'Let’s say, for example, that we want our model to fetch any kind of instructions
    from text and return to us a tutorial in a bullet list. Also, if there are no
    instructions in the provided text, the model should inform us about that. Here
    are the steps:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，例如，我们希望我们的模型从文本中提取任何类型的指令，并以项目符号列表的形式返回教程。此外，如果提供的文本中没有指令，模型应通知我们。以下是步骤：
- en: 'First, we need to initialize our model. For this purpose, we are going to leverage
    OpenAI’s GPT-3.5-turbo model. We first install the `openai` library:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要初始化我们的模型。为此，我们将利用OpenAI的GPT-3.5-turbo模型。我们首先安装`openai`库：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To initialize the model, I used the `openai` Python library and set the OpenAI
    API key as the environmental variable:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要初始化模型，我使用了`openai` Python库，并将OpenAI API密钥设置为环境变量：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, the chat model comes with two variables placeholders: `system
    message` (or metaprompt), where we define how we want our model to behave, and
    `instructions` (or query), where the user will ask the model its questions.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，聊天模型包含两个变量占位符：`system message`（或元提示），其中我们定义了模型应该如何表现，以及`instructions`（或查询），用户将向模型提问。
- en: 'Then, it takes the user’s query (in this case, the text instructions). For
    this scenario, I set the two variables `system_message` and `instructions` as
    follows:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它接受用户的查询（在这种情况下，文本指令）。对于这个场景，我将两个变量`system_message`和`instructions`设置如下：
- en: '[PRE2]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let’s test our model:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们测试我们的模型：
- en: '[PRE3]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We get the following output:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下输出：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that if we pass the model another text that does not contain any instructions,
    it will be able to respond as we instructed it:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，如果我们向模型传递不包含任何指令的另一个文本，它将能够按照我们的指示回答：
- en: '[PRE5]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following is the corresponding output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对应的输出：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By giving clear instructions, you can help the model understand what you want
    it to do and how you want it to do it. This can improve the quality and relevance
    of the model’s output and reduce the need for further revisions or corrections.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过给出清晰的指令，你可以帮助模型理解你想要它做什么以及你想要它如何做。这可以提高模型输出的质量和相关性，并减少进一步修订或校正的需求。
- en: However, sometimes, there are scenarios where clarity is not enough. We might
    need to infer the way of thinking of our LLM to make it more robust with respect
    to its task. In the next section, we are going to examine one of these techniques,
    which will be very useful in the case of accomplishing complex tasks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时，清晰度不足以解决问题。我们可能需要推断我们的LLM的思维方式，使其在任务上更加稳健。在下一节中，我们将检查这些技术之一，这在完成复杂任务时将非常有用。
- en: Split complex tasks into subtasks
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将复杂任务分解为子任务
- en: As discussed earlier, prompt engineering is a technique that involves designing
    effective inputs for LLMs to perform various tasks. Sometimes, the tasks are too
    complex or ambiguous for a single prompt to handle, and it is better to split
    them into simpler subtasks that can be solved by different prompts.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，提示工程是一种技术，涉及为LLM设计有效的输入以执行各种任务。有时，任务过于复杂或含糊不清，以至于单个提示无法处理，最好将它们分解为更简单的子任务，这些子任务可以通过不同的提示来解决。
- en: 'Here are some examples of splitting complex tasks into subtasks:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些将复杂任务分解为子任务的示例：
- en: '**Text summarization:** A complex task that involves generating a concise and
    accurate summary of a long text. This task can be split into subtasks such as:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本摘要**：这是一个复杂的任务，涉及生成长文本的简洁和准确的摘要。这个任务可以分解为以下子任务：'
- en: Extracting the main points or keywords from the text
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中提取主要观点或关键词
- en: Rewriting the main points or keywords in a coherent and fluent way
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以连贯和流畅的方式重写主要观点或关键词
- en: Trimming the summary to fit a desired length or format
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将摘要裁剪到期望的长度或格式
- en: '**Machine translation:** A complex task that involves translating a text from
    one language to another. This task can be split into subtasks such as:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器翻译**：这是一个复杂的任务，涉及将文本从一种语言翻译成另一种语言。这个任务可以分解为以下子任务：'
- en: Detecting the source language of the text
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别文本的源语言
- en: Converting the text into an intermediate representation that preserves the meaning
    and structure of the original text
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本转换为中间表示，以保留原始文本的意义和结构
- en: Generating the text in the target language from the intermediate representation
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从中间表示生成目标语言的文本
- en: '**Poem generation**: A creative task that involves producing a poem that follows
    a certain style, theme, or mood. This task can be split into subtasks such as:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**诗歌生成**：一项涉及创作遵循特定风格、主题或情绪的诗歌的创造性任务。这项任务可以分解为以下子任务：'
- en: Choosing a poetic form (such as sonnet, haiku, limerick, etc.) and a rhyme scheme
    (such as ABAB, AABB, ABCB, etc.) for the poem
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为诗歌选择一种诗歌形式（如十四行诗、俳句、五言绝句等）和韵律模式（如 ABAB、AABB、ABCB 等）
- en: Generating a title and a topic for the poem based on the user’s input or preference
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户的输入或偏好为诗歌生成标题和主题
- en: Generating the lines or verses of the poem that match the chosen form, rhyme
    scheme, and topic
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成符合所选形式、韵律模式和主题的诗句或诗节
- en: Refining and polishing the poem to ensure coherence, fluency, and originality
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精炼和润色诗歌，以确保连贯性、流畅性和原创性
- en: '**Code generation**: A technical task that involves producing a code snippet
    that performs a specific function or task. This task can be split into subtasks
    such as:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：一项涉及生成执行特定功能或任务的代码片段的技术性任务。这项任务可以分解为以下子任务：'
- en: Choosing a programming language (such as Python, Java, C++, etc.) and a framework
    or library (such as TensorFlow, PyTorch, React, etc.) for the code
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一种编程语言（如 Python、Java、C++ 等）以及一个框架或库（如 TensorFlow、PyTorch、React 等）
- en: Generating a function name and a list of parameters and return values for the
    code based on the user’s input or specification
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户的输入或规格为代码生成函数名、参数列表和返回值
- en: Generating the body of the function that implements the logic and functionality
    of the code
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成实现代码逻辑和功能的函数体
- en: Adding comments and documentation to explain the code and its usage
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加注释和文档来解释代码及其用法
- en: 'Let’s consider the following example in Python, where we will ask our model
    to generate a summary of an article:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下 Python 中的示例，我们将要求我们的模型生成一篇文章的摘要：
- en: 'We will leverage OpenAI’s GPT-3.5-turbo model in a manner similar to the example
    discussed earlier in this chapter:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将类似于本章前面讨论的示例，利用 OpenAI 的 GPT-3.5-turbo 模型：
- en: '[PRE7]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s set both the `system_message` and `article` variables as follows (you
    can find the entire scripts in the book’s GitHub repository):'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将 `system_message` 和 `article` 变量设置如下（你可以在书的 GitHub 仓库中找到完整的脚本）：
- en: '[PRE8]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To see the output, you can run the following code:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看输出，你可以运行以下代码：
- en: '[PRE9]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here is the obtained output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是获得的结果：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, the model was able to produce a high-quality summary based on
    the key topics extracted (and displayed) from the given article. The fact that
    we prompted the model to split the task into subtasks “forced” it to reduce the
    complexity of each subtask, hence improving the quality of the final result. This
    approach can also lead to noticeable results when we deal with scenarios such
    as mathematical problems since it enhances the analytical reasoning capabilities
    of the model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，该模型能够根据从给定文章中提取（并显示）的关键主题生成高质量的摘要。我们提示模型将任务拆分为子任务“强制”它降低每个子任务的复杂性，从而提高了最终结果的质量。这种方法在处理诸如数学问题等场景时也能带来明显的效果，因为它增强了模型的推理能力。
- en: '**Note**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: In a landscape of many different LLMs, it is crucial to know that the very same
    system message may not be as efficient in all models. A system message that perfectly
    works with GPT-4 might not be as efficient when applied to Llama 2, for example.
    Therefore, it is pivotal to design the prompt in accordance with the type of LLM
    you decide to pick for your application.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多不同的 LLM 中，了解以下事实至关重要：同一个系统消息可能不是在所有模型上都同样有效。例如，与 GPT-4 完美配合的系统消息在应用于 Llama
    2 时可能效率不高。因此，根据你为应用程序选择的 LLM 类型来设计提示至关重要。
- en: Splitting complex tasks into easier subtasks is a powerful technique; nevertheless,
    it does not address one of the main risks of LLM-generated content, that is, having
    a wrong output. In the next two sections, we are going to see some techniques
    that are mainly aimed at addressing this risk.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 将复杂任务分解为更简单的子任务是一种强大的技术；然而，它并没有解决 LLM 生成内容的主要风险之一，即输出错误。在接下来的两个部分中，我们将看到一些主要旨在解决这一风险的技术。
- en: Ask for justification
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 请求证明
- en: 'LLMs are built in such a way that they predict the next token based on the
    previous ones without looking back at their generations. This might lead the model
    to output wrong content to the user, yet in a very convincing way. If the LLM-powered
    application does not provide a specific reference to that response, it might be
    hard to validate the ground truth behind it. Henceforth, specifying in the prompt
    to support the LLM’s answer with some reflections and justification could prompt
    the model to recover from its actions. Furthermore, asking for justification might
    be useful also in case of answers that are right but we simply don’t know the
    LLM’s reasoning behind it. For example, let’s say we want our LLM to solve riddles.
    To do so, we can instruct it as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLM是以这样的方式构建的，它们根据前面的标记预测下一个标记，而不回顾它们的生成。这可能会导致模型以非常令人信服的方式向用户输出错误的内容。如果LLM驱动的应用程序没有提供对该响应的具体参考，那么验证其背后的真实情况可能很困难。因此，在提示中指定用一些反思和证明来支持LLM的答案，可能会促使模型从其行为中恢复过来。此外，在答案正确但我们不知道LLM背后的推理时，请求证明也可能很有用。例如，假设我们想让我们的LLM解决谜题。为此，我们可以这样指示它：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As you can see, I’ve specified in the metaprompt to the LLM to justify its
    answer and also provide its reasoning. Let’s see how it works:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我在元提示中指定了让LLM证明其答案并提供其推理。让我们看看它是如何工作的：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following is the obtained output:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们获得的结果：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Justifications are a great tool to make your model more reliable and robust
    since they force it to “rethink” its output, as well as provide us with a view
    of how the reasoning was set to solve the problem.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 证明是使你的模型更加可靠和健壮的强大工具，因为它迫使模型“重新思考”其输出，同时也为我们提供了如何设置推理来解决问题的视角。
- en: With a similar approach, we could also intervene at different prompt levels
    to improve our LLM’s performance. For example, we might discover that the model
    is systematically tackling a mathematical problem in the wrong way; henceforth,
    we might want to suggest the right approach directly at the metaprompt level.
    Another example might be that of asking the model to generate multiple outputs
    – along with their justifications – to evaluate different reasoning techniques
    and prompt the best one in the metaprompt.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以类似的方式，我们也可以在不同的提示级别上进行干预，以改善我们LLM的性能。例如，我们可能会发现模型在系统地以错误的方式解决数学问题；因此，我们可能希望在元提示级别上直接建议正确的方法。另一个例子可能是要求模型生成多个输出——以及它们的证明——以评估不同的推理技术，并在元提示中提示最佳的一个。
- en: In the next section, we are going to focus on one of these examples, more specifically,
    the possibility of generating multiple outputs and then picking the most likely
    one.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将重点关注这些例子中的一个，更具体地说，是生成多个输出然后选择最可能的一个的可能性。
- en: Generate many outputs, then use the model to pick the best one
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成许多输出，然后使用模型选择最佳的一个
- en: As we saw in the previous section, LLMs are built in such a way that they predict
    the next token based on the previous ones without looking back at their generations.
    If this is the case, if one sampled token is the wrong one (in other words, if
    the model is unlucky), the LLM will keep generating wrong tokens and, henceforth,
    wrong content. Now, the bad news is that, unlike humans, LLMs cannot recover from
    errors on their own. This means that, if we ask them, they acknowledge the error,
    but we need to explicitly prompt them to think about that.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，LLM是以这样的方式构建的，它们根据前面的标记预测下一个标记，而不回顾它们的生成。如果这种情况发生，如果采样的标记是错误的（换句话说，如果模型运气不好），LLM将继续生成错误的标记，从而生成错误的内容。现在，坏消息是，与人类不同，LLM不能自行从错误中恢复。这意味着，如果我们要求它们，它们会承认错误，但我们需要明确提示它们去思考。
- en: 'One way to overcome this limitation is to broaden the space of probabilities
    of picking the right token. Rather than generating just one response, we can prompt
    the model to generate multiple responses, and then pick the one that is most suitable
    for the user’s query. This splits the job into two subtasks for our LLM:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 克服这种限制的一种方法是通过扩展选择正确标记的概率空间。我们不仅生成一个响应，还可以提示模型生成多个响应，然后选择最适合用户查询的那个。这把我们的LLM的工作分成两个子任务：
- en: Generating multiple responses to the user’s query
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对用户的查询生成多个响应
- en: Comparing those responses and picking the best one, according to some criteria
    we can specify in the metaprompt
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较这些响应并选择最佳的一个，根据我们可以在元提示中指定的某些标准
- en: 'Let’s see an example, following up from the riddles examined in the previous
    section:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个例子，继续探讨上一节中讨论的谜题：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In this case, I’ve prompted the model to generate three answers to the riddle,
    then to give me the most likely, justifying why. Let’s see the result:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我提示模型生成三个谜题的答案，然后给我最可能的答案，并说明理由。让我们看看结果：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We then get the following output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后得到以下输出：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, the model selected the most plausible answer along with a justification
    of its choice. It is interesting to note that “clock” and “watch” might seem similar
    responses; however, the model specified that “watch” is usually worn on a person’s
    wrist and, even though it doesn’t mean it has arms or legs, this element might
    have lowered the probability of being the correct answer.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型选择了最可能的答案，并对其选择进行了说明。值得注意的是，“时钟”和“手表”可能看起来是相似的回答；然而，模型明确指出“手表”通常戴在人的手腕上，尽管这并不意味着它有手臂或腿，但这个元素可能降低了它是正确答案的概率。
- en: What would you have picked?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你会选择什么？
- en: As discussed earlier, forcing the model to tackle a problem with different approaches
    is a way to collect multiple samples of reasonings, which might serve as further
    instructions in the metaprompt. For example, if we want the model to always propose
    something that is not the most straightforward solution to a problem – in other
    words, if we want it to “think differently” – we might force it to solve a problem
    in N ways and then use the most creative reasoning as a framework in the metaprompt.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，迫使模型以不同的方法处理问题是一种收集多个推理样本的方法，这些样本可能作为元提示中的进一步指令。例如，如果我们想让模型始终提出不是问题最直接解决方案的东西——换句话说，如果我们想让它“思考不同”的话——我们可能迫使它以N种方式解决问题，然后使用最富有创意的推理作为元提示的框架。
- en: The last element we are going to examine is the overall structure we want to
    give to our metaprompt. In fact, in previous examples, we saw a sample system
    message with some statements and instructions. In the next section, we will see
    how the order and “strength” of those statements and instructions are not invariants.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要检查的最后一个元素是我们想要给予我们的元提示的整体结构。实际上，在之前的例子中，我们看到了一个包含一些声明和指令的示例系统消息。在下一节中，我们将看到那些声明和指令的顺序和“强度”并不是不变的。
- en: Repeat instructions at the end
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在末尾重复指令
- en: LLMs tend not to process the metaprompt attributing the same weight or imprortance
    to all the sections. In fact, in his blog post *Large Language Model Prompt Engineering
    for Complex Summarization*, John Stewart (a software engineer at Microsoft) found
    some interesting outcomes from arranging prompt sections ([https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/)).
    More specifically, after several experimentations, he found that repeating the
    main instruction at the end of the prompt can help the model overcome its inner
    **recency bias**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs往往不会以相同的权重或重要性处理元提示的所有部分。实际上，在John Stewart（微软的一名软件工程师）的博客文章《大型语言模型复杂摘要的提示工程》中，他发现了一些有趣的成果，这些成果来自于对提示部分的排列（[https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/))。更具体地说，经过几次实验，他发现重复提示末尾的主要指令可以帮助模型克服其内在的**近期偏差**。
- en: '**Definition**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Recency bias is the tendency of LLMs to give more weight to the information
    that appears near the end of a prompt, and ignore or forget the information that
    appears earlier. This can lead to inaccurate or inconsistent responses that do
    not take into account the whole context of the task. For example, if the prompt
    is a long conversation between two people, the model may only focus on the last
    few messages and disregard the previous ones.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 近期偏差是指大型语言模型（LLMs）倾向于给予靠近提示末尾的信息更多权重，而忽略或忘记之前出现的信息。这可能导致不准确或不一致的响应，没有考虑到整个任务的上下文。例如，如果提示是两个人之间的长对话，模型可能只会关注最后几条消息，而忽略之前的消息。
- en: 'Let’s look at some ways to overcome recency bias:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些克服近期偏差的方法：
- en: One possible way to overcome recency bias is to break down the task into smaller
    steps or subtasks and provide feedback or guidance along the way. This can help
    the model focus on each step and avoid getting lost in irrelevant details. We’ve
    covered this technique in the *Split complex tasks into subtasks* section in,
    which we discussed splitting complex tasks into easier subtasks.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种克服近期偏差的可能方法是将任务分解成更小的步骤或子任务，并在过程中提供反馈或指导。这可以帮助模型专注于每个步骤，避免陷入无关紧要的细节。我们在“将复杂任务分解为子任务”部分讨论了这项技术。
- en: Another way to overcome recency bias with prompt engineering techniques is to
    repeat the instructions or the main goal of the task at the end of the prompt.
    This can help remind the model of what it is supposed to do and what kind of response
    it should generate.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种使用提示工程技术克服近期偏差的方法是在提示的末尾重复指令或任务的主要目标。这可以帮助提醒模型它应该做什么以及它应该生成什么样的响应。
- en: For instance, let’s say we want our model to output the sentiment of a whole
    chat history between an AI agent and the user. We want to make sure that the model
    will output the sentiment in lowercase and without punctuation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想让我们的模型输出AI代理和用户之间整个聊天历史的情感。我们想确保模型将输出小写字母且不带标点的情感。
- en: 'Let’s consider the following example (the conversation is truncated, but you
    can find the whole code in the book’s GitHub repository). In this case, the key
    instruction is that of having as output only the sentiment in lowercase and without
    punctuation:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下示例（对话被截断，但您可以在书籍的GitHub仓库中找到完整的代码）。在这种情况下，关键指令是只输出小写字母且不带标点的情感：
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In this scenario, we have key instructions before the conversation, so let’s
    initialize our model and feed it with the two variables `system_message` and `conversation`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，我们在对话之前有关键指令，所以让我们初始化我们的模型，并用两个变量`system_message`和`conversation`给它提供数据：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here is the output that we receive:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们收到的输出：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The model didn’t follow the instruction of having only lowercase letters. Let’s
    try to repeat the instruction also at the end of the prompt:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 模型没有遵循只输出小写字母的指令。让我们尝试在提示的末尾也重复这个指令：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Again, let’s invoke our model with the updated `system_message`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们用更新的`system_message`调用我们的模型：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here is the corresponding output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的输出：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, now the model was able to provide exactly the output we desired.
    This approach is particularly useful whenever we have a conversation history to
    keep storing in the context window. If this is the case, having the main instructions
    at the beginning might induce the model not to have them in mind once it also
    goes through the whole history, hence reducing their strength.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，现在模型能够提供我们想要的精确输出。这种方法特别有用，当我们有需要持续存储在上下文窗口中的对话历史时。如果这种情况发生，将主要指令放在开头可能会让模型在经过整个历史后不再考虑这些指令，从而减弱它们的影响力。
- en: Use delimiters
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用分隔符
- en: The last principle to be covered is related to the format we want to give to
    our metaprompt. This helps our LLM to better understand its intents as well as
    relate different sections and paragraphs to each other.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要讨论的最后一个原则与我们想要给我们的元提示的格式有关。这有助于我们的LLM更好地理解其意图，以及将不同的部分和段落联系起来。
- en: 'To achieve this, we can use delimiters within our prompt. A delimiter can be
    any sequence of characters or symbols that is clearly mapping a schema rather
    than a concept. For example, we can consider the following sequences to be delimiters:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一点，我们可以在提示中使用分隔符。分隔符可以是任何字符或符号的序列，它清楚地映射一个模式而不是一个概念。例如，我们可以考虑以下序列作为分隔符：
- en: '`>>>>`'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '>>>'
- en: '`====`'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ====
- en: '`------`'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '------'
- en: '`####`'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '####'
- en: '`` ` ` ` ` ` ``'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '```'
- en: 'This leads to a series of benefits, including:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了一系列好处，包括：
- en: 'Clear separation: Delimiters mark distinct sections within a prompt, separating
    instructions, examples, and desired output.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰的分离：分隔符在提示中标记不同的部分，分隔指令、示例和期望的输出。
- en: 'Guidance for LLMs: Proper use of delimiters removes ambiguity, guiding the
    model effectively.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM的指导：正确使用分隔符可以消除歧义，有效地引导模型。
- en: 'Enhanced precision: Delimiters improve prompt understanding, resulting in more
    relevant responses.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高精确度：分隔符提高了提示理解，导致更相关的响应。
- en: 'Improved coherence: Effective use of delimiters organizes instructions, inputs,
    and outputs, leading to coherent responses.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高连贯性：有效使用分隔符组织指令、输入和输出，导致连贯的响应。
- en: 'Let’s consider, for example, a metaprompt that aims at instructing the model
    to translate user’s tasks into Python code, providing an example to do so:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个旨在指导模型将用户的任务翻译成Python代码的元提示为例，提供一个这样的例子：
- en: '[PRE23]def my_print(text):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE23]def my_print(text):'
- en: return print(text)
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return print(text)
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the above example, we’ve used delimiters to both specify the beginning and
    end of an example for a one-shot learning approach and, within the example, specify
    the Python code snippet.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，我们使用了分隔符来指定一个用于单次学习方法的示例的开始和结束，并在示例内部指定Python代码片段。
- en: 'Let’s see how it works:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here is our output:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的输出：
- en: '[PRE26]python def fibonacci(n):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE26]python def fibonacci(n):'
- en: 'if n < 0:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'if n < 0:'
- en: return None
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: return None
- en: 'elif n == 0:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif n == 0:'
- en: return 0
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: return 0
- en: 'elif n == 1:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif n == 1:'
- en: return 1
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: return 1
- en: 'else:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: return fibonacci(n-1) + fibonacci(n-2) [PRE27]
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: return fibonacci(n-1) + fibonacci(n-2) [PRE27]
- en: As you can see, it also printed the code with backticks, as shown within the
    system message.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，它还打印了带有反引号的代码，正如系统消息中所示。
- en: All the principles examined up to this point are general rules that can make
    your LLM-powered application more robust. Those techniques should be kept in mind
    regardless of the type of application you are developing since they are general
    best practices that improve your LLM performance. In the following section, we
    are going to see some advanced techniques for prompt engineering.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止检查的所有原则都是可以让你用LLM驱动的应用更健壮的一般规则。无论你正在开发什么类型的应用，都应该记住这些技术，因为它们是通用的最佳实践，可以提高你的LLM性能。在接下来的章节中，我们将看到一些高级的提示工程技术。
- en: Advanced techniques
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级技术
- en: Advanced techniques might be implemented for specific scenarios and address
    the way the model reasons and thinks about the answer before providing it to the
    final user. Let’s look at some of these in the upcoming sections.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 高级技术可能针对特定场景实现，并解决模型在向最终用户提供答案之前如何推理和思考的问题。让我们在接下来的章节中看看其中的一些。
- en: Few-shot approach
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少样本方法
- en: In their paper *Language Models are Few-Shot Learners*, Tom Brown et al. demonstrate
    that GPT-3 can achieve strong performance on many NLP tasks in a few-shot setting.
    This means that for all tasks, GPT-3 is applied without any fine-tuning, with
    tasks and few-shot demonstrations specified purely via text interaction with the
    model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文《语言模型是少样本学习者》中，Tom Brown等人证明了GPT-3在少样本设置下可以在许多NLP任务上取得良好的性能。这意味着对于所有任务，GPT-3都是未经任何微调应用的，任务和少样本演示完全通过与模型的文本交互来指定。
- en: This is an example and evidence of how the concept of few-shot learning – which
    means providing the model with examples of how we would like it to respond – is
    a powerful technique that enables model customization without interfering with
    the overall architecture.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个例子和证据，说明了少样本学习概念——即向模型提供我们希望它如何响应的示例——是一种强大的技术，它可以在不干扰整体架构的情况下实现模型定制。
- en: For example, let’s say we want our model to generate a tagline for a new product
    line of climbing shoes we’ve just coined – Elevation Embrace. We have an idea
    of what the tagline should be like – concise and direct. We could explain it to
    the model in plain text; however, it might be more effective simply to provide
    it with some examples of similar projects.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们希望我们的模型为刚刚命名的攀岩鞋新系列——Elevation Embrace——生成一个标语。我们有一个关于标语应该是什么样的想法——简洁直接。我们可以用纯文本向模型解释它；然而，简单地提供一些类似项目的示例可能更有效。
- en: 'Let’s see an implementation with code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个带有代码的实现：
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s see how our model will handle this request:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的模型将如何处理这个请求：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following is our output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的是我们的输出：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As you can see, it maintained the style, length, and also writing convention
    of the provided taglines. This is extremely useful when you want your model to
    follow examples you already have, such as fixed templates.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，它保持了提供的标语的风格、长度和书写规范。当您希望模型遵循您已有的示例时，例如固定模板，这非常有用。
- en: Note that, most of the time, few-shot learning is powerful enough to customize
    a model even in extremely specialized scenarios, where we could think about fine-tuning
    as the proper tool. In fact, proper few-shot learning could be as effective as
    a fine-tuning process.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，大多数情况下，少样本学习足够强大，甚至可以在极端专业化的场景中定制模型，在这种情况下，我们可以将微调视为适当的工具。事实上，适当的少样本学习可能和微调过程一样有效。
- en: Let’s look at another example. Let’s say we want to develop a model that specializes
    in sentiment analysis. To do so, we provide it with a series of examples of texts
    with different sentiments, alongside the output we would like – positive or negative.
    Note that this set of examples is nothing but a small training set for supervised
    learning tasks; the only difference from fine-tuning is that we are not updating
    the model’s parameters.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个例子。假设我们想要开发一个专注于情感分析的模型。为此，我们向它提供了一系列具有不同情感的文本示例，以及我们希望得到的输出——正面或负面。请注意，这组示例只是监督学习任务的小型训练集；与微调的唯一区别是我们没有更新模型的参数。
- en: 'To provide you with a concrete representation of what was said above, let’s
    provide our model with just two examples for each label:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向您提供一个上述内容的具体表示，让我们为每个标签提供我们的模型仅两个示例：
- en: '[PRE31]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To test our classifier, I’ve used the IMDb database of movie reviews available
    on Kaggle at [https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data).
    As you can see, the dataset contains many movie reviews along with their associated
    sentiment – positive or negative. Let’s substitute the binary label of 0–1 with
    a verbose label of Negative–Positive:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的分类器，我使用了Kaggle上可用的IMDb电影评论数据库[https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data)。如您所见，该数据集包含许多电影评论及其相关的情感——正面或负面。让我们将0-1的二进制标签替换为详尽的标签“负面-正面”：
- en: '[PRE32]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This gives us the first few records of the dataset, which are as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了数据集的前几个记录，如下所示：
- en: '![](img/B21714_04_02.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21714_04_02.png)'
- en: 'Figure 4.2: First observations of the movie dataset'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：电影数据集的第一观察结果
- en: 'Now, we want to test the performance of our model over a sample of 10 observations
    of this dataset:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要测试我们的模型在数据集的10个样本上的性能：
- en: '[PRE33]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following is our output:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们输出的内容：
- en: '![A text on a white background  Description automatically generated](img/B21714_04_03.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![白色背景上的文本  自动生成的描述](img/B21714_04_03.png)'
- en: 'Figure 4.3: Output of a GPT-3.5 model with few-shot examples'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：具有少样本示例的GPT-3.5模型的输出
- en: As you can see, by comparing the `label` and `predicted` columns, the model
    was able to correctly classify all the reviews, without even fine-tuning! This
    is just an example of what you can achieve – in terms of model specialization
    – with the technique of few-shot learning.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，通过比较`标签`和`预测`列，模型能够正确地分类所有评论，甚至没有进行微调！这只是您可以使用少样本学习技术实现的一个例子——在模型专业化方面。
- en: Chain of thought
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链
- en: Introduced in the paper *Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models* by Wei et al., **chain of thought** (**CoT**) is a technique
    that enables complex reasoning capabilities through intermediate reasoning steps.
    It also encourages the model to explain its reasoning, “forcing” it not to be
    too fast and risking giving the wrong response (as we saw in previous sections).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在Wei等人撰写的论文《思维链提示激发大型语言模型中的推理》中引入的**思维链**（**CoT**）是一种通过中间推理步骤实现复杂推理能力的技巧。它还鼓励模型解释其推理，“迫使”它不要过于迅速，以免给出错误的响应（如我们在前面的章节中看到的）。
- en: 'Let’s say that we want to prompt our LLM to solve generic first-degree equations.
    To do so, we are going to provide it with a basic reasoning list that it might
    want to follow:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要提示我们的语言模型（LLM）解决通用的一阶方程。为此，我们将提供给它一个基本的推理列表，它可能想要遵循：
- en: '[PRE34]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s see how it can be implemented:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何实现的：
- en: '[PRE35]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following is our output:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们输出的内容：
- en: '[PRE36]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: As you can see, the model clearly followed the seven steps specified in the
    metaprompt, which also allows the model to “take its time” to perform this task.
    Note that you can also combine it with few-shot prompting to get better results
    on more complex tasks that require reasoning before responding.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型清楚地遵循了元提示中指定的七个步骤，这也允许模型“慢慢来”完成这项任务。请注意，您还可以将其与少样本提示结合使用，以在需要推理才能回答的更复杂任务上获得更好的结果。
- en: With CoT, we are prompting the model to generate intermediate reasoning steps.
    This is also a component of another reasoning technique, which we are going to
    examine in the next section.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CoT（思维链），我们正在提示模型生成中间推理步骤。这也是另一种推理技术的组成部分，我们将在下一节中对其进行探讨。
- en: ReAct
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct
- en: 'Introduced in the paper *ReAct: Synergizing Reasoning and Acting in Language
    Models* by Yao et al., **ReAct** (**Reason and Act**) is a general paradigm that
    combines reasoning and acting with LLMs. ReAct prompts the language model to generate
    verbal reasoning traces and actions for a task, and also receives observations
    from external sources such as web searches or databases. This allows the language
    model to perform dynamic reasoning and quickly adapt its action plan based on
    external information. For example, you can prompt the language model to answer
    a question by first reasoning about the question, then performing an action to
    send a query to the web, then receiving an observation from the search results,
    and then continuing with this thought, action, observation loop until it reaches
    a conclusion.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在姚等人发表的论文《ReAct：在语言模型中协同推理和动作》中引入的**ReAct**（**推理和动作**）是一个将推理和动作与LLM结合的通用范式。ReAct促使语言模型为任务生成口头推理轨迹和动作，并从外部来源（如网络搜索或数据库）接收观察结果。这使得语言模型能够执行动态推理，并根据外部信息快速调整其行动计划。例如，你可以提示语言模型首先对问题进行推理，然后执行动作向网络发送查询，然后从搜索结果中接收观察结果，然后继续这个思考、动作、观察循环，直到得出结论。
- en: The difference between CoT and ReAct approaches is that CoT prompts the language
    model to generate intermediate reasoning steps for a task, while ReAct prompts
    the language model to generate intermediate reasoning steps, actions, and observations
    for a task.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: CoT和ReAct方法之间的区别在于，CoT提示语言模型为任务生成中间推理步骤，而ReAct提示语言模型为任务生成中间推理步骤、动作和观察结果。
- en: Note that the “action” phase is generally related to the possibility for our
    LLM to interact with external tools, such as a web search.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，“动作”阶段通常与我们的语言模型（LLM）与外部工具（如网络搜索）交互的可能性相关。
- en: 'For example, let’s say we want to ask our model for some up-to-date information
    about the upcoming Olympic games. To do so, we are going to build a smart LangChain
    agent (as described in *Chapter 2*) leveraging `SerpAPIWrapperWrapper` (to wrap
    the `SerpApi` to navigate the web), the `AgentType` tool (to decide which type
    of agent to use for our goal), and other prompt-related modules (to make it easier
    to “templatize” our instructions). Let’s see how we can do this (I won’t dive
    deeper into each component of the following code since the next chapter will be
    entirely focused on LangChain and its main components):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要询问模型有关即将到来的奥运会的一些最新信息。为此，我们将构建一个智能LangChain代理（如第2章所述），利用`SerpAPIWrapperWrapper`（将`SerpApi`包装以导航网络）、`AgentType`工具（决定为我们目标使用哪种类型的代理）和其他与提示相关的模块（使其更容易“模板化”我们的指令）。让我们看看我们如何做到这一点（由于下一章将完全专注于LangChain及其主要组件，因此我不会深入探讨以下代码的每个组件）：
- en: '[PRE37]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'As you can see, for this purpose, I’ve used a pre-built agent type available
    in LangChain called `ZERO_SHOT_REACT_DESCRIPTION`. It comes with a precompiled
    prompt that follows the ReAct approach. Let’s inspect that prompt:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，为此，我使用了LangChain中可用的预构建代理类型`ZERO_SHOT_REACT_DESCRIPTION`。它附带了一个遵循ReAct方法的预编译提示。让我们检查一下这个提示：
- en: '[PRE38]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here is the corresponding output:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的输出：
- en: '[PRE39]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let’s now test our agent by asking something about the upcoming Olympic games
    and zooming in on the intermediate steps:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过询问有关即将到来的奥运会的问题并聚焦于中间步骤来测试我们的代理：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This is the output with intermediate steps:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这是包含中间步骤的输出：
- en: '[PRE41]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here is the obtained output:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是获得的输出：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: At the time of this question (7th of October 2023), the answer is definitely
    correct. Note how the model went through several iterations of `Observation`/`Thought`/`Action`
    until it reached the conclusion. This is a great example of how prompting a model
    to think step by step and explicitly define each step of the reasoning makes it
    “wiser” and more cautious before answering. It is also a great technique to prevent
    hallucination.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在提问时（2023年10月7日），答案无疑是正确的。注意模型如何经过几次“观察”/“思考”/“动作”的迭代，直到得出结论。这是一个很好的例子，说明通过提示模型逐步思考和明确定义推理的每一步，可以使它在回答之前变得更加“聪明”和谨慎。这同样是一种防止幻觉的绝佳技术。
- en: Overall, prompt engineering is a powerful discipline, still in its emerging
    phase yet already widely adopted within LLM-powered applications. In the following
    chapters, we are going to see concrete applications of this technique.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，提示工程是一门强大的学科，尽管它仍处于起步阶段，但已经在LLM驱动的应用中得到广泛应用。在接下来的章节中，我们将看到这一技术的具体应用。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered many aspects of the activity of prompt engineering,
    a core step in the context of improving the performance of LLMs within your application,
    as well as customizing it depending on the scenario. Prompt engineering is an
    emerging discipline that is paving the way for a new category of applications,
    infused with LLMs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了提示工程活动的许多方面，这是在应用中提高LLM性能的核心步骤，以及根据场景进行定制。提示工程是一个新兴学科，为注入LLM的新类别应用铺平了道路。
- en: 'We started with an introduction to the concept of prompt engineering and why
    it is important, and then moved toward the basic principles – including clear
    instructions, asking for justification, etc. Then, we moved on to more advanced
    techniques that are meant to shape the reasoning approach of our LLM: few-shot
    learning, CoT, and ReAct.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从介绍提示工程的概念及其重要性开始，然后转向基本原理——包括清晰的指令、要求证明等。然后，我们转向更高级的技术，旨在塑造我们大型语言模型（LLM）的推理方法：少样本学习、CoT和ReAct。
- en: In the next chapters, we will see those techniques in action by building real-world
    applications using LLMs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将通过使用LLM构建实际应用来展示这些技术的实际应用。
- en: References
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'ReAct approach: [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReAct方法：[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
- en: 'What is prompt engineering?: [https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提示工程？[https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering)
- en: 'Prompt engineering techniques: [https://blog.mrsharm.com/prompt-engineering-guide/](https://blog.mrsharm.com/prompt-engineering-guide/)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程技术：[https://blog.mrsharm.com/prompt-engineering-guide/](https://blog.mrsharm.com/prompt-engineering-guide/)
- en: 'Prompt engineering principles: [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程原则：[https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions)
- en: 'Recency bias: [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近期偏差：[https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end)
- en: 'Large Language Model Prompt Engineering for Complex Summarization: [https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂摘要的大语言模型提示工程：[https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/)
- en: 'Language Models are Few-Shot Learners: [https://arxiv.org/pdf/2005.14165.pdf](https://arxiv.org/pdf/2005.14165.pdf)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型是少样本学习者：[https://arxiv.org/pdf/2005.14165.pdf](https://arxiv.org/pdf/2005.14165.pdf)
- en: 'IMDb dataset: [https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IMDb数据集：[https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code)
- en: 'ReAct: [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReAct：[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
- en: 'Chain of Thought Prompting Elicits Reasoning in Large Language Models: [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903
    )'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维链提示在大型语言模型中引发推理：[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
- en: Join our community on Discord
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/llm](https://packt.link/llm )'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/llm](https://packt.link/llm)'
- en: '![](img/QR_Code214329708533108046.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code214329708533108046.png)'
