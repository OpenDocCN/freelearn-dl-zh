- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Taking TensorFlow to Production
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将TensorFlow应用到生产环境
- en: 'Throughout this book, we have seen that TensorFlow is capable of implementing
    many models, but there is more that TensorFlow can do. This chapter will show
    you a few of those things. In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们已经看到TensorFlow能够实现许多模型，但TensorFlow能做的远不止这些。本章将向你展示其中的一些内容。在本章中，我们将涵盖以下主题：
- en: Visualizing graphs in TensorBoard
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在TensorBoard中可视化图表
- en: Managing hyperparameter tuning with TensorBoard's HParams
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorBoard的HParams进行超参数调优
- en: Implementing unit tests using tf.test
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用tf.test实现单元测试
- en: Using multiple executors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多个执行器
- en: Parallelizing TensorFlow using tf.distribute.strategy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用tf.distribute.strategy进行TensorFlow并行化
- en: Saving and restoring a TensorFlow model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存和恢复TensorFlow模型
- en: Using TensorFlow Serving
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow Serving
- en: We'll start by showing how to use the various aspects of TensorBoard, a capability
    that comes with TensorFlow. This tool allows us to visualize summary metrics,
    graphs, and images even while our model is training. Next, we will show you how
    to write code that is ready for production use with a focus on unit tests, training
    distribution across multiple processing units, and efficient model saving and
    loading. Finally, we will address a machine learning serving solution by hosting
    a model as REST endpoints.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先展示如何使用TensorBoard的各个方面，TensorBoard是TensorFlow自带的一个功能。这个工具允许我们即使在模型训练过程中，也能可视化总结指标、图表和图像。接下来，我们将展示如何编写适用于生产环境的代码，重点是单元测试、多处理单元的训练分配，以及高效的模型保存和加载。最后，我们将通过将模型托管为REST端点，解决机器学习服务方案。
- en: Visualizing Graphs in TensorBoard
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在TensorBoard中可视化图表
- en: Monitoring and troubleshooting machine learning algorithms can be a daunting
    task, especially if you have to wait a long time for the training to complete
    before you know the results. To work around this, TensorFlow includes a computational
    graph visualization tool called **TensorBoard**. With TensorBoard, we can visualize
    graphs and important values (loss, accuracy, batch training time, and so on) even
    during training.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 监控和排查机器学习算法可能是一项艰巨的任务，尤其是在你必须等待训练完成后才能知道结果的情况下。为了应对这种情况，TensorFlow提供了一个计算图可视化工具，称为**TensorBoard**。借助TensorBoard，我们可以在训练过程中可视化图表和重要数值（如损失、准确率、批次训练时间等）。
- en: Getting ready
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To illustrate the various ways we can use TensorBoard, we will reimplement the
    MNIST model from *The Introductory CNN Model* recipe in *Chapter 8*, *Convolutional
    Neural Networks*. Then, we'll add the TensorBoard callback and fit the model.
    We will show how to monitor numerical values, histograms of sets of values, how
    to create an image in TensorBoard, and how to visualize TensorFlow models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们如何使用TensorBoard的各种方式，我们将重新实现*第8章*中*卷积神经网络*章节里的*入门CNN模型*配方中的MNIST模型。然后，我们将添加TensorBoard回调并拟合模型。我们将展示如何监控数值、值集的直方图，如何在TensorBoard中创建图像，以及如何可视化TensorFlow模型。
- en: How to do it...
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'First, we''ll load the libraries necessary for the script:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将加载脚本所需的库：
- en: '[PRE0]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We''ll now reimplement the MNIST model:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将重新实现MNIST模型：
- en: '[PRE1]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we will compile the model with the sparse categorical cross-entropy loss
    and the Adam optimizer. Then, we''ll display the summary:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用稀疏类别交叉熵损失和Adam优化器编译模型。然后，我们将展示总结：
- en: '[PRE2]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will create a timestamped subdirectory for each run. The summary writer
    will write the `TensorBoard` logs to this folder:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为每次运行创建一个带时间戳的子目录。总结写入器将把`TensorBoard`日志写入这个文件夹：
- en: '[PRE3]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we will instantiate a `TensorBoard` callback and pass it to the `fit`
    method. All logs during the training phase will be stored in this directory and
    can be viewed instantly in `TensorBoard`:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将实例化一个`TensorBoard`回调并将其传递给`fit`方法。训练阶段的所有日志将存储在此目录中，并可以立即在`TensorBoard`中查看：
- en: '[PRE4]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then start the `TensorBoard` application by running the following command:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们通过运行以下命令启动`TensorBoard`应用程序：
- en: '[PRE5]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then we navigate in our browser to the following link: `http://127.0.0.0:6006`.
    We can specify a different port if needed by passing, for example, a `--port 6007`
    command (for running on port 6007). We can also start TensorBoard within the notebook
    through the `%tensorboard --logdir="logs"` command line. Remember that TensorBoard
    will be viewable as your program is running.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们在浏览器中导航到以下链接：`http://127.0.0.0:6006`。如果需要，我们可以通过传递`--port 6007`命令（例如，在6007端口运行）来指定不同的端口。我们还可以通过在笔记本中运行`%tensorboard
    --logdir="logs"`命令来启动TensorBoard。请记住，TensorBoard将在你的程序运行时可见。
- en: We can quickly and easily visualize and compare metrics of several experiments
    during the model training through TensorBoard's scalars view. By default, TensorBoard
    writes the metrics and losses every epoch. We can update this frequency by batch
    using the following argument: `update_freq='batch'`. We can also visualize model
    weights as images with the argument `write_images=True` or display bias and weights
    with histograms (computing every epoch) using `histogram_freq=1.`
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过 TensorBoard 的标量视图快速且轻松地可视化和比较多个实验的度量。在默认情况下，TensorBoard 会在每个训练周期记录度量和损失。我们可以使用以下参数通过每个批次更新该频率：`update_freq='batch'`。我们还可以使用参数
    `write_images=True` 将模型权重可视化为图像，或者使用 `histogram_freq=1` 以直方图的形式（每个周期计算）显示偏差和权重。
- en: Here is a screenshot of the scalars view:![](img/B16254_12_01.png)
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是标量视图的截图：![](img/B16254_12_01.png)
- en: 'Figure 12.1: Training and test loss decrease over time while the training and
    test accuracy increase'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 12.1：训练和测试损失随着时间推移而减少，而训练和测试准确度则增加
- en: Here, we show how to visualize weights and bias with a histogram summary. With
    this dashboard, we can plot many histogram visualizations of all the values of
    a non-scalar tensor (such as weights and bias) at different points in time. So,
    we can see how the values have changed over time:![](img/B16254_12_02.png)
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里，我们展示如何通过直方图摘要可视化权重和偏差。通过此仪表板，我们可以绘制非标量张量（如权重和偏差）在不同时间点的多个直方图可视化。这样，我们就能看到这些值是如何随时间变化的：![](img/B16254_12_02.png)
- en: 'Figure 12.2: The Histograms view to visualize weights and bias in TensorBoard'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 12.2：在 TensorBoard 中通过直方图视图可视化权重和偏差
- en: Now, we will visualize the TensorFlow model through TensorFlow's Graphs dashboard,
    which shows the model using different views. This dashboard allows visualizing
    the op-level graph but also the conceptual graph. The op-level displays the Keras
    model with extra edges to other computation nodes, whereas the conceptual graph
    displays only the Keras model. These views allow quickly examining and comparing
    our intended design and understanding the TensorFlow model structure.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将通过 TensorFlow 的图形仪表板可视化 TensorFlow 模型，仪表板通过不同的视图展示模型。该仪表板不仅可以可视化操作级别的图，还可以显示概念级别的图。操作级图展示了
    Keras 模型以及指向其他计算节点的额外边缘，而概念级图仅展示 Keras 模型。这些视图可以帮助我们快速检查并比较我们的设计，并理解 TensorFlow
    模型结构。
- en: Here, we show how to visualize the op-level graph:![](img/B16254_12_03.png)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里，我们展示如何可视化操作级别的图：![](img/B16254_12_03.png)
- en: 'Figure 12.3: The op-level graph in TensorBoard'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 12.3：TensorBoard 中的操作级图
- en: 'By adding the TensorBoard callback, we can visualize the loss, the metrics,
    model weights as images, and so on. But we can also use the `tf.summary` module
    for writing summary data that can be visualized in TensorFlow. First, we have
    to create a `FileWriter` and then, we can write histogram, scalar, text, audio,
    or image summaries. Here, we''ll write images using the Image Summary API and
    visualize them in TensorBoard:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加 TensorBoard 回调，我们可以可视化损失、度量、模型权重作为图像等内容。但我们也可以使用 `tf.summary` 模块来写入可以在
    TensorFlow 中可视化的摘要数据。首先，我们需要创建一个 `FileWriter`，然后就可以写入直方图、标量、文本、音频或图像摘要。在这里，我们将使用图像摘要
    API 来写入图像，并在 TensorBoard 中进行可视化：
- en: '[PRE6]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/B16254_12_04.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16254_12_04.png)'
- en: 'Figure 12.4: Visualize images in TensorBoard'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4：在 TensorBoard 中可视化图像
- en: Be careful of writing image summaries too often to TensorBoard. For example,
    if we were to write an image summary every generation for 10,000 generations,
    that would generate 10,000 images worth of summary data. This tends to eat up
    disk space very quickly.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，不要过于频繁地将图像摘要写入 TensorBoard。例如，如果我们在 10,000 次训练中每次都写入一次图像摘要，那么将生成 10,000
    张图像的摘要数据。这会非常迅速地占用磁盘空间。
- en: How it works...
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this section, we implemented a CNN model on the MNIST dataset. We added a
    TensorBoard callback and fitted the model. Then, we used TensorFlow's visualization
    tool, which enables you to monitor numerical values and histograms of sets of
    values, to visualize the model graph, and so on.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们在 MNIST 数据集上实现了一个 CNN 模型。我们添加了 TensorBoard 回调并训练了模型。然后，我们使用 TensorFlow
    的可视化工具来监控数值和数值集合的直方图，进而可视化模型图等。
- en: Remember that we can launch TensorBoard through a command line as in the recipe
    but we can also launch it within a notebook by using the `%tensorboard` magic
    line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们可以通过命令行启动 TensorBoard，如食谱中所示，但也可以通过使用 `%tensorboard` 魔法命令在笔记本中启动它。
- en: See also
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For some references on the TensorBoard API, visit the following websites:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 TensorBoard API 的一些参考资料，请访问以下网站：
- en: 'The official TensorBoard guide: [https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方的 TensorBoard 指南：[https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started)
- en: 'The TensorFlow summary API: [https://www.tensorflow.org/api_docs/python/tf/summary](https://www.tensorflow.org/api_docs/python/tf/summary)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 摘要 API：[https://www.tensorflow.org/api_docs/python/tf/summary](https://www.tensorflow.org/api_docs/python/tf/summary)
- en: There's more...
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: TensorBoard.dev is a free managed service provided by Google. The aim is to
    easily host, track, and share machine learning experiments with anyone. After
    we launch our experiments, we just have to upload our TensorBoard logs to the
    TensorBoard server. Then, we share the link and anyone who has the link can view
    our experiments. Note not to upload sensitive data because uploaded TensorBoard
    datasets are public and visible to everyone.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard.dev 是 Google 提供的免费托管服务。其目的是轻松托管、跟踪和分享机器学习实验给任何人。在我们启动实验后，只需将 TensorBoard
    日志上传到 TensorBoard 服务器。然后，分享链接，任何拥有该链接的人都可以查看我们的实验。请注意不要上传敏感数据，因为上传的 TensorBoard
    数据集是公开的，所有人都可以看到。
- en: Managing Hyperparameter tuning with TensorBoard's HParams
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 的 HParams 管理超参数调优
- en: Tuning hyperparameters in a machine learning project can be a real pain. The
    process is iterative and can take a long time to test all the hyperparameter combinations.
    But fortunately, HParams, a TensorBoard plugin, comes to the rescue. It allows
    testing to find the best combination of hyperparameters.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目中调优超参数可能是一项真正的挑战。这个过程是迭代的，并且可能需要很长时间来测试所有的超参数组合。但幸运的是，HParams——一个 TensorBoard
    插件，来拯救我们。它允许我们通过测试找到最佳的超参数组合。
- en: Getting ready
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To illustrate how the HParams plugin works, we will use a sequential model implementation
    on the MNIST dataset. We'll configure HParams and compare several hyperparameter
    combinations in order to find the best hyperparameter optimization.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明 HParams 插件如何工作，我们将使用一个在 MNIST 数据集上的顺序模型实现。我们将配置 HParams，并比较几个超参数组合，以找到最佳的超参数优化。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, we''ll load the libraries necessary for the script:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将加载脚本所需的库：
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we''ll load and prepare the MNIST dataset:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将加载并准备 MNIST 数据集：
- en: '[PRE8]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, for each hyperparameter, we''ll define the list or the interval of values
    to test. In this section, we''ll go over three hyperparameters: the number of
    units per layer, the dropout rate, and the optimizer:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，对于每个超参数，我们将定义要测试的值列表或区间。在这一部分，我们将介绍三个超参数：每层单元数、Dropout 率和优化器：
- en: '[PRE9]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The model will be a sequential model with five layers: a flatten layer, followed
    by a dense layer, a dropout layer, another dense layer, and the output layer with
    10 units. The train function takes as an argument the HParams dictionary that
    contains a combination of hyperparameters. As we use a Keras model, we add an
    HParams Keras callback on the fit method to monitor each experiment. For each
    experiment, the plugin will log the hyperparameter combinations, losses, and metrics.
    We can add a summary File Writer if we want to monitor other information:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型将是一个顺序模型，包含五层：一个展平层，接着是一个全连接层，一个 Dropout 层，再是另一个全连接层，最后是一个具有 10 个单元的输出层。训练函数将接收一个包含超参数组合的
    HParams 字典作为参数。由于我们使用的是 Keras 模型，我们在 fit 方法中添加了 HParams Keras 回调来监控每次实验。对于每次实验，插件将记录超参数组合、损失值和指标。如果需要监控其他信息，我们还可以添加一个
    Summary File Writer：
- en: '[PRE10]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we''ll iterate on all the hyperparameters:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将对所有超参数进行迭代：
- en: '[PRE11]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We then start the TensorBoard application by running this command:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过运行此命令启动 TensorBoard 应用程序：
- en: '[PRE12]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Then, we can quickly and easily visualize the results (hyperparameters and metrics)
    in the HParams table view. Filters and sorting can be applied on the left pane
    if needed:![](img/B16254_12_05.png)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以快速而轻松地在 HParams 表格视图中可视化结果（超参数和指标）。如果需要，左侧面板可以应用过滤器和排序：![](img/B16254_12_05.png)
- en: 'Figure 12.5: The HParams table view visualized in TensorBoard'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 12.5：在 TensorBoard 中可视化的 HParams 表格视图
- en: On the parallel coordinates view, each axis represents a hyperparameter or a
    metric and each run is represented by a line. This visualization allows the quick
    identification of the best hyperparameter combination:![](img/B16254_12_06.png)
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在平行坐标视图中，每个轴表示一个超参数或指标，每次运行由一条线表示。这个可视化方法可以快速识别出最佳的超参数组合：![](img/B16254_12_06.png)
- en: 'Figure 12.6: The HParams parallel coordinates view visualized in TensorBoard'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.6：在 TensorBoard 中可视化的 HParams 平行坐标视图
- en: Using TensorBoard HParams is a simple and insightful way to identify the best
    hyperparameters and also to manage your experiments with TensorFlow.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorBoard HParams是一种简单且富有洞察力的方式，可以识别最佳超参数，并帮助管理你在TensorFlow中的实验。
- en: See also
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For a reference on the HParams TensorBoard plugin, visit the following website:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 有关HParams TensorBoard插件的参考，请访问以下网站：
- en: 'The official TensorBoard guide: [https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams
    )'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方TensorBoard指南：[https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)
- en: Implementing unit tests
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现单元测试
- en: Testing code results in faster prototyping, more efficient debugging, faster
    changing, and makes it easier to share code. TensorFlow 2.0 provides the `tf.test`
    module and we will cover it in this recipe.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 测试代码可以加速原型开发，提高调试效率，快速变更，并且使得代码共享变得更容易。TensorFlow 2.0提供了`tf.test`模块，我们将在本节中介绍它。
- en: Getting ready
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: When programming a TensorFlow model, it helps to have unit tests to check the
    functionality of the program. This helps us because when we want to make changes
    to a program unit, tests will make sure those changes do not break the model in
    unknown ways. In Python, the main test framework is `unittest` but TensorFlow
    provides its own test framework. In this recipe, we will create a custom layer
    class. We will implement a unit test to illustrate how to write it in TensorFlow.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写TensorFlow模型时，单元测试可以帮助检查程序功能。这对我们很有帮助，因为当我们想对程序单元进行修改时，测试可以确保这些修改不会以未知的方式破坏模型。在Python中，主要的测试框架是`unittest`，但TensorFlow提供了自己的测试框架。在本节中，我们将创建一个自定义层类，并实现一个单元测试，演示如何在TensorFlow中编写单元测试。
- en: How to do it...
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, we need to load the necessary libraries as follows:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要加载必要的库，如下所示：
- en: '[PRE13]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, we need to declare our custom gate that applies the function `f(x) =
    a1 * x + b1`:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要声明我们的自定义门控函数，应用`f(x) = a1 * x + b1`：
- en: '[PRE14]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we create our unit test class that inherits from the `tf.test.TestCase`
    class. The `setup` method is a `hook` method that is called before every `test`
    method. The `assertAllEqual` method checks that the expected and the computed
    outputs have the same values:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个继承自`tf.test.TestCase`类的单元测试类。`setup`方法是一个`hook`方法，在每个`test`方法之前被调用。`assertAllEqual`方法检查预期输出和计算输出是否相等：
- en: '[PRE15]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we need a `main()` function in our script, to run all unit tests:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要在脚本中加入一个`main()`函数，用于运行所有单元测试：
- en: '[PRE16]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'From the terminal, run the following command. We should get the following output:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从终端运行以下命令。我们应该会得到如下输出：
- en: '[PRE17]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We implemented one test and it passed. Don't worry about the two `test_session`
    tests – they are phantom tests.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了一个测试并且通过了。不要担心那两个`test_session`测试——它们是虚拟测试。
- en: Note that many assertions tailored to TensorFlow are available in the `tf.test`
    API.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，许多专门为TensorFlow量身定制的断言可以在`tf.test` API中找到。
- en: How it works...
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this section, we implemented a TensorFlow unit test using the `tf.test` API
    that is very similar to the Python unit test. Remember that unit testing helps
    assure us that code will function as expected, provides confidence in sharing
    code, and makes reproducibility more accessible.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们使用`tf.test` API实现了一个TensorFlow单元测试，它与Python的单元测试非常相似。记住，单元测试有助于确保代码按预期功能运行，增加共享代码的信心，并使得可重复性更容易实现。
- en: See also
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For a reference on the `tf.test` module, visit the following website:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`tf.test`模块的参考，请访问以下网站：
- en: 'The official TensorFlow test API: [https://www.tensorflow.org/api_docs/python/tf/test](https://www.tensorflow.org/api_docs/python/tf/test)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方TensorFlow测试API：[https://www.tensorflow.org/api_docs/python/tf/test](https://www.tensorflow.org/api_docs/python/tf/test)
- en: Using multiple executors
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多个执行器
- en: You will be aware that there are many features of TensorFlow, including computational
    graphs that lend themselves naturally to being computed in parallel. Computational
    graphs can be split over different processors as well as in processing different
    batches. We will address how to access different processors on the same machine
    in this recipe.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能知道，TensorFlow有许多特性，包括计算图，它们天生适合并行计算。计算图可以在不同的处理器之间拆分，也可以在不同的批次之间进行处理。我们将在本节中讨论如何在同一台机器上访问不同的处理器。
- en: Getting ready
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we will show you how to access multiple devices on the same
    system and train on them. A device is a CPU or an accelerator unit (GPUs, TPUs)
    where TensorFlow can run operations. This is a very common occurrence: along with
    a CPU, a machine may have one or more GPUs that can share the computational load.
    If TensorFlow can access these devices, it will automatically distribute the computations
    to multiple devices via a greedy process. However, TensorFlow also allows the
    program to specify which operations will be on which device via a name scope placement.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将向您展示如何访问同一系统上的多个设备并在其上进行训练。设备是CPU或加速单元（GPU、TPU），TensorFlow可以在其上运行操作。这是非常常见的情况：除了CPU，机器可能还有一个或多个GPU可以共享计算负载。如果TensorFlow能够访问这些设备，它将通过贪婪过程自动将计算分配到多个设备。然而，TensorFlow也允许程序通过命名范围位置指定哪些操作将在哪个设备上执行。
- en: In this recipe, we will show you different commands that will allow you to access
    various devices on your system; we'll also demonstrate how to find out which devices
    TensorFlow is using. Remember that some functions are still experimental and are
    subject to change.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将向您展示不同的命令，这些命令将允许您访问系统上的各种设备；我们还将演示如何查找TensorFlow正在使用的设备。请记住，一些功能仍然是实验性的，可能会发生变化。
- en: How to do it...
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'In order to find out which devices TensorFlow is using for which operations,
    we will activate the logs for device placement by setting `tf.debugging.set_log_device_placement` to `True`.
    If a TensorFlow operation is implemented for CPU and GPU devices, the operation
    will be executed by default on a GPU device if a GPU is available:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了查找TensorFlow为哪些操作使用了哪些设备，我们将通过设置`tf.debugging.set_log_device_placement`为`True`来激活设备分配日志。如果TensorFlow操作同时支持CPU和GPU设备，该操作将在默认情况下执行在GPU设备上（如果GPU可用）：
- en: '[PRE18]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can also use the tensor device attribute that returns the name of the device
    on which this tensor will be assigned:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用张量设备属性来返回该张量将分配到的设备名称：
- en: '[PRE19]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'By default, TensorFlow automatically decides how to distribute computations
    across computing devices (CPUs and GPUs) and sometimes we need to select the device
    to use by creating a device context with the `tf.device` function. Each operation
    executed in this context will use the selected device:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，TensorFlow会自动决定如何在计算设备（CPU和GPU）之间分配计算，有时我们需要通过创建`tf.device`函数的设备上下文来选择要使用的设备。在此上下文中执行的每个操作都会使用所选设备：
- en: '[PRE20]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If we move the `matmul` operation out of the context, this operation will be
    executed on a GPU device if it''s available:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们将`matmul`操作移出上下文，如果有可用的GPU设备，则该操作将在GPU设备上执行：
- en: '[PRE21]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'When using GPUs, TensorFlow automatically takes up a large portion of the GPU
    memory. While this is usually desired, we can take steps to be more careful with
    GPU memory allocation. While TensorFlow never releases GPU memory, we can slowly
    grow its allocation to the maximum limit (only when needed) by setting a GPU memory
    growth option. Note that physical devices cannot be modified after being initialized:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用GPU时，TensorFlow会自动占用GPU内存的大部分。虽然这通常是期望的行为，但我们可以采取措施更加谨慎地分配GPU内存。虽然TensorFlow永远不会释放GPU内存，但我们可以通过设置GPU内存增长选项，逐步增加其分配，直到达到最大限制（仅在需要时）。注意，物理设备初始化后不能修改：
- en: '[PRE22]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If we want to put a hard limit on the GPU memory used by TensorFlow, we can
    also create a virtual GPU device and set the maximum memory limit (in MB) to allocate
    on this virtual GPU. Note that virtual devices cannot be modified after being
    initialized:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想要对TensorFlow使用的GPU内存设置硬性限制，我们还可以创建一个虚拟GPU设备并设置分配到该虚拟GPU的最大内存限制（单位：MB）。注意，虚拟设备初始化后不能修改：
- en: '[PRE23]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can also simulate virtual GPU devices with a single physical GPU. This is
    done with the following code:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以通过单个物理GPU来模拟虚拟GPU设备。通过以下代码可以实现：
- en: '[PRE24]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Sometimes we may need to write robust code that can determine whether it is
    running with the GPU available or not. TensorFlow has a built-in function that
    can test whether the GPU is available. This is helpful when we want to write code
    that takes advantage of the GPU when it is available and assign specific operations
    to it. This is done with the following code:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有时我们可能需要编写稳健的代码来判断是否有可用的GPU。TensorFlow有一个内置函数，可以测试GPU是否可用。当我们希望在GPU可用时利用它并将特定操作分配给它时，这非常有帮助。通过以下代码可以实现：
- en: '[PRE25]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If we need to assign specific operations, say, to the GPU, we input the following
    code. This will perform simple calculations and assign operations to the main
    CPU and the two auxiliary GPUs:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们需要将特定操作分配给GPU，可以输入以下代码。这将执行简单的计算，并将操作分配给主CPU和两个辅助GPU：
- en: '[PRE26]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We can see that the first two operations have been performed on the main CPU,
    the next two on the first auxiliary GPU, and the last two on the second auxiliary
    GPU.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，前两个操作已在主CPU上执行，接下来的两个操作在第一个辅助GPU上执行，最后两个操作在第二个辅助GPU上执行。
- en: How it works...
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'When we want to set specific devices on our machine for TensorFlow operations,
    we need to know how TensorFlow refers to such devices. Device names in TensorFlow
    follow the following conventions:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望为TensorFlow操作设置特定设备时，我们需要了解TensorFlow如何引用这些设备。TensorFlow中的设备名称遵循以下约定：
- en: '| Device | Device name |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 设备 | 设备名称 |'
- en: '| Main CPU | `/device:CPU:0` |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 主CPU | `/device:CPU:0` |'
- en: '| Main GPU | `/GPU:0` |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 主GPU | `/GPU:0` |'
- en: '| Second GPU | `/job:localhost/replica:0/task:0/device:GPU:1` |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 第二GPU | `/job:localhost/replica:0/task:0/device:GPU:1` |'
- en: '| Third GPU | `/job:localhost/replica:0/task:0/device:GPU:2` |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 第三GPU | `/job:localhost/replica:0/task:0/device:GPU:2` |'
- en: Remember that TensorFlow considers a CPU as a unique processor even if the processor
    is a multi-core processor. All cores are wrapped in `/device:CPU:0`, that is to
    say, TensorFlow does indeed use multiple CPU cores by default.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，TensorFlow将CPU视为一个独立的处理器，即使该处理器是一个多核处理器。所有核心都被包装在`/device:CPU:0`中，也就是说，TensorFlow默认确实使用多个CPU核心。
- en: There's more...
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Fortunately, running TensorFlow in the cloud is now easier than ever. Many cloud
    computation service providers offer GPU instances that have a main CPU and a powerful
    GPU alongside it. Note that an easy way to have a GPU is to run the code in Google
    Colab and set the GPU as the hardware accelerator in the notebook settings.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，现在在云端运行TensorFlow比以往任何时候都更容易。许多云计算服务提供商提供GPU实例，这些实例拥有主CPU和强大的GPU。请注意，获得GPU的简单方法是通过Google
    Colab运行代码，并在笔记本设置中将GPU设置为硬件加速器。
- en: Parallelizing TensorFlow
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化TensorFlow
- en: Training a model can be very time-consuming. Fortunately, TensorFlow offers
    several distributed strategies to speed up the training, whether for a very large
    model or a very large dataset. This recipe will show us how to use the TensorFlow
    distributed API.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型可能非常耗时。幸运的是，TensorFlow提供了几种分布式策略来加速训练，无论是针对非常大的模型还是非常大的数据集。本食谱将向我们展示如何使用TensorFlow分布式API。
- en: Getting ready
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: The TensorFlow distributed API allows us to distribute the training by replicating
    the model into different nodes and training on different subsets of data. Each
    strategy supports a hardware platform (multiple GPUs, multiple machines, or TPUs)
    and uses either a synchronous or asynchronous training strategy. In synchronous
    training, each worker trains over different batches of data and aggregates their
    gradients at each step. While in the asynchronous mode, each worker is independently
    training over the data and the variables are updated asynchronously. Note that
    for the moment, TensorFlow only supports data parallelism described above and
    according to the roadmap, it will soon support model parallelism. This paradigm
    is used when the model is too large to fit on a single device and needs to be
    distributed over many devices. In this recipe, we will go over the mirrored strategy
    provided by this API.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow分布式API允许我们通过将模型复制到不同节点并在不同数据子集上进行训练来分布式训练。每个策略支持一个硬件平台（多个GPU、多个机器或TPU），并使用同步或异步训练策略。在同步训练中，每个工作节点在不同的数据批次上训练，并在每一步汇聚它们的梯度。而在异步模式下，每个工作节点独立训练数据，变量异步更新。请注意，目前TensorFlow仅支持上面描述的数据并行性，根据路线图，它很快将支持模型并行性。当模型太大，无法放入单个设备时，就需要将模型分布到多个设备上进行训练。本例将介绍该API提供的镜像策略。
- en: How to do it...
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'First, we''ll load the libraries necessary for this recipe as follows:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将加载该食谱所需的库，如下所示：
- en: '[PRE27]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will create two virtual GPUs:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建两个虚拟GPU：
- en: '[PRE28]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we will load the MNIST dataset via the `tensorflow_datasets` API as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过`tensorflow_datasets` API加载MNIST数据集，如下所示：
- en: '[PRE29]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we will prepare the data:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将准备数据：
- en: '[PRE30]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We are now ready to apply a mirrored strategy. The goal of this strategy is
    to replicate the model across all GPUs on the same machine. Each model is trained
    on different batches of data and a synchronous training strategy is applied:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备应用镜像策略。这个策略的目标是在同一台机器上的所有 GPU 上复制模型。每个模型在不同的批次数据上进行训练，并应用同步训练策略：
- en: '[PRE31]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we check that we have two devices corresponding to the two virtual GPUs
    created at the beginning of this recipe as follows:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们检查是否有两个设备对应于在本示例开始时创建的两个虚拟 GPU，如下所示：
- en: '[PRE32]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then, we''ll define the value of the batch size. The batch size given to the
    dataset is the global batch size. The global batch size is the sum of all batch
    sizes of every replica. So, we had to compute the global batch size using the
    number of replicas:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将定义批量大小的值。给数据集的批量大小就是全局批量大小。全局批量大小是每个副本的所有批量大小的总和。所以，我们需要使用副本的数量来计算全局批量大小：
- en: '[PRE33]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we''ll define and compile our model using the mirrored strategy scope.
    Note that all variables created inside the scope are mirrored across all replicas:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用镜像策略作用域定义并编译我们的模型。请注意，所有在作用域内创建的变量都会在所有副本之间镜像：
- en: '[PRE34]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Once the compilation is over, we can fit the previous model as we would normally:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦编译完成，我们就可以像平常一样拟合之前的模型：
- en: '[PRE35]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Using a strategy scope is the only thing you have to do to distribute your training.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用策略作用域是分布式训练所需要做的唯一事情。
- en: How it works...
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Using the distributed TensorFlow API is quite easy. All you have to do is to
    assign the scope. Then, operations can be manually or automatically assigned to
    workers. Note that we can easily switch between strategies.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用分布式 TensorFlow API 非常简单。你需要做的就是分配作用域。然后，可以手动或自动将操作分配给工作节点。请注意，我们可以轻松切换不同的策略。
- en: 'Here''s a brief overview of some distributed strategies:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一些分布式策略的简要概述：
- en: The TPU strategy is like the mirrored strategy but it runs on TPUs.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TPU 策略类似于镜像策略，但它运行在 TPU 上。
- en: The Multiworker Mirrored strategy is very similar to the mirrored strategy but
    the model is trained across several machines, potentially with multiple GPUs.
    We have to specify the cross-device communication.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多工作节点镜像策略与镜像策略非常相似，但模型在多台机器上进行训练，可能配有多个 GPU。我们需要指定跨设备通信。
- en: The Central Storage strategy uses a synchronous mode on one machine with multiple
    GPUs. Variables aren't mirrored but placed on the CPU and operations are replicated
    into all local GPUs.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中央存储策略在一台机器上使用同步模式并配备多个 GPU。变量不进行镜像，而是放置在 CPU 上，操作会复制到所有本地 GPU 上。
- en: The Parameter Server strategy is implemented on a cluster of machines. Some
    machines have a worker role and others have a parameter server role. The workers
    compute and the parameter servers store the variable of the model.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数服务器策略是在一组机器上实现的。一些机器担任工作节点角色，另一些则担任参数服务器角色。工作节点进行计算，参数服务器存储模型的变量。
- en: See also
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For some references on the `tf.distribute.Strategy` module, visit the following
    websites:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 `tf.distribute.Strategy` 模块的一些参考，请访问以下网站：
- en: 'Distributed training with TensorFlow: [https://www.tensorflow.org/guide/distributed_training](https://www.tensorflow.org/guide/distributed_training)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TensorFlow 分布式训练: [https://www.tensorflow.org/guide/distributed_training](https://www.tensorflow.org/guide/distributed_training)'
- en: 'The `tf.distribute` API: [https://www.tensorflow.org/api_docs/python/tf/distribute](https://www.tensorflow.org/api_docs/python/tf/distribute)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.distribute` API: [https://www.tensorflow.org/api_docs/python/tf/distribute](https://www.tensorflow.org/api_docs/python/tf/distribute)'
- en: There's more...
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: In this recipe, we've just gotten over the mirrored strategy and we've executed
    our program eagerly with the Keras API. Note that the TensorFlow distributed API
    works better when used in graph mode than in eager mode.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们刚刚使用了镜像策略，并通过 Keras API 执行了程序。请注意，当在图模式下使用时，TensorFlow 分布式 API 的效果比在急切模式下要好。
- en: This API moves quickly so feel free to consult the official documentation to
    know which distributed strategies are supported in which scenarios (the Keras
    API, a custom training loop, or the Estimator API).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 API 更新速度很快，因此请随时查阅官方文档，了解在什么场景下支持哪些分布式策略（Keras API、自定义训练循环或 Estimator API）。
- en: Saving and restoring a TensorFlow model
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存和恢复 TensorFlow 模型
- en: If we want to use our machine learning model in production or reuse our trained
    model for a transfer learning task, we have to store our model. In this section,
    we will outline some methods for storing and restoring the weights or the whole
    model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在生产环境中使用机器学习模型，或者将我们训练好的模型用于迁移学习任务，我们必须保存我们的模型。在本节中，我们将概述一些保存和恢复权重或整个模型的方法。
- en: Getting ready
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we want to summarize various ways to store a TensorFlow model.
    We will cover the best way to save and restore an entire model, only the weights,
    and model checkpoints.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本篇中，我们将总结几种保存 TensorFlow 模型的方法。我们将涵盖保存和恢复整个模型、仅保存权重以及模型检查点的最佳方式。
- en: How to do it...
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We start by loading the necessary libraries:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先加载必要的库：
- en: '[PRE36]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, we''ll build an MNIST model using the Keras Sequential API:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 Keras Sequential API 构建一个 MNIST 模型：
- en: '[PRE37]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Then, we will use the recommended format to save an entire model on disk named
    the SavedModel format. This format saves the model graph and variables:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将使用推荐的格式保存整个模型为磁盘上的 SavedModel 格式。此格式保存模型图和变量：
- en: '[PRE38]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'A directory named `SavedModel` is created on disk. It contains a TensorFlow
    program,the `saved_model.pb` file; the `variables` directory, which contains the
    exact value of all parameters; and the `assets` directory, which contains files
    used by the TensorFlow graph:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在磁盘上创建一个名为 `SavedModel` 的目录。它包含一个 TensorFlow 程序，`saved_model.pb` 文件；`variables`
    目录，包含所有参数的确切值；以及 `assets` 目录，包含 TensorFlow 图使用的文件：
- en: '[PRE39]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note that the `save()` operation also takes other parameters. Extra directories
    can be created based on the model complexity and the signatures and options passed
    to the s`ave` method.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，`save()` 操作也接受其他参数。可以根据模型的复杂性以及传递给 `save` 方法的签名和选项创建额外的目录。
- en: 'Next, we''ll restore our saved model:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将恢复我们保存的模型：
- en: '[PRE40]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If we prefer to save the model in the H5 format, we can either pass a filename
    that ends in `.h5` or add the `save_format="h5"` argument:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们更倾向于将模型保存为 H5 格式，我们可以传递一个以 `.h5` 结尾的文件名，或者添加 `save_format="h5"` 参数：
- en: '[PRE41]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can also use a `ModelCheckpoint` callback in order to save an entire model
    or just the weights into a checkpoint structure at some intervals. This callback
    is added to the `callback` argument in the `fit` method. In the configuration
    below, the model weights will be stored at each epoch:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用 `ModelCheckpoint` 回调来将整个模型或仅仅是权重保存到检查点结构中，间隔一定的训练周期。这个回调会被添加到 `fit`
    方法中的 `callback` 参数中。在下面的配置中，模型的权重会在每个 epoch 后被保存：
- en: '[PRE42]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can load the entire model or only the weights later in order to continue
    the training. Here, we will reload the weights:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们稍后可以加载整个模型或仅加载权重，以便继续训练。在这里，我们将重新加载权重：
- en: '[PRE43]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Now, you're ready to save and restore an entire model, only the weights, or
    model checkpoints.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经准备好保存和恢复整个模型、仅保存权重或模型检查点。
- en: How it works...
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this section, we provided several ways to store and restore an entire model
    or only the weights. That allows you to put a model into production or avoids
    retraining a full model from scratch. We have also seen how to store a model during
    the training process and after it.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了几种保存和恢复整个模型或仅保存权重的方法。这使得您能够将模型投入生产，或避免从头开始重新训练一个完整的模型。我们还介绍了如何在训练过程中以及训练后保存模型。
- en: See also
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For some references on this topic, visit the following websites:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题的一些参考资料，请访问以下网站：
- en: 'The official training checkpoints guide: [https://www.tensorflow.org/guide/checkpoint](https://www.tensorflow.org/guide/checkpoint)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '官方训练检查点指南: [https://www.tensorflow.org/guide/checkpoint](https://www.tensorflow.org/guide/checkpoint)'
- en: 'The official SavedModel format guide: [https://www.tensorflow.org/guide/saved_model](https://www.tensorflow.org/guide/saved_model)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '官方 SavedModel 格式指南: [https://www.tensorflow.org/guide/saved_model](https://www.tensorflow.org/guide/saved_model)'
- en: 'The `tf.saved_model` API: [https://www.tensorflow.org/api_docs/python/tf/saved_model/save](https://www.tensorflow.org/api_docs/python/tf/saved_model/save)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.saved_model` API: [https://www.tensorflow.org/api_docs/python/tf/saved_model/save](https://www.tensorflow.org/api_docs/python/tf/saved_model/save)'
- en: 'The Keras Model Checkpoint API: [https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Keras 模型检查点 API: [https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)'
- en: Using TensorFlow Serving
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Serving
- en: In this section, we will show you how to serve machine learning models in production.
    We will use the TensorFlow Serving components of the **TensorFlow Extended** (**TFX**)
    platform. TFX is an MLOps tool that builds complete, end-to-end machine learning
    pipelines for scalable and high-performance model tasks. A TFX pipeline is composed
    of a sequence of components for data validation, data transformation, model analysis,
    and model serving. In this recipe, we will focus on the last component, which
    can support model versioning, multiple models, and so on.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示如何在生产环境中提供机器学习模型。我们将使用**TensorFlow扩展**（**TFX**）平台的TensorFlow Serving组件。TFX是一个MLOps工具，旨在为可扩展和高性能的模型任务构建完整的端到端机器学习管道。TFX管道由一系列组件组成，涵盖数据验证、数据转换、模型分析和模型服务等内容。在这个教程中，我们将重点介绍最后一个组件，它支持模型版本控制、多个模型等功能。
- en: Getting ready
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: We'll start this section by encouraging you to read through the official documentation
    and the short tutorials on the TFX site, available at [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 本节开始时，建议您阅读官方文档和TFX网站上的简短教程，网址为[https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx)。
- en: For this example, we will build an MNIST model, save it, download the TensorFlow
    Serving Docker image, run it, and send POST requests to the REST server in order
    to get some image predictions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将构建一个MNIST模型，保存它，下载TensorFlow Serving的Docker镜像，运行它，并向REST服务器发送POST请求以获取一些图像预测。
- en: How to do it...
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Here, we will start in the same way as before, by loading the necessary libraries:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将像之前一样开始，先加载必要的库：
- en: '[PRE44]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We''ll build an MNIST model using the Keras Sequential API:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用Keras的Sequential API构建一个MNIST模型：
- en: '[PRE45]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Then, we will save our model as the SavedModel format and create a directory
    for each version of our model. TensorFlow Serving wants a specific tree structure
    and models saved into SavedModel format. Each model version should be exported
    to a different subdirectory under a given path. So, we can easily specify the
    version of a model we want to use when we call the server to do predictions:![](img/B16254_12_07.png)
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将把模型保存为SavedModel格式，并为每个版本的模型创建一个目录。TensorFlow Serving需要特定的目录结构，并且模型必须以SavedModel格式保存。每个模型版本应导出到给定路径下的不同子目录中。这样，当我们调用服务器进行预测时，就可以轻松指定我们想要使用的模型版本：![](img/B16254_12_07.png)
- en: 'Figure 12.7: A screenshot of the directory structure that TensorFlow Serving
    expects'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.7：TensorFlow Serving期望的目录结构截图
- en: The preceding screenshot shows the desired directory structure. In it, we have
    our defined data directory, `my_mnist_model`, followed by our model-version number, `1`.
    In the version number directory, we save our protobuf model and a `variables` folder
    that contains the desired variables to save.
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上面的截图展示了所需的目录结构。在该结构中，我们有定义好的数据目录`my_mnist_model`，后跟模型版本号`1`。在版本号目录下，我们保存protobuf模型和一个`variables`文件夹，其中包含需要保存的变量。
- en: We should be aware that inside our data directory, TensorFlow Serving will look
    for integer folders. TensorFlow Serving will automatically boot up and grab the
    model under the largest integer number. This means that to deploy a new model,
    we need to label it version 2 and stick it under a new folder that is also labeled 2\.
    TensorFlow Serving will then automatically pick up the model.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要注意，在数据目录中，TensorFlow Serving会查找整数编号的文件夹。TensorFlow Serving会自动启动并获取最大整数编号下的模型。这意味着，要部署一个新模型，我们需要将其标记为版本2，并放入一个新的文件夹，该文件夹也标记为2。TensorFlow
    Serving随后会自动识别该模型。
- en: Then, we'll install TensorFlow Serving by using Docker. We encourage readers
    to visit the official Docker documentation to get Docker installation instructions
    if needed.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将通过Docker安装TensorFlow Serving。如果需要，我们建议读者访问官方Docker文档，以获取Docker安装说明。
- en: 'The first step is to pull the latest TensorFlow Serving Docker image:'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一步是拉取最新的TensorFlow Serving Docker镜像：
- en: '[PRE46]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now, we''ll start a Docker container: publish the REST API port 8501 to our
    host''s port 8501, take the previously created model, `my_mnist_model`, bind it
    to the model base path, `/models/my_mnist_model`, and fill in the environment
    variable `MODEL_NAME` with `my_mnist_model`:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将启动一个Docker容器：将REST API端口8501映射到主机的8501端口，使用之前创建的模型`my_mnist_model`，将其绑定到模型的基本路径`/models/my_mnist_model`，并将环境变量`MODEL_NAME`设置为`my_mnist_model`：
- en: '[PRE47]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Then, we will display the images to predict:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将显示图像进行预测：
- en: '[PRE48]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '![](img/B16254_12_08.png)'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B16254_12_08.png)'
- en: We can now submit binary data to the `<host>:8501` and get back the JSON response
    showing the results. We can do this via any machine and with any programming language.
    It is very useful to not have to rely on the client to have a local copy of TensorFlow.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以将二进制数据提交到`<host>:8501`并获取JSON响应，显示结果。我们可以通过任何机器和任何编程语言来完成此操作。这样做非常有用，因为不必依赖客户端拥有TensorFlow的本地副本。
- en: 'Here, we will send POST predict requests to our server and pass the images.
    The server will return 10 probabilities for each image corresponding to the probability
    for each digit between `0` and `9`:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们将向我们的服务器发送POST预测请求并传递图像。服务器将返回每个图像对应的10个概率，表示每个数字（从`0`到`9`）的概率：
- en: '[PRE49]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Then, we will display the prediction results for our images:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将展示我们图像的预测结果：
- en: '[PRE50]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, let''s look at a visual representation of 16 predictions:'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，让我们看一下16个预测的可视化表示：
- en: '![](img/B16254_12_09.png)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B16254_12_09.png)'
- en: How it works...
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Machine learning teams focus on creating machine learning models and operations
    teams focus on deploying models. MLOps applies DevOps principles to machine learning.
    It brings the best practices of software development (commenting, documentation,
    versioning, testing, and so on) to data science. MLOps is about removing the barriers
    between the machine learning teams that produce models and the operations teams
    that deploy models.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习团队专注于创建机器学习模型，而运维团队则专注于部署模型。MLOps将DevOps原则应用于机器学习。它将软件开发的最佳实践（如注释、文档、版本控制、测试等）带入数据科学领域。MLOps的目标是消除生产模型的机器学习团队与部署模型的运维团队之间的隔阂。
- en: In this recipe, we only focus on serving models using the TFX Serving component
    but TFX is an MLOps tool that builds complete, end-to-end machine learning pipelines.
    We can only encourage the reader to explore this platform.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们只关注使用TFX Serving组件来提供模型，但TFX是一个MLOps工具，可以构建完整的端到端机器学习管道。我们只鼓励读者探索这个平台。
- en: There are also many other solutions available that may be used to serve a model,
    such as Kubeflow, Django/Flask, or managed cloud services such as AWS SageMaker,
    GCP AI Platform, or Azure ML.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他解决方案可以用于提供模型，如Kubeflow、Django/Flask，或者AWS SageMaker、GCP AI平台或Azure ML等托管云服务。
- en: There's more...
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'Links to tools and resources for architectures not covered in this chapter
    are as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 本章未涵盖的架构工具和资源链接如下：
- en: '**Using TensorFlow Serving** **with Docker**: [https://www.tensorflow.org/serving/docker](https://www.tensorflow.org/serving/docker)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用TensorFlow Serving** **与Docker**: [https://www.tensorflow.org/serving/docker](https://www.tensorflow.org/serving/docker)'
- en: '**Using TensorFlow Serving** **with Kubernetes**: [https://www.tensorflow.org/tfx/serving/serving_kubernetes](https://www.tensorflow.org/tfx/serving/serving_kubernetes)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用TensorFlow Serving** **与Kubernetes**: [https://www.tensorflow.org/tfx/serving/serving_kubernetes](https://www.tensorflow.org/tfx/serving/serving_kubernetes)'
- en: '**Installing** **TensorFlow Serving**: [https://www.tensorflow.org/tfx/tutorials/serving/rest_simple](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安装** **TensorFlow Serving**: [https://www.tensorflow.org/tfx/tutorials/serving/rest_simple](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)'
- en: '**TensorFlow** **extended**: [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow** **扩展**: [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx)'
- en: '**Kubeflow – The machine** **learning toolkit for Kubernetes**: [https://www.kubeflow.org/](https://www.kubeflow.org/)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubeflow – Kubernetes的机器学习工具包**: [https://www.kubeflow.org/](https://www.kubeflow.org/)'
- en: '**GCP AI** **Platform**: [https://cloud.google.com/ai-platform](https://cloud.google.com/ai-platform)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GCP AI** **平台**: [https://cloud.google.com/ai-platform](https://cloud.google.com/ai-platform)'
- en: '**AWS** **SageMaker**: [https://aws.amazon.com/fr/sagemaker/](https://aws.amazon.com/fr/sagemaker/)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS** **SageMaker**: [https://aws.amazon.com/fr/sagemaker/](https://aws.amazon.com/fr/sagemaker/)'
- en: '**Azure** **ML**: [https://azure.microsoft.com/services/machine-learning/](https://azure.microsoft.com/services/machine-learning/)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure** **ML**: [https://azure.microsoft.com/services/machine-learning/](https://azure.microsoft.com/services/machine-learning/)'
- en: '| **Share your experience**Thank you for taking the time to read this book.
    If you enjoyed this book, help others to find it. Leave a review at [https://www.amazon.com/dp/1800208863](https://www.amazon.com/dp/1800208863)
    |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| **分享您的经验**感谢您花时间阅读本书。如果您喜欢本书，请帮助其他人找到它。请在[https://www.amazon.com/dp/1800208863](https://www.amazon.com/dp/1800208863)留下评论
    |'
