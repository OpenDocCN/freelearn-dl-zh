- en: '*Chapter 2*: Exploring and Cleaning Up Data with fastai'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 2 章*：使用 fastai 探索和清理数据'
- en: 'In the previous chapter, we got started with the fastai framework by setting
    up its coding environment, working through a concrete application example (MNIST),
    and investigating two frameworks with different relationships to fastai: PyTorch
    and Keras. In this chapter, we are going to dive deeper into an important aspect
    of fastai: **ingesting**, **exploring**, and **cleaning up data**. In particular,
    we are going to explore a selection of the datasets that are curated by fastai.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们通过设置 fastai 框架的编程环境，完成一个具体的应用示例（MNIST），并调查了与 fastai 关系不同的两个框架：PyTorch
    和 Keras，成功入门 fastai。在本章中，我们将深入探讨 fastai 的一个重要方面：**获取**、**探索**和**清理数据**。特别地，我们将探索
    fastai 管理的一些数据集。
- en: By the end of this chapter, you will be able to describe the complete set of
    curated datasets that fastai supports, use the facilities of fastai to examine
    these datasets, and clean up a dataset to eliminate missing and non-numeric values.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够描述 fastai 支持的完整数据集，使用 fastai 提供的工具查看这些数据集，并清理数据集以去除缺失值和非数字值。
- en: 'Here are the recipes that will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下的食谱：
- en: Getting the complete set of *oven-ready* fastai datasets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取完整的 *即用型* fastai 数据集
- en: Examining tabular datasets with fastai
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 fastai 查看表格数据集
- en: Examining text datasets with fastai
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 fastai 查看文本数据集
- en: Examining image datasets with fastai
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 fastai 查看图像数据集
- en: Cleaning up raw datasets with fastai
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 fastai 清理原始数据集
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Ensure that you have completed the setup sections in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, and that you have a working Gradient instance or
    Colab setup. Ensure that you have cloned the repository for this book ([https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook))
    and have access to the `ch2` folder. This folder contains the code samples that
    will be described in this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已完成[*第 1 章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)《与 fastai 开始》中的设置部分，并且拥有一个有效的
    Gradient 实例或 Colab 环境。确保你已克隆了这本书的代码库（[https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook)），并且可以访问
    `ch2` 文件夹。此文件夹包含本章将描述的代码示例。
- en: Getting the complete set of oven-ready fastai datasets
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取完整的即用型 fastai 数据集
- en: In [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019), *Getting Started
    with fastai*, you encountered the MNIST dataset and saw how easy it was to make
    this dataset available to train a fastai deep learning model. You were able to
    train the model without needing to worry about the location of the dataset or
    its structure (apart from the names of the folders containing the training and
    validation datasets). You were able to examine elements of the dataset conveniently.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 1 章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)《与 fastai 开始》中，你接触了
    MNIST 数据集，并了解了如何轻松使该数据集可用于训练 fastai 深度学习模型。你能够训练该模型而不需要担心数据集的位置或结构（除了包含训练集和验证集的文件夹名称）。你还能够方便地查看数据集的元素。
- en: In this section, we'll take a closer look at the complete set of datasets that
    fastai curates and explain how you can get additional information about these
    datasets.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更详细地了解 fastai 管理的完整数据集，并解释你如何获取关于这些数据集的更多信息。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, so that you have a fastai environment set up. Confirm
    that you can open the `fastai_dataset_walkthrough.ipynb` notebook in the `ch2`
    directory of your cloned repository.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已按照[*第 1 章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)《与 fastai 开始》中的步骤设置了
    fastai 环境，并确认可以在克隆的代码库中的 `ch2` 目录下打开 `fastai_dataset_walkthrough.ipynb` 笔记本。
- en: How to do it…
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'In this section, you will be running through the `fastai_dataset_walkthrough.ipynb`
    notebook, as well as the fastai dataset documentation, so that you understand
    the datasets that fastai curates. Once you have the notebook open in your fastai
    environment, complete the following steps:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将通过运行 `fastai_dataset_walkthrough.ipynb` 笔记本以及 fastai 数据集文档，来了解 fastai
    所管理的数据集。一旦你在 fastai 环境中打开了该笔记本，请按照以下步骤操作：
- en: Run the first three cells of the notebook to load the required libraries, set
    up the notebook for fastai, and define the MNIST dataset:![Figure 2.1 – Cells
    to load the libraries, set up the notebook, and define the MNIST dataset
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本中的前三个单元，加载所需的库，设置 fastai 环境，并定义 MNIST 数据集：![图 2.1 – 加载库、设置笔记本环境并定义 MNIST
    数据集的单元
- en: '](img/B16216_02_01.jpg)'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_01.jpg)'
- en: Figure 2.1 – Cells to load the libraries, set up the notebook, and define the
    MNIST dataset
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.1 – 加载库、设置笔记本环境并定义 MNIST 数据集的单元
- en: 'Consider the argument to `untar_data`: `URLs.MINST`. What is this? Let''s try
    the `??`  shortcut to examine the source code for a `URLs` object:![Figure 2.2
    – Source for URLs'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑 `untar_data` 函数的参数：`URLs.MINST`。这是什么？让我们尝试 `??` 快捷方式查看 `URLs` 对象的源代码：![图
    2.2 – `URLs` 的源代码
- en: '](img/B16216_02_02.jpg)'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_02.jpg)'
- en: Figure 2.2 – Source for URLs
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.2 – `URLs` 的源代码
- en: 'By looking at the `image classification datasets` section of the source code
    for `URLs`, we can find the definition of `URLs.MNIST`:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过查看 `URLs` 源代码中的 `image classification datasets` 部分，我们可以找到 `URLs.MNIST` 的定义：
- en: '[PRE0]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Working backward through the source code for the `URLs` class, we can get the
    whole URL for MNIST:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过逆向分析 `URLs` 类的源代码，我们可以得到 MNIST 的完整 URL：
- en: '[PRE1]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Putting it all together, we get the URL for `URLs.MNIST`:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 综合来看，我们可以得到 `URLs.MNIST` 的 URL：
- en: '[PRE2]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can download this file for yourself and untar it. You will see that the
    directory structure of the untarred package looks like this:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以自己下载这个文件并解压。你会发现解压后的包的目录结构是这样的：
- en: '[PRE3]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the untarred directory structure, each of the testing and training directories
    contain subdirectories for each digit. These digit directories contain image files
    for that digit. This means that the label of the dataset – the value that we want
    the model to predict – is encoded in the directory that the image file resides
    in.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在解压后的目录结构中，每个测试和训练目录下都有子目录，分别对应每个数字。这些数字目录包含该数字的图像文件。这意味着数据集的标签——我们希望模型预测的值——是通过图像文件所在的目录来编码的。
- en: Is there a way to get the directory structure of one of the curated datasets
    without having to determine its URL from the definition of `URLs`, download the
    dataset, and unpack it? There is – using `path.ls()`:![Figure 2.3 – Using path.ls()
    to get the dataset's directory structure
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有办法获取某个精心策划的数据集的目录结构，而无需从 `URLs` 的定义中确定其 URL、下载数据集并解压？有的 – 使用 `path.ls()`：![图
    2.3 – 使用 path.ls() 获取数据集的目录结构
- en: '](img/B16216_02_03.jpg)'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_03.jpg)'
- en: Figure 2.3 – Using path.ls() to get the dataset's directory structure
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.3 – 使用 path.ls() 获取数据集的目录结构
- en: 'This tells us that there are two subdirectories in the dataset: `training`
    and `testing`. You can call `ls()` to get the structure of the `training` subdirectory:![Figure
    2.4 – The structure of the training subdirectory'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这告诉我们数据集包含两个子目录：`training` 和 `testing`。你可以调用 `ls()` 来获取 `training` 子目录的结构：![图
    2.4 – 训练子目录的结构
- en: '](img/B16216_02_04.jpg)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_04.jpg)'
- en: Figure 2.4 – The structure of the training subdirectory
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.4 – 训练子目录的结构
- en: Now that we have learned how to get the directory structure of the MNIST dataset
    using the `ls()` function, what else can we learn from the output of `??URLs`?
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经学会如何使用 `ls()` 函数获取 MNIST 数据集的目录结构，那么我们还能从 `??URLs` 的输出中学到什么呢？
- en: 'First, let''s look at the other datasets listed in the output of `??URLs` by
    group. First, let''s look at the datasets listed under `main datasets`. This list
    includes tabular datasets (`ADULT_SAMPLE`), text datasets (`IMDB_SAMPLE`), recommender
    system datasets (`ML_SAMPLE`), and a variety of image datasets (`CIFAR, IMAGENETTE,
    COCO_SAMPLE`):'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们按组查看 `??URLs` 输出中列出的其他数据集。首先，查看 `main datasets` 下列出的数据集。这个列表包括表格数据集（`ADULT_SAMPLE`）、文本数据集（`IMDB_SAMPLE`）、推荐系统数据集（`ML_SAMPLE`）以及各种图像数据集（`CIFAR`,
    `IMAGENETTE`, `COCO_SAMPLE`）：
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, let''s look at the datasets in the other categories: image classification
    datasets, NLP datasets, image localization datasets, audio classification datasets,
    and medical image classification datasets. Note that the list of curated datasets
    includes datasets that aren''t directly associated with any of the four main application
    areas supported by fastai. The audio datasets, for example, apply to a use case
    outside the four main application areas:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们看看其他类别的数据集：图像分类数据集、自然语言处理数据集、图像定位数据集、音频分类数据集和医学图像分类数据集。请注意，精心策划的数据集列表中包括一些与
    fastai 支持的四个主要应用领域无关的数据集。例如，音频数据集应用于四个主要应用领域以外的使用场景：
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now that we have listed all the datasets defined in `URLs`, how can we find
    out more information about them?
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经列出了`URLs`中定义的所有数据集，我们如何了解更多信息呢？
- en: a) The fastai documentation ([https://course.fast.ai/datasets](https://course.fast.ai/datasets))
    documents some of the datasets listed in `URLs`. Note that this documentation
    is not consistent with what's listed in the source of `URLs`. For example, the
    naming of the datasets is not consistent and the documentation page does not cover
    all the datasets. When in doubt, treat the source of `URLs` as your single source
    of truth about fastai curated datasets.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) fastai 文档（[https://course.fast.ai/datasets](https://course.fast.ai/datasets)）记录了`URLs`中列出的一些数据集。请注意，这些文档与`URLs`源中的内容不完全一致。例如，数据集的命名不统一，且文档页面未涵盖所有数据集。如有疑问，请将`URLs`源视为你了解
    fastai 策划数据集的唯一可信来源。
- en: 'b) Use the `path.ls()` function to examine the directory structure, as shown
    in the following example, which lists the directories under the `training` subdirectory
    of the MNIST dataset:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 使用`path.ls()`函数来检查目录结构，如下例所示，它列出了MNIST数据集`training`子目录下的目录：
- en: '![Figure 2.5 – Structure of the training subdirectory'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.5 – 训练子目录结构'
- en: '](img/B16216_02_05.jpg)'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_05.jpg)'
- en: '[PRE6]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'e) Here, you can find the dataset in `storage/data/oxford-iiit-pet`, and you
    can see the directory''s structure:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) 在这里，你可以找到`storage/data/oxford-iiit-pet`中的数据集，并查看目录结构：
- en: '[PRE7]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If you want to see the definition of a function in a notebook, you can run a
    cell with `??`, followed by the name of the function. For example, to see the
    definition of the `ls()` function, you can use `??Path.ls`:![Figure 2.6 – Source
    for Path.ls()
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想查看笔记本中某个函数的定义，可以运行一个包含`??`的单元格，后跟函数名。例如，要查看`ls()`函数的定义，你可以使用`??Path.ls`：![图
    2.6 – Path.ls()的来源
- en: '](img/B16216_02_06.jpg)'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_06.jpg)'
- en: Figure 2.6 – Source for Path.ls()
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.6 – Path.ls()的来源
- en: 'To see the documentation for any function, you can use the `doc()` function.
    For example, the output of `doc(Path.ls)` shows the signature of the function,
    along with links to the source code ([https://github.com/fastai/fastcore/blob/master/fastcore/xtras.py#L111](https://github.com/fastai/fastcore/blob/master/fastcore/xtras.py#L111))
    and the documentation ([https://fastcore.fast.ai/xtras#Path.ls](https://fastcore.fast.ai/xtras#Path.ls))
    for this function:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 若要查看任何函数的文档，你可以使用`doc()`函数。例如，`doc(Path.ls)`的输出会显示该函数的签名，并提供指向源代码（[https://github.com/fastai/fastcore/blob/master/fastcore/xtras.py#L111](https://github.com/fastai/fastcore/blob/master/fastcore/xtras.py#L111)）和文档（[https://fastcore.fast.ai/xtras#Path.ls](https://fastcore.fast.ai/xtras#Path.ls)）的链接：
- en: '![Figure 2.7 – Output of doc(Path.ls)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.7 – doc(Path.ls)的输出'
- en: '](img/B16216_02_07.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_02_07.jpg)'
- en: Figure 2.7 – Output of doc(Path.ls)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – doc(Path.ls)的输出
- en: You have now explored the list of oven-ready datasets curated by fastai. You
    have also learned how to get the directory structure of these datasets, as well
    as how to examine the source and documentation of a function from within a notebook.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经浏览了 fastai 策划的即用型数据集列表。你还学会了如何获取这些数据集的目录结构，以及如何从笔记本中检查函数的源代码和文档。
- en: How it works…
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: As you saw in this section, fastai defines URLs for each of the curated datasets
    in the `URLs` class. When you call `untar_data` with one of the curated datasets
    as the argument, if the files for the dataset have not already been copied, these
    files get downloaded to your filesystem (`storage/data` in a Gradient instance).
    The object you get back from `untar_data` allows you to examine the directory
    structure of the dataset, and then pass it along to the next stage in the process
    of creating a fastai deep learning model. By wrapping a large sampling of interesting
    datasets in such a convenient way, fastai makes it easy for you to create deep
    learning models with these datasets, and also lets you focus your efforts on creating
    and improving the deep learning model rather than fiddling with the details of
    ingesting the datasets.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本节中看到的，fastai 为每个策划的数据集在`URLs`类中定义了相应的链接。当你用某个策划数据集作为参数调用`untar_data`时，如果该数据集的文件尚未被复制，这些文件会被下载到你的文件系统中（在
    Gradient 实例中是`storage/data`）。你从`untar_data`获取的对象允许你查看数据集的目录结构，然后将其传递到创建 fastai
    深度学习模型的下一阶段。通过这种便捷的方式包装大量有趣的数据集，fastai 使得你可以轻松地用这些数据集创建深度学习模型，并且可以将精力集中在创建和改进深度学习模型上，而不是在处理数据集导入的细节。
- en: There's more…
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: 'You might be asking yourself why we went to the trouble of examining the source
    code for the `URLs` class to get details about the curated datasets. After all,
    these datasets are documented in [https://course.fast.ai/datasets](https://course.fast.ai/datasets).
    The problem is that this documentation page doesn''t give a complete list of all
    the curated datasets, and it doesn''t clearly explain what you need to know to
    make the correct `untar_data` calls for a particular curated dataset. The incomplete
    documentation for the curated datasets demonstrates one of the weaknesses of fastai
    – *inconsistent documentation*. Sometimes, the documentation is complete, but
    sometimes, it is lacking details, so you will need to look at the source code
    directly to figure out what''s going on, like we had to do in this section for
    the curated datasets. This problem is compounded by Google search returning hits
    for documentation for earlier versions of fastai. If you are searching for some
    details about fastai, avoid hits for fastai version 1 ([https://fastai1.fast.ai/](https://fastai1.fast.ai/))
    and keep to the documentation for the current version of fastai: [https://docs.fast.ai/](https://docs.fast.ai/).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么我们要费力检查 `URLs` 类的源代码以获取有关精心策划数据集的详细信息。毕竟，这些数据集在 [https://course.fast.ai/datasets](https://course.fast.ai/datasets)
    上有文档说明。问题是，这个文档页面没有提供所有精心策划数据集的完整列表，也没有清楚地解释你需要了解什么，以便为特定的精心策划数据集做出正确的 `untar_data`
    调用。精心策划数据集的不完整文档展示了 fastai 的一个弱点——*文档不一致*。有时，文档是完整的，但有时也缺少细节，因此你需要直接查看源代码来弄清楚发生了什么，就像我们在这一节中为精心策划数据集所做的那样。这个问题还被
    Google 搜索的结果所加剧，因为它返回的是早期版本 fastai 的文档。如果你正在搜索有关 fastai 的一些细节，避免进入 fastai 版本 1
    的文档页面（[https://fastai1.fast.ai/](https://fastai1.fast.ai/)），并始终参考当前版本 fastai 的文档：[https://docs.fast.ai/](https://docs.fast.ai/)。
- en: Examining tabular datasets with fastai
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 fastai 检查表格数据集
- en: In the previous section, we looked at the whole set of datasets curated by fastai.
    In this section, we are going to dig into a tabular dataset from the curated list.
    We will ingest the dataset, look at some example records, and then explore characteristics
    of the dataset, including the number of records and the number of unique values
    in each column.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们查看了 fastai 精心策划的所有数据集。在本节中，我们将深入分析精心策划数据集中一个表格数据集。我们将加载数据集，查看一些示例记录，然后探索数据集的特征，包括记录数和每列的唯一值数量。
- en: Getting ready
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, to get a fastai environment set up. Confirm that
    you can open the `examining_tabular_datasets.ipynb` notebook in the `ch2` directory
    of your repository.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已按照 [*第一章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019) 的步骤，*开始使用 fastai*，并已设置好
    fastai 环境。确认你能够在你的仓库的 `ch2` 目录中打开 `examining_tabular_datasets.ipynb` 笔记本。
- en: I am grateful for the opportunity to include the ADULT_SAMPLE dataset featured
    in this section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我很感激有机会在本节中包含 *ADULT_SAMPLE* 数据集。
- en: Dataset citation
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: 'Ron Kohavi. (1996) *Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree
    Hybrid* ([http://robotics.stanford.edu/~ronnyk/nbtree.pdf](http://robotics.stanford.edu/~ronnyk/nbtree.pdf)).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Ron Kohavi. (1996) *提升朴素贝叶斯分类器的准确性：决策树混合模型* ([http://robotics.stanford.edu/~ronnyk/nbtree.pdf](http://robotics.stanford.edu/~ronnyk/nbtree.pdf))。
- en: How to do it…
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: In this section, you will be running through the `examining_tabular_datasets.ipynb`
    notebook to examine the `ADULT_SAMPLE` dataset.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将运行 `examining_tabular_datasets.ipynb` 笔记本来检查 `ADULT_SAMPLE` 数据集。
- en: 'Once you have the notebook open in your fastai environment, complete the following
    steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 fastai 环境中的笔记本后，完成以下步骤：
- en: Run the first two cells to import the necessary libraries and set up the notebook
    for fastai.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前两个单元格，导入必要的库并为 fastai 设置笔记本环境。
- en: 'Run the following cell to copy the dataset into your filesystem (if it''s not
    already there) and to define the path for the dataset:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，将数据集复制到你的文件系统中（如果尚未复制），并定义数据集的路径：
- en: '[PRE8]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Run the following cell to get the output of `path.ls()` so that you can examine
    the directory structure of the dataset:![Figure 2.8 – Output of path.ls()
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，以获取 `path.ls()` 的输出，查看数据集的目录结构：![图 2.8 – `path.ls()` 的输出
- en: '](img/B16216_02_08.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_08.jpg)'
- en: Figure 2.8 – Output of path.ls()
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.8 – `path.ls()` 的输出
- en: 'The dataset is in the `adult.csv` file. Run the following cell to ingest this
    CSV file into a pandas DataFrame:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集位于 `adult.csv` 文件中。运行以下单元格，将此 CSV 文件加载到 pandas DataFrame 中：
- en: '[PRE9]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Run the `head()` command to get a sample of records from the beginning of the
    dataset:![Figure 2.9 – Sample of records from the beginning of the dataset
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`head()`命令以获取数据集开头的记录样本：![图2.9 - 数据集开头的记录样本
- en: '](img/B16216_02_09.jpg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_09.jpg)'
- en: Figure 2.9 – Sample of records from the beginning of the dataset
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.9 - 数据集开头的记录样本
- en: 'Run the following command to get the number of records (rows) and fields (columns)
    in the dataset:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取数据集中的记录数（行数）和字段数（列数）：
- en: '[PRE10]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Run the following command to get the number of unique values in each column
    of the dataset. Can you tell from the output which columns are categorical?
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取数据集中每一列的唯一值数量。你能从输出中看出哪些列是类别型的吗？
- en: '[PRE11]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Run the following command to get the count of missing values in each column
    of the dataset. Which columns have missing values?
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取数据集中每一列的缺失值数量。哪些列有缺失值？
- en: '[PRE12]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Run the following command to display some sample records from the subset of
    the dataset for people whose age is less than or equal to 40:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以显示数据集中年龄小于或等于40岁的人的部分样本记录：
- en: '[PRE13]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Congratulations! You have ingested a tabular dataset curated by fastai and done
    a basic examination of the dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经摄取了fastai精心策划的表格数据集，并对数据集进行了基本的检查。
- en: How it works…
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The dataset that you explored in this section, `ADULT_SAMPLE`, is one of the
    datasets you would have seen in the source for `URLs` in the previous section.
    Note that while the source for `URLs` identifies which datasets are related to
    image or NLP (text) applications, it does not explicitly identify the tabular
    or recommender system datasets. `ADULT_SAMPLE` is one of the datasets listed under
    `main datasets`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你在本节中探索的数据集`ADULT_SAMPLE`，是你在前一节中看到的源中`URLs`部分列出的数据集之一。请注意，虽然`URLs`源识别了哪些数据集与图像或NLP（文本）应用相关，但它没有明确指出哪些是表格数据集或推荐系统数据集。`ADULT_SAMPLE`是`main
    datasets`下列出的数据集之一：
- en: '![Figure 2.10 – Main datasets from the source for URLs'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.10 - 来自URLs源的主要数据集'
- en: '](img/B16216_02_10.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_02_10.jpg)'
- en: Figure 2.10 – Main datasets from the source for URLs
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 - 来自URLs源的主要数据集
- en: How did I determine that `ADULT_SAMPLE` was a tabular dataset? First, the paper
    by Howard and Gugger ([https://arxiv.org/pdf/2002.04688.pdf](https://arxiv.org/pdf/2002.04688.pdf))
    identifies `ADULT_SAMPLE` as a tabular dataset. Second, I just had to ingest it
    and try it out to confirm it could be ingested into a pandas DataFrame.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我是如何确定`ADULT_SAMPLE`是一个表格数据集的呢？首先，Howard和Gugger的论文（[https://arxiv.org/pdf/2002.04688.pdf](https://arxiv.org/pdf/2002.04688.pdf)）将`ADULT_SAMPLE`标识为一个表格数据集。其次，我只需要摄取它并试一试，确认它能被摄取到pandas
    DataFrame中。
- en: There's more…
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'What about the other curated datasets that aren''t explicitly categorized in
    the source for `URLs`? Here''s a summary of the datasets listed in the source
    for `URLs` under `main datasets`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于源中没有明确分类为`URLs`的其他精心策划的数据集怎么办？以下是源中`URLs`下`main datasets`部分列出的数据集总结：
- en: 'Tabular:'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格数据：
- en: a) `ADULT_SAMPLE`
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `ADULT_SAMPLE`
- en: 'NLP (text):'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理（文本）：
- en: a) `HUMAN_NUMBERS  `
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `HUMAN_NUMBERS  `
- en: b) `IMDB`
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `IMDB`
- en: c) `IMDB_SAMPLE      `
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `IMDB_SAMPLE      `
- en: 'Collaborative filtering:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协同过滤：
- en: a) `ML_SAMPLE               `
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `ML_SAMPLE               `
- en: b) `ML_100k                              `
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `ML_100k                              `
- en: 'Image data:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像数据：
- en: a) All of the other datasets listed in `URLs` under `main datasets`.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `URLs`中`main datasets`下列出的所有其他数据集。
- en: Examining text datasets with fastai
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用fastai检查文本数据集
- en: In the previous section, we looked at how a curated tabular dataset could be
    ingested. In this section, we are going to dig into a text dataset from the curated
    list.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们看了如何摄取一个精心策划的表格数据集。在本节中，我们将深入探讨来自精心策划列表的文本数据集。
- en: Getting ready
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, to get a fastai environment set up. Confirm that
    you can open the `examining_text_datasets.ipynb` notebook in the `ch2` directory
    of your repository.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经按照[*第1章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)中的步骤，*快速入门fastai*，设置了fastai环境。确认你能在仓库的`ch2`目录中打开`examining_text_datasets.ipynb`笔记本。
- en: I am grateful for the opportunity to use the WIKITEXT_TINY dataset ([https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/))
    featured in this section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常感激有机会使用本节中提到的WIKITEXT_TINY数据集（[https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/)）。
- en: Dataset citation
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher. (2016). *Pointer
    Sentinel Mixture Models* ([https://arxiv.org/pdf/1609.07843.pdf](https://arxiv.org/pdf/1609.07843.pdf)).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher. (2016). *指针信号量混合模型*
    ([https://arxiv.org/pdf/1609.07843.pdf](https://arxiv.org/pdf/1609.07843.pdf))。
- en: How to do it…
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: In this section, you will be running through the `examining_text_datasets.ipynb`
    notebook to examine the `WIKITEXT_TINY` dataset. As its name suggests, this is
    a small set of text that's been gleaned from good and featured Wikipedia articles.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将运行`examining_text_datasets.ipynb`笔记本，检查`WIKITEXT_TINY`数据集。顾名思义，这是一个从优秀的维基百科文章中提取的小型文本数据集。
- en: 'Once you have the notebook open in your fastai environment, complete the following
    steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在fastai环境中打开了这个笔记本，完成以下步骤：
- en: Run the first two cells to import the necessary libraries and set up the notebook
    for fastai.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前两个单元格来导入必要的库，并为fastai设置笔记本环境。
- en: 'Run the following cell to copy the dataset into your filesystem (if it''s not
    already there) and to define the path for the dataset:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码将数据集复制到你的文件系统中（如果它还没有在那里），并定义数据集的路径：
- en: '[PRE14]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Run the following cell to get the output of `path.ls()` so that you can examine
    the directory structure of the dataset:![Figure 2.11 – Output of path.ls()
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码获取`path.ls()`的输出，以便检查数据集的目录结构：![图2.11 – path.ls()的输出
- en: '](img/B16216_02_11.jpg)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_11.jpg)'
- en: Figure 2.11 – Output of path.ls()
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.11 – path.ls()的输出
- en: 'There are two CSV files that make up this dataset. Let''s ingest each of them
    into a pandas DataFrame, starting with `train.csv`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个数据集由两个CSV文件组成。让我们将它们分别导入到pandas的DataFrame中，首先导入`train.csv`：
- en: '[PRE15]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When you use `head()` to check the DataFrame, you'll notice that something's
    wrong – the CSV file has no header with column names, but by default, `read_csv`
    assumes the first row is the header, so the first row gets misinterpreted as a
    header. As shown in the following screenshot, the first row of output is in bold,
    which indicates that the first row is being interpreted as a header, even though
    it contains a regular data row:![Figure 2.12 – First record in df_train
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你使用`head()`检查DataFrame时，你会发现有些问题——CSV文件没有列名的标题行，但默认情况下，`read_csv`会假设第一行是标题，所以第一行会被误解为标题。如以下截图所示，输出的第一行是粗体的，这表示第一行被解释为标题，尽管它实际上是普通的数据行：![图2.12
    – df_train中的第一条记录
- en: '](img/B16216_02_12.jpg)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_12.jpg)'
- en: Figure 2.12 – First record in df_train
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.12 – df_train中的第一条记录
- en: 'To fix this problem, rerun the `read_csv` function, but this time with the
    `header=None` parameter, to specify that the CSV file doesn''t have a header:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了解决这个问题，重新运行`read_csv`函数，但这次使用`header=None`参数，指定CSV文件没有标题行：
- en: '[PRE16]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Check `head()` again to confirm that the problem has been resolved:![Figure
    2.13 – Revising the first record in df_train
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次检查`head()`，确认问题已解决：![图2.13 – 修正df_train中的第一条记录
- en: '](img/B16216_02_13.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_13.jpg)'
- en: Figure 2.13 – Revising the first record in df_train
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.13 – 修正df_train中的第一条记录
- en: 'Ingest `test.csv` into a DataFrame using the `header=None` parameter:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`header=None`参数将`test.csv`导入DataFrame：
- en: '[PRE17]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We want to tokenize the dataset and transform it into a list of words. Since
    we want a common set of tokens for the entire dataset, we will begin by combining
    the test and train DataFrames:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们希望对数据集进行分词，并将其转换为单词列表。由于我们希望为整个数据集提供一个通用的词汇集，我们将从合并测试集和训练集的DataFrame开始：
- en: '[PRE18]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Confirm the shape of the train, test, and combined dataframes – the number
    of rows in the combined DataFrame should be the sum of the number of rows in the
    train and test DataFrames:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认训练集、测试集和合并数据集的形状——合并后的DataFrame行数应该是训练集和测试集DataFrame行数的总和：
- en: '[PRE19]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we''re ready to tokenize the DataFrame. The `tokenize_df()` function takes
    the list of columns containing the text we want to tokenize as a parameter. Since
    the columns of the DataFrame are not labeled, we need to refer to the column we
    want to tokenize using its position rather than its name:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们准备对DataFrame进行标记。`tokenize_df()`函数将包含我们要标记文本的列的列表作为参数。由于DataFrame的列没有标签，我们需要通过列的位置而不是列名来引用我们想要标记的列：
- en: '[PRE20]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Check the contents of the first few records of `df_tok`, which is the new DataFrame
    containing the tokenized contents of the combined DataFrame:![Figure 2.14 – The
    first few records of df_tok
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`df_tok`的前几条记录，这是包含组合DataFrame标记内容的新DataFrame：![图2.14 – `df_tok`的前几条记录
- en: '](img/B16216_02_14.jpg)'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_14.jpg)'
- en: Figure 2.14 – The first few records of df_tok
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.14 – `df_tok`的前几条记录
- en: 'Check the count for a few sample words to ensure they are roughly what you
    expected. Pick a very common word, a moderately common word, and a rare word:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查一些示例单词的数量，确保它们大致符合预期。选择一个非常常见的单词、一个中等常见的单词和一个罕见的单词：
- en: '[PRE21]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Congratulations! You have successfully ingested, explored, and tokenized a curated
    text dataset.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功加载、探索并标记了一个精选的文本数据集。
- en: How it works…
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The dataset that you explored in this section, `WIKITEXT_TINY`, is one of the
    datasets you would have seen in the source for `URLs` in the *Getting the complete
    set of oven-ready fastai datasets* section. Here, you can see that `WIKITEXT_TINY`
    is in the NLP datasets section of the source for `URLs`:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您在本节中探索的数据集`WIKITEXT_TINY`是您在*获取完整的即用型fastai数据集*一节中看到的`URLs`来源中的数据集之一。在这里，您可以看到`WIKITEXT_TINY`位于`URLs`来源中的NLP数据集部分：
- en: '![Figure 2.15 – WIKITEXT_TINY in the NLP datasets list in the source for URLs'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.15 – `WIKITEXT_TINY`在`URLs`来源中的NLP数据集列表中'
- en: '](img/B16216_02_15.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_02_15.jpg)'
- en: Figure 2.15 – WIKITEXT_TINY in the NLP datasets list in the source for URLs
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15 – `WIKITEXT_TINY`在`URLs`来源中的NLP数据集列表中
- en: Examining image datasets with fastai
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用fastai检查图像数据集
- en: 'In the past two sections, we examined tabular and text datasets and got a taste
    of the facilities that fastai provides for accessing and exploring these datasets.
    In this section, we are going to look at image data. We are going to look at two
    datasets: the `FLOWERS` image classification dataset and the `BIWI_HEAD_POSE`
    image localization dataset.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的两个部分中，我们检查了表格数据和文本数据，并了解了fastai提供的访问和探索这些数据集的功能。在本部分中，我们将查看图像数据。我们将查看两个数据集：`FLOWERS`图像分类数据集和`BIWI_HEAD_POSE`图像定位数据集。
- en: Getting ready
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, to get a fastai environment set up. Confirm that
    you can open the `examining_image_datasets.ipynb` notebook in the `ch2` directory
    of your repository.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已经按照[*第1章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)，“*快速入门fastai*”部分中的步骤设置好fastai环境。确认您可以在代码库的`ch2`目录中打开`examining_image_datasets.ipynb`笔记本。
- en: I am grateful for the opportunity to use the FLOWERS dataset featured in this
    section.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我很感激有机会使用本节中展示的FLOWERS数据集。
- en: Dataset citation
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: Maria-Elena Nilsback, Andrew Zisserman. (2008). *Automated flower classification
    over a large number of classes* ([https://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf](https://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Maria-Elena Nilsback, Andrew Zisserman. (2008). *自动化花卉分类（跨多个类别）* ([https://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf](https://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf))。
- en: I am grateful for the opportunity to use the BIWI_HEAD_POSE dataset featured
    in this section.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我很感激有机会使用本节中展示的BIWI_HEAD_POSE数据集。
- en: Dataset citation
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: Gabriele Fanelli, Thibaut Weise, Juergen Gall, Luc Van Gool. (2011). R*eal Time
    Head Pose Estimation from Consumer Depth Cameras* ([https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11](https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11)).
    Lecture Notes in Computer Science, vol 6835\. Springer, Berlin, Heidelberg [https://doi.org/10.1007/978-3-642-23123-0_11](https://doi.org/10.1007/978-3-642-23123-0_11).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Gabriele Fanelli, Thibaut Weise, Juergen Gall, Luc Van Gool. (2011). *来自消费者深度相机的实时头部姿态估计*
    ([https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11](https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11))。计算机科学讲义，卷
    6835，Springer，柏林，海德堡 [https://doi.org/10.1007/978-3-642-23123-0_11](https://doi.org/10.1007/978-3-642-23123-0_11)。
- en: How to do it…
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: In this section, you will be running through the `examining_image_datasets.ipynb`
    notebook to examine the `FLOWERS` and `BIWI_HEAD_POSE` datasets.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将运行`examining_image_datasets.ipynb`笔记本，以检查`FLOWERS`和`BIWI_HEAD_POSE`数据集。
- en: 'Once you have the notebook open in your fastai environment, complete the following
    steps:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在fastai环境中打开笔记本，完成以下步骤：
- en: Run the first two cells to import the necessary libraries and set up the notebook
    for fastai.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前两个单元以导入必要的库并为fastai设置笔记本环境。
- en: 'Run the following cell to copy the `FLOWERS` dataset into your filesystem (if
    it''s not already there) and to define the path for the dataset:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元以将`FLOWERS`数据集复制到您的文件系统中（如果还没有的话），并为该数据集定义路径：
- en: '[PRE22]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Run the following cell to get the output of `path.ls()` so that you can examine
    the directory structure of the dataset:![Figure 2.16 – Output of path.ls()
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元来获取`path.ls()`的输出，以便您可以检查数据集的目录结构：![图 2.16 – `path.ls()`的输出
- en: '](img/B16216_2_16.jpg)'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_2_16.jpg)'
- en: Figure 2.16 – Output of path.ls()
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.16 – `path.ls()`的输出
- en: Look at the contents of the `valid.txt` file. This indicates that `train.txt`,
    `valid.txt`, and `test.txt` contain lists of the image files that belong to each
    of these datasets:![Figure 2.17 – The first few records of valid.txt
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看`valid.txt`文件的内容。这表明`train.txt`、`valid.txt`和`test.txt`包含属于这些数据集的图像文件列表：![图
    2.17 – `valid.txt`文件的前几个记录
- en: '](img/B16216_2_17.jpg)'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_2_17.jpg)'
- en: Figure 2.17 – The first few records of valid.txt
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.17 – `valid.txt`文件的前几个记录
- en: 'Examine the `jgp` subdirectory:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看`jgp`子目录：
- en: '[PRE23]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Take a look at one of the image files. Note that the `get_image_files()` function
    doesn''t need to be pointed to a particular subdirectory – it recursively collects
    all the image files in a directory and its subdirectories:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看其中一个图像文件。请注意，`get_image_files()`函数不需要指向特定的子目录，它会递归地收集目录及其子目录中的所有图像文件：
- en: '[PRE24]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You should have noticed that the image displayed in the previous step was the
    native size of the image, which makes it rather big for the notebook. To get the
    image at a more appropriate size, apply the `to_thumb` function with the image
    dimension specified as an argument. Note that you might see a different image
    when you run this cell:![Figure 2.18 – Applying to_thumb to an image
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该注意到，在上一步中显示的图像是图像的原始尺寸，这使得它对笔记本来说相当大。为了获取更合适大小的图像，可以应用`to_thumb`函数，并将图像的尺寸作为参数指定。请注意，当您运行此单元时，您可能会看到不同的图像：![图
    2.18 – 对图像应用to_thumb
- en: '](img/B16216_2_18.jpg)'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_2_18.jpg)'
- en: Figure 2.18 – Applying to_thumb to an image
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.18 – 对图像应用to_thumb
- en: 'Now, ingest the `BIWI_HEAD_POSE` dataset:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，导入`BIWI_HEAD_POSE`数据集：
- en: '[PRE25]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Examine the path for this dataset:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看此数据集的路径：
- en: '[PRE26]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Examine the `05` subdirectory:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看`05`子目录：
- en: '[PRE27]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Examine one of the images. Note that you may see a different image:![Figure
    2.19 – One of the images in the BIWI_HEAD_POSE dataset
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看其中一张图像。请注意，您可能会看到不同的图像：![图 2.19 – `BIWI_HEAD_POSE`数据集中的一张图像
- en: '](img/B16216_2_19.jpg)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_2_19.jpg)'
- en: Figure 2.19 – One of the images in the BIWI_HEAD_POSE dataset
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.19 – `BIWI_HEAD_POSE`数据集中的一张图像
- en: 'In addition to the image files, this dataset also includes text files that
    encode the pose depicted in the image. Ingest one of these text files into a pandas
    DataFrame and display it:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了图像文件，此数据集还包括编码图像中所示姿势的文本文件。将其中一个文本文件导入到pandas DataFrame中并显示：
- en: '![Figure 2.20 – The first few records of one of the position text files'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.20 – 其中一个位置文本文件的前几个记录'
- en: '](img/B16216_02_20.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_02_20.jpg)'
- en: Figure 2.20 – The first few records of one of the position text files
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.20 – 其中一个位置文本文件的前几个记录
- en: In this section, you learned how to ingest two different kinds of image datasets,
    explore their directory structure, and examine images from the datasets.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您学习了如何导入两种不同类型的图像数据集，探索它们的目录结构，并检查数据集中的图像。
- en: How it works…
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'You used the same `untar_data()` function to ingest the curated tabular, text,
    and image datasets, and the same `ls()` function to examine the directory structures
    for all the different kinds of datasets. On top of these common facilities, fastai
    provides additional convenience functions for examining image data: `get_image_files()`
    to collect all the image files in a directory tree starting at a given directory,
    and `to_thumb()` to render the image at a size that is suitable for a notebook.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用了相同的 `untar_data()` 函数来加载精心策划的表格、文本和图像数据集，并使用相同的 `ls()` 函数检查所有不同类型数据集的目录结构。除了这些通用功能，fastai
    还提供了额外的便捷函数来检查图像数据：`get_image_files()` 用于收集从指定目录开始的目录树中所有的图像文件，`to_thumb()` 用于以适合笔记本的尺寸渲染图像。
- en: There's more…
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: In addition to image classification datasets (where the goal of the trained
    model is to predict the category of what's displayed in the image) and image localization
    datasets (where the goal is to predict the location in the image of a given feature),
    the fastai curated datasets also include image segmentation datasets where the
    goal is to identify the subsets of an image that contain a particular object,
    including the `CAMVID` and `CAMVID_TINY` datasets.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 除了图像分类数据集（训练模型的目标是预测图像中显示的类别）和图像定位数据集（目标是预测图像中给定特征的位置），fastai 精心策划的数据集还包括图像分割数据集，目标是识别图像中包含特定物体的子集，包括
    `CAMVID` 和 `CAMVID_TINY` 数据集。
- en: Cleaning up raw datasets with fastai
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 fastai 清理原始数据集
- en: 'Now that we have explored a variety of datasets that are curated by fastai,
    there is one more topic left to cover in this chapter: how to clean up datasets
    with fastai. Cleaning up datasets includes dealing with missing values and converting
    categorical values into numeric identifiers. We need to apply these cleanup steps
    to datasets because deep learning models can only be trained with numeric data.
    If we try to train the model with datasets that contain non-numeric data, including
    missing values and alphanumeric identifiers in categorical columns, the training
    process will fail. In this section, we are going to review the facilities provided
    by fastai to make it easy to clean up datasets, and thus make the datasets ready
    to train deep learning models.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了 fastai 精心策划的各种数据集，本章还有一个主题需要介绍：如何使用 fastai 清理数据集。清理数据集包括处理缺失值和将类别值转换为数字标识符。我们需要对数据集应用这些清理步骤，因为深度学习模型只能使用数字数据进行训练。如果我们尝试用包含非数字数据的数据集（如缺失值和类别列中的字母数字标识符）来训练模型，训练过程将会失败。在本节中，我们将回顾
    fastai 提供的工具，使清理数据集变得更加简单，从而使数据集准备好用于训练深度学习模型。
- en: Getting ready
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, to get a fastai environment set up. Confirm that
    you can open the `cleaning_up_datasets.ipynb` notebook in the `ch2` directory
    of your repository.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已按照 [*第一章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019) *快速入门 fastai*
    中的步骤，设置好 fastai 环境。确认你能够在仓库的 `ch2` 目录下打开 `cleaning_up_datasets.ipynb` 笔记本。
- en: How to do it…
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: In this section, you will be running through the `cleaning_up_datasets.ipynb`
    notebook to address missing values in the `ADULT_SAMPLE` dataset and replace categorical
    values with numeric identifiers.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，你将通过运行 `cleaning_up_datasets.ipynb` 笔记本来处理 `ADULT_SAMPLE` 数据集中的缺失值，并将类别值替换为数字标识符。
- en: 'Once you have the notebook open in your fastai environment, complete the following
    steps:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在 fastai 环境中打开笔记本，完成以下步骤：
- en: Run the first two cells to import the necessary libraries and set up the notebook
    for fastai.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前两个单元格，导入必要的库并为 fastai 设置笔记本环境。
- en: Recall the *Examining tabular datasets with fastai* section of this chapter.
    When you checked to see which columns in the `ADULT_SAMPLE` dataset had missing
    values, you found that some columns did indeed have missing values. We are going
    to identify the columns in `ADULT_SAMPLE` that have missing values, and use the
    facilities of fastai to apply transformations to the dataset that deal with the
    missing values in those columns, and then replace those categorical values with
    numeric identifiers.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回想一下本章的*检查表格数据集与 fastai*部分。当你检查 `ADULT_SAMPLE` 数据集中哪些列存在缺失值时，你会发现确实有些列包含缺失值。我们将识别
    `ADULT_SAMPLE` 中缺失值所在的列，并利用 fastai 提供的功能，对这些列的缺失值进行处理，然后将这些类别值替换为数字标识符。
- en: 'First, let''s ingest the `ADULT_SAMPLE` curated dataset again:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们再次获取 `ADULT_SAMPLE` 精心整理的数据集：
- en: '[PRE28]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, create a pandas DataFrame for the dataset and check for the number of
    missing values in each column. Note which columns have missing values:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个 pandas DataFrame 来存储数据集，并检查每列中的缺失值数量。注意哪些列有缺失值：
- en: '[PRE29]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To deal with these missing values (and prepare categorical columns), we will
    use the fastai `TabularPandas` class ([https://docs.fast.ai/tabular.core.html#TabularPandas](https://docs.fast.ai/tabular.core.html#TabularPandas)).
    To use this class, we need to prepare the following parameters:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了处理这些缺失值（并准备分类列），我们将使用 fastai 的 `TabularPandas` 类 ([https://docs.fast.ai/tabular.core.html#TabularPandas](https://docs.fast.ai/tabular.core.html#TabularPandas))。使用此类时，我们需要准备以下参数：
- en: a) `TabularPandas`. Here, we will specify that we want missing values to be
    filled (`FillMissing`) and that we will replace values in categorical columns
    with numeric identifiers (`Categorify`).
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `TabularPandas`。在这里，我们将指定希望填充缺失值（`FillMissing`），并且我们将用数字标识符替换分类列中的值（`Categorify`）。
- en: b) `ADULT_SAMPLE`, the dependent variable is `salary`.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `ADULT_SAMPLE`，其中因变量是 `salary`。
- en: 'c) `cont_cat_split()` ([https://docs.fast.ai/tabular.core.html#cont_cat_split](https://docs.fast.ai/tabular.core.html#cont_cat_split))
    function to automatically identify the continuous and categorical columns:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `cont_cat_split()` ([https://docs.fast.ai/tabular.core.html#cont_cat_split](https://docs.fast.ai/tabular.core.html#cont_cat_split))
    函数，用于自动识别连续列和分类列：
- en: '[PRE30]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, create a `TabularPandas` object called `df_no_missing` using these parameters.
    This object will contain the dataset with missing values replaced and the values
    in the categorical columns replaced with numeric identifiers:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用这些参数创建一个名为 `df_no_missing` 的 `TabularPandas` 对象。这个对象将包含填补了缺失值的数据集，并且分类列中的值已经被替换为数字标识符：
- en: '[PRE31]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Apply the `show` API to `df_no_missing` to display samples of its contents.
    Note that the values in the categorical columns are maintained when the object
    is displayed using `show()`. What about replacing the categorical values with
    numeric identifiers? Don't worry – we'll see that result in the next step:![Figure
    2.21 – The first few records of df_no_missing
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `show` API 显示 `df_no_missing` 的内容示例。请注意，当使用 `show()` 显示该对象时，分类列中的值得以保留。那么，如何将分类值替换为数字标识符呢？别担心——我们将在下一步中看到这个结果：![图
    2.21 – `df_no_missing` 中的前几条记录，分类列中为数字标识符
- en: '](img/B16216_02_21.jpg)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_21.jpg)'
- en: Figure 2.21 – The first few records of df_no_missing
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.21 – `df_no_missing` 中的前几条记录
- en: 'Now, display some sample contents of `df_no_missing` using the `items.head()`
    API. This time, the categorical columns contain the numeric identifiers rather
    than the original values. This is an example of a benefit provided by fastai:
    the switch between the original categorical values and the numeric identifiers
    is handled elegantly. If you need to see the original values, you can use the
    `show()` API, which transforms the numeric values in categorical columns back
    into their original values, while the `items.head()` API shows the actual numeric
    identifiers in the categorical columns:![Figure 2.22 – The first few records of
    df_no_missing with numeric identifiers in categorical columns'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `items.head()` API 显示 `df_no_missing` 的一些示例内容。这时，分类列中包含的是数字标识符，而非原始值。这是
    fastai 提供的一个好处：它优雅地处理了原始分类值与数字标识符之间的切换。如果你需要查看原始值，可以使用 `show()` API，它会将分类列中的数字值转换回原始值，而
    `items.head()` API 显示的是分类列中的实际数字标识符：![图 2.22 – `df_no_missing` 中前几条记录，分类列中为数字标识符
- en: '](img/B16216_02_22.jpg)'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_02_22.jpg)'
- en: Figure 2.22 – The first few records of df_no_missing with numeric identifiers
    in categorical columns
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.22 – `df_no_missing` 中前几条记录，分类列中为数字标识符
- en: 'Finally, let''s confirm that the missing values were handled correctly. As
    you can see, the two columns that originally had missing values no longer have
    missing values in `df_no_missing`:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们确认缺失值是否已正确处理。正如你所看到的，原本有缺失值的两个列在 `df_no_missing` 中已经没有缺失值：
- en: '![Figure 2.23 – Missing values in df_no_missing'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.23 – `df_no_missing` 中的缺失值'
- en: '](img/B16216_02_23.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_02_23.jpg)'
- en: Figure 2.23 – Missing values in df_no_missing
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.23 – `df_no_missing` 中的缺失值
- en: By following these steps, you have seen how fastai makes it easy to prepare
    a dataset to train a deep learning model. It does this by replacing missing values
    and converting the values in the categorical columns into numeric identifiers.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，你已经看到 fastai 如何轻松准备数据集来训练深度学习模型。它通过填补缺失值并将分类列中的值转换为数字标识符来实现这一点。
- en: How it works…
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this section, you saw several ways that fastai makes it easy to perform common
    data preparation steps. The `TabularPandas` class provides a lot of value by making
    it easy to execute common steps to prepare a tabular dataset (including replacing
    missing values and dealing with categorical columns). The `cont_cat_split()` function
    automatically identifies continuous and categorical columns in your dataset. In
    conclusion, fastai makes the cleanup process easy and less error prone than it
    would be if you had to hand code all the functions required to accomplish these
    dataset cleanup steps.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，你看到了一些fastai如何简化常见数据准备步骤的方法。`TabularPandas`类通过简化执行准备表格数据集的常见步骤（包括替换缺失值和处理类别列）提供了很大的价值。`cont_cat_split()`函数会自动识别数据集中的连续和类别列。总的来说，fastai使得数据清理过程变得更容易，且比手动编写所有所需函数来完成这些数据集清理步骤时出错的概率更低。
