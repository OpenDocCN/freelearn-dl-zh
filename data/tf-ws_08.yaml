- en: 8\. Pre-Trained Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8. 预训练网络
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will analyze pre-trained models. You will get hands-on
    experience using the different state-of-the-art model architectures available
    on TensorFlow. You will explore concepts such as transfer learning and fine-tuning
    and look at TensorFlow Hub and its published deep learning resources.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将分析预训练模型。您将通过实践体验使用 TensorFlow 上提供的不同最先进的模型架构。您将探索诸如迁移学习和微调等概念，并了解 TensorFlow
    Hub 及其发布的深度学习资源。
- en: By the end of the chapter, you will be able to use pre-trained models directly
    from TensorFlow and TensorFlow Hub.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够直接使用 TensorFlow 和 TensorFlow Hub 中的预训练模型。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the previous chapter, you learned how **convolution neural networks** (**CNNs**)
    analyze images and learn relevant patterns to classify their main subjects or
    identify objects within them. You also saw the different types of layers used
    for such models.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您学习了 **卷积神经网络**（**CNNs**）如何分析图像并学习相关模式，以便分类其主要对象或识别其中的物体。您还了解了用于此类模型的不同类型的层。
- en: But rather than training a model from scratch, it would be more efficient if
    you could reuse existing models with pre-calculated weights. This is exactly what
    **transfer learning** and **fine-tuning** are about. You will learn how to apply
    these techniques to your own projects and datasets in this chapter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，与其从头开始训练一个模型，不如利用已经计算好的权重重用现有的模型，这样会更高效。这正是 **迁移学习** 和 **微调** 的核心内容。本章中，您将学习如何将这些技术应用到自己的项目和数据集中。
- en: You will also look at the ImageNet competition and the corresponding dataset
    that is used by deep learning researchers to benchmark their models against state-of-the-art
    algorithms. Finally, you will learn how to use TensorFlow Hub's resources to build
    your own model.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您还将了解 ImageNet 比赛以及深度学习研究人员用来将自己的模型与最先进算法进行基准对比的相应数据集。最后，您将学习如何使用 TensorFlow
    Hub 的资源来构建自己的模型。
- en: ImageNet
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ImageNet
- en: ImageNet is a large dataset containing more than 14 million images annotated
    for image classification or object detection. It was first consolidated by Fei-Fei
    Li and her team in 2007\. The goal was to build a dataset that computer vision
    researchers could benefit from.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 是一个大型数据集，包含超过 1400 万张用于图像分类或物体检测的标注图像。它由 Fei-Fei Li 及其团队在 2007 年首次整合。其目标是构建一个计算机视觉研究人员能够受益的数据集。
- en: The dataset was presented for the first time in 2009, and every year since 2010,
    an annual competition called the **ImageNet Large-Scale Visual Recognition Challenge**
    (**ILSVRC**) has been organized for image classification and object detection
    tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集首次在 2009 年发布，自 2010 年起，每年都会组织一场名为 **ImageNet 大规模视觉识别挑战赛**（**ILSVRC**）的年度竞赛，涵盖图像分类和物体检测任务。
- en: '![Figure 8.1: Examples of images from ImageNet'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.1：来自 ImageNet 的图像示例'
- en: '](img/B16341_08_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_08_01.jpg)'
- en: 'Figure 8.1: Examples of images from ImageNet'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1：来自 ImageNet 的图像示例
- en: Over the years, some of the most famous CNN architectures (such as AlexNet,
    Inception, VGG, and ResNet) have achieved amazing results in this ILSVRC competition.
    In the following graph, you can see how some of the most famous CNN architectures
    performed in this competition. In less than 10 years, performance increased from
    50% accuracy to almost 90%.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，一些最著名的卷积神经网络（CNN）架构（如 AlexNet、Inception、VGG 和 ResNet）在 ILSVRC 比赛中取得了惊人的成果。在下面的图表中，您可以看到一些最著名的
    CNN 架构在这场比赛中的表现。在不到 10 年的时间里，性能从 50% 的准确率提升到接近 90%。
- en: '![Figure 8.2: Model benchmarking from paperswithcode.com'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.2：来自 paperswithcode.com 的模型基准测试'
- en: '](img/B16341_08_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_08_02.jpg)'
- en: 'Figure 8.2: Model benchmarking from paperswithcode.com'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2：来自 paperswithcode.com 的模型基准测试
- en: You will see in the next section how you can use transfer learning with these
    models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在下一节中看到如何使用这些模型进行迁移学习。
- en: Transfer Learning
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: In the previous chapter, you got hands-on practice training different CNN models
    for image classification purposes. Even though you achieved good results, the
    models took quite some time to learn the relevant parameters. If you kept training
    the models, you could have achieved even better results. Using **graphical processing
    units** (**GPUs**) can shorten the training time, but it will still take a bit
    of time, especially for bigger or more complex datasets.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你亲自实践了训练不同的CNN模型进行图像分类。尽管你取得了不错的结果，但模型花费了相当长的时间来学习相关参数。如果你继续训练这些模型，可能会得到更好的结果。使用**图形处理单元**（**GPUs**）可以缩短训练时间，但它仍然需要一些时间，尤其是在处理更大或更复杂的数据集时。
- en: Deep learning researchers have published their work for the benefit of the community.
    Everyone can benefit by taking existing model architectures and customizing them,
    rather than designing architectures from scratch. More than this though, researchers
    also share the weights of their models. You can then not only reuse an architecture
    but also leverage all the training performed on it. This is what transfer learning
    is about. By reusing pre-trained models, you don't have to start from scratch.
    These models are trained on a large dataset such as ImageNet and have learned
    how to recognize thousands of different categories of objects. You can reuse these
    state-of-the-art models straight out of the box without having to train them.
    Isn't that amazing? Rather than training a model for weeks, you can now just use
    an existing model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习研究人员已经发布了他们的工作，以造福社区。每个人都可以通过采用现有的模型架构并进行定制，而不是从零开始设计架构，来获益。更重要的是，研究人员还分享了他们模型的权重。这样，你不仅可以重用一个架构，还可以利用它已经进行的所有训练。这就是迁移学习的核心。通过重用预训练模型，你无需从头开始。这些模型是经过大规模数据集（如ImageNet）训练的，已经学会了如何识别成千上万种不同类别的物体。你可以直接使用这些最新的模型，而无需再次训练它们。是不是很棒？与其训练一个模型几个星期，你现在可以直接使用现有的模型。
- en: TensorFlow provides a list of state-of-the-art models pre-trained on the ImageNet
    dataset for transfer learning in its Keras API.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow提供了一个经过ImageNet数据集预训练的最新模型列表，可用于其Keras API中的迁移学习。
- en: Note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the full list of pre-trained models available in TensorFlow at
    the following link: [https://www.tensorflow.org/api_docs/python/tf/keras/applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接找到TensorFlow中提供的所有预训练模型的完整列表：[https://www.tensorflow.org/api_docs/python/tf/keras/applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications)。
- en: 'Importing a pre-trained model is quite simple in TensorFlow, as shown with
    the following example, where you load the `InceptionV3` model:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中导入预训练模型非常简单，如以下示例所示，其中你加载了`InceptionV3`模型：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now that you have imported the class for the pre-trained model, you need to
    instantiate it by specifying the dimensions of the input image and `imagenet`
    as the pre-trained weights to be loaded:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经导入了预训练模型的类，你需要通过指定输入图像的尺寸和`imagenet`作为要加载的预训练权重来实例化它：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `include_top=True` parameter specifies that you will be re-using the exact
    same top layer (which is the final layer) as for the original model trained on
    ImageNet. This means that the last layer is designed to predict the 1,000 classes
    that are in this dataset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`include_top=True`参数指定你将重用与原始在ImageNet上训练的模型相同的顶层（即最后一层）。这意味着最后一层是用来预测该数据集中1,000个类别的。'
- en: 'Now that you have instantiated your pre-trained model, you can make predictions
    from it:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经实例化了预训练模型，你可以从中进行预测：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you want to use this pre-trained model to predict different categories than
    the ones from ImageNet, you will need to replace the top layer with another one
    that will be trained to recognize the specific categories of the input dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用这个预训练模型来预测与ImageNet类别不同的类别，你需要将顶层替换为另一个将被训练来识别输入数据集中特定类别的层。
- en: 'First, you need to remove this layer by specifying `include_top=False`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要通过指定`include_top=False`来移除这个层：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the preceding example, you have loaded an `InceptionV3` model. The next
    step will be to *freeze* all the layers from this model so that their weights
    will not be updated:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你已经加载了一个`InceptionV3`模型。下一步将是*冻结*这个模型的所有层，这样它们的权重就不会被更新：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After this, you will instantiate a new fully connected layer with the number
    of units and activation function of your choice. In the following example, you
    want to predict 50 different classes. To do this, you create a dense layer with
    `20` units and use softmax as the activation function:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，您将实例化一个新的全连接层，设置所需的单元数量和激活函数。在以下示例中，您希望预测 50 个不同的类别。为此，您创建一个具有 `20` 个单元的密集层，并使用
    softmax 作为激活函数：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then you need to add this fully connected layer to your base model with the
    Sequential API from Keras:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您需要使用 Keras 的 Sequential API 将这个全连接层添加到您的基础模型中：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, you can train this model and only the top-layer weights will be updated.
    All the other layers have been frozen:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以训练这个模型，并且只有顶层的权重会被更新。其他所有层都已被冻结：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In just a few lines of code, you have loaded the Inception V3 model, which is
    a state-of-the-art model that won the ILSVRC competition in 2016\. You learned
    how to adapt it to your own project and dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 仅用几行代码，您就加载了 Inception V3 模型，这是一个在 2016 年 ILSVRC 比赛中获胜的最先进的模型。您学会了如何将其适应到自己的项目和数据集中。
- en: In the next exercise, you will have hands-on practice on transfer learning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，您将亲手实践迁移学习。
- en: 'Exercise 8.01: Classifying Cats and Dogs with Transfer Learning'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 8.01：使用迁移学习对猫和狗进行分类
- en: In this exercise, you will use transfer learning to correctly classify images
    as either cats or dogs. You will use a pre-trained model, NASNet-Mobile, that
    is already available in TensorFlow. This model comes with pre-trained weights
    on ImageNet.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将使用迁移学习正确地将图像分类为猫或狗。您将使用一个预训练的模型 NASNet-Mobile，该模型已经在 TensorFlow 中可用，并且带有
    ImageNet 上的预训练权重。
- en: Note
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The original dataset used in this exercise has been provided by Google. It contains
    25,000 images of dogs and cats. It can be found here: [https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip](https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习中使用的原始数据集由 Google 提供。该数据集包含 25,000 张猫和狗的图像，可以在此找到：[https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip](https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip)。
- en: Open a new Jupyter notebook.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter notebook。
- en: 'Import the TensorFlow library:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 TensorFlow 库：
- en: '[PRE8]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create a variable called `file_url` containing a link to the dataset:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `file_url` 的变量，包含数据集的链接：
- en: '[PRE9]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Download the dataset using `tf.keras.get_file`, with `''cats_and_dogs.zip''`,
    `origin=file_url`, and `extract=True` as parameters, and save the result to a
    variable called `zip_dir`:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tf.keras.get_file` 下载数据集，参数为 `'cats_and_dogs.zip'`、`origin=file_url` 和 `extract=True`，并将结果保存到一个名为
    `zip_dir` 的变量中：
- en: '[PRE10]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Import the `pathlib` library:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pathlib` 库：
- en: '[PRE11]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Create a variable called `path` containing the full path to the `cats_and_dogs_filtered`
    directory using `pathlib.Path(zip_dir).parent`:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `path` 的变量，使用 `pathlib.Path(zip_dir).parent` 获取 `cats_and_dogs_filtered`
    目录的完整路径：
- en: '[PRE12]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create two variables called `train_dir` and `validation_dir` that take the
    full path to the `train` and `validation` folders, respectively:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别叫做 `train_dir` 和 `validation_dir`，它们分别表示 `train` 和 `validation` 文件夹的完整路径：
- en: '[PRE13]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create four variables called `train_cats_dir`, `train_dogs_dir`, `validation_cats_dir`,
    and `validation_dogs_dir` that take the full path to the `cats` and `dogs` folders
    for the train and validation sets, respectively:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建四个变量，分别叫做 `train_cats_dir`、`train_dogs_dir`、`validation_cats_dir` 和 `validation_dogs_dir`，它们分别表示训练集和验证集中的
    `cats` 和 `dogs` 文件夹的完整路径：
- en: '[PRE14]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Import the `os` package. In the next step, you will need to count the number
    of images from a folder:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `os` 包。接下来的步骤中，您需要计算文件夹中图像的数量：
- en: '[PRE15]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create two variables called `total_train` and `total_val` that get the number
    of images for the training and validation sets:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别叫做 `total_train` 和 `total_val`，用于获取训练集和验证集的图像数量：
- en: '[PRE16]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tensorflow.keras.preprocessing` 导入 `ImageDataGenerator`：
- en: '[PRE17]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Instantiate two `ImageDataGenerator` classes and call them `train_image_generator`
    and `validation_image_generator`. These will rescale images by dividing by `255`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化两个 `ImageDataGenerator` 类，并将它们命名为 `train_image_generator` 和 `validation_image_generator`。这两个类将通过除以
    `255` 来重新缩放图像：
- en: '[PRE18]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Create three variables called `batch_size`, `img_height`, and `img_width` that
    take the values `16`, `224`, and `224`, respectively:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建三个变量，分别叫做 `batch_size`、`img_height` 和 `img_width`，它们的值分别是 `16`、`224` 和 `224`：
- en: '[PRE19]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create a data generator called `train_data_gen` using `flow_from_directory()`
    method, and specify the batch size, the path to the training folder, the size
    of the target, and the mode of the class:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`flow_from_directory()`方法创建一个名为`train_data_gen`的数据生成器，并指定批量大小、训练文件夹的路径、目标大小和类别模式：
- en: '[PRE20]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Create a data generator called `val_data_gen` using `flow_from_directory()`
    method and specify the batch size, the path to the validation folder, the size
    of the target, and the mode of the class:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`flow_from_directory()`方法创建一个名为`val_data_gen`的数据生成器，并指定批量大小、验证文件夹的路径、目标大小和类别模式：
- en: '[PRE21]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras`导入`numpy`为`np`，`tensorflow`为`tf`，并导入`layers`：
- en: '[PRE22]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Set `8` (this is totally arbitrary) as `seed` for NumPy and TensorFlow:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`8`（完全是随便设定的）作为NumPy和TensorFlow的`seed`：
- en: '[PRE23]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Import the `NASNETMobile` model from `tensorflow.keras.applications`:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.applications`导入`NASNETMobile`模型：
- en: '[PRE24]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Instantiate the model with the ImageNet weights, remove the top layer, and specify
    the correct input dimensions:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用ImageNet权重实例化模型，移除顶层，并指定正确的输入维度：
- en: '[PRE25]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Freeze all the layers of this model:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 冻结此模型的所有层：
- en: '[PRE26]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Print a summary of the model using the `summary()` method:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`summary()`方法打印模型的摘要：
- en: '[PRE27]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The expected output will be as follows:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 8.3: Summary of the model'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.3：模型摘要'
- en: '](img/B16341_08_03.jpg)'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_08_03.jpg)'
- en: 'Figure 8.3: Summary of the model'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.3：模型摘要
- en: 'Create a new model that combines the `NASNETMobile` model with two new top
    layers with `500` and `1` unit(s) and ReLu and sigmoid as the activation functions:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新模型，将`NASNETMobile`模型与两个新的顶层（分别为`500`和`1`个单元）及ReLU和sigmoid激活函数结合：
- en: '[PRE28]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Compile the model by providing `binary_crossentropy` as the `loss` function,
    an Adam optimizer with a learning rate of `0.001`, and `accuracy` as the metric
    to be displayed:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供`binary_crossentropy`作为`loss`函数，Adam优化器的学习率为`0.001`，并将`accuracy`作为要显示的指标，来编译模型：
- en: '[PRE29]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Fit the model, provide the train and validation data generators, and run it
    for five epochs:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型，提供训练和验证数据生成器，并运行五个周期：
- en: '[PRE30]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The expected output is as follows:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 8.4: Model training output'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.4：模型训练输出'
- en: '](img/B16341_08_04.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_08_04.jpg)'
- en: 'Figure 8.4: Model training output'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4：模型训练输出
- en: You can observe that the model achieved an accuracy score of `0.99` on the training
    set and `0.98` on the validation set. This is quite a remarkable result given
    that you only trained the last two layers, and it took less than a minute. This
    is the benefit of applying transfer learning and using pre-trained state-of-the-art
    models.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以观察到，模型在训练集上达到了`0.99`的准确率，在验证集上达到了`0.98`的准确率。考虑到您只训练了最后两层，并且训练时间不到一分钟，这是一个相当了不起的结果。这就是应用迁移学习和使用预训练的最先进模型的好处。
- en: In the next section, you will see how you can apply fine-tuning to a pre-trained
    model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将看到如何对一个预训练模型进行微调。
- en: Fine-Tuning
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调
- en: Previously, you used transfer learning to leverage pre-trained models on your
    own dataset. You used the weights of state-of-the-art models that have been trained
    on large datasets such as ImageNet. These models learned the relevant parameters
    to recognize different patterns from images and helped you to achieve amazing
    results on different datasets.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，您使用迁移学习将预训练模型应用到您自己的数据集上。您使用了在像ImageNet这样的庞大数据集上训练的最先进模型的权重。这些模型学会了识别图像中的不同模式的相关参数，并帮助您在不同数据集上取得了惊人的结果。
- en: But there is a catch with this approach. Transfer learning works well in general
    if the classes you are trying to predict belong to the same list as that of ImageNet.
    If this is the case, the weight learned from ImageNet will also be relevant to
    your dataset. For example, the `cats` and `dogs` classes from the preceding exercise
    are present in ImageNet, so its weights will also be relevant for this dataset.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这种方法有一个问题。迁移学习通常效果很好，前提是您尝试预测的类别属于与ImageNet相同的类别列表。如果是这种情况，从ImageNet学到的权重也会与您的数据集相关。例如，上一个练习中的`cats`和`dogs`类别就存在于ImageNet中，因此其权重对于这个数据集也会有用。
- en: However, if your dataset is very different from ImageNet, then the weights from
    these pre-trained models may not all be relevant. For example, if your dataset
    contains satellite images, and you are trying to determine whether a house has
    solar panels installed on its roof, this will be very different compared to ImageNet.
    The weights from the last layers will be very specific to the classes from ImageNet,
    such as cat whiskers or car wheels (which are not very useful for the satellite
    image dataset case), while the ones from earlier layers will be more generic,
    such as for detecting shapes, colors, or texture (which can be applied to the
    satellite image dataset).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你的数据集与ImageNet非常不同，那么这些预训练模型的权重可能并不完全适用。例如，如果你的数据集包含卫星图像，而你试图判断房屋屋顶是否安装了太阳能板，这与ImageNet的数据集相比会有很大不同。最后几层的权重将非常特定于ImageNet中的类别，例如猫胡须或汽车车轮（对于卫星图像数据集来说这些并不太有用），而早期层的权重则更为通用，如用于检测形状、颜色或纹理（这些可以应用于卫星图像数据集）。
- en: So, it will be great to still leverage some of the weights from earlier layers
    but train the final layers so that your models can learn the specific patterns
    relevant to your dataset and improve its performance.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，仍然利用早期层的一些权重是很有帮助的，但需要训练最终层，使得模型能够学习与你的数据集相关的特定模式，并提高其性能。
- en: 'This technique is called fine-tuning. The idea behind it is quite simple: you
    freeze early layers and update the weights of the final layers only. Let''s see
    how you can achieve this in TensorFlow:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术称为微调。其背后的理念非常简单：你冻结早期的层，只更新最终层的权重。让我们看看如何在TensorFlow中实现这一点：
- en: 'First, instantiate a pre-trained `MobileNetV2` model without the top layer:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，实例化一个没有顶层的预训练`MobileNetV2`模型：
- en: '[PRE31]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, iterate through the first layers and freeze them by setting them as non-trainable.
    In the following example, you will freeze only the first `100` layers:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，遍历前几层，并通过将其设置为不可训练来冻结它们。在以下示例中，你将只冻结前`100`层：
- en: '[PRE32]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now you need to add your custom top layer to your base model. In the following
    example, you will be predicting 20 different classes, so you need to add a fully
    connected layer of `20` units with the softmax activation function:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你需要将自定义的顶层添加到基础模型中。在以下示例中，你将预测20个不同的类别，因此需要添加一个包含`20`个单元并使用softmax激活函数的全连接层：
- en: '[PRE33]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, you will compile and then train this model:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你将编译并训练这个模型：
- en: '[PRE34]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This will display a number of logs, as seen in the following screenshot:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示一系列日志，如以下截图所示：
- en: '![Figure 8.5: Fine-tuning results on a pre-trained MobileNetV2 model'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.5：在预训练的MobileNetV2模型上进行微调的结果'
- en: '](img/B16341_08_05.jpg)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_08_05.jpg)'
- en: 'Figure 8.5: Fine-tuning results on a pre-trained MobileNetV2 model'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5：在预训练的MobileNetV2模型上进行微调的结果
- en: That's it. You have just performed fine-tuning on a pre-trained MobileNetV2
    model. You have used the first 100 pre-trained weights from ImageNet and only
    updated the weights from layer 100 onward according to your dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。你已经在一个预训练的MobileNetV2模型上进行了微调。你使用了ImageNet的前100个预训练权重，并仅根据你的数据集更新了从第100层开始的权重。
- en: In the next activity, you will put into practice what you have just learned
    and apply fine-tuning to a pre-trained model.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的活动中，你将实践刚刚学到的内容，并将微调应用于一个预训练的模型。
- en: 'Activity 8.01: Fruit Classification with Fine-Tuning'
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 8.01：使用微调进行水果分类
- en: The `Fruits 360` dataset ([https://arxiv.org/abs/1712.00580](https://arxiv.org/abs/1712.00580)),
    which was originally shared by *Horea Muresan and Mihai Oltean, Fruit recognition
    from images using deep learning, Acta Univ. Sapientiae, Informatica Vol. 10, Issue
    1, pp. 26-42, 2018*, contains more than 82,000 images of 120 different types of
    fruit. You will be using a subset of this dataset with more than 16,000 images.
    The numbers of images in the training and validation sets are `11398` and `4752`
    respectively.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`Fruits 360`数据集（[https://arxiv.org/abs/1712.00580](https://arxiv.org/abs/1712.00580)），最初由*Horea
    Muresan 和 Mihai Oltean, 通过深度学习从图像中识别水果，Acta Univ. Sapientiae, Informatica Vol.
    10, Issue 1, pp. 26-42, 2018*共享，包含超过82,000张120种不同类型水果的图像。你将使用该数据集的一个子集，其中包含超过16,000张图像。训练集和验证集的图像数量分别为`11398`和`4752`。'
- en: In this activity, you are tasked with training a `NASNetMobile` model to recognize
    images of different varieties of fruits (classification into 120 different classes).
    You will use fine-tuning to train the final layers of this model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你的任务是训练一个`NASNetMobile`模型来识别不同种类的水果图像（分类为120个不同的类别）。你将使用微调来训练这个模型的最终层。
- en: Note
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset can be found here: [http://packt.link/OFUJj](http://packt.link/OFUJj).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以在这里找到：[http://packt.link/OFUJj](http://packt.link/OFUJj)。
- en: 'The following steps will help you to complete this activity:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成此活动：
- en: Import the dataset and unzip the file using TensorFlow.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 导入数据集并解压文件。
- en: 'Create a data generator with the following data augmentation:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个数据生成器，使用以下数据增强：
- en: '[PRE35]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Load a pre-trained `NASNetMobile` model from TensorFlow.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 TensorFlow 加载一个预训练的 `NASNetMobile` 模型。
- en: Freeze the first `600` layers of the model.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 冻结模型的前 `600` 层。
- en: 'Add two fully connected layers on top of `NASNetMobile`:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `NASNetMobile` 上添加两个全连接层：
- en: – A fully connected layer with `Dense(1000, activation=relu)`
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 一个全连接层，`Dense(1000, activation=relu)`
- en: – A fully connected layer with `Dense(120, activation='softmax')`
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 一个全连接层，`Dense(120, activation='softmax')`
- en: Specify an Adam optimizer with a learning rate of `0.001`.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定一个学习率为 `0.001` 的 Adam 优化器。
- en: Train the model.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: Evaluate the model on the test set.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上评估模型。
- en: 'The expected output is as follows:'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 8.6: Expected output of the activity'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.6：活动的预期输出](img/B16341_08_06.jpg)'
- en: '](img/B16341_08_06.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_08_06.jpg)'
- en: 'Figure 8.6: Expected output of the activity'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6：活动的预期输出
- en: Note
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor274).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以通过[这个链接](B16341_Solution_ePub.xhtml#_idTextAnchor274)找到。
- en: Now that you know how to use pre-trained models from TensorFlow, you will learn
    how models can be accessed from TensorFlow Hub in the following section.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了如何使用来自 TensorFlow 的预训练模型，接下来你将学习如何从 TensorFlow Hub 获取模型。
- en: TensorFlow Hub
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Hub
- en: TensorFlow Hub is a repository of TensorFlow modules shared by publishers such
    as Google, NVIDIA, and Kaggle. TensorFlow modules are self-contained models built
    on TensorFlow that can be reused for different tasks. Put simply, it is an external
    collection of published TensorFlow modules for transfer learning and fine-tuning.
    With TensorFlow Hub, you can access different deep learning models or weights
    than the ones provided directly from TensorFlow's core API.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub 是一个由 Google、NVIDIA 和 Kaggle 等出版商共享的 TensorFlow 模块库。TensorFlow
    模块是基于 TensorFlow 构建的自包含模型，可以用于不同的任务。简单来说，它是一个外部集合，包含了用于迁移学习和微调的发布的 TensorFlow
    模块。通过 TensorFlow Hub，你可以访问不同于直接通过 TensorFlow 核心 API 提供的深度学习模型或权重。
- en: Note
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: 'You can find more information about TensorFlow Hub here: [https://tfhub.dev/](https://tfhub.dev/).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到关于 TensorFlow Hub 的更多信息：[https://tfhub.dev/](https://tfhub.dev/)。
- en: 'In order to use it, you first need to install it:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用它，你首先需要安装它：
- en: '[PRE36]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Once it''s installed, you can load available classification models with the
    `load()` method by specifying the link to a module:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，你可以使用 `load()` 方法加载可用的分类模型，并指定模块的链接：
- en: '[PRE37]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In the preceding example, you have loaded the **EfficientNet B0** model, which
    was trained on ImageNet. You can find more details on this at the TensorFlow Hub
    page: [https://tfhub.dev/tensorflow/efficientnet/b0/classification/1](https://tfhub.dev/tensorflow/efficientnet/b0/classification/1).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，你加载了**EfficientNet B0**模型，该模型是在 ImageNet 上训练的。你可以在 TensorFlow Hub 页面找到更多关于它的细节：[https://tfhub.dev/tensorflow/efficientnet/b0/classification/1](https://tfhub.dev/tensorflow/efficientnet/b0/classification/1)。
- en: Note
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: 'TensorFlow Hub provides a search engine to find a specific module: [https://tfhub.dev/s?subtype=module,placeholder](https://tfhub.dev/s?subtype=module,placeholder).'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub 提供了一个搜索引擎，帮助你找到特定的模块：[https://tfhub.dev/s?subtype=module,placeholder](https://tfhub.dev/s?subtype=module,placeholder)。
- en: 'By default, modules loaded from TensorFlow Hub contain the final layer of a
    model without an activation function. For classification purposes, you need to
    add an activation layer of your choice. To do so, you can use the Sequential API
    from Keras. You just need to convert your model into a Keras layer with the `KerasLayer`
    class:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，从 TensorFlow Hub 加载的模块包含模型的最终层，但没有激活函数。对于分类任务，你需要添加一个激活层。为此，你可以使用 Keras
    的 Sequential API。只需使用 `KerasLayer` 类将模型转换为 Keras 层：
- en: '[PRE38]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, you can use your final model to perform predictions:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用最终模型进行预测：
- en: '[PRE39]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: You just performed transfer learning with a model from TensorFlow Hub. This
    is very similar to what you learned previously using the Keras API, where you
    loaded an entire model with `include_top=True`. With TensorFlow Hub, you can access
    a library of pre-trained models for object detection or image segmentation.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚使用来自 TensorFlow Hub 的模型进行了迁移学习。这与之前使用 Keras API 学习的内容非常相似，在 Keras 中，你通过设置
    `include_top=True` 加载了一个完整的模型。使用 TensorFlow Hub，你可以访问一个预训练模型库，用于物体检测或图像分割。
- en: In the next section, you will learn how to extract features from TensorFlow
    Hub pre-trained modules.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，你将学习如何从 TensorFlow Hub 预训练模块中提取特征。
- en: Feature Extraction
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取
- en: 'TensorFlow Hub provides the option of downloading a model without the final
    layer. In this case, you will be using a TensorFlow module as a feature extractor;
    you can design your custom final layers on top of it. In TensorFlow Hub, a module
    used for feature extraction is known as a feature vector:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub 提供了下载没有最终层的模型的选项。在这种情况下，你将使用 TensorFlow 模块作为特征提取器；你可以在其上设计自定义的最终层。在
    TensorFlow Hub 中，用于特征提取的模块被称为特征向量：
- en: '[PRE40]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Note
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'To find all the available feature vectors on TensorFlow Hub, you can use its
    search engine: [https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2](https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 若要查找 TensorFlow Hub 上所有可用的特征向量，你可以使用其搜索引擎：[https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2](https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2)。
- en: 'Once loaded, you can add your own final layer to the feature vector with the
    Sequential API:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦加载，你可以通过 Sequential API 将自己的最终层添加到特征向量上：
- en: '[PRE41]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In the preceding example, you added a fully connected layer of `20` units with
    the softmax activation function. Next, you need to compile and train your model:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你添加了一个包含 `20` 单元的全连接层，并使用了 softmax 激活函数。接下来，你需要编译并训练你的模型：
- en: '[PRE42]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: And with that, you just used a feature vector from TensorFlow Hub and added
    your custom final layer to train the final model on your dataset.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，你已经使用了 TensorFlow Hub 上的特征向量，并添加了自定义的最终层，以便在你的数据集上训练最终的模型。
- en: Now, test the knowledge you have gained so far in the next activity.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，测试一下你到目前为止所获得的知识，在下一活动中进行验证。
- en: 'Activity 8.02: Transfer Learning with TensorFlow Hub'
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 8.02：使用 TensorFlow Hub 进行迁移学习
- en: In this activity, you are required to correctly classify images of cats and
    dogs using transfer learning. Rather than training a model from scratch, you will
    benefit from the **EfficientNet B0** feature vector from TensorFlow Hub, which
    contains pre-computed weights that can recognize different types of objects.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，你需要通过迁移学习正确分类猫狗图片。与从头开始训练模型不同，你将从 TensorFlow Hub 获取**EfficientNet B0**特征向量，该特征向量包含了预计算的权重，可以识别不同类型的物体。
- en: 'You can find the dataset here: [https://packt.link/RAAtm](https://packt.link/RAAtm).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到数据集：[https://packt.link/RAAtm](https://packt.link/RAAtm)。
- en: 'The following steps will help you to complete this activity:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成此活动：
- en: Import the dataset and unzip the file using TensorFlow.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 导入数据集并解压文件。
- en: Create a data generator that will perform rescaling.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个数据生成器，用于执行重缩放。
- en: Load a pre-trained **EfficientNet B0** feature vector from TensorFlow Hub.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 TensorFlow Hub 加载预训练的**EfficientNet B0**特征向量。
- en: 'Add two fully connected layers on top of the feature vector:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在特征向量上添加两个全连接层：
- en: – A fully connected layer with `Dense(500, activation=relu)`
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 一个全连接层，使用`Dense(500, activation=relu)`
- en: – A fully connected layer with `Dense(1, activation='sigmoid')`
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 一个全连接层，使用`Dense(1, activation='sigmoid')`
- en: Specify an Adam optimizer with a learning rate of `0.001`.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定一个学习率为`0.001`的 Adam 优化器。
- en: Train the model.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: Evaluate the model on the test set.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上评估模型。
- en: 'The expected output is as follows:'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 8.7: Expected output of the activity'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.7：活动的预期输出'
- en: '](img/B16341_08_07.jpg)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_08_07.jpg)'
- en: 'Figure 8.7: Expected output of the activity'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7：活动的预期输出
- en: The expected accuracy scores should be around `1.0` for the training and validation
    sets.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的准确率应该在训练集和验证集上达到 `1.0` 左右。
- en: Note
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor277).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以通过[此链接](B16341_Solution_ePub.xhtml#_idTextAnchor277)找到。
- en: Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you learned two very important concepts: transfer learning
    and fine-tuning. Both help deep learning practitioners to leverage existing pre-trained
    models and adapt them to their own projects and datasets.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了两个非常重要的概念：迁移学习和微调。两者都帮助深度学习实践者利用现有的预训练模型，并将其适应自己的项目和数据集。
- en: Transfer learning is the re-use of models that have been trained on large datasets
    such as ImageNet (which contains more than 14 million images). TensorFlow provides
    a list of such pre-trained models in its core API. You can also access other models
    from renowned publishers such as Google and NVIDIA through TensorFlow Hub.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是重复使用已在大型数据集（如ImageNet，其中包含超过1400万张图像）上训练过的模型。TensorFlow在其核心API中提供了这类预训练模型的列表。您还可以通过TensorFlow
    Hub访问来自谷歌和NVIDIA等知名出版商的其他模型。
- en: Finally, you got some hands-on practice fine-tuning a pre-trained model. You
    learned how to freeze the early layers of a model and only train the last layers
    according to the specificities of the input dataset.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您进行了一些动手实践，微调了一个预训练模型。您学会了如何冻结模型的早期层，并根据输入数据集的特定要求仅训练最后几层。
- en: These two techniques were a major breakthrough for the community as they facilitated
    access to state-of-the-art models for anyone interested in applying deep learning
    models.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种技术对社区来说是一项重大突破，因为它们为有意应用深度学习模型的任何人提供了访问先进模型的便利。
- en: In the next chapter, you will look at another type of model architecture, **recurrent
    neural networks** (**RNNs**). This type of architecture is well suited for sequential
    data such as time series or text.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，您将研究另一种类型的模型架构，**循环神经网络**（**RNNs**）。这种类型的架构非常适合顺序数据，如时间序列或文本。
