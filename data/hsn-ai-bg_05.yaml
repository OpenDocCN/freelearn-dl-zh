- en: Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: '**Convolutional Neural Networks** (**CNNs**), or **ConvNets**, are a special
    class of feedforward networks; they are primarily used for computer vision tasks,
    but have also been adapted to other domains with unstructured data, such as natural
    language processing. As they are feedforward networks, they are very similar to
    the simple networks that we just learned about; information passes through them
    in one direction, and they are made up of layers, weights, and biases.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNN**），或称**ConvNets**，是前馈网络的一个特殊类别；它们主要用于计算机视觉任务，但也已被应用于其他具有非结构化数据的领域，例如自然语言处理。由于它们是前馈网络，它们与我们刚刚学习的简单网络非常相似；信息沿着一个方向传递，且由层、权重和偏差组成。'
- en: CNNs are the image recognition methods used by Facebook for image tagging, Amazon
    for product recommendations, and by self-driving cars for recognizing objects
    in their field of vision. In this chapter, we'll discuss the functions that make
    CNNs different from standard feedforward networks, and then jump into some examples
    of how to apply them to a variety of tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: CNN是Facebook用于图像标签、亚马逊用于产品推荐、以及自动驾驶汽车用于识别视野中物体的图像识别方法。在本章中，我们将讨论使CNN不同于标准前馈网络的功能，并举一些示例说明如何将其应用于多种任务。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Convolutions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积
- en: Pooling layers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化层
- en: Fully formed convolutional neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的卷积神经网络
- en: Convolutional neural networks for image tagging
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于图像标签的卷积神经网络
- en: Overview of CNNs
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN概述
- en: CNNs are one of the most influential classes of networks in the history of deep
    learning. Invented by Yann LeCun (now head of **Facebook** **Artificial Intelligence
    Research**), CNNs really came into their own in 2012, with the introduction of
    deep Convolutional Neural Networks by Alex Krizhevsky.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: CNN是深度学习历史上最具影响力的网络类别之一。由Yann LeCun（现为**Facebook** **人工智能研究**负责人）发明，CNN在2012年迎来了真正的突破，当时Alex
    Krizhevsky引入了深度卷积神经网络。
- en: 'Plain old neural networks don''t scale well to images; CNNs adapt regular old
    feedforward neural networks by adding one or more convolutional layers as the
    input layer to the network. These convolutions are specifically designed to take
    in two-dimensional input, such as images or even sound, as illustrated in the
    following diagram:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 普通的神经网络在处理图像时扩展性较差；卷积神经网络（CNN）通过在网络的输入层添加一个或多个卷积层来改进传统的前馈神经网络。这些卷积层特别设计用来处理二维输入，例如图像甚至声音，如下图所示：
- en: '![](img/1fb7dbc0-ba45-4829-a8ca-222b42a22d13.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1fb7dbc0-ba45-4829-a8ca-222b42a22d13.png)'
- en: As you ...
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见...
- en: Convolutional layers
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: Suppose we have an image recognition program to identify objects in an image,
    such as the example we referred to previously. Now imagine how hard it would be
    to try and classify an image with a standard feedforward network; each pixel in
    the image would be a feature that would have to be sent through the network with
    its own set of parameters. Our parameter space would be quite large, and we could
    likely run out of computing power! Images, which in technical terms are just high-dimensional
    vectors, require some special treatment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个图像识别程序来识别图像中的物体，比如之前提到的例子。现在想象一下，用标准的前馈网络来分类图像有多困难；图像中的每个像素都会成为一个特征，并且必须通过网络传递，每个像素都有一套自己的参数。我们的参数空间会非常大，并且很可能会耗尽计算能力！图像在技术上只是高维向量，处理图像需要一些特殊的方法。
- en: 'What would happen if we were to try and accomplish this task with a basic feedforward
    network? Let''s recall that basic feedforward networks operate on top of vector
    spaces. We start with an image, which is made up of independent pixels. Let''s
    say our image is 32 pixels by 32 pixels; the input to our convolutional layer
    would be *32 x 32 x 3*, where *3* represent the RGB color scale of images. To
    translate this to vector space, we''d end up with a *3072 x 1* vector to represent
    the entire image:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试用基础的前馈网络来完成这个任务，会发生什么呢？我们回想一下，基础的前馈网络是作用在向量空间上的。我们从图像开始，图像由独立的像素组成。假设我们的图像是32×32像素，输入到卷积层的数据将是*32
    x 32 x 3*，其中*3*表示图像的RGB色彩尺度。要将其转化为向量空间，我们将得到一个*3072 x 1*的向量来表示整张图像：
- en: '![](img/a32d2a13-e0b9-4a6a-aaf0-49bad075facb.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a32d2a13-e0b9-4a6a-aaf0-49bad075facb.png)'
- en: Let's also say our network has **10** neuron units; using the simple feedforward
    model, our weight matrix alone would have **30,720** learnable parameters. CNNs
    mitigate this problem, as well as others, with their convolutional layers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的网络有**10**个神经元单元；使用简单的前馈模型，仅权重矩阵就会有**30,720**个可学习参数。CNN通过其卷积层来缓解这个问题以及其他问题。
- en: 'Convolutional layers have four parameters that we have to define when we create
    a CNN:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层在创建CNN时有四个参数需要定义：
- en: The number of filters, *K*
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滤波器的数量，*K*
- en: The size of each filter, *F*
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个滤波器的大小，*F*
- en: The stride, *S*
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步幅，*S*
- en: The amount of zero padding, *P*
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零填充的数量，*P*
- en: In the next section, we'll walk through each of these and look at how they play
    into the structure of the network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将逐一讲解这些内容，并看看它们如何在网络结构中发挥作用。
- en: Layer parameters and structure
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层的参数和结构
- en: Convolutional layers allow us to preserve the original image dimensions, thereby
    improving our ability to learn features and reduce our computational load. They
    do this by utilizing something called a **filter, **which slides across the image,
    learning features by computing dot products. For example, a typical filter on
    the first layer of a CNN might have size *5 x 5 x 3* (namely, *5* pixels width
    and height, and *3* because images have a depth of three colors, RGB).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层使我们能够保持原始图像的尺寸，从而提高学习特征的能力并减少计算负担。它们通过使用一种叫做**滤波器**的东西来实现这一点，滤波器在图像上滑动，通过计算点积来学习特征。例如，CNN的第一层的一个典型滤波器可能具有*5
    x 5 x 3*的大小（即，*5*像素的宽度和高度，*3*是因为图像有三种颜色通道，RGB）。
- en: 'Mathematically, it''s done as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学上，操作如下：
- en: '![](img/0c5e4230-d491-4f74-864f-ed054c9ad84d.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c5e4230-d491-4f74-864f-ed054c9ad84d.png)'
- en: Here, *w* represents our filter, but it also represents our learnable weights.
    We take a transpose of our input filter, ...
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*w* 代表我们的滤波器，但它也代表我们的可学习权重。我们对输入滤波器进行转置，...
- en: Pooling layers
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: 'Convolutional layers are often intertwined with **pooling layers**, which down
    sample the output of the previous convolutional layer in order to decrease the
    amount of parameters we need to compute. A particular form of these layers, **max
    pooling layers**, has become the most widely used variant. In general terms, max
    pooling layers tell us if a feature was present in the region, the previous convolutional
    layer was looking at; it looks for the most significant value in a particular
    region (the maximum value), and utilizes that value as a representation of the
    region, as shown as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层通常与**池化层**交替使用，池化层会下采样前一个卷积层的输出，以减少我们需要计算的参数量。这些层的一个特定形式，**最大池化层**，已经成为最广泛使用的变体。一般来说，最大池化层告诉我们，特征是否出现在卷积层所查看的区域内；它会在特定区域中寻找最显著的值（最大值），并将该值作为该区域的表示，如下所示：
- en: '![](img/bafe3b38-c671-4e75-be57-9325252498a3.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bafe3b38-c671-4e75-be57-9325252498a3.png)'
- en: Max pooling layers help subsequent convolutional layers focus on larger sections
    of the data, providing abstractions of the  that help both reduce overfitting
    and the amount of hyperparameters that we have to learn, ultimately reducing our
    computational cost. This form of automatic feature selection also helps prevent
    overfitting by preventing the network from focusing on too-specific areas of the
    image.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化层帮助后续的卷积层集中关注数据的更大部分，从而提供特征的抽象，帮助减少过拟合以及我们需要学习的超参数的数量，最终减少计算成本。这种自动特征选择的形式也通过防止网络过于关注图像的特定区域，帮助防止过拟合。
- en: Fully connected layers
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全连接层
- en: 'The **fully connected layer** of a CNN works in the same manner as that of
    a vanilla feedforward network. This layer maps the outputs extracted from the
    image to the outputs that we desire from the network, such as a label for an image:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的**全连接层**与普通前馈网络的全连接层工作方式相同。这个层将从图像中提取的输出映射到我们从网络中期望的输出，比如图像的标签：
- en: '![](img/85b80730-0f00-4d28-b8c2-df0383730a18.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85b80730-0f00-4d28-b8c2-df0383730a18.png)'
- en: In the preceding diagram, our inputs are represented by the blue nodes, which
    are fed into the first convolutional layer, A. We then have a max pooling layer,
    a second convolutional layer, and finally the fully connected layer, which transforms
    our output into human– readable output. As with vanilla feedforward networks,
    we typically use a cross-entropy loss function for classification tasks. ...
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图示中，我们的输入由蓝色节点表示，这些输入被送入第一个卷积层A。接着是一个最大池化层、第二个卷积层，最后是全连接层，它将我们的输出转化为人类可读的输出。与普通前馈网络一样，我们通常会使用交叉熵损失函数来进行分类任务……
- en: The training process
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练过程
- en: 'When we connect convolutional layers, a hyperparameter known as the **receptive
    field** or **filter size** prevents us from having to connect the unit to the
    entire input, but rather focuses on learning a particular feature. Our convolutional
    layers typically learn features from simple to complex. The first layer typically
    learns low-level features, the next layer learns mid-level features, and the last
    convolutional layer learns high-level features. One of the beautiful features
    of this is that we do not explicitly tell the network to learn different features
    at these various levels; it learns to differentiate its task in this manner through
    the training process:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们连接卷积层时，一个名为**感受野**或**滤波器大小**的超参数使得我们不必将单元连接到整个输入，而是专注于学习某一特定特征。我们的卷积层通常是从简单到复杂地学习特征。第一层通常学习低级特征，下一层学习中级特征，最后一层卷积层学习高级特征。这个过程的美妙之处在于，我们并没有明确告诉网络在这些不同层次上学习不同的特征；它通过训练过程以这种方式学习区分任务：
- en: '![](img/0da64743-509a-4be8-9549-0a7674c648a7.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0da64743-509a-4be8-9549-0a7674c648a7.png)'
- en: 'As we pass through this process, our network will develop a two-dimensional
    **activation map** to track the response of that particular filter at a given
    position. The network will learn to keep filters that activate when they reach
    an edge of a shape, or perhaps the color of an object. Sometimes, these will be
    lines and smaller pieces of the puzzle, or perhaps a filter will learn entire
    subsections of the image, maybe the horses'' ears, in the preceding diagram. Each
    filter for a specific convolutional layer leaves us with individual activation
    maps. If we have six filters for the image, we would have six activation maps,
    each focusing on something different within the image:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们经历这一过程时，我们的网络将生成一个二维的**激活图**，以跟踪特定滤波器在给定位置的响应。网络将学习保留那些在遇到形状边缘或物体的颜色时激活的滤波器。有时，这些滤波器可能会学到线条或更小的拼图部分，或者可能会学习图像的某些子部分，例如前面图中的马耳朵。每个特定卷积层的滤波器都会生成单独的激活图。如果我们有六个滤波器用于图像，我们将得到六个激活图，每个图聚焦于图像中的不同部分：
- en: '![](img/eb448261-bb5d-4ba1-baf7-0be7192fabde.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb448261-bb5d-4ba1-baf7-0be7192fabde.png)'
- en: 'Our convolutional layers then become a sequence of stacked individual layers,
    interspersed by ReLU activation functions. We typically use ReLU or Leaky ReLU
    here to increase the training speed:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的卷积层将成为一系列堆叠的单独层，这些层之间插入了ReLU激活函数。我们通常在这里使用ReLU或Leaky ReLU，以提高训练速度：
- en: '![](img/d584ec46-dcf8-44f0-a354-6530ad4f89b8.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d584ec46-dcf8-44f0-a354-6530ad4f89b8.png)'
- en: Between these convolutional layers, we add in our max pooling layers. The output
    of these combined convolutional + max pooling layers will be sent to a fully connected
    layer, which will contain our transformation for classification and other tasks. Once
    we reach the end of a forward pass, the error is backpropagated through the network
    in the same manner as vanilla feedforward networks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些卷积层之间，我们加入了最大池化层。这些结合了卷积和最大池化的层的输出将传递到一个全连接层，该层包含我们用于分类和其他任务的变换。一旦完成前向传播，误差将像在普通前馈网络中一样通过网络进行反向传播。
- en: CNNs for image tagging
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN用于图像标注
- en: 'Let''s work on putting our new knowledge of CNNs to the test. We''re going
    to work through one of the most popular tasks for CNNs: image classification.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用新的CNN知识来测试一下。我们将通过CNN的一个最常见的任务——图像分类。
- en: 'In an image classification task, our horse looks at a given image and determines
    the probability that a certain object is an image. In the following example, the
    image is 248 pixels wide, 400 pixels tall, and has three color channels: **red**, **green**,
    and **blue** (**RGB**). Therefore, the image consists of *248 x 400 x 3* numbers,
    or a total of 2,97, 600 numbers. Our job is to turn these numbers into a single
    classified label; is this horse*?*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个图像分类任务中，我们的马会查看给定的图像，并确定某个物体是图像的概率。在下面的例子中，图像宽248像素，高400像素，并且有三个颜色通道：**红色**、**绿色**和**蓝色**（**RGB**）。因此，图像由*248
    x 400 x 3*个数字组成，总共有297,600个数字。我们的任务是将这些数字转化为一个单一的分类标签；这匹马*是*吗？
- en: '![](img/2e8f3d14-79ff-4a59-906d-b3c7be0c51ff.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e8f3d14-79ff-4a59-906d-b3c7be0c51ff.png)'
- en: While this might seem a simple task for ...
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这对...来说可能是一个简单的任务
- en: Summary
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: CNNs have been seminal in solving many computer vision tasks. In this chapter,
    we learned about how these networks differ from our basic feedforward networks,
    what their structures are, and how we can utilize them. CNNs are primarily used
    for computer vision tasks, although they can be adapted for use in other unstructured
    domains, such as natural language processing and audio signal processing.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络在解决许多计算机视觉任务中具有开创性作用。在本章中，我们了解了这些网络与我们基本的前馈网络有何不同，它们的结构是什么，以及我们如何使用它们。卷积神经网络主要用于计算机视觉任务，尽管它们也可以适应用于其他非结构化领域，例如自然语言处理和音频信号处理。
- en: CNNs are made up of convolutional layers interspersed with pooling layers,all
    of which output to a fully connected layer**.** CNNs iterate over images using
    filters. Filters have a size and a stride, which is how quickly they iterate over
    an input image. Input consistency can be better guaranteed by utilizing the zero
    padding technique.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）由卷积层和池化层交替组成，所有这些层的输出都连接到一个全连接层**。** 卷积神经网络通过使用滤波器对图像进行迭代。滤波器有大小和步长，步长决定了它们在输入图像上迭代的速度。通过利用零填充技术，可以更好地保证输入的一致性。
- en: In the next chapter, we'll learn about another important class of networks,
    called **Recurrent Neural Networks**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习另一类重要的网络，称为**递归神经网络**。
