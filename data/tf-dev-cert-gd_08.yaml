- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Handling Overfitting
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理过拟合
- en: One major challenge in **machine learning** (**ML**) is overfitting. **Overfitting**
    occurs when a model is trained too well on the training data but fails to generalize
    on unseen data, resulting in poor performance. In [*Chapter 6*](B18118_06.xhtml#_idTextAnchor129),
    *Improving the Model* we witnessed firsthand how overtraining pushed our model
    into this overfitting trap. In this chapter, we will probe further into the nuances
    of overfitting, striving to unpack both its warning signs and the underlying reasons
    behind it. Also, we will explore the different strategies we can apply to mitigate
    the dangers overfitting presents to real-world ML applications. Using TensorFlow,
    we will apply these ideas in a hands-on fashion to overcome overfitting in a real-world
    case study. By the end of this chapter, you should have a solid understanding
    of what overfitting is and how to mitigate it in real-world image classification
    tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（**ML**）中的一个主要挑战是过拟合。**过拟合**发生在模型对训练数据的拟合过好，但在未见过的数据上表现不佳，导致性能差。在[*第6章*](B18118_06.xhtml#_idTextAnchor129)中，*改进模型*，我们亲眼见证了过度训练如何将我们的模型推入过拟合的陷阱。在本章中，我们将进一步探讨过拟合的细微差别，努力揭示其警告信号及其潜在原因。同时，我们还将探索可以应用的各种策略，以减轻过拟合对现实世界机器学习应用的危害。通过
    TensorFlow，我们将以实践的方式应用这些思想，克服在实际案例中遇到的过拟合问题。通过本章学习结束后，你应该对过拟合的概念以及如何在现实世界的图像分类任务中减少过拟合有一个扎实的理解。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Overfitting in ML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中的过拟合
- en: Early stopping
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提前停止
- en: Changing the model’s architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改模型架构
- en: L1 and L2 regularization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L1 和 L2 正则化
- en: Dropout regularization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dropout 正则化
- en: Data augmentation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据增强
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be using Google Colab to run the coding exercise that requires `python
    >= 3.8.0`, along with the following packages, which can be installed using the
    `pip` `install` command:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Google Colab 来运行需要 `python >= 3.8.0` 的编码练习，并且需要安装以下包，可以通过 `pip install`
    命令进行安装：
- en: '`tensorflow>=2.7.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow>=2.7.0`'
- en: '`os`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os`'
- en: '`pillow==8.4.0`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pillow==8.4.0`'
- en: '`pandas==1.3.4`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas==1.3.4`'
- en: '`numpy==1.21.4`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy==1.21.4`'
- en: '`matplotlib >=3.4.0`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib >=3.4.0`'
- en: 'The code bundle for this book is available at the following GitHub link: [https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate).
    Also, solutions to all exercises can be found in the GitHub repo itself.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包可以通过以下 GitHub 链接访问：[https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate)。此外，所有练习的解答也可以在
    GitHub 仓库中找到。
- en: Overfitting in ML
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的过拟合
- en: From the previous chapters, we now know what overfitting is and its adverse
    effect when used on unseen data. Let's take a step further by digging into what
    the root causes of overfitting are, how we can spot overfitting when we build
    our models, and some important strategies we can apply to curb overfitting. When
    we gain this understanding, we can go on to build effective and robust ML models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的章节中，我们已经知道了什么是过拟合，以及它在未见过的数据上使用时的负面影响。接下来，我们将进一步探讨过拟合的根本原因，如何在构建模型时识别过拟合，以及可以应用的一些重要策略来抑制过拟合。当我们理解了这些内容后，就可以继续构建有效且强大的机器学习模型。
- en: What triggers overfitting
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 触发过拟合的原因
- en: In [*Chapter 6*](B18118_06.xhtml#_idTextAnchor129), *Improving the Model,* we
    saw that by adding more neurons to our hidden layer, our model became too complex.
    This made our model not only capture the patterns in our data but also the noise
    in it, leading to overfitting. Another root cause of overfitting is working with
    insufficient data volume. If our data does not truly capture the full spectrum
    of variations our model will be faced with upon deployment, when we train our
    model on such a dataset, it becomes too specialized and fails to generalize when
    used in the real world.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第6章*](B18118_06.xhtml#_idTextAnchor129)，*改进模型*中，我们看到通过向隐藏层添加更多神经元，我们的模型变得过于复杂。这使得模型不仅捕捉到了数据中的模式，还捕捉到了数据中的噪声，从而导致了过拟合。另一个导致过拟合的根本原因是数据量不足。如果我们的数据无法真正捕捉到模型在部署后将面临的所有变化，当我们在这样的数据集上训练模型时，它会变得过于专门化，并且在实际应用中无法进行有效的泛化。
- en: Beyond the volume of data, another issue we can face is noisy data. Unlike when
    we work with curated or static data, when building real-world applications, we
    may find that our data could be noisy or incorrect. If we develop models with
    such data, there is a chance it would lead to overfitting when put to use. We
    looked at some ideas around why overfitting could occur; the next question we
    may want to ask is, how can we detect overfitting? Let's discuss this in the following
    subsection.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据量之外，我们还可能面临另一个问题——噪声数据。与处理经过筛选或静态的数据不同，在构建实际应用时，我们可能会发现数据存在噪声或错误。如果我们使用这些数据开发模型，可能会导致在实际使用时出现过拟合的情况。我们已经讨论了关于过拟合可能发生的一些原因；接下来我们可能想要问的问题是，我们如何检测过拟合？让我们在接下来的子章节中讨论这个问题。
- en: Detecting overfitting
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测过拟合
- en: One way we can detect overfitting is by comparing a model’s accuracy on training
    data versus the validation/test data. When a model records a high accuracy on
    training and poor accuracy on testing, this disparity indicates that the model
    has memorized the training samples, hence its poor generalization of unseen data.
    Another effective way of discovering overfitting is to examine the training error
    against the validation error. When the training error decreases over time but
    the validation error increases, this can indicate our model overfits, as the model
    performs worse on the validation data. A scenario where the model’s validation
    accuracy deteriorates as its training counterpart flourishes should sound the
    alarm bells for potential overfitting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 检测过拟合的一种方法是比较模型在训练数据和验证/测试数据上的准确度。当模型在训练数据上表现出高准确度，而在测试数据上表现不佳时，这种差异表明模型已经记住了训练样本，因此在未见过的数据上的泛化能力较差。另一种有效的发现过拟合的方法是检查训练误差与验证误差。当训练误差随着时间的推移逐渐减小，而验证误差却增加时，这可能表明我们的模型过拟合了，因为模型在验证数据上的表现变差。当模型的验证准确度恶化，而训练准确度却不断提升时，应该引起警觉，可能存在过拟合的风险。
- en: Let’s revisit our case study from [*Chapter 7*](B18118_07.xhtml#_idTextAnchor146),
    *Image Classification with Convolutional Neural Networks,* the weather dataset
    from WeatherBIG, and examine how we can monitor overfitting by using a validation
    dataset during the model’s training process. By employing a validation dataset,
    we can accurately track the model’s performance and prevent overfitting. Let’s
    begin by creating a baseline model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下来自[*第7章*](B18118_07.xhtml#_idTextAnchor146)的案例研究，*卷积神经网络的图像分类*，以及WeatherBIG的天气数据集，并探讨在模型训练过程中如何通过使用验证数据集来监控过拟合。通过使用验证数据集，我们可以准确地追踪模型的表现，防止过拟合。首先，我们将创建一个基准模型。
- en: Baseline model
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准模型
- en: 'Following the standard three-step approach of building, compiling, and fitting,
    we will construct a **convolutional neural network** (**CNN**) model comprising
    two Conv2D and pooling layers, coupled with a fully connected layer that has a
    dense layer of 1,050 neurons. The output layer consists of four neurons, which
    represent the four classes in our dataset. We then compile and fit the model using
    the training data for 20 epochs:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 按照构建、编译和拟合的标准三步法，我们将构建一个**卷积神经网络**（**CNN**）模型，该模型包括两个Conv2D和池化层，并配有一个具有1,050个神经元的全连接层。输出层由四个神经元组成，表示我们数据集中的四个类别。然后，我们使用训练数据将模型编译并拟合20个周期：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We set the `validation_data` parameter to `valid_data`. This ensures that when
    we run the code, after each epoch, the model will evaluate its performance on
    the validation data, as shown in *Figure 8**.1*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`validation_data`参数设置为`valid_data`。这确保了当我们运行代码时，在每个周期结束后，模型会在验证数据上评估其性能，如*图8.1*所示。
- en: '![Figure 8.1 – The last five training epochs](img/B18118_08_01.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 最后的五个训练周期](img/B18118_08_01.jpg)'
- en: Figure 8.1 – The last five training epochs
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 最后的五个训练周期
- en: This is a straightforward way to compare the loss values between the training
    set and the validation set. We can see that the model accurately predicts every
    sample in the training set, reaching an accuracy of 100 percent. However, on the
    validation set, it attains an accuracy of 91 percent, which suggests that the
    model likely overfits. Another effective way to observe overfitting is to use
    the learning curve to plot the loss and accuracy values of both the training set
    and the validation set – again, a large gap between both plots is a sign of overfitting,
    as shown in *Figure 8**.2*.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种直观的方法，可以比较训练集和验证集之间的损失值。我们可以看到模型能够准确地预测训练集中的每个样本，达到了100%的准确率。然而，在验证集上，它的准确率为91%，这表明模型可能存在过拟合问题。观察过拟合的另一种有效方法是使用学习曲线，绘制训练集和验证集的损失和准确度值——如*图
    8.2*所示，两个图之间存在较大的差距，表明模型存在过拟合。
- en: '![Figure 8.2 – The learning curve showing the loss and accuracy for both training
    and test data](img/B18118_08_02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – 显示训练和测试数据的损失和准确度的学习曲线](img/B18118_08_02.jpg)'
- en: Figure 8.2 – The learning curve showing the loss and accuracy for both training
    and test data
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 显示训练和测试数据的损失和准确度的学习曲线
- en: At the start of the experiment, the difference between the training loss and
    the validation loss is minimal; however, as we move into the fourth epoch, the
    validation loss starts to increase, while the training loss continues to decrease.
    Similarly, the training and validation accuracies are closely aligned at the start,
    but again, at around the fourth epoch, the validation accuracy reaches a peak
    of around 90 percent and stays there, while the training accuracy reaches 100
    percent accuracy.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验开始时，训练损失和验证损失之间的差异较小；然而，进入第四轮时，验证损失开始增加，而训练损失继续下降。类似地，训练和验证的准确度开始时较为接近，但在大约第四轮时，验证准确率达到了90%左右并保持在该水平，而训练准确率达到了100%。
- en: The ultimate objective of building an image classifier is to apply it to real-world
    data. After completing the training process, we evaluate the model on our holdout
    dataset. If the results obtained during testing are significantly different from
    those achieved during training, this could indicate overfitting.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 构建图像分类器的最终目标是将其应用于现实世界的数据。在完成训练过程后，我们使用保留数据集评估模型。如果在测试中获得的结果与训练过程中取得的结果有显著差异，这可能表明模型存在过拟合。
- en: Fortunately, there are several strategies that can be applied to overcome overfitting.
    Some of the main techniques to handle overfitting focus on improving the model
    itself to enhance its generalization capabilities. On the other hand, it is equally
    important to examine the data itself, observing what the model missed during training
    and evaluation. By visualizing the misclassified images, we gain insight into
    where the model falls short. We start by first recreating our baseline model from
    [*Chapter 7*](B18118_07.xhtml#_idTextAnchor146)*, Image Classification with Convolutional
    Neural Networks*. This time, we train it for 20 epochs to enable us to observe
    overfitting, as illustrated in *Figure 8**.2*. Next, let's see how we can curb
    overfitting using several strategies, starting with applying early stopping.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有几种策略可以用来克服过拟合问题。一些主要的应对过拟合的技术侧重于改进模型本身，以提高其泛化能力。另一方面，检查数据本身同样重要，观察模型在训练和评估过程中忽视的部分。通过可视化错误分类的图像，我们可以洞察模型的不足之处。我们从[*第七章*](B18118_07.xhtml#_idTextAnchor146)《卷积神经网络图像分类》开始，首先重新创建我们的基线模型。这次我们将其训练20轮，以便观察过拟合问题，如*图
    8.2*所示。接下来，让我们看看如何通过多种策略来抑制过拟合，首先是应用早停法。
- en: Early stopping
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 早停法
- en: In [*Chapter 6*](B18118_06.xhtml#_idTextAnchor129)*,* *Improving the Model,*
    we introduced the concept of early stopping as an effective way of preventing
    overfitting. It does this by halting training when the model’s performance fails
    to improve over a defined number of epochs, as indicated in *Figure 8**.3*. This
    way, we prevent our model from overfitting.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第六章*](B18118_06.xhtml#_idTextAnchor129)《改进模型》中，我们介绍了早停法的概念，这是一种有效的防止过拟合的方法。它通过在模型性能未能在定义的若干轮次内改善时停止训练，如*图
    8.3*所示，从而避免了过拟合的发生。
- en: '![Figure 8.3 – A learning curve showing early stopping](img/B18118_08_03.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – 显示早停法的学习曲线](img/B18118_08_03.jpg)'
- en: Figure 8.3 – A learning curve showing early stopping
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 显示早停法的学习曲线
- en: 'Let’s recreate the same baseline model, but this time, we will apply a built-in
    callback to stop training when the validation accuracy fails to improve. We will
    use the same build and compile steps as in the first model and then add a callback
    when we fit the model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新创建相同的基准模型，但这次我们将应用一个内置回调，在验证精度未能提高时停止训练。我们将使用与第一个模型相同的构建和编译步骤，然后在拟合模型时添加回调：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, we specified the number of epochs as `20` and added a validation set
    to monitor the model’s performance during training. After this, we used the `callbacks`
    argument to specify a callback function to implement early stopping. We used an
    early stopping callback to stop training after three epochs should the validation
    set accuracy fail to improve. This is done by setting the `patience` parameter
    to `3`. This means that if there’s no progress in validation accuracy for three
    straight epochs, the early stopping callback halts training. We also set the `restore_best_weights`
    parameter to `True`; this restores the best model weight from the training process
    when the training ends. The information from the `fit` function is stored in the
    `history_2` variable:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将周期数指定为`20`，并添加了验证集来监控模型在训练过程中的表现。之后，我们使用`callbacks`参数指定了一个回调函数来实现早停。我们使用了一个早停回调，在验证集的精度未能提高时，训练将在三轮后停止。通过将`patience`参数设置为`3`来实现这一点。这意味着如果验证精度连续三轮没有进展，早停回调将停止训练。我们还将`restore_best_weights`参数设置为`True`；这将在训练结束时恢复训练过程中最好的模型权重。`fit`函数的信息存储在`history_2`变量中：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'From the training process, we can see that our model reaches a peak validation
    accuracy of `0.9218` on the ninth epoch, after which training continues for three
    epochs before stopping. Since there were no further improvements in the validation
    accuracy, training is stopped and the best weight is saved. Now, let''s evaluate
    `model_2` on our test data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练过程来看，我们可以看到模型在第九个周期达到了`0.9218`的最高验证精度，之后训练继续进行了三轮才停止。由于验证精度没有进一步提升，训练被停止，并保存了最佳权重。现在，让我们在测试数据上评估`model_2`：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: When we run the code, we see that the model achieves an accuracy of `0.9355`.
    Here, the performance on the test set is in line with the performance on the validation
    set and higher than our baseline model, where we achieved an accuracy of `0.9097`.
    This is our first step to create a better model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们看到模型达到了`0.9355`的精度。在这里，测试集的表现与验证集的表现一致，并且高于我们的基准模型，后者的精度为`0.9097`。这是我们创建更好模型的第一步。
- en: '![Figure 8.4 – A snapshot of the model summary](img/B18118_08_04.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 模型总结快照](img/B18118_08_04.jpg)'
- en: Figure 8.4 – A snapshot of the model summary
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 模型总结快照
- en: When we inspect our model summary, we can see that our model has over 45 million
    parameters, and this could lead to the model being susceptible to picking up noise
    in the training data, due to the model being highly parameterized. To address
    this issue, we can simplify our model by reducing the number of parameters in
    such a way that our model is not too complex for our dataset. Let's discuss model
    simplification next.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检查模型总结时，我们可以看到我们的模型有超过4500万个参数，这可能导致模型容易在训练数据中拾取噪声，因为模型高度参数化。为了解决这个问题，我们可以通过减少参数数量来简化模型，使得我们的模型对于数据集来说不会过于复杂。接下来，我们将讨论模型简化。
- en: Model simplification
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型简化
- en: To address overfitting, you may consider reassessing the model’s architecture.
    Simplifying your model’s architecture could prove to be an effective strategy
    in tackling overfitting, especially when your model is highly parameterized. However,
    it is important to know that this approach does not always guarantee better performance
    in every instance; in fact, you must be mindful of oversimplifying your model,
    which could lead to the trap of underfitting. Hence, it is important to strike
    the right balance between model complexity and simplicity to achieve an optimally
    performing model, as illustrated in *Figure 8**.5*, as the relationship between
    model complexity and overfitting is not a linear one.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对过拟合，你可以考虑重新评估模型的架构。简化模型的架构可能是应对过拟合的有效策略，特别是在模型高度参数化时。然而，重要的是要知道，这种方法并不总能在每种情况下保证更好的表现；事实上，你必须警惕模型过于简化，这可能导致欠拟合的陷阱。因此，重要的是在模型复杂性和简化之间找到合适的平衡，以实现最佳性能，如*图
    8.5*所示，因为模型复杂性与过拟合之间的关系不是线性的。
- en: '![Figure 8.5 – Overfitting and underfitting in ML](img/B18118_08_05.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – 机器学习中的过拟合和欠拟合](img/B18118_08_05.jpg)'
- en: Figure 8.5 – Overfitting and underfitting in ML
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 机器学习中的过拟合和欠拟合
- en: 'Model simplification can be achieved in a number of ways – for instance, we
    can replace a large number of filters with smaller ones, or we could also reduce
    the number of neurons in the first `Dense` layer. In our architecture, you can
    see that the first dense layer has `1050` neurons. Let''s reduce the neurons to
    `500` as the initial step in our model simplification experiment:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 模型简化可以通过多种方式实现——例如，我们可以用更小的滤波器替换大量的滤波器，或者我们还可以减少第一个 `Dense` 层中的神经元数量。在我们的架构中，你可以看到第一个全连接层有
    `1050` 个神经元。作为模型简化实验的初步步骤，让我们将神经元数量减少到 `500`：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When we compile and fit the model, our model reaches a peak accuracy of `0.9162`
    on the validation set:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们编译并拟合模型时，我们的模型在验证集上达到了 `0.9162` 的最高准确率：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Since our validation accuracy did not fare better, perhaps now will be a good
    time to try a few well-known ideas to fix overfitting. Let's look at L1 and L2
    regularizations in the following subsection. We will discuss how they work and
    apply them to our case study.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的验证准确率并没有更好，或许现在是时候尝试一些著名的想法来解决过拟合问题了。让我们在接下来的小节中看一下 L1 和 L2 正则化。我们将讨论它们如何工作，并将其应用到我们的案例研究中。
- en: Note
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The goal of model simplification is not to achieve a smaller model but a well-designed
    model that generalizes well. We may just need to reduce layers if they are unnecessary
    for our use case, or we could simplify the model by changing the activation function
    or reorganizing the order and arrangement of the model layers to improve the flow
    of information.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 模型简化的目标不是为了得到更小的模型，而是为了设计出一个能很好地泛化的模型。我们可能只需要减少不必要的层，或者通过改变激活函数，或者重新组织模型层的顺序和排列，以改善信息流动，从而简化模型。
- en: L1 and L2 regularization
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: L1 和 L2 正则化
- en: Regularization is a set of techniques used to prevent overfitting by reducing
    a model’s complexity, by applying a penalty term to the loss function. Regularization
    techniques make the model more resistant to the noise in the training data, thus
    improving its ability to generalize to unseen data. There are different types
    of regularization techniques, namely L1 and L2 regularization. **L1 and L2 regularization**
    are two well know regularization techniques; L1 can also be referred to as **lasso
    regression**. When selecting between L1 and L2, it is important to consider the
    type of data we work with.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是一组通过向损失函数应用惩罚项来减少模型复杂性，从而防止过拟合的技术。正则化技术使模型对训练数据中的噪声更加抗干扰，从而提高了它对未见数据的泛化能力。正则化技术有多种类型，分别是
    L1 和 L2 正则化。**L1 和 L2 正则化**是两种广为人知的正则化技术；L1 也可以称为 **套索回归**。在选择 L1 和 L2 时，重要的是要考虑我们所处理数据的类型。
- en: 'L1 regularization comes in handy when working with data with many irrelevant
    features. The penalty term in L1 will cause some of the coefficients to become
    zero, resulting in a reduction in the number of features used during modeling;
    this, in turn, reduces the risk of overfitting, as the model will be trained on
    less noisy data. Conversely, L2 is an excellent choice when the goal is to create
    a model with small weights and good generalization. The penalty term in L2 reduces
    the magnitude of the coefficients, preventing them from becoming too large and
    leading to overfitting:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理具有大量无关特征的数据时，L1 正则化非常有用。L1 中的惩罚项会导致一些系数变为零，从而减少在建模过程中使用的特征数量；这反过来减少了过拟合的风险，因为模型将基于较少的噪声数据进行训练。相反，当目标是创建具有小权重和良好泛化能力的模型时，L2
    是一个非常好的选择。L2 中的惩罚项减少了系数的大小，防止它们变得过大，从而导致过拟合：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When we run this experiment, we reach an accuracy of around 92 percent, not
    faring better than other experiments. To try out L1 regularization, we simply
    changed the regularization method from L2 to L1\. However, in this case, our results
    were not as good. As a result, let's try another regularization method called
    dropout regularization.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这个实验时，准确率大约为 92%，并没有比其他实验表现得更好。为了尝试 L1 正则化，我们只是将正则化方法从 L2 改为 L1。然而，在这种情况下，我们的结果并不好。因此，让我们尝试另一种叫做
    dropout 正则化的正则化方法。
- en: Dropout regularization
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dropout 正则化
- en: One key issue with neural networks is co-dependence. **Co-dependence** is a
    phenomenon in neural networks that occurs when a group of neurons, especially
    in the same layer, become highly correlated such that they rely too much on each
    other. This could lead to them amplifying certain features and failing to capture
    other important features in the data. Because these neurons act in sync, our model
    is more prone to overfitting. To mitigate this risk, we can apply a technique
    referred to as **dropout**. Unlike L1 and L2 regularization, dropout does not
    add a penalty term, but as the name implies, we randomly “drop out” a certain
    percentage of neurons from the model during training, as illustrated in *Figure
    8**.6*, reducing co-dependence between neurons, which can help to mitigate against
    overfitting.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的一个关键问题是共依赖性。**共依赖性**是神经网络中一种现象，当一组神经元，特别是同一层中的神经元，变得高度相关，以至于它们过度依赖彼此时，就会发生共依赖性。这可能导致它们放大某些特征，同时无法捕捉到数据中的其他重要特征。由于这些神经元同步工作，我们的模型更容易发生过拟合。为了减轻这一风险，我们可以应用一种称为
    **dropout** 的技术。与 L1 和 L2 正则化不同，dropout 不会添加惩罚项，但顾名思义，在训练过程中我们会随机“丢弃”一部分神经元，如
    *图 8.6* 所示，这有助于减少神经元之间的共依赖性，从而有助于防止过拟合。
- en: '![Figure 8.6 – A neural network with dropout applied](img/B18118_08_06.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 应用了 dropout 的神经网络](img/B18118_08_06.jpg)'
- en: Figure 8.6 – A neural network with dropout applied
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 应用了 dropout 的神经网络
- en: 'When we apply the dropout technique, the model is forced to learn more robust
    features, since we break co-dependence between neurons. However, it’s worth noting
    that when we apply dropout, the training process may require more iterations to
    achieve convergence. Let’s apply dropout to our baseline model and observe what
    its effect will be:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们应用 dropout 技术时，模型被迫学习更鲁棒的特征，因为我们打破了神经元之间的共依赖性。然而，值得注意的是，当我们应用 dropout 时，训练过程可能需要更多的迭代才能达到收敛。让我们将
    dropout 应用到我们的基础模型上，观察它的效果：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To implement dropout in code, we specify the dropout layer using the `tf.keras.layers.Dropout(0.6)`
    function. This creates a dropout layer with a dropout rate of `0.6` – that is,
    we turn off 60 percent of the neurons during training. It is worth noting that
    we can set the dropout value between 0 and 1:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要在代码中实现 dropout，我们使用 `tf.keras.layers.Dropout(0.6)` 函数来指定 dropout 层。这会创建一个 dropout
    层，dropout 率为 `0.6` —— 即在训练过程中我们会关闭 60% 的神经元。值得注意的是，我们可以将 dropout 值设置在 0 和 1 之间：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this experiment, our model reaches a peak performance of `0.9441` on the
    validation set, improving our baseline model’s performance. Next, let's look at
    changing the learning rate.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们的模型在验证集上达到了 `0.9441` 的最佳性能，提升了基础模型的表现。接下来，让我们看看调整学习率的效果。
- en: Adjusting the learning rate
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整学习率
- en: 'In [*Chapter 6*](B18118_06.xhtml#_idTextAnchor129), *Improving the Model,*
    we discussed learning rates and the need to find an optimal learning rate. For
    this experiment, let us use a learning rate of `0.0001`, which I found to produce
    a good result here, by experimenting with different learning rates, similar to
    what we did in [*Chapter 6*](B18118_06.xhtml#_idTextAnchor129)*, Improving the
    Model*. In [*Chapter 13*](B18118_13.xhtml#_idTextAnchor318),*Time Series, Sequence
    and Prediction with TensorFlow,* we will look at how to apply both custom and
    inbuilt learning rate schedulers. Here, we also apply our early stopping callback
    to ensure that training is terminated once the model fails to improve. Let’s compile
    our model:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 6 章*](B18118_06.xhtml#_idTextAnchor129)《*提高模型*》中，我们讨论了学习率以及寻找最优学习率的重要性。在这个实验中，我们使用
    `0.0001` 的学习率，这是通过尝试不同的学习率得到的一个良好结果，类似于我们在 [*第 6 章*](B18118_06.xhtml#_idTextAnchor129)《*提高模型*》中做的实验。在
    [*第 13 章*](B18118_13.xhtml#_idTextAnchor318)《*使用 TensorFlow 进行时间序列、序列和预测*》中，我们将研究如何应用自定义和内建的学习率调度器。这里，我们还应用了早停回调，以确保当模型无法再提高时，训练能够终止。让我们编译我们的模型：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We will fit the model and run it. In seven epochs, our model’s training stops,
    reaching peak performance of `0.9274` on the validation set:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将拟合模型并运行它。在七个 epoch 后，我们的模型训练停止，达到了验证集上的最佳性能 `0.9274`：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We’ve explored various methods to improve our model and overcome overfitting.
    Now, let’s shift our focus to the dataset itself and examine how error analysis
    can be useful.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探索了各种方法来改善我们的模型并克服过拟合问题。现在，让我们将焦点转向数据集本身，看看错误分析如何发挥作用。
- en: Error analysis
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误分析
- en: From our results so far, we can see that our model fails to misclassify some
    labels correctly. To further improve the generalization ability of our model,
    it is a good idea to examine the mistakes made by the model, with the underlying
    idea to uncover patterns in the misclassified data so that the insights we gain
    from looking at the misclassified labels can be used to improve the model’s generalization
    capability. This technique is referred to as **error analysis**. To perform error
    analysis, we begin by identifying misclassified labels on the validation/test
    set. Next, we put these errors into groups – for example, we can make a group
    to blur images or images taken under poor lighting conditions.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们目前的结果，我们可以看到模型未能正确地将某些标签分类。为了进一步提高模型的泛化能力，最好检查模型所犯的错误，其背后的思想是揭示误分类数据中的模式，以便我们从查看误分类标签中获得的洞察可以用于改善模型的泛化能力。这种技术称为**错误分析**。进行错误分析时，我们首先通过识别验证/测试集中的误分类标签开始。接下来，我们将这些错误分组——例如，我们可以将模糊图像或光照条件差的图像归为一组。
- en: Based on the insights gained from the collected errors, we may need to adjust
    our model architecture or tune our hyperparameters, especially when certain features
    are not captured by the model. Also, our error analysis step can also point us
    to the need to improve our data size and quality. One effective way of resolving
    this is by applying data augmentation, a well-known technique to enrich our data
    size and quality. Let's discuss data augmentation next and apply it to our case
    study.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 基于从收集到的错误中获得的洞察，我们可能需要调整我们的模型架构或调整超参数，特别是当模型未能捕捉到某些特征时。此外，我们的错误分析步骤也可能会指出需要改善数据的大小和质量。解决这一问题的有效方法之一是应用数据增强，这是一种众所周知的技术，用于丰富我们的数据量和质量。接下来，让我们讨论数据增强并将其应用于我们的案例研究。
- en: Data augmentation
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据增强
- en: Image **data augmentation** is a technique used to increase the size and diversity
    of our training set by the application of various transformations, such as rotating,
    flipping, cropping, and scaling to create new, synthetic data, as illustrated
    in *Figure 8**.7*. For many real-world applications, data collection can be a
    very expensive and time-consuming process; hence, data augmentation comes in quite
    handy. Data augmentation helps the model to learn more robust features rather
    than allowing the model to memorize features, thereby improving the model’s generalization
    capabilities.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图像**数据增强**是一种通过应用各种变换（例如旋转、翻转、裁剪和缩放）来增加我们训练集的大小和多样性的技术，从而创建新的合成数据，如*图 8.7*所示。对于许多实际应用来说，数据收集可能是一个非常昂贵且耗时的过程；因此，数据增强非常有用。数据增强帮助模型学习更具鲁棒性的特征，而不是让模型记住特征，从而提高模型的泛化能力。
- en: '![Figure 8.7 – Various data augmentation techniques applied to an image of
    a butterfly (Source: https://medium.com/secure-and-private-ai-writing-challenge/data-augmentation-increases-accuracy-of-your-model-but-how-aa1913468722)](img/B18118_08_07.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – 应用于蝴蝶图像的各种数据增强技术（来源：https://medium.com/secure-and-private-ai-writing-challenge/data-augmentation-increases-accuracy-of-your-model-but-how-aa1913468722)](img/B18118_08_07.jpg)'
- en: 'Figure 8.7 – Various data augmentation techniques applied to an image of a
    butterfly (Source: https://medium.com/secure-and-private-ai-writing-challenge/data-augmentation-increases-accuracy-of-your-model-but-how-aa1913468722)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 应用于蝴蝶图像的各种数据增强技术（来源：https://medium.com/secure-and-private-ai-writing-challenge/data-augmentation-increases-accuracy-of-your-model-but-how-aa1913468722）
- en: Another important use of data augmentation is to create balance across different
    classes in our training dataset. If the training set contains imbalanced data,
    we can use data augmentation techniques to create variants of the minority class,
    thereby building a more balanced dataset with a lower likelihood of overfitting.
    When implementing data augmentation, it’s important to keep in mind various factors
    that may affect the outcome. For instance, the type of data augmentation to use
    depends on the type of data we work with.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强的另一个重要用途是为了在训练数据集中创建不同类别之间的平衡。如果训练集包含不平衡的数据，我们可以使用数据增强技术来创建少数类的变体，从而构建一个更加平衡的数据集，降低过拟合的可能性。在实施数据增强时，重要的是要牢记可能影响结果的各种因素。例如，使用哪种类型的数据增强取决于我们所处理的数据类型。
- en: In image classification tasks, techniques such as random rotations, translations,
    flips, and scaling may prove useful. However, when dealing with numeric datasets,
    applying rotations to numbers could lead to unintended results, such as rotating
    a 6 into a 9\. Again, flipping letters of the alphabet, such as “b” and “d,” can
    also have adverse effects. When applying image augmentation to our training set,
    it’s crucial to consider the magnitude of augmentation and its effect on the quality
    of our training data. Excessive augmentation may lead to severely distorted images,
    resulting in a poorly performing model. To prevent this, it’s equally important
    to monitor the model’s training with a validation set.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像分类任务中，诸如随机旋转、平移、翻转和缩放等技术可能会证明是有用的。然而，在处理数字数据集时，对数字应用旋转可能会导致意想不到的结果，比如将数字
    6 旋转成 9。再者，翻转字母表中的字母，比如“b”和“d”，也可能带来不良影响。当我们对训练集应用图像增强时，考虑增强的幅度及其对训练数据质量的影响至关重要。过度增强可能导致图像严重失真，从而导致模型性能不佳。为防止这种情况的发生，监控模型的训练过程并使用验证集同样重要。
- en: Let's apply data augmentation to our case study and see what our results will
    look like.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对案例研究应用数据增强，看看我们的结果会是什么样子。
- en: 'To implement data augmentation, you can use the `ImageDataGenerator` class
    from the `tf.keras.preprocessing.image` module. This class allows you to specify
    a range of transformations, which should only be applied to images in our training
    set, and it generates synthetic images on the fly during the training process.
    For example, here is how you can use the `ImageDataGenerator` class to apply rotation,
    flipping, and scaling transformations to the training images:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现数据增强，您可以使用 `tf.keras.preprocessing.image` 模块中的 `ImageDataGenerator` 类。这个类允许您指定一系列的变换，这些变换只应应用于训练集中的图像，并且它会在训练过程中实时生成合成图像。例如，您可以使用
    `ImageDataGenerator` 类对训练图像应用旋转、翻转和缩放变换，方法如下：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Using image data augmentation is quite straightforward; we created three instances
    of the `ImageDataGenerator` class from the `keras.preprocessing.image` module
    for our train, validation, and test sets. One key difference is that we added
    the `rotation_range=25` and `zoom_range=0.3` arguments to the `train_datagen`
    object. This will randomly rotate our images by 25 degrees and zoom them by a
    factor of `0.3` during the training process; everything else will remain the same.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像数据增强非常简单；我们为训练集、验证集和测试集创建了 `keras.preprocessing.image` 模块中的 `ImageDataGenerator`
    类的三个实例。一个关键的区别是，我们在 `train_datagen` 对象中添加了 `rotation_range=25` 和 `zoom_range=0.3`
    参数。这样，在训练过程中，图像将随机旋转 25 度并缩放 0.3 倍，其他所有设置保持不变。
- en: 'Next, we will build, compile, and fit our baseline model, with early stopping
    applied, on our augmented data:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建、编译并拟合我们的基准模型，并应用早停技术，在增强数据上进行训练：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In eight epochs, our training comes to an end. This time, we reached `0.9330`
    on the validation set. So far, we have run seven different experiments. Let's
    test each of these models on the test set and examine what the results will look
    like. To do this, we will write a helper function that creates a DataFrame showing
    the top 5 models, each model’s name, and the loss and accuracy of each model,
    as shown in *Figure 8**.8*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在八个训练周期后，我们的训练结束了。这次，我们在验证集上的得分达到了 `0.9330`。到目前为止，我们已经运行了七个不同的实验。接下来，让我们在测试集上测试这些模型，看看结果如何。为此，我们将编写一个辅助函数，创建一个
    DataFrame，显示前五个模型、每个模型的名称，以及每个模型的损失和准确度，如 *图 8.8* 所示。
- en: '![Figure 8.8 – A DataFrame showing the loss and accuracy of the top five models](img/B18118_08_08.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8 – 显示前五个模型的损失和准确度的 DataFrame](img/B18118_08_08.jpg)'
- en: Figure 8.8 – A DataFrame showing the loss and accuracy of the top five models
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 显示前五个模型的损失和准确度的 DataFrame
- en: Our best-performing model on our test data was **model 7**, where we altered
    the learning rate. We have covered a few ideas that are used to tackle overfitting
    in real-world image classifiers; however, a combination of these techniques can
    be applied to build a simpler yet more robust model that is less prone to overfitting.
    Combining various techniques of curbing overfitting is generally a good idea,
    as it may help to produce a more robust and generalizable model. However, it is
    important to keep in mind that there is no one-size-fits-all solution, and the
    best combination of methods will depend on the specific data and task at hand
    and may require multiple experiments.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试数据中，表现最好的模型是**模型7**，它调整了学习率。我们已经讨论了一些在现实世界中用于解决图像分类过拟合问题的想法；然而，结合这些技术可以构建一个更简单但更强大的模型，从而减少过拟合的风险。通常来说，将多种技术结合起来遏制过拟合是一个好主意，因为这可能有助于生成一个更强大且更具泛化能力的模型。然而，重要的是要记住，没有一刀切的解决方案，最好的方法组合将取决于具体的数据和任务，并可能需要多次实验。
- en: Summary
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed overfitting in image classification and explored
    the different techniques to overcome it. We started by examining what overfitting
    is and why it happens, and we discussed how we can apply different techniques
    such as early stopping, model simplification, L1 and L2 regularization, dropout,
    and data augmentation to mitigate against overfitting in image classification
    tasks. Furthermore, we applied each of these techniques in our weather dataset
    case study and saw, hands-on, the effects of these techniques on our case study.
    We also explored combining these techniques in a quest to build an optimal model.
    By now, you should have a good understanding of overfitting and how to mitigate
    it in your own image classification projects.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了图像分类中的过拟合问题，并探索了克服它的不同技术。我们首先探讨了什么是过拟合以及为什么会发生过拟合，接着讨论了如何应用不同的技术，如提前停止、模型简化、L1和L2正则化、dropout以及数据增强来缓解图像分类任务中的过拟合问题。此外，我们还在天气数据集的案例研究中应用了这些技术，并通过实际操作观察了这些技术在案例中的效果。我们还探讨了将这些技术结合起来，以构建一个最优模型的过程。到目前为止，你应该已经对过拟合以及如何在自己的图像分类项目中减轻过拟合有了深入的了解。
- en: In the next chapter, we will dive into transfer learning, a powerful technique
    that allows you to leverage pre-trained models for your specific image classification
    tasks, saving time and resources while achieving impressive results.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨迁移学习，这是一种强大的技术，能够让你利用预训练的模型来完成特定的图像分类任务，从而节省时间和资源，同时取得令人印象深刻的结果。
- en: Questions
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Let’s test what we learned in this chapter:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来测试一下本章学到的内容：
- en: What is overfitting in image classification tasks?
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像分类任务中的过拟合是什么？
- en: How does overfitting occur?
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过拟合是如何发生的？
- en: What techniques can be used to prevent overfitting?
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用哪些技术来防止过拟合？
- en: What is data augmentation, and how is it used to prevent overfitting?
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是数据增强，如何利用它来防止过拟合？
- en: How can data pre-processing, data diversity, and data balancing be used to mitigate
    overfitting?
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何通过数据预处理、数据多样性和数据平衡来缓解过拟合？
- en: Further reading
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'To learn more, you can check out the following resources:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多内容，您可以查看以下资源：
- en: 'Garbin, C., Zhu, X., & Marques, O. (2020). *Dropout vs. Batch Normalization:
    An Empirical Study of Their Impact to Deep Learning*. arXiv preprint arXiv:1911.12677:
    [https://par.nsf.gov/servlets/purl/10166570](https://par.nsf.gov/servlets/purl/10166570).'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garbin, C., Zhu, X., & Marques, O. (2020). *Dropout与Batch Normalization的对比：它们对深度学习的影响的实证研究*。arXiv预印本arXiv:1911.12677：[https://par.nsf.gov/servlets/purl/10166570](https://par.nsf.gov/servlets/purl/10166570)。
- en: Kandel, I., & Castelli, M. (2020). *The effect of batch size on the generalizability
    of the convolutional neural networks on a histopathology dataset*. arXiv preprint
    arXiv:2003.00204.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kandel, I., & Castelli, M. (2020). *批量大小对卷积神经网络在组织病理学数据集上泛化能力的影响*。arXiv预印本arXiv:2003.00204。
- en: '*Effect_batch_size_generalizability_convolutional_neural_networks_histopathology_dataset.pdf
    (unl.pt)*. Kapoor, A., Gulli, A. and Pal, S. (2020): [https://research.unl.pt/ws/portalfiles/portal/18415506/Effect_batch_size_generalizability_convolutional_neural_networks_histopathology_dataset.pdf](https://research.unl.pt/ws/portalfiles/portal/18415506/Effect_batch_size_generalizability_convolutional_neural_networks_histopathology_dataset.pdf).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Effect_batch_size_generalizability_convolutional_neural_networks_histopathology_dataset.pdf
    (unl.pt)*。Kapoor, A., Gulli, A. 和 Pal, S. (2020): [https://research.unl.pt/ws/portalfiles/portal/18415506/Effect_batch_size_generalizability_convolutional_neural_networks_histopathology_dataset.pdf](https://research.unl.pt/ws/portalfiles/portal/18415506/Effect_batch_size_generalizability_convolutional_neural_networks_histopathology_dataset.pdf)。'
- en: '*Deep Learning with TensorFlow and Keras, Third Edition, Amita Kapoor, Antonio
    Gulli, Sujit Pal*, Packt Publishing Ltd.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow与Keras深度学习（第三版），Amita Kapoor，Antonio Gulli，Sujit Pal*，Packt Publishing
    Ltd.'
- en: 'Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
    Salakhutdinov. 2014\. *Dropout: A simple way to prevent neural networks from overfitting*.
    J. Mach. Learn. Res. 15, 1 (2014), 1,929–1,958 [https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf).'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, 和 Ruslan
    Salakhutdinov. 2014\. *Dropout: 一种简单的防止神经网络过拟合的方法*。J. Mach. Learn. Res. 15, 1
    (2014), 1,929–1,958 [https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf).'
- en: 'Zhang, Z., Ma, H., Fu, H., & Zha, C. (2016). *Scene-Free Multi-Class Weather
    Classification on Single Images*. IEEE Access, 8, 146,038–146,049\. doi:10.1109:
    [https://web.cse.ohio-state.edu/~zhang.7804/Cheng_NC2016.pdf](https://web.cse.ohio-state.edu/~zhang.7804/Cheng_NC2016.pdf).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang, Z., Ma, H., Fu, H., & Zha, C. (2016). *无场景的单图像多类别天气分类*。IEEE Access,
    8, 146,038–146,049\. doi:10.1109: [https://web.cse.ohio-state.edu/~zhang.7804/Cheng_NC2016.pdf](https://web.cse.ohio-state.edu/~zhang.7804/Cheng_NC2016.pdf).'
