- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Prompt Engineering
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程
- en: In *Chapter 2*, we introduced the concept of prompt engineering as the process
    of designing and optimizing prompts – the text input that guides the behavior
    of a **large language model** (**LLM**) – for LLMs for a wide variety of applications
    and research topics. Since prompts have a massive impact on LLM performance, prompt
    engineering is a crucial activity while designing LLM-powered applications. In
    fact, there are several techniques that can be implemented not only to refine
    your LLM’s responses but also to reduce risks associated with hallucination and
    bias.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第2章**中，我们介绍了提示工程的概念，即设计优化提示——引导**大型语言模型**（**LLM**）行为的文本输入——的过程，用于广泛的LLM应用和研究主题。由于提示对LLM性能有巨大影响，因此提示工程在设计LLM驱动的应用时是一个关键活动。实际上，有一些技术不仅可以完善你的LLM的响应，还可以降低与幻觉和偏差相关的风险。
- en: In this chapter, we are going to cover the emerging techniques in the field
    of prompt engineering, starting from basic approaches up to advanced frameworks.
    By the end of this chapter, you will have the foundations to build functional
    and solid prompts for your LLM-powered applications, which will also be relevant
    in the upcoming chapters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍提示工程领域的新兴技术，从基本方法到高级框架。到本章结束时，你将拥有为你的LLM驱动的应用构建功能性和稳固提示的基础，这些内容在接下来的章节中也将相关。
- en: 'We will go through the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨以下主题：
- en: Introduction to prompt engineering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程简介
- en: Basic principles of prompt engineering
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程的基本原则
- en: Advanced techniques of prompt engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程的高级技术
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete the tasks in this chapter, you will require the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章中的任务，你需要以下要求：
- en: OpenAI account and API
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI账户和API
- en: Python 3.7.1 or later version
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7.1或更高版本
- en: You can find all the code and examples in the book’s GitHub repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_04.xhtml).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的GitHub仓库[https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_04.xhtml)中找到所有代码和示例。
- en: What is prompt engineering?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: A prompt is a text input that guides the behavior of an LLM to generate a text
    output.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是一种文本输入，它指导LLM生成文本输出。
- en: Prompt engineering is the process of designing effective prompts that elicit
    high-quality and relevant output from LLMs. Prompt engineering requires creativity,
    understanding of the LLM, and precision.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是设计有效的提示，以从LLMs中激发高质量和相关性输出的过程。提示工程需要创造力、对LLM的理解和精确性。
- en: 'The following figure shows an example of how a well-written prompt can instruct
    the same model to perform three different tasks:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了如何通过一个精心编写的提示来指导同一模型执行三个不同的任务：
- en: '![](img/B21714_04_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B21714_04_01.png)'
- en: 'Figure 4.1: Example of prompt engineering to specialize LLMs'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：提示工程示例，用于专门化LLM
- en: As you might imagine, the prompt becomes one of the key elements for an LLM-powered
    application’s success. As such, it is pivotal to invest time and resources in
    this step, following some best practices and principles that we are going to cover
    in the next sections.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，提示成为LLM驱动的应用成功的关键要素之一。因此，在这一步投入时间和资源至关重要，遵循我们将在下一节中介绍的一些最佳实践和原则。
- en: Principles of prompt engineering
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程原理
- en: Generally speaking, there are no fixed rules to obtain the “perfect” prompt
    since there are too many variables to be taken into account (the type of model
    used, the goal of the application, the supporting infrastructure, and so on).
    Nevertheless, there are some clear principles that have proven to produce positive
    effects if incorporated into the prompt. Let’s examine some of them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，由于需要考虑的变量太多（使用的模型类型、应用目标、支持的基础设施等），没有固定的规则来获得“完美”的提示。尽管如此，有一些明确的原理，如果将其纳入提示中，已被证明会产生积极的效果。让我们来探讨一些。
- en: Clear instructions
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 明确的指令
- en: 'The principle of giving clear instructions is to provide the model with enough
    information and guidance to perform the task correctly and efficiently. Clear
    instructions should include the following elements:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 明确指令的原则是向模型提供足够的信息和指导，以便正确且高效地完成任务。明确的指令应包括以下要素：
- en: The goal or objective of the task, such as “write a poem” or “summarize an article”
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的目标或目的，例如“写一首诗”或“总结一篇文章”
- en: The format or structure of the expected output, such as “use four lines with
    rhyming words” or “use bullet points with no more than 10 words each”
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期输出的格式或结构，例如“使用四行押韵的词”或“使用每项不超过10个单词的项目符号”
- en: The constraints or limitations of the task, such as “do not use any profanity”
    or “do not copy any text from the source”
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务约束或限制，例如“不要使用任何粗俗语言”或“不要复制任何源文本”
- en: The context or background of the task, such as “the poem is about autumn” or
    “the article is from a scientific journal”
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的上下文或背景，例如“这首诗是关于秋天的”或“这篇文章来自科学期刊”
- en: 'Let’s say, for example, that we want our model to fetch any kind of instructions
    from text and return to us a tutorial in a bullet list. Also, if there are no
    instructions in the provided text, the model should inform us about that. Here
    are the steps:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，例如，我们希望我们的模型能够从文本中获取任何类型的指令，并以项目符号列表的形式返回教程。此外，如果提供的文本中没有指令，模型应通知我们。以下是步骤：
- en: 'First, we need to initialize our model. For this purpose, we are going to leverage
    OpenAI’s GPT-3.5-turbo model. We first install the `openai` library:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要初始化我们的模型。为此，我们将利用 OpenAI 的 GPT-3.5-turbo 模型。我们首先安装 `openai` 库：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To initialize the model, I used the `openai` Python library and set the OpenAI
    API key as the environmental variable:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了初始化模型，我使用了 `openai` Python 库，并将 OpenAI API 密钥设置为环境变量：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, the chat model comes with two variables placeholders: `system
    message` (or metaprompt), where we define how we want our model to behave, and
    `instructions` (or query), where the user will ask the model its questions.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，聊天模型包含两个变量占位符：`system message`（或元提示），在这里我们定义我们希望模型如何表现，以及`instructions`（或查询），用户将向模型提问。
- en: 'Then, it takes the user’s query (in this case, the text instructions). For
    this scenario, I set the two variables `system_message` and `instructions` as
    follows:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它获取用户的查询（在这种情况下，文本指令）。对于这个场景，我将两个变量 `system_message` 和 `instructions` 设置如下：
- en: '[PRE2]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let’s test our model:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们测试我们的模型：
- en: '[PRE3]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We get the following output:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that if we pass the model another text that does not contain any instructions,
    it will be able to respond as we instructed it:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，如果我们向模型传递另一段不包含任何指令的文本，它将能够按照我们的指示进行响应：
- en: '[PRE5]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following is the corresponding output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对应的输出：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By giving clear instructions, you can help the model understand what you want
    it to do and how you want it to do it. This can improve the quality and relevance
    of the model’s output and reduce the need for further revisions or corrections.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过给出清晰的指令，你可以帮助模型理解你想要它做什么以及你希望它如何去做。这可以提高模型输出的质量和相关性，并减少进一步修订或校正的需求。
- en: However, sometimes, there are scenarios where clarity is not enough. We might
    need to infer the way of thinking of our LLM to make it more robust with respect
    to its task. In the next section, we are going to examine one of these techniques,
    which will be very useful in the case of accomplishing complex tasks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时，即使清晰度足够，也可能存在一些场景。我们可能需要推断我们的 LLM 的思维方式，使其在任务上更加稳健。在下一节中，我们将检查这些技术之一，这在完成复杂任务时将非常有用。
- en: Split complex tasks into subtasks
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将复杂任务分解为子任务
- en: As discussed earlier, prompt engineering is a technique that involves designing
    effective inputs for LLMs to perform various tasks. Sometimes, the tasks are too
    complex or ambiguous for a single prompt to handle, and it is better to split
    them into simpler subtasks that can be solved by different prompts.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，提示工程是一种技术，涉及为 LLM 设计有效的输入以执行各种任务。有时，任务过于复杂或含糊不清，以至于单个提示无法处理，最好将它们分解为更简单的子任务，这些子任务可以通过不同的提示来解决。
- en: 'Here are some examples of splitting complex tasks into subtasks:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些将复杂任务分解为子任务的例子：
- en: '**Text summarization:** A complex task that involves generating a concise and
    accurate summary of a long text. This task can be split into subtasks such as:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本摘要：** 一个复杂任务，涉及生成一个简洁且准确的摘要。这个任务可以分为子任务，例如：'
- en: Extracting the main points or keywords from the text
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中提取主要观点或关键词
- en: Rewriting the main points or keywords in a coherent and fluent way
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以连贯流畅的方式重写主要观点或关键词
- en: Trimming the summary to fit a desired length or format
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将摘要修剪到期望的长度或格式
- en: '**Machine translation:** A complex task that involves translating a text from
    one language to another. This task can be split into subtasks such as:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器翻译：** 一个复杂任务，涉及将文本从一种语言翻译成另一种语言。这个任务可以分为子任务，例如：'
- en: Detecting the source language of the text
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别文本的源语言
- en: Converting the text into an intermediate representation that preserves the meaning
    and structure of the original text
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本转换为保留原始文本意义和结构的中间表示
- en: Generating the text in the target language from the intermediate representation
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从中间表示生成目标语言的文本
- en: '**Poem generation**: A creative task that involves producing a poem that follows
    a certain style, theme, or mood. This task can be split into subtasks such as:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**诗歌生成**：一项创造性的任务，涉及创作遵循特定风格、主题或情感的诗歌。这项任务可以分解为以下子任务：'
- en: Choosing a poetic form (such as sonnet, haiku, limerick, etc.) and a rhyme scheme
    (such as ABAB, AABB, ABCB, etc.) for the poem
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择诗歌的形式（如十四行诗、俳句、雷姆里克等）和押韵模式（如ABAB、AABB、ABCB等）为诗歌
- en: Generating a title and a topic for the poem based on the user’s input or preference
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户的输入或偏好生成诗歌的标题和主题
- en: Generating the lines or verses of the poem that match the chosen form, rhyme
    scheme, and topic
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成符合所选形式、押韵模式和主题的诗行或诗节
- en: Refining and polishing the poem to ensure coherence, fluency, and originality
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精炼和润色诗歌，以确保连贯性、流畅性和原创性
- en: '**Code generation**: A technical task that involves producing a code snippet
    that performs a specific function or task. This task can be split into subtasks
    such as:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：一项技术任务，涉及生成执行特定功能或任务的代码片段。这项任务可以分解为以下子任务：'
- en: Choosing a programming language (such as Python, Java, C++, etc.) and a framework
    or library (such as TensorFlow, PyTorch, React, etc.) for the code
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择编程语言（如Python、Java、C++等）以及框架或库（如TensorFlow、PyTorch、React等）用于代码
- en: Generating a function name and a list of parameters and return values for the
    code based on the user’s input or specification
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户的输入或规格生成代码的函数名和参数列表以及返回值
- en: Generating the body of the function that implements the logic and functionality
    of the code
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成实现代码逻辑和功能的函数体
- en: Adding comments and documentation to explain the code and its usage
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加注释和文档来解释代码及其用法
- en: 'Let’s consider the following example in Python, where we will ask our model
    to generate a summary of an article:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下Python示例，我们将要求我们的模型生成一篇文章的摘要：
- en: 'We will leverage OpenAI’s GPT-3.5-turbo model in a manner similar to the example
    discussed earlier in this chapter:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将利用OpenAI的GPT-3.5-turbo模型，方式与本章前面讨论的示例类似：
- en: '[PRE7]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s set both the `system_message` and `article` variables as follows (you
    can find the entire scripts in the book’s GitHub repository):'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将`system_message`和`article`变量设置为以下内容（您可以在书籍的GitHub存储库中找到整个脚本）：
- en: '[PRE8]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To see the output, you can run the following code:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看输出，您可以运行以下代码：
- en: '[PRE9]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here is the obtained output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是获得的结果：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, the model was able to produce a high-quality summary based on
    the key topics extracted (and displayed) from the given article. The fact that
    we prompted the model to split the task into subtasks “forced” it to reduce the
    complexity of each subtask, hence improving the quality of the final result. This
    approach can also lead to noticeable results when we deal with scenarios such
    as mathematical problems since it enhances the analytical reasoning capabilities
    of the model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型能够根据从给定文章中提取（并显示）的关键主题生成高质量的摘要。我们提示模型将任务分解为子任务“迫使”它降低每个子任务的复杂性，从而提高了最终结果的质量。这种方法在处理数学问题等场景时也能带来显著的效果，因为它增强了模型的推理能力。
- en: '**Note**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: In a landscape of many different LLMs, it is crucial to know that the very same
    system message may not be as efficient in all models. A system message that perfectly
    works with GPT-4 might not be as efficient when applied to Llama 2, for example.
    Therefore, it is pivotal to design the prompt in accordance with the type of LLM
    you decide to pick for your application.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多不同的LLM中，了解同一个系统消息可能并不在所有模型中都同样有效。例如，与GPT-4完美配合的系统消息在应用于Llama 2时可能效率不高。因此，根据您为应用程序选择的LLM类型设计提示至关重要。
- en: Splitting complex tasks into easier subtasks is a powerful technique; nevertheless,
    it does not address one of the main risks of LLM-generated content, that is, having
    a wrong output. In the next two sections, we are going to see some techniques
    that are mainly aimed at addressing this risk.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 将复杂任务分解为更简单的子任务是一种强大的技术；然而，它并没有解决LLM生成内容的主要风险之一，即输出错误。在接下来的两个部分中，我们将看到一些主要旨在解决这一风险的技术。
- en: Ask for justification
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要求进行论证
- en: 'LLMs are built in such a way that they predict the next token based on the
    previous ones without looking back at their generations. This might lead the model
    to output wrong content to the user, yet in a very convincing way. If the LLM-powered
    application does not provide a specific reference to that response, it might be
    hard to validate the ground truth behind it. Henceforth, specifying in the prompt
    to support the LLM’s answer with some reflections and justification could prompt
    the model to recover from its actions. Furthermore, asking for justification might
    be useful also in case of answers that are right but we simply don’t know the
    LLM’s reasoning behind it. For example, let’s say we want our LLM to solve riddles.
    To do so, we can instruct it as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是以一种方式构建的，它们根据前面的标记预测下一个标记，而不会回顾它们的生成内容。这可能会导致模型以非常令人信服的方式向用户输出错误的内容。如果LLM驱动的应用程序没有提供对该响应的具体参考，那么验证其背后的真实情况可能会很困难。因此，在提示中指定使用一些反思和论证来支持LLM的答案可能会促使模型从其行为中恢复过来。此外，要求进行论证也可能在答案正确但我们不知道LLM背后的推理时有用。例如，假设我们想让我们的LLM解决谜语。为此，我们可以这样指示它：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As you can see, I’ve specified in the metaprompt to the LLM to justify its
    answer and also provide its reasoning. Let’s see how it works:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我在元提示中指定了要求LLM对其答案进行论证并提供其推理。让我们看看它是如何工作的：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following is the obtained output:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的输出结果如下：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Justifications are a great tool to make your model more reliable and robust
    since they force it to “rethink” its output, as well as provide us with a view
    of how the reasoning was set to solve the problem.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 论证是使您的模型更加可靠和健壮的绝佳工具，因为它们迫使模型“重新思考”其输出，同时也为我们提供了如何设置推理以解决问题的一个视角。
- en: With a similar approach, we could also intervene at different prompt levels
    to improve our LLM’s performance. For example, we might discover that the model
    is systematically tackling a mathematical problem in the wrong way; henceforth,
    we might want to suggest the right approach directly at the metaprompt level.
    Another example might be that of asking the model to generate multiple outputs
    – along with their justifications – to evaluate different reasoning techniques
    and prompt the best one in the metaprompt.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似的方法，我们也可以在不同的提示级别上进行干预，以改善我们的LLM性能。例如，我们可能会发现模型在系统地以错误的方式解决数学问题；因此，我们可能会在元提示级别上直接建议正确的方法。另一个例子可能是要求模型生成多个输出——包括它们的理由——以评估不同的推理技术，并在元提示中提示最佳的一个。
- en: In the next section, we are going to focus on one of these examples, more specifically,
    the possibility of generating multiple outputs and then picking the most likely
    one.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将关注这些例子中的一个，更具体地说，是生成多个输出然后选择最可能的一个的可能性。
- en: Generate many outputs, then use the model to pick the best one
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成多个输出，然后使用模型选择最佳的一个
- en: As we saw in the previous section, LLMs are built in such a way that they predict
    the next token based on the previous ones without looking back at their generations.
    If this is the case, if one sampled token is the wrong one (in other words, if
    the model is unlucky), the LLM will keep generating wrong tokens and, henceforth,
    wrong content. Now, the bad news is that, unlike humans, LLMs cannot recover from
    errors on their own. This means that, if we ask them, they acknowledge the error,
    but we need to explicitly prompt them to think about that.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中看到的，LLMs（大型语言模型）是以一种方式构建的，它们根据前面的标记预测下一个标记，而不会回顾它们的生成内容。如果这种情况发生，如果一个采样的标记是错误的（换句话说，如果模型运气不好），LLM将会继续生成错误的标记，从而生成错误的内容。现在，坏消息是，与人类不同，LLMs无法自行从错误中恢复。这意味着，如果我们要求它们，它们会承认错误，但我们需要明确提示它们去思考这一点。
- en: 'One way to overcome this limitation is to broaden the space of probabilities
    of picking the right token. Rather than generating just one response, we can prompt
    the model to generate multiple responses, and then pick the one that is most suitable
    for the user’s query. This splits the job into two subtasks for our LLM:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 克服这种限制的一种方法是通过扩大选择正确标记的概率空间。而不仅仅生成一个响应，我们可以提示模型生成多个响应，然后选择最适合用户查询的一个。这把我们的LLM的工作分成了两个子任务：
- en: Generating multiple responses to the user’s query
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对用户的查询生成多个响应
- en: Comparing those responses and picking the best one, according to some criteria
    we can specify in the metaprompt
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较这些响应并根据我们可以在元提示中指定的某些标准选择最佳的一个
- en: 'Let’s see an example, following up from the riddles examined in the previous
    section:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个例子，继续探讨上一节中讨论的谜题：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In this case, I’ve prompted the model to generate three answers to the riddle,
    then to give me the most likely, justifying why. Let’s see the result:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我提示模型对谜题生成三个答案，然后告诉我最有可能的答案，并说明理由。让我们看看结果：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We then get the following output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后得到以下输出：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, the model selected the most plausible answer along with a justification
    of its choice. It is interesting to note that “clock” and “watch” might seem similar
    responses; however, the model specified that “watch” is usually worn on a person’s
    wrist and, even though it doesn’t mean it has arms or legs, this element might
    have lowered the probability of being the correct answer.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型选择了最合理的答案，并对其选择进行了说明。值得注意的是，“时钟”和“手表”可能看起来是相似的回答；然而，模型明确指出“手表”通常戴在人的手腕上，尽管这并不意味着它有手臂或腿，但这个元素可能降低了它成为正确答案的概率。
- en: What would you have picked?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你会选择什么？
- en: As discussed earlier, forcing the model to tackle a problem with different approaches
    is a way to collect multiple samples of reasonings, which might serve as further
    instructions in the metaprompt. For example, if we want the model to always propose
    something that is not the most straightforward solution to a problem – in other
    words, if we want it to “think differently” – we might force it to solve a problem
    in N ways and then use the most creative reasoning as a framework in the metaprompt.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，迫使模型以不同的方法解决一个问题是一种收集多个推理样本的方法，这可能会作为元提示中的进一步指令。例如，如果我们想让模型始终提出不是问题最直接解决方案的建议——换句话说，如果我们想让它“思考不同”的话——我们可能迫使它以N种方式解决问题，然后使用最具创造性的推理作为元提示的框架。
- en: The last element we are going to examine is the overall structure we want to
    give to our metaprompt. In fact, in previous examples, we saw a sample system
    message with some statements and instructions. In the next section, we will see
    how the order and “strength” of those statements and instructions are not invariants.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要检查的最后一个元素是我们想要赋予我们的元提示的整体结构。实际上，在之前的例子中，我们看到了一个包含一些声明和指令的示例系统消息。在下一节中，我们将看到那些声明和指令的顺序和“强度”并不是不变的。
- en: Repeat instructions at the end
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重复指令在末尾
- en: LLMs tend not to process the metaprompt attributing the same weight or imprortance
    to all the sections. In fact, in his blog post *Large Language Model Prompt Engineering
    for Complex Summarization*, John Stewart (a software engineer at Microsoft) found
    some interesting outcomes from arranging prompt sections ([https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/)).
    More specifically, after several experimentations, he found that repeating the
    main instruction at the end of the prompt can help the model overcome its inner
    **recency bias**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）往往不会对元提示中的所有部分赋予相同的权重或重要性。实际上，在John Stewart（微软的一名软件工程师）的博客文章《大型语言模型复杂摘要的提示工程》中，他发现了一些有趣的成果，这些成果来自于对提示部分的排列（[https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/gpt-summary-prompt-engineering/)）。更具体地说，经过几次实验，他发现重复在提示末尾的主要指令可以帮助模型克服其内在的**近期偏差**。
- en: '**Definition**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Recency bias is the tendency of LLMs to give more weight to the information
    that appears near the end of a prompt, and ignore or forget the information that
    appears earlier. This can lead to inaccurate or inconsistent responses that do
    not take into account the whole context of the task. For example, if the prompt
    is a long conversation between two people, the model may only focus on the last
    few messages and disregard the previous ones.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 近期偏差是大型语言模型（LLMs）倾向于给予提示末尾出现的信息更多权重，而忽略或忘记早期出现的信息的倾向。这可能导致不准确或不一致的响应，这些响应没有考虑到整个任务的上下文。例如，如果提示是两个人之间的长对话，模型可能只会关注最后几条消息，而忽略之前的消息。
- en: 'Let’s look at some ways to overcome recency bias:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些克服近期偏差的方法：
- en: One possible way to overcome recency bias is to break down the task into smaller
    steps or subtasks and provide feedback or guidance along the way. This can help
    the model focus on each step and avoid getting lost in irrelevant details. We’ve
    covered this technique in the *Split complex tasks into subtasks* section in,
    which we discussed splitting complex tasks into easier subtasks.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克服近期偏差的一个可能方法是将任务分解成更小的步骤或子任务，并在过程中提供反馈或指导。这可以帮助模型专注于每个步骤，避免在无关的细节中迷失。我们在“将复杂任务拆分为子任务”部分讨论了这项技术。
- en: Another way to overcome recency bias with prompt engineering techniques is to
    repeat the instructions or the main goal of the task at the end of the prompt.
    This can help remind the model of what it is supposed to do and what kind of response
    it should generate.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用提示工程技术克服近期偏差的另一种方法是，在提示的末尾重复指令或任务的主要目标。这可以帮助模型记住它应该做什么以及应该生成什么样的响应。
- en: For instance, let’s say we want our model to output the sentiment of a whole
    chat history between an AI agent and the user. We want to make sure that the model
    will output the sentiment in lowercase and without punctuation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想让我们的模型输出 AI 代理和用户之间整个聊天历史的情感。我们想确保模型将输出小写且不带标点的情感。
- en: 'Let’s consider the following example (the conversation is truncated, but you
    can find the whole code in the book’s GitHub repository). In this case, the key
    instruction is that of having as output only the sentiment in lowercase and without
    punctuation:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下示例（对话被截断，但你可以找到整个代码在本书的 GitHub 仓库中）。在这种情况下，关键指令是只输出小写且不带标点的情感：
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In this scenario, we have key instructions before the conversation, so let’s
    initialize our model and feed it with the two variables `system_message` and `conversation`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们在对话之前有关键指令，所以让我们初始化我们的模型，并用两个变量 `system_message` 和 `conversation` 来喂养它：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here is the output that we receive:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们收到的输出：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The model didn’t follow the instruction of having only lowercase letters. Let’s
    try to repeat the instruction also at the end of the prompt:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 模型没有遵循只使用小写字母的指令。让我们尝试在提示的末尾也重复指令：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Again, let’s invoke our model with the updated `system_message`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们用更新的 `system_message` 调用我们的模型：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here is the corresponding output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的输出：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, now the model was able to provide exactly the output we desired.
    This approach is particularly useful whenever we have a conversation history to
    keep storing in the context window. If this is the case, having the main instructions
    at the beginning might induce the model not to have them in mind once it also
    goes through the whole history, hence reducing their strength.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，现在模型能够提供我们想要的精确输出。这种方法特别有用，每当我们在上下文窗口中存储对话历史时。如果这种情况发生，将主要指令放在开头可能会让模型在通过整个历史记录时不再考虑这些指令，从而减弱它们的影响力。
- en: Use delimiters
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用分隔符
- en: The last principle to be covered is related to the format we want to give to
    our metaprompt. This helps our LLM to better understand its intents as well as
    relate different sections and paragraphs to each other.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要讨论的最后一个原则与我们想要给我们的元提示的格式有关。这有助于我们的 LLM 更好地理解其意图，以及将不同的部分和段落联系起来。
- en: 'To achieve this, we can use delimiters within our prompt. A delimiter can be
    any sequence of characters or symbols that is clearly mapping a schema rather
    than a concept. For example, we can consider the following sequences to be delimiters:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们可以在提示中使用分隔符。分隔符可以是任何字符或符号的序列，它清楚地映射一个模式而不是一个概念。例如，我们可以考虑以下序列作为分隔符：
- en: '`>>>>`'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`>>>>`'
- en: '`====`'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`====`'
- en: '`------`'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`------`'
- en: '`####`'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`####`'
- en: '`` ` ` ` ` ` ``'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`` ` ` ` ` ` ``'
- en: 'This leads to a series of benefits, including:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致一系列的好处，包括：
- en: 'Clear separation: Delimiters mark distinct sections within a prompt, separating
    instructions, examples, and desired output.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰分隔：分隔符在提示中标记不同的部分，分离指令、示例和期望的输出。
- en: 'Guidance for LLMs: Proper use of delimiters removes ambiguity, guiding the
    model effectively.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 指导：正确使用分隔符可以消除歧义，有效地引导模型。
- en: 'Enhanced precision: Delimiters improve prompt understanding, resulting in more
    relevant responses.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高精确度：分隔符改进了提示理解，导致更相关的响应。
- en: 'Improved coherence: Effective use of delimiters organizes instructions, inputs,
    and outputs, leading to coherent responses.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高连贯性：有效使用分隔符组织指令、输入和输出，导致连贯的响应。
- en: 'Let’s consider, for example, a metaprompt that aims at instructing the model
    to translate user’s tasks into Python code, providing an example to do so:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个元提示，其目的是指导模型将用户的任务转换为Python代码，并提供一个示例：
- en: '[PRE23]def my_print(text):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE23]def my_print(text):'
- en: return print(text)
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return print(text)
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the above example, we’ve used delimiters to both specify the beginning and
    end of an example for a one-shot learning approach and, within the example, specify
    the Python code snippet.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，我们使用了分隔符来指定一次学习方法的示例的开始和结束，并在示例内部指定了Python代码片段。
- en: 'Let’s see how it works:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here is our output:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的输出：
- en: '[PRE26]python def fibonacci(n):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE26]python def fibonacci(n):'
- en: 'if n < 0:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'if n < 0:'
- en: return None
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: return None
- en: 'elif n == 0:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif n == 0:'
- en: return 0
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: return 0
- en: 'elif n == 1:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif n == 1:'
- en: return 1
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: return 1
- en: 'else:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: return fibonacci(n-1) + fibonacci(n-2) [PRE27]
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: return fibonacci(n-1) + fibonacci(n-2) [PRE27]
- en: As you can see, it also printed the code with backticks, as shown within the
    system message.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它还打印了带有反引号的代码，正如系统消息中所示。
- en: All the principles examined up to this point are general rules that can make
    your LLM-powered application more robust. Those techniques should be kept in mind
    regardless of the type of application you are developing since they are general
    best practices that improve your LLM performance. In the following section, we
    are going to see some advanced techniques for prompt engineering.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止所检查的所有原则都是通用规则，可以使你的基于LLM的应用程序更加健壮。无论你正在开发哪种类型的应用程序，都应该记住这些技术，因为它们是通用的最佳实践，可以提高你的LLM性能。在下一节中，我们将看到一些高级的提示工程技术。
- en: Advanced techniques
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级技术
- en: Advanced techniques might be implemented for specific scenarios and address
    the way the model reasons and thinks about the answer before providing it to the
    final user. Let’s look at some of these in the upcoming sections.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 根据特定场景实施的高级技术可能针对模型推理和思考答案的方式，在向最终用户提供答案之前。让我们在接下来的章节中看看其中的一些。
- en: Few-shot approach
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少量样本方法
- en: In their paper *Language Models are Few-Shot Learners*, Tom Brown et al. demonstrate
    that GPT-3 can achieve strong performance on many NLP tasks in a few-shot setting.
    This means that for all tasks, GPT-3 is applied without any fine-tuning, with
    tasks and few-shot demonstrations specified purely via text interaction with the
    model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文《Language Models are Few-Shot Learners》中，Tom Brown等人证明了GPT-3在少量样本设置下可以在许多NLP任务上取得良好的性能。这意味着对于所有任务，GPT-3都是未经任何微调应用的，任务和少量样本演示完全通过模型与文本的交互来指定。
- en: This is an example and evidence of how the concept of few-shot learning – which
    means providing the model with examples of how we would like it to respond – is
    a powerful technique that enables model customization without interfering with
    the overall architecture.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例和证据，说明了少量样本学习（few-shot learning）的概念——即向模型提供我们希望其如何响应的示例——是一种强大的技术，它可以在不干扰整体架构的情况下实现模型定制。
- en: For example, let’s say we want our model to generate a tagline for a new product
    line of climbing shoes we’ve just coined – Elevation Embrace. We have an idea
    of what the tagline should be like – concise and direct. We could explain it to
    the model in plain text; however, it might be more effective simply to provide
    it with some examples of similar projects.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们希望我们的模型为我们的新登山鞋产品线——我们刚刚命名的Elevation Embrace——生成一个标语。我们有一个关于标语应该是什么样的想法——简洁直接。我们可以用纯文本向模型解释它；然而，直接提供一些类似项目的示例可能更有效。
- en: 'Let’s see an implementation with code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过代码来查看一个实现：
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let’s see how our model will handle this request:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的模型将如何处理这个请求：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following is our output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们输出的结果：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As you can see, it maintained the style, length, and also writing convention
    of the provided taglines. This is extremely useful when you want your model to
    follow examples you already have, such as fixed templates.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它保持了提供的标签的风格、长度和写作规范。当你希望你的模型遵循你已有的示例时，例如固定模板，这非常有用。
- en: Note that, most of the time, few-shot learning is powerful enough to customize
    a model even in extremely specialized scenarios, where we could think about fine-tuning
    as the proper tool. In fact, proper few-shot learning could be as effective as
    a fine-tuning process.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，大多数情况下，少量样本学习足够强大，甚至可以在极端专业化的场景中定制模型，在这种情况下，我们可以将微调视为适当的工具。事实上，适当的少量样本学习可能和微调过程一样有效。
- en: Let’s look at another example. Let’s say we want to develop a model that specializes
    in sentiment analysis. To do so, we provide it with a series of examples of texts
    with different sentiments, alongside the output we would like – positive or negative.
    Note that this set of examples is nothing but a small training set for supervised
    learning tasks; the only difference from fine-tuning is that we are not updating
    the model’s parameters.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个例子。假设我们想要开发一个专注于情感分析的模型。为此，我们提供了一系列具有不同情感的文本示例，以及我们想要的输出——正面或负面。请注意，这组示例只是监督学习任务的小型训练集；与微调的唯一区别是我们没有更新模型的参数。
- en: 'To provide you with a concrete representation of what was said above, let’s
    provide our model with just two examples for each label:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向您提供一个具体的表示，让我们为每个标签提供两个示例：
- en: '[PRE31]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To test our classifier, I’ve used the IMDb database of movie reviews available
    on Kaggle at [https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data).
    As you can see, the dataset contains many movie reviews along with their associated
    sentiment – positive or negative. Let’s substitute the binary label of 0–1 with
    a verbose label of Negative–Positive:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的分类器，我使用了Kaggle上可用的IMDb电影评论数据库，网址为[https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data)。正如您所看到的，数据集包含许多电影评论及其相关的情感——正面或负面。让我们将0-1的二进制标签替换为详尽的标签“负面-正面”：
- en: '[PRE32]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This gives us the first few records of the dataset, which are as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了数据集的前几条记录，具体如下：
- en: '![](img/B21714_04_02.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21714_04_02.png)'
- en: 'Figure 4.2: First observations of the movie dataset'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：电影数据集的第一观察
- en: 'Now, we want to test the performance of our model over a sample of 10 observations
    of this dataset:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要测试我们的模型在数据集的10个观察样本上的性能：
- en: '[PRE33]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following is our output:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们输出的结果：
- en: '![A text on a white background  Description automatically generated](img/B21714_04_03.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![白色背景上的文本  自动生成的描述](img/B21714_04_03.png)'
- en: 'Figure 4.3: Output of a GPT-3.5 model with few-shot examples'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：GPT-3.5模型在少量示例下的输出
- en: As you can see, by comparing the `label` and `predicted` columns, the model
    was able to correctly classify all the reviews, without even fine-tuning! This
    is just an example of what you can achieve – in terms of model specialization
    – with the technique of few-shot learning.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，通过比较“标签”和“预测”列，模型能够正确地分类所有评论，甚至没有进行微调！这只是您可以通过少量学习技术实现的例子——在模型专业化方面。
- en: Chain of thought
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链
- en: Introduced in the paper *Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models* by Wei et al., **chain of thought** (**CoT**) is a technique
    that enables complex reasoning capabilities through intermediate reasoning steps.
    It also encourages the model to explain its reasoning, “forcing” it not to be
    too fast and risking giving the wrong response (as we saw in previous sections).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在Wei等人撰写的论文《思维链提示在大型语言模型中激发推理》中引入的**思维链**（**CoT**）是一种通过中间推理步骤实现复杂推理能力的技巧。它还鼓励模型解释其推理，迫使它不要过于迅速，以免给出错误响应（如我们在前面的章节中看到的）。
- en: 'Let’s say that we want to prompt our LLM to solve generic first-degree equations.
    To do so, we are going to provide it with a basic reasoning list that it might
    want to follow:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要提示我们的LLM（大型语言模型）解决一元一次方程。为此，我们将提供一个基本的推理列表，它可能想要遵循：
- en: '[PRE34]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s see how it can be implemented:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何实现的：
- en: '[PRE35]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following is our output:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们输出的结果：
- en: '[PRE36]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: As you can see, the model clearly followed the seven steps specified in the
    metaprompt, which also allows the model to “take its time” to perform this task.
    Note that you can also combine it with few-shot prompting to get better results
    on more complex tasks that require reasoning before responding.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型清楚地遵循了元提示中指定的七个步骤，这也允许模型“慢慢来”完成这项任务。请注意，您还可以将其与少量提示结合使用，以在需要推理才能回答的更复杂任务上获得更好的结果。
- en: With CoT, we are prompting the model to generate intermediate reasoning steps.
    This is also a component of another reasoning technique, which we are going to
    examine in the next section.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CoT（思维链），我们正在提示模型生成中间推理步骤。这也是另一种推理技术的组成部分，我们将在下一节中对其进行探讨。
- en: ReAct
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct
- en: 'Introduced in the paper *ReAct: Synergizing Reasoning and Acting in Language
    Models* by Yao et al., **ReAct** (**Reason and Act**) is a general paradigm that
    combines reasoning and acting with LLMs. ReAct prompts the language model to generate
    verbal reasoning traces and actions for a task, and also receives observations
    from external sources such as web searches or databases. This allows the language
    model to perform dynamic reasoning and quickly adapt its action plan based on
    external information. For example, you can prompt the language model to answer
    a question by first reasoning about the question, then performing an action to
    send a query to the web, then receiving an observation from the search results,
    and then continuing with this thought, action, observation loop until it reaches
    a conclusion.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 由姚等人发表的论文《ReAct：在语言模型中协同推理和行动》中引入的**ReAct**（**推理和行动**）是一个将推理和行动与LLMs结合的通用范式。ReAct促使语言模型为任务生成口头推理轨迹和行动，并从外部来源（如网络搜索或数据库）接收观察结果。这使得语言模型能够执行动态推理，并根据外部信息快速调整其行动计划。例如，你可以提示语言模型首先对问题进行推理，然后执行一个动作向网络发送查询，然后从搜索结果中接收观察结果，接着继续这个思考、行动、观察的循环，直到得出结论。
- en: The difference between CoT and ReAct approaches is that CoT prompts the language
    model to generate intermediate reasoning steps for a task, while ReAct prompts
    the language model to generate intermediate reasoning steps, actions, and observations
    for a task.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: CoT和ReAct方法之间的区别在于，CoT提示语言模型为任务生成中间推理步骤，而ReAct提示语言模型为任务生成中间推理步骤、行动和观察。
- en: Note that the “action” phase is generally related to the possibility for our
    LLM to interact with external tools, such as a web search.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，“行动”阶段通常与我们的LLM与外部工具（如网络搜索）交互的可能性有关。
- en: 'For example, let’s say we want to ask our model for some up-to-date information
    about the upcoming Olympic games. To do so, we are going to build a smart LangChain
    agent (as described in *Chapter 2*) leveraging `SerpAPIWrapperWrapper` (to wrap
    the `SerpApi` to navigate the web), the `AgentType` tool (to decide which type
    of agent to use for our goal), and other prompt-related modules (to make it easier
    to “templatize” our instructions). Let’s see how we can do this (I won’t dive
    deeper into each component of the following code since the next chapter will be
    entirely focused on LangChain and its main components):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要询问模型有关即将到来的奥运会的最新信息。为此，我们将构建一个智能LangChain代理（如第2章所述），利用`SerpAPIWrapperWrapper`（将`SerpApi`包装以导航网络）、`AgentType`工具（决定为我们目标使用哪种类型的代理）和其他与提示相关的模块（使其更容易“模板化”我们的指令）。让我们看看我们如何做到这一点（由于下一章将完全专注于LangChain及其主要组件，因此我不会深入探讨以下代码的每个组件）：
- en: '[PRE37]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'As you can see, for this purpose, I’ve used a pre-built agent type available
    in LangChain called `ZERO_SHOT_REACT_DESCRIPTION`. It comes with a precompiled
    prompt that follows the ReAct approach. Let’s inspect that prompt:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，为此，我使用了LangChain中可用的预构建代理类型`ZERO_SHOT_REACT_DESCRIPTION`。它附带了一个遵循ReAct方法的预编译提示。让我们检查一下这个提示：
- en: '[PRE38]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here is the corresponding output:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的输出：
- en: '[PRE39]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let’s now test our agent by asking something about the upcoming Olympic games
    and zooming in on the intermediate steps:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在通过询问有关即将到来的奥运会的问题并聚焦于中间步骤来测试我们的代理：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This is the output with intermediate steps:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对中间步骤的输出：
- en: '[PRE41]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here is the obtained output:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是获得的输出：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: At the time of this question (7th of October 2023), the answer is definitely
    correct. Note how the model went through several iterations of `Observation`/`Thought`/`Action`
    until it reached the conclusion. This is a great example of how prompting a model
    to think step by step and explicitly define each step of the reasoning makes it
    “wiser” and more cautious before answering. It is also a great technique to prevent
    hallucination.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个问题的时间点（2023年10月7日），答案肯定是正确的。注意模型如何经过几次“观察”/“思考”/“行动”的迭代，直到得出结论。这是一个很好的例子，说明通过提示模型逐步思考和明确定义推理的每一步，使其在回答之前变得更加“聪明”和谨慎。这同样是一种防止幻觉的绝佳技术。
- en: Overall, prompt engineering is a powerful discipline, still in its emerging
    phase yet already widely adopted within LLM-powered applications. In the following
    chapters, we are going to see concrete applications of this technique.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，提示工程是一门强大的学科，尽管它仍处于起步阶段，但已经在LLM驱动的应用中得到广泛应用。在接下来的章节中，我们将看到这项技术的具体应用。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered many aspects of the activity of prompt engineering,
    a core step in the context of improving the performance of LLMs within your application,
    as well as customizing it depending on the scenario. Prompt engineering is an
    emerging discipline that is paving the way for a new category of applications,
    infused with LLMs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了提示工程活动的许多方面，这是在应用中提高大型语言模型（LLM）性能以及根据场景定制的一个核心步骤。提示工程是一个新兴学科，为注入LLM的新类别应用铺平了道路。
- en: 'We started with an introduction to the concept of prompt engineering and why
    it is important, and then moved toward the basic principles – including clear
    instructions, asking for justification, etc. Then, we moved on to more advanced
    techniques that are meant to shape the reasoning approach of our LLM: few-shot
    learning, CoT, and ReAct.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从提示工程的概念介绍及其重要性开始，然后转向基本原理——包括清晰的指令、要求理由等。然后，我们转向更高级的技术，旨在塑造我们LLM的推理方法：少样本学习、CoT和ReAct。
- en: In the next chapters, we will see those techniques in action by building real-world
    applications using LLMs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过使用LLM构建实际应用来展示这些技术的实际应用。
- en: References
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'ReAct approach: [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReAct方法：[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
- en: 'What is prompt engineering?: [https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提示工程？：[https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering)
- en: 'Prompt engineering techniques: [https://blog.mrsharm.com/prompt-engineering-guide/](https://blog.mrsharm.com/prompt-engineering-guide/)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程技术：[https://blog.mrsharm.com/prompt-engineering-guide/](https://blog.mrsharm.com/prompt-engineering-guide/)
- en: 'Prompt engineering principles: [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程原则：[https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions)
- en: 'Recency bias: [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近期偏差：[https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#repeat-instructions-at-the-end)
- en: 'Large Language Model Prompt Engineering for Complex Summarization: [https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂摘要的LLM提示工程：[https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/](https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/)
- en: 'Language Models are Few-Shot Learners: [https://arxiv.org/pdf/2005.14165.pdf](https://arxiv.org/pdf/2005.14165.pdf)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型是少样本学习者：[https://arxiv.org/pdf/2005.14165.pdf](https://arxiv.org/pdf/2005.14165.pdf)
- en: 'IMDb dataset: [https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IMDb数据集：[https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/code)
- en: 'ReAct: [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReAct：[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
- en: 'Chain of Thought Prompting Elicits Reasoning in Large Language Models: [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维链提示在大型语言模型中引发推理：[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
- en: Join our community on Discord
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/llm](https://packt.link/llm)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/llm](https://packt.link/llm)'
- en: '![](img/QR_Code214329708533108046.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code214329708533108046.png)'
