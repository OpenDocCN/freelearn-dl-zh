- en: Data Preparation for Training
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据准备
- en: So far, we've used existing Magenta pre-trained models since they are quite
    powerful and easy to use. But training our own models is crucial since it allows
    us to generate music in a specific style or generate specific structures or instruments.
    Building and preparing a dataset is the first step before training our own model.
    To do that, we need to look at existing datasets and APIs that will help us to
    find meaningful data. Then, we need to build two datasets in MIDI for specific
    styles—dance and jazz. Finally, we will need to prepare the MIDI files for training
    using data transformations and pipelines.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用的是现有的Magenta预训练模型，因为它们非常强大且易于使用。但训练我们自己的模型至关重要，因为这能让我们生成特定风格的音乐或特定的结构或乐器。构建和准备数据集是训练我们自己模型的第一步。为了做到这一点，我们需要查看现有的数据集和API，这些工具可以帮助我们找到有意义的数据。接着，我们需要为特定风格（舞曲和爵士）构建两个MIDI数据集。最后，我们需要通过数据转换和管道准备MIDI文件用于训练。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Looking at existing datasets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看现有的数据集
- en: Building a dance music dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建舞曲音乐数据集
- en: Building a jazz dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个爵士数据集
- en: Preparing the data using pipelines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用管道准备数据
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we''ll use the following tools:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下工具：
- en: '**A command line** or **Bash** to launch Magenta from the Terminal'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令行**或**Bash**从终端启动Magenta'
- en: '**Python** and its libraries'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python**及其库'
- en: The Python **multiprocessing** module for multi-threaded data preparation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python的**多进程**模块用于多线程数据准备
- en: '**Matplotlib** to plot our data preparation results'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**用于绘制数据准备结果'
- en: '**Magenta** to launch data pipeline conversion'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Magenta**启动数据管道转换'
- en: '**MIDI**, **ABCNotation**, and **MusicXML** as data formats'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MIDI**、**ABCNotation**和**MusicXML**作为数据格式'
- en: External APIs such as **Last.fm**
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外部API，如**Last.fm**
- en: In Magenta, we'll make use of **data pipelines**. We will explain these in depth
    later in this chapter, but if you feel like you need more information, the pipeline
    README file in Magenta's source code ([github.com/tensorflow/magenta/tree/master/magenta/pipelines](https://github.com/tensorflow/magenta/tree/master/magenta/pipelines))
    is a good place to start. You can also take a look at Magenta's code, which is
    well documented. There's also additional content in the *Further reading* section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在Magenta中，我们将使用**数据管道**。我们将在本章后续部分深入讲解这些内容，但如果你觉得需要更多信息，可以参考Magenta源代码中的管道README文件（[github.com/tensorflow/magenta/tree/master/magenta/pipelines](https://github.com/tensorflow/magenta/tree/master/magenta/pipelines)），这是一个很好的起点。你还可以查看Magenta的代码，文档也非常完善。另有更多内容可参考*进一步阅读*部分。
- en: The code for this chapter can be found in this book's GitHub repository, in
    the `Chapter06` folder, which is located at [github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter06](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter06).
    For this chapter, you should use the `cd Chapter06` command before you start.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在本书的GitHub仓库中找到，位于`Chapter06`文件夹，链接为[github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter06](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter06)。在本章中，你应该在开始之前使用`cd
    Chapter06`命令。
- en: Check out the following video to see the Code in Action: [http://bit.ly/3aXWLmC](http://bit.ly/3aXWLmC)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码如何运作：[http://bit.ly/3aXWLmC](http://bit.ly/3aXWLmC)
- en: Looking at existing datasets
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看现有的数据集
- en: In this chapter, we'll be preparing some data for training. Note that this will
    be covered in more detail in [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*. Preparing data and training models are two different
    activities that are done in tandem—first, we prepare the data, then train the
    models, and finally go back to preparing the data to improve our model's performance.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将为训练准备一些数据。请注意，关于这一点将在[第七章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)中详细介绍，*训练Magenta模型*。数据准备和模型训练是两个不同的活动，它们是并行进行的——首先，我们准备数据，然后训练模型，最后再回过头来准备数据，以提高模型的性能。
- en: First, we'll start by looking at symbolic representations other than MIDI, such
    as MusicXML and ABCNotation, since Magenta also handles them, even if the datasets
    we'll be working with in this chapter will be in MIDI only. Then, we'll provide
    an overview of existing datasets, including datasets from the Magenta team that
    were used to train some models we've already covered. This overview is by no means
    exhaustive but can serve as a starting point when it comes to finding training
    data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将看看除了 MIDI 以外的符号表示法，如 MusicXML 和 ABCNotation，因为 Magenta 也支持它们，即使我们在本章中使用的主要数据集是
    MIDI 格式。接着，我们将概述现有的数据集，包括 Magenta 团队用来训练我们已经介绍过的一些模型的数据集。这个概述并不详尽，但可以作为寻找训练数据的起点。
- en: The main dataset we'll be focusing on is the **Lakh MIDI dataset** (**LMD**),
    a recent and well crafted MIDI dataset that will serve as a basis for most of
    our examples. You can also use other datasets; the code we are providing here
    can be easily adapted to other content.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重点关注的主要数据集是 **Lakh MIDI 数据集**（**LMD**），这是一个最新且精心制作的 MIDI 数据集，将作为我们大部分示例的基础。你也可以使用其他数据集；我们提供的代码可以轻松适配其他内容。
- en: Looking at symbolic representations
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看符号表示法
- en: 'There are three main symbolic representations: MIDI, MusicXML, and ABCNotation.
    We''ve already covered MIDI in detail, but we haven''t talked about MusicXML and
    ABCNotation yet. While we won''t be using these two in this chapter, it is nice
    to know they exist and that Magenta can handle them as well as MIDI files.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种主要的符号表示法：MIDI、MusicXML 和 ABCNotation。我们已经详细讲解了 MIDI，但还没有讨论 MusicXML 和 ABCNotation。虽然我们在本章中不会使用这两种格式，但知道它们的存在以及
    Magenta 能够处理它们和 MIDI 文件也是有帮助的。
- en: '**MusicXML**, as its name suggests, is an XML-based musical representation
    format. It has the advantage of being text-based, meaning it doesn''t require
    an external library such as PrettyMIDI to be processed and is supported in many
    sheet music editors, such as MuseScore. You can find the MusicXML specification
    on its official website: [www.musicxml.com](https://www.musicxml.com/).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**MusicXML**，顾名思义，是一种基于 XML 的音乐表示格式。它的优点是基于文本，这意味着它不需要像 PrettyMIDI 这样的外部库来处理，并且在许多乐谱编辑器中都得到了支持，例如
    MuseScore。你可以在其官方网站找到 MusicXML 规范：[www.musicxml.com](https://www.musicxml.com/)。'
- en: 'Here''s an example of a MusicXML file:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 MusicXML 文件的示例：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**ABCNotation**, as its name suggests, is a text-based musical representation
    format based on the letter notation (A-G). The format is rather compact, with
    some header information concerning the whole file, followed by the content of
    the song using the letter notation. The notation is also well supported in sheet
    music software. Here''s an example of an ABCNotation file:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**ABCNotation**，顾名思义，是一种基于字母记谱（A-G）的文本音乐表示格式。该格式非常紧凑，包含一些关于整个文件的头部信息，后面跟着使用字母记谱法的歌曲内容。该记谱法在乐谱软件中也得到了广泛支持。下面是一个
    ABCNotation 文件的示例：'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We will provide some ABCNotation content in the *Looking at other datasets*
    section of this chapter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的*查看其他数据集*部分提供一些 ABCNotation 内容。
- en: The tools Magenta provides for preparing datasets for training handle MIDI,
    MusicXML, and ABCNotation in a single command, which is really handy. The `convert_dir_to_note_sequences` command
    will parse the content depending on its type and return `NoteSequence` regardless.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 提供的用于准备训练数据集的工具可以通过单个命令处理 MIDI、MusicXML 和 ABCNotation，这非常方便。`convert_dir_to_note_sequences`命令会根据内容类型进行解析，并返回
    `NoteSequence`。
- en: We'll look at these tools in more detail in [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第7章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)，*训练 Magenta 模型* 中详细介绍这些工具。
- en: Building a dataset from the ground up
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始构建数据集
- en: Using an existing dataset and trimming it down is the easiest way to start building
    and preparing a dataset for training since it is a rather fast method of getting
    enough data for training.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用现有的数据集并对其进行裁剪是构建和准备训练数据集的最简单方法，因为这是一种快速获取足够训练数据的方法。
- en: Another option is to build the dataset from scratch, either by creating new
    data for it or by incorporating data from various sources. While requiring more
    work, this method might give better results during training since the resulting
    data is carefully selected. This is a process you should follow if you are a musician
    and have your own MIDI files ready.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是从头开始构建数据集，要么通过为其创建新数据，要么通过整合来自不同来源的数据。虽然这种方法需要更多的工作，但在训练过程中可能会得到更好的结果，因为最终的数据是经过精心挑选的。如果你是音乐人并且已经有自己的
    MIDI 文件，可以遵循这个过程。
- en: Using the LMD for MIDI and audio files
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LMD进行MIDI和音频文件
- en: The LMD ([colinraffel.com/projects/lmd](https://colinraffel.com/projects/lmd/))
    is one of the most complete and easy-to-use MIDI datasets. If you don't have anything
    handy right now, we recommend using it. This chapter's code will use this dataset,
    but you can also follow the examples using another dataset since even if the information
    is different, most of the techniques we will use here can still be used.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LMD（[colinraffel.com/projects/lmd](https://colinraffel.com/projects/lmd/)）是其中一个最完整和易于使用的MIDI数据集。如果您现在手头没有合适的数据集，我们建议使用它。本章的代码将使用此数据集，但您也可以使用其他数据集来跟随示例，因为即使信息不同，我们这里使用的大部分技术仍然适用。
- en: 'The dataset has various distributions, but we''ll be looking at the following
    ones in particular:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有各种分布，但我们特别关注以下几个：
- en: '**LMD-full**: This is the full dataset, which contains 176,581 MIDI files.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LMD-full**：这是完整数据集，包含176,581个MIDI文件。'
- en: '**LMD-matched**: The dataset is partially matched to another dataset, the **million
    song dataset** (**MSD**), which contains 45,129 MIDI files. This subset is useful
    because the matched files contain metadata such as artist and title.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LMD-matched**：该数据集部分匹配到另一个数据集，即**million song dataset**（**MSD**），该数据集包含45,129个MIDI文件。这个子集很有用，因为匹配的文件包含艺术家和标题等元数据。'
- en: '**LMD-aligned**: The LMD-matched dataset is aligned with an audio MP3 preview.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LMD-aligned**：LMD匹配的数据集与音频MP3预览对齐。'
- en: Using the MSD for metadata information
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MSD获取元数据信息
- en: The MSD ([millionsongdataset.com](http://millionsongdataset.com/)) is a large
    scale dataset that has over a million entries containing audio features and metadata
    information. We won't be using the MSD dataset directly; instead, we'll be using
    the matched content included in the LMD-matched dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: MSD（[millionsongdataset.com](http://millionsongdataset.com/)）是一个大规模数据集，包含超过一百万条条目，包括音频特征和元数据信息。我们不会直接使用MSD数据集；相反，我们将使用包含在LMD匹配数据集中的匹配内容。
- en: Using the MAESTRO dataset for performance music
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MAESTRO数据集进行表演音乐
- en: The **MIDI and Audio Edited for Synchronous TRacks and Organization** (**MAESTRO**)
    dataset ([magenta.tensorflow.org/datasets/maestro](https://magenta.tensorflow.org/datasets/maestro))
    is curated by the Magenta team and is based on live performances that have been
    recorded to both audio and MIDI, for over 200 hours of content. Since the recorded
    performances have been played by humans, the notes have expressive timing and
    dynamics (effects pedals are also represented).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**MIDI和音频编辑同步轨道和组织**（**MAESTRO**）数据集（[magenta.tensorflow.org/datasets/maestro](https://magenta.tensorflow.org/datasets/maestro)）由Magenta团队策划，基于录制的现场表演，包括音频和MIDI，超过200小时的内容。由于这些录制的演奏是由人类演奏的，音符具有表现力的时序和动态（还包括效果踏板的表示）。'
- en: The dataset's content comes from the International Piano-e-Competition ([piano-e-competition.com/](http://piano-e-competition.com/)),
    which mainly contains classical music. This dataset has multiple usages, such
    as automatic audio to symbolic representation transcription, which has been used
    to train the Magenta Onsets and Frames model. It has also been used to train the
    Performance RNN model we covered in [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml),
    *Generating Polyphonic Melodies*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集内容来自国际钢琴电竞（[piano-e-competition.com/](http://piano-e-competition.com/)），主要包含古典音乐。该数据集有多种用途，如自动音频转换为符号表示转录，已用于训练Magenta
    Onsets和Frames模型。还用于训练我们在[Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml)中介绍的Performance
    RNN模型生成复调旋律。
- en: Similar to MAESTRO but with less content, you also have the MusicNet and MAPS
    datasets available. We won't be using the MAESTRO dataset for our examples, but
    it is an important dataset you might want to look at. For more information, take
    a look at the *Further reading* section at the end of this chapter.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与MAESTRO类似，但内容较少，您还可以使用MusicNet和MAPS数据集。我们在示例中不会使用MAESTRO数据集，但这是一个重要的数据集，您可能需要查看。有关更多信息，请查看本章末尾的*进一步阅读*部分。
- en: Using the Groove MIDI Dataset for groovy drums
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Groove MIDI数据集进行动感鼓声
- en: The **Groove MIDI Dataset** ([www.tensorflow.org/datasets/catalog/groove](https://www.tensorflow.org/datasets/catalog/groove))
    is composed of 13.6 hours of aligned MIDI and (synthesized) audio of human-performed,
    tempo-aligned expressive drumming captured on an electronic drum. The dataset
    is also split into 2-bars and 4-bars MIDI segments and has been used to train
    the GrooVAE model, which we presented in [Chapter 4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml),
    *Latent Space Interpolation with MusicVAE*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**Groove MIDI 数据集** ([www.tensorflow.org/datasets/catalog/groove](https://www.tensorflow.org/datasets/catalog/groove))
    包含了 13.6 小时的对齐 MIDI 和（合成的）人类演奏的、节奏对齐的富有表现力的电子鼓音频。该数据集还被分割成 2 小节和 4 小节的 MIDI 片段，并已用于训练
    GrooVAE 模型，我们在[第 4 章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)中介绍了该模型，*使用 MusicVAE
    进行潜在空间插值*。'
- en: The GMD is an impressive dataset of recorded performances from professional
    drummers, who also improvised for the occasion, resulting in a diverse dataset.
    The performances are annotated with a genre, which can be used to filter and extract
    certain MIDI files.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: GMD 是一个令人印象深刻的数据集，包含了专业鼓手的录音表演，这些鼓手还即兴创作，因而产生了多样化的数据集。这些表演带有一个类型标签，可以用来筛选和提取特定的
    MIDI 文件。
- en: While not quantized, the GMD can also be used to train quantized models, such
    as the drums RNN. The pipelines, which will be shown in the *Preparing the data
    using pipelines* section, can transform input data such as unquantized MIDI into
    quantized MIDI.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然未量化，但 GMD 也可以用于训练量化模型，如鼓 RNN。我们将在 *使用管道准备数据* 一节中展示的管道可以将未量化的 MIDI 转换为量化 MIDI。
- en: Using the Bach Doodle Dataset
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Bach Doodle 数据集
- en: Bach Doodle is a web application made by Google to celebrate the anniversary
    of the German composer and musician, Johann Sebastian Bach. Doodle allows the
    user to compose a 2-bars melody and ask the application to harmonize the input
    melody in Bach's style using Coconet and TensorFlow.js running in the browser.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Bach Doodle 是 Google 为庆祝德国作曲家和音乐家约翰·塞巴斯蒂安·巴赫周年纪念日而制作的一个 Web 应用程序。Doodle 允许用户创作
    2 小节旋律，并通过浏览器中的 Coconet 和 TensorFlow.js 请求应用程序以巴赫风格和声化输入的旋律。
- en: 'The resulting Bach Doodle Dataset ([magenta.tensorflow.org/datasets/bach-doodle](https://magenta.tensorflow.org/datasets/bach-doodle))
    of harmonized composition is impressive: 21.6 million harmonizations for about
    6 years of user-entered music. It contains the user input sequence and the output
    sequence from the network in note sequence format, as well as some metadata, such
    as the country of the user and the number of times it was played.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的 Bach Doodle 数据集 ([magenta.tensorflow.org/datasets/bach-doodle](https://magenta.tensorflow.org/datasets/bach-doodle))
    包含和声编曲，令人印象深刻：为大约 6 年用户输入的音乐提供了 2160 万种和声。它包含用户输入的序列和网络输出的音符序列格式的输出序列，以及一些元数据，如用户所在国家和播放次数。
- en: See the *Further reading* section for more information about data visualization
    regarding the dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见 *进一步阅读* 部分，了解有关数据集的数据可视化的更多信息。
- en: Using the NSynth dataset for audio content
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 NSynth 数据集进行音频内容处理
- en: We covered the NSynth dataset ([www.tensorflow.org/datasets/catalog/nsynth](https://www.tensorflow.org/datasets/catalog/nsynth))
    in the previous chapter, *Audio Generation with NSynth and GANSynth*. We won't
    be covering audio training in this book, but this is a good dataset to use for
    training the GANSynth model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中介绍了 NSynth 数据集 ([www.tensorflow.org/datasets/catalog/nsynth](https://www.tensorflow.org/datasets/catalog/nsynth))，*使用
    NSynth 和 GANSynth 进行音频生成*。本书不会涉及音频训练，但这是一个很好的数据集，可以用于训练 GANSynth 模型。
- en: Using APIs to enrich existing data
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 API 来丰富现有数据
- en: Using APIs is a good way of finding more information about MIDI tracks. We'll
    be showing an example of this in this chapter, where we'll query an API using
    the song artist and title to find genres and tags associated with the song.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 API 是查找更多 MIDI 曲目相关信息的好方法。在本章中，我们将展示如何使用歌曲艺术家和标题查询 API，来找到与该歌曲相关的类型和标签。
- en: There are multiple services you can use to find such information. We won't list
    all of them, but two good starting points are **Last.fm** ([www.last.fm/](https://www.last.fm/))
    and Spotify's **Echo Nest** ([static.echonest.com/enspex/](http://static.echonest.com/enspex/)).
    The **tagtraum** dataset ([www.tagtraum.com/msd_genre_datasets.html](http://www.tagtraum.com/msd_genre_datasets.html))
    is another good dataset for genre, which is based on MSD.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个服务可以用来查找此类信息。我们不会列出所有这些服务，但两个好的起点是 **Last.fm** ([www.last.fm/](https://www.last.fm/))
    和 Spotify 的 **Echo Nest** ([static.echonest.com/enspex/](http://static.echonest.com/enspex/))。**tagtraum**
    数据集 ([www.tagtraum.com/msd_genre_datasets.html](http://www.tagtraum.com/msd_genre_datasets.html))
    是另一个基于 MSD 的良好类型数据集。
- en: In this chapter, we'll be using the **Last.fm** API to fetch song information,
    and we'll learn how to use its API in an upcoming section, *Building a jazz dataset*.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用**Last.fm** API来获取歌曲信息，并将在即将到来的部分*构建爵士乐数据集*中学习如何使用其API。
- en: Looking at other data sources
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看其他数据源
- en: Outside of curated datasets, there are tons of other sources for music files
    on the internet—mainly websites offering searchable databases. The downside of
    using such sources is that you'll have to download and verify each file by hand,
    which might be time-consuming but necessary if you want to build your own dataset
    from the ground up.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 除了已整理的数据集，互联网上还有大量其他音乐文件的来源——主要是提供可搜索数据库的网站。使用这些来源的缺点是你必须手动下载和验证每个文件，虽然这可能会很耗时，但如果你想从头开始构建自己的数据集，这是必要的。
- en: Websites such as **MidiWorld** ([www.midiworld.com](https://www.midiworld.com/))
    and **MuseScore** ([musescore.com](https://musescore.com/)) contain a lot of MIDI
    files, often classified by style, composer, and instrument. There are also posts
    on Reddit that list pretty big MIDI datasets of varying quality.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如**MidiWorld** ([www.midiworld.com](https://www.midiworld.com/))和**MuseScore**
    ([musescore.com](https://musescore.com/))等网站包含了大量的MIDI文件，通常按风格、作曲家和乐器分类。Reddit上也有一些帖子列出了各种质量的MIDI数据集。
- en: For formats other than MIDI, you have the ABCNotation website ([abcnotation.com](http://abcnotation.com)),
    which features over 600,000 files of mainly folk and traditional music, but with
    links to other sources.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于MIDI以外的格式，你可以访问ABCNotation网站([abcnotation.com](http://abcnotation.com))，它收录了超过60万个文件，主要是民间和传统音乐，还有指向其他资源的链接。
- en: Building a dance music dataset
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建舞曲数据集
- en: Now that we have datasets available so that we can build our own dataset, we'll
    look at different ways of using the information contained in a MIDI file. This
    section will serve as an introduction to the different tools that can be used
    for dataset creation using only MIDI files. In this section, we'll use the **LMD-full**
    distribution.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可用的数据集，可以开始构建自己的数据集了。我们将探讨不同的方法来使用MIDI文件中的信息。本节将作为仅使用MIDI文件构建数据集的不同工具的介绍。在这一节中，我们将使用**LMD-full**发行版。
- en: In the next section, *Building a jazz dataset*, we will delve deeper into using
    external information.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节*构建爵士乐数据集*中，我们将更深入地使用外部信息。
- en: Threading the execution to handle large datasets faster
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线程加速大数据集的处理
- en: When building datasets, we want our code to execute fast because of the amount
    of data we'll be handling. In Python, using threading and multiprocessing is one
    way to go. There are many ways of executing code in parallel in Python, but we'll
    be using the `multiprocessing` module because of its simple design, which is also
    similar to other popular techniques such as using the `joblib` module.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建数据集时，我们希望代码能够快速执行，因为我们需要处理大量的数据。在Python中，使用线程和多进程是一个有效的选择。Python中有许多并行执行代码的方式，但我们将使用`multiprocessing`模块，因为它设计简单，而且与其他流行的技术，如使用`joblib`模块，类似。
- en: You can find this code in the `multiprocessing_utils.py` file, in the source
    code of this chapter. There are more comments and content in the source code,
    so check it out.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的`multiprocessing_utils.py`文件中找到这段代码。源代码中有更多的注释和内容，记得查看一下。
- en: 'For our examples, we''ll be using the following code to start four threads
    that will execute in parallel:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将使用以下代码启动四个并行执行的线程：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s explain this code block in more detail:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地解释这段代码：
- en: You can modify the number of threads in `Pool(4)` to fit your hardware. One
    thread per physical CPU is often a proper value for good performance.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过修改`Pool(4)`中的线程数量来适应你的硬件。通常，物理CPU对应一个线程是性能较好的选择。
- en: We instantiate `Manager`, which is needed to share resources inside threads,
    and `AtomicCounter`, which is available in the `multiprocessing_utils` module
    from this book's code, to share a counter between the threads.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们实例化了`Manager`，它用于在线程之间共享资源，并且实例化了`AtomicCounter`，这是本书源代码中`multiprocessing_utils`模块中的一个组件，用来在线程之间共享一个计数器。
- en: Finally, we use the `pool.starmap` method to launch the `process` method on
    the `elements` list (we'll be defining this method soon). The `starmap` method
    calls the `process` method with two parameters, the first one being **one element**
    of the `elements` list, with the second being `counter`.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用`pool.starmap`方法在`elements`列表上启动`process`方法（我们稍后将定义这个方法）。`starmap`方法会传递两个参数给`process`方法，第一个是**`elements`列表中的一个元素**，第二个是`counter`。
- en: The `process` method will handle one element at the time and will increment
    the counter at each call.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`process`方法将一次处理一个元素，并在每次调用时递增计数器。'
- en: The `process` method should be able to return `None`, making it possible to
    filter out elements.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`process`方法应该能够返回`None`，以便过滤掉不需要的元素。'
- en: The thread's life cycle and the split of the elements list is handled by the
    `multiprocessing` module.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程的生命周期和元素列表的拆分由`multiprocessing`模块处理。
- en: Extracting drum instruments from a MIDI file
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从MIDI文件中提取鼓乐器
- en: MIDI files can contain many instruments—multiple percussion instruments, pianos,
    guitars, and more. Extracting specific instruments and saving the result in a
    new MIDI file is a necessary step when building a dataset.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: MIDI文件可以包含多种乐器——多种打击乐器、钢琴、吉他等等。从MIDI文件中提取特定乐器并将结果保存到新的MIDI文件中，是构建数据集时必不可少的一步。
- en: In this example, we'll be using `PrettyMIDI` to fetch the instruments information
    into a MIDI file, extract the drum instruments, merge them into a single drum
    instrument, and save the resulting instrument in a new MIDI file. Some MIDI files
    have multiple drum instruments to split the drum into multiple parts, such as
    bass drum, snare, and so on. For our example, we've chosen to merge them, but
    depending on what you are trying to do, you might want to keep them separate or
    keep only some parts.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用`PrettyMIDI`来获取MIDI文件中的乐器信息，提取鼓乐器，将它们合并成一个单一的鼓乐器，并将结果保存到新的MIDI文件中。有些MIDI文件有多个鼓乐器，拆分鼓乐器为多个部分，例如低音鼓、军鼓等等。在我们的示例中，我们选择将它们合并，但根据你要做的事情，你可能想要将它们分开或只保留某些部分。
- en: You can find this code in the `chapter_06_example_00.py` file, in the source
    code of this chapter. There are more comments and content in the source code,
    so check it out.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`chapter_06_example_00.py`文件中找到这段代码，它位于本章的源代码中。源代码中有更多的注释和内容，记得查看一下。
- en: 'The `extract_drums` method takes `midi_path` and returns a single `PrettyMIDI`
    instance containing one merged drum instrument:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`extract_drums`方法接受`midi_path`并返回一个包含合并后鼓乐器的单一`PrettyMIDI`实例：'
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, we use `copy.deepcopy` to copy the whole MIDI file content because we
    still want to keep the time signatures and tempo changes from the original file.
    That information is kept in the `PrettyMIDI` instance that's returned in the `copy.deepcopy` method
    from the `pm_drums` variable. Then, we filter the instruments using the `is_drum`
    property. If there are multiple drum instruments, we merge them together into
    a new `Instrument` by copying the notes.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用`copy.deepcopy`复制整个MIDI文件的内容，因为我们仍然希望保留原始文件中的时间签名和节奏变化。这些信息保存在通过`copy.deepcopy`方法从`pm_drums`变量返回的`PrettyMIDI`实例中。接着，我们使用`is_drum`属性过滤乐器。如果有多个鼓乐器，我们通过复制音符将它们合并成一个新的`Instrument`。
- en: Detecting specific musical structures
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测特定的音乐结构
- en: Now that we can extract specific instruments from the MIDI files, we can also
    find specific structures in the MIDI files to further refine our dataset. Dance
    and techno music, in most cases, have a bass drum on each beat, giving you that
    inescapable urge to dance. Let's see whether we can find that in our MIDI files.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从MIDI文件中提取特定乐器，还可以在MIDI文件中找到特定结构，从而进一步细化我们的数据集。舞曲和电子舞曲大多数情况下每个拍子都有低音鼓，这给人一种无法抗拒的舞动冲动。让我们看看能否在我们的MIDI文件中找到这种情况。
- en: 'The `get_bass_drums_on_beat` method returns the proportion of bass drums that
    fall directly on the beat:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_bass_drums_on_beat`方法返回直接落在拍子上的低音鼓的比例：'
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `get_beats` method from `PrettyMIDI` returns an array stating the start
    time of each beat. For example, on a 150 QPM file, we have the following array:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`PrettyMIDI`中的`get_beats`方法返回一个数组，表示每个拍子的开始时间。例如，在一个150 QPM的文件中，我们有以下数组：'
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Then, we take only the bass drum pitches (35 or 36) in the given MIDI and make
    the assumption that we have exactly one instrument because our previous method,
    `extract_drums`, should have been called before. Then, we check whether, for each
    beat, a bass drum was played at that time and return the proportion as `float`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只取给定MIDI中的低音鼓音高（35或36），并假设我们有一个乐器，因为我们之前的方法`extract_drums`应该已经被调用过。接着，我们检查每个拍子是否在该时刻播放了低音鼓，并返回一个比例值作为`float`。
- en: Analyzing the beats of our MIDI files
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析我们的MIDI文件中的拍子
- en: Let's put everything together to check our results.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们把所有内容放在一起，检查我们的结果。
- en: 'First, we''ll add some arguments to our program using the `argparse` module:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用`argparse`模块为程序添加一些参数：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we've declared two command-line arguments, `--path_output_dir` and `--bass_drums_on_beat_threshold`,
    using the `argparse` module. The output directory is useful if we wish to save
    the extracted MIDI files in a separate folder, while the threshold is useful for
    filtering more or less of the extracted MIDI sequences.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`argparse`模块声明了两个命令行参数，`--path_output_dir`和`--bass_drums_on_beat_threshold`。输出目录对于将提取的MIDI文件保存在单独的文件夹中很有用，而阈值则有助于过滤更多或更少的提取MIDI序列。
- en: Writing the process method
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写处理方法
- en: Now that we have our arguments ready, we can write the processing method.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了参数，可以开始编写处理方法。
- en: 'Here is the `process` method that will be called by our multi-threaded code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是`process`方法，将由我们的多线程代码调用：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `process` method will create the output directory if it doesn't already
    exist. Then, it will call the `extract_drums` method with the given MIDI path,
    and then call the `get_bass_drums_on_beat` method using the returned `PrettyMIDI`
    drum, which returns the `bass_drums_on_beat` as a proportion. Then, if the value
    is over the threshold, we save that MIDI file on disk; otherize, we exit the method.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`process`方法将在输出目录不存在时创建它。然后，它将使用给定的MIDI路径调用`extract_drums`方法，再使用返回的`PrettyMIDI`鼓调用`get_bass_drums_on_beat`方法，该方法返回低音鼓的节奏比例。如果该比例超过阈值，我们将把该MIDI文件保存到磁盘；否则，我们将退出该方法。'
- en: The return values of the `process` method are important – by returning the `PrettyMIDI`
    file and the proportion of bass drums on beat, we'll be able to make statistics
    about our dataset to make informed decisions about its size and content. The `process`
    method can also return an empty (`None`) value or raise an exception, which will
    make the caller drop that MIDI file.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`process`方法的返回值很重要——通过返回`PrettyMIDI`文件和节奏上的低音鼓比例，我们将能够对数据集进行统计，以便做出关于其大小和内容的明智决策。`process`方法还可以返回空值（`None`）或抛出异常，这将使调用者丢弃该MIDI文件。'
- en: Calling the process method using threads
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线程调用process方法
- en: Now that we have a processing method, we can use it to launch the execution.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了处理方法，可以用它来启动执行。
- en: 'Let''s create an `app` method that calls the `process` method using threads:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来创建一个`app`方法，通过线程调用`process`方法：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `app` method will be called with a list of MIDI paths when the program launches.
    First, we clean up the output directory for the process method so that we can
    write in it. Then, we start four threads using `Pool(4)` (refer to the previous
    section, *Threading the execution to handle large datasets*, for more information).
    Finally, we calculate how many results were returned for information purposes.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`app`方法将在程序启动时使用MIDI路径列表被调用。首先，我们清理输出目录，为处理方法做准备，以便可以在其中写入内容。然后，我们使用`Pool(4)`启动四个线程（更多信息请参见前一节，*使用线程处理大数据集*）。最后，我们计算返回的结果数量以供参考。'
- en: Plotting the results using Matplotlib
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Matplotlib绘制结果
- en: 'Using the returned results, we can find statistics about our dataset. As an
    example, let''s plot the drum length:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用返回的结果，我们可以找到关于数据集的统计信息。作为示例，绘制鼓的长度：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We are using Matplotlib ([matplotlib.org/](https://matplotlib.org/)), a popular
    and easy to use plotting library for Python. This will result in the following
    output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Matplotlib（[matplotlib.org/](https://matplotlib.org/)），这是一个流行且易于使用的Python绘图库。最终将得到以下输出：
- en: '![](img/dd14f85c-4db9-49f8-a1f6-94e65d9fd4df.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd14f85c-4db9-49f8-a1f6-94e65d9fd4df.png)'
- en: Making plots of different statistics helps you visualize the content and size
    of your dataset.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制不同统计数据的图表帮助你可视化数据集的内容和大小。
- en: Processing a sample of the dataset
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据集的一个样本
- en: Now that we have everything in place, we can call the `app` method using a subset
    of our dataset.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了所有内容，可以使用数据集的一个子集来调用`app`方法。
- en: 'First, we''ll use a smaller sample size to make sure our code works properly:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用较小的样本大小，以确保我们的代码正常工作：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s explain the preceding code in more detail:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地解释前面的代码：
- en: We declare two new arguments, `--sample_size` and `--path_dataset_dir`. The
    first declares the size of the sample, while the second declares the location
    of the dataset.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们声明了两个新参数，`--sample_size`和`--path_dataset_dir`。第一个参数声明了样本的大小，第二个参数声明了数据集的位置。
- en: Then, we use `glob.glob` on the root folder of the dataset, which will return
    a list of paths, with one element per MIDI file.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们在数据集的根文件夹上使用`glob.glob`，它将返回一个路径列表，每个MIDI文件对应一个元素。
- en: Because this operation takes a while on big datasets, you can also cache the
    result on disk (using the `pickle` module, for example) if you execute it often.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为在大型数据集上执行此操作需要一段时间，你也可以将结果缓存到磁盘（例如使用`pickle`模块），如果你频繁执行此操作的话。
- en: We use `random.sample` to take a subset of the MIDI paths and use the resulting
    MIDI paths to call the `app` method.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`random.sample`从MIDI路径中获取一个子集，并使用得到的MIDI路径调用`app`方法。
- en: You can use one of the distributions of LMD to launch the following code. You
    need to download it (for example, the **LMD-full** distribution) and extract the
    ZIP file. See the *Using the Lakh MIDI Dataset* section for the download links.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用LMD的一个发行版来启动以下代码。你需要下载它（例如，**LMD-full**发行版）并解压ZIP文件。下载链接请参见*使用Lakh MIDI数据集*部分。
- en: 'To launch this code with a small sample size, in a Terminal, use the following
    command (by replacing `PATH_DATASET` with the root folder of the extracted dataset
    and `PATH_OUTPUT`):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用小样本启动此代码，请在终端中使用以下命令（将`PATH_DATASET`替换为解压数据集的根文件夹，`PATH_OUTPUT`替换为输出路径）：
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The extracted MIDI file will be in `PATH_OUTPUT`, resulting in the following
    statistics:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 解压后的MIDI文件将位于`PATH_OUTPUT`中，生成以下统计数据：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we can see that approximately 10% of the MIDI file has a `--bass_drums_on_beat_threshold`
    over 0.75\. This returns 12,634 results on the whole LMD dataset, which is more
    than enough to train our model later. We'll look at training in the next chapter.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到大约10%的MIDI文件的`--bass_drums_on_beat_threshold`超过0.75。整个LMD数据集返回了12,634个结果，这足以在后续训练中使用。我们将在下一章讨论训练。
- en: Building a jazz dataset
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建爵士乐数据集
- en: In the previous section, we introduced the tools that are necessary for building
    a dataset based on information contained in the MIDI files from the full LMD dataset.
    In this section, we'll delve deeper into building a custom dataset by using external
    APIs such as the Last.fm API.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们介绍了构建基于完整LMD数据集中的MIDI文件信息的数据集所需的工具。在本节中，我们将深入探讨如何使用外部API（如Last.fm API）构建自定义数据集。
- en: In this section, we'll use the **LMD-matched** distribution since it is (partially)
    matched with the MSD containing metadata information that will be useful for us,
    such as artist and title. That metadata can then be used in conjunction with Last.fm
    to get the song's genre. We'll also be extracting drum and piano instruments,
    just like we did in the previous section.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用**LMD-matched**发行版，因为它与包含元数据的MSD部分匹配，这些元数据对我们很有用，如艺术家和标题。然后可以将这些元数据与Last.fm结合使用，获取歌曲的类型。我们还将提取鼓和钢琴乐器，就像在前一节中所做的那样。
- en: The LMD extraction tools
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LMD提取工具
- en: 'Before we start, we''ll look at how to handle the LMD dataset. First, we need
    to download the following three elements from [colinraffel.com/projects/lmd/](https://colinraffel.com/projects/lmd/):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们先来看一下如何处理LMD数据集。首先，我们需要从[colinraffel.com/projects/lmd/](https://colinraffel.com/projects/lmd/)下载以下三个元素：
- en: '**LMD-matched**: A subset of LMD that is matched with MDS'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LMD-matched**：与MDS匹配的LMD子集'
- en: '**LMD-matched metadata**: The H5 database containing the metadata information'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LMD-matched元数据**：包含元数据的H5数据库'
- en: '**Match scores**: The dictionary of match scores'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**匹配分数**：匹配分数字典'
- en: 'Once extracted in the same folder, you should have the following elements:
    the `lmd_matched` directory, the `lmd_matched_h5` directory, and the `match_scores.json` file.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 解压后，你应该在同一文件夹中找到以下元素：`lmd_matched`目录、`lmd_matched_h5`目录和`match_scores.json`文件。
- en: You can find this code in the `lakh_utils.py` file, in the source code of this
    chapter. There are more comments and content in the source code, so check it out.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`lakh_utils.py`文件中找到这段代码，位于本章的源代码中。源代码中有更多注释和内容，请查阅。
- en: 'In the `lakh_utils.py` file, you have the utilities to find metadata and MIDI
    file paths from a unique identifier, `MSD_ID`. Our starting point will be the
    `match_scores.json` file, a dictionary of matched files in the following format:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在`lakh_utils.py`文件中，你可以使用实用工具通过唯一标识符`MSD_ID`查找元数据和MIDI文件路径。我们的起点将是`match_scores.json`文件，它是一个匹配文件的字典，格式如下：
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As the key, we have the `MSD_ID`, and as the value, we have a dictionary of
    matches, each with a score. From an `MSD_ID`, we can get the highest score match
    using the `get_matched_midi_md5` method. From that MD5, we'll be able to load
    the corresponding MIDI file using the `get_midi_path` method.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 作为键，我们有`MSD_ID`，作为值，我们有一个匹配字典，每个匹配都有一个分数。从`MSD_ID`中，我们可以使用`get_matched_midi_md5`方法获取最高分匹配。通过该MD5，我们将能够使用`get_midi_path`方法加载相应的MIDI文件。
- en: Fetching a song's genre using the Last.fm API
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Last.fm API获取歌曲的类型
- en: The first part of our example uses the Last.fm API to fetch each song's genre.
    There are other APIs, such as Spotify's Echo Nest, that can be used to fetch such
    information. You can choose another service provider for this section if you feel
    like it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例的第一部分使用了Last.fm API来获取每首歌的类型。还有其他API，例如Spotify的Echo Nest，也可以用来获取这些信息。如果你愿意，你可以选择其他服务提供商来完成这一部分。
- en: The first step is to create an account on [www.last.fm/api/](https://www.last.fm/api/).
    Since we won't be making any changes using the API, once you have an account,
    you only need to keep the **API key**.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是在[www.last.fm/api/](https://www.last.fm/api/)上创建一个账户。由于我们不会通过API进行更改，创建账户后，你只需要保留**API密钥**即可。
- en: You can find this section's code in the `chapter_06_example_01.py` file, in
    the source code of this chapter. There are more comments and content in the source
    code, so check it out.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的`chapter_06_example_01.py`文件中找到本节的代码。源代码中有更多注释和内容，快去查看吧。
- en: Reading information from the MSD
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从MSD中读取信息
- en: 'Before we call Last.fm to get the song''s genre, we need to find the artist
    and title of each song. Because LMD is matched with MSD, finding that information
    is easy. Follow these steps to do so:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们调用Last.fm获取歌曲类型之前，我们需要找到每首歌的艺术家和标题。由于LMD与MSD是匹配的，找到这些信息非常简单。按照以下步骤操作即可：
- en: 'First, let''s define a `process` method, as we did in the previous chapter,
    that can be called using threads, and that fetches the artist''s information from
    the H5 database:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们定义一个`process`方法，就像在前一章中一样，可以通过线程调用，并从H5数据库中获取艺术家信息：
- en: '[PRE14]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This code looks just like the code we wrote in the previous section. Here, we
    use the `tables` module to open the H5 database. Then, we use the `msd_id_to_h5`
    method from our `lakh_utils` module to get the path to the H5 file. Finally, we
    fetch the artist and title in the H5 database before returning the result in a
    dictionary.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码看起来与我们在前一节中写的代码非常相似。在这里，我们使用`tables`模块打开H5数据库。然后，我们使用来自`lakh_utils`模块的`msd_id_to_h5`方法来获取H5文件的路径。最后，我们从H5数据库中提取艺术家和标题，然后以字典的形式返回结果。
- en: 'Now, we can call the `process` method, just like we did in the previous chapter.
    Before doing that, we need to load the score matches dictionary, which contains
    all the matches between LMD and MSD:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以像在前一章中一样调用`process`方法。在此之前，我们需要加载得分匹配字典，其中包含LMD和MSD之间的所有匹配项：
- en: '[PRE15]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: To do that, we need to use the `get_msd_score_matches` method, which loads the
    dictionary in memory. Then, we take a sample of the full dataset using our `app`
    method.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要使用`get_msd_score_matches`方法，它会将字典加载到内存中。然后，我们使用`app`方法从完整的数据集中抽取一个样本。
- en: 'Finally, to launch this code with a small sample size, in a Terminal, use the
    following command (by replacing `PATH_DATASET` and `PATH_MATCH_SCORES`):'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，要使用一个小的样本集来运行此代码，在终端中使用以下命令（替换`PATH_DATASET`和`PATH_MATCH_SCORES`）：
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should receive the following output:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到以下输出：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we can plot the 25 most common artists, which should result in the following
    diagram:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以绘制出25个最常见的艺术家，这将生成如下图表：
- en: '![](img/dc57cefb-9c5d-4b6d-8a67-f89485f40645.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc57cefb-9c5d-4b6d-8a67-f89485f40645.png)'
- en: You could create a dataset based on one or multiple artists you like if you
    wanted to. You might end up with too few MIDI files for the training process,
    but it might be worth a shot.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，你可以基于一个或多个你喜欢的艺术家创建数据集。你可能会发现可用于训练的MIDI文件太少，但也许值得尝试。
- en: Using top tags to find genres
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用顶级标签来查找类型
- en: Now that we know how to fetch information in the matched MSD database, we can
    call Last.fm to fetch the genre information for a track.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何在匹配的MSD数据库中获取信息，我们可以调用Last.fm来获取一首歌曲的类型信息。
- en: You can find this section's code in the `chapter_06_example_02.py` file, in
    the source code of this chapter. There are more comments and content in the source
    code, so check it out.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的`chapter_06_example_02.py`文件中找到本节的代码。源代码中有更多注释和内容，快去查看吧。
- en: 'Let''s get started:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧：
- en: 'The easiest way to call the Last.fm API is to perform a simple `GET` request.
    We''ll do this in a `get_tags` method that takes the H5 database as a parameter:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用Last.fm API的最简单方法是执行一个简单的`GET`请求。我们将在一个名为`get_tags`的方法中执行该操作，并将H5数据库作为参数传入：
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This code makes a request to the `track.gettoptags` API endpoint, which returns
    an ordered list of genres for the track, ordered from most tag count to less tag
    count, where the tag count is calculated from the user's submissions. The correct
    classification of those tags varies greatly from one artist to the other.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码向`track.gettoptags` API端点发起请求，返回一个按标签数量排序的曲目流派列表，从最多标签到最少标签，其中标签数量是通过用户提交计算得出的。不同艺术家的标签分类差异很大。
- en: You can find a lot of information on a track, artist, or release using APIs
    such s Last.fm or Echo Nest. Make sure you check out what information they provide
    when building your own dataset.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过像Last.fm或Echo Nest这样的API获取关于曲目、艺术家或专辑的很多信息。确保在构建自己的数据集时检查它们提供的内容。
- en: While a bit naive (we don't clean up the track name an artist name, or retry
    using another matching), most of the tracks (over 80%) are found on Last.fm, which
    is good enough for the purpose of our example.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有些部分可能比较简单（我们没有清理曲目名称和艺术家名称，也没有尝试使用其他匹配方式），但大多数曲目（超过80%）都能在Last.fm上找到，这对于我们示例的目的来说已经足够好。
- en: 'Here''s a simple process method that we can use to call our `get_tags` method:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个简单的过程方法，我们可以用它来调用我们的`get_tags`方法：
- en: '[PRE19]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This example is based on jazz music, but you can use other genres for this
    example if you wish. You can plot the most popular common genres in LMD using
    the following code:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个示例基于爵士乐，但如果你愿意，也可以选择其他流派。你可以使用以下代码绘制LMD中最受欢迎的共通流派：
- en: '[PRE20]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This should produce a plot that looks similar to the one shown in the following
    diagram:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成一个与以下图示类似的图表：
- en: '![](img/f219f960-0db1-49cd-987f-d1c916694e02.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f219f960-0db1-49cd-987f-d1c916694e02.png)'
- en: We'll be using the **jazz** genre, but you might want to combine multiple genres,
    such as **jazz** and **blues**, so that you have more content to work with or
    to create hybrid styles. We'll look at how much data you actually need for your
    models so that you can train them properly in the next chapter.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**爵士乐**流派，但你可能希望将多个流派结合起来，例如**爵士乐**和**蓝调**，以便你有更多的内容可以使用，或创造混合风格。在下一章中，我们将探讨你实际需要多少数据来训练模型，以便能够正确训练。
- en: Finding instrument classes using MIDI
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MIDI查找乐器类别
- en: 'We''ll be training on two instruments for our example, but you can do something
    else if you feel like it:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在示例中使用两种乐器进行训练，但如果你有其他想法，也可以选择其他乐器：
- en: '**Percussion**: We''ll be extracting drum tracks from the MIDI file to train
    a Drums RNN model'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**打击乐**：我们将从MIDI文件中提取鼓轨道，训练一个鼓RNN模型。'
- en: '**Piano**: We''ll be extracting piano tracks to train a Melody RNN model'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**钢琴**：我们将提取钢琴轨道来训练一个旋律RNN模型。'
- en: Here, the first step is finding the instruments that we have in our dataset.
    In the `PrettyMIDI` module, the `Instrument` class contains a `program` property
    that can be used to find such information. As a reminder, you can find more information
    about the various programs in the General MIDI 1 Sound Set specification ([www.midi.org/specifications/item/gm-level-1-sound-set](https://www.midi.org/specifications/item/gm-level-1-sound-set)).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，第一步是找到我们数据集中包含的乐器。在`PrettyMIDI`模块中，`Instrument`类包含一个`program`属性，可以用来查找这些信息。提醒一下，你可以在《通用MIDI
    1声音集规范》([www.midi.org/specifications/item/gm-level-1-sound-set](https://www.midi.org/specifications/item/gm-level-1-sound-set))中找到更多关于各类程序的信息。
- en: 'Each program corresponds to an instrument, and each instrument is classified
    in an instrument class. We''ll be using this classification to find statistics
    about our dataset. Let''s get started:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 每个程序对应一个乐器，每个乐器被分类到一个乐器类别中。我们将使用这种分类来查找我们的数据集统计信息。让我们开始吧：
- en: You can find this section's code in the `chapter_06_example_04.py` file, in
    the source code of this chapter. There are more comments and content in the source
    code, so check it out.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中找到这一部分的代码，文件名为`chapter_06_example_04.py`。源代码中有更多的注释和内容，别忘了查看。
- en: 'First, let''s write the `get_instrument_classes` method for this purpose:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们为此目的编写`get_instrument_classes`方法：
- en: '[PRE21]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: First, we load a `PrettyMIDI` instance and then convert the `program` into its
    instrument class. Here, you can see that we are handling the drums separately
    since there is no `program` property for drums.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载一个`PrettyMIDI`实例，然后将`program`转换为其乐器类别。在这里，你可以看到我们单独处理了鼓部分，因为鼓没有`program`属性。
- en: 'Now, we can write our `process` method as follows:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以按照如下方式编写我们的`process`方法：
- en: '[PRE22]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The most common instrument classes can be found using the following code:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用以下代码找到最常见的乐器类别：
- en: '[PRE23]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should have similar results to what can be seen in the following diagram
    on the LMD:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到类似于LMD中以下图表所展示的结果：
- en: '![](img/22ac43bf-acfe-4473-8ad8-67bafcd5da12.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22ac43bf-acfe-4473-8ad8-67bafcd5da12.png)'
- en: Here, we can see that the most used instrument classes in the LMD are **Guitar**,
    **Drums**, **Ensemble**, and P**iano**. We'll be using the **Drums** and **Piano** classes
    in the upcoming sections, but you can use another class if you feel like it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到LMD中使用最频繁的乐器类别是**吉他**、**鼓**、**合奏**和**钢琴**。我们将在接下来的章节中使用**鼓**和**钢琴**类别，但如果你愿意的话，也可以使用其他类别。
- en: Extracting jazz, drums, and piano tracks
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取爵士、鼓和钢琴轨道
- en: Now that we are able to find the instrument tracks we want, filter the song
    by genre, and export the resulting MIDI files, we can put everything together
    to create two jazz datasets, one containing percussion and the other containing
    piano.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们能够找到我们想要的乐器轨道，按类型筛选歌曲，并导出生成的MIDI文件，我们可以将所有内容整合在一起，创建两个爵士数据集，一个包含打击乐，另一个包含钢琴。
- en: Extracting and merging jazz drums
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取和合并爵士鼓
- en: We've already implemented most of the code for extracting jazz drums, namely
    the `get_tags` method and the `extract_drums` method.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了大部分用于提取爵士鼓的代码，即`get_tags`方法和`extract_drums`方法。
- en: You can find this section's code in the `chapter_06_example_07.py` file, in
    the source code of this chapter. There are more comments and content in the source
    code, so check it out.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码文件`chapter_06_example_07.py`中找到这一部分的代码。源代码中有更多的注释和内容，记得查看。
- en: 'The `process` method should call the `get_tags` and `extract_drums` methods
    like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`process`方法应该像这样调用`get_tags`和`extract_drums`方法：'
- en: '[PRE24]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, we are using the `ast` module to parse the `tags` argument. This is useful
    because it allows us to use the Python list syntax for the value of a flag, that
    is, `--tags="['jazz', 'blues']"`. Then, we can check if the tags coming from Last.fm
    match with one of the required tags and write the resulting MIDI drums file to
    disk if so.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`ast`模块来解析`tags`参数。这很有用，因为它允许我们使用Python列表语法来表示标志的值，例如`--tags="['jazz',
    'blues']"`。然后，我们可以检查来自Last.fm的标签是否与所需标签之一匹配，如果匹配，则将生成的MIDI鼓文件写入磁盘。
- en: 'The drum''s lengths and genre repartition can be seen in the following plots:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓的长度和类型分布可以通过以下图表查看：
- en: '![](img/58ac3d06-1bd5-4bd5-8757-67e39f5674d1.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58ac3d06-1bd5-4bd5-8757-67e39f5674d1.png)'
- en: Here, we can see that we have around 2,000 MIDI files when combining both "**jazz**"
    and "**blues**".
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，通过合并“**爵士**”和“**蓝调**”两种类型的轨道，我们大约有2,000个MIDI文件。
- en: Extracting and splitting jazz pianos
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取和拆分爵士钢琴
- en: 'The last method we need to write is the piano extraction method. The `extract_pianos`
    method is similar to the previous `extract_drums` method, but instead of merging
    the tracks together, it splits them into separate piano tracks, potentially returning
    multiple tracks for each song. Let''s get started:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要编写的最后一个方法是钢琴提取方法。`extract_pianos`方法类似于之前的`extract_drums`方法，但它不是将轨道合并在一起，而是将它们拆分成单独的钢琴轨道，可能会为每首歌曲返回多个轨道。让我们开始吧：
- en: You can find this section's code in the `chapter_06_example_08.py` file, in
    the source code of this chapter. There are more comments and content in the source
    code, so check it out.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码文件`chapter_06_example_08.py`中找到这一部分的代码。源代码中有更多的注释和内容，记得查看。
- en: 'First, we''ll write the `extract_pianos` method, as follows:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将编写`extract_pianos`方法，如下所示：
- en: '[PRE25]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We've already covered most of the code in this snippet. The difference here
    is that we are filtering the instrument on any of the piano programs, ranging
    from 0 to 8\. We're also returning multiple piano MIDI files.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了这段代码的大部分内容。不同之处在于，我们正在筛选任何钢琴程序中的乐器，范围从0到8。我们还将返回多个钢琴MIDI文件。
- en: 'Now, we can call our method using the following `process` method:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下`process`方法调用我们的方法：
- en: '[PRE26]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This code was covered in the previous section on drums, except here, each piano
    file is written separately using an index. The piano''s lengths and genres can
    be plotted like so:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在上一节关于鼓的部分中已经讲过，只不过在这里，每个钢琴文件是使用索引单独写入的。钢琴的长度和类型可以像这样绘制：
- en: '![](img/a83ea8b1-eb95-4280-9dd2-1d7687090c27.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a83ea8b1-eb95-4280-9dd2-1d7687090c27.png)'
- en: Here, we've found just under 2,000 piano tracks for **jazz** and **blues**.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们找到了接近2,000个**爵士**和**蓝调**钢琴轨道。
- en: Preparing the data using pipelines
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用管道准备数据
- en: In the previous sections, we looked at existing datasets and developed tools
    so that we can find and extract specific content. By doing so, we've effectively
    built a dataset we want to train our model on. But building the dataset isn't
    all – we also need to **prepare** it. By preparing, we mean the action of removing
    everything that isn't useful for training, cutting, and splitting tracks, and
    also automatically adding more content.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们查看了现有的数据集，并开发了工具以便能够查找并提取特定内容。通过这些操作，我们有效地构建了一个想要用来训练模型的数据集。但构建数据集并非一切——我们还需要**准备**它。准备的意思是移除那些不适合训练的内容，剪辑和拆分轨道，并且自动添加更多的内容。
- en: In this section, we'll be looking at some built-in utilities that we can use
    to transform the different data formats (MIDI, MusicXML, and ABCNotation) into
    a training-ready format. These utilities are called `pipelines` in Magenta, and
    are a sequence of operations that are executed on the input data.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们将介绍一些内置的工具，它们可以帮助我们将不同的数据格式（MIDI、MusicXML 和 ABCNotation）转换为适合训练的格式。这些工具在Magenta中被称为`管道（pipelines）`，它们是一系列在输入数据上执行的操作。
- en: An example of an operation that is already implemented in pipelines includes
    discarding melodies with too many pitches that are too long or too short. Another
    operation is transposing melodies, which consists of taking a melody and creating
    a new one by shifting the note's pitches up or down. This is a common practice
    in machine learning called **dataset augmentation**, which is useful if we wish
    to make the model train better by providing it with variations of the original
    data.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道中已经实现的操作之一是丢弃音调过多、过长或过短的旋律。另一个操作是转调旋律，即通过上下移动音符的音高来创造新的旋律。这是一种在机器学习中常见的做法，叫做**数据集增强**，如果我们希望通过提供原始数据的变体来让模型更好地训练，这是很有用的。
- en: Let's take a look at what pipelines are and how they can be used. In this section,
    we'll be using the Melody RNN pipeline as an example, but each model has its own
    pipeline with its own specifics. For example, the Drums RNN pipeline does not
    transpose the drums sequences because it wouldn't make sense to do so.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下什么是管道（pipelines），以及它们如何被使用。在这一部分中，我们将以Melody RNN管道为例，但每个模型都有其独特的管道和特定内容。例如，Drums
    RNN管道不会转调鼓的序列，因为这样做没有意义。
- en: Before we start talking about pipelines, we'll have a brief look at manually
    refining the dataset we built previously.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始讨论管道之前，我们将简要地看看如何手动优化我们之前构建的数据集。
- en: Refining the dataset manually
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动优化数据集
- en: 'This might sound obvious, but we''ll stress it because it is also really important:
    verify the MIDI files you''ve extracted. The dataset''s content should correspond
    to what you were looking for in terms of music.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能听起来显而易见，但我们还是要强调，因为它真的很重要：验证你提取的MIDI文件。数据集的内容应该与音乐方面的目标相符。
- en: 'The easiest way of verifying a track''s content is by opening the content in
    MuseScore and listening to it:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 验证轨道内容最简单的方法是将其在MuseScore中打开并进行试听：
- en: '![](img/43a92975-da8c-4b3f-9f04-132c13d44b96.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43a92975-da8c-4b3f-9f04-132c13d44b96.png)'
- en: 'Let''s have a look a the things we can verify for each of these files:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们可以验证每个文件的哪些内容：
- en: The first thing to verify is whether the **instruments** we've extracted are
    present in the resulting MIDI files, meaning that, for our jazz piano example,
    we should have only one instrument track and that it should be any of the eight
    piano programs.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先要验证的是我们提取的**乐器**是否出现在生成的MIDI文件中。以我们的爵士钢琴示例为例，我们应该只有一个乐器轨道，并且它应该是八个钢琴程序中的任意一个。
- en: Another thing to verify is whether the **genre** of the tracks fits our requirements.
    Does the piano sound like jazz music? Does the music actually sound good to you?
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个需要验证的内容是**音乐风格（genre）**是否符合要求。这些钢琴声音像爵士乐吗？这段音乐听起来对你来说好听吗？
- en: Other problems to look out for include tracks that are **incomplete**, too short,
    too long, or full of silence. Some of those tracks will be filtered by the data
    preparation pipeline, but a manual pass on the data is also important.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他需要注意的问题包括**不完整**的轨道，过短、过长或充满沉默的轨道。这些轨道中的一些将会通过数据准备管道过滤掉，但对数据进行人工检查也同样重要。
- en: If some of the tracks you like are filtered by the data preparation pipeline,
    for example, for being too short, you can manually fix this issue by copying and
    pasting parts of it to make it longer. You can also write a pipeline to automatically
    do that.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你喜欢的一些曲目被数据准备管道过滤掉，例如，因为它们太短，你可以手动解决这个问题，方法是复制并粘贴它们的一部分以使其更长。你也可以编写一个管道来自动执行这个操作。
- en: If some of the tracks don't fit your requirements, remove them from the dataset.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一些曲目不符合你的要求，删除它们。
- en: Once you've validated the dataset's content and removed all the unwanted tracks,
    you can also cut and clean the content of each file. The easiest way of doing
    that is by going into MuseScore, listening to the track, removing the parts you
    don't like, and exporting the file back to MIDI.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你验证了数据集的内容并移除了所有不需要的曲目，你也可以修剪和清理每个文件的内容。最简单的方法是进入MuseScore，听一下曲目，移除你不喜欢的部分，然后将文件重新导出为MIDI。
- en: Looking at the Melody RNN pipeline
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看Melody RNN管道
- en: Once we've manually refined the dataset, we are ready to prepare it using a
    pipeline, resulting in data that has been prepared for training. As an example,
    we'll be looking at the Melody RNN pipeline.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们手动完善了数据集，就可以使用管道准备它，从而生成已准备好用于训练的数据。作为示例，我们将查看Melody RNN管道。
- en: Launching the data preparation stage on our dataset
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动数据准备阶段并处理我们的数据集。
- en: The first step when it comes to preparing the data is to call the `convert_dir_to_note_sequences`
    command, which is the same regardless of the model you will be using. This command
    will take a directory containing MIDI files, MusicXML files, or ABCNotation files
    as input and convert them into TensorFlow records of `NoteSequence`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 准备数据的第一步是调用`convert_dir_to_note_sequences`命令，不论你将使用哪个模型，这个命令都是相同的。该命令将一个包含MIDI文件、MusicXML文件或ABCNotation文件的目录作为输入，并将其转换为TensorFlow记录格式的`NoteSequence`。
- en: 'We recommend that you create another folder for your training data (separate
    from the dataset folder you created previously). Now, let''s get started:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议你为训练数据创建另一个文件夹（与你之前创建的数据集文件夹分开）。现在，让我们开始：
- en: 'First, change directory to the folder you''ve created and call the `convert_dir_to_note_sequences`
    command using the following command (replace `PATH_OUTPUT_DIR` with the directory
    you used in the previous section):'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，切换到你创建的文件夹，并使用以下命令调用`convert_dir_to_note_sequences`命令（将`PATH_OUTPUT_DIR`替换为你在上一节中使用的目录）：
- en: '[PRE27]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This will output a bunch of "Converted MIDI" files and produce a `notesequences.tfrecord`. From
    now on, the data is in the same format, regardless of the symbolic representation
    we used when building the dataset.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出一堆“转换后的MIDI”文件，并生成一个`notesequences.tfrecord`。从现在开始，无论我们在构建数据集时使用的是哪种符号表示，数据格式都是相同的。
- en: 'Now, we can launch the pipeline on our data using the following code:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下代码在我们的数据上启动管道：
- en: '[PRE28]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: First, we need to give `--config` as an argument. This is necessary because
    the encoder and decoder are defined in the configuration (see [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml),
    *Generating Polyphonic Melodies*, for a refresher on how encoding and decoding
    works).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要提供`--config`作为一个参数。这是必要的，因为编码器和解码器在配置中定义（参见[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)，*生成复调旋律*，以回顾编码和解码的工作原理）。
- en: We also pass the `--eval_ratio` argument, which will give the pipeline the number
    of elements in the training and evaluation sets. When executed, the pipeline will
    output statistics and warnings about the files it encounters.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还传递了`--eval_ratio`参数，它将给管道提供训练集和评估集中的元素数量。执行时，管道将输出它遇到的文件的统计信息和警告。
- en: 'The statistics are printed on the console for each increment of 500 files that
    are processed, but only the last part (after the **Completed.** output) is of
    interest to us. The following is the output of the 500 samples of the jazz piano
    dataset:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 统计信息会在每处理500个文件时打印到控制台，但只有最后部分（**完成。**输出之后）才是我们关心的。以下是爵士钢琴数据集500个样本的输出：
- en: '[PRE29]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The statistics of interest here are as follows::'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里关注的统计数据如下：
- en: '`Processed 500 inputs total. **Produced 122 outputs.**`: This gives us the
    input size or the number of provided MIDI files, as well as the number of resulting
    `SequenceExample` that will be used for training (122, counting both evaluation
    and training sets). This is the most important statistic.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Processed 500 inputs total. **Produced 122 outputs.**`：这告诉我们输入的大小或提供的MIDI文件数量，以及生成的`SequenceExample`的数量，这些将用于训练（122，计算包括评估集和训练集）。这是最重要的统计数据。'
- en: '`DAGPipeline_MelodyExtractor_MODE_melody_lengths_in_bars`: This gives you the
    length of the resulting `SequenceExample` elements for each "MODE".'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DAGPipeline_MelodyExtractor_MODE_melody_lengths_in_bars`：这将为每个 "MODE" 提供生成的
    `SequenceExample` 元素的长度。'
- en: The `SequenceExample` encapsulates the data that will be fed to the network
    during training. Those statistics are useful because the quantity (as well as
    the quality) of the data is important for the model's training. If a model doesn't
    train properly on 122 outputs, we'll need to make sure we have more data for the
    next time we train.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`SequenceExample` 封装了将在训练过程中输入网络的数据。这些统计数据很有用，因为数据的数量（以及质量）对模型训练至关重要。如果一个模型在122个输出上没有正确训练，我们需要确保下次训练时有更多的数据。'
- en: In that sense, it is really important to look at the produced outputs, which
    tells us about the exact amount of data the network will receive. It doesn't matter
    whether we feed 100,000 MIDI files to the data preparation pipeline if a small
    amount of `SequenceExample` is produced because the input data isn't good. If
    a pipeline produces a small number of outputs for a big input, look at the statistics
    and find out which part of the processing step is removing the elements.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，查看生成的输出非常重要，它能告诉我们网络将接收到的数据量。即使我们给数据准备管道输入了100,000个MIDI文件，如果生成的 `SequenceExample`
    很少，也没有关系，因为输入数据不好。如果管道对大量输入生成了少量输出，查看统计数据并找出哪个处理步骤删除了元素。
- en: Now, let's have a look at how the pipeline is defined and executed for our example.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下管道是如何为我们的示例定义和执行的。
- en: Understanding a pipeline execution
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解管道的执行
- en: 'The statistics we provided in the previous section are a bit confusing because
    they are not shown in the order they are executed. Let''s have a proper look at
    how this is really executed to understand what''s going on:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节提供的统计数据有些混乱，因为它们没有按照执行的顺序显示。让我们正视一下这个过程的实际执行方式，以便理解发生了什么：
- en: '`DagInput` initiates the pipeline''s execution, taking each `NoteSequence`
    of the TensorFlow records as input (500 elements).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DagInput` 启动管道的执行，逐个读取 TensorFlow 记录中的每个 `NoteSequence` 作为输入（500个元素）。'
- en: '`RandomPartition` randomly splits the elements into training and evaluation
    sets given the ratio provided in the command (450 elements in the training set
    and 50 elements in the evaluation set).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RandomPartition` 根据命令中提供的比例随机将元素划分为训练集和评估集（训练集有450个元素，评估集有50个元素）。'
- en: '`TimeChangeSplitter` splits the elements at each time change (doesn''t output
    statistics).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeChangeSplitter` 在每个时间变化点拆分元素（不输出统计数据）。'
- en: '`Quantizer` quantizes the note sequence on the closest step defined by the `steps_per_quarter`
    attribute in the configuration and discards elements with multiple tempos and
    time signatures (doesn''t output statistics).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Quantizer` 根据配置中的 `steps_per_quarter` 属性将音符序列量化到最近的步长，并删除具有多重节奏和时间签名的元素（不输出统计数据）。'
- en: '`TranspositionPipeline` transposes the note sequence into multiple pitches,
    adding new elements in the process (2,387 elements generated by transposition
    for the training set).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TranspositionPipeline` 将音符序列转换为多个音高，并在此过程中添加新的元素（训练集生成了2,387个通过转调产生的元素）。'
- en: '`MelodyExtractor` extracts the melodies from the `NoteSequence`, returning
    a `Melody` and removing elements if needed, such as polyphonic tracks and tracks
    that are too short or too long (1,466 elements are removed for the training set).
    This part also outputs the lengths of the melodies in bars:'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MelodyExtractor` 从 `NoteSequence` 中提取旋律，返回一个 `Melody` 并根据需要删除元素，比如多声部轨道以及那些过短或过长的轨道（训练集中删除了1,466个元素）。这一部分还输出旋律的长度（以小节为单位）：'
- en: The minimum and maximum length of the melody are defined by `min_bars` and `max_steps`,
    respectively. See the next section to learn how to change them.
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旋律的最小和最大长度分别由 `min_bars` 和 `max_steps` 定义。请参阅下一节，了解如何更改这些值。
- en: '`ignore_polyphonic_notes`, which is set `True`, discards polyphonic tracks.'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_polyphonic_notes` 被设置为 `True`，会丢弃多声部轨道。'
- en: '`EncoderPipeline` encodes`Melody` into `SequenceExample` using `KeyMelodyEncoderDecoder`
    defined for the attention configuration (doesn''t output statistics). The encoder
    pipeline receives the configuration passed as an argument; for example, `LookbackEventSequenceEncoderDecoder`
    for the `lookback_rnn` configuration.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EncoderPipeline` 使用为注意力配置定义的 `KeyMelodyEncoderDecoder` 将 `Melody` 编码为 `SequenceExample`（不输出统计数据）。编码器管道接收作为参数传递的配置；例如，对于
    `lookback_rnn` 配置，使用 `LookbackEventSequenceEncoderDecoder`。'
- en: '`DagOutput` finishes the execution.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DagOutput` 完成执行。'
- en: If you want to look at the implementation of the `Pipeline`, have a look at
    the `get_pipeline` method in the `melody_rnn_pipeline` module.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看`Pipeline`的实现，查看`melody_rnn_pipeline`模块中的`get_pipeline`方法。
- en: Writing your own pipeline
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写你自己的管道
- en: As you might have noticed from the code in the `get_pipeline` method, most of
    the configurations cannot be changed. However, we can write our own pipeline and
    call it directly.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从`get_pipeline`方法中的代码中可能注意到的，大部分配置是无法更改的。不过，我们可以编写自己的管道并直接调用它。
- en: You can find this section's code in the `melody_rnn_pipeline_example.py` file,
    in the source code of this chapter. There are more comments and content in the
    source code, so check it out.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中找到这一节的代码，文件名为`melody_rnn_pipeline_example.py`。源代码中有更多注释和内容，记得查看一下。
- en: 'For this example, we''ll take the existing Melody RNN pipeline, copy it, and
    change the transposition and sequence length. Let''s get started:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用现有的Melody RNN管道，复制它，并更改移调和序列长度。让我们开始吧：
- en: 'First, copy the `get_pipeline` method and call it using the following Python
    code (replacing `INPUT_DIR` and `OUTPUT_DIR` with the proper values):'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，复制`get_pipeline`方法，并使用以下Python代码调用它（将`INPUT_DIR`和`OUTPUT_DIR`替换为适当的值）：
- en: '[PRE30]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You should see the same output that we received previously when we used the
    pipeline method. By taking a small sample (500 pieces of data) of the piano jazz
    dataset, we received the following output:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到与我们之前使用管道方法时相同的输出。通过对钢琴爵士数据集的一个小样本（500条数据）进行处理，我们得到了以下输出：
- en: '[PRE31]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, let''s change some parameters to see how it works. In the following code,
    we''ve added some transpositions (the default transposition value is `(0,)`, which
    means no transposition shifts):'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们更改一些参数，看看它是如何工作的。在以下代码中，我们添加了一些移调（默认的移调值是`(0,)`，表示没有移调偏移）：
- en: '[PRE32]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: By using the transpositions `(0,12)`, we're telling the transposition pipeline
    to create, for each existing sequence, a sequence 12 pitches higher, corresponding
    to a full octave shift up. Keep the rest of the code as is.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用移调值`(0,12)`，我们告诉移调管道为每个现有的序列创建一个比原序列高12个音高的序列，相当于一个完整的八度向上偏移。其余的代码保持不变。
- en: Transposition values should follow musical intervals expressed in semitones
    (a pitch value in MIDI). The simplest interval is the perfect interval that we
    are using, which corresponds to an octave, or 12 semitones or MIDI pitches. Other
    intervals can be used, such as the Major third, which is used in the Polyphony
    RNN pipeline, with a transposition range of `(-4, 5)`.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 移调值应该遵循以半音（MIDI音高值）表示的音乐间隔。最简单的间隔是我们正在使用的完美间隔，它对应于一个八度，或者12个半音，或MIDI音高。也可以使用其他间隔，例如大三度，这在Polyphony
    RNN管道中使用，移调范围为`(-4, 5)`。
- en: 'Now, the output should look as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，输出应该如下所示：
- en: '[PRE33]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Notice how we now have approximately twice as much data to work with. Data augmentation
    is important for handling small datasets.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在我们大约有了两倍的数据可以使用。数据增强对于处理小型数据集非常重要。
- en: 'We can also change the minimum and maximum lengths of the sequences in the
    melody extractor, like so:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以更改旋律提取器中序列的最小和最大长度，如下所示：
- en: '[PRE34]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The preceding code will output a total of 92 outputs (instead of our previous
    230).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码将输出总共92个结果（而不是之前的230个）。
- en: 'We can also write our own pipeline class. For example, we could automatically
    cut sequences that are too long or duplicate sequences that are too short, instead
    of discarding them. For a note sequence pipeline, we need to extend the `NoteSequencePipeline`
    class and implement the `transform` method, as shown in the following code:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以编写我们自己的管道类。例如，我们可以自动剪切过长的序列，或者复制过短的序列，而不是丢弃它们。对于音符序列管道，我们需要扩展`NoteSequencePipeline`类，并实现`transform`方法，如以下代码所示：
- en: '[PRE35]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Take a look at the `sequences_lib` module in Magenta, which contains tons of
    utilities for handling note sequences. Each dataset needs to be prepared and the
    easiest way to prepare the data is by creating new pipelines.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Magenta中的`sequences_lib`模块，该模块包含了许多用于处理音符序列的工具。每个数据集都需要进行准备，准备数据的最简单方法是创建新的管道。
- en: Looking at MusicVAE data conversion
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看MusicVAE数据转换
- en: The MusicVAE model doesn't use pipelines – actually, it doesn't even have a
    dataset creation script. Compared to our previous example with Melody RNN, it
    still uses similar transformations (such as data augmentation) and is more configurable
    since some of the transformations can be configured, instead of us needing to
    write a new pipeline.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: MusicVAE模型不使用流水线——实际上，它甚至没有数据集创建脚本。与我们之前使用Melody RNN的例子相比，它仍然使用类似的变换（如数据增强），并且更具可配置性，因为一些变换可以进行配置，而不需要我们编写新的流水线。
- en: 'Let''s have a look at a simple MusicVAE configuration contained in the `configs`
    module of the `music_vae` module. Here, you can find the following `cat-mel_2bar_small`
    configuration:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看`music_vae`模块中`configs`模块中包含的一个简单的MusicVAE配置。在这里，你可以找到以下`cat-mel_2bar_small`配置：
- en: '[PRE36]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The following list further explains the code:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表进一步解释了代码：
- en: By looking at the `NoteSequenceAugmenter` class, you can see that it takes note
    of sequence augmentation by using shifting (like in our custom pipeline) and stretching,
    another data augmentation technique.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过查看`NoteSequenceAugmenter`类，你可以看到它通过使用平移（如我们自定义的流水线中所做）和拉伸这一数据增强技术来进行音符序列的增强。
- en: It also limits the maximum length of the melody to `max_bars=100`, but remember
    that MusicVAE handles limited size samples because of its network type. In this
    example, each sample is sliced to a length of `slice_bars=2`.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还将旋律的最大长度限制为`max_bars=100`，但请记住，MusicVAE因其网络类型的原因，只能处理有限大小的样本。在这个例子中，每个样本被切片为`slice_bars=2`的长度。
- en: The note sequence augmenter lets you decide a transposition range that it will
    randomly choose a value from.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音符序列增强器让你决定一个转调范围，它将在这个范围内随机选择一个值。
- en: Stretching isn't used for Melody RNN because most stretching ratios don't work
    for quantized sequences. Stretching can be used for Performance RNN, for example.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Melody RNN不使用拉伸，因为大多数拉伸比例对量化的序列不起作用。比如，Performance RNN就可以使用拉伸。
- en: We won't be looking at creating a new configuration just now. See [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*, for more information on how to do that.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在不会讨论如何创建新的配置。有关如何做到这一点的更多信息，请参见[第7章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)，*训练Magenta模型*。
- en: Summary
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at how to build and prepare a dataset that will be
    used for training. First, we looked at existing datasets and explained how some
    are more suitable than others for a specific use case. We then looked at the LMD
    and the MSD, which are useful for their size and completeness, and datasets from
    the Magenta team, such as the MAESTRO dataset and the GMD. We also looked at external
    APIs such as Last.fm, which can be used to enrich existing datasets.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了如何构建和准备一个用于训练的数据集。首先，我们查看了现有的数据集，并解释了为什么一些数据集比其他数据集更适合特定的使用案例。接着，我们研究了LMD和MSD，它们由于规模和完整性而具有重要价值，还研究了Magenta团队的数据集，如MAESTRO数据集和GMD。我们还查看了外部API，如Last.fm，它可以用来丰富现有的数据集。
- en: Then, we built a dance music dataset and used information contained in MIDI
    files to detect specific structures and instruments. We learned how to compute
    our results using multiprocessing and how to plot statistics about the resulting
    MIDI files.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们构建了一个舞曲数据集，并使用MIDI文件中包含的信息来检测特定结构和乐器。我们学习了如何使用多进程计算结果，以及如何绘制关于生成的MIDI文件的统计数据。
- en: After, we built a jazz dataset by extracting information from the LMD and using
    the Last.fm API to find the genre of each song. We also looked at how to find
    and extract different instrument tracks in the MIDI files.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们通过从LMD中提取信息，并使用Last.fm API来查找每首歌曲的流派，构建了一个爵士乐数据集。我们还研究了如何在MIDI文件中查找和提取不同的乐器轨道。
- en: Finally, we prepared the data for training. By using pipelines, we were able
    to process the files we extracted, remove the files that weren't of the proper
    length, quantize them, and use data augmentation techniques to create a proper
    dataset, ready for training. By doing this, we saw how different models have different
    pipelines, depending on their network type.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们为训练准备了数据。通过使用流水线，我们能够处理提取的文件，删除不符合适当长度的文件，对其进行量化，并使用数据增强技术创建一个适合训练的正确数据集。通过这样做，我们看到了不同模型根据其网络类型具有不同的流水线。
- en: In the next chapter, we'll use what we produced in this chapter to train some
    models on the datasets we've produced. You'll see that training is an empirical
    process that requires a lot of back and forth between preparing the data and training
    the model. During this process, you will likely come back to this chapter for
    more information.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将使用本章中产生的内容来训练一些模型，使用我们创建的数据集。你将看到，训练是一个经验过程，涉及数据准备与模型训练之间的大量反复。在这个过程中，你可能会回到这一章寻求更多的信息。
- en: Questions
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the advantages and disadvantages of the different symbolic representations?
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同符号表示法的优缺点是什么？
- en: Write a piece of code that will extract cello instruments from MIDI files.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一段代码，从MIDI文件中提取大提琴乐器。
- en: How many rock songs are present in LMD? How many match one of the "jazz", "blues",
    "country" tags?
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LMD中有多少首摇滚歌曲？有多少符合“爵士”，“蓝调”，“乡村”标签？
- en: Write a piece of code that will extend MIDI files that are too short for the
    Melody RNN pipeline.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一段代码，扩展那些对于Melody RNN管道来说过短的MIDI文件。
- en: Extract the jazz drums from GMD. Can we train a quantized model with this?
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从GMD中提取爵士鼓。我们能用这个训练量化模型吗？
- en: Why is data augmentation important?
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么数据增强如此重要？
- en: Further reading
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**The MAESTRO Dataset and Wave2Midi2Wave:** A Magenta team blog post on the
    MAESTRO dataset and its usage in the Wave2Midi2Wave method ([magenta.tensorflow.org/maestro-wave2midi2wave](https://magenta.tensorflow.org/maestro-wave2midi2wave))'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MAESTRO数据集与Wave2Midi2Wave：** Magenta团队关于MAESTRO数据集及其在Wave2Midi2Wave方法中应用的博客文章（[magenta.tensorflow.org/maestro-wave2midi2wave](https://magenta.tensorflow.org/maestro-wave2midi2wave)）'
- en: '**Enabling Factorized Piano Music Modeling and Generation with the MAESTRO
    Dataset:** A paper (2019) about MAESTRO and Wave2Midi2Wave ([arxiv.org/abs/1810.12247](https://arxiv.org/abs/1810.12247))'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启用基于MAESTRO数据集的钢琴音乐建模与生成：** 2019年关于MAESTRO与Wave2Midi2Wave的论文（[arxiv.org/abs/1810.12247](https://arxiv.org/abs/1810.12247)）'
- en: '**Celebrating Johann Sebastian Bach:** The Bach Doodle, which gave us the Bach
    Doodle Dataset ([www.google.com/doodles/celebrating-johann-sebastian-bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach))'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**庆祝约翰·塞巴斯蒂安·巴赫：** 巴赫涂鸦，带给我们巴赫涂鸦数据集（[www.google.com/doodles/celebrating-johann-sebastian-bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)）'
- en: '**Visualizing the Bach Doodle Dataset:** An amazing visualization of the Bach
    Doodle Dataset ([magenta.tensorflow.org/bach-doodle-viz](https://magenta.tensorflow.org/bach-doodle-viz))'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可视化巴赫涂鸦数据集：** 一种令人惊叹的巴赫涂鸦数据集可视化（[magenta.tensorflow.org/bach-doodle-viz](https://magenta.tensorflow.org/bach-doodle-viz)）'
- en: '**The Bach Doodle: Approachable music composition with machine learning at
    scale:** A paper (2019) about the Bach Doodle dataset ([arxiv.org/abs/1907.06637](https://arxiv.org/abs/1907.06637))'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**巴赫涂鸦：使用机器学习进行可扩展的音乐创作：** 2019年关于巴赫涂鸦数据集的论文（[arxiv.org/abs/1907.06637](https://arxiv.org/abs/1907.06637)）'
