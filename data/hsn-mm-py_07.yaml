- en: Natural Language Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: Automatic speech recognition has a lot of potential applications, such as audio
    transcription, dictation, audio search, and virtual assistants. I am sure that
    everyone has interacted with at least one of the virtual assistants by now, be
    it Apple's Siri, Amazon's Alexa, or Google's Assistant. At the core of all these
    speech recognition systems are a set of statistical models over the different
    words or sounds in a language. And since speech has a temporal structure, HMMs
    are the most natural framework to model it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自动语音识别有许多潜在的应用，例如音频转录、听写、音频搜索和虚拟助手。我相信现在每个人至少与一个虚拟助手互动过，无论是苹果的Siri、亚马逊的Alexa，还是谷歌的Assistant。在所有这些语音识别系统的核心，都是一组基于语言中不同单词或声音的统计模型。由于语音具有时间结构，隐马尔可夫模型（HMMs）是最自然的建模框架。
- en: HMMs are virtually at the core of all speech recognition systems and the core
    concepts in modeling haven't changed much in a long time. But over time, a lot
    of sophisticated techniques have been developed to build better systems. In the
    following sections, we will try to cover the main concepts leading to the development
    of these systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 隐马尔可夫模型（HMMs）几乎是所有语音识别系统的核心，建模中的核心概念长时间没有太大变化。但随着时间的推移，已经开发出许多复杂的技术来构建更好的系统。在接下来的部分，我们将尝试涵盖推动这些系统发展的主要概念。
- en: Part-of-speech tagging
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词性标注
- en: The first problem that we will look into is known as **part-of-speech tagging **(**POS
    tagging**). According to Wikipedia, POS tagging, also known as **grammatical tagging**
    or **word-category disambiguation**, is the process of marking up a word in a
    text as corresponding to a particular part of speech based on both its definition
    and its context, that is, its relationship with adjacent and related words in
    a phrase, sentence, or paragraph. A simpler version of this, which is usually
    taught in schools, is classifying words as noun, verbs, adjectives, and so on.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要研究的第一个问题被称为**词性标注**（**POS标注**）。根据维基百科，词性标注，也叫**语法标注**或**词类别消歧义**，是根据一个单词的定义及其上下文（即它与短语、句子或段落中相邻和相关单词的关系）标记该单词为对应某一特定词性的过程。这个过程的一个简化版本，通常在学校里教授，就是将单词分类为名词、动词、形容词等。
- en: 'POS tagging is not as easy as it sounds because the same word can take different
    parts of speech in different contexts. A simple example of this is the word *dogs*.
    The word *dogs* is usually considered a noun, but in the following sentence, it
    acts like a verb:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注并不像听起来那么简单，因为同一个单词在不同的上下文中可以有不同的词性。一个简单的例子是单词*dogs*。单词*dogs*通常被认为是名词，但在以下句子中，它充当了动词：
- en: '*The sailor dogs the hatch*.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*The sailor dogs the hatch*。'
- en: 'Correct grammatical tagging will reflect that *dogs* is used as a verb here,
    not as the more common plural noun. Grammatical context is one way to determine
    this; semantic analysis can also be used to infer that *sailor* and *hatch* implicate
    *dogs* as:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的语法标注将反映出*dogs*在这里作为动词使用，而不是作为更常见的复数名词。语法上下文是确定这一点的一种方式；语义分析也可以用来推断*sailor*和*hatch*使*dogs*暗示为：
- en: In the nautical context
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在航海术语中
- en: An action applied to the object *hatch*
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作用于物体*hatch*的动作
- en: 'In teaching English, generally only nine parts of speech are taught: noun,
    verb, article, adjective, preposition, pronoun, adverb, conjunction, and interjection.
    But we can divide words into more categories and subcategories for finer-grained
    tagging. For example, nouns can be sub-categorized into plural, possessive, and
    singular. Similarly, verbs can be sub-categorized on the basis of tense, aspect,
    and so on. In general, computer-based POS tagging systems are able to distinguish
    50 to 150 separate parts of speech for English. Work on stochastic methods for
    tagging Koine Greek has used over 1,000 parts of speech and found that about as
    many words were ambiguous there as in English.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在英语教学中，通常只教九大词性：名词、动词、冠词、形容词、介词、代词、副词、连词和感叹词。但我们可以将单词划分为更多类别和子类别，以便进行更精细的标注。例如，名词可以细分为复数、所有格和单数。同样，动词可以根据时态、体态等进行子分类。通常，基于计算机的词性标注系统能够区分50到150个英语词性。对科伊内希腊语的随机方法标注工作已经使用了超过1,000个词性，并发现那里有很多单词和英语一样存在歧义。
- en: Code
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: 'For the code example, we will use the `pomegranate` library to build an HMM
    for POS tagging. Pomegranate can be installed by running the following on the
    command line:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码示例，我们将使用`pomegranate`库来构建一个用于词性标注的HMM。可以通过在命令行运行以下命令来安装Pomegranate：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, we will not go into the details of the statistical POS tagger.
    The data we are using is a copy of the Brown corpus. The Brown corpus contains
    500 samples of English-language text, totaling roughly 1,000,000 words, compiled
    from works published in the United States in 1961.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们不深入讨论统计POS标注器。我们使用的数据是Brown语料库的副本。Brown语料库包含500个英语文本样本，总计约100万个单词，编纂自1961年在美国出版的作品。
- en: Getting data
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'Let''s start by defining some functions to read the data from the `corpus`
    files:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们先通过定义一些函数来读取`corpus`文件中的数据：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s now define a couple of classes, `Subset` and `Dataset`, to make it easier
    to handle the data:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义几个类，`Subset`和`Dataset`，以便更方便地处理数据：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let''s try to initialize the `Dataset` class and see how it works:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试初始化`Dataset`类并查看它是如何工作的：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Exploring the data
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据
- en: 'Let''s now explore the data to better understand how our classes store the
    information. We have randomly selected the `b100-38532` key:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索数据，更好地理解我们的类如何存储信息。我们随机选择了`b100-38532`键：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can also check the unique elements in the `corpus`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以检查`corpus`中的唯一元素：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can also use the `X` and `Y` attributes of the `Dataset` class to access
    the words and the corresponding tags:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`Dataset`类的`X`和`Y`属性来访问单词及其对应的标签：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can also use the `stream` method to iterate over pairs of a word and its
    tag:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`stream`方法来遍历单词和标签的配对：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finding the most frequent tag
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找最频繁的标签
- en: 'Now, just to compare the performance of our HMM model, let''s build a **most
    frequent class tagger** (**MFC** **Tagger**). We start by defining a function
    to count the pairs of tags and words:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了比较我们HMM模型的性能，让我们构建一个**最频繁类标注器**（**MFC** **Tagger**）。我们从定义一个函数开始，来统计标签和单词的配对：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, let''s define the `MFCTagger` class:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义`MFCTagger`类：
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here are some helper functions to make predictions from the model:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些辅助函数，用于从模型中进行预测：
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/0768458e-588b-4b73-834e-d7c7a8e3c4a8.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0768458e-588b-4b73-834e-d7c7a8e3c4a8.png)'
- en: Evaluating model accuracy
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型准确性
- en: 'To check how well our model performs, let''s evaluate the accuracy of our model:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查我们模型的表现，让我们评估模型的准确率：
- en: '[PRE12]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: An HMM-based tagger
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于HMM的标注器
- en: 'Now, we will try to build a POS tagger using HMM and hopefully it will improve
    our prediction performance. We will first define some helper functions:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将尝试使用HMM构建一个POS标注器，并希望它能提高我们的预测性能。我们将首先定义一些辅助函数：
- en: '[PRE15]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s build the model now:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们构建模型：
- en: '[PRE19]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](img/9a73582f-4681-4e84-9d86-3ebf5b0f6d93.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a73582f-4681-4e84-9d86-3ebf5b0f6d93.png)'
- en: '[PRE21]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We can see that the HMM-based model has been able to improve the accuracy of
    our model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，基于HMM的模型已经能够提高我们模型的准确率。
- en: Speech recognition
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音识别
- en: In the 1950s, Bell Labs was the pioneer in speech recognition. The early designed
    systems were limited to a single speaker and had a very limited vocabulary. After
    around 70 years of work, the current speech-recognition systems are able to work
    with speech from multiple speakers and can recognize thousands of words in multiple
    languages. A detailed discussion of all the techniques used is beyond the scope
    of this book as enough work has been done on each technique to have a book on
    itself.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在1950年代，贝尔实验室是语音识别的先锋。早期设计的系统仅限于单一发言者，并且词汇量非常有限。经过约70年的努力，当前的语音识别系统能够处理来自多个发言者的语音，并且能够识别数千个词汇，涵盖多种语言。由于每种技术都有足够的工作，已经足够成书，本书并不深入讨论所有使用的技术。
- en: But the general workflow for a speech-recognition system is to first capture
    the audio by converting the physical sound into an electrical signal using a microphone.
    The electrical signal generated by the microphone is analog and needs to be converted
    to a digital form for storage and processing, for which analog-to-digital converters
    are used. Once we have the speech in digital form, we can apply algorithms on
    it to understand the speech.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，语音识别系统的通用工作流程是首先通过麦克风将物理声音转换为电信号来捕捉音频。麦克风生成的电信号是模拟的，需要通过模拟-数字转换器将其转换为数字形式，以便存储和处理。一旦我们得到了数字化的语音，就可以应用算法来理解这些语音。
- en: As mentioned before, most of the state-of-the-art speech-recognition systems
    still use the concept of **Hidden Markov Models** (**HMM**) as their core. This
    is based on the assumption that a speech signal is a stationary process in a short
    time period of a few milliseconds. Hence, the first step for the speech-recognition
    system is to split the signal into small fragments of around 10 milliseconds.
    Then the power spectrum of each fragment is mapped to a vector of real numbers,
    known as **cepstral coefficients**. The dimension of this vector is usually small,
    although more accurate systems usually work with more than 32 dimensions. The
    final output of the HMM model is a sequence of these vectors. Once we have these
    vectors, these groups of vectors are matched to one or more phonemes, which are
    a fundamental unit of speech. But for effectively matching these groups of vectors
    to phonemes, we need to train our system since there is a huge variation in the
    sound of phonemes between different speakers as well as different utterances from
    the same speaker. Once we have the sequence of phonemes, our system tries to guess
    the most likely word that could have possibly produced that sequence of phonemes.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，大多数先进的语音识别系统仍然使用**隐马尔可夫模型**（**HMM**）作为核心。其基本假设是，语音信号在短时间内（几毫秒）是一个平稳的过程。因此，语音识别系统的第一步是将信号拆分为大约10毫秒的小片段。然后，每个片段的功率谱被映射到一个实数向量，这个向量被称为**倒谱系数**。这个向量的维度通常较小，尽管更精确的系统通常会使用超过32维的向量。HMM模型的最终输出是一系列这些向量。一旦我们获得这些向量，这些向量组会与一个或多个音素匹配，音素是语音的基本单位。但为了有效地将这些向量组与音素匹配，我们需要训练系统，因为不同发音者以及同一发音者不同发音之间，音素的发音差异巨大。一旦我们得到音素的序列，系统会尝试猜测最有可能产生该音素序列的词。
- en: As we can imagine, this whole detection process can be computationally quite
    expensive. For dealing with this complexity issue, modern speech-recognition systems
    use neural networks for feature-transformation and dimensionality-reduction before
    using the HMM for recognition. Another commonly used technique to reduce computation
    is to use voice activity detectors, which can detect the regions in the signal
    that contain speech. Using this information, we can design the recognizer to only
    spend computation on the parts of the signal that contain speech.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所想，这整个检测过程计算开销非常大。为了解决这一复杂性问题，现代语音识别系统使用神经网络进行特征转换和降维，然后再使用HMM进行识别。另一个常用的减少计算量的技术是使用语音活动检测器，它可以检测信号中包含语音的区域。利用这些信息，我们可以设计识别器只对包含语音的信号部分进行计算。
- en: Fortunately, Python has a very developed ecosystem to work with speech recognition.
    In the next section, we will look into the different Python packages available
    for working with speech recognition.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Python拥有一个非常发达的生态系统，可以与语音识别技术进行配合。在下一部分中，我们将探讨用于语音识别的不同Python包。
- en: Python packages for speech recognition
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音识别的Python包
- en: 'The Python package hosting service, PyPI, has a lot of speech-recognition systems
    listed. Some of the most commonly used ones are as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Python包托管服务PyPI列出了许多语音识别系统。以下是一些最常用的：
- en: SpeechRecognition ([https://pypi.org/project/SpeechRecognition/](https://pypi.org/project/SpeechRecognition/))
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SpeechRecognition ([https://pypi.org/project/SpeechRecognition/](https://pypi.org/project/SpeechRecognition/))
- en: apiai ([https://pypi.org/project/apiai/](https://pypi.org/project/apiai/))
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: apiai ([https://pypi.org/project/apiai/](https://pypi.org/project/apiai/))
- en: assemblyai ([https://pypi.org/project/assemblyai/](https://pypi.org/project/assemblyai/))
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: assemblyai ([https://pypi.org/project/assemblyai/](https://pypi.org/project/assemblyai/))
- en: pocketsphinx ([https://pypi.org/project/pocketsphinx/](https://pypi.org/project/pocketsphinx/))
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pocketsphinx ([https://pypi.org/project/pocketsphinx/](https://pypi.org/project/pocketsphinx/))
- en: google-cloud-speech ([https://pypi.org/project/google-cloud-speech/](https://pypi.org/project/google-cloud-speech/))
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: google-cloud-speech ([https://pypi.org/project/google-cloud-speech/](https://pypi.org/project/google-cloud-speech/))
- en: watson-developer-cloud ([https://pypi.org/project/watson-developer-cloud/](https://pypi.org/project/watson-developer-cloud/))
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: watson-developer-cloud ([https://pypi.org/project/watson-developer-cloud/](https://pypi.org/project/watson-developer-cloud/))
- en: Some of these Python packages (such as `apiai`) offer more than just speech
    recognition and have implementations of natural language processing algorithms,
    using which the user can identify the speaker's intent from speech. The other
    packages focus only on speech recognition, which can be used to convert audio
    to text.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一些 Python 包（如 `apiai`）不仅提供语音识别，还实现了自然语言处理算法，用户可以通过这些算法从语音中识别出说话者的意图。其他包则专注于语音识别，能够将音频转换为文本。
- en: 'In this chapter, we will use the `SpeechRecognition` package. We have chosen `SpeechRecognition`
    for two reasons:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 `SpeechRecognition` 包。我们选择 `SpeechRecognition` 有两个原因：
- en: It has a very simple-to-use API to directly access and process audio signals.
    For other packages, we usually need to write small scripts for them to be able
    to access files.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了一个非常简单的 API，可以直接访问和处理音频信号。对于其他包，通常需要编写小脚本才能访问文件。
- en: It is a wrapper over several popular speech APIs and therefore is extremely
    flexible, and multiple services can be used without making much change to our
    code.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是多个流行语音 API 的封装，因此非常灵活，且可以在不对代码做太多修改的情况下使用多个服务。
- en: 'So, to start using `SpeechRecognition`, we need to install the package. Since
    it''s hosted on PyPI, it can be installed directly using `pip`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要开始使用 `SpeechRecognition`，我们需要安装该包。由于它托管在 PyPI 上，因此可以通过 `pip` 直接安装：
- en: '[PRE22]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Basics of SpeechRecognition
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音识别基础
- en: The most important class in the package is the `Recognizer` class as it handles
    most of the recognition tasks. We can specify different settings and functionality
    for recognizing speech from an audio source while initializing the class.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该包中最重要的类是 `Recognizer` 类，因为它处理大多数的识别任务。我们可以在初始化类时指定不同的设置和功能，以便从音频源中识别语音。
- en: 'The `Recognizer` class can be initialized very easily without passing any argument:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`Recognizer` 类可以非常简单地初始化，无需传递任何参数：'
- en: '[PRE23]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Each instance of the `Recognizer` class has seven different possible methods
    that can be used to convert speech to text. Each of these methods uses a specific
    speech-recognition service. The seven methods are the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`Recognizer` 类的每个实例有七种不同的方法可以用于将语音转换为文本。这些方法分别使用了特定的语音识别服务。七种方法如下：'
- en: '`recognize_bing`: Uses Microsoft''s Bing Speech.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_bing`：使用微软的 Bing 语音服务。'
- en: '`recognize_google`: Uses Google''s Web Speech API.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_google`：使用 Google 的 Web Speech API。'
- en: '`recognize_google_cloud`: Uses Google''s Cloud Speech. Using this method would
    need `google-cloud-speech` to be installed, which can be easily installed through `pip`by
    running `pip install google-cloud-speech`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_google_cloud`：使用 Google 的 Cloud Speech。使用此方法需要安装 `google-cloud-speech`，可以通过运行
    `pip install google-cloud-speech` 来轻松安装。'
- en: '`recognize_houndify`: Uses SoundHound''s Houndify.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_houndify`：使用 SoundHound 的 Houndify 服务。'
- en: '`recognize_ibm`: Uses IBM''s speech to text.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_ibm`：使用 IBM 的语音转文本服务。'
- en: '`recognize_sphinx`: Uses CMU''s Sphinx. This method has a dependency on `PocketSphinx`,
    which can be installed by running `pip install pocketsphinx`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_sphinx`：使用 CMU 的 Sphinx。此方法依赖于 `PocketSphinx`，可以通过运行 `pip install
    pocketsphinx` 来安装。'
- en: '`recognize_wit`: Uses Wit.ai.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognize_wit`：使用 Wit.ai 服务。'
- en: One important thing to keep in mind while using these methods is that since
    most of these recognition services are offered by companies through web APIs,
    we need an internet connection to access these services. Also, some of these services
    only allow usage after registering with them online. Out of these seven, only `recognize_sphinx`
    works offline.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些方法时要记住的一个重要事项是，由于大多数语音识别服务是通过 Web API 由公司提供的，因此我们需要互联网连接才能访问这些服务。此外，一些服务只有在用户在线注册后才允许使用。在这七种方法中，只有
    `recognize_sphinx` 可以离线工作。
- en: Out of all these web APIs, only Google's Web Speech API works without any registration
    or API key. Therefore, to keep things simple, we will use that in the rest of
    this chapter.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些 Web API 中，只有 Google 的 Web Speech API 在没有注册或 API 密钥的情况下即可使用。因此，为了简化起见，我们将在本章剩余部分使用它。
- en: The recognize methods throw `RequestError` if the server is unavailable, there
    is no internet connection, or the API quota limits are met.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果服务器不可用、没有互联网连接或 API 配额限制已达，recognize 方法会抛出 `RequestError`。
- en: The next thing that we would need in order to do any recognition is some audio
    data. `SpeechRecognition` provides direct functionality to either work with an
    audio file or use audio from an attached microphone. In the following sections,
    we will look into both of these methods.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们需要做任何识别的，是一些音频数据。`SpeechRecognition`提供了直接的功能，可以使用音频文件或附加的麦克风音频。在接下来的部分中，我们将探讨这两种方法。
- en: Speech recognition from audio files
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从音频文件中进行语音识别
- en: To start working with audio files, we first need to download one. For the following
    example, we will use the `harvard.wav` file, which can be downloaded from [https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/harvard.wav](https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/harvard.wav).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用音频文件，首先需要下载一个。对于下面的示例，我们将使用`harvard.wav`文件，它可以从[https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/harvard.wav](https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/harvard.wav)下载。
- en: Make sure to save the audio files in the same directory from where the Python
    interpreter is running. Otherwise, for the following code, the path to the files
    will need to be modified.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将音频文件保存在Python解释器运行的同一目录中。否则，在接下来的代码中，文件的路径需要进行修改。
- en: 'For working with audio files, `SpeechRecognition` has the `AudioFile` class,
    which can be used for reading and working with audio files. We can use the `record`
    method of `AudioFile` to process the contents of the audio file before it can
    be used with the `Recognizer` class:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于音频文件的处理，`SpeechRecognition`提供了`AudioFile`类，用于读取和操作音频文件。我们可以使用`AudioFile`的`record`方法来处理音频文件的内容，然后再与`Recognizer`类一起使用：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The context manager opens the audio and records its content into `audio`, which
    is an instance of `AudioFile`. We can check it by calling the `type` method on `audio`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文管理器打开音频并将其内容记录到`audio`中，`audio`是`AudioFile`的一个实例。我们可以通过调用`type`方法检查它：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, once we have an `AudioFile` instance, we can call any of the recognize
    methods with it as an argument. The recognize method would call the specific web
    API to translate the speech from the audio file and return the following text:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一旦我们拥有了一个`AudioFile`实例，就可以调用任何识别方法，并将其作为参数传递。识别方法会调用特定的网络API，将音频文件中的语音转换成文本，并返回如下文本：
- en: '[PRE26]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In this case, we transcribed the whole audio file, but what if we want to only
    translate a specific part of the audio file? This can be done by passing additional
    arguments to the `record` method:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，我们转录了整个音频文件，但如果我们只想翻译音频文件的特定部分，该怎么办？可以通过将额外的参数传递给`record`方法来实现：
- en: '[PRE27]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `record` method keeps a pointer in the audio file to point at the position
    until which recording has happened. So, if we do another record of four seconds
    on the same file, it will record from the four-second mark to the eight-second
    mark of the original audio file.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`record`方法会在音频文件中保留一个指针，指向记录已经完成的位置。因此，如果我们在同一个文件上再录制四秒钟，它将从原始音频文件的四秒标记到八秒标记进行录音。'
- en: 'In the preceding example, we transcribed a part of the audio file but the starting
    point was the start of the file. What if we want to start at a different time
    point? It can be done by passing another argument, `offset`, to the `record` method:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们转录了音频文件的一部分，但起始点是文件的开始。如果我们希望从不同的时间点开始该怎么办？可以通过将另一个参数`offset`传递给`record`方法来实现：
- en: '[PRE28]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If you listen to the `harvard.wav` file, you will realize that the recording
    is done in perfect conditions without any external noise, but that is usually
    not the case in real-life audio. Let''s try to transcribe another audio signal, `jackhammer.wav`,
    which can be downloaded from [https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/jackhammer.wav](https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/jackhammer.wav).
    If you listen to the audio file, you can notice that it has a lot of background
    noise. Let''s try to transcribe this file and see how the recognizer performs:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你听一下`harvard.wav`文件，你会发现录音是在没有外部噪音的完美环境下完成的，但在现实生活中的音频通常不是这样。我们来试着转录另一个音频信号`jackhammer.wav`，它可以从[https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/jackhammer.wav](https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/jackhammer.wav)下载。如果你听这个音频文件，你会注意到它有很多背景噪音。让我们试着转录这个文件，看看识别器的表现如何：
- en: '[PRE29]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: As we can see, the transcription is way off. In such cases, we can use the `adjust_for_ambient_noise`
    method provided in the `Recognizer` class to calibrate our audio signal with the
    noise.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，转录结果差得很远。在这种情况下，我们可以使用`Recognizer`类中提供的`adjust_for_ambient_noise`方法来调整我们的音频信号与噪声的匹配。
- en: '`adjust_for_ambient_noise` by default uses the first one second of data to
    do the calibration, but we can change that by passing a `duration` argument to
    it:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`adjust_for_ambient_noise`默认使用前一秒的数据进行校准，但我们可以通过传递`duration`参数来改变这一点：'
- en: '[PRE30]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: If we don't want to lose much information, we can reduce the value of the `duration`
    argument, but that can result in a poorer calibration. As we can see, the transcription
    is still not perfect, but it is much better than when we didn't use `adjust_for_ambient_noise`.
    We can actually get better results by trying to clean the noise from the audio
    using signal processing techniques, which are outside the scope of this book.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不想失去太多信息，我们可以减小`duration`参数的值，但这可能会导致较差的校准。如我们所见，转录结果仍然不完美，但比我们没有使用`adjust_for_ambient_noise`时要好得多。实际上，我们可以通过使用信号处理技术来清理音频中的噪声，从而获得更好的结果，但这超出了本书的范围。
- en: 'Another thing that we can do in such cases is to look at all the most likely
    transcriptions by the recognizer. It can be done by using the `show_all` argument
    while calling the `recognize` method:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们还可以做的一件事是查看识别器最可能的所有转录。可以通过在调用`recognize`方法时使用`show_all`参数来实现：
- en: '[PRE31]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Using this, we can then choose the best transcription for our specific problem.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个方法，我们可以选择最适合我们具体问题的转录结果。
- en: Speech recognition using the microphone
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用麦克风进行语音识别
- en: In the previous section, we used the recognizer methods to transcribe speech
    from audio files. In this section, we will do a transcription using speech recorded
    from our microphone.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了识别器方法从音频文件中转录语音。在本节中，我们将使用从麦克风录制的语音进行转录。
- en: But before we get into that, we will need to install an additional package,
    called `PyAudio`. It is also available on PyPI and can be installed directly using
    `pip: pip install PyAudio`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '但在我们开始之前，我们需要安装一个额外的软件包，叫做`PyAudio`。它也可以在PyPI上找到，并且可以直接使用`pip: pip install
    PyAudio`进行安装。'
- en: 'In the previous section, for working with audio files, we were using the `AudioFile`
    class, but for working with a microphone, we will need to use the `Microphone`
    class. Most of the recognition API still remains the same. Let''s take a simple
    example to understand how it works:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，处理音频文件时我们使用了`AudioFile`类，但在处理麦克风时，我们需要使用`Microphone`类。大部分的识别API仍然保持不变。让我们通过一个简单的例子来理解它是如何工作的：
- en: '[PRE32]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Similarly to how we had initialized the `AudioFile` class in the previous section,
    we need to initialize the `Microphone` class this time. Also, instead of `record`,
    we need to call the `listen` method to record the audio. The Python interpreter
    would wait for a while to record audio when executing the previous code block.
    Try saying something into the microphone. Once the interpreter prompt returns,
    we can call the `recognize` method to transcribe the recorded audio:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一节初始化`AudioFile`类类似，这一次我们需要初始化`Microphone`类。此外，我们需要调用`listen`方法来录制音频，而不是`record`。当执行前面的代码块时，Python解释器会等待一段时间来录制音频。试着对着麦克风说话。一旦解释器提示符返回，我们就可以调用`recognize`方法来转录录制的音频：
- en: '[PRE33]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Summary
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we looked into two of the major applications of HMMs: POS
    tagging and speech recognition. We coded the POS tagger using a most-frequent
    tag algorithm and used the `pomegranate` package to build one based on HMM. We
    compared the performance using both these methods and saw that an HMM-based approach
    outperforms the most-frequent tag method. Then, we used the `SpeechRecognition`
    package to transcribe audio to text using Google''s Web Speech API. We looked
    into using the package with both audio files and live audio from a microphone.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探讨了HMM的两个主要应用：词性标注和语音识别。我们使用最频繁标签算法编写了词性标注器，并使用`pomegranate`包基于HMM构建了一个词性标注器。我们比较了这两种方法的性能，发现基于HMM的方法优于最频繁标签法。然后，我们使用`SpeechRecognition`包通过Google的Web语音API将音频转录为文本。我们探讨了如何使用该包处理音频文件和来自麦克风的实时音频。
- en: In the next chapter, we will explore more applications of HMMs, specifically
    in the field of image recognition.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探索HMM的更多应用，特别是在图像识别领域。
