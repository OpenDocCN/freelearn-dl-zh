- en: Exploring the Gym and its Features
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Gym及其功能
- en: Now that you have a working setup, we will start exploring the various features
    and options provided by the Gym toolkit. This chapter will walk you through some
    of the commonly used environments, the tasks they solve, and what it would take
    for your agent to master a task.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了一个工作环境，我们将开始探索Gym工具包提供的各种功能和选项。本章将带你了解一些常用的环境、它们解决的任务以及你的智能体需要做什么才能掌握这些任务。
- en: 'In this chapter, we will explore the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索以下主题：
- en: Exploring the various types of Gym environment
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索各种类型的Gym环境
- en: Understanding the structure of the reinforcement learning loop
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解强化学习循环的结构
- en: Understanding the different observation and action spaces
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解不同的观察空间和动作空间
- en: Exploring the list of environments and nomenclature
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索环境列表和命名法
- en: Let's start by picking an environment and understanding the Gym interface. You
    may already be familiar with the basic function calls to create a Gym environment
    from the previous chapters, where we used them to test our installations. Here,
    we will formally go through them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从选择一个环境并理解Gym接口开始。你可能已经熟悉从前几章中创建Gym环境的基本函数调用，我们曾用这些函数测试过安装情况。在这里，我们将正式通过这些函数。
- en: 'Let''s activate the `rl_gym_book` conda environment and open a Python prompt.
    The first step is to import the Gym Python module using the following line of
    code:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们激活`rl_gym_book`的conda环境，并打开Python提示符。第一步是使用以下代码导入Gym Python模块：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can now use the `gym.make` method to create an environment from the available
    list of environments. You may be asking how to find the list of Gym environments
    available on your system. We will create a small utility script to generate the
    list of environments so that you can refer to it later when you need to. Let''s
    create a script named `list_gym_envs.py` under the `~/rl_gym_book/ch4` directory
    with the following contents:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`gym.make`方法从可用的环境列表中创建一个环境。你可能会问，如何查找系统中可用的Gym环境列表。我们将创建一个小的实用脚本来生成环境列表，方便你在需要时参考。让我们在`~/rl_gym_book/ch4`目录下创建一个名为`list_gym_envs.py`的脚本，内容如下：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This script will print the names of all the environments available through
    your Gym installation, sorted alphabetically. You can run this script using the
    following command to see the names of the environments installed and available
    in your system:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本将按字母顺序打印通过Gym安装可用的所有环境的名称。你可以使用以下命令运行此脚本，以查看系统中已安装并可用的环境名称：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You will get an output like this. Note that only the first few environment
    names are shown in it. They may be different, depending on the environments you
    installed on your system based on what we discussed in [Chapter 3](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12),
    *Getting Started with OpenAI Gym and Deep Reinforcement Learning*:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到如下输出。注意，只有前几个环境名称会显示出来，它们可能会有所不同，具体取决于你系统上安装的环境，这些环境是根据我们在[第3章](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12)中讨论的内容，*开始使用OpenAI
    Gym和深度强化学习*所安装的：
- en: '![](img/00111.jpeg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00111.jpeg)'
- en: From the list of environment names, you may note that there are similar names,
    with some variations. For example, there are eight different variations for the
    Alien environment. Let's try to understand the nomenclature before we pick one
    and start using it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从环境名称列表中，你可能会注意到有一些相似的名称，带有一些变化。例如，Alien环境有八个不同的变种。让我们在开始使用它之前，先理解命名法。
- en: Nomenclature
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名法
- en: The presence of the word *ram* in the environment name means that the observation
    returned by the environment is the contents of the **Random Access Memory** (**RAM**)
    of the Atari console on which the game was designed to run.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 环境名称中包含*ram*这个词，意味着环境返回的观察值是游戏设计运行的Atari主机的**随机存取内存**（**RAM**）的内容。
- en: The presence of the word *deterministic* in the environment names means that
    the actions sent to the environment by the agent are performed repeatedly for
    a *deterministic/fixed* duration of four frames, and then the resulting state
    is returned.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 环境名称中包含*deterministic*这个词，意味着智能体发送给环境的动作会在一个*确定性的/固定的*四帧时长内重复执行，然后返回结果状态。
- en: The presence of the word *NoFrameskip* means that the actions sent to the environment
    by the agent are performed once and the resulting state is returned immediately,
    without skipping any frames in-between.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 包含单词 *NoFrameskip* 表示智能体发送到环境中的动作会执行一次，结果状态立即返回，中间不跳过任何帧。
- en: By default, if *deterministic* and *NoFrameskip* are not included in the environment
    name, the action sent to the environment is repeatedly performed for a duration
    of *n* frames, where *n* is uniformly sampled from {2,3,4}.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，如果环境名称中没有包含 *deterministic* 和 *NoFrameskip*，则发送到环境中的动作会重复执行 *n* 帧的持续时间，其中
    *n* 从 {2,3,4} 中均匀采样。
- en: The letter *v* followed by a number in the environment name represents the version
    of the environment. This is to make sure that any change to the environment implementation
    is reflected in its name so that the results obtained by an algorithm/agent in
    an environment are comparable to the results obtained by another algorithm/agent
    without any discrepancies.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 环境名称中的字母 *v* 后跟一个数字，表示环境的版本。这是为了确保环境实现的任何变化都体现在其名称中，从而使得在不同算法/智能体下得到的结果具有可比性，不会出现任何差异。
- en: 'Let''s understand this nomenclature by looking at the Atari Alien environment.
    The various options available are listed with a description as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过观察 Atari Alien 环境来理解这种命名法。以下列出了可用的各种选项及其描述：
- en: '| **Version name** | **Description** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **版本名称** | **描述** |'
- en: '| `Alien-ram-v0` | Observation is the RAM contents of the Atari machine with
    a total size of 128 bytes and the action sent to the environment is repeatedly
    performed for a duration of *n* frames, where *n* is uniformly sampled from {2,3,4}.
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-ram-v0` | 观察是 Atari 机器的 RAM 内容，总大小为 128 字节，发送到环境中的动作会重复执行 *n* 帧的持续时间，其中
    *n* 从 {2,3,4} 中均匀采样。 |'
- en: '| `Alien-ram-v4` | Observation is the RAM contents of the Atari machine with
    a total size of 128 bytes and the action sent to the environment is repeatedly
    performed for a duration of *n* frames, where *n* is uniformly sampled from {2,3,4}.
    There''s some modification in the environment compared to v0. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-ram-v4` | 观察是 Atari 机器的 RAM 内容，总大小为 128 字节，发送到环境中的动作会重复执行 *n* 帧的持续时间，其中
    *n* 从 {2,3,4} 中均匀采样。与 v0 版本相比，环境有所修改。 |'
- en: '| `Alien-ramDeterministic-v0` | Observation is the RAM contents of the Atari
    machine with a total size of 128 bytes and the action sent to the environment
    is repeatedly performed for a duration of four frames. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-ramDeterministic-v0` | 观察是 Atari 机器的 RAM 内容，总大小为 128 字节，发送到环境中的动作会重复执行四帧的持续时间。
    |'
- en: '| `Alien-ramDeterministic-v4` | Observation is the RAM contents of the Atari
    machine with a total size of 128 bytes and the action sent to the environment
    is repeatedly performed for a duration of four frames. There''s some modification
    in the environment compared to v0. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-ramDeterministic-v4` | 观察是 Atari 机器的 RAM 内容，总大小为 128 字节，发送到环境中的动作会重复执行四帧的持续时间。与
    v0 版本相比，环境有所修改。 |'
- en: '| `Alien-ramNoFrameskip-v0` | Observation is the RAM contents of the Atari
    machine with a total size of 128 bytes and the action sent to the environment
    is applied, and the resulting state is returned immediately without skipping any
    frames. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-ramNoFrameskip-v0` | 观察是 Atari 机器的 RAM 内容，总大小为 128 字节，发送到环境中的动作会应用，并且结果状态立即返回，不跳过任何帧。
    |'
- en: '| `Alien-v0` | Observation is an RGB image of the screen represented as an
    array of shape (210, 160, 3) and the action sent to the environment is repeatedly
    performed for a duration of *n* frames, where *n* is uniformly sampled from {2,3,4}.
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-v0` | 观察是屏幕的 RGB 图像，表示为形状为 (210, 160, 3) 的数组，发送到环境中的动作会重复执行 *n* 帧的持续时间，其中
    *n* 从 {2,3,4} 中均匀采样。 |'
- en: '| `Alien-v4` | Observation is an RGB image of the screen represented as an
    array of shape (210, 160, 3) and the action sent to the environment is repeatedly
    performed for a duration of *n* frames, where *n* is uniformly sampled from {2,3,4}.
    There''s some modification in the environment compared to v0. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `Alien-v4` | 观察是屏幕的 RGB 图像，表示为形状为 (210, 160, 3) 的数组，发送到环境中的动作会重复执行 *n* 帧的持续时间，其中
    *n* 从 {2,3,4} 中均匀采样。与 v0 版本相比，环境有所修改。 |'
- en: '| `AlienDeterministic-v0` | Observation is an RGB image of the screen represented
    as an array of shape (210, 160, 3) and the action sent to the environment is repeatedly
    performed for a duration of four frames. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `AlienDeterministic-v0` | 观察是一个RGB图像，表示为形状为(210, 160, 3)的数组，发送到环境的动作会反复执行，持续四帧。
    |'
- en: '| `AlienDeterministic-v4` | Observation is an RGB image of the screen represented
    as an array of shape (210, 160, 3) and the action sent to the environment is repeatedly
    performed for a duration of four frames. There''s some modification in the environment
    compared to v0. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `AlienDeterministic-v4` | 观察是一个RGB图像，表示为形状为(210, 160, 3)的数组，发送到环境的动作会反复执行，持续四帧。与v0版本相比，环境有所修改。
    |'
- en: '| `AlienNoFrameskip-v0` | Observation is an RGB image of the screen represented
    as an array of shape (210, 160, 3) and the action sent to the environment is applied,
    and the resulting state is returned immediately without skipping any frames. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `AlienNoFrameskip-v0` | 观察是一个RGB图像，表示为形状为(210, 160, 3)的数组，发送到环境的动作会立即应用，且不会跳过任何帧。
    |'
- en: '| `AlienNoFrameskip-v4` | Observation is an RGB image of the screen represented
    as an array of shape (210, 160, 3) and the action sent to the environment is applied,
    and the resulting state is returned immediately without skipping any frames. any
    frames. There''s some modification in the environment compared to v0. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `AlienNoFrameskip-v4` | 观察是一个RGB图像，表示为形状为(210, 160, 3)的数组，发送到环境的动作会立即应用，且不会跳过任何帧。与v0版本相比，环境有所修改。
    |'
- en: This summary should help you understand the nomenclature of the environments,
    and it applies to all environments in general. The RAM may be specific to the
    Atari environments, but you now have an idea of what to expect when you see several
    related environment names.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个总结有助于你理解环境的命名法，并且它适用于所有环境。RAM可能是专门针对Atari环境的，但现在你已经对遇到几个相关的环境名称时应该期望什么有了一个大致的了解。
- en: Exploring the Gym environments
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Gym环境
- en: 'To make it easy for us to visualize what an environment looks like or what
    its task is, we will make use of a simple script that can launch any environment
    and step through it with some randomly sampled actions. You can download the script
    from this book''s code repository under `ch4` or create a file named `run_gym_env.py`
    under `~/rl_gym_book/ch4` with the following contents:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于我们可视化一个环境的样子或它的任务是什么，我们将使用一个简单的脚本，它可以启动任何环境并通过一些随机抽取的动作进行步骤。你可以从本书的代码仓库中下载这个脚本，位于`ch4`目录下，或者在`~/rl_gym_book/ch4`目录下创建一个名为`run_gym_env.py`的文件，内容如下：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This script will take the name of the environment supplied as the first command-line
    argument and the number of steps to be run. For example, we can run the script
    like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本将接受作为第一个命令行参数传入的环境名称，以及要运行的步骤数。例如，我们可以像这样运行脚本：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This command will launch the `Alien-ram-v0` environment and step through it
    2,000 times using random actions sampled from the action space of the environment.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将启动`Alien-ram-v0`环境，并通过随机动作在环境的动作空间中进行2,000次步骤。
- en: 'You will see a window pop up with the `Alien-ram-v0` environment, like this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到一个窗口弹出，显示`Alien-ram-v0`环境，像这样：
- en: '![](img/00112.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00112.jpeg)'
- en: Understanding the Gym interface
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Gym接口
- en: 'Let''s continue our Gym exploration by understanding the interface between
    the Gym environment and the agents that we will develop. To help us with that,
    let''s have another look at the picture we saw in [Chapter 2](part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12), *Reinforcement
    Learning and Deep Reinforcement Learning*, when we were discussing the basics
    of reinforcement learning:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续探索Gym，了解Gym环境与我们将开发的智能体之间的接口。为此，我们再回顾一下在[第2章](part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12)中看到的图片，*强化学习与深度强化学习*，那时我们讨论了强化学习的基本知识：
- en: '![](img/00113.jpeg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00113.jpeg)'
- en: Did the picture give you an idea about the interface between the agent and the
    environment? We will make your understanding secure by going over the description
    of the interface.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图给你提供了关于智能体与环境之间接口的想法吗？我们将通过详细讲解接口的描述来巩固你的理解。
- en: 'After we `import gym` , we `make` an environment using the following line of
    code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们`import gym`之后，我们可以使用以下代码行来`make`一个环境：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, `ENVIRONMENT_NAME` is the name of the environment we want, chosen from
    the list of the environments we found installed on our system. From the previous
    diagram, we can see that the first arrow comes from the environment to the agent,
    and is named Observation. From [Chapter 2](part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12),
    *Reinforcement Learning and Deep Reinforcement Learning*, we understand the difference
    between partially observable environments and fully observable environments, and
    the difference between state and observation in each case. We get that first observation
    from the environment by calling `env.reset()`. Let''s store the observation in
    a variable named `obs` using the following line of code:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`ENVIRONMENT_NAME`是我们想要的环境名称，它是从我们系统中安装的环境列表中选择的。从前面的图中可以看出，第一个箭头是从环境指向智能体的，命名为“Observation”。在[第2章](part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12)《强化学习与深度强化学习》中，我们理解了部分可观察环境与完全可观察环境的区别，以及每种情况下状态与观察的不同。我们通过调用`env.reset()`从环境中获取第一次观察。我们使用以下代码将观察存储在名为`obs`的变量中：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, the agent has received the observation (the end of the first arrow). It's
    time for the agent to take an action and send the action to the environment to
    see what happens. In essence, this is what the algorithms we develop for the agents
    should figure out! We'll be developing various state-of-the-art algorithms to
    develop agents in the next and subsequent chapters. Let's continue our journey
    towards understanding the Gym interface.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，智能体已经接收到了观察（第一个箭头的终点）。是时候让智能体采取行动并将其发送到环境中，看看会发生什么。实际上，这正是我们为智能体开发的算法应该解决的问题！我们将在接下来的章节中开发各种最先进的算法，帮助智能体的发展。让我们继续了解Gym接口的旅程。
- en: 'Once the action to be taken is decided, we send it to the environment (second
    arrow in the diagram) using the `env.step()` method, which will return four values
    in this order: `next_state`, `reward`, `done`, and `info`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦决定了要采取的动作，我们就通过`env.step()`方法将其发送到环境（图中的第二个箭头），该方法将按顺序返回四个值：`next_state`、`reward`、`done`和`info`：
- en: The `next_state` is the resulting state of the environment after the action
    was taken in the previous state.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`next_state`是采取前一个状态下的动作后，环境所产生的结果状态。'
- en: Some environments may internally run one or more steps using the same action
    before returning the `next_state`. We discussed *deterministic* and *NoFrameskip*
    types in the previous section, which are examples of such environments.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有些环境可能在内部运行一个或多个步骤，使用相同的动作，然后再返回`next_state`。我们在前一节讨论了*确定性*和*无帧跳跃*类型，这些都是此类环境的示例。
- en: The `reward` (third arrow in the diagram) is returned by the environment.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`reward`（图中的第三个箭头）是由环境返回的。'
- en: The `done` variable is a Boolean (true or false), which gets a value of true
    if the episode has terminated/finished (therefore, it is time to reset the environment)
    and false otherwise. This will be useful for the agent to know when an episode
    has ended or when the environment is going to be reset to some initial state.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`done`变量是一个布尔值（真或假），如果回合已经结束/完成（因此是时候重置环境了），它的值为真，否则为假。这个变量对于智能体了解回合是否结束或环境是否即将重置为某个初始状态非常有用。'
- en: The `info` variable returned is an optional variable, which some environments
    may return with some additional information. Usually, this is not used by the
    agent to make its decision on which action to take.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`info`变量是一个可选变量，某些环境可能会返回该变量，并附带一些额外的信息。通常，智能体不会使用它来决定采取哪个动作。'
- en: 'Here is a consolidated summary of the four values returned by a Gym environment''s
    `step()` method, together with their types and a concise description about them:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是由Gym环境的`step()`方法返回的四个值的汇总总结，以及它们的类型和简要描述：
- en: '| **Returned value** | **Type** | **Description** |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **返回值** | **类型** | **描述** |'
- en: '| `next_state` (or observation) | `Object` | Observation returned by the environment.
    The object could be the RGB pixel data from the screen/camera, RAM contents, join
    angles and join velocities of a robot, and so on, depending on the environment.
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `next_state`（或观察） | `对象` | 环境返回的观察。该对象可能是来自屏幕/摄像头的RGB像素数据、RAM内容、机器人关节角度和关节速度等，具体取决于环境。
    |'
- en: '| `reward` | `Float` | Reward for the previous action that was sent to the
    environment. The range of the `Float` value varies with each environment, but
    irrespective of the environment, a higher reward is always better and the goal
    of the agent should be to maximize the total reward. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| `reward` | `Float` | 先前动作所获得的奖励，发送到环境中的`Float`类型奖励值。`Float`值的范围因环境而异，但无论环境如何，较高的奖励总是更好，智能体的目标应该是最大化总奖励。
    |'
- en: '| `done` | `Boolean` | Indicates whether the environment is going to be reset
    in the next step. When the Boolean value is true, it most likely means that the
    episode has ended (due to loss of life of the agent, timeout, or some other episode
    termination criteria). |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `done` | `Boolean` | 指示环境是否将在下一步被重置。当布尔值为真时，这通常意味着回合已经结束（可能是由于智能体失去生命、超时或其他回合终止标准）。
    |'
- en: '| `info` | `Dict` | Some additional information that can optionally be sent
    out by an environment as a dictionary of arbitrary key-value pairs. The agent
    we develop should not rely on any of the information in this dictionary for taking
    action. It may be used (if available) for debugging purposes. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `info` | `Dict` | 一些额外的信息，可以作为任意键值对的字典，由环境可选地发送出来。我们开发的智能体不应该依赖该字典中的任何信息来执行动作。它可以在（如果可用的情况下）用于调试目的。
    |'
- en: Note that the following code is provided to show the general structure and is
    not ready to be executed due to the `ENVIRONMENT_NAME` and the `agent.choose_action()`
    not being defined in this snippet.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，以下代码是为了展示一般结构而提供的，不能直接执行，因为`ENVIRONMENT_NAME`和`agent.choose_action()`在此代码片段中没有定义。
- en: 'Let''s put all the pieces together and look at them in one place:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把所有的部分放在一起，集中查看：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'I hope you got a good understanding of one cycle of the interaction between
    the environment and the agent. This process will repeat until we decide to terminate
    the cycle after a certain number of episodes or steps have passed. Let''s now
    have a look at a complete example with the inner loop running for `MAX_STEPS_PER_EPISODE`
    and the outer loop running for `MAX_NUM_EPISODES` in a `Qbert-v0` environment:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你已经对环境和智能体之间交互的一个周期有了清晰的理解。这个过程会一直重复，直到我们决定在一定数量的回合或步骤后终止这个周期。现在让我们看看一个完整的示例，其中内循环运行`MAX_STEPS_PER_EPISODE`，外循环运行`MAX_NUM_EPISODES`，并且环境是`Qbert-v0`：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'When you run this script, you will notice a Qbert screen pop up and Qbert taking
    random actions and getting a score, as shown here:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此脚本时，你会注意到 Qbert 屏幕会弹出，Qbert会进行随机动作并获得分数，如下所示：
- en: '![](img/00114.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00114.jpeg)'
- en: 'You will also see print statements on the console like the following, depending
    on when the episode ended. Note that the step numbers you get might be different
    because the actions are random:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会看到控制台上出现如下的打印语句，这取决于回合何时结束。请注意，你看到的步骤编号可能不同，因为动作是随机的：
- en: '![](img/00115.jpeg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00115.jpeg)'
- en: The boilerplate code is available in this book's code repository under the `ch4`
    folder and is named `rl_gym_boilerplate_code.py`. It is indeed boilerplate code,
    because the overall structure of the program will remain the same. When we build
    our intelligent agents in subsequent chapters, we will extend this boilerplate
    code. It is worth taking a while and going through the script line by line to
    make sure you understand it well.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 样板代码可在本书的代码库中的`ch4`文件夹下找到，名为`rl_gym_boilerplate_code.py`。它确实是样板代码，因为程序的整体结构将保持不变。当我们在后续章节中构建智能体时，我们将扩展这个样板代码。值得花些时间逐行阅读脚本，以确保你能很好地理解它。
- en: You may have noticed that in the example code snippets provided in this chapter
    and in [Chapter 3](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12), *Getting
    Started with OpenAI Gym and Deep Reinforcement Learning*, we used `env.action_space.sample()`
    in place of `action` in the previous code. `env.action_space` returns the type
    of the action space (`Discrete(18)`, for example, in the case of Alien-v0), and
    the `sample()` method randomly samples a value from that `action_space`. That's
    all it means!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在本章和[第3章](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12)《*开始使用
    OpenAI Gym 和深度强化学习*》中提供的示例代码片段中，我们使用了`env.action_space.sample()`来代替之前代码中的`action`。`env.action_space`返回动作空间的类型（例如，在Alien-v0环境中是`Discrete(18)`），而`sample()`方法会从该`action_space`中随机采样一个值。就这层意思！
- en: We will now have a closer look at the spaces in the Gym to understand the state
    space and action spaces of environments.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将更仔细地观察 Gym 中的空间，以理解环境的状态空间和动作空间。
- en: Spaces in the Gym
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gym 中的空间
- en: We can see that each environment in the Gym is different. Every game environment
    under the Atari category is also different from the others. For example, in the
    case of the `VideoPinball-v0` environment, the goal is to keep bouncing a ball
    with two paddles to collect points based on where the ball hits, and to make sure
    that the ball never falls below the paddles, whereas in the case of `Alien-v0`***,***
    which is another Atari game environment, the goal is to move through a maze (the
    rooms in a ship) collecting *dots*, which are equivalent to destroying the eggs
    of the alien. Aliens can be killed by collecting a pulsar dot and the reward/score
    increases when that happens. Do you see the variations in the games/environments?
    How do we know what types of actions are valid in a game?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，Gym 中的每个环境都是不同的。每个 Atari 类别下的游戏环境也都不同。例如，在 `VideoPinball-v0` 环境中，目标是用两个挡板不断弹跳球，通过球的撞击位置来获得积分，并确保球永远不会掉到挡板下方，而在
    `Alien-v0`***，***这是另一个 Atari 游戏环境，目标是在迷宫（船舱中的房间）中移动并收集 *点*，这些点等同于摧毁外星人的蛋。外星人可以通过收集脉冲点来杀死，且当发生这种情况时，奖励/分数会增加。你能看到游戏/环境中的变化吗？我们如何知道在游戏中哪些动作是有效的？
- en: In the VideoPinball environment, naturally, the actions are to move the paddles
    up or down, whereas in the Alien environment, the actions are to command the player
    to move left, right, up, or down. Note that there is no "move left" or "move right"
    action in the case of VideoPinball. When we look at other categories of environment,
    the variations are even greater. For example, in the case of continuous control
    environments such as recently release robotics environments with the fetch robot
    arms, the action is to vary the continuous valued join positions and joint velocities
    to achieve the task. The same discussion can be had with respect to the values
    of the observations from the environment. We already saw the different observation
    object types in the case of Atari (RAM versus RGB images).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 VideoPinball 环境中，行动自然是上下移动挡板，而在 Alien 环境中，行动是指令玩家向左、向右、向上或向下移动。请注意，在 VideoPinball
    环境中没有“向左移动”或“向右移动”的动作。我们如果看其他种类的环境，变化就更大了。例如，在最近发布的机器人环境中，像 fetch 机器人手臂这样的连续控制环境中，动作是改变连续值的关节位置和关节速度来完成任务。关于环境中观察值的讨论也是一样的。我们已经看到在
    Atari 环境中不同的观察对象类型（RAM 与 RGB 图像）。
- en: 'This is the motivation for why the *spaces* (as in mathematics) for the observation
    and actions are defined for each environment. At the time of the writing of this
    book, there are six spaces (plus one more called `prng` for random seed) that
    are supported by OpenAI Gym. They are listed in this table, with a brief description
    of each:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么为每个环境定义观察和动作的 *空间*（如数学中的空间）的动机。在本书编写时，OpenAI Gym 支持六种空间（再加一个叫做 `prng`
    的随机种子空间）。这些空间在下表中列出，并简要描述了每种空间：
- en: '| **Space type** | **Description** | **Usage Example** |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| **Space type** | **描述** | **使用示例** |'
- en: '| `Box` | A box in the ![](img/00116.jpeg)space (an *n*-dimensional box) where
    each coordinate is bounded to lie in the interval defined by [low,high]. Values
    will be an array of *n* numbers. The shape defines the *n* for the space. | `gym.spaces.Box(low=-100,
    high=100, shape=(2,))` |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `Box` | 空间中的盒子！[](img/00116.jpeg)（一个 *n* 维盒子），其中每个坐标都限制在由 [low,high] 定义的区间内。值将是一个
    *n* 数字的数组。形状定义了空间的 *n*。 | `gym.spaces.Box(low=-100, high=100, shape=(2,))` |'
- en: '| `Discrete` | Discrete, integer-value space in the interval [0,n-1]. The argument
    for `Discrete()` defines *n.* | `gym.spaces.Discrete(4)` |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `Discrete` | 离散的整数值空间，区间为 [0,n-1]。`Discrete()` 的参数定义了 *n*。 | `gym.spaces.Discrete(4)`
    |'
- en: '| `Dict` | A dictionary of sample space to create arbitrarily complex space.
    In the example, a Dict space is created, which consists of two discrete spaces
    for positions and velocities in three dimensions. | `gym.spaces.Dict({"position":
    gym.spaces.Discrete(3), "velocity": gym.spaces.Discrete(3)})` |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `Dict` | 一个字典类型的样本空间，用来创建任意复杂的空间。在示例中，创建了一个 Dict 空间，它由三个维度位置和速度的两个离散空间组成。
    | `gym.spaces.Dict({"position": gym.spaces.Discrete(3), "velocity": gym.spaces.Discrete(3)})`
    |'
- en: '| `MultiBinary` | *n*-dimensional binary space. The argument to `MultiBinary()`defines
    *n.* | `gym.spaces.MultiBinary(5)` |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `MultiBinary` | *n* 维二进制空间。`MultiBinary()` 的参数定义了 *n*。 | `gym.spaces.MultiBinary(5)`
    |'
- en: '| `MultiDiscrete` | Multi-dimensional discrete space. | `gym.spaces.MultiDiscrete([-10,10],
    [0,1])` |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `MultiDiscrete` | 多维离散空间。 | `gym.spaces.MultiDiscrete([-10,10], [0,1])` |'
- en: '| `Tuple` | A product of simpler spaces. | `gym.spaces.Tuple((gym.spaces.Discrete(2),
    spaces.Discrete(2)))` |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `Tuple` | 简单空间的组合。 | `gym.spaces.Tuple((gym.spaces.Discrete(2), spaces.Discrete(2)))`
    |'
- en: '`Box` and `Discrete` are the most commonly used action spaces. We now have
    a basic understanding of the various space types available in the Gym. Let''s
    look at how to find which observation and action spaces an environment uses.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`Box` 和 `Discrete` 是最常用的动作空间类型。我们现在对 Gym 中可用的各种空间类型有了基本的了解。接下来，我们来看看如何查找一个环境使用了哪些观察和动作空间。'
- en: 'The following script will print the observation and the action space of a given
    environment, and also optionally print the lower bound and upper bound of the
    values in the case of a `Box Space`. Additionally, it will also print a description/meaning
    of the possible action in the environment if it is provided by the environment:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本将打印出给定环境的观察空间和动作空间，并在 `Box Space` 的情况下，选项性地打印出值的下界和上界。此外，如果环境提供了动作的描述/含义，它还会打印出环境中可能的动作的描述：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This script is also available for download in this book''s code repository
    under `ch4`, named `get_observation_action_space.py`. You can run the script using
    the following command, where we supply the name of the environment as the first
    argument to the script:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本也可以在本书的代码库中下载，位于 `ch4` 文件夹下，名为 `get_observation_action_space.py`。你可以使用以下命令运行脚本，在其中我们将环境名称作为第一个参数提供给脚本：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The script will print an output like this:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本将打印出类似这样的输出：
- en: '![](img/00117.jpeg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00117.jpeg)'
- en: In this example, the script prints that the observation space for the `CartPole-v0`
    environment is `Box(4,)`*, *which corresponds to `cart position`, `cart velocity`,
    `pole angle`, and `pole velocity` at the tip for the four box values.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，脚本打印出 `CartPole-v0` 环境的观察空间是 `Box(4,)`，*这对应于 `小车位置`、`小车速度`、`杆角度` 和 `杆尖端速度`
    四个 box 值*。
- en: The action space is printed out to be `Discrete(2)`, which corresponds to *push
    cart to left *and *push cart to right *for the discrete values `0` and `1`, respectively.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 动作空间被打印为 `Discrete(2)`，这对应于*推动小车向左* 和 *推动小车向右*，离散值 `0` 和 `1` 分别代表这两个动作。
- en: 'Let''s have a look at another example that has a few more complex spaces. This
    time, let''s run the script with the `BipedalWalker-v2`environment:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看另一个例子，它包含了一些更复杂的空间。这一次，让我们使用 `BipedalWalker-v2` 环境运行脚本：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'That produces an output like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生类似这样的输出：
- en: '![](img/00118.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00118.jpeg)'
- en: 'A detailed description of the state space of the Bipedal Walker (v2) environment
    is tabulated here for your quick and easy reference:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 Bipedal Walker (v2) 环境状态空间的详细描述表格，供你快速参考：
- en: '| **Index** | **Name/description** | **Min** | **Max** |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **名称/描述** | **最小值** | **最大值** |'
- en: '| 0 | hull_angle | 0 | 2*pi |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 0 | hull_angle | 0 | 2*pi |'
- en: '| 1 | hull_angularVelocity | -inf | +inf |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 1 | hull_angularVelocity | -inf | +inf |'
- en: '| 2 | vel_x | -1 | +1 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 2 | vel_x | -1 | +1 |'
- en: '| 3 | vel_y | -1 | +1 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 3 | vel_y | -1 | +1 |'
- en: '| 4 | hip_joint_1_angle | -inf | +inf |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 4 | hip_joint_1_angle | -inf | +inf |'
- en: '| 5 | hip_joint_1_speed | -inf | +inf |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 5 | hip_joint_1_speed | -inf | +inf |'
- en: '| 6 | knee_joint_1_angle | -inf | +inf |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 6 | knee_joint_1_angle | -inf | +inf |'
- en: '| 7 | knee_joint_1_speed | -inf | +inf |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 7 | knee_joint_1_speed | -inf | +inf |'
- en: '| 8 | leg_1_ground_contact_flag | 0 | 1 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 8 | leg_1_ground_contact_flag | 0 | 1 |'
- en: '| 9 | hip_joint_2_angle | -inf | +inf |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 9 | hip_joint_2_angle | -inf | +inf |'
- en: '| 10 | hip_joint_2_speed | -inf | +inf |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 10 | hip_joint_2_speed | -inf | +inf |'
- en: '| 11 | knee_joint_2_angle | -inf | +inf |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 11 | knee_joint_2_angle | -inf | +inf |'
- en: '| 12 | knee_joint_2_speed | -inf | +inf |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 12 | knee_joint_2_speed | -inf | +inf |'
- en: '| 13 | leg_2_ground_contact_flag | 0 | 1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 13 | leg_2_ground_contact_flag | 0 | 1 |'
- en: '| 14-23 | 10 lidar readings | -inf | +inf |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 14-23 | 10 个激光雷达读数 | -inf | +inf |'
- en: The state space, as you can see, is quite complicated, which is reasonable for
    a complex bipedal walking robot. It more or less resembles an actual bipedal robot
    system and sensor configuration that we can find in the real world, such as Boston
    Dynamics' (part of Alphabet) Atlas bipedal robot, who stole the limelight during
    the DARPA Robotics Challenge in 2015.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，状态空间非常复杂，这对于一个复杂的双足行走机器人来说是合理的。它或多或少类似于我们在现实世界中可以找到的实际双足机器人系统和传感器配置，例如波士顿动力公司的
    Atlas 双足机器人，它在 2015 年的 DARPA 机器人挑战赛中成为了焦点。
- en: 'Next, we will look into and understand the action space. A detailed description
    of the action space for the Bipedal Walker (v2) environment is tabulated here
    for your quick and easy reference:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入了解动作空间。下面是 Bipedal Walker (v2) 环境的动作空间的详细描述表格，供你快速参考：
- en: '| Index | Name/description | Min | Max |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 索引 | 名称/描述 | 最小值 | 最大值 |'
- en: '| 0 | Hip_1 (torque/velocity) | -1 | +1 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 0 | Hip_1（扭矩/速度） | -1 | +1 |'
- en: '| 1 | Knee_1 (torque/velocity) | -1 | +1 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Knee_1（扭矩/速度） | -1 | +1 |'
- en: '| 2 | Hip_2 (torque/velocity) | -1 | +1 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Hip_2（扭矩/速度） | -1 | +1 |'
- en: '| 3 | Knee_2 (torque/velocity) | -1 | +1 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 3 | Knee_2（扭矩/速度） | -1 | +1 |'
- en: Action
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 动作
- en: The torque control is the default control method, which controls the amount
    of torque applied at the joints.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 扭矩控制是默认的控制方法，它控制关节处施加的扭矩量。
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored the list of Gym environments available on your
    system, which you installed in the previous chapter, and then understood the naming
    conventions, or nomenclature, of the environments. We then revisited the agent-environment
    interaction (the RL loop) diagram and understood how the Gym environment provides
    the interfaces corresponding to each of the arrows we saw in the image. We then
    looked at a consolidated summary of the four values returned by the Gym environment's
    `step()` method in a tabulated, easy-to-understand format to *reinforce* your
    understanding of what they mean!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了系统中可用的Gym环境列表，这是你在上一章中安装的，然后了解了环境的命名约定或术语。接着我们回顾了代理与环境的交互（RL循环）图，并理解了Gym环境如何提供与我们在图像中看到的每个箭头对应的接口。然后，我们以表格形式，易于理解的格式总结了Gym环境的`step()`方法返回的四个值，来*加深*你对它们含义的理解！
- en: We also explored in detail the various types of spaces used in the Gym for the
    observation and action spaces, and we used a script to print out what spaces are
    used by an environment to understand the Gym environment interfaces better. In
    our next chapter, we will consolidate all our learning so far to develop our first
    artificially intelligent agent! Excited?! Flip the page to the next chapter now!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还详细探索了在Gym中用于观察和动作空间的各种空间类型，并使用脚本打印出环境使用的空间，以更好地理解Gym环境接口。在下一章中，我们将整合到目前为止的所有学习，来开发我们的第一个人工智能代理！激动吗？！赶快翻到下一章吧！
