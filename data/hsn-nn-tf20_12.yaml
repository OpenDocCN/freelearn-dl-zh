- en: Generative Adversarial Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: In this chapter, **Generative Adversarial Networks** (**GANs**) and the adversarial
    training process will be presented. In the first section, we will go over a theoretical
    overview of the GAN framework, while highlighting the strengths of the adversarial
    training process and the flexibility that was introduced by using neural networks
    as the model of choice for creating GANs. The theoretical part will give you an
    intuitive idea about which part of the GAN value function is being optimized during
    the adversarial training process and show you why the non-saturating value function
    should be used instead of the original one.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍**生成对抗网络**（**GANs**）及对抗训练过程。在第一部分，我们将概述 GAN 框架的理论内容，同时强调对抗训练过程的优势以及使用神经网络作为创建
    GAN 的模型所带来的灵活性。理论部分将为你提供一个直观的了解，帮助你理解在对抗训练过程中 GAN 的哪些部分被优化，并展示为什么应使用非饱和值函数，而不是原始的值函数。
- en: We will then go through a step-by-step implementation of GAN models and their
    training, with a visual explanation of what happens during this process. You will
    become familiar with the concept of target and learned distributions, which happens
    by watching the model learn.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过一步步实现 GAN 模型及其训练，并用视觉方式解释这个过程中发生的事情。通过观察模型的学习过程，你将熟悉目标分布和学习分布的概念。
- en: The natural extension of the GAN framework to the conditional version is presented
    in the second part of this chapter, and how to create a conditional image generator
    will be shown. This chapter, just like the previous ones, will end with an exercise
    section that you are encouraged not to skip.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章第二部分将介绍 GAN 框架向条件版本的自然扩展，并展示如何创建条件图像生成器。本章与之前的章节一样，最后将会有一个练习部分，鼓励大家不要跳过。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding GANs and their applications
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 GAN 及其应用
- en: Unconditional GANs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无条件 GAN
- en: Conditional GANs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条件 GAN
- en: Understanding GANs and their applications
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 GAN 及其应用
- en: Introduced in 2014 by *Ian Goodfellow et a*l. in the paper *Generative Adversarial
    Networks*, GANs have revolutionized the field of generative models, opening the
    road to incredible applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 由*Ian Goodfellow 等人*在 2014 年提出的论文《生成对抗网络》（*Generative Adversarial Networks*）中，GANs
    彻底改变了生成模型的领域，为令人惊叹的应用铺平了道路。
- en: GANs are frameworks that are used for the estimation of generative models via
    an adversarial process in which two models, the Generator and the Discriminator,
    are trained simultaneously.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 是通过对抗过程估计生成模型的框架，其中两个模型，生成器和判别器，进行同时训练。
- en: 'The goal of the generative model (Generator) is to capture the data distribution
    contained in the training set, while the discriminative model acts as a binary
    classifier. Its goal is to estimate the probability of a sample to come from the
    training data rather than from the Generator. In the following diagram, the general
    architecture of adversarial training is shown:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型（生成器，Generator）的目标是捕捉训练集中包含的数据分布，而判别模型则充当二分类器。它的目标是估计一个样本来自训练数据的概率，而不是来自生成器。在下面的图示中，展示了对抗训练的总体架构：
- en: '![](img/fba6a37e-b988-4e77-8349-1136b7967d6e.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fba6a37e-b988-4e77-8349-1136b7967d6e.png)'
- en: Graphical representation of the adversarial training process. The generator
    goal is used to fool the Discriminator by learning to generate samples that are
    more and more similar to the training set. (Image source: [https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/](https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/)—by
    Thalles Silva)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗训练过程的图形化表示。生成器的目标是通过学习生成越来越像训练集的样本来欺骗判别器。（图像来源：[https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/](https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/)—Thalles
    Silva）
- en: The idea is to train a generative model without explicitly defining a loss function.
    Instead, we use a signal coming from another network as feedback. The Generator's
    aim is to fool the Discriminator, while the Discriminator's aim is to correctly
    classify whether the input samples are real or fake. The power of adversarial
    training comes from the fact that both the Generator and the Discriminator can
    be non-linear, parametric models such as neural networks. It is therefore possible
    to use gradient descent to train them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是训练一个生成模型，而无需明确定义损失函数。相反，我们使用来自另一个网络的信号作为反馈。生成器的目标是愚弄判别器，而判别器的目标是正确分类输入样本是真实的还是虚假的。对抗训练的强大之处在于，生成器和判别器都可以是非线性、参数化的模型，例如神经网络。因此，可以使用梯度下降法来训练它们。
- en: To learn about generator distribution over the data, the generator builds a *mapping*
    from a **prior noise distribution**, ![](img/d91fb882-7ced-4adc-8bdb-288dc00f1560.png), to
    a data space ![](img/3471d5f4-6777-44d6-a144-c7ee3752541a.png).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习生成器在数据上的分布，生成器从**先验噪声分布**，![](img/d91fb882-7ced-4adc-8bdb-288dc00f1560.png)，到数据空间的映射，*映射*。
- en: The Discriminator, ![](img/0928f736-02e1-4807-a547-532c511468a9.png), is a function
    (neural network) that outputs a single scalar representing the probability that
    ![](img/84ccb37f-c4bc-4a14-93a7-e97a3c82eb2a.png) came from the real data distribution
    rather than ![](img/334013b8-4a01-4e39-b5ae-946dacf66adf.png).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器，![](img/0928f736-02e1-4807-a547-532c511468a9.png)，是一个函数（神经网络），其输出一个标量，表示![](img/84ccb37f-c4bc-4a14-93a7-e97a3c82eb2a.png)来自真实数据分布的概率，而不是来自![](img/334013b8-4a01-4e39-b5ae-946dacf66adf.png)。
- en: The original GAN framework is expressed by using a game-theory approach to the
    problem and poses it as a min-max game in which two players, the Generator and
    the Discriminator, compete against each other.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的GAN框架通过使用博弈论方法来表达问题，并将其作为一个最小-最大博弈，其中两个玩家——生成器和判别器——相互竞争。
- en: Value function
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 价值函数
- en: 'The value function is a mathematical way of representing the goals of the players
    in terms of expected returns. The GAN game is expressed by the following value
    function:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 价值函数是以期望回报的形式表示玩家目标的数学方法。GAN博弈通过以下价值函数来表示：
- en: '![](img/d3613a64-5f05-4433-9fe0-a6c87efcc08e.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3613a64-5f05-4433-9fe0-a6c87efcc08e.png)'
- en: This value function represents the game that the two players are playing, along
    with their respective long-term goals.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个价值函数表示了两个玩家所进行的博弈，以及他们各自的长期目标。
- en: The Discriminator's goal is to correctly classify the real and fake samples,
    and this goal is expressed as the **maximization** of both the ![](img/19a63dae-6136-4f21-ac4c-f4b38a1c29b7.png) and ![](img/a1aa6880-eb9b-4525-8622-68a508d897fd.png) terms.
    The former represents the correct classification of the samples coming from the
    real data distribution (therefore, the goal is to get ![](img/e83ace9e-d8be-4a3f-8c7c-b668fd0dad27.png)),
    while the latter is the correct classification of fake samples (and in this case,
    the goal is to get ![](img/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的目标是正确分类真实和虚假样本，这一目标通过最大化![](img/19a63dae-6136-4f21-ac4c-f4b38a1c29b7.png)和![](img/a1aa6880-eb9b-4525-8622-68a508d897fd.png)两项来表示。前者代表正确分类来自真实数据分布的样本（因此，目标是得到![](img/e83ace9e-d8be-4a3f-8c7c-b668fd0dad27.png)），而后者代表正确分类虚假样本（在这种情况下，目标是得到![](img/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png)）。
- en: The generator, on the other hand, is trained to fool the Discriminator, and
    its goal is to **minimize** ![](img/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png).
    The way you minimize this term is by producing samples that are more and more
    similar to the real ones, thereby trying to fool the Discriminator.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，生成器的目标是愚弄判别器，它的目标是**最小化**![](img/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png)。你可以通过生成与真实样本越来越相似的样本来最小化这一项，从而试图愚弄判别器。
- en: A subtlety worth noting is that the min-max game is played only in the second
    term of the value function since, in the first term, only the Discriminator plays.
    It does this by learning to correctly classify the data coming from the real data
    distribution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一点是，最小-最大博弈仅在价值函数的第二项中进行，因为在第一项中，只有判别器在参与。它通过学习正确分类来自真实数据分布的数据来实现这一点。
- en: Although clear and pretty easy to understand, this formulation has a practical
    disadvantage. In the early training steps, the Discriminator can easily learn
    how to correctly classify fake data by maximizing ![](img/a1aa6880-eb9b-4525-8622-68a508d897fd.png) because
    the generated samples are too different from the real ones. Since learning from
    the quality of the generated samples is poor, the Discriminator can reject samples
    with high confidence because they are clearly different from the training data.
    This rejection consists of classing the correct classification of the generated
    samples as fake (![](img/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png)), making the
    term ![](img/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png) saturate. It follows that
    the previous equation may not provide a sufficient gradient for *G* to learn well.
    The solution to this practical problem is the definition of a new value function
    that does not saturate.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种公式清晰且相当容易理解，但它有一个实际的缺点。在训练的早期阶段，判别器可以通过最大化![](img/a1aa6880-eb9b-4525-8622-68a508d897fd.png)轻松学会如何正确分类假数据，因为生成的样本与真实样本差异太大。由于从生成样本的质量学习较差，判别器可以以较高的置信度拒绝这些样本，因为它们与训练数据明显不同。这种拒绝表现为将生成样本的正确分类标为假(![](img/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png))，使得项![](img/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png)饱和。因此，之前的公式可能无法为*G*提供足够的梯度以良好地进行学习。解决这一实际问题的方法是定义一个不饱和的新价值函数。
- en: Non-saturating value function
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非饱和价值函数
- en: The proposed solution is to train *G* to **maximize** ![](img/ec6f3dc9-5b0c-45ca-ad62-cdeb1404156e.png) instead
    of minimizing ![](img/30b90557-a9fe-474e-a64d-b6908d6af3d4.png). Intuitively,
    we can see the proposed solution as a way of playing the same min-max game in
    a different manner.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的解决方案是训练*G*以**最大化**![](img/ec6f3dc9-5b0c-45ca-ad62-cdeb1404156e.png)，而不是最小化![](img/30b90557-a9fe-474e-a64d-b6908d6af3d4.png)。直观地看，我们可以将提出的解决方案视为以不同方式进行相同的最小-最大游戏。
- en: The Discriminator's goal is to maximize the probability of correctly classifying
    the real and fake samples, with no changes with respect to the previous formulation.
    The Generator's goal, on the other hand, is to minimize the Discriminator's probability
    of correctly classifying the generated samples as fake but to explicitly fool
    the Discriminator by making it classify the fake samples as real.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的目标是最大化正确分类真实样本和假样本的概率，与之前的公式没有变化。另一方面，生成器的目标是最小化判别器正确分类生成样本为假的概率，但要通过使判别器将假样本分类为真实的方式显式地欺骗判别器。
- en: 'The value function of the same game, which is played in a different manner
    by the two players, can be expressed as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 同一游戏的价值函数，由两名玩家以不同方式进行游戏，可以表示如下：
- en: '![](img/162c9bb9-438c-4a07-bd81-08ffc92c02a4.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/162c9bb9-438c-4a07-bd81-08ffc92c02a4.png)'
- en: As we stated previously, the power of the adversarial training frameworks comes
    from the fact that both *G* and *D* can be neural networks and that they can both
    be trained via gradient descent.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，敌对训练框架的力量来自于*G*和*D*都可以是神经网络，并且它们都可以通过梯度下降进行训练。
- en: Model definition and training phase
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型定义和训练阶段
- en: Defining the Generator and the Discriminator as neural networks allows us to
    tackle the problem using all the neural network architectures that have been developed
    over the years, with each one specialized to work with a certain data type.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成器和判别器定义为神经网络，使我们能够利用多年来开发的所有神经网络架构来解决问题，每种架构都专门用于处理某种数据类型。
- en: 'There are no constraints in the model''s definition; in fact, it is possible
    to define their architecture in a completely arbitrary manner. The only constraints
    are given by the structure of the data we are working on; the architectures depend
    on the data type, all of which are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的定义没有约束；事实上，可以以完全任意的方式定义其架构。唯一的约束是由我们所处理的数据的结构决定的；架构取决于数据类型，所有类型如下：
- en: '**Images**: Convolutional neural networks'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：卷积神经网络'
- en: '**Sequences, Text**: Recurrent neural networks'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列、文本**：递归神经网络'
- en: '**Numerical, Categorical values**: Fully connected networks'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值、类别值**：全连接网络'
- en: Once we've defined the model's architecture as a function of the data type,
    it is possible to use them to play the min-max game.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们根据数据类型定义了模型的架构，就可以使用它们来进行最小-最大游戏。
- en: 'Adversarial training consists of alternating the execution of training steps.
    Every training step is a player action, and the Generator and Discriminator compete
    against each other in turn. The game follows the following rules:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗训练包括交替执行训练步骤。每个训练步骤都是一个玩家动作，生成器和判别器交替进行对抗。游戏遵循以下规则：
- en: '**Discriminator**: The Discriminator plays first and can repeat the following
    three steps from 1 to *k* times, where *k* is a hyperparameter (often, *k* equals
    1):'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器**：判别器首先进行操作，可以将以下三个步骤重复执行1到*k*次，其中*k*是超参数（通常*k*等于1）：'
- en: Sample a minibatch of *m* noise samples, ![](img/8c7a168d-8b67-487c-a89b-caac740d62f9.png), from
    the noise prior to ![](img/ab6c44ac-0ebc-4771-9cd5-8bd7ae76b1da.png)
  id: totrans-41
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从噪声分布中采样一个* m *噪声样本的迷你批量，![](img/8c7a168d-8b67-487c-a89b-caac740d62f9.png)，来自噪声先验的![](img/ab6c44ac-0ebc-4771-9cd5-8bd7ae76b1da.png)
- en: Sample a minibatch of *m* samples, ![](img/d26d6ddc-669a-47fd-b298-b7464f068ece.png), from
    the real data distribution, ![](img/12e80660-9f99-4caf-abe9-f848567808e5.png)
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从真实数据分布中采样一个* m *样本的迷你批量，![](img/d26d6ddc-669a-47fd-b298-b7464f068ece.png)，来自真实数据分布的![](img/12e80660-9f99-4caf-abe9-f848567808e5.png)
- en: 'Train the Discriminator via stochastic gradient ascent: **![](img/e43e40a8-c222-4ba9-9f07-0009b1325e5a.png)**'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过随机梯度上升训练判别器：**![](img/e43e40a8-c222-4ba9-9f07-0009b1325e5a.png)**
- en: Here, ![](img/5a54844b-6ec5-4e7e-92cd-686cfec824fd.png) is the Discriminator's
    parameters
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/5a54844b-6ec5-4e7e-92cd-686cfec824fd.png)是判别器的参数
- en: '**Generator**: The Generator always plays after the Discriminator''s turn,
    and it plays only once:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器**：生成器始终在判别器操作之后进行，并且每次仅执行一次：'
- en: Sample a minibatch of *m* noise samples, ![](img/6f6acbf8-4fcc-4154-a9bc-ee1c64d5b85b.png), from
    the noise prior to ![](img/e4c37a82-c37a-46d9-aad3-aed8b32e47b1.png)
  id: totrans-46
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从噪声分布中采样一个* m *噪声样本的迷你批量，![](img/6f6acbf8-4fcc-4154-a9bc-ee1c64d5b85b.png)，来自噪声先验的![](img/e4c37a82-c37a-46d9-aad3-aed8b32e47b1.png)
- en: 'Train the Generator via stochastic gradient ascent (this is a maximization
    problem since the game is targeted the non-saturating value function):'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过随机梯度上升训练生成器（这是一个最大化问题，因为游戏的目标是非饱和值函数）：
- en: '![](img/7042fc2f-3c83-4eab-9725-72b756c3d182.png)'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/7042fc2f-3c83-4eab-9725-72b756c3d182.png)'
- en: Here, ![](img/da88d371-aa89-428a-88c7-ccd6fe0b3780.png) is the Generator's parameters
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/da88d371-aa89-428a-88c7-ccd6fe0b3780.png)是生成器的参数
- en: Just like any other neural network that's trained via gradient descent, the
    updates can use any standard optimization algorithm (Adam, SGD, SGD with Momentum,
    and so on). The game should go on until the Discriminator isn't completely fooled
    by the Generator, that is, when the Discriminator always predicts a probability
    of 0.5 for every input sample. The value of 0.5 may sound strange, but intuitively,
    this means that the Generator is now able to generate samples that are similar
    to the real ones and the Discriminator can now only make random guesses.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何通过梯度下降训练的神经网络一样，更新可以使用任何标准优化算法（Adam，SGD，带动量的SGD等）。游戏应该持续，直到判别器不再完全被生成器欺骗，也就是说，当判别器对每个输入样本的预测概率总是为0.5时。0.5的值可能听起来很奇怪，但直观地说，这意味着生成器现在能够生成与真实样本相似的样本，而判别器只能做随机猜测。
- en: Applications of GANs
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GANs的应用
- en: At first glance, Generative models have a limited utility. What is the purpose
    of having a model that generates something similar to what we already have (the
    real sample dataset)?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，生成模型的效用有限。拥有一个生成与我们已有的（真实样本数据集）相似的模型有什么意义？
- en: In practice, learning from a data distribution is extremely useful in the anomaly
    detection domain and in "human-only" fields such as art, painting, and music generation.
    Moreover, the applications of GANs in their conditional formulation are astonishing
    and used to create applications with a great market value (see the *Conditional
    GANs* section of this chapter for more information).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，从数据分布中学习在异常检测领域非常有用，并且在“仅限人类”的领域（如艺术、绘画和音乐生成）中也有重要应用。此外，GANs在其条件形式中的应用令人惊讶，被广泛用于创造具有巨大市场价值的应用程序（更多信息请参阅本章的*条件GANs*部分）。
- en: 'With GANs, it is possible to make a machine generate extremely realistic faces,
    starting from random noise. The following image shows applying GAN to the face
    generation problem. These results were obtained in the paper titled *Progressive
    Growing of GANs for Improved Quality, Stability, and Variation* (T. Karras et
    al. 2017, NVIDIA):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GANs，可以让机器从随机噪声开始生成极其逼真的面孔。以下图像展示了将GAN应用于面部生成问题。这些结果来源于论文《*Progressive Growing
    of GANs for Improved Quality, Stability, and Variation*》（T. Karras等，2017，NVIDIA）：
- en: '![](img/59076122-b87b-4fd7-8c15-03c3de5b7f29.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59076122-b87b-4fd7-8c15-03c3de5b7f29.jpg)'
- en: These people do not exist. Every image, although super realistic, is GAN generated.
    You can try this out for yourself by going to [https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/) (Image
    source, the paper titled *Progressive Growing of GANs for Improved Quality, Stability,
    and Variation*).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些人并不存在。每一张图片，尽管超逼真，都是通过生成对抗网络（GAN）生成的。你可以亲自尝试，通过访问[https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/)来体验一下。（图片来源，论文标题为*Progressive
    Growing of GANs for Improved Quality, Stability, and Variation*）。
- en: Another astonishing application from before GANs were introduced that was practically
    impossible to achieve was domain translation, which is where you use a GAN to
    go from one domain to another, for example, from sketches to a realistic image
    or from an aerial view to a map.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在GAN出现之前，另一个几乎不可能实现的惊人应用是领域转换，指的是你使用GAN从一个领域转换到另一个领域，例如，从素描转换到真实图像，或从鸟瞰图转换为地图。
- en: 'The following image, which was retrieved from the paper *Image-to-Image Translation
    with Conditional Adversarial Networks* (Isola et al., 2017) shows how (conditional)
    GANs are able to solve tasks that were considered impossible only some years ago:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下图来自论文*Image-to-Image Translation with Conditional Adversarial Networks*（Isola等，2017），展示了条件GAN如何解决几年前被认为不可能完成的任务：
- en: '![](img/15b3d462-f535-4de8-b74e-8b735b20c47b.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15b3d462-f535-4de8-b74e-8b735b20c47b.jpg)'
- en: GANs allow you to solve the domain translation problem. Colorizing a black and
    white image or generating photos only from sketches is now possible. Image source:*Image-to-Image
    Translation with Conditional Adversarial Networks* (Isola et al., 2017).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: GAN使得解决领域转换问题成为可能。现在，给黑白图像上色或仅通过素描生成照片变得可行。图片来源：*Image-to-Image Translation
    with Conditional Adversarial Networks*（Isola等，2017）。
- en: GAN applications are astonishing and their practical applications are always
    being discovered. Starting from the next section, we'll learn how to implement
    some of them in pure TensorFlow 2.0.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的应用令人惊叹，其实际应用也在不断被发现。从下一部分开始，我们将学习如何在纯TensorFlow 2.0中实现其中的一些应用。
- en: Unconditional GANs
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无条件GAN
- en: 'It isn''t common to see GANs mentioned as unconditional since this is the default
    and original configuration. In this book, however, we decided to stress this characteristic
    of the original GAN formulation in order to make you aware of the two main GAN
    classifications:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 看到GAN被提到为无条件的并不常见，因为这是默认的原始配置。然而，在本书中，我们决定强调原始GAN公式的这一特性，以便让你意识到GAN的两大主要分类：
- en: Unconditional GANs
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无条件GAN
- en: Conditional GANs
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条件GAN
- en: The generative model that we described in the previous section falls under the
    category of unconditional GANs. The generative model is trained to capture the
    training data distribution and to generate samples that have been randomly sampled
    from the captured distribution. The conditional configuration is a slightly modified
    version of the framework and is presented in the next section.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一部分描述的生成模型属于无条件GAN类别。该生成模型训练的目标是捕捉训练数据分布，并生成从捕捉的分布中随机抽样的样本。条件配置是该框架的略微修改版本，并将在下一部分介绍。
- en: Thanks to TensorFlow 2.0's eager-by-default style, the implementation of adversarial
    training is straightforward. In practice, to implement the adversarial training
    loop as described in the Goodfellow et al. paper (*Generative Adversarial Networks)*,
    it is required to implement it as it is defined, line by line. Of course, the
    best way to create a custom training loop that requires the alternate training
    steps of two different models is not to use Keras, but to implement it manually.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于TensorFlow 2.0的默认即时执行风格，实施对抗训练变得非常简单。实际上，为了实现Goodfellow等人论文中描述的对抗训练循环（*Generative
    Adversarial Networks*），需要逐行按原样实现。当然，创建一个自定义训练循环，特别是需要交替训练两个不同模型的步骤时，最好的方法不是使用Keras，而是手动实现。
- en: Just like in any other machine learning problem, we have to start with the data.
    In this section, we will define a generative model, with the goal of learning
    about the random normal data distribution, centered at 10 and with a small standard
    deviation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何其他机器学习问题一样，我们必须从数据开始。在这一部分，我们将定义一个生成模型，目的是学习关于以10为中心、标准差较小的随机正态数据分布。
- en: Preparing the data
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'Since the goal of this section is to learn about data distribution, we will
    start from the foundations in order to build a strong intuition of the adversarial
    training process. The most simple and the easiest way to visualize data distribution
    is by looking at the random normal distribution. We can, therefore, pick a Gaussian
    (or normal) centered at 10 and with a standard deviation of 0.1 as our target
    data distribution:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本节的目标是学习数据分布，我们将从基础开始，以便建立对对抗训练过程的直觉。最简单且最容易的方式是通过查看随机正态分布来可视化数据分布。因此，我们可以选择一个均值为10，标准差为0.1的高斯（或正态）分布作为我们的目标数据分布：
- en: '![](img/e95a6682-606a-49cd-b738-469c61356163.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e95a6682-606a-49cd-b738-469c61356163.png)'
- en: 'Thanks to the eager execution process, we can use TensorFlow 2.0 itself to
    sample a value from the target distribution. We do this by using the `tf.random.normal`
    function. The following code snippet shows a function that samples (2,000) data
    points from the target distribution:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于即时执行过程，我们可以使用 TensorFlow 2.0 本身从目标分布中采样一个值。我们通过使用 `tf.random.normal` 函数来做到这一点。以下代码片段展示了一个函数，该函数从目标分布中采样（2000）个数据点：
- en: '`(tf2)`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To have a better understanding of what a GAN can learn, and of what happens
    during the adversarial training itself, we use `matplotlib` to visualize the data
    on a histogram:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解GAN能学到什么，以及在对抗训练过程中发生了什么，我们使用 `matplotlib` 来将数据可视化成直方图：
- en: '`(tf2)`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This displays the target distribution that''s shown in the following image.
    As expected, if we have a small standard deviation, the histogram peaks at the
    mean value:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了目标分布，如下图所示。如预期的那样，如果标准差较小，直方图将在均值处达到峰值：
- en: '![](img/3addb3b9-567b-43ac-b27a-7a7fc3340faa.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3addb3b9-567b-43ac-b27a-7a7fc3340faa.png)'
- en: The histogram of the target distribution – 5,000 data points sampled from a
    Gaussian distribution with a mean of 10 and a stddev of 0.1
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 目标分布的直方图——从一个均值为10，标准差为0.1的高斯分布中采样的5000个数据点
- en: Now that we've defined the target data distribution and we have a function that
    samples from it (`sample_dataset`), we are ready to define the Generator and Discriminator
    networks.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了目标数据分布，并且有了一个从中采样的函数（`sample_dataset`），我们准备好定义生成器和判别器网络了。
- en: As we stated at the beginning of this chapter, the power of the adversarial
    training process is that both the Generator and the Discriminator can be neural
    networks, and the models can be trained using gradient descent.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头所述，对抗训练过程的力量在于生成器和判别器都可以是神经网络，并且模型可以使用梯度下降法进行训练。
- en: Defining the Generator
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义生成器
- en: The Generator's goal is to behave like the target distribution. For this reason,
    we have to define it as a network with a single neuron. We can sample one number
    at a time from the target distribution, and the same should be possible from the
    Generator.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的目标是表现得像目标分布。因此，我们必须将其定义为一个具有单个神经元的网络。我们可以从目标分布中每次采样一个数字，生成器也应该能够做到这一点。
- en: There is no guideline or constraint for the model architecture definition. The
    only restrictions are given from the nature of the problem, and these are the
    input and output dimensions. The output dimension, as we explained previously,
    depends on the target distribution, while the input dimension is the arbitrary
    dimension of the noise prior, which is often set to 100.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 模型架构定义没有明确的指导原则或约束条件。唯一的限制来自于问题的性质，这些限制体现在输入和输出的维度。输出维度，如前所述，取决于目标分布，而输入维度是噪声先验的任意维度，通常设置为100。
- en: 'To solve this problem, we are going to define a simple three-layer neural network,
    with two hidden layers with 64 neurons each:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们将定义一个简单的三层神经网络，包含两个隐藏层，每个层有64个神经元：
- en: '`(tf2)`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `generator` function returns a Keras model. The Keras functional API has
    been used to define the model, although a Sequential was enough.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`generator` 函数返回一个 Keras 模型。虽然只用一个 Sequential 模型也足够，但我们使用了 Keras 函数式 API 来定义该模型。'
- en: Defining the Discriminator
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义判别器
- en: Just like the Generator, the Discriminator architecture depends on the target
    distribution. The goal is to classify samples into two categories. The input layer,
    therefore, depends on the size of the samples that have been sampled from the
    target distribution; in our case, it is one. The output layer is a single linear
    neuron that's used to classify the sample into two categories.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 就像生成器一样，判别器的架构依赖于目标分布。目标是将样本分类为两类。因此，输入层依赖于从目标分布中采样的样本的大小；在我们的案例中，它是 1。输出层是一个单独的线性神经元，用于将样本分类为两类。
- en: 'The activation function is linear because the Keras loss function applies the
    sigmoid:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数是线性的，因为 Keras 的损失函数应用了 sigmoid：
- en: '`(tf2)`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'After defining the Generator and Discriminator architecture, we only have to
    instantiate the Keras models by specifying the correct input shapes:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 定义生成器和判别器架构之后，我们只需通过指定正确的输入形状来实例化 Keras 模型：
- en: '`(tf2)`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The models and the target data distribution have been defined; the only thing
    that's missing is expressing the relationships between them, which is done by
    defining the loss functions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 模型和目标数据分布已经定义；唯一缺少的就是表达它们之间的关系，这通过定义损失函数来完成。
- en: Defining the loss functions
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义损失函数
- en: 'As shown in the previous section, the Discriminator''s output is linear because
    the `loss` function we are going to use applies the nonlinearity for us. To implement
    the adversarial training process by following the original formulation, the `loss`
    function to use is binary cross-entropy:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，判别器的输出是线性的，因为我们将要使用的 `loss` 函数为我们应用了非线性。为了按照原始公式实现对抗训练过程，使用的 `loss` 函数是二进制交叉熵：
- en: '`(tf2)`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `bce` object is used to compute the binary cross-entropy between two distributions:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`bce` 对象用于计算两个分布之间的二进制交叉熵：'
- en: The learned distribution, which is represented by the Discriminator's output,
    is squashed into the [0,1] range (by applying it the sigmoid ![](img/6a8ca1bf-50ed-4882-a26a-b442cf60f361.png) function,
    since the `from_logits` parameter is set to `True`). This produces a value closer
    to one if the Discriminator classifies the input as coming from the real data
    distribution.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学到的分布，由判别器的输出表示，通过应用 sigmoid ![](img/6a8ca1bf-50ed-4882-a26a-b442cf60f361.png)函数将其压缩到
    [0,1] 范围内，因为 `from_logits` 参数被设置为 `True`。如果判别器将输入分类为来自真实数据分布，则该值会接近 1。
- en: The conditional empirical distribution over class labels, that is, a discrete
    probability distribution where the probability of it being a real sample, is labeled
    as 1 and is 0 otherwise.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条件经验分布在类别标签上，即一个离散的概率分布，其中真实样本的概率被标记为1，其他情况下为0。
- en: 'Mathematically, the binary cross-entropy between the conditional empirical
    distribution over class labels (![](img/7ce7c2cd-5b7a-4df6-9de3-9b7a0b6a1c1f.png))
    and the generator output squashed in [0,1] (![](img/47650b3e-1949-4757-99e5-f10970d72bcf.png))
    is expressed as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 数学上，条件经验分布与生成器输出（压缩到 [0,1]）之间的二进制交叉熵表示如下：
- en: '![](img/74737ade-b438-4b83-bbc1-336c6f8297fb.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/74737ade-b438-4b83-bbc1-336c6f8297fb.png)'
- en: 'We want to train the Discriminator to correctly classify real and fake data:
    correctly classifying the real data can be seen as the maximization of ![](img/f4a69c26-6d2d-4d9d-acd3-19c9797b2aac.png), while
    the correct classification of the fake data is the maximization of ![](img/bd7a3ae6-9748-49ae-bee6-0430dc8d0b53.png).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望训练判别器正确分类真实和伪造数据：正确分类真实数据可以看作是最大化 ![](img/f4a69c26-6d2d-4d9d-acd3-19c9797b2aac.png)，而正确分类伪造数据是最大化 ![](img/bd7a3ae6-9748-49ae-bee6-0430dc8d0b53.png)。
- en: 'By replacing the expected value with the empirical mean over a batch of *m*
    samples, it is possible to express the maximization of the log probability of
    correctly classifying a sample as the sum of two BCEs:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将期望值替换为批次中 *m* 个样本的经验均值，可以将正确分类一个样本的对数概率的最大化表示为两个 BCE 的和：
- en: '![](img/decb28ca-6b2f-450b-a5a4-6503df00be02.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/decb28ca-6b2f-450b-a5a4-6503df00be02.png)'
- en: The first term is the BCE between the label ![](img/538f700e-e62b-4f8a-a414-9eebc0e3b525.png) and
    the Discriminator output when given a real sample as input, while the second term
    is the BCE between the label ![](img/43bf107b-e712-4374-97ac-33403ff44bc0.png) and
    the Discriminator output when given a fake sample as input.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 第一项是标签 ![](img/538f700e-e62b-4f8a-a414-9eebc0e3b525.png) 在给定真实样本作为输入时的判别器输出之间的
    BCE，而第二项是标签 ![](img/43bf107b-e712-4374-97ac-33403ff44bc0.png) 在给定假样本作为输入时的判别器输出之间的
    BCE。
- en: 'Implementing this loss function in TensorFlow is straightforward:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中实现这个损失函数非常简单：
- en: '`(tf2)`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The same `bce` object we created previously is used inside the `d_loss` function
    since it is a stateless object that only computes the binary cross-entropy between
    its inputs.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前创建的同一 `bce` 对象在 `d_loss` 函数中使用，因为它是一个无状态对象，仅计算其输入之间的二元交叉熵。
- en: Please note that there is no need to add a minus sign in front of the `bce`
    invocations to maximize them; the mathematical formulation of the BCE already
    contains the minus sign.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在最大化它们的 `bce` 调用中不需要添加减号；二元交叉熵的数学公式已经包含减号。
- en: 'The generator loss function follows on from this theory. Implementing the non-saturating
    value function only consists of the TensorFlow implementation of the following
    formula:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器损失函数遵循这一理论。仅实施非饱和值函数包括 TensorFlow 实现以下公式：
- en: '![](img/3c6fa83f-45fe-48eb-a1e1-3121fc5cb745.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c6fa83f-45fe-48eb-a1e1-3121fc5cb745.png)'
- en: This formula is the binary cross-entropy between the log probability of the
    generated images and the distribution of the real images (labeled with 1). In
    practice, we want to maximize the log probability of the generated samples, updating
    the Generator parameters in order to make the Discriminator classify them as real
    (label 1).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该公式是生成图像的对数概率与真实图像的分布（标记为 1）之间的二元交叉熵。在实践中，我们希望最大化生成样本的对数概率，更新生成器参数以使判别器将其分类为真实（标签
    1）。
- en: 'The TensorFlow implementation is trivial:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 实现非常简单：
- en: '`(tf2)`'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Everything is set up to implement the adversarial training process.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都准备好实施对抗训练过程。
- en: Adversarial training process in unconditional GANs
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无条件 GAN 中的对抗训练过程
- en: As we explained at the beginning of this chapter, the adversarial training process
    is where we alternate the execution of the training steps for the Discriminator
    and Generator. The Generator requires the value that's computed by the Discriminator
    to perform its parameter update, while the Discriminator requires the generated
    samples (also known as fake input) and the real samples.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在本章开头解释的那样，对抗训练过程是我们交替执行判别器和生成器的训练步骤的过程。生成器需要通过判别器计算的值来执行其参数更新，而判别器需要生成的样本（也称为假输入）和真实样本。
- en: TensorFlow allows us to define a custom training loop easily. The `tf.GradientTape`
    object, in particular, is extremely useful for computing the gradient of a specific
    model, even when there are two models interacting. In fact, thanks to the `trainable_variables` property
    of every Keras model, it is possible to compute the gradient of a certain function,
    but only with respect to these variables.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 允许我们轻松定义自定义训练循环。特别是 `tf.GradientTape` 对象非常有用，用于计算特定模型的梯度，即使存在两个相互作用的模型。实际上，由于每个
    Keras 模型的 `trainable_variables` 属性，可以计算某个函数的梯度，但只针对这些变量。
- en: 'The training process is exactly like the one that''s described in the GAN paper (*Generative
    Adversarial Networks - Ian Goodfellow et al.)*, thanks to the eager mode. Moreover,
    since this training process can be computationally intensive (especially on big
    datasets where the data distribution that we want to capture is complex), it is
    worth decorating the training step function with `@tf.function` in order to speed
    up the computation by converting it into a graph:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程与 GAN 论文描述的过程完全相同（*生成对抗网络 - Ian Goodfellow 等人*），由于急切模式。此外，由于这个训练过程可能计算密集（特别是在我们希望捕获的数据分布复杂的大型数据集上），值得使用
    `@tf.function` 装饰训练步骤函数，以便通过将其转换为图形加快计算速度：
- en: '`(tf2)`'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In order to visualize what the Generator is learning during the training process,
    we plot the same graph values that were sampled from the target distribution (in
    orange), as well as the values that were sampled from the Generator (in blue):'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化生成器在训练过程中学习到的内容，我们绘制了从目标分布中采样的相同图形值（橙色），以及从生成器中采样的值（蓝色）：
- en: '`(tf2)`'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now that we've defined the whole training loop as a function, we can execute
    it by calling `train()`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将整个训练循环定义为一个函数，可以通过调用 `train()` 来执行它。
- en: The `train_step` function is the most important of the whole snippet since it
    contains the implementation of the adversarial training. A peculiarity that is
    worth highlighting is how, by using `trainable_variables`, it has been possible
    to compute the gradients of the loss function with respect to the model parameters
    we are interested in, while considering everything else constant.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_step` 函数是整个代码片段中最重要的部分，因为它包含了对抗训练的实现。值得强调的一个特点是，通过使用 `trainable_variables`，我们能够计算损失函数相对于我们感兴趣的模型参数的梯度，同时将其他所有因素保持不变。'
- en: The second peculiarity has been the usage of a persistent gradient tape object.
    Using a persistent tape allowed us to keep track of the execution while allocating
    a single object in memory (the tape) and using it twice. If the tape had been
    created non-persistently, we couldn't reuse it since it would be automatically
    destroyed after the first `.gradient` invocation.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个特点是使用了持久化的梯度带对象。使用持久化的带对象使我们能够在内存中分配一个单独的对象（即带对象），并且将其使用两次。如果带对象是非持久化创建的，我们就无法重用它，因为它会在第一次
    `.gradient` 调用后自动销毁。
- en: Instead of visualizing the data using TensorBoard (this is left as an exercise
    for you), we followed the matplotlib approach we've used so far and sampled 5,000
    data points every 200 training steps from both the target and the learned distributions,
    and then visualized them by plotting the corresponding histograms.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有使用 TensorBoard 来可视化数据（这个留给你做练习），而是遵循了到目前为止使用的 matplotlib 方法，并且每200步训练从目标分布和学习到的分布中分别采样5,000个数据点，然后通过绘制相应的直方图进行可视化。
- en: 'During the initial training steps, the learned distribution is different from
    the target one, as shown in the following graph:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练的初期阶段，学习到的分布与目标分布不同，如下图所示：
- en: '![](img/3c0953dc-73f8-4d9d-bc28-086ed9940865.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c0953dc-73f8-4d9d-bc28-086ed9940865.png)'
- en: Data visualization at the 2,600th training step. The target distribution is
    a random normal distribution with a mean of 10 and a standard deviation of 0.1\.
    The values that were sampled from the learned distribution are slowly shifting
    toward the target distribution.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2,600步训练时的数据可视化。目标分布是均值为10，标准差为0.1的随机正态分布。从学习到的分布中采样的值正在慢慢向目标分布移动。
- en: 'During the training phase, it is possible to appreciate how the Generator is
    learning to approximate the target distribution:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段，我们可以看到生成器如何学习逼近目标分布：
- en: '![](img/44a936c4-6db5-4e5b-981c-c0fe8d062daf.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44a936c4-6db5-4e5b-981c-c0fe8d062daf.png)'
- en: Data visualization at the 27,800th training step. The learned distribution is
    approaching the mean value of 10 and is reducing its variance.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在第27,800步训练时的数据可视化。学习到的分布正在接近均值10，并且正在减少其方差。
- en: 'In the late training stages, the two distributions almost completely overlap
    and the training process can be stopped:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练的后期阶段，两个分布几乎完全重合，训练过程可以停止：
- en: '![](img/1a6d82a3-cbfb-47a2-91a7-8b77ca46ce64.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a6d82a3-cbfb-47a2-91a7-8b77ca46ce64.png)'
- en: Data visualization at the 39,000th training step. The target distribution and
    the learned distribution overlap.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在第39,000步训练时的数据可视化。目标分布和学习到的分布重叠。
- en: Thanks to the expressive power of the Keras model and the ease of usage of the
    TensorFlow eager mode (plus the graph-conversion via `tf.function`), defining
    two models and training them by manually implementing the adversarial training
    process has been almost trivial.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了 Keras 模型的表达能力和 TensorFlow eager 模式的易用性（加上通过 `tf.function` 进行图转换），定义两个模型并手动实现对抗训练过程几乎变得微不足道。
- en: Although trivial, this is the very same training loop that we use when working
    with different data types. In fact, the same training loop can be used to train
    image, text, and even audio generators, except that we use different Generator
    and Discriminator architectures in those cases.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看似微不足道，这实际上是我们在处理不同数据类型时使用的相同训练循环。事实上，同样的训练循环可以用于训练图像、文本甚至音频生成器，唯一的区别是我们在这些情况下使用不同的生成器和判别器架构。
- en: A slightly modified version of the GAN framework allows you to collect a conditional
    generation of samples; for example, the Generator is trained to generate specific
    samples when given a condition.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 稍微修改过的 GAN 框架允许你收集条件生成的样本；例如，当给定条件时，生成器被训练生成特定的样本。
- en: Conditional GANs
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件生成对抗网络（Conditional GANs）
- en: Mirza et al. in their paper, *Conditional Generative Adversarial Nets*, introduced
    a conditional version of the GAN framework. This modification is extremely easy
    to understand and is the foundation of amazing GAN applications that are widely
    used in today's world.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Mirza 等人在他们的论文*条件生成对抗网络*中，提出了一种条件版本的GAN框架。这个修改非常容易理解，并且是今天广泛应用的惊人GAN应用的基础。
- en: Some of the most astonishing GAN applications, such as the generation of a street
    scene from a semantic label to the colorization of an image given a grayscale
    input, pass through image super-resolution as specialized versions of the conditional
    GAN idea.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最令人惊叹的GAN应用，例如通过语义标签生成街景，或者给定灰度输入对图像进行上色，作为条件GAN思想的专门版本，经过图像超分辨率处理。
- en: 'Conditional GANs are based on the idea that GANs can be extended to a conditional
    model if both G and D are conditioned on some additional information, *y*. This
    additional information can be any kind of additional information, from class labels
    to semantic maps, or data from other modalities. It is possible to perform this
    conditioning by feeding the additional information into both the Generator and
    the Discriminator as an additional input layer. The following diagram, which was
    taken from the *Conditional Generative Adversarial Nets* paper, clearly shows
    how the Generator and Discriminator models can be extended to support the conditioning:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 条件生成对抗网络基于这样的思想：如果生成器（G）和判别器（D）都根据某些附加信息进行条件化，那么GAN就可以扩展为条件模型，*y*。这些附加信息可以是任何形式的附加数据，从类别标签到语义图，或者来自其他模态的数据。通过将附加信息作为额外的输入层同时馈入生成器和判别器，可以实现这种条件化。下面的图示来自*条件生成对抗网络*论文，清楚地展示了生成器和判别器模型如何扩展以支持条件化：
- en: '![](img/c2f44c63-45d8-4591-972b-2f778dcecb59.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2f44c63-45d8-4591-972b-2f778dcecb59.png)'
- en: 'Conditional GANs. The Generator and the Discriminator have one additional input,
    y, which represents the auxiliary information that conditions the models (Image
    source: *Conditional Generative Adversarial Nets*, Mirza et al., 2014).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 条件生成对抗网络。生成器和判别器有一个附加的输入，y，表示条件化模型的辅助信息（图片来源：*条件生成对抗网络*，Mirza 等，2014）。
- en: The generator architecture is extended to combine the joint hidden representation
    of the noise prior to the condition. There are no constraints on how to feed the
    condition to the Generator network. You can simply concatenate the condition to
    the noise vector. Alternatively, if the condition is complex, you can encode it
    using a neural network and concatenate its output to one layer of the Generator.
    The same reasoning applies to the Discriminator.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器架构被扩展为将噪声的联合隐层表示与条件结合。没有关于如何将条件输入生成器网络的限制。你可以简单地将条件与噪声向量连接起来。或者，如果条件比较复杂，可以使用神经网络对其进行编码，并将其输出连接到生成器的某一层。判别器同样也可以采用相同的逻辑。
- en: 'Conditioning the models changes the value''s function since the data distributions
    that we sample from are now conditioned:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对模型进行条件化改变了值函数，因为我们从中采样的数据分布现在是条件化的：
- en: '![](img/398f42ea-5f04-438b-a766-c0ab7da52270.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/398f42ea-5f04-438b-a766-c0ab7da52270.png)'
- en: There are no other changes in regards to the adversarial training process, and
    the same considerations about the non-saturating value function still apply.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在对抗训练过程中没有其他变化，关于非饱和值函数的考虑仍然适用。
- en: In this section, we are going to implement a conditional Fashion-MNIST generator.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个条件的Fashion-MNIST生成器。
- en: Getting the data for a conditional GAN
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取条件生成对抗网络（GAN）数据
- en: 'By using TensorFlow Datasets, getting the data is straightforward. Since the
    goal is to create a Fashion-MNIST generator, we will use the class labels as a
    condition. The data that''s returned from the `tfds.load` call is in a dictionary
    format. Therefore, we need to define a function that maps the dictionary to a
    tuple that contains only the image and the corresponding label. In this phase,
    we can also prepare the whole data input pipeline:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用TensorFlow数据集，获取数据非常直接。由于目标是创建一个Fashion-MNIST生成器，我们将使用类别标签作为条件。从`tfds.load`调用返回的数据是字典格式。因此，我们需要定义一个函数，将字典映射到一个只包含图像和对应标签的元组。在这个阶段，我们还可以准备整个数据输入管道：
- en: '`(tf2)`'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE10]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Defining the Generator in a conditional GAN
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义条件生成对抗网络中的生成器
- en: 'Since we are working with images, the natural choice is to use a convolutional
    neural network. In particular, using the deconvolution operation we introduced
    in [Chapter 8](51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml), *Semantic Segmentation
    and Custom Dataset Builder*, it is possible to easily define a decoder-like network
    that generates images, starting from a latent representation and a condition:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们处理的是图像，天然的选择是使用卷积神经网络。特别是，使用我们在[第 8 章](51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml)中介绍的反卷积操作，*语义分割和自定义数据集构建器*，可以轻松定义一个类似解码器的网络，从潜在表示和条件开始生成图像：
- en: '`(tf2)`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE11]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Defining the Discriminator in a conditional GAN
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在条件 GAN 中定义判别器
- en: 'The Discriminator architecture is straightforward. A standard way of conditioning
    the Discriminator consists of concatenating the encoded representation of the
    image, with the encoded representation of the condition being placed in a unique
    vector. Doing this requires the definition of two subnetworks – the first one
    encodes the image in a feature vector, while the second one encodes the condition
    in another vector. The following code clarifies this concept:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器架构很简单。条件化判别器的标准方法是将图像的编码表示与条件的编码表示连接在一起，并将条件放置在一个独特的向量中。这样做需要定义两个子网络——第一个子网络将图像编码为特征向量，第二个子网络将条件编码为另一个向量。以下代码阐明了这个概念：
- en: '`(tf2)`'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE12]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After defining the encoder subnetwork that encoded the image into a feature
    vector, we are ready to create a hidden representation of the condition and concatenate
    it with the feature vector. After doing it, we can create the Keras model and
    return it:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了将图像编码为特征向量的编码子网络后，我们准备创建条件的隐藏表示并将其与特征向量连接起来。这样做后，我们可以创建 Keras 模型并返回它：
- en: '`(tf2)`'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE13]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Adversarial training process
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗训练过程
- en: 'The adversarial training process is the same as what we presented for the unconditional
    GAN. The `loss` functions are exactly the same:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗训练过程与我们为无条件 GAN 展示的过程相同。`loss` 函数完全相同：
- en: '`(tf2)`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE14]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The only difference is that our models now accept two input parameters.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是我们的模型现在接受两个输入参数。
- en: 'After deciding on the noise''s prior dimension and instantiated the G and D
    models, defining the train function requires a slight modification of the previous
    training loop. As for the unconditional GAN training loop definition, matplotlib
    has been used to log the images. Improving this script is left as an exercise
    for you to carry out:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定噪声的先验维度并实例化 G 和 D 模型之后，定义训练函数需要对之前的训练循环做一些微小的修改。至于无条件 GAN 的训练循环定义，matplotlib
    被用来记录图像。改进这个脚本的工作留给你去完成：
- en: '`(tf2)`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE15]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The training loop loops over the training set for 10 epochs and displays an
    image of a generated Fashion-MNIST element, along with its label. After a few
    epochs, the generated images become more and more realistic and they start matching
    the label, as shown in the following screenshot:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环遍历训练集 10 个周期，并显示一个生成的 Fashion-MNIST 元素图像及其标签。在几个周期后，生成的图像变得越来越逼真，并开始与标签匹配，如下图所示：
- en: '![](img/3cf10f11-0a41-45fa-938c-710062e95f9a.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3cf10f11-0a41-45fa-938c-710062e95f9a.png)'
- en: A generated sample feeding in input to the Generator's random noise and the
    condition T-shirt/top
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的样本将输入随机噪声和条件 T 恤/上衣馈送给生成器。
- en: Summary
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at GANs and the adversarial training process. In
    the first section, a theoretical explanation of the adversarial training process
    was presented, with a focus on the value function, which is used to formulate
    the problem as a min-max game. We also showed how the non-saturating value function
    is, in practice, the solution to making the Generator learn how to solve the saturation
    problem.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了 GAN 和对抗训练过程。在第一部分中，介绍了对抗训练过程的理论解释，重点讨论了值函数，它用于将问题表述为一个最小-最大博弈。我们还展示了如何通过非饱和值函数，在实践中解决生成器如何解决饱和问题的学习。
- en: We then looked at implementing the Generator and Discriminator models that are
    used to create an unconditional GAN in pure TensorFlow 2.0\. In this section,
    the expressive power of TensorFlow 2.0 and the definition of custom training loops
    was presented. In fact, it has been shown how straightforward it is to create
    Keras models and write the custom training loop that implements the adversarial
    training process, just by following the steps described in the GAN paper (*Generative
    Adversarial Networks - Ian Goodfellow et al.)**.*
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着看了如何在纯TensorFlow 2.0中实现用于创建无条件GAN的生成器和判别器模型。在这一部分，展示了TensorFlow 2.0的表达能力以及自定义训练循环的定义。事实上，展示了如何通过遵循GAN论文（*生成对抗网络——Ian
    Goodfellow等*）中描述的步骤，轻松创建Keras模型并编写实现对抗训练过程的自定义训练循环。
- en: The Keras functional API has been also extensively used, where a conditional
    generator of Fashion-MNIST-like images has been implemented. The implementation
    showed us how, by using the Keras functional API, it is possible to feed a second
    input (the condition) to both the Generator and Discriminator and define a flexible
    neural network architecture easily.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Keras函数式API也被广泛使用，其中实现了一个条件生成器，用于生成类似Fashion-MNIST的图像。该实现向我们展示了通过使用Keras函数式API，如何将第二个输入（条件）传递给生成器和判别器，并轻松定义灵活的神经网络架构。
- en: The GAN universe is rich in terms of very complex architectures and clever ideas
    for astonishing applications. This chapter aims to explain the GAN framework without
    claiming to be complete; there's enough material out there about GANs for me to
    write more than a whole book.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的宇宙在复杂的架构和巧妙的应用创意方面十分丰富。本章旨在解释GAN框架，并不声称涵盖所有内容；关于GAN的材料足够多，我甚至可以写一本完整的书。
- en: 'This chapter ends with an exercise section, which contains a challenge for
    you (questions 16 and 17): can you create a conditional GAN that generates realistic
    images, starting from a semantic label?'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以习题部分结束，其中包含一个挑战（问题16和17）：你能创建一个生成真实图像的条件GAN吗？从一个语义标签开始？
- en: So far, we've focused on how to train various models, from simple classifiers
    to generative models, without worrying about the deployment stage.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们专注于如何训练各种模型，从简单的分类器到生成模型，而不考虑部署阶段。
- en: In the next chapter, [Chapter 10](889170ef-f89d-4485-a111-6cd4e72f0daa.xhtml), *Bringing
    a Model to Production*, the final step of every real-life machine learning application
    will be presented – the deployment of learned models.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，[第10章](889170ef-f89d-4485-a111-6cd4e72f0daa.xhtml)，*将模型投入生产*，将展示每个实际机器学习应用的最后一步——学习模型的部署。
- en: Exercises
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 习题
- en: 'Try answering and working on the following exercises to expand the knowledge
    that you''ve gained from this chapter:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试回答并解决以下习题，以扩展你从本章中获得的知识：
- en: What is the adversarial training process?
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是对抗训练过程？
- en: Write the value function of the min-max game that the Discriminator and Generator
    are playing.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写判别器和生成器所进行的极小极大博弈的价值函数。
- en: Explain why the min-max value function formulation can saturate in the early
    training step of training.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释为什么在训练的早期阶段，极小极大价值函数的公式可能会饱和。
- en: Write and explain the non-saturating value function.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写并解释非饱和价值函数。
- en: Write the rules of the adversarial training process.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写对抗训练过程的规则。
- en: Are there any recommendations on how to feed a condition to a GAN?
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有没有关于如何向GAN传递条件的建议？
- en: What does it mean to create a conditional GAN?
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建条件GAN意味着什么？
- en: Can only the fully connected neural networks be used to create GANs?
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否只能使用全连接神经网络来创建GAN？
- en: Which neural network architecture works better for the image generation problem?
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种神经网络架构更适合图像生成问题？
- en: 'Update the code of the Unconditional GAN: Log the Generator and Discriminator
    loss value on TensorBoard, and also log matplotlib plots.'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新无条件GAN的代码：在TensorBoard上记录生成器和判别器的损失值，同时记录matplotlib图表。
- en: 'Unconditional GAN: Save the model parameter in a checkpoint at every epoch.
    Add support for the model''s restoration, restarting from the latest checkpoint.'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无条件GAN：在每个周期结束时保存模型参数到检查点。添加对模型恢复的支持，可以从最新的检查点重新开始。
- en: Extend the code of the unconditional GAN by making it conditional. Given the
    condition of 0, the Generator must behave like the normal distribution, with a
    mean of 10 and a standard deviation of 0.1\. Given the condition of 1, the Generator
    must produce a value that has been sampled from a Gaussian distribution with a
    mean of 100 and a standard deviation of 1.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将无条件GAN的代码扩展为条件GAN，进行修改。给定条件0时，生成器必须表现得像正态分布，均值为10，标准差为0.1。给定条件1时，生成器必须产生一个从均值为100、标准差为1的高斯分布中采样得到的值。
- en: Log the magnitude of the Gradient that was computed to update the Discriminator
    and Generator in TensorBoard. Apply gradient clipping if the magnitude is greater
    than 1 in an absolute value.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TensorBoard中记录计算得出的梯度幅值，用于更新判别器和生成器。如果梯度幅值的绝对值大于1，应用梯度裁剪。
- en: Repeat exercises 1 and 2 for the conditional GAN.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对条件GAN重复执行第1和第2个练习。
- en: 'Conditional GAN: Do not use matplotlib to plot the images; use `tf.summary.image`
    and TensorBoard.'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 条件GAN：不要使用matplotlib绘制图像；使用`tf.summary.image`和TensorBoard。
- en: Using the dataset we created in the previous chapter, [Chapter 8](51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml), *Semantic
    Segmentation and Custom Dataset Builder*, create a conditional GAN that performs
    domain translation, from the semantic label to an image.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在上一章中创建的数据集，[第8章](51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml)，*语义分割和自定义数据集构建器*，创建一个条件GAN，执行领域转换，从语义标签到图像。
- en: Use TensorFlow Hub to download a pre-trained feature extractor and use it as
    a building block to create the Discriminator for a conditional GAN that generates
    realistic scenes from semantic labels.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用TensorFlow Hub下载一个预训练的特征提取器，并将其作为构建块，用于创建条件GAN的判别器，该GAN根据语义标签生成逼真的场景。
