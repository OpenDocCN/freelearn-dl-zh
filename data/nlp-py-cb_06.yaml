- en: Chunking, Sentence Parse, and Dependencies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分块、句子解析和依赖关系
- en: 'In this chapter, we will perform the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将执行以下配方：
- en: Using the built-in chunker
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内置的分块器
- en: Writing your own simple chunker
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写你自己的简单分块器
- en: Training a chunker
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个分块器
- en: Parsing recursive descent
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析递归下降
- en: Parsing shift reduce
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析移位规约
- en: Parsing dependency grammar and projective dependency
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析依赖语法和投影依赖
- en: Parsing a chart
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析图表
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: We have learned so far that the Python NLTK can be used to do **part-of-speech**
    (**POS**) recognition in a given piece of text. But sometimes we are interested
    in finding more details about the text that we are dealing with. For example,
    I might be interested in finding the names of some famous personalities, places,
    and so on in a given text. We can maintain a very big dictionary of all these
    names. But in the simplest form, we can use a POS analysis to identify these patterns
    very easily.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习到Python NLTK可以用于对给定文本进行**词性**（**POS**）识别。但有时我们对我们处理的文本中更多细节感兴趣。例如，我可能对在给定文本中找到的某些名人、地点等感兴趣。我们可以维护一个非常大的所有这些名称的字典。但在最简单的形式中，我们可以使用POS分析来轻松识别这些模式。
- en: Chunking is the process of extracting short phrases from text. We will leverage
    POS tagging algorithms to do chunking. Remember that the tokens (words) produced
    by chunking do not overlap.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分块是从文本中提取短语的过程。我们将利用POS标记算法进行分块。请记住，分块生成的标记（单词）不重叠。
- en: Using the built-in chunker
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内置的分块器
- en: 'In this recipe, we will learn how to use the in-built chunker. These are the
    features that will be used from NLTK as part of this process:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将学习如何使用内置的分块器。以下是在此过程中从NLTK中使用的特性：
- en: Punkt tokenizer (default)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Punkt标记器（默认）
- en: Averaged perception tagger (default)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均感知标注器（默认）
- en: Maxent NE chunker (default)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大熵NE分块器（默认）
- en: Getting ready
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed along with the `nltk` library. Prior understanding
    of POS tagging as explained in [Chapter 5](d81001da-02ad-4499-a128-913770e0833e.xhtml), *POS
    Tagging and Grammars* is good to have.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该已经安装了Python以及`nltk`库。建议事先了解POS标记，如[第5章](d81001da-02ad-4499-a128-913770e0833e.xhtml)，*POS标记和语法*。
- en: How to do it...
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到…
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或您喜欢的编程编辑器）。
- en: Create a new file called `Chunker.py`.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Chunker.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/46ace391-59f8-4f54-aa9c-1749d3465536.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46ace391-59f8-4f54-aa9c-1749d3465536.png)'
- en: Save the file.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '![](img/f0b45d44-d2cd-4a5b-bfbb-4d9dbc099f35.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0b45d44-d2cd-4a5b-bfbb-4d9dbc099f35.png)'
- en: How it works...
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理…
- en: 'Let''s try to understand how the program works. This instruction imports the `nltk` module
    into the program:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试着理解程序是如何工作的。这条指令将`nltk`模块导入程序中：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is the data that we are going to analyze as part of this recipe. We are
    adding this string to a variable called `text`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们作为这个配方的一部分要分析的数据。我们将这个字符串添加到名为`text`的变量中：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This instruction is going to break the given text into multiple sentences.
    The result is a list of sentences stored in the `sentences` variable:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令将把给定的文本分成多个句子。结果是存储在名为`sentences`的列表中的句子：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this instruction, we are looping through all the sentences that we have
    extracted. Each sentence is stored in the sentence variable:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个指令中，我们正在循环遍历我们提取的所有句子。每个句子都存储在名为`sentence`的变量中：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This instruction breaks the sentence into non-overlapping words. The result
    is stored in a variable called `words`:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令将句子分成不重叠的单词。结果存储在名为`words`的变量中：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this instruction, we do POS analysis using the default tagger that is available
    with NLTK. Once the identification is done, the result is stored in a variable
    called `tags`:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个指令中，我们使用NLTK提供的默认标注器进行POS分析。一旦识别完成，结果将存储在名为`tags`的变量中：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this instruction, we call the `nltk.ne_chunk()` function, which does the
    chunking part for us. The result is stored in a variable called chunks. The result
    is actually tree-structured data that contains the paths of the tree:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个指令中，我们调用`nltk.ne_chunk()`函数，它为我们执行分块部分。结果存储在名为chunks的变量中。实际上，结果是包含树路径的树结构化数据：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This prints the chunks that are identified in the given input string. Chunks
    are grouped in brackets, '`(`' and '`)`', to easily distinguish them from other
    words that are in the input text.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这会打印出在给定输入字符串中识别的分块。分块会被括号 "`(`" 和 "`)`" 包裹，以便与输入文本中的其他单词区分开来。
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Writing your own simple chunker
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写你自己的简单分块器
- en: In this recipe, we will write our own Regex chunker. Since we are going to use
    regular expressions to write this chunker, we need to understand a few differences
    in the way we write regular expressions for chunking.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将编写自己的正则表达式分块器。由于我们将使用正则表达式来编写此分块器，我们需要了解一些编写正则表达式以进行分块时的不同之处。
- en: In [Chapter 4](bdfe8ef1-c7dd-42ff-895d-84c90c5ccfb3.xhtml), *Regular Expressions*,
    we understood regular expressions and how to write them. For example, a regular
    expression of the form *[a-z, A-Z]+* matches all words in a sentence that is written
    in English.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](bdfe8ef1-c7dd-42ff-895d-84c90c5ccfb3.xhtml)《正则表达式》中，我们理解了正则表达式及其编写方法。例如，形式为
    *[a-z, A-Z]+* 的正则表达式匹配英语句子中的所有单词。
- en: We already understand that by using NLTK, we can identify the POS in their short
    form (tags such as `V`, `NN`, `NNP`, and so on). Can we write regular expressions
    using these POS?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经理解，通过使用 NLTK，我们可以识别出词性的简写（如 `V`、`NN`、`NNP` 等）。我们能否使用这些词性编写正则表达式？
- en: The answer is yes. You have guessed it correctly. We can leverage POS-based
    regular expression writing. Since we are using POS tags to write these regular
    expressions, they are called tag patterns.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是肯定的。你猜对了。我们可以利用基于词性的正则表达式编写。由于我们使用词性标签来编写这些正则表达式，它们被称为标签模式。
- en: Just like the way we write the native alphabets (a-z) of a given natural language
    to match various patterns, we can also leverage POS to match words (any combinations
    from dictionary) according to the NLTK matched POS.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们写一个给定自然语言的字母（a-z）来匹配不同的模式一样，我们也可以利用词性（POS）根据 NLTK 匹配的词性来匹配单词（来自字典的任意组合）。
- en: These tag patterns are one of the most powerful features of NLTK because they
    give us the flexibility to match the words in a sentence just by POS-based regular
    expressions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标签模式是 NLTK 最强大的功能之一，因为它们使我们能够仅通过基于词性的正则表达式来匹配句子中的单词。
- en: 'In order to learn more about these, let''s dig further:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地了解这些，让我们进一步探讨：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once we identify the POS, this is how the result looks:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们识别了词性，结果如下所示：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Later, we can use this information to extract the noun phrases.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以使用这些信息来提取名词短语。
- en: 'Let''s pay close attention to the preceding POS output. We can make the following
    observations:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细查看前面的词性输出。我们可以得出以下观察：
- en: Chunks are one or more continuous `NNP`
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分块是一个或多个连续的 `NNP`
- en: Chunks are `NNP` followed by a `DT`
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分块是 `NNP` 后跟 `DT`
- en: Chunks are `NP` followed by one more `JJ`
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分块是 `NP` 后跟另一个 `JJ`
- en: 'By using these three simple observations, let''s write a regular expression
    using POS, which is called as tag phrase in the BNF form:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这三个简单的观察，我们来编写一个基于词性的正则表达式，它在 BNF 形式中称为标签短语：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are interested in extracting the following chunks from the input text:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的是从输入文本中提取以下分块：
- en: '`Ravi`'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ravi`'
- en: '`the CEO`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`the CEO`'
- en: '`a company`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a company`'
- en: '`powerful public speaker`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`powerful public speaker`'
- en: Let's write a simple Python program that gets the job done.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个简单的 Python 程序来完成任务。
- en: Getting ready
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: You should have Python installed, along with the `nltk` library. A fair understanding
    of regular expressions is good to have.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了 Python，并且安装了 `nltk` 库。对正则表达式有一定了解会很有帮助。
- en: How to do it...
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Atom 编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `SimpleChunker.py`.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `SimpleChunker.py` 的新文件。
- en: 'Type the following source code:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/17d11112-d843-46df-98d1-f3123da35353.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/17d11112-d843-46df-98d1-f3123da35353.png)'
- en: Save the file.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/6edc4d4c-4540-4bf8-8338-d0e8f592a15d.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6edc4d4c-4540-4bf8-8338-d0e8f592a15d.png)'
- en: How it works...
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'Now, let''s understand how the program works:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们理解程序是如何工作的：
- en: 'This instruction imports the `nltk` library into the current program:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令将 `nltk` 库导入当前程序：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We are declaring the `text` variable with the sentences that we want to process:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声明了一个 `text` 变量，其中包含我们要处理的句子：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this instruction, we are writing regular expressions, which are written using
    POS; so they are specially called tag patterns. These tag patterns are not a randomly
    created ones. They are carefully crafted from the preceding example.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个指令中，我们编写正则表达式，这些正则表达式是通过词性标注（POS）来写的，因此它们被特别称为标签模式。这些标签模式不是随意创建的，而是从前面的示例中精心制作的。
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s understand these tag patterns:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们理解这些标签模式：
- en: '`NP` is followed by one or more `<DT>` and then an `<NNP>`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NP` 后跟一个或多个 `<DT>`，然后是一个 `<NNP>`'
- en: '`NP` is followed by one or more `<JJ>` and then an `<NN>`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NP` 后跟一个或多个 `<JJ>`，然后是一个 `<NN>`'
- en: '`NP` is one more `<NNP>`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NP` 后跟一个或多个 `<NNP>`'
- en: 'The more text we process, the more rules like this we can discover. These are
    specific to the language we process. So, this is a practice we should do in order
    to become more powerful at information extraction:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们处理的文本越多，就能发现更多这样的规则。这些规则是特定于我们处理的语言的。所以，这是我们应该做的练习，以便在信息提取方面变得更强大：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'First we break the input text into sentences by using the `nltk.sent_tokenize()`
    function:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用 `nltk.sent_tokenize()` 函数将输入文本分割成句子：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This instruction iterates through a list of all sentences and assigns one sentence
    to the `sentence` variable:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令会遍历所有句子的列表，并将每个句子分配给 `sentence` 变量：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This instruction breaks the sentence into tokens using the `nltk.word_tokenize()`
    function and puts the result into the `words` variable:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令使用 `nltk.word_tokenize()` 函数将句子分割成标记，并将结果存入 `words` 变量：
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This instruction does the POS identification on the words variable (which has
    a list of words) and puts the result in the `tags` variable (which has each word
    correctly tagged with its respective POS tag):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令会对单词变量（其中包含一个单词列表）进行词性标注，并将结果存入 `tags` 变量（每个单词会被正确地标注上相应的词性标签）：
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This instruction invokes the `nltk.RegexpParser` on the grammar that we have
    created before. The object is available in the `chunkparser` variable:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令调用 `nltk.RegexpParser` 来解析我们之前创建的语法。对象保存在 `chunkparser` 变量中：
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We parse the tags using the object and the result is stored in the `result`
    variable:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用对象解析这些标签，结果存储在 `result` 变量中：
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now, we display the identified chunks on screen using the `print()` function.
    The output is a tree structure with words and their associated POS.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用 `print()` 函数在屏幕上显示已识别的词块。输出结果是一个树状结构，显示了单词及其对应的词性。
- en: Training a chunker
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练词块解析器
- en: In this recipe, will learn the training process, training our own chunker, and
    evaluating it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将学习训练过程，训练我们自己的词块解析器，并进行评估。
- en: Before we go into training, we need to understand the type of data we are dealing
    with. Once we have a fair understanding of the data, we must train it according
    to the pieces of information we need to extract. One particular way of training
    the data is to use IOB tagging for the chunks that we extract from the given text.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练之前，我们需要了解我们处理的数据类型。一旦我们对数据有了基本了解，就必须根据需要提取的信息来训练它。一种特定的训练数据的方法是使用 IOB 标注法来标记从给定文本中提取的词块。
- en: Naturally, we find different words in a sentence. From these words, we can find
    POS. Later, when chunking the text, we need to further tag the words according
    to where they are present in the text.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，我们在句子中找到了不同的单词。从这些单词中，我们可以找出它们的词性。稍后在进行词块分析时，我们需要根据单词在文本中的位置进一步标注单词。
- en: 'Take the following example:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 取以下示例：
- en: '[PRE21]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once we''ve done POS tagging and hunking of the data, we will see an output
    similar to this one:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成了词性标注和词块分析，我们将看到类似这样的输出：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This is called the IOB format, where each line consists of three tokens separated
    by spaces.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这叫做 IOB 格式，每行由三个由空格分隔的标记组成。
- en: '| **Column** | **Description** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **列** | **描述** |'
- en: '| First column in IOB |  The actual word in the input sentence |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| IOB 中的第一列 | 输入句子中的实际单词 |'
- en: '| Second column in IOB | The POS for the word |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| IOB 中的第二列 | 单词的词性 |'
- en: '| Third column in IOB | Chunk identifier with I (inside chunk), O (outside
    chunk), B (beginning word of the chunk), and the appropriate suffix to indicate
    the category of the word |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| IOB 中的第三列 | 词块标识符，包含 I（词块内）、O（词块外）、B（词块的开始词）以及适当的后缀来表示单词的类别 |'
- en: 'Let''s see this in a diagram:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在图示中查看这一过程：
- en: '![](img/4b640277-64c6-4281-bcd4-f8df8a5825c8.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4b640277-64c6-4281-bcd4-f8df8a5825c8.png)'
- en: Once we have the training data in IOB format, we can further use it to extend
    the reach of our chunker by applying it to other datasets. Training is very expensive
    if we want to do it from scratch or want to identify new types of keywords from
    the text.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了IOB格式的训练数据，我们可以进一步利用它，通过将其应用于其他数据集来扩展我们的chunker的适用范围。如果我们从头开始训练，或者想从文本中识别新的关键字类型，训练是非常昂贵的。
- en: Let's try to write a simple chunker using the `regexparser` and see what types
    of results it gives.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试写一个简单的chunker，使用`regexparser`，看看它能给出什么类型的结果。
- en: Getting ready
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed, along with the `nltk` library.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了Python，并且安装了`nltk`库。
- en: How to do it...
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `TrainingChunker.py`.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`TrainingChunker.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/395ef854-eaff-4e85-ad25-0101fcd8f20b.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/395ef854-eaff-4e85-ad25-0101fcd8f20b.png)'
- en: Save the file.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see this output:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/e8f410a5-afca-465e-abb6-b2ba89496bc2.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8f410a5-afca-465e-abb6-b2ba89496bc2.png)'
- en: How it works...
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'This instruction imports the `nltk` module into the current program:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令将`nltk`模块导入到当前程序中：
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This instruction imports the `conll2000` corpus into the current program:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令将`conll2000`语料库导入到当前程序中：
- en: '[PRE24]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This instruction imports the `treebank` corpus into the current program:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令将`treebank`语料库导入到当前程序中：
- en: '[PRE25]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We are defining a new function, `mySimpleChunker()`. We are also defining a
    simple tag pattern that extracts all the words that have POS of `NNP` (proper
    nouns). This grammar is used for our chunker to extract the named entities:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个新函数`mySimpleChunker()`。我们还定义了一个简单的标签模式，用于提取所有词性为`NNP`（专有名词）的单词。这个语法用于我们的chunker提取命名实体：
- en: '[PRE26]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This is a simple chunker; it doesn''t extract anything from the given text.
    Useful to see if the algorithm works correctly:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的chunker，它不会从给定的文本中提取任何内容。用于检查算法是否正常工作：
- en: '[PRE27]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This function uses `mySimpleChunker()` on the test data and evaluates the accuracy
    of the data with respect to already tagged input data:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数在测试数据上使用`mySimpleChunker()`，并评估数据与已经标记的输入数据的准确性：
- en: '[PRE28]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We create a list of two datasets, one from `conll2000` and another from `treebank`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个包含两个数据集的列表，一个来自`conll2000`，另一个来自`treebank`：
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We iterate over the two datasets and call `test_nothing()` and `test_mysimplechunker()` on
    the first 50-IOB tagged sentences to see what the accuracy of the chunker looks
    like.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对两个数据集进行迭代，并在前50个IOB标记的句子上调用`test_nothing()`和`test_mysimplechunker()`，以查看chunker的准确性。
- en: '[PRE30]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Parsing recursive descent
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归下降解析
- en: Recursive descent parsers belong to the family of parsers that read the input
    from left to right and build the parse tree in a top-down fashion and traversing
    nodes in a pre-order fashion. Since the grammar itself is expressed using CFG
    methodology, the parsing is recursive in nature. This kind of parsing technique
    is used to build compilers for parsing instructions of programming languages.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 递归下降解析器属于一种解析器家族，它从左到右读取输入，并以自顶向下的方式构建解析树，同时以先序遍历的方式遍历节点。由于语法本身是使用CFG方法表达的，解析是递归性质的。这种解析技术用于构建编译器，以解析编程语言的指令。
- en: In this recipe, we will explore how we can use the RD parser that comes with
    the NLTK library.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将探讨如何使用NLTK库自带的RD解析器。
- en: Getting ready
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed, along with the `nltk` library.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了Python，并且安装了`nltk`库。
- en: How to do it...
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `ParsingRD.py`.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`ParsingRD.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/b0d8fa0e-dd08-4019-9c64-7f2d13c8f1cb.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b0d8fa0e-dd08-4019-9c64-7f2d13c8f1cb.png)'
- en: Save the file.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/9ef87056-47cd-4a8a-8492-83731320a330.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ef87056-47cd-4a8a-8492-83731320a330.png)'
- en: 'This graph is the output of the second sentence in the input as parsed by the
    RD parser:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图是输入中第二个句子通过RD解析器解析后的输出：
- en: '![](img/b237930a-c158-4924-a936-f5d0eb839775.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b237930a-c158-4924-a936-f5d0eb839775.png)'
- en: How it works...
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'Let''s see how the program works. In this instruction, we are importing the `nltk` library:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看程序是如何工作的。在这条指令中，我们导入了`nltk`库：
- en: '[PRE31]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In these instructions, we are defining a new function, `SRParserExample`; it
    takes a `grammar` object and `textlist` as parameters:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些说明中，我们定义了一个新的函数 `SRParserExample`；它接受一个 `grammar` 对象和 `textlist` 作为参数：
- en: '[PRE32]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We are creating a new parser object by calling `RecursiveDescentParser` from
    the `nltk.parse` library. We pass grammar to this class for initialization:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用 `nltk.parse` 库中的 `RecursiveDescentParser` 来创建一个新的解析器对象。我们将 grammar 传递给这个类进行初始化：
- en: '[PRE33]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In these instructions, we are iterating over the list of sentences in the `textlist` variable.
    Each text item is tokenized using the `nltk.word_tokenize()` function and then
    the resultant words are passed to the `parser.parse()` function. Once the parse
    is complete, we display the result on the screen and also show the parse tree:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些说明中，我们遍历 `textlist` 变量中的句子列表。每个文本项都使用 `nltk.word_tokenize()` 函数进行分词，然后将结果单词传递给 `parser.parse()` 函数。一旦解析完成，我们会将结果显示在屏幕上，并展示解析树：
- en: '[PRE34]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We create a new `CFG` object using `grammar`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `grammar` 创建一个新的 `CFG` 对象：
- en: '[PRE35]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'These are the two sample sentences we use to understand the parser:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们用来理解解析器的两个样本文本：
- en: '[PRE36]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We call `RDParserExample` using the `grammar` object and the list of sample
    sentences.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用 `RDParserExample` 使用 `grammar` 对象和样本文本列表。
- en: '[PRE37]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Parsing shift-reduce
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移位归约解析
- en: In this recipe, we will learn to use and understand shift-reduce parsing.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将学习如何使用和理解移位归约解析。
- en: Shift-reduce parsers are special types of parsers that parse the input text
    from left to right on a single line sentences and top to bottom on multiline sentences.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 移位归约解析器是特殊类型的解析器，它们从左到右解析单行句子的输入文本，从上到下解析多行句子的输入文本。
- en: 'For every alphabet/token in the input text, this is how parsing happens:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入文本中的每个字母/符号，解析过程如下：
- en: Read the first token from the input text and push it to the stack (shift operation)
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输入文本中读取第一个符号并将其推送到堆栈（移位操作）
- en: Read the complete parse tree on the stack and see which production rule can
    be applied, by reading the production rule from right to left (reduce operation)
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从堆栈中读取完整的解析树，并查看可以应用哪些生成规则，通过从右到左读取生成规则（归约操作）
- en: This process is repeated until we run out of production rules, when we accept
    that parsing has failed
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个过程会一直重复，直到我们用尽所有的生成规则，这时我们认为解析失败
- en: This process is repeated until all of the input is consumed; we say parsing
    has succeeded
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个过程会一直重复，直到所有输入都被消耗完，我们认为解析成功
- en: In the following examples, we see that only one input text is going to be parsed
    successfully and the other cannot be parsed.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们看到只有一个输入文本会被成功解析，另一个则无法解析。
- en: Getting ready
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed, along with the `nltk` library. An understanding
    of writing grammars is needed.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了 Python，并且安装了 `nltk` 库。需要了解如何编写语法规则。
- en: How to do it...
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Atom 编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `ParsingSR.py`.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的文件，命名为 `ParsingSR.py`。
- en: 'Type the following source code:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/baa9e588-2950-481f-8e4d-d91c2077c7b6.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/baa9e588-2950-481f-8e4d-d91c2077c7b6.png)'
- en: Save the file.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/9ad57c15-333e-450e-88cc-17aed8d160f9.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ad57c15-333e-450e-88cc-17aed8d160f9.png)'
- en: How it works...
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s see how the program works. In this instruction we are importing the `nltk` library:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看程序是如何工作的。在这条指令中，我们导入了 `nltk` 库：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In these instructions, we are defining a new function, `SRParserExample`; it
    takes a `grammar` object and `textlist` as parameters:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些说明中，我们定义了一个新的函数 `SRParserExample`；它接受一个 `grammar` 对象和 `textlist` 作为参数：
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We are creating a new parser object by calling `ShiftReduceParser` from the `nltk.parse` library.
    We pass `grammar` to this class for initialization:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用 `nltk.parse` 库中的 `ShiftReduceParser` 来创建一个新的解析器对象。我们将 `grammar` 传递给这个类进行初始化：
- en: '[PRE40]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'In these instructions, we are iterating over the list of sentences in the `textlist` variable.
    Each text item is tokenized using the `nltk.word_tokenize()` function and then
    the resultant words are passed to the `parser.parse()` function. Once the parse
    is complete, we display the result on the screen and also show the parse tree:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些说明中，我们遍历 `textlist` 变量中的句子列表。每个文本项都使用 `nltk.word_tokenize()` 函数进行分词，然后将结果单词传递给 `parser.parse()` 函数。一旦解析完成，我们会将结果显示在屏幕上，并展示解析树：
- en: '[PRE41]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'These are the two sample sentences we are using to understand the shift-reduce
    parser:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们用来理解移位归约解析器的两个样本文本：
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We create a new `CFG` object using the `grammar`:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `grammar` 创建一个新的 `CFG` 对象：
- en: '[PRE43]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We call the `SRParserExample` using the `grammar` object and the list of sample
    sentences.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `grammar` 对象和示例句子的列表调用 `SRParserExample`。
- en: '[PRE44]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Parsing dependency grammar and projective dependency
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析依赖语法和投影依赖
- en: In this recipe, we will learn how to parse dependency grammar and use it with
    the projective dependency parser.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将学习如何解析依赖语法并使用投影依赖解析器。
- en: Dependency grammars are based on the concept that sometimes there are direct
    relationships between words that form a sentence. The example in this recipe shows
    this clearly.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖语法基于这样一个概念：有时，句子中的单词之间存在直接关系。此食谱中的示例清楚地展示了这一点。
- en: Getting ready
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed, along with the `nltk` library.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该安装 Python，并且需要安装`nltk`库。
- en: How to do it...
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Atom 编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `ParsingDG.py`.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `ParsingDG.py` 的新文件。
- en: 'Type the following source code:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/180a1044-b8a0-4c35-b11d-011d90bd07fb.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/180a1044-b8a0-4c35-b11d-011d90bd07fb.png)'
- en: Save the file.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/e2b13330-f4fb-4219-adc7-5561dce8dce2.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2b13330-f4fb-4219-adc7-5561dce8dce2.png)'
- en: How it works...
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s see how the program works. This instruction imports the `nltk` library
    into the program:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看程序是如何工作的。这个指令将 `nltk` 库导入程序：
- en: '[PRE45]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This instruction creates a `grammar` object using the `nltk.grammar.DependencyGrammar` class.
    We are adding the following productions to the grammar:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令使用 `nltk.grammar.DependencyGrammar` 类创建了一个 `grammar` 对象。我们正在向语法中添加以下生成规则：
- en: '[PRE46]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s understand more about these productions:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入了解这些生成规则：
- en: '`small` related to `savings`'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`small` 与 `savings` 相关'
- en: '`savings` related to `yield`'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`savings` 与 `yield` 相关'
- en: '`large` related to `gains`'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`large` 与 `gains` 相关'
- en: '`gains` related to `yield`'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gains` 与 `yield` 相关'
- en: 'This is the sample sentence on which we are going to run the parser. It is
    stored in a variable called `sentence`:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将运行解析器的示例句子。它被存储在一个名为`sentence`的变量中：
- en: '[PRE47]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This instruction is creating a new `nltk.parse.ProjectiveDependencyParser` object
    using the `grammar` we have just defined:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令使用我们刚刚定义的 `grammar` 创建一个新的 `nltk.parse.ProjectiveDependencyParser` 对象：
- en: '[PRE48]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We are doing many things in this for loop:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 for 循环中，我们做了很多事情：
- en: '[PRE49]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Preceding for loop does:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的 for 循环做了以下操作：
- en: We are breaking the words in the sentence
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在拆分句子中的单词
- en: All the list of words are fed to the `dp` object as input
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有单词列表作为输入传递给 `dp` 对象
- en: The result from the parsed output is sorted using the `sorted()` built-in function
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析后的结果通过 `sorted()` 内置函数进行排序
- en: Iterate over all the tree paths and display them on screen as well as render
    the result in a beautiful tree form
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历所有树形路径并将它们显示在屏幕上，同时以漂亮的树形结构呈现结果
- en: Parsing a chart
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析图表
- en: Chart parsers are special types of parsers which are suitable for natural languages
    as they have ambiguous grammars. They use dynamic programming to generate the
    desired results.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图表解析器是适用于自然语言的特殊类型解析器，因为自然语言的语法通常是模糊的。它们使用动态编程来生成所需的结果。
- en: The good thing about dynamic programming is that, it breaks the given problem
    into subproblems and stores the result in a shared location, which can be further
    used by algorithm wherever similar subproblem occurs elsewhere. This greatly reduces
    the need to re-compute the same thing over and over again.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 动态编程的好处是，它将给定问题分解为子问题，并将结果存储在一个共享位置，算法可以在遇到相似子问题时重复使用这些结果。这大大减少了反复计算相同问题的需求。
- en: In this recipe, we will learn the chart parsing features that are provided by
    the NLTK library.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将学习 NLTK 库提供的图表解析功能。
- en: Getting ready
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed, along with the `nltk` library. An understanding
    of grammars is good to have.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该安装 Python，并且需要安装 `nltk` 库。理解语法是很有帮助的。
- en: How to do it...
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Atom 编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `ParsingChart.py`.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `ParsingChart.py` 的新文件。
- en: 'Type the following source code:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/6b02dae4-ee2e-4108-9654-eaff227ef980.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b02dae4-ee2e-4108-9654-eaff227ef980.png)'
- en: Save the file.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/08b17e6d-bc4e-4db0-a801-e74fe4695ff6.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/08b17e6d-bc4e-4db0-a801-e74fe4695ff6.png)'
- en: How it works...
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s see how the program works. This instruction imports the `CFG` module
    into the program:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看程序是如何工作的。此指令将`CFG`模块导入程序：
- en: '[PRE50]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This instruction imports the `ChartParser` and `BU_LC_STRATEGY` features into
    the program:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 本指令将`ChartParser`和`BU_LC_STRATEGY`功能导入程序：
- en: '[PRE51]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We are creating a sample grammar for the example that we are going to use.
    All the producers are expressed in the BNF form:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在为示例创建一个语法规则。所有的产生式都以BNF形式表示：
- en: '[PRE52]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The grammar consists of:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 语法由以下部分组成：
- en: A starting token, `S`, which produces `T1 T4`
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个起始符号`S`，它生成`T1 T4`
- en: Non-terminal tokens `T1`, `T2`, `T3`, and `T4`, which further produce `NNP VBZ`,
    `DT NN`, `IN NNP`, `T2`, or `T2 T3` respectively
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非终结符号`T1`、`T2`、`T3`和`T4`，它们分别生成`NNP VBZ`、`DT NN`、`IN NNP`、`T2`或`T2 T3`
- en: Terminal tokens, which are words from the English dictionary
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 终结符号，即来自英语词典的单词
- en: 'A new chart parser object is created using the grammar object `BU_LC_STRATEGY`,
    and we have set `trace` to `True` so that we can see how the parsing happens on
    the screen:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 使用语法对象`BU_LC_STRATEGY`创建一个新的图表解析器对象，并且我们已将`trace`设置为`True`，以便在屏幕上看到解析过程：
- en: '[PRE53]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We are going to process this sample string in this program; it is stored in
    a variable called `sentence`:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本程序中处理这个示例字符串，它存储在名为`sentence`的变量中：
- en: '[PRE54]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'This instruction creates a list of words from the example sentence:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 本指令从示例句子创建一个单词列表：
- en: '[PRE55]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This instruction takes the list of words as input and then starts the parsing.
    The result of the parsing is made available in the `chart` object:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 本指令将单词列表作为输入，然后开始解析。解析的结果将存储在`chart`对象中：
- en: '[PRE56]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We are acquiring all the parse trees that are available in the chart into the `parses` variable:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在将图表中所有可用的解析树存储到`parses`变量中：
- en: '[PRE57]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'This instruction prints the total number of edges in the current `chart` object:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 本指令打印当前`chart`对象中所有边的总数：
- en: '[PRE58]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'This instruction prints all the parse trees on the screen:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 本指令将所有解析树打印到屏幕上：
- en: '[PRE59]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: This instruction shows a nice tree view of the chart on a GUI widget.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 本指令在GUI控件中显示图表的漂亮树状视图：
- en: '[PRE60]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
