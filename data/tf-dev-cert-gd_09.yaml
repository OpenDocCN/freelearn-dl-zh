- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Transfer Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转移学习
- en: One of the most significant developments of the last decade in the **machine
    learning** (**ML**) space was the concept of **transfer learning**, and rightfully
    so. Transfer learning is the process of applying knowledge gained from solving
    a source task to a target task, which is a different but related task. This approach
    has proven not only effective in saving computational resources required to train
    a deep neural network but also in cases where the target dataset is limited in
    size. Transfer learning reuses learned features from a pre-trained model, enabling
    us to build better-performing models and attain convergence much faster. Because
    of its numerous benefits, transfer learning has become an area of extensive research,
    with several studies exploring the application of transfer learning across different
    domains, such as image classification, object detection, natural language processing,
    and speech recognition.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年在**机器学习**（**ML**）领域最重要的进展之一是**转移学习**的概念，这一点当之无愧。转移学习是将从源任务中获得的知识应用到目标任务中的过程，目标任务与源任务不同但相关。这种方法不仅在节省训练深度神经网络所需的计算资源方面非常有效，而且在目标数据集较小的情况下也表现出色。转移学习通过重用从预训练模型中学到的特征，使我们能够构建性能更好的模型，并更快地达到收敛。由于其众多的优势，转移学习已经成为一个广泛研究的领域，许多研究探讨了转移学习在不同领域中的应用，如图像分类、目标检测、自然语言处理和语音识别等。
- en: In this chapter, we will introduce the concept of transfer learning, examining
    how it works, and some best practices around the application of transfer learning
    in various use cases. We will apply the concept of transfer learning in a real-world
    application with the aid of well-known pre-trained models. We will see in action
    how to apply these pre-trained models as a feature extractor and also learn how
    to fine-tune them to achieve optimal results. By the end of this chapter, you
    will have a solid understanding of what transfer learning is and how to apply
    it effectively to build real-world image classifiers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍转移学习的概念，探讨它是如何工作的，以及转移学习在不同应用场景中的一些最佳实践。我们将借助知名的预训练模型，在现实世界的应用中应用转移学习的概念。我们将看到如何将这些预训练模型作为特征提取器进行应用，并学习如何微调它们以实现最佳结果。在本章结束时，你将对转移学习有一个扎实的理解，并能有效地将其应用于构建现实世界的图像分类器。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: An introduction to transfer learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转移学习简介
- en: Types of transfer learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转移学习的类型
- en: Building a real-world image classifier with transfer learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用转移学习构建现实世界的图像分类器
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will use Google Colab to run the coding exercise, which requires `python
    >= 3.8.0`, along with the following packages, which can be installed using the
    `pip` `install` command:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Google Colab 进行编码练习，这需要 `python >= 3.8.0`，并且需要以下软件包，可以通过 `pip` `install`
    命令进行安装：
- en: '`tensorflow>=2.7.0`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow>=2.7.0`'
- en: '`os`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os`'
- en: '`matplotlib >=3.4.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib >=3.4.0`'
- en: '`pathlib`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pathlib`'
- en: 'The code bundle for this book is available at the following GitHub link: [https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate).
    Also, solutions to all exercises can be found in the GitHub repo itself.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包可以通过以下 GitHub 链接获取：[https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate)。所有习题的解答也可以在该
    GitHub 仓库中找到。
- en: Introduction to transfer learning
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转移学习简介
- en: As humans, it is easy for us to transfer knowledge gained from one task or activity
    to another. For instance, if you have a good grasp of Python (the programming
    language, not the snake) and you decide to learn Rust, because of your background
    knowledge in Python, you will find it easier to learn Rust compared to someone
    who has never written a basic program in any programming language. This is because
    certain concepts, such as object-oriented programming, have similarities across
    different programming languages. Transfer learning follows the same principle.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人类，我们很容易将从一个任务或活动中获得的知识转移到另一个任务中。例如，如果你精通 Python（编程语言，不是蛇），并且决定学习 Rust，凭借你在
    Python 上的背景知识，你会发现学习 Rust 比没有任何编程语言基础的人要容易得多。这是因为一些概念，如面向对象编程，在不同的编程语言中有相似之处。转移学习遵循相同的原理。
- en: Transfer learning is a technique in which we leverage a model pre-trained on
    *task A* to solve a different but related *task B*. For example, we use a neural
    network trained on one task and transfer the knowledge gained to multiple related
    tasks. In image classification, we often use deep learning models that have been
    trained on very large datasets, such as ImageNet, which is made up of more than
    1,000,000 images across 1,000 categories. The knowledge gained by these pre-trained
    models can be applied to many different tasks, such as classifying different breeds
    of dogs in a photograph. Just like how we can learn Rust quicker because of our
    knowledge of Python, the same applies here – pre-trained models can leverage information
    gained from a source task and apply it to the target task, reducing both the training
    time and the need for a large amount of annotated data, which may not be available
    or difficult to collect for the target task.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种技术，我们利用在*任务A*上预训练的模型来解决一个不同但相关的*任务B*。例如，我们使用在一个任务上训练的神经网络，并将获得的知识转移到多个相关任务中。在图像分类中，我们通常使用已经在非常大的数据集上训练的深度学习模型，比如ImageNet，它由超过1,000,000张图像组成，涵盖1,000个类别。这些预训练模型获得的知识可以应用于许多不同的任务，例如在照片中分类不同品种的狗。就像我们因为懂得Python而能更快地学习Rust一样，迁移学习也适用——预训练的模型可以利用从源任务中获得的信息，并将其应用于目标任务，从而减少训练时间和对大量注释数据的需求，而这些数据可能在目标任务中不可得或难以收集。
- en: Transfer learning is not limited to image classification tasks; it can also
    be applied to other deep learning tasks, such as natural language processing,
    speech recognition, and object detection. In [*Chapter 11*](B18118_11.xhtml#_idTextAnchor267),
    *NLP with TensorFlow,* we will apply transfer learning to text classification.
    There, we will see how pretrained models (which we will access from TensorFlow
    Hub), trained on large text corpora, can be fine-tuned for text classification.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习不仅限于图像分类任务；它还可以应用于其他深度学习任务，例如自然语言处理、语音识别和目标检测。在[*第11章*](B18118_11.xhtml#_idTextAnchor267)《使用TensorFlow进行NLP》中，我们将把迁移学习应用于文本分类。在那里，我们将看到如何对在大规模文本语料库上训练的预训练模型（我们将从TensorFlow
    Hub获取）进行微调，从而进行文本分类。
- en: In classic ML, as illustrated in *Figure 9**.1(a)*, we train the model from
    scratch for each task, as we have done so far in this book. This approach is resource-
    and data-intensive.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典机器学习中，如在*图9.1(a)*所示，我们为每个任务从头开始训练模型，正如我们在本书中迄今为止所做的那样。这种方法需要大量的资源和数据。
- en: '![Figure 9.1 – Traditional ML versus transfer learning](img/B18118_09_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 – 传统机器学习与迁移学习](img/B18118_09_01.jpg)'
- en: Figure 9.1 – Traditional ML versus transfer learning
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 传统机器学习与迁移学习
- en: However, researchers discovered it was possible to learn visual features so
    that a model learns low-level features from a massive dataset, such as ImageNet,
    and applies this to a new, related task, as illustrated in *Figure 9**.1(b)* –
    for example, in the classification of our weather dataset, which we used in [*Chapter
    8*](B18118_08.xhtml#_idTextAnchor186)*, Handling Overfitting*. By applying transfer
    learning, we can take advantage of the knowledge gained by a model during its
    training on a large dataset and adapt it to solve different but related tasks
    effectively. This approach proved useful, as it not only saves training time and
    resources but has also learned to improve performance, even in scenarios where
    a limited amount of data is available for the target task.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，研究人员发现，模型可以通过学习视觉特征，从一个庞大的数据集（如ImageNet）中学习低级特征，并将这些特征应用于一个新的、相关的任务，如*图9.1(b)*所示——例如，在我们在[*第8章*](B18118_08.xhtml#_idTextAnchor186)《处理过拟合》中使用的天气数据集的分类中。通过应用迁移学习，我们可以利用模型在大数据集上训练过程中获得的知识，并有效地将其适应于解决不同但相关的任务。这种方法被证明是有用的，因为它不仅节省了训练时间和资源，还学会了提高性能，即使在目标任务可用数据有限的情况下。
- en: Types of transfer learning
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习的类型
- en: There are two main ways we can apply transfer learning in CNNs. First, we can
    use the pre-trained model as a feature extractor. Here, we freeze the weights
    of the convolutional layers to preserve the knowledge gained from the source task
    and add a new classifier, which is trained for classification of the second task.
    This works because the convolutional layers are reusable, since they only learned
    the low-level features such as edges, corners, and textures, which are generic
    and applicable in different images, as shown in *Figure 9**.2*, while the fully
    connected layers are added to learn high-level details, which are used to classify
    different objects in a photograph.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在卷积神经网络（CNN）中通过两种主要方式应用迁移学习。首先，我们可以将预训练模型作为特征提取器。在这种情况下，我们冻结卷积层的权重，以保留源任务中获得的知识，并添加一个新的分类器，该分类器用于第二任务的分类。这是可行的，因为卷积层是可重用的，它们只学习了低级特征，如边缘、角落和纹理，这些是通用的并且适用于不同的图像，如*图
    9**.2*所示，而全连接层则用于学习高级细节，这些细节用于在照片中分类不同的物体。
- en: '![Figure 9.2 – Transfer learning as a feature extractor](img/B18118_09_02.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – 迁移学习作为特征提取器](img/B18118_09_02.jpg)'
- en: Figure 9.2 – Transfer learning as a feature extractor
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 迁移学习作为特征提取器
- en: The second method of applying transfer learning is to unfreeze some layers of
    the pre-trained model and add a classifier model to identify the high-level features,
    as shown in *Figure 9**.3*. Here, we train both the unfrozen layers and the new
    classifier together. The pre-trained model is applied as the starting point of
    the new task, and the weight of the unfrozen layers is fine-tuned along with the
    classification layer to adapt the model to the new task.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的第二种应用方法是解冻预训练模型的部分层，并添加一个分类器模型来识别高级特征，如*图 9**.3*所示。在这里，我们同时训练解冻的层和新的分类器。预训练模型作为新任务的起点，解冻层的权重与分类层一起微调，以使模型适应新任务。
- en: '![Figure 9.3 – Transfer learning as a fine-tuned model](img/B18118_09_03.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.3 – 迁移学习作为微调模型](img/B18118_09_03.jpg)'
- en: Figure 9.3 – Transfer learning as a fine-tuned model
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – 迁移学习作为微调模型
- en: Pre-trained models are deep networks that have been trained on large datasets.
    By leveraging the knowledge and weights these models have already acquired, we
    can use them as a feature extractor or fine-tune them for our use case, with a
    smaller dataset and less training time. Transfer learning provides ML practitioners
    with access to state-of-the-art models, which can be quickly and easily accessed
    in TensorFlow using an API. This means we don’t always have to train our model
    from scratch, saving time and computational resources, as fine-tuning a model
    is faster than training it from the beginning.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型是已经在大数据集上训练过的深度网络。通过利用这些模型已经获得的知识和权重，我们可以将它们用作特征提取器，或通过较小的数据集和更少的训练时间对它们进行微调以适应我们的使用场景。迁移学习为机器学习实践者提供了访问最先进模型的途径，这些模型可以通过TensorFlow中的API快速、轻松地访问。这意味着我们不必总是从头开始训练我们的模型，从而节省时间和计算资源，因为微调模型比从头开始训练要快。
- en: We can apply pre-trained models to relevant use cases, potentially leading to
    higher accuracy and faster convergence. However, if the source and target domains
    are unrelated, transfer learning may not only fail but also harm the performance
    of the target task, due to irrelevant learned features, a situation known as negative
    transfer. Let's apply transfer learning to a real-world image classification task.
    We will explore some of the top-performing pretrained models, such as VGG, Inception,
    MobileNetV2, and EfficientNet. These models have been pretrained for image classification
    tasks. Let’s see how they will fare on the given task.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将预训练模型应用于相关的使用场景，从而可能提高准确性并加快收敛速度。然而，如果源领域和目标领域不相关，迁移学习可能不仅失败，还可能由于学习到的特征不相关，反而损害目标任务的性能，这种情况称为负迁移。让我们将迁移学习应用于一个真实世界的图像分类任务。我们将探索一些表现最好的预训练模型，如VGG、Inception、MobileNetV2和EfficientNet。这些模型已经为图像分类任务进行了预训练。让我们看看它们在给定任务中的表现如何。
- en: Building a real-world image classifier with Transfer learning
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用迁移学习构建一个真实世界的图像分类器
- en: In this case study, your company secured a medical project, and you are assigned
    the responsibility to build a pneumonia classifier for GETWELLAI. You have been
    provided with over 5,000 X-ray JPEG images, made up of two categories (pneumonia
    and normal). The dataset was annotated by expert physicians and low-quality images
    have been removed. Let's see how we can tackle this problem using the two types
    of transfer learning techniques we have discussed so far.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，你的公司获得了一个医疗项目，你被指派负责为 GETWELLAI 构建一个肺炎分类器。你已经获得了超过 5000 张 X 射线 JPEG
    图像，包含两类（肺炎和正常）。数据集由专业医生标注，低质量的图像已被移除。让我们看看如何使用我们迄今为止讨论的两种迁移学习技术来解决这个问题。
- en: Loading the data
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Perform the following steps to load the data:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以加载数据：
- en: 'As usual, we start by loading the necessary libraries that we will need for
    our project:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和往常一样，我们首先加载我们项目所需的必要库：
- en: '[PRE0]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, let''s load the X-ray dataset. To do this, we will use the `wget` command
    to download the file from the specified URL:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们加载 X 射线数据集。为此，我们将使用 `wget` 命令从指定的 URL 下载文件：
- en: '[PRE14]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The downloaded file is saved in the current working directory of our Colab instance
    as a ZIP file, which contains a dataset of the X-ray images.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载的文件作为 ZIP 文件保存在我们 Colab 实例的当前工作目录中，文件中包含 X 射线图像的数据集。
- en: 'Next, we will extract the contents of the `zip` folder by running the following
    code:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过运行以下代码来提取 `zip` 文件夹的内容：
- en: '[PRE15]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When we run the code, we extract a `dataset` folder that holds `test`, `val`,
    and `train` sub-directories, with each sub-directory holding data for both normal
    and pneumonia X-ray images, as shown in *Figure 9**.4*:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们将提取一个名为 `dataset` 的文件夹，其中包含 `test`、`val` 和 `train` 子目录，每个子目录中都有正常和肺炎
    X 射线图像的数据，如 *图 9.4* 所示：
- en: '![Figure 9.4 – A snapshot of the current working directory that holds the extracted
    ZIP file](img/B18118_09_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.4 – 当前工作目录的快照，包含已提取的 ZIP 文件](img/B18118_09_04.jpg)'
- en: Figure 9.4 – A snapshot of the current working directory that holds the extracted
    ZIP file
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – 当前工作目录的快照，包含已提取的 ZIP 文件
- en: 'We will use the following code block to extract the sub-directories and the
    number of images in them. We also saw this code block in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*,*
    *Handling Overfitting*:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用以下代码块来提取子目录及其中文件的数量。我们在 [*第 8 章*](B18118_08.xhtml#_idTextAnchor186)*,*
    *处理过拟合* 中也看到了这段代码块：
- en: '[PRE16]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: It gives us a snapshot of the data in each folder and a sense of the data distribution.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 它为我们提供了每个文件夹中数据的快照，并让我们对数据的分布有一个大致了解。
- en: 'Next, we will use the `view_random_images` function to display some random
    images and their shapes from the `train` directory:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 `view_random_images` 函数从 `train` 目录显示一些随机图像及其形状：
- en: '[PRE21]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: When we run the code, we will get a result similar to *Figure 9**.5*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，结果将类似于 *图 9.5*。
- en: '![Figure 9.5 – Random images displayed from the training samples of the X-ray
    dataset](img/B18118_09_05.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.5 – 从 X 射线数据集的训练样本中随机显示的图像](img/B18118_09_05.jpg)'
- en: Figure 9.5 – Random images displayed from the training samples of the X-ray
    dataset
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – 从 X 射线数据集的训练样本中随机显示的图像
- en: 'We will create an instance of the `ImageDataGenerator` class for our training
    and validation data. We will add the `rescale` parameter to rescale our images
    and ensure that all the pixel values are within the range of 0 to 1\. We do this
    to improve stability and enhance convergence during the training process. The
    resulting `train_datagen` and `valid_datagen` objects are used to generate batches
    of training and validation data, respectively:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为训练数据和验证数据创建一个 `ImageDataGenerator` 类的实例。我们将添加 `rescale` 参数来重新调整图像的大小，确保所有像素值都在
    0 到 1 之间。这样做是为了提高稳定性，并增强训练过程中的收敛性。生成的 `train_datagen` 和 `valid_datagen` 对象分别用于生成训练数据和验证数据的批次：
- en: '[PRE23]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Next, we set up the `train`, `validation`, and `test` directories.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们设置 `train`、`validation` 和 `test` 目录。
- en: '[PRE25]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We used the `flow_from_directory()` method to load images from the training
    directory. The `target_size` argument is used to resize all the images to 224
    x 224 pixels. One key difference between this code and the one we used in [*Chapter
    8*](B18118_08.xhtml#_idTextAnchor186)*, Handling Overfitting* is that the class
    mode argument is set to `binary` because we are dealing with a binary classification
    problem (i.e., normal and pneumonia):'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`flow_from_directory()`方法从训练目录加载图像。`target_size`参数用于将所有图像调整为224 x 224像素。与我们在[*第8章*](B18118_08.xhtml#_idTextAnchor186)*，过拟合处理*中使用的代码相比，一个关键的不同是`class_mode`参数设置为`binary`，因为我们处理的是二分类问题（即正常和肺炎）：
- en: '[PRE29]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `valid_data` and `test_data` generators are quite similar to the `train_data`
    generator, as they both have their target size set to 224 x 224 as well; the key
    difference is they have set `shuffle` to `false`, which means the images will
    not be shuffled. If we set this to `true`, the images get shuffled.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`valid_data`和`test_data`生成器与`train_data`生成器非常相似，因为它们的目标大小也设置为224 x 224；关键区别在于它们将`shuffle`设置为`false`，这意味着图像不会被打乱。如果我们将其设置为`true`，图像将会被打乱。'
- en: Modeling
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模
- en: 'We will start by using the same model we applied in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*,
    Handling Overfitting*. To avoid redundancy, let’s focus on the fully connected
    layer, where we have one neuron in the output layer, as this is a binary classification
    task. We will compare the result with using transfer learning:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从使用在[*第8章*](B18118_08.xhtml#_idTextAnchor186)*，过拟合处理*中应用的相同模型开始。为了避免重复，我们将专注于全连接层，在该层中，输出层有一个神经元，因为这是一个二分类任务。我们将与使用迁移学习的结果进行比较：
- en: '[PRE41]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: In this case, we have one neuron in the output layer, and we changed the activation
    function to a sigmoid function, since we are building a binary classifier. In
    the compile step, we also change the loss function to binary cross entropy; everything
    else remains the same. Then, we fit the model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，输出层有一个神经元，并且我们将激活函数更改为sigmoid函数，因为我们正在构建一个二分类器。在编译步骤中，我们还将损失函数更改为二元交叉熵；其他部分保持不变。然后，我们进行模型拟合。
- en: 'The training ends on the 7th epoch, as the validation loss fails to drop further:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在第7个周期结束，因为验证损失未能进一步下降：
- en: '[PRE42]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'On the fifth epoch, the model reached a validation accuracy of 100 percent,
    which looks promising. Let’s evaluate the model:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在第五个周期，模型达到了100%的验证准确率，看起来很有希望。让我们评估一下模型：
- en: '[PRE43]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: When we evaluate the model on test data, we recorded only an accuracy of 0.7580\.
    This points to signs of overfitting. Of course, we can try a combination of the
    ideas we learned in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*, Handling
    Overfitting* to improve the model’s performance and you are encouraged to do so.
    However, let's learn how to use pre-trained models and see whether we can transfer
    the knowledge gained by these models to our use case and, if possible, get better
    results. Let’s do that next.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在测试数据上评估模型时，我们记录的准确率只有0.7580。这表明模型可能存在过拟合的迹象。当然，我们可以尝试结合在[*第8章*](B18118_08.xhtml#_idTextAnchor186)*，过拟合处理*中学到的想法来提高模型的性能，并且鼓励你这么做。然而，让我们学习如何使用预训练模型，看看是否能够将这些模型获得的知识迁移到我们的应用场景中，并且如果可能的话，取得更好的结果。接下来我们就来做这个。
- en: Modeling with transfer learning
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习建模
- en: 'In this section, we will utilize three widely used pre-trained CNNs for image
    classification – VGG16, InceptionV3, and MobileNet. We will demonstrate the application
    of transfer learning as a feature extractor using these models, followed by adding
    a fully connected layer for label classification. We will also learn how to fine-tune
    a pre-trained model by unfreezing some of its layers. Before we can use these
    models, we need to import them. We can do this using a single line of code:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用三种广泛应用的预训练CNN进行图像分类——VGG16、InceptionV3和MobileNet。我们将展示如何通过这些模型作为特征提取器应用迁移学习，接着添加一个全连接层进行标签分类。我们还将学习如何通过解冻部分层来微调预训练模型。在使用这些模型之前，我们需要导入它们。我们可以通过一行代码来实现：
- en: '[PRE44]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Now that we have our models and we are set to go, let’s begin with VGG16.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了模型并准备好开始，让我们从VGG16开始。
- en: VGG16
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VGG16
- en: VGG16 is a CNN architecture developed by the Visual Geometry Group at the University
    of Oxford. It was trained on the ImageNet dataset. The VGG16 architecture secured
    second place in the image classification category in the ImageNet Challenge 2014
    submission. VGG16 is made up of 13 (a 3 x 3 filter) convolutional layers, 5 (2x2)
    max-pooling layers, and 3 fully connected layers, as illustrated in *Figure 9**.6*.
    This gives us 16 layers with learnable parameters; recall that max-pooling layers
    are for dimensionality reduction and they have no weight. This one takes an input
    tensor of the 224 x 224 RGB image.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16是由牛津大学视觉几何组开发的CNN架构。它是在ImageNet数据集上训练的。VGG16架构在2014年ImageNet挑战赛的图像分类类别中获得了第二名。VGG16由13个（3
    x 3卷积核）卷积层，5个（2x2）最大池化层和3个全连接层组成，如*图9.6*所示。这使我们得到了16层可学习参数；请记住，最大池化层用于降维，它们没有权重。该模型接收224
    x 224 RGB图像的输入张量。
- en: '![Figure 9.6 – The VGG16 model’s architecture (Source: https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765)](img/B18118_09_06.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图9.6 – VGG16模型架构（来源：https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765）](img/B18118_09_06.jpg)'
- en: 'Figure 9.6 – The VGG16 model’s architecture (Source: https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 – VGG16模型架构（来源：https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765）
- en: 'Let''s begin by loading VGG16 from Keras. We want to load the model and use
    pre-trained weights from the ImageNet dataset. To do this, we set the `weights`
    parameter to `imagenet`; we also set the `include_top` parameter to `false`. This
    is done because we want to use the model as a feature extractor. This way, we
    can add our own custom-made, fully connected layers for classification. We set
    the input size to (224,224,3) as this is the input image size that VGG16 expects:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始从Keras加载VGG16。我们想加载该模型并使用从ImageNet数据集获得的预训练权重。为此，我们将`weights`参数设置为`imagenet`；我们还将`include_top`参数设置为`false`。这样做是因为我们想将该模型用作特征提取器。通过这种方式，我们可以添加自定义的全连接层用于分类。我们将输入大小设置为(224,224,3)，因为这是VGG16期望的输入图像大小：
- en: '[PRE45]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The next step enables us to freeze the weights of the model because we want
    to use VGG 16 as a feature extractor. When we freeze all the layers, this makes
    them untrainable, which means their weights will not be updated during training:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步使我们能够冻结模型的权重，因为我们想要使用VGG16作为特征提取器。当我们冻结所有层时，这使它们变为不可训练，这意味着它们的权重在训练过程中不会更新：
- en: '[PRE46]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The next code block creates a new sequential model that uses VGG as its top
    layer, after which we add a fully connected layer made up of a dense layer with
    1,024 neurons, a dropout layer, and an output layer with one neuron, and then
    we set the activation to sigmoid for binary classification:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个代码块创建了一个新的顺序模型，使用VGG作为其顶层，然后我们添加一个由1,024个神经元的密集层、一个Dropout层和一个输出层（包含一个神经元）组成的全连接层，并将激活函数设置为sigmoid，以进行二分类：
- en: '[PRE47]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We compile and fit our model to the data:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编译并将模型拟合到数据上：
- en: '[PRE48]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In four epochs, our model stops training. It reaches a training accuracy of
    0.9810 but on the validation set, we get an accuracy of 0.875:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在四个时期后，我们的模型停止了训练。它达到了0.9810的训练准确率，但在验证集上，我们得到了0.875的准确率：
- en: '[PRE49]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: When we evaluate the model, we reach an accuracy of 84.29\. Now, let's use another
    pre-trained model as a feature extractor.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们评估模型时，达到了84.29的准确率。现在，让我们使用另一个预训练模型作为特征提取器。
- en: MobileNet
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MobileNet
- en: MobileNet is a lightweight CNN model developed by engineers at Google. The model
    is light and efficient, making it a choice model to develop mobile and embedded
    vision apps. Like VGG16, MobileNet was also trained on the ImageNet dataset, and
    it was able to achieve state-of-the-art results. MobileNet has a streamlined architecture
    that makes use of depth-wise separable convolutions. The underlining idea is to
    reduce the number of parameters required during training while maintaining accuracy.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: MobileNet是由谷歌的工程师开发的轻量级CNN模型。该模型轻巧高效，是开发移动和嵌入式视觉应用的首选模型。与VGG16类似，MobileNet也在ImageNet数据集上进行了训练，并能够取得最先进的结果。MobileNet采用了一种简化的架构，利用了深度可分离卷积。其基本理念是在保持准确率的同时，减少训练所需的参数数量。
- en: 'To apply MobileNet as a feature extractor, the steps are similar to what we
    just did with VGG16; hence, let’s look at the code block. We will load the model,
    freeze the layers, and add a fully connected layer as before:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将MobileNet作为特征提取器，步骤与我们刚才使用VGG16时类似；因此，让我们来看一下代码块。我们将加载模型，冻结层，并像之前一样添加一个全连接层：
- en: '[PRE50]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Next, we compile and fit the model:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们编译并拟合模型：
- en: '[PRE51]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'In just four epochs, the model reaches a validation accuracy of 87.50%:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 仅经过四个周期，模型达到了87.50%的验证准确率：
- en: '[PRE52]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Next, let's try fine-tuning a pre-trained model hands-on.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们亲自尝试微调一个预训练模型。
- en: Transfer learning as a fine-tuned model
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将转移学习作为微调模型
- en: InceptionV3 is another CNN architecture developed by Google. It combines 1x1
    and 3x3 filters to capture different aspects of an image. Let’s unfreeze some
    layers of this pre-trained model so that we can train both the layers we unfroze
    and the fully connected layer.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: InceptionV3是Google开发的另一种CNN架构。它结合了1x1和3x3的滤波器，以捕捉图像的不同方面。让我们解冻一些层，这样我们就可以训练这些解冻的层以及全连接层。
- en: 'First, we will load the InceptionV3 model. We set `include_top=False` to remove
    the classification layer of InceptionV3 and use weights from ImageNet. We unfreeze
    the last 50 layers by setting `trainable` to `true` for these layers. This enables
    us to train these layers on the X-ray dataset:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将加载InceptionV3模型。我们设置`include_top=False`以去除InceptionV3的分类层，并使用来自ImageNet的权重。我们通过将这些层的`trainable`设置为`true`来解冻最后50层。这使得我们能够在X光数据集上训练这些层：
- en: '[PRE53]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Note:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：
- en: Unfreezing and fine-tuning too many layers on a small dataset is a bad strategy,
    as this can lead to overfitting.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在小数据集上解冻和微调过多的层并不是一个好策略，因为这可能导致过拟合。
- en: 'We will create, fit, and compile the model, as we have done so far, and the
    new model reaches a validation accuracy of 100 percent on the fifth epoch:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像之前那样创建、拟合和编译模型，并且新模型在第五个周期达到了100%的验证准确率：
- en: '[PRE54]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Next, let''s evaluate the models using our `evaluate_models` helper function:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用`evaluate_models`辅助函数评估这些模型：
- en: '![Figure 9.7 – An evaluation result from our experiments](img/B18118_09_07.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.7 – 我们实验的评估结果](img/B18118_09_07.jpg)'
- en: Figure 9.7 – An evaluation result from our experiments
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – 我们实验的评估结果
- en: From the results in *Figure 9**.7*, MobileNet, VGG16, and InceptionV3 came out
    on top. We can see that these models performed much better than our baseline model
    (**model 1**). We also report the results of a few other models from our notebook.
    We can spot signs of overfitting; hence, you can combine some of the ideas we
    discussed in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*, Handling Overfitting*
    to improve your result.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 9.7*的结果来看，MobileNet、VGG16和InceptionV3表现最佳。我们可以看到这些模型的表现远远超过了我们的基准模型（**模型1**）。我们还报告了来自笔记本的其他一些模型的结果。我们能观察到过拟合的迹象；因此，你可以结合我们在[*第8章*](B18118_08.xhtml#_idTextAnchor186)中讨论的*处理过拟合*的部分来改进结果。
- en: Summary
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Transfer learning has gained traction in the deep learning community, due to
    its improved performance, speed, and accuracy in building deep learning models.
    We discussed the rationale behind transfer learning and explored transfer learning
    as a feature extractor and a fine-tuned model. We built a couple of solutions
    using the top-performing pre-trained models and saw how they outperformed our
    baseline model when applied to the X-ray dataset.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习在深度学习社区中获得了广泛关注，因为它在构建深度学习模型时提高了性能、速度和准确度。我们讨论了转移学习的原理，并探索了将转移学习作为特征提取器和微调模型。我们使用表现最好的预训练模型构建了一些解决方案，并看到它们在应用于X光数据集时超越了我们的基准模型。
- en: By now, you should have gained a solid understanding of transfer learning and
    its applications. Equipped with this knowledge, you should be able to apply transfer
    learning as either a feature extractor or a fine-tuned model when building real-world
    deep learning solutions for a wide range of tasks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经对转移学习及其应用有了扎实的理解。掌握了这些知识后，你应该能够在为各种任务构建现实世界的深度学习解决方案时，将转移学习应用于特征提取器或微调模型。
- en: With this, we have come to the end of this chapter and this section of the book.
    In the next chapter, we will discuss **natural language processing** (**NLP**),
    where we will build exciting NLP applications using TensorFlow.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 到此，我们已结束本章及本书的这一部分。在下一章中，我们将讨论**自然语言处理**（**NLP**），届时我们将使用TensorFlow构建令人兴奋的NLP应用。
- en: Questions
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Let’s test what we learned in this chapter:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下本章所学内容：
- en: Using the test notebook, load the cat and dog dataset.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试笔记本，加载猫狗数据集。
- en: Preprocess the image data using the image data generator.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用图像数据生成器对图像数据进行预处理。
- en: Use a VGG16 model as a feature extractor and build a new CNN model.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用VGG16模型作为特征提取器，并构建一个新的CNN模型。
- en: Unfreeze 40 layers of an InceptionV3 model and build a new CNN model.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解冻InceptionV3模型的40层，并构建一个新的CNN模型。
- en: Evaluate both the VGG16 and InceptionV3 models.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估VGG16和InceptionV3模型。
- en: Further reading
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more, you can check out the following resources:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多内容，您可以查看以下资源：
- en: 'Kapoor, A., Gulli, A. and Pal, S. (2020) *Deep Learning with TensorFlow and
    Keras Third Edition: Build and deploy supervised, unsupervised, deep, and reinforcement
    learning models*. Packt Publishing Ltd.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kapoor, A., Gulli, A. 和 Pal, S. (2020) *与TensorFlow和Keras的深度学习第三版：构建和部署监督学习、无监督学习、深度学习和强化学习模型*。Packt
    Publishing Ltd.
- en: '*Adapting Deep Convolutional Neural Networks for Transfer Learning: A Comparative
    Study* by C. M. B. Al-Rfou, G. Alain, and Y. Bengio, published in arXiv preprint
    arXiv:1511.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*将深度卷积神经网络适应于迁移学习：一项比较研究*，由C. M. B. Al-Rfou、G. Alain和Y. Bengio编写，发表于arXiv预印本arXiv:1511。'
- en: '*Very Deep Convolutional Networks for Large-Scale Image Recognition* by K.
    Simonyan and A. Zisserman, published in arXiv preprint arXiv:1409.1556 in 2014.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*非常深的卷积神经网络用于大规模图像识别*，由K. Simonyan和A. Zisserman编写，发表于2014年arXiv预印本arXiv:1409.1556。'
- en: '*EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks*
    by M. Tan and Q. Le, published in *International Conference on Machine Learning*
    in 2019.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*EfficientNet：重新思考卷积神经网络模型缩放*，由M. Tan和Q. Le编写，发表于2019年*国际机器学习大会*。'
- en: '*MobileNetV2: Inverted Residuals and Linear Bottlenecks* by M. Sandler, A.
    Howard, M. Zhu, A. Zhmoginov, and L. Chen, published in arXiv preprint arXiv:1801.04381
    in 2018.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MobileNetV2：反向残差和线性瓶颈*，由M. Sandler、A. Howard、M. Zhu、A. Zhmoginov和L. Chen编写，发表于2018年arXiv预印本arXiv:1801.04381。'
- en: '*DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition*
    by Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., & Darrell,
    T. (2014).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DeCAF：一种用于通用视觉识别的深度卷积激活特征*，由Donahue, J., Jia, Y., Vinyals, O., Hoffman, J.,
    Zhang, N., Tzeng, E. 和 Darrell, T.（2014）编写。'
- en: '*Harnessing the power of transfer learning for medical image classification*
    by Ryan Burke, *Towards Data* *Science*. [https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7](https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*利用迁移学习的力量进行医学图像分类*，作者：Ryan Burke，*Towards Data* *Science*。 [https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7](https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7)'
- en: Part 3 – Natural Language Processing with TensorFlow
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分 – 使用TensorFlow进行自然语言处理
- en: In this part, you will learn to build **natural language processing** (**NLP**)
    applications with TensorFlow. You will understand how to perform text processing
    and build models for text classification. In this part, you will also learn to
    generate text using LSTMs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分中，您将学习如何使用TensorFlow构建**自然语言处理**（**NLP**）应用程序。您将了解如何进行文本处理，并构建文本分类模型。在本部分中，您还将学习如何使用LSTM生成文本。
- en: 'This section comprises the following chapters:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 10*](B18118_10.xhtml#_idTextAnchor226), *Introduction to Natural
    Language Processing*'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B18118_10.xhtml#_idTextAnchor226)，*自然语言处理简介*'
- en: '[*Chapter 11*](B18118_11.xhtml#_idTextAnchor267), *NLP with TensorFlow*'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B18118_11.xhtml#_idTextAnchor267)，*使用TensorFlow进行NLP*'
