- en: Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络
- en: In this chapter, we will get an overview on neural networks. We will see what
    a simple shallow neural network is and get some familiarity with how they work.
    We will do this by trying to identify the genre of a song using a shallow neural
    network. We will also recall our previous work on the spam detector to use the
    neural network. Further on, we will take a look at larger neural networks, known
    as **deep learning**, and apply what is known as a convolutional neural network
    to identify handwritten mathematical symbols. Finally we will revisit the bird
    species identifier covered previously and use deep learning to produce a much
    more accurate identifier.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将对神经网络进行概述。我们将了解什么是简单的浅层神经网络，并对它们的工作原理有一些了解。我们将通过尝试使用浅层神经网络识别歌曲的风格来进行实践。同时，我们还将回顾之前使用神经网络进行垃圾邮件检测器工作的经验。之后，我们将研究更大的神经网络，称为**深度学习**，并应用卷积神经网络来识别手写的数学符号。最后，我们将重新审视之前讨论的鸟类物种识别器，并使用深度学习来生成一个更加准确的识别器。
- en: 'The topics that we will be covering in this chapter are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖的主题如下：
- en: Understanding neural networks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解神经网络
- en: Identifying the genre of a song using neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络识别歌曲的风格
- en: Recalling our work on the spam detector to use neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾我们在使用神经网络进行垃圾邮件检测器的工作
- en: Understanding neural networks
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解神经网络
- en: Neural networks, which were originally called artificial neural networks, are
    inspired by actual neurons found in animal's brains and other parts of the nervous
    system. Neurons are connected to each other and they receive and send impulses
    throughout the animal's body, or in the case of computing, the network.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络，最初称为人工神经网络，灵感来自于动物大脑及其他神经系统部分中的实际神经元。神经元彼此连接，接收并发送冲动信号，通过动物的身体或计算机中的网络传递。
- en: 'The following diagram shows the components of a single neuron:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了单个神经元的组成部分：
- en: '![](img/00125.jpeg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00125.jpeg)'
- en: Components of a single neuron
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 单个神经元的组成部分
- en: 'The following graph shows how a neuron fires:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了神经元是如何发放信号的：
- en: '![](img/00126.jpeg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00126.jpeg)'
- en: How a neuron fires
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元是如何发放信号的
- en: It is all or nothing, meaning, when the neuron gets enough input from its neighbors,
    it quickly fires and sends a signal down its axon to each forward-connected neuron.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 它是“全或无”的意思，也就是说，当神经元从其邻居那里获得足够的输入时，它会迅速发放信号，并将信号沿着轴突传送给每个前馈连接的神经元。
- en: 'Here, we can see actual neurons in a brain:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到大脑中的实际神经元：
- en: '![](img/00127.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00127.jpeg)'
- en: Actual neurons in a brain
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大脑中的实际神经元
- en: A human brain has about 100 billion neurons all together, and has about 100
    trillion connections. It is worth noting that the neural networks we create in
    software have at least 1 million times less complexity.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 人类大脑总共有大约1000亿个神经元，并且约有100万亿个连接。值得注意的是，我们在软件中创建的神经网络的复杂度至少低于1百万倍。
- en: Feed-forward neural networks
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前馈神经网络
- en: 'Most of the neural networks that we design are feed forward and fully connected.
    This means that every neuron connects to every neuron in the next layer. The first
    layer receives inputs and the last layer gives outputs. The structure of the network,
    meaning the neuron counts and their connections, is decided ahead of time and
    cannot change, at least not during training. Also, every input must have the same
    number of values. This means that images, for example, may need to be resized
    to match the number of input neurons. The number of neurons in each layer is that
    layer''s shape:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计的大多数神经网络都是前馈的，并且是完全连接的。这意味着每个神经元都会连接到下一层的每个神经元。第一层接收输入，最后一层给出输出。网络的结构，包括神经元数量及其连接，是预先决定的，在训练过程中无法更改。此外，每个输入必须具有相同数量的值。这意味着图像等内容可能需要调整大小，以匹配输入神经元的数量。每一层神经元的数量就是该层的形状：
- en: '![](img/00128.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00128.jpeg)'
- en: Feed-forward neural design
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈神经网络设计
- en: Each individual neuron adds up the values it receives from the prior layer.
    Each connection from one neuron to the next has a weight. When adding the inputs,
    the inputs are multiplied by the respective weights. Each neuron also has an extra
    input called a **bias**, which is not connected to any other neurons. Once the
    weighted inputs have been added, an activation function is applied to the sum.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每个神经元会将它从前一层接收到的值累加起来。每个神经元之间的连接都有一个权重。在加和输入时，输入会与相应的权重相乘。每个神经元还有一个额外的输入，称为**偏置**，它与其他神经元没有连接。一旦加权输入值被累加，激活函数会应用于该和。
- en: 'There are several common activation functions, for example, the hyperbolic
    tangent, whose shape is shown here:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种常见的激活函数，例如双曲正切，其形状如下所示：
- en: '![](img/00129.jpeg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00129.jpeg)'
- en: Hyperbolic tangent
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 双曲正切
- en: The output of each neuron is whatever comes out of the activation function.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个神经元的输出是激活函数的结果。
- en: The connection waits in a network start random and are adjusted during training.
    The purpose of training is to examine hundreds, or thousands, or even more example
    cases and adjust the network's weights until the network is sufficiently accurate.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 网络中的连接权重开始时是随机的，并在训练过程中进行调整。训练的目的是通过检查成百上千甚至更多的示例案例，调整网络的权重，直到网络足够准确。
- en: 'After training, we have a network structure that we have already defined, and
    all the weights that were learned during training. As such, the following is true:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 训练结束后，我们得到一个已经定义好的网络结构，并且所有在训练中学到的权重。因此，以下内容是正确的：
- en: '*A trained neural network = Structure + Learned weights*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练过的神经网络 = 结构 + 学到的权重*'
- en: 'This is shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示：
- en: '![](img/00130.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00130.jpeg)'
- en: Network structure after training with weights
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后带有权重的网络结构
- en: Now the network is ready to use on new data outside the training set.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，网络已经准备好应用于训练集之外的新数据。
- en: 'Training proceeds in batches, which means that several training cases are sent
    through the network and the outputs, called **predictions**, are collected. Then,
    the loss is computed for each batch, which is the measure of the overall error:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是按批次进行的，这意味着将多个训练样本送入网络，收集输出结果，称为**预测**。然后，计算每个批次的损失，损失是总体误差的衡量标准：
- en: '![](img/00131.jpeg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00131.jpeg)'
- en: 'Training procedure: evaluate a batch, adjust weights, and repeat'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程：评估一个批次，调整权重，然后重复
- en: Each weight in the network is then adjusted depending on whether and how much
    that weight contributed to the overall loss. With very gradual adjustments, it
    should be the case that when examples in this batch are visited again, predictions
    will be more accurate.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，网络中的每个权重都会根据它对总体损失的贡献程度进行调整。通过非常渐进的调整，应该能确保当这个批次的示例再次被访问时，预测会更准确。
- en: The network is often trained over several epochs. By an epoch, we mean all the
    training data having been processed once. So, 10 epochs means looking at the same
    training data 10 times. We often segregate 20% or so of the training data as a
    validation set. This is data that we don't use during training and instead only
    use to evaluate the model after each epoch.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 网络通常会在多个周期（epoch）中进行训练。一个周期意味着所有训练数据都已处理一次。因此，10个周期意味着对相同的训练数据查看10次。我们通常会将大约20%的训练数据分离出来作为验证集。这部分数据在训练过程中不会使用，只会在每个周期后用于评估模型。
- en: Ideally, we want the network to become more accurate, which means we want to
    decrease loss, and this should be true for both the training set and the validation
    set.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望网络变得更加准确，这意味着我们希望减少损失，这对于训练集和验证集都应适用。
- en: 'The following set of graph shows this ideal kind of behavior:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下一组图表显示了这种理想行为：
- en: '![](img/00132.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00132.jpeg)'
- en: Ideal behavior
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 理想行为
- en: Note the signs of overfitting, meaning training loss goes down but validation
    loss goes up.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意过拟合的迹象，即训练损失下降，但验证损失上升。
- en: If the network is not designed correctly, for example, if it has too many layers,
    the network may overfit, meaning it performs very well in the training set but
    poorly on the validation set. This is an issue because ultimately we want to use
    the neural network on new data from the real world, which will probably be a little
    different than the training set, hence we use a validation set to see how well
    the network performs on data it didn't see for training.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果网络设计不正确，例如网络层数过多，可能会发生过拟合，这意味着网络在训练集上表现很好，但在验证集上表现差。这是一个问题，因为最终我们希望将神经网络应用于来自真实世界的新数据，这些数据可能与训练集略有不同，因此我们使用验证集来查看网络在未见过的训练数据上的表现。
- en: Identifying the genre of a song with neural networks
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络识别歌曲的类型
- en: In this section, we're going to build a neural network that can identify the
    genre of a song. We will use the GTZAN Genre Collection ([http://marsyasweb.appspot.com/download/data_sets/.GTZAN
    Genre Collection](http://marsyasweb.appspot.com/download/data_sets/.)). It has
    1,000 different songs from over 10 different genres. There are 100 songs per genre
    and each song is about 30 seconds long.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将构建一个神经网络来识别歌曲的流派。我们将使用GTZAN流派集（[http://marsyasweb.appspot.com/download/data_sets/.GTZAN
    Genre Collection](http://marsyasweb.appspot.com/download/data_sets/.)）。它包含来自10多种不同流派的1,000首歌曲。每种流派有100首歌曲，每首歌大约30秒长。
- en: We will use the  Python library, `librosa` to extract features from the songs.
    We will use **Mel-frequency cepstral coefficients** (**MFCC**). MFCC values mimic
    human hearing and they are commonly used in speech recognition applications as
    well as music genre detection. These MFCC values will be fed directly into the
    neural network.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Python库`librosa`来从歌曲中提取特征。我们将使用**Mel频率倒谱系数**（**MFCC**）。MFCC值模仿人类听觉，通常用于语音识别应用程序以及音乐流派检测。这些MFCC值将直接输入到神经网络中。
- en: To help us understand the MFCC, let's use two examples. Download Kick Loop 5
    by Stereo Surgeon. You can do this by visiting [https://freesound.org/people/Stereo%20Surgeon/sounds/266093/](https://freesound.org/people/Stereo%20Surgeon/sounds/266093/),
    and download Whistling by cmagar by visiting [https://freesound.org/people/grrlrighter/sounds/98195/](https://freesound.org/people/grrlrighter/sounds/98195/).
    One of them is a low-bass beat and the other is a higher pitched whistling. They
    are clearly different and we are going to see how they look different with MFCC
    values.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们理解MFCC，让我们使用两个示例。下载Stereo Surgeon的《Kick Loop 5》。你可以通过访问[https://freesound.org/people/Stereo%20Surgeon/sounds/266093/](https://freesound.org/people/Stereo%20Surgeon/sounds/266093/)来下载它，另外下载cmagar的《Whistling》可以通过访问[https://freesound.org/people/grrlrighter/sounds/98195/](https://freesound.org/people/grrlrighter/sounds/98195/)来获取。一个是低音鼓，另一个是高频口哨声。它们显然不同，我们将看看它们在MFCC值上有何区别。
- en: 'Let''s go to the code. First, we have to import the `librosa` library. We will
    also import `glob` because we are going to list the files in the different genre
    directories. Also, import `numpy` as usual. We will import `matplotlib` to draw
    the MFCC graphs. Then, will import the Sequential model from Keras. This is a
    typical feed-forward neural network. Finally, we will import the dense neural
    network layer, which is just a layer that has a bunch of neurons in it:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入代码部分。首先，我们需要导入`librosa`库。我们还需要导入`glob`，因为我们将列出不同类型目录中的文件。另外，像往常一样导入`numpy`。我们将导入`matplotlib`来绘制MFCC图表。然后，从Keras导入Sequential模型。这是一个典型的前馈神经网络。最后，我们将导入全连接神经网络层，它只是一个包含许多神经元的层：
- en: '![](img/00133.jpeg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00133.jpeg)'
- en: Unlike a convolution, for example, it's going to have 2D representations. We
    are going to use import activation, which allows us to give each neuron layer
    an activation function, and we will also import `to_categorical`, which allows
    us to turn the class names into things such as rock, disco, and so forth, which
    is what's called one-hot encoding.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 与卷积不同，它将有二维表示。我们将导入激活函数，它允许我们为每个神经元层指定激活函数，还将导入`to_categorical`，它允许我们将类名转换为诸如摇滚、迪斯科等内容，这就是所谓的独热编码（one-hot
    encoding）。
- en: 'We have officially developed a helper function to display the MFCC values:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经正式开发了一个辅助函数来显示MFCC值：
- en: '![](img/00134.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00134.jpeg)'
- en: First, we will load the song and then extract the MFCC values from it. Then,
    we'll use the `specshow`, which is a spectrogram show from the `librosa` library.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将加载歌曲并从中提取MFCC值。接着，我们将使用`specshow`，这是`librosa`库中的一个频谱图显示工具。
- en: 'Here''s the kick drum:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是低音鼓：
- en: '![](img/00135.jpeg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00135.jpeg)'
- en: We can see that at low frequency, the bass is very obvious and the rest of the
    time it's kind of like a wash. Not many other frequencies are represented.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在低频时，低音非常明显，其他频率几乎没有表现出来。
- en: 'However, if we look at the whistling, it''s pretty clear that there''s higher
    frequencies being represented:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们看一下口哨声，很明显可以看到高频成分的表现：
- en: '![](img/00136.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00136.jpeg)'
- en: The darker the color, or closer to red, the more power is in that frequency
    range at that time. So, you can even see the kind of change in frequency with
    the whistles.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色越深，或者越接近红色，表示在该时间点该频率范围内的能量越大。所以，你甚至可以看到口哨声时频率的变化。
- en: 'Now, here is the frequency for disco songs:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是迪斯科歌曲的频率：
- en: '![](img/00137.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00137.jpeg)'
- en: 'This is the frequency output:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是频率输出：
- en: '![](img/00138.jpeg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00138.jpeg)'
- en: You can sort of see the beats in the preceding outputs, but they're only 30
    seconds long, so it is a little bit hard to see the individual beats.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在前面的输出中大致看到节拍，但它们只有30秒长，所以很难看清单独的节拍。
- en: 'Compare this with classical where there are not so much beats as a continuous
    kind of bassline such as one that would come from a cello, for example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 将此与古典音乐进行比较，古典音乐中并不像嘻哈那样有明显的节拍，而是连续的低音线，例如大提琴所发出的那种低音线：
- en: '![](img/00139.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00139.jpeg)'
- en: 'Here is the frequency for hip-hop songs:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是嘻哈歌曲的频率：
- en: '![](img/00140.jpeg)![](img/00141.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00140.jpeg)![](img/00141.jpeg)'
- en: It looks kind of similar to disco, but if it were required that we could tell
    the difference with our own eyes, we wouldn't really need a neural network because
    it'd probably be a relatively simple problem. So, the fact that we can't really
    tell the difference between these is not our problem, it's the neural network's
    problem.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来有点像迪斯科，但如果要求我们能够用肉眼区分这些，我们就不需要神经网络了，因为这可能是一个相对简单的问题。所以，无法用肉眼区分这些不是我们的问题，而是神经网络的问题。
- en: 'We have another auxiliary function here that again just loads the MFCC values,
    but this time we are preparing it for the neural network:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一个辅助函数，这次它只加载MFCC值，但这次我们是为神经网络做准备：
- en: '![](img/00142.jpeg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00142.jpeg)'
- en: We have loaded the MFCC values for the song, but because these values are between
    maybe negative 250 to positive 150, they are no good for a neural network. We
    don't want to feed in these large and small values. We want to feed in values
    near negative 1 and positive 1 or from 0 to 1\. Therefore, we are going to figure
    out what the max is, the absolute value for each song, and then divide all the
    values by that max. Also, the songs are a slightly different length, so we want
    to pick just 25,000 MFCC values. We have to be super certain that what we feed
    into the neural network is always the same size, because there are only so many
    input neurons and we can't change that once we've built the network.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经加载了这首歌的MFCC值，但由于这些值的范围可能在-250到+150之间，因此它们对神经网络没有帮助。我们不想输入这些大值和小值。我们希望输入接近-1和+1或从0到1之间的值。因此，我们将计算每首歌的最大值，即每个歌的绝对值，然后将所有值除以该最大值。此外，由于歌曲的长度略有不同，我们只想选择25,000个MFCC值。我们必须确保输入神经网络的内容始终具有相同的大小，因为神经网络的输入神经元数量是有限的，一旦建立了网络，我们就无法改变它。
- en: 'Next, we have a function called `generate _features_and_labels`, which will
    go through all the different genres and go through all the songs in the dataset
    and produce those MFCC values and the class names:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有一个名为`generate_features_and_labels`的函数，它将遍历所有不同的音乐流派，逐一处理数据集中的所有歌曲，并生成这些MFCC值和类别名称：
- en: '![](img/00143.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00143.jpeg)'
- en: As shown in the preceding screenshot, we will prepare a list for all the features
    and all the labels. Go through each of the 10 genres. For each genre, we will
    look at the files in that folder. The `'generes/'+genre+'/*.au'` folder shows
    how the dataset is organized. When we are processing that folder, there will be
    100 songs each for each file, we will extract the features and put those features
    in the `all_features.append(features)` list. The name of the genre for that song
    needs to be put  in a list also. So, at the end, all features will have 1,000
    entries and all labels will have 1,000 entries. In the case of all features, each
    of those 1,000 entries will have 25,000 entries. That will be a 1,000 x 25,000
    matrix.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，我们将为所有特征和标签准备一个列表。遍历10个流派。对于每个流派，我们将查看该文件夹中的文件。`'generes/'+genre+'/*.au'`文件夹展示了数据集的组织方式。当我们处理该文件夹时，每个文件将有100首歌，我们将提取特征并将这些特征放入`all_features.append(features)`列表中。这首歌的流派名称也需要放入一个列表中。因此，最终，所有特征将包含1,000个条目，所有标签也将包含1,000个条目。对于所有特征，每个1,000个条目将包含25,000个条目。这将是一个1,000
    x 25,000的矩阵。
- en: 'For all labels at the moment, there is a 1,000 entry-long list, and inside
    are words such as `blues`, `classical`, `country`, `disco`, `hiphop`, `jazz`,
    `metal`, `pop`, `reggae`, and `rock`. Now, this is going to be a problem because
    a neural network is not going to predict a word or even letters. We need to give
    it a one-hot encoding, which means that each word here is going to be represented
    as ten binary numbers. In the case of the blues, it is going to be one and then
    nine zeros. In the case of classical, it is going to be zero followed by one,
    followed by nine zeros, and so forth. First, we have to figure out all the unique
    names by using the `np.unique(all_labels, return_inverse=True)` command to get
    them back as integers. Then, we have to use `to_categorical`, which turns those
    integers into one-hot encoding. So, what comes back is 1000 x 10 dimensions. 1,000
    because there are 1,000 songs, and each of those has ten binary numbers to represent
    the one-hot encoding. Then, return all the features stacked together by the command
    return `np.stack(all_features), onehot_labels` into a single matrix, as well as
    the one-hot matrix. So, we will call that upper function and save the features
    and labels:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，对于所有标签，存在一个包含1,000个条目的列表，列表中包含诸如`blues`、`classical`、`country`、`disco`、`hiphop`、`jazz`、`metal`、`pop`、`reggae`和`rock`等词语。现在，这会成为一个问题，因为神经网络不会预测单个单词或字母。我们需要为其提供一个独热编码，这意味着这里的每个词将被表示为十个二进制数。例如，在“blues”情况下，它将是一个1，后面跟着九个0；在“classical”情况下，它将是一个0，后面跟着一个1，再后面跟着九个0，以此类推。首先，我们必须通过使用`np.unique(all_labels,
    return_inverse=True)`命令来找出所有独特的标签，并将其转换为整数。然后，我们需要使用`to_categorical`，它将这些整数转换为独热编码。返回的结果是1000
    x 10维的数组。1,000是因为有1,000首歌，每首歌都有十个二进制数来表示独热编码。然后，通过命令`return np.stack(all_features),
    onehot_labels`将所有特征堆叠到一个矩阵中，返回独热编码矩阵。因此，我们将调用该函数并保存特征和标签：
- en: '![](img/00144.jpeg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00144.jpeg)'
- en: 'Just to be sure, we will print the shape of the features and the labels as
    shown in the following screenshot. So, it is 1,000 by 25,000 for the features
    and 1,000 by 10 for the labels. Now, we will split the dataset into a train and
    test split. Let''s decide the 80% mark defined as `training_split= 0.8` to perform
    a split:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保无误，我们将打印特征和标签的形状，如下截图所示。特征的形状是1,000 x 25,000，标签的形状是1,000 x 10。现在，我们将把数据集拆分为训练集和测试集。我们将80%的数据作为训练集，定义为`training_split=
    0.8`来进行拆分：
- en: '![](img/00145.jpeg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00145.jpeg)'
- en: 'Before that, we will shuffle, and before we shuffle, we need to put the labels
    with the features so that they don''t shuffle in different orders. We will call
    `np.random.shuffle(alldata)` and do the shuffle, split it using `splitidx= int(len(alldata)*training_split)`,
    and then we will have train and testsets, as shown in the snapshot earlier. Looking
    at the shape of the train and the testsets, the train is 800, so 80% of the 1,000
    for the rows: we have 25,010 features. Those aren''t really all features, though.
    It is actually the 25,000 features plus the 10 for the one-hot encoding because,
    remember, we stacked those together before we shuffled. Therefore, we''re going
    to have to strip that back off. We can do that with `train_input = train[:,:-10]`.
    For both the train input and the test input, we take everything but the last 10
    columns, and for the labels, we take the 10 columns to the end, and then we can
    see what the shapes of the train input and train labels are. So now, we have the
    proper 800 by 25,000 and 800 by 10.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们需要先打乱数据，在打乱之前，我们需要将标签和特征配对，以确保它们不会以不同的顺序被打乱。我们将调用`np.random.shuffle(alldata)`来进行打乱，然后使用`splitidx
    = int(len(alldata)*training_split)`来拆分数据集，最终得到训练集和测试集，如前面的截图所示。查看训练集和测试集的形状，训练集有800条数据，即1,000的80%。每条数据有25,010个特征，但这些并不是真正的所有特征。实际上，它是25,000个特征加上10个用于独热编码的特征，因为记住，在打乱之前我们已经将它们堆叠在一起了。因此，我们需要将这部分数据去除。我们可以通过`train_input
    = train[:,:-10]`来完成。对于训练输入和测试输入，我们取所有列除了最后10列，对于标签，我们只取最后10列。然后，我们可以查看训练输入和训练标签的形状。现在，我们得到了正确的800
    x 25,000和800 x 10的形状。
- en: 'Next, we''ll build the neural network:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建神经网络：
- en: '![](img/00146.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00146.jpeg)'
- en: We are going to have a sequential neural network. The first layer will be a
    dense layers of 100 neurons. Now, just on the first layer, it matters that you
    give the input dimensions or the input shape, and that's going to be 25,000 in
    our case. This says how many input values are coming per example. Those 25,000
    are going to connect to the 100 in the first layer. The first layer will do its
    weighted sum of its inputs, its weights, and bias term, and then we are going
    to run the `relu` activation function. `relu`, if you recall, states that anything
    less than 0 will turn out to be a 0\. Anything higher than 0 will just be the
    value itself. These 100 will then connect to 10 more and that will be the output
    layer. It will be 10 because we have done someone-hot encoding and we have 10
    binary numbers in that encoding.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个顺序神经网络。第一层将是100个神经元的密集层。现在，仅在第一层中，输入的维度或输入形状是非常重要的，在我们的例子中，它是25000。这表示每个样本输入多少个值。这25000将会连接到第一层中的100个神经元。第一层会对输入进行加权求和，权重和偏置项，然后我们将运行`relu`激活函数。如果你还记得，`relu`表示任何小于0的值都会变成0，而任何大于0的值都将保持不变。这100个神经元将连接到另外10个神经元，这将是输出层。输出层将是10，因为我们已经进行了独热编码，并且在该编码中有10个二进制数字。
- en: The activation used in the code, `softmax`, says to take the output of the 10
    and normalize them so that they add up to 1\. That way, they end up being probabilities
    and whichever one of the 10 is the highest scoring, the highest probability, we
    take that to be the prediction and that will directly correspond to whichever
    position that highest number is in. For example, if it is in position 4, that
    would be disco (look in the code).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中使用的激活函数`softmax`表示将10个输出进行归一化，使它们的和为1。这样，它们就会变成概率，且在这10个概率中，得分最高的那个（即概率最大）将作为预测结果，并直接对应到得分最高的数字所在的位置。例如，如果最高的得分出现在第4个位置，那就表示是迪斯科（见代码中的说明）。
- en: 'Next, we will compile the model, choose an optimizer such as Adam, and define
    the `loss` function. Any time you have multiple outputs like we have here (we
    have 10), you probably want to do categorical cross-entropy and metrics accuracy
    to see the accuracy as it''s training and during evaluation, in addition to the
    loss, which is always shown: however, accuracy makes more sense to us. Next, we
    can print `model.summary`, which tells us details about the layers.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将编译模型，选择一个优化器，比如Adam，并定义`loss`损失函数。每当我们有多个输出（比如这里的10个输出）时，我们通常会选择分类交叉熵（categorical
    cross-entropy）和精度（accuracy）作为评估指标，以便在训练过程中和评估时查看精度，此外损失函数会始终显示：不过，精度对于我们来说更有意义。接着，我们可以打印`model.summary`，这会告诉我们关于各层的详细信息。
- en: 'It will look something like the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 它的执行结果大致如下：
- en: '![](img/00147.jpeg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00147.jpeg)'
- en: The output shape of the first 100 neuron layer is definitely 100 values because
    there are 100 neurons, and the output of the dense second layer is 10 because
    there are 10 neurons. So, why are there 2.5 million parameters, or weights, in
    the first layer? That's because we have 25,000 inputs. Well, we have 25,000 inputs
    and each one of those inputs is going to each one of the 100 dense neurons. So
    that's 2.5 million, and then plus 100, because each of those neurons in the 100
    has its own bias term, its own bias weight, and that needs to be learned as well.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个100个神经元层的输出形状肯定是100个值，因为有100个神经元，而第二层密集层的输出是10，因为有10个神经元。那么，为什么第一层有250万个参数或权重呢？那是因为我们有25000个输入。实际上，我们有25000个输入，每一个输入都连接到这100个密集神经元中的每一个。所以总数是250万个，再加上100，因为这100个神经元每个都有一个偏置项，自己的偏置权重，而这些也需要被学习。
- en: Overall, we have about 2.5 million parameters or weights. Next, we run the fit.
    It takes the training input and training labels, and takes the number of epochs
    that we want. We want 10, so that's 10 repeats over the trained input; it takes
    a batch size which says how many, in our case, songs to go through before updating
    the weights; and a `validation_split` of 0.2 says *take 20% of that trained input,
    split it out, don't actually train on that, and use that to evaluate how well
    it's doing after every epoch*. It never actually trains on the validation split,
    but the validation split lets us look at the progress as it goes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们有大约250万个参数或权重。接下来，我们运行fit方法。它会接受训练输入和训练标签，并指定我们想要的训练轮数。我们需要10轮，所以是对训练输入进行10次重复训练；它还会接受一个批量大小，表示每次更新权重之前要处理多少个样本，在我们的例子中是若干首歌曲；并且`validation_split`为0.2，这表示*从训练输入中取出20%，不在此上进行训练，而是用它来评估每轮训练后的效果*。验证集永远不会用于训练，但它可以让我们在训练过程中查看模型的进展。
- en: 'Finally, because we did separate the training and test ahead of time, we''re
    going to do an evaluation on the test, the test data, and print the loss and accuracy
    of that. Here it is with the training results:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，因为我们提前分离了训练集和测试集，所以我们将对测试数据进行评估，并打印出该数据集的损失和准确率。这里是训练结果：
- en: '![](img/00148.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00148.jpeg)'
- en: It was printing this as it went. It always prints the loss and the accuracy.
    This is on the training set itself, not the validation set, so this should get
    pretty close to 1.0\. You actually probably don't want it to go close to 1.0 because
    that could represent overfitting, but if you let it go long enough, it often does
    reach 1.0 accuracy on the training set because it's memorizing the training set.
    What we really care about is the validation accuracy because that's letting us
    use the test set. It's data that it's just never looked at before, at least not
    for training, and indeed it's relatively close to the validation accuracy, which
    is our final accuracy. This final accuracy is on the test data that we separated
    ahead of time. Now we're getting an accuracy of around 53%. That seems relatively
    low until we realize that there are 10 different genres. Random guessing would
    give us 10% accuracy, so it's a lot better than random guessing.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 它在运行时会持续打印输出。它总是打印损失和准确率。这是针对训练集本身，而不是验证集，因此准确率应该接近1.0。实际上，你可能不希望它接近1.0，因为那可能意味着过拟合，但如果你让它训练足够长的时间，通常会在训练集上达到1.0的准确率，因为它在记住训练集。我们真正关心的是验证准确率，因为它让我们使用测试集。测试集是模型从未见过的数据，至少在训练时没有见过，事实上，验证准确率与最终准确率非常接近。这个最终准确率是基于我们提前分离出的测试数据。现在我们的准确率大约为53%。这个结果看起来相对较低，直到我们意识到有10种不同的类别。随机猜测的准确率是10%，所以这个结果比随机猜测要好得多。
- en: Revising the spam detector to use neural networks
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修改垃圾邮件检测器以使用神经网络
- en: In this section, we're going to update the spam detector from before to use
    neural networks. Recall that the dataset used was from YouTube. There was an approximate
    of 2,000 comments with around half being spam and the other half not. These comments
    were of five different videos.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将更新之前的垃圾邮件检测器，改为使用神经网络。回想一下，使用的数据集来自YouTube，共有约2,000条评论，其中一半是垃圾邮件，另一半不是。这些评论来自五个不同的视频。
- en: In the last version, we used a bag of words and a random forest. We carried
    out a parameter search to find the parameters best suited for the bag of words,
    which was the CountVectorizer that had 1,000 different words in it. These 1000
    words were the top used words. We used unigrams instead of bigrams or trigrams.
    It would be good to drop the common and the stop words from the English language.
    The best way is to use TF-IDF. It was also found that using a 100 different trees
    would be best for the random forest. Now, we are going to use a bag of words but
    we're going to use a shallow neural network instead of the random forest. Also
    remember that we got 95 or 96 percent accuracy for the previous version.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个版本中，我们使用了词袋模型和随机森林。我们进行了参数搜索，以找到最适合词袋模型的参数，这些参数是包含1,000个不同单词的CountVectorizer。这些1,000个单词是使用频率最高的单词。我们使用了单一词项（unigrams）而非二元组（bigrams）或三元组（trigrams）。最好从英语语言中去除常见词和停用词。最好的方法是使用TF-IDF。我们还发现，使用100棵树对随机森林来说效果最好。现在，我们将继续使用词袋模型，但将随机森林替换为浅层神经网络。另请记住，在上一个版本中，我们的准确率达到了95%或96%。
- en: 'Let''s look at the code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下代码：
- en: '![](img/00149.jpeg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00149.jpeg)'
- en: We start with importing. We'll use pandas once more to load the dataset. This
    time, we're going to use the Keras Tokenizer. There's no particular reason to
    use Tokenizer, except to show an alternative technique. We will import NumPy and
    then proceed to import the sequential model for the neural networks, which is
    the typical feed-forward network. We then have dense layers that are the typical
    neuron layers. We're also going to add the dropout feature, which helps prevent
    over-fitting, and we're going to decide on the activation for each layer. We are
    going to use the `to_categorical` method from the `np_utils` library from Keras
    to produce one-hot encoding, and we're going to introduce `StratifiedKFold` to
    perform our cross-validation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从导入开始。我们再次使用pandas来加载数据集。这次，我们将使用Keras Tokenizer。使用Tokenizer没有特别的理由，只是为了展示一种替代技术。我们将导入NumPy，然后继续导入神经网络的顺序模型，这是典型的前馈网络。接着，我们添加典型的密集层，即神经元层。我们还将添加dropout功能，帮助防止过拟合，并决定每一层的激活函数。我们将使用来自Keras的`np_utils`库中的`to_categorical`方法来生成独热编码，并引入`StratifiedKFold`来执行交叉验证。
- en: 'First, we load the datasets:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载数据集：
- en: '![](img/00150.jpeg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00150.jpeg)'
- en: There are five different CSV files. We will stack them on top of each other
    so that we have one big dataset. We then shuffle it by running a sample which
    picks random rows. We're going to say that we want to keep 100% of the data so
    that it effectively shuffles all of the data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 有五个不同的CSV文件。我们将把它们堆叠在一起，以便形成一个大的数据集。然后我们通过运行一个随机抽取行的样本来对其进行洗牌。我们将设置为保留100%的数据，从而有效地洗牌所有数据。
- en: 'Now, the `StratifiedKFold` technique takes a number of splits, say five, and
    produces the indexes of the original dataset for those splits:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`StratifiedKFold`技术会取一个拆分数，比如五个，并生成原始数据集在这些拆分中的索引：
- en: '![](img/00151.jpeg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00151.jpeg)'
- en: 'We''re going to get an 80%/20% split for training and testing. This 20% testing
    will differ with each split. It''s an iterator, hence, we can use a `for` loop
    to look at all the different splits. We will print the testing positions to see
    that they don''t overlap for each split:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到一个80%/20%的训练和测试集拆分。这个20%的测试集在每次拆分时都会不同。它是一个迭代器，因此我们可以使用`for`循环查看所有不同的拆分。我们将打印测试位置，以确保它们在每次拆分中都没有重叠：
- en: '![](img/00152.jpeg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00152.jpeg)'
- en: 'Here''s the first split:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第一个拆分：
- en: '![](img/00153.jpeg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00153.jpeg)'
- en: 'Here''s the second split:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第二个拆分：
- en: '![](img/00154.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00154.jpeg)'
- en: 'Here''s the third:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第三个：
- en: '![](img/00155.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00155.jpeg)'
- en: 'Here''s the fourth:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第四个：
- en: '![](img/00156.jpeg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00156.jpeg)'
- en: 'And finally, the fifth:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，看看第五个：
- en: '![](img/00157.gif)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00157.gif)'
- en: It is now obvious that they don't overlap.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在显然可以看出它们没有重叠。
- en: 'We then define a function that receives these indexes for the different splits
    and does the bag of words, builds a neural net, trains it, and evaluates it. We
    then return the score for that split. We begin by taking the positions for the
    train and test sets and extract the comments:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个函数，接收这些不同拆分的索引，并执行词袋模型，构建神经网络，训练并评估它。然后返回该拆分的得分。我们从获取训练集和测试集的位置开始，并提取评论：
- en: '![](img/00158.jpeg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00158.jpeg)'
- en: We then proceed to build our Tokenizer. At this point, we can mention the number
    of words we want it to support in the Tokenizer. A general research led us to
    the conclusion that using 2,000 words was better than a 1000 words. For the random
    forest, using a 1,000 words is better and is supported by doing the GridSearch
    for all the different parameters. There's no particular reason to believe that
    because the bag of words works best with a 1,000 words in comparison to the random
    forest, that it is what is necessarily best for the neural network as well. So,
    we're going to use 2,000 words in this case. This is just a constructor. Nothing
    has really happened with the bag of words yet. The next thing we need to do is
    learn what the words are and that's going to happen by using the `fit_on_texts`
    method.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们继续构建我们的Tokenizer。在这个阶段，我们可以指定Tokenizer支持的词汇数量。一项研究得出结论，使用2,000个词比使用1,000个词更好。对于随机森林来说，使用1,000个词更好，并且通过进行所有参数的GridSearch验证了这一点。没有特别的理由认为，由于词袋模型在1,000个词上表现最佳，而随机森林也适用，因此它一定是神经网络的最佳选择。所以，在这个案例中，我们将使用2,000个词。这只是一个构造函数，词袋模型实际上还没有发生什么。接下来我们需要做的是学习这些词汇，这将通过使用`fit_on_texts`方法来实现。
- en: Now, `fit_on_texts` should only be used on the training set. We only want to
    learn the words in the training set. This helps us simulate the real world where
    you've only trained your model on a certain set of data and then the real world
    presents possibly something new that you've never seen before. To do this, we
    have a training testing split. We only want to learn the words on the training
    set. If there are words in the testing set that we've never seen before in the
    training set, they'll be ignored. This is good because that's how it's going to
    work in the real world.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`fit_on_texts`应该只用于训练集。我们只希望学习训练集中的单词。这帮助我们模拟真实世界的情境：在训练模型时，只在某一数据集上进行训练，然后真实世界可能会呈现出一些全新的数据，我们从未见过。为了实现这一点，我们采用了训练和测试的拆分方法。我们只想学习训练集中的单词。如果测试集中的某些单词在训练集中从未出现过，它们将被忽略。这是好的，因为它正是现实世界中会发生的情况。
- en: We'll learn the words on the training set but then transform both the training
    and the testing comments into the bag of words model. The `texts_to _matrix `is
    used for the same. It produces a matrix which can be fed directly into the neural
    network. We give it the `train_content`, which are the comments, and the `test_content`.
    Then, we can then decide if we want `tfidf` scores, binary scores, or frequency
    counts. We're going to go with `tfidf` in this case. `tfidf` is a number between
    0 and any random integer, possibly a large number, and in most cases it's not
    a good idea to give a neuron in a neural network very large numbers or very small
    numbers, meaning negative numbers. Here, we want to kind of scale these numbers
    between maybe 0 and 1, and -1 and 1\. To scale between 0 and 1, we can divide
    by the max. So, we have to look at all the training examples, all the training
    numbers for TF-IDF, and divide each number by the maximum among those. We have
    to do the same for the test. Now, the train inputs and test inputs are `tfidf`
    scores that have been rescaled to 0 to 1.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在训练集上学习单词，然后将训练集和测试集的评论转换成词袋模型。`texts_to_matrix`用于此目的。它生成一个矩阵，可以直接输入到神经网络中。我们给它`train_content`（评论）和`test_content`。然后，我们可以决定是否使用`tfidf`分数、二进制分数或频率计数。我们这次将使用`tfidf`。`tfidf`是一个介于0和任何随机整数之间的数，可能是一个很大的数字，在大多数情况下，不建议给神经网络中的神经元输入过大的数字或过小的数字（即负数）。在这里，我们希望将这些数字缩放到0和1之间，或者-1和1之间。为了将其缩放到0和1之间，我们可以除以最大值。因此，我们必须查看所有训练示例中的所有TF-IDF训练数字，并将每个数字除以其中的最大值。测试集也需要做同样的处理。现在，训练输入和测试输入是已经重新缩放到0到1之间的`tfidf`分数。
- en: We also shift it between -1 and 1 by subtracting the average from each score.
    Now, for the outputs, even though we could use binary, we're going to use categorical
    in this case for no particular reason, except just to show it. We're going to
    take all of the desired outputs, the classes, which is spam, not spam, and turn
    them into 1, 0 and 0, 1 encodings.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还通过从每个分数中减去平均值，将其在-1和1之间进行转换。现在，对于输出，尽管我们可以使用二进制，但我们在此案例中将使用分类输出，没什么特别的原因，仅仅是为了展示。我们将把所有的期望输出（即类别），如垃圾邮件和非垃圾邮件，转换成1，0和0，1的编码。
- en: Now, we can build our network. We're going to build the network all over again
    for each train/test split so it starts randomly. We're going to build a sequential
    network, which is a typical feed-forward network. We're going to have a first
    layer of 512 neurons. They're going to receive 2,000 different inputs. There's
    2,000 because that's the size of the bag of words.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以构建我们的网络了。我们将在每次训练/测试拆分时重新构建网络，这样它就会从随机状态开始。我们将构建一个顺序网络，这是一种典型的前馈网络。我们将有一个由512个神经元组成的第一层。它们将接收2,000个不同的输入。之所以是2,000，是因为词袋模型的大小是2,000。
- en: We then use a ReLU activation. We could also use Tanh. ReLU is common in neural
    networks today. It's pretty fast as well as accurate. There's a 512 layer and
    then a 2 layer. The 2 is very specific because that's the output. We have one-hot
    encoding, so it's 1, 0, 0, 1, so that's two neurons. It has to match the number
    of outputs we have. Each of the two has links to 512 neurons from before. That's
    a lot of edges connecting the first layer to the second layer.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用ReLU激活函数。我们也可以使用Tanh。ReLU在今天的神经网络中很常见，且它的运算速度较快，精度也较高。这里有512个神经元的层，接着是一个2个神经元的层。2个神经元是很特定的，因为这是输出层。我们使用独热编码（one-hot
    encoding），所以是1，0，0，1，这样就是两个神经元。它必须与我们所需的输出数量相匹配。每个神经元都与之前的512个神经元相连接。这是很多边缘连接，将第一层和第二层相连。
- en: To prevent overfitting, we add a dropout. A 50% dropout means that every time
    it goes to update the weights, it just refuses to update half of them, a random
    half. We then find the weighted sum of their inputs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止过拟合，我们加入了一个丢弃层。50%的丢弃率意味着每次更新权重时，它会随机拒绝更新一半的权重。然后，我们会计算它们输入的加权和。
- en: We take that sum and run the softmax. Softmax takes these different outputs
    and turns them into probabilities so that one of them is highest and they're all
    between 0 and 1\. Then, we compile the model to compute the loss as `categorical_
    crossentropy`. This is usually something one uses when they use one-hot encoding.
    Let's use the Adamax optimizer. There are different optimizers that are available
    in Keras, and you can look at the Keras documentation at [https://keras.io/](https://keras.io/).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将那个加权和输入到softmax函数。Softmax会将这些不同的输出转化为概率，使得其中一个概率最大，且所有的概率值都介于0和1之间。接着，我们编译模型，计算损失函数为`categorical_crossentropy`。这是通常在使用独热编码时使用的损失函数。接着，我们使用Adamax优化器。Keras提供了不同的优化器，你可以查看Keras文档：[https://keras.io/](https://keras.io/)。
- en: Accuracy is an essential measure to work on while we train the network, and
    we also want to compute accuracy at the very end to see how well it's done.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是训练网络时需要关注的一个重要指标，我们也希望在最后计算准确率，以查看模型的表现。
- en: We then run fit on the training set. `d_train_inputs` is the train inputs, and `d_train_inputs`
    is the matrix bag of words model, train outputs, and the one -hot encoding. We
    are going to say that we want 10 epochs, which means it'll go through the entire
    training set ten times, and a batch size of 16, which means it will go through
    16 rows and compute the average loss and then update the weight.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在训练集上运行fit函数。`d_train_inputs`是训练输入数据，`d_train_inputs`是矩阵词袋模型，训练输出数据以及独热编码。我们设定10个epoch，这意味着它会遍历整个训练集10次，批量大小为16，这意味着它会遍历16行数据，计算平均损失后再更新权重。
- en: After it's been fit, which indirectly means it's been trained, we evaluate the
    test. It's not until this point that it actually looks at the test. The scores
    that come out are going to be the loss and whatever other metrics we have, which
    in this case is accuracy. Therefore, we'll just show the accuracy times 100 to
    get a percent and we'll return the scores.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型拟合完成后，间接地意味着它已经经过训练，我们会进行测试评估。直到这时，它才会查看测试集。输出的分数包括损失和其他我们设定的度量标准，在这个例子中是准确率。因此，我们将显示准确率乘以100，得到百分比，然后返回分数。
- en: 'Now, let''s build that split again, which is the k-fold split with five different
    folds:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们重新构建那个拆分，即使用五个不同折叠的k折交叉验证：
- en: '![](img/00159.jpeg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00159.jpeg)'
- en: We collect the scores. For each split, we're going to run our `train_and_test`
    function and save the scores. Here, it is running on each split. If you scroll,
    you will see that you get the epochs going. We can see that the accuracy on the
    training input increases per epoch. Now, if this gets really high, you might start
    worrying about over-fitting, but after the 10 epochs, use the testing set which
    it's never seen before. This helps us obtain the accuracy number for the testing
    set. Then, we'll do it all again for the next split and we'll get a different
    accuracy. We'll do this a few more times until we have five different numbers,
    one for each split.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集分数。对于每个拆分，我们将运行`train_and_test`函数并保存分数。在这里，它会在每个拆分上运行。如果你向下滚动，你会看到每个epoch的进展。我们可以看到训练输入的准确率在每个epoch上都在增加。如果准确率非常高，可能会开始担心过拟合，但在经过10个epoch后，我们使用从未见过的测试集进行测试。这帮助我们获得测试集的准确率。然后，我们会对下一个拆分进行相同操作，并得到一个不同的准确率。我们会再做几次，直到我们得到五个不同的数字，每个拆分一个。
- en: 'The average is found as follows: :'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值的计算方法如下：
- en: '![](img/00160.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00160.jpeg)'
- en: Here, we get 95%, which is very close to what we got by using random forest.
    We didn't use this neural network example to show that we can get 100%. We used
    this method to demonstrate an alternative way to detect spam instead of the random
    forest method.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们得到了95%的准确率，这与我们使用随机森林得到的结果非常接近。我们并没有使用这个神经网络示例来证明我们能得到100%的准确率，而是用它来展示一种替代的垃圾邮件检测方法，替代了随机森林的方法。
- en: Summary
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered a brief introduction to neural networks, proceeded
    with feed-forward neural networks, and looked at a program to identify the genre
    of a song with neural networks. Finally, we revised our spam detector from earlier
    to make it work with neural networks.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了神经网络的简要概念，讲解了前馈神经网络，并展示了一个使用神经网络识别歌曲类型的程序。最后，我们修订了之前的垃圾邮件检测器，使其能够与神经网络一起工作。
- en: In the next chapter, we'll look at deep learning and learn about convolutional
    neural networks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入学习深度学习，并了解卷积神经网络。
