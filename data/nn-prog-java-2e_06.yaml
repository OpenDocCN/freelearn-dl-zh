- en: Chapter 6. Classifying Disease Diagnosis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 疾病诊断分类
- en: 'So far, we have been working with supervised learning for predicting numerical
    values; however, in the real world, numbers are just part of the data addressed.
    Real variables also contain categorical values, which are not purely numerical,
    but describe important features that have influence on the problems neural networks
    are applied to solve. In this chapter, the reader will be presented with a very
    didactic but interesting application involving categorical values and classification:
    disease diagnosis. This chapter digs deeper into classification problems and how
    to represent categorical data, as well as showing how to design a classification
    algorithm using neural networks. The topics covered in this chapter are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在使用监督学习来预测数值；然而，在现实世界中，数字只是数据的一部分。真实变量还包含分类值，这些值不是纯数值，但描述了影响神经网络应用解决的问题的重要特征。在本章中，读者将了解到一个涉及分类值和分类的非常具有教育意义且有趣的应用：疾病诊断。本章深入探讨了分类问题以及如何表示分类数据，以及如何使用神经网络设计分类算法。本章涵盖的主题如下：
- en: Foundations of classification problems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类问题的基础
- en: Categorical data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据
- en: Logistic regression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Confusion matrix
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Sensibility and specificity
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 敏感性和特异性
- en: Neural networks for classification
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分类的神经网络
- en: Disease diagnosis using neural networks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络进行疾病诊断
- en: Diagnosis for cancer
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 癌症诊断
- en: Diagnosis for diabetes
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 糖尿病诊断
- en: Foundations of classification problems
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类问题的基础
- en: 'One thing neural networks are really good at is classifying records. The very
    simple perceptron network draws a decision boundary, defining whether a data point
    belongs to one region or another, whereas a region denotes a class. Let''s take
    a look visually on an *x-y* scatter chart:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络真正擅长的一件事是分类记录。非常简单的感知器网络绘制决策边界，定义数据点属于哪个区域，而区域表示一个类别。让我们通过一个*x-y*散点图来直观地看一下：
- en: '![Foundations of classification problems](img/B05964_06_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![分类问题的基础](img/B05964_06_01.jpg)'
- en: The dashed lines explicitly separate the points into classes. These points represent
    data records which originally had the corresponding class labels. That means their
    classes were already known, therefore this classification tasks falls in the supervised
    learning category.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虚线明确地将点分为不同的类别。这些点代表原本具有相应类别标签的数据记录。这意味着它们的类别已经已知，因此这个分类任务属于监督学习类别。
- en: 'A classification algorithm seeks to find the boundaries between the classes
    in the data hyperspace. Once the classification boundaries are defined, a new
    data point, with an unknown class, receives a class label according to the boundaries
    defined by the classification algorithm. The figure below shows how a new record
    is classified:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分类算法试图在数据超空间中的类别之间找到边界。一旦定义了分类边界，一个未知类别的新的数据点就会根据分类算法定义的边界获得一个类别标签。下面的图示显示了如何对一条新记录进行分类：
- en: '![Foundations of classification problems](img/B05964_06_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![分类问题的基础](img/B05964_06_02.jpg)'
- en: Based on the current class configuration, the new record's class is the third
    class.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 根据当前的类别配置，新记录的类别是第三个类别。
- en: Categorical data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类数据
- en: 'Applications usually lead with the types of data shown in the following figure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 应用通常从以下图示中展示的数据类型开始：
- en: '![Categorical data](img/B05964_06_03.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![分类数据](img/B05964_06_03.jpg)'
- en: 'Data can be numerical or categorical or, simply speaking, numbers or words.
    Numerical data is represented by a numeric value, from which it can be continuous
    or discrete. This data type has been used so far in this book''s applications.
    Categorical data is a wider class of data that includes words, letters, or even
    numbers, but with a quite different meaning. While numerical data can support
    arithmetic operations, categorical data is only descriptive and cannot be processed
    like numbers, even if the value is a number. An example is the severity degree
    of a disease in a scale (from zero to five, for example). Another property of
    categorical data is that a certain variable has a finite number of values; in
    other words, only a defined set of values can be assigned to a categorical variable.
    A subclass of data inside the categorical is ordinal data. This class is particular
    because the defined values can be sorted in a predefined order. An example is
    adjectives indicating the state or quality of something (bad, fair, good, excellent):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以是数值型或分类型，简单来说，就是数字或文字。数值型数据由一个数值表示，它可以连续或离散。到目前为止，这本书的应用中已经使用了这种数据类型。分类型数据是一个更广泛的数据类别，包括文字、字母，甚至数字，但具有完全不同的含义。虽然数值型数据可以支持算术运算，但分类型数据仅是描述性的，不能像数字那样处理，即使其值是数字。一个例子是疾病严重程度的等级（例如，从零到五）。分类型数据的另一个特性是，某个变量具有有限个值；换句话说，只能将定义好的值集分配给分类型变量。分类型数据内部的一个子类是顺序数据。这个类别特别之处在于定义的值可以按预定义的顺序排序。一个例子是表示某物状态或质量的形容词（差、一般、好、优秀）：
- en: '| Numerical | Categorical |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 数值型 | 分类型 |'
- en: '| --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Only numbers | Numbers, words, letters, signs |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 仅数字 | 数字、文字、字母、符号 |'
- en: '| Can support arithmetic operations | Do not support arithmetic operations
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 支持算术运算 | 不支持算术运算 |'
- en: '| Infinite or undefined range of values | Finite or defined set of values |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 无限或未定义的值域 | 有限或定义好的值集 |'
- en: '| Continuous | Discrete | Ordinal | Non-ordinal |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 连续 | 离散 | 顺序 | 非顺序 |'
- en: '| Real values | Integers, decimal | Can be ordered | Cannot be ordered |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 实数值 | 整数、小数 | 可以排序 | 不能排序 |'
- en: '| Any possible value | Predefined intervals | Can be assigned numbers | Each
    possible value is a flag |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 任何可能的值 | 预定义的区间 | 可以分配数字 | 每个可能的值是一个标志 |'
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Note that here we are addressing structured data only. In the real world, most
    data is unstructured, including text and multimedia content. Although these types
    of data are also processed in learning from data applications, neural networks
    require them to be transformed into structured data types.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里我们只讨论结构化数据。在现实世界中，大多数数据是非结构化的，包括文本和多媒体内容。尽管这些类型的数据在数据学习应用中也被处理，但神经网络需要将它们转换成结构化数据类型。
- en: Working with categorical data
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理分类数据
- en: 'Structured data files, such as those used in CSV or Excel, usually contain
    columns of numerical and categorical data. In [Chapter 5](ch05.xhtml "Chapter 5. Forecasting
    Weather"), *Forecasting Weather* we have created the classes `LoadCsv` (for loading
    `csv` files) and DataSet (for storing data from csv), but these classes are prepared
    only for working with numerical data. The simplest way of representing categorical
    value is converting each possible value into a binary column, whereby if the given
    value is presented in the original column, the corresponding binary column will
    have a one as the converted value, otherwise it will be zero:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据文件，如CSV或Excel中使用的，通常包含数值型和分类型数据的列。在[第5章](ch05.xhtml "第5章. 预测天气") *预测天气*
    中，我们创建了`LoadCsv`类（用于加载`csv`文件）和`DataSet`类（用于存储csv数据），但这些类仅适用于处理数值数据。表示分类值的最简单方法是将每个可能的值转换为二进制列，其中如果原始列中包含给定值，则相应的二进制列将有一个作为转换值，否则为0：
- en: '![Working with categorical data](img/B05964_06_04.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![处理分类数据](img/B05964_06_04.jpg)'
- en: Ordinal columns can assume the defined values as numerical in the same column;
    however, if the original values are letters or words, they need to be converted
    into numbers via a Java Dictionary.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序列可以假设定义的值作为同一列中的数值；然而，如果原始值是字母或文字，则需要通过Java字典将它们转换为数字。
- en: The strategy described above may be implemented by you as an exercise. Otherwise,
    you would have to handle this manually. In this case, depending on the number
    of data rows, it can be time-consuming.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上述策略可以通过练习由你实现。否则，你将不得不手动处理。在这种情况下，根据数据行数，可能会很耗时。
- en: Logistic regression
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: 'We''ve covered that Neural Networks can work as data classifiers by establishing
    decision boundaries onto data in the hyperspace. This boundary can be linear,
    in the case of perceptrons, or nonlinear, in the case of other neural architectures
    such as MLPs, Kohonen, or Adaline. The linear case is based on linear regression,
    on which the classification boundary is a literally a line, as shown in the previous
    figure. If the scatter chart of the data looks like that of the following figure,
    then a nonlinear classification boundary is needed:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了神经网络可以通过在超空间中的数据上建立决策边界来作为数据分类器工作。这个边界可以是线性的，例如在感知器的情况下，或者非线性的，例如在其他神经网络架构中，如MLPs、Kohonen或Adaline。线性情况基于线性回归，分类边界实际上是一条线，如前图所示。如果数据的散点图看起来像以下图中的那样，则需要非线性分类边界：
- en: '![Logistic regression](img/B05964_06_05.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](img/B05964_06_05.jpg)'
- en: 'Neural Networks are in fact a great nonlinear classifier, and this is achieved
    by the usage of nonlinear activation functions. One nonlinear function that actually
    works well for nonlinear classification is the sigmoid function, whereas the procedure
    for classification using this function is called logistic regression:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络实际上是一个非常好的非线性分类器，这是通过使用非线性激活函数实现的。一个实际上对非线性分类效果很好的非线性函数是Sigmoid函数，而使用此函数进行分类的过程称为逻辑回归：
- en: '![Logistic regression](img/B05964_06_06.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](img/B05964_06_06.jpg)'
- en: 'This function returns values bounded between zero and one. In this function
    α parameter denotes how hard the transition from zero and 1 occurs. The following
    chart shows the difference:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数返回介于零和一之间的值。在此函数中，α参数表示从零到一的转换有多硬。以下图表显示了差异：
- en: '![Logistic regression](img/B05964_06_06_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](img/B05964_06_06_01.jpg)'
- en: Note that the higher the alpha parameter is, the more the logistic function
    takes a shape of a hard-limiting threshold function, also known as a step function.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，alpha参数越高，逻辑函数就越接近硬限定的阈值函数，也称为阶梯函数。
- en: Multiple classes versus binary classes
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多分类与二分类
- en: Classification problems usually deal with a multiple class's case, where each
    class is assigned a label. However, a binary classification schema is useful to
    be applied in neural networks. This is because a neural network with a logistic
    function at the output layer can produce only values between `0` and `1`, meaning
    it belongs (1) or does not belong (0) to some class.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题通常处理多分类的情况，其中每个类别都被分配一个标签。然而，二分类方案在神经网络中很有用。这是因为输出层具有逻辑函数的神经网络只能产生介于`0`和`1`之间的值，这意味着它属于（1）或不属于（0）某个类别。
- en: 'Nevertheless, there is one approach for multiple classes using binary functions.
    Consider that every class is represented by an output neuron, and whenever that
    output neuron fires, that neuron''s corresponding class is applied on the input
    data record. So let''s suppose a network to classify diseases; each neuron output
    will represent a disease to be applied to some symptom:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于多分类，有一种使用二进制函数的方法。假设有一个用于分类疾病的网络；每个神经元的输出将代表一个应用于某些症状的疾病：
- en: '![Multiple classes versus binary classes](img/B05964_06_07.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![多分类与二分类](img/B05964_06_07.jpg)'
- en: Tip
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Note that in that configuration, it would be possible to have multiple diseases
    with the same symptoms, which can happen. However, if only one class would be
    desirable to be chosen, then a schema as the competitive learning algorithm would
    suit more in that case.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在那个配置中，可能会有多个疾病具有相同的症状，这种情况可能发生。然而，如果只希望选择一个类别，那么竞争学习算法的方案在这种情况下可能更适合。
- en: Confusion matrix
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: There is no perfect classifier algorithm; all of them are subject to errors
    and biases; however, it is expected that a classification algorithm can correctly
    classify 70-90% of the records.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 没有完美的分类器算法；它们都存在错误和偏差；然而，预期一个分类算法可以正确分类70-90%的记录。
- en: Tip
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Very high correct classification rates are not always desirable, because of
    possible biases presented in the input data that might affect the classification
    task, and also there is a risk of overtraining, when only the training data is
    correctly classified.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 非常高的正确分类率并不总是理想的，因为输入数据中可能存在的偏差可能会影响分类任务，并且也存在过拟合的风险，当只有训练数据被正确分类时。
- en: 'A confusion matrix shows how much of a given class''s records were correctly
    classified and thereby how much were wrongly classified. The following table depicts
    what a confusion matrix may look like:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵显示了给定类别的记录中有多少被正确分类，以及有多少被错误分类。以下表格描述了混淆矩阵可能的样子：
- en: '![Confusion matrix](img/B05964_06_08.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![混淆矩阵](img/B05964_06_08.jpg)'
- en: Note that the main diagonal is expected to have the higher values, as the classification
    algorithm will always try to extract meaningful information from the input dataset.
    The sum of all rows must be equal to 100%, because all elements of a given class
    are to be classified in one of the available classes. Note that some classes may
    receive more classifications than expected.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，主对角线应期望有更高的值，因为分类算法总是会尝试从输入数据集中提取有意义的信息。所有行的总和必须等于100%，因为给定类别的所有元素都应该被分类到可用的类别之一。注意，某些类别可能会收到比预期更多的分类。
- en: The more a confusion matrix looks like an identity matrix, the better the classification
    algorithm will be.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵越像单位矩阵，分类算法就越好。
- en: Sensitivity and specificity
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 敏感性和特异性
- en: 'When the classification is binary, the confusion matrix is found to be a simple
    2x2 matrix, and therefore its positions are specially named:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当分类是二进制时，混淆矩阵被发现是一个简单的2x2矩阵，因此其位置被特别命名：
- en: '| Actual Class | Inferred Class |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 实际类别 | 推断类别 |'
- en: '| --- | --- |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Positive (1) | Negative (0) |   |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 正面（1） | 负面（0） |   |'
- en: '| Positive (1) | True Positive | False Negative |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 正面（1） | 真阳性 | 假阴性 |'
- en: '| Negative (0) | False Positive | True Negative |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 负面（0） | 假阳性 | 真阴性 |'
- en: In disease diagnosis, which is the subject of this chapter, the concept of a
    binary confusion matrix is applied in the sense that a false diagnosis may be
    either false positive or false negative. The rate of false results can be measured
    by sensitivity and specificity indexes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的主题——疾病诊断中，二进制混淆矩阵的概念被应用，即错误诊断可能是假阳性或假阴性。可以通过敏感性和特异性指数来衡量错误结果的比率。
- en: 'Sensitivity means the true positive rate; it measures how many of the records
    are correctly classified positively:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感性意味着真阳性率；它衡量有多少记录被正确地分类为正面：
- en: '![Sensitivity and specificity](img/B05964_06_09.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![敏感性和特异性](img/B05964_06_09.jpg)'
- en: 'Specificity, in turn, means the true negative rate; it indicates the proportion
    of negative record identification:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 特异性，反过来，意味着真正的负率；它表示负记录识别的比例：
- en: '![Sensitivity and specificity](img/B05964_06_10.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![敏感性和特异性](img/B05964_06_10.jpg)'
- en: High values of both sensitivity and specificity are desired; however, depending
    on the application field, the sensitivity may carry more meaning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 希望敏感性和特异性都高；然而，根据应用领域，敏感性可能更有意义。
- en: Implementing a confusion matrix
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现混淆矩阵
- en: 'In our code, let''s implement the confusion matrix in the class `NeuralOutputData`.
    The method `calculateConfusionMatrix` below is programmed to consider two neurons
    in the output layer. If the output is 10, then it is *yes* to a confusion matrix;
    if the output is 01, then it is no:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，让我们在`NeuralOutputData`类中实现混淆矩阵。下面的`calculateConfusionMatrix`方法被编程为考虑输出层中的两个神经元。如果输出是10，那么它对混淆矩阵来说是*是*；如果输出是01，那么它是否定：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Another method implemented in the `NeuralOutputData` class is called `calculatePerformanceMeasures`.
    It receives as parameter the confusion matrix and it calculates and prints the
    following performance measures of classification:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在`NeuralOutputData`类中实现的一种方法是`calculatePerformanceMeasures`。它接收混淆矩阵作为参数，并计算并打印以下分类的性能指标：
- en: Positive class error rate
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正类错误率
- en: Negative class error rate
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负类错误率
- en: Total error rate
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总错误率
- en: Total accuracy
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总准确率
- en: Precision
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度
- en: Sensibility
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 敏感性
- en: Specificity
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特异性
- en: 'This method is shown below:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示了该方法：
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Neural networks for classification
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类用的神经网络
- en: Classification tasks can be done by any of the supervised neural networks this
    book has covered so far. However, it is recommended that you use more complex
    architectures such as MLPs. In this chapter, we are going to use the `NeuralNet`
    class to build an MLP with one hidden layer and the sigmoid function at the output.
    Every output neuron will mean a class.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用本书迄今为止所涵盖的任何监督神经网络来完成分类任务。然而，建议您使用更复杂的架构，如MLP。在本章中，我们将使用`NeuralNet`类构建一个具有一个隐藏层和输出处的sigmoid函数的MLP。每个输出神经元都代表一个类别。
- en: The code used to implement the examples is very similar to the test class (`BackpropagationTest`).
    However, the class `DiagnosisExample` asks which dataset the user would like to
    use and other neural network parameters, such as number of epochs, number of neurons
    in hidden layer, and learning rate.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 用于实现示例的代码与测试类（`BackpropagationTest`）非常相似。然而，`DiagnosisExample`类会询问用户想要使用哪个数据集以及其他神经网络参数，例如迭代次数、隐藏层中的神经元数量和学习率。
- en: Disease diagnosis with neural networks
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络进行疾病诊断
- en: 'For disease diagnosis, we are going to use the free dataset proben1, which
    is available on the Web ([http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html](http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html)).
    Proben1 is a benchmark set of several datasets from different domains. We are
    going to use the cancer and the diabetes datasets. We add a class to run the experiments
    of each case: `DiagnosisExample`.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于疾病诊断，我们将使用免费的proben1数据集，该数据集可在网络上找到（[http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html](http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html)）。Proben1是从不同领域收集的几个数据集的基准集。我们将使用癌症和糖尿病数据集。我们添加了一个类别来运行每个案例的实验：`DiagnosisExample`。
- en: Breast cancer
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 乳腺癌
- en: The breast cancer dataset is composed of 10 variables, of which nine are inputs
    and one is a binary output. The dataset has 699 records, but we excluded from
    them 16 which were found to be incomplete, thus we used 683 to train and test
    the neural network.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌数据集由10个变量组成，其中9个是输入变量，1个是二进制输出。数据集共有699条记录，但我们排除了其中16条不完整的记录，因此我们使用了683条记录来训练和测试神经网络。
- en: Tip
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: In real practical problems, it is common to have missing or invalid data. Ideally,
    the classification algorithm must handle these records, but sometimes it is recommended
    that you exclude them, since there would be not enough information to produce
    an accurate result.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际实际问题中，常见有缺失或无效数据。理想情况下，分类算法必须处理这些记录，但有时建议排除它们，因为可能没有足够的信息来产生准确的结果。
- en: 'The following table shows a configuration of this dataset:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了该数据集的配置：
- en: '| Variable Name | Type | Maximum Value and Minimum Value |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 变量名称 | 类型 | 最大值和最小值 |'
- en: '| --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Diagnosis result | OUTPUT | [0; 1] |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 诊断结果 | 输出 | [0; 1] |'
- en: '| Clump Thickness | INPUT #1 | [1; 10] |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 腺体厚度 | 输入 #1 | [1; 10] |'
- en: '| Uniformity of Cell Size | INPUT #2 | [1; 10] |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 细胞大小均匀性 | 输入 #2 | [1; 10] |'
- en: '| Uniformity of Cell Shape | INPUT #3 | [1; 10] |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 细胞形状均匀性 | 输入 #3 | [1; 10] |'
- en: '| Marginal Adhesion | INPUT #4 | [1; 10] |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 边缘粘附 | 输入 #4 | [1; 10] |'
- en: '| Single Epithelial Cell Size | INPUT #5 | [1; 10] |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 单个上皮细胞大小 | 输入 #5 | [1; 10] |'
- en: '| Bare Nuclei | INPUT #6 | [1; 10] |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 裸核 | 输入 #6 | [1; 10] |'
- en: '| Bland Chromatin | INPUT #7 | [1; 10] |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 浅色染色质 | 输入 #7 | [1; 10] |'
- en: '| Normal Nucleoli | INPUT #8 | [1; 10] |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 正常核仁 | 输入 #8 | [1; 10] |'
- en: '| Mitoses | INPUT #9 | [1; 10] |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 有丝分裂 | 输入 #9 | [1; 10] |'
- en: 'So, the proposed neural topology will be that of the following figure:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提出的神经网络拓扑结构将如下图的所示：
- en: '![Breast cancer](img/B05964_06_11.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![乳腺癌](img/B05964_06_11.jpg)'
- en: 'The dataset division was made as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的划分如下：
- en: '**Training**: 549 records (80%);'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练**: 549条记录（80%）；'
- en: '**Testing**: 134 records (20%)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试**: 134条记录（20%）'
- en: 'As in the previous cases, we performed many experiments to try to find the
    best neural network to classify whether cancer is benign or malignant. So we conducted
    12 different experiments (1,000 epochs per experiment), wherein MSE and accuracy
    values were analyzed. After that, the confusion matrix, sensitivity, and specificity
    were generated with the test dataset and analysis was done. Finally, an analysis
    of generalization was taken. The neural networks involved in the experiments are
    shown in the following table:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的案例一样，我们进行了多次实验，试图找到最佳的神经网络来分类癌症是良性还是恶性。因此，我们进行了12个不同的实验（每个实验1,000个迭代），分析了均方误差和准确率值。然后，使用测试数据集生成了混淆矩阵、敏感度和特异性，并进行了分析。最后，进行了泛化分析。实验中涉及的神经网络如下表所示：
- en: '| Experiment | Number of neurons in hidden layer | Learning rate | Activation
    Function |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | 隐藏层中的神经元数量 | 学习率 | 激活函数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| #1 | 3 | 0.1 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| #1 | 3 | 0.1 | 隐藏层: SIGLOG 输出层: LINEAR |'
- en: '| #2 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| #2 | 隐藏层: HYPERTAN 输出层: LINEAR |'
- en: '| #3 | 0.5 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| #3 | 0.5 | 隐藏层: SIGLOG 输出层: LINEAR |'
- en: '| #4 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| #4 | 隐藏层: HYPERTAN 输出层: LINEAR |'
- en: '| #5 | 0.9 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| #5 | 0.9 | 隐藏层: SIGLOG 输出层: LINEAR |'
- en: '| #6 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| #6 | 隐藏层：HYPERTAN 输出层：LINEAR |'
- en: '| #7 | 5 | 0.1 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| #7 | 5 | 0.1 | 隐藏层：SIGLOG 输出层：LINEAR |'
- en: '| #8 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| #8 | 隐藏层：HYPERTAN 输出层：LINEAR |'
- en: '| #9 | 0.5 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| #9 | 0.5 | 隐藏层：SIGLOG 输出层：LINEAR |'
- en: '| #10 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| #10 | 隐藏层：HYPERTAN 输出层：LINEAR |'
- en: '| #11 | 0.9 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| #11 | 0.9 | 隐藏层：SIGLOG 输出层：LINEAR |'
- en: '| #12 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| #12 | 隐藏层：HYPERTAN 输出层：LINEAR |'
- en: 'After each experiment, we collected MSE values (Table X); experiments #4, #8,
    #9, #10, and #11 were equivalents, because they have low MSE values and same total
    accuracy measure (92.25%). Therefore, we selected experiments #4 and #11, because
    they have low MSE values among the five experiments mentioned before:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 每次实验后，我们收集了均方误差值（表X）；实验#4、#8、#9、#10和#11是等效的，因为它们具有低均方误差值和相同的总准确度指标（92.25%）。因此，我们选择了实验#4和#11，因为它们在前面提到的五个实验中均方误差值最低：
- en: '| Experiment | MSE training rate | Total accuracy |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | 均方误差训练率 | 总准确率 |'
- en: '| --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| #1 | 0.01067 | 96.29% |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| #1 | 0.01067 | 96.29% |'
- en: '| #2 | 0.00443 | 98.50% |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| #2 | 0.00443 | 98.50% |'
- en: '| #3 | 9.99611E-4 | 97.77% |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| #3 | 9.99611E-4 | 97.77% |'
- en: '| #4 | 9.99913E-4 | 99.25% |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| #4 | 9.99913E-4 | 99.25% |'
- en: '| #5 | 9.99670E-4 | 96.26% |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| #5 | 9.99670E-4 | 96.26% |'
- en: '| #6 | 9.92578E-4 | 97.03% |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| #6 | 9.92578E-4 | 97.03% |'
- en: '| #7 | 0.01392 | 98.49% |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| #7 | 0.01392 | 98.49% |'
- en: '| #8 | 0.00367 | 99.25% |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| #8 | 0.00367 | 99.25% |'
- en: '| #9 | 9.99928E-4 | 99.25% |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| #9 | 9.99928E-4 | 99.25% |'
- en: '| #10 | 9.99951E-4 | 99.25% |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| #10 | 9.99951E-4 | 99.25% |'
- en: '| #11 | 9.99926E-4 | 99.25% |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| #11 | 9.99926E-4 | 99.25% |'
- en: '| #12 | NaN | 3.44% |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| #12 | NaN | 3.44% |'
- en: 'Graphically, the MSE evolution over time is very fast, as can be seen in the
    following chart of the fourth experiment. Although we used 1,000 epochs to train,
    the experiment stopped earlier, because the minimum overall error (0.001) was
    reached:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以看出，第四个实验的均方误差随时间快速演变，尽管我们使用了1,000个周期进行训练，但实验提前停止，因为达到了最小整体误差（0.001）：
- en: '![Breast cancer](img/B05964_06_12.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![乳腺癌](img/B05964_06_12.jpg)'
- en: 'The confusion matrix is shown in the table with the sensibility and specificity
    for both experiments. It is possible to check that measures are the same for both
    experiments:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵以及两个实验的灵敏度和特异性在表中展示。可以检查出两个实验的指标是相同的：
- en: '| Experiment | Confusion Matrix | Sensibility | Specificity |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | 混淆矩阵 | 灵敏度 | 特异性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| #4 | [[34.0, 1.0][0.00, 99.0]] | 97.22% | 100.0% |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| #4 | [[34.0, 1.0][0.00, 99.0]] | 97.22% | 100.0% |'
- en: '| #11 | [[34.0, 1.0][0.00, 99.0]] | 97.22% | 100.0% |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| #11 | [[34.0, 1.0][0.00, 99.0]] | 97.22% | 100.0% |'
- en: 'If we had to choose between models generated by experiments #4 or #11, we recommend
    selecting #4, because it''s simpler than #11 (it has fewer neurons in the hidden
    layer).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不得不在实验#4或#11生成的模型之间做出选择，我们建议选择#4，因为它比#11简单（隐藏层中的神经元更少）。
- en: Diabetes
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 糖尿病
- en: 'An additional example to be explored is the diagnosis of diabetes. This dataset
    has eight inputs and one output, shown in the table below. There are 768 records,
    all complete. However, proben1 states that there are several senseless zero values,
    probably indicating missing data. We''re handling this data as if it was real
    anyway, thereby introducing some errors (or noise) into the dataset:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 需要进一步探索的另一个例子是糖尿病的诊断。此数据集有八个输入和一个输出，如下表所示。共有768条记录，全部完整。然而，proben1表示存在几个无意义的零值，这可能是缺失数据的指示。我们仍然将这些数据当作真实数据来处理，从而在数据集中引入了一些错误（或噪声）：
- en: '| Variable Name | Type | Maximum Value and Minimum Value |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 变量名称 | 类型 | 最大值和最小值 |'
- en: '| --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Diagnosis result | OUTPUT | [0; 1] |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 诊断结果 | 输出 | [0; 1] |'
- en: '| Number of times pregnant | INPUT #1 | [0.0; 17] |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 怀孕次数 | 输入 #1 | [0.0; 17] |'
- en: '| Plasma glucose concentration a 2 hours in an oral glucose tolerance test
    | INPUT #2 | [0.0; 199] |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 口服葡萄糖耐量试验中2小时血浆葡萄糖浓度 | 输入 #2 | [0.0; 199] |'
- en: '| Diastolic blood pressure (mm Hg) | INPUT #3 | [0.0; 122] |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 舒张压（mm Hg） | 输入 #3 | [0.0; 122] |'
- en: '| Triceps skin fold thickness (mm) | INPUT #4 | [0.0; 99] |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 三角肌皮肤褶皱厚度（mm） | 输入 #4 | [0.0; 99] |'
- en: '| 2-Hour serum insulin (mu U/ml) | INPUT #5 | [0.0; 744] |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 2小时血清胰岛素（mu U/ml） | 输入 #5 | [0.0; 744] |'
- en: '| Body mass index (weight in kg/(height in m)^2) | INPUT #6 | [0.0; 67.1] |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 体质指数（体重（kg）/身高（m）^2） | 输入 #6 | [0.0; 67.1] |'
- en: '| Diabetes pedigree function | INPUT #7 | [0.078; 2420] |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 糖尿病家系函数 | 输入 #7 | [0.078; 2420] |'
- en: '| Age (years) | INPUT #8 | [21; 81] |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 年龄（年） | 输入 #8 | [21; 81] |'
- en: 'The dataset division was made as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集划分如下：
- en: '**Training**: 617 records (80%)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练**: 617条记录（80%）'
- en: '**Test**: 151 records (20%)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试**: 151条记录（20%）'
- en: 'To discover the best neural net topology to classify diabetes, we used the
    same schema of neural networks with the same analysis described in the last section.
    However, we''re using multiple class classification in the output layer: two neurons
    in this layer will be used, one for the presence of diabetes and one for absence.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了发现用于分类糖尿病的最佳神经网络拓扑结构，我们使用了与上一节中描述相同的神经网络架构。然而，我们在输出层使用了多类分类：这个层将使用两个神经元，一个用于糖尿病的存在，另一个用于不存在。
- en: 'So, the proposed neural architecture looks like that of the following figure:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，所提出的神经网络架构看起来如下图的所示：
- en: '![Diabetes](img/B05964_06_13.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![糖尿病](img/B05964_06_13.jpg)'
- en: 'The table below shows the MSE training value and accuracy of the first six
    experiments and of the last six experiments:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了前六个实验和最后六个实验的均方误差（MSE）训练值和准确率：
- en: '| Experiment | MSE training rate | Total accuracy |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | MSE训练率 | 总准确率 |'
- en: '| --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| #1 | 0.00807 | 60.54% |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| #1 | 0.00807 | 60.54% |'
- en: '| #2 | 0.00590 | 71.03% |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| #2 | 0.00590 | 71.03% |'
- en: '| #3 | 9.99990E-4 | 75.49% |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| #3 | 9.99990E-4 | 75.49% |'
- en: '| #4 | 9.98840E-4 | 74.17% |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| #4 | 9.98840E-4 | 74.17% |'
- en: '| #5 | 0.00184 | 61.58% |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| #5 | 0.00184 | 61.58% |'
- en: '| #6 | 9.82774E-4 | 59.86% |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| #6 | 9.82774E-4 | 59.86% |'
- en: '| #7 | 0.00706 | 63.57% |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| #7 | 0.00706 | 63.57% |'
- en: '| #8 | 0.00584 | 72.41% |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| #8 | 0.00584 | 72.41% |'
- en: '| #9 | 9.99994E-4 | 74.66% |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| #9 | 9.99994E-4 | 74.66% |'
- en: '| #10 | 0.01047 | 72.14% |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| #10 | 0.01047 | 72.14% |'
- en: '| #11 | 0.00316 | 59.86% |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| #11 | 0.00316 | 59.86% |'
- en: '| #12 | 0.43464 | 40.13% |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| #12 | 0.43464 | 40.13% |'
- en: 'The fall of the MSE is fast in both cases. However, experiment #9 generates
    an increase of error rate in the first values. It is shown in the following figure:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，MSE的下降都很快。然而，实验#9在初始值中产生了错误率的增加。如下图所示：
- en: '![Diabetes](img/B05964_06_14.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![糖尿病](img/B05964_06_14.jpg)'
- en: 'Analyzing the confusion matrixes, it can be seen that the measures are very
    similar:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 分析混淆矩阵，可以看出度量值非常相似：
- en: '| Experiment | Confusion Matrix | Sensibility | Specificity |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | 混淆矩阵 | 灵敏度 | 特异性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| #3 | [[35.0, 12.0][25.0, 79.0]] | 74.46% | 75.96% |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| #3 | [[35.0, 12.0][25.0, 79.0]] | 74.46% | 75.96% |'
- en: '| #9 | [[34.0, 12.0][26.0, 78.0]] | 73.91% | 75.00% |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| #9 | [[34.0, 12.0][26.0, 78.0]] | 73.91% | 75.00% |'
- en: 'One more time, we suggest choosing the simplest model. In the diabetes example,
    it is the artificial neural network generated by experiment #3.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 再次建议选择最简单的模型。在糖尿病的例子中，它是实验#3生成的神经网络。
- en: Tip
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: It is recommended you explore the class `D` `iagnosisExample` and create a GUI
    to become easy select neural net parameters, as was done in the previous chapter.
    You should try to reuse code already programmed through the inheritance concept.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您探索类`D` `iagnosisExample`并创建一个GUI来轻松选择神经网络参数，就像在上一章中所做的那样。您应该尝试通过继承概念重用已编写的代码。
- en: Summary
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we've seen two examples of the application of disease diagnosis
    using neural networks. The fundamentals of classification problems were briefly
    reviewed in order to level the knowledge explored in this chapter. Classification
    tasks belong to one of the most used types of supervised tasks in the machine
    learning / data mining fields, and Neural Networks proved to be very appropriate
    to be applied to this type of problem. The reader was also presented with the
    concepts that evaluate the classification tasks, such as sensitivity, specificity,
    and the confusion matrix. These notations are very useful for all classification
    tasks, including those which are handled with other algorithms besides neural
    networks. The next chapter will explore a similar kind of task but using unsupervised
    learning – that means, without expected output data – but the fundamentals presented
    in this chapter will be somewhat helpful.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了两个使用神经网络进行疾病诊断应用的例子。为了使本章探索的知识水平一致，简要回顾了分类问题的基本原理。分类任务属于机器学习/数据挖掘领域中应用最广泛的有监督任务类型之一，神经网络被证明非常适合应用于此类问题。读者还介绍了评估分类任务的几个概念，如灵敏度、特异性和混淆矩阵。这些符号对于所有分类任务都非常有用，包括那些使用除神经网络以外的其他算法处理的任务。下一章将探索类似类型的任务，但使用无监督学习——这意味着没有预期的输出数据——但本章中介绍的基本原理将有所帮助。
