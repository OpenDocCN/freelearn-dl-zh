- en: '*Chapter 3*: Training Models with Tabular Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*：使用表格数据训练模型'
- en: In the previous chapter, we learned how to ingest various kinds of datasets
    using fastai and how to clean up datasets. In this chapter, we are going to get
    into the details of training a model with fastai using tabular data. **Tabular
    data**, which is data organized in rows and columns that you would find in a spreadsheet
    file or a database table, is critical to most businesses. The fastai framework
    acknowledges the importance of tabular data by providing a full suite of features
    to support deep learning applications based on tabular data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用 fastai 导入各种类型的数据集，以及如何清理数据集。在本章中，我们将深入了解如何使用 fastai 和表格数据训练模型。**表格数据**是指以行和列组织的数据，通常可以在电子表格文件或数据库表中找到，它对大多数企业至关重要。fastai
    框架通过提供一整套功能来支持基于表格数据的深度学习应用，充分认识到了表格数据的重要性。
- en: To explore deep learning with tabular data in fastai, we will return to the
    `ADULT_SAMPLE` dataset, one of the datasets we examined in [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)*,
    Exploring and Cleaning Up Data with fastai*. By using this dataset, we will train
    a deep learning model, while also learning about the `TabularDataLoaders` (used
    to define the training and test datasets) and `tabular_learner` (used to define
    and train the model) objects.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 fastai 探索表格数据的深度学习，我们将回到 `ADULT_SAMPLE` 数据集，这是我们在[*第二章*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)《使用
    fastai 探索和清理数据》中检查的其中一个数据集。通过使用这个数据集，我们将训练一个深度学习模型，同时学习 `TabularDataLoaders`（用于定义训练和测试数据集）和
    `tabular_learner`（用于定义和训练模型）对象。
- en: We will also look at datasets outside the set of curated datasets to learn how
    we can ingest non-curated datasets to train deep learning models in fastai. We
    will wrap up this chapter by exploring what makes a tabular dataset a decent candidate
    for training a fastai deep learning model and how to save a trained model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将研究 curated 数据集以外的其他数据集，学习如何将非 curated 数据集导入到 fastai 中，以便训练深度学习模型。我们将通过探索什么使得表格数据集成为训练
    fastai 深度学习模型的良好候选者，并学习如何保存已训练的模型来结束本章内容。
- en: 'Here are the recipes that will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Training a model in fastai with a curated tabular dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 curated 表格数据集在 fastai 中训练模型
- en: Training a model in fastai with a non-curated tabular dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用非 curated 表格数据集在 fastai 中训练模型
- en: Training a model with a standalone dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用独立数据集训练模型
- en: Assessing whether a tabular dataset is a good candidate for fastai
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估一个表格数据集是否适合 fastai
- en: Saving a trained tabular model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存已训练的表格模型
- en: Test your knowledge
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试你的知识
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Ensure that you have completed the setup sections in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, and have a working Gradient instance or Colab setup.
    Ensure that you have cloned the repository for this book ([https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook))
    and have access to the `ch3` folder. This folder contains the code samples described
    in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经完成了[*第一章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)《使用 fastai 入门》中的设置部分，并且有一个可用的
    Gradient 实例或 Colab 设置。确保你已经克隆了本书的代码仓库（[https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook)），并且可以访问
    `ch3` 文件夹。该文件夹包含本章描述的代码示例。
- en: Training a model in fastai with a curated tabular dataset
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 curated 表格数据集在 fastai 中训练模型
- en: In [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057), *Exploring
    and Cleaning Up Data with fastai*, you learned how to ingest and examine the `ADULT_SAMPLE`
    curated tabular dataset. In this recipe, we will go through the process of training
    a deep learning model on this dataset using fastai. This will give you an overview
    of the *happy path* to creating a tabular deep learning model with fastai. The
    goal of this recipe is to use this dataset to train a deep learning model with
    fastai, which predicts whether the person described in a particular record will
    have a salary above or below 50k.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)《使用 fastai 探索和清理数据》中，你学习了如何导入和检查
    `ADULT_SAMPLE` curated 表格数据集。在这个食谱中，我们将详细介绍如何使用 fastai 在该数据集上训练一个深度学习模型。这将为你提供使用
    fastai 创建表格深度学习模型的*顺畅路径*的概述。本食谱的目标是使用这个数据集训练一个深度学习模型，预测特定记录中描述的人员的薪资是否会高于或低于 50k。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Confirm that you can open the `training_with_tabular_datasets.ipynb` notebook
    in the `ch3` directory of your repository.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 确认你能在你的代码库的`ch3`目录下打开`training_with_tabular_datasets.ipynb`笔记本。
- en: I am grateful for the opportunity to include the ADULT_SAMPLE dataset featured
    in this section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我感谢能有机会在本节中包含`ADULT_SAMPLE`数据集。
- en: Dataset citation
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: 'Ron Kohavi. (1996) *Scaling Up the Accuracy of Naive-Bayes Classifers: a Decision-Tree
    Hybrid* ([http://robotics.stanford.edu/~ronnyk/nbtree.pdf](http://robotics.stanford.edu/~ronnyk/nbtree.pdf)).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Ron Kohavi. (1996) *提高朴素贝叶斯分类器的准确性：决策树混合方法* ([http://robotics.stanford.edu/~ronnyk/nbtree.pdf](http://robotics.stanford.edu/~ronnyk/nbtree.pdf))。
- en: How to do it…
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'In this recipe, you will be running through the `training_with_tabular_datasets.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，你将会运行`training_with_tabular_datasets.ipynb`笔记本。打开笔记本并在fastai环境中后，完成以下步骤：
- en: Run the cells in the notebook up to the `Define transforms`, `dependent variable`,
    `continuous and categorical columns` cell. By running these cells, you will be
    setting up the notebook and ingesting the `ADULT_SAMPLE` curated tabular dataset
    into a pandas DataFrame, which you will use through the rest of this notebook.
    These cells are identical to the ones in the notebook shown in [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057),
    *Exploring and Cleaning Up Data with fastai*, for examining tabular curated datasets
    `examining_tabular_datasets.ipynb`.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本中的单元格，直到`定义转换`、`因变量`、`连续和分类列`单元格。运行这些单元格后，你将设置好笔记本，并将`ADULT_SAMPLE`策划的表格数据集导入到
    pandas DataFrame 中，之后会在本笔记本的其他部分使用它们。这些单元格与在[*第 2 章*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)中展示的笔记本相同，*使用
    fastai 探索和清理数据*，用于检查策划的表格数据集`examining_tabular_datasets.ipynb`。
- en: 'Run the first new cell in the notebook with the following code:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码运行笔记本中的第一个新单元格：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This cell sets the following values:'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个单元格设置了以下值：
- en: 'a) `procs`: This is a list of the transformations that will be applied in the
    `TabularDataLoaders` object. `FillMissing` specifies that missing the values in
    a column will be replaced with the median value for the column. `Categorify` specifies
    that the values in categorical columns will be replaced with numeric identifiers.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `procs`：这是将应用于`TabularDataLoaders`对象的转换列表。`FillMissing`表示将列中的缺失值替换为该列的中位数值。`Categorify`表示将分类列中的值替换为数字标识符。
- en: 'b) `dep_var`: This will be used to identify which column in the dataset contains
    the dependent variable. This column is also known as the target value or the y
    value for the model – it is the value that the trained model will predict. For
    this model, we are predicting the value for the `salary` column.'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `dep_var`：用于识别数据集中哪个列包含因变量。这个列也被称为目标值或模型的 y 值——它是训练好的模型将要预测的值。在这个模型中，我们预测的是`salary`列的值。
- en: 'c) `cont` and `cat`: These are lists of continuous and categorical columns
    from the `df` DataFrame that are returned by `cont_cat_split`, respectively. This
    function is a major benefit that fastai provides for tabular deep learning models.
    It saves a lot of repetitive coding by automatically detecting which columns are
    continuous (that is, can take on an unlimited set of values, such as currency
    amounts, physical dimensions, or counts of objects) or categorical (that is, can
    only take a finite set of distinct values, such as states of the US or days of
    the week).'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `cont`和`cat`：这是从`df` DataFrame中分别返回的连续列和分类列的列表，这些列是由`cont_cat_split`函数返回的。这个函数是fastai为表格深度学习模型提供的一个主要优势。它通过自动检测哪些列是连续的（即可以取无限集合的值，如货币金额、物理尺寸或物体的计数）或分类的（即只能取有限的离散值，如美国的州或一周的天数），从而节省了大量的重复编码。
- en: 'Run the next cell with the following code to define the `TabularDataLoaders`
    object called `dls`. Note that some of the parameters specified in the definition
    of this object (such as batch size) are usually associated with the training process
    rather than defining the training dataset:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码运行下一个单元格，以定义名为`dls`的`TabularDataLoaders`对象。请注意，在定义该对象时指定的一些参数（如批次大小）通常与训练过程相关，而不是定义训练数据集：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The definition of the `TabularDataLoaders` object uses the following arguments:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`TabularDataLoaders`对象的定义使用以下参数：'
- en: 'a) `df, path, procs`: The DataFrame containing the ingested dataset, the path
    object for the dataset, and the list of transformations defined in the previous
    step.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `df, path, procs`：包含已处理数据集的 DataFrame、数据集的路径对象，以及在前一步中定义的转换列表。
- en: 'b) `cat_names, cont_names`: The lists of categorical and continuous columns
    defined in the previous step.'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `cat_names, cont_names`：在前一步中定义的分类列和连续列的列表。
- en: 'c) `y_names`: The column containing the dependent variable/target values.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `y_names`：包含因变量/目标值的列。
- en: 'd) `valid_idx`: The index values of the subset of rows of the `df` DataFrame
    that will be reserved as the validation dataset for the training process.'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `valid_idx`：`df` DataFrame 中将被保留作为训练过程验证数据集的行子集的索引值。
- en: 'e) `bs`: Batch size for the training process.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) `bs`：训练过程中的批量大小。
- en: 'Run the cell with the following code to define and train the model. The first
    line specifies that the model is being defined using the `TabularDataLoaders`
    object, which was defined in the previous step with the default number of layers,
    and using accuracy as the metric that was optimized in the training process. The
    second line triggers the training process for three epochs; that is, three iterations
    through the entire dataset:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码单元格来定义并训练模型。第一行指定使用 `TabularDataLoaders` 对象定义模型，该对象在前一步中已定义，并使用准确度作为训练过程中优化的度量标准。第二行触发训练过程，进行三次迭代（即三轮遍历整个数据集）：
- en: '[PRE2]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output of this cell will be the training results by epoch. The results
    include the epoch''s number, the training loss, the validation loss, and the elapsed
    time for each epoch:'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出将是按轮次显示的训练结果。结果包括每个轮次的编号、训练损失、验证损失以及每轮的耗时：
- en: '![Figure 3.1 – Training results'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.1 – 训练结果'
- en: '](img/B16216_03_01.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_01.jpg)'
- en: Figure 3.1 – Training results
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.1 – 训练结果
- en: Run the following cell to get a sample result of the trained model's predictions.
    You can compare the `salary` column with the `salary_pred` column (the prediction
    made by the model – highlighted in the preceding screenshot) to get a snapshot
    of how the model performed for this sample of rows from the dataset. In this sample
    set, the model's predictions match the actual values of the dependent variable
    in the `salary` column:![Figure 3.2 – Output of show_results
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以获取训练模型预测的示例结果。你可以将 `salary` 列与 `salary_pred` 列（模型预测值，在前面的截图中突出显示）进行比较，从而获得模型在这一数据集样本中表现的概览。在这个样本集中，模型的预测与
    `salary` 列中因变量的实际值相匹配：![图 3.2 – show_results 的输出
- en: '](img/B16216_03_02.jpg)'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_02.jpg)'
- en: Figure 3.2 – Output of show_results
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.2 – show_results 的输出
- en: 'Run the following cell to get a summary of the structure of the trained model:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以获取训练模型结构的总结：
- en: '[PRE3]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output of this cell includes the following details:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出包括以下细节：
- en: 'a) A list of all the layers that make up the model:'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 构成模型的所有层的列表：
- en: '![Figure 3.3 – List of layers that make up the model'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3 – 构成模型的层列表'
- en: '](img/B16216_03_03.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_03.jpg)'
- en: Figure 3.3 – List of layers that make up the model
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 构成模型的层列表
- en: 'b) The parameters in the trained model, the optimizer and loss functions, and
    the callbacks used. Callbacks ([https://docs.fast.ai/callback.core.html](https://docs.fast.ai/callback.core.html))
    specify actions to be taken during the training process, such as stopping the
    training process prior to executing all the epochs. In the case of this trained
    model, callbacks are automatically specified by fastai to track the number of
    epochs done (`TrainEvalCallback`), track losses and metrics by batch/epoch (`Recorder`),
    and display the progress bars shown while the model is being trained (`ProgressCallBack`):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: b) 训练模型中的参数、优化器和损失函数，以及使用的回调函数。回调函数（[https://docs.fast.ai/callback.core.html](https://docs.fast.ai/callback.core.html)）指定在训练过程中执行的操作，如在执行所有迭代之前停止训练过程。对于这个训练好的模型，回调函数由
    fastai 自动指定，以跟踪已完成的训练轮次（`TrainEvalCallback`）、按批次/轮次跟踪损失和度量（`Recorder`）以及在训练过程中显示进度条（`ProgressCallBack`）：
- en: '![Figure 3.4 – Additional details in the output of summary()'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.4 – summary() 输出中的附加细节'
- en: '](img/B16216_03_04.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_04.jpg)'
- en: Figure 3.4 – Additional details in the output of summary()
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – summary() 输出中的附加细节
- en: You have now completely trained a deep learning model with a curated tabular
    dataset using fastai.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经使用 fastai 完全训练了一个深度学习模型，并使用了精心整理的表格数据集。
- en: How it works…
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: As you saw in this recipe, once the data has been ingested, it only takes a
    few lines of code with fastai to get a trained deep learning model. The simplicity
    and compactness of fastai code is partially down to fastai making reasonable default
    choices when possible.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这个食谱中看到的那样，一旦数据被导入，只需几行 fastai 代码就能得到一个训练好的深度学习模型。fastai 代码的简洁性和紧凑性，部分归功于它在可能的情况下做出合理的默认选择。
- en: 'For example, fastai determines that when the target column is categorical,
    the model should be predicting choices in a category (in the case of this model,
    a binary choice of whether a person''s salary is above or below 50 k) rather than
    continuous values. The following are additional benefits provided by fastai for
    training deep learning models with tabular data:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，fastai 确定，当目标列是分类数据时，模型应预测某一类别中的选项（在这个模型中，是预测一个人的工资是否高于或低于 50k，而不是连续的数值）。以下是
    fastai 在使用表格数据训练深度学习模型时提供的额外好处：
- en: Detecting which columns in a DataFrame are categorical or continuous
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测 DataFrame 中哪些列是分类数据，哪些列是连续数据
- en: Selecting appropriate callbacks for the training process
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择适当的回调函数来进行训练过程
- en: Defining the layers for the deep learning model (including embedding layers
    for the categorical columns)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义深度学习模型的层（包括为类别列定义的嵌入层）
- en: Let's compare what we would have to do for a Keras deep learning model. In a
    Keras deep learning model for a tabular dataset, each of these characteristics
    of the model would have to be explicitly coded, resulting in longer, more complex
    code to create the model. In addition, somebody learning about deep learning models
    for tabular datasets would face a bigger challenge by needing to deal with many
    more details to get their first working trained model. The bottom line is that
    fastai makes it possible to get to a basic deep learning model faster.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下在 Keras 深度学习模型中需要做些什么。在 Keras 深度学习模型中，对于一个表格数据集，模型的每个特征都必须明确编码，这将导致创建模型的代码更长、更复杂。此外，学习表格数据集深度学习模型的人还需要处理更多细节，才能得到第一个有效的训练模型。总的来说，fastai
    使得快速构建基本深度学习模型成为可能。
- en: Before moving on to the next recipe, it's worth digging into the model from
    this recipe because the other recipes in this chapter will follow the same pattern.
    A deeply detailed description of the model is beyond the scope of this book, so
    we will just focus on some highlights here.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续下一个食谱之前，值得深入探讨一下这个食谱中的模型，因为本章其他食谱将遵循相同的模式。对该模型的详细描述超出了本书的范围，因此我们这里只关注一些亮点。
- en: 'As shown in the recipe, the model is defined as a `tabular_learner` object
    (documentation here: [https://docs.fast.ai/tabular.learner.html](https://docs.fast.ai/tabular.learner.html)).
    This object is a specialization of the fastai `learner` object which you first
    saw in the *Understanding the world in four applications: tables, text, recommender
    systems, and images* section of [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)*,
    Getting Started with fastai*. You can see the structure of this model from the
    output of `learn.summary()`. The beginning of the output specifies `Input shape:
    [''64 x 9'', ''64 x 6'']` - the second dimension of the first element corresponds
    with the number of categorical columns, and the second dimension of the second
    element corresponds with the number of continuous columns. There are embedding
    layers (documentation here: [https://docs.fast.ai/layers.html#Embeddings](https://docs.fast.ai/layers.html#Embeddings))
    defined for the categorical columns (the columns in the `cat` list) and a `BatchNorm`
    layer (documentation here: [https://docs.fast.ai/layers.html#BatchNorm-layers](https://docs.fast.ai/layers.html#BatchNorm-layers))
    for the continuous columns.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '如食谱中所示，模型被定义为 `tabular_learner` 对象（文档链接：[https://docs.fast.ai/tabular.learner.html](https://docs.fast.ai/tabular.learner.html)）。这个对象是
    fastai `learner` 对象的一个特化版本，后者你首次见到是在 [*第1章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)
    *了解四大应用领域：表格、文本、推荐系统和图像* 部分中。在 `learn.summary()` 的输出中，你可以看到这个模型的结构。输出的开始部分指定了
    `Input shape: [''64 x 9'', ''64 x 6'']` —— 第一个元素的第二维度对应着类别列的数量，第二个元素的第二维度对应着连续列的数量。为类别列（`cat`
    列表中的列）定义了嵌入层（文档链接：[https://docs.fast.ai/layers.html#Embeddings](https://docs.fast.ai/layers.html#Embeddings)），并为连续列定义了一个
    `BatchNorm` 层（文档链接：[https://docs.fast.ai/layers.html#BatchNorm-layers](https://docs.fast.ai/layers.html#BatchNorm-layers)）。'
- en: To see additional details about the structure of the model, see the output of
    `learn.model`. In particular, you can see that for the final `Linear` layer, `out_features
    = 2`, corresponds with the binary output of the model (the individual's income
    is above/below 50 k).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看模型结构的更多详细信息，请查看`learn.model`的输出。特别地，你可以看到，在最后一个`Linear`层中，`out_features =
    2`，这对应着模型的二元输出（个人收入是否高于/低于 50k）。
- en: Training a model in fastai with a non-curated tabular dataset
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 fastai 中使用非精心整理的表格数据集训练模型
- en: In [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057), *Exploring
    and Cleaning Up Data with fastai*, you reviewed the curated datasets provided
    by fastai. In the previous recipe, you created a deep learning model that had
    been trained on one of these curated datasets. What if you want to train a fastai
    model for a tabular dataset that is not one of these curated datasets?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第2章*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)《使用 fastai 探索和清理数据》中，你回顾了
    fastai 提供的精心整理的数据集。在之前的食谱中，你创建了一个深度学习模型，该模型已经在这些精心整理的数据集之一上进行了训练。如果你想为一个非精心整理的数据集训练
    fastai 模型，该怎么办呢？
- en: In this recipe, we will go through the process of ingesting a non-curated dataset
    – the Kaggle house prices dataset ([https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data))
    – and training a deep learning model on it. This dataset presents some additional
    challenges. Compared to a curated fastai dataset, there are additional steps required
    to ingest the dataset, and its structure requires special handling to deal with
    missing values.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将介绍如何处理一个非精心整理的数据集——Kaggle 房价数据集（[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)）并在其上训练深度学习模型。这个数据集提出了一些额外的挑战。与精心整理的
    fastai 数据集相比，处理该数据集需要额外的步骤，而且它的结构需要特别处理，以应对缺失值问题。
- en: The goal of this recipe is to use this dataset to train a deep learning model,
    that then predicts whether a house has a sale price that is above or below the
    average price for the dataset.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱的目标是使用该数据集训练一个深度学习模型，预测房屋的销售价格是高于还是低于该数据集的平均价格。
- en: Getting ready
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'To complete this recipe you will need a Kaggle ID. If you don''t already have
    one, you can get one here: [https://www.kaggle.com/account/login](https://www.kaggle.com/account/login).
    Once you have your Kaggle ID, complete the following steps to get the token for
    accessing the Kaggle house prices dataset from within your notebook:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本食谱，你需要一个 Kaggle ID。如果你还没有，可以在这里注册：[https://www.kaggle.com/account/login](https://www.kaggle.com/account/login)。获得
    Kaggle ID 后，请按照以下步骤获取在笔记本中访问 Kaggle 房价数据集的令牌：
- en: Log in with your Kaggle ID, click on your account (top right), and then click
    on **Account**:![Figure 3.5 – Kaggle account menu
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用你的 Kaggle ID 登录，点击账户（右上角），然后点击**账户**：![图 3.5 – Kaggle 账户菜单
- en: '](img/B16216_03_05.jpg)'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_05.jpg)'
- en: Figure 3.5 – Kaggle account menu
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.5 – Kaggle 账户菜单
- en: On the `kaggle.json` file will be downloaded on your local system:![Figure 3.6
    – Selecting Create New API Token to get a new Kaggle API token
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kaggle.json`文件将被下载到你的本地系统：![图 3.6 – 选择创建新 API 密钥来获取新的 Kaggle API 密钥'
- en: '](img/B16216_03_06.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_06.jpg)'
- en: Figure 3.6 – Selecting Create New API Token to get a new Kaggle API token
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.6 – 选择创建新 API 密钥来获取新的 Kaggle API 密钥
- en: In your Gradient environment, open a Terminal session, go to the `/root` directory,
    and create a new directory called `.kaggle`.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的 Gradient 环境中，打开一个终端会话，进入`/root`目录，并创建一个名为`.kaggle`的新目录。
- en: Upload the `kaggle.json` file that you downloaded in *Step 2* to the new directory
    that you just created; that is, `/root/.kaggle`.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你在*步骤 2*中下载的`kaggle.json`文件上传到你刚刚创建的新目录中，也就是`/root/.kaggle`。
- en: These steps will prepare you to use the Kaggle house price dataset ([https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data))
    in this recipe.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将帮助你准备好在本食谱中使用 Kaggle 房价数据集（[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)）。
- en: I am grateful for the opportunity to include the house price dataset featured
    in this section.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我很感激能有机会在这一部分包含房价数据集。
- en: Dataset citation
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: 'Dean De Cock (2011). Ames, Iowa: Alternative to the Boston Housing Data as
    an End of Semester Regression Project ([http://jse.amstat.org/v19n3/decock.pdf)](http://jse.amstat.org/v19n3/decock.pdf)
    Journal of Statistics Education Volume 19, Number 3(2011), ([www.amstat.org/publications/jse/v19n3/decock.pdf](http://www.amstat.org/publications/jse/v19n3/decock.pdf))'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Dean De Cock (2011)。艾姆斯，爱荷华州：作为学期末回归项目的波士顿住房数据的替代方案 ([http://jse.amstat.org/v19n3/decock.pdf)](http://jse.amstat.org/v19n3/decock.pdf)
    《统计学教育期刊》第19卷，第3期（2011年），([www.amstat.org/publications/jse/v19n3/decock.pdf](http://www.amstat.org/publications/jse/v19n3/decock.pdf))
- en: How to do it…
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, you will be running through the `accessing_non_curated_datasets.ipynb`
    notebook, as well as the fastai dataset documentation, to understand the datasets
    that fastai curates. Once you have the notebook open in your fastai environment,
    complete the following steps:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，你将通过 `accessing_non_curated_datasets.ipynb` 笔记本以及 fastai 数据集文档来理解 fastai
    所整理的数据集。一旦你在 fastai 环境中打开了该笔记本，完成以下步骤：
- en: 'If you have not already done so, install the `kaggle` library by running the
    following command:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有安装，运行以下命令以安装 `kaggle` 库：
- en: '[PRE4]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Run the first three cells of the notebook to load the libraries that you will
    need for this recipe and prepare the notebook for fastai.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本的前三个单元格，加载你在此示例中所需的库，并准备好 fastai 笔记本。
- en: 'In your Gradient environment, go to the `/root/.kaggle` directory and open
    the `kaggle.json` file. The contents of this file should look like this, with
    your ID and your 32-character key as the first and second values, respectively:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的 Gradient 环境中，进入 `/root/.kaggle` 目录并打开 `kaggle.json` 文件。该文件的内容应如下所示，其中你的
    ID 和 32 字符的密钥分别是第一个和第二个值：
- en: '[PRE5]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Copy the contents of your `kaggle.json` file.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制你的 `kaggle.json` 文件的内容。
- en: 'In your copy of the `accessing_non_curated_datasets.ipynb` notebook, paste
    the content of the `kaggle.json` file into single quotes to assign the value to
    the variable creds. Then, run the cell:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你复制的 `accessing_non_curated_datasets.ipynb` 笔记本中，将 `kaggle.json` 文件的内容粘贴到单引号中，以将值分配给变量
    creds。然后，运行此单元格：
- en: '[PRE6]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Run this cell to set the credential path for the dataset:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以设置数据集的凭证路径：
- en: '[PRE7]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run this cell to set the path for your dataset:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以设置数据集的路径：
- en: '[PRE8]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Run this cell to create the target directory for the dataset, download the
    dataset, unzip the dataset in the target directory, and list the contents of the
    target directory:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以创建目标目录以存储数据集，下载数据集，将数据集解压到目标目录，并列出目标目录的内容：
- en: '[PRE9]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output of the `path.ls()` function shows the structure of the dataset.
    In this recipe, we will use `train.csv` to train the deep learning model and then
    use `test.csv` to exercise the trained model:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`path.ls()` 函数的输出显示了数据集的结构。在此示例中，我们将使用 `train.csv` 来训练深度学习模型，然后使用 `test.csv`
    来测试训练后的模型：'
- en: '[PRE10]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Run this cell to ingest the `train.csv` file into a pandas DataFrame called
    `df_train`:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以将 `train.csv` 文件加载到名为 `df_train` 的 pandas DataFrame 中：
- en: '[PRE11]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Run this cell to ingest the `test.csv` file into a pandas DataFrame called
    `df_test`:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以将 `test.csv` 文件加载到名为 `df_test` 的 pandas DataFrame 中：
- en: '[PRE12]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Run the `shape` command to get the dimensions of `df_train` and `df_test`. Notice
    that `df_test` has one fewer columns than `df_train` – can you think of why this
    would be the case and which column is missing from `df_test`?
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `shape` 命令获取 `df_train` 和 `df_test` 的维度。注意到 `df_test` 比 `df_train` 少了一列——你能想到为什么会这样吗？哪个列在
    `df_test` 中缺失？
- en: 'Run this cell to define the `under_over()` function, which returns `''0''`
    if the input value is less than the mean and `''1''` if not:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以定义 `under_over()` 函数，如果输入值小于均值，则返回 `'0'`，否则返回 `'1'`：
- en: '[PRE13]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Run this cell to use the `under_over()` function, which will replace the values
    in the `SalePrice` column with indicators of whether the value was above or below
    the average for the column:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格使用 `under_over()` 函数，该函数将用指示值是否高于或低于该列平均值的标志替换 `SalePrice` 列中的值：
- en: '[PRE14]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: When you display the contents of the `df_train` DataFrame, you will see that
    the values in the `SalePrice` column have been replaced with zeros and ones:![Figure
    3.7 – The values in the SalePrice column have been replaced
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你显示 `df_train` DataFrame 的内容时，你会看到 `SalePrice` 列中的值已被替换为零和一：![图 3.7 – `SalePrice`
    列中的值已被替换
- en: '](img/B16216_03_07.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_07.jpg)'
- en: Figure 3.7 – The values in the SalePrice column have been replaced
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.7 – `SalePrice` 列中的值已被替换
- en: 'Run this cell to see the count of each of the new values in the `SalePrice`
    column:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以查看 `SalePrice` 列中新值的计数：
- en: '[PRE15]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Run this cell to define the transformation to apply to the dataset, the column
    that contains the dependent variable (target), and the continuous and categorical
    columns:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以定义应用于数据集的变换，包含因变量（目标）的列，以及连续和分类列：
- en: '[PRE16]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This cell sets the following values:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元格设置以下值：
- en: 'a) `procs`: This is a list of the transformations that will be applied to the
    `TabularDataLoaders` object. `FillMissing` specifies that the missing values in
    a column are replaced with the median value for the column. `Categorify` specifies
    that the values in the categorical columns are replaced with numeric identifiers.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `procs`：这是一个将应用于`TabularDataLoaders`对象的变换列表。`FillMissing`指定将列中的缺失值替换为该列的中位数值。`Categorify`指定将分类列中的值替换为数字标识符。
- en: 'b) `dep_var`: This will be used to identify which column in the dataset contains
    the dependent variable; that is, the column that contains the value that we want
    the model to predict. For this model, we are predicting the value for the `SalePrice`
    column.'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `dep_var`：用于标识数据集中包含因变量的列，即包含我们希望模型预测的值的列。对于此模型，我们预测的是`SalePrice`列的值。
- en: 'c) `cont` and `cat`: These are lists of continuous and categorical columns
    from the `df_train` DataFrame returned by using `cont_cat_split`.'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `cont`和`cat`：这些是使用`cont_cat_split`从`df_train` DataFrame返回的连续和分类列的列表。
- en: 'Run this cell to check for missing values in the `df_train` DataFrame. The
    first line gets a count of missing values in the DataFrame, while the second line
    defines a new DataFrame, `df_train_missing`, that has a row for each column in
    the original DataFrame that has at least one missing value. The columns of this
    DataFrame are the names of the columns with missing values, the missing value
    count for each column, and the proportion of values that are missing in the column:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以检查`df_train` DataFrame中的缺失值。第一行获取DataFrame中缺失值的计数，而第二行定义了一个新的DataFrame，`df_train_missing`，它包含原始DataFrame中每一列中至少有一个缺失值的行。此DataFrame的列包括包含缺失值的列的名称、每列的缺失值计数以及每列中缺失值的比例：
- en: '[PRE17]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Looking at the values in `df_train_missing`, we can see that some columns have
    a large number of missing values:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 查看`df_train_missing`中的值，我们可以看到某些列有大量的缺失值：
- en: '![Figure 3.8 – Rows from df_train_missing'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.8 – 来自 df_train_missing 的行'
- en: '](img/B16216_03_08.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_08.jpg)'
- en: Figure 3.8 – Rows from df_train_missing
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.8 – 来自 df_train_missing 的行
- en: 'Run this cell to deal with the missing values in the `df_train` and `df_test`
    DataFrames. The first two statements replace the missing values in the categorical
    columns with the most common non-missing value, while the second two statements
    replace the missing values in the continuous columns with zeros:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以处理`df_train`和`df_test` DataFrame中的缺失值。前两条语句将分类列中的缺失值替换为最常见的非缺失值，而后两条语句将连续列中的缺失值替换为零：
- en: '[PRE18]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Run this cell to check for missing values in the `df_train` DataFrame once
    more:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以再次检查`df_train` DataFrame中的缺失值：
- en: '[PRE19]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now, when you check the contents of the `df_train_missing` DataFrame, it will
    be empty, confirming that all the missing values have been dealt with:![Figure
    3.9 – Confirmation that the missing values have been dealt with
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，当你检查`df_train_missing` DataFrame的内容时，它将是空的，确认所有缺失值已经处理完毕：![图 3.9 – 确认缺失值已经处理
- en: '](img/B16216_03_09.jpg)'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_09.jpg)'
- en: Figure 3.9 – Confirmation that the missing values have been dealt with
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.9 – 确认缺失值已经处理
- en: 'Run this cell to create a `TabularDataLoaders` object. The first line defines
    the transformation procedures to be applied in the `TabularDataLoaders` object,
    while the second line defines the `TabularDataLoaders` object:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以创建`TabularDataLoaders`对象。第一行定义了将在`TabularDataLoaders`对象中应用的变换程序，第二行定义了`TabularDataLoaders`对象：
- en: '[PRE20]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here are the arguments for the definition of the `TabularDataLoaders` object:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是`TabularDataLoaders`对象定义的参数：
- en: 'a) `procs`: This is a list of the transformations that will be applied to the
    `TabularDataLoaders` object. `Normalize` specifies that the values are all scaled
    to a consistent range. `Categorify` specifies that the values in the categorical
    columns are replaced with numeric identifiers.'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `procs`：这是一个将应用于`TabularDataLoaders`对象的变换列表。`Normalize`指定所有值都会被缩放到一致的范围。`Categorify`指定将分类列中的值替换为数字标识符。
- en: 'b) `df_train, path, procs`: The DataFrame containing the ingested dataset,
    the path object for the dataset, and the list of transformations defined in the
    previous step.'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `df_train, path, procs`：包含导入数据集的 DataFrame，数据集的路径对象，以及在前一步中定义的转换列表。
- en: 'c) `cat_names, cont_names`: The lists of categorical and continuous columns.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `cat_names, cont_names`：类别和连续列的列表。
- en: 'd) `y_names`: The column containing the dependent variable/target values.'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `y_names`：包含因变量/目标值的列。
- en: 'e) `valid_idx`: The index values of the subset of rows of the `df` DataFrame
    that will be reserved as the validation dataset for the training process.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) `valid_idx`：将保留为训练过程验证数据集的`df` DataFrame中行子集的索引值。
- en: 'f) `bs`: The batch size for the training process.'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f) `bs`：训练过程的批次大小。
- en: 'Run this cell to define and train the deep learning model. The first line specifies
    that the model is being created using the `TabularDataLoaders` object we defined
    in the previous step, with the default number of layers and accuracy as the metrics
    being optimized in the training process. The second line triggers the training
    process for `5` epochs:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格来定义并训练深度学习模型。第一行指定模型是使用我们在前一步中定义的`TabularDataLoaders`对象创建的，并且使用默认的层数和准确度作为训练过程中优化的指标。第二行触发了`5`个
    epoch 的训练过程：
- en: '[PRE21]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The training process produces an output that shows the training loss, validation
    loss, and accuracy for each epoch. This means we have trained a model that can
    predict whether the cost of a given property from the validation set is above
    or below the average with 92% accuracy. Can you think of some reasons why the
    accuracy of this model is somewhat better than the accuracy of the model you trained
    in the previous recipe?
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练过程会产生一个输出，显示每个 epoch 的训练损失、验证损失和准确度。这意味着我们已经训练出了一个可以预测验证集中的某个属性成本是否高于或低于平均值的模型，准确率为
    92%。你能想到一些原因，为什么这个模型的准确率比你在前一节中训练的模型要好一些吗？
- en: '![Figure 3.10 – Results of training on the non-curated dataset'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.10 – 在非精选数据集上训练的结果'
- en: '](img/B16216_03_10.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_10.jpg)'
- en: Figure 3.10 – Results of training on the non-curated dataset
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.10 – 在非精选数据集上训练的结果
- en: 'You can run this cell to apply the trained model to the test dataset. Note
    that because of the structure of this dataset, the test dataset does not include
    y-dependent values, which means that while you can apply the model to the test
    records, you don''t have any way of assessing the accuracy of the predictions
    that the model makes on the test set:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以运行此单元格来将训练好的模型应用于测试数据集。请注意，由于该数据集的结构，测试数据集不包含 y 相关的值，这意味着虽然你可以将模型应用于测试记录，但你无法评估模型在测试集上做出的预测的准确性：
- en: '[PRE22]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Run this cell to get a sample of predictions that the trained model makes on
    the test dataset:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以获取训练模型在测试数据集上做出的预测样本：
- en: '[PRE23]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output of `learn.show_results()` lets you see the result of applying the
    trained model to the dataset:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`learn.show_results()`的输出让你可以查看将训练好的模型应用于数据集的结果：'
- en: '![Figure 3.11 – The subset of results from applying the model trained to a
    non-curated dataset'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.11 – 将训练好的模型应用于非精选数据集后的结果子集'
- en: '](img/B16216_03_11.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_11.jpg)'
- en: Figure 3.11 – The subset of results from applying the model trained to a non-curated
    dataset
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11 – 将训练好的模型应用于非精选数据集后的结果子集
- en: You have now gone through the process of using a non-curated dataset to train
    a fastai deep learning model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经完成了使用非精选数据集来训练 fastai 深度学习模型的过程。
- en: How it works…
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, you learned how to adapt to a different kind of dataset where
    the train and test data is separate. In this case, you cannot rely on the transformations
    in the `TabularDataLoaders` object to deal with missing data. That's why the code
    associated with this recipe deals with the missing values in each of the train
    and test datasets individually.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了如何适应另一种类型的数据集，其中训练集和测试集是分开的。在这种情况下，你不能依赖`TabularDataLoaders`对象中的转换来处理缺失数据。因此，本节中的代码单独处理了训练集和测试集中的缺失值。
- en: Training a model with a standalone dataset
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用独立数据集训练模型
- en: In the previous recipes in this chapter, we looked at training fastai models
    on a curated tabular dataset and a dataset directly loaded from Kaggle. In this
    recipe, we are going to examine how to train a model with a dataset that is from
    a self-standing file. The dataset we will use in this recipe is made up of property
    listings in Kuala Lumpur, Malaysia and is available from the Kaggle site at [https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur](https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前几个食谱中，我们介绍了如何在一个经过整理的表格数据集和一个直接从Kaggle加载的数据集上训练fastai模型。在这个食谱中，我们将探讨如何用来自自立文件的数据集来训练模型。我们将在这个食谱中使用的数据集由马来西亚吉隆坡的房地产列表组成，并可通过Kaggle网站上的[https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur](https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur)获取。
- en: This dataset is not like the tabular datasets we have seen so far. The datasets
    we have already encountered have been well-behaved and have only required a small
    amount of cleanup. The Kualu Lumpur property dataset, by contrast, is a real-world
    dataset. In addition to missing values, it contains many errors and irregularities.
    It is also large enough (over 50k records) to give deep learning a decent chance
    to be useful on it.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集与我们之前见过的表格数据集不同。我们之前遇到的数据集行为良好，仅需要少量清理工作。相比之下，吉隆坡的房地产数据集是一个现实世界的数据集。除了缺失值外，它还包含许多错误和不规则性。它的规模也足够大（超过5万条记录），为深度学习提供了一个合适的应用场景。
- en: Getting ready
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, so that you have a fastai environment set up. Confirm
    that you can open the `training_model_standalone_tabular_dataset.ipynb` notebook
    in the `ch3` directory of your repository. Also, ensure that you have uploaded
    the data file by following these steps:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经按照[*第一章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)中的步骤操作，*快速入门 fastai*，以便设置好
    fastai 环境。确认你能够在你的仓库的`ch3`目录下打开`training_model_standalone_tabular_dataset.ipynb`笔记本。还需确保按照以下步骤上传了数据文件：
- en: Download `data_kaggle.csv.zip` from [https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur](https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur).
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur](https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur)下载`data_kaggle.csv.zip`。
- en: Unzip the downloaded file to extract `data_kaggle.csv`.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压下载的文件以提取`data_kaggle.csv`。
- en: 'From the Terminal in your Gradient environment, make your current directory
    `/storage/archive`:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的Gradient环境中的终端，从`/storage/archive`设置为当前目录：
- en: '[PRE24]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Create a folder called `/storage/archive/kl_property:`
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`/storage/archive/kl_property`的文件夹：
- en: '[PRE25]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Upload `data_kaggle.csv` to `/storage/archive/kl_property`. You can use the
    upload button in JupyterLab in Gradient to do the upload, but you need to do so
    by performing several steps:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`data_kaggle.csv`上传到`/storage/archive/kl_property`。你可以使用Gradient中的JupyterLab上传按钮进行上传，但需要按照以下步骤操作：
- en: 'a) From the Terminal in your Gradient environment, make `/notebooks` your current
    directory:'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 在你的Gradient环境中的终端，将`/notebooks`设置为当前目录：
- en: '[PRE26]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'temp your current folder, select the upload button, as shown in the following
    screenshot, and select the data_kaggle.csv file from your local system folder
    where you extracted it in *step 2*:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 临时打开你的当前文件夹，选择上传按钮，如下图所示，并从你解压文件的本地系统文件夹中选择`data_kaggle.csv`文件：
- en: '[PRE27]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![Figure 3.12 – Upload button in JupyterLab'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12 – JupyterLab中的上传按钮](img/B16216_03_12.jpg)'
- en: '](img/B16216_03_12.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_12.jpg)'
- en: Figure 3.12 – Upload button in JupyterLab
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – JupyterLab中的上传按钮
- en: 'd) From the Terminal in your Gradient environment, copy `data_kaggle.csv` into
    `/storage/archive/kl_property`:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: d) 在你的Gradient环境中的终端，将`data_kaggle.csv`复制到`/storage/archive/kl_property`：
- en: '[PRE28]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: I want to acknowledge the dataset featured in this section and express my gratitude
    for the opportunity to include it in the book.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在此感谢本节中使用的数据集，并感谢能够将其纳入本书的机会。
- en: Dataset citation
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: Jas S (2019). *Property Listings in Kuala Lumpur* ([https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur](https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur))
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Jas S (2019)。 *吉隆坡房地产列表* ([https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur](https://www.kaggle.com/dragonduck/property-listings-in-kuala-lumpur))
- en: Let's see how to go about it in the next section.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看下一节该如何进行。
- en: How to do it…
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: In this recipe, you will be running through the `training_model_standalone_tabular_dataset.ipynb`
    notebook to train a model using the Kuala Lumpur property prices dataset.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将通过运行`training_model_standalone_tabular_dataset.ipynb`笔记本，使用吉隆坡房地产价格数据集来训练模型。
- en: 'Once you have the notebook open in your fastai environment, follow these steps:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 打开fastai环境中的笔记本后，按照以下步骤操作：
- en: Run the first three cells to import the necessary libraries and set up the notebook
    for fastai.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前三个单元格以导入必要的库，并为fastai设置笔记本。
- en: 'Run this cell to associate `path` with the directory that you copied the `data_kaggle.csv`
    file into:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格，将`path`与您复制了`data_kaggle.csv`文件的目录关联起来：
- en: '[PRE29]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Run this cell to ingest the dataset into the `df_train` DataFrame:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以将数据集导入到`df_train`数据框中：
- en: '[PRE30]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Run the following cell to see the first few rows of the dataset:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格查看数据集的前几行：
- en: '[PRE31]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output of `df_train.head()` shows a sample of rows from the dataset:'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`df_train.head()`的输出显示了数据集中的一些数据行：'
- en: '![Figure 3.13 – A sample of rows from the Kuala Lumpur property dataset'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.13 – 吉隆坡房地产数据集中的一部分数据行'
- en: '](img/B16216_03_13.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_13.jpg)'
- en: Figure 3.13 – A sample of rows from the Kuala Lumpur property dataset
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.13 – 吉隆坡房地产数据集中的一部分数据行
- en: 'Note the values in the `Price` column. The goal of this recipe is to train
    a deep learning model to predict whether values in this column are above or below
    the average. To do this, we need to start with numeric values in this column.
    You can see three problems just from this small sample of data:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意查看`Price`列中的值。本教程的目标是训练一个深度学习模型，预测此列中的值是高于还是低于平均值。为此，我们需要从此列中的数值开始。仅从这小段数据样本中，你可以看到三个问题：
- en: a) The values include `RM`, the symbol for the ringgit, the Malaysian currency.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 这些值包括`RM`，这是马来西亚货币林吉特的符号。
- en: b) The values include a comma thousand separator.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 这些值包括千分位的逗号分隔符。
- en: c) Some rows have a missing value in this column.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 某些行在此列中有缺失值。
- en: Over the next few cells of the notebook, we will deal with these problems so
    that we end up with this column containing entirely valid numeric values.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在接下来的几个单元格中，我们将处理这些问题，确保该列最终包含完全有效的数值。
- en: 'Run this cell to get the number of rows in the dataset. The first element of
    the output is the number of rows in the DataFrame:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以获取数据集中的行数。输出的第一个元素是数据框中的行数：
- en: '[PRE32]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Run the cells to define the `remove_currency()` and `remove_after_space()` functions.
    You will need these functions to clean up the dataset.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行单元格以定义`remove_currency()`和`remove_after_space()`函数。你将需要这些函数来清理数据集。
- en: 'Run this cell to address the problems with the `Price` column demonstrated
    by the output of `df_train.head()`. This cell drops rows in the dataset where
    the `Price` value is missing (first statement), removes the currency symbol from
    the `Price` column (second statement), and converts the values in the `Price`
    column into numeric values after removing any commas:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以解决`Price`列中由`df_train.head()`输出显示的问题。此单元格将删除数据集中`Price`值缺失的行（第一条语句），去除`Price`列中的货币符号（第二条语句），并在去除逗号后将`Price`列中的值转换为数值：
- en: '[PRE33]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Run this cell to get the number of rows in the dataset again. It's important
    to know this number because we have eliminated some rows from the dataset in the
    last cell, and we will remove more as we clean up the `Size` column. By checking
    the shape of the DataFrame as we are removing rows, we can be sure we're not losing
    too much information:![Figure 3.14 – Getting the shape of the DataFrame prior
    to dropping rows
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格再次获取数据集中的行数。了解这个数字很重要，因为我们已经在上一个单元格中删除了一些行，并且在清理`Size`列时还会删除更多行。通过检查删除行前后数据框的形状，我们可以确保不会丢失过多的信息：![图3.14
    – 删除行之前获取数据框的形状
- en: '](img/B16216_03_14.jpg)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_14.jpg)'
- en: Figure 3.14 – Getting the shape of the DataFrame prior to dropping rows
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.14 – 删除行之前获取数据框的形状
- en: 'The `Size` column has a lot of useful information in it, but we have to do
    some work to get it ready to help train a deep learning model. To start with,
    run the following cell to see some examples of the values in the `Size` column.
    Here is the information we want to extract from this column:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Size`列包含了许多有用的信息，但我们必须做一些工作，才能将其准备好帮助训练深度学习模型。首先，运行以下单元格以查看`Size`列中一些示例值。我们希望从此列中提取以下信息：'
- en: a) Extract the prefix (for example, `Built-up`, `Land area`, and so on) into
    a new column.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 将前缀（例如，`Built-up`、`Land area`等）提取到新列中。
- en: b) Get a single numeric value for the remainder of the contents of the column;
    that is, replace 1,335 sq. ft. with 1,335 and replace 22 x 80 sq. ft. with 1,760.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 获取`Size`列剩余内容的单一数值；即，将1,335 sq. ft.替换为1,335，将22 x 80 sq. ft.替换为1,760。
- en: c) Drop rows where the suffix in the `Size` column cannot yield a numeric value.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 删除`Size`列中后缀无法转换为数值的行。
- en: 'The output of `df_train[''Size''].head()` shows examples of the values in the
    `Size` column:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`df_train[''Size''].head()`的输出显示了`Size`列中值的示例：'
- en: '![Figure 3.15 – Examples of values in the Size column'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.15 – `Size`列中值的示例'
- en: '](img/B16216_03_15.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_15.jpg)'
- en: Figure 3.15 – Examples of values in the Size column
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.15 – `Size`列中值的示例
- en: 'Here are the operations we want to perform on the `Size` column to prepare
    it to train a deep learning model:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是我们希望对`Size`列进行的操作，以便为训练深度学习模型做准备：
- en: a) Extract the prefix (for example, `Built-up`, `Land area`, and so on) into
    a new column.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 将前缀（例如`Built-up`、`Land area`等）提取到一个新列中。
- en: b) Where possible, get a single numeric value for the remainder of the contents
    of the `Size` column. For example, we want to replace 1,335 sq. ft. with 1,335
    and replace 22 x 80 sq. ft. with 1,760.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 在可能的情况下，获取`Size`列剩余内容的单一数值。例如，我们希望将1,335 sq. ft.替换为1,335，将22 x 80 sq. ft.替换为1,760。
- en: c) For rows where it is not possible to get a numeric value from the remainder
    of the contents of the `Size` column, drop the row.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 对于无法从`Size`列剩余内容中提取数值的行，删除该行。
- en: 'Run the cell to define the `clean_up_size()` function. You will use this function
    to perform the following set of cleanup steps on the `Size` column. The result
    will be a DataFrame where all values in the `Size` column are numeric values representing
    the area of the property. Here are some of the transformations that are performed
    by the `clean_up_size()` function:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行单元格以定义`clean_up_size()`函数。你将使用此函数对`Size`列执行以下清理步骤。结果将是一个DataFrame，`Size`列中的所有值都将是代表物业面积的数值。以下是`clean_up_size()`函数执行的一些转换：
- en: a) Lowercase all the values in the `Size` column.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 将`Size`列中的所有值转为小写。
- en: b) Split the `Size` column into a new column (`Size_type`) that contains the
    non-numeric information and a remainder `Size` column that contains the numeric
    information about the area of the property.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 将`Size`列拆分为一个新列(`Size_type`)，该列包含非数值信息，剩余的`Size`列则包含有关物业面积的数值信息。
- en: c) Replace the missing values in the new `Size` column with `0`.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 用`0`替换新`Size`列中的缺失值。
- en: d) Remove the rows that do not contain any digits.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 删除不包含任何数字的行。
- en: e) Remove the rows that contain problematic substrings, as listed in `clean_up_list`.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) 删除包含问题子串的行，如`clean_up_list`中列出的内容。
- en: f) Replace extraneous characters so that all the `Size` entries are either numeric
    or of the `numerica * numericb` form.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f) 替换多余的字符，使所有`Size`条目都为数值型或`numerica * numericb`的形式。
- en: g) Replace values of the `numerica * numericb` form with the product of the
    two values; that is, `numerica` and `numericb`.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: g) 将`numerica * numericb`形式的值替换为两者的乘积；即，`numerica`和`numericb`。
- en: 'Run this cell to execute the `clean_up_size()` function:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格以执行`clean_up_size()`函数：
- en: '[PRE34]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Run the `shape` command again to get the shape of the DataFrame after dropping
    the rows that don't contain enough data to be useful. This confirms that we lost
    about 2% of the rows from the original dataset after removing the offending rows:![Figure
    3.16 – Getting the shape of the DataFrame after cleanup
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次运行`shape`命令，以获取删除了不包含足够数据的行后的DataFrame形状。这确认了在删除无效行后，我们丢失了约2%的行：![图3.16 –
    清理后DataFrame的形状
- en: '](img/B16216_03_16.jpg)'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_16.jpg)'
- en: Figure 3.16 – Getting the shape of the DataFrame after cleanup
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.16 – 清理后DataFrame的形状
- en: 'Run `df_train.head()` to see a sample of the DataFrame after the cleanup steps.
    Note that now, we have the following:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`df_train.head()`查看清理步骤后的DataFrame样本。注意，现在我们得到以下结果：
- en: a) There is a new `Size_type` column.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 添加了新的`Size_type`列。
- en: b) The `Size` column contains numeric values.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `Size`列包含数值型数据。
- en: 'The output of `df_train.head()` shows what the DataFrame looks like after the
    `Price` and `Size` columns have been cleaned up:'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`df_train.head()`的输出显示了`Price`和`Size`列清理后的DataFrame样子：'
- en: '![Figure 3.17 – The DataFrame after performing the cleanup steps on the Price
    and Size columns'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.17 – 对价格和面积列执行清理步骤后的DataFrame'
- en: '](img/B16216_03_17.jpg)'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_17.jpg)'
- en: Figure 3.17 – The DataFrame after performing the cleanup steps on the Price
    and Size columns
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.17 – 执行完Price和Size列清理步骤后的DataFrame
- en: Run the cell to define the `under_over()` function. You will run this function
    to replace the values in the `Price` column with an indicator of whether the price
    is under or over the average price.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行该单元格以定义`under_over()`函数。你将运行该函数，以将`Price`列中的值替换为指示价格是否高于或低于平均价格的标记。
- en: 'Run the following cell to replace the values in the `Price` column with indicators
    of whether the price is above or below the average:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以将`Price`列中的值替换为指示价格高于或低于平均值的标记：
- en: '[PRE35]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After running this cell, the values in the `Price` column will be replaced:'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行该单元格后，`Price`列中的值将被替换：
- en: '![Figure 3.18 – The DataFrame after replacing the Price values with under/over
    average indicators'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.18 – 替换了价格值为高于/低于平均值指示的DataFrame'
- en: '](img/B16216_03_18.jpg)'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_18.jpg)'
- en: Figure 3.18 – The DataFrame after replacing the Price values with under/over
    average indicators
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.18 – 替换了价格值为高于/低于平均值指示的DataFrame
- en: 'Run this cell to define the transformations to be applied to `TabularDataLoaders`
    object, the target column (`Price`), and the continuous and categorical column
    lists:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行该单元格以定义将应用于`TabularDataLoaders`对象的转换、目标列（`Price`）以及连续和类别列列表：
- en: '[PRE36]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Run this cell to define the `TabularDataLoaders` object with the arguments
    that you have defined so far in the notebook, including the dataset (`df_train`),
    the list of transformations (`procs`) to be applied to the dataset, the continuous
    and categorical column lists (`cont` and `cat`), and the dependent variable (`dep_var`):'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行该单元格以定义`TabularDataLoaders`对象，使用你在笔记本中定义的参数，包括数据集（`df_train`）、将应用于数据集的转换列表（`procs`）、连续和类别列列表（`cont`和`cat`）以及因变量（`dep_var`）：
- en: '[PRE37]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Run this cell to fit the model and see the model's performance. Your accuracy
    and loss may be slightly different, but you should see over 90% accuracy, which
    is good for a model that's been trained on fewer than 100k records:![Figure 3.19
    – Results of fitting the model
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行该单元格以拟合模型并查看模型的性能。你的准确率和损失值可能会有所不同，但你应该能看到超过90%的准确率，对于一个训练数据少于10万条记录的模型来说，这已经很好了：![图
    3.19 – 模型拟合结果
- en: '](img/B16216_03_19.jpg)'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_19.jpg)'
- en: Figure 3.19 – Results of fitting the model
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.19 – 模型拟合结果
- en: 'Run this cell to see the results in the validation set. You will see that for
    this set of results, the model correctly predicts whether a property will have
    a price above or below the average:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行该单元格以查看验证集中的结果。你将看到，在这组结果中，模型正确预测了一个属性的价格是否高于或低于平均价格：
- en: '![Figure 3.20 – Model predictions of whether properties will have a price above
    or below the average'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.20 – 模型预测属性价格是否高于或低于平均值'
- en: '](img/B16216_03_20.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_20.jpg)'
- en: Figure 3.20 – Model predictions of whether properties will have a price above
    or below the average
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20 – 模型预测属性价格是否高于或低于平均值
- en: Congratulations! You have trained a deep learning model with fastai on a dataset
    that required non-trivial cleanup before it could be used to train the model.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已经在一个需要进行不小清理的数据集上，使用fastai训练了一个深度学习模型。
- en: How it works…
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, you saw that while fastai provides utilities that make it easier
    to train a deep learning model on a tabular dataset, you still have to ensure
    that the dataset is capable of training the model. This means that non-numeric
    values need to be removed from numeric columns. This may require iterative cleanup
    steps, as you saw while working through the notebook featured in this recipe.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你看到虽然fastai提供了便捷工具来训练深度学习模型，以处理表格数据集，但你仍需确保数据集能够训练模型。这意味着需要从数值列中去除非数值值。这可能需要迭代清理步骤，就像你在本教程的笔记本中所看到的那样。
- en: The dataset featured in this recipe contains the kind of anomalies and inconsistencies
    that are typical of real-world datasets, so the techniques you exercised in this
    recipe (including pandas manipulations to remove rows that had problematic values
    in certain columns, as well as string replacement techniques) will be applicable
    to other real-world datasets.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中的数据集包含了典型的现实世界数据集中的异常和不一致，因此你在本教程中使用的技术（包括通过pandas操作去除某些列中有问题值的行，以及字符串替换技术）将适用于其他现实世界的数据集。
- en: Even with a messy dataset, fastai makes it easy to get a high performing deep
    learning model, thanks to it picking intelligent defaults and automating key operations
    (such as identifying categorical and continuous columns and dealing with missing
    values).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据集杂乱，得益于 fastai 自动选择智能默认值并自动化关键操作（如识别分类和连续列、处理缺失值），它也能轻松帮助你获得高性能的深度学习模型。
- en: Assessing whether a tabular dataset is a good candidate for fastai
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估表格数据集是否适合 fastai
- en: So far in this chapter, we have created three deep learning models for tabular
    datasets using fastai. But what if you want to determine whether a new dataset
    is a good candidate for training a deep learning model with fastai? In this recipe,
    we'll go through the process of assessing whether a dataset is a good candidate
    for deep learning with fastai.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用 fastai 为表格数据集创建了三个深度学习模型。但如果你想确定一个新数据集是否适合使用 fastai 训练深度学习模型呢？在本节中，我们将介绍如何评估一个数据集是否适合使用
    fastai 进行深度学习。
- en: Getting ready
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, to get a fastai environment set up.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已按照[*第 1 章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)的步骤，*快速入门 fastai*，设置好
    fastai 环境。
- en: How to do it…
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'As you have seen so far in this chapter, you have many choices surrounding
    datasets that could possibly be applied to deep learning. To assess whether a
    dataset is a good candidate, we will go through the process of creating a new
    notebook from scratch and ingesting data from an online API. Follow these steps:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本章中所看到的，你可以选择多种数据集进行深度学习应用。为了评估一个数据集是否适合，我们将通过从头开始创建一个新的笔记本并从在线 API 获取数据的过程。请按照以下步骤操作：
- en: 'Create a new notebook in Gradient. You can do this in Gradient JupyterLab by
    following these steps:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Gradient 中创建一个新笔记本。你可以通过以下步骤在 Gradient JupyterLab 中完成此操作：
- en: 'a) Click on the new launcher button (**+**) in the main window:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 点击主窗口中的新启动器按钮（**+**）：
- en: '![Figure 3.21 – Opening New Launcher in JupyterLab'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.21 – 在 JupyterLab 中打开新启动器'
- en: '](img/B16216_03_21.jpg)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_21.jpg)'
- en: Figure 3.21 – Getting a new launcher in JupyterLab
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.21 – 在 JupyterLab 中获取新启动器
- en: 'b) When the launcher pane opens, click on **Python 3** to open a new notebook:'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 当启动器窗格打开时，点击 **Python 3** 来打开一个新的笔记本：
- en: '![Figure 3.22 – The Launcher pane in JupyterLab'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.22 – JupyterLab 中的启动器窗格'
- en: '](img/B16216_03_22.jpg)'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_22.jpg)'
- en: Figure 3.22 – The launcher pane in JupyterLab
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.22 – JupyterLab 中的启动器窗格
- en: In the new notebook, create and run two new cells with the statements required
    to set up the notebook:![Figure 3.23 – The cells to set up a fastai notebook for
    tabular datasets
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新笔记本中，创建并运行两个新的单元格，设置笔记本所需的语句：![图 3.23 – 为表格数据集设置 fastai 笔记本的单元格
- en: '](img/B16216_03_23.jpg)'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_23.jpg)'
- en: Figure 3.23 – The cells to set up a fastai notebook for tabular datasets
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.23 – 为表格数据集设置 fastai 笔记本的单元格
- en: 'Run the following cell to import the additional libraries required to investigate
    this dataset:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以导入调查此数据集所需的附加库：
- en: '[PRE38]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Run the following cell to load a dataset of stock prices for the company AstraZeneca
    (stock ticker = `AZN`):'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以加载 AstraZeneca（股票代码 = `AZN`）公司的股票价格数据集：
- en: '[PRE39]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Check the output of `df.head()` to see the contents of the dataframe:![Figure
    3.24 – Sample of the stock prices dataset
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `df.head()` 的输出，查看数据框的内容：![图 3.24 – 股票价格数据集示例
- en: '](img/B16216_03_24.jpg)'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_24.jpg)'
- en: Figure 3.24 – Sample of the stock prices dataset
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.24 – 股票价格数据集示例
- en: Get the shape of the dataframe `df` to determine how many rows are in the dataframe.
    Do you think this dataset is big enough to successfully train a deep learning
    model?![Figure 3.25 – Getting the shape of df
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取数据框 `df` 的形状，以确定数据框中有多少行。你认为这个数据集足够大，能够成功训练一个深度学习模型吗？![图 3.25 – 获取 df 的形状
- en: '](img/B16216_03_25.jpg)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_25.jpg)'
- en: Figure 3.25 – Getting the shape of df
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.25 – 获取 df 的形状
- en: Run the following cell to prepare to check the dataframe for missing values
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以准备检查数据框是否有缺失值
- en: '[PRE40]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Now confirm the dataset has no missing values![Figure 3.26 – Confirming the
    dataset has no missing values
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在确认数据集没有缺失值！[图 3.26 – 确认数据集没有缺失值
- en: '](img/B16216_03_26.jpg)'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_26.jpg)'
- en: Figure 3.26 – Confirming the dataset has no missing values
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.26 – 确认数据集没有缺失值
- en: 'Run the following cell to set the parameters for the training run:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以设置训练运行的参数：
- en: '[PRE41]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Run the following cell to define the TabularDataLoaders object::'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来定义TabularDataLoaders对象：
- en: '[PRE42]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Run the following cell to define and train the model::'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来定义并训练模型：
- en: '[PRE43]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: You can see from the following output that the performance of the model is poor:![Figure
    3.27 – Poor performance when training the model
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以从以下输出看到模型的表现很差：![图3.27 – 训练模型时的较差表现
- en: '](img/B16216_03_27.jpg)'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_03_27.jpg)'
- en: Figure 3.27 – Poor performance when training the model
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.27 – 训练模型时的较差表现
- en: 'Now we want to make some changes to try to get a model that has better performance.
    To start with, run the following cell to define a function to create a new target
    column:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们想进行一些更改，尝试获得一个表现更好的模型。首先，运行以下单元格来定义一个函数，创建一个新的目标列：
- en: '[PRE44]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Run the following cell to define the new target column:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来定义新的目标列：
- en: '[PRE45]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Run the following cell to specify that the new `target` column is the dependent
    variable and to limit `cont`, the set of continuous columns used to train the
    model. Note that in the first model in this section, the dependent variable was
    `Close`, a continuous column. That means the first model was trying to predict
    a continuous value. Because `target` is a categorical column, the new model will
    predict a categorical value rather than a continuous value:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来指定新的`target`列为因变量，并限制`cont`，即用于训练模型的连续列集合。注意，在本节的第一个模型中，因变量是`Close`，一个连续列。这意味着第一个模型是在尝试预测一个连续值。由于`target`是一个分类列，新的模型将预测一个分类值而不是连续值：
- en: '[PRE46]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Run the following cell to train a new model using the new dependent variable
    and the new set of continuous columns:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来使用新的因变量和新的连续列集合训练一个新模型：
- en: '[PRE47]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You can see that this new model has much better performance than the previous
    model:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以看到这个新模型比之前的模型有更好的表现：
- en: '![Figure 3.28 – Improved performance with the second model'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.28 – 第二个模型的表现提升'
- en: '](img/B16216_03_28.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_28.jpg)'
- en: Figure 3.28 – Improved performance with the second model
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28 – 第二个模型的表现提升
- en: In this recipe, you tried two variations on a deep learning model for a dataset
    of stock price information. The first model had a continuous dependent variable
    and used fastai defaults throughout. Unlike the other recipes in this chapter,
    the first model had poor performance. If you attempt to train the first model
    with more epochs you will see that the performance does not improve. The second
    model, where the dependent variable is changed from continuous to categorical,
    has much better performance.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，你尝试了两种深度学习模型变体，用于预测股价信息数据集。第一个模型的因变量是连续的，并且在整个过程中使用了fastai的默认设置。与本章中的其他配方不同，第一个模型的表现较差。如果你尝试使用更多的训练轮次来训练第一个模型，你会发现性能并没有改善。第二个模型将因变量从连续变量改为分类变量，表现要好得多。
- en: How it works…
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The first model in this section was unsuccessful. Attempting to predict a continuous
    value with a deep learning model trained on 1.3 k records is not likely to work.
    Generally speaking, you need a training set that is an order of magnitude bigger,
    in the hundreds of thousands or millions of records, to predict a continuous outcome.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的第一个模型并未成功。在使用1.3千条记录训练深度学习模型来预测连续值时，很可能无法成功。一般来说，你需要一个大一个数量级的训练集，至少是数十万条甚至数百万条记录，才能预测一个连续的结果。
- en: Saving a trained tabular model
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存训练好的表格模型
- en: So far, we have trained a series of fastai deep learning models on tabular datasets.
    These models are available to us in the Python session where we train the model,
    but what can we do to save the models so that we can use them later in a different
    session? In this recipe, we will learn how to save a fastai deep learning model
    to a file and access that model in another Python session.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在表格数据集上训练了一系列fastai深度学习模型。这些模型在我们训练模型的Python会话中是可用的，但是我们该如何保存这些模型，以便在不同的会话中再次使用呢？在这个配方中，我们将学习如何将一个fastai深度学习模型保存到文件，并在另一个Python会话中访问该模型。
- en: Getting ready
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have followed the steps in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, to get a fastai environment set up. Confirm that
    you can open the `saving_models_trained_with_tabular_datasets.ipynb` and `loading_saved_models_trained_with_tabular_datasets.ipynb`
    notebooks in the `ch3` directory of your repository.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已经按照[*第 1 章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)的步骤，*快速入门 fastai*，来设置
    fastai 环境。确认您可以在存储库的`ch3`目录中打开`saving_models_trained_with_tabular_datasets.ipynb`和`loading_saved_models_trained_with_tabular_datasets.ipynb`笔记本。
- en: How to do it…
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: In this recipe, you will be running through the `saving_models_trained_with_tabular_datasets.ipynb`
    notebook to train a model – the same model that you trained in the first recipe
    of this chapter – and save it. Then, you will use the `loading_saved_models_trained_with_tabular_datasets.ipynb`
    notebook to load and exercise a saved fastai model.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个操作步骤中，您将通过运行`saving_models_trained_with_tabular_datasets.ipynb`笔记本来训练一个模型——这个模型与本章第一个操作步骤中训练的模型相同——并将其保存。然后，您将使用`loading_saved_models_trained_with_tabular_datasets.ipynb`笔记本加载并执行已保存的
    fastai 模型。
- en: 'Once you have the `saving_models_trained_with_tabular_datasets.ipynb` notebook
    open in your fastai environment, follow these steps:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在 fastai 环境中打开了`saving_models_trained_with_tabular_datasets.ipynb`笔记本，按照以下步骤操作：
- en: Run the cells in the notebook up to the `Save the trained model` cell. By running
    these cells, you will be ingesting the `ADULT_SAMPLE` curated tabular dataset
    into a pandas DataFrame and training a fastai model on it.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本中的单元格，直到`保存训练好的模型`单元格。通过运行这些单元格，您将把`ADULT_SAMPLE`整理好的表格数据集导入到 pandas DataFrame
    中，并在其上训练一个 fastai 模型。
- en: Run the next two cells to set the value of the path for the model to a writable
    directory. Ensure that the directory that you set learn.path to exists and is
    writable.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行接下来的两个单元格，将模型的路径值设置为可写目录。确保您设置的 learn.path 指向的目录存在并且是可写的。
- en: 'Run this cell to save the trained model to the `adult_sample_model.pkl` file:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格，将训练好的模型保存到`adult_sample_model.pkl`文件中：
- en: '[PRE48]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Now that you have saved the trained model into a file, you must load it into
    another notebook to test the process you would go through to retrieve the model
    in a new Python session, and then use the saved model to make a prediction on
    the test data.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您已经将训练好的模型保存到文件中，您必须将其加载到另一个笔记本中，以测试您在新的 Python 会话中加载模型的过程，然后使用保存的模型对测试数据进行预测。
- en: Open the `loading_saved_models_trained_with_tabular_datasets.ipynb` notebook
    in a Gradient session.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Gradient 会话中打开`loading_saved_models_trained_with_tabular_datasets.ipynb`笔记本。
- en: Run the cells up to the `Load the saved, trained model` cell to load the required
    libraries and set up the notebook.
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行单元格，直到`加载已保存的训练模型`单元格，以加载所需的库并设置笔记本。
- en: 'Run this cell to load the model you saved earlier in this recipe into this
    new notebook. Ensure that you specify the path where you saved the model earlier
    in this recipe:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格，将您之前在本操作步骤中保存的模型加载到这个新笔记本中。确保您指定了之前保存模型的路径：
- en: '[PRE49]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Run this cell to load the test dataset into a DataFrame:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格，将测试数据集加载到 DataFrame 中：
- en: '[PRE50]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Run this cell to select the first row of the test dataset and apply the trained
    model to get a prediction for this data point:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此单元格，选择测试数据集的第一行，并应用训练好的模型来获取该数据点的预测：
- en: '[PRE51]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The result includes the prediction of the model on this data point. You can
    see that for this data point, the model is predicting a `salary` value of `1.0`,
    which means that it is predicting that this individual will have a salary of over
    50k:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果包括模型对该数据点的预测。您可以看到，对于这个数据点，模型预测的`salary`值为`1.0`，这意味着它预测该个体的工资将超过 50k：
- en: '![Figure 3.29 – Results of applying the saved model to a test data point'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.29 – 应用保存的模型对测试数据点进行预测的结果](img/B16216_03_29.jpg)'
- en: '](img/B16216_03_29.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_29.jpg)'
- en: Figure 3.29 – Results of applying the saved model to a test data point
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.29 – 应用保存的模型对测试数据点进行预测的结果
- en: Congratulations! You have successfully saved a fastai deep learning model, loaded
    the saved model in a new notebook, and applied the saved model to get a prediction
    on a row of test data.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已经成功保存了一个 fastai 深度学习模型，加载了保存的模型到新笔记本中，并应用该模型对一行测试数据进行预测。
- en: How it works…
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其工作原理…
- en: The fastai framework includes support to make it easy to save deep learning
    models to your filesystem using the `export()` method of `learner` objects. In
    this recipe, you saw an example of how you can save a trained model to a pickle
    file. You also learned how to load the pickle file back into Python and then apply
    the trained model to a new data example. This is a peek ahead at the process of
    performing inference on a deployed model. In [*Chapter 7*](B16216_07_Final_VK_ePub.xhtml#_idTextAnchor178),
    *Deployment and Model Maintenance*, you will see complete examples of performing
    inference on a deployed model.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: fastai框架包括支持，使用`learner`对象的`export()`方法将深度学习模型保存到文件系统中。在这个配方中，你看到了如何将训练后的模型保存到pickle文件的示例。你还学会了如何将pickle文件加载回Python，并将训练后的模型应用于新的数据示例。这是对在部署的模型上进行推理的过程的提前预览。在[*第7章*](B16216_07_Final_VK_ePub.xhtml#_idTextAnchor178)《部署与模型维护》中，你将看到在部署的模型上进行推理的完整示例。
- en: Test your knowledge
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试你的知识
- en: Now that you have completed the recipes in this chapter, follow the steps shown
    here to exercise what you have learned. You will do this by adapting one of the
    notebooks you worked through in this chapter so that it works with a new dataset.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经完成了本章中的配方，按照这里展示的步骤来实践你所学的内容。你将通过调整你在本章中操作过的一个笔记本，使其能够与新数据集配合使用。
- en: Getting ready
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Follow these steps to upload a new tabular dataset:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤上传新的表格数据集：
- en: Go to the site for the Kaggle competition on future sales prediction ([https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data](https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data))
    and accept the conditions for the competition to get access to the datasets associated
    with the competition.
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问Kaggle未来销售预测比赛的站点（[https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data](https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data)），并接受比赛条件，以便访问与比赛相关的数据集。
- en: Download the `sales_train.csv.zip` and `test.csv.zip` files.
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载`sales_train.csv.zip`和`test.csv.zip`文件。
- en: Unzip the downloaded files to extract `sales_train.csv` and `test.csv`.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压下载的文件以提取`sales_train.csv`和`test.csv`。
- en: 'From the Terminal in your Gradient environment, make your current directory
    `/storage/archive`:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Gradient环境中的终端中，将当前目录设置为`/storage/archive`：
- en: '[PRE52]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Create a folder called `/storage/archive/price_prediction`:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`/storage/archive/price_prediction`的文件夹：
- en: '[PRE53]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Upload `sales_train.csv` and `test.csv` to `/storage/archive/price_prediction`.
    You can use the upload button in JupyterLab in Gradient to do the upload via the
    `/notebooks/temp` directory that you created earlier in this chapter:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`sales_train.csv`和`test.csv`上传到`/storage/archive/price_prediction`。你可以使用Gradient中的JupyterLab上传按钮，通过你在本章前面创建的`/notebooks/temp`目录来上传：
- en: 'a) In the JupyterLab file browser, make `temp` your current folder, select
    the upload button, as shown in the following screenshot, and select `sales_train.csv`
    and `test.csv` from the local system folder where you extracted them in *step
    2*:'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 在JupyterLab文件浏览器中，将`temp`设置为当前文件夹，选择上传按钮，如下图所示，然后从本地系统文件夹中选择`sales_train.csv`和`test.csv`，该文件夹是你在*第2步*中提取它们的地方：
- en: '![Figure 3.30 – Upload button in JupyterLab'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.30 – JupyterLab 中的上传按钮'
- en: '](img/B16216_03_30.jpg)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_30.jpg)'
- en: Figure 3.30 – Upload button in JupyterLab
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.30 – JupyterLab 中的上传按钮
- en: 'b) From the Terminal in your Gradient environment, make `/storage/archive/price_prediction`
    your current directory:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: b) 在Gradient环境中的终端中，将`/storage/archive/price_prediction`设置为当前目录：
- en: '[PRE54]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'c) Copy `sales_train.csv`, `test.csv`, and `data_kaggle.csv` into `/storage/archive/price_prediction`:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: c) 将`sales_train.csv`、`test.csv`和`data_kaggle.csv`复制到`/storage/archive/price_prediction`：
- en: '[PRE55]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now that you have uploaded the dataset, it''s time to create a notebook to
    ingest the dataset:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经上传了数据集，是时候创建一个笔记本来导入数据集了：
- en: Make a copy of the `training_model_standalone_tabular_dataset.ipynb` notebook
    that you worked through in the *Training a model with a standalone dataset* recipe.
    Call the copy `training_model_new_tabular_dataset.ipynb`.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个你在*使用独立数据集训练模型*配方中操作过的`training_model_standalone_tabular_dataset.ipynb`笔记本的副本。将副本命名为`training_model_new_tabular_dataset.ipynb`。
- en: 'In your new notebook, update the cells that ingest the training dataset:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的新笔记本中，更新用于导入训练数据集的单元格：
- en: '[PRE56]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output of `df_train.head()` should show you the structure of the dataset.
    You can find a description of the columns of this dataset at [https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data?select=sales_train.csv](https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data?select=sales_train.csv):'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df_train.head()` 的输出应该展示数据集的结构。你可以在 [https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data?select=sales_train.csv](https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data?select=sales_train.csv)
    找到该数据集的列描述：'
- en: '![Figure 3.31 – A sample of the contents of sales_train.csv'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.31 – sales_train.csv 内容的一个样本'
- en: '](img/B16216_03_31.jpg)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_03_31.jpg)'
- en: Figure 3.31 – A sample of the contents of sales_train.csv
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.31 – sales_train.csv 内容的一个样本
- en: Congratulations! You have ingested another standalone tabular dataset into a
    fastai notebook. You can apply similar techniques to make other tabular datasets
    available so that they can used in fastai solutions.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经将另一个独立的表格数据集导入到 fastai 笔记本中。你可以应用类似的技术将其他表格数据集导入，以便在 fastai 解决方案中使用。
- en: Now that you have ingested the dataset, consider the steps you would take to
    prepare this dataset for training a deep learning model. How would you deal with
    any missing values? Are there tests you can apply to some of the columns to detect
    and correct incorrect values? The Kaggle competition predicts the total sales
    for every product and store for the next month. Completing a fastai model to tackle
    this problem is beyond the scope of this book, but consider how you might refactor
    the dataset to prepare it for this problem.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经导入了数据集，考虑一下你将采取哪些步骤来准备该数据集用于训练深度学习模型。你会如何处理任何缺失值？你是否可以对某些列应用测试，来检测和修正错误值？Kaggle
    比赛预测每个产品和商店的下个月总销售量。完成一个 fastai 模型来解决这个问题超出了本书的范围，但请考虑如何重构数据集，以便为这个问题做好准备。
