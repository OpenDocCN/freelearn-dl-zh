- en: 7\. Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7. 卷积神经网络
- en: This chapter describes **convolutional neural networks** (**CNNs**). CNNs are
    used everywhere in AI, including image recognition and speech recognition. This
    chapter will detail the mechanisms of CNNs and how to implement them in Python.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍**卷积神经网络**（**CNN**）。CNN广泛应用于AI领域，包括图像识别和语音识别。本章将详细讲解CNN的机制及如何在Python中实现它们。
- en: Overall Architecture
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总体架构
- en: 'First, let''s look at the network architecture of CNNs. You can create a CNN
    by combining layers, much in the same way as the neural networks that we have
    seen so far. However, CNNs have other layers as well: a convolution layer and
    a pooling layer. We will look at the details of the convolution and pooling layers
    in the following sections. This section describes how layers are combined to create
    a CNN.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看CNN的网络架构。你可以通过组合各层来创建CNN，方法与我们之前看到的神经网络相似。然而，CNN还有其他层：卷积层和池化层。我们将在接下来的部分详细探讨卷积层和池化层。本节将描述如何组合这些层来创建CNN。
- en: In the neural networks that we have seen so far, all the neurons in adjacent
    layers are connected. These layers are called **fully connected** layers, and
    we implemented them as Affine layers. You can use Affine layers to create a neural
    network consisting of five fully connected layers, for example, as shown in *Figure
    7.1*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们迄今为止看到的神经网络中，所有相邻层的神经元都是连接的。这些层被称为**全连接**层，我们将它们实现为仿射层。例如，你可以使用仿射层创建一个由五个全连接层组成的神经网络，如*图7.1*所示。
- en: 'As *Figure 7.1* shows, the ReLU layer (or the Sigmoid layer) for the activation
    function follows the Affine layer in a fully connected neural network. Here, after
    four pairs of **Affine – ReLU** layers, comes the Affine layer, which is the fifth
    layer. And finally, the Softmax layer outputs the final result (probability):'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图7.1*所示，在全连接神经网络中，激活函数的ReLU层（或Sigmoid层）跟随仿射层。在这里，经过四对**仿射 – ReLU**层后，接着是第五层的仿射层。最后，Softmax层输出最终结果（概率）：
- en: '![Figure 7.1: Sample network consisting of fully connected layers (Affine layers)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.1：由全连接层（仿射层）组成的示例网络'
- en: '](img/fig07_1.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_1.jpg)'
- en: 'Figure 7.1: Sample network consisting of fully connected layers (Affine layers)'
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7.1：由全连接层（仿射层）组成的示例网络
- en: 'So, what architecture does a CNN have? *Figure 7.2* shows a sample CNN:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，CNN的架构是什么样的呢？*图7.2*展示了一个示例CNN：
- en: '![Figure 7.2: Sample CNN – convolution and pooling layers are added (they are
    shown as gray rectangles)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.2：示例CNN – 添加了卷积层和池化层（它们显示为灰色矩形）'
- en: '](img/fig07_2.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_2.jpg)'
- en: 'Figure 7.2: Sample CNN – convolution and pooling layers are added (they are
    shown as gray rectangles)'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7.2：示例CNN – 添加了卷积层和池化层（它们显示为灰色矩形）
- en: As shown in *Figure 7.2*, CNN has additional convolution and pooling layers.
    In the CNN, layers are connected in the order of **Convolution – ReLU – (Pooling)**
    (a pooling layer is sometimes omitted). We can consider the previous **Affine
    – ReLU** connection as being replaced with "Convolution – ReLU – (Pooling)."
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图7.2*所示，CNN具有额外的卷积层和池化层。在CNN中，各层按**卷积 – ReLU – （池化）**的顺序连接（池化层有时会省略）。我们可以将之前的**仿射
    – ReLU**连接视为被“卷积 – ReLU – （池化）”替代。
- en: In the CNN of *Figure 7.2*, note that the layers near the output are the previous
    "Affine – ReLU" pairs, while the last output layers are the previous "Affine –
    Softmax" pairs. This is the structure often seen in an ordinary CNN.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.2*中的CNN中，请注意靠近输出的层是之前的“仿射 – ReLU”对，而最后的输出层是之前的“仿射 – Softmax”对。这就是普通CNN中常见的结构。
- en: The Convolution Layer
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层
- en: There are some CNN-specific terms, such as padding and stride. The data that
    flows through each layer in a CNN is data with shape (such as three-dimensional
    data), unlike in previous fully connected networks. Therefore, you may feel that
    CNNs are difficult when you learn about them for the first time. Here, we will
    look at the mechanism of the convolution layer used in CNNs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些CNN特有的术语，如填充和步幅。流经CNN中每一层的数据是具有特定形状的数据（如三维数据），这与之前的全连接网络不同。因此，当你第一次学习CNN时，可能会觉得它们很复杂。在这里，我们将深入探讨CNN中使用的卷积层的机制。
- en: Issues with the Fully Connected Layer
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全连接层的问题
- en: The fully connected neural networks that we have seen so far used fully connected
    layers (Affine layers). In a fully connected layer, all the neurons in the adjacent
    layer are connected, and the number of outputs can be determined arbitrarily.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前见过的完全连接神经网络使用了完全连接层（仿射层）。在完全连接层中，邻接层中的所有神经元都会连接在一起，并且输出的数量可以任意确定。
- en: The issue with a fully connected layer, though, is that the shape of the data
    is *ignored*. For example, when the input data is an image, it usually has a three-dimensional
    shape, determined by the height, the width, and the channel dimension. However,
    three-dimensional data must be converted into one-dimensional flat data when it
    is provided to a fully connected layer. In the previous examples that we used
    for the MNIST dataset, the input images had the shape of 1, 28, 28 (1 channel,
    28 pixels in height, and 28 pixels in width), but the elements were arranged in
    a line, and the resulting 784 pieces of data were provided to the first Affine
    layer.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，完全连接层的问题在于，数据的形状被*忽略*了。例如，当输入数据是图像时，它通常具有三维形状，取决于高度、宽度和通道维度。然而，当这些三维数据提供给完全连接层时，必须转换为一维的平面数据。在我们之前使用的
    MNIST 数据集的例子中，输入图像的形状是 1, 28, 28（1 个通道，高度为 28 像素，宽度为 28 像素），但这些元素被排列成一行，最终得到了
    784 个数据点，并提供给了第一个仿射层。
- en: Let's say an image has a three-dimensional shape and that the shape contains
    important spatial information. Essential patterns to recognize this information
    may hide in three-dimensional shapes. Spatially close pixels have similar values,
    the RBG channels are closely related to each other, and the distant pixels are
    not related. However, a fully connected layer ignores the shape and treats all
    the input data as equivalent neurons (neurons with the same number of dimensions),
    so it cannot use the information regarding the shape.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一张图像具有三维形状，并且这种形状包含重要的空间信息。识别这些信息的关键模式可能隐藏在三维形状中。空间上接近的像素具有相似的值，RGB 通道彼此紧密相关，而远离的像素则没有关系。然而，完全连接层忽略了形状，将所有输入数据视为等价的神经元（具有相同维度的神经元），因此无法利用形状相关的信息。
- en: On the other hand, a convolution layer maintains the shape. For images, it receives
    the input data as three-dimensional data and outputs three-dimensional data to
    the next layer. Therefore, CNNs can understand data with a shape, such as images,
    properly.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，卷积层保持数据的形状。对于图像，它接收作为三维数据的输入，并将三维数据输出到下一层。因此，卷积神经网络（CNN）可以正确理解具有形状的数据，例如图像。
- en: In a CNN, the input/output data for a convolution layer is sometimes called
    a **feature map**. The input data for a convolution layer is called an **input
    feature map**, while the output data for a convolution layer is called an **output
    feature map**. In this book, *input/output data* and *feature map* will be used
    interchangeably.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积神经网络（CNN）中，卷积层的输入/输出数据有时被称为**特征图**。卷积层的输入数据叫做**输入特征图**，而卷积层的输出数据叫做**输出特征图**。在本书中，*输入/输出数据*和*特征图*将交替使用。
- en: Convolution Operations
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积操作
- en: 'The processing performed in a convolution layer is called a "convolution operation"
    and is equivalent to the "filter operation" in image processing. Let''s look at
    example (*Figure 7.3*) to understand a convolution operation:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层中执行的处理称为“卷积操作”，等同于图像处理中的“滤波操作”。让我们看一个例子（*图 7.3*）来理解卷积操作：
- en: '![Figure 7.3: Convolution operation – the ⊛ symbol indicates a convolution
    operation'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.3：卷积操作 – ⊛ 符号表示卷积操作'
- en: '](img/fig07_3.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_3.jpg)'
- en: 'Figure 7.3: Convolution operation – the ⊛ symbol indicates a convolution operation'
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.3：卷积操作 – ⊛ 符号表示卷积操作
- en: As shown in *Figure 7.3*, a convolution operation applies a filter to input
    data. In this example, the shape of the input data has a height and width, and
    so does the shape of the filter. When we indicate the shape of the data and filter
    as (height, width), the input size is (4, 4), the filter size is (3, 3), and the
    output size is (2, 2) in this example. Some literature uses the word "kernel"
    for the term "filter."
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.3*所示，卷积操作将滤波器应用于输入数据。在这个例子中，输入数据的形状有高度和宽度，滤波器的形状也是如此。当我们将数据和滤波器的形状表示为（高度，宽度）时，输入大小为（4，4），滤波器大小为（3，3），输出大小为（2，2）。一些文献中使用“核”这个词来表示“滤波器”。
- en: Now, let's break down the calculation performed in the convolution operation
    shown in *Figure 7.3*. *Figure 7.4* shows the calculation procedure of the convolution
    operation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来分析*图 7.3*中展示的卷积操作所执行的计算。*图 7.4*展示了卷积操作的计算过程。
- en: A convolution operation is applied to the input data while the filter window
    is shifted at a fixed interval. The window here indicates the gray 3x3 section
    shown in *Figure 7.4*. As shown in *Figure 7.4*, the element of the filter and
    the corresponding element of the input are multiplied and summed at each location
    (this calculation is sometimes called a **multiply-accumulate operation**). The
    result is stored in the corresponding position of the output. The output of the
    convolution operation can be obtained by performing this process at all locations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作被应用到输入数据时，滤波器窗口按固定间隔滑动。这里的窗口指的是*图 7.4*中显示的灰色 3x3 区域。如*图 7.4*所示，滤波器的元素和输入的对应元素在每个位置上进行乘法和求和（这个计算有时称为**乘加操作**）。结果被存储在输出的对应位置。通过在所有位置执行这个过程，可以得到卷积操作的输出。
- en: 'A fully connected neural network has biases as well as weight parameters. In
    a CNN, the filter parameters correspond to the previous "weights." It also has
    biases. The convolution operation of *Figure 7.3* shows the stage when a filter
    was applied. *Figure 7.5* shows the processing flow of a convolution operation,
    including biases:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全连接神经网络有偏置和权重参数。在卷积神经网络（CNN）中，滤波器参数对应于之前的“权重”。它同样也有偏置。*图 7.3*中的卷积操作展示了滤波器应用的阶段。*图
    7.5*展示了卷积操作的处理流程，包括偏置：
- en: '![Figure 7.4: Calculation procedure of a convolution operation'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.4：卷积操作的计算过程'
- en: '](img/fig07_4.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_4.jpg)'
- en: 'Figure 7.4: Calculation procedure of a convolution operation'
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.4：卷积操作的计算过程
- en: '![Figure 7.5: Bias in a convolution operation – a fixed value (bias) is added
    to the element'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.5：卷积操作中的偏置 – 在元素上添加一个固定值（偏置）'
- en: after the filter is applied
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用滤波器后
- en: '](img/fig07_5.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_5.jpg)'
- en: 'Figure 7.5: Bias in a convolution operation – a fixed value (bias) is added
    to the element after the filter is applied'
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.5：卷积操作中的偏置 – 在应用滤波器后，向元素中添加一个固定值（偏置）
- en: As shown in *Figure 7.5*, a bias term is added to the data after the filter
    is applied. Here, the bias is always only one (1x1) where one bias exists for
    the four pieces of data after the filter is applied. This one value is added to
    all the elements after the filter is applied.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.5*所示，偏置项在应用滤波器后被添加到数据中。在这里，偏置始终是一个固定值（1x1），即在滤波器应用后的四个数据元素中，每个都存在一个偏置。这个值会被加到滤波器应用后的所有元素中。
- en: Padding
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 填充
- en: 'Before a convolution layer is processed, fixed data (such as 0) is sometimes
    filled around the input data. This is called **padding** and is often used in
    a convolution operation. For example, in *Figure 7.6*, padding of 1 is applied
    to the (4, 4) input data. The padding of 1 means filling the circumference with
    zeros with the width of one pixel:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层处理之前，有时会在输入数据周围填充固定数据（如 0）。这叫做**填充**，并且在卷积操作中经常使用。例如，在*图 7.6*中，对（4, 4）输入数据进行了填充
    1。填充 1意味着用一个像素宽度的零填充周围：
- en: '![Figure 7.6: Padding in a convolution operation – add zeros around the input
    data (padding is shown by dashed lines here, and the zeros are omitted)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6：卷积操作中的填充 – 在输入数据周围添加零（这里用虚线表示填充，零被省略）'
- en: '](img/fig07_6.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_6.jpg)'
- en: 'Figure 7.6: Padding in a convolution operation – add zeros around the input
    data (padding is shown by dashed lines here, and the zeros are omitted)'
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.6：卷积操作中的填充 – 在输入数据周围添加零（这里用虚线表示填充，零被省略）
- en: As shown in *Figure 7.6*, padding converts the (4, 4) input data into (6, 6)
    data. After the (3, 3) filter is applied, (4, 4) output data is generated. In
    this example, the padding of 1 was used. You can set any integer, such as 2 or
    3, as the padding value. If the padding value was 2, the size of the input data
    would be (8, 8). If the padding was 3, the size would be (10, 10).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.6*所示，填充将（4, 4）输入数据转换为（6, 6）数据。在应用（3, 3）滤波器后，生成（4, 4）输出数据。在这个例子中，使用了填充
    1。你可以设置任意整数值作为填充值，例如 2 或 3。如果填充值是 2，输入数据的大小将是（8, 8）。如果填充是 3，则大小为（10, 10）。
- en: Note
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: Padding is used mainly for adjusting the output size. For example, when a (3,
    3) filter is applied to (4, 4) input data, the output size is (2, 2). The output
    size is smaller than the input size by two elements. This causes a problem in
    deep networks, where convolution operations are repeated many times. If each convolution
    operation spatially reduces the size, the output size will reach 1 at a certain
    time, and no more convolution operations will be available. To avoid such a situation,
    you can use padding. In the previous example, the output size (4, 4) remains the
    same as the input size (4, 4) when the width of padding is 1\. Therefore, you
    can pass the data of the same spatial size to the next layer after performing
    a convolution operation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 填充主要用于调整输出大小。例如，当一个（3, 3）滤波器应用于（4, 4）输入数据时，输出大小为（2, 2）。输出大小比输入大小少了两个元素。这在深度网络中会引发一个问题，因为卷积操作会重复很多次。如果每次卷积操作都在空间上减小大小，输出大小最终会达到1，这时就无法再进行卷积操作了。为避免这种情况，可以使用填充。在前面的例子中，当填充宽度为1时，输出大小（4,
    4）与输入大小（4, 4）保持一致。因此，你可以在执行卷积操作后将相同空间大小的数据传递给下一层。
- en: Stride
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步幅
- en: The interval of the positions for applying a filter is called a **stride**.
    In all previous examples, the stride was 1\. When the stride is 2, for example,
    the interval of the window for applying a filter will be two elements, as shown
    in *Figure 7.7*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 应用滤波器的位置间隔称为**步幅**。在之前的所有例子中，步幅为1。例如，当步幅为2时，应用滤波器的窗口间隔为两个元素，如*图 7.7*所示。
- en: In *Figure 7.7*, a filter is applied to the (7, 7) input data with the stride
    of 2\. When the stride is 2, the output size becomes (3, 3). Thus, the stride
    specifies the interval for applying a filter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 7.7*中，使用步幅为2的滤波器应用于（7, 7）输入数据。当步幅为2时，输出大小变为（3, 3）。因此，步幅指定了应用滤波器的间隔。
- en: '![Figure 7.7: Sample convolution operation where the stride is 2'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7：步幅为 2 的示例卷积操作'
- en: '](img/fig07_7.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_7.jpg)'
- en: 'Figure 7.7: Sample convolution operation where the stride is 2'
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.7：步幅为 2 的示例卷积操作
- en: As we have seen so far, the larger the stride, the smaller the output size,
    and the larger the padding, the larger the output size. How can we represent such
    relations in equations? Let's see how the output size is calculated based on padding
    and stride.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，步幅越大，输出大小越小；填充越大，输出大小越大。我们如何用方程表示这些关系呢？让我们来看一下如何根据填充和步幅来计算输出大小。
- en: 'Here, the input size is (*H*, *W*), the filter size is (*FH*, *FW*), the output
    size is (*OH*, *OW*), the padding is *P*, and the stride is *S*. In this case,
    you can calculate the output size with the following equation—that is, equation
    (7.1):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，输入大小是(*H*, *W*)，滤波器大小是(*FH*, *FW*)，输出大小是(*OH*, *OW*)，填充是*P*，步幅是*S*。在这种情况下，你可以通过以下方程来计算输出大小，即方程（7.1）：
- en: '| ![90](img/Figure_7.7a.png) | (7.1) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| ![90](img/Figure_7.7a.png) | （7.1） |'
- en: 'Now, let''s use this equation to do some calculations:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用这个方程做一些计算：
- en: '**Example 1: Example is shown in Figure 7.6**'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**示例 1：示例见图 7.6**'
- en: 'Input size: (4, 4), padding: 1, stride: 1, filter size: (3, 3):'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入大小：（4, 4），填充：1，步幅：1，滤波器大小：（3, 3）：
- en: '![91](img/Figure_7.7c.jpg)'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![91](img/Figure_7.7c.jpg)'
- en: '**Example 2: Example is shown in Figure 7.7**'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**示例 2：示例见图 7.7**'
- en: 'Input size: (7, 7), padding: 0, stride: 2, filter size: (3, 3):'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入大小：（7, 7），填充：0，步幅：2，滤波器大小：（3, 3）：
- en: '![92](img/Figure_7.7e.jpg)'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![92](img/Figure_7.7e.jpg)'
- en: '**Example 3**'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**示例 3**'
- en: 'Input size: (28, 31), padding: 2, stride: 3, filter size:(5, 5):'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入大小：（28, 31），填充：2，步幅：3，滤波器大小：（5, 5）：
- en: '![93](img/Figure_7.7g.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![93](img/Figure_7.7g.jpg)'
- en: As these examples show, you can calculate the output size by assigning values
    to equation (7.1). You can only obtain the output size by assignment, but note
    that you must assign values so that ![94](img/Figure_7.7i.png) and ![95](img/Figure_7.7j.png)
    in equation (7.1) are divisible. If the output size is not divisible (i.e., the
    result is a decimal), you must handle that by generating an error. Some deep learning
    frameworks advance this process without generating an error; for example, they
    round the value to the nearest integer when it is not divisible.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 正如这些例子所示，你可以通过赋值给方程（7.1）来计算输出大小。你只能通过赋值来获得输出大小，但请注意，你必须赋值以确保方程（7.1）中的![94](img/Figure_7.7i.png)和![95](img/Figure_7.7j.png)能被整除。如果输出大小不能整除（即结果是小数），你必须通过生成错误来处理这个问题。一些深度学习框架会在没有生成错误的情况下提前处理这个过程；例如，当无法整除时，它们会将值四舍五入到最接近的整数。
- en: Performing a Convolution Operation on Three-Dimensional Data
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对三维数据进行卷积操作
- en: The examples we've looked at so far targeted two-dimensional shapes that have
    a height and a width. For images, we must handle three-dimensional data that has
    a channel dimension, as well as a height and a width. Here, we will look at an
    example of a convolution operation on three-dimensional data using the same technique
    we used in the previous examples.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们查看的示例针对的是具有高度和宽度的二维形状。对于图像，我们必须处理具有通道维度、高度和宽度的三维数据。在这里，我们将使用之前示例中使用的相同技术，查看三维数据上的卷积操作示例。
- en: '*Figure 7.8* shows an example of convolution operation, while *Figure 7.9*
    shows the calculation procedure. Here, we can see the result of performing a convolution
    operation on three-dimensional data. You can see that the feature maps have increased
    in depth (the channel dimension) compared to the two-dimensional data (the example
    shown in *Figure 7.3*). If there are multiple feature maps in the channel dimension,
    a convolution operation using the input data and the filter is performed for each
    channel, and the results are added to obtain one output:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.8* 显示了卷积操作的示例，而 *图 7.9* 显示了计算过程。在这里，我们可以看到在三维数据上执行卷积操作的结果。与二维数据（*图 7.3*
    中的示例）相比，你可以看到特征图的深度（通道维度）增加了。如果在通道维度上有多个特征图，则对每个通道使用输入数据和滤波器执行卷积操作，并将结果相加以获得一个输出：'
- en: '![Figure 7.8: Convolution operation for three-dimensional data'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.8：三维数据的卷积操作'
- en: '](img/fig07_8.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_8.jpg)'
- en: 'Figure 7.8: Convolution operation for three-dimensional data'
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.8：三维数据的卷积操作
- en: '![Figure 7.9: Calculation procedure of the convolution operation for three-dimensional
    data'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.9：三维数据的卷积操作计算过程'
- en: '](img/fig07_9.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_9.jpg)'
- en: 'Figure 7.9: Calculation procedure of the convolution operation for three-dimensional
    data'
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.9：三维数据的卷积操作计算过程
- en: Note
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: In a three-dimensional convolution operation, as shown in this example, the
    input data and the filter must be the same in terms of the number of channels
    they have. In this example, the number of channels in the input data and the filter
    are the same; there are three. On the other hand, you can set the filter size
    to whatever you like. In this example, the filter size is (3, 3). You can set
    it to any size, such as (2, 2), (1, 1), or (5,5). However, as mentioned earlier,
    the number of channels must be the same as that of the input data. In this example,
    there must be three.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在三维卷积操作中，如本例所示，输入数据和滤波器在通道数上必须相同。在本例中，输入数据和滤波器的通道数相同，都是三。然而，你可以设置滤波器的大小为你喜欢的任何值。在本例中，滤波器的大小为
    (3, 3)。你可以将其设置为任何大小，如 (2, 2)、(1, 1) 或 (5, 5)。然而，如前所述，通道数必须与输入数据的通道数相同。在本例中，必须是三。
- en: Thinking in Blocks
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 思考块
- en: 'In a three-dimensional convolution operation, you can consider the data and
    filter as rectangular blocks. A block here is a three-dimensional cuboid, as shown
    in *Figure 7.10*. We will represent three-dimensional data as a multidimensional
    array in the order channel, height, width. So, when the number of channels is
    C, the height is H, and the width is W for shape, it is represented as (C, H,
    W). We will represent a filter in the same order so that when the number of channels
    is C, the height is **FH** (**Filter Height**), and the width is **FW** (**Filter
    Width**) for a filter, it is represented as (C, FH, FW):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在三维卷积操作中，你可以将数据和滤波器视为矩形块。这里的块是一个三维长方体，如*图 7.10*所示。我们将三维数据表示为一个多维数组，顺序为通道、高度、宽度。因此，当通道数为
    C，高度为 H，宽度为 W 时，形状表示为 (C, H, W)。我们将以相同的顺序表示滤波器，因此当通道数为 C，高度为 **FH**（**滤波器高度**），宽度为
    **FW**（**滤波器宽度**）时，滤波器的形状表示为 (C, FH, FW)：
- en: '![Figure 7.10: Using blocks to consider a convolution operation'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.10：使用块来考虑卷积操作'
- en: '](img/fig07_10.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_10.jpg)'
- en: 'Figure 7.10: Using blocks to consider a convolution operation'
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.10：使用块来考虑卷积操作
- en: 'In this example, the data''s output is one feature map. One feature map means
    that the size of the output channel is one. So, how can we provide multiple outputs
    of convolution operations in the channel dimension? To do that, we use multiple
    filters (weights). *Figure 7.11* shows this graphically:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，数据的输出是一个特征图。一个特征图意味着输出通道的大小为一。那么，如何在通道维度上提供多个卷积操作的输出呢？为此，我们使用多个滤波器（权重）。*图
    7.11* 图示了这一点：
- en: '![Figure 7.11: Sample convolution operation with multiple filters'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.11：使用多个滤波器的卷积操作示例'
- en: '](img/fig07_11.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_11.jpg)'
- en: 'Figure 7.11: Sample convolution operation with multiple filters'
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.11：具有多个滤波器的示例卷积操作
- en: As shown in *Figure 7.11*, when the number of filters applied is FN, the number
    of output maps generated is also FN. By combining FN maps, you can create a block
    of the shape (FN, OH, OW). Passing this completed block to the next layer is the
    process a CNN.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 7.11* 所示，当应用的滤波器数量为FN时，生成的输出地图数量也为FN。通过组合FN地图，您可以创建形状为（FN，OH，OW）的块。将这个完成的块传递到下一层是CNN的过程。
- en: You must also consider the number of filters in a convolution operation. To
    do that, we will write the filter weight data as four-dimensional data (output_channel,
    input_channel, height, width). For example, when there are 20 filters with three
    channels where the size is 5 x 5, it is represented as (20, 3, 5, 5).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您还必须考虑卷积操作中的滤波器数量。为此，我们将编写滤波器权重数据作为四维数据（output_channel，input_channel，height，width）。例如，当有20个具有三个通道的大小为5
    x 5的滤波器时，表示为（20，3，5，5）。
- en: A convolution operation has biases (like a fully connected layer). *Figure 7.12*
    shows the example provided in *Figure 7.11* when you add biases.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作具有偏置项（类似于全连接层）。*图 7.12* 展示了在添加偏置项后 *图 7.11* 提供的示例。
- en: 'As we can see, each channel has only one bias data. Here, the shape of the
    bias is (FN, 1, 1), while the shape of the filter output is (FN, OH, OW). Adding
    these two blocks adds the same bias value to each channel in the filter output
    result, (FN, OH, OW). NumPy''s broadcasting facilitates blocks of different shapes
    (please refer to *Broadcasting* section in *Chapter 1*, *Introduction to Python*):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，每个通道只有一个偏置数据。这里，偏置的形状是（FN，1，1），而滤波器输出的形状是（FN，OH，OW）。添加这两个块将相同的偏置值添加到滤波器输出结果的每个通道中，（FN，OH，OW）。NumPy的广播功能有助于处理不同形状的块（请参考*第1章*中*Python介绍*中的*广播*部分）：
- en: '![Figure 7.12: Process flow of a convolution operation (the bias term is also
    added)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.12：卷积操作流程（也添加了偏置项）'
- en: '](img/fig07_12.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_12.jpg)'
- en: 'Figure 7.12: Process flow of a convolution operation (the bias term is also
    added)'
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.12：卷积操作流程（也添加了偏置项）
- en: Batch Processing
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理
- en: Input data is processed in batches in neural network processing. The implementations
    we've looked at so far for fully connected neural networks have supported batch
    processing, which enables more efficient processing and supports mini-batches
    in the training process.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据在神经网络处理中批处理。到目前为止，我们已经查看了对全连接神经网络的实现，支持批处理，这使得在训练过程中支持小批量更加高效。
- en: We can also support batch processing in a convolution operation by storing the
    data that flows through each layer as four-dimensional data. Specifically, the
    data is stored in the order (batch_num, channel, height, width). For example,
    when the processing shown in *Figure 7.12* is conducted for N data in batches,
    the shape of the data becomes as follows.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过将每层数据流作为四维数据存储来支持卷积操作的批处理。具体来说，数据按顺序存储为（batch_num，channel，height，width）。例如，当对N个数据进行批处理中显示的处理时，数据的形状如下。
- en: 'In the data flow for batch processing shown here, the dimensions for the batches
    are added at the beginning of each piece of data. Thus, the data passes each layer
    as four-dimensional data. Please note that four-dimensional data that flows in
    the network indicates that a convolution operation is performed for N data; that
    is, N processes are conducted at one time:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在此展示的批处理数据流中，每个数据片段的批次维度都添加在数据的开头。因此，数据作为四维数据通过每一层传递。请注意，在网络中流动的四维数据表示对N个数据进行卷积操作；即，同时进行N个处理：
- en: '![Figure 7.13: Process flow of a convolution operation (batch processing)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.13：卷积操作流程（批处理）'
- en: '](img/Figure_7.13.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_7.13.jpg)'
- en: 'Figure 7.13: Process flow of a convolution operation (batch processing)'
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.13：卷积操作流程（批处理）
- en: The Pooling Layer
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化层
- en: 'A pooling operation makes the space of the height and width smaller. As shown
    in *Figure 7.14,* it converts a 2 x 2 area into one element to reduce the space''s
    size:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 池化操作使高度和宽度的空间变小。如 *图 7.14* 所示，它将一个2 x 2的区域转换为一个元素以减小空间的大小：
- en: '![Figure 7.14: Procedure of max pooling'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14：最大池化过程'
- en: '](img/fig07_14.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_14.jpg)'
- en: 'Figure 7.14: Procedure of max pooling'
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.14：最大池化过程
- en: This example shows this procedure when 2 x 2 max-pooling is conducted with a
    stride of 2\. "Max pooling" takes the maximum value of a region, while "2 x 2"
    indicates the size of the target region. As we can see, it takes the maximum element
    in a 2 x 2 region. The stride is 2 in this example, so the 2 x 2 window moves
    by two elements at one time. Generally, the same value is used for the pooling
    window size and the stride. For example, the stride is 3 for a 3 x 3 window, and
    the stride is 4 for a 4 x 4 window.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 本例展示了当进行 2 x 2 最大池化，并且步幅为 2 时的过程。“最大池化”取区域内的最大值，而“2 x 2”表示目标区域的大小。如图所示，它取的是
    2 x 2 区域内的最大元素。步幅在这个例子中是 2，因此 2 x 2 窗口每次移动两个元素。一般来说，池化窗口的大小和步幅使用相同的值。例如，3 x 3
    窗口的步幅是 3，4 x 4 窗口的步幅是 4。
- en: Note
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: In addition to max pooling, average pooling can also be used. Max pooling takes
    the maximum value in the target region, while average pooling averages the values
    in the target region. In image recognition, max pooling is mainly used. Therefore,
    a "pooling layer" in this book indicates max pooling.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 除了最大池化，还可以使用平均池化。最大池化取目标区域中的最大值，而平均池化则对目标区域内的值进行平均。在图像识别中，主要使用最大池化。因此，本书中的“池化层”指的就是最大池化。
- en: Characteristics of a Pooling Layer
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 池化层的特性
- en: A pooling layer has various characteristics, described below.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层具有多种特性，下面将进行描述。
- en: '**There are no parameters to learn**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有需要学习的参数**'
- en: Unlike a convolution layer, a pooling layer has no parameters to learn. Pooling
    has no parameters to learn because it only takes the maximum value (or averages
    the values) in the target region.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与卷积层不同，池化层没有需要学习的参数。池化层没有需要学习的参数，因为它仅仅是在目标区域内取最大值（或对值进行平均）。
- en: '**The number of channels does not change**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**通道数不变**'
- en: 'In pooling, the number of channels in the output data is the same as that in
    the input data. As shown in *Figure 7.15*, this calculation is performed independently
    for each channel:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在池化中，输出数据的通道数与输入数据的通道数相同。如*图 7.15*所示，这一计算是独立地对每个通道进行的：
- en: '![Figure 7.15: Pooling does not change the number of channels'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.15：池化不会改变通道数量'
- en: '](img/fig07_15.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_15.jpg)'
- en: 'Figure 7.15: Pooling does not change the number of channels'
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.15：池化不会改变通道数量
- en: '**It is robust to a tiny position change**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**对微小的位移变化具有鲁棒性**'
- en: 'Pooling returns the same result, even when the input data is shifted slightly.
    Therefore, it is robust to a tiny shift of input data. For example, in 3 x 3 pooling,
    pooling absorbs the shift of input data, as shown in *Figure 7.16*:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 即使输入数据发生轻微偏移，池化层也能返回相同的结果。因此，它对输入数据的微小位移变化具有鲁棒性。例如，在 3 x 3 池化中，池化能够吸收输入数据的位移，正如*图
    7.16*所示：
- en: '![Figure 7.16: Even when the input data is shifted by one element in terms
    of width, the output is the same (it may not be the same, depending on the data)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.16：即使输入数据在宽度方向上移动了一个元素，输出仍然相同（可能因数据不同而有所不同）'
- en: '](img/fig07_16.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_16.jpg)'
- en: 'Figure 7.16: Even when the input data is shifted by one element in terms of
    width, the output is the same (it may not be the same, depending on the data)'
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.16：即使输入数据在宽度方向上移动了一个元素，输出仍然相同（可能因数据不同而有所不同）
- en: Implementing the Convolution and Pooling Layers
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现卷积层和池化层
- en: So far, we have seen convolution and pooling layers in detail. In this section,
    we will implement these two layers in Python. As described in *Chapter 5*, *Backpropagation*,
    the class that will be implemented here also provides forward and backward methods
    so that it can be used as a module.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经详细了解了卷积层和池化层。在本节中，我们将用 Python 实现这两个层。如《第 5 章 反向传播》中所述，这里实现的类同样提供了前向和后向方法，可以作为一个模块使用。
- en: You may feel that implementing convolution and pooling layers is complicated,
    but you can implement them easily if you use a certain "trick." This section describes
    this trick and makes the task at hand easy. Then, we will implement a convolution
    layer.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能觉得实现卷积和池化层比较复杂，但如果你使用某些“技巧”，就能轻松实现它们。本节将介绍这个技巧，使得当前的任务变得简单。接下来，我们将实现一个卷积层。
- en: Four-Dimensional Arrays
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 四维数组
- en: 'As described earlier, four-dimensional data flows in each layer in a CNN. For
    example, when the shape of the data is (10, 1, 28, 28), it indicates that ten
    pieces of data with a height of 28, width of 28, and 1 channel exist. You can
    implement this in Python as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在 CNN 的每一层中，四维数据都会流动。例如，当数据的形状是 (10, 1, 28, 28) 时，表示有十块数据，每块数据的高度为 28，宽度为
    28，并且只有 1 个通道。你可以在 Python 中如下实现：
- en: '[PRE0]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To access the first piece of data, you can write `x[0]` ( the index begins
    at 0 in Python). Similarly, you can write `x[1]` to access the second piece of
    data:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问第一块数据，你可以写 `x[0]`（在 Python 中，索引从 0 开始）。同样，你可以写 `x[1]` 来访问第二块数据：
- en: '[PRE1]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To access the spatial data in the first channel of the first piece of data,
    you can write the following:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问第一块数据中第一个通道的空间数据，你可以写如下内容：
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can handle four-dimensional data in this way in a CNN. Therefore, implementing
    a convolution operation may be complicated. However, a "trick" called `im2col`
    makes this task easy.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 CNN 中通过这种方式处理四维数据。因此，卷积操作的实现可能会很复杂。然而，有一个被称为 `im2col` 的“技巧”使得这个任务变得简单。
- en: Expansion by im2col
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 im2col 进行扩展
- en: To implement a convolution operation, you normally need to nest `for` statements
    several times. Such an implementation is slightly troublesome and `for` statements
    in NumPy slow down the processing speed (in NumPy, it is desirable that you do
    not use any `for` statements to access elements). Here, we will not use any `for`
    statements. Instead, we will use a simple function called `im2col` for a simple
    implementation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现卷积操作，通常需要多次嵌套 `for` 语句。这样的实现方式稍显麻烦，且在 NumPy 中使用 `for` 语句会降低处理速度（在 NumPy 中，最好不要使用
    `for` 语句来访问元素）。在这里，我们不会使用任何 `for` 语句，而是使用一个简单的函数——`im2col` 来实现一个简单的实现。
- en: The `im2col` function expands input data conveniently for a filter (weight).
    As shown in *Figure 7.17*, `im2col` converts three-dimensional input data into
    a two-dimensional matrix (to be exact, it converts four-dimensional data, including
    the number of batches, into two-dimensional data).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`im2col` 函数便捷地为滤波器（权重）扩展输入数据。如 *图 7.17* 所示，`im2col` 将三维输入数据转换为二维矩阵（准确地说，它将包括批量数量的四维数据转换为二维数据）。'
- en: '`im2col` expands the input data conveniently for a filter (weight). Specifically,
    it expands the area that a filter will be applied to in the input data (a three-dimensional
    block) into a row, as shown in *Figure 7.18*. `im2col` expands all the locations
    to apply a filter to.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`im2col` 为滤波器（权重）便捷地扩展输入数据。具体来说，它将滤波器将在输入数据（一个三维块）上应用的区域扩展为一行，如 *图 7.18* 所示。`im2col`
    扩展了所有应用滤波器的区域。'
- en: 'In *Figure 7.18,* a large stride is used so that the filter areas do not overlap.
    This is done for visibility reasons. In actual convolution operations, the filter
    areas will overlap in most cases, in which case, the number of elements after
    expansion by `im2col` will be larger than that in the original block. Therefore,
    an implementation using `im2col` has the disadvantage of consuming more memory
    than usual. However, putting data into a large matrix is beneficial to perform
    calculations with a computer. For example, matrix calculation libraries (linear
    algebra libraries) highly optimize matrix calculations so that they can multiply
    large matrices quickly. Therefore, you can use a linear algebra library effectively
    by converting input data into a matrix:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 7.18* 中，使用了大步幅，以使得滤波器区域不重叠。这是出于可视化的原因。在实际的卷积操作中，滤波器区域在大多数情况下会重叠，此时通过 `im2col`
    扩展后的元素数量会比原始块中的更多。因此，使用 `im2col` 的实现存在一个缺点，就是比通常情况下消耗更多的内存。然而，将数据放入大矩阵对于计算机进行计算是有利的。例如，矩阵计算库（线性代数库）对矩阵计算进行了高度优化，可以快速乘大矩阵。因此，通过将输入数据转换为矩阵，你可以有效地使用线性代数库：
- en: '![Figure 7.17: Overview of im2col'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.17：im2col 概述'
- en: '](img/fig07_17.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_17.jpg)'
- en: 'Figure 7.17: Overview of im2col'
  id: totrans-142
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.17：im2col 概述
- en: '![Figure 7.18: Expanding the filter target area from the beginning in a row'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.18：从一开始就在行中扩展滤波器目标区域'
- en: '](img/fig07_18.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_18.jpg)'
- en: 'Figure 7.18: Expanding the filter target area from the beginning in a row'
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.18：从一开始就在行中扩展滤波器目标区域
- en: Note
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The name `im2col` is an abbreviation of "image to column," meaning the conversion
    of images into matrices. Deep learning frameworks such as Caffe and Chainer provide
    the `im2col` function, which is used to implement a convolution layer.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`im2col` 这个名称是 "image to column"（图像到列）的缩写，意思是将图像转换为矩阵。深度学习框架如 Caffe 和 Chainer
    提供了 `im2col` 函数，用于实现卷积层。'
- en: 'After using `im2col` to expand input data, all you have to do is expand the
    filter (weight) for the convolution layer into a row and multiply the two matrices
    (see *Figure 7.19*). This process is almost the same as that of a fully connected
    Affine layer:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`im2col`扩展输入数据后，你需要做的就是将卷积层的滤波器（权重）展开为一行，并将这两个矩阵相乘（见*图 7.19*）。这个过程几乎与全连接的仿射层相同：
- en: '![Figure 7.19: Details of filtering in a convolution operation – expand the
    filter into a column and multiply the matrix by the data expanded by im2col. Lastly,
    reshape the result of the size of the output data.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.19：卷积操作中的滤波细节——将滤波器展开成列，并将矩阵与通过im2col扩展的数据相乘。最后，重塑输出数据的结果大小。'
- en: '](img/fig07_19.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_19.jpg)'
- en: 'Figure 7.19: Details of filtering in a convolution operation – expand the filter
    into a column and multiply the matrix by the data expanded by im2col. Lastly,
    reshape the result of the size of the output data.'
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.19：卷积操作中的滤波细节——将滤波器展开成列，并将矩阵与通过`im2col`扩展的数据相乘。最后，重塑输出数据的结果大小。
- en: As shown in *Figure 7.19*, the output of using the `im2col` function is a two-dimensional
    matrix. You must transform two-dimensional output data into an appropriate shape
    because a CNN stores data as four-dimensional arrays. The next section covers
    the flow of implementing a convolution layer.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.19*所示，使用`im2col`函数的输出是一个二维矩阵。你必须将二维输出数据转换为合适的形状，因为CNN将数据存储为四维数组。下一部分将介绍实现卷积层的流程。
- en: Implementing a Convolution Layer
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现卷积层
- en: This book uses the `im2col` function, and we will use it as a black box without
    considering its implementation. The `im2col` implementation is located at `common/util.py`.
    It is a simple function that is about 10 lines in length. Please refer to it if
    you are interested.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了`im2col`函数，我们将把它当作一个黑盒来使用，而不考虑它的实现。`im2col`的实现位于`common/util.py`。它是一个简单的函数，长度大约为10行。如果你感兴趣，请参考它。
- en: 'This `im2col` function has the following interface:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`im2col`函数的接口如下：
- en: '[PRE3]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`input_data`: Input data that consists of arrays of four dimensions (amount
    of data, channel, height, breadth)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_data`：由四维数组组成的输入数据（数据量、通道数、高度、宽度）'
- en: '`filter_h`: Height of the filter'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_h`：滤波器的高度'
- en: '`filter_w`: Width of the filter'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_w`：滤波器的宽度'
- en: '`stride`: Stride'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`：步长'
- en: '`pad`: Padding'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad`：填充'
- en: 'The `im2col` function considers the "filter size," "stride," and "padding"
    to expand input data into a two-dimensional array, as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`im2col`函数考虑了“滤波器大小”、“步长”和“填充”来将输入数据扩展为二维数组，具体如下：'
- en: '[PRE4]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding code shows two examples. The first one uses 7x7 data with a batch
    size of 1, where the number of channels is 3\. The second one uses data of the
    same shape with a batch size of 10\. When we use the `im2col` function, the number
    of elements in the second dimension is 75 in both cases. This is the total number
    of elements in the filter (3 channels, size 5x5). When the batch size is 1, the
    result from `im2col` is (9, 75) in size. On the other hand, it is (90, 75) in
    the second example because the batch size is 10\. It can store 10 times as much
    data.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码展示了两个例子。第一个使用7x7的数据，批次大小为1，通道数为3。第二个使用相同形状的数据，批次大小为10。当我们使用`im2col`函数时，在这两种情况下第二维的元素数量都是75。这是滤波器中元素的总数（3个通道，大小为5x5）。当批次大小为1时，`im2col`的结果大小是(9,
    75)。另一方面，当批次大小为10时，第二个例子的结果是(90, 75)，因为批次大小是10，它可以存储10倍的数据。
- en: 'Now, we will use `im2col` to implement a convolution layer as a class called
    `Convolution`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`im2col`实现一个卷积层，作为一个名为`Convolution`的类：
- en: '[PRE5]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The initialization method of the convolution layer takes the filter (weight),
    bias, stride, and padding as arguments. The filter is four-dimensional, (`FN`,
    `C`, `FH`, and `FW`). `FN` stands for filter number (number of filters), `C` stands
    for a channel, `FH` stands for filter height, and `FW` stands for filter width.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层的初始化方法接受滤波器（权重）、偏置、步长和填充作为参数。滤波器是四维的，(`FN`、`C`、`FH` 和 `FW`)。`FN`表示滤波器数量（滤波器的个数），`C`表示通道数，`FH`表示滤波器的高度，`FW`表示滤波器的宽度。
- en: In the implementation of a convolution layer, an important section has been
    shown in bold. Here, `im2col` is used to expand the input data, while `reshape`
    is used to expand the filter into a two-dimensional array. The expanded matrices
    are multiplied.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层的实现中，一个重要的部分已经用粗体标出。在这里，`im2col`用来扩展输入数据，而`reshape`用来将滤波器扩展为二维数组。扩展后的矩阵被相乘。
- en: The section of code that expands the filter (the section in bold in the preceding
    code) expands the block of each filter into one line, as shown in *Figure 7.19*.
    Here, `-1` is specified as `reshape (FN, -1)`, which is one of the convenient
    features of `reshape`. When `-1` is specified for `reshape`, the number of elements
    is adjusted so that it matches the number of elements in a multidimensional array.
    For example, an array with the shape of (10, 3, 5, 5) has 750 elements in total.
    When `reshape(10, -1)` is specified here, it is reshaped into an array with the
    shape of (10, 75).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展滤波器的代码段（前面代码中加粗的部分）将每个滤波器的块扩展为一行，如*图7.19*所示。这里，`-1` 被指定为 `reshape (FN, -1)`，这是
    `reshape` 的一个便捷特性。当 `reshape` 使用 `-1` 时，元素数量会自动调整以匹配多维数组中的元素数量。例如，一个形状为 (10, 3,
    5, 5) 的数组总共有750个元素。此处指定 `reshape(10, -1)` 后，它会被重塑为形状为 (10, 75) 的数组。
- en: The `forward` function adjusts the output size appropriately at the end. NumPy's
    `transpose` function is used there. The `transpose` function changes the order
    of axes in a multidimensional array. As shown in *Figure 7.20*, you can specify
    the order of indices (numbers) that starts at 0 to change the order of axes.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward` 函数会在最后适当调整输出大小。这里使用了 NumPy 的 `transpose` 函数。`transpose` 函数改变多维数组中轴的顺序。如*图7.20*所示，你可以指定从0开始的索引顺序，以改变轴的顺序。'
- en: Thus, you can implement the forward process of a convolution layer in almost
    the same way as a fully connected Affine layer by using `im2col` for expansion
    (see *Implementing the Affine and Softmax Layers* section in *Chapter 5*, *Backpropagation*
    ). Next, we will implement backward propagation in the convolution layer. Note
    that backward propagation in the convolution layer must do the reverse of `im2col`.
    This is handled by the col2im function, which is provided in this book (located
    at `common/util.py`). Except for when col2im is used, you can implement backward
    propagation in the convolution layer in the same way as the Affine layer. The
    implementation of backward propagation in the convolution layer is located at
    `common/layer.py`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以几乎以与全连接的仿射层相同的方式实现卷积层的前向过程，通过使用 `im2col` 来进行扩展（详见*第五章*中的*实现仿射层与Softmax层*、*反向传播*）。接下来，我们将实现卷积层的反向传播。请注意，卷积层的反向传播必须执行
    `im2col` 的反向操作。这由本书提供的 col2im 函数处理（位于 `common/util.py`）。除非使用 col2im，否则你可以像实现仿射层一样实现卷积层的反向传播。卷积层反向传播的实现位于
    `common/layer.py`。
- en: '![Figure 7.20: Using NumPy''s transpose to change the order of the axes – specifying
    the indices'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.20：使用 NumPy 的转置函数更改轴的顺序——指定索引'
- en: (numbers) to change the order of axes
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: （数字）以改变轴的顺序
- en: '](img/fig07_20.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_20.jpg)'
- en: 'Figure 7.20: Using NumPy''s transpose to change the order of the axes – specifying
    the indices (numbers) to change the order of axes'
  id: totrans-175
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7.20：使用 NumPy 的转置函数更改轴的顺序——指定索引（数字）以改变轴的顺序
- en: Implementing a Pooling Layer
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现池化层
- en: You can use `im2col` to expand the input data when implementing a pooling layer,
    as in the case of a convolution layer. What is different is that pooling is independent
    of the channel dimension, unlike a convolution layer. As shown in *Figure 7.21*,
    the target pooling area is expanded independently for each channel.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现池化层时，可以像卷积层一样使用 `im2col` 来扩展输入数据。不同之处在于，池化操作不依赖于通道维度，这与卷积层不同。如*图7.21*所示，目标池化区域在每个通道上独立扩展。
- en: After this expansion, you have only to take the maximum value in each row of
    the expanded matrix and transform the result into an appropriate shape (*Figure
    7.22*).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展后，你只需在扩展后的矩阵的每一行中取最大值，并将结果转变为适当的形状（*图7.22*）。
- en: 'This is how the forward process in a pooling layer is implemented. The following
    shows a sample implementation in Python:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是池化层中前向过程的实现方法。以下是一个Python示例实现：
- en: '[PRE6]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Figure 7.21: Expanding the target pooling area of the input data (pooling
    of 2x2)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.21：扩展输入数据的目标池化区域（2x2池化）'
- en: '](img/fig07_21.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_21.jpg)'
- en: 'Figure 7.21: Expanding the target pooling area of the input data (pooling of
    2x2)'
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7.21：扩展输入数据的目标池化区域（2x2池化）
- en: 'As shown in *Figure 7.22*, there are three steps when it comes to implementing
    a pooling layer:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图7.22*所示，实现池化层时有三个步骤：
- en: Expand the input data.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展输入数据。
- en: Take the maximum value in each row.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每行中取最大值。
- en: Reshape the output appropriately.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 适当调整输出形状。
- en: 'The implementation of each step is simple and is only one or two lines in length:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 每个步骤的实现都很简单，只有一两行代码：
- en: '![Figure 7.22: Flow of implementation of a pooling layer – the maximum elements'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.22：池化层实现的流程——池化区域中的最大元素'
- en: in the pooling area are shown in gray
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 池化区域中的元素以灰色显示
- en: '](img/fig07_22.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_22.jpg)'
- en: 'Figure 7.22: Flow of implementation of a pooling layer – the maximum elements
    in the pooling area are shown in gray'
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.22：池化层实现的流程——池化区域中的最大元素以灰色显示
- en: Note
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: You can use NumPy's `np.max` method to take the maximum value. By specifying
    the axis argument in np.max, you can take the maximum value along the specified
    axis. For example, `np.max(x, axis=1)` returns the maximum value of `x` on each
    axis of the first dimension.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用NumPy的`np.max`方法来获取最大值。通过在`np.max`中指定`axis`参数，你可以沿指定的轴获取最大值。例如，`np.max(x,
    axis=1)`返回`x`在第一维每个轴上的最大值。
- en: That's all for the forward process in a pooling layer. As shown here, after
    expanding the input data into a shape that's suitable for pooling, subsequent
    implementations of it are very simple.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是池化层前向过程的全部内容。如图所示，在将输入数据扩展成适合池化的形状后，后续的实现非常简单。
- en: For the backward process in a pooling layer, backward propagation of `max` (used
    in the implementation of the ReLU layer in the *ReLU Layer* sub-section in *Chapter
    5*, *Backpropagation*), provides more information on this. The implementation
    of a pooling layer is located at `common/layer.py`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于池化层中的反向过程，`max`的反向传播（用于*第5章*中*ReLU层*小节中的ReLU层实现），提供了更多的信息。池化层的实现位于`common/layer.py`。
- en: Implementing a CNN
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现一个CNN
- en: So far, we have implemented convolution and pooling layers. Now, we will combine
    these layers to create a CNN that recognizes handwritten digits and implement
    it, as shown in *Figure 7.23*.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经实现了卷积和池化层。现在，我们将结合这些层，创建一个可以识别手写数字的卷积神经网络（CNN）并实现它，如*图 7.23*所示。
- en: 'As shown in *Figure 7.23*, the network consists of "Convolution – ReLU – Pooling
    – Affine – ReLU – Affine – Softmax" layers. We will implement this as a class
    named `SimpleConvNet`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.23*所示，网络由“卷积 – ReLU – 池化 – 仿射 – ReLU – 仿射 – Softmax”层组成。我们将实现它作为一个名为`SimpleConvNet`的类：
- en: '![Figure 7.23: Network configuration of a simple CNN'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.23：简单CNN的网络配置'
- en: '](img/fig07_23.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_23.jpg)'
- en: 'Figure 7.23: Network configuration of a simple CNN'
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.23：简单CNN的网络配置
- en: 'Now, let''s look at the initialization of `SimpleConvNet (__init__)`. It takes
    the following arguments:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看`SimpleConvNet (__init__)`的初始化。它接受以下参数：
- en: '`input_dim`: Dimensions of the input data (**channel**, **height**, **width**).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_dim`：输入数据的维度（**通道**，**高度**，**宽度**）。'
- en: '`conv_param`: Hyperparameters of the convolution layer (dictionary). The following
    are the dictionary keys:'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv_param`：卷积层的超参数（字典）。以下是字典的键：'
- en: '`filter_num`: Number of filters'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_num`：滤波器的数量'
- en: '`filter_size`: Size of the filter'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_size`：滤波器的大小'
- en: '`stride`: Stride'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stride`：步幅'
- en: '`pad`: Padding'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pad`：填充'
- en: '`hidden_size`: Number of neurons in the hidden layer (fully connected)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hidden_size`：隐藏层中的神经元数量（全连接）'
- en: '`output_size`: Number of neurons in the output layer (fully connected)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_size`：输出层中的神经元数量（全连接）'
- en: '`weight_init_std`: Standard deviation of the weights at initialization'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_init_std`：初始化时权重的标准差'
- en: Here, the hyperparameters of the convolution layer are provided as a dictionary
    called `conv_param`. We assume that the required hyperparameter values are stored
    using `{'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1}`.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，卷积层的超参数作为一个名为`conv_param`的字典提供。我们假设所需的超参数值存储为`{'filter_num':30, 'filter_size':5,
    'pad':0, 'stride':1}`。
- en: 'The implementation of the initialization of `SimpleConvNet` is a little long,
    so here it''s divided into three parts to make this easier to follow. The following
    code shows the first part of the initialization process:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`SimpleConvNet`初始化的实现稍微长一些，所以这里将其分成三个部分，以便更容易理解。以下代码展示了初始化过程的第一部分：'
- en: '[PRE7]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, the hyperparameters of the convolution layer that are provided by the
    initialization argument are taken out of the dictionary (so that we can use them
    later). Then, the output size of the convolution layer is calculated. The following
    code initializes the weight parameters:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，初始化参数提供的卷积层超参数从字典中提取（以便我们可以在后续使用）。然后，计算卷积层的输出大小。以下代码初始化了权重参数：
- en: '[PRE8]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The parameters required for training are the weights and biases of the first
    (convolution) layer and the remaining two fully connected layers. The parameters
    are stored in the instance dictionary variable, `params`. The `W1` key is used
    for the weight, while the `b1` key is used for the bias of the first (convolution)
    layer. In the same way, the `W2` and `b2` keys are used for the weight and bias
    of the second (fully connected) layer and the `W3` and `b3` keys are used for
    the weight and bias of the third (fully connected) layer, respectively. Lastly,
    the required layers are generated, as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 训练所需的参数是第一层（卷积层）和剩余的两层全连接层的权重和偏置。这些参数存储在实例字典变量`params`中。`W1`键用于表示第一层（卷积层）的权重，`b1`键用于表示第一层（卷积层）的偏置。同样，`W2`和`b2`键分别用于表示第二层（全连接层）的权重和偏置，`W3`和`b3`键分别用于表示第三层（全连接层）的权重和偏置。最后，所需的层被生成，具体如下：
- en: '[PRE9]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Layers are added to the ordered dictionary (`OrderedDict`) in an appropriate
    order. Only the last layer, `SoftmaxWithLoss`, is added to another variable, `last-layer`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 层按适当顺序添加到有序字典（`OrderedDict`）中。只有最后一层`SoftmaxWithLoss`被添加到另一个变量`last-layer`中。
- en: 'This is the initialization of `SimpleConvNet`. After the initialization, you
    can implement the `predict` method for predicting and the `loss` method for calculating
    the value of the loss function, as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`SimpleConvNet`的初始化。在初始化之后，您可以实现`predict`方法来进行预测，以及`loss`方法来计算损失函数的值，具体如下：
- en: '[PRE10]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, the `x` argument is the input data and the `t` argument is the label.
    The `predict` method only calls the added layers in order from the top, and passes
    the result to the next layer. In addition to forward processing in the `predict`
    method, the `loss` method performs forward processing until the last layer, `SoftmaxWithLoss`.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`x`参数是输入数据，`t`参数是标签。`predict`方法只按顺序调用添加的各层，将结果传递到下一层。除了`predict`方法中的前向处理外，`loss`方法在最后一层`SoftmaxWithLoss`之前执行前向处理。
- en: 'The following implementation obtains the gradients via backpropagation, as
    follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 以下实现通过反向传播获得梯度，具体如下：
- en: '[PRE11]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Backpropagation is used to obtain the gradients of the parameters. To do that,
    forward propagation and backward propagation are conducted one after the other.
    Because the forward and backward propagation are implemented properly in each
    layer, we have only to call them in an appropriate order here. Lastly, the gradient
    of each weight parameter is stored in the `grads` dictionary. Thus, you can implement
    `SimpleConvNet`.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 使用反向传播来获得参数的梯度。为此，前向传播和后向传播依次进行。由于每一层的前向和后向传播都已正确实现，这里只需要按适当顺序调用它们。最后，每个权重参数的梯度存储在`grads`字典中。因此，您可以实现`SimpleConvNet`。
- en: Now, let's train the `SimpleConvNet` class using the MNIST dataset. The code
    for training is almost the same as that described in the *Implementing a Training
    Algorithm* section in *Chapter 4*, *Neural Network Training*. Therefore, the code
    won't be shown here (the source code is located at `ch07/train_convnet.py`).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用MNIST数据集来训练`SimpleConvNet`类。训练的代码几乎与《第四章，神经网络训练》中的*实现训练算法*部分描述的相同。因此，这里不再展示代码（源代码位于`ch07/train_convnet.py`）。
- en: When `SimpleConvNet` is used to train the MNIST dataset, the recognition accuracy
    of the training data is 99.82%, while the recognition accuracy of the test data
    is 98.96% (the recognition accuracies are slightly different from training to
    training). 99% is a very high recognition accuracy for the test data for a relatively
    small network. In the next chapter, we will add layers to create a network where
    the recognition accuracy of the test data exceeds 99%.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`SimpleConvNet`训练MNIST数据集时，训练数据的识别准确率为99.82%，测试数据的识别准确率为98.96%（不同的训练可能导致略有不同的识别准确率）。对于一个相对较小的网络，99%的测试数据识别准确率已经非常高。在下一章，我们将添加更多层，创建一个测试数据识别准确率超过99%的网络。
- en: As we have seen here, convolution and pooling layers are indispensable modules
    in image recognition. A CNN can read the spatial characteristics of images and
    achieve high accuracy in handwritten digit recognition.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，卷积层和池化层是图像识别中不可或缺的模块。卷积神经网络（CNN）能够读取图像的空间特征，并在手写数字识别中达到高精度。
- en: Visualizing a CNN
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化卷积神经网络（CNN）
- en: What does the convolution layer used in a CNN "see"? Here, we will visualize
    a convolution layer to explore what happens in a CNN.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）中的卷积层“看到”什么？在这里，我们将可视化卷积层，探索卷积神经网络中的运作。
- en: Visualizing the Weight of the First Layer
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化第一层的权重
- en: 'Earlier, we conducted simple CNN training for the MNIST dataset. The shape
    of the weight of the first (convolution) layer was (30, 1, 5, 5). It was 5x5 in
    size, had 1 channel, and 30 filters. When the filter is 5x5 in size and has 1
    channel, it can be visualized as a one-channel gray image. Now, let''s show the
    filters of the convolution layer (the first layer) as images. Here, we will compare
    the weights before and after training. *Figure 7.24* shows the results (the source
    code is located at `ch07/visualize_filter.py`):'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们对 MNIST 数据集进行了简单的 CNN 训练。第一层（卷积层）权重的形状为（30, 1, 5, 5）。它的尺寸为 5x5，具有 1 个通道和
    30 个过滤器。当过滤器的尺寸为 5x5 且具有 1 个通道时，它可以被视为一个单通道灰度图像。现在，让我们将卷积层（第一层）的过滤器作为图像展示。在这里，我们将比较训练前后的权重。*图
    7.24* 展示了结果（源代码位于 `ch07/visualize_filter.py`）：
- en: '![Figure 7.24: Weight of the first (convolution) layer before and after training.
    The elements of the weight are real numbers, but they are normalized between 0
    and 255 to show the images so that the smallest value is black (0) and the largest
    value is white (255)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.24：训练前后第一层（卷积层）权重。权重的元素是实数，但它们在 0 到 255 之间进行归一化，以便展示图像，最小值为黑色（0），最大值为白色（255）'
- en: '](img/fig07_24.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_24.jpg)'
- en: 'Figure 7.24: Weight of the first (convolution) layer before and after training.
    The elements of the weight are real numbers, but they are normalized between 0
    and 255 to show the images so that the smallest value is black (0) and the largest
    value is white (255)'
  id: totrans-236
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.24：训练前后第一层（卷积层）权重。权重的元素是实数，但它们在 0 到 255 之间进行归一化，以便展示图像，最小值为黑色（0），最大值为白色（255）。
- en: As shown in *Figure 7.24*, the filters before training are initialized randomly.
    Black-and-white shades have no pattern. On the other hand, the filters after training
    are images with a pattern. Some filters have gradations from white to black, while
    some filters have small areas of color (called "blobs"), which indicates that
    training provided a pattern to the filters.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.24*所示，训练前的过滤器是随机初始化的。黑白色调没有任何规律。另一方面，训练后的过滤器是具有某种模式的图像。一些过滤器从白色到黑色有渐变，而一些过滤器有小的颜色区域（称为“斑点”），这表明训练为过滤器提供了模式。
- en: The filters with a pattern on the right-hand side of *Figure 7.24* "see" edges
    (boundaries of colors) and blobs. For example, when a filter is white in the left
    half and black in the right half, it reacts to a vertical edge, as shown in *Figure
    7.25*.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 7.24*的右侧，具有模式的过滤器“看到了”边缘（颜色的边界）和斑点。例如，当一个过滤器的左半部分为白色、右半部分为黑色时，它对垂直边缘做出了反应，如*图
    7.25*所示。
- en: '*Figure 7.25* shows the results when two learned filters are selected, and
    convolution processing is performed on the input image. You can see that "filter
    1" reacted to a vertical edge and that "filter 2" reacted to a horizontal edge:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.25* 展示了选择两个学习到的过滤器并对输入图像进行卷积处理时的结果。你可以看到“过滤器 1”对垂直边缘做出了反应，而“过滤器 2”对水平边缘做出了反应：'
- en: '![Figure 7.25: Filters reacting to horizontal and vertical edges. White pixels
    appear at a vertical edge in output image 1\. Meanwhile, many white pixels appear
    at a horizontal edge in output image 2.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.25：过滤器对水平和垂直边缘的反应。输出图像 1 中的垂直边缘处出现了白色像素。与此同时，输出图像 2 中的水平边缘处出现了许多白色像素。'
- en: '](img/fig07_25.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig07_25.jpg)'
- en: 'Figure 7.25: Filters reacting to horizontal and vertical edges. White pixels
    appear at a vertical edge in output image 1\. Meanwhile, many white pixels appear
    at a horizontal edge in output image 2.'
  id: totrans-242
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.25：过滤器对水平和垂直边缘的反应。输出图像 1 中的垂直边缘处出现了白色像素。与此同时，输出图像 2 中的水平边缘处出现了许多白色像素。
- en: Thus, you can see that the filters in a convolution layer extract primitive
    information such as edges and blobs. The CNN that was implemented earlier passes
    such primitive information to subsequent layers.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以看到卷积层中的过滤器提取了诸如边缘和斑点等基本信息。之前实现的 CNN 将这些基本信息传递给后续层。
- en: Using a Hierarchical Structure to Extract Information
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用层次结构提取信息
- en: 'The preceding result comes from the first (convolution) layer. It extracts
    low-level information such as edges and blobs. So, what type of information does
    each layer in a CNN with multiple layers extract? Research on visualization in
    deep learning [(*Matthew D. Zeiler and Rob Fergus (2014): Visualizing and Understanding
    Convolutional Networks. In David Fleet, Tomas Pajdla, Bernt Schiele, & Tinne Tuytelaars,
    eds. Computer Vision – ECCV 2014\. Lecture Notes in Computer Science. Springer
    International Publishing, 818 – 833*) and (*A. Mahendran and A. Vedaldi (2015):
    Understanding deep image representations by inverting them. In the 2015 IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR). 5188 – 5196\. DOI:* ([http://dx.doi.org/10.1109/CVPR.2015.7299155](http://dx.doi.org/10.1109/CVPR.2015.7299155))]
    has stated that the deeper a layer, the more abstract the extracted information
    (to be precise, neurons that react strongly).'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '上述结果来自第一个（卷积）层。它提取了低级信息，如边缘和斑点。那么，具有多层的CNN中的每一层提取了什么类型的信息呢？关于深度学习中的可视化研究[*Matthew
    D. Zeiler 和 Rob Fergus (2014): 可视化和理解卷积网络。在David Fleet, Tomas Pajdla, Bernt Schiele,
    & Tinne Tuytelaars编辑的《计算机视觉 – ECCV 2014》一书中，Lecture Notes in Computer Science.
    Springer International Publishing，818 – 833*]和[*A. Mahendran 和 A. Vedaldi (2015):
    通过反转深度图像表示理解它们。在2015年IEEE计算机视觉与模式识别会议（CVPR）上，5188 – 5196\. DOI:* ([http://dx.doi.org/10.1109/CVPR.2015.7299155](http://dx.doi.org/10.1109/CVPR.2015.7299155))]中指出，越深的层，提取的信息越抽象（更准确地说，是反应强烈的神经元）。'
- en: Typical CNNs
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 典型的CNN
- en: 'CNNs of various architectures have been proposed so far. In this section, we
    will look at two important networks. One is LeNet (*Y. Lecun, L. Bottou, Y. Bengio,
    and P. Haffner (1998): Gradient-based learning applied to document recognition.
    Proceedings of the IEEE 86, 11 (November 1998), 2278 – 2324\. DOI*: ([http://dx.doi.org/10.1109/5.726791](http://dx.doi.org/10.1109/5.726791))).
    It was one of the first CNNs and was first proposed in 1998\. The other is AlexNet
    (*Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton (2012): ImageNet Classification
    with Deep Convolutional Neural Networks. In F. Pereira, C. J. C. Burges, L. Bottou,
    & K. Q. Weinberger, eds. Advances in Neural Information Processing Systems 25\.
    Curran Associates, Inc., 1097 – 1105*). It was proposed in 2012 and drew attention
    to deep learning.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '迄今为止，已经提出了多种不同架构的卷积神经网络（CNN）。在本节中，我们将介绍两个重要的网络。其中一个是LeNet（*Y. Lecun, L. Bottou,
    Y. Bengio, 和 P. Haffner (1998): 基于梯度的学习应用于文档识别。《IEEE 86卷，11期》（1998年11月），2278 –
    2324\. DOI*: ([http://dx.doi.org/10.1109/5.726791](http://dx.doi.org/10.1109/5.726791)))。它是最早的CNN之一，并于1998年首次提出。另一个是AlexNet（*Alex
    Krizhevsky, Ilya Sutskever, 和 Geoffrey E. Hinton (2012): 基于深度卷积神经网络的ImageNet分类。在F.
    Pereira, C. J. C. Burges, L. Bottou, & K. Q. Weinberger编辑的《神经信息处理系统进展 25》一书中，Curran
    Associates，Inc.，1097 – 1105*）。它在2012年提出，引起了人们对深度学习的关注。'
- en: LeNet
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LeNet
- en: LeNet is a network for handwritten digit recognition that was proposed in 1998\.
    In the network, a convolution layer and a pooling layer (i.e., a subsampling layer
    that only "thins out elements") are repeated, and finally, a fully connected layer
    outputs the result.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet是一个用于手写数字识别的网络，提出于1998年。在该网络中，卷积层和池化层（即只“稀疏元素”的子采样层）被重复使用，最后通过全连接层输出结果。
- en: 'There are some differences between LeNet and the "current CNN." One is that
    there''s an activation function. A sigmoid function is used in LeNet, while ReLU
    is mainly used now. Subsampling is used in the original LeNet to reduce the size
    of intermediate data, while max pooling is mainly used now:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet与“当前CNN”之间确实存在一些差异。一个是激活函数的不同，LeNet使用的是sigmoid函数，而现在主要使用ReLU。原始LeNet中使用了子采样来减少中间数据的大小，而现在主要使用最大池化：
- en: In this way, there are some differences between LeNet and the "current CNN,"
    but they are not significant. This is surprising when we consider that LeNet was
    the "first CNN" to be proposed almost 20 years ago.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，LeNet与“当前CNN”之间存在一些差异，但差异并不显著。考虑到LeNet几乎是20年前提出的“第一个CNN”，这一点令人惊讶。
- en: AlexNet
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AlexNet
- en: 'AlexNet was published nearly 20 years after LeNet was proposed. Although AlexNet
    created a boom in deep learning, its network architecture hasn''t changed much
    from LeNet:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet发布距LeNet提出已有近20年。尽管AlexNet引发了深度学习的热潮，但其网络架构与LeNet相比变化不大：
- en: 'AlexNet stacks a convolution layer and a pooling layer and outputs the result
    through a fully connected layer. Its architecture is not much different from LeNet,
    but there are some differences, as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet将卷积层和池化层堆叠，并通过全连接层输出结果。它的架构与LeNet差异不大，但也有一些不同之处，如下所示：
- en: ReLU is used as the activation function
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ReLU作为激活函数
- en: A layer for local normalization called **Local Response Normalization** (**LRN**)
    is used
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用了一种名为**局部响应归一化**（**LRN**）的局部归一化层。
- en: Dropout is used (see *Dropout* sub-section in *Chapter 6*, *Training Techniques*)
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用了Dropout（请参见*第6章*中的*Dropout*小节，*训练技巧*）。
- en: LeNet and AlexNet are not very different in terms of their network architectures.
    However, the surrounding environment and computer technologies have advanced greatly.
    Now, everyone can obtain a large quantity of data, and widespread GPUs that are
    good at large parallel computing enable massive operations at high speed. Big
    data and GPUs greatly motivated the development of deep learning.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet和AlexNet在网络架构上没有太大区别。然而，周围的环境和计算机技术有了显著进步。现在，人人都能获取大量数据，而且广泛使用的GPU擅长进行大规模并行计算，从而能够以高速进行大规模操作。大数据和GPU极大地推动了深度学习的发展。
- en: Note
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Many parameters often exist in deep learning (a network with many layers). Many
    calculations are required for training, and a large quantity of data is required
    to "satisfy" these parameters. We can say that GPUs and big data cast light on
    these challenges.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中通常存在许多参数（即网络具有许多层）。训练需要大量计算，而且需要大量数据来“满足”这些参数。我们可以说，GPU和大数据为解决这些挑战提供了帮助。
- en: Summary
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about CNNs. Specifically, we covered convolution
    layers and pooling layers (the basic modules that constitute CNNs) in great detail
    in order to understand them at the implementation level. CNNs are mostly used
    when looking at data regarding images. Please ensure that you understand the content
    of this chapter before moving on.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了CNN。具体来说，我们详细讨论了卷积层和池化层（构成CNN的基本模块），以便从实现的角度理解它们。CNN主要用于处理与图像相关的数据。在继续学习之前，请确保你理解了本章的内容。
- en: 'In this chapter, we learned about the following:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们学习了以下内容：
- en: In a CNN, convolution, and pooling layers are added to the previous network,
    which consists of fully connected layers.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在CNN中，卷积层和池化层被添加到之前由全连接层组成的网络中。
- en: You can use `im2col` (a function for expanding images into arrays) to implement
    convolution and pooling layers simply and efficiently.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用`im2col`（一个用于将图像扩展为数组的函数）来简洁高效地实现卷积层和池化层。
- en: Visualizing a CNN enables you to see how advanced information is extracted as
    the layer becomes deeper.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化CNN可以让你看到随着网络层次变深，如何提取更高级的信息。
- en: Typical CNNs include LeNet and AlexNet.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型的CNN包括LeNet和AlexNet。
- en: Big data and GPUs contribute significantly to the development of deep learning.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据和GPU对深度学习的发展有着重要的推动作用。
