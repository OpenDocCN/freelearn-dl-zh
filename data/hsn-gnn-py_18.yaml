- en: '18'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '18'
- en: Unlocking the Potential of Graph Neural Networks for Real-World Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁图神经网络在现实应用中的潜力
- en: Thank you for taking the time to read *Hands-On Graph Neural Networks Using
    Python*. We hope that it has provided you with valuable insights into the world
    of graph neural networks and their applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您抽出时间阅读*《使用 Python 实战图神经网络》*。我们希望它为您提供了关于图神经网络及其应用的宝贵见解。
- en: As we conclude this book, we would like to leave you with some final pieces
    of advice on how to effectively use GNNs. GNNs can be incredibly performant in
    the right conditions, but they suffer from the same pros and cons as other deep
    learning techniques. Knowing when and where to apply these models is a crucial
    skill to master, as over-engineered solutions can result in poor performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书结束时，我们想给您一些关于如何有效使用 GNN 的最后建议。GNN 在合适的条件下可以非常高效，但它们也有与其他深度学习技术相同的优缺点。知道何时何地应用这些模型是掌握的一项关键技能，因为过度设计的解决方案可能会导致性能不佳。
- en: First, GNNs are especially effective when a large amount of data is available
    for training. This is because deep learning algorithms require a lot of data to
    learn complex patterns and relationships effectively. With a large enough dataset,
    GNNs can achieve high levels of accuracy and generalization.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，当有大量数据可供训练时，GNN 特别有效。这是因为深度学习算法需要大量数据才能有效地学习复杂的模式和关系。在足够大的数据集上，GNN 可以实现高水平的准确性和泛化能力。
- en: For similar reasons, GNNs are most valuable when dealing with complex, high-dimensional
    data (node and edge features). They can automatically learn intricate patterns
    and relationships between features that would be difficult or impossible for humans
    to identify. Traditional machine learning algorithms, such as linear regression
    or decision trees, rely on handcrafted features that are often limited in their
    ability to capture the complexity of real-world data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 出于类似的原因，GNN 在处理复杂的高维数据（节点和边特征）时最具价值。它们可以自动学习复杂的模式和特征之间的关系，这些是人类很难或无法识别的。传统的机器学习算法，如线性回归或决策树，依赖于手工制作的特征，这些特征通常在捕捉现实世界数据的复杂性方面存在局限性。
- en: Finally, when working with GNNs, it is important to ensure that the graph representation
    adds value to the features. This is particularly applicable when the graph is
    an artificially constructed representation rather than a natural one, such as
    social networks or protein structures. The connections between nodes should not
    be arbitrary but represent meaningful relationships between the nodes.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在使用 GNN 时，确保图表示能够为特征增加价值非常重要。特别是在图是人工构建的表示时（而非自然图），如社交网络或蛋白质结构时尤其适用。节点之间的连接不应是随意的，而应代表节点之间有意义的关系。
- en: You might notice that some examples in this book did not follow the previous
    rules. This is mostly due to the technical limitation of being able to run the
    code in Google Colab, and a general lack of high-quality datasets. However, this
    is also reflective of real-life datasets, which can be messy and difficult to
    obtain in large quantities. Most of this data also tends to be tabular, where
    excellent tree-based models such as XGBoost are difficult to beat.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，本书中的某些示例没有遵循之前的规则。这主要是由于在 Google Colab 中运行代码的技术限制，以及普遍缺乏高质量的数据集。然而，这也反映了现实生活中的数据集，通常是杂乱的，而且难以大量获取。这些数据大多数也是表格数据，优秀的基于树的模型，如
    XGBoost，通常难以超越。
- en: More generally, sound baseline solutions are crucial, as they can be challenging
    to outperform, even in the right conditions. A powerful strategy when working
    with GNNs is to implement multiple types of GNNs and compare their performance.
    For example, a convolutional-based GNN such as GCN ([*Chapter 6*](B19153_06.xhtml#_idTextAnchor074))
    might work well for certain types of graphs, while an attention-based GNN such
    as GAT ([*Chapter 7*](B19153_07.xhtml#_idTextAnchor082)) might be better suited
    for others. Additionally, a message-passing GNN such as MPNN ([*Chapter 12*](B19153_12.xhtml#_idTextAnchor144))
    might excel in certain contexts. Note how each approach is more expressive than
    the previous one, and each has different strengths and weaknesses.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般而言，可靠的基准解决方案至关重要，因为即使在合适的条件下，它们也可能很难被超越。使用GNN时，一个有效的策略是实现多种类型的GNN并比较它们的表现。例如，基于卷积的GNN（如GCN，见[*第6章*](B19153_06.xhtml#_idTextAnchor074)）可能在某些类型的图上表现良好，而基于注意力的GNN（如GAT，见[*第7章*](B19153_07.xhtml#_idTextAnchor082)）可能更适合其他类型的图。此外，基于消息传递的GNN（如MPNN，见[*第12章*](B19153_12.xhtml#_idTextAnchor144)）可能在某些背景下表现出色。请注意，每种方法相比之前的方法表达能力更强，而且每种方法有不同的优点和缺点。
- en: If you’re working on a more specific problem, there are several GNN approaches
    covered in this book that may be more appropriate. For example, if you’re dealing
    with small graph data that lacks node and edge features, you may want to consider
    using Node2Vec ([*Chapter 4*](B19153_04.xhtml#_idTextAnchor054)). On the contrary,
    if you’re dealing with large graphs, GraphSAGE and LightGCN can help manage the
    computational time and memory storage requirements (*Chapters 8* and *17*).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在解决一个更具体的问题，本书中有几种GNN方法可能更加合适。例如，如果你处理的是缺乏节点和边特征的小型图数据，你可能会考虑使用Node2Vec（见[*第4章*](B19153_04.xhtml#_idTextAnchor054)）。相反，如果你处理的是大型图，GraphSAGE和LightGCN可以帮助管理计算时间和内存存储要求（见*第8章*和*第17章*）。
- en: Additionally, GIN and global pooling layers may be suitable for graph classification
    tasks ([*Chapter 9*](B19153_09.xhtml#_idTextAnchor106)), while Variational Graph
    Autoencoders and SEAL can be used for link prediction ([*Chapter 10*](B19153_10.xhtml#_idTextAnchor116)).
    For generating new graphs, you can explore GraphRNN and MolGAN ([*Chapter 11*](B19153_11.xhtml#_idTextAnchor131)).
    If you’re working with heterogeneous graphs, you may want to consider one of the
    many flavors of heterogeneous GNNs (*Chapters 12* and *16*). For spatio-temporal
    graphs, Graph WaveNet, STGraph, and other temporal GNNs can be useful (*Chapters
    13* and *15*). Finally, if you need to explain the predictions made by your GNN,
    you can turn to the graph explainability techniques covered in [*Chapter 14*](B19153_14.xhtml#_idTextAnchor165).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，GIN和全局池化层可能适用于图分类任务（见[*第9章*](B19153_09.xhtml#_idTextAnchor106)），而变分图自编码器和SEAL可以用于链接预测（见[*第10章*](B19153_10.xhtml#_idTextAnchor116)）。对于生成新图，你可以探索GraphRNN和MolGAN（见[*第11章*](B19153_11.xhtml#_idTextAnchor131)）。如果你在处理异构图，可能需要考虑使用不同种类的异构GNN（见*第12章*和*第16章*）。对于时空图，Graph
    WaveNet、STGraph及其他时序GNN可以派上用场（见*第13章*和*第15章*）。最后，如果你需要解释你的GNN做出的预测，你可以参考[*第14章*](B19153_14.xhtml#_idTextAnchor165)中介绍的图可解释性技术。
- en: By reading this book, you will have gained a deep understanding of GNNs and
    how they can be applied to solve real-world problems. As you continue to work
    in this field, we encourage you to put this knowledge into practice, experiment
    with new approaches, and continue to grow your expertise. The field of machine
    learning is constantly evolving, and your skills will only become more valuable
    as time goes on. We hope that you will apply what you have learned to tackle challenges
    and have a positive impact on the world. Thank you again for reading this book,
    and we wish you all the best in your future endeavors.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过阅读本书，你将深入理解图神经网络（GNN）及其如何应用于解决现实世界中的问题。随着你在该领域的持续工作，我们鼓励你将这些知识付诸实践，尝试新的方法，并不断提升自己的专业技能。机器学习领域在不断发展，随着时间的推移，你的技能将变得越来越有价值。我们希望你能够将所学应用于应对挑战，并对世界产生积极的影响。再次感谢你阅读本书，祝你在未来的工作中一切顺利。
