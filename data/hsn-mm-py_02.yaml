- en: Hidden Markov Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐马尔可夫模型
- en: In the previous chapter, we discussed Markov chains, which are helpful in modelling
    a sequence of observations across time. In this chapter, we are going to study
    the **Hidden Markov Model** (**HMM**), which is also used to model sequential
    data but is much more flexible than Markov chains.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了马尔可夫链，它对于建模跨时间的观察序列非常有帮助。在本章中，我们将研究**隐马尔可夫模型**（**HMM**），它也用于建模序列数据，但比马尔可夫链更加灵活。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Markov models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马尔可夫模型
- en: The HMM
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HMM
- en: Evaluation of an HMM
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HMM的评估
- en: Extensions of HMM
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HMM的扩展
- en: Markov models
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫模型
- en: The Markov model is a stochastic model in which the state of the random variable
    at the next instance of time depends only on the outcome of the random variable
    at the current time. The simplest kind of Markov model is a Markov chain, which
    we discussed in [Chapter 1](c8b01245-1f2b-4b5e-837f-bdcc1d87343e.xhtml), *Introduction
    to Markov Process*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型是一种随机模型，其中随机变量在下一个时间点的状态仅依赖于当前时间点的随机变量结果。最简单的马尔可夫模型是马尔可夫链，我们在[第1章](c8b01245-1f2b-4b5e-837f-bdcc1d87343e.xhtml)中讨论过，*马尔可夫过程简介*。
- en: 'Suppose we have a set of sequential observations (*x[1],. . ., x[n])* obeying
    the Markov property, then we can state the joint probability distribution for *N *observations
    as the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组顺序观察值（*x[1],. . ., x[n])*，遵循马尔可夫性质，那么我们可以表示*N*个观察值的联合概率分布如下：
- en: '![](img/5c66bf6e-6ea7-484b-994a-be9b41ebd265.png)![](img/6f36b56b-0134-419b-b19c-8b86f17fb3fe.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c66bf6e-6ea7-484b-994a-be9b41ebd265.png)![](img/6f36b56b-0134-419b-b19c-8b86f17fb3fe.png)'
- en: Graphical representation of a first-order Markov chain in which the distribution
    of the current observation is conditioned on the value of the previous observation
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一阶马尔可夫链的图示表示，其中当前观察值的分布依赖于前一个观察值的值
- en: The preceding representation of the Markov chain is different from the representations
    we saw earlier. In this representation, the observations are presented as nodes
    and the edges represent conditional probability between two observations, namely
    *Pr(x[n]|x[n-1])*. This is how probabilistic graphical models are generally represented,
    where nodes represent random variables and edges represent a conditional probability
    distribution between these two variables. This graphical representation gives
    us insight into the causal relationships between random variables.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 上述马尔可夫链的表示与我们之前看到的表示不同。在这种表示中，观察值呈现为节点，边表示两个观察值之间的条件概率，即*Pr(x[n]|x[n-1])*。这就是概率图模型的一般表示方式，其中节点表示随机变量，边表示这两个变量之间的条件概率分布。这种图形化表示帮助我们理解随机变量之间的因果关系。
- en: State space models
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 状态空间模型
- en: 'We can see that a simple Markov chain is very restrictive and does not work
    well for situations where we anticipate that several successive observations will
    provide important information required to predict the next observation. Fortunately,
    a Markov chain can be tweaked to support these cases as well:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，简单的马尔可夫链是非常有限的，不能很好地处理我们预期多个连续观察值能提供预测下一个观察值所需的重要信息的情况。幸运的是，马尔可夫链可以进行调整，以支持这些情况：
- en: '![](img/7034d32a-d9eb-416a-93ee-7b3c690948ce.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7034d32a-d9eb-416a-93ee-7b3c690948ce.png)'
- en: Second-order Markov chain in which the distribution of the current observation
    is conditioned on the values of the last two observations
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 二阶马尔可夫链，其中当前观察值的分布依赖于最后两个观察值的值
- en: 'Let''s consider a Markov chain where the probability of the next state not
    only depends on the current state but also on the last state. This type of Markov
    chain is called a **second-order Markov chain** and the joint probability distribution
    can be represented as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个马尔可夫链，其中下一个状态的概率不仅依赖于当前状态，还依赖于前一个状态。这种类型的马尔可夫链被称为**二阶马尔可夫链**，其联合概率分布可以表示如下：
- en: '![](img/f3e9a95b-56cb-46be-8cd9-eee411ac53a3.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3e9a95b-56cb-46be-8cd9-eee411ac53a3.png)'
- en: Using the d-separation property, we see that the conditional distribution of
    *X[n]* given *X[n-1]* and *X[n-2]* is independent of all observations, *X[1],
    . . ., X[n-3]*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 利用d-分离性质，我们可以看到，给定*X[n-1]*和*X[n-2]*的条件下，*X[n]*的条件分布与所有观察值*X[1], . . ., X[n-3]*是独立的。
- en: Similarly, we can extend this to an *M^(th)*-order Markov chain in which the
    conditional distribution for a particular observation depends on the previous
    *M* observations. However, we are now paying the price of a large number of parameters
    for increased flexibility.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以将其扩展到一个*M^(th)*阶马尔可夫链，其中特定观察值的条件分布依赖于前*M*个观察值。然而，现在我们需要为增加的灵活性付出代价，即需要更多的参数。
- en: Suppose that the observations are discrete variables having *K* states. Then
    the conditional distribution, *Pr(X[n]|X[n-1])*,in a first-order Markov chain
    will be specified by a set of *K-1* parameters for each of the *K* states of *X[n-1]*,
    giving a total of *K(K-1)* parameters. If we extend this to an *M^(th)*-order
    Markov chain, where joint distribution is built up from conditionals, *Pr(x[n]|x[n-M],
    . . ., x[n-1])*, the number of parameters in such a model would have *K^(M-1)(K-1)*.
    Because this grows exponentially with *M*, it will often render this approach
    impractical for larger values of *M*. But, what if we want to build a model for
    sequential data that is not bounded by any order of Markov assumption, and yet
    it can be represented by a limited number of parameters?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设观察值是具有*K*状态的离散变量。那么在一阶马尔可夫链中，条件分布*Pr(X[n]|X[n-1])*将由每个*K*状态的*X[n-1]*的*K-1*个参数来指定，给出总共*K(K-1)*个参数。如果我们将其扩展到一个*M^(th)*阶马尔可夫链，其中联合分布由条件分布*Pr(x[n]|x[n-M],
    . . ., x[n-1])*构建，那么该模型中的参数数量将为*K^(M-1)(K-1)*。由于这个数量随着*M*的增加呈指数增长，它通常会使得对于较大的*M*值，这种方法变得不切实际。但如果我们想构建一个不受马尔可夫假设阶数限制的序列数据模型，并且它可以通过有限数量的参数来表示，该怎么办呢？
- en: 'Such models can be created by introducing latent (or hidden) variables. Latent
    variables allow us to create a rich class of models constructed out of simple
    components. Let''s assume that for each observation, *x[n]*, we have a latent
    variable, *z[n ]*(which may or may not have the same dimensionality as the observed
    variable). If these latent variables form a first-order Markov chain, this type
    of model can be called a **state space model**, which is represented in the following
    diagram:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型可以通过引入潜在（或隐藏）变量来创建。潜在变量使我们能够构建由简单组件组成的丰富模型类。假设对于每个观察值，*x[n]*，我们有一个潜在变量，*z[n]*（它可能与观察变量的维度相同，也可能不同）。如果这些潜在变量形成一个一阶马尔可夫链，那么这种类型的模型可以称为**状态空间模型**，其表示如下图所示：
- en: '![](img/ab40bbf5-fbfa-40e5-b890-c60f1245c51f.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ab40bbf5-fbfa-40e5-b890-c60f1245c51f.png)'
- en: State space model representing a distribution, where each observation is conditioned
    upon a latent variable
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表示分布的状态空间模型，其中每个观察值都基于一个潜在变量进行条件化
- en: Using the d-separation property, we can see that there is always a path between
    any two observed variables, *x[n]* and *x[m]*, via latent variables and this path
    can never be blocked. So the *Pr(x[n+1]|x[1], . . ., x[n])* distribution for observation
    *x[n+1]* given all previous observations does not exhibit any conditional independence
    properties, and thus the prediction for *x[n+1]* depends on all previous observations.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 利用d-separation性质，我们可以看到，任何两个观察变量之间始终存在一条路径，*x[n]*和*x[m]*通过潜在变量连接，而且这条路径永远不会被阻塞。因此，给定所有前期观察值的*Pr(x[n+1]|x[1],
    . . ., x[n])*分布不具有任何条件独立性特性，因此，*x[n+1]*的预测依赖于所有前期观察值。
- en: 'As the latent variables form a Markov chain, they satisfy the following conditional
    distribution:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于潜在变量形成了一个马尔可夫链，它们满足以下条件分布：
- en: '![](img/081d9b87-ab89-4b8c-95c1-9640bdf73bc2.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/081d9b87-ab89-4b8c-95c1-9640bdf73bc2.png)'
- en: 'Thus, the joint distribution of this model can be stated as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个模型的联合分布可以表述如下：
- en: '![](img/2e6929df-c3e3-46b5-a85f-47bbd6b4565d.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e6929df-c3e3-46b5-a85f-47bbd6b4565d.png)'
- en: The HMM
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐马尔可夫模型（HMM）
- en: An HMM is a specific case of state space model in which the latent variables
    are discrete and multinomial variables. From the graphical representation, we
    can also consider an HMM to be a double stochastic process consisting of a hidden
    stochastic Markov process (of latent variables) that we cannot observe directly,
    and another stochastic process that produces a sequence of the observation given
    the first process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 隐马尔可夫模型（HMM）是状态空间模型的一个特例，其中潜在变量是离散的多项式变量。从图形表示来看，我们也可以将HMM视为一个双重随机过程，包含一个我们无法直接观察的隐藏随机马尔可夫过程（潜在变量），以及另一个生成观察序列的随机过程，这个过程基于第一个过程。
- en: 'Before moving on to the parameterization, let''s consider an example of coin-tossing
    to get an idea of how it works. Assume that we have two unfaircoins, *M[1]* and
    *M[2]*, with *M[1]* having a higher probability (70%) of getting heads and *M[2]* having
    a higher probability (80%) of getting tails. Someone sequentially flips these
    two coins, however, we do not know which one. We can only observe the outcome,
    which can either be heads (*H*) or tails (*T*):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续讨论参数化之前，我们先通过一个掷硬币的例子来了解它的工作原理。假设我们有两枚不公平的硬币，*M[1]* 和 *M[2]*，其中 *M[1]* 具有较高的正面概率（70%），而
    *M[2]* 具有较高的反面概率（80%）。某人按顺序掷这两枚硬币，但我们并不知道是哪一枚。我们只能观察到结果，它可能是正面（*H*）或反面（*T*）：
- en: '![](img/ce6640f8-df25-4556-8bb7-6022359b457b.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce6640f8-df25-4556-8bb7-6022359b457b.png)'
- en: 'We can consider the unfair coin selected to be the latent variable, and the
    outcome of the coin toss to be the observed data. To predict the next outcome
    sequence of observation, we would at least require information such as which coin
    was selected at first, the next coin to flip given the previous one, and the probability
    of getting *H* or *T* given the coin. Assuming that both of the coins have equal
    priority of getting selected at first and each coin is equally likely to get selected
    given the previous coin selected, we can create the following state diagram:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将选中的不公平硬币视为潜在变量，硬币投掷的结果视为观察数据。为了预测下一次观察序列的结果，我们至少需要以下信息：首先选择了哪枚硬币、给定之前选中的硬币下一枚硬币的选择以及根据硬币得到
    *H* 或 *T* 的概率。假设两枚硬币在首次选择时的优先级相等，并且每次硬币的选择都是根据之前选择的硬币以同等的概率进行选择，我们可以创建如下的状态图：
- en: '![](img/09da993d-b970-4820-ab7b-79f5e77e25f1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09da993d-b970-4820-ab7b-79f5e77e25f1.png)'
- en: State diagram for coin toss HMM
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 掷硬币 HMM 的状态图
- en: In the previous diagram, **z[1]** and **z[2]** represent states of the latent
    variable coin selected *(***z[1]**representing coin **M[1]** getting selected,
    and **z[2]** representing coin **M[2]**being selected). The arcs represent transition
    probabilities of moving from one state of latent variable to the other and the
    straight lines represent the probabilities of the observed variable (toss outcome)
    given the latent variable (coin selected).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的图示中，**z[1]** 和 **z[2]** 代表潜在变量硬币的状态（*其中 **z[1]** 代表硬币 **M[1]** 被选中，**z[2]**
    代表硬币 **M[2]** 被选中*）。弧线表示从一个潜在变量状态转移到另一个状态的转移概率，直线则表示给定潜在变量（选中的硬币）时观察到的变量（投掷结果）的概率。
- en: Parameterization of HMM
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HMM 的参数化
- en: In the previous section, we saw an example of an HMM to get an idea of how the
    model works. Let's now formally parameterize an HMM.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了一个 HMM 的例子来了解模型的工作原理。现在我们正式开始对 HMM 进行参数化。
- en: As the latent variables of an HMM are discrete multinomial variables, we can
    use the 1-of-K encoding scheme to represent it, where the *z[n]* variable is represented
    by a K-dimensional vector of binary variables, *z[nk] ∈ {0,1}*, such that *z[nk]
    = 1* and *z[nj] = 0* for *j ≠ k* if the *z[n]* variable is in the *k* state.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 HMM 的潜在变量是离散的多项式变量，我们可以使用 1-of-K 编码方案来表示它，其中 *z[n]* 变量由一个 K 维的二进制变量向量表示，*z[nk]
    ∈ {0,1}*，当 *z[n]* 变量处于 *k* 状态时，*z[nk] = 1* 且 *z[nj] = 0*（对于 *j ≠ k*）。
- en: 'With this in mind, we can create a matrix with the transition probability matrix
    *A*, where *A[ij]* = *Pr(Z[nj ]= 1| z[n-1], i = 1)*. As the *A[ij]* represent
    the probability of moving from state *i* to state *j*, it holds the property of ![](img/4ad55b94-7a14-470d-8994-feb70fc80bcb.png) and
    can be expressed using the *K(K-1)* parameters. Thus we can represent the conditional
    probability distribution as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们可以创建一个包含转移概率矩阵 *A* 的矩阵，其中 *A[ij]* = *Pr(Z[nj] = 1| z[n-1], i = 1)*。由于
    *A[ij]* 代表从状态 *i* 转移到状态 *j* 的概率，它具备 ![](img/4ad55b94-7a14-470d-8994-feb70fc80bcb.png)
    的性质，并且可以通过 *K(K-1)* 参数表示。因此，我们可以如下表示条件概率分布：
- en: '![](img/3e8acc3f-3118-4382-8647-1bc598a13328.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e8acc3f-3118-4382-8647-1bc598a13328.png)'
- en: 'The transition matrix is generally represented using a state-transition diagram,
    as we saw in [Chapter 1](https://cdp.packtpub.com/hands_on_markov_models_with_python/wp-admin/post.php?post=25&action=edit#post_24), *Introduction
    to Markov Process*. But we can take the same representation and unfold it across
    time to get a *lattice* or *trellis* diagram, as presented in the following image.
    We will be using this representation of HMM in the following sections for learning
    parameters and making inferences from the model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 转移矩阵通常通过状态转移图来表示，正如我们在[第一章](https://cdp.packtpub.com/hands_on_markov_models_with_python/wp-admin/post.php?post=25&action=edit#post_24)中看到的，*马尔可夫过程简介*。但我们可以将相同的表示方法展开到时间维度，得到一个*网格*或*格子*图，如下图所示。在接下来的章节中，我们将使用这种HMM的表示方法来学习参数并从模型中进行推断：
- en: '![](img/36f8e635-07bc-4c8a-8b27-b0cee3c2a0a3.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36f8e635-07bc-4c8a-8b27-b0cee3c2a0a3.png)'
- en: Trellis diagram for an HMM with latent variables with three states
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 带有三个状态的HMM隐变量的格子图
- en: 'As the initial latent node, *z[1]*, does not have a parent node, it has a marginal
    distribution, *Pr(z[1])*, which can be represented by a vector of probabilities, *π*,
    such that *π[k] = Pr(z[1k] = 1)* with ![](img/afb5fed2-f1d9-48ac-9595-db3ef99d4465.png).
    Thus, the probability of *Pr(z[1]|π*) can be expressed as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于初始隐节点*z[1]*没有父节点，它具有边际分布*Pr(z[1])*，可以通过概率向量*π*表示，*π[k] = Pr(z[1k] = 1)*，如图所示。这样，*Pr(z[1]|π*)*的概率可以表示如下：
- en: '![](img/28e79bdb-aea8-45be-9822-d4ca7b68eb50.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/28e79bdb-aea8-45be-9822-d4ca7b68eb50.png)'
- en: The third and final parameter required to parameterize an HMM is the conditional
    probability of the observed variable given the latent variable, namely the emission
    probability. It is represented by the conditional distribution, *Pr(x[n]| z[n], Φ)*,
    which is governed by some parameters, *Φ*. If the observed variable, *x[n]*, is
    discrete, the emission probability may take the form of a conditional probability
    table (multinomial HMM). Similarly, if the observed variable, *x[n]*, is continuous,
    then this distribution might be a Gaussian distribution (Gaussian HMM) where ![](img/e188d3e6-22f0-4a60-abad-ca3b1d67a157.png) denotes
    the set of parameters governing the distribution, namely the mean and variance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 参数化HMM所需的第三个也是最后一个参数是给定隐变量的观测变量的条件概率，即发射概率。它由条件分布*Pr(x[n]| z[n], Φ)*表示，且由一些参数*Φ*控制。如果观测变量*x[n]*是离散的，则发射概率可以采用条件概率表的形式（多项式HMM）。类似地，如果观测变量*x[n]*是连续的，则该分布可能是高斯分布（高斯HMM），其中![](img/e188d3e6-22f0-4a60-abad-ca3b1d67a157.png)表示控制分布的参数集，即均值和方差。
- en: 'Thus, the joint probability distribution over both the latent and observed
    variables can be stated as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，隐变量和观测变量的联合概率分布可以表示如下：
- en: '![](img/f28a70f1-1d0d-49c6-872b-48f4785f4fd3.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f28a70f1-1d0d-49c6-872b-48f4785f4fd3.png)'
- en: Here, *X = {x[1], ..., x[N]}*, *Z = {z[1], ..., z[N]}* and *θ = {A, π, Φ}* denotes
    the set of parameters governing the model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*X = {x[1], ..., x[N]}*，*Z = {z[1], ..., z[N]}*，以及*θ = {A, π, Φ}*表示控制模型的参数集。
- en: An HMM model is called a **homogenous model** when all the conditional distributions
    governing the latent variables share the same transition matrix, *A*, and all
    the emission probabilities share the same parameters, *Φ*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有控制隐变量的条件分布共享相同的转移矩阵*A*，且所有发射概率共享相同的参数*Φ*时，HMM模型被称为**齐次模型**：
- en: 'Now, let''s try to code a simple multinomial HMM. We will start by defining
    a simple `MultinomialHMM` class and keep on adding methods as we move forward:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试编写一个简单的多项式隐马尔可夫模型（HMM）。我们将从定义一个简单的`MultinomialHMM`类开始，并在接下来的过程中不断添加方法：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Using the `MultinomialHMM` class, we can define the HMM coin that we discussed
    previously as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`MultinomialHMM`类，我们可以像之前讨论的那样定义HMM硬币模型，如下所示：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Generating an observation sequence
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成观测序列
- en: 'For a given HMM parameterized by *{A, π, Φ}*, we can generate a sequence of
    observations, *{x[1], ..., x[N]}*, using the following steps:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个由*{A, π, Φ}*参数化的HMM，我们可以通过以下步骤生成一系列观测值，*{x[1], ..., x[N]}*：
- en: Set *n = 1*
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置*n = 1*
- en: Choose an initial state of the latent variable, *z[1]*, according to the prior
    distribution, *π*
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据先验分布*π*选择初始隐状态*z[1]*：
- en: Choose an observation, *x[1]*, for the given value of *z[1]*, by sampling the
    emission-probability distribution governed by *Φ*
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据给定的*z[1]*值，通过采样由*Φ*控制的发射概率分布来选择观测值，*x[1]*：
- en: Transit to the next state of the latent variable, *z[n+1]*, according to the
    state-transition probability matrix, *A*
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据状态转移概率矩阵 *A*，转移到潜变量 *z[n+1]* 的下一个状态
- en: Set *n = n + 1 *and repeat step 3 if *n ≤ N*, otherwise terminate
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 *n = n + 1* 并重复第 3 步，如果 *n ≤ N*，否则终止
- en: 'We can add a method to generate samples in the previously defined `MultinomialHMM`
    class, as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向之前定义的 `MultinomialHMM` 类中添加一个生成样本的方法，如下所示：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can use the `generate_samples` method on our HMM coin example to generate
    an observation sequence:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 HMM 投币示例上使用 `generate_samples` 方法来生成观测序列：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Installing Python packages
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Python 包
- en: 'HMM can also have a Gaussian distribution for the emission probability. Just
    like `MultinomialHMM`, we can also sample from `GaussianHMM`. In the next code
    example, we use the `GaussianHMM` class provided in the `hmmlearn` library to
    see how the samples are generated from this type of model:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: HMM 也可以拥有用于发射概率的高斯分布。就像 `MultinomialHMM` 一样，我们也可以从 `GaussianHMM` 中进行采样。在下一个代码示例中，我们使用
    `hmmlearn` 库提供的 `GaussianHMM` 类，看看如何从这种类型的模型中生成样本：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the Python packages are installed, we can use the following code to generate
    samples from `Gaussian HMM`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了 Python 包，我们可以使用以下代码从 `Gaussian HMM` 生成样本：
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](img/fded911f-78d0-4b3b-a756-2c15392d329b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fded911f-78d0-4b3b-a756-2c15392d329b.png)'
- en: Sampling from an HMM with a four-state latent variable, z, and a Gaussian emission
    model, p(x|z)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从具有四状态潜变量 z 和高斯发射模型 p(x|z) 的 HMM 中进行采样
- en: Evaluation of an HMM
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HMM 的评估
- en: In the previous section, we discussed generating an observation sequence of
    a given HMM. But, in reality, most of the time we are not interested in generating
    the observation sequence, mostly because we don't know the parameters of the HMM
    to generate observations in the first place.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了生成给定 HMM 的观测序列。但是，实际上，大多数时候我们并不关心生成观测序列，主要是因为我们一开始并不知道 HMM 的参数，因此无法生成观测。
- en: 'For a given HMM representation, in most of the applications, we are always
    trying to address the following three problems:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定的 HMM 表示，在大多数应用中，我们总是试图解决以下三个问题：
- en: '**Evaluation of the model**: Given the parameters of the model and the observation
    sequence, estimating the probability of the sequence'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**：给定模型的参数和观测序列，估计该序列的概率'
- en: '**Predicting the optimal sequence**: Given the parameters of the model and
    the observation sequence, estimating the most probable sequence of the state sequence
    that had produced these observations'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测最优序列**：给定模型的参数和观测序列，估计产生这些观测的最可能的状态序列'
- en: '**Parameter-learning**: Given a sequence of observations, estimating the parameters
    of the HMM model that generated it'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数学习**：给定一系列观测，估计生成这些观测的 HMM 模型的参数'
- en: In this section, we'll discuss the first problem, the evaluation of the model,
    and in the following chapters, we will discuss the other two problems in detail.
    As we will see in the later chapters, evaluating the model forms the basis for
    solving the other two problems. Thus, solving this problem efficiently is the
    first stepping stone toward parameter-learning and inference.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论第一个问题，即模型评估，接下来的章节中，我们将详细讨论其他两个问题。正如我们将在后续章节中看到的，评估模型是解决其他两个问题的基础。因此，高效地解决这个问题是迈向参数学习和推理的第一步。
- en: Let's formally describe the problem of model evaluation. Given an HMM parameterized
    by *θ = {A, π, Φ}* and an observation sequence, *X = {x[1], ..., x[N]}*, we need
    to compute the probability of *Pr(X|θ)*. From our discussions in the previous
    section, we can say that we can compute *Pr(X|θ)* by marginalizing the joint-probability
    distribution *Pr(X, Z|θ)*, where *Z = {z[1], ..., z[N]}*, with respect to *Z:*
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们正式描述模型评估问题。给定一个由 *θ = {A, π, Φ}* 参数化的 HMM 和一个观测序列，*X = {x[1], ..., x[N]}*，我们需要计算
    *Pr(X|θ)* 的概率。通过前一节的讨论，我们可以说，我们可以通过边缘化联合概率分布 *Pr(X, Z|θ)* 来计算 *Pr(X|θ)*，其中 *Z
    = {z[1], ..., z[N]}*，对 *Z* 进行边际化：
- en: '![](img/bf84a382-52f0-44a7-8f9b-dbfbf4dfc8fe.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf84a382-52f0-44a7-8f9b-dbfbf4dfc8fe.png)'
- en: 'In the previous section, we saw that the following is true:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们看到以下结论：
- en: '![](img/f3c9df46-6db1-4419-87a4-27c7d9cf0d74.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3c9df46-6db1-4419-87a4-27c7d9cf0d74.png)'
- en: 'Thus the *Pr(X, Z|θ)* probability can be stated as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*Pr(X, Z|θ)* 概率可以表示为如下：
- en: '![](img/14fcbdbb-0a0a-4a54-a16a-4ae0eafe7249.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/14fcbdbb-0a0a-4a54-a16a-4ae0eafe7249.png)'
- en: For a model with *K* states and an observation length of *N*, there are *K^T* possible
    state sequences. Each term in the summation requires *2N* operations. As a result,
    the evaluation becomes a mathematical operation of the order of *2N X K^T*. For
    example, if we consider a model with five states, *K = 5*, and an observation
    sequence of length *N = 100*, the number of required operations is of the order
    of 10^(72), which makes this method of evaluation intractable even for a very
    small HMM.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有 *K* 状态和观测长度 *N* 的模型，有 *K^T* 种可能的状态序列。求和中的每一项需要 *2N* 次运算。因此，评估的复杂度为 *2N
    X K^T* 的数量级。例如，如果我们考虑一个具有五个状态的模型，*K = 5*，并且观测序列的长度为 *N = 100*，则所需的运算次数为 10^(72)
    级别，这使得即使对于一个非常小的HMM，评估方法也变得不可处理。
- en: Extensions of HMM
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HMM的扩展
- en: In the previous sections, we discussed HMM, sampling from it and evaluating
    the probability of a given sequence given its parameters. In this section, we
    are going to discuss some of its variations.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了HMM，从中进行采样并根据其参数评估给定序列的概率。在本节中，我们将讨论它的一些变种。
- en: Factorial HMMs
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因式分解HMM
- en: Let's consider the problem of modelling of several objects in a sequence of
    images. If there are *M* objects with *K* different positions and orientations
    in the image, there are be *K^M* possible states for the system underlying an
    image. An HMM would require *K^M* distinct states to model the system. This way
    of representing the system is not only inefficient but also difficult to interpret.
    We would prefer that our HMM could capture the state space by using *M* different
    *K*-dimensional variables.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑建模一系列图像中多个物体的问题。如果图像中有 *M* 个物体，且每个物体有 *K* 种不同的位置和方向，则该图像背后的系统可能有 *K^M*
    种状态。一个HMM将需要 *K^M* 个不同的状态来建模该系统。这种表示系统的方式不仅效率低，而且难以解释。我们更希望我们的HMM能够通过使用 *M* 个不同的
    *K* 维变量来捕捉状态空间。
- en: 'A factorial HMM is such a representation. In this model, there are multiple
    independent Markov chains of latent variables and the distribution of the observed
    variable at any given time is conditional on the states of all the corresponding
    latent variables in that given time. The graphical model of the system can be
    represented as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因式分解HMM就是这样的一种表示方法。在这个模型中，存在多个独立的马尔可夫链潜在变量，并且在任何给定时间，观测变量的分布都依赖于该时间点所有对应潜在变量的状态。该系统的图形模型可以表示如下：
- en: '![](img/855f8b95-963e-4e71-89ff-1554067981f6.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/855f8b95-963e-4e71-89ff-1554067981f6.png)'
- en: A factorial HMM comprising two Markov chains
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 包含两个马尔可夫链的因式分解HMM
- en: The motivation for considering factorial HMM can be seen by noting that in order
    to represent, say, 10 bits of information at a given time step, a standard HMM
    would need *K = 2^(10) = 1024* latent states, whereas a factorial HMM could make
    use of 10 binary latent chains. However, this presents additional complexity in
    training, as we will see in the later chapters.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑因式分解HMM的动机可以通过注意到，在某一时间步表示10位信息时，标准HMM需要 *K = 2^(10) = 1024* 个潜在状态，而因式分解HMM可以使用10个二进制的潜在链。然而，这会带来额外的训练复杂度，正如我们将在后续章节中看到的那样。
- en: Tree-structured HMM
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树形结构HMM
- en: 'In the previous section, we discussed factorial HMM, in which the latent variables
    formed independent Markov chains. This independence assumption about the latent
    variables can be relaxed by introducing some coupling between them. One way to
    couple latent variables is to order them such that ![](img/5deeb537-39a8-40d7-b5e3-a2170aae1970.png) depends
    on ![](img/22d1629a-e9a1-4f2a-a8cd-32fadc0b78e5.png) for all *1 ≤ l ≤ m*. Furthermore,
    if all the output variables and the latent variables depend on some random input
    variable, *x[n]*, we obtain a tree-structured HMM represented as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了因式分解HMM，其中潜在变量形成独立的马尔可夫链。通过引入潜在变量之间的耦合，可以放宽关于潜在变量的独立性假设。一种耦合潜在变量的方法是将它们排序，使得 ![](img/5deeb537-39a8-40d7-b5e3-a2170aae1970.png) 依赖于 ![](img/22d1629a-e9a1-4f2a-a8cd-32fadc0b78e5.png) 对于所有 *1
    ≤ l ≤ m*。此外，如果所有的输出变量和潜在变量都依赖于某个随机输入变量 *x[n]*，则我们得到一个树形结构的HMM，表示如下：
- en: '![](img/8702cf40-118a-4e62-9291-5358b5805598.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8702cf40-118a-4e62-9291-5358b5805598.png)'
- en: Graphical representation of a tree-structured HMM
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 树形结构HMM的图示表示
- en: The architecture of this model can be interpreted as a probabilistic decision
    tree. Let's considered at first-time slice *n=1*, and try to understand how this
    model would generate data. Based on the value of *x[1]*, the top node, ![](img/e7a75457-434e-4c4a-b294-da1e2f2c5b9c.png),
    can take *K* values (assuming that the hidden variables have *K* states). This
    partitions the *x* space into *K* decision groups. The next node, ![](img/3c6d4a75-fd66-406f-a0fe-b874f461124b.png), further
    partitions into *K* subregions, and so on. The output, *y[1]*, is generated from
    the input, *x[1]*, and K-way decisions at each node. At the next time slice, the
    same thing is going to happen, expect that each decision in the tree depends on
    the decision taken at that node in the previous time slice. Therefore, this model
    can be interpreted as a probabilistic decision tree with Markovian dynamics.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的架构可以解释为一个概率决策树。我们首先考虑时间切片*n=1*，并尝试理解这个模型是如何生成数据的。根据*x[1]*的值，顶节点，![](img/e7a75457-434e-4c4a-b294-da1e2f2c5b9c.png)，可以取*K*个值（假设隐藏变量有*K*个状态）。这将*x*空间划分为*K*个决策组。下一个节点，![](img/3c6d4a75-fd66-406f-a0fe-b874f461124b.png)，进一步划分为*K*个子区域，以此类推。输出，*y[1]*，是由输入*x[1]*和每个节点的K种决策生成的。在下一个时间切片中，同样的事情会发生，只不过树中的每个决策都依赖于前一个时间切片中该节点所做的决策。因此，该模型可以解释为一个具有马尔可夫动态的概率决策树。
- en: Summary
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we got a detailed introduction to Markov model and HMM. We
    talked about parameterizing an HMM, generating samples from it, and their code.
    We discussed estimating the probability of observation, which would form the basis
    of inference, which we'll cover in the next chapter. We also talked about various
    extensions of HMMs.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们详细介绍了马尔可夫模型和HMM。我们讨论了如何对HMM进行参数化，从中生成样本，以及它们的代码。我们讨论了如何估计观测的概率，这将构成推理的基础，下一章我们将讲解这一部分内容。我们还讨论了HMM的各种扩展。
- en: In the next chapter, we will take an in-depth look at inference in HMMs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨HMM中的推理。
