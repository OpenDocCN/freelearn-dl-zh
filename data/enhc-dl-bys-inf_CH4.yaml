- en: ChapterÂ 4
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬4ç« 
- en: Introducing Bayesian Deep Learning
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ä»‹ç»è´å¶æ–¯æ·±åº¦å­¦ä¹ 
- en: In [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002),
    *Fundamentals of* *Bayesian Inference*, we saw how traditional methods for Bayesian
    inference can be used to produce model uncertainty estimates, and we introduced
    the properties of well-calibrated and well-principled methods for uncertainty
    estimation. While these traditional methods are powerful in many applications,
    [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002)
    also highlighted some of their limitations with respect to scaling. In *Chapter
    3,* *Fundamentals of Deep Learning*, we saw the impressive things DNNs are capable
    of given large amounts of data; but we also learned that they arenâ€™t perfect.
    In particular, they often lack robustness for out-of-distribution data â€“ a major
    concern when we consider the deployment of these methods in real-world applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ï¼Œ*è´å¶æ–¯æ¨æ–­åŸºç¡€*ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°ä¼ ç»Ÿçš„è´å¶æ–¯æ¨æ–­æ–¹æ³•å¦‚ä½•ç”¨æ¥äº§ç”Ÿæ¨¡å‹çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶ä»‹ç»äº†è‰¯å¥½æ ¡å‡†å’Œæœ‰åŸåˆ™çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•çš„ç‰¹æ€§ã€‚å°½ç®¡è¿™äº›ä¼ ç»Ÿæ–¹æ³•åœ¨è®¸å¤šåº”ç”¨ä¸­éå¸¸å¼ºå¤§ï¼Œ[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ä¹Ÿçªå‡ºäº†å®ƒä»¬åœ¨æ‰©å±•æ€§æ–¹é¢çš„ä¸€äº›å±€é™æ€§ã€‚åœ¨*ç¬¬3ç« *ï¼Œ*æ·±åº¦å­¦ä¹ åŸºç¡€*ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†DNNsåœ¨å¤§é‡æ•°æ®ä¸‹æ‰€èƒ½å±•ç°çš„ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼›ä½†æˆ‘ä»¬ä¹Ÿäº†è§£åˆ°å®ƒä»¬å¹¶ä¸å®Œç¾ã€‚ç‰¹åˆ«æ˜¯ï¼Œå®ƒä»¬å¾€å¾€ç¼ºä¹å¯¹åˆ†å¸ƒå¤–æ•°æ®çš„é²æ£’æ€§â€”â€”è¿™æ˜¯æˆ‘ä»¬è€ƒè™‘å°†è¿™äº›æ–¹æ³•éƒ¨ç½²åˆ°ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„ä¸€ä¸ªä¸»è¦é—®é¢˜ã€‚
- en: '![PIC](img/file79.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file79.png)'
- en: 'FigureÂ 4.1: BDL combines the strengths of both deep learning and traditional
    Bayesian inference'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4.1ï¼šBDLç»“åˆäº†æ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿè´å¶æ–¯æ¨æ–­çš„ä¼˜åŠ¿
- en: 'BDL looks to ameliorate the shortcomings of both traditional Bayesian inference
    and standard DNNs, using the strengths from one method to address the weaknesses
    of the other. The fundamental idea is pretty straightforward: our DNNs gain uncertainty
    estimates, and so can be implemented more robustly, and our Bayesian inference
    methods gain the scalability and high-dimensional non-linear representation learning
    of DNNs.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: BDLæ—¨åœ¨æ”¹è¿›ä¼ ç»Ÿè´å¶æ–¯æ¨æ–­å’Œæ ‡å‡†DNNçš„ä¸è¶³ï¼Œåˆ©ç”¨ä¸€ç§æ–¹æ³•çš„ä¼˜åŠ¿æ¥å¼¥è¡¥å¦ä¸€ç§æ–¹æ³•çš„ä¸è¶³ã€‚åŸºæœ¬æ€æƒ³ç›¸å½“ç›´æ¥ï¼šæˆ‘ä»¬çš„DNNè·å¾—ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå› æ­¤å¯ä»¥æ›´ç¨³å¥åœ°å®æ–½ï¼Œè€Œæˆ‘ä»¬çš„è´å¶æ–¯æ¨æ–­æ–¹æ³•åˆ™è·å¾—äº†DNNçš„å¯æ‰©å±•æ€§å’Œé«˜ç»´éçº¿æ€§è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ã€‚
- en: While conceptually this is quite intuitive, practically itâ€™s not a case of just
    gluing things together. As the model complexity increases, so does the computational
    cost of Bayesian inference â€“ making certain methods for Bayesian inference (such
    as via sampling) intractable.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ä»æ¦‚å¿µä¸Šè®²ï¼Œè¿™ç›¸å½“ç›´è§‚ï¼Œä½†å®é™…ä¸Šå¹¶ä¸æ˜¯ç®€å•åœ°å°†ä¸¤è€…æ‹¼æ¥åœ¨ä¸€èµ·ã€‚éšç€æ¨¡å‹å¤æ‚æ€§çš„å¢åŠ ï¼Œè´å¶æ–¯æ¨æ–­çš„è®¡ç®—æˆæœ¬ä¹Ÿä¼šå¢åŠ â€”â€”ä½¿å¾—æŸäº›è´å¶æ–¯æ¨æ–­æ–¹æ³•ï¼ˆä¾‹å¦‚é€šè¿‡é‡‡æ ·ï¼‰å˜å¾—ä¸å¯è¡Œã€‚
- en: 'In this chapter, weâ€™ll introduce the concept of an ideal **Bayesian Neural**
    **Network** (**BNN**) and discuss its limitations, and weâ€™ll learn about how we
    can use BNNs to create more robust deep learning systems. In particular, weâ€™ll
    be covering the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç†æƒ³**è´å¶æ–¯ç¥ç»ç½‘ç»œ**ï¼ˆ**BNN**ï¼‰çš„æ¦‚å¿µï¼Œå¹¶è®¨è®ºå…¶å±€é™æ€§ï¼Œæˆ‘ä»¬è¿˜å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨BNNåˆ›å»ºæ›´ç¨³å¥çš„æ·±åº¦å­¦ä¹ ç³»ç»Ÿã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹å†…å®¹ï¼š
- en: The ideal BNN
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç†æƒ³çš„BNN
- en: BDL fundamentals
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BDLåŸºç¡€
- en: Tools for BDL
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BDLå·¥å…·
- en: 4.1 Technical requirements
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 æŠ€æœ¯è¦æ±‚
- en: 'To complete the practical tasks in this chapter, you will need a Python 3.8
    environment with the `SciPy` stack and the following additional Python packages
    installed:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å®Œæˆæœ¬ç« ä¸­çš„å®é™…ä»»åŠ¡ï¼Œæ‚¨éœ€è¦ä¸€ä¸ªå®‰è£…äº†`SciPy`å †æ ˆçš„Python 3.8ç¯å¢ƒï¼Œå¹¶å®‰è£…ä»¥ä¸‹é¢å¤–çš„Pythonè½¯ä»¶åŒ…ï¼š
- en: TensorFlow 2.0
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 2.0
- en: TensorFlow Probability
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlowæ¦‚ç‡
- en: Seaborn plotting library
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Seabornç»˜å›¾åº“
- en: 'All of the code for this book can be found in the GitHub repository for the
    book: [https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦çš„æ‰€æœ‰ä»£ç å¯ä»¥åœ¨ä¹¦ç±çš„GitHubä»“åº“ä¸­æ‰¾åˆ°ï¼š[https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference)ã€‚
- en: 4.2 The ideal BNN
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 ç†æƒ³çš„BNN
- en: As we saw in the previous chapter, a standard neural network comprises multiple
    layers. Each of these layers comprises a number of perceptrons â€“ and these perceptrons
    comprise a multiplicative component (weight) and an additive component (bias).
    Each weight and bias parameter comprises a single parameter â€“ or point estimate
    â€“ and, in combination, these parameters transform the input to the perceptron.
    As weâ€™ve seen, multiple layers of perceptrons are capable of achieving impressive
    feats when trained via backpropagation. However, these point estimates contain
    very limited information â€“ letâ€™s take a look.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€ç« æ‰€çœ‹åˆ°çš„ï¼Œä¸€ä¸ªæ ‡å‡†çš„ç¥ç»ç½‘ç»œç”±å¤šä¸ªå±‚ç»„æˆã€‚æ¯ä¸€å±‚ç”±è‹¥å¹²æ„ŸçŸ¥æœºç»„æˆâ€”â€”è¿™äº›æ„ŸçŸ¥æœºåŒ…å«ä¹˜æ³•ç»„ä»¶ï¼ˆæƒé‡ï¼‰å’ŒåŠ æ³•ç»„ä»¶ï¼ˆåç½®ï¼‰ã€‚æ¯ä¸ªæƒé‡å’Œåç½®å‚æ•°éƒ½æ˜¯å•ä¸€çš„å‚æ•°â€”â€”æˆ–ç‚¹ä¼°è®¡â€”â€”å¹¶ä¸”è¿™äº›å‚æ•°çš„ç»„åˆå°†è¾“å…¥è½¬æ¢ä¸ºæ„ŸçŸ¥æœºçš„è¾“å‡ºã€‚æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œé€šè¿‡åå‘ä¼ æ’­è®­ç»ƒçš„å¤šä¸ªæ„ŸçŸ¥æœºå±‚èƒ½å¤Ÿå®ç°ä»¤äººå°è±¡æ·±åˆ»çš„æˆå°±ã€‚ç„¶è€Œï¼Œè¿™äº›ç‚¹ä¼°è®¡åŒ…å«çš„ä¿¡æ¯éå¸¸æœ‰é™â€”â€”æˆ‘ä»¬æ¥çœ‹çœ‹ã€‚
- en: 'Generally speaking, the goal of deep learning is to find (potentially very,
    very many) parameter values that best map a set of inputs onto a set of outputs.
    That is, given some data, for each parameter in our network, weâ€™ll choose the
    parameter that best describes the data. This often boils down to taking the mean
    â€“ or expectation â€“ of the candidate parameter values. Letâ€™s see what this may
    look like for a single parameter in a neural network:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬è€Œè¨€ï¼Œæ·±åº¦å­¦ä¹ çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ï¼ˆå¯èƒ½éå¸¸éå¸¸å¤šçš„ï¼‰å‚æ•°å€¼ï¼Œæœ€å¥½çš„å°†ä¸€ç»„è¾“å…¥æ˜ å°„åˆ°ä¸€ç»„è¾“å‡ºã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç»™å®šæŸäº›æ•°æ®ï¼Œå¯¹äºç½‘ç»œä¸­çš„æ¯ä¸ªå‚æ•°ï¼Œæˆ‘ä»¬å°†é€‰æ‹©æœ€èƒ½æè¿°æ•°æ®çš„å‚æ•°ã€‚è¿™é€šå¸¸å½’ç»“ä¸ºå–å€™é€‰å‚æ•°å€¼çš„å‡å€¼â€”â€”æˆ–æœŸæœ›å€¼ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™å¯¹äºç¥ç»ç½‘ç»œä¸­çš„å•ä¸€å‚æ•°æ¥è¯´å¯èƒ½æ˜¯ä»€ä¹ˆæ ·çš„ï¼š
- en: '![PIC](img/file80.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file80.png)'
- en: 'FigureÂ 4.2: A table of values illustrating how parameters are averaged in machine
    learning models'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.2ï¼šå±•ç¤ºå¦‚ä½•åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­å¯¹å‚æ•°è¿›è¡Œå¹³å‡çš„æ•°å€¼è¡¨
- en: To understand this better, weâ€™ll use a table to illustrate the relationship
    between input values, model parameters, and output values. The table shows, for
    five example input values (first column), what the ideal parameter (second column)
    would be to obtain the target output value (fourth column). In this context, ideal
    here simply means that the input value multiplied by the ideal parameter will
    exactly equal the target output value. Because we need to find a single value
    that best maps our input data to our output data, we end up taking the expectation
    (or mean) of our ideal parameters.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°ç†è§£è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¡¨æ ¼æ¥è¯´æ˜è¾“å…¥å€¼ã€æ¨¡å‹å‚æ•°å’Œè¾“å‡ºå€¼ä¹‹é—´çš„å…³ç³»ã€‚è¯¥è¡¨æ ¼æ˜¾ç¤ºäº†å¯¹äºäº”ä¸ªç¤ºä¾‹è¾“å…¥å€¼ï¼ˆç¬¬ä¸€åˆ—ï¼‰ï¼Œè·å¾—ç›®æ ‡è¾“å‡ºå€¼ï¼ˆç¬¬å››åˆ—ï¼‰æ‰€éœ€çš„ç†æƒ³å‚æ•°ï¼ˆç¬¬äºŒåˆ—ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç†æƒ³çš„æ„æ€æ˜¯è¾“å…¥å€¼ä¹˜ä»¥ç†æƒ³å‚æ•°å°†å®Œå…¨ç­‰äºç›®æ ‡è¾“å‡ºå€¼ã€‚å› ä¸ºæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³æ˜ å°„è¾“å…¥æ•°æ®åˆ°è¾“å‡ºæ•°æ®çš„å•ä¸€å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ€ç»ˆå–ç†æƒ³å‚æ•°çš„æœŸæœ›ï¼ˆæˆ–å‡å€¼ï¼‰ã€‚
- en: As we see here, taking the mean of these parameters is the compromise our model
    needs to make in order to find a parameter value that best fits all five data
    points in the example. This is the compromise that is made with traditional deep
    learning â€“ by using distributions, rather than point estimates, BDL can improve
    on this. If we look at our standard deviation (*Ïƒ*) values, we get an idea of
    how the variation in the *ideal* parameter values (and thus the variance in the
    input values) translates to a variation in the loss. So, what happens if we have
    a poor selection of parameter values?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œå–è¿™äº›å‚æ•°çš„å‡å€¼æ˜¯æˆ‘ä»¬æ¨¡å‹éœ€è¦åšå‡ºçš„æŠ˜è¡·ï¼Œä»¥æ‰¾åˆ°ä¸€ä¸ªæœ€é€‚åˆç¤ºä¾‹ä¸­äº”ä¸ªæ•°æ®ç‚¹çš„å‚æ•°å€¼ã€‚è¿™æ˜¯ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ‰€åšçš„æŠ˜è¡·â€”â€”é€šè¿‡ä½¿ç”¨åˆ†å¸ƒï¼Œè€Œä¸æ˜¯ç‚¹ä¼°è®¡ï¼ŒBDLèƒ½å¤Ÿåœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ã€‚å¦‚æœæˆ‘ä»¬æŸ¥çœ‹æ ‡å‡†å·®ï¼ˆ*Ïƒ*ï¼‰å€¼ï¼Œæˆ‘ä»¬å¯ä»¥å¤§è‡´äº†è§£ç†æƒ³å‚æ•°å€¼çš„å˜åŒ–ï¼ˆä»è€Œè¾“å…¥å€¼çš„æ–¹å·®ï¼‰å¦‚ä½•è½¬åŒ–ä¸ºæŸå¤±çš„å˜åŒ–ã€‚é‚£ä¹ˆï¼Œå¦‚æœæˆ‘ä»¬é€‰æ‹©äº†ä¸åˆé€‚çš„å‚æ•°å€¼ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ
- en: '![PIC](img/file81.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file81.png)'
- en: 'FigureÂ 4.3: A table of values illustrating how parameter *Ïƒ* increases for
    poor sets of parameters'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.3ï¼šå±•ç¤ºå¦‚ä½•åœ¨å‚æ•°ä¸ç†æƒ³çš„æƒ…å†µä¸‹ï¼Œå‚æ•°*Ïƒ*å€¼å¢å¤§çš„æ•°å€¼è¡¨
- en: 'If we compare *Figure* [*4.2*](#x1-51002r2) and *Figure* [*4.3*](#x1-51004r3),
    we see how a significant variance in parameter values can lead to poorer approximation
    from the model, and that larger *Ïƒ* can be indicative of an error (at least for
    well-calibrated models). While in practice things are a little more complicated,
    what we see here is essentially whatâ€™s happening in every parameter of a deep
    learning model: parameter distributions are distilled down to point estimates,
    losing information in the process. In BDL, weâ€™re interested in harnessing the
    additional information from these parameter distributions, using it for more robust
    training and for the creation of uncertainty-aware models.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æ¯”è¾ƒ[*å›¾4.2*](#x1-51002r2)å’Œ[*å›¾4.3*](#x1-51004r3)ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å‚æ•°å€¼çš„æ˜¾è‘—æ–¹å·®å¦‚ä½•å¯¼è‡´æ¨¡å‹è¿‘ä¼¼åº¦é™ä½ï¼Œè€Œè¾ƒå¤§çš„*Ïƒ*å¯èƒ½è¡¨æ˜æ¨¡å‹å­˜åœ¨è¯¯å·®ï¼ˆè‡³å°‘å¯¹äºç»è¿‡è‰¯å¥½æ ¡å‡†çš„æ¨¡å‹ï¼‰ã€‚è™½ç„¶åœ¨å®é™…ä¸­äº‹æƒ…è¦å¤æ‚ä¸€äº›ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„æœ¬è´¨ä¸Šæ˜¯åœ¨æ¯ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å‚æ•°ä¸­å‘ç”Ÿçš„äº‹æƒ…ï¼šå‚æ•°åˆ†å¸ƒè¢«å‹ç¼©æˆç‚¹ä¼°è®¡ï¼Œè¿‡ç¨‹ä¸­çš„ä¿¡æ¯ä¸¢å¤±ã€‚åœ¨BDLä¸­ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯ä»è¿™äº›å‚æ•°åˆ†å¸ƒä¸­è·å–é¢å¤–ä¿¡æ¯ï¼Œç”¨äºæ›´å¼ºå¥çš„è®­ç»ƒå’Œåˆ›å»ºå…·æœ‰ä¸ç¡®å®šæ€§æ„è¯†çš„æ¨¡å‹ã€‚
- en: BNNs look to achieve this by modeling the distribution over neural network parameters.
    In the ideal case, the BNN would be able to learn any arbitrary distribution for
    every parameter in the network. At inference time, we would sample from the NN
    to obtain a distribution of output values. Using the sampling methods introduced
    in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of* *Bayesian Inference*](CH2.xhtml#x1-250002),
    we would repeat this process until we have obtained a statistically sufficient
    number of samples from which we could assume a good approximation of our output
    distribution. We could then use this output distribution to infer something about
    our input data, whether that be classifying speech content or performing regression
    on house prices.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: BNNsé€šè¿‡å¯¹ç¥ç»ç½‘ç»œå‚æ•°çš„åˆ†å¸ƒå»ºæ¨¡æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼ŒBNNèƒ½å¤Ÿå­¦ä¹ æ¯ä¸ªç½‘ç»œå‚æ•°çš„ä»»æ„åˆ†å¸ƒã€‚åœ¨æ¨ç†æ—¶ï¼Œæˆ‘ä»¬å°†ä»ç¥ç»ç½‘ç»œä¸­é‡‡æ ·ï¼Œè·å¾—è¾“å‡ºå€¼çš„åˆ†å¸ƒã€‚åˆ©ç”¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ä¸­ä»‹ç»çš„é‡‡æ ·æ–¹æ³•ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ï¼Œæˆ‘ä»¬å°†é‡å¤è¿™ä¸€è¿‡ç¨‹ï¼Œç›´åˆ°è·å¾—è¶³å¤Ÿæ•°é‡çš„æ ·æœ¬ï¼Œä»è€Œèƒ½å¤Ÿå‡è®¾æˆ‘ä»¬çš„è¾“å‡ºåˆ†å¸ƒå·²å¾—åˆ°å¾ˆå¥½çš„è¿‘ä¼¼ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸ªè¾“å‡ºåˆ†å¸ƒæ¨æ–­è¾“å…¥æ•°æ®çš„æŸäº›ç‰¹å¾ï¼Œæ— è®ºæ˜¯åˆ†ç±»è¯­éŸ³å†…å®¹è¿˜æ˜¯å¯¹æˆ¿ä»·è¿›è¡Œå›å½’åˆ†æã€‚
- en: 'Because weâ€™d have parameter distributions, rather than point estimates, our
    ideal BNN would produce precise uncertainty estimates. These would tell us how
    likely the parameter values are given the input data. In doing so, they would
    allow us to detect cases where our input data deviates from the data seen at training
    time, and to quantify the degree of this deviation by how far a given sample of
    values lies from the distribution learned at training time. With this information,
    we would be able to handle our neural network outputs more intelligently â€“ for
    example, if theyâ€™re highly uncertain, then we could fall back to some safe, pre-defined
    behavior. This concept of interpreting model predictions based on uncertainties
    should be familiar: we saw this in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals
    of Bayesian Inference*](CH2.xhtml#x1-250002), where we learned that high uncertainties
    are indicative of erroneous model predictions.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬ä¼šæœ‰å‚æ•°åˆ†å¸ƒï¼Œè€Œä¸æ˜¯ç‚¹ä¼°è®¡ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ç†æƒ³BNNå°†æä¾›ç²¾ç¡®çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚è¿™äº›ä¼°è®¡å°†å‘Šè¯‰æˆ‘ä»¬ç»™å®šè¾“å…¥æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå‚æ•°å€¼çš„å¯èƒ½æ€§æœ‰å¤šå¤§ã€‚è¿™æ ·ï¼Œå®ƒä»¬å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ£€æµ‹è¾“å…¥æ•°æ®ä¸è®­ç»ƒæ—¶æ•°æ®çš„åç¦»æƒ…å†µï¼Œå¹¶é€šè¿‡ç»™å®šæ ·æœ¬å€¼ä¸è®­ç»ƒæ—¶å­¦ä¹ åˆ°çš„åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚é‡åŒ–è¿™ç§åå·®çš„ç¨‹åº¦ã€‚æœ‰äº†è¿™äº›ä¿¡æ¯ï¼Œæˆ‘ä»¬å°±èƒ½æ›´æ™ºèƒ½åœ°å¤„ç†ç¥ç»ç½‘ç»œçš„è¾“å‡ºâ€”â€”ä¾‹å¦‚ï¼Œå¦‚æœè¾“å‡ºçš„ä¸ç¡®å®šæ€§å¾ˆé«˜ï¼Œæˆ‘ä»¬å¯ä»¥å›é€€åˆ°ä¸€äº›å®‰å…¨çš„ã€é¢„å®šä¹‰çš„è¡Œä¸ºã€‚è¿™ç§åŸºäºä¸ç¡®å®šæ€§æ¥è§£è¯»æ¨¡å‹é¢„æµ‹çš„æ¦‚å¿µåº”è¯¥å¾ˆç†Ÿæ‚‰ï¼šæˆ‘ä»¬åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ä¸­å­¦åˆ°ï¼Œé«˜ä¸ç¡®å®šæ€§è¡¨æ˜æ¨¡å‹é¢„æµ‹å­˜åœ¨è¯¯å·®ã€‚
- en: Looking back to [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian
    Inference*](CH2.xhtml#x1-250002) again, we saw that sampling quickly becomes computationally
    intensive. Now imagine sampling from a distribution for each parameter in an NN
    â€“ even if we take a relatively small network such as MobileNet (an architecture
    specifically designed to be more computationally efficient), weâ€™re still looking
    at an enormous 4.2 million parameters. Performing this kind of sampling-based
    inference on such a network would be incredibly computationally intensive, and
    this would be even worse for other network architectures (for example, AlexNet
    has 60 million parameters!).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å›é¡¾[*ç¬¬äºŒç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ï¼Œæˆ‘ä»¬çœ‹åˆ°é‡‡æ ·å¾ˆå¿«å˜å¾—è®¡ç®—ä¸Šä¸å¯è¡Œã€‚ç°åœ¨ï¼Œå‡è®¾ä»æ¯ä¸ªç¥ç»ç½‘ç»œå‚æ•°çš„åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·â€”â€”å³ä½¿æˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„ç½‘ç»œï¼Œå¦‚
    MobileNetï¼ˆä¸€ç§ä¸“é—¨è®¾è®¡ä»¥æé«˜è®¡ç®—æ•ˆç‡çš„æ¶æ„ï¼‰ï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦å¤„ç†å¤šè¾¾ 420 ä¸‡ä¸ªå‚æ•°ã€‚å¯¹è¿™æ ·çš„ç½‘ç»œè¿›è¡ŒåŸºäºé‡‡æ ·çš„æ¨æ–­å°†éå¸¸è®¡ç®—å¯†é›†ï¼Œè€Œå¯¹äºå…¶ä»–ç½‘ç»œæ¶æ„ï¼Œè¿™ç§æƒ…å†µä¼šæ›´åŠ ç³Ÿç³•ï¼ˆä¾‹å¦‚ï¼ŒAlexNet
    æœ‰ 6000 ä¸‡ä¸ªå‚æ•°ï¼ï¼‰ã€‚
- en: Because of this intractability, BDL methods make use of various approximations
    in order to facilitate uncertainty quantification. In the next section, weâ€™ll
    learn about some of the fundamental principles applied to make uncertainty estimates
    possible with DNNs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè¿™ç§ä¸å¯è¡Œæ€§ï¼ŒBDL æ–¹æ³•é‡‡ç”¨äº†å„ç§è¿‘ä¼¼æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›ä¸ç¡®å®šæ€§é‡åŒ–ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£ä¸€äº›åŸºæœ¬åŸç†ï¼Œè¿™äº›åŸç†è¢«åº”ç”¨äºä½¿å¾—ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰è¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡æˆä¸ºå¯èƒ½ã€‚
- en: 4.3 BDL fundamentals
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 BDL åŸºç¡€
- en: Throughout the rest of the book, we will introduce a range of methods necessary
    to make BDL possible. There are a number of common themes present through these
    methods. Weâ€™ll cover these here, so that we have a good understanding of these
    concepts when we encounter them later on.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¹¦çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä½¿å¾— BDL æˆä¸ºå¯èƒ½çš„ä¸€ç³»åˆ—æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•ä¸­æœ‰è®¸å¤šå…±åŒçš„ä¸»é¢˜ã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œè¦†ç›–è¿™äº›å†…å®¹ï¼Œä»¥ä¾¿åœ¨ç¨åé‡åˆ°æ—¶èƒ½å¤Ÿå¾ˆå¥½åœ°ç†è§£è¿™äº›æ¦‚å¿µã€‚
- en: 'These concepts include the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ¦‚å¿µåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
- en: '**Gaussian assumptions**: With many BDL methods, we use Gaussian assumptions
    to make things computationally tractable'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é«˜æ–¯å‡è®¾**ï¼šè®¸å¤š BDL æ–¹æ³•ä½¿ç”¨é«˜æ–¯å‡è®¾æ¥ä½¿è®¡ç®—å˜å¾—å¯è¡Œã€‚'
- en: '**Uncertainty sources**: Weâ€™ll take a look at the different sources of uncertainty,
    and how we can determine the contributions of these sources for some BDL methods'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸ç¡®å®šæ€§æ¥æº**ï¼šæˆ‘ä»¬å°†æŸ¥çœ‹ä¸åŒçš„ä¸ç¡®å®šæ€§æ¥æºï¼Œå¹¶äº†è§£å¦‚ä½•ç¡®å®šè¿™äº›æ¥æºåœ¨æŸäº› BDL æ–¹æ³•ä¸­çš„è´¡çŒ®ã€‚'
- en: '**Likelihoods**: We were introduced to likelihoods in [*ChapterÂ 2*](CH2.xhtml#x1-250002),
    [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002), and here weâ€™ll learn
    more about the importance of likelihood as a metric for evaluating the calibration
    of probabilistic models'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¼¼ç„¶**ï¼šæˆ‘ä»¬åœ¨[*ç¬¬äºŒç« *](CH2.xhtml#x1-250002)å’Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ä¸­ä»‹ç»äº†ä¼¼ç„¶ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥äº†è§£ä¼¼ç„¶ä½œä¸ºè¯„ä¼°æ¦‚ç‡æ¨¡å‹æ ¡å‡†çš„åº¦é‡æ ‡å‡†çš„é‡è¦æ€§ã€‚'
- en: Letâ€™s look at each of these in the following subsections.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥æˆ‘ä»¬å°†æŸ¥çœ‹ä»¥ä¸‹å°èŠ‚ä¸­çš„æ¯ä¸ªé—®é¢˜ã€‚
- en: 4.3.1 Gaussian assumptions
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 é«˜æ–¯å‡è®¾
- en: 'In the ideal case described previously, we talked about learning distributions
    for each neural network parameter. While realistically each parameter would follow
    a specific non-Gaussian distribution, this would make an already difficult problem
    even *more* difficult. This is because, for a BNN, weâ€™re interested in learning
    two key probabilities:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰é¢æè¿°çš„ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸ºæ¯ä¸ªç¥ç»ç½‘ç»œå‚æ•°å­¦ä¹ åˆ†å¸ƒã€‚å®é™…ä¸Šï¼Œè™½ç„¶æ¯ä¸ªå‚æ•°å°†éµå¾ªç‰¹å®šçš„éé«˜æ–¯åˆ†å¸ƒï¼Œä½†è¿™å°†ä½¿æœ¬å·²å›°éš¾çš„é—®é¢˜å˜å¾—æ›´åŠ *å¤æ‚*ã€‚è¿™æ˜¯å› ä¸ºï¼Œå¯¹äºè´å¶æ–¯ç¥ç»ç½‘ç»œï¼ˆBNNï¼‰ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯å­¦ä¹ ä¸¤ä¸ªå…³é”®æ¦‚ç‡ï¼š
- en: 'The probability of the weights *W* given some data *D*:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šæŸäº›æ•°æ® *D*ï¼Œæƒé‡ *W* çš„æ¦‚ç‡ï¼š
- en: '![P (W |D ) ](img/file82.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![P (W |D)](img/file82.jpg)'
- en: 'The probability of some output *Å·* given some input **x**:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šæŸäº›è¾“å…¥ **x**ï¼Œè¾“å‡º *Å·* çš„æ¦‚ç‡ï¼š
- en: '![P (yË†|x) ](img/file83.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![P (yË†|x)](img/file83.jpg)'
- en: Obtaining these probabilities for arbitrary probability distributions would
    involve solving intractable integrals. Gaussian integrals, on the other hand,
    have closed-form solutions â€“ making them a very popular choice for approximating
    distributions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä»»æ„æ¦‚ç‡åˆ†å¸ƒï¼Œè·å¾—è¿™äº›æ¦‚ç‡éœ€è¦æ±‚è§£æ— æ³•æ±‚è§£çš„ç§¯åˆ†ã€‚è€Œé«˜æ–¯ç§¯åˆ†æœ‰å°é—­è§£â€”â€”ä½¿å¾—å®ƒä»¬æˆä¸ºè¿‘ä¼¼åˆ†å¸ƒæ—¶çš„éå¸¸æµè¡Œçš„é€‰æ‹©ã€‚
- en: 'For this reason, itâ€™s common in BDL to assume that we can closely approximate
    the true underlying distribution of our weights with Gaussian distributions (similarly
    to what weâ€™ve seen in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian
    Inference*](CH2.xhtml#x1-250002)). Letâ€™s see what this would look like â€“ taking
    our typical linear perceptron model:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨è´å¶æ–¯æ·±åº¦å­¦ä¹ ï¼ˆBDLï¼‰ä¸­ï¼Œå‡è®¾æˆ‘ä»¬å¯ä»¥ç”¨é«˜æ–¯åˆ†å¸ƒè¿‘ä¼¼æˆ‘ä»¬æƒé‡çš„çœŸå®åº•å±‚åˆ†å¸ƒæ˜¯å¾ˆå¸¸è§çš„ï¼ˆè¿™ä¸æˆ‘ä»¬åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨ç†åŸºç¡€*](CH2.xhtml#x1-250002)ä¸­çœ‹åˆ°çš„ç±»ä¼¼ï¼‰ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¼šæ˜¯ä»€ä¹ˆæ ·å­â€”â€”ä»¥æˆ‘ä»¬å…¸å‹çš„çº¿æ€§æ„ŸçŸ¥æœºæ¨¡å‹ä¸ºä¾‹ï¼š
- en: '![z = f(x) = Î²X + Î¾ ](img/file84.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![z = f(x) = Î²X + Î¾ ](img/file84.jpg)'
- en: 'Here, *x* is our input to the perceptron, *Î²* is our learned weight value,
    *Î¾* is our learned bias value, and *z* is the value that is returned (typically
    passed to the next layer). With a Bayesian approach, we turn our parameters *Î²*
    and *Î¾* into distributions, rather than point estimates, such that:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ*x* æ˜¯æˆ‘ä»¬è¾“å…¥åˆ°æ„ŸçŸ¥æœºçš„å€¼ï¼Œ*Î²* æ˜¯æˆ‘ä»¬å­¦ä¹ åˆ°çš„æƒé‡å€¼ï¼Œ*Î¾* æ˜¯æˆ‘ä»¬å­¦ä¹ åˆ°çš„åç½®å€¼ï¼Œè€Œ *z* æ˜¯è¿”å›çš„å€¼ï¼ˆé€šå¸¸ä¼ é€’ç»™ä¸‹ä¸€å±‚ï¼‰ã€‚é‡‡ç”¨è´å¶æ–¯æ–¹æ³•ï¼Œæˆ‘ä»¬å°†
    *Î²* å’Œ *Î¾* è½¬æ¢ä¸ºåˆ†å¸ƒï¼Œè€Œä¸æ˜¯ç‚¹ä¼°è®¡ï¼Œå…·ä½“æ¥è¯´ï¼š
- en: '![Î² â‰ˆ ğ’© (Î¼ Î²,ÏƒÎ²) ](img/file85.jpg)![Î¾ â‰ˆ ğ’© (Î¼ Î¾,ÏƒÎ¾) ](img/file86.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Î² â‰ˆ ğ’© (Î¼ Î²,ÏƒÎ²) ](img/file85.jpg)![Î¾ â‰ˆ ğ’© (Î¼ Î¾,ÏƒÎ¾) ](img/file86.jpg)'
- en: 'The learning process would now involve learning four parameters instead of
    two, as each Gaussian is described by two parameters: the mean (*Î¼*) and standard
    deviation (*Ïƒ*). Doing this for each perceptron in our neural network, we end
    up doubling the number of parameters we need to learn â€“ we can see this illustrated,
    starting with *Figure* [*4.4*](#x1-53005r4):'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å­¦ä¹ è¿‡ç¨‹å°†æ¶‰åŠå­¦ä¹ å››ä¸ªå‚æ•°ï¼Œè€Œä¸æ˜¯ä¸¤ä¸ªï¼Œå› ä¸ºæ¯ä¸ªé«˜æ–¯åˆ†å¸ƒç”±ä¸¤ä¸ªå‚æ•°æè¿°ï¼šå‡å€¼ï¼ˆ*Î¼*ï¼‰å’Œæ ‡å‡†å·®ï¼ˆ*Ïƒ*ï¼‰ã€‚å¯¹æˆ‘ä»¬ç¥ç»ç½‘ç»œä¸­çš„æ¯ä¸ªæ„ŸçŸ¥æœºæ‰§è¡Œæ­¤æ“ä½œåï¼Œæˆ‘ä»¬æœ€ç»ˆéœ€è¦å­¦ä¹ çš„å‚æ•°æ•°é‡ç¿»å€â€”â€”æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»*å›¾
    4.4*ï¼ˆ[*Figure*](#x1-53005r4)ï¼‰å¼€å§‹çœ‹åˆ°è¿™ä¸€ç‚¹ï¼š
- en: '![PIC](img/DNN-standard.JPG)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/DNN-standard.JPG)'
- en: 'FigureÂ 4.4: An illustration of a standard DNN'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.4ï¼šæ ‡å‡†DNNçš„ç¤ºæ„å›¾
- en: 'Introducing one-dimensional Gaussian distributions for our weights, our network
    becomes as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¼•å…¥ä¸€ç»´é«˜æ–¯åˆ†å¸ƒä½œä¸ºæˆ‘ä»¬çš„æƒé‡åï¼Œç½‘ç»œå˜ä¸ºå¦‚ä¸‹ï¼š
- en: '![PIC](img/DNN-bayesian.JPG)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/DNN-bayesian.JPG)'
- en: 'FigureÂ 4.5: An illustration of a BNN with Gaussian priors over the weights'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.5ï¼šå¸¦æœ‰é«˜æ–¯å…ˆéªŒçš„è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ˆBNNï¼‰ç¤ºæ„å›¾
- en: In *Chapter 5, Principled Approaches for Bayesian Deep Learning*, weâ€™ll see
    methods that do exactly this. While this does increase the computational complexity
    and memory footprint of our network, it makes the process of Bayesian inference
    with NNs manageable â€“ making it a very worthwhile trade-off.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬5ç« ï¼Œè´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸåˆ™æ–¹æ³•*ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°æ­£æ˜¯è¿™äº›æ–¹æ³•ã€‚è™½ç„¶è¿™ç¡®å®å¢åŠ äº†ç½‘ç»œçš„è®¡ç®—å¤æ‚æ€§å’Œå†…å­˜å ç”¨ï¼Œä½†å®ƒä½¿å¾—é€šè¿‡ç¥ç»ç½‘ç»œè¿›è¡Œè´å¶æ–¯æ¨ç†æˆä¸ºå¯èƒ½â€”â€”è¿™ä½¿å¾—å®ƒæˆä¸ºä¸€ä¸ªéå¸¸å€¼å¾—çš„æƒè¡¡ã€‚
- en: So, what is it weâ€™re actually trying to capture in these uncertainty estimates?
    In [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002),
    we saw how uncertainty varies according to the sample of data used for training
    â€“ but what are the sources of this uncertainty, and why is it important in deep
    learning applications? Letâ€™s continue on to the next section to find out.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å®é™…ä¸Šæƒ³è¦åœ¨è¿™äº›ä¸ç¡®å®šæ€§ä¼°è®¡ä¸­æ•è·ä»€ä¹ˆå‘¢ï¼Ÿåœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨ç†åŸºç¡€*](CH2.xhtml#x1-250002)ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸ç¡®å®šæ€§æ˜¯å¦‚ä½•æ ¹æ®ç”¨äºè®­ç»ƒçš„æ•°æ®æ ·æœ¬è€Œå˜åŒ–çš„â€”â€”ä½†æ˜¯è¿™ç§ä¸ç¡®å®šæ€§çš„æ¥æºæ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå®ƒåœ¨æ·±åº¦å­¦ä¹ åº”ç”¨ä¸­å¾ˆé‡è¦ï¼Ÿè®©æˆ‘ä»¬ç»§ç»­å¾€ä¸‹çœ‹ï¼Œæ‰¾å‡ºç­”æ¡ˆã€‚
- en: 4.3.2 Sources of uncertainty
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2 ä¸ç¡®å®šæ€§çš„æ¥æº
- en: 'As we saw in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian
    Inference*](CH2.xhtml#x1-250002), and as weâ€™ll see later on in the book, we typically
    deal with uncertainties as scalar variables associated with a parameter or output.
    These variables represent the variation in the parameter or output of interest,
    but while they are just scalar variables, there are multiple sources contributing
    to their values. These sources of uncertainty fall into two categories:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨ç†åŸºç¡€*](CH2.xhtml#x1-250002)ä¸­çœ‹åˆ°çš„ï¼Œæ­£å¦‚æˆ‘ä»¬å°†åœ¨æœ¬ä¹¦åç»­ç« èŠ‚ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬é€šå¸¸å°†ä¸ç¡®å®šæ€§è§†ä¸ºä¸æŸä¸ªå‚æ•°æˆ–è¾“å‡ºç›¸å…³çš„æ ‡é‡å˜é‡ã€‚è¿™äº›å˜é‡è¡¨ç¤ºå‚æ•°æˆ–è¾“å‡ºçš„å˜åŒ–ï¼Œä½†å°½ç®¡å®ƒä»¬åªæ˜¯æ ‡é‡å˜é‡ï¼Œä½†æœ‰å¤šä¸ªæ¥æºå¯¹å®ƒä»¬çš„å€¼äº§ç”Ÿå½±å“ã€‚è¿™äº›ä¸ç¡®å®šæ€§çš„æ¥æºå¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼š
- en: '**Aleatoric uncertainty**, otherwise known as observational uncertainty or
    data uncertainty, is the uncertainty associated with our inputs. It describes
    the variation in our **observations**, and as such is **irreducible**.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¶ç„¶æ€§ä¸ç¡®å®šæ€§**ï¼Œä¹Ÿç§°ä¸ºè§‚æµ‹ä¸ç¡®å®šæ€§æˆ–æ•°æ®ä¸ç¡®å®šæ€§ï¼Œæ˜¯ä¸è¾“å…¥ç›¸å…³çš„ä¸ç¡®å®šæ€§ã€‚å®ƒæè¿°äº†æˆ‘ä»¬**è§‚æµ‹å€¼**çš„å˜åŒ–ï¼Œå› æ­¤æ˜¯**ä¸å¯çº¦çš„**ã€‚'
- en: '**Epistemic uncertainty**, otherwise known as model uncertainty, is the uncertainty
    that stems from our model. In the case of machine learning, this is the variance
    associated with the parameters of our model that *does not* stem from the observations,
    and is instead a product of the model, or how the model is trained. For example,
    in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002),
    we saw how different priors affected the uncertainty produced by Gaussian processes.
    This is an example of how model parameters influence the epistemic uncertainty
    â€“ in this case, because they explicitly modify how the model interprets the relationship
    between different data points.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®¤çŸ¥ä¸ç¡®å®šæ€§**ï¼Œä¹Ÿç§°ä¸ºæ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œæ˜¯æºäºæˆ‘ä»¬æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œè¿™æŒ‡çš„æ˜¯ä¸æˆ‘ä»¬æ¨¡å‹çš„å‚æ•°ç›¸å…³çš„æ–¹å·®ï¼Œå®ƒ*å¹¶é*æ¥æºäºè§‚å¯Ÿï¼Œè€Œæ˜¯æ¨¡å‹æœ¬èº«æˆ–æ¨¡å‹çš„è®­ç»ƒæ–¹å¼çš„äº§ç‰©ã€‚ä¾‹å¦‚ï¼Œåœ¨[*ç¬¬
    2 ç« *](CH2.xhtml#x1-250002)ã€Š[*è´å¶æ–¯æ¨ç†åŸºç¡€*](CH2.xhtml#x1-250002)ã€‹ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°ä¸åŒçš„å…ˆéªŒå¦‚ä½•å½±å“é«˜æ–¯è¿‡ç¨‹äº§ç”Ÿçš„ä¸ç¡®å®šæ€§ã€‚è¿™æ˜¯æ¨¡å‹å‚æ•°å¦‚ä½•å½±å“è®¤çŸ¥ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªä¾‹å­â€”â€”åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå› ä¸ºå®ƒä»¬æ˜ç¡®åœ°ä¿®æ”¹äº†æ¨¡å‹å¯¹ä¸åŒæ•°æ®ç‚¹ä¹‹é—´å…³ç³»çš„è§£é‡Šã€‚'
- en: 'We can build an intuition of these concepts through some simple examples. Letâ€™s
    say we have a basket of fruit containing apples and bananas. If we measure the
    height and length of some apples and bananas, weâ€™ll see that apples are generally
    round, and that bananas are generally long, as illustrated in *Figure* [*4.6*](#x1-54010r6).
    We know from our observations that the exact dimensions of each fruit varies:
    we accept that there is randomness, or stochasticity, associated with the measurements
    of any given distribution of apples, but we know that they will all be roughly
    similar. This is the **irreducible uncertainty**: the inherent uncertainty in
    the data.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›ç®€å•çš„ä¾‹å­æ¥å»ºç«‹å¯¹è¿™äº›æ¦‚å¿µçš„ç›´è§‰ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ç¯®æ°´æœï¼Œå…¶ä¸­åŒ…å«è‹¹æœå’Œé¦™è•‰ã€‚å¦‚æœæˆ‘ä»¬æµ‹é‡ä¸€äº›è‹¹æœå’Œé¦™è•‰çš„é«˜åº¦å’Œé•¿åº¦ï¼Œæˆ‘ä»¬ä¼šå‘ç°è‹¹æœé€šå¸¸æ˜¯åœ†å½¢çš„ï¼Œè€Œé¦™è•‰é€šå¸¸æ˜¯é•¿çš„ï¼Œå¦‚*å›¾*
    [*4.6*](#x1-54010r6)æ‰€ç¤ºã€‚é€šè¿‡è§‚å¯Ÿæˆ‘ä»¬çŸ¥é“ï¼Œæ¯ç§æ°´æœçš„å…·ä½“å°ºå¯¸ä¼šæœ‰æ‰€ä¸åŒï¼šæˆ‘ä»¬æ¥å—ä¸ä»»ä½•ç»™å®šçš„è‹¹æœåˆ†å¸ƒçš„æµ‹é‡ç›¸å…³çš„éšæœºæ€§æˆ–éšæœºæ€§ï¼Œä½†æˆ‘ä»¬çŸ¥é“å®ƒä»¬å¤§è‡´ç›¸ä¼¼ã€‚è¿™å°±æ˜¯**ä¸å¯å‡å°‘çš„ä¸ç¡®å®šæ€§**ï¼šæ•°æ®ä¸­çš„å›ºæœ‰ä¸ç¡®å®šæ€§ã€‚
- en: '![PIC](img/aleatoric-uncertainty-illustration.JPG)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/aleatoric-uncertainty-illustration.JPG)'
- en: 'FigureÂ 4.6: An illustration of aleatoric uncertainty, using fruit shapes as
    an example'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.6ï¼šä½¿ç”¨æ°´æœå½¢çŠ¶ä½œä¸ºç¤ºä¾‹çš„å¶ç„¶ä¸ç¡®å®šæ€§çš„æ’å›¾
- en: We can make use of this information to build a model to classify fruit as either
    apples or bananas according to these input features. But what happens if we mainly
    train our model on apples, with only a few measurements for bananas? This is illustrated
    in *Figure* [*4.7*](#x1-54013r7).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œæ ¹æ®è¿™äº›è¾“å…¥ç‰¹å¾å°†æ°´æœåˆ†ç±»ä¸ºè‹¹æœæˆ–é¦™è•‰ã€‚ä½†å¦‚æœæˆ‘ä»¬ä¸»è¦åŸºäºè‹¹æœæ¥è®­ç»ƒæ¨¡å‹ï¼Œè€Œåªæœ‰å°‘é‡é¦™è•‰çš„æµ‹é‡æ•°æ®ä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿè¿™åœ¨*å›¾*
    [*4.7*](#x1-54013r7)ä¸­æœ‰ç¤ºä¾‹ã€‚
- en: '![PIC](img/epistemic-uncertainty-illustration.JPG)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/epistemic-uncertainty-illustration.JPG)'
- en: 'FigureÂ 4.7: An illustration of high epistemic uncertainty based on our fruit
    example'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.7ï¼šåŸºäºæ°´æœç¤ºä¾‹çš„é«˜è®¤çŸ¥ä¸ç¡®å®šæ€§çš„æ’å›¾
- en: 'Here, we see that â€“ because of limited data â€“ our model has incorrectly classified
    bananas as apples. While these data points fall within our modelâ€™s `apple` boundary,
    we also see that they lie very far from the other apples, meaning that, although
    theyâ€™re classified as apples, our model (if itâ€™s Bayesian) will have a high predictive
    uncertainty associated with these data points. This epistemic uncertainty is very
    useful in practical applications: it gives us an indication of when we can trust
    our model, and when we should be cautious about our modelâ€™s predictions. Unlike
    aleatoric uncertainty, epistemic uncertainty is **reducible** â€“ if we give our
    model more examples of bananas, its class boundaries will improve, and the epistemic
    uncertainty will approach the aleatoric uncertainty.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°â€”â€”ç”±äºæ•°æ®æœ‰é™â€”â€”æˆ‘ä»¬çš„æ¨¡å‹é”™è¯¯åœ°å°†é¦™è•‰åˆ†ç±»ä¸ºè‹¹æœã€‚è™½ç„¶è¿™äº›æ•°æ®ç‚¹è½åœ¨æˆ‘ä»¬æ¨¡å‹çš„`è‹¹æœ`è¾¹ç•Œå†…ï¼Œä½†æˆ‘ä»¬ä¹Ÿçœ‹åˆ°å®ƒä»¬ç¦»å…¶ä»–è‹¹æœéå¸¸è¿œï¼Œè¿™æ„å‘³ç€ï¼Œå°½ç®¡å®ƒä»¬è¢«åˆ†ç±»ä¸ºè‹¹æœï¼Œä½†æˆ‘ä»¬çš„æ¨¡å‹ï¼ˆå¦‚æœæ˜¯è´å¶æ–¯æ¨¡å‹ï¼‰ä¼šå¯¹è¿™äº›æ•°æ®ç‚¹å…·æœ‰è¾ƒé«˜çš„é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚è¿™ç§è®¤çŸ¥ä¸ç¡®å®šæ€§åœ¨å®é™…åº”ç”¨ä¸­éå¸¸æœ‰ç”¨ï¼šå®ƒèƒ½å‘Šè¯‰æˆ‘ä»¬ä½•æ—¶å¯ä»¥ä¿¡ä»»æ¨¡å‹ï¼Œä½•æ—¶æˆ‘ä»¬åº”è¯¥å¯¹æ¨¡å‹çš„é¢„æµ‹ä¿æŒè°¨æ…ã€‚ä¸å¶ç„¶ä¸ç¡®å®šæ€§ä¸åŒï¼Œè®¤çŸ¥ä¸ç¡®å®šæ€§æ˜¯**å¯å‡å°‘**çš„â€”â€”å¦‚æœæˆ‘ä»¬ç»™æ¨¡å‹æ›´å¤šçš„é¦™è•‰ç¤ºä¾‹ï¼Œå®ƒçš„åˆ†ç±»è¾¹ç•Œä¼šæ”¹å–„ï¼Œè®¤çŸ¥ä¸ç¡®å®šæ€§å°†æ¥è¿‘å¶ç„¶ä¸ç¡®å®šæ€§ã€‚
- en: '![PIC](img/epistemic-uncertainty-illustration2.JPG)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/epistemic-uncertainty-illustration2.JPG)'
- en: 'FigureÂ 4.8: Illustration of low epistemic uncertainty'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.8ï¼šä½è®¤çŸ¥ä¸ç¡®å®šæ€§çš„æ’å›¾
- en: In *Figure* [*4.8*](#x1-54016r8), we see that the epistemic uncertainty has
    reduced significantly now that our model has observed more data, and itâ€™s looking
    a lot more like the aleatoric uncertainty illustrated in *Figure* [*4.6*](#x1-54010r6).
    Epistemic uncertainty is therefore incredibly useful, both for indicating how
    much we can trust our model, and as a means of improving our modelâ€™s performance.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*å›¾*[*4.8*](#x1-54016r8)ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œéšç€æˆ‘ä»¬çš„æ¨¡å‹è§‚å¯Ÿåˆ°æ›´å¤šæ•°æ®ï¼Œè®¤è¯†ä¸ç¡®å®šæ€§æ˜¾è‘—å‡å°‘ï¼Œå®ƒç°åœ¨çœ‹èµ·æ¥æ›´åƒæ˜¯*å›¾*[*4.6*](#x1-54010r6)ä¸­å±•ç¤ºçš„éšæœºä¸ç¡®å®šæ€§ã€‚å› æ­¤ï¼Œè®¤è¯†ä¸ç¡®å®šæ€§åœ¨ä¸¤æ–¹é¢éƒ½æå…¶æœ‰ç”¨ï¼šå®ƒä¸ä»…èƒ½æŒ‡ç¤ºæˆ‘ä»¬å¯ä»¥å¤šå¤§ç¨‹åº¦ä¸Šä¿¡ä»»æ¨¡å‹ï¼Œè€Œä¸”è¿˜èƒ½ä½œä¸ºæé«˜æ¨¡å‹æ€§èƒ½çš„ä¸€ç§æ‰‹æ®µã€‚
- en: 'As deep learning approaches are increasingly applied in mission-critical and
    safety-critical applications, itâ€™s crucial that the methods we use can estimate
    the degree of epistemic uncertainty associated with their predictions. To illustrate
    this, letâ€™s change the domain of our example from *Figure* [*4.7*](#x1-54013r7):
    instead of classifying fruit, weâ€™re now classifying whether a jet engine is operating
    within safe parameters, as shown in *Figure* [*4.9*](#x1-54019r9).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æ·±åº¦å­¦ä¹ æ–¹æ³•è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºä»»åŠ¡å…³é”®å’Œå®‰å…¨å…³é”®çš„åº”ç”¨ï¼Œä½¿ç”¨çš„æ–¹æ³•èƒ½å¤Ÿä¼°è®¡ä¸å…¶é¢„æµ‹ç›¸å…³çš„è®¤è¯†ä¸ç¡®å®šæ€§çš„ç¨‹åº¦å˜å¾—è‡³å…³é‡è¦ã€‚ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬å°†ç¤ºä¾‹çš„é¢†åŸŸä»*å›¾*[*4.7*](#x1-54013r7)ä¸­çš„æ°´æœåˆ†ç±»ï¼Œæ”¹ä¸ºç°åœ¨åˆ†ç±»å–·æ°”å¼•æ“æ˜¯å¦åœ¨å®‰å…¨å‚æ•°èŒƒå›´å†…è¿è¡Œï¼Œå¦‚*å›¾*[*4.9*](#x1-54019r9)æ‰€ç¤ºã€‚
- en: '![PIC](img/epistemic-uncertainty-illustration-engine-failure.JPG)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/epistemic-uncertainty-illustration-engine-failure.JPG)'
- en: 'FigureÂ 4.9: An illustration of high epistemic uncertainty in a safety-critical
    application'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4.9ï¼šé«˜è®¤è¯†ä¸ç¡®å®šæ€§åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„ç¤ºæ„å›¾
- en: Here, we see that our epistemic uncertainty could be a life-saving indicator
    of engine failure. Without this uncertainty estimate, our model would assume that
    all is fine, even though the temperature of the engine is unusual given the other
    parameters â€“ this could lead to catastrophic consequences. Fortunately, because
    of our uncertainty estimates, our model is able to tell us that something is wrong,
    despite the fact that itâ€™s never encountered this situation before.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„è®¤è¯†ä¸ç¡®å®šæ€§å¯èƒ½æ˜¯å¼•æ“æ•…éšœçš„ä¸€ä¸ªç”Ÿæ­»æ”¸å…³çš„æŒ‡ç¤ºã€‚å¦‚æœæ²¡æœ‰è¿™ä¸ªä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼šå‡è®¾ä¸€åˆ‡æ­£å¸¸ï¼Œå°½ç®¡åœ¨å…¶ä»–å‚æ•°çš„æƒ…å†µä¸‹å¼•æ“çš„æ¸©åº¦å¼‚å¸¸â€”â€”è¿™å¯èƒ½å¯¼è‡´ç¾éš¾æ€§çš„åæœã€‚å¹¸è¿çš„æ˜¯ï¼Œç”±äºæˆ‘ä»¬æœ‰ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå°½ç®¡æˆ‘ä»¬çš„æ¨¡å‹ä»æœªé‡åˆ°è¿‡è¿™ç§æƒ…å†µï¼Œå®ƒä¾ç„¶èƒ½å¤Ÿå‘Šè¯‰æˆ‘ä»¬å‡ºäº†é—®é¢˜ã€‚
- en: Separating sourcing of uncertainty
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åˆ†ç¦»ä¸ç¡®å®šæ€§çš„æ¥æº
- en: 'In this section, weâ€™ve been introduced to two sources of uncertainty, and weâ€™ve
    seen how epistemic uncertainty can be very useful for understanding how to interpret
    our modelâ€™s outputs. So, you may be wondering: is it possible to separate our
    sources of uncertainty?'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸¤ç§ä¸ç¡®å®šæ€§çš„æ¥æºï¼Œå¹¶ä¸”æˆ‘ä»¬çœ‹åˆ°è®¤è¯†ä¸ç¡®å®šæ€§å¯¹äºç†è§£å¦‚ä½•è§£é‡Šæ¨¡å‹è¾“å‡ºéå¸¸æœ‰ç”¨ã€‚é‚£ä¹ˆï¼Œä½ å¯èƒ½ä¼šæƒ³ï¼šæˆ‘ä»¬èƒ½å¦å°†ä¸ç¡®å®šæ€§æ¥æºåˆ†ç¦»å¼€æ¥ï¼Ÿ
- en: Generally speaking, there are limited guarantees when trying to decompose uncertainty
    into epistemic and aleatoric components, but some models allow us to obtain a
    good approximation of this. Ensemble methods provide a particularly good illustrative
    example.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬æ¥è¯´ï¼Œåœ¨å°è¯•å°†ä¸ç¡®å®šæ€§åˆ†è§£ä¸ºè®¤è¯†æ€§ä¸ç¡®å®šæ€§å’Œéšæœºæ€§ä¸ç¡®å®šæ€§æ—¶ï¼Œæä¾›çš„ä¿è¯æœ‰é™ï¼Œä½†æœ‰äº›æ¨¡å‹å…è®¸æˆ‘ä»¬è·å¾—è¾ƒå¥½çš„è¿‘ä¼¼ã€‚é›†æˆæ–¹æ³•æä¾›äº†ä¸€ä¸ªç‰¹åˆ«å¥½çš„ç¤ºä¾‹ã€‚
- en: 'Letâ€™s say we have an ensemble of *M* models that produce the predictive posterior
    *P*(*y*|**x***,D*) for some input **x** and output *y* from data *D*. For a given
    input, our prediction will have entropy:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«*M*ä¸ªæ¨¡å‹çš„é›†åˆï¼Œå®ƒä»¬ä¸ºæŸäº›è¾“å…¥**x**å’Œè¾“å‡º*y*ä»æ•°æ®*D*ä¸­ç”Ÿæˆé¢„æµ‹åéªŒ*P*ï¼ˆ*y*|**x***,D*ï¼‰ã€‚å¯¹äºç»™å®šçš„è¾“å…¥ï¼Œæˆ‘ä»¬çš„é¢„æµ‹å°†å…·æœ‰ç†µï¼š
- en: '![ 1 âˆ‘M m m H [P (y|x, D)] â‰ˆ H [M- P (y|x,ğœƒ )],ğœƒ âˆ¼ p(ğœƒ|D ) m=1 ](img/file93.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 âˆ‘M m m H [P (y|x, D)] â‰ˆ H [M- P (y|x,ğœƒ )],ğœƒ âˆ¼ p(ğœƒ|D ) m=1 ](img/file93.jpg)'
- en: 'Here, *H* denotes entropy, and *ğœƒ* denotes our model parameters. This is a
    formal exdivssion of concepts weâ€™ve already covered, showing that the entropy
    (in other words, uncertainty) of our predictive posterior will be high when our
    aleatoric and/or epistemic uncertainty is high. This, therefore, represents our
    **total** **uncertainty**, which is the uncertainty weâ€™ll be working with throughout
    this book. We can represent this in a manner more consistent with what weâ€™ll be
    encountering in the book â€“ in terms of our predictive standard deviation *Ïƒ*:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ*H*è¡¨ç¤ºç†µï¼Œ*ğœƒ*è¡¨ç¤ºæˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ã€‚è¿™æ˜¯æˆ‘ä»¬å·²ç»è®¨è®ºè¿‡çš„æ¦‚å¿µçš„æ­£å¼è¡¨è¾¾ï¼Œè¡¨æ˜å½“æˆ‘ä»¬çš„éšæœºä¸ç¡®å®šæ€§å’Œ/æˆ–è®¤è¯†ä¸ç¡®å®šæ€§è¾ƒé«˜æ—¶ï¼Œé¢„æµ‹åéªŒçš„ç†µï¼ˆæ¢å¥è¯è¯´ï¼Œä¸ç¡®å®šæ€§ï¼‰å°†å¾ˆé«˜ã€‚å› æ­¤ï¼Œè¿™ä»£è¡¨äº†æˆ‘ä»¬çš„**æ€»**ä¸ç¡®å®šæ€§ï¼Œè¿™æ˜¯æœ¬ä¹¦ä¸­æˆ‘ä»¬å°†å¤„ç†çš„ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ç§æ›´ç¬¦åˆæœ¬ä¹¦å†…å®¹çš„æ–¹å¼æ¥è¡¨ç¤ºè¿™ä¸€ç‚¹â€”â€”ä»¥æˆ‘ä»¬çš„é¢„æµ‹æ ‡å‡†å·®*Ïƒ*ä¸ºå•ä½ï¼š
- en: '![Ïƒ = Ïƒa + Ïƒe ](img/file94.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![Ïƒ = Ïƒa + Ïƒe ](img/file94.jpg)'
- en: Where *a* and *e* denote aleatoric and epistemic uncertainty, respectively.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ*a*å’Œ*e*åˆ†åˆ«è¡¨ç¤ºå¶ç„¶ä¸ç¡®å®šæ€§å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚
- en: 'Because weâ€™re working with ensembles, we can go a step further than our total
    uncertainty. Ensembles are unique in that each model learns something slightly
    different from the data, due to different data or parameter initialization. As
    we get an uncertainty estimate for each model, we can take the expectation (in
    other words, the average) of these uncertainty estimates:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨é›†æˆæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥è¶…è¶Šæ€»ä¸ç¡®å®šæ€§ã€‚é›†æˆæ–¹æ³•çš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºæ¯ä¸ªæ¨¡å‹ä»æ•°æ®ä¸­å­¦ä¹ åˆ°çš„å†…å®¹ç•¥æœ‰ä¸åŒï¼ŒåŸå› åœ¨äºä¸åŒçš„æ•°æ®æˆ–å‚æ•°åˆå§‹åŒ–ã€‚ç”±äºæˆ‘ä»¬ä¸ºæ¯ä¸ªæ¨¡å‹éƒ½è·å¾—äº†ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹è¿™äº›ä¸ç¡®å®šæ€§ä¼°è®¡å€¼è¿›è¡ŒæœŸæœ›ï¼ˆæ¢å¥è¯è¯´ï¼Œå³æ±‚å¹³å‡ï¼‰ï¼š
- en: '![ âˆ‘M ğ”¼ [H [P(y|x,ğœƒ)]] â‰ˆ -1- H [P (y|x,ğœƒm )],ğœƒm âˆ¼ p(ğœƒ|D ) p(ğœƒ|D) M m=1 ](img/file95.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘M ğ”¼ [H [P(y|x,ğœƒ)]] â‰ˆ -1- H [P (y|x,ğœƒm )],ğœƒm âˆ¼ p(ğœƒ|D ) p(ğœƒ|D) M m=1 ](img/file95.jpg)'
- en: This gives us our **expected data uncertainty** â€“ an estimate of our aleatoric
    uncertainty. This approximate measure of aleatoric uncertainty becomes more accurate
    as ensemble size increases. This is possible because of the way ensemble members
    learn from different subsets of data. If there is no epistemic uncertainty, then
    the models are consistent, meaning their outputs are identical, and the total
    uncertainty exclusively comprises the aleatoric uncertainty.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™äº†æˆ‘ä»¬**æœŸæœ›çš„æ•°æ®ä¸ç¡®å®šæ€§**â€”â€”å¯¹å¶ç„¶ä¸ç¡®å®šæ€§çš„ä¼°è®¡ã€‚éšç€é›†æˆè§„æ¨¡çš„å¢åŠ ï¼Œè¿™ç§å¶ç„¶ä¸ç¡®å®šæ€§çš„è¿‘ä¼¼åº¦é‡å˜å¾—æ›´ä¸ºå‡†ç¡®ã€‚è¿™æ˜¯å› ä¸ºé›†æˆæˆå‘˜ä»ä¸åŒæ•°æ®å­é›†å­¦ä¹ çš„æ–¹å¼ã€‚å¦‚æœæ²¡æœ‰è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼Œé‚£ä¹ˆæ¨¡å‹æ˜¯ä¸€è‡´çš„ï¼Œæ„å‘³ç€å®ƒä»¬çš„è¾“å‡ºæ˜¯ç›¸åŒçš„ï¼Œæ€»ä¸ç¡®å®šæ€§å®Œå…¨ç”±å¶ç„¶ä¸ç¡®å®šæ€§æ„æˆã€‚
- en: 'If, on the other hand, there is some epistemic uncertainty, then our total
    uncertainty comprises both aleatoric and epistemic uncertainty. We can use the
    expected data uncertainty to determine how much epistemic uncertainty is present
    in our total uncertainty. We do this using **mutual information**, which is given
    by:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œå¦‚æœå­˜åœ¨è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„æ€»ä¸ç¡®å®šæ€§åŒ…æ‹¬å¶ç„¶ä¸ç¡®å®šæ€§å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœŸæœ›çš„æ•°æ®ä¸ç¡®å®šæ€§æ¥ç¡®å®šæˆ‘ä»¬æ€»ä¸ç¡®å®šæ€§ä¸­å­˜åœ¨å¤šå°‘è®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨**äº’ä¿¡æ¯**æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œå…¬å¼å¦‚ä¸‹ï¼š
- en: '![I[y,ğœƒ|x,D ] = H [P (y|x, D)]âˆ’ ğ”¼p (ğœƒ|D )[H [P(y|x,ğœƒ)]] ](img/file96.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![I[y,ğœƒ|x,D ] = H [P (y|x, D)]âˆ’ ğ”¼p (ğœƒ|D )[H [P(y|x,ğœƒ)]] ](img/file96.jpg)'
- en: 'We can also exdivss this in terms of equation [4.3.2](#x1-550002):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡æ–¹ç¨‹[4.3.2](#x1-550002)æ¥è¡¨ç¤ºè¿™ä¸ªé—®é¢˜ï¼š
- en: '![I[y,ğœƒ|x,D ] = Ïƒe = Ïƒ âˆ’ Ïƒa ](img/file97.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![I[y,ğœƒ|x,D ] = Ïƒe = Ïƒ âˆ’ Ïƒa ](img/file97.jpg)'
- en: 'As we can see, the concept is pretty straightforward: simply subtract our aleatoric
    uncertainty from our total uncertainty! The ability to estimate the aleatoric
    uncertainty can make ensemble methods more attractive for uncertainty quantification,
    as it allows us to decompose uncertainty, thus providing additional information
    we donâ€™t usually have access to. In *Chapter 6, Bayesian* *Inference with a Standard
    Deep Learning Toolbox*, weâ€™ll learn more about ensemble techniques for BDL. For
    non-ensemble methods, we just have the general predictive uncertainty, *Ïƒ* (the
    combined aleatoric and epistemic uncertainty), which is suitable in most cases.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè¿™ä¸ªæ¦‚å¿µç›¸å½“ç›´æ¥ï¼šç®€å•åœ°å°†æˆ‘ä»¬çš„**å¶ç„¶ä¸ç¡®å®šæ€§**ä»æ€»ä¸ç¡®å®šæ€§ä¸­å‡å»ï¼èƒ½å¤Ÿä¼°è®¡å¶ç„¶ä¸ç¡®å®šæ€§ä½¿å¾—é›†æˆæ–¹æ³•åœ¨ä¸ç¡®å®šæ€§é‡åŒ–ä¸­æ›´å…·å¸å¼•åŠ›ï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬åˆ†è§£ä¸ç¡®å®šæ€§ï¼Œä»è€Œæä¾›é€šå¸¸æ— æ³•è·å¾—çš„é¢å¤–ä¿¡æ¯ã€‚åœ¨*ç¬¬å…­ç« ï¼Œè´å¶æ–¯æ¨æ–­ä¸æ ‡å‡†æ·±åº¦å­¦ä¹ å·¥å…·ç®±*ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ æ›´å¤šå…³äºBDLçš„é›†æˆæŠ€æœ¯ã€‚å¯¹äºéé›†æˆæ–¹æ³•ï¼Œæˆ‘ä»¬åªæœ‰ä¸€èˆ¬çš„é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œ*Ïƒ*ï¼ˆåˆå¹¶äº†å¶ç„¶å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§ï¼‰ï¼Œè¿™åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯åˆé€‚çš„ã€‚
- en: In the next section, weâ€™ll see how we can incorporate uncertainties in how we
    evaluate our models, and how they can be incorporated in the loss function to
    improve model training.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å°†ä¸ç¡®å®šæ€§çº³å…¥åˆ°æ¨¡å‹è¯„ä¼°ä¸­ï¼Œå¹¶ä¸”å¦‚ä½•å°†å…¶çº³å…¥æŸå¤±å‡½æ•°ä»¥æ”¹å–„æ¨¡å‹è®­ç»ƒã€‚
- en: '4.3.3 Going beyond maximum likelihood: the importance of likelihoods'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.3 è¶…è¶Šæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼šä¼¼ç„¶çš„é‡è¦æ€§
- en: In the previous section, we saw how uncertainty quantification can help to avoid
    potentially hazardous scenarios in real-world applications of machine learning.
    Going back even further to [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals
    of Bayesian Inference*](CH2.xhtml#x1-250002) and [*ChapterÂ 3*](CH3.xhtml#x1-350003),
    [*Fundamentals of Deep Learning*](CH3.xhtml#x1-350003), we were introduced to
    the concept of calibration, and shown how well-calibrated methodsâ€™ uncertainties
    increase as data at inference deviates from training data â€“ a concept illustrated
    in *Figure* [*4.7*](#x1-54013r7).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸ç¡®å®šæ€§é‡åŒ–å¦‚ä½•å¸®åŠ©é¿å…åœ¨æœºå™¨å­¦ä¹ çš„å®é™…åº”ç”¨ä¸­å‡ºç°æ½œåœ¨çš„å±é™©åœºæ™¯ã€‚å›é¡¾æ›´æ—©ä¹‹å‰çš„[*ç¬¬2ç« *](CH2.xhtml#x1-250002)çš„[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)å’Œ[*ç¬¬3ç« *](CH3.xhtml#x1-350003)çš„[*æ·±åº¦å­¦ä¹ åŸºç¡€*](CH3.xhtml#x1-350003)ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ ¡å‡†çš„æ¦‚å¿µï¼Œå¹¶å±•ç¤ºäº†æ ¡å‡†è‰¯å¥½çš„æ–¹æ³•å¦‚ä½•éšç€æ¨ç†æ•°æ®åç¦»è®­ç»ƒæ•°æ®è€Œå¢åŠ å…¶ä¸ç¡®å®šæ€§â€”â€”è¿™ä¸€æ¦‚å¿µåœ¨*å›¾*
    [*4.7*](#x1-54013r7)ä¸­å¾—åˆ°äº†è¯´æ˜ã€‚
- en: While itâ€™s easy to illustrate the concept of calibration with simple data â€“
    as we saw in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002)
    (through *Figure* [*2.21*](CH2.xhtml#x1-31029r21)) â€“ unfortunately, itâ€™s not easy
    or practical to do this in most applications. A much more practical approach to
    understanding how well-calibrated a given method would be to use a metric that
    incorporates its uncertainty â€“ and this is exactly what we get with **likelihood**.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ç”¨ç®€å•æ•°æ®æ¥è¯´æ˜æ ¡å‡†çš„æ¦‚å¿µå¾ˆå®¹æ˜“â€”â€”æ­£å¦‚æˆ‘ä»¬åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ä¸­çš„[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ï¼ˆé€šè¿‡*å›¾*
    [*2.21*](CH2.xhtml#x1-31029r21)ï¼‰ä¸­çœ‹åˆ°çš„é‚£æ ·â€”â€”ä¸å¹¸çš„æ˜¯ï¼Œåœ¨å¤§å¤šæ•°åº”ç”¨ä¸­ï¼Œåšè¿™ä¸ªå¹¶ä¸å®¹æ˜“æˆ–å®é™…ã€‚ç†è§£ç»™å®šæ–¹æ³•çš„æ ¡å‡†ç¨‹åº¦çš„ä¸€ä¸ªæ›´å®é™…çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸€ä¸ªåŒ…å«å…¶ä¸ç¡®å®šæ€§çš„åº¦é‡â€”â€”è¿™æ­£æ˜¯**ä¼¼ç„¶**æ‰€æä¾›çš„ã€‚
- en: 'Likelihood is the probability that some parameters describe some data. As mentioned
    earlier, we typically work with Gaussian distributions to make things tractable
    â€“ so weâ€™re interested in Gaussian likelihood: the likelihood that the parameters
    of a Gaussian fit some observed data. The equation for Gaussian likelihood is
    as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼¼ç„¶æ˜¯æŸäº›å‚æ•°æè¿°æŸäº›æ•°æ®çš„æ¦‚ç‡ã€‚å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¥ç®€åŒ–é—®é¢˜â€”â€”å› æ­¤æˆ‘ä»¬å¯¹é«˜æ–¯ä¼¼ç„¶æ„Ÿå…´è¶£ï¼šå³é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°æ‹Ÿåˆä¸€äº›è§‚æµ‹æ•°æ®çš„ä¼¼ç„¶ã€‚é«˜æ–¯ä¼¼ç„¶çš„å…¬å¼å¦‚ä¸‹ï¼š
- en: '![ 1 (y âˆ’ Î¼)2 p(y) = âˆš----exp {âˆ’ ----2--} 2Ï€ Ïƒ 2Ïƒ ](img/file98.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 (y âˆ’ Î¼)2 p(y) = âˆš----exp {âˆ’ ----2--} 2Ï€ Ïƒ 2Ïƒ ](img/file98.jpg)'
- en: 'Letâ€™s see what these distributions would look like for the parameter values
    we saw earlier in *Figures* [*4.2*](#x1-51002r2) and [*4.3*](#x1-51004r3):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹è¿™äº›åˆ†å¸ƒåœ¨æˆ‘ä»¬ä¹‹å‰åœ¨*å›¾* [*4.2*](#x1-51002r2) å’Œ [*4.3*](#x1-51004r3) ä¸­çœ‹åˆ°çš„å‚æ•°å€¼ä¸‹ä¼šæ˜¯ä»€ä¹ˆæ ·å­ï¼š
- en: '![PIC](img/file99.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file99.png)'
- en: 'FigureÂ 4.10: The plot of Gaussian distributions corresponding to the parameter
    sets from Figures [4.2](#x1-51002r2) and [4.3](#x1-51004r3)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4.10ï¼šä¸å›¾[4.2](#x1-51002r2) å’Œ [4.3](#x1-51004r3) ä¸­çš„å‚æ•°é›†å¯¹åº”çš„é«˜æ–¯åˆ†å¸ƒå›¾
- en: 'Visualizing these two distributions highlights the difference in uncertainty
    between the two parameter sets: our first set of parameters has high probability
    (solid line), whereas our second set of parameters has low probability (dotted
    line). But what does this mean for the resulting likelihood values associated
    with our modelâ€™s outputs? To investigate these, we need to plug these values into
    equation [4.3.3](#x1-560003). To do this, weâ€™ll need a value for *y*. Weâ€™ll use
    the mean of our target values: 24*.*03\. For our *Î¼* and *Ïƒ* values, weâ€™ll take
    the means and standard deviations of the predicted output values, respectively:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–è¿™ä¸¤ä¸ªåˆ†å¸ƒçªå‡ºäº†è¿™ä¸¤ç»„å‚æ•°çš„ä¸ç¡®å®šæ€§å·®å¼‚ï¼šæˆ‘ä»¬çš„ç¬¬ä¸€ç»„å‚æ•°å…·æœ‰é«˜æ¦‚ç‡ï¼ˆå®çº¿ï¼‰ï¼Œè€Œæˆ‘ä»¬çš„ç¬¬äºŒç»„å‚æ•°å…·æœ‰ä½æ¦‚ç‡ï¼ˆè™šçº¿ï¼‰ã€‚ä½†æ˜¯ï¼Œè¿™å¯¹ä¸æˆ‘ä»¬æ¨¡å‹è¾“å‡ºç›¸å…³çš„ä¼¼ç„¶å€¼æ„å‘³ç€ä»€ä¹ˆå‘¢ï¼Ÿä¸ºäº†è°ƒæŸ¥è¿™äº›ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›å€¼ä»£å…¥æ–¹ç¨‹[4.3.3](#x1-560003)ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª*y*çš„å€¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ç›®æ ‡å€¼çš„å‡å€¼ï¼š24*.*03\.
    å¯¹äºæˆ‘ä»¬çš„*Î¼*å’Œ*Ïƒ*å€¼ï¼Œæˆ‘ä»¬å°†åˆ†åˆ«å–é¢„æµ‹è¾“å‡ºå€¼çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼š
- en: '![ 1 (24.03 âˆ’ 24.01)2 p(ğœƒ1) = âˆš---------exp { âˆ’ ----------2----} = 0.29 2Ï€
    Ã— 1.37 2 Ã— 1.37 ](img/file100.jpg)![ -----1----- (24.03âˆ’--31.11)2 âˆ’ 5 p(ğœƒ2) =
    âˆš2-Ï€-Ã— 1.78 exp {âˆ’ 2Ã— 1.782 } = 7.88Ã— 10 ](img/file101.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 (24.03 âˆ’ 24.01)2 p(ğœƒ1) = âˆš---------exp { âˆ’ ----------2----} = 0.29 2Ï€
    Ã— 1.37 2 Ã— 1.37 ](img/file100.jpg)![ -----1----- (24.03âˆ’--31.11)2 âˆ’ 5 p(ğœƒ2) =
    âˆš2-Ï€-Ã— 1.78 exp {âˆ’ 2Ã— 1.782 } = 7.88Ã— 10 ](img/file101.jpg)'
- en: We see here that we have a much higher likelihood score for our first set of
    parameters (*ğœƒ*[1]) than for our second (*ğœƒ*[2]). This is consistent with *Figure*
    [*4.10*](#x1-56004r10), and indicates that, given the data, parameters *ğœƒ*[1]
    have a higher probability than parameters *ğœƒ*[2] â€“ in other words, parameters
    *ğœƒ*[1] do a better job of mapping the inputs to the outputs.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°ï¼Œåœ¨å‚æ•°é›†*ğœƒ*[1]ä¸*ğœƒ*[2]ä¹‹é—´ï¼Œå‰è€…çš„ä¼¼ç„¶å¾—åˆ†æ˜¾è‘—é«˜äºåè€…ã€‚è¿™ä¸*å›¾* [*4.10*](#x1-56004r10)ä¸€è‡´ï¼Œè¡¨æ˜æ ¹æ®æ•°æ®ï¼Œå‚æ•°*ğœƒ*[1]æ¯”å‚æ•°*ğœƒ*[2]å…·æœ‰æ›´é«˜çš„æ¦‚ç‡â€”â€”æ¢å¥è¯è¯´ï¼Œå‚æ•°*ğœƒ*[1]æ›´å¥½åœ°å°†è¾“å…¥æ˜ å°„åˆ°è¾“å‡ºã€‚
- en: These examples illustrate the impact of incorporating uncertainty estimates,
    allowing us to compute the likelihood of the data. While our error has increased
    somewhat due to the poorer mean prediction, our likelihood has decreased more
    dramatically â€“ falling by many orders of magnitude. This tells us that these parameters
    are doing a very poor job of describing the data, and it does so in a more principled
    way than simply computing the error between our outputs and our targets.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ä¾‹å­å±•ç¤ºäº†å¼•å…¥ä¸ç¡®å®šæ€§ä¼°è®¡çš„å½±å“ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè®¡ç®—æ•°æ®çš„ä¼¼ç„¶æ€§ã€‚è™½ç„¶ç”±äºå¹³å‡é¢„æµ‹è¾ƒå·®ï¼Œæˆ‘ä»¬çš„è¯¯å·®æœ‰æ‰€å¢åŠ ï¼Œä½†æˆ‘ä»¬çš„ä¼¼ç„¶æ€§ä¸‹é™å¾—æ›´ä¸ºæ˜¾è‘—â€”â€”ä¸‹é™äº†å¤šä¸ªæ•°é‡çº§ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬ï¼Œè¿™äº›å‚æ•°åœ¨æè¿°æ•°æ®æ–¹é¢è¡¨ç°å¾—éå¸¸ç³Ÿç³•ï¼Œè€Œä¸”å®ƒæ¯”ä»…ä»…è®¡ç®—è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„è¯¯å·®æ›´å…·åŸåˆ™æ€§ã€‚
- en: 'An important feature of likelihood is that it balances a modelâ€™s accuracy with
    its uncertainty. Models that are over-confident have low uncertainty on data for
    which they have incorrect predictions, and likelihood penalizes them for this
    overconfidence. Similarly, well-calibrated models are confident on data for which
    they have correct predictions, and uncertain on data for which they have incorrect
    predictions. While the models will still be penalized for the incorrect predictions,
    they will also be rewarded for being uncertain in the right places, and not being
    over-confident. To see this in practice, we can again use the target output value
    from the tables shown in *Figure* [*4.2*](#x1-51002r2) and *Figure* [*4.3*](#x1-51004r3):
    *y* = 24*.*03, but weâ€™ll also use an incorrect prediction: *Å·* = 5*.*00\. As we
    can see, this produces a pretty significant error of |*y* âˆ’*Å·*| = |24*.*03 âˆ’ 5*.*00|
    = 19*.*03\. Letâ€™s take a look at what happens to our likelihood as we increase
    our *Ïƒ*Â² value associated with this prediction:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼¼ç„¶æ€§çš„é‡è¦ç‰¹å¾ä¹‹ä¸€æ˜¯å®ƒå¹³è¡¡äº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œä¸ç¡®å®šæ€§ã€‚è¿‡äºè‡ªä¿¡çš„æ¨¡å‹åœ¨æ•°æ®çš„é¢„æµ‹ä¸æ­£ç¡®æ—¶ï¼Œè¡¨ç°å‡ºè¾ƒä½çš„ä¸ç¡®å®šæ€§ï¼Œè€Œä¼¼ç„¶æ€§ä¼šå› è¿™ç§è¿‡åº¦è‡ªä¿¡è€Œæƒ©ç½šå®ƒä»¬ã€‚åŒæ ·ï¼Œæ ¡å‡†è‰¯å¥½çš„æ¨¡å‹åœ¨é¢„æµ‹æ­£ç¡®çš„æ•°æ®ä¸Šè¡¨ç°å‡ºä¿¡å¿ƒï¼Œè€Œåœ¨é¢„æµ‹é”™è¯¯çš„æ•°æ®ä¸Šè¡¨ç°å‡ºä¸ç¡®å®šæ€§ã€‚è™½ç„¶æ¨¡å‹ä»ä¼šå› é”™è¯¯çš„é¢„æµ‹è€Œå—åˆ°æƒ©ç½šï¼Œä½†å®ƒä»¬ä¹Ÿä¼šå› åœ¨æ­£ç¡®çš„åœ°æ–¹è¡¨ç°å‡ºä¸ç¡®å®šæ€§è€Œè·å¾—å¥–åŠ±ï¼Œè€Œä¸ä¼šè¿‡åº¦è‡ªä¿¡ã€‚ä¸ºäº†å®è·µè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥å†æ¬¡ä½¿ç”¨*å›¾*
    [*4.2*](#x1-51002r2)å’Œ*å›¾* [*4.3*](#x1-51004r3)ä¸­æ˜¾ç¤ºçš„ç›®æ ‡è¾“å‡ºå€¼ï¼š*y* = 24*.*03ï¼Œä½†æˆ‘ä»¬ä¹Ÿä¼šä½¿ç”¨ä¸€ä¸ªä¸æ­£ç¡®çš„é¢„æµ‹å€¼ï¼š*Å·*
    = 5*.*00ã€‚å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¿™äº§ç”Ÿäº†ä¸€ä¸ªç›¸å½“å¤§çš„è¯¯å·®ï¼š|*y* âˆ’*Å·*| = |24*.*03 âˆ’ 5*.*00| = 19*.*03ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ï¼Œå½“æˆ‘ä»¬å¢åŠ ä¸æ­¤é¢„æµ‹ç›¸å…³çš„*Ïƒ*Â²å€¼æ—¶ï¼Œä¼¼ç„¶æ€§ä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ï¼š
- en: '![PIC](img/file102.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file102.png)'
- en: 'FigureÂ 4.11: A plot of likelihood values with increasing variance'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.11ï¼šæ–¹å·®å¢åŠ æ—¶ä¼¼ç„¶å€¼çš„å˜åŒ–å›¾
- en: As we see here, our likelihood value is very small when *Ïƒ*Â² = 0*.*00, but increases
    as *Ïƒ*Â² increases to around 0*.*15, before falling off again. This demonstrates
    that, given an incorrect prediction, some uncertainty is better than none when
    it comes to likelihood values. Thus, using likelihoods allows us to train better
    calibrated models.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œå½“*Ïƒ*Â² = 0*.*00æ—¶ï¼Œæˆ‘ä»¬çš„ä¼¼ç„¶å€¼éå¸¸å°ï¼Œä½†éšç€*Ïƒ*Â²å¢åŠ åˆ°çº¦0*.*15æ—¶ï¼Œå®ƒåˆå¼€å§‹ä¸Šå‡ï¼Œç„¶åå†æ¬¡ä¸‹é™ã€‚è¿™è¡¨æ˜ï¼Œåœ¨é¢„æµ‹ä¸æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œä¸æ²¡æœ‰ä¸ç¡®å®šæ€§ç›¸æ¯”ï¼Œä¸€å®šçš„ä¸ç¡®å®šæ€§å¯¹äºä¼¼ç„¶å€¼æ›´æœ‰åˆ©ã€‚å› æ­¤ï¼Œä½¿ç”¨ä¼¼ç„¶æ€§å¯ä»¥å¸®åŠ©æˆ‘ä»¬è®­ç»ƒå‡ºæ›´å¥½æ ¡å‡†çš„æ¨¡å‹ã€‚
- en: 'Similarly, we can see that if we fix our uncertainty, in this case to *Ïƒ*Â²
    = 0*.*1, and vary our predictions, our likelihood peaks at the correct value,
    falling off in either direction as our predictions *Å·* become less accurate and
    our error |*y* âˆ’*Å·*| grows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·åœ°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæˆ‘ä»¬å›ºå®šä¸ç¡®å®šæ€§ï¼Œè¿™é‡Œè®¾ä¸º*Ïƒ*Â² = 0*.*1ï¼Œå¹¶æ”¹å˜é¢„æµ‹å€¼ï¼Œä¼¼ç„¶æ€§åœ¨æ­£ç¡®å€¼å¤„è¾¾åˆ°å³°å€¼ï¼Œå½“é¢„æµ‹*Å·*å˜å¾—ä¸å‡†ç¡®æ—¶ï¼Œä¼¼ç„¶æ€§åœ¨ä»»ä¸€æ–¹å‘ä¸Šéƒ½ä¼šä¸‹é™ï¼ŒåŒæ—¶æˆ‘ä»¬çš„è¯¯å·®|*y*
    âˆ’*Å·*|ä¹Ÿåœ¨å¢å¤§ï¼š
- en: '![PIC](img/likelihood-varying-predictions.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/likelihood-varying-predictions.png)'
- en: 'FigureÂ 4.12: A plot of likelihood values with varying predictions'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4.12ï¼šéšç€é¢„æµ‹å˜åŒ–çš„ä¼¼ç„¶å€¼å›¾
- en: 'Practically, we donâ€™t usually use the likelihood, but instead use the **negative**
    **log-likelihood** (**NLL**). We make it negative because, with loss functions,
    we are interested in finding the minima, rather than the maxima. We use the log
    because this allows us to use addition, rather than multiplication, which makes
    things more computationally efficient (making use of the logarithmic identity
    *log*(*a* âˆ— *b*) = *log*(*a*) + *log*(*b*)). The equation that weâ€™ll typically
    be using is therefore:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œæˆ‘ä»¬é€šå¸¸ä¸ä½¿ç”¨ä¼¼ç„¶å‡½æ•°ï¼Œè€Œæ˜¯ä½¿ç”¨**è´Ÿå¯¹æ•°ä¼¼ç„¶**ï¼ˆ**NLL**ï¼‰ã€‚æˆ‘ä»¬å°†å…¶å–è´Ÿï¼Œå› ä¸ºåœ¨æŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å…³å¿ƒçš„æ˜¯å¯»æ‰¾æœ€å°å€¼ï¼Œè€Œä¸æ˜¯æœ€å¤§å€¼ã€‚æˆ‘ä»¬ä½¿ç”¨å¯¹æ•°ï¼Œå› ä¸ºè¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨åŠ æ³•è€Œéä¹˜æ³•ï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡ï¼ˆåˆ©ç”¨å¯¹æ•°æ’ç­‰å¼*log*(*a*
    âˆ— *b*) = *log*(*a*) + *log*(*b*)ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨çš„æ–¹ç¨‹æ˜¯ï¼š
- en: '![ 2 N LL (y) = âˆ’ log{-1--}âˆ’ (y-âˆ’-Î¼)- 2Ï€Ïƒ 2 Ïƒ2 ](img/file103.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 N LL (y) = âˆ’ log{-1--}âˆ’ (y-âˆ’-Î¼)- 2Ï€Ïƒ 2 Ïƒ2 ](img/file103.jpg)'
- en: Now that weâ€™re familiar with the core concepts of uncertainty and likelihood,
    weâ€™re ready for the next section, where weâ€™ll learn how to work with probabilistic
    concepts in code using the TensorFlow Probability library.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ç†Ÿæ‚‰äº†ä¸ç¡®å®šæ€§å’Œä¼¼ç„¶æ€§è¿™ä¸¤ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å‡†å¤‡è¿›å…¥ä¸‹ä¸€éƒ¨åˆ†ï¼Œå­¦ä¹ å¦‚ä½•åœ¨ä»£ç ä¸­ä½¿ç”¨TensorFlowæ¦‚ç‡åº“å¤„ç†æ¦‚ç‡æ¦‚å¿µã€‚
- en: 4.4 Tools for BDL
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 BDLå·¥å…·
- en: In this chapter, as well as in [*ChapterÂ 2*](CH2.xhtml#x1-250002), [*Fundamentals
    of Bayesian Inference*](CH2.xhtml#x1-250002), weâ€™ve seen a lot of equations involving
    probability. While itâ€™s possible to create BDL models without a probability library,
    having a library that supports some of the fundamental functions makes things
    much easier. As weâ€™re using TensorFlow for the examples in this book, weâ€™ll be
    using the **TensorFlow** **Probability** (**TFP**) library to help us with some
    of these probabilistic components. In this section, weâ€™ll introduce TFP and show
    how it can be used to easily implement many of the concepts weâ€™ve seen in [*ChapterÂ 2*](CH2.xhtml#x1-250002),
    [*Fundamentals of Bayesian Inference*](CH2.xhtml#x1-250002) and [*ChapterÂ 4*](#x1-490004),
    [*Introducing Bayesian Deep* *Learning*](#x1-490004).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæ­£å¦‚åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)ä¸­æ‰€è§ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°äº†è®¸å¤šæ¶‰åŠæ¦‚ç‡çš„æ–¹ç¨‹ã€‚è™½ç„¶æ²¡æœ‰æ¦‚ç‡åº“ä¹Ÿèƒ½åˆ›å»ºBDLæ¨¡å‹ï¼Œä½†æœ‰ä¸€ä¸ªæ”¯æŒåŸºæœ¬å‡½æ•°çš„åº“ä¼šä½¿äº‹æƒ…å˜å¾—æ›´å®¹æ˜“ã€‚ç”±äºæœ¬ä¹¦ä¸­çš„ç¤ºä¾‹ä½¿ç”¨äº†TensorFlowï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**TensorFlow**
    **æ¦‚ç‡**ï¼ˆ**TFP**ï¼‰åº“æ¥å¸®åŠ©æˆ‘ä»¬å®ç°è¿™äº›æ¦‚ç‡ç»„ä»¶ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»TFPï¼Œå¹¶å±•ç¤ºå¦‚ä½•ä½¿ç”¨å®ƒè½»æ¾å®ç°æˆ‘ä»¬åœ¨[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ï¼Œ[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)å’Œ[*ç¬¬4ç« *](#x1-490004)ï¼Œ[*ä»‹ç»è´å¶æ–¯æ·±åº¦*
    *å­¦ä¹ *](#x1-490004)ä¸­çœ‹åˆ°çš„è®¸å¤šæ¦‚å¿µã€‚
- en: 'Much of the content up to this point has been about introducing the concept
    of working with distributions. As such, the first TFP module weâ€™ll learn about
    is the `distributions` module. Letâ€™s take a look:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œå¾ˆå¤šå†…å®¹éƒ½åœ¨ä»‹ç»å¦‚ä½•ä¸åˆ†å¸ƒè¿›è¡Œå·¥ä½œã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¦å­¦ä¹ çš„ç¬¬ä¸€ä¸ªTFPæ¨¡å—æ˜¯`distributions`æ¨¡å—ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹ï¼š
- en: '[PRE0]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, we have a simple example of initializing a Gaussian (or normal) distribution
    using the `distributions` module. We can now sample from this distribution â€“ weâ€™ll
    visualize the distribution of our samples using `seaborn` and `matplotlib`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œä½¿ç”¨`distributions`æ¨¡å—åˆå§‹åŒ–ä¸€ä¸ªé«˜æ–¯ï¼ˆæˆ–æ­£æ€ï¼‰åˆ†å¸ƒã€‚æˆ‘ä»¬ç°åœ¨å¯ä»¥ä»è¿™ä¸ªåˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·â€”â€”æˆ‘ä»¬å°†ä½¿ç”¨`seaborn`å’Œ`matplotlib`å¯è§†åŒ–æˆ‘ä»¬çš„æ ·æœ¬åˆ†å¸ƒï¼š
- en: '[PRE1]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This produces the following plot:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†ç”Ÿæˆä»¥ä¸‹å›¾è¡¨ï¼š
- en: '![PIC](img/file104.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file104.png)'
- en: 'FigureÂ 4.13: A probability distribution of samples drawn from a Gaussian distribution
    using TFP'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4.13ï¼šä½¿ç”¨TFPä»é«˜æ–¯åˆ†å¸ƒä¸­æŠ½æ ·å¾—åˆ°çš„æ ·æœ¬çš„æ¦‚ç‡åˆ†å¸ƒ
- en: 'As we can see, the samples follow a Gaussian distribution defined by our parameters
    *Î¼* = 0 and *Ïƒ* = 1*.*5\. The TFD distribution classes also have methods for useful
    functions such as **Probability Density Function** (**PDF**) and **Cumulative
    Density Function** (**CDF**). Letâ€™s take a look, starting with computing the PDF
    over a range of values:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæ ·æœ¬éµå¾ªç”±æˆ‘ä»¬çš„å‚æ•°*Î¼* = 0å’Œ*Ïƒ* = 1*.*5å®šä¹‰çš„é«˜æ–¯åˆ†å¸ƒã€‚TFDåˆ†å¸ƒç±»è¿˜å…·æœ‰ä¸€äº›æœ‰ç”¨çš„å‡½æ•°æ–¹æ³•ï¼Œå¦‚**æ¦‚ç‡å¯†åº¦å‡½æ•°**ï¼ˆ**PDF**ï¼‰å’Œ**ç´¯ç§¯åˆ†å¸ƒå‡½æ•°**ï¼ˆ**CDF**ï¼‰ã€‚è®©æˆ‘ä»¬å…ˆä»è®¡ç®—PDFåœ¨ä¸€ç³»åˆ—å€¼ä¸Šçš„è¡¨ç°å¼€å§‹ï¼š
- en: '[PRE2]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With the divceding code, weâ€™ll produce the following plot:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»¥ä¸‹ä»£ç ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä»¥ä¸‹å›¾è¡¨ï¼š
- en: '![PIC](img/file105.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file105.png)'
- en: 'FigureÂ 4.14: A plot of probability density function values for a range of inputs
    spanning *x* = âˆ’4 to *x* = 4'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4.14ï¼šä¸€ç³»åˆ—è¾“å…¥ï¼ˆ*x* = âˆ’4åˆ°*x* = 4ï¼‰å¯¹åº”çš„æ¦‚ç‡å¯†åº¦å‡½æ•°å€¼çš„å›¾
- en: 'Similarly, we can also compute the CDF:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®¡ç®—CDFï¼š
- en: '[PRE3]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Compared with the PDF, the CDF produces cumulative probability values, from
    0 to 1, as we see in the following plot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸PDFç›¸æ¯”ï¼ŒCDFç”Ÿæˆç´¯ç§¯æ¦‚ç‡å€¼ï¼ŒèŒƒå›´ä»0åˆ°1ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹é¢çš„å›¾è¡¨ä¸­æ‰€çœ‹åˆ°çš„ï¼š
- en: '![PIC](img/file106.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file106.png)'
- en: 'FigureÂ 4.15: Cumulative density function values for a range of inputs spanning
    *x* = âˆ’4 to *x* = 4'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4.15ï¼šé’ˆå¯¹èŒƒå›´å†…è¾“å…¥å€¼çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°å€¼ï¼Œ*x* = âˆ’4åˆ°*x* = 4
- en: 'The `tfp.distributions` classes also give us easy access to the parameters
    of the distributions, for example, we can recover the parameters of our Gaussian
    distribution via the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfp.distributions`ç±»è¿˜ä¸ºæˆ‘ä»¬æä¾›äº†è½»æ¾è®¿é—®åˆ†å¸ƒå‚æ•°çš„æ–¹å¼ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¢å¤é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼š'
- en: '[PRE4]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that these will return `tf.Tensor` objects, but the NumPy values can be
    accessed easily via the `.numpy()` function, for example:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œè¿™äº›å°†è¿”å›`tf.Tensor`å¯¹è±¡ï¼Œä½†å¯ä»¥é€šè¿‡`.numpy()`å‡½æ•°è½»æ¾è®¿é—®NumPyå€¼ï¼Œä¾‹å¦‚ï¼š
- en: '[PRE5]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This gives us two NumPy scalars for our `mu` and `sigma` variables: 0*.*0 and
    1*.*5, respectively.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™å‡ºäº†æˆ‘ä»¬çš„`mu`å’Œ`sigma`å˜é‡çš„ä¸¤ä¸ªNumPyæ ‡é‡å€¼ï¼šåˆ†åˆ«ä¸º0*.*0å’Œ1*.*5ã€‚
- en: 'Just as we can compute the probability, and thus obtain the PDF, using the
    `prob()` function, we can also easily compute the log probability, or log likelihood,
    using the `log_prob()` function. This makes things a little easier than coding
    the full likelihood equation (for instance, equation [4.3.3](#x1-56010r3)) each
    time:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`prob()`å‡½æ•°è®¡ç®—æ¦‚ç‡ï¼Œä»è€Œå¾—åˆ°PDFä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è½»æ¾åœ°ä½¿ç”¨`log_prob()`å‡½æ•°è®¡ç®—å¯¹æ•°æ¦‚ç‡æˆ–å¯¹æ•°ä¼¼ç„¶ã€‚è¿™ä½¿å¾—æˆ‘ä»¬æ¯”æ¯æ¬¡éƒ½ç¼–å†™å®Œæ•´çš„ä¼¼ç„¶æ–¹ç¨‹ï¼ˆä¾‹å¦‚ï¼Œæ–¹ç¨‹[4.3.3](#x1-56010r3)ï¼‰æ›´ç®€å•ä¸€äº›ï¼š
- en: '[PRE6]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we first obtain the log likelihood for some value *x* = 5, and then obtain
    the NLL, such as would be used in the context of gradient descent.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆè·å¾—æŸä¸ªå€¼*x* = 5çš„å¯¹æ•°ä¼¼ç„¶å€¼ï¼Œç„¶åè·å¾—NLLï¼Œè¿™åœ¨æ¢¯åº¦ä¸‹é™çš„ä¸Šä¸‹æ–‡ä¸­ä¼šç”¨åˆ°ã€‚
- en: As we continue through the book, weâ€™ll learn more about what TFP has to offer
    â€“ using the `distributions` module to sample from parameter distributions, and
    exploring the powerful `tfp.layers` module, which implements probabilistic versions
    of common neural network layers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æˆ‘ä»¬ç»§ç»­é˜…è¯»æœ¬ä¹¦ï¼Œæˆ‘ä»¬å°†æ›´å¤šåœ°äº†è§£TFPçš„åŠŸèƒ½â€”â€”ä½¿ç”¨`distributions`æ¨¡å—ä»å‚æ•°åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œå¹¶æ¢ç´¢å¼ºå¤§çš„`tfp.layers`æ¨¡å—ï¼Œè¯¥æ¨¡å—å®ç°äº†å¸¸è§ç¥ç»ç½‘ç»œå±‚çš„æ¦‚ç‡ç‰ˆæœ¬ã€‚
- en: 4.5 Summary
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 æ€»ç»“
- en: In this chapter, we were introduced to the fundamental concepts that weâ€™ll need
    to progress through the book and learn how to implement and use BNNs. Most crucially,
    we learned about the ideal BNN, which introduced us to the core ideas underlying
    BDL, and the computational difficulties of achieving this in practice. We also
    covered the fundamental practical methods used in BDL, giving us a grounding in
    the concepts that allow us to implement computationally tractable BNNs.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å®ç°å¹¶ä½¿ç”¨BNNæ‰€éœ€çš„åŸºæœ¬æ¦‚å¿µã€‚æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬äº†è§£äº†ç†æƒ³çš„BNNï¼Œè¿™ä½¿æˆ‘ä»¬æ¥è§¦åˆ°BDLçš„æ ¸å¿ƒæ€æƒ³ï¼Œä»¥åŠåœ¨å®è·µä¸­å®ç°è¿™ä¸€ç‚¹çš„è®¡ç®—å›°éš¾ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†BDLä¸­ä½¿ç”¨çš„åŸºæœ¬å®è·µæ–¹æ³•ï¼Œä¸ºæˆ‘ä»¬å®ç°è®¡ç®—å¯è¡Œçš„BNNæ‰“ä¸‹äº†åŸºç¡€ã€‚
- en: 'The chapter also introduced the concept of uncertainty sources, describing
    the difference between data and model uncertainty, how these contribute to total
    uncertainty, and how we can estimate the contributions of different types of uncertainty
    with various models. We also introduced one of the most fundamental components
    in probabilistic inference â€“ the likelihood function â€“ and learned about how it
    can help us to train better principled and better calibrated models. Lastly, we
    were introduced to TensorFlow Probability: a powerful library for probabilistic
    inference, and a crucial component of the practical examples later in the book.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« è¿˜ä»‹ç»äº†ä¸ç¡®å®šæ€§æ¥æºçš„æ¦‚å¿µï¼Œæè¿°äº†æ•°æ®ä¸ç¡®å®šæ€§å’Œæ¨¡å‹ä¸ç¡®å®šæ€§ä¹‹é—´çš„åŒºåˆ«ï¼Œè¿™äº›å¦‚ä½•å½±å“æ€»ä¸ç¡®å®šæ€§ï¼Œå¹¶ä¸”æˆ‘ä»¬å¦‚ä½•é€šè¿‡ä¸åŒçš„æ¨¡å‹ä¼°è®¡å„ç§ä¸ç¡®å®šæ€§ç±»å‹çš„è´¡çŒ®ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†æ¦‚ç‡æ¨æ–­ä¸­æœ€åŸºæœ¬çš„ç»„æˆéƒ¨åˆ†ä¹‹ä¸€â€”â€”ä¼¼ç„¶å‡½æ•°ï¼Œå¹¶äº†è§£äº†å®ƒå¦‚ä½•å¸®åŠ©æˆ‘ä»¬è®­ç»ƒæ›´å¥½çš„ã€åŸåˆ™æ€§æ›´å¼ºä¸”æ›´ä¸ºç²¾ç¡®çš„æ¨¡å‹ã€‚æœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†TensorFlowæ¦‚ç‡ï¼šä¸€ä¸ªå¼ºå¤§çš„æ¦‚ç‡æ¨æ–­åº“ï¼Œå¹¶ä¸”æ˜¯æœ¬ä¹¦åé¢å®è·µä¾‹å­ä¸­çš„ä¸€ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ã€‚
- en: Now that weâ€™ve covered these fundamentals, weâ€™re ready to see how the concepts
    weâ€™ve encountered so far can be applied in the implementation of several key BDL
    models. Weâ€™ll learn about the advantages and disadvantages of these approaches,
    and how to apply them to a variety of real-world problems. Continue on to [*ChapterÂ 5*](CH5.xhtml#x1-600005),
    [*Principled Approaches for Bayesian* *Deep Learning*](CH5.xhtml#x1-600005), where
    weâ€™ll learn about two key principled approaches for BDL.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å·²ç»æ¶µç›–äº†è¿™äº›åŸºç¡€çŸ¥è¯†ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½çœ‹çœ‹æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢é‡åˆ°çš„æ¦‚å¿µå¦‚ä½•åº”ç”¨åˆ°å¤šä¸ªå…³é”®BDLæ¨¡å‹çš„å®ç°ä¸­ã€‚æˆ‘ä»¬å°†äº†è§£è¿™äº›æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶å­¦ä¹ å¦‚ä½•å°†å®ƒä»¬åº”ç”¨äºå„ç§å®é™…é—®é¢˜ã€‚ç»§ç»­é˜…è¯»[*ç¬¬5ç« *](CH5.xhtml#x1-600005)ï¼Œ[*è´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸåˆ™æ€§æ–¹æ³•*](CH5.xhtml#x1-600005)ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†å­¦ä¹ ä¸¤ç§å…³é”®çš„BDLåŸåˆ™æ€§æ–¹æ³•ã€‚
- en: 4.6 Further reading
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 è¿›ä¸€æ­¥é˜…è¯»
- en: 'This chapter has introduced the material necessary to start working with BDL;
    however, there are many resources that go into more depth on the topics of uncertainty
    sources. The following are a few recommendations for readers interested in exploring
    the theory and code in more depth:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« ä»‹ç»äº†å¼€å§‹ä½¿ç”¨ BDL æ‰€éœ€çš„ææ–™ï¼›ç„¶è€Œï¼Œè¿˜æœ‰è®¸å¤šèµ„æºå¯ä»¥æ›´æ·±å…¥åœ°æ¢è®¨ä¸ç¡®å®šæ€§æ¥æºçš„ç›¸å…³ä¸»é¢˜ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›æ¨èï¼Œä¾›é‚£äº›æœ‰å…´è¶£æ›´æ·±å…¥æ¢ç´¢ç†è®ºå’Œä»£ç çš„è¯»è€…å‚è€ƒï¼š
- en: '*Machine Learning: A Probabilistic Perspective, Murphy*: Kevin Murphyâ€™s extremely
    popular book on machine learning has become a staple for students and researchers
    in the field. This book provides a detailed treatment of machine learning from
    a probabilistic standpoint, unifying concepts from statistics, machine learning,
    and Bayesian probability.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœºå™¨å­¦ä¹ ï¼šä¸€ç§æ¦‚ç‡è§†è§’ï¼ŒMurphy*ï¼šå‡¯æ–‡Â·å¢¨è²ï¼ˆKevin Murphyï¼‰å…³äºæœºå™¨å­¦ä¹ çš„æä¸ºæµè¡Œçš„ä¹¦ç±å·²æˆä¸ºè¯¥é¢†åŸŸå­¦ç”Ÿå’Œç ”ç©¶äººå‘˜çš„å¿…å¤‡è¯»ç‰©ã€‚æœ¬ä¹¦ä»æ¦‚ç‡çš„è§’åº¦è¯¦ç»†ä»‹ç»äº†æœºå™¨å­¦ä¹ ï¼Œç»Ÿä¸€äº†ç»Ÿè®¡å­¦ã€æœºå™¨å­¦ä¹ å’Œè´å¶æ–¯æ¦‚ç‡çš„æ¦‚å¿µã€‚'
- en: '*TensorFlow Probability* *Tutorials*: in this book, weâ€™ll see how TensorFlow
    Probability can be used to develop BNNs, but their website includes a wide array
    of tutorials addressing probabilistic programming more generally: [https://www.tensorflow.org/probability/overview](https://www.tensorflow.org/probability/overview)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow Probability* *æ•™ç¨‹*ï¼šåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ TensorFlow Probability å¼€å‘ BNNsï¼Œä½†ä»–ä»¬çš„ç½‘ç«™æä¾›äº†å¹¿æ³›çš„æ•™ç¨‹ï¼Œæ›´å¹¿æ³›åœ°æ¶‰åŠæ¦‚ç‡ç¼–ç¨‹ï¼š[https://www.tensorflow.org/probability/overview](https://www.tensorflow.org/probability/overview)'
- en: '*Pyro Tutorials*: Pyro is a PyTorch-based library for probabilistic programming
    â€“ itâ€™s another powerful tool for Bayesian inference, and the Pyro website has
    many excellent tutorials and examples of probabilistic inference: [https://pyro.ai/](https://pyro.ai/).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pyroæ•™ç¨‹*ï¼šPyro æ˜¯ä¸€ä¸ªåŸºäº PyTorch çš„æ¦‚ç‡ç¼–ç¨‹åº“â€”â€”è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„è´å¶æ–¯æ¨æ–­å·¥å…·ï¼ŒPyro ç½‘ç«™ä¸Šæœ‰è®¸å¤šå…³äºæ¦‚ç‡æ¨æ–­çš„ä¼˜ç§€æ•™ç¨‹å’Œç¤ºä¾‹ï¼š[https://pyro.ai/](https://pyro.ai/)'
