- en: Chapter 6. Disentangled Representation GANs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 解耦表示的GANs
- en: As we've explored, GANs can generate meaningful outputs by learning the data distribution.
    However, there was no control over the attributes of the outputs generated. Some
    variations of GANs like **Conditional GAN** (**CGAN**) and **Auxiliary Classifier
    GAN** (**ACGAN**), as discussed in the previous chapter are able to train a generator
    that is conditioned to synthesize specific outputs. For example, both CGAN and
    ACGAN can induce the generator to produce a specific MNIST digit. This is achieved
    by using both a 100-dim noise code and the corresponding one-hot label as inputs.
    However, other than the one-hot label, we have no other ways to control the properties
    of generated outputs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所探讨的，GAN通过学习数据分布可以生成有意义的输出。然而，对于生成的输出属性并没有控制。一些GAN的变体，如**条件GAN**（**CGAN**）和**辅助分类器GAN**（**ACGAN**），如前一章所讨论的，能够训练一个受条件限制的生成器来合成特定的输出。例如，CGAN和ACGAN都能引导生成器生成特定的MNIST数字。这是通过使用一个100维的噪声代码和相应的独热标签作为输入来实现的。然而，除了独热标签之外，我们没有其他方法来控制生成输出的属性。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For a review on CGAN and ACGAN, please see [Chapter 4](ch04.html "Chapter 4. Generative
    Adversarial Networks (GANs)"), *Generative Adversarial Networks (GANs),* and [Chapter
    5](ch05.html "Chapter 5. Improved GANs"), *Improved GANs*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 关于CGAN和ACGAN的回顾，请参见[第4章](ch04.html "第4章 生成对抗网络（GANs）")，*生成对抗网络（GANs）*，以及[第5章](ch05.html
    "第5章 改进的GANs")，*改进的GANs*。
- en: In this chapter, we will be covering the variations of GANs that enable us to
    modify the generator outputs. In the context of the MNIST dataset, apart from
    which number to produce, we may find that we want to control the writing style.
    This could involve the tilt or the width of the desired digit. In other words,
    GANs can also learn disentangled latent codes or representations that we can use
    to vary the attributes of the generator outputs. A disentangled code or representation
    is a tensor that can change a specific feature or attribute of the output data
    while not affecting the other attributes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一些能够修改生成器输出的GAN变体。在MNIST数据集的背景下，除了生成哪个数字，我们可能还希望控制书写风格。这可能涉及到所需数字的倾斜度或宽度。换句话说，GAN也可以学习解耦的潜在代码或表示，我们可以使用这些代码或表示来改变生成器输出的属性。解耦的代码或表示是一个张量，它可以改变输出数据的特定特征或属性，而不会影响其他属性。
- en: 'In the first section of this chapter, we will be discussing **InfoGAN**: *Interpretable
    Representation Learning by Information Maximizing Generative Adversarial Nets*
    [1], an extension to GANs. InfoGAN learns the disentangled representations in
    an unsupervised manner by maximizing the mutual information between the input
    codes and the output observation. On the MNIST dataset, InfoGAN disentangles the writing
    styles from digits dataset.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分，我们将讨论**InfoGAN**：*通过信息最大化生成对抗网络进行可解释表示学习* [1]，这是一种GAN的扩展。InfoGAN通过最大化输入代码和输出观察之间的互信息，以无监督的方式学习解耦的表示。在MNIST数据集上，InfoGAN将书写风格与数字数据集解耦。
- en: In the following part of the chapter, we'll also be discussing the **Stacked
    Generative Adversarial Networks** or **StackedGAN** [2], another extension to
    GANs. StackedGAN uses a pretrained encoder or classifier in order to aid in disentangling
    the latent codes. StackedGAN can be viewed as a stack of models, with each being
    made of an encoder and a GAN. Each GAN is trained in an adversarial manner by
    using the input and output data of the corresponding encoder.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后续部分，我们还将讨论**堆叠生成对抗网络**（**StackedGAN**）[2]，这是GAN的另一种扩展。StackedGAN使用预训练的编码器或分类器来帮助解耦潜在代码。StackedGAN可以视为一堆模型，每个模型由一个编码器和一个GAN组成。每个GAN通过使用相应编码器的输入和输出数据，以对抗的方式进行训练。
- en: 'In summary, the goal of this chapter is to present:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章的目标是展示：
- en: The concepts of disentangled representations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解耦表示的概念
- en: The principles of both InfoGAN and StackedGAN
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: InfoGAN和StackedGAN的原理
- en: Implementation of both InfoGAN and StackedGAN using Keras
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keras实现InfoGAN和StackedGAN
- en: Disentangled representations
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解耦表示
- en: 'The original GAN was able to generate meaningful outputs, but the downside
    was that it couldn''t be controlled. For example, if we trained a GAN to learn
    the distribution of celebrity faces, the generator would produce new images of
    celebrity-looking people. However, there is no way to influence the generator
    on the specific attributes of the face that we want. For example, we''re unable
    to ask the generator for a face of a female celebrity with long black hair, a
    fair complexion, brown eyes, and whose smiling. The fundamental reason for this
    is because the 100-dim noise code that we use entangles all of the salient attributes
    of the generator outputs. We can recall that in Keras, the 100-dim code was generated
    by random sampling of uniform noise distribution:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的 GAN 能够生成有意义的输出，但其缺点是无法进行控制。例如，如果我们训练一个 GAN 来学习名人面孔的分布，生成器会生成新的名人样貌的人物图像。然而，无法控制生成器生成我们想要的面孔的特定特征。例如，我们无法要求生成器生成一张女性名人面孔，长黑发，皮肤白皙，棕色眼睛，正在微笑。根本原因是我们使用的
    100 维噪声代码将生成器输出的所有显著特征都缠结在一起。我们可以回忆起在 Keras 中，100 维代码是通过从均匀噪声分布中随机抽样生成的：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If we are able to modify the original GAN, such that we were able to separate
    the code or representation into entangled and disentangled interpretable latent
    codes, we would be able to tell the generator what to synthesize.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能够修改原始 GAN，使其能够将代码或表示分离为缠结和解耦的可解释潜在代码，我们将能够告诉生成器生成我们所需的内容。
- en: 'Following figure shows us a GAN with an entangled code and its variation with
    a mixture of entangled and disentangled representations. In the context of the
    hypothetical celebrity face generation, with the disentangled codes, we are able
    to indicate the gender, hairstyle, facial expression, skin complexion and eye
    color of the face we wish to generate. The *n–dim* entangled code is still needed
    to represent all the other facial attributes that we have not disentangled like
    the face shape, facial hair, eye-glasses, as just three examples. The concatenation
    of entangled and disentangled codes serves as the new input to the generator.
    The total dimension of the concatenated code may not be necessarily 100:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的图像展示了一个具有缠结代码的 GAN 及其结合缠结和解耦表示的变化。在假设的名人面孔生成背景下，使用解耦代码，我们可以指定我们希望生成的面孔的性别、发型、面部表情、肤色和眼睛颜色。*n–dim*
    的缠结代码仍然用于表示我们尚未解耦的所有其他面部特征，例如面部形状、面部毛发、眼镜，仅举三个例子。缠结和解耦代码的拼接作为生成器的新输入。拼接代码的总维度不一定是
    100：
- en: '![Disentangled representations](img/B08956_06_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![解耦表示](img/B08956_06_01.jpg)'
- en: 'Figure 6.1.1: The GAN with the entangled code and its variation with both entangled
    and disentangled codes. This example is shown in the context of celebrity face
    generation.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1.1：具有缠结代码的 GAN 以及其结合缠结和解耦代码的变化。此示例展示了名人面孔生成的背景。
- en: 'Looking at preceding figure, it appears that GANs with disentangled representations
    can also be optimized in the same way as a vanilla GAN can be. This is because
    the generator output can be represented as:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图像来看，具有解耦表示的 GAN 也可以像普通的 GAN 一样进行优化。这是因为生成器的输出可以表示为：
- en: '![Disentangled representations](img/B08956_06_001.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![解耦表示](img/B08956_06_001.jpg)'
- en: (Equation 6.1.1)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: （方程式 6.1.1）
- en: The code
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 代码
- en: '![Disentangled representations](img/B08956_06_002.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![解耦表示](img/B08956_06_002.jpg)'
- en: 'is made of two elements:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由两个元素组成：
- en: Incompressible entangled noise code similar to GANs *z* or noise vector.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似于 GAN 的不可压缩缠结噪声代码 *z* 或噪声向量。
- en: Latent codes, *c**1*,*c**2*,…,*c**L*, which represent the interpretable disentangled
    codes of the data distribution. Collectively all latent codes are represented
    by *c*.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 潜在代码，*c**1*,*c**2*,…,*c**L*，表示数据分布的可解释解耦代码。所有潜在代码统一表示为 *c*。
- en: 'For simplicity, all the latent codes are assumed to be independent:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，假设所有潜在代码都是独立的：
- en: '![Disentangled representations](img/B08956_06_003.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![解耦表示](img/B08956_06_003.jpg)'
- en: (Equation 6.1.2)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: （方程式 6.1.2）
- en: The generator function
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器函数
- en: '![Disentangled representations](img/B08956_06_004.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![解耦表示](img/B08956_06_004.jpg)'
- en: is provided with both the incompressible noise code and the latent codes. From
    the point of view of the generator, optimizing
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了不可压缩的噪声代码和潜在代码。从生成器的角度来看，优化
- en: '![Disentangled representations](img/B08956_06_005.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![解耦表示](img/B08956_06_005.jpg)'
- en: is the same as optimizing *z*. The generator network will simply ignore the constraint
    imposed by the disentangled codes when coming up with a solution. The generator
    learns the distribution
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 之间的互信息与优化 *z* 相同。生成器网络在得出解决方案时会忽略由解耦代码施加的约束。生成器学习分布
- en: '![Disentangled representations](img/B08956_06_006.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![Disentangled representations](img/B08956_06_006.jpg)'
- en: . This will practically defeat the objective of disentangled representations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 。这将实际破坏解耦表示的目标。
- en: InfoGAN
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: InfoGAN
- en: To enforce the disentanglement of codes, InfoGAN proposed a regularizer to the
    original loss function that maximizes the mutual information between the latent
    codes *c* and
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加强代码的解耦，InfoGAN向原始损失函数中提出了一个正则化项，该项最大化潜在代码 *c* 和
- en: '![InfoGAN](img/B08956_06_007.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_007.jpg)'
- en: ':'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ：
- en: '![InfoGAN](img/B08956_06_008.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_008.jpg)'
- en: (Equation 6.1.3)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: （方程6.1.3）
- en: The regularizer forces the generator to consider the latent codes when it formulates
    a function that synthesizes the fake images. In the field of information theory,
    the mutual information between latent codes *c* and
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该正则化项迫使生成器在构建合成假图像的函数时考虑潜在代码。在信息论领域，潜在代码 *c* 和
- en: '![InfoGAN](img/B08956_06_009.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_009.jpg)'
- en: 'is defined as:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 定义为：
- en: '![InfoGAN](img/B08956_06_010.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_010.jpg)'
- en: (Equation 6.1.4)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: （方程6.1.4）
- en: Where *H*(*c*) is the entropy of the latent code *c* and
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *H*(*c*) 是潜在代码 *c* 的熵，和
- en: '![InfoGAN](img/B08956_06_011.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_011.jpg)'
- en: is the conditional entropy of *c,* after observing the output of the generator,
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 是观察到生成器输出后的 *c* 的条件熵，
- en: '![InfoGAN](img/B08956_06_012.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_012.jpg)'
- en: . Entropy is a measure of uncertainty of a random variable or an event. For
    example, information like, *the sun rises in the east*, has low entropy. Whereas,
    *winning the jackpot in the lottery* has high entropy.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 。熵是衡量随机变量或事件不确定性的一个度量。例如，像 *太阳从东方升起* 这样的信息熵较低。而 *中彩票中大奖* 的熵则较高。
- en: In *Equation 6.1.4*, maximizing the mutual information means minimizing
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *方程6.1.4* 中，最大化互信息意味着最小化
- en: '![InfoGAN](img/B08956_06_013.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_013.jpg)'
- en: or decreasing the uncertainty in the latent code upon observing the generated
    output. This makes sense since, for example, in the MNIST dataset, the generator
    becomes more confident in synthesizing the digit 8 if the GAN sees that it observed
    the digit 8.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 或者通过观察生成的输出减少潜在代码的不确定性。这是有道理的，例如，在MNIST数据集中，如果GAN看到它观察到数字8，生成器会对合成数字8更有信心。
- en: However, it is hard to estimate
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，估计它是很难的
- en: '![InfoGAN](img/B08956_06_014.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_014.jpg)'
- en: since it requires knowledge of the posterior
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它需要了解后验知识
- en: '![InfoGAN](img/B08956_06_015.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_015.jpg)'
- en: ', which is something that we don''t have access to. The workaround is to estimate
    the lower bound of mutual information by estimating the posterior with an auxiliary
    distribution *Q*(*c|x*). InfoGAN estimates the lower bound of mutual information
    as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ，而这是我们无法访问的。解决方法是通过估计辅助分布 *Q*(*c|x*) 来估算互信息的下界。InfoGAN 通过以下方式估算互信息的下界：
- en: '![InfoGAN](img/B08956_06_016.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_016.jpg)'
- en: (Equation 6.1.5)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: （方程6.1.5）
- en: In InfoGAN, *H*(*c*) is assumed to be a constant. Therefore, maximizing the
    mutual information is a matter of maximizing the expectation. The generator must
    be confident that it has generated an output with the specific attributes. We
    should note that the maximum value of this expectation is zero. Therefore, the
    maximum of the lower bound of the mutual information is *H*(*c*). In InfoGAN,
    *Q*(*c*|*x*) for discrete latent codes can be represented by *softmax* nonlinearity.
    The expectation is the negative `categorical_crossentropy` loss in Keras.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在InfoGAN中，*H*(*c*)被假定为常数。因此，最大化互信息就是最大化期望值。生成器必须确信它已经生成了具有特定属性的输出。我们应该注意到，这个期望值的最大值是零。因此，互信息下界的最大值是
    *H*(*c*)。在InfoGAN中，离散潜在代码的 *Q*(*c*|*x*) 可以通过 *softmax* 非线性表示。期望值是Keras中负的 `categorical_crossentropy`
    损失。
- en: For continuous codes of a single dimension, the expectation is a double integral
    over *c* and *x*. This is due to the expectation that samples from both disentangled
    code distribution and generator distribution. One way of estimating the expectation
    is by assuming the samples as a good measure of continuous data. Therefore, the
    loss is estimated as *c* log *Q*(*c*|*x*).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单维连续代码，期望是对 *c* 和 *x* 的双重积分。这是因为期望从解缠代码分布和生成器分布中采样。估计期望的一种方法是假设样本是连续数据的良好度量。因此，损失被估计为
    *c* log *Q*(*c*|*x*)。
- en: 'To complete the network of InfoGAN, we should have an implementation of *Q*(*c*|*x*).
    For simplicity, the network *Q* is an auxiliary network attached to the second
    to last layer of the discriminator. Therefore, this has a minimal impact on the
    training of the original GAN. Following figure shows InfoGAN network diagram:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成 InfoGAN 网络，我们应该有一个 *Q*(*c*|*x*) 的实现。为了简单起见，网络 *Q* 是附加在判别器倒数第二层的辅助网络。因此，这对原始
    GAN 的训练影响最小。下图展示了 InfoGAN 的网络图：
- en: '![InfoGAN](img/B08956_06_02.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_02.jpg)'
- en: 'Figure 6.1.2: A network diagram showing the discriminator and generator training
    in InfoGAN'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1.2：展示 InfoGAN 中判别器和生成器训练的网络图
- en: Following table shows the loss functions of InfoGAN as compared to the original
    GAN. The loss functions of InfoGAN differ from the original GAN by an additional
    term
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了 InfoGAN 相对于原始 GAN 的损失函数。InfoGAN 的损失函数相比原始 GAN 多了一个额外的项
- en: '![InfoGAN](img/B08956_06_017.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_017.jpg)'
- en: where
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '![InfoGAN](img/B08956_06_018.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_018.jpg)'
- en: is a small positive constant. Minimizing the loss function of InfoGAN translates
    to minimizing the loss of the original GAN and maximizing the mutual information
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个小的正常数。最小化 InfoGAN 的损失函数意味着最小化原始 GAN 的损失并最大化互信息
- en: '![InfoGAN](img/B08956_06_019.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_019.jpg)'
- en: .
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: '| Network | Loss Functions | Number |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 损失函数 | 数字 |'
- en: '| --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GAN | ![InfoGAN](img/B08956_06_020.jpg)![InfoGAN](img/B08956_06_021.jpg)
    | 4.1.14.1.5 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| GAN | ![InfoGAN](img/B08956_06_020.jpg)![InfoGAN](img/B08956_06_021.jpg)
    | 4.1.14.1.5 |'
- en: '| InfoGAN | ![InfoGAN](img/B08956_06_022.jpg)![InfoGAN](img/B08956_06_023.jpg)For
    continuous codes, InfoGAN recommends a value of![InfoGAN](img/B08956_06_024.jpg).
    In our example, we set![InfoGAN](img/B08956_06_025.jpg). For discrete codes, InfoGAN
    recommends![InfoGAN](img/B08956_06_026.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '| InfoGAN | ![InfoGAN](img/B08956_06_022.jpg)![InfoGAN](img/B08956_06_023.jpg)对于连续代码，InfoGAN
    推荐一个值为![InfoGAN](img/B08956_06_024.jpg)。在我们的示例中，我们设置为![InfoGAN](img/B08956_06_025.jpg)。对于离散代码，InfoGAN
    推荐![InfoGAN](img/B08956_06_026.jpg)'
- en: 'Table 6.1.1: A comparison between the loss functions of GAN and InfoGAN'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6.1.1：GAN 和 InfoGAN 损失函数的比较
- en: . | 6.1.16.1.2 |
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: . | 6.1.16.1.2 |
- en: 'If applied on the MNIST dataset, InfoGAN can learn the disentangled discrete
    and continuous codes in order to modify the generator output attributes. For example,
    like CGAN and ACGAN, the discrete code in the form of a 10-dim one-hot label will
    be used to specify the digit to generate. However, we can add two continuous codes,
    one for controlling the angle of writing style and another for adjusting the stroke
    width. Following figure shows the codes for the MNIST digit in InfoGAN. We retain
    the entangled code with a smaller dimensionality to represent all other attributes:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果应用于 MNIST 数据集，InfoGAN 可以学习解缠的离散和连续代码，从而修改生成器的输出属性。例如，像 CGAN 和 ACGAN 一样，离散代码以
    10 维独热标签的形式用于指定要生成的数字。然而，我们可以添加两个连续代码，一个用于控制书写风格的角度，另一个用于调整笔画宽度。下图展示了 InfoGAN
    中 MNIST 数字的代码。我们保留较小维度的纠缠代码来表示所有其他属性：
- en: '![InfoGAN](img/B08956_06_03.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN](img/B08956_06_03.jpg)'
- en: 'Figure 6.1.3: The codes for both GAN and InfoGAN in the context of MNIST dataset'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1.3：在 MNIST 数据集背景下 GAN 和 InfoGAN 的代码
- en: Implementation of InfoGAN in Keras
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: InfoGAN 在 Keras 中的实现
- en: To implement InfoGAN on MNIST dataset, there are some changes that need to be
    made in the base code of ACGAN. As highlighted in following listing, the generator
    concatenates both entangled (*z* noise code) and disentangled codes (one-hot label
    and continuous codes) to serve as input. The builder functions for the generator
    and discriminator are also implemented in `gan.py` in the `lib` folder.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 MNIST 数据集上实现 InfoGAN，需要对 ACGAN 的基础代码进行一些修改。如以下列表所示，生成器将纠缠的（*z* 噪声代码）和解缠的代码（独热标签和连续代码）拼接起来作为输入。生成器和判别器的构建函数也在
    `lib` 文件夹中的 `gan.py` 中实现。
- en: Note
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete code is available on GitHub:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码可以在 GitHub 上找到：
- en: '[https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)'
- en: 'Listing 6.1.1, `infogan-mnist-6.1.1.py` shows us how the InfoGAN generator
    concatenates both entangled and disentangled codes to serve as input:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1.1，`infogan-mnist-6.1.1.py`展示了InfoGAN生成器如何将纠缠的和解耦的代码连接在一起作为输入：
- en: '[PRE1]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding listing shows the discriminator and *Q*-Network with the original
    default GAN output. The three auxiliary outputs corresponding to discrete code
    (for one-hot label) `softmax` prediction and the continuous codes probabilities
    given the input MNIST digit image are highlighted.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的列表展示了带有原始默认GAN输出的判别器和*Q*网络。突出了与离散代码（用于一热标签）`softmax`预测和给定输入MNIST数字图像的连续代码概率相对应的三个辅助输出。
- en: 'Listing 6.1.2, `infogan-mnist-6.1.1.py`. InfoGAN discriminator and *Q*-Network:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1.2，`infogan-mnist-6.1.1.py`。InfoGAN判别器和*Q*网络：
- en: '[PRE2]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Figure 6.1.4* shows the InfoGAN model in Keras. Building the discriminator
    and adversarial models also requires a number of changes. The changes are on the
    loss functions used. The original discriminator loss function `binary_crossentropy`,
    the `categorical_crossentropy` for discrete code, and the `mi_loss` function for
    each continuous code comprise the overall loss function. Each loss function is
    given a weight of 1.0, except for the `mi_loss` function which is given 0.5 corresponding
    to ![Implementation of InfoGAN in Keras](img/B08956_06_027.jpg) for the continuous
    code.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.1.4*展示了Keras中的InfoGAN模型。构建判别器和对抗模型还需要一些更改。更改主要体现在所使用的损失函数上。原始的判别器损失函数是`binary_crossentropy`，用于离散代码的`categorical_crossentropy`，以及针对每个连续代码的`mi_loss`函数，构成了整体损失函数。每个损失函数的权重为1.0，除了`mi_loss`函数，其权重为0.5，适用于![InfoGAN在Keras中的实现](img/B08956_06_027.jpg)连续代码。'
- en: '*Listing 6.1.3* highlights the changes made. However, we should note that by
    using the builder function, the discriminator is instantiated as:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表6.1.3*突出了所做的更改。然而，我们应该注意到，通过使用构建器函数，判别器的实例化方式如下：'
- en: '[PRE3]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The generator is created by:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器是通过以下方式创建的：
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Implementation of InfoGAN in Keras](img/B08956_06_04.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN在Keras中的实现](img/B08956_06_04.jpg)'
- en: 'Figure 6.1.4: The InfoGAN Keras model'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1.4：InfoGAN Keras模型
- en: 'Listing 6.1.3, `infogan-mnist-6.1.1.py` shows us the mutual Information loss
    function as used in building the InfoGAN discriminator and adversarial networks:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1.3，`infogan-mnist-6.1.1.py`展示了在构建InfoGAN判别器和对抗网络时使用的互信息损失函数：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As far as the training is concerned, we can see that InfoGAN is similar to ACGAN
    except that we need to supply *c* for the continuous code. *c* is drawn from normal
    distribution with a standard deviation of 0.5 and mean of 0.0\. We'll use randomly
    sampled labels for the fake data and dataset class labels for the real data to
    represent discrete latent code. Following listing highlights the changes made
    on the training function. Similar to all previous GANs, the discriminator and
    generator (through adversarial) are trained alternately. During adversarial training,
    the discriminator weights are frozen. Sample generator output images are saved
    every 500 interval steps by using the `gan.py plot_images()` function.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 就训练而言，我们可以看到InfoGAN与ACGAN类似，唯一的区别是我们需要为连续代码提供*c*。*c*来自标准差为0.5、均值为0.0的正态分布。对于假数据，我们将使用随机采样的标签，而对于真实数据，我们将使用数据集类标签来表示离散潜在代码。以下列表突出了在训练函数中所做的更改。与之前的所有GAN类似，判别器和生成器（通过对抗）交替训练。在对抗训练期间，判别器的权重被冻结。每500步间隔使用`gan.py
    plot_images()`函数保存生成器输出的样本图像。
- en: 'Listing 6.1.4, `infogan-mnist-6.1.1.py` shows us how the training function
    for InfoGAN is similar to ACGAN. The only difference is that we supply continuous
    codes sampled from a normal distribution:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1.4，`infogan-mnist-6.1.1.py`展示了InfoGAN的训练函数如何类似于ACGAN。唯一的区别是我们提供从正态分布中采样的连续代码：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Generator outputs of InfoGAN
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: InfoGAN的生成器输出
- en: 'Similar to all previous GANs that have been presented to us, we''ve trained
    InfoGAN for 40,000 steps. After the training is completed, we''re able to run
    the InfoGAN generator to generate new outputs using the model saved on the `infogan_mnist.h5`
    file. The following validations are conducted:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们之前介绍的所有GAN，我们已将InfoGAN训练了40,000步。训练完成后，我们可以运行InfoGAN生成器，利用保存在`infogan_mnist.h5`文件中的模型生成新的输出。以下是进行的验证：
- en: 'Generate digits 0 to 9 by varying the discrete labels from 0 to 9\. Both continuous
    codes are set to zero. The results are shown in *Figure 6.1.5*. We can see that
    the InfoGAN discrete code can control the digits produced by the generator:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将离散标签从 0 到 9 变化，生成数字 0 到 9\. 两个连续编码都设置为零。结果如 *图 6.1.5* 所示。我们可以看到，InfoGAN 的离散编码能够控制生成器生成的数字：
- en: '[PRE7]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: to
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 到
- en: '[PRE8]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Examine the effect of the first continuous code to understand which attribute
    has been affected. We vary the first continuous code from -2.0 to 2.0 for digits
    0 to 9\. The second continuous code is set to 0.0\. *Figure 6.1.6* shows that
    the first continuous code controls the thickness of the digit:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查第一个连续编码的效果，了解哪个属性受到了影响。我们将第一个连续编码从 -2.0 变化到 2.0，数字从 0 到 9\. 第二个连续编码设置为 0.0\.
    *图 6.1.6* 显示第一个连续编码控制数字的粗细：
- en: '[PRE9]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Similar to the previous step, but instead focusing more on the second continuous
    code. *Figure 6.1.7* shows that the second continuous code controls the rotation
    angle (tilt) of the writing style:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与前一步骤类似，但重点更多放在第二个连续编码上。*图 6.1.7* 显示第二个连续编码控制书写风格的旋转角度（倾斜）：
- en: '[PRE10]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Generator outputs of InfoGAN](img/B08956_06_06.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN 生成器输出](img/B08956_06_06.jpg)'
- en: 'Figure 6.1.5: The images generated by the InfoGAN as the discrete code is varied
    from 0 to 9\. Both continuous codes are set to zero.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1.5：InfoGAN 生成的图像，当离散编码从 0 变化到 9 时。两个连续编码都设置为零。
- en: '![Generator outputs of InfoGAN](img/B08956_06_07.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN 生成器输出](img/B08956_06_07.jpg)'
- en: 'Figure 6.1.6: The images generated by InfoGAN as the first continuous code
    is varied from -2.0 to 2.0 for digits 0 to 9\. The second continuous code is set
    to zero. The first continuous code controls the thickness of the digit.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1.6：InfoGAN 生成的图像，当第一个连续编码从 -2.0 变化到 2.0 时，数字从 0 到 9\. 第二个连续编码设置为零。第一个连续编码控制数字的粗细。
- en: '![Generator outputs of InfoGAN](img/B08956_06_08.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![InfoGAN 生成器输出](img/B08956_06_08.jpg)'
- en: 'Figure 6.1.7: The images generated by InfoGAN as the second continuous code
    is varied from -2.0 to 2.0 for digits 0 to 9\. The first continuous code is set
    to zero. The second continuous code controls the rotation angle (tilt) of the
    writing style.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1.7：InfoGAN 生成的图像，当第二个连续编码从 -2.0 变化到 2.0 时，数字从 0 到 9\. 第一个连续编码设置为零。第二个连续编码控制书写风格的旋转角度（倾斜）。
- en: From these validation results, we can see that apart from the ability to generate
    MNIST looking digits, InfoGAN expanded the ability of conditional GANs such as CGAN
    and ACGAN. The network automatically learned two arbitrary codes that can control
    the specific attributes of the generator output. It would be interesting to see
    what additional attributes could be controlled if we increased the number of continuous
    codes beyond 2.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些验证结果中，我们可以看到，除了能够生成类似 MNIST 的数字外，InfoGAN 扩展了条件 GAN（如 CGAN 和 ACGAN）的能力。网络自动学习了两个任意编码，可以控制生成器输出的特定属性。如果我们将连续编码的数量增加到超过
    2 个，看看还能控制哪些其他属性，将会很有趣。
- en: StackedGAN
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StackedGAN
- en: In the same spirit as InfoGAN, StackedGAN proposes a method for disentangling
    latent representations for conditioning generator outputs. However, StackedGAN
    uses a different approach to the problem. Instead of learning how to condition
    the noise to produce the desired output, StackedGAN breaks down a GAN into a stack
    of GANs. Each GAN is trained independently in the usual discriminator-adversarial
    manner with its own latent code.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与 InfoGAN 同样的理念，StackedGAN 提出了通过分解潜在表示来调整生成器输出条件的方法。然而，StackedGAN 采用了不同的方式来解决这一问题。StackedGAN
    并非学习如何调整噪声以产生所需的输出，而是将 GAN 拆解成一堆 GAN。每个 GAN 都以通常的鉴别器对抗方式独立训练，并拥有自己的潜在编码。
- en: '*Figure 6.2.1* shows us how StackedGAN works in the context of the hypothetical
    celebrity face generation. Assuming that the *Encoder* network is trained to classify
    celebrity faces.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6.2.1* 向我们展示了 StackedGAN 如何在假设的名人面部生成背景下工作。假设 *编码器* 网络经过训练，能够分类名人面孔。'
- en: The *Encoder* network is made of a stack of simple encoders, *Encoder* *i* *where
    i = 0 … n - 1* corresponding to *n* features. Each encoder extracts certain facial
    features. For example, *Encoder*[0] may be the encoder for hairstyle features,
    *Features*1\. All the simple encoders contribute to making the overall *Encoder*
    perform correct predictions.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*编码器* 网络由一堆简单的编码器组成，*编码器* *i* *其中 i = 0 … n - 1* 对应于 *n* 个特征。每个编码器提取某些面部特征。例如，*编码器*[0]
    可能是用于发型特征的编码器，*特征*1。所有简单的编码器共同作用，使得整个 *编码器* 能正确预测。'
- en: The idea behind StackedGAN is that if we would like to build a GAN that generates
    fake celebrity faces, we should simply invert the *Encoder*. StackedGAN are made
    of a stack of simpler GANs, GAN[i] where i = 0 … *n* - 1 corresponding to *n*
    features. Each GAN[i] learns to invert the process of its corresponding encoder,
    *Encoder* [i]. For example, *GAN*[0] generates fake celebrity faces from fake
    hairstyle features which is the inverse of the *Encoder*[0] process.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: StackedGAN背后的思想是，如果我们想要构建一个生成虚假名人面孔的GAN，我们应该简单地反转*编码器*。StackedGAN由一堆简单的GAN组成，GAN[i]，其中i
    = 0 … *n* - 1对应*n*个特征。每个GAN[i]学习反转其对应编码器*编码器*[i]的过程。例如，*GAN*[0]从虚假的发型特征生成虚假的名人面孔，这是*编码器*[0]过程的反转。
- en: 'Each *GAN* [i] uses a latent code, *z* [i], that conditions its generator output.
    For example, the latent code, *z*[0], can alter the hairstyle from curly to wavy.
    The stack of GANs can also act as one to synthesize fake celebrity faces, completing
    the inverse process of the whole *Encoder*. The latent code of each *GAN*[i],
    *z* [i], can be used to alter specific attributes of fake celebrity faces:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 每个*GAN*[i]使用一个潜在代码*z*[i]，它决定生成器的输出。例如，潜在代码*z*[0]可以将发型从卷发改变为波浪发型。GAN堆叠也可以作为一个整体，用来合成虚假的名人面孔，完成整个*编码器*的反向过程。每个*GAN*[i]的潜在代码*z*[i]可用于改变虚假名人面孔的特定属性：
- en: '![StackedGAN](img/B08956_06_09.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN](img/B08956_06_09.jpg)'
- en: 'Figure 6.2.1: The basic idea of StackedGAN in the context of celebrity faces
    generation. Assuming that there is a hypothetical deep encoder network that can
    perform classification on celebrity faces, a StackedGAN simply inverts the process
    of the encoder.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.1：在生成名人面孔的背景下，StackedGAN的基本思想。假设存在一个假设的深度编码器网络，能够对名人面孔进行分类，StackedGAN只是反转编码器的过程。
- en: Implementation of StackedGAN in Keras
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Keras中实现StackedGAN
- en: 'The detailed network model of StackedGAN can be seen in the following figure.
    For conciseness, only two encoder-GANs per stack are shown. The figure may initially
    appear complex, but it is just a repetition of an encoder-GAN. Meaning that if
    we understood how to train one encoder-GAN, the rest uses the same concept. In
    the following section, we assume that the StackedGAN is designed for the MNIST
    digit generation:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: StackedGAN的详细网络模型可以在下图中看到。为了简洁起见，每个堆叠中仅显示了两个编码器-GAN。图看起来可能很复杂，但它只是编码器-GAN的重复。换句话说，如果我们理解了如何训练一个编码器-GAN，那么其他的也遵循相同的概念。在接下来的部分中，我们假设StackedGAN是为MNIST数字生成设计的：
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_10.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![在Keras中实现StackedGAN](img/B08956_06_10.jpg)'
- en: 'Figure 6.2.2: A StackedGAN is made of a stack of an encoder and GAN. The encoder
    is pre-trained to perform classification. *Generator*[1], *G*[1], learns to synthesize
    *f*[1][f] features conditioned on the fake label, *y* [f], and latent code, *z*[1][f].
    *Generator*[0], *G*[0], produces fake images using both the fake features, *f*[1][f]
    and latent code, *z*[0][f].'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.2：StackedGAN由编码器和GAN的堆叠组成。编码器经过预训练，用于执行分类任务。*生成器*[1]，*G*[1]，学习基于虚假标签*y*[f]和潜在代码*z*[1][f]合成*f*[1][f]特征。*生成器*[0]，*G*[0]，使用虚假特征*f*[1][f]和潜在代码*z*[0][f]生成虚假图像。
- en: 'StackedGAN starts with an *Encoder*. It could be a trained classifier that
    predicts the correct labels. The intermediate features vector, *f*[1][r], is made
    available for GAN training. For MNIST, we can use a CNN-based classifier similar
    to what we discussed in [Chapter 1](ch01.html "Chapter 1. Introducing Advanced
    Deep Learning with Keras"), *Introducing Advanced Deep Learning with Keras*. Following
    figure shows the *Encoder* and its network model implementation in Keras:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: StackedGAN以*编码器*开始。它可以是一个经过训练的分类器，用于预测正确的标签。中间特征向量*f*[1][r]可用于GAN训练。对于MNIST，我们可以使用类似于[第1章](ch01.html
    "第1章. 使用Keras介绍深度学习")中讨论的基于CNN的分类器，*使用Keras介绍深度学习*。下图显示了*编码器*及其在Keras中的网络模型实现：
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_11.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![在Keras中实现StackedGAN](img/B08956_06_11.jpg)'
- en: 'Figure 6.2.3: The encoder in StackedGAN is a simple CNN-based classifier'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.3：StackedGAN中的编码器是一个简单的基于CNN的分类器
- en: '*Listing* *6.2.1* shows the Keras code for preceding figure. It is similar
    to the CNN-based classifier in [Chapter 1](ch01.html "Chapter 1. Introducing Advanced
    Deep Learning with Keras"), *Introducing Advanced Deep Learning with Keras* except
    that we use a `Dense` layer to extract the 256-dim feature. There are two output
    models, *Encoder*[0] and *Encoder*[1]. Both will be used to train the StackedGAN.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表* *6.2.1*展示了前图的Keras代码。它类似于[第1章](ch01.html "第1章。Keras的高级深度学习介绍")中的基于CNN的分类器，*Keras的高级深度学习介绍*，除了我们使用`Dense`层提取256维特征。这里有两个输出模型，*Encoder*[0]和*Encoder*[1]。两者都将用于训练StackedGAN。'
- en: The *Encoder*[0] output, *f*[0][r], is the 256-dim feature vector that we want
    *Generator*[1] to learn to synthesize. It is available as an auxiliary output
    of *Encoder*[0], *E*[0]. The overall *Encoder* is trained to classify MNIST digits,
    *x* [r]. The correct labels, *y* [r], are predicted by *Encoder*[1], *E*[1]. In
    the process, the intermediate set of features, *f*[1]*r*, is learned and made
    available for *Generator*[0] training. Subscript *r* is used to emphasize and
    distinguish real data from fake data when the GAN is trained against this encoder.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*Encoder*[0]的输出，*f*[0][r]，是我们希望*Generator*[1]学习合成的256维特征向量。它作为*Encoder*[0]的辅助输出，*E*[0]。整体的*Encoder*被训练用于分类MNIST数字，*x*
    [r]。正确的标签，*y* [r]，由*Encoder*[1]，*E*[1]预测。在此过程中，中间特征集，*f*[1]*r*，被学习并可用于*Generator*[0]的训练。在训练GAN时，子脚本*r*用于强调并区分真实数据与假数据。'
- en: 'Listing 6.2.1, `stackedgan-mnist-6.2.1.py` shows encoder implementation in
    Keras:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2.1，`stackedgan-mnist-6.2.1.py`展示了在Keras中实现的编码器：
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '| Network | Loss Functions | Number |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 损失函数 | 编号 |'
- en: '| --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GAN | ![Implementation of StackedGAN in Keras](img/B08956_06_028.jpg)![Implementation
    of StackedGAN in Keras](img/B08956_06_029.jpg) | 4.1.14.1.5 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| GAN | ![Keras中StackedGAN的实现](img/B08956_06_028.jpg)![Keras中StackedGAN的实现](img/B08956_06_029.jpg)
    | 4.1.14.1.5 |'
- en: '| StackedGAN | ![Implementation of StackedGAN in Keras](img/B08956_06_030.jpg)![Implementation
    of StackedGAN in Keras](img/B08956_06_031.jpg)![Implementation of StackedGAN in
    Keras](img/B08956_06_032.jpg)![Implementation of StackedGAN in Keras](img/B08956_06_033.jpg)![Implementation
    of StackedGAN in Keras](img/B08956_06_034.jpg)where ![Implementation of StackedGAN
    in Keras](img/B08956_06_035.jpg) are weights and![Implementation of StackedGAN
    in Keras](img/B08956_06_036.jpg) | 6.2.16.2.26.2.36.2.46.2.5 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| StackedGAN | ![Keras中StackedGAN的实现](img/B08956_06_030.jpg)![Keras中StackedGAN的实现](img/B08956_06_031.jpg)![Keras中StackedGAN的实现](img/B08956_06_032.jpg)![Keras中StackedGAN的实现](img/B08956_06_033.jpg)![Keras中StackedGAN的实现](img/B08956_06_034.jpg)其中![Keras中StackedGAN的实现](img/B08956_06_035.jpg)是权重，![Keras中StackedGAN的实现](img/B08956_06_036.jpg)
    | 6.2.16.2.26.2.36.2.46.2.5 |'
- en: 'Table 6.2.1: A comparison between the loss functions of GAN and StackedGAN.
    ~*p* [data] means sampling from the corresponding encoder data (input, feature
    or output).'
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 表6.2.1：GAN与StackedGAN损失函数的比较。~*p* [data]表示从相应的编码器数据（输入、特征或输出）中采样。
- en: Given the *Encoder* inputs (*x*[r]) intermediate features (*f*1*r*) and labels
    (*y* *r*), each GAN is trained in the usual discriminator–adversarial manner.
    The loss functions are given by *Equation* *6.2.1* to *6.2.5* in *Table 6.2.1*.
    Equations *6.2.1* and *6.2.2* are the usual loss functions of the generic GAN.
    StackedGAN has two additional loss functions, **Conditional** and **Entropy**.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 给定*Encoder*输入（*x*[r]）中间特征（*f*1*r*）和标签（*y* *r*），每个GAN按照常规的鉴别器—对抗性方式进行训练。损失函数由*方程*
    *6.2.1*至*6.2.5*在*表6.2.1*中给出。方程*6.2.1*和*6.2.2*是通用GAN的常规损失函数。StackedGAN有两个额外的损失函数，**条件**和**熵**。
- en: The conditional loss function,
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 条件损失函数，
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_037.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![Keras中StackedGAN的实现](img/B08956_06_037.jpg)'
- en: 'in *Equation 6.2.3*, ensures that the generator does not ignore the input,
    *f*[i+1], when synthesizing the output, *f*[i], from input noise code *z*[i].
    The encoder, *Encoder*[i], must be able to recover the generator input by inverting
    the process of the generator, *Generator*[i]. The difference between the generator
    input and the recovered input using the encoder is measured by *L2* or Euclidean
    distance **Mean Squared Error** (**MSE**). *Figure 6.2.4* shows the network elements
    involved in the computation of ![Implementation of StackedGAN in Keras](img/B08956_06_038.jpg):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '在*方程6.2.3*中，确保生成器在合成输出*f*[i]时不会忽略输入*f*[i+1]，即使在输入噪声代码*z*[i]的情况下。编码器，*编码器*[i]，必须能够通过逆转生成器*生成器*[i]的过程来恢复生成器输入。生成器输入与通过编码器恢复的输入之间的差异由*L2*或欧几里得距离**均方误差**（**MSE**）衡量。*图6.2.4*展示了参与计算的网络元素！[StackedGAN在Keras中的实现](img/B08956_06_038.jpg):'
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_12.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_12.jpg)'
- en: 'Figure 6.2.4: A simpler version of Figure 6.2.3 showing only the network elements
    involved in the computation of ![Implementation of StackedGAN in Keras](img/B08956_06_039.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.4：图6.2.3的简化版本，仅显示参与计算的网络元素！[StackedGAN在Keras中的实现](img/B08956_06_039.jpg)
- en: The conditional loss function, however, introduces a new problem for us. The
    generator ignores the input noise code, *z* *i* and simply relies on *f* [i+1].
    Entropy loss function,
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，条件损失函数引入了一个新问题。生成器忽略输入的噪声代码，*z* *i*，并仅依赖于*f* [i+1]。熵损失函数，
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_40.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_40.jpg)'
- en: in *Equation* *6.2.4*, ensures that the generator does not ignore the noise
    code, *z* *i*. The *Q*-Network recovers the noise code from the output of the
    generator. The difference between the recovered noise and the input noise is also
    measured by *L2* or the MSE. Following figure shows the network elements involved
    in the computation of
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在*方程* *6.2.4*中，确保生成器不忽略噪声代码，*z* *i*。*Q*网络从生成器的输出中恢复噪声代码。恢复的噪声与输入噪声之间的差异也通过*L2*或均方误差（MSE）进行测量。下图展示了参与计算的网络元素
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_041.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_041.jpg)'
- en: ':'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ':'
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_13.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_13.jpg)'
- en: 'Figure 6.2.5: A simpler version of Figure 6.2.3 only showing us the network
    elements involved in the computation of'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.5：图6.2.3的简化版本，仅展示了参与计算的网络元素
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_042.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_042.jpg)'
- en: The last loss function is similar to the usual GAN loss. It's made of a discriminator
    loss
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个损失函数与通常的GAN损失相似。它由一个判别器损失组成
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_043.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_043.jpg)'
- en: and a generator (through adversarial) loss
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以及一个生成器（通过对抗）损失
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_044.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_044.jpg)'
- en: '. Following figure shows us the elements involved in the GAN loss:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了我们GAN损失中涉及的元素：
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_14.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_14.jpg)'
- en: 'Figure 6.2.6: A simpler version of Figure 6.2.3 showing only the network elements
    involved in the computation of'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.6：图6.2.3的简化版本，仅展示了参与计算的网络元素
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_045.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_045.jpg)'
- en: and
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_46.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN在Keras中的实现](img/B08956_06_46.jpg)'
- en: In *Equation* *6.2.5*, the weighted sum of the three generator loss functions
    is the final generator loss function. In the Keras code that we will present,
    all the weights are set to 1.0, except for the entropy loss which is set to 10.0\.
    In *Equation 6.2.1* to *Equation 6.2.5*, *i* refers to the encoder and GAN group
    id or level. In the original paper, the network is first trained independently
    and then jointly. During independent training, the encoder is trained first. During
    joint training, both real and fake data are used.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在*方程* *6.2.5*中，三个生成器损失函数的加权和是最终的生成器损失函数。在我们将要展示的Keras代码中，所有权重都设置为1.0，除了熵损失设置为10.0。*方程6.2.1*至*方程6.2.5*中，*i*表示编码器和GAN组ID或层级。在原始论文中，网络首先独立训练，然后进行联合训练。在独立训练期间，先训练编码器。在联合训练期间，使用真实数据和伪造数据。
- en: 'The implementation of the StackedGAN generator and discriminator in Keras requires
    few changes to provide auxiliary points to access the intermediate features. *Figure
    6.2.7* shows the generator Keras model. *Listing 6.2.2* illustrates the function
    that builds two generators (`gen0` and `gen1`) corresponding to *Generator*0 and
    *Generator*[1]. The `gen1` generator is made of three `Dense` layers with label
    and the noise code *z*1*f* as inputs. The third layer generates the fake *f*[1]*f*
    feature. The `gen0` generator is similar to other GAN generators that we''ve presented
    and can be instantiated using the generator builder in `gan.py`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: StackedGAN的生成器和判别器的实现仅需对Keras作少量修改，以便提供辅助点以访问中间特征。*图6.2.7*展示了生成器Keras模型。*列表6.2.2*阐明了构建两个生成器的函数（`gen0`
    和 `gen1`），它们分别对应 *生成器*0 和 *生成器*1。`gen1`生成器由三个`Dense`层组成，标签和噪声编码 *z*1*f* 作为输入。第三层生成伪造的
    *f*[1]*f* 特征。`gen0`生成器与我们之前介绍的其他GAN生成器相似，可以通过`gan.py`中的生成器构建器进行实例化：
- en: '[PRE12]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `gen0` input is *f*[1] features and the noise code *z*[0]. The output is
    the generated fake image, *x*[*f*]:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`gen0` 输入是 *f* 特征和噪声编码 *z*。[0] 输出是生成的伪造图像，*x*[*f*]：'
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_15.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![Keras中StackedGAN的实现](img/B08956_06_15.jpg)'
- en: 'Figure 6.2.7: A StackedGAN Generator model in Keras'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.7：Keras中的StackedGAN生成器模型
- en: 'Listing 6.2.2, `stackedgan-mnist-6.2.1.py` shows us generator implementation
    in Keras:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2.2，`stackedgan-mnist-6.2.1.py`展示了我们在Keras中实现生成器的代码：
- en: '[PRE13]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*Figure 6.2.8* shows the discriminator Keras model. We provide the functions
    to build *Discriminator*[0] and *Discriminator*[1] (`dis0` and `dis1`).The `dis0`
    discriminator is similar to a GAN discriminator except for the feature vector
    input and the auxiliary network *Q*[0] that recovers *z*[0]. The builder function
    in `gan.py` is used to create `dis0`:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.2.8*展示了判别器Keras模型。我们提供了构建 *判别器*[0] 和 *判别器*[1] (`dis0` 和 `dis1`) 的函数。`dis0`
    判别器与GAN判别器相似，只是输入是特征向量，并且有辅助网络 *Q*[0] 来恢复 *z*[0]。`gan.py` 中的构建器函数用于创建 `dis0`：'
- en: '[PRE14]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `dis1` discriminator is made of a three-layer MLP as shown in *Listing*
    *6.2.3*. The last layer discriminates between the real and fake *f*[1]. *Q*[1]
    network shares the first two layers of `dis1`. Its third layer recovers *z*[1]:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`dis1`判别器由三层MLP组成，如*列表* *6.2.3*所示。最后一层用于区分真实与伪造的 *f*[1]。*Q*[1] 网络共享 `dis1`
    的前两层。其第三层恢复 *z*[1]：'
- en: '![Implementation of StackedGAN in Keras](img/B08956_06_16.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![Keras中StackedGAN的实现](img/B08956_06_16.jpg)'
- en: 'Figure 6.2.8: A StackedGAN Discriminator model in Keras'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.8：Keras中的StackedGAN判别器模型
- en: 'Listing 6.2.3, `stackedgan-mnist-6.2.1.py` shows the *Discriminator*[1] implementation
    in Keras:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2.3，`stackedgan-mnist-6.2.1.py`展示了*判别器*[1]在Keras中的实现：
- en: '[PRE15]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: With all builder functions available, StackedGAN is assembled in *Listing* *6.2.4*.
    Before training StackedGAN, the encoder is pretrained. Note that we already incorporated
    the three generator loss functions (adversarial, conditional, and entropy) in
    the adversarial model training. The *Q*-Network shares some common layers with
    the discriminator model. Therefore, its loss function is also incorporated in
    the discriminator model training.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 所有构建器函数可用后，StackedGAN在*列表* *6.2.4* 中组装完成。在训练StackedGAN之前，需要先预训练编码器。注意，我们已经将三个生成器损失函数（对抗性、条件性和熵）融入到对抗模型训练中。*Q*-Network与判别器模型共享一些公共层。因此，它的损失函数也会在判别器模型训练中包含。
- en: 'Listing 6.2.4, `stackedgan-mnist-6.2.1.py`. Building StackedGAN in Keras:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2.4，`stackedgan-mnist-6.2.1.py`。在Keras中构建StackedGAN：
- en: '[PRE16]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, the training function bears a resemblance to a typical GAN training
    except that we only train one GAN at a time (that is, *GAN*[1] then *GAN*[0]).
    The code is shown in *Listing* *6.2.5*. It''s worth noting that the training sequence
    is:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，训练函数与典型的GAN训练相似，只是我们一次只训练一个GAN（即 *GAN*[1] 然后是 *GAN*[0]）。代码显示在*列表* *6.2.5*中。值得注意的是，训练顺序是：
- en: '*Discriminator*[1] and *Q*[1] networks by minimizing the discriminator and
    entropy losses'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*判别器*[1] 和 *Q*[1] 网络通过最小化判别器和熵损失'
- en: '*Discriminator*[0] and *Q*[0] networks by minimizing the discriminator and
    entropy losses'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*判别器*[0] 和 *Q*[0] 网络通过最小化判别器和熵损失'
- en: '*Adversarial*[1] network by minimizing the adversarial, entropy, and conditional
    losses'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*对抗性*网络通过最小化对抗性、熵和条件损失'
- en: '*Adversarial*[0] network by minimizing the adversarial, entropy, and conditional
    losses'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*对抗性*网络通过最小化对抗性、熵和条件损失'
- en: 'Listing 6.2.5, `stackedgan-mnist-6.2.1.py` shows us training the StackedGAN
    in Keras:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2.5，`stackedgan-mnist-6.2.1.py`展示了我们在Keras中训练StackedGAN的代码：
- en: '[PRE17]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Generator outputs of StackedGAN
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StackedGAN的生成器输出
- en: After training the StackedGAN for 10,000 steps, the *Generator*[0] and *Generator*[1]
    models are saved on files. Stacked together, *Generator*[0] and *Generator*[1]
    can synthesize fake images conditioned on label and noise codes, *z*[0] and *z*[1].
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 经过10,000步的训练后，StackedGAN的*Generator*[0]和*Generator*[1]模型被保存到文件中。将*Generator*[0]和*Generator*[1]堆叠在一起，可以基于标签和噪声代码*z*[0]和*z*[1]合成虚假图像。
- en: 'The StackedGAN generator can be qualitatively validated by:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过以下方式定性验证StackedGAN生成器：
- en: 'Varying the discrete labels from 0 to 9 with both noise codes, *z*[0] and *z*[1]
    sampled from a normal distribution with a mean of 0.5 and standard -deviation
    of 1.0\. The results are shown in *Figure 6.2.9*. We''re able to see that the
    StackedGAN discrete code can control the digits produced by the generator:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让离散标签从0到9变化，同时两个噪声代码，*z*[0]和*z*[1]，从均值为0.5，标准差为1.0的正态分布中抽取样本。结果如*图6.2.9*所示。我们可以看到，StackedGAN的离散代码能够控制生成器生成的数字：
- en: '[PRE18]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: to
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 到
- en: 'Varying the first noise code, *z*[0], as a constant vector from -4.0 to 4.0
    for digits 0 to 9 as shown as follows. The second noise code, *z*[0], is set to
    zero vector. *Figure 6.2.10* shows that the first noise code controls the thickness
    of the digit. For example, for digit 8:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让第一个噪声代码，*z*[0]，作为常量向量从-4.0变化到4.0，用于数字0到9，如下所示。第二个噪声代码，*z*[0]，设置为零向量。*图6.2.10*显示第一个噪声代码控制数字的厚度。例如，数字8：
- en: '[PRE19]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Varying the second noise code, *z*[1], as a constant vector from -1.0 to 1.0
    for digits 0 to 9 shown as follows. The first noise code, *z*[0], is set to zero
    vector. *Figure 6.2.11* shows that the second noise code controls the rotation
    (tilt) and to a certain extent the thickness of the digit. For example, for digit
    8:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让第二个噪声代码，*z*[1]，作为常量向量从-1.0变化到1.0，用于数字0到9，如下所示。第一个噪声代码，*z*[0]，设置为零向量。*图6.2.11*显示第二个噪声代码控制数字的旋转（倾斜）以及在一定程度上数字的厚度。例如，数字8：
- en: '[PRE20]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Generator outputs of StackedGAN](img/B08956_06_17.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN生成器输出](img/B08956_06_17.jpg)'
- en: 'Figure 6.2.9: Images generated by StackedGAN as the discrete code is varied
    from 0 to 9\. Both ![Generator outputs of StackedGAN](img/B08956_06_047.jpg) and
    ![Generator outputs of StackedGAN](img/B08956_06_048.jpg) have been sampled from
    a normal distribution with zero mean and 0.5 standard deviation.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.9：当离散代码从0变动到9时，由StackedGAN生成的图像。两个图像![StackedGAN生成器输出](img/B08956_06_047.jpg)和![StackedGAN生成器输出](img/B08956_06_048.jpg)都来自于一个均值为0，标准差为0.5的正态分布。
- en: '![Generator outputs of StackedGAN](img/B08956_06_18.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN生成器输出](img/B08956_06_18.jpg)'
- en: 'Figure 6.2.10: Images generated by using a StackedGAN as the first noise code,
    *z*[0], varies from constant vector -4.0 to 4.0 for digits 0 to 9\. *z*[0] appears
    to control the thickness of each digit.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.10：使用StackedGAN生成的图像，当第一个噪声代码，*z*[0]，从常量向量-4.0变化到4.0时，适用于数字0到9。*z*[0]似乎控制每个数字的厚度。
- en: '![Generator outputs of StackedGAN](img/B08956_06_19.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN生成器输出](img/B08956_06_19.jpg)'
- en: 'Figure 6.2.11: The images generated by StackedGAN as the second noise code,
    *z*[1], varies from constant vector -1.0 to 1.0 for digits 0 to 9\. *z*[1] appears
    to control the rotation (tilt) and the thickness of stroke of each digit.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.11：当第二个噪声代码，*z*[1]，从常量向量-1.0到1.0变化时，由StackedGAN生成的图像。*z*[1]似乎控制每个数字的旋转（倾斜）和笔画厚度。
- en: '*Figures 6.2.9* to *6.2.11* demonstrate that the StackedGAN has provided additional
    control on the attributes of the generator outputs. The control and attributes
    are (label, which digit), (*z*0, digit thickness), and (*z*1, digit tilt). From
    this example, there are other possible experiments that we can control such as:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.2.9*到*图6.2.11*展示了StackedGAN提供了更多的控制，可以控制生成器输出的属性。控制和属性包括（标签，数字类型），(*z*0，数字厚度），和(*z*1，数字倾斜度)。从这个例子来看，我们还可以控制其他可能的实验，例如：'
- en: Increasing the number of elements of the stack from the current 2
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加堆叠元素的数量，从当前的2开始
- en: Decreasing the dimension of codes *z*0 and *z*1, like in InfoGAN
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低代码*z*0和*z*1的维度，像在InfoGAN中一样
- en: 'Following figure shows the differences between the latent codes of InfoGAN
    and StackedGAN. The basic idea of disentangling codes is to put a constraint on
    the loss functions such that only specific attributes are affected by a code.
    Structure-wise, InfoGAN are easier to implement when compared to StackedGAN. InfoGAN
    is also faster to train:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的图展示了InfoGAN和StackedGAN的潜在代码差异。解耦代码的基本思想是对损失函数施加约束，使得只有特定的属性会被一个代码所影响。从结构上来看，InfoGAN比StackedGAN更容易实现。InfoGAN的训练速度也更快：
- en: '![Generator outputs of StackedGAN](img/B08956_06_20.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![StackedGAN生成器输出](img/B08956_06_20.jpg)'
- en: 'Figure 6.2.12: Latent representations for different GANs'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2.12：不同GAN的潜在表示
- en: Conclusion
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we've discussed how to disentangle the latent representations
    of GANs. Earlier on in the chapter, we discussed how InfoGAN maximizes the mutual
    information in order to force the generator to learn disentangled latent vectors.
    In the MNIST dataset example, InfoGAN uses three representations and a noise code
    as inputs. The noise represents the rest of the attributes in the form of an entangled
    representation. StackedGAN approaches the problem in a different way. It uses
    a stack of encoder-GANs to learn how to synthesize fake features and images. The
    encoder is first trained to provide a dataset of features. Then, the encoder-GANs
    are trained jointly to learn how to use the noise code to control attributes of
    the generator output.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何解开GAN的潜在表示。我们在本章的早期讨论了InfoGAN如何通过最大化互信息来迫使生成器学习解耦的潜在向量。在MNIST数据集的例子中，InfoGAN使用了三个表示和一个噪声编码作为输入。噪声表示其余的属性，以纠缠表示的形式出现。StackedGAN以不同的方式处理这个问题。它使用一堆编码器GAN来学习如何合成虚假的特征和图像。首先训练编码器以提供一个特征数据集。然后，编码器GANs被联合训练，学习如何利用噪声编码来控制生成器输出的属性。
- en: In the next chapter, we will embark on a new type of GAN that is able to generate
    new data in another domain. For example, given an image of a horse, the GAN can perform
    an automatic transformation to an image of a zebra. The interesting feature of
    this type of GAN is that it can be trained without supervision.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍一种新的GAN类型，它能够在另一个领域生成新数据。例如，给定一张马的图片，该GAN可以自动转换为斑马的图片。这种类型的GAN的有趣之处在于，它可以在无监督的情况下进行训练。
- en: Reference
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Xi Chen and others. *InfoGAN: Interpretable Representation Learning by Information
    Maximizing Generative Adversarial Nets*. Advances in Neural Information Processing
    Systems, 2016([http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf)).'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Xi Chen等人。*InfoGAN：通过信息最大化生成对抗网络进行可解释的表示学习*。《神经信息处理系统进展》，2016（[http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf)）。
- en: Xun Huang and others. *Stacked Generative Adversarial Networks*. IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR). Vol. 2, 2017([http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.pdf)).
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Xun Huang等人。*堆叠生成对抗网络*。IEEE计算机视觉与模式识别会议（CVPR）。第2卷，2017（[http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.pdf)）。
