- en: Combining It All Together
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 综合所有内容
- en: 'Now that we have understood and implemented different **Artificial Intelligence**
    (**AI**)/**machine learning** (**ML**) algorithms, it is time to combine it all
    together, understand which type of data is best suited for each, and, at the same
    time, understand the basic preprocessing required for each type of data. By the
    end of this chapter, you will know the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经理解并实现了不同的**人工智能**（**AI**）/**机器学习**（**ML**）算法，是时候将它们结合起来，了解每种算法最适合哪种类型的数据，并同时理解每种数据类型所需的基本预处理。在本章结束时，你将了解以下内容：
- en: The different types of data that can be fed to your model
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以输入模型的不同类型数据
- en: How to process time series data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何处理时间序列数据
- en: Preprocessing of textual data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本数据的预处理
- en: Different transforms that can be done on image data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以对图像数据进行的不同转换
- en: How to handle video files
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何处理视频文件
- en: How to handle speech data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何处理语音数据
- en: Cloud computing options
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云计算选项
- en: Processing different types of data
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理不同类型的数据
- en: 'Data is available in all shapes, sizes, and forms: tweets, daily stock prices,
    per minute heartbeat signals, photos from cameras, video obtained from CCTV, audio
    recordings, and so on. Each of them contain information and when properly processed
    and used with the right model, we can analyze the data and, obtain advanced information
    about the underlying patterns. In this section, we will cover the basic preprocessing
    required for each type of data before it can be fed to a model and the models
    that can be used for it.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有各种各样的形式、大小和类型：推文、每日股价、每分钟的心跳信号、相机拍摄的照片、通过CCTV获取的视频、音频录音等。每种数据都包含信息，当这些数据经过正确的处理并与合适的模型结合使用时，我们可以分析这些数据，并获得关于潜在模式的高级信息。在本节中，我们将介绍每种数据类型在输入模型之前所需的基本预处理，以及可以使用的模型。
- en: Time series modeling
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列建模
- en: Time underlies many interesting human behaviors, and hence, it is important
    that AI-powered IoT systems know how to deal with time-dependent data. Time can
    be represented either explicitly, for example, capturing data at regular intervals
    where the time-stamp is also part of data, or implicitly, for example, in speech
    or written text. The methods that allow us to capture inherent patterns in time-dependent
    data is called **time series modeling**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 时间是许多有趣的人类行为的基础，因此，AI驱动的物联网系统必须知道如何处理时间相关的数据。时间可以显式地表示，例如，通过定期捕获数据，其中时间戳也是数据的一部分，或者隐式地表示，例如，在语音或书面文本中。能够捕捉时间相关数据中固有模式的方法称为**时间序列建模**。
- en: 'The data that is captured at regular intervals is a time series data, for example,
    stock price data is a time series data. Let''s take a look at Apple stock price
    data; this data can be downloaded from the NASDAQ site ([https://www.nasdaq.com/symbol/aapl/historical](https://www.nasdaq.com/symbol/aapl/historical)).
    Alternatively, you can use the `pandas_datareader` module to directly download
    the data by specifying the data source. To install `pandas_datareader` in your
    working environment, use the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在定期间隔捕获的数据是时间序列数据，例如，股价数据就是时间序列数据。让我们来看一下苹果股票价格数据；这些数据可以从NASDAQ网站下载（[https://www.nasdaq.com/symbol/aapl/historical](https://www.nasdaq.com/symbol/aapl/historical)）。或者，你可以使用`pandas_datareader`模块直接下载数据，通过指定数据源来实现。要在你的工作环境中安装`pandas_datareader`，可以使用以下命令：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following code downloads the Apple Inc stock price from Yahoo Finance from
    1^(st) January 2010 to 31^(st) December 2015:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码从2010年1月1日到2015年12月31日，从Yahoo Finance下载苹果公司股票价格：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The downloaded DataFrame provides `High`, `Low`, `Open`, `Close`, `Volume`,
    and `Adj Close` values for each working day:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载的DataFrame提供了每个工作日的`High`、`Low`、`Open`、`Close`、`Volume`和`Adj Close`值：
- en: '![](img/1fb0ab65-15be-41bb-b84b-0aca162443a4.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1fb0ab65-15be-41bb-b84b-0aca162443a4.png)'
- en: 'Let''s now plot it, shown as follows:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来绘制图表，如下所示：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](img/fa7e0db3-3e92-49f9-a9ef-bf5e5a396a44.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa7e0db3-3e92-49f9-a9ef-bf5e5a396a44.png)'
- en: 'To be able to model time series data, we need to identify a few things: trend,
    seasonality, and stationarity.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够建模时间序列数据，我们需要识别几个要素：趋势、季节性和稳定性。
- en: '**Trend** means to find whether, on average, the measurements tend to decrease
    (or increase) over time. The most common way to find a trend is by plotting a
    moving average, shown as follows:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**趋势**是指找出在平均情况下，测量值是否随着时间的推移而减少（或增加）。找到趋势最常见的方法是绘制移动平均，如下所示：'
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/860eb6d8-e51e-418e-a446-c6d9a88a5876.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/860eb6d8-e51e-418e-a446-c6d9a88a5876.png)'
- en: 'We can see, with a window of 20, the upward and downward trend. For time series
    modeling, we should detrend the data. Detrending can be done by subtracting the
    trend (moving average) from the original signal. Another popular way is using
    the first order difference method, where you take the difference between successive
    data points:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到，使用窗口为20，上升和下降趋势。 对于时间序列建模，我们应该去趋势化数据。 去趋势化可以通过从原始信号中减去趋势（移动平均值）来完成。 另一种流行的方法是使用一阶差分方法，即取相邻数据点之间的差异：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](img/5730da71-8b00-4cf1-8b44-a59920e3cab6.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5730da71-8b00-4cf1-8b44-a59920e3cab6.png)'
- en: '**Seasonality** is the presence of a regularly repeating pattern of highs and
    lows related to time (for example, sine series). The easiest way is to find autocorrelation
    in the data. Once you find the seasonality, you can remove it by differencing
    the data by a time lag corresponding to the season length:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**季节性**是与时间相关的高低规律重复出现的模式（例如，正弦系列）。 最简单的方法是在数据中找到自相关。 找到季节性后，您可以通过将数据差分到与季节长度相对应的时间滞来移除它：'
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](img/d024cf46-d51b-45f2-a1d4-307cf981e712.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d024cf46-d51b-45f2-a1d4-307cf981e712.png)'
- en: The last thing is to ensure whether the series is **stationary**, that is, the
    mean of the series is no longer a function of time. Stationarity of data is essential
    for time series modeling. We achieve stationarity by removing any trends or seasonality
    present within the data. Once the data is stationary, we can use regression models
    to model it.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一件事是确保系列是否**平稳**，即系列的均值不再是时间的函数。 数据的平稳性对于时间序列建模至关重要。 我们通过消除数据中存在的任何趋势或季节性来实现平稳性。
    一旦数据平稳，我们可以使用回归模型对其进行建模。
- en: 'Traditionally, time series data was modeled using auto-regressive and moving
    average based models like ARMA and ARIMA. To learn more about time series modeling,
    the interested reader can refer to these books:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，时间序列数据是使用自回归和移动平均模型（如ARMA和ARIMA）进行建模的。 要了解更多关于时间序列建模的信息，感兴趣的读者可以参考这些书籍：
- en: 'Pandit, S. M., and Wu, S. M. (1983). *Time Series and System Analysis with
    Applications*(Vol. 3). New York: Wiley.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandit, S. M., and Wu, S. M. (1983). *带应用的时间序列与系统分析*(Vol. 3). 纽约：约翰·威利。
- en: 'Brockwell, P. J., Davis, R. A., and Calder, M. V. (2002). *Introduction to
    Time Series and Forecasting*(Vol. 2). New York: Springer.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brockwell, P. J., Davis, R. A., and Calder, M. V. (2002). *时间序列和预测简介*(Vol. 2).
    纽约：斯普林格出版社。
- en: 'The stationarity is an important property for any time series data, whether
    you are using traditional time series modeling or deep learning models. This is
    so because, if a series has stationarity (even if it is weak stationarity), then
    it means the data has same distribution across time, and hence, can be estimated
    in time. If you are planning to use deep learning models such as RNN or LSTM,
    then after confirming stationarity of the time series, additionally, you need
    to normalize the data and use a sliding window transform to convert the series
    in to input-output pairs on which regression can be done.  This can be very easily
    done using the scikit-learn library and NumPy:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何时间序列数据，平稳性都是一个重要的特性，无论您是使用传统的时间序列建模还是深度学习模型。 这是因为，如果一个系列具有平稳性（即使是弱平稳性），那么它意味着数据在时间上具有相同的分布，因此可以在时间上进行估计。
    如果您计划使用诸如RNN或LSTM之类的深度学习模型，则在确认时间序列的平稳性后，此外，您需要对数据进行归一化，并使用滑动窗口转换将系列转换为输入-输出对，以便进行回归。
    使用scikit-learn库和NumPy可以非常容易地完成这一操作：
- en: 'Let''s normalize the `close` DataFrame. Normalization ensures that data lies
    between `0` and `1`. Observe that the following plot is the same as the plot of
    the `close` DataFrame in the preceding *step 3* , however, the *y*-axis scale
    is now different:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们对`close` DataFrame进行归一化。 归一化确保数据位于`0`和`1`之间。 请注意，以下图与前述*步骤3*中`close` DataFrame的图表相同，但*y*轴比例现在不同：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/ea95f634-5716-4007-9e07-689e5f4b1095.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ea95f634-5716-4007-9e07-689e5f4b1095.png)'
- en: 'We define a `window_transform()` function, which will convert the data series
    into a sequence of input-output pairs. For example, you want to construct an RNN
    that takes the previous five values as output and predicts the sixth value. Then,
    you choose `window_size = 5`:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个`window_transform()`函数，它将数据系列转换为一系列输入-输出对。 例如，您想构建一个RNN，该RNN将前五个值作为输出，并预测第六个值。
    然后，您选择`window_size = 5`：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Please refer to the GitHub repository, `Chapter-12/time_series_data_preprocessing.ipynb`,
    for the complete code of this section.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅GitHub存储库，`Chapter-12/time_series_data_preprocessing.ipynb`，查看本节的完整代码。
- en: Preprocessing textual data
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理文本数据
- en: 'Language plays a very important role in our daily life. For us, reading a written
    text is very natural, but what about computers? Can they read it? Can we make
    our deep learning models generate new text based on the old pattern? For example,
    if I say, "Yesterday, I had ____ at Starbucks," most of us will be able to guess
    that the blank space is coffee, but can our deep learning models do it? The answer
    is yes; we can train our deep learning models to guess the next word (or character).
    However, deep learning models run on computers, and computers understand only
    binary, only 0s and 1s. Hence, we need a way to process out textual data so that
    it can be converted in to a form that is easy for the computer to handle. Moreover,
    while cat or CAT or Cat have different ASCII representation, they mean the same;
    it is easy for us to see, but for models to take them as the same, we need to
    preprocess the textual data. This section will list the necessary preprocessing
    steps for the textual data, and you will learn how to do it in Python:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 语言在我们日常生活中扮演着非常重要的角色。对我们来说，阅读书面文本是非常自然的，但计算机呢？它们能读取文本吗？我们能让深度学习模型根据旧的模式生成新的文本吗？例如，如果我说，“昨天，我在星巴克喝了____”，我们大多数人都能猜出空白处是“咖啡”，但是我们的深度学习模型能做到吗？答案是肯定的；我们可以训练我们的深度学习模型来猜测下一个词（或字符）。然而，深度学习模型运行在计算机上，而计算机只理解二进制，只有0和1。因此，我们需要一种方法来处理文本数据，以便将其转换为计算机易于处理的形式。此外，尽管“cat”、“CAT”和“Cat”有不同的ASCII表示，但它们表示的意思相同；这对我们来说很容易理解，但要让模型将它们视为相同，我们需要对文本数据进行预处理。本节将列出文本数据的必要预处理步骤，您将学习如何在Python中实现：
- en: 'For this section, we will consider a small text from my favorite science fiction
    novel, *Foundation,* by Isaac Asimov. The text is in the `foundation.txt` file.
    The first step is, we read in the text:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一节中，我们将考虑来自我最喜欢的科幻小说《基地》的小段文本，作者是艾萨克·阿西莫夫。该文本位于`foundation.txt`文件中。第一步是，读取文本：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The next step in text processing is cleaning the data. We retain only that
    part of the text that is relevant. In most cases, punctuation does not add any
    additional meaning to the text, so we can safely remove it:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本处理的下一步是清洗数据。我们保留文本中相关的部分。在大多数情况下，标点符号不会为文本增加额外的含义，因此我们可以放心地将其去除：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After cleaning the data, we need to normalize the text. In text processing,
    normalizing the text means converting all text in to the same case, lowercase
    or uppercase. Conventionally, lowercase is preferred, so we convert the text in
    to lowercase:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清洗数据后，我们需要对文本进行规范化处理。在文本处理过程中，规范化文本意味着将所有文本转换为相同的大小写，通常是小写。为了遵循惯例，我们将文本转换为小写：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once the text is normalized, the next step is tokenizing the text. We can tokenize
    a text in word tokens or sentence tokens. To do this, you can use either the split
    function or use the powerful NLTK module. If you do not have NLTK installed in
    your system, you can do it using `pip install nltk`. In the following, we use
    NLTK''s word tokenizer to do the task:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦文本被规范化，下一步是对文本进行分词。我们可以将文本分割为单词令牌或句子令牌。为了做到这一点，您可以使用`split`函数，或者使用功能强大的NLTK模块。如果您的系统中没有安装NLTK，可以通过`pip
    install nltk`进行安装。在接下来的例子中，我们使用NLTK的单词分词器来完成这项任务：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Depending on the type of text you have and the work you are doing, you will
    need to remove stop words. Stop words are words that are present in most text
    samples, and hence, do not add any information to the context or meaning of the
    text. For example, the, a, and an. You can declare your own stop words or use
    the stop words provided by NLTK. Here, we remove `stopwords` of the `english`
    language from our text:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据您拥有的文本类型和所做的工作，您可能需要去除停用词。停用词是出现在大多数文本样本中的词，因此不会为文本的上下文或意义增加任何信息。例如，the、a和an。您可以声明自己的停用词，也可以使用NLTK提供的停用词。在这里，我们从文本中移除`english`语言的`stopwords`：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Another thing that you can perform on the textual data is stemming and lemmatization.
    These are used to convert the words into canonical form:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一个可以在文本数据上进行的操作是词干提取和词形还原。这些操作用于将单词转换为规范形式：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can access the notebook with this code at GitHub: `Chapter12/text_processing.ipynb`.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过GitHub访问包含此代码的笔记本：`Chapter12/text_processing.ipynb`。
- en: Data augmentation for images
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像数据增强
- en: Python has OpenCV, which provides very good support for images. OpenCV can be
    downloaded from both Conda channels and PyPi for installation. Once the image
    is read using the OpenCV `imread()` function, the image is represented as an array.
    In case the image is coloured, the channels are stored in BGR order. Each element
    of the array represents the intensity of the corresponding pixel value (the values
    lie in the range 0 to 255).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Python有OpenCV，它为图像提供了非常好的支持。OpenCV可以从Conda通道和PyPi下载安装。一旦使用OpenCV的`imread()`函数读取图像，图像就表示为一个数组。如果图像是彩色的，则通道以BGR顺序存储。数组中的每个元素表示相应像素值的强度（这些值的范围在0到255之间）。
- en: 'Let''s say you have trained a model to recognize a ball: you present it with
    a tennis ball, and it recognizes it as a ball. The next image of the ball that
    we present is taken after zooming: will our model still recognize it? A model
    is just as good as the dataset it has been trained on, and so, if the model while
    training had seen rescaled images, it will be easy for it to identify the zoomed
    ball as a ball. One way to ensure that such images are available in your dataset
    is to implicitly include such variable images, however, since images are represented
    as an array, we can perform mathematical transformations to rescale, flip, rotate,
    and even change intensities. The process of performing these transformations on
    existing training images to generate new images is called **data augmentation**.
    Another advantage of using data augmentation  is that you are able to increase
    the size of your training dataset (when used with data generators, we can get
    infinite images).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经训练了一个模型来识别一个球：你给它展示一个网球，它能识别为球。接下来我们展示的这张球的图像是在缩放之后拍摄的：我们的模型还能识别它吗？一个模型的效果取决于它所训练的数据集，因此，如果模型在训练时看到了缩放后的图像，它将很容易识别出缩放后的球是一个球。一种确保数据集中有这些图像的方法是隐式地包含这些变化图像，然而，由于图像是作为数组表示的，我们可以进行数学变换来重新缩放、翻转、旋转，甚至改变强度。在现有训练图像上执行这些变换以生成新图像的过程叫做**数据增强**。使用数据增强的另一个好处是，您可以增加训练数据集的大小（当与数据生成器一起使用时，我们可以获得无限的图像）。
- en: 'Most deep learning libraries have standard APIs to perform data augmentation.
    In Keras ([https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)
    ), there is `ImageDataGenerator`, and in TensorFlow-TfLearn, we have `ImageAugmentation`.
    TensorFlow also has Ops to perform image conversions and transformations ([https://www.tensorflow.org/api_guides/python/image](https://www.tensorflow.org/api_guides/python/image)).
    Here we will see how we can use OpenCV''s powerful library for data augmentation
    and create our own data generator:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数深度学习库都提供了标准的API来进行数据增强。在Keras（[https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)）中，有`ImageDataGenerator`，在TensorFlow-TfLearn中，我们有`ImageAugmentation`。TensorFlow也有操作符来执行图像转换和变换（[https://www.tensorflow.org/api_guides/python/image](https://www.tensorflow.org/api_guides/python/image)）。在这里，我们将看看如何使用OpenCV强大的库进行数据增强，并创建我们自己的数据生成器：
- en: 'We import the necessary modules: OpenCV to read and process images, `numpy`
    for matrix manipulations, Matplotlib to visualize images, `shuffle` from scikit-learn
    for randomly shuffling the data, and Glob to find files within directories:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入了必要的模块：OpenCV用于读取和处理图像，`numpy`用于矩阵操作，Matplotlib用于可视化图像，`shuffle`来自scikit-learn用于随机打乱数据，以及Glob用于查找目录中的文件：
- en: '[PRE14]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We read the necessary files. For this example, we downloaded some images of
    the previous President of the United States, Barack Obama, from Google image search:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取了必要的文件。对于这个示例，我们从Google图像搜索中下载了一些前美国总统巴拉克·奥巴马的图像：
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We create a function that can randomly introduce any of the following distortions
    in the image: random rotation in the range 0–50 degrees, randomly change the intensity,
    randomly shift the image horizontally and vertically by up to 50 pixels, or randomly
    flip the image:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个函数，可以在图像中随机引入以下任意变形：在0到50度范围内随机旋转，随机改变图像强度，随机将图像水平和垂直平移最多50个像素，或者随机翻转图像：
- en: '[PRE16]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the following image, you can see the result of the preceding function on
    randomly chosen images from our dataset:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下图中，您可以看到前述函数在我们数据集中随机选择的图像上的结果：
- en: '![](img/e35d972d-8a55-4be5-88d9-647b3aaee380.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e35d972d-8a55-4be5-88d9-647b3aaee380.png)'
- en: 'And finally, you can create a data generator using Python `yield` to generate
    as many images as you want:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您可以使用Python的`yield`创建数据生成器，生成您需要的任意数量的图像：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `Chapter12/data_augmentation.ipynb` file contains the code for this section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`Chapter12/data_augmentation.ipynb`文件包含了这一部分的代码。'
- en: Handling videos files
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理视频文件
- en: 'Videos are nothing but a collection of still images (frames), therefore, if
    we can extract images from the videos, we can apply our trusted CNN networks on
    the same. The only necessary thing to do is convert the video in to a list of
    frames:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 视频本质上是静态图像（帧）的集合，因此，如果我们能够从视频中提取图像，就可以将我们信任的CNN网络应用到这些图像上。唯一需要做的就是将视频转换为帧列表：
- en: 'The first thing we import are the requisite modules. We will need OpenCV to
    read the video and convert it in to frames. We will also need the `math` module
    for basic mathematical operations and Matplotlib for visualizing the frames:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入必要的模块。我们需要OpenCV来读取视频并将其转换为帧。我们还需要`math`模块进行基本的数学运算，以及Matplotlib来可视化这些帧：
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We read the video file using the OpenCV function and get its frame rate by
    using the property identifier, `5` ([https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get)):'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用OpenCV函数读取视频文件，并通过属性标识符`5`来获取视频的帧率（[https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get)）：
- en: '[PRE19]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We loop through all of the frames of the video one by one using the `read()`
    function. Although we read only one frame at a time, we save only the first frame
    in each second. This way, we can cover the whole video, and yet reduce the data
    size:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过`read()`函数逐帧读取视频中的所有帧。虽然我们每次只读取一帧，但我们只保存每秒的第一帧。这样，我们可以覆盖整个视频，同时减少数据大小：
- en: '[PRE20]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s visualize the fifth frame that we saved:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来可视化一下我们保存的第五帧：
- en: '[PRE21]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](img/7aa195c7-3649-451f-ad8c-5a1145c049e1.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7aa195c7-3649-451f-ad8c-5a1145c049e1.png)'
- en: The video file for this code was taken from the site maintained by Ivan Laptev
    and Barbara Caputo ([http://www.nada.kth.se/cvap/actions/](http://www.nada.kth.se/cvap/actions/)).
    The code is available at GitHub: `Chapter12/Video_to_frames.ipynb`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本代码所用的视频文件来自Ivan Laptev和Barbara Caputo维护的网站（[http://www.nada.kth.se/cvap/actions/](http://www.nada.kth.se/cvap/actions/)）。代码可以在GitHub上找到：`Chapter12/Video_to_frames.ipynb`。
- en: 'One of the best papers that uses CNN for classifying videos is *Large-scale
    Video Classification with Convolutional Neural Networks* by Andrej Karpathy et
    al.. You can access here: [https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CNN进行视频分类的最佳论文之一是Andrej Karpathy等人撰写的*大规模视频分类与卷积神经网络*。你可以在这里访问：[https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html)。
- en: Audio files as input data
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 音频文件作为输入数据
- en: 'Another interesting data type is audio files. Models that convert speech in
    to text or classify audio sounds take as input audio files. If you want to work
    with audio files, then you will need the `librosa` module. There are many ways
    to treat an audio file; we can convert it into a time series and use a recurrent
    network. Another way that has given good results is to use them as one-dimensional
    or two-dimensional patterns, and train a CNN to classify them. Some good papers
    that adopt this approach are as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的数据类型是音频文件。将语音转换为文本或分类音频声音的模型以音频文件作为输入。如果你想处理音频文件，那么你需要使用`librosa`模块。处理音频文件的方法有很多；我们可以将其转换为时间序列并使用循环神经网络。另一种取得良好结果的方法是将其作为一维或二维图案，并训练CNN进行分类。一些采用这种方法的优秀论文如下：
- en: Hershey, S., Chaudhuri, S., Ellis, D. P., Gemmeke, J. F., Jansen, A., Moore,
    R. C., and Slaney, M. (2017, March). *CNN architectures for large-scale audio
    classification.* In Acoustics, Speech, and Signal Processing (ICASSP), 2017 IEEE
    International Conference on (pp. 131-135). IEEE.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hershey, S., Chaudhuri, S., Ellis, D. P., Gemmeke, J. F., Jansen, A., Moore,
    R. C., 和 Slaney, M. (2017年3月). *用于大规模音频分类的CNN架构.* 在声学、语音和信号处理（ICASSP）2017年IEEE国际会议（第131-135页）。IEEE.
- en: Palaz, D., Magimai-Doss, M., and Collobert, R. (2015). *Analysis of CNN-based
    speech recognition system using raw speech as input*. In Sixteenth Annual Conference
    of the International Speech Communication Association.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Palaz, D., Magimai-Doss, M., 和 Collobert, R. (2015). *基于CNN的语音识别系统分析，使用原始语音作为输入*。在第十六届国际语音通信协会年会上。
- en: Zhang, H., McLoughlin, I., and Song, Y. (2015, April). *Robust sound event recognition
    using convolutional neural networks*. In Acoustics, Speech, and Signal Processing
    (ICASSP), 2015 IEEE International Conference on (pp. 559-563). IEEE.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang, H., McLoughlin, I., and Song, Y. (2015, April). *使用卷积神经网络进行稳健的声音事件识别*。在《声学、语音与信号处理》(ICASSP)，2015年IEEE国际会议中（第559-563页）。IEEE。
- en: Costa, Y. M., Oliveira, L. S., and Silla Jr, C. N. (2017). *An evaluation of
    convolutional neural networks for music classification using spectrograms*. Applied
    soft computing, 52, 28–38.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Costa, Y. M., Oliveira, L. S., and Silla Jr, C. N. (2017). *使用声谱图对卷积神经网络进行音乐分类的评估*。应用软计算，52，28–38。
- en: 'We will use the `librosa` module to read an audio file and convert it in to
    a one-dimensional sound pattern and two-dimensional spectrogram. You can install
    `librosa` in your Anaconda environment using the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`librosa`模块读取音频文件，并将其转换为一维声音波形和二维声谱图。你可以通过以下方式在你的Anaconda环境中安装`librosa`：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, we will import `numpy`, `matplotlib`, and `librosa`. We will take the
    example audio file from the `librosa` datasets:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将导入`numpy`、`matplotlib`和`librosa`。我们将从`librosa`数据集中获取示例音频文件：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `librosa` load function returns the audio data as time series represented
    as a one-dimensional NumPy floating-point array. We can use them as time series
    or even as a one-dimensional pattern for a CNN:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`librosa`的加载函数返回音频数据，表示为一维NumPy浮点数组的时间序列。我们可以将它们用作时间序列，甚至用作CNN的一维模式：'
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the following, you can see the one-dimensional audio wave pattern after
    normalization:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是归一化后的一维音频波形图：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](img/058703e1-2a99-474e-b3d6-6aa9d4e0d830.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/058703e1-2a99-474e-b3d6-6aa9d4e0d830.png)'
- en: '`librosa` also has a `melspectrogram` function that we can use to form a mel
    spectrogram, which can be used as a two-dimensional image for a CNN:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`librosa`还有一个`melspectrogram`函数，我们可以使用它来生成梅尔声谱图，该图可以作为CNN的二维图像使用：'
- en: '[PRE26]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here is a mel spectrogram of the same audio signal:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是相同音频信号的梅尔声谱图：
- en: '[PRE27]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/d3217b50-224b-4b88-8a53-957f64dd20fb.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3217b50-224b-4b88-8a53-957f64dd20fb.png)'
- en: You can find the code file for the example in the GitHub repository under the `Chapter12/audio_processing.ipynb`
    file.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub仓库中的`Chapter12/audio_processing.ipynb`文件找到示例的代码文件。
- en: Computing in the cloud
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云计算
- en: 'Applying AI algorithms to IoT-generated data requires computing resources.
    With the availability of a large number of cloud platforms offering service at
    competitive prices, cloud computing offers a cost-effective solution. Out of the
    many cloud platforms available today, we will talk about three main cloud platform
    providers that occupy the majority of the market share: **Amazon Web Service**
    (**AWS**), **Google Cloud Platform** (**GCP**), and Microsoft Azure.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 将AI算法应用于物联网生成的数据需要计算资源。随着大量云平台以具有竞争力的价格提供服务，云计算提供了一个具有成本效益的解决方案。在如今众多的云平台中，我们将讨论三大云平台提供商，它们占据了大部分市场份额：**Amazon
    Web Service**（**AWS**）、**Google Cloud Platform**（**GCP**）和Microsoft Azure。
- en: AWS
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS
- en: Amazon offers almost every feature under the cloud, from a cloud database, to
    cloud computing resources, to even cloud analytics. It even provides space to
    build a secure data lake. Its IoT core allows users to connect devices to the
    cloud. It provides a single dashboard that can be used to control the services
    you sign for. It charges per hour for its services. It has been offering these
    services for almost 15 years. Amazon continuously upgrades the service providing
    a better user experience. You can learn more about AWS from its site: [https://aws.amazon.com/](https://aws.amazon.com/).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon提供几乎所有云计算功能，从云数据库、云计算资源，到云分析，甚至是建立安全数据湖的空间。它的物联网核心允许用户将设备连接到云端。它提供一个统一的仪表盘，可以用来控制你注册的服务。它按小时收费，提供这些服务已有近15年。Amazon不断升级其服务，提供更好的用户体验。你可以通过其网站了解更多关于AWS的信息：[https://aws.amazon.com/](https://aws.amazon.com/)。
- en: It allows new users to make use of many of its services for free for one whole
    year.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许新用户免费使用其许多服务整整一年。
- en: Google Cloud Platform
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Cloud Platform
- en: Google Cloud Platform ([https://cloud.google.com/](https://cloud.google.com/))
    also offers a myriad of services. It offers cloud computing, data analytics, data
    storage, and even cloud AI products that provide users with pre-trained models
    and service to generate their own tailored models. The platform allows you to
    pay per minute. It offers enterprise-level secure services. The Google Cloud console
    is the one place stop to access and control all of your GCP services. GCP offers
    $300 credit for the first year, which allows you to access all of its services
    for free.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Platform ([https://cloud.google.com/](https://cloud.google.com/))
    也提供了众多服务。它提供云计算、数据分析、数据存储，甚至云 AI 产品，用户可以使用这些预训练模型和服务来生成自定义的模型。该平台允许按分钟计费。它提供企业级安全服务。Google
    Cloud 控制台是访问和控制所有 GCP 服务的唯一入口。GCP 为第一年提供 $300 的信用额度，让你可以免费访问其所有服务。
- en: Microsoft Azure
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Microsoft Azure
- en: Microsoft Azure offers a wide variety of cloud services too. The best part of
    Microsoft Cloud services ([https://azure.microsoft.com/en-in/](https://azure.microsoft.com/en-in/))
    is its ease of use; you can integrate it easily with available Microsoft tools.
    It claims to be five times less expensive compared to AWS. Like AWS and GCP, Azure
    also offers a one-year free trial worth $200 credits.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Azure 也提供了各种云服务。Microsoft 云服务的最大特点是其易用性；你可以轻松地将其与现有的 Microsoft 工具集成。与
    AWS 相比，它声称成本低五倍。像 AWS 和 GCP 一样，Azure 也提供了价值 $200 的一年免费试用。
- en: You can use these cloud services to develop, test, and deploy your applications.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用这些云服务来开发、测试和部署你的应用程序。
- en: Summary
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter focused on providing the reader with tools to handle different
    types of data and how to prepare them for the deep learning models. We started
    with time series data. This chapter next detailed how textual data needs to be
    preprocessed. This chapter showed how to perform data augmentation, an important
    technique for image classification and object detection. We next moved on to handling
    video; we show how to form image frames from a video. Next, this chapter covered
    audio files; we formed a time series and mel spectrogram from an audio file. Finally,
    we moved on to cloud platforms and discussed the features and services provided
    by three major cloud service providers.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点提供了处理不同类型数据的工具以及如何为深度学习模型准备这些数据。我们从时间序列数据开始。本章接着详细介绍了文本数据如何进行预处理。本章展示了如何执行数据增强，这是一项对图像分类和物体检测至关重要的技术。接着，我们进入了视频处理部分；我们展示了如何从视频中提取图像帧。然后，本章介绍了音频文件；我们从音频文件中生成了时间序列和梅尔频谱图。最后，我们讨论了云平台，并介绍了三大云服务提供商的功能和服务。
