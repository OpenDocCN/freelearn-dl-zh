- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: The Deepfake Workflow
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度伪造工作流程
- en: Creating a deepfake is an involved process. The tools within the various software
    applications help to significantly reduce the amount of manual work required;
    however, they do not eliminate this requirement entirely. Most of this manual
    work involves collecting and curating source material, as well as cleaning up
    data for the final swap.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 创建深度伪造是一个复杂的过程。各种软件应用程序中的工具有助于显著减少所需的手动工作量；然而，它们并不能完全消除这一需求。大部分手动工作涉及收集和整理原始材料，以及为最终交换清理数据。
- en: Whilst there are various applications available for creating deepfakes this
    chapter will use the open source software Faceswap ([http://www.Faceswap.dev](http://www.Faceswap.dev)).
    The general workflow for creating a deepfake is the same from application to application,
    but you will find the nuances and available options vary between packages.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有各种用于创建深度伪造的应用程序，但本章将使用开源软件 Faceswap ([http://www.Faceswap.dev](http://www.Faceswap.dev))。创建深度伪造的一般工作流程在各个应用程序之间是相同的，但您会发现细微差别和可用选项在不同软件包之间有所不同。
- en: It is also worth noting that Faceswap, at its core, is a command-line application.
    However, it also comes with a GUI that acts as a wrapper to launch the various
    processes. Within this chapter, the GUI will be used to illustrate the workflow;
    however, most of the tasks performed here can also be run from the command-line.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，Faceswap 在本质上是一个命令行应用程序。然而，它还附带了一个图形用户界面（GUI），该界面作为包装器来启动各种进程。在本章中，我们将使用
    GUI 来展示工作流程；然而，这里执行的大多数任务也可以从命令行运行。
- en: 'In this chapter, the deepfake workflow will be covered from the inception of
    the swap to the final product. Specifically, the following topics will be covered:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖从交换的初始阶段到最终产品的整个深度伪造工作流程。具体来说，以下内容将被涉及：
- en: Identifying suitable candidates for a swap
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定适合交换的候选对象
- en: Preparing the training images
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备训练图像
- en: Training a model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Applying a trained model to perform a swap
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将训练好的模型应用于执行交换
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: As with all machine learning techniques, deepfakes can be created on any PC
    with a minimum of 4 GB of RAM. However, a machine with 8 GB of RAM or higher and
    a GPU (a graphics card) is strongly recommended. Training a model on a CPU is
    likely to take months to complete, which does not make it a realistic endeavor.
    Graphics cards are built specifically to perform matrix calculations, which makes
    them ideal for machine learning tasks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有机器学习技术一样，深度伪造可以在具有至少 4 GB RAM 的任何 PC 上创建。然而，强烈建议使用具有 8 GB 或更高 RAM 和 GPU（显卡）的机器。在
    CPU 上训练模型可能需要数月才能完成，这并不现实。显卡专门设计用于执行矩阵计算，这使得它们非常适合机器学习任务。
- en: Faceswap will run on Linux, Windows, and Intel-based macOS systems. At a minimum,
    Faceswap should be run on a system with 4 GB of VRAM (GPU memory). Ideally, an
    NVIDIA GPU should be used, as AMD GPUs are not as fully featured as their Nvidia
    counterparts and run considerably slower. Some features that are available for
    NVIDIA users are not available for AMD users, due to NVIDIA’s proprietary CUDA
    library being accepted as an industry standard for machine learning. GPUs with
    more VRAM will be able to run more of the larger Faceswap models than smaller
    GPUs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Faceswap 可在 Linux、Windows 和基于 Intel 的 macOS 系统上运行。至少，Faceswap 应该在具有 4 GB VRAM（GPU
    内存）的系统上运行。理想情况下，应使用 NVIDIA GPU，因为 AMD GPU 的功能不如其 Nvidia 对手全面，且运行速度较慢。由于 NVIDIA
    的专有 CUDA 库被接受为机器学习的行业标准，因此一些 NVIDIA 用户可用的功能对 AMD 用户不可用。具有更多 VRAM 的 GPU 可以运行比小
    GPU 更多的较大 Faceswap 模型。
- en: It is also possible to rent cloud services (such as Google’s Cloud Compute or
    Amazon’s AWS) to run Faceswap remotely.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以通过租赁云服务（如 Google 的云计算或 Amazon 的 AWS）来远程运行 Faceswap。
- en: Installing and setting up the software will not be covered in this chapter,
    as the method will vary between OSs, and detailed installation instructions can
    be found on the Faceswap website ([https://forum.Faceswap.dev/viewforum.php?f=4](https://forum.Faceswap.dev/viewforum.php?f=4)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将不涵盖软件的安装和设置，因为方法会因操作系统而异，详细的安装说明可以在 Faceswap 网站上找到 ([https://forum.Faceswap.dev/viewforum.php?f=4](https://forum.Faceswap.dev/viewforum.php?f=4))).
- en: Identifying suitable candidates for a swap
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定适合交换的候选对象
- en: While it is technically possible to swap any face with another, creating a convincing
    deepfake requires paying some attention to the attributes of your source and destination
    faces. Depending on what you hope to achieve from your deepfake, this may be more
    or less important to you, but assuming that you wish to create a convincing swap,
    you should pay attention to the following attributes.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然技术上可以将任何面部与另一个面部交换，但要创建一个令人信服的深度伪造，需要关注源面和目标面的属性。根据你希望从你的深度伪造中实现的目标，这可能对你来说更重要或更不重要，但假设你希望创建一个令人信服的交换，你应该注意以下属性。
- en: '**Face/head shape**: Are the shapes of the faces similar to one another? If
    one face is quite narrow and the other quite round, then while the facial features
    will be correct, the final swap is unlikely to be particularly convincing if the
    final swap contains a head shape that is significantly different from the individual
    you are attempting to target.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面部/头部形状**：面部的形状是否相似？如果一个面部非常窄而另一个非常圆，那么尽管面部特征将是正确的，但如果最终交换包含一个与你要尝试针对的个人显著不同的头部形状，那么最终交换可能不会特别令人信服。'
- en: '**Hairline/hairstyles**: While it is possible to do full head swaps, these
    are generally harder to pull off, as hair is complex, and hairstyles can change
    significantly. You will generally be swapping the face but keeping the hair from
    the original material, so you need to keep hairline and hairstyles in mind when
    considering your swap.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发际线/发型**：虽然可以进行整个头部的交换，但这些通常更难实现，因为头发很复杂，发型也可能有显著变化。你通常会交换面部，但保留原始材料中的头发，因此当你考虑交换时，需要考虑发际线和发型。'
- en: '**Skin tone**: The neural network will do some work in matching the skin tone
    between the faces that you train the model on; however, this will only work to
    a certain extent. As some attributes of the original face are likely to still
    exist within the final swap when it is blended into the original frame, it is
    important to ensure that the natural skin tone between the faces is not significantly
    different.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**肤色**：神经网络将在匹配你训练模型时使用的面部之间的肤色方面做一些工作；然而，这只能在一定程度上起作用。由于原始面部的某些属性很可能仍然存在于最终交换中，当它融合到原始框架中时，确保两个面部的自然肤色没有显著差异是很重要的。'
- en: Once you have identified your candidates for creating a deepfake, it is time
    to collect data to train the model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了用于创建深度伪造的候选人，就是时候收集数据来训练模型了。
- en: Preparing the training images
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备训练图像
- en: In this section, we will be collecting, extracting, and curating the images
    to train our model. Far and away the best sources for collecting face data are
    video files. Videos are just a series of still images, but as you can obtain 25
    still images for every second of video in a standard 25 FPS file, they are a valuable
    and plentiful resource. Video is also likely to contain a lot more natural and
    varied poses than photographs, which tend to be posed and contain limited expressions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将收集、提取和整理图像以训练我们的模型。收集面部数据最好的来源无疑是视频文件。视频只是一系列静态图像，但因为你可以在标准25 FPS文件中每秒获得25张静态图像，所以它们是一个宝贵且丰富的资源。视频还可能包含比照片更多的自然和多样的姿势，而照片往往是有姿势的，并且表情有限。
- en: Video sources should be of a high quality. The absolute best source of data
    is HD content encoded at a high bitrate. You should be wary of video content acquired
    from online streaming platforms, as these tend to be of a low bitrate, even if
    the resolution is high. For similar reasons, JPEG images can also be problematic.
    The neural network will learn to recreate what it sees, and this will include
    learning compression artifacts from low-bitrate/highly compressed sources. Footage
    filmed on a modern-day smartphone or better, or extracted from Blu-ray or DVD
    sources, is ideal. One caveat to this is that you should avoid using HDR footage
    at all costs. HDR, by its very nature, contains images within a dynamic range.
    Neural networks expect the data they receive to be within a consistent range,
    so they struggle with HDR data and, quite often, cannot learn at all when provided
    with this kind of data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 视频源应具有较高的质量。最佳的数据来源是高比特率编码的HD内容。您应谨慎对待从在线流媒体平台获取的视频内容，因为这些内容往往比特率较低，即使分辨率较高。出于类似原因，JPEG图像也可能存在问题。神经网络将学会重现它所看到的内容，这包括从低比特率/高度压缩的源中学习压缩伪影。使用现代智能手机或更好的设备拍摄的素材，或从蓝光或DVD源中提取的素材，是理想的。但有一点需要注意，那就是您应不惜一切代价避免使用HDR素材。HDR的本质是包含动态范围内的图像。神经网络期望接收到的数据在一致的范围内，因此它们在处理HDR数据时会有所困难，而且常常在提供这类数据时无法学习。
- en: You are looking to collect material from as many different sources as possible.
    It is a misconception that a model is trained for a specific scene. Neural networks
    of the type that deepfakes use benefit from highly varied data. As the neural
    network is looking to encode important features for each of the faces it sees,
    giving it as much varied data as possible will enable it to generate better encodings
    and better feature maps. This includes variety in poses, expressions, and lighting
    conditions. While the neural network will do some work to simulate different lighting
    conditions, this is to help augment already varied data rather than act as a replacement
    for missing data. The neural network will not be able to create poses and expressions
    that are significantly different from anything it has seen before.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望尽可能从多个不同的来源收集材料。一个误区是模型是为特定场景训练的。深度伪造所使用的神经网络类型受益于高度多样化的数据。由于神经网络正在寻找为它看到的每个面部编码重要特征，因此尽可能多地提供多样化的数据将使它能够生成更好的编码和更好的特征图。这包括姿势、表情和光照条件的多样性。虽然神经网络会做一些工作来模拟不同的光照条件，但这是为了帮助增强已经多样化的数据，而不是作为缺失数据的替代。神经网络无法创建与之前所见内容显著不同的姿势和表情。
- en: Extracting faces from your source data
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从您的源数据中提取面部
- en: Now that you have a variety of sources, the next step is to extract and **align**
    the faces (a process that normalizes the faces in the images) from these sources
    to build your training set. You are looking to collect between 500 to 50,000 faces
    for each side that you intend to train on. The variety of data is more important
    than the quantity of data. Five-hundred highly varied faces will lead to far superior
    results than 50,000 near-identical faces.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有了多种来源，下一步是从这些来源中提取并**对齐**（一个将图像中的面部进行归一化的过程）面部，以构建您的训练集。您希望收集500到50,000张面部，以便对每一边进行训练。数据的多样性比数据量更重要。500张高度多样的面部将比50,000张几乎相同的面部产生更好的结果。
- en: 'During the extraction process, an “alignments file” will be created. This file
    (with a `.fsa` extension) contains information about the faces that have been
    discovered within each of your sources. With this in mind, it is good practice
    to set up a project folder structure to store your data so that you can easily
    locate and edit any of the data as required. A reasonable structure could be along
    the following lines:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在提取过程中，将创建一个“对齐文件”。此文件（具有`.fsa`扩展名）包含有关您每个来源中发现的每个面部的信息。考虑到这一点，设置一个项目文件夹结构来存储您的数据是一个好习惯，这样您可以轻松地找到并编辑所需的数据。一个合理的结构可能如下所示：
- en: '![Figure 4.1 – A suggested Faceswap folder structure](img/B17535_04_001.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 – 建议的Faceswap文件夹结构](img/B17535_04_001.jpg)'
- en: Figure 4.1 – A suggested Faceswap folder structure
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 建议的Faceswap文件夹结构
- en: For each side of the model (**A** and **B**), we are creating a folder to store
    the source videos in, along with their associated generated alignments files (**Videos**),
    and a faces folder to store the extracted faces (**Faces**). If you are extracting
    from images as a source for faces, then you can add an **Images** folder.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型的每一侧（**A**和**B**），我们都在创建一个文件夹来存储源视频以及相关的生成对齐文件（**Videos**），以及一个用于存储提取面部的**Faces**文件夹。如果您将图像作为面部源进行提取，则可以添加一个**Images**文件夹。
- en: 'Copy the video and image source files to their associated folders and launch
    the Faceswap application:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将视频和图像源文件复制到相应的文件夹，并启动Faceswap应用程序：
- en: '![Figure 4.2 – The Faceswap GUI](img/Image98335.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2 – Faceswap GUI](img/Image98335.jpg)'
- en: Figure 4.2 – The Faceswap GUI
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 – Faceswap GUI
- en: The application is divided up into separate sections, depending on the task
    that you are currently performing. At this stage, we are extracting faces, so
    make sure that the **Extract** tab is selected.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您当前执行的任务，应用程序被划分为不同的部分。在此阶段，我们正在提取面部，因此请确保已选择**提取**选项卡。
- en: There are many options available here, but we will just be focusing on those
    that are required to generate a training set. Optional or unnecessary options
    will be skipped for brevity, but you can view the tooltip for more information
    in the GUI.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有许多选项可用，但我们只关注那些用于生成训练集所必需的选项。为了简洁，将跳过可选或不必要的选项，但您可以在GUI中查看工具提示以获取更多信息。
- en: Tip
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Faceswap comes with built-in **tooltips** that explain what each option does.
    Hover over the entries to access the corresponding ToolTip.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Faceswap内置了**工具提示**，解释每个选项的功能。将鼠标悬停在条目上以访问相应的工具提示。
- en: Data
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'This section is where the location of the source material that we intend to
    extract faces from is entered, as well as the location that we wish to extract
    the faces to:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此部分是输入我们打算从中提取面部以及我们希望提取面部的位置的源材料的位置：
- en: '**Input Dir**: The location of the source video file or folder of images that
    contain the faces you wish to extract. Clicking the buttons on the right will
    launch a file browser to easily navigate to the correct location. Select the left-hand
    icon if extracting faces from a video file or the right-hand icon if extracting
    faces from a folder of images.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入目录**：源视频文件或包含您希望提取的面部的图像文件夹的位置。点击右侧的按钮将启动文件浏览器，以便轻松导航到正确的位置。如果从视频文件中提取面部，则选择左侧图标；如果从图像文件夹中提取面部，则选择右侧图标。'
- en: '**Output Dir**: The location that identified faces should be extracted to.
    This should be a new folder within the **Faces** folder that you set up when creating
    your project folder structure.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出目录**：识别的面部应提取到的位置。这应该是您在创建项目文件夹结构时设置的**Faces**文件夹中的新文件夹。'
- en: '![Figure 4.3 – The Data section for face extraction](img/B17535_04_003.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 面部提取的数据部分](img/B17535_04_003.jpg)'
- en: Figure 4.3 – The Data section for face extraction
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 面部提取的数据部分
- en: Next, let’s look at the plugins we can use.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看我们可以使用的插件。
- en: Plugins
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插件
- en: 'The plugins section is where the neural networks that will we use to identify
    faces within the images are chosen, as well as those plugins that identify the
    key landmarks within the face and any neural network-based masks to apply to the
    extracted faces:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 插件部分是选择我们将用于在图像中识别面部以及识别面部关键地标和应用于提取面部任何基于神经网络的掩码的插件的区域：
- en: '**Detector**: The detector identifies faces within each of the images. The
    most robust detector at the time of writing is **S3Fd** (based on the paper Single
    Shot Scale-Invariant Face Detector: https://arxiv.org/abs/1708.05237). It is,
    however, resource-intensive, requiring at least 3 GB of GPU memory to run. It
    also runs incredibly slowly on a CPU due to its complexity. However, if you have
    the resources available, this is the detector to use. Otherwise, the **MTCneural
    network** ([https://arxiv.org/abs/1604.02878](https://arxiv.org/abs/1604.02878))
    detector should be used, which will run on far fewer resources and runs a lot
    quicker on a CPU.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探测器**：探测器用于识别每张图像中的面部。截至编写时，最稳健的探测器是**S3Fd**（基于论文《单次射击尺度不变面部探测器》：https://arxiv.org/abs/1708.05237）。然而，它非常消耗资源，运行时至少需要3
    GB的GPU内存。由于其复杂性，它也在CPU上运行得非常慢。但是，如果您有可用的资源，这就是您应该使用的探测器。否则，应使用**MTCneural网络**（[https://arxiv.org/abs/1604.02878](https://arxiv.org/abs/1604.02878)）探测器，它将使用更少的资源，并且在CPU上运行得更快。'
- en: '**Aligner**: Responsible for identifying key facial landmarks. These landmarks
    are used for aligning any faces detected so that they are consistent for feeding
    the model during training. **FAN** ([https://arxiv.org/pdf/1703.07332.pdf](https://arxiv.org/pdf/1703.07332.pdf))
    is the best aligner and, if at all possible, should be the option you select here.
    It is, however, slow on a CPU, in which case, the **CV2-D** neural network aligner
    is available. While this will run a lot quicker on a CPU, it is far inferior to
    FAN.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对齐器**：负责识别关键面部地标。这些地标用于对齐检测到的任何面部，以便在训练期间输入模型时保持一致性。**FAN** ([https://arxiv.org/pdf/1703.07332.pdf](https://arxiv.org/pdf/1703.07332.pdf))
    是最佳对齐器，如果可能的话，应选择此选项。然而，它在CPU上运行较慢，在这种情况下，可使用**CV2-D**神经网络对齐器。虽然这将在CPU上运行得更快，但它的性能远不如FAN。'
- en: '**Masker**: When extracting faces, it is also possible to use neural networks
    for masking an area of interest. Specifically, we are only interested in training
    our model on the face area of the extracted image. The background to the face
    that is included in the extracted images just adds noise to the model, which it
    is advantageous to exclude. Two masks are always included by default, based on
    the landmark data generated by the aligner. The landmark-based masks are fine
    for a lot of use cases, but they are limited insofar as they do not include the
    forehead within the masked area (they crop just above the eyebrows). The neural
    network-based masks attempt to address this issue by using AI to generate masks
    on extracted faces. Generally, the **BiSeNet-FP** mask works best.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮罩器**：在提取面部时，还可以使用神经网络来对感兴趣的区域进行遮罩。具体来说，我们只对在提取图像的面部区域进行模型训练感兴趣。包含在提取图像中的面部背景只会给模型增加噪声，这有利于排除。默认情况下，总是包括两个遮罩，基于对齐器生成的地标数据。基于地标的数据遮罩对于许多用例来说很好，但它们有限，因为它们不包括在遮罩区域内的额头（它们在眉毛上方裁剪）。基于神经网络的遮罩通过使用AI在提取面部上生成遮罩来尝试解决这个问题。通常，**BiSeNet-FP**遮罩效果最佳。'
- en: It is worth noting that masks do not need to be created at extract time. Faceswap
    includes a tool to add masks to training sets after extraction has been performed.
    This can be beneficial, as often you will not want to spend time generating neural
    network-based masks until you are happy that the extracted faces are correct and
    properly aligned. Be aware that the more neural network-based masks that are added
    (multiple masks can be selected), the longer the extraction process will take.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，遮罩不需要在提取时创建。Faceswap包括一个工具，在提取完成后向训练集中添加遮罩。这可能是有益的，因为通常你不会想在提取的面部正确且正确对齐后才生成基于神经网络的遮罩。请注意，添加的基于神经网络的遮罩越多（可以选择多个遮罩），提取过程将需要更长的时间。
- en: '![Figure 4.4 – A side-by-side comparison of a BiSeNET-FP (neural network-based)
    mask (top) and a components (landmarks-based) mask (bottom). The left image is
    the original aligned face, the right image is the generated mask, and the center
    image is the aligned face with the mask applied](img/B17535_04_004.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4 – BiSeNET-FP（基于神经网络）遮罩（顶部）和组件（基于地标）遮罩（底部）的并排比较。左侧图像是原始对齐面部，右侧图像是生成的遮罩，中间图像是应用遮罩的对齐面部](img/B17535_04_004.jpg)'
- en: Figure 4.4 – A side-by-side comparison of a BiSeNET-FP (neural network-based)
    mask (top) and a components (landmarks-based) mask (bottom). The left image is
    the original aligned face, the right image is the generated mask, and the center
    image is the aligned face with the mask applied
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – BiSeNET-FP（基于神经网络）遮罩（顶部）和组件（基于地标）遮罩（底部）的并排比较。左侧图像是原始对齐面部，右侧图像是生成的遮罩，中间图像是应用遮罩的对齐面部
- en: '**Normalization**: When the aligner is looking to identify key landmarks, it
    can help to normalize the image being fed to the plugin. Generally, **histogram
    normalization** (**Hist**) or **contrast limited adaptive histogram equalization**
    (**CLAHE**) works best, but it will depend on the source material.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化**：当对齐器正在寻找识别关键地标时，对插件输入的图像进行归一化可能会有所帮助。通常，**直方图归一化**（**Hist**）或**对比度受限自适应直方图均衡化**（**CLAHE**）效果最佳，但这将取决于原始材料。'
- en: '**Re Feed**/**Rotate Images**: To generate a training set, these options are
    not necessary and should be left at their default values (**1** and blank respectively).'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新填充**/**旋转图像**：为了生成训练集，这些选项不是必需的，应保留其默认值（分别为**1**和空白）。'
- en: '![Figure 4.5 – The Plugins selection options for face extraction](img/B17535_04_005.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – 面部提取的插件选择选项](img/B17535_04_005.jpg)'
- en: Figure 4.5 – The Plugins selection options for face extraction
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 人脸提取的插件选择选项
- en: Face processing
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人脸处理
- en: Face processing is any task that should be performed after faces have been identified
    within an image. The only option of concern here is **Min Size**. False positives
    can be found by the detector (items that the detector considers a face but are
    not actually so). This option allows you to discard faces that do not meet this
    minimum threshold (measured in pixels from corner to corner of the detected face).
    The value specified here will vary, depending on the size of the input frames
    and how many of the images are taken up by the faces you are interested in. Leaving
    it set at a low value, regardless, can help with the curation of data within the
    next phase.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸处理是在图像中识别人脸之后应执行的任务。这里需要关注的唯一选项是**最小尺寸**。检测器可能会找到假阳性（检测器认为是人脸但实际上不是的情况）。此选项允许你丢弃不符合此最小阈值（以像素为单位，从检测到的脸的角到角测量）的人脸。这里指定的值将根据输入帧的大小以及你感兴趣的人脸在图像中占据的多少而变化。无论如何，将其设置为低值可以帮助在下一阶段筛选数据。
- en: The other option within this section is the face filter. Generally, it is advised
    to avoid using the filter, as it can be somewhat hit and miss at correctly identifying
    faces and will significantly slow down the extraction process.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的另一个选项是人脸过滤器。通常建议避免使用过滤器，因为它在正确识别人脸方面可能不太准确，并且会显著减慢提取过程。
- en: '![Figure 4.6 – The Face Processing options for face extraction](img/B17535_04_006.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 人脸提取的人脸处理选项](img/B17535_04_006.jpg)'
- en: Figure 4.6 – The Face Processing options for face extraction
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 人脸提取的人脸处理选项
- en: Output
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出
- en: The final area of interest is the **Output** section. The only option that needs
    to be amended from default is the **Extract Every N** option. While you need lots
    of images to train a model, variety is more important. When using video as a source
    of training images, each frame is extremely similar to its immediate neighbor.
    To reduce the number of similar faces that will be extracted, it is possible to
    skip frames to parse for faces. The number that is set here will depend on the
    frame rate of your video, as well as the number of sources that you intend to
    extract faces from. Generally, between 2 to 8 frames per second of video is a
    good number to aim for (for example, for a 30 fps video, an **Extract Every N**
    value of 6 will extract faces from 5 frames for every 1 second of video).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后关注的区域是**输出**部分。需要修改的默认选项只有**每 N 提取**。虽然你需要大量的图像来训练模型，但多样性更为重要。当使用视频作为训练图像的来源时，每一帧与其相邻帧极为相似。为了减少将要提取的相似人脸数量，可以跳过一些帧来解析人脸。这里设置的数字将取决于视频的帧率以及你打算从中提取人脸的源数量。通常，每秒
    2 到 8 帧的视频是一个好的目标数字（例如，对于 30 fps 的视频，**每 N 提取**的值为 6 将在每秒视频中提取 5 帧的人脸）。
- en: '![Figure 4.7 – The Output options for face extraction](img/B17535_04_007.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 人脸提取的输出选项](img/B17535_04_007.jpg)'
- en: Figure 4.7 – The Output options for face extraction
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 人脸提取的输出选项
- en: Extract
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提取
- en: Now that the options have all been set, the **Extract** button can be pressed.
    This will extract all of the discovered faces into your given folder and generate
    the corresponding alignments file. The amount of time this will take will depend
    on the available hardware, the length of the source material, and the plugins
    that have been chosen.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在所有选项都已设置，可以按下**提取**按钮。这将把所有发现的人脸提取到指定的文件夹中，并生成相应的对齐文件。这个过程所需的时间将取决于可用硬件、源材料的长度以及所选的插件。
- en: Curating training images
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 筛选训练图像
- en: Once faces have been extracted, the data needs to be curated. The neural networks
    used to identify, extract, and align faces do a good job, but they are not perfect.
    Along with the correctly detected and aligned faces, it is most likely that a
    not insignificant amount of unusable data will also have been collected. This
    may include faces other than the target, false positives (parts of the image that
    the neural network considers a face but are not actually so), and misaligned faces
    (faces that have been correctly identified but the aligner has failed to align
    them correctly).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提取了面部，就需要对数据进行整理。用于识别、提取和对齐面部的神经网络做得很好，但它们并不完美。除了正确检测和对齐的面部外，很可能还会收集到相当数量的不可用数据。这可能包括目标之外的面部、假阳性（神经网络认为是面部但实际上不是的面部部分）以及未正确对齐的面部（被正确识别但对齐器未能正确对齐的面部）。
- en: '![Figure 4.8 – A concentrated example of misaligned faces](img/B17535_04_008.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 不对齐的面部集中示例](img/B17535_04_008.jpg)'
- en: Figure 4.8 – A concentrated example of misaligned faces
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 不对齐的面部集中示例
- en: Examining a folder that contains a significant number of unusable faces, it
    may, at first, appear to be a mammoth task to clean up and curate the training
    images. Fortunately, neural networks can again be leveraged to make this job a
    lot easier.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 检查包含大量不可用面部的文件夹，一开始可能看起来清理和整理训练图像是一项庞大的任务。幸运的是，可以再次利用神经网络使这项工作变得容易得多。
- en: Sorting the faces
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排序面部
- en: 'The faces will have been extracted in frame order – that is, they will exist
    within the output folder in the order that they were discovered within the source
    video or images. Faceswap includes a number of sorting mechanisms to arrange these
    faces in an order to enable easier pruning, which can be accessed by selecting
    the **Tools** tab, followed by the **Sort** sub-tab:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 面部将按照帧顺序提取 – 即，它们将按照在源视频或图像中发现它们的顺序存在于输出文件夹中。Faceswap 包含多种排序机制，可以将这些面部按顺序排列，以便更容易地进行修剪，这可以通过选择
    **工具** 选项卡，然后选择 **排序** 子选项卡来访问：
- en: '![Figure 4.9 – The Sort tool within the Tools section of Faceswap](img/B17535_04_009.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – Faceswap 工具部分中的排序工具](img/B17535_04_009.jpg)'
- en: Figure 4.9 – The Sort tool within the Tools section of Faceswap
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – Faceswap 工具部分中的排序工具
- en: The most powerful sorting method, by some distance, is to sort by **face**.
    This uses the neural network **VGG Face 2** developed by researchers at the Visual
    Geometry Group at the University of Oxford ([https://arxiv.org/abs/1710.08092](https://arxiv.org/abs/1710.08092)).
    Faceswap utilizes this network to cluster similar faces together, making the data
    far easier to parse.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最强大的排序方法，无疑是通过**面部**排序。这使用了由牛津大学视觉几何组研究人员开发的神经网络**VGG Face 2** ([https://arxiv.org/abs/1710.08092](https://arxiv.org/abs/1710.08092))。Faceswap利用这个网络将相似的面部聚类在一起，使得数据处理变得容易得多。
- en: 'Within the **Sort** section of Faceswap, the following options should be selected:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Faceswap 的 **排序** 部分中，应选择以下选项：
- en: '**Input**: The folder that contains the extracted faces that are to be curated'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入**：包含要整理的提取面部的文件夹'
- en: '**Sort By**: Select **Face**'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**排序方式**：选择**面部**'
- en: '**Final Process**: Rename (the faces will be sorted in place, with the filenames
    renamed)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终步骤**：重命名（面部将就地排序，文件名将被重命名）'
- en: 'All other options can be left at their default values, as shown in the following
    screenshot:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他选项都可以保留默认值，如下面的截图所示：
- en: '![Figure 4.10 – The selected options within Faceswap’s Sort tool](img/B17535_04_010.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – Faceswap 排序工具中的选择选项](img/B17535_04_010.jpg)'
- en: Figure 4.10 – The selected options within Faceswap’s Sort tool
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – Faceswap 排序工具中的选择选项
- en: Press the **Sort** button to launch the sorting process. Depending on your setup
    and the number of faces to be sorted, this may take some time.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**排序**按钮以启动排序过程。根据您的设置和要排序的面部数量，这可能需要一些时间。
- en: Removing faces
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除面部
- en: Once the sorting process has completed, the OS’s standard file manager can be
    used to scroll through the folder and remove any incorrect faces. The sorting
    process will have grouped all of the similar faces together, making this a far
    simpler task, as all of the misidentified faces can be bulk selected and deleted.
    Just ensure that the sort order of the folder is by **filename**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦排序过程完成，可以使用操作系统的标准文件管理器浏览文件夹并删除任何错误的面部。排序过程会将所有相似的面部分组在一起，这使得这项任务变得简单得多，因为所有误识别的面部都可以批量选择并删除。只需确保文件夹的排序顺序是按**文件名**排序。
- en: It is also a good idea, at this stage, to remove any faces that are not of suitable
    quality for training. This includes those images that are of the target individual
    but are sub-standard in some way – for instance, if the face is not aligned correctly
    within the frame, the face is significantly obstructed, or the quality of the
    image is too low. Generally, training images should be of high quality. Not all
    low-quality/blurry images need to be removed from the training set, as the neural
    network will also need to know how to recreate these lower-quality/resolution
    images; however, they should form a minority of the training set.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，移除任何不适合训练的高质量面部图像也是一个好主意。这包括那些虽然是目标个体的图像，但在某些方面不符合标准的情况——例如，如果面部在框架内没有正确对齐，面部被严重遮挡，或者图像质量太低。通常，训练图像应该是高质量的。并非所有低质量/模糊的图像都需要从训练集中移除，因为神经网络也需要知道如何重新创建这些低质量/分辨率的图像；然而，它们应该只占训练集的一小部分。
- en: Now that the folder just contains faces that are suitable for training, it is
    a best practice to clean the alignments file. This is the process of removing
    the faces that you have just deleted from that file. This enables us to go back
    to the video source and alignments file and re-extract the faces, while avoiding
    the requirement to sort the data again. This action has a second advantage, insofar
    as it will also rename all the faces their original filenames.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在文件夹中只包含适合训练的面部图像，最佳实践是清理对齐文件。这是从该文件中删除您刚刚删除的面部图像的过程。这使得我们可以回到视频源和对齐文件，重新提取面部图像，同时避免再次排序数据的需求。这一动作还有一个优点，即它还将所有面部重命名为它们的原始文件名。
- en: 'Once again, Faceswap has a tool to help with this – specifically, navigate
    to the **Tools** tab and then the **Alignments** sub-tab:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，Faceswap有一个工具可以帮助完成这项任务——具体来说，导航到**工具**标签，然后是**对齐**子标签：
- en: '![Figure 4.11 – The location of the Alignments tool within Faceswap](img/B17535_04_011.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11 – Alignments工具在Faceswap中的位置](img/B17535_04_011.jpg)'
- en: Figure 4.11 – The location of the Alignments tool within Faceswap
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 – Alignments工具在Faceswap中的位置
- en: 'The **Alignments** tool allows multiple actions to be performed on the alignments
    file. The job that is of interest is **Remove-Faces**, which examines a folder
    of faces and removes the faces that you have deleted from the alignments file.
    The following options should be selected:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**对齐**工具允许对对齐文件执行多个操作。感兴趣的作业是**移除面部**，它检查一个面部文件夹，并从对齐文件中移除您已从对齐文件中删除的面部。应选择以下选项：'
- en: '**Job**: Select **Remove-Faces**'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作业**：选择**移除面部**'
- en: '`.fsa` alignments file'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.fsa`对齐文件'
- en: '**Faces Folder**: Browse to the location that contains your curated face set
    and select the folder'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面部文件夹**：浏览到包含您精选面部集的位置，并选择文件夹'
- en: 'All other options can be left at their default values:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他选项都可以保留其默认值：
- en: '![Figure 4.12 – The selected options within Faceswap’s Alignments tool](img/B17535_04_012.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – Faceswap对齐工具中的选择选项](img/B17535_04_012.jpg)'
- en: Figure 4.12 – The selected options within Faceswap’s Alignments tool
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – Faceswap对齐工具中的选择选项
- en: Press the **Alignments** button. A backup of the alignments file will be taken,
    then the process will remove all the faces that do not appear in the faces folder
    from the file. Finally, the faces will be renamed with their originally extracted
    names.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 按下**对齐**按钮。将对齐文件进行备份，然后过程将删除文件中未出现在面部文件夹中的所有面部。最后，面部将被重命名为它们最初提取的名称。
- en: Collating training images
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 整理训练图像
- en: Now that the training sources have been curated, the images can be collated
    into the final training sets.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练源已经整理完毕，可以将图像整理成最终的训练集。
- en: Tip
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: If the required mask was not generated during extraction, it can also be added
    to the faces now, using the **Mask** tool (the **Tools** tab | the **Mask** sub-tab).
    This should be done prior to collating the final training sets.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在提取过程中没有生成所需的掩码，现在也可以使用**掩码**工具（**工具**标签 | **掩码**子标签）将其添加到面部。这应该在整理最终训练集之前完成。
- en: This is as simple as taking all of the contents of each source’s extracted faces
    and placing them all into the same folder (one folder for the **A** side, and
    one folder for the **B** side). All the information required by Faceswap to train
    on these images is stored within the EXIF header of the PNG images.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像将每个源提取的面部内容的全部放入同一个文件夹中（一个文件夹用于**A**面，另一个文件夹用于**B**面）。Faceswap训练这些图像所需的所有信息都存储在PNG图像的EXIF头部中。
- en: Some final curating may be required to bring the number of training images down
    to a manageable size, but anywhere in the region of 500 to 50,000 images per side
    of the model is reasonable.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 可能需要进行一些最终的整理，以将训练图像的数量减少到可管理的规模，但模型每一边大约有 500 到 50,000 张图像是合理的。
- en: Now that the data has been collected and curated, it is time to train the model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经收集和整理，是时候训练模型了。
- en: Training a model
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: This part of the process requires the least amount of manual intervention but
    will take the longest in terms of compute time. Depending on the model chosen
    and the hardware in use, this can take anywhere from 12 hours to several weeks
    to complete.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程需要最少的手动干预，但在计算时间上会花费最长。根据所选模型和硬件，这个过程可能需要从 12 小时到几周不等才能完成。
- en: It is advised to use a relatively lightweight model when creating a deepfake
    for the first time. Creating swaps is fairly nuanced, and understanding what works
    and what doesn’t comes with experience. Whilst Faceswap offers several models,
    starting with the **Original** or **Lightweight** model will allow you to gauge
    the performance of the swap relatively quickly, while not necessarily giving you
    the best possible final result.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 建议在第一次创建深度伪造时使用相对轻量级的模型。创建交换操作相当复杂，而了解哪些有效哪些无效则需要经验。虽然 Faceswap 提供了多个模型，但开始时使用
    **原始** 或 **轻量级** 模型将允许你相对快速地评估交换的性能，而不会必然给出最佳可能的结果。
- en: Faceswap comes with numerous configurable settings for models and training.
    These are available within the **Settings** menu of the application. To cover
    all of these settings is well outside of the scope of this walk-through, so default
    settings will be used unless otherwise stated.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Faceswap 为模型和训练提供了许多可配置的设置。这些设置在应用程序的 **设置** 菜单中可用。要涵盖所有这些设置超出了本指南的范围，因此除非另有说明，否则将使用默认设置。
- en: Setting up
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: 'Navigate to the **Train** tab of the Faceswap application:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到 Faceswap 应用程序的 **训练** 选项卡：
- en: '![Figure 4.13 – The training options section of Faceswap](img/B17535_04_013.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – Faceswap 的训练选项部分](img/B17535_04_013.jpg)'
- en: Figure 4.13 – The training options section of Faceswap
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – Faceswap 的训练选项部分
- en: Faces
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面部
- en: 'This section is where we tell the process where our training images are stored.
    If you followed the extraction and curation steps, then these faces will exist
    within your project folder, with a single folder for each side:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分内容是告知我们的训练图像存储的位置。如果你遵循了提取和整理步骤，那么这些面部图像将存在于你的项目文件夹中，每一边都有一个单独的文件夹：
- en: '**Input A**: The path to the folder containing the extracted faces for the
    **A** side of the model (that is, the original face that is to be removed from
    the final video).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入 A**：包含模型 **A** 边提取的面部文件夹的路径（即要从最终视频中移除的原始面部）。'
- en: '**Input B**: The path to the folder containing the extracted faces for the
    **B** side of the model (that is, the face that you wish to transpose to the final
    video).'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入 B**：包含模型 **B** 边提取的面部文件夹的路径（即你希望转置到最终视频中的面部）。'
- en: '![Figure 4.14 – The Faces options for training a model](img/B17535_04_014.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.14 – 训练模型的面部选项](img/B17535_04_014.jpg)'
- en: Figure 4.14 – The Faces options for training a model
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – 训练模型的面部选项
- en: Model
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型
- en: 'The model section is where Faceswap is instructed on which model to use, where
    that model should be stored, and any model-specific actions to perform at runtime:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部分是指导 Faceswap 使用哪个模型，模型应存储在哪里，以及在运行时执行任何特定于模型的操作：
- en: '**Model Dir**: The folder that the model should be stored in, or if you are
    resuming a pre-existing model, then the folder that contains the model to be resumed.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型目录**：模型应存储的文件夹，或者如果你正在恢复一个现有的模型，那么应指向包含要恢复的模型的文件夹。'
- en: If you are starting a new model, then this location should not pre-exist on
    the hard drive. When the model is created, the folder specified here will be created
    and populated with the model and associated files required by Faceswap to track
    training.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在开始一个新的模型，那么这个位置在硬盘上不应预先存在。当模型创建时，这里指定的文件夹将被创建并填充上 Faceswap 需要跟踪训练所需的模型和相关文件。
- en: If you are resuming a previously created model, then this should point to the
    folder that was created when initially setting up the model (the folder created
    by Faceswap containing the associated model files).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在恢复之前创建的模型，那么这个位置应指向最初设置模型时创建的文件夹（由 Faceswap 创建并包含相关模型文件的文件夹）。
- en: '**Trainer**: Faceswap has multiple models available (named **Trainer** for
    legacy reasons). These models are more or less configurable within the **Settings**
    menu, depending on the model chosen. As discussed before, if you are just starting
    out, then it is advisable to use the **Original** or **Lightweight** model.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练器**：Faceswap有多个模型可供选择（出于历史原因命名为**训练器**）。这些模型在**设置**菜单中可配置性或多或少，取决于所选的模型。如前所述，如果您是初学者，那么建议使用**原始**或**轻量级**模型。'
- en: If you are starting a new model, then the model selected here will be the model
    used for all future training sessions of it. It is not possible to change a model
    type once it has been created.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在开始一个新的模型，那么这里选择的模型将用于该模型所有未来的训练会话。一旦创建，就无法更改模型类型。
- en: The other options within this section can be ignored for your first model, although
    they may become more relevant as you gain experience using the software. As with
    all the options, the tooltips will tell you what these additional options do.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在此部分中的其他选项在您的第一个模型中可以忽略，尽管随着您使用软件经验的增加，它们可能变得更加相关。与所有选项一样，工具提示会告诉您这些附加选项的功能。
- en: '![Figure 4.15 – The Model options for training in Faceswap](img/B17535_04_015.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图4.15 – Faceswap中训练的模型选项](img/B17535_04_015.jpg)'
- en: Figure 4.15 – The Model options for training in Faceswap
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15 – Faceswap中训练的模型选项
- en: Training
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: 'These options relate to how the model should be trained:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选项与模型应该如何训练有关：
- en: '**Batch Size**: The number of faces to be fed through the model at once. Generally,
    a higher batch size will lead to a higher training speed; however, higher batch
    sizes will mean the model generalizes more. Increasing batch size is only sensible
    up to a limit. Anything beyond 128 and the model will start to struggle to obtain
    useful information for each batch.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量大小**：一次通过模型传输的人脸数量。通常，较大的批量大小会导致更高的训练速度；然而，较大的批量大小意味着模型泛化能力更强。增加批量大小只有在一定范围内才是合理的。超过128，模型将开始难以从每个批量中获得有用的信息。'
- en: Batch size is also VRAM-limited. For more complicated models, you will have
    little choice but to use a smaller batch size, and obviously, the less VRAM available
    on the GPU, the more limited you are.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 批量大小也受VRAM限制。对于更复杂的模型，您可能别无选择，只能使用较小的批量大小，显然，GPU上可用的VRAM越少，您的限制就越大。
- en: '**Iterations**: This can be left at default unless it is desired that the model
    should stop after a certain number of iterations. Knowing when to stop a model
    comes from experience and is dictated by the quality of output, so it will never
    be after a “set number of iterations.”'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代次数**：除非希望模型在特定次数的迭代后停止，否则可以将其保留为默认值。何时停止模型取决于经验，并由输出质量决定，因此它永远不会在“设定次数的迭代”后停止。'
- en: '**Distributed**: This option is for multi-GPU users only. It allows for multiple
    video cards to be used, speeding up training by splitting batches over multiple
    devices.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式**：此选项仅适用于多GPU用户。它允许使用多个视频卡，通过在多个设备上分割批量来加速训练。'
- en: Tip
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: It can be beneficial to start training a model at a higher batch size to get
    the speed benefits, and then reduce it later in training to get the benefits of
    drilling down for details.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在较高的批量大小下开始训练模型以获得速度优势是有益的，然后在训练后期减少批量大小以获得深入细节的好处。
- en: '![Figure 4.16 – The Training options within Faceswap](img/B17535_04_016.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图4.16 – Faceswap中的训练选项](img/B17535_04_016.jpg)'
- en: Figure 4.16 – The Training options within Faceswap
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 – Faceswap中的训练选项
- en: Augmentation
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增强
- en: 'The **Augmentation** section allows you to enable or disable certain image
    augmentations (the way a neural network artificially increases the number of training
    images). When starting a new model, these should all be disabled (all augmentations
    are active). Later in the training session (when faces are becoming identifiable
    and more detailed), it can be desirable to turn some of these augmentations off:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**增强**部分允许您启用或禁用某些图像增强（这是神经网络人工增加训练图像数量的方式）。在开始一个新的模型时，这些都应该被禁用（所有增强都是激活的）。在训练会话的后期（当人脸变得可识别且更详细时），可能希望关闭一些这些增强：'
- en: '**Warp to Landmarks**: This is just an alternative warping technique. There
    is no conclusive evidence that enabling or disabling this option makes any real
    difference, so it is recommended to leave it disabled at all times.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**到特征点的扭曲**：这只是另一种扭曲技术。没有确凿的证据表明启用或禁用此选项会有任何真正的区别，因此建议始终将其禁用。'
- en: '**No Flip**: Faces are vaguely symmetrical. The neural network leverages this
    knowledge by flipping around 50% of the images horizontally. For nearly all use
    cases, this is fine, and all images can be flipped at all times. However, in cases
    when there are distinct details on one side of a face (for example, a beauty mark),
    then this option should be enabled when you see that faces start to take shape
    within the training preview window.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无翻转**：人脸大致是对称的。神经网络通过翻转大约50%的图像水平方向来利用这一知识。对于几乎所有用例，这是可以的，并且所有图像都可以随时翻转。然而，在人脸一侧有独特细节（例如，美人痣）的情况下，当你在训练预览窗口中看到人脸开始成形时，应启用此选项。'
- en: '**No Augment Color**: The color augmentation helps the neural network to match
    color and lighting between the A and B sides by artificially coloring and changing
    other visual attributes of the images it sees. Generally, this is always desirable
    and should be left on, but for some use cases, it can be desirable to disable
    this augmentation.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无增强颜色**：颜色增强有助于神经网络通过人工着色和改变它所看到的图像的其他视觉属性，来匹配A面和B面之间的颜色和光照。通常，这总是期望的，并且应该保持开启状态，但对于某些用例，可能希望禁用此增强。'
- en: '**No Warp**: This is possibly the most important option within this section.
    Warping is incredibly important to how a neural network learns. It is absolutely
    imperative that all models commence with warping enabled (failure to do so will
    invariably lead to a sub-standard model or, worse, model collapse). However, later
    in training, particularly when attempting to drill down into finer details, this
    warp actually becomes detrimental to the model’s training, and so this option
    to disable the warp should be selected.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无扭曲**：这是本节中可能最重要的选项。扭曲对于神经网络的学习至关重要。所有模型都必须在启用扭曲的情况下开始（未能这样做将不可避免地导致模型质量低下，或者更糟，模型崩溃）。然而，在训练的后期，尤其是在尝试深入更细致的细节时，这种扭曲实际上对模型的训练有害，因此应选择禁用扭曲的选项。'
- en: '![Figure 4.17 – The Augmentation section to train a model](img/B17535_04_017.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图4.17 – 训练模型的增强部分](img/B17535_04_017.jpg)'
- en: Figure 4.17 – The Augmentation section to train a model
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17 – 训练模型的增强部分
- en: A rule of thumb is that if faces are recognizable and they do not appear to
    be getting any sharper over a significant period of time, then it is probably
    time to disable warping. Seeing clearly defined teeth and eye glare is a good
    indicator. It is important to note that it is near impossible to disable warping
    too late, but it is very definitely possible to disable warping too early, so
    err on the side of caution.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个经验法则是，如果人脸在相当长的时间内没有变得更清晰，那么可能就是时候禁用扭曲了。清晰地看到牙齿和眼睛反光是一个很好的指标。重要的是要注意，禁用扭曲过晚几乎是不可能的，但确实有可能过早地禁用扭曲，因此应谨慎行事。
- en: Author’s note
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注
- en: Color augmentation and warping images are both invaluable ways to get more mileage
    from your data. Like the other augmentations in this section, they change your
    image slightly, as a way to effectively get new images that the AI model hasn’t
    seen before.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色增强和图像扭曲都是从数据中获得更多收益的无价方法。就像本节中的其他增强一样，它们稍微改变了图像，作为有效获取AI模型之前未见过的图像的一种方式。
- en: Color augmentation works by slightly altering the colors of the image. This
    gives the model new colors to work with. This also helps the model with new lighting
    situations that might be absent from the data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色增强通过稍微改变图像的颜色来实现。这为模型提供了新的颜色来处理。这也帮助模型应对可能从数据中缺失的新光照情况。
- en: Warping works by slightly modifying the shape of the face in the image. This
    helps if certain expressions are less common in your data. It also helps ensure
    that the decoder builds the face from memory and not just from a copy of the original
    image.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 扭曲通过稍微修改图像中人脸的形状来实现。如果数据中某些表情比较少见，这会有所帮助。它还帮助确保解码器从记忆中构建人脸，而不仅仅是复制原始图像。
- en: Launching and monitoring training
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动和监控训练
- en: Once the model configuration has been entered and all the settings have been
    adjusted to their appropriate value, the **Train** button can be pressed to launch
    the training session. Training can and will take a long time to complete, and
    there is no mathematical or numerical measure to know when a model has finished
    training. Knowing when a model is unlikely to improve anymore mostly comes with
    experience; however, there are some indicators in place that can help us to determine
    whether it is time to stop training.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦输入了模型配置并调整了所有设置到适当的值，就可以按下**训练**按钮来启动训练会话。训练可能需要很长时间才能完成，并且没有数学或数值指标可以知道何时模型完成训练。知道何时模型不太可能再进一步主要依赖于经验；然而，有一些指标可以帮助我们确定何时应该停止训练。
- en: Previews
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预览
- en: Probably the most important measure of the model’s progress is the preview images
    themselves. At each saved iteration, a series of preview images is generated to
    enable visualization of how the model is progressing.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的进步最重要的衡量标准可能是预览图像本身。在每次保存的迭代中，都会生成一系列预览图像，以便可视化模型进展情况。
- en: '![Figure 4.18 – Faceswap’s GUI with the Preview window on the right](img/Image98480.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图4.18 – Faceswap的GUI界面，右侧是预览窗口](img/Image98480.jpg)'
- en: Figure 4.18 – Faceswap’s GUI with the Preview window on the right
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.18 – Faceswap的GUI界面，右侧是预览窗口
- en: This preview consists of 28 faces randomly picked from the training set (14
    for each side). For each training image, the original is shown, followed by an
    image showing the AI’s attempt to recreate the original face. The final image
    shows the AI’s attempt to swap the original face with the identity from the other
    side.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个预览包含从训练集中随机选取的28张人脸（每侧14张）。对于每个训练图像，首先展示原始图像，然后展示AI尝试重新创建原始人脸的图像。最后一张图像展示AI尝试将原始人脸与另一侧的身份进行交换的尝试。
- en: When training commences, these images may look like a solid color or a blurry
    image that is vaguely face-shaped; however, it will fairly quickly resolve into
    an identifiable face and slowly improve over time. It is worth noting that model
    improvement is not linear. While the faces will improve fairly quickly at first,
    this improvement will slow down until no visible difference will be seen from
    iteration to iteration. However, over a period of time, the model will improve.
    When comparing previews, it is not uncommon to compare the improvements of images
    that have been taken 10,000 to 100,000 iterations apart.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练开始时，这些图像可能看起来像单一颜色或模糊的、大致呈人脸形状的图像；然而，它们会相当快地变成可识别的人脸，并且随着时间的推移逐渐改善。值得注意的是，模型改进并非线性。虽然最初人脸会迅速改善，但这种改善会逐渐减慢，直到迭代之间没有明显的差异。然而，在一段时间内，模型会持续改善。在比较预览时，比较相隔10,000到100,000次迭代的图像改进并不罕见。
- en: Loss
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 损失
- en: Another measure available to us is the loss for each iteration. Every time a
    batch is processed through the model, the neural network scores itself for how
    well it thinks it has recreated the images. While the loss value can swing wildly
    from batch to batch, over time the average value will drop. It is important to
    note that the actual value of the loss is not important. In fact, the value itself
    is effectively meaningless. The only issue to concern ourselves with is whether
    the value is dropping. This is for a couple of reasons; firstly, different loss
    functions will result in different numbers being generated, which are not comparable
    with each other. Secondly, the loss values given do not actually represent a score
    for anything that is useful for us to measure. The loss is generated by how well
    the neural network thinks it is recreating the **A** and **B** faces. It does
    this by looking at the original face and its recreation, and scoring itself based
    on the quality of the recreation. However, this score is not useful to us. What
    we would like to see is a score based on how well the neural network is taking
    a face and swapping it with another face. As there are no real-world examples
    of people who have had their faces swapped, this is an impossible measure to achieve,
    so we make do with using the loss values for face reconstruction rather than for
    face swapping.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采用的另一个指标是每次迭代的损失。每当一批数据通过模型处理时，神经网络会为自己评分，以评估它认为重建图像的效果如何。虽然损失值可能会在批次之间大幅波动，但随时间推移，平均值会下降。需要注意的是，损失的真正值并不重要。事实上，这个值本身实际上是没有意义的。我们唯一需要关心的问题是这个值是否在下降。这有几个原因；首先，不同的损失函数会产生不同的数字，这些数字之间是不可比较的。其次，给出的损失值实际上并不代表对我们有用的任何东西的评分。损失是由神经网络认为它重建的**A**和**B**脸的效果来生成的。它是通过查看原始脸和它的重建版本，并根据重建的质量给自己评分来做到这一点的。然而，这个评分对我们来说并没有用。我们希望看到的是基于神经网络如何将一张脸与另一张脸交换的评分。由于没有现实世界中人脸交换的真实例子，这是一个无法实现的指标，所以我们只能使用损失值来进行人脸重建而不是人脸交换。
- en: Graphs
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图表
- en: While loss on its own and at any given time is not a useful measure, its trend
    over time is. Ultimately, if loss is decreasing, the model is learning. The further
    a model is trained, the harder it is to ascertain whether the loss is actually
    still decreasing over time. Faceswap collects logging data for each batch passed
    through the model in the form of **TensorFlow event logs**. These logs are stored
    in the same folder as the model and can be used to visualize data in Faceswap’s
    GUI, or analyzed using **TensorBoard** (TensorFlow’s visualization toolkit).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然损失本身在任何给定时间都不是一个有用的衡量标准，但它在时间上的趋势是。最终，如果损失在下降，那么模型正在学习。模型训练得越久，就越难确定损失是否实际上仍在随时间下降。Faceswap收集通过模型传递的每个批次的日志数据，形式为**TensorFlow事件日志**。这些日志存储在与模型相同的文件夹中，可以用于在Faceswap的GUI中可视化数据，或使用**TensorBoard**（TensorFlow的可视化工具包）进行分析。
- en: 'To analyze the learning progress of an existing model, navigate to the `state.json`
    file, located within the model folder. Once the data is parsed, session summary
    statistics will be displayed for each training session carried out:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要分析现有模型的学习进度，导航到模型文件夹中的`state.json`文件。一旦数据被解析，每个训练会话的会话摘要统计信息将显示出来：
- en: '![Figure 4.19 – Statistics for a series of Faceswap training sessions](img/B17535_04_019.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图4.19 – 一系列Faceswap训练会话的统计数据](img/B17535_04_019.jpg)'
- en: Figure 4.19 – Statistics for a series of Faceswap training sessions
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19 – 一系列Faceswap训练会话的统计数据
- en: 'Clicking the green **Graph** icon next to any of the session rows will bring
    up the training graph for that session, displaying the loss for each iteration
    during it:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 点击任何会话行旁边的绿色**图形**图标，将显示该会话的训练图，显示每次迭代中的损失：
- en: '![Figure 4.20 – A training graph showing loss over time for a Faceswap training
    session](img/B17535_04_020.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图4.20 – 显示Faceswap训练会话随时间损失变化的训练图](img/B17535_04_020.jpg)'
- en: Figure 4.20 – A training graph showing loss over time for a Faceswap training
    session
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.20 – 显示Faceswap训练会话随时间损失变化的训练图
- en: For long sessions, it can be hard to ascertain whether the loss is still falling,
    due to the sheer quantity and range of data. Fortunately, it is possible to zoom
    into a selected range of the graph to get a better idea, by selecting the **Zoom
    to Rectangle** button toward the bottom right of the screen and selecting the
    area of interest. In this example, we shall zoom in on the last 100,000 iterations
    trained and make sure that we are viewing the rolling average of the loss values.
    As we can see, the loss is still clearly improving.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 对于长时间的会话，由于数据量庞大和范围广泛，很难确定损失是否仍在下降。幸运的是，可以通过选择屏幕右下角的**缩放到矩形**按钮并选择感兴趣的区域来放大图表的选定范围，从而获得更好的了解。在这个例子中，我们将放大最后100,000次迭代的训练，并确保我们正在查看损失值的滚动平均值。正如我们所看到的，损失仍在明显改善。
- en: '![Figure 4.21 – A zoomed-in view of the last 100,000 iterations of a training
    session](img/B17535_04_021.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图4.21 – 训练会话最后100,000次迭代的放大视图](img/B17535_04_021.jpg)'
- en: Figure 4.21 – A zoomed-in view of the last 100,000 iterations of a training
    session
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.21 – 训练会话最后100,000次迭代的放大视图
- en: Manual intervention
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动干预
- en: 'While training a model is mostly a “fire and forget” task, toward the end of
    training, it can help to take some steps to improve the final output. These steps
    are by no means necessary, but they can help with the final product. For any of
    these actions to take effect, the model will need to be stopped, the relevant
    settings adjusted, and then the model can be resumed:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然训练模型主要是一个“点火后忘记”的任务，但在训练的后期，采取一些步骤来提高最终输出是有帮助的。这些步骤并非必需，但它们可以帮助提高最终产品。为了使任何这些动作生效，需要停止模型，调整相关设置，然后才能继续训练模型：
- en: '**Disabling Warp**: As previously mentioned, warping is imperative for a model
    to learn; however, as the model enters the middle to later stages of training,
    the warping augmentation can actually hurt the model in terms of image fidelity
    and clarity. Enabling the **No Warp** option is good practice for a high-quality
    final swap. As a general rule of thumb, this option should not be selected until
    you are at least 50% through the total train or you can see clearly defined features,
    such as individual teeth and eye glare. It is very hard to disable warping too
    late, but it is very easy to disable it too early. If the previews still look
    like they appear to be improving, then it is probably too early to disable warping.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**禁用变形**：如前所述，变形对于模型学习至关重要；然而，当模型进入训练的中后期阶段时，变形增强实际上可能会损害模型的图像保真度和清晰度。启用**无变形**选项是进行高质量最终交换的良好实践。一般来说，这个选项不应在选择之前至少完成50%的总训练，或者你能够清楚地看到定义明确的特点，例如单个牙齿和眼睛反光。禁用变形过晚是非常困难的，但过早禁用变形却非常容易。如果预览仍然看起来像是在改善，那么可能还太早禁用变形。'
- en: '**Lowering Learning Rate**: As the model enters the late stage of training,
    it can help to lower the learning rate. This can help the model to drill down
    into the finer details. It is common to lower the learning rate a little, resume
    training, lower it some more, resume training, and repeat this cycle until you
    are happy with the results.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降低学习率**：当模型进入训练的后期阶段时，降低学习率是有帮助的。这可以帮助模型深入到更细微的细节中。通常的做法是稍微降低学习率，然后继续训练，再降低一些，然后继续训练，重复这个循环，直到你对结果满意为止。'
- en: '**Fit Training**: A technique that can help is fitting data to the actual scene
    that is to be swapped. While it is not recommended to fully train a model only
    using data that will appear within the final swap, using this data can be useful
    to fine-tune an otherwise fully trained model.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拟合训练**：一种可以帮助的技术是将数据拟合到将要交换的实际场景中。虽然不建议仅使用最终交换中会出现的数据来完全训练模型，但使用这些数据可以用来微调其他已经完全训练好的模型。'
- en: When you are happy that you have trained the model as far as you can, it is
    time to take the trained model and apply it to a source video file to swap the
    faces.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 当你满意地认为你已经尽可能多地训练了模型时，是时候将训练好的模型应用到源视频文件上以交换面部了。
- en: Applying a trained model to perform a swap
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用训练好的模型进行交换
- en: Once the model has completed training, it can be used to swap the faces on any
    video to that contains the individual that is to be swapped out. Three items are
    required to successfully perform a swap – a video/series of images, a trained
    model, and an alignments file for the media that is to be converted. The first
    two items are self-explanatory; the alignments file is the one item we need to
    create.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型完成训练，就可以用它来交换任何包含要交换个体的视频中的面部。成功执行交换需要三个项目——一个视频/一系列图像、一个训练模型以及要转换的媒体的对齐文件。前两项是显而易见的；对齐文件是我们需要创建的一项。
- en: The alignments file
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对齐文件
- en: The alignments file is a file bespoke to Faceswap, with a `.fsa` extension.
    This file should exist for every media source that is to be converted. It contains
    information about the location of faces within a video file, the alignment information
    (how the faces are orientated within each frame), as well as any associated masks
    for each frame.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐文件是针对Faceswap定制的文件，具有`.fsa`扩展名。对于要转换的每个媒体源，都应该存在这样一个文件。它包含有关视频文件中面部位置的信息，对齐信息（每个帧中面部的方向），以及每个帧的任何相关掩码。
- en: Generating an alignments file is fairly trivial. In fact, at least one has been
    generated already when we built a training set. The process for generating training
    data and generating an alignments file is the same, bar a few changes. For this
    reason, a lot of the steps will be familiar to you, as they are the same ones
    we performed within the *Extracting faces from your source data* section. The
    most notable difference in this section is that alignment information needs to
    be generated for every single frame within the media source, while for generating
    a training set, it is more common to only extract faces for a subset of frames
    within the source material.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对齐文件相当简单。实际上，当我们构建训练集时，至少已经生成了一个。生成训练数据和生成对齐文件的过程是相同的，只是有一些变化。因此，许多步骤对你来说都很熟悉，因为它们与我们*从源数据中提取面部*部分中执行的是相同的步骤。本节最显著的区别是，需要对媒体源中的每个单独帧生成对齐信息，而在生成训练集时，通常只从源材料中提取一部分帧的面部图像。
- en: Please refer back to *Extracting faces from your source data* for a more detailed
    explanation of the common options between running an extract to generate training
    data and running an extract to perform a swap.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考*从源数据中提取面部*以获取关于在运行用于生成训练数据的提取和运行用于执行交换的提取之间常见选项的更详细说明。
- en: Within the Faceswap application, select the **Extract** tab, and then follow
    the following sections.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在Faceswap应用程序中，选择**提取**选项卡，然后按照以下部分进行操作。
- en: Data
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'This section is the location of the source material that we need to generate
    alignments for, as well as an output folder that faces will be extracted to. The
    faces generated here are not used by the Faceswap process at all, but they are
    very useful for cleaning our alignments file:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本节是生成对齐文件所需源材料的位置，以及面部将被提取到的输出文件夹。这里生成的面部在Faceswap过程中根本不使用，但它们对于清理我们的对齐文件非常有用：
- en: '**Input Dir**: The location of the media that we intend to swap the faces within'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入目录**: 我们打算在其中交换面部图像的媒体位置'
- en: '**Output Dir**: The location that identified faces will be extracted to'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出目录**: 识别出的面部将被提取到的位置'
- en: '![Figure 4.22 – The Data options within Faceswap’s extraction settings](img/B17535_04_022.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图4.22 – Faceswap提取设置中的数据选项](img/B17535_04_022.jpg)'
- en: Figure 4.22 – The Data options within Faceswap’s extraction settings
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.22 – Faceswap提取设置中的数据选项
- en: Plugins
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插件
- en: 'The plugins that are selected are likely to be the same as those selected when
    generating a training set, so refer to the previous section for more information
    on the options. Only one option within this section will likely change when extracting
    an alignments file:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 选择的插件可能与生成训练集时选择的相同，因此请参考上一节以获取有关选项的更多信息。在本节中，可能只有一个选项在提取对齐文件时会发生变化：
- en: '**Re Feed**: As the extraction process has no understanding of temporal coherence
    (that is, how each frame relates to the previous and subsequent frame), it can
    lead to “jittery” alignments within the final swap. This means that the face in
    the final swap moves a small amount from frame to frame. While this is not important
    for training sets, it is important when generating the file for the final swap.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新输入**：由于提取过程没有理解时间一致性（即每个帧与前一帧和后续帧的关系），这可能导致最终交换中的“抖动”对齐。这意味着最终交换中的面部在帧与帧之间移动一小段距离。虽然这对训练集来说并不重要，但在生成最终交换文件时却很重要。'
- en: Re Feed is a mechanism to help prevent this jitter by feeding a detected face
    into the aligner a set number of times and taking the average of the results.
    It is worth noting that each increase in the re-feed amount will slow extraction
    down, as the data needs to be passed through the process multiple times. The higher
    this number is set, the smoother the final output should be, but it is diminishing
    returns. Setting the value too high is unlikely to net any visible benefit but
    will take significantly longer to run an extract.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 重新输入是一种机制，通过将检测到的面部多次输入到对齐器中并取结果的平均值来帮助防止这种抖动。值得注意的是，重新输入量的每次增加都会减慢提取速度，因为数据需要多次通过该过程。此数值设置得越高，最终输出应该越平滑，但这是递减的回报。设置值过高不太可能带来任何明显的益处，但运行提取的时间会显著增加。
- en: Set this to a value that brings you satisfactory results, while also running
    at a speed you can live with. Any value above 1 should give improved results over
    extracting without re-feed. A re-feed value of 8–10 will likely get the output
    close to as good as it can be.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 将其设置为能带来满意结果且运行速度可接受的价值。任何大于1的值都应该比不重新输入提取时提供更好的结果。重新输入值为8-10将可能使输出接近最佳。
- en: '![Figure 4.23 – The Plugins options within Faceswap’s extraction settings](img/B17535_04_023.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图4.23 – Faceswap提取设置中的插件选项](img/B17535_04_023.jpg)'
- en: Figure 4.23 – The Plugins options within Faceswap’s extraction settings
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.23 – Faceswap提取设置中的插件选项
- en: Face Processing
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面部处理
- en: As with extracting training faces, **Min Size** is the only option within this
    section that may need to be adjusted. The value specified here will generally
    correspond to the size of the faces within the source material, but leaving it
    set at a low value, regardless, can help with removing some false positives that
    are clearly not valid faces.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 与提取训练面部一样，本节中可能需要调整的唯一选项是**最小尺寸**。此处指定的值通常对应于源材料中面部的大小，但无论怎样，将其设置为低值都可以帮助去除一些明显不是有效面部的误报。
- en: '![Figure 4.24 – The Face Processing options within Faceswap’s extraction settings](img/B17535_04_024..jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图4.24 – Faceswap提取设置中的面部处理选项](img/B17535_04_024..jpg)'
- en: Figure 4.24 – The Face Processing options within Faceswap’s extraction settings
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.24 – Faceswap提取设置中的面部处理选项
- en: Output
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出
- en: Finally, the **Output** section should be reviewed and updated. The only option
    that needs to be amended from the settings used for extracting a training set
    is **Extract Every N**. It is imperative that every frame has a corresponding
    entry in the generated alignments file, so this should be set to **1**.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，应审查和更新**输出**部分。需要从用于提取训练集的设置中修改的唯一选项是**每N个提取**。确保每个帧在生成的对齐文件中都有一个对应的条目至关重要，因此应将其设置为**1**。
- en: '![Figure 4.25 – The Output options within Faceswap’s extraction settings](img/B17535_04_025..jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图4.25 – Faceswap提取设置中的输出选项](img/B17535_04_025..jpg)'
- en: Figure 4.25 – The Output options within Faceswap’s extraction settings
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.25 – Faceswap提取设置中的输出选项
- en: Extract
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提取
- en: Once the appropriate settings have been locked in, press the **Extract** button,
    to generate the alignments file and extract the found faces into the given folder.
    The amount of time this will take will depend on the available hardware, the length
    of the source material, and the re-feed value that has been set.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦锁定了适当的设置，请按**提取**按钮，以生成对齐文件并将找到的面部提取到指定的文件夹中。这需要的时间将取决于可用硬件、源材料的长度以及已设置的重新输入值。
- en: Cleaning the alignments file
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理对齐文件
- en: Similarly to when we collected faces to build a training set, the extraction
    process will have done a decent job of identifying faces, but it will not have
    done a perfect job, so some manual processing is now required to clean up the
    alignments file. The process is the same as that in the *Curating training images*
    section with an additional step, so follow the steps within that section to perform
    the initial cleansing of the alignments file. Once unwanted faces have been removed
    from the alignments file, the folder of extracted faces can be deleted. The faces
    are not actually used by the conversion process; they are just used as a mechanism
    to clean the alignments file.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们收集面部以构建训练集时，提取过程会对识别面部做相当好的工作，但不会做到完美，因此现在需要一些手动处理来清理对齐文件。这个过程与*整理训练图像*部分相同，但增加了一个额外步骤，因此请遵循该部分中的步骤来执行对齐文件的初步清理。一旦从对齐文件中移除了不需要的面部，可以删除提取面部的文件夹。面部实际上并不用于转换过程；它们只是用作清理对齐文件的一种机制。
- en: At this point, we should have a source video that is the target for swapping
    faces and a corresponding alignments file that holds information about the location
    of faces within that file. It is entirely feasible to run a conversion at this
    stage, but another step is required for the best results – fixing the alignments
    file.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们应该有一个目标面部交换的源视频和一个包含该文件中面部位置信息的对应对齐文件。在这个阶段进行转换是完全可行的，但为了获得最佳结果，还需要进行另一个步骤——修复对齐文件。
- en: Fixing the alignments file
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修复对齐文件
- en: 'Whilst we have removed unwanted faces, false positives, and any clearly misaligned
    faces from our alignments file, some further work is required to clean up the
    file for the final conversion. The main reasons for this are to fix frames where
    the following scenarios occur:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经从对齐文件中移除了不需要的面部、误报和任何明显错位的面部，但仍需进一步清理文件以进行最终转换。主要原因是为了修复以下场景中的帧：
- en: Multiple faces have been identified. Sometimes, the detector will find two faces
    in a frame, but the aligner performs alignment on the same face twice. This often
    happens when two faces appear close to each other within a frame.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别出多个面部。有时，检测器会在一个帧中找到两个面部，但对齐器会对同一个面部进行两次对齐。这种情况通常发生在两个面部在帧中彼此靠近时。
- en: The face is not aligned correctly. Sometimes, the face may appear aligned correctly
    when scanning through the folder of images, but examining the landmarks will demonstrate
    that this is not the case. These faces will sometimes convert correctly, but often
    this misalignment will lead to a messy swap for those frames (the swap will not
    look quite correct, it may look blurry, or may flicker between frames).
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部对齐不正确。有时，当扫描图像文件夹时，面部可能看起来对齐正确，但检查地标将证明并非如此。这些面部有时可以正确转换，但通常这种错位会导致这些帧的交换变得混乱（交换看起来不太正确，可能看起来模糊，或者可能在帧之间闪烁）。
- en: A face hasn’t been identified. Ensuring that all faces being swapped have been
    identified is necessary; otherwise, the original face, rather than the swapped
    face, will appear in those frames.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未识别到面部。确保所有需要交换的面部都已识别，否则，原始面部而不是交换的面部将出现在那些帧中。
- en: The mask has not been detected correctly. Depending on the conditions of the
    source frame, some neural network-based masks may not have been detected correctly,
    so these need to be fixed up. Depending on how the mask has been rendered, an
    incorrect mask may mean that parts of the original face show through, or parts
    of the background frame do not render correctly.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有正确检测到面具。根据源帧的条件，一些基于神经网络的 masks 可能没有正确检测到，因此需要修复。根据面具的渲染方式，一个不正确的面具可能意味着原始面部的一部分会显示出来，或者背景帧的部分渲染不正确。
- en: Again, Faceswap provides tools to make this process easier – specifically, the
    **Manual tool**, which enables the visualization and editing of alignments/masks
    within the context of the original frame.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，Faceswap 提供了工具来简化此过程——特别是**手动工具**，它允许在原始帧的上下文中可视化和编辑对齐/masks。
- en: 'To launch the Manual tool, navigate to the **Tools** tab and then the **Manual**
    sub-tab:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动手动工具，请导航到**工具**标签页，然后是**手动**子标签页：
- en: '![Figure 4.26 – The location of the Manual tool within Faceswap’s GUI](img/B17535_04_026.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图4.26 – Faceswap的GUI中手动工具的位置](img/B17535_04_026.jpg)'
- en: Figure 4.26 – The location of the Manual tool within Faceswap’s GUI
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.26 – Faceswap的GUI中手动工具的位置
- en: Assuming that the alignments file for the video to be converted is in the default
    location, then only one argument needs to be provided to launch the Manual tool
    the location of the source video/folder of images that is to be converted. Specify
    this location within the **Frames** box and hit the **Manual** button to launch
    the tool.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 假设要转换的视频的对齐文件位于默认位置，那么启动手动工具时只需要提供一个参数，即要转换的源视频/图像文件夹的位置。在**帧**框中指定此位置，然后点击**手动**按钮以启动工具。
- en: '![Figure 4.27 – The Data options for launching Faceswap’s Manual Tool](img/B17535_04_027.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图4.27 – 启动Faceswap手动工具的数据选项](img/B17535_04_027.jpg)'
- en: Figure 4.27 – The Data options for launching Faceswap’s Manual Tool
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.27 – 启动Faceswap手动工具的数据选项
- en: Once the tool loads, you will be greeted with a main “video” window that shows
    the source that is being worked on and a secondary window that displays all of
    the faces that exist within the alignments file.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 工具加载后，您将看到一个主要的“视频”窗口，显示正在处理的数据源，以及一个次要窗口，显示对齐文件中存在的所有面孔。
- en: '![Figure 4.28 – The Faceswap manual tool showing the video window at the top
    and the faces viewer at the bottom](img/B17535_04_028.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图4.28 – Faceswap手动工具显示顶部的视频窗口和底部的人脸查看器](img/B17535_04_028.jpg)'
- en: Figure 4.28 – The Faceswap manual tool showing the video window at the top and
    the faces viewer at the bottom
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.28 – Faceswap手动工具显示顶部的视频窗口和底部的人脸查看器
- en: 'The top left buttons allow you to perform different actions on the alignments,
    so hover over the tooltips to see what is available:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 左上角的按钮允许您对对齐执行不同的操作，因此将鼠标悬停在工具提示上以查看可用选项：
- en: '![Figure 4.29 – The Editor selection buttons within Faceswap’s Manual tool](img/B17535_04_029.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图4.29 – Faceswap手动工具中的编辑选择按钮](img/B17535_04_029.jpg)'
- en: Figure 4.29 – The Editor selection buttons within Faceswap’s Manual tool
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.29 – Faceswap手动工具中的编辑选择按钮
- en: 'Another area of interest is the **Filter**. The Filter is a pull-down list
    that is located between the frames and faces windows and enables you to filter
    the frames and faces shown in the tool by certain criteria:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得关注的地方是**过滤器**。过滤器是一个下拉列表，位于帧和面孔窗口之间，允许您根据某些标准过滤工具中显示的帧和面孔：
- en: '![Figure 4.30 – The face Filter options within Faceswap’s Manual tool](img/B17535_04_030.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图4.30 – Faceswap手动工具中的人脸过滤器选项](img/B17535_04_030.jpg)'
- en: Figure 4.30 – The face Filter options within Faceswap’s Manual tool
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.30 – Faceswap手动工具中的人脸过滤器选项
- en: 'Finally, the faces window also has some buttons on the left-hand side, which
    enable you to toggle the display of the face landmark mesh and the selected mask
    for faces displayed in the faces area:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，人脸窗口的左侧也有一些按钮，这些按钮允许您切换人脸区域中显示的人脸特征网格和选定的面具：
- en: '![Figure 4.31 – The face viewer buttons within Faceswap’s Manual tool](img/B17535_04_031.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图4.31 – Faceswap手动工具中的人脸查看器按钮](img/B17535_04_031.jpg)'
- en: Figure 4.31 – The face viewer buttons within Faceswap’s Manual tool
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.31 – Faceswap手动工具中的人脸查看器按钮
- en: Removing multiple faces
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除多个面孔
- en: To remove any extra faces from frames that contain multiple faces, select the
    **Multiple Faces** filter. The main video window will now only show any frames
    that contain multiple faces. If no frames show in the top window and no faces
    show in the bottom window, then there are no frames with multiple faces, and you
    can move on to the next action.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要从包含多个面孔的帧中移除任何额外的面孔，请选择**多个面孔**过滤器。此时，主视频窗口将只显示包含多个面孔的任何帧。如果顶部窗口中没有帧显示，底部窗口中也没有面孔显示，那么没有包含多个面孔的帧，您可以继续进行下一步操作。
- en: Knowing which face to remove is sometimes not obvious, so press the **Display
    landmarks mesh** button to the left of the faces window to bring up the landmarks
    overlay. If none of the faces are obviously misaligned (when the displayed landmarks
    mesh does not correspond to the underlying facial features), then any of the multiple
    faces can be deleted; otherwise, aim to delete the face with the landmarks that
    correspond least with the underlying face.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有时知道要移除哪个面孔并不明显，因此请按人脸窗口左侧的**显示特征网格**按钮以显示特征叠加。如果没有任何面孔明显错位（当显示的特征网格与面部特征不对应时），则可以删除多个面孔中的任何一个；否则，尝试删除与面部特征对应最少的面孔。
- en: There are several ways to delete faces from the frame. They can be deleted from
    the main video window by hovering over the unwanted face and pressing the **Del**
    key, or by right-clicking on the unwanted face in either the video or faces window
    and selecting **Delete Face**. When a frame no longer contains multiple faces
    (just one face remains in the frame), the faces for that frame will be removed
    from the faces window. Using this mechanism, it is usually quickest to right-click
    and select **Delete Face** from the faces window for all those faces that are
    unwanted until no faces remain.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以从框架中删除脸部。可以通过在主视频窗口中悬停在不想要的脸上并按 **Del** 键来删除，或者通过在视频或脸部窗口中右键单击不想要的脸上并选择
    **删除脸部**。当一个框架不再包含多个脸部（框架中只剩下一个脸部）时，该框架的脸部将从脸部窗口中移除。使用此机制，通常最快的方法是右键单击，并在脸部窗口中选择
    **删除脸部**，直到没有脸部为止。
- en: Once all frames with multiple faces have been cleaned, hit the **Save** icon
    to save the changes to the alignments file.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦清理了所有包含多个脸部的框架，点击 **保存** 图标以将更改保存到对齐文件中。
- en: Fixing misaligned faces
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修复错位脸部
- en: The Manual tool has misalignment detection built in. It is not perfect, but
    it does help in identifying and fixing the most obviously misaligned faces. While
    the detection can find faces that are obviously misaligned, it will not find faces
    where the face landmarks are in the correct location in relation to each other
    but do not correspond with the underlying face.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 手动工具内置了错位检测功能。它并不完美，但它有助于识别和修复最明显错位的脸部。虽然检测可以找到明显错位的脸部，但它不会找到脸部地标相对于彼此的位置正确，但与底层脸部不对应的情况。
- en: 'Select the **Misaligned Faces** filter to only display frames and faces where
    misaligned faces have been detected. A slider will appear next to the filter list
    box to control the distance:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 **错位脸部** 过滤器以仅显示检测到错位脸部的帧和脸部。过滤器列表框旁边将出现一个滑块来控制距离：
- en: '![Figure 4.32 – The Distance slider for selecting misaligned faces](img/B17535_04_032.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.32 – 选择错位脸部的距离滑块](img/B17535_04_032.jpg)'
- en: Figure 4.32 – The Distance slider for selecting misaligned faces
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.32 – 选择错位脸部的距离滑块
- en: This is how far the landmark points within each face have to be from an “average
    face” to be considered misaligned. Low values will be less restrictive, so are
    likely to contain faces that are properly aligned but are at more extreme angles/poses.
    Generally, distances between 6 and **10** work fairly well. A distance of **10**
    should only show misaligned faces. A distance of 6 is likely to show a mixture
    of misaligned faces and more extreme poses, but it will catch misaligned faces
    that higher values will miss. It can be easier to set a higher distance (**10**,
    for example) and fix the misaligned faces that appear. Then, set the distance
    to 8 and repeat the process, continuing to step down until the filter is not catching
    enough misaligned faces in relation to more extremely posed faces.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这是每个脸部内的特征点需要离“平均脸部”多远才能被认为是错位的。低值将限制较少，因此可能包含正确对齐但角度/姿势更极端的脸部。一般来说，6 到 **10**
    之间的距离效果相当好。**10** 的距离应该只显示错位脸部。**6** 的距离可能会显示错位脸部和更极端姿势的混合，但它会捕捉到高值会错过的错位脸部。可以更容易地设置一个更高的距离（例如
    **10**），并修复出现的错位脸部。然后，将距离设置为 8 并重复此过程，继续逐步降低，直到过滤器没有捕捉到足够多的错位脸部与更极端姿势的脸部相比。
- en: 'Regardless of the distance that has been set, to fix misaligned faces, the
    following actions should be taken:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 无论已设置的距离是多少，要修复错位脸部，应采取以下行动：
- en: Enable the landmark mesh for the faces viewer by toggling the landmarks button
    to the left of the faces viewer.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过切换脸部查看器左侧的地标按钮来启用脸部查看器的地标网格。
- en: Click on a face that has misaligned landmarks.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击一个具有错位地标的脸部。
- en: Within the main frame editor, make sure that the Bounding Box Editor is selected.
    This editor allows for control of the blue box around the face. This is the “detected
    face” box that was picked up by the face detector during the extraction phase.
    Adjusting this box will update the face that is fed to the aligner, with new landmarks
    being calculated. Continue to adjust the box until the landmarks align correctly.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主框架编辑器中，确保已选择边界框编辑器。此编辑器允许控制脸部周围的蓝色框。这是在提取阶段由脸部检测器捕获的“检测到的脸部”框。调整此框将更新提供给对齐器的脸部，并计算新的地标。继续调整框，直到地标正确对齐。
- en: If the landmarks are not aligning, it can help to switch between the different
    **Normalization Methods** options in the right-hand settings box. Different methods
    work better or worse in different situations, but **Hist** or **Clahe** tend to
    return the best results.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果地标没有对齐，可以在右侧设置框中切换不同的**归一化方法**选项。不同的方法在不同情况下效果更好或更差，但**直方图**或**CLAHE**通常能返回最佳结果。
- en: 'Some faces can be stubborn (difficult angles, obstructions, or bad lighting).
    In these cases, it can be next to impossible for the aligner to detect the landmarks.
    A couple of other editors can be used in these situations:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些面部可能很固执（困难的角度、遮挡或不良照明）。在这些情况下，对齐器可能几乎无法检测到地标。在这种情况下，可以使用几个其他编辑器：
- en: '**Extract Box Editor**: This editor shows a green box that corresponds to the
    area of the frame that will be extracted if face extraction is run. It is possible
    to move, resize, and rotate this extract box, which will impact the location of
    the landmarks within the extract box. This can be leveraged to quickly align a
    face by copying the landmarks from the previous or next frame (assuming that the
    landmarks have not changed too much between frames – for example, a scene change)
    and quickly adjusting the extract box to fit the current frame.'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提取框编辑器**：此编辑器显示一个绿色框，对应于如果运行面部提取将提取的框架区域。可以移动、调整大小和旋转此提取框，这将影响提取框内地标的位置。可以利用这一点通过从上一帧或下一帧复制地标（假设地标在帧之间没有太大变化——例如场景变化）并快速调整提取框以适应当前框架来快速对齐面部。'
- en: '**Landmark Point Editor**: This editor allows for the location of each individual
    point within the 68 landmarks to be manipulated. This level of granular control
    is rarely necessary, but it exists if it is needed.'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地标点编辑器**：此编辑器允许操作68个地标中每个单独点的位置。这种细粒度控制很少需要，但如果需要，它就存在。'
- en: Once the obviously misaligned landmarks have been fixed, hit the **Save** button
    to update the changes to the alignments file.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦明显错位的地标被修复，点击**保存**按钮以更新对齐文件中的更改。
- en: Adding missing faces
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加缺失面部
- en: Some frames may not have had faces identified where they should have been. The
    most common reason for this is that the detector did find a face, but the aligner
    failed to align it correctly, and then the face was deleted during the sorting
    process. Again, the Manual tool has a filter to help with this.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 一些帧可能没有在应该出现面部的地方识别到面部。这种情况最常见的原因是检测器确实找到了面部，但对齐器未能正确对齐它，然后在排序过程中删除了面部。同样，手动工具有一个过滤器可以帮助解决这个问题。
- en: Select the **No Faces** filter to filter the top window to only those frames
    where no faces appear. The bottom window will remain empty for this particular
    filter. Navigate through the video until a frame that contains a face that has
    not been detected is reached, and make sure that the Bounding Box Editor is selected.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**无面部**过滤器以过滤顶层窗口，只显示那些没有面部出现的帧。对于这个特定的过滤器，底层窗口将保持为空。导航视频，直到到达包含未检测到面部帧的位置，并确保已选择边界框编辑器。
- en: Landmarks can be created by clicking over a face within a frame, or copied from
    the previous or next frame and then amended. The bounding box can then be edited
    in the same way as in the previous step, with the same caveat about difficult
    faces.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过在框架内点击面部来创建地标，或者从上一帧或下一帧复制并修改。然后可以像上一步一样编辑边界框，同时要注意关于难以处理的面部的注意事项。
- en: When all frames that were missing faces have been fixed, hit the **Save** button
    to save the changes to the alignments file.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有缺失面部帧都已被修复后，点击**保存**按钮以将更改保存到对齐文件中。
- en: Final alignments fixups
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终对齐修复
- en: Once the obvious missing and misaligned faces have been fixed, it’s time to
    perform any final fixes to the alignments file. This is as simple as scrolling
    through all of the faces in the faces viewer and fixing any faces that remain
    misaligned. The faces viewer window can be expanded to show more faces within
    a single screen, and then the page-up/page-down buttons can be used to scroll
    through the faces a page at a time. When a misaligned face is discovered, it can
    be clicked on, and then the Bounding Box Editor can be used to re-align the face
    correctly.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦修复了明显的缺失和错位面部，就到了对对齐文件进行任何最终修复的时候了。这就像在面部查看器中滚动所有面部并修复任何仍然错位的面部一样简单。面部查看器窗口可以扩展以在单个屏幕上显示更多面部，然后可以使用页面向上/向下按钮逐页滚动面部。当发现错位面部时，可以点击它，然后可以使用边界框编辑器将其正确对齐。
- en: Finally, once all faces have been reviewed and fixed, press the **Save** button
    to save the final changes to the alignments file.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一旦所有面部都被检查并修复，请按**保存**按钮以将最终更改保存到对齐文件。
- en: Now that the alignments file has been fixed, you can close the Manual tool.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对齐文件已经修复，您可以关闭手动工具。
- en: Regenerating masks
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重新生成面具
- en: If an neural network-based mask is to be used for the swap, then these masks
    will need to be re-generated for any faces where the alignment data has been edited.
    The reason for this is that the aligned face, generated from the landmarks, is
    used to generate the face that is fed into the masking model. Once these landmarks
    have been edited, the mask is invalidated, so the process automatically deletes
    these invalid masks when the alignments are changed.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要使用基于神经网络的 masks 进行交换，那么在编辑了对齐数据后的任何面部都需要重新生成这些 masks。原因是，从地标生成的对齐面部用于生成输入到面具模型的面部。一旦这些地标被编辑，面具就无效了，因此当对齐更改时，这个过程会自动删除这些无效的面具。
- en: 'Again, Faceswap provides a tool to add masks to existing alignments files –
    the appropriately named **Mask tool**. This tool can be used to generate masks
    that did not previously exist in the alignments file, regenerate all masks, or
    just populate masks for those faces that are missing the specified mask:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，Faceswap提供了一个工具来为现有的对齐文件添加面具——名为**面具工具**的适当工具。此工具可用于生成对齐文件中之前不存在的面具，重新生成所有面具，或者只为缺少指定面具的脸生成面具：
- en: 'Navigate to the **Tools** tab and then the **Mask** sub-tab:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到**工具**标签，然后是**面具**子标签：
- en: '![Figure 4.33 – The location of the Mask tool within Faceswap’s GUI](img/B17535_04_033.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图4.33 – 面具工具在Faceswap的GUI中的位置](img/B17535_04_033.jpg)'
- en: Figure 4.33 – The location of the Mask tool within Faceswap’s GUI
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.33 – 面具工具在Faceswap的GUI中的位置
- en: 'Within the **Data** section, add the path to the video file to regenerate masks
    for the **Input** field, as well as the corresponding alignments file for the
    **Alignments** field. As the source to be worked on are the final frames to swap
    onto, make sure that **Frames** is selected under **Input Type**:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**数据**部分，将视频文件的路径添加到**输入**字段以重新生成面具，以及相应的对齐文件到**对齐**字段。由于要处理的源是最终要交换的帧，请确保在**输入类型**下选择**帧**：
- en: '![Figure 4.34 – The Data settings of Faceswap’s Mask tool](img/B17535_04_034.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图4.34 – Faceswap的面具工具的数据设置](img/B17535_04_034.jpg)'
- en: Figure 4.34 – The Data settings of Faceswap’s Mask tool
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.34 – Faceswap的面具工具的数据设置
- en: 'In the **Process** section, select the mask that is to be populated into the
    alignments file for **Masker**. Under **Processing**, select **Missing** if masks
    have already been generated and the goal is to repopulate those masks that are
    associated with faces that have had their alignments fixed; otherwise, select
    **All** to generate masks for every face within the alignments file:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**过程**部分，选择要填充到对齐文件中的面具到**面具器**。在**处理**下，如果已经生成了面具且目标是重新填充与已经修复对齐的面部关联的面具，请选择**缺失**；否则，选择**所有**以生成对齐文件中每个面部的面具：
- en: '![Figure 4.35 – The Process settings of Faceswap’s Mask tool](img/B17535_04_035.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![图4.35 – Faceswap的面具工具的过程设置](img/B17535_04_035.jpg)'
- en: Figure 4.35 – The Process settings of Faceswap’s Mask tool
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.35 – Faceswap的面具工具的过程设置
- en: The **Output** section is just for visualizing the masks, serving no practical
    purpose, so it can be ignored.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输出**部分仅用于可视化面具，没有实际用途，因此可以忽略。'
- en: Press the **Mask** button to generate the missing masks and save them to the
    alignments file.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按下**面具**按钮以生成缺失的面具并将它们保存到对齐文件。
- en: Fixing masks
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修复面具
- en: A final optional step is to fix up the generated masks. Much like face alignment,
    the neural networks that generate the masks are good, but they are often not perfect.
    This can be down to a number of reasons, such as lighting conditions and the quality
    of an image. In particular, obstructions in front of the face are not handled
    well by any of the maskers, so these will need to be manually edited.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个可选步骤是修复生成的面具。与面部对齐类似，生成面具的神经网络很好，但它们通常并不完美。这可能是由于多种原因，例如照明条件和图像质量。特别是，任何面具器都无法很好地处理面部前的障碍物，因此这些需要手动编辑。
- en: This should be the absolute last action performed on the alignments file. Any
    edits performed on landmark data within the alignment file will strip any neural
    network masks from the file and overwrite any edited landmark-based masks with
    the latest landmark data, destroying any manual edits that have been performed.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该是对对齐文件执行的绝对最后一步操作。对对齐文件中地标数据进行的任何编辑都将从文件中移除任何神经网络掩码，并用最新的地标数据覆盖任何编辑过的基于地标的数据掩码，从而破坏任何已执行的手动编辑。
- en: 'The Manual tool, used to fix up the alignments, can also be used to fix masks:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 用于修复对齐的手动工具也可以用于修复掩码：
- en: Launch the Manual tool by selecting the **Tools** tab, followed by the **Manual**
    sub-tab, and launch in the same way as before.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择 **工具** 选项卡，然后选择 **手动** 子选项卡来启动手动工具，并像之前一样启动。
- en: Select the **Mask Editor** button from the buttons next to the frame viewer,
    and then select the mask type to be edited from the right-hand side options panel.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从帧查看器旁边的按钮中选择 **掩码编辑器** 按钮，然后从右侧选项面板中选择要编辑的掩码类型。
- en: Press the **Mask Display** toggle button next to the faces viewer to display
    the selected mask within the faces window.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按下位于面部查看器旁边的 **掩码显示** 切换按钮以在面部窗口中显示所选掩码。
- en: Scroll through the faces window, looking for masks that require fixing. If a
    face is discovered that requires editing, it can be clicked on to bring the relevant
    frame into the frame viewer. The **Brush** and **Eraser** tools can then be used
    to paint in or out the desired mask areas.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在面部窗口中滚动，寻找需要修复的掩码。如果发现需要编辑的面部，可以点击它将相关帧带到帧查看器中。然后可以使用 **画笔** 和 **橡皮擦** 工具来绘制或擦除所需的掩码区域。
- en: Once all the masks have been fixed, press the **Save** button to save the mask
    edits to the alignments file.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有掩码都已修复，请按 **保存** 按钮将掩码编辑保存到对齐文件中。
- en: Using the Preview tool
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预览工具
- en: It is possible to process the swap now and view the final output. However, some
    settings will need to be adjusted on a case-by-case basis, specifically various
    post-processing actions, such as mask erosion/blending, color correction, and
    sharpening.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以处理交换并查看最终输出。但是，某些设置需要根据具体情况调整，特别是各种后处理操作，如掩码腐蚀/混合、色彩校正和锐化。
- en: 'Faceswap includes the **Preview tool** to help lock these settings in prior
    to running the final conversion, which can be accessed by selecting the **Tools**
    tab and then the **Preview** sub-tab:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Faceswap 包含 **预览工具**，用于在运行最终转换之前锁定这些设置，可以通过选择 **工具** 选项卡然后选择 **预览** 子选项卡来访问：
- en: '![Figure 4.36 – The location of the Preview tool within Faceswap’s GUI](img/B17535_04_036.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.36 – 预览工具在 Faceswap GUI 中的位置](img/B17535_04_036.jpg)'
- en: Figure 4.36 – The location of the Preview tool within Faceswap’s GUI
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.36 – 预览工具在 Faceswap GUI 中的位置
- en: 'To launch the tool, provide the location of the video you intend to swap onto
    in the **Input Dir** field, and the folder that contains the trained model in
    the **Model Dir** field. The **Alignments** field can be left blank, unless the
    alignments file has been moved or renamed, in which case it will need to be explicitly
    specified:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动此工具，请在 **输入目录** 字段中提供你打算交换的视频的位置，并在 **模型目录** 字段中提供包含训练模型的文件夹。**对齐** 字段可以留空，除非对齐文件已被移动或重命名，在这种情况下，需要明确指定：
- en: '![Figure 4.37 – The Data settings for Faceswap’s Preview tool](img/B17535_04_037.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.37 – Faceswap 预览工具的数据设置](img/B17535_04_037.jpg)'
- en: Figure 4.37 – The Data settings for Faceswap’s Preview tool
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.37 – Faceswap 预览工具的数据设置
- en: Press the **Preview** button to launch the tool.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 按 **预览** 按钮启动工具。
- en: The tool is split into three sections. The main window shows the faces from
    the original frame in the top row, with the swap applied with current settings
    in the bottom row. As settings are adjusted, the bottom row will update to reflect
    these changes.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 工具分为三个部分。主窗口显示顶部行中的原始帧中的面部，底部行显示应用当前设置后的交换。随着设置的调整，底部行将更新以反映这些更改。
- en: '![Figure 4.38 – Faceswap’s Preview tool](img/B17535_04_038.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.38 – Faceswap 的预览工具](img/B17535_04_038.jpg)'
- en: Figure 4.38 – Faceswap’s Preview tool
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.38 – Faceswap 的预览工具
- en: The bottom-left panel displays command-line choices, while the bottom-right
    panel displays plugin settings.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 左下角的面板显示命令行选项，而右下角的面板显示插件设置。
- en: Command-line choices
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命令行选项
- en: 'These are parameters that are chosen each time the conversion process is run
    (these options are not persistent), so you will need to remember what is set here
    to replicate it in the main Faceswap conversion process. Specifically, the options
    that can be set here are as follows:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在每次运行转换过程时选择的参数（这些选项不是持久的），因此您需要记住在此处设置的值，以便在主Faceswap转换过程中复制它。具体来说，可以在此设置的选项如下：
- en: '![Figure 4.39 – The Preview Tool’s Command Line Choices](img/B17535_04_039.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![图4.39 – 预览工具的命令行选择](img/B17535_04_039.jpg)'
- en: Figure 4.39 – The Preview Tool’s Command Line Choices
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.39 – 预览工具的命令行选择
- en: '**Color**: The color-matching methodology to use. The best choice here will
    depend on the scene being converted. The **Color Balance**, **Manual Balance**,
    and **Match Hist** options have further configuration options that can be adjusted
    from the **Plugin** **Settings** section.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色**：要使用的颜色匹配方法。最佳选择将取决于要转换的场景。**颜色平衡**、**手动平衡**和**匹配历史**选项有进一步的配置选项，可以从**插件****设置**部分进行调整。'
- en: '**Mask Type**: The type of mask to use for overlaying the swapped face onto
    the original frame. By default, the landmarks-based **extended** and **components**
    masks will be available. Any additional neural network-based masks that exist
    within the alignments file will also be accessible, as well as the option to entirely
    disable the mask (**None**). The settings that control the blending of the chosen
    mask into the background frame are adjusted from the **Plugin** **Settings** section.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮罩类型**：用于将交换的面叠加到原始帧上的遮罩类型。默认情况下，将提供基于地标的基础**扩展**和**组件**遮罩。任何存在于对齐文件中的额外基于神经网络遮罩也将可用，以及完全禁用遮罩的选项（**无**）。控制所选遮罩与背景帧混合的设置从**插件****设置**部分进行调整。'
- en: Plugin settings
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插件设置
- en: This section contains the configuration settings for the various post-processing
    plugins available in Faceswap. Values selected here, once saved, are persisted
    for all future conversions. As such, unlike the **Command Line Choices** options,
    there is no need to make a note of what is being set within this section.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 此部分包含Faceswap中可用的各种后处理插件的配置设置。在此处选择的值一旦保存，将持久保存在所有未来的转换中。因此，与**命令行选择**选项不同，无需在此部分记录设置的值。
- en: 'The plugin settings are split into three configuration groups:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 插件设置分为三个配置组：
- en: '**Color**: Configuration options for color-matching plugins. The actual methodology
    to use is selected within the **Command Line Choices** section, but some of the
    choices have additional configuration parameters that are controllable here. Make
    sure that the correct methodology is set within the **Command Line Choices** section
    to observe any changes within the main window.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色**：颜色匹配插件的配置选项。实际要使用的方法在**命令行选择**部分进行选择，但其中一些选择有额外的配置参数可以在此处控制。请确保在**命令行选择**部分设置了正确的方法，以便在主窗口中观察任何变化。'
- en: '**Mask**: Options to control the blending of the swapped image into the background
    frame. These settings are broken down into two further categories – **Box Blend**,
    which controls the settings that blend the extracted square containing the face
    into the background frame, and **Mask Blend**, which controls the settings for
    blending the mask around the face into the background frame. (Note that if **None**
    has been selected as the mask type in the **Command Line Choices** section, then
    any changes made within the **Mask Blend** settings will not be visible within
    the preview window.)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮罩**：控制交换图像与背景帧混合的选项。这些设置分为两个更进一步的类别——**框混合**，它控制将包含面部提取的正方形与背景帧混合的设置，以及**遮罩混合**，它控制将面部周围的遮罩与背景帧混合的设置。（注意：如果在**命令行选择**部分已选择**无**作为遮罩类型，则在**遮罩混合**设置中进行的任何更改在预览窗口中都不会可见。）'
- en: How much of an impact each of these settings will have on the final output will
    depend greatly on the coverage and centering options that were selected when training
    the model. For example, with a low coverage and legacy centering (that is, very
    closely cropped), it is entirely possible that an extracted face box is contained
    entirely within the mask, in which case **Mask Blend** settings would have no
    visible effect. Similarly, with high coverage, and face or head centering, it
    is possible that the full mask exists within the extract box, in which case the
    **Box Blend** settings would have no visible effect. In most cases, adjusting
    a combination of the two blending settings will be necessary.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设置中的每一个对最终输出的影响将很大程度上取决于在训练模型时选择的覆盖和居中选项。例如，对于低覆盖和传统居中（即非常紧密裁剪），提取的面部框完全位于遮罩内是完全可能的，在这种情况下，**遮罩混合**设置将没有可见效果。同样，对于高覆盖和面部或头部居中，整个遮罩可能存在于提取框内，在这种情况下，**框混合**设置将没有可见效果。在大多数情况下，调整这两种混合设置的组合将是必要的。
- en: '**Scaling**: The final configurable plugin controls any artificial sharpening
    to apply to an image. Quite often, the swapped face will need to be upscaled to
    fit into the final frame. This section allows you to control any sharpening effects
    to help better upscale the image.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缩放**：最终的配置插件控制应用于图像的任何人工锐化。通常，交换的面部需要放大以适应最终帧。本节允许您控制任何锐化效果，以帮助更好地放大图像。'
- en: Tip
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: To get a better impression of the effects of adjusting the mask plugin settings,
    select **Manual Balance** as the color command-line choice, and then adjust **Contrast**
    and **Brightness** to **–100** within the **Manual Balance** plugin setting. This
    will display the swap area as entirely black, which can make it easier to adjust
    the mask correctly.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地了解调整遮罩插件设置的效果，请将颜色命令行选择设置为**手动平衡**，然后在**手动平衡**插件设置中将**对比度**和**亮度**调整到**-100**。这将使交换区域显示为全黑色，这可以使正确调整遮罩更容易。
- en: Tuning the conversion settings
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调整转换设置
- en: The actual configuration choices to be used will vary on a video-by-video basis;
    there are no hard and fast rules, so it is just a question of adjusting the settings
    until a satisfactory result is achieved. Once a plugin is configured correctly,
    that plugin’s configuration can be saved by clicking the bottom-right **Save**
    button. To save the settings for all plugins that have been adjusted, click the
    bottom-left **Save** button.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 实际使用的配置选项将根据每个视频而有所不同；没有固定的规则，所以只是调整设置直到达到满意的结果。一旦插件配置正确，可以通过点击右下角的**保存**按钮保存该插件的配置。要保存所有已调整插件的设置，请点击左下角的**保存**按钮。
- en: When appropriate settings have been locked in, make a note of the **Command
    Line Choices** settings and exit the Preview tool.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 当适当的设置已锁定时，记录**命令行选择**设置并退出预览工具。
- en: Generating the swap
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成交换
- en: Once the model has been trained, the alignments file has been created, and the
    swap settings have been locked in, the final product can be created. The process
    of generating a swap is called **converting** – that is, converting the faces
    in a source video from their original form to the version generated from the trained
    model.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型经过训练，对齐文件已创建，交换设置已锁定，就可以创建最终产品。生成交换的过程称为**转换**——即，将源视频中的面部从原始形式转换为从训练模型生成的版本。
- en: 'Converting is probably the least involved of the main Faceswap processes. Access
    the **Convert** section of the Faceswap application by selecting the **Convert**
    tab:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 转换可能是Faceswap主要过程中最不复杂的一个。通过选择**转换**选项卡来访问Faceswap应用程序的**转换**部分：
- en: '![Figure 4.40 – The location of the Convert settings within Faceswap’s GUI](img/B17535_04_040.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![图4.40 – Faceswap GUI中转换设置的位置](img/B17535_04_040.jpg)'
- en: Figure 4.40 – The location of the Convert settings within Faceswap’s GUI
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.40 – Faceswap GUI中转换设置的位置
- en: Data
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'This section is used to tell the process where the assets are located to perform
    the swap, as well as where the final output should be exported to:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 本节用于说明执行交换操作时资产所在的位置，以及最终输出应导出的位置：
- en: '**Input Dir**: The location of the source video or folder of images to be processed.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入目录**：源视频或待处理图像文件夹的位置。'
- en: '**Output Dir**: The location that the converted media should be outputted to.
    This folder should not pre-exist.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出目录**：转换后的媒体应输出的位置。此文件夹不应预先存在。'
- en: '**Alignments**: Optionally, specify the location of the alignments file. If
    the alignments file is in its default location (next to the source video) with
    the default name, then this can be left blank, as the file will be detected.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对齐**：可选地指定对齐文件的位置。如果对齐文件位于其默认位置（在源视频旁边）并使用默认名称，则可以将其留空，因为文件将被检测到。'
- en: '**Reference Video**: This option is only required if the source is a folder
    of individual frames and the desired output is a video file. The reference video
    would be the original video file that the folder of frames was extracted from,
    and it provides the conversion process with the audio track and the FPS that should
    be compiled into the final video.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参考视频**：如果源是一个包含单独帧的文件夹，并且所需的输出是视频文件，则此选项是必需的。参考视频将是提取帧的文件夹所提取的原始视频文件，它为转换过程提供了音频轨道和应编译到最终视频中的帧率（FPS）。'
- en: '**Model Dir**: The location of the folder that contains the trained Faceswap
    model.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型目录**：包含训练好的 Faceswap 模型的文件夹位置。'
- en: '![Figure 4.41 – The Data options within Faceswap’s Convert settings](img/B17535_04_041.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.41 – Faceswap 的转换设置中的数据选项](img/B17535_04_041.jpg)'
- en: Figure 4.41 – The Data options within Faceswap’s Convert settings
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.41 – Faceswap 的转换设置中的数据选项
- en: Plugins
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插件
- en: 'There are several plugins available for the conversion process, which are selectable
    here. Two of the plugins will have been seen before when we used the Preview tool
    (**Color Adjustment** and **Mask Type**), so ensure that you select the same options
    here as those selected within the Preview tool for the output to remain consistent:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 转换过程中有多个可用的插件可供选择，这里可以进行选择。其中两个插件在我们使用预览工具时已经见过（**颜色调整**和**遮罩类型**），因此请确保在此处选择与预览工具中选择的相同选项，以确保输出保持一致：
- en: '**Color Adjustment**: The color correction to use. This will have been previewed
    and selected using the Preview tool, so select the same plugin here. The actual
    plugin to use will vary from project to project.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色调整**：要使用的颜色校正。这已经使用预览工具预览并选择，因此请在此处选择相同的插件。实际要使用的插件将因项目而异。'
- en: '**Mask Type**: The type of mask to use to overlay the swapped face over the
    original frame. The chosen mask here must exist within the alignments file (**Components**
    and **Extended** will always exist; other masks need to be generated). Generally,
    this will be the same mask that the model was trained with and will have been
    previewed with the Preview tool, so select the same mask that was used to preview.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮罩类型**：用于在原始帧上叠加交换人脸的遮罩类型。此处选择的遮罩必须在对齐文件中存在（**组件**和**扩展**始终存在；其他遮罩需要生成）。通常，这将与模型训练时使用的相同遮罩，并且已经使用预览工具进行了预览，因此请选择用于预览的相同遮罩。'
- en: '**Writer**: The plugin to use to create the final media. The writer plugins
    are used to generate the final product. **Ffmpeg** is used to create video files,
    **Gif** is used to create animated GIFs, and **OpenCV** and **Pillow** will create
    a folder of images, with OpenCV being quicker but having a more limited file format
    choice than Pillow.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**写入器**：用于创建最终媒体的插件。写入器插件用于生成最终产品。**Ffmpeg**用于创建视频文件，**Gif**用于创建动画 GIF，而**OpenCV**和**Pillow**将创建一个包含图像的文件夹，其中
    OpenCV 比较快，但比 Pillow 具有更有限的文件格式选择。'
- en: 'The writers can each be configured by selecting **Settings** | **Configure
    Settings** and selecting the relevant writer plugin under the **Convert** node:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过选择**设置** | **配置设置**并选择**转换**节点下的相关写入器插件来配置每个写入器：
- en: '![Figure 4.42 – Faceswap’s Convert plugin settings](img/B17535_04_042.jpg)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.42 – Faceswap 的转换插件设置](img/B17535_04_042.jpg)'
- en: Figure 4.42 – Faceswap’s Convert plugin settings
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.42 – Faceswap 的转换插件设置
- en: It is possible to create the swap on a separate transparent layer only containing
    the swapped face and the mask, to overlay over the original frame in various external
    VFX applications. The **OpenCV** and **Pillow** writers both support this, with
    OpenCV allowing the generation of four-channel PNG images and Pillow allowing
    the generation of four-channel PNG or TIFF images. This option can be enabled
    by selecting the **Draw Transparent** option within either of these plugins’ configuration
    settings.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在单独的透明层上创建交换，该层仅包含交换的人脸和遮罩，以覆盖原始帧，并在各种外部 VFX 应用程序中叠加。**OpenCV**和**Pillow**写入器都支持此功能，其中
    OpenCV 允许生成四通道 PNG 图像，而 Pillow 允许生成四通道 PNG 或 TIFF 图像。此选项可以通过在任一插件配置设置中选择**绘制透明**选项来启用。
- en: '![Figure 4.43 – The Plugins options within Faceswap’s Convert settings](img/B17535_04_043.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.43 – Faceswap 转换设置中的插件选项](img/B17535_04_043.jpg)'
- en: Figure 4.43 – The Plugins options within Faceswap’s Convert settings
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.43 – Faceswap 转换设置中的插件选项
- en: Other settings
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他设置
- en: '**Frame Processing** can be ignored in most cases. The most likely option of
    interest is **Output Scale** though, which scales the final output media by the
    designated amount. For example, setting an output scale of **50** for a 720p input
    video will result in a final output at 360p.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下可以忽略**帧处理**。然而，最可能引起兴趣的选项是**输出缩放**，它通过指定的量缩放最终输出媒体。例如，将输入视频的输出缩放设置为**50**，最终输出将是
    360p。
- en: The **Face Processing** section can be ignored. If the alignments file has been
    created correctly, then none of the options here are relevant. Similarly, most
    of the options within the **Settings** section can be ignored in most cases. The
    only possible exception to this is the **Swap Model** option. This can be used
    to create a swap in the opposite direction to which the model was trained – that
    is, instead of **A** > **B**, the conversion will run **B** > **A**. This can
    be useful if you have a model trained on a face pair and you wish to run conversion
    in the opposite direction, or if a model has accidentally been trained the wrong
    way around (the original face has been trained on the **B** side, with the desired
    swap trained on the **A** side).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 可以忽略**人脸处理**部分。如果对齐文件已正确创建，则这里没有相关的选项。同样，在**设置**部分的大多数选项在大多数情况下也可以忽略。唯一的可能例外是**交换模型**选项。这可以用来创建与模型训练方向相反的交换
    – 也就是说，而不是**A** > **B**，转换将运行**B** > **A**。如果你有一个在人脸对上训练的模型，并且希望以相反的方向运行转换，或者如果模型意外地以错误的方式训练（原始人脸在**B**侧训练，所需交换在**A**侧训练），这可能会很有用。
- en: Once all of the settings are set correctly, press the **Convert** button to
    apply the trained model on your source media and generate the swap in the output
    destination.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有设置都正确设置，请按**转换**按钮，将训练的模型应用于你的源媒体，并在输出目标中生成交换。
- en: Summary
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned the workflow required to create a deepfake using
    the open source Faceswap software. The importance of data variety was discussed
    and the steps required to acquire, curate and generate face sets were demonstrated.
    We learned how to train a model within Faceswap, and how to gauge when a model
    has been fully trained, as well as learned some tricks to improve the quality
    of the model. Finally, we learned how to take our trained model and apply it to
    a source video to swap the faces within the video.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了使用开源 Faceswap 软件创建 deepfake 所需的工作流程。讨论了数据多样性的重要性，并演示了获取、整理和生成人脸集所需的步骤。我们学习了如何在
    Faceswap 中训练模型，以及如何判断模型是否已经完全训练，还学习了一些提高模型质量的技巧。最后，我们学习了如何将我们的训练模型应用于源视频，以在视频中交换人脸。
- en: In the next chapter, we will begin to take a hands-on look at the neural networks
    available to build a deepfake pipeline from scratch using the PyTorch ML toolkit,
    starting with the models available for detecting and extracting faces from source
    images.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始亲身体验使用 PyTorch 机器学习工具包从头开始构建 deepfake 管道的神经网络，从可用于从源图像中检测和提取人脸的模型开始。
- en: EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: EBSCOhost - 2023 年 11 月 27 日 6:20 AM 打印。所有使用均受 [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
    条款约束。
- en: 'Part 2: Getting Hands-On with the Deepfake Process'
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：亲身体验 Deepfake 流程
- en: This part of the book is all about getting hands-on with the code. We will look
    deep into exactly what it takes to make a deepfake from beginning to end, leaving
    no stone unturned or line of code unexplained. If you’re here for the code, this
    is the section for you.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 本书这部分内容全部关于亲身体验代码。我们将深入探讨从头到尾制作 deepfake 所需的每一步，不留任何遗漏或未解释的代码行。如果你是为了代码而来，这部分内容就是为你准备的。
- en: In the first chapter of this section, we’ll examine extraction. This is the
    process of getting all the faces out of a video so that we can use them in other
    stages of the process. We’ll look at the process of turning a video into frame
    images, then we’ll go through all the code necessary to turn the frames into clean,
    aligned faces with matching mask images ready for training. After that, we’ll
    look into training, examine the neural network from the bottom up, and then show
    the entire learning process of the model. Finally, we’ll get into conversion,
    where we’ll examine the process of going through every image to swap a new face
    onto the original, including turning it back into a video.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的第一章中，我们将探讨提取过程。这是从视频中提取所有人脸以便在过程的其它阶段使用的过程。我们将查看将视频转换为帧图像的过程，然后我们将通过所有必要的代码将帧转换为干净、对齐的人脸，并准备匹配的遮罩图像以供训练。之后，我们将探讨训练过程，从下至上检查神经网络，然后展示模型的整个学习过程。最后，我们将进入转换阶段，检查将新人脸交换到原始图像上的过程，包括将其转换回视频。
- en: By the end of this part, you’ll know exactly how to code your own deepfakes
    from beginning to end.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 到本部分结束时，你将确切知道如何从头到尾编码你自己的深度伪造。
- en: 'This part comprises the following chapters:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 5*](B17535_05.xhtml#_idTextAnchor090), *Extracting Faces*'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B17535_05.xhtml#_idTextAnchor090)，*提取人脸*'
- en: '[*Chapter 6*](B17535_06.xhtml#_idTextAnchor107), *Training a Deepfake Model*'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B17535_06.xhtml#_idTextAnchor107)，*训练深度伪造模型*'
- en: '[*Chapter 7*](B17535_07.xhtml#_idTextAnchor123), *Swapping the Face back into
    the Video*'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B17535_07.xhtml#_idTextAnchor123)，*将人脸重新放回视频中*'
- en: EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: EBSCOhost - 2023年11月27日 6:20 AM 打印。所有使用均受[https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)条款约束
