- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: OpenAI API Endpoints Explained
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI API 端点解析
- en: The OpenAI API is not just one endpoint, but instead a collection of different
    endpoints that can be used to generate text completions, images, and even transcribe
    audio. In this chapter, we dive into all these use cases covering the main endpoints
    that are used by developers when integrating the OpenAI API into their applications.
    By the end of this chapter, you will know how to use the diverse capabilities
    of the OpenAI API, the first step in building intelligent applications. You’ll
    understand the nuances of each endpoint, ensuring that you can tailor your integration
    to your specific needs. Whether you’re aiming to create dynamic text content,
    generate captivating visuals, or transcribe audio, you will learn how to accomplish
    these tasks all using the API.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 不仅仅是一个端点，而是一个由多个不同端点组成的集合，这些端点可以用来生成文本补全、图片，甚至转录音频。在本章中，我们将深入探讨所有这些用例，涵盖开发人员在将
    OpenAI API 集成到应用程序时使用的主要端点。通过本章的学习，你将了解如何利用 OpenAI API 的多种功能，这是构建智能应用程序的第一步。你将理解每个端点的细微差别，确保能够根据你的具体需求定制集成方案。无论你是希望创建动态文本内容、生成引人注目的视觉效果，还是转录音频，你都将学会如何使用
    API 完成这些任务。
- en: 'Specifically, we will cover the following recipes in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将具体介绍以下配方：
- en: Generating customized responses using the Chat Completions endpoint
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用聊天补全端点生成自定义响应
- en: Creating pictures using the Images endpoint
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图像端点创建图片
- en: Generating transcripts using the Audio endpoint
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用音频端点生成转录
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have access to the OpenAI API (via a generated
    API key) and have an API client installed, such as Postman. You can refer to the
    *Making OpenAI API requests with Postman* recipe in [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021)for
    more information on how to obtain your API key and set up Postman.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求你拥有访问 OpenAI API 的权限（通过生成的 API 密钥）并安装 API 客户端，如 Postman。你可以参考 [*第 1 章*](B21007_01.xhtml#_idTextAnchor021)
    中的 *使用 Postman 发出 OpenAI API 请求* 配方，了解如何获取 API 密钥并设置 Postman。
- en: Generating customized responses using the Chat Completions endpoint
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用聊天补全端点生成自定义响应
- en: We previously explored the Chat Completions endpoint at the end of [*Chapter
    1*](B21007_01.xhtml#_idTextAnchor021), but our request body was fairly simple
    and did not make use of the important parameters that we also discussed in the
    *Running a completion request in the OpenAI Playground* recipe. For example, we
    learned how the Chat Log could be used to *fine-tune* the responses that are generated.
    Additionally, the Chat Log feature can be used to deploy a chat bot inside your
    application.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在 [*第 1 章*](B21007_01.xhtml#_idTextAnchor021) 末尾探讨了聊天补全端点，但我们的请求体相对简单，并未使用我们在
    *在 OpenAI Playground 中运行补全请求* 配方中讨论的关键参数。例如，我们了解了如何使用聊天记录来 *微调* 生成的响应。此外，聊天记录功能还可以用于在应用程序中部署聊天机器人。
- en: In this recipe, we will cover how to generate responses using the Chat Completions
    endpoint while using the Chat Log parameters.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将介绍如何使用聊天补全端点和聊天记录参数生成响应。
- en: Getting ready
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have an OpenAI Platform account with available usage credits. If
    you don’t, please follow the *Setting up your OpenAI Playground environment* recipe
    in [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你拥有一个 OpenAI Platform 账户并且有可用的使用积分。如果没有，请参考 [*第 1 章*](B21007_01.xhtml#_idTextAnchor021)
    中的 *设置 OpenAI Playground 环境* 配方。
- en: Furthermore, ensure you have Postman installed, you have created a new workspace,
    you have created a new HTTP request, and that the `Headers` for that request are
    correctly configured. This is important because without the `Authorization` configured,
    you will not be able to use the API. If you don’t have Postman installed and configured
    as mentioned, please follow the *Making OpenAI API requests with Postman* recipe
    in [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，确保你已安装 Postman，创建了一个新的工作区，创建了一个新的 HTTP 请求，并且该请求的 `Headers` 配置正确。这一点非常重要，因为没有正确配置
    `Authorization`，你将无法使用 API。如果你没有按上述说明安装和配置 Postman，请参考 [*第 1 章*](B21007_01.xhtml#_idTextAnchor021)
    中的 *使用 Postman 发出 OpenAI API 请求* 配方。
- en: All the recipes in this chapter will have this same requirement.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有配方都将具有相同的要求。
- en: How to do it…
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: In Postman, create a new request by selecting the **New** button on the top-left
    menu bar, and then select **HTTP**.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Postman 中，通过点击左上角菜单栏中的 **New** 按钮，选择 **HTTP** 来创建一个新的请求。
- en: Change the HTTP request type from **GET** to **POST** in the **Method** drop-down
    menu (by default, it will be set to **GET**).
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 HTTP 请求类型从**GET**更改为**POST**，方法下拉菜单（默认情况下，它将设置为**GET**）。
- en: 'Enter the following URL as the endpoint for Chat Completions: [https://api.openai.com/v1/chat/completions](https://api.openai.com/v1/chat/completions).'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下 URL 作为聊天完成的端点：[https://api.openai.com/v1/chat/completions](https://api.openai.com/v1/chat/completions)。
- en: 'Select **Headers** from the sub-menu and add the following key-value pairs
    into the table below it:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从子菜单中选择**Headers**，并将以下键值对添加到下面的表格中：
- en: '| *Key* | *Value* |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| *键* | *值* |'
- en: '| --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Content-Type` | `application/json` |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| `Content-Type` | `application/json` |'
- en: '| `Authorization` | `Bearer <your API` `key here>` |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `Authorization` | `Bearer <your API` `key here>` |'
- en: 'Select **Body** from the sub-menu and then select **raw** for the request type.
    Enter the following in **Body**. After that, select **Send**:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从子菜单中选择**Body**，然后选择请求类型中的**raw**。在**Body**中输入以下内容。之后，选择**发送**：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '5. After sending the HTTP request, you should see the following response from
    the OpenAI API. Note that your response may be different. The section of the HTTP
    response that we particularly want to take note of is the `content` value:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 发送 HTTP 请求后，你应该看到来自 OpenAI API 的以下响应。请注意，你的响应可能会有所不同。我们特别需要注意 HTTP 响应中的`content`值：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '6. Let’s now add messages into the Chat Log (or `messages`, as it’s referred
    to in the API) to modify and tune the responses that are generated. Modify `messages`:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 6. 现在，让我们将消息添加到聊天记录中（或称为 API 中的`messages`），以修改和调整生成的响应。修改`messages`：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '7. Click **Send** to execute the HTTP request. You should see a response similar
    to the following from the OpenAI API:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 7. 点击**发送**以执行 HTTP 请求。你应该会看到来自 OpenAI API 的类似响应：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works…
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The OpenAI API works very similar to the **Playground**, where developers can
    add messages to the *Chat Log*. This, in turn, fine-tunes the responses that the
    API generates – it learns from the assistant responses that we have created.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 的工作方式与**Playground**非常相似，开发者可以将消息添加到*聊天记录*中。这样可以微调 API 生成的响应——它从我们创建的助手响应中学习。
- en: We did this by first executing a simple chat completion request, and only specified
    a `System message` and a `User message` (i.e., the prompt), as shown in *Figure
    2**.1*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过首先执行一个简单的聊天完成请求，并且只指定了`系统消息`和`用户消息`（即提示），如*图 2.1*所示。
- en: '![Figure 2.1 – Excerpt of messages object within the request body](img/B21007_02_1.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 请求体中消息对象的摘录](img/B21007_02_1.jpg)'
- en: Figure 2.1 – Excerpt of messages object within the request body
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 请求体中消息对象的摘录
- en: This was done by adding message objects within the messages object in **Body**.
    Each message object must contain a *role* and some *content*, as we learned in
    [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过在**Body**中添加消息对象到消息对象中完成的。每个消息对象必须包含一个*角色*和一些*内容*，正如我们在[**第 1 章**](B21007_01.xhtml#_idTextAnchor021)中学到的那样。
- en: We can then add additional `Assistant` and `User` messages to teach the model
    how it should formulate its responses. Importantly, the model will attempt to
    match any pattern it sees within the messages tagged as `Assistant`. It is almost
    as if we are *teaching* the model how it should generate its responses. In this
    case, all of the `Assistant` responses contained the words **Hello Ice Cream Fan**
    and **SCREAM FOR** **ICE CREAM!**
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以添加额外的`助手`和`用户`消息，教模型如何制定其响应。重要的是，模型将尝试匹配它在标记为`助手`的消息中看到的任何模式。就好像我们在*教*模型如何生成响应一样。在这种情况下，所有的`助手`响应都包含了**Hello
    Ice Cream Fan**和**为冰淇淋欢呼！**
- en: 'As a result of us adding messages to the *Chat Log*, when we provided the API
    with an additional prompt, it returned a response that matched the pattern described
    in the preceding paragraph:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将消息添加到*聊天记录*中，当我们向 API 提供额外的提示时，它返回的响应与前面段落中描述的模式相匹配：
- en: '**Hello Ice Cream Fan, thank you for the kind words. We love our location and
    our staff too. SCREAM FOR** **ICE CREAM!**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hello Ice Cream Fan，感谢你的好评。我们也喜欢我们的地点和员工。为** **冰淇淋欢呼！**'
- en: In this recipe, we learned how to use the Chat Completions endpoint in the OpenAI
    API to generate text, and how to use the System Message, User prompts, and Chat
    Log to modify the generated text. This is important because the Chat Completions
    endpoint is the most common OpenAI API endpoint to use when integrating with other
    systems to create intelligent applications. Furthermore, as we begin to load the
    API for practical purposes, it’s important to know how to adjust the generated
    text to fit our desired use case using levers such as the Chat Log.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们学习了如何使用 OpenAI API 中的 Chat Completions 端点生成文本，以及如何使用系统消息、用户提示和聊天日志来修改生成的文本。这一点很重要，因为
    Chat Completions 端点是与其他系统集成以创建智能应用程序时最常用的 OpenAI API 端点。此外，当我们开始实际加载 API 时，了解如何通过使用聊天日志等方法调整生成的文本以适应我们的预期用途也非常重要。
- en: There’s more…
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'Adding messages to the *Chat Log* has many more purposes than just fine-tuning
    the assistant responses. Another important use case is creating a chat bot, where
    the conversation (the preceding `User` and `Assistant` messages) must be taken
    into context before a response can be generated. For instance, consider the following
    example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 向*Chat Log*中添加消息不仅仅是为了微调助手的响应。另一个重要的应用场景是创建聊天机器人，在这种情况下，必须在生成响应之前考虑到对话（即前面的
    `User` 和 `Assistant` 消息）。例如，考虑以下示例：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that the preceding block is pseudocode for the purposes of illustration
    and because it’s easier to read than the proper JSON structure that would be required
    for the OpenAI API. In order to use this example in the OpenAI API, the request
    **Body** would need to be what is displayed in the following code block:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的代码块是为了说明目的而编写的伪代码，因为它比 OpenAI API 所需的正式 JSON 结构更易于阅读。为了在 OpenAI API 中使用这个示例，请求的
    **Body** 必须是以下代码块中显示的内容：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, the user prompt is `How big is it?`. However, if we were to call the API
    using just this prompt, it would not generate the correct answer – in fact, it
    wouldn’t know at all what we were talking about because the previous `User` and
    `Assistant` messages are not in the request **Body**.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，用户提示是 `How big is it?`。但是，如果我们只使用这个提示调用 API，它将无法生成正确的答案——事实上，它根本不知道我们在说什么，因为之前的
    `User` 和 `Assistant` 消息并不在请求的 **Body** 中。
- en: As a result, we would need to construct the request body with all of the messages
    listed in the preceding code block for the model to provide an accurate response.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要构造请求体，将前面的代码块中列出的所有消息包含进去，才能让模型提供准确的响应。
- en: Creating pictures using the Images endpoint
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用图像端点创建图片
- en: The OpenAI API can do more than generate text (although that is its main purpose);
    it can also create images. It does this with a similar methodology to text generation,
    but instead of predicting characters, it predicts pixels. The inner workings of
    the model are complex (it involves the use of encoders, decoders, and embeddings),
    but that doesn’t stop us from actually using the model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 不仅能生成文本（虽然这是它的主要功能）；它还可以创建图像。它使用与文本生成类似的方法来实现这一点，但不是预测字符，而是预测像素。模型的内部工作原理是复杂的（它涉及编码器、解码器和嵌入技术），但这并不妨碍我们实际使用这个模型。
- en: This significantly opens up the types of applications you can create with the
    OpenAI API. For example, you can create an application that produces stock images
    based on a user prompt. In this recipe, we will use the OpenAI API to generate
    several types of images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这极大地拓宽了您可以使用 OpenAI API 创建的应用程序类型。例如，您可以创建一个根据用户提示生成库存图像的应用程序。在本教程中，我们将使用 OpenAI
    API 生成几种类型的图像。
- en: How to do it…
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: In Postman, create a new request by selecting the **New** button on the top-left
    menu bar, and then select **HTTP**.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Postman 中，通过点击左上角菜单栏的**New**按钮创建一个新请求，然后选择**HTTP**。
- en: Change the HTTP request type from **GET** to **POST** in the **Method** drop-down
    menu (by default, it will be set to **GET**).
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**Method**下拉菜单中将 HTTP 请求类型从**GET**更改为**POST**（默认情况下，它将设置为**GET**）。
- en: 'Enter the following URL as the endpoint for images: [https://api.openai.com/v1/images/generations](https://api.openai.com/v1/images/generations)'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为图像的端点，请输入以下 URL：[https://api.openai.com/v1/images/generations](https://api.openai.com/v1/images/generations)
- en: 'Select **Headers** in the sub-menu, and add the following key-value pairs into
    the table below it:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在子菜单中选择**Headers**，并将以下键值对添加到其下方的表格中：
- en: '| *Key* | *Value* |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| *Key* | *Value* |'
- en: '| `Content-Type` | `application/json` |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| `Content-Type` | `application/json` |'
- en: '| `Authorization` | `Bearer <your API` `key here>` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `Authorization` | `Bearer <your API` `key here>` |'
- en: 'Select **Body** in the sub-menu and then select **raw** for the request type.
    Enter the following and after that, select **Send**:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在子菜单中选择**Body**，然后选择请求类型为**raw**。输入以下内容后，点击**Send**：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '5. After sending the HTTP request, you should see the following response from
    the OpenAI API. Note that your response will be different – it will produce a
    completely different URL. The following URL has been artificially condensed:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 发送 HTTP 请求后，你应该会看到来自 OpenAI API 的以下响应。请注意，你的响应会有所不同——它会生成一个完全不同的 URL。以下的
    URL 已被人工压缩：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 6. The image is contained within the URL that is generated in the response.
    Copy the URL from the `url` object and paste it into your internet browser. You
    should see an image of a dog. Similar to text generation, the image that you see
    will be different than the following one.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 6. 图像包含在响应中生成的 URL 内。从 `url` 对象中复制该 URL，并粘贴到你的互联网浏览器中。你应该能看到一张狗的图片。和文本生成类似，你看到的图像与以下的图像会有所不同。
- en: '![Figure 2.2 – Output of DALLE-2 OpenAI image generation of a dog](img/B21007_02_2.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – DALL-E 2 OpenAI 图像生成的狗的输出](img/B21007_02_2.jpg)'
- en: Figure 2.2 – Output of DALLE-2 OpenAI image generation of a dog
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – DALL-E 2 OpenAI 图像生成的狗的输出
- en: 7. Return to Postman and modify the request `A brown furry medium-sized corgi
    dog on a green grass field,` `profile view`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 7. 返回到 Postman 并修改请求为 `一只棕色毛茸茸的中等大小柯基狗站在绿草地上，` `侧面视图`。
- en: 8. Copy and paste the URL from the **Response** field into your browser, and
    should see a clear photo of a Corgi dog.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 8. 从**Response**字段复制并粘贴 URL 到浏览器中，你应该能看到一张清晰的柯基狗照片。
- en: '![Figure 2.3 – Output of DALL-E 2 OpenAI image generation with a more detailed
    prompt](img/B21007_02_3.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – DALL-E 2 OpenAI 图像生成的更详细提示输出](img/B21007_02_3.jpg)'
- en: Figure 2.3 – Output of DALL-E 2 OpenAI image generation with a more detailed
    prompt
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – DALL-E 2 OpenAI 图像生成的更详细提示输出
- en: How it works…
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The Images endpoint works using an AI model called **DALL-E**, which is a variation
    of the GPT model, but used to produce visualizations instead of text output. The
    model was trained on several billion image-text prompts to associate certain textual
    characteristics with visual representations. The power of this model is available
    within OpenAI, but a particular endpoint needs to be used, as we described in
    the recipe.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图像端点使用一个名为**DALL-E**的 AI 模型，该模型是 GPT 模型的一种变体，但用于生成可视化内容，而不是文本输出。该模型在数十亿的图像-文本提示对上进行了训练，以将特定的文本特征与视觉表示关联起来。该模型的强大功能在
    OpenAI 内部可以使用，但需要使用特定的端点，如我们在教程中所描述的。
- en: Note
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: DALL-E was introduced by OpenAI in early 2021 as its first text-to-image generation
    model. DALL-E 2, its next iteration, was released one year later ([https://openai.com/dall-e-2](https://openai.com/dall-e-2)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 是 OpenAI 在 2021 年初推出的首个文本到图像生成模型。DALL-E 2 是其下一版本，于一年后发布（[https://openai.com/dall-e-2](https://openai.com/dall-e-2)）。
- en: Both DALL-E and DALL-E 2 serve the same purpose (generating images from text)
    and are even called using the same API. The key difference is that DALL-E 2 employs
    a more advanced and more popular technique called **diffusion**, a particular
    image generation method that leads to more realistic and high-resolution images.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 和 DALL-E 2 都具有相同的功能（根据文本生成图像），并且通过相同的 API 调用。关键区别在于，DALL-E 2 使用了一种更先进且更流行的技术，叫做**扩散**，这是一种特殊的图像生成方法，能够生成更逼真和高分辨率的图像。
- en: In this book, DALL-E and DALL-E 2 will be used interchangeably to refer to the
    OpenAI’s text-to-image generation model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，DALL-E 和 DALL-E 2 将交替使用，用来指代 OpenAI 的文本到图像生成模型。
- en: Request body and response
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 请求体和响应
- en: 'The request **Body** for the Images endpoint is actually far simpler than the
    Chat Completions endpoint. Here are all its components:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图像端点的请求**Body**其实比聊天完成功能的请求要简单得多。以下是它的所有组成部分：
- en: '**prompt**: This is the textual instruction provided to the model for image
    generation. Usually, the more detailed this statement is, the more accurate your
    desired image will be.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**prompt**：这是提供给模型的文本指令，用于图像生成。通常，这个指令越详细，生成的图像就会越接近你的需求。'
- en: '**n**: This expresses to the API the number of images that the model should
    generate. Each image will have slightly different variations, as the model attempts
    to provide different interpretations or angles based on the prompt.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**n**：这告诉 API 模型应生成的图像数量。每张图像都会有些微不同的变化，因为模型尝试根据提示提供不同的解释或角度。'
- en: '**size**: This specifies the dimensions of the generated image. Note that,
    at this point, only the following image sizes can be created: 256x256, 512x512,
    and 1024x1024.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**size**: 这指定生成图像的尺寸。目前，仅能生成以下尺寸的图像：256x256、512x512和1024x1024。'
- en: 'The **Response** that we receive from the Images endpoint is also very easy
    to understand:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从图像端点收到的**响应**也非常容易理解：
- en: '**created**: This represents the Unix timestamp of when the image was generated'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**created**: 这表示图像生成时的Unix时间戳'
- en: '**data**: The value of this object is actually an array of objects, each containing
    the **url** parameter:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**data**: 该对象的值实际上是一个对象数组，每个对象都包含**url**参数：'
- en: '**url**: This contains the direct link to the generated image'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**url**: 这是生成图像的直接链接'
- en: Importance of being detailed
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 详细描述的重要性
- en: Unlike text generation, where you can afford to be a bit general and any ambiguity
    is usually addressed by the context of the Chat Log and System Message, image
    generation requires detailed, descriptive, and specific language to produced the
    desired output. We clearly saw this in this recipe. The simle prompt, `A dog`,
    resulted in a standard image of a dog, but observe in *Figure 2**.4* the variation
    of images that are produced when we run image generation again with the same prompt.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与文本生成不同，文本生成你可以稍微泛泛而谈，任何歧义通常可以通过聊天记录和系统消息的上下文来解决，而图像生成需要详细、描述性和具体的语言来产生期望的输出。在本食谱中我们清楚地看到了这一点。简单的提示`A
    dog`（一只狗）生成了一张标准的狗的图像，但请观察*图 2.4*，当我们使用相同的提示再次进行图像生成时，生成的图像呈现出了不同的变化。
- en: '![Figure 2.4 – Outputs generated for the same image prompt](img/B21007_02_4.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – 相同图像提示生成的输出](img/B21007_02_4.jpg)'
- en: Figure 2.4 – Outputs generated for the same image prompt
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 相同图像提示生成的输出
- en: The images contain different types of dogs, different environments, different
    angles, and different lighting. Compare this to the more detailed prompt we used
    – the following figure shows the additional images that were produced by the more
    detailed prompt about a Corgi in this recipe.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像包含不同种类的狗、不同的环境、不同的角度和不同的光照。与我们使用的更详细提示进行对比——下图展示了使用关于这张柯基狗图像的更详细提示所生成的额外图像。
- en: '![Figure 2.5 – Different outputs generated from a specific prompt](img/B21007_02_5.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – 从特定提示生成的不同输出](img/B21007_02_5.jpg)'
- en: Figure 2.5 – Different outputs generated from a specific prompt
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 从特定提示生成的不同输出
- en: A more descriptive prompt significantly narrows down the possibilities, guiding
    the model towards producing an image that matches the user’s wants and intentions.
    It’s important to specify colors, positioning, objects, emotions, lighting, and
    other details so that the user can ensure that the generated image is not only
    relevant but also intricately tailored to their requirements.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 更具描述性的提示显著缩小了可能性，引导模型生成符合用户需求和意图的图像。指定颜色、位置、物体、情感、光照等细节非常重要，以便用户可以确保生成的图像不仅相关，而且精细地契合他们的需求。
- en: The Images endpoint in the OpenAI API unlocks a variety of different use cases.
    For example, the endpoint can be used to build personalized pictures in stories,
    visualize different food recipe ideas, and even create funny pictures for greeting
    cards. The possibilities are truly endless!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API中的图像端点解锁了多种不同的使用场景。例如，该端点可以用于在故事中创建个性化的图片、可视化不同的食谱创意，甚至为贺卡制作有趣的图片。可能性真的是无限的！
- en: Generating transcripts using the Audio endpoint
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用音频端点生成转录文本
- en: In this recipe, we will learn how to use the OpenAI API’s Audio endpoint, which
    converts audio into text. This enables developers to create voice applications,
    such as voice agents and speech conversational bots.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将学习如何使用OpenAI API的音频端点，该端点将音频转换为文本。这使开发者能够创建语音应用程序，如语音助手和语音对话机器人。
- en: Getting ready
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: This recipe will also use Postman, but the typical set of Headers that we use
    will need to be modified so that the HTTP client uses form data instead of typical
    JSON. In addition, we must have a sample audio file that we can use as an example
    to convert speech to text. **Form data** is a way to encode and send data as key-value
    pairs in HTTP requests instead of JSON-formatted strings. Form data is often used
    for uploading files.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱还将使用Postman，但我们通常使用的Header设置需要进行修改，以便HTTP客户端使用表单数据而不是典型的JSON格式。另外，我们需要一个示例音频文件，用于将语音转换为文本。**表单数据**是一种以键值对的方式编码和发送数据的HTTP请求格式，通常用于上传文件。
- en: After opening a new request in Postman, navigate to the `Content-Type application/json`
    entry. This will force Postman to default to the `Content-Type` of the request
    based on what is passed in the request **Body**.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 打开Postman中的新请求后，导航到`Content-Type application/json`条目。这样Postman将强制默认根据请求**Body**中的内容来设置请求的`Content-Type`。
- en: 'Next, we need an audio file. Any short (i.e., less than a minute) file will
    do, but it must contain words that can be transcribed and must be in one of the
    following formats: `.mp3`, `.mp4`, `.mpeg`, `.mpga`, `.m4a`, `.wav`, or `.webm`.
    You can also download a 10-second audio snip that I cr[eated here: https://github.com/hasygithub/ChatGPT-API-Book/raw/main/aud](https://github.com/hasygithub/ChatGPT-API-Book/raw/main/audiosample.mp3)iosample.mp3.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一个音频文件。任何短的（即小于一分钟）文件都可以，但它必须包含可以转录的词语，并且必须是以下格式之一：`.mp3`、`.mp4`、`.mpeg`、`.mpga`、`.m4a`、`.wav`或`.webm`。你也可以下载我创建的一个10秒钟的音频片段，点击此处：[下载链接](https://github.com/hasygithub/ChatGPT-API-Book/raw/main/audiosample.mp3)。
- en: How to do it…
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We can add examples of prompts and responses to the Chat Log to modify the
    model’s behavior. Let’s observe this with the following steps:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以添加提示和响应的示例到聊天日志中，以修改模型的行为。让我们通过以下步骤来观察这一点：
- en: 'In Postman, change the **Endpoint** value to the following URL and change the
    request type to **Post**:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Postman中，将**Endpoint**的值改为以下URL，并将请求类型更改为**Post**：
- en: '[PRE8]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Select **Body**, and then select the **form-data** radio button. This will open
    the form data fields. Each field contains a **Key** and a **Value**.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**Body**，然后选择**form-data**单选按钮。这将打开表单数据字段。每个字段包含一个**Key**和一个**Value**。
- en: Note
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We have the option to set each field as **Text** or **File**. We can do this
    by hovering over **Key** and selecting our chosen option from the drop-down menu,
    as demonstrated in *Figure 2**.6*.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择将每个字段设置为**文本**或**文件**。我们可以通过将鼠标悬停在**Key**上，并从下拉菜单中选择我们选择的选项，正如*图2.6*所示。
- en: 'Enter the following fields in the form data:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在表单数据中输入以下字段：
- en: '| *Key* | *Instruction/Value* |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| *Key* | *指令/值* |'
- en: '| `file` | Click **Select Files** and upload the audio file you created or
    downloaded earlier |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `file` | 点击**选择文件**并上传你之前创建或下载的音频文件 |'
- en: '| `model` | `whisper-1` |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `model` | `whisper-1` |'
- en: '![Figure 2.6 – Selecting field types in Postman](img/B21007_02_6.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 在Postman中选择字段类型](img/B21007_02_6.jpg)'
- en: Figure 2.6 – Selecting field types in Postman
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 在Postman中选择字段类型
- en: 4. Select the **Send** button to submit the HTTP request.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 选择**发送**按钮以提交HTTP请求。
- en: '5. You should see the following response from OpenAI, specifying the text that
    was transcribed:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 你应该会看到OpenAI返回的以下响应，指明了被转录的文本：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How it works…
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: This recipe uses the *Audio* endpoint, but note that the way we interacted with
    this endpoint’s API was completely different than the other endpoints. In particular,
    this endpoint expects the `Content-Type` of the request to be `form-data`, instead
    of the typical JSON structure that we saw previously. The reason for this is because
    `form-data` is capable of handling file streaming, which we needed here as we
    are uploading audio to OpenAI. In the other endpoints, raw JSON is sufficient
    because only text is being sent to OpenAI, not files.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法使用了*音频*端点，但请注意，我们与这个端点的API交互方式与其他端点完全不同。特别是，这个端点要求请求的`Content-Type`为`form-data`，而不是之前看到的典型JSON结构。原因在于`form-data`能够处理文件流，这正是我们在上传音频文件到OpenAI时所需要的。而在其他端点中，由于只是发送文本而非文件，原始的JSON就足够了。
- en: '**HTTP requests** are the bedrock of data communication on the web and are
    frequently used to interact with APIs. Two options for sending data within HTTP
    requests are **JSON** and **forms**. JSON has now become the ubiquitous data interchange
    format due to its flexibility in structure – it can be used to communicate key-value
    pairs, lists, and hierarchy concepts. However, the reason we used forms is that
    they enable developers to encode binary data. In short, forms enable you to transfer
    files (such as a 10-second MP3 file, in this case).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**HTTP请求**是网络数据通信的基石，并且通常用于与API进行交互。发送数据的两种方式是**JSON**和**表单**。由于JSON在结构上的灵活性，现在已经成为了广泛使用的数据交换格式——它可以用于传输键值对、列表和层级结构等概念。然而，我们使用表单的原因是，它们允许开发者编码二进制数据。简而言之，表单使得你能够传输文件（例如在此案例中是一个10秒钟的MP3文件）。'
- en: 'In the form, there were two fields: **file** and **model**. The **file** field
    represents the audio file object that we want to transcribe, and the **model**
    field represents the particular transcription model we want to use – which, in
    this case, was actually limited to only one option: **whisper-1**.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在表单中，有两个字段：**file** 和 **model**。**file** 字段表示我们想要转录的音频文件对象，**model** 字段表示我们想要使用的特定转录模型——在这种情况下，实际上仅限于一个选项：**whisper-1**。
- en: The **Response** is simple – a JSON with one object (*text*), representing the
    transcribed text.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**响应**很简单——一个 JSON 对象（*text*），表示转录的文本。'
- en: Now that we know how to use this endpoint, we can integrate it to create powerful
    and smart business applications. For example, typical workflows such as transcribing
    recorded meetings and lectures can be done with a single API request. Several
    endpoints can be chained together for even more advanced use cases. For example,
    we can create voice assistants similar to Siri that take a recorded voice, convert
    it to text, and then call the Chat Completions API to get a response.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何使用这个端点，我们可以集成它来创建强大而智能的商业应用程序。例如，典型的工作流程，如转录录制的会议和讲座，可以通过单个 API 请求完成。可以链式地连接多个端点，以实现更高级的用例。例如，我们可以创建类似于
    Siri 的语音助手，它接收录制的声音，将其转换为文本，然后调用聊天完成 API 获取响应。
- en: It’s important to know that the OpenAI API is more than just text generation;
    it can perform image generation, voice-to-text, and even create embeddings for
    semantic search. The OpenAI API is a collection of several different endpoints
    that, when combined, offer developers an invaluable set of tools to build intelligent
    applications.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要知道，OpenAI API 不仅仅是文本生成；它可以执行图像生成、语音转文本，甚至为语义搜索创建嵌入。OpenAI API 是几个不同端点的集合，结合使用时，为开发者提供了一个无价的工具集，用于构建智能应用程序。
