- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Mastering Prompt Generation and Understanding How Auto-GPT Generates Prompts
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握提示生成并理解Auto-GPT如何生成提示
- en: You are really into the book! Congratulations on reaching this chapter!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你真的很喜欢这本书！恭喜你到达这一章！
- en: In the previous chapters, we explored the basics of Auto-GPT and its installation.
    Now, we are going to delve deeper into one of the most crucial aspects of working
    with this powerful language model – prompt generation. In this chapter, we will
    demystify the process of how Auto-GPT generates prompts, understand why they are
    so important, and learn how to craft effective prompts to get the most out of
    Auto-GPT. Let’s get started!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们探讨了Auto-GPT的基础知识及其安装过程。现在，我们将更深入地探讨与使用这个强大语言模型相关的最关键方面之一——提示生成。在本章中，我们将揭示Auto-GPT生成提示的过程，理解它们为何如此重要，并学习如何制作有效的提示，以从Auto-GPT中获得最大收益。让我们开始吧！
- en: 'In this chapter, we will explore these topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下主题：
- en: What are prompts, and why are they important?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提示，它们为什么重要？
- en: Tips to craft effective prompts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作有效提示的技巧
- en: An overview of how Auto-GPT generates prompts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Auto-GPT如何生成提示的概述
- en: Examples of what works and what confuses GPT
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么有效，什么让GPT困惑的示例
- en: What are prompts, and why are they important?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示，它们为什么重要？
- en: We usually know how to talk to ChatGPT, which is chatting with it directly.
    ChatGPT responds directly with its answer to whatever we ask it. But how does
    this relate to prompts?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常知道如何与ChatGPT交流，即直接与它聊天。ChatGPT会直接回应我们提出的任何问题。但这与提示有何关系呢？
- en: The text we send is called a prompt; it can be a question, a statement, a task,
    or just whatever we want to tell the **large language model** (**LLM**) . However,
    this text is not fed into the LLM directly.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发送的文本叫做提示，它可以是一个问题、陈述、任务，或者我们想告诉**大型语言模型**（**LLM**）的任何内容。然而，这些文本并不会直接输入到LLM中。
- en: The application generally provides the context of the conversation, such as
    constraints (for example, *You are a helpful assistant. Never argue with the user,
    and answer requests only if it is ethical and helpful to* *the user*).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序通常会提供对话的上下文，例如约束（例如，*你是一个有帮助的助手。永远不要与用户争论，只在符合伦理且对用户有帮助时才回答请求*）。
- en: Prompts are the initial inputs that you provide to a language model to generate
    a response. They can take several forms, such as a question, a statement, or a
    task.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是你提供给语言模型生成回应的初始输入。它们可以有多种形式，例如问题、陈述或任务。
- en: For example, if you were to ask the model, *What is the weather like today?*,
    this would be a question prompt.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你问模型，*今天的天气怎么样？*，这将是一个问题提示。
- en: A statement prompt could be something like *Tell me about the history of Rome*,”
    while a task prompt might be *Write a short story about a spaceship*. Each type
    of prompt serves a different purpose and can elicit different types of responses
    from the model. Understanding how to use these different types of prompts effectively
    is key to getting the most out of your interaction with Auto-GPT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一条陈述性提示可能是像*告诉我关于罗马的历史*，而任务提示可能是*写一个关于宇宙飞船的短故事*。每种类型的提示都有不同的目的，并且可以引发模型不同类型的回应。理解如何有效地使用这些不同类型的提示是从与Auto-GPT的互动中获得最大收益的关键。
- en: 'Here was a prompt that was sent to Auto-GPT, which someone removed:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个发送给Auto-GPT的提示，有人将其删除：
- en: '*please add the text that was here before which was containing* *the prompt—*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*请添加之前包含提示的文本—*'
- en: 'With that prompt, we provided the following constraints:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用该提示时，我们提供了以下约束：
- en: '“Never argue with the user”:'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “永远不要与用户争论”：
- en: '**Interpretation**: The user is always the source of truth.'
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释**：用户始终是信息的真实来源。'
- en: '**Effect**: This constraint emphasizes a user-centric approach where the AI
    refrains from challenging the user’s statements or perspectives. It ensures that
    the AI’s responses are in agreement or neutral to the user’s input, but this could
    potentially limit the depth of interactive dialogue. It may also cause the AI
    to “role play” and act as if the situation was only a story, trying to respond
    in a manner that fits the context or even the aforementioned sentence. This may
    cause Auto-GPT to make wrong assumptions or become blind to untrue information,
    such as steps to setting up something that are made up and only sound kind of
    right.'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效果**：这一限制强调以用户为中心的方法，AI避免挑战用户的陈述或观点。它确保AI的回答与用户的输入一致或保持中立，但这可能限制互动对话的深度。它还可能导致AI“角色扮演”，假装情况仅仅是一个故事，尽量以符合上下文或上述句子的方式回应。这可能导致Auto-GPT做出错误假设，或者忽视不真实的信息，例如一些设置步骤虽然听起来合理，但其实是编造的。'
- en: '“You are a helpful assistant”:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “你是一个有帮助的助手”：
- en: '**Role definition**: Clearly establishes the AI’s role as an assistant.'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色定义**：明确界定了AI的角色是助手。'
- en: '**Tone and interaction**: Sets a predefined tone and direction for conversations.
    The AI is programmed to strictly adhere to an assistant’s role. However, this
    might not always align with user expectations. Users may anticipate a more informal,
    friendly tone and interactive engagement, such as receiving proactive questions
    such as “*How can I assist you today?*” Instead, the AI’s involvement might be
    limited to reactive responses without creative input.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语气和互动**：为对话设置预定义的语气和方向。AI被编程为严格遵循助手角色。然而，这未必总是符合用户的预期。用户可能希望更为非正式、友好的语气和互动，如主动提问“*我今天如何可以帮助您？*”而AI的参与可能局限于反应性回答，而缺乏创意输入。'
- en: '“Answer questions only if it is ethical and helpful to the user”:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “只有在道德和有益于用户的情况下才回答问题”：
- en: '**The scope of capabilities**: Imposes significant limitations on the AI’s
    functionality. The AI is programmed to prioritize ethical considerations and user
    utility in every interaction.'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**能力范围**：对AI的功能施加了重大限制。AI被编程为在每次互动中优先考虑道德和用户效用。'
- en: '**An impact on decision-making assistance**: This could lead to an overly cautious
    approach where the AI refrains from performing tasks that might relieve users
    of decision-making responsibilities. For example, if faced with complex or morally
    ambiguous tasks, the AI might opt for minimal engagement rather than comprehensive
    assistance.'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对决策支持的影响**：这可能导致过于谨慎的处理方式，AI避免执行可能帮助用户减轻决策责任的任务。例如，当面对复杂或道德模糊的任务时，AI可能选择最小化参与，而不是提供全面的帮助。'
- en: '**An example in practice**: When asked to assist in creative tasks, such as
    writing a chapter about the varying colors of roses, the AI might limit its response
    to outlining potential approaches (e.g., suggesting bullet points for the chapter),
    rather than actively engaging in the creative process itself.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实践中的一个例子**：当要求协助创作任务时，例如写一章关于玫瑰的不同颜色，AI可能会将回应限制为概述潜在的做法（例如，提出章节的要点），而不是主动参与到创作过程本身。'
- en: Prompts define the task as well as the context of what the LLM is supposed to
    answer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 提示定义了任务以及LLM应该回答的内容的背景。
- en: 'As we discussed in [*Chapter 1*](B21128_01.xhtml#_idTextAnchor013), Auto-GPT
    sends a fairly huge prompt, where it defines the context, commands, and constraints,
    as well as a `"user"` message that says the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第1章*](B21128_01.xhtml#_idTextAnchor013)中讨论的，Auto-GPT会发送一个相当庞大的提示，其中定义了上下文、命令和限制，以及一条“`user`”消息，内容如下：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This way, GPT actually plays a role in a hypothetical story that contains the
    current context of information and the possible commands that only Auto-GPT can
    execute, responding to the query prompt of the user with what command it thinks
    it should use next.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，GPT实际上在一个假设的故事中扮演角色，包含当前信息的背景以及只有Auto-GPT才能执行的可能命令，依据其认为应使用的命令回应用户的查询提示。
- en: This is even more interesting if you consider that when instructing, for example,
    ChatGPT to do something, it would generally respond with the so-annoying phrase,
    “*As an AI* *language model...*”
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果考虑到例如让ChatGPT做某件事情，它通常会回应那句让人恼火的“*作为一个AI* *语言模型...*”时，这会变得更加有趣。
- en: Phrasing
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词语表述
- en: When we look at the prompts that Auto-GPT uses, we could easily think about
    rephrasing them, making them shorter to save tokens, or adding more context.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看 Auto-GPT 使用的提示时，我们很容易想到重新措辞，缩短提示以节省 token，或添加更多的上下文。
- en: However, each of those operations has a downside.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，每个操作都有其缺点。
- en: LLMs are not human; they aren’t really an intelligence that understands the
    input that it is given and what it outputs. They are only trained to generate
    text that is the most probable, given a certain input.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）并不是人类；它们并不真正理解它所接收的输入和输出的内容。它们只是被训练来生成在给定某个输入时最可能的文本。
- en: This means that even though a sentence could have the exact same meaning as
    another, both sentences may be interpreted completely differently.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着即使两个句子具有完全相同的含义，它们也可能被完全不同地解释。
- en: Due to the nature of machine learning, the texts that were used to train an
    LLM pretty much also define how it stores its knowledge.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习的性质，用于训练 LLM 的文本几乎也定义了它如何存储其知识。
- en: If the sentence “*I have just sold my car because I just wanted to buy an ice
    cream*” never appeared in the training data, an LLM would have a harder time understanding
    the sentence, given that the tokens are not related. “Buy” would be related to
    “car” and “ice cream,” but “car” and “ice cream” would be considerably unrelated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果句子“*我刚刚卖掉了我的车，因为我只是想买一个冰淇淋*”在训练数据中从未出现过，LLM 会更难理解这个句子，因为这些 token 没有关系。“买”会与“车”和“冰淇淋”相关，但“车”和“冰淇淋”之间的关联则非常薄弱。
- en: As GPT-4 is not open source, we have to rely on Llama to understand how models
    work.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 GPT-4 不是开源的，我们必须依赖 Llama 来理解模型是如何工作的。
- en: Llama has a few parameters, such as length penalties and uniqueness (i.e., how
    often the same words appear). These limit the vector length of each embedding,
    for example.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 有一些参数，比如长度惩罚和唯一性（即相同单词出现的频率）。这些限制了每个嵌入的向量长度，例如。
- en: Embeddings
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入（Embeddings）
- en: Embeddings are a crucial part of how Auto-GPT generates prompts. They are essentially
    a way of representing words and phrases in a numerical form that a model can understand.
    Each word or phrase is represented as a point in a multidimensional space, where
    the distance and direction between points can represent the relationship between
    words or phrases.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入（Embeddings）是 Auto-GPT 生成提示的关键部分。它们本质上是一种将单词和短语表示为模型能够理解的数字形式的方法。每个单词或短语都被表示为多维空间中的一个点，其中点与点之间的距离和方向可以表示单词或短语之间的关系。
- en: For instance, in this multidimensional space, the words “king” and “queen” might
    be close together, indicating a strong relationship, while “king” and “ice cream”
    would be further apart, indicating a weaker relationship. This is how a model
    understands context and can generate relevant responses.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这个多维空间中，“king”和“queen”可能会靠得很近，表示它们之间有很强的关系，而“king”和“ice cream”则会相距较远，表示它们之间的关系较弱。这就是模型如何理解上下文并生成相关响应的方式。
- en: The process of creating these embeddings involves breaking down the input text
    into tokens, which can be words, parts of words, or even single characters, depending
    on the language. These tokens are then mapped to vectors in the multidimensional
    space.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 创建这些嵌入的过程涉及将输入文本分解成 token，token 可以是单词、单词的一部分，甚至是单个字符，这取决于语言。然后，这些 token 会被映射到多维空间中的向量。
- en: The model then uses these vectors to generate a response. It does this by calculating
    the probability of each possible next token, based on the current context. The
    token with the highest probability is selected, and the process is repeated until
    a complete response is generated.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 模型然后使用这些向量生成响应。它通过计算基于当前上下文每个可能下一个 token 的概率来实现这一点。具有最高概率的 token 被选中，然后重复这一过程，直到生成完整的响应。
- en: This is a simplified explanation of the process, and the actual implementation
    involves a lot more complexity, including the use of attention mechanisms to determine
    which parts of the input are most relevant, and the use of transformer models
    to handle long sequences of tokens.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该过程的简化解释，实际实现要复杂得多，包括使用注意力机制来确定输入中最相关的部分，以及使用 Transformer 模型来处理长序列的 token。
- en: However, the key takeaway is that a model generates prompts by understanding
    the context of the input and calculating the most probable next token. This is
    why the phrasing of prompts is so important, as it can greatly influence the model’s
    understanding of the context and, therefore, the generated response.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关键的要点是，模型通过理解输入的上下文并计算出最可能的下一个词来生成提示。这就是为什么提示措辞如此重要，因为它可以极大地影响模型对上下文的理解，从而影响生成的回应。
- en: In the next section, we will look at some tips to craft effective prompts and
    provide some examples of what works and what confuses Auto-GPT.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将查看一些制作有效提示的技巧，并提供一些什么有效、什么让Auto-GPT困惑的例子。
- en: Tips to craft effective prompts
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 制作有效提示的技巧
- en: 'The art of crafting effective prompts is a skill that requires a nuanced understanding
    of a language model’s capabilities and limitations. The following guidelines will
    help you to create prompts that are more likely to yield the desired responses
    from Auto-GPT:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 制作有效提示的艺术是一项需要对语言模型的能力和局限性有细致理解的技能。以下指南将帮助你制作更可能获得Auto-GPT理想回应的提示：
- en: '**Precision is key**: The specificity of your prompt can significantly influence
    the relevance of the response. For instance, a vague prompt such as “*Tell me
    about dogs*” might yield a generic response about dogs. However, a more specific
    prompt such as “*What are the different breeds of dogs and their characteristics?*”
    is likely to generate a more detailed and informative response.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确至关重要**：提示的具体性会显著影响回应的相关性。例如，像“*告诉我关于狗的事*”这样的模糊提示可能会得到关于狗的通用回答。然而，更具体的提示，如“*狗的不同品种及其特点是什么？*”则更可能生成更详细和有益的信息。'
- en: '**Clarity and simplicity**: It’s crucial to remember that while Auto-GPT is
    a sophisticated language model, it’s not a human. Therefore, it’s best to avoid
    jargon or complex language that could potentially confuse the model. Instead,
    opt for clear, simple language that the model can easily interpret.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**清晰与简洁**：重要的是要记住，虽然Auto-GPT是一个复杂的语言模型，但它不是人类。因此，最好避免使用术语或复杂语言，这可能会使模型感到困惑。相反，选择清晰、简洁的语言，模型能够轻松理解。'
- en: '**Contextual Clues**: One of the key tips to craft effective prompts is to
    provide sufficient contextual clues. This means giving a model enough information
    to understand the broader context of the conversation or task. For example, if
    you were asking the model to write a story set in medieval times, you might provide
    some context about the setting, characters, and plot before giving the actual
    prompt. This could be done through a more detailed prompt or by utilizing the
    conversation history feature of Auto-GPT. By providing sufficient context, you
    can help the model generate a more relevant and coherent response.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文线索**：制作有效提示的一个关键技巧是提供足够的上下文线索。这意味着给模型足够的信息，以理解对话或任务的更广泛背景。例如，如果你要求模型编写一个发生在中世纪的故事，你可能会在给出实际提示之前，提供一些关于背景、角色和情节的上下文。这可以通过更详细的提示，或利用Auto-GPT的对话历史功能来实现。通过提供足够的上下文，你可以帮助模型生成更相关和连贯的回应。'
- en: '**Experimentation**: Don’t hesitate to experiment with different phrasing and
    approaches. A slight change in the phrasing of your prompt can sometimes lead
    to a significantly different response.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**：不要犹豫尝试不同的措辞和方法。提示措辞的细微变化有时会导致截然不同的回应。'
- en: Next, we will look at a few examples of effective and ineffective prompts.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看一些有效和无效提示的示例。
- en: Examples of effective and ineffective prompts
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有效与无效提示的示例
- en: 'To better understand these principles, let’s examine some examples of such
    prompts:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些原则，让我们检查一些这样的提示示例：
- en: '**Example 1**: “Tell me a joke.” This prompt is simple and clear, and Auto-GPT
    is likely to respond with a joke, demonstrating its ability to generate creative
    content.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 1**：“告诉我一个笑话。”这个提示简单明了，Auto-GPT很可能会回应一个笑话，展示其生成创意内容的能力。'
- en: '**Example 2**: “What is the meaning of life?” This prompt is philosophical
    and broad, which might lead to a vague or generic response, as the model might
    struggle to provide a concise and meaningful answer.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 2**：“生命的意义是什么？”这个提示哲学性强且宽泛，可能导致模糊或通用的回应，因为模型可能难以提供简洁而有意义的答案。'
- en: '**Example 3**: “As a language model, explain the concept of machine learning.”
    This prompt is clear, and specific, and provides context, which will likely result
    in a detailed explanation of the concept.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 3**：“作为一个语言模型，解释机器学习的概念。”这个提示明确、具体，并提供了上下文，可能会导致对该概念的详细解释。'
- en: '**Example 4**: “Translate the following text into French: ‘Hello, how are you?’”
    This prompt is clear, specific, and task-oriented, which should lead to a correct
    translation.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 4**：“将以下文本翻译成法语：‘Hello, how are you?’”这个提示明确、具体，且以任务为导向，应该能得到正确的翻译。'
- en: In conclusion, understanding the intricacies of how Auto-GPT generates prompts
    and mastering the art of crafting effective prompts can significantly enhance
    your interaction with the model. Remember, the key is to be specific, use clear
    and simple language, provide ample context, and embrace experimentation. With
    these guidelines in mind, you’re well on your way to becoming a proficient user
    of Auto-GPT.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，理解 Auto-GPT 如何生成提示的复杂性，并掌握有效提示的编写技巧，可以显著提升与模型的互动。记住，关键是要具体、使用简洁明了的语言、提供充分的上下文并进行实验。遵循这些指导方针，你将能够成为
    Auto-GPT 的熟练用户。
- en: An overview of how Auto-GPT generates prompts
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Auto-GPT 生成提示的概述
- en: Here, we will understand the prompt generation process in Auto-GPT.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将了解 Auto-GPT 中的提示生成过程。
- en: Auto-GPT’s prompt generation process is a sophisticated mechanism that involves
    a deep understanding of the input context and the calculation of the most probable
    next token. This process is not just about generating responses but also about
    setting the stage for the conversation, defining the roles, and establishing the
    rules of engagement.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 的提示生成过程是一个复杂的机制，涉及对输入上下文的深刻理解以及计算最可能的下一个标记。这个过程不仅仅是生成响应，还包括为对话设定舞台、定义角色和建立互动规则。
- en: 'Let’s delve deeper into this process:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探讨这个过程：
- en: '**Tokenization**: The initial step involves breaking down the input text into
    tokens, which could be words, parts of words, or even individual characters, depending
    on the language.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记化**：初步步骤涉及将输入文本分解为标记，这些标记可以是单词、单词的一部分，甚至是单独的字符，这取决于语言。'
- en: '**Embedding**: Each token is then mapped to a vector in a multidimensional
    space, creating an “embedding.” The position of each vector in this space signifies
    the meaning of the corresponding token in relation to all other tokens.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入**：每个标记随后被映射到多维空间中的一个向量，形成一个“嵌入”。每个向量在该空间中的位置表示对应标记与其他标记的关系。'
- en: '**Contextual understanding**: Auto-GPT uses these embeddings to comprehend
    the context of the input. It calculates the distance and direction between the
    vectors, representing the relationships between the tokens.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文理解**：Auto-GPT 使用这些嵌入向量来理解输入的上下文。它计算向量之间的距离和方向，表示标记之间的关系。'
- en: '**Response generation**: The model then generates a response by calculating
    the probability of each possible next token, based on the current context. The
    token with the highest probability is selected, and the process is repeated until
    a complete response is generated.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应生成**：模型随后通过计算每个可能的下一个标记的概率来生成响应，基于当前上下文。选择具有最高概率的标记，并重复这个过程直到生成完整的响应。'
- en: '**An attention mechanism**: An attention mechanism is employed to determine
    which parts of the input are most relevant to the current context. This allows
    the model to focus on the most important parts of the input when generating a
    response.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意力机制**：注意力机制用于确定输入的哪些部分与当前上下文最相关。这使得模型在生成响应时，能够专注于输入中最重要的部分。'
- en: '**Transformer models**: To handle long sequences of tokens, the model uses
    transformer models. These models can process the tokens in parallel, making them
    much more efficient than traditional sequential models.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer 模型**：为了处理长序列的标记，模型使用 Transformer 模型。这些模型可以并行处理标记，比传统的顺序模型更加高效。'
- en: In [*Chapter 1*](B21128_01.xhtml#_idTextAnchor013), we discussed the default
    prompt that Auto-GPT uses, which includes constraints, context, goals, and commands.
    This default prompt sets the stage for a conversation, defines the roles, and
    establishes the rules of engagement. For instance, constraints such as “*Never
    argue with the user*” and “*You are a helpful assistant*” set the tone and direction
    of the conversation. The context and goals provide a clear understanding of the
    task at hand, and the commands guide the model’s responses.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第1章*](B21128_01.xhtml#_idTextAnchor013)中，我们讨论了Auto-GPT使用的默认提示，包括约束、上下文、目标和命令。这个默认提示为对话奠定了基础，定义了角色，并建立了互动规则。例如，约束条件如“*永远不要与用户争论*”和“*你是一个有帮助的助手*”设定了对话的基调和方向。上下文和目标则为任务提供了清晰的理解，而命令则指导了模型的回应。
- en: This is a high-level overview of the process, and the actual implementation
    involves a lot more complexity. However, the key takeaway is that Auto-GPT generates
    prompts by understanding the context of the input and calculating the most probable
    next token. This is why the phrasing of the prompts is so important, as it can
    greatly influence the model’s understanding of the context and, therefore, the
    generated response.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该过程的高级概述，实际实现涉及更多复杂性。然而，关键的结论是，Auto-GPT通过理解输入的上下文并计算最可能的下一个词来生成提示。这就是为什么提示的措辞如此重要，因为它可以极大地影响模型对上下文的理解，从而影响生成的回应。
- en: Examples of what works, and what confuses GPT
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成功的提示与让GPT困惑的提示示例
- en: 'Here are some examples of what GPT understands and what it might miss out on:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些关于GPT理解什么和可能忽略什么的例子：
- en: '**Example 1 – an effective prompt**: Here are the AI settings for this one:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**例子 1 – 有效的提示**：以下是此例的AI设置：'
- en: '**Role**: An AI-powered author and researcher specializing in creating comprehensive,
    well-structured, and engaging content on Auto-GPT and its plugins, while maintaining
    an open line of communication with the user for feedback and guidance'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：一位由AI驱动的作者和研究员，专门创建有关Auto-GPT及其插件的全面、结构良好且引人入胜的内容，同时与用户保持开放的沟通，以获取反馈和指导。'
- en: '**Goals**: Conduct a thorough analysis of the current state of the book and
    identify areas for improvement'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标**：对当前书籍的状态进行全面分析，并识别改进的领域。'
- en: '**Prompt**: AuthorGPT, I have placed a text file in your working directory;
    can you analyze the current state of the book and suggest areas for improvement?'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示**：AuthorGPT，我已经将一个文本文件放在你的工作目录里；你能分析一下这本书的当前状态并提出改进的建议吗？'
- en: This prompt aligns perfectly with the role and goal defined in the AI settings.
    The model is likely to respond with a detailed analysis of the book and suggestions
    for improvement.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个提示与AI设置中定义的角色和目标完全一致。模型很可能会提供有关书籍的详细分析，并提出改进建议。
- en: '**Example 2 – ineffective prompts**: Understanding hallucinations in GPT models
    – a compact exploration.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**例子 2 – 无效的提示**：理解GPT模型中的幻觉现象——一个简要的探索。'
- en: 'Hallucinations in GPT models refer to occasions where a model generates text
    that seems logical but is not based on reality. This usually occurs when the model
    encounters vague or incomplete prompts. Interestingly, generative AI such as GPT
    can begin to “hallucinate.” We’ll delve into the mechanics of this phenomenon
    shortly, but first, let’s define it more clearly. Here are the AI settings:'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT模型中的幻觉是指模型生成的文本看似合逻辑，但并非基于现实。这通常发生在模型遇到模糊或不完整的提示时。有趣的是，生成型AI如GPT会开始“幻觉”。我们将很快深入探讨这一现象的机制，但首先，让我们更清晰地定义它。以下是AI的设置：
- en: '**Role**: An AI-powered author and researcher specializing in creating comprehensive,
    well-structured, and engaging content on Auto-GPT and its plugins, while maintaining
    an open line of communication with the user for feedback and guidance.'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：一位由AI驱动的作者和研究员，专门创建有关Auto-GPT及其插件的全面、结构良好且引人入胜的内容，同时与用户保持开放的沟通，以获取反馈和指导。'
- en: '**Goals**: Conduct a thorough analysis of the current state of the book and
    identify areas for improvement'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标**：对当前书籍的状态进行全面分析，并识别改进的领域。'
- en: '**Prompt**: AuthorGPT, can you analyze the current state of the book and suggest
    areas for improvement?'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示**：AuthorGPT，你能分析一下这本书的当前状态并提出改进的建议吗？'
- en: With this prompt, you would expect Auto-GPT to ask you for the context, but
    I found that GPT tries to improvise instead and starts to hallucinate.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个提示，你应该期望Auto-GPT向你询问上下文，但我发现GPT反而尝试即兴发挥并开始出现幻觉。
- en: Hallucination with GPT means it starts to act as if it is doing something factual
    whereas it isn’t. Let’s understand this more in depth ahead.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPT中，幻觉意味着模型开始表现得像是在做某个事实性的事情，实际上它并没有做。接下来我们将更深入地理解这一现象。
- en: What does hallucination mean in GPT?
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPT中的幻觉是什么意思？
- en: Hallucination in GPT models manifests when a model acts as though it’s performing
    a task. This ranges from creating code files for projects that only contain placeholders
    to fabricating facts that sound contextually appropriate. For example, in certain
    situations, it might discuss a topic closely related to the context’s keywords.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型中的幻觉现象表现为模型好像在执行任务。其表现形式从为项目创建仅包含占位符的代码文件，到编造听起来符合语境的事实。例如，在某些情况下，模型可能会讨论一个与上下文关键词密切相关的话题。
- en: Hallucination in language models such as GPT happens when the model produces
    text that appears plausible but is unanchored in reality. This is often the result
    of the model working with ambiguous or insufficient information.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: GPT等语言模型中的幻觉现象发生在模型生成的文本看起来合理，但与现实脱节。通常，这种现象是由于模型处理了模糊或不足的信息。
- en: Take, for instance, if you request the model to write a story about a non-existent
    character. It might “hallucinate” details about the character’s life, appearance,
    or traits. While this can yield creative and unforeseen results, it can also lead
    to text that is illogical or unrelated to the original prompt.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，如果你请求模型编写一个关于虚构角色的故事，它可能会“幻觉”出关于该角色的生活、外貌或特征的细节。虽然这可能会产生创意和出人意料的结果，但也可能导致文本不合逻辑或与原始提示不相关。
- en: A case in point is when I asked Auto-GPT to develop a `three.js`-based RPG browser
    game. It began researching how to gather weather data from a non-existent API.
    This was a result of processing excessive context with GPT-3.5-turbo, which I
    had used before transitioning to GPT-4.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，当我要求Auto-GPT开发一个基于`three.js`的RPG浏览器游戏时，它开始研究如何从一个不存在的API收集天气数据。这是因为我在切换到GPT-4之前使用过GPT-3.5-turbo，导致处理过多的上下文信息。
- en: Auto-GPT’s memory sometimes harbors incorrect facts or memories. To economize
    tokens, its memory is condensed by *Chat Completion* prompts with GPT. This can
    lead to misunderstandings, especially when summarizing texts that have already
    been summarized and merging these summaries.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT的记忆有时会包含错误的事实或记忆。为了节省标记，它的记忆通过与GPT的*聊天完成*提示进行压缩。这可能会导致误解，特别是在总结已经总结过的文本并合并这些总结时。
- en: Confusion can also stem from tokens closely related to the current context.
    For example, if writing a weather API tool and a web-based game are both related
    to “JavaScript,” the model might perceive the weather API as a relevant topic.
    Such confusion is less frequent with GPT-4, thanks to its advanced parameters
    and enhanced precision.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 困惑也可能来源于与当前上下文密切相关的标记。例如，如果编写一个天气API工具和一个基于Web的游戏都与“JavaScript”相关，模型可能会将天气API视为一个相关话题。由于GPT-4的先进参数和增强的精确度，这种困惑在GPT-4中较少出现。
- en: Confusing a prompt and its impact on AI performance
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混淆提示词及其对AI性能的影响
- en: 'Here are some AI settings where the prompt can be confusing, impacting the
    performance of the AI it works with:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些AI设置，提示词可能会造成混淆，进而影响AI的表现：
- en: '**Role**: An AI-powered author and researcher specializing in creating comprehensive,
    well-structured, and engaging content on Auto-GPT and its plugins, while maintaining
    an open line of communication with the user for feedback and guidance'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：一位AI驱动的作者和研究员，专注于创建关于Auto-GPT及其插件的全面、结构良好且引人入胜的内容，同时保持与用户的开放沟通，以便提供反馈和指导。'
- en: '**Goals**: Conduct a thorough analysis of the current state of the book and
    identify areas for improvement'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标**：对当前书籍的状态进行深入分析，并识别需要改进的领域。'
- en: '**Prompt**: AuthorGPT, can you tell me a joke?'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示词**：AuthorGPT，你能告诉我一个笑话吗？'
- en: This seemingly simple prompt can lead to confusion for the model, primarily
    because it diverges from its established role and goal. The request for a joke
    seems out of place in the context of analyzing a book and suggesting enhancements.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个看似简单的提示词可能会让模型感到困惑，主要是因为它偏离了模型既定的角色和目标。要求一个笑话似乎与分析一本书并建议改进措施的上下文不符。
- en: Initially, the model might comply and tell a joke. However, this deviation can
    have longer-term repercussions. As the model integrates this interaction into
    its memory summary, it may become increasingly perplexed. This is because Auto-GPT
    instructs GPT to retain as much information as possible to prevent topic shifts,
    hallucinations, or previous steps being forgotten.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，模型可能会遵从并讲个笑话。然而，这种偏离可能会产生长期的影响。当模型将这种互动整合到其记忆总结中时，它可能会变得越来越困惑。这是因为Auto-GPT指示GPT尽可能保留信息，以防止话题转换、幻觉或之前的步骤被遗忘。
- en: A specific issue arises when Auto-GPT focuses on a particular task but encounters
    an unrelated prompt. For example, if it receives a command irrelevant to the ongoing
    context, the model might lose track of its previous actions. It could end up in
    a loop of searching for information related to the new input, attempting to reconcile
    it with the earlier task. As a result, Auto-GPT might start intertwining the unrelated
    joke with its Google Search results, leading to a mix-up of topics.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当Auto-GPT专注于某个特定任务，但遇到一个无关的提示时，会出现一个具体问题。例如，如果它收到一个与当前上下文无关的指令，模型可能会失去对之前动作的跟踪。它可能会陷入一个寻找与新输入相关的信息的循环，尝试将其与早期任务调和。因此，Auto-GPT可能会开始将无关的笑话与其Google搜索结果混在一起，导致话题混乱。
- en: This scenario highlights the importance of aligning prompts with the AI’s defined
    role and objectives to maintain effectiveness and avoid confusion.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这一场景突出了提示与AI定义的角色和目标对齐的重要性，以保持效果并避免混淆。
- en: An effective prompt and its impact on AI performance
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有效提示及其对AI性能的影响
- en: 'Here are the AI settings for an effective prompt and its advantages on AI performance:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是有效提示的AI设置及其对AI性能的优势：
- en: '**Role**: An AI-powered author and researcher specializing in creating comprehensive,
    well-structured, and engaging content on Auto-GPT and its plugins, while maintaining
    an open line of communication with the user for feedback and guidance'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：一名AI驱动的作者和研究员，专注于创建关于Auto-GPT及其插件的全面、结构良好且引人入胜的内容，同时与用户保持开放的沟通渠道，以便获取反馈和指导。'
- en: '**Goal**: Develop a comprehensive plan to create task lists that will help
    you structure research, a detailed outline per chapter, and individual parts'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标**：制定一个全面的计划，创建任务列表，帮助你构建研究框架、每章的详细大纲以及各个部分的内容。'
- en: '**Prompt**: AuthorGPT, can you help me develop a comprehensive plan to create
    task lists to structure my research and outline for each chapter?'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示**：AuthorGPT，你能帮我制定一个全面的计划，创建任务列表以结构化我的研究并为每一章拟定大纲吗？'
- en: This prompt is clear, specific, and aligns perfectly with the role and goal
    defined in the AI settings. The model is likely to provide a detailed plan for
    creating task lists and structuring research.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示明确、具体，并与AI设置中定义的角色和目标完美对齐。模型很可能会提供一个详细的任务列表创建计划和研究结构化方案。
- en: Confusing a prompt and its impact on AI performance
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混淆提示及其对AI性能的影响
- en: 'Here is an example of a confusing prompt and its impact on AI performance:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个令人困惑的提示及其对AI性能的影响：
- en: '**Role**: An AI-powered author and researcher specializing in creating comprehensive,
    well-structured, and engaging content on Auto-GPT and its plugins, while maintaining
    an open line of communication with the user for feedback and guidance'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：一名AI驱动的作者和研究员，专注于创建关于Auto-GPT及其插件的全面、结构良好且引人入胜的内容，同时与用户保持开放的沟通渠道，以便获取反馈和指导。'
- en: '**Goal**: Develop a comprehensive plan to create task lists that will help
    you structure research, a detailed outline per chapter, and individual parts.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标**：制定一个全面的计划，创建任务列表，帮助你构建研究框架、每章的详细大纲以及各个部分的内容。'
- en: '**Prompt**: AuthorGPT, what is the weather like today?'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示**：AuthorGPT，今天的天气怎么样？'
- en: Understanding the disparity
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解差异
- en: This prompt stands in stark contrast to AI’s designated role and goal. The model,
    configured to focus on task list creation and research structuring, faces a dilemma
    with a prompt that is unrelated to these tasks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示与AI的指定角色和目标形成鲜明对比。模型被配置为专注于任务列表创建和研究结构化，但面对与这些任务无关的提示时，陷入了困境。
- en: This is likely to confuse the model because it doesn’t align with the defined
    role and goal. The model might struggle to provide a relevant response because
    the prompt doesn’t involve creating a plan or structuring research.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这很可能会让模型感到困惑，因为它与定义的角色和目标不一致。模型可能会因为该提示不涉及创建计划或结构化研究而难以提供相关回答。
- en: 'Here are some potential AI behavior scenarios:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些潜在的AI行为场景：
- en: While Auto-GPT may respond correctly by researching the weather or just shrugging
    off that question by explaining that it is not the main focus, it could get confused
    and drop the previous task, either partially or completely. This could result
    in a very inaccurate future behavior, or even the issue escalating to GPT not
    responding correctly to the Auto-GPT module that communicates with it, causing
    a fatal error.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管Auto-GPT可能通过查询天气来正确回应，或者通过解释天气不是主要关注点来轻描淡写地回避该问题，但它也可能感到困惑并放弃之前的任务，部分或完全丢失任务。这可能导致非常不准确的未来行为，甚至可能导致问题升级，导致GPT无法正确响应与其通信的Auto-GPT模块，从而引发致命错误。
- en: The model might also try to relate every decision to checking the weather now,
    or it will keep checking the weather in later steps if Auto-GPT does not manage
    to compress its memory correctly (for example, when it tries to summarize the
    memory to reduce data amounts, it may put more emphasis on weather data now).
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型可能还会尝试将每个决策与当前的天气检查相关联，或者如果Auto-GPT没有正确压缩其记忆，它会在后续步骤中继续检查天气（例如，当它试图总结记忆以减少数据量时，可能会更加关注当前的天气数据）。
- en: In conclusion, crafting effective prompts for Auto-GPT involves aligning your
    prompts with the defined role and goal in the AI settings. Clear, specific prompts
    that align with these parameters are more likely to yield relevant responses,
    while prompts that don’t align can confuse the model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，为Auto-GPT设计有效的提示涉及将提示与AI设置中的定义角色和目标对齐。清晰、具体的提示更容易得到相关的回应，而不对齐的提示则可能会使模型产生困惑。
- en: Summary
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we delved into the intricacies of prompt generation and how
    Auto-GPT generates prompts. We started by defining prompts and their importance
    in shaping the responses of the language model. We learned that prompts can be
    questions, statements, tasks, or any text that we want to communicate to a language
    model.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了提示生成的复杂性以及Auto-GPT是如何生成提示的。我们首先定义了提示及其在塑造语言模型回应中的重要性。我们了解到，提示可以是问题、陈述、任务或任何我们希望传达给语言模型的文本。
- en: We also discussed the role of constraints in providing context to a conversation
    and guiding a model’s responses. We examined how specific constraints can influence
    the tone, direction, and ethical boundaries of the conversation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了约束在为对话提供背景并指导模型回应中的作用。我们检查了具体的约束如何影响对话的语气、方向和伦理边界。
- en: We then explored the technical aspects of prompt generation, including tokenization,
    embedding, context understanding, response generation, attention mechanisms, and
    transformer models. We learned that a model generates prompts by understanding
    the context of the input and calculating the most probable next token.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着探讨了提示生成的技术细节，包括分词、嵌入、上下文理解、回应生成、注意力机制和变换器模型。我们了解到，模型通过理解输入的上下文并计算最可能的下一个标记来生成提示。
- en: Then, we provided tips to craft effective prompts, emphasizing the importance
    of specificity, clarity, context, and experimentation. We also looked at examples
    of effective and confusing prompts, demonstrating how alignment with the defined
    role and goal in the AI settings can influence a model’s responses.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们提供了制定有效提示的技巧，强调了特定性、清晰度、上下文和实验的重要性。我们还查看了有效和令人困惑的提示示例，展示了在AI设置中与定义角色和目标对齐如何影响模型的回应。
- en: Finally, we examined examples of prompts based on specific AI settings, demonstrating
    how effective prompts align with the defined role and goal, while confusing prompts
    do not.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们举了基于特定AI设置的提示示例，展示了如何通过有效的提示与定义的角色和目标对齐，而令人困惑的提示则没有。
- en: In conclusion, mastering prompt generation and understanding how Auto-GPT generates
    prompts can significantly enhance your interaction with a model. The key is to
    craft clear, specific prompts that align with the model’s role and goal, provide
    ample context, and not be afraid to experiment.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，掌握提示生成并理解Auto-GPT是如何生成提示的，可以显著提高你与模型的互动效果。关键是要设计清晰、具体的提示，确保与模型的角色和目标对齐，提供充分的上下文，并勇于尝试。
- en: In the next chapter, we will use the skills we acquired with plugins and learn
    how to customize prompts.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将使用我们通过插件学习到的技能，学习如何自定义提示。
