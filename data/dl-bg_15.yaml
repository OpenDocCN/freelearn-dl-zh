- en: Convolutional Neural Networks
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: This chapter introduces convolutional neural networks, starting with the convolution
    operation and moving forward to ensemble layers of convolutional operations, with
    the aim of learning about filters that operate over datasets. The pooling strategy
    is then introduced to show how such changes can improve the training and performance
    of a model. The chapter concludes by showing how to visualize the filters learned.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了卷积神经网络，从卷积操作开始，逐步介绍卷积操作的集成层，目的是学习在数据集上操作的过滤器。接着介绍了池化策略，展示了这些变化如何提高模型的训练和性能。最后，展示了如何可视化学习到的过滤器。
- en: By the end of this chapter, you will be familiar with the motivation behind
    convolutional neural networks and will know how the convolution operation works
    in one and two dimensions. When you finish this chapter, you will know how to
    implement convolution in layers so as to learn filters through gradient descent.
    Finally, you will have a chance to use many tools that you learned previously,
    including dropout and batch normalization, but now you will know how to use pooling
    as an alternative to reduce the dimensionality of the problem and create levels
    of information abstraction.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将熟悉卷积神经网络背后的动机，并且知道卷积操作是如何在一维和二维中工作的。完成本章后，你将知道如何在层中实现卷积，以通过梯度下降学习过滤器。最后，你将有机会使用之前学过的许多工具，包括dropout和批量归一化，但现在你将知道如何使用池化作为减少问题维度并创建信息抽象层次的替代方法。
- en: 'This chapter is organized as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的结构如下：
- en: Introduction to convolutional neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络简介
- en: Convolution in *n*-dimensions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n*维度的卷积'
- en: Convolutional layers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层
- en: Pooling strategies
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化策略
- en: Visualization of filters
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤器的可视化
- en: Introduction to convolutional neural networks
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络简介
- en: 'Previously, in [Chapter 11](03e9a734-fb56-485d-ae90-66fb98ecd4d1.xhtml), *Deep
    and Wide Neural Networks*, we used a dataset that was very challenging for a general-purpose
    network. However, **convolutional neural networks** (**CNNs**) will prove to be
    more effective, as you will see. CNNs have been around since the late 80s (LeCun,
    Y., et al. (1989)). They have transformed the world of computer vision and audio
    processing (Li, Y. D., et al. (2016)). If you have some kind of AI-based object
    recognition capability in your smartphone, chances are it is using some kind of
    CNN architecture; for example:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第11章](03e9a734-fb56-485d-ae90-66fb98ecd4d1.xhtml)《深度和广度神经网络》中，我们使用了一个对通用网络非常具有挑战性的数据集。然而，**卷积神经网络**（**CNNs**）将证明更加有效，正如你将看到的那样。CNNs自80年代末以来就已经存在（LeCun,
    Y., 等人（1989））。它们已经改变了计算机视觉和音频处理的世界（Li, Y. D., 等人（2016））。如果你的智能手机有某种基于AI的物体识别功能，很可能它使用了某种CNN架构，例如：
- en: The recognition of objects in images
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像中的物体识别
- en: The recognition of a digital fingerprint
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字指纹的识别
- en: The recognition of voice commands
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音命令的识别
- en: 'CNNs are interesting because they have solved some of the most challenging
    problems in computer vision, including beating a human being at an image recognition
    problem called ImageNet (Krizhevsky, A., et al. (2012)*)*. If you can think of
    the most complex object recognition tasks, CNNs should be your first choice for
    experimentation: they will never disappoint!'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs之所以有趣，是因为它们解决了一些计算机视觉中最具挑战性的问题，包括在一个叫做ImageNet的图像识别问题上击败人类（Krizhevsky, A.,
    等人（2012））。如果你能想到最复杂的物体识别任务，CNNs应该是你实验的首选：它们永远不会让你失望！
- en: The key to the success of CNNs is their unique ability to **encode spatial relationships**.
    If we contrast two different datasets, one about student school records that includes
    current and past grades, attendance, online activity, and so on, and a second
    dataset about images of cats and dogs, if we aim to classify students or cats
    and dogs, the data is different. In one we have student features that have no
    spatial relationships.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: CNN成功的关键在于它们独特的**编码空间关系**的能力。如果我们对比两个不同的数据集，一个是关于学生的学校记录，包括当前和过去的成绩、出勤、在线活动等，另一个是关于猫和狗的图像数据集。如果我们的目标是对学生或猫和狗进行分类，这些数据是不同的。在一个数据集中，我们有学生特征，但这些特征没有空间关系。
- en: For example, if grades are the first feature, attendance does not have to be
    next to it, so their positions can be interchanged and the classification performance
    should not be affected, right? However, with images of cats and dogs, features
    (pixels) of eyes have to be adjacent to a nose or an ear; when you change the
    spatial features and observe an ear in the middle of two eyes (strange), the performance
    of the classifier should be affected because there is usually no cat or dog that
    has an ear in between its eyes. This is the type of spatial relationship that
    CNNs are good at encoding. You can also think of audio or speech processing. You
    know that some sounds must come after others in certain words. If the dataset
    allows for spatial relationships, CNNs have the potential to perform well.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果成绩是第一个特征，出勤率并不需要紧跟其后，因此它们的位置可以互换，而不会影响分类性能，对吗？然而，对于猫和狗的图像，眼睛的特征（像素）必须紧邻鼻子或耳朵；如果你改变空间特征并在两只眼睛中间看到一个耳朵（很奇怪），分类器的性能应该会受到影响，因为通常没有猫或狗的眼睛中间有耳朵。这就是CNN擅长编码的空间关系类型。你也可以考虑音频或语音处理。你知道某些声音在特定单词中必须在其他声音之后出现。如果数据集允许空间关系，CNN有潜力表现得很好。
- en: Convolution in n-dimensions
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: n维卷积
- en: The name of CNNs comes from their signature operation: **convolution**. This
    operation is a mathematical operation that is very common in the signal processing
    area. Let's go ahead and discuss the convolution operation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的名称来源于它们的标志性操作：**卷积**。这是一种在信号处理领域非常常见的数学运算。接下来，我们来讨论一下卷积操作。
- en: 1-dimension
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一维卷积
- en: 'Let''s start with the discrete-time convolution function in one dimension.
    Suppose that we have input data, ![](img/42ad14d7-4801-41de-8544-14d064f7699d.png),
    and some weights, ![](img/e36d108f-f5b2-4205-bfb8-f85808f76dcd.png), we can define
    the discrete-time convolution operation between the two as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一维离散时间卷积函数开始。假设我们有输入数据！[](img/42ad14d7-4801-41de-8544-14d064f7699d.png)和一些权重！[](img/e36d108f-f5b2-4205-bfb8-f85808f76dcd.png)，我们可以定义这两个之间的离散时间卷积操作如下：
- en: '![](img/e5873a07-cbe5-4f7c-ba38-1088178ab472.png).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/e5873a07-cbe5-4f7c-ba38-1088178ab472.png)。'
- en: In this equation, the convolution operation is denoted by a ***** symbol. Without
    complicating things too much, we can say that ![](img/8f014c06-f6a8-402e-9f00-0e79616523e0.png)
    is inverted, ![](img/a2dbdcc5-92fb-4538-b80d-949e4edb4024.png), and then shifted, ![](img/3cfe2848-09e8-4fb0-9069-e4c711729d34.png).
    The resulting vector is ![](img/781cc345-61b4-4a24-936a-8aeba31cd79c.png), which
    can be interpreted as the *filtered* version of the input when the filter ![](img/4dea30d8-7115-4bcc-8634-64707a585ecd.png)
    is applied.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，卷积操作用*****符号表示。为了不让事情变得过于复杂，我们可以说！[](img/8f014c06-f6a8-402e-9f00-0e79616523e0.png)是反转的，！[](img/a2dbdcc5-92fb-4538-b80d-949e4edb4024.png)，然后是平移的，！[](img/3cfe2848-09e8-4fb0-9069-e4c711729d34.png)。得到的结果是！[](img/781cc345-61b4-4a24-936a-8aeba31cd79c.png)，它可以被解释为应用滤波器！[](img/4dea30d8-7115-4bcc-8634-64707a585ecd.png)后输入的*过滤*版本。
- en: If we define the two vectors as follows, ![](img/667d186e-3d70-423b-a31b-05a9832f428a.png) and ![](img/04ea475a-0074-4c06-b144-ed21e87c8651.png),
    then the convolution operation yields ![](img/45c8af6e-5ee5-494c-8f9c-033d812a2478.png).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将两个向量定义如下，！[](img/667d186e-3d70-423b-a31b-05a9832f428a.png)和！[](img/04ea475a-0074-4c06-b144-ed21e87c8651.png)，那么卷积操作将得到！[](img/45c8af6e-5ee5-494c-8f9c-033d812a2478.png)。
- en: '*Figure 12.1* shows every single step involved in obtaining this result by
    inverting and shifting the filter and multiplying across the input data:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*图12.1*展示了通过反转和平移滤波器并在输入数据上进行相乘来获得此结果的每个步骤：'
- en: '![](img/54f721f1-4fd2-497f-ae21-6733dc208006.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/54f721f1-4fd2-497f-ae21-6733dc208006.png)'
- en: Figure 12.1 - Example of a convolution operation involving two vectors
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 - 涉及两个向量的卷积操作示例
- en: 'In NumPy, we can achieve this by using the `convolve()` method as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在NumPy中，我们可以通过使用`convolve()`方法来实现这一点，代码如下：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This outputs the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下结果：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, if you think about it, the most "complete" information is when the filter
    fully overlaps with the input data, and that is for ![](img/1c903d14-4aa7-4725-8ac5-12b0e536298d.png).
    In Python, you can get that by using the `''valid''` argument as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你想一下，最“完整”的信息是当滤波器完全与输入数据重叠时，这对于！[](img/1c903d14-4aa7-4725-8ac5-12b0e536298d.png)是成立的。在Python中，你可以通过使用`'valid'`参数来得到这个效果，代码如下：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This simply gives the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出以下结果：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once again, this is only to maximize the *relevant* information because the
    convolution operation is more *uncertain* around the edges of the vector, that
    is, at the beginning and the end where the vectors do not fully overlap. Furthermore,
    for convenience, we could obtain an output vector of the same size as the input
    by using the `''same''` argument as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这只是为了最大化*相关*信息，因为卷积操作在向量的边缘，即向量开始和结束时，不完全重叠，因此不确定性更高。此外，为了方便，我们可以通过使用`'same'`参数，获得与输入相同大小的输出向量，方法如下：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This prints the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出如下内容：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here are some practical reasons for each of the three ways of using convolution:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用卷积的三种方式的实际原因：
- en: Use `'valid'` when you need all the *good *information without any of the noise
    caused by the partial overlaps of the filter.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要所有*有效*信息而不包含由于滤波器部分重叠所引起的噪声时，请使用`'valid'`。
- en: Use `'same'` when you want to make it easier for the computations to work. This
    will make it easy in the sense that you will have the same dimensions in the input
    and the output.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你希望计算更加简单时，请使用`'same'`。这将使得输入和输出的维度保持一致，计算也会更为方便。
- en: Otherwise, use nothing to obtain the full analytical solution to the convolution
    operation for any purposes that you want.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，可以不使用任何方法来获得卷积操作的完整解析解，以满足您的任何需求。
- en: Convolution became very popular with the surge of microprocessors specialized
    in multiplying and adding numbers extremely quickly and with the development of
    the **fast Fourier transform** (**FFT**) algorithm. The FFT exploits the mathematical
    property that convolution in the discrete time domain is equivalent to multiplication
    in the Fourier domain and vice versa.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积随着微处理器的发展而变得非常流行，这些微处理器专门用于极快地进行乘法和加法运算，同时随着**快速傅里叶变换**（**FFT**）算法的发展，卷积的应用也变得广泛。FFT利用了一个数学性质，即离散时间域中的卷积等价于傅里叶域中的乘法，反之亦然。
- en: Now, let's move on to the next dimension.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续讨论下一个维度。
- en: 2-dimensions
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2维
- en: A two-dimensional convolution is very similar to the one-dimensional convolution.
    However, rather than having a vector, we will have a matrix, and that's why images
    are directly applicable here.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 二维卷积与一维卷积非常相似。然而，我们将拥有一个矩阵而不是一个向量，这也是图像可以直接应用的原因。
- en: 'Let''s say that we have two matrices: one represents some input data, and the
    other is a filter, like so:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个矩阵：一个表示输入数据，另一个是滤波器，如下所示：
- en: '![](img/747990d4-5b12-4a09-a25d-26fb3ac8571f.png).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/747990d4-5b12-4a09-a25d-26fb3ac8571f.png)。'
- en: 'We can calculate the two-dimensional discrete convolution by inverting (in
    both dimensions) and shifting (also in both dimensions) the filter. The equation
    is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过反转（在两个维度上）和移动（同样在两个维度上）滤波器来计算二维离散卷积。其方程如下：
- en: '![](img/6e04a69a-26bc-4b1a-b54b-76a0d621c719.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e04a69a-26bc-4b1a-b54b-76a0d621c719.png)'
- en: 'This is very similar to the one-dimensional version. The following diagram
    illustrates the first two steps and the last one, to save space and avoid repetition:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这与一维版本非常相似。下图展示了前两步和最后一步，为了节省空间并避免重复：
- en: '![](img/e1f06f2e-de3f-47be-8e56-57bf9822d95d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1f06f2e-de3f-47be-8e56-57bf9822d95d.png)'
- en: Figure 12.2 - Two-dimensional discrete convolution example
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 - 二维离散卷积示例
- en: 'In Python, we can calculate the two-dimensional convolution using SciPy''s
    `convolve2d` method, as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，我们可以使用SciPy的`convolve2d`方法来计算二维卷积，方法如下：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This outputs the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出如下内容：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The results shown here are the full analytical result. However, similar to
    the one-dimensional implementation, if you only want results that fully overlap,
    you can invoke a `''valid''` result, or if you want a result of the same size
    as the input, you can invoke the `''same''` alternative as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示的结果是完整的解析结果。然而，与一维实现类似，如果您只想要完全重叠的结果，可以调用`'valid'`结果，或者如果您想要与输入大小相同的结果，可以调用`'same'`选项，如下所示：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This would yield the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到如下结果：
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now, let's move on to n-dimensional convolutions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续讨论n维卷积。
- en: n-dimensions
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: n维
- en: 'Once you have understood convolution in one and two dimensions, you have understood
    the basic concept behind it. However, you might still need to perform convolutions
    in larger dimensions, for example, in multispectral datasets. For this, we can
    simply prepare NumPy arrays of any number of  dimensions and then use SciPy''s `convolve()`
    functionality. Consider the following example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了一维和二维卷积，你就掌握了背后的基本概念。然而，你可能仍然需要在更高维度上执行卷积，例如，在多光谱数据集中。为此，我们可以简单地准备任意维度的
    NumPy 数组，然后使用 SciPy 的 `convolve()` 功能。考虑以下示例：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here, vectors ![](img/a239161e-8542-499f-bb20-3ad3a3fd22ca.png) are three-dimensional
    arrays, and can be convolved successfully, producing the following output:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，向量 ![](img/a239161e-8542-499f-bb20-3ad3a3fd22ca.png) 是三维数组，可以成功地进行卷积，产生如下输出：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The only difficult part about n-dimensional convolutions could be visualizing
    them or imagining them in your mind. We humans can easily understand one, two,
    and three dimensions, but larger dimensional spaces are tricky to illustrate.
    But remember, if you understand how convolution works in one and two dimensions,
    you can trust that the math works and the algorithms work in any dimensions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: n维卷积的唯一困难可能是将其可视化或在脑海中想象它们。我们人类可以轻松理解一维、二维和三维，但更高维度的空间很难表示。但请记住，如果你理解了在一维和二维中如何进行卷积，你可以相信数学原理和算法在任何维度中都会有效。
- en: Next, let's look at how to *learn* such convolutional filters by defining Keras
    layers and adding them to a model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看一下如何通过定义 Keras 层并将其添加到模型中来 *学习* 这些卷积滤波器。
- en: Convolutional layers
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: 'Convolution has a number of properties that are very interesting in the field
    of deep learning:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积在深度学习领域具有一些非常有趣的特性：
- en: It can successfully encode and decode spatial properties of the data.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以成功地对数据的空间属性进行编码和解码。
- en: It can be calculated relatively quickly with the latest developments.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以通过最新的技术快速计算。
- en: It can be used to address several computer vision problems.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以用于解决多个计算机视觉问题。
- en: It can be combined with other types of layers for maximum performance.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以与其他类型的层结合以达到最佳性能。
- en: 'Keras has wrapper functions for TensorFlow that involve the most popular dimensions,
    that is, one, two, and three dimensions: `Conv1D`, `Conv2D`, and `Conv3D`. In
    this chapter, we will continue to focus on two-dimensional convolutions, but be
    sure that if you have understood the concept, you can easily go ahead and use
    the others.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 为 TensorFlow 提供了封装函数，涉及最常见的维度，即一维、二维和三维：`Conv1D`、`Conv2D` 和 `Conv3D`。在本章中，我们将继续聚焦于二维卷积，但只要你理解了这一概念，你可以轻松地使用其他类型的卷积。
- en: Conv2D
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Conv2D
- en: 'The two-dimensional convolution method has the following signature: `tensorflow.keras.layers.Conv2D`.
    The most common arguments used in a convolutional layer are the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 二维卷积方法的签名如下：`tensorflow.keras.layers.Conv2D`。卷积层中最常用的参数如下：
- en: '`filters` refers to the number of filters to be learned in this particular
    layer and affects the dimension of the output of the layer.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filters` 指的是在该特定层中需要学习的滤波器数量，并且影响该层输出的维度。'
- en: '`kernel_size` refers to the size of the filters; for example, in the case of
    *Figure 12.2*, it would be size (3,3).'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_size` 指的是滤波器的大小；例如，在 *图 12.2* 中，它的大小为 (3,3)。'
- en: '`strides=(1, 1)` is new for us. Strides is defined as the size of the steps
    that are taken when the filters are sliding across the input. All the examples
    we have shown so far assume that we follow the original definition of convolution
    and take unit steps. However, in convolutional layers, you can take larger steps,
    which will lead to smaller outputs but also the loss of information.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strides=(1, 1)` 对我们来说是新的。步幅（strides）定义为滤波器滑过输入时的步伐大小。我们迄今为止展示的所有示例都假设我们遵循卷积的原始定义，采用单位步幅。然而，在卷积层中，你可以选择更大的步幅，这会导致较小的输出，但也会丢失信息。'
- en: '`padding=''valid''` refers to the way of dealing with the information in the
    edges of the convolution result. Note that the options here are only `''valid''`
    or `''same''`, and that there is no way of obtaining the full analytical result.
    The meaning is the same as we have seen before in this chapter.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding=''valid''` 指的是处理卷积结果边缘信息的方式。请注意，这里的选项只有 `''valid''` 或 `''same''`，并且无法获得完整的解析结果。其含义与本章前面提到的相同。'
- en: '`activation=None` gives the option to include an activation function in the
    layer if you need one; for example, `activation=''relu''`.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation=None` 提供了一个选项，可以在层中包括一个激活函数，如果需要的话；例如，`activation=''relu''`。'
- en: 'To exemplify this, consider a convolutional layer such as the one shown in
    the following diagram, where the first layer is convolutional (in 2D) with 64
    filters of size 9x9 and a stride of 2, 2 (that is, two in each direction). We
    will explain the rest of the model in the following diagram as we proceed:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明这一点，考虑一个如以下图所示的卷积层，其中第一层是二维卷积层，包含 64 个 9x9 的滤波器，步长为 2, 2（即每个方向两个）。我们将在接下来的图示中继续解释模型的其余部分：
- en: '![](img/0025a4ec-aba0-4f83-9a6c-ce8f45623b47.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0025a4ec-aba0-4f83-9a6c-ce8f45623b47.png)'
- en: Figure 12.3 - Architecture of a convolutional neural network for CIFAR 10
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.3 - 用于 CIFAR 10 的卷积神经网络架构
- en: 'The first convolutional layer in the diagram can be defined as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的第一个卷积层可以定义如下：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This essentially will create a convolutional layer with the given specifications.
    The print statement will effectively produce the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上将创建一个具有给定规格的卷积层。打印语句将有效地产生以下内容：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If you do the math, each and every single filter out of the 64 will produce
    a 23x23 `'valid'` output, but since a (2,2) stride is being used, an 11.5x11.5
    output should be obtained. However, since we cannot have fractions, TensorFlow
    will round up to 12x12\. Therefore, we end up with the preceding shape as the
    output.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你做一下计算，64 个滤波器中的每一个都会产生一个 23x23 的 `'valid'` 输出，但由于使用了 (2,2) 的步长，应该得到一个 11.5x11.5
    的输出。然而，由于我们不能有小数，TensorFlow 会将其四舍五入到 12x12。因此，我们最终得到上面的输出形状。
- en: The layer+activation combo
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层+激活组合
- en: As mentioned previously, the `Conv2D` class has the ability to include an activation
    function of your choice. This is much appreciated because it will save some lines
    of code for all who want to learn to code efficiently. However, we have to be
    careful not to forget to document somewhere the type of activation used.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`Conv2D` 类具有包括你选择的激活函数的能力。这是非常受欢迎的，因为它可以节省一些代码行，帮助那些希望高效编写代码的人。然而，我们必须小心，不能忘记在某处记录使用的激活类型。
- en: '*Figure 12.3* shows the activation in a separate block. This is a good idea
    to keep track of what activations are used throughout. The most common activation
    function for a convolutional layer is a ReLU, or any of the activations of the
    ReLU family, for example, leaky ReLU and ELU. The next *new *element is a pooling
    layer. Let''s talk about this.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12.3* 显示了一个单独块中的激活。这是一个很好的方法，可以跟踪整个过程中的激活使用情况。卷积层最常见的激活函数是 ReLU，或者是 ReLU
    家族中的任何激活函数，例如，leaky ReLU 和 ELU。下一个 *新* 元素是池化层。让我们来谈谈这个。'
- en: Pooling strategies
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化策略
- en: 'You will usually find pooling accompanying convolutional layers. Pooling is
    an idea that is intended to reduce the number of computations by reducing the
    dimensionality of the problem. We have a few pooling strategies available to us
    in Keras, but the most important and popular ones are the following two:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会发现池化层伴随卷积层出现。池化是一种旨在通过降低问题的维度来减少计算量的理念。在 Keras 中，我们有几种池化策略可供选择，但最重要和最常用的两种策略是以下两种：
- en: AveragePooling2D
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AveragePooling2D
- en: MaxPooling2D
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MaxPooling2D
- en: 'These also exist for other dimensions, such as 1D. However, in order to understand
    pooling, we can simply look at the example in the following diagram:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这些池化操作也存在于其他维度中，如 1D。然而，为了理解池化，我们可以简单地查看以下图示中的示例：
- en: '![](img/d6c68d88-284b-460f-abb6-48b69dfe190c.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d6c68d88-284b-460f-abb6-48b69dfe190c.png)'
- en: Figure 12.4 - Max pooling example in 2D
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4 - 2D 最大池化示例
- en: In the diagram, you can observe how max pooling would look at individual 2x2
    squares moving two spaces at a time, which leads to a 2x2 result. The whole point
    of pooling is to **find a smaller summary of the data** in question. When it comes
    to neural networks, we often look at neurons that are *excited* the most, and
    so it makes sense to look at the maximum values as good representatives of larger
    portions of data. However, remember that you can also look at the average of the
    data (`AveragePooling2D`), which is also good in all senses.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在图示中，你可以看到最大池化如何在每个 2x2 的小块上移动，每次移动两个位置，从而得出一个 2x2 的结果。池化的全部目的在于 **找到数据的一个更小的总结**。在神经网络中，我们通常关注最被
    *激活* 的神经元，因此查看最大值作为更大数据部分的代表是有意义的。然而，请记住，你也可以查看数据的平均值（`AveragePooling2D`），它在各个方面也都是有效的。
- en: There is a slight difference in time performance in favor of max pooling, but
    this is very small.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间性能上，最大池化略占优势，但这一差异非常小。
- en: 'In Keras, we can implement pooling very easily. In the case of max pooling
    in 2D, for example, we can simply do the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在Keras中，我们可以非常轻松地实现池化。例如，对于2D的最大池化，我们可以简单地做如下操作：
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This produces the same output as in *Figure 12.4*:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成与*图12.4*相同的输出：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can also do the same for average pooling as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以对平均池化做同样的操作，如下所示：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This gives the following output:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Both pooling strategies work perfectly fine in terms of summarizing the data.
    You will be safe in choosing either one.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 两种池化策略在总结数据方面都非常有效。你可以放心选择任何一种。
- en: Now for the big reveal. We will put all of this together in a CNN next.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是大揭晓时刻。接下来，我们将在CNN中将所有这些内容结合起来。
- en: Convolutional neural network for CIFAR-10
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CIFAR-10的卷积神经网络
- en: 'We have reached the point where we can actually implement a fully functional
    CNN after looking at the individual pieces: understanding the convolution operation,
    understanding pooling, and understanding how to implement convolutional layers
    and pooling. Now we will be implementing the CNN architecture shown in *Figure
    12.3*.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经达到了可以实际实现一个功能完备的CNN的阶段，经过对各个组成部分的了解：理解卷积操作，理解池化操作，理解如何实现卷积层和池化层。现在，我们将实现*图12.3*中展示的CNN架构。
- en: Implementation
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: We will be implementing the network in *Figure 12.3* step by step, broken down
    into sub-sections.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一步一步地实现*图12.3*中的网络，分解成子部分。
- en: Loading data
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Let''s load the CIFAR-10 dataset as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按如下方式加载CIFAR-10数据集：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This should effectively load the dataset and print its shape, which is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该有效地加载数据集并打印出其形状，如下所示：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This is very straightforward, but we can go further and verify that the data
    is loaded correctly by loading and plotting the first image of every class in
    the `x_train` set as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常直接，但我们可以进一步验证数据是否正确加载，通过加载并绘制`x_train`集合中每个类别的第一张图片，如下所示：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This will produce the output shown in the following screenshot:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成如下截图所示的输出：
- en: '![](img/3031d060-a19c-492f-91ca-df7a029dffb0.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3031d060-a19c-492f-91ca-df7a029dffb0.png)'
- en: Figure 12.5 - Samples of CIFAR-10
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 - CIFAR-10样本
- en: Next, we will implement the layers of the network.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将实现网络的各个层。
- en: Compiling the model
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译模型
- en: 'Again, recall the model in *Figure 12.3*, and how we can implement it as shown
    here. Everything you are about to see is something we have looked at in this and
    previous chapters:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回想一下*图12.3*中的模型，以及我们如何像这样实现它。接下来你将看到的所有内容，都是我们在这一章和之前的章节中讨论过的：
- en: '[PRE21]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We continue adding more convolutional layers like so:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续添加更多的卷积层，如下所示：
- en: '[PRE22]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then we can compile the model and print a summary as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以编译模型并打印出总结，如下所示：
- en: '[PRE23]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This will output a summary of the network that will look like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出一个网络总结，内容如下所示：
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: One thing that must be very obvious to you at this point is the number of parameters
    of this network. If you recall from the previous chapter, you will be surprised
    that this network has nearly a quarter of a million parameters, while the wide
    or deep network had a few million parameters. Furthermore, you will see shortly
    that this relatively small network, while still *overparameterized*, is going
    to perform better than the networks in the previous chapter that had more parameters.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，有一件事应该对你非常明显，那就是这个网络的参数数量。如果你回忆一下前一章，你会惊讶地发现这个网络有近25万个参数，而宽或深的网络有几百万个参数。此外，你会很快看到，尽管这个相对较小的网络仍然是*过度参数化的*，它的表现将比前一章中那些有更多参数的网络要好。
- en: Next, let's train the network.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们训练网络。
- en: Training the CNN
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练CNN
- en: We can train the CNN using the *callbacks* that we studied in [Chapter 11](03e9a734-fb56-485d-ae90-66fb98ecd4d1.xhtml), *Deep
    and Wide Neural Networks*, to stop the network early if there is no progress,
    and to reduce the learning rate to focus the efforts of the gradient descent algorithm
    if it reaches a *plateau*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用我们在[第11章](03e9a734-fb56-485d-ae90-66fb98ecd4d1.xhtml)《深度与宽度神经网络》中学习过的*回调函数*来训练CNN，如果网络没有进展，提前停止训练，或者如果达到*平台期*，通过降低学习率来集中梯度下降算法的努力。
- en: 'We will train it as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按如下方式训练它：
- en: '[PRE25]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The results of this will vary from computer to computer. For example, it may
    take fewer or more epochs, or the gradient might take a different direction if
    the mini-batches (which are selected at random) contain several edge cases. However,
    for the most part, you should get a similar result to this:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果会因计算机而异。例如，可能需要更多或更少的训练轮次，或者梯度的方向可能会有所不同，如果小批量（随机选择的）包含多个边缘案例。然而，大多数情况下，你应该得到一个与此类似的结果：
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: At this point, when the training is finished, you can get an estimate of the
    accuracy of 83.15%. Be careful, this is not a **balanced** accuracy. For that,
    we will take a look at the **Balanced Error Rate** (**BER**) metric in the next
    section. But before we do that, we can look at the training curve to see how the
    loss was minimized.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，训练完成后，你可以得到约83.15%的准确率估算值。请注意，这并不是**平衡**准确率。为此，我们将在下一节中查看**平衡误差率**（**BER**）指标。但在那之前，我们可以看看训练曲线，看看损失是如何被最小化的。
- en: 'The following code will produce what we want:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将生成我们所需的结果：
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This gives the plot shown in *Figure 12.6*:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成如下所示的图像，见*图12.6*：
- en: '![](img/cbf15643-e4bd-451a-86c6-1d71011cb5c4.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cbf15643-e4bd-451a-86c6-1d71011cb5c4.png)'
- en: Figure 12.6 - Loss minimization for a CNN on CIFAR-10
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 - CIFAR-10上的CNN损失最小化
- en: From this diagram, you can appreciate the bumps that the learning curve has,
    particularly visible on the training set curve, which are due to the reduction
    in the learning rate through the callback function, `ReduceLROnPlateau`. The training
    stops after the loss no longer improves on the test set, thanks to the `EarlyStopping`
    callback.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图表中，你可以看到学习曲线上的波动，尤其是在训练集的曲线中比较明显，这些波动是由于通过回调函数`ReduceLROnPlateau`减少学习率所致。当测试集的损失不再改善时，训练将停止，这得益于`EarlyStopping`回调。
- en: Results
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: 'Now, let''s look at objective, numerical results:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看客观的数值结果：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This will give us the following numerical results, which we can compare with
    the results from the previous chapter:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下的数值结果，我们可以将其与上一章的结果进行比较：
- en: '[PRE29]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Accuracy for specific classes can be as high as 87%, while the lowest accuracy
    is 66%. This is much better than the previous models in the previous chapter.
    The BER is of 0.2288, which can all be interpreted as a balanced accuracy of 77.12%.
    This matches the accuracy reported in the test set during training, which indicates
    that the model was trained properly. For comparison purposes, the following diagram
    shows a visual representation of the confusion matrix:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 特定类别的准确率最高可达87%，而最低准确率为66%。这比上一章中的模型要好得多。BER为0.2288，所有这些可以解读为77.12%的平衡准确率。这与训练过程中测试集上报告的准确率相符，表明模型已正确训练。为了进行对比，以下图表展示了混淆矩阵的可视化表示：
- en: '![](img/db92150e-3920-4e15-b975-40e7e6f287f7.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db92150e-3920-4e15-b975-40e7e6f287f7.png)'
- en: Figure 12.7 - Confusion matrix for a CNN trained over CIFAR-10
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 - 在CIFAR-10上训练的CNN的混淆矩阵
- en: It might be a bit clearer from the visual confusion matrix that classes 3 and
    5 can be confused between themselves more than other classes. Classes 3 and 5
    correspond to cats and dogs, respectively.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉混淆矩阵中可以更清楚地看出，类别3和5之间的混淆程度比其他类别更高。类别3和5分别对应猫和狗。
- en: 'That''s it. As you can see, this is a nice result already, but you could perform
    more experiments on your own. You can edit and add more convolutional layers to
    your model and make it better. If you are curious, there are other larger CNNs
    that have been very successful. Here are the two most famous ones:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。如你所见，这已经是一个不错的结果，但你可以自己进行更多实验。你可以编辑并添加更多卷积层来改进模型。如果你有兴趣，还有其他更大的CNN模型也取得了很大成功。以下是最著名的两个：
- en: 'VGG-19: This contains 12 convolutional layers and 3 dense layers (Simonyan,
    K., et al. (2014)).'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VGG-19：该模型包含12个卷积层和3个全连接层（Simonyan, K., 等人 (2014)）。
- en: 'ResNet: This contains 110 convolutional layers and 1 dense layer (He, K., et
    al. (2016)). This particular configuration can achieve an error rate as low as
    6.61% (±0.16%) on CIFAR-10.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ResNet：该模型包含110个卷积层和1个全连接层（He, K., 等人 (2016)）。该配置在CIFAR-10数据集上能够达到6.61%（±0.16%）的最低错误率。
- en: Let's discuss next how to visualize the filters learned.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们来讨论如何可视化学习到的滤波器。
- en: Visualization of filters
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滤波器可视化
- en: This last piece in this chapter deals with the visualization of the learned
    filters. This may be useful to you if you want to do research on what the network
    is learning. It may help with the *explainability *of the network. However, note
    that the deeper the network is, the more complicated it gets to understand it.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后一部分处理了学习到的滤波器的可视化。如果你想研究网络学到了什么，这可能对你有用。这有助于提升网络的*可解释性*。然而，请注意，网络越深，理解它就越复杂。
- en: 'The following code will help you visualize the filters of the first convolutional
    layer of the network:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将帮助你可视化网络的第一个卷积层的滤波器：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This code depends heavily on knowing which layer you want to visualize, the
    number of filters you want to visualize, and the size of the filters themselves.
    In this case, we want to visualize the first convolutional layer. It has 64 filters
    (displayed in an 8x8 grid), and each filter is 9x9x3 because the input is color
    images. *Figure 12.8* shows the resulting plot of the code shown previously:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在很大程度上依赖于你知道想要可视化的层、想要可视化的滤波器数量以及滤波器本身的大小。在这种情况下，我们要可视化第一个卷积层。它有64个滤波器（以8x8的网格显示），每个滤波器的大小为9x9x3，因为输入的是彩色图像。*图12.8*显示了前面代码生成的结果图：
- en: '![](img/f37fe0c8-877d-4ae1-8d94-b468a47f6295.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f37fe0c8-877d-4ae1-8d94-b468a47f6295.png)'
- en: Figure 12.8 - Filters learned in the first convolutional layer
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 - 第一个卷积层中学习到的滤波器
- en: If you are an expert in image processing, you may recognize some of these patterns
    as they resemble Gabor filters (Jain, A. K., et al. (1991)). Some of these filters
    are designed to look for edges, textures, or specific shapes. The literature suggests
    that in convolutional networks, deeper layers usually encode highly complex information,
    while the first layers are used to detect features such as edges.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是图像处理专家，你可能会认出其中一些模式，它们类似于Gabor滤波器（Jain, A. K., 等人（1991））。其中一些滤波器旨在寻找边缘、纹理或特定的形状。文献表明，在卷积网络中，较深的层通常编码高度复杂的信息，而第一层用于检测边缘等特征。
- en: Feel free to go ahead and try to display another layer by making the necessary
    modifications.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 随时可以继续前进，尝试通过进行必要的修改来展示另一个层。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This intermediate chapter showed how to create CNNs. You learned about the convolution
    operation, which is the fundamental concept behind them. You also learned how
    to create convolutional layers and aggregated pooling strategies. You designed
    a network to learn filters to recognize objects based on CIFAR-10 and learned
    how to display the learned filters.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 本中级章节展示了如何创建卷积神经网络（CNN）。你了解了卷积操作，这是其基本概念。你还学习了如何创建卷积层和聚合池化策略。你设计了一个网络，通过学习滤波器来识别CIFAR-10中的物体，并学习了如何展示已学习的滤波器。
- en: At this point, you should feel confident explaining the motivation behind convolutional
    neural networks rooted in computer vision and signal processing. You should feel
    comfortable coding the convolution operation in one and two dimensions using NumPy,
    SciPy, and Keras/TensorFlow. Furthermore, you should feel confident implementing
    convolution operations in layers and learning filters through gradient descent
    techniques. If you are asked to show what the network has learned, you should
    feel prepared to implement a simple visualization method to display the filters
    learned.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，你应该能自信地解释卷积神经网络背后的动机，这些动机根植于计算机视觉和信号处理领域。你应该能够使用NumPy、SciPy和Keras/TensorFlow来编写一维和二维卷积操作的代码。此外，你应该能够自信地在层中实现卷积操作，并通过梯度下降技术学习滤波器。如果有人要求你展示网络所学到的内容，你应该能准备好实现一个简单的可视化方法来展示学到的滤波器。
- en: CNNs are great at encoding highly correlated spatial information, such as images,
    audio, or text. However, there is an interesting type of network that is meant
    to encode information that is sequential in nature. [Chapter 13](a6e892c5-e890-4c0a-ad92-c5442328a64a.xhtml), *Recurrent
    Neural Networks*, will present the most fundamental concepts of recurrent networks,
    leading to long short-term memory models. We will explore multiple variants of
    sequential models with applications in image classification and natural language
    processing.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: CNN擅长编码高度相关的空间信息，如图像、音频或文本。然而，还有一种有趣的网络类型，旨在编码顺序性的信息。[第13章](a6e892c5-e890-4c0a-ad92-c5442328a64a.xhtml)，*递归神经网络*，将介绍递归网络的最基本概念，进而引入长短期记忆模型。我们将探索多种顺序模型的变体，并应用于图像分类和自然语言处理。
- en: Questions and answers
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题与答案
- en: '**What data summarization strategy discussed in this chapter can reduce the
    dimensionality of a convolutional model?**'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**本章讨论的哪种数据总结策略可以减少卷积模型的维度？**'
- en: Pooling.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 池化。
- en: '**Does adding more convolutional layers make the network better? **'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**增加更多卷积层会让网络变得更好吗？**'
- en: Not always. It has been shown that more layers has a positive effect on networks,
    but there are certain occasions when there is no gain. You should determine the
    number of layers, filter sizes, and pooling experimentally.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 并非总是如此。研究表明，更多层数对网络有正面影响，但在某些情况下并没有提升效果。你应该通过实验来确定层数、滤波器大小和池化策略。
- en: '**What other applications are there for CNNs?**'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**卷积神经网络（CNN）还有哪些其他应用？**'
- en: Audio processing and classification; image denoising; image super-resolution;
    text summarization and other text-processing and classification tasks; the encryption
    of data.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 音频处理与分类；图像去噪；图像超分辨率；文本摘要及其他文本处理与分类任务；数据加密。
- en: References
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard,
    W., and Jackel, L. D. (1989). *Backpropagation applied to handwritten zip code
    recognition*. *Neural computation*, 1(4), 541-551.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard,
    W., 和 Jackel, L. D. (1989). *反向传播应用于手写邮政编码识别*. *神经计算*, 1(4), 541-551。
- en: Li, Y. D., Hao, Z. B., and Lei, H. (2016). *Survey of convolutional neural networks*.
    *Journal of Computer Applications*, 36(9), 2508-2515.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li, Y. D., Hao, Z. B., 和 Lei, H. (2016). *卷积神经网络综述*. *计算机应用杂志*, 36(9), 2508-2515。
- en: Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). *Imagenet classification
    with deep convolutional neural networks*. In *Advances in neural information processing
    systems* (pp. 1097-1105).
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky, A., Sutskever, I., 和 Hinton, G. E. (2012). *使用深度卷积神经网络进行Imagenet分类*.
    见 *神经信息处理系统进展*（第1097-1105页）。
- en: Simonyan, K., and Zisserman, A. (2014). *Very deep convolutional networks for
    large-scale image recognition*. arXiv preprint arXiv:1409.1556.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan, K., 和 Zisserman, A. (2014). *用于大规模图像识别的非常深的卷积网络*. arXiv预印本arXiv:1409.1556。
- en: He, K., Zhang, X., Ren, S., and Sun, J. (2016). *Deep residual learning for
    image recognition*. In *Proceedings of the IEEE conference on computer vision
    and pattern recognition* (pp. 770-778).
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He, K., Zhang, X., Ren, S., 和 Sun, J. (2016). *深度残差学习用于图像识别*. 见 *IEEE计算机视觉与模式识别大会论文集*（第770-778页）。
- en: Jain, A. K., and Farrokhnia, F. (1991). *Unsupervised texture segmentation using
    Gabor filters*. *Pattern recognition*, 24(12), 1167-1186.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jain, A. K., 和 Farrokhnia, F. (1991). *使用Gabor滤波器的无监督纹理分割*. *模式识别*, 24(12),
    1167-1186。
