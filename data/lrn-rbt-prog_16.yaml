- en: '*Chapter 13*: Robot Vision – Using a Pi Camera and OpenCV'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第13章*：机器人视觉 – 使用Pi摄像头和OpenCV'
- en: Giving a robot the ability to see things allows it to behave in ways to which
    humans relate well. Computer vision is still actively being researched, but some
    of the basics are already available for use in our code, with a Pi Camera and
    a little work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 给机器人赋予看到事物的能力，使其能够以人类能够理解的方式行事。计算机视觉仍在积极研究中，但一些基础知识已经可用于我们的代码中，使用Pi摄像头和一点工作即可。
- en: In this chapter, we will use the robot and camera to drive to objects and follow
    faces with our pan-and-tilt mechanism. We'll be using the PID algorithm some more
    and streaming camera output to a web page, giving you a way to see what your robot
    is seeing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用机器人和摄像头驱动到物体上，并使用我们的云台机构跟踪人脸。我们将再次使用PID算法，并将摄像头输出流式传输到网页上，这样你就可以看到你的机器人看到的内容。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Setting up the Raspberry Pi camera
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置树莓派摄像头
- en: Setting up computer vision software
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置计算机视觉软件
- en: Building a Raspberry Pi camera stream app
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建树莓派摄像头流应用程序
- en: Running background tasks when streaming
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在流媒体传输时运行后台任务
- en: Following colored objects with Python
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python跟踪彩色物体
- en: Tracking faces with Python
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python跟踪人脸
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要以下物品：
- en: The robot with the pan-and-tilt mechanism from [*Chapter 11*](B15660_11_Final_ASB_ePub.xhtml#_idTextAnchor219),
    *Programming Encoders with Python*.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自[*第11章*](B15660_11_Final_ASB_ePub.xhtml#_idTextAnchor219)，*使用Python编程编码器*的带有云台的机器人。
- en: Code for the robot up to [*Chapter 11*](B15660_11_Final_ASB_ePub.xhtml#_idTextAnchor219),
    *Programming Encoders with Python*, which you can download from GitHub at [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter11](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter11).
    We will be extending and modifying this for new functionality.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到[*第11章*](B15660_11_Final_ASB_ePub.xhtml#_idTextAnchor219)，*使用Python编程编码器*的机器人代码，您可以从GitHub上下载[https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter11](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter11)。我们将扩展和修改它以实现新的功能。
- en: A Raspberry Pi camera.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个树莓派摄像头。
- en: A 300 mm-long Pi Camera cable, as the cable included with the camera is too
    short. Be sure that the cable is not for a Pi Zero (which has different connectors).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一根300毫米长的Pi摄像头线，因为随摄像头附带的线太短了。确保该线不是为Pi Zero（它有不同连接器）准备的。
- en: Two M2 bolts and an M2 nut.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个M2螺栓和一个M2螺母。
- en: A small square of thin cardboard—a cereal box will do.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一小块薄薄的硬纸板——一个谷物箱就可以。
- en: A small jeweler's screwdriver.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一把小珠宝螺丝刀。
- en: A pencil.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一支铅笔。
- en: A kids' bowling set—the type with differently colored pins (plain, with no pictures).
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个儿童保龄球套装——带有不同颜色球柱（普通，没有图案）。
- en: A well-lit space for the robot to drive in.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个光线充足的区域，供机器人行驶。
- en: Internet access.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互联网接入。
- en: The code for this chapter is on GitHub, available at [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter13](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter13).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码在GitHub上，可在[https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter13](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter13)找到。
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/39xfDJ9](https://bit.ly/39xfDJ9)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际应用：[https://bit.ly/39xfDJ9](https://bit.ly/39xfDJ9)
- en: Setting up the Raspberry Pi camera
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置树莓派摄像头
- en: Before we can get into computer vision, we need to prepare the camera on your
    robot. There is hardware installation and software installation involved.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入计算机视觉之前，我们需要在你的机器人上准备摄像头。这涉及到硬件安装和软件安装。
- en: 'When we have completed this installation, our robot block diagram will look
    like *Figure 13.1*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此安装后，我们的机器人框图将看起来像*图13.1*：
- en: '![](img/B15660_13_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_01.jpg)'
- en: Figure 13.1 – Our robot block diagram with the camera added
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – 添加摄像头后的我们的机器人框图
- en: '*Figure 13.1* continues the block diagrams we have shown throughout the book,
    with the camera''s addition and its connection to the Raspberry Pi highlighted
    on the left.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.1*继续展示了我们在整本书中展示的框图，左侧突出了摄像头的添加及其与树莓派的连接。'
- en: We will first attach the camera to the pan-and-tilt assembly. We can then use
    a longer cable to wire the camera into the Pi. Let's start preparing the camera
    to be attached.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将相机连接到俯仰机构。然后我们可以使用更长的线缆将相机连接到Pi。让我们开始准备安装相机。
- en: Attaching the camera to the pan-and-tilt mechanism
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将相机连接到俯仰机构
- en: In [*Chapter 10*](B15660_10_Final_ASB_ePub.xhtml#_idTextAnchor192), *Using Python
    to Control Servo Motors*, you added a pan-and-tilt mechanism to your robot. You
    will mount the camera onto the front plate of this mechanism. There are brackets
    and kits, but they are not universally available. Feel free to use one of these
    if you can adapt it to the pan-and-tilt mechanism; if not, I have a few plans.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第10章*](B15660_10_Final_ASB_ePub.xhtml#_idTextAnchor192)中，*使用Python控制伺服电机*，你为你的机器人添加了一个俯仰机构。你将把相机安装到这个机构的正面板上。有支架和套件，但它们并不普遍可用。如果你能将其适配到俯仰机构，请随意使用其中之一；如果不能，我有一些计划。
- en: Building a robot requires creative thinking and being adaptable, as well as
    the necessary technical skills. I frequently look through the materials I have
    for possible solutions before I go and buy something. Sometimes, the first thing
    you attempt will not work, and you'll need a plan B. My plan A was to use a hook-and-loop
    fastener (such as Velcro) stuck directly to the camera, but it does not adhere
    well to the back of the camera. So I had to move to plan B, that is, using a square
    of cardboard, making holes for 2 mm screws in it, bolting the camera to the cardboard,
    and then using the hook-and-loop fastener to attach the camera assembly to the
    Pi. Another possibility is to drill additional holes in the pan-and-tilt mechanism
    to line up with the camera screw holes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器人需要创造性思维、适应性以及必要的技能。我在购买东西之前，经常查看我拥有的材料以寻找可能的解决方案。有时，你尝试的第一个方案可能不会成功，你需要计划B。我的计划A是直接将钩环式搭扣（如魔术贴）粘到相机上，但它并不很好地粘附在相机的背面。所以我不得不转向计划B，即使用方形纸板，在其上打孔以安装2毫米的螺丝，将相机固定到纸板上，然后使用钩环式搭扣将相机组件固定到Pi上。另一种可能性是在俯仰机构上钻更多的孔，使其与相机螺丝孔对齐。
- en: Tip
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Could I glue this? Yes, like most of our robot build, some glue—even crazy glue—could
    be used to adhere the camera to the pan and tilt. It would probably be an easier
    build. However, I can easily foresee that you would need to replace or remove
    the camera at some point. Reasons for that might be to reverse the camera cable
    or swap the camera out for another sensor, or even a newer camera with better
    features. It is for this reason that I generally avoid glue in my robot builds,
    looking for modular and replaceable solutions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我能粘上这个吗？是的，就像我们大多数的机器人搭建一样，一些胶水——甚至强力胶——可以用来将相机粘接到俯仰和倾斜上。这可能会更容易搭建。然而，我很容易预见你会在某个时候需要更换或移除相机。原因可能是反转相机线或更换相机为另一个传感器，甚至是一个具有更好功能的更新相机。正因为如此，我在机器人搭建中通常避免使用胶水，寻找模块化和可更换的解决方案。
- en: 'The parts needed are shown in *Figure 13.2*:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的部件如图*图13.2*所示：
- en: '![](img/B15660_13_02.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_02.jpg)'
- en: Figure 13.2 – The parts needed for our plan to fit the camera module
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 – 我们计划安装相机模块所需的部件
- en: '*Figure 13.2* shows the tools and materials laid out: some thin card, 2 mm
    bolts and screws, the Pi Camera module, some scissors, a small spanner (or pliers),
    hook-and-loop tape, and a small screwdriver. You will also need a pencil.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.2*显示了摆放的工具和材料：一些薄纸板，2毫米螺栓和螺钉，Pi相机模块，一些剪刀，一个小扳手（或钳子），钩环式搭扣胶带，一个小螺丝刀。你还需要一支铅笔。'
- en: 'While making this, please try not to touch the camera''s lens. So let''s begin.
    The following figure shows you the steps to attach the camera:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在制作这个时，请尽量不要触摸相机的镜头。那么，让我们开始吧。以下图示显示了安装相机的步骤：
- en: '![](img/B15660_13_03.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_03.jpg)'
- en: Figure 13.3 – Fitting the camera, steps 1–2
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 – 安装相机，步骤1-2
- en: 'Here''s how to use these parts to mount the camera:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何使用这些部件安装相机的：
- en: First, cut a small amount for one side of the hook-and-loop fastener and adhere
    it to the pan-and-tilt mechanism, as shown in *Figure 13.3*.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，剪下一小部分用于钩环式搭扣的一侧，并将其粘贴到俯仰机构上，如图*图13.3*所示。
- en: Mark and cut out a small square of cardboard a little larger than the camera:![](img/B15660_13_04.jpg)
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在相机略大的地方剪下一个小的方形纸板：![](img/B15660_13_04.jpg)
- en: Figure 13.4 – Using a pen to mark the screw positions
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.4 – 使用笔标记螺丝位置
- en: Then use a pen or pencil to poke through the camera screw holes to mark a dot,
    as shown in *Figure 13.4*. Then take a pointed tool (such as the point of a cross-headed
    jeweler's screwdriver or a math set compass), and on a firm surface, punch a hole
    where you made the mark:![](img/B15660_13_05.jpg)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用钢笔或铅笔在摄像头螺丝孔中戳一个点，如图 13.4 所示。然后拿一个尖锐的工具（例如十字螺丝刀的尖端或数学套件中的圆规），在一个坚固的表面上，在标记的位置打一个孔：![](img/B15660_13_05.jpg)
- en: Figure 13.5 – Bolting the camera to the cardboard
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.5 – 将摄像头固定到纸板上
- en: Use a couple of M2 bolts and nuts to fasten the camera onto the cardboard carrier,
    as shown in *Figure 13.5*. Note that the bolt-facing side is at the back—this
    is so any protruding threads won't interfere with the hook and loop:![](img/B15660_13_06.jpg)
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用几颗 M2 螺丝和螺母将摄像头固定到纸板载体上，如图 13.5 所示。注意，螺栓朝向的一侧在背面——这样任何突出的螺纹都不会干扰钩扣和搭扣：![](img/B15660_13_06.jpg)
- en: Figure 13.6 – The back of the cardboard/camera assembly with our hook-and-loop
    fastener
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.6 – 纸板/摄像头组件的背面，带有我们的钩扣式固定件
- en: Now cut a small amount of the hook-and-loop fabric, to which the material on
    the pan-and-tilt mechanism will fasten, and stick it to the back of the cardboard,
    as shown in *Figure 13.6*.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，剪下一小段钩扣式织物，将这段织物固定在万向节机构上的材料上，并将其粘贴到纸板的背面，如图 13.6 所示。
- en: Note that the camera may have a film covering the lens—please remove this.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，摄像头可能有一层薄膜覆盖在镜头上——请将其取下。
- en: The camera is ready to be stuck to the robot. Don't attach the camera just yet,
    as we need to wire in the cable first. Let's see how in the next section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 摄像头已经准备好可以粘贴到机器人上了。现在不要连接摄像头，因为我们首先需要连接电缆。让我们在下一节中看看如何操作。
- en: Wiring in the camera
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接摄像头
- en: With the camera ready to attach, we'll need to use the Raspberry Pi camera cable
    to connect it to the Pi. We'll need to move some parts to get to the Raspberry
    Pi connector and thread the ribbon connector through.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好连接摄像头，我们需要使用树莓派摄像头线将其连接到树莓派上。我们需要移动一些部件以便到达树莓派连接器，并将扁平电缆穿过。
- en: 'The sequence of images in *Figure 13.7* shows how we will wire this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.7* 中的图像序列显示了我们将如何进行接线：'
- en: '![](img/B15660_13_07.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_07.jpg)'
- en: Figure 13.7 – The camera connector slot and the motor board
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – 摄像头连接器槽和电机板
- en: 'The steps in *Figure 13.7* show how we''ll prepare the cable connector:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.7* 中的步骤显示了我们将如何准备电缆连接器：'
- en: The Raspberry Pi has a slot specifically for the camera—the camera cable fits
    into this. We will be wiring our camera into this slot, but the motor board covers
    the slot on our robot.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 树莓派有一个专门用于摄像头的槽——摄像头电缆可以插入这个槽中。我们将把摄像头连接到这个槽中，但电机板覆盖了我们的机器人上的这个槽。
- en: To get around the slot being covered, we will need to lift the other boards
    above the Pi. You'll temporarily need to unbolt the **Inertial Measurement Unit**
    (**IMU**), so the motor board isn't covered by it. Loosen the nut on top of the
    IMU; then you can turn the lower spacer post by hand to remove the IMU, leaving
    the IMU and standoff assembly complete.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了绕过被覆盖的槽，我们需要抬起树莓派上的其他板。你需要暂时卸下 **惯性测量单元**（**IMU**），这样电机板就不会被它覆盖。松开 IMU 顶部的螺母；然后你可以手动转动下方的垫圈柱，以卸下
    IMU，留下 IMU 和支撑件组件完整。
- en: Disconnect the motor wires (note how you'd previously connected them, or take
    a photo for later reference).
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 断开电机线（注意你之前是如何连接它们的，或者拍张照片以供以后参考）。
- en: Now gently lift the motor board off the Raspberry Pi.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，轻轻地将电机板从树莓派上抬起。
- en: When you connect the camera to the Pi, the long cable will need to pass through
    the motor board. Keep this in mind as you perform the next step.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你将摄像头连接到树莓派时，长电缆需要穿过电机板。在执行下一步时，请记住这一点。
- en: I recommend following *Connect ribbon cable to camera* in *The Official Raspberry
    Pi Camera Guide* ([https://magpi.raspberrypi.org/books/camera-guide](https://magpi.raspberrypi.org/books/camera-guide))
    for attaching the camera using the long 300 mm cable. After following the guide,
    you should have the ribbon installed the correct way around in the camera, then
    going through the slot in the motor board and into the port the right way around
    on the Raspberry Pi.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议遵循 *《官方树莓派摄像头指南》中的* “连接扁平电缆到摄像头” ([https://magpi.raspberrypi.org/books/camera-guide](https://magpi.raspberrypi.org/books/camera-guide))，使用长
    300 毫米的电缆连接摄像头。按照指南操作后，你应该已经正确地将扁平电缆安装在摄像头中，然后穿过电机板上的槽，并正确地插入树莓派的端口。
- en: Double-checking that your connections are the right way around before replacing
    the motor board will save you a lot of time.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在更换电机板之前，仔细检查你的连接是否正确，这将为你节省大量时间。
- en: 'To complete the reassembly, take a look at *Figure 13.8*:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成重新组装，请查看*图 13.8*：
- en: '![](img/B15660_13_08.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_08.jpg)'
- en: Figure 13.8 – Completing the camera interface
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8 – 完成相机接口
- en: 'Follow these steps, using *Figure 13.8* as a reference:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤操作，并参考*图 13.8*：
- en: Gently replace the motor board, pushing its header down onto the Raspberry Pi
    GPIO header and the holes onto spacers.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 轻轻更换电机板，将其引脚推到 Raspberry Pi GPIO 引脚上，并将孔推到间隔器上。
- en: Bolt the IMU back in.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 IMU 重新安装回去。
- en: Reconnect the motor cables based on your reference.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据你的参考重新连接电机电缆。
- en: Push the camera onto the hook-and-loop attachment on the pan-and-tilt head,
    with the cable facing upward.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相机推到云台头的搭扣附件上，确保电缆向上。
- en: You've seen how to wire in Raspberry Pi cameras. This camera is now wired and
    ready to use. Next, we will start preparing the software to get images from the
    camera.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何连接 Raspberry Pi 相机。现在相机已经连接好，准备使用。接下来，我们将开始准备软件以从相机获取图像。
- en: Setting up computer vision software
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置计算机视觉软件
- en: Before we can start writing code, we'll need to set up drivers, tools, and libraries
    to interact with the camera and software to assist with computer vision.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以开始编写代码之前，我们需要设置驱动程序、工具和库，以便与相机和软件进行交互，以帮助进行计算机视觉。
- en: In this section, we will activate the camera in Raspberry Pi OS Raspberry Pi
    OS and get a test picture. Then we will add the libraries to start interacting
    with the camera for visual processing.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将激活 Raspberry Pi OS 中的相机，并获取一张测试照片。然后我们将添加库以开始与相机进行交互，进行视觉处理。
- en: We will then build our first app with the tool to demonstrate that the parts
    are in place and give us a starting point for the behaviors. Let's get into setting
    up the software.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用工具构建我们的第一个应用程序，以证明部件已就位，并为我们提供行为的一个起点。让我们开始设置软件。
- en: Setting up the Pi Camera software
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 Pi 相机软件
- en: 'So that the camera is ready to use, we need to enable it:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使相机准备好使用，我们需要启用它：
- en: Power up the Pi on external power (that is, plugged into a USB wall adapter)
    for this operation, leaving the motors powered down for now.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此操作中，请使用外部电源（即插入 USB 墙式适配器）启动 Pi，暂时关闭电机电源。
- en: 'Log in via SSH. At the terminal, type the following:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 SSH 登录。在终端中，键入以下内容：
- en: '[PRE0]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You should now see `raspi-config`. Select the **Interfacing Options** menu item
    by using the cursor keys and *Enter*.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你应该能看到 `raspi-config`。使用光标键选择**接口选项**菜单项，然后按*Enter*。
- en: Select `raspi-config` will then ask whether you would like the camera interface
    to be enabled. Select **Yes** and **Ok**, then **Finish**.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `raspi-config` 将会询问你是否希望启用相机接口。选择**是**和**确定**，然后**完成**。
- en: 'You will need to reboot for this to take effect:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要重新启动以使此更改生效：
- en: '[PRE1]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To verify that we can get pictures, we'll need the `picamera` package. At the
    time of writing, there is a copy of `picamera` already installed in Raspberry
    Pi OS.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们能否获取图片，我们需要 `picamera` 包。在撰写本文时，Raspberry Pi OS 中已经安装了 `picamera`。
- en: Now that the camera is enabled, let's try getting our first picture.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，相机已启用，让我们尝试获取第一张图片。
- en: Getting a picture from the Raspberry Pi
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 Raspberry Pi 获取图片
- en: 'The first thing we need to do, to confirm that our setup was successful, is
    to ask the Pi Camera to take a picture. If the camera isn''t detected, please
    go back and check that the cable connection is correct, that you have installed
    `picamera`, and that you have enabled the Raspberry Pi camera in `raspi-config`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是确认我们的设置是否成功，即要求 Pi 相机拍照。如果相机未检测到，请返回并检查电缆连接是否正确，是否已安装 `picamera`，以及是否在
    `raspi-config` 中启用了 Raspberry Pi 相机：
- en: 'Reconnect to the Raspberry Pi and type the following to get a picture:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新连接到 Raspberry Pi 并键入以下内容以获取图片：
- en: '[PRE2]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can then use your SFTP client (which we set up in [*Chapter 4*](B15660_04_Final_ASB_ePub.xhtml#_idTextAnchor063),
    *Preparing a Headless Raspberry Pi for a Robot*) to download this image and verify
    it on your computer. You will notice that the picture is upside down, due to how
    the camera is mounted. Don't worry—we will correct this with our software.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以使用你的 SFTP 客户端（我们在 [*第 4 章*](B15660_04_Final_ASB_ePub.xhtml#_idTextAnchor063)，*为机器人准备无头
    Raspberry Pi*）下载此镜像并在你的电脑上验证它。你会注意到图片是颠倒的，这是由于相机安装方式造成的。不用担心——我们将通过软件进行纠正。
- en: With a picture taken, you know that the camera works. Now we can install the
    rest of the software needed to use the camera in visual processing applications.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 拍摄一张照片后，你知道相机是正常工作的。现在我们可以安装使用相机进行视觉处理应用所需的其余软件。
- en: Installing OpenCV and support libraries
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装OpenCV和支持库
- en: We will need a few helper libraries to do the heavy lifting of visual processing
    and display the output in a useful way. **Open Computer Vision** (**OpenCV**)
    is a library with a collection of tools for manipulating pictures and extracting
    information. Code can use these OpenCV tools together to make useful behaviors
    and pipelines for processing images.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一些辅助库来完成视觉处理的繁重工作，并以有用的方式显示输出。**Open Computer Vision**（**OpenCV**）是一个包含用于操作图片和提取信息的工具集合的库。代码可以使用这些OpenCV工具一起制作有用的行为和图像处理管道。
- en: 'To run our code on the Raspberry Pi, we will need to install the Python OpenCV
    library there:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要在树莓派上运行我们的代码，我们需要安装Python OpenCV库：
- en: 'OpenCV has some dependencies that are needed first:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenCV有一些依赖项需要首先安装：
- en: '[PRE3]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Raspberry Pi OS requires a library to be identified for OpenCV to work. This
    line identifies the library every time you log in to the Pi. We should also prepare
    it for this session:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 树莓派操作系统需要为OpenCV工作而识别一个库。此行会在每次登录到Pi时识别该库。我们也应该为此会话做好准备：
- en: '[PRE4]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Flask** is a library for creating web servers that we''ll use to stream the
    video data to a browser:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Flask**是一个用于创建网络服务器的库，我们将使用它将视频数据流式传输到浏览器：'
- en: '[PRE5]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**NumPy**, the numeric Python library, is excellent for the manipulation of
    large blocks of numbers. An image stored on a computer is essentially a large
    block of numbers, with each tiny dot having similar content to the three-color
    numbers we sent to the LEDs in [*Chapter 9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171),
    *Programming RGB LED Strips in Python*:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**NumPy**，这个数值Python库，非常适合处理大量数字。存储在计算机上的图像本质上是一大块数字，每个小点都有与我们在[*第9章*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171)，“用Python编程RGB
    LED灯带”中发送到LED的三色数字相似的内容：'
- en: '[PRE6]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will need to install the large array extension for `picamera`. This will
    help us convert it''s data for use in NumPy and OpenCV:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要为`picamera`安装大型数组扩展。这将帮助我们将其数据转换为NumPy和OpenCV可以使用的形式：
- en: '[PRE7]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will continue testing on external power for the next few operations.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个操作中，我们将继续在外部电源上进行测试。
- en: You've now prepared the software libraries and verified that the camera can
    take pictures. Next, we'll build an app to stream video from the camera to your
    browser.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经准备好了软件库，并验证了相机可以拍照。接下来，我们将构建一个应用程序，从相机流式传输视频到你的浏览器。
- en: Building a Raspberry Pi camera stream app
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建树莓派相机流应用程序
- en: Downloading one picture at a time is fine, but we need to do things with those
    pictures on our robot. We also need a handy way to see what the robot is doing
    with the camera data. For that, we will learn how to use a Flask web server to
    serve up our pictures so we can view the output on a phone or laptop. We can use
    the core of this app to make a few different behaviors. We'll keep the base app
    around for them.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一次下载一张图片是可以的，但我们需要在我们的机器人上对这些图片进行处理。我们还需要一种方便的方法来查看机器人如何使用相机数据。为此，我们将学习如何使用Flask网络服务器来提供我们的图片，这样我们就可以在手机或笔记本电脑上查看输出。我们可以使用此应用程序的核心来创建几种不同的行为。我们将保留基本应用程序以供使用。
- en: A video or video stream is a sequence of images, usually known as **frames**.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 视频或视频流是一系列图像，通常称为**帧**。
- en: Let's design our streaming server.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设计我们的流服务器。
- en: Designing the OpenCV camera server
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计OpenCV相机服务器
- en: 'The diagram in *Figure 13.9* shows an image data pipeline, going from the camera,
    through the processing, and out to our web browser:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.9*中的图表展示了图像数据处理流程，从相机开始，经过处理，最终输出到我们的网页浏览器：'
- en: '![](img/B15660_13_09.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_09.jpg)'
- en: Figure 13.9 – The image server app
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9 – 图像服务器应用程序
- en: The image server app in *Figure 13.9* starts with the camera. The camera feeds
    image data to a **convert to OpenCV** step, with the raw photo given. Image data
    needs some processing for OpenCV to be able to manipulate it.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.9*中的图像服务器应用程序从相机开始。相机将图像数据馈送到一个“转换为OpenCV”步骤，提供原始照片。图像数据需要一些处理，以便OpenCV能够操作它。'
- en: '**convert to OpenCV** feeds data to **process a frame**, which can be anything
    we require; for this example, we''ll apply a color mask, which we explore in more
    depth in the next section. Above the **process a frame** step is an example of
    an image after using a red color mask.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**转换为OpenCV**将数据馈送到**处理帧**，这可以是任何我们需要的；在这个例子中，我们将应用一个颜色掩码，我们将在下一节中更深入地探讨。在**处理帧**步骤之上是一个使用红色颜色掩码后的图像示例。'
- en: The raw frame and processed frame go into the next step, **join with original**,
    which creates a compound image with both images. Above the step are the two images
    joined into a single longer frame.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 原始帧和已处理帧进入下一步，**与原始帧合并**，这会创建一个包含两个图像的复合图像。在此步骤之上，是两个图像合并成单个更长的帧。
- en: The joined images go into the `jpeg`, an image encoding that a browser can show,
    and importantly, display as a sequence of frames, a streaming movie.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 合并的图像进入`jpeg`，这是一种浏览器可以显示的图像编码，并且重要的是，可以显示为一系列帧的流媒体。
- en: The encoded data goes to **serve over HTTP**, getting the data into a system
    you can view with a web browser. It uses a template (some layout and text for
    the browser) to serve this.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 编码的数据通过**HTTP服务**发送，将数据放入你可以用网页浏览器查看的系统。它使用模板（一些布局和文本用于浏览器）来提供服务。
- en: The image output then goes from **serve over HTTP**, via the network, to the
    users, browser. Finally, the browser shows the image to the user. The browser
    could be on a laptop or a phone.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图像输出随后通过**HTTP服务**，通过网络传输到用户，浏览器。最后，浏览器将图像显示给用户。浏览器可以是笔记本电脑或手机。
- en: 'It''s time to start building the code. We''ll break it down into two major
    parts: first, a `CameraStream` object, which will send our frames to the second
    part of our code project, an `image_server.py` script.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候开始构建代码了。我们将将其分解为两个主要部分：首先是一个`CameraStream`对象，它将我们的帧发送到代码项目的第二部分，即`image_server.py`脚本。
- en: Writing the CameraStream object
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写CameraStream对象
- en: 'As part of our system, we will create a helper library to set up the camera
    and get data streams from it:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们系统的一部分，我们将创建一个辅助库来设置摄像头并从中获取数据流：
- en: 'Start the `camera_stream.py` file with the following imports:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以以下导入开始`camera_stream.py`文件：
- en: '[PRE8]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The next few lines set up parameters for the capture size and image quality:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来的几行设置了捕获大小和图像质量的参数：
- en: '[PRE9]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Add a function to set up the camera:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个设置摄像头的函数：
- en: '[PRE10]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After initializing the camera, we set its resolution to the size. I mentioned
    that the camera is the wrong way up, so we set its rotation to 180 degrees to
    turn the pictures around.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 初始化摄像头后，我们将其分辨率设置为大小。我提到摄像头是颠倒的，因此我们将其旋转设置为180度以翻转图片。
- en: 'We will need a function to start capturing a stream of images (a video, but
    a frame at a time):'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一个函数来开始捕获一系列图像（一个视频，但一次一个帧）：
- en: '[PRE11]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can loop through `cam_stream` for frames until we choose to stop. Python
    has a concept of `for` loop is a generator. Every cycle will yield the raw `.array`
    from the frame that the stream captured. What this means is that a loop can use
    the output of the `start_stream` function, so when looped over, the code in this
    `for` loop will run just enough to produce one raw frame, then the next, and so
    on. Python generators are a way to construct processing pipelines.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以循环遍历`cam_stream`直到我们选择停止。Python有一个概念，即`for`循环是一个生成器。每次循环都会产生流捕获的帧的原始`.array`。这意味着循环可以使用`start_stream`函数的输出，因此当循环遍历时，这个`for`循环中的代码将运行足够的时间以产生一个原始帧，然后是下一个，依此类推。Python生成器是构建处理管道的一种方式。
- en: The last line of the loop calls `truncate` to reset `image_storage` ready to
    hold another image. `PiRGBArray` can store many images in sequence, but we only
    want the latest one. More than one image may have arrived while we were processing
    a frame, so we must throw them away.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 循环的最后一行调用`truncate`以重置`image_storage`，使其准备好存储另一张图像。`PiRGBArray`可以按顺序存储许多图像，但我们只想保留最新的一张。在我们处理帧的同时，可能已经到达了多张图像，因此我们必须丢弃它们。
- en: 'The final thing we add to the `camera_stream.py` script is a function to encode
    an image as `jpeg` and then into bytes for sending, as shown here:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们添加到`camera_stream.py`脚本中的最后一件事是一个函数，用于将图像编码为`jpeg`然后转换为字节以发送，如下所示：
- en: '[PRE12]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We will use the `camera_stream` library for a few of our behaviors, giving us
    the ability to fetch and encode camera frames, both ready for input and encoded
    for display. With that ready, let's use it in a test app to serve frames in a
    browser.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`camera_stream`库来执行我们的某些行为，这使我们能够获取和编码摄像头帧，既可用于输入，也可用于显示。有了这些准备，让我们在一个测试应用程序中使用它来在浏览器中提供帧。
- en: Writing the image server main app
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写图像服务器主应用程序
- en: 'This part of the app will set up Flask, start our camera stream, and link them
    together. We will put this in a new script named `image_server.py`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的这一部分将设置 Flask，启动我们的相机流，并将它们连接起来。我们将把这个放在一个名为 `image_server.py` 的新脚本中：
- en: 'We need to import all of these components and set up a Flask app:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要导入所有这些组件并设置一个 Flask 应用程序：
- en: '[PRE13]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Flask works in routes, which are links between an address you hit a web server
    at and a registered handler function. A matching address asked for at our server
    app will run the corresponding function. Let''s set up the most basic route:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Flask 在路由中工作，这些路由是您击中 Web 服务器地址和注册的处理函数之间的链接。在我们的服务器应用程序中请求的匹配地址将运行相应的函数。让我们设置最基本的路由：
- en: '[PRE14]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we get to the tricky bit, the video feed. Although `camera_stream` does
    some of the encoding, we need to turn the frames into an HTTP stream of data,
    that is, data that your browser expects to be continuous. I''ll put this in a
    `frame_generator` function, which we''ll need to break down a little. Let''s start
    by setting up the camera stream:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来到了一个棘手的部分，视频流。尽管 `camera_stream` 进行了一些编码，但我们还需要将帧转换为浏览器期望的连续数据流，即数据流。我将在
    `frame_generator` 函数中实现这一点，我们稍后会对其进行分解。让我们先设置相机流：
- en: '[PRE15]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, we need to loop over the frames from `camera_stream`:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要遍历来自 `camera_stream` 的帧：
- en: '[PRE16]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To send the encoded frame bytes back to the browser, we use another generator
    with `yield`, so Flask considers this a multipart stream—a response made of multiple
    chunks of data, with parts deferred for later—which many frames of the same video
    would be. Note that HTTP content declarations prefix the encoded bytes:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将编码的帧字节发送回浏览器，我们使用另一个带有 `yield` 的生成器，这样 Flask 就会将其视为多部分流——由多个数据块组成的响应，这些块被延迟到稍后处理——这对于同一视频的多个帧来说很常见。注意，HTTP
    内容声明是编码字节的序言：
- en: '[PRE17]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The next function, named `display`, routes from Flask to a loopable stream
    of HTTP frames from `frame_generator`:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个函数，命名为 `display`，将 Flask 路由到来自 `frame_generator` 的可循环 HTTP 帧流：
- en: '[PRE18]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now we can just add the code to start Flask. I''ve put this app on port `5001`:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们只需添加代码来启动 Flask。我已经将此应用程序放在端口 `5001`：
- en: '[PRE19]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The app is nearly ready, but we mentioned a template—let's use this to describe
    what will go on the web page with the camera stream.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序几乎准备好了，但我们提到了一个模板——让我们用这个来描述相机流将在网页上显示的内容。
- en: Building a template
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建模板
- en: 'Flask makes web pages using HTML templates, which route functions render into
    the output, replacing some elements at runtime if necessary. Create a `templates`
    folder, then make a file in that folder named `image_server.html`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Flask 使用 HTML 模板创建网页，这些模板将函数渲染到输出中，如果需要，在运行时替换一些元素。创建一个 `templates` 文件夹，然后在其中创建一个名为
    `image_server.html` 的文件：
- en: 'Our template starts with the HTML tag, with a title and a level 1 heading:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的模板从 HTML 标签开始，有一个标题和一级标题：
- en: '[PRE20]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we add the image link that will display the output of our server:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们添加一个图像链接来显示服务器输出：
- en: '[PRE21]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, we just close the tags in the template:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们只需在模板中关闭标签：
- en: '[PRE22]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We can serve this template up in our main server app.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在主服务器应用程序中提供这个模板。
- en: Now we can upload all three of these parts, ensuring that you upload the template
    into the `templates` directory on the Pi.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以上传这三个部分，确保您将模板上传到 Pi 的 `templates` 目录中。
- en: With the server code and templates ready, you should be able to run the image
    server.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器代码和模板准备就绪后，您应该能够运行图像服务器。
- en: Running the server
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行服务器
- en: Start the app with `python3 image_server.py`.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `python3 image_server.py` 启动应用程序。
- en: 'Point your browser at the app by going to `http://myrobot.local:5001` (or your
    robot''s address), and you should see a video served, as shown in *Figure 13.10*:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的浏览器指向应用程序，通过访问 `http://myrobot.local:5001`（或您的机器人地址），您应该会看到一个视频流，如图 *图13.10*
    所示：
- en: '![](img/B15660_13_10.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_10.jpg)'
- en: Figure 13.10 – Screen capture of the robot image server
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10 – 机器人图像服务器的屏幕截图
- en: The screenshot in *Figure 13.10* shows our robot image server output in a browser.
    The top shows the browser search bar, with the `myrobot.local:5001` address in
    it. Below this is the **Robot Image Server** heading from the template. Below
    the heading is an image capture of a kids' red bowling pin taken from a robot
    camera—served up with the video stream code.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.10* 中的截图显示了在浏览器中我们的机器人图像服务器输出。顶部显示了浏览器搜索栏，其中包含 `myrobot.local:5001` 地址。下面是这个地址，是模板中的
    **机器人图像服务器** 标题。标题下面是机器人相机拍摄的儿童红色保龄球柱的图像捕获——与视频流代码一起提供。'
- en: Troubleshooting
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'If you have problems running the server and seeing the picture, try the following
    steps:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在运行服务器和查看图片时遇到问题，请尝试以下步骤：
- en: 'If you see errors while running the code, do the following:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在运行代码时看到错误，请执行以下操作：
- en: a) Ensure you can capture images with raspistill.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 确保可以使用 raspistill 捕获图像。
- en: b) Ensure you have installed all the required dependencies.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 确保已安装所有必需的依赖项。
- en: c) If it's about `libatomic`, please ensure that you have performed the previous
    `LD_PRELOAD` exports.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 如果是关于 `libatomic` 的，请确保您已执行了之前的 `LD_PRELOAD` 导出。
- en: d) Check that the code is correct.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 检查代码是否正确。
- en: If the image is black, check your lighting. The Raspberry Pi camera is susceptible
    to light conditions and needs a well-lit space to operate. Note that none of the
    following tracking will work if the camera is not getting enough light.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果图像是黑色的，请检查您的照明。树莓派摄像头对光照条件敏感，需要明亮的空间才能正常工作。请注意，如果摄像头没有获得足够的光线，以下任何跟踪都不会工作。
- en: Expect the rate to be slow—this is not a fast or high-quality capture.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期速度会较慢——这不是快速或高质量的捕获。
- en: Now you can stream images from a Raspberry Pi into a browser. Next, we will
    add a background worker task and control mechanism to the app, as this whole server
    depends on the slow browser request cycle.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以从树莓派将图像流式传输到浏览器。接下来，我们将向应用程序添加后台工作任务和控制机制，因为整个服务器都依赖于缓慢的浏览器请求周期。
- en: Running background tasks when streaming
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在流式传输时运行后台任务
- en: Our image service works but has a significant flaw. Currently it will wait between
    requests before taking each action, but what if we want our robot to be doing
    something? To do this, we need to be able to run a behavior in parallel with the
    server. That behavior and the server both need access to the image data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的形象服务虽然工作，但有一个显著的缺陷。目前它将在每个动作之间等待请求，但如果我们想让我们的机器人做些什么呢？为了做到这一点，我们需要能够在服务器并行运行一个行为。这个行为和服务器都需要访问图像数据。
- en: We will approach this by making the Flask web app a secondary process, with
    the behavior as the primary process for the robot when it is running. Python has
    a handy tool for precisely this kind of structure, called multiprocessing. Find
    out more at [https://docs.python.org/3/library/multiprocessing.html](https://docs.python.org/3/library/multiprocessing.html).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过将 Flask 网络应用程序作为次要进程，将行为作为机器人运行时的主要进程来解决这个问题。Python 有一个方便的工具可以精确地实现这种结构，称为
    multiprocessing。更多信息请访问 [https://docs.python.org/3/library/multiprocessing.html](https://docs.python.org/3/library/multiprocessing.html)。
- en: Communicating between multiple processes is tricky. If two processes try to
    access (read or write) the same data simultaneously, the results can be unpredictable
    and cause strange behavior. So, to save them trying to access data simultaneously,
    we will use the multiprocessing queue object. A queue allows one process to put
    data in at one end and another process to consume it safely at the other—it is
    a one-way flow of information. We will use one queue to send images to the server
    and another to get control data from user interactions in the browser.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个进程之间进行通信很复杂。如果两个进程同时尝试访问（读取或写入）相同的数据，结果可能是不可预测的，并可能导致奇怪的行为。因此，为了避免它们同时尝试访问数据，我们将使用多进程队列对象。队列允许一个进程在一端放入数据，另一个进程在另一端安全地消费它——这是一个信息单向流动。我们将使用一个队列将图像发送到服务器，另一个队列从浏览器中的用户交互获取控制数据。
- en: 'The diagram in *Figure 13.11* shows the way data will flow through these behaviors:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.11* 中的图表显示了数据将通过这些行为流动的方式：'
- en: '![](img/B15660_13_11.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_11.jpg)'
- en: Figure 13.11 – Data flow between a browser, server process, and robot behavior
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11 – 浏览器、服务器进程和机器人行为之间的数据流
- en: In *Figure 13.11*, we abridge some of the sections in *Figure 13.9*. First,
    there is data from the camera going into a visual processing behavior (for example,
    tracking an object). This behavior will output image frames to an image queue.
    The output will be the fully processed and joined image.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图13.11* 中，我们对 *图13.9* 中的某些部分进行了简化。首先，有来自摄像头的数据进入视觉处理行为（例如，跟踪一个对象）。这种行为将输出图像帧到图像队列。输出将是完全处理并合并的图像。
- en: A server process, the web app, will take the images from the image queue to
    serve them to a browser via the network. However, the web app will also handle
    commands from user interaction in the browser. The app puts them in the control
    queue as messages. The visual processing behavior will read any messages from
    the control queue and act on them.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器进程，即网络应用程序，将从图像队列中获取图像并通过网络将它们发送到浏览器。然而，网络应用程序也将处理来自浏览器用户交互的命令。应用程序将它们作为消息放入控制队列。视觉处理行为将读取控制队列中的任何消息并对它们采取行动。
- en: 'A few caveats: the visual processing behavior will only place images in the
    image queue when it''s empty, so the queue will only ever contain one image. Allowing
    only one prevents the visual processing behavior from trying to overwrite an image
    in shared memory when a server tries to output it. The control queue has no such
    restriction; we''ll just expect that user interactions will not produce control
    messages faster than the behavior loop can consume them.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一些注意事项：视觉处理行为只有在图像队列空时才会将图像放入图像队列，因此队列将始终只包含一个图像。只允许一个可以防止视觉处理行为在服务器尝试输出图像时尝试覆盖共享内存中的图像。控制队列没有这样的限制；我们只期望用户交互不会产生比行为循环消耗它们更快的控制消息。
- en: We will separate the web app as a core and then write a behavior based on it.
    We can use the web app core multiple times. Let's write this code.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把网络应用分为核心部分，然后基于它编写一个行为。我们可以多次使用网络应用核心。让我们编写这段代码。
- en: Writing a web app core
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写网络应用核心
- en: In this design, the web app core will handle setting up the queues, running
    the server process, and the Flask-based routing. We will write the library in
    Flask style, using plain Python functions in a module.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个设计中，网络应用核心将处理设置队列、运行服务器进程以及基于 Flask 的路由。我们将以 Flask 风格编写库，在模块中使用纯 Python 函数。
- en: 'As an interface to the core, our other behaviors will be able to do the following:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 作为核心的接口，我们的其他行为将能够执行以下操作：
- en: '`start_server_process(template_name)` will start the web app server, using
    the named template.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start_server_process(template_name)` 将启动网络应用服务器，使用指定的模板。'
- en: '`put_output_image(encoded_bytes)` will put images into the display queue.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`put_output_image(encoded_bytes)` 将图像放入显示队列。'
- en: '`get_control_instruction()` is used to check and return instructions from the
    control queue. This function returns a dictionary of instruction data.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get_control_instruction()` 用于检查并返回控制队列中的指令。这个函数返回一个包含指令数据的字典。'
- en: 'The Flask/web server part of the app is slightly independent of the behavior,
    allowing the user to *tune in* to see its display, but it should not stop the
    app running when a user is not present or a browser stalls:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的 Flask/web 服务器部分在行为上稍微独立一些，允许用户*调整*以查看其显示，但当用户不在场或浏览器卡住时，它不应该停止应用程序的运行：
- en: 'Let''s start with some imports. We''ll put this code in `image_app_core.py`:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从一些导入开始。我们将这段代码放在 `image_app_core.py` 文件中：
- en: '[PRE23]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we define our Flask app and the queues. We only really want one frame
    queued, but we put in one in case of hiccups while transmitting—although we can
    check whether a `Queue` instance is empty, this is not 100% reliable, and we don''t
    want one part of the app waiting for the other:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义我们的 Flask 应用和队列。我们实际上只想有一个帧排队，但以防在传输过程中出现故障，我们放入了一个——尽管我们可以检查 `Queue`
    实例是否为空，但这并不总是100%可靠的，我们不希望应用程序的一部分等待另一部分：
- en: '[PRE24]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We will also define a global `display_template` here, in which we''ll store
    the main app template:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将在这里定义一个全局的 `display_template`，在其中我们将存储主应用程序模板：
- en: '[PRE25]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now we add routes for this Flask app. The index route is only different in
    that it uses `display_template`:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们为这个 Flask 应用添加路由。索引路由只在其使用 `display_template` 方面有所不同：
- en: '[PRE26]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next, we will create the loop for getting frames: a modified version of `frame_generator`.
    This function is our main video feed. So that it doesn''t *spin* (that is, run
    very quickly in a tight loop), we put in a sleep of 0.05 to limit the frame rate
    to 20 frames per second:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建获取帧的循环：`frame_generator` 的修改版。这个函数是我们的主要视频源。为了防止它*旋转*（即，在紧密的循环中非常快速地运行），我们加入了一个0.05秒的睡眠，以将帧率限制在每秒20帧：
- en: '[PRE27]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After the sleep, we should try to get data from `display_queue` (we''ll put
    frames into the queue later). Like we did in `image_server`, this loop also turns
    our data into multi-part data:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 睡眠之后，我们应该尝试从 `display_queue` 中获取数据（我们稍后会把帧放入队列）。就像在 `image_server` 中做的那样，这个循环也将我们的数据转换成多部分数据：
- en: '[PRE28]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now make that available through a display block:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在通过一个显示块使其可用：
- en: '[PRE29]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We need a way to post control messages to our app. The `control` route accepts
    these, takes their form data (a dictionary with instructions), and uses `control_queue.put`
    to pass that along to the robot behavior:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一种方法来向我们的应用程序发送控制消息。`control` 路由接受这些消息，获取它们的表单数据（一个包含指令的字典），并使用 `control_queue.put`
    将其传递给机器人行为：
- en: '[PRE30]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'That gives us all the core internals, but we also need to start the server
    process. The part of the app from earlier that started our server, we''ve now
    put into a function named `start_server_process`:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这为我们提供了所有核心内部结构，但我们也需要启动服务器进程。之前启动我们服务器的应用程序部分，我们现在将其放入一个名为 `start_server_process`
    的函数中：
- en: '[PRE31]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The next interface task is putting an image into the queue we created in *step
    1*. To ensure that we don''t run up a lot of memory, we only intend the queue
    to have a length of one. That means that the first frame will be stale, but the
    next frame will arrive soon enough for it not to affect the user:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个界面任务是将在*步骤1*中创建的队列中的图像放入队列。为了确保我们不会消耗太多内存，我们只打算让队列长度为1。这意味着第一个帧会过时，但下一个帧很快就会到达，不会影响用户：
- en: '[PRE32]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Finally, for this interface, we need a function to get the control messages
    out. This function will not wait and will return a message if there is one or
    `None` for *no message*:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，对于这个界面，我们需要一个函数来获取控制消息。这个函数不会等待，如果有消息则返回消息，否则返回`None`表示没有消息：
- en: '[PRE33]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `image_app_core.py` file establishes a controllable base for us to build
    visual processing robot behaviors with, or indeed any behavior with a web interface,
    control instructions, an output stream, and background process. Next, let's test
    this core with a simple behavior.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`image_app_core.py`文件为我们提供了一个可控的基础，我们可以用它来构建视觉处理机器人行为，或者实际上任何具有网络界面、控制指令、输出流和后台进程的行为。接下来，让我们用简单行为测试这个核心。'
- en: Making a behavior controllable
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使行为可控
- en: 'We can try out our core with a behavior that sends images to the web service
    and accepts a simple `exit` control message:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用一个将图像发送到网络服务并接受简单`exit`控制消息的行为来测试我们的核心：
- en: 'Let''s make a new file called `control_image_behavior.py`, starting with imports
    for the `image_app_core` interface and `camera_stream`:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个名为`control_image_behavior.py`的新文件，从导入`image_app_core`接口和`camera_stream`开始：
- en: '[PRE34]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We then add a function that runs our simple behavior with the main loop. I''ve
    broken this function down as it''s a little complicated. First, we''ll set up
    the camera and use a sleep to give the camera warm-up time:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们添加一个函数，在主循环中运行我们的简单行为。由于这个函数有点复杂，所以我将其拆分。首先，我们将设置摄像头并使用睡眠来给摄像头预热时间：
- en: '[PRE35]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, we get frames from a camera stream in a `for` loop and put those as encoded
    bytes on the output queue:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在`for`循环中从摄像头流中获取帧，并将这些帧作为编码的字节放在输出队列中：
- en: '[PRE36]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'While still in the loop, we will try accepting a control instruction to exit.
    Normally the instruction will be `None`, signalling there are no control instructions
    waiting. But if we have a message, we should match the command in it to exit:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在循环中，我们将尝试接受一个退出控制指令。通常指令将是`None`，表示没有等待的控制指令。但如果我们有消息，我们应该匹配其中的命令以退出：
- en: '[PRE37]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We then need to start the server and start our behavior. We always want to
    stop the web server process. By surrounding the behavior with `try` and `finally`,
    it will *always* run anything in the `finally` part, in this case, making sure
    the process is terminated (stopped):'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要启动服务器并开始我们的行为。我们总是希望停止网络服务器进程。通过将行为包裹在`try`和`finally`中，它将*总是*运行`finally`部分中的任何内容，在这种情况下，确保进程被终止（停止）：
- en: '[PRE38]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We now have a simple controllable behavior; however, it mentions the `control_image_behavior.html`
    template. We need to provide that.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个简单的可控行为；然而，它提到了`control_image_behavior.html`模板。我们需要提供这个模板。
- en: Making the control template
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制作控制模板
- en: 'This template, in `templates/control_image_behavior.html`, is the same as the
    one before, but with two important differences, shown here in bold:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模板，在`templates/control_image_behavior.html`中，与之前的相同，但有两个重要的不同之处，这里用粗体标出：
- en: '[PRE39]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The differences are as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 差异如下：
- en: In this template, we load a library in our browser called `jquery`, which is
    handy for interactive web pages. There is great documentation for jQuery at [https://api.jquery.com/](https://api.jquery.com/).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个模板中，我们在浏览器中加载了一个名为`jquery`的库，这对于交互式网页来说非常方便。jQuery在[https://api.jquery.com/](https://api.jquery.com/)有很好的文档。
- en: We have the image and header that we saw before, but new to this code is an
    `a` tag (for anchor), which when clicked will post the `exit` command to the `'/control'`
    route on our web app. `<br>` just creates a line break to show the exit link below
    the image.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有之前看到的图像和标题，但在这段代码中新增了一个`a`标签（用于锚点），当点击时，会将`exit`命令发送到我们的网络应用的`'/control'`路由。`<br>`创建一个换行，以在图像下方显示退出链接。
- en: If you wanted to run this where internet access is difficult, you would need
    the server to serve the `jquery` library. This template tells the browser to download
    `jquery` directly from the internet.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在没有互联网接入的地方运行这个程序，你需要服务器提供`jquery`库。这个模板告诉浏览器直接从互联网下载`jquery`。
- en: Now we have the components, we should try running our controllable behavior.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了组件，我们应该尝试运行我们的可控行为。
- en: Running the controllable image server
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行可控制图像服务器
- en: 'Now we have the components, let''s get this running and try out the commands:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了组件，让我们运行它并尝试一下命令：
- en: 'To run the image server, you need to upload all three files:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行图像服务器，您需要上传所有三个文件：
- en: a) `image_app_core.py`
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `image_app_core.py`
- en: b) `control_image_behavior.py`
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `control_image_behavior.py`
- en: c) `templates/control_image_behavior.html`.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `templates/control_image_behavior.html`。
- en: On your Pi, use `python3 control_image_behavior.py` to start the process.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的Pi上，使用`python3 control_image_behavior.py`来启动进程。
- en: Point your browser at `http://myrobot.local:5001` (or the address of your robot).
    You will see the pictures again.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的浏览器指向`http://myrobot.local:5001`（或您的机器人地址）。您将再次看到这些图片。
- en: If you click on the **Exit** link below the image, this will send a control
    instruction to your app, which should gracefully quit.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您点击图片下方的**退出**链接，这将向您的应用发送控制指令，应用应该优雅地退出。
- en: You've now seen how to get image data from a behavior while sending control
    data back to the behavior. With the control and streaming technique tested and
    ready, and a framework to use for it, we can build a more interesting behavior.
    In the next section, we'll make the robot follow an object with a specific color.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经看到了如何在行为中获取图像数据的同时将控制数据发送回行为。随着控制和流技术经过测试并准备就绪，以及一个用于它的框架，我们可以构建一个更有趣的行为。在下一节中，我们将使机器人跟随一个具有特定颜色的物体。
- en: Following colored objects with Python
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python跟踪彩色物体
- en: Now we have some basics ready; we can use this to build some more interesting
    behaviors.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了一些基础知识，我们可以用它来构建一些更有趣的行为。
- en: We will create a behavior that will chase, but not get too close to, a colored
    object. This behavior will make the robot seem very intelligent. We will revisit
    color models, covered in [*Chapter 9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171),
    *Programming RGB Strips in Python*. We'll add color masking and filtering and
    use the OpenCV contours tools to detect the largest blob of color in an image
    and point the robot at it.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个行为，使机器人追逐一个彩色物体，但不会离得太近。这种行为会使机器人看起来非常智能。我们将回顾在[*第9章*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171)中介绍的颜色模型，即*在Python中编程RGB条带*。我们将添加颜色掩码和过滤，并使用OpenCV轮廓工具检测图像中最大的彩色块，并将机器人指向它。
- en: 'Building the color-chasing behavior requires a few steps. Let''s start with
    a diagram showing an overview of this whole behavior in *Figure 13.12*:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 构建颜色追逐行为需要几个步骤。让我们从一张图开始，展示这个整个行为的概述，即*图13.12*：
- en: '![](img/B15660_13_12.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_12.jpg)'
- en: Figure 13.12 – The color-tracking behavior
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12 – 颜色追踪行为
- en: The flow of data in *Figure 13.12* starts from **camera images**. These go through
    **visual processing** to **get object info from image**. **get object info from
    image** outputs the object's size (based on the radius of a circle around it)
    and the object's position (the middle of the enclosing circle) and puts frames
    on the image queue for the web app/browser.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.12*中的数据流从**相机图像**开始。这些图像经过**视觉处理**以从图像中获取物体信息。**从图像中获取物体信息**输出物体的尺寸（基于围绕它的圆的半径）和物体的位置（包围圆的中心）并将帧放入图像队列，供Web应用/浏览器使用。'
- en: The object size goes into a speed **Proportional Integral Derivative** (**PID**)
    controller, which also has an object size reference as its set point. Depending
    on the difference between the expected size and actual size, this PID will output
    a speed for the motors, optimizing the radius to be the same as the reference
    size. That way, the robot will maintain a distance from an object of a known size.
    This is a base speed for both motors.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 物体大小进入一个速度**比例积分微分**（PID）控制器，该控制器也有一个物体大小参考值作为其设定点。根据预期大小和实际大小的差异，这个PID将为电机输出一个速度，优化半径以与参考大小相同。这样，机器人将保持与已知大小的物体之间的距离。这是两个电机的基准速度。
- en: The object position has an `x` component and a `y` component. This behavior
    will turn to center the object, so we are interested in the `x` coordinate. The
    `x` coordinate goes into a PID for controlling the direction/heading. This PID
    takes a reference position—the center of the camera viewport. This direction PID
    will produce an output to try and get the difference between these coordinates
    to zero. By adding to one motor's speed and reducing the other's speed, the robot
    will turn to face the object (or, if you swap them for fun, it'll turn away!).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 物体位置有一个`x`分量和一个`y`分量。这个行为将转向以使物体居中，所以我们感兴趣的是`x`坐标。`x`坐标进入PID以控制方向/航向。这个PID接受一个参考位置——摄像头视口的中心。这个方向PID将产生一个输出，试图使这些坐标之间的差异为零。通过增加一个电机的速度并减少另一个电机的速度，机器人将转向面对物体（或者，如果你为了乐趣而交换它们，它将转向远离！）
- en: The images are sent, via an image queue using the app core, to the browser.
    A detail not shown in the diagram is the control queue with messages to start
    the motors, stop the motors, and exit the behavior.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像通过使用应用核心的图像队列发送到浏览器。图中未显示的控制队列包含启动电机、停止电机和退出行为的消息。
- en: The final part of this system, and probably the most interesting, is the color
    tracking. The box labeled **get object info from image** performs the tracking.
    Let's see how that works next.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这个系统的最后一部分，也许是最有趣的，就是颜色追踪。标记为**从图像获取对象信息**的框执行追踪操作。让我们看看它是如何工作的。
- en: Turning a picture into information
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将图片转换为信息
- en: We are using colored pins from a kids' bowling set. They come in nice, bright,
    primary colors. I will use green as an example. We start with just a picture.
    However, a set of transformations to the data is needed to turn the picture into
    information the robot can use to make decisions.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用儿童保龄球套件中的彩色针。它们有漂亮的鲜艳的原色。我将用绿色作为例子。我们从一个图片开始。然而，需要一组数据转换来将图片转换为机器人可以用来做出决策的信息。
- en: 'A pipeline is a good way to design a set of transformations. Let''s look at
    the color tracking as an image processing pipeline in *Figure 13.13*:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 管道是设计一组转换的好方法。让我们看看*图13.13*中的颜色追踪作为图像处理管道：
- en: '![](img/B15660_13_13.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15660_13_13.jpg)'
- en: Figure 13.13 – Getting color object information from a camera
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.13 – 从摄像头获取颜色对象信息
- en: As with other pipelines, *Figure 13.13* starts from the camera. This is converted
    to a low resolution to keep things fast. The figure shows a camera image above
    the step.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他管道一样，*图13.13*从摄像头开始。这被转换为低分辨率以保持速度。图示显示了这一步骤之上的摄像头图像。
- en: The process converts the output from the image capture to HSV, the colorspace
    we mentioned in [*Chapter 9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171),
    *Programming RGB Strips in Python*. We use HSV because it means the process can
    filter colors in a specific range of hues, by their light (very dark objects may
    confuse us), and by saturation, so it won't include almost-gray objects. RGB (or
    BGR) images are tricky to filter, as getting the different light and saturation
    levels of a particular hue (say, the blues) is not viable. The figure shows the
    hue color wheel above this step.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程将图像捕获的输出转换为HSV，这是我们提到的[*第9章*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171)，*在Python中编程RGB条带*中提到的色彩空间。我们使用HSV，因为这意味着过程可以过滤特定色调范围内的颜色，通过它们的亮度（非常暗的物体可能会让我们困惑），以及饱和度，因此它不会包括几乎灰色的物体。RGB（或BGR）图像过滤起来很棘手，因为获取特定色调（比如蓝色）的不同亮度和饱和度级别是不可行的。图示显示了这一步骤之上的色调颜色轮。
- en: OpenCV has a function, `cv2.cvtColor`, to convert whole images between colorspaces.
    Note that OpenCV uses 0–179 for the hue range, instead of 0–359\. This is so it
    fits in a byte (0–255), but you can convert hue values by simply dividing by 2
    if you know the value you want.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV有一个函数，`cv2.cvtColor`，可以将整个图像在不同色彩空间之间转换。请注意，OpenCV使用0–179作为色调范围，而不是0–359。这样做是为了使其适合一个字节（0–255），但如果你知道你想要的值，你可以通过简单地除以2来转换色调值。
- en: 'After converting to HSV, we then filter the colors in the image with a mask,
    highlighting pixels in a particular range. It will output white if the object
    is in the range, or black if it''s not. Above this step, the unshaded region on
    the hue color wheel shows the range, with the masked output next to it. There
    is a function in OpenCV to do this: `cv2.inRange`. This gives us a very easy binary
    output, a masked image, to draw around for our system.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换为HSV之后，我们使用掩码过滤图像中的颜色，突出显示特定范围内的像素。如果物体在该范围内，则输出白色，如果不在此范围内，则输出黑色。在此步骤之上，色调颜色轮上的无阴影区域显示了范围，掩码输出紧邻其旁。OpenCV有一个函数可以做到这一点：`cv2.inRange`。这给我们一个非常简单的二进制输出，一个掩码图像，我们可以用它来绘制我们的系统。
- en: Our pipeline then uses the contours system to draw around our masked image.
    The contour specifies only the boundary points of our object. OpenCV provides
    a `cv2.findContours` function to do exactly this, which returns a list of shapes,
    each defined by its outlines. The preceding figure shows the contours (taken from
    the mask) drawn onto the raw image. Note how light and shade have made the bottom
    of the bowling pin a bit rough as it doesn't quite fit the mask.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们的管道使用轮廓系统来绘制蒙版图像的周围。轮廓仅指定我们物体的边界点。OpenCV提供了一个`cv2.findContours`函数来执行此操作，它返回一个形状列表，每个形状由其轮廓定义。前面的图显示了从蒙版中提取的轮廓绘制在原始图像上。注意，由于光线和阴影的影响，保龄球瓶的底部有点粗糙，因为它并不完全符合蒙版。
- en: The processing pipeline then takes the contours (outlines) and uses `cv2.minEnclosingCircle`
    to draw circles around them. We will then have some circles, described by a center
    `x`, `y` coordinate, and radius. The preceding figure shows these circles projected
    on the raw image.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 处理管道随后取轮廓（轮廓）并使用`cv2.minEnclosingCircle`在它们周围绘制圆圈。然后我们将有一些圆，由中心`x`、`y`坐标和半径描述。前面的图显示了这些圆在原始图像上的投影。
- en: Our object may have highlights, producing more than one circle, and other objects
    may also produce smaller circles. We are only interested in one, the largest of
    these, so we can loop through the circles, and keep only the largest. Above the
    **get the largest circle** step is the raw image with only the largest circle
    drawn.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标物体可能有高光，产生多个圆，其他物体也可能产生较小的圆。我们只对其中一个感兴趣，即这些圆中最大的一个，因此我们可以遍历这些圆，并只保留最大的一个。在**获取最大圆**步骤之上是只画了最大圆的原始图像。
- en: This largest circle's coordinates and radius give us enough information for
    our robot to start chasing an object. Above this last step is just the circle,
    with crosshairs showing its position.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最大圆的坐标和半径为我们机器人开始追逐物体提供了足够的信息。在上一个步骤之上，只是一个圆，上面有十字准星显示其位置。
- en: Important note
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'A caveat about red objects: we will use green because red is slightly tricky,
    as it requires two masks. The hues for red cross a boundary between 179 (the upper
    limit of our hue range) and 0 (the lower limit), so we would have to mask the
    image twice and then combine these with an `or` operation. You could use the `cv2.bitwise_or`
    function to try masking red.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 关于红色物体的注意事项：我们将使用绿色，因为红色稍微有点棘手，因为它需要两个蒙版。红色的色调跨越了179（我们色调范围的上限）和0（下限）之间的边界，因此我们不得不对图像进行两次蒙版处理，然后通过`or`操作将这些蒙版组合起来。你可以使用`cv2.bitwise_or`函数尝试对红色进行蒙版。
- en: Now we have examined how the pipeline will work and its caveats. We've seen
    how this pipeline will fit with PID controllers to create an interesting behavior.
    Let's build this code.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经检查了管道的工作方式和其注意事项。我们看到了这个管道如何与PID控制器结合以创建有趣的行为。让我们构建这段代码。
- en: Enhancing the PID controller
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强PID控制器
- en: We are going to be using more PID controllers. We still don't require the differential
    component, but we will develop an issue with our integral component building up
    while the motors take time to move. The integral has a sum that starts to grow
    if there is a constant error. It is good to correct for that error but it can
    result in a large overshoot. This overshoot, due to the integral still growing
    after the robot has started to react, albeit slowly, is called **integral windup**.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用更多的PID控制器。我们仍然不需要微分组件，但我们将遇到积分组件在电机移动时积累的问题。如果存在恒定误差，积分的求和将开始增长。纠正这个误差是好的，但它可能导致大的超调。由于积分在机器人开始缓慢反应后仍然增长，这种超调称为**积分风上**。
- en: 'We can prevent this sum from getting too large by introducing a windup limit
    to our PID:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向PID中引入风上限制来防止这个求和值变得过大：
- en: 'Open up the `pid_controller.py` file and make the changes in bold in the following
    snippet. First, add the `windup_limit` parameter, which defaults to `None` if
    you don''t set a limit:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`pid_controller.py`文件，并在以下片段中做出粗体字的变化。首先，添加`windup_limit`参数，如果你不设置限制，它默认为`None`：
- en: '[PRE40]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We want to prevent our integral growth if we have a limit and hit it. Our integral
    will change if any of the following occurs:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们有上限并达到它，我们想要防止积分增长。如果以下任何一种情况发生，积分将改变：
- en: a) There is no windup limit (you set it to `None`).
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 没有风上限制（你将其设置为`None`）。
- en: b) The absolute value of the sum is below the windup limit.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 求和的绝对值低于风上限制。
- en: c) The sign of the error would reduce the sum (by being opposed to it).
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 误差的符号会减少求和（因为它与之相反）。
- en: This prevents us from going above the limit if there is one.
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这防止了我们在有上限的情况下超过这个限制。
- en: 'Let''s see this in code—this code will replace the previous `handle_integral`
    method:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看看代码示例——这段代码将替换之前的`handle_integral`方法：
- en: '[PRE41]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can `start` and `stop` this behavior from the web page. If we start moving
    again, we won''t want the PIDs to carry old values. Let''s add a `reset` function
    to zero out the integral sum:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从网页上`start`和`stop`这个行为。如果我们再次开始移动，我们不想让PID携带旧值。让我们添加一个`reset`函数来将积分总和清零：
- en: '[PRE42]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The PID controller is now able to reset and has a windup limit to stop big overshoots.
    Let's build the other behavior components that use it.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: PID控制器现在可以重置，并且有一个防风振限制来停止大的超调。让我们构建使用它的其他行为组件。
- en: Writing the behavior components
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写行为组件
- en: This behavior has two files—a template to pass to our app core with the control
    buttons, and then the main behavior code. Let's start by writing the template.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这个行为有两个文件——一个模板，用于将控制按钮传递给我们的应用核心，然后是主要的行为代码。让我们先编写模板。
- en: Writing the control template
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写控制模板
- en: 'This template is for the stream app, with some different controls:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模板是为流应用设计的，有一些不同的控制项：
- en: Copy the template from `templates/control_image_behavior.html` to `templates/color_track_behavior.html`.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`templates/control_image_behavior.html`模板复制到`templates/color_track_behavior.html`。
- en: 'We will add two further controls to this, `start` and `stop`, displayed here
    in bold:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将添加两个额外的控制项，`start`和`stop`，这里用粗体显示：
- en: '[PRE43]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We intend to run the program with the robot stopped first, so we can tune in
    with our phone or browser, see what the robot is detecting, and click the **Start**
    button to get it moving.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们打算首先停止机器人运行程序，这样我们就可以用手机或浏览器进行微调，查看机器人检测到什么，然后点击**开始**按钮让它移动。
- en: With the template modified, we will need to write the behavior code next.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 模板修改后，我们需要编写行为代码。
- en: Writing the behavior code
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写行为代码
- en: 'We''ll put this new behavior in a file called `color_track_behavior.py`:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个新的行为放入一个名为`color_track_behavior.py`的文件中：
- en: 'It''s no surprise that we start with the imports. Because we are bringing together
    many elements, there are quite a few, but we have seen them all before:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有什么奇怪的，我们首先开始导入。因为我们正在组合许多元素，所以有很多，但我们之前都见过：
- en: '[PRE44]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, we add the `Behavior` class to find and get close to a colored object.
    We pass this the `robot` object:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们添加`Behavior`类来寻找并接近一个彩色对象。我们传递这个`robot`对象：
- en: '[PRE45]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'These values are intended to be tuned for the color mask and object size:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些值旨在针对颜色掩码和对象大小进行调整：
- en: '[PRE46]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The last member variable set here is `running`. This will be set to `True`
    when we want the robot to be moving. When set to `False`, the processing still
    occurs, but the motors and PIDs will stop:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里设置的最后一个成员变量是`running`。当我们想让机器人移动时，它将被设置为`True`。当设置为`False`时，处理仍然发生，但电机和PID将停止：
- en: '[PRE47]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The next bit of code is to process any control instructions from the web app:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一段代码是处理来自Web应用的任何控制指令：
- en: '[PRE48]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Next, we have the code that will find an object from a frame. This implements
    the pipeline shown in *Figure 13.13*. We''ll break this function down a bit, though:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们有代码来从一个帧中找到一个对象。这实现了*图13.13*中显示的管道。不过，我们将稍微分解这个函数：
- en: '[PRE49]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Because this code is complex, we have a documentation string or **docstring**
    explaining what it does and what it returns.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因为这段代码很复杂，所以我们有一个文档字符串或**docstring**来解释它做什么以及它返回什么。
- en: 'Next, the method converts the frame to HSV, so it can be filtered using `inRange`
    to leave only the `masked` pixels from our frame:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，这个方法将帧转换为HSV，这样就可以使用`inRange`进行过滤，只留下我们帧中的`masked`像素：
- en: '[PRE50]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now that we have the masked image, we can draw contours (outline points) around
    it:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了掩码图像，我们可以在它周围绘制轮廓（轮廓点）：
- en: '[PRE51]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The next thing is to find all the enclosing circles for each contour. We use
    a tiny loop to do this. The `minEnclosingCircle` method gets the smallest circle
    that entirely encloses all points in a contour:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是找到每个轮廓的所有包围圆。我们使用一个微小的循环来完成这个操作。`minEnclosingCircle`方法获取完全包围轮廓中所有点的最小圆：
- en: '[PRE52]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'However, we only want the biggest one. Let''s filter for it:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，我们只想得到最大的一个。让我们过滤出来：
- en: '[PRE53]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We end this method by returning the masked image, the largest coordinates,
    and the largest radius:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过返回掩码图像、最大坐标和最大半径来结束这个方法：
- en: '[PRE54]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Our next method will take an original frame and processed frame, then turn
    them into a dual-screen display (two images of the same scale joined together
    horizontally) on the output queue through to the web app:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们下一个方法将接受原始帧和已处理帧，然后将它们转换成双屏显示（两个相同比例的水平拼接图像）并输出到队列，最终传递到Web应用：
- en: '[PRE55]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The next method processes a frame of data through the preceding functions,
    finding the objects and setting the display. It then returns the object info as
    follows:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个方法通过前面的函数处理一帧数据，找到对象并设置显示。然后，它以以下方式返回对象信息：
- en: '[PRE56]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The next method is the actual behavior, turning the preceding coordinates and
    radius into robot movements. When we start our behavior, the pan-and-tilt mechanism
    may not be pointing straight forward. We should ensure that the mechanism is facing
    forward by setting both servos to `0`, then start the camera:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个方法是将前面的坐标和半径转换为机器人运动的实际行为。当我们开始行为时，云台可能不会指向正前方。我们应该确保机制面向前方，将两个伺服电机设置为`0`，然后启动相机：
- en: '[PRE57]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'While the servos are moving and the camera is warming up, we can prepare the
    two PID controllers we need for speed (based on radius) and direction (based on
    distance from the horizontal middle):'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当伺服电机移动且相机预热时，我们可以准备我们需要的两个PID控制器，用于速度（基于半径）和方向（基于水平中间的距离）：
- en: '[PRE58]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: These values I arrived at through much tuning; you may find you need to tune
    these further. The *Tuning the PID controller settings* section will cover how
    to tune the PIDs.
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些值是通过大量调整得到的；你可能需要进一步调整这些值。*调整PID控制器设置*部分将介绍如何调整PID。
- en: 'Now we wait a little while for the camera and pan-and-tilt servos to settle,
    and then we turn off the servos in the center position:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们等待一会儿，让相机和云台伺服电机稳定下来，然后在中位位置关闭伺服电机：
- en: '[PRE59]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We let the user know, with a `print` statement, and output some debug headers:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过`print`语句通知用户，并输出一些调试标题：
- en: '[PRE60]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We can then enter the main loop. First, we get the processed data from the
    frame. Notice we use brackets to unpack `coordinates` into `x` and `y`:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以进入主循环。首先，我们从帧中获取处理后的数据。注意，我们使用括号将`coordinates`解包到`x`和`y`：
- en: '[PRE61]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We should check our control messages at this point. We then check whether we
    are allowed to move, or whether there is any object big enough to be worth looking
    for. If there is, we can start as follows:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，我们应该检查我们的控制消息。然后，我们检查我们是否被允许移动，或者是否有足够大的对象值得寻找。如果有，我们可以这样开始：
- en: '[PRE62]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now we know the robot should be moving, so let''s calculate error values to
    feed the PID controllers. We get the size error and feed it into the speed PID
    to get speed values:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们知道机器人应该移动，所以让我们计算误差值来输入PID控制器。我们获取大小误差并将其输入到速度PID以获取速度值：
- en: '[PRE63]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We use the center coordinate and current object, `x`, to calculate a direction
    error, feeding that into the direction PID:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用中心坐标和当前对象`x`来计算方向误差，并将其输入到方向PID中：
- en: '[PRE64]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'So we can debug this; we print a debug message here matching with the headers
    shown before:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这样我们就可以调试这个了；我们在这里打印一个与之前显示的标题匹配的调试信息：
- en: '[PRE65]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'We can use the speed and direction values to produce left and right motor speeds:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用速度和方向值来产生左右电机速度：
- en: '[PRE66]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We''ve handled what to do when the motors are running. If they are not, or
    there is no object worth examining, then we should stop the motors. If we have
    hit the **Stop** button, we should also reset the PIDs, so they do not accumulate
    odd values:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经处理了电机运行时应该做什么。如果它们没有运行，或者没有值得检查的对象，那么我们应该停止电机。如果我们按下了**停止**按钮，我们还应该重置PID，这样它们就不会积累奇怪的价值：
- en: '[PRE67]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'We have now finished that function and the `ColorTrackingBehavior` class. Now,
    all that is left is to set up our behavior and web app core, then start them:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在已经完成了这个函数和`ColorTrackingBehavior`类。现在，剩下的只是设置我们的行为和Web应用核心，然后启动它们：
- en: '[PRE68]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: This behavior code is built and ready to run. You've seen how to convert the
    image, then mask it for a particular color, and how to draw around the blobs in
    the mask, and then find the largest one. I've also shown you how to turn this
    visual processing into robot moving behavior by feeding this data through PIDs
    and using their output to control motor movements. Let's try it out!
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这段行为代码已经构建并准备好运行。你已经看到了如何转换图像，然后针对特定颜色进行掩码处理，以及如何围绕掩码中的blob绘制，然后找到最大的一个。我还展示了如何通过PID将这种视觉处理转换为机器人移动行为，通过输入这些数据并使用它们的输出控制电机运动。让我们试试吧！
- en: Running the behavior
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行行为
- en: 'I''m sure you are keen to see this working and fix any problems that there
    are. Let''s get into it:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你很想知道这个是如何工作的，并修复任何存在的问题。让我们开始吧：
- en: To run this behavior, you will need to upload `color_track_behavior.py`, the
    modified `pid_controller.py` file, and the template at `templates/color_track_behavior.html`.
    I'll assume that you already have `robot.py` and the other supporting files uploaded.
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行此行为，你需要上传 `color_track_behavior.py`、修改后的 `pid_controller.py` 文件和位于 `templates/color_track_behavior.html`
    的模板。我将假设你已经上传了 `robot.py` 和其他支持文件。
- en: Start the app with `python3 color_track_behavior.py`, which will start the web
    server and wait.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `python3 color_track_behavior.py` 启动应用程序，这将启动网络服务器并等待。
- en: At this point, you should use your browser to connect to `http://myrobot.local:5001`,
    and you should be able to see your robot's image feed.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，你应该使用你的浏览器连接到 `http://myrobot.local:5001`，你应该能够看到你的机器人的图像流。
- en: 'You can see the object and its circle, along with links to control the robot,
    as shown in the screenshot in *Figure 13.14*:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以看到对象及其圆圈，以及控制机器人的链接，如 *图13.14* 中的截图所示：
- en: '![](img/B15660_13_14.jpg)'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B15660_13_14.jpg)'
- en: Figure 13.14 – The color-tracking web app
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.14 – 颜色跟踪网络应用程序
- en: '*Figure 13.14* shows a screenshot of our app server running the code to track
    a colored object. Under the address bar and heading is a dual-screen type output.
    The left has the direct feed from the camera, with a kids'' green bowling pin
    close to the middle and a blue circle outlining the pin, generated by the behavior
    to show it''s tracking the largest matching object. On the right is the mask''s
    output, so we can see what aspects of the image match and tune the mask values
    if we need to. Under this are **Start**, **Stop**, and **Exit** links, to start
    the motors, stop the motors, and exit the program.'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图13.14* 展示了我们的应用程序服务器运行跟踪彩色对象的代码的截图。在地址栏和标题下方是一个双屏类型的输出。左侧是来自摄像头的直接视频流，中间靠近一个儿童绿色保龄球柱，一个蓝色圆圈勾勒出柱子，这是由行为生成的，以显示它正在跟踪最大的匹配对象。右侧是掩码的输出，因此我们可以看到图像的哪些部分匹配，并在需要时调整掩码值。在此之下是**开始**、**停止**和**退出**链接，用于启动电机、停止电机和退出程序。'
- en: To make the robot start moving, press the **Start** button on the web page.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使机器人开始移动，请按网页上的 **开始** 按钮。
- en: When the robot starts moving, you will see the PID debug output in the console
    (PuTTY). This will only show when the robot is running.
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当机器人开始移动时，你将在控制台（PuTTY）中看到PID调试输出。这只有在机器人运行时才会显示。
- en: You can press the **Stop** button on the web page to stop the robot moving or
    the **Exit** button to exit the behavior.
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以按网页上的 **停止** 按钮停止机器人移动或按 **退出** 按钮退出行为。
- en: The robot won't be moving quite right; the movements may be understeering or
    overshooting. You'll need to tune the PID controllers to get this right, as shown
    in the next section.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人可能不会正确移动；动作可能不足或过度。你需要调整PID控制器以获得正确效果，如下一节所示。
- en: Tuning the PID controller settings
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 调整PID控制器设置
- en: I start with a proportional constant of 0.1, and raise it, using `nano` to make
    quick edits on the Pi, until the robot starts to overshoot—that is, it goes past
    its target, then returns far back—then I halve this proportional constant value.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我从比例常数0.1开始，使用 `nano` 在Pi上快速编辑，直到机器人开始过度射击——也就是说，它超过了目标，然后返回很远——然后我将这个比例常数值减半。
- en: 'It may then have a constant error, so I start raising the integral constant
    by about 0.01 to counter this error. Tuning PIDs is a slow process: start by getting
    the object close to dead center and tuning `direction_pid` until it''s pretty
    good, then come back for `speed_pid`.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它可能有一个恒定的误差，所以我开始将积分常数提高约0.01来抵消这个误差。调整PID是一个缓慢的过程：首先将对象移至中心附近，调整 `direction_pid`
    直到它相当不错，然后回来调整 `speed_pid`。
- en: Important note
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Do not try to tweak all the values at once—rather, change one thing and retry.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 不要试图同时调整所有值——而是改变一件事并重试。
- en: For a deeper look at this, see *Tuning a PID controller* in the *Further reading*
    section.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更深入的了解，请参阅 *进一步阅读* 部分的 *调整PID控制器*。
- en: Troubleshooting
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'Color tracking is a tricky behavior, and there are some things that can go
    wrong:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色跟踪是一种棘手的行为，有些事情可能会出错：
- en: If the motors stop or slow down, the simplest fix is to use fresh batteries.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果电机停止或减速，最简单的修复方法是使用新电池。
- en: If there are syntax errors, please check your code carefully.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有语法错误，请仔细检查你的代码。
- en: Ensure that the web app examples work with the camera and that you troubleshoot
    any problems there.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保网络应用程序示例与摄像头兼容，并解决那里出现的问题。
- en: You will need good lighting, as the mask may not pick up poorly lit objects.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要良好的照明，因为掩码可能无法检测到光线不足的对象。
- en: Beware of other objects in the view that may match; the mask may pick up things
    other than your intended items.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小心视野中可能匹配的其他物体；掩码可能会拾取除你想要的项目之外的东西。
- en: Use the web app to check your object is in view and that the mask shows your
    object mostly in white. If not, then you may need to tune the upper and lower
    HSV ranges. The hue is the factor most likely to cause problems, as the saturation
    and value ranges are quite permissive.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用网络应用检查你的物体是否在视野中，并且掩码主要显示为白色。如果不是，那么你可能需要调整HSV的上下范围。色调是最可能引起问题的因素，因为饱和度和值范围相当宽容。
- en: If the robot starts weaving from side to side, you may need to tune the direction
    PID. Reduce the proportional element somewhat.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器人开始从一侧到另一侧编织，你可能需要调整方向PID。稍微减少比例元素。
- en: If the robot barely turns, you can increase the proportional element a little.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器人几乎不转动，你可以稍微增加比例元素。
- en: If the robot is stopped but not facing the detected object, then increase the
    integral element for the direction PID by about 0.01\. If you see the same problems
    moving back and forward, try applying the same tweaks.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器人停止了但不是面向检测到的物体，那么增加方向PID的积分元素大约0.01。如果你在前后移动时遇到相同的问题，尝试应用相同的调整。
- en: You've seen how to track a brightly colored object with a camera, a technique
    you can use to spot objects in a room, or by industrial robots to detect ripe
    fruit. It is quite impressive to watch. However, some objects are more subtle
    than just a color, for example, a human face. In the next section, we look at
    how to use cascading feature matches to pick out objects.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何使用相机跟踪一个颜色鲜艳的物体，这是一种你可以用来在房间里定位物体，或者由工业机器人用来检测成熟水果的技术。观看起来非常令人印象深刻。然而，有些物体比颜色更微妙，例如，人脸。在下一节中，我们将探讨如何使用级联特征匹配来挑选出物体。
- en: Tracking faces with Python
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python跟踪人脸
- en: Detecting faces (or other objects) by features is a smart behavior. Once our
    robot is detecting faces, it will point the pan-and-tilt mechanism at the nearest
    (well, largest) face.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 通过特征检测人脸（或其他物体）是一种智能行为。一旦我们的机器人开始检测人脸，它就会将俯仰和倾斜机制指向最近（好吧，最大的）人脸。
- en: Using **Haar cascades** is a common technique, well documented in a paper by
    Paul Viola and Michael Jones (known as *Viola Jones*). In essence, it means using
    a cascade of feature matches to search for a matching object. We will give an
    overview of this technique, then put it into use on our robot to create a fun
    behavior. Using different cascade model files, we could pick out faces or other
    objects.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**Haar级联**是一种常见技术，在Paul Viola和Michael Jones（被称为*Viola Jones*）的一篇论文中有很好的记录。本质上，这意味着使用一系列特征匹配来搜索匹配的物体。我们将概述这项技术，然后将其应用于我们的机器人以创建一种有趣的行为。使用不同的级联模型文件，我们可以挑选出人脸或其他物体。
- en: Finding objects in an image
  id: totrans-400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在图像中寻找物体
- en: We will be using an algorithm implemented in OpenCV as a single and useful function,
    which makes it very easy to use. It provides a simple way to detect objects. More
    advanced and complex methods involve machine learning, but many systems use Haar
    cascades, including camera apps on phones. Our code will convert the images into
    grayscale (black through gray to white) for this detection method. Each pixel
    here holds a number for the intensity of light.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用OpenCV中实现的一个单一且有用的算法，这使得它非常容易使用。它提供了一种简单的方法来检测物体。更高级和复杂的方法涉及机器学习，但许多系统使用Haar级联，包括手机上的相机应用。我们的代码将图像转换为灰度（从黑到灰再到白）以进行这种检测方法。这里的每个像素都包含一个表示光强度的数字。
- en: 'First, let''s dig into a way of representing these images: integral images.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们深入了解一种表示这些图像的方法：积分图像。
- en: Converting to integral images
  id: totrans-403
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换为积分图像
- en: 'There are two stages applied in the function. The first is to produce an **integral**
    image, or **summed-area table**, as shown in *Figure 13.15*:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 函数中应用了两个阶段。第一个阶段是生成一个**积分**图像，或称为**求和区域表**，如图*图13.15*所示：
- en: '![](img/B15660_13_15.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15660_13_15.jpg)'
- en: Figure 13.15 – Integral images and summed-area tables
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.15 – 积分图像和求和区域表
- en: The left side of *Figure 13.15* shows a *smiling face* type image, with numeric
    pixels representing shades, with larger numbers making for a lighter color. Every
    shade has a number.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.15*的左侧显示了一个*笑脸*类型的图像，其中的数字像素代表阴影，数字越大颜色越浅。每种阴影都有一个数字。'
- en: On the right of *Figure 13.15* is the integral image. Each pixel in the integral
    image is the sum or **integral** of the previous pixels. It adds itself to the
    original pixels above and left of it. The coordinate 2,2 is circled. It is the
    last in a 3x3 grid. The cell here has the value 44\. 44 is the sum of the pixels
    in the highlighted box (9 + 9 + 5 + 9 + 5 + 1 + 5 + 1 + 0).
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图13.15*的右侧是积分图像。积分图像中的每个像素都是之前像素的总和或**积分**。它将自己添加到它上面的原始像素和左边的像素中。坐标2,2被圈出。它是3x3网格中的最后一个。这里的单元格值为44。44是突出显示的框中像素的总和（9
    + 9 + 5 + 9 + 5 + 1 + 5 + 1 + 0）。
- en: When the code sums the pixels, the integral process can use a shortcut and use
    the previous sums. The new sum is equal to the pixel to the left plus the pixel
    above. For example, for a pixel much further down (8,8), also circled in the image,
    we could add all the numbers, but it will be faster to reuse the results we already
    have. We can take the pixel value (1), add the sum above (166), and add the sum
    to the left (164). This sum will have included the middle pixels twice, so we
    need to subtract those, so take away the value up and to the left (146). The sum
    for this would be 1 + 164 + 166 – 146 = 185\. The computer can do this pretty
    quickly.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 当代码对像素进行求和时，积分过程可以使用捷径并使用之前的总和。新的总和等于左边的像素加上上面的像素。例如，对于图像中较远的像素（8,8），也在图中用圆圈标出，我们可以添加所有数字，但重新使用我们已有的结果会更快。我们可以取像素值（1），加上上面的总和（166），再加上左边的总和（164）。这个总和将包括中间像素两次，所以我们需要减去这些像素，所以减去左上角的像素值（146）。这个总和将是1
    + 164 + 166 – 146 = 185。计算机可以非常快速地完成这个操作。
- en: This creates an array of numbers with the same dimensions as the image. Each
    coordinate is the sum of all the pixels' intensities between the current coordinate
    and 0,0.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了一个与图像相同维度的数字数组。每个坐标是当前坐标和0,0之间所有像素强度的总和。
- en: 'Code can use the integral image to quickly find the intensity sum of any rectangle
    in it, of any size. You can start with the bottom-right pixel of the image, then
    subtract the top-right one, leaving the sum of pixels below the top-right pixel.
    We also then want to subtract the bottom-left pixel. This nearly constrains the
    sum to only the rectangle''s pixels, but we would have taken away sections above
    the top-left pixel twice. To correct this, add back the value of the top-left
    pixel:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 代码可以使用积分图像快速找到其中任何矩形区域的强度总和，无论其大小。你可以从图像的右下角像素开始，然后减去右上角的像素，留下右上角像素下方的像素总和。我们还想减去左下角的像素。这几乎将总和限制在只有矩形像素上，但我们已经两次减去了上方左上角的区域。为了纠正这一点，需要将左上角的像素值加回：
- en: '![](img/B15660_13_001.jpg)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_001.jpg)'
- en: The equation works for a small rectangle of 2x2 or a large 300x200 rectangle.
    See the Viola Jones paper in the *Further reading* section for more details. The
    good news is, you don't need to write this code as it's already part of the OpenCV
    classifier. The cascade stage can use this integral image to perform its next
    potent trick quickly.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程适用于2x2的小矩形或300x200的大矩形。在*进一步阅读*部分查看Viola Jones论文以获取更多详细信息。好消息是，你不需要编写这段代码，因为它已经是OpenCV分类器的一部分。级联阶段可以使用这个积分图像快速执行其下一个强大的技巧。
- en: Scanning for basic features
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扫描基本特征
- en: 'The next part of this puzzle is scanning the image for features. The features
    are extremely simple, involving looking for the difference between two rectangles,
    so they are quick to apply. *Figure 13.16* shows a selection of these basic features:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 这个谜题的下一部分是扫描图像以寻找特征。这些特征非常简单，涉及寻找两个矩形之间的差异，因此它们的应用非常快速。*图13.16*展示了这些基本特征的选择：
- en: '![](img/B15660_13_16.jpg)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_16.jpg)'
- en: Figure 13.16 – Simple rectangular feature types
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.16 – 简单矩形特征类型
- en: The top left of *Figure 13.16* shows a left/right feature, where the left pixels
    are set to **1** and the right set to **0** (and shaded). This will match a vertical
    contrast feature. The figure's top right has two rows of **0**s (shaded), two
    rows of **1**s, and then two further rows of shaded **0**s; this will match a
    horizontal bar feature. The middle left has the top three rows set to **1**s and
    the lower three rows shaded and set to **0**s, matching a horizontal contrast
    feature. The figure's middle right has two columns of shaded **0**s, followed
    by two columns of **1**s, and then two further rows of shaded **0**s; this will
    match a vertical bar feature.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.16*的左上角显示了一个左右特征，其中左侧像素设置为**1**，右侧设置为**0**（并着色）。这将匹配垂直对比度特征。图的右上角有两行**0**（着色），两行**1**，然后是两行进一步着色的**0**；这将匹配水平条特征。中间的左侧将顶部三行设置为**1**，底部三行着色并设置为**0**，匹配水平对比度特征。图的中间右侧有两列着色的**0**，接着是两列**1**，然后是两行进一步着色的**0**；这将匹配垂直条特征。'
- en: The bottom image shows a feature with the first few rows as three **1**s followed
    by three **0**s. It follows these rows with three rows of three **0**s andt three
    **1**s. This makes a small checkerboard pattern that will match a feature with
    diagonal contrast.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 底部图像显示一个特征，前几行是三个**1**，然后是三个**0**。接着是三行三个**0**和三个**1**。这形成了一个小棋盘图案，可以匹配具有对角线对比度的特征。
- en: The algorithm will apply rectangles like those from *Figure 13.16* in a particular
    order and relative locations, then each match will *cascade* to a further attempt
    to match another feature. Files describe objects as a set of features. There are
    face cascades with 16,000 features to apply. Applying every single one to every
    part of an image would take a long time. So they are applied in groups, starting
    perhaps with just one. If a feature check fails, that part of the image is not
    subject to further feature tests. Instead, they cascade into later group tests.
    The groups include weighting and applying groups of these features at different
    angles.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 算法将以特定顺序和相对位置应用类似于*图13.16*中的矩形，然后每个匹配项将*级联*到进一步匹配另一个特征的尝试。文件将对象描述为一系列特征。有包含16,000个特征的人脸级联来应用。将每个特征应用到图像的每个部分将花费很长时间。因此，它们以组的形式应用，可能从只有一个开始。如果特征检查失败，则该图像部分将不再进行进一步的特征测试。相反，它们将级联到后续的组测试。这些组包括加权以及在不同角度应用这些特征的组。
- en: If all the feature checks pass, then the checked region is taken as a match.
    For this to work, we need to find the feature cascade that will identify our object.
    Luckily, OpenCV has such a file designed for face recognition, and we have already
    installed it on our Raspberry Pi.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有特征检查都通过，则检查的区域被视为匹配。为此，我们需要找到将识别我们的对象的特征级联。幸运的是，OpenCV有一个为面部识别设计的文件，并且我们已经在我们的Raspberry
    Pi上安装了它。
- en: 'This whole operation of applying the summed area, then using the cascade file
    to look for potential matches, is all available through two OpenCV operations:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 应用累加区域，然后使用级联文件查找潜在匹配项的整个操作，都可通过两个OpenCV操作实现：
- en: '`cv2.CascadeClassifier(cascade_filename)` will open the given cascade file,
    which describes the features to test. The file only needs to be loaded once and
    can be used on all the frames. This is a constructor and returns a `CascadeClassifier`
    object.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.CascadeClassifier(cascade_filename)` 将打开指定的级联文件，该文件描述了要测试的特征。该文件只需加载一次，并且可以在所有帧上使用。这是一个构造函数，返回一个`CascadeClassifier`对象。'
- en: '`CascadeClassifier.detectMultiScale(image)` applies the classifier check to
    an image.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CascadeClassifier.detectMultiScale(image)` 将分类器检查应用于图像。'
- en: You now have a basic understanding of a common face (and object) recognition
    technique. Let's use cascade classifier visual processing with our existing behavior
    experience to plan the face-tracking behavior.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在对常见的（人脸和物体）识别技术有了基本了解。让我们利用现有的行为经验，通过级联分类器的视觉处理来规划人脸追踪行为。
- en: Planning our behavior
  id: totrans-426
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规划我们的行为
- en: 'We can use code fairly similar to our color-tracking behavior to track faces.
    We''ll set our robot up to use the pan-and-tilt mechanism to follow the largest
    face seen in the camera. The block diagram in *Figure 13.17* shows an overview
    of the face behavior:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与我们的颜色追踪行为相当相似的代码来追踪人脸。我们将设置机器人使用俯仰和倾斜机制来跟随相机中看到的最大人脸。*图13.17*中的框图显示了人脸行为的概述：
- en: '![](img/B15660_13_17.jpg)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_13_17.jpg)'
- en: Figure 13.17 – The face-tracking behavior
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.17 – 人脸追踪行为
- en: The flow in *Figure 13.17* will look very familiar. We have the same camera
    to visual behavior to image queue we've seen before. This time, the visual processing
    is `x` and `y` coordinate for the item. We feed position `x` into a PID with center
    `x` to get a pan position, which is then used by the pan servo motor. Position
    `y` is fed to a PID with center `y` and outputs a tilt position to the tilt servos.
    The servos move the camera, creating a feedback loop where the view moves.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.17*中的流程看起来非常熟悉。我们有相同的摄像头到视觉行为到图像队列，我们之前已经见过。这次，视觉处理是项目的`x`和`y`坐标。我们将位置`x`输入到中心为`x`的PID中，以获得一个平移位置，然后由平移伺服电机使用。位置`y`输入到中心为`y`的PID中，输出一个倾斜位置到倾斜伺服电机。伺服电机移动摄像头，创建一个视图移动的反馈循环。'
- en: The differences are in the data we are sending to the PID controllers, and that
    each PID controls a different servo motor.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 差异在于我们发送给PID控制器的数据，以及每个PID控制不同的伺服电机。
- en: Now we have a plan; let's write the code.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个计划；让我们编写代码。
- en: Writing face-tracking code
  id: totrans-433
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写人脸跟踪代码
- en: 'The code for this behavior will seem very familiar—adapting the previous behavior
    code for this purpose. It''s possible that refactoring could yield more common
    code, but it is currently simpler to work with a copy for now. This code will
    go into the `face_track_behavior.py` file. I''ve not even created a new template,
    as the color track template will work just fine for this:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 此行为的代码看起来非常熟悉——将先前行为代码适应此目的。可能重构会产生更多通用代码，但当前使用副本更简单。此代码将放入`face_track_behavior.py`文件。我甚至没有创建一个新的模板，因为颜色跟踪模板对此也适用：
- en: 'The imports are nearly the same as our `color_track_behavior`:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入几乎与我们的`color_track_behavior`相同：
- en: '[PRE69]'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The `init` function for the behavior class is slightly different, starting
    with loading the Haar cascade. There are many other cascade files in the same
    directory, with which you could try to track things other than a face. This code
    uses `assert` to verify that the file exists at the location here because OpenCV
    will instead return cryptic errors in `detectMultiscale` if it cannot find it:'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 行为类的`init`函数略有不同，它从加载Haar级联开始。同一目录下还有许多其他级联文件，你可以尝试跟踪除了人脸之外的其他事物。此代码使用`assert`来验证文件是否存在于此处，因为如果OpenCV找不到它，在`detectMultiscale`中会返回神秘的错误：
- en: '[PRE70]'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The tuning parameters have center positions and a minimum face size. I''ve
    also brought the PID controllers out to the class, so they can be tuned here,
    and then reset in the control handler (you could add the reset to the previous
    behavior too):'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调节参数包括中心位置和最小人脸大小。我还将PID控制器带到了类中，因此它们可以在这里调节，然后在控制处理程序中重置（你还可以将重置添加到先前的行为中）：
- en: '[PRE71]'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Our constructor still tracks whether the behavior is running motors or not:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的构造函数仍然跟踪行为是否正在运行电机：
- en: '[PRE72]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The process control here differs; when the `stop` instruction is received,
    it stops the motors and resets the PIDs:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此处的流程控制不同；当接收到`stop`指令时，它停止电机并重置PID：
- en: '[PRE73]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'This behavior still has a `find_object` method, taking the original frame.
    First, we convert the image to grayscale to reduce the amount of data to search:'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此行为仍然有一个`find_object`方法，它接受原始帧。首先，我们将图像转换为灰度以减少搜索所需的数据量：
- en: '[PRE74]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Next, we use the grayscale image with the cascade `detectMultiScale` method
    to get a list of matches:'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用带有级联`detectMultiScale`方法的灰度图像来获取匹配项列表：
- en: '[PRE75]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We can use a loop similar to the color-tracking behavior to find the largest
    rectangle by area. First, we need to set up a store for the current largest rectangle,
    in a data structure holding the area, then a sub-list containing the `x`, `y`,
    width, and height:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用类似于颜色跟踪行为的循环来通过面积找到最大的矩形。首先，我们需要设置一个存储当前最大矩形的存储库，在一个包含面积的数据结构中，然后是一个包含`x`、`y`、宽度和高度的子列表：
- en: '[PRE76]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'We return the position and dimensions of that largest rectangle:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们返回那个最大矩形的坐标和尺寸：
- en: '[PRE77]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The `make_display` method is simpler than the color-tracking behavior, as there
    is only one image. It must still encode the image, though:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`make_display`方法比颜色跟踪行为简单，因为只有一个图像。尽管如此，它仍然需要编码图像：'
- en: '[PRE78]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The `process_frame` method finds the object and then draws a rectangle on the
    frame for output. The `cv2.rectangle` function takes two coordinates: a starting
    `x`,`y` and an ending `x`,`y`, along with a color value. To get the ending coordinates,
    we need to add the width and height back in:'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`process_frame`方法找到对象，然后在帧上绘制一个矩形进行输出。`cv2.rectangle`函数需要两个坐标：起始`x`、`y`和结束`x`、`y`，以及一个颜色值。为了得到结束坐标，我们需要将宽度和高度加回来：'
- en: '[PRE79]'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Now comes the `run` function. We start with the camera setup and warm-up time:'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来是`run`函数。我们开始于摄像头设置和预热时间：
- en: '[PRE80]'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Like the color-tracking behavior, we start the main loop by processing the
    frame and checking for control instructions:'
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与颜色跟踪行为一样，我们通过处理帧并检查控制指令来启动主循环：
- en: '[PRE81]'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We only want to be moving if we''ve detected a large enough object (using height,
    as faces tend to be bigger in this dimension) and if the robot is running:'
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只想在检测到足够大的对象（使用高度，因为人脸在这个维度上通常更大）并且机器人正在运行时移动：
- en: '[PRE82]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'When we know the robot is running, we feed the PIDs and send the output values
    straight to the servo motors for both pan and tilt. Note that to find the middle
    of the object, we take the coordinate and add half its width or height:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们知道机器人正在运行时，我们将PID和输出值直接发送到伺服电机，用于水平和垂直移动。请注意，为了找到对象的中心，我们取坐标并加上其宽度或高度的一半：
- en: '[PRE83]'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'So that we can track what is going on here, a debug `print` statement is recommended:'
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了跟踪这里发生的事情，建议使用调试`print`语句：
- en: '[PRE84]'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Finally, we need to add the code to set up and run our behavior. Notice that
    we still use the color-tracking template:'
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要添加设置和运行我们行为的代码。请注意，我们仍然使用颜色跟踪模板：
- en: '[PRE85]'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: With the code ready, including the setup functions, we can try it out and see
    the behavior running.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 代码准备就绪，包括设置函数，我们可以尝试运行并查看行为运行。
- en: Running the face-tracking behavior
  id: totrans-470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行人脸跟踪行为
- en: 'To run this behavior, you will need to have uploaded the color-tracking behavior
    files already:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此行为，您需要已经上传了颜色跟踪行为文件：
- en: Upload the `face_track_behavior.py` file.
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传`face_track_behavior.py`文件。
- en: Start using `$ python3 face_track_behavior.py`.
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始使用`$ python3 face_track_behavior.py`。
- en: Send your browser to `http://myrobot.local:5001`. You should see a single frame
    of the camera, with a rectangular outline around the largest face.
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的浏览器导航到`http://myrobot.local:5001`。您应该看到一个摄像头的单帧画面，其中最大的脸周围有一个矩形轮廓。
- en: You must press the **Start** button for the robot to move.
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您必须按下**开始**按钮，机器人才能移动。
- en: The servo motors on the pan-and-tilt mechanism should move to try and put your
    face in the middle of the screen, which will mean the camera is pointed right
    at you. If you move your head around, the camera will (slowly) follow you. If
    you have someone stand behind you, the behavior won't pick them up, but if you
    cover half your face with your hand, it will stop recognizing you, and turn to
    their face instead.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 平移和倾斜机制上的伺服电机应该移动，试图将您的脸放在屏幕中间，这意味着摄像头正对着您。如果您四处移动头部，摄像头会（缓慢地）跟随您。如果您有人在您身后站立，行为不会检测到他们，但如果您用一只手遮住一半的脸，它将停止识别您，并转向他们的脸。
- en: Troubleshooting
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'Start with the troubleshooting steps that we covered for the previous behavior—that
    should get you most of the way—then try these if you need to:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们之前行为中提到的故障排除步骤开始——这应该能解决大部分问题——然后如果您需要，再尝试以下步骤：
- en: 'If the app fails to find the Haar cascade file, check the location for the
    files there. These files have moved between OpenCV packaging versions and may
    do so again. Check that you haven''t mistyped it. If not, then try the following
    command:'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果应用程序找不到Haar级联文件，请检查文件所在位置。这些文件在OpenCV包装版本之间可能已经移动，也可能再次移动。请确认您没有输入错误。如果没有，那么请尝试以下命令：
- en: '[PRE86]'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: This command should show the location of the files on the Raspberry Pi.
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令应显示Raspberry Pi上文件的位置。
- en: If the camera fails to detect faces in the picture, try making sure the area
    is well lit.
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果摄像头无法在图片中检测到人脸，请确保区域有良好的照明。
- en: The detection algorithm is only for faces that face the camera head-on, and
    anything obscuring a part of the face will fool it. It is a little picky, so glasses
    and hats may confuse it.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测算法仅适用于正对摄像头的人脸，任何遮挡人脸一部分的东西都会欺骗它。它有点挑剔，所以眼镜和帽子可能会使其困惑。
- en: Faces only partially in the frame are also likely to be missed. Faces that are
    too far away or small are filtered. Reducing the minimum parameter will pick up
    more objects but generate false positives from tiny face-like objects.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有部分在帧中的人脸也可能被忽略。距离太远或太小的人脸会被过滤。降低最小参数将检测到更多对象，但也会从微小的类似人脸对象中产生误报。
- en: Please check the indentation matches, as this can change the meaning of where
    things happen in Python.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请检查缩进是否匹配，因为这可能会改变Python中事件发生的意义。
- en: You have now made code that will detect and track faces in a camera view. Face-tracking
    behavior is sure to be impressive. Let's summarize what we've seen in this chapter.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在编写的代码将能够在摄像头视图中检测和跟踪人脸。人脸跟踪行为肯定会给人留下深刻印象。让我们总结一下本章所看到的内容。
- en: Summary
  id: totrans-487
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you saw how to set up the Raspberry Pi Camera module. You then
    used it to see what your robot sees—the robot's view of the world.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你看到了如何设置树莓派摄像头模块。然后你使用它来看到机器人看到的世界——机器人的视角。
- en: You got the robot to display its camera as a web app on a phone or desktop,
    and then used the camera to drive smart color- and face-tracking behaviors. I've
    suggested ways the behaviors could be enhanced and hopefully given you a taste
    of what computer vision can do.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 你让机器人将摄像头作为手机或桌面上的Web应用显示，然后使用摄像头来驱动智能颜色和面部跟踪行为。我建议了增强这些行为的方法，并希望让你尝到计算机视觉能做什么。
- en: In the next chapter, we will extend our object-tracking visual processing to
    follow lines with the camera, seeing further ways to use the camera.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将扩展我们的物体跟踪视觉处理，使用摄像头跟踪线条，看到更多使用摄像头的方法。
- en: Exercises
  id: totrans-491
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'This code is fun, but there are many ways you could improve the behaviors.
    Here are some suggested ways to extend this code and deepen your learning:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码很有趣，但你可以用很多方法来改进这些行为。以下是一些扩展此代码并加深你学习的建议方法：
- en: Use the control pipeline to allow a user to tune the color filters, correct
    radius, and PID values from the web page. Perhaps the initial PID values should
    be close to the other tunable values?
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用控制管道允许用户从网页调整颜色过滤器、半径和PID值。也许初始PID值应该接近其他可调整的值？
- en: There is quite a lot of setup code. Could you put this into a function/method?
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有相当多的设置代码。你能把它放入一个函数/方法中吗？
- en: Could the queues to the web page be used to send the debug data to the page,
    instead of printing them in the console? Could the data be plotted in a graph?
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能否将发送到网页的队列用于将调试数据发送到页面，而不是在控制台打印它们？数据能否在图表中绘制？
- en: The field of view for tracking with the Pi Camera is pretty narrow. A wide-angle
    lens would improve the field of view a lot, letting the robot see more.
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Pi摄像头进行跟踪的视野相当窄。一个广角镜头将大大提高视野，让机器人看到更多。
- en: The camera doesn't perform too well when it's dark. The robot has an LED strip,
    but it's not illuminating much. Could you add a bright LED as a headlamp for the
    camera?
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当环境变暗时，摄像头表现不佳。机器人有一个LED灯带，但它并没有提供太多照明。你能为摄像头添加一个明亮的LED作为头灯吗？
- en: You could track other objects by trying the other cascade files found in the
    `/usr/share/opencv/haarcascades` folder on the Raspberry Pi.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过尝试在树莓派上的`/usr/share/opencv/haarcascades`文件夹中找到的其他级联文件来跟踪其他物体。
- en: Perhaps you could try swapping features of the two behaviors to use the servo
    motors to track the colored object, or chase the faces?
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 也许你可以尝试交换两种行为的特征，使用伺服电机来跟踪彩色物体，或者追逐面部？
- en: Could you combine the pan-and-tilt mechanism with the main wheels to track an
    object, then engage the main wheels to chase the matching face and aim to center
    the pan while keeping the object in view? This may require some fancy PID controller
    thinking.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能将俯仰机构与主轮结合来跟踪物体，然后启动主轮来追逐匹配的面部，同时保持摄像头中心对准并保持物体在视野中吗？这可能需要一些复杂的PID控制器思考。
- en: With these ideas, you should have plenty of ways to dig further into this type
    of visual processing.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 有这些想法，你应该有足够多的方法来进一步挖掘这种视觉处理。
- en: Further reading
  id: totrans-502
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Visual processing is a deep topic, so this is only a small selection of places
    where you can read more about using a camera for visual processing:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉处理是一个深奥的话题，所以这只是一个你可以阅读更多关于使用摄像头进行视觉处理的小样本：
- en: '*The Official Raspberry Pi Camera Guide* at [https://magpi.raspberrypi.org/books/camera-guide](https://magpi.raspberrypi.org/books/camera-guide)
    is an excellent resource for getting to know the camera, with many practical projects
    for it.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[官方树莓派摄像头指南](https://magpi.raspberrypi.org/books/camera-guide)是一个了解摄像头的极好资源，其中包含许多实用的项目。'
- en: To delve in far greater depth into using the Raspberry Pi Camera, I recommend
    the PiCamera documentation, available at [https://picamera.readthedocs.io/](https://picamera.readthedocs.io/).
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要更深入地了解使用树莓派摄像头，我推荐PiCamera文档，可在[https://picamera.readthedocs.io/](https://picamera.readthedocs.io/)找到。
- en: To gain insight into further techniques, the PyImageSearch website, at [https://www.pyimagesearch.com](https://www.pyimagesearch.com),
    has great resources.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要深入了解更多技术，PyImageSearch网站[https://www.pyimagesearch.com](https://www.pyimagesearch.com)提供了丰富的资源。
- en: OpenCV and visual processing is a complex topic, only briefly covered here.
    I recommend *OpenCV 3 Computer Vision with Python Cookbook*, by *Alexey Spizhevoy*
    and *Aleksandr Rybnikov*, from *Packt Publishing*, available at [https://www.packtpub.com/application-development/opencv-3-computer-vision-python-cookbook](https://www.packtpub.com/application-development/opencv-3-computer-vision-python-cookbook),
    for more information.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV和视觉处理是一个复杂的话题，这里只是简要介绍。我推荐由*Alexey Spizhevoy*和*Aleksandr Rybnikov*所著，由*Packt
    Publishing*出版的*《OpenCV 3计算机视觉Python食谱》*，可在[https://www.packtpub.com/application-development/opencv-3-computer-vision-python-cookbook](https://www.packtpub.com/application-development/opencv-3-computer-vision-python-cookbook)找到，以获取更多信息。
- en: Streaming video through Flask is a neat trick and is explored further in *Video
    Streaming with Flask*, at [https://blog.miguelgrinberg.com/post/video-streaming-with-flask](https://blog.miguelgrinberg.com/post/video-streaming-with-flask).
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Flask进行视频流是一个巧妙的技巧，在*Video Streaming with Flask*中有更深入的探讨，可在[https://blog.miguelgrinberg.com/post/video-streaming-with-flask](https://blog.miguelgrinberg.com/post/video-streaming-with-flask)找到。
- en: I recommend [https://flaskbook.com/](https://flaskbook.com/) for other neat
    ways to use Flask to manage your robot from your phone or laptop.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我推荐[https://flaskbook.com/](https://flaskbook.com/)，以了解使用Flask从手机或笔记本电脑管理机器人的其他巧妙方法。
- en: Tuning a PID controller—we touched on this in [*Chapter 11*](B15660_11_Final_ASB_ePub.xhtml#_idTextAnchor219),
    *Programming Encoders with Python*, and needed more in this chapter. *Robots For
    Roboticists* | *PID Control*, available at [http://robotsforroboticists.com/pid-control/](http://robotsforroboticists.com/pid-control/),
    is a little heavy on the math but has an excellent section on manually tuning
    a PID.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整PID控制器——我们在[*第11章*](B15660_11_Final_ASB_ePub.xhtml#_idTextAnchor219)《使用Python编程编码器》中提到了这一点，本章需要更多内容。*《为机器人学家的机器人》|
    *PID控制*，可在[http://robotsforroboticists.com/pid-control/](http://robotsforroboticists.com/pid-control/)找到，虽然数学内容较多，但手动调整PID的部分非常出色。
- en: '*Rapid Object Detection Using a Boosted Cascade of Simple Features*, by Paul
    Viola and Michael Jones, available at [https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf).
    This paper, from 2001, discusses in more detail the Haar cascade object-finding
    technique that we used.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《使用简单特征增强的快速目标检测》*，由Paul Viola和Michael Jones所著，可在[https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)找到。这篇2001年的论文更详细地讨论了我们使用的Haar级联目标检测技术。'
- en: A good video introducing face tracking is *Detecting Faces (Viola Jones Algorithm)
    – Computerphile*, available at [https://www.youtube.com/watch?v=uEJ71VlUmMQ](https://www.youtube.com/watch?v=uEJ71VlUmMQ),
    which dives into the combination of techniques used.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一部介绍人脸追踪的好视频是*Detecting Faces (Viola Jones Algorithm) – Computerphile*，可在[https://www.youtube.com/watch?v=uEJ71VlUmMQ](https://www.youtube.com/watch?v=uEJ71VlUmMQ)找到，它深入探讨了所使用的各种技术的组合。
- en: The cascade classification OpenCV documentation, at [https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html](https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html),
    gives a reference for the library functions used in the face-tracking behavior.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV的级联分类文档，位于[https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html](https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html)，提供了在人脸追踪行为中使用的库函数的参考。
- en: 'OpenCV also has a tutorial on face tracking (for version 3.0), called *OpenCV:
    Face Detection using Haar Cascades*, which is available at [https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html](https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html).'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV还有一个关于人脸追踪的教程（针对3.0版本），名为*OpenCV：使用Haar级联进行人脸检测*，可在[https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html](https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html)找到。
