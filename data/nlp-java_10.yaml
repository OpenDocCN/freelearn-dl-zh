- en: Chapter 7. Finding Coreference Between Concepts/People
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章：在概念/人物之间寻找共指
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Named entity coreference with a document
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与文档中的命名实体共指
- en: Adding pronouns to coreference
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向共指中添加代词
- en: Cross-document coreference
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨文档共指
- en: The John Smith problem
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: John Smith问题
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Coreference is a basic mechanism in human language that allows two sentences
    to be about the same thing. It''s a big deal for human communication—it functions
    much in the same way as variable names do in programming languages, with the additional
    subtly that scope is defined by very different rules than blocks. Coreference
    is less important commercially—maybe this chapter will help change that. Here
    is an example:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 共指是人类语言中的一种基本机制，它使得两句话可以指代同一个事物。对人类交流而言，它非常重要——其功能与编程语言中的变量名非常相似，但在细节上，作用范围的定义规则与代码块截然不同。共指在商业上不那么重要——也许本章将帮助改变这一点。这里有一个例子：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Coreference exists between `Alice` and `She`; the phrases talk about the same
    thing. It all gets very interesting when we start asking whether Alice in one
    document is the same as Alice in another.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 共指存在于`Alice`和`She`之间；这些短语指代的是同一个事物。当我们开始探讨一个文档中的Alice是否与另一个文档中的Alice相同时，情况变得非常有趣。
- en: Coreference, like word-sense disambiguation, is a next-generation industrial
    capacity. The challenges of coreference contribute to the insistence of the IRS
    to have a social security number that unambiguously identifies persons independent
    of their names. Many of the techniques discussed were developed to help track
    persons and organizations in text data with varying degrees of success.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 共指，就像词义消歧一样，是下一代的工业能力。共指的挑战促使美国国税局（IRS）坚持要求一个能够明确识别个人的社会保障号码，而不依赖于其名字。许多讨论的技术都是为了帮助跟踪文本数据中的个人和组织，尽管成功程度不一。
- en: Named entity coreference with a document
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与文档中的命名实体共指
- en: As seen in [Chapter 5](ch05.html "Chapter 5. Finding Spans in Text – Chunking"),
    *Finding Spans in Text – Chunking*, LingPipe can use a variety of techniques to
    recognize proper nouns that correspond to persons, places, things, genes, and
    so on. However, chunking doesn't quite finish the job, because it doesn't help
    with finding an entity when two named entities are the same. Being able to say
    that John Smith is the same entity as Mr. Smith, John or even an exact repeat,
    John Smith, can be very useful—so useful that the idea was the basis of our company
    when we were a baby-defense contractor. Our novel contribution was the generation
    of sentences indexed by what entities they mentioned, which turned out to be an
    excellent way to summarize what was being said about that entity, particularly
    if the mapping spanned languages—we call it **entity-based summarization**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第5章](ch05.html "第5章：文本中的跨度 – Chunking")中所见，*文本中的跨度 – Chunking*，LingPipe可以使用多种技术来识别与人、地方、事物、基因等相关的专有名词。然而，分块并未完全解决问题，因为它无法帮助在两个命名实体相同的情况下找到一个实体。能够判断John
    Smith和Mr. Smith、John甚至完全重复的John Smith是同一个实体是非常有用的——它甚至在我们还是一个初创国防承包商时就成为了我们公司成立的基础。我们的创新贡献是生成按实体索引的句子，这种方法证明是总结某个实体所讨论内容的极佳方式，尤其是当这种映射跨越不同语言时——我们称之为**基于实体的摘要化**。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The idea for entity-based summarization came about as a result of a talk Baldwin
    gave at the University of Pennsylvania at a graduate student seminar. Mitch Marcus,
    the then department chair, thought that showing all sentences that mentioned an
    entity—including pronouns—will be an excellent summary of that entity. In some
    sense, this comment is why LingPipe exists. It led to Baldwin leading a UPenn
    DARPA project and then the creation of Alias-i. Lesson learned—talk to everybody
    about your ideas and research.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基于实体的摘要化的想法源自巴尔温在宾夕法尼亚大学研究生研讨会上的一次讲座。时任系主任的米奇·马库斯认为，展示所有提到某个实体的句子——包括代词——将是对该实体的极佳总结。从某种意义上说，这就是LingPipe诞生的原因。这一想法促使巴尔温领导了一个UPenn
    DARPA项目，并最终创立了Alias-i。经验教训——与每个人交流你的想法和研究。
- en: This recipe will take you through the basics of computing coreferences.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将带你了解计算共指的基础知识。
- en: Getting ready
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Lay your hands on some narrative text; we will use a simple example that we
    know works—coreference systems usually need a lot of tuning to the domain. Feel
    free to pick something else, but it will need to be in English.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 拿到一些叙述性文本，我们将使用一个简单的示例，大家知道它是有效的——共指系统通常需要针对特定领域进行大量调整。你可以自由选择其他文本，但它必须是英文的。
- en: How to do it…
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: As usual, we will take you through running code from the command line and then
    dive into what the code actually does. Off we go.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如常，我们将通过命令行运行代码，然后深入分析代码的实际功能。我们开始吧。
- en: 'We will start with a simple text to illustrate coreference. The file is in
    `data/simpleCoref.txt`, and it contains:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从一个简单的文本开始，以说明共指。文件位于`data/simpleCoref.txt`，它包含：
- en: '[PRE1]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Get thee to a command line and a Java interpreter and reproduce the following:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 去命令行和Java解释器那里，复制以下内容：
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This results in:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这会得到以下结果：
- en: '[PRE3]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There are three named entities found. Note that there is an `ID` field in the
    output. The `John Smith` and `Mr. Smith` entities have the same ID, `id=0`. This
    means that the phrases are considered to be coreferent. The remaining entity `Washington`
    has a different ID, `id=1`, and is not coreferent with John Smith / Mr. Smith.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到了三个命名实体。注意，输出中有一个`ID`字段。`John Smith`和`Mr. Smith`实体具有相同的ID，`id=0`。这意味着这些短语被认为是共指的。剩余的实体`Washington`具有不同的ID，`id=1`，并且与John
    Smith / Mr. Smith不共指。
- en: Create your own text file, supply it as an argument on the command line, and
    see what gets computed.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建你自己的文本文件，将其作为参数传递到命令行，看看会计算出什么。
- en: How it works…
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The coreference code in LingPipe is a heuristic system built on top of sentence
    detection and named-entity recognition. The overall flow is as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: LingPipe中的共指代码是建立在句子检测和命名实体识别之上的启发式系统。总体流程如下：
- en: Tokenize the text.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对文本进行分词。
- en: 'Detect sentences in the document, for each sentence, detect named entities
    in the sentence in the left-to-right order, and for each named entity, perform
    the following tasks:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检测文档中的句子，对于每个句子，按从左到右的顺序检测句子中的命名实体，并对每个命名实体执行以下任务：
- en: Create a mention. A mention is a single instance of a named entity.
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个提到。提到是命名实体的单一实例。
- en: Mentions can be added to the existing mention chains, or they can start their
    own mention chains.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提到可以被添加到现有的提到链中，或者可以启动它们自己的提到链。
- en: Try to resolve the mention to a mention chain that is already created. If a
    unique match is found, then add the mention to the mention chain; otherwise, create
    a new mention chain.
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试将提到的实体解析为已创建的提到链。如果找到唯一匹配，则将该提到添加到提到链中；否则，创建一个新的提到链。
- en: 'The code is in `src/com/lingpipe/cookbook/chapter7/NamedEntityCoreference.java`.
    The `main()` method starts by setting up the parts of this recipe, starting with
    a tokenizer factory, sentence chunker, and finally, a named-entity chunker:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码位于`src/com/lingpipe/cookbook/chapter7/NamedEntityCoreference.java`。`main()`方法首先设置这个配方的各个部分，从分词器工厂、句子分块器，到最后的命名实体分块器：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we have set up the basic infrastructure for the recipe. Next is a coreference-specific
    class:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经设置了基本的配方基础设施。接下来是一个共指专用类：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `MentionFactory` class creates mentions from phrases and types—the current
    source is named `entities`. Next, the coreference class is created with `MentionFactory`
    as a parameter:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`MentionFactory`类从短语和类型创建提到——当前的源被命名为`entities`。接下来，共指类会以`MentionFactory`作为参数创建：'
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `WithinDocCoref` class wraps all the mechanics of computing coreference.
    From [Chapter 5](ch05.html "Chapter 5. Finding Spans in Text – Chunking"), *Finding
    Spans in Text - Chunking*, you should be familiar with the code to get the document
    text, detect sentences, and iterate over the sentences that apply a named-entity
    chunker to each sentence:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`WithinDocCoref`类封装了计算共指的所有机制。从[第5章](ch05.html "第5章 查找文本中的跨度 – 分块")，*查找文本中的跨度
    – 分块*，你应该熟悉获取文档文本、检测句子，并遍历应用命名实体分块器到每个句子的代码：'
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the context of the current sentence, the named entities from the sentence
    are iterated over in the left-to-right order as they would be read. We know this
    because the `ChunkingImpl` class returns chunks in the order that they were added,
    and our `HMMChunker` adds them in the left-to-right order:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前句子的上下文中，句子中的命名实体会按从左到右的顺序进行迭代，就像它们被阅读的顺序一样。我们知道这一点是因为`ChunkingImpl`类按照它们被添加的顺序返回块，而我们的`HMMChunker`是以从左到右的顺序添加它们的：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following code takes the information from the chunk—type and phrase, but
    *not* the offset information, and creates a mention:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码从分块中获取信息——类型和短语，但*不*包括偏移信息，并创建一个提到：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next line runs coreference with the mention and what sentence it is in
    and returns its ID:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下一行与提到的内容进行共指，并返回它所在的句子的ID：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If the mention was resolved to an existing entity, it will have that ID, as
    we saw with Mr. Smith. Otherwise, it will get a distinct ID and itself be available
    as an antecedent for subsequent mentions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提及已解析为现有实体，它将具有该ID，正如我们在Mr. Smith例子中看到的那样。否则，它将获得一个独立的ID，并且可以作为后续提及的先行词。
- en: This covers the mechanics of running within a document coreference. The upcoming
    recipes will cover the modification of this class. The next recipe will add pronouns
    and provide references.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这涵盖了在文档内运行共指关系的机制。接下来的配方将介绍如何修改这个类。下一个配方将添加代词并提供引用。
- en: Adding pronouns to coreference
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向共指关系中添加代词
- en: The preceding recipe handled coreference between named entities. This recipe
    will add pronouns to the mix.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的配方处理了命名实体之间的共指关系。这个配方将把代词添加到其中。
- en: How to do it…
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: This recipe will use an interactive version to help you explore the properties
    of the coreference algorithm. The system is very dependent on the quality of the
    named-entity detection, so use examples that the HMM is likely to get right. This
    was trained on *Wall Street Journal* articles from the '90s.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方将使用交互式版本帮助你探索共指算法的特性。该系统非常依赖命名实体检测的质量，因此请使用HMM可能正确识别的例子。它是在90年代的*华尔街日报*文章上进行训练的。
- en: 'Saddle up your console and type the following command:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动你的控制台并键入以下命令：
- en: '[PRE11]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the resulting command prompt, type this:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在结果命令提示符中，键入以下内容：
- en: '[PRE12]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The shared ID between `He` and `John Smith` indicates the coreference between
    the two. More examples will follow, with comments. Note that each input is considered
    a distinct document with separate ID spaces.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`He`和`John Smith`之间的共享ID表示它们之间的共指关系。接下来会有更多的例子和注释。请注意，每个输入被视为具有独立ID空间的不同文档。'
- en: 'If pronouns are not resolved to a named entity, they get the index `-1` as
    shown here:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果代词没有解析为命名实体，它们会得到`-1`的索引，如下所示：
- en: '[PRE13]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following case also results in a `-1` value for `id`, because there is
    not one unique person in the prior context but two. This is called a failed uniqueness
    presupposition:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下情况也会导致`id`为`-1`，因为在先前的上下文中没有唯一的一个人，而是两个人。这被称为失败的唯一性预设：
- en: '[PRE14]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following code shows that `John Smith` can be resolved to a female pronoun
    as well. This is because there is no data about what names indicate which genders.
    It can be added, but generally, the context will disambiguate. `John` could be
    a female name. The key here is that the pronoun will disambiguate the gender,
    and a following male pronoun will fail to match:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码显示了`John Smith`也可以解析为女性代词。这是因为没有关于哪些名字表示哪种性别的数据。可以添加这类数据，但通常上下文会消除歧义。`John`也可能是一个女性名字。关键在于，代词会消除性别歧义，后续的男性代词将无法匹配：
- en: '[PRE15]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The gender assignment will block reference by an incorrect gender. The `He`
    pronoun in the following code is resolved to ID `-1`, because the only person
    is resolved to a female pronoun:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 性别分配将阻止错误性别的引用。以下代码中的`He`代词被解析为ID`-1`，因为唯一的人被解析为女性代词：
- en: '[PRE16]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Coreference can happen inside a sentence as well:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 共指关系也可以发生在句子内部：
- en: '[PRE17]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The order of the mentions (ordered by the most recent mention) matters when
    resolving mentions. In the following code, `He` is resolved to `James`, not `John`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提及的顺序（按最新提及排序）在解析提及时很重要。在以下代码中，`He`被解析为`James`，而不是`John`：
- en: '[PRE18]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The same effect takes place with named-entity mentions. The `Mr. Smith` entity
    resolves to the last mention:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 命名实体提及也会产生相同的效果。`Mr. Smith`实体解析为最后一次提及：
- en: '[PRE19]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The distinction between `John` and `James` goes away if there are too many
    intervening sentences:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果插入太多句子，`John`和`James`之间的区别将消失：
- en: '[PRE20]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The preceding examples are meant to demonstrate the properties of the within-document
    coreference system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子旨在展示文档内共指关系系统的特性。
- en: How it works…
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The code changes to add pronouns are straightforward. The code for this recipe
    is in `src/com/lingpipe/cookbook/chapter7/Coreference.java`. The recipe assumes
    that you understood the previous recipe, so it just covers the addition of pronoun
    mentions:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 添加代词的代码变化非常直接。此配方的代码位于`src/com/lingpipe/cookbook/chapter7/Coreference.java`。该配方假设你理解了前一个配方，因此这里只涵盖了代词提及的添加：
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We added the `Mention` objects from multiple sources, so there are no order
    guarantees on the order of elements anymore. Correspondingly, we created `TreeSet`
    and the appropriate comparator and added all the chunkings from the `neChunker`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从多个来源添加了`Mention`对象，因此元素的顺序不再有保证。相应地，我们创建了`TreeSet`和适当的比较器，并将所有来自`neChunker`的分块添加到其中。
- en: 'Next, we will add the male and female pronouns:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将添加男性和女性代词：
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `MALE_EN_PRONOUNS` constant is a regular expression, `Pattern`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`MALE_EN_PRONOUNS`常量是一个正则表达式，`Pattern`：'
- en: '[PRE23]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following lines of code show the `addRegExMatchingChunks` subroutine. It
    adds chunks based on regular expression matches and removes the overlapping, existing
    HMM-derived chunks:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行展示了`addRegExMatchingChunks`子程序。它根据正则表达式匹配添加片段，并移除重叠的、已有的HMM派生片段：
- en: '[PRE24]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The one complex bit is that the type for the `MALE_PRONOUN` and `FEMALE_PRONOUN`
    pronouns will be used to match against `PERSON` entities, with the consequence
    that the resolution sets the gender of the resolved-to entity.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂之处在于，`MALE_PRONOUN`和`FEMALE_PRONOUN`代词的类型将用于与`PERSON`实体匹配，结果是解析过程会设置被解析实体的性别。
- en: Other than that, the code should look very familiar with our standard I/O loop
    running the interaction in the command prompt.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，代码应与我们标准的I/O循环非常相似，该循环在命令提示符中运行交互。
- en: See also
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The algorithm behind the system is based on the PhD. thesis of Baldwin. The
    system was called CogNIAC, and the work is from the mid '90s and is not a current
    state-of-the-art coreference system. A more modern approach would most likely
    use a machine-learning framework to take the features generated by Baldwin's approach
    and many other features and use it to develop a better performing system. A paper
    on the system is at [http://www.aclweb.org/anthology/W/W97/W97-1306.pdf](http://www.aclweb.org/anthology/W/W97/W97-1306.pdf).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 系统背后的算法基于Baldwin的博士论文。该系统名为CogNIAC，工作始于90年代中期，并非当前最先进的共指消解系统。更现代的方法很可能会使用机器学习框架，利用Baldwin方法生成的特征和其他许多特征来开发一个性能更好的系统。有关该系统的论文可见于[http://www.aclweb.org/anthology/W/W97/W97-1306.pdf](http://www.aclweb.org/anthology/W/W97/W97-1306.pdf)。
- en: Cross-document coreference
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨文档共指
- en: Cross-document coreference (XDoc) takes the `id` space of an individual document
    and makes it global to a larger universe. This universe typically includes other
    processed documents and databases of known entities. While the annotation is trivial,
    all that one needs to do is swap the document-scope IDs for the universe-scope
    IDs. The calculation of XDoc can be quite difficult.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 跨文档共指（XDoc）将单个文档的`id`空间扩展到更广泛的宇宙。这一宇宙通常包括其他处理过的文档和已知实体的数据库。虽然注解本身非常简单，只需将文档范围内的ID替换为宇宙范围内的ID即可，但计算XDoc可能相当复杂。
- en: This recipe will tell us how to use a lightweight implementation of XDoc developed
    over the course of deploying such systems over the years. We will provide a code
    overview for those who might want to extend/modify the code—but there is a lot
    going on, and the recipe is quite dense.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将告诉我们如何使用在多年部署此类系统过程中开发的轻量级XDoc实现。我们将为那些可能希望扩展/修改代码的人提供代码概述，但内容较为复杂，教程也相当密集。
- en: 'The input is in the XML format where each file can contain multiple documents:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输入采用XML格式，其中每个文件可以包含多个文档：
- en: '[PRE25]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The goal is to produce annotations where the mentions of Breck Baldwin share
    the same ID across documents as for Krishna. Note that both are mentioned by their
    nicknames in the last document.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是生成注解，其中Breck Baldwin的提及在各个文档中共享与Krishna相同的ID。注意，在最后一篇文档中，二者都是以昵称被提及的。
- en: A very common elaboration of XDoc is linking a **database** (**DB**) of known
    entities to text mentions of these entities. This bridges the divide between structured
    DB and unstructured data (text), which many consider to be the next big thing
    in business intelligence / voice of the customer / enterprise-knowledge management.
    We have built systems that linked DBs of genes/proteins to MEDLINE abstracts and
    persons-of-interest lists to free text, and so on. DBs also provide a natural
    way for human editors to control how XDoc behaves.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: XDoc的一个常见扩展是将已知实体的**数据库**（**DB**）与文本中提到的这些实体进行链接。这弥合了结构化数据库和非结构化数据（文本）之间的鸿沟，许多人认为这是商业智能/客户声音/企业知识管理中的下一个重要发展方向。我们曾构建过将基因/蛋白质数据库与MEDLINE摘要、以及人物关注名单与自由文本等链接的系统。数据库还为人工编辑提供了一种自然的方式来控制XDoc的行为。
- en: How to do it...
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: All the code for this recipe is in the `com.lingpipe.cookbook.chapter7.tracker`
    package.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱的所有代码都位于 `com.lingpipe.cookbook.chapter7.tracker` 包中。
- en: 'Gain access to your IDE and run `RunTracker` or type the following command
    in the command line:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问您的 IDE 并运行 `RunTracker`，或者在命令行中输入以下命令：
- en: '[PRE26]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The screen will scroll by with the analysis of documents, but we will go to
    the designated output file and examine it. Open `cookbook/data/xDoc/output/docs1.xml`
    in your favorite text editor. You will see a poorly formatted version of the example
    output, unless your editor automatically formats XML usefully—the Firefox web
    browser does a decent job of rendering XML. The output should look like this:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 屏幕将会滚动，显示文档分析的过程，但我们将转到指定的输出文件并进行查看。用您喜欢的文本编辑器打开 `cookbook/data/xDoc/output/docs1.xml`。您将看到一个格式不佳的示例输出版本，除非您的编辑器能够自动格式化
    XML（例如，Firefox 浏览器能较好地呈现 XML）。输出应如下所示：
- en: '[PRE27]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`Krishna` is recognized in the first two documents with the shared ID, `1000000002`,
    but the nickname, `K-dog`, is not recognized at all. `Breck` is recognized in
    all three documents, but since the ID on the third mention, `Breckles`, is different
    from the one in the first two mentions, the system does not consider them to be
    the same entity.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Krishna` 在前两份文档中被共享 ID `1000000002` 识别，但昵称 `K-dog` 完全没有被识别。`Breck` 在所有三份文档中都被识别，但由于第三次提到的
    ID `Breckles` 与前两次提到的不同，系统认为它们不是同一个实体。'
- en: 'Next, we will use a DB in the form of a dictionary to improve the recognition
    of the authors when they are mentioned via nicknames. There is a dictionary at
    `data/xDoc/author-dictionary.xml`; it looks like this:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用字典形式的数据库来提高当作者通过昵称提及时的识别度。`data/xDoc/author-dictionary.xml` 中有一个字典，内容如下：
- en: '[PRE28]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The aforementioned dictionary contains nicknames for both authors, in addition
    to their first names. Aliases that have the `xdc=1` value will be used to link
    entities across documents. The `xdc=0` value will only apply within a document.
    All aliases will be used to identify named entities via a dictionary lookup.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述字典包含了两位作者的昵称，以及他们的名字。带有 `xdc=1` 值的别名将用于跨文档链接实体。`xdc=0` 值只会在单个文档内应用。所有别名将通过字典查找来识别命名实体。
- en: 'Run the following command, which specifies the entity dictionary or IDE equivalent:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令，指定实体字典或相应的 IDE 等效项：
- en: '[PRE29]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output in `xDoc/output/docs1.xml` is very different from that of the previous
    run. First, note that the IDs for us are now the same as specified in the dictionary
    file: `1` for `Breck` and `2` for `Krishna`. This is a link between the structured
    DB, such as the nature of the dictionary and unstructured text. Second, notice
    that both our nicknames have been correctly identified and assigned to the correct
    IDs. Third, note that the types are now `MALE` instead of `OTHER`:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`xDoc/output/docs1.xml` 中的输出与上次运行的结果有很大不同。首先，注意现在的 ID 与字典文件中指定的相同：`Breck` 的
    ID 为 `1`，`Krishna` 的 ID 为 `2`。这是结构化数据库（如字典的性质）与非结构化文本之间的联系。其次，注意到我们的昵称已经被正确识别并分配到正确的
    ID。第三，注意到类型现在是 `MALE`，而不是 `OTHER`：'
- en: '[PRE30]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This was a very quick introduction to how to run XDoc. In the next section,
    we will see how it works.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对如何运行 XDoc 的简要介绍。在接下来的部分，我们将看到它是如何工作的。
- en: How it works…
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Up until this recipe, we have attempted to keep code simple, straightforward,
    and understandable without a deep dive into piles of source. This recipe is more
    complicated. The code that backs this recipe is not going to fit into the allocated
    space for complete explanation. The exposition assumes that you will explore entire
    classes on your own and that you will refer to other recipes in this book for
    explanation. We offer this recipe because XDoc coreference is a very interesting
    problem, and our existing infrastructure might help others explore the phenomenon.
    Welcome to the deep end of the pool.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这道食谱之前，我们一直尝试保持代码简单、直观并且易于理解，而不深入探讨大量源代码。这道食谱更为复杂。支撑这个食谱的代码无法完全放入预定的空间中进行解释。此处的阐述假设您会自行探究整个类，并参考本书中的其他食谱进行说明。我们提供这道食谱是因为
    XDoc 核心参考是一个非常有趣的问题，我们现有的基础设施可能帮助其他人探索这一现象。欢迎来到游泳池的深水区。
- en: The batch process life cycle
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理生命周期
- en: 'The entire process is controlled by the `RunTracker.java` class. The overall
    flow of the `main()` method is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程由 `RunTracker.java` 类控制。`main()` 方法的总体流程如下：
- en: Read the DB of known entities that will be a source of named-entity recognition
    via `Dictionary` and a known mapping from aliases to dictionary entries. Aliases
    come with instructions regarding whether they should be used for matching entities
    across documents via the `xdc=1` or `xdc=0` flag.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取已知实体的数据库，这些实体将通过`Dictionary`进行命名实体识别，并且存在从别名到字典条目的已知映射。别名包含关于是否应该通过`xdc=1`或`xdc=0`标志用于跨文档匹配实体的说明。
- en: Set up `EnitityUniverse`, which is the global data structure of IDs for what
    is found in the texts and from the mentioned dictionary of known entities.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置`EntityUniverse`，它是文本中找到的实体及已知实体字典的全局ID数据结构。
- en: Set up what is needed for within-document coreference—things such as a tokenizer,
    sentence detector, and named-entity detector. It gets a bit fancy with a POS tagger
    and some word counts.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置文档内核心指代所需的内容——例如分词器、句子检测器和命名实体检测器。还会用到一些POS标注器和词汇计数器，处理得稍微复杂一些。
- en: There is a Boolean that controls whether speculative entities will be added.
    If this Boolean is `true`, it means that we will update our universe of cross-document
    entities with the ones that we have never seen before. It is a much tougher task
    to reliably compute with this set to `true`.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有一个布尔值控制是否会添加推测性实体。如果该布尔值为`true`，则表示我们会将从未见过的实体添加到跨文档实体的宇宙中。将该值设置为`true`时，可靠地计算是更具挑战性的任务。
- en: All the mentioned configuration goes into creating a `Tracker` object.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有提到的配置都用于创建`Tracker`对象。
- en: 'Then, the `main()` method reads in documents to process, hands them off to
    the `Tracker` object for processing, and writes them to disk. The major steps
    of the `Tracker.processDocuments()` method are as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，`main()`方法读取待处理的文档，将其交给`Tracker`对象进行处理，并将处理结果写入磁盘。`Tracker.processDocuments()`方法的主要步骤如下：
- en: Take a set of documents in the XML format and get the individual documents.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取一组XML格式的文档，并获取单个文档。
- en: For each document, apply the `processDocument()` method, which runs within-document
    coreference using the dictionary to help find entities as well as the named-entity
    detector and returns `MentionChain[]`. Then, resolve the individual mentions'
    chains against the entity universe to update document-level IDs to entity universe
    IDs. The last step is to write the document to disk with the entity universe IDs.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个文档，应用`processDocument()`方法，该方法使用字典进行文档内核心指代分析，帮助查找实体以及命名实体检测器，并返回`MentionChain[]`。然后，将每个提及的链条与实体宇宙进行对比，以更新文档级ID为实体宇宙ID。最后一步是将文档写入磁盘，带上实体宇宙ID。
- en: That is all that we will say about `RunTracker`; there is nothing in there that
    you should not be able to handle in the context of this book. In the following
    sections, we will address the individual components that `RunTracker` uses.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以上就是我们要说的关于`RunTracker`的内容，里面没有任何你在本书中无法处理的内容。在接下来的章节中，我们将讨论`RunTracker`使用的各个组成部分。
- en: Setting up the entity universe
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设置实体宇宙
- en: The entity universe `EntityUniverse.java`, is an in-memory representation of
    the global entities mentioned in a document/database collection. The entity universe
    also contains various indexes into these entities, which support computing XDoc
    on individual documents.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实体宇宙`EntityUniverse.java`是文档/数据库集合中提到的全局实体的内存表示。实体宇宙还包含指向这些实体的各种索引，支持在单个文档上计算XDoc。
- en: The dictionary seeds the `EntityUniverse` file with known entities, and the
    documents processed subsequently are sensitive to these entities. The XDoc algorithm
    tries to merge with existing entities before creating new ones, so the dictionary
    entities are strong attractors for mentions of these entities.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 字典将已知实体填充到`EntityUniverse`文件中，随后处理的文档会对这些实体敏感。XDoc算法尝试在创建新实体之前与现有实体合并，因此字典中的实体会强烈吸引这些实体的提及。
- en: 'Each entity consists of a unique long ID, a set of aliases partitioned into
    four separate lists and a type (person, location, and so on). Whether the entity
    is in the user-defined dictionary and whether speculative mentions are allowed
    to be added to the entity are also mentioned. The `toString()` method lists an
    entity as:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个实体由唯一的长整型ID、一组分为四个单独列表的别名和一个类型（如人、地点等）组成。还会说明该实体是否在用户定义的字典中，以及是否允许添加推测性提及到该实体。`toString()`方法将实体列出为：
- en: '[PRE31]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The global data structures are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 全局数据结构如下：
- en: '[PRE32]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Entities need unique IDs, and we have a convention that the `FIRST_SYSTEM_ID`
    value is a large integer, such as `1,000,000`. This provides a space (IDs < 1,000,000)
    for users to add new entities without collisions with entities found by the system.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 实体需要唯一的ID，我们约定`FIRST_SYSTEM_ID`的值是一个大整数，比如`1,000,000`。这样可以为用户提供一个空间（ID < 1,000,000），以便他们在不会与系统已发现的实体发生冲突的情况下添加新实体。
- en: 'We will instantiate a tokenizer for use across the tracker:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为整个跟踪器实例化一个分词器：
- en: '[PRE33]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'There is a global mapping from unique entity IDs to the entities:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个全局映射，将唯一的实体ID映射到实体：
- en: '[PRE34]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Another important data structure is a mapping from aliases (phrases) to entities
    that have the alias—`mXdcPhraseToEntitySet`. Only phrases that are candidates
    for finding likely matches for cross-document coreference get added here. From
    the dictionary, the aliases that are `xdc=1` are added:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的数据结构是一个将别名（短语）映射到拥有该别名的实体的映射——`mXdcPhraseToEntitySet`。只有那些可以作为跨文档共指候选的短语才会被添加到这里。从字典中，`xdc=1`的别名会被添加进来：
- en: '[PRE35]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: For speculatively found aliases, if the alias has at least two tokens and is
    not already on another entity, it is added to this set. This reflects a heuristic
    that tries hard to not split the entities apart. The logic of this is quite twisted
    and beyond the scope of this tutorial. You can refer to `EntityUniverse.createEntitySpeculative`
    and `EntityUniverse.addPhraseToEntity` for the code.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推测性找到的别名，如果该别名至少包含两个标记且尚未关联到其他实体，则将其添加到此集合中。这反映了一种启发式方法，力求不拆分实体。这一逻辑相当复杂，超出了本教程的范畴。你可以参考`EntityUniverse.createEntitySpeculative`和`EntityUniverse.addPhraseToEntity`中的代码。
- en: Why are some aliases not used in finding candidate entities? Consider that `George`
    has very little descriptive content to discriminate entities in `EntityUniverse`,
    but `George H.W. Bush` has much more information to work with.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么有些别名在寻找候选实体时不被使用？考虑到`George`对`EntityUniverse`中的实体区分帮助不大，而`George H.W. Bush`则提供了更多的信息用于区分。
- en: ProcessDocuments() and ProcessDocument()
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ProcessDocuments()和ProcessDocument()
- en: 'The interesting bits start to happen in the `Tracker.processDocuments()` method,
    which calls the XML parsing of each document and then incrementally calls the
    `processDocument()` method. The code is straightforward for the former, so we
    will move on to where the more task-specific work happens with the `processDocument()`
    method called:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的部分开始出现在`Tracker.processDocuments()`方法中，该方法调用每个文档的XML解析，然后逐步调用`processDocument()`方法。前者的代码比较简单，因此我们将跳到更具任务特定性的工作部分，即调用`processDocument()`方法时的逻辑：
- en: '[PRE36]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We used a document format that supports distinguishing the title from the body
    of the document. This is a good idea if title case is distinct from body case,
    as is usual with newswire. The `chains` variable will have chains from the title
    and body of the text, with possible coreference between them. The `mentionStartList`
    and `mentionEndList` arrays will make it possible to realign the document scoped
    IDs with the entity universe scoped IDs later in the method:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一种文档格式，可以将标题与正文区分开来。如果标题格式与正文格式有所不同，这种做法是一个好主意，就像新闻稿中通常所做的那样。`chains`变量将包含来自标题和正文的链条，其中可能存在相互指代的情况。`mentionStartList`和`mentionEndList`数组将在方法的后续步骤中使得重新对齐文档范围内的ID与实体宇宙范围内的ID成为可能：
- en: '[PRE37]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Computing XDoc
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算XDoc
- en: The XDoc code is the result of many hours of hand-tuning the algorithm to work
    well on news-style data. It has been run on datasets in the 20,000 document range
    and is designed to support dictionary entries very aggressively. The code also
    attempts to prevent **short circuits**, which occur when obviously different entities
    have been merged together. If you mistakenly make Barbara Bush and George Bush
    coreferent in your global database, then you will have embarrassingly bad results
    that users will see.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: XDoc代码是通过多小时手动调试算法的结果，旨在处理新闻风格的数据。它已经在20,000文档范围的数据集上运行，并且设计上非常积极地支持词典条目。该代码还试图避免**短路**，即当显然不同的实体被合并在一起时会发生的错误。如果你错误地将芭芭拉·布什和乔治·布什视为同义词，那么结果将会非常尴尬，用户将看到这些错误。
- en: The other sort of error is having two entities in the global store when one
    will do. This is a sort of *Superman/Clark Kent problem* that can also apply to
    multiple mentions of the same name.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种错误是全局存储中有两个实体，而实际上一个就足够了。这类似于*超人/克拉克·肯特问题*，同样也适用于多次提及同一个名字的情况。
- en: 'We will begin with the top-level code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从顶层代码开始：
- en: '[PRE38]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: A document has a list of mention chains, and each mention chain will be either
    added to an existing entity, or the mention chain will be promoted to being a
    new entity. Mention chains must contain a mention that is not pronominal, which
    is handled at the within-document coreference level.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一个文档包含一个提及链列表，每个提及链要么被添加到现有实体中，要么被提升为一个新实体。提及链必须包含一个非代词的提及，这在文档内的共指层面上进行处理。
- en: 'Three data structures are updated as each mention chain is processed:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理每个提及链时，会更新三种数据结构：
- en: The `Entity[]` entities are returned by the `xdocCoref` method to support the
    inline annotation of the documents.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Entity[]` 实体由 `xdocCoref` 方法返回，以支持文档的内联注解。'
- en: '`Map<MentionChain,Entity> chainToEntity` maps from mention chains to entities.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Map<MentionChain,Entity> chainToEntity` 将提及链映射到实体。'
- en: '`ObjectToSet<Entity,MentionChain> entityToChainSet` is the converse of `chainToEntity`.
    It is possible that multiple chains in the same document get mapped to the same
    entity, so this data structure is sensitive to this possibility. This version
    of the code allows this to happen—in effect, XDoc is setting up a within-doc resolution
    as a side effect.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ObjectToSet<Entity,MentionChain> entityToChainSet` 是 `chainToEntity` 的反向映射。可能同一文档中的多个链条映射到同一实体，因此这个数据结构要考虑到这种可能性。该版本的代码允许这种情况发生——实际上，XDoc
    正在以副作用的方式设置文档内的共指解析。'
- en: Simple enough, if an entity is found, then the `addMentionChainToEntity()` method
    adds any new information from the mention chain to the entity. New information
    can include new aliases and type changes (that is, a person is moved to being
    male or female in virtue of a disambiguating pronoun reference). If no entity
    is found, then the mention chain goes to `promote()`, which creates a new entity
    in the entity universe. We will start with `promote()`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，如果找到了实体，`addMentionChainToEntity()` 方法会将提及链中的任何新信息添加到该实体中。新信息可能包括新别名和类型变化（例如，通过消歧代词引用将一个人从无性别转变为男性或女性）。如果没有找到实体，那么提及链会被送到
    `promote()`，它会在实体宇宙中创建一个新实体。我们将从 `promote()` 开始。
- en: The promote() method
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`promote()` 方法'
- en: 'The entity universe is a minimalist data structure that just keeps track of
    phrases, types, and IDs. The `TTMentionChain` class is a more complex representation
    of the mentions of a particular document:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 实体宇宙是一个极简的数据结构，仅记录短语、类型和 ID。`TTMentionChain` 类是特定文档中提及的更复杂的表示形式：
- en: '[PRE39]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The call to `mEntityUniverse.createEntitySpeculative` only requires the phrases
    for the chain (in this case, normalized phrases that have been lowercased and
    in which all sequences of whitespaces converted into a single space) and the type
    of the entity. No record is kept of the document from which the mention chain
    came, counts, or other potentially useful information. This is to keep the memory
    representation as small as possible. If there is a need to find all the sentences
    or documents that an entity is mentioned in (a common task), then that mapping
    from entity IDs has to be stored elsewhere. The XML representation produced for
    the document after XDoc is run is a natural place to start addressing these needs.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `mEntityUniverse.createEntitySpeculative` 的调用只需要链条的短语（在这种情况下，已归一化为小写且所有空格序列被转换为单个空格的短语）以及实体的类型。不会记录提及链来自的文档、计数或其他潜在有用的信息。这样做是为了尽量减小内存表示。如果需要查找实体被提及的所有句子或文档（这是一个常见任务），那么实体
    ID 到文档的映射必须存储在其他地方。XDoc 执行后生成的文档 XML 表示是解决这些需求的一个自然起点。
- en: The createEntitySpeculative() method
  id: totrans-162
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`createEntitySpeculative()` 方法'
- en: 'Creation of a speculatively found new entity only requires determining which
    of its aliases are the good candidates to link mention chains. Those that are
    good for cross-document coreference go into the `xdcPhrases` set, and the others
    go into the `nonXdc` phrases:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个推测性找到的新实体只需要确定哪些别名是将提及链连接起来的好候选。适合跨文档共指的那些别名进入 `xdcPhrases` 集合，其他的进入 `nonXdc`
    短语集合：
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `boolean` method, `XdcPhrase()`, plays a critical role in the XDoc process.
    The current approach supports a very conservative notion of what a good XDoc phrase
    is. Intuitively, in the domain of newswire, phrases such as `he`, `Bob`, and `John
    Smith` are poor indicators of a unique individual being talked about. Good phrases
    might be `Breckenridge Baldwin`, because that is likely a unique name. There are
    lots of fancy theories for what is going on here, see rigid designators ([http://en.wikipedia.org/wiki/Rigid_designator](http://en.wikipedia.org/wiki/Rigid_designator)).
    The next few lines of code run roughshod over 2,000 years of philosophical thought:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`boolean` 方法 `XdcPhrase()` 在 XDoc 过程中扮演着关键角色。当前的方法支持一种非常保守的对什么是好 XDoc 短语的定义。直觉上，在新闻领域，诸如
    `he`、`Bob` 和 `John Smith` 这样的短语并不好，无法有效地指示正在讨论的独特个体。好的短语可能是 `Breckenridge Baldwin`，因为那可能是一个独特的名字。有很多复杂的理论解释这里发生了什么，参见刚性指示符（[http://en.wikipedia.org/wiki/Rigid_designator](http://en.wikipedia.org/wiki/Rigid_designator)）。接下来的几行代码几乎抹去了
    2,000 年的哲学思想：'
- en: '[PRE41]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This approach attempts to identify the bad phrases for XDoc rather than the
    good ones. The reasoning is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法试图识别 XDoc 中的不良短语，而不是好的短语。推理如下：
- en: '**There is already an entity associated with the phrase**: This enforces an
    assumption that there is only one John Smith in the world. This worked very well
    for intelligence-gathering applications, where the analysts had little trouble
    teasing apart the `John Smith` cases. You can refer to the *The John Smith problem*
    recipe at the end of this chapter for more about this.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短语已经与一个实体相关联**：这强制假设世界上只有一个 John Smith。这对于情报收集应用程序非常有效，因为分析师在分辨 `John Smith`
    案例时几乎没有困难。你可以参考本章末尾的 *The John Smith problem* 配方了解更多内容。'
- en: '**The phrase is only one word, and there are multiword phrases associated with
    the mention chain or entity**: This assumes that longer words are better for XDoc.
    Note that different orders of entity creation can result in one-word phrases having
    `xdc` to be `true` on entities with multiword aliases.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短语只有一个单词，并且与提及链或实体相关联的有多个单词短语**：这假设较长的单词对 XDoc 更有利。请注意，实体创建的不同顺序可能导致单个单词短语在具有多单词别名的实体上，`xdc`
    为 `true`。'
- en: '**The phrase is a pronoun**: This is a fairly safe assumption, unless we are
    in religious texts where `He` or `Him` capitalized in the middle of a sentence
    indicate reference to God.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短语是代词**：这是一个相对安全的假设，除非我们处在宗教文本中，其中句中间大写的 `He` 或 `Him` 表示指向上帝。'
- en: Once the sets of `xdc` and `nonXdc` phrases are known, then the entity is created.
    Refer to the source code for `Entity.java` to understand how entities are created.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦知道了 `xdc` 和 `nonXdc` 短语的集合，实体就会被创建。请参阅 `Entity.java` 的源代码，了解实体是如何创建的。
- en: 'Then, the entity is created, and an `add` method updates a mapping in the `EntityUniverse`
    file of `xdc` phrases to entity IDs:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，实体被创建，`add` 方法更新 `EntityUniverse` 文件中从 `xdc` 短语到实体 ID 的映射：
- en: '[PRE42]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `EntityUniverse` file's global `mXdcPhraseToEntitySet` variable is the key
    to finding candidate entities for XDoc as used in `xdcEntitiesToPhrase()`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`EntityUniverse` 文件的全局 `mXdcPhraseToEntitySet` 变量是找到候选实体的关键，正如在 `xdcEntitiesToPhrase()`
    中使用的那样。'
- en: The XDocCoref.addMentionChainToEntity() entity
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`XDocCoref.addMentionChainToEntity()` 实体'
- en: 'Returning to the `XDocCoref.xdocCoref()` method, we have covered how to create
    a new entity via `XDocCoref.promote()`. The next option to cover is what happens
    when a mention chain is resolved to an existing entity, namely `XDocCoref.addMentionChainToEntity()`.
    For the speculative mentions to be added, the entity must allow speculatively
    found mentions as provided by the `Entity.allowSpeculativeAliases()` method. This
    is a feature of the user-defined dictionary entities discussed in user-defined
    entities. If speculative entities are allowed, then the mention chains are added
    to the entity with a sensitivity to whether they are `xdc` phrases or not:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到 `XDocCoref.xdocCoref()` 方法，我们已经介绍了如何通过 `XDocCoref.promote()` 创建一个新实体。接下来要讨论的选项是当提及链被解析为现有实体时会发生什么，即
    `XDocCoref.addMentionChainToEntity()`。为了添加推测性提及，实体必须允许通过 `Entity.allowSpeculativeAliases()`
    方法提供的推测性找到的提及。这是用户定义的字典实体的一个特性，已在用户定义实体中讨论过。如果允许推测性实体，则提及链会被添加到实体中，并且会根据它们是否为
    `xdc` 短语来敏感处理：
- en: '[PRE43]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The only change that adding a mention chain can add to an entity is the addition
    of a new phrase. The additional phrases are classified for whether they are `xdc`
    or not in the same way as was done in the promotion of a mention chain.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 添加提及链到实体的唯一变化就是增加了一个新的短语。这些附加的短语会像在提及链的提升过程中那样被分类为是否为`xdc`。
- en: At this point, we have gone over the basics of how mention chains from documents
    are either promoted to speculative entities or are merged with existing entities
    in `EntityUniverse`. Next, we will take a look at how resolution occurs in `XDocCoref.resolveMentionChain()`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了文档中的提及链是如何被提升为猜测实体，或者如何与`EntityUniverse`中的现有实体合并的。接下来，我们将探讨在`XDocCoref.resolveMentionChain()`中解析是如何进行的。
- en: The XDocCoref.resolveMentionChain() entity
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`XDocCoref.resolveMentionChain()`实体'
- en: 'The `XDocCoref.resolveMentionChain()` method assembles a covering set of entities
    that can possibly match the mention chain being resolved and then attempt to find
    a unique entity via a call to `XDocCoref.resolveCandates()`:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`XDocCoref.resolveMentionChain()`方法组装了一个可能与被解析的提及链匹配的实体集合，并通过调用`XDocCoref.resolveCandidates()`尝试找到唯一的实体：'
- en: '[PRE44]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The code assembles a set of entities by doing a lookup into the entity universe
    with `EntityUniverse.xdcEntitiesWithPhrase()`. All aliases for the mention chain
    are tried without consideration of whether they are good XDoc aliases. Before
    the entities are added to `candidateEntities`, the type returned must be consistent
    with the type of the mention chain as determined by `TTMatchers.unifyEntityTypes`.
    This way, `Washington`, a location is not resolved to `Washington`, a person.
    A bit of record keeping is done to determine whether the longest alias on the
    mention chain has matched an entity.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码通过调用`EntityUniverse.xdcEntitiesWithPhrase()`从实体宇宙中查找实体集合。所有提及链的别名都会被尝试，而不考虑它们是否是有效的XDoc别名。在将实体添加到`candidateEntities`之前，返回的类型必须与`TTMatchers.unifyEntityTypes`所确定的提及链类型一致。这样，`华盛顿`（地点）就不会被解析为`华盛顿`（人名）。在此过程中，会做一些记录工作，以确定提及链上最长的别名是否与某个实体匹配。
- en: The resolveCandidates() method
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`resolveCandidates()`方法'
- en: 'The `resolveCandidates()` method captures a key assumption that holds both
    for within-document and XDoc coreferences—this unambiguous reference is the only
    basis of resolution. In the within-document case, an example where humans have
    this problem is the sentence, `Bob and Joe were working together. He fell into
    the threshing machine.` Who is `he` referring to? The linguistic expectation that
    a singular referring term have a unique antecedent is called a uniqueness presupposition.
    An example XDoc case is as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`resolveCandidates()`方法捕捉了一个关键假设，这一假设适用于文档内和XDoc共指的情况——这种不歧义的引用是唯一的解析基础。在文档内的案例中，一个类似的问题是“Bob和Joe一起工作。他掉进了脱粒机。”这里的“他”指的是谁？单一指代词有唯一先行词的语言预期被称为唯一性假设。一个XDoc的例子如下：'
- en: '**Doc1**: John Smith is a character from Pocohontas'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Doc1**：约翰·史密斯是《风中奇缘》中的一个角色'
- en: '**Doc2**: John Smith is the chairman or GM'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Doc2**：约翰·史密斯是董事长或总经理'
- en: '**Doc3**: John Smith is admired'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Doc3**：约翰·史密斯受人尊敬'
- en: 'Which `John Smith` does the `John Smith` from Doc3 go with? Perhaps, neither.
    The algorithm in this software requires that there should be a single possible
    entity that survives the matching criteria. If there is more than one or zero,
    then a new entity is created. The implementation is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`Doc3`中的`约翰·史密斯`与哪个`约翰·史密斯`相匹配？也许，两者都不是。这个软件中的算法要求在匹配标准下应该有一个唯一的实体得以保留。如果有多个或没有，系统就会创建一个新的实体。其实现方式如下：'
- en: '[PRE45]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `filterCandidates` method eliminates all the candidate entities that fail
    for various semantic reasons. Coreference with an entity in the entity universe
    only happens if there is a single possible solution. There is not a distinction
    between too many candidate entities (more than one) or too few (zero). In a more
    advanced system, one could try and further disambiguate if there are too many
    entities via `context`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`filterCandidates`方法会删除因各种语义原因无法通过的所有候选实体。只有当实体宇宙中的一个实体有唯一的匹配时，才会发生共指。这里并没有区分候选实体过多（多个）或过少（零）的情况。在一个更高级的系统中，如果实体过多，可以尝试通过`context`进一步消除歧义。'
- en: 'This is the heart of the XDoc code. The rest of the code marks up the document
    with entity-universe-relevant indices as returned by the `xdocCoref` method, which
    we just covered:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这是XDoc代码的核心。其余的代码使用`xdocCoref`方法返回的实体宇宙相关索引对文档进行标注，这部分我们刚刚已经讲解过：
- en: '[PRE46]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The following `for` loop iterates over the mention chains, which are aligned
    with `Entities[]` returned by `xdocCoref`. For each mention chain, the mention
    is mapped to its cross-document entity:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的`for`循环遍历了提到的链，这些链与`xdocCoref`返回的`Entities[]`对齐。对于每一个提到的链，提到的内容会被映射到它的跨文档实体：
- en: '[PRE47]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Next, the code will set up a bunch of mappings to create chunks that reflect
    the entity universe IDs:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，代码将设置一系列映射，创建反映实体宇宙ID的块：
- en: '[PRE48]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The actual creation of the chunks happens next:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的块创建在下一步进行：
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The chunkings are then used to create the relevant portions of the document,
    and `OutputDocument` is returned:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，块被用来创建文档的相关部分，并返回`OutputDocument`：
- en: '[PRE50]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: So, this is what we have to offer as a starting place for XDoc coreference.
    Hopefully, we have explained the intentions behind the more opaque methods. Good
    luck!
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们为XDoc共指提供的起点。希望我们已经解释了更多晦涩方法背后的意图。祝你好运！
- en: The John Smith problem
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 约翰·史密斯问题
- en: Different people, locations, and concepts can have the same orthographic representation
    but be distinct. There are multiple instances of "John Smith", "Paris", and "bank"
    in the world, and a proper cross-document coreference system should be able to
    handle it. For the case of concepts such as "bank" (a river bank versus a financial
    bank), the term of art is word-sense disambiguation. This recipe will demonstrate
    one approach to the problem that Baldwin developed back in the day with Amit Bagga
    for person disambiguation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的人、地点和概念可能有相同的书面表示，但却是不同的。世界上有多个“约翰·史密斯”、“巴黎”和“银行”的实例，适当的跨文档共指系统应该能够处理这些情况。对于“银行”这样的概念（例如：河岸和金融银行），术语是词义消歧。本示例将展示巴尔温（Baldwin）和阿米特·巴加（Amit
    Bagga）当年为人物消歧开发的一个方法。
- en: Getting ready
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The code for this recipe closely follows the clustering tutorial at [http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html](http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html)
    but changes it to more closely fit the original Bagga-Baldwin work. There is a
    fair amount of code but nothing very complicated. The source is in `src/com/lingpipe/cookbook/chapter7/JohnSmith.java`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的代码紧跟[http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html](http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html)的聚类教程，但进行了修改，以更贴合最初的Bagga-Baldwin工作。代码量不小，但没有非常复杂的部分。源代码在`src/com/lingpipe/cookbook/chapter7/JohnSmith.java`。
- en: 'The class starts with the standard panoply of NLP tools for tokenization, sentence
    detection, and named-entity detection. Refer to the previous recipes if this stack
    is unfamiliar:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 该类首先使用了标准的NLP工具包，包括分词、句子检测和命名实体检测。如果这个工具堆栈不熟悉，请参阅前面的示例：
- en: '[PRE51]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Next up, we will revisit `TfIdfDistance`. However, the task requires that we
    wrap the class to operate over `Documents` rather than `CharSequences`, because
    we would like to retain the filename and be able to manipulate what text is used
    for the calculations to come:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将重新访问`TfIdfDistance`。不过，任务要求我们将类封装成处理`Documents`而非`CharSequences`，因为我们希望保留文件名，并能够操作用于后续计算的文本：
- en: '[PRE52]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Dropping to the referenced class, we have the following code:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 降级到引用的类，我们有以下代码：
- en: '[PRE53]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The `train` method interfaces with the `TfIdfDistance.handle()` method and provides
    an implementation of a `distance(Document doc1, Document doc2)` method that will
    drive the clustering code discussed below. All that the `train` method does is
    pull out the relevant text and hand it off to the `TfIdfDistance` class for the
    relevant value.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法与`TfIdfDistance.handle()`方法接口，并提供了一个`distance(Document doc1, Document
    doc2)`方法的实现，驱动下面讨论的聚类代码。`train`方法的作用仅仅是提取相关文本，并将其交给`TfIdfDistance`类来计算相关值。'
- en: 'The reference class, `Document`, is an inner class in `JohnSmith`, and it is
    quite simple. It gets sentences that have entities which match the `.*John Smith.*`
    pattern and puts them in the `mCoreferentText` variable:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 引用类`Document`是`JohnSmith`中的一个内部类，非常简单。它获取包含匹配`.*John Smith.*`模式的实体的句子，并将其放入`mCoreferentText`变量中：
- en: '[PRE54]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Going deeper into the code, we will now visit the `getCoreferentSents()` method:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 深入到代码中，我们现在将访问`getCoreferentSents()`方法：
- en: '[PRE55]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Look at the *Cross-document coreference* recipe for most of the moving parts
    of the preceding method. We will call out a few notable bits. We are cheating
    in some sense by using a regular expression chunker to find any string that has
    as a `John Smith` substring and adding it in as a `PERSON` entity. Like most kinds
    of cheating, this is quite useful if your sole purpose in life is tracking `John
    Smith`. The cheating we did in reality was to use dictionary matching to find
    all variations of high-value intelligence targets such as `Osama bin Laden`. In
    the end, we had over 40 versions of his name scouring openly available news sources
    as a part of the MiTAP project.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 查看*跨文档共指*的配方，了解前面方法的大部分运动部分。我们将挑出一些值得注意的部分。某种意义上，我们通过使用正则表达式分块器来找到任何包含`John
    Smith`子字符串的字符串，并将其作为`PERSON`实体添加进来，算是作弊。像大多数类型的作弊一样，如果你的人生目标仅仅是追踪`John Smith`，这种方法相当有效。实际上，我们做的作弊是使用字典匹配来找到`Osama
    bin Laden`等高价值情报目标的所有变种。最终，在MiTAP项目中，我们找到了超过40个版本的他的名字，遍历公开的新闻来源。
- en: Further, as each sentence is processed, we will check all the mentions for a
    matching pattern for `John Smith`, and if so, we will collect any sentence that
    has a mention of this ID. This means that a sentence that refers back to `John
    Smith` with a pronoun will be included, as will the `Mr. Smith` cases if coreference
    is doing its job. Note that we need to see a match for `John Smith` before we
    start collecting contextual information, so we will miss the first sentence of
    `He awoke. John Smith was a giant cockroach`. Also note that if a second `John
    Smith` shows up with a different ID, it will be ignored—this can happen.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在处理每个句子时，我们会检查所有提及的内容是否匹配`John Smith`的模式，如果匹配，则收集包含该ID的句子。这意味着，任何提到`John
    Smith`的句子，包括用代词指代的句子，如果共指工作正常，`Mr. Smith`的情况也会被包括在内。注意，我们需要看到`John Smith`的匹配才能开始收集上下文信息，所以我们会错过句子`He
    awoke. John Smith was a giant cockroach`的第一个句子。同时，如果第二个`John Smith`出现并带有不同的ID，它将被忽略——这种情况是可能发生的。
- en: Finally, note that there is some error checking, in that if `John Smith` is
    not found, then an error is reported to `System.out`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，注意有一些错误检查，如果找不到`John Smith`，系统会向`System.out`报告错误。
- en: 'If we pop back to mundane I/O slinging in our `main()` method after setting
    up `TfIdfDocumentDistance`, we would have:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在设置好`TfIdfDocumentDistance`后又回到`main()`方法中的普通I/O处理，我们将会有：
- en: '[PRE56]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We have not discussed this, but the truth annotation of which document references
    which `Mr. Smith` is encoded in the directory structure of the data. Each subdirectory
    in the top `johnSmith` directory is treated as the truth cluster. So, `referencePartition`
    contains the truth. We could have wrapped this as a classification problem with
    each subdirectory, the correct classification. We will leave it as an exercise
    to you to stuff this into a cross-validating corpus with a logistic regression
    solution.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有讨论这个问题，但关于哪个文档引用了哪个`Mr. Smith`的真实注解编码在数据的目录结构中。`johnSmith`顶级目录中的每个子目录都被视为真实聚类。所以，`referencePartition`包含了真实数据。我们本可以将其包装为一个分类问题，每个子目录对应正确的分类。我们将这个作为练习留给你，要求将其嵌入到交叉验证语料库中，并用逻辑回归解决。
- en: 'Moving on, we will construct the test set by flattening our previous categories
    into a single set of `Documents`. We could have done this in the previous step,
    but mixing tasks tends to produce bugs, and the extra `for` loop does very little
    damage to the execution speed:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过将之前的类别展平为一个`Documents`的集合来构建测试集。我们本可以在前一步完成这个操作，但混合任务往往会产生错误，而且多出的`for`循环对执行速度几乎没有影响：
- en: '[PRE57]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Next, we will tee up the clustering algorithms. We will do both `CompleteLink`
    and `SingleLink` driven by `TfIdfDocumentDistance` that runs the show:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将启动聚类算法。我们将执行`CompleteLink`和`SingleLink`，由`TfIdfDocumentDistance`驱动，后者负责整个过程：
- en: '[PRE58]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The details of the clustering algorithms are covered in [Chapter 5](ch05.html
    "Chapter 5. Finding Spans in Text – Chunking"), *Finding Spans in Texts – Chunking*.
    Now, we will report performance based on the number of clusters varied from `1`
    to the number of inputs. The one fancy bit is that the `Cross` category uses `SingleLinkClusterer`
    as the reference and `CompleteLinkClusterer` as the response:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类算法的细节在[第5章](ch05.html "第5章：文本中的跨度查找 – 分块")中进行了介绍，*文本中的跨度查找 – 分块*。现在，我们将根据聚类数从`1`到输入数量的变化来报告性能。一个特别的地方是，`Cross`类别使用`SingleLinkClusterer`作为参考，而`CompleteLinkClusterer`作为响应：
- en: '[PRE59]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: That's all that we need to do to get ready for this recipe. This is a rare phenomenon
    to be computed, and this is a toy implementation, but the key concepts should
    be evident.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们为准备这个配方所需做的一切。这是一个罕见的现象要计算，这是一个玩具实现，但关键概念应该是显而易见的。
- en: How to do it...
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will just run this code and then mess with it a bit:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需运行这段代码，稍微调整一下：
- en: 'Get yourself to a terminal and type:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到终端并输入：
- en: '[PRE60]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The result will be piles of information that indicate what sentences are being
    extracted for use in the clustering—remember that the truth annotation is determined
    by the directory that the files are in. The first cluster is `0`:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果将是一堆信息，指示正在提取用于聚类的句子——记住真相注释是由文件所在目录确定的。第一个聚类是`0`：
- en: '[PRE61]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The code reports sentences that contain references to `John Smith`:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码报告包含对`John Smith`的引用的句子：
- en: '[PRE62]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The pronominal reference to `John Smith` is the basis of inclusion of the second
    sentence.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`John Smith`的代词引用是包含第二句的基础。
- en: 'The system output goes on, and finally, we will get the results for a single-link
    clustering against the truth and a complete link against the truth. The `K` column
    indicates how many clusters the algorithm was allowed with precision, recall,
    and F-measure reported. The first row is in this case that there is only one cluster
    that will allow for 100 percent recall and 23 percent precision for both complete
    and single links. Looking down at the scores, we can see that the complete link
    reports the best F-measure with 11 clusters at `0.60`—in truth, there are 35 clusters.
    The single-link approach maxes out F-measure at 68 clusters with `0.78` and shows
    much greater robustness on varying numbers of clusters. The cross case shows that
    single link and complete link are quite different in direct comparison as well.
    Note that some `K` values have been eliminated for readability:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统输出继续进行，最后，我们将获得与真相进行单链接聚类和与真相进行完全链接的结果。`K`列指示算法允许多少个聚类，并报告了精确度、召回率和F-度量。第一行在这种情况下是只允许一个聚类，将允许百分之百的召回率和23%的精确度，无论是完全链接还是单链接。查看得分，我们可以看到完全链接在`0.60`时报告了最佳的F-度量——事实上，有35个聚类。单链接方法在`0.78`时将F-度量最大化到68个聚类，并在不同数量的聚类上显示出更大的鲁棒性。交叉案例显示单链接和完全链接在直接比较中有很大的不同。请注意，为了可读性，一些`K`值已被消除：
- en: '[PRE63]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The following output constrains clustering not by cluster size but by the max
    distance threshold. The output is for the single-link cluster with `.05` increases
    the distance and the evaluation is the B-cubed metric. The output is the distance,
    precision, recall, and the size of the resulting cluster. The performance at `.80`
    and `.9` is quite good, but beware of setting production thresholds in this after
    the fact fashion. In a production environment, we will want to see much more data
    before setting the threshold:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下面的输出限制了聚类的方式不是通过聚类大小，而是通过最大距离阈值。输出是对单链接聚类的，增加了`.05`距离，并且评估是B-cubed度量。输出是距离、精确度、召回率以及生成聚类的大小。在`.80`和`.9`的表现非常好，但要小心在事后设置生产阈值。在生产环境中，我们将希望在设置阈值之前看到更多数据：
- en: '[PRE64]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The B-cubed (Bagga, Bierman, and Baldwin) evaluation was created to heavily
    penalize pushing large clusters together. It assumes that it is more of a problem
    to push lots of documents about George W. Bush together with George H. W. Bush,
    both large clusters, than to mistake George Bush, the mechanic who got mentioned
    once in the dataset. Other scoring metrics will count both the mistakes as equally
    bad. It is the standard scoring metric used in the literature for this phenomenon.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B-cubed（Bagga、Bierman和Baldwin）评估被设计为严重惩罚将大量文档关联在一起的情况。它假设将关于乔治·W·布什和乔治·H·W·布什这样的大型聚类合并在一起是更大的问题，而不是误将提到数据集中的一次性提到的机械师乔治·布什的情况。其他评分指标将同样认为这两种错误同样糟糕。这是文献中用于此现象的标准评分指标。
- en: See also
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: There is a fair amount of work in the research literature on this exact problem.
    We were not the first ones to think about this, but we came up with the dominant
    evaluation metric, and we released a corpus for other groups to compare themselves
    with us and each other. Our contribution is *Entity-based cross-document coreferencing
    using the Vector Space Model* by Bagga and Baldwin in *ACL '98 Proceedings of
    the 36th Annual Meeting of the Association for Computational Linguistics and 17th
    International Conference on Computational Linguistics*. There has been much progress
    since—there are more than 400 citations to this model on Google Scholar; they
    are worth a look if this problem is of importance to you.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究文献中，关于这个具体问题有相当多的工作。我们并不是第一个考虑这个问题的人，但我们提出了主流的评估指标，并发布了一个语料库供其他团队与我们以及彼此进行比较。我们的贡献是*基于实体的跨文档共指消解，使用向量空间模型*，由Bagga和Baldwin提出，收录于*ACL
    '98 第36届计算语言学会年会和第17届国际计算语言学会议论文集*。自那时以来已经取得了许多进展——Google Scholar上已有超过400次引用，如果这个问题对你来说很重要，它们值得一看。
