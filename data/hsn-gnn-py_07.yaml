- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Graph Attention Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图注意力网络
- en: '**Graph Attention Networks** (**GATs**) are a theoretical improvement over
    GCNs. Instead of static normalization coefficients, they propose weighting factors
    calculated by a process called **self-attention**. The same process is at the
    core of one of the most successful deep learning architectures: the **transformer**,
    popularized by **BERT** and **GPT-3**. Introduced by Veličković et al. in 2017,
    GATs have become one of the most popular GNN architectures thanks to excellent
    out-of-the-box performance.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**图注意力网络**（**GATs**）是GCN的理论改进。它们提出了通过一个叫做**自注意力**的过程来计算加权因子，而不是使用静态归一化系数。这个过程也是一种成功的深度学习架构——**Transformer**的核心，后者由**BERT**和**GPT-3**等模型普及。GAT由Veličković等人在2017年提出，凭借其卓越的开箱即用性能，已经成为最受欢迎的GNN架构之一。'
- en: In this chapter, we will learn how the graph attention layer works in four steps.
    This is actually the perfect example for understanding how self-attention works
    in general. This theoretical background will allow us to implement a graph attention
    layer from scratch in `NumPy`. We will build the matrices by ourselves to understand
    how their values are calculated at each step.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将通过四个步骤来学习图注意力层是如何工作的。这实际上是理解自注意力如何工作的一 个完美示例。这些理论背景将帮助我们从零开始使用`NumPy`实现一个图注意力层。我们将自己构建矩阵，以便理解它们在每一步是如何计算值的。
- en: 'In the last section, we’ll use a GAT on two node classification datasets: `Cora`,
    and a new one called `CiteSeer`. As anticipated in the last chapter, this will
    be a good opportunity to analyze our results a little further. Finally, we will
    compare the accuracy of this architecture with a GCN.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们将在两个节点分类数据集上使用GAT：`Cora`和一个新的数据集`CiteSeer`。正如上一章所预期的，这将是进一步分析结果的好机会。最后，我们将比较该架构与GCN的准确度。
- en: By the end of this chapter, you will be able to implement a graph attention
    layer from scratch and a GAT in **PyTorch Geometric** (**PyG**). You will learn
    about the differences between this architecture and a GCN. Furthermore, you will
    master an error analysis tool for graph data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够从零开始实现图注意力层，并在**PyTorch Geometric**（**PyG**）中实现一个GAT。你将学习这种架构与GCN之间的区别。此外，你还将掌握一个用于图数据的错误分析工具。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing the graph attention layer
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍图注意力层
- en: Implementing the graph attention layer in NumPy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在NumPy中实现图注意力层
- en: Implementing a GAT in PyTorch Geometric
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在PyTorch Geometric中实现GAT
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code examples from this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter07](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter07).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码示例可以在GitHub上找到，链接为：[https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter07](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter07)。
- en: The installation steps required to run the code on your local machine can be
    found in the *Preface* section of this book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的*前言*部分，你可以找到在本地机器上运行代码所需的安装步骤。
- en: Introducing the graph attention layer
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍图注意力层
- en: 'The main idea behind GATs is that some nodes are more important than others.
    In fact, this was already the case with the graph convolutional layer: nodes with
    few neighbors were more important than others, thanks to the normalization coefficient
    ![](img/Formula_B19153_07_001.png). This approach is limiting because it only
    takes into account node degrees. On the other hand, the goal of the graph attention
    layer is to produce weighting factors that also consider the importance of node
    features.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: GAT的主要思想是，有些节点比其他节点更重要。实际上，这一点在图卷积层中就已经存在：具有较少邻居的节点比其他节点更重要，因为它们有归一化系数![](img/Formula_B19153_07_001.png)。这种方法存在局限性，因为它只考虑节点的度数。另一方面，图注意力层的目标是生成考虑节点特征重要性的加权因子。
- en: 'Let’s call our weighting factors **attention scores** and note, ![](img/Formula_B19153_07_002.png),
    the attention score between the nodes ![](img/Formula_B19153_07_005.png) and ![](img/Formula_B19153_07_007.png).
    We can define the graph attention operator as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的加权因子称为**注意力得分**，并注意到，![](img/Formula_B19153_07_002.png)，表示节点![](img/Formula_B19153_07_005.png)和![](img/Formula_B19153_07_007.png)之间的注意力得分。我们可以将图注意力算子定义如下：
- en: '![](img/Formula_B19153_07_005.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_005.jpg)'
- en: 'An important characteristic of GATs is that the attention scores are calculated
    implicitly by comparing inputs to each other (hence the name *self*-attention).
    In this section, we will see how to calculate these attention scores in four steps
    and also how to make an improvement to the graph attention layer:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GATs 的一个重要特征是注意力得分是通过比较输入之间的关系隐式计算的（因此命名为*自*注意力）。在这一节中，我们将看到如何通过四个步骤来计算这些注意力得分，并且如何对图注意力层进行改进：
- en: Linear transformation
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性变换
- en: Activation function
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数
- en: Softmax normalization
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Softmax 标准化
- en: Multi-head attention
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多头注意力
- en: Improved graph attention layer
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进的图注意力层
- en: First things first, let’s see how the linear transformation differs from previous
    architectures.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看一下线性变换是如何与之前的架构不同的。
- en: Linear transformation
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性变换
- en: 'The attention score represents the importance between a central node ![](img/Formula_B19153_07_0051.png)
    and a neighbor ![](img/Formula_B19153_07_0071.png). As stated previously, it requires
    node features from both nodes. In the graph attention layer, it is represented
    by a concatenation between the hidden vectors ![](img/Formula_B19153_07_008.png)
    and ![](img/Formula_B19153_07_009.png), ![](img/Formula_B19153_07_010.png). Here,
    ![](img/Formula_B19153_07_011.png) is a classic shared weight matrix to compute
    hidden vectors. An additional linear transformation is applied to this result
    with a dedicated learnable weight matrix ![](img/Formula_B19153_07_012.png). During
    training, this matrix learns weights to produce attention coefficients ![](img/Formula_B19153_07_013.png).
    This process is summarized by the following formula:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力得分表示一个中心节点 ![](img/Formula_B19153_07_0051.png) 与一个邻居节点 ![](img/Formula_B19153_07_0071.png)
    之间的重要性。如前所述，这需要来自两个节点的节点特征。在图注意力层中，它通过隐藏向量 ![](img/Formula_B19153_07_008.png)
    和 ![](img/Formula_B19153_07_009.png) 的连接来表示， ![](img/Formula_B19153_07_010.png)。在这里，![](img/Formula_B19153_07_011.png)
    是一个经典的共享权重矩阵，用于计算隐藏向量。一个额外的线性变换被应用于这个结果，并使用一个专门的可学习权重矩阵 ![](img/Formula_B19153_07_012.png)。在训练过程中，这个矩阵学习权重以生成注意力系数
    ![](img/Formula_B19153_07_013.png)。这个过程可以通过以下公式总结：
- en: '![](img/Formula_B19153_07_014.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_014.jpg)'
- en: This output is given to an activation function like in traditional neural networks.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出被传递给像传统神经网络中那样的激活函数。
- en: Activation function
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活函数
- en: Nonlinearity is an essential component in neural networks to approximate nonlinear
    target functions. Such functions could not be captured by simply stacking linear
    layers, as their final outcome would still behave like a single linear layer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性是神经网络中的一个重要组成部分，用于逼近非线性目标函数。这些函数无法仅通过堆叠线性层来捕捉，因为最终的结果仍然会表现得像单一的线性层。
- en: 'In the official implementation ([https://github.com/PetarV-/GAT/blob/master/utils/layers.py](https://github.com/PetarV-/GAT/blob/master/utils/layers.py)),
    the authors chose the **Leaky Rectified Linear Unit** (**ReLU**) activation function
    (see *Figure 7**.1*). This function fixes the *dying ReLU* problem, where ReLU
    neurons only output zero:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在官方实现中（[https://github.com/PetarV-/GAT/blob/master/utils/layers.py](https://github.com/PetarV-/GAT/blob/master/utils/layers.py)），作者选择了**Leaky
    Rectified Linear Unit**（**ReLU**）激活函数（见*图 7.1*）。该函数修复了*dying ReLU*问题，即 ReLU 神经元仅输出零：
- en: '![Figure 7.1 – ReLU versus Leaky ReLU functions](img/B19153_07_001.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – ReLU 与 Leaky ReLU 函数对比](img/B19153_07_001.jpg)'
- en: Figure 7.1 – ReLU versus Leaky ReLU functions
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – ReLU 与 Leaky ReLU 函数对比
- en: 'This is implemented by applying the Leaky ReLU function to the output of the
    previous step:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过将 Leaky ReLU 函数应用于上一步骤的输出实现的：
- en: '![](img/Formula_B19153_07_015.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_015.jpg)'
- en: 'However, we are now facing a new problem: the resulting values are not normalized!'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们现在面临一个新问题：结果值没有被标准化！
- en: Softmax normalization
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax 标准化
- en: 'We want to compare different attention scores, which means we need normalized
    values on the same scale. In machine learning, it is common to use the softmax
    function for this purpose. Let’s call ![](img/Formula_B19153_07_016.png) the neighboring
    nodes of node ![](img/Formula_B19153_07_0052.png), including itself:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望比较不同的注意力得分，这意味着我们需要在同一尺度上进行标准化的值。在机器学习中，通常使用 softmax 函数来实现这一点。我们称 ![](img/Formula_B19153_07_016.png)
    为节点 ![](img/Formula_B19153_07_0052.png) 的邻居节点，包括它本身：
- en: '![](img/Formula_B19153_07_018.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_018.jpg)'
- en: 'The result of this operation gives us our final attention scores ![](img/Formula_B19153_07_019.png).
    But there’s another problem: self-attention is not very stable.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该操作的结果给出了我们的最终注意力得分 ![](img/Formula_B19153_07_019.png)。但是还有另一个问题：自注意力并不是非常稳定。
- en: Multi-head attention
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多头注意力
- en: This issue was already noticed by Vaswani et al. (2017) in the original transformer
    paper. Their proposed solution consists of calculating multiple embeddings with
    their own attention scores instead of a single one. This technique is called multi-head
    attention.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这一问题已经在原始的 Transformer 论文中由 Vaswani 等人（2017）提出。他们提出的解决方案是计算多个嵌入并为每个嵌入分配不同的注意力权重，而不是仅计算一个嵌入。这项技术被称为多头注意力。
- en: 'The implementation is straightforward, as we just have to repeat the three
    previous steps multiple times. Each instance produces an embedding ![](img/Formula_B19153_07_020.png),
    where ![](img/Formula_B19153_07_021.png) is the index of the attention head. There
    are two ways of combining these results:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 实现非常简单，因为我们只需要重复前面三个步骤多次。每个实例都会生成一个嵌入！[](img/Formula_B19153_07_020.png)，其中！[](img/Formula_B19153_07_021.png)是注意力头的索引。这里有两种方法来结合这些结果：
- en: '**Averaging**: With this, we sum the different embeddings and normalize the
    result by the number of attention heads ![](img/Formula_B19153_07_022.png):'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均**：在这种方法中，我们对不同的嵌入进行求和，并通过注意力头的数量！[](img/Formula_B19153_07_022.png)对结果进行归一化：'
- en: '![](img/Formula_B19153_07_023.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_023.jpg)'
- en: '**Concatenation**: Here, we concatenate the different embeddings, which will
    produce a larger matrix:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拼接**：在这种方法中，我们将不同的嵌入拼接在一起，产生一个更大的矩阵：'
- en: '![](img/Formula_B19153_07_024.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_024.jpg)'
- en: 'In practice, there is a simple rule to know which one to use: we choose the
    concatenation scheme when it’s a hidden layer and the average scheme when it’s
    the last layer of the network. The entire process can be summarized by the following
    diagram:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，有一个简单的规则可以帮助决定使用哪种方式：当它是一个隐藏层时，我们选择拼接方案，当它是网络的最后一层时，我们选择平均方案。整个过程可以通过以下图示来总结：
- en: '![Figure 7.2 – Calculating attention scores with multi-head attention](img/B19153_07_002.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 使用多头注意力计算注意力得分](img/B19153_07_002.jpg)'
- en: Figure 7.2 – Calculating attention scores with multi-head attention
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 使用多头注意力计算注意力得分
- en: This is all there is to know about the theoretical aspect of the graph attention
    layer. However, since its inception in 2017, an improvement has been suggested.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是图注意力层的理论方面的全部内容。然而，自2017年问世以来，已有一种改进方案被提出。
- en: Improved graph attention layer
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改进的图注意力层
- en: Brody et al. (2021) argued that the graph attention layer only computes a static
    type of attention. This is an issue because there are simple graph problems we
    cannot express with a GAT. So they introduced an improved version, called GATv2,
    which computes a strictly more expressive dynamic attention.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Brody 等人（2021）认为，图注意力层只计算静态类型的注意力。这是一个问题，因为有一些简单的图问题是我们无法用 GAT 来表达的。因此，他们引入了一个改进版本，称为
    GATv2，它计算的是严格更具表现力的动态注意力。
- en: 'Their solution consists of modifying the order of operations. The weight matrix
    ![](img/Formula_B19153_07_025.png) is applied after the concatenation and the
    attention weight matrix ![](img/Formula_B19153_07_026.png) after the ![](img/Formula_B19153_07_027.png)
    function. In summary, here is the original **Graph Attentional Operator**, also
    **GAT**:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的解决方案是修改操作的顺序。权重矩阵！[](img/Formula_B19153_07_025.png) 在拼接之后应用，注意力权重矩阵！[](img/Formula_B19153_07_026.png)
    在！[](img/Formula_B19153_07_027.png)函数之后应用。总结一下，下面是原始的 **图注意力操作符**，即 **GAT**：
- en: '![](img/Formula_B19153_07_028.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_028.jpg)'
- en: 'And this is the modified operator, GATv2:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是修改后的操作符，GATv2：
- en: '![](img/Formula_B19153_07_029.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_029.jpg)'
- en: 'Which one should we use? According to Brody et al., GATv2 consistently outperforms
    the GAT and thus should be preferred. In addition to the theoretical proof, they
    also ran several experiments to show the performance of GATv2 compared to the
    original GAT. In the rest of this chapter, we will consider both options: the
    GAT in the second section and GATv2 in the third section.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该使用哪种方法？根据 Brody 等人（2021）的研究，GATv2 始终优于 GAT，因此应该首选 GATv2。除了理论证明，他们还进行了多次实验，以展示
    GATv2 相较于原始 GAT 的表现。在本章的其余部分，我们将同时讨论这两种选择：第二节中的 GAT 和第三节中的 GATv2。
- en: Implementing the graph attention layer in NumPy
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 NumPy 中实现图注意力层
- en: As previously stated, neural networks work in terms of matrix multiplications.
    Therefore, we need to translate our individual embeddings into operations for
    the entire graph. In this section, we will implement the original graph attention
    layer from scratch to properly understand the inner workings of self-attention.
    Naturally, this process can be repeated several times to create multi-head attention.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，神经网络是通过矩阵乘法来工作的。因此，我们需要将我们的单个嵌入转换为整个图的操作。在这一部分，我们将从零开始实现原始的图注意力层，以便正确理解自注意力的内部工作原理。当然，这一过程可以重复多次，以创建多头注意力。
- en: 'The first step consists of translating the original graph attention operator
    in terms of matrices. This is how we defined it in the last section:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将原始的图注意力算子转换为矩阵的形式。这就是我们在上一节中定义它的方式：
- en: '![](img/Formula_B19153_07_059.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_059.jpg)'
- en: 'By taking inspiration from the graph linear layer, we can write the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从图的线性层中获得灵感，我们可以写出以下内容：
- en: '![](img/Formula_B19153_07_031.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_07_031.jpg)'
- en: Where ![](img/Formula_B19153_07_032.png) is a matrix that stores every ![](img/Formula_B19153_07_033.png).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/Formula_B19153_07_032.png) 是一个矩阵，存储每个 ![](img/Formula_B19153_07_033.png)。
- en: 'In this example, we will use the following graph from the previous chapter:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用上一章的以下图表：
- en: '![Figure 7.3 – Simple graph where nodes have different numbers of neighbors](img/B19153_07_003.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – 一个简单的图，其中节点具有不同数量的邻居](img/B19153_07_003.jpg)'
- en: Figure 7.3 – Simple graph where nodes have different numbers of neighbors
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – 一个简单的图，其中节点具有不同数量的邻居
- en: 'The graph must provide two important pieces of information: the adjacency matrix
    with self-loops ![](img/Formula_B19153_07_034.png) and the node features ![](img/Formula_B19153_07_035.png).
    Let’s see how to implement it in NumPy:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图必须提供两项重要信息：带有自环的邻接矩阵 ![](img/Formula_B19153_07_034.png) 和节点特征 ![](img/Formula_B19153_07_035.png)。让我们看看如何在NumPy中实现它：
- en: 'We can build the adjacency matrix from the connections in *Figure 7**.3*:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以根据*图 7.3*中的连接构建邻接矩阵：
- en: '[PRE0]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For ![](img/Formula_B19153_07_036.png), we generate a random matrix of node
    features using `np.random.uniform()`:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 ![](img/Formula_B19153_07_036.png)，我们使用`np.random.uniform()`生成一个随机的节点特征矩阵：
- en: '[PRE1]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The next step is to define our weight matrices. Indeed, in graph attention
    layers, there are two of them: the regular weight matrix ![](img/Formula_B19153_07_037.png),
    and the attention weight matrix ![](img/Formula_B19153_07_038.png). There are
    different ways to initialize them (Xavier or He initialization, for example),
    but we can just reuse the same random function in this example.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是定义我们的权重矩阵。实际上，在图注意力层中，有两个权重矩阵：常规权重矩阵 ![](img/Formula_B19153_07_037.png)
    和注意力权重矩阵 ![](img/Formula_B19153_07_038.png)。初始化它们的方式有很多种（例如 Xavier 或 He 初始化），但在这个例子中，我们可以简单地重用相同的随机函数。
- en: 'The matrix ![](img/Formula_B19153_07_039.png) has to be carefully designed
    as its dimensions are ![](img/Formula_B19153_07_040.png) Notice that ![](img/Formula_B19153_07_041.png)
    is already fixed because it represents the number of nodes in ![](img/Formula_B19153_07_042.png).
    On the contrary, the value of ![](img/Formula_B19153_07_043.png) is arbitrary:
    we’ll choose ![](img/Formula_B19153_07_044.png) in this example:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 ![](img/Formula_B19153_07_039.png) 必须精心设计，因为它的维度是 ![](img/Formula_B19153_07_040.png)。注意，![](img/Formula_B19153_07_041.png)
    已经是固定的，因为它表示 ![](img/Formula_B19153_07_042.png) 中的节点数。相反，![](img/Formula_B19153_07_043.png)
    的值是任意的：我们将在这个例子中选择 ![](img/Formula_B19153_07_044.png)：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This attention matrix is applied to the concatenation of hidden vectors to
    produce a unique value. Thus, its size needs to be ![](img/Formula_B19153_07_045.png):'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个注意力矩阵应用于隐藏向量的拼接，生成一个唯一的值。因此，它的大小需要是 ![](img/Formula_B19153_07_045.png)：
- en: '[PRE3]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We want to concatenate hidden vectors from source and destination nodes. A
    simple way to obtain pairs of source and destination nodes is to look at our adjacency
    matrix ![](img/Formula_B19153_07_046.png) in COO format: rows store source nodes,
    and columns store destination nodes. NumPy provides a quick and efficient way
    of doing it with `np.where()`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们希望将源节点和目标节点的隐藏向量进行拼接。获取源节点和目标节点对的一种简单方法是查看我们的邻接矩阵 ![](img/Formula_B19153_07_046.png)，它采用COO格式：行存储源节点，列存储目标节点。NumPy提供了一种快速高效的方法，使用`np.where()`来实现：
- en: '[PRE4]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can concatenate hidden vectors of source and destination nodes using `np.concatenate`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `np.concatenate` 来拼接源节点和目标节点的隐藏向量：
- en: '[PRE5]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We then apply a linear transformation to this result with the attention matrix
    ![](img/Formula_B19153_07_047.png):'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用注意力矩阵 ![](img/Formula_B19153_07_047.png) 对该结果进行线性变换：
- en: '[PRE6]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The second step consists of applying a Leaky ReLU function to the previous
    outcome:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二步是对前一个结果应用 Leaky ReLU 函数：
- en: '[PRE7]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We have the right values but need to place them correctly in a matrix. This
    matrix should look like ![](img/Formula_B19153_07_048.png) because there is no
    need for unnormalized attention scores when there is no connection between two
    nodes. To build this matrix, we know the sources ![](img/Formula_B19153_07_049.png)
    and destinations ![](img/Formula_B19153_07_050.png) thanks to `connections`. So,
    the first value in `e` corresponds to ![](img/Formula_B19153_07_051.png), the
    second value to ![](img/Formula_B19153_07_052.png), but the seventh value corresponds
    to ![](img/Formula_B19153_07_053.png) and not to ![](img/Formula_B19153_07_054.png).
    We can fill the matrix as follows:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有正确的值，但需要将它们正确地放置在矩阵中。这个矩阵应该看起来像 ![](img/Formula_B19153_07_048.png)，因为当两个节点之间没有连接时，不需要标准化的注意力分数。为了构建这个矩阵，我们通过`connections`知道源节点
    ![](img/Formula_B19153_07_049.png) 和目标节点 ![](img/Formula_B19153_07_050.png)。因此，`e`中的第一个值对应于
    ![](img/Formula_B19153_07_051.png)，第二个值对应于 ![](img/Formula_B19153_07_052.png)，但第七个值对应于
    ![](img/Formula_B19153_07_053.png)，而不是 ![](img/Formula_B19153_07_054.png)。我们可以按如下方式填充矩阵：
- en: '[PRE8]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The next step is to normalize every row of attention scores. This requires
    a custom `softmax` function to produce our final attention scores:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是规范化每一行的注意力分数。这需要一个自定义的 `softmax` 函数来生成最终的注意力分数：
- en: '[PRE9]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This attention matrix ![](img/Formula_B19153_07_055.png) provides weights for
    every possible connection in the network. We can use it to calculate our matrix
    of embeddings ![](img/Formula_B19153_07_056.png), which should give us two-dimensional
    vectors for each node:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个注意力矩阵 ![](img/Formula_B19153_07_055.png) 为网络中每一个可能的连接提供了权重。我们可以用它来计算我们的嵌入矩阵
    ![](img/Formula_B19153_07_056.png)，该矩阵应为每个节点提供二维向量：
- en: '[PRE10]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Our graph attention layer is now complete! Adding multi-head attention consists
    of repeating these steps with different ![](img/Formula_B19153_07_057.png) and
    ![](img/Formula_B19153_07_058.png) before aggregating the results.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的图注意力层现在已经完成！添加多头注意力的过程包括在聚合结果之前使用不同的 ![](img/Formula_B19153_07_057.png) 和
    ![](img/Formula_B19153_07_058.png) 重复这些步骤。
- en: The graph attention operator is an essential building block to developing GNNs.
    In the next section, we will use a PyG implementation to create a GAT.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图注意力操作符是开发 GNN 的一个重要构建块。在下一节中，我们将使用 PyG 实现创建一个 GAT。
- en: Implementing a GAT in PyTorch Geometric
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 PyTorch Geometric 中实现 GAT
- en: 'We now have a complete picture of how the graph attention layer works. These
    layers can be stacked to create our new architecture of choice: the GAT. In this
    section, we will follow the guidelines from the original GAT paper to implement
    our own model using PyG. We will use it to perform node classification on the
    `Cora` and `CiteSeer` datasets. Finally, we will comment on these results and
    compare them.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完整地了解了图注意力层的工作原理。这些层可以堆叠起来，创建我们选择的新架构：GAT。在本节中，我们将遵循原始 GAT 论文中的指导方针，使用
    PyG 实现我们自己的模型。我们将用它在 `Cora` 和 `CiteSeer` 数据集上执行节点分类。最后，我们将对这些结果进行评论并进行比较。
- en: 'Let’s start with the `Cora` dataset:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `Cora` 数据集开始：
- en: 'We import `Cora` from the `Planetoid` class using PyG:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从 PyG 导入 `Cora` 数据集中的 `Planetoid` 类：
- en: '[PRE11]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We import the necessary libraries to create our own GAT class, using the GATv2
    layer:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入必要的库来创建我们自己的 GAT 类，使用 GATv2 层：
- en: '[PRE12]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We implement the `accuracy()` function to evaluate the performance of our model:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现 `accuracy()` 函数来评估模型的性能：
- en: '[PRE13]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The class is initialized with two improved graph attention layers. Note it
    is important to declare the number of heads used for multi-head attention. The
    authors stated that eight heads improved performance for the first layer, but
    it didn’t make any difference for the second one:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该类初始化时包含两个改进的图注意力层。注意，声明多头注意力所使用的头数非常重要。作者指出，八个头对于第一层性能有所提升，但对于第二层没有任何影响：
- en: '[PRE14]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Compared to the previous implementation of a GCN, we’re adding two dropout
    layers to prevent overfitting. These layers randomly zero some values from the
    input tensor with a predefined probability (`0.6` in this case). Conforming to
    the original paper, we also use the **Exponential Linear Unit** (**ELU**) function,
    which is the exponential version of the Leaky ReLU:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与之前实现的 GCN 相比，我们添加了两个 dropout 层来防止过拟合。这些层以预定义的概率（在此情况下为 `0.6`）随机将一些值从输入张量中置为零。为了符合原论文，我们还使用了
    **指数线性单元**（**ELU**）函数，它是 Leaky ReLU 的指数版本：
- en: '[PRE15]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `fit()` function is identical to the GCN’s. The parameters of the Adam
    optimizer have been tuned to match the best values for the `Cora` dataset, according
    to the authors:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`fit()` 函数与 GCN 的相同。根据作者的说法，Adam 优化器的参数已经调整，以匹配 `Cora` 数据集的最佳值：'
- en: '[PRE16]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `test()` function is exactly the same:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`test()` 函数完全相同：'
- en: '[PRE17]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We create a GAT and train it for `100` epochs:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个 GAT 并训练它 `100` 个周期：
- en: '[PRE18]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This outputs the final test accuracy:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这输出了最终的测试准确度：
- en: '[PRE19]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This accuracy score is slightly better than the average score we obtained with
    a GCN. We’ll make a proper comparison after applying the GAT architecture to the
    second dataset.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个准确度分数略高于我们用 GCN 获得的平均分数。我们将在将 GAT 架构应用于第二个数据集后做出适当的比较。
- en: 'We will use a new popular dataset for node classification called `CiteSeer`
    (MIT License). Like `Cora`, it represents a network of research papers where each
    connection is a citation. `CiteSeer` involves `3327` nodes, whose features represent
    the presence (1) or absence (0) of `3703` words in a paper. The goal of this dataset
    is to correctly classify these nodes into six categories. *Figure 7**.4* shows
    a plot of `CiteSeer` made with yEd Live:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个新的流行节点分类数据集 `CiteSeer`（MIT 许可证）。与 `Cora` 类似，它代表了一个研究论文的网络，每个连接都是一个引用。`CiteSeer`
    涉及 `3327` 个节点，这些节点的特征表示论文中 `3703` 个单词的存在（1）或不存在（0）。该数据集的目标是将这些节点正确分类为六个类别。*图 7.4*
    显示了使用 yEd Live 绘制的 `CiteSeer` 图：
- en: '![Figure 7.4 – The CiteSeer dataset (made with yEd Live)](img/B19153_07_004.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – CiteSeer 数据集（使用 yEd Live 绘制）](img/B19153_07_004.jpg)'
- en: Figure 7.4 – The CiteSeer dataset (made with yEd Live)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – CiteSeer 数据集（使用 yEd Live 绘制）
- en: 'Compared to `Cora`, this dataset is larger in terms of the number of nodes
    (from 2,708 to 3,327) and also in terms of feature dimensionality (from 1,433
    to 3,703). However, the exact same process can be applied to it:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `Cora` 相比，这个数据集在节点数量（从 2,708 到 3,327）和特征维度（从 1,433 到 3,703）上都更大。然而，可以应用完全相同的过程：
- en: 'First, we load the `CiteSeer` dataset:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们加载 `CiteSeer` 数据集：
- en: '[PRE20]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For good measure, we plot the number of nodes per node degree, using the code
    from the last chapter:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更好地衡量，我们绘制了每个节点度数的节点数，使用了上一章的代码：
- en: '[PRE21]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It gives us the following output:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它给出了以下输出：
- en: '![Figure 7.5 – Number of nodes per node degree (CiteSeer)](img/B19153_07_005.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – 每个节点度数的节点数（CiteSeer）](img/B19153_07_005.jpg)'
- en: Figure 7.5 – Number of nodes per node degree (CiteSeer)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – 每个节点度数的节点数（CiteSeer）
- en: '*Figure 7**.5* looks like a typical heavy-tailed distribution but with a twist:
    some nodes have a degree of zero! In other words, they are not connected to any
    other node. We can assume that they will be much more difficult to classify than
    the rest.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.5* 看起来像是典型的重尾分布，但有所不同：一些节点的度数为零！换句话说，它们没有连接到任何其他节点。我们可以假设它们会比其他节点更难分类。'
- en: 'We initialize a new GAT model with the correct number of input and output nodes
    and train it for `100` epochs:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们初始化一个新的 GAT 模型，具有正确的输入和输出节点数，并训练它 `100` 个周期：
- en: '[PRE22]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We obtain the following test accuracy score:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获得了以下测试准确度分数：
- en: '[PRE23]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Is it a good result? This time, we have no point of comparison.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个好结果吗？这次，我们没有比较的标准。
- en: According to Schur et al. in *Pitfalls of Graph Neural Network Evaluation*,
    the GAT is slightly better than the GCN (82.8% ± 0.6% versus 81.9% ± 0.8%) on
    `Cora` and `CiteSeer` (71.0 ± 0.6% versus 69.5% ± 0.9%). The authors also note
    that the accuracy scores are not normally distributed, making the usage of standard
    deviation less relevant. It is important to keep that in mind in this type of
    benchmark.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Schur 等人在 *图神经网络评估的陷阱* 中的研究，GAT 在 `Cora` 和 `CiteSeer` 上的表现略优于 GCN（82.8% ±
    0.6% 对比 81.9% ± 0.8%，71.0 ± 0.6% 对比 69.5% ± 0.9%）。作者还指出，准确度分数并非正态分布，这使得标准差的使用变得不那么相关。在这种基准测试中需要记住这一点。
- en: 'Previously, I speculated that poorly connected nodes might negatively impact
    performance. We can verify this hypothesis by plotting the average accuracy score
    for each node degree:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我推测连接较差的节点可能会对性能产生负面影响。我们可以通过绘制每个节点度数的平均准确率来验证这一假设：
- en: 'We get the model’s classifications:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获得模型的分类结果：
- en: '[PRE24]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We calculate the degree of each node:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算每个节点的度数：
- en: '[PRE25]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We store the accuracy scores and sample sizes:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们存储了准确率分数和样本大小：
- en: '[PRE26]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We get the average accuracy for each node degree between zero and five using
    a mask with `np.where()`:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`np.where()`计算每个节点度数介于零和五之间的平均准确率：
- en: '[PRE27]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We repeat this process for every node with a degree higher than five:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对每个度数大于五的节点重复这一过程：
- en: '[PRE28]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We plot these accuracy scores with the corresponding node degrees:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们绘制了这些准确率分数与对应的节点度数：
- en: '[PRE29]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'It outputs the following graph:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它输出以下图形：
- en: '![Figure 7.6 – Accuracy score per node degree (CiteSeer)](img/B19153_07_006.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6 – 每个节点度数的准确率（CiteSeer）](img/B19153_07_006.jpg)'
- en: Figure 7.6 – Accuracy score per node degree (CiteSeer)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 每个节点度数的准确率（CiteSeer）
- en: '*Figure 7**.6* confirms our hypothesis: nodes with few neighbors are harder
    to classify correctly. Furthermore, it even shows that, in general, the higher
    the node degree, the better the accuracy score. This is quite natural because
    a higher number of neighbors will provide more information to the GNN to make
    its predictions.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.6*验证了我们的假设：邻居较少的节点更难正确分类。此外，它甚至显示出通常节点度数越高，准确率越好。这是非常自然的，因为更多的邻居将为GNN提供更多的信息，从而帮助它做出预测。'
- en: Summary
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we introduced a new essential architecture: the GAT. We saw
    its inner workings with four main steps, from linear transformation to multi-head
    attention. We saw how it works in practice by implementing a graph attention layer
    in NumPy. Finally, we applied a GAT model (with GATv2) to the `Cora` and `CiteSeer`
    datasets, where it provided excellent accuracy scores. We showed that these scores
    were dependent on the number of neighbors, which is a first step toward error
    analysis.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们介绍了一个新的重要架构：GAT。我们通过四个主要步骤了解了其内部工作原理，从线性变换到多头注意力。我们通过在NumPy中实现图注意力层，实际展示了它的工作方式。最后，我们将GAT模型（包括GATv2）应用于`Cora`和`CiteSeer`数据集，并取得了优异的准确率分数。我们展示了这些分数依赖于邻居的数量，这是进行错误分析的第一步。
- en: In [*Chapter 8*](B19153_08.xhtml#_idTextAnchor096), *Scaling Graph Neural Networks
    with GraphSAGE*, we will introduce a new architecture dedicated to managing large
    graphs. To test this claim, we will implement it on a new dataset several times
    bigger than what we’ve seen so far. We will talk about transductive and inductive
    learning, which is an important distinction for GNN practitioners.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第8章*](B19153_08.xhtml#_idTextAnchor096)，*使用GraphSAGE扩展图神经网络*中，我们将介绍一种专门用于管理大规模图的新架构。为了验证这一说法，我们将在一个比我们目前看到的数据集大数倍的全新数据集上多次实现该架构。我们将讨论传导性学习和归纳性学习，这对于图神经网络（GNN）实践者来说是一个重要的区分。
- en: 'Part 3: Advanced Techniques'
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：高级技术
- en: In this third part of the book, we will delve into the more advanced and specialized
    GNN architectures that have been developed to solve a variety of graph-related
    problems. We will cover state-of-the-art GNN models designed for specific tasks
    and domains, which can address challenges and requirements more effectively. In
    addition, we will provide an overview of several new graph-based tasks that can
    be tackled using GNNs, such as link prediction and graph classification, and demonstrate
    their applications through practical code examples and implementations.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第三部分，我们将深入探讨已开发的更多先进和专门化的GNN架构，这些架构旨在解决各种与图相关的问题。我们将介绍为特定任务和领域设计的最先进的GNN模型，这些模型能更有效地应对挑战和需求。此外，我们还将概述一些可以使用GNN解决的新图任务，如链接预测和图分类，并通过实际的代码示例和实现展示它们的应用。
- en: By the end of this part, you will be able to understand and implement advanced
    GNN architectures and apply them to solve your own graph-based problems. You will
    have a comprehensive understanding of specialized GNNs and their respective strengths,
    as well as hands-on experience with code examples. This knowledge will equip you
    with the skills to apply GNNs to real-world use cases and potentially contribute
    to the development of new and innovative GNN architectures.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分结束时，您将能够理解并实现先进的GNN架构，并将其应用于解决您自己的图相关问题。您将全面了解专业化的GNN及其各自的优势，并通过代码示例获得实践经验。这些知识将使您能够将GNN应用于实际的使用场景，并有可能为新的创新型GNN架构的发展做出贡献。
- en: 'This part comprises the following chapters:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 8*](B19153_08.xhtml#_idTextAnchor096)*, Scaling Up Graph Neural Networks
    with GraphSAGE*'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B19153_08.xhtml#_idTextAnchor096)*，使用GraphSAGE扩展图神经网络*'
- en: '[*Chapter 9*](B19153_09.xhtml#_idTextAnchor106)*, Defining Expressiveness for
    Graph Classification*'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B19153_09.xhtml#_idTextAnchor106)*，为图分类定义表达能力*'
- en: '[*Chapter 10*](B19153_10.xhtml#_idTextAnchor116)*, Predicting Links with Graph
    Neural Networks*'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B19153_10.xhtml#_idTextAnchor116)*，使用图神经网络预测链接*'
- en: '[*Chapter 11*](B19153_11.xhtml#_idTextAnchor131)*, Generating Graphs Using
    Graph Neural Networks*'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B19153_11.xhtml#_idTextAnchor131)*，使用图神经网络生成图*'
- en: '[*Chapter 12*](B19153_12.xhtml#_idTextAnchor144)*, Learning from Heterogeneous
    Graphs*'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B19153_12.xhtml#_idTextAnchor144)*，从异构图中学习*'
- en: '[*Chapter 13*](B19153_13.xhtml#_idTextAnchor153)*, Temporal Graph Neural Networks*'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B19153_13.xhtml#_idTextAnchor153)*，时序图神经网络*'
- en: '[*Chapter 14*](B19153_14.xhtml#_idTextAnchor165)*, Explaining Graph Neural
    Networks*'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第14章*](B19153_14.xhtml#_idTextAnchor165)*，解释图神经网络*'
