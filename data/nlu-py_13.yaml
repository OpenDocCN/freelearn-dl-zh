- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: How Well Does It Work? – Evaluation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它工作得怎么样？——评估
- en: In this chapter, we will address the question of quantifying how well a **natural
    language understanding** (**NLU**) system works. Throughout this book, we assumed
    that we want the NLU systems that we develop to do a good job on the tasks that
    they are designed for. However, we haven’t dealt in detail with the tools that
    enable us to tell how well a system works – that is, how to evaluate it. This
    chapter will illustrate a number of evaluation techniques that will enable you
    to tell how well the system works, as well as to compare systems in terms of performance.
    We will also look at some ways to avoid drawing erroneous conclusions from evaluation
    metrics.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论如何量化一个**自然语言理解**（**NLU**）系统的效果。在本书的整个过程中，我们假设我们希望开发的NLU系统能够在其设计的任务上表现良好。然而，我们并没有详细讨论使我们能够判断系统表现如何的工具——也就是如何评估系统。本章将介绍一些评估技术，帮助你了解系统的表现如何，以及如何在性能上比较不同的系统。我们还将探讨一些避免从评估指标中得出错误结论的方法。
- en: 'The topics we will cover in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论的主题如下：
- en: Why evaluate an NLU system?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么要评估自然语言理解系统？
- en: Evaluation paradigms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估范式
- en: Data partitioning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分割
- en: Evaluation metrics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估指标
- en: User testing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户测试
- en: Statistical significance of differences
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 差异的统计显著性
- en: Comparing three text classification methods
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较三种文本分类方法
- en: We will start by asking the question of why it’s important to evaluate NLU systems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从为什么评估自然语言理解系统非常重要这个问题开始。
- en: Why evaluate an NLU system?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要评估自然语言理解系统？
- en: There are many questions that we can ask about the overall quality of an NLU
    system, and evaluating it is the way that we answer these questions. How we evaluate
    depends on the goal of developing the system and what we want to learn about the
    system to make sure that the goal is achieved.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以提出许多关于自然语言理解系统整体质量的问题，评估它就是回答这些问题的方式。我们如何评估取决于系统开发的目标以及我们想要了解系统的哪些方面，以确保目标得以实现。
- en: 'Different kinds of developers will have different goals. For example, consider
    the goals of the following types of developers:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的开发者有不同的目标。例如，考虑以下类型的开发者的目标：
- en: I am a researcher, and I want to learn whether my ideas advance the science
    of NLU. Another way to put this is to ask how my work compares to the **state
    of the art** (**SOTA**) – that is, the best results that anyone has reported on
    a particular task.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是一个研究员，我想知道我的想法是否推动了自然语言理解（**NLU**）科学的发展。换句话说，我想知道我的工作与**最新技术**（**SOTA**）相比如何——也就是说，与在某个特定任务上任何人报告的最佳结果相比，我的工作如何。
- en: I am a developer, and I want to make sure that my overall system performance
    is good enough for an application.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是一个开发者，我想确保我的整体系统性能足够好，适用于某个应用。
- en: I am a developer, and I want to see how much my changes improve a system.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是一个开发者，我想看看我的修改如何提高系统的表现。
- en: I am a developer, and I want to make sure my changes have not decreased a system’s
    performance.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是一个开发者，我想确保我的修改没有降低系统的性能。
- en: I am a researcher or developer who wants to know how my system performs on different
    classes of data.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是一个研究员或开发者，我想知道我的系统在不同数据类别上的表现如何。
- en: The most important question for all of these developers and researchers is,
    *how well does the system perform its* *intended function?*
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对所有这些开发者和研究员来说，最重要的问题是，*系统在执行其* *预期功能* 时表现如何？
- en: 'This is the question we will focus on in this chapter, and we will address
    how each of these different kinds of developers discovers the information they
    need. However, there are other important NLU system properties that can be evaluated,
    and sometimes, these will be more important than overall system performance. It
    is worth mentioning them briefly so that you are aware of them. For example, other
    aspects of evaluation questions include the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点讨论的问题是：如何让不同类型的开发者获取他们所需的信息。然而，还有其他重要的自然语言理解系统属性可以评估，有时这些可能比整体系统性能更为重要。值得简要提及这些，以便你了解它们。例如，其他评估问题的方面包括：
- en: '**The size of the machine learning model that supports the application**: Today’s
    models can be very large, and there is significant research effort directed at
    making models smaller without significantly degrading their performance. If it
    is important to have a small model, you will want to look at the trade-offs between
    model size and accuracy.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持应用程序的机器学习模型大小**：如今的模型可以非常庞大，并且有大量的研究致力于使模型变得更小而不显著降低其性能。如果需要小型模型，则需要权衡模型大小与准确性之间的关系。'
- en: '**Training time**: Some algorithms require training time on the order of several
    weeks on highly capable GPU processors, especially if they are training on large
    datasets. Reducing this time makes it much easier to experiment with alternative
    algorithms and tuning hyperparameters. In theory, larger models will provide better
    results, at the cost of more training time, but in practice, we need to ask how
    much difference do they make in the performance of any particular task?'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练时间**：一些算法需要在高度强大的GPU处理器上进行几个星期的训练时间，尤其是当它们训练的是大规模数据集时。缩短训练时间可以大大简化实验不同算法和调整超参数的过程。从理论上讲，较大的模型会提供更好的结果，但代价是更多的训练时间，但在实践中，我们需要问的是，这些更大的模型在任何特定任务的表现上有多大差异？'
- en: '**Amount of training data**: Today’s **large language models** (**LLMs**) require
    enormous amounts of training data. In fact, in the current SOTA, this amount of
    data is prohibitively large for all but the largest organizations. However, as
    we saw in [*Chapter 11*](B19005_11.xhtml#_idTextAnchor193), LLMs can be fine-tuned
    with application-specific data. The other consideration for training data is whether
    there is enough data available to train a system that works well.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据量**：如今的**大规模语言模型**（**LLMs**）需要大量的训练数据。事实上，在当前的SOTA（最先进技术）中，数据量对于除最大型组织之外的所有机构来说都是过于庞大的。然而，正如我们在[*第11章*](B19005_11.xhtml#_idTextAnchor193)中看到的那样，LLMs可以通过特定应用的数据进行微调。另一个关于训练数据的考量是，是否有足够的数据来训练一个能够良好工作的系统。'
- en: '**The expertise of developers**: Depending on highly expert developers is expensive,
    so a development process that can be performed by less expert developers is usually
    desirable. The rule-based systems discussed in [*Chapter 8*](B19005_08.xhtml#_idTextAnchor159),often
    require highly expert developers, which is one reason that they tend to be avoided
    if possible. On the other hand, experimenting with SOTA deep learning models can
    call for the knowledge of expert data scientists, who can also be expensive and
    hard to find.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发者的专业知识**：依赖于高度专业的开发者成本很高，因此通常希望有一个可以由较少经验的开发者执行的开发过程。在[*第8章*](B19005_08.xhtml#_idTextAnchor159)中讨论的基于规则的系统，通常需要高度专业的开发者，这也是它们往往尽可能避免使用的原因之一。另一方面，实验最先进的深度学习模型可能需要专家数据科学家的知识，而这些专家既昂贵又难以找到。'
- en: '**Cost of training**: The training costs for very large models are in the range
    of millions of dollars, even if we are only taking into account the cost of computing
    resources. A lower training cost is clearly a desirable property of an NLU system.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练成本**：对于非常大的模型，训练成本通常在几百万美元的范围内，即使只考虑计算资源的成本。较低的训练成本显然是自然语言理解（NLU）系统的一项理想特性。'
- en: '**Environmental impact**: Closely related to the cost of training is its environmental
    impact in terms of energy expenditure, which can be very high. Reducing this is
    obviously desirable.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境影响**：与训练成本密切相关的是其在能源消耗方面的环境影响，这可能非常高。显然，减少这种影响是非常理想的。'
- en: '**Processing time for inference**: This question relates to how long it takes
    a trained system to process an input and deliver results. With today’s systems,
    this is not usually a problem, with the short inputs that are used with interactive
    systems such as chatbots or spoken dialog systems. Almost any modern approach
    will enable them to be processed quickly enough that users will not be annoyed.
    However, with offline applications such as analytics, where an application may
    need to extract information from many hours of audio or gigabytes of text, slow
    processing times will add up.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理的处理时间**：这个问题涉及到训练好的系统处理输入并给出结果所需的时间。对于今天的系统来说，这通常不是问题，特别是在聊天机器人或语音对话系统等互动系统中使用的短输入。几乎任何现代方法都能让它们快速处理到足够的速度，用户不会感到烦恼。然而，对于离线应用（如分析）而言，如果一个应用需要从数小时的音频或数GB的文本中提取信息，处理时间较慢将会积累起来。'
- en: '**Budget**: Paid cloud-based LLMs such as GPT-4 usually provide very good results,
    but a local open source model such as BERT could be much cheaper and give results
    that are good enough for a specific application.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预算**：像GPT-4这样的付费云端大型语言模型（LLMs）通常能提供非常好的结果，但像BERT这样的本地开源模型可能便宜得多，且能为特定应用提供足够好的结果。'
- en: 'Even though these properties can be important to know when we’re deciding on
    which NLU approach to use, how well an NLU system works is probably the most important.
    As developers, we need the answers to such fundamental questions as the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 即便这些属性在我们决定使用哪种NLU方法时可能很重要，但NLU系统的实际效果可能是最重要的。作为开发者，我们需要回答一些基础性问题，例如：
- en: '*Does this system perform its intended functions well enough to* *be useful?*'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*这个系统的表现是否足够好，能够* *满足预期功能并且* *有用？*'
- en: '*As changes are made in the system, is it* *getting better?*'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*随着系统的变化，它是否在不断* *变得更好？*'
- en: '*How does this system’s performance compare to the performance of* *other systems?*'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*这个系统的表现与* *其他系统的表现相比如何？*'
- en: The answers to these questions require evaluation methods that assign numerical
    values to a system’s performance. Subjective or non-quantitative evaluation, where
    a few people look at a system’s performance and decide whether it *looks good*
    or not, is not precise enough to provide reliable answers to those questions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的答案需要评估方法来给系统的性能分配数值。主观的或非定量的评估方法（例如少数人查看系统的表现并决定它是否*看起来好*）不够精确，无法为这些问题提供可靠的答案。
- en: We will start our discussion of evaluation by reviewing some overall approaches
    to evaluation, or *evaluation paradigms*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过回顾一些整体的评估方法来开始我们的评估讨论，或称为*评估范式*。
- en: Evaluation paradigms
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估范式
- en: In this section, we will review some of the major evaluation paradigms that
    are used to quantify system performance and compare systems.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾一些用于量化系统性能并比较系统的主要评估范式。
- en: Comparing system results on standard metrics
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较系统在标准指标上的表现
- en: This is the most common evaluation paradigm and probably the easiest to carry
    out. The system is simply given data to process, and its performance is evaluated
    quantitatively based on standard metrics. The upcoming *Evaluation metrics* section
    will delve into this topic in much greater detail.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最常见的评估范式，可能也是最容易执行的。系统只需处理数据，并根据标准指标对其表现进行定量评估。即将到来的*评估指标*部分将更详细地探讨这个话题。
- en: Evaluating language output
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估语言输出
- en: Some NLU applications produce natural language output. These include applications
    such as translation or summarizing text. They differ from applications with a
    specific right or wrong answer, such as classification and slot filling, because
    there is no single correct answer – there could be many good answers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一些自然语言理解（NLU）应用程序生成自然语言输出。这些应用包括翻译或文本摘要等。它们与需要给出明确对错答案的应用不同，如分类和槽填充，因为在这些应用中没有唯一正确的答案——可能有许多好的答案。
- en: One way to evaluate machine translation quality is for humans to look at the
    original text and the translation and judge how accurate it is, but this is usually
    too expensive to be used extensively. For that reason, metrics have been developed
    that can be applied automatically, although they are not as satisfactory as human
    evaluation. We will not cover these in detail here, but we will briefly list them
    so that you can investigate them if you need to evaluate language output.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器翻译质量的一种方法是让人类查看原文和翻译，并判断其准确性，但这种方法通常过于昂贵，无法广泛使用。因此，已经开发出了可以自动应用的指标，尽管它们不如人工评估令人满意。我们在这里不会详细讨论这些指标，但会简要列出它们，以便你在需要评估语言输出时可以进一步研究。
- en: The **bilingual evaluation understudy** (**BLEU**) metric is one well-established
    metric to evaluate translations. This metric is based on comparing machine translation
    results to human translations and measuring the difference. Because it is possible
    that a very good machine translation will be quite different from any particular
    human translation, the BLEU scores will not necessarily correspond to human judgments
    of translation quality. Other evaluation metrics for applications that produce
    language output include the **metric for evaluation for translation with explicit
    ordering** (**METEOR**), the **recall-oriented understudy for gisting evaluation**
    (**ROUGE**), and the **cross-lingual optimized metric for evaluation of** **translation**
    (**COMET**).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**双语评估替代指标**（**BLEU**）是评估翻译质量的一个公认的指标。这个指标通过将机器翻译结果与人工翻译进行对比，衡量二者之间的差异。由于非常优秀的机器翻译与任何特定的人工翻译可能有很大不同，因此BLEU分数不一定能与人工翻译质量评判一致。其他用于评估语言输出应用程序的指标包括**带显式顺序的翻译评估指标**（**METEOR**）、**摘要评估的召回导向替代指标**（**ROUGE**）和**跨语言优化翻译评估指标**（**COMET**）。'
- en: In the next section, we will discuss an approach to evaluation that involves
    removing part of a system to determine what effect it has on the results. Does
    it make the results better or worse, or does it not result in any changes?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将讨论一种评估方法，该方法涉及去除系统的一部分，以确定它对结果的影响。这是否会使结果变得更好或更差，还是根本不会造成任何变化？
- en: Leaving out part of a system – ablation
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 去除系统的一部分——消融
- en: If an experiment includes a pipeline of several operations, it’s often informative
    to compare results by removing steps in the pipeline. This is called **ablation**,
    and it is useful in two different situations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个实验包括多个操作步骤的流水线，通常通过去除流水线中的步骤来比较结果会提供更多信息。这种方法叫做**消融**，它在两种不同情况下都非常有用。
- en: The first case is when an experiment is being done for a research paper or an
    academic project that includes some innovative techniques in the pipeline. In
    that case, you want to be able to quantify what effect every step in the pipeline
    had on the final outcome. This will allow readers of the paper to evaluate the
    importance of each step, especially if the paper is attempting to show that one
    or more of the steps is a major innovation. If the system still performs well
    when the innovations are removed, then they are unlikely to be making a significant
    contribution to the system’s overall performance. Ablation studies will enable
    you to find out exactly what contributions are made by each step.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个情况是当实验用于研究论文或包含一些创新技术的学术项目时。在这种情况下，你希望能够量化流水线中每个步骤对最终结果的影响。这将使论文的读者能够评估每个步骤的重要性，特别是如果论文试图展示某个步骤或多个步骤是一个重要的创新。如果去除这些创新后系统仍然表现良好，那么这些创新可能对系统整体性能的贡献并不显著。消融研究将帮助你准确了解每个步骤的贡献。
- en: The second case for ablation is more practical and occurs when you’re working
    on a system that needs to be computationally efficient for deployment. By comparing
    versions of a system with and without specific steps in the pipeline, you can
    decide whether the amount of time that they take justifies the degree of improvement
    they make in the system’s performance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 消融的第二个情况更为实际，发生在你正在开发一个需要在部署时具有计算效率的系统时。通过比较有无特定步骤的系统版本，你可以判断这些步骤所花费的时间是否值得它们对系统性能的提升。
- en: An example of why you would want to consider doing an ablation study for this
    second reason could include finding out whether preprocessing steps such as stopword
    removal, lemmatization, or stemming make a difference in the system’s performance.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑做消融研究的第二个原因的一个例子可能是，了解像停用词去除、词形还原或词干提取这样的预处理步骤是否对系统的性能有影响。
- en: Another approach to evaluation involves a test where several independent systems
    process the same data and the results are compared. These are shared tasks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种评估方法涉及一个测试，其中多个独立系统处理相同的数据并进行结果比较。这些就是共享任务。
- en: Shared tasks
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 共享任务
- en: The field of NLU has long benefited from comparing systems on **shared tasks**,
    where systems developed by different developers are all tested on a single set
    of shared data on a specific topic and the results are compared. In addition,
    the teams working on the shared task usually publish system descriptions that
    provide very useful insights into how their systems achieved their results.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**自然语言理解（NLU）**领域长期以来受益于在**共享任务**上进行系统比较，其中不同开发人员开发的系统都在一组特定主题的共享数据上进行测试，结果进行比较。此外，参与共享任务的团队通常会发布系统描述，提供关于他们的系统如何达到这些结果的非常有用的见解。'
- en: 'The shared task paradigm has two benefits:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 共享任务范式有两个好处：
- en: First, it enables developers who participate in the shared task to get precise
    information about how their system compares to others because the data is exactly
    the same
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，它使得参与共享任务的开发人员能够精确地获得关于他们的系统与其他系统的比较信息，因为数据是完全相同的。
- en: Second, the data used in the shared tasks is made available to the research
    community for use in developing future systems
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，参与共享任务的数据可以提供给研究社区，用于开发未来的系统。
- en: Shared data can be useful for a long time because it is not affected by changes
    in NLU technology – for example, the **air travel information system** (**ATIS**)
    data from a travel planning task has been in use since the early 1990s.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 共享数据可以长期使用，因为它不受NLU技术变化的影响——例如，旅行规划任务中的**航空旅行信息系统**（**ATIS**）数据自1990年代初以来一直在使用。
- en: The *NLP-progress* website at [http://nlpprogress.com/](http://nlpprogress.com/)
    is a good source of information on shared tasks and shared task data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*NLP-progress* 网站 [http://nlpprogress.com/](http://nlpprogress.com/) 是一个关于共享任务和共享任务数据的良好信息来源。'
- en: In the next section, we will look at ways of dividing data into subsets in preparation
    for evaluation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何将数据划分为子集，以为评估做准备。
- en: Data partitioning
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据划分
- en: In earlier chapters, we divided our datasets into subsets used for *training*,
    *validation*, and *testing*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们将数据集划分为用于*训练*、*验证*和*测试*的子集。
- en: As a reminder, training data is used to develop the NLU model that is used to
    perform the eventual task of the NLU application, whether that is classification,
    slot-filling, intent recognition, or most other NLU tasks.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，训练数据用于开发**自然语言理解（NLU）**模型，该模型用于执行最终的NLU应用任务，无论是分类、槽位填充、意图识别还是其他大多数NLU任务。
- en: '**Validation data** (sometimes called **development test** data) is used during
    training to assess the model on data that was not used in training. This is important
    because if the system is tested on the training data, it could get a good result
    simply by, in effect, memorizing the training data. This would be misleading because
    that kind of system isn’t very useful – we want the system to generalize or work
    well on the new data that it’s going to get when it is deployed. Validation data
    can also be used to help tune hyperparameters in machine learning applications,
    but this means that during development, the system has been exposed a bit to the
    validation data, and as a consequence, that data is not as novel as we would like
    it to be.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证数据**（有时称为**开发测试**数据）在训练过程中用于评估模型在未用于训练的数据上的表现。这非常重要，因为如果系统在训练数据上进行测试，它可能只是通过“记住”训练数据来获得良好的结果。这是误导性的，因为那种系统并不十分有用——我们希望系统能够在部署后面对新的数据时，具有良好的泛化能力或表现。验证数据还可以用于帮助调整机器学习应用中的超参数，但这意味着在开发过程中，系统已经暴露了一些验证数据，因此这些数据不如我们希望的那样具有新颖性。'
- en: For that reason, another set of completely new data is typically held out for
    a final test; this is the test data. In preparation for system development, the
    full dataset is partitioned into training, validation, and test data. Typically,
    around 80% of the full dataset is allocated to training, 10% is allocated to validation,
    and 10% is allocated to testing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通常会预留另一组全新的数据进行最终测试；这就是测试数据。为了系统开发的准备，完整的数据集会被划分为训练数据、验证数据和测试数据。通常，大约80%的数据集用于训练，10%用于验证，10%用于测试。
- en: 'There are three general ways that data can be partitioned:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据划分的三种常见方式：
- en: 'In some cases, the dataset is already partitioned into training, validation,
    and testing sets. This is most common in generally available datasets such as
    those we have used in this book or shared tasks. Sometimes, the data is only partitioned
    into training and testing. If so, a subset of the training data should be used
    for validation. Keras provides a useful utility, `text_dataset_from_directory`,
    that loads a dataset from a directory, using subdirectory names for the supervised
    categories of the text in the directories, and partitions a validation subset.
    In the following code, the training data is loaded from the `aclImdb/train` directory,
    and then 20% of the data is split out to be used as validation data:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些情况下，数据集已经被划分为训练集、验证集和测试集。这在一些普遍可用的数据集中最为常见，例如我们在本书中使用的数据集或共享任务中的数据集。有时，数据只会被划分为训练集和测试集。如果是这样，应该使用训练数据的一个子集作为验证集。Keras
    提供了一个有用的工具 `text_dataset_from_directory`，它可以从目录中加载数据集，使用子目录名作为目录中文本的监督类别，并划分出一个验证子集。在以下代码中，训练数据是从
    `aclImdb/train` 目录加载的，然后将 20% 的数据划分出来作为验证数据：
- en: '[PRE0]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of course, making use of a previous partition is only useful when you work with
    generally available datasets that have already been partitioned. If you have your
    own data, you will need to do your own partitioning. Some of the libraries that
    we’ve been working with have functions that can automatically partition the data
    when it is loaded. For example, scikit-learn, TensorFlow, and Keras have `train_test_split`
    functions that can be used for this.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当然，使用先前的划分只有在你使用的是已经划分过的数据集时才有意义。如果你有自己的数据，你将需要自己进行数据划分。我们使用的一些库具有能够在加载数据时自动进行划分的功能。例如，scikit-learn、TensorFlow
    和 Keras 都有可以用于此目的的 `train_test_split` 函数。
- en: You can also manually write Python code to partition your dataset. Normally,
    it would be preferable to work with pretested code from a library, so writing
    your own Python code for this would not be recommended unless you are unable to
    find a suitable library, or you are simply interested in the exercise of learning
    more about the partitioning process.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你也可以手动编写 Python 代码来划分你的数据集。通常，最好使用来自库的经过测试的代码，因此除非你无法找到合适的库，或者你只是对学习更多关于划分过程的内容感兴趣，否则不推荐编写自己的
    Python 代码来完成这个任务。
- en: The final data partitioning strategy is called **k-fold cross-validation**.
    This strategy involves partitioning the whole dataset into *k* subsets, or *folds*,
    and then treating each of the folds as test data for an evaluation of the system.
    The overall system score in *k*-fold cross-validation is the average score of
    all of the tests.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的数据划分策略称为**k-折交叉验证**。该策略涉及将整个数据集划分为 *k* 个子集，或称 *folds*，然后将每一个 fold 作为测试数据来评估系统。在
    *k*-折交叉验证中的整体系统得分是所有测试的平均得分。
- en: The advantage of this approach is that it reduces the chances of an accidental
    difference between the test and training data, leading to a model that gives poor
    predictions for new test examples. It is harder for an accidental difference to
    affect the results in *k*-fold cross-validation because there is no strict line
    between training and test data; the data in each fold takes a turn at being the
    test data. The disadvantage of this approach is that it multiplies the amount
    of time it takes to test the system by *k*, which could become very large if the
    dataset is also large.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优点是它减少了测试数据和训练数据之间意外差异的可能性，从而避免了模型在对新测试样本进行预测时效果不佳。由于在 *k*-折交叉验证中，训练数据和测试数据之间没有严格的划分，因此意外差异更难影响结果；每一折的数据轮流作为测试数据。该方法的缺点是它将测试系统所需的时间乘以
    *k*，如果数据集很大，这个时间可能会变得非常长。
- en: Data partitioning is necessary for almost every evaluation metric that we will
    discuss in this chapter, with the exception of user testing.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据划分对于我们将在本章讨论的几乎每个评估指标都是必要的，唯一的例外是用户测试。
- en: In the next section, we will look at some of the most common specific quantitative
    metrics. In [*Chapter 9*](B19005_09.xhtml#_idTextAnchor173), we went over the
    most basic and intuitive metric, accuracy. Here, we will review other metrics
    that can usually provide better insights than accuracy and explain how to use
    them.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论一些最常见的具体定量指标。在[*第9章*](B19005_09.xhtml#_idTextAnchor173)中，我们介绍了最基本和直观的指标——准确率。在这里，我们将回顾其他通常能比准确率提供更好洞察的指标，并解释如何使用它们。
- en: Evaluation metrics
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'There are two important concepts that we should keep in mind when selecting
    an evaluation metric for NLP systems or, more generally, any system that we want
    to evaluate:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择用于自然语言处理（NLP）系统评估的指标时，或者更广泛地说，选择任何我们想评估的系统时，有两个重要的概念需要牢记：
- en: '**Validity**: The first is validity, which means that the metric corresponds
    to what we think of intuitively as the actual property we want to know about.
    For example, we wouldn’t want to pick the length of a text as a measurement for
    its positive or negative sentiment because the length of a text would not be a
    valid measure of its sentiment.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效性**：第一个是有效性，意味着该指标对应于我们直观上认为的我们想了解的实际属性。例如，我们不希望选择文本长度作为其积极或消极情感的衡量标准，因为文本长度不能作为其情感的有效度量。'
- en: '**Reliability**: The other important concept is reliability, which means that
    if we measure the same thing repeatedly, we always get the same result.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性**：另一个重要的概念是可靠性，意味着如果我们重复测量相同的事物，我们总能得到相同的结果。'
- en: In the next sections, we will look at some of the most commonly used metrics
    in NLU that are considered to be both valid and reliable.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论一些在自然语言理解（NLU）中最常用的、被认为既有效又可靠的指标。
- en: Accuracy and error rate
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确度和错误率
- en: In [*Chapter 9*](B19005_09.xhtml#_idTextAnchor173), we defined accuracy as the
    number of correct system responses divided by the overall number of inputs. Similarly,
    we defined **error rate** as incorrect responses divided by the number of inputs.
    Note that you might encounter a **word error rate** when you read reports of speech
    recognition results. Because the word error rate is calculated according to a
    different formula that takes into account different kinds of common speech recognition
    errors, this is a different metric, which we will not cover here.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第9章*](B19005_09.xhtml#_idTextAnchor173)中，我们将准确度定义为正确系统响应的数量除以总输入数量。类似地，我们将**错误率**定义为错误响应除以输入数量。请注意，当你阅读语音识别结果报告时，可能会遇到**词错误率**。由于词错误率是根据一个不同的公式计算的，该公式考虑了不同类型的常见语音识别错误，因此这是一个不同的指标，我们在此不进行详细讨论。
- en: The next section will go over some more detailed metrics, precision, recall,
    and F1 score, which were briefly mentioned in [*Chapter 9*](B19005_09.xhtml#_idTextAnchor173).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将详细介绍一些更具体的指标，包括精度、召回率和F1分数，这些在[*第9章*](B19005_09.xhtml#_idTextAnchor173)中已有简要提及。
- en: These metrics usually provide more insight into a system’s processing results
    than accuracy.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标通常比准确度提供更多关于系统处理结果的洞察。
- en: Precision, recall, and F1
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精度、召回率和F1
- en: '**Accuracy** can give misleading results under certain conditions. For example,
    we might have a dataset where there are 100 items but the classes are unbalanced,
    and the vast majority of cases (say, 90) belong to one class, which we call the
    majority class. This is very common in real datasets. In that situation, 90% accuracy
    could be obtained by automatically assigning every case to the majority class,
    but the 10 remaining instances that belong to the other class (let’s assume we
    only have two classes for simplicity) would always be wrong. Intuitively, accuracy
    would seem to be an invalid and misleading metric for this situation. To provide
    a more valid metric, some refinements were introduced – most importantly, the
    concepts of recall and precision.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确度**在某些情况下可能会给出误导性的结果。例如，我们可能有一个包含100个项目的数据集，但类别不平衡，绝大多数情况（比如说90个）属于一个类别，我们称之为多数类。这在真实数据集中非常常见。在这种情况下，通过自动将每个案例分配给多数类，可以获得90%的准确度，但属于另一个类别的剩余10个实例（假设我们只有两个类别，简化讨论）将始终被分类错误。从直觉上讲，准确度似乎在这种情况下是不可靠且具有误导性的指标。为了提供更有效的指标，引入了一些改进——最重要的是召回率和精度的概念。'
- en: '**Recall** means that a system finds every example of a class and does not
    miss any. In our example, it correctly finds all 90 instances of the majority
    class but no instances of the other class.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**意味着一个系统能找到每一个类别的实例且不漏掉任何一个。在我们的例子中，它正确地找到了所有90个多数类的实例，但没有找到其他类别的任何实例。'
- en: 'The formula for recall is shown in the following equation, where *true positives*
    are instances of the class that were correctly identified, and *false negatives*
    are instances of that class that were missed. In our initial example, assuming
    that there are 100 items in the dataset, the system correctly found 90 (the majority
    class) but missed the 10 examples of the other class. Therefore, the recall score
    of the majority class is 1.0, but the recall score of the other class is 0:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率的公式如下所示，其中*真正例*是被正确识别的类别实例，*假负例*是被遗漏的该类别实例。在我们的初始例子中，假设数据集中有100个项目，系统正确识别了90个（多数类），但遗漏了10个属于其他类别的例子。因此，主要类别的召回率为1.0，但另一个类别的召回率为0：
- en: recall =  true positives  _____________________  true positives + false negatives
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: recall =  真正例  ________________  真正例 + 假负例
- en: 'On the other hand, **precision** means that whatever was identified was correct.
    Perfect precision means that no items were misidentified, although some items
    might have been missed. The following is the formula for precision, where *false
    positives* are instances that were misidentified. In this example, the false positives
    are the 10 items that were incorrectly identified as belonging to the majority
    class. In our example, the precision score for the majority class is 1.0, but
    for the other class, it is 0 because there are no *true positives*. The precision
    and recall scores in this example give us more detail about the kinds of mistakes
    that the system has made:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**精确率**意味着所有被识别的项目都是正确的。完美的精确率意味着没有项目被误识别，尽管可能会遗漏一些项目。精确率的公式如下，其中*假正例*是被误识别的实例。在这个例子中，假正例是10个被错误识别为属于多数类的项目。在我们的例子中，少数类的精确率为1.0，但对于另一个类别，精确率为0，因为没有*真正例*。这个例子中的精确率和召回率得分让我们更详细地了解系统犯了哪些错误：
- en: precision =  true positives  ____________________  true positives + false positives
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: precision =  真正例  ________________  真正例 + 假正例
- en: 'Finally, there is another important metric, **F**1, that combines precision
    and recall scores. This is a useful metric because we often want to have a single
    overall metric to describe a system’s performance. This is probably the most commonly
    used metric in NLU. The formula for F1 is as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有另一个重要的指标，**F**1，它结合了精确率和召回率的得分。这个指标非常有用，因为我们通常希望有一个单一的总体指标来描述系统的性能。这可能是自然语言理解（NLU）中最常用的指标。F1的公式如下：
- en: F 1 =  precision × recall  ____________  precision + recall
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: F1 =  精确率 × 召回率  ____________  精确率 + 召回率
- en: '*Figure 13**.1* shows correct and incorrect classifications graphically for
    one class. Items in the ellipse are identified as **Class 1**. The round markers
    inside the ellipse are true positives – items identified as **Class 1** that are
    actually **Class 1**. The square markers inside the ellipse are false positives
    – items in **Class 2** that are incorrectly identified as **Class 1**. Round markers
    outside of the ellipse are false negatives – items that are actually in **Class
    1** but were not recognized:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.1* 以图形方式展示了单类的正确和错误分类。椭圆内的项目被识别为**类别1**。椭圆内的圆形标记是真正例——被识别为**类别1**且实际属于**类别1**的项目。椭圆内的方形标记是假正例——实际属于**类别2**但错误地被识别为**类别1**的项目。椭圆外的圆形标记是假负例——实际属于**类别1**但未被识别的项目：'
- en: '![Figure 13.1 – The classification for one class](img/B19005_13_01.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1 – 单类分类](img/B19005_13_01.jpg)'
- en: Figure 13.1 – The classification for one class
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – 单类分类
- en: There is an assumption with the `F`1 metric that the recall and precision scores
    are equally important. This is true in many cases, but not always. For example,
    consider an application whose goal is to detect mentions of its company’s products
    in tweets. The developers of this system might consider it to be very important
    not to miss any tweets about their products. In that case, they will want to emphasize
    recall at the expense of precision, which means that they might get a lot of false
    positives – tweets that the system categorized as being about their product but
    actually were not. There are more general versions of the `F`1 metric that can
    be used to weight recall and precision if you develop a system where recall and
    precision are not equally important.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`F`1度量假设召回率和精确度的得分同等重要。这在许多情况下是正确的，但并非总是如此。例如，考虑一个目标是检测推文中提及公司产品的应用程序。该系统的开发人员可能认为，不错过任何关于其产品的推文非常重要。在这种情况下，他们可能会强调召回率，即使这会以牺牲精确度为代价，这意味着他们可能会得到许多假阳性——系统将某些推文分类为关于其产品的推文，但实际上并非如此。如果你开发的系统中召回率和精确度并不等同重要，可以使用更通用的`F`1度量版本来加权召回率和精确度。'
- en: The receiver operating characteristic and area under the curve
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接收操作特征与曲线下面积
- en: The decision of the class to which a test item belongs depends on its score
    for that class. If the item’s score exceeds a given threshold score (selected
    by the developer), then the system decides that the item does actually belong
    in that class. We can see that true positive and false positive scores can be
    affected by this threshold. If we make the threshold very high, few items will
    fall into that class, and the true positives will be lower. On the other hand,
    if the threshold is very low, the system will decide that many items fall into
    that class, the system will accept many items that don’t belong, and the false
    positives will be very high. What we really want to know is how good the system
    is at discriminating between classes at every threshold.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 测试项属于哪个类别的决策取决于它在该类别的得分。如果该项的得分超过了一个给定的阈值（由开发人员选择），系统就会判断该项确实属于该类别。我们可以看到，真正阳性和假阳性得分会受到这个阈值的影响。如果我们将阈值设置得非常高，很少有项会进入该类别，真正阳性会减少。另一方面，如果阈值设置得非常低，系统会判断许多项属于该类别，系统会接受许多不属于该类别的项，假阳性将会非常高。我们真正想知道的是，在每个阈值下，系统区分不同类别的能力如何。
- en: 'A good way to visualize the trade-off between false positives (precision failures)
    and false negatives (recall failures) is a graph called the **receiver operating
    characteristic** (**ROC**) and its related metric, the **area under the curve**
    (**AUC**). The ROC curve is a measurement of how good a system is overall at discriminating
    between classes. The best way to understand this is to look at an example of an
    ROC curve, which we can see in *Figure 13**.2*. This figure is based on randomly
    generated data:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉化虚假阳性（精确度失败）与虚假阴性（召回率失败）之间权衡的一个好方法是使用**接收操作特征**（**ROC**）图及其相关度量——**曲线下面积**（**AUC**）。ROC曲线是衡量系统区分不同类别能力的总体表现。理解这一点的最佳方法是查看一个ROC曲线示例，正如我们在*图13**.2*中所看到的那样。该图基于随机生成的数据：
- en: '![Figure 13.2 – The ROC curve for a perfect classifier compared to a random
    classifier](img/B19005_13_02.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图13.2 – 完美分类器与随机分类器的ROC曲线](img/B19005_13_02.jpg)'
- en: Figure 13.2 – The ROC curve for a perfect classifier compared to a random classifier
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 – 完美分类器与随机分类器的ROC曲线
- en: In *Figure 13**.2*, we can see that at point (**0**, **1)**, the system has
    no false positives, and all of the true positives are correctly detected. If we
    set the acceptance threshold to **1**, the system will still accept all of the
    true positives, and there will still be no false positives. On the other hand,
    if the classifier can’t tell the classes apart at all, we would get something
    like the **Random Classifier** line. No matter where we set the threshold, the
    system will still make many mistakes, as if it was randomly assigning classes
    to inputs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图13**.2*中，我们可以看到，在点(**0**, **1**)处，系统没有假阳性，所有的真正阳性都被正确检测。如果我们将接受阈值设为**1**，系统仍然会接受所有真正阳性，且仍然没有假阳性。另一方面，如果分类器完全无法区分不同类别，我们会得到类似**随机分类器**的线条。无论我们设定什么阈值，系统仍然会犯很多错误，仿佛它在随机地为输入分配类别。
- en: A common way to summarize a system’s ability to discriminate between classes
    is the area under the ROC curve, or AUC. The perfect classifier’s AUC score will
    be **1.0**, a random classifier’s AUC score will be around **0.5**, and if the
    classifier performs at a level that is worse than random, the AUC score will be
    less than **0.5**. Note that we look at a binary classification problem here because
    it is simpler to explain, but there are techniques to apply these ideas to multi-class
    problems as well. We will not go into these here, but a good discussion of the
    techniques to look at ROC curves for multi-class datasets can be found in the
    scikit-learn documentation at [https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 总结系统区分各类别能力的常见方法是ROC曲线下的面积，或AUC。完美分类器的AUC得分为**1.0**，随机分类器的AUC得分大约为**0.5**，如果分类器的表现比随机分类还差，AUC得分则会低于**0.5**。注意，我们这里讨论的是二分类问题，因为它更容易解释，但也有技术可以将这些概念应用于多分类问题。我们在此不深入讨论，但有关如何查看多分类数据集ROC曲线的技术，可以参考scikit-learn文档，地址为[https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)。
- en: Confusion matrix
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Another important evaluation tool is a **confusion matrix**, which shows how
    often each class is confused with each other class. This will be much clearer
    with an example, so we will postpone discussing confusion matrices until we go
    over the example at the end of this chapter.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的评估工具是**混淆矩阵**，它显示每个类别与其他类别混淆的频率。通过一个示例，这个概念会更加清晰，因此我们会推迟讨论混淆矩阵，直到本章最后的示例部分。
- en: User testing
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户测试
- en: In addition to direct system measurements, it is also possible to evaluate systems
    with user testing, where test users who are representative of a system’s intended
    users interact with it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了直接的系统度量，用户测试也可以用来评估系统，在这种测试中，代表系统预期用户的测试用户与系统进行交互。
- en: '**User testing** is a time-consuming and expensive type of testing, but sometimes,
    it is the only way that you can find out qualitative aspects of system performance
    – for example, how easy it is for users to complete tasks with a system, or how
    much they enjoy using it. Clearly, user testing can only be done on aspects of
    the system that users can perceive, such as conversations, and users should be
    only expected to evaluate the system as a whole – that is, users can’t be expected
    to reliably discriminate between the performance of the speech recognition and
    the NLU components of the system.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户测试**是一种耗时且昂贵的测试方式，但有时它是唯一能揭示系统性能定性方面的方法——例如，用户在使用系统时完成任务的难易程度，或他们对使用系统的享受程度。显然，用户测试只能在用户能够感知的系统方面进行，比如对话，用户只应被期望评估系统整体表现——也就是说，不能指望用户可靠地区分语音识别和自然语言理解（NLU）组件的表现。'
- en: 'Carrying out a valid and reliable evaluation with users is actually a psychological
    experiment. This is a complex topic, and it’s easy to make mistakes that make
    it impossible to draw conclusions from the results. For those reasons, providing
    complete instructions to conduct user testing is outside of the scope of this
    book. However, you can do some exploratory user testing by having a few users
    interact with a system and measuring their experiences. Some simple measurements
    that you can collect in user testing include the following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与用户进行有效且可靠的评估实际上是一项心理学实验。这是一个复杂的话题，容易犯错误，导致无法从结果中得出结论。因此，提供完整的用户测试指南超出了本书的范围。不过，你可以通过让一些用户与系统互动并测量他们的体验来进行一些探索性的用户测试。你可以在用户测试中收集的简单测量包括以下内容：
- en: Having users fill out a simple questionnaire about their experiences.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让用户填写一个简单的问卷，评估他们的体验。
- en: 'Measuring how long users spend interacting with the system. The amount of time
    users spend interacting with the system can be a positive or negative measurement,
    depending on the purpose of the system, such as the following:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量用户与系统互动的时间。用户与系统互动的时间可以是正面或负面的度量，具体取决于系统的目的，例如：
- en: If you are developing a social system that’s just supposed to be fun, you will
    want them to spend more time interacting with the system
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在开发一个旨在带来乐趣的社交系统，你会希望用户花更多时间与系统互动。
- en: On the other hand, if you are developing a task-oriented system that will help
    users complete a task, you will usually want the users to spend less time interacting
    with the system
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，如果你正在开发一个任务导向的系统，旨在帮助用户完成某项任务，你通常希望用户与系统的互动时间越少越好。
- en: 'However, you also have to be cautious with user testing:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你在进行用户测试时也必须谨慎：
- en: It is important for users to be representative of the actual intended user population.
    If they are not, the results can be very misleading. For example, a company chatbot
    intended for customer support should be tested on customers, not employees, since
    employees have much more knowledge about the company than customers and will ask
    different questions.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户必须具有代表性，能够代表实际的目标用户群体。如果用户不具代表性，结果可能会非常具有误导性。例如，一个面向客户支持的公司聊天机器人应该在客户身上进行测试，而不是员工，因为员工对公司了解得比客户多，他们提问的问题也会不同。
- en: Keep questionnaires simple, and don’t ask users to provide information that
    isn’t relevant to what you are trying to learn. Users who are bored or impatient
    with the questionnaire will not provide useful information.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让问卷简洁明了，不要要求用户提供与您要了解的内容无关的信息。如果用户对问卷感到厌烦或不耐烦，他们提供的信息将不具任何参考价值。
- en: If the results of user testing are very important to the project, you should
    find a human factors engineer – that is, someone with experience designing experiments
    with human users – to design the testing process so that the results are valid
    and reliable.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户测试的结果对项目至关重要，你应该找到一位人因工程师——即有经验设计人类用户实验的人——来设计测试过程，以确保结果有效且可靠。
- en: So far, we have looked at several different ways to measure the performance
    of systems. Applying each of these techniques will result in one or more numerical
    values, or *metrics* that quantify a system’s performance. Sometimes, when we
    use these metrics to compare several systems, or several versions of the same
    system, we will find that the different values of the metrics are small. It is
    then worth asking whether small differences are really meaningful. This question
    is addressed by the topic of statistical significance, which we will cover in
    the next section.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了几种不同的衡量系统性能的方法。应用这些技术会得到一个或多个数值，或称为*度量指标*，用以量化系统的表现。有时，当我们用这些度量指标来比较多个系统，或同一个系统的不同版本时，我们会发现这些度量指标的差异很小。这时，值得问一下，差异是否真的具有意义。这个问题是通过统计显著性来解决的，我们将在下一节进行讲解。
- en: Statistical significance of differences
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 差异的统计显著性
- en: 'The last general topic we will cover in evaluation is the topic of determining
    whether the differences between the results of experiments we have done reflect
    a real difference between the experimental conditions, or whether they reflect
    differences that are due to chance. This is called **statistical significance**.
    Whether a difference in the values of the metrics represents a real difference
    between systems isn’t something that we can know for certain, but what we can
    know is how likely it is that a difference that we’re interested in is due to
    chance. Let’s suppose we have the situation with our data that’s shown in *Figure
    13**.3*:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在评估中要讨论的最后一个主题是，如何判断我们所做实验的结果之间的差异是否反映了实验条件之间的实际差异，或者这些差异是否由于偶然因素所致。这就是所谓的**统计显著性**。度量指标值之间的差异是否代表系统之间的实际差异，是我们无法确定的，但我们可以知道的是，这种我们关心的差异是否可能是偶然造成的。假设我们的数据情形如*图13.3*所示：
- en: '![Figure 13.3 – Two distributions of measurement values – do they reflect a
    real difference between the things they’re measuring?](img/B19005_13_03.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图13.3 – 测量值的两个分布——它们是否反映了被测物体之间的实际差异？](img/B19005_13_03.jpg)'
- en: Figure 13.3 – Two distributions of measurement values – do they reflect a real
    difference between the things they’re measuring?
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 – 测量值的两个分布——它们是否反映了被测物体之间的实际差异？
- en: '*Figure 13**.3* shows two sets of measurements, one with a mean of **0**, on
    the left, and one with a mean of **0.75**, on the right. Here, we might be comparing
    the performance of two classification algorithms on different datasets, for example.
    It looks like there is a real difference between the algorithms, but could this
    difference be an accident? We usually consider that if the probability of a difference
    of this size occurring by chance is once out of 20, then the difference is considered
    to be statistically significant, or not due to chance. Of course, that means that
    1 out of 20 statistically significant results is probably actually due to chance.
    This probability is determined by standard statistical formulas such as the *t-statistic*
    or the *analysis* *of variance*.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.3* 显示了两组测量结果，一组平均值为**0**，在左边，另一组平均值为**0.75**，在右边。在这里，我们可能在比较两个分类算法在不同数据集上的表现。例如，看起来两个算法之间确实存在差异，但这种差异可能是偶然的？我们通常认为，如果这种差异偶然发生的概率是20分之一，那么这个差异就被认为是统计显著的，也就是不太可能是偶然的。当然，这也意味着每20个统计显著的结果中，可能有1个实际上是偶然发生的。这种概率是通过标准的统计公式来计算的，比如*t-统计量*或*方差分析*。'
- en: If you read a paper that performs a significance test on its results and it
    states something such as *p<.05*, the *p* refers to the probability of the difference
    being due to chance. This kind of statistical analysis is most commonly performed
    with data where knowing whether differences are statistically significant is very
    important, such as academic papers for presentation at conferences or for publication
    in academic journals. We will not cover the process of how statistical significance
    is calculated here, since it can become quite a complex process, but you should
    be aware of what it means if you have a need for it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了一篇对其结果进行显著性检验的论文，并且它指出类似*p<.05*的内容，*p*表示这个差异是由于偶然发生的概率。这样的统计分析通常用于数据中，其中确定差异是否具有统计显著性非常重要，比如会议上展示的学术论文或用于发表在学术期刊中的论文。我们在这里不讨论统计显著性是如何计算的，因为这个过程可能会变得相当复杂，但如果你需要使用它，你应该知道它的含义。
- en: It is also important to consider that a result can be statistically significant
    but not really meaningful in realistic situations. If the results of one classification
    algorithm are only slightly better than another but the better algorithm is much
    more complicated to compute, it might not be worth bothering with the better algorithm.
    These trade-offs are something that has to be considered from the perspective
    of how the algorithm will be used. Even a small, but significant, difference could
    be important in an academic paper but not important at all in a deployed application.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要考虑一个问题，那就是结果可能在统计学上显著，但在现实情况下可能并不具有实际意义。如果一种分类算法的结果仅比另一种稍微好一些，但更好的算法计算起来要复杂得多，那么可能不值得去使用那个更好的算法。这些权衡必须从算法的实际应用角度进行考虑。即便是一个小的，但显著的差异，对于学术论文可能非常重要，但对于已部署的应用程序则可能完全无关紧要。
- en: Now that we have reviewed several approaches to evaluating systems, let’s take
    a look at applying them in practice. In the next section, we will work through
    a case study that compares three different approaches to text classification on
    the same data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了几种评估系统的方法，让我们看看如何在实际中应用它们。在接下来的部分中，我们将通过一个案例研究，比较三种不同的文本分类方法在相同数据上的表现。
- en: Comparing three text classification methods
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较三种文本分类方法
- en: One of the most useful things we can do with evaluation techniques is to decide
    which of several approaches to use in an application. Are the traditional approaches
    such as **term frequency - inverse document frequency** (**TF-IDF**), **support
    vector machines** (**SVMs**), and **conditional random fields** (**CRFs**) good
    enough for our task, or will it be necessary to use deep learning and transformer
    approaches that have better results at the cost of longer training time?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用评估技术可以做的最有用的事情之一是决定在应用程序中使用哪种方法。像**词频-逆文档频率**（**TF-IDF**）、**支持向量机**（**SVMs**）和**条件随机场**（**CRFs**）这样的传统方法是否足够满足我们的任务，还是必须使用深度学习和变换器方法，这些方法虽然训练时间更长，但效果更好？
- en: In this section, we will compare the performance of three approaches on a larger
    version of the movie review dataset that we looked at in [*Chapter 9*](B19005_09.xhtml#_idTextAnchor173).
    We will look at using a small BERT model, TF-IDF vectorization with the Naïve
    Bayes classification, and a larger BERT model.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将比较三种方法在一个更大的电影评论数据集上的表现，该数据集我们在[*第9章*](B19005_09.xhtml#_idTextAnchor173)中讨论过。我们将比较使用小型BERT模型、TF-IDF向量化与朴素贝叶斯分类以及较大的BERT模型。
- en: A small transformer system
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小型变压器系统
- en: We will start by looking at the BERT system that we developed in [*Chapter 11*](B19005_11.xhtml#_idTextAnchor193).
    We will use the same BERT model as in [*Chapter 11*](B19005_11.xhtml#_idTextAnchor193),
    which is one of the smallest BERT models, `small_bert/bert_en_uncased_L-2_H-128_A-2`,
    with two layers, a hidden size of `128`, and two attention heads.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先查看我们在[*第11章*](B19005_11.xhtml#_idTextAnchor193)中开发的BERT系统。我们将使用与[*第11章*](B19005_11.xhtml#_idTextAnchor193)相同的BERT模型，即`small_bert/bert_en_uncased_L-2_H-128_A-2`，它是最小的BERT模型之一，具有两层、隐藏层大小为`128`，并且有两个注意力头。
- en: We will be making a few changes in order to better evaluate this model’s performance.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进行一些调整，以便更好地评估该模型的表现。
- en: 'First, we will add new metrics, precision and recall, to the `BinaryAccuracy`
    metric that we used in [*Chapter 11*](B19005_11.xhtml#_idTextAnchor193):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将添加新的指标，精确度和召回率，作为我们在[*第11章*](B19005_11.xhtml#_idTextAnchor193)中使用的`BinaryAccuracy`指标的补充：
- en: '[PRE6]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With these metrics, the `history` object will include the changes in precision
    and recall during the 10-epoch training process. We can look at these with the
    following code:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些指标，`history`对象将包括在10个训练周期内精确度和召回率的变化。我们可以通过以下代码查看这些变化：
- en: '[PRE7]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As shown in the preceding code snippet, the first steps are to pull out the
    results we are interested in from the `history` object. The next step is to plot
    the results as they change over training epochs, which is calculated in the following
    code:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码片段所示，第一步是从`history`对象中提取我们感兴趣的结果。接下来的步骤是绘制随着训练周期变化的结果，这将在以下代码中计算：
- en: '[PRE8]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The preceding code shows the plotting process for the training and validation
    loss, which results in the top plot in *Figure 13**.4*. The rest of the plots
    in *Figure 13**.4* and the plots in *Figure 13**.5* are calculated in the same
    manner, but we will not show the full code here, since it is nearly the same as
    the code for the first plot.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码展示了训练和验证损失的绘图过程，生成了*图13.4*中的顶部图表。*图13.4*中的其余图表和*图13.5*中的图表是以相同的方式计算的，但由于它们与第一个图表的代码几乎相同，我们这里不再展示完整代码。
- en: '*Figure 13**.4* shows decreasing loss and increasing accuracy over training
    epochs, which we saw previously. We can see that loss for both the training and
    validation data is leveling off between **0.40** and **0.45**. At epoch **7**,
    it looks like additional training is unlikely to improve performance:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13.4*展示了训练周期内损失的下降和准确率的上升，正如我们之前看到的。我们可以看到，训练数据和验证数据的损失值在**0.40**到**0.45**之间趋于平稳。在第**7**个周期时，看起来额外的训练可能不会改善性能：'
- en: '![Figure 13.4 – Loss and accuracy over 10 training epochs](img/B19005_13_04.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图13.4 – 在10个训练周期内的损失和准确率](img/B19005_13_04.jpg)'
- en: Figure 13.4 – Loss and accuracy over 10 training epochs
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – 在10个训练周期内的损失和准确率
- en: 'Since we have added the precision and recall metrics, we can also see that
    these metrics level off at around **0.8** at around **7** epochs of training,
    as shown in *Figure 13**.5*:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们添加了精确度和召回率指标，我们还可以看到这些指标在大约**0.8**的水平上趋于平稳，在大约**7**个训练周期时达到平衡，如*图13.5*所示：
- en: '![Figure 13.5 – Precision and recall over 10 training epochs](img/B19005_13_05.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图13.5 – 在10个训练周期内的精确度和召回率](img/B19005_13_05.jpg)'
- en: Figure 13.5 – Precision and recall over 10 training epochs
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5 – 在10个训练周期内的精确度和召回率
- en: 'We can also look at the confusion matrix and classification report for more
    information with the following code, using functions from scikit-learn:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看混淆矩阵和分类报告，以获得更多信息，使用以下代码，调用来自scikit-learn的函数：
- en: '[PRE9]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will plot the confusion matrix as shown in *Figure 13**.6*:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这将绘制出如*图13.6*所示的混淆矩阵：
- en: '![Figure 13.6 – The confusion matrix for a small BERT model](img/B19005_13_06.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图13.6 – 小型BERT模型的混淆矩阵](img/B19005_13_06.jpg)'
- en: Figure 13.6 – The confusion matrix for a small BERT model
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.6 – 小型BERT模型的混淆矩阵
- en: 'The dark cells in *Figure 13**.6* show the number of correct classifications,
    where actual negative and positive reviews were assigned to the right classes.
    We can see that there are quite a few incorrect classifications. We can see more
    detail by printing a summary classification report with the following code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.6* 中的深色单元格显示了正确分类的数量，实际的负面和正面评论被分配到了正确的类别。我们可以看到，有相当多的错误分类。通过打印以下代码的汇总分类报告，我们可以看到更详细的信息：'
- en: '[PRE10]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The classification report shows the `recall`, `precision`, and `F1` scores
    for both classes:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 分类报告显示了两个类别的 `召回率`、`精确度` 和 `F1` 分数：
- en: '[PRE11]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: From this report, we can see that the system is almost equally good at recognizing
    positive and negative reviews. The system correctly classifies many reviews but
    is still making many errors.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 从该报告中，我们可以看到系统在识别正面和负面评论方面几乎同样优秀。系统正确分类了许多评论，但仍然犯了很多错误。
- en: Now, we will compare the BERT test with one of our earlier tests, based on TF-IDF
    vectorization and Naïve Bayes classification.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将比较 BERT 测试与我们之前的一个测试，该测试基于 TF-IDF 向量化和朴素贝叶斯分类。
- en: TF-IDF evaluation
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TF-IDF 评估
- en: In [*Chapter 9*](B19005_09.xhtml#_idTextAnchor173), we learned about vectorizing
    with TF-IDF and classifying with Naïve Bayes. We illustrated the process with
    the movie review corpus. We want to compare these very traditional techniques
    with the newer transformer-based LLMs, such as BERT, that we just saw. How much
    better are transformers than the traditional approaches? Do the transformers justify
    their much bigger size and longer training time? To make the comparison between
    BERT and TF-IDF/Naïve Bayes fair, we will use the larger `aclimdb` movie review
    dataset that we used in [*Chapter 11*](B19005_11.xhtml#_idTextAnchor193).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 9 章*](B19005_09.xhtml#_idTextAnchor173) 中，我们学习了如何使用 TF-IDF 向量化并进行朴素贝叶斯分类。我们通过电影评论语料库展示了这一过程。我们想将这些非常传统的技术与新型的基于变换器的
    LLM（如 BERT）进行比较。变换器相比传统方法到底有多好？这些变换器是否值得其更大的体积和更长的训练时间？为了公平地比较 BERT 和 TF-IDF/朴素贝叶斯，我们将使用我们在
    [*第 11 章*](B19005_11.xhtml#_idTextAnchor193) 中使用的较大 `aclimdb` 电影评论数据集。
- en: 'We will use the same code we used in [*Chapter 9*](B19005_09.xhtml#_idTextAnchor173)
    to set up the system and perform the TF-IDF/Naïve Bayes classification, so we
    won’t repeat it here. We will just add the final code to show the confusion matrix
    and display the results graphically:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在 [*第 9 章*](B19005_09.xhtml#_idTextAnchor173) 中使用的相同代码来设置系统并执行 TF-IDF/朴素贝叶斯分类，因此这里不再重复。我们将仅添加最终的代码以显示混淆矩阵并以图形方式展示结果：
- en: '[PRE12]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The text version of the confusion matrix is the array:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的文本版本是数组：
- en: '`[[``9330 3171]`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`[[``9330 3171]`'
- en: '`[``3444 9056]]`'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`[``3444 9056]]`'
- en: 'However, this is not very easy to understand. We can display it more clearly
    by using `matplotlib` in the following code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不容易理解。我们可以通过使用 `matplotlib` 在以下代码中更清晰地显示它：
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result is shown in *Figure 13**.7*:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在 *图 13.7* 中：
- en: "![Figure 13.7 – The confusion matrix for TF\uFEFF-IDF/the Naïve Bayes classification](img/B19005_13_07.jpg)"
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – TF-IDF/朴素贝叶斯分类的混淆矩阵](img/B19005_13_07.jpg)'
- en: Figure 13.7 – The confusion matrix for TF-IDF/the Naïve Bayes classification
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – TF-IDF/朴素贝叶斯分类的混淆矩阵
- en: The dark cells in *Figure 13**.7* show the correct classifications, where actual
    negative and positive reviews were assigned to the right classes. We can also
    see that **3171** actual negative reviews were misclassified as positive and **3444**
    actual positive reviews were misclassified as negative.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.7* 中的深色单元格显示了正确分类的数量，实际的负面和正面评论被分配到了正确的类别。我们还可以看到，**3171** 个实际的负面评论被误分类为正面，**3444**
    个实际的正面评论被误分类为负面。'
- en: 'To see the recall, precision, and F1 scores, we can print the classification
    report:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看召回率、精确度和 F1 分数，我们可以打印分类报告：
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The resulting classification report shows the recall, precision, and F1 scores,
    along with the accuracy, the number of items in each class (`support`), and other
    statistics:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 结果分类报告显示了召回率、精确度和 F1 分数，以及准确率、每个类别的项数（`支持度`）和其他统计数据：
- en: '[PRE15]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: From this report, we can see that the system is slightly better at recognizing
    negative reviews. The system correctly classifies many reviews but is still making
    many errors. Comparing these results to the results for the BERT system in *Figure
    13**.6*, we can see that the BERT results are quite a bit better. The BERT F1
    score is **0.81**, while the TF-IDF/Naïve Bayes F1 score is **0.74**. For this
    task, the BERT system would be the better choice, but can we do better?
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个报告中，我们可以看到该系统在识别负面评论方面稍微有些优势。系统正确分类了许多评论，但仍然存在很多错误。将这些结果与BERT系统在*图13.6*中的结果进行比较，我们可以看到BERT的结果要好得多。BERT的F1得分为**0.81**，而TF-IDF/朴素贝叶斯的F1得分为**0.74**。在这项任务中，BERT系统是更好的选择，但我们能做得更好吗？
- en: In the next section, we will ask another question that compares two systems.
    The question concerns what might happen with other BERT transformer models. Larger
    models will almost always have better performance than smaller models but will
    take more training time. How much better will they be in terms of performance?
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将提出另一个比较两个系统的问题。这个问题涉及到其他BERT变换器模型可能发生的情况。较大的模型几乎总是比较小的模型具有更好的性能，但训练时间会更长。它们在性能方面究竟会好多少呢？
- en: A larger BERT model
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更大的BERT模型
- en: So far, we have compared a very small BERT model to a system based on TF-IDF
    and Naïve Bayes. We saw from the comparison between the two systems’ classification
    reports that the BERT system was definitely better than the TF-IDF/Naïve Bayes
    system. For this task, BERT is better as far as correct classification goes. On
    the other hand, BERT is much slower to train.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经将一个非常小的BERT模型与基于TF-IDF和朴素贝叶斯的系统进行了比较。通过对比这两个系统的分类报告，我们可以看到BERT系统显然比TF-IDF/朴素贝叶斯系统更好。在这项任务中，BERT在正确分类方面更具优势。另一方面，BERT的训练速度要慢得多。
- en: Can we get even better performance with another transformer system, such as
    another variation of BERT? We can find this out by comparing our system’s results
    to the results from other variations of BERT. This is easy to do because the BERT
    system includes many more models of various sizes and complexities, which can
    be found at [https://tfhub.dev/google/collections/bert/1](https://tfhub.dev/google/collections/bert/1).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能通过另一个变换器系统（比如BERT的另一种变体）获得更好的性能吗？我们可以通过将我们的系统结果与其他BERT变体的结果进行比较来找出答案。由于BERT系统包含更多不同大小和复杂度的模型，因此这很容易实现，这些模型可以在[https://tfhub.dev/google/collections/bert/1](https://tfhub.dev/google/collections/bert/1)找到。
- en: 'Let’s compare another model to the BERT system we just tested. The system that
    we’ve tested is one of the smaller BERT systems, `small_bert/bert_en_uncased_L-2_H-128_A-2`.
    The name encodes its important properties – two layers, a hidden size of `128`,
    and two attention heads. We might be interested in finding out what happens with
    a larger model. Let’s try one, `small_bert/bert_en_uncased_L-4_H-512_A-8`, which
    is nevertheless not too large to train on a CPU (rather than a GPU). This model
    is still rather small, with four layers, a hidden size of `512`, and eight attention
    heads. Trying a different model is quite easy to do, with just a minor modification
    of the code that sets up the BERT model for use by including the information for
    the new model:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将另一个模型与我们刚才测试过的BERT系统进行比较。我们测试的系统是一个较小的BERT系统，`small_bert/bert_en_uncased_L-2_H-128_A-2`。该名称编码了它的重要特性——两层、隐藏层大小为`128`，并且有两个注意力头。我们可能想知道使用更大的模型会有什么结果。让我们试试一个较大的模型，`small_bert/bert_en_uncased_L-4_H-512_A-8`，这个模型仍然不至于太大，能够在CPU上训练（而不是GPU）。这个模型仍然相当小，有四层，隐藏层大小为`512`，并且有八个注意力头。尝试不同的模型非常简单，只需对设置BERT模型以供使用的代码进行一些小的修改，包含新模型的信息即可：
- en: '[PRE16]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As the code shows, all we have to do is select the model’s name, map it to
    the URL where it is located, and assign it to a preprocessor. The rest of the
    code will be the same. *Figure 13**.8* shows the confusion matrix for the larger
    BERT model:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码所示，我们所需要做的就是选择模型的名称，将其映射到存放它的URL，并将其分配给预处理器。其余的代码将保持不变。*图13.8*显示了更大的BERT模型的混淆矩阵：
- en: '![Figure 13.8 – The confusion matrix for the larger BERT model](img/B19005_13_08.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图13.8 – 更大BERT模型的混淆矩阵](img/B19005_13_08.jpg)'
- en: Figure 13.8 – The confusion matrix for the larger BERT model
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8 – 更大BERT模型的混淆矩阵
- en: The performance of this model, as shown in the confusion matrix, is superior
    to that of the smaller BERT model as well as the TF-IDF/Naïve Bayes model. The
    classification report is shown in the following snippet, and it also shows that
    this model performs the best of the three models we have looked at in this section,
    with an average `F1` score of `0.85`, compared to `0.81` for the smaller BERT
    model and `0.74` for the TF-IDF/Naïve Bayes model.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如混淆矩阵所示，该模型的性能优于较小的BERT模型以及TF-IDF/朴素贝叶斯模型。分类报告显示在下面的代码片段中，并且也表明该模型在我们本节中查看的三种模型中表现最佳，平均`F1`得分为`0.85`，相比之下，较小的BERT模型为`0.81`，TF-IDF/朴素贝叶斯模型为`0.74`。
- en: '[PRE17]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The training time for this model on the `aclimdb` dataset with 25,000 items
    was about eight hours on a standard CPU, which is probably acceptable for most
    applications. Is this performance good enough? Should we explore even bigger models?
    There is clearly quite a bit of room for improvement, and there are many other
    BERT models that we can experiment with. The decision of whether the results are
    acceptable or not is up to the developers of the application and depends on the
    importance of getting correct answers and avoiding wrong answers. It can be different
    for every application. You are encouraged to experiment with some of the larger
    models and consider whether the improved performance justifies the additional
    training time.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在`aclimdb`数据集（包含25,000条数据）上的训练时间约为8小时，使用的是标准CPU，这对于大多数应用程序来说可能是可以接受的。这个性能是否足够好？我们应该探索更大的模型吗？显然，仍然有很大的改进空间，我们可以尝试更多其他BERT模型。是否接受这些结果由应用程序的开发者决定，取决于获取正确答案和避免错误答案的优先级。每个应用程序的情况可能不同。我们鼓励你尝试一些更大的模型，考虑提高的性能是否值得额外的训练时间。
- en: Summary
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about a number of important topics related to evaluating
    NLU systems. You learned how to separate data into different subsets for training
    and testing, and you learned about the most commonly used NLU performance metrics
    – accuracy, precision, recall, F1, AUC, and confusion matrices – and how to use
    these metrics to compare systems. You also learned about related topics, such
    as comparing systems with ablation, evaluation with shared tasks, statistical
    significance testing, and user testing.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了与评估NLU系统相关的一些重要主题。你学习了如何将数据分成不同的子集用于训练和测试，并学习了最常用的NLU性能评估指标——准确率、精确率、召回率、F1值、AUC和混淆矩阵——以及如何使用这些指标来比较系统。你还学习了相关主题，如通过消融实验进行系统比较、共享任务评估、统计显著性测试和用户测试。
- en: The next chapter will start *Part 3* of this book, where we cover systems in
    action – applying NLU at scale. We will start *Part 3* by looking at what to do
    if a system isn’t working. If the original model isn’t adequate or the system
    models a real-world situation that changes, what has to be changed? The chapter
    discusses topics such as adding new data and changing the structure of the application.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将开始本书的*第三部分*，我们将在这里讨论系统实践——大规模应用NLU。我们将从*第三部分*开始，探讨如果系统无法正常工作该怎么办。如果原始模型不够完善，或者系统模型处理的实际情况发生了变化，那么需要做哪些调整？本章讨论了添加新数据和更改应用程序结构等话题。
- en: 'Part 3: Systems in Action – Applying Natural Language Understanding at Scale'
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：系统实践——大规模应用自然语言理解
- en: In *Part 3*, you will learn about applying natural language understanding in
    running applications. This part will cover adding new data to existing applications,
    dealing with volatile applications, adding and removing categories, and will include
    a final chapter summarizing the book and looking to the future of natural language
    understanding.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第三部分*，你将学习如何将自然语言理解应用于运行中的应用程序。本部分将涉及将新数据添加到现有应用程序中、处理易变的应用程序、添加和删除类别，并包括总结本书内容以及展望自然语言理解未来的最后一章。
- en: We focus on getting NLU systems out of the lab and making them do real work
    solving practical problems.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专注于将NLU系统从实验室带到实际应用中，使其能够解决实际问题。
- en: 'This part comprises the following chapters:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下几章：
- en: '[*Chapter 14*](B19005_14.xhtml#_idTextAnchor248), *What to Do If the System
    Isn’t Working*'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第14章*](B19005_14.xhtml#_idTextAnchor248)，*系统无法正常工作时该怎么办*'
- en: '[*Chapter 15*](B19005_15.xhtml#_idTextAnchor262), *Summary and Looking to the
    Future*'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第15章*](B19005_15.xhtml#_idTextAnchor262)，*总结与未来展望*'
