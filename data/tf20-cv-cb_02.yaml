- en: '*Chapter 2*: Performing Image Classification'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第2章*：执行图像分类'
- en: Computer vision is a vast field that takes inspiration from many places. Of
    course, this means that its applications are wide and varied. However, the biggest
    breakthroughs over the past decade, especially in the context of deep learning
    applied to visual tasks, have occurred in a particular domain known as **image
    classification**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是一个广泛的领域，借鉴了许多地方的灵感。当然，这意味着它的应用也非常广泛和多样。然而，过去十年里，特别是在深度学习应用于视觉任务的背景下，最大的突破出现在一个特定领域，即**图像分类**。
- en: As the name suggests, image classification consists of the process of discerning
    what's in an image based on its visual content. Is there a dog or a cat in this
    image? What number is in this picture? Is the person in this photo smiling or
    not?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，图像分类的过程是根据图像的视觉内容来识别图像中的内容。这个图像中有狗还是猫？这张图片中显示的数字是什么？这张照片中的人是微笑还是不微笑？
- en: Because image classification is such an important and pervasive task in deep
    learning applied to computer vision, the recipes in this chapter will focus on
    the ins and outs of classifying images using TensorFlow 2.x.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像分类是计算机视觉领域深度学习应用中的一项重要而广泛的任务，本章中的食谱将重点介绍使用TensorFlow 2.x进行图像分类的所有细节。
- en: 'We''ll cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下食谱：
- en: Creating a binary classifier to detect smiles
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个二分类器来检测微笑
- en: Creating a multi-class classifier to play Rock Paper Scissors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个多类别分类器来玩石头剪刀布
- en: Creating a multi-label classifier to label watches
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个多标签分类器来标记手表
- en: Implementing ResNet from scratch
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从零开始实现ResNet
- en: Classifying images with a pre-trained network using the Keras API
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keras API通过预训练网络进行图像分类
- en: Classifying images with a pre-trained network using TensorFlow Hub
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练网络通过TensorFlow Hub进行图像分类
- en: Using data augmentation to improve performance with the Keras API
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据增强来提高Keras API的性能
- en: Using data augmentation to improve performance with the tf.data and tf.image
    APIs
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用tf.data和tf.image API进行数据增强以提高性能
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Besides a working installation of TensorFlow 2.x, it''s highly recommended
    to have access to a GPU, given that some of the recipes are very resource-intensive,
    making the use of a CPU an inviable option. In each recipe, you''ll find the steps
    and dependencies needed to complete it in the *Getting ready* section. Finally,
    the code shown in this chapter is available in full here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除了正确安装TensorFlow 2.x外，强烈建议使用GPU，因为某些食谱非常消耗资源，使用CPU将无法完成任务。在每个食谱中，你将找到完成它所需的步骤和依赖项，这些内容位于*准备工作*部分。最后，本章中展示的代码可以在这里完整查看：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2)。
- en: 'Check out the following link to see the Code in Action video:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接，观看《代码实践》视频：
- en: '[https://bit.ly/3bOjqnU](https://bit.ly/3bOjqnU)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/3bOjqnU](https://bit.ly/3bOjqnU)'
- en: Creating a binary classifier to detect smiles
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个二分类器来检测微笑
- en: In its most basic form, image classification consists of discerning between
    two classes, or signaling the presence or absence of some trait. In this recipe,
    we'll implement a binary classifier that tells us whether a person in a photo
    is smiling.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本的形式下，图像分类是区分两种类别，或者判断某种特征是否存在。 在本食谱中，我们将实现一个二分类器，用于判断照片中的人是否在微笑。
- en: Let's begin, shall we?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们开始吧，好吗？
- en: Getting ready
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You''ll need to install `Pillow`, which is very easy with `pip`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装`Pillow`，使用`pip`安装非常简单：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We''ll use the `SMILEs` dataset, located here: [https://github.com/hromi/SMILEsmileD](https://github.com/hromi/SMILEsmileD).
    Clone or download a zipped version of the repository to a location of your preference.
    In this recipe, we assume the data is inside the `~/.keras/datasets` directory,
    under the name `SMILEsmileD-master`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`SMILEs`数据集，位于这里：[https://github.com/hromi/SMILEsmileD](https://github.com/hromi/SMILEsmileD)。克隆或下载该仓库的压缩版本到你喜欢的目录。在本食谱中，我们假设数据位于`~/.keras/datasets`目录下，文件夹名为`SMILEsmileD-master`：
- en: '![Figure 2.1 – Positive (left) and negative (right) examples](img/B14768_02_001.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 正例（左）和反例（右）](img/B14768_02_001.jpg)'
- en: Figure 2.1 – Positive (left) and negative (right) examples
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 正例（左）和反例（右）
- en: Let's get started!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！
- en: How to do it…
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Follow these steps to train a smile classifier from scratch on the `SMILEs`
    dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤，从头开始训练一个基于`SMILEs`数据集的微笑分类器：
- en: 'Import all necessary packages:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的包：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define a function to load the images and labels from a list of file paths:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数从文件路径列表中加载图像和标签：
- en: '[PRE2]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Notice that we are loading the images in grayscale, and we're encoding the labels
    by checking whether the word *positive* is in the file path of the image.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们正在以灰度图像的形式加载图像，并通过检查图像路径中是否包含单词*positive*来对标签进行编码。
- en: 'Define a function to build the neural network. This model''s structure is based
    on **LeNet** (you can find a link to LeNet''s paper in the *See also* section):'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来构建神经网络。该模型的结构基于**LeNet**（你可以在*另见*部分找到LeNet论文的链接）：
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Because this is a binary classification problem, a single Sigmoid-activated
    neuron is enough in the output layer.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于这是一个二分类问题，输出层只需要一个Sigmoid激活的神经元。
- en: 'Load the image paths into a list:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像路径加载到列表中：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Use the `load_images_and_labels()` function defined previously to load the
    dataset into memory:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用之前定义的`load_images_and_labels()`函数将数据集加载到内存中：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Normalize the images and compute the number of positive, negative, and total
    examples in the dataset:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对图像进行归一化处理，并计算数据集中的正例、负例和总例数：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create train, test, and validation subsets of the data:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练、测试和验证数据子集：
- en: '[PRE7]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Instantiate the model and compile it:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化模型并编译它：
- en: '[PRE8]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Train the model. Because the dataset is unbalanced, we are assigning weights
    to each class proportional to the number of positive and negative images in the
    dataset:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。由于数据集不平衡，我们为每个类别分配了与数据集中正负图像数量成比例的权重：
- en: '[PRE9]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Evaluate the model on the test set:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上评估模型：
- en: '[PRE10]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After 20 epochs, the network should get around 90% accuracy on the test set.
    In the following section, we'll explain the previous steps.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过20个周期后，网络应该能够在测试集上达到约90%的准确率。在接下来的部分中，我们将解释前述步骤。
- en: How it works…
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: 'We just trained a network to determine whether a person is smiling or not in
    a picture. Our first big task was to take the images in the dataset and load them
    into a format suitable for our neural network. Specifically, the `load_image_and_labels()`
    function is in charge of loading an image in grayscale, resizing it to 32x32x1,
    and then converting it into a `numpy` array. To extract the label, we looked at
    the containing folder of each image: if it contained the word positive, we encoded
    the label as 1; otherwise, we encoded it as 0 (a trick we used here was casting
    a Boolean as a float, like this: `float(label)`).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚训练了一个网络来判断一个人是否在图片中微笑。我们的第一个大任务是将数据集中的图像加载成适合神经网络的格式。具体来说，`load_image_and_labels()`函数负责加载灰度图像，调整其大小为32x32x1，然后将其转换为`numpy`数组。为了提取标签，我们查看了每个图像所在的文件夹：如果文件夹名称中包含单词positive，我们就将标签编码为1；否则，将其编码为0（这里我们用的是将布尔值转换为浮点数的技巧，像这样：`float(label)`）。
- en: Next, we built the neural network, which is inspired by the LeNet architecture.
    The biggest takeaway here is that because this is a binary classification problem,
    we can use a single Sigmoid-activated neuron to discern between the two classes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们构建了神经网络，它受到LeNet架构的启发。这里的最大收获是，由于这是一个二分类问题，我们可以使用一个Sigmoid激活的神经元来区分两个类别。
- en: We then took 20% of the images to comprise our test set, and from the remaining
    80% we took an additional 20% to create our validation set. With these three subsets
    in place, we proceeded to train the network over 20 epochs, using `binary_crossentropy`
    as our loss function and `rmsprop` as the optimizer.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将20%的图像用作测试集，从剩下的80%中再取20%用作验证集。设置好这三个子集后，我们开始在20个周期内训练网络，使用`binary_crossentropy`作为损失函数，`rmsprop`作为优化器。
- en: To account for the imbalance in the dataset (out of the 13,165 images, only
    3,690 contain smiling people, while the remaining 9,475 do not), we passed a `class_weight`
    dictionary where we assigned a weight conversely proportional to the number of
    instances of each class in the dataset, effectively forcing the model to pay more
    attention to the 1.0 class, which corresponds to *smile*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理数据集中的类别不平衡问题（在13,165张图像中，只有3,690张包含微笑的人，而其余9,475张不包含），我们传递了一个`class_weight`字典，其中我们为每个类别分配了与类别实例数成反比的权重，从而有效地迫使模型更多关注1.0类，即*微笑*类别。
- en: Finally, we achieved around 90.5% accuracy on the test set.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们在测试集上取得了大约90.5%的准确率。
- en: See also
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For more information on the `SMILEs` dataset, you can visit the official GitHub
    repository here: [https://github.com/hromi/SMILEsmileD](https://github.com/hromi/SMILEsmileD).
    You can read the LeNet paper here (it''s pretty long, though): [http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`SMILEs`数据集的更多信息，可以访问官方GitHub仓库：[https://github.com/hromi/SMILEsmileD](https://github.com/hromi/SMILEsmileD)。你也可以阅读LeNet论文（虽然很长）：[http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)。
- en: Creating a multi-class classifier to play rock paper scissors
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个多类别分类器来玩石头剪刀布
- en: More often than not, we are interested in categorizing an image into more than
    two classes. As we'll see in this recipe, implementing a neural network to differentiate
    between many categories is fairly straightforward, and what better way to demonstrate
    this than by training a model that can play the widely known Rock Paper Scissors
    game?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 更多时候，我们关注的是将图像分类为两个以上的类别。正如我们在这个示例中看到的，实现一个神经网络来区分多个类别是相对简单的，最好的展示方法是什么呢？那就是训练一个能够玩著名的“石头剪刀布”游戏的模型。
- en: Are you ready? Let's dive in!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你准备好了吗？让我们深入了解！
- en: Getting ready
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We''ll use the `Rock-Paper-Scissors Images` dataset, which is hosted on Kaggle
    at the following location: [https://www.kaggle.com/drgfreeman/rockpaperscissors](https://www.kaggle.com/drgfreeman/rockpaperscissors).
    To download it, you''ll need a Kaggle account, so sign in or sign up accordingly.
    Then, unzip the dataset in a location of your preference. In this recipe, we assume
    the unzipped folder is inside the `~/.keras/datasets` directory, under the name
    `rockpaperscissors`.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`Rock-Paper-Scissors Images`数据集，该数据集托管在Kaggle上，位置如下：[https://www.kaggle.com/drgfreeman/rockpaperscissors](https://www.kaggle.com/drgfreeman/rockpaperscissors)。要下载它，你需要一个Kaggle账户，请登录或注册。然后，在你选择的位置解压缩数据集。在这个示例中，我们假设解压缩后的文件夹位于`~/.keras/datasets`目录下，名为`rockpaperscissors`。
- en: 'Here are some sample images:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些示例图像：
- en: '![Figure 2.2 – Example images of rock (left), paper (center), and scissors
    (right)](img/B14768_02_002.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – 石头（左）、布（中）和剪刀（右）的示例图像](img/B14768_02_002.jpg)'
- en: Figure 2.2 – Example images of rock (left), paper (center), and scissors (right)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 石头（左）、布（中）和剪刀（右）的示例图像
- en: Let's begin implementing.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始实现吧。
- en: How to do it…
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'The following steps explain how to train a multi-class **Convolutional Neural
    Network** (**CNN**) to distinguish between the three classes of the Rock Paper
    Scissors game:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤说明如何训练一个多类别**卷积神经网络**（**CNN**）来区分石头剪刀布游戏的三种类别：
- en: 'Import the required packages:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包：
- en: '[PRE11]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Define a list with the three classes, and also an alias to `tf.data.experimental.AUTOTUNE`,
    which we''ll use later:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个包含三个类别的列表，并为`tf.data.experimental.AUTOTUNE`定义一个别名，我们稍后将使用它：
- en: '[PRE12]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The values in `CLASSES` match the names of the directories that contain the
    images for each class.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`CLASSES`中的值与每个类别的图像所在目录的名称匹配。'
- en: 'Define a function to load an image and its label, given its file path:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来加载图像及其标签，给定图像的文件路径：
- en: '[PRE13]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Notice that we are one-hot encoding by comparing the name of the folder that
    contains the image (extracted from `image_path`) with the `CLASSES` list.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，我们通过将包含图像的文件夹名称（从`image_path`提取）与`CLASSES`列表进行比较来进行one-hot编码。
- en: 'Define a function to build the network architecture. In this case, it''s a
    very simple and shallow one, which is enough for the problem we are solving:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来构建网络架构。在这个例子中，这是一个非常简单和浅层的架构，对于我们要解决的问题足够了：
- en: '[PRE14]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Define a function to, given a path to a dataset, return a `tf.data.Dataset`
    instance of images and labels, in batches and optionally shuffled:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，给定数据集路径，返回一个`tf.data.Dataset`实例，其中包含图像和标签，按批次并可选地进行洗牌：
- en: '[PRE15]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Load the image paths into a list:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像路径加载到列表中：
- en: '[PRE16]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create train, test, and validation subsets of image paths:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练、测试和验证数据集的图像路径：
- en: '[PRE17]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Prepare the training, test, and validation datasets:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备训练、测试和验证数据集：
- en: '[PRE18]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Instantiate and compile the model:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化并编译模型：
- en: '[PRE19]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Fit the model for `250` epochs:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合`250`个epoch：
- en: '[PRE20]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Evaluate the model on the test set:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上评估模型：
- en: '[PRE21]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: After 250 epochs, our network achieves around 93.5% accuracy on the test set.
    Let's understand what we just did.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过250轮训练后，我们的网络在测试集上达到了大约93.5%的准确率。让我们来理解一下我们刚才做了什么。
- en: How it works…
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: We started by defining the `CLASSES` list, which allowed us to quickly one-hot
    encode the labels of each image, based on the name of the directory where they
    were contained, as we observed in the body of the `load_image_and_label()` function.
    In this same function, we read an image from disk, decoded it from its JPEG format,
    converted it to grayscale (color information is not necessary in this problem),
    and then resized it to more manageable dimensions of 32x32x1.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了`CLASSES`列表，这使得我们可以快速根据每张图片所在目录的名称，对其标签进行独热编码，正如我们在`load_image_and_label()`函数中观察到的那样。在同一个函数中，我们从磁盘读取图片，解码JPEG格式，将其转换为灰度图（此问题不需要颜色信息），然后将其调整为32x32x1的尺寸。
- en: '`build_network()` creates a very simple and shallow CNN, comprising a single
    convolutional layer, activated with `ReLU()`, followed by an output, a fully connected
    layer of three neurons, corresponding to the number of categories in the dataset.
    Because this is a multi-class classification task, we use `Softmax()` to activate
    the outputs.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`build_network()`创建了一个非常简单且浅的卷积神经网络（CNN），包含一个卷积层，使用`ReLU()`激活函数，后接一个输出层，包含三个神经元，分别对应数据集中类别的数量。由于这是一个多类分类任务，我们使用`Softmax()`来激活输出层。'
- en: '`prepare_dataset()` leverages the `load_image_and_label()` function defined
    previously to convert file paths into batches of image tensors and one-hot encoded
    labels.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`prepare_dataset()`利用之前定义的`load_image_and_label()`函数，将文件路径转换为图像张量批次和独热编码标签。'
- en: Using the three functions explained here, we prepared three subsets of data,
    with the purpose of training, validating, and testing the neural network. We trained
    the model for 250 epochs, using the `adam` optimizer and `CategoricalCrossentropy(from_logits=True)`
    as our loss function (`from_logits=True` produces a bit more numerical stability).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此处解释的三个功能，我们准备了三个数据子集，目的是训练、验证和测试神经网络。我们训练模型250个epoch，使用`adam`优化器和`CategoricalCrossentropy(from_logits=True)`作为损失函数（`from_logits=True`提供了更高的数值稳定性）。
- en: Finally, we got around 93.5% accuracy on the test set. Based on these results,
    you could use this network as a component of a Rock Paper Scissors game to recognize
    the hand gestures of a player and react accordingly.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们在测试集上达到了约93.5%的准确率。根据这些结果，你可以将这个网络作为石头剪刀布游戏的一个组件，用来识别玩家的手势并做出相应的反应。
- en: See also
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 另见
- en: 'For more information on the `Rock-Paper-Scissors Images` dataset, refer to
    the official Kaggle page where it''s hosted: [https://www.kaggle.com/drgfreeman/rockpaperscissors](https://www.kaggle.com/drgfreeman/rockpaperscissors).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`Rock-Paper-Scissors Images`数据集的更多信息，请参考它的Kaggle官方页面：[https://www.kaggle.com/drgfreeman/rockpaperscissors](https://www.kaggle.com/drgfreeman/rockpaperscissors)。
- en: Creating a multi-label classifier to label watches
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个多标签分类器来标记手表
- en: A neural network is not limited to modeling the distribution of a single variable.
    In fact, it can easily handle instances where each image has multiple labels associated
    with it. In this recipe, we'll implement a CNN to classify the gender and style/usage
    of watches.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络不仅仅局限于建模单一变量的分布。实际上，它可以轻松处理每张图片关联多个标签的情况。在这个配方中，我们将实现一个卷积神经网络（CNN），用来分类手表的性别和风格/用途。
- en: Let's get started.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Getting ready
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we must install `Pillow`:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须安装`Pillow`：
- en: '[PRE22]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, we''ll use the `Fashion Product Images (Small)` dataset hosted in Kaggle,
    which, after signing in, you can download here: [https://www.kaggle.com/paramaggarwal/fashion-product-images-small](https://www.kaggle.com/paramaggarwal/fashion-product-images-small).
    In this recipe, we assume the data is inside the `~/.keras/datasets` directory,
    under the name `fashion-product-images-small`. We''ll only use a subset of the
    data, focused on watches, which we''ll construct programmatically in the *How
    to do it…* section.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用Kaggle上托管的`Fashion Product Images (Small)`数据集，登录后可以在这里下载：[https://www.kaggle.com/paramaggarwal/fashion-product-images-small](https://www.kaggle.com/paramaggarwal/fashion-product-images-small)。在本配方中，我们假设数据位于`~/.keras/datasets`目录下，文件夹名为`fashion-product-images-small`。我们只会使用该数据集的一个子集，专注于手表部分，这将在*如何操作……*部分通过编程方式构建。
- en: 'Here are some sample images:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些示例图片：
- en: '![Figure 2.3 – Example images](img/B14768_02_003.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 示例图片](img/B14768_02_003.jpg)'
- en: Figure 2.3 – Example images
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 示例图片
- en: Let's begin the recipe.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始这个配方吧。
- en: How to do it…
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Let''s review the steps to complete the recipe:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下完成这个配方的步骤：
- en: 'Import the necessary packages:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE23]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Define a function to build the network architecture. First, implement the convolutional
    blocks:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来构建网络架构。首先，实现卷积模块：
- en: '[PRE24]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, add the fully convolutional layers:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，添加全卷积层：
- en: '[PRE25]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Define a function to load all images and labels (gender and usage), given a
    list of image paths and a dictionary of metadata associated with each of them:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，根据图像路径列表和与每个图像关联的元数据字典，加载所有图像和标签（性别和使用场景）：
- en: '[PRE26]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Set the random seed to guarantee reproducibility:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子以确保结果可复现：
- en: '[PRE27]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Define the paths to the images and the `styles.csv` metadata file:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义图像路径和`styles.csv`元数据文件的路径：
- en: '[PRE28]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Keep only the `Watches` images for `Casual`, `Smart Casual`, and `Formal` usage,
    suited to `Men` and `Women`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅保留适用于`Casual`、`Smart Casual`和`Formal`使用场景的`Watches`图像，适合`Men`和`Women`：
- en: '[PRE29]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Load the images and labels, resizing the images into a 64x64x3 shape:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像和标签，将图像调整为64x64x3的形状：
- en: '[PRE30]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Normalize the images and multi-hot encode the labels:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对图像进行归一化，并对标签进行多热编码：
- en: '[PRE31]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Create the train, validation, and test splits:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练集、验证集和测试集的划分：
- en: '[PRE32]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Build and compile the network:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建并编译网络：
- en: '[PRE33]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Train the model for `20` epochs, in batches of `64` images at a time:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型`20`个epoch，每次批处理`64`张图像：
- en: '[PRE34]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Evaluate the model on the test set:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上评估模型：
- en: '[PRE35]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This block prints as follows:'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该块打印如下内容：
- en: '[PRE36]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Use the model to make predictions on a test image, displaying the probability
    of each label:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型对测试图像进行预测，显示每个标签的概率：
- en: '[PRE37]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'That prints this:'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印出如下内容：
- en: '[PRE38]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Compare the ground truth labels with the network''s prediction:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较真实标签与网络预测的结果：
- en: '[PRE39]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE40]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Let's see how it all works in the next section.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到所有内容如何工作。
- en: How it works…
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'We implemented a smaller version of a `gender` and `usage` metadata associated
    with each watch. In other words, we modeled two binary classification problems
    at the same time: one for `gender`, and one for `usage`. This is the reason we
    activated the outputs of the network with Sigmoid, instead of Softmax, and also
    why the loss function used is `binary_crossentropy` and not `categorical_crossentropy`.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了一个较小版本的与每个手表相关联的`gender`和`usage`元数据。换句话说，我们同时建模了两个二分类问题：一个是`gender`（性别），另一个是`usage`（使用场景）。这就是为什么我们使用Sigmoid激活网络输出，而不是Softmax，并且使用`binary_crossentropy`损失函数而不是`categorical_crossentropy`的原因。
- en: We trained the aforementioned network over 20 epochs, on batches of 64 images
    at a time, obtaining a respectable 90% accuracy on the test set. Finally, we made
    a prediction on an unseen image from the test set and verified that the labels
    produced with great certainty by the network (100% certainty for `Casual`, and
    99.16% for `Women`) correspond to the ground truth categories `Casual` and `Women`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上述网络上训练了20个epoch，每次使用64张图像的批处理，最终在测试集上获得了90%的准确率。最后，我们在一个未见过的测试集图像上进行了预测，并验证了网络以高度确信（`Casual`的100%确信度，`Women`的99.16%确信度）输出的标签与真实标签`Casual`和`Women`完全一致。
- en: See also
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For more information on the `Fashion Product Images (Small)` dataset, refer
    to the official Kaggle page where it is hosted: [https://www.kaggle.com/paramaggarwal/fashion-product-images-small](https://www.kaggle.com/paramaggarwal/fashion-product-images-small).
    I recommend you read the paper where the seminal **VGG** architecture was introduced:
    [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于`Fashion Product Images (Small)`数据集的信息，请参考官方Kaggle页面：[https://www.kaggle.com/paramaggarwal/fashion-product-images-small](https://www.kaggle.com/paramaggarwal/fashion-product-images-small)。我建议你阅读介绍**VGG**架构的论文：[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)。
- en: Implementing ResNet from scratch
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零实现ResNet
- en: '**Residual Network**, or **ResNet** for short, constitutes one of the most
    groundbreaking advancements in deep learning. This architecture relies on a component
    called the residual module, which allows us to ensemble networks with depths that
    were unthinkable a couple of years ago. There are variants of **ResNet** that
    have more than 100 layers, without any loss of performance!'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**残差网络**（**ResNet**的简称）是深度学习中最具突破性的进展之一。该架构依赖于一种叫做残差模块的组件，它使得我们能够将深度网络组合起来，构建出几年前无法想象的深度网络。某些**ResNet**变种的层数超过100层，且性能没有任何下降！'
- en: In this recipe, we'll implement `CIFAR-10`, `CINIC-10`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配方中，我们将实现`CIFAR-10`、`CINIC-10`。
- en: Getting ready
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We won''t explain **ResNet** in depth, so it is a good idea to familiarize
    yourself with the architecture if you are interested in the details. You can read
    the original paper here: [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入解释**ResNet**，因此如果你对细节感兴趣，最好先了解一下该架构。你可以在这里阅读原始论文：[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)。
- en: How to do it…
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Follow these steps to implement **ResNet** from the ground up:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤从头开始实现**ResNet**：
- en: 'Import all necessary modules:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的模块：
- en: '[PRE41]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Define an alias to the `tf.data.expertimental.AUTOTUNE` option, which we''ll
    use later:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个别名给`tf.data.experimental.AUTOTUNE`选项，稍后我们会使用它：
- en: '[PRE42]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Define a function to create a residual module in the `reduce=True`, we apply
    a 1x1 convolution:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，在`reduce=True`时创建一个残差模块，我们应用1x1卷积：
- en: '[PRE43]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Finally, we combine the shortcut and the third block into a single layer and
    return that as our output:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们将跳跃连接和第三个块合并成一个单一的层，并将其作为输出返回：
- en: '[PRE44]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Define a function to build a custom **ResNet** network:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来构建自定义**ResNet**网络：
- en: '[PRE45]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Define a function to load an image and its one-hot encoded labels, based on
    its file path:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来加载图像及其一热编码标签，基于其文件路径：
- en: '[PRE46]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Define a function to create a `tf.data.Dataset` instance of images and labels
    from a glob-like pattern that refers to the folder where the images are:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，通过类似 glob 的模式创建`tf.data.Dataset`实例，模式指向图像所在的文件夹：
- en: '[PRE47]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Define the mean RGB values of the `CINIC-10` dataset, which is used in the
    `load_image_and_label()` function to mean normalize the images (this information
    is available on the official `CINIC-10` site):'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`CINIC-10`数据集的平均RGB值，这些值将在`load_image_and_label()`函数中用于图像的均值归一化（该信息可在官方`CINIC-10`网站上找到）：
- en: '[PRE48]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Define the classes of the `CINIC-10` dataset:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`CINIC-10`数据集的类别：
- en: '[PRE49]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Download and extract the `CINIC-10` dataset to the `~/.keras/datasets` directory:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并解压`CINIC-10`数据集到`~/.keras/datasets`目录：
- en: '[PRE50]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Define the glob-like patterns to the train, test, and validation subsets:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义类似 glob 的模式来表示训练、测试和验证子集：
- en: '[PRE51]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Prepare the datasets:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据集：
- en: '[PRE52]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Build, compile, and train a `ModelCheckpoint()` callback:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建、编译并训练`ModelCheckpoint()`回调：
- en: '[PRE53]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Load the best model (in this case, `model.38-0.72.hdf5`) and evaluate it on
    the test set:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载最佳模型（在此例中为`model.38-0.72.hdf5`）并在测试集上进行评估：
- en: '[PRE54]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'This prints the following:'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将打印以下内容：
- en: '[PRE55]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Let's learn how it all works in the next section.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分我们将学习它是如何工作的。
- en: How it works…
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The key to `residual_module()` function receives the input data (`data`), the
    number of filters (`filters`), the stride (`stride`) of the convolutional blocks,
    a `reduce` flag to indicate whether we want to reduce the spatial size of the
    shortcut branch by applying a 1x1 convolution (a technique used to reduce the
    dimensionality of the output volumes of the filters), and parameters to adjust
    the amount of regularization (`reg`) and batch normalization applied to the different
    layers (`bn_eps` and `bn_momentum`).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`residual_module()`函数的关键接收输入数据（`data`）、滤波器数量（`filters`）、卷积块的步幅（`stride`）、`reduce`标志用于指示是否通过应用1x1卷积来减少跳跃分支的空间大小（该技术用于减少滤波器输出的维度），以及调整不同层的正则化（`reg`）和批量归一化（`bn_eps`和`bn_momentum`）的参数。'
- en: 'A residual module comprises two branches: the first one is the skip connection,
    also known as the shortcut branch, which is basically the same as the input. The
    second or main branch is composed of three convolution blocks: a 1x1 with a quarter
    of the filters, a 3x3 one, also with a quarter of the filters, and finally another
    1x1, which uses all the filters. The shortcut and main branches are concatenated
    in the end using the `Add()` layer.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一个残差模块由两条分支组成：第一条是跳跃连接，也叫捷径分支，基本上和输入相同。第二条或主分支由三个卷积块组成：一个1x1的卷积块，使用四分之一的滤波器，一个3x3的卷积块，同样使用四分之一的滤波器，最后是另一个1x1的卷积块，使用所有的滤波器。跳跃分支和主分支最终通过`Add()`层连接在一起。
- en: '`build_network()` allows us to specify the number of stages to use, and also
    the number of filters per stage. We start by applying a 3x3 convolution to the
    input (after being batch normalized). Then we proceed to create the stages. A
    stage is a series of residual modules connected to each other. The length of the
    `stages` list controls the number of stages to create, and each element in this
    list controls the number of layers in that particular stage. The `filters` parameter
    contains the number of filters to use in each residual block within a stage. Finally,
    we built a fully connected network, Softmax-activated, on top of the stages with
    as many units as there are classes in the dataset (in this case, 10).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`build_network()` 允许我们指定使用的阶段数量，以及每个阶段的过滤器数量。我们首先对输入应用一个 3x3 的卷积（在进行批量归一化后）。然后我们开始创建各个阶段。一个阶段是由一系列残差模块相互连接组成的。`stages`
    列表的长度控制要创建的阶段数，每个元素则控制该阶段中层数的数量。`filters` 参数包含每个阶段中每个残差块要使用的过滤器数量。最后，我们在这些阶段的基础上构建了一个全连接网络，并使用
    Softmax 激活函数，其单位数等于数据集中类别的数量（在此情况下为 10）。'
- en: Because `CINIC-10` is not an easy dataset and that we did not apply any data
    augmentation or transfer learning.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `CINIC-10` 数据集并不容易，而且我们没有应用任何数据增强或迁移学习。
- en: See also
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'For more information on the `CINIC-10` dataset, visit this link: [https://datashare.is.ed.ac.uk/handle/10283/3192](https://datashare.is.ed.ac.uk/handle/10283/3192).'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于 `CINIC-10` 数据集的信息，请访问此链接：[https://datashare.is.ed.ac.uk/handle/10283/3192](https://datashare.is.ed.ac.uk/handle/10283/3192)。
- en: Classifying images with a pre-trained network using the Keras API
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras API 和预训练网络进行图像分类
- en: We do not always need to train a classifier from scratch, especially when the
    images we want to categorize resemble ones that another network trained on. In
    these instances, we can simply reuse the model, saving ourselves lots of time.
    In this recipe, we'll use a pre-trained network on ImageNet to classify a custom
    image.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并不总是需要从头开始训练一个分类器，特别是当我们想要分类的图像与其他网络训练过的图像相似时。在这些情况下，我们可以简单地重用已训练的模型，从而节省大量时间。在这个教程中，我们将使用一个在
    ImageNet 上预训练的网络来对自定义图像进行分类。
- en: Let's begin!
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始吧！
- en: Getting ready
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正在准备中
- en: 'We will need `Pillow`. We can install it as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要 `Pillow`。可以通过以下方式安装：
- en: '[PRE56]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You''re free to use your own images in the recipe. Alternatively, you can download
    the one at this link: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe5/dog.jpg](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe5/dog.jpg).'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以自由使用你自己的图像，也可以从这个链接下载一张：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe5/dog.jpg](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe5/dog.jpg)。
- en: 'Here''s the image we''ll pass to the classifier:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将传递给分类器的图像：
- en: '![Figure 2.4 – Image passed to the pre-trained classifier'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4 – 输入到预训练分类器的图像'
- en: '](img/B14768_02_004.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_004.jpg)'
- en: Figure 2.4 – Image passed to the pre-trained classifier
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 输入到预训练分类器的图像
- en: How to do it…
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: As we'll see in this section, re-using a pre-trained classifier is very easy!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在这一节中将看到的，重用一个预训练的分类器非常简单！
- en: 'Import the required packages. These include the pre-trained network used for
    classification, as well as some helper functions to pre process the images:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包，包括用于分类的预训练网络，以及一些预处理图像的辅助函数：
- en: '[PRE57]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Instantiate an `InceptionV3` network pre-trained on ImageNet:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个在 ImageNet 上预训练的 `InceptionV3` 网络：
- en: '[PRE58]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Load the image to classify. `InceptionV3` takes a 299x299x3 image, so we must
    resize it accordingly:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载要分类的图像。`InceptionV3` 接受一个 299x299x3 的图像，因此我们必须相应地调整其大小：
- en: '[PRE59]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Convert the image to a `numpy` array, and wrap it into a singleton batch:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为 `numpy` 数组，并将其包装成一个单例批次：
- en: '[PRE60]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Pre process the image the same way `InceptionV3` does:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照 `InceptionV3` 的方式预处理图像：
- en: '[PRE61]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Use the model to make predictions on the image, and then decode the predictions
    to a matrix:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型对图像进行预测，然后将预测解码为矩阵：
- en: '[PRE62]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Examine the top `5` predictions along with their probability:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看前 `5` 个预测及其概率：
- en: '[PRE63]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'This produces the following output:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE64]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Plot the original image with its most probable label:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始图像及其最可能的标签：
- en: '[PRE65]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'This block generates the following image:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个块生成了以下图像：
- en: '![Figure 2.5 – Correctly classified image'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.5 – 正确分类的图像'
- en: '](img/B14768_02_005.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_005.jpg)'
- en: Figure 2.5 – Correctly classified image
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 正确分类的图像
- en: Let's see how it all works in the next section.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一节看看它是如何工作的。
- en: How it works…
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'As evidenced here, in order to classify images effortlessly, using a pre-trained
    network on ImageNet, we just need to instantiate the proper model with the right
    weights, like this: `InceptionV3(weights=''imagenet'')`. This will download the
    architecture and the weights if it is the first time we are using them; otherwise,
    a version of these files will be cached in our system.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如此所示，为了轻松分类图像，只需使用在ImageNet上预训练的网络，我们只需要用正确的权重实例化适当的模型，像这样：`InceptionV3(weights='imagenet')`。如果这是第一次使用它，它将下载架构和权重；否则，这些文件的版本将被缓存到我们的系统中。
- en: Then, we loaded the image we wanted to classify, resized it to dimensions compatible
    with `InceptionV3` (299x299x3), converted it into a singleton batch with `np.expand_dims(image,
    axis=0)`, and pre processed it the same way `InceptionV3` did when it was trained,
    with `preprocess_input(image)`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们加载了我们想要分类的图像，将其调整为与`InceptionV3`兼容的尺寸（299x299x3），通过`np.expand_dims(image,
    axis=0)`将其转换为单例批次，并以`InceptionV3`训练时相同的方式进行预处理，使用`preprocess_input(image)`。
- en: Next, we got the predictions from the model, which we need to transform to a
    prediction matrix with the help of `imagenet_utils.decode_predictions(predictions)`.
    This matrix contains the label and probabilities in the 0th row, which we inspected
    to get the five most probable classes.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从模型中获取预测结果，我们需要借助`imagenet_utils.decode_predictions(predictions)`将其转换为预测矩阵。这个矩阵在第0行包含了标签和概率，我们检查了它以获取最有可能的五个类别。
- en: See also
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can read more about Keras pre-trained models here: [https://www.tensorflow.org/api_docs/python/tf/keras/applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications).'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里阅读更多关于Keras预训练模型的内容：[https://www.tensorflow.org/api_docs/python/tf/keras/applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications)。
- en: Classifying images with a pre-trained network using TensorFlow Hub
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow Hub通过预训练网络对图像进行分类
- en: '**TensorFlow Hub** (**TFHub**) is a repository of hundreds of machine learning
    models contributed to by the big and rich community that surrounds TensorFlow.
    Here we can find models for a myriad of different tasks, not only for computer
    vision but for applications in many different domains, such as **Natural Language
    Processing** (**NLP**) and reinforcement learning.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow Hub** (**TFHub**) 是一个包含数百个机器学习模型的仓库，受到了围绕TensorFlow的庞大社区的贡献。在这里，我们可以找到多种不同任务的模型，不仅限于计算机视觉，还包括许多其他领域的应用，如**自然语言处理**
    (**NLP**)和强化学习。'
- en: In this recipe, we'll use a model trained on ImageNet, hosted on TFHub, to make
    predictions on a custom image. Let's begin!
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用一个在ImageNet上训练的模型，该模型托管在TFHub上，用来对自定义图像进行预测。让我们开始吧！
- en: Getting ready
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll need the `tensorflow-hub` and `Pillow` packages, which can be easily
    installed using `pip`, as follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`tensorflow-hub`和`Pillow`包，它们可以通过`pip`轻松安装，如下所示：
- en: '[PRE66]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'If you want to use the same image we use in this recipe, you can download it
    here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe6/beetle.jpg](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe6/beetle.jpg).'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用我们在这个食谱中使用的相同图像，可以在这里下载：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe6/beetle.jpg](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch2/recipe6/beetle.jpg)。
- en: 'Here''s the image we''ll classify:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要分类的图像：
- en: '![Figure 2.6 – Image to be classified'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.6 – 待分类的图像'
- en: '](img/B14768_02_006.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_006.jpg)'
- en: Figure 2.6 – Image to be classified
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 待分类的图像
- en: Let's head to the next section.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进入下一节。
- en: How to do it…
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s proceed with the recipe steps:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续食谱步骤：
- en: 'Import the necessary packages:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE67]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Define the URL of the pre-trained `ResNetV2152` classifier in **TFHub**:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义预训练的`ResNetV2152`分类器的URL地址，托管在**TFHub**上：
- en: '[PRE68]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Download and instantiate the classifier hosted on TFHub:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并实例化托管在TFHub上的分类器：
- en: '[PRE69]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Load the image we''ll classify, convert it to a `numpy` array, normalize it,
    and wrap it into a singleton batch:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载我们要分类的图像，将其转换为`numpy`数组，对其进行归一化，并将其包装为单例批次：
- en: '[PRE70]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Use the pre-trained model to classify the image:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预训练模型对图像进行分类：
- en: '[PRE71]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Extract the index of the most probable prediction:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取最可能的预测的索引：
- en: '[PRE72]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Download the ImageNet labels into a file named `ImageNetLabels.txt`:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载名为`ImageNetLabels.txt`的ImageNet标签文件：
- en: '[PRE73]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Read the labels into a `numpy` array:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标签读取到`numpy`数组中：
- en: '[PRE74]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Extract the name of the class corresponding to the index of the most probable
    prediction:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取与最可能的预测索引对应的类别名称：
- en: '[PRE75]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Plot the original image with its most probable label:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始图像及其最可能的标签：
- en: '[PRE76]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'This produces the following:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将生成以下结果：
- en: '![Figure 2.7 – Correctly classified image'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.7 – 正确分类的图像'
- en: '](img/B14768_02_007.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_007.jpg)'
- en: Figure 2.7 – Correctly classified image
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – 正确分类的图像
- en: Let's see how it all works.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这一切是如何工作的。
- en: How it works…
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'After importing the relevant packages, we proceeded to define the URL of the
    model we wanted to use to classify our input image. To download and convert such
    a network into a Keras model, we used the convenient `hub.KerasLayer` class in
    *Step 3*. Then, in *Step 4*, we loaded the image we wanted to classify into memory,
    making sure its dimensions match the ones the network expects: 224x224x3.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入相关包后，我们继续定义我们想要用来分类输入图像的模型 URL。为了下载并将这个网络转换为 Keras 模型，我们在*步骤 3* 中使用了方便的 `hub.KerasLayer`
    类。然后，在*步骤 4* 中，我们将想要分类的图像加载到内存中，确保它的维度与网络所期望的相匹配：224x224x3。
- en: '*Steps 5* and *6* perform the classification and extract the most probable
    category, respectively. However, to make this prediction human-readable, we downloaded
    a plain text file with all ImageNet labels in *Step 7*, which we then parsed using
    `numpy`, allowing us to use the index of the most probable category to obtain
    the corresponding label, finally displayed in *Step 10* along with the input image.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 5* 和 *6* 分别执行分类和提取最可能的类别。然而，为了使这个预测对人类可读，我们在*步骤 7* 中下载了一个包含所有 ImageNet
    标签的纯文本文件，然后使用 `numpy` 解析它，这样我们就可以使用最可能类别的索引来获取对应的标签，最终在*步骤 10* 中与输入图像一起显示出来。'
- en: See also
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can learn more about the pre-trained model we used here: [https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4](https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4).'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里了解更多关于我们使用的预训练模型：[https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4](https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4)。
- en: Using data augmentation to improve performance with the Keras API
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据增强通过 Keras API 提高性能
- en: More often than not, we can benefit from providing more data to our model. But
    data is expensive and scarce. Is there a way to circumvent this limitation? Yes,
    there is! We can synthesize new training examples by performing little modifications
    on the ones we already have, such as random rotations, random cropping, and horizontal
    flipping, among others. In this recipe, we'll learn how to use data augmentation
    with the Keras API to improve performance.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们可以通过为模型提供更多的数据来提高效果。但数据是昂贵且稀缺的。有办法绕过这一限制吗？是的，有办法！我们可以通过对已有数据进行一些小的修改，如随机旋转、随机裁剪和水平翻转等，来合成新的训练样本。在本食谱中，我们将学习如何使用
    Keras API 进行数据增强来提升性能。
- en: Let's begin.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Getting ready
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'We must install `Pillow` and `tensorflow_docs`:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须安装 `Pillow` 和 `tensorflow_docs`：
- en: '[PRE77]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'In this recipe, we''ll use the `Caltech 101` dataset, which is available here:
    [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/).
    Download and decompress `101_ObjectCategories.tar.gz` to your preferred location.
    From now on, we assume the data is inside the `~/.keras/datasets` directory, under
    the name `101_ObjectCategories`.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用 `Caltech 101` 数据集，可以在这里找到：[http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)。下载并解压
    `101_ObjectCategories.tar.gz` 到你选择的位置。从现在开始，我们假设数据位于 `~/.keras/datasets` 目录下，文件名为
    `101_ObjectCategories`。
- en: 'Here are sample images from `Caltech 101`:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是来自`Caltech 101`的数据集的示例图像：
- en: '![Figure 2.8 – Caltech 101 sample images'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.8 – Caltech 101 示例图像'
- en: '](img/B14768_02_008.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_008.jpg)'
- en: Figure 2.8 – Caltech 101 sample images
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – Caltech 101 示例图像
- en: Let's implement!
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现吧！
- en: How to do it…
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: The steps listed here are necessary to complete the recipe. Let's get started!
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出的步骤是完成该食谱所必需的。让我们开始吧！
- en: 'Import the required modules:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的模块：
- en: '[PRE78]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Define a function to load all images in the dataset, along with their labels,
    based on their file paths:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，根据文件路径加载数据集中的所有图像及其标签：
- en: '[PRE79]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Define a function to build a smaller version of **VGG**:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来构建一个更小版本的**VGG**：
- en: '[PRE80]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Define a function to plot and save a model''s training curve:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来绘制并保存模型的训练曲线：
- en: '[PRE81]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Set the random seed:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子：
- en: '[PRE82]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Load the paths to all images in the dataset, excepting the ones of the `BACKGROUND_Google`
    class:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集中所有图像的路径，除了 `BACKGROUND_Google` 类别的图像：
- en: '[PRE83]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Compute the set of classes in the dataset:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算数据集中的类别集合：
- en: '[PRE84]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Load the dataset into memory, normalizing the images and one-hot encoding the
    labels:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集加载到内存中，对图像进行归一化处理并进行 one-hot 编码标签：
- en: '[PRE85]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Create the training and testing subsets:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练和测试子集：
- en: '[PRE86]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Build, compile, train, and evaluate a neural network without data augmentation:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建、编译、训练并评估一个没有数据增强的神经网络：
- en: '[PRE87]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The accuracy on the test set is as follows:'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试集上的准确率如下：
- en: '[PRE88]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'And here''s the accuracy curve:'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是准确率曲线：
- en: '![Figure 2.9 – Training and validation accuracy for a network without data
    augmentation'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.9 – 没有数据增强的网络训练和验证准确率'
- en: '](img/B14768_02_009.jpg)'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_02_009.jpg)'
- en: Figure 2.9 – Training and validation accuracy for a network without data augmentation
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.9 – 没有数据增强的网络训练和验证准确率
- en: 'Build, compile, train, and evaluate the same network, this time with data augmentation:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建、编译、训练并评估相同的网络，这次使用数据增强：
- en: '[PRE89]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The accuracy on the test set when we use data augmentation is as follows:'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用数据增强时，我们在测试集上的准确率如下：
- en: '[PRE90]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'And the accuracy curve looks like this:'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确率曲线如下所示：
- en: '![Figure 2.10 – Training and validation accuracy for a network with data augmentation'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.10 – 使用数据增强的网络训练和验证准确率'
- en: '](img/B14768_02_010.jpg)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_010.jpg)'
- en: Figure 2.10 – Training and validation accuracy for a network with data augmentation
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 使用数据增强的网络训练和验证准确率
- en: Comparing *Steps 10* and *11*, we observe a noticeable gain in performance by
    using data augmentation. Let's understand better what we did in the next section.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 比较*步骤 10*和*步骤 11*，我们观察到通过使用数据增强，性能有了显著提升。让我们在下一节中更好地理解我们做了什么。
- en: How it works…
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, we implemented a scaled-down version of `Caltech 101` dataset.
    First, we trained a network only on the original data, and then using data augmentation.
    The first network (see *Step 10*) obtained an accuracy level on the test set of
    61.3% and clearly shows signs of overfitting, because the gap that separates the
    training and validation accuracy curves is very wide. On the other hand, by applying
    a series of random perturbations, through `ImageDataGenerator()`, such as horizontal
    flips, rotations, width, and height shifting, among others (see *Step 11*), we
    increased the accuracy on the test set to 65.2%. Also, the gap between the training
    and validation accuracy curves is much smaller this time, which suggests a regularization
    effect resulting from the application of data augmentation.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们实现了一个简化版的`Caltech 101`数据集。首先，我们只用原始数据训练一个网络，然后使用数据增强。第一个网络（见*步骤 10*）在测试集上的准确率为61.3%，并且明显表现出过拟合的迹象，因为训练和验证准确率曲线之间的差距非常大。另一方面，通过应用一系列随机扰动，使用`ImageDataGenerator()`，例如水平翻转、旋转、宽度和高度平移等（见*步骤
    11*），我们将测试集上的准确率提高到了65.2%。此外，这次训练和验证准确率曲线之间的差距明显缩小，这表明数据增强的应用产生了正则化效应。
- en: See also
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can learn more about `Caltech 101` here: [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/).'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里了解更多关于`Caltech 101`的信息：[http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)。
- en: Using data augmentation to improve performance with the tf.data and tf.image
    APIs
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据增强来提高性能，使用tf.data和tf.image API
- en: Data augmentation is a powerful technique we can apply to artificially increment
    the size of our dataset, by creating slightly modified copies of the images at
    our disposal. In this recipe, we'll leverage the `tf.data` and `tf.image` APIs
    to increase the performance of a CNN trained on the challenging `Caltech 101`
    dataset.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是一个强大的技术，我们可以通过创建稍作修改的图像副本，人工增加数据集的大小。在本示例中，我们将利用`tf.data`和`tf.image` API来提高在具有挑战性的`Caltech
    101`数据集上训练的CNN性能。
- en: Getting ready
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We must install `tensorflow_docs`:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须安装`tensorflow_docs`：
- en: '[PRE91]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'In this recipe, we''ll use the `Caltech 101` dataset, which is available here:
    [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/).
    Download and decompress `101_ObjectCategories.tar.gz` to your preferred location.
    From now on, we assume the data is inside the `~/.keras/datasets` directory, in
    a folder named `101_ObjectCategories`.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将使用`Caltech 101`数据集，您可以在这里找到：[http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)。下载并解压`101_ObjectCategories.tar.gz`到您喜欢的位置。从现在开始，我们假设数据位于`~/.keras/datasets`目录下的名为`101_ObjectCategories`的文件夹中。
- en: 'Here are some sample images from `Caltech 101`:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是`Caltech 101`的一些示例图像：
- en: '![Figure 2.11 – Caltech 101 sample images'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.11 – Caltech 101 示例图像'
- en: '](img/B14768_02_011.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_011.jpg)'
- en: Figure 2.11 – Caltech 101 sample images
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – Caltech 101 示例图像
- en: Let's go to the next section.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入下一节。
- en: How to do it…
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: Let's go over the steps required to complete this recipe.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下完成此任务所需的步骤。
- en: 'Import the necessary dependencies:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的依赖项：
- en: '[PRE92]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Create an alias for the `tf.data.experimental.AUTOTUNE` flag, which we''ll
    use later on:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`tf.data.experimental.AUTOTUNE`标志创建一个别名，稍后我们将使用它：
- en: '[PRE93]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Define a function to create a smaller version of **VGG**. Start by creating
    the input layer and the first block of two convolutions with 32 filters each:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来创建一个更小版本的**VGG**。首先创建输入层和第一组具有32个滤波器的两个卷积层：
- en: '[PRE94]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Continue with the second block of two convolutions, this time each with 64
    kernels:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续进行第二个包含两个卷积层的模块，这次每个模块有64个卷积核：
- en: '[PRE95]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Define the last part of the architecture, which consists of a series of fully
    connected layers:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义架构的最后部分，其中包括一系列全连接层：
- en: '[PRE96]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Define a function to plot and save the training curves of a model, given its
    training history:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，根据模型的训练历史绘制并保存训练曲线：
- en: '[PRE97]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Define a function to load an image and one-hot encode its label, based on the
    image''s file path:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来加载图像并进行独热编码标签，基于图像的文件路径：
- en: '[PRE98]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Define a function to augment an image by performing random transformations
    on it:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，通过对图像执行随机变换来增强图像：
- en: '[PRE99]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Define a function to prepare a `tf.data.Dataset` of images, based on a glob-like
    pattern that refers to the folder where they live:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来准备基于类似glob模式的`tf.data.Dataset`图像集，该模式指向图像所在的文件夹：
- en: '[PRE100]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Set the random seed:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子：
- en: '[PRE101]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Load the paths to all images in the dataset, excepting the ones of the `BACKGROUND_Google`
    class:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集中所有图像的路径，排除`BACKGROUND_Google`类别的图像：
- en: '[PRE102]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Compute the unique categories in the dataset:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算数据集中的唯一类别：
- en: '[PRE103]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Split the image paths into training and testing subsets:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像路径分割成训练集和测试集：
- en: '[PRE104]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'Prepare the training and testing datasets, without augmentation:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备训练和测试数据集，不进行数据增强：
- en: '[PRE105]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Instantiate, compile, train and evaluate the network:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化、编译、训练并评估网络：
- en: '[PRE106]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'The accuracy on the test set is:'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在测试集上的精度是：
- en: '[PRE107]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'And here''s the accuracy curve:'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是精度曲线：
- en: '![Figure 2.12 – Training and validation accuracy for a network without data
    augmentation'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图2.12 – 没有数据增强的网络的训练和验证精度'
- en: '](img/B14768_02_012.jpg)'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_02_012.jpg)'
- en: Figure 2.12 – Training and validation accuracy for a network without data augmentation
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.12 – 没有数据增强的网络的训练和验证精度
- en: 'Prepare the training and testing sets, this time applying data augmentation
    to the training set:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备训练和测试集，这次对训练集应用数据增强：
- en: '[PRE108]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Instantiate, compile, train, and evaluate the network on the augmented data:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化、编译、训练并在增强数据上评估网络：
- en: '[PRE109]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The accuracy on the test set when we use data augmentation is as follows:'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用数据增强时，测试集上的精度如下所示：
- en: '[PRE110]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'And the accuracy curve looks like this:'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 精度曲线如下所示：
- en: '![Figure 2.13 – Training and validation accuracy for a network with data augmentation'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.13 – 具有数据增强的网络的训练和验证精度'
- en: '](img/B14768_02_013.jpg)'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_02_013.jpg)'
- en: Figure 2.13 – Training and validation accuracy for a network with data augmentation
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13 – 具有数据增强的网络的训练和验证精度
- en: Let's understand what we just did in the next section.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一节中了解我们刚刚做了什么。
- en: How it works…
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: We just implemented a trimmed down version of the famous `Caltech 101` dataset.
    To better understand the advantages of data augmentation, we fitted a first version
    on the original data, without any modification, obtaining an accuracy level of
    65.32% on the test set. This first model displays signs of overfitting, because
    the gap that separates the training and validation accuracy curves widens early
    in the training process.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚实现了著名的`Caltech 101`数据集的精简版本。为了更好地理解数据增强的优势，我们在原始数据上拟合了第一个版本，未进行任何修改，在测试集上的准确率为65.32%。该模型表现出过拟合的迹象，因为训练和验证精度曲线之间的差距在训练初期就开始变宽。
- en: Next, we trained the same network on an augmented dataset (see *Step 15*), using
    the `augment()` function defined earlier. This greatly improved the model's performance,
    reaching a respectable accuracy of 74.19% on the test set. Also, the gap between
    the training and validation accuracy curves is noticeably smaller, which suggests
    a regularization effect coming out from the application of data augmentation.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在增强数据集上训练了相同的网络（参见*步骤15*），使用之前定义的`augment()`函数。这极大地提升了模型性能，在测试集上达到了74.19%的准确率。此外，训练和验证精度曲线之间的差距明显缩小，这表明数据增强的应用具有正则化效果。
- en: See also
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can learn more about `Caltech 101` here: [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/).'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里了解更多关于`Caltech 101`的信息：[http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)。
