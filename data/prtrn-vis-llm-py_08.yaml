- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Large-Scale Training on SageMaker
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 SageMaker 上的大规模训练
- en: In this chapter, we will cover the key features and functionality available
    with Amazon SageMaker to run highly optimized distributed training. You’ll learn
    how to optimize your script for SageMaker training, along with key usability features.
    You’ll also learn about backend optimizations for distributed training with SageMaker,
    such as GPU health checks, resilient training, checkpointing, and script mode.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍 Amazon SageMaker 提供的关键功能和特性，以便进行高效的分布式训练。你将学习如何优化脚本以适应 SageMaker
    训练，并掌握一些关键的可用性特性。你还将了解 SageMaker 的后端优化，例如 GPU 健康检查、弹性训练、检查点和脚本模式。
- en: 'We are going to cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主题：
- en: Optimizing your script for SageMaker training
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 SageMaker 训练优化你的脚本
- en: Top usability features for SageMaker training
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 训练的顶级可用性特性
- en: Optimizing your script for SageMaker training
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为 SageMaker 训练优化你的脚本
- en: So far in this book, you have learned quite a lot! We have covered everything
    from the foundations of pretraining to GPU optimization, picking the right use
    case, dataset and model preparation, parallelization basics, finding the right
    hyperparameters, and so on. The vast majority of this is that these are applicable
    in any compute environment you choose to apply them to. This chapter, however,
    is exclusively scoped to AWS and SageMaker especially. Why? So that you can master
    all the nuances included in at least one compute platform. Once you have learned
    how to become proficient in one compute platform, then you will be able to use
    that to work on any project you like! When, for various reasons, you need to transition
    onto another platform, you will at least have the basic concepts you need to know
    about to look for and consider the transition.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学到了很多内容！我们已经涵盖了从预训练基础到 GPU 优化、选择合适的用例、数据集和模型准备、并行化基础、寻找合适的超参数等等。这些内容绝大部分是适用于你选择应用的任何计算环境的。然而，本章专门面向
    AWS 和特别是 SageMaker。为什么？这样你就可以掌握至少一种计算平台的所有细节。一旦你学会了如何在一种计算平台上变得熟练，那么你就能够将它用于任何你喜欢的项目！当出于各种原因需要过渡到另一个平台时，你至少能掌握过渡时所需要了解的基本概念。
- en: 'First, let us look at your scripts. The core of most SageMaker training scripts
    has at least three things:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看你的脚本。大多数 SageMaker 训练脚本的核心至少包含以下三项内容：
- en: Package imports
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包导入
- en: Argument parsing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数解析
- en: Function definitions and usage
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数定义和使用
- en: Let’s break these down next.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将逐一解析这些内容。
- en: Importing packages
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入包
- en: As we’ve covered previously, you can install and access really any package you
    need. You have many different ways to make these accessible within SageMaker training.
    At a minimum, when you define your job, you can bring a `requirements.txt` file
    with the packages defined. SageMaker will then use `pip install` to install these
    on your training compute for you, making them available.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论过的，你可以安装并访问任何你需要的包。你有多种方法可以在 SageMaker 训练中使它们可用。至少，当你定义你的作业时，你可以带上一个包含已定义包的
    `requirements.txt` 文件。然后，SageMaker 将使用 `pip install` 安装这些包到你的训练计算环境中，使它们可用。
- en: Alternatively, you can build a base container with all of these pre-installed.
    This is certainly the fastest option, since it saves time during the training
    process. Rather than using *pip install*, you can use a pre-built image with all
    of the packages available. Another option is to import your own Python packages,
    sending your entire project to the SageMaker training environment. Then, you can
    import whatever code you’re working on.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以构建一个预装了所有这些内容的基础容器。这无疑是最快的选择，因为它节省了训练过程中的时间。与其使用 *pip install*，不如使用一个预构建的镜像，所有的包都已包含。另一种选择是导入你自己的
    Python 包，将整个项目发送到 SageMaker 训练环境中。然后，你可以导入你正在工作的代码。
- en: Argument parsing
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数解析
- en: An extremely common package we use in the SageMaker training environment is
    `argparse`. If you’re not familiar with this, let me introduce you to it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SageMaker 训练环境中，我们经常使用的一个非常常见的包是 `argparse`。如果你不熟悉它，让我来介绍一下。
- en: Once you’ve built a Python script, you might need to run it with different flags,
    settings, or arguments. Some of these might be with different hyperparameters,
    modes, or features that you want your script to run for you. The `argparse` package
    is a great way to do this in Python. First, in your script, you’ll need to *explicitly
    add a line of code for each argument you want to use*. In SageMaker, you might
    start with something like this.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你构建了Python脚本，你可能需要通过不同的标志、设置或参数来运行它。其中一些可能是不同的超参数、模式或你希望脚本执行的功能。`argparse`包是Python中实现这一目标的绝佳方式。首先，在脚本中，你需要*明确地为每个你想使用的参数添加一行代码*。在SageMaker中，你可能会这样开始。
- en: '![Figure 8.1 – A basic arg parsing function](img/B18942_Figure_8.01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 一个基本的参数解析函数](img/B18942_Figure_8.01.jpg)'
- en: Figure 8.1 – A basic arg parsing function
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 一个基本的参数解析函数
- en: As you can see in *Figure 8**.1*, I’m simply importing `argparse`, creating
    the `parser` object, and then adding an argument called `train_folder`. This will
    default to looking up *my environment variable*, which, as you may remember, is
    how SageMaker training injects information into your environment. If you’re curious,
    you can step through the CloudWatch logs for any of your SageMaker training jobs
    to see a list of all of the available environment variables. These will include
    all of the metadata for your job, all of your hyperparameters, and so on.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图8.1*中看到的，我只是导入了`argparse`，创建了`parser`对象，然后添加了一个名为`train_folder`的参数。默认情况下，它会查找*我的环境变量*，你可能还记得，SageMaker训练通过这种方式将信息注入到你的环境中。如果你感兴趣，你可以通过CloudWatch日志查看任何SageMaker训练作业，了解所有可用环境变量的列表。这些环境变量包括你作业的所有元数据、所有超参数等等。
- en: In this brief example, I’m pointing to my *train channel*. I created this by
    pointing to S3, or an optional FSx for Lustre, when I created my training job.
    That’s my training data. First, I upload it to S3\. Then, I point to it when I
    configure my job. SageMaker copies that onto my SageMaker training instance and
    loads it onto a local path. The local path is usually something like `/opt/ml/input/data/train/`.
    When you want to point to that local path on your training container, you call
    `args.train_folder`, or however you’ve defined it. To read the file, you can either
    list the name from the folder or pass the name as another argument.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简短的示例中，我指向了我的*训练通道*。当我创建训练作业时，通过指向S3或可选的FSx for Lustre，我创建了这个训练通道。这就是我的训练数据。首先，我将其上传到S3。然后，我在配置作业时指向它。SageMaker将其复制到我的SageMaker训练实例，并加载到本地路径。这个本地路径通常是`/opt/ml/input/data/train/`这样的路径。当你想指向训练容器上的本地路径时，你调用`args.train_folder`，或者你定义的任何名称。要读取文件，你可以列出文件夹中的文件名，或将文件名作为另一个参数传递。
- en: My personal favorite way to keep my script clean and tidy is to wrap all of
    my `arg` parsing in a dedicated function. Then, this will neatly return the `args`
    object. Here’s the full script.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人喜欢保持脚本清晰整洁的方法是将所有的`arg`解析封装在一个专用函数中。然后，它会整齐地返回`args`对象。以下是完整脚本。
- en: '![Figure 8.2 – Invoking the arg parsing function in your main script](img/B18942_Figure_8.02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 在主脚本中调用参数解析函数](img/B18942_Figure_8.02.jpg)'
- en: Figure 8.2 – Invoking the arg parsing function in your main script
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 在主脚本中调用参数解析函数
- en: Another common argument you might pass is `model_dir`. You can point this to
    the `SM_MODEL_DIR` SM environment variable. SageMaker will write your model from
    the training container to S3 after the job is finished.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的参数是`model_dir`。你可以将其指向`SM_MODEL_DIR` SM环境变量。SageMaker将在作业完成后，将你的模型从训练容器写入S3。
- en: You can add any other hyperparameter you want, using the `hyperparameters` argument
    in the job config. Then, you can use these in your scripts. I’ve built arguments
    to point to things such as my data index, how to run my scripts, a path to checkpoint
    my model, and countless other arguments you may need for your project.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用作业配置中的`hyperparameters`参数添加任何你想要的超参数。然后，你可以在脚本中使用这些超参数。我已经创建了指向诸如我的数据索引、如何运行我的脚本、检查点模型路径以及你项目中可能需要的其他无数参数的命令行参数。
- en: Functions definition and usage
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数的定义和使用
- en: At the risk of stating the obvious here, you can write whatever software you
    want to write. You can copy directly to and from any accessible data source, spawn
    other jobs, initiate other cloud resources, or use open source packages – the
    possibilities are endless.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在此声明可能有些显而易见，你可以编写你想编写的任何软件。你可以直接从任何可访问的数据源读取和写入，启动其他作业，启动其他云资源，或使用开源包——可能性无穷无尽。
- en: Invoke your script with mpi
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用mpi调用你的脚本
- en: When you’re using distributed training, SageMaker invokes your script with `mpi`.
    As you learned earlier, this is a core library useful to run distributed training.
    We’ll use `mpirun` or `smddprun` to invoke your script. As you can see, we’ll
    invoke your script with all of the relevant parameters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用分布式训练时，SageMaker 会通过 `mpi` 调用你的脚本。如前所述，这是一个在分布式训练中非常有用的核心库。我们将使用 `mpirun`
    或 `smddprun` 来调用你的脚本。如你所见，我们会使用所有相关的参数来调用你的脚本。
- en: '![Figure 8.3 – How SageMaker training invokes your script](img/B18942_Figure_8.03.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – SageMaker 训练如何调用你的脚本](img/B18942_Figure_8.03.jpg)'
- en: Figure 8.3 – How SageMaker training invokes your script
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – SageMaker 训练如何调用你的脚本
- en: This is from a very complex example, training tens of billions of parameters
    for GPT-2, but it shows you many of the available ways you can configure your
    distributed training cluster on SageMaker.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常复杂的示例，训练了 GPT-2 的数百亿参数，但它展示了你可以在 SageMaker 上配置分布式训练集群的多种方法。
- en: Logging and CloudWatch
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 日志记录与 CloudWatch
- en: As you may be aware, you have many options for logging. print statements are
    a great way to debug, but as you grow, you may move to something more managed
    such as the `logging` package. Remember that all of these are sent to CloudWatch
    logs, so you can easily view and debug your scripts. Open up the training job
    view in the AWS console, scroll to the bottom, and click the *View logs*. This
    takes you to CloudWatch, giving you one log stream per node in your cluster, each
    called `algo`. Usually, the top log stream is the leader node, but all of the
    streams will try to connect to the leader, so just see which algo they are trying
    to connect to. The logs will start after your instances are online and the script
    has been invoked, so it may take a few minutes after the job starts to see these.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，你有很多日志记录的选项。打印语句是调试的好方法，但随着项目的发展，你可能会转向更为管理化的工具，比如 `logging` 包。记住，所有这些日志都会发送到
    CloudWatch 中，因此你可以轻松查看和调试你的脚本。打开 AWS 控制台中的训练任务视图，滚动到底部，点击 *查看日志*。这将带你进入 CloudWatch，提供每个节点的日志流，每个日志流被命名为
    `algo`。通常，顶部的日志流是主节点，但所有日志流都会尝试连接到主节点，因此你只需查看它们尝试连接的 `algo`。日志将在你的实例上线并且脚本被调用后开始记录，因此在任务开始后可能需要几分钟才能看到这些日志。
- en: Checkpointing
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 检查点
- en: One last parameter to be aware of in your SageMaker training scripts is **checkpointing**.
    In SageMaker, this actually serves a different role than just the model path.
    The model path will be copied to S3 at the end of your training job, but your
    checkpoints *will be copied throughout*. This makes them a great candidate for
    in-job debugging, running TensorBoard *(2)*, and restarting from the latest checkpoint.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SageMaker 训练脚本中，另一个需要注意的参数是 **检查点**。在 SageMaker 中，检查点的作用不同于仅仅作为模型路径。模型路径将在训练任务结束时复制到
    S3，但你的检查点 *将在整个过程中被复制*。这使得它们成为在任务中调试、运行 TensorBoard *(2)* 和从最新检查点重启的理想选择。
- en: Implementing a restart from your checkpoint is an extremely efficient technique
    to learn and perfect. It’s not hard – just look in S3 for the right path, configure
    your job, and then make sure you’re looking in the right directory for your base
    model. For large-scale jobs, we recommend you checkpoint at least every 2–3 hours.
    This makes it easy for you to get through any hardware, software, networking,
    data, or other issues that will almost certainly arise throughout your training
    process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 实现从检查点重启是一种非常高效的技术，值得学习和完善。这并不难——只需在 S3 中查找正确的路径，配置你的任务，然后确保你在正确的目录中查找你的基础模型。对于大规模任务，我们建议你至少每
    2 到 3 小时创建一次检查点。这将帮助你应对训练过程中几乎肯定会出现的硬件、软件、网络、数据或其他问题。
- en: For a detailed example of this, take a look at our GPT-2 training example at
    *(3)* in the *References* section. It implements a `load_partial` parameter that
    points to the S3 path you can provide for checkpointing.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 若要查看更详细的示例，可以参考我们在 *参考文献* 部分 *(3)* 中的 GPT-2 训练示例。它实现了一个 `load_partial` 参数，指向你可以为检查点提供的
    S3 路径。
- en: Configuring your job via the SageMaker estimator
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 SageMaker 估算器配置任务
- en: While you do have multiple ways of running your SageMaker job, notably through
    the UI, the CLI, and `boto3`, probably the most popular way of doing this is through
    the Python SDK.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你有多种方法可以运行你的 SageMaker 任务，特别是通过 UI、CLI 和 `boto3`，但最常见的方式可能是通过 Python SDK。
- en: 'Here’s an example of what this might look like:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个可能的示例：
- en: '![Figure 8.4 – Using the SageMaker estimator to run your remote training job](img/B18942_Figure_8.04.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 使用 SageMaker 估算器运行远程训练任务](img/B18942_Figure_8.04.jpg)'
- en: Figure 8.4 – Using the SageMaker estimator to run your remote training job
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 使用 SageMaker 估算器运行远程训练任务
- en: 'Note that we’re pointing to a base image, actually through the `PyTorch` object.
    This points to a base AWS Deep Learning Container, defined by what framework version
    you specify. You can override this by pointing to `image_uri`, which will need
    to be a Docker container in Amazon ECS. In this estimator, you can also pass key
    parameters such as the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们指向的是一个基础镜像，实际上是通过 `PyTorch` 对象来指向的。它指向一个基础的 AWS 深度学习容器，具体由你指定的框架版本决定。你可以通过指向
    `image_uri` 来覆盖它，这需要是 Amazon ECS 中的 Docker 容器。在这个估算器中，你还可以传递一些关键参数，例如：
- en: '`instance_count` and `instance_type` to configure your training resource.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance_count` 和 `instance_type` 用于配置你的训练资源。'
- en: Your entry point script and its source directory. This is where SageMaker will
    look for `requirements.txt` and your main script to execute both of the files.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的入口点脚本及其源目录。这是 SageMaker 查找 `requirements.txt` 和你的主脚本以执行两个文件的地方。
- en: Your hyperparameters – again, you define them based on what you need.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的超参数 – 再次提醒，你根据自己的需求定义这些参数。
- en: Your distribution parameters. We’ll cover them in the last section of this chapter.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的分发参数。我们将在本章的最后一节中讲解它们。
- en: Next, let’s take a look at some interesting usability features for SageMaker
    training.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们来看看一些 SageMaker 训练中的有趣可用性功能。
- en: Top usability features for SageMaker training
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SageMaker 训练的顶级可用性功能
- en: Now that you have some sense of how to integrate your scripts with SageMaker
    training, let’s learn about a few key aspects of SageMaker that make it especially
    easy and fun to work with.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你对如何将脚本与 SageMaker 训练集成有了一些了解，我们来学习一下 SageMaker 的一些关键方面，它们让使用 SageMaker 变得尤其简单和有趣。
- en: Warm pools for rapid experimentation
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 热池用于快速实验
- en: 'Once your SageMaker job is online, it moves through the following phases:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的 SageMaker 任务上线，它将经历以下阶段：
- en: Initializing resources
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化资源
- en: Downloading your data
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载你的数据
- en: Downloading your training image
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载你的训练镜像
- en: Invoking your main script
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用你的主脚本
- en: Uploading the model artifact to S3 on completion
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务完成后，将模型文件上传到 S3
- en: You might be wondering, what happens if my job breaks and I need to update a
    few lines of code? Do I need to completely restart the entire cluster from scratch?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，如果我的任务崩溃了，我需要更新几行代码怎么办？我需要从头开始完全重启整个集群吗？
- en: Fortunately for you, the answer is no! Definitely not. You can use managed warm
    pools. Just add one extra hyperparameter, `keep_alive_period_in_seconds`, and
    it’ll keep your job online even after your script either fails or finishes completely.
    This is useful because, in many cases, that upfront job initialization actually
    is the largest bottleneck in your flow. It can take anywhere from a few minutes
    for smaller CPU-based instances to as much as 8 minutes or more for larger GPU-based
    instances to initialize.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，答案是否定的！绝对不是。你可以使用托管的热池。只需添加一个额外的超参数 `keep_alive_period_in_seconds`，它将保持你的任务在线，即使脚本失败或完全完成。这非常有用，因为在许多情况下，前期的任务初始化实际上是你工作流程中最大的瓶颈。它可能需要几分钟，取决于小型基于
    CPU 的实例，而较大型基于 GPU 的实例可能需要 8 分钟或更长时间来初始化。
- en: On the upside, that wait time for GPU instances is ultimately saving you money
    and time because we’re running GPU health checks on the backend to ensure you
    get only good news. On the downside, 8 minutes is a long time to wait between
    development iterations. This is particularly painful if you’re updating something
    embarrassingly simple, such as a basic syntax error.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从积极的一面来看，GPU 实例的等待时间最终为你节省了时间和金钱，因为我们在后台运行 GPU 健康检查，确保你只接收到好消息。消极的一面是，8 分钟的等待时间对于开发迭代之间来说实在是太长了。如果你只是更新一些非常简单的内容，比如一个基础的语法错误，那就特别痛苦了。
- en: '![Figure 8.5 – Viewing your training jobs in the console](img/B18942_Figure_8.05.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – 在控制台查看你的训练任务](img/B18942_Figure_8.05.jpg)'
- en: Figure 8.5 – Viewing your training jobs in the console
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 在控制台查看你的训练任务
- en: 'Managed warm pools solve this problem for you as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 托管的热池通过以下方式为你解决了这个问题：
- en: First, add that hyperparameter to your job configuration.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，将该超参数添加到你的任务配置中。
- en: Next, once the job finishes training, either successfully or with an error,
    the warm pool status should show **Available**.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，一旦任务完成训练，无论是成功还是出错，热池状态应该显示为**可用**。
- en: Afterward, when you submit another job with a matching image URI, instance type,
    and instance count, this will show the **In Use** status and then ultimately **Reused**,
    as shown in *Figure 8**.5*.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此后，当你提交另一个具有匹配的镜像 URI、实例类型和实例数量的作业时，它将显示**正在使用**状态，最终显示**已重用**，如 *图 8.5* 所示。
- en: While saving a few minutes through using managed warm pools may not seem like
    a huge gain, it truly adds up a scale. When you’re working up against a deadline
    and every hour of the day counts, using warm pools may be the difference between
    hitting your deadline and not. It means that in a single hour, you can update
    your script easily hundreds of times, whereas before you may only have been able
    to do this up to about 10 times in an hour.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然通过使用托管的热池节省几分钟时间看起来可能不是一个巨大的收益，但它确实在大规模上积累起来。当你在与截止日期赛跑时，每一小时都至关重要，使用热池可能就是你是否能够按时完成任务的关键。它意味着在一个小时内，你可以轻松地更新你的脚本数百次，而以前你可能只能做到每小时大约更新
    10 次。
- en: SSM and SSH into training instances
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SSM 和 SSH 连接到训练实例
- en: Once your job is up and running successfully, especially a long-running job
    with lots of complex steps along the way, you can imagine how useful it would
    be to connect to the instance directly, view it, and run debug commands.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的作业成功启动并运行，尤其是一个长期运行并包含许多复杂步骤的作业，你可以想象直接连接到实例、查看它并运行调试命令是多么有用。
- en: Fortunately, we have a solution for that – a group of our very own ML SAs built
    out a custom design pattern that helps you enable this in your own environments
    *(1)*. They listened closely to customers, iterated on requirements, and developed
    a very nice project.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们有一个解决方案——我们的一组 ML SAs 构建了一个自定义设计模式，帮助你在自己的环境中启用这一功能 *(1)*。他们仔细听取了客户的意见，反复迭代需求，并开发了一个非常不错的项目。
- en: You can follow the steps in the following repository to install this in your
    own SageMaker resources, allowing you to easily connect to running jobs and analyze
    them in flight.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照以下代码库中的步骤，在自己的 SageMaker 资源中安装这个功能，轻松地连接到正在运行的作业并分析它们。
- en: '![Figure 8.6 – SSH in SageMaker training jobs](img/B18942_Figure_8.06.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 在 SageMaker 训练作业中的 SSH](img/B18942_Figure_8.06.jpg)'
- en: Figure 8.6 – SSH in SageMaker training jobs
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 在 SageMaker 训练作业中的 SSH
- en: From a systems architecture perspective, there are two key paths forward in
    evaluating this solution. On the one hand, you can use the fully-managed service,
    AWS Systems Manager. This is generally more secure than SSH but is a bit more
    limited in functionality. If all you need is to open up a terminal onto a remote
    instance, run some debug commands, and view the output in progress, this is probably
    the solution for you. Setting it up isn’t too hard; you just need to configure
    the IAM and SSM resources accordingly. When used in combination with warm pools,
    this is really powerful!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从系统架构的角度来看，在评估这个解决方案时，有两条关键路径。 一方面，你可以使用完全托管的服务 AWS Systems Manager。这通常比 SSH
    更安全，但功能上有些限制。如果你所需的只是打开一个终端，连接到远程实例，运行一些调试命令，并查看进度中的输出，这可能就是适合你的解决方案。设置起来并不难，你只需相应配置
    IAM 和 SSM 资源。与热池结合使用时，这非常强大！
- en: On the other hand, you can also use SSH directly. SSH is generally less secure
    than SSM. This is because SSM uses a managed AWS service, while SSH opens up the
    possibility that any malicious user could connect to the nodes using port forwarding.
    This means that in an enterprise environment, in many cases you’re better off
    starting with SSM. SSH will, however, let you update a local script and use port
    forwarding. This means if you want something to take your local script and send
    it to the remote training instance seamlessly, SSH is the way to go. However,
    given that you now have warm pools, it’s questionable whether you’d need this.
    The SSH solution is really nice if your IDE supports remote connection points,
    such as VS Code or PyCharm.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，你也可以直接使用 SSH。通常，SSH 的安全性低于 SSM，因为 SSM 使用的是托管的 AWS 服务，而 SSH 打开了一个可能性，即任何恶意用户都可以通过端口转发连接到节点。这意味着在企业环境中，在许多情况下，你最好从
    SSM 开始。然而，SSH 允许你更新本地脚本并使用端口转发。这意味着，如果你想让某个东西将你的本地脚本无缝地传输到远程训练实例，SSH 是最合适的选择。然而，考虑到现在有了热池，你可能不再需要这个。SSH
    解决方案非常适合你的 IDE 支持远程连接点的情况，比如 VS Code 或 PyCharm。
- en: Track jobs and experiments to replicate results
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪作业和实验以复制结果
- en: One of my personal favorite features of SageMaker training is, honestly, its
    most basic – storing everything about your job and keeping it searchable by default!
    That’s called the **metadata**. All the hyperparameters, input data locations,
    images, variables, and other information about your job are stored every time
    you submit them. This means you can easily track your jobs over time, logging
    in to view the CloudWatch logs, downloading the model from S3 whenever you need
    to, adding tags to specify other details, and so on.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人最喜欢的 SageMaker 训练功能，老实说，就是它最基本的功能——默认情况下，存储有关你的作业的所有信息并保持可搜索性！这就叫做**元数据**。每次提交时，所有的超参数、输入数据位置、图像、变量和其他作业信息都会被存储。这意味着你可以轻松地追踪你的作业，通过登录查看
    CloudWatch 日志，随时从 S3 下载模型，添加标签来指定其他细节，等等。
- en: '![Figure 8.7 – Viewing your training job metadata in the AWS console](img/B18942_Figure_8.07.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – 在 AWS 控制台查看训练作业的元数据](img/B18942_Figure_8.07.jpg)'
- en: Figure 8.7 – Viewing your training job metadata in the AWS console
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 在 AWS 控制台查看训练作业的元数据
- en: All of this data is in your account for the long haul, without your paying for
    any of it. You also use SageMaker Search to find jobs with the highest accuracy
    from a given S3 path, an instance type or count, a hyperparameter, or any available
    value. Just recently we’ve launched a few new features that make using SageMaker
    Training much easier. One of them is a hosted TensorBoard (https://aws.amazon.com/about-aws/whats-new/2023/04/amazon-sagemaker-hosted-tensorboard/)
    which lets you easily track and compare experiments. The second is a new @remote
    decorator that lets you transition local functions to remote jobs very easily!
    ([https://aws.amazon.com/blogs/machine-learning/run-your-local-machine-learning-code-as-amazon-sagemaker-training-jobs-with-minimal-code-changes/?sc_channel=sm&sc_campaign=Machine_Learning&sc_publisher=LINKEDIN&sc_geo=GLOBAL&sc_outcome=awareness&sc_content=ml_services&trk=machine_learning&linkId=211795861](https://aws.amazon.com/blogs/machine-learning/run-your-local-machine-learning-code-as-amazon-sagemaker-training-jobs-with-minimal-code-changes/?sc_channel=sm&sc_campaign=Machine_Learning&sc_publisher=LINKEDIN&sc_geo=GLOBAL&sc_outcome=awareness&sc_content=ml_services&trk=machine_learning&linkId=211795861))
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数据都长期保存在你的账户中，你无需为此付费。你还可以使用 SageMaker Search 查找来自指定 S3 路径、实例类型或数量、超参数或任何可用值的精度最高的作业。最近，我们发布了一些新的功能，使得使用
    SageMaker 训练变得更加轻松。其一是托管的 TensorBoard（[https://aws.amazon.com/about-aws/whats-new/2023/04/amazon-sagemaker-hosted-tensorboard/](https://aws.amazon.com/about-aws/whats-new/2023/04/amazon-sagemaker-hosted-tensorboard/)），它让你轻松跟踪和比较实验。其二是新的
    @remote 装饰器，它让你轻松地将本地函数转为远程作业！（[https://aws.amazon.com/blogs/machine-learning/run-your-local-machine-learning-code-as-amazon-sagemaker-training-jobs-with-minimal-code-changes/?sc_channel=sm&sc_campaign=Machine_Learning&sc_publisher=LINKEDIN&sc_geo=GLOBAL&sc_outcome=awareness&sc_content=ml_services&trk=machine_learning&linkId=211795861](https://aws.amazon.com/blogs/machine-learning/run-your-local-machine-learning-code-as-amazon-sagemaker-training-jobs-with-minimal-code-changes/?sc_channel=sm&sc_campaign=Machine_Learning&sc_publisher=LINKEDIN&sc_geo=GLOBAL&sc_outcome=awareness&sc_content=ml_services&trk=machine_learning&linkId=211795861))
- en: Now, let’s close out the chapter by learning about backend optimizations!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过学习后端优化来结束本章！
- en: Backend optimizations for distributed training with SageMaker
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 SageMaker 进行分布式训练的后端优化
- en: You’ve learned how to update your training scripts for SageMaker, and you’ve
    taken a closer look at some of the ways SageMaker is pretty fun and friendly to
    work with. Let’s finish by exploring ways that SageMaker optimizes the backend
    for large-scale distributed training.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学习了如何更新你的 SageMaker 训练脚本，并且你也更深入地了解了 SageMaker 在使用时一些有趣且友好的特性。现在，让我们通过探讨
    SageMaker 如何优化大规模分布式训练的后端来结束本章内容。
- en: As you have probably guessed, SageMaker can spin up anywhere from a few to a
    few thousand GPUs. This is due to the core service offering for training – the
    ability to turn on, orchestrate, and manage all of these GPUs on your behalf.
    You define this cluster when you define a training job, and as you learned earlier
    in this chapter, you use *mpi* to communicate between all of the nodes. You can
    store all of the hyperparameters and job metadata, stream all of your logs to
    CloudWatch, plug into your favorite operations tooling, ensure the nodes are healthy,
    connect to your data in S3, download and run your image, and so on. This *large-scale
    cluster orchestration* is completely elastic, easily flowing from one to hundreds
    of instances.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经猜到的那样，SageMaker 可以在任何地方启动从几个到几千个 GPU。这是因为训练的核心服务提供——在你定义训练作业时，打开、编排和管理所有这些
    GPU 的能力。你在定义这个集群时，以及你在本章早些时候学到的一样，使用 *mpi* 在所有节点之间进行通信。你可以存储所有的超参数和作业元数据，将所有的日志流式传输到
    CloudWatch，连接到你喜爱的操作工具，确保节点健康，连接到 S3 中的数据，下载并运行你的镜像，等等。这种 *大规模集群编排* 完全是弹性的，可以轻松地从一个实例流动到数百个实例。
- en: However, orchestrating this cluster is not especially useful, unless you have
    healthy GPUs. As you learned earlier in the book, writing software to successfully
    orchestrate all the tens of thousands of cores in a single GPU is no small task.
    Even when you have updated CUDA, drivers, and the latest deep learning frameworks,
    the bad news is that you may still get a bad GPU. Hardware fails, and GPU failures
    are incredibly common. As you scale up your training jobs to more GPUs, the odds
    of you getting a GPU failure even once in that massive pool of compute increases.
    This is why the *GPU health checks* that SageMaker brings to the table are incredibly
    useful! We can track down the latest GPU errors and have integrated checks for
    these in our job orchestrator. It means that when you get a node on SageMaker,
    it is much more likely to be healthy.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，编排这个集群并不特别有用，除非你的 GPU 健康状况良好。正如你在本书的早些部分所学到的，编写软件成功地编排单个 GPU 上数以万计的核心并不是一件小事。即使你更新了
    CUDA、驱动程序和最新的深度学习框架，坏消息是你仍然可能会遇到糟糕的 GPU。硬件故障，特别是 GPU 故障是非常常见的。随着你将训练作业扩展到更多的 GPU，你在这个庞大的计算池中遇到一次
    GPU 故障的概率也会增加。这就是为什么 SageMaker 提供的 *GPU 健康检查* 非常有用！我们可以追踪最新的 GPU 错误，并在我们的作业编排器中集成检查这些错误。这意味着当你在
    SageMaker 上获得一个节点时，它更有可能是健康的。
- en: Even with extensive GPU health checks and large-scale job orchestration, it
    is still possible that your job will error out even before it starts. You might
    get something like an *insufficient capacity error*, indicating that there are
    simply not enough of your requested instance type in your requested region. You
    could also get an *internal service error*, unsurprisingly telling you that something
    went wrong at your end. For these and other cases, it is extremely useful to have
    `max_retry_attempts` to your preference; personally, I just max it out at 30 every
    time I am running something with more than 8 instances.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 即使进行了广泛的 GPU 健康检查和大规模作业编排，你的作业在开始之前可能仍会出现错误。你可能会遇到类似 *容量不足错误* 的情况，这表明你请求的实例类型在请求的区域内数量不足。你也可能遇到
    *内部服务错误*，并不奇怪地告诉你在你这端出了问题。对于这些以及其他情况，设置 `max_retry_attempts` 非常有用；就我个人而言，每次运行超过
    8 个实例的作业时，我都会将其最大化设置为 30 次。
- en: While this is useful to get a job successfully started, I also have customers
    who *implement another job restart*. This might come into play when stepping through
    your mini-batches during your training loop. While the `bf16` data type has proven
    extremely useful to improve the stability of large-scale distributed GPU training,
    it is still not uncommon to see the loss of your model spontaneously spike, plateau,
    or drop. You might also see your total job throughput unexpectedly change. If
    any of these things happen, it’s wise to trigger an emergency checkpoint, kill
    the job, and then start again from that same checkpoint and step number. A combination
    of a few extra functions in your training script and a Lambda function listening
    via the `EventBridge` would be a natural way to do this. For a recent summary
    of some best practices, take a look at the blog post *(4)* in the *References*
    section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这对于成功启动作业非常有用，但我也有客户*实现了另一个作业重启*。这可能会在你通过训练循环的迷你批次时发生。当`bf16`数据类型被证明对大规模分布式GPU训练的稳定性有极大的改善作用时，仍然不罕见看到模型损失突然飙升、停滞或下降。你还可能看到总作业吞吐量的意外变化。如果发生这些情况，最好触发紧急检查点，终止作业，然后从相同的检查点和步骤号重新开始。将训练脚本中的一些附加功能与通过`EventBridge`监听的Lambda函数结合使用，是一种自然的做法。有关一些最佳实践的最新总结，请查看*参考文献*部分中的博客文章*(4)*。
- en: Distributed training libraries – a model and data parallel
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式训练库 – 模型和数据并行
- en: As you’ve learned previously, AWS has optimizations for distributed training.
    These are extremely effective methods to scale up to hundreds and thousands of
    GPUs on SageMaker. Let’s take one more look at them in detail.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你之前学到的，AWS针对分布式训练进行了优化。这些方法在SageMaker上有效地扩展到了数百甚至数千个GPU。让我们再详细看看它们。
- en: Remember that AlexNet only achieved groundbreaking results because it used multiple
    GPUs? Historically speaking, one of the earliest approaches to a multi-node deep
    learning process was called a **parameter server**. Parameter servers, as you
    can see in the following diagram, are a simple and effective way to orchestrate
    distributed gradient descent at scale. One node operates as the leader. It synchronizes
    gradients with the worker nodes, checking their health, and maintaining one globally
    consistent version of the model. Parameter servers can be somewhat slow, but they
    are actually more efficient in terms of the bandwidth they consume. Let’s explore
    this visually.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得AlexNet之所以取得突破性成果，是因为它使用了多个GPU吗？从历史上看，最早的多节点深度学习方法之一被称为**参数服务器**。如下面的图所示，参数服务器是一种简单而有效的方式，用于大规模地协调分布式梯度下降。一个节点作为主节点，负责与工作节点同步梯度，检查节点的健康状况，并维护一个全局一致的模型版本。参数服务器可能稍显缓慢，但在带宽消耗方面更为高效。让我们通过图示来进一步了解。
- en: '![Figure 8.7 – Historical approaches to distributed gradient descent](img/B18942_Figure_8.08.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图8.7 – 分布式梯度下降的历史方法](img/B18942_Figure_8.08.jpg)'
- en: Figure 8.7 – Historical approaches to distributed gradient descent
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 – 分布式梯度下降的历史方法
- en: This slowness, however, led to a slightly different approach. Ring-based topologies
    used the `AllReduce` algorithm under the hood to communicate between all nodes,
    collecting the average of the gradients and distributing the result to each of
    the nodes. This is the same basic approach common in Horovod and PyTorch DistributedDataParallel,
    popularized by their increase in speed over their older cousin.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种慢速性导致了稍微不同的方法。基于环的拓扑结构在底层使用`AllReduce`算法在所有节点之间进行通信，收集梯度的平均值，并将结果分发给每个节点。这是Horovod和PyTorch
    DistributedDataParallel中常见的基本方法，因其速度比旧版本更快而受到广泛使用。
- en: However, `AllReduce` as a basic collective does *not* perform well at scale.
    Every additional node increases the bandwidth consumed during the `AllReduce`
    step. This means that your scaling efficiency gets worse as you add more instances,
    ultimately leading to poor utilization of your instances and, thus, your compute
    budget.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`AllReduce`作为一种基本的集体操作，在大规模下*表现不佳*。每增加一个节点，`AllReduce`步骤所消耗的带宽就会增加。这意味着，随着实例数量的增加，你的扩展效率会变差，最终导致实例的利用率低下，从而影响计算预算。
- en: To counter this negative impact, AWS developed *custom collectives for data
    parallel*. These are the single best way to get the highest performance on the
    AWS Cloud. This was introduced as **SageMaker Distributed Data Parallel** (**SMDDP**)
    *(5)*, available as an SDK, in your container, and for any supported SageMaker
    job. Use SMDDP to ensure your large-scale GPU jobs are running as quickly and
    efficiently as possible, using them as the backend for any supported distributed
    software. SMDDP also integrates with Amazon’s Elastic Fabric Adapter, a low-jitter
    low-latency communication enhancement on AWS. Generally, SMDDP makes it easy for
    you to point to it from deep learning frameworks, setting it as your distributed
    backend.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这种负面影响，AWS 开发了 *自定义数据并行集合*。这是在 AWS 云上获得最高性能的最佳方式。这一技术被称为 **SageMaker 分布式数据并行**
    (**SMDDP**) *(5)*，作为 SDK 提供，可以在容器中使用，并适用于任何支持的 SageMaker 作业。使用 SMDDP 可以确保您的大规模
    GPU 作业运行尽可能快速和高效，将其作为任何支持的分布式软件的后端。SMDDP 还与亚马逊的弹性网络适配器（Elastic Fabric Adapter）集成，这是
    AWS 上的一项低抖动、低延迟通信增强功能。通常，SMDDP 使您可以轻松地将其从深度学习框架中指向，将其设置为分布式后端。
- en: Fortunately for you, as of the December 2022 release, this is now also available
    in the *model parallel* family. Now, you can set a `ddp` backend in the `smp_options`
    object, with `ddp_dist_backend:auto`. When this new backend option is combined
    with the *sharded data parallel* configuration we discussed in [*Chapter 5*](B18942_05.xhtml#_idTextAnchor085),
    this gives you another 30% boost!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，从 2022 年 12 月发布开始，这项功能现在也可以在 *模型并行* 系列中使用。现在，您可以在 `smp_options` 对象中设置 `ddp`
    后端，使用 `ddp_dist_backend:auto`。当这个新的后端选项与我们在 [*第 5 章*](B18942_05.xhtml#_idTextAnchor085)
    中讨论的 *分片数据并行* 配置结合使用时，它将带来额外的 30% 提升！
- en: Now, let’s close out the chapter with a quick recap.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过简短的回顾来结束本章。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the key features of Amazon SageMaker for large-scale
    distributed training. We looked at how to optimize your script, from importing
    packages to parsing arguments, writing code, invoking your script with `mpi`,
    writing to CloudWatch logs, checkpointing, working with the SM estimator, and
    so on. We covered key usability features to make SageMaker more fun and friendly
    to work with, such as warm pools for rapid experimentation, SSM and SSH in training
    instances, and tracking jobs. Finally, we learned about backend optimizations
    for distributed training, such as SMDDP collectives, using it both standalone
    and in combination with the model parallel package.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们了解了 Amazon SageMaker 在大规模分布式训练中的关键功能。我们探讨了如何优化脚本，从导入包到解析参数、编写代码、使用 `mpi`
    调用脚本、写入 CloudWatch 日志、检查点、与 SM 估算器一起使用等。我们涵盖了提高 SageMaker 可用性的关键功能，以使其更有趣且更易于使用，例如用于快速实验的热池、训练实例中的
    SSM 和 SSH 以及作业追踪。最后，我们了解了分布式训练的后端优化，如 SMDDP 集合，既可以单独使用，也可以与模型并行包结合使用。
- en: In the next chapter, we’ll explore even more advanced topics in distributed
    training!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将探索分布式训练中的更高级主题！
- en: References
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Please go through the following content for more information on a few topics
    covered in the chapter:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下内容，了解本章涵盖的一些主题：
- en: '*aws-sample/sagemaker-ssh-helper*: [https://github.com/aws-samples/sagemaker-ssh-helper](https://github.com/aws-samples/sagemaker-ssh-helper)'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*aws-sample/sagemaker-ssh-helper*: [https://github.com/aws-samples/sagemaker-ssh-helper](https://github.com/aws-samples/sagemaker-ssh-helper)'
- en: '*Use TensorBoard in Amazon SageMaker* *Studio*:[https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html)'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在 Amazon SageMaker* *Studio* 中使用 TensorBoard：[https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html)'
- en: '*aws/amazon-sagemaker-examples*: [https://github.com/aws/amazon-sagemaker-examples/blob/main/training/distributed_training/pytorch/model_parallel/gpt2/train_gpt_simple.py](https://github.com/aws/amazon-sagemaker-examples/blob/main/training/distributed_training/pytorch/model_parallel/gpt2/train_gpt_simple.py)'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*aws/amazon-sagemaker-examples*: [https://github.com/aws/amazon-sagemaker-examples/blob/main/training/distributed_training/pytorch/model_parallel/gpt2/train_gpt_simple.py](https://github.com/aws/amazon-sagemaker-examples/blob/main/training/distributed_training/pytorch/model_parallel/gpt2/train_gpt_simple.py)'
- en: '*Training large language models on Amazon SageMaker: Best* *practices*: [https://aws.amazon.com/blogs/machine-learning/training-large-language-models-on-amazon-sagemaker-best-practices/](https://aws.amazon.com/blogs/machine-learning/training-large-language-models-on-amazon-sagemaker-best-practices/)'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在 Amazon SageMaker 上训练大型语言模型：最佳* *实践*：[https://aws.amazon.com/blogs/machine-learning/training-large-language-models-on-amazon-sagemaker-best-practices/](https://aws.amazon.com/blogs/machine-learning/training-large-language-models-on-amazon-sagemaker-best-practices/)'
- en: '*Introduction to SageMaker’s Distributed Data Parallel* *Library*: [https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-intro.html](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-intro.html)'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*SageMaker 分布式数据并行* *库简介*：[https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-intro.html](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-intro.html)'
