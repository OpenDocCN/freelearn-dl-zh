- en: Introduction to Magenta and Generative Art
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Magenta 和生成艺术简介
- en: In this chapter, you'll learn the basics of generative music and what already
    exists. You'll learn about the new techniques of artwork generation, such as machine
    learning, and how those techniques can be applied to produce music and art. Google's
    Magenta open source research platform will be introduced, along with Google's
    open source machine learning platform TensorFlow, along with an overview of its
    different parts and the installation of the required software for this book. We'll
    finish the installation by generating a simple MIDI file on the command line.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习生成音乐的基础知识以及现有的相关技术。您将了解生成艺术的新技术，例如机器学习，以及如何将这些技术应用于音乐和艺术创作。我们将介绍 Google
    的 Magenta 开源研究平台，Google 的开源机器学习平台 TensorFlow，并概述其不同的部分，以及为本书安装所需的软件。最后，我们将通过命令行生成一个简单的
    MIDI 文件来完成安装。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Overview of generative artwork
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成艺术概述
- en: New techniques with machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的新技术
- en: Magenta and TensorFlow in music generation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magenta 和 TensorFlow 在音乐生成中的应用
- en: Installing Magenta
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Magenta
- en: Installing the music software and synthesizers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装音乐软件和合成器
- en: Installing the code editing software
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装代码编辑软件
- en: Generating a basic MIDI file
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成基本的 MIDI 文件
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we''ll use the following tools:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下工具：
- en: '**Python**, **Conda**, and **pip**, to install and execute the Magenta environment'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python**、**Conda** 和 **pip**，用于安装和执行 Magenta 环境'
- en: '**Magenta**, to test our setup by performing music generation'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Magenta**，通过执行音乐生成来测试我们的设置'
- en: '**Magenta GPU** (**optional**), CUDA drivers, and cuDNN drivers, to make Magenta
    run on the GPU'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Magenta GPU**（**可选**）、CUDA 驱动程序和 cuDNN 驱动程序，使 Magenta 在 GPU 上运行'
- en: '**FluidSynth**, to listen to the generated music sample using a software synthesizer'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FluidSynth**，通过软件合成器收听生成的音乐样本'
- en: Other optional software we might use throughout this book, such as **Audacity**
    for audio editing, **MuseScore** for sheet music editing, and **Jupyter Notebook**
    for code editing.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书中可能会使用的其他可选软件，例如用于音频编辑的 **Audacity**，用于乐谱编辑的 **MuseScore**，以及用于代码编辑的 **Jupyter
    Notebook**。
- en: 'It is recommended that you follow this book''s source code when you read the
    chapters in this book. The source code also provides useful scripts and tips.
    Follow these steps to check out the code in your user directory (you can use another
    location if you want):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈建议在阅读本书章节时，遵循书中的源代码。源代码还提供了有用的脚本和技巧。按照以下步骤，在您的用户目录中查看代码（如果您愿意，也可以选择其他位置）：
- en: First, you need to install Git, which can be installed on any platform by downloading
    and executing the installer at [git-scm.com/downloads](https://git-scm.com/downloads).
    Then, follow the prompts and make sure you add the program to your PATH so that
    it is available on the command line.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，您需要安装 Git，可以通过下载并执行 [git-scm.com/downloads](https://git-scm.com/downloads)
    上的安装程序，在任何平台上安装。然后，按照提示操作，确保将该程序添加到您的 PATH 中，以便在命令行上使用。
- en: 'Then, clone the source code repository by opening a new Terminal and executing
    the following command:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，打开新的终端并执行以下命令，克隆源代码库：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Each chapter has its own folder; `Chapter01`, `Chapter02`, and so on. For example,
    the code for this chapter is located at [https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter01](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter01).
    The examples and code snippets will be located in this chapter's folder. For this
    chapter, you should open `cd Chapter01` before you start.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每个章节都有自己的文件夹；`Chapter01`、`Chapter02` 等。例如，本章的代码位于 [https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter01](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter01)。示例和代码片段将位于本章的文件夹中。在开始之前，您应该打开
    `cd Chapter01`。
- en: We won't be using a lot of Git commands except `git clone`, which duplicates
    a code repository to your machine, but if you are unfamiliar with Git and want
    to learn more, a good place to start is the excellent Git Book ([git-scm.com/book/en/v2](https://git-scm.com/book/en/v2)),
    which is available in multiple languages.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会使用很多 Git 命令，除了 `git clone`，该命令将代码库复制到您的机器上，但如果您不熟悉 Git 并想学习更多内容，一个很好的起点是优秀的
    Git 书籍 ([git-scm.com/book/en/v2](https://git-scm.com/book/en/v2))，它支持多种语言。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，观看代码实践：
- en: '[http://bit.ly/2O847tW](http://bit.ly/2O847tW)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2O847tW](http://bit.ly/2O847tW)'
- en: Overview of generative art
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成艺术概览
- en: The term **generative art** has been coined with the advent of the computer,
    and since the very beginning of computer science, artists and scientists used
    technology as a tool to produce art. Interestingly, generative art predates computers,
    because generative systems can be derived by hand.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成艺术**一词是在计算机出现后被创造的，早期的计算机科学中，艺术家和科学家们使用技术作为工具来创作艺术。有趣的是，生成艺术早于计算机的出现，因为生成系统本来可以手工制作。'
- en: In this section, we'll provide an overview of generative music by showing you
    interesting examples from art history going back to the 18th century. This will
    help you understand the different types of generative music by looking at specific
    examples and prepare the groundwork for later chapters.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过展示一些来自艺术史的有趣例子，概述生成音乐，例子可以追溯到18世纪。这将帮助你通过具体的示例了解不同类型的生成音乐，并为后续章节的学习奠定基础。
- en: Pen and paper generative music
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 钢笔和纸上的生成音乐
- en: There's a lot of examples of generative art in the history of mankind. A popular
    example dates back to the 18th century, where a game called Musikalisches Würfelspiel
    (German for *musical dice game*) grew popular in Europe. The concept of the game
    was attributed to Mozart by Nikolaus Simrock in 1792, though it was never confirmed
    to be his creation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 人类历史上有很多生成艺术的例子。一个流行的例子可以追溯到18世纪，当时一款名为Musikalisches Würfelspiel（德语为*音乐骰子游戏*）的游戏在欧洲广受欢迎。该游戏的概念由尼古劳斯·辛梅罗克于1792年归功于莫扎特，尽管没有证实这确实是他的创作。
- en: The players of the game throw a dice and from the result, select one of the
    predefined 272 musical measures from it. Throwing the dice over and over again
    allows the players to compose a full minute (the musical genre that is generated
    by the game) that respects the rules of the genre because it was composed in such
    a way that the possible arrangements sound pretty.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏的玩家掷骰子，并从结果中选择一个预定义的272个音乐乐句中的一个。通过反复掷骰，玩家可以创作出一整分钟（该游戏生成的音乐类型），并且遵循该音乐类型的规则，因为它是通过这样的方式创作的，生成的音乐编排听起来非常和谐。
- en: 'In the following table and the image that follows, a small part of a musical
    dice game can be seen. In the table, the y-axis represents the dice throw outcome
    while the x-axis represents the measure of the score you are currently generating.
    The players will throw two dices 16 times:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的表格和随后的图片中，可以看到一个音乐骰子游戏的小部分。在表格中，y轴代表骰子投掷结果，而x轴代表你当前生成的乐句。玩家将掷两颗骰子16次：
- en: On the first throw of two dices, we read the first column. A total of two will
    output the measure 96 (first row), a total of two will output the measure 32 (second
    row), and so on.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两颗骰子的第一次掷骰中，我们读取第一列。两个骰子的总和为二时，输出的是第96号乐句（第一行），两个骰子的总和为二时，输出的是第32号乐句（第二行），以此类推。
- en: On the second throw of two dices, we read the second column. A total of two
    will output the measure 22 (first row), a total of three will output the measure
    6 (second row), and so on.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两颗骰子的第二次掷骰中，我们读取第二列。两个骰子的总和为二时，输出的是第22号乐句（第一行），总和为三时，输出的是第6号乐句（第二行），以此类推。
- en: 'After 16 throws, the game will have output 16 measures for the index:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 经过16次投掷后，游戏将为该指标输出16个乐句：
- en: '|  | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |'
- en: '| 2 | 96 | 22 | 141 | 41 | 105 | 122 | 11 | 30 | 70 | 121 | 26 | 9 | 112 |
    49 | 109 | 14 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 96 | 22 | 141 | 41 | 105 | 122 | 11 | 30 | 70 | 121 | 26 | 9 | 112 |
    49 | 109 | 14 |'
- en: '| 3 | 32 | 6 | 128 | 63 | 146 | 46 | 134 | 81 | 117 | 39 | 126 | 56 | 174 |
    18 | 116 | 83 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 32 | 6 | 128 | 63 | 146 | 46 | 134 | 81 | 117 | 39 | 126 | 56 | 174 |
    18 | 116 | 83 |'
- en: '| 4 | 69 | 95 | 158 | 13 | 153 | 55 | 110 | 24 | 66 | 139 | 15 | 132 | 73 |
    58 | 145 | 79 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 69 | 95 | 158 | 13 | 153 | 55 | 110 | 24 | 66 | 139 | 15 | 132 | 73 |
    58 | 145 | 79 |'
- en: '| 5 | 40 | 17 | 113 | 85 | 161 | 2 | 159 | 100 | 90 | 176 | 7 | 34 | 67 | 160
    | 52 | 170 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 40 | 17 | 113 | 85 | 161 | 2 | 159 | 100 | 90 | 176 | 7 | 34 | 67 | 160
    | 52 | 170 |'
- en: '| 6 | 148 | 74 | 163 | 45 | 80 | 97 | 36 | 107 | 25 | 143 | 64 | 125 | 76 |
    136 | 1 | 93 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 148 | 74 | 163 | 45 | 80 | 97 | 36 | 107 | 25 | 143 | 64 | 125 | 76 |
    136 | 1 | 93 |'
- en: '| 7 | 104 | 157 | 27 | 167 | 154 | 68 | 118 | 91 | 138 | 71 | 150 | 29 | 101
    | 162 | 23 | 151 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 104 | 157 | 27 | 167 | 154 | 68 | 118 | 91 | 138 | 71 | 150 | 29 | 101
    | 162 | 23 | 151 |'
- en: '| 8 | 152 | 60 | 171 | 53 | 99 | 133 | 21 | 127 | 16 | 155 | 57 | 175 | 43
    | 168 | 89 | 172 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 152 | 60 | 171 | 53 | 99 | 133 | 21 | 127 | 16 | 155 | 57 | 175 | 43
    | 168 | 89 | 172 |'
- en: '| 9 | 119 | 84 | 114 | 50 | 140 | 86 | 169 | 94 | 120 | 88 | 48 | 166 | 51
    | 115 | 72 | 111 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 119 | 84 | 114 | 50 | 140 | 86 | 169 | 94 | 120 | 88 | 48 | 166 | 51
    | 115 | 72 | 111 |'
- en: '| 10 | 98 | 142 | 42 | 156 | 75 | 129 | 62 | 123 | 65 | 77 | 19 | 82 | 137
    | 38 | 149 | 8 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 98 | 142 | 42 | 156 | 75 | 129 | 62 | 123 | 65 | 77 | 19 | 82 | 137
    | 38 | 149 | 8 |'
- en: '| 11 | 3 | 87 | 165 | 61 | 135 | 47 | 147 | 33 | 102 | 4 | 31 | 164 | 144 |
    59 | 173 | 78 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 3 | 87 | 165 | 61 | 135 | 47 | 147 | 33 | 102 | 4 | 31 | 164 | 144 |
    59 | 173 | 78 |'
- en: '| 12 | 54 | 130 | 10 | 103 | 28 | 37 | 106 | 5 | 35 | 20 | 108 | 92 | 12 |
    124 | 44 | 131 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 54 | 130 | 10 | 103 | 28 | 37 | 106 | 5 | 35 | 20 | 108 | 92 | 12 |
    124 | 44 | 131 |'
- en: The preceding table shows a small part of the whole score, with each measure
    annotated with an index. For each of the generated 16 indexes, we take the corresponding
    measure in order, which constitutes our minuet (the minuet is the style that's
    generated by this game – basically, it's a music score with specific rules).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 上表显示了整个乐谱的一小部分，每一小节都有索引标注。对于每一个生成的16个索引，我们按顺序选取相应的小节，这就构成了我们的华尔兹舞曲（华尔兹是这个游戏生成的风格——基本上，它是一首遵循特定规则的音乐乐谱）。
- en: 'There are different types of generative properties:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成属性有不同的类型：
- en: '**Chance or randomness**, which the dice game is a good example of, where the
    outcome of the generated art is partially or totally defined by chance. Interestingly,
    adding randomness to a process in art is often seen as *humanizing* the process,
    since an underlying rigid algorithm might generate something that sounds *artificial*.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偶然性或随机性**，例如骰子游戏就是一个很好的例子，其中生成的艺术结果部分或完全由偶然性定义。有趣的是，向艺术过程中添加随机性通常被认为是*人性化*这一过程，因为一个底层的刚性算法可能会生成一些听起来*人造*的东西。'
- en: '**Algorithmic generation** (or rule-based generation), where the rules of the
    generation will define its outcome. Good examples of such generation include a
    cellular automaton, such as the popular Conway''s Game of Life, a game where a
    grid of cells changes each iteration according to predefined rules: each cell
    might be on or off, and the neighboring cells are updated as a function of the
    grid''s state and rules. The result of such generation is purely deterministic;
    it has no randomness or probability involved.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法生成**（或基于规则的生成），在这种情况下，生成的规则将定义其结果。这种生成的典型例子包括像著名的康威生命游戏这样的细胞自动机，这是一种每次迭代时，网格中的细胞根据预定规则变化的游戏：每个细胞可能是开或关，邻近的细胞根据网格的状态和规则进行更新。这种生成的结果是完全确定的；其中不涉及随机性或概率。'
- en: '**Stochastic-based generation**, where sequences are derived from the probability
    of elements. Examples of this include Markov chains, a stochastic model in which
    for each element of a sequence, the resulting probability of the said event is
    defined only on the present state of the system. Another good example of stochastic-based
    generation is machine learning generation, which we''ll be looking at throughout
    this book.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于随机过程的生成**，其中序列由元素的概率派生。一个例子是马尔科夫链，这是一种随机模型，其中序列的每个元素的结果概率仅由当前系统状态定义。另一个很好的基于随机过程的生成例子是机器学习生成，这将在本书中多次涉及。'
- en: 'We will use a simple definition of generative art for this book:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将采用生成艺术的简单定义：
- en: <q>"Generative art is an artwork partially or completely created by an autonomous
    system"</q>.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: <q>“生成艺术是一种部分或完全由自主系统创作的艺术作品”</q>。
- en: By now, you should understand that we don't actually need a computer to generate
    art since the rules of a system can be derived by hand. But using a computer makes
    it possible to define complex rules and handle tons of data, as we'll see in the
    following chapters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该明白我们实际上并不需要计算机来生成艺术，因为一个系统的规则可以手工推导出来。但使用计算机使得定义复杂的规则并处理大量数据成为可能，正如我们在接下来的章节中将看到的。
- en: Computerized generative music
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机生成的音乐
- en: The first instance of generative art by computer dates back to 1957, where Markov
    chains were used to generate a score on an electronic computer, the ILLIAC I,
    by composers Lejaren Hiller and Leonard Issacson. Their paper, *Musical Composition
    with a High-Speed Digital Computer*, describes the techniques that were used in
    composing the music. The composition, titled *Illac Suite*, consists of four movements,
    each exploring a particular technique of music generation, from a rule-based generation
    of *cantus firmi* to stochastic generation with Markov chain.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机生成艺术的首次实例可以追溯到1957年，当时使用马尔科夫链在电子计算机ILLIAC I上生成了一个乐谱，由作曲家Lejaren Hiller和Leonard
    Issacson创作。他们的论文《使用高速数字计算机的音乐创作》描述了用于创作音乐的技术。这部名为《Illac Suite》的作品由四个乐章组成，每个乐章都探索了一种特定的音乐生成技巧，从基于规则的*cantus
    firmus*生成到使用马尔科夫链的随机生成。
- en: Many famous examples of generative composition have followed since, such as
    Xenakis's *Atrées* in 1962, which explored the idea of stochastic composition;
    Ebcioglo's composition software named CHORAL, which contained handcrafted rules;
    and David Cope's software called EMI, which extended the concept to be able to
    learn from a corpus of scores.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随后出现了许多著名的生成作曲实例，例如1962年泽纳基斯的*Atrées*，它探索了随机作曲的理念；埃布齐奥格罗（Ebcioglo）的作曲软件CHORAL，内含手工编写的规则；以及大卫·科普（David
    Cope）的EMI软件，它扩展了这一概念，能够从大量乐谱中学习。
- en: As of today, generative music is everywhere. A lot of tools allow musicians
    to compose original music based on the generative techniques we described previously.
    A whole genre and musical community, called **algorave**, originated from those
    techniques. Stemming from the underground electronic music scene, musicians use
    generative algorithms and software to produce live dance music on stage, hence
    the name of the genre. Software such as *TidalCycles* and *Orca* allow the musician
    to define rules on the fly and let the system generate the music autonomously.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 截至今天，生成音乐无处不在。许多工具允许音乐家基于我们之前描述的生成技术创作原创音乐。一个名为**算法派对**（algorave）的全新音乐流派和音乐社区就是由这些技术衍生出来的。源于地下电子音乐场景，音乐家们使用生成算法和软件在舞台上实时创作舞曲，因此这个流派被命名为“算法派对”。如*TidalCycles*和*Orca*等软件允许音乐家即时定义规则，让系统自主生成音乐。
- en: Looking back on those techniques, stochastic models such as Markov chains have
    been widely used in generative music. It stems from the fact that they are conceptually
    simple and easy to represent since the model is a transition probability table
    and can learn from a few examples. The problem with Markov models is that representing
    a long-term temporal structure is hard since most models will only consider *n*
    previous states, where *n* is small, to define the resulting probability. Let's
    take a look at what other types of models can be used to generate music.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾这些技术，随机模型（如马尔可夫链）已被广泛应用于生成音乐。这是因为它们在概念上简单，容易表示，因为该模型是一个转移概率表，并且可以从少量实例中学习。马尔可夫模型的问题在于表示长期时间结构非常困难，因为大多数模型只会考虑*前n*个状态，其中*n*是一个较小的数字，用以定义结果的概率。让我们看看有哪些其他类型的模型可以用来生成音乐。
- en: In a 2012 paper titled *Ten Questions Concerning Generative Computer Art*, the
    author talks about the possibility of machine creation, the formalization of human
    aesthetics, and randomness. More importantly, it defines the limitations of such
    systems. What can a generative system produce? Can machines only do what they
    are instructed to?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在2012年的一篇题为*关于生成计算机艺术的十个问题*的论文中，作者讨论了机器创作的可能性、人类美学的形式化以及随机性。更重要的是，它定义了此类系统的局限性。生成系统能够产生什么？机器只能做它们被指示去做的事吗？
- en: New techniques with machine learning
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的新技术
- en: Machine learning is important for computer science because it allows complex
    functions to be modeled without them being explicitly written. Those models are
    automatically learned from examples, instead of being manually defined. This has
    a huge implication for arts in general since explicitly writing the rules of a
    painting or a musical score is inherently difficult.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习对于计算机科学至关重要，因为它可以在无需明确编写的情况下对复杂功能进行建模。这些模型是通过从实例中自动学习得到的，而不是手动定义的。这对艺术领域有着巨大的意义，因为明确编写绘画或音乐乐谱的规则本身就非常困难。
- en: In recent years, the advent of deep learning has propelled machine learning
    to new heights in terms of efficiency. Deep learning is especially important for
    our use case of music generation since using deep learning techniques doesn't
    require a preprocessing step of *feature extraction*, which is necessary for classical
    machine learning and hard to do on raw data such as image, text, and – you guessed
    it – audio. In other words, traditional machine learning algorithms do not work
    well for music generation. Therefore, all the networks in this book will be deep
    neural networks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习的出现将机器学习推向了新的高度，尤其在效率方面。深度学习对于我们音乐生成的应用尤为重要，因为使用深度学习技术不需要像传统机器学习那样进行*特征提取*的预处理步骤，而特征提取在处理图像、文本以及——你猜到了——音频等原始数据时非常困难。换句话说，传统的机器学习算法在音乐生成中并不适用。因此，本书中所有的网络都会是深度神经网络。
- en: In this section, we'll learn what advances in deep learning allow for music
    generation and introduce the concepts we'll be using throughout this book. We'll
    also look at the different types of musical representations for those algorithms,
    which is important as it will serve as the groundwork for this book for data in
    general.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习深度学习的进展如何推动音乐生成，并介绍本书中将要使用的概念。我们还将探讨这些算法的不同类型的音乐表示方法，这一点很重要，因为它将为本书中的数据处理提供基础。
- en: Advances in deep learning
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的进展
- en: We all know that deep learning has recently become a fast-growing domain in
    computer science. Not so long ago, no deep learning algorithms could outperform
    standard techniques. That was before 2012 when, for the first time, a deep learning
    algorithm, AlexNet, did better in an image classification competition by using
    a deep neural network trained on GPUs (see the *Further reading* section for the
    AlexNet paper, one of the most influential papers that was published in computer
    vision). Neural network techniques are more than 30 years old, but the recent
    reemergence can be explained by the availability of massive data, efficient computing
    power, and technical advances.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道，深度学习最近已经成为计算机科学中一个快速发展的领域。就在不久前，没有任何深度学习算法能够超越传统技术。那是在2012年之前，当时第一次有一个深度学习算法——AlexNet，通过使用在GPU上训练的深度神经网络，在图像分类比赛中表现得更好（有关AlexNet论文的详细信息，请参见*进一步阅读*部分，它是计算机视觉领域最具影响力的论文之一）。神经网络技术已经有超过30年的历史，但其近期的复兴可以通过大数据的可用性、高效的计算能力以及技术进步来解释。
- en: Most importantly, a deep learning technique is *general*, in the sense that,
    as opposed to the music generation techniques we've specified previously, a machine
    learning system is agnostic and can learn from an arbitrary corpus of music. The
    same system can be used in multiple musical genres, as we'll see during this book
    when we train an existing model on jazz music in [Chapter 6](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml),
    *Data Preparation for Training*.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，深度学习技术是*通用的*，即与我们之前指定的音乐生成技术不同，机器学习系统是与音乐类型无关的，可以从任意的音乐语料库中学习。我们将在本书中看到同一系统可以用于多种音乐风格，例如在[第6章](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml)中，我们会训练一个现有模型来处理爵士乐，*训练数据准备*。
- en: 'Many techniques in deep learning were discovered a long time ago but only find
    meaningful usage today. Of the technical advances in the field that concern music
    generation, those are present in Magenta and will be explained later in this book:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中的许多技术早在很久以前就被发现了，但直到今天才找到了有意义的应用。在与音乐生成相关的技术进展方面，这些技术在Magenta中得到了应用，并将在本书后面进行解释：
- en: '**Recurrent Neural Networks** (**RNNs**) are interesting for music generation
    because they allow us to operate over sequences of vectors for the input and output.
    When using classic neural networks or convolutional networks (which are used in
    image classification), you are limited to a fixed size input vector to produce
    a fixed size output vector, which would be very limiting for music processing,
    but works well for certain types of image processing. The other advantage of RNN
    is the possibility of producing a new state vector at each pass by combining a
    function with the previous state vector, which a powerful mean of describing complex
    behavior and long-term state. We''ll be talking about RNNs in [Chapter 2](b60deee5-c58f-45eb-88a2-23718802e580.xhtml),
    *Generating Drum Sequences with Drums RNN*.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**递归神经网络**（**RNNs**）在音乐生成中非常有趣，因为它们允许我们对输入和输出的向量序列进行操作。当使用经典神经网络或卷积网络（这些网络用于图像分类）时，你只能使用固定大小的输入向量来产生固定大小的输出向量，这对于音乐处理来说非常有限，但在某些类型的图像处理上效果良好。RNN的另一个优势是每次迭代时可以通过将一个函数与前一个状态向量结合来生成新的状态向量，这是一种描述复杂行为和长期状态的强大手段。在[第2章](b60deee5-c58f-45eb-88a2-23718802e580.xhtml)中，我们将讨论RNNs，*用Drums
    RNN生成鼓点序列*。'
- en: '**Long Sho****rt-Term Memory** (**LSTM**) is an RNN with slightly different
    properties. It solves the problem of vanishing gradients that is present in RNNs
    and makes it impossible for the network to learn long-term dependencies, even
    if it theoretically could. The approach of using LSTM in music generation has
    been presented by Douglas Eck and Jurgen Schmidhuber in 2002 in a paper called
    *Finding temporal structure in music: Blues improvisation with LSTM recurrent
    networks*. We''ll be talking about LSTM in [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml),
    *Generating Polyphonic Melodies*.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长短期记忆**（**LSTM**）是一个具有稍微不同特性的RNN。它解决了RNN中存在的梯度消失问题，这使得网络即使在理论上可以学习长期依赖关系，也无法做到。Douglas
    Eck 和 Jurgen Schmidhuber 于2002年在一篇名为《在音乐中寻找时间结构：基于LSTM递归网络的蓝调即兴演奏》的论文中提出了LSTM在音乐生成中的应用。我们将在[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)《生成复调旋律》中讨论LSTM。'
- en: '**Variational autoencoders** (**VAEs**) are analogous to classical autoencoders,
    in the sense that their architecture is similar, consisting of an encoder (for
    the input to a hidden layer), a decoder (for a hidden layer to the output), and
    a loss function, with the model learning to reconstruct the original input with
    specific constraints. The usage of VAE in generative models is recent but has
    shown interesting results. We''ll be talking about VAE in [Chapter 4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml),
    *Latent Space Interpolation with Music VAE*.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变分自编码器**（**VAE**）类似于经典的自编码器，其架构相似，包含编码器（将输入转换为隐藏层）、解码器（将隐藏层转换为输出）以及损失函数，模型通过特定的约束学习重建原始输入。VAE
    在生成模型中的应用较为新颖，但已显示出有趣的结果。我们将在[第4章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)《基于音乐VAE的潜在空间插值》中讨论
    VAE。'
- en: '**Generative adversarial networks** (**GANs**) are a class of machine learning
    systems where two neural networks compete with each other in a game: a generative
    network generates candidates while a discriminating network evaluates them. We''ll
    be talking about GANs in [Chapter 5](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml),
    *Audio Generation with NSynth and GANSynth*.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成对抗网络**（**GANs**）是一类机器学习系统，其中两个神经网络相互竞争：一个生成网络生成候选项，而一个判别网络对其进行评估。我们将在[第5章](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml)《使用NSynth和GANSynth进行音频生成》中讨论GAN。'
- en: 'Recent deep learning advances have profoundly changed not only music generation
    but also genre classification, audio transcription, note detection, composition,
    and more. We won''t be talking about these subjects here, but they all share common
    ground: musical representation.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的深度学习进展不仅深刻改变了音乐生成，还影响了音乐风格分类、音频转录、音符检测、作曲等领域。我们在这里不会讨论这些主题，但它们都有一个共同点：音乐表示。
- en: Representation in music processes
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 音乐处理过程中的表示方式
- en: 'These systems can work with different representations:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统可以使用不同的表示方式：
- en: '**Symbolic representation**, such as the **MIDI** (**Musical Instrument Digital
    Interface** (**MIDI**), describes the music using a notation containing the musical
    notes and timing, but not the sound or timbre of the actual sound. In general,
    sheet music is a good example of this. A symbolic representation of music has
    no sound by itself; it has to be played by instruments.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**符号表示**，例如**MIDI**（**音乐仪器数字接口**（**MIDI**）），通过包含音乐音符和节奏的符号描述音乐，但不涉及实际声音的音质或音色。一般来说，乐谱是这一表示方式的典型例子。音乐的符号表示本身没有声音；它必须通过乐器演奏出来。'
- en: '**Sub-symbolic representation**, such as a raw audio waveform or a spectrogram,
    describes the actual sound of the music.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子符号表示**，例如原始音频波形或频谱图，描述了音乐的实际声音。'
- en: Different processes will require a different representation. For example, most
    speech recognition and synthesis models work with spectrograms, while most of
    the examples we will see in this book uses MIDI to generate music scores. Processes
    that integrate both representations are rare, but an example of this could be
    a score transcription that takes an audio file and translate it into MIDI or other
    symbolic representations.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的处理过程需要不同的表示方式。例如，大多数语音识别和合成模型使用频谱图，而本书中大部分示例使用 MIDI 来生成音乐乐谱。集成这两种表示方式的过程比较少见，但一个例子可能是乐谱转录，它将音频文件转换为MIDI或其他符号表示。
- en: Representing music with MIDI
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MIDI表示音乐
- en: There are other symbolic representations than MIDI, such as MusicXML and AbcNotation,
    but MIDI is by far the most common representation. The MIDI specification also
    doubles down as a protocol since it is used to carry note messages that can be
    used in real-time performance as well as control messages.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他符号化表示法，如MusicXML和AbcNotation，但MIDI无疑是最常见的表示方式。MIDI规范本身也充当了一种协议，因为它被用来传输音符消息，这些消息可以用于实时演奏，也可以用于控制消息。
- en: 'Let''s consider some parts of a MIDI message that will be useful for this book:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一下在本书中会用到的一些MIDI消息的部分：
- en: '**Channel [0-15]**: This indicates the track that the message is sent on'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通道 [0-15]**：这表示消息发送的轨道'
- en: '**Note number [0-127]**: This indicates the pitch of the note'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音符编号 [0-127]**：这表示音符的音高'
- en: '**Velocity [0-127]**: This indicates the volume of the note'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度 [0-127]**：这表示音符的音量'
- en: 'To represent a musical note in MIDI, you have to send two different message
    types with proper timing: a `Note On` event, followed by a `Note Off` event. This
    implicitly defines the **length** of the note, which is not present in the MIDI
    message. This is important because MIDI was defined with live performance in mind,
    so using two messages – one for a keypress and another for a key release – makes
    sense.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要在MIDI中表示一个音乐音符，你必须发送两种不同的消息类型，并且确保适当的时间顺序：一个`Note On`事件，紧接着一个`Note Off`事件。这隐含了**音符的时长**，但MIDI消息中并未包含此信息。之所以如此重要，是因为MIDI最初是为了实时演奏定义的，所以使用两条消息——一条用于按键，另一条用于释放按键——是合理的。
- en: From a data perspective, we'll need either need to convert MIDI notes into a
    format that has the note length encoded in it or keep a note on and note off approach,
    depending on what we're trying to do. For each model in Magenta, we'll see how
    the MIDI notes are encoded.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据角度来看，我们要么需要将MIDI音符转换为一种编码了音符时长的格式，要么保持按键和释放按键的方式，具体取决于我们想做什么。对于Magenta中的每个模型，我们将看到MIDI音符是如何被编码的。
- en: The following image shows a MIDI representation of a generated drum file, shown
    as a plot of time and pitch. Each MIDI note is represented by a rectangle. Because
    of the nature of percussion data, all the notes have the same length ("note on"
    followed by "note off" messages), but in general, that could vary. A drum file,
    by essence, is polyphonic, meaning that multiple notes can be played at the same
    time. We'll be talking about monophony and polyphony in the upcoming chapters.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了生成的鼓文件的MIDI表示，它以时间和音高的图形形式展示。每个MIDI音符由一个矩形表示。由于打击乐数据的特点，所有音符的时长相同（"note
    on"后跟"note off"消息），但通常情况下，这个时长可能会有所不同。由于鼓文件本质上是复音的，这意味着多个音符可以同时演奏。我们将在接下来的章节中讨论单音和复音。
- en: 'Note that the abscissa is expressed in seconds, but it is also common to note
    it with bars or measures. The MIDI channel is absent from this diagram:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，横坐标以秒为单位表示，但通常也可以用小节（bars）来表示。该图中未显示MIDI通道：
- en: '![](img/1cd47be5-1cd9-4af3-9f28-a1c24ddbef99.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1cd47be5-1cd9-4af3-9f28-a1c24ddbef99.png)'
- en: The script for plotting a generated MIDI file can be found in the GitHub code
    for this chapter in the `Chapter01/provided` folder. The script is called `midi2plot.py`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制生成的MIDI文件的脚本可以在本章节的GitHub代码中的`Chapter01/provided`文件夹里找到。这个脚本的名字叫做`midi2plot.py`。
- en: 'In the case of music generation, the majority of current deep learning systems
    use symbolic notation. This is also the case with Magenta. There are a couple
    of reasons for this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在音乐生成的过程中，目前大多数深度学习系统使用符号化表示法，Magenta也采用了这种方式。这背后有几个原因：
- en: It is easier to represent the essence of music in terms of composition and harmony
    with symbolic data.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用符号数据表示音乐的本质，特别是在作曲和和声方面，是更为简便的。
- en: Processing those two types of representations by using a deep learning network
    is similar, so choosing between both boils down to whichever is faster and more
    convenient. A good example of this is that the WaveNet audio generation network
    also has a MIDI implementation, known as the MidiNet symbolic generation network.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理这两种表示方式并使用深度学习网络进行训练是类似的，因此选择其中一种表示方式，归根结底取决于哪一种更快、更方便。一个很好的例子是，WaveNet音频生成网络也有一个MIDI实现，称为MidiNet符号生成网络。
- en: We'll see that the MIDI format is not directly used by Magenta, but converted
    into and from `NoteSequence`, a **Protocol Buffers** (**Protobuf**) implementation
    of the musical structure that is then used by TensorFlow. This is hidden from
    the end user since the input and output data is always MIDI. The `NoteSequence`
    implementation is useful because it implements a data format that can be used
    by the models for training. For example, instead of using two messages to define
    a note's length, a `Note` in a `NoteSequence` has a length attribute. We'll be
    explaining the `NoteSequence` implementation as we go along.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会看到，MIDI格式并未直接被Magenta使用，而是被转换为`NoteSequence`，这是一种**协议缓冲区**（**Protobuf**）实现的音乐结构，之后由TensorFlow使用。这一过程对最终用户是透明的，因为输入和输出数据始终是MIDI格式。`NoteSequence`的实现之所以有用，是因为它实现了一种数据格式，可以供模型进行训练。例如，在`NoteSequence`中的`Note`有一个长度属性，而不是使用两个消息来定义音符的长度。我们将在接下来的讲解中详细说明`NoteSequence`的实现。
- en: Representing music as a waveform
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将音乐表示为波形
- en: An audio waveform is a graph displaying amplitude changes over time. Zoomed
    out, a waveform looks rather simple and smooth, but zoomed in, we can see tiny
    variations – it is those variations that represent the sound.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 音频波形是一个显示振幅随时间变化的图表。从远距离看，波形看起来相当简单和平滑，但放大后，我们可以看到微小的变化——这些变化代表了声音。
- en: To illustrate how a waveform works, imagine a speaker cone that's is at rest
    when the amplitude is at 0\. If the amplitude moves to a negative value of 1,
    for example, then the speaker moves backward a little bit, or forward in the case
    of a positive value. For each amplitude variation, the speaker will move, making
    the air move, thus making your eardrums move.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明波形是如何工作的，假设扬声器锥体在振幅为0时处于静止状态。如果振幅变化到负值1，例如，扬声器就会向后移动一点，或者在振幅为正值时，扬声器则会向前移动。每次振幅变化时，扬声器都会移动，进而推动空气流动，从而使耳膜发生震动。
- en: The bigger the amplitude is in the waveform, the more the speaker cone moves
    in terms of distance, and the louder the sound. This is expressed in **decibel**
    (**dB**), a measure of sound pressure.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 波形中的振幅越大，扬声器锥体的位移距离就越大，声音也就越响。这用**分贝**（**dB**）表示，是声音压力的度量。
- en: The faster the movement, the higher the pitch. This is expressed in **hertz**
    (**Hz**).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 运动越快，音高越高。这用**赫兹**（**Hz**）表示。
- en: 'In the following image, we can see the MIDI file from the previous section
    played by instruments to make a WAV recording. The instrument that''s being used
    is a 1982 Roland TR-808 drum sample pack. You can visually match some instruments,
    such as double the Conga Mid (MIDI note 48) at around 4.5 seconds. In the upper
    right corner, you can see a zoom of the waveform at 100th of a second to show
    the actual amplitude change:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下的图像中，我们可以看到上一部分的MIDI文件由乐器演奏，并制作成WAV录音。使用的乐器是1982年款的Roland TR-808鼓样本包。你可以通过图像大致匹配一些乐器，例如，在大约4.5秒时，看到双倍Conga
    Mid（MIDI音符48）。在右上角，你可以看到一个缩放的波形图，精确到百分之一秒，用来显示实际的振幅变化：
- en: '![](img/fb612e63-ef48-4c37-aaae-935c764fc653.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb612e63-ef48-4c37-aaae-935c764fc653.png)'
- en: The script for plotting a WAV file can be found in the GitHub code for this
    chapter in the `Chapter01/provided` folder. The script is called `wav2plot.py`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制WAV文件的脚本可以在本章的GitHub代码中找到，位于`Chapter01/provided`文件夹中。该脚本名为`wav2plot.py`。
- en: In machine learning, using a raw audio waveform used to be uncommon as a data
    source since the computational load is bigger than other transformed representations,
    both in terms of memory and processing. But recent advances in the field, such
    as WaveNet models, makes it on par with other methods of representing audio, such
    as spectrograms, which were historically more popular for machine learning algorithms,
    especially for speech recognition and synthesis.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，使用原始音频波形作为数据源曾经并不常见，因为与其他转换过的表示方式相比，原始波形的计算负担更大，无论是在内存使用还是处理速度上。但随着该领域的最新进展，例如WaveNet模型，原始波形与其他音频表示方法（如频谱图）已不相上下，后者在机器学习算法中，尤其是在语音识别和合成中，历史上更为流行。
- en: 'Bear in mind that training on audio is really cost-intensive because raw audio
    is a dense medium. Basically, a waveform is a digital recreation of a dynamic
    voltage over time. Simply put, a process called **Pulse Code Modulation** (**PCM**)
    assigns a bit value to each sample at the sampling rate you are running. The sampling
    rate for recording purposes is pretty standard: 44,100 Hz, which is called the
    Nyquist Frequency. But you don''t always need a 44,100 Hz sample rate; for example,
    16,000 Hz is more than enough to cover human speech frequencies. At that frequency,
    the first second of audio is represented by 16,000 samples.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对音频进行训练是非常昂贵的，因为原始音频是一种密集的媒介。基本上，波形是动态电压随时间变化的数字重建。简单来说，一个叫做**脉冲编码调制**（**PCM**）的过程为你所运行的采样率下的每个样本分配一个比特值。录音用的采样率相当标准：44,100
    Hz，这就是所谓的奈奎斯特频率。但是你并不总是需要44,100 Hz的采样率；例如，16,000 Hz就足够覆盖人类语音频率了。在这个频率下，音频的第一秒由16,000个样本表示。
- en: If you want to know more about PCM, the sampling theory for audio, and the Nyquist
    Frequency, check out the *Further reading* section at the end of this chapter.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于PCM、音频采样理论以及奈奎斯特频率的内容，请查看本章末尾的*进一步阅读*部分。
- en: This frequency was chosen for a very specific purpose. Thanks to the Nyquist
    theorem, it allows us to recreate the original audio without a loss of sounds
    that humans can hear.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 选择这个频率是有特定目的的。得益于奈奎斯特定理，它可以让我们在不丢失人耳能够听到的声音的情况下重建原始音频。
- en: The human ear can hear sounds up to 20,000 Hz, so you need 40,000 Hz to represent
    it in a waveform since you need a negative value and a positive value to make
    a sound (see the explanation at the beginning of this subsection). Then, you can
    add 4,100 Hz for rounding errors on very low and very high frequencies to make
    44,100 Hz.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 人耳能够听到的声音频率最高为20,000 Hz，因此你需要40,000 Hz来表示它，因为你需要一个负值和一个正值来产生声音（参见本小节开头的解释）。然后，你可以为非常低和非常高频率的舍入误差加上4,100
    Hz，得到44,100 Hz。
- en: This is a good example of a sampled (discrete) representation that can be reversed
    to its original continuous representation because the pitch spectrum the ear can
    hear is limited.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的采样（离散）表示的例子，它可以被反转回原始的连续表示，因为人耳能听到的音高范围是有限的。
- en: We'll look at audio representation in more detail in [Chapter 5](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml),
    *Audio Generation with NSynth and GANSynth*, since we are going to be using NSynth,
    a Wavenet model, to generate audio samples.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5章](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml)中更详细地探讨音频表示问题，*使用NSynth和GANSynth进行音频生成*，因为我们将使用NSynth，这是一个Wavenet模型，用于生成音频样本。
- en: Representing music with a spectrogram
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用频谱图表示音乐
- en: Historically, spectrograms have been a popular form of handling audio for machine
    learning, for two reasons – it is compact and extracting features from it is easier.
    To explain this, imagine the raw audio stream of the example from the previous
    section and cut it into chunks of 1/50th of a second (20 milliseconds) for processing.
    Now, you have chunks of 882 samples that are hard to represent; it is a mixed
    bag of amplitudes that don't really represent anything.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，频谱图一直是机器学习处理中常用的音频表示方式，原因有两个——它既紧凑又容易从中提取特征。为了说明这一点，假设我们有上一节中的原始音频流，并将其切割成每段1/50秒（20毫秒）的块进行处理。现在，你将得到882个样本的音频块，这些样本很难表示；它们是一个混合的振幅集合，实际上并没有代表任何东西。
- en: 'A spectrogram is the result of doing a Fourier transform on the audio stream.
    A Fourier transform will decompose a signal (a function of time) into its constituent
    frequencies. For an audio signal, this gives us the intensity of a frequency band,
    with a band being a small split of the whole spectrum, for example, 50 Hz. After
    applying a Fourier transform on our previous example and taking sample 1 of the
    882 samples, we''ll end up with the intensity for each frequency band:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱图是对音频流进行傅里叶变换的结果。傅里叶变换将一个信号（时间的函数）分解为其组成频率。对于音频信号，这为我们提供了每个频带的强度，其中频带是整个频谱的小块，例如50
    Hz。在对我们之前的例子进行傅里叶变换并取882个样本中的第1个样本后，我们将得到每个频带的强度：
- en: '*[0 Hz - 50 Hz]: a[1]*'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*[0 Hz - 50 Hz]：a[1]*'
- en: '*[50 Hz - 100 Hz]: a[2]*'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*[50 Hz - 100 Hz]：a[2]*'
- en: '*...*'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*...*'
- en: '*[22000 Hz - 22050 Hz:]: a[n]*'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*[22000 Hz - 22050 Hz]：a[n]*'
- en: You'll end up with intensity *[a[1], a[2], ..., a[n]]* for each band of 50 Hz
    up to 22,050, which is the y-axis, with an assigned color spectrum for smaller
    to bigger intensities. Repeating that for each 20 ms on the x-axis until the whole
    audio is covered gives you a spectrogram. What is interesting in a spectrogram
    is that you can actually see the content of the music. If a C major chord is played,
    you'll see C, E, and G emerge in the spectrogram at their corresponding frequency.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你将为每个50 Hz到22,050 Hz的频带得到强度 *[a[1], a[2], ..., a[n]]*，作为 y 轴，并为不同强度分配颜色谱。通过对每
    20 毫秒的时间段重复这个过程，直到覆盖整个音频，便得到一个频谱图。频谱图的有趣之处在于，你可以实际看到音乐的内容。如果演奏了 C 大调和弦，你将在频谱图中看到
    C、E 和 G 出现，并在对应的频率上显示。
- en: 'The following spectrogram has been generated from the waveform of the previous
    section. From this, you can clearly see the frequencies that are being played
    by the TR 808 from the given MIDI file. You should be able to visually match the
    waveform from the previous section with the spectrogram:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下频谱图是从上一节的波形生成的。从中，你可以清楚地看到 TR 808 在给定 MIDI 文件中播放的频率。你应该能够在视觉上将上一节的波形与频谱图对应起来：
- en: '![](img/f226d763-cc79-4e90-b897-f514da3c7ec8.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f226d763-cc79-4e90-b897-f514da3c7ec8.png)'
- en: The script for plotting the spectrogram of a WAV file can be in the GitHub code
    for this chapter in the `Chapter01/provided` folder. The script is called `wav2spectrogram.py`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制 WAV 文件频谱图的脚本可以在本章 GitHub 代码的 `Chapter01/provided` 文件夹中找到，脚本名为 `wav2spectrogram.py`。
- en: 'Spectrograms are mainly used in speech recognition. They are also used in speech
    synthesis: first, a model is trained on spectrograms aligned with text, and from
    there, the model will be able to produce a spectrogram that corresponds to a given
    text. The Griffin-Lim algorithm is used to recover an audio signal from a spectrogram.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱图主要用于语音识别，也应用于语音合成：首先，训练一个与文本对齐的频谱图模型，之后该模型便能生成与给定文本相对应的频谱图。Griffin-Lim 算法用于从频谱图中恢复音频信号。
- en: We won't be using spectrograms in this book, but knowing how they work and what
    they are used for is important since they are used in many applications.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中不会使用频谱图，但了解其工作原理和应用领域非常重要，因为它们被广泛应用于许多场景中。
- en: 'Fun fact: musicians have been known to hide images in music that are visible
    when looking at the audio''s spectrogram. A famous example is the Aphex Twin''s
    *Windowlicker* album, where he embedded his grinning face on the second track.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味小知识：音乐家们有时会在音乐中隐藏图片，这些图片在查看音频的频谱图时会显现出来。一个著名的例子是 Aphex Twin 的*Windowlicker*专辑，他在第二首曲目中嵌入了自己笑脸的图像。
- en: So far, we have learned which deep learning technical advances are important
    in music generation and learned about music representation in those algorithms.
    These two topics are important because we'll be looking at them throughout this
    book.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了在音乐生成中哪些深度学习技术进展是重要的，并学习了这些算法中的音乐表示。这两个主题很重要，因为我们将在本书中持续关注它们。
- en: In the next section, we'll introduce Magenta, where you'll see much of this
    section's content come into play.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍 Magenta，在这里你会看到本节的许多内容得以应用。
- en: Google's Magenta and TensorFlow in music generation
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌的 Magenta 和 TensorFlow 在音乐生成中的应用
- en: 'Since its launch, TensorFlow has been important for the data scientist community
    for being *An Open Source Machine Learning Framework for Everyone*. Magenta, which
    is based on TensorFlow, can be seen the same way: even if it''s using state of
    the art machine learning techniques, it can still be used by anyone. Musicians
    and computer scientists alike can install it and generate new music in no time.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 自推出以来，TensorFlow 因其*面向所有人的开源机器学习框架*而成为数据科学家社区的重要工具。基于 TensorFlow 的 Magenta 也可以这样看待：即使它采用了最先进的机器学习技术，仍然可以被任何人使用。无论是音乐家还是计算机科学家，都可以安装它，并在短时间内创作新音乐。
- en: In this section, we'll look at the content of Magenta by introducing what it
    can and cannot do and refer to the chapters that explain the content in more depth.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将通过介绍 Magenta 的功能和限制，来深入探讨它的内容，并参考章节内容以获得更详细的解释。
- en: Creating a music generation system
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个音乐生成系统
- en: Magenta is a framework for art generation, but also for attention, storytelling,
    and the evaluation of generative music. As the book advances, we'll come to see
    and understand how those elements are crucial for pleasing music generation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 是一个艺术生成框架，但它也涉及注意力机制、讲故事和生成音乐的评估。随着本书的推进，我们将看到并理解这些元素在令人愉悦的音乐生成中的重要性。
- en: Evaluating and interpreting generative models is inherently hard, especially
    for audio. A common criterion in machine learning is the average log-likelihood,
    which calculates how much the generated samples deviate from the training data,
    which might give you the proximity of two elements, but not the musicality of
    the generated one.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 评估和解释生成模型本质上是困难的，尤其是对于音频。机器学习中一个常见的标准是平均对数似然（average log-likelihood），它计算生成的样本与训练数据的偏差，这可能给你提供两个元素的接近度，但无法体现生成音乐的音乐性。
- en: 'Even if the progress in GANs is promising in such evaluations, we are often
    left with only our ears to evaluate. We can also imagine a Turing test for a music
    piece: a composition is played to an audience that has to decide whether the piece
    was generated by a computer.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 即使 GAN 在这种评估中有了很大的进展，我们往往只能依靠我们的耳朵来进行评估。我们也可以想象一个音乐作品的图灵测试：将一首作品演奏给观众，观众需要判断这首作品是否是由计算机生成的。
- en: 'We''ll be using Magenta for two different purposes, assisting and autonomous
    music creation:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Magenta 来实现两个不同的目的：辅助和自主音乐创作：
- en: '**Assisting music systems** helps with the process of composing music. Examples
    of this would be the Magenta interface, `magenta_midi.py`, where the musician
    can enter a MIDI sequence and Magenta will answer with a generated sequence that''s
    inspired by the provided one. These types of systems can be used alongside traditional
    systems to compose music and get new inspirations. We''ll be talking about this
    in [Chapter 9](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml), *Making Magenta Interact
    with Music Applications*, where Magenta Studio can be integrated into a traditional
    music production tool.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**辅助音乐系统**有助于作曲过程。这类系统的例子包括 Magenta 界面 `magenta_midi.py`，在这里，音乐家可以输入一个 MIDI
    序列，Magenta 会生成一个基于提供序列的音乐灵感。此类系统可以与传统系统一起使用，帮助作曲并获得新的灵感。我们将在[第九章](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml)《让
    Magenta 与音乐应用互动》中讨论这一点，Magenta Studio 可以集成到传统的音乐制作工具中。'
- en: '**Autonomous music systems** continuously produce music without the input of
    an operator. At the end of this book, you''ll have all the tools you''ll need
    to build an autonomous music generation system consisting of the various building
    blocks of Magenta.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自主音乐系统**能在没有操作员输入的情况下持续生成音乐。在本书的最后，你将掌握构建一个自主音乐生成系统所需的所有工具，这个系统由 Magenta
    的各种构建模块组成。'
- en: Looking at Magenta's content
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看 Magenta 的内容
- en: 'Remembering what we saw in the previous section, there are many ways of representing
    music: symbolic data, spectrogram data, and raw audio data. Magenta works mainly
    with symbolic data, meaning we''ll mainly work on the underlying score in music
    instead of working directly with audio. Let''s look into Magenta''s content, model
    by model.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾上一节的内容，音乐可以通过多种方式表示：符号数据、谱图数据和原始音频数据。Magenta 主要处理符号数据，这意味着我们将主要关注音乐中的基础乐谱，而不是直接处理音频。让我们逐个模型地了解
    Magenta 的内容。
- en: Differentiating models, configurations, and pre-trained models
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区分模型、配置和预训练模型
- en: In Magenta and in this book, the term **model** refers to a specific deep neural
    network that is specific for one task. For example, the Drums RNN model is an
    LSTM network with attention configuration, while the MusicVAE model is a variational
    autoencoder network. The Melody RNN model is also an LSTM network but is geared
    toward generating melodies instead of percussion patterns.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Magenta 和本书中，**模型**一词指的是一个特定任务的深度神经网络。例如，Drums RNN 模型是一个带有注意力配置的 LSTM 网络，而
    MusicVAE 模型是一个变分自编码器网络。Melody RNN 模型也是一个 LSTM 网络，但它专门用于生成旋律，而不是打击乐模式。
- en: Each model has different **configurations** that will change how the data is
    encoded for the network, as well as how the network is configured. For example,
    the Drums RNN model has a `one_drum` configuration, which encodes the sequence
    to a single class, as well as a `drum_kit` configuration, which maps the sequence
    to nine drum instruments and also configures the attention length to 32.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型都有不同的 **配置**，这些配置会改变数据如何被编码进网络以及网络的配置方式。例如，Drums RNN 模型有一个 `one_drum` 配置，它将序列编码为单一类别；还有一个
    `drum_kit` 配置，它将序列映射到九种打击乐器，并将注意力长度配置为 32。
- en: Finally, each configuration comes with one or more **pre-trained models**. For
    example, Magenta provides a pre-trained Drums RNN `drum_kit` model, as well as
    multiple pre-trained MusicVAE `cat-drums_2bar_small` models.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，每种配置都配有一个或多个 **预训练模型**。例如，Magenta 提供了一个预训练的 Drums RNN `drum_kit` 模型，以及多个预训练的
    MusicVAE `cat-drums_2bar_small` 模型。
- en: We'll be using this terminology throughout this book. For the first few chapters,
    we'll be using the Magenta pre-trained models, since they are already quite powerful.
    After, we'll create our own configurations and train our own models.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们将使用这些术语。在前几章，我们将使用Magenta预训练模型，因为它们已经非常强大。之后，我们将创建自己的配置并训练自己的模型。
- en: Generating and stylizing images
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成和风格化图像
- en: Image generation and stylization can be achieved in Magenta with the *Sketch
    RNN* and *Style Transfer* models, respectively. Sketch-RNN is a **Sequence-to-Sequence**
    (**Seq2Seq**) variational autoencoder.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成和风格化可以通过Magenta中的*Sketch RNN*和*Style Transfer*模型分别实现。Sketch-RNN是一个**序列到序列**（**Seq2Seq**）变分自编码器。
- en: Seq2Seq models are used to convert sequences from one domain into another domain
    (for example, to translate a sentence in English to a sentence in French) that
    do not necessarily have the same length, which is not possible for a traditional
    model structure. The network will encode the input sequence into a vector, called
    a latent vector, from which a decoder will try to reproduce the input sequence
    as closely as possible.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Seq2Seq模型用于将一个领域的序列转换为另一个领域的序列（例如，将一句英语句子翻译为法语句子），这些序列的长度不一定相同，这是传统模型结构无法实现的。网络将把输入序列编码成一个向量，称为潜在向量，解码器将尽可能准确地重现输入序列。
- en: Image processing is not part of this book, but we'll see the usage of latent
    space in [Chapter 4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml), *Latent Space
    Interpolation with MusicVAE*, when we use the MusicVAE model. If you are interested
    in the SketchRNN model, see the *Further reading* section for more information.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理不属于本书的内容，但我们将在[第4章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)《*使用MusicVAE进行潜在空间插值*》中看到潜在空间的应用，当时我们会使用MusicVAE模型。如果你对SketchRNN模型感兴趣，请参阅*进一步阅读*部分了解更多信息。
- en: Generating audio
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成音频
- en: Audio generation in Magenta is done with the *NSynth*, a WaveNet-based autoencoder,
    and *GANSynth* models. What's interesting about WaveNet is that it is a convolutional
    architecture, prevalent in image applications, but seldom used in music applications,
    in favor of recurrent networks. **Convolutional neural networks** (**CNNs**) are
    mainly defined by a convolution stage, in which a filter is slid through the image,
    computing a feature map of the image. Different filter matrices can be used to
    detect different features, such as edges or curves, which are useful for image
    classification.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在Magenta中，音频生成是通过*NSynth*（一个基于WaveNet的自编码器）和*GANSynth*模型完成的。WaveNet的有趣之处在于，它是一种卷积架构，广泛应用于图像领域，但在音乐应用中很少使用，反而更多使用递归网络。**卷积神经网络**（**CNNs**）主要通过卷积阶段定义，在这个阶段中，滤波器在图像中滑动，计算图像的特征图。可以使用不同的滤波器矩阵来检测不同的特征，如边缘或曲线，这对图像分类非常有用。
- en: We'll see the usage of these models in [Chapter 5](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml),
    *Audio Generation with NSynth and GANSynth*.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5章](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml)《*使用NSynth和GANSynth生成音频*》中看到这些模型的应用。
- en: Generating, interpolating, and transforming score
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成、插值和转换乐谱
- en: 'Score generation is the main part of Magenta and can be split into different
    categories representing the different parts of a musical score:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 乐谱生成是Magenta的主要部分，可以分为代表乐谱不同部分的不同类别：
- en: '**Rhythms generation**: This can be done with the "Drums RNN" model, an RNN
    network that applies language modeling using an LSTM. Drum tracks are polyphonic
    by definition because multiple drums can be hit simultaneously. This model will
    be presented in [Chapter 2](b60deee5-c58f-45eb-88a2-23718802e580.xhtml), *Generating
    Drum Sequences with Drums RNN*.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节奏生成**：这可以通过"Drums RNN"模型完成，该模型是一个应用LSTM进行语言建模的RNN网络。鼓轨道从定义上来说是多声部的，因为多个鼓可以同时击打。这个模型将在[第2章](b60deee5-c58f-45eb-88a2-23718802e580.xhtml)《*使用Drums
    RNN生成鼓序列*》中介绍。'
- en: '**Melody generation**: Also known as monophonic generation, this can be done
    with the "Melody RNN" and "Improv RNN" models, which also implement the use of
    attention, allowing the models to learn longer dependencies. These models will
    be presented in [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml), *Generating
    Polyphonic Melodies*.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旋律生成**：也称为单声部生成，这可以通过"Melody RNN"和"Improv RNN"模型完成，这些模型同样实现了注意力机制，允许模型学习更长的依赖关系。这些模型将在[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)《*生成多声部旋律*》中介绍。'
- en: '**Polyphonic generation**: This can be done with the *Polyphony RNN* and *Performance
    RNN* models, where the latter also implements expressive timing (sometimes called
    groove, where the notes don''t start and stop exactly in the grid, giving it a
    human fell) and dynamics (or velocity). These models will be presented in [Chapter
    3](48023567-4100-492a-a28e-53b18a63e01e.xhtml), *Generating Polyphonic Melodies*.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多声部生成**：可以使用*Polyphony RNN*和*Performance RNN*模型完成，其中后者还实现了表现力的时序（有时称为groove，即音符并非完全按照网格开始和停止，给人一种人类演奏的感觉）和动态（或速度）。这些模型将在[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)，*生成多声部旋律*中介绍。'
- en: '**Interpolation**: This can be done with the MusicVAE model, a variational
    autoencoder that learns the latent space of a musical sequence and can interpolate
    between existing sequences. This model will be presented in [Chapter 4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml),
    *Latent Space Interpolation with Music VAE*.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插值**：可以使用MusicVAE模型完成，它是一个变分自编码器，可以学习音乐序列的潜在空间，并在现有序列之间进行插值。这个模型将在[第4章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)，*使用Music
    VAE进行潜在空间插值*中介绍。'
- en: '**Transformation**: This can be done with the *GrooVAE* model, a variant of
    the MusicVAE model that will add groove to an existing drum performance. This
    model will be presented in [Chapter 4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml),
    *Latent Space Interpolation with Music VAE*.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换**：可以使用*GrooVAE*模型完成，这是MusicVAE模型的一个变种，可以为现有的鼓表演添加节奏感。这个模型将在[第4章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)，*使用Music
    VAE进行潜在空间插值*中介绍。'
- en: Installing Magenta and Magenta for GPU
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Magenta和适用于GPU的Magenta
- en: Installing a machine learning framework is not an easy task and often a pretty
    big entry barrier, mainly because Python is an infamous language concerning dependency
    management. We'll try to make this easy by providing clear instructions and versions.
    We'll be covering installation instructions for Linux, Windows, and macOS since
    the commands and versions are mostly the same.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 安装机器学习框架并非易事，且通常是一个较大的入门障碍，主要是因为Python在依赖管理方面有着恶名。我们将通过提供清晰的指引和版本信息来简化这一过程。我们将覆盖Linux、Windows和macOS的安装指引，因为这些系统的命令和版本大多相同。
- en: In this section, we'll be installing Magenta and Magenta for GPU, if you have
    the proper hardware. Installing Magenta for a GPU takes a bit more work but is
    necessary if you want to train a model, which we will do in [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml), *Training
    Magenta Models*. If you are unsure about doing this, you can skip this section
    and come back to it later. We'll also provide a solution if you don't have a GPU
    but still want to do the chapter by using cloud-based solutions.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将安装Magenta以及适用于GPU的Magenta版本（如果你有合适的硬件）。为GPU安装Magenta需要多一些步骤，但如果你希望训练模型（我们将在[第7章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)，*训练Magenta模型*中进行），这是必要的。如果你不确定是否进行此操作，可以跳过本节并稍后再回来。我们还将提供一种解决方案，帮助你在没有GPU的情况下，通过云端解决方案完成这一章节。
- en: TensorFlow will be installed through Magenta's dependencies. We'll also look
    at optional but useful programs that can help you visualize and play audio content.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow将通过Magenta的依赖项进行安装。我们还将介绍一些可选但有用的程序，帮助你可视化和播放音频内容。
- en: Choosing the right versions
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择正确的版本
- en: 'At the time of writing, newer versions of Python and CUDA are available, but
    we are using the following versions because of incompatibilities with TensorFlow
    and TensorFlow GPU. We''ll be using Magenta 1.1.7 since it is the stable version
    of Magenta at the time of writing. You can try using a newer version for the examples
    and roll back if it doesn''t work:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本文撰写时，已有更新版的Python和CUDA可供使用，但由于与TensorFlow和TensorFlow GPU的不兼容，我们将使用以下版本。我们将使用Magenta
    1.1.7版本，因为这是本文撰写时Magenta的稳定版本。你可以尝试使用更新版本进行示例操作，如果不工作可以回退到当前版本：
- en: 'Magenta: 1.1.7'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Magenta: 1.1.7'
- en: 'TensorFlow: 1.15.0 (this version is installed automatically when installing
    Magenta)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TensorFlow: 1.15.0（此版本在安装Magenta时会自动安装）'
- en: 'This means that we need to use exactly the following versions for TensorFlow
    to work:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们需要使用以下版本，才能让TensorFlow正常工作：
- en: 'Python: 3.6.x'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Python: 3.6.x'
- en: 'CUDA libraries: 10.0'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA库：10.0
- en: 'CudRNN: 7.6.x (the latest version is OK)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CudRNN: 7.6.x（最新版本可以）'
- en: Let's look at how to install those versions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何安装这些版本。
- en: Creating a Python environment with Conda
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Conda创建Python环境
- en: Throughout this book, we'll be using a Python environment, a standalone and
    separate installation of Python you can switch to when you are working with a
    specific piece of software, such as when you're working on this book or another
    piece of software. This also ensures that the system-wide installation remains
    safe.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的整个过程中，我们将使用一个 Python 环境，这是一个独立的、与系统安装分开的 Python 环境，你可以在处理特定软件时切换到它，比如在编写本书或处理其他软件时。这样也确保了系统范围的安装保持安全。
- en: There are many Python environment managers available, but we'll use Conda here,
    which we'll come installed with a standalone Python installation called **Miniconda**.
    You can think of Miniconda as a program with a packaged Python, some dependencies,
    and Conda.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多 Python 环境管理工具，但我们在这里使用 Conda，它会随一个名为 **Miniconda** 的独立 Python 安装包一起安装。你可以将
    Miniconda 理解为一个包含打包好的 Python、一部分依赖和 Conda 的程序。
- en: To install Miniconda, go to [docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html),
    download the installer for your platform, choose Python 3.7 as the Python version
    (this is NOT the Python version Magenta will run in), and either 32-bit or 64-bit
    (you probably have the latter).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 Miniconda，请访问 [docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)，下载适合你平台的安装程序，选择
    Python 3.7 作为 Python 版本（这不是 Magenta 将运行的 Python 版本），并选择 32 位或 64 位（你可能是后者）。
- en: 'For Windows, follow these steps:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Windows，请按照以下步骤操作：
- en: Double-click the installer. Then, follow the prompts and leave the defaults
    as they are.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击安装程序。然后，按照提示操作，保持默认设置不变。
- en: Add `conda` to PATH by going to `Control Panel > System > Advanced system settings
    > Environment Variables... > Path > Edit... > New` and add the `condabin` folder
    to the Miniconda installation folder (which should be `C:\Users\Packt\Miniconda3\condabin`).
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过进入 `控制面板 > 系统 > 高级系统设置 > 环境变量... > Path > 编辑... > 新建` 来将 `conda` 添加到 PATH
    中，并将 `condabin` 文件夹添加到 Miniconda 安装文件夹（通常是 `C:\Users\Packt\Miniconda3\condabin`）。
- en: If you are facing issues installing Miniconda on Windows, you can also use **Anaconda**,
    which is the same software but packaged with more tools.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Windows 上安装 Miniconda 时遇到问题，你也可以使用 **Anaconda**，它是相同的软件，但捆绑了更多的工具。
- en: First, download Anaconda from [www.anaconda.com/distribution](https://www.anaconda.com/distribution/),
    double-click the installer, follow the prompts, and leave the defaults as they
    are.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从 [www.anaconda.com/distribution](https://www.anaconda.com/distribution/)
    下载 Anaconda，双击安装程序，按照提示操作，保持默认设置不变。
- en: Then, launch **Anaconda Prompt** from the Start menu instead of the **Command
    Prompt**, which will launch a new command-line window with Conda initialized.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，从开始菜单启动 **Anaconda Prompt** 而不是 **命令提示符**，这将启动一个新的命令行窗口，并初始化 Conda。
- en: 'For macOS and Linux, open a Terminal where you downloaded the file as follow
    these steps:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 macOS 和 Linux，请打开终端，进入下载文件的目录，按以下步骤操作：
- en: 'Make the script executable for your user by replacing `<platform>` with the
    platform you downloaded:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将 `<platform>` 替换为你下载的平台，使脚本对你的用户可执行：
- en: '[PRE1]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, execute the script, which will install the software:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，执行脚本，安装软件：
- en: '[PRE2]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now that Conda has been installed, let''s check if it works properly:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Conda 已经安装好了，让我们检查它是否正常工作：
- en: 'Open a new Terminal and type in the following:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的终端并输入以下命令：
- en: '[PRE3]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Your output will look different, but the idea is the same.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输出可能有所不同，但原理是一样的。
- en: 'Now, we need to create a new environment for this book. Let''s call it "magenta":'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要为本书创建一个新的环境。我们将其命名为“magenta”：
- en: '[PRE4]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Notice that the Python version is 3.6, as we mentioned at the beginning of this
    section.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Python 版本为 3.6，正如我们在本节开头提到的那样。
- en: 'Your new environment with the correct version of Python and some dependencies
    has been created. You now have three different Python environments, each with
    a version of Python with its own dependencies :'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经创建了一个包含正确版本 Python 和一些依赖项的新环境。现在你有三个不同的 Python 环境，每个环境都有自己版本的 Python 和依赖：
- en: '**None**: This is the system-wide installation of Python from the system (this
    might be absent on Windows), and you can switch to it with `conda deactivate`.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**None**：这是系统范围的 Python 安装（在 Windows 上可能不存在），你可以通过 `conda deactivate` 切换到它。'
- en: '**base**: This is the Miniconda Python installation of Python 3.7 we downloaded,
    and you can switch to it with `conda activate base`.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**base**：这是我们下载的 Python 3.7 的 Miniconda 安装版本，你可以通过 `conda activate base` 切换到它。'
- en: '**magenta**: This is our new Python 3.6 installation for this project, and
    you can switch to it with `conda activate magenta`.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**magenta**：这是我们为本项目安装的新的 Python 3.6 环境，你可以通过 `conda activate magenta` 切换到它。'
- en: Since we are still in the base environment, we need to activate the "magenta"
    environment.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们仍然处于基础环境中，我们需要激活“magenta”环境。
- en: 'Use the `activate` flag to change environments:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`activate`标志来切换环境：
- en: '[PRE5]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: From there, your Terminal should prefix the line with "(magenta)", meaning the
    commands you are executing are being executed in this specific environment.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 从此开始，你的终端行前缀会显示“(magenta)”，这意味着你执行的命令是在此特定环境中运行的。
- en: 'Let''s check our Python version:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查一下 Python 版本：
- en: '[PRE6]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you have something else here (you should have Python version 3.6.x and Anaconda
    packaging), stop and make sure you followed the installation instructions properly.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你这里有其他内容（你应该安装 Python 版本 3.6.x 和 Anaconda 打包工具），请停止操作并确保你已正确按照安装说明进行安装。
- en: This is just a reminder that you **need Python 3.6.x**. An older version of
    Python won't be able to run the code in this book because we are using language
    features from 3.6, and a newer version won't run TensorFlow because it doesn't
    support 3.7 yet.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提醒一下，你**需要 Python 3.6.x**。较旧的 Python 版本无法运行本书中的代码，因为我们使用了 3.6 版本的语言特性，而较新的版本则无法运行
    TensorFlow，因为它尚不支持 3.7。
- en: Installing prerequisite software
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装先决软件
- en: 'Now that we have a Python environment up and running, you''ll need some prerequisite
    software that will be useful throughout this book. Let''s get started:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经启动并运行了 Python 环境，你将需要一些本书中会用到的先决软件。让我们开始吧：
- en: 'First, we''ll need to install `curl`, which is preinstalled on Windows and
    macOS, but not Linux (at least not in all distributions). On a Debian distribution,
    use the following command. On other distributions, use your package manager:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要安装 `curl`，在 Windows 和 macOS 上默认预装，但 Linux 上通常没有（至少并非所有发行版都预装）。在 Debian
    发行版上，使用以下命令。在其他发行版上，使用你的包管理工具：
- en: '[PRE7]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we need to install Visual MIDI, the MIDI visualization library we''ll
    use to make the diagrams of our generated scores. While in the Magenta environment,
    run the following command:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要安装 Visual MIDI，这是一种 MIDI 可视化库，我们将用它来生成我们创建的乐谱的图表。在 Magenta 环境中，运行以下命令：
- en: '[PRE8]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we''ll install the tables modules, which will be useful later to read
    external datasets stored in H5 databases:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将安装表格模块，这对于稍后读取存储在 H5 数据库中的外部数据集非常有用：
- en: '[PRE9]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Installing Magenta
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Magenta
- en: 'With our environment and the prerequisite software installed, we can now install
    Magenta version 1.1.7\. You can use a more recent version of Magenta, but do this
    at your own risk: this book''s code was written with version 1.1.7, and the Magenta
    source code has a tendency to change. Let''s get started:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们安装了环境和所需的软件后，现在可以安装 Magenta 版本 1.1.7。你也可以使用 Magenta 的更新版本，但请自行承担风险：本书的代码是基于
    1.1.7 版本编写的，并且 Magenta 源代码有变化的趋势。让我们开始吧：
- en: 'While in the Magenta environment, run the following command:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Magenta 环境中，运行以下命令：
- en: '[PRE10]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you want to try a more recent version of Magenta, just remove the version
    information contained in the `pip` command. Then, it will install the latest version.
    If you have problems using a newer version, you can reinstall version 1.1.7 using
    the `pip install 'magenta==1.1.7' --force-reinstall` command.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想尝试更新版本的 Magenta，只需在`pip`命令中去掉版本信息。这样，它将安装最新版本。如果使用更新版本时遇到问题，你可以使用`pip install
    'magenta==1.1.7' --force-reinstall`命令重新安装 1.1.7 版本。
- en: 'Then, test the installation by importing Magenta into a Python shell and printing
    the version:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过在 Python shell 中导入 Magenta 并打印版本来测试安装：
- en: '[PRE11]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Installing Magenta for GPU (optional)
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装适用于 GPU 的 Magenta（可选）
- en: Now that we have installed Magenta, we'll install Magenta for GPU, which is
    required for Magenta to execute on the GPU. This is optional if you don't have
    a GPU, are not planning to train any models, or want to use a cloud-based solution
    for training. Before continuing, we need to make sure our GPU is CUDA enabled
    with a compute capability greater than 3.0 by checking out NVIDIA's website: [developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了 Magenta，接下来我们将安装适用于 GPU 的 Magenta，这是让 Magenta 在 GPU 上执行所必需的。如果你没有
    GPU、没有计划训练模型，或希望使用基于云的训练解决方案，则可以选择不安装。继续之前，我们需要确保我们的 GPU 支持 CUDA，并且计算能力大于 3.0，检查方法是访问
    NVIDIA 网站：[developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)。
- en: On Windows, you need to download and install the Visual Studio Community IDE
    from [visualstudio.microsoft.com](https://visualstudio.microsoft.com/), which
    should install all the required dependencies for us.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，你需要从 [visualstudio.microsoft.com](https://visualstudio.microsoft.com/)
    下载并安装 Visual Studio Community IDE，它应该会为我们安装所有所需的依赖项。
- en: 'Then, for all platforms, follow these steps:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于所有平台，按照以下步骤进行操作：
- en: Download the **CUDA Toolkit** from [developer.nvidia.com/cuda-10.0-download-archive](https://developer.nvidia.com/cuda-10.0-download-archive)
    and launch the installation wizard using any of the provided installation methods.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [developer.nvidia.com/cuda-10.0-download-archive](https://developer.nvidia.com/cuda-10.0-download-archive)
    下载 **CUDA 工具包**，并使用提供的任何安装方法启动安装向导。
- en: During the CUDA driver's installation, you might get a message saying that "Your
    display drivers are more recent than the ones provided with this installation".
    This is normal since this CUDA version is not the latest. You can keep your current
    display drivers by selecting **CUDA drivers only**.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 CUDA 驱动程序时，可能会出现一条消息，提示“您的显示驱动程序比此安装包提供的驱动程序更新”。这是正常的，因为此 CUDA 版本不是最新的。您可以选择**仅安装
    CUDA 驱动程序**来保留当前的显示驱动程序。
- en: 'Now that CUDA has been installed, you might have to restart your computer to
    load the NVIDIA driver. You can test your installation by using the following
    command:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在 CUDA 已经安装完成，您可能需要重新启动计算机以加载 NVIDIA 驱动程序。您可以使用以下命令来测试您的安装是否成功：
- en: '[PRE12]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now, we need to install the **cuDNN library**, which is a toolkit for executing
    deep learning commands on the GPU with the CUDA driver. You should be able to
    use the most recent cuDNN version from [developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download)
    for CUDA 10.0\. Choose `Download cuDNN v7.6.x (...), for CUDA 10.0`.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要安装 **cuDNN 库**，它是一个用于在 GPU 上使用 CUDA 驱动程序执行深度学习命令的工具包。您应该能够从 [developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download)
    获取适用于 CUDA 10.0 的最新 cuDNN 版本。选择 `Download cuDNN v7.6.x (...)，for CUDA 10.0`。
- en: Make sure you use the `cuDNN Library for Platform` link so that we have the
    full library archive to work with (do not download the `.deb` file, for example).
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保使用 `cuDNN Library for Platform` 这个链接，以便我们可以获得完整的库存档进行操作（例如，不要下载 `.deb` 文件）。
- en: 'Once downloaded, we''ll have to copy the files from the proper location; see
    the following commands for each platform:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载后，我们需要从正确的位置复制文件；请查看每个平台的以下命令：
- en: 'Linux: [docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar)'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Linux: [docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar)'
- en: 'macOS: [docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-mac](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-mac)'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'macOS: [docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-mac](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-mac)'
- en: 'Windows: [docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows)'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Windows: [docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows)'
- en: 'Now, we are ready to install Magenta for GPU:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们准备好为 GPU 安装 Magenta 了：
- en: '[PRE13]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Check out the tip in the *Generating a basic MIDI file* section to verify TensorFlow
    is working properly with your GPU.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看 *生成基本 MIDI 文件* 部分的提示，以验证 TensorFlow 是否与您的 GPU 正常工作。
- en: Installing the music software and synthesizers
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装音乐软件和合成器
- en: During the course of this book, we'll be handling MIDI and audio files. Handling
    the MIDI files requires specific software that you should install now since you'll
    need it for the entirety of this book.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的过程中，我们将处理 MIDI 和音频文件。处理 MIDI 文件需要特定的软件，您现在应该安装它，因为在整个本书中您都会用到它。
- en: Installing the FluidSynth software synthesizer
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 FluidSynth 软件合成器
- en: A software synthesizer is a piece of software that will play incoming MIDI notes
    or MIDI files with virtual instruments from sound banks (called SoundFont) or
    by synthesizing audio using waveforms. We will need a software synthesizer to
    play the notes that are generated by our models.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 软件合成器是一个能够用虚拟乐器（来自音色库，即 SoundFont）或通过合成音频使用波形来播放输入的 MIDI 音符或 MIDI 文件的软件。我们将需要一个软件合成器来播放我们模型生成的音符。
- en: For this book, we'll be using FluidSynth, a powerful and cross-platform software
    synth available on the command line. We'll go through the installation procedure
    for each platform in this section.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书，我们将使用 FluidSynth，这是一款强大且跨平台的命令行软件合成器。本节将介绍每个平台的安装过程。
- en: Installing SoundFont
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 SoundFont
- en: 'The SoundFont installation is the same for all platforms. We''ll download and
    keep the SoundFont file in an easy-access location since we''ll need it throughout
    this book. Follow these steps:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: SoundFont 安装在所有平台上都是相同的。我们将下载并将 SoundFont 文件保存在一个便于访问的位置，因为我们将在本书中需要它。请按照以下步骤操作：
- en: Download SoundFont at [ftp.debian.org/debian/pool/main/f/fluid-soundfont/fluid-soundfont_3.1.orig.tar.gz](http://ftp.debian.org/debian/pool/main/f/fluid-soundfont/fluid-soundfont_3.1.orig.tar.gz).
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载 SoundFont 文件：[ftp.debian.org/debian/pool/main/f/fluid-soundfont/fluid-soundfont_3.1.orig.tar.gz](http://ftp.debian.org/debian/pool/main/f/fluid-soundfont/fluid-soundfont_3.1.orig.tar.gz)。
- en: Extract the `.tar.gz` file.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压 `.tar.gz` 文件。
- en: Copy the `FluidR3_GM.sf2` file to an easy-access location.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `FluidR3_GM.sf2` 文件复制到一个便于访问的位置。
- en: Installing FluidSynth
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 FluidSynth
- en: 'Unfortunately, for **Windows**, binaries are not maintained by the FluidSynth
    core team. Instead of building from the source, we''ll need to fetch the binaries
    from a GitHub project (the versions might be a bit behind the release schedule,
    though). Follow these steps:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，对于**Windows**，FluidSynth 核心团队没有维护二进制文件。我们需要从 GitHub 项目中获取二进制文件（尽管这些版本可能略微滞后于发布计划）。请按照以下步骤操作：
- en: Download the zip at [github.com/JoshuaPrzyborowski/FluidSynth-Windows-Builds/archive/master.zip](https://github.com/JoshuaPrzyborowski/FluidSynth-Windows-Builds/archive/master.zip).
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载 [github.com/JoshuaPrzyborowski/FluidSynth-Windows-Builds/archive/master.zip](https://github.com/JoshuaPrzyborowski/FluidSynth-Windows-Builds/archive/master.zip)
    的压缩包。
- en: Unzip the file and navigate to the `bin64` folder.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压文件并进入 `bin64` 文件夹。
- en: Copy the `fluidsynth-2.0.x` folder (containing the latest version of FluidSynth)
    to an easy-access location.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `fluidsynth-2.0.x` 文件夹（包含最新版本的 FluidSynth）复制到一个便于访问的位置。
- en: Copy the content of the `fluidsynth-required-dlls` file to `C:\Windows\System32`.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `fluidsynth-required-dlls` 文件的内容复制到 `C:\Windows\System32`。
- en: Add FluidSynth to `PATH` by going to `Control Panel > System > Advanced system
    settings > Environment Variables... > Path > Edit... > New` and add the `bin` folder
    from the copied folder from *step 3*.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过进入 `控制面板 > 系统 > 高级系统设置 > 环境变量... > Path > 编辑... > 新建` 来将 FluidSynth 添加到 `PATH`，然后添加步骤
    3 中复制的文件夹的 `bin` 文件夹。
- en: For **Linux**, most distributions maintain a FluidSynth package. Here, we're
    providing the installation instruction for Debian-based distributions. Refer to
    your package manager for other distributions. In a Terminal, use the `sudo apt
    install fluidsynth` command to download FluidSynth.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**Linux**，大多数发行版都维护着 FluidSynth 包。在这里，我们提供针对基于 Debian 的发行版的安装说明。对于其他发行版，请参考你的包管理器。在终端中，使用
    `sudo apt install fluidsynth` 命令来下载 FluidSynth。
- en: For **MacOS X**, we'll be using Homebrew to install FluidSynth. Before starting,
    make sure you have the latest Homebrew version. In a Terminal, use the `brew install
    fluidsynth` command to download FluidSynth.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 **MacOS X**，我们将使用 Homebrew 安装 FluidSynth。在开始之前，请确保你已安装了最新版本的 Homebrew。在终端中，使用
    `brew install fluidsynth` 命令来下载 FluidSynth。
- en: Testing your installation
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试你的安装
- en: 'Now, you can test your FluidSynth installation (do this by replacing `PATH_SF2`
    with the path to the SoundFont we installed previously):'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以测试你的 FluidSynth 安装（通过将 `PATH_SF2` 替换为我们之前安装的 SoundFont 路径）：
- en: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2`'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2`'
- en: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2`'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2`'
- en: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2`'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2`'
- en: 'You should see an output similar to the following, without any errors:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到类似以下的输出，且没有任何错误：
- en: '[PRE14]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Using a hardware synthesizer (optional)
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用硬件合成器（可选）
- en: Instead of using a software synthesizer, you could use a hardware synthesizer
    to listen to your generated MIDI files. We'll look at this in more detail in [Chapter
    9](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml), *Making Magenta Interact with
    Music Applications*, but you can already plug the synthesizer into your computer
    via USB; the device should register as a new input MIDI port. This port can be
    used by Magenta to send incoming MIDI notes.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用软件合成器，你还可以使用硬件合成器来聆听生成的 MIDI 文件。我们将在[第9章](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml)《让
    Magenta 与音乐应用程序互动》中更详细地讲解这一点，但你可以通过 USB 将合成器连接到电脑；该设备应该会作为一个新的输入 MIDI 端口注册。Magenta
    可以使用这个端口来发送传入的 MIDI 音符。
- en: Installing Audacity as a digital audio editor (optional)
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Audacity 作为数字音频编辑器（可选）
- en: We won't be handling audio until [Chapter 5](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml),
    *Audio Generation with NSynth and GANSynth*, so you can wait until that chapter
    to install Audacity. Audacity is an amazing open source cross-platform (Windows,
    Linux, macOS) software for editor audio clips. It doesn't have the functionality
    of a Digital Audio Workstation (see the *Installing a Digital Audio Workstation* section
    for more on this), but it is easy to use and powerful.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会处理音频，直到 [第 5 章](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml)，*使用 NSynth 和
    GANSynth 生成音频*，所以你可以等到那一章再安装 Audacity。Audacity 是一款出色的开源跨平台（Windows、Linux、macOS）音频剪辑编辑软件。它没有数字音频工作站的全部功能（有关更多信息，请参见*安装数字音频工作站*部分），但它易于使用且功能强大。
- en: 'Audacity can be used to easily record audio, cut and split audio clips, add
    simple effects, do simple equalization, and export various formats:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Audacity 可用于轻松录制音频、剪切和拆分音频片段、添加简单效果、进行简单的均衡调整，并导出各种格式：
- en: '![](img/5ba1f748-93eb-462c-ac14-8bc2a69726ea.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ba1f748-93eb-462c-ac14-8bc2a69726ea.png)'
- en: We'll be explaining how to use Audacity in [Chapter 5](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml),
    *Audio Generation with NSynth and GANSynth*.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 [第 5 章](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml)，*使用 NSynth 和 GANSynth
    生成音频* 中详细解释如何使用 Audacity。
- en: Installing MuseScore for sheet music (optional)
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 MuseScore 用于乐谱（可选）
- en: Throughout this book, we'll be working with sheet music a lot, especially MIDI.
    We'll have command-line utilities to generate still images representing the score,
    but it is useful to see and edit the sheet music in a GUI, as well as listen to
    them with digital instruments. Take note that MuseScore cannot play live MIDI,
    so it is different from a software synthesizer. It also doesn't work well with
    expressive timing (where the notes do not fall on the beginning and end steps).
    We'll make note of when not to use MuseScore in the next chapter.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将大量使用乐谱，尤其是 MIDI。我们将使用命令行工具生成表示乐谱的静态图像，但在 GUI 中查看和编辑乐谱并使用数字乐器播放它们也是非常有用的。请注意，MuseScore
    无法播放实时 MIDI，因此它与软件合成器不同。它也不太适用于表现性节奏（即音符不在开始和结束的精确时刻）。我们将在下一章中说明何时不使用 MuseScore。
- en: MuseScore is a good and free notation software available at [musescore.org](https://musescore.org)
    and works on all platforms. You can install it now if you want, or wait until
    later when you need it.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: MuseScore 是一款免费的优秀乐谱软件，网址为 [musescore.org](https://musescore.org)，适用于所有平台。如果你愿意，现在就可以安装，或者等到需要时再安装。
- en: 'MuseScore also doubles down as a collaborative sheet music database at [musescore.com](https://musescore.com),
    which we''ll use throughout this book:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: MuseScore 还充当了一个协作的乐谱数据库，网址为 [musescore.com](https://musescore.com)，我们将在本书中贯穿使用：
- en: '![](img/b61b9e6b-80b5-4f0d-afac-38d7cacdb56f.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b61b9e6b-80b5-4f0d-afac-38d7cacdb56f.png)'
- en: Installing a Digital Audio Workstation (optional)
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装数字音频工作站（可选）
- en: Installing a DAW is not necessary for this book, except for [Chapter 9](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml),
    *Making Magenta Interact with Music Applications*. Such software comes in various
    forms and complexity and is important in music production in general since it
    can handle all the necessities of music production, such as audio and MIDI handling,
    composition, effects, mastering, VSTs, and so on.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不需要安装 DAW，除非是 [第 9 章](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml)，*让 Magenta
    与音乐应用程序互动*。这类软件有不同的形式和复杂性，并且在音乐制作中非常重要，因为它能处理音乐制作的所有必要任务，如音频和 MIDI 处理、作曲、效果、母带处理、VST
    插件等。
- en: Ardour ([ardour.org](https://ardour.org)) is the only open source and cross-platform
    DAW available and requires you to pay a small fee for a pre-built version of the
    software. Depending on your platform, you might want to try different DAWs. On
    Linux, you can go with Ardour. On macOS and Windows, you can use Ableton Live,
    a well-established DAW. We won't be recommending any specific software for this
    part, so you can go with whatever you are used to. In [Chapter 9](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml),
    *Making Magenta Interact with Music Applications*, we'll go into more detail by
    giving specific examples for specific DAWs, so you can wait until then to install
    a new one.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Ardour ([ardour.org](https://ardour.org)) 是唯一一款开源且跨平台的 DAW，它要求你为预构建版本支付一小笔费用。根据你的平台，你可能想尝试不同的
    DAW。在 Linux 上，你可以使用 Ardour；在 macOS 和 Windows 上，你可以使用 Ableton Live，这是一款成熟的 DAW。我们不会为这一部分推荐任何特定软件，因此你可以使用任何你习惯的软件。在
    [第 9 章](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml)，*让 Magenta 与音乐应用程序互动* 中，我们会通过具体例子详细介绍各个
    DAW，因此你可以等到那时再安装新的 DAW。
- en: Installing the code editing software
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装代码编辑软件
- en: In this section, we'll recommend optional software regarding code editing. While
    not mandatory, it might help considerably to use them, especially for newcomers,
    for whom plain code editing software can be daunting.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将推荐一些关于代码编辑的可选软件。虽然不是必需的，但对于初学者来说，使用这些软件会有很大帮助，因为纯文本代码编辑软件可能让他们感到困惑。
- en: Installing Jupyter Notebook (optional)
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Jupyter Notebook（可选）
- en: Notebooks are a great way of sharing code that contains text, explanations,
    figures, and other rich content. It is used extensively in the data science community
    because it can store and display the result of long-running operations, while
    also providing a dynamic runtime to edit and execute the content in.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Notebooks 是一种很好的方式来共享包含文本、解释、图表和其他丰富内容的代码。它在数据科学社区中被广泛使用，因为它可以存储和显示长时间运行操作的结果，同时还提供一个动态的运行时环境，以便编辑和执行内容。
- en: The code for this book is available on GitHub as plain Python code, but also
    in the form of Jupyter Notebooks. Each chapter will have its own notebook that
    serves as an example.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码可以在 GitHub 上以普通 Python 代码的形式获得，也可以以 Jupyter Notebook 的形式提供。每个章节都有一个自己的笔记本，作为示例。
- en: 'To install Jupyter and launch your first notebook, follow these steps:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 Jupyter 并启动你的第一个笔记本，请按照以下步骤操作：
- en: 'While in the Magenta environment, execute the following command:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Magenta 环境中，执行以下命令：
- en: '[PRE15]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we can start the Jupyter server by executing the following command (also
    while in the Magenta environment):'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过执行以下命令来启动 Jupyter 服务器（也是在 Magenta 环境中执行）：
- en: '[PRE16]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The Jupyter interface will be shown in a web browser. The previous command should
    have launched your default browser. If not, use the URL in the output of the command
    to open it.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 界面将在 Web 浏览器中显示。之前的命令应该已经启动了默认浏览器。如果没有，请使用命令输出中的 URL 打开它。
- en: Once in the notebook UI, you should see your disk content. Navigate to the code
    for this book and load the notebook from `Chapter01/notebook.ipynb`.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入笔记本 UI 后，你应该能看到磁盘内容。导航到本书的代码并加载 `Chapter01/notebook.ipynb` 笔记本。
- en: Make sure the selected kernel is **Python 3**. This kernel corresponds to the
    Python interpreter that's been installed in your Magenta environment.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保选择的内核是 **Python 3**。这个内核对应于已经安装在你 Magenta 环境中的 Python 解释器。
- en: Run the code blocks using the **Run** button for each cell. This will make sure
    that Jupyter executes in a proper environment by printing the TensorFlow and Magenta
    versions.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **运行** 按钮运行每个单元的代码块。这将确保 Jupyter 在正确的环境中执行，并通过打印 TensorFlow 和 Magenta 的版本来验证。
- en: 'This is what the notebook should look like:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这是笔记本应该显示的样子：
- en: '![](img/b0e9fce6-c40a-4eb1-aadc-acb4e4e9510d.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b0e9fce6-c40a-4eb1-aadc-acb4e4e9510d.png)'
- en: Installing and configuring an IDE (optional)
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和配置 IDE（可选）
- en: The usage of an **Integrated Development Environment** (**IDE**) is not necessary
    for this book since all the examples run from the command line. However, an IDE
    is a good tool to use since it provides autocompletion, integrated development
    tools, refactoring options, and more. It is also really useful for debugging since
    you can step into the code directly.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 本书并不要求必须使用 **集成开发环境**（**IDE**），因为所有示例都可以从命令行运行。然而，IDE 是一个很好的工具，因为它提供了自动补全、集成开发工具、重构选项等功能。它在调试时也非常有用，因为你可以直接进入代码进行调试。
- en: A good IDE for this book is JetBrains's PyCharm ([www.jetbrains.com/pycharm](https://www.jetbrains.com/pycharm)),
    a Python IDE with a community (open source) edition that provides everything you
    need.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 本书推荐的一个好 IDE 是 JetBrains 的 PyCharm（[www.jetbrains.com/pycharm](https://www.jetbrains.com/pycharm)），这是一个
    Python IDE，提供社区版（开源版），它提供了你所需要的一切。
- en: Whether you use PyCharm or another IDE, you'll need to change Python interpreter
    to the one we installed previously. This is the equivalent of activating our Magenta
    environment using Conda. In the project settings in the IDE, find the Python interpreter
    settings and change it to the installation path of our environment.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用 PyCharm 还是其他 IDE，都需要将 Python 解释器更改为我们之前安装的那个。这相当于使用 Conda 激活我们的 Magenta
    环境。在 IDE 的项目设置中，找到 Python 解释器设置，并将其更改为我们环境的安装路径。
- en: 'If you don''t remember its location, use the following commands:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你忘记了它的位置，可以使用以下命令：
- en: '[PRE17]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: On Windows, the Python interpreter is in the root folder, while on Linux or
    macOS, it is in the `bin` directory under it.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，Python 解释器位于根文件夹，而在 Linux 或 macOS 上，它位于根目录下的 `bin` 目录中。
- en: Generating a basic MIDI file
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成基本的 MIDI 文件
- en: 'Magenta comes with multiple command-line scripts (installed in the `bin` folder
    of your Magenta environment). Basically, each model has its own console script
    for dataset preparation, model training, and generation. Let''s take a look:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 提供了多个命令行脚本（安装在 Magenta 环境的 `bin` 文件夹中）。基本上，每个模型都有自己的控制台脚本，用于数据集准备、模型训练和生成。让我们来看看：
- en: 'While in the Magenta environment, download the Drums RNN pre-trained model, `drum_kit_rnn`:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Magenta 环境中，下载 Drums RNN 预训练模型 `drum_kit_rnn`：
- en: '[PRE18]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, use the following command to generate your first few MIDI files:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用以下命令生成你的第一个几个 MIDI 文件：
- en: '[PRE19]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: By default, the preceding command generates the files in `/tmp/drums_rnn/generated` (on
    Windows `C:\tmp\drums_rnn\generated`). You should see 10 new MIDI files, along
    with timestamps and a generation index.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，前面的命令会在 `/tmp/drums_rnn/generated` 目录生成文件（在 Windows 上是 `C:\tmp\drums_rnn\generated`）。你应该会看到
    10 个新的 MIDI 文件，以及时间戳和生成索引。
- en: 'If you are using a GPU, you can verify if TensorFlow is using it properly by
    searching for "Created TensorFlow device ... -> **physical GPU** (name: ..., compute
    capability: ...)" in the output of the script. If it''s not there, this means
    it is executing on your CPU.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你正在使用 GPU，可以通过在脚本输出中搜索“Created TensorFlow device ... -> **physical GPU**
    (name: ..., compute capability: ...)”来验证 TensorFlow 是否正确使用了它。如果没有找到，说明它正在你的 CPU
    上执行。'
- en: You can also check your GPU usage while Magenta is executing, which should go
    up if Magenta is using the GPU properly.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在 Magenta 执行时检查 GPU 的使用情况，如果 Magenta 正确使用 GPU，这个值应该会增加。
- en: 'Finally, to listen to the generated MIDI, use your software synthesizer or
    MuseScore. For the software synth, refer to the following command, depending on
    your platform, and replace `PATH_TO_SF2` and `PATH_TO_MIDI` with the proper values:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，为了听到生成的 MIDI，你可以使用软件合成器或 MuseScore。对于软件合成器，请根据你的平台参考以下命令，并将 `PATH_TO_SF2`
    和 `PATH_TO_MIDI` 替换为正确的值：
- en: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: Congratulations! You have generated your first musical score using a machine
    learning model! You'll learn how to generate much more throughout this book.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经使用机器学习模型生成了你的第一个音乐乐谱！你将在本书中学到如何生成更多的内容。
- en: Summary
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter is important because it introduces the basic concepts of music
    generation with machine learning, all of which we'll build upon throughout this
    book.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 本章很重要，因为它介绍了使用机器学习生成音乐的基本概念，所有这些内容将在本书中进一步展开。
- en: 'In this chapter, we learned what generative music is and that its origins predate
    even the advent of computers. By looking at specific examples, we saw different
    types of generative music: random, algorithmic, and stochastic.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了什么是生成音乐，并且它的起源甚至早于计算机的出现。通过查看具体示例，我们看到了不同类型的生成音乐：随机的、算法的和随机过程的。
- en: We also learned how machine learning is rapidly transforming how we generate
    music. By introducing music representation and various processes, we learned about
    MIDI, waveforms, and spectrograms, as well as various neural network architectures
    we'll get to look at throughout this book.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了机器学习如何快速改变我们生成音乐的方式。通过引入音乐表示和各种处理方法，我们了解了 MIDI、波形和频谱图，以及本书中将要接触的各种神经网络架构。
- en: Finally, we saw an overview of what we can do with Magenta in terms of generating
    and processing image, audio, and score. By doing that, we introduced the primary
    models we'll be using throughout this book; that is, Drums RNN, Melody RNN, MusicVAE,
    NSynth, and others.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们回顾了在生成和处理图像、音频以及乐谱方面，Magenta 可以做些什么。通过这些内容，我们介绍了本书中将要使用的主要模型，即 Drums RNN、Melody
    RNN、MusicVAE、NSynth 等。
- en: You also installed your development environment for this book and generated
    your first musical score. Now, we're ready to go!
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 你还为本书安装了开发环境，并生成了你的第一个音乐乐谱。现在，我们准备开始了！
- en: The next chapter will delve deeper into some of the concepts we introduced in
    this chapter. We'll explain what an RNN is and why it is important for music generation.
    Then, we'll use the Drums RNN model on the command line and in Python while explaining
    its inputs and outputs. We'll finish by creating the first building block of our
    autonomous music generating system.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将深入探讨我们在本章中介绍的一些概念。我们将解释什么是RNN，以及它在音乐生成中的重要性。然后，我们将在线命令行和Python中使用Drums RNN模型，并解释其输入和输出。最后，我们将创建我们自主音乐生成系统的第一个构建模块。
- en: Questions
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: On what generative principle does the *musical dice game* rely upon?
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*音乐骰子游戏*依赖于什么生成原理？'
- en: What stochastic-based generation technique was used in the first computerized
    generative piece of music, *Illiac Suite*?
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一部计算机生成的音乐作品《*Illiac Suite*》中，使用了什么基于随机的生成技术？
- en: What is the name of the music genre where a live coder implements generative
    music on the scene?
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现场程序员在现场实现生成音乐的音乐类型叫什么名字？
- en: What model structure is important for tracking temporally distant events in
    a musical score?
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么样的模型结构对于追踪音乐乐谱中时间上相距较远的事件很重要？
- en: What is the difference between autonomous and assisting music systems?
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自主音乐系统和辅助音乐系统有什么区别？
- en: What are examples of symbolic and sub-symbolic representations?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是符号表示和子符号表示的例子？
- en: How is a note represented in MIDI?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 音符在MIDI中是如何表示的？
- en: What frequency range can be represented without loss at a sample rate of 96
    kHz? Is it better for listening to audio?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在96 kHz的采样率下，能表示哪些频率范围而不会失真？这对听音频有帮助吗？
- en: In a spectrogram, a block of 1 second of intense color at 440 Hz is shown. What
    is being played?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在频谱图中，440 Hz频率处显示一个1秒钟的强烈颜色块。这代表着什么音符？
- en: What different parts of a musical score can be generated with Magenta?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Magenta可以生成音乐乐谱中的哪些不同部分？
- en: Further reading
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**Ten Questions Concerning Generative Computer Art:** An interesting paper
    (2012) on generative computer art ([users.monash.edu/~jonmc/research/Papers/TenQuestionsLJ-Preprint.pdf](http://users.monash.edu/~jonmc/research/Papers/TenQuestionsLJ-Preprint.pdf)).'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关于生成计算机艺术的十个问题：** 一本关于生成计算机艺术的有趣论文（2012年） ([users.monash.edu/~jonmc/research/Papers/TenQuestionsLJ-Preprint.pdf](http://users.monash.edu/~jonmc/research/Papers/TenQuestionsLJ-Preprint.pdf))。'
- en: '**Pulse Code Modulation (PCM):** A short introduction to PCM ([www.technologyuk.net/telecommunications/telecom-principles/pulse-code-modulation.shtml](https://www.technologyuk.net/telecommunications/telecom-principles/pulse-code-modulation.shtml)).'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脉冲编码调制（PCM）：** 简短的PCM介绍 ([www.technologyuk.net/telecommunications/telecom-principles/pulse-code-modulation.shtml](https://www.technologyuk.net/telecommunications/telecom-principles/pulse-code-modulation.shtml))。'
- en: '**Making Music with Computers:** A good introduction to the sampling theory
    and the Nyquist frequency ([legacy.earlham.edu/~tobeyfo/musictechnology/4_SamplingTheory.html](http://legacy.earlham.edu/~tobeyfo/musictechnology/4_SamplingTheory.html)).'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用计算机制作音乐：** 这是一本关于采样理论和奈奎斯特频率的良好入门书籍 ([legacy.earlham.edu/~tobeyfo/musictechnology/4_SamplingTheory.html](http://legacy.earlham.edu/~tobeyfo/musictechnology/4_SamplingTheory.html))。'
- en: '**SketchRNN model released in Magenta:** A blog post from the Magenta team
    on SketchRNN, with a link to the corresponding paper ([magenta.tensorflow.org/sketch_rnn](https://magenta.tensorflow.org/sketch_rnn)).'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Magenta中发布的SketchRNN模型：** Magenta团队发布的一篇关于SketchRNN的博客文章，并附有相应论文的链接 ([magenta.tensorflow.org/sketch_rnn](https://magenta.tensorflow.org/sketch_rnn))。'
- en: '**Creation by refinement: a creativity paradigm for gradient descent learning
    networks:** An early paper (1988) on generating content using a gradient-descent
    search ([ieeexplore.ieee.org/document/23933](https://ieeexplore.ieee.org/document/23933)).'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过改进创造：梯度下降学习网络的创造力范式：** 一本关于使用梯度下降搜索生成内容的早期论文（1988年） ([ieeexplore.ieee.org/document/23933](https://ieeexplore.ieee.org/document/23933))。'
- en: '**A First Look at Music Composition using LSTM Recurrent Neural Networks:** An
    important paper (2002) on generating music using LSTM ([www.semanticscholar.org/paper/A-First-Look-at-Music-Composition-using-LSTM-Neural-Eck-Schmidhuber/3b70fbcd6c0fdc7697c93d0c3fb845066cf34487](https://www.semanticscholar.org/paper/A-First-Look-at-Music-Composition-using-LSTM-Neural-Eck-Schmidhuber/3b70fbcd6c0fdc7697c93d0c3fb845066cf34487)).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用LSTM递归神经网络进行音乐创作初探：** 一本关于使用LSTM生成音乐的重要论文（2002年） ([www.semanticscholar.org/paper/A-First-Look-at-Music-Composition-using-LSTM-Neural-Eck-Schmidhuber/3b70fbcd6c0fdc7697c93d0c3fb845066cf34487](https://www.semanticscholar.org/paper/A-First-Look-at-Music-Composition-using-LSTM-Neural-Eck-Schmidhuber/3b70fbcd6c0fdc7697c93d0c3fb845066cf34487))。'
- en: '**ImageNet Classification with Deep Convolutional Neural Networks:** The AlexNet
    paper, one of the most influential papers that was published in computer vision
    ([papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)).'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用深度卷积神经网络进行ImageNet分类：** AlexNet论文，计算机视觉领域最具影响力的论文之一（[papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)）。'
- en: '**WaveNet: A Generative Model for Raw Audio:** A paper (2016) on WaveNet ([arxiv.org/abs/1609.03499](https://arxiv.org/abs/1609.03499)).'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WaveNet: 一种原始音频生成模型：** 一篇关于WaveNet的论文（2016年）（[arxiv.org/abs/1609.03499](https://arxiv.org/abs/1609.03499)）。'
- en: '**DeepBach: a Steerable Model for Bach Chorales Generation:** A paper (2016)
    on Bach-like polyphonic music generation ([arxiv.org/abs/1612.01010](https://arxiv.org/abs/1612.01010)).'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeepBach: 一种可操控的巴赫合唱生成模型：** 一篇关于生成巴赫风格的复调音乐的论文（2016年）（[arxiv.org/abs/1612.01010](https://arxiv.org/abs/1612.01010)）。'
- en: '**SampleRNN: An Unconditional End-to-End Neural Audio Generation Model:** A
    paper (2017) on generating audio ([arxiv.org/abs/1612.07837](https://arxiv.org/abs/1612.07837)).'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SampleRNN: 一种无条件端到端神经音频生成模型：** 一篇关于生成音频的论文（2017年）（[arxiv.org/abs/1612.07837](https://arxiv.org/abs/1612.07837)）。'
