- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: 'Cloud Computing Meets Generative AI: Bridging Infinite Impossibilities'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云计算与生成式AI的相遇：连接无限可能
- en: During the last few decades, we have seen unprecedented progress in the world
    of **artificial intelligence** (**AI**) and **machine learning** (**ML**) due
    to the rise of computing, especially cloud computing, and the massive influx of
    data from the digital revolution. In 2022, the subset of AI known as generative
    AI emerged as a significant turning point. We have surpassed an inflection point
    in AI and we believe this will boost incredible productivity and growth in society
    in the coming years. This is the field of conversational AI powered by **large
    language models** (**LLMs**), a fascinating paradigm where computers learn and
    generate human-like text, images, audio, and video, engaging with us in increasingly
    interactive and intelligent ways. The transformative potential of LLMs, epitomized
    by models, such as OpenAI’s GPT-based ChatGPT, marks a major shift in how we interact
    with technology. Generative AI models now have improved accuracy and effectiveness.
    Use cases that were unattainable for non-technical users in businesses a couple
    of years ago are now readily implementable. Additionally, the easy availability
    of open source models, which can be tailored to specific business requirements,
    coupled with access to high-performance GPUs via cloud computing, has played a
    crucial role in propelling the advancement of generative AI.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年里，由于计算（尤其是云计算）的兴起以及数字革命带来的大量数据涌入，人工智能（AI）和机器学习（ML）领域取得了前所未有的进步。2022年，被称为生成式AI的AI子集成为了一个重要的转折点。我们已经超过了AI的一个拐点，我们相信这将在未来几年中极大地提高社会生产力和增长。这是由大型语言模型（LLMs）驱动的对话式AI领域，这是一个令人着迷的范例，其中计算机学习并生成类似人类的文本、图像、音频和视频，以越来越互动和智能的方式与我们互动。以OpenAI的基于GPT的ChatGPT等模型为代表的LLMs的变革潜力，标志着我们与技术互动方式的重大转变。生成式AI模型现在具有更高的准确性和有效性。几年前对非技术用户来说难以触及的业务用例现在可以轻松实现。此外，开源模型的易于获取，可以根据特定业务需求进行定制，以及通过云计算访问高性能GPU，在推动生成式AI的进步中发挥了关键作用。
- en: This chapter aims to provide a comprehensive introduction to conversational
    and generative AI and delve into its fundamentals and powerful capabilities. ChatGPT,
    a very powerful conversational AI agent, is built on an LLM; hence, to fully understand
    how ChatGPT works and to learn how to implement it in your applications or services
    to harness its power, it’s necessary to understand the evolution of conversational
    AI systems and the broader context of LLMs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在全面介绍对话式和生成式AI，并深入探讨其基础和强大功能。ChatGPT是一个非常强大的对话式AI代理，它基于大型语言模型（LLM）；因此，为了完全理解ChatGPT的工作原理，以及学习如何在您的应用程序或服务中实现它以利用其力量，了解对话式AI系统的演变以及LLM的更广泛背景是必要的。
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Evolution of conversation AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对话式AI的演变
- en: Introduction to generative AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI简介
- en: Trending models and business applications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 热门模型和商业应用
- en: 'Deep dive: open source vs closed source models'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨：开源模型与闭源模型
- en: Cloud computing for scalability, cost optimization, and automation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云计算用于可扩展性、成本优化和自动化
- en: 'From vision to value: navigating the journey to production'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从愿景到价值：导航生产之旅
- en: Evolution of conversation AI
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对话式AI的演变
- en: Understanding the evolution of conversational AI is crucial for learning generative
    AI as it provides foundational knowledge and context. This historical perspective
    reveals how AI technologies have progressed from simple, rule-based systems to
    complex machine learning and deep learning models that are core to both conversational
    and generative AI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 理解对话式AI的演变对于学习生成式AI至关重要，因为它提供了基础知识和背景。这一历史视角揭示了人工智能技术是如何从简单的基于规则的系统发展到复杂的机器学习和深度学习模型，这些模型是对话式和生成式AI的核心。
- en: This section explores the evolution of conversational AI, culminating in an
    in-depth look at LLMs, the technological backbone of contemporary chatbots.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了对话式AI的演变，最终深入探讨了LLM，这是当代聊天机器人的技术支柱。
- en: What is conversational AI?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是对话式AI？
- en: 'Conversational AI refers to technologies that enable machines to engage in
    human-like dialogue, comprehend complex commands, and respond intelligently. This
    is achieved through machine learning and natural language processing capabilities,
    enabling the system to learn, understand, and improve over time. The following
    figure demonstrates one such conversation:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式人工智能指的是使机器能够进行类似人类的对话、理解复杂命令并智能回应的技术。这是通过机器学习和自然语言处理能力实现的，使系统能够随着时间的推移进行学习、理解和改进。以下图展示了这样一个对话示例：
- en: '![Figure 1.1 – Conversations with Alexa](img/B21443_01_1.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1 – 与 Alexa 的对话](img/B21443_01_1.jpg)'
- en: Figure 1.1 – Conversations with Alexa
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 与 Alexa 的对话
- en: For instance, a customer interacts with a conversational AI to book a flight.
    They might say, “I’d like a flight to New York next Friday.” The system comprehends
    the request, asks for any further specific details (such as departure city or
    preferred time), and delivers the results, all without human intervention.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，客户与对话式人工智能互动以预订航班。他们可能会说：“我想要下周五去纽约的航班。”系统理解请求，询问任何进一步的详细信息（例如出发城市或首选时间），并交付结果，整个过程无需人工干预。
- en: Some popular conversational AI systems include Microsoft’s Cortana, Amazon Alexa,
    Apple’s Siri, and Google Assistant, which can respond to complex commands and
    respond intelligently.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一些流行的对话式人工智能系统包括微软的 Cortana、亚马逊的 Alexa、苹果的 Siri 和谷歌助手，它们可以响应复杂的命令并智能地做出回应。
- en: Evolution of conversational AI
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话式人工智能的演变
- en: 'Exploring the evolution of conversational AI, from rule-based chatbots to AI-powered
    systems, is vital as it offers historical context, highlights the technological
    advancements from the 1960s and the historical challenges, and sets the stage
    for understanding how LLMs have revolutionized natural language interactions.
    The following figure depicts the conversational AI timeline:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 探索对话式人工智能的演变，从基于规则的聊天机器人到人工智能驱动的系统，至关重要，因为它提供了历史背景，突出了从 1960 年代以来的技术进步和历史挑战，并为理解大型语言模型如何革命性地改变自然语言交互奠定了基础。以下图展示了对话式人工智能的时间线：
- en: '![Figure 1.2 – Timeline showing the evolution of chatbots](img/B21443_01_2.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2 – 展示聊天机器人演变的时序图](img/B21443_01_2.jpg)'
- en: Figure 1.2 – Timeline showing the evolution of chatbots
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – 展示聊天机器人演变的时序图
- en: Rule-based chatbots
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于规则的聊天机器人
- en: Chatbots that were initially developed during the 1960s operated on a rule-based
    system. Eliza, the first chatbot software, was created by Joseph Weizenbaum at
    MIT’s Artificial Intelligence Laboratory in 1966\. It used pattern matching and
    substitution technology. Users interacted with Eliza through a text-based platform,
    with the chatbot’s responses being based on scripted templates. Like Eliza, the
    first-generation chatbots were rule-based. They utilized pattern-matching techniques
    to align user inputs with predetermined responses. The chatbot’s conversation
    flows were mapped out by developers who decided how it should respond to anticipated
    customer inquiries. Responses were formulated based on predefined rules and written
    in languages such as **artificial intelligence markup language** (**AIML**), Rivescript,
    Chatscript, and others. These chatbots, typically used as FAQ agents, could answer
    simple questions or common queries about a specific situation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最初在 1960 年代开发的聊天机器人基于规则系统。第一个聊天机器人软件 Eliza 是由麻省理工学院人工智能实验室的约瑟夫·魏岑鲍姆在 1966 年创建的。它使用了模式匹配和替换技术。用户通过基于文本的平台与
    Eliza 互动，聊天机器人的回应基于脚本模板。与 Eliza 一样，第一代聊天机器人是基于规则的。它们使用模式匹配技术将用户输入与预定的响应对齐。聊天机器人的对话流程由开发者绘制，他们决定如何对预期的客户查询做出回应。响应是根据预定义的规则制定的，并使用如**人工智能标记语言**（**AIML**）、Rivescript、Chatscript
    等语言编写。这些聊天机器人通常用作常见问题解答代理，可以回答简单的问题或关于特定情况的一般查询。
- en: 'However, rule-based systems had significant limitations:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，基于规则的系统存在重大局限性：
- en: Rule-based systems required manual design, forcing developers to program each
    response
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 基于规则的系统需要手动设计，迫使开发者编写每个响应的代码
- en: They were effective only in the scenarios for which they were specifically trained
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 它们只在特定训练的场景中有效
- en: It was difficult for developers to anticipate and program all possible responses
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者很难预测并编写所有可能的响应
- en: These chatbots were unable to identify grammatical or syntactic errors in user
    inputs, often resulting in misunderstandings
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些聊天机器人无法识别用户输入中的语法或句法错误，通常导致误解
- en: They were unable to learn from interactions or generate new responses, limiting
    their adaptability and intelligence
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 它们无法从交互中学习或生成新的响应，这限制了它们的适应性和智能。
- en: Despite their speed, the inability to understand context or user intents made
    interactions feel mechanical rather than conversational
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们速度快，但无法理解上下文或用户意图，使得交互感觉像机械式的而不是对话式的。
- en: This mechanical interaction often led to user frustration with systems that
    failed to accurately understand and meet their needs
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机械式的交互往往导致用户对无法准确理解和满足其需求的系统感到沮丧。
- en: Over time, there has been a significant increase in demand for intelligent,
    real-time, and personalized interactions in customer support services. As a result,
    rule-based chatbots have evolved into AI-powered chatbots that offer advanced
    features such as human-like voice, intent extraction, sentiment analysis, contextual
    semantic search, grammatical analysis, learning over time, and scalability to
    allow for seamless integration with more demanding applications and services.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，对智能、实时和个性化客户支持服务的需求显著增加。因此，基于规则的聊天机器人已经演变成由AI驱动的聊天机器人，它们提供高级功能，如类似人类的语音、意图提取、情感分析、上下文语义搜索、语法分析、随时间学习以及可扩展性，以便与更复杂的应用和服务无缝集成。
- en: LLM-powered chatbots – multimodal, context-aware, and agent-based
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 由LLM驱动的聊天机器人——多模态、上下文感知和基于代理的。
- en: In contrast to rule-based systems, AI-based systems utilize natural language
    processing to facilitate natural conversations and extract context from user inputs.
    They can also learn from past interactions aka context. Recently, deep learning
    has significantly advanced conversational AI, even surpassing human performance
    in some tasks, attributed to its incredible reasoning engine. This has decreased
    the reliance on extensive linguistic knowledge and rule-based techniques when
    building language services. As a result, AI-based systems have seen widespread
    adoption across various industries, including media, entertainment, telecommunications,
    finance, healthcare, and retail, to name a few.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于规则的系统相比，基于AI的系统利用自然语言处理来促进自然对话并从用户输入中提取上下文。它们还可以从过去的交互中学习，即上下文。最近，深度学习在对话式人工智能方面取得了显著进步，甚至在某些任务上超过了人类的表现，这归功于其令人难以置信的推理引擎。这减少了在构建语言服务时对广泛的语言知识和基于规则的技术的依赖。因此，基于AI的系统在各个行业得到了广泛应用，包括媒体、娱乐、电信、金融、医疗保健和零售等行业，仅举几例。
- en: 'Current conversational AI systems, leveraging LLMs such as GPT-4-Turbo, differ
    significantly from traditional rule-based systems in their approach and capabilities:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当前利用LLM如GPT-4-Turbo的对话式人工智能系统，在方法和能力上与传统基于规则的系统有显著差异：
- en: While rule-based systems rely on predefined rules and responses, limiting them
    to specific, anticipated interactions, LLMs harness extensive datasets and advanced
    reasoning abilities to produce responses that are not only natural and varied
    but also highly context-aware
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 而基于规则的系统依赖于预定义的规则和响应，将它们限制在特定的、预期的交互中，而大型语言模型（LLM）利用庞大的数据集和高级推理能力来生成既自然又多样化的响应，同时高度感知上下文。
- en: They are also multimodal, which means they can understand and respond to multiple
    forms of communication such as text, voice, image, or video
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它们也是多模态的，这意味着它们可以理解和响应多种形式的通信，如文本、语音、图像或视频。
- en: These exceptional reasoning abilities enable them to handle tasks with increased
    efficiency and sophistication, leading to conversations that closely mimic human
    interaction and understanding
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些卓越的推理能力使它们能够以更高的效率和复杂性处理任务，从而产生与人类互动和理解非常相似的对话。
- en: Let’s take the scenario of a customer service interaction as an example to highlight
    the differences between traditional rule-based systems and modern conversational
    AI systems that use LLMs, such as GPT-4.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以客户服务交互的场景为例，来突出传统基于规则的系统和现代使用LLM（如GPT-4）的现代对话式人工智能系统之间的差异。
- en: 'The following is a rule-based system example:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个基于规则的系统示例：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this case, the rule-based chatbot is programmed to ask for an order number
    as a part of its return process script. It can’t handle the nuance of the customer’s
    situation where they don’t have a receipt. It’s stuck in its predefined rules
    and can’t adapt to the unexpected scenario.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，基于规则的聊天机器人被编程为在其退货流程脚本中请求订单号。它无法处理客户没有收据的情况的细微差别。它陷入了预定义的规则中，无法适应意外的情况。
- en: 'The following is an LLM-powered conversational AI example:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个由LLM驱动的对话式人工智能示例：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The LLM-powered chatbot, on the other hand, understands the context of not having
    a receipt and offers alternative methods for returning the item. It does not require
    the customer to stick to a strict script but instead adapts to the context of
    the conversation and provides a helpful response. This showcases the advanced
    reasoning capabilities of LLMs, allowing for more natural, flexible, and human-like
    conversations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，由大型语言模型（LLM）驱动的聊天机器人理解没有收据的情境，并提供了退货的替代方法。它不需要客户坚持严格的脚本，而是适应对话的上下文，并提供有用的回应。这展示了
    LLM 的高级推理能力，使得对话更加自然、灵活，更接近人类。
- en: LLM-powered chatbots also possess inherent limitations, including difficulties
    in generating accurate up-to-date information, a tendency to hallucinate, and
    the reproduction of biases present in their training data. We explore these limitations
    throughout this book, along with strategies to mitigate and eliminate them.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 驱动的聊天机器人也存在固有的局限性，包括难以生成准确的信息、容易产生幻觉以及在其训练数据中存在的偏差的再现。我们将在本书中探讨这些局限性，以及减轻和消除这些局限性的策略。
- en: Chatbots and agents
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聊天机器人和代理
- en: GenAI-based chatbots can also execute tasks or actions with the help of agents.
    LLM agents are programs that enhance standard LLMs by connecting to external tools,
    such as APIs and plugins, and assist in planning and executing tasks. They often
    interact with other software and databases for complex tasks, such as chatbot
    scheduling meetings and needing access to calendars and emails. When a user requests
    a meeting, the chatbot, utilizing its LLM, comprehends the request’s specifics,
    such as time, participants, and purpose. It then autonomously interacts with the
    employees’ digital calendars and email systems to find a suitable time slot, considering
    everyone’s availability. Once it identifies an appropriate time, the chatbot schedules
    the meeting and sends invites via email, managing the entire process without human
    intervention. This showcases the chatbot’s ability to perform complex, multi-step
    tasks efficiently, blending language understanding and reasoning with practical
    action in a business environment. We will learn more about LLM agents in [*Chapter
    6*](B21443_06.xhtml#_idTextAnchor117).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 GenAI 的聊天机器人还可以在代理的帮助下执行任务或采取行动。LLM 代理是程序，通过连接到外部工具（如 API 和插件）来增强标准 LLM，并协助规划和执行任务。它们通常与其他软件和数据库交互以执行复杂任务，例如聊天机器人安排会议并需要访问日历和电子邮件。当用户请求会议时，聊天机器人利用其
    LLM 理解请求的具体内容，如时间、参与者和目的。然后它自主地与员工的数字日历和电子邮件系统交互，以找到合适的时段，考虑每个人的可用性。一旦确定合适的时段，聊天机器人就会安排会议并通过电子邮件发送邀请，整个过程无需人工干预。这展示了聊天机器人高效执行复杂多步任务的能力，将语言理解和推理与商业环境中的实际行动相结合。我们将在[第
    6 章](B21443_06.xhtml#_idTextAnchor117)中了解更多关于 LLM 代理的内容。
- en: ChatGPT, launched in November 2022 by OpenAI, attracted 100 million users within
    just two months due to its advanced language capabilities and broad applicability
    across various tasks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT，由 OpenAI 于 2022 年 11 月推出，由于其先进的语言能力和在各种任务中的广泛应用，仅两个月内就吸引了 1 亿用户。
- en: In the upcoming section, we will delve into the fundamentals of LLMs as the
    driving force behind modern chatbots and their significance.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨 LLM 作为现代聊天机器人驱动力及其重要性的基础。
- en: Introduction to generative AI
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式 AI 简介
- en: 'Generative AI refers to a field of AI (as stated in the preceding figure) that
    focuses on creating or generating new content, such as images, text, music, video,
    code, 3D objects, or synthetic data that is not directly copied or replicated
    from existing data. It involves training deep learning models to understand patterns
    and relationships within a given dataset and then using that knowledge to generate
    novel and unique content. The following is a visualization of what generative
    AI is:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 指的是人工智能（如前图所述）的一个领域，该领域专注于创建或生成新的内容，如图像、文本、音乐、视频、代码、3D 对象或合成数据，这些内容不是直接从现有数据中复制或复制的。它涉及训练深度学习模型来理解给定数据集中的模式和关系，然后使用这些知识来生成新颖和独特的内容。以下是对生成式
    AI 的可视化：
- en: '![Figure 1.3 – What is generative AI?](img/B21443_01_3.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – 什么是生成式 AI?](img/B21443_01_3.jpg)'
- en: Figure 1.3 – What is generative AI?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 什么是生成式 AI?
- en: It is a broad field whose primary function is to generate novel content. Examples
    of generative AI models include image generation models such as **DALL-E** and
    **MidJourney**, text generation models such as **GPT-4**, **PaLM**, and **Claude**,
    code generation models such as **Codex**, audio generation tools such as **MusicLM**,
    and video generation models such as **SORA**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个广泛的领域，其主要功能是生成新颖的内容。生成式AI模型的例子包括图像生成模型如**DALL-E**和**MidJourney**，文本生成模型如**GPT-4**、**PaLM**和**Claude**，代码生成模型如**Codex**，音频生成工具如**MusicLM**，以及视频生成模型如**SORA**。
- en: The rise of generative AI in 2022-23
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2022-23年生成式AI的兴起
- en: 'Generative AI has reached an inflection point in recent times, and this can
    be attributed to three key factors:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI在最近达到了一个拐点，这可以归因于三个关键因素：
- en: '**Size and variety of datasets**: The surge in available data due to the digital
    revolution has been crucial for training AI models to generate human-like content.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集的大小和多样性**：由于数字革命导致的数据激增对于训练AI模型生成类似人类的内容至关重要。'
- en: '**Innovative deep learning models**: Advancements in model architectures such
    as **generative adversarial networks** (**GANs**) and transformer-based models
    facilitate the learning of complex patterns, resulting in high-quality AI-generated
    outputs. The research paper “Attention Is All You Need” ([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))
    introduced transformer architecture, enabling significantly more efficient and
    powerful models for natural language processing, which became foundational for
    the development of advanced generative AI models. Progress has also been significantly
    fueled by the availability of open source state-of-the-art pre-trained models
    via platforms such as the Hugging Face Community.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创新的深度学习模型**：在模型架构方面的进步，如**生成对抗网络**（GANs）和基于transformer的模型，促进了复杂模式的学习，从而产生了高质量的AI生成输出。《Attention
    Is All You Need》这篇研究论文（[https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)）介绍了transformer架构，使得自然语言处理模型更加高效和强大，这成为了高级生成式AI模型发展的基础。研究进步也因通过Hugging
    Face社区等平台提供的开源最先进预训练模型而得到显著推动。'
- en: '**Powerful computing**: Advancements in hardware such as Nvidia GPUs and access
    to computing through cloud computing have enabled the training of complex AI models,
    driving advancements in generative AI.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强大的计算能力**：硬件方面的进步，如Nvidia GPU，以及通过云计算获得的计算能力，使得训练复杂的AI模型成为可能，推动了生成式AI的进步。'
- en: There are various types of generative AI models with different underlying architectures.
    Among them, **VAEs**, **diffusion models**, **GANs**, and **autoregressive models**
    are particularly popular. While we won’t delve into every model architecture extensively
    as it is outside the scope of this book. In [*Chapter 2*](B21443_02.xhtml#_idTextAnchor036),
    we will focus on a more detailed discussion of ChatGPT’s LLM architecture, which
    utilizes an **autoregressive-based** **transformer architecture**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 存在着各种类型的生成式AI模型，它们具有不同的底层架构。其中，**变分自编码器**（VAEs）、**扩散模型**、**GANs**和**自回归模型**特别受欢迎。虽然我们不会深入探讨每个模型架构，因为这超出了本书的范围。在[*第二章*](B21443_02.xhtml#_idTextAnchor036)中，我们将更详细地讨论ChatGPT的LLM架构，该架构利用了**基于自回归的****transformer架构**。
- en: Moving from the topic of generative AI, we now turn our attention to foundation
    models. Often used interchangeably with LLMs, these models are the driving force
    behind the success and possibilities of generative AI. The remarkable strides
    made in foundation models have been instrumental in propelling the advancements
    we witness today in generative AI applications. Their development has not only
    enabled more sophisticated AI capabilities but has also set the stage for a new
    era of innovation and possibilities in AI.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从生成式AI的话题转向，我们现在将注意力转向基础模型。这些模型通常与LLMs互换使用，是生成式AI成功和可能性的驱动力。在基础模型方面取得的显著进步对于推动我们今天在生成式AI应用中看到的进步至关重要。它们的发展不仅使AI能力更加复杂，还为AI创新和可能性的新时代奠定了基础。
- en: Foundation models
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础模型
- en: The term foundation models was coined by Stanford in 2021 in the paper “On the
    Opportunities and Risks of Foundation Models” ([https://arxiv.org/pdf/2108.07258.pdf](https://arxiv.org/pdf/2108.07258.pdf)).
    Foundation models are a class of large-scale model that are pre-trained on vast
    amounts of data across various domains and tasks. They serve as a base for further
    fine-tuning or adaptation to a wide range of downstream tasks, not limited to
    language but including vision, sound, and other modalities. The term *foundation*
    signifies that these models provide a foundational layer of understanding and
    capabilities upon which specialized models can be built. They are characterized
    by their ability to learn and generalize from the training data to a variety of
    applications, sometimes with little to no additional training data. The model
    is as follows:.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: “基础模型”这个术语是由斯坦福大学在2021年的论文“On the Opportunities and Risks of Foundation Models”中提出的（[https://arxiv.org/pdf/2108.07258.pdf](https://arxiv.org/pdf/2108.07258.pdf)）。基础模型是一类在大规模数据上预训练的模型，这些数据跨越了各种领域和任务。它们作为进一步微调或适应广泛下游任务的基础，不仅限于语言，还包括视觉、声音和其他模态。术语“基础”意味着这些模型提供了一个基础层级的理解和能力，在之上可以构建专门的模型。它们的特点是能够从训练数据中学习并泛化到各种应用中，有时甚至不需要额外的训练数据。模型如下：.
- en: '![Figure 1.4 – Foundation models](img/B21443_01_4.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4 – 基础模型](img/B21443_01_4.jpg)'
- en: Figure 1.4 – Foundation models
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 基础模型
- en: LLMs
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs
- en: LLMs, on the other hand, are a subset of foundation models that specifically
    deal with natural language processing tasks. They are trained in large text corpora
    and are designed to understand, generate, and translate language at a scale and
    sophistication that closely resembles human language understanding. LLMs are trained
    on massive amounts of data, such as books, articles, and the internet. For example,
    ChatGPT’s base model was trained on 45 TB of data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，LLMs是基础模型的一个子集，专门处理自然语言处理任务。它们在大规模文本语料库中进行训练，旨在以接近人类语言理解的方式理解和生成语言。LLMs在大量数据上进行训练，例如书籍、文章和互联网。例如，ChatGPT的基础模型是在45
    TB的数据上训练的。
- en: LLMs such as GPTs use transformer architecture to process text sequences, training
    themselves to predict the next word in a given sequence. Through exposure to vast
    amounts of text, these models adjust their internal weights based on the difference
    between predicted and actual words, a process known as backpropagation. Over time,
    by repeatedly refining these weights across multiple layers of attention mechanisms,
    they capture intricate statistical patterns and dependencies in the language,
    enabling them to generate contextually relevant text. In [*Chapter 2*](B21443_02.xhtml#_idTextAnchor036),
    we will delve deeper into the transformer architecture of LLMs that enables the
    ChatGPT application.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，GPTs等LLMs使用transformer架构来处理文本序列，通过训练自己预测给定序列中的下一个单词。通过接触大量的文本，这些模型根据预测单词和实际单词之间的差异调整其内部权重，这个过程被称为反向传播。随着时间的推移，通过在多个注意力机制层中反复微调这些权重，它们捕捉到语言中的复杂统计模式和依赖关系，使它们能够生成上下文相关的文本。在[*第二章*](B21443_02.xhtml#_idTextAnchor036)中，我们将更深入地探讨LLMs的transformer架构，该架构使得ChatGPT应用成为可能。
- en: LLMs traditionally refer to models that handle large-scale language tasks; the
    principles and architecture underlying them can be, and are being, extended to
    other domains such as image generation. This expansion of capabilities reflects
    the versatility and adaptability of the transformer-based models that power both
    LLMs and their multimodal counterparts.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）通常指的是处理大规模语言任务的模型；其背后的原理和架构可以，并且正在被扩展到其他领域，如图像生成。这种能力范围的扩展反映了基于transformer的模型的多功能和适应性，这些模型既推动了LLMs，也推动了它们的多模态对应物。
- en: Models such as DALL-E, for instance, are sometimes referred to as LLMs due to
    their foundation in transformer architecture, which was originally developed for
    language tasks. However, DALL-E is more accurately described as a multimodal AI
    model because it understands both text and images and can generate images from
    textual descriptions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，DALL-E等模型有时被称为LLMs，因为它们基于最初为语言任务开发的transformer架构。然而，DALL-E更准确地被描述为一个多模态AI模型，因为它理解文本和图像，并且可以从文本描述中生成图像。
- en: Core attributes of LLMs
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs的核心属性
- en: In the process of creating LLM-based AI applications, it is crucial to understand
    the core attributes of LLMs, such as model parameters, licensing model, privacy,
    cost, quality, and latency. It is important to note that there isn’t a flawless
    model, and making tradeoffs might be necessary to align with the specific business
    requirements of the application. The following content concentrates only on vital
    considerations when designing LLM applications.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建基于LLM的AI应用程序的过程中，了解LLM的核心属性至关重要，例如模型参数、许可模型、隐私、成本、质量和延迟。需要注意的是，没有完美的模型，为了满足特定应用程序的商业需求，可能需要进行权衡。以下内容仅关注设计LLM应用程序时的关键考虑因素。
- en: Model parameters
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型参数
- en: Model parameters in LLMs are the internal settings that the model uses to understand
    and generate text. These parameters can be coefficients, weights, and biases and
    are part of large mathematical equations that underlie LLM models. They are adjusted
    through training, where the model learns from vast amounts of data how to predict
    the next word in a sentence, understand context, and generate coherent and relevant
    text.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM中的模型参数是模型用来理解和生成文本的内部设置。这些参数可以是系数、权重和偏差，它们是LLM模型背后的复杂数学方程式的一部分。这些参数通过训练进行调整，模型通过学习大量数据来预测句子中的下一个单词，理解上下文，并生成连贯且相关的文本。
- en: For example, in the context of LLMs, model parameters are akin to internal notes
    that guide predictions based on learned data patterns. For example, if an LLM
    frequently encounters the phrase “sunny weather” during training, it adjusts its
    parameters to strengthen the connection between “sunny” and “weather.” These adjustments
    are like turning knobs to increase the likelihood of predicting “weather” after
    “sunny” in new sentences. Thus, the model’s parameters encode relationships between
    words, enabling it to generate contextually relevant text based on its training.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，在LLM的背景下，模型参数类似于基于学习到的数据模式的预测指导内部笔记。例如，如果一个LLM在训练过程中经常遇到“晴朗天气”这个短语，它会调整其参数以加强“晴朗”和“天气”之间的联系。这些调整就像转动旋钮，增加在新句子中预测“天气”在“晴朗”之后的可能性。因此，模型的参数编码了单词之间的关系，使其能够根据其训练生成上下文相关的文本。
- en: The number of parameters indicates the model’s size and complexity, with larger
    models generally capable of capturing more complex patterns and nuances in language
    but requiring more computational resources.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数数量表示模型的大小和复杂性，一般来说，较大的模型能够捕捉到语言中更复杂模式和细微差别，但需要更多的计算资源。
- en: Understanding the parameters in LLMs is crucial for interpreting model behavior,
    customizing and adapting the model, and evaluating and comparing different models.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解LLM（大型语言模型）中的参数对于解释模型行为、定制和调整模型、评估和比较不同模型至关重要。
- en: Smaller models are more fine-tunable because of the lower number of parameters
    as compared to larger models.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相较于大型模型，较小的模型由于参数数量较少，因此更容易微调。
- en: While designing applications, it’s crucial to understand whether a smaller model
    can fulfill the needs of a particular use case by means of fine-tuning/in-context
    learning or whether a larger model is necessary. For example, smaller models such
    as GPT-3.5 and FLAN-T5 typically come with lower costs as compared to GPT-4 and
    often prove highly efficient with fine-tuning or in-context learning, especially
    in specific tasks such as conversation summarization.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设计应用程序时，了解是否可以通过微调/上下文学习或是否需要较大的模型来满足特定用例的需求至关重要。例如，较小的模型如GPT-3.5和FLAN-T5通常成本较低，与GPT-4相比，它们在微调或上下文学习的情况下往往非常高效，尤其是在像对话摘要这样的特定任务中。
- en: Licensing
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 许可证
- en: Open source models can be used as-is or customized for commercial and non-commercial
    use. They are usually smaller than proprietary LLM models, less expensive, and
    more task-specific. For example, Whisper is an open source speech-to-text model
    developed by Open AI, and Llama from Facebook is an open source model.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开源模型可以直接使用或根据商业和非商业用途进行定制。它们通常比专有LLM模型小，成本更低，且更针对特定任务。例如，Whisper是Open AI开发的开源语音转文本模型，而Facebook的Llama是一个开源模型。
- en: Proprietary models are usually larger models and require licensing. They may
    be restricted for commercial use and modifications. For example, GPT-4 is a proprietary
    model developed by Open AI.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专有模型通常是较大的模型，需要获得许可。它们可能仅限于商业用途和修改。例如，GPT-4是Open AI开发的专有模型。
- en: When designing applications, it is important to understand whether it is an
    open source or a licensed model and whether it is permitted for commercial use.
    This is crucial to ensure legal compliance, financial planning, ethical considerations,
    customization possibilities, and the long-term success of your application.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设计应用时，了解它是一个开源模型还是许可模型，以及是否允许商业使用非常重要。这对于确保法律合规性、财务规划、伦理考量、定制可能性以及应用的长期成功至关重要。
- en: Privacy
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐私
- en: Ensuring the security of data used for fine-tuning and prompting LLMs, especially
    when it involves sensitive customer information, is paramount.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保用于微调和提示LLMs的数据安全至关重要，尤其是在涉及敏感客户信息时。
- en: Guardrails must be established to ensure that customer data is redacted before
    fine-tuning the models and also when using them in prompts.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须建立护栏以确保在微调模型之前以及在使用它们进行提示时，客户数据被删除。
- en: It is also crucial to understand how the data will be stored and utilized by
    the model. Data controls can be configured in ChatGPT to prevent chats from being
    saved by the system and thus not allowing them to be used to train the models.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据将被模型如何存储和利用也非常关键。在ChatGPT中可以配置数据控制，以防止系统保存聊天记录，从而不允许它们用于训练模型。
- en: Cost
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成本
- en: When architecting LLM applications, it is important to understand the cost of
    acquiring the model (e.g. licensing costs), infrastructure costs related to data
    storage, computing, data transfer, fine-tuning, and maintenance costs such as
    monitoring.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设计LLM应用时，了解获取模型（例如许可费用）、与数据存储、计算、数据传输、微调和维护成本（如监控）相关的基础设施成本非常重要。
- en: Latency
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 延迟
- en: This is crucial for ensuring smooth interaction for users. When deciding on
    models, you must discern whether the output requires real-time or near-real-time
    responses.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这对于确保用户交互顺畅至关重要。在决定模型时，您必须判断输出是否需要实时或近实时响应。
- en: Larger model APIs may have slightly slower response times and higher costs as
    compared to smaller models, but the quality of outputs may be better in certain
    scenarios. For example, GPT-4 is slightly slower than GPT 3.5 Turbo but may perform
    better in certain scenarios where complex reasoning is involved.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比于小型模型，较大的模型API可能响应时间略慢且成本更高，但在某些场景下输出质量可能更好。例如，GPT-4比GPT 3.5 Turbo略慢，但在涉及复杂推理的场景中可能表现更佳。
- en: Attaining low latency necessitates considering several elements, such as picking
    the right LLM API or hardware infrastructure for self-hosted open source LLMs
    or modifying the length of input and output. The application of methods such as
    cache and load balancing of APIs can drastically reduce response durations, leading
    to a fluid user experience.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要实现低延迟，需要考虑多个因素，例如为自托管开源LLMs选择合适的LLM API或硬件基础设施，或修改输入和输出的长度。应用缓存和API负载均衡等方法可以显著减少响应时间，从而带来流畅的用户体验。
- en: The core attributes mentioned provide an excellent starting point for shortlisting
    models based on business requirements. However, it’s important to understand that
    some LLMs may exhibit more biases and a higher tendency to hallucinate. In [*Chapter
    3*](B21443_03.xhtml#_idTextAnchor052), we discuss industry-leading benchmarks
    that will help you make informed decisions considering these limitations.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 提到的核心属性为根据业务需求筛选模型提供了良好的起点。然而，重要的是要了解某些LLMs可能表现出更多的偏见和更高的幻觉倾向。在[*第3章*](B21443_03.xhtml#_idTextAnchor052)中，我们讨论了行业领先的基准，这将帮助您在考虑这些限制的情况下做出明智的决定。
- en: Relationship between generative AI, foundation models, and LLMs
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式AI、基础模型和LLMs之间的关系
- en: Generative AI broadly refers to AI systems that can create new content, such
    as text, image, audio, or video. Foundation models are a subset of generative
    AI, characterized by their large scale and versatility across multiple tasks,
    often trained on extensive and diverse datasets. LLMs, a type of foundation model,
    specifically focus on understanding and generating human language, exemplified
    by systems such as GPT-3.5-Turbo and Llama 2.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI广泛指的是能够创建新内容的人工智能系统，如文本、图像、音频或视频。基础模型是生成式AI的一个子集，其特点在于规模庞大且在多个任务中具有多面性，通常在大量且多样化的数据集上训练。LLMs作为一种基础模型，特别关注理解和生成人类语言，例如GPT-3.5-Turbo和Llama
    2系统。
- en: Foundation models can be applied to a variety of AI tasks beyond language, such
    as image recognition, whereas LLMs are specifically focused on language-related
    tasks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型可以应用于多种AI任务，而不仅仅是语言，例如图像识别，而LLM则专注于与语言相关的任务。
- en: In practice, the terms can sometimes be used interchangeably when the context
    is clearly about language tasks, but it’s important to know that the concept of
    foundation models was originally supposed to be broader and encompass a wider
    range of AI capabilities.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，当上下文明确涉及语言任务时，这些术语有时可以互换使用，但重要的是要知道，基础模型的概念最初是希望更广泛，并涵盖更广泛的AI能力。
- en: However, now, as LLMs such as GPT-4 Turbo are extending to multimodal capabilities,
    this difference between foundation models and LLMs has been narrowing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在，随着像GPT-4 Turbo这样的LLM扩展到多模态能力，基础模型和LLM之间的这种差异正在缩小。
- en: 'Generative AI encompasses a wide array of AI models designed to create new,
    previously unseen content, spanning domains from text and images to music. The
    following image illustrates the relationship between generative AI, LLMs, and
    foundation models:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI包含了一系列AI模型，旨在创建新的、以前未见过的内容，涵盖了从文本和图像到音乐的各个领域。以下图像展示了生成式AI、LLM和基础模型之间的关系：
- en: '![Figure 1.5 – What is an LLM?](img/B21443_01_5.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 – 什么是LLM？](img/B21443_01_5.jpg)'
- en: Figure 1.5 – What is an LLM?
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 什么是LLM？
- en: The LLMs behind ChatGPT
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聊天机器人背后的LLM
- en: As of early 2024, ChatGPT is a specialized application of GPT-3.5 and GPT-4
    that is fine-tuned for conversational interactions. While GPT-3.5/4 is a general
    language model capable of a variety of language tasks, ChatGPT has been specifically
    trained to respond to prompts in a way that mimics human conversation. The process
    starts with the base foundation model GPT-3.5/4 model that has been pre-trained
    on a large corpus of text from the internet. Then, to create ChatGPT, OpenAI conducts
    further training (fine-tuning) on datasets that include many examples of human
    dialogue. This helps ChatGPT to better understand and generate conversational
    responses. In essence, GPT-3.5/4 can be thought of as the underlying technology,
    and ChatGPT as a specific implementation of that technology optimized for conversation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2024年初，ChatGPT是GPT-3.5和GPT-4的一个专门应用，经过微调以适应对话交互。虽然GPT-3.5/4是一个通用的语言模型，能够执行各种语言任务，但ChatGPT已被专门训练以模仿人类对话的方式响应提示。这个过程从预先在互联网上的大量文本语料库上预训练的基础基础模型GPT-3.5/4模型开始。然后，为了创建ChatGPT，OpenAI在包含许多人类对话示例的数据集上进行了进一步的训练（微调）。这有助于ChatGPT更好地理解和生成对话式响应。本质上，GPT-3.5/4可以被视为底层技术，而ChatGPT则是该技术的具体实现，针对对话进行了优化。
- en: Google’s Bard (now known as Gemini) is a similar application to ChatGPT and
    is built on an LLM called PaLM-2.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Google的Bard（现更名为Gemini）与ChatGPT类似，它基于一个名为PaLM-2的LLM构建。
- en: Open source models such as Llama 2 from Facebook have become more popular lately.
    But how do they contrast with closed source or proprietary models? What are their
    advantages? In the next section, we will explore more about the details of and
    what defines an LLM as an open source model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 来自Facebook的Llama 2等开源模型最近变得更加流行。但它们与闭源或专有模型有何不同？它们有哪些优势？在下一节中，我们将探讨LLM作为开源模型的详细信息和定义。
- en: Deep dive – open source vs closed source/proprietary models
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨 – 开源与闭源/专有模型
- en: Open source models such as **Llama 2**, **Mistral**, and **Falcon** have become
    increasingly popular in the recent past. As Gen AI Cloud Architects, the authors
    have witnessed considerable debate on choosing between open source and closed
    source models and identifying the appropriate contexts for their use. This section
    delves into the fundamental distinctions between these models on “What is revealed?”
    and “What is not revealed?” along with key deployment differences, drawing on
    our insights from the field.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，像**Llama 2**、**Mistral**和**Falcon**这样的开源模型变得越来越受欢迎。作为通用人工智能云架构师，作者们见证了在开源和闭源模型之间选择以及确定它们适用场景的激烈辩论。本节深入探讨了这些模型在“揭示什么”和“未揭示什么”方面的基本区别，以及关键的部署差异，借鉴了我们在该领域的见解。
- en: Closed source LLMs (e.g., GPT-4, PaLM-2, Claude-2)
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 闭源LLM（例如，GPT-4、PaLM-2、Claude-2）
- en: 'What is revealed is the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 揭示的内容如下：
- en: '**Functionality and capabilities**: Users know what the model can do, such
    as generating text, answering questions, and more.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能和能力**：用户知道模型能做什么，例如生成文本、回答问题等。'
- en: '**Usage guidelines**: Information on how to interact with the model (e.g.,
    APIs) and its intended use cases are revealed. OpenAI provides API access to GPT
    models, but the underlying models are not openly distributed.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用指南**：关于如何与模型交互（例如，API）及其预期用例的信息被公开。OpenAI提供了GPT模型的API访问，但底层模型并未公开分发。'
- en: '**Performance metrics**: OpenAI shares details about GPT’s performance in various
    tasks and benchmarks.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能指标**：OpenAI分享了GPT在各项任务和基准测试中的性能细节。'
- en: '**Ethical standards**: OpenAI discusses the ethical considerations and guidelines
    followed during development.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理标准**：OpenAI讨论了在开发过程中遵循的伦理考虑和指南。'
- en: '**General architecture overview**: While not in detail, there’s usually some
    high-level information about the model’s architecture.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一般架构概述**：虽然不是非常详细，但通常会有一些关于模型架构的高级信息。'
- en: 'What is not revealed is the following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 没有公开的是以下内容：
- en: '**Source code**: The actual codebase of closed-source models is not publicly
    available'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源代码**：闭源模型的实际代码库不公开提供'
- en: '**Model weights**: Access to the actual model weights for complete replication
    is restricted'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型权重**：访问实际模型权重以实现完全复制的权限受到限制'
- en: '**Training data details**: Specifics about the training datasets, including
    their sources and compositions, are generally not disclosed'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据细节**：关于训练数据集的具体信息，包括它们的来源和组成，通常不会公开披露'
- en: '**Detailed model architecture**: The intricate details of the model’s architecture
    and algorithms are proprietary'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**详细模型架构**：模型架构和算法的复杂细节属于专有信息'
- en: '**Training process**: Specifics on how the model was trained, including hyperparameters
    and training duration, are not shared'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练过程**：关于模型如何训练的具体细节，包括超参数和训练时长，并未公开'
- en: The above conclusions were drawn up based on the GPT-4 Technical Report ([https://arxiv.org/pdf/2303.08774.pdf](https://arxiv.org/pdf/2303.08774.pdf))
    released by OpenAI. In the report, OpenAI states that due to the competitive landscape
    and safety implications of large-scale models such as GPT-4, it doesn’t reveal
    intricate details about the architecture, including model size, hardware, training
    computing, dataset construction, training method, or similar.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 上述结论是基于OpenAI发布的GPT-4技术报告([https://arxiv.org/pdf/2303.08774.pdf](https://arxiv.org/pdf/2303.08774.pdf))得出的。在报告中，OpenAI表示，由于GPT-4等大型模型在竞争环境和安全影响方面，它没有透露关于架构的复杂细节，包括模型大小、硬件、训练计算、数据集构建、训练方法或类似内容。
- en: Open source LLMs (e.g., Llama 2, Mistral, Falcon)
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开源大型语言模型（例如，Llama 2、Mistral、Falcon）
- en: 'What is revealed is the following:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 公开的是以下内容：
- en: '**Source code**: The full codebase is usually available for public access.
    Hence, individuals and businesses can deploy open source models on personal PCs
    and in on-premises or internal servers.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源代码**：完整的代码库通常可供公众访问。因此，个人和企业可以在个人电脑和本地或内部服务器上部署开源模型。'
- en: '**Model weights**: The weights of the model can be downloaded and used by researchers
    and developers.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型权重**：模型的权重可以被研究人员和开发者下载和使用。'
- en: '**Training process details**: Detailed information about how the model was
    trained, including datasets and hyperparameters.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练过程细节**：关于模型如何训练的详细信息，包括数据集和超参数。'
- en: '**Full architecture details**: Comprehensive information on the model’s architecture
    is provided.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完整架构细节**：提供了关于模型架构的全面信息。'
- en: '**Dataset information**: Although with some constraints, more information about
    the training datasets may be available.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集信息**：尽管存在一些限制，关于训练数据集的更多信息可能可用。'
- en: 'What is not revealed is the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 没有公开的是以下内容：
- en: '**Resource requirements**: Specific details on the computational resources
    required for training might not be fully disclosed'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源需求**：关于训练所需的计算资源的具体细节可能不会完全公开'
- en: '**Ethical considerations**: Open source projects may not always have the same
    level of ethical oversight as some closed source projects'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理考虑**：开源项目可能并不总是像某些闭源项目那样拥有相同的伦理监管水平'
- en: '**Performance optimization secrets**: Some nuances of performance optimization
    during training might be left out'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能优化秘诀**：在训练过程中可能省略了一些性能优化的细微之处'
- en: '**Full training data**: Even in open source models, sharing the entire training
    data can be impractical due to size and licensing issues'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完整训练数据**：即使在开源模型中，由于数据大小和许可问题，分享整个训练数据可能不切实际'
- en: '**Continuous updates**: Unlike some closed source models, open source models
    may not receive continuous updates or support'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续更新**：与一些封闭源模型不同，开源模型可能不会收到持续的更新或支持'
- en: 'The following table details the key deployment differences between open and
    closed source models:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格详细说明了开源和封闭源模型之间的关键部署差异：
- en: '|  | **Closed** **source models** | **Open source** **LLMs (OSS)** |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|  | **封闭源模型** | **开源** **LLMs (OSS)** |'
- en: '| --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Access, cost, and deployment endpoint | Access is typically restricted to
    paid licenses, APIs, or subscription models. The cost can be a barrier for smaller
    organizations or individual developers.Costs associated with such deployments
    are typically associated with the number of tokens in prompts and completions.For
    example, as of early 2024, OpenAI charges $0.01 /1K tokens for prompts and $0.03
    /1K tokens for completions for gpt-4-0125-preview. | Generally, the source code
    is freely available. Deploying open source models necessitates the initial setup
    of compute instances, serving as the foundation for an inference endpoint. This
    endpoint can operate in real time or process data in batches. The expenses linked
    to this deployment strategy primarily involve the operational costs of the compute
    resources.However, new pricing models have emerged, such as MaaS (model-as-a-service),
    which charges just like API-based models based on the tokens used. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 访问、成本和部署端点 | 访问通常限于付费许可证、API或订阅模式。成本可能成为小型组织或个人开发者的障碍。与这种部署相关的成本通常与提示和完成中的令牌数量相关。例如，截至2024年初，OpenAI对gpt-4-0125-preview的提示收费为每1K令牌0.01美元，对完成收费为每1K令牌0.03美元。
    | 通常，源代码是免费提供的。部署开源模型需要设置计算实例的初始设置，这作为推理端点的基础。该端点可以实时运行或批量处理数据。与此部署策略相关的费用主要涉及计算资源的运营成本。然而，新的定价模式已经出现，例如MaaS（模型即服务），其收费方式类似于基于API的模型，根据使用的令牌数量收费。
    |'
- en: '| Customization and flexibility | Due to the unavailability of source code,
    customization options are often limited to what the provider allows. Users may
    not be able to modify the model’s core architecture or training datasets. | Greater
    flexibility for customization is offered. Developers can tweak the models, retrain
    with specific datasets, or even adjust the underlying algorithms. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 定制化和灵活性 | 由于源代码不可用，定制选项通常仅限于提供商允许的范围。用户可能无法修改模型的内核架构或训练数据集。 | 提供了更大的定制灵活性。开发者可以调整模型，使用特定数据集重新训练，甚至调整底层算法。
    |'
- en: '| Support and documentation | Usually, they come with professional support
    and comprehensive documentation, ensuring smoother deployment, and troubleshooting
    processes. | While there is often a community for support, the quality and availability
    of formal support and documentation can vary. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 支持和文档 | 通常，它们附带专业的支持和全面的文档，确保更顺畅的部署和故障排除过程。 | 虽然通常有一个支持社区，但正式支持和文档的质量和可用性可能会有所不同。
    |'
- en: '| Integration and compatibility | They might have better integration with other
    proprietary tools or platforms offered by the same provider but could be less
    flexible in terms of compatibility with a wide range of technologies. | They are
    typically designed to be more flexible and compatible with a variety of platforms
    and tools, though integration may require more effort from the user. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 集成和兼容性 | 它们可能与同一提供商提供的其他专有工具或平台有更好的集成，但在与广泛技术的兼容性方面可能不太灵活。 | 它们通常设计得更加灵活，并与各种平台和工具兼容，尽管集成可能需要用户付出更多努力。
    |'
- en: '| Security and updates | Security updates and patches are typically managed
    by the provider, ensuring a consistent level of maintenance. | Security relies
    on the community and maintainers, which can lead to varying degrees of promptness
    and effectiveness in updates. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 安全性和更新 | 安全更新和补丁通常由提供商管理，确保一致的维护水平。 | 安全性依赖于社区和维护者，这可能导致更新在及时性和有效性方面存在不同程度的差异。
    |'
- en: '| Ethics, compliance, and liability | Providers are generally responsible for
    compliance with regulations, offering a certain level of assurance for businesses.
    | Users often need to ensure compliance themselves, which can be a significant
    consideration for businesses in regulated industries. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 道德、合规性和责任 | 提供商通常负责遵守法规，为商业活动提供一定程度的保障。 | 用户通常需要自行确保合规性，这对于受监管行业的商业活动来说可能是一个重要的考虑因素。
    |'
- en: '| Risks |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 风险 |'
- en: Potentially higher costs due to licensing fees
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于许可费用可能导致的潜在更高成本
- en: Limited ability to customize to meet business requirements as compared to open
    source
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与开源相比，定制能力有限，以满足业务需求
- en: Vendor Lock-In
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商锁定
- en: Reduced transparency, due to the limited knowledge of the internal workings
    of the LLMs
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于对大型语言模型内部运作的了解有限，透明度降低
- en: '|'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Potential security vulnerabilities as they are community-driven and might enable
    malicious use
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于是社区驱动的，可能允许恶意使用，存在潜在的安全漏洞
- en: Lack of centralized quality control can lead to inconsistencies in updates and
    improvements
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于缺乏集中质量控制，可能导致更新和改进的不一致性
- en: Reliance on community support may lead to inconsistent troubleshooting and issue
    resolution, affecting projects that need stable, continuous maintenance
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖社区支持可能导致故障排除和问题解决不一致，影响需要稳定、持续维护的项目
- en: '|'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Figure 1.6 – Key deployment differences
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 关键部署差异
- en: 'The decision for organizations to adopt open source or closed source models
    is inherently subjective and hinges on their unique needs and goals. A more pertinent
    question might be: after conducting internal benchmarking, which model emerges
    as the most effective for your specific use case? These benchmarks are available
    on Hugging Face ([https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 组织选择采用开源或闭源模型的决定本质上具有主观性，并取决于它们的独特需求和目标。一个更相关的问题可能是：在进行内部基准测试后，哪个模型成为您特定用例中最有效的？这些基准测试可以在
    Hugging Face 上找到（[https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)）。
- en: Trending models, tasks, and business applications
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行模型、任务和商业应用趋势
- en: Generative AI has a wide range of applications across various industries, presenting
    several use cases that can bring significant benefits to businesses, and the applications
    are continuing to grow at a fast pace. In this section, we will discuss popular
    tasks and models and examine the latest emerging business applications that have
    gained significant traction recently.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能在各个行业都有广泛的应用，提出了可以为企业带来显著效益的多种用例，并且应用正在以快速的速度增长。在本节中，我们将讨论流行的任务和模型，并检查最近获得显著关注的最新新兴商业应用。
- en: Let’s begin with text generation models.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从文本生成模型开始。
- en: Text
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本
- en: 'Text generation models can be used for diverse tasks as outlined here. In the
    following, we have mentioned the most popular tasks that we have seen architecting
    solutions with our customers:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成模型可以用于各种任务，如本文所述。以下，我们提到了我们与客户合作构建解决方案时看到的最受欢迎的任务：
- en: '**Summarization**: They can condense long documents, such as textbook chapters
    or detailed product descriptions, into concise summaries while retaining the key
    information.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摘要**：它们可以将长文档，如教科书章节或详细的产品描述，压缩成简洁的摘要，同时保留关键信息。'
- en: '**Question answering**: These models can provide accurate answers to questions,
    which is particularly useful in automating the creation of FAQ documents from
    extensive knowledge base content.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问答**：这些模型可以提供准确的答案，这在从广泛的知识库内容自动创建常见问题解答文档时特别有用。'
- en: '**Classification**: Text generation models can classify text, assigning labels
    based on criteria such as grammatical correctness or other predefined categories.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：文本生成模型可以对文本进行分类，根据语法正确性或其他预定义类别等标准分配标签。'
- en: '**Sentiment analysis**: As a specialized form of classification, these models
    can analyze and label the sentiment of a text, identifying emotions such as happiness
    and anger or general positive and negative tones.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情感分析**：作为一种专门的分类形式，这些模型可以分析和标记文本的情感，识别诸如快乐和愤怒或一般积极和消极的情绪。'
- en: '**Entity extraction**: They can extract specific pieces of information, such
    as movie names, from larger text bodies, aiding in information retrieval and organization.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实体提取**：它们可以从更大的文本体中提取特定的信息，如电影名称，从而有助于信息检索和组织。'
- en: '**Translation**: Language models excel in translation by quickly and accurately
    converting text from one language to another, leveraging vast datasets to understand
    and maintain context and nuances. Code generation can be considered a type of
    translation, where the language model translates human language instructions into
    programming code.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**翻译**：语言模型在翻译方面表现出色，能够快速准确地转换一种语言到另一种语言，利用庞大的数据集来理解和维护上下文和细微差别。代码生成可以被视为一种翻译，其中语言模型将人类语言指令翻译成编程代码。'
- en: 'These capabilities make text-generation models invaluable tools and have led
    to the creation of innovative applications. Here we have mentioned a few interesting
    business applications we have observed across various industries due to the proliferation
    of text generation models:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这些能力使文本生成模型成为无价之宝，并导致了创新应用的创造。以下是我们观察到的一些有趣的商业应用，这些应用是由于文本生成模型的普及而在各个行业中出现的：
- en: '**Enterprise chatbots**: Text generation models power conversational agents
    that can engage in natural language conversations with users, offering customer
    support, HR support, L&D, and assistance with tasks. The top use case in terms
    of popularity that we observed was the implementation of an enterprise chatbot
    grounded on organizational data.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**企业聊天机器人**：文本生成模型为能够与用户进行自然语言对话的对话代理提供动力，提供客户支持、人力资源支持、学习和开发以及任务协助。我们观察到的最流行的用例是建立在组织数据基础上的企业聊天机器人的实施。'
- en: '**Content creation (articles, blog posts, reports, books)**: Text generation
    models can automatically generate high-quality written content on various topics,
    saving time and effort for content creators and enabling seamless Q&A experiences
    on the same. This has been a major productivity booster in the media, marketing,
    entertainment, and publication industries.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容创作（文章、博客文章、报告、书籍）**：文本生成模型可以自动生成各种主题的高质量书面内容，为内容创作者节省时间和精力，并使在同一平台上实现无缝问答体验。这在媒体、营销、娱乐和出版行业中已成为提高生产力的主要因素。'
- en: '**Real estate listings**: Text generation models enable real estate companies
    to effortlessly craft attractive house listings by inputting details such as the
    number of bedrooms, property age, neighborhood information, and other unique selling
    points, significantly enhancing the appeal of properties to potential buyers.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**房地产列表**：文本生成模型使房地产公司能够通过输入诸如卧室数量、房产年龄、社区信息和其他独特卖点等详细信息，轻松地制作吸引人的房屋列表，显著增强了房产对潜在买家的吸引力。'
- en: '**Automatic email drafting**: Text generation models assist in composing personalized
    and contextually relevant emails, streamlining communication, and improving productivity
    in email correspondence, for example, Microsoft’s Copilot application.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动电子邮件草稿**：文本生成模型帮助撰写个性化的、与上下文相关的电子邮件，简化沟通，并提高电子邮件通信中的生产力，例如微软的Copilot应用程序。'
- en: '**Personalized advertising**: These models help tailor marketing messages and
    content to individual users, enhancing the effectiveness of advertising campaigns
    by delivering more relevant and engaging content.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化广告**：这些模型有助于根据个人用户定制营销信息和内容，通过提供更相关和吸引人的内容来提高广告活动的有效性。'
- en: '**Proposal creation**: They significantly streamline the operations of real
    estate companies by automating the creation of proposals for **request for proposal**
    (**RFP**) responses. This tool also facilitated efficient searching through RFP
    submissions and greatly assisted marketing teams in crafting and authoring high-quality
    content.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提案创建**：它们通过自动化创建**请求提案**（RFP）响应的提案，极大地简化了房地产公司的运营。此工具还促进了RFP提交的快速搜索，并在制作和撰写高质量内容方面极大地帮助了营销团队。'
- en: '**Ad campaigns**: In the realm of marketing and advertising campaigns, text
    generation models offer a powerful advantage by providing precise and efficient
    summarization of lengthy content. Moreover, these models seamlessly translate
    text between various languages, effectively dismantling language barriers. This
    capability enhanced cross-cultural communication, enabling marketers to reach
    and resonate with a diverse, global audience more effectively.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广告活动**：在营销和广告活动中，文本生成模型通过提供对长篇内容的精确和高效摘要，提供了强大的优势。此外，这些模型能够在各种语言之间无缝翻译文本，有效地消除语言障碍。这种能力增强了跨文化交流，使营销人员能够更有效地触及和引起不同、全球受众的共鸣。'
- en: '**Code co-pilot**: Developer productivity in organizations has increased tremendously
    due to products such as GitHub Copilot.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码协同**：GitHub Copilot等产品的出现极大地提高了组织中的开发者生产力。'
- en: 'The following highlights the leading text generation models as of early 2024
    in a rapidly advancing field:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列出了截至2024年初在快速发展的领域中领先的文本生成模型：
- en: '**GPT-4-Turbo**: Developed by OpenAI, the most popular model in production
    today. GPT-4 is a large multimodal model with deep learning capabilities, enabling
    it to generate human-like, conversational text. It can accept both text and image
    inputs to produce human-like text outputs. It accepts 128,000 tokens in its context
    window, which is close to 300 pages of text.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4-Turbo**：由OpenAI开发，是目前生产中最受欢迎的模型。GPT-4是一个具有深度学习能力的大型多模态模型，能够生成类似人类的对话文本。它可以接受文本和图像输入以生成类似人类的文本输出。其上下文窗口可以接受128,000个token，接近300页文本。'
- en: '**Llama 2**: The Llama 2 open source models have been trained on 2 trillion
    tokens and offer double the context length (~4K tokens) of their predecessor,
    Llama 1\. These models excel in a variety of benchmarks, including reasoning,
    coding, proficiency, and knowledge tests, and include specialized chat models
    trained on over one million new human annotations.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Llama 2**：Llama 2开源模型在2000亿个token上进行了训练，并提供了其前代Llama 1的两倍上下文长度（约4K个token）。这些模型在各种基准测试中表现出色，包括推理、编码、熟练度和知识测试，并包括在超过一百万个新的人类标注上训练的专用聊天模型。'
- en: '**Mistral**: Developed by Mistral AI, founded by former Meta and Google AI
    researchers, Mistral is a leading open source model LLM with 7.3 billion parameters,
    capable of generating coherent text and performing various natural language processing
    tasks. It represents a significant advancement over previous models, outperforming
    many existing AI models in a variety of benchmarks.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mistral**：由前Meta和Google AI研究人员创立的Mistral AI开发，Mistral是一个具有73亿参数的领先开源模型LLM，能够生成连贯的文本并执行各种自然语言处理任务。它代表了相对于先前模型的重大进步，在各种基准测试中优于许多现有的AI模型。'
- en: '**PaLM-2**: Developed by Google, PaLM-2, which stands for pathways language
    model, is a next-generation language model part of a family of LLMs trained on
    a vast amount of data for next-word prediction. It shows improved multilingual,
    reasoning, and coding capabilities, and is extensively trained on multilingual
    text, covering over 100 languages.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PaLM-2**：由Google开发，PaLM-2代表路径语言模型，是下一代语言模型家族的一部分，该家族在大量数据上训练以进行下一词预测。它展示了改进的多语言、推理和编码能力，并在多语言文本上进行了广泛训练，覆盖超过100种语言。'
- en: '**Claude2**: Developed by Anthropic, Claude2 is an advanced version of its
    predecessor, Claude. This LLM is designed to be safer and more capable, with improved
    performance and longer response capabilities. It can handle a context window of
    up to 100K tokens, allowing it to work with extensive documents. Claude-2 has
    been noted for its focus on AI safety and its potential as a competitor in the
    field of conversational AI.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude2**：由Anthropic开发，Claude2是其前代产品Claude的升级版。这个LLM旨在更安全、更强大，具有改进的性能和更长的响应能力。它能够处理高达100K个token的上下文窗口，使其能够处理大量文档。Claude-2因其对AI安全的关注以及在对话AI领域的竞争潜力而备受瞩目。'
- en: '**Gemini 1.5**: Google’s latest model was released in February 2024 with more
    efficient architecture and enhanced performance. It comes in three sizes: Ultra,
    Pro, and Nano, and can accept up to one million tokens in the context window.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gemini 1.5**：Google最新的模型于2024年2月发布，具有更高效的架构和增强的性能。它有三种尺寸：Ultra、Pro和Nano，上下文窗口可以接受多达一百万个token。'
- en: Next, let’s explore image generation models.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探索图像生成模型。
- en: Image
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像
- en: 'In the evolving landscape of computer vision, image generation models are advancing,
    with key areas such as image synthesis and classification already somewhat mature.
    Emerging fields include visual question and answer, which interprets images to
    answer queries, and image segmentation, which breaks down images for detailed
    analysis. The key areas are detailed in the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉不断发展的领域中，图像生成模型正在进步，关键领域如图像合成和分类已经相对成熟。新兴领域包括视觉问答，它通过解释图像来回答查询，以及图像分割，它将图像分解以进行详细分析。以下详细介绍了关键领域：
- en: '**Image synthesis**: Generating new images or altering existing ones based
    on specific inputs or requirements'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像合成**：根据特定的输入或要求生成新图像或修改现有图像'
- en: '**Image classification**: Identifying and categorizing objects within an image
    into predefined classes, crucial for applications such as facial recognition and
    automated photo tagging'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分类**：将图像中的对象识别和分类到预定义的类别中，这对于人脸识别和自动照片标记等应用至关重要'
- en: '**Visual question answering** (**VQA**): Combining image processing and natural
    language understanding to answer questions about a given image'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉问答（VQA**）：结合图像处理和自然语言理解来回答关于给定图像的问题'
- en: '**Image segmentation**: Dividing an image into segments or parts for simpler,
    more meaningful analysis'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分割**：将图像分割成片段或部分，以便进行更简单、更有意义的分析'
- en: 'These capabilities make image-generation models invaluable tools and have led
    to the creation of innovative applications. In the following, we have mentioned
    a few interesting business applications that are emerging across various industries
    due to the advancements in recent image generation models:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这些能力使图像生成模型成为无价之宝，并导致了创新应用的诞生。以下，我们提到了由于近期图像生成模型的发展，在各个行业中涌现的几个有趣的商业应用：
- en: '**Generating Images from Text Descriptions**: Image generation models can take
    text descriptions as input and create corresponding images. This is valuable in
    applications such as generating illustrations for books, articles, or product
    listings. For example, a text description of a tropical beach scene can be turned
    into a realistic image of that scene, aiding in visual storytelling and marketing.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从文本描述生成图像**：图像生成模型可以接受文本描述作为输入并创建相应的图像。这在生成书籍、文章或产品列表的插图等应用中非常有价值。例如，一个热带海滩场景的文本描述可以转化为该场景的逼真图像，有助于视觉叙事和营销。'
- en: '**Storyboarding**: Entertainment firms are utilizing image-generation models
    for crafting storyboards. These visual aids depict narratives, concepts, or scripts,
    offering a glimpse into how a story might appear when animated or performed.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故事板制作**：娱乐公司正在利用图像生成模型来制作故事板。这些视觉辅助工具描绘叙事、概念或剧本，为故事动画或表演时的外观提供一瞥。'
- en: '**Fashion design**: Image generation models are helping fashion designers create
    new clothing designs by generating various apparel designs, patterns, and color
    combinations. Designers can input parameters or inspiration, and the model can
    generate visual concepts to inspire new collections.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时尚设计**：图像生成模型正帮助时尚设计师通过生成各种服装设计、图案和色彩组合来创造新的服装设计。设计师可以输入参数或灵感，模型可以生成视觉概念来启发新的系列。'
- en: '**Interior design**: Similarly, for interior designers, these models can generate
    room layouts, furniture arrangements, and decor ideas based on input criteria,
    enabling quick and creative design exploration.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**室内设计**：类似地，对于室内设计师来说，这些模型可以根据输入标准生成房间布局、家具排列和装饰理念，从而实现快速和富有创意的设计探索。'
- en: '**Automatic photo editing**: Image generation models can be used to automate
    and enhance the photo editing process. They can intelligently adjust color balance,
    contrast, and lighting, remove unwanted objects or blemishes, and apply artistic
    filters or styles to photos. This can significantly reduce the time and effort
    required for manual photo editing tasks.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动照片编辑**：图像生成模型可用于自动化和增强照片编辑过程。它们可以智能地调整色彩平衡、对比度和照明，移除不需要的对象或瑕疵，并应用于照片的艺术滤镜或风格。这可以显著减少手动照片编辑任务所需的时间和精力。'
- en: '**Creating digital artwork**: Digital artists and illustrators can use image
    generation models to spark their creativity. These models can generate abstract
    or realistic art pieces, offer new design ideas, or assist in creating concept
    art for various projects. Artists can use the generated images as a starting point
    for their work.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建数字艺术品**：数字艺术家和插图画家可以使用图像生成模型激发他们的创造力。这些模型可以生成抽象或逼真的艺术作品，提供新的设计理念，或协助为各种项目创建概念艺术。艺术家可以使用生成的图像作为他们工作的起点。'
- en: '**Doctor copilot**: This falls under the multimodal category, where the diverse
    functionalities of LLMs are applied to a variety of medical imaging tasks, including
    medical visual question-and-answer scenarios. Essentially, this involves developing
    applications that can respond to queries from doctors regarding X-rays or CT scans
    as well as aid in the generation of radiology reports.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医生副驾驶**：这属于多模态类别，其中LLM的多样化功能被应用于各种医学影像任务，包括医学视觉问答场景。本质上，这涉及到开发能够响应医生关于X光或CT扫描的查询以及帮助生成放射学报告的应用程序。'
- en: '**Facial recognition**: Image generation models can enhance facial recognition
    by creating diverse, high-quality training datasets, enabling the algorithms to
    learn and identify a wide range of facial features and expressions under various
    conditions. Additionally, they can assist in reconstructing partial or obscured
    faces in images, improving the accuracy and reliability of recognition systems.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面部识别**：图像生成模型可以通过创建多样化的、高质量的训练数据集来增强面部识别，使算法能够在各种条件下学习并识别广泛的面部特征和表情。此外，它们还可以帮助在图像中重建部分或被遮挡的面部，提高识别系统的准确性和可靠性。'
- en: 'The following highlights the leading image generation models as of December
    2023 in a rapidly advancing field:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列出了截至2023年12月，在快速发展的领域中领先的图像生成模型：
- en: '**DALL-E3**: Developed by OpenAI, DALL-E 3 is an advanced AI model capable
    of generating detailed and imaginative images from textual descriptions.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DALL-E3**：由OpenAI开发，DALL-E 3是一个高级AI模型，能够根据文本描述生成详细和富有想象力的图像。'
- en: '**Google’s Imagen**: Imagen by Google is a text-to-image diffusion AI model
    known for producing highly photorealistic images from textual prompts.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谷歌的Imagen**：谷歌的Imagen是一个文本到图像的扩散AI模型，以其能够从文本提示中生成高度逼真的图像而闻名。'
- en: '**Stable Diffusion**: Stable Diffusion, an open source model created by Stability
    AI, is a text-to-image model designed to generate high-quality images based on
    user-provided text descriptions.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Stable Diffusion**：Stable Diffusion是由Stability AI创建的开源模型，是一个文本到图像模型，旨在根据用户提供的文本描述生成高质量的图像。'
- en: '**Midjourney v5.2**: Midjourney v5.2, developed by Midjourney Inc. and launched
    in June 2023, represents the latest and most sophisticated iteration of Midjourney’s
    AI image generation model. This version focuses on enhancing the performance,
    consistency, and quality of the generated images. It is known for producing more
    detailed and sharper results with improved colors, contrast, and compositions
    compared to its predecessors.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Midjourney v5.2**：Midjourney v5.2是由Midjourney Inc.开发并于2023年6月推出的，代表了Midjourney
    AI图像生成模型的最新和最复杂版本。这个版本专注于提高生成图像的性能、一致性和质量。与前辈相比，它以更详细、更清晰的结果以及改进的颜色、对比度和构图而闻名。'
- en: '**Segment Anything Model** (**SAM**): The Segment Anything Model developed
    by Facebook’s Meta AI is not primarily an image generation model; instead, it’s
    an image segmentation model. Image segmentation models are designed to identify
    and delineate specific parts or objects within an image, essentially segmenting
    the image into different areas based on the objects present. We have mentioned
    it here as it falls under models within the realm of computer vision.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Segment Anything Model**（**SAM**）：由Facebook的Meta AI开发的Segment Anything Model（SAM）不是一个主要的图像生成模型；相反，它是一个图像分割模型。图像分割模型旨在识别和描绘图像中的特定部分或对象，本质上是根据图像中存在的对象将图像分割成不同的区域。我们在这里提到它，因为它属于计算机视觉领域的模型。'
- en: 'The following figure shows the segmentation of the New York skyline into different
    objects using SAM:'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了使用SAM将纽约天际线分割成不同对象的过程：
- en: '![Figure 1.7 – Image segmentation example](img/B21443_01_7.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7 – 图像分割示例](img/B21443_01_7.jpg)'
- en: Figure 1.7 – Image segmentation example
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – 图像分割示例
- en: Let’s move on to audio generation models.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论音频生成模型。
- en: Audio
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频
- en: 'Audio generation models are versatile tools for various applications, as demonstrated
    through our experience in developing solutions with our customers. The most popular
    tasks are as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 音频生成模型是适用于各种应用的通用工具，正如我们在与客户开发解决方案的经验中展示的那样。以下是最受欢迎的任务：
- en: '**Speech synthesis**: Generating human-like speech from text (text-to-speech)
    and used in voice assistants, audiobooks, and various accessibility tools'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音合成**：从文本生成类似人类的语音（文本到语音），并用于语音助手、有声读物和各种辅助工具。'
- en: '**Speaker identification**: Recognizing and differentiating between different
    speakers in audio recordings, which can be useful in security systems and personalized
    user experiences'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**说话人识别**：在音频记录中识别和区分不同的说话人，这在安全系统和个性化用户体验中可能很有用。'
- en: '**Emotion detection**: Identifying emotions from speech, which can enhance
    customer service interactions or aid in mental health assessments'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情感检测**：从语音中识别情感，这可以增强客户服务互动或帮助进行心理健康评估。'
- en: '**Sound generation**: Creating music or sound effects using AI, which has applications
    in entertainment, gaming, and virtual reality'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**声音生成**：使用AI创作音乐或音效，这在娱乐、游戏和虚拟现实领域有应用。'
- en: '**Voice cloning**: Generating a synthetic voice that sounds like a specific
    person, which can be used in personalized speech interfaces or entertainment'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**声音克隆**：生成与特定人物声音相似的人工合成声音，可用于个性化语音界面或娱乐'
- en: '**Speech recognition**: Converting spoken language into text, which is fundamental
    in creating transcriptions, automated subtitles, and voice commands'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音识别**：将口语语言转换为文本，这在创建转录、自动字幕和语音命令中是基本的'
- en: '**Speech translation**: Translating spoken language from one language to another
    in real-time, facilitating cross-lingual communication'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音翻译**：实时将一种语言的口语翻译成另一种语言，促进跨语言交流'
- en: 'Audio-based LLMs can generate various forms of audio, such as speech, music,
    and sound effects, based on textual or other input. For instance, here we mention
    a few emerging noteworthy business applications with audio generation models:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 基于音频的LLM可以根据文本或其他输入生成各种形式的音频，如语音、音乐和音效。例如，以下我们提到一些基于音频生成模型的值得关注的新兴商业应用：
- en: '**ChatBot audio and avatar**: Recent advancements in avatar-based experiences
    have led organizations to create immersive audio experiences featuring copilots
    with lifelike avatars'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天机器人音频和头像**：基于头像的体验的最近进展导致组织创建具有逼真头像的共飞行员沉浸式音频体验'
- en: '**Music composition and production**: These models are used to create new music
    pieces, simulate various musical styles, and assist composers in exploring new
    soundscapes and melodies'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音乐创作和生产**：这些模型用于创作新的音乐作品，模拟各种音乐风格，并协助作曲家探索新的声音景观和旋律'
- en: '**Sound effects and Foley in media production**: They can generate realistic
    or imaginative sound effects for use in films, video games, and other multimedia
    projects, offering a cost-effective alternative to traditional Foley artistry'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体制作中的音效和福雷**：它们可以生成用于电影、视频游戏和其他多媒体项目的逼真或富有想象力的音效，为传统的福雷艺术提供了一种成本效益高的替代方案'
- en: '**Language learning and pronunciation training**: By generating accurate and
    diverse speech samples, these models aid in language learning applications, helping
    users with pronunciation and listening comprehension'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言学习和发音训练**：通过生成准确且多样化的语音样本，这些模型有助于语言学习应用，帮助用户提高发音和听力理解'
- en: '**Accessibility applications**: Audio generation models are crucial in developing
    tools for visually impaired individuals, converting text and visual information
    into audio, thus enhancing accessibility in various digital platforms'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**辅助应用**：音频生成模型在开发为视障人士的工具中至关重要，将文本和视觉信息转换为音频，从而在各种数字平台上提高可访问性'
- en: 'This space is evolving, but there hasn’t been as much advancement in this domain
    as with text and image generation models. Here we mention a couple of interesting
    audio generation models from Google and OpenAI:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这个领域正在发展，但在这个领域的发展程度还没有像文本和图像生成模型那样高。以下我们提到来自谷歌和OpenAI的几个有趣的音频生成模型：
- en: '**MusicLM**: From Google Research, this is a cutting-edge AI model that transforms
    music creation using text prompts. It generates high-quality music across genres
    from simple text inputs. This innovative model utilizes a sophisticated hierarchical
    sequence-to-sequence approach, trained on a dataset of 5.5K expert-crafted music-text
    pairs, offering valuable opportunities for researchers and music enthusiasts.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MusicLM**：来自谷歌研究，这是一个前沿的AI模型，使用文本提示来转换音乐创作。它从简单的文本输入中生成跨流派的高质量音乐。这个创新模型利用了复杂的层次序列到序列方法，在5.5K个专家制作的音乐-文本对数据集上训练，为研究人员和音乐爱好者提供了宝贵的机会。'
- en: '**Open AI JukeBox**: This model, created by OpenAI in 2020, generates new music
    samples based on inputs such as genre, artist, and lyrics ([https://github.com/openai/jukebox](https://github.com/openai/jukebox)).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Open AI JukeBox**：这个模型由OpenAI于2020年创建，根据流派、艺术家和歌词等输入生成新的音乐样本（[https://github.com/openai/jukebox](https://github.com/openai/jukebox)）。'
- en: Finally, we look at video generation models.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来看视频生成模型。
- en: Video
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频
- en: 'Video generation models, which are advanced forms of AI designed to create,
    manipulate, and analyze video content, can perform a wide range of tasks. Some
    of the key emerging tasks across our customers in this field are as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 视频生成模型是高级人工智能形式，旨在创建、操作和分析视频内容，可以执行各种任务。我们客户在这个领域的几个关键新兴任务如下：
- en: '**Video synthesis**: Creating new video content from scratch or based on textual
    descriptions, which includes generating realistic scenes, animations, or simulations'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频合成**：从头开始创建或基于文本描述创建新的视频内容，这包括生成逼真的场景、动画或模拟'
- en: '**Deepfake generation**: Creating highly realistic and convincing videos where
    one person’s likeness is replaced with another, often used in film production,
    in education, or for entertainment purposes'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度伪造生成**：创建高度逼真且令人信服的视频，其中一个人的形象被另一个人的形象所取代，常用于电影制作、教育或娱乐目的'
- en: '**Video editing and enhancement**: Automatically editing videos to improve
    their quality, such as enhancing resolution, color correction, and stabilizing
    shaky footage'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频编辑和增强**：自动编辑视频以提高其质量，例如增强分辨率、色彩校正和稳定抖动的画面'
- en: '**Video summarization**: Condensing longer videos into shorter summaries while
    retaining the essential content, which is useful for quickly conveying information
    in large video files'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频摘要**：将较长的视频压缩成较短的摘要，同时保留关键内容，这对于快速传达大量视频文件中的信息非常有用'
- en: '**Object tracking and recognition**: Identifying and tracking objects or individuals
    across a video sequence, which is crucial for surveillance, sports analysis, and
    autonomous vehicles'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标跟踪和识别**：在视频序列中识别和跟踪物体或个人，这对于监控、体育分析和自动驾驶汽车至关重要'
- en: '**Scene understanding**: Analyzing a video to understand the context, setting,
    or events taking place, which can be applied in video indexing and search systems'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景理解**：分析视频以理解上下文、场景或正在发生的事件，这可以应用于视频索引和搜索系统'
- en: '**Motion analysis**: Studying the movement of objects or individuals within
    a video, applicable in sports training, physical therapy, and animation'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运动分析**：研究视频中的物体或个人的运动，适用于体育训练、物理治疗和动画'
- en: '**Facial expression and gesture analysis**: Interpreting facial expressions
    and body language to gauge emotions, reactions, or intentions, which is useful
    in customer service or behavioral studies'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面部表情和手势分析**：解释面部表情和肢体语言以衡量情绪、反应或意图，这在客户服务或行为研究中非常有用'
- en: '**Video-to-text transcription**: Converting the visual and auditory components
    of a video into textual descriptions, aiding in content accessibility and searchability'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频转文字转录**：将视频的视觉和听觉成分转换为文本描述，有助于内容的可访问性和可搜索性'
- en: '**Interactive video creation**: Generating interactive videos where viewers
    can influence the storyline or outcome, enhancing user engagement in gaming, education,
    and marketing'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互式视频创作**：生成交互式视频，其中观众可以影响故事情节或结果，增强游戏、教育和营销中的用户参与度'
- en: 'Text-to-video models are a type of AI technology that generates video content
    based on textual descriptions. While there have been considerable advancements
    in recent **text-to-video** (**T2V**) generation techniques, most of these developments
    are concentrated on creating short video clips that depict a single event set
    against a single backdrop, essentially limited to single-scene videos. As video
    generation models evolve, exciting new applications are beginning to emerge, offering
    innovative possibilities in this field:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到视频模型是一种基于文本描述生成视频内容的AI技术。尽管在最近的**文本到视频**（**T2V**）生成技术方面取得了相当大的进步，但这些发展主要集中在创建描绘单一事件且背景单一的短视频片段上，本质上局限于单场景视频。随着视频生成模型的演变，一些令人兴奋的新应用开始出现，为该领域提供了创新的可能性：
- en: '**Q&A over video archive**: In the media and entertainment industry, a prominent
    use case emerging involves embedding video data using models such as CLIP and
    then creating enhanced search experiences on top of it'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频档案问答**：在媒体和娱乐行业，一个正在兴起的主要用例涉及使用CLIP等模型嵌入视频数据，然后在上面创建增强的搜索体验'
- en: '**Film and animation**: These models can aid in rapidly prototyping scenes
    and creating short animations, streamlining the filmmaking and animation process'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电影和动画**：这些模型可以帮助快速原型设计和创建短片动画，简化电影和动画制作过程'
- en: '**Advertising and marketing**: Businesses can utilize video generation models
    to create engaging content for marketing campaigns and advertisements tailored
    to specific audiences'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广告和营销**：企业可以利用视频生成模型为营销活动和广告创建吸引人的内容，这些内容针对特定受众'
- en: '**Education and training**: They can enhance educational content by producing
    custom videos that illustrate complex concepts or simulate real-life scenarios
    for more effective learning and training'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教育和培训**：它们可以通过制作展示复杂概念或模拟真实场景的定制视频来增强教育内容，从而实现更有效的学习和培训'
- en: '**Gaming and virtual reality**: In gaming, these models can be used to generate
    dynamic environments and characters, enriching the gaming experience, and reducing
    development time'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**游戏和虚拟现实**：在游戏中，这些模型可以用来生成动态环境和角色，丰富游戏体验，并减少开发时间'
- en: '**Research and development**: Video generation models are valuable in visualizing
    scientific theories, simulating experiments, or presenting research findings in
    an interactive format'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究和开发**：视频生成模型在可视化科学理论、模拟实验或以交互式格式展示研究结果方面非常有价值'
- en: 'This space is evolving and there hasn’t been as much advancement in the video
    domain as with text and image generation models. Here we mention two models with
    promising capabilities in the video space:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这个领域正在不断发展，视频领域的进步并没有像文本和图像生成模型那样显著。在这里，我们提到了两个在视频领域具有潜力的模型：
- en: '**Stable Video Diffusion**: Announced in November 2023 by Stability AI, this
    is a model that creates high-resolution videos (576 x 1024) from text or single
    images. It advances latent diffusion models previously limited to 2D images to
    video, maintaining high detail at 14 or 25 frames per second. The research highlights
    the importance of data curation in enhancing high-resolution video generation
    performance ([https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt)).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳定的视频扩散**：Stability AI于2023年11月宣布，这是一个从文本或单张图像创建高分辨率视频（576 x 1024）的模型。它将之前仅限于2D图像的潜在扩散模型推进到视频领域，在每秒14或25帧的帧率下保持高细节。研究强调了数据整理在提高高分辨率视频生成性能方面的重要性（[https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt)）。'
- en: '**GPT-4V**: From OpenAI, this is a multimodal LLM capable of analyzing videos
    but unable to generate videos as of early 2024.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4V**：来自OpenAI，这是一个多模态LLM，能够分析视频，但截至2024年初尚不能生成视频。'
- en: Note
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: OpenAI announced SORA in early 2024, its first text-to-video generation model.
    Although it has not been released to the public as it is undergoing comprehensive
    red teaming testing, based on the samples shared by OpenAI, we think this innovation
    is a significant leap in multimodal LLMs. It allows you to transform text prompts
    into high-quality, one-minute videos.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在2024年初宣布了SORA，这是其首个文本到视频生成模型。尽管它尚未向公众发布，因为它正在进行全面的红队测试，但根据OpenAI分享的样本，我们认为这一创新是多模态LLM的重大飞跃。它允许您将文本提示转换为高质量的一分钟视频。
- en: 'Here’s what SORA brings to the table:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是SORA带来的优势：
- en: '**Complex scene generation**: SORA excels in creating detailed scenes featuring
    multiple characters, various motions, and precise subject and background details.
    The model understands not only what the user has asked for in the prompt, but
    also how those things exist in the physical world.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂场景生成**：SORA在创建包含多个角色、各种动作和精确主题和背景细节的详细场景方面表现出色。该模型不仅理解用户在提示中要求的内容，还理解这些事物在物理世界中的存在方式。'
- en: '**Advanced language comprehension**: With its profound grasp of language, SORA
    can bring prompts to life with characters that showcase a range of emotions. Moreover,
    it can craft multiple shots within a video, maintaining consistency in character
    and visual style.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级语言理解**：凭借其对语言的深刻理解，SORA可以通过展示各种情绪的角色使提示栩栩如生。此外，它可以在视频中制作多个镜头，保持角色和视觉风格的一致性。'
- en: We have highlighted the most prominent LLMs currently known. However, the field
    is advancing swiftly, and fresh models are continuously emerging. For the latest
    and trending models, we suggest regularly visiting the Hugging Face website, which
    maintains an up-to-date list of these innovative and influential models ([https://huggingface.co/models](https://huggingface.co/models)).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经突出了目前已知的最突出的LLM。然而，该领域正在迅速发展，新的模型不断涌现。对于最新和趋势性的模型，我们建议定期访问Hugging Face网站，该网站维护着这些创新和有影响力的模型的最新列表（[https://huggingface.co/models](https://huggingface.co/models)）。
- en: Cloud computing for scalability, cost optimization, and security
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云计算用于可扩展性、成本优化和安全
- en: Cloud computing has been instrumental in bringing LLMs to a wider audience.
    LLMs use large-scale GPU processing to learn and generate human-like text, image,
    audio, and video, engaging in increasingly interactive and intelligent ways.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算在将LLM带给更广泛的受众方面发挥了关键作用。LLM使用大规模GPU处理来学习和生成类似人类的文本、图像、音频和视频，并以越来越互动和智能的方式参与其中。
- en: 'This section highlights several advantages of leveraging LLMs in a cloud environment:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 本节突出了在云环境中利用LLM的几个优势：
- en: '**Scalability**: Cloud computing enables users to access high-performance computing
    such as GPUs as necessary to run LLMs. This makes it easy to scale applications
    as required based on consumption needs.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：云计算使用户能够根据需求访问高性能计算，如GPU，以运行LLM。这使得根据消费需求轻松扩展应用程序变得容易。'
- en: Since LLM models such as GPT are heavy API-driven workloads, there is a need
    for API management services, such as Azure APIM, that help achieve scalability,
    security, and high availability across regions. They can also capture telemetry
    that can help determine token usage and error logging across organizations. We
    discuss scaling strategies on Azure in [*Chapter 7*](B21443_07.xhtml#_idTextAnchor143).
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于LLM模型如GPT是重量级的API驱动工作负载，因此需要API管理服务，如Azure APIM，以帮助实现跨区域的可扩展性、安全性和高可用性。它们还可以捕获遥测数据，有助于确定组织间的令牌使用和错误日志。我们将在[*第7章*](B21443_07.xhtml#_idTextAnchor143)中讨论Azure上的扩展策略。
- en: '**Affordability**: There is no need for large upfront infrastructure investment
    as you can easily access computing power from the cloud, making it more affordable.
    Utilizing a pay-as-you-go service allows you the flexibility to activate instances
    for open source models as needed and terminate them at your convenience, ensuring
    that you have control and adaptability in managing your resources.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**经济性**：您无需进行大量前期基础设施投资，因为您可以从云中轻松访问计算能力，这使得成本更低。利用按需付费服务，您可以根据需要激活开源模型的实例，并在方便时终止它们，确保您在管理资源时拥有控制和适应性。'
- en: '**Data storage**: LLMs may require a large amount of data for training and
    fine-tuning. Cloud services offer scalable and cheap storage options to manage
    vast amounts of structured and unstructured data.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据存储**：LLM可能需要大量数据用于训练和微调。云服务提供可扩展且经济的存储选项，以管理大量结构化和非结构化数据。'
- en: For instance, Azure Blob Storage provides several cheap and flexible storage
    options for storing structured and unstructured data and this can be used in conjunction
    with Azure AI search to enable vector storage with advanced security capabilities.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，Azure Blob存储提供了多种经济且灵活的存储选项，用于存储结构化和非结构化数据，并且可以与Azure AI搜索结合使用，以实现具有高级安全功能的向量存储。
- en: '**Accessibility and collaboration**: Cloud platforms make it easy to access
    LLMs from anywhere in the world, making it easy for researchers, data scientists,
    cloud architects, and developers to collaborate.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可访问性和协作**：云平台使您能够从世界任何地方轻松访问LLM，这使得研究人员、数据科学家、云架构师和开发者之间的协作变得容易。'
- en: '**Managed services**: Cloud platforms offer managed services that can simplify
    deployment and infrastructure management for LLMs on the cloud.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**托管服务**：云平台提供托管服务，可以简化云上LLM的部署和基础设施管理。'
- en: For instance, Microsoft’s model-as-a-service allows you to deploy open source
    models such as Llama 2 as a pay-as-you-go service. Azure handles the infrastructure
    provisioning and charges you based on token usage. This eliminates the management
    overhead of provisioning inference computing for open source models.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，微软的模型即服务允许您将开源模型如Llama 2作为按需付费服务部署。Azure负责基础设施配置，并按令牌使用量向您收费。这消除了为开源模型配置推理计算的管理开销。
- en: '**Speed**: With access to the cloud, you have access to high-speed computer
    power, providing you with more options based on the latency needs of your LLM
    applications.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：通过访问云，您可以使用高速计算机能力，这为您提供了更多基于LLM应用程序延迟需求的选择。'
- en: In Azure, you can get access to several GPU-optimized VM sizes options, such
    as Nvidia A100s V4 series and NCV3 series ([https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu)).
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在Azure中，您可以访问多个GPU优化的虚拟机大小选项，例如Nvidia A100s V4系列和NCV3系列([https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu))。
- en: Different LLMs may necessitate varying sizes of GPU computing power that affect
    the latency and cost of running the applications.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不同的LLM可能需要不同大小的GPU计算能力，这会影响应用程序的延迟和成本。
- en: '**Security and compliance**: Top cloud platforms provide comprehensive and
    industry-leading security and compliance services for your data, thus providing
    authentication, authorization, encryption, monitoring, and logging capabilities
    to protect your AI infrastructure. They also provide services to identify potential
    jailbreak attacks. Jailbreak attacks on LLMs are methods used to bypass or manipulate
    the model’s safety and ethical guidelines to elicit prohibited or restricted responses.
    We will learn more about jailbreak attacks in [*Chapter 8*](B21443_08.xhtml#_idTextAnchor163)
    on security.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全和合规性**：顶级云平台为您提供全面且行业领先的网络安全和合规性服务，从而为您的数据提供身份验证、授权、加密、监控和日志记录功能，以保护您的AI基础设施。它们还提供识别潜在越狱攻击的服务。对LLM的越狱攻击是绕过或操纵模型的安全和道德指南以诱发出禁止或受限响应的方法。我们将在第8章[安全](B21443_08.xhtml#_idTextAnchor163)中了解更多关于越狱攻击的内容。'
- en: '**Responsible AI solutions**: With the advent of new-generation AI applications,
    implementing robust guardrails to detect and filter out harmful content becomes
    crucial. Tools such as Azure Content Safety are designed to moderate text and
    image content, helping to maintain a safe and appropriate user experience. Additionally,
    the use of safety metaprompts, which are essentially guiding instructions or constraints
    embedded in the system messages of LLMs, plays a vital role. These metaprompts
    can instruct the LLM to avoid generating inappropriate, biased, or harmful content,
    acting as an integral part of the model’s ethical framework and ensuring responsible
    AI usage.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负责任的AI解决方案**：随着新一代AI应用的兴起，实施强大的防护措施以检测和过滤有害内容变得至关重要。例如，Azure内容安全工具旨在调节文本和图像内容，帮助维护安全且适当的使用体验。此外，使用安全元提示也发挥着至关重要的作用，这些元提示本质上是在LLM的系统消息中嵌入的指导性指令或约束。这些元提示可以指导LLM避免生成不适当、有偏见或有害的内容，作为模型道德框架的组成部分，并确保负责任的AI使用。'
- en: While it’s possible to deploy certain open source models on personal laptops
    or establish a dedicated infrastructure within an organization, this approach
    often incurs substantial upfront costs, including significant investment in talent
    acquisition and ongoing management overhead. Additionally, maintaining the security
    of such infrastructure might not match the advanced levels offered by cloud service
    providers. Therefore, cloud services emerge as the more advantageous solution,
    offering a wide array of flexible, secure, scalable, and ethically responsible
    options for deploying generative AI solutions. In the next section, we will delve
    into the process of transforming an innovative idea into reality, examining the
    various stages involved in deploying it on the cloud and using our experiences
    as cloud solution architects during the initial stages of generative AI deployments
    across various organizations.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在个人笔记本电脑上部署某些开源模型或在组织内建立专用基础设施是可能的，但这种方法通常会产生大量的前期成本，包括对人才获取的重大投资和持续的管理开销。此外，维护此类基础设施的安全性可能无法与云服务提供商提供的先进水平相匹配。因此，云服务成为更优的解决方案，提供了一系列灵活、安全、可扩展且负责任的选项，用于部署生成式AI解决方案。在下一节中，我们将深入探讨将创新想法转化为现实的过程，检查将其部署到云上涉及的各个阶段，并回顾我们在将生成式AI部署到各个组织初期阶段作为云解决方案架构师的经验。
- en: From vision to value – navigating the journey to production
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从愿景到价值——导航生产之旅
- en: Developing an idea and moving it into production is a multi-phase process that
    typically involves ideation, validation, development, testing, and deployment.
    The multi-phase process of developing an idea and moving it into production is
    crucial because it methodically transforms a concept into a viable product.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个想法开发并投入生产是一个多阶段的过程，通常涉及构思、验证、开发、测试和部署。将一个想法开发并投入生产的多阶段过程至关重要，因为它系统地将一个概念转化为可行的产品。
- en: 'Take a look at the following image about overlooking a crucial aspect:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 看看以下关于忽视关键方面的图片：
- en: '![Figure 1.8 – Two entrepreneurs engaging in a humorous discussion about overlooking
    expenses](img/B21443_01_8.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图1.8 – 两位企业家就忽视开支进行幽默讨论](img/B21443_01_8.jpg)'
- en: Figure 1.8 – Two entrepreneurs engaging in a humorous discussion about overlooking
    expenses
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 – 两位企业家就忽视开支进行幽默讨论
- en: The above image satirically showcases how some organizations claim to build
    AI from scratch, when in reality, they're just utilizing API calls to services
    like OpenAI. It humorously uncovers this exaggeration when asked about the Open
    AI bills, mocking the notion of starting from scratch.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图像讽刺性地展示了某些组织声称从头开始构建AI，而实际上他们只是利用了像OpenAI这样的服务的API调用。当被问及Open AI账单时，它幽默地揭露了这种夸张，嘲讽了从头开始的概念。
- en: 'Each phase serves a distinct purpose: ideation fosters innovation, validation
    ensures market demand and feasibility, development translates validated ideas
    into tangible products, testing guarantees functionality and user satisfaction,
    and deployment introduces the product into the market. This structured approach
    mitigates risks, optimizes the use of resources, assures product quality, and
    secures market fit. It’s a strategic pathway that allows for informed decision-making
    and efficient allocation of capital and maximizes the chances of commercial success.
    Here’s a structured approach:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 每个阶段都有其独特的作用：创意促进创新，验证确保市场需求和可行性，开发将验证的想法转化为有形产品，测试保证功能性和用户满意度，部署将产品引入市场。这种结构化方法降低了风险，优化了资源的使用，保证了产品质量，并确保了市场适应性。这是一个战略途径，允许进行明智的决策，有效地分配资本，并最大限度地提高商业成功的可能性。以下是一个结构化方法：
- en: '![Figure 1.9 – Stages from ideation to deployment](img/B21443_01_9.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图1.9 – 从创意到部署的阶段](img/B21443_01_9.jpg)'
- en: Figure 1.9 – Stages from ideation to deployment
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9 – 从创意到部署的阶段
- en: Let’s look at each stage in more detail.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看每个阶段。
- en: 'The following steps are involved in ideation:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 创意涉及以下步骤：
- en: Generate and brainstorm ideas without constraints to encourage creativity
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无限制地生成和头脑风暴想法，以鼓励创造力
- en: Prioritize ideas based on factors such as feasibility, market potential, and
    alignment with business goals
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据可行性、市场潜力和与业务目标的一致性等因素优先考虑想法
- en: 'Hackathon events: fostering innovation in generative AI'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 黑客马拉松活动：促进生成式AI的创新
- en: In our early roles as Cloud Architects in the generative AI space, we witnessed
    a surge of hackathon events across various organizations. These events, integral
    to the ideation phase, encouraged rapid problem-solving, innovative thinking,
    and the free exchange of ideas, unencumbered by the usual workplace constraints.
    Participants were exposed to new perspectives and skills, while the event’s structure
    promoted quick development and validation of ideas. The combination of collaboration,
    focused effort, and a supportive community made hackathons an ideal breeding ground
    for creative solutions and new concepts.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们作为生成式AI领域的早期云架构师角色中，我们见证了各种组织之间黑客马拉松活动的激增。这些活动对于创意阶段至关重要，鼓励了快速的问题解决、创新思维和不受通常工作场所限制的自由思想交流。参与者接触到了新的观点和技能，而活动结构促进了快速的开发和想法验证。协作、专注的努力和支持性的社区使黑客马拉松成为创意解决方案和新概念的理想孵化地。
- en: 'The following steps are involved in market research and validation:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 市场研究和验证涉及以下步骤：
- en: Conduct thorough market research to understand the demand and competition
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行彻底的市场研究，以了解需求和竞争
- en: Validate the idea through customer interviews, surveys, or focus groups
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过客户访谈、调查或焦点小组来验证想法
- en: 'The following steps are involved in **Proof of** **Concept** (**PoC**):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念验证**（PoC）涉及以下步骤：'
- en: Create a PoC to demonstrate the idea’s feasibility
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个PoC来展示想法的可行性
- en: Use the PoC to gather initial feedback and iterate on the design
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PoC收集初步反馈并迭代设计
- en: Determine success criteria for the PoC
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定PoC的成功标准
- en: 'Initial PoCs: leveraging ChatGPT for internal co-pilots'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 初始PoC：利用ChatGPT进行内部合作飞行员
- en: Drawing from our experience, the initial PoCs typically involve internal-facing
    co-pilots utilizing the ‘ChatGPT on your data’ feature on Azure focused on organizational
    data. These projects were seen as low-hanging fruit, offering rapid wins and valuable
    lessons learned.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的经验中汲取，最初的PoC通常涉及面向内部使用的合作飞行员，利用Azure上的“ChatGPT在你的数据上”功能，专注于组织数据。这些项目被视为低垂的果实，提供了快速的成功和宝贵的经验教训。
- en: 'The following steps are involved in business case and planning:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 商业案例和规划涉及以下步骤：
- en: Build a business case by outlining the value proposition, market entry strategy,
    and financial projections
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过概述价值主张、市场进入策略和财务预测来构建商业案例
- en: Plan the project, including timelines, budget, resources, and risk assessment
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划项目，包括时间表、预算、资源和风险评估
- en: Determine ROI
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定投资回报率
- en: ROI for generative AI workloads
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI工作负载的回报率（ROI）
- en: Assessing the ROI of generative AI workloads poses a significant challenge,
    involving not only the calculation of the end-to-end solution cost but also the
    quantification of returns through automation and the elimination of manual tasks.
    Adding to this, offering the solution as a white-label product for other companies
    can substantially enhance ROI. This approach opens new revenue streams, offers
    cost efficiency for clients, enables scalability, indirectly boosts brand recognition,
    and provides a rich feedback loop for product improvement. By leveraging white
    labeling, businesses can maximize the value and reach of their generative AI solutions,
    making it a strategic move to increase overall returns on investment in a competitive
    market. In [*Chapter 7*](B21443_07.xhtml#_idTextAnchor143), we discuss a few of
    the cost optimization strategies companies can leverage to reduce their overall
    cost of generative AI workloads.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 评估生成式AI工作负载的回报率（ROI）是一个重大挑战，这不仅涉及端到端解决方案成本的计算，还包括通过自动化和消除手动任务来量化回报。此外，将解决方案作为白标产品提供给其他公司可以显著提高回报率。这种方法开辟了新的收入来源，为客户提供了成本效益，实现了可扩展性，间接提升了品牌知名度，并为产品改进提供了丰富的反馈循环。通过利用白标，企业可以最大化其生成式AI解决方案的价值和影响力，使其成为在竞争激烈的市场中增加整体投资回报率的一项战略举措。在[*第7章*](B21443_07.xhtml#_idTextAnchor143)中，我们讨论了几种公司可以利用的成本优化策略，以降低其生成式AI工作负载的整体成本。
- en: 'The following steps are involved in prototype/MVP development:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 原型/最小可行产品（MVP）开发中涉及以下步骤：
- en: Develop a prototype that’s closer to the product than the PoC
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个比原型更接近产品的原型
- en: Iterate on the prototype based on feedback and technical feasibility
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据反馈和技术可行性对原型进行迭代
- en: Develop an MVP with the minimal necessary features to satisfy early adopters
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发具有最小必要功能的最小可行产品（MVP）以满足早期采用者
- en: The MVP serves to validate product-market fit and gather user feedback
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MVP旨在验证产品与市场的匹配度并收集用户反馈
- en: 'The following steps are involved in testing and quality assurance:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 测试和质量保证中涉及以下步骤：
- en: Perform various types of testing (unit, integration, system, user acceptance)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行各种类型的测试（单元、集成、系统、用户验收）
- en: Ensure that the product meets quality standards and is free of critical bugs
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保产品符合质量标准且无严重错误
- en: 'The following steps are involved in pre-production and staging:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 预生产和预发布中涉及以下步骤：
- en: Deploy the application in a staging environment that closely mimics production
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个与生产环境非常相似的预发布环境中部署应用程序
- en: Conduct further testing, including load and performance tests
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行进一步的测试，包括负载和性能测试
- en: 'The following steps are involved in the deployment strategy:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 部署策略中涉及以下步骤：
- en: Develop a deployment strategy, such as blue-green deployments and canary releases
    to minimize risks
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定部署策略，例如蓝绿部署和金丝雀发布，以最小化风险
- en: Plan for rollback procedures in the case of failures
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在出现故障的情况下计划回滚程序
- en: 'The following steps are involved in the launch:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 发布中涉及以下步骤：
- en: Launch the product to the target user base
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将产品发布到目标用户群体
- en: Monitor the product closely for any issues or unexpected behaviors
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密切关注产品，以发现任何问题或意外行为
- en: 'The following steps are involved in continuous monitoring and feedback loop:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 持续监控和反馈循环中涉及以下步骤：
- en: Establish mechanisms for continuous monitoring, error logging, and performance
    tracking through LLMOps
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过LLMOps建立持续监控、错误记录和性能跟踪的机制
- en: Create feedback channels for users to report issues or suggest improvements
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为用户提供反馈渠道，以便报告问题或提出改进建议
- en: Tip
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Large language model operations** (**LLMOps**) focus on deploying, managing,
    and scaling LLMs in production to ensure that they integrate smoothly into applications
    for optimal performance, security, and cost-effectiveness. This involves practices
    such as continuous integration and deployment for automated updates, continuous
    monitoring for performance and cost efficiency, version control for updates without
    disruption, security measures for compliance, and auto-scaling for demand changes.
    LLMOps are crucial for organizations using LLMs in production, simplifying operational
    challenges to foster innovation. More on LLMOps is discussed in [*Chapter 6*](B21443_06.xhtml#_idTextAnchor117).'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '**大型语言模型操作**（**LLMOps**）专注于在生产环境中部署、管理和扩展LLMs，以确保它们能够无缝集成到应用程序中，以实现最佳性能、安全性和成本效益。这包括持续集成和部署以实现自动化更新、持续监控性能和成本效率、版本控制以实现无中断的更新、合规性的安全措施以及自动扩展以应对需求变化。LLMOps对于在生产环境中使用LLMs的组织至关重要，它简化了运营挑战，以促进创新。关于LLMOps的更多内容将在[*第6章*](B21443_06.xhtml#_idTextAnchor117)中讨论。'
- en: 'The following steps are involved in iterative improvement:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代改进涉及以下步骤：
- en: Use data and user feedback to make iterative improvements to the product
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据和用户反馈对产品进行迭代改进
- en: Plan for regular updates and feature releases
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划定期更新和功能发布
- en: 'The following steps are involved in scalability:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性涉及以下步骤：
- en: Ensure that the architecture is scalable to handle growth in users or data
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保架构可扩展以处理用户或数据的增长
- en: Regularly review infrastructure and optimize as necessary
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期审查基础设施并在必要时进行优化
- en: We recommend
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议
- en: This approach is vital to guarantee superior user experience, ensuring the solution’s
    high availability and incorporating disaster recovery measures. We discuss these
    concepts elaborately in [*Chapter 7*](B21443_07.xhtml#_idTextAnchor143).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法对于保证卓越的用户体验至关重要，确保解决方案的高可用性并纳入灾难恢复措施。我们将在[*第7章*](B21443_07.xhtml#_idTextAnchor143)中详细讨论这些概念。
- en: 'The following steps are involved in maintenance and support:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 维护和支持涉及以下步骤：
- en: Provide ongoing maintenance and support to users
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为用户提供持续维护和支持
- en: Keep the product up to date with the latest security patches and compliance
    standards
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持产品与最新的安全补丁和合规标准保持同步
- en: Throughout this process, it’s essential to stay agile and be prepared to pivot
    or make changes based on new insights and feedback. Communicate regularly with
    all stakeholders and ensure that there’s a clear understanding of the vision,
    progress, and challenges associated with developing the idea and moving it into
    production.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，保持敏捷并准备好根据新的见解和反馈进行转变或做出改变至关重要。定期与所有利益相关者沟通，并确保对开发想法并将其投入生产相关的愿景、进展和挑战有清晰的理解。
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The aim of this introductory chapter was to highlight the history, core concepts,
    and other essential information necessary for readers to develop an end-to-end
    generative AI solution on the cloud. We have explored the evolution of chatbots
    from simple rule-based systems to multimodal, context-aware, and action-oriented
    agentic LLMs. We delved into the rise of generative AI, focusing on LLMs and foundation
    models as well as their relationship and key attributes. The differences between
    open source and closed source models were examined, alongside trending business
    applications drawn from our experiences. In the rapidly evolving landscape of
    AI, we’ve examined a few leading models, including text, image, audio, and video
    generation. These models represent the forefront of AI technology, showcasing
    remarkable capabilities in creating high-quality, lifelike content. We then highlighted
    how cloud computing facilitates the development of secure, scalable, cost-efficient,
    and ethical generative AI applications. We also outlined a framework for transforming
    ideas into production-ready solutions. In the next chapter, we’ll dive into the
    NLP capabilities of LLMs and their transformer architecture, which is fundamental
    to the functioning of these models.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是突出介绍生成式AI在云上构建端到端解决方案所需的历史、核心概念和其他必要信息。我们探讨了从简单的基于规则的聊天机器人系统到多模态、上下文感知和以代理为导向的LLMs的演变。我们深入研究了生成式AI的兴起，重点关注LLMs和基础模型以及它们之间的关系和关键属性。我们考察了开源和闭源模型之间的差异，以及从我们的经验中提炼出的趋势商业应用。在人工智能快速发展的领域中，我们考察了几种领先模型，包括文本、图像、音频和视频生成。这些模型代表了人工智能技术的最前沿，展示了在创建高质量、逼真内容方面的非凡能力。然后我们强调了云计算如何促进安全、可扩展、成本效益和道德的生成式AI应用的发展。我们还概述了一个将想法转化为生产就绪解决方案的框架。在下一章中，我们将深入探讨LLMs的自然语言处理能力及其Transformer架构，这是这些模型运行的基础。
- en: References
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Nvidia Generative AI: [https://www.nvidia.com/en-us/glossary/data-science/generative-ai/#:~:text=Generative%20AI%20models%20use%20neural,semi%2Dsupervised%20learning%20for%20training](https://www.nvidia.com/en-us/glossary/data-science/generative-ai/#:~:text=Generative%20AI%20models%20use%20neural,semi%2Dsupervised%20learning%20for%20training)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '英伟达生成式AI: [https://www.nvidia.com/en-us/glossary/data-science/generative-ai/#:~:text=Generative%20AI%20models%20use%20neural,semi%2Dsupervised%20learning%20for%20training](https://www.nvidia.com/en-us/glossary/data-science/generative-ai/#:~:text=Generative%20AI%20models%20use%20neural,semi%2Dsupervised%20learning%20for%20training)'
- en: 'CSET Georgetown University: [https://cset.georgetown.edu/article/what-are-generative-ai-large-language-models-and-foundation-models/#:~:text=Using%20the%20term%20%E2%80%9Cgenerative%20AI,system%20that%20works%20with%20language](https://cset.georgetown.edu/article/what-are-generative-ai-large-language-models-and-foundation-models/#:~:text=Using%20the%20term%20%E2%80%9Cgenerative%20AI,system%20that%20works%20with%20language)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '乔治城大学CSET: [https://cset.georgetown.edu/article/what-are-generative-ai-large-language-models-and-foundation-models/#:~:text=Using%20the%20term%20%E2%80%9Cgenerative%20AI,system%20that%20works%20with%20language](https://cset.georgetown.edu/article/what-are-generative-ai-large-language-models-and-foundation-models/#:~:text=Using%20the%20term%20%E2%80%9Cgenerative%20AI,system%20that%20works%20with%20language)'
- en: 'Databricks course: [https://microsoft-academy.databricks.com/learn/course/1765/play/12440/llms-and-generative-ai](https://microsoft-academy.databricks.com/learn/course/1765/play/12440/llms-and-generative-ai)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Databricks课程: [https://microsoft-academy.databricks.com/learn/course/1765/play/12440/llms-and-generative-ai](https://microsoft-academy.databricks.com/learn/course/1765/play/12440/llms-and-generative-ai)'
