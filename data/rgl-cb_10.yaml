- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Regularization in Computer Vision
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉中的正则化
- en: In this chapter, we will explore another popular field of deep learning – computer
    vision. **Computer vision** is a large field with many tasks, from classification
    through generative models to object detection. Even though we can’t cover all
    of them, we will supply methods that can apply to all tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索深度学习的另一个热门领域——计算机视觉。**计算机视觉**是一个庞大的领域，包含许多任务，从分类、生成模型到物体检测。虽然我们无法覆盖所有内容，但我们会提供适用于所有任务的方法。
- en: 'In this chapter, we’ll cover the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下几种配方：
- en: Training a **convolutional neural** **network** (**CNN**)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个**卷积神经网络**（**CNN**）
- en: Regularizing a CNN with vanilla **neural network** (**NN**) methods
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用传统的**神经网络**（**NN**）方法对CNN进行正则化
- en: Regularizing a CNN with transfer learning for object detection
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用迁移学习对CNN进行正则化以进行物体检测
- en: Semantic segmentation using transfer learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用迁移学习进行语义分割
- en: At the end of this chapter, you will be able to handle several computer vision
    tasks such as image classification, object detection, instance segmentation, and
    semantic segmentation. You will be able to apply several tools to regularize the
    trained models, such as architecture, transfer learning, and freezing weights
    for fine-tuning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够处理多个计算机视觉任务，如图像分类、物体检测、实例分割和语义分割。你将能够应用多种工具来正则化训练的模型，如架构、迁移学习和冻结权重进行微调。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this section, we will train CNNs, object detection, and semantic segmentation
    models, requiring the following libraries:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将训练CNN、物体检测和语义分割模型，所需的库包括：
- en: NumPy
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: scikit-learn
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn
- en: Matplotlib
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib
- en: PyTorch
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch
- en: torchvision
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: torchvision
- en: Ultralytics
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ultralytics
- en: '`segmentation-models-pytorch`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`segmentation-models-pytorch`'
- en: Training a CNN
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练一个CNN
- en: In this recipe, after reviewing the fundamental components of CNN, we will train
    one on a classification task – the CIFAR10 dataset.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，在回顾CNN的基本组件后，我们将训练一个用于分类任务的CNN——CIFAR10数据集。
- en: Getting started
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用
- en: Computer vision is a special field for many reasons. The data handled in computer
    vision projects is usually rather large, multidimensional, and unstructured. However,
    its most specific aspect is arguably its spatial structure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉由于多种原因是一个特殊的领域。计算机视觉项目中处理的数据通常是相当庞大、多维且无结构的。然而，它最具特征的方面可能就是其空间结构。
- en: 'With its spatial structure comes a lot of potential difficulties, such as the
    following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其空间结构带来了许多潜在的困难，如下所示：
- en: '**Aspect ratio**: Some images come with different aspect ratios depending on
    their source, such as 16/9, 4/3, 1/1, and 9/16'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**纵横比**：一些图像根据来源不同，可能具有不同的纵横比，如16/9、4/3、1/1和9/16'
- en: '**Occlusion**: An object can be occluded by another one'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮挡**：一个物体可能被另一个物体遮挡'
- en: '**Deformation**: An object can be deformed, either because of perspective or
    physical deformation'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变形**：物体可以因透视或物理变形而发生变形'
- en: '**Point of view**: Depending on the point of view, an object can look totally
    different'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视角**：根据视角的不同，一个物体可能看起来完全不同'
- en: '**Illumination**: A picture can be taken in many light environments that may
    alter the image'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光照**：一张图片可以在多种光照环境下拍摄，可能会改变图像'
- en: Many of these difficulties are summarized in *Figure 10**.1*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些困难在*图10.1*中做了总结。
- en: '![Figure 10.1 – Examples of difficulties specific to computer vision](img/B19629_10_01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 特定于计算机视觉的困难示例](img/B19629_10_01.jpg)'
- en: Figure 10.1 – Examples of difficulties specific to computer vision
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 特定于计算机视觉的困难示例
- en: Due to the spatial structure of data, models are needed to process it. While
    recurrent neural networks are well suited to sequential data, CNNs are well suited
    to spatially structured data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据的空间结构，需要模型来处理它。虽然循环神经网络非常适合处理顺序数据，但CNN非常适合处理空间结构化数据。
- en: 'In order to properly build a CNN, we need to introduce two new types of layers:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确构建CNN，我们需要引入两种新的层：
- en: Convolutional layers
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层
- en: Pooling layers
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化层
- en: Let’s quickly explain them both.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速解释一下它们两者。
- en: Convolutional layer
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积层
- en: A **convolutional layer** is a layer made of convolutions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积层**是由卷积操作组成的层。'
- en: In a fully connected layer, a weighted sum of the input features (or the input
    activation of the previous layer) is computed, with the weights being learned
    while training.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在全连接层中，计算输入特征（或上一层的输入激活）的加权和，权重在训练过程中被学习。
- en: In a convolutional layer, a convolution is applied to the input features (or
    the input activation of the previous layer), with the values of the convolution
    kernel being learned while training. It means the NN will learn the kernel through
    training to extract the most relevant features from the input images.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层中，卷积应用于输入特征（或前一层的输入激活），卷积核的值在训练过程中被学习。这意味着神经网络将在训练过程中学习卷积核，以从输入图像中提取最相关的特征。
- en: 'A CNN can be fine-tuned with several hyperparameters:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过几个超参数来微调CNN：
- en: The kernel size
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核大小
- en: The padding size
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充大小
- en: The stride size
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步长大小
- en: The number of output channels (i.e., the number of kernels to learn)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出通道的数量（即需要学习的内核数量）
- en: Tip
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: See the *There’s more…* subsection for more information about kernels and other
    hyperparameters of the CNNs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有关内核及CNN其他超参数的更多信息，请参见*更多内容...*小节。
- en: Pooling layer
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 池化层
- en: A **pooling layer** allows you to reduce the dimensionality of images and is
    commonly used in CNNs. For example, a max pooling layer with a 2x2 kernel will
    reduce the dimension of an image by 4 (a factor of 2 both in width and height),
    as shown in *Figure 10**.2*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**池化层**允许你减少图像的维度，并且在CNN中常常使用。例如，具有2x2内核的最大池化层将把图像的维度减少4倍（宽度和高度都减少2倍），如*图10.2*所示。
- en: '![Figure 10.2 – On the left is an input image of 4x4, at the top right is the
    result of 2x2 max pooling, and at the bottom right is the result of a 2x2 average
    pooling](img/B19629_10_02.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2 – 左边是4x4的输入图像，右上方是2x2最大池化的结果，右下方是2x2平均池化的结果](img/B19629_10_02.jpg)'
- en: Figure 10.2 – On the left is an input image of 4x4, at the top right is the
    result of 2x2 max pooling, and at the bottom right is the result of a 2x2 average
    pooling
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 左边是4x4的输入图像，右上方是2x2最大池化的结果，右下方是2x2平均池化的结果
- en: 'There are several types of pooling, such as the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种类型的池化，如下所示：
- en: '**Max pooling**: Computing the maximum value'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大池化**：计算最大值'
- en: '**Average pooling**: Computing the average value'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均池化**：计算平均值'
- en: '**Global average pooling**: Computing a global average value for all channels
    (commonly used before fully connected layers)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局平均池化**：为所有通道计算全局平均值（通常在全连接层之前使用）'
- en: LeNet-5
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LeNet-5
- en: '**LeNet-5** was one of the first proposed CNN architectures, by Yann Le Cun,
    for handwritten digit recognition. Its architecture is shown in *Figure 10**.3*,
    taken from Yann’s paper *Gradient-Based Learning Applied to* *Document Recognition*.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**LeNet-5**是由Yann Le Cun提出的最早的CNN架构之一，用于手写数字识别。其架构如*图10.3*所示，摘自Yann的论文《基于梯度的学习应用于文档识别》。'
- en: '![Figure 10.3 – LeNet-5’s original architecture](img/B19629_10_03.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3 – LeNet-5的原始架构](img/B19629_10_03.jpg)'
- en: Figure 10.3 – LeNet-5’s original architecture
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – LeNet-5的原始架构
- en: 'Let’s describe it in detail:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细描述一下：
- en: An input image of dimension 32x32
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像的尺寸为32x32
- en: '**C1**: A convolution layer with a 5x5 kernel and 6 output channels'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C1**：一个具有5x5内核和6个输出通道的卷积层'
- en: '**S2**: A pooling layer with a 2x2 kernel'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S2**：一个具有2x2内核的池化层'
- en: '**C3**: A convolution layer with a 5x5 kernel and 16 output channels'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C3**：一个具有5x5内核和16个输出通道的卷积层'
- en: '**S4**: A pooling layer with a 2x2 kernel'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S4**：一个具有2x2内核的池化层'
- en: '**C5**: A fully connected layer with 120 units'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C5**：一个具有120个单元的全连接层'
- en: '**F6**: A fully connected layer with 84 units'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F6**：一个具有84个单元的全连接层'
- en: '**Output**: An output layer with 10 units for 10 classes (0 to 9 digits)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出**：一个具有10个单元的输出层，用于10个类别（数字0到9）'
- en: We will implement this network in this recipe on the CIFAR-10 dataset.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本食谱中使用CIFAR-10数据集实现此网络。
- en: 'To run this recipe, the needed libraries can be installed with the following
    command:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此食谱，可以使用以下命令安装所需的库：
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How to do it…
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: In this recipe, we will train a CNN for image classification on the CIFAR-10
    dataset. The CIFAR-10 dataset is a dataset of 32x32 RGB images, made of 10 classes
    – `plane`, `car`, `bird`, `cat`, `deer`, `dog`, `frog`, `horse`, `ship`, and `truck`.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将在CIFAR-10数据集上训练一个CNN进行图像分类。CIFAR-10数据集包含32x32的RGB图像，分为10个类别——`plane`（飞机）、`car`（汽车）、`bird`（鸟）、`cat`（猫）、`deer`（鹿）、`dog`（狗）、`frog`（青蛙）、`horse`（马）、`ship`（船）和`truck`（卡车）。
- en: 'Import the needed modules:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的模块：
- en: matplotlib for visualization
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于可视化的matplotlib
- en: NumPy for data manipulation
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于数据处理的NumPy
- en: Several torch modules and classes
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 若干torch模块和类
- en: The dataset and transformation module from torchvision
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自torchvision的数据集和转换模块
- en: 'Here are the `import` statements:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`import`语句：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Instantiate the transformation to apply to images. Here, it’s a simple two-step
    transformation:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化应用于图像的转换。这里是一个简单的两步转换：
- en: Convert data to a torch tensor
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据转换为 PyTorch 张量
- en: 'Normalize with `0.5` mean and standard deviation values:'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `0.5` 的均值和标准差进行归一化：
- en: '[PRE2]'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Load the data and instantiate the data loaders. The previously defined transformation
    is applied directly at loading as an argument of the `CIFAR10` constructor. The
    data loaders are here instantiated with a batch size of `64`:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据并实例化数据加载器。之前定义的转换在加载时作为 `CIFAR10` 构造函数的参数直接应用。数据加载器在这里以批量大小 `64` 实例化：
- en: '[PRE7]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Optionally, we can visualize a few images to check what the inputs are:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，我们可以可视化几张图像，以检查输入数据是什么：
- en: '[PRE16]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This is the output:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 10.4 – 64 random images from the CIFAR-10 dataset. The images are
    blurry, but most are clear enough for humans to classify correctly](img/B19629_10_04.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.4 – 来自 CIFAR-10 数据集的 64 张随机图像。图像模糊，但大多数足够清晰，供人类正确分类](img/B19629_10_04.jpg)'
- en: Figure 10.4 – 64 random images from the CIFAR-10 dataset. The images are blurry,
    but most are clear enough for humans to classify correctly
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 来自 CIFAR-10 数据集的 64 张随机图像。这些图像有些模糊，但大多数足够清晰，供人类正确分类
- en: 'Implement the `LeNet5` model:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现 `LeNet5` 模型：
- en: '[PRE28]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'This implementation has almost the same layers as the original paper. Here
    are a few interesting points:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实现与原论文中的层结构几乎相同。这里有一些有趣的要点：
- en: '`nn.Conv2d` is the 2D convolution layer in `torch`, having as hyperparameters
    the output dimension, kernel size, stride, and padding'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.Conv2d` 是 `torch` 中的 2D 卷积层，其超参数包括输出维度、卷积核大小、步幅和填充'
- en: '`nn.MaxPool2d` is the max pooling layer in torch, having as a hyperparameter
    the kernel size (and, optionally, the stride, defaulting to the kernel size)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.MaxPool2d` 是 PyTorch 中的最大池化层，其超参数为卷积核大小（可选的，步幅默认为卷积核大小）'
- en: We use the ReLU activation function, even if it was not the function used in
    the original paper
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用 ReLU 激活函数，尽管它并不是原论文中使用的激活函数
- en: '`torch.flatten` allows us to flatten a 2D tensor to a 1D tensor so that we
    can apply fully connected layers'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.flatten` 允许我们将 2D 张量展平为 1D 张量，从而可以应用全连接层'
- en: 'Instantiate the model, and make sure that it works well with a random input
    tensor:'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例化模型，并确保它在随机输入张量上能够正常工作：
- en: '[PRE52]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The resulting output will look like this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 结果输出将如下所示：
- en: '[PRE62]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Instantiate the loss and optimizer – a cross-entropy loss for multiclass classification,
    with an Adam optimizer:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化损失函数和优化器——用于多类分类的交叉熵损失函数和 Adam 优化器：
- en: '[PRE63]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Implement a helper function, `epoch_step_cifar`, that computes forward propagation,
    backpropagation (in the case of the training set), loss, and accuracy for an epoch:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个辅助函数 `epoch_step_cifar`，它计算前向传播、反向传播（在训练集的情况下）、损失和每个 epoch 的准确率：
- en: '[PRE65]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Implement a helper function, `train_cifar_classifier`, that trains the model
    on a given number of epochs and returns the loss and accuracy:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个辅助函数 `train_cifar_classifier`，它训练模型并返回训练集和测试集的损失与准确率：
- en: '[PRE84]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'Using the helper function, train the model on 50 epochs and store the loss
    and accuracy for both the training and test sets:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用辅助函数，在 50 个 epoch 上训练模型，并存储训练集和测试集的损失和准确率：
- en: '[PRE128]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'The last line of the output will look like this:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的最后一行将如下所示：
- en: '[PRE132]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: 'Plot the loss for the train and test sets:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制训练集和测试集的损失曲线：
- en: '[PRE133]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'This is the resulting graph:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成的图表：
- en: '![Figure 10.5 – Cross-entropy loss for the train and test sets](img/B19629_10_05.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.5 – 训练集和测试集的交叉熵损失](img/B19629_10_05.jpg)'
- en: Figure 10.5 – Cross-entropy loss for the train and test sets
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 训练集和测试集的交叉熵损失
- en: After less than 10 epochs, the curves start diverging.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 少于 10 个 epoch 后，曲线开始发散。
- en: 'Plot the accuracy as a function of the epoch:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制准确率随训练轮数（epoch）变化的图示：
- en: '[PRE139]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'This is the graph that we get:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的图：
- en: '![Figure 10.6 – Accuracy as a function of the epoch for both train and test
    sets](img/B19629_10_06.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.6 – 训练集和测试集的准确率随训练轮数（epoch）变化的图示](img/B19629_10_06.jpg)'
- en: Figure 10.6 – Accuracy as a function of the epoch for both train and test sets
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 训练集和测试集的准确率随训练轮数（epoch）变化的图示
- en: After about 20 epochs, the accuracy reaches a plateau of around 60% accuracy,
    while the train accuracy keeps growing, suggesting overfitting.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 经过大约 20 个 epoch 后，准确率达到约 60% 的平稳状态，而训练准确率持续增长，这表明发生了过拟合。
- en: There’s more…
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'In this subsection, let’s have a quick recap of some necessary tools and concepts
    to properly understand CNNs:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，让我们快速回顾一些理解 CNN 的必要工具和概念：
- en: How to store an image
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何存储图像
- en: Padding
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充
- en: Kernel and convolution
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核与卷积
- en: Stride
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步幅
- en: How to store an image
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何存储图像
- en: An image is nothing but a spatially arranged array of pixels. For example, a
    1-million-pixel grayscale square image is an array of 1,000x1,000 pixels.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图像只不过是空间上排列的像素数组。例如，一个百万像素的灰度方形图像就是一个由 1000x1000 像素组成的数组。
- en: Each pixel is usually stored as an 8-bit value and can be represented as an
    unsigned integer in the range of [0, 255]. So, ultimately, such an image can be
    represented in Python as a NumPy array of `uint8` with a shape of (1000, 1000).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 每个像素通常存储为一个 8 位值，并且可以表示为范围为 [0, 255] 的无符号整数。因此，最终这样的图像可以在 Python 中表示为形状为 (1000,
    1000) 的 `uint8` 类型的 NumPy 数组。
- en: We can go one step further with color images. A color image is commonly stored
    with three channels – **Red, Green, and Blue** (**RGB**). Each of these channels
    is stored as an 8-bit integer, so a squared 1M pixels color image can be stored
    as a NumPy array of a shape of (3, 1000, 1000), assuming the channel is stored
    first.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步处理彩色图像。彩色图像通常存储有三个通道——**红色、绿色、蓝色**（**RGB**）。每个通道都以 8 位整数形式存储，因此一个 1M
    像素的平方彩色图像可以存储为一个形状为 (3, 1000, 1000) 的 NumPy 数组，假设通道是首先存储的。
- en: Tip
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: There are many other ways to describe a colored image – **hue, saturation, value**
    (**HSV**), CIELAB, transparency, and so on. However, in this book, and many computer
    vision cases, RGB color space is enough.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 描述彩色图像还有许多其他方式——**色相、饱和度、亮度**（**HSV**）、CIELAB、透明度等。然而，在本书中，以及许多计算机视觉的案例中，RGB
    色彩空间已经足够。
- en: Padding
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 填充
- en: We already used padding in earlier chapters for NLP processing. It consists
    of adding “space” around an image, basically by adding layers of values around
    an image. An example of padding on a 4x4 matrix is given in *Figure 10**.7*.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的章节中已经使用了填充（padding）进行自然语言处理（NLP）。它通过在图像周围添加“空间”，基本上是通过在图像周围添加值的层来实现的。*图
    10.7* 给出了一个 4x4 矩阵填充的例子。
- en: '![Figure 10.7 – An example of a 4x4 matrix padded with one layer of zeros](img/B19629_10_07.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.7 – 一个 4x4 矩阵，填充了一个零层的示例](img/B19629_10_07.jpg)'
- en: Figure 10.7 – An example of a 4x4 matrix padded with one layer of zeros
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 一个 4x4 矩阵，填充了一个零层的示例
- en: 'Padding can take several arguments, such as the following:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 填充可以接受多个参数，例如：
- en: The number of layers of padding
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充的层数
- en: The padding method – a given value, repetition, mirror, and so on
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充方法——给定值、重复、镜像等等
- en: Most of the time, zero padding is used, but sometimes, more sophisticated padding
    can be useful.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，使用零填充，但有时更复杂的填充方法会很有用。
- en: Kernel and convolution
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核与卷积
- en: 'A convolution is a mathematical operation, between an image and a kernel, that
    outputs another image. It can be simply schematized as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是一种数学操作，是图像和核之间的运算，输出另一个图像。它可以简要表示如下：
- en: Convolution (input image, kernel) → Output image
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积（输入图像，核）→ 输出图像
- en: A kernel is just a smaller matrix of predefined values, allowing us to get a
    property from an image through convolution. For example, with the right kernel,
    a convolution on an image allows us to blur an image, sharpen an image, detect
    edges, and so on.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 核只是一个预定义值的小矩阵，通过卷积我们可以从图像中获取某些属性。例如，使用正确的核，对图像进行卷积可以让我们模糊图像、锐化图像、检测边缘等等。
- en: 'The computation of a convolution is quite simple and can be described as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积的计算非常简单，可以描述如下：
- en: Spatially match the kernel and the image from the top-left corner.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左上角开始，空间上匹配核和图像。
- en: Compute the weights sum of all the image pixels, with the corresponding kernel
    value as the weight, and store this value as the top-left output image pixel.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有图像像素的权重和，使用相应的核值作为权重，并将此值存储为左上角的输出图像像素。
- en: Go one pixel to the right and repeat; if you reach the rightmost edge of the
    image, go back to the leftmost pixel and one pixel down.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向右移动一个像素，重复上述操作；如果到达图像的最右边缘，则返回到最左边的像素，并向下移动一个像素。
- en: 'This may look complicated, but it gets much easier with a diagram, as shown
    in *Figure 10**.8*:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很复杂，但通过图示来表示会简单得多，如*图 10.8*所示：
- en: '![Figure 10.8 – An example of an image convolution by a kernel.Note that the
    resulting image is smaller in dimension](img/B19629_10_08.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.8 – 通过核进行图像卷积的示例。注意，得到的图像在尺寸上较小](img/B19629_10_08.jpg)'
- en: Figure 10.8 – An example of an image convolution by a kernel.Note that the resulting
    image is smaller in dimension
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 通过核进行图像卷积的示例。注意，得到的图像在尺寸上较小
- en: As we can see in *Figure 10**.8*, the output image is slightly smaller than
    the input image. Indeed, the larger the kernel, the smaller the output image.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在 *图 10**.8* 中所见，输出图像稍微小于输入图像。事实上，卷积核越大，输出图像越小。
- en: Stride
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步幅
- en: One more useful concept about convolutions is the concept of **stride**. The
    stride is the number of step pixels to take between two convolutional operations.
    In the example in *Figure 10**.8*, we implicitly considered a stride of 1 – the
    kernel is moved by one pixel each time.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 关于卷积的另一个有用概念是**步幅**。步幅是指在两次卷积操作之间移动的像素步数。在 *图 10**.8* 中的示例中，我们隐式地使用了步幅为1 – 每次卷积核移动一个像素。
- en: 'However, it’s possible to consider a larger stride – we can have a step of
    any number, as shown in *Figure 10**.9*:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，也可以考虑更大的步幅 – 我们可以有任意步长，如 *图 10**.9* 所示：
- en: '![Figure 10.9 – The stride effect on convolution – the larger the stride, the
    smaller the output image](img/B19629_10_09.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.9 – 步幅对卷积的影响 – 步幅越大，输出图像越小](img/B19629_10_09.jpg)'
- en: Figure 10.9 – The stride effect on convolution – the larger the stride, the
    smaller the output image
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – 步幅对卷积的影响 – 步幅越大，输出图像越小
- en: 'Having a larger stride will mainly have several, related, consequences:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更大的步幅主要会带来几个相关的后果：
- en: Since the convolution skips more pixels, less information remains in the output
    image
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于卷积跳过了更多的像素，输出图像中保留的信息更少
- en: The output image is smaller, allowing a reduction in dimensionality
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出图像更小，从而实现降维
- en: The computation time is lower
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间更短
- en: Depending on the needs, having a stride larger than one can be an efficient
    way to have lower computation time.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需求，使用大于1的步幅可以有效地降低计算时间。
- en: 'To summarize, we can control several aspects of a convolution with three parameters:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们可以通过三个参数来控制卷积的多个方面：
- en: The padding
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充
- en: The kernel size
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积核大小
- en: The stride
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步幅
- en: 'They all affect the size of the output image, following this formula:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都影响输出图像的大小，遵循以下公式：
- en: '![](img/Formula_10_001.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_001.jpg)'
- en: 'This formula can be broken down as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式可以分解为如下：
- en: '*I* is the input image size'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*I* 是输入图像的大小'
- en: '*k* is the kernel size'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k* 是卷积核的大小'
- en: '*p* is the padding size'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p* 是填充大小'
- en: '*s* is the stride size'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*s* 是步幅大小'
- en: '*O* is the output image size'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*O* 是输出图像的大小'
- en: Thanks to this formula, we can efficiently choose the required parameters in
    any case.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 借助这个公式，我们可以高效地选择所需的参数。
- en: See also
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Documentation about CNN layers: [https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.xhtml#torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.xhtml#torch.nn.Conv2d)'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于CNN层的文档：[https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.xhtml#torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.xhtml#torch.nn.Conv2d)
- en: 'Documentation about pooling layers: [https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.xhtml#torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.xhtml#torch.nn.MaxPool2d)'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于池化层的文档：[https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.xhtml#torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.xhtml#torch.nn.MaxPool2d)
- en: 'A paper about LeNet-5: [http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于LeNet-5的论文：[http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
- en: 'The amazing Stanford course about deep learning for computer vision: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯坦福大学关于计算机视觉深度学习的精彩课程：[http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
- en: Regularizing a CNN with vanilla NN methods
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用传统神经网络方法对CNN进行正则化
- en: 'Since CNNs are a special kind of NNs, most vanilla NN optimization methods
    can be applied to them. A non-exhaustive list of regularization techniques we
    can use with CNNs is the following:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CNN是神经网络的一种特殊类型，大多数传统神经网络优化方法都可以应用于它们。我们可以使用的CNN正则化技术的非详尽列表如下：
- en: Kernel size
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积核大小
- en: Pooling size
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化大小
- en: L2 regularization
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L2 正则化
- en: A fully connected number of units (if any)
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全连接的单元数（如果有的话）
- en: Dropout
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dropout
- en: Batch normalization
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量归一化
- en: In this recipe, we will apply batch normalization to add regularization, reusing
    the LeNet-5 model on the CIFAR-10 dataset, but any other method may work as well.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方案中，我们将应用批量归一化来增加正则化，重用LeNet-5模型处理CIFAR-10数据集，但任何其他方法也可能有效。
- en: Batch normalization is a simple yet very effective method that can help NNs
    regularize and converge faster. The idea of batch normalization is to normalize
    the activation values of a hidden layer for a given batch. The method is very
    similar to a standard scaler for data preparation of quantitative data, but there
    are some differences. Let’s have a look at how it works.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化是一种简单而非常有效的方法，可以帮助神经网络进行正则化并加速收敛。批量归一化的思想是对给定批次的隐藏层激活值进行归一化。该方法非常类似于定量数据准备中的标准缩放器，但也存在一些区别。我们来看看它是如何工作的。
- en: 'The first step is to compute the mean value µ and the standard deviation ![](img/Formula_10_002.png)
    of the activation values ![](img/Formula_10_003.png) of a given layer. Assuming
    ![](img/Formula_10_004.png) is the activation value of the I-th unit of the layer
    and the layer has *n* units, here are the formulas:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是计算给定层的激活值的均值µ和标准差！[](img/Formula_10_002.png)。假设！[](img/Formula_10_004.png)是该层第I个单元的激活值，且该层有*n*个单元，以下是公式：
- en: '![](img/Formula_10_005.jpg)![](img/Formula_10_006.jpg)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_005.jpg)![](img/Formula_10_006.jpg)'
- en: 'Just like with a standard scaler, it is now possible to compute the rescaled
    the activation values ![](img/Formula_10_007.png) with the following formula:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 就像使用标准缩放器一样，现在可以通过以下公式计算重新缩放后的激活值！[](img/Formula_10_007.png)：
- en: '![](img/Formula_10_008.jpg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_008.jpg)'
- en: Here, ![](img/Formula_10_009.png) is just a small value to avoid division by
    zero.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/Formula_10_009.png)只是一个小值，用来避免除以零。
- en: 'Finally, unlike a standard scaler, there is one more step that allows the model
    to learn what is the best distribution with a scale and shift approach, thanks
    to two new learnable parameters, β and ![](img/Formula_10_010.png). They are used
    to compute the final batch normalization output ![](img/Formula_10_011.png):'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，不同于标准缩放器，批量归一化还有一个额外的步骤，它允许模型通过缩放和偏移的方法来学习最佳分布，这要得益于两个新的可学习参数β和！[](img/Formula_10_010.png)。它们被用来计算最终的批量归一化输出！[](img/Formula_10_011.png)：
- en: '![](img/Formula_10_012.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_012.jpg)'
- en: Here, ![](img/Formula_10_013.png) allows us to adjust the scale, while β allows
    us to adjust the shift. These two parameters are learned during training, like
    any other parameter of the NN. This allows the model to adjust the distribution
    if required to improve its performance.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，！[](img/Formula_10_013.png) 使我们能够调整缩放，而β允许我们调整偏移量。这两个参数是在训练过程中学习的，就像神经网络的任何其他参数一样。这使得模型能够根据需要调整分布，以提高其性能。
- en: For a more visual example, we can see in *Figure 10**.10* a possible distribution
    of activation values on the left for a three-unit layer – the values are skewed
    and with a large standard deviation. After batch normalization, on the right part
    of *Figure 10**.10*, the distributions are now close to normal distributions.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个更直观的示例，我们可以在*图10.10*中看到，左侧是一个三单元层的激活值分布——值呈偏态且标准差较大。经过批量归一化后，*图10.10*的右侧，分布接近正态分布。
- en: '![Figure 10.10 – Possible activation distributions of three units of a layer
    before (left) and after (right) batch normalization](img/B19629_10_10.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![图10.10 – 三单元层的激活分布在批量归一化前（左）和批量归一化后（右）的可能情况](img/B19629_10_10.jpg)'
- en: Figure 10.10 – Possible activation distributions of three units of a layer before
    (left) and after (right) batch normalization
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 - 三单元层的激活分布在批量归一化前（左）和批量归一化后（右）的可能情况
- en: Thanks to this method, NNs tend to converge faster and generalize better, as
    we will see in this recipe.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种方法，神经网络（NN）往往能更快收敛并且具有更好的泛化能力，正如我们在本食谱中所看到的。
- en: Getting started
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用
- en: 'For this recipe, we will reuse torch and its integrated CIFAR-10 dataset so
    that all the needed libraries can be installed with the following command line
    (if not already installed in the previous recipe):'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本食谱，我们将重用torch及其集成的CIFAR-10数据集，因此所有需要的库可以通过以下命令行安装（如果在之前的食谱中尚未安装）：
- en: '[PRE145]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: How to do it…
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Since we will reuse the same data and almost the same network as in the previous
    recipe, we will assume the imports and instantiated classes can be reused:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将重复使用与前一个食谱几乎相同的数据和网络，因此我们假设导入的库和实例化的类可以被重用：
- en: 'Implement the regularized model. Here, we will mostly reuse the LeNet-5 architecture,
    with added batch normalization at each step:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现正则化模型。在这里，我们将主要重复使用LeNet-5架构，并在每个步骤中添加批量归一化：
- en: '[PRE146]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '[PRE153]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '[PRE155]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '[PRE158]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: '[PRE166]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '[PRE167]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: '[PRE169]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '[PRE170]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE171]'
- en: '[PRE172]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: '[PRE173]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: 'As shown in the code, batch normalization can be simply added as a layer with
    `nn.BatchNorm1d` (or `nn.BatchNorm2d` for the convolutional part), which takes
    as an argument the following input dimensions:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码所示，批归一化可以简单地作为一个层添加，使用`nn.BatchNorm1d`（对于卷积部分使用`nn.BatchNorm2d`），它接受以下输入维度作为参数：
- en: The number of units for fully connected layers and `BatchNorm1d`
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接层和`BatchNorm1d`的单元数
- en: The number of kernels for convolution layers and `BatchNorm2d`
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层和`BatchNorm2d`的卷积核数量
- en: Important note
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Placing batch normalization after the activation function is arguable, and some
    people would rather place it before the activation function.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 将批归一化放置在激活函数之后存在争议，有些人更倾向于将其放在激活函数之前。
- en: 'Instantiate the model, with the loss as cross-entropy and the optimizer as
    Adam:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化模型，使用交叉熵作为损失函数，Adam作为优化器：
- en: '[PRE174]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '[PRE179]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: 'Train the model over 20 epochs by reusing the `train_cifar_classifier` helper
    function of the previous recipe. Note that the model converges faster than without
    batch normalization in the previous recipe:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过重新使用前一个配方中的`train_cifar_classifier`辅助函数，训练模型20个epochs。请注意，与前一个配方中没有批归一化的情况相比，模型收敛得更快：
- en: '[PRE182]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '[PRE184]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE185]'
- en: 'Plot the loss as a function of the epoch:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制损失与epochs的关系：
- en: '[PRE186]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE186]'
- en: '[PRE187]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: '[PRE188]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '[PRE189]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: '[PRE190]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '[PRE191]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: 'Here is the graph:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图表：
- en: '![Figure 10.11 – Cross-entropy loss as a function of the epoch](img/B19629_10_11.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.11 – 交叉熵损失与epochs的关系](img/B19629_10_11.jpg)'
- en: Figure 10.11 – Cross-entropy loss as a function of the epoch
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 – 交叉熵损失与epochs的关系
- en: Overfitting starts appearing after only a few epochs.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合在仅经过几轮训练后就开始出现。
- en: 'Plot the accuracy for the train and test sets:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制训练集和测试集的准确率：
- en: '[PRE192]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: '[PRE193]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '[PRE195]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: 'This is what we get:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的结果：
- en: '![Figure 10.12 – Accuracy as a function of the epoch. The test accuracy climbs
    to 66%, compared to 61% without batch normalization](img/B19629_10_12.jpg)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.12 – 准确率与epochs的关系。测试准确率上升至66%，而没有批归一化时为61%](img/B19629_10_12.jpg)'
- en: Figure 10.12 – Accuracy as a function of the epoch. The test accuracy climbs
    to 66%, compared to 61% without batch normalization
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12 – 准确率与epochs的关系。测试准确率上升至66%，而没有批归一化时为61%
- en: As a result, we can see that while there is still some overfitting, the test
    accuracy improved significantly from 61% to 66%, thanks to batch normalization.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到，尽管仍然存在一定的过拟合，但得益于批归一化，测试准确率显著提高，从61%提升至66%。
- en: There’s more…
  id: totrans-411
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'What’s interesting about CNNs is that we can have a look at what they learn
    from data. One way to do so is to look at the learned kernels. This can be done
    using the `visualize_kernels` function, as defined here:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的有趣之处在于我们可以查看它们从数据中学到了什么。查看学习到的卷积核是一种方法。可以使用`visualize_kernels`函数来做到这一点，定义如下：
- en: '[PRE198]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: 'We can now apply this function to visualize the learned kernels of the `C1`
    and `C3` layers:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以应用这个函数来可视化`C1`和`C3`层学到的卷积核：
- en: '[PRE199]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: 'Here is the C1 layer:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是C1层：
- en: '![](img/B19629_10_13-A.jpg)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19629_10_13-A.jpg)'
- en: 'Here is the C3 layer:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是C3层：
- en: '![Figure 10.13 – Top – the learned kernels of the C1 layer, and bottom – the
    learned kernels of the C3 layer](img/B19629_10_13-B.jpg)'
  id: totrans-419
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.13 – 上图为C1层的学到的卷积核，下图为C3层的学到的卷积核](img/B19629_10_13-B.jpg)'
- en: Figure 10.13 – Top – the learned kernels of the C1 layer, and bottom – the learned
    kernels of the C3 layer
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.13 – 上图为C1层的学到的卷积核，下图为C3层的学到的卷积核
- en: Displaying kernels is not always helpful, but, depending on the task, they can
    give hints on what shapes a model recognizes.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 显示卷积核并不总是有用的，但根据任务的不同，它们可以提供模型识别的形状的提示。
- en: See also
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'The torch documentation about batch normalization: [https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.xhtml](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.xhtml)'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于批归一化的PyTorch文档：[https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.xhtml](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.xhtml)
- en: 'The batch normalization paper: [https://arxiv.org/pdf/1502.03167.pdf](https://arxiv.org/pdf/1502.03167.pdf%0D)'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批归一化的论文：[https://arxiv.org/pdf/1502.03167.pdf](https://arxiv.org/pdf/1502.03167.pdf%0D)
- en: 'A very well-written blog post about batch normalization: [https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338)'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一篇关于批归一化的精彩博文：[https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338)
- en: Regularizing a CNN with transfer learning for object detection
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用迁移学习对CNN进行正则化，用于物体检测
- en: In this recipe, we will perform another typical task in computer vision – object
    detection. Before taking advantage of the power of transfer learning to help get
    better performances using a **You Only Look Once** (**YOLO**) model (a widely
    used class of models for object detection), we will give insights about what object
    detection is, the main methods and metrics, as well as the COCO dataset.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将执行计算机视觉中的另一个典型任务——目标检测。在利用**一次性检测**（**YOLO**）模型的迁移学习能力（YOLO是一种广泛用于目标检测的模型类别）来提升性能之前，我们将简要介绍目标检测是什么，主要方法和指标，以及COCO数据集。
- en: Object detection
  id: totrans-428
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标检测
- en: '**Object detection** is a computer vision task, involving both the identification
    and localization of objects of a given class (for example, a car, phone, person,
    or dog). As shown in *Figure 10**.14*, the objects are usually localized, thanks
    to predicted bounding boxes, as well as predicted classes.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标检测**是计算机视觉任务，涉及识别和定位给定类别的物体（例如，汽车、手机、人物或狗）。如*图10.14*所示，物体通常通过预测的边界框以及预测的类别来定位。'
- en: '![Figure 10.14 – An example of an image with object detection. Objects are
    detected with a bounding box and a class](img/B19629_10_14.jpg)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
  zh: '![图10.14 – 一张带有目标检测的图像示例。物体通过边界框和类别进行检测](img/B19629_10_14.jpg)'
- en: Figure 10.14 – An example of an image with object detection. Objects are detected
    with a bounding box and a class
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 – 一张带有目标检测的图像示例。物体通过边界框和类别进行检测
- en: 'Researchers have proposed many methods to help solve object detection problems,
    some of which are heavily used in many industries. There are several groups of
    methods for object detection, but perhaps the two most widely used groups of methods
    are currently the following:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员提出了许多方法来帮助解决目标检测问题，其中一些在许多行业中得到广泛应用。目标检测方法有多种分组，但目前最常用的两大方法组可能是以下两种：
- en: One-stage methods, such as YOLO and SSD
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一阶段方法，如YOLO和SSD
- en: Two-stage methods, based on **Region-Based** **CNN** (**R-CNN**)
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两阶段方法，基于**区域卷积神经网络**（**R-CNN**）
- en: Methods based on R-CNN are powerful and usually more accurate than one-stage
    methods. On the other hand, one-stage methods are usually less computationally
    expensive and can run in real time, but they may fail at detecting small objects
    more often.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 基于R-CNN的方法功能强大，通常比一阶段方法更准确。另一方面，一阶段方法通常计算开销较小，能够实时运行，但它们在检测小物体时可能更容易失败。
- en: Mean average precision
  id: totrans-436
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平均精度
- en: Since this is a specific task, a specific metric is needed to assess the performances
    of such models – the **mean Average Precision** (**mAP**). Let’s get an overview
    of what mAP is. For that, we need to introduce several concepts, such as the **Intersection
    over Union** (**IoU**) and precision and recall in the context of object detection.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个特定任务，因此需要一个特定的指标来评估这些模型的表现——**平均精度**（**mAP**）。让我们概述一下mAP是什么。为此，我们需要介绍几个概念，如**交并比**（**IoU**）以及在目标检测中的精准率和召回率。
- en: 'When an object is detected, it comes with three pieces of information:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个物体被检测到时，会伴随三项信息：
- en: A predicted class
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的类别
- en: A bounding box (usually four points, either center plus width and height, or
    top-left and bottom-right locations)
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个边界框（通常由四个点组成，可以是中心加宽度和高度，或者是左上角和右下角的位置）
- en: A confidence level or probability that the box contains an object
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个表示该框内包含物体的置信度或概率
- en: To consider an object successfully detected, the classes must match, and the
    bounding box must be well localized. While knowing whether the classes match is
    trivial, the bounding box localization is computed using a metric called IoU.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 要认为一个物体被成功检测到，类别必须匹配，并且边界框必须定位准确。虽然判断类别是否匹配是显而易见的，但边界框定位则通过一个名为IoU的指标来计算。
- en: Having an explicit name, the IoU can be computed as the intersection of the
    ground truth and the predicted boxes, over the union of those two same boxes,
    as shown in *Figure 10**.15*.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有明确的名称，IoU可以通过计算地面实况框和预测框的交集，再除以这两个框的并集来得出，如*图10.15*所示。
- en: '![Figure 10.15 – A representation of the IoU metric](img/B19629_10_15.jpg)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
  zh: '![图10.15 – IoU指标的表示](img/B19629_10_15.jpg)'
- en: Figure 10.15 – A representation of the IoU metric
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15 – IoU指标的表示
- en: 'Given two bounding boxes – for example, *A* and *B* – IoU can be mathematically
    described with the following equation:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个边界框——例如，*A*和*B*——IoU可以通过以下方程来数学描述：
- en: '![](img/Formula_10_014.jpg)'
  id: totrans-447
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_014.jpg)'
- en: 'IoU has several advantages for a metric:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: IoU作为一个指标具有几个优点：
- en: The values are between 0 and 1
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些值介于0和1之间
- en: A value of 0 means the two boxes don’t overlap
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 0 表示两个框没有重叠
- en: A value of 1 means the two boxes perfectly match
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值为 1 表示两个框完全匹配
- en: A threshold is then applied to the IoU. If the IoU is above the threshold, it
    is considered a **True Positive** (**TP**); otherwise, it is considered a **False
    Positive** (**FP**), allowing us to effectively compute the precision. Finally,
    a **False Negative** (**FN**) is an object that was not detected, given the IoU
    threshold.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 然后应用 IoU 阈值。如果 IoU 高于该阈值，则被视为 **真正例** (**TP**)，否则被视为 **假正例** (**FP**)，从而可以有效地计算精度。最后，**假负例**
    (**FN**) 是未被检测到的物体，基于 IoU 阈值。
- en: Using these definitions of TP, FP, and FN, it is then possible to compute the
    precision and recall.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些 TP、FP 和 FN 的定义，我们可以计算精确度和召回率。
- en: 'As a reminder, the precision *P* and recall *R* formulas are the following:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，精确度 *P* 和召回率 *R* 的公式如下：
- en: '![](img/Formula_10_015.jpg)![](img/Formula_10_016.jpg)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_015.jpg)![](img/Formula_10_016.jpg)'
- en: Using P and R, it is possible to plot the **Precision-Recall curve** (**PR curve**),
    with P as a function of R for various confidence-level thresholds, from 0 to 1\.
    Using this PR curve, it is possible to compute the **Average Precision** (**AP**)
    for a given class by averaging P for different values of R (for example, averaging
    the interpolated P for R values in [0, 0.1, 0.2... 1]).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 P 和 R，可以绘制 **精确度-召回率曲线** (**PR 曲线**)，其中 P 是 R 的函数，表示不同置信度阈值（从 0 到 1）下的结果。通过这个
    PR 曲线，可以通过对不同 R 值下的 P 值（例如，计算 [0, 0.1, 0.2... 1] 范围内的 P 的插值）进行平均，来计算 **平均精度**
    (**AP**)。
- en: Important note
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The average recall metric can be computed reciprocally using the same method,
    by reversing R and P.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 平均召回率指标可以通过反向计算使用相同的方法，通过交换 R 和 P 来实现。
- en: Finally, the mAP is simply computed by averaging the AP over all the classes.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，mAP 通过对所有类别的 AP 取平均值来计算。
- en: Tip
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: See the *See also* subsection for a link to a great blog post that explains
    in detail the mAP computation.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅 *另见* 子部分，获取一篇详细解释 mAP 计算的优秀博客文章链接。
- en: One drawback of this AP computation is that we considered only one IoU threshold,
    considering the same way almost perfect boxes with an IoU of 0.95 and not-so-good
    boxes with an IoU of 0.5\. This is why some evaluation metrics average the AP
    for several IoU thresholds – for example, from 0.5 to 0.95 with a step of 0.05,
    usually noted as `AP@[IoU=0.5:0.95`] or `AP50-95`.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 这种 AP 计算方法的一个缺点是我们只考虑了一个 IoU 阈值，按相同的方式考虑了几乎完美的 IoU 为 0.95 的框和不太好的 IoU 为 0.5
    的框。这就是为什么一些评估指标会对多个 IoU 阈值计算 AP 的平均值——例如，从 0.5 到 0.95，步长为 0.05，通常表示为 `AP@[IoU=0.5:0.95`]
    或 `AP50-95`。
- en: COCO dataset
  id: totrans-463
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: COCO 数据集
- en: 'The **Common Objects in Context** (**COCO**) dataset is a widely used dataset
    in object detection, having the following nice features:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '**常见物体背景数据集** (**COCO**) 是一个在目标检测中广泛使用的数据集，具有以下优点：'
- en: Hundreds of thousands of images with labels
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成千上万的带标签图像
- en: 80 classes of objects
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 80 类对象
- en: Flexible terms of use
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活的使用条款
- en: A wide community
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个庞大的社区
- en: This is a standard dataset when working with object detection. Thanks to that,
    most standard object detection models come with a set of pre-trained weights on
    the COCO dataset, allowing us to take advantage of transfer learning.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 这是进行目标检测时的标准数据集。正因为如此，大多数标准的目标检测模型都提供了在 COCO 数据集上预训练的权重，使我们能够利用迁移学习。
- en: Getting started
  id: totrans-470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入门
- en: In this recipe, we will use the YOLO algorithm, proposed by Ultralytics. **YOLO**
    stands for **You Only Look Once**, referring to the fact the method operates in
    a single stage, enabling real-time execution on devices with powerful enough power.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用 Ultralytics 提出的 YOLO 算法。**YOLO** 代表 **You Only Look Once**，指的是该方法在单个阶段内操作，能够在具有足够计算能力的设备上实时执行。
- en: YOLO is a popular object detection algorithm that was first proposed in 2015\.
    It has had a lot of new versions with improvements since then; version 8 is currently
    being developed.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO 是一个流行的目标检测算法，首次提出于 2015 年。自那时以来，已有许多版本发布并进行改进；目前正在开发版本 8。
- en: 'It can be installed simply with the following command line:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过以下命令行简单安装：
- en: '[PRE200]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: 'We will train an object detection algorithm on a vehicles dataset available
    on Kaggle. It can be downloaded and prepared with the following commands:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Kaggle 上的一个车辆数据集上训练目标检测算法。可以通过以下命令下载并准备数据集：
- en: 'Download the dataset using the Kaggle API:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kaggle API 下载数据集：
- en: '[PRE201]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE201]'
- en: 'Rename the folder for simplicity:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了简化，重命名文件夹：
- en: '[PRE202]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE202]'
- en: 'Create a `datasets` folder:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `datasets` 文件夹：
- en: '[PRE203]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE203]'
- en: 'Move the dataset to this folder:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集移动到此文件夹：
- en: '[PRE204]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE204]'
- en: 'As a result, you should now have a folder dataset with the following structure:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，你现在应该有一个包含以下结构的文件夹数据集：
- en: '[PRE205]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE205]'
- en: The dataset is split into `train`, `val`, and `test` sets, with respectively
    738, 185, and 278 images. As we will see in the next subsection, these are typical
    road traffic images. The labels have seven classes – `Car`, `Number Plate`, `Blur
    Number Plate`, `Two-Wheeler`, `Auto`, `Bus`, and `Truck`. We can now proceed to
    train the object detection model.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集分为 `train`、`val` 和 `test` 集，分别包含 738、185 和 278 张图像。如我们在下一小节中所见，这些是典型的道路交通图像。标签有七个类别——`Car`、`Number
    Plate`、`Blur Number Plate`、`Two-Wheeler`、`Auto`、`Bus` 和 `Truck`。我们现在可以继续训练目标检测模型。
- en: How to do it…
  id: totrans-487
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We will first have to quickly explore the dataset and then train and evaluate
    a YOLO model on this data:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先快速探索数据集，然后在这些数据上训练并评估一个 YOLO 模型：
- en: 'Import the required modules and functions:'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的模块和函数：
- en: '`matplotlib` and `cv2` for image loading and visualization'
  id: totrans-490
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib` 和 `cv2` 用于图像加载和可视化'
- en: '`YOLO` for the model training'
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YOLO` 用于模型训练'
- en: '`glob` as `util` to list the files:'
  id: totrans-492
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `glob` 作为 `util` 来列出文件：
- en: '[PRE206]'
  id: totrans-493
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE206]'
- en: '[PRE207]'
  id: totrans-494
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '[PRE208]'
  id: totrans-495
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '[PRE209]'
  id: totrans-496
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: 'Let’s now explore the dataset. First, we will list the images in the `train`
    folder using `glob`, and then we will display eight of them:'
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们来探索数据集。首先，我们将使用 `glob` 列出 `train` 文件夹中的图像，然后展示其中的八张：
- en: '[PRE210]'
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: '[PRE211]'
  id: totrans-499
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: '[PRE212]'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '[PRE213]'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '[PRE214]'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '[PRE215]'
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: '[PRE216]'
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE216]'
- en: '[PRE217]'
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE217]'
- en: '[PRE218]'
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE218]'
- en: 'Here is the result:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 10.16 – A patchwork of eight images from the train set of the traffic
    dataset](img/B19629_10_16.jpg)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.16 – 来自交通数据集训练集的八张图像拼接图](img/B19629_10_16.jpg)'
- en: Figure 10.16 – A patchwork of eight images from the train set of the traffic
    dataset
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16 – 来自交通数据集训练集的八张图像拼接图
- en: As we can see, these are mostly traffic-related images of different shapes and
    aspects.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，这些大多数是与交通相关的图像，具有不同的形状和特征。
- en: 'If we have a look at the labels by reading a file, we get the following:'
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们通过读取文件查看标签，得到如下内容：
- en: '[PRE219]'
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE219]'
- en: '[PRE220]'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE220]'
- en: '[PRE221]'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE221]'
- en: 'The output is the following:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE222]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE222]'
- en: 'The labels are an object per line, so here, we have three labeled objects in
    the image. Each line contains five numbers:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 标签是每行一个对象，因此这里我们在图像中有三个标注对象。每行包含五个数字：
- en: The class number
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别编号
- en: The box center *x* coordinate
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 盒子中心的 *x* 坐标
- en: The box center *y* coordinate
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 盒子中心的 *y* 坐标
- en: The box width
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 盒子的宽度
- en: The box height
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 盒子的高度
- en: Note that all the box information is relative to the size of the image, so they
    are represented as floats in [0, 1].
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有框的信息相对于图像的大小，因此它们以 [0, 1] 范围内的浮动数字表示。
- en: Tip
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: There are other data formats for boxes in images such as the COCO and the Pascal
    VOC formats. More information about can be found in the *See* *also* subsection.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 图像中的框数据还有其他格式，例如 COCO 和 Pascal VOC 格式。更多信息可以在 *另见* 子章节中找到。
- en: 'We can even plot this image with the boxes of the labels, using the `plot_labels`
    function implemented here:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以使用这里实现的 `plot_labels` 函数，绘制带有标签框的图像：
- en: '[PRE223]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE223]'
- en: 'Here is the result:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 10.17 – An example of an image and its labeled bounding boxes](img/B19629_10_17.jpg)'
  id: totrans-529
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.17 – 图像及其标注的边界框示例](img/B19629_10_17.jpg)'
- en: Figure 10.17 – An example of an image and its labeled bounding boxes
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17 – 图像及其标注的边界框示例
- en: In this photo, we have labels for two cars and one plate. Let’s go on to the
    next step to train a model on this data.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张照片中，我们有两辆车和一块车牌的标签。接下来，我们将进行下一步，使用这些数据训练一个模型。
- en: 'We need to create a `.yaml` file, expected by the YOLO model, containing the
    dataset location and classes. Create and edit a file named `dataset.yaml` in the
    current directory with your favorite editor, and then fill it with the following
    content:'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要创建一个 `.yaml` 文件，这是 YOLO 模型所期望的文件，包含数据集位置和类别。请在当前目录中创建并编辑一个名为 `dataset.yaml`
    的文件，并用你喜欢的编辑器填充以下内容：
- en: '[PRE224]'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE224]'
- en: '[PRE225]'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE225]'
- en: '[PRE226]'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE226]'
- en: '[PRE227]'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE227]'
- en: '[PRE228]'
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE228]'
- en: 'We can now instantiate a new model. This will instantiate a YOLOv8 nano model.
    The YOLO model comes in five sizes:'
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以实例化一个新模型。这个模型将实例化一个 YOLOv8 nano 模型。YOLO 模型有五个不同的尺寸：
- en: '`''yolov8n.yaml''` for the smallest model with 3.2 million parameters'
  id: totrans-539
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''yolov8n.yaml''`，用于最小模型，具有 320 万个参数'
- en: '`''yolov8s.yaml''` with 11.2 million parameters'
  id: totrans-540
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''yolov8s.yaml''`，具有 1120 万个参数'
- en: '`''yolov8m.yaml''` with 25.9 million parameters'
  id: totrans-541
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''yolov8m.yaml''`，具有 2590 万个参数'
- en: '`''yolov8l.yaml''` with 43.7 million parameters'
  id: totrans-542
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''yolov8l.yaml''`，具有 4370 万个参数'
- en: '`''yolov8x.yaml''` for the largest model with 68.2 million parameters:'
  id: totrans-543
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''yolov8x.yaml''`，用于最大模型，具有 6820 万个参数：'
- en: '[PRE229]'
  id: totrans-544
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE229]'
- en: '[PRE230]'
  id: totrans-545
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE230]'
- en: 'Train the model, providing the dataset with the previously created `dataset.yaml`
    file, the number of epochs, and the name (optional):'
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型，提供包含之前创建的 `dataset.yaml` 文件的数据集、训练轮数以及名称（可选）：
- en: '[PRE231]'
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE231]'
- en: '[PRE232]'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE232]'
- en: '[PRE233]'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE233]'
- en: Tip
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: A lot of information is displayed when a model trains in memory, losses, and
    metrics. There’s nothing too complicated if you want to look at it in detail.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型在内存中训练时，会显示大量信息，包括损失和指标。如果你想详细查看这些信息，其实并不复杂。
- en: The name is optional but allows us to easily find where the results and output
    are stored – in the `runs/detect/<name>` folder. If the folder already exists,
    it is simply incremented and not overwritten.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 名称是可选的，但它可以帮助我们轻松找到结果和输出存储的位置——在`runs/detect/<name>`文件夹中。如果文件夹已存在，则会简单地增加一个编号，而不是覆盖。
- en: 'In this folder, several useful files can be found, including the following:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个文件夹中，可以找到一些有用的文件，包括以下内容：
- en: '`weights/best.pt`: The weights of the epoch that has the best validation loss'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weights/best.pt`：具有最佳验证损失的训练轮次权重'
- en: '`results.csv` with the logged results for each epoch'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`results.csv`：记录每个训练轮次结果的日志文件'
- en: Several curves and information about the data
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示了几个曲线和数据相关的信息
- en: 'Display the results. Here, we will display the automatically saved results
    image, `results.png`:'
  id: totrans-557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示结果。在这里，我们将展示自动保存的结果图像，`results.png`：
- en: '[PRE234]'
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE234]'
- en: '[PRE235]'
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE235]'
- en: '[PRE236]'
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE236]'
- en: '[PRE237]'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE237]'
- en: 'Here is the result:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.18 – A results summary of the YOLO model trained from scratch after
    100 epochs](img/B19629_10_18.jpg)'
  id: totrans-563
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.18 – 从零开始训练的YOLO模型在100个训练轮次后的结果汇总](img/B19629_10_18.jpg)'
- en: Figure 10.18 – A results summary of the YOLO model trained from scratch after
    100 epochs
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18 – 从零开始训练的YOLO模型在100个训练轮次后的结果汇总
- en: Several train and validation losses are displayed, as well as several losses
    – precision (P), recall (R), mAP50, and mAP50-95.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 显示了几个训练和验证的损失，以及精度（P）、召回率（R）、mAP50和mAP50-95等指标的损失。
- en: The results are encouraging considering the small dataset – we see a decreasing
    loss and a mAP50 increasing to 0.7, meaning the model is learning well.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到小数据集，结果是令人鼓舞的——我们看到损失在减少，而mAP50提高到了0.7，这意味着模型在良好学习。
- en: 'Let’s display the results as an example of the test set. For that, we first
    need to implement a function that allows us to display the image and the predicted
    boxes and classes, `plot_results_one_image`:'
  id: totrans-567
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们以测试集中的一张图像为例展示结果。为此，我们首先需要实现一个函数，用于展示图像以及预测的边界框和类别，`plot_results_one_image`：
- en: '[PRE238]'
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE238]'
- en: '[PRE239]'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE239]'
- en: '[PRE240]'
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE240]'
- en: '[PRE241]'
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE241]'
- en: '[PRE242]'
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE242]'
- en: '[PRE243]'
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE243]'
- en: '[PRE244]'
  id: totrans-574
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE244]'
- en: '[PRE245]'
  id: totrans-575
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE245]'
- en: '[PRE246]'
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE246]'
- en: '[PRE247]'
  id: totrans-577
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE247]'
- en: '[PRE248]'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE248]'
- en: '[PRE249]'
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE249]'
- en: 'We can then compute the inference and display the results on an image from
    the test set:'
  id: totrans-580
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以计算推理结果并将其展示在测试集中的一张图像上：
- en: '[PRE250]'
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE250]'
- en: '[PRE251]'
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE251]'
- en: '[PRE252]'
  id: totrans-583
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE252]'
- en: '[PRE253]'
  id: totrans-584
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE253]'
- en: '[PRE254]'
  id: totrans-585
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE254]'
- en: 'Here is the result:'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.19 – An image from the test set and the predicted detections from
    the trained model](img/B19629_10_19.jpg)'
  id: totrans-587
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.19 – 测试集中的一张图像和训练模型预测的检测结果](img/B19629_10_19.jpg)'
- en: Figure 10.19 – An image from the test set and the predicted detections from
    the trained model
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.19 – 测试集中的一张图像和训练模型预测的检测结果
- en: 'As we can see, our YOLO model has already learned to detect and correctly classify
    several classes. However, there is still room for improvement:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的YOLO模型已经学会了检测并正确分类多个类别。然而，仍然有改进的空间：
- en: The boxes do not perfectly match the objects; they are either too large or too
    small
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些框与物体并不完全匹配；它们要么太大，要么太小
- en: An object may have two classes (even if the difference between the `Blur Number
    Plate` and `Number Plate` classes is arguable)
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个物体可能具有两个类别（即使`模糊车牌`和`车牌`这两个类别之间的差异有争议）
- en: Important note
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: It is worth mentioning that the direct output of the YOLO model usually contains
    many more bounding boxes. A postprocessing step, called the **non-max suppression**
    algorithm, has been applied here. This algorithm only keeps bounding boxes with
    a high enough confidence level, and small enough overlapping (computed with IoU)
    with other boxes of the same class.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，YOLO模型的直接输出通常包含更多的边界框。这里应用了一个后处理步骤，称为**非极大抑制**算法。该算法仅保留具有足够高置信度，并且与同类其他框重叠较小（通过IoU计算）的边界框。
- en: Let’s try to fix this using transfer learning.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过迁移学习来修复这个问题。
- en: Training with transfer learning
  id: totrans-595
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用迁移学习进行训练
- en: 'We will now train another model on this exact same dataset, with the same number
    of epochs. However, instead of using a model with random weights, we will load
    a model that was trained on the COCO dataset, allowing us to take advantage of
    transfer learning:'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将在完全相同的数据集上训练另一个模型，使用相同的训练轮数（epochs）。不过，与使用随机权重的模型不同，我们将加载一个在COCO数据集上训练过的模型，从而利用迁移学习的优势：
- en: 'Instantiate and train a pre-trained model. Instead of instantiating the model
    with `yolov8n.yaml`, we only need to instantiate it with `yolov8n.pt`; this will
    automatically download the pretrained weights and load them:'
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化并训练一个预训练模型。我们无需使用`yolov8n.yaml`来实例化模型，只需使用`yolov8n.pt`即可；这将自动下载预训练权重并加载它们：
- en: '[PRE255]'
  id: totrans-598
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE255]'
- en: '[PRE256]'
  id: totrans-599
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE256]'
- en: '[PRE257]'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE257]'
- en: '[PRE258]'
  id: totrans-601
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE258]'
- en: '[PRE259]'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE259]'
- en: 'Let’s now display the results of this model:'
  id: totrans-603
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们展示这个模型的结果：
- en: '[PRE260]'
  id: totrans-604
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE260]'
- en: '[PRE261]'
  id: totrans-605
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE261]'
- en: '[PRE262]'
  id: totrans-606
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE262]'
- en: '[PRE263]'
  id: totrans-607
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE263]'
- en: 'Here is the result:'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.20 – A results summary of the YOLO model, with pretrained weights
    on the COCO dataset after 100 epochs](img/B19629_10_20.jpg)'
  id: totrans-609
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.20 – 经过100轮训练后，YOLO模型在COCO数据集上使用预训练权重的结果总结](img/B19629_10_20.jpg)'
- en: Figure 10.20 – A results summary of the YOLO model, with pretrained weights
    on the COCO dataset after 100 epochs
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.20 – 经过100轮训练后，YOLO模型在COCO数据集上使用预训练权重的结果总结
- en: Using transfer learning, all metrics have better performances – the mAP50 now
    climbs up to 0.8 against 0.7 previously, which is a significant improvement.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 通过迁移学习，所有指标的表现都得到了提升——mAP50现在提高到了0.8，而之前是0.7，这是一个显著的改进。
- en: 'We can now display the results in the same image as we did previously so that
    we can compare them:'
  id: totrans-612
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以在与之前相同的图像中展示结果，以便进行比较：
- en: '[PRE264]'
  id: totrans-613
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE264]'
- en: '[PRE265]'
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE265]'
- en: '[PRE266]'
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE266]'
- en: 'Here is the result:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.21 – An image from the test set and the predicted detections from
    the model with the pretrained weights](img/B19629_10_21.jpg)'
  id: totrans-617
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.21 – 来自测试集的图像，以及使用预训练权重的模型预测的检测结果](img/B19629_10_21.jpg)'
- en: Figure 10.21 – An image from the test set and the predicted detections from
    the model with the pretrained weights
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.21 – 来自测试集的图像，以及使用预训练权重的模型预测的检测结果
- en: This single image already shows several improvements – not only do the bounding
    boxes now perfectly fit the objects, but also no two objects are detected for
    a single number plate anymore. Thanks to transfer learning, we were able to efficiently
    help the model generalize.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 这张单独的图像已经展示了几个改进——现在边界框不仅完全适应了物体，而且同一个车牌不再被检测为两个物体。得益于迁移学习，我们能够有效地帮助模型进行泛化。
- en: There’s more…
  id: totrans-620
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: In this recipe, we focused on the object detection task, but YOLO models can
    do much more than that.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们专注于目标检测任务，但YOLO模型不仅仅能做这些。
- en: 'Using the same library, it is also possible to train models for the following:'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的库，还可以训练以下模型：
- en: Classification
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Segmentation
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割
- en: Pose
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姿态
- en: All these models also come with pretrained weights so that transfer learning
    can be leveraged to get good performances, even with small datasets.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些模型也都附带预训练权重，因此可以利用迁移学习，即使是小数据集也能获得良好的表现。
- en: See also
  id: totrans-627
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'A blog post explaining the mAP metric computation: [https://pyimagesearch.com/2022/05/02/mean-average-precision-map-using-the-coco-evaluator/](https://pyimagesearch.com/2022/05/02/mean-average-precision-map-using-the-coco-evaluator/)'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一篇解释mAP指标计算的博客文章：[https://pyimagesearch.com/2022/05/02/mean-average-precision-map-using-the-coco-evaluator/](https://pyimagesearch.com/2022/05/02/mean-average-precision-map-using-the-coco-evaluator/)
- en: 'The COCO dataset website, which allows you to easily browse and display the
    dataset: [https://cocodataset.org/#home](https://cocodataset.org/#home)'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COCO数据集网站，它允许您轻松浏览和显示数据集：[https://cocodataset.org/#home](https://cocodataset.org/#home)
- en: 'A link to the original YOLO paper: [https://arxiv.org/abs/1506.02640](https://arxiv.org/abs/1506.02640)'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向原始YOLO论文的链接：[https://arxiv.org/abs/1506.02640](https://arxiv.org/abs/1506.02640)
- en: 'A link to the ultralytics documentation: [https://docs.ultralytics.com/usage/python/](https://docs.ultralytics.com/usage/python/)'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个指向Ultralytics文档的链接：[https://docs.ultralytics.com/usage/python/](https://docs.ultralytics.com/usage/python/)
- en: 'The YOLOv8 GitHub repo: [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLOv8 GitHub 仓库：[https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
- en: 'A clear and concise post from Albumentations about the main bounding boxes
    formats: [https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/)'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自Albumentations的简洁清晰的帖子，介绍了主要的边界框格式：[https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/)
- en: Semantic segmentation using transfer learning
  id: totrans-634
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用迁移学习进行语义分割
- en: In this recipe, we will take advantage of transfer learning and the fine-tuning
    of pretrained models to undertake a specific task of computer vision – the semantic
    segmentation of drone images.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将利用迁移学习和预训练模型的微调，来完成一个特定的计算机视觉任务——无人机图像的语义分割。
- en: Object detection and instance segmentation are about detecting objects in an
    image – an object is delimited by a bounding box, as well as a polygon in the
    case of instance segmentation. Alternatively, **semantic segmentation** is about
    classifying all the pixels of an image in a class.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测和实例分割主要关注图像中的物体检测 – 物体通过边界框进行限定，在实例分割中则使用多边形来限定物体。相反，**语义分割**则是对图像中的所有像素进行类别分类。
- en: As we can see in *Figure 10**.22*, all pixels have a given color so that each
    one is attributed a class.
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在*图 10.22*中所见，所有像素都有特定的颜色，因此每个像素都被分配了一个类别。
- en: '![Figure 10.22 – An example of annotation of semantic segmentation. On the
    left is the original image, and on the right is the labeled image – there is one
    class of object per color, and each pixel is assigned to a given class](img/B19629_10_22.jpg)'
  id: totrans-638
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.22 – 语义分割注释的示例。左侧是原始图像，右侧是标注图像 – 每种颜色代表一个物体类别，每个像素都分配给一个特定类别](img/B19629_10_22.jpg)'
- en: Figure 10.22 – An example of annotation of semantic segmentation. On the left
    is the original image, and on the right is the labeled image – there is one class
    of object per color, and each pixel is assigned to a given class
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.22 – 语义分割注释的示例。左侧是原始图像，右侧是标注图像 – 每种颜色代表一个物体类别，每个像素都分配给一个特定类别
- en: Even if it may look similar to instance segmentation, we will see in this recipe
    that the concepts and methods used are quite different. We will review the possible
    metrics, losses, architectures, and encoders to solve a semantic segmentation
    problem.
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 即使它看起来可能与实例分割相似，我们将在本教程中看到，所使用的概念和方法是完全不同的。我们将回顾解决语义分割问题的可能度量、损失、架构和编码器。
- en: Metrics
  id: totrans-641
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 度量标准
- en: Since semantic segmentation can be seen as a multiclass classification of each
    pixel, the most intuitive metric is the averaged accuracy score – the pixel accuracy
    averaged over the whole image.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语义分割可以看作是对每个像素的多类别分类，最直观的度量标准是平均准确率分数 – 即整个图像的像素准确率的平均值。
- en: Indeed, it can be used to sometimes yield solid results. However, most of the
    time in semantic segmentation, some classes are far less present than others –
    for example, in urban pictures, it is likely that there will be a lot of pixels
    of roads and buildings, and much less of persons or bikes. It is then likely to
    have good accuracy but not offer a model that accurately segments underrepresented
    classes.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，它有时可以用来得出较为稳固的结果。然而，在大多数语义分割任务中，一些类别的像素远少于其他类别 – 例如，在城市图像中，路面和建筑物的像素可能很多，而人的或自行车的像素则相对较少。这时，模型可能会得到很好的准确率，但并不一定能准确分割那些低频类别。
- en: Because of the limitation of the accuracy metric, many other metrics were proposed.
    One of the most used metrics in semantic segmentation is the IoU, already explained
    in the previous recipe. The IoU can be computed for each class independently and
    then averaged to compute a single metric (other averaging methods exist and are
    explored in more detail in *There’s more…* subsection). The IoU is sometimes referred
    to as the **Jaccard index**.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 由于准确率度量的局限性，许多其他度量标准应运而生。在语义分割中，最常用的度量之一是 IoU，已经在前面的教程中解释过。IoU 可以针对每个类别独立计算，然后求平均值来计算一个单一的度量（其他平均方法也存在，并在*后续部分*中有更详细的探讨）。IoU
    有时也被称为**Jaccard 指数**。
- en: 'One more frequently used metric is the **Dice coefficient**. Given two sets
    of pixels, A (for example, the predictions for a class) and B (for example, the
    ground truth for a class), the Dice coefficient can be computed with the following
    formula:'
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常用的度量标准是**Dice 系数**。给定两个像素集，A（例如，某一类别的预测）和 B（例如，某一类别的真实标注），Dice 系数可以通过以下公式计算：
- en: '![](img/Formula_10_017.jpg)'
  id: totrans-646
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_10_017.jpg)'
- en: Here, |A| is simply the number of pixels in A, sometimes called the cardinality
    of A. The Dice coefficient is usually compared to the F1 score and is mathematically
    equivalent. Just like the IoU, the Dice coefficient can be averaged over all the
    classes.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，|A| 仅仅是 A 中像素的数量，有时称为 A 的基数。Dice 系数通常与 F1 分数进行比较，并且在数学上是等价的。与 IoU 相似，Dice
    系数也可以在所有类别上求平均。
- en: Of course, other metrics exist and can be used, but they are outside the scope
    of this recipe.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，存在其他可以使用的度量标准，但它们超出了本教程的范围。
- en: Losses
  id: totrans-649
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 损失
- en: Several losses were developed over the years to improve the performance of semantic
    segmentation models. Again, if we just think of semantic segmentation as a classification
    task over many pixels, cross-entropy loss is an intuitive choice. However, just
    like the accuracy score, cross-entropy loss is not a good choice in the case of
    imbalanced classes.
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，已经开发出几种损失函数，以提高语义分割模型的性能。同样，如果我们仅将语义分割视为在多个像素上的分类任务，交叉熵损失是一个直观的选择。然而，像准确度评分一样，交叉熵损失在类别不平衡的情况下并不是一个好的选择。
- en: In practice, it is common to simply use the Dice loss, which directly reuses
    the Dice coefficient. Dice loss is usually better in case of class imbalance,
    but it sometimes has bumpy training losses.
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，常常直接使用Dice损失，它直接重用Dice系数。Dice损失在类别不平衡的情况下通常表现更好，但有时训练损失会波动较大。
- en: Many other losses were proposed, such as the focal loss and the Tversky loss,
    and all have strengths and improvements. A paper summarizing the most widely used
    losses is cited in the *See* *also* subsection.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他损失函数被提出，比如焦点损失和Tversky损失，它们各有优点和改进。总结最广泛使用的损失函数的论文已在*另见*小节中引用。
- en: Architectures
  id: totrans-653
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 架构
- en: Semantic segmentation is a very specific task, in the sense that unlike object
    detection, the input and output are both images. Indeed, for a given input image
    of size 480x640 (purposefully omitting the RGB channels), the output image is
    expected to have the exact same dimension of 480x640, since each pixel must have
    a predicted class.
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割是一个非常特定的任务，因为与目标检测不同，输入和输出都是图像。事实上，对于一个给定的480x640大小的输入图像（特意省略RGB通道），期望输出图像具有相同的480x640维度，因为每个像素必须有一个预测的类别。
- en: More precisely, for an *N*-class semantic segmentation task, the output dimension
    would be 480x640x*N*, having for each pixel a set of *N* probabilities as the
    output of a softmax function.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 更准确地说，对于一个*N*类别的语义分割任务，输出维度将是480x640x*N*，每个像素的输出是Softmax函数的*N*个概率值。
- en: 'The architectures to deal with such problems are usually based on the encoder-decoder
    principle:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 处理此类问题的架构通常基于编码器-解码器原理：
- en: An encoder computes describing features on the input image
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器计算输入图像的特征描述。
- en: A decoder decodes those encoded features in order to have the expected outputs
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器解码这些编码特征，以便获得预期的输出。
- en: 'One of the most famous architectures for semantic segmentation is the U-Net
    architecture, shown in *Figure 10**.23*:'
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的语义分割架构之一是U-Net架构，如*图 10.23*所示：
- en: '![Figure 10.23 – The U-Net architecture as presented in the original paper
    U-Net: Convolutional Networks for Biomedical Image Segmentation](img/B19629_10_23.jpg)'
  id: totrans-660
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.23 – U-Net架构，如原始论文《U-Net：用于生物医学图像分割的卷积网络》中所述](img/B19629_10_23.jpg)'
- en: 'Figure 10.23 – The U-Net architecture as presented in the original paper U-Net:
    Convolutional Networks for Biomedical Image Segmentation'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.23 – U-Net架构，如原始论文《U-Net：用于生物医学图像分割的卷积网络》中所述
- en: 'As we can see in *Figure 10**.23*, the U-Net architecture can be broken down
    as follows:'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 10.23*所示，U-Net架构可以分解为如下：
- en: The input image is at the top left of the diagram.
  id: totrans-663
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入图像位于图示的左上角。
- en: The input image is sequentially encoded, as we can move down to the bottom of
    the diagram with convolutional and pooling layers.
  id: totrans-664
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入图像被顺序编码，我们可以通过卷积层和池化层逐步向图示的底部移动。
- en: As we go back up to the top right of the diagram, the output of the encoder
    is decoded and concatenated with the previous output of the encoder with convolutional
    and upscaling layers.
  id: totrans-665
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们向图示的右上角回退时，编码器的输出被解码，并与之前的编码器输出通过卷积和上采样层进行拼接。
- en: Finally, an output of the same width and height as the input image is predicted.
  id: totrans-666
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，预测的输出图像具有与输入图像相同的宽度和高度。
- en: One strength of U-Net is that it encodes and then decodes, and it also concatenates
    the intermediate encodings to have efficient predictions. It is now a standard
    architecture when it comes to semantic segmentation.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: U-Net的一个优点是它先进行编码再进行解码，并且它还将中间编码拼接起来，从而实现高效的预测。现在它已经成为语义分割的标准架构。
- en: 'Other architectures exist, some of which are widely used too, such as the following:'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 还存在其他架构，其中一些也被广泛使用，例如以下几种：
- en: '**Feature Pyramid** **Networks** (**FPN**)'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征金字塔** **网络**（**FPN**）'
- en: U-Net++, a proposed improvement of U-Net
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: U-Net++，是U-Net的一个改进版本。
- en: Encoders
  id: totrans-671
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码器
- en: In the original U-Net paper, as we can see in *Figure 10**.23*, the encoder
    part is a specific one, made of convolution and pooling layers. In practice, however,
    it is common to use famous networks as encoders, pretrained on ImageNet or the
    COCO dataset, so that we can take advantage of transfer learning.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始的U-Net论文中，正如我们在*图10.23*中看到的，编码器部分是一个特定的结构，由卷积层和池化层组成。然而，在实际应用中，通常会使用著名的网络作为编码器，这些网络在ImageNet或COCO数据集上进行了预训练，这样我们就可以利用迁移学习的优势。
- en: 'Depending on the needs and constraints, several encoders may be used, such
    as the following:'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需求和约束，可以使用多个编码器，如下所示：
- en: MobileNet – a light encoder, developed for fast inference on the edge
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MobileNet – 一个轻量级的编码器，专为边缘设备上的快速推理开发
- en: '**Visual Geometry Group** (**VGG**) architectures'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉几何组**（**VGG**）架构'
- en: ResNet and ResNet-based architectures
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ResNet及其基于ResNet的架构
- en: EfficientNet architectures
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EfficientNet架构
- en: The SMP library
  id: totrans-678
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMP库
- en: 'The **Segmentation Models PyTorch** (**SMP**) library is an open source library
    allowing us to do all we need, including the following:'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: '**分割模型PyTorch**（**SMP**）库是一个开源库，允许我们做所有需要的操作，包括以下内容：'
- en: Choosing architectures such as U-Net, FPN, or U-Net++
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择如U-Net、FPN或U-Net++等架构
- en: Choosing encoders such as VGG or MobileNet
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择像VGG或MobileNet这样的编码器
- en: Already implemented losses such as the Dice loss and the focal loss
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已实现的损失函数，如Dice损失和焦点损失
- en: Helper functions to compute metrics such as Dice and the IoU
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算Dice和IoU等指标的辅助函数
- en: We will use this library in this recipe to train semantic segmentation models
    on a drone dataset.
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本教程中使用这个库，在无人机数据集上训练语义分割模型。
- en: Getting started
  id: totrans-685
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用
- en: 'For this recipe, we will need to download a dataset containing 400 images and
    associated labels. It can be downloaded with the Kaggle API using the following
    commands:'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个教程，我们需要下载一个包含400张图像及其相关标签的数据集。可以使用Kaggle API通过以下命令下载：
- en: '[PRE267]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE267]'
- en: We end up with three folders, containing several datasets. We will use the one
    in `classes_dataset`, a five-classes dataset.
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终得到三个文件夹，其中包含多个数据集。我们将使用`classes_dataset`中的数据集，这是一个包含五个类别的数据集。
- en: 'We also need to install the required libraries with the following command:'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要使用以下命令安装所需的库：
- en: '[PRE268]'
  id: totrans-690
  prefs: []
  type: TYPE_PRE
  zh: '[PRE268]'
- en: How to do it…
  id: totrans-691
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: We will first train a U-Net model with a MobileNet encoder with transfer learning
    on our task, and then we will do the same with fine-tuning techniques by freezing
    layers and gradually decreasing the learning rate, in order to improve the performance
    of the model.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用迁移学习在我们的任务上训练一个带有MobileNet编码器的U-Net模型，然后我们将通过冻结层并逐步降低学习率的微调技术进行相同的训练，以提高模型的性能。
- en: Training with ImageNet weights and unfreezing all weights
  id: totrans-693
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用ImageNet权重进行训练并解冻所有权重
- en: 'We will first train a pretrained model on ImageNet in a regular fashion, with
    all the weights trainable:'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先按常规方式训练一个在ImageNet上预训练的模型，所有权重都是可训练的：
- en: 'We will first make the required imports for this recipe:'
  id: totrans-695
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先进行所需的导入操作：
- en: '[PRE269]'
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE269]'
- en: '[PRE270]'
  id: totrans-697
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE270]'
- en: '[PRE271]'
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE271]'
- en: '[PRE272]'
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE272]'
- en: '[PRE273]'
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE273]'
- en: '[PRE274]'
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE274]'
- en: '[PRE275]'
  id: totrans-702
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE275]'
- en: '[PRE276]'
  id: totrans-703
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE276]'
- en: '[PRE277]'
  id: totrans-704
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE277]'
- en: '[PRE278]'
  id: totrans-705
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE278]'
- en: '[PRE279]'
  id: totrans-706
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE279]'
- en: 'Implement the `DroneDataset` class:'
  id: totrans-707
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现`DroneDataset`类：
- en: '[PRE280]'
  id: totrans-708
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE280]'
- en: '[PRE281]'
  id: totrans-709
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE281]'
- en: '[PRE282]'
  id: totrans-710
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE282]'
- en: '[PRE283]'
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE283]'
- en: '[PRE284]'
  id: totrans-712
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '[PRE285]'
  id: totrans-713
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE285]'
- en: '[PRE286]'
  id: totrans-714
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE286]'
- en: '[PRE287]'
  id: totrans-715
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE287]'
- en: '[PRE288]'
  id: totrans-716
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE288]'
- en: '[PRE289]'
  id: totrans-717
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '[PRE290]'
  id: totrans-718
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE290]'
- en: '[PRE291]'
  id: totrans-719
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE291]'
- en: '[PRE292]'
  id: totrans-720
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE292]'
- en: '[PRE293]'
  id: totrans-721
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE293]'
- en: '[PRE294]'
  id: totrans-722
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE294]'
- en: '[PRE295]'
  id: totrans-723
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE295]'
- en: '[PRE296]'
  id: totrans-724
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE296]'
- en: '[PRE297]'
  id: totrans-725
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE297]'
- en: '[PRE298]'
  id: totrans-726
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE298]'
- en: '[PRE299]'
  id: totrans-727
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE299]'
- en: '[PRE300]'
  id: totrans-728
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE300]'
- en: '[PRE301]'
  id: totrans-729
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE301]'
- en: '[PRE302]'
  id: totrans-730
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE302]'
- en: '[PRE303]'
  id: totrans-731
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE303]'
- en: '[PRE304]'
  id: totrans-732
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE304]'
- en: '[PRE305]'
  id: totrans-733
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE305]'
- en: '[PRE306]'
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE306]'
- en: '[PRE307]'
  id: totrans-735
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE307]'
- en: '[PRE308]'
  id: totrans-736
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE308]'
- en: The `__init__` method just reads all the available image and mask files. It
    also takes a Boolean variable for the train versus test dataset, allowing you
    to select only the first 80% or the last 20% of the files.
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: '`__init__`方法只是读取所有可用的图像和掩膜文件。它还接受一个布尔变量，表示是训练集还是测试集，使你可以选择文件的前80%或后20%。'
- en: The `__getitem__` method simply loads an image from a path and returns the transformed
    image as well as the mask as tensors.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: '`__getitem__`方法只是从路径加载图像，并将转换后的图像以及掩膜作为张量返回。'
- en: 'Instantiate the transformation to apply it to images – here, it’s simply a
    tensor conversion and a normalization:'
  id: totrans-739
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化转换操作，并将其应用于图像——在这里，它只是简单的张量转换和归一化：
- en: '[PRE309]'
  id: totrans-740
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE309]'
- en: '[PRE310]'
  id: totrans-741
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE310]'
- en: '[PRE311]'
  id: totrans-742
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE311]'
- en: '[PRE312]'
  id: totrans-743
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE312]'
- en: '[PRE313]'
  id: totrans-744
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE313]'
- en: 'Define a few constants – the batch size, learning rate, classes, and device:'
  id: totrans-745
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义几个常量——批次大小、学习率、类别和设备：
- en: '[PRE314]'
  id: totrans-746
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE314]'
- en: '[PRE315]'
  id: totrans-747
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE315]'
- en: '[PRE316]'
  id: totrans-748
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE316]'
- en: '[PRE317]'
  id: totrans-749
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE317]'
- en: '[PRE318]'
  id: totrans-750
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE318]'
- en: '[PRE319]'
  id: totrans-751
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE319]'
- en: 'Instantiate the datasets and data loaders:'
  id: totrans-752
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化数据集和数据加载器：
- en: '[PRE320]'
  id: totrans-753
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE320]'
- en: '[PRE321]'
  id: totrans-754
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE321]'
- en: '[PRE322]'
  id: totrans-755
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE322]'
- en: '[PRE323]'
  id: totrans-756
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE323]'
- en: '[PRE324]'
  id: totrans-757
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE324]'
- en: '[PRE325]'
  id: totrans-758
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE325]'
- en: '[PRE326]'
  id: totrans-759
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE326]'
- en: '[PRE327]'
  id: totrans-760
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE327]'
- en: '[PRE328]'
  id: totrans-761
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE328]'
- en: '[PRE329]'
  id: totrans-762
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE329]'
- en: '[PRE330]'
  id: totrans-763
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE330]'
- en: '[PRE331]'
  id: totrans-764
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE331]'
- en: '[PRE332]'
  id: totrans-765
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE332]'
- en: '[PRE333]'
  id: totrans-766
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE333]'
- en: '[PRE334]'
  id: totrans-767
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE334]'
- en: '[PRE335]'
  id: totrans-768
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE335]'
- en: 'Display an image with an overlay of the associated labels:'
  id: totrans-769
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示带有相关标签叠加的图像：
- en: '[PRE336]'
  id: totrans-770
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE336]'
- en: '[PRE337]'
  id: totrans-771
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE337]'
- en: '[PRE338]'
  id: totrans-772
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE338]'
- en: '[PRE339]'
  id: totrans-773
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE339]'
- en: '[PRE340]'
  id: totrans-774
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE340]'
- en: '[PRE341]'
  id: totrans-775
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE341]'
- en: '[PRE342]'
  id: totrans-776
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE342]'
- en: '[PRE343]'
  id: totrans-777
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE343]'
- en: 'Here is the result:'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 10.24 – An image of the Drone dataset with its mask overlay, made
    of five colors for five classes](img/B19629_10_24.jpg)'
  id: totrans-779
  prefs: []
  type: TYPE_IMG
  zh: '![图10.24 – 带有掩膜覆盖的无人机数据集图像，掩膜由五种颜色表示五个类别](img/B19629_10_24.jpg)'
- en: Figure 10.24 – An image of the Drone dataset with its mask overlay, made of
    five colors for five classes
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.24 – 带有掩膜覆盖的无人机数据集图像，掩膜由五种颜色表示五个类别
- en: 'As we can see, there are several colors overlayed on the image:'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，图像上叠加了几种颜色：
- en: Yellow for `'landing-zones'`
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黄色代表`'landing-zones'`
- en: Dark green for `'soft-surfaces'`
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深绿色代表`'soft-surfaces'`
- en: Blue for `'water'`
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝色表示`'water'`
- en: Purple for `'obstacles'`
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 紫色表示`'obstacles'`
- en: Light green for `'moving-objects'`
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浅绿色表示`'moving-objects'`
- en: 'Instantiate the model – a U-Net architecture, with EfficientNet as an encoder
    (more specifically, the `''efficientnet-b5''` encoder), pretrained on `imagenet`:'
  id: totrans-787
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化模型——一个U-Net架构，使用EfficientNet作为编码器（更具体地说，是`'efficientnet-b5'`编码器），并在`imagenet`上进行预训练：
- en: '[PRE344]'
  id: totrans-788
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE344]'
- en: '[PRE345]'
  id: totrans-789
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE345]'
- en: '[PRE346]'
  id: totrans-790
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE346]'
- en: '[PRE347]'
  id: totrans-791
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE347]'
- en: '[PRE348]'
  id: totrans-792
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE348]'
- en: '[PRE349]'
  id: totrans-793
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE349]'
- en: 'Instantiate the Adam optimizer and the loss as the Dice loss:'
  id: totrans-794
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化Adam优化器，并将损失设置为Dice损失：
- en: '[PRE350]'
  id: totrans-795
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE350]'
- en: '[PRE351]'
  id: totrans-796
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE351]'
- en: '[PRE352]'
  id: totrans-797
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE352]'
- en: '[PRE353]'
  id: totrans-798
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE353]'
- en: 'Implement a helper function, `compute_metrics`, that will help compute the
    IoU and F1-score (equivalent to the Dice coefficient):'
  id: totrans-799
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个辅助函数，`compute_metrics`，它将帮助计算IoU和F1分数（等同于Dice系数）：
- en: '[PRE354]'
  id: totrans-800
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE354]'
- en: '[PRE355]'
  id: totrans-801
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE355]'
- en: '[PRE356]'
  id: totrans-802
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE356]'
- en: '[PRE357]'
  id: totrans-803
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE357]'
- en: '[PRE358]'
  id: totrans-804
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE358]'
- en: '[PRE359]'
  id: totrans-805
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE359]'
- en: '[PRE360]'
  id: totrans-806
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE360]'
- en: '[PRE361]'
  id: totrans-807
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE361]'
- en: '[PRE362]'
  id: totrans-808
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE362]'
- en: '[PRE363]'
  id: totrans-809
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE363]'
- en: 'Implement a helper function, `epoch_step_unet`, that will compute forward propagation,
    backpropagation if needed, the loss function, and metrics:'
  id: totrans-810
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个辅助函数，`epoch_step_unet`，该函数将计算前向传播、需要时的反向传播、损失函数和指标：
- en: '[PRE364]'
  id: totrans-811
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE364]'
- en: '[PRE365]'
  id: totrans-812
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE365]'
- en: '[PRE366]'
  id: totrans-813
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE366]'
- en: '[PRE367]'
  id: totrans-814
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE367]'
- en: '[PRE368]'
  id: totrans-815
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE368]'
- en: '[PRE369]'
  id: totrans-816
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE369]'
- en: '[PRE370]'
  id: totrans-817
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE370]'
- en: '[PRE371]'
  id: totrans-818
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE371]'
- en: '[PRE372]'
  id: totrans-819
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE372]'
- en: '[PRE373]'
  id: totrans-820
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE373]'
- en: '[PRE374]'
  id: totrans-821
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE374]'
- en: '[PRE375]'
  id: totrans-822
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE375]'
- en: '[PRE376]'
  id: totrans-823
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE376]'
- en: '[PRE377]'
  id: totrans-824
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE377]'
- en: '[PRE378]'
  id: totrans-825
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE378]'
- en: '[PRE379]'
  id: totrans-826
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE379]'
- en: '[PRE380]'
  id: totrans-827
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE380]'
- en: '[PRE381]'
  id: totrans-828
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE381]'
- en: '[PRE382]'
  id: totrans-829
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE382]'
- en: '[PRE383]'
  id: totrans-830
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE383]'
- en: '[PRE384]'
  id: totrans-831
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE384]'
- en: '[PRE385]'
  id: totrans-832
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE385]'
- en: 'Implement a `train_unet` function, allowing us to train the model:'
  id: totrans-833
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个`train_unet`函数，允许我们训练模型：
- en: '[PRE386]'
  id: totrans-834
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE386]'
- en: '[PRE387]'
  id: totrans-835
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE387]'
- en: '[PRE388]'
  id: totrans-836
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE388]'
- en: '[PRE389]'
  id: totrans-837
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE389]'
- en: '[PRE390]'
  id: totrans-838
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE390]'
- en: '[PRE391]'
  id: totrans-839
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE391]'
- en: '[PRE392]'
  id: totrans-840
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE392]'
- en: '[PRE393]'
  id: totrans-841
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE393]'
- en: '[PRE394]'
  id: totrans-842
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE394]'
- en: '[PRE395]'
  id: totrans-843
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE395]'
- en: '[PRE396]'
  id: totrans-844
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE396]'
- en: '[PRE397]'
  id: totrans-845
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE397]'
- en: '[PRE398]'
  id: totrans-846
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE398]'
- en: '[PRE399]'
  id: totrans-847
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE399]'
- en: '[PRE400]'
  id: totrans-848
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE400]'
- en: '[PRE401]'
  id: totrans-849
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE401]'
- en: '[PRE402]'
  id: totrans-850
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE402]'
- en: '[PRE403]'
  id: totrans-851
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE403]'
- en: '[PRE404]'
  id: totrans-852
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE404]'
- en: '[PRE405]'
  id: totrans-853
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE405]'
- en: '[PRE406]'
  id: totrans-854
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE406]'
- en: '[PRE407]'
  id: totrans-855
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE407]'
- en: '[PRE408]'
  id: totrans-856
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE408]'
- en: '[PRE409]'
  id: totrans-857
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE409]'
- en: '[PRE410]'
  id: totrans-858
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE410]'
- en: '[PRE411]'
  id: totrans-859
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE411]'
- en: '[PRE412]'
  id: totrans-860
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE412]'
- en: '[PRE413]'
  id: totrans-861
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE413]'
- en: '[PRE414]'
  id: totrans-862
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE414]'
- en: '[PRE415]'
  id: totrans-863
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE415]'
- en: '[PRE416]'
  id: totrans-864
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE416]'
- en: '[PRE417]'
  id: totrans-865
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE417]'
- en: '[PRE418]'
  id: totrans-866
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE418]'
- en: '[PRE419]'
  id: totrans-867
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE419]'
- en: '[PRE420]'
  id: totrans-868
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE420]'
- en: '[PRE421]'
  id: totrans-869
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE421]'
- en: '[PRE422]'
  id: totrans-870
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE422]'
- en: '[PRE423]'
  id: totrans-871
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE423]'
- en: '[PRE424]'
  id: totrans-872
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE424]'
- en: '[PRE425]'
  id: totrans-873
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE425]'
- en: '[PRE426]'
  id: totrans-874
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE426]'
- en: '[PRE427]'
  id: totrans-875
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE427]'
- en: '[PRE428]'
  id: totrans-876
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE428]'
- en: 'The `train_unet` function does the following:'
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_unet`函数执行以下操作：'
- en: Trains the model on the train set, and compute the evaluation metrics (the IoU
    and F1-score)
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练集上训练模型，并计算评估指标（IoU和F1分数）
- en: Evaluates the model on the test set with the evaluation metrics
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用评估指标在测试集上评估模型
- en: If a learning rate scheduler is provided, applies a step (see the *There’s more*
    subsection for more about this)
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了学习率调度器，则应用一个步骤（更多信息请见*更多内容*小节）
- en: Displays in the standard output the train and test losses and IoU
  id: totrans-881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在标准输出中显示训练和测试的损失以及IoU
- en: Returns the train and test metrics
  id: totrans-882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回训练和测试的指标
- en: 'Train the model for 50 epochs and store the output train and test metrics:'
  id: totrans-883
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型50个epochs并存储输出的训练和测试指标：
- en: '[PRE429]'
  id: totrans-884
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE429]'
- en: '[PRE430]'
  id: totrans-885
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE430]'
- en: '[PRE431]'
  id: totrans-886
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE431]'
- en: 'Display the metrics for the train and test sets:'
  id: totrans-887
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示训练集和测试集的指标：
- en: '[PRE432]'
  id: totrans-888
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE432]'
- en: '[PRE433]'
  id: totrans-889
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE433]'
- en: '[PRE434]'
  id: totrans-890
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE434]'
- en: '[PRE435]'
  id: totrans-891
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE435]'
- en: '[PRE436]'
  id: totrans-892
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE436]'
- en: '[PRE437]'
  id: totrans-893
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE437]'
- en: '[PRE438]'
  id: totrans-894
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE438]'
- en: '[PRE439]'
  id: totrans-895
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE439]'
- en: '[PRE440]'
  id: totrans-896
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE440]'
- en: '[PRE441]'
  id: totrans-897
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE441]'
- en: '[PRE442]'
  id: totrans-898
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE442]'
- en: '[PRE443]'
  id: totrans-899
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE443]'
- en: '[PRE444]'
  id: totrans-900
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE444]'
- en: '[PRE445]'
  id: totrans-901
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE445]'
- en: '[PRE446]'
  id: totrans-902
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE446]'
- en: '[PRE447]'
  id: totrans-903
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE447]'
- en: '[PRE448]'
  id: totrans-904
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE448]'
- en: '[PRE449]'
  id: totrans-905
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE449]'
- en: 'Here is the result:'
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.25 – The Dice loss (top), IoU (middle), and F1-score (bottom) as
    a function of the epoch for the train and test sets](img/B19629_10_25.jpg)'
  id: totrans-907
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.25 – Dice损失（上图），IoU（中图）和F1分数（下图）随epoch变化的图像，分别显示训练集和测试集](img/B19629_10_25.jpg)'
- en: Figure 10.25 – The Dice loss (top), IoU (middle), and F1-score (bottom) as a
    function of the epoch for the train and test sets
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.25 – Dice损失（上图），IoU（中图）和F1分数（下图）随epoch变化的图像，分别显示训练集和测试集
- en: As we can see, the IoU goes up to 87% on the test set and seems to reach a plateau
    after about 30 epochs. Also, the test set metrics are bumpy and unstable, which
    can be because of a learning rate that is too high, as well as a model too large.
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，IoU在测试集上达到了87%，并且在大约30个epochs后似乎达到了一个平台期。此外，测试集的指标波动较大且不稳定，这可能是由于学习率过高或模型过大所致。
- en: Let’s now try to do the same with the freezing layer and gradually the decrease
    the learning rate.
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试使用冻结层，并逐渐降低学习率来做同样的事情。
- en: Fine-tuning a pretrained model by freezing layers
  id: totrans-911
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过冻结层来微调预训练模型
- en: 'We will now train a pretrained model in two stages – first, we will freeze
    most of the layers of the model for 20 epochs, then only unfreeze all the layers,
    and train 30 more epochs to fine-tune the model:'
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将对预训练模型进行两阶段训练——首先，我们将在20个epochs内冻结模型的大部分层，然后解冻所有层，再训练30个epochs来微调模型：
- en: 'First, let’s define two helper functions to freeze and unfreeze layers. The
    `freeze_encoder` function will freeze all the layers of the encoder up to a given
    block level, provided by the `max_level` argument. If no `max_level` is given,
    all weights of the encoder will be frozen:'
  id: totrans-913
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们定义两个辅助函数来冻结和解冻层。`freeze_encoder`函数将冻结编码器的所有层，直到给定的模块级别，由`max_level`参数提供。如果未给定`max_level`，则编码器的所有权重将被冻结：
- en: '[PRE450]'
  id: totrans-914
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE450]'
- en: '[PRE451]'
  id: totrans-915
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE451]'
- en: '[PRE452]'
  id: totrans-916
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE452]'
- en: '[PRE453]'
  id: totrans-917
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE453]'
- en: '[PRE454]'
  id: totrans-918
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE454]'
- en: '[PRE455]'
  id: totrans-919
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE455]'
- en: '[PRE456]'
  id: totrans-920
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE456]'
- en: '[PRE457]'
  id: totrans-921
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE457]'
- en: '[PRE458]'
  id: totrans-922
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE458]'
- en: '[PRE459]'
  id: totrans-923
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE459]'
- en: '[PRE460]'
  id: totrans-924
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE460]'
- en: '[PRE461]'
  id: totrans-925
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE461]'
- en: 'Instantiate a new model, which is the same as before, and print the number
    of trainable parameters:'
  id: totrans-926
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个新模型，与之前的模型相同，并打印可训练参数的数量：
- en: '[PRE462]'
  id: totrans-927
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE462]'
- en: '[PRE463]'
  id: totrans-928
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE463]'
- en: '[PRE464]'
  id: totrans-929
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE464]'
- en: '[PRE465]'
  id: totrans-930
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE465]'
- en: '[PRE466]'
  id: totrans-931
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE466]'
- en: '[PRE467]'
  id: totrans-932
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE467]'
- en: '[PRE468]'
  id: totrans-933
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE468]'
- en: 'The code output is the following:'
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 代码输出如下：
- en: '[PRE469]'
  id: totrans-935
  prefs: []
  type: TYPE_PRE
  zh: '[PRE469]'
- en: As we can see, this model is made of ~31.2 million parameters.
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，模型由大约3120万个参数构成。
- en: 'Le’’s now freeze part of the encoder – the first three blocks, which are basically
    most of the weights of the encoder, as we will see – and print the number of trainable
    parameters left over:'
  id: totrans-937
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们冻结编码器的一部分——前三个模块，这基本上是编码器的大部分权重——并打印剩余可训练参数的数量：
- en: '[PRE470]'
  id: totrans-938
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE470]'
- en: '[PRE471]'
  id: totrans-939
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE471]'
- en: '[PRE472]'
  id: totrans-940
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE472]'
- en: 'The output is the following:'
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE473]'
  id: totrans-942
  prefs: []
  type: TYPE_PRE
  zh: '[PRE473]'
- en: We now have only ~3.9 million trainable parameters left. Almost 27.3 million
    parameters from the encoder are now frozen, out of ~28 million parameters in the
    encoder – the remaining parameters are from the decoder. This means we will mostly
    train the decoder first and use the pretrained encoder as a feature extractor.
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在只剩下大约 390 万个可训练参数。编码器中的大约 2730 万个参数现在被冻结，编码器中的总参数约为 2800 万个——剩余的参数来自解码器。这意味着我们将首先训练解码器，并将预训练的编码器用作特征提取器。
- en: 'Instantiate a new optimizer for training, as well as a scheduler. We will use
    an `ExponentialLR` scheduler here, with a gamma value of `0.95` – this means that
    at each epoch, the learning rate will be multiplied by 0.95:'
  id: totrans-944
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个新的优化器进行训练，并使用调度器。我们将在这里使用 `ExponentialLR` 调度器，gamma 值为 `0.95` ——这意味着在每个
    epoch 后，学习率将乘以 0.95：
- en: '[PRE474]'
  id: totrans-945
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE474]'
- en: '[PRE475]'
  id: totrans-946
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE475]'
- en: '[PRE476]'
  id: totrans-947
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE476]'
- en: '[PRE477]'
  id: totrans-948
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE477]'
- en: 'Train the model with frozen layers on 20 epochs:'
  id: totrans-949
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在冻结层的情况下训练模型，训练 20 个 epoch：
- en: '[PRE478]'
  id: totrans-950
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE478]'
- en: '[PRE479]'
  id: totrans-951
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE479]'
- en: '[PRE480]'
  id: totrans-952
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE480]'
- en: '[PRE481]'
  id: totrans-953
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE481]'
- en: As we can see, after 20 epochs only, the IoU on the test set already reaches
    88%, slightly higher than without freezing and without any learning rate decay.
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，仅经过 20 个 epoch，测试集上的 IoU 已经达到了 88%，略高于没有冻结且没有任何学习率衰减的情况。
- en: 'Now that the decoder and last layers of the encoder are warmed up against this
    dataset, let’s unfreeze all the parameters before training for more epochs:'
  id: totrans-955
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在解码器和编码器的最后几层已对该数据集进行预热，让我们在训练更多的 epoch 之前解冻所有参数：
- en: '[PRE482]'
  id: totrans-956
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE482]'
- en: '[PRE483]'
  id: totrans-957
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE483]'
- en: 'The code output is the following:'
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: 代码输出如下：
- en: '[PRE484]'
  id: totrans-959
  prefs: []
  type: TYPE_PRE
  zh: '[PRE484]'
- en: As we can see, the trainable parameters are now back at 31.2 million, meaning
    that all the parameters are trainable.
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，可训练参数现在已回升至 3120 万，意味着所有参数都可以训练。
- en: 'Train the model on 30 more epochs:'
  id: totrans-961
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 30 个 epoch 后训练模型：
- en: '[PRE485]'
  id: totrans-962
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE485]'
- en: '[PRE486]'
  id: totrans-963
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE486]'
- en: '[PRE487]'
  id: totrans-964
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE487]'
- en: '[PRE488]'
  id: totrans-965
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE488]'
- en: 'Plot the results by concatenating the results with and without freezing:'
  id: totrans-966
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将冻结与不冻结的结果拼接，绘制结果：
- en: '[PRE489]'
  id: totrans-967
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE489]'
- en: '[PRE490]'
  id: totrans-968
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE490]'
- en: '[PRE491]'
  id: totrans-969
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE491]'
- en: '[PRE492]'
  id: totrans-970
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE492]'
- en: '[PRE493]'
  id: totrans-971
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE493]'
- en: '[PRE494]'
  id: totrans-972
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE494]'
- en: '[PRE495]'
  id: totrans-973
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE495]'
- en: '[PRE496]'
  id: totrans-974
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE496]'
- en: '[PRE497]'
  id: totrans-975
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE497]'
- en: '[PRE498]'
  id: totrans-976
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE498]'
- en: '[PRE499]'
  id: totrans-977
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE499]'
- en: '[PRE500]'
  id: totrans-978
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE500]'
- en: '[PRE501]'
  id: totrans-979
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE501]'
- en: '[PRE502]'
  id: totrans-980
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE502]'
- en: '[PRE503]'
  id: totrans-981
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE503]'
- en: '[PRE504]'
  id: totrans-982
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE504]'
- en: '[PRE505]'
  id: totrans-983
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE505]'
- en: '[PRE506]'
  id: totrans-984
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE506]'
- en: 'Here is the result:'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.26 – The Dice loss (top), IoU (middle), and F1-score (bottom) as
    a function of the epoch for train and test sets with fine-tuning – after a drop
    when unfreezing the weights, the metrics improve and are stable again](img/B19629_10_26.jpg)'
  id: totrans-986
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.26 – Dice 损失（顶部）、IoU（中间）和 F1-score（底部）作为经过微调的训练集和测试集的 epoch 函数 – 在解冻权重时出现下降后，指标再次提高并保持稳定](img/B19629_10_26.jpg)'
- en: Figure 10.26 – The Dice loss (top), IoU (middle), and F1-score (bottom) as a
    function of the epoch for train and test sets with fine-tuning – after a drop
    when unfreezing the weights, the metrics improve and are stable again
  id: totrans-987
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.26 – Dice 损失（顶部）、IoU（中间）和 F1-score（底部）作为经过微调的训练集和测试集的 epoch 函数 – 在解冻权重时出现下降后，指标再次提高并保持稳定
- en: We can see that as soon as we unfreeze all the parameters at epoch 20, the curves
    get a bit bumpy. However, after 10 more epochs at around epoch 30, the metrics
    become stable again.
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，一旦在第 20 个 epoch 解冻所有参数，曲线就变得有些颠簸。然而，在接下来的 10 个 epoch（大约在第 30 个 epoch
    时），指标再次变得稳定。
- en: After 50 epochs in total, the IoU reaches almost 90%, against only 87% earlier
    without the fine-tuning techniques (freezing and the learning rate decay).
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: 总共经过 50 个 epoch 后，IoU 几乎达到了 90%，而没有微调技术（冻结和学习率衰减）时，IoU 仅为 87%。
- en: 'Out of curiosity, we can also plot the learning rate as a function of the epoch,
    to look at the decrease:'
  id: totrans-990
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 出于好奇，我们还可以将学习率作为 epoch 的函数绘制出来，以查看其下降情况：
- en: '[PRE507]'
  id: totrans-991
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE507]'
- en: '[PRE508]'
  id: totrans-992
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE508]'
- en: '[PRE509]'
  id: totrans-993
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE509]'
- en: '[PRE510]'
  id: totrans-994
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE510]'
- en: 'Here is the result:'
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 10.27 – The learning rate value as a function of the epoch for a torch
    ExponentialLR class, with a gamma value of 0.95](img/B19629_10_27.jpg)'
  id: totrans-996
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.27 – 对于 torch ExponentialLR 类，学习率值作为 epoch 的函数，gamma 值为 0.95](img/B19629_10_27.jpg)'
- en: Figure 10.27 – The learning rate value as a function of the epoch for a torch
    ExponentialLR class, with a gamma value of 0.95
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.27 – 对于 torch ExponentialLR 类，学习率值作为 epoch 的函数，gamma 值为 0.95
- en: As expected, after 50 epochs, the initial learning rate of 0.05 is divided by
    almost 13, down to roughly 0.0003, since ![](img/Formula_10_018.png).
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，在 50 个 epoch 后，初始学习率 0.05 被大约除以 13，降到大约 0.0003，因为 ![](img/Formula_10_018.png)。
- en: There’s more…
  id: totrans-999
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'There are several ways to compute the metrics such as the IoU or Dice coefficient
    in semantic segmentation. In this recipe, as implemented in the `compute_metrics`
    function, the `''micro''` option was chosen with the following code:'
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 计算语义分割中的指标（如 IoU 或 Dice 系数）有多种方法。在本食谱中，正如在 `compute_metrics` 函数中实现的那样，选择了 `'micro'`
    选项，以下是代码：
- en: '[PRE511]'
  id: totrans-1001
  prefs: []
  type: TYPE_PRE
  zh: '[PRE511]'
- en: First, we can define the TP, FP, FN, and TN for each pixel just like in any
    other classification task. The metrics are then computed based on those values.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以像在任何其他分类任务中一样，定义每个像素的 TP、FP、FN 和 TN。然后，基于这些值计算指标。
- en: 'Based on that, the most common computation methods are available and well summarized
    in the SMP documentation:'
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，最常见的计算方法已经在SMP文档中得到了很好的总结：
- en: '`''micro''`: Sum the TP, FP, FN, and TN pixels over all images and classes
    and then only compute the score.'
  id: totrans-1004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''micro''`：对所有图像和类别中的TP、FP、FN和TN像素进行求和，然后计算得分。'
- en: '`''macro''`: Sum the TP, FP, FN, and TN pixels over all images for each label,
    compute the score for each label, and then average over the labels. If there is
    an imbalanced class (which is usually the case in semantic segmentation), this
    method will not take it into account and should be avoided.'
  id: totrans-1005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''macro''`：对所有图像中的每个标签的TP、FP、FN和TN像素求和，为每个标签计算得分，然后对所有标签取平均。如果存在类别不平衡（通常在语义分割中会出现），该方法将不予考虑，因此应该避免使用。'
- en: '`''weighted''`: The same as `''macro''` but with a weighted average over the
    labels.'
  id: totrans-1006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''weighted''`：与 `''macro''` 相同，但使用标签的加权平均。'
- en: '`''micro-imagewise''`, `''macro-imagewise''`, and `''weighted-imagewise''`:
    The same as `''micro''`, `''macro''`, and `''weighted''`, respectively, but they
    compute the score for each image independently before averaging over the images.
    This can be useful when images in a dataset do not have the same dimensions, for
    example.'
  id: totrans-1007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''micro-imagewise''`、`''macro-imagewise''` 和 `''weighted-imagewise''`：分别与
    `''micro''`、`''macro''` 和 `''weighted''` 相同，但它们在对所有图像求平均之前，会先独立地对每张图像计算得分。当数据集中的图像尺寸不一致时，这种方法非常有用。'
- en: Most of the time, a `'micro'` or `'weighted'` approach works fine, but it’s
    always useful to understand the differences and to be able to play with them.
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，`'micro'` 或 `'weighted'` 方法效果不错，但理解它们之间的差异并能够灵活使用总是很有帮助的。
- en: See also
  id: totrans-1009
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'A paper proposing a review of several losses used in semantic segmentation:
    [https://arxiv.org/pdf/2006.14822.pdf](https://arxiv.org/pdf/2006.14822.pdf)'
  id: totrans-1010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出对多种语义分割损失函数进行综述的论文：[https://arxiv.org/pdf/2006.14822.pdf](https://arxiv.org/pdf/2006.14822.pdf)
- en: 'The paper proposing the U-Net architecture: [https://arxiv.org/pdf/1505.04597.pdf](https://arxiv.org/pdf/1505.04597.pdf)'
  id: totrans-1011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出 U-Net 架构的论文：[https://arxiv.org/pdf/1505.04597.pdf](https://arxiv.org/pdf/1505.04597.pdf)
- en: 'The GitHub repo of the SMP library: [https://github.com/qubvel/segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch)'
  id: totrans-1012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SMP库的GitHub仓库：[https://github.com/qubvel/segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch)
- en: 'A link to the Kaggle dataset: [https://www.kaggle.com/datasets/santurini/semantic-segmentation-drone-dataset](https://www.kaggle.com/datasets/santurini/semantic-segmentation-drone-dataset)'
  id: totrans-1013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle 数据集链接：[https://www.kaggle.com/datasets/santurini/semantic-segmentation-drone-dataset](https://www.kaggle.com/datasets/santurini/semantic-segmentation-drone-dataset)
