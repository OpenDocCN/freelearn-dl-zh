- en: ChapterÂ 5
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬5ç« 
- en: Principled Approaches for Bayesian Deep Learning
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: è´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸç†æ–¹æ³•
- en: Now that weâ€™ve introduced the concept of **Bayesian Neural Networks** (**BNNs**),
    weâ€™re ready to explore the various ways in which they can be implemented. As we
    discussed previously, ideal BNNs are computationally intensive, becoming intractable
    with more sophisticated architectures or larger amounts of data. In recent years,
    researchers have developed a range of methods that make BNNs tractable, allowing
    them to be implemented with larger and more sophisticated neural network architectures.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ä»‹ç»äº†**è´å¶æ–¯ç¥ç»ç½‘ç»œ**ï¼ˆ**BNN**ï¼‰çš„æ¦‚å¿µï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å‡†å¤‡æ¢ç´¢å®ç°å®ƒä»¬çš„å„ç§æ–¹æ³•ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„ï¼Œç†æƒ³çš„BNNè®¡ç®—é‡å·¨å¤§ï¼Œéšç€æ›´å¤æ‚çš„æ¶æ„æˆ–æ›´å¤§æ•°æ®é‡ï¼Œå˜å¾—ä¸å¯å¤„ç†ã€‚è¿‘å¹´æ¥ï¼Œç ”ç©¶äººå‘˜å¼€å‘äº†ä¸€ç³»åˆ—æ–¹æ³•ï¼Œä½¿å¾—BNNå˜å¾—å¯å¤„ç†ï¼Œä»è€Œèƒ½å¤Ÿåœ¨æ›´å¤§ä¸”æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œæ¶æ„ä¸­å®ç°ã€‚
- en: 'In this chapter, weâ€™ll explore two particularly popular methods: **Probabilistic**
    **Backpropagation** (**PBP**) and **Bayes by Backprop** (**BBB**). Both methods
    can be referred to as *probabilistic neural network models*: neural networks designed
    to learn probabilities over their weights, rather than simply learning point estimates
    (a fundamental defining feature of BNNs, as we learned in [*ChapterÂ 4*](CH4.xhtml#x1-490004),
    [*Introducing Bayesian Deep Learning*](CH4.xhtml#x1-490004)). Because they explicitly
    learn distributions over the weights at training time, we refer to them as *principled*
    methods; in contrast to the methods weâ€™ll explore in the next chapter, which more
    loosely approximate Bayesian inference with neural networks. Weâ€™ll cover these
    topics in the following sections of this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸¤ç§ç‰¹åˆ«æµè¡Œçš„æ–¹æ³•ï¼š**æ¦‚ç‡åå‘ä¼ æ’­**ï¼ˆ**PBP**ï¼‰å’Œ**è´å¶æ–¯åå‘ä¼ æ’­**ï¼ˆ**BBB**ï¼‰ã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½å¯ä»¥ç§°ä¸º*æ¦‚ç‡ç¥ç»ç½‘ç»œæ¨¡å‹*ï¼šæ—¨åœ¨å­¦ä¹ å…¶æƒé‡çš„æ¦‚ç‡ï¼Œè€Œä¸ä»…ä»…æ˜¯å­¦ä¹ ç‚¹ä¼°è®¡ï¼ˆè¿™æ˜¯BNNçš„ä¸€ä¸ªåŸºæœ¬ç‰¹å¾ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨[*ç¬¬4ç« *](CH4.xhtml#x1-490004)ä¸­å­¦ä¹ çš„é‚£æ ·ï¼Œ[*ä»‹ç»è´å¶æ–¯æ·±åº¦å­¦ä¹ *](CH4.xhtml#x1-490004)ï¼‰ã€‚å› ä¸ºå®ƒä»¬åœ¨è®­ç»ƒæ—¶æ˜¾å¼åœ°å­¦ä¹ æƒé‡çš„åˆ†å¸ƒï¼Œæ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸º*åŸç†æ€§*æ–¹æ³•ï¼›ä¸æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç« æ¢è®¨çš„æ–¹æ³•ç›¸æ¯”ï¼Œåè€…æ›´åŠ å®½æ¾åœ°è¿‘ä¼¼è´å¶æ–¯æ¨æ–­ä¸ç¥ç»ç½‘ç»œçš„ç»“åˆã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„ä»¥ä¸‹éƒ¨åˆ†è®¨è®ºè¿™äº›ä¸»é¢˜ï¼š
- en: Explaining notation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¦å·è¯´æ˜
- en: Familiar probabilistic concepts from deep learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·±åº¦å­¦ä¹ ä¸­çš„å¸¸è§æ¦‚ç‡æ¦‚å¿µ
- en: Bayesian inference by backpropagation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡åå‘ä¼ æ’­çš„è´å¶æ–¯æ¨æ–­
- en: Implementing BBB with TensorFlow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨TensorFlowå®ç°BBB
- en: Scalable Bayesian deep learning with PBP
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨PBPçš„å¯æ‰©å±•è´å¶æ–¯æ·±åº¦å­¦ä¹ 
- en: Implementing PBP
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°PBP
- en: First, letâ€™s quickly review the technical requirements for this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¿«é€Ÿå›é¡¾ä¸€ä¸‹æœ¬ç« çš„æŠ€æœ¯è¦æ±‚ã€‚
- en: 5.1 Technical requirements
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 æŠ€æœ¯è¦æ±‚
- en: 'To complete the practical tasks in this chapter, you will need a Python 3.8
    environment with the Python SciPy stack and the following additional Python packages
    installed:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å®Œæˆæœ¬ç« çš„å®é™…ä»»åŠ¡ï¼Œä½ å°†éœ€è¦ä¸€ä¸ªå®‰è£…äº†Python 3.8ç¯å¢ƒä»¥åŠPython SciPyæ ˆå’Œä»¥ä¸‹é™„åŠ PythonåŒ…çš„ç¯å¢ƒï¼š
- en: TensorFlow 2.0
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 2.0
- en: TensorFlow Probability
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlowæ¦‚ç‡
- en: 'All of the code for this book can be found on the GitHub repository for the
    book: [https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦çš„æ‰€æœ‰ä»£ç éƒ½å¯ä»¥åœ¨æœ¬ä¹¦çš„GitHubä»“åº“ä¸­æ‰¾åˆ°ï¼š[https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference)ã€‚
- en: 5.2 Explaining notation
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 ç¬¦å·è¯´æ˜
- en: 'While weâ€™ve introduced much of the notation used throughout the book in the
    previous chapters, weâ€™ll be introducing more notation associated with BDL in the
    following chapters. As such, weâ€™ve provided an overview of the notation here for
    reference:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æˆ‘ä»¬åœ¨å‰å‡ ç« ä¸­ä»‹ç»äº†ä¹¦ä¸­ä½¿ç”¨çš„å¤§éƒ¨åˆ†ç¬¦å·ï¼Œä½†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸BDLç›¸å…³çš„æ›´å¤šç¬¦å·ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæä¾›äº†ç¬¦å·çš„æ¦‚è¿°ï¼Œä¾›å‚è€ƒï¼š
- en: '*Î¼*: The mean. To make it easy to cross-reference our chapter with the original
    Probabilistic Backpropagation paper, this is represented as *m* when discussing
    PBP.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Î¼*ï¼šå‡å€¼ã€‚ä¸ºäº†æ–¹ä¾¿å°†æœ¬ç« ä¸åŸå§‹çš„æ¦‚ç‡åå‘ä¼ æ’­è®ºæ–‡è¿›è¡Œäº¤å‰å¼•ç”¨ï¼Œè®¨è®ºPBPæ—¶ï¼Œè¿™ä¸ªç¬¦å·ç”¨*m*è¡¨ç¤ºã€‚'
- en: '*Ïƒ*: The standard deviation.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Ïƒ*ï¼šæ ‡å‡†å·®ã€‚'
- en: '*Ïƒ*Â²: The variance (meaning the square of the standard deviation). To make
    it easy to cross-reference our chapter with the paper, this is represented as
    *v* when discussing PBP.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Ïƒ*Â²ï¼šæ–¹å·®ï¼ˆå³æ ‡å‡†å·®çš„å¹³æ–¹ï¼‰ã€‚ä¸ºäº†æ–¹ä¾¿å°†æœ¬ç« ä¸è®ºæ–‡è¿›è¡Œäº¤å‰å¼•ç”¨ï¼Œåœ¨è®¨è®ºPBPæ—¶ï¼Œä½¿ç”¨*v*è¡¨ç¤ºã€‚'
- en: '**x**: A single vector input to our model. If considering multiple inputs,
    weâ€™ll use **X** to represent a matrix comprising multiple vector inputs.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**x**ï¼šè¾“å…¥æ¨¡å‹çš„å•ä¸€å‘é‡ã€‚å¦‚æœè€ƒè™‘å¤šä¸ªè¾“å…¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**X**è¡¨ç¤ºç”±å¤šä¸ªå‘é‡è¾“å…¥ç»„æˆçš„çŸ©é˜µã€‚'
- en: '**x**: An approximation of our input **x**.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**x**ï¼šæˆ‘ä»¬è¾“å…¥çš„è¿‘ä¼¼å€¼**x**ã€‚'
- en: '*y*: A single scalar target. When considering multiple targets, weâ€™ll use **y**
    to represent a vector of multiple scalar targets.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*ï¼šå•ä¸ªæ ‡é‡ç›®æ ‡ã€‚å½“è€ƒè™‘å¤šä¸ªç›®æ ‡æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **y** æ¥è¡¨ç¤ºå¤šä¸ªæ ‡é‡ç›®æ ‡çš„å‘é‡ã€‚'
- en: '*Å·*: A single scalar output from our model. When considering multiple outputs,
    weâ€™ll use **Å·** to represent a vector of multiple scalar outputs.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Å·*ï¼šæ¥è‡ªæˆ‘ä»¬æ¨¡å‹çš„å•ä¸ªæ ‡é‡è¾“å‡ºã€‚å½“è€ƒè™‘å¤šä¸ªè¾“å‡ºæ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **Å·** æ¥è¡¨ç¤ºå¤šä¸ªæ ‡é‡è¾“å‡ºçš„å‘é‡ã€‚'
- en: '**z**: The output of an intermediate layer of our model.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**z**ï¼šæˆ‘ä»¬æ¨¡å‹ä¸­é—´å±‚çš„è¾“å‡ºã€‚'
- en: '*P*: Some ideal or target distribution.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*ï¼šæŸä¸ªç†æƒ³æˆ–ç›®æ ‡åˆ†å¸ƒã€‚'
- en: '*Q*: An approximate distribution.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Q*ï¼šè¿‘ä¼¼åˆ†å¸ƒã€‚'
- en: '*KL*[*Q*âˆ¥*P*]: The KL preergence between our target distribution *P* and our
    approximate distribution *Q*.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*KL*[*Q*âˆ¥*P*]ï¼šæˆ‘ä»¬çš„ç›®æ ‡åˆ†å¸ƒ *P* å’Œè¿‘ä¼¼åˆ†å¸ƒ *Q* ä¹‹é—´çš„ KL æ•£åº¦ã€‚'
- en: 'â„’: The loss.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â„’ï¼šæŸå¤±ã€‚
- en: ': The expectation.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ï¼šæœŸæœ›ã€‚
- en: '*N*(*Î¼,Ïƒ*): A normal (or Gaussian) distribution parameterized by the mean *Î¼*
    and the standard deviation *Ïƒ*.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*N*(*Î¼,Ïƒ*)ï¼šä¸€ä¸ªç”±å‡å€¼ *Î¼* å’Œæ ‡å‡†å·® *Ïƒ* å‚æ•°åŒ–çš„æ­£æ€ï¼ˆæˆ–é«˜æ–¯ï¼‰åˆ†å¸ƒã€‚'
- en: '*ğœƒ*: A set of model parameters.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ğœƒ*ï¼šä¸€ç»„æ¨¡å‹å‚æ•°ã€‚'
- en: 'Î”: A gradient.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Î”ï¼šæ¢¯åº¦ã€‚
- en: '*âˆ‚*: A partial derivative.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*âˆ‚*ï¼šåå¯¼æ•°ã€‚'
- en: '*f*(): Some function (e.g. *y* = *f*(*x*) indicates that *y* is produced by
    applying function *f*() to input *x*).'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f*()ï¼šæŸä¸ªå‡½æ•°ï¼ˆä¾‹å¦‚ *y* = *f*(*x*) è¡¨ç¤º *y* æ˜¯é€šè¿‡å¯¹è¾“å…¥ *x* åº”ç”¨å‡½æ•° *f*() å¾—åˆ°çš„ï¼‰ã€‚'
- en: We will encounter different variations of this notation, using different subscripts
    or variable combinations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é‡åˆ°ä¸åŒå˜ä½“çš„ç¬¦å·ï¼Œä½¿ç”¨ä¸åŒçš„ä¸‹æ ‡æˆ–å˜é‡ç»„åˆã€‚
- en: 5.3 Familiar probabilistic concepts from deep learning
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 æ·±åº¦å­¦ä¹ ä¸­çš„å¸¸è§æ¦‚ç‡æ¦‚å¿µ
- en: While this book introduces many concepts that may be unfamiliar, you may find
    that some ideas discussed here are familiar. In particular, **Variational** **Inference**
    (**VI**) is something you may be familiar with due to its use in **Variational
    Autoencoders** (**VAEs**).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦ä»‹ç»äº†è®¸å¤šå¯èƒ½ä¸ç†Ÿæ‚‰çš„æ¦‚å¿µï¼Œä½†ä½ å¯èƒ½ä¼šå‘ç°è¿™é‡Œè®¨è®ºçš„ä¸€äº›æƒ³æ³•æ˜¯ä½ å·²ç»ç†Ÿæ‚‰çš„ã€‚ç‰¹åˆ«æ˜¯ï¼Œ**å˜åˆ†æ¨æ–­**ï¼ˆ**VI**ï¼‰å¯èƒ½å› ä¸ºåœ¨**å˜åˆ†è‡ªç¼–ç å™¨**ï¼ˆ**VAE**ï¼‰ä¸­çš„åº”ç”¨è€Œä¸ºä½ æ‰€ç†ŸçŸ¥ã€‚
- en: As a quick refresher, VAEs are generative models that learn encodings that can
    be used to generate plausible data. Much like standard autoencoders, VAEs comprise
    an encoder-decoder architecture.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¿«é€Ÿå›é¡¾ä¸€ä¸‹ï¼ŒVAE æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒå­¦ä¹ å¯ä»¥ç”¨äºç”Ÿæˆåˆç†æ•°æ®çš„ç¼–ç ã€‚ä¸æ ‡å‡†è‡ªç¼–ç å™¨ç±»ä¼¼ï¼ŒVAE ä¹Ÿé‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ã€‚
- en: '![PIC](img/file107.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file107.png)'
- en: 'FigureÂ 5.1: Illustration of autoencoder architecture'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5.1ï¼šè‡ªç¼–ç å™¨æ¶æ„çš„ç¤ºæ„å›¾
- en: With a standard autoencoder, the model learns a mapping from the encoder to
    the latent space, and then from the latent space to the decoder.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ ‡å‡†è‡ªç¼–ç å™¨ï¼Œæ¨¡å‹å­¦ä¹ ä»ç¼–ç å™¨åˆ°æ½œåœ¨ç©ºé—´çš„æ˜ å°„ï¼Œç„¶åä»æ½œåœ¨ç©ºé—´åˆ°è§£ç å™¨çš„æ˜ å°„ã€‚
- en: 'As we see here, our output is simply defined as **x** = *f*[*d*](**z**), where
    our encoding **z** is simply: **z** = *f*[*e*](**x**), where *f*[*e*]() and *f*[*d*]()
    are our encoder and decoder functions, respectively. If we want to generate new
    data using values in our latent space, we could simply inject some random values
    into the input of our decoder; bypassing the encoder and randomly sampling from
    our latent space:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬çš„è¾“å‡ºç®€å•åœ°å®šä¹‰ä¸º **x** = *f*[*d*](**z**)ï¼Œå…¶ä¸­æˆ‘ä»¬çš„ç¼–ç  **z** å®šä¹‰ä¸ºï¼š**z** = *f*[*e*](**x**)ï¼Œå…¶ä¸­
    *f*[*e*]() å’Œ *f*[*d*]() åˆ†åˆ«æ˜¯æˆ‘ä»¬çš„ç¼–ç å™¨å’Œè§£ç å™¨å‡½æ•°ã€‚å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨æ½œåœ¨ç©ºé—´ä¸­çš„å€¼ç”Ÿæˆæ–°æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‘è§£ç å™¨è¾“å…¥æ³¨å…¥ä¸€äº›éšæœºå€¼ï¼›ç»•è¿‡ç¼–ç å™¨ï¼Œç›´æ¥ä»æ½œåœ¨ç©ºé—´ä¸­éšæœºé‡‡æ ·ï¼š
- en: '![PIC](img/file108.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file108.png)'
- en: 'FigureÂ 5.2: Illustration of sampling from the latent space of a standard autoencoder'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5.2ï¼šä»æ ‡å‡†è‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ä¸­é‡‡æ ·çš„ç¤ºæ„å›¾
- en: The problem with this approach is that a standard autoencoder doesnâ€™t do a great
    job of learning the structure of the latent space. This means that while weâ€™re
    free to randomly sample points in this space, thereâ€™s no guarantee that those
    points will correspond to something that can be processed by the decoder to generate
    plausible data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•çš„é—®é¢˜åœ¨äºï¼Œæ ‡å‡†è‡ªç¼–ç å™¨åœ¨å­¦ä¹ æ½œåœ¨ç©ºé—´çš„ç»“æ„ä¸Šè¡¨ç°ä¸ä½³ã€‚è¿™æ„å‘³ç€ï¼Œè™½ç„¶æˆ‘ä»¬å¯ä»¥è‡ªç”±åœ°åœ¨è¯¥ç©ºé—´ä¸­éšæœºé‡‡æ ·ç‚¹ï¼Œä½†æ— æ³•ä¿è¯è¿™äº›ç‚¹èƒ½å¤Ÿè¢«è§£ç å™¨å¤„ç†ï¼Œç”Ÿæˆåˆç†çš„æ•°æ®ã€‚
- en: In a VAE, the latent space is modeled as a distribution. Therefore, what was
    **z** = *f*[*e*](**x**) becomes **z** â‰ˆğ’©(*Î¼*[x], *Ïƒ*[x]); that is to say, our
    latent space **z** now becomes a Gaussian distribution conditioned on our input
    **x**. Now, when we want to generate data using our trained network, we can do
    so simply by sampling from a normal distribution.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ VAE ä¸­ï¼Œæ½œåœ¨ç©ºé—´è¢«å»ºæ¨¡ä¸ºä¸€ä¸ªåˆ†å¸ƒã€‚å› æ­¤ï¼Œ**z** = *f*[*e*](**x**) å˜ä¸º **z** â‰ˆğ’©(*Î¼*[x], *Ïƒ*[x])ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬çš„æ½œåœ¨ç©ºé—´
    **z** ç°åœ¨å˜æˆäº†ä¸€ä¸ªæ¡ä»¶äºè¾“å…¥ **x** çš„é«˜æ–¯åˆ†å¸ƒã€‚ç°åœ¨ï¼Œå½“æˆ‘ä»¬æƒ³ä½¿ç”¨è®­ç»ƒå¥½çš„ç½‘ç»œç”Ÿæˆæ•°æ®æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·ã€‚
- en: 'To achieve this, we need to ensure that the latent space approximates a Gaussian
    distribution. To do so, we use the **Kullback-Leibler divergence** (or KL divergence)
    during training by incorporating it as a regularization term:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æ½œåœ¨ç©ºé—´è¿‘ä¼¼ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨**Kullback-Leibleræ•£åº¦**ï¼ˆæˆ–KLæ•£åº¦ï¼‰ï¼Œå¹¶å°†å…¶ä½œä¸ºæ­£åˆ™åŒ–é¡¹åŠ å…¥ï¼š
- en: '![ 2 â„’ = âˆ¥xâˆ’ Ë†x âˆ¥ + KL [Q âˆ¥P] ](img/file109.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 â„’ = âˆ¥xâˆ’ Ë†x âˆ¥ + KL [Q âˆ¥P] ](img/file109.jpg)'
- en: 'Here, *P* is our target distribution (in this case, a multivariate Gaussian
    distribution), which weâ€™re trying to approximate with *Q*, which is the distribution
    associated with our latent space, which in this case is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*P* æ˜¯æˆ‘ä»¬çš„ç›®æ ‡åˆ†å¸ƒï¼ˆåœ¨æ­¤æƒ…å†µä¸‹æ˜¯å¤šå˜é‡é«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œæˆ‘ä»¬æ­£è¯•å›¾ç”¨*Q*æ¥é€¼è¿‘å®ƒï¼Œ*Q*æ˜¯ä¸æˆ‘ä»¬æ½œåœ¨ç©ºé—´ç›¸å…³çš„åˆ†å¸ƒï¼Œåœ¨æ­¤æƒ…å†µä¸‹å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Q = z â‰ˆ ğ’© (Î¼,Ïƒ) ](img/file110.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![Q = z â‰ˆ ğ’© (Î¼,Ïƒ) ](img/file110.jpg)'
- en: 'So, our loss now becomes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæˆ‘ä»¬çš„æŸå¤±ç°åœ¨å˜ä¸ºï¼š
- en: '![â„’ = âˆ¥xâˆ’ Ë†x âˆ¥2 + KL [q(z|x)âˆ¥p(z )] ](img/file111.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![â„’ = âˆ¥xâˆ’ Ë†x âˆ¥2 + KL [q(z|x)âˆ¥p(z )] ](img/file111.jpg)'
- en: 'We can expand it as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å¦‚ä¸‹æ‰©å±•ï¼š
- en: '![â„’ = âˆ¥x âˆ’ Ë†xâˆ¥2 + KL [ğ’© (Î¼,Ïƒ)âˆ¥ğ’© (0,I)] ](img/file112.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![â„’ = âˆ¥x âˆ’ Ë†xâˆ¥2 + KL [ğ’© (Î¼,Ïƒ)âˆ¥ğ’© (0,I)] ](img/file112.jpg)'
- en: 'Here, *I* is the identity matrix. This will allow our latent space to converge
    on our Gaussian prior, while also minimizing the reconstruction loss. The KL divergence
    can additionally be rewritten as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*I* æ˜¯å•ä½çŸ©é˜µã€‚è¿™å°†ä½¿æˆ‘ä»¬çš„æ½œåœ¨ç©ºé—´èƒ½å¤Ÿæ”¶æ•›åˆ°æˆ‘ä»¬çš„é«˜æ–¯å…ˆéªŒï¼ŒåŒæ—¶æœ€å°åŒ–é‡æ„æŸå¤±ã€‚KLæ•£åº¦è¿˜å¯ä»¥é‡æ–°å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: '![KL [q(z|x )âˆ¥p (z)] =q (z|x) logq(z|x )âˆ’ q(z|x) log p(z) ](img/file113.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![KL [q(z|x )âˆ¥p (z)] =q (z|x) logq(z|x )âˆ’ q(z|x) log p(z) ](img/file113.jpg)'
- en: The terms on the right hand side of our equation here are the expectation (or
    mean) of log *q*(**z**|**x**) and log *p*(**z**). As we know from [*ChapterÂ 2*](CH2.xhtml#x1-250002),
    [*Fundamentals of* *Bayesian Inference*](CH2.xhtml#x1-250002) and [*ChapterÂ 4*](CH4.xhtml#x1-490004),
    [*Introducing Bayesian Deep Learning*](CH4.xhtml#x1-490004), we can obtain the
    the expectation of a given distribution by sampling. Thus, as we can see that
    all terms of our KL divergence are expectations computed with respect to our approximate
    distribution *q*(**z**|**x**), we can approximate our KL divergence by sampling
    from *q*(**z**|**x**), which is exactly what weâ€™re about to do!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ–¹ç¨‹å³ä¾§çš„é¡¹æ˜¯å¯¹æ•°*q*(**z**|**x**)å’Œå¯¹æ•°*p*(**z**)çš„æœŸæœ›ï¼ˆæˆ–å‡å€¼ï¼‰ã€‚æ­£å¦‚æˆ‘ä»¬ä»[*ç¬¬2ç« *](CH2.xhtml#x1-250002)ã€[*è´å¶æ–¯æ¨æ–­åŸºç¡€*](CH2.xhtml#x1-250002)å’Œ[*ç¬¬4ç« *](CH4.xhtml#x1-490004)ã€[*å¼•å…¥è´å¶æ–¯æ·±åº¦å­¦ä¹ *](CH4.xhtml#x1-490004)ä¸­äº†è§£åˆ°çš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é‡‡æ ·æ¥è·å¾—ç»™å®šåˆ†å¸ƒçš„æœŸæœ›ã€‚å› æ­¤ï¼Œæ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼ŒKLæ•£åº¦çš„æ‰€æœ‰é¡¹éƒ½æ˜¯ç›¸å¯¹äºæˆ‘ä»¬è¿‘ä¼¼åˆ†å¸ƒ*q*(**z**|**x**)è®¡ç®—çš„æœŸæœ›ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»*q*(**z**|**x**)ä¸­é‡‡æ ·æ¥è¿‘ä¼¼æˆ‘ä»¬çš„KLæ•£åº¦ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦åšçš„ï¼
- en: 'Now that our encoding is represented by the distribution shown in equation
    [5.3](#x1-63006r3), our neural network structure has to change. We need to learn
    the mean (*Î¼*) and standard deviation (*Ïƒ*) parameters of our distribution:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„ç¼–ç ç”±æ–¹ç¨‹[5.3](#x1-63006r3)ä¸­æ˜¾ç¤ºçš„åˆ†å¸ƒè¡¨ç¤ºï¼Œæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œç»“æ„å¿…é¡»å‘ç”Ÿå˜åŒ–ã€‚æˆ‘ä»¬éœ€è¦å­¦ä¹ æˆ‘ä»¬åˆ†å¸ƒçš„å‡å€¼ï¼ˆ*Î¼*ï¼‰å’Œæ ‡å‡†å·®ï¼ˆ*Ïƒ*ï¼‰å‚æ•°ï¼š
- en: '![PIC](img/file114.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file114.png)'
- en: 'FigureÂ 5.3: Illustration of autoencoder architecture with mean and standard
    deviation weights'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾5.3ï¼šå¸¦æœ‰å‡å€¼å’Œæ ‡å‡†å·®æƒé‡çš„è‡ªåŠ¨ç¼–ç å™¨æ¶æ„ç¤ºæ„å›¾
- en: The issue with constructing a VAE in this way is that our encoding *z* is now
    stochastic, rather than deterministic. This is a problem because we canâ€™t obtain
    a gradient for stochastic variables â€“ and if we canâ€™t obtain a gradient, we have
    nothing to backpropagate â€“ so we canâ€™t learn!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥è¿™ç§æ–¹å¼æ„å»ºVAEçš„é—®é¢˜åœ¨äºæˆ‘ä»¬çš„ç¼–ç *z*ç°åœ¨æ˜¯éšæœºçš„ï¼Œè€Œä¸æ˜¯ç¡®å®šæ€§çš„ã€‚è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬æ— æ³•ä¸ºéšæœºå˜é‡è·å¾—æ¢¯åº¦â€”â€”å¦‚æœæˆ‘ä»¬æ— æ³•è·å¾—æ¢¯åº¦ï¼Œå°±æ— æ³•è¿›è¡Œåå‘ä¼ æ’­â€”â€”å› æ­¤æˆ‘ä»¬æ— æ³•è¿›è¡Œå­¦ä¹ ï¼
- en: 'We can fix this using something called the **reparameterization trick**. The
    reparameterization trick involves modifying how we compute **z**. Instead of sampling
    **z** from our distribution parameters, we will define it as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ç§å«åš**é‡å‚æ•°åŒ–æŠ€å·§**çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚é‡å‚æ•°åŒ–æŠ€å·§æ¶‰åŠåˆ°ä¿®æ”¹æˆ‘ä»¬è®¡ç®—**z**çš„æ–¹å¼ã€‚æˆ‘ä»¬ä¸å†ä»åˆ†å¸ƒå‚æ•°ä¸­æŠ½æ ·**z**ï¼Œè€Œæ˜¯å°†å…¶å®šä¹‰ä¸ºå¦‚ä¸‹ï¼š
- en: '![z = Î¼ + Ïƒ âŠ™ ğœ– ](img/file115.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![z = Î¼ + Ïƒ âŠ™ ğœ– ](img/file115.jpg)'
- en: 'As you can see, weâ€™ve introduced a new variable, *ğœ–*, which is sampled from
    a Gaussian distribution with *Î¼* = 0 and *Ïƒ* = 1:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å˜é‡ï¼Œ*ğœ–*ï¼Œå®ƒæ˜¯ä»ä¸€ä¸ªå‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„ï¼š
- en: '![ğœ– = ğ’© (0,1) ](img/file116.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![ğœ– = ğ’© (0,1) ](img/file116.jpg)'
- en: 'Introducing *ğœ–* has allowed us to move the stochasticity out of our backpropagation
    path. With the stochasticity residing solely in *ğœ–*, weâ€™re able to backpropagate
    through our weights as normal:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¼•å…¥*ğœ–*ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†éšæœºæ€§ç§»å‡ºåå‘ä¼ æ’­è·¯å¾„ã€‚ç”±äºéšæœºæ€§ä»…å­˜åœ¨äº*ğœ–*ä¸­ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåƒæ­£å¸¸æƒ…å†µä¸€æ ·é€šè¿‡æƒé‡è¿›è¡Œåå‘ä¼ æ’­ï¼š
- en: '![PIC](img/file117.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file117.png)'
- en: 'FigureÂ 5.4: Illustration of typical VAE architecture with mean and standard
    deviation weights, having moved the sampling component out of the backpropagation
    path'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5.4ï¼šå…¸å‹ VAE æ¶æ„çš„ç¤ºæ„å›¾ï¼Œå…¶ä¸­åŒ…å«å‡å€¼å’Œæ ‡å‡†å·®æƒé‡ï¼Œå¹¶å°†é‡‡æ ·ç»„ä»¶ç§»å‡ºäº†åå‘ä¼ æ’­è·¯å¾„
- en: 'This means weâ€™re able to represent our encoding as a distribution while still
    being able to backpropagate the gradient of *z*: learning the parameters *Î¼* and
    *Ïƒ*, and using *ğœ–* to sample from the distribution. Being able to represent *z*
    as a distribution means weâ€™re able to use it to compute the KL divergence, allowing
    us to incorporate our regularization term in equation 5.1, which in turn allows
    our embedding to converge towards a Gaussian distribution during training.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æˆ‘ä»¬èƒ½å¤Ÿå°†ç¼–ç è¡¨ç¤ºä¸ºä¸€ä¸ªåˆ†å¸ƒï¼ŒåŒæ—¶ä»ç„¶èƒ½å¤Ÿåå‘ä¼ æ’­ *z* çš„æ¢¯åº¦ï¼šå­¦ä¹  *Î¼* å’Œ *Ïƒ* çš„å‚æ•°ï¼Œå¹¶ä½¿ç”¨ *ğœ–* ä»åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ã€‚èƒ½å¤Ÿå°†
    *z* è¡¨ç¤ºä¸ºåˆ†å¸ƒæ„å‘³ç€æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨å®ƒæ¥è®¡ç®— KL æ•£åº¦ï¼Œä»è€Œå°†æ­£åˆ™åŒ–é¡¹çº³å…¥æ–¹ç¨‹ 5.1ï¼Œè¿™åè¿‡æ¥åˆä½¿æˆ‘ä»¬çš„åµŒå…¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘é«˜æ–¯åˆ†å¸ƒæ”¶æ•›ã€‚
- en: These are the fundamental steps in variational learning, and are what turn our
    standard autoencoder into a VAE. But this isnâ€™t all about learning. Crucially
    for VAEs, because weâ€™ve learned a normally distributed latent space, we can now
    sample effectively from that latent space, enabling us to use our VAE to generate
    new data according to the data landscape learned during training. Unlike the brittle
    random sampling we had with a standard autoencoder, our VAE is now able to generate
    *plausible* data!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯å˜åˆ†å­¦ä¹ çš„åŸºæœ¬æ­¥éª¤ï¼Œå®ƒä»¬å°†æˆ‘ä»¬çš„æ ‡å‡†è‡ªç¼–ç å™¨è½¬å˜ä¸º VAEã€‚ä½†è¿™ä¸ä»…ä»…æ˜¯å…³äºå­¦ä¹ çš„ã€‚å¯¹äº VAE æ¥è¯´ï¼Œè‡³å…³é‡è¦çš„æ˜¯ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å­¦åˆ°äº†ä¸€ä¸ªæ­£æ€åˆ†å¸ƒçš„æ½œåœ¨ç©ºé—´ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä»è¿™ä¸ªæ½œåœ¨ç©ºé—´æœ‰æ•ˆåœ°è¿›è¡Œé‡‡æ ·ï¼Œä½¿å¾—æˆ‘ä»¬å¯ä»¥ä½¿ç”¨
    VAE æ ¹æ®è®­ç»ƒæœŸé—´å­¦åˆ°çš„æ•°æ®æ™¯è§‚ç”Ÿæˆæ–°æ•°æ®ã€‚ä¸æ ‡å‡†è‡ªç¼–ç å™¨ä¸­çš„è„†å¼±éšæœºé‡‡æ ·ä¸åŒï¼Œæˆ‘ä»¬çš„ VAE ç°åœ¨èƒ½å¤Ÿç”Ÿæˆ*åˆç†*çš„æ•°æ®ï¼
- en: To do this, we sample *ğœ–* from a normal distribution and multiply *Ïƒ* by this
    value. This gives us a sample of *z* to pass through our decoder, obtaining our
    generated data, **x**, at the output.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ · *ğœ–* å¹¶å°† *Ïƒ* ä¸è¯¥å€¼ç›¸ä¹˜ã€‚è¿™å°†ç»™æˆ‘ä»¬ä¸€ä¸ª *z* çš„æ ·æœ¬ï¼Œä¼ é€’ç»™è§£ç å™¨ï¼Œä»è€Œåœ¨è¾“å‡ºç«¯è·å¾—æˆ‘ä»¬ç”Ÿæˆçš„æ•°æ®ï¼Œ**x**ã€‚
- en: Now that weâ€™re familiar with the fundamentals of variational learning, in the
    next section weâ€™ll see how these principles can be applied to create BNNs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ç†Ÿæ‚‰äº†å˜åˆ†å­¦ä¹ çš„åŸºç¡€ï¼Œåœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å°†è¿™äº›åŸç†åº”ç”¨äºåˆ›å»º BNNã€‚
- en: 5.4 Bayesian inference by backpropagation
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 é€šè¿‡åå‘ä¼ æ’­è¿›è¡Œè´å¶æ–¯æ¨æ–­
- en: In their 2015 paper, *Weight Uncertainty in Neural Networks*, Charles Blundell
    and his colleagues at DeepMind introduced a method for using variational learning
    for Bayesian inference with neural networks. Their method, which learned the BNN
    parameters via standard backpropagation, was appropriately named **Bayes by Backprop**
    (**BBB**).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ 2015 å¹´çš„è®ºæ–‡ã€Šç¥ç»ç½‘ç»œä¸­çš„æƒé‡ä¸ç¡®å®šæ€§ã€‹ä¸­ï¼ŒCharles Blundell åŠå…¶åœ¨ DeepMind çš„åŒäº‹ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨å˜åˆ†å­¦ä¹ è¿›è¡Œç¥ç»ç½‘ç»œè´å¶æ–¯æ¨æ–­çš„æ–¹æ³•ã€‚ä»–ä»¬çš„æ–¹æ³•é€šè¿‡æ ‡å‡†åå‘ä¼ æ’­æ¥å­¦ä¹ 
    BNN å‚æ•°ï¼Œå¹¶ä¸”è¿™ä¸ªæ–¹æ³•è¢«æ°å½“åœ°å‘½åä¸º**è´å¶æ–¯åå‘ä¼ æ’­**ï¼ˆ**BBB**ï¼‰ã€‚
- en: 'In the previous section, we saw how we can use variational learning to estimate
    the posterior distribution of our encoding, *z*, learning *P*(*z*|*x*). For BBB,
    weâ€™re going to be doing very much the same thing, except this time itâ€™s not just
    the encoding we care about. This time we want to learn the posterior distribution
    over all of the parameters (or weights) of our network: *P*(*ğœƒ*|*D*).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•ä½¿ç”¨å˜åˆ†å­¦ä¹ æ¥ä¼°è®¡æˆ‘ä»¬ç¼–ç çš„åéªŒåˆ†å¸ƒ *z*ï¼Œå­¦ä¹  *P*(*z*|*x*)ã€‚å¯¹äº BBBï¼Œæˆ‘ä»¬å°†åšéå¸¸ç±»ä¼¼çš„äº‹æƒ…ï¼Œåªæ˜¯è¿™ä¸€æ¬¡æˆ‘ä»¬ä¸ä»…ä»…å…³å¿ƒç¼–ç ã€‚æˆ‘ä»¬è¿™æ¬¡è¦å­¦ä¹ çš„æ˜¯æ‰€æœ‰å‚æ•°ï¼ˆæˆ–æƒé‡ï¼‰çš„åéªŒåˆ†å¸ƒï¼š*P*(*ğœƒ*|*D*)ã€‚
- en: 'You can think of this as having an entire network made up of VAE encoding layers,
    looking something like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å°†å…¶çœ‹ä½œæ˜¯ä¸€ä¸ªç”± VAE ç¼–ç å±‚ç»„æˆçš„æ•´ä¸ªç½‘ç»œï¼Œç±»ä¼¼äºä¸‹é¢è¿™æ ·ï¼š
- en: '![PIC](img/file118.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file118.png)'
- en: 'FigureÂ 5.5: Illustration of BBB'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5.5ï¼šBBB çš„ç¤ºæ„å›¾
- en: 'As such, itâ€™s logical that the learning strategy is also similar to that which
    we used for the VAE. We again use the principle of variational learning to learn
    parameters for *Q*, and approximation of the true distribution *P*, but this time
    weâ€™re looking for the parameters *ğœƒ*^(*â‹†*) that minimize this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå­¦ä¹ ç­–ç•¥ä¹Ÿä¸æˆ‘ä»¬ä¸º VAE ä½¿ç”¨çš„ç­–ç•¥ç±»ä¼¼ï¼Œè¿™æ˜¯åˆä¹é€»è¾‘çš„ã€‚æˆ‘ä»¬å†æ¬¡ä½¿ç”¨å˜åˆ†å­¦ä¹ çš„åŸç†æ¥å­¦ä¹  *Q* çš„å‚æ•°ï¼Œå¹¶è¿‘ä¼¼çœŸå®åˆ†å¸ƒ *P*ï¼Œä½†è¿™ä¸€æ¬¡æˆ‘ä»¬è¦å¯»æ‰¾çš„æ˜¯æœ€å°åŒ–ä»¥ä¸‹å†…å®¹çš„å‚æ•°
    *ğœƒ*^(*â‹†*)ï¼š
- en: '![ğœƒâ‹† = ğœƒ KL [q(w |ğœƒ)||P(w |D)] ](img/file119.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![ğœƒâ‹† = ğœƒ KL [q(w |ğœƒ)||P(w |D)] ](img/file119.jpg)'
- en: 'Here, *D* is our data, **w** is our network weights, and *ğœƒ* is the parameters
    of our distribution, e.g. *Î¼* and *Ïƒ* in the case of a Gaussian distribution.
    To do this we make use of an important cost function in Bayesian learning: the
    **Evidence Lower** **Bound**^([1](#footnote1)) , or **ELBO** (also referred to
    as the variational free energy). We denote this with the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*D* æ˜¯æˆ‘ä»¬çš„æ•°æ®ï¼Œ**w** æ˜¯æˆ‘ä»¬çš„ç½‘ç»œæƒé‡ï¼Œ*ğœƒ* æ˜¯æˆ‘ä»¬çš„åˆ†å¸ƒå‚æ•°ï¼Œä¾‹å¦‚åœ¨é«˜æ–¯åˆ†å¸ƒä¸­ï¼Œ*Î¼* å’Œ *Ïƒ* æ˜¯å‚æ•°ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è´å¶æ–¯å­¦ä¹ ä¸­çš„ä¸€ä¸ªé‡è¦æˆæœ¬å‡½æ•°ï¼š**è¯æ®ä¸‹ç•Œ**ï¼ˆ**ELBO**ï¼Œä¹Ÿå«å˜åˆ†è‡ªç”±èƒ½ï¼‰ã€‚æˆ‘ä»¬ç”¨ä»¥ä¸‹å…¬å¼è¡¨ç¤ºï¼š
- en: '![â„’(D,ğœƒ ) = KL [q(w |ğœƒ)||P (w)]âˆ’ q(w |ğœƒ) [log P(D |w)] ](img/file120.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![â„’(D,ğœƒ ) = KL [q(w |ğœƒ)||P (w)]âˆ’ q(w |ğœƒ) [log P(D |w)] ](img/file120.jpg)'
- en: 'This looks rather complicated, but itâ€™s really just a generalization of what
    we saw in equation 5.4\. We can break it down as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœ‹èµ·æ¥ç›¸å½“å¤æ‚ï¼Œä½†å…¶å®å®ƒåªæ˜¯æˆ‘ä»¬åœ¨æ–¹ç¨‹ 5.4 ä¸­çœ‹åˆ°çš„å†…å®¹çš„ä¸€ç§æ¦‚æ‹¬ã€‚æˆ‘ä»¬å¯ä»¥æŒ‰ä»¥ä¸‹æ–¹å¼è¿›è¡Œæ‹†è§£ï¼š
- en: On the left-hand side, we have the KL divergence between our prior *P*(**w**)
    and our approximate distribution *q*(**w**|*ğœƒ*). This is similar to what we saw
    in equations 5.1-5.4 in the previous section. Incorporating the KL divergence
    in our loss allows us to tune our parameters *ğœƒ* such that our approximate distribution
    converges on our prior distribution.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å·¦è¾¹ï¼Œæˆ‘ä»¬æœ‰å…ˆéªŒ *P*(**w**) å’Œè¿‘ä¼¼åˆ†å¸ƒ *q*(**w**|*ğœƒ*) ä¹‹é—´çš„ KL æ•£åº¦ã€‚è¿™ä¸æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚çš„æ–¹ç¨‹ 5.1-5.4 ä¸­çœ‹åˆ°çš„å†…å®¹ç±»ä¼¼ã€‚åœ¨æŸå¤±ä¸­åŠ å…¥
    KL æ•£åº¦ä½¿å¾—æˆ‘ä»¬å¯ä»¥è°ƒæ•´å‚æ•° *ğœƒ*ï¼Œä½¿å¾—æˆ‘ä»¬çš„è¿‘ä¼¼åˆ†å¸ƒæ”¶æ•›åˆ°å…ˆéªŒåˆ†å¸ƒã€‚
- en: On the right-hand side, we have the expectation of the negative log-likelihood
    of our data *D* given our neural network weights **w** with respect to the variational
    distribution. Minimizing this (because itâ€™s the *negative log-likelihood*) ensures
    that we learn parameters that maximize the likelihood of our data given our weights;
    our network learns to map our inputs to our outputs.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å³è¾¹ï¼Œæˆ‘ä»¬æœ‰å…³äºç»™å®šç¥ç»ç½‘ç»œæƒé‡ **w** å’Œå˜åˆ†åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œæ•°æ® *D* çš„è´Ÿå¯¹æ•°ä¼¼ç„¶çš„æœŸæœ›å€¼ã€‚æœ€å°åŒ–è¿™ä¸ªï¼ˆå› ä¸ºå®ƒæ˜¯*è´Ÿå¯¹æ•°ä¼¼ç„¶*ï¼‰å¯ä»¥ç¡®ä¿æˆ‘ä»¬å­¦ä¹ åˆ°çš„å‚æ•°èƒ½æœ€å¤§åŒ–ç»™å®šæƒé‡æƒ…å†µä¸‹æ•°æ®çš„ä¼¼ç„¶ï¼›æˆ‘ä»¬çš„ç½‘ç»œå­¦ä¼šå°†è¾“å…¥æ˜ å°„åˆ°è¾“å‡ºã€‚
- en: 'Just as with VAEs, BBB makes use of the reparameterization trick to allow us
    to backpropagate gradients through our network parameters. Also as before, we
    sample from our distribution. Taking the form of the KL divergence introduced
    in equation 5.5, our loss becomes as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒ VAE ä¸€æ ·ï¼ŒBBB ä½¿ç”¨äº†é‡å‚æ•°åŒ–æŠ€å·§ï¼Œä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡ç½‘ç»œå‚æ•°åå‘ä¼ æ’­æ¢¯åº¦ã€‚å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬ä»åˆ†å¸ƒä¸­é‡‡æ ·ã€‚æ ¹æ®æ–¹ç¨‹ 5.5 ä¸­å¼•å…¥çš„ KL æ•£åº¦å½¢å¼ï¼Œæˆ‘ä»¬çš„æŸå¤±å‡½æ•°å˜ä¸ºå¦‚ä¸‹ï¼š
- en: '![ âˆ‘N â„’ (D,ğœƒ) â‰ˆ logq(wi |ğœƒ)âˆ’ log P(wi) âˆ’ log P(D |wi) i=1 ](img/file121.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘N â„’ (D,ğœƒ) â‰ˆ logq(wi |ğœƒ)âˆ’ log P(wi) âˆ’ log P(D |wi) i=1 ](img/file121.jpg)'
- en: '*N* is the number of samples, and *i* denotes a particular sample. While weâ€™ll
    be using Gaussian priors here, an interesting property of this approach is that
    it can be applied to a wide range of distributions.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*N* æ˜¯æ ·æœ¬çš„æ•°é‡ï¼Œ*i* è¡¨ç¤ºæŸä¸ªç‰¹å®šæ ·æœ¬ã€‚è™½ç„¶æˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„æ˜¯é«˜æ–¯å…ˆéªŒï¼Œä½†è¿™ä¸ªæ–¹æ³•çš„ä¸€ä¸ªæœ‰è¶£ç‰¹ç‚¹æ˜¯ï¼Œå®ƒå¯ä»¥åº”ç”¨äºå„ç§åˆ†å¸ƒã€‚'
- en: 'The next step is to use our weight samples to train our network:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥æ˜¯ä½¿ç”¨æˆ‘ä»¬çš„æƒé‡æ ·æœ¬æ¥è®­ç»ƒç½‘ç»œï¼š
- en: 'First, just as with VAEs, we sample *ğœ–* from a Gaussian distribution:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œå°±åƒåœ¨ VAE ä¸­ä¸€æ ·ï¼Œæˆ‘ä»¬ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ · *ğœ–*ï¼š
- en: '![ğœ– â‰ˆ ğ’© (0,I) ](img/file122.jpg)'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ğœ– â‰ˆ ğ’© (0,I) ](img/file122.jpg)'
- en: 'Next, we apply *ğœ–* to the weights in a particular layer, just as with our VAE
    encoding:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°† *ğœ–* åº”ç”¨äºæŸä¸€å±‚çš„æƒé‡ï¼Œå°±åƒåœ¨ VAE ç¼–ç ä¸­ä¸€æ ·ï¼š
- en: '![w = Î¼ + log(1 + exp(Ï))âŠ™ ğœ– ](img/file123.jpg)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![w = Î¼ + log(1 + exp(Ï))âŠ™ ğœ– ](img/file123.jpg)'
- en: Note that in BBB, *Ïƒ* is parameterized as *Ïƒ* = log(1 + exp(*Ï*)). This ensures
    that it is always non-negative (because a standard deviation cannot be negative!).
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨ BBB ä¸­ï¼Œ*Ïƒ* è¢«å‚æ•°åŒ–ä¸º *Ïƒ* = log(1 + exp(*Ï*))ã€‚è¿™ç¡®ä¿äº†å®ƒå§‹ç»ˆæ˜¯éè´Ÿçš„ï¼ˆå› ä¸ºæ ‡å‡†å·®ä¸èƒ½æ˜¯è´Ÿæ•°ï¼ï¼‰ã€‚
- en: 'With our parameters *ğœƒ* = (*Î¼,Ï*), we define our loss, following equation 3.10,
    as follows:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æˆ‘ä»¬çš„å‚æ•° *ğœƒ* = (*Î¼,Ï*)ï¼Œæˆ‘ä»¬æ ¹æ®æ–¹ç¨‹ 3.10 å®šä¹‰æˆ‘ä»¬çš„æŸå¤±å‡½æ•°å¦‚ä¸‹ï¼š
- en: '![f(w, ğœƒ) = logq(w |ğœƒ )âˆ’ log P (w )P (D |w ) ](img/file124.jpg)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![f(w, ğœƒ) = logq(w |ğœƒ )âˆ’ log P (w )P (D |w ) ](img/file124.jpg)'
- en: 'Because our neural network is made up of weights for both means and standard
    deviations, we need to calculate the gradients for them separately. We first calculate
    the gradient with respect to the mean, *Î¼*:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œåŒ…å«å‡å€¼å’Œæ ‡å‡†å·®çš„æƒé‡ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åˆ†åˆ«è®¡ç®—å®ƒä»¬çš„æ¢¯åº¦ã€‚æˆ‘ä»¬é¦–å…ˆè®¡ç®—ç›¸å¯¹äºå‡å€¼ *Î¼* çš„æ¢¯åº¦ï¼š
- en: '![ âˆ‚f(w,-ğœƒ) âˆ‚f-(w,ğœƒ) Î” Î¼ = âˆ‚w + âˆ‚Î¼ ](img/file125.jpg)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ âˆ‚f(w,-ğœƒ) âˆ‚f-(w,ğœƒ) Î” Î¼ = âˆ‚w + âˆ‚Î¼ ](img/file125.jpg)'
- en: 'Then we calculate the gradient with respect to the standard deviation parameter,
    *Ï*:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è®¡ç®—ç›¸å¯¹äºæ ‡å‡†å·®å‚æ•° *Ï* çš„æ¢¯åº¦ï¼š
- en: '![ âˆ‚f(w, ğœƒ) ğœ– âˆ‚f (w, ğœƒ) Î” Ï = --------------------+ -------- âˆ‚w 1 + exp(âˆ’ Ï)
    âˆ‚Ï ](img/file126.jpg)'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ âˆ‚f(w, ğœƒ) ğœ– âˆ‚f (w, ğœƒ) Î” Ï = --------------------+ -------- âˆ‚w 1 + exp(âˆ’ Ï)
    âˆ‚Ï ](img/file126.jpg)'
- en: 'Now we have all the components necessary to update our weights via backpropagation,
    in a similar fashion to a typical neural network, except we update our mean and
    variance weights with their respective gradients:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å…·å¤‡äº†é€šè¿‡åå‘ä¼ æ’­æ›´æ–°æƒé‡æ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶ï¼Œè¿™ä¸å…¸å‹çš„ç¥ç»ç½‘ç»œç±»ä¼¼ï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨å„è‡ªçš„æ¢¯åº¦æ›´æ–°å‡å€¼å’Œæ–¹å·®æƒé‡ï¼š
- en: '![Î¼ â† Î¼ âˆ’ Î± Î”Î¼ ](img/file127.jpg)![Ï â† Ï âˆ’ Î±Î” Ï ](img/file128.jpg)'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Î¼ â† Î¼ âˆ’ Î± Î”Î¼ ](img/file127.jpg)![Ï â† Ï âˆ’ Î±Î” Ï ](img/file128.jpg)'
- en: You may have noticed that the first terms of the gradient computations in equations
    5.14 and 5.15 are the gradients you would compute for backpropagation of a typical
    neural network; weâ€™re simply augmenting these gradients with *Î¼*- and *Ï*-specific
    update rules.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½æ³¨æ„åˆ°ï¼Œåœ¨æ–¹ç¨‹5.14å’Œ5.15ä¸­çš„æ¢¯åº¦è®¡ç®—çš„ç¬¬ä¸€é¡¹ï¼Œæ­£æ˜¯ä½ ä¼šä¸ºå…¸å‹ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­è®¡ç®—çš„æ¢¯åº¦ï¼›æˆ‘ä»¬åªæ˜¯é€šè¿‡*Î¼*å’Œ*Ï*ç‰¹å®šçš„æ›´æ–°è§„åˆ™å¢å¼ºäº†è¿™äº›æ¢¯åº¦ã€‚
- en: 'While that was fairly heavy in terms of mathematical content, we can break
    it down into a few simple concepts:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™éƒ¨åˆ†å†…å®¹åœ¨æ•°å­¦æ–¹é¢ç›¸å¯¹è¾ƒé‡ï¼Œä½†æˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†è§£ä¸ºå‡ ä¸ªç®€å•çš„æ¦‚å¿µï¼š
- en: Just as with the encoding in VAEs, we are working with weights that represent
    the mean and standard deviation of a multivariate distribution, except this time
    they make up our entire network, not just the encoding layer.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ä¸­çš„ç¼–ç ç±»ä¼¼ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨è¡¨ç¤ºå¤šå…ƒåˆ†å¸ƒå‡å€¼å’Œæ ‡å‡†å·®çš„æƒé‡ï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œè¿™æ¬¡è¿™äº›æƒé‡æ„æˆäº†æ•´ä¸ªç½‘ç»œï¼Œè€Œä¸ä»…ä»…æ˜¯ç¼–ç å±‚ã€‚
- en: 'Because of this, we again use a loss that incorporates the KL divergence: weâ€™re
    looking to maximize the ELBO.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å†æ¬¡ä½¿ç”¨ä¸€ä¸ªåŒ…å«KLæ•£åº¦çš„æŸå¤±å‡½æ•°ï¼šæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ELBOã€‚
- en: As we are dealing with mean and standard deviation weights, we update these
    separately with update rules that use the gradients for the respective set of
    weights.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ­£åœ¨å¤„ç†å‡å€¼å’Œæ ‡å‡†å·®æƒé‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ›´æ–°è§„åˆ™åˆ†åˆ«æ›´æ–°å®ƒä»¬ï¼Œè§„åˆ™ä½¿ç”¨çš„æ˜¯å„è‡ªæƒé‡é›†çš„æ¢¯åº¦ã€‚
- en: Now that we understand the core principles behind BBB, weâ€™re ready to see how
    it all comes together in code!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ç†è§£äº†BBBèƒŒåçš„æ ¸å¿ƒåŸç†ï¼Œå‡†å¤‡å¥½çœ‹çœ‹å®ƒå¦‚ä½•åœ¨ä»£ç ä¸­å®ç°ï¼
- en: 5.5 Implementing BBB with TensorFlow
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 ä½¿ç”¨TensorFlowå®ç°BBB
- en: In this section, weâ€™ll see how to implement BBB in TensorFlow. Some of the code
    youâ€™ll see will be familiar; the core concepts of layers, loss functions, and
    optimizers will be very similar to what we covered in *Chapter 3, Fundamentals
    of* *Deep Learning*. Unlike the examples in [*ChapterÂ 3*](CH3.xhtml#x1-350003),
    [*Fundamentals of Deep* *Learning*](CH3.xhtml#x1-350003), weâ€™ll see how we can
    create neural networks capable of probabilistic inference.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åœ¨TensorFlowä¸­å®ç°BBBã€‚ä½ å°†çœ‹åˆ°ä¸€äº›ä½ å·²ç»ç†Ÿæ‚‰çš„ä»£ç ï¼›å±‚ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨çš„æ ¸å¿ƒæ¦‚å¿µä¸æˆ‘ä»¬åœ¨*ç¬¬3ç«  æ·±åº¦å­¦ä¹ åŸºç¡€*ä¸­æ‰€æ¶µç›–çš„éå¸¸ç›¸ä¼¼ã€‚ä¸[*ç¬¬3ç« *](CH3.xhtml#x1-350003)ã€[*æ·±åº¦å­¦ä¹ åŸºç¡€*](CH3.xhtml#x1-350003)ä¸­çš„ä¾‹å­ä¸åŒï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åˆ›å»ºèƒ½å¤Ÿè¿›è¡Œæ¦‚ç‡æ¨æ–­çš„ç¥ç»ç½‘ç»œã€‚
- en: 'Step 1: Importing packages'
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬1æ­¥ï¼šå¯¼å…¥åŒ…
- en: 'We start by importing the relevant packages. Importantly, we will import `tensorflow-probability`,
    which will provide us with the layers of the network that replace the point-estimate
    with a distribution and implement the reparameterization trick. We also set the
    global parameter for the number of inferences, which will determine how often
    we sample from the network later:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆå¯¼å…¥ç›¸å…³åŒ…ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å°†å¯¼å…¥`tensorflow-probability`ï¼Œå®ƒå°†ä¸ºæˆ‘ä»¬æä¾›ç½‘ç»œçš„å±‚ï¼Œè¿™äº›å±‚ç”¨åˆ†å¸ƒæ›¿ä»£äº†ç‚¹ä¼°è®¡ï¼Œå¹¶å®ç°äº†é‡æ–°å‚æ•°åŒ–æŠ€å·§ã€‚æˆ‘ä»¬è¿˜è®¾ç½®äº†æ¨ç†æ¬¡æ•°çš„å…¨å±€å‚æ•°ï¼Œè¿™å°†å†³å®šç¨åæˆ‘ä»¬ä»ç½‘ç»œä¸­é‡‡æ ·çš„é¢‘ç‡ï¼š
- en: '[PRE0]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Step 2: Acquiring data'
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬2æ­¥ï¼šè·å–æ•°æ®
- en: 'We then download the MNIST Fashion dataset, which is a dataset that contains
    images of ten different clothing items. We also set the class names and derive
    the number of training examples and classes:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä¸‹è½½MNIST Fashionæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«åç§ä¸åŒè¡£ç‰©å›¾åƒçš„æ•°æ®é›†ã€‚æˆ‘ä»¬è¿˜è®¾ç½®äº†ç±»åˆ«åç§°ï¼Œå¹¶æ¨å¯¼å‡ºè®­ç»ƒæ ·æœ¬å’Œç±»åˆ«çš„æ•°é‡ï¼š
- en: '[PRE1]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 3: Helper functions'
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬3æ­¥ï¼šè¾…åŠ©å‡½æ•°
- en: Next, we create a helper function that defines our model. As you can see, we
    use a very simple convolutional neural network structure for image classification
    that consists of a convolutional layer, followed by a max-pooling layer and a
    fully connected layer. The convolutional layer and the dense layer are imported
    from the `tensorflow-probability` package, as indicated by the prefix *tfp*. Instead
    of defining point-estimates for the weights, they will define weight distributions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ã€‚å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªéå¸¸ç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œç»“æ„è¿›è¡Œå›¾åƒåˆ†ç±»ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªå·ç§¯å±‚ï¼Œéšåæ˜¯ä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚å’Œä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚å·ç§¯å±‚å’Œå…¨è¿æ¥å±‚æ¥è‡ª`tensorflow-probability`åŒ…ï¼Œå¦‚*tfp*å‰ç¼€æ‰€ç¤ºã€‚ä¸å®šä¹‰æƒé‡çš„ç‚¹ä¼°è®¡ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬å®šä¹‰çš„æ˜¯æƒé‡åˆ†å¸ƒã€‚
- en: 'As the names `Convolution2DReparameterization` and `DenseReparameterization`
    suggest, these layers will use the reparameterization trick to update the weight
    parameters during backpropagation:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚`Convolution2DReparameterization`å’Œ`DenseReparameterization`çš„åç§°æ‰€ç¤ºï¼Œè¿™äº›å±‚å°†ä½¿ç”¨é‡å‚æ•°åŒ–æŠ€å·§åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ›´æ–°æƒé‡å‚æ•°ï¼š
- en: '[PRE2]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We also create another helper function that compiles the model for us, using
    `Adam` as our optimizer and a categorical cross-entropy loss. Provided with this
    loss and the preceding network structure, `tensorflow-probability` will automatically
    add the Kullback-Leibler divergence that is contained in the convolutional and
    dense layers to the cross-entropy loss. This combination effectively amounts to
    calculating the ELBO loss that we described in equation 5.9:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜åˆ›å»ºäº†å¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥ä¸ºæˆ‘ä»¬ç¼–è¯‘æ¨¡å‹ï¼Œä½¿ç”¨`Adam`ä½œä¸ºä¼˜åŒ–å™¨å’Œåˆ†ç±»äº¤å‰ç†µæŸå¤±ã€‚æä¾›äº†è¿™ä¸ªæŸå¤±å’Œå‰è¿°çš„ç½‘ç»œç»“æ„åï¼Œ`tensorflow-probability`å°†è‡ªåŠ¨å°†åŒ…å«åœ¨å·ç§¯å’Œå¯†é›†å±‚ä¸­çš„KLæ•£åº¦æ·»åŠ åˆ°äº¤å‰ç†µæŸå¤±ä¸­ã€‚è¿™ç§ç»„åˆæœ‰æ•ˆåœ°ç›¸å½“äºè®¡ç®—æˆ‘ä»¬åœ¨æ–¹ç¨‹å¼5.9ä¸­æè¿°çš„ELBOæŸå¤±ï¼š
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Step 4: model training'
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4ï¼šæ¨¡å‹è®­ç»ƒ
- en: 'Before we can train the model, we first need to convert the labels of the training
    data from integers to one-hot vectors because this is what TensorFlow expects
    for the categorical cross-entropy loss. For example, if an image shows a t-shirt
    and the integer label for t-shirts is 1, then this label will be transformed like
    this: `[1,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0]`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å°†è®­ç»ƒæ•°æ®çš„æ ‡ç­¾ä»æ•´æ•°è½¬æ¢ä¸ºç‹¬çƒ­å‘é‡ï¼Œå› ä¸ºè¿™æ˜¯TensorFlowå¯¹äºåˆ†ç±»äº¤å‰ç†µæŸå¤±çš„æœŸæœ›ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€å¼ å›¾åƒæ˜¾ç¤ºä¸€ä»¶Tæ¤ï¼Œè€ŒTæ¤çš„æ•´æ•°æ ‡ç­¾ä¸º1ï¼Œåˆ™è¯¥æ ‡ç­¾å°†è¢«è½¬æ¢å¦‚ä¸‹ï¼š`[1,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0,``Â 0]`ï¼š
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we are ready to train our model on the training data. We will train for
    ten epochs:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡åœ¨è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†è®­ç»ƒåä¸ªepochï¼š
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Step 5: inference'
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 5ï¼šæ¨æ–­
- en: 'We can then use the trained model to perform inference on the test images.
    Here, we predict the class label for the first 50 images in the test split. For
    every image, we sample seven times from the network (as determined by `NUM_INFERENCES`),
    which will give us seven predictions for every image:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•å›¾åƒè¿›è¡Œæ¨æ–­ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¢„æµ‹æµ‹è¯•é›†ä¸­å‰ 50 å¼ å›¾åƒçš„ç±»æ ‡ç­¾ã€‚å¯¹äºæ¯å¼ å›¾åƒï¼Œæˆ‘ä»¬ä»ç½‘ç»œä¸­è¿›è¡Œä¸ƒæ¬¡é‡‡æ ·ï¼ˆç”±`NUM_INFERENCES`ç¡®å®šï¼‰ï¼Œè¿™å°†ä¸ºæ¯å¼ å›¾åƒç»™å‡ºä¸ƒä¸ªé¢„æµ‹ï¼š
- en: '[PRE6]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And thatâ€™s it: we have a working BBB model! Letâ€™s visualize the first image
    in the test split and the seven different predictions for that image. First, we
    obtain the class predictions:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼šæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¯ç”¨çš„BBBæ¨¡å‹ï¼è®©æˆ‘ä»¬å¯è§†åŒ–æµ‹è¯•é›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒä»¥åŠè¯¥å›¾åƒçš„ä¸ƒä¸ªä¸åŒé¢„æµ‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è·å–ç±»åˆ«é¢„æµ‹ï¼š
- en: '[PRE7]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we visualize the image along with the predicted class for every inference:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯è§†åŒ–å›¾åƒä»¥åŠæ¯æ¬¡æ¨æ–­çš„é¢„æµ‹ç±»åˆ«ï¼š
- en: '[PRE8]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Looking at the image in *Figure* [*5.7*](#x1-70136r7), on most samples the network
    predicts Ankle boot (which is the correct class). For two of the samples, the
    network also predicted Sneaker, which is somewhat plausible given the image is
    showing a shoe.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹*Figure* [*5.7*](#x1-70136r7)ä¸­çš„å›¾åƒï¼Œåœ¨å¤§å¤šæ•°æ ·æœ¬ä¸­ï¼Œç½‘ç»œé¢„æµ‹ä¸ºâ€œè¸é´â€ï¼ˆè¿™æ˜¯æ­£ç¡®çš„ç±»åˆ«ï¼‰ã€‚åœ¨ä¸¤ä¸ªæ ·æœ¬ä¸­ï¼Œç½‘ç»œè¿˜é¢„æµ‹ä¸ºâ€œè¿åŠ¨é‹â€ï¼Œè¿™åœ¨å›¾åƒæ˜¾ç¤ºé‹ç±»æ—¶ä¹Ÿæ˜¯åˆç†çš„ã€‚
- en: '![PIC](img/file129.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file129.png)'
- en: 'FigureÂ 5.6: Class predictions across the seven different samples from the network
    trained with the BBB approach on the first test image in the MNIST fashion dataset'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾Â 5.6ï¼šæ¥è‡ªé‡‡ç”¨BBBæ–¹æ³•è®­ç»ƒçš„ç½‘ç»œçš„ä¸ƒä¸ªä¸åŒæ ·æœ¬ä¸­çš„ç¬¬ä¸€å¼ æµ‹è¯•å›¾åƒçš„ç±»é¢„æµ‹
- en: 'Given that we now have seven predictions per image, we can also calculate the
    mean variance across these predictions to approximate an uncertainty value:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æ¯å¼ å›¾åƒæœ‰äº†ä¸ƒä¸ªé¢„æµ‹ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®¡ç®—è¿™äº›é¢„æµ‹ä¹‹é—´çš„å¹³å‡æ–¹å·®ï¼Œä»¥è¿‘ä¼¼ä¸ç¡®å®šæ€§å€¼ï¼š
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For example, the uncertainty value for the first test image in the MNIST fashion
    dataset is 0*.*0000002\. To put this uncertainty value into context, letâ€™s load
    some images from the regular MNIST dataset, which contains handwritten digits
    between 0 and 9, and obtain uncertainty values from the model we have trained.
    We load the dataset and then perform inference again and obtain the uncertainty
    values:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ—¶è£…MNISTæ•°æ®é›†ä¸­ç¬¬ä¸€å¼ æµ‹è¯•å›¾åƒçš„ä¸ç¡®å®šæ€§å€¼ä¸º0*.*0000002ã€‚ä¸ºäº†å°†æ­¤ä¸ç¡®å®šæ€§å€¼ç½®äºä¸Šä¸‹æ–‡ä¸­ï¼Œè®©æˆ‘ä»¬ä»å¸¸è§„MNISTæ•°æ®é›†åŠ è½½ä¸€äº›å›¾åƒï¼Œå…¶ä¸­åŒ…å«ä»‹äº0åˆ°9ä¹‹é—´çš„æ‰‹å†™æ•°å­—ï¼Œå¹¶ä»æˆ‘ä»¬è®­ç»ƒè¿‡çš„æ¨¡å‹ä¸­è·å–ä¸ç¡®å®šæ€§å€¼ã€‚æˆ‘ä»¬åŠ è½½æ•°æ®é›†ï¼Œç„¶åå†æ¬¡è¿›è¡Œæ¨æ–­å¹¶è·å–ä¸ç¡®å®šæ€§å€¼ï¼š
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We can then visualize and compare the uncertainty values between the first 50
    images in the fashion MNIST dataset and the regular MNIST dataset.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å¯è§†åŒ–æ¯”è¾ƒæ—¶è£…MNISTæ•°æ®é›†ä¸­å‰ 50 å¼ å›¾åƒå’Œå¸¸è§„MNISTæ•°æ®é›†ä¹‹é—´çš„ä¸ç¡®å®šæ€§å€¼ã€‚
- en: In *Figure* [*5.7*](#x1-70136r7), we see that uncertainty values are a lot greater
    for images from the regular MNIST dataset than for the fashion MNIST dataset.
    This is expected, given that our model has only seen fashion MNIST images during
    training and the handwritten digits from the regular MNIST dataset are out-of-distribution
    for the model we trained.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ *å›¾* [*5.7*](#x1-70136r7) ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¥è‡ªå¸¸è§„ MNIST æ•°æ®é›†çš„å›¾åƒçš„ä¸ç¡®å®šæ€§å€¼è¿œé«˜äºæ—¶å°š MNIST æ•°æ®é›†çš„å›¾åƒã€‚è¿™æ˜¯é¢„æœŸä¸­çš„æƒ…å†µï¼Œå› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒæ—¶åªçœ‹åˆ°äº†æ—¶å°š
    MNIST å›¾åƒï¼Œè€Œå¸¸è§„ MNIST æ•°æ®é›†ä¸­çš„æ‰‹å†™æ•°å­—å¯¹äºæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹æ¥è¯´æ˜¯è¶…å‡ºåˆ†å¸ƒçš„ã€‚
- en: '![PIC](img/file130.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file130.png)'
- en: 'FigureÂ 5.7: Uncertainty values for images in the fashion MNIST dataset (left)
    versus the regular MNIST dataset (right)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5.7ï¼šæ—¶å°š MNIST æ•°æ®é›†ï¼ˆå·¦ï¼‰ä¸å¸¸è§„ MNIST æ•°æ®é›†ï¼ˆå³ï¼‰ä¸­å›¾åƒçš„ä¸ç¡®å®šæ€§å€¼
- en: BBB is perhaps the most commonly encountered highly principled Bayesian deep
    learning method, but it isnâ€™t the only option for those concerned with better
    principled methods. In the next section, weâ€™ll introduce another highly principled
    method and learn about the properties that differentiate it from BBB.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: BBB å¯èƒ½æ˜¯æœ€å¸¸é‡åˆ°çš„é«˜åº¦åŸåˆ™åŒ–çš„è´å¶æ–¯æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä½†å¯¹äºé‚£äº›å…³æ³¨æ›´å¥½åŸåˆ™æ€§æ–¹æ³•çš„äººæ¥è¯´ï¼Œå®ƒå¹¶ä¸æ˜¯å”¯ä¸€çš„é€‰æ‹©ã€‚åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦ä¸€ç§é«˜åº¦åŸåˆ™åŒ–çš„æ–¹æ³•ï¼Œå¹¶äº†è§£å®ƒä¸
    BBB çš„åŒºåˆ«ã€‚
- en: 5.6 Scalable Bayesian Deep Learning with Probabilistic Backpropagation
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 å¯æ‰©å±•çš„è´å¶æ–¯æ·±åº¦å­¦ä¹ ä¸æ¦‚ç‡åå‘ä¼ æ’­
- en: 'BBB provided a great introduction to Bayesian inference with neural networks,
    but variational methods have one key drawback: their reliance on sampling at training
    and inference time. Unlike a standard neural network, we need to sample from the
    weight parameters using a range of *ğœ–* values in order to produce the distributions
    necessary for probabilistic training and inference.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: BBB ä¸ºè´å¶æ–¯æ¨æ–­ä¸ç¥ç»ç½‘ç»œçš„ç»“åˆæä¾›äº†å¾ˆå¥½çš„ä»‹ç»ï¼Œä½†å˜åˆ†æ–¹æ³•æœ‰ä¸€ä¸ªå…³é”®çš„ç¼ºç‚¹ï¼šå®ƒä»¬ä¾èµ–äºè®­ç»ƒå’Œæ¨ç†æ—¶çš„é‡‡æ ·ã€‚ä¸æ ‡å‡†ç¥ç»ç½‘ç»œä¸åŒï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ç³»åˆ—
    *ğœ–* å€¼ä»æƒé‡å‚æ•°ä¸­è¿›è¡Œé‡‡æ ·ï¼Œä»¥ç”Ÿæˆè¿›è¡Œæ¦‚ç‡è®­ç»ƒå’Œæ¨ç†æ‰€éœ€çš„åˆ†å¸ƒã€‚
- en: 'At around the same time that BBB was introduced, researchers at Harvard University
    were working on their own brand of Bayesian inference with neural networks: **Probabilistic
    Backpropagation**, or **PBP**. Like BBB, PBPâ€™s weights form the parameters of
    a distribution, in this case mean and variance weights (using variance, *Ïƒ*Â²,
    rather than *Ïƒ*). In fact, the similarities donâ€™t end here â€“ weâ€™re going to see
    quite a few similarities to BBB but, crucially, weâ€™re going to end up with a different
    approach to BNN approximation with its own advantages and disadvantages. So, letâ€™s
    get started.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ BBB è¢«å¼•å…¥çš„åŒæ—¶ï¼Œå“ˆä½›å¤§å­¦çš„ç ”ç©¶äººå‘˜ä¹Ÿåœ¨ç ”ç©¶ä»–ä»¬è‡ªå·±çš„è´å¶æ–¯æ¨æ–­ä¸ç¥ç»ç½‘ç»œç›¸ç»“åˆçš„æ–¹æ³•ï¼š**æ¦‚ç‡åå‘ä¼ æ’­**ï¼Œæˆ–ç§° **PBP**ã€‚åƒ BBB
    ä¸€æ ·ï¼ŒPBP çš„æƒé‡ä¹Ÿæ„æˆäº†ä¸€ä¸ªåˆ†å¸ƒçš„å‚æ•°ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯å‡å€¼å’Œæ–¹å·®æƒé‡ï¼ˆä½¿ç”¨æ–¹å·® *Ïƒ*Â²ï¼Œè€Œä¸æ˜¯ *Ïƒ*ï¼‰ã€‚å®é™…ä¸Šï¼Œç›¸ä¼¼ä¹‹å¤„ä¸ä»…é™äºæ­¤â€”â€”æˆ‘ä»¬å°†çœ‹åˆ°è®¸å¤šä¸
    BBB ç›¸ä¼¼çš„åœ°æ–¹ï¼Œä½†å…³é”®æ˜¯ï¼Œæˆ‘ä»¬æœ€ç»ˆä¼šé‡‡ç”¨ä¸€ç§ä¸åŒçš„ BNN è¿‘ä¼¼æ–¹æ³•ï¼Œè¿™ç§æ–¹æ³•æœ‰å…¶ç‹¬ç‰¹çš„ä¼˜ç¼ºç‚¹ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚
- en: 'To make things simpler, and for parity with the various PBP papers, weâ€™ll stick
    with individual weights while we work through the core ideas of PBP. Hereâ€™s a
    visualization of how these weights are related in a small neural network:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œå¹¶ä¸å„ç§ PBP è®ºæ–‡ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬å°†åœ¨é˜è¿° PBP æ ¸å¿ƒæ€æƒ³æ—¶åšæŒä½¿ç”¨å•ä¸ªæƒé‡ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªå°å‹ç¥ç»ç½‘ç»œä¸­è¿™äº›æƒé‡å¦‚ä½•å…³è”çš„å¯è§†åŒ–ï¼š
- en: '![PIC](img/file131.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file131.png)'
- en: 'FigureÂ 5.8: Illustration of neural network weights in PBP'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5.8ï¼šPBP ä¸­ç¥ç»ç½‘ç»œæƒé‡çš„ç¤ºæ„å›¾
- en: 'Just as before, we see that our network is essentially built from two sub-networks:
    one for the mean weights, or *m*, and one for the variance weights, or *v*. The
    core idea behind PBP is that, for each weight, we have some distribution *P*(*w*|*D*)
    that weâ€™re trying to approximate:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä¹‹å‰æ‰€è§ï¼Œæˆ‘ä»¬çš„ç½‘ç»œæœ¬è´¨ä¸Šæ˜¯ç”±ä¸¤ä¸ªå­ç½‘ç»œç»„æˆï¼šä¸€ä¸ªç”¨äºå‡å€¼æƒé‡ï¼Œæˆ–è€…è¯´ *m*ï¼Œå¦ä¸€ä¸ªç”¨äºæ–¹å·®æƒé‡ï¼Œæˆ–è€…è¯´ *v*ã€‚PBP çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œå¯¹äºæ¯ä¸ªæƒé‡ï¼Œæˆ‘ä»¬éƒ½æœ‰ä¸€ä¸ªåˆ†å¸ƒ
    *P*(*w*|*D*)ï¼Œæˆ‘ä»¬æ­£åœ¨å°è¯•å¯¹å…¶è¿›è¡Œè¿‘ä¼¼ï¼š
- en: '![q(w) = ğ’© (w|m, v) ](img/file132.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![q(w) = ğ’© (w|m, v) ](img/file132.jpg)'
- en: This notation should be very familiar now, with *P*() being the true (intractable)
    distribution, and *q*() being the approximate distribution. In PBPâ€™s case, as
    demonstrated in equation 5.18, this is a Gaussian distribution parameterized by
    mean *m* and variance *v*.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç¬¦å·ç°åœ¨åº”è¯¥å¾ˆç†Ÿæ‚‰äº†ï¼Œå…¶ä¸­ *P*() æ˜¯çœŸå®ï¼ˆä¸å¯è§£ï¼‰åˆ†å¸ƒï¼Œ*q*() æ˜¯è¿‘ä¼¼åˆ†å¸ƒã€‚åœ¨ PBP ä¸­ï¼Œå¦‚å…¬å¼ 5.18 æ‰€ç¤ºï¼Œè¿™æ˜¯ç”±å‡å€¼ *m* å’Œæ–¹å·®
    *v* å‚æ•°åŒ–çš„é«˜æ–¯åˆ†å¸ƒã€‚
- en: In BBB, we saw how variational learning via the ELBO used the KL divergence
    to ensure our weight distribution converged towards our prior *P*(*w*). In PBP,
    we will again make use of the KL divergence, although this time weâ€™ll do it indirectly.
    The way that we achieve this is through the use of a process called **Assumed
    Density Filtering** (**ADF**).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ BBB ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å˜åˆ†å­¦ä¹ é€šè¿‡ ELBO ä½¿ç”¨ KL æ•£åº¦ç¡®ä¿æˆ‘ä»¬çš„æƒé‡åˆ†å¸ƒæ”¶æ•›åˆ°æˆ‘ä»¬çš„å…ˆéªŒ *P*(*w*)ã€‚åœ¨ PBP ä¸­ï¼Œæˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨ KL
    æ•£åº¦ï¼Œå°½ç®¡è¿™ä¸€æ¬¡æˆ‘ä»¬æ˜¯é—´æ¥åœ°å®ç°çš„ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä¸€ç§å«åš**å‡å®šå¯†åº¦æ»¤æ³¢**ï¼ˆ**ADF**ï¼‰çš„è¿‡ç¨‹æ¥å®ç°è¿™ä¸€ç‚¹ã€‚
- en: 'ADF was developed as a fast sequential method of minimizing the KL divergence
    between the true posterior *P*(*w*|*D*) and some approximation *q*(*w*|*D*). A
    key point here is the fact that it is a *sequential* algorithm: just like gradient
    descent, which we use with standard neural networks, ADF updates its parameters
    sequentially. This makes it particularly well suited for adapting to a neural
    network. The ADF algorithm can be described in two key steps:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ADF æ˜¯ä¸€ç§å¿«é€Ÿçš„é¡ºåºæ–¹æ³•ï¼Œç”¨äºæœ€å°åŒ–çœŸå®åéªŒ *P*(*w*|*D*) ä¸æŸä¸ªè¿‘ä¼¼ *q*(*w*|*D*) ä¹‹é—´çš„ KL æ•£åº¦ã€‚è¿™é‡Œçš„ä¸€ä¸ªå…³é”®ç‚¹æ˜¯å®ƒæ˜¯ä¸€ä¸ª*é¡ºåº*ç®—æ³•ï¼šå°±åƒæˆ‘ä»¬ä¸æ ‡å‡†ç¥ç»ç½‘ç»œä¸€èµ·ä½¿ç”¨çš„æ¢¯åº¦ä¸‹é™ä¸€æ ·ï¼ŒADF
    ä¹Ÿæ˜¯é¡ºåºåœ°æ›´æ–°å…¶å‚æ•°ã€‚è¿™ä½¿å¾—å®ƒç‰¹åˆ«é€‚åˆé€‚åº”ç¥ç»ç½‘ç»œã€‚ADF ç®—æ³•å¯ä»¥é€šè¿‡ä¸¤ä¸ªå…³é”®æ­¥éª¤æ¥æè¿°ï¼š
- en: Initialize our parameters, with *m* = 0 and *v* = 1; that is, we start with
    a unit Gaussian ğ’©(0*,*1).
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–æˆ‘ä»¬çš„å‚æ•°ï¼Œ*m* = 0ï¼Œ*v* = 1ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬ä»å•ä½é«˜æ–¯ ğ’©(0*,*1) å¼€å§‹ã€‚
- en: Next, we go through each data point *x*[*i*] âˆˆ **x** and update the parameters
    of our model using a set of specific update equations that update our model parameters
    *m* and *v* separately.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éå†æ¯ä¸ªæ•°æ®ç‚¹ *x*[*i*] âˆˆ **x**ï¼Œå¹¶ä½¿ç”¨ä¸€ç»„ç‰¹å®šçš„æ›´æ–°æ–¹ç¨‹æ›´æ–°æˆ‘ä»¬çš„æ¨¡å‹å‚æ•° *m* å’Œ *v*ï¼Œè¿™ä¸¤ä¸ªå‚æ•°åˆ†åˆ«è¿›è¡Œæ›´æ–°ã€‚
- en: While itâ€™s beyond the scope of this book to provide a full derivation of ADF,
    you should know that as we update our parameters through ADF, we also minimize
    the KL divergence.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶åœ¨æœ¬ä¹¦çš„èŒƒå›´ä¹‹å¤–æä¾› ADF çš„å®Œæ•´æ¨å¯¼ï¼Œä½†ä½ åº”è¯¥çŸ¥é“ï¼Œåœ¨é€šè¿‡ ADF æ›´æ–°å‚æ•°æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿåœ¨æœ€å°åŒ– KL æ•£åº¦ã€‚
- en: 'Thus, for PBP, we need to adapt typical neural network update rules so that
    the weights are updated along the lines of ADF instead. We do this using the following
    update rules, which are derived from the original ADF equations:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¯¹äº PBPï¼Œæˆ‘ä»¬éœ€è¦è°ƒæ•´å…¸å‹çš„ç¥ç»ç½‘ç»œæ›´æ–°è§„åˆ™ï¼Œä½¿å¾—æƒé‡æ²¿ç€ ADF çš„æ–¹å‘è¿›è¡Œæ›´æ–°ã€‚æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ›´æ–°è§„åˆ™æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œè¿™äº›è§„åˆ™æ˜¯ä»åŸå§‹ ADF
    æ–¹ç¨‹æ¨å¯¼å‡ºæ¥çš„ï¼š
- en: '![mnew = m + v âˆ‚logZ-- âˆ‚m ](img/file133.jpg)![ [ ( ) ] new 2 âˆ‚-log-Z- âˆ‚-log-Z-
    v = v âˆ’ v âˆ‚m âˆ’ 2 âˆ‚v ](img/file134.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![mnew = m + v âˆ‚logZ-- âˆ‚m ](img/file133.jpg)![ [ ( ) ] new 2 âˆ‚-log-Z- âˆ‚-log-Z-
    v = v âˆ’ v âˆ‚m âˆ’ 2 âˆ‚v ](img/file134.jpg)'
- en: 'Here, log *Z* denotes the Gaussian marginal likelihood, which is defined as
    follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œlog *Z* è¡¨ç¤ºé«˜æ–¯è¾¹é™…ä¼¼ç„¶ï¼Œå…¶å®šä¹‰å¦‚ä¸‹ï¼š
- en: '![ 2 logZ = âˆ’ log p(y|m, v) = âˆ’ 0.5 Ã— log-v +-(y-âˆ’-m-) v ](img/file135.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 logZ = âˆ’ log p(y|m, v) = âˆ’ 0.5 Ã— log-v +-(y-âˆ’-m-) v ](img/file135.jpg)'
- en: 'This is the **negative log-likelihood** (**NLL**). Equation 5.21 is crucial
    to how we learn the parameters of PBP, as this is the loss function that weâ€™re
    trying to optimise - so letâ€™s take some time to understand whatâ€™s going on. Just
    as with our loss for BBB (equation 5.9), we can see that our log *Z* loss incorporates
    a few important pieces of information:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯**è´Ÿå¯¹æ•°ä¼¼ç„¶**ï¼ˆ**NLL**ï¼‰ã€‚æ–¹ç¨‹ 5.21 å¯¹äºæˆ‘ä»¬å­¦ä¹  PBP çš„å‚æ•°è‡³å…³é‡è¦ï¼Œå› ä¸ºè¿™æ˜¯æˆ‘ä»¬è¯•å›¾ä¼˜åŒ–çš„æŸå¤±å‡½æ•°â€”â€”æ‰€ä»¥æˆ‘ä»¬éœ€è¦èŠ±äº›æ—¶é—´æ¥ç†è§£å…¶ä¸­çš„å«ä¹‰ã€‚å°±åƒæˆ‘ä»¬åœ¨
    BBB ä¸­çš„æŸå¤±ï¼ˆæ–¹ç¨‹ 5.9ï¼‰ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å¯¹æ•°*Z*æŸå¤±åŒ…å«äº†å‡ ä¸ªé‡è¦çš„ä¿¡æ¯ï¼š
- en: In the numerator, we see (*y*âˆ’*m*)Â². This is similar to a typical loss weâ€™re
    used to seeing in standard neural network training (the L2 loss). This incorporates
    the penalty between our target *y* and our mean estimate for the value, *m*.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨åˆ†å­ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ° (*y*âˆ’*m*)Â²ã€‚è¿™ç±»ä¼¼äºæˆ‘ä»¬åœ¨æ ‡å‡†ç¥ç»ç½‘ç»œè®­ç»ƒä¸­å¸¸è§çš„å…¸å‹æŸå¤±ï¼ˆL2 æŸå¤±ï¼‰ã€‚å®ƒåŒ…å«äº†ç›®æ ‡ *y* å’Œæˆ‘ä»¬å¯¹è¯¥å€¼çš„å‡å€¼ä¼°è®¡ *m*
    ä¹‹é—´çš„æƒ©ç½šã€‚
- en: The whole equation gives us the NLL function, which describes the joint probability
    of our target *y* as a function of our distribution parameterised by *m* and *v*.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•´ä¸ªæ–¹ç¨‹ç»™å‡ºäº† NLL å‡½æ•°ï¼Œå®ƒæè¿°äº†æˆ‘ä»¬çš„ç›®æ ‡ *y* ä½œä¸ºæˆ‘ä»¬ç”± *m* å’Œ *v* å‚æ•°åŒ–çš„åˆ†å¸ƒçš„è”åˆæ¦‚ç‡ã€‚
- en: 'This has some important properties, which we can explore through a few simple
    examples. Letâ€™s look at the loss for some arbitrary parameters *m* = 0*.*8 and
    *v* = 0*.*4 for a given target *y* = 0*.*6:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å…·æœ‰ä¸€äº›é‡è¦çš„æ€§è´¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‡ ä¸ªç®€å•çš„ä¾‹å­æ¥æ¢ç´¢ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å¯¹äºç»™å®šç›®æ ‡ *y* = 0*.*6ï¼Œå‚æ•° *m* = 0*.*8 å’Œ *v* =
    0*.*4 çš„æŸå¤±ï¼š
- en: '![ 2 2 âˆ’ 0.5Ã— logv-+-(y âˆ’-m)- = âˆ’ 0.5 Ã— log(0.4)-+-(0.6-âˆ’-0.8)- = 1.095 v 0.4
    ](img/file136.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 2 âˆ’ 0.5Ã— logv-+-(y âˆ’-m)- = âˆ’ 0.5 Ã— log(0.4)-+-(0.6-âˆ’-0.8)- = 1.095 v 0.4
    ](img/file136.jpg)'
- en: Here, we can see that our typical error, in this case the squared error, is
    (0*.*6 âˆ’ 0*.*8)Â² = 0*.*04, and we know that as *m* converges towards *y*, this
    will shrink. In addition to that, the log-likelihood scales our error. This is
    important, because a well-conditioned model for uncertainty quantification will
    be *more uncertain* when itâ€™s wrong, and *more confident* when itâ€™s right. The
    likelihood function gives us a way of achieving this, ensuring that our likelihood
    is greater if weâ€™re uncertain about incorrect predictions and certain about correct
    predictions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å…¸å‹è¯¯å·®ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯å¹³æ–¹è¯¯å·®ï¼Œ(0*.*6 âˆ’ 0*.*8)Â² = 0*.*04ï¼Œå¹¶ä¸”æˆ‘ä»¬çŸ¥é“ï¼Œå½“*m*è¶‹è¿‘äº*y*æ—¶ï¼Œè¿™ä¸ªè¯¯å·®ä¼šç¼©å°ã€‚æ­¤å¤–ï¼Œä¼¼ç„¶å‡½æ•°ä¼šç¼©æ”¾æˆ‘ä»¬çš„è¯¯å·®ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºä¸€ä¸ªç”¨äºä¸ç¡®å®šæ€§é‡åŒ–çš„è‰¯å¥½æ¡ä»¶æ¨¡å‹åœ¨é”™è¯¯æ—¶ä¼š*æ›´ä¸ç¡®å®š*ï¼Œåœ¨æ­£ç¡®æ—¶ä¼š*æ›´è‡ªä¿¡*ã€‚ä¼¼ç„¶å‡½æ•°ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§æ–¹æ³•ï¼Œç¡®ä¿åœ¨æˆ‘ä»¬å¯¹é”™è¯¯é¢„æµ‹ä¸ç¡®å®šæ—¶ï¼Œå®ƒçš„ä¼¼ç„¶å€¼è¾ƒå¤§ï¼Œè€Œå¯¹æ­£ç¡®é¢„æµ‹æ—¶ï¼Œåˆ™è¾ƒä¸ºç¡®å®šã€‚
- en: 'We can see this in action by substituting another value of *v* and seeing how
    this changes the NLL. For example, letâ€™s increase our variance to *v* = 0*.*9:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡æ›¿æ¢å¦ä¸€ä¸ª*v*çš„å€¼ï¼ŒæŸ¥çœ‹å®ƒå¦‚ä½•æ”¹å˜NLLï¼Œæ¥è§‚å¯Ÿè¿™ä¸ªè¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ–¹å·®å¢åŠ åˆ°*v* = 0*.*9ï¼š
- en: '![ 2 âˆ’ 0.5Ã— log(0.9)+-(0.6âˆ’-0.8)- = 0.036 0.9 ](img/file137.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 âˆ’ 0.5Ã— log(0.9)+-(0.6âˆ’-0.8)- = 0.036 0.9 ](img/file137.jpg)'
- en: 'This significant increase in variance produces a similarly significant reduction
    in NLL. Similarly, weâ€™ll see our NLL increase again if we have high variance for
    a correct prediction *m* = *y*:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹å·®çš„æ˜¾è‘—å¢åŠ ä¼šå¯¼è‡´NLLçš„æ˜¾è‘—ä¸‹é™ã€‚ç±»ä¼¼åœ°ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ä¸€ä¸ªæ­£ç¡®çš„é¢„æµ‹*m* = *y*æœ‰å¾ˆé«˜çš„æ–¹å·®ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°NLLå†æ¬¡å¢åŠ ï¼š
- en: '![ log(0.9)+-(0.8âˆ’-0.8)2 âˆ’ 0.5Ã— 0.9 = 0.059 ](img/file138.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![ log(0.9)+-(0.8âˆ’-0.8)2 âˆ’ 0.5Ã— 0.9 = 0.059 ](img/file138.jpg)'
- en: 'Hopefully, with this example you can see how using the NLL loss translates
    to well calibrated uncertainty estimates over our outputs. In fact, this property
    â€“ using the variance to scale to our objective function â€“ is a fundamental component
    of all principled BNN methods: BBB also does this, although itâ€™s a little more
    difficult to demonstrate on paper as it requires sampling.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›é€šè¿‡è¿™ä¸ªä¾‹å­ï¼Œä½ èƒ½çœ‹åˆ°ä½¿ç”¨NLLæŸå¤±å¦‚ä½•è½¬åŒ–ä¸ºæˆ‘ä»¬è¾“å‡ºçš„è‰¯å¥½æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚å®é™…ä¸Šï¼Œè¿™ä¸ªå±æ€§â€”â€”åˆ©ç”¨æ–¹å·®æ¥ç¼©æ”¾ç›®æ ‡å‡½æ•°â€”â€”æ˜¯æ‰€æœ‰æœ‰åŸåˆ™çš„BNNæ–¹æ³•çš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼šBBBä¹Ÿåšäº†è¿™ä»¶äº‹ï¼Œå°½ç®¡ç”±äºéœ€è¦é‡‡æ ·ï¼Œå®ƒåœ¨çº¸é¢ä¸Šå±•ç¤ºèµ·æ¥æœ‰ç‚¹å¤æ‚ã€‚
- en: There are a few low-level details of PBP that weâ€™ll encounter in the implementation.
    These relate to the ADF process, and we encourage you to take a look at the articles
    in the *Further reading* section for comprehensive derivations of PBP and ADF.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é‡åˆ°ä¸€äº›PBPçš„ä½çº§ç»†èŠ‚ã€‚å®ƒä»¬ä¸ADFè¿‡ç¨‹æœ‰å…³ï¼Œæˆ‘ä»¬é¼“åŠ±ä½ æŸ¥çœ‹*è¿›ä¸€æ­¥é˜…è¯»*éƒ¨åˆ†ä¸­çš„æ–‡ç« ï¼Œä»¥è·å¾—PBPå’ŒADFçš„è¯¦ç»†æ¨å¯¼ã€‚
- en: Now that weâ€™ve covered PBPâ€™s core concepts, letâ€™s take a look at how we implement
    it with TensorFlow.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å·²ç»æ¶µç›–äº†PBPçš„æ ¸å¿ƒæ¦‚å¿µï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨TensorFlowå®ç°å®ƒã€‚
- en: 5.7 Implementing PBP
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.7 å®ç°PBP
- en: Because PBP is quite complex, weâ€™ll implement it as a class. Doing so will keep
    our example code tidy and allow us to easily compartmentalize our various blocks
    of code. It will also make it easier to experiment with, for example, if you want
    to explore changing the number of units or layers in your network.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºPBPç›¸å½“å¤æ‚ï¼Œæˆ‘ä»¬å°†æŠŠå®ƒå®ç°ä¸ºä¸€ä¸ªç±»ã€‚è¿™æ ·åšå¯ä»¥ä½¿æˆ‘ä»¬çš„ç¤ºä¾‹ä»£ç æ›´åŠ ç®€æ´ï¼Œå¹¶ä¸”æ–¹ä¾¿æˆ‘ä»¬å°†ä¸åŒçš„ä»£ç å—è¿›è¡Œæ¨¡å—åŒ–ã€‚å®ƒè¿˜å°†ä½¿å¾—å®éªŒå˜å¾—æ›´å®¹æ˜“ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³æ¢ç´¢æ”¹å˜ç½‘ç»œä¸­å•å…ƒæˆ–å±‚çš„æ•°é‡ã€‚
- en: 'Step 1: Importing libraries'
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥åº“
- en: 'We begin by importing various libraries. In this example, we will use scikit-learnâ€™s
    California Housing dataset to predict house prices:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆå¯¼å…¥å„ç§åº“ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨scikit-learnçš„åŠ åˆ©ç¦å°¼äºšä½æˆ¿æ•°æ®é›†æ¥é¢„æµ‹æˆ¿ä»·ï¼š
- en: '[PRE11]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To make sure we produce the same output every time, we initialize our seeds:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¡®ä¿æ¯æ¬¡ç”Ÿæˆç›¸åŒçš„è¾“å‡ºï¼Œæˆ‘ä»¬åˆå§‹åŒ–æˆ‘ä»¬çš„ç§å­å€¼ï¼š
- en: '[PRE12]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can then load our dataset and create train and test splits:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥åŠ è½½æ•°æ®é›†å¹¶åˆ›å»ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š
- en: '[PRE13]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Step 2: Helper functions'
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ­¥ï¼šè¾…åŠ©å‡½æ•°
- en: 'Next, we define two helper functions that ensure that our data is in the correct
    format, one for the input and another one for the output data:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸¤ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç¡®ä¿æˆ‘ä»¬çš„æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œä¸€ä¸ªç”¨äºè¾“å…¥ï¼Œå¦ä¸€ä¸ªç”¨äºè¾“å‡ºæ•°æ®ï¼š
- en: '[PRE14]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We will also create a short class to initialize a gamma distribution: `ReciprocalGammaInitializer`.
    This distribution is used as the prior for PBPâ€™s precision parameter *Î»* and the
    noise parameter *Î³*.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å°†åˆ›å»ºä¸€ä¸ªç®€çŸ­çš„ç±»æ¥åˆå§‹åŒ–ä¸€ä¸ªä¼½ç›åˆ†å¸ƒï¼š`ReciprocalGammaInitializer`ã€‚è¿™ä¸ªåˆ†å¸ƒè¢«ç”¨ä½œPBPç²¾åº¦å‚æ•°*Î»*å’Œå™ªå£°å‚æ•°*Î³*çš„å…ˆéªŒã€‚
- en: '[PRE15]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: A thorough treatment of these variables is not required for a general understanding
    of PBP. For further details on this, please see the PBP paper listed in the *Further
    reading* section.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹è¿™äº›å˜é‡çš„æ·±å…¥å¤„ç†å¯¹äºç†è§£PBPå¹¶ä¸æ˜¯å¿…éœ€çš„ã€‚å¦‚éœ€è¿›ä¸€æ­¥äº†è§£ï¼Œ è¯·å‚è§*è¿›ä¸€æ­¥é˜…è¯»*éƒ¨åˆ†ä¸­åˆ—å‡ºçš„PBPè®ºæ–‡ã€‚
- en: 'Step 3: Data preparation'
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰æ­¥ï¼šæ•°æ®å‡†å¤‡
- en: 'With these prerequisites implemented, we can normalize our data. Here, we normalize
    to mean zero and unit standard deviation. This is a common pre-processing step
    that will make it easier for our model to find the right set of weights:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®ç°è¿™äº›å…ˆå†³æ¡ä»¶åï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ•°æ®å½’ä¸€åŒ–ä¸ºå‡å€¼ä¸ºé›¶ï¼Œæ ‡å‡†å·®ä¸ºå•ä½ã€‚è¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„é¢„å¤„ç†æ­¥éª¤ï¼Œæœ‰åŠ©äºæ¨¡å‹æ›´å®¹æ˜“æ‰¾åˆ°åˆé€‚çš„æƒé‡ï¼š
- en: '[PRE16]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Step 4: Defining our model class'
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬4æ­¥ï¼šå®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ç±»
- en: 'We can now start to define our model. Our model will consist of three layers:
    two ReLU layers and one linear layer. We use Kerasâ€™ `Layer` to define our layers.
    The code for this layer is quite long, so we will break it into several subsections.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹äº†ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†ç”±ä¸‰å±‚ç»„æˆï¼šä¸¤å±‚ReLUå±‚å’Œä¸€å±‚çº¿æ€§å±‚ã€‚æˆ‘ä»¬ä½¿ç”¨Kerasçš„`Layer`æ¥å®šä¹‰è¿™äº›å±‚ã€‚ç”±äºè¿™ä¸€å±‚çš„ä»£ç æ¯”è¾ƒé•¿ï¼Œå› æ­¤æˆ‘ä»¬å°†å…¶æ‹†åˆ†æˆå‡ ä¸ªå­éƒ¨åˆ†ã€‚
- en: 'First, we subclass the `Layer` to create our own `PBPLayer` and define our
    `init` method. Our initialization method sets the number of units in our layer:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬ç»§æ‰¿`Layer`ç±»æ¥åˆ›å»ºæˆ‘ä»¬è‡ªå·±çš„`PBPLayer`å¹¶å®šä¹‰`init`æ–¹æ³•ã€‚æˆ‘ä»¬çš„åˆå§‹åŒ–æ–¹æ³•è®¾ç½®äº†å±‚ä¸­çš„å•å…ƒæ•°é‡ï¼š
- en: '[PRE17]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We then create a `build()` method that defines the weights of our layer. As
    we discussed in the previous section, PBP comprises both *mean* weights and *variance*
    weights. As a simple MLP is composed of a multiplicative component, or weight,
    and a bias, weâ€™ll split both our weights and biases into mean and variance variables:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`build()`æ–¹æ³•ï¼Œç”¨äºå®šä¹‰æˆ‘ä»¬å±‚çš„æƒé‡ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­è®¨è®ºçš„ï¼ŒPBPåŒ…å«äº†*å‡å€¼*æƒé‡å’Œ*æ–¹å·®*æƒé‡ã€‚ç”±äºä¸€ä¸ªç®€å•çš„MLPç”±ä¹˜æ³•ç»„ä»¶æˆ–æƒé‡å’Œåç½®ç»„æˆï¼Œæˆ‘ä»¬å°†æƒé‡å’Œåç½®åˆ†è§£ä¸ºå‡å€¼å’Œæ–¹å·®å˜é‡ï¼š
- en: '[PRE18]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `weights_m` and `weights_v` variables are our mean and variance weights,
    forming the very core of our PBP model. We will continue our definition of `PBPLayer`
    when we work through our model fitting function. For now, we can subclass this
    class to create our ReLU layer:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`weights_m`å’Œ`weights_v`å˜é‡æ˜¯æˆ‘ä»¬çš„å‡å€¼å’Œæ–¹å·®æƒé‡ï¼Œæ„æˆäº†PBPæ¨¡å‹çš„æ ¸å¿ƒã€‚æˆ‘ä»¬å°†åœ¨é€šè¿‡æ¨¡å‹æ‹Ÿåˆå‡½æ•°æ—¶ç»§ç»­å®šä¹‰`PBPLayer`ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç»§æ‰¿è¯¥ç±»æ¥åˆ›å»ºæˆ‘ä»¬çš„ReLUå±‚ï¼š'
- en: '[PRE19]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You can see that we overwrite two functions: our `call()` and `predict()` functions.
    The `call()` function calls our regular linear `call()` function and then applies
    the ReLU max operation we saw in [*ChapterÂ 3*](CH3.xhtml#x1-350003), [*Fundamentals
    of Deep* *Learning*](CH3.xhtml#x1-350003). The `predict()` function calls our
    regular `predict()` function, but then also calls a new function, `get_bias_mean_variance()`.
    This function computes the mean and variance of our bias in a numerically stable
    way, as shown here:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬é‡å†™äº†ä¸¤ä¸ªå‡½æ•°ï¼š`call()`å’Œ`predict()`å‡½æ•°ã€‚`call()`å‡½æ•°è°ƒç”¨æˆ‘ä»¬å¸¸è§„çš„çº¿æ€§`call()`å‡½æ•°ï¼Œç„¶ååº”ç”¨æˆ‘ä»¬åœ¨[*ç¬¬3ç« *](CH3.xhtml#x1-350003)ï¼Œã€Šæ·±åº¦å­¦ä¹ åŸºç¡€ã€‹[*Chapter
    3*](CH3.xhtml#x1-350003)ä¸­çœ‹åˆ°çš„ReLUæœ€å¤§æ“ä½œã€‚`predict()`å‡½æ•°è°ƒç”¨æˆ‘ä»¬å¸¸è§„çš„`predict()`å‡½æ•°ï¼Œä½†éšåä¹Ÿè°ƒç”¨äº†ä¸€ä¸ªæ–°å‡½æ•°`get_bias_mean_variance()`ã€‚è¯¥å‡½æ•°ä»¥æ•°å€¼ç¨³å®šçš„æ–¹å¼è®¡ç®—åç½®çš„å‡å€¼å’Œæ–¹å·®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE20]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'With our layer definitions in place, we can build our network. We first create
    a list of all layers in our network:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å®šä¹‰å¥½å±‚ä¹‹åï¼Œå°±å¯ä»¥æ„å»ºæˆ‘ä»¬çš„ç½‘ç»œã€‚æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªåŒ…å«ç½‘ç»œä¸­æ‰€æœ‰å±‚çš„åˆ—è¡¨ï¼š
- en: '[PRE21]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We then create a `PBP` class that contains the modelâ€™s `fit()` and `predict()`
    functions, similar to what you see in a model defined with Kerasâ€™s `tf.keras.Model`
    class. Next, weâ€™ll see a number of important variables; letâ€™s go through them
    here:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`PBP`ç±»ï¼ŒåŒ…å«æ¨¡å‹çš„`fit()`å’Œ`predict()`å‡½æ•°ï¼Œç±»ä¼¼äºä½ åœ¨ä½¿ç”¨Kerasçš„`tf.keras.Model`ç±»å®šä¹‰çš„æ¨¡å‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ä¸€äº›é‡è¦çš„å˜é‡ï¼›è®©æˆ‘ä»¬åœ¨è¿™é‡Œä¸€èµ·äº†è§£å®ƒä»¬ï¼š
- en: '`alpha` and `beta` : These are parameters of our gamma distribution'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`å’Œ`beta`ï¼šè¿™äº›æ˜¯æˆ‘ä»¬ä¼½é©¬åˆ†å¸ƒçš„å‚æ•°'
- en: '`Gamma` : An instance of the `tfp.distributions.Gamma()` class for our gamma
    distributions, which is a hyper-prior on PBPâ€™s precision parameter *Î»*'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Gamma`ï¼šä¸€ä¸ª`tfp.distributions.Gamma()`ç±»çš„å®ä¾‹ï¼Œç”¨äºæˆ‘ä»¬çš„ä¼½é©¬åˆ†å¸ƒï¼Œå®ƒæ˜¯PBPç²¾åº¦å‚æ•°*Î»*çš„è¶…å…ˆéªŒ'
- en: '`layers` : This variable specifies the number of layers in the model'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layers`ï¼šè¿™ä¸ªå˜é‡æŒ‡å®šäº†æ¨¡å‹ä¸­çš„å±‚æ•°'
- en: '`Normal` : Here, we instantiate an instance of the `tfp.distributions.Normal()`
    class, which implements a Gaussian probability distribution (in this case, with
    a mean of 0 and a standard deviation of 1):'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Normal`ï¼šåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®ä¾‹åŒ–äº†`tfp.distributions.Normal()`ç±»ï¼Œå®ƒå®ç°äº†ä¸€ä¸ªé«˜æ–¯æ¦‚ç‡åˆ†å¸ƒï¼ˆæ­¤å¤„å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼‰ï¼š'
- en: '[PRE22]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `PBP` class `__init__` function creates a number of parameters but essentially
    initializes our *Î±* and *Î²* hyper-priors with a normal and a gamma distribution.
    Furthermore, we save the layers that we created in the previous step.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`PBP`ç±»çš„`__init__`å‡½æ•°åˆ›å»ºäº†å¤šä¸ªå‚æ•°ï¼Œä½†æœ¬è´¨ä¸Šæ˜¯é€šè¿‡æ­£æ€åˆ†å¸ƒå’Œä¼½é©¬åˆ†å¸ƒåˆå§‹åŒ–æˆ‘ä»¬çš„*Î±*å’Œ*Î²*è¶…å…ˆéªŒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä¿å­˜äº†åœ¨ä¸Šä¸€æ­¥åˆ›å»ºçš„å±‚ã€‚'
- en: 'The `fit()` function updates the gradients of our layers and then updates our
    *Î±* and *Î²* parameters. The function for updating gradients is defined as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit()`å‡½æ•°æ›´æ–°æˆ‘ä»¬å±‚çš„æ¢¯åº¦ï¼Œç„¶åæ›´æ–°*Î±*å’Œ*Î²*å‚æ•°ã€‚æ›´æ–°æ¢¯åº¦çš„å‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š'
- en: '[PRE23]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Before we can update our gradients, we need to propagate them forward through
    the network. To do so, weâ€™ll implement our `predict()` method:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ›´æ–°æ¢¯åº¦ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ç½‘ç»œä¼ æ’­æ¢¯åº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å®ç°æˆ‘ä»¬çš„`predict()`æ–¹æ³•ï¼š
- en: '[PRE24]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now that we can propagate values through our network, we are ready to implement
    our loss function. As we saw in the previous section, we use the NLL, which weâ€™ll
    define here:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡ç½‘ç»œä¼ æ’­å€¼ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½å®ç°æˆ‘ä»¬çš„æŸå¤±å‡½æ•°äº†ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨å‰ä¸€èŠ‚æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨NLLï¼ˆè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼‰ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†å®šä¹‰å®ƒï¼š
- en: '[PRE25]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can now propagate values through the network and obtain our gradient with
    respect to our loss (as we would with a standard neural network). This means weâ€™re
    ready to update our gradients by applying the update rules we saw in equations
    5.19 and 5.20 for the mean weights and variance weights, respectively:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡ç½‘ç»œä¼ æ’­å€¼ï¼Œå¹¶è®¡ç®—ç›¸å¯¹äºæŸå¤±çš„æ¢¯åº¦ï¼ˆå°±åƒæˆ‘ä»¬åœ¨æ ‡å‡†ç¥ç»ç½‘ç»œä¸­ä¸€æ ·ï¼‰ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥æ ¹æ®å…¬å¼5.19å’Œ5.20ä¸­çš„æ›´æ–°è§„åˆ™ï¼Œåˆ†åˆ«æ›´æ–°å‡å€¼æƒé‡å’Œæ–¹å·®æƒé‡ï¼š
- en: '[PRE26]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As discussed in the previous section, PBP belongs to the class of **Assumed**
    **Density Filtering** (**ADF**) methods. As such, we update the *Î±* and *Î²* parameters
    according to ADFâ€™s update rules:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰ä¸€èŠ‚æ‰€è®¨è®ºï¼ŒPBPå±äº**å‡è®¾****å¯†åº¦æ»¤æ³¢**ï¼ˆ**ADF**ï¼‰æ–¹æ³•çš„ç±»åˆ«ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ ¹æ®ADFçš„æ›´æ–°è§„åˆ™æ›´æ–°*Î±*å’Œ*Î²*å‚æ•°ï¼š
- en: '[PRE27]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Step 5: Avoiding numerical errors'
  id: totrans-226
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤5ï¼šé¿å…æ•°å€¼é”™è¯¯
- en: 'Finally, letâ€™s define a few helper functions to ensure that we avoid numerical
    errors during fitting:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œä»¥ç¡®ä¿åœ¨æ‹Ÿåˆè¿‡ç¨‹ä¸­é¿å…æ•°å€¼é”™è¯¯ï¼š
- en: '[PRE28]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Step 6: Instantiating our model'
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤6ï¼šå®ä¾‹åŒ–æˆ‘ä»¬çš„æ¨¡å‹
- en: 'And there we have it: the core code for training PBP. Now weâ€™re ready to instantiate
    our model and train it on some data. Letâ€™s use a small batch size and a single
    epoch in this example:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼šè®­ç»ƒPBPçš„æ ¸å¿ƒä»£ç å®Œæˆäº†ã€‚ç°åœ¨æˆ‘ä»¬å‡†å¤‡å®ä¾‹åŒ–æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶åœ¨ä¸€äº›æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡å¤§å°å’Œä¸€ä¸ªè®­ç»ƒå‘¨æœŸï¼š
- en: '[PRE29]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Step 7: Using our model for inference'
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤7ï¼šä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œæ¨ç†
- en: 'Now that we have our fitted model, letâ€™s see how well it works on our test
    set. We first normalize our test set:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å¾—åˆ°äº†æ‹Ÿåˆçš„æ¨¡å‹ï¼Œæ¥ä¸‹æ¥çœ‹çœ‹å®ƒåœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¦‚ä½•ã€‚æˆ‘ä»¬é¦–å…ˆå¯¹æµ‹è¯•é›†è¿›è¡Œæ ‡å‡†åŒ–ï¼š
- en: '[PRE30]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then we get our model predictions: the mean and variance:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¾—åˆ°æ¨¡å‹é¢„æµ‹ç»“æœï¼šå‡å€¼å’Œæ–¹å·®ï¼š
- en: '[PRE31]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then we post-process these values to make sure they have the right shape and
    are in the range of the original input data:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯¹è¿™äº›å€¼è¿›è¡Œåå¤„ç†ï¼Œä»¥ç¡®ä¿å®ƒä»¬å…·æœ‰æ­£ç¡®çš„å½¢çŠ¶ï¼Œå¹¶ä¸”åœ¨åŸå§‹è¾“å…¥æ•°æ®çš„èŒƒå›´å†…ï¼š
- en: '[PRE32]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now that weâ€™ve got our predictions, we can compute how well our modelâ€™s done.
    Weâ€™ll use a standard error metric, RMSE, as well as the metric we used for our
    loss: the NLL. We can compute them using the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†é¢„æµ‹ç»“æœï¼Œå¯ä»¥è®¡ç®—æˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°å¦‚ä½•ã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ ‡å‡†è¯¯å·®æŒ‡æ ‡RMSEï¼Œä»¥åŠæˆ‘ä»¬åœ¨æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨çš„æŒ‡æ ‡ï¼šNLLã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—å®ƒä»¬ï¼š
- en: '[PRE33]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Evaluating both of these metrics is good practice for any regression task for
    which you have model uncertainty estimates. The RMSE gives you your standard error
    metric, which allows you to compare directly with non-probabilistic methods. The
    NLL gives you an imdivssion of how well calibrated your method is by evaluating
    how confident your model is when itâ€™s doing well versus doing poorly, as we discussed
    earlier in the chapter. Together, these metrics give you a comprehensive imdivssion
    of a Bayesian modelâ€™s performance, and youâ€™ll see them used time and time again
    in the literature.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°è¿™ä¸¤ä¸ªæŒ‡æ ‡æ˜¯ä»»ä½•å›å½’ä»»åŠ¡çš„å¥½åšæ³•ï¼Œå°¤å…¶æ˜¯å½“ä½ æœ‰æ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡æ—¶ã€‚RMSEç»™å‡ºäº†æ ‡å‡†è¯¯å·®æŒ‡æ ‡ï¼Œå®ƒå…è®¸ä½ ç›´æ¥ä¸éæ¦‚ç‡æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚NLLåˆ™é€šè¿‡è¯„ä¼°å½“æ¨¡å‹è¡¨ç°å¥½ä¸è¡¨ç°å·®æ—¶æ¨¡å‹çš„ä¿¡å¿ƒï¼Œæ¥åˆ¤æ–­ä½ çš„æ–¹æ³•çš„æ ¡å‡†ç¨‹åº¦ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨æœ¬ç« å‰é¢è®¨è®ºè¿‡çš„é‚£æ ·ã€‚æ€»ä½“æ¥çœ‹ï¼Œè¿™äº›æŒ‡æ ‡æä¾›äº†è´å¶æ–¯æ¨¡å‹æ€§èƒ½çš„å…¨é¢è¯„ä¼°ï¼Œä½ ä¼šåœ¨æ–‡çŒ®ä¸­åå¤çœ‹åˆ°å®ƒä»¬çš„åº”ç”¨ã€‚
- en: 5.8 Summary
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8 å°ç»“
- en: In this chapter, we learned about two fundamental, well-principled, Bayesian
    deep learning models. BBB showed us how we can make use of variational inference
    to efficiently sample from our weight space and produce output distributions,
    while PBP demonstrated that itâ€™s possible to obtain predictive uncertainties *without*
    sampling. This makes PBP more computationally efficient than BBB, but each model
    has its pros and cons.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¸¤ä¸ªåŸºç¡€çš„ã€åŸåˆ™æ˜ç¡®çš„è´å¶æ–¯æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚BBBå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨å˜åˆ†æ¨æ–­é«˜æ•ˆåœ°ä»æƒé‡ç©ºé—´è¿›è¡Œé‡‡æ ·å¹¶ç”Ÿæˆè¾“å‡ºåˆ†å¸ƒï¼Œè€ŒPBPåˆ™å±•ç¤ºäº†é€šè¿‡ä¸è¿›è¡Œé‡‡æ ·ä¹Ÿèƒ½è·å¾—é¢„æµ‹ä¸ç¡®å®šæ€§çš„å¯èƒ½æ€§ã€‚è¿™æ ·ï¼ŒPBPåœ¨è®¡ç®—ä¸Šæ¯”BBBæ›´é«˜æ•ˆï¼Œä½†æ¯ä¸ªæ¨¡å‹éƒ½æœ‰å…¶ä¼˜ç¼ºç‚¹ã€‚
- en: 'In BBBâ€™s case, while itâ€™s less computationally efficient than PBP, itâ€™s also
    more adaptable (particularly with the tools available in TensorFlow for variational
    layers). We can apply this to a variety of different DNN architectures with relatively
    little difficulty. The price is incurred through the sampling required at both
    inference and training time: we need to do more than just a single forward pass
    to obtain our output distributions.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ BBB çš„æƒ…å†µä¸‹ï¼Œè™½ç„¶å®ƒåœ¨è®¡ç®—æ•ˆç‡ä¸Šä¸å¦‚ PBPï¼Œä½†å®ƒä¹Ÿæ›´å…·é€‚åº”æ€§ï¼ˆç‰¹åˆ«æ˜¯åœ¨ TensorFlow ä¸­ç”¨äºå˜åˆ†å±‚çš„å·¥å…·ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥å°†å…¶åº”ç”¨äºå„ç§ä¸åŒçš„
    DNN æ¶æ„ï¼Œä¸”ç›¸å¯¹ä¸è´¹åŠ›ã€‚ä»£ä»·åˆ™æ˜¯åœ¨æ¨ç†å’Œè®­ç»ƒæ—¶æ‰€éœ€çš„é‡‡æ ·ï¼šæˆ‘ä»¬éœ€è¦è¿›è¡Œçš„ä¸ä»…ä»…æ˜¯ä¸€æ¬¡å‰å‘ä¼ é€’æ‰èƒ½è·å¾—è¾“å‡ºåˆ†å¸ƒã€‚
- en: Conversely, PBP allows us to obtain our uncertainty estimates with a single
    pass, but â€“ as weâ€™ve just seen â€“ itâ€™s quite complex to implement. This makes it
    awkward to adapt to other network architectures, and while it has been done (see
    the *Further reading* section), itâ€™s not a particularly practical method to use
    given the technical overhead of implementation and the relatively marginal gains
    compared to other methods.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åï¼ŒPBP å…è®¸æˆ‘ä»¬é€šè¿‡ä¸€æ¬¡ä¼ é€’è·å¾—ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œä½†æ­£å¦‚æˆ‘ä»¬åˆšæ‰æ‰€è§ï¼Œå®ƒçš„å®ç°ç›¸å½“å¤æ‚ã€‚è¿™ä½¿å¾—å®ƒåœ¨é€‚åº”å…¶ä»–ç½‘ç»œæ¶æ„æ—¶æ˜¾å¾—æœ‰äº›ç¬¨æ‹™ï¼Œå°½ç®¡å·²ç»æœ‰å®ç°ï¼ˆå‚è§*è¿›ä¸€æ­¥é˜…è¯»*éƒ¨åˆ†ï¼‰ï¼Œä½†é‰´äºå®æ–½çš„æŠ€æœ¯å¼€é”€ä»¥åŠä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ç›¸å¯¹è¾ƒå°çš„æ”¶ç›Šï¼Œå®ƒå¹¶ä¸æ˜¯ä¸€ç§ç‰¹åˆ«å®ç”¨çš„æ–¹æ³•ã€‚
- en: In summary, these methods are excellent if you need robust, well-principled
    BNN approximations and arenâ€™t constrained in terms of memory or computational
    overheads at inference. But what if you have limited memory and/or limited compute,
    such as running on edge devices? In these cases, you may want to turn to more
    practical methods of obtaining predictive uncertainties.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä¹‹ï¼Œå¦‚æœä½ éœ€è¦ç¨³å¥ä¸”åŸåˆ™æ¸…æ™°çš„ BNN è¿‘ä¼¼ï¼Œå¹¶ä¸”åœ¨æ¨ç†æ—¶ä¸å—å†…å­˜æˆ–è®¡ç®—å¼€é”€çš„é™åˆ¶ï¼Œè¿™äº›æ–¹æ³•éå¸¸ä¼˜ç§€ã€‚ä½†å¦‚æœä½ æœ‰æœ‰é™çš„å†…å­˜å’Œ/æˆ–è®¡ç®—èµ„æºï¼Œæ¯”å¦‚åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œï¼Œæ€ä¹ˆåŠï¼Ÿåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½éœ€è¦è½¬å‘æ›´å®ç”¨çš„æ–¹æ³•æ¥è·å¾—é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚
- en: In *Chapter 6, Bayesian Neural Network Approximation Using a Standard Deep*
    *Learning Toolbox*, weâ€™ll see how we can use more familiar components in TensorFlow
    to create more practical probabilistic neural network models.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬å…­ç« ï¼Œä½¿ç”¨æ ‡å‡†æ·±åº¦å­¦ä¹ å·¥å…·ç®±çš„è´å¶æ–¯ç¥ç»ç½‘ç»œè¿‘ä¼¼*ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ TensorFlow ä¸­æ›´ç†Ÿæ‚‰çš„ç»„ä»¶æ¥åˆ›å»ºæ›´å®ç”¨çš„æ¦‚ç‡ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚
- en: 5.9 Further reading
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.9 è¿›ä¸€æ­¥é˜…è¯»
- en: '*Weight Uncertainty in Neural Networks*, Charles Blundell *et al.*: This is
    the paper that introduced BBB, and is one of the key pieces of BDL literature.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç¥ç»ç½‘ç»œä¸­çš„æƒé‡ä¸ç¡®å®šæ€§*ï¼ŒCharles Blundell *ç­‰äºº*ï¼šè¿™ç¯‡è®ºæ–‡ä»‹ç»äº† BBBï¼Œå¹¶ä¸”æ˜¯ BDL æ–‡çŒ®ä¸­çš„å…³é”®æ–‡çŒ®ä¹‹ä¸€ã€‚'
- en: '*Practical Variational Inference for Neural Networks*, Alex Graves *et al.*:
    An influential paper on the use of variational inference for neural networks,
    this work introduces a straightforward stochastic variational method that can
    be applied to a variety of neural network architectures.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç¥ç»ç½‘ç»œçš„å®ç”¨å˜åˆ†æ¨æ–­*ï¼ŒAlex Graves *ç­‰äºº*ï¼šè¿™æ˜¯ä¸€ç¯‡å…³äºç¥ç»ç½‘ç»œä¸­ä½¿ç”¨å˜åˆ†æ¨æ–­çš„æœ‰å½±å“åŠ›çš„è®ºæ–‡ï¼Œä»‹ç»äº†ä¸€ç§ç®€å•çš„éšæœºå˜åˆ†æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºå„ç§ç¥ç»ç½‘ç»œæ¶æ„ã€‚'
- en: '*Probabilistic Backpropagation for Scalable Learning of Bayesian* *Neural Networks*,
    JosÃ© Miguel HernÃ¡ndez-Lobato *et al.*: Another important work in BDL literature,
    this work introduced PBP, demonstrating how Bayesian inference can be achieved
    via more scalable means.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯æ‰©å±•è´å¶æ–¯ç¥ç»ç½‘ç»œå­¦ä¹ çš„æ¦‚ç‡åå‘ä¼ æ’­*ï¼ŒJosÃ© Miguel HernÃ¡ndez-Lobato *ç­‰äºº*ï¼šBDL æ–‡çŒ®ä¸­çš„å¦ä¸€é¡¹é‡è¦å·¥ä½œï¼Œä»‹ç»äº†
    PBPï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ›´å…·å¯æ‰©å±•æ€§çš„æ–¹æ³•å®ç°è´å¶æ–¯æ¨æ–­ã€‚'
- en: '*Practical Considerations for Probabilistic Backpropagation*, Matt Benatan
    *et al.*: In this work, the authors introduce methods for making PBP more practical
    for real-world applications.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¦‚ç‡åå‘ä¼ æ’­çš„å®ç”¨è€ƒè™‘*ï¼ŒMatt Benatan *ç­‰äºº*ï¼šåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œä½œè€…ä»‹ç»äº†ä½¿ PBP æ›´é€‚åˆå®é™…åº”ç”¨çš„æ–¹æ³•ã€‚'
- en: '*Fully Bayesian Recurrent Neural Networks for Safe Reinforcement* *Learning*,
    Matt Benatan *et al.*: This paper shows how PBP can be adapted to an RNN architecture,
    and shows how BNNs can be advantageous in safety-critical systems.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç”¨äºå®‰å…¨å¼ºåŒ–å­¦ä¹ çš„å®Œå…¨è´å¶æ–¯é€’å½’ç¥ç»ç½‘ç»œ*ï¼ŒMatt Benatan *ç­‰äºº*ï¼šè¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†å¦‚ä½•å°† PBP é€‚åº”äº RNN æ¶æ„ï¼Œå¹¶å±•ç¤ºäº† BNN
    åœ¨å®‰å…¨å…³é”®ç³»ç»Ÿä¸­çš„ä¼˜åŠ¿ã€‚'
- en: '**[1](#footref1)** It is beyond the scope of this book to guide the reader
    through the derivation of ELBO, but we encourage the reader to see the Further
    reading section for texts that provide a more comprehensive overview of ELBO.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '**[1](#footref1)** æœ¬ä¹¦çš„èŒƒå›´ä¸åŒ…æ‹¬å¼•å¯¼è¯»è€…æ¨å¯¼ ELBOï¼Œä½†æˆ‘ä»¬é¼“åŠ±è¯»è€…å‚é˜…è¿›ä¸€æ­¥é˜…è¯»éƒ¨åˆ†ä¸­çš„æ–‡æœ¬ï¼Œä»¥è·å¾—å¯¹ ELBO æ›´å…¨é¢çš„æ¦‚è¿°ã€‚'
