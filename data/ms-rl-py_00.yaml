- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '**Reinforcement** **Learning** (**RL**) is a field of artificial intelligence
    used for creating self-learning autonomous agents. This book takes a pragmatic
    approach to RL and uses practical examples inspired by real-world business and
    industry problems to teach you about RL techniques.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）是人工智能的一个领域，用于创建自学习的自主智能体。本书采取务实的方法，通过真实的商业和行业问题中的实际例子来教授你强化学习技巧。'
- en: Starting with an overview of RL elements, you'll get to grips with Markov chains
    and Markov decision processes, which comprise the mathematical foundations of
    modeling an RL problem. You'll then cover Monte Carlo methods and **temporal**
    **difference** (**TD**) learning methods that are used for solving RL problems.
    Next, you'll learn about deep Q-learning, policy gradient algorithms, actor-critic
    methods, model-based methods, and multi-agent reinforcement learning. As you advance,
    you'll delve into many novel algorithms with advanced implementations using modern
    Python libraries. You'll also find out how to implement RL to solve real-world
    challenges faced in areas such as autonomous systems, supply chain management,
    games, finance, smart cities, and cybersecurity. Finally, you'll gain a clear
    understanding of which method to use and when, how to avoid common pitfalls, and
    how to overcome challenges faced in implementing RL.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从强化学习元素的概述开始，你将掌握马尔可夫链和马尔可夫决策过程（MDP），它们是建模强化学习问题的数学基础。接下来，你将学习蒙特卡罗方法和**时间差分**(**TD**)学习方法，它们被用于解决强化学习问题。然后，你将了解深度Q学习、策略梯度算法、演员-评论家方法、基于模型的方法和多智能体强化学习。随着学习的深入，你将探讨许多新颖的算法，并利用现代Python库实现高级功能。你还将了解如何实施强化学习来解决现实世界中的挑战，例如自主系统、供应链管理、游戏、金融、智慧城市和网络安全等领域的问题。最后，你将清楚了解该使用哪种方法以及何时使用，如何避免常见的陷阱，并克服在实施强化学习过程中遇到的挑战。
- en: By the end of this reinforcement learning book, you'll have mastered how to
    train and deploy your own RL agents for solving RL problems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本书的结尾，你将掌握如何训练和部署你自己的RL智能体，以解决强化学习问题。
- en: Who this book is for
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合谁阅读
- en: This book is for expert machine learning practitioners and deep learning researchers
    looking to implement advanced RL concepts in real-world projects. This book will
    also appeal to RL experts who want to tackle complex sequential decision-making
    problems through self-learning agents. Working knowledge of Python programming
    and machine learning along with prior experience RL is required.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适合有经验的机器学习从业者和深度学习研究人员，特别是那些希望在现实世界项目中实现高级强化学习概念的人。本书还将吸引那些希望通过自学习智能体解决复杂序列决策问题的强化学习专家。需要具备Python编程、机器学习基础知识和之前的强化学习经验。
- en: What this book covers
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容概述
- en: '[*Chapter 1*](B14160_01_Final_SK_ePub.xhtml#_idTextAnchor016), *Introduction
    to Reinforcement Learning*, provides an introduction to RL, gives motivating examples
    and success stories, and looks at RL applications in industry. It then gives fundamental
    definitions to refresh your mind on RL concepts and concludes with a section on
    software and hardware setup.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第一章*](B14160_01_Final_SK_ePub.xhtml#_idTextAnchor016)，*强化学习介绍*，提供了强化学习的介绍，给出激励性的例子和成功故事，并探讨了强化学习在行业中的应用。接着，书中给出了强化学习概念的基本定义，并以软件和硬件设置部分作为总结。'
- en: '[*Chapter 2*](B14160_02_Final_SK_ePub.xhtml#_idTextAnchor038), *Multi-Armed
    Bandits*, covers a rather simpler RL setting, that is, bandit problems without
    context, which have tremendous applications in industry as an alternative to the
    traditional A/B testing. The chapter also serves as an introduction to a very
    fundamental RL concept: exploration versus exploitation. We also solve a prototype
    online advertising case with four different methods.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第二章*](B14160_02_Final_SK_ePub.xhtml#_idTextAnchor038)，*多臂赌博机*，介绍了一个相对简单的强化学习（RL）设定，即没有上下文的赌博机问题，这在工业界有着巨大的应用前景，是传统A/B测试的替代方法。本章还作为对一个非常基础的强化学习概念——探索与利用（exploration
    versus exploitation）的介绍。我们还通过四种不同的方法解决了一个原型在线广告案例。'
- en: '[*Chapter 3*](B14160_03_Final_SK_ePub.xhtml#_idTextAnchor059), *Contextual
    Bandits*, takes the discussion on MABs to an advanced level by adding context
    to the decision-making process and involving deep neural networks in decision
    making. We adapt a real dataset from the US Census to an online advertising problem.
    We conclude the chapter with a section on the applications of bandit problems
    in industry and business.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第三章*](B14160_03_Final_SK_ePub.xhtml#_idTextAnchor059)，*上下文赌博者*，通过为决策过程添加上下文并引入深度神经网络参与决策，使多臂赌博机问题（MABs）达到了一个更高级的层次。我们将来自美国人口普查的真实数据集应用于在线广告问题。最后，我们通过讨论赌博问题在工业和商业中的应用来结束本章内容。'
- en: '[*Chapter 4*](B14160_04_Final_SK_ePub.xhtml#_idTextAnchor080), *Making of the
    Markov Decision Process*, builds the mathematical theory with which we model RL
    problems. We start with Markov chains, where we describe types of states, ergodicity,
    transitionary, and steady-state behavior. Then we go into Markov reward and decision
    processes. Along the way, we introduce return, discount, policy, and value functions,
    and Bellman optimality, which are key concepts in RL theory that will be frequently
    referred to in later chapters. We conclude the chapter with a discussion on partially
    observed Markov decision processes. Throughout the chapter, we use a grid world
    example to illustrate the concepts.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第四章*](B14160_04_Final_SK_ePub.xhtml#_idTextAnchor080)，*马尔可夫决策过程的构建*，构建了我们用来建模强化学习问题的数学理论。我们从马尔可夫链开始，描述状态的类型、遍历性、转移行为和稳态行为。接着我们讨论马尔可夫奖励过程和决策过程。在过程中，我们介绍了回报、折扣、策略和价值函数，以及贝尔曼最优性，这些都是强化学习理论中的关键概念，将在后续章节中频繁提及。最后，我们讨论了部分可观察马尔可夫决策过程。在整个章节中，我们使用一个网格世界的例子来说明这些概念。'
- en: '[*Chapter 5*](B14160_05_Final_SK_ePub.xhtml#_idTextAnchor106), *Solving the
    Reinforcement Learning Problem*, introduces DP methods, which are fundamental
    to understanding how to solve an MDP. Key concepts such as policy evaluation,
    policy iteration, and value iteration are introduced and illustrated. Throughout
    the chapter, we solve an example inventory replenishment problem. We conclude
    the chapter with a discussion on the issues with using DP in real-world examples.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第五章*](B14160_05_Final_SK_ePub.xhtml#_idTextAnchor106)，*解决强化学习问题*，介绍了动态规划（DP）方法，这些方法是理解如何解决马尔可夫决策过程（MDP）问题的基础。介绍并说明了诸如策略评估、策略迭代和价值迭代等关键概念。整个章节通过解决一个库存补货问题来进行演示。最后，我们讨论了在现实世界例子中使用动态规划时遇到的问题。'
- en: '[*Chapter 6*](B14160_06_Final_SK_ePub.xhtml#_idTextAnchor124), *Deep Q-Learning
    at Scale*, provides an introduction to deep RL and covers deep Q-learning end
    to end. We start with a discussion on why deep RL is needed, then introduce RLlib,
    a popular and scalable RL library. After introducing the case studies we will
    work with (one simple, one medium-difficulty, and one video game example), we
    will build deep Q-learning methods from fitted Q-iteration to DQN to Rainbow.
    Then we will go into more advanced topics on distributed DQN (APEX), continuous
    DQN, and a discussion on important hyperparameters to tune. For classical DQN,
    you will implement it in TensorFlow. For Rainbow, we will use RLlib.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第六章*](B14160_06_Final_SK_ePub.xhtml#_idTextAnchor124)，*大规模深度Q学习*，提供了深度强化学习的介绍，并涵盖了从头到尾的深度Q学习。我们首先讨论为什么需要深度强化学习，然后介绍流行且可扩展的RL库——RLlib。在介绍完将要使用的案例研究（一个简单的、一个中等难度的以及一个视频游戏例子）之后，我们将从拟合Q迭代、DQN到Rainbow构建深度Q学习方法。接着，我们将进入更高级的话题，讨论分布式DQN（APEX）、连续DQN，并讨论需要调整的重要超参数。对于经典的DQN，你将使用TensorFlow实现；而对于Rainbow，我们将使用RLlib。'
- en: '[*Chapter 7*](B14160_07_Final_SK_ePub.xhtml#_idTextAnchor147), *Policy-Based
    Methods*, introduces the second important class of RL methods: policy-based methods.
    You will first learn how they are different and why they are needed. We then go
    into the details of several state-of-the-art policy gradient and trust region
    methods. We conclude the chapter with Actor-Critic algorithms. We mostly rely
    on RLlib implementations of these algorithms and focus on how and when to use
    them rather than lengthy implementation details.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第七章*](B14160_07_Final_SK_ePub.xhtml#_idTextAnchor147)，*基于策略的方法*，介绍了强化学习方法的第二大类：基于策略的方法。你将首先了解它们与其他方法的不同之处以及它们的必要性。接着，我们将深入探讨几种最先进的策略梯度和信赖域方法。最后，我们将讨论演员-评论员算法。我们主要依赖RLlib对这些算法的实现，并关注如何以及何时使用这些算法，而不是详细的实现细节。'
- en: '[*Chapter 8*](B14160_08_Final_SK_ePub.xhtml#_idTextAnchor177), *Model-Based
    Methods*, shows what assumptions model-based methods make and what advantages
    they have over other methods. We also discuss the model behind the famous AlphaGo
    Zero. We conclude the chapter with an exercise that uses a model-based algorithm.
    The chapter includes a mix of using manual and RLlib implementations.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B14160_08_Final_SK_ePub.xhtml#_idTextAnchor177), *基于模型的方法*，展示了基于模型的方法所做的假设以及它们相较于其他方法的优势。我们还讨论了著名的AlphaGo
    Zero背后的模型。本章的最后，我们通过一个使用基于模型算法的练习来总结这一章。章节内容包括手动和RLlib实现的结合使用。'
- en: '[*Chapter 9*](B14160_09_Final_SK_ePub.xhtml#_idTextAnchor200), *Multi-Agent
    Reinforcement Learning*, gives you a framework to model multi-agent RL problems
    and introduces MADDPG to solve such problems. The chapter uses an RLlib MADDPG
    implementation.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B14160_09_Final_SK_ePub.xhtml#_idTextAnchor200), *多智能体强化学习*，为你提供了一个框架，用以建模多智能体RL问题，并介绍了MADDPG来解决此类问题。章节中使用了RLlib的MADDPG实现。'
- en: '[*Chapter 10*](B14160_10_Final_SK_ePub.xhtml#_idTextAnchor220), *Machine Teaching*,
    discusses the machine teaching approach to break down complex problems into smaller
    pieces and make them solvable. This approach is necessary for many real-life problems
    and you will learn practical tips and tricks for how to design an RL model and
    go beyond algorithm selection in solving RL problems.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B14160_10_Final_SK_ePub.xhtml#_idTextAnchor220), *机器教学*，讨论了机器教学方法，如何将复杂问题分解为更小的部分，并使其可解。该方法对于许多现实生活中的问题是必需的，你将学到一些实用的技巧，如何设计一个RL模型，并超越算法选择来解决RL问题。'
- en: '[*Chapter 11*](B14160_11_Final_SK_ePub.xhtml#_idTextAnchor239), *Generalization
    and Domain Randomization*, covers why partial observability and the sim2real gap
    are a problem, and how to overcome those by using LSTM-like models and domain
    randomization.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第11章*](B14160_11_Final_SK_ePub.xhtml#_idTextAnchor239), *泛化与领域随机化*，讨论了部分可观察性和sim2real差距为何成为问题，并介绍了如何通过使用LSTM-like模型和领域随机化来克服这些问题。'
- en: '[*Chapter 12*](B14160_12_Final_SK_ePub.xhtml#_idTextAnchor260), *Meta-Reinforcement
    Learning*, introduces approaches that allow us to use a single model for multiple
    tasks. As sample efficiency is a major problem in RL, this chapter exposes you
    to a very important future direction in RL.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第12章*](B14160_12_Final_SK_ePub.xhtml#_idTextAnchor260), *元强化学习*，介绍了使我们能够为多个任务使用单一模型的方法。由于样本效率是RL中的一个主要问题，本章让你了解了RL中的一个非常重要的未来方向。'
- en: '[*Chapter 13*](B14160_13_Final_SK_ePub.xhtml#_idTextAnchor276), *Other Advanced
    Topics*, introduces cutting-edge RL research. Many approaches discussed so far
    have certain assumptions and limitations. The topics discussed in this chapter
    address these limitations and give ideas about how to overcome them. At the end
    of this chapter, you will learn which approaches to look into when you hit the
    limitations of the algorithms we covered in earlier chapters.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第13章*](B14160_13_Final_SK_ePub.xhtml#_idTextAnchor276), *其他高级主题*，介绍了前沿的RL研究。到目前为止讨论的许多方法都有一定的假设和局限性。本章讨论的主题解决了这些局限性，并给出了如何克服它们的思路。在本章结束时，你将了解到当你遇到我们在前面章节中讨论的算法的局限性时，应该关注哪些方法。'
- en: '[*Chapter 14*](B14160_14_Final_SK_ePub.xhtml#_idTextAnchor306), *Autonomous
    Systems*, covers the potential of RL for creating real-life autonomous systems.
    We cover success stories and sample problems for autonomous robots and self-driving
    cars.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第14章*](B14160_14_Final_SK_ePub.xhtml#_idTextAnchor306), *自主系统*，探讨了RL在创建现实世界自主系统方面的潜力。我们涵盖了成功案例和自主机器人以及自动驾驶汽车的样本问题。'
- en: '[*Chapter 15*](B14160_15_Final_SK_ePub.xhtml#_idTextAnchor329), *Supply Chain
    Management*, gives you hands-on experience in inventory planning and bin packing
    problems. We model them as an RL problem and solve sample cases.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第15章*](B14160_15_Final_SK_ePub.xhtml#_idTextAnchor329), *供应链管理*，让你亲身体验库存规划和箱子装配问题。我们将这些问题建模为RL问题，并解决一些样本案例。'
- en: '[*Chapter 16*](B14160_16_Final_SK_ePub.xhtml#_idTextAnchor348), *Marketing,
    Personalization, and Finance*, covers RL applications in marketing, advertising,
    recommendation systems, and finance. This chapter gives you a broad understanding
    of how RL can be utilized in business, and what the opportunities and limitations
    are. In this chapter, we also go into examples of contextual multi-armed bandit
    problems.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第16章*](B14160_16_Final_SK_ePub.xhtml#_idTextAnchor348), *营销、个性化和金融*，涵盖了RL在营销、广告、推荐系统和金融中的应用。本章将帮助你广泛了解RL在商业中的应用，以及其机会与局限性。在本章中，我们还讨论了上下文多臂赌博机问题的例子。'
- en: '[*Chapter 17*](B14160_17_Final_SK_ePub.xhtml#_idTextAnchor365), *Smart City
    and Cybersecurity*, covers sample problems from the area of smart cities and cybersecurity,
    such as traffic control, service provision regulation, and intrusion detection.
    We also discuss how multi-agent approaches can be used in these applications.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第17章*](B14160_17_Final_SK_ePub.xhtml#_idTextAnchor365)，*智慧城市与网络安全*，涵盖了智慧城市和网络安全领域的示例问题，如交通控制、服务提供监管和入侵检测。我们还讨论了多智能体方法如何在这些应用中发挥作用。'
- en: '[*Chapter 18*](B14160_18_Final_SK_ePub.xhtml#_idTextAnchor388), *Challenges
    and Future Directions in Reinforcement Learning*, goes into the details of what
    these challenges are and what state-of-the-art research suggests to overcome them.
    This chapter teaches you how to assess the feasibility of the RL approach for
    a given problem.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第18章*](B14160_18_Final_SK_ePub.xhtml#_idTextAnchor388)，*强化学习的挑战与未来方向*，详细探讨了这些挑战是什么以及最前沿的研究提出了如何克服它们的建议。本章教你如何评估RL方法在特定问题中的可行性。'
- en: To get the most out of this book
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了充分利用本书
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code via the GitHub repository (link available
    in the next section). Doing so will help you avoid any potential errors related
    to the copying and pasting of code.**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你使用的是本书的电子版，建议你手动输入代码，或者通过GitHub仓库（下节中会提供链接）访问代码。这样可以避免因复制粘贴代码而导致的潜在错误。**'
- en: Download the example code files
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[www.packt.com](http://www.packt.com)账户中下载本书的示例代码文件。如果你在其他地方购买了本书，可以访问[www.packtpub.com/support](http://www.packtpub.com/support)，注册后将文件直接发送给你。
- en: 'You can download the code files by following these steps:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照以下步骤下载代码文件：
- en: Log in or register at [www.packt.com](http://www.packt.com).
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录或注册账号，访问[www.packt.com](http://www.packt.com)。
- en: Select the **Support** tab.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**支持**标签。
- en: Click on **Code Downloads**.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: Enter the name of the book in the **Search** box and follow the onscreen instructions.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名，并按照屏幕上的指示操作。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，请确保使用以下最新版本的工具解压或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows下的WinRAR/7-Zip
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac下的Zipeg/iZip/UnRarX
- en: 7-Zip/PeaZip for Linux
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux下的7-Zip/PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python](https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包也托管在GitHub上，地址为[https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python](https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python)。如果代码有更新，更新内容将会同步到现有的GitHub仓库中。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了其他丰富书籍和视频的代码包，地址为[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。赶快去看看吧！
- en: Download the color images
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781838644147_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838644147_ColorImages.pdf).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个PDF文件，其中包含本书中使用的截图/图表的彩色图像。你可以在此下载：[https://static.packt-cdn.com/downloads/9781838644147_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838644147_ColorImages.pdf)。
- en: Conventions used
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了一些文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: "Install NVIDIA Modprobe, for example, for Ubuntu,
    using `sudo apt-get install nvidia-modprobe`."'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`：表示文本中的代码词、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter用户名。例如：“例如，使用`sudo
    apt-get install nvidia-modprobe`命令安装NVIDIA Modprobe。”'
- en: 'A block of code is set as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块如下所示：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望引起您对代码块的特定部分的注意时，相关行或条目将以粗体显示：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Tips or important notes
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 提示或重要说明
- en: Appear like this.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Appear like this.
- en: Get in touch
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    mention the book title in the subject of your message and email us at [customercare@packtpub.com](mailto:customercare@packtpub.com).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果您对本书的任何方面有疑问，请在邮件主题中提及书名，并发送邮件至 [customercare@packtpub.com](mailto:customercare@packtpub.com)。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽一切努力确保内容的准确性，但错误确实会发生。如果您发现了本书中的错误，请向我们报告。请访问 [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)，选择您的书籍，点击勘误提交表单链接，并输入详细信息。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们作品的任何形式的非法拷贝，请向我们提供位置地址或网站名称。请通过链接 [copyright@packt.com](mailto:copyright@packt.com)
    联系我们。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您对某个您擅长的主题感兴趣，并且有意撰写或贡献一本书，请访问 [authors.packtpub.com](http://authors.packtpub.com)。'
- en: Reviews
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评论
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论。在阅读和使用本书后，为什么不在购买它的网站上留下评论呢？潜在的读者可以看到并使用您的客观意见来做购买决策，我们在 Packt 可以了解您对我们产品的看法，而我们的作者可以看到您对他们书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packt.com](http://packt.com).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 Packt 的更多信息，请访问 [packt.com](http://packt.com)。
