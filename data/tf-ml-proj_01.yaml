- en: Overview of TensorFlow and Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 和机器学习概述
- en: TensorFlow is a popular library for implementing machine learning-based solutions.
    It includes a low-level API known as TensorFlow core and many high-level APIs,
    including two of the most popular ones, known as TensorFlow Estimators and Keras.
    In this chapter, we will learn about the basics of TensorFlow and build a machine
    learning model using logistic regression to classify handwritten digits as an
    example.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是一个流行的库，用于实现基于机器学习的解决方案。它包括一个低级 API，称为 TensorFlow 核心，以及许多高级 API，其中两个最受欢迎的
    API 被称为 TensorFlow Estimators 和 Keras。在本章中，我们将学习 TensorFlow 的基础知识，并使用逻辑回归构建一个机器学习模型，以手写数字分类为例。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: 'TensorFlow core:'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 核心：
- en: Tensors in TensorFlow core
  id: totrans-4
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 核心中的张量
- en: Constants
  id: totrans-5
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常量
- en: Placeholders
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 占位符
- en: Operations
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作
- en: Tensors from Python objects
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自 Python 对象的张量
- en: Variables
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量
- en: Tensors from library functions
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自库函数的张量
- en: 'Computation graphs:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算图：
- en: Lazy loading and execution order
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟加载和执行顺序
- en: Graphs on multiple devices – CPU and GPGPU
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多设备上的图 – CPU 和 GPGPU
- en: Working with multiple graphs
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多个图
- en: Machine learning, classification, and logistic regression
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习、分类和逻辑回归
- en: Logistic regression examples in TensorFlow
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 中的逻辑回归示例
- en: Logistic regression examples in Keras
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 中的逻辑回归示例
- en: You can follow the code examples in this chapter by using the Jupyter Notebook
    named `ch-01_Overview_of_TensorFlow_and_Machine_Learning.ipynb` that's included
    in the code bundle.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用名为 `ch-01_Overview_of_TensorFlow_and_Machine_Learning.ipynb` 的 Jupyter
    Notebook 来跟随本章中的代码示例，该 Notebook 已包含在代码包中。
- en: What is TensorFlow?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 TensorFlow？
- en: '**TensorFlow** is a popular open source library that''s used for implementing
    machine learning and deep learning. It was initially built at Google for internal
    consumption and was released publicly on November 9, 2015\. Since then, TensorFlow
    has been extensively used to develop machine learning and deep learning models
    in several business domains.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow** 是一个流行的开源库，广泛用于实现机器学习和深度学习。它最初在 Google 内部构建，后来于 2015 年 11 月 9
    日公开发布。从那时起，TensorFlow 被广泛用于开发多个业务领域的机器学习和深度学习模型。'
- en: 'To use TensorFlow in our projects, we need to learn how to program using the
    TensorFlow API. TensorFlow has multiple APIs that can be used to interact with
    the library. The TensorFlow APIs are divided into two levels:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的项目中使用 TensorFlow，我们需要学习如何使用 TensorFlow API 编程。TensorFlow 有多个 API 可供与库进行交互。TensorFlow
    的 API 分为两级：
- en: '**Low-level API**: The API known as TensorFlow core provides fine-grained lower
    level functionality. Because of this, this low-level API offers complete control
    while being used on models. We will cover TensorFlow core in this chapter.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低级 API**：称为 TensorFlow 核心的 API 提供了细粒度的低级功能。因此，这个低级 API 在使用模型时提供了完全控制。我们将在本章中讨论
    TensorFlow 核心。'
- en: '**High-level API**: These APIs provide high-level functionalities that have
    been built on TensorFlow core and are comparatively easier to learn and implement.
    Some high-level APIs include Estimators, Keras, TFLearn, TFSlim, and Sonnet. We
    will also cover Keras in this chapter.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级 API**：这些 API 提供了建立在 TensorFlow 核心上的高级功能，比较容易学习和实现。一些高级 API 包括 Estimators、Keras、TFLearn、TFSlim
    和 Sonnet。本章中我们也将讨论 Keras。'
- en: The TensorFlow core
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 核心
- en: The **TensorFlow core** is the lower-level API on which the higher-level TensorFlow
    modules are built. In this section, we will go over a quick overview of TensorFlow
    core and learn about the basic elements of TensorFlow.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow 核心** 是构建更高层 TensorFlow 模块的低级 API。在本节中，我们将简要回顾 TensorFlow 核心，并了解
    TensorFlow 的基本元素。'
- en: Tensors
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量
- en: '**Tensors** are the basic components in TensorFlow. A tensor is a multidimensional
    collection of data elements. It is generally identified by shape, type, and rank. **Rank** refers
    to the number of dimensions of a tensor, while **shape** refers to the size of each
    dimension. You may have seen several examples of tensors before, such as in a
    zero-dimensional collection (also known as a scalar), a one-dimensional collection (also
    known as a vector), and a two-dimensional collection (also known as a matrix).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**张量** 是 TensorFlow 中的基本组件。张量是一个多维数据元素集合。它通常由形状、类型和秩来标识。**秩** 指的是张量的维度数，而 **形状**
    指的是每个维度的大小。你可能之前见过一些张量的例子，比如零维集合（也称为标量）、一维集合（也称为向量）和二维集合（也称为矩阵）。'
- en: A scalar value is a tensor of rank 0 and shape []. A vector, or a one-dimensional
    array, is a tensor of rank 1 and shape [`number_of_columns`] or [`number_of_rows`].
    A matrix, or a two-dimensional array, is a tensor of rank 2 and shape [`number_of_rows`,
    `number_of_columns`]. A three-dimensional array is a tensor of rank 3\. In the
    same way, an n-dimensional array is a tensor of rank n.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 标量值是一个秩为0且形状为[]的张量。向量或一维数组是一个秩为1且形状为[`列数`]或[`行数`]的张量。矩阵或二维数组是一个秩为2且形状为[`行数`,
    `列数`]的张量。三维数组是一个秩为3的张量。以此类推，n维数组是一个秩为n的张量。
- en: A tensor can store data of one type in all of its dimensions, and the data type
    of a tensor is the same as the data type of its elements.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一个张量可以在其所有维度中存储相同类型的数据，且张量的数据类型与其元素的数据类型相同。
- en: The data types that can be found in the TensorFlow library are described at
    the following link: [https://www.tensorflow.org/api_docs/python/tf/DType](https://www.tensorflow.org/api_docs/python/tf/DType).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在TensorFlow库中找到的数据类型在以下链接中有所描述：[https://www.tensorflow.org/api_docs/python/tf/DType](https://www.tensorflow.org/api_docs/python/tf/DType)。
- en: 'The following are the most commonly used data types in TensorFlow:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是TensorFlow中最常用的数据类型：
- en: '| **TensorFlow Python API data type** | **Description** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **TensorFlow Python API数据类型** | **描述** |'
- en: '| `tf.float16` | 16-bit floating point (half-precision) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `tf.float16` | 16位浮点数（半精度） |'
- en: '| `tf.float32` | 32-bit floating point (single-precision) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `tf.float32` | 32位浮点数（单精度） |'
- en: '| `tf.float64` | 64-bit floating point (double-precision) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `tf.float64` | 64位浮点数（双精度） |'
- en: '| `tf.int8` | 8-bit integer (signed) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `tf.int8` | 8位整数（有符号） |'
- en: '| `tf.int16` | 16-bit integer (signed) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `tf.int16` | 16位整数（有符号） |'
- en: '| `tf.int32` | 32-bit integer (signed) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `tf.int32` | 32位整数（有符号） |'
- en: '| `tf.int64` | 64-bit integer (signed) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `tf.int64` | 64位整数（有符号） |'
- en: Use TensorFlow data types for defining tensors instead of native data types
    from Python or data types from NumPy.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow数据类型来定义张量，而不是使用Python原生数据类型或NumPy的数据类型。
- en: 'Tensors can be created in the following ways:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 张量可以通过以下几种方式创建：
- en: By defining constants, operations, and variables, and passing the values to
    their constructor
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过定义常量、操作和变量，并将值传递给它们的构造函数
- en: By defining placeholders and passing the values to `session.run()`
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '通过定义占位符并将值传递给`session.run()` '
- en: By converting Python objects, such as scalar values, lists, NumPy arrays, and
    pandas DataFrames, with the `tf.convert_to_tensor()` function
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将Python对象（如标量值、列表、NumPy数组和pandas DataFrame）转换为张量，使用`tf.convert_to_tensor()`函数
- en: Let's explore different ways of creating Tensors.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索不同的创建张量的方式。
- en: Constants
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常量
- en: 'The constant valued tensors are created using the `tf.constant()` function,
    and has the following definition:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 常量值张量是通过`tf.constant()`函数创建的，具有以下定义：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s create some constants with the following code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用以下代码创建一些常量：
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s take a look at the preceding code in detail:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看前面的代码：
- en: The first line of code defines a constant tensor, `const1`, stores a value of `34`,
    and names it `x1`.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一行代码定义了一个常量张量`const1`，存储值`34`，并命名为`x1`。
- en: The second line of code defines a constant tensor, `const2`, stores a value
    of `59.0`, and names it `y1`.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二行代码定义了一个常量张量`const2`，存储了值`59.0`，并命名为`y1`。
- en: The third line of code defines the data type as `tf.float16` for `const3`. Use
    the `dtype` parameter or place the data type as the second argument to denote
    the data type.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三行代码为`const3`定义了数据类型`tf.float16`。使用`dtype`参数或将数据类型作为第二个参数来指定数据类型。
- en: 'Let''s print the constants `const1`, `const2`, and `const3`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印常量`const1`、`const2`和`const3`：
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When we print these constants, we get the following output:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们打印这些常量时，我们将得到以下输出：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Upon printing the previously defined tensors, we can see that the data types
    of `const1` and `const2` are automatically deduced by TensorFlow.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 打印之前定义的张量时，我们可以看到`const1`和`const2`的数据类型由TensorFlow自动推断。
- en: 'To print the values of these constants, we can execute them in a TensorFlow
    session with the `tfs.run()` command:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要打印这些常量的值，我们可以在TensorFlow会话中执行它们，使用`tfs.run()`命令：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will see the following output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Operations
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作
- en: 'The TensorFlow library contains several built-in operations that can be applied on
    tensors. An operation node can be defined by passing input values and saving the
    output in another tensor. To understand this better, let''s define two operations, `op1` and `op2`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow库包含几个内置的操作，可以应用于张量。操作节点可以通过传递输入值并将输出保存在另一个张量中来定义。为了更好地理解这一点，我们来定义两个操作，`op1`和`op2`：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s print `op1` and `op2`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印 `op1` 和 `op2`：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows, and shows that `op1` and `op2` are defined as tensors:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下，显示 `op1` 和 `op2` 被定义为张量：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To print the output from executing these operations, the `op1` and `op2` tensors
    have to be executed in a TensorFlow session:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要打印执行这些操作后的输出，必须在 TensorFlow 会话中执行 `op1` 和 `op2` 张量：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Some of the built-in operations of TensorFlow include arithmetic operations,
    math functions, and complex number operations.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 的一些内置操作包括算术运算、数学函数和复数运算。
- en: Placeholders
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 占位符
- en: 'While constants store the value at the time of defining the tensor, placeholders
    allow you to create empty tensors so that the values can be provided at runtime.
    The TensorFlow library provides the `tf.placeholder()` function with the following
    signature to create placeholders:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然常量在定义张量时存储值，占位符允许你创建空张量，以便在运行时提供值。TensorFlow 库提供了一个名为 `tf.placeholder()` 的函数，以下是它的签名，用于创建占位符：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As an example, let''s create two placeholders and print them:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个示例，我们来创建两个占位符并打印它们：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following output shows that each placeholder has been created as a tensor:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示每个占位符已被创建为一个张量：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s define an operation using these placeholders:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这些占位符定义一个操作：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In TensorFlow, shorthand symbols can be used for various operations. In the
    preceding code, `p1 * p2` is shorthand for `tf.multiply(p1,p2)`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，可以使用简写符号进行各种操作。在前面的代码中，`p1 * p2` 是 `tf.multiply(p1, p2)` 的简写：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding command runs `mult_op` in the TensorFlow session and feeds the
    values dictionary (the second argument to the `run()` operation) with the values
    for `p1` and `p2`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令在 TensorFlow 会话中运行 `mult_op`，并通过值字典（`run()` 操作的第二个参数）为 `p1` 和 `p2` 提供值。
- en: 'The output is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can also specify the values dictionary by using the `feed_dict` parameter
    in the `run()` operation:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过在 `run()` 操作中使用 `feed_dict` 参数来指定值字典：
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s look at one final example, which is of a vector being fed to the same
    operation:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个最终的示例，展示一个向量被传递到同一个操作中的情况：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The elements of the two input vectors are multiplied in an element-wise fashion.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 两个输入向量的元素按元素逐一相乘。
- en: Tensors from Python objects
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 Python 对象创建张量
- en: 'Tensors can be created from Python objects such as lists, NumPy arrays, and
    pandas DataFrames. To create tensors from Python objects, use the `tf.convert_to_tensor()`
    function with the following definition:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 张量可以通过 Python 对象（如列表、NumPy 数组和 pandas DataFrame）创建。要从 Python 对象创建张量，请使用 `tf.convert_to_tensor()`
    函数，以下是它的定义：
- en: '[PRE21]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s practice doing this by creating some tensors and printing their definitions
    and values:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过创建一些张量并打印它们的定义和值来进行练习：
- en: 'Define a 0-D tensor:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个零维张量：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Define a 1-D tensor:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个一维张量：
- en: '[PRE24]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Define a 2-D tensor:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个二维张量：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Define a 3-D tensor:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个三维张量：
- en: '[PRE28]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE29]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Variables
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量
- en: In the previous sections, we learned how to define tensor objects of different
    types, such as constants, operations, and placeholders. The values of parameters
    need to be held in an updatable memory location while building and training models
    with TensorFlow. Such updatable memory locations for tensors are known as variables
    in TensorFlow.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了如何定义不同类型的张量对象，例如常量、操作和占位符。在使用 TensorFlow 构建和训练模型时，参数的值需要保存在可更新的内存位置。这些用于张量的可更新内存位置在
    TensorFlow 中被称为变量。
- en: To summarize this, TensorFlow variables are tensor objects in that their values
    can be modified during the execution of the program.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，TensorFlow 变量是张量对象，因为它们的值可以在程序执行过程中被修改。
- en: 'Although `tf.Variable` seems to be similar to `tf.placeholder`, they have certain
    differences. These are listed in the following table:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `tf.Variable` 看起来与 `tf.placeholder` 相似，但它们之间有一些差异。以下表格列出了这些差异：
- en: '| `tf.placeholder` | `tf.Variable` |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `tf.placeholder` | `tf.Variable` |'
- en: '| `tf.placeholder` defines the input data that does not get updated over time
    | `tf.Variable` defines values that get updated over time |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `tf.placeholder` 定义了不随时间更新的输入数据 | `tf.Variable` 定义了随时间更新的值 |'
- en: '| `tf.placeholder` does not need to be provided with an initial value at the
    time of definition | `tf.Variable` needs an initial value to be provided at the
    time of definition |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `tf.placeholder` 在定义时不需要提供初始值 | `tf.Variable` 在定义时需要提供初始值 |'
- en: 'In TensorFlow, a variable can be created with the API function `tf.Variable()`.
    Let''s look at an example of using placeholders and variables and create the following
    model in TensorFlow:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中，变量可以通过API函数`tf.Variable()`创建。让我们看一个使用占位符和变量的例子，并在TensorFlow中创建以下模型：
- en: '![](img/276d3b44-1c56-4249-8e14-0b3625e49ba8.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/276d3b44-1c56-4249-8e14-0b3625e49ba8.png)'
- en: 'Define the model parameters `w` and `b` as variables with the initial values
    `[.3]` and `[-0.3]`:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型参数`w`和`b`定义为变量，初始值分别为`[.3]`和`[-0.3]`：
- en: '[PRE30]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Define the input placeholder `x` and the output operation node `y`:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入占位符`x`和输出操作节点`y`：
- en: '[PRE31]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Print the variables and placeholders `w`, `v`, `x`, and `y`:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印变量和占位符`w`、`v`、`x`和`y`：
- en: '[PRE32]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output depicts the type of nodes as `Variable`, `Placeholder`, or operation
    node, as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输出描绘了节点的类型，如`Variable`、`Placeholder`或操作节点，如下所示：
- en: '[PRE33]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The preceding output indicates that `x` is a `Placeholder` tensor, `y` is an
    operation tensor, and that `w` and `b` are variables with a shape of `(1,)` and
    a data type of `float32`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出表明，`x`是一个`Placeholder`张量，`y`是一个操作张量，`w`和`b`是具有形状`(1,)`和数据类型`float32`的变量。
- en: The variables in a TensorFlow session have to be initialized before they can
    be used. We can either initialize a single variable by running its initializer
    operation or we can initialize all or a group of variables.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow会话中，变量必须在使用之前进行初始化。我们可以通过运行其初始化操作来初始化单个变量，也可以初始化所有或一组变量。
- en: 'For example, to initialize the `w` variable, we can use the following code:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要初始化`w`变量，可以使用以下代码：
- en: '[PRE34]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'TensorFlow provides a convenient function that can initialize all of the variables:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow提供了一个方便的函数，可以初始化所有变量：
- en: '[PRE35]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: TensorFlow also provides the `tf.variables_initializer()` function so that you
    can initialize a specific set of variables.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow还提供了`tf.variables_initializer()`函数，可以初始化一组特定的变量。
- en: 'The global convenience function for initializing these variables can be executed
    in an alternative way. Instead of executing inside the `run()` function of a session
    object, the run function of the object returned by the initializer function itself
    can be executed:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化这些变量的全局便利函数可以以另一种方式执行。与在会话对象的`run()`函数内部执行不同，可以直接执行由初始化函数返回的对象的运行函数：
- en: '[PRE36]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'After the variables have been initialized, execute the model to get the output
    for the input values of `x = [1,2,3,4]`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在变量初始化后，执行模型以获取输入值`x = [1,2,3,4]`的输出：
- en: '[PRE37]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE38]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Tensors generated from library functions
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从库函数生成的张量
- en: TensorFlow provides various functions to generate tensors with pre-populated
    values. The generated values from these functions can be stored in a constant
    or variable tensor. Such generated values can also be provided to the tensor constructor
    at the time of initialization.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow提供了各种函数来生成具有预填充值的张量。这些函数生成的值可以存储在常量或变量张量中，这些生成的值也可以在初始化时提供给张量构造函数。
- en: 'As an example, let''s generate a 1-D tensor that''s been pre-populated with
    `100` zeros:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，生成一个预先填充了`100`个零的1维张量：
- en: '[PRE39]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Some of the TensorFlow library functions that populate these tensors with different
    values at the time of their definition are listed as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow库中的一些函数会在定义时用不同的值填充这些张量，列举如下：
- en: Populating all of the elements of a tensor with similar values: `tf.ones_like()`, `tf.ones()`,` tf.fill()`, `tf.zeros()`,
    and`tf.zeros_like()`
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用相同的值填充张量的所有元素：`tf.ones_like()`、`tf.ones()`、`tf.fill()`、`tf.zeros()`和`tf.zeros_like()`
- en: Populating tensors with sequences: `tf.range()`,and `tf.lin_space()`
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用序列填充张量：`tf.range()`和`tf.lin_space()`
- en: Populating tensors with a probability distribution: `tf.random_uniform()`, `tf.random_normal()`, `tf.random_gamma()`,and `tf.truncated_normal()`
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用概率分布填充张量：`tf.random_uniform()`、`tf.random_normal()`、`tf.random_gamma()`和`tf.truncated_normal()`
- en: Obtaining variables with the tf.get_variable()
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`tf.get_variable()`获取变量
- en: If a variable is defined with a name that has already been used for another
    variable, then an exception is thrown by TensorFlow. The `tf.get_variable()` function
    makes it convenient and safe to create a variable in place of using the `tf.Variable()` function.
    The `tf.get_variable()` function returns a variable that has been defined with
    a given name. If the variable with the given name does not exist, then it will
    create the variable with the specified initializer and shape.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个变量的名称已被另一个变量使用，则TensorFlow会抛出异常。`tf.get_variable()`函数提供了一种方便且安全的方式来创建变量，取代使用`tf.Variable()`函数。`tf.get_variable()`函数返回一个已定义的变量，如果给定名称的变量不存在，则会使用指定的初始化器和形状创建该变量。
- en: 'Consider the following example:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑以下示例：
- en: '[PRE40]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The initializer can either be a list of values or another tensor. An initializer
    can also be one of the built-in initializers. Some of these are as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化器可以是值的列表或另一个张量。初始化器还可以是内置初始化器之一，部分初始化器如下：
- en: '`tf.ones_initializer`'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.ones_initializer`'
- en: '`tf.constant_initializer`'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.constant_initializer`'
- en: '`tf.zeros_initializer`'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.zeros_initializer`'
- en: '`tf.truncated_normal_initializer`'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.truncated_normal_initializer`'
- en: '`tf.random_normal_initializer`'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.random_normal_initializer`'
- en: '`tf.random_uniform_initializer`'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.random_uniform_initializer`'
- en: '`tf.uniform_unit_scaling_initializer`'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.uniform_unit_scaling_initializer`'
- en: '`tf.orthogonal_initializer`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.orthogonal_initializer`'
- en: The `tf.get_variable()` function only returns the global variables when the
    code is run across multiple machines in distributed TensorFlow. The local variables
    can be retrieved by using the `tf.get_local_variable()` function.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.get_variable()`函数仅在跨多个机器运行的分布式TensorFlow中返回全局变量。可以通过`tf.get_local_variable()`函数来检索本地变量。'
- en: '**Sharing or reusing variables**: Getting variables that have already been
    defined promotes reuse. However, an exception will be thrown if the reuse flags
    are not set by using `tf.variable_scope.reuse_variable()` or `tf.variable.scope(reuse=True)`.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**共享或重用变量**：获取已经定义的变量可以促进重用。然而，如果没有通过`tf.variable_scope.reuse_variable()`或`tf.variable.scope(reuse=True)`设置重用标志，系统将抛出异常。'
- en: 'Now that we have learned how to define tensors, constants, operations, placeholders,
    and variables, let''s learn about the next level of abstraction in TensorFlow
    that combines these basic elements to form a basic unit of computation: the computation
    graph.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学习了如何定义张量、常量、操作、占位符和变量，接下来让我们学习TensorFlow中的更高级别的抽象，它将这些基本元素组合在一起形成计算的基本单元：计算图。
- en: Computation graph
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算图
- en: A **computation graph** is the basic unit of computation in TensorFlow. A computation
    graph consists of nodes and edges. Each node represents an instance of `tf.Operation`,
    while each edge represents an instance of `tf.Tensor` that gets transferred between
    the nodes.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算图**是TensorFlow中计算的基本单元。计算图由节点和边组成。每个节点表示一个`tf.Operation`的实例，而每条边代表一个`tf.Tensor`的实例，数据在节点之间传输。'
- en: A model in TensorFlow contains a computation graph. First, you must create the
    graph with the nodes representing variables, constants, placeholders, and operations,
    and then provide the graph to the TensorFlow execution engine. The TensorFlow
    execution engine finds the first set of nodes that it can execute. The execution
    of these nodes starts the execution of the nodes that follow the sequence of the
    computation graph.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow中的模型包含计算图。首先，您必须创建包含表示变量、常量、占位符和操作的节点的图，然后将该图提供给TensorFlow执行引擎。TensorFlow执行引擎会找到它可以执行的第一组节点。执行这些节点会启动后续节点的执行，遵循计算图的顺序。
- en: 'Thus, TensorFlow-based programs are made up of performing two types of activities
    on computation graphs:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基于TensorFlow的程序由在计算图上执行的两种活动组成：
- en: Defining the computation graph
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义计算图
- en: Executing the computation graph
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行计算图
- en: 'A TensorFlow program starts execution with a default graph. Unless another
    graph is explicitly specified, a new node gets implicitly added to the default
    graph. Explicit access to the default graph can be obtained using the following
    command:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 一个TensorFlow程序在默认图中开始执行。除非显式指定另一个图，否则新节点会隐式地添加到默认图中。可以使用以下命令显式访问默认图：
- en: '[PRE41]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'For example, the following computation graph represents the addition of three
    inputs to produce the output, that is, ![](img/14e21277-f407-42a8-a84f-64349368adf2.png):'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下计算图表示将三个输入相加以产生输出，即 ![](img/14e21277-f407-42a8-a84f-64349368adf2.png)：
- en: '![](img/8fdf5a9c-c960-445b-9059-3863ee9eb841.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8fdf5a9c-c960-445b-9059-3863ee9eb841.png)'
- en: In TensorFlow, the add operation node in the preceding diagram would correspond
    to the code `y = tf.add( x1 + x2 + x3 )`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，前面示意图中的加法操作节点对应的代码是 `y = tf.add( x1 + x2 + x3 )`。
- en: The variables, constants, and placeholders get added to the graph as and when
    they are created. After defining the computation graph, a session object is instantiated
    that *executes* the operation objects and *evaluates* the tensor objects.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 变量、常量和占位符在创建时会被添加到图中。定义计算图后，会话对象被实例化，它会*执行*操作对象并*评估*张量对象。
- en: 'Let''s define and execute a computation graph to calculate ![](img/b44e70e9-36d0-4a12-9e1d-42496c5e860d.png),
    just like we saw in the preceding example:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义并执行一个计算图来计算 ![](img/b44e70e9-36d0-4a12-9e1d-42496c5e860d.png)，就像我们在前面的示例中看到的那样：
- en: '[PRE42]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Creating and using a session in the `with` block ensures that the session is
    automatically closed when the block is finished. Otherwise, the session has to
    be explicitly closed with the `tfs.close()` command, where `tfs` is the session
    name.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `with` 块中创建并使用会话可以确保在块执行完成后会话自动关闭。否则，必须通过 `tfs.close()` 命令显式关闭会话，其中 `tfs`
    是会话名称。
- en: The order of execution and lazy loading
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行顺序与懒加载
- en: The nodes in a computation graph are executed in their order of dependency.
    If node *x* depends on node *y*, then *x* is executed before *y *when the execution
    of *y* is requested. A node is only executed if either the node itself or another
    node depending on it is invoked for execution. This execution philosophy is known
    as lazy loading. As the name implies, the node objects are not instantiated and
    initialized until they are actually required.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 计算图中的节点按照依赖关系的顺序执行。如果节点 *x* 依赖于节点 *y*，那么在请求执行 *y* 时，*x* 会在 *y* 之前执行。只有当节点本身或依赖于它的其他节点被调用执行时，节点才会被执行。这种执行哲学被称为懒加载。顾名思义，节点对象只有在实际需要时才会实例化和初始化。
- en: 'Often, it is necessary to control the order of the execution of the nodes in
    a computation graph. This can be done with the `tf.Graph.control_dependencies()` function.
    For example, if the graph has the nodes `l`*,* `m`*,* `n`*,* and `o`, and we want
    to execute `n` and `o` before `l` and `m`, then we would use the following code:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，需要控制计算图中节点的执行顺序。这可以通过 `tf.Graph.control_dependencies()` 函数来完成。例如，如果图中有节点
    `l`、`m`、`n` 和 `o`，并且我们希望在执行 `l` 和 `m` 之前执行 `n` 和 `o`，那么我们可以使用以下代码：
- en: '[PRE43]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This makes sure that any node in the preceding `with` block is executed after
    nodes `n` and `o` have been executed.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保了在前面的 `with` 块中，任何节点都会在节点 `n` 和 `o` 执行之后执行。
- en: Executing graphs across compute devices – CPU and GPGPU
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨计算设备执行图 – CPU 和 GPGPU
- en: 'A graph can be partitioned into several parts, and each part can be placed
    and executed on different devices, such as a CPU or GPU. All of the devices that
    are available for graph execution can be listed with the following command:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以被划分为几个部分，每个部分可以在不同的设备上进行放置和执行，例如 CPU 或 GPU。所有可用于图执行的设备可以通过以下命令列出：
- en: '[PRE44]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output is listed as follows (the output for your machine will be different
    because this will depend on the available compute devices in your specific system):'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示（由于依赖于您系统中可用的计算设备，您的机器输出将有所不同）：
- en: '[PRE45]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The devices in TensorFlow are identified with the string `/device:<device_type>:<device_idx>`.
    In the last output, `CPU` and `GPU` denote the device type, and `0` denotes the
    device index.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 中的设备通过字符串 `/device:<device_type>:<device_idx>` 来标识。在最后的输出中，`CPU`
    和 `GPU` 表示设备类型，`0` 表示设备索引。
- en: One thing to note about the last output is that it shows only one CPU, whereas
    our computer has 8 CPUs. The reason for this is that TensorFlow implicitly distributes
    the code across the CPU units and thus, by default, `CPU:0` denotes all of the
    CPUs available to TensorFlow. When TensorFlow starts executing graphs, it runs
    the independent paths within each graph in a separate thread, with each thread
    running on a separate CPU. We can restrict the number of threads used for this
    purpose by changing the number of `inter_op_parallelism_threads`. Similarly, if,
    within an independent path, an operation is capable of running on multiple threads,
    TensorFlow will launch that specific operation on multiple threads. The number
    of threads in this pool can be changed by setting the number of `intra_op_parallelism_threads`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 关于最后一个输出需要注意的一点是，它只显示了一个 CPU，而我们的计算机有 8 个 CPU。原因在于 TensorFlow 会隐式地将代码分配到 CPU
    单元，因此默认情况下，`CPU:0`表示所有可用的 CPU。当 TensorFlow 开始执行图时，它会在每个图的独立路径中运行在不同线程上，每个线程运行在不同的
    CPU 上。我们可以通过更改`inter_op_parallelism_threads`来限制用于此目的的线程数。类似地，如果在独立路径中某个操作能够在多个线程上运行，TensorFlow
    会在多个线程上启动该操作。这个线程池中的线程数可以通过设置`intra_op_parallelism_threads`来更改。
- en: Placing graph nodes on specific compute devices
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将图节点放置在特定的计算设备上
- en: 'To enable the logging of variable placement by defining a config object, set
    the `log_device_placement` property to `true`, and then pass this `config` object
    to the session as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 通过定义一个配置对象来启用变量放置的日志记录，将`log_device_placement`属性设置为`true`，然后将这个`config`对象传递给会话，如下所示：
- en: '[PRE46]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output from the console window of the Jupyter Notebook is listed as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook 控制台窗口的输出如下所示：
- en: '[PRE47]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Thus, by default, TensorFlow creates the variable and operations nodes on a
    device so that it can get the highest performance. These variables and operations
    can be placed on specific devices by using the `tf.device()` function. Let''s
    place the graph on the CPU:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，默认情况下，TensorFlow 会在一个设备上创建变量和操作节点，以便获得最高的性能。这些变量和操作可以通过使用`tf.device()`函数将其放置在特定设备上。我们来将图放置在
    CPU 上：
- en: '[PRE48]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In the Jupyter console, we can see that the variables have been placed on the
    CPU and that execution also takes place on the CPU:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter 控制台中，我们可以看到变量已被放置在 CPU 上，并且执行也发生在 CPU 上：
- en: '[PRE49]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Simple placement
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单放置
- en: 'TensorFlow follows the following rules for placing the variables on devices:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 遵循以下规则来将变量放置在设备上：
- en: '[PRE50]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Dynamic placement
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态放置
- en: The `tf.device()` function can be provided with a function name in place of
    a device string. If a function name is provided, then the function has to return
    the device string. This way of providing a device string through a custom function
    allows complex algorithms to be used for placing the variables on different devices.
    For example, TensorFlow provides a round robin device setter function in `tf.train.replica_device_setter()`.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.device()`函数可以通过提供函数名称来替代设备字符串。如果提供了函数名称，则该函数必须返回设备字符串。通过自定义函数提供设备字符串的方式，可以使用复杂的算法来将变量放置在不同的设备上。例如，TensorFlow
    提供了一个轮询设备设置函数`tf.train.replica_device_setter()`。'
- en: Soft placement
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软放置
- en: 'If a TensorFlow operation is placed on the GPU, then the execution engine must
    have the GPU implementation of that operation, known as the **kernel**. If the
    kernel is not present, then the placement results in a runtime error. Also, if
    the requested GPU device does not exist, then a runtime error is raised. The best
    way to handle such errors is to allow the operation to be placed on the CPU if
    requesting the GPU device results in an error. This can be achieved by setting
    the following `config` value:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个 TensorFlow 操作被放置在 GPU 上，那么执行引擎必须具有该操作的 GPU 实现，这被称为**内核**。如果内核不存在，那么放置将导致运行时错误。此外，如果请求的
    GPU 设备不存在，则会引发运行时错误。处理此类错误的最佳方法是允许操作在 GPU 设备请求失败时放置到 CPU 上。这可以通过设置以下`config`值来实现：
- en: '[PRE51]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: GPU memory handling
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU 内存处理
- en: 'At the start of the TensorFlow session, by default, a session grabs all of
    the GPU memory, even if the operations and variables are placed only on one GPU
    in a multi-GPU system. If another session starts execution at the same time, it
    will receive an out-of-memory error. This can be solved in multiple ways:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 会话开始时，默认情况下，会话会占用所有的 GPU 内存，即使操作和变量仅放置在多 GPU 系统中的一个 GPU 上。如果另一个会话同时开始执行，它将遇到内存不足错误。这个问题可以通过多种方式解决：
- en: 'For multi-GPU systems, set the environment variable `CUDA_VISIBLE_DEVICES=<list
    of device idx>`:'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多GPU系统，设置环境变量`CUDA_VISIBLE_DEVICES=<device idx 列表>`：
- en: '[PRE52]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The code that's executed after this setting will be able to grab all of the
    memory of the visible GPU.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置之后执行的代码将能够获取所有可见GPU的内存。
- en: 'For letting the session grab a part of the memory of the GPU, use the config
    option `per_process_gpu_memory_fraction` to allocate a percentage of the memory:'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要让会话只抓取GPU的一部分内存，请使用配置选项`per_process_gpu_memory_fraction`来分配内存的百分比：
- en: '[PRE53]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This will allocate 50% of the memory in all of the GPU devices.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这将分配50%的内存到所有GPU设备上。
- en: By combining both of the preceding strategies, you can make only a certain percentage,
    alongside just some of the GPU, visible to the process.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过结合前面两种策略，您可以让进程只看到GPU的一定百分比和部分GPU。
- en: 'Limit the TensorFlow process to grab only the minimum required memory at the
    start of the process. As the process executes further, set a config option to
    allow for the growth of this memory:'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制TensorFlow进程仅抓取启动时所需的最小内存。随着进程的进一步执行，可以设置配置选项，允许内存逐步增长：
- en: '[PRE54]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This option only allows for the allocated memory to grow, so the memory is never
    released back.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项仅允许已分配的内存增长，因此内存永远不会被释放回去。
- en: To find out more about learning techniques for distributing computation across
    multiple compute devices, refer to our book, *Mastering TensorFlow*.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 若想了解更多关于分布式计算技术的学习方法，请参考我们的书籍《*Mastering TensorFlow*》。
- en: Multiple graphs
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多图
- en: 'We can create our own graphs, which are separate from the default graph, and
    execute them in a session. However, creating and executing multiple graphs is
    not recommended, because of the following disadvantages:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建自己的图，这些图与默认图分开，并在会话中执行它们。然而，创建和执行多个图并不推荐，因为有以下缺点：
- en: Creating and using multiple graphs in the same program would require multiple
    TensorFlow sessions, and each session would consume heavy resources
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一程序中创建和使用多个图需要多个TensorFlow会话，每个会话都会消耗大量资源
- en: Data cannot be directly passed in-between graphs
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据不能直接在图之间传递
- en: 'Hence, the recommended approach is to have multiple subgraphs in a single graph.
    In case we wish to use our own graph instead of the default graph, we can do so
    with the `tf.graph()` command. In the following example, we create our own graph, `g`,
    and execute it as the default graph:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，推荐的方法是在一个图中使用多个子图。如果我们希望使用自己的图而不是默认图，可以使用`tf.graph()`命令来实现。在下面的示例中，我们创建了自己的图`g`，并将其作为默认图执行：
- en: '[PRE55]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Now, let's put this learning into practice and implement the classification
    of handwritten digital images with TensorFlow.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将所学的知识付诸实践，使用TensorFlow实现手写数字图像的分类。
- en: Machine learning, classification, and logistic regression
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习、分类和逻辑回归
- en: Let's now learn about machine learning, classification, and logistic regression.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们学习机器学习、分类以及逻辑回归。
- en: Machine learning
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Machine learning refers to the application of algorithms to make computers learn
    from data. The models that are learned by computers are used to make predictions
    and forecasts. Machine learning has been successfully applied in a variety of
    areas, such as natural language processing, self-driving vehicles, image and speech
    recognition, chatbots, and computer vision.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习指的是通过算法使计算机从数据中学习。计算机学习到的模型用于进行预测和预报。机器学习已经在多个领域取得了成功应用，例如自然语言处理、自动驾驶、图像与语音识别、聊天机器人以及计算机视觉。
- en: 'Machine learning algorithms are broadly categorized into three types:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法大致可以分为三类：
- en: '**Supervised learning**: In supervised learning, the machine learns the model
    from a training dataset that consists of features and labels. The supervised learning
    problems are generally of two types: *regression* and *classification*. Regression
    refers to predicting future values based on the model, while classification refers
    to predicting the categories of the input values.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：在监督学习中，机器通过由特征和标签组成的训练数据集来学习模型。监督学习问题通常有两种类型：*回归*和*分类*。回归是指基于模型预测未来的数值，而分类是指预测输入值的类别。'
- en: '**Unsupervised learning**: In unsupervised learning, the machine learns the
    model from a training dataset that consists of features only. One of the most
    common types of unsupervised learning is known as **clustering**. Clustering refers
    to dividing the input data into multiple groups, thus producing clusters or segments.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：在无监督学习中，机器从仅包含特征的训练数据集中学习模型。最常见的无监督学习类型之一称为**聚类**。聚类是指将输入数据分成多个组，从而产生聚类或分段。'
- en: '**Reinforcement learning**: In reinforcement learning, the agent starts with
    an initial model and then continuously learns the model based on the feedback
    from the environment. A reinforcement learning agent learns or updates the model
    by applying supervised or unsupervised learning techniques as part of the reinforcement
    learning algorithms.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**：在强化学习中，代理从初始模型开始，并根据来自环境的反馈持续学习模型。强化学习代理通过应用监督或无监督学习技术来学习或更新模型，作为强化学习算法的一部分。'
- en: 'These machine learning problems are abstracted to the following equation in
    one form or another:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这些机器学习问题在某种形式上被抽象为以下方程：
- en: '![](img/ce510bf8-62f2-44b1-8114-679eae1cbd33.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce510bf8-62f2-44b1-8114-679eae1cbd33.png)'
- en: Here, *y* represents the *target* and *x* represents the *feature*. If *x* is
    a collection of features, it is also called a feature vector and denoted with *X*.
    The model is the function *f* that maps features to targets. Once the computer
    learns *f*, it can use the new values of *x* to predict the values of *y*.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*y*表示*目标*，*x*表示*特征*。如果*x*是特征的集合，则也称为特征向量，并用*X*表示。模型是函数*f*，它将特征映射到目标。一旦计算机学习了*f*，它就可以使用新的*x*值来预测*y*的值。
- en: 'The preceding simple equation can be rewritten in the context of linear models
    for machine learning as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习线性模型的上下文中，可以将前述简单方程重写如下：
- en: '![](img/cca6472f-8449-4fc9-a9ef-16ff8a8f76d7.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca6472f-8449-4fc9-a9ef-16ff8a8f76d7.png)'
- en: Here, *w* is known as the weight and *b* is known as the bias. Thus, the machine
    learning problem now can be stated as a problem of finding w and *b* from the
    current values of *X* so that the equation can now be used to predict the values
    of *y*.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*w*被称为权重，*b*被称为偏置。因此，机器学习问题现在可以陈述为从当前的*X*值中找到*w*和*b*的问题，以便可以用这个方程来预测*y*的值。
- en: 'Regression analysis or regression modeling refers to the methods and techniques
    used to estimate relationships among variables. The variables that are used as
    input for regression models are called independent variables, predictors, or features,
    and the output variables from regression models are called dependent variables
    or targets. Regression models are defined as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析或回归建模指的是用于估计变量之间关系的方法和技术。用作回归模型输入的变量称为独立变量、预测变量或特征，而从回归模型得出的输出变量称为因变量或目标。回归模型定义如下：
- en: '![](img/4f835c01-2187-4d76-aa73-58a00674429d.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f835c01-2187-4d76-aa73-58a00674429d.png)'
- en: Where *Y* is the target variable, *X* is a vector of features, and *β* is a
    vector of parameters (*w*,*b* in the preceding equation).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*Y*是目标变量，*X*是特征向量，*β*是参数向量（前述方程中的*w*、*b*）。
- en: Classification
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: Classification is one of the classical problems in machine learning. Data under consideration
    could belong to one class or another, for example, if the images provided are
    data, they could be pictures of cats or dogs. Thus, the classes, in this case,
    are cats and dogs. Classification means identifying the label or class of the
    objects under consideration. Classification falls under the umbrella of supervised
    machine learning. In classification problems, a training dataset is provided that
    has features or inputs and their corresponding outputs or labels. Using this training
    dataset, a model is trained; in other words, the parameters of the model are computed.
    The trained model is then used on new data to find its correct labels.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是机器学习中的经典问题之一。考虑的数据可能属于一类或另一类，例如，如果所提供的图像是数据，则它们可能是猫或狗的图片。因此，在这种情况下，类别就是猫和狗。分类意味着识别正在考虑的对象的标签或类别。分类属于监督机器学习的范畴。在分类问题中，提供了一个训练数据集，其中包含特征或输入及其相应的输出或标签。使用这个训练数据集，训练一个模型；换句话说，计算模型的参数。然后，训练好的模型被用于新数据，以找到其正确的标签。
- en: Classification problems can be of two types: **binary class** or **multiclass**.
    Binary class means that the data is to be classified into two distinct and discrete
    labels; for example, the patient has cancer or the patient does not have cancer,
    and the images are of cats or dogs and so on. Multiclass means that the data is
    to be classified among multiple classes, for example, an email classification problem
    will divide emails into social media emails, work-related emails, personal emails,
    family-related emails, spam emails, shopping offer emails, and so on. Another
    example would be of pictures of digits; each picture could be labeled between
    0 and 9, depending on what digit the picture represents. In this chapter, we will
    look at examples of both kinds of classification.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题可以分为两种类型：**二分类** 或 **多分类**。二分类意味着数据要被分类成两个不同且离散的标签；例如，病人是否患癌症，或者图像是猫还是狗，等等。多分类意味着数据要在多个类别之间分类，例如，电子邮件分类问题会将电子邮件分为社交媒体邮件、工作相关邮件、个人邮件、家庭相关邮件、垃圾邮件、购物优惠邮件等。另一个例子是数字图像；每张图像的标签可以是
    0 到 9 之间的任意数字，取决于该图像表示的是哪个数字。本章将会展示这两种分类问题的示例。
- en: 'The most popular method for classification is logistic regression. Logistic regression is
    a probabilistic and linear classifier. The probability that the vector of input
    features belongs to a specific class can be described mathematically by the following
    equation:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 最流行的分类方法是逻辑回归。逻辑回归是一种概率性且线性的分类器。输入特征向量属于某一特定类别的概率可以通过以下数学方程来描述：
- en: '![](img/9a303e0f-ce6b-4910-9193-b20ff0d71ff8.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a303e0f-ce6b-4910-9193-b20ff0d71ff8.png)'
- en: 'In the preceding equation, the following applies:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述方程中，以下内容适用：
- en: '*Y* represents the output'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y* 代表输出'
- en: '*i* represents one of the classes'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*i* 代表类别之一'
- en: '*x* represents the inputs'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* 代表输入'
- en: '*w* represents the weights'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w* 代表权重'
- en: '*b* represents the biases'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b* 代表偏差'
- en: '*z* represents the regression equation ![](img/c31c0e53-eceb-4e8b-99aa-4ba0c19db77b.png)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*z* 代表回归方程 ![](img/c31c0e53-eceb-4e8b-99aa-4ba0c19db77b.png)'
- en: '*ϕ* represents the smoothing function (or model, in our case)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ϕ* 代表平滑函数（或者在我们案例中的模型）'
- en: The *ϕ(z)* function represents the probability that *x* belongs to class *i* when *w* and *b* are
    given. Thus, the model has to be trained to maximize the value of this probability.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*ϕ(z)* 函数表示在给定 *w* 和 *b* 时，*x* 属于类别 *i* 的概率。因此，模型必须经过训练，以最大化此概率的值。'
- en: Logistic regression for binary classification
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二分类的逻辑回归
- en: 'For binary classification, the model function *ϕ(z)* is defined asthe sigmoid
    function, which can be described as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类，模型函数 *ϕ(z)* 定义为 sigmoid 函数，其表达式如下：
- en: '![](img/dcf29118-cfc3-4624-bc9b-5350dd509600.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dcf29118-cfc3-4624-bc9b-5350dd509600.png)'
- en: 'The sigmoid function transforms the *y* value to be between the range [0,1].
    Thus, the value of *y=ϕ(z)* can be used to predict the class: if *y* > 0.5, then the
    object belongs to 1, otherwise the object belongs to 0.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 函数将 *y* 值转换为在 [0,1] 范围内。因此，*y=ϕ(z)* 的值可用于预测类别：如果 *y* > 0.5，则该对象属于 1，否则该对象属于
    0。
- en: 'The model training means to search for the parameters that minimize the loss
    function, which can either be the sum of squared errors or the sum of mean squared
    errors. For logistic regression, the likelihood is maximized as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练是指寻找能最小化损失函数的参数，这些参数可以是平方误差的总和或均方误差的总和。对于逻辑回归，似然函数的最大化如下：
- en: '![](img/cab647bc-44e9-466c-bfda-61edd8576e9d.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cab647bc-44e9-466c-bfda-61edd8576e9d.png)'
- en: However, as it is easier to maximize the log-likelihood, we use the log-likelihood
    (*l(w)*) as the cost function. The loss function (*J(w)*) is written as *-l(w)*,
    and can be minimized by using optimization algorithms such as gradient descent.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于最大化对数似然较为容易，我们使用对数似然 (*l(w)*) 作为成本函数。损失函数 (*J(w)*) 写作 *-l(w)*，可以通过使用诸如梯度下降之类的优化算法进行最小化。
- en: 'The loss function for binary logistic regression is written mathematically
    as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类逻辑回归的损失函数在数学上写作如下：
- en: '![](img/3d3c322a-f6bc-4f4c-b2d7-778782788a8c.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d3c322a-f6bc-4f4c-b2d7-778782788a8c.png)'
- en: Here, *ϕ(z)* is the sigmoid function.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*ϕ(z)* 是 sigmoid 函数。
- en: Logistic regression for multiclass classification
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多分类的逻辑回归
- en: 'When more than two classes are involved, logistic regression is known as multinomial
    logistic regression. In multinomial logistic regression, instead of sigmoid, use the
    softmax function, which can be described mathematically as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到多于两个类别时，逻辑回归被称为多项逻辑回归。在多项逻辑回归中，使用 softmax 函数代替 sigmoid 函数，该函数可以通过以下数学方式描述：
- en: '![](img/825ae940-aa27-4241-ad2d-7443037331a7.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/825ae940-aa27-4241-ad2d-7443037331a7.png)'
- en: The softmax function produces the probabilities for each class so that the probabilities
    vector adds up to *1*. At the time of inference, the class with the highest softmax
    value becomes the output or predicted class. The loss function, as we discussed
    earlier, is the negative log-likelihood function, *-l(w)*, that can be minimized
    by the optimizers, such as gradient descent.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: softmax 函数为每个类别生成概率，使得概率向量的和为 *1*。在推理时，具有最高 softmax 值的类别成为输出或预测的类别。正如我们之前讨论的，损失函数是负对数似然函数，*-l(w)*，可以通过优化器（如梯度下降）进行最小化。
- en: 'The loss function for multinomial logistic regression is written formally as
    follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 多项逻辑回归的损失函数正式写作如下：
- en: '![](img/632dd8f0-9c91-453c-a5c0-ed267c5d80b3.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/632dd8f0-9c91-453c-a5c0-ed267c5d80b3.png)'
- en: Here, *ϕ(z)* is the softmax function.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*ϕ(z)* 是 softmax 函数。
- en: We will implement this loss function in the next section. In the following section,
    we will dig into our example for multiclass classification with logistic regression
    in TensorFlow.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中实现这个损失函数。在接下来的部分，我们将深入探讨如何使用 TensorFlow 进行多类分类的逻辑回归示例。
- en: Logistic regression with TensorFlow
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 进行逻辑回归
- en: 'One of the most popular examples regarding multiclass classification is to
    label the images of handwritten digits. The classes, or labels, in this example
    are *{0,1,2,3,4,5,6,7,8,9}*. The dataset that we are going to use is popularly
    known as MNIST and is available from the following link: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
    The MNIST dataset has 60,000 images for training and 10,000 images for testing.
    The images in the dataset appear as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 关于多类分类的最流行示例之一是标记手写数字图像。在这个示例中，类别或标签是 *{0,1,2,3,4,5,6,7,8,9}*。我们将使用的数据集通常被称为
    MNIST，可以通过以下链接获取：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)。MNIST
    数据集有 60,000 张用于训练的图像和 10,000 张用于测试的图像。数据集中的图像如下所示：
- en: '![](img/95ce1802-2f03-4e6a-ac4b-a4289bc12086.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95ce1802-2f03-4e6a-ac4b-a4289bc12086.png)'
- en: 'First, we must import `datasetslib`, a library that was written by us to help
    with examples in this book (available as a submodule of this book''s GitHub repository):'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须导入 `datasetslib`，这是我们编写的一个库，用来帮助书中的示例（可以作为本书 GitHub 仓库的子模块获取）：
- en: '[PRE56]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Set the path to the `datasets` folder in our home directory, which is where
    we want all of the `datasets` to be stored:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置我们主目录中 `datasets` 文件夹的路径，这是我们希望存储所有 `datasets` 的地方：
- en: '[PRE57]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Get the MNIST data using our `datasetslib` and print the shapes to ensure that
    the data is loaded properly:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们的 `datasetslib` 获取 MNIST 数据，并打印数据形状以确保数据已正确加载：
- en: '[PRE58]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Define the hyperparameters for training the model:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义训练模型的超参数：
- en: '[PRE59]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Define the placeholders and parameters for our simple model:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为我们的简单模型定义占位符和参数：
- en: '[PRE60]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Define the model with `logits` and `y_hat`:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `logits` 和 `y_hat` 来定义模型：
- en: '[PRE61]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Define the `loss` function:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `loss` 函数：
- en: '[PRE62]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Define the `optimizer` function:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `optimizer` 函数：
- en: '[PRE63]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Define the function to check the accuracy of the trained model:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来检查训练模型的准确率：
- en: '[PRE64]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Run the `training` loop for each epoch in a TensorFlow session:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 TensorFlow 会话中为每个 epoch 运行 `training` 循环：
- en: '[PRE65]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Run the evaluation function for each epoch with the test data in the same TensorFlow
    session that was created previously:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在之前创建的 TensorFlow 会话中，针对每个 epoch 使用测试数据运行评估函数：
- en: '[PRE66]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We get the following output:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE67]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: There you go. We just trained our very first logistic regression model using
    TensorFlow for classifying handwritten digit images and got 74.3% accuracy.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。我们刚刚使用 TensorFlow 训练了我们的第一个逻辑回归模型，用于对手写数字图像进行分类，并且得到了 74.3% 的准确率。
- en: Now, let's see how writing the same model in Keras makes this process even easier.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看在 Keras 中编写相同模型是如何让这个过程变得更简单的。
- en: Logistic regression with Keras
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras 进行逻辑回归
- en: '**Keras** is a high-level library that is available as part of TensorFlow.
    In this section, we will rebuild the same model we built earlier with TensorFlow
    core with Keras:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '**Keras** 是一个高级库，它作为 TensorFlow 的一部分提供。在这一节中，我们将用 Keras 重建我们之前用 TensorFlow
    核心构建的相同模型：'
- en: 'Keras takes data in a different format, and so we must first reformat the data
    using `datasetslib`:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Keras 以不同的格式接收数据，因此我们必须首先使用 `datasetslib` 重新格式化数据：
- en: '[PRE68]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: In the preceding code, we are loading the training images in memory before both
    the training and test images are scaled, which we do by dividing them by `255`.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们在训练和测试图像被缩放之前将训练图像加载到内存中，我们通过将其除以 `255` 来实现缩放。
- en: 'Then, we build the model:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们构建模型：
- en: '[PRE69]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Compile the model with the `sgd` optimizer. Set the categorical entropy as
    the `loss` function and the accuracy as a metric to test the model:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sgd` 优化器编译模型。将分类熵作为 `loss` 函数，准确率作为测试模型的指标：
- en: '[PRE70]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Train the model for `5` epochs with the training set of images and labels:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练集图像和标签训练模型 `5` 个周期：
- en: '[PRE71]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Evaluate the model with the test data:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试数据评估模型：
- en: '[PRE72]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'We get the following evaluation scores as output:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下评估分数作为输出：
- en: '[PRE73]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Wow! Using Keras, we can achieve higher accuracy. We achieved approximately
    90% accuracy. This is because Keras internally sets many optimal values for us
    so that we can quickly start building models.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！使用 Keras，我们可以实现更高的准确性。我们达到了大约 90% 的准确率。这是因为 Keras 在内部为我们设置了许多最优值，使我们能够快速开始构建模型。
- en: To learn more about Keras and to look at more examples, refer to the book *Mastering
    TensorFlow,* from Packt Publications.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 Keras 的信息并查看更多示例，请参考 Packt 出版社的书籍 *精通 TensorFlow*。
- en: Summary
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we briefly covered the TensorFlow library. We covered the TensorFlow
    data model elements, such as constants, variables, and placeholders, and how they
    can be used to build TensorFlow computation graphs. We learned how to create tensors
    from Python objects. Tensor objects can also be generated as specific values,
    sequences, or random valued distributions from various TensorFlow library functions.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要介绍了 TensorFlow 库。我们介绍了 TensorFlow 数据模型元素，如常量、变量和占位符，以及如何使用它们构建 TensorFlow
    计算图。我们学习了如何从 Python 对象创建张量。张量对象还可以作为特定值、序列或从各种 TensorFlow 库函数生成的随机值分布来生成。
- en: We covered the TensorFlow programming model, which includes defining and executing
    computation graphs. These computation graphs have nodes and edges. The nodes represent
    operations and edges represent tensors that transfer data from one node to another.
    We covered how to create and execute graphs, the order of execution, and how to
    execute graphs on multiple compute devices, such as CPU and GPU.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了 TensorFlow 编程模型，包括定义和执行计算图。这些计算图包含节点和边。节点代表操作，边代表在节点之间传输数据的张量。我们讲解了如何创建和执行图、执行顺序以及如何在多个计算设备上执行图，如
    CPU 和 GPU。
- en: We also learned about machine learning and implemented a classification algorithm
    to identify the handwritten digits dataset. The algorithm we implemented is known
    as multinomial logistic regression. We used both TensorFlow core and Keras to
    implement the logistic regression algorithm.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解了机器学习，并实现了一个分类算法来识别手写数字数据集。我们实现的算法被称为多项式逻辑回归。我们使用了 TensorFlow 核心和 Keras
    来实现逻辑回归算法。
- en: Starting from the next chapter, we will look at many projects that will be implemented
    using TensorFlow and Keras.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 从下一章开始，我们将查看许多使用 TensorFlow 和 Keras 实现的项目。
- en: Questions
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Enhance your understanding by practicing the following questions:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 通过练习以下问题来加深理解：
- en: Modify the logistic regression model that was given in this chapter so that
    you can use different training rates and observe how it impacts training
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改本章中给出的逻辑回归模型，以便使用不同的训练率，并观察其对训练的影响。
- en: Use different optimizer functions and observe the impact of different functions
    on training time and accuracy
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不同的优化器函数，观察不同函数对训练时间和准确度的影响。
- en: Further reading
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'We suggest the reader learn more by reading the following materials:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议读者通过阅读以下材料来进一步学习：
- en: '*Mastering TensorFlow* by Armando Fandango.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*精通 TensorFlow* 由 Armando Fandango 编写。'
- en: TensorFlow tutorials at [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/).
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 教程请参见 [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)。
- en: '*TensorFlow 1.x Deep Learning Cookbook* by Antonio Gulli and Amita Kapoor'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow 1.x 深度学习实用宝典* 由 Antonio Gulli 和 Amita Kapoor 编写。'
