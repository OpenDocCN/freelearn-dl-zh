- en: Getting Data into Your Neural Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据输入神经网络
- en: There are many techniques you can use to load data to train a neural network
    or make predictions. What technique you use depends on how large your dataset
    is and in what format you've stored your data. In the previous chapter, we've
    seen how to feed data into a CNTK trainer manually. In this chapter, we will learn
    more ways to feed data into your neural network.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用许多技术将数据加载到神经网络中进行训练或预测。你使用什么技术取决于你的数据集有多大，以及你存储数据的格式是什么。在上一章中，我们已经看到了如何手动将数据传递给CNTK训练器。在本章中，我们将学习更多将数据输入神经网络的方法。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主题：
- en: Training your neural network efficiently with minibatches
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用小批量高效训练神经网络
- en: Working with small in-memory datasets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理小型内存数据集
- en: Working with large datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大型数据集
- en: Taking control over the minibatch loop
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制小批量循环
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We assume you have a recent version of Anaconda installed on your computer and
    have followed the steps in [Chapter 1](9a2c8c46-f9a0-4e05-86ef-31300a28a7ba.xhtml),
    *Getting Started with CNTK*, to install CNTK on your computer. The sample code
    for this chapter can be found in our GitHub repository at [https://github.com/PacktPublishing/Deep-Learning-with-Microsoft-Cognitive-Toolkit-Quick-Start-Guide/tree/master/ch3](https://github.com/PacktPublishing/Deep-Learning-with-Microsoft-Cognitive-Toolkit-Quick-Start-Guide/tree/master/ch3).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设你已经在电脑上安装了最新版本的Anaconda，并且已经按照[第1章](9a2c8c46-f9a0-4e05-86ef-31300a28a7ba.xhtml)中的步骤，*开始使用CNTK*，将CNTK安装到你的电脑上。本章的示例代码可以在我们的GitHub仓库中找到，地址是[https://github.com/PacktPublishing/Deep-Learning-with-Microsoft-Cognitive-Toolkit-Quick-Start-Guide/tree/master/ch3](https://github.com/PacktPublishing/Deep-Learning-with-Microsoft-Cognitive-Toolkit-Quick-Start-Guide/tree/master/ch3)。
- en: 'In this chapter, we''ll work on a few examples stored in Jupyter notebooks.
    To access the sample code, run the following commands inside an Anaconda prompt
    in the directory where you''ve downloaded the code:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将在存储在Jupyter笔记本中的几个示例上进行操作。要访问示例代码，请在Anaconda提示符中运行以下命令，命令路径为你下载代码的目录：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We'll mention the relevant notebooks in each of the sections so you can follow
    along and try out different techniques yourself.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在每个部分中提到相关的笔记本，以便你可以跟着做，并亲自尝试不同的技术。
- en: 'Check out the following video to see the code in action:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际应用：
- en: '[http://bit.ly/2UczHuH](http://bit.ly/2UczHuH)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2UczHuH](http://bit.ly/2UczHuH)'
- en: Training a neural network efficiently with minibatches
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用小批量高效训练神经网络
- en: In the previous chapter, we discussed how to build and train a neural network.
    In this chapter, we'll discuss various ways to feed data to the CNTK trainer.
    Before we dive into the details of each data processing method, let's take a closer
    look at what happens with the data when you train a neural network.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了如何构建和训练神经网络。在本章中，我们将讨论如何将数据输入CNTK训练器的各种方法。在深入了解每种数据处理方法的细节之前，让我们先仔细看看训练神经网络时数据发生了什么。
- en: You need a couple of things to train a neural network. As we discussed in the
    previous chapter, you need to have a basic structure for your model and a loss
    function. The `trainer` and the `learner` are the final pieces to the puzzle and
    are responsible for controlling the training process.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络需要一些东西。正如我们在上一章中讨论的，你需要有一个基本的模型结构和损失函数。`trainer`和`learner`是最后的拼图部分，负责控制训练过程。
- en: 'The `trainer` performs four steps:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainer`执行四个步骤：'
- en: It takes a number of training samples and feeds them through the network and
    `loss` function
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它接受一批训练样本并将其输入到网络和`loss`函数中
- en: Next, it takes the output of the `loss` function and feeds it through the `learner`
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，它将`loss`函数的输出通过`learner`处理。
- en: It then uses the `learner` to get a set of gradients for the parameters in the
    network
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它使用`learner`获取网络中参数的梯度集合
- en: Finally, it uses the gradients to determine the new value of each parameter
    in the network
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它使用梯度来确定网络中每个参数的新值
- en: This process is repeated for all samples in your dataset to train the network
    for a full epoch. Usually, you need to train the network for multiple epochs to
    get the best result.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程会对数据集中的所有样本重复进行，以便训练网络完成一个完整的epoch。通常，你需要训练网络多个epoch才能获得最佳结果。
- en: We previously only talked about single samples when training a neural network.
    But that is not what happens inside CNTK.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前只讨论了训练神经网络时的单个样本。但这并不是CNTK内部发生的情况。
- en: CNTK and many other frameworks use minibatches to train neural networks. A minibatch
    is a set of samples taken from your dataset. Essentially, a minibatch is a very
    small table of samples. It contains a predefined number of samples for the input
    features and an equal number of samples for the targets of your neural network.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CNTK和许多其他框架都使用小批量来训练神经网络。小批量是从数据集中提取的一组样本。本质上，小批量就是一个非常小的样本表格。它包含输入特征的预定义数量的样本，以及与神经网络目标数量相等的样本。
- en: The minibatch is passed through the network during training to calculate the
    output of the loss function. The output for the `loss` function is no longer a
    single value, but rather a list of values equal to the number of rows in the minibatch.
    This list of values is then passed through the `learner` to obtain a set of gradients
    for each of the parameters in the neural network.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 小批量在训练过程中通过网络传递，用于计算损失函数的输出。`loss`函数的输出不再是一个单一的值，而是一个值的列表，列表中的值等于小批量中的行数。然后，这个值的列表会传递给`learner`，从而为神经网络的每个参数计算出一组梯度。
- en: Now, there's a problem with working with minibatches. We want one gradient per
    parameter to optimize its value. But we get a list of gradients instead. We can
    solve this by calculating the average over the gradients for each parameter. The
    average gradients are then used to update the parameters in the neural network.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，处理小批量时有一个问题。我们希望每个参数都有一个梯度来优化其值。但实际上我们得到的是梯度的列表。我们可以通过对每个参数的梯度计算平均值来解决这个问题。然后，使用平均梯度来更新神经网络中的参数。
- en: Working with minibatches speeds up the training process but comes at a cost.
    Because we now have to deal with averages, we lose some resolution in calculating
    the gradients for the parameters in the model. It is quite possible to have a
    gradient of zero in a single minibatch as a result of averaging all the calculated
    gradients. When you use minibatches to train your neural network, you will get
    a lower quality model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用小批量加速了训练过程，但也带来了一些代价。因为我们现在必须处理平均值，所以在计算模型参数的梯度时，会失去一些分辨率。由于平均所有计算得到的梯度，单个小批量的梯度可能为零。当你使用小批量训练神经网络时，模型的质量可能较低。
- en: You need to set the number of samples per minibatch yourself before you start
    to train your neural network. Choosing a higher minibatch size will result in
    faster training at the cost of quality. A lower minibatch size is slower but produces
    better models. Choosing the right minibatch size is a matter of experimentation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练神经网络之前，你需要自己设置每个小批量的样本数量。选择较大的小批量大小将加速训练，但会以质量为代价。较小的小批量大小训练较慢，但能产生更好的模型。选择合适的小批量大小是一个实验性的问题。
- en: There's also a memory aspect to choosing the minibatch size. The minibatch size
    depends on how much memory you have available in your machine. You will find that
    you can fit fewer samples in the memory of your graphics card than you can in
    regular computer memory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 选择小批量大小时还有一个内存方面的考量。小批量大小取决于你机器中可用的内存。你会发现，你的显卡内存能够容纳的样本比普通计算机内存少。
- en: All methods described the next sections will use minibatches automatically.
    Later in the chapter, in the section, *Taking control over the minibatch loop,*
    we will discuss how to take control of the minibatch loop yourself should you
    need to.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来章节中描述的所有方法都会自动使用小批量。在本章后面的章节，*控制小批量循环*部分，我们将讨论如何在需要时控制小批量循环。
- en: Working with small in-memory datasets
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用小型内存数据集
- en: There are many ways in which you can feed data to the CNTK trainer. Which technique
    you should use depends on the size of the dataset and the format of the data.
    Let's take a look at how to work with smaller in-memory datasets first.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以将数据提供给CNTK训练器。你应该使用哪种技术取决于数据集的大小和数据的格式。首先让我们来看一下如何处理较小的内存数据集。
- en: When you work with in-memory data in Python you will most likely use a framework
    such as Pandas or NumPy. These frameworks work with vectors and matrices of floating
    point or object data at their core and offer various levels of convenience when
    it comes to working with data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在Python中处理内存数据时，你很可能会使用像Pandas或NumPy这样的框架。这些框架以浮动点或对象数据为核心，处理向量和矩阵，并在处理数据时提供不同级别的便利性。
- en: Let's go over each of these libraries and explore how you can use data stored
    in these libraries to train your neural network.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一了解这些库，并探讨如何使用存储在这些库中的数据来训练你的神经网络。
- en: Working with numpy arrays
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用numpy数组
- en: The first library we'll explore is numpy. Numpy is the most basic library available
    in Python for performing mathematical operations on n-dimensional arrays. It features
    an efficient way to store matrices and vectors in computer memory. The numpy library
    defines a large number of operators to manipulate these n-dimensional arrays.
    For example, it has built-in functions to calculate the average value over a whole
    matrix or rows/columns in a matrix.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先探索的库是numpy。Numpy是Python中最基本的库，用于对n维数组执行数学操作。它提供了一种高效的方式来存储计算机内存中的矩阵和向量。numpy库定义了大量操作符来操作这些n维数组。例如，它有内置的函数来计算整个矩阵或矩阵中的行/列的平均值。
- en: You can follow along with any of the code in this section by opening the `Training
    using numpy arrays.ipynb` notebook in your browser using the instructions described
    at the start of this chapter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过按照本章开始时描述的步骤，打开`Training using numpy arrays.ipynb`笔记本，在浏览器中跟随本节中的任何代码。
- en: 'Let''s take a look at how to work with a numpy-based dataset in CNTK. As an
    example, we''ll use a randomly generated dataset. We''ll simulate data for a binary
    classification problem. Imagine that we have a set of observations with four features.
    We want to predict two possible labels with our model. First, we need to generate
    a set of labels that contain a one-hot vector representation of the labels that
    we want to predict. Next, we''ll also need a set of features that will serve as
    the input features for our model:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何在CNTK中使用基于numpy的数据集。作为示例，我们将使用一个随机生成的数据集。我们将模拟一个二元分类问题的数据。假设我们有一组包含四个特征的观察数据。我们希望用我们的模型预测两个可能的标签。首先，我们需要生成一组标签，其中包含我们想要预测的标签的热编码向量表示。接下来，我们还需要一组特征，这些特征将作为我们模型的输入特征：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Follow the given steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定步骤操作：
- en: First, import the `numpy` package under the `np` alias
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入`numpy`包，并使用`np`作为别名。
- en: Then, generate a `label mapping` using the `np.eye` function
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用`np.eye`函数生成一个`label mapping`。
- en: After that, collect `20,000` random samples from the generated `label mapping`
    using the `np.random.choice` function
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用`np.random.choice`函数从生成的`label mapping`中收集`20,000`个随机样本。
- en: Finally, generate an array of random floating point values using the `np.random.random`
    function
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用`np.random.random`函数生成一个随机浮点值数组。
- en: 'The generated label mapping is a one-hot representation of the possible classes
    that we support and looks like this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的标签映射是我们支持的可能类别的一个热编码表示，看起来像这样：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The generated matrices need to be converted to 32-bit floating point numbers
    in order to match the format expected by CNTK. Without this step, you will see
    an error telling you the format is not of the expected type. CNTK expects that
    you provide double-precision or float 32 data points.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的矩阵需要转换为32位浮点数，以匹配CNTK所期望的格式。没有这个步骤，你将看到一个错误，提示格式不是预期的类型。CNTK要求你提供双精度或float
    32的数据点。
- en: 'Let''s define a basic model that fits the dataset we just generated:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个适配我们刚生成的数据集的基本模型：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Follow the given steps:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定步骤操作：
- en: First, import the `Dense` and `Sequential` layer function from the `layers`
    module
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从`layers`模块导入`Dense`和`Sequential`层函数。
- en: Then, import the `sigmoid` as the activation function for the layers in the
    network
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，导入`sigmoid`作为网络中各层的激活函数。
- en: After that, import the `binary_cross_entropy` function as the `loss` function
    to train the network
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，导入`binary_cross_entropy`函数作为`loss`函数来训练网络。
- en: Next, define the default options for the network providing the `sigmoid` activation
    function as a default setting
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义网络的默认选项，提供`sigmoid`激活函数作为默认设置。
- en: Now, create the model using the `Sequential` layer function.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`Sequential`层函数创建模型。
- en: Use two `Dense` layers, one with `6` neurons and another one with `2` neurons
    which will serve as the output layer
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用两个`Dense`层，一个具有`6`个神经元，另一个具有`2`个神经元，后者将作为输出层。
- en: Initialize an `input_variable` with `4` input features, which will serve as
    the input for the network.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个`input_variable`，它有`4`个输入特征，将作为网络的输入。
- en: Finally, connect the `features` variable to the neural network to complete it.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将`features`变量连接到神经网络以完成它。
- en: This model will have four inputs and two outputs matching the format of our
    randomly generated dataset. For demonstration purposes, we inserted an additional
    hidden layer with six neurons.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型将具有四个输入和两个输出，匹配我们随机生成的数据集的格式。为了演示目的，我们插入了一个额外的隐藏层，包含六个神经元。
- en: 'Now that we have a neural network, let''s train it using our in-memory dataset:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了神经网络，接下来用我们的内存数据集来训练它：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Follow the given steps:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下步骤操作：
- en: First, import the `sgd` learner from the `learners` module
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从`learners`模块导入`sgd`学习器
- en: Next, import the `ProgressPrinter` from the `logging` module
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，从`logging`模块导入`ProgressPrinter`
- en: Define a new `input_variable` for the labels
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为标签定义一个新的`input_variable`
- en: To train the model, define a `loss` using the `binary_cross_entropy` function
    and provide it the model `z` and the `labels` variable
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了训练模型，定义一个使用`binary_cross_entropy`函数的`loss`，并为其提供模型`z`和`labels`变量
- en: Next, initialize the `sgd` learner and provide it with the parameters of the
    model and the `labels` variable
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，初始化`sgd`学习器，并为其提供模型参数和`labels`变量
- en: Finally, call the `train` method on the `loss` function and provide it with
    the input data, the `sgd` learner and the `progress_printer` as a callback
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，调用`train`方法，并为其提供输入数据、`sgd`学习器以及`progress_printer`回调
- en: You're not required to provide callbacks for the `train` method. But it can
    be useful to plug in a progress writer so you can monitor the training process.
    Without this, you can't really see what is happening during training.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必为`train`方法提供回调函数。但如果插入一个进度写入器来监控训练过程会很有用。没有这个，你无法真正看到训练过程中发生了什么。
- en: 'When you run the sample code, it will produce output similar to this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行示例代码时，它将产生类似于以下内容的输出：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It lists the learning average loss per minibatch, the loss since the last minibatch,
    and the metrics. Since we didn't provide metrics, the values in the metrics columns
    will remain `0`. In the last column, the number of examples seen by the neural
    network is listed.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 它列出了每个迷你批次的学习平均损失、上一个迷你批次以来的损失以及度量标准。由于我们没有提供度量标准，度量列中的值将保持为`0`。在最后一列中，列出了神经网络看到的示例数量。
- en: 'In the previous example, we''ve executed the `learner` with a default batch
    size. You can control the batch size using the `minibatch_size` keyword argument:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，我们使用默认批次大小执行了`learner`。你可以使用`minibatch_size`关键字参数来控制批次大小：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Setting `minibatch_size` to a larger value will increase the speed of training
    but at the cost of a slightly worse model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 将`minibatch_size`设置为更大的值将提高训练速度，但代价是模型可能会稍微变差。
- en: Try experimenting with different minibatch sizes in the sample code and see
    how it affects the performance of the model. Even with a model trained with random
    data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在示例代码中使用不同的迷你批次大小，观察它对模型性能的影响。即使是使用随机数据训练的模型也是如此。
- en: Working with pandas DataFrames
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pandas数据框
- en: Numpy arrays are the most basic way of storing data. Numpy arrays are very limited
    in what they can contain. A single n-dimensional array can contain data of a single
    data type. For many real-world cases, you need a library that can handle more
    than one data type in a single dataset. For example, you will find many datasets
    online where the label column is a string while the rest of the columns in the
    dataset contain floating point numbers.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Numpy数组是存储数据的最基本方式。Numpy数组在可以包含的内容上有很大限制。一个单一的n维数组只能包含单一数据类型的数据。在许多实际应用场景中，你需要一个能够处理单个数据集内多种数据类型的库。例如，你会发现许多在线数据集的标签列是字符串类型，而数据集中的其他列则包含浮动点数。
- en: The pandas library makes it easier to work with these kinds of datasets and
    is used by many developers and data scientists. It's a library that allows you
    to load datasets from disk stored in many different formats as DataFrames. For
    example, you can read DataFrames stored as JSON, CSV, and even Excel.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas库让处理这些类型的数据集变得更加容易，许多开发者和数据科学家都在使用它。它是一个可以将存储在不同格式中的数据集作为DataFrame加载的库。例如，你可以读取存储为JSON、CSV甚至Excel格式的DataFrame。
- en: 'Pandas introduces the concept of a dataframe and with it introduces a large
    amount of mathematical and statistical functions that you can run against a data
    frame. Let''s take a look at the structure of a pandas DataFrame to see how this
    library works:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas引入了数据框（DataFrame）的概念，并带来了大量可以在数据框上运行的数学和统计函数。让我们看看pandas数据框的结构，以了解这个库是如何工作的：
- en: '![](img/f8b34cd7-f296-4aea-b136-3f3036e6f091.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f8b34cd7-f296-4aea-b136-3f3036e6f091.png)'
- en: A DataFrame in pandas is a collection of series that define the individual columns.
    Each DataFrame also has an index that allows you to look up specific rows in the
    DataFrame by a key value stored in the index.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: pandas中的DataFrame是由定义各个列的系列（series）组成的集合。每个DataFrame还有一个索引，允许你通过存储在索引中的键值查找DataFrame中特定的行。
- en: What makes a DataFrame unique is the large collection of methods defined on
    both the series and the dataset itself. For example, you can call `describe` on
    the DataFrame to get summary statistics for the whole DataFrame at once.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame独特之处在于，它在系列和数据集本身上定义了大量方法。例如，你可以调用`describe`方法来获取整个DataFrame的摘要统计信息。
- en: Invoking the `describe` method on a single series will get you the same summary
    statistics for that specific column in your DataFrame.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对单个系列调用`describe`方法将为该特定列提供相同的摘要统计信息。
- en: Pandas is widely used by data scientists and developers to work with data in
    Python. Because it is so widely used, it is good to know how to handle data stored
    in pandas with CNTK.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas是数据科学家和开发人员在Python中处理数据的广泛使用的工具。因为它如此广泛使用，了解如何使用CNTK处理存储在pandas中的数据非常重要。
- en: In the previous chapter, we've loaded a dataset that contains samples of Iris
    flowers and used that dataset to train a classification model. Before, we used
    a trainer instance to train the neural network. This is what happens too when
    you call `train` on a `loss` function. The `train` method will automatically create
    a trainer and a session for you so you don't have to do it manually.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们加载了一个包含鸢尾花样本的数据集，并使用该数据集训练了一个分类模型。之前，我们使用了一个训练器实例来训练神经网络。当你对`loss`函数调用`train`时，也会发生类似的情况。`train`方法将自动为你创建一个训练器和一个会话，因此你无需手动操作。
- en: 'In [chapter 2](4c9da7a9-6873-4de9-99a9-43de693d65f8.xhtml), *Building Neural
    Networks with CNTK*, we talked about classifying three possible species of iris
    flowers based on four properties. You can either get the file from the sample
    code included with this book or by downloading the dataset from the UCI datasets
    archive at [https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris).
    Let''s see how we can use the `train` method on the `loss` function to train the
    network that we created in the previous chapter:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](4c9da7a9-6873-4de9-99a9-43de693d65f8.xhtml)，*使用CNTK构建神经网络*中，我们讨论了如何根据四个特性对三种鸢尾花的物种进行分类。你可以通过本书附带的示例代码文件，或者从UCI数据集档案[https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)下载数据集来获取该文件。让我们看看如何在前一章中创建的网络上使用`train`方法来训练损失函数：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The model we used previously to classify flowers contains one hidden layer and
    an output layer with three neurons to match the number of classes we can predict.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前用来分类花朵的模型包含一个隐藏层和一个输出层，输出层有三个神经元，以匹配我们可以预测的类别数。
- en: 'In order to train the model, we need to load and preprocess the iris dataset
    so that it matches the expected layout and data format for the neural network:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，我们需要加载并预处理鸢尾花数据集，以便它与神经网络的预期布局和数据格式匹配：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Follow the givens steps:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定的步骤操作：
- en: First, load the dataset into memory using the `read_csv` function
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用`read_csv`函数将数据集加载到内存中。
- en: Next, create a dictionary mapping the labels in the dataset with their corresponding
    numeric representation
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个字典，将数据集中标签与其对应的数字表示进行映射。
- en: Select the first four columns using the `iloc` indexer on the `DataFrame`
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`iloc`索引器选择`DataFrame`中的前四列。
- en: Select the species columns as the labels for the dataset
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择物种列作为数据集的标签。
- en: Map the labels in the dataset using the `label_mapping` and use `one_hot` encoding
    to convert them into one-hot encoded arrays
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`label_mapping`映射数据集中的标签，并使用`one_hot`编码将它们转换为独热编码数组。
- en: Convert both the features and the mapped labels to floats so you can use them
    with CNTK
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征和映射后的标签都转换为浮点数，以便可以与CNTK一起使用。
- en: 'The labels are stored in the dataset as strings, CNTK can''t work with these
    string values it needs one-hot encoded vectors representing the labels. To encode
    the labels we''ll need to use the mapping table and the `one_hot` function which
    you can create using the following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 标签以字符串形式存储在数据集中，CNTK无法处理这些字符串值，它需要使用表示标签的独热编码向量。为了对标签进行编码，我们需要使用映射表和`one_hot`函数，您可以使用以下代码创建它：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Follow the given steps:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定的步骤操作：
- en: Use the `np.zeros` function to create a new vector of size `length` and fill
    it with zeros
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`np.zeros`函数创建一个大小为`length`的新向量，并用零填充它。
- en: Select the element at the provided `index` and set its value to `1`
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择提供的`index`处的元素，并将其值设置为`1`。
- en: Return the `result` so it can be used in the dataset
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回`result`，以便在数据集中使用。
- en: 'Once we have the numpy arrays in the right format, we can use them as before
    to train our model:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了格式正确的numpy数组，我们可以像以前一样使用它们来训练我们的模型：
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Follow the given steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定的步骤操作：
- en: Import the `cross_entropy_with_softmax` function as the loss for the model.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`cross_entropy_with_softmax`函数作为模型的损失函数。
- en: Then, import the `sgd` learner to optimize the parameters.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，导入`sgd`学习器以优化参数。
- en: After that, import the `ProgressPrinter` from the `logging` module to visualize
    the training progress.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，从`logging`模块导入`ProgressPrinter`以可视化训练进度。
- en: Next, create a new instance of the `ProgressPrinter` to log the output of the
    optimizer.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的`ProgressPrinter`实例，用于记录优化器的输出。
- en: Create a new `input_variable` to store the labels for training.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的`input_variable`来存储训练标签。
- en: Initialize the `sgd` learner and give it the parameters of the model and a learning
    rate of `0.1`.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`sgd`学习器，并给它模型的参数和一个学习率为`0.1`。
- en: Finally, invoke the `train` method on the loss and feed it the training data,
    the `learner` and the `progress_writer`. In addition to this provide the `train`
    method with a `minibatch_size` of `16` and set the `max_epochs` keyword argument
    to `5`.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，调用`train`方法并将训练数据、`learner`和`progress_writer`传递给它。此外，为`train`方法提供`minibatch_size`为`16`，并将`max_epochs`关键字参数设置为`5`。
- en: The `max_epochs` keyword argument for the `train` method on the `loss` function
    is optional. When you leave it out, the `trainer` will train the model for one
    epoch.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法中`loss`函数的`max_epochs`关键字参数是可选的。如果你不提供该参数，`trainer`将训练模型一个epoch。'
- en: 'We''re using `ProgressWriter` to generate output from the training process
    so we can monitor the progress of the training session. You can leave this out,
    but it''s a great help to get a sense of what is happening during training. With
    the progress writer configured, the output will look similar to this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`ProgressWriter`来生成训练过程的输出，以便我们监控训练过程的进展。你可以不使用它，但它对于理解训练过程中发生了什么非常有帮助。配置好进度写入器后，输出会类似于以下内容：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Since we're using the same method to train the network as with regular numpy
    arrays, we can control the batch size too. We'll leave it up to you to try different
    settings for the batch size and discover what produces the best model.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用与常规numpy数组相同的方法来训练网络，因此我们也可以控制批量大小。我们留给你尝试不同的批量大小设置，并发现哪个设置能产生最佳的模型。
- en: Working with large datasets
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理大数据集
- en: We've looked at NumPy and Pandas as ways to feed in-memory dataset to CNTK for
    training. But not every dataset is small enough to fit into memory. This is especially
    true for datasets that contain images, video samples, or sound samples. When you
    work with larger datasets, you only want to load small portions of the dataset
    at a time into memory. Usually, you will only load enough samples into memory
    to run a single minibatch of training.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过了NumPy和Pandas作为将内存中的数据集传递给CNTK进行训练的方式。但并非每个数据集都足够小，能够完全载入内存。对于包含图像、视频样本或声音样本的数据集尤其如此。当你处理更大的数据集时，你只希望一次加载数据集的小部分到内存中。通常，你只会加载足够的样本到内存中，以运行一个单一的minibatch训练。
- en: CNTK supports working with larger datasets through the use of `MinibatchSource`.
    Now, `MinibatchSource` is a component that can load data from disk in chunks.
    It can automatically randomize samples read from the data source. This is useful
    for preventing your neural network from overfitting due to a fixed order in the
    training dataset.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: CNTK支持通过使用`MinibatchSource`处理更大的数据集。现在，`MinibatchSource`是一个可以从磁盘分块加载数据的组件。它可以自动随机化从数据源读取的样本。这有助于防止神经网络由于训练数据集中的固定顺序而过拟合。
- en: '`MinibatchSource` has a built-in transformation pipeline. You can use this
    pipeline to augment your data. This is a useful feature when you work with data
    such as images. When you are training a model based on images, you want to make
    sure that an image is recognized even at a funny angle. The transformation pipeline
    allows you to generate extra samples by rotating the original images read from
    disk.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`MinibatchSource`具有内置的转换管道。你可以使用这个管道来增强数据。当你处理如图像之类的数据时，这是一个非常有用的功能。当你训练一个基于图像的模型时，你希望确保即使图像处于奇怪的角度，也能被识别。转换管道允许你通过旋转从磁盘读取的原始图像来生成额外的样本。'
- en: A unique feature of `MinibatchSource` is that it loads data on a background
    thread separate from the training process. By loading data in a separate thread,
    it can load minibatches ahead of time so that your graphics card doesn't get stalled
    on this process.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`MinibatchSource`的一个独特特点是，它会在与训练过程分开的后台线程中加载数据。通过在单独的线程中加载数据，它可以提前加载minibatch，这样你的显卡就不会因为这一过程而卡住。'
- en: In this chapter, we'll limit ourselves to the basic usage of `MinibatchSource`.
    In [Chapter 5](9d91a0e4-3870-4a2f-b483-82fdb8849bc2.xhtml), *Working with Images**,*
    and [Chapter 6](a5da9ef2-399a-4c30-b751-318d64939369.xhtml), *Working with Time
    Series Data*, we'll look at how you can use the `MinibatchSource` component with
    images and time series data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将限制在`MinibatchSource`的基本使用上。在[第5章](9d91a0e4-3870-4a2f-b483-82fdb8849bc2.xhtml)，《*与图像的工作*》和[第6章](a5da9ef2-399a-4c30-b751-318d64939369.xhtml)，《*与时间序列数据的工作*》中，我们将探讨如何使用`MinibatchSource`组件处理图像和时间序列数据。
- en: Let's explore how to use a minibatch source with out-of-memory data to work
    with larger datasets and use it to feed data for training a neural network.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨如何使用minibatch源处理内存外数据，以便处理更大的数据集，并将其用于训练神经网络。
- en: Creating a MinibatchSource instance
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建MinibatchSource实例
- en: 'In the section, *Working with pandas DataFrames*, we worked on the iris flower
    example. Let''s go back and replace the code that uses data from a pandas DataFrame
    with `MinibatchSource`. The first step is to create a basic `MinibatchSource`
    instance:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在*与pandas DataFrame的工作*部分，我们处理了鸢尾花的例子。让我们回过头来，将使用来自pandas DataFrame的数据的代码替换为`MinibatchSource`。第一步是创建一个基本的`MinibatchSource`实例：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Follow the given steps:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定的步骤操作：
- en: First, import the components for the minibatch source from the `io` module.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从`io`模块导入用于minibatch源的组件。
- en: Next, create a stream definition for the labels using the `StreamDef` class.
    Use the labels field and set it to read `3` features from the stream. Make sure
    to use the `is_sparse` keyword argument and set it to `False`.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`StreamDef`类为标签创建流定义。使用标签字段并设置为从流中读取`3`个特征。确保使用`is_sparse`关键字参数并将其设置为`False`。
- en: Then, create another `StreamDef` instance and read the features field from the
    input file. This stream has `4` features. Use the `is_sparse` keyword argument
    to specify that the data is stored as dense vectors.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，创建另一个`StreamDef`实例，并从输入文件中读取特征字段。此流具有`4`个特征。使用`is_sparse`关键字参数指定数据以密集向量形式存储。
- en: After that, initialize the `deserializer`. Provide the `iris.ctf` file as the
    input and feed it the stream definitions by wrapping them in a `StreamDefs` instance.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，初始化`deserializer`。提供`iris.ctf`文件作为输入，并通过将其包装在`StreamDefs`实例中来传递流定义。
- en: Finally, create a `MinibatchSource` instance using the `deserializer`.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用`deserializer`创建`MinibatchSource`实例。
- en: Creating CTF files
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建CTF文件
- en: 'The data that we''re using comes from the file `iris.ctf` and is stored in
    a file format called **CNTK Text Format** (**CTF**). This is a file format that
    looks like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用的数据来自`iris.ctf`文件，并存储在一种叫做**CNTK文本格式**（**CTF**）的文件格式中。这是一种类似这样的文件格式：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Each line contains a single sample for our neural network. Each line can contain
    values for multiple inputs of our model. Each input is preceded by a vertical
    pipe. The values for each input are separated by a space.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行包含我们神经网络的一个样本。每一行可以包含多个输入的值。每个输入前面都有一个竖线。每个输入的值由一个空格分隔。
- en: The `CTFDeserializer` can read the file by using the stream definitions that
    we initialized in the code sample.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`CTFDeserializer`可以通过使用我们在代码示例中初始化的流定义来读取文件。'
- en: In order to get the data for the `MinibatchSource` instance we just created,
    you need to create a CTF file for our dataset. There's no official converter to
    turn data formats such as **Comma-Separated Value** (**CSV**) into CTF files,
    so you need to write some Python code. You can find the code to prepare a CTF
    file for training with a minibatch size in the `Creating a CTF file.ipynb` notebook
    in the sample code for this chapter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取我们刚刚创建的`MinibatchSource`实例的数据，您需要为我们的数据集创建一个CTF文件。目前没有官方的转换器可以将诸如**逗号分隔值**（**CSV**）这样的数据格式转换为CTF文件，因此您需要编写一些Python代码。您可以在本章的示例代码中的`Creating
    a CTF file.ipynb`笔记本中找到准备CTF文件以进行minibatch训练的代码。
- en: 'Let''s explore how to create a CTF file using Python. The first step is to
    load the data into memory and convert it to the correct format:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨如何使用Python创建CTF文件。第一步是将数据加载到内存中并转换为正确的格式：
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Follow the given steps:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定的步骤操作：
- en: Before we start to process the data, import the `pandas` and `numpy` packages
    to get access to the data processing functions.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们开始处理数据之前，导入`pandas`和`numpy`包，以便访问数据处理函数。
- en: First, load the `iris.csv` file into memory and store it in the `df_source`
    variable.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，将`iris.csv`文件加载到内存中，并将其存储在`df_source`变量中。
- en: Then, take the contents of the first four columns using the `iloc` indexer as
    the features.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用`iloc`索引器获取前四列的内容作为特征。
- en: Next, use the data from species column as the labels for our dataset.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用物种列中的数据作为我们数据集的标签。
- en: Now create a `label_mapping` dictionary to create a mapping between the label
    name and its numeric representation.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个`label_mapping`字典，用于在标签名称和其数字表示之间建立映射。
- en: Finally, convert the labels to a set of one-hot encoded vectors using a Python
    list comprehension and the `one_hot` function.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 Python 列表推导式和`one_hot`函数将标签转换为一组独热编码向量。
- en: 'To encode the labels we''ll use a utility function called `one_hot` that you
    can create using the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对标签进行编码，我们将使用一个名为`one_hot`的实用函数，你可以使用以下代码创建它：
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Follow the given steps:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定步骤操作：
- en: Generate a new empty vector with the specified `length` using the `np.zeros`
    function
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`np.zeros`函数生成一个指定`length`的空向量
- en: Next, take the element at the specified `index` and set it to `1`
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，取指定`index`处的元素并将其设置为`1`
- en: Finally, return the newly generated one-hot encoded vector so you can use it
    in the rest of your code
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，返回新生成的独热编码向量，以便你可以在代码的其余部分中使用它
- en: 'Once we have loaded and preprocessed the data, we can store it on disk in the
    CTF file format:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦加载并预处理了数据，我们就可以将其存储到磁盘上的CTF文件格式中：
- en: '[PRE16]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Follow the given steps:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定步骤操作：
- en: First, we open the `iris.ctf` file for writing
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们打开`iris.ctf`文件进行写入
- en: Then, iterate over all the records in the dataset
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，遍历数据集中的所有记录
- en: For each record, create a new string containing the serialized values for the
    `features` vector
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每条记录，创建一个新字符串，包含`features`向量的序列化值
- en: Next, serialize the `labels` to a string using a Python list comprehension
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用 Python 列表推导式将`labels`序列化为字符串
- en: Finally, write the `features` and `labels` to the file
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将`features`和`labels`写入文件
- en: The elements in the `features` and `labels` vector should be separated by a
    space. Note that each of the serialized pieces of data gets prefixed by a pipe-character
    and its name in the output file.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`features`和`labels`向量中的元素应由空格分隔。请注意，输出文件中的每个序列化数据片段都以管道字符和其名称为前缀。'
- en: Feeding data into a training session
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据输入到训练会话中
- en: 'To train with `MinibatchSource`, we can use the same training logic as before.
    Only this time, we''ll use `MinibatchSource` as the input for the `train` method
    on the `loss` function:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`MinibatchSource`进行训练，我们可以使用之前的相同训练逻辑。只不过这次，我们将使用`MinibatchSource`作为`train`方法在`loss`函数中的输入：
- en: '[PRE17]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Follow the given steps:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定步骤操作：
- en: First, import the `ProgressPrinter` so we can log the output of the training
    session.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入`ProgressPrinter`，这样我们就能记录训练会话的输出。
- en: Next, import the `trainer` and the `training_session`, you'll need these to
    set up the training session.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，导入`trainer`和`training_session`，你将需要这些来设置训练会话。
- en: Then, define a set of constants for the training code. The `minibatch_size`
    to control the number of samples per batch, `samples_per_epoch` to control the
    number of samples in a single epoch and finally the `num_epochs` setting to control
    the number of epochs to train for.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，定义一组常量用于训练代码。`minibatch_size`用来控制每批次的样本数量，`samples_per_epoch`用来控制单个epoch中的样本数量，最后是`num_epochs`设置，用来控制训练的轮数。
- en: Define a mapping between the input variables for the network and the streams
    in the minibatch source so CNTK knows how to read data during training.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为网络的输入变量和小批量源中的流定义映射，这样 CNTK 就知道如何在训练期间读取数据。
- en: Then, initialize the `progress_writer` variable with a new `ProgressPrinter`
    instance to log the output of the training process.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，用新的`ProgressPrinter`实例初始化`progress_writer`变量，用于记录训练过程中的输出。
- en: Finally, invoke the `train` method on the `loss` providing the `MinibatchSource`
    and the `input_map` in the `model_inputs_to_stream keyword` argument.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在`loss`上调用`train`方法，提供`MinibatchSource`和`input_map`作为`model_inputs_to_stream
    keyword`参数。
- en: 'You can run the code from this section when you open `Training with a minibatch
    source.ipynb` from the sample code for this chapter. We''ve included a `progress
    printer` instance to visualize the output of the training session. When you run
    the code, you will get output similar to this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当你从本章的示例代码中打开`Training with a minibatch source.ipynb`时，你可以运行此部分的代码。我们已经包括了一个`progress
    printer`实例，用于可视化训练会话的输出。运行代码后，你将看到类似以下的输出：
- en: '[PRE18]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Taking control over the minibatch loop
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制小批量循环
- en: In the previous section, we've seen how to use the CTF format with `MinibatchSource`
    to feed data to the CNTK trainer. But most datasets don't come in this format.
    So, you can't really use this format unless you create your own dataset or convert
    the original dataset to the CTF format.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们已经看到了如何使用`MinibatchSource`配合CTF格式将数据传递给CNTK训练器。但是大多数数据集并不是以这种格式提供的。因此，除非你创建自己的数据集或将原始数据集转换为CTF格式，否则你不能使用这种格式。
- en: CNTK currently supports a limited set of `deserializers` for images, text, and
    speech. You can't extend the deserializers at the moment, which limits what you
    can do with the standard `MinibatchSource`. You can create your own `UserMinibatchSource`,
    but this is a complicated process. So, instead of showing you how to build a custom
    `MinibatchSource`, let's look at how to feed data into the CNTK trainer manually.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: CNTK当前仅支持有限的`deserializers`，用于图像、文本和语音。你目前不能扩展这些反序列化器，这限制了你使用标准`MinibatchSource`的能力。你可以创建自己的`UserMinibatchSource`，但这是一个复杂的过程。所以，在这里我们不会向你展示如何构建自定义的`MinibatchSource`，而是看一下如何手动将数据传递给CNTK训练器。
- en: 'Let''s first recreate the model we used to classify Iris flowers:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先重建用于分类鸢尾花的模型：
- en: '[PRE19]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The model remains the same as in previous sections; it is a basic classification
    model with four input neurons and three output neurons. We'll be using a categorical
    cross-entropy loss since this is a multi-class classification problem.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 模型与前几节保持一致；它是一个基本的分类模型，具有四个输入神经元和三个输出神经元。我们将使用类别交叉熵损失，因为这是一个多类别分类问题。
- en: 'Let''s train the model using a manual minibatch loop:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用手动小批量循环来训练模型：
- en: '[PRE20]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Follow the given steps:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 按照给定的步骤进行：
- en: First, import the components needed for training the neural network.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入训练神经网络所需的组件。
- en: Next, define an `input _variable` to store the labels.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义一个`input_variable`来存储标签。
- en: Then, define the `loss` function using the `cross_entropy_with_softmax` function
    and connect the output of the neural network and the labels variable to it.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用`cross_entropy_with_softmax`函数定义`loss`函数，并将神经网络的输出和标签变量连接到它。
- en: After that, initialize the `learner` with the parameters of the neural network
    and a learning rate of `0.1`.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，使用神经网络的参数和学习率`0.1`初始化`learner`。
- en: Create a new instance of the `ProgressWriter` to log the output of the training
    process.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的`ProgressWriter`实例，用于记录训练过程的输出。
- en: Next, create a new instance of the `Trainer` class and initialize it with the
    network, the `loss`, the `learner` and the `progress_writer`.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建`Trainer`类的新实例，并使用网络、`loss`、`learner`和`progress_writer`对其进行初始化。
- en: After you've initialized the network, Load the dataset from disk and use the
    `chunksize` keyword argument so it is read in chunks rather than loading the dataset
    into memory in one operation.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化网络后，从磁盘加载数据集，并使用`chunksize`关键字参数，使其分块读取，而不是一次性将整个数据集加载到内存中。
- en: Now create a new `for` loop to iterate over the chunks of the dataset.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在创建一个新的`for`循环，遍历数据集的各个数据块。
- en: Process each chunk by extracting the `labels` and `features` from it in the
    appropriate format. Use the first four columns as the input features for the neural
    network and the last column as the labels.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提取适当格式的`labels`和`features`来处理每个数据块。使用前四列作为神经网络的输入特征，最后一列作为标签。
- en: Convert the label values to one-hot encoded vectors using the `one_hot` function
    from the section *Working with pandas DataFrames.*
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`one_hot`函数将标签值转换为独热编码向量，该函数来自于*与pandas DataFrame一起使用*章节。
- en: Finally, call the `train_minibatch` method on the `trainer` and feed it the
    `features` and `labels`.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，调用`trainer`上的`train_minibatch`方法，并将`features`和`labels`传递给它。
- en: Note that we didn't write any code to run multiple epochs of training. If you
    want, you can introduce this into the code by wrapping the logic for reading and
    processing minibatches from the CSV file in another `for` loop. Check out the
    `Training with a manual minibatch loop.ipynb` notebook in the sample code for
    this chapter to give it a try.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们没有编写任何代码来运行多轮训练。如果你需要，你可以通过在另一个`for`循环中包装读取和处理CSV文件中小批量数据的逻辑来实现。可以参考本章示例代码中的`Training
    with a manual minibatch loop.ipynb`笔记本来尝试一下。
- en: You will find that preparing a single minibatch is a lot more work with a manual
    minibatch loop. This comes mainly from the fact that we're not using the automatic
    chunking that comes with the standard `MinibatchSource` logic. Also, since we
    haven't preprocessed the dataset beforehand, we need to encode the labels during
    training.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，使用手动小批量循环准备单个小批量需要更多的工作。这主要是因为我们没有使用标准`MinibatchSource`逻辑中的自动分块功能。此外，由于我们没有事先对数据集进行预处理，我们需要在训练过程中对标签进行编码。
- en: When you have to work with a large dataset and can't use `MinibatchSource`,
    a manual minibatch loop is your last resort. It is, however, much more powerful
    because you get a lot more control over how your model is trained. Using a manual
    minibatch loop can be very useful if you want to perform complex operations on
    each minibatch or change settings as the training progresses.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当你必须处理大型数据集且无法使用`MinibatchSource`时，手动小批量循环是最后的选择。然而，这种方法更强大，因为你可以更好地控制模型的训练过程。如果你希望对每个小批量执行复杂的操作或在训练过程中更改设置，使用手动小批量循环会非常有用。
- en: Summary
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've explored how you can train your neural networks with
    both small and large datasets. For smaller datasets, we've looked at how you can
    quickly train a model by calling the `train` method on the `loss` function. For
    larger datasets, we've explored how you can use both `MinibatchSource` and a manual
    minibatch loop to train your network.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了如何使用小型和大型数据集来训练神经网络。对于较小的数据集，我们讨论了如何通过在`loss`函数上调用`train`方法来快速训练模型。对于较大的数据集，我们则探索了如何同时使用`MinibatchSource`和手动小批量循环来训练网络。
- en: Using the right method of training can make a big difference in how long it
    takes to train your model and how good your model will be in the end. You can
    now make an informed choice between using in-memory data and reading data in chunks.
    Make sure you experiment with the minibatch size settings to see what works best
    for your model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正确的训练方法可以显著影响训练模型所需的时间以及最终模型的效果。现在你可以在使用内存数据和分块读取数据之间做出明智的选择。确保你通过调整小批量大小设置来进行实验，看看哪个设置最适合你的模型。
- en: Up until this chapter, we haven't looked at methods to monitor your model. We
    did see some fragments with a progress writer to help you visualize the training
    process. But that's pretty limited.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 直到本章为止，我们还没有研究如何监控你的模型。我们确实看过一些使用进度写入器的片段，帮助你可视化训练过程，但这些功能相对有限。
- en: In the next chapter, we'll learn how to measure the performance of neural networks.
    We'll also explore how to monitor and debug CNTK models using different visualization
    and monitoring tools.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何衡量神经网络的性能。我们还将探讨如何使用不同的可视化和监控工具来监控和调试CNTK模型。
