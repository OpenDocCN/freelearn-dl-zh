- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Cross-Validation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: '**Cross-validation** is a statistical technique used to assess how well a machine
    learning model generalizes to unseen data. It involves partitioning a dataset
    into multiple subsets or “folds,” training the model on some of these subsets
    while testing it on the remaining ones. This process is repeated to ensure a reliable
    performance estimate. This helps detect overfitting and provides a more robust
    evaluation than a single train-test split. In the context of LLMs, cross-validation
    must be adapted to address the complexities of pre-training, fine-tuning, few-shot
    learning, and domain generalization, making it an essential tool for evaluating
    model performance across varied tasks and data distributions.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉验证**是一种统计技术，用于评估机器学习模型对未见数据的泛化能力。它涉及将数据集划分为多个子集或“折”，在这些子集上训练模型，同时在剩余的子集上进行测试。这个过程会重复进行，以确保可靠的性能估计。这有助于检测过拟合，并提供比单一训练-测试分割更稳健的评估。在LLM的背景下，交叉验证必须适应解决预训练、微调、少样本学习和领域泛化的复杂性，使其成为评估模型在多种任务和数据分布上性能的必要工具。'
- en: In this chapter, you will explore cross-validation strategies specifically designed
    for LLMs. We’ll delve into methods for creating appropriate data splits for pre-training
    and fine-tuning, as well as strategies for few-shot and zero-shot evaluation.
    You’ll learn how to assess domain and task generalization in LLMs and handle the
    unique challenges of cross-validation in the context of LLMs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将探索专门为LLM设计的交叉验证策略。我们将深入研究创建适当的预训练和微调数据分割的方法，以及少样本和零样本评估的策略。你将学习如何评估LLM中的领域和任务泛化，并处理LLM背景下交叉验证的独特挑战。
- en: By the end of this chapter, you’ll be equipped with robust cross-validation
    techniques to reliably assess your LLM’s performance and generalization capabilities
    across various domains and tasks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将掌握强大的交叉验证技术，以可靠地评估你的LLM在各种领域和任务上的性能和泛化能力。
- en: 'In this chapter, we’ll be covering the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下主题：
- en: Pre-training and fine-tuning data splits
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预训练和微调数据分割
- en: Few-shot and zero-shot evaluation strategies
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少样本和零样本评估策略
- en: Domain and task generalization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域和任务泛化
- en: Continual learning evaluation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续学习评估
- en: Cross-validation challenges and best practices
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证的挑战和最佳实践
- en: Pre-training and fine-tuning data splits
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练和微调数据分割
- en: In LLMs, data splits refer to the division of datasets into training, validation,
    and test sets to ensure the model learns generalizable patterns rather than memorizing
    data. This is essential for evaluating performance fairly, tuning model parameters,
    and preventing data leakage. Proper splitting is especially important in LLMs
    due to their scale, the diversity of tasks, and the need to assess domain and
    task generalization.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM中，数据分割指的是将数据集划分为训练集、验证集和测试集，以确保模型学习可泛化的模式，而不是记住数据。这对于公平地评估性能、调整模型参数和防止数据泄露至关重要。在LLM中，适当的分割尤为重要，因为它们的规模很大，任务多样性高，并且需要评估领域和任务泛化。
- en: Stratified sampling for pre-training data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预训练数据的分层抽样
- en: '**Stratified sampling** is a sampling method that first divides the population
    into smaller subgroups (**strata**) based on shared characteristics and then randomly
    samples from within each stratum to ensure proportional representation of all
    groups in the final sample. This is particularly useful when dealing with imbalanced
    datasets.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**分层抽样**是一种抽样方法，首先根据共享特征将总体划分为更小的子组（**层**），然后从每个层中随机抽样以确保在最终样本中所有组按比例代表。这在处理不平衡数据集时特别有用。'
- en: 'When creating data splits for pre-training, it’s important to ensure that each
    split represents the diversity of the entire dataset. Here’s an example of how
    you might implement **stratified sampling** for pre-training data:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建预训练数据分割时，确保每个分割代表整个数据集的多样性非常重要。以下是一个你可能用于预训练数据的**分层抽样**示例：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code uses `StratifiedShuffleSplit` to create a stratified split of the
    pre-training data, ensuring that the distribution of domains (or any other relevant
    categorical variable) is similar in both the training and test sets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用`StratifiedShuffleSplit`创建预训练数据的分层分割，确保训练集和测试集中领域的分布（或任何其他相关分类变量）相似。
- en: Time-based splitting for fine-tuning data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于时间的微调数据分割
- en: For fine-tuning tasks that involve time-sensitive data, it’s often beneficial
    to use **time-based splitting**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于涉及时间敏感数据的微调任务，使用**基于时间的分割**通常是有益的。
- en: Time-based splitting is a data partitioning strategy where the dataset is divided
    according to chronological order, ensuring that earlier data is used for training
    and later data for validation or testing. This approach is especially important
    for fine-tuning tasks involving time-sensitive data—such as financial forecasting,
    user behavior modeling, or event prediction—where future information should not
    influence past training. By preserving the natural temporal sequence, time-based
    splitting helps evaluate how well a model can generalize to future, unseen scenarios,
    closely mimicking real-world deployment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 基于时间的分割是一种数据分区策略，其中数据集根据时间顺序进行划分，确保早期数据用于训练，而后期数据用于验证或测试。这种方法对于涉及时间敏感数据的微调任务尤为重要——例如金融预测、用户行为建模或事件预测——在这些任务中，未来的信息不应影响过去的训练。通过保留自然的时间序列，基于时间的分割有助于评估模型对未来未见场景的泛化能力，紧密模拟现实世界的部署。
- en: 'This approach helps evaluate how well the model generalizes to future data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法有助于评估模型对未来数据的泛化能力：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This function splits the data based on a specified date, which is particularly
    useful for tasks where the model needs to generalize to future events or trends.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数根据指定的日期分割数据，这对于模型需要泛化到未来事件或趋势的任务特别有用。
- en: Oversampling and weighting techniques for data balancing
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据平衡的过采样和加权技术
- en: When working with datasets that have an uneven distribution of categories, such
    as imbalanced domains or label frequencies, **oversampling** and **weighting techniques**
    can help ensure that the model learns effectively from all classes. Oversampling
    involves replicating examples from underrepresented categories to increase their
    presence in the training data, preventing the model from ignoring them. This can
    be done using methods such as random oversampling or synthetic data generation
    (e.g., SMOTE for structured data). On the other hand, weighting techniques adjust
    the loss function by assigning higher importance to underrepresented categories,
    so the model learns from them without necessarily increasing the dataset size.
    Both approaches help mitigate bias, improving the model’s ability to generalize
    across all categories, rather than favoring the most frequent ones.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理类别分布不均的数据集时，例如不平衡领域或标签频率，**过采样**和**加权技术**可以帮助确保模型从所有类别中有效地学习。过采样涉及复制来自代表性不足类别的示例，以增加其在训练数据中的存在，防止模型忽略它们。这可以通过随机过采样或合成数据生成方法（例如，SMOTE用于结构化数据）来完成。另一方面，加权技术通过为代表性不足的类别分配更高的重要性来调整损失函数，因此模型可以从它们中学习，而无需
    necessarily 增加数据集的大小。两种方法都有助于减轻偏差，提高模型在所有类别中泛化的能力，而不是偏向最频繁的类别。
- en: 'Here’s a short code example demonstrating oversampling and class weighting
    techniques using PyTorch and sklearn, applied to a text classification task:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个简短的代码示例，展示了使用PyTorch和sklearn的过采样和类加权技术，应用于文本分类任务：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The code demonstrates two common techniques for addressing class imbalance
    in classification tasks: class weighting and oversampling. First, it uses `compute_class_weight`
    of `sklearn` to calculate weights inversely proportional to class frequencies,
    assigning higher importance to underrepresented classes (e.g., class 2, which
    appears less often). These weights are passed to PyTorch’s `CrossEntropyLoss`,
    so that during training, misclassifying rare classes penalizes the model more
    than misclassifying common ones. Second, it performs oversampling by computing
    a per-sample weight based on the inverse frequency of each sample’s class, which
    ensures that samples from minority classes have a higher probability of being
    selected during training. These sample weights are used to initialize PyTorch’s
    `WeightedRandomSampler`, which enables the `DataLoader` to sample training data
    in a balanced way across classes without having to physically duplicate data.
    Together, these techniques help the model learn to treat all classes fairly, improving
    its generalization on imbalanced datasets.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码演示了两种解决分类任务中类别不平衡的常见技术：类别权重和过采样。首先，它使用 `sklearn` 的 `compute_class_weight`
    来计算与类别频率成反比的权重，将更高的重要性分配给代表性不足的类别（例如，出现频率较低的类别 2）。这些权重被传递到 PyTorch 的 `CrossEntropyLoss`，因此在训练过程中，对稀有类别的误分类比常见类别的误分类对模型的惩罚更大。其次，它通过根据每个样本类别的逆频率计算每个样本的权重来进行过采样，这确保了在训练过程中，来自少数类别的样本有更高的概率被选中。这些样本权重用于初始化
    PyTorch 的 `WeightedRandomSampler`，这使得 `DataLoader` 能够在类之间以平衡的方式采样训练数据，而无需实际复制数据。这些技术共同帮助模型学会公平地对待所有类别，从而提高其在不平衡数据集上的泛化能力。
- en: Few-shot and zero-shot evaluation strategies
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 少样本和零样本评估策略
- en: Few-shot and zero-shot evaluation strategies enable LLMs to generalize across
    tasks without requiring extensive retraining. Zero-shot learning is useful for
    tasks where no labeled examples are available, while few-shot learning enhances
    performance by providing limited guidance. These methods are key to making LLMs
    adaptable and scalable for real-world applications.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本和零样本评估策略使大型语言模型（LLMs）能够在不进行大量重新训练的情况下跨任务泛化。零样本学习在无标签示例可用的情况下很有用，而少样本学习通过提供有限的指导来提高性能。这些方法是使
    LLMs 能够适应现实世界应用并可扩展的关键。
- en: 'Here is a comparison between the two strategies:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这两种策略的比较：
- en: '| **Aspect** | **Zero-shot** | **Few-shot** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **方面** | **零样本** | **少样本** |'
- en: '| **Description** | No examples; model must infer task from prompt alone |
    Provides a small number of labeled examples in the prompt |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | 无示例；模型必须仅从提示中推断任务 | 在提示中提供少量标签示例 |'
- en: '| **Strengths** | No labeled data needed, highly flexible | Higher accuracy,
    better task comprehension |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | 不需要标签数据，高度灵活 | 准确率更高，对任务理解更好 |'
- en: '| **Weaknesses** | Lower accuracy, risk of ambiguity | Requires careful example
    selection, still less effective than fine-tuning |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **弱点** | 准确率较低，存在歧义风险 | 需要仔细选择示例，仍然不如微调有效 |'
- en: '| **Use Cases** | Open-ended Q&A, commonsense reasoning, general-knowledge
    tasks | Text classification, translation, summarization, code generation |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| **用例** | 开放式问答，常识推理，通用知识任务 | 文本分类，翻译，摘要，代码生成 |'
- en: Table 15.1 – Few-shot vs. zero-shot
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表 15.1 – 少样本与零样本
- en: Let’s see how to implement each of these strategies.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何实现这些策略中的每一个。
- en: Few-shot evaluation
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少样本评估
- en: 'In **few-shot evaluation**, we provide the model with a small number of examples
    before asking it to perform a task. Here’s an example of how you might implement
    few-shot evaluation:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在**少样本评估**中，我们在要求模型执行任务之前，向模型提供少量示例。以下是一个实现少样本评估的示例：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code demonstrates how to perform few-shot evaluation on a sentiment analysis
    task using a pre-trained GPT-2 model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码演示了如何使用预训练的 GPT-2 模型在情感分析任务上执行少样本评估。
- en: The `few_shot_evaluate` function takes a GPT-2 model, tokenizer, task description,
    examples, and a test instance as input. It constructs a `tokenizer.encode`, converting
    it into numerical tokens suitable for the model. The function then uses `model.generate`
    inside a `torch.no_grad()` block to generate text without computing gradients,
    making inference more efficient. The model generates a response with a maximum
    length of `100` tokens, ensuring it stays concise. The generated text is then
    decoded using `tokenizer.decode`, with `skip_special_tokens=True` to remove unwanted
    tokens. Finally, the function extracts the part of the response after the last
    occurrence of `"Output:"` to isolate the model’s generated answer, trimming any
    extra whitespace. This approach effectively enables **few-shot learning**, where
    the model leverages provided examples to make a more informed prediction.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`few_shot_evaluate` 函数接收一个 GPT-2 模型、分词器、任务描述、示例和一个测试实例作为输入。它构建一个 `tokenizer.encode`，将其转换为适合模型处理的数值标记。然后，该函数在
    `torch.no_grad()` 块中使用 `model.generate` 来生成文本，不计算梯度，使推理更高效。模型生成的响应最长为 `100` 个标记，确保其简洁。随后，使用
    `tokenizer.decode` 对生成的文本进行解码，通过设置 `skip_special_tokens=True` 来移除不需要的标记。最后，该函数提取响应中最后一个
    `"Output:"` 发生之后的部分，以隔离模型生成的答案，并修剪任何额外的空白字符。这种方法有效地实现了 **少样本学习**，其中模型利用提供的示例来做出更明智的预测。'
- en: Zero-shot evaluation
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本评估
- en: '**Zero-shot evaluation** tests a model’s ability to perform a task without
    any specific examples. Here’s how you might implement zero-shot evaluation:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**零样本评估** 测试模型在没有特定示例的情况下执行任务的能力。以下是实现零样本评估的方法：'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This function demonstrates zero-shot evaluation on a text classification task.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数演示了在文本分类任务上的零样本评估。
- en: 'The `zero_shot_evaluate` function performs `task_description` with `test_instance`,
    ensuring that the model understands the task and what it needs to classify. The
    phrase `"Output:"` is appended to signal where the model should generate its response.
    The prompt is then tokenized using tokenizer.encode, converting it into numerical
    input tensors that the model can process. The function uses `torch.no_grad()`
    to disable gradient computation, making inference more efficient. The `model.generate`
    function takes the tokenized prompt and generates an output sequence with a maximum
    length of `100` tokens while returning only one sequence. The generated output
    is then decoded back into text using `tokenizer.decode`, ensuring that any special
    tokens are removed. Finally, the function extracts and returns the portion of
    the generated text that appears after `"Output:"`, which represents the model’s
    predicted classification. In the example usage, the function is applied to a classification
    task where the model is asked to categorize a given text snippet`—"NASA''s Mars
    rover has discovered traces of ancient microbial life."`—into one of the predefined
    categories: `Science`, `Politics`, `Sports`, or `Entertainment`. The model, without
    seeing any labeled examples, infers the correct category based on its prior knowledge.
    The output is then printed, demonstrating the model’s zero-shot classification
    ability.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`zero_shot_evaluate` 函数使用 `test_instance` 执行 `task_description`，确保模型理解任务及其需要分类的内容。短语
    `"Output:"` 被附加以指示模型应生成响应的位置。然后，使用分词器.encode 对提示进行标记化，将其转换为模型可以处理的数值输入张量。函数使用
    `torch.no_grad()` 禁用梯度计算，使推理更高效。`model.generate` 函数接收标记化的提示，并生成一个最大长度为 `100` 个标记的输出序列，同时只返回一个序列。生成的输出随后使用
    `tokenizer.decode` 解码回文本，确保移除任何特殊标记。最后，函数提取并返回出现在 `"Output:"` 之后的部分，这代表了模型的预测分类。在示例用法中，该函数应用于一个分类任务，模型被要求将给定的文本片段`——“NASA的火星探测器发现了古代微生物生命的痕迹。”`分类到预定义的类别之一：`科学`、`政治`、`体育`或`娱乐`。模型没有看到任何标记的示例，根据其先验知识推断出正确的类别。然后输出被打印出来，展示了模型的零样本分类能力。'
- en: Domain and task generalization
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 领域和任务泛化
- en: Assessing how well an LLM generalizes across different domains and tasks is
    crucial for understanding its true capabilities. Let’s explore some techniques
    for this purpose.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 评估一个大型语言模型（LLM）在不同领域和任务上的泛化能力对于理解其真实能力至关重要。让我们探讨一些用于此目的的技术。
- en: Evaluating domain adaptation
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估领域自适应
- en: 'To evaluate **domain adaptation**, we can test the model on data from a different
    domain than it was trained on. Here’s an example:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 **领域自适应**，我们可以测试模型在训练领域之外的数据上的表现。以下是一个示例：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following is how we evaluate domain adaptation and print out the result:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们评估领域自适应并输出结果的方法：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Putting it together, we can use the preceding code to evaluate the model’s performance
    on both the source domain (what it was trained on) and the target domain, calculating
    the drop in performance as a measure of domain adaptation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码整合起来，我们可以使用它来评估模型在源域（它所训练的域）和目标域上的性能，计算性能下降作为领域自适应的度量。
- en: Evaluating task generalization
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估任务泛化
- en: 'To assess **task generalization**, we can evaluate the model on a variety of
    tasks it wasn’t specifically fine-tuned for. Here’s an example using the GLUE
    benchmark (which we discussed in [*Chapter 14*](B31249_14.xhtml#_idTextAnchor230)):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估**任务泛化能力**，我们可以评估模型在它没有特定微调的各种任务上的表现。以下是一个使用GLUE基准（我们在[*第14章*](B31249_14.xhtml#_idTextAnchor230)中讨论过）的例子：
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following is how to run the evaluation based on the previously defined
    function:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于先前定义的函数运行评估的方法：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Putting together the preceding code, we can evaluate the model on multiple GLUE
    tasks to assess its ability to generalize across different NLP tasks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码整合起来，我们可以评估模型在多个GLUE任务上的表现，以评估其跨不同NLP任务的泛化能力。
- en: Continual learning evaluation
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续学习评估
- en: '**Continual learning** is the ability of a model to learn new tasks without
    forgetting previously learned ones. Here’s an example of how you might evaluate
    continual learning in LLMs:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**持续学习**是指模型在不会忘记先前学习的内容的情况下学习新任务的能力。以下是如何在LLMs中评估持续学习的例子：'
- en: 'Set up our continual learning framework by initializing the model, the tokenizer,
    and the main function structure:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过初始化模型、分词器和主要函数结构来设置我们的持续学习框架：
- en: '[PRE9]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Define the preprocessing function that handles different input formats for
    various GLUE tasks:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义预处理函数，以处理各种GLUE任务的不同输入格式：
- en: '[PRE10]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Preprocess and prepare the dataset for each task:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理并准备每个任务的训练数据集：
- en: '[PRE11]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Provide the training setup and execution for each task:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供每个任务的训练设置和执行：
- en: '[PRE12]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Conduct an evaluation across all previously seen tasks:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有先前看到的任务上执行评估：
- en: '[PRE13]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Run the evaluation and display the results:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行评估并显示结果：
- en: '[PRE14]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Putting the preceding code blocks together, we show how to fine-tune the model
    on a sequence of tasks and evaluate its performance on all previously seen tasks
    after each fine-tuning step, allowing us to assess how well it retains knowledge
    of earlier tasks.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码块整合起来，我们展示了如何对一系列任务进行微调，并在每次微调步骤之后评估模型在所有先前看到的任务上的性能，从而评估它保留早期任务知识的能力。
- en: Cross-validation challenges and best practices
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证的挑战和最佳实践
- en: 'LLMs present unique challenges for cross-validation due to their scale and
    the nature of their training data. Here are some key challenges:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLMs的规模和训练数据的性质，它们在交叉验证中面临独特的挑战。以下是一些关键挑战：
- en: '**Data contamination**: Avoiding test set overlap with pre-training data is
    difficult given the vast and diverse web data LLMs are trained on, making it hard
    to ensure a truly unseen validation set'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据污染**：由于LLM训练所依赖的互联网数据非常庞大且多样化，避免测试集与预训练数据重叠变得困难，这使得确保一个真正未见过的验证集变得很困难'
- en: '**Computational cost**: Traditional methods such as k-fold cross-validation
    are often infeasible due to the immense computational resources required for models
    of this scale'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算成本**：由于需要巨大的计算资源，传统的k折交叉验证方法通常不可行'
- en: '**Domain shift**: LLMs may show inconsistent performance when exposed to data
    from underrepresented or entirely new domains, complicating the evaluation of
    generalizability'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域偏移**：当LLM接触到来自代表性不足或全新的领域的数据时，可能会表现出不一致的性能，这复杂了泛化能力的评估'
- en: '**Prompt sensitivity**: The performance of LLMs can vary significantly based
    on subtle differences in prompt wording, adding another layer of variability to
    the validation process'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示敏感性**：LLMs的性能可能会根据提示措辞的微妙差异而有很大差异，这为验证过程增加了另一层可变性'
- en: 'Based on these challenges, here are some best practices for LLM cross-validation:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些挑战，以下是LLM交叉验证的一些最佳实践：
- en: '**Mitigate data contamination**: Use rigorous data deduplication methods to
    identify and remove overlaps between the pre-training corpus and validation datasets.
    Tools such as MinHash or Bloom filters can efficiently detect near-duplicates
    in large datasets.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减轻数据污染**：使用严格的数据去重方法来识别和删除预训练语料库和验证数据集之间的重叠。例如，MinHash或Bloom过滤器可以在大型数据集中有效地检测近重复项。'
- en: MinHash
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: MinHash
- en: '**MinHash** is a probabilistic technique for quickly estimating how similar
    two sets are by converting large sets into smaller, representative fingerprints
    (**hashes**) where the probability of hash collision is proportional to the similarity
    between the original sets, making it particularly useful for detecting near-duplicate
    content in large datasets.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**MinHash**是一种概率技术，通过将大型集合转换为较小的、代表性的指纹（**散列**），快速估计两个集合的相似度，其中散列冲突的概率与原始集合之间的相似度成比例，这使得它在检测大型数据集中的近似重复内容时特别有用。'
- en: '**MinHashLSH** is based on MinHash and **locality-sensitive hashing** (**LSH**),
    which groups similar items into the same “buckets” to enable fast lookup and comparison.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**MinHashLSH**基于MinHash和**局部敏感哈希**（**LSH**），它将相似项分组到相同的“桶”中，以实现快速查找和比较。'
- en: 'The following code example demonstrates data deduplication using MinHash and
    MinHashLSH for detecting near-duplicates in datasets:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例演示了使用MinHash和MinHashLSH进行数据去重，以检测数据集中的近似重复项：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Reduce computational cost**: Use stratified sampling or a single-split validation
    (e.g., train-validation-test) approach to minimize computational overhead. Alternatively,
    employ smaller model checkpoints or distilled versions of the LLM during experimentation
    before scaling up.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降低计算成本**：使用分层抽样或单一分割验证方法（例如，训练-验证-测试）以最小化计算开销。或者，在扩展之前，在实验中使用较小的模型检查点或LLM的蒸馏版本。'
- en: 'The following code example shows stratified sampling for efficient validation:'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码示例展示了用于高效验证的分层抽样：
- en: '[PRE16]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Handle domain shift**: Construct validation datasets with explicit representation
    from diverse domains. Fine-tune models with representative domain-specific data
    to reduce performance gaps in underrepresented areas.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理领域偏移**：构建具有来自不同领域显式表示的验证数据集。使用具有代表性的领域特定数据微调模型，以减少在代表性不足区域中的性能差距。'
- en: 'This code example demonstrates handling domain shift through domain-specific
    validation:'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此代码示例演示了通过领域特定验证处理领域偏移：
- en: '[PRE17]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**Address prompt sensitivity**: Perform prompt engineering systematically.
    Use techniques such as prompt paraphrasing, instruction tuning, or ensemble evaluation
    across multiple prompts to ensure robustness and minimize the variability introduced
    by prompt changes.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解决提示敏感性**：系统性地进行提示工程。使用提示释义、指令调整或跨多个提示的集成评估等技术，以确保鲁棒性并最小化提示变化引入的变异性。'
- en: 'The following code example shows systematic prompt engineering with multiple
    variants:'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码示例展示了使用多个变体的系统提示工程：
- en: '[PRE18]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following code example shows how to combine all these approaches into a
    single evaluation pipeline:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例展示了如何将这些方法组合成一个单一的评估流程：
- en: '[PRE19]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Summary
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Cross-validation for LLMs requires careful consideration of their unique characteristics
    and capabilities. By implementing these advanced techniques and best practices,
    you can obtain a more robust and comprehensive assessment of your LLM’s performance
    across various domains and tasks.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LLM的交叉验证需要仔细考虑它们的独特特性和能力。通过实施这些高级技术和最佳实践，您可以获得对LLM在各个领域和任务中性能的更稳健和全面的评估。
- en: As we move forward, the next chapter will delve into the crucial topic of interpretability
    in LLMs. We’ll explore techniques for understanding and explaining the outputs
    and behaviors of LLMs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续前进，下一章将深入探讨LLM中解释性的关键主题。我们将探讨理解和解释LLM输出和行为的技术。
