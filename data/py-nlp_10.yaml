- en: Advanced Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级工具
- en: This appendix focuses on how the various frameworks can be used in NLP applications.
    We will look at an overview of the frameworks and touch on the basic features
    and what they do for you. We are not going to see look at a detailed architecture
    of each framework. Here, the purpose is to get you aware of the different tools
    and frameworks that can be used together to build various NLP applications. We
    will also look at visualization libraries that can help you develop a dashboard.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录主要讨论各种框架如何在 NLP 应用程序中使用。我们将概述这些框架，并简要介绍它们的基本功能及其作用。我们不会详细查看每个框架的架构。此处的目的是让你了解可以一起使用的不同工具和框架，以便构建各种
    NLP 应用程序。我们还将了解一些可帮助你开发仪表盘的可视化库。
- en: Apache Hadoop as a storage framework
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Hadoop 作为一个存储框架
- en: Apache Hadoop is one of the widely used frameworks. Hadoop allows the distributed
    processing of large datasets across clusters of commodity computers using a simple
    programming model. Hadoop uses the concept of MapReduce. MapReduce divides the
    input query into small parts and processes them in parallel to the data stored
    on the **Hadoop distributed file system** (**HDFS**).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Hadoop 是一个广泛使用的框架。Hadoop 允许使用简单的编程模型在商品计算机集群上分布式处理大数据集。Hadoop 使用了 MapReduce
    的概念。MapReduce 将输入查询划分为小部分，并对存储在 **Hadoop 分布式文件系统** (**HDFS**) 上的数据进行并行处理。
- en: 'Hadoop has the following features:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 具有以下特点：
- en: It is scalable
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有可扩展性
- en: It is cost-effective
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有成本效益
- en: It provides a robust ecosystem
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了一个强大的生态系统
- en: It provides faster data processing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供更快的数据处理
- en: Hadoop can be used as a storage framework for NLP applications. If you want
    to store large amounts of data, then you can use a multinode Hadoop cluster and
    store data on HDFS. So, many NLP applications use HDFS for their historical data.
    Hadoop sends a program to the data and the data processes it locally. These features
    give Hadoop good speed. Note that Hadoop performs operations on the disk level,
    which is slow, but we execute operations in parallel so data processing is fast.
    Now, you may think that disk operations are slow compared to memory operations,
    but we have large amounts of data, which will not fit into memory at once. So,
    this approach of processing data locally and executing operations in parallel,
    using a multinode cluster, gives us a good throughput.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 可以作为 NLP 应用程序的存储框架。如果你想存储大量数据，那么可以使用一个多节点 Hadoop 集群，并将数据存储在 HDFS 上。因此，许多
    NLP 应用程序会使用 HDFS 来存储它们的历史数据。Hadoop 将程序发送到数据上，数据会在本地处理。这个特性使得 Hadoop 具有较高的速度。需要注意的是，Hadoop
    在磁盘级别执行操作，这比较慢，但我们通过并行执行操作，所以数据处理速度很快。现在，你可能会认为磁盘操作相比内存操作较慢，但我们有大量数据，这些数据一次是无法全部放入内存的。因此，采用在本地处理数据并通过多节点集群并行执行操作的方式，能给我们提供良好的吞吐量。
- en: 'Hadoop has the following components as part of its core architecture:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 作为其核心架构的一部分，具有以下组件：
- en: HDFS
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDFS
- en: MapReduce
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MapReduce
- en: YARN
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YARN
- en: Hadoop common utilities
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 常用工具
- en: 'You can see the architecture of Hadoop in *Figure 01*:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 *图 01* 中看到 Hadoop 的架构：
- en: '![](img/3a83ddd1-6c61-4781-9061-b9f04f5667cf.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a83ddd1-6c61-4781-9061-b9f04f5667cf.png)'
- en: 'Figure 01: Hadoop 2.x yarn architecture(Image credit: https://github.com/zubayr/big_config/blob/master/hbase/hbase_tuning.md)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 01：Hadoop 2.x YARN 架构（图片来源：[https://github.com/zubayr/big_config/blob/master/hbase/hbase_tuning.md](https://github.com/zubayr/big_config/blob/master/hbase/hbase_tuning.md)）
- en: 'You can see the Hadoop ecosystem in *Figure 02*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 *图 02* 中看到 Hadoop 生态系统：
- en: '![](img/a9cef694-fe42-41d9-91e1-e65a1d3bf4bf.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9cef694-fe42-41d9-91e1-e65a1d3bf4bf.png)'
- en: 'Figure 02: The Hadoop ecosystem (Image credit: https://s3.amazonaws.com/files.dezyre.com/images/blog/Big+Data+and+Hadoop+Training+Hadoop+Components+and+Architecture_1.png)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 02：Hadoop 生态系统（图片来源：[https://s3.amazonaws.com/files.dezyre.com/images/blog/Big+Data+and+Hadoop+Training+Hadoop+Components+and+Architecture_1.png](https://s3.amazonaws.com/files.dezyre.com/images/blog/Big+Data+and+Hadoop+Training+Hadoop+Components+and+Architecture_1.png)）
- en: For real-time data processing, Hadoop is a bit slow and not very efficient.
    Don't worry! We have another framework that helps us with real-time data processing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实时数据处理，Hadoop 稍显缓慢且效率较低。别担心！我们还有另一个框架可以帮助我们进行实时数据处理。
- en: Many NLP applications use Hadoop for data storage because it can handle data
    processing very well. On a personal level, I used Hadoop to store my corpus on
    HDFS. Then, I have used Spark MLlib to develop **machine learning** (**ML**) algorithms.
    For real-time data processing, I use Apache Flink.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 NLP 应用程序使用 Hadoop 来存储数据，因为它能很好地处理数据。就个人而言，我曾使用 Hadoop 将我的语料库存储在 HDFS 上。然后，我使用
    Spark MLlib 来开发 **机器学习** (**ML**) 算法。对于实时数据处理，我使用了 Apache Flink。
- en: 'For experimenting purposes, I have provided you with the steps of setting up
    a single-node Hadoop cluster. The GitHub link for this is: [https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_3_Hadoop_installation.md](https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_3_Hadoop_installation.md).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实验目的，我为你提供了设置单节点Hadoop集群的步骤。相关的GitHub链接是：[https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_3_Hadoop_installation.md](https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_3_Hadoop_installation.md)。
- en: 'You can find some of the commands of Hadoop in this document:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此文档中找到一些Hadoop的命令：
- en: '[https://dzone.com/articles/top-10-hadoop-shell-commands](https://dzone.com/articles/top-10-hadoop-shell-commands).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://dzone.com/articles/top-10-hadoop-shell-commands](https://dzone.com/articles/top-10-hadoop-shell-commands)。'
- en: '[https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html)'
- en: Apache Spark as a processing framework
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark作为处理框架
- en: Apache Spark is a large-scale data processing framework. It is a fast and general-purpose
    engine. It is one of the fastest processing frameworks. Spark can perform in-memory
    data processing, as well as on-disk data processing.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark是一个大规模数据处理框架。它是一个快速且通用的引擎。它是最快的处理框架之一。Spark可以进行内存数据处理，也可以进行磁盘数据处理。
- en: 'Spark''s important features are as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的重要功能如下：
- en: '**Speed**: Apache Spark can run programs up to 100 times faster than Hadoop
    MapReduce in-memory or 10 times faster on-disk'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：Apache Spark可以比Hadoop MapReduce在内存中运行快100倍，或者在磁盘上运行快10倍。'
- en: '**Ease of use**: There are various APIs available for Scala, Java, Spark, and
    R to develop your application'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易用性**：提供了多种API，适用于Scala、Java、Spark和R，用于开发应用程序。'
- en: '**Generality**: Spark provides features of Combine SQL, streaming, and complex
    analytics'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用性**：Spark提供了结合SQL、流式处理和复杂分析的功能。'
- en: '**Run everywhere**: Spark can run on Hadoop, Mesos, standalone, or in the cloud.
    You can access diverse data sources by including HDFS, Cassandra, HBase, and S3'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随处运行**：Spark可以在Hadoop、Mesos、独立模式或云端运行。你可以通过包括HDFS、Cassandra、HBase和S3来访问多种数据源。'
- en: 'I have used Spark to train my models using MLlib. I have used Spark Java as
    well as PySpark API. The result is you can redirect to the HDFS. I have saved
    my trained models on HDFS and then loaded them as and when needed. Spark really
    speeds up your processing time. I have experienced this. The reason behind this
    is its in-memory processing architecture. Spark architecture is given in *Figure
    03*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用Spark通过MLlib训练我的模型。我使用了Spark Java和PySpark API。结果是，你可以将数据重定向到HDFS。我将训练好的模型保存到HDFS，并根据需要加载它们。Spark确实加速了你的处理时间。我亲身体验过这一点。其背后的原因是其内存中处理架构。Spark的架构如*图03*所示：
- en: '![](img/22b44ae1-d342-45a5-8aed-40263890ab27.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22b44ae1-d342-45a5-8aed-40263890ab27.png)'
- en: 'Figure 03: Spark running architecture (Image credit: https://www.slideshare.net/datamantra/spark-architecture)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图03：Spark运行架构（图片来源：https://www.slideshare.net/datamantra/spark-architecture）
- en: 'You can see the Spark ecosystem in *Figure 04*:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在*图04*中看到Spark生态系统：
- en: '![](img/0efc3011-5cf0-4850-b821-cc786b50c45b.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0efc3011-5cf0-4850-b821-cc786b50c45b.png)'
- en: 'Figure 04: Spark ecosystem (Image credit: http://jorditorres.org/spark-ecosystem/)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图04：Spark生态系统（图片来源：http://jorditorres.org/spark-ecosystem/)
- en: 'You can see the installation steps on this GitHub link:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个GitHub链接查看安装步骤：
- en: '[https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_4_Spark_installation.md](https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_4_Spark_installation.md)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_4_Spark_installation.md](https://github.com/jalajthanaki/NLPython/blob/master/Appendix3/Installationdocs/App3_4_Spark_installation.md)'
- en: 'You can find more information on the following links:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下链接获取更多信息：
- en: '[https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/)'
- en: '[https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/detail](https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/detail](https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details)'
- en: '[http://spark.apache.org/](http://spark.apache.org/)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/](http://spark.apache.org/)'
- en: '[http://spark.apache.org/docs/latest/ml-guide.html](http://spark.apache.org/docs/latest/ml-guide.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/docs/latest/ml-guide.html](http://spark.apache.org/docs/latest/ml-guide.html)'
- en: '[http://spark.apache.org/docs/latest/mllib-guide.html](http://spark.apache.org/docs/latest/mllib-guide.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/docs/latest/mllib-guide.html](http://spark.apache.org/docs/latest/mllib-guide.html)'
- en: Apache Flink as a real-time processing framework
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Flink作为实时处理框架
- en: Apache Flink is used for real-time streaming and batch processing. I have told
    you we should not worry about real-time frameworks. The reason is we have the
    Flink framework for this.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Flink用于实时流处理和批处理。我之前提到过我们不需要担心实时框架，因为我们有Flink框架来处理这个问题。
- en: Flink is an open source stream processing framework for distributed, high-performing,
    always available, and accurate data streaming applications. You can see more about
    Flink at [https://flink.apache.org/](https://flink.apache.org/).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Flink是一个开源流处理框架，适用于分布式、高性能、始终可用且精准的数据流应用。你可以在[https://flink.apache.org/](https://flink.apache.org/)查看更多关于Flink的信息。
- en: 'Flink will definitely provide a very nice future. You can see in *Figure 05*:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Flink必定会提供一个非常美好的未来。你可以在*图05*中看到：
- en: '![](img/8b221644-574a-411c-b8d6-7cf90df17616.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b221644-574a-411c-b8d6-7cf90df17616.png)'
- en: 'Figure 05: Features of Flink (Image credit: https://flink.apache.org/)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图05：Flink的特性（图片来源：https://flink.apache.org/）
- en: 'Flink is quite a new framework. If you want to perform real-time sentiment
    analysis or make a real recommendation engine, then Flink is very useful. You
    can refer to the following video where you can understand how the HDFS, Flink,
    Kappa, and lamda architecture has been used. It''s a must-see video:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Flink是一个相对较新的框架。如果你想执行实时情感分析或制作一个推荐引擎，那么Flink非常有用。你可以参考以下视频，了解HDFS、Flink、Kappa和Lambda架构是如何被使用的。这是一个必看的视频：
- en: '[https://www.youtube.com/watch?v=mYGF4BUwtaw](https://www.youtube.com/watch?v=mYGF4BUwtaw)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=mYGF4BUwtaw](https://www.youtube.com/watch?v=mYGF4BUwtaw)'
- en: This video helps you understand how various frameworks fuse together to develop
    a good real-time application.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这段视频帮助你理解各种框架如何融合在一起开发一个好的实时应用程序。
- en: Visualization libraries in Python
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的可视化库
- en: Visualization is one of the important activities that is used to track certain
    processes and the results of your application. We used `matplotlib` in Chapter
    6, *Advance Feature Engineering and NLP Algorithms*, as well as in other chapters.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化是跟踪某些过程和应用程序结果的重要活动之一。在第六章《高级特征工程与NLP算法》中，我们使用了`matplotlib`，其他章节也有使用。
- en: 'Apart from `matplotlib`, we can use various visualization libraries:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`matplotlib`，我们还可以使用各种可视化库：
- en: '`matplotlib`: It is simple to use and very useful'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`：简单易用且非常实用'
- en: '`bokeh`: It provides customized themes and charts'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bokeh`：提供自定义主题和图表'
- en: '`pygal`: You can make cool graphs and charts with this'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pygal`：你可以用它制作酷炫的图表和图形'
- en: You can use the following links to refer to each of the libraries. All libraries
    have written documentation so you can check them and start making your own charts.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下链接参考每个库。所有库都有详细的文档，你可以查阅并开始制作自己的图表。
- en: You can find more on `matplotlib` at [https://matplotlib.org/](https://matplotlib.org/).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://matplotlib.org/](https://matplotlib.org/)找到更多关于`matplotlib`的信息。
- en: You can find more on `Bokeh` at [http://bokeh.pydata.org/en/latest/docs/gallery.html](http://bokeh.pydata.org/en/latest/docs/gallery.html).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://bokeh.pydata.org/en/latest/docs/gallery.html](http://bokeh.pydata.org/en/latest/docs/gallery.html)找到更多关于`Bokeh`的信息。
- en: You can find documentation about `pygal` at [http://pygal.org/en/stable/documentation/index.html](http://pygal.org/en/stable/documentation/index.html).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://pygal.org/en/stable/documentation/index.html](http://pygal.org/en/stable/documentation/index.html)上找到关于`pygal`的文档。
- en: Summary
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: If you want detailed information regarding these frameworks and libraries, then
    you can use the Gitter room to connect with me, because in-depth details of the
    frameworks are out of the scope of this book.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解关于这些框架和库的详细信息，可以使用Gitter聊天室与我联系，因为框架的深入细节超出了本书的范围。
- en: This framework overview will help you figure out how various frameworks can
    be used in NLP applications. Hadoop is used for storage. Spark MLlib is used to
    develop machine learning models and store the trained models on HDFS. We can run
    the trained model as and when needed by loading it. Flink makes our lives easier
    when real-time analysis and data processing come into the picture. Real-time sentiment
    analysis, document classification, user recommendation engine, and so on are some
    of the real-time applications that you can build using Flink. The `matplotlib`
    is used while developing machine learning models. The `pygal` and `bokeh` are
    used to make nice dashboards for our end users.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个框架概述将帮助您了解各种框架在自然语言处理（NLP）应用中的应用方式。Hadoop 用于存储。Spark MLlib 用于开发机器学习模型，并将训练好的模型存储在
    HDFS 上。我们可以通过加载模型，根据需要运行训练好的模型。Flink 在实时分析和数据处理方面为我们带来了便利。实时情感分析、文档分类、用户推荐引擎等是您可以使用
    Flink 构建的一些实时应用。`matplotlib` 用于开发机器学习模型。`pygal` 和 `bokeh` 用于为我们的最终用户制作漂亮的仪表盘。
