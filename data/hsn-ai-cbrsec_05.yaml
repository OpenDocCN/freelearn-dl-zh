- en: Ham or Spam? Detecting Email Cybersecurity Threats with AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾邮件还是正常邮件？使用人工智能检测电子邮件中的网络安全威胁
- en: Most security threats use email as an attack vector. Since the amount of traffic
    conveyed in this way is particularly large, it is necessary to use automated detection
    procedures that exploit **machine learning** (**ML**) algorithms. In this chapter,
    different detection strategies ranging from linear classifiers and Bayesian filters
    to more sophisticated solutions such as decision trees, logistic regression, and **natural
    language processing** (**NLP**) will be illustrated.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数安全威胁使用电子邮件作为攻击向量。由于通过这种方式传输的流量特别大，因此需要使用自动化检测程序，这些程序利用**机器学习**（**ML**）算法。在本章中，将介绍不同的检测策略，从线性分类器和贝叶斯滤波器到更复杂的解决方案，如决策树、逻辑回归和**自然语言处理**（**NLP**）。
- en: 'This chapter will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: How to detect spam with Perceptrons
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用感知器检测垃圾邮件
- en: Image spam detection with **support vector machines** (**SVMs**)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**支持向量机**（**SVMs**）进行图像垃圾邮件检测
- en: Phishing detection with logistic regression and decision trees
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用逻辑回归和决策树进行钓鱼检测
- en: Spam detection with Naive Bayes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯的垃圾邮件检测
- en: Spam detection adopting NLP
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于NLP的垃圾邮件检测
- en: Detecting spam with Perceptrons
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用感知器检测垃圾邮件
- en: One of the first concrete and successful applications of AI in the field of
    cybersecurity was spam detection, and one of the most famous open source tools
    is **SpamAssassin**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在网络安全领域的第一个具体成功应用之一就是垃圾邮件检测，而最著名的开源工具之一就是**SpamAssassin**。
- en: The strategies that can be implemented for effective spam detection are different,
    as we will see in the course of the chapter, but the most common and simpler one
    uses **Neural Networks** (**NNs**) in the most basic form; that is, the Perceptron.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 可以实施的有效垃圾邮件检测策略是不同的，正如我们将在本章中看到的那样，但最常见且简单的策略是使用**神经网络**（**NNs**）的最基本形式；也就是感知器（Perceptron）。
- en: Spam detection also provides us with the opportunity to introduce theoretical
    concepts related to NNs in a gradual and accessible way, starting with the Perceptron.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件检测还为我们提供了逐步引入与神经网络相关的理论概念的机会，从感知器开始，以一种易于理解的方式进行介绍。
- en: Meet NNs at their purest – the Perceptron
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解神经网络最纯粹的形态——感知器
- en: The peculiar characteristic that unites all NNs (regardless of their implementation
    complexity) is that they conceptually mimic the behavior of the human brain. The
    most basic structure we encounter when we analyze the behavior of the brain, is
    undoubtedly the neuron.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所有神经网络的共同特征（无论其实现复杂性如何）是，它们在概念上模仿人脑的行为。当我们分析大脑的行为时，最基本的结构无疑是神经元。
- en: 'The Perceptron is one of the first successful implementations of a neuron in
    the field of **Artificial Intelligence** (**AI**). Just like a neuron in the human
    brain, it is characterized by a layered structure, aimed at associating a result
    in output to certain input levels, as shown in the following diagram:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是**人工智能**（**AI**）领域中最早成功实现神经元的案例之一。就像人类大脑中的神经元一样，它具有分层结构，旨在将特定输入级别的结果与输出关联，如下图所示：
- en: '![](img/8ed6924f-b57b-4920-916d-6bf7aca65538.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ed6924f-b57b-4920-916d-6bf7aca65538.png)'
- en: 'In the same way, the artificial representation of the neuron implemented through
    the Perceptron model is structured in such a way as to associate a given output
    value to one or more levels of input data:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，通过感知器模型实现的人工神经元表示是以一种结构化的方式，旨在将给定的输出值与一个或多个输入数据级别关联起来：
- en: '![](img/ce0d6325-06b4-42af-bf86-736180df18a3.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce0d6325-06b4-42af-bf86-736180df18a3.png)'
- en: The mechanism that transforms the input data into an output value is implemented
    by making use of an appropriate weighing of the values of an input, which are
    synthesized and forwarded to an activation function, which, when exceeding a certain
    threshold, produces a value of output that is forwarded to the remaining components
    of the NN.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入数据转化为输出值的机制是通过对输入值进行适当加权实现的，这些值经过综合后传递给激活函数，当超过某个阈值时，生成的输出值将传递给神经网络的其余部分。
- en: It's all about finding the right weight!
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键在于找到合适的权重！
- en: One of the differences in the approach between the statistical models and the
    AI algorithms is that the algorithms implement an optimization strategy based
    on the iteration. At each iteration, in fact, the algorithm tries to adjust its
    own estimate of the values, attributing to them a greater or lesser weight depending
    on the cost function that we must minimize. One of the aims of the algorithm is
    to identify precisely an optimal weight vector to be applied to the estimated
    values in order to obtain reliable future predictions on unknown future data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 统计模型与人工智能算法方法之间的一个区别在于，算法实现了一种基于迭代的优化策略。事实上，在每次迭代中，算法会尝试调整自己对值的估计，依据我们需要最小化的成本函数，为其分配更大或更小的权重。算法的目标之一是精确地识别一个最佳的权重向量，以便将其应用于估算值，从而对未知的未来数据做出可靠的预测。
- en: To fully understand the power of AI algorithms applied to spam detection, we
    must first clarify the ideas on which tasks we should perform a spam filter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分理解应用于垃圾邮件检测的人工智能算法的强大功能，我们必须首先明确我们应该执行垃圾邮件过滤器的任务。
- en: Spam filters in a nutshell
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简言之，垃圾邮件过滤器。
- en: To understand the tasks performed by a spam filter, let's look at an example.
    Imagine separating the emails we receive, categorizing them based on the presence
    or the absence of particular keywords occurring within the text of the emails
    with a certain frequency. To this end, we could list all the messages we receive
    in our inbox within a table. But how will we proceed with classifying our messages
    as ham or spam?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解垃圾邮件过滤器执行的任务，我们来看一个例子。假设将我们收到的电子邮件进行分类，根据电子邮件文本中出现某些特定关键词的频率，判断这些关键词是否存在。为此，我们可以将收到的所有邮件列入表格。但是，我们将如何进行邮件的分类，将其标记为“正常邮件”还是“垃圾邮件”呢？
- en: As we said, we will look for the number of occurrences of the suspicious keywords
    within the text of the email messages. We will then assign a score to the individual
    messages identified as spam, based on the number of occurrences of identified
    keywords. This score will also provide us with a reference to classify subsequent
    email messages.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说的，我们将查找电子邮件文本中可疑关键词的出现次数。然后，我们将根据识别的关键词的出现次数，为单个被识别为垃圾邮件的消息分配分数。这个分数也将为我们提供一个参考，用于分类后续的电子邮件。
- en: We will identify a threshold value that allows us to separate spam messages.
    If the calculated score exceeds the threshold value, the email will automatically
    be classified as spam; otherwise, it will be accepted as a legitimate message,
    and thus classified as ham. This threshold value (as well as the assigned scores)
    will be constantly redetermined to take into account the new series of spam messages
    that we will meet in the future.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将识别一个阈值，该值允许我们分离垃圾邮件。如果计算出的分数超过阈值，邮件将自动被分类为垃圾邮件；否则，它将被接受为合法邮件，并因此被分类为正常邮件。这个阈值（以及分配的分数）将不断重新确定，以考虑我们将来遇到的新一系列垃圾邮件。
- en: 'Even from the abstract description of our spam detection algorithm, we notice
    some important features that must be kept in mind: we must proceed to identify
    a certain number of suspicious keywords that allow us to classify the messages
    as potential spam emails, assigning to each email a score based on the number
    of occurrences of identified keywords.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 即使从我们对垃圾邮件检测算法的抽象描述中，我们也注意到一些必须牢记的重要特征：我们必须识别一定数量的可疑关键词，以便将邮件分类为潜在的垃圾邮件，并为每封邮件根据识别出的关键词出现次数分配一个分数。
- en: We need to set a threshold value for the score assigned to the individual emails
    above which the emails will automatically be classified as spam. We must also
    correctly weigh the significance of the keywords present in the text of the emails
    in order to adequately represent the degree of probability that the message that
    contains them represents spam (the keywords, in fact, taken individually, could
    even be harmless, but put together, they are more likely to represent junk mail).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为分配给各个电子邮件的分数设置一个阈值，超过该阈值的邮件将自动被分类为垃圾邮件。我们还必须正确地权衡电子邮件文本中关键词的意义，以便充分表示包含这些关键词的消息代表垃圾邮件的概率（实际上，单独来看，关键词可能是无害的，但将它们组合在一起时，它们更有可能代表垃圾邮件）。
- en: We must consider that the spammers are well aware of our attempt to filter unwanted
    messages, and therefore they'll try their best to adopt new strategies to deceive
    us and our spam filters. This translates into a process of continuous and iterative
    learning, which lends itself well to being implemented using an AI algorithm.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须考虑到垃圾邮件发送者充分意识到我们正在尝试过滤不需要的邮件，因此他们会尽最大努力采用新的策略来欺骗我们和我们的垃圾邮件过滤器。这就导致了一个持续和迭代的学习过程，这个过程非常适合用人工智能算法来实现。
- en: From what we have said, it is clear that it is no coincidence that spam detection
    represents a first test in the adoption of AI in the cybersecurity field. The
    first spam detection solution, in fact, made use of static rules, using regular
    expressions to identify predefined patterns of suspicious words in the email text.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们所说的内容来看，很明显垃圾邮件检测成为人工智能在网络安全领域应用的首次测试并非偶然。事实上，第一代垃圾邮件检测解决方案使用了静态规则，通过正则表达式识别电子邮件文本中预定义的可疑词语模式。
- en: These static rules quickly proved to be ineffective as a result of the ever-new
    deception strategies implemented by spammers to deceive the anti-spam filters.
    It was therefore necessary to adopt a dynamic approach, which allowed the spam
    filter to learn based on the continuous innovations introduced by spammers, also
    taking advantage of the decisions made by the user in classifying their emails.
    This way, it was possible to effectively manage the explosive spread of the spam
    phenomenon.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些静态规则很快证明是无效的，因为垃圾邮件发送者不断采用新的欺骗策略来欺骗反垃圾邮件过滤器。因此，必须采用一种动态方法，使得垃圾邮件过滤器能够根据垃圾邮件发送者不断创新的方式进行学习，同时还可以借助用户在分类电子邮件时做出的决策。通过这种方式，能够有效地管理垃圾邮件现象的爆炸性传播。
- en: Spam filters in action
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾邮件过滤器的作用
- en: 'How does an anti-spam algorithm actually behave in the classification of emails?
    First of all, let''s classify the emails based on suspicious keywords. Let''s
    imagine, for the sake of simplicity, that the list of the most representative
    suspicious keywords is thus reduced to only two words: buy and sex.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 反垃圾邮件算法在电子邮件分类时的实际表现如何呢？首先，我们根据可疑关键词来对电子邮件进行分类。为了简化问题，我们假设最具代表性的可疑关键词列表只包含两个词：buy（购买）和sex（性）。
- en: 'At this point, we will classify the email messages within a table, showing
    the number of occurrences of the individual keywords identified within the text
    of the emails, indicating the messages as spam or ham:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将把电子邮件消息分类在一个表格中，显示在电子邮件文本中识别出的各个关键词的出现次数，并标明这些消息是垃圾邮件还是正常邮件：
- en: '![](img/1d2b3161-314c-406a-9866-ed9e0b87d485.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d2b3161-314c-406a-9866-ed9e0b87d485.png)'
- en: At this point, we will assign a score to every single email message.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将给每一封电子邮件消息分配一个分数。
- en: This score will be calculated using a scoring function that takes into account
    the number of occurrences of suspicious keywords contained within the text.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分数将通过一个评分函数来计算，该函数考虑了文本中可疑关键词的出现次数。
- en: A possible scoring function could be the sum of the occurrences of our two keywords,
    represented in this case by the *B* variable instead of the word buy, and the
    *S* variable instead of the word sex.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的评分函数可以是我们两个关键词出现次数的总和，在这种情况下，使用 *B* 变量表示“buy”一词，使用 *S* 变量表示“sex”一词。
- en: 'The scoring function therefore becomes the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，评分函数变成了如下形式：
- en: <q>![](img/7fe320e9-9583-4ddf-b21b-50309382d3ff.png)</q>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <q>![](img/7fe320e9-9583-4ddf-b21b-50309382d3ff.png)</q>
- en: We can also attribute different weights to the representative variables of the
    respective keywords, based on the fact that, for example, the keyword sex contained
    within the message is indicative of a greater probability of spam than the word
    buy.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以根据不同的关键词，为各自的代表性变量赋予不同的权重。例如，消息中包含关键词“sex”比包含“buy”更可能被判定为垃圾邮件，因此可以赋予“sex”更高的权重。
- en: It is clear that if both words are present in the text of the email, the probability
    of it being spam increases. Therefore, we will attribute a lower weight of *2* to
    the *B* variable and a greater weight of *3* to the *S* variable.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，如果文本中同时出现这两个词，那么它被判定为垃圾邮件的概率就会增加。因此，我们会为 *B* 变量赋予较低的权重 *2*，为 *S* 变量赋予较高的权重
    *3*。
- en: 'Our scoring function, corrected with the relative weights assigned to the variables/keywords,
    therefore becomes the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评分函数，经过相应权重调整后，变成了以下公式：
- en: '![](img/f1080b19-8eb9-4a55-8151-2e18a348d0c4.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1080b19-8eb9-4a55-8151-2e18a348d0c4.png)'
- en: 'Now let''s try to reclassify our emails, calculating the relative scores with
    our scoring function:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试重新分类我们的邮件，计算每封邮件的相对得分，使用我们的评分函数：
- en: '![](img/7a298cdb-ef25-4c2f-97f8-f51ebf195e7b.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a298cdb-ef25-4c2f-97f8-f51ebf195e7b.png)'
- en: At this point, we must try to identify a threshold value that effectively separates
    spam from ham. Indeed, a threshold value between **4** and **5** allows us to
    properly separate the spam from the ham. In other words, in the event that a new
    email message scores a value equal to or greater than **4**, we would most likely
    be faced with spam rather than ham.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们必须尝试确定一个阈值，有效地区分垃圾邮件和正常邮件。实际上，**4** 和 **5** 之间的阈值可以帮助我们正确地区分垃圾邮件和正常邮件。换句话说，如果一封新邮件的得分大于或等于
    **4**，我们很可能面临的是垃圾邮件，而非正常邮件。
- en: How can we effectively translate the concepts we have just seen into mathematical
    formulas that can be used in our algorithms?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将刚刚看到的概念有效地转化为可用于算法的数学公式呢？
- en: To this end, linear algebra (as we mentioned in [Chapter 2](fbb9686a-7359-4659-bcdf-d0bf5e4e6af8.xhtml), *Setting
    Your AI for Cybersecurity Arsenal*, when we talked about the matrix implementation
    offered by the `numpy` library) comes to our aid.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，线性代数（正如我们在 [第2章](fbb9686a-7359-4659-bcdf-d0bf5e4e6af8.xhtml) *为网络安全武器设置你的
    AI* 中提到的，当时我们讨论了 `numpy` 库提供的矩阵实现）为我们提供了帮助。
- en: We will discuss further the implementation of Perceptrons, but first, we will
    introduce the concept of a linear classifier, useful for mathematically representing
    the task performed by a common spam detection algorithm.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进一步讨论感知机的实现，但首先，我们将介绍线性分类器的概念，它对于数学表示常见的垃圾邮件检测算法任务非常有用。
- en: Detecting spam with linear classifiers
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性分类器检测垃圾邮件
- en: 'As known from linear algebra, the equation that represents the function used
    to determine the score to be associated with every single email message is as
    follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如线性代数中所知，用于确定每封邮件得分的函数方程如下：
- en: '![](img/ebf6f6ad-2011-4d6c-b4b0-be0c9587e690.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebf6f6ad-2011-4d6c-b4b0-be0c9587e690.png)'
- en: 'This identifies a straight line in the Cartesian plane; therefore, the classifier
    used by our spam filter to classify emails is called a **linear classifier**.
    Using the known mathematical formalization commonly adopted in statistics, it
    is possible to redefine the previous equation in a more compact form by introducing
    the sum operator ![](img/e17c9d51-ab4d-4c35-a5ac-dc51b490b4fc.png), substituting
    in place of the *B* and *S* variables a matrix of indexed values ![](img/18e041cb-9379-4929-995d-7ad8488cbe71.png),
    and a vector of weights ![](img/cabcde63-c1a9-4098-bfca-ce82f3b97179.png) associated
    with it:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这标识了笛卡尔平面中的一条直线；因此，我们的垃圾邮件过滤器用于分类邮件的分类器称为 **线性分类器**。通过采用统计学中常见的数学形式化，可以通过引入求和运算符
    ![](img/e17c9d51-ab4d-4c35-a5ac-dc51b490b4fc.png)，用一个索引值矩阵 ![](img/18e041cb-9379-4929-995d-7ad8488cbe71.png)
    和一个与之关联的权重向量 ![](img/cabcde63-c1a9-4098-bfca-ce82f3b97179.png) 来替代 *B* 和 *S* 变量，从而以更紧凑的形式重新定义先前的方程：
- en: '![](img/e2c5ccfa-dd01-462f-86b1-74ba10310214.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2c5ccfa-dd01-462f-86b1-74ba10310214.png)'
- en: 'With the index *i,* which takes the values from *1* to *n, *this formalization
    is nothing more than the compact form of the previous summation between the variables
    and our relative weights:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用索引 *i*，其取值范围从 *1* 到 *n*，这种形式化只是前述变量与相对权重之间求和的紧凑表示：
- en: '![](img/014da7e8-db01-451b-bf0f-d46ed7176999.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/014da7e8-db01-451b-bf0f-d46ed7176999.png)'
- en: This way, we have generalized our linear classifier to an unspecified number
    of variables, *n*, rather than limiting ourselves to *2* as in the previous case.
    This compact representation is also useful for exploiting linear algebra formulas
    in the implementation of our algorithms.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们将线性分类器推广到了一个不确定的变量个数 *n*，而不是像前一个例子中那样限制为 *2*。这种紧凑的表示法对于在线性代数公式中利用算法实现也非常有用。
- en: 'In fact, our function translates into a sum of products (between individual
    weights and variables) that can easily be represented as a product of matrices
    and vectors:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们的函数转化为一系列乘积的和（每个权重和变量的乘积），这可以很容易地表示为矩阵与向量的乘积：
- en: '![](img/8f0458cf-0f6c-4264-8ad9-20a99cf8e4c6.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f0458cf-0f6c-4264-8ad9-20a99cf8e4c6.png)'
- en: Here, *wT* stands for the transposed weights carrier, necessary calculating
    the product of the matrices and vectors.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*wT* 表示转置的权重载体，计算矩阵与向量乘积时是必需的。
- en: 'As we have seen, to adequately classify email messages, we need to identify
    an appropriate threshold value that correctly splits spam messages from ham messages:
    if the score associated with a single email message is equal to or higher than
    the threshold value, the message email will be classified as spam (and we will
    assign it the value `+1`); otherwise, it will be classified as ham (to which we
    will assign the value `-1`).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，为了正确地分类电子邮件，我们需要识别一个合适的阈值，以正确地将垃圾邮件与正常邮件区分开：如果某封电子邮件的得分等于或高于阈值，则该邮件将被分类为垃圾邮件（并赋予值
    `+1`）；否则，它将被分类为正常邮件（我们将赋值 `-1`）。
- en: 'In formal terms, we represent this condition as follows (where *θ* represents
    the threshold value):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从正式的角度来看，我们将此条件表示为如下（其中 *θ* 代表阈值）：
- en: '![](img/443b7012-87c0-4c7e-abec-3367a3abb7be.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/443b7012-87c0-4c7e-abec-3367a3abb7be.png)'
- en: 'The preceding conditions are nothing but the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 前述条件不过是以下形式：
- en: '![](img/1a3e4c31-ab06-452a-8774-8f2f7845186b.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a3e4c31-ab06-452a-8774-8f2f7845186b.png)'
- en: 'It is a consolidated habit to further generalize this formalization by shifting
    the *θ* threshold value on the left side of the equation, associating it with
    the *x[0]* variable (thus introducing the *i = 0* positional index of the summation)
    to which we attribute the conventional value of 1, and a weight *w[0]* equal to
    *-θ* (that is, the threshold value taken with the negative sign, following the
    displacement of *θ* on the left side of the equation). Therefore, with *θ* we
    replace the product:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 将 *θ* 阈值移到方程的左侧，并将其与 *x[0]* 变量关联（从而引入求和的 *i = 0* 位置索引），并为 *x[0]* 分配常规值 1，同时将权重
    *w[0]* 设为 *-θ*（即阈值的负值，跟随 *θ* 向方程左侧的位移）。因此，用 *θ* 替代乘积：
- en: '![](img/091ecebf-33c3-4e1a-b7fc-56971aec261b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/091ecebf-33c3-4e1a-b7fc-56971aec261b.png)'
- en: 'This way, our compact formulation of the linear classifier takes its definitive
    form:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们对线性分类器的简洁公式就变成了最终的形式：
- en: '![](img/ed16fec0-b6bc-4fa0-b2f3-fa888f826544.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed16fec0-b6bc-4fa0-b2f3-fa888f826544.png)'
- en: Here, the index ![](img/85b1f65e-49c9-4197-96c2-1e0fba296044.png) now assumes
    the values from *0* to *n*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，索引 ![](img/85b1f65e-49c9-4197-96c2-1e0fba296044.png) 现在取值从 *0* 到 *n*。
- en: How the Perceptron learns
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感知机是如何学习的
- en: The approach followed by Rosenblatt Perceptron model, which we have described
    so far in this chapter, is based on a simplified description of the neuron of
    the human brain. Just as the brain's neurons activate in the case of a positive
    signal, and remain inert otherwise, the Perceptron uses the threshold value via
    an activation function, which assigns a `+1` value (in case of excitement of the
    Perceptron, which indicates the pre-established threshold value has been exceeded),
    or a `-1` value (in other words, indicating a failure to exceed the threshold
    value).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中迄今为止描述的Rosenblatt感知机模型所采用的方法，基于对人脑神经元的简化描述。正如大脑的神经元在接收到正信号时会激活，否则保持静止一样，感知机通过激活函数使用阈值，该函数会分配一个
    `+1` 值（在感知机激活的情况下，表示预设的阈值已被超过），或 `-1` 值（换句话说，表示未能超过阈值）。
- en: 'Taking up the previous mathematical expression that determines the conditions
    of activation of the Perceptron:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 重新审视前面确定感知机激活条件的数学表达式：
- en: '![](img/8db10016-290d-4dd5-8186-11841ebeac4f.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8db10016-290d-4dd5-8186-11841ebeac4f.png)'
- en: We see that it is the product of the ![](img/ab8d4619-eaa0-4f07-aaa6-634ba22ef1e2.png) values
    (that is, the input data for the corresponding weights) that has to overcome the
    *θ* threshold to determine the activation of the Perceptron. Since the *x[i]*
    input data is by definition prefixed, it is the value of the corresponding weights
    that helps to determine if the Perceptron has to activate itself or not.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，它是 ![](img/ab8d4619-eaa0-4f07-aaa6-634ba22ef1e2.png) 值的乘积（即对应权重的输入数据），必须超过
    *θ* 阈值才能确定感知机是否激活。由于 *x[i]* 输入数据按定义是预先设定的，正是对应权重的值帮助判断感知机是否需要激活。
- en: But how are weights updated in practice, thus determining the Perceptron learning
    process?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 但在实际操作中，权重是如何更新的，从而确定感知机的学习过程呢？
- en: 'The Perceptron learning process can be synthesized in the following three phases:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机的学习过程可以总结为以下三个阶段：
- en: Initializing the weights to a predefined value (usually equal to *0*)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将权重初始化为预定义值（通常为 *0*）
- en: Calculating the output value, ![](img/6bf7d5f2-776c-4897-87d9-093052675e4f.png), for
    each corresponding training sample, ![](img/d41005e9-d267-4216-bfb0-8794327e9c79.png)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算每个相应训练样本的输出值![](img/6bf7d5f2-776c-4897-87d9-093052675e4f.png)，![](img/d41005e9-d267-4216-bfb0-8794327e9c79.png)
- en: Updating the weights on the basis of the distance between the expected output
    value (that is, the ![](img/19a2dde2-3988-4d4e-8097-65ce1b3bad83.png) value associated
    with the original class label of the corresponding input data, ![](img/caa3cac9-acc6-44e0-9e39-83ce74d8ad8b.png))
    and the predicted value (the ![](img/f30fa8fa-3141-4c99-9118-a3fb1ef950a5.png)value estimated
    by the Perceptron)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于预期输出值（即与相应输入数据的原始类别标签相关联的![](img/19a2dde2-3988-4d4e-8097-65ce1b3bad83.png)值，![](img/caa3cac9-acc6-44e0-9e39-83ce74d8ad8b.png)）和预测值（感知器估算的![](img/f30fa8fa-3141-4c99-9118-a3fb1ef950a5.png)值）之间的距离来更新权重。
- en: 'In practice, the individual weights are updated according to the following
    formula:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，个别权重根据以下公式进行更新：
- en: '![](img/2ffa93f5-2b2a-48d6-a6ef-bc9dda3c258d.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ffa93f5-2b2a-48d6-a6ef-bc9dda3c258d.png)'
- en: 'Here, the ![](img/b5c79404-c080-4be4-ae11-a978b4912c51.png) value represents
    the deviation between the expected (***y***) value and the predicted value (![](img/70392b2e-fb5a-4bd5-b2fb-f404b267f785.png)):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/b5c79404-c080-4be4-ae11-a978b4912c51.png)值表示预期（***y***）值与预测值之间的偏差![](img/70392b2e-fb5a-4bd5-b2fb-f404b267f785.png)：
- en: '![](img/53423643-515b-4686-b32f-bb24a7e4bae1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53423643-515b-4686-b32f-bb24a7e4bae1.png)'
- en: As is evident from the preceding formula, the deviation between the expected
    ***y*** value and predicted ![](img/3a2ca1aa-1975-4a19-bbfe-ac56a659697f.png)
    value is multiplied by the value of input ![](img/d338e333-09e9-49cb-a2d2-824e58873414.png),
    and by the ![](img/15dc2b1d-f3df-4f4d-a0ac-cd4218c3e8c7.png) constant, which represents
    the learning rate assigned to the Perceptron. The ![](img/c2622b38-1fd9-402e-afc9-12e4c79d7e84.png)
    constant usually assumes a value between *0.0* and *1.0*, a value that is assigned
    at the Perceptron initialization phase.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的公式可以明显看出，预期的***y***值与预测值之间的偏差![](img/3a2ca1aa-1975-4a19-bbfe-ac56a659697f.png)会被输入值![](img/d338e333-09e9-49cb-a2d2-824e58873414.png)的值和![](img/15dc2b1d-f3df-4f4d-a0ac-cd4218c3e8c7.png)常数相乘，这个常数表示分配给感知器的学习率。![](img/c2622b38-1fd9-402e-afc9-12e4c79d7e84.png)常数通常取值在*0.0*到*1.0*之间，该值是在感知器初始化阶段指定的。
- en: As we will see, the value of the learning rate is crucial for the learning of
    the Perceptron, and it is therefore necessary to carefully evaluate (even by trial
    and error) the value to be attributed to the ![](img/64f04147-11a8-43bf-9f96-79cff0f45531.png)
    constant to optimize the results returned from the Perceptron.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，学习率的值对感知器的学习至关重要，因此有必要仔细评估（甚至通过反复试验）赋给![](img/64f04147-11a8-43bf-9f96-79cff0f45531.png)常数的值，以优化感知器返回的结果。
- en: A simple Perceptron-based spam filter
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个基于感知器的简单垃圾邮件过滤器
- en: We will now see a concrete example of the use of the Perceptron. We will use
    the `scikit-learn` library to create a simple spam filter based on the Perceptron.
    The dataset we will use to test our spam filter is based on the sms spam messages
    collection, available at [https://archive.ics.uci.edu/ml/datasets/sms+spam+collection](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到一个使用感知器的实际例子。我们将使用`scikit-learn`库创建一个基于感知器的简单垃圾邮件过滤器。我们将用来测试垃圾邮件过滤器的数据集来自于短信垃圾邮件消息集，数据集可在[https://archive.ics.uci.edu/ml/datasets/sms+spam+collection](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)找到。
- en: The original dataset can be downloaded in CSV format; we proceeded to process
    the data contained in the CSV file, transforming it into numerical values to make
    it manageable by the Perceptron. Moreover, we have selected only the messages
    containing the buy and sex keywords (according to our previous description), counting
    for each message (be it spam or ham) the number of occurrences of the keywords
    present in the text of the message.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集可以以CSV格式下载；我们处理了CSV文件中的数据，将其转化为数字值，以便感知器能够处理。此外，我们只选择了包含“buy”和“sex”关键词的消息（根据我们之前的描述），并计算了每条消息（无论是垃圾邮件还是正常邮件）中这些关键词在文本中出现的次数。
- en: The result of our preprocessing is available in the `sms_spam_perceptron.csv`
    file (attached to the source code repository that comes with this book).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预处理后的结果保存在`sms_spam_perceptron.csv`文件中（附在本书的源代码库中）。
- en: 'Then proceed with the loading of data from the `sms_spam_perceptron.csv` file,
    through the `pandas` library, extracting from the `DataFrame` of pandas the respective
    values, referenced through the `iloc()` method:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用`pandas`库加载`sms_spam_perceptron.csv`文件中的数据，从`pandas`的`DataFrame`中提取相应的值，通过`iloc()`方法引用：
- en: '[PRE0]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We have, therefore, assigned the class labels `ham` and `spam` (present in the
    `.csv` file in the first column of the `DataFrame`) to the `y` variable (which
    represents the vector of the expected values) using the `iloc()` method. Moreover,
    we have converted the previously mentioned class labels into the numerical values
    of `-1` (in the case of spam) and `+1` (in the case of ham) using the `where()`
    method of NumPy, to allow us to manage the class labels with the Perceptron.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用`iloc()`方法，将类标签`ham`和`spam`（出现在`DataFrame`的`.csv`文件的第一列中）分配给`y`变量（表示期望值的向量）。此外，我们使用NumPy的`where()`方法将之前提到的类标签转换为数值`-1`（对于垃圾邮件）和`+1`（对于正常邮件），以便我们能够在感知机中管理这些类标签。
- en: In the same way, we assigned to the `X` matrix the values corresponding to the
    `sex` and `buy` columns of the `DataFrame`, containing the number of occurrences
    corresponding to the two keywords within the message text. These values are also
    in numerical format, so it is possible to feed them to our Perceptron.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们将`DataFrame`中`sex`和`buy`列对应的值分配给了`X`矩阵，这些值是文本中与两个关键字对应的出现次数。这些值也是数字格式，因此可以将它们输入到我们的感知机中。
- en: 'Before proceeding with the creation of the Perceptron, we divide the input
    data between training data and test data:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建感知机之前，我们将输入数据分为训练数据和测试数据：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using the `train_test_split()` method applied to the `X` and `y` variables,
    we split the dataset into two subsets, assigning a percentage of 30% of the original
    dataset (using the parameter `test_size = 0.3`) to the test values, and the remaining
    70% to the training values.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用应用于`X`和`y`变量的`train_test_split()`方法，我们将数据集分成两个子集，将原始数据集的30%（使用`test_size =
    0.3`参数）分配给测试值，将剩余的70%分配给训练值。
- en: 'At this point, we can define our Perceptron by instantiating the `Perceptron`
    class of the `sklearn.linear_model` package:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以通过实例化`sklearn.linear_model`包中的`Perceptron`类来定义我们的感知机：
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: During the initialization phase of the `p` Perceptron, we assigned a maximum
    number of iterations equal to `40` (with the `max_iter = 40parameter` initialization)
    and a learning rate equal to `0.1` (`eta0 = 0.1`). Finally, we invoked the `fit()`
    method of the Perceptron, training the `p`object with the training data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在`p`感知机的初始化阶段，我们设置最大迭代次数为`40`（初始化时使用`max_iter = 40`参数）和学习率为`0.1`（`eta0 = 0.1`）。最后，我们调用感知机的`fit()`方法，用训练数据训练`p`对象。
- en: 'We can now proceed to estimate the values on the test data, invoking the `predict()`
    method of the Perceptron:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续在测试数据上估计值，调用感知机的`predict()`方法：
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As a consequence of the training phase on the sample data (which accounts for
    70% of the original dataset), the Perceptron should now be able to correctly estimate
    the expected values of the test data subset (equal to the remaining 30% of the
    original dataset).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 作为训练阶段的结果（训练数据占原始数据集的70%），感知机现在应该能够正确估计测试数据子集（原始数据集剩余的30%）的期望值。
- en: 'We can verify the accuracy of the estimated values returned by the Perceptron
    using the `sklearn.metrics` package of `scikit-learn` as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`scikit-learn`的`sklearn.metrics`包来验证感知机返回的估计值的准确性，方法如下：
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By comparing the test data (`y_test`) with the predicted values (`y_pred`),
    and summing up the overall number of mismatches, we are now able to evaluate the
    accuracy of the predictions provided by the Perceptron.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将测试数据（`y_test`）与预测值（`y_pred`）进行比较，并统计所有的不匹配项，我们现在能够评估感知机提供的预测准确性。
- en: In our example, the percentage of accuracy is quite good (90%), since the total
    number of cases of incorrect classifications amounts to only three.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，准确率相当好（90%），因为错误分类的总数仅为三个。
- en: Pros and cons of Perceptrons
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感知机的优缺点
- en: 'Despite the relative simplicity of the implementation of the Perceptron (simplicity
    here constitutes the strength of the algorithm, if compared to the accuracy of
    the predictions provided), it suffers from some important limitations. Being essentially
    a binary linear classifier, the Perceptron is able to offer accurate results only
    if the analyzed data can be linearly separable; that is, it is possible to identify
    a straight line (or a hyperplane, in case of multidimensional data) that completely
    bisects the data in the Cartesian plane:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管感知器的实现相对简单（这里的简单性是该算法的优势，相较于预测结果的准确性），但它存在一些重要的局限性。作为一个本质上的二分类线性分类器，感知器只有在分析的数据是线性可分的情况下才能提供准确的结果；也就是说，可以识别一条直线（或在多维数据的情况下，一个超平面），将数据完全分割在笛卡尔平面中：
- en: '![](img/77014850-7866-4ff8-a0a2-2bad99558bef.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77014850-7866-4ff8-a0a2-2bad99558bef.png)'
- en: 'If instead (and this is so in the majority of real cases) the analyzed data
    was not linearly separable, the Perceptron learning algorithm would oscillate
    indefinitely around the data, looking for a possible vector of weights that can
    linearly separate the data (without, however, being able to find it):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果相反（在大多数实际情况中确实如此）分析的数据不可线性分离，感知器学习算法将围绕数据无限振荡，试图寻找一个可以线性分离数据的权重向量（但无法找到）：
- en: '![](img/8cfba7dd-ad73-4b1a-b4e9-20d90b614b91.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8cfba7dd-ad73-4b1a-b4e9-20d90b614b91.png)'
- en: Therefore, the convergence of the Perceptron is only possible in the presence
    of linearly separable data, and in the case of a small learning rate. If the classes
    of data are not linearly separable, it is of great importance to set a maximum
    number of iterations (corresponding to the `max_iter` parameter) in order to prevent
    the algorithm from oscillating indefinitely in search of an (nonexistent) optimal
    solution.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，感知器的收敛仅在数据线性可分且学习率较小的情况下才可能发生。如果数据的类别不可线性分离，那么设置最大迭代次数（对应于`max_iter`参数）非常重要，以防止算法在寻找（不存在的）最优解时无限振荡。
- en: One way to overcome the Perceptron's practical limitations is to accept a **wider
    margin** of data separation between them. This is the strategy followed by SVMs,
    a topic we'll encounter in the next section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 克服感知器实际限制的一种方法是接受更**宽的间隔**来分离数据。这正是SVM所采用的策略，我们将在下一节中讨论这一话题。
- en: Spam detection with SVMs
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SVM进行垃圾邮件检测
- en: SVMs are an example of *supervised* algorithms (as well as the Perceptron),
    whose task is to identify the hyperplane that best separates classes of data that
    can be represented in a **multidimensional space**. It is possible, however, to
    identify different hyperplanes that correctly separate the data from each other;
    in this case, the choice falls on the hyperplane that **optimizes the prefixed
    margin**, that is, the distance between the hyperplane and the data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是*监督式*算法的一个例子（与感知器一样），其任务是识别最佳分离数据类别的超平面，这些数据可以在**多维空间**中表示。然而，可以识别出不同的超平面来正确分离数据；在这种情况下，选择的超平面是**优化预设间隔**的，即超平面与数据之间的距离。
- en: 'One of the advantages of the SVM is that the identified hyperplane is **not
    limited** to the linear model (unlike the Perceptron), as shown in the following
    screenshot:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的一个优势是，所识别的超平面**不限于**线性模型（与感知器不同），如下图所示：
- en: '![](img/57633dad-9b33-4d6a-97ed-408eda75ecae.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57633dad-9b33-4d6a-97ed-408eda75ecae.png)'
- en: The SVM can be considered as an extension of the Perceptron, however. While
    in the case of the Perceptron, our goal was to **minimize** classification errors,
    in the case of SVM, our goal instead is to **maximize** the margin, that is, the
    **distance** between the hyperplane and the training data *closest* to the hyperplane
    (the nearest training data is thus known as a **support vector**).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，SVM可以被看作是感知器的扩展。在感知器的情况下，我们的目标是**最小化**分类错误，而在SVM的情况下，我们的目标则是**最大化**间隔，即超平面与训练数据之间的**距离**，并且该数据是距离超平面*最近*的（因此，最接近的训练数据被称为**支持向量**）。
- en: SVM optimization strategy
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM优化策略
- en: Why choose the hyperplane that maximizes the margin in the first place? The
    reason lies in the fact that **wider margins** correspond to fewer classification
    errors, while with **narrower margins** we risk incurring the phenomenon known
    as **overfitting** (a real disaster that we may incur when dealing with *iterative*
    algorithms, as we will see when we will discuss verification and optimization
    strategies for our AI solutions).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么一开始选择最大化边距的超平面？原因在于，**更宽的边距**对应于更少的分类错误，而**更窄的边距**则可能导致我们遭遇**过拟合**现象（当我们处理*迭代*算法时，过拟合是一个真正的灾难，正如我们将在讨论AI解决方案的验证和优化策略时所见）。
- en: 'We can translate the SVM optimization strategy in mathematical terms, similar
    to what we have done in the case of the Perceptron (which remains our starting
    point). We define the condition that must be met to assure that the SVM correctly
    identifies the best hyperplane that separates the classes of data:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用数学术语来翻译SVM优化策略，类似于我们在感知机案例中所做的（感知机仍然是我们的起点）。我们定义了必须满足的条件，以确保SVM正确识别出将数据类分隔开的最佳超平面：
- en: '![](img/ef752721-9f69-4f15-a213-e9a48c28e73f.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef752721-9f69-4f15-a213-e9a48c28e73f.png)'
- en: Here, the *β* constant represents the *bias*, while *µ* represents our *margin*
    (which assumes the maximum possible positive value in order to obtain the best
    separation between the classes of values).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*β*常数表示*偏置*，而*µ*表示我们的*边距*（它假设最大可能的正值，以便在各个值的类别之间获得最佳分隔）。
- en: In practice, to the algebraic multiplication (represented by ![](img/d31c5f8b-b344-4e90-b3dd-54e4eeece6a4.png))
    we add the value of the *β* bias, which allows us to obtain a value greater than
    or equal to zero, in the presence of values ​​that fall in the same **class label**
    (remember that *y* can only assume the values of ​​`-1` or `+1` to distinguish
    between the corresponding classes to which the samples belong, as we have already
    seen in the case of the Perceptron).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在代数乘法（由 ![](img/d31c5f8b-b344-4e90-b3dd-54e4eeece6a4.png) 表示）中，我们添加了*β*偏置值，这使得我们能够在值落入相同的**类标签**时，得到一个大于或等于零的值（记住，*y*只能取`-1`或`+1`的值，以区分样本所属的相应类别，正如我们在感知机案例中已经看到的那样）。
- en: At this point, the value calculated in this way is compared with the ![](img/0b961c0e-f1c9-427f-82ce-c80f17a8b870.png) margin in
    order to ensure that the distance between each sample and the separating hyperplane
    we identified (thus constituting our decision boundary) is greater or at most
    equal to our margin (which, as we have seen, is identified as the maximum possible
    positive value, in order to obtain the *best* separation between the classes of
    values).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在此时，我们以这种方式计算出的值与 ![](img/0b961c0e-f1c9-427f-82ce-c80f17a8b870.png) 边距进行比较，以确保每个样本与我们识别出的分隔超平面（即构成我们的决策边界）之间的距离大于或等于我们的边距（正如我们所看到的，边距被确定为最大可能的正值，以便在各个值的类别之间获得*最佳*分隔）。
- en: SVM spam filter example
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM垃圾邮件过滤器示例
- en: Let's go back to our sample spam filter, and replace the Perceptron with an
    SVM, as we have seen in the identification of the hyperplane that we are not limited
    to using linear classifier models only (being able to choose between classifiers
    characterized by greater complexity).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的垃圾邮件过滤器示例，并将感知机替换为SVM，正如我们在识别超平面时所看到的那样，我们并不仅限于使用线性分类器模型（可以选择具有更高复杂性的分类器）。
- en: However, to compare the results obtained previously with the Perceptron, which
    represents a strictly linear classifier, we will also choose a linear classifier
    in the case of the SVM.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了比较之前与感知机得到的结果，感知机是一个严格的线性分类器，我们在SVM的情况下也选择了线性分类器。
- en: This time, however, our dataset (stored in the `sms_spam_svm.csv` file, and
    derived from the collection of SMS spam messages we found earlier in the chapter,
    in which the total occurrences of the various suspicious keywords were extracted
    and compared to the total number of harmless words appearing within the messages)
    is not strictly linearly separable.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这一次，我们的数据集（存储在`sms_spam_svm.csv`文件中，并源自本章前面找到的SMS垃圾邮件消息集合，其中提取并比较了各种可疑关键词的总出现次数和消息中无害单词的总数）并不是严格线性可分的。
- en: 'In the same way as in the case of the Perceptron, we will proceed to load the
    data with `pandas`, associating the class labels with the corresponding ​​`-1` values
    (in the case of spam) and `1` (in the case of ham):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 与感知机案例中相同，我们将使用`pandas`加载数据，将类标签与相应的`-1`值（表示垃圾邮件）和`1`值（表示正常邮件）关联起来：
- en: '[PRE5]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once the data has been loaded, we proceed to split the original dataset into
    30% test data and 70% training data:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据加载完毕，我们接着将原始数据集拆分为30%的测试数据和70%的训练数据：
- en: '[PRE6]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'At this point, we can thus proceed to instantiate our SVM, importing the `SVC`
    class (which stands for **support vector classifier**) from the `sklearn.svm` package,
    choosing the linear classifier (`kernel = ''linear''`), then proceeding to the
    model training by invoking the `fit()` method, and finally estimating the test
    data by invoking the `predict()` method:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以继续实例化我们的SVM，导入`SVC`类（代表**支持向量分类器**）来自`sklearn.svm`包，选择线性分类器（`kernel
    = 'linear'`），然后通过调用`fit()`方法进行模型训练，最后通过调用`predict()`方法估计测试数据：
- en: '[PRE7]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can now evaluate the accuracy of the predictions returned by the SVM algorithm,
    making use of the `sklearn.metrics` package as we did with the Perceptron:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过使用`sklearn.metrics`包来评估SVM算法返回的预测准确性，就像我们在使用感知机时所做的那样：
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Even in the presence of non-linearly separable data, we see how well the SVM
    algorithm behaves, since the level of accuracy of the predictions accounts to
    84%, with the number of incorrect classifications accounting to only 7 cases.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在存在非线性可分数据的情况下，我们也可以看到SVM算法的表现如何，因为预测的准确度达到了84%，而错误分类的案例仅为7个。
- en: Image spam detection with SVMs
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SVM进行图像垃圾邮件检测
- en: The versatility of the SVM algorithm allows us to deal with even more complex
    real-world classification cases, such as in the case of spam messages represented
    by images, instead of simple text.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: SVM算法的多功能性使我们能够处理更复杂的现实世界分类案例，例如以图像形式呈现的垃圾邮件，而不是简单的文本。
- en: As we have seen, spammers are well aware of our detection attempts, and therefore
    try to adopt all possible solutions to deceive our filters. One of the evasion
    strategies is to use images as a vehicle for spreading spam, instead of simple
    text.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，垃圾邮件发送者非常清楚我们的检测尝试，因此会尝试采用各种可能的解决方案来欺骗我们的过滤器。规避策略之一是使用图像作为传播垃圾邮件的载体，而不是简单的文本。
- en: 'For some time, however, viable image-based spam detection solutions have been
    available. Among these, we can distinguish detection strategies based on the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，已有一段时间，基于图像的垃圾邮件检测解决方案已可行。在这些方案中，我们可以区分以下几种基于不同策略的检测方法：
- en: '**Content-based filtering**: The approach consists of trying to identify the
    suspect keywords that are most commonly used in textual spam messages even within
    images; to this end, pattern recognition techniques leveraging optical character
    recognition (**OCR**) technology are implemented in order to extract text from
    images (this is the solution that SpamAssassin adopts).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容的过滤**：这种方法的核心是尝试识别在文本垃圾邮件中常见的嫌疑关键词，即使在图像中也存在这些关键词；为此，采用模式识别技术并利用光学字符识别（**OCR**）技术来提取图像中的文本（这是SpamAssassin采用的解决方案）。'
- en: '**Non content-based filtering**: In this case, we try to identify specific
    features of spam images (such as color features and so on), on the grounds that
    spam images, being computer-generated, show different characteristics compared
    to natural images; for the extraction of the features, we make use of advanced
    recognition techniques based on NNs and **deep learning** (**DL**).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非基于内容的过滤**：在这种情况下，我们尝试识别垃圾邮件图像的特定特征（如颜色特征等），理由是垃圾邮件图像由于计算机生成，与自然图像相比显示出不同的特征；为了提取这些特征，我们采用基于神经网络（NN）和**深度学习**（**DL**）的先进识别技术。'
- en: How did SVM come into existence?
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM是如何诞生的？
- en: Once the salient features of the images have been extracted, and the corresponding
    samples have been classified within their respective classes (spam or ham), it
    is possible to exploit an SVM to perform model training on these features.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提取出图像的显著特征，并且将相应的样本归类到其对应类别（垃圾邮件或正常邮件）中，就可以利用SVM对这些特征进行模型训练。
- en: One of the most recent projects on this subject is *Image Spam Analysis* by
    Annapurna Sowmya Annadatha ([http://scholarworks.sjsu.edu/etd_projects/486](http://scholarworks.sjsu.edu/etd_projects/486)),
    which is characterized by the innovative approach adopted, based on the assumption
    that the features that characterize a spam image, being computer generated, are
    different to those associated with an image generated by a camera; and the selective
    use of SVM, which leads to high accuracy of results compared to a reduced cost
    in computational terms.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题的最新项目之一是*图像垃圾邮件分析*，由Annapurna Sowmya Annadatha ([http://scholarworks.sjsu.edu/etd_projects/486](http://scholarworks.sjsu.edu/etd_projects/486))完成，该项目以创新的方法为特点，基于以下假设：垃圾邮件图像的特征由于是计算机生成的，与由相机生成的图像的特征不同；并且选择性使用SVM，从而在计算成本较低的情况下，实现了结果的高准确度。
- en: 'The approach consists of the following steps:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法包括以下步骤：
- en: Train the classifier using the linear SVM and the feature set
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用线性SVM和特征集训练分类器
- en: Compute the SVM weights for all the features
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有特征的SVM权重
- en: Select the first one with the largest weights
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择第一个具有最大权重的
- en: Create a model based on the subset
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于该子集创建模型
- en: For further information, refer to the project reference mentioned in the previous
    paragraph.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请参阅上一段提到的项目参考资料。
- en: Phishing detection with logistic regression and decision trees
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用逻辑回归和决策树进行钓鱼检测
- en: After having analyzed the Perceptron and the SVM, we now deal with alternative
    classification strategies that make use of logistic regression and decision trees.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析了感知机和SVM之后，我们现在处理使用逻辑回归和决策树的替代分类策略。
- en: But before continuing, we will discover the distinctive features of these algorithms
    and their use for spam detection and phishing, starting with regression models.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 但在继续之前，我们将首先了解这些算法的独特特征以及它们在垃圾邮件检测和钓鱼检测中的应用，从回归模型开始。
- en: Regression models
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归模型
- en: Regression models are undoubtedly the most used of all learning algorithms.
    Developed from statistical analysis, regression models have quickly spread in
    ML and in AI in general. The most known and used regression model is linear regression,
    thanks to the simplicity of its implementation and the good predictive capacity
    that it allows us to achieve in many practical cases (such as estimating the level
    of house prices in relation to changes in interest rates).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型无疑是所有学习算法中最常用的。回归模型起源于统计分析，并迅速在机器学习和人工智能中得到应用。最为人熟知和使用的回归模型是线性回归，因为它的实现简单，并且在许多实际案例中（例如根据利率变化估算房价水平）具有良好的预测能力。
- en: Alongside the linear model, there is also the logistic regression model, especially
    useful in the most complex cases, where the linear model proves to be too rigid
    for the data to be treated. Both models, therefore, represent the tools of choice
    for analysts and algorithm developers.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 除了线性模型外，还有逻辑回归模型，特别是在数据处理过于复杂、线性模型过于僵化的情况下非常有用。因此，这两种模型代表了分析师和算法开发人员的首选工具。
- en: In the next section, we will analyze the characteristics and advantages of regression
    models, and their possible uses in the field of spam detection. Let's start our
    analysis with the simplest model, the linear regression model, which will help
    us make comparisons with the logistic regression model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将分析回归模型的特性和优势，以及它们在垃圾邮件检测领域的可能应用。让我们从最简单的模型——线性回归模型开始分析，这将帮助我们与逻辑回归模型进行比较。
- en: Introducing linear regression models
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍线性回归模型
- en: The linear regression model is characterized by the fact that the data is represented
    as sums of features, leading to a straight line in the Cartesian plane.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型的特点在于，数据表现为特征的和，从而在笛卡尔平面上形成一条直线。
- en: 'In formal terms, linear regression can be described by the following formula:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 从正式的角度看，线性回归可以用以下公式描述：
- en: '![](img/61f944ad-cec4-4a1f-8dbd-4f4c901079b9.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61f944ad-cec4-4a1f-8dbd-4f4c901079b9.png)'
- en: Here, *y* represents the predicted values, which are the result of the linear
    combination of the single features (represented by the *X* matrix) to which a
    weight vector is applied (represented by the *w vector*), and by the addition
    of a constant (*β*), which represents the default predicted value when all features
    assume the value of zero (or simply are missing).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*y* 代表预测值，它是单个特征（由 *X* 矩阵表示）的线性组合结果，应用了一个权重向量（由 *w* 向量表示），并加上一个常数 (*β*)，这个常数代表在所有特征的值为零（或简单缺失）时的默认预测值。
- en: The *β* constant can also be interpreted as the systematic distortion of the
    model, and corresponds graphically with the intercept value on the vertical axis
    of the Cartesian plane (that is to say, the point where the regression line meets
    the vertical axis).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*β* 常数也可以解释为模型的系统性偏差，并在图形上与笛卡尔平面垂直轴上的截距值对应（也就是说，回归线与垂直轴相交的点）。'
- en: 'Obviously, the linear model can be extended to cases in which there is more
    than just one feature. In this case, the mathematical formalization assumes the
    following aspect:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，线性模型可以扩展到有多个特征的情况。在这种情况下，数学公式化的形式如下：
- en: '![](img/1707e517-6e40-432d-8e07-1b998b2aa02d.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1707e517-6e40-432d-8e07-1b998b2aa02d.png)'
- en: The geometric representation of the previous formula will correspond to a hyperplane
    in the *n*-dimensional space, rather than a straight line in the Cartesian plane.
    We have mentioned the importance of the ![](img/ee6a30be-f904-4e97-8f92-ca8517a68fa8.png)
    constant as the default predictive value of the model in the case in which the
    features assume a value equal to zero.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 之前公式的几何表示将对应于 *n* 维空间中的超平面，而不是笛卡尔平面中的直线。我们已经提到过，![](img/ee6a30be-f904-4e97-8f92-ca8517a68fa8.png)
    常数作为模型在特征值为零时的默认预测值，具有重要性。
- en: The individual ​​![](img/6dffb83c-d6d6-4145-9f31-e6ec4acba0a6.png) values within
    the vector of the weights, ![](img/aa889ef4-0ff3-4e3f-9b5b-05c300af8b09.png),
    can be interpreted as a measure of the intensity of the corresponding features,
    ![](img/1cd520fc-8894-40a4-b160-ca820d1ac691.png)[.]
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 权重向量中的各个![](img/6dffb83c-d6d6-4145-9f31-e6ec4acba0a6.png) 值，![](img/aa889ef4-0ff3-4e3f-9b5b-05c300af8b09.png)，可以解释为相应特征的重要性度量，![](img/1cd520fc-8894-40a4-b160-ca820d1ac691.png)[.]
- en: In practice, if the value of the ![](img/5c0cd86a-07c6-4abd-b14a-4a395f6a092f.png)
    weight is close to zero, the corresponding ![](img/37084f2a-9bfa-4559-b9b5-38177aebd8c1.png)
    feature assumes a minimum importance (or none at all) in the determination of
    predicted values. If, instead, the ![](img/d5561866-a060-4c5f-984e-3f1a36a87a7b.png)
    weight assumes positive values, it will amplify the final value returned by the
    regression model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果![](img/5c0cd86a-07c6-4abd-b14a-4a395f6a092f.png) 权重值接近零，则对应的![](img/37084f2a-9bfa-4559-b9b5-38177aebd8c1.png)
    特征在预测值的确定中具有最小重要性（或者根本没有重要性）。相反，如果![](img/d5561866-a060-4c5f-984e-3f1a36a87a7b.png)
    权重为正值，它将放大回归模型返回的最终值。
- en: If, on the other hand, ![](img/89ba77ce-4e92-4de7-a30e-42d0f1230e70.png) assumes
    negative values, it will help to reverse the direction of the model's predictions,
    as the value of the *![](img/f4aae63f-6229-4f1f-a898-807f7044571d.png)* feature increases,
    it will correspond to a decrease in the value estimated by the regression. Hence,
    it is important to consider the impacts of the weights on the *![](img/9c016c68-d6c7-4054-9d11-5616f3db9da9.png)* features, as
    they are determinant in the correctness of the predictions that we can derive
    from the regression model.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果![](img/89ba77ce-4e92-4de7-a30e-42d0f1230e70.png) 取负值，它将有助于逆转模型预测的方向，因为当
    *![](img/f4aae63f-6229-4f1f-a898-807f7044571d.png)* 特征增加时，它将对应回归模型估算值的下降。因此，考虑权重对
    *![](img/9c016c68-d6c7-4054-9d11-5616f3db9da9.png)* 特征的影响非常重要，因为它们是我们从回归模型中推导出预测正确性的决定性因素。
- en: Linear regression with scikit-learn
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 进行线性回归
- en: 'In the following code snippet, we will see how to implement a simple predictive
    model based on linear regression, using the `linear_model` module of `scikit-learn`,
    which we will feed with one of the previously used spam message datasets:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码片段中，我们将看到如何基于线性回归实现一个简单的预测模型，使用 `scikit-learn` 的 `linear_model` 模块，并以之前使用的垃圾邮件数据集之一作为输入：
- en: '[PRE9]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To verify the accuracy of the predictions provided by the linear regression
    model, we can use the `score()` method, which gives us the measurement of the
    coefficient of the R² determination.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证线性回归模型提供的预测的准确性，我们可以使用 `score()` 方法，该方法给我们提供 R² 判定系数的度量。
- en: This coefficient varies between `0` and `1`, and measures how much better the
    predictions returned by the linear model are, when compared to the simple mean.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这个系数在`0`和`1`之间变化，用来衡量当与简单均值相比时，线性模型返回的预测有多好。
- en: Linear regression – pros and cons
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归 – 优缺点
- en: As we have seen, the simplicity of implementation represents an undoubted advantage
    of the linear regression model. However, the limitations of the model are rather
    important.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，线性回归模型的实现简单性代表了其无可争议的优势。然而，模型的局限性也相当显著。
- en: In fact, the linear regression model can only be used to manage quantitative
    data, whereas in the case where the predictive analysis used categorical data,
    we have to resort to the logistic regression model. Furthermore, the major limitation
    of linear regression is that the model assumes that features are mostly unrelated;
    that is, they do not influence each other. This assumption legitimizes the representation
    of the products between the features and their respective weights as sums of independent
    terms.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，线性回归模型只能用来处理定量数据，而在使用分类数据进行预测分析的情况下，我们必须借助逻辑回归模型。此外，线性回归的主要局限性在于模型假设特征之间大多不相关；也就是说，特征之间不会相互影响。这一假设使得我们可以将特征及其各自权重的乘积表示为独立项的和。
- en: There are, however, real cases in which this assumption is unrealistic (for
    example, the possible relationship between variables such as the age and the weight
    of a person, which are related to each other, as weight varies according to age).
    The negative side effect of this assumption consists in the fact that we risk
    adding the same information several times, failing to correctly predict the effect
    of the combination of the variables on the final result.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，确实存在一些实际情况，其中这一假设并不现实（例如，人的年龄与体重之间可能存在关系，体重会随年龄变化）。这一假设的负面副作用是，我们可能会多次添加相同的信息，无法正确预测变量组合对最终结果的影响。
- en: In technical terms, the linear regression model is characterized by a greater
    bias in the predictions, instead of greater variance (we will have the opportunity
    to face the trade-off between bias and variance later on).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度看，线性回归模型的特点是预测中具有较大的偏差，而不是较大的方差（稍后我们将有机会讨论偏差和方差之间的权衡）。
- en: In other words, when the data being analyzed exhibits complex relationships,
    the linear regression model leads us to systematically distorted predictions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，当被分析的数据表现出复杂的关系时，线性回归模型会导致我们做出系统性的失真预测。
- en: Logistic regression
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: 'We have seen that one of the limits of linear regression is that it cannot
    be used to solve classification problems:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，线性回归的一个限制是它不能用来解决分类问题：
- en: In fact, in case we wanted to use linear regression to classify the samples
    within two classes (as is the case in spam detection) whose labels are represented
    by numerical values ​​(for example, `-1` for **spam**, and `+1` for **ham**),
    the linear regression model will try to identify the result that is closest to
    the target value (that is, linear regression has the purpose of minimizing forecasting
    errors). The negative side effect of this behavior is that it leads to greater
    classification errors. With respect to the Perceptron, linear regression does
    not give us good results in terms of classification accuracy, precisely because
    linear regression works better with continuous intervals of values, rather than
    with classes of discrete values ​​(as is the case in classification).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果我们想使用线性回归对属于两个类别的样本进行分类（如垃圾邮件检测中的情况），这些样本的标签由数值表示（例如，`-1`表示**垃圾邮件**，`+1`表示**正常邮件**），线性回归模型将试图识别与目标值最接近的结果（也就是说，线性回归的目标是最小化预测误差）。这种行为的负面副作用是，它会导致更大的分类误差。相对于感知器，线性回归在分类准确性方面无法给出良好的结果，正是因为线性回归在处理值的连续区间时效果较好，而不是处理离散值的类别（如分类中的情况）。
- en: An alternative strategy, most useful for the purposes of classification, consists
    of estimating the probability of the samples belonging to individual classes.
    This is the strategy adopted by logistic regression (which, in spite of the name,
    constitutes a classification algorithm, rather than a regression model).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一种替代策略，更适用于分类目的，是估算样本属于各个类别的概率。这是逻辑回归所采用的策略（尽管名字中有“回归”二字，但它实际上是一个分类算法，而不是回归模型）。
- en: 'The mathematical formulation of logistic regression is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的数学公式如下：
- en: '![](img/a127c2e4-f02b-4988-abb2-688c11c6e204.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a127c2e4-f02b-4988-abb2-688c11c6e204.png)'
- en: Here, ![](img/dc3f4c7d-604d-4827-977a-748627caf92e.png). ![](img/2760b21d-2534-48ee-bdb2-9e6f36a3a9d7.png)
    therefore measures the conditional probability that a given sample falls into
    the ![](img/00e35927-6dee-4570-ab02-1fd300f2007b.png) class, given the ![](img/28a16344-441e-46fb-9f56-43417e767bb3.png)
    features.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这里， ![](img/dc3f4c7d-604d-4827-977a-748627caf92e.png)。 ![](img/2760b21d-2534-48ee-bdb2-9e6f36a3a9d7.png)
    因此衡量的是给定样本属于 ![](img/00e35927-6dee-4570-ab02-1fd300f2007b.png) 类别的条件概率，前提是已知 ![](img/28a16344-441e-46fb-9f56-43417e767bb3.png)
    特征。
- en: A phishing detector with logistic regression
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用逻辑回归的钓鱼检测器
- en: We can then use logistic regression to implement a phishing detector, exploiting
    the fact that logistic regression is particularly useful for solving classification
    problems. Like spam detection, phishing detection is nothing more than a sample
    classification task.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用逻辑回归来实现一个钓鱼检测器，利用逻辑回归特别适用于解决分类问题的特点。像垃圾邮件检测一样，钓鱼检测不过是一个样本分类任务。
- en: In our example, we will use the dataset available on the UCI machine learning
    repository website ([https://archive.ics.uci.edu/ml/datasets/Phishing+Websites](https://archive.ics.uci.edu/ml/datasets/Phishing+Websites)).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将使用UCI机器学习库网站提供的数据集（[https://archive.ics.uci.edu/ml/datasets/Phishing+Websites](https://archive.ics.uci.edu/ml/datasets/Phishing+Websites)）。
- en: The dataset has been converted into CSV format starting from the original `.arff`
    format, using the data wrangling technique known as **one-hot encoding** ([https://en.wikipedia.org/wiki/One-hot](https://en.wikipedia.org/wiki/One-hot)),
    and consists of records containing 30 features that characterize phishing websites.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集已经从原始的`.arff`格式转换为CSV格式，采用了被称为**独热编码**的数据整理技术（[https://en.wikipedia.org/wiki/One-hot](https://en.wikipedia.org/wiki/One-hot)），包含了30个特征，用于表征钓鱼网站。
- en: 'Find the source code of our detector in the following code block:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中找到我们检测器的源代码：
- en: '[PRE10]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As we can see, the level of accuracy of the logistic regression classifier is
    quite good, as the model is able to correctly detect over 90% of URLs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，逻辑回归分类器的准确率相当不错，因为该模型能够正确检测出超过90%的URL。
- en: Logistic regression pros and cons
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归的优缺点
- en: 'The advantages of adopting logistic regression can be summarized as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 采用逻辑回归的优势可以总结如下：
- en: The model can be trained very efficiently
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型可以非常高效地训练
- en: It can be used effectively even in the presence of a large number of features
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使在特征数量较多的情况下，它也能有效使用
- en: The algorithm has a high degree of scalability, due to the simplicity of its
    scoring function
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于其评分函数的简洁性，该算法具有很高的可扩展性
- en: At the same time, however, logistic regression suffers from some important limitations,
    deriving from the basic assumptions that characterize it, such as the need for
    the features to be linearly independent (a rule that translates in technical terms
    as the absence of multicollinearity), as well as requiring more training samples
    on average than other competing algorithms, as the maximum likelihood criterion
    adopted in logistic regression is known to be less powerful than, say, the least
    squares method used in linear regression to minimize prediction errors.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，逻辑回归也存在一些重要的局限性，这些局限性源于其基本假设，比如要求特征必须是线性独立的（这一规则在技术上称为不存在多重共线性），并且通常需要比其他竞争算法更多的训练样本，因为逻辑回归中采用的最大似然准则比起线性回归中用于最小化预测误差的最小二乘法来说，较为无力。
- en: Making decisions with trees
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用树进行决策
- en: As we saw in the previous paragraphs, when we have to choose which algorithm
    to use to perform a given task, we must consider the type of features that characterize
    our data. The features can in fact be made up of quantitative values ​​or qualitative
    data.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前述段落中所见，当我们需要选择使用哪种算法来执行某项任务时，必须考虑构成数据的特征类型。特征实际上可以由定量值或定性数据组成。
- en: ML algorithms are obviously more at ease when dealing with quantitative values;
    however, most of the real cases involve the use of data expressed in a qualitative
    form (such as descriptions, labels, words, and so on) that imply information expressed
    in non-numerical form.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法显然更擅长处理定量值；然而，大多数实际情况涉及使用以定性形式（如描述、标签、单词等）表示的数据，这些数据包含了非数字形式的信息。
- en: As in the case of spam detection, we have seen how the translation in numerical
    form (a practice known as **numeric encoding**) of qualitative features (such
    as the spam and ham labels, to which we assigned the numerical values of ​​`-1`
    and `+1`, respectively) only partially solve the classification problems.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 正如垃圾邮件检测的例子，我们已经看到如何将定性特征（如垃圾邮件和正常邮件标签，分别赋予数值`-1`和`+1`）转换为数值形式（这种做法称为**数值编码**），但它仅部分解决了分类问题。
- en: It is not by chance that the paper entitled *Induction of Decision Trees* ([http://dl.acm.org/citation.cfm?id=637969](http://dl.acm.org/citation.cfm?id=637969)),
    in which John Ross Quinlan described the decision trees algorithm, takes into
    consideration information conveyed in qualitative form. The object of the paper
    by Quinlan (whose contribution was significant for the development of decision
    trees) is in fact the choice of whether to play tennis outside, based on features
    such as outlook (sunny, overcast, or rain), temperatures (cool, mild, or hot),
    humidity (high or normal), windy (true or false).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这并非偶然，约翰·罗斯·昆兰（John Ross Quinlan）在论文《决策树的归纳》（*Induction of Decision Trees*）中描述了决策树算法，这篇论文考虑了以定性形式传递的信息。昆兰的论文（他的贡献对决策树的发展至关重要）实际上是选择是否在户外打网球，基于如天气（晴天、多云或下雨）、温度（凉爽、温和或炎热）、湿度（高或正常）、风速（真或假）等特征。
- en: How can we instruct a machine to process information presented both in quantitative
    and qualitative forms?
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何指示机器处理同时以定量和定性形式呈现的信息？
- en: Decision trees rationales
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树的基本原理
- en: Decision trees use binary trees to analyze and process data, thus succeeding
    in formulating predictions concerning both values ​​expressed in numerical and
    categorical form, accepting both numerical values ​​and qualitative information
    as input data.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树使用二叉树来分析和处理数据，从而成功地对以数值和类别形式表示的值做出预测，接受数值型和定性信息作为输入数据。
- en: 'To intuitively understand the strategy adopted by decision trees, let''s see
    the typical steps involving their implementation:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了直观理解决策树所采用的策略，下面我们来看一看其实现中的典型步骤：
- en: The first step consists in subdividing the original dataset into two child subsets,
    after having verified a binary condition, following the first subdivision, we
    will have two child subsets as a result, in which the binary condition is verified
    or falsified.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是将原始数据集划分为两个子集，在验证二元条件后，进行第一次划分，结果会得到两个子集，在这两个子集中二元条件被验证或否定。
- en: The child subsets will be further subdivided on the basis of further conditions;
    at each step, the condition that provides the best bipartition of the original
    subset is chosen (for this purpose, appropriate metrics are used to measure the
    quality of the subdivision).
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 子集将根据进一步的条件继续细分；在每一步中，选择能够提供最佳二分划分的条件（为此，使用适当的度量标准来衡量划分质量）。
- en: The division proceeds in a recursive manner. It is therefore necessary to define
    a stopping condition (such as the achievement of a maximum depth).
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 划分过程是递归进行的。因此，必须定义一个停止条件（例如，达到最大深度）。
- en: At each iteration, the algorithm generates a tree structure in which the child
    nodes represent the choices taken at each step, with each leaf contributing to
    the overall classification of the input data.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次迭代中，算法生成一棵树结构，其中子节点代表每一步所做的选择，每个叶子节点则有助于输入数据的整体分类。
- en: 'Take a look at the following diagram, which depicts the decision tree for the
    Iris dataset:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看下图，它展示了Iris数据集的决策树：
- en: '![](img/003c40cf-dfa5-4005-9e8a-ac54f87b6aa1.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/003c40cf-dfa5-4005-9e8a-ac54f87b6aa1.png)'
- en: Decision trees are also very efficient in the elaboration of large datasets.
    In fact, the characteristics of the tree data structures allow us to limit the
    complexity of the algorithm to an order of magnitude equal to *0* (*log n*).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树在处理大型数据集方面也非常高效。事实上，树形数据结构的特点使我们能够将算法的复杂度限制在一个数量级为*0*（*log n*）的范围内。
- en: Phishing detection with decision trees
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树进行钓鱼攻击检测
- en: 'We will now see the use of decision trees in the task of phishing detection.
    As we said in the previous paragraphs, phishing detection (as well as spam filtering)
    basically involves the classification of input data:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看决策树在钓鱼攻击检测任务中的应用。如前所述，钓鱼攻击检测（以及垃圾邮件过滤）基本上涉及输入数据的分类：
- en: '[PRE11]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can see how the decision tree classifier further enhances the already excellent
    performance obtained previously with logistic regression.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，决策树分类器进一步增强了之前通过逻辑回归获得的优秀性能。
- en: Decision trees – pros and cons
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树——优缺点
- en: In addition to the advantages already described, we must remember the possible
    disadvantages related to decision trees; these are essentially associated with
    the phenomenon of overfitting, which is due to the complexity of the tree data
    structures (it is in fact necessary to proceed in a systematic manner with the
    pruning of the tree, in order to reduce its overall complexity).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 除了已经描述的优点外，我们还必须记住与决策树相关的可能缺点；这些缺点主要与过拟合现象有关，这是由于树形数据结构的复杂性（实际上，必须通过系统化的方式进行树的修剪，以减少其整体复杂性）。
- en: One of the undesirable consequences of the complexity is the high sensitivity
    of the algorithm to even the smallest changes in the training dataset, which can
    lead to sensible impacts on the prediction model. Therefore, decision trees are
    not the best fit for incremental learning.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂性带来的一个不利后果是算法对训练数据集中的细微变化非常敏感，这可能会对预测模型产生显著影响。因此，决策树不适合增量学习。
- en: Spam detection with Naive Bayes
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯进行垃圾邮件检测
- en: One of the advantages associated with the use of Naive Bayes is the fact that
    it requires little starting data to begin classifying input data; moreover, the
    information that progressively adds up contributes to dynamically updating the
    previous estimates, incrementally improving the forecasting model (unlike, as
    we saw in the previous paragraph, the algorithm based on decision trees).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯的一个优势是，它只需要很少的初始数据就可以开始对输入数据进行分类；此外，随着信息的逐步增加，它有助于动态更新先前的估计，逐步改善预测模型（与我们在前一段看到的基于决策树的算法不同）。
- en: Advantages of Naive Bayes for spam detection
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯在垃圾邮件检测中的优势
- en: The aforementioned features are well suited to the task of spam detection. Without
    the need to resort to large datasets, in fact, the spam detection algorithms based
    on Naive Bayes can exploit the emails already present in the inbox, constantly
    updating the probability estimations on the base of new email messages that are
    progressively added to those already existing.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 上述特性非常适合垃圾邮件检测任务。事实上，在不需要大量数据集的情况下，基于朴素贝叶斯的垃圾邮件检测算法可以利用收件箱中已经存在的邮件，不断地根据逐渐加入的新邮件更新概率估计。
- en: 'The constant process of updating the probability estimates is based on the
    well-known Bayes rule:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 不断更新概率估计的过程基于著名的贝叶斯规则：
- en: '![](img/6283b99d-def2-4213-8f43-85cd788579df.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6283b99d-def2-4213-8f43-85cd788579df.png)'
- en: The preceding equation describes the relationship between the probability of
    the occurrence of an event, *A,* conditioned to the evidence, *E*.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方程描述了事件*A*发生的概率与证据*E*之间的关系。
- en: This relationship depends on the probability of *A* (prior probability) and
    the likelihood, ![](img/834b7330-4413-44d0-a70a-be766c67857f.png), of evidence, *E*,
    which determines the probability estimate, ![](img/cf3e7f1e-cb2f-4e29-b54b-85a51147b8b1.png)
    (the posterior probability).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个关系取决于*A*（先验概率）和证据*E*的似然性！[](img/834b7330-4413-44d0-a70a-be766c67857f.png)，后者决定了概率估计！[](img/cf3e7f1e-cb2f-4e29-b54b-85a51147b8b1.png)（后验概率）。
- en: An important feature of the Bayes rule probability update is that the probability
    ![](img/fb696743-a298-4c7f-9d4f-1f72d190f1eb.png) (the posterior probability),
    as a result of the updating process, becomes the new prior probability, thus contributing
    to dynamically updating the existing probability estimates.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯规则概率更新的一个重要特性是，经过更新过程后，概率 ![](img/fb696743-a298-4c7f-9d4f-1f72d190f1eb.png)（后验概率）会成为新的先验概率，从而有助于动态更新现有的概率估计。
- en: Why Naive Bayes?
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择朴素贝叶斯？
- en: One of the basic assumptions of the Bayes rule is that it postulates the independence
    of events. This assumption is not always realistic.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯规则的基本假设之一是它假设事件之间是独立的。这个假设并不总是现实的。
- en: However, in most cases, it is a reasonable condition that leads to good forecasts,
    while at the same time simplifying the application of the Bayes rule, especially
    in the presence of several competing events, thus reducing the calculations to
    a simple multiplication of the probabilities associated with each event.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在大多数情况下，这是一个合理的条件，有助于做出良好的预测，同时简化了贝叶斯法则的应用，特别是在多个竞争事件的情况下，从而将计算简化为对每个事件相关概率的简单相乘。
- en: Before seeing Naive Bayes in action, applying the algorithm in spam detection,
    we need to analyze the text analysis techniques to allow Naive Bayes to dynamically
    recognize the suspect keywords used by spammers (rather than choosing them in
    a fixed fashion, as we did in the previous examples).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际使用朴素贝叶斯算法进行垃圾邮件检测之前，我们需要分析文本分析技术，以使朴素贝叶斯能够动态地识别垃圾邮件发送者使用的可疑关键词（而不是像之前的示例那样以固定的方式选择它们）。
- en: NLP to the rescue
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLP来拯救我们
- en: One of the most exciting areas of AI is certainly NLP, which consists of the
    analysis and automated understanding of human language.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: AI最令人兴奋的领域之一无疑是自然语言处理（NLP），它包括对人类语言的分析和自动化理解。
- en: The purpose of NLP is to try to extract sensible information from unstructured
    data (such as email messages, tweets, and Facebook posts).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: NLP的目的是尝试从非结构化数据中提取有意义的信息（例如电子邮件、推文和Facebook帖子）。
- en: The fields of application of NLP are huge, and vary from simultaneous translations
    to sentiment analysis speech recognition.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: NLP的应用领域非常广泛，从实时翻译到情感分析和语音识别等。
- en: NLP steps
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLP步骤
- en: 'The phases that characterize NPL are as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: NLP的主要阶段如下：
- en: Identification of the words (tokens) constituting the language
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别构成语言的单词（标记）
- en: Analysis of the structure of the text
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本结构分析
- en: Identification of the relationships between words (in paragraphs, sentences,
    and so on)
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别单词之间的关系（例如段落、句子等）
- en: Semantic analysis of the text
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本的语义分析
- en: One of the best known Python libraries for NLP is the **Natural Language Toolkit**
    (**NLTK**), often used for spam detection.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的Python自然语言处理库之一是**自然语言工具包**（**NLTK**），它常用于垃圾邮件检测。
- en: In the following example, we will see how to take advantage of NLTK combined
    with Naive Bayes to create a spam detector.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将看到如何利用NLTK结合朴素贝叶斯算法来创建一个垃圾邮件检测器。
- en: A Bayesian spam detector with NLTK
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NLTK的贝叶斯垃圾邮件检测器
- en: As a concluding example, we will show the use of a classifier based on Naive
    Bayes, using `MultinomialNB` from the `sklearn.naive_bayes` module. As usual,
    we will divide the original dataset consisting of the spam message archive in
    CSV format, assigning a percentage equal to 30% to the test data subset, and the
    remaining 70% to the training data subset.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 作为结束示例，我们将展示如何使用基于朴素贝叶斯的分类器，采用来自`sklearn.naive_bayes`模块的`MultinomialNB`。和往常一样，我们将把原始数据集（包含CSV格式的垃圾邮件消息存档）划分为测试数据子集和训练数据子集，其中30%为测试数据，70%为训练数据。
- en: The data will be treated with the **bag of words** (**BoW**) technique, which
    assigns a number to each identified word in the text using `CountVectorizer` of `sklearn`,
    to which we will pass the `get_lemmas()` method, which returns the individual
    tokens extracted from the text of the messages.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 数据将采用**词袋模型**（**BoW**）技术处理，该技术使用`sklearn`的`CountVectorizer`为文本中识别的每个单词分配一个编号，并传入`get_lemmas()`方法，该方法返回从消息文本中提取的单个标记。
- en: Finally, we will proceed to normalize and weigh the data using `TfidfTransformer`,
    which transforms a count matrix to a normalized `tf` or `tf-idf` representation.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用`TfidfTransformer`对数据进行标准化和加权，它将计数矩阵转换为标准化的`tf`或`tf-idf`表示。
- en: 'In the scikit-learn documentation for `TfidfTransformer` ([https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)),
    we can find the following:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在scikit-learn文档中关于`TfidfTransformer`的说明（[https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)），我们可以找到如下内容：
- en: '"Tf means term frequency, while tf-idf means term-frequency times inverse document
    frequency. This is a common term weighting scheme in information retrieval that
    has also found good use in document classification. The goal of using tf-idf instead
    of the raw frequencies of occurrence of a token in a given document is to scale
    down the impact of tokens that occur very frequently in a given corpus and that
    are hence empirically less informative than features that occur in a small fraction
    of the training corpus<q>."</q>'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: “Tf 代表词频，而 tf-idf 代表词频与逆文档频率的乘积。这是一种在信息检索中常用的词项加权方案，且在文档分类中也得到了良好的应用。使用 tf-idf
    而非原始的词项在特定文档中出现的频率的目的是缩小那些在给定语料库中频繁出现的词项的影响，这些词项经验上比那些在训练语料库中出现频率较低的特征提供的讯息更少<q>。</q>”
- en: 'Let''s get into the source code:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入源代码：
- en: '[PRE12]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can check if `spam_detector` works well by trying to run a prediction on
    a random message (in our example, we chose the 26^(th) message from the dataset),
    and checking that the detector correctly classifies the type of message (spam
    or ham) by comparing the predicted value with the corresponding `type` label associated
    with the message:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过尝试对一个随机消息进行预测来检查 `spam_detector` 是否正常工作（在我们的示例中，我们选择了数据集中的第26条消息），并通过将预测值与消息的对应
    `type` 标签进行比较，检查检测器是否正确分类了消息类型（垃圾邮件或正常邮件）：
- en: '[PRE13]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'At this point, once the correct functioning has been verified, we proceed to
    the prediction on the whole dataset:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，一旦验证了正确功能，我们就可以对整个数据集进行预测：
- en: '[PRE14]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding commands generate the following output:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 前述命令生成了以下输出：
- en: '![](img/1782eb55-8ee7-4a9c-b80d-23c1110c6e34.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1782eb55-8ee7-4a9c-b80d-23c1110c6e34.png)'
- en: As can be seen in the preceding screenshot, the level of accuracy of Naive Bayes
    is already quite high (equal to 80%) with the advantage, unlike the other algorithms,
    that this accuracy can improve further still as the number of messages analyzed
    increases.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的截图所示，朴素贝叶斯的准确率已经相当高（达到 80%），与其他算法不同的是，随着分析的消息数量增加，这个准确率还可以进一步提高。
- en: Summary
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, several supervised learning algorithms have been explained,
    and we have seen their concrete application in solving common tasks in the field
    of cybersecurity, such as spam detection and phishing detection.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们解释了几种监督学习算法，并展示了它们在解决网络安全领域常见任务中的具体应用，例如垃圾邮件检测和钓鱼邮件检测。
- en: The knowledge acquired in this chapter contributes to forming the right mindset
    to face increasingly complex tasks, such as those we will face in the next chapters,
    leading to a greater awareness of the advantages and disadvantages associated
    with each AI algorithm.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 本章获得的知识有助于培养正确的思维方式，以应对越来越复杂的任务，例如我们将在接下来的章节中面临的任务，从而更清晰地认识到每种 AI 算法的优缺点。
- en: In the next chapter, we will learn about malware analysis and advanced malware
    detection with DL.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习恶意软件分析以及通过深度学习进行高级恶意软件检测。
