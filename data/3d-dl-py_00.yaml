- en: 3D Deep Learning with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《使用Python进行3D深度学习》
- en: Design and develop your computer vision model with 3D data using PyTorch3D and
    more
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyTorch3D及更多工具，设计并开发您的计算机视觉模型，基于3D数据
- en: Xudong Ma
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Xudong Ma
- en: Vishakh Hegde
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Vishakh Hegde
- en: Lilit Yolyan
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Lilit Yolyan
- en: '![](img/Packt_Logo_SuperSite_2022_Orange.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Packt_Logo_SuperSite_2022_Orange.png)'
- en: BIRMINGHAM—MUMBAI
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 伯明翰——孟买
- en: 3D Deep Learning with Python
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《使用Python进行3D深度学习》
- en: Copyright © 2022 Packt Publishing
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 版权所有 © 2022 Packt出版公司
- en: '*All rights reserved*. No part of this book may be reproduced, stored in a
    retrieval system, or transmitted in any form or by any means, without the prior
    written permission of the publisher, except in the case of brief quotations embedded
    in critical articles or reviews.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*保留所有权利*。未经出版商事先书面许可，本书的任何部分不得以任何形式或通过任何手段复制、存储在检索系统中或传输，但在批评性文章或评论中引用短暂的摘录除外。'
- en: Every effort has been made in the preparation of this book to ensure the accuracy
    of the information presented. However, the information contained in this book
    is sold without warranty, either express or implied. Neither the authors, nor
    Packt Publishing or its dealers and distributors, will be held liable for any
    damages caused or alleged to have been caused directly or indirectly by this book.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书在准备过程中已尽力确保所提供信息的准确性。然而，本书中的信息是以无任何明示或暗示的保证出售的。作者、Packt出版公司及其经销商和分销商对于因本书直接或间接引起的任何损害或被声称引起的损害不承担责任。
- en: Packt Publishing has endeavored to provide trademark information about all of
    the companies and products mentioned in this book by the appropriate use of capitals.
    However, Packt Publishing cannot guarantee the accuracy of this information.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Packt出版公司已尽力通过适当的使用大写字母提供关于本书中提到的所有公司和产品的商标信息。然而，Packt出版公司不能保证这些信息的准确性。
- en: '**Publishing Product Manager**: Dinesh Chaudhary'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**出版产品经理**：Dinesh Chaudhary'
- en: '**Content Development Editor**: Joseph Sunil'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**内容开发编辑**：Joseph Sunil'
- en: '**Technical Editor**: Rahul Limbachiya'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**技术编辑**：Rahul Limbachiya'
- en: '**Copy Editor**: Safis Editing'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**文稿编辑**：Safis Editing'
- en: '**Project Coordinator**: Farheen Fathima'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**项目协调员**：Farheen Fathima'
- en: '**Proofreader**: Safis Editing'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**校对员**：Safis Editing'
- en: '**Indexer**: Rekha Nair'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**索引员**：Rekha Nair'
- en: '**Production Designer**: Ponraj Dhandapani'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**制作设计师**：Ponraj Dhandapani'
- en: '**Marketing Coordinator**: Shifa Ansari'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**市场协调员**：Shifa Ansari'
- en: 'First published: November 2022'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首次出版：2022年11月
- en: 'Production reference: 1211022'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 制作参考：1211022
- en: Published by Packt Publishing Ltd.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由Packt出版有限公司出版
- en: Livery Place
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Livery Place
- en: 35 Livery Street
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 35 Livery Street
- en: Birmingham
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 伯明翰
- en: B3 2PB, UK.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 英国B3 2PB。
- en: ISBN 978-1-80324-782-3
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ISBN 978-1-80324-782-3
- en: '[www.packt.com](http://www.packt.com)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.packt.com](http://www.packt.com)'
- en: '"To my wife and family, for their support and encouragement at every step".
    - Vishakh Hegde'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: “献给我的妻子和家人，感谢他们在每一步的支持和鼓励。” - Vishakh Hegde
- en: '"To my family and friends, whose love and support have been my biggest motivation".
    - Lilit Yolyan'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: “献给我的家人和朋友，他们的爱和支持一直是我最大的动力。” - Lilit Yolyan
- en: Contributors
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贡献者
- en: About the author
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于作者
- en: '**Xudong Ma** is a Staff Machine Learning engineer with Grabango Inc. in Berkeley
    California. He was a Senior Machine Learning Engineer at Facebook (Meta) Oculus
    and worked closely with the 3D PyTorch Team on 3D facial tracking projects. He
    has many years of experience working on computer vision, machine learning, and
    deep learning and holds a Ph.D. in Electrical and Computer Engineering.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**Xudong Ma**是Grabango Inc.（位于加利福尼亚伯克利）的工作人员机器学习工程师。他曾是Facebook（Meta）Oculus的高级机器学习工程师，并与3D
    PyTorch团队紧密合作，进行3D面部追踪项目。他在计算机视觉、机器学习和深度学习方面有多年经验，并拥有电气与计算机工程学博士学位。'
- en: '**Vishakh Hegde** is a Machine Learning and Computer Vision researcher. He
    has over 7 years of experience in the field, during which he has authored multiple
    well-cited research papers and published patents. He holds a masters from Stanford
    University specializing in applied mathematics and machine learning, and a BS
    and MS in Physics from IIT Madras. He previously worked at Schlumberger and Matroid.
    He is a Senior Applied Scientist at Ambient.ai, where he helped build their weapon
    detection system which is deployed at several Global Fortune 500 companies. He
    is now leveraging his expertise and passion for solving business challenges to
    build a technology startup in Silicon Valley. You can learn more about him on
    his website.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**Vishakh Hegde**是一名机器学习和计算机视觉研究员。他在该领域拥有超过7年的经验，在此期间，他撰写了多篇广受引用的研究论文并申请了专利。他拥有斯坦福大学应用数学和机器学习专业的硕士学位，以及印度理工学院马德拉斯分校的物理学学士和硕士学位。他曾在Schlumberger和Matroid工作过。他现在是Ambient.ai的高级应用科学家，在那里他帮助构建了武器检测系统，该系统已经在多个全球财富500强公司中部署。他目前正在利用自己的专业知识和解决商业挑战的热情，在硅谷创办技术初创公司。你可以通过他的网站了解更多关于他的内容。'
- en: I would like to thank the computer vision researchers whose breakthrough research
    I got to write about. I want to thank the reviewers for their feedback and the
    wonderful team at Packt Publishing for giving me the chance to be creative. Finally,
    I want to thank my wife and family for all their support and encouragement when
    I most needed it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢那些突破性研究让我有机会撰写的计算机视觉研究人员。我要感谢评审们的反馈，以及Packt Publishing团队给予我创造性发挥的机会。最后，我要感谢我的妻子和家人，在我最需要的时候给予我所有的支持和鼓励。
- en: '**Lilit Yolyan** is a machine learning researcher working on her Ph.D. at YSU.
    Her research focuses on building computer vision solutions for smart cities using
    remote sensing data. She has 5 years of experience in the field of computer vision
    and has worked on a complex driver safety solution to be deployed by many well-known
    car manufacturing companies.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lilit Yolyan**是YSU的机器学习研究员，目前正在攻读博士学位。她的研究重点是利用遥感数据为智慧城市构建计算机视觉解决方案。她在计算机视觉领域有5年的经验，并且参与了一个复杂的驾驶员安全解决方案，该解决方案将由多个知名汽车制造公司部署。'
- en: About the reviewer
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于评审人
- en: '**Eya Abid** is a Masters of Engineering student specializing in Deep Learning
    and Computer Vision. She holds the position of an AI instructor within NVIDIA
    and quantum machine learning at CERN.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**Eya Abid**是一名专攻深度学习和计算机视觉的工程硕士生。她目前担任NVIDIA的AI讲师，以及在CERN从事量子机器学习的工作。'
- en: I would like to dedicate this work first to my family, friends, and whoever
    helped me through this process. A special dedication to Aymen, to whom I am forever
    grateful.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我要将这项工作献给我的家人、朋友以及在这个过程中帮助过我的每一个人。特别献给Aymen，我将永远感激他。
- en: '**Ramesh Sekhar** is the CEO and co-founder of Dapster.ai, a company that builds
    affordable and easily deployable robots that perform the most arduous tasks in
    warehouses. Ramesh has worked at companies like Symbol, Motorola, and Zebra and
    specializes in building products at the intersection of computer vision, AI, and
    Robotics. He has a BS in Electrical Engineering and an MS in Computer Science.
    Ramesh founded Dapster.ai in 2020\. Dapster’s mission is to build robots that
    positively impact human beings by performing dangerous and unhealthy tasks. Their
    vision is to unlock better jobs, fortify supply chains, and better negotiate the
    challenges arising from climate change.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ramesh Sekhar**是Dapster.ai的首席执行官兼联合创始人，这是一家构建可负担且易于部署的机器人公司的企业，这些机器人可以在仓库中执行最繁重的任务。Ramesh曾在Symbol、Motorola和Zebra等公司工作，专注于构建计算机视觉、人工智能和机器人学交汇处的产品。他拥有电气工程学士学位和计算机科学硕士学位。Ramesh于2020年创立了Dapster.ai。Dapster的使命是通过执行危险和不健康的任务来构建对人类产生积极影响的机器人。他们的愿景是解锁更好的工作，强化供应链，并更好地应对气候变化带来的挑战。'
- en: '**Utkarsh Srivastava** is an AI/ML professional, trainer, YouTuber, and blogger.
    He loves to tackle and develop ML, NLP, and computer vision algorithms to solve
    complex problems. He started his data science career as a blogger on his blog
    (datamahadev.com) and YouTube channel (datamahadev), followed by working as a
    senior data science trainer at an institute in Gujarat. Additionally, he has trained
    and counseled 1,000+ working professionals and students in AI/ML. Utkarsh has
    completed 40+ freelance training and development work/projects in data science
    and analytics, AI/ML, Python development, and SQL. He hails from Lucknow and is
    currently settled in Bangalore, India, as an analyst at Deloitte USI Consulting.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**乌特卡什·斯里瓦斯塔瓦**是人工智能/机器学习专业人士、培训师、YouTuber和博主。他热衷于解决复杂问题，开发机器学习、自然语言处理和计算机视觉算法。他的职业生涯始于他的博客（datamahadev.com）和YouTube频道（datamahadev），之后在古吉拉特邦的一所机构担任高级数据科学培训师。此外，他还曾培训并辅导了1,000多名在职专业人士和学生，涵盖人工智能/机器学习领域。乌特卡什已完成40多个自由职业的数据科学与分析、AI/ML、Python开发和SQL培训与开发项目。他来自卢克瑙，目前定居在印度班加罗尔，担任德勤USI咨询公司的分析师。'
- en: I would like to thank my mother, Mrs. Rupam Srivastava, for her continuous guidance
    and support throughout my hardships and struggles. Thanks also to the Supreme
    Para-Brahman.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢我的母亲，Rupam Srivastava女士，在我经历的困难与奋斗中，给予我持续的指导和支持。也感谢至尊Para-Brahman。
- en: '**Mason McGough** is a Sr. R&D Engineer and Computer Vision Specialist at Lowe’s
    Innovation Labs. He has a passion for imaging and has spent over a decade solving
    computer vision problems across a broad range of industrial and academic disciplines
    including geology, bio-informatics, game development, and retail. Most recently
    he is exploring the use of Digital Twins and 3D scanning for retail stores.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**梅森·麦高夫**是Lowe''s创新实验室的高级研发工程师和计算机视觉专家。他对成像充满热情，已经花费超过十年时间解决广泛行业和学术领域中的计算机视觉问题，包括地质学、生物信息学、游戏开发和零售。最近，他正在探索数字双胞胎和3D扫描在零售店中的应用。'
- en: I wish to thank Andy Lykos, Joseph Canzano, Alexander Arango, Oleg Alexander,
    Erin Clark, and my family for their support.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢Andy Lykos、Joseph Canzano、Alexander Arango、Oleg Alexander、Erin Clark以及我的家人对我的支持。
- en: Table of Contents
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '[Preface](B18217_Preface_eBook.xhtml#_idTextAnchor004)'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[前言](B18217_Preface_eBook.xhtml#_idTextAnchor004)'
- en: '[PART 1: 3D Data Processing Basics](B18217_Part_1.xhtml#_idTextAnchor014)'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[第一部分：3D数据处理基础](B18217_Part_1.xhtml#_idTextAnchor014)'
- en: '[1](B18217_01.xhtml#_idTextAnchor015)'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[1](B18217_01.xhtml#_idTextAnchor015)'
- en: '[Introducing 3D Data Processing](B18217_01.xhtml#_idTextAnchor016)'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[介绍3D数据处理](B18217_01.xhtml#_idTextAnchor016)'
- en: '[Technical requirements](B18217_01.xhtml#_idTextAnchor017)'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_01.xhtml#_idTextAnchor017)'
- en: '[Setting up a development environment](B18217_01.xhtml#_idTextAnchor018)'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[设置开发环境](B18217_01.xhtml#_idTextAnchor018)'
- en: '[3D data representation](B18217_01.xhtml#_idTextAnchor019)'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3D数据表示](B18217_01.xhtml#_idTextAnchor019)'
- en: '[Understanding point cloud representation](B18217_01.xhtml#_idTextAnchor020)'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解点云表示](B18217_01.xhtml#_idTextAnchor020)'
- en: '[Understanding mesh representation](B18217_01.xhtml#_idTextAnchor021)'
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解网格表示](B18217_01.xhtml#_idTextAnchor021)'
- en: '[Understanding voxel representation](B18217_01.xhtml#_idTextAnchor022)'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解体素表示](B18217_01.xhtml#_idTextAnchor022)'
- en: '[3D data file format – Ply files](B18217_01.xhtml#_idTextAnchor023)'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3D数据文件格式 – Ply文件](B18217_01.xhtml#_idTextAnchor023)'
- en: '[3D data file format – OBJ files](B18217_01.xhtml#_idTextAnchor025)'
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3D数据文件格式 – OBJ文件](B18217_01.xhtml#_idTextAnchor025)'
- en: '[Understanding 3D coordination systems](B18217_01.xhtml#_idTextAnchor026)'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解3D坐标系统](B18217_01.xhtml#_idTextAnchor026)'
- en: '[Understanding camera models](B18217_01.xhtml#_idTextAnchor027)'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解摄像机模型](B18217_01.xhtml#_idTextAnchor027)'
- en: '[Coding for camera models and coordination systems](B18217_01.xhtml#_idTextAnchor028)'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[摄像机模型和坐标系统的编码](B18217_01.xhtml#_idTextAnchor028)'
- en: '[Summary](B18217_01.xhtml#_idTextAnchor029)'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_01.xhtml#_idTextAnchor029)'
- en: '[2](B18217_02.xhtml#_idTextAnchor030)'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[2](B18217_02.xhtml#_idTextAnchor030)'
- en: '[Introducing 3D Computer Vision and Geometry](B18217_02.xhtml#_idTextAnchor031)'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[介绍3D计算机视觉和几何学](B18217_02.xhtml#_idTextAnchor031)'
- en: '[Technical requirements](B18217_02.xhtml#_idTextAnchor032)'
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_02.xhtml#_idTextAnchor032)'
- en: '[Exploring the basic concepts of rendering, rasterization, and shading](B18217_02.xhtml#_idTextAnchor033)'
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索渲染、光栅化和阴影处理的基本概念](B18217_02.xhtml#_idTextAnchor033)'
- en: '[Understanding barycentric coordinates](B18217_02.xhtml#_idTextAnchor034)'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解重心坐标](B18217_02.xhtml#_idTextAnchor034)'
- en: '[Light source models](B18217_02.xhtml#_idTextAnchor035)'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[光源模型](B18217_02.xhtml#_idTextAnchor035)'
- en: '[Understanding the Lambertian shading model](B18217_02.xhtml#_idTextAnchor036)'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解兰伯特光照模型](B18217_02.xhtml#_idTextAnchor036)'
- en: '[Understanding the Phong lighting model](B18217_02.xhtml#_idTextAnchor037)'
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解 Phong 光照模型](B18217_02.xhtml#_idTextAnchor037)'
- en: '[Coding exercises for 3D rendering](B18217_02.xhtml#_idTextAnchor038)'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3D 渲染的编码练习](B18217_02.xhtml#_idTextAnchor038)'
- en: '[Using PyTorch3D heterogeneous batches and PyTorch optimizers](B18217_02.xhtml#_idTextAnchor039)'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[使用 PyTorch3D 异构批量和 PyTorch 优化器](B18217_02.xhtml#_idTextAnchor039)'
- en: '[A coding exercise for a heterogeneous mini-batch](B18217_02.xhtml#_idTextAnchor040)'
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[异构小批量的编码练习](B18217_02.xhtml#_idTextAnchor040)'
- en: '[Understanding transformations and rotations](B18217_02.xhtml#_idTextAnchor042)'
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解变换与旋转](B18217_02.xhtml#_idTextAnchor042)'
- en: '[A coding exercise for transformation and rotation](B18217_02.xhtml#_idTextAnchor043)'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[变换和旋转的编码练习](B18217_02.xhtml#_idTextAnchor043)'
- en: '[Summary](B18217_02.xhtml#_idTextAnchor044)'
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_02.xhtml#_idTextAnchor044)'
- en: '[PART 2: 3D Deep Learning Using PyTorch3D](B18217_Part_2.xhtml#_idTextAnchor045)'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[第二部分：使用 PyTorch3D 的 3D 深度学习](B18217_Part_2.xhtml#_idTextAnchor045)'
- en: '[3](B18217_03.xhtml#_idTextAnchor046)'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[3](B18217_03.xhtml#_idTextAnchor046)'
- en: '[Fitting Deformable Mesh Models to Raw Point Clouds](B18217_03.xhtml#_idTextAnchor047)'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[将可变形网格模型拟合到原始点云](B18217_03.xhtml#_idTextAnchor047)'
- en: '[Technical requirements](B18217_03.xhtml#_idTextAnchor048)'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_03.xhtml#_idTextAnchor048)'
- en: '[Fitting meshes to point clouds – the problem](B18217_03.xhtml#_idTextAnchor049)'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[将网格拟合到点云——问题](B18217_03.xhtml#_idTextAnchor049)'
- en: '[Formulating a deformable mesh fitting problem into an optimization problem](B18217_03.xhtml#_idTextAnchor050)'
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[将可变形网格拟合问题公式化为优化问题](B18217_03.xhtml#_idTextAnchor050)'
- en: '[Loss functions for regularization](B18217_03.xhtml#_idTextAnchor051)'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[正则化的损失函数](B18217_03.xhtml#_idTextAnchor051)'
- en: '[Mesh Laplacian smoothing loss](B18217_03.xhtml#_idTextAnchor052)'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格拉普拉斯平滑损失](B18217_03.xhtml#_idTextAnchor052)'
- en: '[Mesh normal consistency loss](B18217_03.xhtml#_idTextAnchor053)'
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格法线一致性损失](B18217_03.xhtml#_idTextAnchor053)'
- en: '[Mesh edge loss](B18217_03.xhtml#_idTextAnchor054)'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格边缘损失](B18217_03.xhtml#_idTextAnchor054)'
- en: '[Implementing the mesh fitting with PyTorch3D](B18217_03.xhtml#_idTextAnchor055)'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[实现 PyTorch3D 网格拟合](B18217_03.xhtml#_idTextAnchor055)'
- en: '[The experiment of not using any regularization loss functions](B18217_03.xhtml#_idTextAnchor056)'
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[不使用任何正则化损失函数的实验](B18217_03.xhtml#_idTextAnchor056)'
- en: '[The experiment of using only the mesh edge loss](B18217_03.xhtml#_idTextAnchor057)'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[仅使用网格边缘损失的实验](B18217_03.xhtml#_idTextAnchor057)'
- en: '[Summary](B18217_03.xhtml#_idTextAnchor058)'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_03.xhtml#_idTextAnchor058)'
- en: '[4](B18217_04.xhtml#_idTextAnchor059)'
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[4](B18217_04.xhtml#_idTextAnchor059)'
- en: '[Learning Object Pose Detection and Tracking by Differentiable Rendering](B18217_04.xhtml#_idTextAnchor060)'
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[通过可微分渲染学习物体姿态检测与跟踪](B18217_04.xhtml#_idTextAnchor060)'
- en: '[Technical requirements](B18217_04.xhtml#_idTextAnchor062)'
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_04.xhtml#_idTextAnchor062)'
- en: '[Why we want to have differentiable rendering](B18217_04.xhtml#_idTextAnchor063)'
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[为什么我们希望使用可微分渲染](B18217_04.xhtml#_idTextAnchor063)'
- en: '[How to make rendering differentiable](B18217_04.xhtml#_idTextAnchor064)'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[如何使渲染可微分](B18217_04.xhtml#_idTextAnchor064)'
- en: '[What problems can be solved by using differentiable rendering](B18217_04.xhtml#_idTextAnchor065)'
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[使用可微分渲染可以解决的问题](B18217_04.xhtml#_idTextAnchor065)'
- en: '[The object pose estimation problem](B18217_04.xhtml#_idTextAnchor066)'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[物体姿态估计问题](B18217_04.xhtml#_idTextAnchor066)'
- en: '[How it is coded](B18217_04.xhtml#_idTextAnchor067)'
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[如何编码实现](B18217_04.xhtml#_idTextAnchor067)'
- en: '[An example of object pose estimation for both silhouette fitting and texture
    fitting](B18217_04.xhtml#_idTextAnchor068)'
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[物体姿态估计示例：轮廓拟合和纹理拟合](B18217_04.xhtml#_idTextAnchor068)'
- en: '[Summary](B18217_04.xhtml#_idTextAnchor069)'
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_04.xhtml#_idTextAnchor069)'
- en: '[5](B18217_05.xhtml#_idTextAnchor070)'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[5](B18217_05.xhtml#_idTextAnchor070)'
- en: '[Understanding Differentiable Volumetric Rendering](B18217_05.xhtml#_idTextAnchor071)'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[理解可微分体积渲染](B18217_05.xhtml#_idTextAnchor071)'
- en: '[Technical requirements](B18217_05.xhtml#_idTextAnchor073)'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_05.xhtml#_idTextAnchor073)'
- en: '[Overview of volumetric rendering](B18217_05.xhtml#_idTextAnchor074)'
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[体积渲染概述](B18217_05.xhtml#_idTextAnchor074)'
- en: '[Understanding ray sampling](B18217_05.xhtml#_idTextAnchor075)'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解光线采样](B18217_05.xhtml#_idTextAnchor075)'
- en: '[Using volume sampling](B18217_05.xhtml#_idTextAnchor076)'
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[使用体积采样](B18217_05.xhtml#_idTextAnchor076)'
- en: '[Exploring the ray marcher](B18217_05.xhtml#_idTextAnchor077)'
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索光线行进器](B18217_05.xhtml#_idTextAnchor077)'
- en: '[Differentiable volumetric rendering](B18217_05.xhtml#_idTextAnchor078)'
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[可微分体积渲染](B18217_05.xhtml#_idTextAnchor078)'
- en: '[Reconstructing 3D models from multi-view images](B18217_05.xhtml#_idTextAnchor079)'
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[从多视角图像重建 3D 模型](B18217_05.xhtml#_idTextAnchor079)'
- en: '[Summary](B18217_05.xhtml#_idTextAnchor080)'
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_05.xhtml#_idTextAnchor080)'
- en: '[6](B18217_06.xhtml#_idTextAnchor081)'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[6](B18217_06.xhtml#_idTextAnchor081)'
- en: '[Exploring Neural Radiance Fields (NeRF)](B18217_06.xhtml#_idTextAnchor082)'
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[探索神经辐射场（NeRF）](B18217_06.xhtml#_idTextAnchor082)'
- en: '[Technical requirements](B18217_06.xhtml#_idTextAnchor083)'
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_06.xhtml#_idTextAnchor083)'
- en: '[Understanding NeRF](B18217_06.xhtml#_idTextAnchor084)'
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解NeRF](B18217_06.xhtml#_idTextAnchor084)'
- en: '[What is a radiance field?](B18217_06.xhtml#_idTextAnchor085)'
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[什么是辐射场？](B18217_06.xhtml#_idTextAnchor085)'
- en: '[Representing radiance fields with neural networks](B18217_06.xhtml#_idTextAnchor086)'
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[用神经网络表示辐射场](B18217_06.xhtml#_idTextAnchor086)'
- en: '[Training a NeRF model](B18217_06.xhtml#_idTextAnchor087)'
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[训练NeRF模型](B18217_06.xhtml#_idTextAnchor087)'
- en: '[Understanding the NeRF model architecture](B18217_06.xhtml#_idTextAnchor088)'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解NeRF模型架构](B18217_06.xhtml#_idTextAnchor088)'
- en: '[Understanding volume rendering with radiance fields](B18217_06.xhtml#_idTextAnchor089)'
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解使用辐射场的体积渲染](B18217_06.xhtml#_idTextAnchor089)'
- en: '[Projecting rays into the scene](B18217_06.xhtml#_idTextAnchor090)'
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[将射线投射到场景中](B18217_06.xhtml#_idTextAnchor090)'
- en: '[Accumulating the color of a ray](B18217_06.xhtml#_idTextAnchor091)'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[累积射线的颜色](B18217_06.xhtml#_idTextAnchor091)'
- en: '[Summary](B18217_06.xhtml#_idTextAnchor092)'
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_06.xhtml#_idTextAnchor092)'
- en: '[PART 3: State-of-the-art 3D Deep Learning Using PyTorch3D](B18217_Part_3.xhtml#_idTextAnchor093)'
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[第3部分：使用PyTorch3D的最先进3D深度学习](B18217_Part_3.xhtml#_idTextAnchor093)'
- en: '[7](B18217_07.xhtml#_idTextAnchor094)'
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[7](B18217_07.xhtml#_idTextAnchor094)'
- en: '[Exploring Controllable Neural Feature Fields](B18217_07.xhtml#_idTextAnchor095)'
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[探索可控神经特征场](B18217_07.xhtml#_idTextAnchor095)'
- en: '[Technical requirements](B18217_07.xhtml#_idTextAnchor096)'
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_07.xhtml#_idTextAnchor096)'
- en: '[Understanding GAN-based image synthesis](B18217_07.xhtml#_idTextAnchor097)'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解基于GAN的图像合成](B18217_07.xhtml#_idTextAnchor097)'
- en: '[Introducing compositional 3D-aware image synthesis](B18217_07.xhtml#_idTextAnchor098)'
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[介绍组合式3D感知图像合成](B18217_07.xhtml#_idTextAnchor098)'
- en: '[Generating feature fields](B18217_07.xhtml#_idTextAnchor099)'
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[生成特征场](B18217_07.xhtml#_idTextAnchor099)'
- en: '[Mapping feature fields to images](B18217_07.xhtml#_idTextAnchor100)'
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[将特征场映射到图像](B18217_07.xhtml#_idTextAnchor100)'
- en: '[Exploring controllable scene generation](B18217_07.xhtml#_idTextAnchor101)'
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索可控场景生成](B18217_07.xhtml#_idTextAnchor101)'
- en: '[Exploring controllable car generation](B18217_07.xhtml#_idTextAnchor102)'
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索可控汽车生成](B18217_07.xhtml#_idTextAnchor102)'
- en: '[Exploring controllable face generation](B18217_07.xhtml#_idTextAnchor103)'
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索可控面部生成](B18217_07.xhtml#_idTextAnchor103)'
- en: '[Training the GIRAFFE model](B18217_07.xhtml#_idTextAnchor104)'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[训练GIRAFFE模型](B18217_07.xhtml#_idTextAnchor104)'
- en: '[Frechet Inception Distance](B18217_07.xhtml#_idTextAnchor105)'
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[Frechet起始距离](B18217_07.xhtml#_idTextAnchor105)'
- en: '[Training the model](B18217_07.xhtml#_idTextAnchor106)'
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[训练模型](B18217_07.xhtml#_idTextAnchor106)'
- en: '[Summary](B18217_07.xhtml#_idTextAnchor107)'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_07.xhtml#_idTextAnchor107)'
- en: '[8](B18217_08.xhtml#_idTextAnchor108)'
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[8](B18217_08.xhtml#_idTextAnchor108)'
- en: '[Modeling the Human Body in 3D](B18217_08.xhtml#_idTextAnchor109)'
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[3D人体建模](B18217_08.xhtml#_idTextAnchor109)'
- en: '[Technical requirements](B18217_08.xhtml#_idTextAnchor110)'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_08.xhtml#_idTextAnchor110)'
- en: '[Formulating the 3D modeling problem](B18217_08.xhtml#_idTextAnchor111)'
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[制定3D建模问题](B18217_08.xhtml#_idTextAnchor111)'
- en: '[Defining a good representation](B18217_08.xhtml#_idTextAnchor112)'
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[定义良好的表示](B18217_08.xhtml#_idTextAnchor112)'
- en: '[Understanding the Linear Blend Skinning technique](B18217_08.xhtml#_idTextAnchor113)'
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解线性混合蒙皮技术](B18217_08.xhtml#_idTextAnchor113)'
- en: '[Understanding the SMPL model](B18217_08.xhtml#_idTextAnchor114)'
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[理解SMPL模型](B18217_08.xhtml#_idTextAnchor114)'
- en: '[Defining the SMPL model](B18217_08.xhtml#_idTextAnchor115)'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[定义SMPL模型](B18217_08.xhtml#_idTextAnchor115)'
- en: '[Using the SMPL model](B18217_08.xhtml#_idTextAnchor116)'
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[使用SMPL模型](B18217_08.xhtml#_idTextAnchor116)'
- en: '[Estimating 3D human pose and shape using SMPLify](B18217_08.xhtml#_idTextAnchor118)'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[使用SMPLify估计3D人体姿态和形状](B18217_08.xhtml#_idTextAnchor118)'
- en: '[Defining the optimization objective function](B18217_08.xhtml#_idTextAnchor119)'
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[定义优化目标函数](B18217_08.xhtml#_idTextAnchor119)'
- en: '[Exploring SMPLify](B18217_08.xhtml#_idTextAnchor120)'
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索SMPLify](B18217_08.xhtml#_idTextAnchor120)'
- en: '[Running the code](B18217_08.xhtml#_idTextAnchor121)'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[运行代码](B18217_08.xhtml#_idTextAnchor121)'
- en: '[Exploring the code](B18217_08.xhtml#_idTextAnchor122)'
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[探索代码](B18217_08.xhtml#_idTextAnchor122)'
- en: '[Summary](B18217_08.xhtml#_idTextAnchor123)'
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_08.xhtml#_idTextAnchor123)'
- en: '[9](B18217_09.xhtml#_idTextAnchor124)'
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[9](B18217_09.xhtml#_idTextAnchor124)'
- en: '[Performing End-to-End View Synthesis with SynSin](B18217_09.xhtml#_idTextAnchor125)'
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[使用SynSin进行端到端视图合成](B18217_09.xhtml#_idTextAnchor125)'
- en: '[Technical requirements](B18217_09.xhtml#_idTextAnchor126)'
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_09.xhtml#_idTextAnchor126)'
- en: '[Overview of view synthesis](B18217_09.xhtml#_idTextAnchor127)'
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[视图合成概述](B18217_09.xhtml#_idTextAnchor127)'
- en: '[SynSin network architecture](B18217_09.xhtml#_idTextAnchor128)'
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[SynSin 网络架构](B18217_09.xhtml#_idTextAnchor128)'
- en: '[Spatial feature and depth networks](B18217_09.xhtml#_idTextAnchor129)'
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[空间特征与深度网络](B18217_09.xhtml#_idTextAnchor129)'
- en: '[Neural point cloud renderer](B18217_09.xhtml#_idTextAnchor130)'
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[神经点云渲染器](B18217_09.xhtml#_idTextAnchor130)'
- en: '[Refinement module and discriminator](B18217_09.xhtml#_idTextAnchor131)'
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[细化模块与鉴别器](B18217_09.xhtml#_idTextAnchor131)'
- en: '[Hands-on model training and testing](B18217_09.xhtml#_idTextAnchor132)'
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[实践模型训练与测试](B18217_09.xhtml#_idTextAnchor132)'
- en: '[Summary](B18217_09.xhtml#_idTextAnchor133)'
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_09.xhtml#_idTextAnchor133)'
- en: '[10](B18217_10.xhtml#_idTextAnchor134)'
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[10](B18217_10.xhtml#_idTextAnchor134)'
- en: '[Mesh R-CNN](B18217_10.xhtml#_idTextAnchor135)'
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[Mesh R-CNN](B18217_10.xhtml#_idTextAnchor135)'
- en: '[Technical requirements](B18217_10.xhtml#_idTextAnchor136)'
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_10.xhtml#_idTextAnchor136)'
- en: '[Overview of meshes and voxels](B18217_10.xhtml#_idTextAnchor137)'
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格与体素概述](B18217_10.xhtml#_idTextAnchor137)'
- en: '[Mesh R-CNN architecture](B18217_10.xhtml#_idTextAnchor138)'
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[Mesh R-CNN 架构](B18217_10.xhtml#_idTextAnchor138)'
- en: '[Graph convolutions](B18217_10.xhtml#_idTextAnchor139)'
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[图卷积](B18217_10.xhtml#_idTextAnchor139)'
- en: '[Mesh predictor](B18217_10.xhtml#_idTextAnchor140)'
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格预测器](B18217_10.xhtml#_idTextAnchor140)'
- en: '[Demo of Mesh R-CNN with PyTorch](B18217_10.xhtml#_idTextAnchor141)'
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[PyTorch 下的 Mesh R-CNN 演示](B18217_10.xhtml#_idTextAnchor141)'
- en: '[Demo](B18217_10.xhtml#_idTextAnchor142)'
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[演示](B18217_10.xhtml#_idTextAnchor142)'
- en: '[Summary](B18217_10.xhtml#_idTextAnchor143)'
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_10.xhtml#_idTextAnchor143)'
- en: '[Index](B18217_Index.xhtml#_idTextAnchor144)'
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[索引](B18217_Index.xhtml#_idTextAnchor144)'
- en: '[Other Books You May Enjoy](B18217_BM_eBook.xhtml#_idTextAnchor146)'
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[您可能喜欢的其他书籍](B18217_BM_eBook.xhtml#_idTextAnchor146)'
