- en: '*Chapter 1*: Getting Started with TensorFlow 2.x for Computer Vision'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 1 章*：使用 TensorFlow 2.x 进行计算机视觉入门'
- en: One of the greatest features of TensorFlow 2.x is that it finally incorporates
    Keras as its high-level API. Why is this so important? While it's true that Keras
    and TensorFlow have had very good compatibility for a while, they have remained
    separate libraries with different development cycles, which causes frequent compatibility
    issues. Now that the relationship between these two immensely popular tools is
    official, they'll grow in the same direction, following a single roadmap and making
    the interoperability between them completely seamless. In the end, Keras is TensorFlow
    and TensorFlow is Keras.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 2.x 最棒的特点之一是，它终于将 Keras 纳入了高层 API。这为什么如此重要呢？虽然 Keras 和 TensorFlow
    之间已经有很好的兼容性，但它们依然是独立的库，拥有不同的开发周期，这导致了频繁的兼容性问题。如今，这两个极为流行的工具关系正式确立，它们将朝着同一个方向发展，遵循同一条路线图，实现无缝的互操作性。最终，Keras
    就是 TensorFlow，TensorFlow 也就是 Keras。
- en: Perhaps the biggest advantage of this merger is that by using Keras' high-level
    features, we are not sacrificing performance by any means. Simply put, Keras code
    is production-ready!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 或许这次合并最大的优势就是，通过使用 Keras 的高层功能，我们在性能上丝毫没有妥协。简单来说，Keras 代码已经准备好用于生产！
- en: Unless the requirements of a particular project demand otherwise, in the vast
    majority of the recipes in this book, we'll rely on TensorFlow's Keras API.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 除非某个项目的具体要求另有规定，否则在本书的大多数配方中，我们将依赖 TensorFlow 的 Keras API。
- en: 'The reason behind this decision is twofold:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这一决策背后的原因有两个：
- en: Keras is easier to understand and work with.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 更易于理解和使用。
- en: It's the encouraged way to develop using TensorFlow 2.x.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是使用 TensorFlow 2.x 开发的推荐方式。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下配方：
- en: Working with the basic building blocks of the Keras API
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras API 的基本构建模块
- en: Loading images using the Keras API
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras API 加载图像
- en: Loading images using the tf.data.Dataset API
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 tf.data.Dataset API 加载图像
- en: Saving and loading a model
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存和加载模型
- en: Visualizing a model's architecture
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化模型架构
- en: Creating a basic image classifier
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个基本的图像分类器
- en: Let's get started!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始吧！
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need a working installation of TensorFlow 2.x. If
    you can access a GPU, either physical or via a cloud provider, your experience
    will be much more enjoyable. In each recipe, in the *Getting ready* section, you
    will find the specific preliminary steps and dependencies to complete it. Finally,
    all the code shown in this chapter is available in this book's GitHub repository
    at [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch1](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch1).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章内容，您需要安装并配置好 TensorFlow 2.x。如果能访问到 GPU，无论是物理 GPU 还是通过云服务提供商提供的 GPU，您的体验将更加愉快。在每个配方的
    *准备工作* 部分，您都能找到完成它所需的具体前期步骤和依赖项。最后，本章中所有的代码都可以在本书的 GitHub 仓库中找到，地址为 [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch1](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch1)。
- en: 'Check out the following link to see the Code in Action video:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下链接，观看“代码实战”视频：
- en: '[https://bit.ly/39wkpGN](https://bit.ly/39wkpGN).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/39wkpGN](https://bit.ly/39wkpGN)。'
- en: Working with the basic building blocks of the Keras API
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras API 的基本构建模块
- en: Keras is the official high-level API for TensorFlow 2.x and its use is highly
    encouraged for both experimental and production-ready code. Therefore, in this
    first recipe, we'll review the basic building blocks of Keras by creating a very
    simple fully connected neural network.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 是 TensorFlow 2.x 的官方高层 API，并且强烈建议在实验性和生产级代码中使用。因此，在本配方中，我们将通过创建一个非常简单的全连接神经网络来回顾
    Keras 的基本构建模块。
- en: Are you ready? Let's begin!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好了吗？我们开始吧！
- en: Getting ready
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: At the most basic level, a working installation of TensorFlow 2.x is all you
    need.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本的层面上，安装好 TensorFlow 2.x 就能满足所有需求。
- en: How to do it…
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In the following sections, we''ll go over the sequence of steps required to
    complete this recipe. Let''s get started:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将逐步讲解完成此配方所需的步骤。我们开始吧：
- en: 'Import the required libraries from the Keras API:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Keras API 导入所需的库：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a model using the Sequential API by passing a list of layers to the
    Sequential constructor. The numbers in each layer correspond to the number of
    neurons or units it contains:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Sequential API 创建模型，通过将层列表传递给 Sequential 构造函数。每一层中的数字对应其包含的神经元或单元数：
- en: '[PRE1]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a model using the `add()` method to add one layer at a time. The numbers
    in each layer correspond to the number of neurons or units it contains:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `add()` 方法逐层添加模型。每一层中的数字对应其包含的神经元或单元数：
- en: '[PRE2]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a model using the Functional API. The numbers in each layer correspond
    to the number of neurons or units it contains:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用功能 API 创建模型。每一层中的数字对应其包含的神经元或单元数：
- en: '[PRE3]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create a model using an object-oriented approach by sub-classing `tensorflow.keras.models.Model`.
    The numbers in each layer correspond to the number of neurons or units it contains:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用面向对象的方法，通过子类化 `tensorflow.keras.models.Model` 来创建模型。每一层中的数字对应其包含的神经元或单元数：
- en: '[PRE4]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Prepare the data so that we can train all the models we defined previously.
    We must reshape the images into vector format because that''s the format that''s
    expected by a fully connected network:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据，以便我们可以训练之前定义的所有模型。我们必须将图像重塑为向量格式，因为这是全连接网络所期望的格式：
- en: '[PRE5]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'One-hot encode the labels to break any undesired ordering bias:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对标签进行独热编码，以消除任何不必要的排序偏差：
- en: '[PRE6]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Take 20% of the data for validation:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 20% 的数据用于验证：
- en: '[PRE7]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Compile, train the models for 50 epochs, and evaluate them on the test set:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译、训练这些模型 50 个 epochs，并在测试集上进行评估：
- en: '[PRE8]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After 50 epochs, all three models should have obtained around 98% accuracy on
    the test set.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 50 个 epochs 后，所有三个模型应该在测试集上达到约 98% 的准确率。
- en: How it works…
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理如下…
- en: In the previous section, we went over the basic building blocks we'll need to
    build most deep learning-powered computer vision projects using TensorFlow 2.x.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了构建大多数基于 TensorFlow 2.x 的深度学习计算机视觉项目所需的基本构建模块。
- en: First, we imported the Keras API, the high-level interface for the second version
    of TensorFlow. We learned that all Keras-related functionality is located inside
    the `tensorflow` package.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入了 Keras API，这是 TensorFlow 第二版的高级接口。我们了解到所有与 Keras 相关的功能都位于 `tensorflow`
    包内。
- en: 'Next, we found that TensorFlow 2.x offers great flexibility when it comes to
    defining models. In particular, we have two main APIs we can use to build models:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们发现 TensorFlow 2.x 在定义模型时提供了很大的灵活性。特别是，我们有两个主要的 API 可以用来构建模型：
- en: '**Symbolic**: Also known as the declarative API, it allows us to define a model
    as a **Directed Acyclic Graph (DAG)**, where each layer constitutes a node and
    the interactions or connections between layers are the edges. The pros of this
    API are that you can examine the model by plotting it or printing its architecture;
    compatibility checks are run by the framework, diminishing the probability of
    runtime errors; and if the model compiles, it runs. On the other hand, the main
    con is that it''s not suited for non-DAG architectures (networks with loops),
    such as Tree-LSTMs.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**符号化**：也被称为声明式 API，它允许我们将模型定义为**有向无环图（DAG）**，其中每一层构成一个节点，层之间的交互或连接是边缘。这个 API
    的优点是可以通过绘图或打印其架构来检查模型；框架会运行兼容性检查，减少运行时错误的概率；如果模型编译通过，它就会运行。另一方面，其主要缺点是不适合非 DAG
    架构（具有循环的网络），例如 Tree-LSTMs。'
- en: '**Imperative**: Also known as the **model sub-classing API**, this API is a
    more Pythonic, developer-friendly way of specifying a model. It also allows for
    more flexibility in the forward pass than its symbolic counterpart. The pros of
    this API are that developing models becomes no different than any other object-oriented
    task, which speeds up the process of trying out new ideas; specifying a control
    flow is easy using Python''s built-in constructs; and it''s suited for non-DAG
    architectures, such as Tree-RNNs. In terms of its cons, reusability is lost because
    the architecture is hidden within the class; almost no inter-layer compatibility
    checks are run, thus moving most of the debugging responsibility from the framework
    to the developer; and there''s loss of transparency because information about
    the interconnectedness between layers is not available.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令式**：也称为**模型子类化API**，这种API是一种更符合Python编程习惯、对开发者友好的指定模型方式。与其符号化的对应方式相比，它也允许在前向传播中具有更多的灵活性。该API的优点是，开发模型与其他面向对象任务没有区别，这加快了尝试新想法的速度；使用Python的内置结构指定控制流很容易；它适用于非DAG架构，如树形RNN。缺点是，由于架构隐藏在类内部，复用性降低；几乎不进行层间兼容性检查，因此将大部分调试责任从框架转移到开发者身上；并且由于层之间的相互联系信息不可用，透明性降低。'
- en: We defined the same architecture using both the Sequential and Functional APIs,
    which correspond to the symbolic or declarative way of implementing networks,
    and also a third time using an imperative approach.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了Sequential和Functional API定义了相同的架构，分别对应符号化或声明式的网络实现方式，并且还使用命令式方法定义了第三种方式。
- en: To make it clear that, in the end, the three networks are the same, no matter
    which approach we took, we trained and evaluated them on the famous `MNIST` dataset,
    obtaining a decent 98% accuracy on the test set.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确说明，无论我们采用哪种方法，最终这三种网络是相同的，我们在著名的`MNIST`数据集上进行了训练和评估，最终在测试集上达到了98%的不错准确率。
- en: See also
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'If you''re interested in learning more about Tree-LSTMs, you can read the paper
    where they were first introduced here: https://nlp.stanford.edu/pubs/tai-socher-manning-acl2015.pdf.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对Tree-LSTM（树形LSTM）感兴趣，可以阅读首次介绍它们的论文，点击这里查看：https://nlp.stanford.edu/pubs/tai-socher-manning-acl2015.pdf。
- en: Loading images using the Keras API
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras API加载图像
- en: In this recipe, we will learn how to load images using the Keras API, a very
    important task considering that, in computer vision, we'll always work with visual
    data. In particular, we'll learn how to open, explore, and visualize a single
    image, as well as a batch of them. Additionally, we will learn how to programmatically
    download a dataset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将学习如何使用 Keras API 加载图像，这在计算机视觉中是一个非常重要的任务，因为我们总是需要处理视觉数据。具体来说，我们将学习如何打开、浏览和可视化单张图像，以及一批图像。此外，我们还将学习如何通过编程下载数据集。
- en: Getting ready
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Keras relies on the `Pillow` library to manipulate images. You can install
    it easily using `pip`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Keras依赖于`Pillow`库来处理图像。你可以通过`pip`轻松安装它：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let's get started!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！
- en: How to do it…
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Now, let''s begin this recipe:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始本教程：
- en: 'Import the necessary packages:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE10]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Define the URL and destination of the `CINIC-10` dataset, an alternative to
    the famous `CIFAR-10` dataset:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`CINIC-10`数据集的URL和目标路径，这是著名`CIFAR-10`数据集的替代品：
- en: '[PRE11]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Download and decompress the data. By default, it will be stored in `~/.keras/datasets/<FILE_NAME>`:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并解压数据。默认情况下，它将存储在`~/.keras/datasets/<FILE_NAME>`中：
- en: '[PRE12]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Load all image paths and print the number of images found:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载所有图像路径并打印找到的图像数量：
- en: '[PRE13]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output should be as follows:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE14]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Load a single image from the dataset and print its metadata:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中加载单张图像并打印其元数据：
- en: '[PRE15]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output should be as follows:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE16]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Convert an image into a `NumPy` array:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为`NumPy`数组：
- en: '[PRE17]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here''s the output:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE18]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Display an image using `matplotlib`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`matplotlib`显示图像：
- en: '[PRE19]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This gives us the following image:'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这给我们带来了以下图像：
- en: '![Figure 1.1 – Sample image'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.1 – 示例图像'
- en: '](img/B14768_01_001.jpg)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_01_001.jpg)'
- en: Figure 1.1 – Sample image
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.1 – 示例图像
- en: 'Load a batch of images using `ImageDataGenerator`. As in the previous step,
    each image will be rescaled to the range [0, 1]:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ImageDataGenerator`加载一批图像。与前一步一样，每张图像将被重新缩放到[0, 1]的范围内：
- en: '[PRE20]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Using `image_generator`, we''ll pick and display a random batch of 10 images
    directly from the directory they are stored in:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`image_generator`，我们将从存储图像的目录中直接挑选并显示一批随机的10张图像：
- en: '[PRE21]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The displayed batch is shown here:'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 显示的批次如下所示：
- en: '![Figure 1.2 – Batch of images'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.2 – 图像批次'
- en: '](img/B14768_01_002.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_01_002.jpg)'
- en: Figure 1.2 – Batch of images
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 图像批次
- en: Let's see how it all works.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这一切是如何工作的。
- en: How it works…
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: First, we downloaded a visual dataset with the help of the `get_file()` function,
    which, by default, stores the file with a name of our choosing inside the `~/.keras/datasets`
    directory. If the file already exists in this location, `get_files()` is intelligent
    enough to not download it again.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们借助`get_file()`函数下载了一个视觉数据集，该函数默认将文件存储在我们选择的文件名下，并保存在`~/.keras/datasets`目录中。如果文件已存在于此位置，`get_file()`会智能地避免重新下载。
- en: Next, we decompressed the `CINIC-10` dataset using `untar`. Although these steps
    are not required to load images (we can manually download and decompress a dataset),
    it's often a good idea to automate as many steps as we can.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`untar`解压了`CINIC-10`数据集。尽管这些步骤并非加载图像所必需（我们可以手动下载和解压数据集），但通常将尽可能多的步骤自动化是个好主意。
- en: We then loaded a single image into memory with `load_img()`, a function that
    uses `Pillow` underneath. Because the result of this invocation is in a format
    a neural network won't understand, we transformed it into a `NumPy` array with
    `img_to_array()`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们用`load_img()`加载了一张图像到内存中，这个函数底层使用了`Pillow`库。由于该函数返回的结果格式不是神经网络可以理解的格式，我们使用`img_to_array()`将其转换为`NumPy`数组。
- en: Finally, to load batches of images instead of each one individually, we used
    `ImageDataGenerator`, which had been configured to also normalize each image.
    `ImageDataGenerator` is capable of much more, and we'll often use it whenever
    we want to implement data augmentation, but for this recipe, we only used it to
    load groups of 10 images at a time directly from disk, thanks to the `flow_from_directory()`
    method. As a final remark, this last method returns batches of images and labels,
    but we ignored the latter as we're only interested in the former.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了批量加载图像而不是一个一个地加载，我们使用了`ImageDataGenerator`，它已被配置为同时对每张图像进行归一化处理。`ImageDataGenerator`能够做更多的事情，我们通常会在需要实现数据增强时使用它，但在这个示例中，我们只使用它一次性从磁盘加载10张图像，得益于`flow_from_directory()`方法。最后需要说明的是，尽管这个方法返回的是一批图像和标签，但我们忽略了标签，因为我们只对图像感兴趣。
- en: See also
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'To learn more about processing images with Keras, please consult the official
    documentation here: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image.
    For more information on the `CINIC-10` dataset, visit this link: [https://datashare.is.ed.ac.uk/handle/10283/3192](https://datashare.is.ed.ac.uk/handle/10283/3192).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于使用Keras处理图像的信息，请参考官方文档：https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image。有关`CINIC-10`数据集的更多信息，请访问此链接：[https://datashare.is.ed.ac.uk/handle/10283/3192](https://datashare.is.ed.ac.uk/handle/10283/3192)。
- en: Loading images using the tf.data.Dataset API
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用tf.data.Dataset API加载图像
- en: In this recipe, we will learn how to load images using the `tf.data.Dataset`
    API, one of the most important innovations that TensorFlow 2.x brings. Its functional
    style interface, as well as its high level of optimization, makes it a better
    alternative than the traditional Keras API for large projects, where efficiency
    and performance is a must.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将学习如何使用`tf.data.Dataset` API加载图像，这是TensorFlow 2.x带来的最重要创新之一。其函数式接口以及高效的优化，使其在大规模项目中成为比传统Keras
    API更好的选择，尤其是在效率和性能至关重要的场景下。
- en: In particular, we'll learn how to open, explore, and visualize a single image,
    as well as a batch of them. Additionally, we will learn how to programmatically
    download a dataset.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将学习如何打开、探索和可视化单张图像，以及一批图像。此外，我们还将学习如何通过编程下载数据集。
- en: How to do it…
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: 'Let''s begin this recipe:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始这个示例：
- en: 'First, we need to import all the packages we''ll need for this recipe:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入本示例所需的所有包：
- en: '[PRE22]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define the URL and destination of the `CINIC-10` dataset, an alternative to
    the famous `CIFAR-10` dataset:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`CINIC-10`数据集的URL和存储路径，这是`CIFAR-10`数据集的一个替代品：
- en: '[PRE23]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Download and decompress the data. By default, it will be stored in `~/keras/dataset/<FILE_NAME>`:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并解压数据。默认情况下，它将存储在`~/keras/dataset/<FILE_NAME>`路径下：
- en: '[PRE24]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a dataset of image paths using a glob-like pattern:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用类似glob模式的方式创建图像路径的数据集：
- en: '[PRE25]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Take a single path from the dataset and use it to read the corresponding image:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中获取一个路径，并用它读取相应的图像：
- en: '[PRE26]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Even though the image is now in memory, we must convert it into a format a
    neural network can work with. For this, we must decode it from its PNG format
    into a `NumPy` array, as follows:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管图像现在已经加载到内存中，我们仍然需要将其转换为神经网络可以处理的格式。为此，我们必须将其从PNG格式解码为`NumPy`数组，如下所示：
- en: '[PRE27]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Display the image using `matplotlib`:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`matplotlib`显示图像：
- en: '[PRE28]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here''s the result:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 1.3 – Sample image'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.3 – 示例图像](img/B14768_01_003.jpg)'
- en: '](img/B14768_01_003.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.3 – 示例图像](img/B14768_01_003.jpg)'
- en: Figure 1.3 – Sample image
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.3 – 示例图像
- en: 'Take the first 10 elements of `image_dataset`, decode and normalize them, and
    then display them using `matplotlib`:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取`image_dataset`的前10个元素，解码并归一化它们，然后使用`matplotlib`进行显示：
- en: '[PRE29]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here''s the output:'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 1.4 – Batch of images](img/B14768_01_004.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4 – 图像批次](img/B14768_01_004.jpg)'
- en: Figure 1.4 – Batch of images
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 图像批次
- en: Let's explain this in more detail.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地解释一下。
- en: How it works…
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理……
- en: First, we downloaded the `CINIC-10` dataset using the `get_file()` helper function,
    which saves the fetched file with a name we give it inside the `~/.keras/datasets`
    directory by default. If the file was downloaded before, `get_files()` won't download
    it again.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用`get_file()`辅助函数下载了`CINIC-10`数据集，该函数默认将获取的文件保存在`~/.keras/datasets`目录下，并使用我们指定的文件名。如果文件已经下载过，`get_files()`将不会再次下载。
- en: Because CINIC-10 is compressed, we used `untar` to extract its contents. This
    is certainly not required to execute these steps each time we want to load images,
    given that we can manually download and decompress a dataset, but it's a good
    practice to automate as many steps as possible.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CINIC-10是压缩文件，我们使用`untar`提取了它的内容。当然，每次加载图像时并不需要执行这些步骤，因为我们可以手动下载并解压数据集，但将尽可能多的步骤自动化是一个良好的实践。
- en: To load the images into memory, we created a dataset of their file paths, which
    enabled us to follow almost the same process to display single or multiple images.
    We did this using the path to load the image into memory. Then, we decoded it
    from its source format (PNG, in this recipe), converted it into a `NumPy` array,
    and then pre-processed it as needed.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将图像加载到内存中，我们创建了一个包含其文件路径的数据集，这使得我们几乎可以使用相同的流程来显示单张或多张图像。我们通过路径加载图像到内存，然后将其从源格式（本教程中是PNG）解码，转换为`NumPy`数组，并根据需要进行预处理。
- en: Finally, we took the first 10 images in the dataset and displayed them with
    `matplotlib`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们取了数据集中前10张图像，并使用`matplotlib`进行了显示。
- en: See also
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'If you want to learn more about the `tf.data.Dataset` API, please refer to
    the official documentation here: [https://www.tensorflow.org/api_docs/python/tf/data/Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).
    For more information regarding the CINIC-10 dataset, go to this link: https://datashare.is.ed.ac.uk/handle/10283/3192.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于`tf.data.Dataset` API的内容，请参阅官方文档：[https://www.tensorflow.org/api_docs/python/tf/data/Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)。关于CINIC-10数据集的更多信息，请访问此链接：https://datashare.is.ed.ac.uk/handle/10283/3192。
- en: Saving and loading a model
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存和加载模型
- en: Training a neural network is hard work and time-consuming. That's why retraining
    a model every time is impractical. The good news is that we can save a network
    to disk and load it whenever we need it, whether to improve its performance with
    more training or to use it to make predictions on fresh data. In this recipe,
    we'll learn about different ways to persist a model.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络是一个艰难且耗时的工作。因此，每次都重新训练模型并不实际。好消息是，我们可以将网络保存到磁盘，并在需要时加载，无论是通过更多训练提升其性能，还是用它来对新数据进行预测。在本教程中，我们将学习不同的保存模型的方法。
- en: Let's get started!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到……
- en: 'In this recipe, we''ll train a `mnist` just to illustrate our point. Let''s
    get started:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将训练一个`mnist`模型，仅用于说明我们的观点。让我们开始：
- en: 'Import everything we will need:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入我们需要的所有内容：
- en: '[PRE30]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Define a function that will download and prepare the data by normalizing the
    train and test sets and one-hot encoding the labels:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来下载并准备数据，方法是对训练集和测试集进行归一化，并进行标签的独热编码：
- en: '[PRE31]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Define a function for building a network. The architecture comprises a single
    convolutional layer and two fully connected layers:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个用于构建网络的函数。该架构包含一个卷积层和两个全连接层：
- en: '[PRE32]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Implement a function that will evaluate a network using the test set:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个函数，用来使用测试集评估网络：
- en: '[PRE33]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Prepare the data, create a validation split, and instantiate the neural network:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据，创建验证集，并实例化神经网络：
- en: '[PRE34]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Compile and train the model for 50 epochs, with a batch size of `1024`. Feel
    free to tune these values according to the capacity of your machine:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译并训练模型50个epoch，批次大小为`1024`。根据你机器的性能调整这些值：
- en: '[PRE35]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Save the model, along with its weights, in HDF5 format using the `save()` method.
    Then, load the persisted model using `load_model()` and evaluate the network''s
    performance on the test set:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`save()`方法将模型及其权重以HDF5格式保存。然后，使用`load_model()`加载保存的模型，并评估该网络在测试集上的表现：
- en: '[PRE36]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE37]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Here, we can see that our loaded model obtains 98.36% accuracy on the test set.
    Let's take a look at this in more detail.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到加载的模型在测试集上达到了98.36%的准确率。让我们更详细地看看这个结果。
- en: How it works…
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We just learned how to persist a model to disk and back into memory using TensorFlow's
    2.0 Keras API, which consists of saving both the model and its weights in a single
    `save()` method. Although there are other ways to achieve the same goal, this
    is the preferred and most commonly used method because we can simply restore a
    network to its saved state using the `load_model()` function, and then resume
    training or use it for inference.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚学会了如何使用TensorFlow的2.0 Keras API将模型持久化到磁盘并再加载到内存中，这包括通过单一的`save()`方法保存模型及其权重。虽然还有其他方法可以实现同样的目标，但这是最常用和推荐的方法，因为我们可以通过`load_model()`函数简单地恢复网络的保存状态，然后继续训练或用于推断。
- en: There's more…
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: You can also store the model separately from the weights – the former in `to_json()`
    and `save_weights()`, respectively. The advantage of this approach is that we
    can copy a network with the same architecture from scratch using the `model_from_json()`
    function. The downside, though, is that we need more function calls, and this
    effort is rarely worth it.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以将模型与权重分开存储——分别使用`to_json()`和`save_weights()`。这种方法的优势在于，我们可以通过`model_from_json()`函数从头开始复制一个具有相同架构的网络。然而，缺点是我们需要更多的函数调用，这种做法很少值得采用。
- en: Visualizing a model's architecture
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化模型架构
- en: 'Due to their complexity, one of the most effective ways to debug a neural network
    is by visualizing its architecture. In this recipe, we''ll learn about two different
    ways we can display a model''s architecture:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 由于神经网络的复杂性，调试神经网络最有效的方式之一就是可视化它的架构。在本教程中，我们将学习两种不同的方式来展示模型的架构：
- en: Using a text summary
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用文本摘要
- en: Using a visual diagram
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用视觉图示
- en: Getting ready
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll need both `Pillow` and `pydot` to generate a visual representation of
    a network''s architecture. We can install both libraries using pip, as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`Pillow`和`pydot`来生成网络架构的视觉表示。我们可以通过以下方式使用pip安装这两个库：
- en: '[PRE38]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How to do it…
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Visualizing a model''s architecture is pretty easy, as we''ll learn in the
    following steps:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化模型的架构非常简单，正如我们将在接下来的步骤中所学到的：
- en: 'Import all the required libraries:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必需的库：
- en: '[PRE39]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Implement a model using all the layers we imported in the previous step. Notice
    that we are naming each layer for ease of reference later on. First, let''s define
    the input:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在前一步中导入的所有层来实现一个模型。请注意，我们为方便后续引用给每个层命名。首先，让我们定义输入：
- en: '[PRE40]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Here''s the first convolution block:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是第一个卷积块：
- en: '[PRE41]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here''s the second convolution block:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是第二个卷积块：
- en: '[PRE42]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we''ll define the dense layers and the model itself:'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们将定义密集层和模型本身：
- en: '[PRE43]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Summarize the model by printing a text representation of its architecture,
    as follows:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打印其架构的文本表示来总结模型，如下所示：
- en: '[PRE44]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here''s the summary. The numbers in the **Output Shape** column describe the
    dimensions of the volume produced by that layer, while the number in the **Param
    #** column states the number of parameters in that layer:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是摘要。**输出形状**列中的数字描述了该层生成的体积的维度，而**参数数量**列中的数字则表示该层中的参数数量：
- en: '![Figure 1.5 – Text representation of the network'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.5 – 网络的文本表示'
- en: '](img/B14768_01_005.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_01_005.jpg)'
- en: Figure 1.5 – Text representation of the network
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.5 – 网络的文本表示
- en: The last few lines summarize the number of trainable and non-trainable parameters.
    The more parameters a model has, the harder and slower it is to train.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后几行总结了可训练和不可训练参数的数量。模型的参数越多，训练起来就越困难和缓慢。
- en: 'Plot a diagram of the network''s architecture:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制网络架构的图示：
- en: '[PRE45]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This produces the following output:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会产生以下输出：
- en: '![Figure 1.6 – Visual representation of the network'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6 – 网络的视觉表示'
- en: '](img/B14768_01_006.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_01_006.jpg)'
- en: Figure 1.6 – Visual representation of the network
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 网络的视觉表示
- en: Now, let's learn how this all works.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解这一切是如何工作的。
- en: How it works…
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Visualizing a model is as simple as calling `plot_model()` on the variable that
    holds it. For it to work, however, we must ensure we have the required dependencies
    installed; for instance, `pydot`. Nevertheless, if we want a more detailed summary
    of the number of parameters in our network layer-wise, we must invoke the `summarize()`
    method.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化一个模型就像对包含模型的变量调用`plot_model()`一样简单。然而，为了使其正常工作，我们必须确保已安装所需的依赖项；例如，`pydot`。尽管如此，如果我们希望更详细地总结网络各层的参数数量，我们必须调用`summarize()`方法。
- en: Finally, naming each layer is a good convention to follow. This makes the architecture
    more readable and easier to reuse in the feature because we can simply retrieve
    a layer by its name. One remarkable application of this feature is **neural style
    transfer**.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为每一层命名是一个良好的约定。这使得架构更具可读性，并且在将来更容易重用，因为我们可以通过名称简单地检索某一层。这一特性的一个显著应用是**神经风格迁移**。
- en: Creating a basic image classifier
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个基本的图像分类器
- en: We'll close this chapter by implementing an image classifier on `Fashion-MNIST`,
    a popular alternative to `mnist`. This will help us consolidate the knowledge
    we've acquired from the previous recipes. If, at any point, you need more details
    on a particular step, please refer to the previous recipes.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过在`Fashion-MNIST`数据集上实现一个图像分类器来结束本章，`Fashion-MNIST`是`mnist`的一个流行替代品。这将帮助我们巩固从前面教程中学到的知识。如果在某个步骤中你需要更多的细节，请参考之前的教程。
- en: Getting ready
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'I encourage you to complete the five previous recipes before tackling this
    one since our goal is to come full circle with the lessons we''ve learned throughout
    this chapter. Also, make sure you have `Pillow` and `pydot` on your system. You
    can install them using pip:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你在处理本教程之前先完成前面五个教程，因为我们的目标是通过本章学到的知识形成一个完整的循环。此外，确保你的系统中已经安装了`Pillow`和`pydot`。你可以使用pip安装它们：
- en: '[PRE46]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, we''ll use the `tensorflow_docs` package to plot the loss and accuracy
    curves of the model. You can install this library with the following command:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用`tensorflow_docs`包来绘制模型的损失和准确率曲线。你可以通过以下命令安装这个库：
- en: '[PRE47]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: How to do it…
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Follow these steps to complete this recipe:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本教程：
- en: 'Import the necessary packages:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE48]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Define a function that will load and prepare the dataset. It will normalize
    the data, one-hot encode the labels, take a portion of the training set for validation,
    and wrap the three data subsets into three separate `tf.data.Dataset` instances
    to increase performance using `from_tensor_slices()`:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来加载并准备数据集。它将对数据进行归一化处理，对标签进行独热编码，取部分训练集用于验证，并将三个数据子集包装成三个独立的`tf.data.Dataset`实例，以通过`from_tensor_slices()`提高性能：
- en: '[PRE49]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Implement a function that will build a network similar to `BatchNormalization`,
    which we''ll use to make the network faster and most stable, and `Dropout` layers,
    which will help us combat overfitting, a situation where the network loses generalization
    power due to high variance:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个函数，构建一个类似于`BatchNormalization`的网络，我们将使用它来使网络更快、更稳定；同时也实现`Dropout`层，帮助我们应对过拟合问题，这是由于方差过大导致网络失去泛化能力的情况。
- en: '[PRE50]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Define a function that takes a model''s training history, along with a metric
    of interest, to create a plot corresponding to the training and validation of
    the curves of such a metric:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，该函数接收模型的训练历史记录以及一个感兴趣的度量标准，用于创建对应于训练和验证曲线的图：
- en: '[PRE51]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Consume the training and validation datasets in batches of 256 images at a
    time. The `prefetch()` method spawns a background thread that populates a buffer
    of size `1024` with image batches:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以每次256张图片的批次来消费训练和验证数据集。`prefetch()`方法会启动一个后台线程，填充大小为`1024`的缓冲区，缓存图像批次：
- en: '[PRE52]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Build and train the network:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建并训练网络：
- en: '[PRE53]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Plot the training and validation loss and accuracy:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制训练和验证的损失与准确率：
- en: '[PRE54]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The first graph corresponds to the loss curve both on the training and validation
    sets:'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个图对应训练集和验证集的损失曲线：
- en: '![Figure 1.7 – Loss plot'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.7 – 损失图'
- en: '](img/B14768_01_007.jpg)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_01_007.jpg)'
- en: Figure 1.7 – Loss plot
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.7 – 损失图
- en: 'The second plot shows the accuracy curve for the training and validation sets:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二个图显示了训练和验证集的准确率曲线：
- en: '![Figure 1.8 – Accuracy plot'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.8 – 准确率图'
- en: '](img/B14768_01_008.jpg)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_01_008.jpg)'
- en: Figure 1.8 – Accuracy plot
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.8 – 准确率图
- en: 'Visualize the model''s architecture:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化模型的架构：
- en: '[PRE55]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The following is a diagram of our model:'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是我们模型的示意图：
- en: '![Figure 1.9 – Model architecture'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.9 – 模型架构'
- en: '](img/B14768_01_009.jpg)'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_01_009.jpg)'
- en: Figure 1.9 – Model architecture
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.9 – 模型架构
- en: 'Save the model:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存模型：
- en: '[PRE56]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Load and evaluate the model:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并评估模型：
- en: '[PRE57]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output is as follows:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE58]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: That completes the final recipe of this chapter. Let's review how it all works.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了本章的最终步骤。让我们回顾一下它的全部运作。
- en: How it works…
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we used all the lessons learned in this chapter. We started
    by downloading `Fashion-MNIST` and used the `tf.data.Dataset` API to load its
    images so that we could feed them to our network, which we implemented using the
    declarative Functional high-level Keras API. After fitting our model to the data,
    we examined its performance by reviewing the loss and accuracy curves on the training
    and validation sets with the help of `matplotlib` and `tensorflow_docs`. To gain
    a better understanding of the network, we visualized its architecture with `plot_model()`
    and then saved it to disk, along with its weights, in the convenient HDF5 format.
    Finally, we loaded the model with `load_model()` to evaluate it on new, unseen
    data – that is, the test set – obtaining a respectable 91.3% accuracy rating.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，我们运用了本章中学到的所有教训。我们首先下载了`Fashion-MNIST`，并使用`tf.data.Dataset` API加载其图像，以便将它们馈送到我们使用声明式功能高级
    Keras API 实现的网络中。在将我们的模型拟合到数据之后，我们通过检查在训练和验证集上的损失和准确率曲线来审视其性能，借助`matplotlib`和`tensorflow_docs`。为了更好地理解网络，我们使用`plot_model()`可视化其架构，然后将其以便捷的
    HDF5 格式保存到磁盘上，包括其权重。最后，我们使用`load_model()`加载模型以在新的、未见过的数据上评估它 —— 即测试集 —— 获得了令人满意的
    91.3% 的准确率评分。
- en: See also
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'For a deeper explanation of `Fashion-MNIST`, visit this site: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist).
    The GitHub repository for the TensorFlow docs is available here: [https://github.com/tensorflow/docs](https://github.com/tensorflow/docs).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 欲深入了解`Fashion-MNIST`，请访问此网站：[https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)。TensorFlow
    文档的 GitHub 仓库在此处可用：[https://github.com/tensorflow/docs](https://github.com/tensorflow/docs)。
