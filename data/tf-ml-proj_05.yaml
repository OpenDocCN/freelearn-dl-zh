- en: Speech to Text and Topic Extraction Using NLP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音转文本与主题提取使用自然语言处理
- en: Recognizing and understanding spoken language is a challenging problem due to
    the complexity and variety of speech data. There have been several different technologies
    deployed to recognize spoken words in the past. Most of those approaches were
    very limited in their scope, as they were unable to recognize a wide variety of
    words, accents, and tones, and aspects of spoken language, such as a pause between
    spoken words. Some of the prevalent modeling technique for speech recognition
    include **Hidden Markov Models** (**HMM**), **Dynamic Time Warping** (**DTW**),
    **Long Short-Term Memory Network**s (**LSTM**), and **Connectionist Temporal Classification**
    (**CTC**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语音数据的复杂性和多样性，识别和理解口语语言是一个具有挑战性的问题。过去已经部署了几种不同的技术来识别口语单词。大多数方法的适用范围非常有限，因为它们无法识别各种单词、口音和语调，以及口语语言的某些方面，如单词之间的停顿。一些常见的语音识别建模技术包括**隐马尔可夫模型**（**HMM**）、**动态时间规整**（**DTW**）、**长短期记忆网络**（**LSTM**）和**连接时序分类**（**CTC**）。
- en: 'In this chapter, we shall learn about various options for speech to text and
    the prebuilt model from Google''s TensorFlow team, using the Speech Commands Dataset.
    We shall cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍语音转文本的各种选项，以及 Google 的 TensorFlow 团队使用语音命令数据集的预构建模型。我们将讨论以下主题：
- en: Speech to text frameworks and toolkits
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音转文本框架和工具包
- en: Google Speech Commands Dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 语音命令数据集
- en: CNN based architecture for speech recognition
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于卷积神经网络的语音识别架构
- en: A TensorFlow speech commands example
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 TensorFlow 语音命令示例
- en: Download and follow the code for this chapter from [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并遵循本章的代码：[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/)。
- en: Speech-to-text frameworks and toolkits
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音转文本框架和工具包
- en: 'Many cloud-based AI providers offer speech to text as a service:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基于云的 AI 提供商提供语音转文本作为服务：
- en: 'Amazon''s offering for speech recognition is known as **Amazon Transcribe**.
    Amazon Transcribe allows transcription of the audio files stored in Amazon S3
    in four different formats: `.flac`, `.wav`, `.mp4`, and `.mp3`. It allows an audio
    file with a maximum of two hours in length and 1 GB in size. The results of the
    transcription are created as a JSON file in an Amazon S3 bucket.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊提供的语音识别服务被称为**Amazon Transcribe**。Amazon Transcribe 支持将存储在 Amazon S3 中的音频文件转录为四种不同格式：`.flac`、`.wav`、`.mp4`
    和 `.mp3`。它允许最大长度为两小时，最大大小为 1 GB 的音频文件。转录结果以 JSON 文件格式保存在 Amazon S3 存储桶中。
- en: Google offers speech to text as part of its Google Cloud ML Services. Google
    Cloud Speech to Text supports `FLAC`, `Linear16`, `MULAW`, `AMR`, `AMR_WB`, and
    `OGG_OPUS` file formats.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 将语音转文本作为其 Google Cloud ML 服务的一部分提供。Google Cloud Speech to Text 支持 `FLAC`、`Linear16`、`MULAW`、`AMR`、`AMR_WB`
    和 `OGG_OPUS` 文件格式。
- en: Microsoft offers a speech to text API as part of its Azure Cognitive Services
    platform, known as Speech Service SDK. The Speech Service SDK integrates with
    rest of the Microsoft APIs to transcribe recorded audio. It only allows the WAV
    or PCM file format with a single channel and sample rate of 6 kHz.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软在其 Azure 认知服务平台中提供语音转文本 API，称为语音服务 SDK。语音服务 SDK 与其他 Microsoft API 集成，用于转录录制的音频。它仅支持单声道
    WAV 或 PCM 文件格式，且采样率为 6 kHz。
- en: 'IBM offers a speech to text API as part if its Watson platform. Watson Speech
    to Text supports eight audio formats: BASIC, FLAC, L16, MP3, MULAW, OGG, WAV,
    and WEBM. The maximum size and length of the audio files vary depending on the
    format used. The results of transcription are returned as a JSON file.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IBM 在其 Watson 平台中提供语音转文本 API。Watson Speech to Text 支持八种音频格式：BASIC、FLAC、L16、MP3、MULAW、OGG、WAV
    和 WEBM。音频文件的最大大小和时长根据使用的格式而异。转录结果以 JSON 文件返回。
- en: 'Apart from the support for various international spoken languages and an extensive
    global vocabulary, these cloud services support the following features to different
    extents:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对各种国际口语语言和广泛的全球词汇表的支持外，这些云服务还在不同程度上支持以下功能：
- en: '**Multichannel recognition**: Identifying multiple participants recorded in
    multiple channels'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多通道识别**：识别多个通道中记录的多个参与者'
- en: '**Speaker diarization**: Prediction of speech of a certain speaker'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**说话者分离**：预测特定说话者的语音'
- en: '**Custom models and model selection**: Plug in your own models and select from
    a plethora of pre-built models'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义模型和模型选择**：插入您自己的模型并从大量预构建模型中选择'
- en: Inappropriate content filtering and noise filtering
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不当内容过滤和噪声过滤
- en: There are also many open source toolkits for speech recognition, such as Kaldi.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多用于语音识别的开源工具包，如Kaldi。
- en: Kaldi ([http:/kaldi-asr.org](http:/kaldi-asr.org)) is a popular open source
    speech to text recognition library. It is written in C++ and is available from [https://github.com/kaldi-asr/kaldi](https://github.com/kaldi-asr/kaldi).
    Kaldi can be integrated into your applications using its C++ API. It also supports
    Android using NDK, clang++, and OpenBLAS.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Kaldi ([http:/kaldi-asr.org](http:/kaldi-asr.org)) 是一个流行的开源语音转文本识别库。它是用C++编写的，且可以从[https://github.com/kaldi-asr/kaldi](https://github.com/kaldi-asr/kaldi)获取。Kaldi可以通过其C++
    API集成到您的应用程序中，也支持使用NDK、clang++和OpenBLAS在Android上运行。
- en: Google Speech Commands Dataset
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google语音命令数据集
- en: The Google Speech Commands Dataset was created by the TensorFlow and AIY teams
    to showcase the speech recognition example using the TensorFlow API. The dataset
    has 65,000 clips of one-second-long duration. Each clip contains one of the 30
    different words spoken by thousands of different subjects.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Google语音命令数据集由TensorFlow和AIY团队创建，旨在展示使用TensorFlow API的语音识别示例。该数据集包含65,000个一秒钟长的音频片段，每个片段包含由成千上万的不同发音者所说的30个不同单词之一。
- en: The Google Speech Commands Dataset is available from the following link: [http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz](http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Google语音命令数据集可以从以下链接下载：[http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz](http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz)。
- en: 'The clips were recorded in realistic environments with phones and laptops.
    The 35 words contained noise words and the ten command words most useful in a
    robotics environment, and are listed as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些音频片段是在真实环境中使用手机和笔记本电脑录制的。35个单词包含噪声词，另外10个命令词是机器人环境中最有用的，列举如下：
- en: 'Yes'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的
- en: 'No'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否
- en: Up
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向上
- en: Down
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向下
- en: Left
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向左
- en: Right
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向右
- en: 'On'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向前
- en: 'Off'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关闭
- en: Stop
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止
- en: Go
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续
- en: 'More details on how the speech dataset is prepared can be found in the following
    links:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何准备语音数据集的更多细节，请参见以下链接：
- en: '[https://arxiv.org/pdf/1804.03209.pdf](https://arxiv.org/pdf/1804.03209.pdf)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/pdf/1804.03209.pdf](https://arxiv.org/pdf/1804.03209.pdf)'
- en: '[https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html)'
- en: With this dataset, thus the problem that shown in the example in this chapter
    is known as Keyword Spotting Task.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数据集，因此，本章中的示例问题被称为关键字检测任务。
- en: Neural network architecture
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络架构
- en: 'The network used for this example has three modules:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例使用的网络包含三个模块：
- en: A feature extraction module that processes the audio clips into feature vectors
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个特征提取模块，将音频片段处理为特征向量
- en: A deep neural network module that produces softmax probabilities for each word
    in the input frame of feature vectors
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个深度神经网络模块，为输入特征向量帧中的每个单词生成软最大概率
- en: A posterior handling module that combines the frame-level posterior scores into
    a single score for each keyword
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个后验处理模块，将帧级后验分数合并成每个关键字的单一分数
- en: Feature extraction module
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取模块
- en: In order to make the computation easy, the incoming audio signal is run through
    a voice-activity detection system and the signal is divided into speech and non-speech
    parts of the signals. The voice activity detector uses a 30-component diagonal
    covariance GMM model. The input to this model is 13-dimensional PLP features,
    their deltas, and double deltas. The output of GMM is passed to a State Machine
    that does temporal smoothing.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化计算，传入的音频信号通过语音活动检测系统，信号被划分为语音部分和非语音部分。语音活动检测器使用一个30分量对角协方差GMM模型。该模型的输入是13维PLP特征、其增量和二阶增量。GMM的输出传递给一个状态机进行时间平滑处理。
- en: The output of this GMM-SM module is speech and non-speech parts of the signal.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 该GMM-SM模块的输出是信号中的语音部分和非语音部分。
- en: The speech parts of the signal are further processed to generate the features.
    The acoustic features are generated based on 40-dimensional log-filterbank energies
    computed every 10 ms over a window of 25 ms. 10 Future and 30 Pas frames are added
    to the signal.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 信号中的语音部分进一步处理以生成特征。声学特征基于40维对数滤波器组能量计算，每10毫秒计算一次，窗口为25毫秒。信号中还加入了10个未来帧和30个过去帧。
- en: More details on feature extractor can be obtained from the original papers,
    links provided in the further readings section.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 关于特征提取器的更多细节可以从原始论文中获得，相关链接在进一步阅读部分提供。
- en: Deep neural network module
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络模块
- en: The DNN module is implemented with the Convolutional Neural Network (CNN) architecture.
    The code implements multiple variations of ConvNet, each variation producing different
    levels of accuracy and taking a different amount of time to train.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: DNN 模块是使用卷积神经网络（CNN）架构实现的。代码实现了多种不同变体的 ConvNet，每个变体产生不同的准确度，并且训练所需的时间不同。
- en: 'The code for building the model is provided in the `models.py` file. It allows
    the creation of four different models, depending on the parameter passed at the
    command line:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 构建模型的代码提供在 `models.py` 文件中。它允许根据命令行传递的参数创建四种不同的模型：
- en: '`single_fc`: This model has only one fully connected layer.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`single_fc`：该模型仅有一个全连接层。'
- en: '`conv`: This model is a full CNN architecture with two pairs of Convolution
    and MaxPool layers, followed by a fully connected layer.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conv`：该模型是一个完整的 CNN 架构，包含两对卷积层和最大池化层，后跟一个全连接层。'
- en: '`low_latency_conv`: This model has one convolutional layer, followed by three
    fully connected layers. As the name suggests, it has a lesser number of parameters
    and computations compared with the `conv` architecture.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_latency_conv`：该模型有一个卷积层，后面跟着三个全连接层。顾名思义，与 `conv` 架构相比，它的参数和计算量较少。'
- en: '`low_latency_svdf`: This model follows the architecture and layers from the
    paper titled *Compressing Deep Neural*'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`low_latency_svdf`：该模型遵循论文《*压缩深度神经网络*》中的架构和层。'
- en: '*Networks using a Rank-Constrained Topology* available from [https://research.google.com/pubs/archive/43813.pdf](https://research.google.com/pubs/archive/43813.pdf).'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*使用秩约束拓扑的网络* 可从 [https://research.google.com/pubs/archive/43813.pdf](https://research.google.com/pubs/archive/43813.pdf)
    获得。'
- en: '`tiny_conv`: This model has only one convolutional and one fully connected
    layer.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tiny_conv`：该模型只有一个卷积层和一个全连接层。'
- en: 'The default architecture is `conv`, if the architecture is not passed from
    the command line. In our runs, the architectures showed the following accuracies
    for training, validation, and test sets when running the models with default accuracy
    and default number of steps of 18,000:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果命令行未传递架构，则默认架构为 `conv`。在我们的运行中，架构在使用默认准确率和默认步数 18,000 训练模型时，显示了以下训练、验证和测试集的准确率：
- en: '| Architecture | Accuracy (in %) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 架构 | 准确率（%） |'
- en: '| Train set | Validation set | Test set |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 训练集 | 验证集 | 测试集 |'
- en: '| `conv` (default) | 90 | 88.5 | 87.7 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `conv`（默认） | 90 | 88.5 | 87.7 |'
- en: '| `single_fc` | 50 | 48.5 | 48.2 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `single_fc` | 50 | 48.5 | 48.2 |'
- en: '| `low_latenxy_conv` | 22 | 21.6 | 23.6 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| `low_latenxy_conv` | 22 | 21.6 | 23.6 |'
- en: '| `low_latency_svdf` | 7 | 8.9 | 8.6 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `low_latency_svdf` | 7 | 8.9 | 8.6 |'
- en: '| `tiny_conv` | 55 | 65.7 | 65.4 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `tiny_conv` | 55 | 65.7 | 65.4 |'
- en: Since the network architecture uses CNN layers that are more suitable for image
    data, the speech files are converted to a single-channel image by converting the
    audio signal of a short segment into vectors of frequency strengths.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 由于网络架构使用的是更适合图像数据的 CNN 层，因此语音文件通过将短时间段的音频信号转换为频率强度的向量，转化为单通道图像。
- en: As we can see from the preceding observations, the shortened architectures give
    lower accuracy for same hyper-parameters, but they run faster. Hence, they can
    be run for a higher number of epochs, or the learning rate could be increased
    to get higher accuracy.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的观察可以看出，缩短的架构在相同超参数下给出的准确率较低，但运行速度更快。因此，可以运行更多的迭代轮次，或者可以增加学习率以获得更高的准确率。
- en: Now let's see how to train and use this model.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下如何训练和使用这个模型。
- en: Training the model
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'Move to the folder where you cloned the code from the repository, and train
    the model with the following command:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动到从仓库克隆代码的文件夹，并使用以下命令训练模型：
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You will start seeing the output of the training as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你将开始看到训练的输出，如下所示：
- en: '[PRE1]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the training iterations start, the code prints out the learning rate,
    along with accuracy and the cross entropy loss on the training set, as follows:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦训练迭代开始，代码会打印出学习率、训练集的准确率以及交叉熵损失，如下所示：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The code also keeps saving the model every 100 steps, so that if training is
    interrupted, then it can be restarted from the latest checkpoint saved:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码还会每 100 步保存一次模型，因此如果训练中断，可以从最近的检查点重新开始：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The training runs for several hours for 18,000 steps and at the end prints
    the final training learning rate, accuracy, loss, and confusion matrix as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 训练运行了几个小时，共 18,000 步，最终会打印出最终的训练学习率、准确度、损失和混淆矩阵，如下所示：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: One observation from this output is that, although the code starts with a learning
    rate of 0.001, it reduces the learning rate to 0.001 towards the end. Since there
    are 12 command words, it also prints out a 12 x 12 confusion matrix.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以观察到，尽管代码一开始的学习率为 0.001，但它在训练结束时将学习率降低到 0.001。由于有 12 个命令词，它还会输出一个 12 x
    12 的混淆矩阵。
- en: 'The code also prints the accuracy and confusion matrix on the validation set
    as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 代码还会打印验证集的准确度和混淆矩阵，如下所示：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, the code prints the test set accuracy as follows:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，代码打印出测试集的准确度，如下所示：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: That's it. The model has been trained and can be exported for serving through
    TensorFlow, or embedding in another desktop, web, or mobile app.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。模型已经训练完成，可以通过 TensorFlow 导出并用于服务，或者嵌入到其他桌面、Web 或移动应用中。
- en: Summary
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about a project for converting audio data to text.
    There are many open source SDKs and commercial paid cloud services that allow
    us to convert from audio recordings and files to text data. As an example project,
    we took Google's Speech Commands Dataset and TensorFlow's deep learning-based
    example to convert audio files to spoken words in order to recognize the commands.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了一个将音频数据转为文本的项目。现在有许多开源 SDK 和商业付费云服务，可以将音频记录和文件转换为文本数据。作为示例项目，我们使用了
    Google 的语音命令数据集和 TensorFlow 基于深度学习的示例，将音频文件转换为语音命令进行识别。
- en: In the next chapter, we continue this journey to build a project for predicting
    stock prices using Gaussian Processes, which is a popular algorithm for forecasting.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将继续这个旅程，构建一个使用高斯过程预测股票价格的项目，这是一个广泛用于预测的算法。
- en: Questions
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the interpretation of the confusion matrix provided at the end of the
    training?
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混淆矩阵在训练结束时的解释是什么？
- en: Create a dataset of your own recorded voices with your friends and family members.
    Run the model on this data and observe what the accuracy is.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个你和家人朋友录制的声音数据集。使用这个数据运行模型并观察准确率如何。
- en: Retrain the model on your own dataset and check the accuracy for your own train,
    validation and test sets.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你自己的数据集上重新训练模型，并检查你自己训练、验证和测试集的准确度。
- en: Experiment with different options from train.py and share your findings in a
    blog.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试修改 `train.py` 中的不同选项，并在博客中分享你的发现。
- en: Add different architectures to the models.py file and see if you can create
    a better architecture for the speech dataset or your own recorded dataset.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向 `models.py` 文件中添加不同的架构，看看你是否能为语音数据集或自己录制的数据集创建一个更好的架构。
- en: Further reading
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The following links are helpful in learning more about speech to text:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接有助于深入了解语音转文本：
- en: '[https://arxiv.org/pdf/1804.03209.pdf](https://arxiv.org/pdf/1804.03209.pdf)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/pdf/1804.03209.pdf](https://arxiv.org/pdf/1804.03209.pdf)'
- en: '[https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html](https://arxiv.org/pdf/1804.03209.pdf)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html](https://arxiv.org/pdf/1804.03209.pdf)'
- en: '[https://research.google.com/pubs/archive/43813.pdf](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://research.google.com/pubs/archive/43813.pdf](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html)'
- en: '[https://cloud.google.com/speech-to-text/docs/](https://research.google.com/pubs/archive/43813.pdf)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/speech-to-text/docs/](https://research.google.com/pubs/archive/43813.pdf)'
- en: '[https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html](https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html](https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html)'
- en: '[https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/](https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/](https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html)'
- en: '[https://nlp.stanford.edu/projects/speech.shtml](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://nlp.stanford.edu/projects/speech.shtml](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/)'
