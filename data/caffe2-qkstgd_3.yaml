- en: Training Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练网络
- en: In [Chapter 2](270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml), *Composing Networks*,
    we learned how to create Caffe2 operators and how we can compose networks from
    them. In this chapter, the focus is on training neural networks. We will learn
    how to create a network that is intended for training and how to train it using
    Caffe2\. We will continue to use the MNIST dataset as an example. However, instead
    of the MLP network we built in the previous chapter, we will create a popular
    network named LeNet.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 2 章](270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml)，*构建网络*中，我们学习了如何创建 Caffe2
    操作符，以及如何利用它们构建网络。在本章中，我们将重点介绍神经网络的训练。我们将学习如何创建一个用于训练的网络，并使用 Caffe2 进行训练。我们将继续使用
    MNIST 数据集作为示例。然而，与上一章中构建的 MLP 网络不同，我们将在本章创建一个名为 LeNet 的流行网络。
- en: 'This chapter will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to training a neural network
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络训练简介
- en: Building the training network for LeNet
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建 LeNet 的训练网络
- en: Training and monitoring the LeNet network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和监控 LeNet 网络
- en: Introduction to training
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练简介
- en: In this section, we provide a brief overview of how a neural network is trained.
    This will help us to understand the later sections where we use Caffe2 to actually
    train a network.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将简要概述神经网络的训练过程。这将帮助我们理解后续章节中如何使用 Caffe2 实际训练网络。
- en: Components of a neural network
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的组件
- en: We employ neural networks to solve a particular type of problem for which devising
    a computer algorithm would be onerous or difficult. For example, in the MNIST
    problem (introduced in [Chapter 2](270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml),
    *Composing Networks*), handcrafting a complicated algorithm to detect the common
    stroke patterns for each digit, and thereby determining each digit, would be tedious.
    Instead, it is easier to design a neural network suited to this problem and then
    train it (as shown later in this chapter) using a lot of data to do the same.
    If the training data is diverse and the training is done carefully, such a network
    would also be far more robust to variations in the input data than any deterministic
    handcrafted algorithm would.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用神经网络来解决某些类型的问题，对于这些问题，设计计算机算法将会非常繁琐或困难。例如，在 MNIST 问题中（在[第 2 章](270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml)，*构建网络*中介绍），手工设计一个复杂的算法来检测每个数字的常见笔画模式，并据此确定每个数字，将会非常繁琐。相反，设计一个适合该问题的神经网络，然后使用大量数据对其进行训练（如本章后面所示）来实现这一目标，会更为简单。如果训练数据多样且训练过程谨慎，这样的网络在处理输入数据的变化时也会比任何确定性的手工算法更加健壮。
- en: 'A neural network has two main components: its structure and its weights. We
    typically design the network structure and then use a training algorithm and training
    data to determine the weights. After it is trained, the network structure, with
    its embedded weights, can be used for inference on new unseen data, as shown in
    the following diagram:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络有两个主要组件：其结构和权重。我们通常先设计网络结构，然后使用训练算法和训练数据来确定权重。经过训练后，网络结构及其嵌入的权重可以用于对新的未见过的数据进行推理，如下图所示：
- en: '![](img/990caef5-f3af-4b7d-871a-f26df03aeb66.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/990caef5-f3af-4b7d-871a-f26df03aeb66.png)'
- en: 'Figure 3.1: Structure and weights of a network used for inference'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：用于推理的网络结构和权重
- en: Structure of a neural network
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的结构
- en: The structure of a network is the series of its layers, their types, and their
    configurations. The structure is typically devised by a researcher or a practitioner
    familiar with the problem that the neural network is being designed to solve.
    For example, to solve image classification problems, computer vision researchers
    might typically use a series of convolution layers in the network. (We will learn
    about the convolution layer later in this chapter.) Various configuration parameters
    of each layer also need to be determined beforehand, such as the size and number
    of the convolution filters in a convolution layer. There is a huge amount of interest
    in using deep learning itself to ascertain the structure of a network suited to
    a particular problem. However, discussion of this meta-learning topic is beyond
    the scope of this book.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的结构是各层的系列、它们的类型和配置。这个结构通常由研究人员或熟悉神经网络所要解决问题的实践者设计。例如，为了解决图像分类问题，计算机视觉研究人员通常会在网络中使用一系列卷积层。（我们将在本章稍后学习卷积层。）每层的各种配置参数也需要事先确定，比如卷积层中卷积滤波器的大小和数量。现在有很多兴趣将深度学习本身用于确定适合特定问题的网络结构。然而，关于这个元学习主题的讨论超出了本书的范围。
- en: Weights of a neural network
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的权重
- en: The second component of a network is its weights and biases. We generally refer
    to them together as **weights**, or sometimes as **parameters**. These are the
    floating point values that are the parameters of every layer in the network. How
    the weights of a layer are used is determined by the type of layer. For example,
    in a fully connected layer, a bigger weight value might signify a stronger correlation
    between an input signal and the network's output. In a convolution layer, the
    weights of a convolution filter might signify what type of pattern or shape in
    the input it is looking for.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的第二个组成部分是它的权重和偏置。我们通常将它们统称为**权重**，有时也称为**参数**。这些是网络中每一层的浮点值参数。每一层的权重如何使用取决于层的类型。例如，在全连接层中，较大的权重值可能表示输入信号和网络输出之间的更强相关性。在卷积层中，卷积滤波器的权重可能表示它在输入中寻找的特定模式或形状。
- en: In summary, we sit down and devise the structure of a network to solve a particular
    problem. Our choices in this process will be limited by our understanding of the
    problem space, the types of layers available in the DL framework, the hardware
    constraints of the accelerator we are using, and how much training time we are
    prepared to put up with. For example, the memory available in a GPU or CPU might
    limit the number of weights we might use in a layer or the number of layers we
    might use in the network. The amount of training time we are willing to spend
    also limits the number of weights and layers we can use in a network, because
    the more of these we employ, the longer it may take for the network to converge
    and train.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们坐下来设计一个网络的结构以解决特定问题。这个过程中我们的选择将受到对问题空间的理解、深度学习框架中可用的层类型、我们使用的加速器的硬件限制，以及我们愿意花费多少训练时间的限制。例如，GPU
    或 CPU 中可用的内存可能会限制我们在一层中使用的权重数量或网络中使用的层数。我们愿意花费的训练时间也限制了我们可以在网络中使用的权重和层的数量，因为使用越多的权重和层，网络收敛和训练的时间可能会越长。
- en: Training process
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练过程
- en: 'Once we have a network structure fleshed out, we can then use a DL framework
    such as Caffe2 to describe that structure. We then apply one of the many training
    algorithms available in the framework on our training data. This trains the network
    and learns the weights of the layers that would best amplify the signal and dampen
    the noise. This process is depicted in Figure 3.2:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们构建了一个网络结构，我们就可以使用像 Caffe2 这样的深度学习框架来描述该结构。然后，我们在训练数据上应用框架中可用的多种训练算法之一。这将训练网络并学习每一层的权重，以最佳方式放大信号并抑制噪声。这个过程如图
    3.2 所示：
- en: '![](img/1286ef22-d6f7-41aa-b550-43778aff6980.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1286ef22-d6f7-41aa-b550-43778aff6980.png)'
- en: 'Figure 3.2: Training is the process of learning the weights of a neural network
    using a training algorithm and data'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：训练是使用训练算法和数据学习神经网络权重的过程
- en: 'Neural networks are typically trained using a gradient-based optimization algorithm.
    To do this, we first define an **objective function** or **loss function** for
    the network. This function computes a loss or error value by comparing the output
    of the network on a given input to the ground truth result of that input. The
    training process iteratively picks training data and computes its loss, and then
    uses the optimization algorithm to update the weights so that the error is reduced.
    This process is repeated until we see no further improvement in the accuracy of
    the network:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通常使用基于梯度的优化算法进行训练。为此，我们首先为网络定义一个**目标函数**或**损失函数**。该函数通过将网络在给定输入上的输出与该输入的真实结果进行比较，从而计算出损失或误差值。训练过程迭代地选择训练数据并计算其损失，然后使用优化算法更新权重，以减少误差。这个过程会不断重复，直到我们看到网络准确率没有进一步提高为止：
- en: '![](img/6d3af34c-bebe-4b12-910d-1a905be35517.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d3af34c-bebe-4b12-910d-1a905be35517.png)'
- en: 'Figure 3.3: Three stages of an iteration in training'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：训练中迭代的三个阶段
- en: A single iteration of the training process is depicted in *Figure 3.3*. We can
    see that it has three distinct stages. The first stage is a **Forward pass**,
    where we essentially perform inference of the network with its current weights
    to obtain the result or hypothesis of the network. In the second stage, we compute
    the loss of the network using a loss function. The third stage is a **Backward
    pass**, where we use an algorithm called backpropagation to update the weights
    of the network.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程的单次迭代如*图 3.3*所示。我们可以看到，它有三个不同的阶段。第一阶段是**前向传播**，在这一阶段，我们基本上使用当前权重对网络进行推理，以获得网络的结果或假设。第二阶段，我们使用损失函数计算网络的损失。第三阶段是**反向传播**，我们使用一种叫做反向传播（backpropagation）的算法来更新网络的权重。
- en: Gradient descent variants
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降的变体
- en: There are commonly three variants of gradient descent we can employ to sample
    the training data used in every iteration of training. If we use the entire training
    dataset in each iteration, this process is called **batch gradient descent**.
    If we use one randomly chosen sample of the training data in each iteration, then
    the process is called **stochastic gradient descent**. The variant that is most
    commonly used is **mini-batch gradient descent**, where we use a randomly chosen
    subset of the training data in each iteration. For best results, this is done
    by shuffling the training data, and then dividing it into mini-batches used in
    each iteration. After we are finished with one run through the training data,
    called an **epoch**, we shuffle and divide again into batches and continue.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常可以使用三种梯度下降的变体来采样每次训练迭代中使用的训练数据。如果每次迭代都使用整个训练数据集，这个过程叫做**批量梯度下降**。如果每次迭代都只使用一个随机选择的训练样本，那么这个过程叫做**随机梯度下降**。最常用的变体是**小批量梯度下降**，即每次迭代时使用一个随机选择的训练数据子集。为了获得最佳结果，我们会将训练数据打乱，然后将其划分为小批量，每次迭代使用一个小批量。完成一次训练数据的处理后，我们称之为**一个周期（epoch）**，然后再一次打乱并重新划分成小批量，继续训练。
- en: In the remainder of this chapter, we will learn about the LeNet network that
    can be used for MNIST, how to build it, and how to use it for training using Caffe2.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将学习可以用于 MNIST 的 LeNet 网络，如何构建它，以及如何使用 Caffe2 进行训练。
- en: LeNet network
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LeNet 网络
- en: 'In [Chapter](270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml) 2, *Composing Networks*,
    we built an MLP network that was composed of multiple pairs of fully connected
    layers and activation layers. In this chapter, we will build and train a **convolutional
    neural network** (**CNN**). This type of network is so named because it primarily
    uses convolution layers (introduced in the next section). For computer vision
    problems, CNNs have been shown to deliver better results with fewer numbers of
    parameters compared to MLPs. One of the first successful CNNs was used to solve
    the MNIST problem that we looked at earlier. This network, named **LeNet-5**,
    was created by Yann LeCun and his colleagues:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](270a3617-74cd-4e64-98f7-eb0c4e3cbcf6.xhtml)，*构建网络*中，我们构建了一个由多个全连接层和激活层对组成的
    MLP 网络。在本章中，我们将构建并训练一个**卷积神经网络**（**CNN**）。这种类型的网络之所以得名，是因为它主要使用卷积层（将在下一节介绍）。对于计算机视觉问题，CNN
    相比 MLP 已经证明可以用更少的参数提供更好的结果。最早成功的 CNN 之一被用来解决我们之前提到的 MNIST 问题。这个名为**LeNet-5**的网络是由
    Yann LeCun 及其同事创建的：
- en: '![](img/b8d74f04-007f-4288-a8c2-7f2c537fd2a4.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8d74f04-007f-4288-a8c2-7f2c537fd2a4.png)'
- en: 'Figure 3.4: Structure of our LeNet model'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：我们 LeNet 模型的结构
- en: We will construct a network similar in spirit to the LeNet. We will refer to
    this as the LeNet model in the remainder of this book. From *Figure 3.4*, we can
    see that our LeNet network has eight layers. After the input layer, there are
    two pairs of convolution layers and pooling layers. They are followed by a pair
    of fully connected and ReLU activation layers and another fully connected layer.
    A final SoftMax layer is used to obtain the MNIST classification result.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个与 LeNet 精神相似的网络。我们将在本书余下部分中称之为 LeNet 模型。从 *图 3.4* 中可以看到，我们的 LeNet 网络有八层。输入层之后，有两对卷积层和池化层。它们之后是一个全连接层和
    ReLU 激活层的对，接着是另一个全连接层。最后使用 SoftMax 层来获得 MNIST 分类结果。
- en: 'We next look at two new layers that are important in CNNs and are part of LeNet:
    convolution and pooling.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍 CNN 中两个重要的层，它们是 LeNet 的一部分：卷积层和池化层。
- en: Convolution layer
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: 'The *convolution layer* is the most important layer in neural networks that
    are used to solve computer vision problems, involving images and video. The input
    tensor to a convolution layer has at least three dimensions in its size: ![](img/0cfc418c-1293-4fde-b975-479b21fcecb4.png).
    That is, the input has ![](img/c945c225-fbf5-4062-92f5-6224033d66a8.png) channels,
    each channel being a 2D matrix of height ![](img/6c535cec-90bc-4514-a283-f594567d32b5.png)
    and width ![](img/85b6c19e-b58c-4b0b-8e2f-ee6cc2ef4aa4.png). This follows naturally
    from the layout of images. For example, an RGB image has three channels, each
    channel of a certain height and width.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*卷积层* 是神经网络中最重要的一层，用于解决涉及图像和视频的计算机视觉问题。卷积层的输入张量至少具有三个维度：![](img/0cfc418c-1293-4fde-b975-479b21fcecb4.png)。也就是说，输入有
    ![](img/c945c225-fbf5-4062-92f5-6224033d66a8.png) 个通道，每个通道都是一个高度为 ![](img/6c535cec-90bc-4514-a283-f594567d32b5.png)
    和宽度为 ![](img/85b6c19e-b58c-4b0b-8e2f-ee6cc2ef4aa4.png) 的 2D 矩阵。这自然符合图像的布局。例如，RGB
    图像有三个通道，每个通道具有一定的高度和宽度。'
- en: 'When we refer to **convolution**, we generally mean **2-dimensional** (**2D**)
    convolution. A 2D convolution layer has two sets of parameters that are learned
    during training: filter parameters and bias parameters.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们提到 **卷积** 时，通常指的是 **2维** (**2D**) 卷积。一个 2D 卷积层有两组在训练过程中学习的参数：滤波器参数和偏置参数。
- en: The first set of parameters associated with a 2D convolution layer is ![](img/b00de931-2ab9-49a4-9a24-ef12fc601b8c.png)
    filters. Each **filter** or **kernel** is a **3-dimensional** (**3D**) tensor
    of shape ![](img/68dde4f0-a566-4cc2-8023-f7cb583b9038.png) holding floating point
    values that were learned during training. So, the total number of filter parameters
    that need to be learned during training for a 2D convolution layer is ![](img/a73b1f10-003e-47d0-bea6-7577d4814c77.png).
    Note how a kernel of a 2D convolution layer has the same number of channels, ![](img/35e85920-9ccd-4bf8-8464-8685609f987d.png),
    as the input to the layer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与 2D 卷积层相关的第一组参数是 ![](img/b00de931-2ab9-49a4-9a24-ef12fc601b8c.png) 滤波器。每个 **滤波器**
    或 **卷积核** 都是一个 **3维** (**3D**) 张量，形状为 ![](img/68dde4f0-a566-4cc2-8023-f7cb583b9038.png)，包含在训练过程中学习到的浮点值。因此，对于一个
    2D 卷积层，在训练过程中需要学习的滤波器参数总数为 ![](img/a73b1f10-003e-47d0-bea6-7577d4814c77.png)。请注意，2D
    卷积层的卷积核与层的输入具有相同的通道数 ![](img/35e85920-9ccd-4bf8-8464-8685609f987d.png)。
- en: The second set of parameters associated with a 2D convolution layer are ![](img/a845ffeb-7a17-457a-a671-414b043747aa.png)
    bias values, each value being associated with each of the ![](img/55ff6eb5-7ff4-456d-9e9e-bd2ababe2676.png)
    filters described previously.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与 2D 卷积层相关的第二组参数是 ![](img/a845ffeb-7a17-457a-a671-414b043747aa.png) 偏置值，每个偏置值与之前描述的
    ![](img/55ff6eb5-7ff4-456d-9e9e-bd2ababe2676.png) 个滤波器相关。
- en: 'During convolution, each of the ![](img/0b647453-d81b-4a4d-bcd3-c3d3555d652a.png)
    kernels is slid across the width and height of the input. At every location where
    a kernel stops, a dot product is computed between the kernel values and the input
    values that overlap with the kernel, in order to obtain one output value for that
    location. Finally, the bias value associated with that kernel is added to each
    output value. This process is illustrated in Figure 3.5:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积过程中，每个 ![](img/0b647453-d81b-4a4d-bcd3-c3d3555d652a.png) 卷积核会在输入的宽度和高度上滑动。在每个卷积核停止的地方，会计算卷积核值与输入值的点积，这些输入值与卷积核重叠，从而获得该位置的一个输出值。最后，卷积核相关的偏置值会加到每个输出值上。这个过程如图
    3.5 所示：
- en: '![](img/8f7525d1-6f20-4e70-acef-c0ba0404c8e1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f7525d1-6f20-4e70-acef-c0ba0404c8e1.png)'
- en: 'Figure 3.5: 2D convolution of ![](img/4cfefe2f-2b21-4f5f-bba1-96e80fb0b76c.png)
    input with two filters of shape ![](img/d9bfaa13-634c-4df9-a999-46af255782ad.png).
    Output is of the shape ![](img/40b5a8c5-6887-4478-9d8a-e5e815cee36d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：二维卷积操作，输入 ![](img/4cfefe2f-2b21-4f5f-bba1-96e80fb0b76c.png) 使用两个形状为 ![](img/d9bfaa13-634c-4df9-a999-46af255782ad.png)
    的滤波器。输出形状为 ![](img/40b5a8c5-6887-4478-9d8a-e5e815cee36d.png)。
- en: Note how convolving with each kernel results in an output tensor of size ![](img/568b94bd-6728-4846-8c1e-05723ed034d7.png).
    Thus, when an input of size ![](img/3074dce5-23d2-4c38-af4b-28a556b54d5b.png)
    is fed to a 2D convolution layer, the resulting output is of size ![](img/55440054-fd94-4cd0-90a9-2671ce0b9e6b.png).
    If we feed a batch of ![](img/164214f4-a9f3-47f0-aabb-631e66695444.png) inputs
    to a 2D convolution layer, the resulting output is of size ![](img/3a91706e-03ab-4e94-b07b-e41dc7c7462b.png).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，通过与每个卷积核进行卷积，结果输出张量的大小为 ![](img/568b94bd-6728-4846-8c1e-05723ed034d7.png)。因此，当输入大小为
    ![](img/3074dce5-23d2-4c38-af4b-28a556b54d5b.png) 时，输入到二维卷积层后的输出大小为 ![](img/55440054-fd94-4cd0-90a9-2671ce0b9e6b.png)。如果我们将一批
    ![](img/164214f4-a9f3-47f0-aabb-631e66695444.png) 输入送入二维卷积层，结果输出的大小为 ![](img/3a91706e-03ab-4e94-b07b-e41dc7c7462b.png)。
- en: A 2D convolution layer has a few other arguments. A couple of important arguments
    are the stride and padding. **Stride** indicates how many values along the height
    and width a kernel moves before stopping to perform a convolution. For example,
    if the stride is ![](img/b20bf2d0-23dc-420a-a6f9-e9b75663ce10.png), kernels only
    visit every alternate location in the input. **Padding** indicates how much the
    height and width of input can be assumed to be expanded with **padding values**
    for performing convolution. Zero values are commonly used as padding values, and
    this is called **zero padding**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 二维卷积层还有其他一些参数。两个重要的参数是步幅（**stride**）和填充（**padding**）。**步幅**表示卷积核沿高度和宽度移动多少个值后才停下来进行卷积。例如，如果步幅为
    ![](img/b20bf2d0-23dc-420a-a6f9-e9b75663ce10.png)，卷积核只会访问输入中的每隔一个位置。**填充**表示为了进行卷积，输入的高度和宽度可以假设扩展了多少，通常是使用**零填充**，即填充零值。
- en: Pooling layer
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: 'Another popular type of layer used in CNNs is called the **pooling layer**.
    It is typically used to reduce the width and height of the outputs of a previous
    layer. It operates by subsampling its input to produce the output. Unlike a convolution
    layer, a pooling layer does not have any pretrained parameters. It has two arguments
    associated with it: a **window size** and a **reduction function**. Similar to
    the convolution layer, a pooling layer has arguments such as stride and padding.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种在卷积神经网络（CNN）中常用的层叫做**池化层**。它通常用于减少前一层输出的宽度和高度。池化层通过子采样输入来生成输出。与卷积层不同，池化层没有任何预训练参数。池化层有两个与之相关的参数：**窗口大小**和**缩减函数**。类似于卷积层，池化层也有一些参数，如步幅和填充。
- en: 'What the pooling layer does is to slide the window of specified width and height
    across the input. At each location where it stops, it applies its reduction function
    to the input values in the window to produce a single output value:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层的作用是沿着输入滑动具有指定宽度和高度的窗口。在每个停靠位置，它会将其缩减函数应用于窗口中的输入值，以产生一个单一的输出值：
- en: '![](img/2ba01ee9-2a27-4fc2-aaa9-43f129b9ffc8.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ba01ee9-2a27-4fc2-aaa9-43f129b9ffc8.png)'
- en: 'Figure 3.6: Pooling layer producing ![](img/88ded9de-47b1-41ff-83bc-d224e781cc30.png)
    output after pooling ![](img/95426f58-5746-4bcf-bb2c-23f19c438f96.png) input with
    a ![](img/bd09d1ca-b52e-4e3c-884d-026fe55ead2c.png) pooling window'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：池化层在池化输入 ![](img/95426f58-5746-4bcf-bb2c-23f19c438f96.png) 时，使用 ![](img/bd09d1ca-b52e-4e3c-884d-026fe55ead2c.png)
    池化窗口产生的输出 ![](img/88ded9de-47b1-41ff-83bc-d224e781cc30.png)。
- en: Common reduction functions are max and average. In a max-pooling layer, the
    maximum of the values in the input window becomes the output value. In an **average-pooling
    layer**, the average of the values in the input window becomes the output value.
    *Figure 3.6* illustrates an operation in a max-pooling layer.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的缩减函数有最大池化（max）和平均池化（average）。在最大池化层中，输入窗口中值的最大值成为输出值。在**平均池化层**中，输入窗口中值的平均值成为输出值。*图
    3.6* 展示了最大池化层中的一个操作。
- en: The pooling window is 2D and moves along the width and height of the input.
    So, it only reduces the width and height of the input. The number of channels
    remains the same in the input and in the output.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 池化窗口是二维的，并沿着输入的宽度和高度进行移动。因此，它只减少输入的宽度和高度，输入和输出中的通道数保持不变。
- en: We are now ready to look at a code example that trains a LeNet network. The
    complete source code for this is available as `ch3/mnist_lenet.py`. We begin by
    reading the MNIST training data in the next section.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备查看一个训练 LeNet 网络的代码示例。完整的源代码可以在 `ch3/mnist_lenet.py` 中找到。我们将在下一节开始读取 MNIST
    训练数据。
- en: Training data
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据
- en: 'We use brew in this chapter to simplify the process of building our LeNet network.
    We begin by first initializing the model using `ModelHelper`, which was introduced
    in the previous chapter:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中使用 brew 来简化构建 LeNet 网络的过程。首先，我们使用 `ModelHelper` 初始化模型，该方法在上一章中介绍过：
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then add inputs to the training network using our `add_model_inputs` method:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 `add_model_inputs` 方法将输入添加到训练网络中：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Training data is usually stored in a **database** (**DB**) so that it can be
    accessed efficiently. Reading from a DB is usually faster than reading from thousands
    of individual files on the filesystem. For every training image in the MNIST dataset,
    the DB stores the ![](img/794e7fbf-e3ba-4db8-85c5-2896e17aed95.png) grayscale
    pixel values of the image and the digit that is in the image. Each grayscale pixel
    value is an 8-bit unsigned integer, with values in the range ![](img/30176a5d-e2f0-4dae-a677-971f411d6f79.png).
    The actual digit that is in each image is called a **label** and is usually annotated
    by a human by inspecting the image. For example, if the handwritten digit in the
    image is a 9, then a human annotator would have looked at the image and given
    it a label of 9.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据通常存储在 **数据库**（**DB**）中，以便高效访问。读取数据库通常比从数千个单独的文件中读取要快。对于 MNIST 数据集中的每张训练图像，数据库存储图像的
    ![](img/794e7fbf-e3ba-4db8-85c5-2896e17aed95.png) 灰度像素值和图像中的数字。每个灰度像素值是一个 8 位无符号整数，取值范围为
    ![](img/30176a5d-e2f0-4dae-a677-971f411d6f79.png)。每张图像中的实际数字称为 **标签**，通常是由人工通过检查图像进行注释的。例如，如果图像中的手写数字是
    9，那么人工注释者会查看图像并给它标注为 9。
- en: 'In our `add_model_inputs` method, we use a convenient brew helper function
    named `db_input` to connect the DB to our model:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `add_model_inputs` 方法中，我们使用一个便捷的 brew 辅助函数 `db_input` 将 DB 连接到我们的模型：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We specify the names of the blobs in our workspace to which the image and label
    data should be stored: `input_images_uint8` and `input_labels`. We also specify
    the batch size and information required to access the DB, such as its name and
    type.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定工作区中存储图像和标签数据的 blob 名称：`input_images_uint8` 和 `input_labels`。我们还指定了批量大小和访问数据库所需的信息，如数据库的名称和类型。
- en: 'Neural networks almost always work with float values, ideally normalized to
    the range ![](img/12c6eec1-e08e-476d-99b7-f59c6ff39426.png). So, we indicate that
    our input image data, which is an 8-bit unsigned integer data type, should be
    cast to the float data type and normalized:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络几乎总是使用浮动值，理想情况下，值需要标准化到范围 ![](img/12c6eec1-e08e-476d-99b7-f59c6ff39426.png)。因此，我们将输入图像数据（它是一个
    8 位无符号整数数据类型）转换为浮动数据类型并进行标准化：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Note how the Caffe2 `ModelHelper` provides helpful methods to perform both
    these operations with ease: `Cast` and `Scale`.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意 Caffe2 的 `ModelHelper` 提供了有用的方法，使得执行这两项操作变得轻松：`Cast` 和 `Scale`。
- en: 'Finally, we add a `StopGradient` operator to the image data blob to indicate
    to the backward pass algorithm not to compute gradients for it:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们向图像数据 blob 添加一个 `StopGradient` 操作符，指示反向传递算法不要为其计算梯度：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We do this because the input layer is not a real layer of the neural network.
    It has no learnable parameters and does not have anything to be trained. So, the
    backward pass can stop there and does not need to move past it. `StopGradient`
    is a pseudo operator in Caffe2 that achieves this effect.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样做是因为输入层不是神经网络的实际层。它没有可学习的参数，也没有需要训练的内容。因此，反向传递可以在这里停止，无需继续进行。`StopGradient`
    是 Caffe2 中的一个伪操作符，它实现了这一效果。
- en: Building LeNet
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 LeNet
- en: 'We build the LeNet layers required for inference by calling the `build_mnist_lenet`
    method in our script:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在脚本中调用 `build_mnist_lenet` 方法来构建用于推理的 LeNet 层：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note how we only pass in the image pixel data input to this network and not
    the labels. The labels are not required for inference; they are required for training
    or testing to use as ground truth to compare against the prediction of the network’s
    final layer.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们只将图像像素数据输入到该网络，而不是标签。推理时不需要标签；标签用于训练或测试，以作为真实值与网络最终层预测结果进行比较。
- en: The remainder of the following subsections describe how we add pairs of convolution
    and pooling layers, the fully connected and ReLU layers, and the final SoftMax
    layer, to create the LeNet network.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的各小节描述了如何添加卷积和池化层的对，完全连接层和 ReLU 层，以及最终的 SoftMax 层，以构建 LeNet 网络。
- en: Layer 1 – Convolution
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层 1 – 卷积
- en: The first layer in LeNet is a convolution layer, which we introduced earlier
    in this chapter. We build it from a Caffe2 2D convolution operator, `Conv2D`,
    available in the operators' catalog. This can be added to the model using the
    handy `brew.conv` method.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet 的第一层是卷积层，我们在本章之前已经介绍过。我们使用 Caffe2 的二维卷积操作符 `Conv2D` 来构建该层，可以从操作符目录中找到。可以使用方便的
    `brew.conv` 方法将其添加到模型中。
- en: 'When creating the operator, we specify that the input is a single-channel matrix
    of grayscale values. We also indicate that the output should have `20` channels,
    each channel holding a matrix. Finally, we specify that each convolution kernel
    used should have a width and height of `5` pixels. In Caffe2, we can provide minimal
    information like this and the API figures out the rest of the necessary arguments:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建操作符时，我们指定输入是一个单通道的灰度值矩阵。我们还指明输出应该有`20`个通道，每个通道保存一个矩阵。最后，我们指定每个卷积核的宽度和高度为`5`像素。在
    Caffe2 中，我们只需要提供这样的最小信息，API 会自动处理其余的必要参数：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let's expand these values to get a better idea of the sizes of the input, output,
    and kernels of this layer. Since the MNIST dataset is a ![](img/164e8dc6-95e9-4536-9238-878e3fac1a99.png)
    grid of values of a single grayscale channel, the input to this first layer of
    the network is a 3D array of size ![](img/50a726c1-8bfb-4082-bd09-9da816d48385.png).
    We are performing 2D convolution here, where each kernel has the same number of
    channels as the input to the layer. Furthermore, we indicated that the kernel
    width and height should be 5\. So, the size of each kernel is ![](img/1c43255e-5f55-41d0-8d2d-91a990fb4818.png).
    Since we indicated that we want 20 channels of output from this layer, we need
    20 such kernels. Hence, the actual size of kernel parameters of this layer is
    ![](img/4302d892-80e0-402a-885f-3261315691a4.png). Convolution layers also use
    a bias value, one for each output channel, so the size of bias values is ![](img/ec2c64ef-8cb2-4b64-9289-f339d9d492ae.png).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们扩展这些值，以更好地了解该层的输入、输出和卷积核的尺寸。由于 MNIST 数据集是一个 ![](img/164e8dc6-95e9-4536-9238-878e3fac1a99.png)
    的单通道灰度值网格，因此网络第一层的输入是一个尺寸为 ![](img/50a726c1-8bfb-4082-bd09-9da816d48385.png) 的
    3D 数组。我们这里执行的是二维卷积，每个卷积核的通道数与输入层的通道数相同。此外，我们指明卷积核的宽度和高度为 5。因此，每个卷积核的尺寸为 ![](img/1c43255e-5f55-41d0-8d2d-91a990fb4818.png)。由于我们要求此层的输出有
    20 个通道，所以需要 20 个这样的卷积核。因此，这一层卷积核参数的实际尺寸为 ![](img/4302d892-80e0-402a-885f-3261315691a4.png)。卷积层还使用偏置值，每个输出通道一个，所以偏置值的尺寸为
    ![](img/ec2c64ef-8cb2-4b64-9289-f339d9d492ae.png)。
- en: If a ![](img/94d82477-647b-4887-9b0c-d527cd3e3bf0.png) kernel is convolved on
    a ![](img/0096a185-07f2-4eb9-a84f-e8b185bf58d4.png) input with a stride of 1,
    the result is ![](img/c55d39ae-efd3-42d1-9911-152d98acfcdc.png). When 20 such
    kernels are used, the result is ![](img/eabb0e24-f509-4813-bcf3-f5ab7c4e7884.png).
    This is the size of the output of this layer.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果对一个 ![](img/94d82477-647b-4887-9b0c-d527cd3e3bf0.png) 卷积核在 ![](img/0096a185-07f2-4eb9-a84f-e8b185bf58d4.png)
    输入上进行卷积，步幅为 1，结果是 ![](img/c55d39ae-efd3-42d1-9911-152d98acfcdc.png)。当使用 20 个这样的卷积核时，结果是
    ![](img/eabb0e24-f509-4813-bcf3-f5ab7c4e7884.png)。这就是该层输出的尺寸。
- en: Layer 2 – Max-pooling
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层 2 – 最大池化
- en: 'The output of the first convolution layer is connected to a max-pooling layer,
    introduced earlier in this chapter. We build it from a Caffe2 max-pooling operator,
    `MaxPool`, available in the operators'' catalog. This can be added to the model
    using the handy `brew.max_pool` method. When creating this operator, we specify
    that its kernels are 2 x 2 in size, and that the stride is 2:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个卷积层的输出连接到一个最大池化层，这个池化层在本章之前已经介绍过。我们使用 Caffe2 的最大池化操作符 `MaxPool` 来构建该层，该操作符可以从操作符目录中找到。可以使用方便的
    `brew.max_pool` 方法将其添加到模型中。在创建此操作符时，我们指定其卷积核大小为 2 x 2，并且步幅为 2：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The output of the previous convolution layer was of the size ![](img/53b05c6d-a7ac-4662-8ec4-3fe0b3823426.png).
    When max-pooling using window size ![](img/a0bd1dfd-87bb-4d09-a39c-cf5d3930d410.png)
    and stride 2 is performed, the output is of the size ![](img/41f92570-45d4-4f54-b0a0-df93ccd522de.png).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 上一层卷积的输出尺寸为 ![](img/53b05c6d-a7ac-4662-8ec4-3fe0b3823426.png)。当使用窗口大小 ![](img/a0bd1dfd-87bb-4d09-a39c-cf5d3930d410.png)
    和步幅为 2 进行最大池化时，输出尺寸为 ![](img/41f92570-45d4-4f54-b0a0-df93ccd522de.png)。
- en: Layers 3 and 4 – Convolution and max-pooling
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层 3 和层 4 – 卷积和最大池化
- en: 'The first pair of convolution and pooling layers is followed by another pair
    of convolution and pooling layers in LeNet, to further reduce the width and height
    and increase the channels:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个卷积层和池化层后面是LeNet中的另一对卷积层和池化层，进一步减少宽度和高度并增加通道数：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The second pair of convolution and pooling layers is similar to the first pair,
    in that convolution kernels have a size of 5 x 5 and the stride is 2, while the
    max-pooling window size is ![](img/5ce98050-ac22-45cc-bc9f-42ce41850c58.png) and
    the stride is 2\. What is different is that the second convolution layer uses
    50 kernels to produce an output having 50 channels. After the second convolution
    layer, the output is of the size ![](img/e333ca6a-e958-4d28-be29-7fc833f6bb1d.png).
    After the second max-pooling layer, the output is ![](img/b024ade5-42d5-43a5-8142-03fc5b8dc05e.png).
    Note how the width and height of the inputs have gone down dramatically.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 第二对卷积层和池化层与第一对相似，卷积核大小为5 x 5，步长为2，而最大池化窗口大小为![](img/5ce98050-ac22-45cc-bc9f-42ce41850c58.png)，步长为2。不同之处在于，第二个卷积层使用50个卷积核，生成一个具有50个通道的输出。在第二个卷积层之后，输出大小为![](img/e333ca6a-e958-4d28-be29-7fc833f6bb1d.png)。在第二个最大池化层之后，输出为![](img/b024ade5-42d5-43a5-8142-03fc5b8dc05e.png)。注意，输入的宽度和高度已经大幅度下降。
- en: Layers 5 and 6 – Fully connected and ReLU
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5层和第6层 – 完全连接层和ReLU层
- en: 'The convolution and pooling layers are followed by a pair of fully connected
    and ReLU layers, added using the handy methods, `brew.fc` and `brew.relu`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层和池化层后面跟着一对完全连接层和ReLU层，通过便捷的方法`brew.fc`和`brew.relu`添加：
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The input to the fully connected layer is of size ![](img/d2047bd9-1ae3-4748-86a4-cbdbec659ae1.png).
    This 3D input is flattened to a vector of size 800 when fed to the fully connected
    layer. We have specified the output size of the layer as `500`. So this layer
    needs to learn ![](img/6e72624a-259d-4f1c-b667-1f78d84e2b3b.png) values, plus
    a bias value, during training, so that they can be used during inference. The
    output of the fully connected layer is fed to a ReLu layer, which acts as an activation
    function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 完全连接层的输入大小为![](img/d2047bd9-1ae3-4748-86a4-cbdbec659ae1.png)。这个3D输入在传递给完全连接层时被展平为一个大小为800的向量。我们已经指定了该层的输出大小为`500`。因此，在训练过程中，这一层需要学习![](img/6e72624a-259d-4f1c-b667-1f78d84e2b3b.png)个值，再加上一个偏置值，这些值将在推理时使用。完全连接层的输出被传递给一个ReLU层，作为激活函数。
- en: Layer 7 and 8 – Fully connected and Softmax
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7层和第8层 – 完全连接层和Softmax层
- en: 'LeNet-5 uses a second fully connected layer to reduce the output down to the
    `10` values required to predict probabilities for the 10 digits:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet-5使用第二个完全连接层将输出减少到预测10个数字概率所需的`10`个值：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'A final SoftMax layer converts the 10 output values of the fully connected
    layer to a probability distribution:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的SoftMax层将完全连接层的10个输出值转换为概率分布：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Training layers
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练层
- en: In earlier sections, we built the layers of a LeNet network required for inference
    and added inputs of image pixels and the label corresponding to each image. In
    this section, we are adding a few layers at the end of the network required to
    compute the loss function and for backpropagation. These layers are only required
    during training and can be discarded when using the trained network for inference.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们构建了LeNet网络的层结构，这些层是推理所需的，并且添加了图像像素的输入以及与每张图像对应的标签。在这一部分，我们在网络的末端添加了一些层，旨在计算损失函数并进行反向传播。这些层只在训练过程中需要，使用训练好的网络进行推理时可以丢弃。
- en: Loss layer
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失层
- en: As we noted in the *Introduction to training* section, we need a `loss` function
    at the end of the network to determine the error of the network. Caffe2 provides
    implementations of many common loss functions as operators in its operators' catalog.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*训练简介*部分中提到的，我们需要在网络的最后设置一个`loss`函数，用来确定网络的误差。Caffe2在其操作符目录中提供了许多常见的损失函数的实现。
- en: 'For this example, we compute the loss value using **categorical cross-entropy
    loss**. This loss is typically used to measure the performance of a classification
    model whose output is between `0` and `1`. In Caffe2, this loss can be implemented
    as a composition of two operators, `LabelCrossEntropy` and `AveragedLoss`, shown
    as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们使用**分类交叉熵损失**计算损失值。该损失通常用于衡量分类模型的性能，其输出介于`0`和`1`之间。在Caffe2中，这个损失可以通过两个操作符的组合来实现，分别是`LabelCrossEntropy`和`AveragedLoss`，如以下所示：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Optimization layers
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化层
- en: In the *Introduction to training* section, we noted how a gradient-based optimization
    algorithm lies at the heart of the training process.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在*训练介绍*一节中，我们提到过，基于梯度的优化算法是训练过程的核心。
- en: 'We first indicate to Caffe2 to use the output of the loss layer we added earlier
    to start the computation of gradients during the backward pass during training:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先指示 Caffe2 使用我们之前添加的损失层的输出，在训练期间的反向传播计算梯度：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `AddGradientOperators` method takes away the pain of specifying these operators
    explicitly and adds them to the network for us.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`AddGradientOperators` 方法免去了我们显式指定这些操作符的麻烦，并将其添加到网络中。'
- en: 'Finally, we specify the gradient-based optimization algorithm **Stochastic
    Gradient Descent** (**SGD**) to be used for our training:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们指定基于梯度的优化算法**随机梯度下降**（**SGD**）用于我们的训练：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We specify important SGD parameters, such as the learning rate to use, the policy
    to use in order to change the learning rate, the step size, and gamma.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定了重要的 SGD 参数，例如使用的学习率、调整学习率的策略、步长和 gamma。
- en: Optimization algorithms are implemented as `Optimizer` in Caffe2\. The DL framework
    has implementations of many common optimization algorithms, including SGD, Adam,
    AdaGrad, RMSProp, and AdaDelta. In our preceding call, we used a helpful wrapper,
    `build_sgd`, provided by the `optimizer` module that configures the SGD optimizer
    for us.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 优化算法在 Caffe2 中作为 `Optimizer` 实现。该深度学习框架实现了许多常见的优化算法，包括 SGD、Adam、AdaGrad、RMSProp
    和 AdaDelta。在我们之前的调用中，我们使用了 `optimizer` 模块提供的有用包装器 `build_sgd`，该包装器为我们配置了 SGD 优化器。
- en: Accuracy layer
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确率层
- en: 'Finally, we indicate that the accuracy of the model should be tracked with
    a call to our `add_accuracy_op` method, which has this statement:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过调用 `add_accuracy_op` 方法来指示应该跟踪模型的准确性，该方法包含如下语句：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note the second argument to the function call. This indicates to Caffe2 that
    the output of the SoftMax layer should be compared against the ground truth labels
    to determine the accuracy of the model.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意函数调用的第二个参数。这表明 Caffe2 应该将 SoftMax 层的输出与真实标签进行比较，以确定模型的准确性。
- en: The `accuracy` layer is helpful for human supervision of the training process.
    We can perform inference at any point in the training process and, using the output
    of the accuracy layer, get a sense of how accurate the network is at that point.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`accuracy` 层有助于对训练过程进行人工监督。我们可以在训练过程的任何阶段执行推理，并通过准确率层的输出，了解网络在该阶段的准确性。'
- en: Training and monitoring
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练与监控
- en: 'We begin the training process by creating the network in the workspace and
    initializing all the parameter blobs of the network in the workspace. This is
    done by calling the workspace `RunNetOnce` method:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在工作空间中创建网络并初始化网络的所有参数 blob 来开始训练过程。这是通过调用工作空间的 `RunNetOnce` 方法完成的：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we ask Caffe2 to create the network in memory:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们请求 Caffe2 在内存中创建网络：
- en: '[PRE17]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We are finally ready to train. We iterate a predetermined number of times and,
    in each iteration, we use the workspace `RunNet` method to run a forward pass
    and a backward pass.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于准备好开始训练。我们会迭代一个预定的次数，并在每次迭代中使用工作空间的 `RunNet` 方法运行前向传播和反向传播。
- en: Training a small network such as our LeNet model is fast both on CPU and GPU.
    However, many of the real models you train might take several hours or days to
    train. For this reason, it is a good idea to constantly monitor the training process
    by extracting the loss and accuracy after every training iteration.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 训练像我们的 LeNet 模型这样的小型网络在 CPU 和 GPU 上都非常快速。然而，许多真实的模型训练可能需要数小时甚至数天。因此，建议通过在每次训练迭代后提取损失和准确性值来持续监控训练过程。
- en: 'For our LeNet model, we use the following code to extract the loss and accuracy
    values after each training iteration from the output blobs of the loss and accuracy
    layers we added earlier to the training network:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 LeNet 模型，我们使用以下代码从我们先前添加到训练网络的损失层和准确率层的输出 blobs 中提取每次训练迭代后的损失和准确性值：
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can monitor the health of the training by looking at the raw values, or
    importing them into a spreadsheet, or plotting them in a graph. Figure 3.7 shows
    a graph plotted from the values of one such training session:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看原始值、将其导入电子表格或绘制图表来监控训练的健康状况。图 3.7 显示了从一次训练会话的值绘制的图表：
- en: '![](img/0d9b338b-8f4d-49f9-a229-0509f7ec5df7.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d9b338b-8f4d-49f9-a229-0509f7ec5df7.png)'
- en: 'Figure 3.7: Loss and accuracy of training our model'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：训练我们模型的损失与准确性
- en: We can see that the loss is high at the beginning. This is expected, as we typically
    initialize a network with zero or random weights. As the training proceeds, we
    see that the loss decreases and, correspondingly, the accuracy of the network
    increases. If you do not see the loss decreasing or accuracy increasing, then
    that indicates a problem with our training parameters or training data. If the
    training pace is slow or is causing values to blow off, then you might need to
    tweak the learning rate and such parameters.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，训练开始时损失值较高。这是预期的，因为我们通常以零或随机的权重初始化网络。随着训练的进行，损失值逐渐减小，相应地，网络的准确度也在提高。如果你没有看到损失值减少或准确度提升，那么说明我们的训练参数或训练数据可能存在问题。如果训练进度缓慢或出现值爆炸的情况，可能需要调整学习率等参数。
- en: We can typically stop training at any iteration where the loss curve is leveling
    off and the accuracy is suitable. To aid the export of a model at a particular
    iteration, it is a good idea to export the model to disk (demonstrated in [Chapter
    5](4481e225-7882-4625-9d42-63ba41e74b4f.xhtml), *Working with Other Frameworks*)
    after each iteration. That way, you can pick the model at the best iteration after
    the training is complete.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们可以在损失曲线趋于平稳且准确度适当时停止训练。为了便于在某一迭代时导出模型，最好在每次迭代后将模型导出到磁盘（如[第5章](4481e225-7882-4625-9d42-63ba41e74b4f.xhtml)中所示，*与其他框架的协作*）。这样，训练完成后，你可以选择在最佳迭代时保存的模型。
- en: Another useful practice is to measure the accuracy on a validation dataset after
    every epoch or so. **Validation data** is typically a portion of the training
    data that is separated out for this purpose prior to the training. We did not
    use validation data in our example, in order to keep it simple.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的做法是，在每个epoch后，使用验证数据集来测量准确度。**验证数据**通常是从训练数据中分离出来的一部分，事先为此目的而准备。为了简化起见，我们在示例中没有使用验证数据。
- en: Summary
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the general training process for a neural
    network using a gradient-based optimization algorithm. We learned about CNNs and
    the classic LeNet CNN to solve the MNIST problem. We built this network, and learned
    how to add training and test layers to it, so that we could use it for training.
    We finally used this network to train and learned how to monitor the network during
    training using Caffe2\. In the following chapters, we will learn how to work with
    models trained using other frameworks, such as Caffe, TensorFlow, and PyTorch.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了使用基于梯度的优化算法进行神经网络的一般训练过程。我们了解了卷积神经网络（CNN）及经典的LeNet CNN，并使用它解决了MNIST问题。我们构建了这个网络，并学习了如何向其添加训练层和测试层，以便用于训练。最后，我们使用这个网络进行训练，并学习了如何在训练过程中使用Caffe2监控网络。在接下来的章节中，我们将学习如何使用其他框架（如Caffe、TensorFlow和PyTorch）训练的模型。
