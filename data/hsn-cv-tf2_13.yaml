- en: Migrating from TensorFlow 1 to TensorFlow 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 TensorFlow 1 迁移到 TensorFlow 2
- en: Since TensorFlow 2 has only been released very recently, most of the projects
    that are available online are still built for TensorFlow 1\. While this first
    version was already packed with useful features, such as AutoGraph and the Keras
    API, it is recommended that you migrate to the latest version of TensorFlow so
    as to avoid any technical debt. Thankfully, TensorFlow 2 comes with an automatic
    migration tool that is able to convert most projects to its latest version. It
    requires little effort and outputs functional code. However, migrating to idiomatic
    TensorFlow 2 code requires some diligence and knowledge of both versions. In this
    section, we will introduce the migration tool and compare TensorFlow 1 concepts
    with their TensorFlow 2 counterparts.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 TensorFlow 2 最近才发布，因此大多数在线项目仍然是为 TensorFlow 1 构建的。尽管第一版已经具备了许多有用的功能，如 AutoGraph
    和 Keras API，但建议你迁移到最新版本的 TensorFlow，以避免技术债务。幸运的是，TensorFlow 2 提供了一个自动迁移工具，能够将大多数项目转换为其最新版本。该工具几乎不需要额外的努力，并且会输出功能正常的代码。然而，要将代码迁移到符合
    TensorFlow 2 规范的版本，需要一些细心和对两个版本的了解。在本节中，我们将介绍迁移工具，并将 TensorFlow 1 的概念与其 TensorFlow
    2 对应概念进行比较。
- en: Automatic migration
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动迁移
- en: 'After installing TensorFlow 2, the migration tool is available from the command
    line. To convert a project directory, run the following command:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 TensorFlow 2 后，可以通过命令行使用迁移工具。要转换项目目录，请运行以下命令：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is a sample of the command''s logs on an example project:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是示例项目中命令日志的样本：
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The conversion tool details all the changes it made to the files. In the rare
    case when it detects a code line that requires manual attention, it outputs a
    warning with instructions to update.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 转换工具会详细列出它对文件所做的所有更改。在极少数情况下，当它检测到需要手动处理的代码行时，会输出带有更新说明的警告。
- en: 'Most of the outdated calls are moved to `tf.compat.v1`. Indeed, despite the
    deprecation of many concepts, TensorFlow 2 still provides access to the old API
    through this module. However, be aware that calls to `tf.contrib` will cause the
    conversion tool to fail and generate an error:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数过时的调用都已移至 `tf.compat.v1`。事实上，尽管许多概念已经废弃，TensorFlow 2 仍然通过此模块提供对旧 API 的访问。然而，请注意，调用
    `tf.contrib` 会导致转换工具失败并生成错误：
- en: '[PRE2]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Migrating TensorFlow 1 code
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移 TensorFlow 1 代码
- en: If the tool runs without any error, the code can be used as is. However, the
    `tf.compat.v1` module used by the migration tool is deemed to be deprecated. Calling
    this module already outputs deprecation warnings, and its content will not be
    further updated by the community. For this reason, it is recommended that you
    refactor the code in order to make it more idiomatic. In the following sections,
    we will introduce TensorFlow 1 concepts and explain how to migrate them to TensorFlow
    2\. In the following examples, `tf1` will be used instead of `tf` to denote the
    use of TensorFlow 1.13.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工具运行没有任何错误，代码可以按原样使用。然而，迁移工具使用的 `tf.compat.v1` 模块被认为已废弃。调用此模块时会输出废弃警告，并且该模块的内容将不再由社区更新。因此，建议重构代码，使其更加符合
    TensorFlow 2 的规范。在接下来的部分中，我们将介绍 TensorFlow 1 的概念，并解释如何将它们迁移到 TensorFlow 2。在以下示例中，将使用
    `tf1` 来代替 `tf`，表示使用 TensorFlow 1.13。
- en: Sessions
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 会话
- en: 'Since TensorFlow 1 does not use eager execution by default, the results of
    the operations are not directly available. For instance, when summing two constants,
    the output object is an operation:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 TensorFlow 1 默认不使用即时执行（eager execution），因此操作的结果不会直接显示。例如，当对两个常量求和时，输出对象是一个操作：
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To compute a result, you need to manually create `tf1.Session`. A session takes
    care of the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算结果，你需要手动创建 `tf1.Session`。会话负责以下任务：
- en: Managing the memory
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理内存
- en: Running operations on CPU or GPU
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 CPU 或 GPU 上运行操作
- en: Running on several machines if necessary
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如有必要，跨多台机器运行
- en: 'The most common way of using a session is through the `with` statement in Python.
    As with other unmanaged resources, the `with` statement guarantees that the session
    is properly closed after we use it. If the session is not closed, it may keep
    using memory. Sessions in TensorFlow 1 are, therefore, typically instantiated
    and used as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用会话最常见的方法是通过 Python 中的 `with` 语句。与其他不受管理的资源一样，`with` 语句确保我们使用完会话后会正确关闭。如果会话没有关闭，可能会继续占用内存。因此，TensorFlow
    1 中的会话通常是这样实例化和使用的：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can also explicitly close a session, but it is not recommended:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以显式关闭会话，但不推荐这么做：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In TensorFlow 2, session management happens behind the scenes. As the new version
    uses eager execution, there is no need for this superfluous code to compute results.
    Calls to `tf1.Session()` can, therefore, be removed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 2 中，会话管理发生在幕后。由于新版本使用了急切执行，因此不需要这段冗余代码来计算结果。因此，可以删除对 `tf1.Session()`
    的调用。
- en: Placeholders
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`Placeholders`'
- en: 'In the previous example, we computed the sum of two vectors. However, we defined
    the value of those vectors when creating the graph. If we wanted to use variables
    instead, we could have used `tf1.placeholder`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，我们计算了两个向量的和。然而，我们在创建图时定义了这些向量的值。如果我们想使用变量代替，我们本可以使用 `tf1.placeholder`：
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In TensorFlow 1, placeholders are mostly used to provide input data. Their type
    and shape have to be defined. In our example, the shape is `(None,)` because we
    may want to run the operation on vectors of any size. When running the graph,
    we have to provide specific values for our placeholders. This is why we use the `feed_dict` argument
    in `sess.run`, passing the content of variables as a dictionary, with the placeholders
    as keys. Failing to provide a value for all placeholders would cause an exception.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 1 中，`placeholders` 主要用于提供输入数据。它们的类型和形状必须定义。在我们的示例中，形状是 `(None,)`，因为我们可能希望在任意大小的向量上运行操作。在运行图时，我们必须为
    `placeholders` 提供具体的值。这就是我们在 `sess.run` 中使用 `feed_dict` 参数的原因，将变量的内容作为字典传递，`placeholders`
    作为键。如果未为所有 `placeholders` 提供值，将会引发异常。
- en: Before TensorFlow 2, placeholders were used to provide input data, as well as
    layers' parameters. The former use case can be replaced with `tf.keras.Input`,
    while the latter can be addressed using `tf.keras.layers.Layer` parameters.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 2 之前，`placeholders` 被用来提供输入数据和层的参数。前者可以通过 `tf.keras.Input` 来替代，而后者可以通过
    `tf.keras.layers.Layer` 参数来处理。
- en: Variable management
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量管理
- en: 'In TensorFlow 1, variables were created globally. Each variable had a unique
    name and the best practice in terms of creating them was to use `tf1.get_variable()`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 1 中，变量是全局创建的。每个变量都有一个唯一的名称，创建变量的最佳实践是使用 `tf1.get_variable()`：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, we created a global variable named `W`. Deleting the Python `weights` variable
    (using the Python `del weights` command, for instance) would have no effect on
    TensorFlow memory. In fact, if we try to create the same variable again, we would
    end up with an error:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个名为 `W` 的全局变量。删除 Python 中的 `weights` 变量（例如使用 Python 的 `del weights`
    命令）不会影响 TensorFlow 内存。事实上，如果我们尝试再次创建相同的变量，我们将会遇到错误：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'While `tf1.get_variable()` allows you to reuse variables, its default behavior
    is to throw an error if a variable with the chosen name already exists, preventing
    you from mistakenly overriding variables. To avoid this error, we can update our
    call to `tf1.variable_scope(...)` and employ the `reuse` argument:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `tf1.get_variable()` 允许你重用变量，但它的默认行为是在选择的变量名已经存在时抛出错误，以防止你不小心覆盖变量。为了避免这个错误，我们可以更新调用
    `tf1.variable_scope(...)` 并使用 `reuse` 参数：
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `variable_scope` context manager was used to manage variable creation. On
    top of handling variable reuse, it was useful to group variables together by appending
    a prefix to their name. In the previous example, the variable would be named `conv1/W`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`variable_scope` 上下文管理器用于管理变量的创建。除了处理变量重用外，它还通过为变量名称附加前缀来方便地将变量分组。在之前的示例中，变量会被命名为
    `conv1/W`。'
- en: 'In this case, setting reuse to `True` means that if TensorFlow encounters a
    variable called `conv1/W`, it will not throw an error as it did before. Instead,
    it will reuse the existing variable, including its content. However, if you try
    calling the preceding code and the variable named `conv1/W` does not exist, you
    will encounter the following error:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，将 `reuse` 设置为 `True` 意味着，如果 TensorFlow 遇到名为 `conv1/W` 的变量，它不会像之前那样抛出错误。相反，它会重用现有的变量及其内容。然而，如果你尝试调用之前的代码，而名为
    `conv1/W` 的变量不存在，你将遇到以下错误：
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Indeed, `reuse=True` can only be specified when reusing an existing variable.
    If you want to create a variable if it does not exist, and reuse it when it does
    exist, you can pass `reuse=tf.AUTO_REUSE`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，`reuse=True` 只能在重用现有变量时指定。如果你想在变量不存在时创建一个变量，并在它存在时重用，可以传递 `reuse=tf.AUTO_REUSE`。
- en: 'In TensorFlow 2, the behavior is different. While variable scope still exists
    to make naming and debugging easier, variables are no longer global. They are
    handled at the Python level. As long as you can access the Python reference (the
    `weights` variable, in our example), you can modify the variable. To delete the
    variable, you need to delete its reference, for instance, by running the following
    command:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 2 中，行为有所不同。虽然变量作用域依然存在以便于命名和调试，但变量不再是全局的。它们在 Python 层级上进行管理。只要你能够访问
    Python 引用（在我们的例子中是 `weights` 变量），就可以修改该变量。要删除变量，你需要删除其引用，例如通过运行以下命令：
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Previously, variables could be accessed and modified globally, and could potentially
    be overridden by other pieces of code. The deprecation of global variables makes
    TensorFlow code more readable and less prone to errors.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，变量可以全局访问和修改，并且可能会被其他代码覆盖。全局变量的弃用使得 TensorFlow 代码更加易读且更不容易出错。
- en: Layers and models
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层与模型
- en: 'TensorFlow models were originally defined using `tf1.layers`. As this module
    has been deprecated in TensorFlow 2, the replacement of choice is `tf.keras.layers`.
    To train a model using TensorFlow 1, a *train operation* has to be defined using
    an optimizer and a loss. For instance, if `y` is the output of a fully connected
    layer, we would define the training operation using the following command:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 模型最初是通过 `tf1.layers` 定义的。由于该模块在 TensorFlow 2 中已被弃用，推荐使用 `tf.keras.layers`
    作为替代。要使用 TensorFlow 1 训练模型，需要使用优化器和损失函数定义一个*训练操作*。例如，如果 `y` 是全连接层的输出，我们可以使用以下命令定义训练操作：
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Every time we call this operation, a batch of images will be fed to the network
    and a single step of backpropagation will happen. We then run a loop to compute
    multiple training steps:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每次调用此操作时，一批图像将被送入网络并执行一次反向传播步骤。然后我们运行一个循环来计算多个训练步骤：
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: When opening the session, a call to `tf1.global_variables_initializer()` is
    necessary so that layers are initialized with the correct weights. A failure to
    do so would throw an exception. In TensorFlow 2, the initialization of variables
    is handled automatically.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在打开会话时，需要调用 `tf1.global_variables_initializer()` 以确保层被正确初始化。如果没有这样做，将抛出异常。在
    TensorFlow 2 中，变量的初始化是自动处理的。
- en: Other concepts
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他概念
- en: We detailed the most common TensorFlow 1 concepts that were deprecated in the
    new version. Many smaller modules and paradigms were also redesigned in TensorFlow
    2\. When migrating a project, we recommend having a thorough look at the documentation
    of both versions. To ensure that a migration went well and the TensorFlow 2 version
    works as expected, we recommend that you log both inference metrics (such as latency,
    accuracy, or average precision) and training metrics (such as the number of iterations
    before convergence), and compare their values between the old and new versions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们详细介绍了在新版本中被弃用的 TensorFlow 1 中最常见的概念。许多较小的模块和范式在 TensorFlow 2 中也进行了重新设计。在迁移项目时，我们建议详细查看两个版本的文档。为了确保迁移顺利，并且
    TensorFlow 2 版本按预期工作，我们建议你记录推理指标（如延迟、准确率或平均精度）和训练指标（如收敛前的迭代次数），并比较旧版和新版的值。
- en: As it is open source and backed by an active community, TensorFlow is constantly
    evolving—integrating new features, optimizing others, improving the developer
    experience, and more. While this may sometimes require some additional effort,
    upgrading to the latest version as soon as possible will provide you with the
    best environment to develop more performant recognition applications.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 TensorFlow 是开源的，并且得到了活跃社区的支持，它不断发展——集成新特性、优化其他功能、改善开发者体验等等。尽管这有时需要额外的工作，但尽早升级到最新版本将为你提供最佳的环境，以开发性能更高的识别应用程序。
- en: References
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: This section lists the scientific papers and other web resources mentioned in
    this book.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本节列出了本书中提到的科学论文和其他网络资源。
- en: 'Chapter 1: Computer Vision and Neural Networks'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 1 章：计算机视觉与神经网络
- en: Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., 2008\. *A Fast and Incremental
    Method for Loop-Closure Detection Using Bags of Visual Words*. *IEEE Transactions
    on Robotics 1027–1037*.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., 2008\. *一种快速且增量的方法，用于基于视觉词袋的回环检测*。*IEEE
    机器人学报 1027–1037*。
- en: Bradski, G., Kaehler, A., 2000\. OpenCV. *Dr. Dobb’s Journal of Software Tools
    3*.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bradski, G., Kaehler, A., 2000\. OpenCV。*Dr. Dobb’s 软件工具期刊 3*。
- en: Cortes, C., Vapnik, V., 1995\. *Support-Vector Networks*. *Machine Learning
    20, 273–297*.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cortes, C., Vapnik, V., 1995\. *支持向量网络*。 *机器学习 20，273–297*。
- en: 'Drucker, H., Burges, C.J., Kaufman, L., Smola, A.J., Vapnik, V., 1997\. *Support
    Vector Regression Machines. In: Advances in Neural Information Processing Systems,
    pp. 155–161*.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Drucker, H., Burges, C.J., Kaufman, L., Smola, A.J., Vapnik, V., 1997\. *支持向量回归机*。*见：神经信息处理系统进展，pp.
    155–161*。
- en: 'Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012\. *ImageNet Classification
    with Deep Convolutional Neural Networks*. *In: Advances in Neural Information
    Processing Systems, pp. 1097–1105*.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012\. *ImageNet 分类与深度卷积神经网络*。*见：神经信息处理系统进展，pp.
    1097–1105*。
- en: 'Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., 1997\. *Face Recognition:
    A Convolutional Neural-Network Approach*. *IEEE Transactions on Neural Networks
    8, 98–113*.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., 1997\. *面部识别：卷积神经网络方法*。*IEEE
    神经网络交易 8, 98–113*。
- en: 'LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard,
    W.E., Jackel, L.D., 1990\. *Handwritten Digit Recognition with a Back-Propagation
    Network*. *In: Advances in Neural Information Processing Systems, pp. 396–404*.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard,
    W.E., Jackel, L.D., 1990\. *使用反向传播网络进行手写数字识别*。*见：神经信息处理系统进展，pp. 396–404*。
- en: LeCun, Y., Cortes, C., Burges, C., 2010\. *MNIST Handwritten Digit Database.
    AT&T Labs [Online]*. Available at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)
    2, 18.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun, Y., Cortes, C., Burges, C., 2010\. *MNIST 手写数字数据库。AT&T Labs [在线]*。可在
    [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist) 查阅 2, 18。
- en: Lowe, D.G., 2004\. *Distinctive Image Features from Scale-Invariant Keypoints*.
    *International Journal of Computer Vision 60, 91–110*.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lowe, D.G., 2004\. *从尺度不变关键点提取独特图像特征*。*国际计算机视觉杂志 60, 91–110*。
- en: Minsky, M., 1961\. *Steps Toward Artificial Intelligence*. *Proceedings of the
    IRE 49, 8–30*.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minsky, M., 1961\. *迈向人工智能的步骤*。*IRE 会议记录 49, 8–30*。
- en: 'Minsky, M., Papert, S.A., 2017\. *Perceptrons: An Introduction to Computational
    Geometry. MIT press*.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minsky, M., Papert, S.A., 2017\. *感知器：计算几何学入门。MIT出版社*。
- en: Moravec, H., 1984\. *Locomotion, Vision, and Intelligence*.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moravec, H., 1984\. *运动、视觉与智能*。
- en: Papert, S.A., 1966\. *The Summer Vision Project*.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papert, S.A., 1966\. *夏季视觉项目*。
- en: Plaut, D.C., et al., 1986\. *Experiments on Learning by Back Propagation*.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Plaut, D.C., 等人，1986\. *反向传播学习实验*。
- en: 'Rosenblatt, F., 1958\. *The Perceptron: A Probabilistic Model for Information
    Storage and Organization in the Brain*. *Psychological Review 65, 386*.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenblatt, F., 1958\. *感知器：大脑中信息存储与组织的概率模型*。*心理学评论 65, 386*。
- en: Turk, M., Pentland, A., 1991\. *Eigenfaces for Recognition. Journal of Cognitive
    Neuroscience 3, 71–86*.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turk, M., Pentland, A., 1991\. *用于识别的特征脸*。*认知神经科学杂志 3, 71–86*。
- en: Wold, S., Esbensen, K., Geladi, P., 1987\. *Principal Component Analysis. Chemometrics
    and Intelligent Laboratory Systems 2, 37–52*.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wold, S., Esbensen, K., Geladi, P., 1987\. *主成分分析*。*化学计量学与智能实验室系统 2, 37–52*。
- en: 'Chapter 2: TensorFlow Basics and Training a Model'
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章：TensorFlow 基础与模型训练
- en: 'Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado,
    G.S., Davis, A., Dean, et al. *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems 19*.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado,
    G.S., Davis, A., Dean, 等人。*TensorFlow: 大规模机器学习在异构分布式系统上的应用 19*。'
- en: '*API Documentation [WWW Document], n.d. TensorFlow*. URL: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)
    (accessed December 14, 2018).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*API 文档 [WWW 文档]，无日期。TensorFlow*。网址：[https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)（访问于
    2018年12月14日）。'
- en: Chollet, F., 2018\. TensorFlow is the platform of choice for deep learning in
    the research community. There are deep learning framework mentions on arXiv over
    the past three months, *pic.twitter.com/v6ZEi63hzP. @fchollet*.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chollet, F., 2018\. TensorFlow 是研究界深度学习的首选平台。过去三个月在 arXiv 上有提到深度学习框架，*pic.twitter.com/v6ZEi63hzP.
    @fchollet*。
- en: Goldsborough, P., 2016\. *A Tour of TensorFlow. arXiv:1610.01178 [cs]*.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goldsborough, P., 2016\. *TensorFlow 介绍。arXiv:1610.01178 [cs]*。
- en: 'Chapter 3: Modern Neural Networks'
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章：现代神经网络
- en: 'Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
    Ghemawat, S., Irving, G., Isard, M., et al., 2016\. *Tensorflow: A System for
    Large-Scale Machine Learning. In: OSDI, pp. 265–283*.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
    Ghemawat, S., Irving, G., Isard, M., 等人，2016\. *Tensorflow: 大规模机器学习的系统。见：OSDI，pp.
    265–283*。'
- en: '*API Documentation, URL*: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)
    (accessed December 14, 2018).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*API 文档，网址*：[https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)（访问于
    2018年12月14日）。'
- en: 'Bottou, L., 2010\. *Large-Scale Machine Learning with Stochastic Gradient Descent.
    In: Proceedings of COMPSTAT''2010*. *Springer, pp. 177–186*.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bottou, L., 2010. *使用随机梯度下降进行大规模机器学习. 载于：COMPSTAT'2010 会议论文集*. *Springer，第177–186页*。
- en: Bottou, L., Curtis, F.E., Nocedal, J., 2018\. *Optimization Methods for Large-Scale
    Machine Learning. SIAM Review 60, 223–311*.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bottou, L., Curtis, F.E., Nocedal, J., 2018. *大规模机器学习的优化方法. SIAM 综述 60, 223–311*。
- en: Dozat, T., 2016\. *Incorporating Nesterov Momentum into Adam*.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dozat, T., 2016. *将 Nesterov 动量融入 Adam*。
- en: Duchi, J., Hazan, E., Singer, Y., 2011\. *Adaptive Subgradient Methods for Online
    Learning and Stochastic Optimization. Journal of Machine Learning Research 12,
    2121–2159*.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duchi, J., Hazan, E., Singer, Y., 2011. *在线学习与随机优化的自适应子梯度方法. 机器学习研究杂志 12, 2121–2159*。
- en: 'Gardner, W.A., 1984\. *Learning Characteristics of Stochastic Gradient Descent
    Algorithms: A General Study, Analysis, and Critique. Signal Processing 6, 113–133*.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gardner, W.A., 1984. *随机梯度下降算法的学习特性：一项综合研究、分析与批评. 信号处理 6, 113–133*。
- en: Girosi, F., Jones, M., Poggio, T., 1995\. *Regularization Theory and Neural
    Networks Architectures*. *Neural Computation 7, 219–269*.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Girosi, F., Jones, M., Poggio, T., 1995. *正则化理论与神经网络架构*. *神经计算 7, 219–269*。
- en: 'Ioffe, S., Szegedy, C., 2015\. *Batch Normalization: Accelerating Deep Network
    Training by Reducing Internal Covariate Shift.* *arXiv preprint arXiv:1502.03167*.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe, S., Szegedy, C., 2015. *批量归一化：通过减少内部协方差偏移加速深度网络训练.* *arXiv 预印本 arXiv:1502.03167*。
- en: 'Karpathy, A., n.d. *Stanford University CS231n: Convolutional Neural Networks
    for Visual Recognition [WWW Document]*. URL: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
    (accessed December 14, 2018).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karpathy, A., n.d. *斯坦福大学 CS231n：用于视觉识别的卷积神经网络 [WWW 文档]*. URL: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
    （访问日期：2018年12月14日）。'
- en: 'Kingma, D.P., Ba, J., 2014\. *Adam: A Method for Stochastic Optimization. arXiv
    preprint arXiv:1412.6980*.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma, D.P., Ba, J., 2014. *Adam：一种随机优化方法. arXiv 预印本 arXiv:1412.6980*。
- en: 'Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012\. *ImageNet Classification
    with Deep Convolutional Neural Networks*. *In: Advances in Neural Information
    Processing Systems, pp. 1097–1105*.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. *使用深度卷积神经网络进行图像分类*. *载于：神经信息处理系统进展，第1097–1105页*。
- en: 'Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., 1997\. *Face Recognition:
    A Convolutional Neural Network Approach*. *IEEE Transactions on Neural Networks
    8, 98–113*.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., 1997. *人脸识别：一种卷积神经网络方法*.
    *IEEE 神经网络学报 8, 98–113*。
- en: Le and Borji – 2017 – *What are the Receptive, Effective Receptive, and P.pdf,
    n.d*.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le 和 Borji – 2017 – *卷积神经网络中神经元的感受野、有效感受野和投影场是什么？ pdf, n.d*。
- en: Le, H., Borji, A., 2017\. *What are the Receptive, Effective Receptive, and
    Projective Fields of Neurons in Convolutional Neural Networks? arXiv:1705.07049
    [cs]*.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le, H., Borji, A., 2017. *卷积神经网络中神经元的感受野、有效感受野和投影场是什么？ arXiv:1705.07049 [cs]*。
- en: LeCun, Y., Cortes, C., Burges, C., 2010\. *MNIST Handwritten Digit Database.
    AT&T Labs [Online]*. Available at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)
    2.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun, Y., Cortes, C., Burges, C., 2010. *MNIST 手写数字数据库. AT&T 实验室 [在线]*. 可从
    [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist) 获取 2。
- en: 'LeCun, Y., et al., 2015\. LeNet-5, *Convolutional Neural Networks*. URL: [http://yann.lecun.com/exdb/lenet](http://yann.lecun.com/exdb/lenet)
    20.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LeCun, Y., 等, 2015. LeNet-5, *卷积神经网络*. URL: [http://yann.lecun.com/exdb/lenet](http://yann.lecun.com/exdb/lenet)
    20。'
- en: Lenail, A., *n.d. NN SVG [WWW Document]*. URL: [http://alexlenail.me/NN-SVG/](http://alexlenail.me/NN-SVG/)
    (accessed December 14, 2018).
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lenail, A., *n.d. NN SVG [WWW 文档]*. URL: [http://alexlenail.me/NN-SVG/](http://alexlenail.me/NN-SVG/)
    （访问日期：2018年12月14日）。'
- en: Luo, W., Li, Y., Urtasun, R., Zemel, R., n.d. *Understanding the Effective Receptive
    Field in Deep Convolutional Neural Networks 9*.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo, W., Li, Y., Urtasun, R., Zemel, R., n.d. *理解深度卷积神经网络中的有效感受野 9*。
- en: 'Nesterov, Y., 1998\. *Introductory Lectures on Convex Programming Volume I:
    Basic Course. Lecture notes*.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nesterov, Y., 1998. *凸编程导论 第一卷：基础课程. 讲义*。
- en: Perkins, E.S., Davson, H., n.d. *Human Eye | Definition, Structure, & Function
    [WWW Document]*. *Encyclopedia Britannica*. URL: [https://www.britannica.com/science/human-eye](https://www.britannica.com/science/human-eye)
    (accessed December 14, 2018).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Perkins, E.S., Davson, H., n.d. *人眼 | 定义、结构与功能 [WWW 文档]*. *大英百科全书*. URL: [https://www.britannica.com/science/human-eye](https://www.britannica.com/science/human-eye)
    （访问日期：2018年12月14日）。'
- en: Perone, C.S., n.d. *The effective receptive field on CNNs | Terra Incognita.
    Terra Incognita*.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perone, C.S., n.d. *卷积神经网络中的有效感受野 | Terra Incognita. Terra Incognita*。
- en: Polyak, B.T., 1964\. *Some methods of speeding up the convergence of iteration
    methods. USSR Computational Mathematics and Mathematical Physics 4, 1–17*.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polyak, B.T., 1964\. *加速迭代方法收敛的一些方法. 苏联计算数学与数学物理 4, 1–17*.
- en: Raj, D., 2018\. *A Short Note on Gradient Descent Optimization Algorithms*.
    *Medium*.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raj, D., 2018\. *梯度下降优化算法简短说明*. *Medium*.
- en: 'Simard, P.Y., Steinkraus, D., Platt, J.C., 2003\. *Best Practices for Convolutional
    Neural Networks Applied to Visual Document Analysis. In: Null, p. 958*.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simard, P.Y., Steinkraus, D., Platt, J.C., 2003\. *卷积神经网络在视觉文档分析中的最佳实践. 见：Null，第958页*.
- en: 'Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.,
    2014\. *Dropout: A Simple Way to Prevent Neural Networks from Overfitting. The
    Journal of Machine Learning Research 15, 1929–1958*.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.,
    2014\. *Dropout：一种防止神经网络过拟合的简单方法. 机器学习研究期刊 15, 1929–1958*.
- en: 'Sutskever, I., Martens, J., Dahl, G., Hinton, G., 2013\. *On the importance
    of initialization and momentum in deep learning. In: International Conference
    on Machine Learning, pp. 1139–1147*.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutskever, I., Martens, J., Dahl, G., Hinton, G., 2013\. *在深度学习中初始化与动量的重要性.
    见：国际机器学习大会，1139–1147页*.
- en: 'Tieleman, T., Hinton, G., 2012\. *Lecture 6.5-rmsprop:* *Divide the gradient
    by a running average of its recent magnitude. COURSERA: Neural Networks for Machine
    Learning 4, 26–31*.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tieleman, T., Hinton, G., 2012\. *讲座6.5-rmsprop：* *通过最近的梯度幅度的滑动平均值来划分梯度. COURSERA:
    神经网络与机器学习 4, 26–31*.'
- en: Walia, A.S., 2017\. *Types of Optimization Algorithms Used in Neural Networks
    and Ways to Optimize Gradient Descent [WWW Document]. Towards Data Science*. URL: [https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f)
    (accessed December 14, 2018).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Walia, A.S., 2017\. *神经网络中使用的优化算法类型及优化梯度下降的方法 [WWW文档]. Towards Data Science*.
    URL: [https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f)（访问时间：2018年12月14日）。'
- en: 'Zeiler, M.D., 2012\. *ADADELTA: An Adaptive Learning Rate Method. arXiv preprint
    arXiv:1212.5701*.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeiler, M.D., 2012\. *ADADELTA：一种自适应学习率方法. arXiv预印本 arXiv:1212.5701*.
- en: 'Zhang, T., 2004\. *Solving large-scale linear prediction problems using stochastic
    gradient descent algorithms*. *In: Proceedings of the Twenty-first International
    Conference on Machine Learning, p. 116*.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang, T., 2004\. *使用随机梯度下降算法解决大规模线性预测问题*. *见：第二十一届国际机器学习会议论文集，第116页*.
- en: 'Chapter 4: Influential Classification Tools'
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章：影响力的分类工具
- en: '*API Documentation [WWW Document], n.d. TensorFlow*. URL: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)
    (accessed December 14, 2018).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*API文档 [WWW文档], n.d. TensorFlow*. URL: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)（访问时间：2018年12月14日）。'
- en: Goodfellow, I., Bengio, Y., Courville, A., 2016\. *Deep Learning. MIT Press*.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow, I., Bengio, Y., Courville, A., 2016\. *深度学习. MIT出版社*.
- en: He, K., Zhang, X., Ren, S., Sun, J., 2015\. *Deep Residual Learning for Image
    Recognition. arXiv:1512.03385 [cs]*.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He, K., Zhang, X., Ren, S., Sun, J., 2015\. *用于图像识别的深度残差学习. arXiv:1512.03385
    [cs]*.
- en: 'Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto,
    M., Adam, H., 2017\. *MobileNets: Efficient Convolutional Neural Networks for
    Mobile Vision Applications. arXiv:1704.04861 [cs]*.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto,
    M., Adam, H., 2017\. *MobileNets：面向移动视觉应用的高效卷积神经网络. arXiv:1704.04861 [cs]*.
- en: Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q., 2016\. *Densely Connected
    Convolutional Networks. arXiv:1608.06993 [cs]*.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q., 2016\. *密集连接卷积网络.
    arXiv:1608.06993 [cs]*.
- en: 'Karpathy, A., n.d. *Stanford University CS231n: Convolutional Neural Networks
    for Visual Recognition [WWW Document]*. URL: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
    (accessed December 14, 2018).'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karpathy, A., n.d. *斯坦福大学 CS231n：视觉识别的卷积神经网络 [WWW文档]*. URL: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)（访问时间：2018年12月14日）。'
- en: Karpathy, A. *What I learned from competing against a ConvNet on ImageNet [WWW
    Document], n.d*. URL: [http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/)
    (accessed January 4, 2019).
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpathy, A. *我从与ConvNet在ImageNet上竞争中学到的东西 [WWW文档], 未注明日期*. URL: [http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/)（访问日期：2019年1月4日）。
- en: Lin, M., Chen, Q., Yan, S., 2013\. *Network In Network. arXiv:1312.4400 [cs]*.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin, M., Chen, Q., Yan, S., 2013\. *网络中的网络. arXiv:1312.4400 [cs]*.
- en: Pan, S.J., Yang, Q., 2010\. *A Survey on Transfer Learning. IEEE Transactions
    on Knowledge and Data Engineering 22, 1345–1359*.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan, S.J., Yang, Q., 2010\. *迁移学习调查. IEEE知识与数据工程学报 22, 1345–1359*.
- en: Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang,
    Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2014\. *ImageNet
    Large-Scale Visual Recognition Challenge. arXiv:1409.0575 [cs]*.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang,
    Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2014\. *ImageNet大规模视觉识别挑战.
    arXiv:1409.0575 [cs]*.
- en: Sarkar, D. (DJ), 2018\. *A Comprehensive Hands-on Guide to Transfer Learning
    with Real-World Applications in Deep Learning [WWW Document]. Towards Data Science*.
    URL: [https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)
    (accessed January 15, 2019).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarkar, D. (DJ), 2018\. *迁移学习的全面实用指南：深度学习中的真实世界应用 [WWW文档]. Towards Data Science*.
    URL: [https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)（访问日期：2019年1月15日）。
- en: shu-yusa, 2018\. *Using Inception-v3 from TensorFlow Hub for Transfer Learning.
    Medium.*
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: shu-yusa, 2018\. *使用TensorFlow Hub的Inception-v3进行迁移学习. Medium*.
- en: '*Simonyan, K., Zisserman, A., 2014\. Very Deep Convolutional Networks for Large-Scale
    Image Recognition. arXiv:1409.1556 [cs]*.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Simonyan, K., Zisserman, A., 2014\. 用于大规模图像识别的非常深的卷积网络. arXiv:1409.1556 [cs]*.'
- en: Srivastava, R.K., Greff, K., Schmidhuber, J., 2015\. *Highway Networks. arXiv:1505.00387
    [cs]*.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava, R.K., Greff, K., Schmidhuber, J., 2015\. *高速公路网络. arXiv:1505.00387
    [cs]*.
- en: Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., 2016\. *Inception-v4, Inception-ResNet
    and the Impact of Residual Connections on Learning. arXiv:1602.07261 [cs]*.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., 2016\. *Inception-v4, Inception-ResNet以及残差连接对学习的影响.
    arXiv:1602.07261 [cs]*.
- en: Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan,
    D., Vanhoucke, V., Rabinovich, A., 2014\. *Going Deeper with Convolutions. arXiv:1409.4842
    [cs]*.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan,
    D., Vanhoucke, V., Rabinovich, A., 2014\. *深入卷积神经网络的研究. arXiv:1409.4842 [cs]*.
- en: Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., 2015\. *Rethinking
    the Inception Architecture for Computer Vision. arXiv:1512.00567 [cs]*.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., 2015\. *重新思考Inception架构在计算机视觉中的应用.
    arXiv:1512.00567 [cs]*.
- en: Thrun, S., Pratt, L., 1998\. *Learning to Learn*.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thrun, S., Pratt, L., 1998\. *学习如何学习*.
- en: 'Zeiler, Matthew D., Fergus, R., 2014\. *Visualizing and Understanding Convolutional
    Networks*. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (Eds.), *Computer
    Vision – ECCV 2014\. Springer International Publishing, Cham, pp. 818–833*.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeiler, Matthew D., Fergus, R., 2014\. *卷积网络的可视化与理解*. 见：Fleet, D., Pajdla, T.,
    Schiele, B., Tuytelaars, T. (编辑), *计算机视觉 – ECCV 2014\. Springer国际出版公司, Cham, 页码818–833*.
- en: 'Zeiler, Matthew D, Fergus, R., 2014\. *Visualizing and Understanding Convolutional
    Networks. In: European Conference on Computer Vision, pp. 818–833*.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeiler, Matthew D., Fergus, R., 2014\. *卷积网络的可视化与理解. 见：欧洲计算机视觉会议, 页码818–833*.
- en: 'Chapter 5: Object Detection Models'
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：目标检测模型
- en: 'Everingham, M., Eslami, S.M.A., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman,
    A., 2015\. *The Pascal Visual Object Classes Challenge: A Retrospective. International
    Journal of Computer Vision 111, 98–136*.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Everingham, M., Eslami, S.M.A., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman,
    A., 2015\. *Pascal视觉目标类别挑战：回顾. 国际计算机视觉杂志 111, 98–136*.
- en: Girshick, R., 2015\. *Fast R-CNN. arXiv:1504.08083 [cs]*.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Girshick, R., 2015\. *Fast R-CNN. arXiv:1504.08083 [cs]*.
- en: Girshick, R., Donahue, J., Darrell, T., Malik, J., 2013\. *Rich feature hierarchies
    for accurate object detection and semantic segmentation. arXiv:1311.2524 [cs]*.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Girshick, R., Donahue, J., Darrell, T., Malik, J., 2013\. *准确的目标检测和语义分割的丰富特征层次.
    arXiv:1311.2524 [cs]*.
- en: 'Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2015\. *You Only Look Once:
    Unified, Real-Time Object Detection. arXiv:1506.02640 [cs]*.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2015\. *You Only Look Once:
    统一的实时目标检测。arXiv:1506.02640 [cs]*。'
- en: 'Redmon, J., Farhadi, A., 2016\. YOLO9000: *Better, Faster, Stronger. arXiv:1612.08242
    [cs]*.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Redmon, J., Farhadi, A., 2016\. YOLO9000: *更好、更快、更强。arXiv:1612.08242 [cs]*。'
- en: 'Redmon, J., Farhadi, A., 2018\. YOLOv3: *An Incremental Improvement. arXiv:1804.02767
    [cs]*.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Redmon, J., Farhadi, A., 2018\. YOLOv3: *渐进性改进。arXiv:1804.02767 [cs]*。'
- en: 'Ren, S., He, K., Girshick, R., Sun, J., 2015\. *Faster R-CNN: Towards Real-Time
    Object Detection with Region Proposal Networks. arXiv:1506.01497 [cs]*.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ren, S., He, K., Girshick, R., Sun, J., 2015\. *Faster R-CNN: 基于区域提议网络的实时目标检测。arXiv:1506.01497
    [cs]*。'
- en: 'Chapter 6: Enhancing and Segmenting Images'
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章：图像增强与分割
- en: Bai, M., Urtasun, R., 2016\. *Deep Watershed Transform for Instance Segmentation.
    arXiv:1611.08303 [cs]*.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai, M., Urtasun, R., 2016\. *用于实例分割的深度分水岭变换。arXiv:1611.08303 [cs]*。
- en: 'Beyer, L., 2019\. *Python wrapper to Philipp Krähenbühl''s dense (fully connected)
    CRFs with gaussian edge potentials: lucasb-eyer/pydensecr**f*.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beyer, L., 2019\. *Python包装器用于Philipp Krähenbühl的稠密（全连接）条件随机场，带有高斯边缘潜力：lucasb-eyer/pydensecr**f*。
- en: '*Building Autoencoders in Keras [WWW Document]*, n.d. URL: [https://blog.keras.io/building-autoencoders-in-keras.html](https://blog.keras.io/building-autoencoders-in-keras.html)
    (accessed January 18, 2019).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在Keras中构建自编码器 [WWW Document]*, n.d. URL: [https://blog.keras.io/building-autoencoders-in-keras.html](https://blog.keras.io/building-autoencoders-in-keras.html)
    (accessed January 18, 2019).'
- en: 'Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
    Franke, U., Roth, S., Schiele, B., 2016\. *The Cityscapes Dataset for Semantic
    Urban Scene Understanding. In: 2016 IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR)*. *Presented at the 2016 IEEE Conference on Computer Vision
    and Pattern Recognition (CVPR)*, *IEEE, Las Vegas, NV, USA, pp. 3213–3223*.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
    Franke, U., Roth, S., Schiele, B., 2016\. *用于语义城市场景理解的Cityscapes数据集。发表于2016 IEEE计算机视觉与模式识别大会（CVPR）*。*在2016
    IEEE计算机视觉与模式识别大会（CVPR）上展示*，*IEEE, 拉斯维加斯, NV, USA, 第3213-3223页*。
- en: Dice, L.R., 1945\. *Measures of the Amount of Ecologic Association Between Species.
    Ecology 26, 297–302*.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dice, L.R., 1945\. *物种间生态关联量度。生态学 26, 297–302*。
- en: Drozdzal, M., Vorontsov, E., Chartrand, G., Kadoury, S., Pal, C., 2016\. *The
    Importance of Skip Connections in Biomedical Image Segmentation. arXiv:1608.04117
    [cs]*.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Drozdzal, M., Vorontsov, E., Chartrand, G., Kadoury, S., Pal, C., 2016\. *跳跃连接在生物医学图像分割中的重要性。arXiv:1608.04117
    [cs]*。
- en: Dumoulin, V., Visin, F., 2016\. *A Guide to Convolution Arithmetic for Deep
    Learning. arXiv:1603.07285 [cs, stat]*.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dumoulin, V., Visin, F., 2016\. *深度学习卷积算术指南。arXiv:1603.07285 [cs, stat]*。
- en: Guan, S., Khan, A., Sikdar, S., Chitnis, P.V., n.d. *Fully Dense UNet for 2D
    Sparse Photoacoustic Tomography Artifact Removal 8*.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan, S., Khan, A., Sikdar, S., Chitnis, P.V., n.d. *用于2D稀疏光声断层成像伪影去除的完全稠密UNet
    8*。
- en: He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017\. *Mask R-CNN. arXiv:1703.06870
    [cs]*.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017\. *Mask R-CNN. arXiv:1703.06870
    [cs]*.
- en: '*Kaggle. 2018 Data Science Bowl [WWW Document]*, n.d. URL: [https://kaggle.com/c/data-science-bowl-2018](https://kaggle.com/c/data-science-bowl-2018)
    (accessed February 8, 2019).'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kaggle. 2018数据科学碗 [WWW Document]*, n.d. URL: [https://kaggle.com/c/data-science-bowl-2018](https://kaggle.com/c/data-science-bowl-2018)
    (accessed February 8, 2019).'
- en: Krähenbühl, P., Koltun, V., n.d. *Efficient Inference in Fully Connected CRFs
    with Gaussian Edge Potentials 9*.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krähenbühl, P., Koltun, V., n.d. *带有高斯边缘潜力的完全连接条件随机场高效推理 9*。
- en: 'Lan, T., Li, Y., Murugi, J.K., Ding, Y., Qin, Z., 2018\. *RUN: Residual U-Net
    for Computer-Aided Detection of Pulmonary Nodules without Candidate Selection.
    arXiv:1805.11856 [cs]*.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lan, T., Li, Y., Murugi, J.K., Ding, Y., Qin, Z., 2018\. *RUN：用于计算机辅助肺结节检测的残差U-Net，无需候选选择。arXiv:1805.11856
    [cs]*。
- en: 'Li, X., Chen, H., Qi, X., Dou, Q., Fu, C.-W., Heng, P.A., 2017\. *H-DenseUNet:
    Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes.
    arXiv:1709.07330 [cs]*.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li, X., Chen, H., Qi, X., Dou, Q., Fu, C.-W., Heng, P.A., 2017\. *H-DenseUNet:
    用于肝脏和肿瘤分割的混合稠密连接UNet，从CT体积中提取。arXiv:1709.07330 [cs]*。'
- en: Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollár, P., 2017\. *Focal Loss
    for Dense Object Detection. arXiv:1708.02002 [cs]*.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollár, P., 2017\. *Focal Loss
    for Dense Object Detection. arXiv:1708.02002 [cs]*.
- en: 'Milletari, F., Navab, N., Ahmadi, S.-A., 2016\. *V-Net: Fully Convolutional
    Neural Networks for Volumetric Medical Image Segmentation*. *In: 2016 Fourth International
    Conference on 3D Vision (3DV)*. *Presented at the 2016 Fourth International Conference
    on 3D Vision (3DV), IEEE, Stanford, CA, USA, pp. 565–571*.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Milletari, F., Navab, N., Ahmadi, S.-A., 2016\. *V-Net：用于体积医学图像分割的完全卷积神经网络*。*在：2016年第四届国际三维视觉会议（3DV）*。*在2016年第四届国际三维视觉会议（3DV）上展示，IEEE，斯坦福，美国加利福尼亚州，页码565–571*。
- en: 'Noh, H., Hong, S., Han, B., 2015\. *Learning Deconvolution Network for Semantic
    Segmentation*. In: 2015 *IEEE International Conference on Computer Vision (ICCV)*.
    *Presented at the 2015 ICCV, IEEE, Santiago, Chile, pp. 1520–1528*.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Noh, H., Hong, S., Han, B., 2015\. *用于语义分割的去卷积网络学习*。在：2015 *IEEE国际计算机视觉会议（ICCV）*。*2015年ICCV会议上展示，IEEE，智利圣地亚哥，页码1520–1528*。
- en: Odena, A., Dumoulin, V., Olah, C., 2016\. *Deconvolution and Checkerboard Artifacts.
    Distill 1, e3*.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Odena, A., Dumoulin, V., Olah, C., 2016\. *去卷积与棋盘伪影。Distill 1, e3*。
- en: 'Ronneberger, O., Fischer, P., Brox, T., 2015\. *U-Net: Convolutional Networks
    for Biomedical Image Segmentation. arXiv:1505.04597 [cs]*.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronneberger, O., Fischer, P., Brox, T., 2015\. *U-Net：用于生物医学图像分割的卷积网络。arXiv:1505.04597
    [cs]*。
- en: Shelhamer, E., Long, J., Darrell, T., 2017\. *Fully Convolutional Networks for
    Semantic Segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence
    39, 640–651*.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shelhamer, E., Long, J., Darrell, T., 2017\. *完全卷积网络用于语义分割。IEEE模式分析与机器智能学报39,
    640–651*。
- en: Sørensen, T., 1948\. *A method of establishing groups of equal amplitude in
    plant sociology based on similarity of species and its application to analyses
    of the vegetation on Danish commons. Biol. Skr. 5, 1–34*.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sørensen, T., 1948\. *基于物种相似性在植物社会学中建立相等幅度群体的方法及其在丹麦公共草地植被分析中的应用。Biol. Skr.
    5, 1–34*。
- en: '*Unsupervised Feature Learning and Deep Learning Tutorial [WWW Document]*,
    n.d. URL: [http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)
    (accessed January 17, 2019).'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无监督特征学习与深度学习教程 [WWW 文档]*，无日期。URL：[http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)（访问日期：2019年1月17日）。'
- en: Zeiler, M.D., Fergus, R., 2013\. *Visualizing and Understanding Convolutional
    Networks. arXiv:1311.2901 [cs]*.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeiler, M.D., Fergus, R., 2013\. *可视化与理解卷积网络。arXiv:1311.2901 [cs]*。
- en: Zhang, Z., Liu, Q., Wang, Y., 2018\. *Road Extraction by Deep Residual U-Net.
    IEEE Geoscience and Remote Sensing Letters 15, 749–753*.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang, Z., Liu, Q., Wang, Y., 2018\. *基于深度残差U-Net的道路提取。IEEE地球科学与遥感快报15, 749–753*。
- en: 'Chapter 7: Training on Complex and Scarce Datasets'
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章：在复杂和稀缺数据集上的训练
- en: 'Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., 2017a. *Unsupervised
    Pixel-Level Domain Adaptation with Generative Adversarial Networks*. *In: 2017
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Presented at
    the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE,
    Honolulu*, *HI, pp. 95–104*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., 2017a. *基于生成对抗网络的无监督像素级领域适应*。*在：2017年IEEE计算机视觉与模式识别会议（CVPR）上展示。2017年IEEE计算机视觉与模式识别会议（CVPR），IEEE，夏威夷檀香山，页码95–104*。
- en: 'Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., 2017b. *Unsupervised
    Pixel-Level Domain Adaptation with Generative Adversarial Networks. In: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3722–3731*.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., 2017b. *基于生成对抗网络的无监督像素级领域适应。
    在：IEEE计算机视觉与模式识别会议论文集，页码3722–3731*。
- en: 'Brodeur, S., Perez, E., Anand, A., Golemo, F., Celotti, L., Strub, F., Rouat,
    J., Larochelle, H., Courville, A., 2017\. *HoME: a Household Multimodal Environment.
    arXiv:1711.11017 [cs, eess]*.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brodeur, S., Perez, E., Anand, A., Golemo, F., Celotti, L., Strub, F., Rouat,
    J., Larochelle, H., Courville, A., 2017\. *HoME：家庭多模态环境。arXiv:1711.11017 [cs,
    eess]*。
- en: 'Chang, A.X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., Savarese,
    S., Savva, M., Song, S., Su, H., Xiao, J., Yi, L., Yu, F., 2015\. ShapeNet: *An
    Information-Rich 3D Model Repository (No. arXiv:1512.03012 [cs.GR]). Stanford
    University – Princeton University – Toyota Technological Institute at Chicago*.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chang, A.X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., Savarese,
    S., Savva, M., Song, S., Su, H., Xiao, J., Yi, L., Yu, F., 2015\. ShapeNet: *一个信息丰富的
    3D 模型库（编号 arXiv:1512.03012 [cs.GR]）。斯坦福大学 – 普林斯顿大学 – 芝加哥丰田技术研究院*。'
- en: 'Chen, Y., Li, W., Sakaridis, C., Dai, D., Van Gool, L., 2018\. *Domain Adaptive
    Faster R-CNN for Object Detection in the Wild. In: 2018 IEEE/CVF Conference on
    Computer Vision and Pattern Recognition*. *Presented at the 2018 IEEE/CVF Conference
    on Computer Vision and Pattern Recognition (CVPR), IEEE, Salt Lake City, UT, USA,
    pp. 3339–3348*.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen, Y., Li, W., Sakaridis, C., Dai, D., Van Gool, L., 2018\. *面向野外目标检测的领域自适应Faster
    R-CNN. 见：2018年IEEE/CVF计算机视觉与模式识别大会*。*在2018年IEEE/CVF计算机视觉与模式识别大会（CVPR）上发表，IEEE，美国犹他州盐湖城，第3339–3348页*。
- en: 'Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
    Franke, U., Roth, S., Schiele, B., 2016\. *The Cityscapes Dataset for Semantic
    Urban Scene Understanding. In: Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, pp. 3213–3223*.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
    Franke, U., Roth, S., Schiele, B., 2016\. *Cityscapes数据集：语义城市场景理解. 见：IEEE计算机视觉与模式识别会议论文集，第3213–3223页*。
- en: 'Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette,
    F., Marchand, M., Lempitsky, V., 2017\. *Domain-Adversarial Training of Neural
    Networks. In: Csurka, G. (Ed.), Domain Adaptation in Computer Vision Applications.
    Springer International Publishing, Cham, pp. 189–209*.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette,
    F., Marchand, M., Lempitsky, V., 2017\. *神经网络的领域对抗训练. 见：Csurka, G.（编），《计算机视觉应用中的领域适应》，Springer国际出版社，Cham，第189–209页*。
- en: 'Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., Courville, A., Bengio, Y., 2014\. *Generative Adversarial Nets. In: Advances
    in Neural Information Processing Systems, pp. 2672–2680*.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., Courville, A., Bengio, Y., 2014\. *生成对抗网络. 见：《神经信息处理系统进展》，第2672–2680页*。
- en: 'Gschwandtner, M., Kwitt, R., Uhl, A., Pree, W., 2011\. *BlenSor: Blender Sensor
    Simulation Toolbox. In: International Symposium on Visual Computing, pp. 199–208*.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gschwandtner, M., Kwitt, R., Uhl, A., Pree, W., 2011\. *BlenSor：Blender传感器仿真工具箱.
    见：国际视觉计算研讨会，第199–208页*。
- en: 'Hernandez-Juarez, D., Schneider, L., Espinosa, A., Vázquez, D., López, A.M.,
    Franke, U., Pollefeys, M., Moure, J.C., 2017\. *Slanted Stixels: Representing
    San Francisco''s Steepest Streets. arXiv:1707.05397 [cs]*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hernandez-Juarez, D., Schneider, L., Espinosa, A., Vázquez, D., López, A.M.,
    Franke, U., Pollefeys, M., Moure, J.C., 2017\. *倾斜的Stixels：表示旧金山最陡峭的街道. arXiv:1707.05397
    [cs]*。
- en: 'Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros,
    A.A., Darrell, T., 2017\. *CyCADA: Cycle-Consistent Adversarial Domain Adaptation.
    arXiv:1711.03213 [cs]*.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros,
    A.A., Darrell, T., 2017\. *CyCADA：循环一致性对抗领域适应. arXiv:1711.03213 [cs]*。
- en: 'Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., 2017\. *Image-to-Image Translation
    with Conditional Adversarial Networks. In: Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pp. 1125–1134*.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., 2017\. *基于条件对抗网络的图像到图像翻译. 见：IEEE计算机视觉与模式识别会议论文集，第1125–1134页*。
- en: Kingma, D.P., Welling, M., 2013\. *Auto-encoding Variational Bayes. arXiv preprint
    arXiv:1312.6114*.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma, D.P., Welling, M., 2013\. *自编码变分贝叶斯. arXiv预印本arXiv:1312.6114*。
- en: Long, M., Cao, Y., Wang, J., Jordan, M.I., n.d. *Learning Transferable Features
    with Deep Adaptation Networks 9*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long, M., Cao, Y., Wang, J., Jordan, M.I., 无日期。 *使用深度适应网络学习可迁移特征9*。
- en: 'Planche, B., Wu, Z., Ma, K., Sun, S., Kluckner, S., Lehmann, O., Chen, T.,
    Hutter, A., Zakharov, S., Kosch, H., et al., 2017\. *Depthsynth: Real-Time Realistic
    Synthetic Data Generation from CAD Models for 2.5D Recognition. In: 2017 International
    Conference on 3D Vision (3DV), pp*. 1–10.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Planche, B., Wu, Z., Ma, K., Sun, S., Kluckner, S., Lehmann, O., Chen, T., Hutter,
    A., Zakharov, S., Kosch, H., 等人，2017\. *Depthsynth：来自CAD模型的实时逼真合成数据生成，用于2.5D识别.
    见：2017年国际三维视觉会议（3DV），第1–10页*。
- en: Planche, B., Zakharov, S., Wu, Z., Hutter, A., Kosch, H., Ilic, S., 2018\. *Seeing
    Beyond Appearance—Mapping Real Images into Geometrical Domains for Unsupervised
    CAD-based Recognition. arXiv preprint arXiv:1810.04158*.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Planche, B., Zakharov, S., Wu, Z., Hutter, A., Kosch, H., Ilic, S., 2018\. *超越外观——将真实图像映射到几何领域以进行无监督CAD识别.
    arXiv预印本arXiv:1810.04158*。
- en: '*Protocol Buffers [WWW Document], n.d. Google Developers*. URL: [https://developers.google.com/protocol-buffers/](https://developers.google.com/protocol-buffers/)
    (accessed February 23, 2019).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协议缓冲区 [WWW文档]，无日期。Google开发者*. URL：[https://developers.google.com/protocol-buffers/](https://developers.google.com/protocol-buffers/)（访问日期：2019年2月23日）。'
- en: Radford, A., Metz, L., Chintala, S., 2015\. *Unsupervised Representation Learning
    with Deep Convolutional Generative Adversarial Networks. arXiv:1511.06434 [cs]*.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford, A., Metz, L., Chintala, S., 2015\. *无监督表示学习与深度卷积生成对抗网络. arXiv:1511.06434
    [cs]*。
- en: 'Richter, S.R., Vineet, V., Roth, S., Koltun, V., 2016\. *Playing for Data:
    Ground Truth from Computer Games. In: European Conference on Computer Vision,
    pp. 102–118*.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Richter, S.R., Vineet, V., Roth, S., Koltun, V., 2016\. *为数据而玩：来自电脑游戏的真实数据。见：欧洲计算机视觉会议，页102–118*。
- en: 'Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.M., 2016\. *The
    SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation
    of Urban Scenes. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR). Presented at the 2016 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR), IEEE, Las Vegas, NV, USA, pp. 3234–3243*.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.M., 2016\. *SYNTHIA
    数据集：用于城市场景语义分割的大规模合成图像集合。见：2016 IEEE计算机视觉与模式识别会议（CVPR）。在2016 IEEE计算机视觉与模式识别会议（CVPR）上展示，IEEE，拉斯维加斯，美国，页3234–3243*。
- en: Rozantsev, A., Lepetit, V., Fua, P., 2015\. *On Rendering Synthetic Images for
    Training an Object Detector. Computer Vision and Image Understanding 137, 24–37*.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rozantsev, A., Lepetit, V., Fua, P., 2015\. *为训练物体检测器渲染合成图像。计算机视觉与图像理解 137,
    24–37*。
- en: 'Tremblay, J., Prakash, A., Acuna, D., Brophy, M., Jampani, V., Anil, C., To,
    T., Cameracci, E., Boochoon, S., Birchfield, S., 2018\. *Training Deep Networks
    with Synthetic Data: Bridging the Reality Gap by Domain Randomization. In: 2018
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*.
    *Presented at the 2018 IEEE/CVF CVPRW, IEEE, Salt Lake City, UT, pp. 1082–10828*.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tremblay, J., Prakash, A., Acuna, D., Brophy, M., Jampani, V., Anil, C., To,
    T., Cameracci, E., Boochoon, S., Birchfield, S., 2018\. *使用合成数据训练深度网络：通过领域随机化弥合现实差距。见：2018
    IEEE/CVF计算机视觉与模式识别研讨会（CVPRW）。在2018 IEEE/CVF CVPRW上展示，IEEE，盐湖城，美国，页1082–10828*。
- en: 'Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., 2017\. *Adversarial Discriminative
    Domain Adaptation. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR)*. *Presented at the 2017 IEEE CVPR, IEEE, Honolulu, HI, pp. 2962–2971*.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., 2017\. *对抗性辨别领域适应。见：2017 IEEE计算机视觉与模式识别会议（CVPR）。在2017
    IEEE CVPR上展示，IEEE，檀香山，美国，页2962–2971*。
- en: 'Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., 2017\. *Unpaired Image-to-Image
    Translation Using Cycle-Consistent Adversarial Networks. In: Proceedings of the
    IEEE International Conference on Computer Vision, pp. 2223–2232*.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., 2017\. *使用循环一致的对抗网络进行非配对图像到图像的转换。见：IEEE国际计算机视觉会议论文集，页2223–2232*。
- en: 'Chapter 8: Video and Recurrent Neural Networks'
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章：视频与递归神经网络
- en: Britz, D., 2015\. *Recurrent Neural Networks Tutorial, Part 3 – Backpropagation
    Through Time and Vanishing Gradients. WildML*.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Britz, D., 2015\. *递归神经网络教程，第三部分 – 时间反向传播与梯度消失。WildML*。
- en: 'Brown, C., 2019\. *repo for learning neural nets and related material: go2carter/nn-learn.*'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown, C., 2019\. *用于学习神经网络及相关资料的仓库：go2carter/nn-learn*。
- en: '*Chung, J., Gulcehre, C., Cho, K., Bengio, Y., 2014\. Empirical Evaluation
    of Gated Recurrent Neural Networks on Sequence Modeling. arXiv:1412.3555 [cs]*.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Chung, J., Gulcehre, C., Cho, K., Bengio, Y., 2014\. 门控递归神经网络在序列建模中的实证评估。arXiv:1412.3555
    [cs]*。'
- en: Hochreiter, S., Schmidhuber, J., 1997\. *Long Short-Term Memory. Neural Computation
    9, 1735–1780*.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter, S., Schmidhuber, J., 1997\. *长短期记忆。神经计算 9, 1735–1780*。
- en: Lipton, Z.C., Berkowitz, J., Elkan, C., 2015\. *A Critical Review of Recurrent
    Neural Networks for Sequence Learning. arXiv:1506.00019 [cs]*.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lipton, Z.C., Berkowitz, J., Elkan, C., 2015\. *递归神经网络在序列学习中的关键回顾。arXiv:1506.00019
    [cs]*。
- en: 'Soomro, K., Zamir, A.R., Shah, M., 2012\. *UCF101: A Dataset of 101 Human Actions
    Classes From Videos in The Wild. arXiv:1212.0402 [cs]*.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Soomro, K., Zamir, A.R., Shah, M., 2012\. *UCF101：来自野外视频的101个人类动作类别数据集。arXiv:1212.0402
    [cs]*。
- en: 'Chapter 9: Optimizing Models and Deploying on Mobile Devices'
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章：优化模型并部署到移动设备
- en: 'Goodfellow, I.J., Erhan, D., Carrier, P.L., Courville, A., Mirza, M., Hamner,
    B., Cukierski, W., Tang, Y., Thaler, D., Lee, D.-H., Zhou, Y., Ramaiah, C., Feng,
    F., Li, R., Wang, X., Athanasakis, D., Shawe-Taylor, J., Milakov, M., Park, J.,
    Ionescu, R., Popescu, M., Grozea, C., Bergstra, J., Xie, J., Romaszko, L., Xu,
    B., Chuang, Z., Bengio, Y., 2013\. *Challenges in Representation Learning: A Report
    on Three Machine Learning Contests. arXiv:1307.0414 [cs, stat]*.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow, I.J., Erhan, D., Carrier, P.L., Courville, A., Mirza, M., Hamner,
    B., Cukierski, W., Tang, Y., Thaler, D., Lee, D.-H., Zhou, Y., Ramaiah, C., Feng,
    F., Li, R., Wang, X., Athanasakis, D., Shawe-Taylor, J., Milakov, M., Park, J.,
    Ionescu, R., Popescu, M., Grozea, C., Bergstra, J., Xie, J., Romaszko, L., Xu,
    B., Chuang, Z., Bengio, Y., 2013\. *表示学习中的挑战：三项机器学习竞赛报告。arXiv:1307.0414 [cs, stat]*。
- en: Hinton, G., Vinyals, O., Dean, J., 2015\. *Distilling the Knowledge in a Neural
    Network. arXiv:1503.02531 [cs, stat]*.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton, G., Vinyals, O., Dean, J.，2015年。*从神经网络中提取知识。arXiv:1503.02531 [cs, stat]*。
- en: Hoff, T., n.d. *The Technology Behind Apple Photos and the Future of Deep Learning
    and Privacy – High Scalability*.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoff, T.，未注明日期。*苹果照片背后的技术以及深度学习与隐私的未来——高可扩展性*。
- en: '*Tencent, n.d. Tencent/PocketFlow: An Automatic Model Compression (AutoMC)
    Framework for Developing Smaller and Faster AI Applications*.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*腾讯，未注明日期。腾讯/PocketFlow：一个用于开发更小、更快的AI应用的自动模型压缩（AutoMC）框架*。'
