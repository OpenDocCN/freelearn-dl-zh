- en: Applications of Deep Learning in NLP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在自然语言处理中的应用
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Classification of emails using deep neural networks after generating TF-IDF
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成TF-IDF后，使用深度神经网络进行电子邮件分类
- en: IMDB sentiment classification using convolutional networks CNN 1D
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积神经网络CNN 1D进行IMDB情感分类
- en: IMDB sentiment classification using bidirectional LSTM
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用双向LSTM进行IMDB情感分类
- en: Visualization of high-dimensional words in 2D with neural word vector visualization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经词向量可视化在二维空间中可视化高维词汇
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In recent times, deep learning has become very prominent in the application
    of text, voice, and image data to obtain state-of-the-art results, which are primarily
    used in the creation of applications in the field of artificial intelligence.
    However, these models turn out to be producing such results in all the fields
    of application. In this chapter, we will be covering various applications in NLP/text
    processing.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，深度学习在文本、语音和图像数据的应用中变得非常突出，获得了最先进的结果，这些结果主要用于人工智能领域应用的创建。然而，这些模型证明在所有应用领域都能产生这样的结果。本章将涵盖自然语言处理（NLP）/文本处理中的各种应用。
- en: Convolutional neural networks and recurrent neural networks are central themes
    in deep learning that you will keep meeting across the domain.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络和循环神经网络是深度学习中的核心主题，您将在整个领域中不断遇到。
- en: Convolutional neural networks
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: 'CNNs are primarily used in image processing to classify images into a fixed
    set of categories and so on. CNN''s working principle has been described in the
    following diagram, wherein a filter of size 3 x 3 convolves over the original
    matrix of size 5 x 5, which produces an output of size 3 x 3\. The filter can
    stride horizontally by a step size of 1 or any value greater than 1 also. For
    cell (1, 1) the value obtained is 3, which is a product of the underlying matrix
    value and filter values. In this way, the filter will hover across the original
    5 x 5 matrix to create convolved features of 3 x 3, also known as activation maps:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）主要用于图像处理，将图像分类为固定类别等。CNN的工作原理已在下图中描述，其中一个3x3的滤波器对一个5x5的原始矩阵进行卷积，产生一个3x3的输出。滤波器可以按步长1或大于1的值水平滑动。对于单元（1,1），得到的值是3，它是底层矩阵值和滤波器值的乘积。通过这种方式，滤波器将遍历原始5x5矩阵，生成3x3的卷积特征，也称为激活图：
- en: '![](img/1f0de83f-8f28-4815-8546-e0291f2381ed.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f0de83f-8f28-4815-8546-e0291f2381ed.png)'
- en: 'The advantages of using convolutions:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用卷积的优点：
- en: Instead of a fixed size, fully connected layers save the number of neurons and
    hence the computational power requirement of the machine.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与固定大小不同，完全连接的层节省了神经元的数量，从而减少了机器的计算能力需求。
- en: Only a small size of filter weights is used to hover across the matrix, rather
    than each pixel connected to the next layers. So this is a better way of summarization
    of the input image into the next layers.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只使用小尺寸的滤波器权重在矩阵上滑动，而不是每个像素连接到下一个层。因此，这是一种更好的方式，将输入图像摘要到下一个层。
- en: During backpropagation, only the weights of the filter need to be updated based
    on the backpropagated errors, hence the higher efficiency.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在反向传播过程中，只需根据反向传播的误差更新滤波器的权重，因此效率较高。
- en: 'CNNs perform mappings between spatially/temporally distributed arrays in arbitrary
    dimensions. They appear to be suitable for application to time series, images,
    or videos. CNNs are characterized by:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: CNN执行空间/时间分布数组之间的映射，适用于时间序列、图像或视频等应用。CNN的特点包括：
- en: Translation invariance (neural weights are fixed with respect to spatial translation)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平移不变性（神经权重在空间平移方面是固定的）
- en: Local connectivity (neural connections exist only between spatially local regions)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 局部连接（神经连接仅存在于空间上局部的区域之间）
- en: An optional progressive decrease in spatial resolution (as the number of features
    is gradually increased)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间分辨率的可选逐渐降低（随着特征数量的逐步增加）
- en: 'After convolution, the convolved feature/activation map needs to be reduced
    based on the most important features, as the same operation reduces the number
    of points and improves computational efficiency. Pooling is an operation typically
    performed to reduce unnecessary representations. Brief details about pooling operations
    are given as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积后，卷积特征/激活图需要根据最重要的特征进行降维，因为相同的操作减少了点数并提高了计算效率。池化是通常用来减少不必要表示的操作。关于池化操作的简要说明如下：
- en: '**Pooling**: Pooling makes the activation representation (obtained from convolving
    the filter over the input combination of input and weight values) smaller and
    more manageable. It operates over each activation map independently. Pooling applies
    to the width and breadth of the layer, and the depth will remain the same during
    the pooling stage. In the following diagram, a pooling operation of 2 x 2 is explained.
    Every original 4 x 4 matrix has been reduced by half. In the first four cell values
    of 2, 4, 5, and 8, the maximum is extracted, which is 8:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**池化（Pooling）**：池化使得激活表示（从在输入组合和权重值上进行卷积的滤波器获得）变小且更易管理。它独立地作用于每个激活映射。在池化阶段，宽度和高度将被应用，而深度在此过程中将保持不变。在下图中，解释了一个2
    x 2的池化操作。每个原始的4 x 4矩阵已经缩小了一半。在前四个单元格值2、4、5和8中，提取了最大值，即8：'
- en: '![](img/3170d0b6-f394-4a6e-892a-e4cfa2098e20.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3170d0b6-f394-4a6e-892a-e4cfa2098e20.png)'
- en: Due to the operation of convolution, it is natural that the size of pixels/input
    data size reduces over the stages. But in some cases, we would really like to
    maintain the size across operations. A hacky way to achieve this is padding with
    zeros at the top layer accordingly.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积的操作，像素/输入数据大小在各个阶段自然会减少。但在某些情况下，我们确实希望在操作中保持大小。一种可行的方法是在顶层相应地用零填充。
- en: '**Padding**: The following diagram (its width and breadth) will be shrunk consecutively;
    this is undesirable in deep networks, and padding keeps the size of the picture
    constant or controllable in size throughout the network.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**填充（Padding）**：以下图（其宽度和深度）将依次缩小；这在深度网络中是不希望的，填充可以保持图片大小在整个网络中恒定或可控。'
- en: '![](img/06710dbf-06c0-4d56-83ef-24aa6b2c386b.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06710dbf-06c0-4d56-83ef-24aa6b2c386b.png)'
- en: A simple equation for calculating the activation map size based on given input
    width, filter size, padding, and stride is shown as follows. This equation gives
    an idea of how much computational power is needed, and so on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 基于给定的输入宽度、滤波器大小、填充和步长的简单方程如下所示。这个方程给出了需要多少计算能力的概念，等等。
- en: '**Calculation of activation map size**: In the following formula, the size
    of the activation map obtained from the convolutional layer is:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活映射大小的计算**：在下面的公式中，从卷积层获得的激活映射的大小是：'
- en: '![](img/ed1eab2b-75be-4e81-9f68-bebb519fda72.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed1eab2b-75be-4e81-9f68-bebb519fda72.png)'
- en: Where, *W* is the width of original image, *F* is the filter size, *P* is padding
    size (*1* for a single layer of padding, *2* for a double layer of padding, and
    so on), *S* is stride length
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*W*是原始图像的宽度，*F*是滤波器大小，*P*是填充大小（单层填充为*1*，双层填充为*2*，依此类推），*S*是步长长度
- en: For example, consider an input image of size 224 x 224 x 3 (3 indicates Red,
    Green, and Blue channels), with a filter size of 11 x 11 and number of filters
    as 96\. The stride length is 4 and there is no padding. What is the activation
    map size generated out from these filters?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个大小为224 x 224 x 3的输入图像（3表示红、绿和蓝通道），滤波器大小为11 x 11，滤波器数量为96。步长为4，没有填充。这些滤波器生成的激活映射大小是多少？
- en: '![](img/6267bd0f-60a3-4992-914d-1a5380ac7ce1.png)![](img/184c95da-33a8-4650-b17d-def9e96dd982.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6267bd0f-60a3-4992-914d-1a5380ac7ce1.png)![](img/184c95da-33a8-4650-b17d-def9e96dd982.png)'
- en: The activation map dimensions would be 55 x 55 x 96\. Using the preceding formula,
    only width and depth can be computed, but the depth depends on the number of filters
    used. In fact, this is what was obtained in step 1 after convolution stage in
    AlexNet, which we will describe now.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 激活映射的维度将是55 x 55 x 96。使用前述公式，只能计算宽度和深度，但深度取决于使用的滤波器数量。事实上，在AlexNet的卷积阶段第一步骤中得到了这个结果，我们现在将进行描述。
- en: '**AlexNet used in ImageNet competition during 2012**: The following image describes
    AlexNet, developed to win the ImageNet competition during 2012\. It produced significantly
    more accuracy compared with other competitors.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AlexNet在2012年ImageNet竞赛中的应用**：以下图描述了AlexNet，在2012年的ImageNet竞赛中获胜。它相比其他竞争者显著提高了准确性。'
- en: '![](img/28456fad-7aea-4783-949f-e3bd0ec3dc14.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/28456fad-7aea-4783-949f-e3bd0ec3dc14.png)'
- en: In AlexNet, all techniques such as convolution, pooling, and padding have been
    used, and finally get connected with the fully connected layer.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在AlexNet中，所有技术如卷积、池化和填充都被使用，并最终与全连接层连接。
- en: Applications of CNNs
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN的应用
- en: 'CNNs are used in various applications, a few of them are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs在各种应用中被使用，以下是其中的几个例子：
- en: '**Image classification**: Compared with other methods, CNNs achieve higher
    accuracy on large-scale images of data size. In image classification, CNNs are
    used at the initial stage, and once enough features are extracted using pooling
    layers, followed by other CNNs and so on, will be finally connected with the fully
    connected layers to classify them into the number of given classes.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分类**：与其他方法相比，CNN在大规模图像数据集上具有更高的准确性。在图像分类中，CNN在初始阶段被使用，一旦通过池化层提取了足够的特征，接着使用其他CNN层，最后通过全连接层将它们分类到指定类别中。'
- en: '**Face recognition**: CNNs are invariant to position, brightness, and so on, which
    will recognize faces from images and process them despite bad lighting, a face
    looking sideways, and so on.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸识别**：CNN对位置、亮度等不变，这使得它能够从图像中识别人脸，并在光线不佳、人脸侧面朝向等情况下依然能够处理图像。'
- en: '**Scene labeling**: Each pixel is labeled with the category of the object it
    belongs to in scene labeling. CNNs are utilized here to combine pixels in a hierarchical
    manner.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景标注**：在场景标注中，每个像素都会被标记为它所属的物体类别。这里使用卷积神经网络（CNN）以层次化的方式将像素组合在一起。'
- en: '**NLP**: In NLP, CNNs are used similarly with bag-of-words, in which the sequence
    of words does not play a critical role in identifying the final class of email/text
    and so on. CNNs are used on matrices, which are represented by sentences in vector
    format. Subsequently, filters are applied but CNNs are one-dimensional, in which
    width is constant, and filters traverse only across height (the height is 2 for
    bi-grams, 3 for tri-grams, and so on).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理（NLP）**：在NLP中，CNN与词袋模型类似使用，其中词语的顺序在识别电子邮件/文本等的最终类别时并不起关键作用。CNN被应用于矩阵，这些矩阵由句子以向量形式表示。随后，滤波器会应用于其中，但CNN是单维的，宽度保持不变，滤波器仅在高度（对于二元组，高度为2；对于三元组，高度为3，依此类推）上进行遍历。'
- en: Recurrent neural networks
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: 'A recurrent neural network is used to process a sequence of vectors X by applying
    a recurrence formula at every time step. In convolutional neural networks, we
    assume all inputs are independent of each other. But in some tasks, inputs are
    dependent on each other, for example, time series forecasting data, or predicting
    the next word in a sentence depending on past words, and so on, which needs to
    be modeled by considering dependency of past sequences. These types of problems
    are modeled with RNNs as they provide better accuracy, In theory, RNNs can make
    use of information in arbitrarily long sequences, but in practice, they are limited
    to looking back only for a few steps. The next formula explains the RNN functionality:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络用于处理一系列向量X，通过在每个时间步应用递归公式。在卷积神经网络中，我们假设所有输入是彼此独立的。但在某些任务中，输入是相互依赖的，例如时间序列预测数据，或根据过去的词预测句子的下一个词等，这些都需要通过考虑过去序列的依赖关系来建模。这类问题通过RNN进行建模，能够提供更高的准确性。理论上，RNN能够利用任意长序列中的信息，但实际上，它们仅限于回顾过去的几个步骤。下述公式解释了RNN的功能：
- en: '![](img/6c951b2a-f3cd-4761-895c-174e48adebef.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c951b2a-f3cd-4761-895c-174e48adebef.png)'
- en: '![](img/3d3b30c1-c0b3-4000-91be-d2499713d1c4.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d3b30c1-c0b3-4000-91be-d2499713d1c4.png)'
- en: '![](img/ebc6d56d-0880-4b8f-ba97-517c5726551c.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebc6d56d-0880-4b8f-ba97-517c5726551c.png)'
- en: '![](img/dbcf9f07-3081-48ae-b330-7d04b13bd121.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dbcf9f07-3081-48ae-b330-7d04b13bd121.png)'
- en: '![](img/db890bd1-2148-4e01-96c4-2cb3ca05aad3.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db890bd1-2148-4e01-96c4-2cb3ca05aad3.png)'
- en: '![](img/d39ddee4-9fdf-44bd-8c93-072018b21b35.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d39ddee4-9fdf-44bd-8c93-072018b21b35.png)'
- en: '![](img/5a7099c1-83bd-4c00-a499-c47d03cbc953.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5a7099c1-83bd-4c00-a499-c47d03cbc953.png)'
- en: '**Vanishing or exploding the gradient problem in RNNs**: Gradients does vanish
    quickly with the more number of layers and this issue is severe with RNNs as at
    each layer there are many time steps which also do occur and recurrent weights
    are multiplicative in nature, hence gradients either explode or vanish quickly,
    which makes neural networks untrainable. Exploding gradients can be limited by
    using a gradient clipping technique, in which an upper limit will be set to explode
    the gradients, but however vanishing gradient problem still does exists. This
    issue can be overcome by using **long short-term memory** (**LSTM**) networks.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RNN中的梯度消失或爆炸问题**：随着层数的增加，梯度会迅速消失，这个问题在RNN中尤为严重，因为在每一层都会有很多时间步，而循环权重本质上是乘法性的，因此梯度要么爆炸，要么迅速消失，这使得神经网络无法训练。通过使用梯度裁剪技术，可以限制梯度爆炸，设定一个上限来限制梯度的爆炸，但消失梯度问题仍然存在。这个问题可以通过使用**长短期记忆**（**LSTM**）网络来克服。'
- en: '**LSTM**: LSTM is an artificial neural network contains LSTM blocks in addition
    to regular network units. LSTM blocks contain gates that determine when the input
    is significant enough to remember, when it should continue to remember or when
    it should forget the value, and when it should output the value.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LSTM**：LSTM 是一种人工神经网络，除了常规的网络单元外，还包含 LSTM 块。LSTM 块包含门控机制，用于决定何时输入的内容足够重要以被记住，何时需要继续记住，何时需要忘记该值，以及何时输出该值。'
- en: '![](img/71294f9c-1aff-473a-8966-8cb7616da3d4.png)![](img/b706152e-fc50-47a8-b1df-d695e7c5ab26.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/71294f9c-1aff-473a-8966-8cb7616da3d4.png)![](img/b706152e-fc50-47a8-b1df-d695e7c5ab26.png)'
- en: Vanishing and exploding gradient problems do not occur in LSTM as the same is
    an additive model rather than multiplicative model which is the case with RNN.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 不会发生梯度消失和爆炸问题，因为它是加性模型，而不是 RNN 中的乘法模型。
- en: Application of RNNs in NLP
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RNN 在 NLP 中的应用
- en: RNNs have shown great success in many NLP tasks. The most commonly used variant
    of RNN is LSTM due to overcoming the issue of vanishing/exploding gradients.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 在许多 NLP 任务中取得了巨大成功。RNN 最常用的变体是 LSTM，因为它克服了梯度消失/爆炸的问题。
- en: '**Language modeling**: Given a sequence of words, the task is to predict the
    next probable word'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言建模**：给定一系列单词，任务是预测下一个可能的单词'
- en: '**Text generation**: To generate text from the writings of some authors'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成**：从某些作者的作品中生成文本'
- en: '**Machine translation**: To convert one language into other language (English
    to Chinese and so on.)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器翻译**：将一种语言转换为另一种语言（如英语到中文等）'
- en: '**Chat bot**: This application is very much like machine translation; however
    question and answer pairs are used to train the model'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天机器人**：这个应用非常类似于机器翻译；然而，问答对被用来训练模型'
- en: '**Generating an image description**: By training together with CNNs, RNNs can
    be used to generate a caption/description of the image'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成图像描述**：通过与 CNN 一起训练，RNN 可用于生成图像的标题/描述'
- en: Classification of emails using deep neural networks after generating TF-IDF
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在生成 TF-IDF 后使用深度神经网络对电子邮件进行分类
- en: In this recipe, we will use deep neural networks to classify emails into one
    of the 20 pre-trained categories based on the words present in each email. This
    is the simple model to start with to understand the subject of deep learning and
    its applications on NLP.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将使用深度神经网络根据每封电子邮件中出现的单词将电子邮件分类到 20 个预训练类别之一。这是一个简单的模型，可以帮助我们理解深度学习的主题及其在
    NLP 中的应用。
- en: Getting ready
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The 20 newsgroups dataset from scikit-learn have been utilized to illustrate
    the concept. Number of observations/emails considered for analysis are 18,846
    (train observations - 11,314 and test observations - 7,532) and its corresponding
    classes/categories are 20, which are shown in the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用来自 scikit-learn 的 20 个新闻组数据集来说明该概念。用于分析的观察/电子邮件数量为 18,846（训练数据 - 11,314，测试数据
    - 7,532），其对应的类别/类为 20，如下所示：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the following screenshot, a sample first data observation and target class
    category has been shown. From the first observation or email we can infer that
    the email is talking about a two-door sports car, which we can classify manually
    into autos category which is `8`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，展示了一个样本的首个数据观察及目标类别。通过第一个观察或电子邮件，我们可以推断出该电子邮件是在谈论一辆双门跑车，我们可以将其手动分类为汽车类别
    `8`。
- en: Target value is `7` due to the indexing starts from `0`), which is validating
    our understanding with actual target class `7`
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目标值是 `7`（由于索引从 `0` 开始），这验证了我们对实际目标类别 `7` 的理解。
- en: '![](img/1afe5527-7747-4d8e-9cce-291ed16337a9.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1afe5527-7747-4d8e-9cce-291ed16337a9.png)'
- en: How to do it...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Using NLP techniques, we have pre-processed the data for obtaining finalized
    word vectors to map with final outcomes spam or ham. Major steps involved are:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 NLP 技术，我们已经对数据进行了预处理，以获得最终的单词向量，并与最终结果（垃圾邮件或正常邮件）进行映射。主要步骤包括：
- en: Pre-processing.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理。
- en: Removal of punctuations.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除标点符号。
- en: Word tokenization.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单词分词。
- en: Converting words into lowercase.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将单词转换为小写字母。
- en: Stop word removal.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 停用词移除。
- en: Keeping words of length of at least 3.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持单词长度至少为 3。
- en: Stemming words.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词干提取。
- en: POS tagging.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词性标注。
- en: 'Lemmatization of words:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词形还原：
- en: TF-IDF vector conversion.
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: TF-IDF 向量转换。
- en: Deep learning model training and testing.
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度学习模型训练与测试。
- en: Model evaluation and results discussion.
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估和结果讨论。
- en: How it works...
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The NLTK package has been utilized for all the pre-processing steps, as it
    consists of all the necessary NLP functionality under one single roof:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 已经使用NLTK包处理了所有的预处理步骤，因为它包含了所有必要的NLP功能，集中在一个平台上：
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The function written (pre-processing) consists of all the steps for convenience.
    However, we will be explaining all the steps in each section:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 编写的函数（预处理）包含了所有步骤，便于操作。然而，我们将在每个章节中解释每一步：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following line of the code splits the word and checks each character to
    see if it contains any standard punctuations, if so it will be replaced with a
    blank or else it just don''t replace with blank:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行将单词拆分，并检查每个字符是否包含任何标准标点符号，如果包含则替换为空格，否则保持不变：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following code tokenizes the sentences into words based on whitespaces
    and puts them together as a list for applying further steps:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将句子根据空格分词，并将它们组合成一个列表以应用进一步步骤：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Converting all the cases (upper, lower and proper) into lower case reduces
    duplicates in corpus:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有大小写（大写、小写和专有名词）转为小写，可以减少语料库中的重复：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As mentioned earlier, Stop words are the words that do not carry much of weight
    in understanding the sentence; they are used for connecting words and so on. We
    have removed them with the following line of code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，停用词是那些在理解句子时没有太多意义的词，它们用于连接词等。我们已通过以下代码将它们移除：
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Keeping only the words with length greater than `3` in the following code for
    removing small words which hardly consists of much of a meaning to carry;
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，仅保留长度大于`3`的单词，用于去除那些几乎没有意义的小词；
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Stemming applied on the words using Porter stemmer which stems the extra suffixes
    from the words:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Porter词干提取器对单词进行词干化，从单词中去除多余的后缀：
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: POS tagging is a prerequisite for lemmatization, based on whether word is noun
    or verb or and so on. it will reduce it to the root word
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注是词形还原的前提，基于词汇是名词、动词等，它将词汇简化为词根。
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`pos_tag` function returns the part of speed in four formats for Noun and six
    formats for verb. NN - (noun, common, singular), NNP - (noun, proper, singular),
    NNPS - (noun, proper, plural), NNS - (noun, common, plural), VB - (verb, base
    form), VBD - (verb, past tense), VBG - (verb, present participle), VBN - (verb,
    past participle), VBP - (verb, present tense, not 3rd person singular), VBZ -
    (verb, present tense, third person singular)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`pos_tag`函数返回四种名词格式和六种动词格式。NN -（名词，普通，单数），NNP -（名词，专有，单数），NNPS -（名词，专有，复数），NNS
    -（名词，普通，复数），VB -（动词，原形），VBD -（动词，过去式），VBG -（动词，现在分词），VBN -（动词，过去分词），VBP -（动词，现在时，非第三人称单数），VBZ
    -（动词，现在时，第三人称单数）'
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following function, `prat_lemmatize`, has been created only for the reasons
    of mismatch between the `pos_tag` function and intake values of `lemmatize` function.
    If the tag for any word falls under the respective noun or verb tags category,
    `n` or `v` will be applied accordingly in `lemmatize` function:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数`prat_lemmatize`仅为了解决`pos_tag`函数与`lemmatize`函数输入值不匹配的问题而创建。如果某个单词的标签属于名词或动词类别，则`lemmatize`函数将分别应用`n`或`v`标签：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After performing tokenization and applied all the various operations, we need
    to join it back to form stings and the following function performs the same:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行分词并应用所有操作后，我们需要将其重新组合成字符串，以下函数执行了此操作：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Applying pre-processing on train and test data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对训练数据和测试数据应用预处理：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'After the pre-processing step has been completed, processed TF-IDF vectors
    have to be sent to the following deep learning code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理步骤完成后，处理后的TF-IDF向量需要传入以下深度学习代码：
- en: '[PRE14]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The following image produces the output after firing up the preceding Keras
    code. Keras has been installed on Theano, which eventually works on Python. A
    GPU with 6 GB memory has been installed with additional libraries (CuDNN and CNMeM)
    for four to five times faster execution, with a choking of around 20% memory;
    hence only 80% memory out of 6 GB is available;
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了运行前面Keras代码后产生的输出。Keras已经在Theano上安装，并且最终在Python上运行。安装了一块6GB内存的GPU，并添加了额外的库（CuDNN和CNMeM），使执行速度提高了四到五倍，同时内存占用约为20%，因此仅有80%的6GB内存可用；
- en: '![](img/32236634-34b3-4191-891e-e41530804966.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32236634-34b3-4191-891e-e41530804966.png)'
- en: 'The following code explains the central part of the deep learning model. The
    code is self-explanatory, with the number of classes considered `20`, batch size
    `64`, and number of epochs to train, `20`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码解释了深度学习模型的核心部分。代码是自解释的，考虑到的类别数为`20`，批次大小为`64`，训练的epoch数为`20`：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following code converts the `20` categories into one-hot encoding vectors
    in which `20` columns are created and the values against the respective classes
    are given as `1`. All other classes are given as `0`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将`20`个类别转换为一热编码向量，其中创建了`20`列，并且对应类别的值为`1`。所有其他类别的值为`0`：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the following building blocks of Keras code, three hidden layers (`1000`,
    `500`, and `50` neurons in each layer respectively) are used, with dropout as
    50% for each layer with Adam as an optimizer:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下的Keras代码构建模块中，使用了三个隐藏层（每层分别有`1000`、`500`和`50`个神经元），每层的dropout为50%，并使用Adam优化器：
- en: '[PRE17]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The architecture is shown as follows and describes the flow of the data from
    a start of 10,000 as input. Then there are `1000`, `500`, `50`, and `20` neurons
    to classify the given email into one of the `20` categories:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 架构如下所示，描述了从输入开始为10,000的数据流。然后有`1000`、`500`、`50`和`20`个神经元，将给定的电子邮件分类到`20`个类别中的一个：
- en: '![](img/665d79f4-cae5-4110-a960-1eccd8cd3b6f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/665d79f4-cae5-4110-a960-1eccd8cd3b6f.png)'
- en: 'The model is trained as per the given metrics:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是根据给定的指标进行训练的：
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The model has been fitted with 20 epochs, in which each epoch took about 2
    seconds. The loss has been minimized from `1.9281` to `0.0241`. By using CPU hardware,
    the time required for training each epoch may increase as a GPU massively parallelizes
    the computation with thousands of threads/cores:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已经在20个epoch中进行了拟合，每个epoch大约需要2秒钟。损失从`1.9281`减少到`0.0241`。使用CPU硬件时，每个epoch所需的时间可能会增加，因为GPU通过数千个线程/核心并行计算大大加速了计算：
- en: '![](img/0566ec9a-9f67-4733-b22d-a199c949fecb.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0566ec9a-9f67-4733-b22d-a199c949fecb.png)'
- en: 'Finally, predictions are made on the train and test datasets to determine the
    accuracy, precision, and recall values:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在训练集和测试集上进行预测，以确定准确率、精度和召回值：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/072cd7f7-a8ef-4989-a480-3b3a80a27faa.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/072cd7f7-a8ef-4989-a480-3b3a80a27faa.png)'
- en: It appears that the classifier is giving a good 99.9% accuracy on the train
    dataset and 80.7% on the test dataset.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来分类器在训练数据集上提供了99.9%的准确率，在测试数据集上则为80.7%。
- en: IMDB sentiment classification using convolutional networks CNN 1D
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积神经网络CNN 1D进行IMDB情感分类
- en: In this recipe, we will use the Keras IMDB movie review sentiment data, which
    has labeled its sentiment (positive/negative). Reviews are pre-processed, and
    each review is already encoded as a sequence of word indexes (integers). However,
    we have decoded it to show a you sample in the following code.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用Keras IMDB电影评论情感数据，该数据已经标注了情感（正面/负面）。评论已经过预处理，每个评论已经被编码为一个单词索引序列（整数）。然而，我们已将其解码，以下代码中展示了一个示例。
- en: Getting ready
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'The IMDB dataset from Keras has a set of words and its respective sentiment.
    The following is the pre-processing of the data:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Keras中的IMDB数据集包含一组单词及其相应的情感。以下是数据的预处理过程：
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In this set of parameters, we did put maximum features or number of words to
    be extracted are 6,000 with maximum length of an individual sentence as 400 words:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一组参数中，我们设置了最大特征或要提取的单词数为6,000，并且单个句子的最大长度为400个单词：
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The dataset has an equal number of train and test observations, in which we
    will build a model on 25,000 observations and test the trained model on the test
    data with 25,000 data observations. A sample of data can be seen in this screenshot:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集具有相同数量的训练和测试观察值，我们将在25,000个观察值上构建模型，并在测试数据的25,000个数据观察值上测试训练好的模型。以下截图展示了数据的一个示例：
- en: '![](img/f07abcac-0aa8-4375-8d77-43dc55726312.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f07abcac-0aa8-4375-8d77-43dc55726312.png)'
- en: 'The following code is used to create the dictionary mapping of a word and its
    respective integer index value:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于创建单词及其相应整数索引值的字典映射：
- en: '[PRE22]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We see the first observation as a set of numbers rather than any English word,
    because the computer can only understand and work with numbers rather than characters,
    words, and so on:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到的第一个观察值是数字的集合，而不是任何英文单词，因为计算机只能理解并处理数字，而不是字符、单词等：
- en: '![](img/75264b5f-29a6-4688-a678-f98f27f46e03.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75264b5f-29a6-4688-a678-f98f27f46e03.png)'
- en: 'Decoding using a created dictionary of inverse mapping is shown here:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用创建的逆映射字典进行解码，如下所示：
- en: '[PRE23]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following screenshot describes the stage after converting a number mapping
    into textual format. Here, dictionaries are utilized to reverse a map from integer
    format to text format:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图描述了将数字映射转换为文本格式后的阶段。在这里，字典被用来反转从整数格式到文本格式的映射：
- en: '![](img/f4e42ef6-d95d-464b-b523-d4c8cba3a207.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f4e42ef6-d95d-464b-b523-d4c8cba3a207.png)'
- en: How to do it...
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The major steps involved are described as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 主要步骤如下：
- en: Pre-processing, during this stage, we do pad sequences to bring all observations
    into one fixed dimension, which enhances speed and enables computation.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理：在此阶段，我们对序列进行填充，使所有观察值具有相同的固定维度，这有助于提高速度并实现计算。
- en: CNN 1D model development and validation.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CNN 1D模型的开发与验证。
- en: Model evaluation.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估。
- en: How it works...
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The following code does perform padding operation for adding extra sentences
    which can make up to maximum length of 400 words. By doing this, data will become
    even and easier to perform computation using neural networks:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码执行填充操作，添加额外的句子，使其达到最大长度400个单词。通过这样做，数据将变得均匀，并且更容易通过神经网络进行计算：
- en: '[PRE24]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/70c9e3df-a73e-4654-8ead-dab9d254c9eb.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70c9e3df-a73e-4654-8ead-dab9d254c9eb.png)'
- en: 'The following deep learning code describes the application of Keras code to
    create a CNN 1D model:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下深度学习代码描述了应用Keras代码创建CNN 1D模型：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In the following screenshot, the entire model summary has been displayed, indicating
    the number of dimensions and its respective number of neurons utilized. These
    directly impact the number of parameters that will be utilized in computation
    from input data into the final target variable, whether it is `0` or `1`. Hence
    a dense layer has been utilized at the last layer of the network:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下截图中，显示了整个模型的总结，指出了维度数量及其各自的神经元数量。这些直接影响将用于计算的参数数量，从输入数据到最终目标变量（无论是`0`还是`1`）。因此，在网络的最后一层使用了一个全连接层：
- en: '![](img/abdfbfd6-1fb3-465f-ad18-578f32ee6107.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abdfbfd6-1fb3-465f-ad18-578f32ee6107.png)'
- en: 'The following code performs model fitting operation on training data in which
    both `X` and `Y` variables are used to train data by batch wise:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码执行训练数据的模型拟合操作，其中`X`和`Y`变量用于按批次训练数据：
- en: '[PRE26]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The model has been trained for three epochs, in which each epoch consumes 5
    seconds on the GPU. But if we observe the following iterations, even though the
    train accuracy is moving up, validation accuracy is decreasing. This phenomenon
    can be identified as model overfitting. This indicates that we need to try some
    other ways to improve the model accuracy rather than just increase the number
    of epochs. Other ways we probably should look at are increasing the architecture
    size and so on. Readers are encouraged to experiment with various combinations.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已训练三个周期，每个周期在GPU上消耗5秒。但如果我们观察以下迭代，尽管训练准确率在上升，验证准确率却在下降。这个现象可以被识别为模型过拟合。这表明我们需要尝试其他方法来提高模型准确率，而不仅仅是增加训练周期的次数。我们可能应该关注的方法还包括增加架构的规模等。鼓励读者尝试不同的组合。
- en: '![](img/3c7a82dc-aec0-440f-9207-4bbf0a3b3420.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c7a82dc-aec0-440f-9207-4bbf0a3b3420.png)'
- en: 'The following code is used for prediction of classes for both train and test
    data:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于预测训练数据和测试数据的类别：
- en: '[PRE27]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The following screenshot describes various measurable metrics to judge the
    model performance. From the result, the train accuracy seems significantly high
    at 96%; however, the test accuracy is at a somewhat lower value of 88.2 %. This
    could be due to model overfitting:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图描述了用于判断模型性能的各种可度量指标。从结果来看，训练准确率高达96%，然而测试准确率为88.2%，略低。这可能是由于模型过拟合：
- en: '![](img/89ab2d00-affb-4a62-8f93-a38cde3ef341.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89ab2d00-affb-4a62-8f93-a38cde3ef341.png)'
- en: IMDB sentiment classification using bidirectional LSTM
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用双向LSTM进行IMDB情感分类
- en: In this recipe, we are using same IMDB sentiment data to show the difference
    between CNN and RNN methodology in terms of accuracies and so on. Data pre-processing
    steps remain the same; only the architecture of the model varies.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用相同的IMDB情感数据，展示CNN和RNN方法在准确率等方面的差异。数据预处理步骤保持不变，只有模型架构不同。
- en: Getting ready
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'The IMDB dataset from Keras has set of words and its respective sentiment.
    Here is the pre-processing of the data:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Keras中的IMDB数据集包含了一组词汇及其对应的情感。以下是数据的预处理过程：
- en: '[PRE28]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: How to do it...
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The major steps involved are described as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 主要步骤如下：
- en: Pre-processing, during this stage, we do pad sequences to bring all the observations
    into one fixed dimension, which enhances speed and enables computation.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理，在此阶段，我们对序列进行填充，使所有观测值都进入一个固定的维度，从而提高速度并实现计算。
- en: LSTM model development and validation.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTM模型的开发与验证。
- en: Model evaluation.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估。
- en: How it works...
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '[PRE29]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following deep learning code describes the application of Keras code to
    create a bidirectional LSTM model:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 以下深度学习代码描述了Keras代码的应用，用于创建一个双向LSTM模型：
- en: 'Bidirectional LSTMs have a connection from both forward and backward, which
    enables them to fill in the middle words to get connected well with left and right
    words:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 双向LSTM具有来自前向和后向的连接，这使得它们能够填补中间单词，与左右单词更好地连接：
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here is the architecture of the model. The embedding layer has been used to
    reduce the dimensions to `128`, followed by bidirectional LSTM, ending up with
    a dense layer for modeling sentiment either zero or one:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是模型的架构。嵌入层被用来将维度减少到`128`，接着是双向LSTM，最后用一个全连接层来建模情感（0或1）：
- en: '![](img/72079ae1-a362-4078-8f09-a01ad6a0affa.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/72079ae1-a362-4078-8f09-a01ad6a0affa.png)'
- en: 'The following code is used for training the data:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于训练数据：
- en: '[PRE31]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'LSTM models take longer than CNNs because LSTMs are not easily parallelizable
    with GPU (4x to 5x), whereas CNNs (100x) are massively parallelizable. One important
    observation: even after an increase in the training accuracy, the validation accuracy
    was decreasing. This situation indicates overfitting.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM模型的训练时间比CNN长，因为LSTM不容易在GPU上进行并行化（比CNN慢4到5倍），而CNN（100倍）是大规模并行化的。一个重要的观察是：即使训练准确率提高，验证准确率却在下降。这种情况表明出现了过拟合。
- en: '![](img/9887f540-5eb9-4a05-95e8-09a1df5f0d30.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9887f540-5eb9-4a05-95e8-09a1df5f0d30.png)'
- en: 'The following code has been used for predicting the class for both train and
    test data:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于预测训练和测试数据的类别：
- en: '[PRE32]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](img/89f3a771-4199-4c30-9edb-5f571e93abb6.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89f3a771-4199-4c30-9edb-5f571e93abb6.png)'
- en: It appears that LSTM did provide slightly less test accuracy compared with CNN;
    however, with careful tuning of the model parameters, we can obtain better accuracies
    in RNNs compared with CNNs.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来LSTM的测试准确率相较于CNN稍微低一些；然而，通过精心调整模型参数，我们可以在RNN中获得比CNN更好的准确率。
- en: Visualization of high-dimensional words in 2D with neural word vector visualization
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将高维单词在二维中可视化，使用神经网络词向量进行可视化。
- en: In this recipe, we will use deep neural networks to visualize words from a high-dimensional
    space in a two-dimensional space.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方案中，我们将使用深度神经网络，将高维空间中的单词可视化到二维空间中。
- en: Getting ready
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The *Alice in Wonderland* dataset has been used to extract words and create
    a visualization using the dense network made to be like the encoder-decoder architecture:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '*爱丽丝梦游仙境*数据集已被用来提取单词并使用密集网络创建可视化，类似于编码器-解码器架构：'
- en: '[PRE33]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How to do it...
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The major steps involved are described here:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 主要步骤如下所示：
- en: Pre-processing, creation of skip-grams and using the middle word to predict
    either the left or the right word.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理，创建跳字模型，并使用中间单词预测左侧或右侧的单词。
- en: Application of one-hot encoding for feature engineering.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对特征工程应用独热编码。
- en: Model building using encoder-decoder architecture.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用编码器-解码器架构构建模型。
- en: Extraction of the encoder architecture to create two-dimensional features for
    visualization from test data.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取编码器架构，从测试数据中创建用于可视化的二维特征。
- en: How it works...
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The following code creates dictionary, which is a mapping of word to index
    and index to word (vice versa). As we knew, models simply do not work on character/word
    input. Hence, we will be converting words into numeric equivalents (particularly
    integer mapping), and once the computation has been performed using the neural
    network model, the reverse of the mapping (index to word) will be applied to visualize
    them. The counter from the `collections` library has been used for efficient creation
    of dictionaries:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码创建了一个字典，它是单词与索引、索引与单词（反向）的映射。正如我们所知道的，模型不能直接处理字符/单词输入。因此，我们将把单词转换成数字等价物（特别是整数映射），一旦通过神经网络模型完成计算，反向映射（索引到单词）将被应用以进行可视化。`collections`库中的计数器用于高效创建字典：
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following code applies word-to-integer mapping and extracts the tri-grams
    from the embedding. Skip-gram is the methodology in which the central word is
    connected to both left and right adjacent words for training, and if during testing
    phase if it predicts correctly:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码应用了词到整数的映射，并从嵌入中提取三元组。Skip-gram 是一种方法，其中中心单词与左侧和右侧相邻的单词连接进行训练，如果在测试阶段预测正确：
- en: '[PRE35]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The following code describes that the length of the dictionary is the vocabulary
    size. Nonetheless, based on user specification, any custom vocabulary size can
    be chosen. Here, we are considering all words though!
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码描述了字典的长度就是词汇表的大小。不过，根据用户的指定，可以选择任何自定义的词汇表大小。在这里，我们考虑了所有的单词！
- en: '[PRE36]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Based on vocabulary size, all independent and dependent variables are transformed
    into vector representations with the following code, in which the number of rows
    would be the number of words and the number of columns would be the vocabulary
    size. The neural network model basically maps the input and output variables over
    the vector space:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 基于词汇表的大小，所有独立和依赖变量都被转换为向量表示，使用以下代码，其中行数为单词数量，列数为词汇表的大小。神经网络模型基本上是在向量空间中映射输入和输出变量：
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Out of total 13,868 observations, train and test are split into 70% and 30%,
    which are created as 9,707 and 4,161 respectively:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在总共 13,868 个观测值中，训练集和测试集被分为 70% 和 30%，分别为 9,707 和 4,161：
- en: '![](img/e9c7b361-7274-4cdb-ba36-da1b08448548.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e9c7b361-7274-4cdb-ba36-da1b08448548.png)'
- en: The central part of the model is described in the following few lines of deep
    learning code using Keras software. It is a convergent-divergent code, in which
    initially the dimensions of all input words are squeezed to achieve the output
    format.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的核心部分通过以下几行使用 Keras 软件编写的深度学习代码进行描述。这是一个收敛-发散代码，最初将所有输入单词的维度压缩，以达到输出格式。
- en: 'While doing so, the dimensions are reduced to 2D in the second layer. After
    training the model, we will extract up to the second layer for predictions on
    test data. This literally works similar to the conventional encoder-decoder architecture:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，第二层将维度降低到二维。训练完模型后，我们将提取到第二层以对测试数据进行预测。这的工作原理与传统的编码器-解码器架构类似：
- en: '[PRE38]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The following code is used to train the model:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于训练模型：
- en: '[PRE39]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: By carefully observing the accuracy on both the training and validation datasets,
    we can find that the best accuracy values are not even crossing 6%. This happens
    due to limited data and architecture of deep learning models. In order to make
    this really work, we need at least gigabytes of data and large architectures.
    Models too need to be trained for very long. Due to practical constraints and
    illustration purposes, we have just trained for 20 iterations. However, readers
    are encouraged to try various combinations to improve the accuracy.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细观察训练和验证数据集的准确性，我们可以发现最佳准确率值甚至没有超过 6%。这主要是由于数据量有限以及深度学习模型的架构问题。为了使其真正有效，我们需要至少几千兆字节的数据和大型架构。模型也需要训练很长时间。由于实际限制和示范目的，我们仅训练了
    20 次迭代。然而，鼓励读者尝试各种组合以提高准确性。
- en: '![](img/088aa145-de48-42fd-a671-3b2224d6ec9e.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/088aa145-de48-42fd-a671-3b2224d6ec9e.png)'
- en: '[PRE40]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The following image describes the visualization of the words in two-dimensional
    space. Some words are closer to each other than other words, which indicates closeness
    and relationships with nearby words. For example, words such as `never`, `ever`,
    and `ask` are very close to each other.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像描述了在二维空间中单词的可视化。某些单词彼此靠得比其他单词近，这表示它们与附近单词的接近性和关系。例如，`never`、`ever` 和 `ask`
    这些单词彼此非常接近。
- en: '![](img/7bbb0dc1-8d24-4db3-878c-330052d9f83c.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7bbb0dc1-8d24-4db3-878c-330052d9f83c.png)'
