- en: '*Appendix*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*附录*'
- en: About
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于
- en: This section is included to assist the learners to perform the activities present
    in the book. It includes detailed steps that are to be performed by the learners
    to complete and achieve the objectives of the book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容是为了帮助学习者完成书中的活动，内容包括学习者需要执行的详细步骤，以完成并实现书本中的目标。
- en: 'Chapter 1: Introduction to Natural Language Processing'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 1 章：自然语言处理简介
- en: 'Activity 1: Generating word embeddings from a corpus using Word2Vec.'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 1：使用 Word2Vec 从语料库生成词嵌入。
- en: '**Solution:**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Upload the text corpus from the link aforementioned.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从上述链接上传文本语料。
- en: Import the word2vec from gensim models
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 gensim 模型中导入 word2vec
- en: '[PRE0]'
  id: totrans-8
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Store the corpus in a variable.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将语料库存储在一个变量中。
- en: '[PRE1]'
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Fit the word2vec model on the corpus.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在语料库上拟合 word2vec 模型。
- en: '[PRE2]'
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Find the most similar word to 'man'.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到与‘man’最相似的词。
- en: '[PRE3]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.29: Output for similar word embeddings](img/C13783_01_29.jpg)'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.29：相似词嵌入的输出](img/C13783_01_29.jpg)'
- en: 'Figure 1.29: Output for similar word embeddings'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.29：相似词嵌入的输出
- en: '''Father'' is to ''girl'', ''x'' is to boy. Find the top 3 words for x.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ‘Father’对应‘girl’，‘x’对应boy。找出x的前三个词。
- en: '[PRE4]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is as follows:'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.30: Output for top three words for ‘x’'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.30：‘x’的前三个词的输出](img/C13783_02_19.jpg)'
- en: '](img/C13783_01_30.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_01_30.jpg)'
- en: 'Figure 1.30: Output for top three words for ''x'''
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.30：‘x’的前三个词的输出
- en: 'Chapter 2: Applications of Natural Language Processing'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 2 章：自然语言处理的应用
- en: 'Activity 2: Building and training your own POS tagger'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 2：构建并训练你自己的词性标注器
- en: '**Solution:**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: 'The first thing to do is pick a corpus that we want to train our tagger on.
    Import the necessary Python packages. Here, we use the `nltk` `treebank` corpus
    to work on:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一件事是选择我们想要训练标注器的语料。导入必要的 Python 包。在这里，我们使用`nltk` `treebank`语料库进行操作：
- en: '[PRE5]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we need to determine what features our tagger will take into consideration
    when determining what tag to assign to a word. These can include whether the word
    is all capitalized, is in lowercase, or has one capital letter:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要确定我们的标注器在为一个词分配标签时会考虑哪些特征。这些特征可以包括该词是否全大写、是否小写或是否有一个大写字母：
- en: '[PRE6]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create a function to strip the tagged words of their tags so that we can feed
    them into our tagger:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来剥离标注词的标签，以便我们可以将它们输入到标注器中：
- en: '[PRE7]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now we need to build our training set. Our tagger needs to take features individually
    for each word, but our corpus is actually in the form of sentences, so we need
    to do a little transforming. Split the data into training and testing sets. Apply
    this function on the training set.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要构建我们的训练集。我们的标注器需要为每个词单独提取特征，但我们的语料库实际上是句子的形式，所以我们需要做一些转换。将数据拆分为训练集和测试集。对训练集应用此函数。
- en: '[PRE8]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Apply this function on the training set. Now we can train our tagger. It's basically
    a classifier since it's categorizing words into classes, so we can use a classification
    algorithm. You can use any that you like or try out a bunch of them to see which
    works best. Here, we'll use the decision tree classifier. Import the classifier,
    initialize it, and fit the model on the training data. Print the accuracy score.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上应用此函数。现在我们可以训练我们的标注器。它本质上是一个分类器，因为它将词分类到不同的类别中，所以我们可以使用分类算法。你可以使用任何你喜欢的算法，或者尝试多个看看哪个效果最好。这里，我们将使用决策树分类器。导入分类器，初始化它，并将模型拟合到训练数据上。然后打印准确率分数。
- en: '[PRE9]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C13783_02_19.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13783_02_19.jpg)'
- en: 'Figure 2.19: Accuracy score'
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.19：准确率分数
- en: 'Activity 3: Performing NER on a Tagged Corpus'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 3：在标注语料上执行命名实体识别（NER）
- en: '**Solution:**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Import the necessary Python packages and classes.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 包和类。
- en: '[PRE10]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Print the `nltk.corpus.treebank.tagged_sents()` to see the tagged corpus that
    you need extract named entities from.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`nltk.corpus.treebank.tagged_sents()`查看你需要从中提取命名实体的标注语料。
- en: '[PRE11]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Store the first sentence of the tagged sentences in a variable.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标注句子的第一句存储在一个变量中。
- en: '[PRE12]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Use `nltk.ne_chunk` to perform NER on the sentence. Set binary to True and print
    the named entities.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`nltk.ne_chunk`对句子执行命名实体识别（NER）。将binary设置为True并打印命名实体。
- en: '[PRE13]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C13783_02_20.jpg)'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13783_02_20.jpg)'
- en: 'Figure 2.20: NER on tagged corpus'
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.20：在标注语料上的命名实体识别（NER）
- en: 'Chapter 3: Introduction to Neural Networks'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 3 章：神经网络简介
- en: 'Activity 4: Sentiment Analysis of Reviews'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 4：评论的情感分析
- en: '**Solution:**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Open a new `Jupyter` notebook. Import `numpy`, `pandas` and `matplotlib.pyplot`.
    Load the dataset into a dataframe.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的`Jupyter`笔记本。导入`numpy`、`pandas`和`matplotlib.pyplot`。将数据集加载到数据框中。
- en: '[PRE14]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next step is to clean and prepare the data. Import `re` and `nltk`. From `nltk.corpus`
    import `stopwords`. From `nltk.stem.porter`, import `PorterStemmer`. Create an
    array for your cleaned text to be stored in.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是清理和准备数据。导入`re`和`nltk`。从`nltk.corpus`导入`stopwords`。从`nltk.stem.porter`导入`PorterStemmer`。创建一个数组来存储清理后的文本。
- en: '[PRE15]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using a for loop, iterate through every instance (every review). Replace all
    non-alphabets with a ' ' (whitespace). Convert all alphabets into lowercase. Split
    each review into individual words. Initiate the `PorterStemmer`. If the word is
    not a stopword, perform stemming on the word. Join all the individual words back
    together to form a cleaned review. Append this cleaned review to the array you
    created.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用for循环，遍历每个实例（每个评论）。将所有非字母字符替换为`' '`（空格）。将所有字母转换为小写。将每条评论拆分成单个单词。初始化`PorterStemmer`。如果该单词不是停用词，则对该单词进行词干提取。将所有单个单词重新组合成一条清理后的评论。将这条清理后的评论附加到你创建的数组中。
- en: '[PRE16]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Import `CountVectorizer`. Convert the reviews into word count vectors using
    `CountVectorizer`.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`CountVectorizer`。使用`CountVectorizer`将评论转换为词频向量。
- en: '[PRE17]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Create an array to store each unique word as its own column, hence making them
    independent variables.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个数组来存储每个唯一的单词作为独立的列，从而使它们成为独立变量。
- en: '[PRE18]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Import `LabelEncoder` from `sklearn.preprocessing`. Use the `LabelEncoder` on
    the target output (`y`).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.preprocessing`导入`LabelEncoder`。对目标输出（`y`）使用`LabelEncoder`。
- en: '[PRE19]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Import `train_test_split`. Divide the dataset into a training set and a validation
    set.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`train_test_split`。将数据集划分为训练集和验证集。
- en: '[PRE20]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Import `StandardScaler` from `sklearn.preprocessing`. Use the `StandardScaler`
    on the features of both the training set and the validation set (`X`).
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.preprocessing`导入`StandardScaler`。对训练集和验证集（`X`）的特征使用`StandardScaler`。
- en: '[PRE21]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now the next task is to create the neural network. Import `keras`. Import `Sequential`
    from `keras.models` and `Dense` from Keras layers.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在下一个任务是创建神经网络。导入`keras`。从`keras.models`导入`Sequential`，从Keras层导入`Dense`。
- en: '[PRE22]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Initialize the neural network. Add the first hidden layer with '`relu`' as the
    activation function. Repeat step for the second hidden layer. Add the output layer
    with '`softmax`' as the activation function. Compile the neural network, using
    '`adam`' as the optimizer, '`binary_crossentropy`' as the loss function and '`accuracy`'
    as the performance metric.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化神经网络。添加第一个隐藏层，激活函数使用`'relu'`。对第二个隐藏层重复此步骤。添加输出层，激活函数使用`'softmax'`。编译神经网络，使用`'adam'`作为优化器，`'binary_crossentropy'`作为损失函数，`'accuracy'`作为性能评估标准。
- en: '[PRE23]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now we need to train the model. Fit the neural network on the training dataset
    with a `batch_size` of 3 and a `nb_epoch` of 5.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要训练模型。使用`batch_size`为3和`nb_epoch`为5，在训练数据集上拟合神经网络。
- en: '[PRE24]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Validate the model. Evaluate the neural network and print the accuracy scores
    to see how it's doing.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证模型。评估神经网络并打印准确度得分，以查看其表现如何。
- en: '[PRE25]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: (Optional) Print the confusion matrix by importing `confusion_matrix` from `sklearn.metrics`.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）通过从`sklearn.metrics`导入`confusion_matrix`打印混淆矩阵。
- en: '[PRE26]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Your output should look similar to this:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应类似于此：
- en: '![](img/C13783_03_21.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13783_03_21.jpg)'
- en: 'Figure 3.21: Accuracy score for sentiment analysis'
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.21：情感分析的准确度得分
- en: 'Chapter 4: Introduction to convolutional networks'
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四章：卷积网络介绍
- en: 'Activity 5: Sentiment Analysis on a real-life dataset'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 5：对真实数据集进行情感分析
- en: '**Solution:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Import the necessary classes
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的类
- en: '[PRE27]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Define your variables and parameters.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义你的变量和参数。
- en: '[PRE28]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Import the data.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据。
- en: '[PRE29]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Printing this out on a `Jupyter` notebook should display:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在`Jupyter`笔记本中打印此内容应显示：
- en: '![Figure 4.27: Labelled dataset'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.27：带标签的数据集'
- en: '](img/C13783_04_271.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![](img/C13783_04_271.jpg)'
- en: 'Figure 4.27: Labelled dataset'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.27：带标签的数据集
- en: Select the '`sentence`' and '`label`' columns
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`'sentence'`和`'label'`列
- en: '[PRE30]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Split your data into training and test set
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集
- en: '[PRE31]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Tokenize
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分词
- en: '[PRE32]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Pad in order to ensure that all sequences have the same length
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充数据以确保所有序列的长度相同
- en: '[PRE33]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Create the model. Note that we use a sigmoid activation function on the last
    layer and the binary cross entropy for calculating loss. This is because we are
    doing a binary classification.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建模型。注意，我们在最后一层使用sigmoid激活函数，并使用二元交叉熵来计算损失。这是因为我们正在进行二分类。
- en: '[PRE34]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The above code should yield
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码应该输出
- en: '![](img/C13783_04_28.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13783_04_28.jpg)'
- en: 'Figure 4.28: Model summary'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.28：模型总结
- en: 'The model can be visualized as follows as well:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型也可以如下所示进行可视化：
- en: '![Figure 4.29: Model visualization'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.29：模型可视化'
- en: '](img/C13783_04_29.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13783_04_29.jpg)'
- en: 'Figure 4.29: Model visualization'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.29：模型可视化
- en: Train and test the model.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练并测试模型。
- en: '[PRE35]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The accuracy output should be as follows:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确度输出应如下所示：
- en: '![Figure 4.30: Accuracy score](img/C13783_04_30.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.30：准确度评分](img/C13783_04_30.jpg)'
- en: 'Figure 4.30: Accuracy score'
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.30：准确度评分
- en: 'Chapter 5: Foundations of Recurrent Neural Network'
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 5 章：循环神经网络基础
- en: 'Activity 6: Solve a problem with RNN – Author Attribution'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 6：用 RNN 解决问题——作者归属
- en: '**Solution:**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Prepare the data
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备数据
- en: We begin by setting up the data pre-processing pipeline. For each one of the
    authors, we aggregate all the known papers into a single long text. We assume
    that style does not change across the various papers, hence a single text is equivalent
    to multiple small ones yet it is much easier to deal with programmatically.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先设置数据预处理管道。对于每个作者，我们将所有已知的论文聚合为一篇长文。我们假设风格在不同论文中没有变化，因此一篇长文等同于多篇短文，而且从程序角度处理起来要更容易。
- en: 'For each paper of each author we perform the following steps:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个作者的每篇论文，我们执行以下步骤：
- en: Convert all text into lower-case (ignoring the fact that capitalization may
    be a stylistic property)
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有文本转换为小写字母（忽略大小写可能是风格属性这一事实）
- en: Converting all newlines and multiple whitespaces into single whitespaces
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有换行符和多个空格转换为单个空格
- en: Remove any mention of the authors' names, otherwise we risk data leakage (authors
    names are *hamilton* and *madison*)
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除任何涉及作者姓名的内容，否则我们可能会面临数据泄漏的风险（作者的名字是 *hamilton* 和 *madison*）
- en: Do the above steps in a function as it is needed for predicting the unknown
    papers.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上述步骤封装成一个函数，因为它在预测未知论文时是必需的。
- en: '[PRE36]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output for this should be as follows:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该输出应如下所示：
- en: '![Figure 5.34: Text length count'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.34：文本长度计数'
- en: '](img/C13783_05_341.jpg)'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13783_05_341.jpg)'
- en: 'Figure 5.34: Text length count'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.34：文本长度计数
- en: The next step is to break the long text for each author into many small sequences.
    As described above, we empirically choose a length for the sequence and use it
    throughout the model's lifecycle. We get our full dataset by labeling each sequence
    with its author.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一步是将每个作者的长文本拆分为多个小序列。如上所述，我们经验性地选择一个序列长度，并在模型生命周期内始终使用该长度。我们通过为每个序列标注其作者来获取完整的数据集。
- en: To break the long texts into smaller sequences we use the `Tokenizer` class
    from the `keras` framework. In particular, note that we set it up to tokenize
    according to characters and not words.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了将长文本拆分为较小的序列，我们使用 `keras` 框架中的 `Tokenizer` 类。特别地，注意我们将其设置为按字符而非按词进行标记。
- en: Choose `SEQ_LEN` hyper parameter, this might have to be changed if the model
    doesn't fit well to training data.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `SEQ_LEN` 超参数，如果模型与训练数据不匹配，可能需要更改此参数。
- en: Write a function `make_subsequences` to turn each document into sequences of
    length SEQ_LEN and give it a correct label.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个函数 `make_subsequences`，将每个文档转化为长度为 SEQ_LEN 的序列，并赋予正确的标签。
- en: Use Keras `Tokenizer` with `char_level=True`
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Keras `Tokenizer` 并设置 `char_level=True`
- en: Fit the tokenizer on all the texts
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对所有文本进行分词器拟合
- en: Use this tokenizer to convert all texts into sequences using `texts_to_sequences()`
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个分词器将所有文本转换为序列，方法是使用 `texts_to_sequences()`
- en: Use `make_subsequences()` to turn these sequences into appropriate shape and
    length
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `make_subsequences()` 将这些序列转化为合适的形状和长度
- en: '[PRE37]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output should be as follows:'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 5.35: Character count of sequences'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.35：序列的字符计数'
- en: '](img/C13783_05_351.jpg)'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13783_05_351.jpg)'
- en: 'Figure 5.35: Character count of sequences'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.35：序列的字符计数
- en: Compare the number of raw characters to the number of labeled sequences for
    each author. Deep Learning requires many examples of each input. The following
    code calculates the number of total and unique words in the texts.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较每个作者的原始字符数与标注序列数。深度学习需要大量的每种输入的示例。以下代码计算文本中的总词数和唯一词数。
- en: '[PRE38]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output should be as follows:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 5.36: Total word count and unique word count'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.36：总词数和唯一词数'
- en: '](img/C13783_05_36.jpg)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13783_05_36.jpg)'
- en: 'Figure 5.36: Total word count and unique word count'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5.36：总词数和唯一词数
- en: We now proceed to create our train, validation sets.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在开始创建我们的训练集和验证集。
- en: Stack `x` data together and y data together.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `x` 数据堆叠在一起，将 `y` 数据堆叠在一起。
- en: Use `train_test_split` to split the dataset into 80% training and 20% validation.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `train_test_split` 将数据集分割为 80% 的训练集和 20% 的验证集。
- en: Reshape the data to make sure that they are sequences of correct length.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重塑数据，确保它们是正确长度的序列。
- en: '[PRE39]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.37: Testing and training datasets](img/C13783_05_37.jpg)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.37: 测试集和训练集](img/C13783_05_37.jpg)'
- en: 'Figure 5.37: Testing and training datasets'
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.37: 测试集和训练集'
- en: Finally, we construct the model graph and perform the training procedure.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们构建模型图并执行训练过程。
- en: Create a model using `RNN` and `Dense` layers.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `RNN` 和 `Dense` 层创建模型。
- en: Since its a binary classification problem, the output layer should be `Dense`
    with `sigmoid` activation.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于这是一个二分类问题，输出层应为 `Dense`，并使用 `sigmoid` 激活函数。
- en: Compile the model with `optimizer`, appropriate loss function and metrics.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `optimizer`，适当的损失函数和指标编译模型。
- en: Print the summary of the model.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型摘要。
- en: '[PRE40]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output is as follows:'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C13783_05_38.jpg)'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13783_05_38.jpg)'
- en: 'Figure 5.38: Model summary'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.38: 模型摘要'
- en: Decide upon the batch size, epochs and train the model using training data and
    validate with validation data
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定批量大小、训练周期，并使用训练数据训练模型，使用验证数据进行验证。
- en: Based on the results, go back to model above, change it if needed (use more
    layers, use regularization, dropout, etc., use different optimizer, or a different
    learning rate, etc.)
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据结果，返回上述模型，必要时进行更改（使用更多层，使用正则化，dropout 等，使用不同的优化器，或不同的学习率等）。
- en: Change `Batch_size`, `epochs` if needed.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有需要，修改 `Batch_size`、`epochs`。
- en: '[PRE41]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output is as follows:'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C13783_05_39.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C13783_05_39.jpg)'
- en: 'Figure 5.39: Epoch training'
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.39: 训练周期'
- en: Applying the Model to the Unknown Papers
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将模型应用于未知论文
- en: Do this all the papers in the Unknown folder
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 对“Unknown”文件夹中的所有论文进行此操作。
- en: Preprocess them same way as training set (lower case, removing white lines,
    etc.)
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以与训练集相同的方式预处理它们（小写，去除空白行等）。
- en: Use `tokenizer` and `make_subsequences` function above to turn them into sequences
    of required size.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tokenizer` 和上述 `make_subsequences` 函数将它们转换为所需大小的序列。
- en: Use the model to predict on these sequences.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型对这些序列进行预测。
- en: Count the number of sequences assigned to author **A** and the ones assigned
    to author **B**
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算分配给作者 **A** 和作者 **B** 的序列数。
- en: Based on the count, pick the author with highest votes/count
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据计数，选择具有最高票数/计数的作者。
- en: '[PRE42]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output is as follows:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.40: Output for author attribution](img/C13783_05_40.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.40: 作者归属输出](img/C13783_05_40.jpg)'
- en: 'Figure 5.40: Output for author attribution'
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 5.40: 作者归属输出'
- en: 'Chapter 6: Foundations of GRUs'
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 6 章：GRU 基础
- en: 'Activity 7: Develop a sentiment classification model using Simple RNN'
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 7：使用简单 RNN 开发情感分类模型
- en: '**Solution:**'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Load the dataset.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集。
- en: '[PRE43]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Pad sequences so that each sequence has the same number characters.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充序列，以确保每个序列具有相同数量的字符。
- en: '[PRE44]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Define and compile model using `SimpleRNN` with 32 hidden units.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 32 个隐藏单元的 `SimpleRNN` 定义并编译模型。
- en: '[PRE45]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Plot the validation and training accuracy and losses.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制验证和训练准确度及损失。
- en: '[PRE46]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Plot the model
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制模型图。
- en: '[PRE47]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.29: Training and validation accuracy loss'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.29: 训练和验证准确度损失](img/C13783_06_29.jpg)'
- en: '](img/C13783_06_29.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_06_29.jpg)'
- en: 'Figure 6.29: Training and validation accuracy loss'
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.29: 训练和验证准确度损失'
- en: 'Activity 8: Train your own character generation model with a dataset of your
    choice'
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 8：使用您选择的数据集训练自己的字符生成模型。
- en: '**Solution:**'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Load the text file and import the necessary Python packages and classes.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载文本文件，并导入必要的 Python 包和类。
- en: '[PRE48]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output is as follows:'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.30: Sonnets from Shakespeare](img/C13783_06_30.jpg)'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.30: 莎士比亚的十四行诗](img/C13783_06_30.jpg)'
- en: 'Figure 6.30: Sonnets from Shakespeare'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.30: 莎士比亚的十四行诗'
- en: Create dictionaries mapping characters to indices and vice-versa.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建字典，将字符映射到索引，并反向映射。
- en: '[PRE49]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.31: Distinct character count](img/C13783_06_31.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.31: 不同字符计数](img/C13783_06_31.jpg)'
- en: 'Figure 6.31: Distinct character count'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.31: 不同字符计数'
- en: Create sequences from the text.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文本中创建序列。
- en: '[PRE50]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output is as follows:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.32: nb sequence count](img/C13783_06_32.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.32: 序列计数](img/C13783_06_32.jpg)'
- en: 'Figure 6.32: nb sequence count'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.32: 序列计数'
- en: Make input and output arrays to feed the model.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建输入和输出数组，以供模型使用。
- en: '[PRE51]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Build and train the model using GRU and save the model.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 GRU 构建并训练模型，并保存该模型。
- en: '[PRE52]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Define sampling and generation functions.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义采样和生成函数。
- en: '[PRE53]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Generate text.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成文本。
- en: '[PRE54]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.33: Generated text output'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.33: 生成的文本输出](img/C13783_06_33.jpg)'
- en: '](img/C13783_06_33.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_06_33.jpg)'
- en: 'Figure 6.33: Generated text output'
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.33：生成的文本输出
- en: 'Chapter 7: Foundations of LSTM'
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 7 章：LSTM 基础
- en: 'Activity 9: Build a Spam or Ham classifier using a Simple RNN'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 活动 9：使用简单的 RNN 构建垃圾邮件或正常邮件分类器。
- en: '**Solution:**'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Import required Python packages
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的 Python 包。
- en: '[PRE55]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Read the input file containing a column that contains text and another column
    that contains the label for the text depicting whether the text is spam or not.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取输入文件，文件中包含一列文本和另一列标签，标签表示该文本是否为垃圾邮件。
- en: '[PRE56]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output is as follows:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.35: Input data file](img/C13783_07_351.jpg)'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 7.35：输入数据文件](img/C13783_07_351.jpg)'
- en: 'Figure 7.35: Input data file'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.35：输入数据文件
- en: Label the columns in the input data.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标注输入数据中的列。
- en: '[PRE57]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output is as follows:'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.36: Labelled input data](img/C13783_07_361.jpg)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 7.36：标注的输入数据](img/C13783_07_361.jpg)'
- en: 'Figure 7.36: Labelled input data'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.36：标注的输入数据
- en: Count spam, ham characters in the `v1` column.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`v1`列中垃圾邮件和正常邮件字符的数量。
- en: '[PRE58]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output is as follows:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.37: Value counts for spam or ham](img/C13783_07_371.jpg)'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 7.37：垃圾邮件或正常邮件的值计数](img/C13783_07_371.jpg)'
- en: 'Figure 7.37: Value counts for spam or ham'
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.37：垃圾邮件或正常邮件的值计数
- en: Get `X` as feature and `Y` as target.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取`X`作为特征，`Y`作为目标。
- en: '[PRE59]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Convert to sequences and pad the sequences.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为序列并填充序列。
- en: '[PRE60]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output is as follows:'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.38: Tokenized data](img/C13783_07_381.jpg)'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 7.38：分词数据](img/C13783_07_381.jpg)'
- en: 'Figure 7.38: Tokenized data'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.38：分词数据
- en: Train the sequences
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练序列。
- en: '[PRE61]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Build the model
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建模型。
- en: '[PRE62]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Predict the mail category on new test data.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对新测试数据预测邮件类别。
- en: '[PRE63]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output is as follows:'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.39: Output for new test data](img/C13783_07_391.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.39：新测试数据的输出](img/C13783_07_391.jpg)'
- en: 'Figure 7.39: Output for new test data'
  id: totrans-270
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.39：新测试数据的输出
- en: 'Activity 10: Create a French to English translation model'
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 10：创建法语到英语的翻译模型
- en: '**Solution:**'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Import the necessary Python packages and classes.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 包和类。
- en: '[PRE64]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Read the file in sentence pairs.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以句子对的形式读取文件。
- en: '[PRE65]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Remove `\u202f` character
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除`\u202f`字符。
- en: '[PRE66]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Append '**BEGIN_** ' and ' **_END**' words to target sequences. Map words to
    integers.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在目标序列中附加`**BEGIN_** `和` **_END**`词，将词映射到整数。
- en: '[PRE67]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Define encoder-decoder inputs.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义编码器-解码器输入。
- en: '[PRE68]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Build the model.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建模型。
- en: '[PRE69]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Initiate encoder training.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化编码器训练。
- en: '[PRE70]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Initiate decoder training.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化解码器训练。
- en: '[PRE71]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Define the final model.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义最终模型。
- en: '[PRE72]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Provide inferences to encoder and decoder
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将推理提供给编码器和解码器。
- en: '[PRE73]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Reverse-lookup token index to decode sequences
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用反向查找标记索引解码序列。
- en: '[PRE74]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Encode input as a state vector
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入编码为状态向量。
- en: '[PRE75]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Generate empty target sequence of length 1.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成长度为 1 的空目标序列。
- en: '[PRE76]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Populate the first character of target sequence with the start character.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用开始字符填充目标序列的第一个字符。
- en: '[PRE77]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Sampling loop for a batch of sequences
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为一批序列进行采样循环。
- en: '[PRE78]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Sample a token.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采样一个标记。
- en: '[PRE79]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Exit condition: either hit max length or find stop character.'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 退出条件：达到最大长度或找到停止字符。
- en: '[PRE80]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Update the target sequence (of length 1).
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新目标序列（长度为 1）。
- en: '[PRE81]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Update states
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新状态。
- en: '[PRE82]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Inference for user input: take in a word sequence, convert the sequence word
    by word into encoded.'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户输入推理：接受一个词序列，逐个词地将序列转换为编码。
- en: '[PRE83]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The output is as follows:'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.47: French to English translator](img/C13783_07_47.jpg)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.47：法语到英语翻译器](img/C13783_07_47.jpg)'
- en: 'Figure 7.47: French to English translator'
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7.47：法语到英语翻译器
- en: 'Chapter 8: State of the art in Natural Language Processing'
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 8 章：自然语言处理的最新进展
- en: 'Activity 11: Build a Text Summarization Model'
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 11：构建文本摘要模型
- en: '**Solution:**'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案：**'
- en: Import the necessary Python packages and classes.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 包和类。
- en: '[PRE84]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Load the dataset and read the file.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集并读取文件。
- en: '[PRE85]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Make vocab dictionary.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建词汇字典。
- en: '[PRE86]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: Convert lowercase to standardize.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为小写字母以标准化。
- en: '[PRE87]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Run the previous code snippet to load data, get vocab dictionaries and define
    some utility functions to be used later. Define length of input characters and
    output characters.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行之前的代码片段以加载数据，获取词汇字典并定义一些稍后使用的工具函数。定义输入字符和输出字符的长度。
- en: '[PRE88]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Use `repeator` to repeat `s_prev` to be of shape (`m`, `Tx`, `n_s`) so that
    you can concatenate it with all hidden states "`a`"
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`repeator`将`s_prev`重复为形状（`m`，`Tx`，`n_s`），以便可以将其与所有隐藏状态“`a`”连接。
- en: '[PRE89]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用连接器在最后一个轴上连接`a`和`s_prev`（≈ 1 行）
- en: '[PRE90]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Use `densor1` to propagate `concat` through a small fully-connected neural network
    to compute the "intermediate energies" variable e.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`densor1`通过一个小型全连接神经网络传播`concat`，以计算“中间能量”变量e。
- en: '[PRE91]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Use `densor2` to propagate e through a small fully-connected neural network
    to compute the "`energies`" variable energies.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`densor2`通过一个小型全连接神经网络传播e，计算“`能量`”变量energies。
- en: '[PRE92]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Use "`activator`" on "`energies`" to compute the attention weights "`alphas`"
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用“`activator`”对“`能量`”计算注意力权重“`alphas`”
- en: '[PRE93]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Use `dotor` together with "`alphas`" and "`a`" to compute the context vector
    to be given to the next (post-attention) LSTM-cell
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`dotor`与“`alphas`”和“`a`”一起计算要传递给下一个（后注意力）LSTM单元的上下文向量
- en: '[PRE94]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Define the inputs of your model with a shape (`Tx`,)
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型的输入，形状为（`Tx`,）
- en: Define `s0` and `c0`, initial hidden state for the decoder LSTM of shape (`n_s`,)
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`s0`和`c0`，解码器LSTM的初始隐藏状态，形状为（`n_s`,）
- en: '[PRE95]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Initialize empty list of outputs
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化空的输出列表
- en: '[PRE96]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True.
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义你的前注意力Bi-LSTM。记得使用return_sequences=True。
- en: '[PRE97]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Apply the post-attention LSTM cell to the "`context`" vector.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将后注意力LSTM单元应用于“`上下文`”向量。
- en: '[PRE98]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: Apply `Dense` layer to the hidden state output of the post-attention LSTM
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Dense`层应用于后注意力LSTM的隐藏状态输出
- en: '[PRE99]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Append "out" to the "outputs" list
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将“out”附加到“outputs”列表中
- en: '[PRE100]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Create model instance taking three inputs and returning the list of outputs.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建模型实例，接受三个输入并返回输出列表。
- en: '[PRE101]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'The output is as follows:'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 8.18: Text summarization model output'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.18：文本摘要模型输出](img/C13783_08_18.jpg)'
- en: '](img/C13783_08_18.jpg)'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_08_18.jpg)'
- en: 'Figure 8.18: Text summarization model output'
  id: totrans-359
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8.18：文本摘要模型输出
- en: 'Chapter 9: A practical NLP project workflow in an organisation'
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第9章：组织中的实际NLP项目工作流程
- en: Code for LSTM model
  id: totrans-361
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LSTM模型的代码
- en: Check if GPU is detected
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否检测到GPU
- en: '[PRE102]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Setting up collar notebook
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置领口笔记本
- en: '[PRE103]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Import necessary Python packages and classes.
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的Python包和类。
- en: '[PRE104]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Load the data file.
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据文件。
- en: '[PRE105]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Initialize tokenization.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化分词。
- en: '[PRE106]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: Fit tokenizer.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合分词器。
- en: '[PRE107]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Pad sequences.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充序列。
- en: '[PRE108]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Get target variable
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取目标变量
- en: '[PRE109]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: Fit the model.
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型。
- en: '[PRE110]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: Save model and tokenizer.
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存模型和分词器。
- en: '[PRE111]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Code for Flask
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Flask的代码
- en: Import the necessary Python packages and classes.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的Python包和类。
- en: '[PRE112]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Define the input files and load in dataframe
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入文件并加载到数据框中
- en: '[PRE113]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Define preprocessing functions similar to the training code:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义类似于训练代码的预处理函数：
- en: '[PRE114]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Define a Flask app instance:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义Flask应用实例：
- en: '[PRE115]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Define an endpoint that displays a fixed message:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个显示固定消息的端点：
- en: '[PRE116]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'We''ll have a prediction endpoint, to which we can send our review strings.
    The kind of HTTP request we will use is a ''`POST`'' request:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将拥有一个预测端点，通过它可以发送我们的评论字符串。我们将使用的HTTP请求类型是'`POST`'请求：
- en: '[PRE117]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: Start the web server.
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Web服务器。
- en: '[PRE118]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Save this file as `app.py` (any name could be used). Run this code from the
    terminal using `app.py`:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此文件保存为`app.py`（可以使用任何名称）。通过终端使用`app.py`运行此代码：
- en: '[PRE119]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'The output is as follows:'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.31: Output for flask](img/C13783_09_31.jpg)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![图9.31：Flask输出](img/C13783_09_31.jpg)'
- en: 'Figure 9.31: Output for flask'
  id: totrans-401
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.31：Flask输出
