- en: Deep Learning Models Using TensorFlow in R
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 R 中使用 TensorFlow 构建深度学习模型
- en: This chapter is about using TensorFlow in R. We have already used TensorFlow
    quite a lot, as Keras is a high-level neural network API that uses either TensorFlow,
    CNTK, or Theano. In R, Keras uses TensorFlow in the background. TensorFlow is
    more difficult to develop deep learning models in. However, there are two interesting
    packages in TensorFlow that could be overlooked: TensorFlow estimators and TensorFlow
    runs. We will cover both of these packages in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容将介绍如何在 R 中使用 TensorFlow。我们已经在使用 TensorFlow 了很多，因为 Keras 是一个高级神经网络 API，它可以使用
    TensorFlow、CNTK 或 Theano。在 R 中，Keras 背后使用的是 TensorFlow。尽管使用 TensorFlow 开发深度学习模型较为复杂，但
    TensorFlow 中有两个有趣的包可能会被忽视：TensorFlow 估算器和 TensorFlow 运行。我们将在本章中介绍这两个包。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: Introduction to TensorFlow
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 简介
- en: Building models using TensorFlow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 构建模型
- en: TensorFlow estimators
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 估算器
- en: TensorFlow runs packages
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 运行包
- en: Introduction to the TensorFlow library
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 库简介
- en: '**TensorFlow** is not just a deep learning library, but an expressive programming
    language that can implement various optimization and mathematical transformations
    on data. While it is mainly used to implement deep learning algorithms, it can
    perform much more. In TensorFlow, programs are represented as computational graphs,
    and data in TensorFlow is stored in `tensors`. A **tensor** is an array of data
    that has the same data type, and the rank of a tensor is the number of dimensions.
    Because all the data in a tensor must have the same type, they are more similar
    to R matrices than data frames.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow** 不仅是一个深度学习库，还是一个表达性强的编程语言，可以对数据执行各种优化和数学变换。虽然它主要用于实现深度学习算法，但它能够做的远不止这些。在
    TensorFlow 中，程序通过计算图表示，数据则以 `tensors` 的形式存储。**张量** 是一种数据数组，所有元素具有相同的数据类型，张量的秩是指其维度的数量。由于张量中的所有数据必须是相同类型的，因此它们与
    R 矩阵更为相似，而不是数据框。'
- en: 'Here is an example of tensors of various ranks:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是不同秩的张量示例：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A TensorFlow program has two parts. First, you have to build the computational
    graph, which contains the tensors and the operations on those tensors. When they
    have defined the graph, the second part is to create a TensorFlow session to run
    the graph. In the previous example, the first time we print out the value for
    the tensor, `a`, we only get the tensor definition and not the value. All we have
    done is define part of the computation graph. It is only when we call `tf$InteractiveSession`
    that we tell TensorFlow to run the operations on the tensors. A session is responsible
    for running the computational graph.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 TensorFlow 程序包含两个部分。首先，您需要构建计算图，图中包含张量以及对这些张量的操作。定义完图之后，第二部分是创建一个 TensorFlow
    会话来运行计算图。在前面的例子中，当我们第一次打印张量 `a` 的值时，我们只得到张量的定义，而不是其值。我们所做的只是定义了计算图的一部分。只有当我们调用
    `tf$InteractiveSession` 时，我们才会告诉 TensorFlow 执行张量上的操作。会话负责运行计算图。
- en: The TensorFlow program is referred to as a graph because the code can be structured
    as a graph. This might not be obvious to us as most of the deep learning models
    that we have built in this book have consisted of sequential operations on layers.
    In TensorFlow (and Keras and MXNet), it is possible to use the output of an operation
    multiple times and to combine inputs in one operation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 程序被称为图，因为代码可以构建成图的形式。对于我们而言，这可能不太直观，因为我们在本书中构建的大多数深度学习模型都包含了层上的顺序操作。在
    TensorFlow（以及 Keras 和 MXNet）中，操作的输出可以多次使用，并且可以将多个输入结合到一个操作中。
- en: As deep learning models get larger, it is increasingly difficult to visualize
    and debug them. In some code blocks, we have printed a summary of the model showing
    the layers, or we have plotted the network. However, neither of these tools would
    be helpful for debugging problems in a model with 10 million+ parameters! Fortunately,
    there is a visualization tool included with TensorFlow to help summarize, debug,
    and fix TensorFlow programs. This is called TensorBoard, and we will cover this
    next.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习模型的规模不断增大，越来越难以进行可视化和调试。在一些代码块中，我们打印了显示模型层次结构的摘要，或者绘制了网络图。然而，这些工具对于调试具有千万级参数的模型帮助不大！幸运的是，TensorFlow
    提供了一个可视化工具，用于总结、调试和修复 TensorFlow 程序。这个工具叫做 TensorBoard，我们将在接下来介绍它。
- en: Using TensorBoard to visualize deep learning networks
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 可视化深度学习网络
- en: 'Computation graphs in TensorFlow can be very complex, so there is a visualization
    tool called **TensorBoard** to visualize these graphs and assist in debugging.
    TensorBoard can plot a computation graph, display metrics from training, and so
    on. Since Keras uses TensorFlow in the backend, it too can use TensorBoard. Here
    is the MNIST example from Keras with TensorBoard logging enabled. This code can
    be found in the `Chapter8/mnist_keras.R` folder. The first part of the code loads
    the data, pre-processes it, and defines the model architecture. Hopefully, this
    should be familiar to you at this stage:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 中的计算图可以非常复杂，因此有一个叫做**TensorBoard**的可视化工具，用于可视化这些图并辅助调试。TensorBoard
    可以绘制计算图、显示训练过程中的指标等。由于 Keras 在后台使用 TensorFlow，它也可以使用 TensorBoard。以下是启用了 TensorBoard
    日志的 Keras MNIST 示例代码。该代码可以在 `Chapter8/mnist_keras.R` 文件夹中找到。代码的第一部分加载数据，进行预处理，并定义模型架构。希望这一部分你已经比较熟悉了：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To enable logging, add a `callbacks` parameter to the `model.fit` function
    to tell Keras/TensorFlow to log events to a directory. The following code will
    output log data to the `/tensorflow_logs` directory:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用日志记录，在 `model.fit` 函数中添加一个 `callbacks` 参数，以告诉 Keras/TensorFlow 将事件日志记录到某个目录。以下代码将日志数据输出到
    `/tensorflow_logs` 目录：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Warning**: The event logs can take up a lot of space. For 5 epochs on the
    `MNIST` dataset, 1.75 GB of information was created. Most of this was because
    of the image data that was included, so you may consider setting `write_images=0`
    to reduce the size of the logs.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**：事件日志可能会占用大量空间。在`MNIST`数据集上训练5个epoch时，生成了1.75 GB的信息。大部分数据来自于图像数据，因此你可以考虑设置`write_images=0`来减少日志的大小。'
- en: 'TensorBoard is a web application, and you must start the TensorBoard program
    for it to run. When the model has finished training, follow these steps to start
    the TensorBoard web application:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 是一个 Web 应用程序，你必须启动 TensorBoard 程序才能运行它。当模型训练完成后，按照以下步骤启动 TensorBoard
    Web 应用程序：
- en: 'Open up Command Prompt and enter the following:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开命令提示符并输入以下内容：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If TensorBoard starts successfully, you should get a message similar to the
    following at Command Prompt:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 TensorBoard 启动成功，你应该会在命令提示符中看到类似以下的消息：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Open a web browser to the link that was provided. The web page should be similar
    to the following:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个网页浏览器，访问提供的链接。网页应该类似于以下内容：
- en: '![](img/2c775aa3-5ea3-40d4-9bdd-b2dfaf3e5786.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c775aa3-5ea3-40d4-9bdd-b2dfaf3e5786.png)'
- en: 'Figure 8.1: TensorBoard – model metrics'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.1: TensorBoard – 模型指标'
- en: 'The preceding screenshot shows us the model metrics on the training and validation
    test sets – these are similar to the metrics shown in RStudio during training:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上面的截图显示了训练集和验证集上的模型指标——这些指标类似于在 RStudio 中训练时显示的指标：
- en: '![](img/c4be3ad7-5e78-4f42-9ef6-3fc0645d3843.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c4be3ad7-5e78-4f42-9ef6-3fc0645d3843.png)'
- en: 'Figure 8.2: RStudio – model metrics'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.2: RStudio – 模型指标'
- en: 'If you click on the **Images** option, you will be able to visualize the layers
    in the model and see how they change over epochs:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你点击**图像**选项，你将能够可视化模型中的各个层，并查看它们在训练过程中如何变化：
- en: '![](img/c9a63540-797c-45c4-bb53-bccdd90bb7ed.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9a63540-797c-45c4-bb53-bccdd90bb7ed.png)'
- en: 'Figure 8.3: TensorBoard – visualizing the model layers'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.3: TensorBoard – 可视化模型层'
- en: 'If you click on the **Graphs** option, it will show the computation graph for
    the model. You can also download it as an image file. Here is the computation
    graph for this model:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你点击**图形**选项，它将显示模型的计算图。你也可以将其下载为图像文件。以下是该模型的计算图：
- en: '![](img/85274738-c4f0-4804-9588-550900583db8.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85274738-c4f0-4804-9588-550900583db8.png)'
- en: 'Figure 8.4: TensorBoard – computation graph'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.4: TensorBoard – 计算图'
- en: Some of this will seem familiar. We can see our convolutional, max pooling,
    flatten, dense, and dropout layers. The rest are not as obvious. As a higher-level
    abstraction, Keras takes care of a lot of the complexities in creating the computation
    graph.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些部分应该是你已经熟悉的。我们可以看到卷积层、最大池化层、扁平化层、全连接层和 Dropout 层。其他部分不那么明显。作为一种更高级的抽象，Keras
    处理了创建计算图时的许多复杂性。
- en: 'By clicking on the **Histogram** option, you can see how the distribution of
    tensors changes over time:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**直方图**选项，你可以看到张量的分布随时间变化的情况：
- en: '![](img/7d0685a1-da65-43e7-b00c-6afaa95f4abc.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d0685a1-da65-43e7-b00c-6afaa95f4abc.png)'
- en: 'Figure 8.5: TensorBoard – histograms'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.5: TensorBoard – 直方图'
- en: It is possible to use TensorBoard to debug a model. For example, it would be
    possible to investigate a vanishing gradient or an exploding gradient problem
    to see where the weights of the model were either vanishing to zero or exploding
    to infinity. There is a lot more to TensorBoard, so if you are curious you can
    follow the online documentation on it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用TensorBoard来调试模型。例如，可以调查梯度消失或梯度爆炸问题，查看模型的权重是否在消失到零或爆炸到无限大。TensorBoard的功能远不止这些，如果你感兴趣，可以参考在线文档了解更多内容。
- en: In the next section, we will use TensorFlow to build a regression model and
    a convolutional neural network.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将使用TensorFlow构建一个回归模型和一个卷积神经网络。
- en: TensorFlow models
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow模型
- en: In this section, we will use TensorFlow to build some machine learning models.
    First, we will build a simple linear regression model and then a convolutional
    neural network model, similar to what we have seen in [Chapter 5](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml), *Image
    Classification Using Convolutional Neural Networks*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用TensorFlow构建一些机器学习模型。首先，我们将构建一个简单的线性回归模型，然后是一个卷积神经网络模型，类似于我们在[第5章](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml)《使用卷积神经网络进行图像分类》中看到的模型。
- en: 'The following code loads the TensorFlow library. We can confirm it loaded successfully
    by setting and accessing a constant string value:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码加载TensorFlow库。我们可以通过设置并访问一个常量字符串值来确认它是否成功加载：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Linear regression using TensorFlow
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow的线性回归
- en: 'In this first Tensorflow example, we will look at regression. The code for
    this section is in the `Chapter8/regression_tf.R` folder:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一个TensorFlow示例中，我们将探讨回归问题。此部分的代码位于`Chapter8/regression_tf.R`文件夹中：
- en: 'First, we create some fake data for an an input value, *x*, and an output value,
    *y*. We set *y* to be approximately equal to `0.8 + x * 1.3`. We want the application
    to discover the `beta0` and `beta1` values, which are `0.8` and `1.3`, respectively:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们为输入值*x*和输出值*y*创建一些虚拟数据。我们将*y*设为大约等于`0.8 + x * 1.3`。我们希望应用程序发现`beta0`和`beta1`的值，分别为`0.8`和`1.3`：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we set up our `loss` function so that the gradient descent algorithm can
    work:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们设置`loss`函数，以便梯度下降算法可以工作：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We then set up a TensorFlow session and initialize the variables. Finally,
    we can run the graph:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们设置TensorFlow会话并初始化变量。最后，我们可以运行图：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can see that the model manages to find the values for `beta0` and `beta1`
    that solve the function `y=beta0 + beta1*x`. The next section is a more more complex
    example, where we will build a TensorFlow model for image classification.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，模型成功找到了`beta0`和`beta1`的值，这些值解出了函数`y=beta0 + beta1*x`。下一部分是一个更复杂的示例，我们将为图像分类构建一个TensorFlow模型。
- en: Convolutional neural networks using TensorFlow
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow的卷积神经网络
- en: In this section, we will build a TensorFlow model on the MNIST dataset. The
    code has similar layers and parameters to the Lenet model that we saw in [Chapter
    5](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml), *Image Classification Using Convolutional
    Neural Networks*. However, the code to build the model in TensorFlow is more complicated
    than the code to build the model in Keras or in MXNet. One reason for this is
    that it is the programmer's job to ensure that the sizes of the layers are correctly
    aligned. In the Keras/MXNet models, we can just change the number of nodes in
    a layer in one statement. In TensorFlow, if we change the number of nodes in a
    layer, we must ensure that we also change the inputs in the next layer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将基于MNIST数据集构建一个TensorFlow模型。该代码具有与[第5章](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml)《使用卷积神经网络进行图像分类》中的Lenet模型相似的层和参数。然而，在TensorFlow中构建模型的代码比在Keras或MXNet中构建模型的代码要复杂。原因之一是，程序员需要确保各层的尺寸正确对齐。在Keras/MXNet模型中，我们只需更改某一层的节点数即可。在TensorFlow中，如果我们更改一层的节点数，必须确保同时更改下一层的输入。
- en: 'In some ways, programming in TensorFlow is closer to the hand-written neural
    network code we wrote in [Chapter 3](6e6dd858-9f00-454a-8434-a95c59e85b25.xhtml),
    *Deep Learning Fundamentals*. Another difference from Keras/MXNet in the training
    loop is that we need to manage the batches rather than just call, asking to iterate
    over all the data *x* times (where *x* is an epoch). The code for this example
    is in the `Chapter8/mnist_tf.R` folder. First, we load the Keras package to get
    the MNIST data, but we train the model using TensorFlow. Here is the first part
    of the code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些方面，在TensorFlow中编程更接近我们在[第3章](6e6dd858-9f00-454a-8434-a95c59e85b25.xhtml)《深度学习基础》中手写的神经网络代码。与Keras/MXNet在训练循环中的另一个区别是，我们需要管理批次，而不仅仅是调用要求遍历所有数据
    *x* 次（其中 *x* 是一个时期）。此示例的代码位于`Chapter8/mnist_tf.R`文件夹中。首先，我们加载Keras包以获取MNIST数据，但我们使用TensorFlow训练模型。以下是代码的第一部分：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We use the `decodeClassLabels` function from the RSNNS library because TensorFlow
    requires a dummy coded matrix, so each possible class is represented as a column
    coded as 0/1, as shown in the preceding code output.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用来自RSNNS库的`decodeClassLabels`函数，因为TensorFlow要求一个虚拟编码矩阵，因此每个可能的类都表示为一个列，并以0/1的形式编码，如前面的代码输出所示。
- en: 'In the next code block, we create some placeholders for our input and output
    values in the model. We also reshape the input data into a rank-4 tensor, that
    is, a 4 dimensional data structure. The first dimension (-1L) is for the records
    that will be processed in a batch. The next two dimensions are the dimensions
    of the image files, and the final dimension is the channels, which is the number
    of colors. Since our images are greyscale, there is only 1 channel. If the images
    were color images, there would be 3 channels. The following code block creates
    the placeholders and reshapes the data:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个代码块中，我们为模型的输入和输出值创建一些占位符。我们还将输入数据重塑为一个4阶张量，即一个4维数据结构。第一维（-1L）用于处理批次中的记录。接下来的两维是图像文件的维度，最后一维是通道数，即颜色数。由于我们的图像是灰度图像，因此只有1个通道。如果图像是彩色图像，则有3个通道。以下代码块创建了占位符并重塑数据：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we will define the model architecture. We will create convolution blocks,
    just like we did previously. However, there are a lot more values that need to
    be set. For example, in the first convolutional layer, we must define the shape,
    initialize the weights, and take care of the bias variable. Here is the code for
    the TensorFlow model:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义模型架构。我们将创建卷积块，就像之前做的那样。不过，有许多其他值需要设置。例如，在第一个卷积层中，我们必须定义形状，初始化权重，并处理偏置变量。以下是TensorFlow模型的代码：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we have to define the loss equation, define the optimizer to use (Adam),
    and define the accuracy metric:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要定义损失方程，定义使用的优化器（Adam），并定义准确率指标：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, we can train the model over 10 epochs. However, one complication still
    exists, so we must manually manage the batches. We get the number of batches to
    train for and load them in turn. If we have 60,000 images in our train dataset,
    we have 469 batches (60,000/128 = 468.75 and round up to 469) per epoch. We feed
    in every batch and output metrics every 100 batches:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以在10个周期内训练模型。然而，仍然存在一个复杂性，因此我们必须手动管理批次。我们获取训练所需的批次数量，并依次加载它们。如果我们的训练数据集中有60,000张图像，则每个周期有469个批次（60,000/128
    = 468.75并四舍五入为469）。我们每次输入一个批次，并每100个批次输出一次指标：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here is the output for the first epoch:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第一轮训练的输出：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'When training is complete, we can evaluate the model by calculating the accuracy
    on the test set. Again, we have to do this in batches to prevent out-of-memory
    errors:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，我们可以通过计算测试集上的准确率来评估模型。同样，我们必须按批次执行此操作，以防止内存溢出错误：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We get a final accuracy of `0.9802`. If we compare this code to the MNIST example
    in [Chapter 5](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml),* Image Classification
    Using Convolutional Neural Networks*, the TensorFlow code is more verbose and
    it is easier to make mistakes. We can really see the benefit of using a higher,
    level abstraction, such as MXNet or Keras (which can use TensorFlow as a backend).
    For most deep learning use cases, especially for building deep learning models
    using existing layers as building blocks, there is little to be gained in developing
    code in TensorFlow. For these use cases, it is simpler and more efficient to use
    Keras or MXNet.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终获得了 `0.9802` 的准确率。如果将这段代码与 [第 5 章](1c0b9897-b0cc-4a8f-9ce8-e6409c347f4f.xhtml)
    *卷积神经网络图像分类* 中的 MNIST 示例进行比较，可以发现 TensorFlow 代码更为冗长，且更容易出错。我们可以真正看到使用更高层次抽象的好处，比如
    MXNet 或 Keras（它可以使用 TensorFlow 作为后端）。对于大多数深度学习应用场景，尤其是使用现有层作为构建块构建深度学习模型时，在 TensorFlow
    中编写代码并没有太多好处。在这些场景中，使用 Keras 或 MXNet 更简单且更高效。
- en: After seeing this code, you may want to go back to something more familiar in
    Keras and MXNet. However, the next section looks at TensorFlow estimators and
    TensorFlow runs, which are two useful packages that you should be aware of.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 查看完这段代码后，你可能会想回到更熟悉的 Keras 和 MXNet。不过，接下来的部分将介绍 TensorFlow 估算器和 TensorFlow 运行包，这是两个非常有用的包，你应该了解它们。
- en: TensorFlow estimators and TensorFlow runs packages
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 估算器和 TensorFlow 运行包
- en: TensorFlow estimators and the TensorFlow runs packages are great packages to
    use for deep learning. In this section, we will use both to train a model based
    on our churn prediction data from [Chapter 4](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml),
    *Training Deep Prediction Models*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 估算器和 TensorFlow 运行包是非常适合深度学习的工具包。在本节中，我们将使用这两个包基于来自 [第 4 章](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml)
    *训练深度预测模型* 的流失预测数据来训练一个模型。
- en: TensorFlow estimators
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 估算器
- en: '**TensorFlow estimators** allow you to build TensorFlow models using a simpler
    API interface. In R, the `tfestimators` package allows you to call this API. There
    are different model types, including linear models and neural networks. The following
    estimators are available:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow 估算器** 允许你使用更简洁的 API 接口来构建 TensorFlow 模型。在 R 中，`tfestimators` 包允许你调用这个
    API。不同的模型类型包括线性模型和神经网络。可用的估算器如下：'
- en: '`linear_regressor()` for linear regression'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`linear_regressor()` 用于线性回归'
- en: '`linear_classifier()` for linear classification'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`linear_classifier()` 用于线性分类'
- en: '`dnn_regressor()` for deep neural network regression'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dnn_regressor()` 用于深度神经网络回归'
- en: '`dnn_classifier()` for deep neural network classification'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dnn_classifier()` 用于深度神经网络分类'
- en: '`dnn_linear_combined_regressor()` for deep neural network linear combined regression'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dnn_linear_combined_regressor()` 用于深度神经网络线性组合回归'
- en: '`dnn_linear_combined_classifier()` for deep neural network linear combined
    classification'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dnn_linear_combined_classifier()` 用于深度神经网络线性组合分类'
- en: Estimators hide a lot of the detail in creating a deep learning model, including building
    the graph, initializing variables and layers, and they can also integrate with TensorBoard.
    More details are available at [https://tensorflow.rstudio.com/tfestimators/](https://tensorflow.rstudio.com/tfestimators/).
    We will use `dnn_classifier` with the data from the binary classification task
    from [Chapter 4](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml),* Training Deep Prediction
    Models*. The following code in the `Chapter8/tf_estimators.R` folder demonstrates TensorFlow
    estimators.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 估算器隐藏了创建深度学习模型的很多细节，包括构建图、初始化变量和层，并且它们还可以与 TensorBoard 集成。更多详细信息请访问 [https://tensorflow.rstudio.com/tfestimators/](https://tensorflow.rstudio.com/tfestimators/)。我们将使用
    `dnn_classifier` 处理来自 [第 4 章](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml) *训练深度预测模型*
    的二元分类任务的数据。以下代码位于 `Chapter8/tf_estimators.R` 文件夹中，演示了 TensorFlow 估算器的使用。
- en: 'We only include the code that is specific to TensorFlow estimators and omit
    the code at the start of the file that loads the data and splits it into train
    and test data:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只包含特定于 TensorFlow 估算器的代码，省略了文件开头加载数据并将其拆分为训练数据和测试数据的部分：
- en: '[PRE16]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once the model is trained, the following code plots the training and validation
    metrics:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练完成后，以下代码将绘制训练和验证的指标：
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This produces the following plot:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![](img/9b2eefd3-08c8-40d2-ad7d-4ee4b0250033.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b2eefd3-08c8-40d2-ad7d-4ee4b0250033.png)'
- en: 'Figure 8.6: Training a loss plot for a TensorFlow estimator model'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6：训练 TensorFlow 估算器模型的损失图
- en: 'The next part of the code calls the `evaluate` function to produce metrics
    for the model:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的下一部分调用 `evaluate` 函数来生成模型的评估指标：
- en: '[PRE18]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can see that we got an accuracy of `77.57%`, which is actually almost identical
    to the accuracy we got on the MXNet model in [Chapter 4](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml),
    *Training Deep Prediction Models*, which had a similar architecture. The `dnn_classifier()`
    function hides a lot of the detail, so Tensorflow estimators are a good way to
    use the power of TensorFlow for tasks with structured data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们获得了`77.57%`的准确率，这实际上几乎与我们在[第4章](28315a07-2bf0-45c8-8e6f-0e4f01616ca3.xhtml)《训练深度预测模型》中，使用类似架构的MXNet模型所获得的准确率完全相同。`dnn_classifier()`函数隐藏了许多细节，因此TensorFlow估算器是利用TensorFlow强大功能处理结构化数据任务的好方法。
- en: 'Models created using TensorFlow estimators can be saved onto disk and loaded
    later. The `model_dir()` function shows the location of where the model artifacts
    were saved (usually in a `temp` directory, but it can be copied elsewhere):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow估算器创建的模型可以保存到磁盘，并在以后加载。`model_dir()`函数显示模型工件保存的位置（通常在`temp`目录中，但也可以复制到其他位置）：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Included in the model artifacts are the event logs that can be used by TensorBoard.
    For example, when I load TensorBoard up and point it to the logs directory in
    the `temp` directory, I can see the TensorFlow graph that was created:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 模型工件中包含了可以被TensorBoard使用的事件日志。例如，当我启动TensorBoard并将其指向`temp`目录中的日志目录时，我可以看到创建的TensorFlow图表：
- en: '![](img/b3037cf0-3e7e-4247-8606-2b0b4c550baf.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3037cf0-3e7e-4247-8606-2b0b4c550baf.png)'
- en: 'Figure 8.7: Graph using TensorBoard for a TensorFlow estimator model'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7：使用TensorBoard显示TensorFlow估算器模型的图表
- en: TensorFlow runs package
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow运行包
- en: The `tfruns` package is a set of utilities for managing different training runs
    for deep learning models. It can be used as a framework to build multiple deep
    learning models using different hyper-parameters. It can track the hyper-parameters,
    metrics, output, and source code for every training run and allows you to compare
    the best models so that you can see the differences between the training runs.
    This makes hyper-parameter tuning much easier and can be used with any `tfestimator`
    model or `Keras` model. For more details, go to [https://tensorflow.rstudio.com/tools/tfruns/articles/overview.html](https://tensorflow.rstudio.com/tools/tfruns/articles/overview.html).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfruns`包是一组用于管理深度学习模型不同训练运行的工具集。它可以作为框架，用不同的超参数构建多个深度学习模型。它可以跟踪每次训练运行的超参数、度量标准、输出和源代码，并允许你比较最佳模型，以便看到训练运行之间的差异。这使得超参数调优变得更加容易，并且可以与任何`tfestimator`模型或`Keras`模型一起使用。更多详情，请访问[https://tensorflow.rstudio.com/tools/tfruns/articles/overview.html](https://tensorflow.rstudio.com/tools/tfruns/articles/overview.html)。'
- en: 'The following code is in the `Chapter8/hyperparams.R` folder and also uses
    the script we used in the *TensorFlow estimators* section (`Chapter8/tf_estimators.R`):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码位于`Chapter8/hyperparams.R`文件夹中，并且还使用了我们在*TensorFlow估算器*部分中使用的脚本（`Chapter8/tf_estimators.R`）：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This will run the `Chapter8/tf_estimators.R` script with different hyper-parameters.
    The first time, we don't change any hyper-parameters, so it uses the defaults
    included in `Chapter8/tf_estimators.R`. Each time a new model is trained using
    the classification script, it is called a **training r****un**, and the details
    of the training run is stored in the `runs` folder in the current working directory.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使用不同的超参数运行`Chapter8/tf_estimators.R`脚本。第一次运行时，我们不会更改任何超参数，因此它使用`Chapter8/tf_estimators.R`中包含的默认值。每次使用分类脚本训练一个新模型时，都会被称为**训练运行**，并且训练运行的详细信息将保存在当前工作目录的`runs`文件夹中。
- en: 'For each training run, a new website will pop up with details on the run, as
    shown in the following screenshot:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每次训练运行，一个新的网站将弹出，显示该运行的详细信息，如下图所示：
- en: '![](img/320da535-5b81-4e24-9072-6c2c4ee07181.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/320da535-5b81-4e24-9072-6c2c4ee07181.png)'
- en: 'Figure 8.8: TensorFlow training run – Summary screen'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8：TensorFlow训练运行 – 概要屏幕
- en: We can see the progress of the training in the plots, along with the details
    of when the training run occurred and the evaluation metrics. We can also see
    in the bottom right that the **flags** (that is, hyper-parameters) used in the
    training run are also shown. There is another tab for the R code output, which
    includes all of the output from the R code in the inner file (`Chapter8/tf_estimators.R`),
    including plots.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到训练进度图，以及训练运行发生的时间和评估指标的详细信息。我们还可以在右下角看到用于训练运行的**标志**（即超参数）。还有一个标签页显示R代码输出，其中包含来自内部文件（`Chapter8/tf_estimators.R`）的所有输出，包括图表。
- en: 'Once all of the training runs are complete, the following code shows a summary
    of all the training runs:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有训练运行完成，以下代码会显示所有训练运行的摘要：
- en: '[PRE21]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here, we have ordered the results by the column `eval_accuracy`. If you close
    the window showing the summary for the training run, you can display it again by
    calling the `view_run` function and passing in the folder name. For example, to
    show the summary for the best training run, use the following code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们按 `eval_accuracy` 列排序结果。如果你关闭了显示训练运行摘要的窗口，你可以通过调用 `view_run` 函数并传入文件夹名称来重新显示它。例如，要显示最佳训练运行的摘要，可以使用以下代码：
- en: '[PRE22]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, you can also compare two runs. Here, we are comparing the two best
    models:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你还可以比较两个运行。在这里，我们比较了两个最佳模型：
- en: '[PRE23]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This brings up a page similar to the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将弹出类似以下内容的页面：
- en: '![](img/e006024e-8f31-4080-8a20-b5e7f81e6949.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e006024e-8f31-4080-8a20-b5e7f81e6949.png)'
- en: 'Figure 8.9: Comparing two TensorFlow runs'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9：比较两个 TensorFlow 运行
- en: This page shows the evaluation metrics for both training runs and also displays
    the hyper-parameters that were used. As we can see, this makes managing the process
    of tuning deep learning models much easier. This approach to hyper-parameter tuning
    has automatic logging, traceability, and it is easy to compare different sets
    of hyper-parameters. You can see the metrics and the different hyper-parameters
    used for the training runs. There's no more comparing configuration files to try
    and match hyper-parameter settings to output logs! In comparison, the code I wrote
    for hyper-parameter selection for the NLP example in [Chapter 7](03f666ab-60ce-485a-8090-c158b29ef306.xhtml),
    *Natural Language Processing Using Deep Learning*, seems crude in comparison
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此页面展示了两个训练运行的评估指标，并显示了所使用的超参数。如我们所见，这使得调整深度学习模型的过程更加容易。超参数调整的方法具有自动日志记录、可追溯性，并且可以轻松比较不同的超参数设置。你可以看到训练运行的指标和使用的不同超参数。再也不需要比较配置文件来尝试匹配超参数设置和输出日志了！相比之下，我为[第7章](03f666ab-60ce-485a-8090-c158b29ef306.xhtml)《*使用深度学习的自然语言处理*》中的
    NLP 示例所写的超参数选择代码，在此看起来显得粗糙。
- en: Summary
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we developed some TensorFlow models. We looked at TensorBoard,
    which is a great tool for visualizing and debugging deep learning models. We built
    a couple of models using TensorFlow, including a basic regression model and a Lenet
    model for computer vision models. From these examples, we saw that programming
    in TensorFlow was more complicated and error-prone than using the higher-level
    APIs (MXNet and Keras) that we used elsewhere in this book.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们开发了一些 TensorFlow 模型。我们看了 TensorBoard，它是一个非常好的工具，用于可视化和调试深度学习模型。我们使用
    TensorFlow 构建了几个模型，包括一个基本的回归模型和一个用于计算机视觉的 Lenet 模型。通过这些示例，我们看到了使用 TensorFlow 编程比使用本书中其他地方的高级
    API（如 MXNet 和 Keras）更复杂且容易出错。
- en: We then moved onto using TensorFlow estimators, which is a much easier interface
    than using TensorFlow. We then used that script in another package called **tfruns**,
    which stands for TensorFlow runs. This package allows us to call a TensorFlow
    estimators or Keras script with different flags each time. We used this for hyper-parameter
    selection, running, and evaluating multiple models. The TensorFlow runs have excellent
    integration with RStudio and we were able to view summaries for each run and compare
    runs to see the difference in the metrics and hyper-parameters that were used.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们开始使用 TensorFlow 估算器，这比直接使用 TensorFlow 界面更简单。然后我们在另一个名为**tfruns**的包中使用了该脚本，tfruns
    代表 TensorFlow 运行。这个包允许我们每次调用 TensorFlow 估算器或 Keras 脚本时使用不同的标志。我们用它来进行超参数选择、运行和评估多个模型。TensorFlow
    运行与 RStudio 有出色的集成，我们能够查看每次运行的摘要，并比较不同的运行，查看使用的指标和超参数的差异。
- en: In the next chapter, we we will look at embeddings and auto-encoders. We have
    already seen embeddings in [Chapter 7](03f666ab-60ce-485a-8090-c158b29ef306.xhtml),
    *Natural Language Processing Using Deep Learning*, so in the next chapter we will
    see how embeddings can create a lower level encoding of data. We will also use
    train auto-encoders, which create these embeddings. We will use auto-encoders
    for anomaly detection and also for collaborative filtering (recommender system).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论嵌入和自编码器。我们已经在[第7章](03f666ab-60ce-485a-8090-c158b29ef306.xhtml)《*使用深度学习的自然语言处理*》中看过嵌入，因此在下一章我们将看到嵌入如何创建数据的低层次编码。我们还将使用训练自编码器，这些自编码器会创建这些嵌入。我们将使用自编码器进行异常检测，并且还会用于协同过滤（推荐系统）。
