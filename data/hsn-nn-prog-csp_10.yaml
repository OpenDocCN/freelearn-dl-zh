- en: Training CNNs Using ConvNetSharp
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ConvNetSharp训练CNN
- en: 'In this chapter, we are going to use the phenomenal open source package **ConvNetSharp**,
    by Cédric Bovar, to demonstrate how to train our **Convolutional Neural Networks** (**CNNs**).
    In this chapter, we will look at the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Cédric Bovar的杰出开源包**ConvNetSharp**，来展示如何训练我们的**卷积神经网络**（**CNN**）。在本章中，我们将探讨以下主题：
- en: Common neural network modules
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的神经网络模块
- en: The various terms and concepts related to CNNs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与CNN相关的各种术语和概念
- en: Convolutional networks that process images
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理图像的卷积网络
- en: Technical requirements
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need Microsoft Visual Studio and ConvNetSharp framework for this chapter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要Microsoft Visual Studio和ConvNetSharp框架来完成本章内容。
- en: Getting acquainted
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 熟悉环境
- en: Before we begin diving into code, let's cover some basic terminology so that
    we are all on the same page when referring to things. This terminology applies
    to CNNs as well as the **ConvNetSharp **framework.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始深入代码之前，让我们先了解一下一些基本术语，这样当我们提到这些术语时，我们都在同一页面上。这个术语适用于CNN以及**ConvNetSharp**框架。
- en: '**Convolution**: In mathematics, a *convolution* is an operation performed
    on two functions. This operation produces a third function, which is an expression
    of how the shape of one is modified by the other. This is represented visually
    in the following diagram:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积**: 在数学中，*卷积*是对两个函数执行的操作。这个操作产生第三个函数，它表达了其中一个形状如何被另一个形状修改的表达式。这在以下图中以视觉方式表示：'
- en: '![](img/b3fdf9f1-90bd-4897-9781-ccf6e645341b.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b3fdf9f1-90bd-4897-9781-ccf6e645341b.png)'
- en: It is important to note that the convolutional layer itself is the building
    block of a CNN. This layer's parameters consist of a set of learnable filters
    (sometimes called **kernels**). These kernels have a small receptive field, which
    is a smaller view into the total image, and this view extends through the full
    depth of the input volume. During the forward propagation phase, each filter is
    **convolved** across the width and the height of the entire input volume. It is
    this convolution that computes the dot product between the filter and the input.
    This then produces a two-dimensional map (sometimes called an **activation map**)
    of the filter. This helps the network learn which filters should activate when
    they detect a feature at that respective input position.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，卷积层本身是CNN的构建块。这个层的参数由一组可学习的过滤器（有时称为**核**）组成。这些核具有小的感受野，这是一个对整个图像的较小视图，并且这个视图扩展到输入体积的整个深度。在前向传播阶段，每个过滤器在整个输入体积的宽度和高度上**卷积**。正是这种卷积计算了过滤器和输入之间的点积。然后产生一个二维图（有时称为**激活图**）的过滤器。这有助于网络学习在检测到相应输入位置的特征时应该激活哪些过滤器。
- en: '**Dot product computation**: The following diagram is a visualization of what
    we mean when we say dot product computation:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**点积计算**: 以下图是当我们说点积计算时我们指的是什么的一个可视化：'
- en: '![](img/3831e519-e3b9-458d-95fb-c4f32f93a446.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3831e519-e3b9-458d-95fb-c4f32f93a446.png)'
- en: '**Vol class**: In ConvNetSharp, the `Vol` class is simply a wrapper around
    a one-dimensional list of numbers, their gradients, and dimensions (that is, width,
    depth, and height).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Vol类**: 在ConvNetSharp中，`Vol`类简单地说是一个围绕一维数字列表、它们的梯度以及维度（即宽度、深度和高度）的包装。'
- en: '**Net class**: In ConvNetSharp, `Net` is a very simple class that contains
    a list of layers. When a `Vol` is passed through the `Net` class, `Net` iterates
    through all its layers, forward-propagates each one by calling the `forward()`
    function, and returns the result of the last layer. During back propagation, `Net`
    calls the `backward()` function of each layer to compute the gradient.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Net类**: 在ConvNetSharp中，`Net`是一个非常简单的类，它包含一个层的列表。当一个`Vol`通过`Net`类时，`Net`会遍历所有其层，通过调用`forward()`函数逐个前向传播，并返回最后一层的输出。在反向传播过程中，`Net`会调用每个层的`backward()`函数来计算梯度。'
- en: '**Layers**: As we know, every neural network is just a linear list of layers,
    and ours is no different. For a neural network, the first layer must be an input
    layer, and our last layer must be an output layer. Every layer takes an input
    `Vol` and produces a new output `Vol`.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层**: 如我们所知，每个神经网络都是一个层的线性列表，我们的也不例外。对于一个神经网络，第一层必须是输入层，我们的最后一层必须是输出层。每一层都接受一个输入`Vol`并产生一个新的输出`Vol`。'
- en: '**Fully-connected layer**: The fully-connected layer is perhaps the most important
    layer and is definitely the most interesting in terms of what it does. It houses
    a layer of neurons that perform weighted addition of all the inputs. These are
    then passed through a non-linear activation function such as a ReLU.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层**：全连接层可能是最重要的层，并且在功能上肯定是最有趣的。它包含一个执行所有输入加权加权的神经元层。然后，这些输入通过一个非线性激活函数，如ReLU。'
- en: '**Loss layers** and **classifier layers**: These layers are helpful when we
    need to predict a set of discrete classes for our data. You can use softmax, SVM,
    and many other types of layers. As always, you should experiment with your particular
    problem to see which one works best.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失层**和**分类器层**：当我们需要为我们的数据预测一组离散类别时，这些层非常有用。你可以使用softmax、SVM和许多其他类型的层。像往常一样，你应该对你的特定问题进行实验，看看哪一个效果最好。'
- en: '**Loss layers** and the **L2 regression layer**: This layer takes a list of
    targets and backward-propagates the L2 loss through them.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失层**和**L2回归层**：这一层接受一个目标列表，并通过它们反向传播L2损失。'
- en: '**Convolution layer**: This layer is almost a mirror of the fully-connected
    layer. The difference here is that neurons are only connected locally to a few
    neurons in the layer rather than being connected to all of them. They also share
    parameters.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层**：这一层几乎与全连接层是镜像关系。这里的区别在于神经元仅与层中的一些神经元局部连接，而不是与所有神经元连接。它们也共享参数。'
- en: '**Trainers**: The `Trainer` class takes a network and a set of parameters.
    It passes this through the network, sees the predictions, and adjusts the network
    weights to make the provided labels more accurate for that particular input. Over
    time, the process will transform the network and map all the inputs to the correct
    outputs.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练器**：`Trainer`类接受一个网络和一组参数。它将这些参数通过网络传递，查看预测结果，并调整网络权重以使提供的标签对特定输入更加准确。随着时间的推移，这个过程将改变网络，并将所有输入映射到正确的输出。'
- en: With that behind us, let's now talk a bit about CNNs themselves. A CNN consists
    of an input and an output layer; there's no big surprise there. There will be
    one or more hidden layers which consist of convolutional layers, pooling layers,
    fully-connected layers, or normalization layers. It is in these hidden layers
    that the magic happens. Convolutional layers apply a **convolution** operation
    to the input and pass the result to the next layer. We'll talk more about that
    in a moment.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们解决了这些问题之后，现在让我们谈谈CNN本身。CNN由输入层和输出层组成；这并不令人惊讶。将有一到多个隐藏层，这些隐藏层由卷积层、池化层、全连接层或归一化层组成。魔法就发生在这些隐藏层中。卷积层对输入应用**卷积**操作，并将结果传递到下一层。我们稍后会更多地讨论这一点。
- en: As we progress, the activation maps will be stacked for all of the filters that
    run along the depth dimension. This, in turn, will form the full output volume
    of the layer itself. Each neuron on that layer processes data only for its own
    receptive field (the data view it can see). This information is shared with other
    neurons.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们前进，激活图将被堆叠，以处理沿着深度维度的所有过滤器。这反过来将形成层的完整输出体积。该层上的每个神经元只处理其自身的感受野（它可以看到的数据）。这些信息与其他神经元共享。
- en: The thing that we have to always keep in mind with a CNN is the input size,
    which can require an extremely high number of neurons to process, depending on
    the resolution of the image. This could become architecturally inconvenient, and
    even intractable, because each pixel is a variable that needs to be processed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在CNN中，我们必须始终牢记输入大小，这可能会根据图像的分辨率需要处理极大量的神经元。这可能会在架构上变得不方便，甚至无法处理，因为每个像素都是一个需要处理的可变因素。
- en: Let's take a look at an example. If we have an image of 100 x 100 pixels, we
    would all agree that this is a small image. However, this image has 10,000 pixels
    in total (100 x 100), all of which are weights for each neuron in the second layer.
    Convolution is key to addressing this issue, as it reduces the number of parameters
    and allows the network to go deeper with fewer parameters. With 10,000 learnable
    parameters, the solution may be totally intractable; however, if we reduce that
    image to a 5 x 5 area, for example, we now have 25 different neurons to handle
    instead of 10,000, which is much more feasible. This will also help us to eliminate,
    or at least greatly reduce, the vanishing or exploding gradient problem we sometimes
    encounter when we train multi-layer networks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。如果我们有一个100 x 100像素的图像，我们都会同意这是一个小图像。然而，这个图像总共有10,000个像素（100 x 100），这些像素是第二层中每个神经元的权重。卷积是解决这个问题的关键，因为它减少了参数的数量，并允许网络在更少的参数下更深入地学习。如果有10,000个可学习的参数，解决方案可能是完全不可行的；然而，如果我们把这个图像缩小到5
    x 5的区域，例如，我们现在有25个不同的神经元来处理，而不是10,000个，这要现实得多。这也有助于我们消除，或者至少大大减少，我们在训练多层网络时有时会遇到梯度消失或爆炸问题。
- en: 'Let''s now take a quick look at how this works visually. As shown in the following
    diagram, we will use the number 6 and run it through a CNN to see if our network
    can detect the number we are trying to draw. The image at the bottom of the following
    screenshot is what we will draw. By the time we convolve things all the way up
    to the top, we should be able to light up the single neuron that denotes the number
    6, as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们快速看一下这是如何视觉化的。如图所示，我们将使用数字6并通过CNN运行它，看看我们的网络是否能够检测到我们试图绘制的数字。以下屏幕截图底部的图像是我们将要绘制的。当我们把所有卷积都做到顶部时，我们应该能够点亮表示数字6的单个神经元，如下所示：
- en: '![](img/6739312a-092e-4a5c-9d00-86e2217de804.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6739312a-092e-4a5c-9d00-86e2217de804.png)'
- en: 'In the preceding screenshot, we can see an input layer (our single number 6),
    convolutional layers, down-sampling layers, and an output layer. Our progression
    is as follows: we start with a 32 x 32 image, which leaves us with 1,024 neurons.
    We then go down to 120 neurons, then to 100 neurons, and finally to 10 neurons
    in our output layer – that''s one neuron for each of the 10 numerical digits.
    You can see that as we progress towards our output layer, the dimension of the
    image decreases. As we can see, we have 32 x 32 in our first convolutional layer,
    10 x 10 in our second, and 5 x 5 in our second pooling layer.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，我们可以看到一个输入层（我们单独的数字6），卷积层，下采样层，以及输出层。我们的进展如下：我们从一个32 x 32的图像开始，这给我们留下了1,024个神经元。然后我们减少到120个神经元，然后到100个神经元，最后在我们的输出层有10个神经元 –
    那就是每个10个数字中的一个神经元。你可以看到，随着我们向输出层前进，图像的维度在减小。正如我们所看到的，我们的第一个卷积层是32 x 32，第二个是10
    x 10，第二个池化层是5 x 5。
- en: It's also worth noting that each neuron in the output layer is fully connected
    to all 100 nodes in the fully-connected layer preceding it; hence, the term fully-connected
    layer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，输出层中的每个神经元都与它前面的全连接层中的所有100个节点完全连接；因此，称之为全连接层。
- en: 'If we make a three-dimensional drawing of this network and flip it around,
    we can better see how convolution occurs. The following diagram depicts just that,
    as the activated neurons are brighter in color. The layers continue to convolve until
    a decision is made as to which digit we have drawn, shown as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们把这个网络的三维图画出来并翻转它，我们可以更好地看到卷积是如何发生的。以下图解正是如此，因为激活的神经元颜色更亮。层继续卷积，直到决定我们画的是哪个数字，如下所示：
- en: '![](img/57d82dfd-42e3-4e84-8732-4bea9d17e9cc.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/57d82dfd-42e3-4e84-8732-4bea9d17e9cc.png)'
- en: Filters
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过滤器
- en: One of the other unique features of a CNN is that many neurons can share the
    same vector of weights and biases, or more formally, the same **filter**. Why
    is that important? Because each neuron computes an output value by applying a
    function to the input values of the previous layer. Incremental adjustments to
    these weights and biases are what helps the network to learn. If the same filter
    can be re-used, then the required memory footprint will be greatly reduced. This
    becomes very important, especially as the image or receptive field gets larger.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的另一个独特特征是许多神经元可以共享相同的权重和偏差向量，或者更正式地说，相同的**过滤器**。那为什么这很重要呢？因为每个神经元通过将一个函数应用于前一层的输入值来计算输出值。对这些权重和偏差的增量调整有助于网络学习。如果相同的过滤器可以被重用，那么所需的内存占用将大大减少。这变得非常重要，尤其是在图像或感受野变得更大时。
- en: 'CNNs have the following distinguishing features:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 具有以下特点：
- en: '**Three-dimensional volumes of neurons**: The layers of a CNN have neurons
    arranged in three dimensions: width, height, and depth. The neurons inside each
    layer are connected to a small region of the layer before it called their receptive
    field. Different types of connected layers are stacked to form the actual convolutional
    architecture, as shown in the following diagram:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经元的体积**：CNN 的层在三个维度上排列神经元：宽度、高度和深度。每个层内的神经元连接到其前一层的较小区域，称为它们的感受野。不同类型的连接层堆叠形成实际的卷积架构，如下所示：'
- en: '![](img/bb61aafc-a0ad-4dc4-88b6-bc5dd911e80a.png)**Convolving**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/bb61aafc-a0ad-4dc4-88b6-bc5dd911e80a.png)**卷积**'
- en: '**Shared weights**: In a convolutional neural network, each receptive field
    (filter) is replicated across the entire visual field, as the preceding image
    shows. These filters share the same weight vector and bias parameters, and form
    what is commonly referred to as a **feature map**. This means that all the neurons
    in a given convolutional layer respond to the same feature within their specific
    field. Replicating units in this way allows for features to be detected regardless
    of their position in the visual field. The following diagram is a simple example
    of what this means:'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享权重**：在卷积神经网络中，每个感受野（滤波器）在整个视觉场中复制，如前述图像所示。这些滤波器共享相同的权重向量和偏置参数，形成了通常所说的
    **特征图**。这意味着给定卷积层中的所有神经元对其特定区域内的同一特征做出响应。以这种方式复制单元允许无论特征在视觉场中的位置如何都能检测到特征。以下图是这一含义的简单示例：'
- en: '**This is a sample**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是一个示例**'
- en: This is a sample
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例
- en: This is a sample
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例
- en: This is a sample
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例
- en: Creating a network
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个网络
- en: 'Using the ConvNetSharp framework, there are three ways in which to create a
    neural network. First, we can use the `Core.Layers` or `Flow.Layers` objects to
    create a convolutional network (with or without a computational graph), as shown
    in the following diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ConvNetSharp 框架，有三种创建神经网络的方法。首先，我们可以使用 `Core.Layers` 或 `Flow.Layers` 对象创建卷积网络（带或不带计算图），如下所示：
- en: '![](img/43f2c91a-b159-41aa-96d6-8ad561d05816.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43f2c91a-b159-41aa-96d6-8ad561d05816.png)'
- en: 'Alternatively, we can create a computational graph like the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以创建一个如下所示的计算图：
- en: '![](img/3c529c15-1cf6-4a33-85e6-9e377fac4259.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c529c15-1cf6-4a33-85e6-9e377fac4259.png)'
- en: Example 1 – a simple example
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 1 – 一个简单示例
- en: 'Let''s take a look at our first example. This is a minimal example in which
    we will define a **two**-**layer neural network** and train it on a single data
    point. We are intentionally making this example verbose so that we can walk through
    each step together to improve our understanding:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的第一个示例。这是一个最简单的示例，我们将定义一个 **两层** 神经网络，并在单个数据点上对其进行训练。我们故意使这个例子详细，以便我们可以一起逐步了解，以加深我们的理解：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `InputLayer` variable declares size of input. As shown in the preceding
    code, we use two-dimensional data. Three-dimensional volumes (width, height, and
    depth) are required, but if you''re not dealing with images then we can leave
    the first two dimensions (width and height) at a size of 1, as we have done in
    the following example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`InputLayer` 变量声明了输入的大小。如前述代码所示，我们使用二维数据。需要三维体积（宽度、高度和深度），但如果您不处理图像，则可以将前两个维度（宽度和高度）设置为1，如下例所示：'
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Declare a fully-connected layer comprising `20` neurons, as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 声明一个包含 `20` 个神经元的全连接层，如下所示：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we need to declare a Rectified Linear Unit non-linearity (`ReLU`) layer,
    as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要声明一个 Rectified Linear Unit 非线性层（`ReLU`），如下所示：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, declare a fully-connected layer that will be used by the `SoftmaxLayer`
    with the following code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用以下代码声明一个全连接层，该层将被 `SoftmaxLayer` 使用：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Declare the linear classifier on top of the previous hidden layer, as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个隐藏层之上声明线性分类器，如下所示：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We then need to move forward with a random data point through the network,
    as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要通过一个随机数据点在网络中前进，如下所示：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`prob` is a volume. Volumes have property weights that store the raw data,
    and weight gradients that store gradients. The following code prints approximately
    0.50101, as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`prob` 是一个体积。体积具有属性权重，用于存储原始数据，以及权重梯度，用于存储梯度。以下代码打印出约 0.50101，如下所示：'
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we need to train the network, specifying that `x` is class zero and using
    a stochastic gradient descent trainer, shown as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要训练网络，指定 `x` 是类别零，并使用随机梯度下降训练器，如下所示：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The output should now be 0.50374, which is slightly higher than the previous
    value of 0.50101\. This is because the network weights have been adjusted by the
    `trainer` to give a higher probability to the class we trained the network with
    (which was zero).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的输出应该是0.50374，这略高于之前的0.50101。这是因为网络权重已经被`trainer`调整，给训练网络时我们训练的类别（即零）更高的概率。
- en: Example 2 – another simple example
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例2 – 另一个简单示例
- en: 'As in the previous section, the following example also solves a simple problem,
    while demonstrating how to save and load a graph as well:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如前文所述，以下示例同样解决了一个简单问题，同时展示了如何保存和加载一个图：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To create a graph, input the following code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个图，请输入以下代码：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, to compute the dCost/dW at every node of the graph, we use the following
    code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了计算图中每个节点的dCost/dW，我们使用以下代码：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To display the graph, input the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示图，请输入以下代码：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Example 3 – our final simple example
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例3 – 我们最后的简单示例
- en: 'The following example does a simple calculation and displays the resultant
    computational graph. The code needed is as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例执行了一个简单的计算，并显示了结果计算图。所需的代码如下：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To create a graph, use the following code:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个图，请使用以下代码：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, to compute the dCost/dW at every node of the graph, we use the following
    code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了计算图中每个节点的dCost/dW，我们使用以下代码：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, to display the graph, input the following code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了显示图，请输入以下代码：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Using the Fluent API
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Fluent API
- en: For those of you who have the bug for Fluent APIs, ConvNetSharp has done a job
    of providing one for you.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些有Fluent API错误的朋友，ConvNetSharp已经为您提供了一个解决方案。
- en: 'Just look at the following example to see how easy it is to use the Fluent
    DSL when adding layers:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 只需查看以下示例，看看使用Fluent DSL添加层是多么简单：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: GPU
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU
- en: In order to use GPU capability in your software using ConvNetSharp, you must
    have CUDA Version 8 and Cudnn Version 6.0 (April 27, 2017) installed. The `Cudnn
    bin path` should also be referenced in the **PATH** environment variable.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在您的软件中使用ConvNetSharp的GPU功能，您必须安装CUDA版本8和Cudnn版本6.0（2017年4月27日）。同时，`Cudnn bin
    path`也应该在**PATH**环境变量中引用。
- en: Fluent training with the MNIST database
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MNIST数据库进行Fluent训练
- en: In the following example, we will train our CNN against the `MNIST` database
    of images.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将训练我们的CNN对抗`MNIST`图像数据库。
- en: 'To declare a function, use the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 声明一个函数，请使用以下代码：
- en: '[PRE18]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, download the training and testing `datasets` with the following command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用以下命令下载训练和测试`datasets`：
- en: '[PRE19]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Load `100` validation sets with the following command:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令加载`100`个验证集：
- en: '[PRE20]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now it''s time to create the neural network using the Fluent API, as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候使用Fluent API创建神经网络了，如下所示：
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Create the stochastic gradient descent trainer from the network with the following
    command:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令从网络创建随机梯度下降训练器：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, get the `NextBatch` of data with the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用以下代码获取数据的`NextBatch`：
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`Train` the data received with the following command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令`Train`接收到的数据：
- en: '[PRE24]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'It''s now time to get the `NextBatch` of data; to do so, use the following
    command:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候获取数据的`NextBatch`；为此，请使用以下命令：
- en: '[PRE25]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The code can be tested with the following command:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令测试代码：
- en: '[PRE26]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To report the `accuracy`, input the following command:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要报告`accuracy`，请输入以下命令：
- en: '[PRE27]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Training the network
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练网络
- en: 'To train the convolutional network, we must perform both forward- and backward-propagation,
    as shown in the following example:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练卷积网络，我们必须执行前向和反向传播，如下所示：
- en: '[PRE28]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following screenshot illustrates our training in progress:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了我们的训练过程：
- en: '![](img/3a081492-e7e9-4de1-90cf-575f5f8f5f83.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a081492-e7e9-4de1-90cf-575f5f8f5f83.png)'
- en: Testing the data
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试数据
- en: 'This section details the `Test` function, which will show us how to test the
    data we have trained. We get the network prediction and track the accuracy for
    each label that we have with the following command:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细介绍了`Test`函数，它将向我们展示如何测试我们已训练的数据。我们通过以下命令获取网络预测并跟踪每个标签的准确性：
- en: '[PRE29]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`Forward` momentum can be found with the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`Forward`动量可以通过以下代码找到：'
- en: '[PRE30]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To track the `accuracy`, input the following code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟踪`accuracy`，请输入以下代码：
- en: '[PRE31]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Predicting data
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测数据
- en: 'Predicting data in this instance means predicting the `argmax` value. To do
    this, we assume that the last layer of the network is a `SoftmaxLayer`. Prediction
    occurs when we call the `GetPrediction()`function, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，预测数据意味着预测`argmax`值。为此，我们假设网络的最后一层是一个`SoftmaxLayer`。当调用`GetPrediction()`函数时，就会发生预测，如下所示：
- en: '[PRE32]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Computational graphs
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算图
- en: 'The following screenshots two computational graphs that we created based on
    our example applications:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们基于示例应用创建的两个计算图截图：
- en: '![](img/7d55cd18-0124-4aef-aab3-00679b65dea2.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7d55cd18-0124-4aef-aab3-00679b65dea2.png)'
- en: '![](img/255f4619-e2a1-41bc-9e33-712f0eac428d.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/255f4619-e2a1-41bc-9e33-712f0eac428d.png)'
- en: Summary
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we used the open source package ConvNetSharp to explain CNNs.
    We looked at how to test and train these networks and also learned why they are
    convolutional. We worked with several example applications to explain how ConvNetSharp
    functions and operates. In the next chapter, we will look at autoencoders and
    RNNSharp, exposing you further to recurrent neural networks.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了开源包ConvNetSharp来解释卷积神经网络。我们探讨了如何测试和训练这些网络，并学习了为什么它们是卷积的。我们与几个示例应用合作，解释了ConvNetSharp如何工作和操作。在下一章中，我们将探讨自编码器和RNNSharp，进一步向您介绍循环神经网络。
- en: References
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: ConvNetSharp Copyright (c) 2018 Cédric Bovar. Used with permission granted.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ConvNetSharp 版权所有 (c) 2018 Cédric Bovar。经许可使用。
- en: The mostly complete chart of neural networks, explained, Asimov Institute, used
    with permission granted.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的大部分完整图表，由Asimov Institute解释，经许可使用。
- en: '[http://scs.ryerson.ca/~aharley/vis/conv/flat.html](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://scs.ryerson.ca/~aharley/vis/conv/flat.html](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)'
