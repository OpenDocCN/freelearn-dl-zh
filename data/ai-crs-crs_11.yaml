- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: AI for Business – Minimize Costs with Deep Q-Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI在商业中的应用 – 通过深度Q学习最小化成本
- en: It's great that you can implement a deep Q-learning model to build a self-driving
    car. Really, once again, huge congratulations to you for that. But I also want
    you to be able to use deep Q-learning to solve a real-world business problem.
    With this next application, you'll be more than ready to add value to your work
    or business by leveraging AI. Even though we'll once again use a specific application,
    this chapter will provide you with a general AI framework, a blueprint containing
    the general steps of the process you have to follow when solving a real-world
    problem with deep Q-learning. This chapter is very important to you and for your
    career; I don't want you to close this book before you feel confident with the
    skills you'll learn here. Let's smash this next application together!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你能用深度Q学习模型来构建一辆自动驾驶汽车真是太棒了。真的，再次祝贺你。但我也希望你能用深度Q学习来解决现实世界的商业问题。通过这个下一个应用，你将完全准备好通过利用AI为你的工作或商业增加价值。尽管我们再次使用了一个具体应用，但这一章将为你提供一个通用的AI框架，一个包含你在用深度Q学习解决现实世界问题时必须遵循的一般步骤的蓝图。本章对你和你的职业生涯都非常重要；我不希望你在掌握这里学到的技能之前就把这本书合上。让我们一起冲破这个下一个应用吧！
- en: Problem to solve
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要解决的问题
- en: When I said we were going to solve a real-world business problem, I didn't overstate
    the problem; the problem we're about to tackle with deep Q-learning is very similar
    to the following, which was solved in the real world via deep Q-learning.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说我们要解决一个现实世界的商业问题时，我并没有夸大其词；我们将通过深度Q学习来解决的问题与以下问题非常相似，且该问题已经在现实世界中通过深度Q学习得以解决。
- en: 'In 2016, DeepMind AI minimized a big part of Google''s yearly costs by reducing
    the Google Data Center''s cooling bill by 40% using their DQN AI model (deep Q-learning).
    Check the link here:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在2016年，DeepMind AI通过使用其DQN AI模型（深度Q学习）将Google数据中心的冷却费用减少了40%，从而大大减少了Google的年度开支。请查看此链接：
- en: '[https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/)'
- en: In this case study, we'll do something very similar. We'll set up our own server
    environment, and we'll build an AI that controls the cooling and heating of the
    server so that it stays in an optimal range of temperatures while using the minimum
    of energy, therefore minimizing the costs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们将做类似的事情。我们将搭建自己的服务器环境，并且构建一个AI来控制服务器的冷却和加热，使其保持在最佳的温度范围内，同时尽可能节省能源，从而最小化成本。
- en: Just as the DeepMind AI did, our goal will be to achieve at least 40% energy
    savings! Are you ready for this? Let's bring it on!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 就像DeepMind AI所做的那样，我们的目标将是至少实现40%的能源节省！你准备好了吗？让我们开始吧！
- en: 'As ever, my first question to you is: What''s our first step?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我对你的第一个问题是：我们的第一步是什么？
- en: I'm sure by this point I don't need to spell out the answer. Let's get straight
    to building our environment!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信到此时，我不需要再拼写出答案了。让我们直接开始搭建环境吧！
- en: Building the environment
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搭建环境
- en: 'Before we define the states, actions, and rewards, we need to set up the server
    and explain how it operates. We''ll do that in several steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义状态、动作和奖励之前，我们需要搭建服务器并解释其操作方式。我们将分几步完成：
- en: First, we'll list all the environment parameters and variables by which the
    server is controlled.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将列出所有控制服务器的环境参数和变量。
- en: After that we'll set the essential assumptions of the problem, on which your
    AI will rely to provide a solution.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们将设定问题的基本假设，你的AI将依赖这些假设来提供解决方案。
- en: Then we'll specify how you'll simulate the whole process.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将指定如何模拟整个过程。
- en: Finally, we'll explain the overall functioning of the server, and how the AI plays
    its role.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将解释服务器的整体工作原理，以及AI如何发挥作用。
- en: Parameters and variables of the server environment
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务器环境的参数和变量
- en: 'Here is a list of all the parameters, which keep their values fixed, of the
    server environment:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是服务器环境中所有固定值参数的列表：
- en: The average atmospheric temperature for each month.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个月的平均大气温度。
- en: The optimal temperature range of the server, which we'll set as ![](img/B14110_11_001.png).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器的最佳温度范围，我们将其设置为 ![](img/B14110_11_001.png)。
- en: The minimum temperature, below which the server fails to operate, which we'll
    set as ![](img/B14110_11_002.png).
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最低温度，低于该温度服务器将无法正常运行，我们将其设置为 ![](img/B14110_11_002.png)。
- en: The maximum temperature, above which the server fails to operate, which we'll
    set as ![](img/B14110_11_003.png).
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器无法正常运行的最高温度，我们将其设置为！[](img/B14110_11_003.png)。
- en: The minimum number of users in the server, which we'll set as 10.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器的最小用户数量，我们将其设置为10。
- en: The maximum number of users in the server, which we'll set as 100.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器的最大用户数量，我们将其设置为100。
- en: The maximum change of users in the server per minute, which we'll set as 5;
    so every minute, the server can only have a change of 5 extra users or 5 fewer
    users at most.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器每分钟用户数量的最大变化值，我们将其设置为5；因此每分钟，服务器的用户数量最多只能变化增加5或减少5。
- en: The minimum rate of data transmission in the server, which we'll set as 20.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器的最小数据传输速率，我们将其设置为20。
- en: The maximum rate of data transmission in the server, which we'll set as 300.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器的最大数据传输速率，我们将其设置为300。
- en: The maximum change of the rate of data transmission per minute, which we'll
    set as 10; so every minute, the rate of data transmission can only change by a
    maximum value of 10 in either direction.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据传输速率每分钟的最大变化值，我们将其设置为10；因此每分钟，数据传输速率只能在任一方向上变化最多10。
- en: 'Next, we''ll list all the variables, which have values that fluctuate over
    time, of the server environment:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将列出服务器环境中所有的变量，这些变量的值会随时间波动：
- en: The temperature of the server at a given minute.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定时刻服务器的温度。
- en: The number of users connected to the server at a given minute.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定时刻连接到服务器的用户数量。
- en: The rate of data transmission at a given minute.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定时刻的数据传输速率。
- en: The energy spent by the AI onto the server (to cool it down or heat it up) at a given
    minute.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AI在给定时刻向服务器所消耗的能量（用于冷却或加热）。
- en: The energy that would be spent by the server's integrated cooling system to
    automatically bring the server's temperature back to the optimal range, whenever
    the server's temperature goes outside this optimal range. This is to keep track
    of how much energy a **non-AI** system would use, so we can compare our AI system
    to it.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器的集成冷却系统所消耗的能量，以自动将服务器温度恢复到最佳范围内，每当服务器温度超出这个最佳范围时。此举旨在跟踪**非AI**系统所使用的能量，以便与我们的AI系统进行比较。
- en: All these parameters and variables will be part of the environment, and will
    influence the actions of our AI.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些参数和变量都将成为环境的一部分，并将影响我们AI的行为。
- en: Next, we'll explain the two core assumptions of the environment. It's important
    to understand that these assumptions are not AI related, but just used to simplify
    the environment so that we can focus on creating a functional AI solution.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将解释环境的两个核心假设。需要理解的是，这些假设与AI无关，而是用来简化环境，使我们能够专注于创建一个功能性AI解决方案。
- en: Assumptions of the server environment
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务器环境的假设
- en: 'We''ll rely on the following two essential assumptions:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将依赖以下两个关键假设：
- en: Assumption 1 – We can approximate the server temperature
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假设1 – 我们可以近似服务器温度
- en: 'The temperature of the server can be approximated through Multiple Linear Regression,
    that is, by a linear function of the atmospheric temperature, the number of users
    and the rate of data transmission, like so:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器的温度可以通过多元线性回归来近似，即通过大气温度、用户数量和数据传输速率的线性函数来近似，如下所示：
- en: '*server temperature* = ![](img/B14110_11_004.png) + ![](img/B14110_11_005.png)
    *atmospheric temperature* + ![](img/B14110_11_006.png) *number of users* + ![](img/B14110_11_007.png)
    *rate of data transmission*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务器温度* = ![](img/B14110_11_004.png) + ![](img/B14110_11_005.png) *大气温度* +
    ![](img/B14110_11_006.png) *用户数量* + ![](img/B14110_11_007.png) *数据传输速率*'
- en: where ![](img/B14110_11_008.png), ![](img/B14110_11_009.png), ![](img/B14110_11_010.png),
    and ![](img/B14110_11_011.png).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中！[](img/B14110_11_008.png)、！[](img/B14110_11_009.png)、！[](img/B14110_11_010.png)
    和！[](img/B14110_11_011.png)。
- en: The raison d'être of this assumption and the reason why ![](img/B14110_11_012.png),
    ![](img/B14110_11_013.png), and ![](img/B14110_11_014.png) are intuitive to understand.
    It makes sense that when the atmospheric temperature increases, the temperature
    of the server increases. The more users that are connected to the server, the
    more energy the server has to spend handling them, and therefore the higher the
    temperature of the server will be. Finally, the more data is transmitted inside
    the server, the more energy the server has to spend processing it, and therefore
    the higher the temperature of the server will be.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这个假设的存在意义以及为什么 ![](img/B14110_11_012.png)，![](img/B14110_11_013.png)，和 ![](img/B14110_11_014.png)
    是直观易懂的原因。可以理解的是，当大气温度升高时，服务器的温度也会升高。连接到服务器的用户越多，服务器需要花费更多的能量来处理它们，因此服务器的温度会更高。最后，服务器内部传输的数据越多，服务器需要花费更多的能量来处理这些数据，因此服务器的温度也会更高。
- en: For simplicity's sake, we can just suppose that these correlations are linear.
    However, you could absolutely run the same simulation by assuming they were quadratic
    or logarithmic, and altering the code to reflect those equations. This is just
    my simulation of a virtual server environment; feel free to tweak it as you like!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，我们可以假设这些相关性是线性的。然而，您完全可以假设它们是二次或对数的，并相应地修改代码来反映这些方程式。这只是我对虚拟服务器环境的模拟；您可以根据需要进行调整！
- en: 'Let''s assume further that after performing this Multiple Linear Regression,
    we obtained the following values of the coefficients: ![](img/B14110_11_015.png),
    ![](img/B14110_11_016.png), ![](img/B14110_11_017.png), and ![](img/B14110_11_018.png).
    Accordingly:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在执行此多元线性回归后，我们得到了以下系数值：![](img/B14110_11_015.png)，![](img/B14110_11_016.png)，![](img/B14110_11_017.png)，以及![](img/B14110_11_018.png)。因此：
- en: '*server temperature* = *atmospheric temperature* + ![](img/B14110_11_019.png)
    *number of users* + ![](img/B14110_11_020.png) *rate of data transmission*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务器温度* = *大气温度* + ![](img/B14110_11_019.png) *用户数量* + ![](img/B14110_11_020.png)
    *数据传输速率*'
- en: Now, if we were facing this problem in real life, we could get the dataset of
    temperatures for our server and calculate these values directly. Here, we're just
    assuming values that are easy to code and understand, because our goal in this
    chapter is not to perfectly model a real server; it's to go through the steps
    of solving a real-world problem with AI.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们在现实生活中面对这个问题，我们可以获取服务器温度的数据集，并直接计算这些值。在这里，我们只是假设一些易于编码和理解的值，因为本章的目标不是完美地模拟一个真实服务器，而是通过人工智能的步骤解决一个现实世界的问题。
- en: Assumption 2 – We can approximate the energy costs
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假设 2 – 我们可以近似计算能源成本
- en: 'The energy spent by any cooling system, either our AI or the server''s integrated
    cooling system that we''ll compare our AI to, that changes the server''s temperature
    from ![](img/B14110_11_021.png) to ![](img/B14110_11_022.png) within 1 unit of
    time (in our case 1 minute), can be approximated again through regression by a
    linear function of the server''s absolute temperature change, as so:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 任何冷却系统（无论是我们的 AI 还是我们与之对比的服务器集成冷却系统）在 1 个时间单位内（在我们这里是 1 分钟）将服务器温度从 ![](img/B14110_11_021.png)
    变化到 ![](img/B14110_11_022.png) 所消耗的能量，可以通过回归近似为一个服务器绝对温度变化的线性函数，如下所示：
- en: '![](img/B14110_11_023.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_023.png)'
- en: 'where:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](img/B14110_11_024.png) is the energy spent by the system on the server
    between times ![](img/B14110_11_025.png) and ![](img/B14110_11_026.png) minute.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_024.png) 是系统在时间 ![](img/B14110_11_025.png) 和 ![](img/B14110_11_026.png)
    分钟之间消耗的能量。'
- en: '![](img/B14110_11_027.png) is the change in the server''s temperature caused
    by the system, between times ![](img/B14110_11_028.png) and ![](img/B14110_11_029.png)
    minute.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_027.png) 是由系统引起的服务器温度变化，在时间 ![](img/B14110_11_028.png) 和
    ![](img/B14110_11_029.png) 分钟之间。'
- en: '![](img/B14110_11_030.png) is the temperature of the server at time ![](img/B14110_11_031.png).'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_030.png) 是时间 ![](img/B14110_11_031.png) 分钟时服务器的温度。'
- en: '![](img/B14110_11_032.png) is the temperature of the server at time ![](img/B14110_11_026.png)
    minute.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_032.png) 是在时间 ![](img/B14110_11_026.png) 分钟时服务器的温度。'
- en: '![](img/B14110_11_034.png).'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_034.png)。'
- en: '![](img/B14110_11_035.png).'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_035.png)。'
- en: Let's explain why it intuitively makes sense to make this assumption with ![](img/B14110_11_036.png).
    That's simply because the more the AI or the old-fashioned integrated cooling
    system heats up or cools down the server, the more energy it spends to achieve
    that heat transfer.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用![](img/B14110_11_036.png)来解释为什么这个假设在直观上是合理的。这仅仅是因为，AI或传统的集成冷却系统越是加热或冷却服务器，它所花费的能量越多，才能实现那个热量转移。
- en: For example, imagine the server suddenly has overheating issues and just reached
    ![](img/B14110_11_037.png)C; then within one unit of time (1 minute), either system
    will need much more energy to bring the server's temperature back to its optimal
    temperature, ![](img/B14110_11_038.png)C, than to bring it back to ![](img/B14110_11_039.png)C.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设服务器突然出现过热问题，温度已经达到了![](img/B14110_11_037.png)C；那么在一个时间单位（1分钟）内，任何系统都需要更多的能量才能将服务器的温度从过高温度恢复到其最佳温度![](img/B14110_11_038.png)C，而不是将其恢复到![](img/B14110_11_039.png)C。
- en: For simplicity's sake, in this example we suppose that these correlations are
    linear, instead of calculating true values from a real dataset. In case you're
    wondering why we take the absolute value, that's simply because when the AI cools
    down the server, ![](img/B14110_11_040.png), so ![](img/B14110_11_041.png). Since
    an energy cost is always positive, we have to take the absolute value of ![](img/B14110_11_042.png).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，在这个例子中我们假设这些相关性是线性的，而不是从真实数据集中计算出实际值。如果你在想为什么我们取绝对值，那是因为当AI冷却服务器时，![](img/B14110_11_040.png)，因此！[](img/B14110_11_041.png)。由于能量消耗总是正数，我们必须取![](img/B14110_11_042.png)的绝对值。
- en: 'Keeping our desired simplicity in mind, we''ll assume that the results of the
    regression are ![](img/B14110_11_043.png) and ![](img/B14110_11_044.png), so that
    we get the following final equation based on Assumption 2:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记我们想要的简化假设，我们假设回归结果为![](img/B14110_11_043.png)和![](img/B14110_11_044.png)，因此我们根据*假设2*得出以下最终方程：
- en: '![](img/B14110_11_045.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_045.png)'
- en: 'thus:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此：
- en: '![](img/B14110_11_046.png), that is, if the server is heated up,'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_046.png)，也就是说，如果服务器被加热，'
- en: '![](img/B14110_11_047.png), that is, if the server is cooled down.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_047.png)，也就是说，如果服务器被冷却。'
- en: Now we've got our assumptions covered, let's explain how we'll simulate the
    operation of the server, with users logging on and off and data coming in and
    out.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经覆盖了假设，接下来让我们解释如何模拟服务器的运行，用户登录与退出，以及数据的进出。
- en: Simulation
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 仿真
- en: The number of users and the rate of data transmission will randomly fluctuate,
    to simulate the unpredictable user activity and data requirements of an actual
    server. This leads to randomness in the temperature. The AI needs to learn how
    much cooling or heating power it should transfer to the server so as to not deteriorate
    the server performance, and at the same time, expend as little energy as possible
    by optimizing its heat transfer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 用户数量和数据传输速率将会随机波动，以模拟实际服务器中不可预测的用户活动和数据需求。这导致了温度的随机性。AI需要学习它应该向服务器传输多少冷却或加热能量，以避免服务器性能恶化，同时通过优化热量转移来尽可能减少能量消耗。
- en: Now that we have the full picture, I'll explain the overall functioning of the
    server and the AI inside this environment.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了完整的图景，接下来我将解释在这个环境下服务器和AI的整体功能。
- en: Overall functioning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 整体功能
- en: Inside a data center, we're dealing with a specific server that is controlled
    by the parameters and variables listed previously. Every minute, some new users
    log on to the server and some current users log off, therefore updating the number
    of active users in the server. Also, every minute some new data is transmitted
    into the server, and some existing data is transmitted outside the server, therefore
    updating the rate of data transmission happening inside the server.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据中心内，我们处理的是一个特定的服务器，这个服务器由之前列出的参数和变量控制。每分钟，都会有一些新用户登录到服务器，也会有一些当前用户退出服务器，因此更新服务器中活动用户的数量。同时，每分钟会有一些新的数据传输到服务器，也会有一些现有数据从服务器传出，从而更新服务器内部的数据传输速率。
- en: Hence, based on *Assumption 1* given earlier, the temperature of the server
    is updated every minute. Now please focus, because this is where you'll understand
    the huge role the AI has to play on the server.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基于之前给出的*假设1*，服务器的温度每分钟更新一次。现在请集中注意力，因为在这里你将理解到AI在服务器中所扮演的重要角色。
- en: 'Two possible systems can regulate the temperature of the server: the AI, or
    the server''s integrated cooling system. The server''s integrated cooling system
    is an unintelligent system that automatically brings the server''s temperature
    back inside its optimal temperature range.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种可能的系统可以调节服务器的温度：AI或服务器的集成冷却系统。服务器的集成冷却系统是一个没有智能的系统，会自动将服务器的温度带回其最佳温度范围。
- en: Every minute, the server's temperature is updated. If the server is using the
    integrated cooling system, that system watches to see what happens; that update
    can either leave the temperature within the range of optimal temperatures (![](img/B14110_11_048.png)),
    or move it outside this range. If it goes outside the optimal range, for example
    to ![](img/B14110_11_049.png)C, the server's integrated cooling system automatically
    brings the temperature back to the closest bound of the optimal range, in this
    case ![](img/B14110_11_038.png)C. For the purposes of our simulation, we're assuming
    that no matter how big the change in temperature is, the integrated cooling system
    can bring it back into the optimal range in under a minute. This is, obviously,
    an unrealistic assumption, but the purpose of this chapter is for you to build
    a functioning AI capable of solving the problem, not to perfectly simulate the
    thermal dynamics of a real server. Once we've completed our example together,
    I highly recommend that you tinker with the code and try to make it more realistic;
    for now, to keep things simple, we'll believe in our magically effective integrated
    cooling system.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 每分钟，服务器的温度会被更新。如果服务器使用集成冷却系统，该系统会观察发生了什么；这个更新可能会使温度保持在最佳温度范围内（![](img/B14110_11_048.png)），或者将其推移到这个范围之外。如果它超出了最佳范围，例如达到![](img/B14110_11_049.png)C，服务器的集成冷却系统会自动将温度带回最佳范围的最近边界，在此案例中是![](img/B14110_11_038.png)C。为了我们的模拟假设，不管温度变化有多大，我们假设集成冷却系统可以在不到一分钟的时间内将其恢复到最佳范围。这显然是一个不现实的假设，但本章的目的是让你构建一个能解决问题的功能性AI，而不是完美地模拟真实服务器的热力学。一旦我们一起完成这个示例，我强烈建议你修改代码并尝试让它更现实；目前，为了简化问题，我们将相信这个神奇有效的集成冷却系统。
- en: If the server is instead using the AI, then in that case the server's integrated
    cooling system is deactivated and it is the AI itself that updates the temperature
    of the server to regulate it the best way. The AI changes the temperature after
    making some prior predictions, not in a purely deterministic way as with the unintelligent
    integrated cooling system. Before there's an update to the number of users and
    the rate of data transmission, causing a change in the temperature of the server,
    the AI predicts if it should cool down the server, do nothing, or heat up the
    server, and acts. Then the temperature change happens and the AI reiterates.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果服务器改为使用AI，那么服务器的集成冷却系统将被禁用，由AI本身来更新服务器的温度，以最佳方式进行调节。AI在进行一些先前预测后改变温度，而不是像没有智能的集成冷却系统那样以完全确定的方式改变温度。在更新用户数量和数据传输速率之前，AI会预测是否应该降温、什么都不做，或者加热服务器，并进行相应的操作。然后温度变化发生，AI会重新迭代。
- en: Since these two systems are distinct from one another, we can evaluate them
    separately to compare their performance; to train or run the AI on a server, while
    keeping track of how much energy the integrated cooling system would have used
    in the same circumstances.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这两个系统彼此独立，我们可以单独评估它们以比较性能；训练或运行AI时，我们可以跟踪在相同情况下集成冷却系统所消耗的能量。
- en: 'That brings us to the energy. Remember that one primary goal of the AI is to
    lower the energy cost of running this server. Accordingly, our AI has to try and
    use less energy than the unintelligent cooling system would use on the server.
    Since, based on *Assumption 2* given preceding, the energy spent on the server
    (by any system) is proportional to the change of temperature within one unit of
    time:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了能量问题。记住，AI的一个主要目标是降低运行服务器的能量成本。因此，我们的AI必须尽量使用比没有智能的冷却系统在服务器上使用的能量更少。由于根据前面的*假设2*，服务器上花费的能量（无论是哪个系统）与单位时间内的温度变化成正比：
- en: '![](img/B14110_11_051.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_051.png)'
- en: 'thus:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此：
- en: '![](img/B14110_11_052.png), that is, if the server is heated up,'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_052.png)，也就是说，如果服务器加热，'
- en: '![](img/B14110_11_053.png), that is, if the server is cooled down,'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_053.png)，也就是说，如果服务器降温，'
- en: 'then that means that the energy saved by the AI at each iteration ![](img/B14110_11_054.png)
    (each minute) is equal to the difference in absolute changes of temperatures caused
    in the server between the unintelligent server''s integrated cooling system and
    the AI from ![](img/B14110_11_055.png) and ![](img/B14110_11_056.png):'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这意味着AI在每次迭代 ![](img/B14110_11_054.png)（每分钟）节省的能量等于由非智能服务器的集成冷却系统与AI之间在服务器中造成的温度绝对变化的差异，从
    ![](img/B14110_11_055.png) 到 ![](img/B14110_11_056.png)：
- en: Energy saved by the AI between ![](img/B14110_11_057.png) and ![](img/B14110_11_058.png)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: AI在 ![](img/B14110_11_057.png) 和 ![](img/B14110_11_058.png) 之间节省的能量
- en: '![](img/B14110_11_059.png)![](img/B14110_11_060.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_059.png)![](img/B14110_11_060.png)'
- en: 'where:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](img/B14110_11_061.png) is the change of temperature that the server''s
    integrated cooling system would cause in the server during the iteration ![](img/B14110_11_062.png),
    that is, from ![](img/B14110_11_063.png) to ![](img/B14110_11_064.png) minute.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_061.png) 是服务器集成冷却系统在迭代 ![](img/B14110_11_062.png) 期间在服务器中造成的温度变化，即从
    ![](img/B14110_11_063.png) 到 ![](img/B14110_11_064.png) 分钟。'
- en: '![](img/B14110_11_065.png) is the change of temperature that the AI would cause
    in the server during the iteration ![](img/B14110_11_062.png), that is, from ![](img/B14110_11_062.png)
    to ![](img/B14110_11_068.png) minute.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_065.png) 是AI在迭代 ![](img/B14110_11_062.png) 期间在服务器中造成的温度变化，即从
    ![](img/B14110_11_062.png) 到 ![](img/B14110_11_068.png) 分钟。'
- en: The AIs goal is to save as much as it can every minute, therefore saving the
    maximum total energy over 1 full year of simulation, and eventually saving the
    business the maximum cost possible on their cooling/heating electricity bill.
    That's how we do business in the 21st century; with AI!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: AI的目标是每分钟尽可能节省能源，从而在1年的模拟中节省最大总能量，并最终帮助企业在冷却/加热电费上节省最大成本。这就是我们在21世纪做生意的方式；有了AI！
- en: 'Now that we fully understand how our server environment works, and how it''s
    simulated, it''s time to proceed with what absolutely must be done when defining
    an AI environment. You know the next steps already:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完全理解了服务器环境的工作方式，以及它是如何被模拟的，接下来是定义AI环境时绝对必须做的事情。你已经知道接下来的步骤：
- en: Defining the states.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义状态。
- en: Defining the actions.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义动作。
- en: Defining the rewards.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义奖励。
- en: Defining the states
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义状态
- en: 'Remember, when you''re doing deep Q-learning, the input state is always a 1D
    vector. (Unless you are doing deep convolutional Q-learning, in which case the
    input state is a 2D image, but that''s getting ahead of ourselves! Wait for *Chapter
    12*, *Deep Convolution Q-Learning*). So, what will the input state vector be in
    this server environment? What information will it contain in order to describe
    well enough each state of the environment? These are the questions you must ask
    yourself when modeling an AI problem and building the environment. Try to answer
    these questions first on your own and figure out the input state vector in this
    case, and you can find out what we''re using in the next paragraph. Hint: have
    a look again at the variable defined preceding.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，当你进行深度Q学习时，输入状态总是一个1D向量。（除非你在进行深度卷积Q学习，在这种情况下，输入状态是一个2D图像，但那是另一个话题！等到*第12章*，*深度卷积Q学习*再说）。那么，在这个服务器环境中，输入状态向量是什么？它将包含哪些信息，才能充分描述环境的每一个状态？这些是你在建模AI问题并构建环境时必须问自己的问题。试着先自己回答这些问题，找出在这种情况下的输入状态向量，接下来你可以看看我们在下一段中使用了什么。提示：再看一下前面定义的变量。
- en: 'The input state ![](img/B14110_11_069.png) at time ![](img/B14110_11_070.png)
    is composed of the following three elements:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输入状态 ![](img/B14110_11_069.png) 在时间 ![](img/B14110_11_070.png) 由以下三个元素组成：
- en: The temperature of the server at time ![](img/B14110_11_031.png)
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间 ![](img/B14110_11_031.png) 服务器的温度
- en: The number of users in the server at time ![](img/B14110_11_072.png)
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间 ![](img/B14110_11_072.png) 服务器中的用户数量
- en: The rate of data transmission in the server at time ![](img/B14110_11_028.png)
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间 ![](img/B14110_11_028.png) 服务器中的数据传输速率
- en: Thus, the input state will be an input vector of these three elements. Our future
    AI will take this vector as input, and will return an action to perform at each
    time, ![](img/B14110_11_074.png). Speaking of the actions, what are they going
    to be? Let's find out.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，输入状态将是这三个元素的输入向量。我们未来的AI将以这个向量作为输入，并会在每个时刻返回一个动作 ![](img/B14110_11_074.png)。说到动作，它们将是什么？我们一起来看看。
- en: Defining the actions
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义动作
- en: 'To figure out which actions to perform, we need to remember the goal, which
    is to optimally regulate the temperature of the server. The actions are simply
    going to be the temperature changes that the AI can cause inside the server, in
    order to heat it up or cool it down. In deep Q-learning, the actions must always
    be discrete; they can''t be plucked from a range, we need a defined number of
    possible actions. Therefore, we''ll consider five possible temperature changes,
    from ![](img/B14110_11_075.png)C to ![](img/B14110_11_076.png)C, so that we end
    up with five possible actions that the AI can perform to regulate the temperature
    of the server:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定需要执行哪些动作，我们需要记住目标，即最优调节服务器温度。动作简单来说就是AI能够在服务器内部引起的温度变化，用以加热或冷却服务器。在深度Q学习中，动作必须是离散的；它们不能从一个范围中选取，我们需要一个明确数量的可能动作。因此，我们将考虑五个可能的温度变化，从![](img/B14110_11_075.png)C到![](img/B14110_11_076.png)C，这样我们就得到了AI可以用来调节服务器温度的五个可能动作：
- en: '![](img/B14110_11_01.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_01.png)'
- en: 'Figure 1: Defining the actions'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：定义动作
- en: Great. Finally, let's see how we're going to reward and punish our AI.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了。最后，让我们看看如何对AI进行奖励和惩罚。
- en: Defining the rewards
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义奖励
- en: 'You might have guessed from the earlier *Overall functioning* section what
    the reward is going to be. The reward at iteration ![](img/B14110_11_054.png)
    is the energy saved by the AI, with respect to how much energy the server''s integrated
    cooling system would have spent; that is, the difference between the energy that
    the unintelligent cooling system would spend if the AI was deactivated, and the
    energy that the AI spends on the server:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经从之前的*总体功能*部分猜到奖励是什么。在迭代![](img/B14110_11_054.png)时，奖励是AI节省的能量，具体是相对于服务器集成冷却系统本应消耗的能量；也就是说，AI关闭时非智能冷却系统本应消耗的能量与AI为服务器所消耗的能量之间的差异：
- en: '![](img/B14110_11_078.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_078.png)'
- en: 'Since according to *Assumption 2*, the energy spent is equal to the change
    of the temperature induced in the server (by any system, including the AI or the
    unintelligent cooling system):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于根据*假设2*，所消耗的能量等于服务器中温度变化所引起的能量变化（无论是由任何系统引起，包括AI或非智能冷却系统）：
- en: '![](img/B14110_11_079.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_079.png)'
- en: 'thus:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此：
- en: '![](img/B14110_11_080.png), if the server is heated up,'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_080.png)，如果服务器加热，'
- en: '![](img/B14110_11_081.png), if the server is cooled down,'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_081.png)，如果服务器被冷却，'
- en: 'then we receive a reward at time ![](img/B14110_11_028.png) that is the difference
    in the change of temperature caused in the server between unintelligent cooling
    system (that is when there is no AI) and the AI:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在时刻![](img/B14110_11_028.png)收到奖励，奖励是服务器中温度变化的差异，比较非智能冷却系统（即没有AI的情况下）与AI的效果：
- en: Energy saved by the AI between ![](img/B14110_11_083.png) and ![](img/B14110_11_084.png)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: AI在![](img/B14110_11_083.png)和![](img/B14110_11_084.png)之间节省的能量
- en: '![](img/B14110_11_085.png)![](img/B14110_11_086.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_085.png)![](img/B14110_11_086.png)'
- en: 'where:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](img/B14110_11_087.png) is the change of temperature that the server''s
    integrated cooling system would cause in the server during the iteration ![](img/B14110_11_088.png),
    that is, from ![](img/B14110_11_028.png) to ![](img/B14110_11_026.png) minute.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_087.png)是服务器集成冷却系统在迭代![](img/B14110_11_088.png)期间对服务器造成的温度变化，即从![](img/B14110_11_028.png)到![](img/B14110_11_026.png)分钟。'
- en: '![](img/B14110_11_091.png) is the change of temperature that the AI would cause
    in the server during the iteration ![](img/B14110_11_062.png), that is, from ![](img/B14110_11_062.png)
    to ![](img/B14110_11_094.png) minute.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B14110_11_091.png)是AI在迭代![](img/B14110_11_062.png)期间对服务器造成的温度变化，即从![](img/B14110_11_062.png)到![](img/B14110_11_094.png)分钟。'
- en: '**Important note**: It''s important to understand that the systems (our AI
    and the server''s integrated cooling system) will be evaluated separately, in
    order to compute the rewards. Since at each time point the actions of the two
    different systems lead to different temperatures, we have to keep track of the
    two temperatures separately, as ![](img/B14110_11_095.png) and ![](img/B14110_11_096.png).
    In other words, we''re performing two separate simulations at the same time, following
    the same fluctuations of users and data; one for the AI, and one for the server''s
    integrated cooling system.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要说明**：需要理解的是，系统（我们的AI和服务器的集成冷却系统）将被单独评估，以计算奖励。由于每个时刻，两个不同系统的行为会导致不同的温度，我们必须分别记录这两个温度，分别为![](img/B14110_11_095.png)和![](img/B14110_11_096.png)。换句话说，我们正在同时进行两个独立的模拟，跟踪用户和数据的波动；一个是AI的，另一个是服务器集成冷却系统的。'
- en: To complete this section, we'll do a small simulation of 2 iterations (that
    is, 2 minutes) as an example to make everything crystal clear.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这一部分，我们将做一个小的模拟，模拟2次迭代（即2分钟），作为示例来使一切更加清晰。
- en: Final simulation example
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终模拟示例
- en: 'Let''s say that we''re at time ![](img/B14110_11_097.png) pm, and that the
    temperature of the server is ![](img/B14110_11_098.png)C, both with the AI and
    without it. At this exact time, the AI predicts an action: 0, 1, 2, 3 or 4\. Since,
    right now, the server''s temperature is outside the optimal temperature range,
    ![](img/B14110_11_099.png), the AI will probably predict actions 0, 1 or 2\. Let''s
    say that it predicts 1, which corresponds to cooling the server down by ![](img/B14110_11_100.png)C.
    Therefore, between ![](img/B14110_11_097.png) pm and ![](img/B14110_11_102.png)
    pm, the AI makes the server''s temperature go from ![](img/B14110_11_103.png)
    to ![](img/B14110_11_104.png):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 假设现在是下午![](img/B14110_11_097.png)，服务器的温度是![](img/B14110_11_098.png)℃，无论有无AI，情况都一样。在这个确切的时刻，AI会预测一个动作：0、1、2、3或4。由于此时服务器的温度已经超出了最佳温度范围![](img/B14110_11_099.png)，因此AI很可能会预测动作0、1或2。假设它预测的是1，这意味着将服务器温度降至![](img/B14110_11_100.png)℃。因此，在下午![](img/B14110_11_097.png)到![](img/B14110_11_102.png)之间，AI将服务器的温度从![](img/B14110_11_103.png)调整到![](img/B14110_11_104.png)：
- en: '![](img/B14110_11_105.png)![](img/B14110_11_106.png)![](img/B14110_11_107.png)![](img/B14110_11_108.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_105.png)![](img/B14110_11_106.png)![](img/B14110_11_107.png)![](img/B14110_11_108.png)'
- en: 'Thus, based on *Assumption 2*, the energy spent by the AI on the server is:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据*假设2*，AI对服务器消耗的能量为：
- en: '![](img/B14110_11_109.png)![](img/B14110_11_110.png)![](img/B14110_11_111.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_109.png)![](img/B14110_11_110.png)![](img/B14110_11_111.png)'
- en: 'Now only one piece of information is missing to compute the reward: the energy
    that the server''s integrated cooling system would have spent if the AI was deactivated
    between 4:00 pm and 4:01 pm. Remember that this unintelligent cooling system automatically
    brings the server''s temperature back to the closest bound of the optimal temperature
    range ![](img/B14110_11_112.png). Since at ![](img/B14110_11_097.png) pm the temperature
    was ![](img/B14110_11_114.png)C, then the closest bound of the optimal temperature
    range at that time was ![](img/B14110_11_115.png)C. Thus, the server''s integrated
    cooling system would have changed the temperature from ![](img/B14110_11_116.png)
    to ![](img/B14110_11_117.png), and the server''s temperature change that would
    have occurred if there was no AI is:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，计算奖励时只缺少一个信息：如果在下午4:00到4:01之间AI被停用，服务器的集成冷却系统将消耗多少能量。请记住，这个非智能冷却系统会自动将服务器的温度调整到最佳温度范围的最接近边界![](img/B14110_11_112.png)。由于在下午![](img/B14110_11_097.png)时，温度为![](img/B14110_11_114.png)℃，因此当时最佳温度范围的最接近边界为![](img/B14110_11_115.png)℃。因此，服务器的集成冷却系统将温度从![](img/B14110_11_116.png)调整到![](img/B14110_11_117.png)，如果没有AI，服务器温度的变化为：
- en: '![](img/B14110_11_118.png)![](img/B14110_11_119.png)![](img/B14110_11_120.png)![](img/B14110_11_121.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_118.png)![](img/B14110_11_119.png)![](img/B14110_11_120.png)![](img/B14110_11_121.png)'
- en: 'Based on *Assumption 2*, the energy that the unintelligent cooling system would
    have spent if there was no AI is:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 根据*假设2*，如果没有AI，非智能冷却系统所消耗的能量为：
- en: '![](img/B14110_11_122.png)![](img/B14110_11_123.png)![](img/B14110_11_1231.png)![](img/B14110_11_124.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_122.png)![](img/B14110_11_123.png)![](img/B14110_11_1231.png)![](img/B14110_11_124.png)'
- en: 'In conclusion, the reward the AI gets after playing this action at time ![](img/B14110_11_097.png)
    pm is:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，AI在下午![](img/B14110_11_097.png)进行这一动作后获得的奖励为：
- en: '![](img/B14110_11_126.png)![](img/B14110_11_127.png)![](img/B14110_11_128.png)![](img/B14110_11_129.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_126.png)![](img/B14110_11_127.png)![](img/B14110_11_128.png)![](img/B14110_11_129.png)'
- en: I'm sure you'll have noticed that as it stands, our AI system doesn't involve
    itself with the optimal range of temperatures for the server; as I've mentioned
    before, everything comes from the rewards, and the AI doesn't get any reward for
    being inside the optimal range or any penalty for being outside it. Once we've
    built the AI completely, I recommend that you play around with the code and try
    adding some rewards or penalties that get the AI to stick close to the optimal
    range; but for now, to keep things simple and get our AI up and running, we'll
    leave the reward as entirely linked to energy saved.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你已经注意到，当前我们的AI系统并未涉及服务器的最佳温度范围；正如我之前提到的，所有内容都来自于奖励，而AI在最佳温度范围内并不会获得奖励，也不会因超出范围而受到惩罚。一旦我们完全构建了AI，我建议你可以尝试修改代码，添加一些奖励或惩罚机制，让AI尽可能保持在最佳温度范围内；但现在，为了简化操作并让我们的AI正常运行，我们将奖励完全与节省的能量挂钩。
- en: 'Then, between ![](img/B14110_11_130.png) pm and ![](img/B14110_11_131.png)
    pm, new things happen: some new users log on to the server, some existing users
    log off, some new data transmits into the server, and some existing data transmits
    out. Based on *Assumption 1*, these factors make the server''s temperature change.
    Let''s say that overall, they increase the server''s temperature by ![](img/B14110_11_132.png)C:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在![](img/B14110_11_130.png) pm到![](img/B14110_11_131.png) pm之间，会发生一些新变化：一些新用户登录到服务器，一些现有用户登出，新的数据传输进服务器，已有的数据传输出服务器。根据*假设
    1*，这些因素使得服务器的温度发生变化。假设总的来说，它们将服务器的温度提高了![](img/B14110_11_132.png)C：
- en: '![](img/B14110_11_133.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_133.png)'
- en: 'Now, remember that we''re evaluating two systems separately: our AI, and the
    server''s integrated cooling system. Therefore we must compute the two temperatures
    we would get with each of these two systems separately, one without the other,
    at ![](img/B14110_11_134.png) pm. Let''s start with the AI.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，请记住我们分别评估两个系统：我们的AI和服务器的集成冷却系统。因此，我们必须分别计算这两个系统在![](img/B14110_11_134.png)
    pm时得到的温度，假设这两个系统互不干扰。我们先从AI开始。
- en: 'The temperature we get at ![](img/B14110_11_102.png) pm when the AI is activated
    is:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当AI启用时，在![](img/B14110_11_102.png) pm时我们得到的温度是：
- en: '![](img/B14110_11_136.png)![](img/B14110_11_137.png)![](img/B14110_11_138.png)![](img/B14110_11_139.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_136.png)![](img/B14110_11_137.png)![](img/B14110_11_138.png)![](img/B14110_11_139.png)'
- en: 'And the temperature we get at ![](img/B14110_11_140.png) pm if the AI is not
    activated is:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI未启用，那么在![](img/B14110_11_140.png) pm时我们得到的温度是：
- en: '![](img/B14110_11_141.png)![](img/B14110_11_142.png)![](img/B14110_11_143.png)![](img/B14110_11_144.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_141.png)![](img/B14110_11_142.png)![](img/B14110_11_143.png)![](img/B14110_11_144.png)'
- en: Now we have our two separate temperatures, which are ![](img/B14110_11_145.png)=
    31.5°*C* when the AI is activated, and ![](img/B14110_11_146.png)= 29°*C* when
    the AI is not activated.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了两个独立的温度，当AI启用时，温度为![](img/B14110_11_145.png)= 31.5°C，当AI未启用时，温度为![](img/B14110_11_146.png)=
    29°C。
- en: 'Let''s simulate what happens between ![](img/B14110_11_147.png) pm and ![](img/B14110_11_148.png)
    pm. Again, our AI will make a prediction, and since the server is heating up,
    let''s say it predicts action 0, which corresponds to cooling down the server
    by ![](img/B14110_11_149.png), bringing it down to ![](img/B14110_11_150.png).
    Therefore, the energy spent by the AI between ![](img/B14110_11_151.png) pm and
    ![](img/B14110_11_152.png) pm is:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们模拟一下![](img/B14110_11_147.png) pm到![](img/B14110_11_148.png) pm之间会发生什么。再次强调，我们的AI将做出预测，假设服务器正在升温，那么它预测执行动作0，也就是让服务器降温![](img/B14110_11_149.png)，降至![](img/B14110_11_150.png)。因此，AI在![](img/B14110_11_151.png)
    pm到![](img/B14110_11_152.png) pm之间消耗的能量是：
- en: '![](img/B14110_11_153.png)![](img/B14110_11_154.png)![](img/B14110_11_155.png)![](img/B14110_11_156.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_153.png)![](img/B14110_11_154.png)![](img/B14110_11_155.png)![](img/B14110_11_156.png)'
- en: 'Now regarding the server''s integrated cooling system (that is, when there
    is no AI), since at ![](img/B14110_11_157.png) pm we had ![](img/B14110_11_158.png),
    then the closest bound of the optimal range of temperatures is still ![](img/B14110_11_159.png),
    and so the energy that the server''s unintelligent cooling system would spend
    between ![](img/B14110_11_102.png) pm and ![](img/B14110_11_161.png) pm is:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在关于服务器的集成冷却系统（即当没有AI时），由于在![](img/B14110_11_157.png) pm时我们有![](img/B14110_11_158.png)，因此最佳温度范围的最近边界仍然是![](img/B14110_11_159.png)，所以服务器的非智能冷却系统在![](img/B14110_11_102.png)
    pm到![](img/B14110_11_161.png) pm之间将消耗的能量是：
- en: '![](img/B14110_11_162.png)![](img/B14110_11_163.png)![](img/B14110_11_164.png)![](img/B14110_11_165.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_162.png)![](img/B14110_11_163.png)![](img/B14110_11_164.png)![](img/B14110_11_165.png)'
- en: 'Hence the reward obtained between ![](img/B14110_11_166.png) pm and ![](img/B14110_11_167.png)
    pm, which is only and entirely based on the amount of energy saved, is:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在！[](img/B14110_11_166.png) 下午和！[](img/B14110_11_167.png) 下午之间获得的奖励，仅仅完全基于节省的能量，计算结果为：
- en: '![](img/B14110_11_168.png)![](img/B14110_11_169.png)![](img/B14110_11_170.png)![](img/B14110_11_171.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_168.png)![](img/B14110_11_169.png)![](img/B14110_11_170.png)![](img/B14110_11_171.png)'
- en: 'Finally, the total reward obtained between ![](img/B14110_11_172.png) pm and
    ![](img/B14110_11_173.png) pm is:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在！[](img/B14110_11_172.png) 下午和！[](img/B14110_11_173.png) 下午之间获得的总奖励是：
- en: '![](img/B14110_11_174.png)![](img/B14110_11_175.png)![](img/B14110_11_176.png)![](img/B14110_11_177.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_174.png)![](img/B14110_11_175.png)![](img/B14110_11_176.png)![](img/B14110_11_177.png)'
- en: That was an example of the whole process happening for two minutes. In our implementation
    we'll run the same process over 1000 epochs of 5-month periods for the training,
    and then, once our AI is trained, we'll run the same process over 1 full year
    of simulation for the testing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这是整个过程发生两分钟的一个示例。在我们的实现中，我们将对训练进行1000个周期，每个周期为5个月；然后，一旦我们的AI训练完成，我们将在1年的完整模拟中运行相同的过程进行测试。
- en: Now that we've defined and built the environment in detail, it's time for our
    AI to take action! This is where deep Q-learning comes into play. Our model will
    be more advanced than the previous one because I'm introducing some new tricks,
    called **dropout** and **early stopping**, which are great techniques for you
    to have in your toolkit; they usually improve the training performance of deep
    Q-learning.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经详细定义并构建了环境，是时候让我们的AI采取行动了！这就是深度Q学习发挥作用的地方。我们的模型将比之前的模型更先进，因为我将引入一些新的技巧，称为**dropout**（丢弃法）和**early
    stopping**（提前停止），这些都是非常棒的技巧，可以成为你工具包中的一部分；它们通常会提升深度Q学习的训练性能。
- en: Don't forget, you'll also get an AI Blueprint, which will allow you to adapt
    what we do here to any other business problem that you want to solve with deep
    Q-learning.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了，你还会获得一个AI蓝图，它将允许你将我们在这里所做的应用到任何其他业务问题，使用深度Q学习来解决。
- en: Ready? Let's smash this.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好了吗？让我们开始吧。
- en: AI solution
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI解决方案
- en: 'Let''s start by reminding ourselves of the whole deep Q-learning model, while
    adapting it to this case study, so that you don''t have to scroll or turn many
    pages back into the previous chapters. Repetition is never bad; it sticks the
    knowledge into our heads more firmly. Here''s the deep Q-learning algorithm for
    you again:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先回顾一下整个深度Q学习模型，并将其适应到这个案例研究中，这样你就不需要滚动或者翻回前面的章节了。重复永远没有坏处，它能帮助我们将知识牢牢地记在脑海中。这里是你再次看到的深度Q学习算法：
- en: 'Initialization:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化：
- en: The memory of the experience replay is initialized to an empty list, called
    `memory` in the code (the `dqn.py` Python file in the `Chapter 11` folder of the
    GitHub repo).
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经验回放的记忆初始化为空列表，在代码中称为`memory`（位于GitHub仓库的`Chapter 11`文件夹中的`dqn.py` Python文件）。
- en: We choose a maximum size for the memory, called `max_memory` in the code (the
    `dqn.py` Python file in the `Chapter 11` folder of the GitHub repo).
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为记忆选择一个最大大小，在代码中称为`max_memory`（位于GitHub仓库的`Chapter 11`文件夹中的`dqn.py` Python文件）。
- en: 'At each time *t* (each minute), we repeat the following process, until the
    end of the epoch:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间点*t*（每分钟），我们重复以下过程，直到周期结束：
- en: We predict the Q-values of the current state ![](img/B14110_11_178.png). Since
    five actions can be performed (0 == Cooling 3°C, 1 == Cooling 1.5°C, 2 == No Heat
    Transfer, 3 == Heating 1.5°C, 4 == Heating 3°C), we get five predicted Q-values.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预测当前状态的Q值！[](img/B14110_11_178.png)。由于可以执行五种动作（0 == 降温3°C，1 == 降温1.5°C，2 ==
    无热传递，3 == 加热1.5°C，4 == 加热3°C），我们会得到五个预测Q值。
- en: We perform the action selected by the argmax method, which simply consists of
    selecting the action that has the highest of the five predicted Q-values:![](img/B14110_11_179.png)
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们执行通过argmax方法选择的动作，这个方法简单地选择具有五个预测Q值中最高值的动作：![](img/B14110_11_179.png)
- en: We get the reward ![](img/B14110_11_180.png), which is the difference ![](img/B14110_11_181.png).
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获得了奖励！[](img/B14110_11_180.png)，它是差值！[](img/B14110_11_181.png)。
- en: 'We reach the next state ![](img/B14110_07_0452.png), which is composed of the
    three following elements:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们达到了下一个状态！[](img/B14110_07_0452.png)，它由以下三个元素组成：
- en: The temperature of the server at time ![](img/B14110_11_183.png)
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器在时间点！[](img/B14110_11_183.png)时的温度
- en: The number of users in the server at time ![](img/B14110_11_094.png)
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器中用户的数量在时间点！[](img/B14110_11_094.png)
- en: The rate of data transmission in the server at time ![](img/B14110_11_185.png)
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器在时间![](img/B14110_11_185.png)的数据显示传输速率
- en: We append the transition ![](img/B14110_11_186.png) in the memory.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将过渡过程![](img/B14110_11_186.png)附加到内存中。
- en: 'We take a random batch ![](img/B14110_11_187.png) of transitions. For all the
    transitions ![](img/B14110_11_188.png) of the random batch ![](img/B14110_11_189.png):'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随机选择一批过渡！[](img/B14110_11_187.png)。对于随机批次中的所有过渡！[](img/B14110_11_188.png)：![](img/B14110_11_189.png)
- en: 'We get the predictions: ![](img/B14110_11_190.png)'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们获得预测值：![](img/B14110_11_190.png)
- en: 'We get the targets: ![](img/B14110_11_191.png)'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们获得目标：![](img/B14110_11_191.png)
- en: We compute the loss between the predictions and the targets over the whole batch
    ![](img/B14110_11_192.png):![](img/B14110_11_193.png)
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们计算预测值和目标值之间的损失，涵盖整个批次！[](img/B14110_11_192.png):![](img/B14110_11_193.png)
- en: And then finally we backpropagate this loss error back into the neural network,
    and through stochastic gradient descent we update the weights according to how
    much they contributed to the loss error.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们最终通过反向传播将这个损失误差传递回神经网络，并通过随机梯度下降，根据它们对损失误差的贡献程度更新权重。
- en: I hope the refresher was refreshing! Let's move on to the brain of the outfit.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 希望复习一下让你耳目一新！让我们继续谈谈这个系统的大脑。
- en: The brain
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大脑
- en: By the brain, I mean of course the artificial neural network of our AI.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 所谓大脑，当然是指我们的AI的人工神经网络。
- en: Our brain will be a fully connected neural network, composed of two hidden layers,
    the first one with 64 neurons, and the second one with 32 neurons. As a reminder,
    this neural network takes as inputs the states of the environment, and returns
    as outputs the Q-values for each of the five possible actions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大脑将是一个全连接神经网络，包含两层隐藏层，第一层有64个神经元，第二层有32个神经元。提醒一下，这个神经网络的输入是环境的状态，输出是每个可能动作的Q值。
- en: This particular design of a neural network, with two hidden layers of 64 and
    32 neurons respectively, is considered something of a **classic** architecture.
    It's suitable to solve a lot of problems, and it will work well for us here.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这种神经网络设计，分别有64和32个神经元的两层隐藏层，通常被认为是**经典**架构。它适用于解决许多问题，并且在这里会很好地工作。
- en: This artificial brain will be trained with a **Mean Squared Error** (**MSE**)
    loss, and an `Adam` optimizer. The choice for the MSE loss is because we want
    to measure and reduce the squared difference between the predicted value and the
    target value, and the `Adam` optimizer is a classic optimizer used, in practice,
    by default.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个人工大脑将使用**均方误差**（**MSE**）损失和`Adam`优化器进行训练。选择MSE损失是因为我们想要衡量并减少预测值和目标值之间的平方差，而`Adam`优化器是实践中默认使用的经典优化器。
- en: 'Here is what this artificial brain looks like:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个人工大脑的样子：
- en: '![](img/B14110_11_02.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_02.png)'
- en: 'Figure 2: The artificial brain of our AI'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：我们AI的人工大脑
- en: 'This artificial brain looks complex to create, but we can build it very easily
    thanks to the amazing Keras library. In the last chapter, we used PyTorch because
    it''s the neural network library I''m more familiar with; but I want you to be
    able to use as many AI tools as possible, so in this chapter we''re going to power
    on with Keras. Here''s a preview of the full implementation containing the part
    that builds this brain all by itself (taken from the `brain_nodropout.py` file):'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这个人工大脑看起来很复杂，但得益于强大的Keras库，我们可以非常轻松地构建它。在上一章中，我们使用了PyTorch，因为它是我更熟悉的神经网络库；但我希望你能尽可能多地使用AI工具，所以在这一章中，我们将使用Keras。以下是完整实现的预览，其中包含构建这个大脑的部分（来自`brain_nodropout.py`文件）：
- en: '[PRE0]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, it only takes a couple of lines of code, and I'll explain every
    line of that code to you in a later section. Now let's move on to the implementation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这仅仅需要几行代码，我会在后续章节中逐行解释这段代码。现在让我们继续实现部分。
- en: Implementation
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: This implementation will be divided into five parts, each part having its own
    Python file. You can find the full implementation in the `Chapter 11` folder of
    the GitHub repository. These five parts constitute the general AI framework, or
    AI Blueprint, that should be followed whenever you build an environment to solve
    any business problem with deep reinforcement learning.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 该实现将分为五个部分，每个部分都有其独立的Python文件。你可以在GitHub仓库的`Chapter 11`文件夹中找到完整的实现。这五个部分构成了通用的AI框架，或者称为AI蓝图，应该在每次建立环境来解决深度强化学习的业务问题时遵循。
- en: 'Here they are, from Step 1 to Step 5:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 从步骤1到步骤5，它们是这样的：
- en: '**Step 1**: Building the environment (`environment.py`)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1**：构建环境（`environment.py`）'
- en: '**Step 2**: Building the brain (`brain_nodropout.py` or `brain_dropout.py`)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2**：构建大脑（`brain_nodropout.py` 或 `brain_dropout.py`）'
- en: '**Step 3**: Implementing the deep reinforcement learning algorithm, which in our
    case is a deep Q-learning model (`dqn.py`)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 3**：实现深度强化学习算法，在我们的案例中是深度Q学习模型（`dqn.py`）'
- en: '**Step 4**: Training the AI (`training_noearlystopping.py` or `training_earlystopping.py`)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4**：训练AI（`training_noearlystopping.py` 或 `training_earlystopping.py`）'
- en: '**Step 5**: Testing the AI (`testing.py`)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 5**：测试AI（`testing.py`）'
- en: In order, those are the main steps of the general AI framework.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 按顺序，这些是通用AI框架的主要步骤。
- en: We'll follow this AI Blueprint to implement the AI for our specific case in
    the following five sections, each corresponding to one of these five main steps.
    Within each step, we'll distinguish the sub-steps that are still part of the general
    AI framework from the sub-steps that are specific to our project by writing the
    titles of the code sections in capital letters for all the sub-steps of the general
    AI framework, and in lowercase letters for all the sub-steps specific to our project.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遵循这个AI蓝图，在接下来的五个部分中为我们的特定案例实现AI，每个部分对应以下五个主要步骤。在每个步骤中，我们将通过将通用AI框架的所有子步骤的代码部分标题写成大写字母，来区分那些仍然属于通用AI框架的子步骤与那些特定于我们项目的子步骤，将后者的标题写成小写字母。
- en: That means that anytime you see a new code section where the title is written
    in capital letters, then it is the next sub-step of the general AI framework,
    which you should also follow when building an AI for your own business problem.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，每当你看到一个新的代码部分，其中标题是大写字母时，它就是通用AI框架的下一个子步骤，在为你自己业务问题构建AI时，你也应该遵循这一点。
- en: This next step, building the environment, is the largest Python implementation
    file for this project. Make sure you're rested and your batteries are recharged,
    and as soon as you are ready, let's tackle this together!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，构建环境，是这个项目中最大的Python实现文件。确保你已经休息好了，电量充足，一旦准备好，让我们一起解决这个问题！
- en: Step 1 – Building the environment
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 1 – 构建环境
- en: In this first step, we are going to build the environment inside a class. Why
    a class? Because we would like our environment to be an object which we can easily
    create with any values we choose for some parameters.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，我们将把环境构建成一个类。为什么选择类？因为我们希望环境成为一个对象，可以轻松地通过选择一些参数的值来创建。
- en: For example, we can create one environment object for a server that has a certain
    number of connected users and a certain rate of data at a specific time, and another
    environment object for a different server that has a different number of connected
    users and a different rate of data. Thanks to the advanced structure of this class,
    we can easily plug-and-play the environment objects we create on different servers
    which have their own parameters, regulating their temperatures with several different
    AIs, so that we can minimize the energy consumption of a whole data center, just
    as Google DeepMind did for Google's data centers with its DQN (deep Q-learning)
    algorithm.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以为一台服务器创建一个环境对象，这台服务器在特定时间有一定数量的连接用户和一定的数据传输速率；同时为另一台服务器创建一个环境对象，这台服务器有不同数量的连接用户和不同的数据传输速率。得益于该类的先进结构，我们可以轻松地将我们在不同服务器上创建的环境对象进行即插即用，这些服务器有各自的参数，通过多个不同的AI来调节它们的温度，从而最小化整个数据中心的能耗，就像Google
    DeepMind使用其DQN（深度Q学习）算法为Google的数据中心做的那样。
- en: 'This class follows the following sub-steps, which are part of the general AI
    Framework inside Step 1 – Building the environment:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 该类遵循以下子步骤，这些步骤属于步骤 1 – 构建环境中的通用AI框架：
- en: '**Step 1-1**: Introducing and initializing all the parameters and variables
    of the environment.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-1**：介绍并初始化环境的所有参数和变量。'
- en: '**Step 1-2**: Making a method that updates the environment right after the
    AI plays an action.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-2**：创建一个方法，在AI执行一个动作后更新环境。'
- en: '**Step 1-3**: Making a method that resets the environment.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-3**：创建一个重置环境的方法。'
- en: '**Step 1-4**: Making a method that gives us at any time the current state,
    the last reward obtained, and whether the game is over.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-4**：创建一个方法，随时向我们提供当前状态、最后获得的奖励以及游戏是否结束。'
- en: 'You''ll find the whole implementation of this `Environment` class in this section.
    Remember the most important thing: all the code sections with their titles written
    in capital letters are steps of the general AI framework/Blueprint, and all the
    code sections having their titles written in lowercase letters are specific to
    our case study.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本节中找到整个`Environment`类的实现。记住最重要的事情：所有标题为大写字母的代码部分都是通用AI框架/蓝图的步骤，而所有标题为小写字母的代码部分则是我们案例研究的具体实现。
- en: 'The implementation of the environment has 144 lines of code. I won''t explain
    each line of code for two reasons:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 环境实现代码共有144行。我不会逐行解释代码，原因有两个：
- en: It would make this chapter really overwhelming.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这会让本章内容显得非常繁重。
- en: The code is very simple, is commented on for clarity, and just creates everything
    we've defined so far in this chapter.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码非常简单，并且已经进行了注释以提高清晰度，基本上是创建了我们在本章迄今为止定义的所有内容。
- en: I'm confident you'll have no problems understanding it. Besides, the code section
    titles and the chosen variable names are clear enough to understand the structure
    and the flow of the code at face value. I'll walk you through the code broadly.
    Here we go!
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你理解起来不会有问题。除此之外，代码段的标题和所选的变量名称已经足够清晰，能够让你从表面上就理解代码的结构和流程。我将简要介绍一下代码，开始吧！
- en: 'First, we start building the `Environment` class with its first method, the
    `__init__` method, which introduces and initializes all the parameters and variables,
    as we described earlier:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们开始构建`Environment`类，并定义它的第一个方法，即`__init__`方法，该方法会引入并初始化我们之前提到的所有参数和变量：
- en: '[PRE1]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You''ll notice the `self.monthly_atmospheric_temperatures` variable; that''s
    a list containing the average monthly atmospheric temperatures for each of the
    12 months: 1°C in January, 5°C in February, 7°C in March, and so on.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到`self.monthly_atmospheric_temperatures`变量，它是一个列表，包含了12个月份的平均大气温度：1月为1°C，2月为5°C，3月为7°C，依此类推。
- en: The `self.atmospheric_temperature` variable is the current average atmospheric
    temperature of the month we're in during the simulation, and it's initialized
    as the atmospheric temperature of the initial month, which we'll set later as
    January.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.atmospheric_temperature`变量表示当前模拟月份的平均大气温度，它被初始化为初始月份的气温，我们稍后会将其设置为1月。'
- en: The `self.game_over` variable tells the AI whether or not we should reset the
    temperature of the server, in case it goes outside the allowed range of [-20°C,
    80°C]. If it does, `self.game_over` will be set equal to 1, otherwise it will
    remain at 0.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.game_over`变量告诉AI是否需要重置服务器温度，防止其超过允许的范围[-20°C, 80°C]。如果超过范围，`self.game_over`将被设置为1，否则保持为0。'
- en: Finally, the `self.train` variable tells us whether we're in training mode or
    inference mode. If we're in training mode, `self.train = 1`. If we're in inference
    mode, `self.train = 0`. The rest is just putting into code everything we defined
    in words at the beginning of this chapter.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`self.train`变量告诉我们当前是处于训练模式还是推理模式。如果是训练模式，`self.train = 1`；如果是推理模式，`self.train
    = 0`。剩下的代码就是将本章开头所定义的所有内容实现成代码。
- en: Let's move on!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续！
- en: 'Now, we make the second method, `update_env`, which updates the environment
    after the AI performs an action. This method takes three arguments as inputs:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来定义第二个方法`update_env`，它在AI执行某个操作后更新环境。这个方法有三个输入参数：
- en: '`direction`: A variable describing the direction of the heat transfer the AI
    imposes on the server, like so: if `direction == 1`, the AI is heating up the
    server. If `direction == -1`, the AI is cooling down the server. We''ll need to
    have the value of this direction before calling the `update_env` method, since
    this method is called after the action is performed.'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`direction`：描述AI对服务器施加的热量传输方向的变量，像这样：如果`direction == 1`，则表示AI在加热服务器；如果`direction
    == -1`，则表示AI在冷却服务器。我们需要在调用`update_env`方法之前获取这个方向的值，因为该方法是在操作执行后调用的。'
- en: '`energy_ai`: The energy spent by the AI to heat up or cool down the server
    at this specific time when the action is played. Based on assumption 2, it will
    be equal to the temperature change caused by the AI in the server.'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`energy_ai`：AI在执行动作时，所消耗的能量，用来加热或冷却服务器。根据假设2，它等于AI在服务器中引起的温度变化。'
- en: '`month`: Simply the month we''re in at the specific time when the action is
    played.'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`month`：表示在执行动作时我们所在的月份。'
- en: 'The first actions the program takes inside this method are to compute the reward.
    Indeed, right after the action is played, we can immediately deduce the reward,
    since it is the difference between the energy that the server''s integrated system
    would spend if there was no AI, and the energy spent by the AI:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 程序在此方法内执行的第一步是计算奖励。实际上，在执行动作后，我们可以立即推断出奖励，因为它是服务器集成系统在没有 AI 的情况下消耗的能量与 AI 实际消耗的能量之间的差异：
- en: '[PRE2]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You have probably noticed that we choose to scale the reward at the end. In
    short, scaling is bringing the values (here the rewards) down into a short range.
    For example, normalization is a scaling technique where all the values are brought
    down into a range between 0 and 1\. Another widely used scaling technique is standardization,
    which will be explained a bit later on.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们选择在最后对奖励进行缩放。简而言之，缩放是将数值（这里是奖励）缩小到一个较小的范围。例如，归一化是一种缩放技术，其中所有值都缩小到0和1之间的范围。另一种广泛使用的缩放技术是标准化，这将在稍后解释。
- en: Scaling is a common practice that is usually recommended in research papers
    when performing deep reinforcement learning, as it stabilizes training and improves
    the performance of the AI.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放是深度强化学习研究论文中通常推荐的一种常见做法，因为它可以稳定训练并提高 AI 性能。
- en: 'After getting the reward, we reach the next state. Remember that each state
    is composed of the following elements:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得奖励后，我们进入下一个状态。记住，每个状态由以下元素组成：
- en: The temperature of the server at time ![](img/B14110_11_083.png)
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器在时间点的温度 ![](img/B14110_11_083.png)
- en: The number of users in the server at time ![](img/B14110_11_083.png)
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器在时间点的用户数量 ![](img/B14110_11_083.png)
- en: The rate of data transmission in the server at time ![](img/B14110_11_062.png)
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器在时间点的数据传输速率 ![](img/B14110_11_062.png)
- en: 'So, as we reach the next state, we update each of these elements one by one,
    following the sub-steps highlighted as comments in this next code section:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，当我们进入下一个状态时，我们逐个更新这些元素，遵循下一段代码中的注释部分所强调的子步骤：
- en: '[PRE3]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we update the `self.game_over` variable if needed, that is, if the temperature
    of the server goes outside the allowed range of [-20°C, 80°C]. This can happen
    if the server temperature goes below the minimum temperature of -20°C, or if the
    server temperature goes higher than the maximum temperature of 80°C. Plus we do
    two extra things: we bring the server temperature back into the optimal temperature
    range (closest bound), and since doing this spends some energy, we update the
    total energy spent by the AI (`self.total_energy_ai`). That''s exactly what is
    coded in the next code section:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果需要，我们更新 `self.game_over` 变量，也就是说，如果服务器的温度超出允许的范围 [-20°C, 80°C]，则会发生这种情况。如果服务器温度低于最低温度
    -20°C，或者高于最高温度 80°C，就会出现这种情况。此外，我们还做了两件事：将服务器温度恢复到最佳温度范围内（最接近的边界），并且由于此操作会消耗一些能量，我们更新了
    AI 消耗的总能量（`self.total_energy_ai`）。这正是下一段代码所实现的内容：
- en: '[PRE4]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, I know it seems unrealistic for the server to snap right back to 24 degrees
    from 80, or to 18 from -20, but this is an action the magically efficient integrated
    cooling system we defined earlier is perfectly capable of. Think of it as the
    AI switching to the integrated system for a moment in the case of a temperature
    disaster. Once again, this is an area that will benefit enormously from your ongoing
    tinkering once we've got the AI up and running; after that, you can play around
    with these figures as you like in the interests of a more realistic server model.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我知道对于服务器来说，温度从80度迅速降回24度，或者从-20度升到18度似乎不太现实，但这是我们之前定义的高效集成冷却系统完全能够做到的动作。可以将其理解为在温度灾难情况下，AI
    会短暂切换到集成系统。再次强调，这个领域将从你在 AI 正常运行后继续调试中受益巨大；之后，你可以随意调整这些数值，以便实现更真实的服务器模型。
- en: 'Then, we update the two scores coming from the two separate simulations, which are:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们更新来自两个独立仿真模型的两个分数，它们是：
- en: '`self.total_energy_ai`: The total energy spent by the AI'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`self.total_energy_ai`：AI 消耗的总能量'
- en: '`self.total_energy_noai`: The total energy spent by the server''s integrated
    cooling system when there is no AI.'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`self.total_energy_noai`：当没有 AI 时，服务器集成冷却系统消耗的总能量。'
- en: '[PRE5]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then to improve the performance, we scale the next state by scaling each of
    its three elements (server temperature, number of users, and data transmission
    rate). To do so, we perform a simple standardization scaling technique, which
    simply consists of subtracting the minimum value of the variable, and then dividing
    by the maximum delta of the variable:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了提高性能，我们通过对下一个状态的三个元素（服务器温度、用户数量和数据传输率）进行缩放来进行标准化处理。具体做法是通过简单的标准化缩放技术，即先减去变量的最小值，再除以变量的最大变化量：
- en: '[PRE6]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we end this `update_env` method by returning the next state, the reward
    received, and whether the game is over or not:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过返回下一个状态、收到的奖励以及游戏是否结束，来结束这个`update_env`方法：
- en: '[PRE7]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Great! We''re done with this long, but important, method that updates the environment
    at each time step (each minute). Now there are two final and very easy methods
    to go: one that resets the environment, and one that gives us three pieces of information
    at any time: the current state, the last reward received, and whether or not the
    game is over.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！我们完成了这个冗长但重要的方法，它会在每个时间步（每分钟）更新环境。现在只剩下两个最终且非常简单的方法：一个是重置环境，另一个是随时提供三项信息：当前状态、上次收到的奖励以及游戏是否结束。
- en: 'Here''s the `reset` method, which resets the environment when a new training
    episode starts, by resetting all the variables of the environment to their originally
    initialized values:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`reset`方法，它会在新的训练回合开始时重置环境，将环境的所有变量恢复到最初初始化的值：
- en: '[PRE8]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, here''s the `observe` method, which lets us know at any given time
    the current state, the last reward received, and whether the game is over:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是`observe`方法，它让我们随时知道当前状态、上次收到的奖励以及游戏是否结束：
- en: '[PRE9]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Awesome! We're done with the first step of the implementation, building the
    environment. Now let's move on to the next step and start building the brain.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们完成了实现的第一步——构建环境。现在让我们继续下一步，开始构建大脑。
- en: Step 2 – Building the brain
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 2 步——构建大脑
- en: 'In this step, we''re going to build the artificial brain of our AI, which is
    nothing other than a fully connected neural network. Here it is again:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们将构建我们 AI 的人工大脑，它就是一个完全连接的神经网络。再看一遍：
- en: '![](img/B14110_11_03.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_03.png)'
- en: 'Figure 3: The artificial brain of our AI'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：我们 AI 的人工大脑
- en: We'll build this artificial brain inside a class for the same reason as before,
    which is to allow us to create several artificial brains, for different servers
    inside a data center. Maybe some servers will need different artificial brains
    with different hyper-parameters than other servers. That's why, thanks to this
    class/object advanced Python structure, we can easily switch from one brain to
    another, to regulate the temperature of a new server that requires an AI with
    different neural network parameters. That's the beauty of **Object-Oriented Programming**
    (**OOP**).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个人工大脑构建在一个类里，原因和之前一样，就是为了让我们能够为数据中心内的不同服务器创建多个人工大脑。也许有些服务器需要不同的人工大脑，并且具有不同的超参数。这就是为什么，通过这个类/对象的高级
    Python 结构，我们可以轻松地从一个大脑切换到另一个大脑，以调节需要不同神经网络参数的新服务器的温度。这就是**面向对象编程**（**OOP**）的魅力所在。
- en: We're building this artificial brain with the amazing Keras library. From this
    library, we use the `Dense()` class to create our two fully connected hidden layers,
    the first one from 64 hidden neurons, and the second one from 32 neurons. Remember,
    this is a classic neural network architecture often used by default, as common
    practice, and seen in many research papers. At the end, we use the `Dense()` class
    again to return the Q-values, which are the outputs of the artificial neural network.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用强大的 Keras 库来构建这个人工大脑。在这个库中，我们使用`Dense()`类来创建两个完全连接的隐藏层，第一个隐藏层有 64 个神经元，第二个隐藏层有
    32 个神经元。记住，这是一个经典的神经网络架构，通常作为默认结构使用，也是许多研究论文中看到的常见做法。最后，我们再次使用`Dense()`类返回 Q 值，这些是人工神经网络的输出。
- en: Later on, when we code the training and testing files, we'll use the argmax
    method to select the action that has the maximum Q-value. Then, we assemble all
    the components of the brain, including the inputs and outputs, by creating it
    as an object of the `Model()` class (which is very useful in that we can save
    and load a model with specific weights). Finally, we'll compile it with a mean
    squared error loss and an Adam optimizer. I'll explain all this in more detail
    later.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 以后，当我们编写训练和测试文件时，我们将使用argmax方法选择具有最大Q值的动作。然后，通过创建一个`Model()`类对象来组装大脑的所有组件，包括输入和输出（这非常有用，因为我们可以保存和加载具有特定权重的模型）。最后，我们将其与均方误差损失和Adam优化器一起编译。稍后我会详细解释这一切。
- en: 'Here are the new steps of the general AI framework:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通用AI框架的新步骤：
- en: '**Step 2-1**: Build the input layer, composed of the input states.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤2-1**：构建输入层，由输入状态组成。'
- en: '**Step 2-2**: Build a defined number of hidden layers with a defined number
    of neurons inside each layer, fully connected to the input layer and between each
    other.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤2-2**：构建一定数量的隐藏层，每个隐藏层包含一定数量的神经元，并与输入层以及彼此之间全连接。'
- en: '**Step 2-3**: Build the output layer, fully connected to the last hidden layer.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤2-3**：构建输出层，完全连接到最后一个隐藏层。'
- en: '**Step 2-4**: Assemble the full architecture inside a model object.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤2-4**：将完整架构组装到一个模型对象中。'
- en: '**Step 2-5**: Compile the model with a mean squared error loss function and
    a chosen optimizer.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤2-5**：使用均方误差损失函数和所选优化器编译模型。'
- en: 'The implementation of this is presented to you in a choice of two different
    files:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 该实现以两种不同文件的形式提供给你：
- en: '`brain_nodropout.py`: An implementation file that builds the artificial brain
    without the dropout regularization technique (I''ll explain what it is very soon).'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`brain_nodropout.py`：一个实现文件，使用没有dropout正则化技术的人工神经网络（我很快会解释它是什么）。'
- en: '`brain_dropout.py`: An implementation file that builds the artificial brain
    with the dropout regularization technique.'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`brain_dropout.py`：一个实现文件，使用dropout正则化技术构建人工神经网络。'
- en: First let me give you the implementation without dropout, and then I'll provide
    one with dropout and explain it.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，给你提供没有dropout的实现，然后再提供带有dropout的实现并解释它。
- en: Without dropout
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 没有dropout
- en: 'Here is the full implementation of the artificial brain, without any dropout
    regularization technique:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这是没有任何dropout正则化技术的人工神经网络完整实现：
- en: '[PRE10]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, let's go through the code in detail.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细查看代码。
- en: '**Line 5**: We import the `Input` and `Dense` classes from the `layers` module
    in the `keras` library. The `Input` class allows us to build the input layer,
    and the `Dense` class allows us to build the fully-connected layers.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**第5行**：我们从`keras`库的`layers`模块中导入`Input`和`Dense`类。`Input`类允许我们构建输入层，而`Dense`类允许我们构建全连接层。'
- en: '**Line 6**: We import the `Model` class from the `models` module in the `keras`
    library. It allows us to build the whole neural network model by assembling its
    different layers.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**第6行**：我们从`keras`库的`models`模块中导入`Model`类。它允许我们通过组装不同的层来构建整个神经网络模型。'
- en: '**Line 7**: We import the `Adam` class from the `optimizers` module in the
    `keras` library. It allows us to use the Adam optimizer, used to update the weights
    of the neural network through stochastic gradient descent, when backpropagating
    the loss error in each iteration of the training.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '**第7行**：我们从`keras`库的`optimizers`模块中导入`Adam`类。它允许我们使用Adam优化器，通过随机梯度下降更新神经网络的权重，在每次训练迭代中反向传播损失误差。'
- en: '**Line 11**: We introduce the `Brain` class, which will contain not only the
    whole architecture of the artificial neural network, but also the connection of
    the model to the loss (Mean-Squared Error) and the Adam optimizer.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '**第11行**：我们引入了`Brain`类，它不仅包含人工神经网络的整个架构，还包含模型与损失（均方误差）以及Adam优化器的连接。'
- en: '**Line 15**: We introduce the `__init__` method, which will be the only method
    of this class. We define the whole architecture of the neural network inside it,
    just by creating successive variables which together assemble the neural network.
    This method takes as inputs two arguments:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '**第15行**：我们引入了`__init__`方法，这将是该类的唯一方法。我们在其中定义了神经网络的整个架构，通过创建连续的变量，这些变量共同组装成神经网络。此方法接受两个参数作为输入：'
- en: The learning rate (`learning_rate`), which is a measure of how fast you want
    the neural network to learn (the higher the learning rate, the faster the neural
    network learns; but at the cost of quality). The default value is `0.001`.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 学习率（`learning_rate`），这是一个衡量你希望神经网络学习速度的指标（学习率越高，神经网络学习越快；但代价是质量下降）。默认值为`0.001`。
- en: 'The number of actions (`number_actions`), which is of course the number of
    actions that our AI can perform. Now you might be thinking: why do we need to
    put that as an argument? Well that''s just in case you want to build another AI
    that can perform more or fewer actions. In which case you would simply need to
    change the value of the argument and that''s it. Pretty practical, isn''t it?'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`number_actions`（动作数量），当然是指我们的 AI 能执行的动作数。现在你可能在想：为什么我们需要将这个作为参数呢？这只是为了防止你想要构建一个可以执行更多或更少动作的
    AI。在这种情况下，你只需要更改参数的值，其他就不需要改动了。相当实用，不是吗？'
- en: '**Line 16**: We create an object variable for the learning rate, `self.learning_rate`,
    initialized as the value of the `learning_rate` argument provided in the `__init__`
    method (therefore the argument of the `Brain` class when we create the object
    in the future).'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**第16行**：我们为学习率创建一个对象变量，`self.learning_rate`，并初始化为`__init__`方法中提供的`learning_rate`参数的值（因此当我们将来创建`Brain`类的对象时，该参数就会被使用）。'
- en: '**Line 19**: We create the input states layer, called `states`, as an object
    of the `Input` class. Into this `Input` class we enter one argument, `shape =
    (3,)`, which simply tells that the input layer is a 1D vector composed of three
    elements (the server temperature, the number of users, and the data transmission
    rate).'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '**第19行**：我们创建输入状态层，命名为`states`，作为`Input`类的一个对象。我们向这个`Input`类传入一个参数，`shape =
    (3,)`，这只是说明输入层是一个由三个元素组成的1D向量（服务器温度、用户数量和数据传输速率）。'
- en: '**Line 22**: We create the first fully-connected hidden layer, called `x`,
    as an object of the `Dense` class, which takes as input two arguments:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**第22行**：我们创建第一个完全连接的隐藏层，命名为`x`，作为`Dense`类的一个对象，它接受两个参数作为输入：'
- en: '`units`: The number of hidden neurons we want to have in this first hidden
    layer. Here, we choose to have 64 hidden neurons.'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`units`：我们希望在第一个隐藏层中拥有的隐藏神经元数量。在这里，我们选择了64个隐藏神经元。'
- en: '`activation`: The activation function used to pass on the signal when forward-propagating
    the inputs into this first hidden layer. Here we choose, by default, a sigmoid
    activation function, which is as follows:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`activation`：前向传播输入到第一个隐藏层时使用的激活函数。这里我们默认选择了sigmoid激活函数，其形式如下：'
- en: '![](img/B14110_11_04.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_04.png)'
- en: 'Figure 4: The sigmoid activation function'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：sigmoid激活函数
- en: The ReLU activation function would also have worked well here; I encourage you
    to experiment! Note also how the connection from the input layer to this first
    hidden layer is made by calling the `states` variable right after the `Dense`
    class.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU激活函数在这里也会非常有效；我鼓励你进行实验！还要注意，输入层到第一个隐藏层的连接是通过在`Dense`类之后调用`states`变量来实现的。
- en: '**Line 23**: We create the second fully-connected hidden layer, called `y`,
    as an object of the `Dense` class, which takes as input the same two arguments:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '**第23行**：我们创建第二个完全连接的隐藏层，命名为`y`，作为`Dense`类的一个对象，它接受相同的两个参数作为输入：'
- en: '`units`: The number of hidden neurons we want to have in this second hidden
    layer. This time we choose to have 32 hidden neurons.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`units`：我们希望在第二个隐藏层中拥有的隐藏神经元数量。这次我们选择了32个隐藏神经元。'
- en: '`activation`: The activation function used to pass on the signal when forward-propagating
    the inputs into this first hidden layer. Here, again, we choose a sigmoid activation
    function.'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`activation`：前向传播输入到第一个隐藏层时使用的激活函数。这里，我们再次选择了sigmoid激活函数。'
- en: Note once again how the connection from the first hidden layer to this second
    hidden layer is made by calling the `x` variable right after the `Dense` class.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，第一隐藏层到第二隐藏层的连接是通过在`Dense`类之后调用`x`变量来实现的。
- en: '**Line 26**: We create the output layer, called `q_values`, fully connected
    to the second hidden layer, as an object of the `Dense` class. This time, we input
    `number_actions` units since the output layer contains the actions to play, and
    a `softmax` activation function, as seen in *Chapter 5*, *Your First AI Model
    – Beware the Bandits!*, on the deep Q-learning theory.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '**第26行**：我们创建输出层，命名为`q_values`，并完全连接到第二个隐藏层，作为`Dense`类的一个对象。这次我们输入`number_actions`个单元，因为输出层包含要执行的动作，并且使用`softmax`激活函数，正如在*第5章*，*你的第一个AI模型——警惕“土匪”!*中，关于深度Q学习理论的内容所看到的那样。'
- en: '**Line 29**: Using the `Model` class, we assemble the successive layers of
    the neural network, by just inputting the `states` as the inputs, and the `q_values`
    as the outputs.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 29 行**：使用 `Model` 类，我们将神经网络的各层串联起来，只需将 `states` 作为输入，`q_values` 作为输出。'
- en: '**Line 32**: Using the `compile` method taken from the `Model` class, we connect
    our model to the Mean-Squared Error loss and the Adam optimizer. The latter takes
    the `learning_rate` argument as input.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 32 行**：使用 `Model` 类中的 `compile` 方法，我们将模型连接到均方误差损失函数和 Adam 优化器。后者接受 `learning_rate`
    参数作为输入。'
- en: With dropout
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 dropout
- en: 'It''ll be valuable for you to add one more powerful technique to your toolkit:
    **dropout**.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 对你来说，添加一个更强大的技术到你的工具箱里会非常有价值：**dropout**。
- en: Dropout is a regularization technique that prevents overfitting, which is the
    situation where the AI model performs well on the training set, but poorly on
    the test set. Dropout simply consists of deactivating a randomly selected portion
    of neurons during each step of forward- and back-propagation. That means not all
    the neurons learn the same way, which prevents the neural network from overfitting
    the training data.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 是一种正则化技术，用于防止过拟合，过拟合是指人工智能模型在训练集上表现良好，但在测试集上表现较差的情况。Dropout 通过在每次前向传播和反向传播步骤中禁用随机选择的一部分神经元来实现。这意味着并不是所有的神经元都以相同的方式学习，从而防止了神经网络对训练数据的过拟合。
- en: 'Adding dropout is very easy with `keras`. You simply need to call the `Dropout`
    class right after the `Dense` class, and input the proportion of neurons you want
    to deactivate, like so:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `keras` 添加 dropout 非常简单。你只需要在 `Dense` 类后面调用 `Dropout` 类，并输入你希望禁用的神经元比例，如下所示：
- en: '[PRE11]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here, we apply dropout to the first and second fully-connected layers, by deactivating
    10% of their neurons each. Now, let''s move on to the next step of our general
    AI framework: Step 3 – Implementing the deep reinforcement learning algorithm.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对第一层和第二层全连接层应用 dropout，每层禁用 10% 的神经元。接下来，让我们进入我们的一般 AI 框架的下一步：第 3 步 –
    实现深度强化学习算法。
- en: Step 3 – Implementing the deep reinforcement learning algorithm
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 步 – 实现深度强化学习算法
- en: 'In this new implementation (given in the `dqn.py` file), we simply have to
    follow the deep Q-learning algorithm provided before. Hence, this implementation
    follows the following sub-steps, which are part of the general AI framework:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新实现中（见 `dqn.py` 文件），我们只需要遵循之前提供的深度 Q-learning 算法。因此，这个实现遵循以下子步骤，它们是一般 AI
    框架的一部分：
- en: '**Step 3-1**: Introduce and initialize all the parameters and variables of
    the deep Q-learning model.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 3-1 步**：引入并初始化深度 Q-learning 模型的所有参数和变量。'
- en: '**Step 3-2**: Make a method that builds the memory in experience replay.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 3-2 步**：制作一个构建经验回放记忆的方法。'
- en: '**Step 3-3**: Make a method that builds and returns two batches of 10 inputs
    and 10 targets.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 3-3 步**：制作一个构建并返回两批次 10 个输入和 10 个目标的方法。'
- en: 'First, have a look at the whole code, and then I''ll explain it line by line:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，浏览一下整个代码，然后我会逐行解释：
- en: '[PRE12]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Line 5**: We import the `numpy` library, because we''ll be working with `numpy`
    arrays.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 5 行**：我们导入 `numpy` 库，因为我们将使用 `numpy` 数组。'
- en: '**Line 9**: We introduce the `DQN` class (**DQN** stands for **Deep Q-Network**),
    which contains the main parts of the deep Q-Learning algorithm, including experience
    replay.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 9 行**：我们引入 `DQN` 类（**DQN** 代表 **深度 Q 网络**），它包含深度 Q-learning 算法的主要部分，包括经验回放。'
- en: '**Line 12**: We introduce the `__init__` method, which creates the three following
    object variables of the `DQN` model: the experience replay memory, the capacity
    (maximum size of the memory), and the discount factor in the formula of the target.
    It takes as arguments `max_memory` (the capacity) and `discount` (the discount
    factor), in case we want to build other experience replay memories with different
    capacities, or if we want to change the value of the discount factor in the computation
    of the target. The default values of these arguments are respectively `100` and
    `0.9`, which were chosen arbitrarily and turned out to work quite well; these
    are good arguments to experiment with, to see what difference it makes when you
    set them differently.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 12 行**：我们引入 `__init__` 方法，它创建了 `DQN` 模型的以下三个对象变量：经验回放记忆、容量（记忆的最大大小）和目标公式中的折扣因子。它的参数是
    `max_memory`（容量）和 `discount`（折扣因子），如果我们想构建具有不同容量的其他经验回放记忆，或者如果我们想更改折扣因子在目标计算中的值，可以传入这些参数。默认值分别是
    `100` 和 `0.9`，这两个值是任意选择的，结果表明效果相当好；这些是很好的实验参数，可以试试看当它们设置为不同值时会有什么区别。'
- en: '**Line 13**: We create the experience replay memory object variable, `self.memory`,
    and we initialize it as an empty list.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '**第13行**：我们创建经验回放记忆对象变量`self.memory`，并将其初始化为空列表。'
- en: '**Line 14**: We create the object variable for the memory capacity, `self.max_memory`,
    and we initialize it as the value of the `max_memory` argument.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**第14行**：我们创建记忆容量的对象变量`self.max_memory`，并将其初始化为`max_memory`参数的值。'
- en: '**Line 15**: We create the object variable for the discount factor, `self.discount`,
    and we initialize it as the value of the `discount` argument.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '**第15行**：我们创建折扣因子对象变量`self.discount`，并将其初始化为`discount`参数的值。'
- en: '**Line 18**: We introduce the `remember` method, which takes as input a transition
    to be added to the memory, and `game_over`, which states whether or not this transition
    leads the server''s temperature to go outside of the allowed range of temperatures.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '**第18行**：我们引入了`remember`方法，该方法的输入为需要添加到记忆中的过渡，以及`game_over`，它表示该过渡是否导致服务器温度超出允许的温度范围。'
- en: '**Line 19**: Using the `append` function called from the `memory` list, we
    add the transition with the `game_over` boolean into the memory (in the last position).'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '**第19行**：通过从`memory`列表调用`append`函数，我们将带有`game_over`布尔值的过渡添加到记忆中（位于最后位置）。'
- en: '**Line 20**: If, after adding this transition, the size of the memory exceeds
    the memory capacity (`self.max_memory`).'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '**第20行**：如果在添加此过渡后，记忆的大小超过了记忆容量（`self.max_memory`）。'
- en: '**Line 21**: We delete the first element of the memory.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**第21行**：我们删除记忆中的第一个元素。'
- en: '**Line 24**: We introduce the `get_batch` method, which takes as inputs the
    model we built in the previous Python file (`model`) and a batch size (`batch_size`),
    and builds two batches of inputs and targets by extracting `10` transitions from
    the memory (if the batch size is 10).'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '**第24行**：我们引入了`get_batch`方法，该方法的输入为我们在前一个Python文件中构建的模型（`model`）和批处理大小（`batch_size`），并通过从记忆中提取`10`个过渡（如果批处理大小是10），构建两个输入和目标的批次。'
- en: '**Line 25**: We get the current number of elements in the memory and put it
    into a new variable, `len_memory`.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**第25行**：我们获取记忆中当前的元素数量，并将其存入一个新变量`len_memory`。'
- en: '**Line 26**: We get the number of elements in the input state vector (which
    is 3), but instead of directly entering 3, we access this number from the `shape`
    attribute of the input state vector element of the memory, which we get by taking
    the `[0][0][0]` indexes. Each element of the memory is structured as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '**第26行**：我们获取输入状态向量中的元素数量（为3），但不是直接输入3，而是通过访问记忆中输入状态向量元素的`shape`属性来获取这个数字，这个元素通过取`[0][0][0]`索引来获得。记忆中的每个元素结构如下：'
- en: '[[`current_state`, `action`, `reward`, `next_state`], `game_over`]'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[[`current_state`, `action`, `reward`, `next_state`], `game_over`]'
- en: Thus in `[0][0][0]`, the first `[0]` corresponds to the first element of the
    memory (meaning the first transition), the second `[0]` corresponds to the tuple
    [`current_state`, `action`, `reward`, `next_state`], and so the third `[0]` corresponds
    to the `current_state` element of that tuple. Hence, `self.memory[0][0][0]` corresponds
    to the first current state, and by adding `.shape[1]` we get the number of elements
    in that input state vector. You might be wondering why we didn't enter 3 directly;
    that's because we want to generalize this code to any input state vector dimension
    you might want to have in your environment. For example, you might want to consider
    an input state with more information about your server, such as the humidity.
    Thanks to this line of code, you won't have to change anything regarding your
    new number of state elements.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在`[0][0][0]`中，第一个`[0]`对应记忆的第一个元素（即第一个过渡），第二个`[0]`对应元组[`current_state`、`action`、`reward`、`next_state`]，所以第三个`[0]`对应该元组中的`current_state`元素。因此，`self.memory[0][0][0]`对应第一个当前状态，通过添加`.shape[1]`，我们可以得到该输入状态向量中的元素数量。你可能会问，为什么我们没有直接输入3；这是因为我们想将这段代码推广到任何你可能希望在环境中使用的输入状态向量维度。例如，你可能希望考虑一个包含更多关于服务器信息的输入状态，比如湿度。得益于这行代码，你无需更改关于状态元素数量的任何内容。
- en: '**Line 27**: We get the number of elements of the model output, meaning the
    number of actions. Just like on the previous line, instead of entering directly
    5, we generalize by accessing this from the `shape` attribute called from our
    `model` object of the `Model` class. `-1` means that we get the last index of
    that `shape` attribute, where the number of actions is contained.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '**第27行**：我们获取模型输出的元素数量，也就是动作的数量。就像前一行一样，我们并不是直接输入5，而是通过访问`model`对象中的`shape`属性来实现这个目标，`model`是`Model`类的实例。`-1`意味着我们获取`shape`属性的最后一个索引，在这个位置包含了动作的数量。'
- en: '**Line 28**: We introduce and initialize the batch of inputs as a `numpy` array,
    of `batch_size` = 10 rows and 3 columns corresponding to input state elements,
    with only zeros. If the memory doesn''t have 10 transitions yet, the number of
    rows will just be the length of the memory.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '**第28行**：我们引入并初始化输入批次作为一个`numpy`数组，`batch_size` = 10行和3列，分别对应输入状态元素，初始值全为零。如果内存中还没有10个过渡，行数将是内存的长度。'
- en: 'If the memory already has at least 10 transitions, what we get with this line
    of code is the following:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 如果内存中已经有至少10个过渡，这行代码的输出将是：
- en: '![](img/B14110_11_05.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_05.png)'
- en: 'Figure 5: Batch of inputs (1/2)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：输入批次（1/2）
- en: '**Line 29**: We introduce and initialize the batch of targets as a `numpy`
    array of `batch_size` = 10 rows and 5 columns corresponding to the five possible
    actions, with only zeros. Just like before, if the memory doesn''t have 10 transitions
    yet, the number of rows will just be the length of the memory. If the memory already
    has at least 10 transitions, what we get with this line of code is the following:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '**第29行**：我们引入并初始化目标批次作为一个`numpy`数组，`batch_size` = 10行和5列，分别对应五种可能的动作，初始值全为零。和之前一样，如果内存中还没有10个过渡，行数就会是内存的长度。如果内存中已经有至少10个过渡，这行代码的输出将是：'
- en: '![](img/B14110_11_06.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_06.png)'
- en: 'Figure 6: Batch of targets (1/3)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：目标批次（1/3）
- en: '**Line 30**: We do a double iteration inside the same `for` loop. The first
    iterative variable `i` goes from 0 to the batch size (or up to `len_memory` if
    `len_memory` < `batch_size`):'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '**第30行**：我们在同一个`for`循环内进行双重迭代。第一个迭代变量`i`从0遍历到批次大小（或者如果`len_memory` < `batch_size`，则迭代到`len_memory`为止）：'
- en: '`i` = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '`i` = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9'
- en: That way, `i` will iterate each element of the batch. The second iterative variable
    `idx` takes 10 random indexes of the memory, in order to extract 10 random transitions
    from the memory. Inside the `for` loop, we populate the two batches of inputs
    and targets with their right values by iterating through each of their elements.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，`i`将迭代批次中的每个元素。第二个迭代变量`idx`随机选择内存中的10个索引，用于从内存中提取10个随机过渡。在`for`循环内，我们通过迭代每个元素来填充输入和目标的两个批次，并为它们赋予正确的值。
- en: '**Line 31**: We get the transition of the sampled index `idx` from the memory,
    composed of the current state, the action, the reward, and the next state. The
    reason we add `[0]` is because an element of the memory is structured as follows:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**第31行**：我们获取从内存中抽样的索引`idx`对应的过渡，包含当前状态、动作、奖励和下一个状态。我们之所以加上`[0]`，是因为内存中的元素结构如下：'
- en: '[[`current_state`, `action`, `reward`, `next_state`], `game_over`]'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '[[`current_state`, `action`, `reward`, `next_state`], `game_over`]'
- en: We'll get the `game_over` value separately, in the next line of code.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一行代码中单独获取`game_over`值。
- en: '**Line 32**: We get the `game_over` value corresponding to that same index
    `idx` of the memory. As you can see, this time we add `[1]` on the end to get
    the second element of a memory element:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '**第32行**：我们获取对应于内存中相同索引`idx`的`game_over`值。如你所见，这次我们在末尾加上`[1]`来获取内存元素中的第二个元素：'
- en: '[[`current_state`, `action`, `reward`, `next_state`], `game_over`]'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[[`current_state`, `action`, `reward`, `next_state`], `game_over`]'
- en: '**Line 33**: We populate the batch of inputs with all the current states, in
    order to get this at the end of the `for` loop:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '**第33行**：我们用所有当前状态填充输入批次，最终在`for`循环结束时得到：'
- en: '![](img/B14110_11_07.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_07.png)'
- en: 'Figure 7: Batch of inputs (2/2)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：输入批次（2/2）
- en: '**Line 34**: Now we start populating the batch of targets with the right values.
    First, we populate it with all the Q-values ![](img/B14110_11_197.png) that the
    model predicts for the different state-action pairs: (current state, action 0),
    (current state, action 1), (current state, action 2), (current state, action 3),
    and (current state, action 4). Thus we first get this (at the end of the `for`
    loop):'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 34 行**：现在我们开始用正确的值填充目标批次。首先，我们用模型预测的所有 Q 值 ![](img/B14110_11_197.png) 填充它，这些
    Q 值对应不同的状态-动作对：（当前状态，动作 0）、（当前状态，动作 1）、（当前状态，动作 2）、（当前状态，动作 3）和（当前状态，动作 4）。因此，我们首先得到了这个（在
    `for` 循环的末尾）：'
- en: '![](img/B14110_11_08.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_08.png)'
- en: 'Figure 8: Batch of targets (2/3)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：目标批次 (2/3)
- en: 'Remember that for the action that is played, the formula of the target must
    be this one:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对于执行的操作，目标的公式必须是这样的：
- en: '![](img/B14110_11_198.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_198.png)'
- en: 'What we do in the following lines of code is to put this formula into the column
    of each action that was played within the 10 selected transitions. In other words,
    we get this:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在接下来的代码行中所做的事情是将这个公式填入每个在 10 个选定过渡中执行的动作对应的列中。换句话说，我们得到了这个：
- en: '![](img/B14110_11_09.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_09.png)'
- en: 'Figure 9: Batch of targets (3/3)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：目标批次 (3/3)
- en: In that example, **Action 1** was performed in the first transition (**Target
    1**), **Action 3** was performed in the second transition (**Target 2**), **Action
    0** was performed in the third transition (**Target 3**), and so on. Let's populate
    this in the following lines of code.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，**动作 1** 在第一次过渡中执行（**目标 1**），**动作 3** 在第二次过渡中执行（**目标 2**），**动作 0** 在第三次过渡中执行（**目标
    3**），依此类推。让我们在接下来的代码行中填充这个内容。
- en: '**Line 35**: We first start getting the ![](img/B14110_11_199.png) part of
    the formula of the target:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 35 行**：我们首先开始获取目标公式中的 ![](img/B14110_11_199.png) 部分：'
- en: '![](img/B14110_11_200.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_200.png)'
- en: '**Line 36**: We check if `game_over` = 1, meaning that the server has gone
    outside the allowed range of server temperatures. Because if it has, there''s
    actually no next state (because we basically reset the environment by putting
    the server''s temperature back into the optimal range so we start from a new state);
    and therefore we shouldn''t consider ![](img/B14110_11_201.png).'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 36 行**：我们检查 `game_over` 是否为 1，表示服务器已经超出了允许的温度范围。因为如果是这样，实际上就没有下一个状态（因为我们基本上通过将服务器温度恢复到最佳范围来重置环境，所以我们从一个新状态开始）；因此，我们不应该考虑
    ![](img/B14110_11_201.png)。'
- en: '**Line 37**: In that case, we only keep the ![](img/B14110_11_202.png) part
    of the target.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 37 行**：在这种情况下，我们只保留目标中的 ![](img/B14110_11_202.png) 部分。'
- en: '**Line 38**: However, if the game is not over (`game_over` = 0)...'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 38 行**：然而，如果游戏没有结束（`game_over` = 0）...'
- en: '**Line 39**: We keep the whole formula of the target, but of course only for
    the action that was performed, meaning ![](img/B14110_11_203.png) here:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 39 行**：我们保留目标的完整公式，但当然只保留执行的动作部分，也就是说，这里是 ![](img/B14110_11_203.png)：'
- en: '![](img/B14110_11_204.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_204.png)'
- en: 'Hence, we get the following batch of targets, as you saw earlier:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得到了如下的目标批次，正如你之前所看到的：
- en: '![](img/B14110_11_10.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_10.png)'
- en: 'Figure 10: Batch of targets (3/3)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：目标批次 (3/3)
- en: '**Line 40**: At last, we `return` the final batches of `inputs` and `targets`.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 40 行**：最后，我们 `return` 最终的 `inputs` 和 `targets` 批次。'
- en: That was epic—you've successfully created an artificial brain. Now that you've
    done it, we're ready to start the training.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 那真是太棒了——你已经成功创造了一个人工大脑。现在，既然你已经完成了它，我们可以开始训练了。
- en: 'Step 4: Training the AI'
  id: totrans-358
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 4：训练 AI
- en: 'Now that our AI has a fully functional brain, it''s time to train it. That''s
    exactly what we do in this fourth Python implementation. You actually have a choice
    of two files to use for this:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们的 AI 拥有了完全功能的大脑，接下来就是训练它的时候了。这正是我们在第四个 Python 实现中所做的事情。你实际上可以选择两个文件来进行此操作：
- en: '`training_noearlystopping.py`, which trains your AI on a full 1000 epochs of
    5-months period.'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`training_noearlystopping.py`，它在 5 个月的周期内训练你的 AI，共 1000 轮。'
- en: '`training_earlystopping.py`, which trains your AI on 1000 epochs as well, but
    which can stop the training early if the performance no longer improves over the
    iterations. This technique is called **early stopping**.'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`training_earlystopping.py`，它同样训练你的 AI 1000 轮，但如果性能在迭代过程中不再提高，它会提前停止训练。这种技术叫做
    **提前停止**。'
- en: Both these implementations are long, but very simple. We start by setting all
    the parameters, then we build the environment by creating an object of the `Environment()`
    class, then we build the brain of the AI by creating an object of the `Brain()`
    class, then we build the deep Q-learning model by creating an object of the `DQN()`
    class, and finally we launch the training connecting all these objects together
    over 1000 epochs of 5-month periods.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个实现都比较长，但非常简单。我们从设置所有参数开始，然后通过创建`Environment()`类的对象来构建环境，接着通过创建`Brain()`类的对象来构建AI的大脑，然后通过创建`DQN()`类的对象来构建深度Q学习模型，最后将所有这些对象连接起来，进行1000个周期的5个月训练。
- en: You'll notice in the training loop that we also do some exploration when performing
    the actions, performing some random actions from time to time. In our case, this
    will be done 30% of the time, since we use an exploration parameter ![](img/B14110_11_205.png),
    and then we force the AI to perform a random action when we draw a random value
    between 0 and 1 that is below ![](img/B14110_11_205.png). The reason we do some
    exploration is because it improves the deep reinforcement learning process, as
    we discussed in *Chapter 9*, *Going Pro with Artificial Brains – Deep Q-Learning*,
    and the reason we don't use Softmax in this project is just to give you a look
    at how to implement a different exploration method.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练循环中，你会注意到我们在执行动作时也进行了一些探索，偶尔会执行一些随机动作。在我们的案例中，30%的时间我们会这样做，因为我们使用了探索参数 ![](img/B14110_11_205.png)，然后当我们从0到1之间抽取一个随机值，并且这个值低于
    ![](img/B14110_11_205.png) 时，我们就强制AI执行一个随机动作。我们进行一些探索的原因是它能够改进深度强化学习过程，正如我们在*第9章*《走向专业：深度Q学习》中所讨论的那样，而我们在这个项目中不使用Softmax的原因仅仅是为了让你了解如何实现一种不同的探索方法。
- en: Later, you'll be introduced to another little improvement in the `training_noearlystopping.py`
    file, where we use an early stopping technique which stops the training early
    if there's no improvement in the performance.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 后面你会在`training_noearlystopping.py`文件中看到另一个小的改进，我们使用了一种早停技术，如果性能没有改善，训练会提前停止。
- en: 'Let''s highlight the new steps which still belong to our general AI framework/Blueprint:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重点介绍这些新的步骤，它们仍然属于我们的通用AI框架/蓝图：
- en: '**Step 4-1**: Building the environment by creating an object of the `Environment`
    class.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-1**：通过创建`Environment`类的对象来构建环境。'
- en: '**Step 4-2**: Building the artificial brain by creating an object of the `Brain`
    class.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-2**：通过创建`Brain`类的对象来构建人工大脑。'
- en: '**Step 4-3**: Building the `DQN` model by creating an object of the `DQN` class.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-3**：通过创建`DQN`类的对象来构建`DQN`模型。'
- en: '**Step 4-4**: Selecting the training mode.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-4**：选择训练模式。'
- en: '**Step 4-5**: Starting the training with a `for` loop over 100 epochs of 5-month
    periods.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-5**：通过一个`for`循环开始训练，进行100个周期的5个月训练。'
- en: '**Step 4-6**: During each epoch we repeat the whole deep Q-learning process,
    while also doing some exploration 30% of the time.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-6**：在每个epoch中，我们重复整个深度Q学习过程，同时30%的时间也进行一些探索。'
- en: No early stopping
  id: totrans-372
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 没有早停
- en: 'Ready to implement this? Maybe get a good coffee or tea first because this
    is going to be a bit long (88 lines of code, but easy ones!). We''ll start without
    early stopping and then at the end I''ll explain how to add the early stopping
    technique. The file to follow along with is `training_noearlystopping.py`. Since
    this is pretty long, let''s do it section by section this time, starting with
    the first one:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好实现这个了吗？或许先喝杯好咖啡或茶吧，因为这个过程会有点长（88行代码，但都是简单的！）。我们会先从不使用早停开始，然后在最后我会解释如何添加早停技术。接下来的文件是`training_noearlystopping.py`。由于这个过程比较长，这次我们按部分来进行，从第一部分开始：
- en: '[PRE13]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Line 5**: We import the `os` library, which will be used to set a seed for
    reproducibility so that if you run the training several times, you''ll get the
    same result each time. You can, of course, choose to remove this when you tinker
    with the code yourself!'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 5 行**：我们导入`os`库，它将用于设置随机种子，以确保结果的可重复性，这样即使你多次运行训练，每次都会得到相同的结果。当然，你也可以在自己修改代码时选择去除它！'
- en: '**Line 6**: We import the `numpy` library, since we''ll work with `numpy` arrays.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 6 行**：我们导入`numpy`库，因为我们将处理`numpy`数组。'
- en: '**Line 7**: We import the `random` library, which we''ll use to do some exploration.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 7 行**：我们导入`random`库，它将用于进行一些探索。'
- en: '**Line 8**: We import the `environment.py` file, implemented in Step 1, which
    contains the whole defined environment.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8 行**：我们导入`environment.py`文件，它在步骤1中实现，包含了整个定义的环境。'
- en: '**Line 9**: We import the `brain_nodropout.py` file, our artificial brain without
    dropout that we implemented in Step 2\. This contains the whole neural network
    of our AI.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '**第9行**：我们导入了`brain_nodropout.py`文件，这是我们在第2步实现的无dropout人工大脑。它包含了我们AI的整个神经网络。'
- en: '**Line 10**: We import the `dqn.py` file implemented in Step 3, which contains
    the main parts of the deep Q-learning algorithm, including experience replay.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '**第10行**：我们导入了第3步实现的`dqn.py`文件，它包含了深度Q学习算法的主要部分，包括经验回放。'
- en: 'Moving on to the next section:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来进入下一部分：
- en: '[PRE14]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Lines 13, 14, and 15**: We set seeds for reproducibility, to get the same
    results after several rounds of training. This is really only important so you
    can reproduce your findings—if you don''t need to do that, some people prefer
    them and others don''t. If you don''t want the seeds you can just remove them.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '**第13、14、15行**：我们设置了种子以确保可重复性，这样可以在多轮训练后获得相同的结果。这实际上只是为了让你能重现你的实验结果——如果你不需要这样做，部分人可能偏好使用种子，其他人则不使用。如果你不想使用种子，可以直接移除它们。'
- en: '**Line 18**: We introduce the exploration factor ![](img/B14110_11_207.png),
    and we set it to `0.3`, meaning that there will be 30% of exploration (performing
    random actions) vs. 70% of exploitation (performing the actions of the AI).'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '**第18行**：我们引入了探索因子 ![](img/B14110_11_207.png)，并将其设置为`0.3`，这意味着有30%的探索（执行随机动作）与70%的利用（执行AI的动作）。'
- en: '**Line 19**: We set the number of actions to `5`.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '**第19行**：我们将动作数量设置为`5`。'
- en: '**Line 20**: We set the direction boundary, meaning the action index below
    which we cool down the server, and above which we heat up the server. Since actions
    0 and 1 cool down the server, and actions 3 and 4 heat up the server, that direction
    boundary is (5-1)/2 = 2, which corresponds to the action that transfers no heat
    to the server (action 2).'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '**第20行**：我们设置了方向边界，意思是设置一个动作索引，低于该索引时我们会让服务器冷却，高于该索引时我们会让服务器加热。由于动作0和1使服务器冷却，动作3和4使服务器加热，因此该方向边界为(5-1)/2
    = 2，对应于不向服务器传递热量的动作（动作2）。'
- en: '**Line 21**: We set the number of training epochs to `100`.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '**第21行**：我们将训练的epoch数设置为`100`。'
- en: '**Line 22**: We set the memory capacity, meaning its maximum size, to `3000`.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '**第22行**：我们将内存容量（即最大大小）设置为`3000`。'
- en: '**Line 23**: We set the batch size to `512`.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '**第23行**：我们将批量大小设置为`512`。'
- en: '**Line 24**: We introduce the temperature step, meaning the absolute temperature
    change that the AI cause onto the server by playing actions 0, 1, 3, or 4\. And
    that''s of course `1.5`°C.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '**第24行**：我们引入了温度步长，意味着AI通过执行动作0、1、3或4对服务器产生的绝对温度变化。而这个值当然是`1.5`°C。'
- en: '**Line 27**: We create the `environment` object, as an instance of the `Environment`
    class which we call from the `environment` file. Inside this `Environment` class,
    we enter all the arguments of the `init` method:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '**第27行**：我们创建了`environment`对象，作为`Environment`类的实例，调用自`environment`文件。在这个`Environment`类中，我们输入了`init`方法的所有参数：'
- en: '[PRE15]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Line 30**: We create the `brain` object as an instance of the `Brain` class,
    which we call from the `brain_nodropout` file. Inside this `Brain` class, we enter
    all the arguments of the `init` method:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '**第30行**：我们创建了`brain`对象，作为`Brain`类的实例，调用自`brain_nodropout`文件。在这个`Brain`类中，我们输入了`init`方法的所有参数：'
- en: '[PRE16]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Line 33**: We create the `dqn` object as an instance of the `DQN` class,
    which we call from the `dqn` file. Inside this `DQN` class we enter all the arguments
    of the `init` method:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '**第33行**：我们创建了`dqn`对象，作为`DQN`类的实例，调用自`dqn`文件。在这个`DQN`类中，我们输入了`init`方法的所有参数：'
- en: '[PRE17]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**Line 36**: We set the training mode to `True`, because the next code section
    will contain the big `for` loop that performs all the training.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '**第36行**：我们将训练模式设置为`True`，因为接下来的代码部分将包含执行所有训练的大`for`循环。'
- en: All good so far? Don't forget to take a break or a step back by reading the
    previous paragraphs again anytime you feel a bit overwhelmed or lost.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止都还好吗？如果你感到有些不知所措或迷失，不妨稍作休息，或者回过头阅读前面的段落。
- en: 'Now let''s begin the big training loop; that''s the last code section of this
    file:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始进行大规模的训练循环；这是这个文件的最后一部分代码：
- en: '[PRE18]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Line 39**: We set the `env.train` object variable (this is a variable of
    our `environment` object) to the value of the `train` variable entered just before,
    which is of course equal to `True`, meaning we are indeed in training mode.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '**第39行**：我们将`env.train`对象变量（这是我们`environment`对象的一个变量）设置为之前输入的`train`变量的值，当然这个值为`True`，表示我们确实处于训练模式。'
- en: '**Line 40**: We get the model from our `brain` object. This model contains
    the whole architecture of the neural network, plus its optimizer. It also has
    extra practical tools, like for example the `save` and `load` methods, which will
    allow us respectively to save the weights after the training or load them anytime
    in the future.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '**第40行**：我们从`brain`对象中获取模型。这个模型包含神经网络的完整架构，以及它的优化器。它还具有额外的实用工具，例如`save`和`load`方法，分别允许我们在训练后保存权重，或随时加载它们。'
- en: '**Line 41**: If we are in training mode…'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '**第41行**：如果我们处于训练模式...'
- en: '**Line 43**: We start the main training `for` loop, iterating the training
    epochs from 1 to 100.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '**第43行**：我们开始主训练`for`循环，迭代训练周期从1到100。'
- en: '**Line 45**: We set the total reward (total reward accumulated over the training
    iterations) to `0`.'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '**第45行**：我们将总奖励（训练过程中累积的总奖励）设置为`0`。'
- en: '**Line 46**: We set the loss to `0` (`0` because the loss will be a `float`).'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '**第46行**：我们将损失设置为`0`（`0`因为损失将是一个`float`类型）。'
- en: '**Line 47**: We set the starting month of the training, called `new_month`,
    to a random integer between 0 and 11\. For example, if the random integer is 2,
    we start the training in March.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**第47行**：我们将训练的起始月份，称为`new_month`，设置为0到11之间的一个随机整数。例如，如果随机整数是2，我们就从3月开始训练。'
- en: '**Line 48**: By calling the `reset` method from our `env` object of the `Environment`
    class built in Step 1, we reset the environment starting from that `new_month`.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '**第48行**：通过调用我们在步骤1中构建的`Environment`类的`env`对象中的`reset`方法，我们将从`new_month`重新设置环境。'
- en: '**Line 49**: We set the `game_over` variable to `False`, because we''re starting
    in the allowed range of server temperatures.'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '**第49行**：我们将`game_over`变量设置为`False`，因为我们正处于允许的服务器温度范围内。'
- en: '**Line 50**: By calling the `observe` method from our `env` object of the `Environment`
    class built in Step 1, we get the current state only, which is our starting state.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '**第50行**：通过调用我们在步骤1中构建的`Environment`类的`env`对象中的`observe`方法，我们只获得当前的状态，这就是我们的起始状态。'
- en: '**Line 51**: We set the first `timestep` to `0`. This is the first minute of
    the training.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '**第51行**：我们将第一个`timestep`设置为`0`。这是训练的第一分钟。'
- en: '**Line 53**: We start the `while` loop that will iterate all the timesteps
    (minutes) for the whole period of the epoch, which is 5 months. Therefore, we
    iterate through `5 * 30 * 24 * 60` minutes; that is, 216,000 timesteps.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '**第53行**：我们开始`while`循环，该循环将迭代整个周期内的所有时间步（分钟），即5个月。因此，我们将迭代`5 * 30 * 24 * 60`分钟；即216,000个时间步。'
- en: If, however, during those timesteps we go outside the allowed range of server
    temperatures (that is, if `game_over` = 1), then we stop the epoch and we start
    a new one.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果在这些时间步内，我们超出了允许的服务器温度范围（也就是说，如果`game_over` = 1），那么我们会停止这一轮并开始一个新的周期。
- en: Lines 55 to 61 make sure the AI performs a random action 30% of the time. This
    is exploration. The trick to it in this case is to sample a random number between
    0 and 1, and if this random number is between 0 and 0.3, the AI performs a random
    action. That means the AI will perform a random action 30% of the time, because
    this sampled number has a 30% chance to be between 0 and 0.3.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 第55行到61行确保AI在30%的时间内执行随机动作。这是探索。其窍门在于从0到1之间采样一个随机数字，如果这个数字在0到0.3之间，AI就会执行一个随机动作。这意味着AI将在30%的时间内执行随机动作，因为这个采样数字有30%的机会落在0到0.3之间。
- en: '**Line 55**: If a sampled number between 0 and 1 is below ![](img/B14110_11_208.png)...'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '**第55行**：如果从0到1之间采样的数字小于![](img/B14110_11_208.png)...'
- en: '**Line 56**: ... we play a random action index from 0 to 4.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '**第56行**：...我们执行一个从0到4的随机动作索引。'
- en: '**Line 57**: Now that we''ve just performed an action, we compute the direction
    and the energy spent; remember that they''re are the required arguments of the
    `update_env` method of the `Environment` class, which we''ll call later to update
    the environment. The AI distinguishes between two cases by checking if the action
    is below or above the direction boundary of 2\. If the action is below the direction
    boundary of 2, meaning the AI cools down the server...'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '**第57行**：既然我们刚刚执行了一个动作，我们就计算方向和耗费的能量；记住它们是`Environment`类的`update_env`方法所需的参数，我们稍后会调用该方法来更新环境。AI通过检查动作是否低于或高于2的方向边界来区分两种情况。如果动作低于2的方向边界，意味着AI正在冷却服务器...'
- en: '**Line 58**: ...then the heating direction is equal to `-1` (cooling down).'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '**第58行**：...则加热方向为`-1`（冷却）。'
- en: '**Line 59 and 60**: Else the heating direction is equal to `+1` (heating up).'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '**第59行和60行**：否则，加热方向为`+1`（加热）。'
- en: '**Line 61**: We compute the energy spent by the AI onto the server, which according
    to Assumption 2 is:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '**第61行**：我们计算AI在服务器上消耗的能量，根据假设2，计算方法是：'
- en: '|*action* - *direction_boundary*| * *temperature_step* = |*action* - 2| * 1.5
    *Joules*'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '|*动作* - *方向边界*| * *温度步长* = |*动作* - 2| * 1.5 *焦耳*'
- en: For example, if the action is 4, then the AI heats up the server by 3°C, and
    so according to Assumption 2 the energy spent is 3 Joules. And we check indeed
    that |4-2|*1.5 = 3.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果动作是4，那么AI将服务器加热3°C，因此根据假设2，消耗的能量是3焦耳。我们检查到确实有|4-2|*1.5 = 3。
- en: '**Line 63**: Now we play the actions by inference, meaning directly from our
    AI''s predictions. The inference starts from the `else` statement, which corresponds
    to the `if` statement of line 55\. This `else` corresponds to the situation where
    the sampled number is between 0.3 and 1, which happens 70% of the time.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '**第63行**：现在我们通过推理来执行动作，即直接根据我们AI的预测进行。推理从`else`语句开始，这对应于第55行的`if`语句。这个`else`语句对应的情况是抽样的数字介于0.3和1之间，这种情况发生的概率是70%。'
- en: '**Line 64**: By calling the `predict` method from our `model` object (`predict`
    is a pre-built method of the `Model` class), we get the five predicted Q-values
    from our AI model.'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '**第64行**：通过调用我们`model`对象的`predict`方法（`predict`是`Model`类的一个预构建方法），我们从AI模型中获得五个预测的Q值。'
- en: '**Line 65**: Using the `argmax` function from `numpy`, we select the action
    that has the maximum Q-value among the five predicted ones at Line 64.'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '**第65行**：使用`numpy`中的`argmax`函数，我们从第64行预测的五个Q值中选择Q值最大的动作。'
- en: '**Lines 66 to 70**: We do exactly the same as in Lines 57 to 61, but this time
    with the action performed by inference.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '**第66至70行**：我们做的与第57至61行完全相同，只不过这次是使用推理执行的动作。'
- en: '**Line 72**: Now we have everything ready to update the environment. We call
    the big `update_env` method made in the `Environment` class of Step 1, by inputting
    the heating direction, the energy spent by the AI, and the month we''re in at
    that specific timestep of the `while` loop. We get in return the next state, the
    reward received, and whether the game is over (that is, whether or not we went
    outside the optimal range of server temperatures).'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '**第72行**：现在我们已经准备好更新环境。我们调用第1步中`Environment`类中制作的`update_env`方法，输入加热方向、AI消耗的能量以及我们当前在`while`循环中特定时刻的月份。我们得到的返回值是下一个状态、获得的奖励，以及游戏是否结束（即是否超出了服务器温度的最佳范围）。'
- en: '**Line 73**: We add this last reward received to the total reward.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '**第73行**：我们将最后收到的奖励加到总奖励中。'
- en: '**Line 75**: By calling the `remember` method from our `dqn` object of the
    `DQN` class built in Step 3, we store the new transition [[`current_state`, `action`,
    `reward`, `next_state`], `game_over`] into the memory.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '**第75行**：通过调用我们在第3步构建的`DQN`类中的`dqn`对象的`remember`方法，我们将新的过渡[[`当前状态`，`动作`，`奖励`，`下一个状态`]，`游戏结束`]存储到内存中。'
- en: '**Line 77**: By calling the `get_batch` method from our `dqn` object of the
    `DQN` class built in Step 3, we create two separate batches of `inputs` and `targets`,
    each one having 512 elements (since `batch_size` = 512).'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '**第77行**：通过调用我们在第3步构建的`DQN`类中的`dqn`对象的`get_batch`方法，我们创建了两个独立的`inputs`和`targets`批次，每个批次包含512个元素（因为`batch_size`
    = 512）。'
- en: '**Line 79**: By calling the `train_on_batch` method from our `model` object
    (`train_on_batch` is a pre-built method of the `Model` class), we compute the
    loss error between the predictions and the targets over the whole batch. As a
    reminder, this loss error is the mean-squared error loss. Then in this same line,
    we add this loss error to the total loss of the epoch, in case we want to check
    how this total loss evolves over the epochs during the training.'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '**第79行**：通过调用我们`model`对象的`train_on_batch`方法（`train_on_batch`是`Model`类的一个预构建方法），我们计算预测值与目标值之间的损失误差，覆盖整个批次。提醒一下，这个损失误差是均方误差损失。然后在同一行中，我们将这个损失误差加到当前周期的总损失中，以便我们可以查看在训练过程中这个总损失如何随周期变化。'
- en: '**Line 80**: We increment the `timestep`.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '**第80行**：我们增加了`timestep`。'
- en: '**Line 81**: We update the current state, which becomes the new state reached.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '**第81行**：我们更新当前状态，它变成了新的达到的状态。'
- en: '**Line 83**: We print a new line to separate out the training results so we
    can look them over easily.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '**第83行**：我们打印一个新行，以便将训练结果分开，这样我们就能更容易地查看它们。'
- en: '**Line 84**: We print the epoch reached (the one we are in at this specific
    moment of the main training `for` loop).'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '**第84行**：我们打印出当前已达到的周期（即我们在主训练`for`循环的这一特定时刻所处的周期）。'
- en: '**Line 85**: We print the total energy spent by the AI over that specific epoch
    (the one we are in at this specific moment of the main training `for` loop).'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '**第85行**：我们打印出AI在该特定轮次（即当前`for`循环所处的那一轮）所消耗的总能量。'
- en: '**Line 86**: We print the total energy spent by the server''s integrated cooling
    system over that same specific epoch.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '**第86行**：我们打印出服务器集成冷却系统在该特定轮次（即同一轮训练中）所消耗的总能量。'
- en: '**Line 88**: We save the model''s weights at the end of the training, in order
    to load them in the future, anytime we want to use our pre-trained model to regulate
    a server''s temperature.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '**第88行**：我们在训练结束时保存模型的权重，以便将来加载这些权重，随时使用我们预训练的模型来调节服务器的温度。'
- en: That's it for training our AI without early stopping; now let's have a look
    at what you'd need to change to implement it.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是没有使用早停技术训练我们的AI的过程；现在让我们来看一下需要做什么更改才能实现它。
- en: Early stopping
  id: totrans-440
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 早停
- en: 'Now open the `training_earlystopping.py` file. Compare it to the previous file;
    all the lines of code from 1 to 40 are the same. Then, in the last code section,
    `TRAINING THE AI`, we have the same process, to which is added the early stopping
    technique. As a reminder, it consists of stopping the training if there''s no
    more improvement of the performance, which could be assessed two different ways:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 现在打开`training_earlystopping.py`文件。与之前的文件进行对比，代码第1到40行是一样的。然后，在最后的代码部分“`TRAINING
    THE AI`”中，我们执行相同的过程，并增加了早停技术。提醒一下，早停技术的作用是在性能不再提升时停止训练，这可以通过两种方式来评估：
- en: If the total reward of an epoch no longer increases much over the epochs.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果某一轮的总奖励在多轮训练中不再显著增加。
- en: If the total loss of an epoch no longer decreases much over the epochs.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果某一轮的总损失在多轮训练中不再显著下降。
- en: Let's see how we do this.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何做到这一点。
- en: 'First, we introduce four new variables just before the main training `for`
    loop:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在主要的训练`for`循环之前引入四个新变量：
- en: '[PRE19]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**Line 41**: We introduce a new variable, `early_stopping`, which is set equal
    to `True` if we decide to activate the early stopping technique, meaning if we
    decide to stop the training when the performance no longer improves.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '**第41行**：我们引入了一个新变量`early_stopping`，如果我们决定激活早停技术，即当性能不再提升时停止训练，它的值为`True`。'
- en: '**Line 42**: We introduce a new variable, `patience`, which is the number of
    epochs we wait without performance improvement before stopping the training. Here
    we choose a patience of `10` epochs, which means that if the best total reward
    of an epoch doesn''t increase during the next 10 epochs, we will stop the training.'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '**第42行**：我们引入了一个新变量`patience`，它表示在没有性能提升的情况下，我们等待多少轮才停止训练。在这里，我们选择`10`轮的耐心值，这意味着如果某一轮的最佳总奖励在接下来的10轮内没有提高，我们将停止训练。'
- en: '**Line 43**: We introduce a new variable, `best_total_reward`, which is the
    best total reward recorded over a full epoch. If we don''t beat that best total
    reward before 10 epochs go by, the training stops. It''s initialized to `-np.inf`,
    which represents `-infinity`. That''s just a trick to say that nothing can be
    lower than that best total reward at the beginning. Then as soon as we get the
    first total reward over the first epoch, `best_total_reward` becomes that first
    total reward.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '**第43行**：我们引入了一个新变量`best_total_reward`，它记录了一轮训练中获得的最佳总奖励。如果在10轮训练内没有超过这个最佳总奖励，则训练停止。它的初始值为`-np.inf`，代表`负无穷`。这只是一个技巧，表示最初没有什么比这个最佳总奖励还要低的。然后，一旦我们得到第一轮训练的总奖励，`best_total_reward`就变为该总奖励。'
- en: '**Line 44**: We introduce a new variable, `patience_count`, which is a counter
    starting from `0`, and is incremented by 1 each time the total reward of an epoch
    doesn''t beat the best total reward. If `patience_count` reaches 10 (the patience),
    we stop the training. And if one epoch beats the best total reward, `patience_count`
    is reset to 0.'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '**第44行**：我们引入了一个新变量`patience_count`，它是一个从`0`开始的计数器，每当某一轮的总奖励没有超过最佳总奖励时，`patience_count`加1。如果`patience_count`达到10（即耐心值），则停止训练。如果某一轮的总奖励超过最佳总奖励，`patience_count`会被重置为0。'
- en: 'Then, the main training `for` loop is the same as before, but just before saving
    the model we add the following:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，主要的训练`for`循环与之前相同，但在保存模型之前，我们添加了以下内容：
- en: '[PRE20]'
  id: totrans-452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Line 92**: If the `early_stopping` variable is `True`, meaning if the early
    stopping technique is activated…'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '**第92行**：如果`early_stopping`变量为`True`，表示早停技术被激活…'
- en: '**Line 93**: And if the total reward of the current epoch (we are still in
    the main training `for` loop that iterates the epochs) is lower than the best
    total reward of an epoch obtained so far…'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '**第93行**：如果当前周期的总奖励（我们仍然处于主训练`for`循环中，该循环会迭代周期）低于到目前为止获得的最佳周期总奖励…'
- en: '**Line 94**: ...we increment the `patience_count` variable by `1`.'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '**第94行**：...我们将`patience_count`变量增加`1`。'
- en: '**Line 95**: However, if the total reward of the current epoch is higher than
    the best total reward of an epoch obtained so far…'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '**第95行**：然而，如果当前周期的总奖励高于到目前为止获得的最佳周期总奖励…'
- en: '**Line 96**: ...we update the best total reward, which becomes that new total
    reward of the current epoch.'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '**第96行**：...我们更新最佳总奖励，将其设置为当前周期的新的总奖励。'
- en: '**Line 97**: ...and we reset the `patience_count` variable to `0`.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '**第97行**：...我们将`patience_count`变量重置为`0`。'
- en: '**Line 98**: Then in a new `if` condition, we check that if the `patience_count`
    variable goes higher than the patience of 10…'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '**第98行**：然后，在一个新的`if`条件中，我们检查`patience_count`变量是否超过10的耐心阈值…'
- en: '**Line 99**: ...we print `Early Stopping`,'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '**第99行**：...我们打印`Early Stopping`，'
- en: '**Line 100**: ...and we stop the main training `for` loop with a `break` statement.'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '**第100行**：...然后我们通过`break`语句停止主训练`for`循环。'
- en: That's the whole thing. Easy and intuitive, right? Now you know how to implement
    early stopping.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是全部内容。简单直观，对吧？现在你知道如何实现早停法了。
- en: After executing the code (I'll explain how to run this in a bit), we'll already
    see some good performances from our AI during the training, spending less energy
    than the server's integrated cooling system most of the time. But that's only
    training; now we need to see if we get good performance from the AI on a new 1-year
    simulation. That's where our next and final Python file comes into play.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行代码后（稍后我会解释如何运行它），我们会看到我们的AI在训练期间表现良好，大部分时间消耗的能量比服务器的集成冷却系统还少。但这只是训练阶段；现在我们需要看看AI在新的1年模拟中的表现如何。这就是我们下一个也是最后一个Python文件的作用所在。
- en: Step 5 – Testing the AI
  id: totrans-464
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤5 – 测试AI
- en: Now we need to test the performance of our AI in a brand-new situation. To do
    so, we run a 1-year simulation in inference mode, meaning that there's no training
    happening at any time. Our AI only returns predictions over a full year of simulation.
    Then, thanks to our environment object, in the end we'll be able to see the total
    energy spent by the AI over the full year, as well as the total energy that would
    have been spent in the exact same year by the server's integrated cooling system.
    Finally, we compare these two total energies spent, by computing their relative
    difference (in %) which shows us precisely the total energy saved by the AI. Buckle up
    for the final results—we'll reveal them very soon!
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要在全新的环境中测试我们的AI表现。为此，我们在推理模式下运行一个1年的模拟，这意味着在任何时刻都不会进行训练。我们的AI只会对整个1年的模拟进行预测。然后，借助我们的环境对象，最终我们将能够看到AI在整个1年中消耗的总能量，以及服务器集成冷却系统在同一年中本应消耗的总能量。最后，我们通过计算两者的相对差异（以%表示）来比较这两种总能量消耗，准确地显示出AI节省的总能量。系好安全带，最终结果马上揭晓！
- en: 'In terms of the AI blueprint, for the testing implementation we have almost
    the same process as the training implementation, except that this time we don''t
    need to create a `brain` object nor a `DQN` model object; and, of course, we won''t
    run the deep Q-learning process over some training epochs. However, we do have
    to create a new `environment` object, and instead of creating a `brain`, we''ll
    load our artificial brain with its pre-trained weights from the previous training
    that we executed in Step 4 – Training the AI. Let''s take a look at the final
    sub-steps of this final part of the AI framework/Blueprint:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI蓝图方面，对于测试实现，我们几乎和训练实现过程相同，唯一不同的是这次我们不需要创建`brain`对象或`DQN`模型对象；当然，我们也不会在一些训练周期上运行深度Q学习过程。然而，我们确实需要创建一个新的`environment`对象，并且，我们将不会创建一个`brain`，而是将我们的人工大脑加载到其从之前训练中获得的预训练权重。让我们来看看AI框架/蓝图最后部分的最终子步骤：
- en: '**Step 5-1**: Build a new environment by creating an object of the `Environment`
    class.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤5-1**：通过创建`Environment`类的对象来构建一个新的环境。'
- en: '**Step 5-2**: Load the artificial brain with its pre-trained weights from the
    previous training.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤5-2**：加载人工大脑，并从之前的训练中加载其预训练权重。'
- en: '**Step 5-3**: Choose the inference mode.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤5-3**：选择推理模式。'
- en: '**Step 5-4**: Start the 1-year simulation.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤5-4**：开始为期1年的模拟。'
- en: '**Step 5-5**: In each iteration (each minute), our AI only performs the action
    that results from its prediction, and no exploration or deep Q-learning training
    happens whatsoever.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤5-5**：在每次迭代中（每分钟），我们的AI仅执行根据其预测得出的动作，不进行任何探索或深度Q学习训练。'
- en: 'The implementation is a piece of cake to understand. It''s actually the same
    as the training file, except that:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 实现非常简单易懂。它实际上与训练文件相同，只是：
- en: Instead of creating a `brain` object from the `Brain` class, we load the pre-trained
    weights resulting from the training.
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不再从`Brain`类创建`brain`对象，而是加载训练得到的预训练权重。
- en: Instead of running a training loop over 100 epochs of 5-month periods, we run
    an inference loop over a single 12-month period. Inside this inference loop, you'll
    find exactly the same code as the inference part of the training `for` loop. You've
    got this!
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不再进行100个epochs的5个月周期训练，而是对一个12个月的周期运行推理循环。在这个推理循环中，你会看到与训练`for`循环的推理部分完全相同的代码。你能搞定的！
- en: 'Have a look at the full testing implementation in the following code:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下代码中的完整测试实现：
- en: '[PRE21]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Everything's more or less the same as before; we just removed the parts related
    to the training.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 一切与之前基本相同，只是我们删除了与训练相关的部分。
- en: The demo
  id: totrans-478
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演示
- en: 'Given the different files we have, make sure to understand that there are four
    possible ways to run the program:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们有不同的文件，请确保理解有四种可能的运行程序的方式：
- en: Without dropout and without early stopping
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不启用dropout并且不启用early stopping
- en: Without dropout and with early stopping
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不启用dropout并启用early stopping
- en: With dropout and without early stopping
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用dropout并且不启用early stopping
- en: With dropout and with early stopping
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用dropout并启用early stopping
- en: 'Then, for each of these four combinations, the way to run this is the same:
    we first execute the training file, and then the testing file. In this demo section,
    we''ll execute the 4th option, with both dropout and early stopping.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于这四种组合，运行的方式是相同的：我们首先执行训练文件，然后执行测试文件。在本演示部分，我们将执行第4个选项，包含dropout和early stopping。
- en: 'Now how do we run this? We have two options: with or without Google Colab.'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们该如何运行呢？我们有两个选项：使用或不使用Google Colab。
- en: 'I''ll explain how to do it on Google Colab, and I''ll even give you a Google
    Colab file where you only have to hit the play button. For those of you who want
    to execute this without Colab, on your favorite Python IDE, or through the terminal,
    let me explain how it''s done. It''s easy; you just need to download the main
    repository from GitHub, then in your Python IDE set the right working directory
    folder, which is the `Chapter 11` folder, and then run the following two files
    in this order:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 我将解释如何在Google Colab上操作，并且我还会给你一个Google Colab文件，你只需点击播放按钮即可。对于那些希望在自己的Python
    IDE或终端上执行此操作的用户，我将解释如何进行。这很简单；你只需要从GitHub下载主仓库，然后在Python IDE中设置正确的工作目录文件夹，即`Chapter
    11`文件夹，然后按此顺序运行以下两个文件：
- en: '`training_earlystopping.py`, inside which you should make sure to import `brain_dropout`
    at line 9\. This will execute the training, and you''ll have to wait until that
    finishes (which will take about 10 minutes).'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`training_earlystopping.py`，你应该确保在第9行导入`brain_dropout`。这将执行训练，你需要等待直到完成（大约需要10分钟）。'
- en: '`testing.py`, which will test the model on one full year of data.'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`testing.py`，它将在一整年的数据上测试模型。'
- en: 'Now, back to Google Colab. First, open a new Colaboratory file, and call it
    **Deep Q-Learning for Business**. Then add all your files from the `Chapter 11`
    folder of GitHub into this Colaboratory file, right here:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到Google Colab。首先，打开一个新的Colaboratory文件，并将其命名为**Deep Q-Learning for Business**。然后将来自GitHub的`Chapter
    11`文件夹中的所有文件添加到该Colaboratory文件中，如下所示：
- en: '![](img/B14110_11_11.png)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_11.png)'
- en: 'Figure 11: Google Colab – Step 1'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：Google Colab - 第1步
- en: 'Unfortunately, it''s not easy to add the different files manually. You can
    only do this by using the `os` library, which we won''t bother with. Instead,
    copy-paste the five Python implementations in five different cells of our Colaboratory
    file, in the following order:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，手动添加不同的文件并不容易。你只能通过使用`os`库来实现这一点，但我们不会在这里处理它。相反，请将五个Python实现代码粘贴到我们Colaboratory文件的五个不同单元格中，顺序如下：
- en: A first cell containing the whole `environment.py` implementation.
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个单元格包含完整的`environment.py`实现。
- en: A second cell containing the whole `brain_dropout.py` implementation.
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个单元格包含完整的`brain_dropout.py`实现。
- en: A third cell containing the whole `dqn.py` implementation.
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三个单元格包含完整的`dqn.py`实现。
- en: A fourth cell containing the whole `training_earlystopping.py` implementation.
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个包含整个 `training_earlystopping.py` 实现的第四个单元格。
- en: And a last cell containing the whole `testing.py` implementation.
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有一个包含整个 `testing.py` 实现的最后一个单元格。
- en: 'Here''s what it looks like, after adding some snazzy titles:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一些炫酷标题后的样子如下：
- en: '![](img/B14110_11_12.png)'
  id: totrans-499
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_12.png)'
- en: 'Figure 12: Google Colab – Step 2'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：Google Colab – 第2步
- en: '![](img/B14110_11_13.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_13.png)'
- en: 'Figure 13: Google Colab – Step 3'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：Google Colab – 第3步
- en: '![](img/B14110_11_14.png)'
  id: totrans-503
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_14.png)'
- en: 'Figure 14: Google Colab – Step 4'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：Google Colab – 第4步
- en: '![](img/B14110_11_15.png)'
  id: totrans-505
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_15.png)'
- en: 'Figure 15: Google Colab – Step 5'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：Google Colab – 第5步
- en: '![](img/B14110_11_16.png)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_16.png)'
- en: 'Figure 16: Google Colab – Step 6'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：Google Colab – 第6步
- en: 'Now before we execute each of these cells in the order one through five, we
    need to remove the `import` commands of the Python files. The reason for this
    is that now that the implementations are in cells, they''re like a single Python
    implementation, and we don''t have to import the interdependent files in every
    single cell. First, remove the following three different rows in the training
    file:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在按照顺序执行每个单元格（从第一个到第五个）之前，我们需要移除Python文件中的 `import` 命令。原因是现在这些实现都在单元格中，它们就像一个完整的Python实现，我们不需要在每个单元格中都导入相互依赖的文件。首先，移除训练文件中的以下三行：
- en: '![](img/B14110_11_17.png)'
  id: totrans-510
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_17.png)'
- en: 'Figure 17: Google Colab – Step 7'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：Google Colab – 第7步
- en: 'After doing that, we end up with this:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 完成之后，结果是这样的：
- en: '![](img/B14110_11_18.png)'
  id: totrans-513
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_18.png)'
- en: 'Figure 18: Google Colab – Step 8'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：Google Colab – 第8步
- en: 'Then, since we removed these imports, we also have to remove the three filenames
    for the `environment`, the `brain`, and the `dqn`, when creating the objects:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，由于我们移除了这些导入，我们也需要在创建对象时移除 `environment`、`brain` 和 `dqn` 这三个文件名：
- en: '**First the environment**:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '**首先是环境**：'
- en: '![](img/B14110_11_19.png)'
  id: totrans-517
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_19.png)'
- en: 'Figure 19: Google Colab – Step 9'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 图19：Google Colab – 第9步
- en: '**Then the brain**:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '**然后是大脑**：'
- en: '![](img/B14110_11_20.png)'
  id: totrans-520
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_20.png)'
- en: 'Figure 20: Google Colab – Step 10'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 图20：Google Colab – 第10步
- en: '**And finally the dqn**:'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '**最后是dqn**：'
- en: '![](img/B14110_11_21.png)'
  id: totrans-523
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_21.png)'
- en: 'Figure 21: Google Colab – Step 11'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 图21：Google Colab – 第11步
- en: 'Now the training file''s good to go. In the testing file, we just have to remove
    two things, the `environment` import at line 12:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练文件已经准备好。在测试文件中，我们只需移除两件事，分别是第12行的 `environment` 导入：
- en: '![](img/B14110_11_22.png)'
  id: totrans-526
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_22.png)'
- en: 'Figure 22: Google Colab – Step 12'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 图22：Google Colab – 第12步
- en: 'and the `environment.` at row 25:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 以及第25行的 `environment.`：
- en: '![](img/B14110_11_23.png)'
  id: totrans-529
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_23.png)'
- en: 'Figure 23: Google Colab – Step 13'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 图23：Google Colab – 第13步
- en: That's it; now you're all set! You're ready to literally hit the play button
    on each of the cells from top to the bottom.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样；现在一切准备就绪！你可以开始按顺序从上到下逐个点击每个单元格的播放按钮了。
- en: First, execute the first cell. After executing it, no output is displayed. That's
    fine!
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，执行第一个单元格。执行后不会显示任何输出。这是正常的！
- en: 'Then execute the second cell:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 然后执行第二个单元格：
- en: '[PRE22]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: After executing it, you can see the output `Using TensorFlow backend.`
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '执行后，你会看到输出 `Using TensorFlow backend.` '
- en: Then execute the third cell, after which no output is displayed.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 然后执行第三个单元格，执行后不会显示任何输出。
- en: 'Now it gets a bit exciting! You''re about to execute the training, and follow
    the training performance in real time. Do this by executing the fourth cell. After
    executing it, the training launches, and you should see the following results:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 现在开始变得有点令人兴奋了！你即将执行训练，并实时跟踪训练表现。通过执行第四个单元格来实现。执行后，训练将启动，你应该看到以下结果：
- en: '![](img/B14110_11_24.png)'
  id: totrans-538
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_24.png)'
- en: 'Figure 24: The output'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 图24：输出结果
- en: 'Don''t worry about those warnings, everything''s running the way it should.
    Since early stopping is activated, you''ll reach the end of the training way before
    the 100 epochs, at the 15th epoch:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心那些警告，一切都按照预期运行。由于启用了早期停止，训练会在100个epoch之前很早就结束，通常在第15个epoch时：
- en: '![](img/B14110_11_25.png)'
  id: totrans-541
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_25.png)'
- en: 'Figure 25: The output at the 15th epoch'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 图25：第15个epoch的输出结果
- en: 'Note that the pre-trained weights are saved in **Files**, in the `model.h5`
    file:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，预训练的权重保存在**文件**中，文件名为 `model.h5`：
- en: '![](img/B14110_11_26.png)'
  id: totrans-544
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14110_11_26.png)'
- en: 'Figure 26: The model.h5 file'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 图26：model.h5 文件
- en: The training results look promising. Most of the time the AI spends less energy
    than the alternative server's integrated cooling system. Check that this is still
    the case with a full test, on one new year of simulation.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 训练结果看起来很有前景。大多数时候，AI所消耗的能量比替代服务器的集成冷却系统要少。通过完整测试，检查一下在模拟一整年的情况下，情况是否仍然如此。
- en: Execute the final cell and when it finishes running, (which takes approximately
    3 minutes), you obtain in the printed results that the total energy consumption
    saved by the AI is…
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 执行最后一个单元格，运行完成后（大约需要3分钟），你将在打印结果中看到AI节省的总能量消耗是……
- en: '[PRE23]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**Total Energy saved by the AI = 87%**'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI节省的总能源 = 87%**'
- en: 'That''s a lot of energy saved! Google DeepMind achieved similarly impressive
    results in 2016\. If you look up the results by searching "DeepMind reduces Google
    cooling bill," you''ll see that the result they achieved was 40%. Not bad! Of
    course, let''s be critical: their server/ data center environment is much more
    complex than our server environment and has many more parameters, so even though
    they have one of the most talented AI teams in the world, they could only reduce
    the cooling bill by less than 50%.'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 这节省了大量的能源！谷歌DeepMind在2016年也取得了类似令人印象深刻的成果。如果你搜索“DeepMind减少谷歌冷却费用”，你会看到他们取得的成果是40%。不错吧！当然，我们也要保持批判性：他们的服务器/数据中心环境比我们的服务器环境要复杂得多，参数也更多，所以即使他们拥有世界上最优秀的AI团队之一，他们的冷却费用也只能减少不到50%。
- en: Our environment's very simple, and if you dig into it (which I recommend you
    do) you'll likely find that the variations of users and data, and therefore the
    variation of temperature, follow a uniform distribution. Accordingly, the server's
    temperature usually stays around the optimal range of temperatures. The AI understands
    that well, and thus chooses most of the time to take no action and cause no change
    of temperature, thus consuming very little energy.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的环境非常简单，如果你深入研究（我建议你这样做），你可能会发现用户和数据的变化，以及温度的变化，遵循的是均匀分布。因此，服务器的温度通常保持在最优温度范围内。AI对此理解得很好，因此大多数时候它选择不采取任何行动，也不会改变温度，从而消耗的能量非常少。
- en: I highly recommend that you play around with your server cooling model; make
    it as complex as you like, and try out different rewards to see if you can cause
    different behaviors.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议你尝试调整你的服务器冷却模型；可以根据自己的喜好使其变得更加复杂，并尝试不同的奖励，看看是否能引发不同的行为。
- en: Even though our environment is simple, you can be proud of your achievement.
    What matters is that you were able to build a deep Q-learning model for a real-world
    business problem. The environment itself is less important; what's most important
    is that you know how to connect a deep reinforcement learning model to an environment,
    and how to train the model inside.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们的环境很简单，你也可以为自己的成就感到骄傲。重要的是你成功地为一个真实世界的商业问题构建了一个深度Q学习模型。环境本身并不重要；最重要的是你知道如何将一个深度强化学习模型与环境连接，并且如何在其中训练该模型。
- en: Now, after your successes with the self-driving car plus this business application,
    you know how to do just that!
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在你取得了自动驾驶汽车和这个商业应用的成功之后，你知道该如何做到了！
- en: What we've built is excellent for our business client, as our AI will seriously
    reduce their costs. Remember that thanks to our object-oriented structure (working with
    classes and objects), we could very easily take the objects created in this implementation
    for one server, and then plug them into other servers, so that in the end we end
    up lowering the total energy consumption of a whole data center! That's how Google
    saved billions of dollars in energy-related costs, thanks to the `DQN` model built
    by their DeepMind AI.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所构建的系统对于我们的商业客户来说非常出色，因为我们的AI将大幅降低他们的成本。记住，得益于我们的面向对象结构（使用类和对象），我们可以非常容易地将这个实现中为一个服务器创建的对象，直接移植到其他服务器上，这样最终我们就能降低整个数据中心的总能耗！这正是谷歌凭借其DeepMind
    AI的`DQN`模型节省数十亿美元能源成本的方式。
- en: My heartiest congratulations to you for smashing this new application. You've
    just made huge progress with your AI skills.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 衷心祝贺你成功实现了这个新应用。你刚刚在AI技能上取得了巨大进步。
- en: 'Finally, here''s the link to the Colaboratory file with this whole implementation
    as promised. You don''t have to install anything, Keras and NumPy are already
    pre-installed (this is the beauty of Google Colab!):'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是承诺的带有完整实现的Colaboratory文件链接。你无需安装任何东西，Keras和NumPy已经预安装好（这就是Google Colab的魅力！）：
- en: '[https://colab.research.google.com/drive/1KGAoT7S60OC3UGHNnrr_FuN5Hcil0cHk](https://colab.research.google.com/drive/1KGAoT7S60OC3UGHNnrr_FuN5Hcil0cHk)'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://colab.research.google.com/drive/1KGAoT7S60OC3UGHNnrr_FuN5Hcil0cHk](https://colab.research.google.com/drive/1KGAoT7S60OC3UGHNnrr_FuN5Hcil0cHk)'
- en: Before we finish this chapter and move onto the world of deep convolutional
    Q-learning, let me give you a useful recap of the whole general AI blueprint when
    building a deep reinforcement learning model.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成这一章并进入深度卷积 Q 学习的世界之前，让我给你提供一份关于建立深度强化学习模型时整体 AI 蓝图的有用回顾。
- en: Recap – The general AI framework/Blueprint
  id: totrans-560
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回顾 – 一般 AI 框架/蓝图
- en: Let's recap the whole AI Blueprint, so that you can print it out and put it
    on your wall.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下整个 AI 蓝图，这样你就可以将其打印出来并挂在墙上。
- en: '**Step 1: Building the environment**'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：建立环境**'
- en: '**Step 1-1**: Introducing and initializing all the parameters and variables
    of the environment.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-1**：引入并初始化环境的所有参数和变量。'
- en: '**Step 1-2**: Making a method that updates the environment right after the
    AI plays an action.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-2**：创建一个方法，在 AI 执行动作后立即更新环境。'
- en: '**Step 1-3**: Making a method that resets the environment.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-3**：创建一个方法，重置环境。'
- en: '**Step 1-4**: Making a method that gives us at any time the current state,
    the last reward obtained, and whether the game is over.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1-4**：创建一个方法，使我们可以随时获取当前状态、最后获得的奖励以及游戏是否结束。'
- en: '**Step 2: Building the brain**'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：建立大脑**'
- en: '**Step 2-1**: Building the input layer composed of the input states.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2-1**：构建由输入状态组成的输入层。'
- en: '**Step 2-2**: Building the hidden layers with a chosen number of these layers
    and neurons inside each, fully connected to the input layer and between each other.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2-2**：构建隐藏层，选择这些层的数量以及每层中的神经元数量，并将其与输入层以及彼此之间完全连接。'
- en: '**Step 2-3**: Building the output layer, fully connected to the last hidden
    layer.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2-3**：建立与最后一个隐藏层完全连接的输出层。'
- en: '**Step 2-4**: Assembling the full architecture inside a model object.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2-4**：将完整的架构组装到一个模型对象中。'
- en: '**Step 2-5**: Compiling the model with a mean squared error loss function and
    a chosen optimizer (a good one is Adam).'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2-5**：使用均方误差损失函数和选择的优化器（推荐使用 Adam）来编译模型。'
- en: '**Step 3: Implementing the deep reinforcement learning algorithm**'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3：实现深度强化学习算法**'
- en: '**Step 3-1**: Introducing and initializing all the parameters and variables
    of the `DQN` model.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 3-1**：引入并初始化 `DQN` 模型的所有参数和变量。'
- en: '**Step 3-2**: Making a method that builds the memory in experience replay.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 3-2**：创建一个方法，用于在经验回放中构建记忆。'
- en: '**Step 3-3**: Making a method that builds and returns two batches of 10 inputs
    and 10 targets.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 3-3**：创建一个方法，构建并返回两个批次，每个批次包含 10 个输入和 10 个目标。'
- en: '**Step 4: Training the AI**'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 4：训练 AI**'
- en: '**Step 4-1**: Building the environment by creating an object of the `Environment`
    class built in Step 1.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-1**：通过创建在步骤 1 中构建的 `Environment` 类的对象来建立环境。'
- en: '**Step 4-2**: Building the artificial brain by creating an object of the `Brain`
    class built in Step 2.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-2**：通过创建在步骤 2 中构建的 `Brain` 类的对象来建立人工大脑。'
- en: '**Step 4-3**: Building the `DQN` model by creating an object of the `DQN` class
    built in Step 3.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-3**：通过创建在步骤 3 中构建的 `DQN` 类的对象来建立 `DQN` 模型。'
- en: '**Step 4-4**: Choosing the training mode.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-4**：选择训练模式。'
- en: '**Step 4-5**: Starting the training with a `for` loop over a chosen number
    of epochs.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-5**：通过一个 `for` 循环来开始训练，遍历选择的 epoch 数量。'
- en: '**Step 4-6**: During each epoch we repeat the whole deep Q-learning process,
    while also doing some exploration 30% of the time.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 4-6**：在每一个 epoch 中，我们重复整个深度 Q 学习过程，同时 30% 的时间进行一些探索。'
- en: '**Step 5: Testing the AI**'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 5：测试 AI**'
- en: '**Step 5-1**: Building a new environment by creating an object of the `Environment`
    class built in Step 1.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 5-1**：通过创建在步骤 1 中构建的 `Environment` 类的对象来建立一个新的环境。'
- en: '**Step 5-2**: Loading the artificial brain with its pre-trained weights from
    the previous training.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 5-2**：通过加载来自先前训练的人工大脑及其预训练的权重来加载人工大脑。'
- en: '**Step 5-3**: Choosing the inference mode.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 5-3**：选择推理模式。'
- en: '**Step 5-4**: Starting the simulation.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 5-4**：开始模拟。'
- en: '**Step 5-5**: At each iteration (each minute), our AI only plays the action
    that results from its prediction, and no exploration or deep Q-learning training
    is happening whatsoever.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 5-5**：在每次迭代（每分钟）中，我们的 AI 只执行其预测结果产生的动作，不进行任何探索或深度 Q 学习训练。'
- en: Summary
  id: totrans-590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter you re-applied deep Q-learning to a new business problem. You
    were supposed to find the best strategy to cool down and heat up the server. Before
    you started defining the AI strategy, you had to make some assumptions about your
    environment, for example the way the temperature is calculated. As inputs to your
    ANN, you had information about the server at any given time, like the temperature
    and data transmission. As outputs, your AI predicted whether to cool down or heat
    up our server by a certain amount. The reward was the energy saved with respect
    to the other, traditional cooling system. Your AI was able to save 87% energy.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你重新应用了深度Q学习来解决一个新的商业问题。你需要找到最优策略来冷却和加热服务器。在开始定义AI策略之前，你需要对环境做出一些假设，例如温度是如何计算的。作为你的人工神经网络（ANN）的输入，你有关于服务器在任何给定时刻的信息，比如温度和数据传输情况。作为输出，你的AI预测是否应该将服务器冷却或加热一定的量。奖励是相较于其他传统冷却系统所节省的能量。你的AI能够节省87%的能量。
