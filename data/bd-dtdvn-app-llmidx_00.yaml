- en: '<html:html><html:head><html:title>Understanding Large Language Models</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-16">Understanding
    Large Language Models</html:h1> <html:div id="_idContainer016"><html:p>If you
    are reading <html:a id="_idIndexMarker000"></html:a>this book, you have probably
    explored the realm of <html:strong class="bold">large language models</html:strong>
    ( <html:strong class="bold">LLMs</html:strong> ) and already recognize their potential
    applications as well as their pitfalls. This book aims to address the challenges
    LLMs face and provides a practical guide to building data-driven LLM applications
    with LlamaIndex, taking <html:a id="_idIndexMarker001"></html:a>developers from
    foundational concepts to advanced techniques for implementing <html:strong class="bold">retrieval-augmented
    generation</html:strong> ( <html:strong class="bold">RAG</html:strong> ) to create
    high-performance interactive <html:strong class="bold">artificial intelligence</html:strong>
    ( <html:strong class="bold">AI</html:strong> ) systems <html:a id="_idIndexMarker002"></html:a>augmented
    by <html:span class="No-Break">external data.</html:span></html:p> <html:p>This
    chapter introduces <html:strong class="bold">generative AI</html:strong> ( <html:strong
    class="bold">GenAI</html:strong> ) and LLMs. It explains how LLMs generate <html:a
    id="_idIndexMarker003"></html:a>human-like text after training on massive datasets.
    We’ll also overview LLM capabilities, limitations such as outdated knowledge potential
    for false information, and lack of reasoning. You’ll be introduced to RAG as a
    potential solution, combining retrieval models using indexed data with generative
    models to increase fact accuracy, logical reasoning, and context relevance. Overall,
    you’ll gain a basic LLM understanding and learn about RAG as a way to overcome
    some LLM weaknesses, setting the stage for utilizing <html:span class="No-Break">LLMs
    practically.</html:span></html:p> <html:p>In this chapter, we will cover the following
    <html:span class="No-Break">main topics:</html:span></html:p> <html:ul><html:li>Introducing
    GenAI <html:span class="No-Break">and LLMs</html:span></html:li> <html:li>Understanding
    the role of LLMs in <html:span class="No-Break">modern technology</html:span></html:li>
    <html:li>Exploring challenges <html:span class="No-Break">with LLMs</html:span></html:li>
    <html:li>Augmenting LLMs <html:span class="No-Break">with RAG</html:span></html:li></html:ul>
    <html:a id="_idTextAnchor016"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Introducing
    GenAI and LLMs</html:title></html:head> <html:body><html:div class="epub-source"><html:h1
    id="_idParaDest-17">Introducing GenAI and LLMs</html:h1> <html:div id="_idContainer016"><html:p>Introductions
    <html:a id="_idIndexMarker004"></html:a>are sometimes boring, but here, it is
    important <html:a id="_idIndexMarker005"></html:a>for us to set the context and
    help you familiarize yourself with GenAI and LLMs before we dive deep into LlamaIndex.
    I will try to be as concise as possible and, if the reader is already familiar
    with this information, I apologize for the <html:span class="No-Break">brief digression.</html:span></html:p>
    <html:a id="_idTextAnchor017"></html:a><html:h2 id="_idParaDest-18">What is GenAI?</html:h2>
    <html:p><html:strong class="bold">GenAI</html:strong> refers to <html:a id="_idIndexMarker006"></html:a>systems
    that are capable of generating new content such as text, images, audio, or video.
    Unlike more specialized AI systems that are designed for specific tasks such as
    image classification or speech recognition, GenAI models can create completely
    new assets that are often very difficult – if not impossible – to distinguish
    from <html:span class="No-Break">human-created content.</html:span></html:p> <html:p>These
    <html:a id="_idIndexMarker007"></html:a>systems use <html:strong class="bold">machine
    learning</html:strong> ( <html:strong class="bold">ML</html:strong> ) techniques
    such as <html:strong class="bold">neural networks</html:strong> ( <html:strong
    class="bold">NNs</html:strong> ) that <html:a id="_idIndexMarker008"></html:a>are
    trained on vast amounts of data. By learning patterns and structures within the
    training data, generative models can model the underlying probability distribution
    of the data and sample from this distribution to generate new examples. In other
    words, they act as big <html:span class="No-Break">prediction machines.</html:span></html:p>
    <html:p>We will now discuss LLMs, which are one of the most popular fields <html:span
    class="No-Break">in GenAI.</html:span></html:p> <html:a id="_idTextAnchor018"></html:a><html:h2
    id="_idParaDest-19">What is an LLM?</html:h2> <html:p>One of <html:a id="_idIndexMarker009"></html:a>the
    most prominent and rapidly advancing branches <html:a id="_idIndexMarker010"></html:a>of
    GenAI is <html:strong class="bold">natural language generation</html:strong> (
    <html:strong class="bold">NLG</html:strong> ) through <html:strong class="bold">LLMs</html:strong>
    ( <html:span class="No-Break"><html:em class="italic">Figure 1</html:em></html:span>
    <html:span class="No-Break"><html:em class="italic">.1</html:em></html:span> <html:span
    class="No-Break">):</html:span></html:p> <html:p class="IMG---Caption" lang="en-US">Figure
    1.1 – LLMs are a sub-branch of GenAI</html:p> <html:p>LLMs are NNs that are specifically
    designed and optimized to understand and generate human language. They are <html:em
    class="italic">large</html:em> in the sense that they are trained on massive amounts
    of text containing <html:a id="_idIndexMarker011"></html:a>billions or even trillions
    of words scraped from the internet and other sources. Larger models show increased
    performance on benchmarks, better generalization, and new emergent abilities.
    In contrast with earlier, rule-based generation systems, the main distinguishing
    feature of an LLM is that it can produce novel, original text that <html:span
    class="No-Break">reads naturally.</html:span></html:p> <html:p>By learning patterns
    from many sources, LLMs acquire various language skills found in their training
    data – from nuanced grammar to topic knowledge and even basic common-sense reasoning.
    These learned patterns allow LLMs to extend human-written text in contextually
    relevant ways. As they keep improving, LLMs create new possibilities for automatically
    <html:a id="_idIndexMarker012"></html:a>generating <html:strong class="bold">natural
    language</html:strong> ( <html:strong class="bold">NL</html:strong> ) content
    <html:span class="No-Break">at scale.</html:span></html:p> <html:p>During the
    training process, LLMs gradually learn probabilistic relationships between words
    and rules that govern language structure from their huge dataset of training data.
    Once trained, they are able to generate remarkably human-like text by predicting
    the probability of the next word in a sequence, based on the previous words. In
    many cases, the text they generate is so natural that it makes you wonder: aren’t
    we humans just a similar but more sophisticated prediction machine? But that’s
    a topic for <html:span class="No-Break">another book.</html:span></html:p> <html:p>One
    of the key <html:a id="_idIndexMarker013"></html:a>architectural innovations is
    the <html:strong class="bold">transformer</html:strong> (that is the <html:em
    class="italic">T</html:em> in <html:em class="italic">GPT</html:em> ), which uses
    an <html:strong class="bold">attention mechanism</html:strong> to learn contextual
    relationships between words. Attention <html:a id="_idIndexMarker014"></html:a>allows
    the model to learn long-range dependencies in text. It’s like if you’re listening
    carefully in a conversation, you pay <html:strong class="bold">attention</html:strong>
    to the context to understand the full meaning. This means they <html:em class="italic">understand</html:em>
    not just words that are close together but also how words that are far apart in
    a sentence or paragraph relate to <html:span class="No-Break">each other.</html:span></html:p>
    <html:p><html:em class="italic">Attention</html:em> allows the model to selectively
    focus on relevant parts of the input sequence when making predictions, thus capturing
    complex patterns and dependencies within the data. This feature <html:a id="_idIndexMarker015"></html:a>makes
    it possible for particularly large transformer models (with many parameters and
    trained on massive datasets) to demonstrate surprising new abilities such as in-context
    learning, where they can perform tasks <html:a id="_idIndexMarker016"></html:a>with
    just a few examples in their prompt. To learn more about transformers and <html:strong
    class="bold">Generative Pre-trained Transformer</html:strong> ( <html:strong class="bold">GPT</html:strong>
    ), you can refer to <html:em class="italic">Improving Language Understanding with
    unsupervised learning</html:em> – Alec Radford, Karthik Narasimhan, Tim Salimans
    and Ilya <html:span class="No-Break">Sutskever (</html:span> <html:a><html:span
    class="No-Break">https://openai.com/research/language-unsupervised</html:span></html:a>
    <html:span class="No-Break">).</html:span></html:p> <html:p>The best-performing
    LLMs such as GPT-4, Claude 2.1, and Llama 2 contain trillions of parameters <html:a
    id="_idIndexMarker017"></html:a>and have been trained on internet-scale datasets
    using advanced <html:strong class="bold">deep learning</html:strong> ( <html:strong
    class="bold">DL</html:strong> ) techniques. The resulting model has an extensive
    vocabulary and a broad knowledge of language structure such as grammar and syntax,
    and about the world in general. Thanks to their unique traits, LLMs are able to
    generate text that is coherent, grammatically correct, and semantically relevant.
    The outputs they produce may not always be completely logical or factually accurate,
    but they usually read convincingly like being written by a human. But it’s not
    all about size. The quality of data and training algorithms – among others – can
    also play a huge role in the resulting performance of a <html:span class="No-Break">particular
    model.</html:span></html:p> <html:p>Many models feature a user interface that
    allows for response generation through prompts. Additionally, some offer an API
    for developers to access the model programmatically. This method will be our primary
    focus in the upcoming chapters of <html:span class="No-Break">our book.</html:span></html:p>
    <html:p>Next up, we’ll talk about how LLMs are making big changes in tech. They’re
    helping not just big companies but everyone. Curious? Let’s <html:span class="No-Break">keep
    reading.</html:span></html:p> <html:a id="_idTextAnchor019"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Understanding
    the role of LLMs in modern technology</html:title></html:head> <html:body><html:div
    class="epub-source"><html:h1 id="_idParaDest-20">Understanding the role of LLMs
    in modern technology</html:h1> <html:div id="_idContainer016"><html:p>Oh! What
    good times we are living in. There has never been a more favorable era for small
    businesses <html:a id="_idIndexMarker018"></html:a>and entrepreneurs. Given the
    enormous potential of this technology, it’s a real miracle that, instead of ending
    up strictly under the control of large corporations or governments, it is literally
    within everyone’s reach. Now, it’s truly possible for almost anyone – even a non-technical
    person – to realize their ideas and solve problems that until now seemed impossible
    to solve without a huge amount <html:span class="No-Break">of resources.</html:span></html:p>
    <html:p>The disruptive potential that LLMs have – in almost all industries – <html:span
    class="No-Break">is enormous.</html:span></html:p> <html:p>It’s true: there are
    concerns that this technology could replace us. However, technology’s role is
    to make lives easier, taking over repetitive activities. As before, we’ll likely
    do the same things, only much more efficiently and better with LLMs’ help. We
    will do more <html:span class="No-Break">with less.</html:span></html:p> <html:p>I
    would dare say that LLMs have become the foundation of NLG technology. They can
    already power chatbots, search engines, coding assistants, text summarization
    tools, and other applications that synthesize written text interactively or automatically.
    And their capabilities keep advancing rapidly with bigger datasets <html:span
    class="No-Break">and models.</html:span></html:p> <html:p>And then, there are
    also the <html:strong class="bold">agents</html:strong> . These automated wonders
    are capable of perceiving and interpreting <html:em class="italic">stimuli</html:em>
    from the digital environment – and not just digital – to make decisions and act
    accordingly. Backed by the power of an LLM, intelligent agents can solve complex
    problems and fundamentally change the way we interact with technology. We’ll cover
    this topic in more detail throughout <html:a><html:span class="No-Break"><html:em
    class="italic">Chapter 8</html:em></html:span></html:a> , <html:em class="italic">Building
    Chatbots and Agents</html:em> <html:span class="No-Break"><html:em class="italic">with
    LlamaIndex</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p>Despite their relatively short existence, LLMs have already proven to
    be remarkably versatile and powerful. With the right techniques and prompts, their
    output can be steered in useful directions at scale. LLMs are driving innovation
    in numerous fields as their generative powers continue to evolve. Their capabilities
    keep expanding from nuanced dialog to multimodal intelligence. And, at the moment,
    the LLM-powered wave of innovation across industries and technologies shows no
    signs of <html:span class="No-Break">slowing down.</html:span></html:p> <html:p><html:strong
    class="bold">The Gartner Hype Cycle model</html:strong> serves <html:a id="_idIndexMarker019"></html:a>as
    a strategic guide for technology leaders, helping them evaluate new technologies
    not just on their merits but also in the context of their organization’s specific
    needs and <html:span class="No-Break">goals (</html:span> <html:a><html:span class="No-Break">https://www.gartner.com/en/research/methodologies/gartner-hype-cycle</html:span></html:a>
    <html:span class="No-Break">).</html:span></html:p> <html:p>Judging by current
    adoption levels, LLMs are currently well into the <html:strong class="bold">Slope
    of Enlightenment</html:strong> stage, ready to take off into the <html:strong
    class="bold">Plateau of Productivity</html:strong> – where mainstream adoption
    really starts to take off ( <html:span class="No-Break"><html:em class="italic">Figure
    1</html:em></html:span> <html:em class="italic">.2</html:em> ). Companies are
    becoming more pragmatic <html:a id="_idIndexMarker020"></html:a>about their application,
    focusing on specialized use cases where they offer the <html:span class="No-Break">most
    value:</html:span></html:p> <html:p class="IMG---Caption" lang="en-US">Figure
    1.2 – The Gartner Hype Cycle</html:p> <html:p>But, unlike other more specific
    technologies, LLMs are rather a new form of infrastructure – a kind of ecosystem
    where new concepts will be able to manifest and, undoubtedly, revolutionary applications
    will <html:span class="No-Break">be born.</html:span></html:p> <html:p>This is
    their true potential, and this is the ideal time to learn how to take advantage
    of the opportunities <html:span class="No-Break">they offer.</html:span></html:p>
    <html:p>Before we jump into innovative solutions that could maximize LLMs’ capabilities,
    let’s take a step back and look at some challenges <html:span class="No-Break">and
    limitations.</html:span></html:p> <html:a id="_idTextAnchor020"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Exploring
    challenges with LLMs</html:title></html:head> <html:body><html:div class="epub-source"><html:h1
    id="_idParaDest-21">Exploring challenges with LLMs</html:h1> <html:div id="_idContainer016"><html:p>Not
    all the news is good, however. It’s time to also discuss the <html:em class="italic">darker</html:em>
    side <html:span class="No-Break">of LLMs.</html:span></html:p> <html:p>These <html:a
    id="_idIndexMarker021"></html:a>models do have important limitations and some
    collateral effects too. Here is a list of the most important ones, but please
    consider it non-exhaustive. There may be others not included here, and the order
    is <html:span class="No-Break">arbitrarily chosen:</html:span></html:p> <html:ul><html:li>They
    lack access to <html:span class="No-Break">real-time data.</html:span> <html:ul><html:li>LLMs
    are trained on a static dataset, meaning that the information they have is only
    as up to date as the data they were trained on, which might not include the latest
    news, scientific discoveries, or <html:span class="No-Break">social trends.</html:span></html:li>
    <html:li>This limitation can be critical when users seek real-time or recent information,
    as the LLMs might provide outdated or irrelevant responses. Furthermore, even
    if they cite data or statistics, these numbers are likely to have changed or evolved,
    leading to <html:span class="No-Break">potential misinformation.</html:span></html:li></html:ul></html:li></html:ul>
    <html:p class="callout-heading">Note</html:p> <html:p class="callout">While recent
    features introduced by OpenAI, for example, allow the underlying LLM to integrate
    with Bing to retrieve fresh context from the internet, that’s not an inherent
    feature of the LLM but rather an augmentation provided by the <html:span class="No-Break">ChatGPT
    interface.</html:span></html:p> <html:ul><html:li>This lack of real-time updating
    also means that LLMs – by themselves – are not suited for tasks such as live customer
    service queries that may require real-time access to user data, inventory levels,
    or system statuses, <html:span class="No-Break">for example.</html:span></html:li></html:ul>
    <html:ul><html:li>They have no intrinsic way of distinguishing factual truth <html:span
    class="No-Break">from falsehoods.</html:span> <html:ul><html:li>Without proper
    monitoring, they can generate convincing misinformation. And trust me – they don’t
    do it on purpose. In very simple terms, LLMs are basically just looking for words
    that <html:span class="No-Break">fit together.</html:span></html:li> <html:li>Check
    out <html:em class="italic">Figure 1.3</html:em> for an example of how one of
    the previous versions of the GPT-3.5 model would produce <html:span class="No-Break">false
    information:</html:span></html:li></html:ul></html:li></html:ul> <html:p class="IMG---Caption"
    lang="en-US">Figure 1.3 – Screenshot from a GPT 3.5-turbo-instruct playground</html:p>
    <html:ul><html:li>As these models stochastically (randomly) generate text, their
    outputs are not guaranteed to be completely logical, factual, or harmless. Also,
    the training <html:a id="_idIndexMarker022"></html:a>data inherently biases the
    model, and LLMs may generate toxic, incorrect, or nonsensical text without warning.
    Since this data sometimes includes unsavory elements of online discourse, LLMs
    risk amplifying harmful biases and toxic content present in their <html:span class="No-Break">training
    data.</html:span></html:li></html:ul> <html:p class="callout-heading">Note</html:p>
    <html:p class="callout">While this kind of result may be easily achieved in a
    playground environment, using an older AI model, OpenAI’s ChatGPT interface uses
    newer models and employs additional guardrails, thus making these kinds of responses
    much <html:span class="No-Break">less probable.</html:span></html:p> <html:ul><html:li>They
    also cannot maintain context and memory over <html:span class="No-Break">long
    documents.</html:span> <html:ul><html:li>An interaction with a vanilla-flavor,
    standard LLM can prove to be a charm for simple topics or a quick question-and-answer
    session. But go beyond the context window limit of the model, and you’ll soon
    experience its limitations as it struggles to maintain coherence and may lose
    important details from earlier parts of the conversation or document. This can
    result in fragmented or incomplete responses that may not fully address the complexities
    of a long-form interaction or in-depth analysis, just like a human suffering from
    <html:em class="italic">short-term</html:em> <html:span class="No-Break"><html:em
    class="italic">memory loss</html:em></html:span> <html:span class="No-Break">.</html:span></html:li></html:ul></html:li></html:ul>
    <html:p class="callout-heading">Note</html:p> <html:p class="callout">Although
    recently released AI models such as Anthropic’s Claude 2.1 and Google’s Gemini
    Pro 1.5 have dramatically raised the bar in terms of context window limit, ingesting
    an entire book and running inference on such a large context may prove to be prohibitive
    from a <html:span class="No-Break">cost perspective.</html:span></html:p> <html:ul><html:li>LLMs
    also <html:a id="_idIndexMarker023"></html:a>exhibit unpredictable failures in
    reasoning and fact retention. Take a look at <html:span class="No-Break"><html:em
    class="italic">Figure 1</html:em></html:span> <html:em class="italic">.4</html:em>
    for a typical logic reasoning problem that proves to be challenging even for newer
    models such <html:span class="No-Break">as GPT-4:</html:span></html:li></html:ul>
    <html:p class="IMG---Caption" lang="en-US">Figure 1.4 – Screenshot from a GPT-4
    playground</html:p> <html:ul><html:li>In this example, the answer is wrong because
    the only scenario that fits is if Emily is the one telling the truth. The treasure
    would then be neither in the attic nor in <html:span class="No-Break">the basement.</html:span></html:li>
    <html:li>Their capabilities beyond fluent text generation remain inconsistent
    and limited. Blindly trusting their output without skepticism <html:span class="No-Break">invites
    errors.</html:span></html:li></html:ul> <html:ul><html:li>The complexity of massive
    LLMs also reduces transparency into <html:span class="No-Break">their functioning.</html:span>
    <html:ul><html:li>The lack of interpretability makes it hard to audit for issues
    or understand exactly when and why they fail. All you get is the output, but there’s
    no easy way of knowing the actual decision process that led to that output or
    the documented fact in which that particular output is grounded. As such, LLMs
    still require careful governance to mitigate risks from biased, false, or <html:span
    class="No-Break">dangerous outputs.</html:span></html:li></html:ul></html:li>
    <html:li>As with <html:a id="_idIndexMarker024"></html:a>many other things out
    there, it turns out we cannot really call them sustainable. At least <html:span
    class="No-Break">not yet.</html:span> <html:ul><html:li>Their massive scale makes
    them expensive to train and environmentally costly due to huge computing requirements.
    And it’s not just the training itself but also their usage. According to some
    estimates, “ <html:em class="italic">the water consumption of ChatGPT has been
    estimated at 500 milliliters for a session of 20-50 queries</html:em> ” – <html:em
    class="italic">AMPLIFY, VOL. 36, NO. 8</html:em> : <html:em class="italic">Arthur
    D. Little’s Greg Smith, Michael Bateman, Remy Gillet, and Eystein Thanisch</html:em>
    ( <html:a>https://www.cutter.com/article/environmental-impact-large-language-models</html:a>
    ). This is not negligible by any means. Think about the countless failed attempts
    to get an answer from an LLM, then multiply that with the countless users exercising
    their prompt engineering skills <html:span class="No-Break">every minute.</html:span></html:li></html:ul></html:li>
    <html:li>And here’s some more bad news: as models advance in complexity and training
    techniques, LLMs are rapidly becoming a huge source of <html:span class="No-Break">machine-generated
    text.</html:span> <html:ul><html:li>So huge, in fact, that according to predictions,
    it will end up almost entirely replacing human-generated text ( <html:em class="italic">Brown,
    Tom B. et al. (2020)</html:em> . <html:em class="italic">Language Models are Few-Shot
    Learners</html:em> . <html:em class="italic">arXiv:2005.14165 [</html:em> <html:span
    class="No-Break"><html:em class="italic">cs.CL]</html:em></html:span> <html:span
    class="No-Break">.</html:span> <html:a><html:span class="No-Break">https://arxiv.org/abs/2005.14165</html:span></html:a>
    <html:span class="No-Break">).</html:span></html:li> <html:li>In a way, this means
    they may become the victims of their own success. As more and more data is generated
    by AI, it gradually <html:em class="italic">contaminates</html:em> the training
    of new models, decreasing <html:span class="No-Break">their capabilities.</html:span></html:li>
    <html:li>As in biology, any ecosystem that cannot maintain a healthy diversity
    in its genetic pool will <html:span class="No-Break">gradually degrade.</html:span></html:li></html:ul></html:li></html:ul>
    <html:p><html:em class="italic">I saved the good news</html:em> <html:span class="No-Break"><html:em
    class="italic">for last.</html:em></html:span></html:p> <html:p>What if I told
    you there is at least one solution that can partially address almost all <html:span
    class="No-Break">these problems?</html:span></html:p> <html:p>In many ways, a
    language model is very similar to an operating system. It provides a foundational
    layer upon which applications can be built. Just as an operating system manages
    <html:a id="_idIndexMarker025"></html:a>hardware resources and provides services
    for computer programs, LLMs manage linguistic resources and provide services <html:a
    id="_idIndexMarker026"></html:a>for various <html:strong class="bold">NL processing</html:strong>
    ( <html:strong class="bold">NLP</html:strong> ) tasks. Using prompts to interact
    with them is much like writing code using an Assembly Language. It’s a low-level
    interaction. But, as you’ll soon find out, there are more sophisticated and practical
    ways of using LLMs to their <html:span class="No-Break">full potential.</html:span></html:p>
    <html:p>It’s time to talk <html:span class="No-Break">about RAG.</html:span></html:p>
    <html:a id="_idTextAnchor021"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Augmenting
    LLMs with RAG</html:title></html:head> <html:body><html:div class="epub-source"><html:h1
    id="_idParaDest-22">Augmenting LLMs with RAG</html:h1> <html:div id="_idContainer016"><html:p>Coined
    for <html:a id="_idIndexMarker027"></html:a>the first time in a 2020 <html:a id="_idIndexMarker028"></html:a>paper,
    <html:em class="italic">Lewis, Patrick et al. (2005). “Retrieval-Augmented Generation
    for Knowledge-Intensive NLP Tasks”. arXiv:2005.11401 [cs.CL]</html:em> ( <html:a>https://arxiv.org/abs/2005.11401</html:a>
    ), published by several researchers from Meta, RAG is a technique that combines
    the powers of retrieval methods and generative models to answer user questions.
    The idea is to first retrieve relevant information from an indexed data source
    containing proprietary knowledge and then use that retrieved information to generate
    a more informed, context-rich response using a generative model ( <html:span class="No-Break"><html:em
    class="italic">Figure 1</html:em></html:span> <html:span class="No-Break"><html:em
    class="italic">.5</html:em></html:span> <html:span class="No-Break">):</html:span></html:p>
    <html:p class="IMG---Caption" lang="en-US">Figure 1.5 – A RAG model</html:p> <html:p>Let’s
    <html:a id="_idIndexMarker029"></html:a>have a look at what this <html:a id="_idIndexMarker030"></html:a>means
    <html:span class="No-Break">in practice:</html:span></html:p> <html:ul><html:li><html:strong
    class="bold">Much better fact retention</html:strong> : One of the advantages
    of using RAG is its ability to pull from specific data sources, which can improve
    fact retention. Instead of relying solely on the generative model’s own <html:em
    class="italic">knowledge</html:em> – which is mostly generic – it refers to external
    documents to construct its answers, increasing the chances that the information
    <html:span class="No-Break">is accurate.</html:span></html:li> <html:li><html:strong
    class="bold">Improved reasoning</html:strong> : The retrieval step allows RAG
    models to pull in information that is specifically related to the question. In
    general, this would result in more logical and coherent reasoning. This could
    help overcome limitations in reasoning that many <html:span class="No-Break">LLMs
    face.</html:span></html:li> <html:li><html:strong class="bold">Context relevance</html:strong>
    : Because it pulls information from external sources based on the query, RAG can
    be more contextually accurate than a standalone generative model, which has to
    rely only on its training data and might not have the most up-to-date or contextually
    relevant information. Not only that, but you could also get an actual <html:em
    class="italic">quote</html:em> from the model regarding the source of the actual
    knowledge used in <html:span class="No-Break">the answer.</html:span></html:li>
    <html:li><html:strong class="bold">Reduced trust issues</html:strong> : While
    not foolproof, the hybrid approach means that RAG could, in principle, be less
    prone to generating completely false or nonsensical answers. That means an increased
    probability of receiving a <html:span class="No-Break">valid output.</html:span></html:li>
    <html:li><html:strong class="bold">Validation</html:strong> : It’s often easier
    to validate the reliability of the retrieved documents in an RAG setup by setting
    up a mechanism to provide a reference to the original information used for generating
    a response. This could be a step toward more transparent and trustworthy <html:span
    class="No-Break">model behavior.</html:span></html:li></html:ul> <html:p class="callout-heading">A
    word of caution</html:p> <html:p class="callout">Even <html:a id="_idIndexMarker031"></html:a>if
    RAG makes LLMs better <html:a id="_idIndexMarker032"></html:a>and more reliable,
    it doesn’t completely fix the issue of them sometimes giving wrong or confusing
    answers. There is no silver bullet that will completely eliminate all the issues
    mentioned previously. It’s still a good idea to double-check and evaluate their
    outputs, and we’ll talk about ways of doing that later in the book. Because, as
    you may already know or you’ve probably guessed by now, LlamaIndex is one of the
    many ways of augmenting LLM-based applications using RAG. And a very effective
    one, I <html:span class="No-Break">should add.</html:span></html:p> <html:p>While
    some LLM providers have started introducing RAG components into their API, such
    as OpenAI’s <html:strong class="bold">Assistants</html:strong> feature, using
    a standalone framework such as LlamaIndex provides many more customization options.
    It also enables the usage of local models, enabling self-hosted solutions and
    greatly reducing costs and privacy concerns associated with a <html:span class="No-Break">hosted
    model.</html:span></html:p> <html:a id="_idTextAnchor022"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Summary</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-23">Summary</html:h1>
    <html:div id="_idContainer016"><html:p>In this chapter, we covered a quick introduction
    to GenAI and LLMs. You learned how LLMs such as GPT work and some of their capabilities
    and limitations. A key takeaway is that while powerful, LLMs have weaknesses –
    such as the potential for false information and lack of reasoning – that require
    mitigation techniques. We discussed RAG as one method to overcome some <html:span
    class="No-Break">LLM limitations.</html:span></html:p> <html:p>These lessons provide
    useful background on how to approach LLMs practically while being aware of their
    risks. At the same time, you learned the importance of techniques such as RAG
    to address LLMs’ <html:span class="No-Break">potential downsides.</html:span></html:p>
    <html:p>With this introductory foundation in place, we are now ready to dive into
    the next chapter where we will explore the LlamaIndex ecosystem. LlamaIndex offers
    an effective RAG framework to augment LLMs with indexed data for more accurate,
    logical outputs. Learning to leverage LlamaIndex tools will be the natural next
    step to harness the power of LLMs in a <html:span class="No-Break">proficient
    way.</html:span></html:p></html:div></html:div></html:body></html:html>'
  prefs: []
  type: TYPE_NORMAL
