- en: Training Magenta Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练Magenta模型
- en: In this chapter, we'll use the prepared data from the previous chapter to train
    some of the RNN and VAE networks. Machine learning training is a finicky process
    involving a lot of tuning, experimentation, and back and forth between your data
    and your model. We'll learn to tune hyperparameters, such as batch size, learning
    rate, and network size, to optimize network performance and training time. We'll
    also show common training problems such as overfitting and models not converging.
    Once a model's training is complete, we'll show how to use the trained model to
    generate new sequences. Finally, we'll show how to use Google Cloud Platform to
    train models faster on the cloud.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用前一章准备的数据来训练一些RNN和VAE网络。机器学习训练是一个复杂的过程，涉及大量的调优、实验以及数据与模型之间的反复迭代。我们将学习如何调整超参数，如批次大小、学习率和网络大小，以优化网络性能和训练时间。我们还将展示常见的训练问题，如过拟合和模型不收敛。一旦模型训练完成，我们将展示如何使用训练好的模型生成新的序列。最后，我们将展示如何使用Google
    Cloud Platform在云端加速模型训练。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: Choosing the model and configuration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择模型和配置
- en: Training and tuning a model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和调整模型
- en: Using Google Cloud Platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google Cloud Platform
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we''ll use the following tools:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下工具：
- en: A **command line** or **Bash** to launch Magenta from the Terminal
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**命令行**或**Bash**从终端启动Magenta
- en: '**Python** and its libraries to write specific training configuration for a
    model'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Python**及其库编写特定的模型训练配置
- en: '**Magenta** and **Magenta GPU** to train our models'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Magenta**和**Magenta GPU**来训练我们的模型
- en: '**TensorBoard** to verify the training metrics'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorBoard** 用于验证训练指标'
- en: '**Google Cloud Platform** to offload the training in the cloud'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Google Cloud Platform**在云端进行训练
- en: In Magenta, we'll make the use of the **Drums RNN**, **Melody RNN**, and **MusicVAE**
    models for training. We'll be explaining the training for those models, but if
    you feel like you need more information, the model's README in Magenta's source
    code ([github.com/tensorflow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models))
    is a good place to start. You can also take a look at Magenta's code, which is
    well documented. We have also provided additional content in the last section,
    *Further reading*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在Magenta中，我们将使用**Drums RNN**、**Melody RNN**和**MusicVAE**模型进行训练。我们将解释这些模型的训练过程，但如果你觉得需要更多信息，可以查看Magenta源代码中的模型README
    ([github.com/tensorflow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models))，它是一个不错的起点。你还可以查看Magenta的代码，它有很好的文档支持。我们还在最后一节提供了*进一步阅读*的内容。
- en: The code for this chapter is in this book's GitHub repository in the `Chapter07` folder,
    located at [github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter07](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter07).
    The examples and code snippets will assume you are located in the chapter folder.
    For this chapter, you should go to `cd Chapter07` before you start.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于本书的GitHub仓库中的`Chapter07`文件夹，地址是[github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter07](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter07)。示例和代码片段假定你位于该章节的文件夹中。在本章开始之前，你应该先运行`cd
    Chapter07`。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，查看代码的实际应用：
- en: '[http://bit.ly/2OcaY5p](http://bit.ly/2OcaY5p)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2OcaY5p](http://bit.ly/2OcaY5p)'
- en: Choosing the model and configuration
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择模型和配置
- en: In [Chapter 6](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml), *Data Preparation
    for Training*, we looked at how to build a dataset. The datasets we produced were
    symbolic ones composed of MIDI files containing specific instruments, such as
    percussion or piano, and from specific genres, such as dance music and jazz music.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml)中，*训练数据准备*，我们研究了如何构建数据集。我们制作的数据集是符号型数据，由包含特定乐器（如打击乐器或钢琴）和特定音乐风格（如舞曲和爵士乐）的MIDI文件组成。
- en: We also looked at how to prepare a dataset, which corresponds to the action
    of preparing the input formats (MIDI, MusicXML, or ABCNotation) into a format
    that can be fed to the network. That format is specific to a Magenta model, meaning
    the preparation will be different for the Drums RNN and MusicVAE models, even
    if both models can train on percussion data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探讨了如何准备数据集，这对应于将输入格式（MIDI、MusicXML或ABCNotation）准备为可以输入到网络中的格式。该格式是特定于Magenta模型的，这意味着即使两个模型都能在打击乐数据上进行训练，Drums
    RNN和MusicVAE模型的准备工作也会有所不同。
- en: The first step before starting the training is to choose the proper model and
    configuration for our use case. Remember, a model in Magenta defines a deep neural
    network architecture, and each network type has its advantages and disadvantages.
    Let's have a look at how to choose a model, configure it, and train it from scratch.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练之前的第一步是为我们的使用案例选择合适的模型和配置。记住，Magenta中的模型定义了一个深度神经网络架构，每种网络类型都有其优缺点。让我们来看看如何选择一个模型，配置它并从头开始训练它。
- en: Comparing music generation use cases
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较音乐生成的使用案例
- en: 'Let''s take the example of training a percussion model. If we want to train
    a model that generates rhythmic percussion, we can either choose the Drums RNN
    model or the MusicVAE model:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以训练一个打击乐模型为例。如果我们想要训练一个生成节奏性打击乐的模型，我们可以选择Drums RNN模型或MusicVAE模型：
- en: The first model, Drums RNN, will be more efficient at **generating longer sequences**
    that keep the global musical structure because the model can learn long-term dependencies
    using the attention mechanism (refer to [Chapter 2](b60deee5-c58f-45eb-88a2-23718802e580.xhtml),
    *Generating Drum Sequences with Drums RNN*, for a refresher on that).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个模型，Drums RNN，将在**生成较长序列**时更有效，因为该模型可以通过注意力机制学习长期依赖关系，从而保持全球音乐结构（有关详细信息，请参见[第2章](b60deee5-c58f-45eb-88a2-23718802e580.xhtml)，*使用Drums
    RNN生成鼓序列*）。
- en: The second model, MusicVAE, won't be able to do that but will be able to sample
    from the latent space and **interpolate between sequences** (refer to [Chapter
    4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml), *Latent Space Interpolation with
    MusicVAE*, for a refresher on that).
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个模型，MusicVAE，无法做到这一点，但能够从潜在空间中进行采样并**在序列之间插值**（有关详细信息，请参见[第4章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)，*使用MusicVAE进行潜在空间插值*）。
- en: Depending on your use case, you might want to train one or the other or both,
    but keep in mind their strengths and weaknesses.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的使用案例，你可能想训练其中之一或两者，但请记住它们的优缺点。
- en: If we take the example of training a melody model, we can use a monophonic model,
    such as Melody RNN or MusicVAE (with the same restrictions as previously mentioned)
    if we want the resulting generation to be monophonic. We can also use a polyphonic
    model, such as Polyphony RNN if we want the generation to be polyphonic.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以训练一个旋律模型为例，如果我们希望生成的结果是单声部的，我们可以使用单声部模型，如Melody RNN或MusicVAE（具有之前提到的相同限制）。如果我们希望生成的结果是多声部的，我们可以使用多声部模型，如Polyphony
    RNN。
- en: Sometimes, we know what model to use, but the configuration doesn't fit our
    use case. Let's look at how to create a new configuration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们知道要使用哪个模型，但配置不适合我们的使用案例。让我们来看看如何创建一个新的配置。
- en: Creating a new configuration
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建新配置
- en: We'll take the example of a bass dataset we would like to train using the Music
    VAE model. Looking at the `configs` module in the `magenta.models.music_vae` module,
    we find the `cat-mel_2bar_small` configuration, which is close to what we want
    to achieve, but when the dataset is converted, the notes that don't correspond
    to a melody program (defined as 0 to 32 in Magenta) are thrown out.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以我们想要使用Music VAE模型训练的贝斯数据集为例。查看`magenta.models.music_vae`模块中的`configs`模块，我们找到了`cat-mel_2bar_small`配置，它接近我们想要实现的目标，但当数据集被转换时，不对应旋律程序的音符（在Magenta中定义为0到32）会被丢弃。
- en: You can find this code in the `chapter_07_example_01.py` file in the source
    code of this chapter. There are more comments and content in the source code,
    so you should go check it out.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的`chapter_07_example_01.py`文件中找到此代码。源代码中有更多的注释和内容，所以你应该去查看它。
- en: 'To achieve that, we''ll create a new configuration called `cat-bass_2bar_small`
    and we''ll change the valid programs to `bass` programs:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们将创建一个名为`cat-bass_2bar_small`的新配置，并将有效的程序更改为`bass`程序：
- en: 'First, let''s create a new `Config` instance with the following content:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个新的`Config`实例，内容如下：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The only part we've changed here is the `valid_programs=BASS_PROGRAMS` argument
    in `OneHotMelodyConverter`, but we could have changed other elements, such as
    `NoteSequenceAugmenter` that we talked about in the previous chapter. Hyperparameters
    can be changed using the `hparams` flag, but we can also define them in a configuration
    if we want to define default values for a model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里唯一改变的部分是`OneHotMelodyConverter`中的`valid_programs=BASS_PROGRAMS`参数，但我们本可以更改其他元素，例如上一章提到的`NoteSequenceAugmenter`。超参数可以使用`hparams`标志进行更改，但如果我们希望为模型定义默认值，也可以在配置中定义它们。
- en: 'To use the new configuration, we can call the `run` method of the `music_vae_train`
    module:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用新的配置，我们可以调用`music_vae_train`模块的`run`方法：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, we import the whole configuration map and add our new configuration before
    calling the `run` method, so that we can still pass other configurations in the
    `--config` flag.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们导入整个配置映射并在调用`run`方法之前添加新的配置，以便我们仍然可以在`--config`标志中传递其他配置。
- en: 'We can then call this code the same way as we would call the `music_vae_train`
    command:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以像调用`music_vae_train`命令一样调用此代码：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, `FLAGS` are the training flags we need to pass, such as `--run_dir` and
    `--sequence_example_file`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`FLAGS`是我们需要传递的训练标志，例如`--run_dir`和`--sequence_example_file`。
- en: Other models, such as the Drums RNN or Melody RNN models, will be configured
    in the same manner. Refer to the next section for examples on how to do that.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 其他模型，如鼓乐RNN或旋律RNN模型，也将以相同的方式进行配置。有关如何操作的示例，请参考下一节。
- en: Now that we know how to choose a model and a configuration (or create a new
    one), let's look at how to start and configure the training.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何选择模型和配置（或创建新配置），接下来看看如何开始和配置训练。
- en: Training and tuning a model
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和调整模型
- en: Training a machine model is an empirical and iterative approach, where we first
    prepare the data and the configuration, then train the model, fail, and restart
    again. Getting models to train on the first try is rare, but we'll persevere through
    hardship together.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 训练机器模型是一种经验性和迭代的方法，我们首先准备数据和配置，然后训练模型，失败后重新开始。在第一次尝试时让模型成功训练是很少见的，但我们会共同克服困难，继续前行。
- en: When launching a **training phase**, we'll be looking at specific metrics to
    verify that our model is training properly and converging. We'll also be launching
    an **evaluation phase**, which executes on a separate, smaller dataset, to verify
    that the model can properly generalize on data that it hasn't seen yet.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动**训练阶段**时，我们将查看特定的度量指标，以验证我们的模型是否在正确训练并且收敛。我们还将启动**评估阶段**，它将在一个单独的小型数据集上执行，以验证模型是否能够在未见过的数据上正确地泛化。
- en: The **evaluation** dataset is often called the **validation** dataset in machine
    learning in general, but we'll keep the term evaluation since it is used in Magenta.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估**数据集通常在机器学习中称为**验证**数据集，但我们将保持“评估”这一术语，因为在Magenta中使用的是这个术语。'
- en: The validation dataset is different than the **test** dataset, which is an external
    dataset, often curated by hand, and contains hard examples, giving a final test
    to measure the network performance. The test dataset is often used to compare
    different models' performance. We won't be looking at test datasets here.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 验证数据集与**测试**数据集不同，测试数据集是外部数据集，通常由人工整理，并包含难度较大的样本，用来对网络性能进行最终测试。测试数据集通常用于比较不同模型的性能。我们这里不会涉及测试数据集。
- en: We'll break down and explain each step of the process. Let's start by looking
    at some best practices and conventions we'll be using for this chapter.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分解并解释每个步骤的过程。首先，让我们看看本章将使用的一些最佳实践和约定。
- en: Organizing datasets and training data
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组织数据集和训练数据
- en: Because of the iterative nature of training, we'll get to produce many datasets
    and many **training runs**. The best way to proceed is to keep both separate,
    for example, in two folders named `datasets` and `training`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练是一个迭代过程，我们将生成许多数据集和多个**训练运行**。最好的做法是将这两者分开，例如，分别存放在名为`datasets`和`training`的文件夹中。
- en: 'In the `datasets` folder, we can copy what we produced from the previous chapter
    in separate folders, for example, `dance_drums`, `jazz_drums`, `piano_drums`,
    and so on, with the folders containing the MIDI files:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在`datasets`文件夹中，我们可以将上一章中生成的内容复制到不同的文件夹中，例如`dance_drums`、`jazz_drums`、`piano_drums`等，每个文件夹中包含MIDI文件：
- en: We keep the `notesequences.tfrecords` file in the proper dataset folder since
    it is produced only once per dataset.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将`notesequences.tfrecords`文件保存在正确的数据集文件夹中，因为它仅在每个数据集上生成一次。
- en: We keep the `sequence_examples` folder outside of this folder because it is
    model dependent, meaning we'll be regenerating this folder for each model, for
    example, once for Drums RNN and once for MusicVAE (even if we use the same data).
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将`sequence_examples`文件夹放在这个文件夹外面，因为它与模型相关，意味着我们将为每个模型重新生成这个文件夹，例如，Drums RNN和MusicVAE各生成一次（即使我们使用相同的数据）。
- en: 'In the `training` folder, we''ll be creating a new folder for each model and
    dataset, for example, `drums_rnn_dance_drums`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在`training`文件夹中，我们将为每个模型和数据集创建一个新文件夹，例如，`drums_rnn_dance_drums`：
- en: We'll be executing the `MODEL_create_dataset` command (if available), creating
    the `sequence_examples` directory (if any) for the model.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将执行`MODEL_create_dataset`命令（如果可用），并为模型创建`sequence_examples`目录（如果有的话）。
- en: 'Then, we''ll be launching multiple training runs, with proper naming, for example,
    `run1_with_dropout`, or other configuration we might want to use:'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们将启动多个训练运行，并进行适当命名，例如，`run1_with_dropout`，或者其他我们可能想使用的配置：
- en: '![](img/c44e2218-c64f-46ff-861b-3fcaea388f2a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c44e2218-c64f-46ff-861b-3fcaea388f2a.png)'
- en: Having a single training folder with multiple runs is useful because we can
    load multiple training runs in TensorBoard and compare how each model has performed.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个包含多个运行的单一训练文件夹非常有用，因为我们可以在TensorBoard中加载多个训练运行，并比较每个模型的表现。
- en: Training on a CPU or a GPU
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在CPU或GPU上训练
- en: Training is a computationally extensive activity. Training a simple model, such
    as the Drums RNN model, on an entry-level GPU (for example, an RTX 2060) will
    take around 5 hours. Training on the CPU takes a lot more time since the operations
    needed in network training (namely, vector arithmetic) are optimized to be executed
    in parallel on a GPU. To use a GPU, we also need to have properly installed the
    `magenta-gpu` package, as well as the CUDA libraries (see [Chapter 1](c5602f6c-c094-42f2-936f-98746cf04a49.xhtml),
    *Introduction on Magenta and Generative Art*, for more information on that).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是一项计算密集型活动。比如在入门级GPU（例如RTX 2060）上训练一个简单的模型，如Drums RNN模型，约需要5个小时。使用CPU训练则需要更多时间，因为网络训练中所需的操作（即向量运算）已被优化以在GPU上并行执行。要使用GPU，我们还需要正确安装`magenta-gpu`包和CUDA库（有关更多信息，请参见[第1章](c5602f6c-c094-42f2-936f-98746cf04a49.xhtml)，*Magenta与生成艺术简介*）。
- en: If you don't have a GPU, don't despair, you can follow this chapter anyway.
    You can do the data preparation steps and launch the training on a small network
    (see the first training example later on how to do that). Then, let the network
    train for a while, and if you see encouraging results, follow the steps in the
    last section, *Using Google Cloud Platform*, to restart the training on a faster
    machine. This will enable you to test the commands and datasets locally and then
    offload the bulk of the work to GCP. Even if you have a GPU, this might be a good
    way to proceed, especially if you want to train multiple models at the same time,
    or test different hyperparameters at the same time.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有GPU，不用担心，你仍然可以继续学习本章。你可以完成数据准备步骤，并在一个小型网络上启动训练（请参见后面第一个训练示例，了解如何进行）。然后，让网络训练一段时间，如果你看到令人鼓舞的结果，可以按照最后一节*使用Google云平台*中的步骤，在更快的机器上重新启动训练。这将允许你先在本地测试命令和数据集，然后将大部分工作卸载到GCP。即使你有GPU，这也可能是一个不错的选择，尤其是当你希望同时训练多个模型，或同时测试不同超参数时。
- en: The following sections and commands still apply to both CPU and GPU training,
    as well as GCP.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下章节和命令同样适用于CPU和GPU训练，以及GCP。
- en: Training RNN models
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练RNN模型
- en: We now have all of the elements to start training a model. Let's take a simple
    example, we'll use the `dance_drums` dataset from the previous chapter and train
    the Drums RNN model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了开始训练模型的所有元素。让我们以一个简单的例子开始，我们将使用上一章的`dance_drums`数据集，并训练Drums RNN模型。
- en: You can find this code in the `README.md` file in the source code of this chapter.
    Since most of the code snippets in this chapter are command line, we are not providing
    example files for each example.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章源代码的`README.md`文件中找到这段代码。由于本章中的大多数代码片段是命令行格式，我们没有为每个示例提供示例文件。
- en: From the previous chapter, we should now have a `datasets/dance_drums` folder
    ready with the MIDI files. We've already executed the `convert_dir_to_note_sequences`
    command, which produces a `notesequences.tfrecord` file.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章开始，我们应该已经准备好了包含MIDI文件的`datasets/dance_drums`文件夹。我们已经执行了`convert_dir_to_note_sequences`命令，生成了`notesequences.tfrecord`文件。
- en: Creating the dataset and launching the training
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建数据集并启动训练
- en: We'll now create the dataset (an operation we've already done in the previous
    chapter, but we show it again here as a refresher) and launch the training.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建数据集（这是我们在上一章已经做过的操作，但在这里再次展示以帮助复习），并启动训练。
- en: 'First, let''s create the sequence examples. In the `training` folder, create
    and change directory to a new folder called `drums_rnn_dance_drums`, and execute
    (replacing `PATH_TO_NOTE_SEQUENCES` with the proper file):'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们创建序列示例。在`training`文件夹中创建并切换到名为`drums_rnn_dance_drums`的新文件夹，并执行（将`PATH_TO_NOTE_SEQUENCES`替换为正确的文件）：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This should create a `sequence_examples` folder containing two files, a training
    set and an evaluation set for the drum sequences.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会创建一个`sequence_examples`文件夹，里面包含两个文件，一个是训练集，另一个是鼓序列的评估集。
- en: Ideally, the `drums_rnn_create_dataset` command should be called only once for
    all of the training runs. Since we are going to tune the hyperparameters between
    each run, and that the hyperparameters are sensible to the training data, changing
    the training and evaluation dataset while tuning the model is not a good idea.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，`drums_rnn_create_dataset`命令应该只在所有训练运行中调用一次。由于我们将在每次运行之间调整超参数，而超参数对训练数据非常敏感，因此在调优模型时改变训练和评估数据集并不是一个好主意。
- en: 'We''ll now start the training using a small network:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将开始使用一个小型网络进行训练：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: On Windows, the `--run_dir` flag should use a backslash. For this example and
    all of the following examples, instead of writing `--run_dir="logdir/run1_small"`,
    use `--run_dir="logdir\run1_small"`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，`--run_dir`标志应该使用反斜杠。对于这个例子以及所有后续的例子，不要写`--run_dir="logdir/run1_small"`，而应使用`--run_dir="logdir\run1_small"`。
- en: We use an output directory named `run1_small`, so we can remember later what
    run it is, and an input file named `training_drum_tracks.tfrecord`. The hyperparameters
    are a batch size of 64 and a two-layer RNN network of 64 units for each layer,
    the number of elements in the list defining the number of layers. For a 3 layers
    RNN network, use [64, 64, 64].
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个名为`run1_small`的输出目录，这样以后可以记住是哪次运行，以及一个名为`training_drum_tracks.tfrecord`的输入文件。超参数是批量大小为64，每层64个单元的两层RNN网络，列表中定义了层数。对于一个3层RNN网络，使用[64,
    64, 64]。
- en: 'You should see in the Terminal the complete list of hyperparameters and their
    values, which are taken from the configuration when not overridden by a flag:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在终端看到完整的超参数列表及其值，这些值来自配置文件，除非被标志覆盖。
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We''ll soon see how hyperparameters affect training in the following sections.
    If you are using a GPU, make sure TensorFlow can use your GPU by checking this
    output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快就会看到超参数如何影响训练。在接下来的章节中，如果你使用的是GPU，请通过检查以下输出确保TensorFlow可以使用你的GPU：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, the network will start training, and you should see outputs like this:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，网络将开始训练，你应该看到类似这样的输出：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We'll be talking about the different metrics soon. When we launched the training,
    we've used the `--num_training_steps=20000` flag, meaning the network will stop
    its training after reaching 20,000 global steps. We won't be talking about epoch
    here, which consists of a full cycle through the training data since we only handle
    steps in Magenta. The model should converge before that, but giving an upper bound
    is good so that it doesn't execute for too long for no reason.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快会讨论不同的评估指标。当我们启动训练时，使用了`--num_training_steps=20000`标志，这意味着网络将在达到20,000个全局步骤后停止训练。我们在这里不会讨论epoch，它是指遍历训练数据的完整周期，因为我们在Magenta中只处理步骤。模型应该会在此之前收敛，但给出一个上限是有好处的，这样它就不会无故执行太久。
- en: If you want to have an approximation on the time the training will take to reach
    20,000 steps, you can use the `global_step`/`sec` output. For the previous output,
    our job should finish in approximately 9 hours, but this is an upper bound, so
    chances are we can stop it before.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想大致估算训练完成20,000步所需的时间，可以使用`global_step`/`sec`输出。对于之前的输出，我们的工作大约需要9小时完成，但这是一个上限，因此我们有可能在此之前停止它。
- en: Now that the training is launched, we can launch the evaluation.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练已启动，我们可以启动评估。
- en: Launching the evaluation
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动评估
- en: The evaluation job executes on the evaluation dataset, which is a smaller (we
    previously used a `--eval_ratio=0.10` flag, meaning 10%) and separate dataset
    from the training set. The evaluation job evaluates the model and computes the
    loss function, without updating any of the weights in the network. Therefore,
    the evaluation process is fast and can be executed at the same time as the training
    job on the CPU.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 评估作业在评估数据集上执行，该数据集比训练集小（我们之前使用了`--eval_ratio=0.10`标志，表示10%），且与训练集分开。评估作业对模型进行评估，并计算损失函数，但不会更新网络中的任何权重。因此，评估过程非常快速，可以与训练作业在CPU上同时执行。
- en: To launch the evaluation, we use the same command, using the `--eval` flag.
    If you are using a GPU, you'll need to deactivate the GPU for that execution,
    using the `CUDA_VISIBLE_DEVICES=""` environment variable, because the previous
    TensorFlow process takes all of the available memory.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动评估，我们使用相同的命令，并使用`--eval`标志。如果你正在使用GPU，你需要通过`CUDA_VISIBLE_DEVICES=""`环境变量禁用GPU执行，因为之前的TensorFlow进程占用了所有可用内存。
- en: On Windows, don't forget to use a backslash in the `--run_dir` flag. Also on
    Windows, use the `set` command to set an environment variable for the current
    command-line session. On Linux and macOS, you can set the environment variable
    for a single command by prefixing the variable value before the command.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，不要忘记在`--run_dir`标志中使用反斜杠。此外，在Windows上，使用`set`命令为当前命令行会话设置环境变量。在Linux和macOS上，你可以通过在命令前面加上变量值来为单个命令设置环境变量。
- en: 'On Windows, use the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，使用以下命令：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'On Linux and macOS, use the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux和macOS上，使用以下命令：
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For this command, the provided network size needs to correspond to the training
    network size. If you used `rnn_layer_sizes=[64,64]` in the training command, then
    you need to use the same here. The two flags we've changed from the previous command
    are the `--eval` and `--sequence_example_file` flags.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个命令，提供的网络大小需要与训练时的网络大小一致。如果你在训练命令中使用了`rnn_layer_sizes=[64,64]`，那么这里也需要使用相同的配置。我们从之前的命令中改变了两个标志，分别是`--eval`和`--sequence_example_file`标志。
- en: 'The evaluation will execute when a new checkpoint (which happens approximately
    every 40 steps) is added in the running directory. When that happens, you''ll
    see outputs similar to this:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行目录中添加了一个新的检查点（大约每40步添加一次）时，评估将开始执行。发生这种情况时，你会看到类似以下的输出：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The evaluation job will stop automatically when the training job hasn't produced
    a checkpoint for a while.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练作业一段时间未生成检查点时，评估作业会自动停止。
- en: Looking at TensorBoard
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看TensorBoard
- en: During and after training, we can launch TensorBoard, which helps to visualize
    the network metrics. We'll be using TensorBoard to tune the hyperparameters and
    iterate with the data preparation phase.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练期间以及训练后，我们可以启动TensorBoard，帮助可视化网络指标。我们将使用TensorBoard来调整超参数并与数据准备阶段进行迭代。
- en: 'To launch TensorBoard, use the following command:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动TensorBoard，请使用以下命令：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Notice that we pass the parent output directory, meaning we''ll have access
    to all of the contained runs (currently, there''s only one). We can find the URL
    of TensorBoard in the console. Once opened, the page will look like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们传递了父输出目录，这意味着我们可以访问所有包含的运行（目前只有一个）。我们可以在控制台中找到TensorBoard的URL。打开后，页面将如下所示：
- en: '![](img/805823b5-0ced-4f1f-903e-2d12343a48e9.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/805823b5-0ced-4f1f-903e-2d12343a48e9.png)'
- en: This is the result of our trained model after 20,000 steps. On the left, we
    have the training and evaluation jobs, which can be toggled. On the right, different
    metrics are shown in the screenshot, with the abscissa being the global step count,
    which goes to 20,000 steps. The two most interesting metrics for us are **loss**
    and **accuracy**. We want the **loss to go down**, both for the training and evaluation
    sets, and the **accuracy to go up**.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们训练模型经过20,000步后的结果。左侧是训练和评估作业，可以切换显示。右侧的截图显示了不同的指标，其中横坐标是全局步数，达到了20,000步。对我们来说最重要的两个指标是**损失**和**准确度**。我们希望**损失下降**，无论是训练集还是评估集，同时希望**准确度上升**。
- en: 'We notice that this model has converged, meaning we have a successful training
    at hand, but we need to verify that the resulting model is good, by looking at
    the loss metric. Let''s have a look at the loss function, comparing the training
    loss and the evaluation loss:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到该模型已经收敛，这意味着我们成功地完成了训练，但我们需要通过查看损失指标来验证结果模型的好坏。让我们来看看损失函数，比较训练损失和评估损失：
- en: '![](img/4bc7a1a3-a4af-4278-bff6-ca8ab4d71cc1.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4bc7a1a3-a4af-4278-bff6-ca8ab4d71cc1.png)'
- en: We can see here that the model is slightly overfitting the training data. You
    can find the model optimum by taking the **evaluation loss curve at its lowest
    point** before it starts going up. On the left of that point, the model is underfitting
    the training data; on the right, the model is overfitting the data. The difference
    between both curves is called the generalization gap.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这里模型略微过拟合了训练数据。您可以通过找到**评估损失曲线的最低点**来找到模型的最优点，在该点之前曲线下降，之后曲线开始上升。在该点的左侧，模型在欠拟合训练数据；而在右侧，模型在过拟合数据。两条曲线之间的差异被称为泛化误差。
- en: Let's explain underfitting and overfitting before continuing on to other examples.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续其他例子之前，我们先来解释一下欠拟合和过拟合。
- en: Explaining underfitting and overfitting
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释欠拟合和过拟合
- en: Understanding underfitting and overfitting and how to prevent them is important
    for proper network training. When a model is too simple and cannot learn from
    the training dataset, we say the model is **underfitting**. On the other hand,
    when a model is learning properly from the training dataset but cannot generalize
    to data outside of it, we say the model is **overfitting**.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 理解欠拟合和过拟合以及如何防止它们，对于正确的网络训练至关重要。当模型过于简单，无法从训练数据集中学习时，我们称模型为**欠拟合**。另一方面，当模型能够正确地从训练数据集中学习，但无法将其泛化到数据集之外时，我们称模型为**过拟合**。
- en: 'We show underfitting, optimal solution, and overfitting in the following diagram:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在下图中展示了欠拟合、最优解和过拟合：
- en: '![](img/ebaab65a-ee21-416e-a484-ce3e621229e8.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebaab65a-ee21-416e-a484-ce3e621229e8.png)'
- en: On the left, we show underfitting, meaning the model didn't learn on the dataset.
    In the middle, we show an optimal solution, and on the right, we show overfitting,
    where the resulting model is overly complex for the given data, meaning the model
    won't generalize to other datasets.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，我们展示了欠拟合，意味着模型没有在数据集上学习。中间展示了一个最优解，而右侧展示了过拟合，其中得到的模型对于给定数据来说过于复杂，这意味着该模型无法泛化到其他数据集。
- en: Remember that the objective of a neural network is to perform well on the training
    dataset as well as **new data that it has never seen**, which will be used to
    make predictions. Achieving that is hard since it requires a proper combination
    of quality and quantity of data, as well as proper network size and learning parameters.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，神经网络的目标是既能在训练数据集上表现良好，也能在**从未见过的新数据**上表现良好，而这些数据将用于做出预测。要实现这一目标非常困难，因为这需要在数据的质量和数量、网络规模和学习参数之间找到适当的平衡。
- en: Let's have a look at how to fix those issues.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何解决这些问题。
- en: Fixing underfitting
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决欠拟合问题
- en: Underfitting is easy to address and can be solved by **increasing the capacity
    of the model**—basically, by adding more layers and units. By increasing the model's
    capacity, the network can learn more types of functions for mapping inputs to
    outputs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合问题容易解决，可以通过**增加模型的容量**来解决——基本上就是通过增加更多的层和单元。通过增加模型的容量，网络可以学习更多种类的函数，将输入映射到输出。
- en: 'For our previous example, we can increase the capacity of the model by adding
    more units (neurons) in each of the two layers:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们之前的例子，我们可以通过在两个层中每层增加更多的单元（神经元）来增加模型的容量：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We also need to train long enough, which might be hardware dependent, since
    if we are training on slow hardware, it might take a lot of time to reach the
    optimal point.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要训练足够长的时间，这可能与硬件有关，因为如果我们在性能较慢的硬件上训练，可能需要很长时间才能达到最优点。
- en: See the section, *Defining proper network size and hyperparameters*, for more
    information on network size.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 有关网络规模的更多信息，请参见*定义适当的网络规模和超参数*一节。
- en: Fixing overfitting
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决过拟合问题
- en: 'Overfitting, on the other hand, is harder to address since it comes from a
    variety of factors. The two most common causes are as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，过拟合问题更难解决，因为它源于多种因素。最常见的两种原因如下：
- en: When a model overfits, it is because it has the capacity of overfitting the
    training dataset. By keeping the same training dataset, you can **reduce the network
    capacity**, so that the network won't have the necessary resources to overfit
    the training data anymore. To reduce the network capacity, use the `rnn_layer_sizes`
    hyperparameter as in the previous example.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当模型出现过拟合时，是因为它具有过拟合训练数据集的能力。通过保持相同的训练数据集，您可以**减少网络容量**，以便网络没有足够的资源来过拟合训练数据。要减少网络容量，可以像之前的例子那样使用`rnn_layer_sizes`超参数。
- en: By keeping the same network capacity, you can **augment the training dataset
    size** so that, with more data, the network might not have the capacity to overfit
    it anymore. The added data needs to be varied enough to fix overfitting and might
    not always work. To augment the training dataset size, go back to [Chapter 6](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml),
    *Data Preparation for Training*, and add content to the dataset. Be aware that
    augmenting the dataset with data that isn't diverse enough won't help to resolve
    overfitting.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过保持相同的网络容量，你可以**增加训练数据集的大小**，这样，随着数据的增加，网络可能就不再有过拟合的能力。添加的数据需要足够多样化，以修复过拟合问题，但并不总是有效。要增加训练数据集的大小，请返回到[第6章](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml)，*数据准备训练*，并向数据集添加内容。请注意，如果增加的数据不够多样化，将无助于解决过拟合问题。
- en: 'There is a relationship between the training dataset and the network size:
    **the bigger and more diverse the dataset, the bigger the network has to be**.
    A bigger network won''t necessarily produce better results if the training dataset
    isn''t big enough or qualitative enough.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集与网络大小之间存在关系：**数据集越大且越多样化，网络就越大**。如果训练数据集不够大或者质量不够好，一个更大的网络不一定会产生更好的结果。
- en: 'There are other ways of fixing overfitting that can be used in Magenta models:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在Magenta模型中，有其他修复过拟合的方法可以使用：
- en: '**Early stopping** of the training phase at the optimal point is one way since
    all of the training after that point makes the resulting network worse. To use
    early stopping, see the next section, *Using a specific checkpoint to implement
    early stop*.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提前停止**在最佳点结束训练阶段是一种方法，因为在那一点之后的所有训练都会使结果网络变得更差。要使用提前停止，请参见下一节，*使用特定的检查点实现提前停止*。'
- en: Using regularization techniques such as **dropout**, which randomly and temporarily
    drops a unit/neuron out of the network, is another way. To use dropout, use the
    `dropout_keep_prob` hyperparameter.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用诸如**dropout**这样的正则化技术，它会随机且临时地从网络中丢弃一个单元/神经元。要使用dropout，请使用`dropout_keep_prob`超参数。
- en: Regularization techniques are a class of approach that aims at constraining
    the size of the weights in a neural network and is widely used as a way to prevent
    overfitting.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化技术是一类方法，旨在约束神经网络中权重的大小，并广泛用作预防过拟合的方法。
- en: As you might have noticed by now, there's a relationship between our dataset
    and our model that needs to be taken into account when tuning the training phase.
    Let's have a more detailed look into network size and hyperparameters.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你现在可能已经注意到的，我们的数据集和模型之间存在关系，在调整训练阶段时需要考虑这一点。让我们更详细地看一下网络大小和超参数。
- en: Defining network size and hyperparameters
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义网络大小和超参数
- en: Defining a proper network size is a trial and error process, but a good starting
    point, if your hardware is good enough, are the values in the configuration of
    the model you want to use.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 定义适当的网络大小是一个反复试验的过程，但是一个很好的起点是，如果你的硬件足够好，那么就使用你想要的模型配置中的数值。
- en: 'Let''s take an example using the `attention_rnn` configuration of the Melody
    RNN model, using `batch_size=128`, `rnn_layer_sizes=[128, 128]`, `dropout_keep_prob=0.5`,
    `learning_rate=0.001`, and `clip_norm=3`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个例子，使用Melody RNN模型的`attention_rnn`配置，使用`batch_size=128`，`rnn_layer_sizes=[128,
    128]`，`dropout_keep_prob=0.5`，`learning_rate=0.001`和`clip_norm=3`：
- en: 'If the model is overfitting, we can try the following:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果模型出现过拟合，我们可以尝试以下方法：
- en: Using more dropout, for example, `dropout_keep_prob=0.4` and lower values
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 例如，使用更多的dropout，如`dropout_keep_prob=0.4`和较低的值。
- en: Adding more data
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加更多数据
- en: Reducing the network size using `rnn_layer_sizes=[64, 64]`
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`rnn_layer_sizes=[64, 64]`来减小网络大小
- en: If the model is converging and not overfitting, we can try using a bigger model, `rnn_layer_sizes=[256,
    256]`. If we have good data, using a bigger model will yield better results, so
    we want to optimize that.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果模型正在收敛且没有过拟合，我们可以尝试使用更大的模型，例如`rnn_layer_sizes=[256, 256]`。如果我们有足够好的数据，使用更大的模型将产生更好的结果，因此我们希望优化这一点。
- en: When changing something, we need to make sure we are making a single modification
    and then testing the result before making any other change. Changing multiple
    parameters at the same time will prevent us from knowing the direct impact of
    each one.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在更改某些内容时，我们需要确保每次只进行单一修改，然后测试结果，而不是同时更改多个参数。同时更改多个参数会阻止我们了解每个参数的直接影响。
- en: Sometimes, when increasing the network size, we might stumble into a model that
    doesn't converge, meaning the loss function starts increasing again, which will
    result in a training error. That can be fixed by changing `learning_rate` or `clip_norm`.
    See the next section, *Fixing a model not converging*, for more information.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，当增加网络大小时，我们可能会遇到模型无法收敛的情况，这意味着损失函数开始再次增加，从而导致训练错误。通过更改`learning_rate`或`clip_norm`可以解决这个问题。有关更多信息，请参阅下一节，*修复无法收敛的模型*。
- en: Determining the batch size
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定批量大小
- en: We haven't talked about `batch_size` yet. The batch size is the amount of data
    the network will handle at once. A bigger batch size may improve the training
    time by making the model parameters converge faster. It also should remove some
    computational overhead from transferring a larger chunk of data to the GPU memory
    at once.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有讨论过`batch_size`。批量大小是网络一次处理的数据量。较大的批量大小可以通过使模型参数更快地收敛来提高训练时间。它还应该通过一次将更多数据传输到GPU内存中来减少一些计算开销。
- en: A rule of thumb is that when you increase the batch size, you'll also need to
    **increase the learning rate**. Since more data is taken into account at the same
    time, the model's weight can get updated using a bigger ratio.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经验法则是，当你增加批量大小时，你也需要**增加学习率**。由于一次处理的数据更多，模型的权重可以使用更大的比例进行更新。
- en: Increasing the batch size might improve training time, but it might as well
    **decrease the performance of the model**, so using a too big batch size might
    not be a good idea. Overall, the batch size is often a trade-off between execution
    time and the resulting quality of the model.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 增加批量大小可能会改善训练时间，但也可能**降低模型的性能**，因此使用过大的批量大小可能不是一个好主意。总的来说，批量大小通常是执行时间和模型质量之间的权衡。
- en: We provide more information on this in the last section, *Further reading*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在最后一节中提供了更多信息，*进一步阅读*。
- en: Fixing out of memory errors
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修复内存溢出错误
- en: 'Sometimes, when using a batch size or network size too big, you might end up
    with the following error:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，当使用过大的批量大小或网络大小时，你可能会遇到以下错误：
- en: '[PRE13]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Reduce the batch size and network size until the out of memory error disappears.
    Sometimes, the error is not fatal, in which case it will negatively impact the
    training performance.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 减小批量大小和网络大小，直到内存溢出错误消失。有时，错误并不致命，在这种情况下，它会对训练性能产生负面影响。
- en: Fixing a wrong network size
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修复错误的网络大小
- en: When using an existing run directory, either from continuing a previous training,
    starting an evaluation job, or starting a generation job, we need to provide the
    same network size as when it was first launched.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用现有的运行目录时，无论是继续先前的训练、启动评估作业，还是启动生成作业，我们都需要提供与首次启动时相同的网络大小。
- en: 'If the training run was first started using `rnn_layer_sizes=[256,256,256]`
    and then restarted using `rnn_layer_sizes=[128,128,128]`, we''ll end up with the
    following error:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果训练运行首次使用`rnn_layer_sizes=[256,256,256]`启动，然后使用`rnn_layer_sizes=[128,128,128]`重新启动，我们将遇到以下错误：
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this case, we'll need to use the network size that was first used when we
    started the training.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们需要使用我们在开始训练时使用的网络大小。
- en: Fixing a model not converging
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修复无法收敛的模型
- en: A model that converges is defined by a **decreasing loss function** on both
    the training and evaluation sets. If our loss function goes up at some point,
    the model is unstable and isn't properly converging. There are many reasons as
    to why a model might not converge.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛的模型由训练集和评估集上的**损失函数下降**定义。如果我们的损失函数在某个时刻上升，模型就不稳定，并且没有正确地收敛。模型无法收敛的原因有很多。
- en: 'Let''s take a simple example (this example uses the `jazz_drums` dataset we
    created in the previous chapter):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个简单的例子为例（这个例子使用了我们在上一章创建的`jazz_drums`数据集）：
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When a model is diverging, we might get an error at some point:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型发散时，我们可能会在某个时候遇到错误：
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The resulting TensorBoard graph will show the loss function going up. Let''s
    fix the problem by using a smaller learning rate. The default learning rate value
    that was used in the previous command is `learning_rate=0.001`, so we''ll make
    that 10 times smaller:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的TensorBoard图将显示损失函数的上升。让我们通过使用较小的学习率来解决这个问题。前一个命令中使用的默认学习率值是`learning_rate=0.001`，所以我们将其调整为原来值的十分之一：
- en: '[PRE17]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here is the resulting TensorBoard graph with both runs:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这是包含两次运行结果的TensorBoard图：
- en: '![](img/d4808a0e-2910-49a0-944b-25004a1a3f21.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4808a0e-2910-49a0-944b-25004a1a3f21.png)'
- en: You can see that `run1_diverge` has a loss function that goes up, and `run2_learning_rate` is
    training properly.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，`run1_diverge`的损失函数在不断增大，而`run2_learning_rate`正在正常训练。
- en: 'There are many ways of fixing a diverging model, but since the problem is dependent
    on the data and the network size, you''ll have to test various methods:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 修复发散模型的方法有很多，但由于问题依赖于数据和网络规模，你需要测试各种方法：
- en: Try **reducing the learning rate**, like in our previous example. Learning rate
    decay (available in the Music VAE model), where the learning rate is gradually
    reduced, can also help.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**降低学习率**，就像在我们之前的示例中一样。学习率衰减（在Music VAE模型中可用），即学习率逐渐降低，也能有所帮助。
- en: Try **changing the network size**. In this example, using a network size of
    `rnn_layer_sizes=[256,256,256]` will also fix the problem.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**更改网络规模**。在这个示例中，使用`rnn_layer_sizes=[256,256,256]`的网络规模也可以修复该问题。
- en: Try **decreasing the gradient clipping**. In our previous example, the gradient
    clipping default value is `clip_norm=3`, so you will want to decrease the `clip_norm`
    hyperparameter, for example, to `clip_norm=2`. Remember, default hyperparameter
    values are in the configurations for each model (see the previous section, *Creating
    a new configuration*, for more information on this).
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**减少梯度裁剪**。在我们之前的示例中，梯度裁剪的默认值是`clip_norm=3`，因此你可能需要减少`clip_norm`超参数的值，例如设置为`clip_norm=2`。记住，默认的超参数值会在每个模型的配置文件中（有关更多信息，请参见前一节，*创建新配置*）。
- en: Sometimes, fixing a diverging model will make another problem arise. For example,
    fixing the problem using a bigger network size might result in the network overfitting.
    Make sure you test multiple solutions so that the chosen one is best.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，修复一个发散的模型会引发另一个问题。例如，使用更大的网络规模来修复问题可能会导致网络过拟合。确保你测试多个解决方案，以便选择最合适的一个。
- en: Most often than not, the NaN loss during training error is caused by the exploding
    gradients problem we've already talked about in [Chapter 4](48023567-4100-492a-a28e-53b18a63e01e.xhtml),
    *Generating Polyphonic Melodies*. This problem is common in RNNs, and even if
    LSTM cells helps a lot to make the model converge, the exploding gradient problem
    can still occur, given the accumulation of gradients unrolled over hundreds of
    input time steps.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，NaN损失错误大多是由我们在[第4章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)中提到的梯度爆炸问题引起的，*生成多声部旋律*。这个问题在RNN中很常见，即使LSTM单元有助于模型的收敛，但由于在数百个输入时间步长上展开的梯度累积，梯度爆炸问题仍然可能发生。
- en: During training, the loss is calculated on the training examples, and then its
    derivative is backpropagated through the network, updating the weights by a fraction
    of the propagated error, this fraction being the learning rate. When the weights
    get updated over and over by large values, they tend to explode, or overflow,
    which is why using a smaller learning rate might fix the problem.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，损失函数会在训练示例上计算，然后其导数会通过网络反向传播，按照传播误差的一个比例更新权重，这个比例就是学习率。当权重被不断更新且更新值过大时，往往会导致爆炸或溢出，这也是为什么使用较小的学习率可能修复该问题。
- en: Gradient clipping has a similar effect but is useful if we prefer not changing
    the learning rate. By using gradient clipping, we can rescale, or clip to a maximum
    value, the gradient vector (the error derivative) that will be backpropagated
    through the network. The parameter we have available in Magenta is `clip_norm`,
    which is used by TensorFlow as `tf.clip_by_norm(t, clip_norm)`. By decreasing
    the parameter's value, we effectively normalize the error gradient so that the
    norm is equal or less than the provided value.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度裁剪有类似的效果，但如果我们不想改变学习率，它仍然是有用的。通过使用梯度裁剪，我们可以重新调整或裁剪梯度向量（即误差导数）的最大值，该梯度会通过网络反向传播。在Magenta中，我们提供了`clip_norm`参数，它在TensorFlow中被用作`tf.clip_by_norm(t,
    clip_norm)`。通过减少参数的值，我们有效地对误差梯度进行归一化，使得其范数小于或等于提供的值。
- en: Fixing not enough training data
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修复不足的训练数据
- en: 'Let''s now train the Melody RNN model using our previous chapter''s jazz piano
    dataset:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用上一章的爵士钢琴数据集来训练Melody RNN模型：
- en: 'We first create the dataset using the `attention_rnn` configuration. In the
    `training` folder, create and change the directory to a new folder called `melody_rnn_jazz_piano`,
    and execute (replacing `PATH_TO_NOTE_SEQUENCES` with the proper file, which should
    be in your `datasets` folder):'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先使用`attention_rnn`配置创建数据集。在`training`文件夹中，创建并切换到一个名为`melody_rnn_jazz_piano`的新文件夹，然后执行（将`PATH_TO_NOTE_SEQUENCES`替换为适当的文件路径，文件应该在你的`datasets`文件夹中）：
- en: '[PRE18]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We then train the model using the following:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用以下内容训练模型：
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'When checked in TensorFlow, we can look at the `run1_few_data` run:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中查看时，我们可以查看`run1_few_data`的运行情况：
- en: '![](img/974cbacb-aadb-44c5-afc9-130d1afdc52c.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/974cbacb-aadb-44c5-afc9-130d1afdc52c.png)'
- en: In the **loss** diagram, the first two lines at the top are the train and evaluation
    metrics for the run, `run1_few_data`. The evaluation loss goes up, meaning the
    model is overfitting really fast. This is because we don't have a lot of data
    (659 outputs to be exact).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在**损失**图中，顶部的前两条线是`run1_few_data`运行的训练和评估指标。评估损失值上升，意味着模型在快速过拟合。这是因为我们没有很多数据（确切地说是659个输出）。
- en: Fixing this problem requires us to go back to preparing the data. For the `run2_more_data` run,
    in the loss diagram, the two lowest curves show us that the problem is fixed.
    To get more data, we came back to the pipeline from the previous chapter, `melody_rnn_pipeline_example.py`,
    and changed `ignore_polyphonic_notes=False` to `True` in the `MelodyExtractor`
    pipeline. This means that, instead of throwing out polyphonic melodies, the pipeline
    converts them into a monophonic one, keeping the highest note. The conversion
    method is in the `melodies_lib` module, so if we want to change that behavior,
    we'll have to write our own pipeline.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题需要我们回到数据准备步骤。对于`run2_more_data`运行，在损失图中，最底部的两条曲线表明问题已经解决。为了获取更多的数据，我们回到上一章的管道`melody_rnn_pipeline_example.py`，并将`MelodyExtractor`管道中的`ignore_polyphonic_notes=False`更改为`True`。这意味着，管道不再丢弃多声部旋律，而是将其转换为单声部旋律，保留最高的音符。转换方法在`melodies_lib`模块中，如果我们想改变这个行为，就必须编写我们自己的管道。
- en: 'Because this change modifies the musical content of our dataset, we''ll need
    to carefully listen to the generated results, to verify that the trained model
    outputs interesting samples. Here is a generated sample from the `run2_more_data` trained
    model:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个变化修改了我们数据集中的音乐内容，我们需要仔细听生成的结果，以验证训练好的模型是否输出有趣的样本。以下是来自`run2_more_data`训练模型的生成样本：
- en: '![](img/2bd8188d-e618-42bd-8cca-e7a60ff35b15.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bd8188d-e618-42bd-8cca-e7a60ff35b15.png)'
- en: This example is a good example of the necessity of going back and forth between
    the data preparation step and the training step. See the next section, *Generating
    sequences from a trained model*, for more information on how to generate sequences
    from a trained model.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子很好地说明了在数据准备步骤和训练步骤之间反复切换的重要性。请参阅下一节，*从训练好的模型生成序列*，以获取更多关于如何从训练模型生成序列的信息。
- en: Configuring attention and other hyperparameters
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置注意力和其他超参数
- en: The Melody RNN model uses attention during training to look at previous steps
    (see [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml), *Generating Polyphonic
    Melodies*, for a refresher on that). You can use the `attn_length` hyperparameter to
    configure the length of the attention spawn.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Melody RNN模型在训练时使用注意力机制查看前面的步骤（有关此内容的回顾，请参见[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)，*生成多声部旋律*）。你可以使用`attn_length`超参数来配置注意力范围的长度。
- en: Each model has its own configuration. Make sure you check them out in their
    respective configuration files to see what parameter you can tune during training.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型都有自己的配置。确保查看它们各自的配置文件，了解在训练过程中可以调整的参数。
- en: Generating sequences from a trained model
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从训练好的模型生成序列
- en: Now that we have a trained model, `run1_small`, and we understand that it slightly
    overfits, let's try and generate a sequence out of it to see how it goes. To generate
    a sequence when the network has finished training or during training, we can use
    the model's `generate` command.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个训练好的模型`run1_small`，并且知道它稍微出现了过拟合，接下来我们来尝试从它生成一个序列，看看结果如何。要在网络训练完成后或训练过程中生成序列，我们可以使用模型的`generate`命令。
- en: 'Let''s call the `drums_rnn_generate` method using the following parameters
    (if you are launching this command during training and you are using a GPU, don''t
    forget to use `CUDA_VISIBLE_DEVICES=""`):'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来使用以下参数调用`drums_rnn_generate`方法（如果你在训练过程中启动此命令并且使用GPU，请记得使用`CUDA_VISIBLE_DEVICES=""`）：
- en: '[PRE20]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The `generate` command will take the latest checkpoint in the run directory
    and use it to generate a sequence. We need to use the same network size as for
    the training phase.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`generate`命令将会获取运行目录中的最新检查点，并用它生成一个序列。我们需要使用与训练阶段相同的网络大小。'
- en: 'Here is a generated sequence from our training phase:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们训练阶段生成的一个序列：
- en: '![](img/be288cd0-828d-4787-87b0-3c039172c22f.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be288cd0-828d-4787-87b0-3c039172c22f.png)'
- en: The model should have generated 10 sequences; we should listen to hear what
    it sounds like. Congratulations! You've heard the first notes of your own generated
    model.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 模型应该已经生成了10个序列；我们应该听一听它的声音是什么样的。恭喜！你已经听到了自己生成模型的第一音符。
- en: 'The advantage of using the `dance` dataset is that it is easy to verify that
    the training model is generating what we expected: in the resulting 10 sequences,
    each of them mostly has a bass drum on beat. Now, we need to ask ourselves whether
    the resulting generation is diverse and interesting. If not, we should go back
    to prepare a new dataset and iterate on it.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`dance`数据集的好处在于，可以轻松验证训练模型是否生成了我们预期的内容：在生成的10个序列中，每个序列基本上都有一个低音鼓在节拍上。现在，我们需要问自己，生成的结果是否具有多样性和趣味性。如果没有，我们应该回去准备一个新的数据集并进行迭代。
- en: Using a specific checkpoint to implement early stops
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用特定的检查点实现提前停止
- en: We previously talked about early stopping, which is the action of stopping training
    at the optimum, instead of letting the model degrade further, as a way to prevent
    overfitting. There are multiple ways of doing that, such as coding a stop condition
    that checks whether the evaluation loss function starts going up, but the easiest
    approach is to keep only the checkpoint that is nearest to the optimum after the
    training phase is over.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过提前停止，这是在最优点停止训练的操作，而不是让模型进一步退化，以防止过拟合。有多种方式可以做到这一点，比如编写一个停止条件，检查评估损失函数是否开始上升，但最简单的方法是在训练阶段结束后仅保留距离最优点最近的检查点。
- en: 'Going back to our previous example, we find the evaluation loss curve minimum
    to be at around 7,000 steps. In the `logdir/run1_small` directory, we find that
    we have a checkpoint near our optimum that we can use: `model.**ckpt-6745**.data-00000.`'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 回到之前的例子，我们发现评估损失曲线的最小值大约在7000步时。在`logdir/run1_small`目录中，我们发现一个接近最优的检查点可以使用：`model.**ckpt-6745**.data-00000`。
- en: 'To use that checkpoint, we need to use the `--checkpoint_file` flag instead
    of the `--run_dir` flag:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用该检查点，我们需要使用`--checkpoint_file`标志，而不是`--run_dir`标志：
- en: '[PRE21]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Notice we don't pass the full filename (only `model.ckpt-6745` and not `model.ckpt-6745.data-00000-of-00001`)
    because TensorFlow expects only the first part. The command should generate 10
    new elements using that checkpoint.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们没有传递完整的文件名（只使用`model.ckpt-6745`，而不是`model.ckpt-6745.data-00000-of-00001`），因为TensorFlow只需要传递文件名的第一部分。该命令应该使用该检查点生成10个新的元素。
- en: Packaging and distributing the result using bundles
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用捆绑包打包并分发结果
- en: 'When we are satisfied with our trained model, we can package it using Magenta''s
    bundle for distribution. Remember that bundles are available for RNN models only,
    but we''ll provide ways of bundling other models such as Music VAE when we get
    there. Follow these steps:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对训练好的模型感到满意时，可以使用Magenta的捆绑包进行打包以供分发。记住，捆绑包仅适用于RNN模型，但我们将在后面提供将其他模型（如Music
    VAE）打包的方法。按照以下步骤操作：
- en: 'To package a bundle, we call the generate command using the `--bundle_file`
    and `--save_generator_bundle` flags:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要打包一个捆绑包，我们使用`--bundle_file`和`--save_generator_bundle`标志调用生成命令：
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This will save the bundle in the `drums_rnn_dance_small.mag` file using the
    latest checkpoint. We can also use the `--checkpoint_file` flag from the previous
    command if we need another checkpoint that is not the latest.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使用最新的检查点将捆绑包保存在`drums_rnn_dance_small.mag`文件中。如果我们需要另一个不是最新的检查点，可以使用之前命令中的`--checkpoint_file`标志。
- en: 'We can now use the bundle as follows:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以按如下方式使用捆绑包：
- en: '[PRE23]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Notice how the hyperparameters are left out—this is because they are configured
    in the bundle file. This also means the bundle hyperparameters overrides the ones
    configured in the `drum_kit` configuration.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 注意超参数是被省略的——这是因为它们已在捆绑包文件中配置。这也意味着捆绑包中的超参数将覆盖在`drum_kit`配置中的设置。
- en: Now that we have our first model trained, tuned, and packaged, we'll have a
    look at training other models.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练、调优并打包了第一个模型，我们将继续看看如何训练其他模型。
- en: Training MusicVAE
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练MusicVAE
- en: Let's now train the MusicVAE model so that we can compare the sampling with
    an RNN generation. One thing that differs for the MusicVAE training is that the
    data preparation step (the `create dataset` command) doesn't exist because the
    data conversion is made right before the model starts training. We'll manually
    create the dataset using a pipeline and then start the training.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们训练MusicVAE模型，以便可以将采样与RNN生成进行比较。MusicVAE训练的一个不同之处在于，数据准备步骤（`create dataset`命令）不存在，因为数据转换是在模型开始训练之前完成的。我们将手动使用管道创建数据集，然后开始训练。
- en: Splitting the dataset into evaluation and training sets
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据集拆分为评估集和训练集
- en: Since there is no dataset creation command but we still need to split the dataset
    into training and evaluation data, we're going to write a pipeline to do that.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有创建数据集的命令，但我们仍然需要将数据集拆分为训练数据和评估数据，因此我们将编写一个管道来完成此操作。
- en: You can find this code in the `chapter_07_example_02.py` file in the source
    code of this chapter. There are more comments and content in the source code,
    so you should go check it out.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的`chapter_07_example_02.py`文件中找到这段代码。源代码中有更多的注释和内容，建议你去查看一下。
- en: 'We''ll also convert the note sequences into tensors, which will help us to
    validate the data before we start the training:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将把笔记序列转换为张量，这将帮助我们在开始训练之前验证数据：
- en: 'First, let''s write the `partition` method that will split the dataset into
    training and evaluation data:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们编写`partition`方法，将数据集拆分为训练数据和评估数据：
- en: '[PRE24]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We've already seen similar code in the previous chapter; we are actually reusing
    the `RandomPartition` class we've already covered, which will split the input
    into two sets using a given ratio.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一章已经看到过类似的代码；我们实际上是在重复使用我们之前讲解过的`RandomPartition`类，该类将使用给定的比例将输入拆分为两个集合。
- en: 'Then, let''s write the `TensorValidator` class:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，让我们编写`TensorValidator`类：
- en: '[PRE25]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: What is interesting here is that we are using the configuration to find the
    data converter (drums conversion, melody conversion, and so on) and then converting
    into tensors, a step that will be done before the model starts training. This
    step validates our input data and can help us to make statistics about the number
    of "valid" tensors as well as how much data we have. Unfortunately, the fact that
    we don't have a "create dataset" command makes it harder for us to know exactly
    what kind of data will be fed to the network, which is why this class is useful.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有趣的是，我们使用配置来找到数据转换器（鼓转换、旋律转换等），然后将其转换为张量，这个步骤会在模型开始训练之前完成。这个步骤验证了我们的输入数据，并可以帮助我们统计“有效”张量的数量以及我们有多少数据。不幸的是，由于没有“创建数据集”的命令，我们很难准确知道将被馈送到网络的数据类型，这就是这个类有用的原因。
- en: 'Finally, we''ll call the `partition` method and declare some flags for the
    command line:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将调用`partition`方法并声明一些命令行标志：
- en: '[PRE26]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, let''s create a new training directory and then call our new Python script
    (replacing `PATH_TO_PYTHON_SCRIPT` and `PATH_TO_DATASET_TFRECORDS` with proper
    values):'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个新的训练目录，然后调用我们的Python脚本（将`PATH_TO_PYTHON_SCRIPT`和`PATH_TO_DATASET_TFRECORDS`替换为正确的值）：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This will create a `sequence_examples` directory containing the `eval.tfrecords` and
    `train.tfrecords` datasets.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为`sequence_examples`的目录，其中包含`eval.tfrecords`和`train.tfrecords`数据集。
- en: Launching the training and evaluation
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动训练和评估
- en: Now that we have validated our data and split it into two datasets, we can start
    the training.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经验证了数据并将其拆分为两个数据集，我们可以开始训练了。
- en: 'Launching the training, evaluation, and TensorBoard is similar to the previous
    sections:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 启动训练、评估和TensorBoard与前面的章节类似：
- en: '[PRE28]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Like for the previous models, you can pass hyperparameters using the `--hparams=FLAGS`
    flag. Here, we are using the "small" configuration since MusicVAE models can get
    big in terms of size pretty fast. A small model is enough for good performance,
    for example, the Magenta pre-trained drum model uses the `cat-drums_2bar_small` configuration.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的模型一样，你可以使用`--hparams=FLAGS`标志传递超参数。在这里，我们使用的是“小型”配置，因为MusicVAE模型的大小增长得很快。一个小型模型就足够提供良好的性能。例如，Magenta预训练的鼓模型使用的是`cat-drums_2bar_small`配置。
- en: 'When training Music VAE, we''ll also want to tune the following two hyperparameters:
    `free_bits` and `max_beta`. By increasing `free_bits` or decreasing `max_beta`,
    we are decreasing the effect of the KL loss, resulting in a model that is better
    at reconstruction, with potentially worse random samples. See the previous chapter,
    [Chapter 4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml), *Latent Space Interpolation
    with MusicVAE*, if you don''t remember how **Kulback-Leibler** (**KL**) divergence
    affects the model performance.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练Music VAE时，我们还需要调整以下两个超参数：`free_bits`和`max_beta`。通过增加`free_bits`或减少`max_beta`，我们减少了KL损失的影响，从而得到一个在重建上表现更好的模型，但随机样本可能会变差。如果你不记得**Kulback-Leibler**（**KL**）散度如何影响模型性能，可以查看前一章，[第4章](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml)，*使用MusicVAE进行潜在空间插值*。
- en: Distributing a trained model
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分发训练好的模型
- en: 'Unfortunately, for MusicVAE, we cannot create a Magenta bundle. The simplest
    way to distribute a TensorFlow checkpoint is to copy the checkpoint files and
    zip them for the transfer:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，对于 MusicVAE，我们无法创建一个 Magenta 包。分发 TensorFlow 检查点的最简单方法是复制检查点文件并将其压缩以便传输：
- en: 'First, let''s copy the corresponding files (replace `STEP` with the checkpoint
    step you want to keep):'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们复制相应的文件（将 `STEP` 替换为你想保留的检查点步骤）：
- en: '[PRE29]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You should now have three files in the `complete/cat-drums_2bar_small` directory.
    Remember, TensorFlow checkpoints should be loaded using their prefix, for example, `model.ckpt-157780`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该在 `complete/cat-drums_2bar_small` 目录中有三个文件。记住，TensorFlow 检查点应该使用其前缀加载，例如
    `model.ckpt-157780`。
- en: 'Enter the following to use the checkpoint in a generation (replace `STEP` with
    the checkpoint you want to use):'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下内容以在生成中使用检查点（将 `STEP` 替换为你想要使用的检查点）：
- en: '[PRE30]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Remember that checkpoints do not contain information about the changes you've
    made to the hyperparameters (unlike Magenta bundles), so you'll need to pass the
    same hyperparameters you've used during training each time you use it.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，检查点不包含关于你对超参数所做的更改的信息（与 Magenta 包不同），因此每次使用时，你需要传递训练时使用的相同超参数。
- en: Some hyperparameters can be changed. For example, there is no sense in using
    a batch size of 512 when you are sampling (unless you are sampling 512 sequences
    at once, perhaps), but it could be the value you've used for training.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一些超参数是可以更改的。例如，使用 512 的批量大小进行采样是没有意义的（除非你一次采样 512 个序列），但这可能是你在训练时使用的值。
- en: You will want to keep everything related to the TensorFlow graph, which means
    the network size and anything related to encoding and decoding.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要保持与 TensorFlow 图相关的所有内容，包括网络大小以及与编码和解码相关的任何内容。
- en: Creating a configuration for this specific training is probably the easiest
    way of keeping track of the hyperparameters that were used.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 为这个特定训练创建配置可能是跟踪所使用超参数的最简单方法。
- en: Training other models
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练其他模型
- en: We won't be training every model here, but training other models should be fairly
    similar to the one we've shown. The same model tuning, regarding overfitting,
    for example, can be applied to other models. Refer to the README files of the
    model you want to train for more information.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会在这里训练所有模型，但训练其他模型应该与我们展示的相似。针对过拟合的相同模型调优可以应用到其他模型上。请参考你想要训练的模型的 README 文件以获取更多信息。
- en: Using Google Cloud Platform
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Google Cloud Platform
- en: 'Using a cloud computing provider is useful to offload computing to faster machines.
    It can also be used if we want to make multiple runs at the same time. For example,
    we could try fixing exploding gradients by launching two runs: one with a lower
    learning rate and one with a lower gradient clipping. We could spawn two different
    VMs, each training its own model, and see which performs better.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用云计算服务提供商可以将计算任务转移到更快的机器上，这非常有用。如果我们希望同时进行多次运行，也可以使用云计算。例如，我们可以通过启动两个运行来尝试修复梯度爆炸：一个使用较低的学习率，另一个使用较低的梯度裁剪。我们可以启动两个不同的虚拟机，每个训练自己的模型，然后比较哪个表现更好。
- en: We are going to use Google Cloud Platform (GCP), but other cloud providers,
    such as Amazon AWS or Microsoft Azure, will also work. We'll go through the different
    steps needed to train a Melody RNN model on the piano jazz dataset from the previous
    chapter, including the GCP account configuration and VM instance creation.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Google Cloud Platform（GCP），但其他云服务提供商，如 Amazon AWS 或 Microsoft Azure，也可以使用。我们将介绍训练上一章中的钢琴爵士乐数据集的
    Melody RNN 模型所需的不同步骤，包括 GCP 账户配置和虚拟机实例创建。
- en: Creating and configuring an account
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和配置一个账户
- en: 'First, head to [console.cloud.google.com](https://console.cloud.google.com)
    and create a new Google account (or use an existing one). Once in GCP, follow
    these steps:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，访问 [console.cloud.google.com](https://console.cloud.google.com)，并创建一个新的 Google
    账户（或使用现有账户）。进入 GCP 后，按照以下步骤操作：
- en: If this is your first time logging in, you will need to create a new project,
    which you can call `Magenta`. If not, find your current project at the top of
    the screen, and create a new one if you want.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果这是你第一次登录，你需要创建一个新的项目，可以命名为 `Magenta`。如果不是，找到屏幕顶部当前的项目，如果需要可以创建一个新的项目。
- en: Then, we'll need to set up quotas, since when a new account is created, it cannot
    create VM instances with GPUs. On the left, go to **IAM & Admin** > **Quotas**,
    and find the **GPUs (all regions)** quotas by searching `GPU` in the **Metrics**
    field. Click on the checkbox, then **Edit**, and change the quota to another value,
    like 5\. The quota modification will take a bit of time to get validated.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要设置配额，因为新账户创建时，默认不能创建带GPU的虚拟机实例。在左侧，进入**IAM与管理员** > **配额**，并通过在**指标**字段中搜索`GPU`来找到**GPU（所有区域）**的配额。勾选框后，点击**编辑**，并将配额更改为其他值，如5。配额修改需要一些时间才能验证通过。
- en: Finally, we'll need to set up billing. On the left, go to **Billing** and then
    follow the instructions to add a **Billing Account**.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要设置结算。在左侧，进入**结算**，然后按照提示添加**结算账户**。
- en: Our account being properly setup, we can now create a new VM instance.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 账户设置完成后，我们可以创建一个新的虚拟机实例。
- en: Preparing an SSH key (optional)
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备SSH密钥（可选）
- en: Using an SSH key is useful to connect to the VM instance from a local Terminal.
    This is an optional step since, in GCP, you can connect to the VM instance using
    a Terminal in a browser, which works pretty well, but with really slow upload
    and download speeds.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SSH密钥有助于通过本地终端连接到虚拟机实例。这是一个可选步骤，因为在GCP中，你也可以使用浏览器中的终端连接虚拟机实例，虽然这种方式很有效，但上传和下载速度非常慢。
- en: If you already have an SSH key ready, you can skip this step. If you are unsure,
    check the file at `~/.ssh/id_rsa.pub`.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经有了SSH密钥，可以跳过此步骤。如果不确定，请检查`~/.ssh/id_rsa.pub`文件。
- en: 'On Linux and macOS, you can generate a new SSH key by entering the following
    in a Terminal:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux和macOS上，你可以通过在终端中输入以下命令生成新的SSH密钥：
- en: '[PRE31]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This will save a key in `~/.ssh/id_rsa.pub`. On Windows, the easiest way to
    do this is to install Git Bash ([git-scm.com/download/win](https://git-scm.com/download/win)),
    which contains two commands we'll use—`ssh-keygen` and `scp`, which we'll be using
    in the next sections.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在`~/.ssh/id_rsa.pub`中保存一个密钥。在Windows上，最简单的方法是安装Git Bash（[git-scm.com/download/win](https://git-scm.com/download/win)），它包含我们将使用的两个命令——`ssh-keygen`和`scp`，我们将在接下来的部分中使用这些命令。
- en: 'Once generated, the public key looks like this:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 生成后，公钥看起来是这样的：
- en: '[PRE32]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `user` part before the host is important since it will be the user to provide
    to GCP when you log in.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 主机前面的`user`部分很重要，因为它将在登录时作为提供给GCP的用户。
- en: Creating a VM instance from a Tensforflow image
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从TensorFlow镜像创建虚拟机实例
- en: 'Now, we return to GCP then, on the menu on the left, we go to **Compute Engine**:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们返回到GCP，在左侧菜单中，进入**计算引擎**：
- en: Once in **Compute** **Engine**, choose **I****mages** from the left menu.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入**计算引擎**，从左侧菜单中选择**镜像**。
- en: In the **Filter Images** search, type `TensorFlow` and find the most recent
    image. At the time of writing, the image is called **c3-deeplearning-tf-1-15-cu100-20191112**.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**筛选镜像**搜索框中，输入`TensorFlow`并找到最新的镜像。在撰写本文时，该镜像名为**c3-deeplearning-tf-1-15-cu100-20191112**。
- en: 'Choose the image and then choose **Create instance**; you will see the create
    instance screen:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择镜像后，点击**创建实例**；你将看到创建实例的界面：
- en: '![](img/155d37d9-c178-45eb-9bb5-ccfcc9e69c28.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](img/155d37d9-c178-45eb-9bb5-ccfcc9e69c28.png)'
- en: 'We''ll now fill the information as in the preceding diagram:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将根据前面的示意图填写信息：
- en: In **Name**, use `Magenta`.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**名称**中，使用`Magenta`。
- en: In **Region** and **Zone**, find a place that is near you.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**区域**和**区域**中，选择一个靠近你的地方。
- en: In **Machine** **Type**, use at least **n1-standard-4**, a 4 core CPU with 15
    GB of RAM.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**机器类型**中，选择至少**n1-standard-4**，即配备4核CPU和15GB内存的配置。
- en: In **CPU platform and GPU**, click on **Add GPU** and choose a **GPU type**,
    using at least an **NVIDIA Tesla K80**.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**CPU平台和GPU**中，点击**添加GPU**，并选择至少一款**NVIDIA Tesla K80** GPU。
- en: Depending on the chosen region and the current availability, you'll have different
    GPUs available. The NVIDIA Tesla K80 GPUs have an average computing power (0.45
    global step/second on Melody RNN) and the P100 GPUs are almost twice as powerful
    (0.75 global step/second on Melody RNN). As a comparison, an entry-level gaming
    GPU such as the RTX 2060 makes 0.6 global step/second on Melody RNN.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 根据选择的区域和当前的可用性，你将看到不同的GPU可供选择。NVIDIA Tesla K80 GPU的计算能力平均为（Melody RNN上为0.45全球步长/秒），而P100
    GPU的计算能力几乎是其两倍（Melody RNN上为0.75全球步长/秒）。作为比较，入门级游戏GPU如RTX 2060，在Melody RNN上每秒可处理0.6全球步长。
- en: 'Now, let''s go on to the disk content:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来处理磁盘内容：
- en: '![](img/95410c03-38bb-410c-a776-1663a11e0a93.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95410c03-38bb-410c-a776-1663a11e0a93.png)'
- en: 'We will initialize the instance using the following steps:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤初始化实例：
- en: The boot disk should be already filled with a **Deep Learning Image** of 50
    GB.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动磁盘应该已经填充了 **深度学习镜像**，大小为 50 GB。
- en: After expanding the **Management, security, disks, networking, sole tenancy**
    section, in the **Security** tab, paste your public SSH key (if you have one).
    The resulting user (in this case, **user**) will be shown on the left.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在展开 **管理、安全、磁盘、网络、单独租用** 部分后，在 **安全** 标签中粘贴你的公钥 SSH 密钥（如果有的话）。结果用户（在此例中为 **user**）将显示在左侧。
- en: Check the resulting price in the upper-right corner, which is **about $1.269
    hourly** for this machine. Note that we are billed for the machine uptime. If
    we don't use the machine, we won't be billed for it, so we'll need to close it
    when we are finished.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查右上角显示的价格，大约是**每小时 1.269 美元**。请注意，我们按机器的运行时间收费。如果不使用该机器，我们将不会被收费，所以完成后我们需要关闭它。
- en: Click on **Create**.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **创建**。
- en: In the **VM instances** menu on the left, you should see the newly created VM.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧的 **虚拟机实例** 菜单中，你应该能看到新创建的虚拟机。
- en: Initializing the VM
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化虚拟机（VM）
- en: Now that we have a new VM to work with, we need to install all of the required
    software. We can refer to [Chapter 1](c5602f6c-c094-42f2-936f-98746cf04a49.xhtml),
    *Introduction on Magenta and Generative Art*, for the detailed installation instructions,
    but we'll also put the main commands here.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个新的虚拟机来工作，我们需要安装所有必需的软件。我们可以参考 [第 1 章](c5602f6c-c094-42f2-936f-98746cf04a49.xhtml)，*Magenta
    和生成艺术的介绍*，以获取详细的安装说明，但我们也会在这里提供主要命令。
- en: Installing the NVIDIA CUDA drivers
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 NVIDIA CUDA 驱动程序
- en: 'Fortunately, the VM image we are using does a lot of the installation for us.
    Let''s first connect and install the required drivers:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们使用的虚拟机镜像为我们做了很多安装工作。首先，让我们连接并安装所需的驱动程序：
- en: 'First, we need to connect to the VM. If we don''t have an SSH key, we use the
    **SSH** button on the right of the VM instance, which should start a new browser
    Terminal. If we have an SSH key, we can use the following command, on Linux, macOS,
    and Windows (using Git Bash):'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要连接到虚拟机。如果没有 SSH 密钥，我们可以使用虚拟机实例右侧的 **SSH** 按钮，启动新的浏览器终端。如果有 SSH 密钥，我们可以使用以下命令，适用于
    Linux、macOS 和 Windows（使用 Git Bash）：
- en: '[PRE33]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, we have to replace `USER` with the user in our SSH key and `IP` with the
    external IP shown in the VM instance page.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们需要将 `USER` 替换为我们 SSH 密钥中的用户，并将 `IP` 替换为虚拟机实例页面中显示的外部 IP。
- en: 'The VM will greet us with the following message, which we answer with `y`:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚拟机会用以下消息问候我们，我们需要回答`y`：
- en: '[PRE34]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The NVIDIA drivers (CUDA drivers and cuDNN), in the proper versions for TensorFlow,
    should get installed. Unfortunately, there is a problem with the cuDNN versions,
    so we'll have to manually reinstall it.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA 驱动程序（CUDA 驱动程序和 cuDNN），以及适用于 TensorFlow 的正确版本应该已经安装。不幸的是，cuDNN 版本存在问题，我们将需要手动重新安装它。
- en: Download the latest cuDNN a.b.c for CUDA 10.0 at [developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download)
    (download the full cuDNN Library) on your local machine.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 [developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download)
    下载适用于 CUDA 10.0 的最新 cuDNN a.b.c（下载完整的 cuDNN 库）到本地机器。
- en: 'Transfer the cuDNN archive to the VM instance. If we don''t have an SSH key,
    we will use the interface to transfer the file (in the upper-right corner). If
    we have an SSH key, we use our Terminal:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 cuDNN 归档文件传输到虚拟机实例。如果没有 SSH 密钥，我们将使用界面来传输文件（在右上角）。如果有 SSH 密钥，我们可以使用终端：
- en: '[PRE35]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We'll have to replace `PATH_TO_CUDNN_ARCHIVE`, `USER`, and `IP` with proper
    values. The archive should now be in our home directory in the VM instance.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将 `PATH_TO_CUDNN_ARCHIVE`、`USER` 和 `IP` 替换为适当的值。归档文件现在应该位于虚拟机实例的主目录中。
- en: 'Now, log in to the machine using SSH (we don''t have to do this if we are using
    the browser Terminal):'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 SSH 登录到机器（如果使用浏览器终端，我们无需执行此操作）：
- en: '[PRE36]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We'll have to replace `USER` and `IP` with proper values.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将 `USER` 和 `IP` 替换为适当的值。
- en: 'Extract the archive:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压归档文件：
- en: '[PRE37]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We'll have to replace `CUDNN_ARCHIVE_NAME` with the archive name.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将`CUDNN_ARCHIVE_NAME`替换为归档文件的名称。
- en: 'Now let''s override the current cuDNN installation with the new versions:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们用新版本覆盖当前的 cuDNN 安装：
- en: '[PRE38]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Now that we have the CUDA drivers with the proper versions up and running, let's
    install the prerequisite software and Magenta GPU.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功安装了正确版本的 CUDA 驱动程序，接下来让我们安装所需的软件和 Magenta GPU。
- en: Installing Magenta GPU
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Magenta GPU
- en: 'Some packages are not installed by default on this image, so we''ll have to
    install them manually:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 该镜像默认未安装某些软件包，因此我们需要手动安装它们：
- en: 'First, we''ll install some audio dependencies:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将安装一些音频依赖项：
- en: '[PRE39]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Then, we''ll install Miniconda ([docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html))
    and create a new environment:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将安装 Miniconda（[docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)）并创建一个新的环境：
- en: '[PRE40]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, let''s install the Magenta GPU:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们安装 Magenta GPU：
- en: '[PRE41]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We are now good to go, so let's start a training job on our new VM instance.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始了，所以让我们在新的虚拟机实例上启动训练作业。
- en: Launching the training
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动训练
- en: 'To start the training, we''ll need to first transfer the dataset to the VM
    instance:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始训练，我们首先需要将数据集传输到虚拟机实例：
- en: 'To transfer a dataset to the VM instance, first zip it, and then use the Terminal
    browser interface to upload it if you aren''t using an SSH key. If you are using
    an SSH key, you can use `scp` to do that:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将数据集传输到虚拟机实例，首先压缩它，如果你没有使用 SSH 密钥，则可以通过终端浏览器界面上传它。如果你正在使用 SSH 密钥，则可以使用 `scp`
    来完成：
- en: '[PRE42]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: We'll have to replace `PATH_TO_DATASET`, `USER`, and `IP` with proper values.
    The archive should now be in our home directory in the VM instance.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将 `PATH_TO_DATASET`、`USER` 和 `IP` 替换为合适的值。现在，压缩包应该已经在我们的虚拟机实例的主目录中了。
- en: 'Once uploaded, we unzip the archive, and then we start the training process
    as we would on a local machine, for example, for the Melody RNN model:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传后，我们解压缩该压缩包，然后像在本地机器上一样开始训练过程，例如，训练 Melody RNN 模型：
- en: '[PRE43]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We'll have to replace `PATH_TO_NOTE_SEQUENCE_TFRECORDS` with a proper value.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将 `PATH_TO_NOTE_SEQUENCE_TFRECORDS` 替换为合适的值。
- en: 'To start the evaluation, we have to start a new Terminal; SSH again on the
    VM instance, and then we can launch the evaluation:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始评估，我们需要启动一个新的终端；再次通过 SSH 连接到虚拟机实例，然后我们可以启动评估：
- en: '[PRE44]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We can also see TensorBoard by using connection-forwarding in SSH. In a new
    Terminal, use the following command to connect to the VM instance:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以通过 SSH 使用连接转发来查看 TensorBoard。在新的终端中，使用以下命令连接到虚拟机实例：
- en: '[PRE45]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: We'll have to replace `USER` and `IP` with proper values. This command redirects
    the local port `16006` to port `6006` in the VM instance.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将 `USER` 和 `IP` 替换为合适的值。此命令将本地端口 `16006` 转发到虚拟机实例中的 `6006` 端口。
- en: 'Then, in the previous Terminal, we can launch TensorBoard:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在之前的终端中，我们可以启动 TensorBoard：
- en: '[PRE46]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The TensorBoard can be opened locally by using the `127.0.0.1:16006` address
    in the browser. Once the training is finished, we can zip the training folder
    on the VM instance, and then get it back using `scp` or the browser Terminal.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 可以通过在浏览器中使用 `127.0.0.1:16006` 地址本地打开。一旦训练完成，我们可以压缩虚拟机实例上的训练文件夹，然后使用
    `scp` 或浏览器终端将其获取回来。
- en: Once this is finished, don't forget to **stop the running instance**. Remember,
    we are billed on usage on GCP; we don't want to keep our VM instance running without
    a reason.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，别忘了**停止运行的实例**。记住，我们在 GCP 上是按使用情况收费的，我们不想在没有理由的情况下让虚拟机实例持续运行。
- en: At the time of writing, the cost of training a Melody RNN model for 20,000 steps
    on a P100 GPU is around $5.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在写本文时，使用 P100 GPU 训练 Melody RNN 模型 20,000 步的费用大约是 $5。
- en: Summary
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we used the datasets that we prepared in the previous chapter
    to train the Magenta models on different instruments and genres. We first compared
    different models and configurations for specific use cases and then showed how
    to create a new one if necessary.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了在上一章中准备的数据集，训练了 Magenta 模型，涵盖了不同的乐器和风格。我们首先比较了不同模型和配置的适用性，然后展示了如何在必要时创建一个新的模型。
- en: Then, we launched different training runs and looked at how to tune the model
    for better training. We showed how to launch the training and evaluation jobs
    and how to check the resulting metrics on the TensorBoard. Then, we saw a case
    of overfitting and explained how to fix overfitting and underfitting. We also
    showed how to define the proper network size and hyperparameters, by looking at
    problems such as incorrect batch size, memory errors, a model not converging,
    and not having enough training data. Using our newly trained model, we've generated
    sequences and showed how to package and handle checkpoints.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们启动了不同的训练任务，并查看了如何调优模型以获得更好的训练效果。我们展示了如何启动训练和评估作业，并在 TensorBoard 上检查结果指标。接着，我们观察到了过拟合的情况，并解释了如何解决过拟合和欠拟合问题。我们还展示了如何定义合适的网络大小和超参数，解决诸如不正确的批处理大小、内存错误、模型未收敛以及训练数据不足等问题。使用我们新训练的模型，我们生成了序列并展示了如何打包和处理检查点。
- en: Finally, we've shown how to use GCP to train our model in the cloud on powerful
    machines. We've introduced how to create a Magenta VM instance and how to launch
    training, evaluation, and TensorBoard on it.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了如何使用GCP在强大的机器上云端训练我们的模型。我们介绍了如何创建Magenta VM实例，以及如何在上面启动训练、评估和TensorBoard。
- en: This chapter marks the end of the training content for this book. In the next
    chapters, we'll be looking at parts that are outside the core features of Magenta,
    such as Magenta.js, and making Magenta interact with a **Digital Audio Workstation**
    (**DAW**).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 本章标志着本书训练内容的结束。在接下来的章节中，我们将探讨一些Magenta核心功能以外的部分，比如Magenta.js，并且让Magenta与**数字音频工作站**（**DAW**）进行交互。
- en: Questions
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Write a new configuration for the Drums RNN model that uses an attention length
    of 64 and that encodes only the snares and bass drums, but inverted.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个新的Drums RNN模型配置，使用64的注意力长度，并且只对小军鼓和低音鼓进行编码，但进行反向处理。
- en: 'We have a model that underfits: what does this mean and how do we fix the problem?'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有一个欠拟合的模型：这是什么意思，我们该如何解决这个问题？
- en: 'We have a model that overfits: what does this mean and how do we fix the problem?'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有一个过拟合的模型：这是什么意思，我们该如何解决这个问题？
- en: What is a technique that makes sure that, for a given training run, we stop
    at the optimum?
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有什么技术可以确保我们在给定的训练过程中停止在最佳状态？
- en: Why might increasing batch size make the model worse in terms of performance?
    Will it make it worse in terms of efficiency or training time?
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么增加批量大小会使得模型在性能上变得更差？它是否会在效率或训练时间上造成不良影响？
- en: What is a good network size?
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是合适的网络规模？
- en: Does limiting the value of the error derivative before backpropagation help
    or worsen the problem of exploding gradients? What is another solution to that
    problem?
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在反向传播之前，限制误差导数的值是否有助于或加剧梯度爆炸的问题？这个问题还有什么其他的解决方法？
- en: Why is using a cloud provider useful to train our models?
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么使用云服务商来训练我们的模型很有用？
- en: Further reading
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: '**How to Choose Loss Functions When Training Deep Learning Neural Networks**:
    A very thorough article on how to write a loss function ([machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/))'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如何选择深度学习神经网络的损失函数**：一篇非常详细的关于如何编写损失函数的文章 ([machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/))'
- en: '**How to Avoid Overfitting in Deep Learning Neural Networks**: An article on
    underfitting and overfitting and its solutions ([machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/))'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如何避免深度学习神经网络中的过拟合**：关于欠拟合和过拟合及其解决方案的文章 ([machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/))'
- en: '**How to Avoid Exploding Gradients With Gradient Clipping**: An article on
    exploding gradients and how to fix it using gradient clipping ([machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/](https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/))'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如何通过梯度裁剪避免梯度爆炸**：关于梯度爆炸及如何通过梯度裁剪解决它的文章 ([machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/](https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/))'
- en: '**Use Weight Regularization to Reduce Overfitting of Deep Learning Models**:
    An article on weight regularization, which helps reduce overfitting ([machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/](https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/))'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用权重正则化减少深度学习模型的过拟合**：关于权重正则化的文章，它有助于减少过拟合 ([machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/](https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/))'
- en: '**A Gentle Introduction to Dropout for Regularizing Deep Neural Networks**:
    An article on dropout, which helps to reduce overfitting ([machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/))'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度神经网络正则化的温和介绍——Dropout**：关于Dropout的文章，它有助于减少过拟合 ([machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/))'
- en: '**A Gentle Introduction to Early Stopping to Avoid Overtraining Neural Networks**:
    An article on early stopping, which helps to reduce overfitting ([machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/))'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**避免神经网络过拟合的早停方法简介**：一篇关于早停的文章，有助于减少过拟合 ([machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/))'
- en: '**On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima**:
    A paper (2017) explaining why a larger batch size might lead to a less efficient
    network ([arxiv.org/abs/1609.04836](https://arxiv.org/abs/1609.04836))'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习中的大批量训练：泛化误差与陡峭最小值**：一篇论文（2017年），解释了为什么较大的批量大小可能导致网络效率下降 ([arxiv.org/abs/1609.04836](https://arxiv.org/abs/1609.04836))'
