- en: Performing Anomaly Detection on Unsupervised Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在无监督数据上执行异常检测
- en: In this chapter, we will perform anomaly detection with the **Modified National
    Institute of Standards and Technology** (**MNIST**) dataset using a simple autoencoder without
    any pretraining. We will identify the outliers in the given MNIST data. Outlier digits
    can be considered as most untypical or not normal digits. We will encode the MNIST
    data and then decode it back in the output layer. Then, we will calculate the reconstruction
    error for the MNIST data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用**修改版国家标准与技术研究院**（**MNIST**）数据集，通过一个简单的自编码器进行异常检测，且没有任何预训练。我们将识别给定MNIST数据中的离群值。离群数字可以被认为是最不典型或不正常的数字。我们将对MNIST数据进行编码，然后在输出层解码回来。然后，我们将计算MNIST数据的重建误差。
- en: The MNIST sample that closely resembles a digit value will have low reconstruction
    error. We will then sort them based on the reconstruction errors and then display
    the best samples and the worst samples (outliers) using the JFrame window. The
    autoencoder is constructed using a feed-forward network. Note that we are not
    performing any pretraining. We can process feature inputs in an autoencoder and
    we won't require MNIST labels at any stage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与数字值相似的MNIST样本将具有较低的重建误差。然后，我们将根据重建误差对它们进行排序，并使用JFrame窗口显示最佳样本和最差样本（离群值）。自编码器使用前馈网络构建。请注意，我们并没有进行任何预训练。我们可以在自编码器中处理特征输入，并且在任何阶段都不需要MNIST标签。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Extracting and preparing MNIST data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取并准备MNIST数据
- en: Constructing dense layers for input
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建输入的密集层
- en: Constructing output layers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建输出层
- en: Training with MNIST images
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MNIST图像进行训练
- en: Evaluating and sorting the results based on the anomaly score
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据异常得分评估并排序结果
- en: Saving the resultant model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存生成的模型
- en: Let's begin.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code for this chapter can be found here: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节的代码可以在这里找到：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java)
- en: 'The JFrame-specific implementation can be found here:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: JFrame特定的实现可以在这里找到：
- en: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java#L134](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java#L134).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java#L134](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java#L134)'
- en: After cloning our GitHub repository, navigate to the` Java-Deep-Learning-Cookbook/08_Performing_Anomaly_detection_on_unsupervised
    data/sourceCode` directory. Then, import the `cookbook-app` project as a Maven
    project by importing `pom.xml`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆我们的GitHub仓库后，导航到`Java-Deep-Learning-Cookbook/08_Performing_Anomaly_detection_on_unsupervised
    data/sourceCode`目录。然后，通过导入`pom.xml`将`cookbook-app`项目作为Maven项目导入。
- en: Note that we use the MNIST dataset from here: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用的MNIST数据集可以在这里找到：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
- en: However, we don't have to download the dataset for this chapter: DL4J has a
    custom implementation that allows us to fetch MNIST data automatically. We will
    be using this in this chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们不需要为本章下载数据集：DL4J有一个自定义实现，允许我们自动获取MNIST数据。我们将在本章中使用它。
- en: Extracting and preparing MNIST data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取并准备MNIST数据
- en: Unlike supervised image classification use cases, we will perform an anomaly
    detection task on the MNIST dataset. On top of that, we are using an unsupervised
    model, which means that we will not be using any type of label to perform the
    training process. To start the ETL process, we will extract this unsupervised
    MNIST data and prepare it so that it is usable for neural network training.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与有监督的图像分类任务不同，我们将对 MNIST 数据集执行异常检测任务。更重要的是，我们使用的是无监督模型，这意味着我们在训练过程中不会使用任何类型的标签。为了启动
    ETL 过程，我们将提取这种无监督的 MNIST 数据并将其准备好，以便可以用于神经网络的训练。
- en: How to do it...
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create iterators for the MNIST data using `MnistDataSetIterator`:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `MnistDataSetIterator` 为 MNIST 数据创建迭代器：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Use `SplitTestAndTrain` to split the base iterator into train/test iterators:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `SplitTestAndTrain` 将基础迭代器拆分为训练/测试迭代器：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create lists to store the feature sets from the train/test iterators:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建列表以存储来自训练/测试迭代器的特征集：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Populate the values into the feature/label lists that were previously created:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将之前创建的特征/标签列表填充数据：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Call `argmax()` for every iterator instance to convert the labels to one dimensional
    data if it''s multidimensional:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对每个迭代器实例调用 `argmax()`，如果标签是多维的，则将其转换为一维数据：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In step 1, we have used `MnistDataSetIterator` to extract and load MNIST data
    in one place. DL4J comes with this specialized iterator to load MNIST data without
    having to worry about downloading the data on your own. You might notice that
    MNIST data on the official website follows the `ubyte` format. This is certainly
    not the desired format, and we need to extract all the images separately to load
    them properly on the neural network.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 中，我们使用 `MnistDataSetIterator` 在一个地方提取并加载 MNIST 数据。DL4J 提供了这个专门的迭代器来加载
    MNIST 数据，而无需担心自行下载数据。你可能会注意到，MNIST 数据在官方网站上是 `ubyte` 格式。这显然不是我们想要的格式，因此我们需要分别提取所有的图像，以便正确加载到神经网络中。
- en: 'Therefore, it is very convenient to have an MNIST iterator implementation such
    as `MnistDataSetIterator` in DL4J. It simplifies the typical task of handling
    MNIST data in the `ubyte` format. MNIST data has a total of 60,000 training digits,
    10,000 test digits, and 10 labels. Digit images have a dimension of 28 x 28, the
    shape of the data is in a flattened format: [`minibatch`, 784]. `MnistDataSetIterator`
    internally uses the `MnistDataFetcher` and `MnistManager` classes to fetch the
    MNIST data and load them into the proper format. In step 1, `binarize`: `true` or `false` indicates
    whether to binarize the MNIST data.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在 DL4J 中拥有像 `MnistDataSetIterator` 这样的 MNIST 迭代器实现非常方便。它简化了处理 `ubyte` 格式
    MNIST 数据的常见任务。MNIST 数据共有 60,000 个训练数字，10,000 个测试数字和 10 个标签。数字图像的尺寸为 28 x 28，数据的形状是扁平化格式：[
    `minibatch`，784]。`MnistDataSetIterator` 内部使用 `MnistDataFetcher` 和 `MnistManager`
    类来获取 MNIST 数据并将其加载到正确的格式中。在步骤 1 中，`binarize`：`true` 或 `false` 表示是否对 MNIST 数据进行二值化。
- en: Note that in step 2, `numHoldOut` indicates the number of samples to be held
    for training. If `miniBatchSize` is `100` and `numHoldOut` is `80`, then the remaining
    20 samples are meant for testing and evaluation. We can use `DataSetIteratorSplitter`instead
    of `SplitTestAndTrain` for splitting of data, as mentioned in step 2.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在步骤 2 中，`numHoldOut` 表示用于训练的样本数量。如果 `miniBatchSize` 为 `100` 且 `numHoldOut`
    为 `80`，则剩余的 20 个样本用于测试和评估。我们可以使用 `DataSetIteratorSplitter` 代替步骤 2 中提到的 `SplitTestAndTrain`
    进行数据拆分。
- en: In step 3, we created lists to maintain the features and labels with respect
    to training and testing. We need them for the training and evaluation stages,
    respectively. We also created a list to store labels from the test set to map
    the outliers with labels during the test and evaluation phases. These lists are
    populated once in every occurrence of a batch. For example, in the case of `featuresTrain` or `featuresTest`,
    a batch of features (after data splitting) is represented by an `INDArray` item.
    We have also used an `argMax()` function from ND4J. This converts the labels array
    into a one-dimensional array. MNIST labels from `0` to `9` effectively need just
    one-dimensional space for representation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 3 中，我们创建了列表来维护与训练和测试相关的特征和标签。它们分别用于训练和评估阶段。我们还创建了一个列表，用于存储来自测试集的标签，在测试和评估阶段将异常值与标签进行映射。这些列表在每次批次发生时都会填充一次。例如，在
    `featuresTrain` 或 `featuresTest` 的情况下，一个批次的特征（经过数据拆分后）由一个 `INDArray` 项表示。我们还使用了
    ND4J 中的 `argMax()` 函数，它将标签数组转换为一维数组。MNIST 标签从 `0` 到 `9` 实际上只需要一维空间来表示。
- en: 'In the following code, `1`denotes the dimension:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，`1` 表示维度：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Also, note that we use the labels for mapping outliers to labels and not for
    training.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同时请注意，我们使用标签来映射异常值，而不是用于训练。
- en: Constructing dense layers for input
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建输入的密集层
- en: The core of the neural network design is the layer architecture. For autoencoders,
    we need to design dense layers that do encoding at the front and decoding at the
    other end. Basically, we are reconstructing the inputs in this way. Accordingly,
    we need to make our layer design.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络设计的核心是层架构。对于自编码器，我们需要设计在前端进行编码、在另一端进行解码的密集层。基本上，我们就是通过这种方式重建输入。因此，我们需要设计我们的层结构。
- en: Let's start configuring our autoencoder using the default settings and then
    proceed further by defining the necessary input layers for our autoencoder. Remember
    that the number of incoming connections to the neural network will be equal to
    the number of outgoing connections from the neural network.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从配置默认设置开始设置我们的自编码器，然后进一步定义自编码器所需的输入层。记住，神经网络的输入连接数应等于输出连接数。
- en: How to do it...
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Use `MultiLayerConfiguration` to construct the autoencoder network:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`MultiLayerConfiguration`构建自编码器网络：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create input layers using `DenseLayer`:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DenseLayer`创建输入层：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works...
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In step 1, while configuring generic neural network parameters, we set the
    default learning rate as shown here:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1步中，在配置通用神经网络参数时，我们设置了默认的学习率，如下所示：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `Adagrad` optimizer is based on how frequently a parameter gets updated
    during training. `Adagrad` is based on a vectorized learning rate. The learning
    rate will be small when there are many updates received. This is crucial for high-dimensional
    problems. Hence, this optimizer can be a good fit for our autoencoder use case.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`Adagrad`优化器基于在训练期间参数更新的频率。`Adagrad`基于矢量化学习率。当接收到更多更新时，学习率会较小。这对于高维度问题至关重要。因此，这个优化器非常适合我们的自编码器应用场景。'
- en: We are performing dimensionality reduction at the input layers in an autoencoder
    architecture. This is also known as encoding the data. We want to ensure that
    the same set of features are decoded from the encoded data. We calculate reconstruction
    errors to measure how close we are compared to the real feature set before encoding.
    In step 2, we are trying to encode the data from a higher dimension (`784`) to
    a lower dimension (`10`).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在自编码器架构中，我们在输入层执行降维。这也被称为对数据进行编码。我们希望确保从编码数据中解码出相同的特征集合。我们计算重建误差，以衡量我们与编码前的真实特征集合有多接近。在第2步中，我们尝试将数据从较高维度（`784`）编码到较低维度（`10`）。
- en: Constructing output layers
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建输出层
- en: As a final step, we need to decode the data back from the encoded state. Are
    we able to reconstruct the input just the way it is? If yes, then it's all good.
    Otherwise, we need to calculate an associated reconstruction error. Remember that
    the incoming connections to the output layer should be the same as the outgoing
    connections from the preceding layer.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们需要将数据从编码状态解码回原始状态。我们能否完美地重建输入？如果可以，那么一切都好。否则，我们需要计算相关的重建误差。记住，输出层的输入连接应该与前一层的输出连接相同。
- en: How to do it...
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Create an output layer using `OutputLayer`:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`OutputLayer`创建一个输出层：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Add `OutputLayer` to the layer definitions:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`OutputLayer`添加到层定义中：
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We have mentioned the **mean square error** (**MSE**) as the error function
    associated with the output layer. `lossFunction`, which is used in autoencoder
    architecture, is MSE in most cases. MSE is optimal in calculating how close the
    reconstructed input is to the original input. ND4J has an implementation for MSE,
    which is `LossFunction.MSE`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到了**均方误差**（**MSE**）作为与输出层相关的误差函数。`lossFunction`，在自编码器架构中，通常是MSE。MSE在计算重建输入与原始输入之间的接近程度时是最优的。ND4J有一个MSE的实现，即`LossFunction.MSE`。
- en: In the output layer, we get the reconstructed input in their original dimensions.
    We will then use an error function to calculate the reconstruction error. In step
    1, we're constructing an output layer that calculates the reconstruction error
    for anomaly detection. It is important to keep the incoming and outgoing connections
    the same at the input and output layers, respectively. Once the output layer definition
    is created, we need to add it to a stack of layer configurations that is maintained
    to create the neural network configuration. In step 2, we added the output layer
    to the previously maintained neural network configuration builder. In order to
    follow an intuitive approach, we have created configuration builders first, unlike
    the straightforward approach here: [https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出层，我们得到重建后的输入，并且它们的维度与原始输入相同。然后我们将使用误差函数来计算重建误差。在第1步中，我们构建了一个输出层，用于计算异常检测的重建误差。重要的是，输入和输出层的输入连接和输出连接需要保持一致。一旦定义了输出层，我们需要将其添加到一个层配置堆栈中，以此来创建神经网络的配置。在第2步中，我们将输出层添加到之前维护的神经网络配置构建器中。为了遵循直观的方法，我们首先创建了配置构建器，而不像这里所采用的简单方法：[https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java](https://github.com/PacktPublishing/Java-Deep-Learning-Cookbook/blob/master/08_Performing_Anomaly_detection_on_unsupervised%20data/sourceCode/cookbook-app/src/main/java/MnistAnomalyDetectionExample.java)。
- en: You can obtain a configuration instance by calling the `build()` method on the
    `Builder` instance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在`Builder`实例上调用`build()`方法来获取配置实例。
- en: Training with MNIST images
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MNIST图像进行训练
- en: Once the layers are constructed and the neural network is formed, we can initiate
    the training session. During the training session, we reconstruct the input multiple
    times and evaluate the reconstruction error. In previous recipes, we completed
    the autoencoder network configuration by defining the input and output layers
    as required. Note that we are going to train the network with its own input features,
    not the labels. Since we use an autoencoder for anomaly detection, we encode the
    data and then decode it back to measure the reconstruction error. Based on that,
    we list the most probable anomalies in MNIST data.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦构建了各层并形成了神经网络，我们就可以启动训练过程。在训练过程中，我们会多次重建输入并评估重建误差。在之前的示例中，我们通过根据需要定义输入和输出层完成了自编码器网络配置。请注意，我们将使用自编码器进行异常检测，因此我们使用其自身的输入特征来训练网络，而不是标签。因为我们使用自编码器进行异常检测，所以我们先编码数据，然后再解码回来以衡量重建误差。基于此，我们列出MNIST数据中最可能的异常。
- en: How to do it...
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Choose the correct training approach. Here is what is expected to happen during
    the training instance:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择正确的训练方法。以下是训练过程中预期会发生的情况：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: So, we need to train output against input (output ~ input, in an ideal case).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们需要训练输出与输入相对应（理想情况下，输出 ~ 输入）。
- en: 'Train every feature set using the `fit()` method:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fit()`方法训练每个特征集：
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `fit()` method accepts both features and labels as attributes for the first
    and second attributes, respectively. We reconstruct the MNIST features against
    themselves. In other words, we are trying to recreate the features once they are
    encoded and check how much they vary from actual features. We measure the reconstruction
    error during training and bother only about the feature values. So, the output
    is validated against the input and resembles how an autoencoder functions. So,
    step 1 is crucial for the evaluation stage as well.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit()`方法接受特征和标签作为第一和第二个属性。我们会将MNIST特征与它们自己进行重建。换句话说，我们试图在特征被编码后重新创建它们，并检查它们与实际特征的差异。在训练过程中，我们测量重建误差，并且只关注特征值。因此，输出将与输入进行验证，并类似于自编码器的功能。所以，第1步对于评估阶段也至关重要。'
- en: 'Refer to this block of code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下代码块：
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: That's the reason why we train the autoencoder against its own features (inputs)
    as we call `fit()` in this way: `net.fit(data,data)` in step 2.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们为何将自编码器训练为其自身特征（输入）的原因，在第2步中我们通过这种方式调用`fit()`：`net.fit(data,data)`。
- en: Evaluating and sorting the results based on the anomaly score
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 根据异常评分评估和排序结果
- en: We need to calculate the reconstruction error for all the feature sets. Based
    on that, we will find the outlier data for all the MNIST digits (0 to 9). Finally,
    we will display the outlier data in the JFrame window. We also need feature values
    from a test set for the evaluation. We also need label values from the test set,
    not for evaluation, but for mapping anomalies with labels. Then, we can plot outlier
    data against each label. The labels are only used for plotting outlier data in
    JFrame against respective labels. In this recipe, we evaluate the trained autoencoder
    model for MNIST anomaly detection, and then sort the results and display them.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要计算所有特征集的重建误差。根据这个，我们会找出所有MNIST数字（0到9）的离群数据。最后，我们将在JFrame窗口中显示离群数据。我们还需要来自测试集的特征值用于评估。我们还需要来自测试集的标签值，标签不是用来评估的，而是用于将异常与标签关联。然后，我们可以根据每个标签绘制离群数据。标签仅用于在JFrame中根据相应的标签绘制离群数据。在本配方中，我们评估了训练好的自编码器模型用于MNIST异常检测，然后排序结果并显示出来。
- en: How to do it...
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Compose a map that relates each MNIST digit to a list of (score, feature) pairs:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个将每个MNIST数字与一组(score, feature)对相关联的映射：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Iterate through each and every test feature, calculate the reconstruction error,
    make a score-feature pair for the purpose of displaying the sample with a low
    reconstruction error:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历每一个测试特征，计算重建误差，生成分数-特征对用于显示具有低重建误差的样本：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a custom comparator to sort the map:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个自定义的比较器来排序映射：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Sort the map using `Collections.sort()`:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Collections.sort()`对映射进行排序：
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Collect the best/worst data to display in a JFrame window for visualization:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集最佳/最差数据，以在JFrame窗口中显示用于可视化：
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Use a custom JFrame implementation for visualization, such as `MNISTVisualizer`,
    to visualize the results:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用自定义的JFrame实现进行可视化，比如`MNISTVisualizer`，来展示结果：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How it works...
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Using step 1 and step 2, for every MNIST digit, we maintain a list of (score,
    feature) pairs. We composed a map that relates each MNIST digit to this list of
    pairs. In the end, we just have to sort it to find the best/worst cases.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通过步骤1和步骤2，对于每个MNIST数字，我们维护一个(score, feature)对的列表。我们构建了一个将每个MNIST数字与这个列表相关联的映射。最后，我们只需要排序就可以找到最好的/最差的案例。
- en: 'Also, we used the `score()` function to calculate the reconstruction error:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用了`score()`函数来计算重建误差：
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: During the evaluation, we reconstruct the test features and measure how much
    it differs from actual feature values. A high reconstruction error indicates the
    presence of a high percentage of outliers.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估过程中，我们会重建测试特征，并测量它与实际特征值的差异。较高的重建误差表明存在较高比例的离群值。
- en: 'After step 4, we should see JFrame visualization for reconstruction errors, as
    shown here:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤4之后，我们应该能看到JFrame可视化的重建误差，如下所示：
- en: '![](img/48f96597-f613-4198-8ebf-2e049ba79953.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48f96597-f613-4198-8ebf-2e049ba79953.png)'
- en: Visualization is JFrame dependent. Basically, what we do is take the *N* best/worst
    pairs from the previously created map in step 1\. We make a list of best/worst
    data and pass it to our JFrame visualization logic to display the outlier in the
    JFrame window. The JFrame window on the right side represents the outlier data. We
    are leaving the JFrame implementation aside as it is beyond the scope for this
    book. For the complete JFrame implementation, refer to GitHub source mentioned
    in the *Technical requirements* section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化依赖于JFrame。基本上，我们所做的是从第1步中创建的映射中取出*N*个最佳/最差的对。我们制作一个最佳/最差数据的列表，并将其传递给我们的JFrame可视化逻辑，以便在JFrame窗口中显示离群值。右侧的JFrame窗口表示离群数据。我们将JFrame的实现留到一边，因为这超出了本书的范围。完整的JFrame实现请参考“技术要求”部分中提到的GitHub源代码。
- en: Saving the resultant model
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存结果模型
- en: Model persistence is very important as it enables the reuse of neural network
    models without having to train more than once. Once the autoencoder is trained
    to perform outlier detection, we can save the model to the disk for later use.
    We explained the `ModelSerializer` class in a previous chapter. We use this to
    save the autoencoder model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 模型持久化非常重要，因为它使得无需重新训练即可重复使用神经网络模型。一旦自编码器被训练用于执行离群值检测，我们就可以将模型保存到磁盘以供以后使用。我们在前一章中解释了`ModelSerializer`类，我们用它来保存自编码器模型。
- en: How to do it...
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Use `ModelSerializer` to persist the model:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ModelSerializer`持久化模型：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Add a normalizer to the persisted model:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向持久化模型中添加一个标准化器：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We officially target the DL4J version 1.0.0-beta 3 in this chapter. We used `ModelSerializer`
    to save the models to disk. If you use the new version, 1.0.0-beta 4, there is
    another recommended way to save the model by using the `save()` method offered
    by `MultiLayerNetwork`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们正式针对DL4J版本1.0.0-beta 3。我们使用`ModelSerializer`将模型保存到磁盘。如果你使用的是新版本1.0.0-beta
    4，还有另一种推荐的保存模型方法，即使用`MultiLayerNetwork`提供的`save()`方法：
- en: '[PRE23]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Use `saveUpdater = true` if you want to train the network in the future.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望未来训练网络，使用`saveUpdater = true`。
- en: There's more...
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'To restore the network model, call the `restoreMultiLayerNetwork()` method:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复网络模型，调用`restoreMultiLayerNetwork()`方法：
- en: '[PRE24]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Additionally, if you use the latest version, 1.0.0-beta 4, you can use the `load()` method
    offered by `MultiLayerNetwork`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你使用最新版本 1.0.0-beta 4，你可以使用`MultiLayerNetwork`提供的`load()`方法：
- en: '[PRE25]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
