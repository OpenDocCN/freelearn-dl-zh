- en: Appendix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: This appendix serves as a practical reference guide to the major LLM providers
    that integrate with LangChain. As you develop applications with the techniques
    covered throughout this book, you’ll need to connect to various model providers,
    each with its own authentication mechanisms, capabilities, and integration patterns.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录作为与LangChain集成的LLM主要提供商的实用参考指南。随着你使用本书中介绍的技术开发应用程序，你需要连接到各种模型提供商，每个提供商都有自己的身份验证机制、功能和集成模式。
- en: We’ll first cover the detailed setup instructions for the major LLM providers,
    including OpenAI, Hugging Face, Google, and others. For each provider, we walk
    through the process of creating accounts, generating API keys, and configuring
    your development environment to use these services with LangChain. We then conclude
    with a practical implementation example that demonstrates how to process content
    exceeding an LLM’s context window—specifically, summarizing long videos using
    map-reduce techniques with LangChain. This pattern can be adapted for various
    scenarios where you need to process large volumes of text, audio transcripts,
    or other content that won’t fit into a single LLM context.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍主要LLM提供商的详细设置说明，包括OpenAI、Hugging Face、Google和其他。对于每个提供商，我们将指导创建账户、生成API密钥以及配置你的开发环境以使用LangChain服务的过程。然后，我们将通过一个实际实现示例来结束，该示例演示了如何处理超出LLM上下文窗口的内容——具体来说，使用LangChain的map-reduce技术总结长视频。这种模式可以适应各种需要处理大量文本、音频转录或其他内容的场景，这些内容无法适应单个LLM上下文。
- en: OpenAI
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI
- en: OpenAI remains one of the most popular LLM providers, offering models with various
    levels of power suitable for different tasks, including GPT-4 and GPT-o1\. LangChain
    provides seamless integration with OpenAI’s APIs, supporting both their traditional
    completion models and chat models. Each of these models has its own price, typically
    per token.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI仍然是最受欢迎的LLM提供商之一，提供不同级别的模型，适用于各种任务，包括GPT-4和GPT-o1。LangChain提供了与OpenAI
    API的无缝集成，支持他们的传统完成模型和聊天模型。这些模型各自有不同的价格，通常是按令牌计费。
- en: 'To work with OpenAI models, we need to obtain an OpenAI API key first. To create
    an API key, follow these steps:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用OpenAI模型，我们首先需要获取一个OpenAI API密钥。要创建API密钥，请按照以下步骤操作：
- en: You need to create a login at [https://platform.openai.com/](https://platform.openai.com/).
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要在[https://platform.openai.com/](https://platform.openai.com/)创建一个登录。
- en: Set up your billing information.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置你的账单信息。
- en: You can see the API keys under **Personal** | **View API Keys**.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以在**个人** | **查看API密钥**下看到API密钥。
- en: Click on **Create new secret key** and give it a name.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建新的密钥**并给它命名。
- en: 'Here’s how this should look on the OpenAI platform:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是OpenAI平台上的样子：
- en: '![Figure A.1: OpenAI API platform – Create new secret key](img/B32363_Appendix_01-01.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图A.1：OpenAI API平台 – 创建新的密钥](img/B32363_Appendix_01-01.png)'
- en: 'Figure A.1: OpenAI API platform – Create new secret key'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.1：OpenAI API平台 – 创建新的密钥
- en: After clicking **Create secret key**, you should see the message API key generated.
    You need to copy the key to your clipboard and save it, as you will need it. You
    can set the key as an environment variable (**OPENAI_API_KEY**) or pass it as
    a parameter every time you construct a class for OpenAI calls.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**创建密钥**后，你应该会看到消息“API密钥已生成”。你需要将密钥复制到剪贴板并保存，因为你将需要它。你可以将密钥设置为环境变量（**OPENAI_API_KEY**）或每次构建用于OpenAI调用的类时都传递它。
- en: You can specify different models when you initialize your model, be it a chat
    model or an LLM. You can see a list of models at [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当你初始化模型时，可以指定不同的模型，无论是聊天模型还是LLM。你可以在[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)看到模型列表。
- en: 'OpenAI provides a comprehensive suite of capabilities that integrate seamlessly
    with LangChain, including:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI提供了一套全面的与LangChain无缝集成的功能，包括：
- en: Core language models via the OpenAI API
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过OpenAI API的核心语言模型
- en: Embedding class for text embedding models
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本嵌入模型的嵌入类
- en: We’ll cover the basics of model integration in this chapter, while deeper explorations
    of specialized features like embeddings, assistants, and moderation will follow
    in Chapters 4 and 5.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍模型集成的基础知识，而关于嵌入、助手和审查等专用功能的深入探索将在第4章和第5章中进行。
- en: Hugging Face
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hugging Face
- en: Hugging Face is a very prominent player in the NLP space and has considerable
    traction in open-source and hosting solutions. The company is a French American
    company that develops tools for building ML applications. Its employees develop
    and maintain the Transformers Python library, which is used for NLP tasks, includes
    implementations of state-of-the-art and popular models like Mistral 7B, BERT,
    and GPT-2, and is compatible with PyTorch, TensorFlow, and JAX.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face在NLP领域是一个非常突出的参与者，在开源和托管解决方案方面有相当的影响力。该公司是一家法美公司，开发用于构建机器学习应用的工具。其员工开发和维护Transformers
    Python库，该库用于NLP任务，包括Mistral 7B、BERT和GPT-2等最先进和流行的模型的实现，并且与PyTorch、TensorFlow和JAX兼容。
- en: In addition to their products, Hugging Face has been involved in initiatives
    such as the BigScience Research Workshop, where they released an open LLM called
    BLOOM with 176 billion parameters. Hugging Face has also established partnerships
    with companies like Graphcore and Amazon Web Services to optimize their offerings
    and make them available to a broader customer base.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了他们的产品外，Hugging Face还参与了诸如BigScience Research Workshop等倡议，在那里他们发布了一个名为BLOOM的开放LLM，具有1760亿个参数。Hugging
    Face还与Graphcore和Amazon Web Services等公司建立了合作伙伴关系，以优化其产品并使其可供更广泛的客户群使用。
- en: LangChain supports leveraging the Hugging Face Hub, which provides access to
    a massive number of models, datasets in various languages and formats, and demo
    apps. This includes integrations with Hugging Face Endpoints, enabling text generation
    inference powered by the Text Generation Inference service. Users can connect
    to different Endpoint types, including the free Serverless Endpoints API and dedicated
    Inference Endpoints for enterprise workloads that come with support for AutoScaling.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain支持利用Hugging Face Hub，该Hub提供对大量模型、各种语言和格式的数据集以及演示应用的访问。这包括与Hugging Face端点的集成，通过文本生成推理服务实现由文本生成推理服务驱动的文本生成推理。用户可以连接到不同的端点类型，包括免费的Serverless
    Endpoints API和针对企业工作负载的专用推理端点，这些端点支持自动扩展。
- en: For local use, LangChain provides integration with Hugging Face models and pipelines.
    The `ChatHuggingFace` class allows using Hugging Face models for chat applications,
    while the `HuggingFacePipeline` class enables running Hugging Face models locally
    through pipelines. Additionally, LangChain supports embedding models from Hugging
    Face, including `HuggingFaceEmbeddings`, `HuggingFaceInstructEmbeddings`, and
    `HuggingFaceBgeEmbeddings`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本地使用，LangChain提供了与Hugging Face模型和管道的集成。`ChatHuggingFace`类允许在聊天应用中使用Hugging
    Face模型，而`HuggingFacePipeline`类则通过管道在本地运行Hugging Face模型。此外，LangChain支持从Hugging
    Face加载嵌入模型，包括`HuggingFaceEmbeddings`、`HuggingFaceInstructEmbeddings`和`HuggingFaceBgeEmbeddings`。
- en: The `HuggingFaceHubEmbeddings` class allows leveraging the Hugging Face **Text
    Embeddings Inference** (**TEI**) toolkit for high-performance extraction. LangChain
    also provides a `HuggingFaceDatasetLoader` to load datasets from the Hugging Face
    Hub.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`HuggingFaceHubEmbeddings`类允许利用Hugging Face **文本嵌入推理**（**TEI**）工具包进行高性能提取。LangChain还提供了一个`HuggingFaceDatasetLoader`，用于从Hugging
    Face Hub加载数据集。'
- en: To use Hugging Face as a provider for your models, you can create an account
    and API keys at [https://huggingface.co/settings/profile](https://huggingface.co/settings/profile).
    Additionally, you can make the token available in your environment as `HUGGINGFACEHUB_API_TOKEN`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要将Hugging Face作为模型提供者，您可以在[https://huggingface.co/settings/profile](https://huggingface.co/settings/profile)创建账户和API密钥。此外，您可以将令牌作为`HUGGINGFACEHUB_API_TOKEN`在您的环境中可用。
- en: Google
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google
- en: 'Google offers two primary platforms to access its LLMs, including the latest
    Gemini models:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Google提供两个主要平台以访问其LLM，包括最新的Gemini模型：
- en: 1\. Google AI platform
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1. Google AI平台
- en: 'The Google AI platform provides a straightforward setup for developers and
    users, and access to the latest Gemini models. To use the Gemini models via Google
    AI:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Google AI平台为开发者和用户提供了一个简单的设置，并可以访问最新的Gemini模型。要通过Google AI使用Gemini模型：
- en: '**Google Account**: A standard Google account is sufficient for authentication.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google账户**：一个标准的Google账户就足以进行身份验证。'
- en: '**API Key**: Generate an API key to authenticate your requests.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API密钥**：生成API密钥以验证您的请求。'
- en: 'Visit this page to create your API key: [https://ai.google.dev/gemini-api/docs/api-key](https://ai.google.dev/gemini-api/docs/api-key
    )'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问此页面以创建您的API密钥：[https://ai.google.dev/gemini-api/docs/api-key](https://ai.google.dev/gemini-api/docs/api-key)
- en: After obtaining the API key, set the `GOOGLE_API_KEY` environment variable in
    your development environment (see the instructions for OpenAI) to authenticate
    your requests.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取API密钥后，在您的开发环境中设置`GOOGLE_API_KEY`环境变量以验证您的请求（参见OpenAI的说明）。
- en: 2\. Google Cloud Vertex AI
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2. Google Cloud Vertex AI
- en: 'For enterprise-level features and integration, Google’s Gemini models are available
    through Google Cloud’s Vertex AI platform. To use models via Vertex AI:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于企业级功能和集成，Google的Gemini模型可通过Google Cloud的Vertex AI平台获取。要通过Vertex AI使用模型：
- en: Create a Google Cloud account, which requires accepting the terms of service
    and setting up billing.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Google Cloud账户，需要接受服务条款并设置账单。
- en: Install the gcloud CLI to interact with Google Cloud services. Follow the installation
    instructions at [https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装gcloud CLI以与Google Cloud服务交互。请遵循[https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)上的安装说明。
- en: 'Run the following command to authenticate and obtain a key token:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令进行身份验证并获取密钥令牌：
- en: '[PRE0]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Ensure that the Vertex AI API is enabled for your Google Cloud project.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保Vertex AI API已为您Google Cloud项目启用。
- en: 'You can set your Google Cloud project ID – for example, using the `gcloud`
    command:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以设置您的Google Cloud项目ID——例如，使用`gcloud`命令：
- en: '[PRE1]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Other methods are passing a constructor argument when initializing the LLM,
    using aiplatform.init(), or setting a GCP environment variable.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法包括在初始化LLM时传递构造函数参数，使用`aiplatform.init()`，或设置GCP环境变量。
- en: You can read more about these options in the Vertex documentation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在Vertex文档中了解更多关于这些选项的信息。
- en: If you haven’t enabled the relevant service, you should get a helpful error
    message pointing you to the right website, where you click **Enable**. You have
    to either enable Vertex or the Generative Language API according to preference
    and availability.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尚未启用相关服务，您应该会收到一个有用的错误消息，该消息会指向正确的网站，您可以在该网站上点击**启用**。您必须根据偏好和可用性启用Vertex或生成语言API。
- en: LangChain offers integrations with Google services such as language model inference,
    embeddings, data ingestion from different sources, document transformation, and
    translation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了与Google服务的集成，例如语言模型推理、嵌入、从不同来源的数据摄取、文档转换和翻译。
- en: 'There are two main integration packages:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有两个集成包：
- en: '`langchain-google-vertexai`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-google-vertexai`'
- en: '`langchain-google-genai`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-google-genai`'
- en: We’ll be using `langchain-google-genai`, the package recommended by LangChain
    for individual developers. The setup is simple, only requiring a Google account
    and API key. It is recommended to move to `langchain-google-vertexai` for larger
    projects. This integration offers enterprise features such as customer encryption
    keys, virtual private cloud integration, and more, requiring a Google Cloud account
    with billing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用LangChain推荐的`langchain-google-genai`包。设置很简单，只需要一个Google账户和API密钥。对于大型项目，建议迁移到`langchain-google-vertexai`。此集成提供了企业级功能，如客户加密密钥、虚拟私有云集成等，需要具有账单的Google
    Cloud账户。
- en: If you’ve followed the instructions on GitHub, as indicated in the previous
    section, you should already have the `langchain-google-genai` package installed.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已遵循上一节中GitHub上的说明，你应该已经安装了`langchain-google-genai`包。
- en: Other providers
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他提供商
- en: '**Replicate**: You can authenticate with your GitHub credentials at [https://replicate.com/](https://replicate.com/).
    If you then click on your user icon at the top left, you’ll find the API tokens
    – just copy the API key and make it available in your environment as `REPLICATE_API_TOKEN`.
    To run bigger jobs, you need to set up your credit card (under billing).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Replicate**：您可以使用GitHub凭据在[https://replicate.com/](https://replicate.com/)进行身份验证。然后点击左上角的用户图标，您将找到API令牌——只需复制API密钥并将其作为`REPLICATE_API_TOKEN`在您的环境中可用。要运行更大的作业，您需要设置您的信用卡（在账单下）。'
- en: '**Azure**: By authenticating either through GitHub or Microsoft credentials,
    we can create an account on Azure at [https://azure.microsoft.com/](https://azure.microsoft.com/).
    We can then create new API keys under **Cognitive Services** | **Azure OpenAI**.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure**：通过GitHub或Microsoft凭据进行身份验证，我们可以在[https://azure.microsoft.com/](https://azure.microsoft.com/)上创建Azure账户。然后我们可以在**认知服务**
    | **Azure OpenAI**下创建新的API密钥。'
- en: '**Anthropic**: You need to set the `ANTHROPIC_API_KEY` environment variable.
    Please make sure you’ve set up billing and added funds on the Anthropic console
    at [https://console.anthropic.com/](https://console.anthropic.com/).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic**：您需要设置`ANTHROPIC_API_KEY`环境变量。请确保您已在Anthropic控制台[https://console.anthropic.com/](https://console.anthropic.com/)上设置了计费并添加了资金。'
- en: Summarizing long videos
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结长视频
- en: ln *Chapter 3*, we demonstrated how to summarize long videos (that don’t fit
    into the context window) with a map-reduce approach. We used LangGraph to design
    such a workflow. Of course, you can use the same approach to any similar case
    – for example, to summarize long text or to extract information from long audios.
    Let’s now do the same using LangChain only, since it will be a useful exercise
    that will help us to better understand some internals of the framework.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3章中，我们展示了如何使用map-reduce方法总结长视频（不适合上下文窗口）。我们使用LangGraph设计了这样的工作流程。当然，您可以使用相同的方法处理任何类似的情况——例如，总结长文本或从长音频中提取信息。现在让我们只使用LangChain来完成同样的工作，因为这将是一个有用的练习，将帮助我们更好地理解框架的一些内部机制。
- en: First, a `PromptTemplate` doesn’t support media types (as of February 2025),
    so we need to convert an input to a list of messages manually. To use a parameterized
    chain, as a workaround, we will create a Python function that takes arguments
    (always provided by name) and creates a list of messages to be processed. Every
    message instructs an LLM to summarize a certain piece of the video (by splitting
    it into offset intervals), and these messages can be processed in parallel. The
    output will be a list of strings, each summarizing a subpart of the original video.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`PromptTemplate`不支持媒体类型（截至2025年2月），因此我们需要手动将输入转换为消息列表。为了使用参数化链，作为一个解决方案，我们将创建一个Python函数，该函数接受参数（总是以名称提供）并创建要处理的消息列表。每个消息都指示LLM摘要视频的某个部分（通过将其分割为偏移间隔），这些消息可以并行处理。输出将是一个字符串列表，每个字符串都摘要了原始视频的子部分。
- en: 'When you use an extra asterisk (***) in Python function declarations, it means
    that arguments after the asterisk should be provided by name only. For example,
    let’s create a simple function with many arguments that we can call in different
    ways in Python by passing only a few (or none) of the parameters by name:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在Python函数声明中使用额外的星号（***）时，这意味着星号之后的参数应该只按名称提供。例如，让我们创建一个具有许多参数的简单函数，我们可以在Python中以不同的方式调用它，只需通过名称传递少量（或没有）参数：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'But if you change its signature, the first invocation will throw an error:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果您更改其签名，第一次调用将引发错误：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You might see this a lot if you look at LangChain’s source code. That’s why
    we decided to explain it in a little bit more detail.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看LangChain的源代码，您可能会看到很多这种情况。这就是我们决定更详细地解释它的原因。
- en: 'Now, back to our code. We still need to run two separate steps if we want to
    pass `video_uri` as an input argument. Of course, we can wrap these steps as a
    Python function, but as an alternative, we merge everything into a single chain:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到我们的代码。如果我们想将`video_uri`作为输入参数传递，我们仍然需要运行两个独立的步骤。当然，我们可以将这些步骤封装为一个Python函数，但作为替代方案，我们将所有内容合并为一个单一链：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now let’s merge all summaries provided into a single prompt and ask an LLM
    to prepare a final summary:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将所有提供的摘要合并成一个单独的提示，并让一个LLM准备最终的摘要：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To combine everything together, we need a chain that first executes all the
    MAP steps and then the REDUCE phase:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要将所有内容组合在一起，我们需要一个链，它首先执行所有MAP步骤，然后是REDUCE阶段：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let’s reiterate what we did. We generated multiple summaries of different parts
    of the video, and then we passed these summaries to an LLM as texts and tasked
    it to generate a final summary. We prepared summaries of each piece independently
    and then combined them, which allowed us to overcome the limitation of a context
    window size for video and decreased latency a lot due to parallelization. Another
    alternative is the so-called **refine** approach. We begin with an empty summary
    and perform summarization step by step – each time, providing an LLM with a new
    piece of the video and a previously generated summary as input. We encourage readers
    to build this themselves since it will be a relatively simple change to the code.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下我们做了什么。我们为视频的不同部分生成了多个摘要，然后将这些摘要作为文本传递给一个LLM，并要求它生成最终的摘要。我们独立地为每个部分准备了摘要，然后将其合并，这使得我们克服了视频上下文窗口大小的限制，并通过并行化大大降低了延迟。另一种替代方法是所谓的**精炼**方法。我们从空摘要开始，逐步进行摘要，每次都向LLM提供一个视频的新片段和之前生成的摘要作为输入。我们鼓励读者自己构建这个功能，因为这将对代码进行相对简单的更改。
