- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: From Installation to Your First AI-Generated Text
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从安装到你的第一个 AI 生成文本
- en: Now that we have finished the first chapter, let’s discuss the must-have requirements
    of **Auto-GPT**.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了第一章，让我们讨论一下**Auto-GPT**的必备要求。
- en: At this point, before we start, whether you choose to register for an **application
    programming interface** (**API**) account or not at OpenAI is up to you. I first
    recommend trying to install and start Auto-GPT before registering, in case Auto-GPT
    only works in Docker (which could happen as it keeps changing); it may or may
    not be possible for you to run Auto-GPT. However, let’s begin by setting up Auto-GPT
    without the account. Otherwise, you will have an OpenAI account but there is no
    need for it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，在我们开始之前，是否选择在 OpenAI 注册一个**应用程序接口**（**API**）账户取决于你自己。我首先建议在注册之前尝试安装并启动
    Auto-GPT，以防 Auto-GPT 只在 Docker 中运行（这可能会发生，因为它不断变化）；你可能能够或不能运行 Auto-GPT。不过，我们先从没有账户的情况下设置
    Auto-GPT 开始。否则，你会有一个 OpenAI 账户，但其实并不需要它。
- en: In this chapter, we will guide you through preparing your machine to run Auto-GPT,
    the installation process, and your first steps with Auto-GPT.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将指导你准备机器以运行 Auto-GPT，安装过程，以及你使用 Auto-GPT 的第一步。
- en: We’ll cover the fundamental concepts, installation, and setup instructions for
    Auto-GPT. We will conclude by explaining how to execute your first AI-automated
    task using Auto-GPT.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖 Auto-GPT 的基本概念、安装和设置说明。最后，我们将解释如何使用 Auto-GPT 执行你的第一个 AI 自动化任务。
- en: The team at Auto-GPT (including me) is working hard on making Auto-GPT as accessible
    as possible.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 团队（包括我）正在努力让 Auto-GPT 尽可能易于访问。
- en: Recently a new tool has been made by one of the maintainers called **Auto-GPT
    Wizard**. If you struggle with setting up Auto-GPT at any point, this tool is
    meant to automate the installation and make it easier for newbies to get into
    Auto-GPT.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Auto-GPT 的一位维护者开发了一个新工具，叫做**Auto-GPT Wizard**。如果你在任何时候遇到设置 Auto-GPT 的困难，这个工具旨在自动化安装并让新手更容易上手
    Auto-GPT。
- en: You can find the tool at [https://github.com/Significant-Gravitas/AutoGPT_Wizard](https://github.com/Significant-Gravitas/AutoGPT_Wizard).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [https://github.com/Significant-Gravitas/AutoGPT_Wizard](https://github.com/Significant-Gravitas/AutoGPT_Wizard)
    找到这个工具。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下内容：
- en: System requirements and prerequisites
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统要求和先决条件
- en: Installing and setting up Auto-GPT
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装并设置 Auto-GPT
- en: Going through the basic concepts and terminology
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解基本概念和术语
- en: First run
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首次运行
- en: 'Here are some system requirements and prerequisites:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些系统要求和先决条件：
- en: Install VS Code.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 VS Code。
- en: Install Python.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Python。
- en: Install Poetry.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Poetry。
- en: Installing VS Code
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 VS Code
- en: I strongly recommend installing VS Code for usability or using any other IDE
    you see fit for Python. Working as a triage catalyst (reviewer, support, and contributor
    role at Auto-GPT), I have encountered many people who got stuck because they used
    their text editor or even Microsoft Word.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议安装 VS Code 以提高可用性，或者使用任何你认为合适的 Python IDE。作为 Auto-GPT 的一个 triage catalyst（审阅者、支持者和贡献者角色），我遇到过很多人因为使用文本编辑器，甚至是
    Microsoft Word 而卡住。
- en: Using advanced text editors configured properly might be adequate for basic
    scripting or editing configuration files, as they can be configured to avoid issues
    with text encoding and incorrect file extensions. However, IDEs such as VS Code
    offer more robust tools and integrations for a seamless development experience,
    especially when dealing with complex projects such as Auto-GPT; but we will have
    to edit JSON files, a `.env` file, and sometimes markdown (`.md`) files. Editing
    those with anything else than an IDE will probably result in the wrong file extension
    being added (for example, `.env` and `settings.json` could become `.env.txt` or
    `settings.json.docx`, which do not work).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用配置得当的高级文本编辑器可能足够用于基本脚本编写或编辑配置文件，因为它们可以配置以避免文本编码和文件扩展名错误的问题。然而，像 VS Code 这样的
    IDE 提供了更强大的工具和集成，能够为复杂的项目（如 Auto-GPT）提供无缝的开发体验；但我们需要编辑 JSON 文件、`.env` 文件，有时还需要编辑
    markdown（`.md`）文件。使用其他工具编辑这些文件可能会导致错误的文件扩展名（例如，`.env` 和 `settings.json` 可能会变成
    `.env.txt` 或 `settings.json.docx`，这些是无法正常工作的）。
- en: As a common tool to be used by many developers and it being free to use, we
    will focus on VS Code.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个许多开发者都会使用的常见工具，并且它是免费的，我们将重点介绍 VS Code。
- en: To not drift off the topic of why else you could use VS Code, Microsoft wrote
    a very good article on why VS Code is worth using. Of course, you can also use
    other IDEs. The main reason I recommend VS Code is that it is open source and
    free to use and also used by most Auto-GPT contributors, making it very easy to
    work with Auto-GPT and some integrated project settings for VS Code.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了不偏离为何你还可以使用 VS Code 这个话题，微软写了一篇非常好的文章，说明了为何 VS Code 值得使用。当然，你也可以使用其他的 IDE。我推荐使用
    VS Code 的主要原因是它是开源的且免费使用，并且被大多数 Auto-GPT 贡献者使用，这使得它与 Auto-GPT 以及一些 VS Code 的集成项目设置非常容易配合使用。
- en: Installing Python 3.10
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Python 3.10
- en: If you want to run Auto-GPT directly without Docker, you may need to install
    Python 3.10 or enable it as the terminal’s `python` and `python3` alias, to make
    sure that Auto-GPT doesn’t accidentally call a different Python version.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想直接运行 Auto-GPT 而不使用 Docker，可能需要安装 Python 3.10 或将其启用为终端的 `python` 和 `python3`
    别名，以确保 Auto-GPT 不会意外调用其他 Python 版本。
- en: Auto-GPT is developed in Python and it specifically requires Python version
    3.10.x. The *x* in 3.10.x represents any sub-version (for example, 3.10.0, 3.10.6),
    and the software is compatible with these sub-versions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 是用 Python 开发的，它特别要求使用 Python 版本 3.10.x。3.10.x 中的 *x* 代表任何子版本（例如，3.10.0、3.10.6），该软件与这些子版本兼容。
- en: While Auto-GPT is lightweight in terms of file size, it can be resource-intensive
    depending on the options and plugins you enable. Consequently, it’s essential
    to have a compatible and optimized environment to ensure the smooth operation
    of Auto-GPT and the plugins you may choose to use, as those are all written for
    Python 3.10 and those expected modules that are also for 3.10\. In addition to
    installing Python 3.10, it is recommended to use virtual environments for Auto-GPT
    development. Virtual environments allow you to manage dependencies and Python
    versions on a project-by-project basis, ensuring that Auto-GPT runs in an isolated
    and controlled setting without affecting other Python projects you may be working
    on. This is crucial for maintaining compatibility and avoiding conflicts between
    different project requirements.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Auto-GPT 在文件大小上比较轻量，但根据你启用的选项和插件，它可能会消耗大量资源。因此，确保有一个兼容并且经过优化的环境对于保证 Auto-GPT
    及其插件的顺利运行至关重要，因为这些插件都是为 Python 3.10 编写的，并且那些预期的模块也都为 3.10 版本所准备。除了安装 Python 3.10，建议为
    Auto-GPT 开发使用虚拟环境。虚拟环境允许你按项目管理依赖项和 Python 版本，确保 Auto-GPT 在一个独立且可控的环境中运行，而不会影响你可能正在开发的其他
    Python 项目。这对于维护兼容性并避免不同项目要求之间的冲突至关重要。
- en: Why choose Python 3.10?
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 Python 3.10？
- en: 'Python 3.10 introduces several features and optimizations that are beneficial
    for running Auto-GPT. One such feature is the improved syntax for type hinting.
    In Python 3.10, you can use the pipe symbol, `|`, as a more concise way of indicating
    that a variable can be of multiple types. This is known as the **type** **union
    operator**:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3.10 引入了许多对运行 Auto-GPT 有利的功能和优化。其中一项功能是改进了类型提示的语法。在 Python 3.10 中，你可以使用管道符号
    `|` 作为一种更简洁的方式，表示一个变量可以是多种类型。这被称为 **类型** **联合操作符**：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example error message, Auto-GPT is attempting to use this new type union
    syntax, which is not supported in Python versions earlier than 3.10\. This is
    why using Python 3.9 results in a syntax error, as it cannot parse the new syntax.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例错误信息中，Auto-GPT 尝试使用这种新的类型联合语法，而该语法在 3.10 之前的 Python 版本中不被支持。这就是为什么使用 Python
    3.9 会导致语法错误，因为它无法解析新的语法。
- en: Additionally, Python 3.10 brings performance improvements, better error messages,
    and new features that can be advantageous for complex applications such as Auto-GPT.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Python 3.10 带来了性能改进、更好的错误信息以及对复杂应用程序（如 Auto-GPT）有利的新功能。
- en: Therefore, to avoid compatibility issues and take advantage of the new features
    and optimizations, it is crucial to install and set up Python 3.10 correctly before
    running Auto-GPT.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了避免兼容性问题并利用新功能和优化，正确安装和设置 Python 3.10 在运行 Auto-GPT 之前是至关重要的。
- en: Prerequisites for Python Installation
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 安装先决条件
- en: 'Before installing Python 3.10, it’s important to ensure that your system meets
    the necessary prerequisites. These prerequisites include the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 Python 3.10 之前，确保你的系统满足必要的先决条件非常重要。以下是这些先决条件：
- en: '**Sufficient disk space**: Make sure your system has an adequate amount of
    free disk space to accommodate the Python installation and any additional packages
    or libraries you may install in the future.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**足够的磁盘空间**：确保你的系统有足够的空闲磁盘空间来容纳Python安装以及你将来可能安装的任何附加包或库。'
- en: '**Checking for existing Python installations**: If you already have a previous
    version of Python installed on your system, it’s recommended to check for any
    potential conflicts or compatibility issues that may arise with Python 3.10\.
    You can do this by running the appropriate version-specific commands or using
    the Python version management tool for your **operating** **system** (**OS**).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检查现有的Python安装**：如果你的系统中已经安装了先前版本的Python，建议检查是否存在与Python 3.10的潜在冲突或兼容性问题。你可以通过运行适当的版本特定命令或使用操作系统的Python版本管理工具来检查。'
- en: By ensuring that your system meets these prerequisites, you can proceed with
    confidence to install Python 3.10 and set up Auto-GPT successfully.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你的系统满足这些先决条件后，你可以自信地继续安装Python 3.10并成功设置Auto-GPT。
- en: Installing Python 3.10
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装Python 3.10
- en: Auto-GPT is mostly based on Python 3.10 packages; if you try to run it with
    3.9 for example, you will only receive a few exceptions and you will not be able
    to execute Auto-GPT.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT主要基于Python 3.10包；如果你尝试使用3.9运行它，举例来说，你只会遇到一些异常，无法执行Auto-GPT。
- en: 'Running Python 3.10 requires a system that can support this version of the
    programming language. Here are the system requirements and installation instructions
    for each OS:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Python 3.10需要一个能够支持此版本编程语言的系统。以下是每个操作系统的系统要求和安装说明：
- en: For Windows, use the documentation at [https://www.digitalocean.com/community/tutorials/install-python-windows-10](https://www.digitalocean.com/community/tutorials/install-python-windows-10).
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Windows系统，请参考[https://www.digitalocean.com/community/tutorials/install-python-windows-10](https://www.digitalocean.com/community/tutorials/install-python-windows-10)的文档。
- en: 'To verify the installation, run the following command in the command prompt:'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要验证安装是否成功，请在命令提示符中运行以下命令：
- en: '[PRE1]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For installing Python 3.10 on Linux (Ubuntu/Debian), you may have to do a bit
    of research depending on what flavor of Linux you are using. But, as they say,
    with great power comes great responsibility; you may have to research how to enable
    Python 3.10 on your machine.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Linux（Ubuntu/Debian）上安装Python 3.10时，可能需要根据所使用的Linux发行版做一些研究。不过，正如人们所说，强大的能力带来的是巨大的责任；你可能需要研究如何在你的机器上启用Python
    3.10。
- en: 'For Ubuntu and Debian, here is the documentation on how to install 3.10: [https://www.linuxcapable.com/how-to-install-python-3-10-on-ubuntu-linux/](https://www.linuxcapable.com/how-to-install-python-3-10-on-ubuntu-linux/).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Ubuntu和Debian，关于如何安装3.10的文档可以在此找到：[https://www.linuxcapable.com/how-to-install-python-3-10-on-ubuntu-linux/](https://www.linuxcapable.com/how-to-install-python-3-10-on-ubuntu-linux/)。
- en: 'To verify if the installation was done successfully, run the following command:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要验证安装是否成功，请运行以下命令：
- en: '[PRE2]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The system should return Python 3.10.x.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 系统应该返回Python 3.10.x。
- en: Note
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The exact commands and steps might vary slightly based on the specific version
    of each OS. Always refer to the official Python documentation or your OS’s documentation
    for the most correct and up-to-date information.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 具体的命令和步骤可能会根据每个操作系统的版本略有不同。始终参考官方的Python文档或操作系统的文档，以获取最准确和最新的信息。
- en: Installing Poetry
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装Poetry
- en: A new dependency was recently added, which is a bit tricky to install.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最近添加了一个新的依赖项，安装起来有点复杂。
- en: 'Documentation on how to install it can be found here: [https://python-poetry.org/docs/#installing-with-pipx](https://python-poetry.org/docs/#installing-with-pipx).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如何安装的文档可以在这里找到：[https://python-poetry.org/docs/#installing-with-pipx](https://python-poetry.org/docs/#installing-with-pipx)。
- en: 'If you struggle to set it up (on Windows, for example), you may also try the
    Wizard script here: [https://github.com/Significant-Gravitas/AutoGPT_Wizard](https://github.com/Significant-Gravitas/AutoGPT_Wizard).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在设置过程中遇到困难（例如在Windows上），你也可以尝试这里的向导脚本：[https://github.com/Significant-Gravitas/AutoGPT_Wizard](https://github.com/Significant-Gravitas/AutoGPT_Wizard)。
- en: Additional requirements that may come up
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可能出现的额外要求
- en: Please check the official documentation at [https://docs.agpt.co/autogpt/setup/](https://docs.agpt.co/autogpt/setup/)
    to make sure you are not missing anything.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请检查官方文档：[https://docs.agpt.co/autogpt/setup/](https://docs.agpt.co/autogpt/setup/)，以确保没有遗漏任何内容。
- en: 'In addition to having a compatible version of Python and poetry installed on
    your system, it is also essential to ensure that your hardware meets specific
    minimum requirements for running Auto-GPT effectively:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在系统上安装兼容版本的 Python 和 poetry 外，还必须确保您的硬件符合运行 Auto-GPT 的特定最低要求：
- en: '**Processor (CPU)**: A modern multi-core processor (Intel Core i5/i7 or AMD
    Ryzen) is recommended for optimal performance when using Auto-GPT'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理器（CPU）**：推荐使用现代多核处理器（如 Intel Core i5/i7 或 AMD Ryzen），以实现在使用 Auto-GPT 时的最佳性能。'
- en: '**Memory (RAM)**: A minimum of 8 GB RAM is recommended; however, having more
    memory available will improve performance when working with large datasets or
    complex tasks'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存（RAM）**：建议至少有 8 GB RAM；然而，拥有更多可用内存将会提高处理大型数据集或复杂任务时的性能。'
- en: '**Storage**: Ensure sufficient free disk space on your computer’s primary storage
    drive (HDD/SSD) – at least several gigabytes – as Auto-GPT may generate temporary
    files during operation and require additional space for storing generated output
    files'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：确保计算机主存储驱动器（HDD/SSD）上有足够的空闲磁盘空间 — 至少数千兆字节 — 因为在操作期间 Auto-GPT 可能会生成临时文件，并且在存储生成的输出文件时可能需要额外空间。'
- en: '**Internet connection**: A stable internet connection with reasonable bandwidth
    is necessary since Auto-GPT communicates with OpenAI’s API to access GPT models
    and generate text'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**互联网连接**：Auto-GPT 通信需要稳定且带有合理带宽的互联网连接，以便访问 OpenAI 的 API 来使用 GPT 模型并生成文本。'
- en: '**GPU support (optional)**: While not strictly required, having a compatible
    NVIDIA or AMD GPU can significantly improve the performance of certain tasks,
    such as using text-to-speech engines such as Silero **Text-to-Speech** (**TTS**)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPU 支持（可选）**：虽然不是严格要求，但拥有兼容的 NVIDIA 或 AMD GPU 可显著提高某些任务的性能，例如使用 Silero **文本转语音**（**TTS**）引擎。'
- en: By ensuring that your system meets these requirements and prerequisites, you
    will be well prepared to install and use Auto-GPT effectively.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过确保您的系统符合这些要求和先决条件，您将能够有效地安装和使用 Auto-GPT。
- en: In the next sections, we will guide you through the installation process for
    Auto-GPT on various OSs and provide an overview of basic concepts and terminology
    related to Auto-GPT and its underlying technology.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将为您介绍如何在各种操作系统上安装 Auto-GPT，并提供与 Auto-GPT 及其底层技术相关的基本概念和术语概述。
- en: Remember that while these system requirements and prerequisites are designed
    to provide a smooth experience when using Auto-GPT, individual needs may vary
    depending on the specific tasks you plan to perform with the tool. For example,
    if you intend to use Auto-GPT for large-scale text generation or complex **natural
    language processing** (**NLP**) tasks, you might benefit from having a more powerful
    CPU or additional memory available.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，虽然这些系统要求和先决条件旨在在使用 Auto-GPT 时提供流畅的体验，但具体任务的个体需求可能会有所不同。例如，如果您打算用 Auto-GPT
    进行大规模文本生成或复杂的**自然语言处理**（**NLP**）任务，您可能会受益于拥有更强大的 CPU 或额外的可用内存。
- en: In any case, it is always a good idea to monitor your system’s performance while
    using Auto-GPT and adjust your hardware configuration as needed. This will help
    ensure that you can make the most of this powerful AI-driven text generation tool
    without meeting performance bottlenecks or other issues.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，在使用 Auto-GPT 时，随时监视系统性能并根据需要调整硬件配置都是一个好主意。这将有助于确保您能够充分利用这款强大的基于 AI 的文本生成工具，而不会遇到性能瓶颈或其他问题。
- en: 'Before installing and setting up Auto-GPT on your system, do the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装和设置 Auto-GPT 在您的系统上之前，请执行以下操作：
- en: Ensure that your OS (macOS, Linux/Ubuntu/Debian, Windows) meets the minimum
    requirements for running Python 3.10.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保您的操作系统（macOS、Linux/Ubuntu/Debian、Windows）满足运行 Python 3.10 的最低要求。
- en: Install Python 3.10.x, following the instructions provided for each OS.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Python 3.10.x，按照每个操作系统提供的指示进行操作。
- en: Verify that Python 3.10.x has been installed correctly by checking its version
    in Terminal (macOS/Linux) or Command Prompt (Windows).
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在终端（macOS/Linux）或命令提示符（Windows）中检查其版本，验证 Python 3.10.x 是否已正确安装。
- en: Make sure your hardware meets minimum requirements such as processor (CPU),
    memory (RAM), storage space availability, and internet connection stability/bandwidth.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保您的硬件符合最低要求，如处理器（CPU）、内存（RAM）、存储空间可用性以及互联网连接的稳定性/带宽。
- en: This step is optional. Consider GPU support if planning to use resource-intensive
    features such as text-to-speech engines or a local LLM such as Vicuna or LLAMA
    (this is an interesting topic, as most GPUs cannot handle an LLM that’s usable
    with Auto-GPT).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一步是可选的。如果计划使用资源密集型功能，如语音合成引擎或本地LLM（如Vicuna或LLAMA），可以考虑GPU支持（这是一个有趣的话题，因为大多数GPU无法处理与Auto-GPT兼容的LLM）。
- en: By following these guidelines carefully and ensuring that your system meets
    all requirements and prerequisites before installing Auto-GPT, you will be well
    prepared for a successful installation process and an enjoyable experience using
    this powerful AI-driven text generation tool.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细遵循这些指南，并确保在安装Auto-GPT之前系统满足所有要求和前置条件，你将为成功安装并愉快地使用这个强大的AI驱动文本生成工具做好充分准备。
- en: In our next sections, we will guide you through every step of getting started
    with this incredible software – from installation procedures tailored specifically
    for each OS to understanding the fundamental concepts and terminology that underpin
    Auto-GPT’s functionality.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将引导你完成每个步骤，帮助你开始使用这个令人惊叹的软件——从为每个操作系统量身定制的安装程序，到理解Auto-GPT功能背后的基本概念和术语。
- en: Installing and setting up Auto-GPT
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和设置Auto-GPT
- en: 'Here are the steps to install Auto-GPT:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是安装Auto-GPT的步骤：
- en: Depending on your experience, you may want to either use Git directly and clone
    the repository from [https://github.com/Significant-Gravitas/Auto-GPT.git](https://github.com/Significant-Gravitas/Auto-GPT.git).
    Or, if you are less experienced with the Terminal, you may go to [https://github.com/Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT).
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据你的经验，你可能想要直接使用Git并从[https://github.com/Significant-Gravitas/Auto-GPT.git](https://github.com/Significant-Gravitas/Auto-GPT.git)克隆仓库。或者，如果你对终端不太熟悉，你可以访问[https://github.com/Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)。
- en: On the top right, click on `.zip` file, and save it anywhere you want Auto-GPT’s
    folder to be. Then, simply unpack the `.``zip` file.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右上角点击`.zip`文件，并将其保存到你希望存放Auto-GPT文件夹的任何位置。然后，简单地解压`.zip`文件。
- en: If you want to be 100% sure that you are on the most stable version, go to [https://github.com/Significant-Gravitas/Auto-GPT/releases/latest](https://github.com/Significant-Gravitas/Auto-GPT/releases/latest).
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想100%确保使用的是最稳定的版本，请访问[https://github.com/Significant-Gravitas/Auto-GPT/releases/latest](https://github.com/Significant-Gravitas/Auto-GPT/releases/latest)。
- en: Pick the latest release (in our case, 0.4.1) download the `.zip` file in the
    **Assets** section of that post, and unzip it.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最新的版本（在我们的例子中是0.4.1），在该帖子的**Assets**部分下载`.zip`文件并解压。
- en: The latest version that I used was release v0.4.7; anything above that version
    may be restructured, for example, 0.5.0 already has the Auto-GPT folder inside
    `Auto-GPT/autogpts/autogpt`. For closer inspection, read the updated `README`
    and documentation inside the repository itself to see which version you are looking
    at.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我使用的最新版本是v0.4.7；任何更高版本可能已重新结构化，例如，0.5.0版本已经将Auto-GPT文件夹放在了`Auto-GPT/autogpts/autogpt`中。为了更详细地了解，阅读仓库中的更新版`README`和文档，查看你正在使用的版本。
- en: Installing Auto-GPT
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装Auto-GPT
- en: For a fast-growing project, the installation of Auto-GPT may differ, so if you
    have any trouble with the following guide, try to check [https://docs.agpt.co/](https://docs.agpt.co/)
    if anything has changed.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个快速发展的项目，Auto-GPT的安装可能会有所不同，因此如果你在按照以下指南操作时遇到问题，可以查看[https://docs.agpt.co/](https://docs.agpt.co/)了解是否有任何变化。
- en: As Auto-GPT on its own comes with a variety of Python dependencies, you may
    now want to navigate to your Auto-GPT folder in a Terminal.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Auto-GPT本身包含多种Python依赖项，你现在可能想要在终端中导航到你的Auto-GPT文件夹。
- en: 'Using Auto-GPT with Docker, do the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker运行Auto-GPT，请按以下步骤操作：
- en: Some developers use Dockerfile directly, but I (as a Docker newbie) recommend
    using `docker-compose.yml`, which some folks have added.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些开发者直接使用Dockerfile，但我（作为Docker新手）推荐使用`docker-compose.yml`，这是一些人添加的。
- en: Make sure you have Docker installed (go back to *Installing Docker* in the previous
    chapter).
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你已安装Docker（请回到上一章节的*安装Docker*部分）。
- en: 'Simply navigate into the Auto-GPT folder and run the following commands:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只需进入Auto-GPT文件夹，运行以下命令：
- en: '[PRE3]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: I am giving `–gpt3only` as an example only to make sure we don’t spend any money
    yet, as I assume you have just created your OpenAI account, which grants a free
    $5 starting bonus.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我提供`–gpt3only`仅仅是为了确保我们现在不花费任何钱，因为我假设你刚创建了OpenAI账户，并获得了5美元的免费起始奖金。
- en: Using Docker to pull the Auto-GPT image
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Docker拉取Auto-GPT镜像
- en: Here, let’s ensure you have Docker installed on your system. If you are not
    sure, you can jump to [*Chapter 6*](B21128_06.xhtml#_idTextAnchor091), where I
    cover how to set up Docker on your machine and give you some extra tips on using
    Docker with Auto-GPT.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，让我们确保你的系统上安装了 Docker。如果不确定，你可以跳到 [*第6章*](B21128_06.xhtml#_idTextAnchor091)，我会在其中介绍如何在你的机器上设置
    Docker，并给出一些关于如何在 Auto-GPT 中使用 Docker 的额外提示。
- en: 'If you have Docker installed, do the following steps:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经安装了 Docker，请执行以下步骤：
- en: 'Create a project directory for Auto-GPT:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 Auto-GPT 创建一个项目目录：
- en: '[PRE4]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Create the necessary configuration files. You can find templates in the repository.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建必要的配置文件。你可以在仓库中找到模板。
- en: 'Pull the latest image from Docker Hub:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Docker Hub 拉取最新镜像：
- en: '[PRE5]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Run with Docker according to the instructions given in the documentation.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照文档中的指示使用 Docker 运行。
- en: Cloning Auto-GPT using Git
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Git 克隆 Auto-GPT
- en: Assuming you have Git installed on your system (doesn’t come natively on Windows
    for example), we will cover the process of cloning Auto-GPT here.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经在系统上安装了 Git（例如 Windows 系统默认不带 Git），我们将在这里介绍如何克隆 Auto-GPT。
- en: 'Let’s ensure you have Git installed for your OS:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确保你的操作系统已安装 Git：
- en: 'We need to first clone the repository with the help of the following command:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先需要借助以下命令来克隆仓库：
- en: '[PRE6]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we will navigate to the directory where you downloaded the repository:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将导航到你下载仓库的目录：
- en: '[PRE7]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Without Git/Docker
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 未使用 Git/Docker
- en: 1\. Download the source code (the `.zip` file) from the latest stable release.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 从最新的稳定版本下载源代码（`.zip` 文件）。
- en: 2\. Extract the zipped file into a folder.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 将压缩文件解压到一个文件夹中。
- en: 'Next, we will navigate to the directory where you downloaded the repository:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将导航到你下载仓库的目录：
- en: '[PRE8]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: From here, depending on the version you may install, Auto-GPT could be inside
    the `Auto-GPT/autogpts/autogpt` folder, as the main repository was turned into
    more of a framework to be used to create other `Auto-GPT` instances. The Auto-GPT
    project we discuss in this book is inside the folder mentioned previously.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，根据你可能安装的版本，Auto-GPT 可能位于 `Auto-GPT/autogpts/autogpt` 文件夹中，因为主仓库已被转变为一个框架，用于创建其他
    `Auto-GPT` 实例。我们在本书中讨论的 Auto-GPT 项目位于前述文件夹中。
- en: Configuration
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置
- en: 'Here is how we configuration happens:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们如何进行配置：
- en: Find the file named `.env.template` in the main Auto-GPT folder.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主 Auto-GPT 文件夹中找到名为 `.env.template` 的文件。
- en: Create a copy of `.env.template` and rename it `.env`.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `.env.template` 的副本，并将其重命名为 `.env`。
- en: Open the `.env` file in a text editor. If you have not already, investigate
    using VS Code, for example, so that you can just open Auto-GPT as a project and
    edit anything you need to.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文本编辑器中打开 `.env` 文件。如果还没有，建议使用 VS Code 之类的工具，这样你就可以将 Auto-GPT 作为项目打开，并编辑你需要的任何内容。
- en: Find the line that says `OPENAI_API_KEY=`.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到包含 `OPENAI_API_KEY=` 的那一行。
- en: Enter your unique OpenAI API key after the `=` symbol without any quotes or
    spaces.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `=` 符号后输入你的唯一 OpenAI API 密钥，不要加引号或空格。
- en: If you use multiple Auto-GPT instances (which can be easily done with just another
    `auto-gpt` folder; it is best to create multiple API keys), you can make sure
    you keep an eye on the costs of each instance.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用多个 Auto-GPT 实例（只需另建一个 `auto-gpt` 文件夹即可轻松实现，最好创建多个 API 密钥），你可以确保关注每个实例的费用。
- en: Depending on which GPT model you have access to, you must now change the `FAST_LLM_MODEL`
    and `SMART_LLM_MODEL` attributes the same way we just did with the API key.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据你可以访问的 GPT 模型，你现在需要像我们刚才对 API 密钥所做的那样，修改 `FAST_LLM_MODEL` 和 `SMART_LLM_MODEL`
    属性。
- en: To find out which models are available to you, go to [https://platform.openai.com/account/rate-limits](https://platform.openai.com/account/rate-limits).
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要了解哪些模型对你可用，请访问 [https://platform.openai.com/account/rate-limits](https://platform.openai.com/account/rate-limits)。
- en: It only lists the ones you can use.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它只列出了你可以使用的项。
- en: As of writing this chapter, OpenAI has just released a 16 K model of gpt-3.5-turbo-16k.
    It can carry more tokens/words than GPT-4 can, but I generally feel like the output
    is still worse than GPT-4’s, as Auto-GPT tends to do random tasks that it makes
    up out of nowhere.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 截至写这章时，OpenAI 刚刚发布了一个 16 K 模型的 gpt-3.5-turbo-16k。它可以处理比 GPT-4 更多的令牌/单词，但我通常认为其输出仍不如
    GPT-4，因为 Auto-GPT 倾向于执行一些它凭空编造的随机任务。
- en: The issue lies in the context process ability, although it can work with more
    tokens, GPT-4 has far more parameters than it works with and is much more optimized.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 问题出在上下文处理能力上，尽管它可以处理更多的令牌，GPT-4 的参数更多，并且经过了更多优化。
- en: The default number of tokens is 4,000 if you set GPT-3.5-Turbo as a model and
    8,000 tokens if you set GPT-4 as a model, but I do recommend setting those limits
    slightly below those.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置GPT-3.5-Turbo作为模型，则默认的令牌数量为4,000；如果设置GPT-4作为模型，则为8,000令牌，但我建议将这些限制稍微调低。
- en: For example, 7,000 instead of 8,000 gives less room for memory summarization
    on the `SMART_LLM_MODEL`, while still making sure there are no exceptions where
    more words or tokens slip through to the Chat Completion prompt.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用7,000而不是8,000令牌，在`SMART_LLM_MODEL`上会减少内存摘要的空间，同时仍确保没有更多的单词或令牌溢出到Chat Completion提示中。
- en: Auto-GPT has introduced customizing options such as disallowing certain commands
    or which text-to-speech engine you want to use.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 引入了自定义选项，比如禁止某些命令或选择你想要使用的文本转语音引擎。
- en: Having speech enabled makes Auto-GPT talk to you via voice. The choice of which
    TTS engine to use is all yours. I prefer Silero TTS, as it is almost as good as
    ElevenLabs but it is completely free to use; you just need a computer with a powerful
    CPU and/or GPU (you can select whether to use CPU or GPU for the TTS model).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 启用语音功能使得Auto-GPT可以通过语音与您对话。选择使用哪个TTS引擎完全由您决定。我个人更喜欢Silero TTS，它几乎与ElevenLabs一样优秀，而且完全免费；只需要一台具有强大CPU和/或GPU的计算机（您可以选择是否使用CPU或GPU来进行TTS模型的处理）。
- en: As you already may have noticed, Auto-GPT comes with a huge set of terminologies
    that come from the world of AI and machine learning. We will now cover some of
    the most frequent ones here.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，Auto-GPT带有大量来自人工智能和机器学习领域的术语。接下来我们将介绍一些最常见的术语。
- en: Basic concepts and terminologies
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本概念和术语
- en: 'Before we start using Auto-GPT, let’s review some basic concepts and terminologies
    that will help us understand how it works:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用Auto-GPT之前，让我们回顾一些基本的概念和术语，以帮助我们理解它是如何工作的：
- en: '**Text generation**: Text generation is the task of creating natural language
    text from given input data or context. For example, given a topic, a genre, or
    a prompt, text generation can produce a paragraph, an article, a story, or a dialogue
    that matches the input.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成**：文本生成是根据给定的输入数据或上下文创建自然语言文本的任务。例如，给定一个主题、体裁或提示，文本生成可以生成一段文字、一篇文章、一则故事或一段对话，且与输入相匹配。'
- en: '**Model**: A model is a mathematical representation of a system or a process
    that can be used to make predictions or decisions. In machine learning, a model
    is a function that maps an input to an output. For example, a model can take an
    image as an input and output a label that describes what is in the image.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：模型是一个系统或过程的数学表示，用来做出预测或决策。在机器学习中，模型是一个将输入映射到输出的函数。例如，一个模型可以将图像作为输入，输出描述图像内容的标签。'
- en: '**Chain of thought**: This concept is centered on the progressive development
    and refining of ideas or solutions through the systematic and sequential application
    of thought processes. In the context of using a tool such as ChatGPT, a “chain
    of thought” approach would involve feeding the output from one query as the input
    to the next query, essentially creating a “chain” of evolving responses.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维链**：这一概念着眼于通过系统化和顺序应用思维过程，逐步发展和完善思想或解决方案。在使用像ChatGPT这样的工具时，“思维链”方法会将一个查询的输出作为下一个查询的输入，实质上创建一个“链条”般不断演进的回答。'
- en: This method allows for the deep exploration of a topic or problem, as each step
    in the chain builds upon the previous, potentially leading to more nuanced and
    sophisticated results. It could be particularly useful in tasks such as developing
    a complex narrative, iteratively refining a model, or exploring multiple angles
    of a problem before settling on a solution.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种方法允许对一个主题或问题进行深度探索，因为链条中的每个步骤都建立在前一个步骤的基础上，可能会导致更细致、更复杂的结果。这在一些任务中尤其有用，例如开发复杂的叙事、迭代优化模型，或在确定解决方案之前，从多个角度探讨问题。
- en: '**Tree of thought**: A strategy to retrieve much better results in text generation,
    ChatGPT for example, is to instruct it to solve a problem and provide multiple
    alternatives. This can be achieved by saying “Write four alternatives, assess
    them, and improve.” This simple instruction tells the model to be creative and
    create four alternatives to an already given solution, evaluate them, and then
    encourage it to output an improved solution instead of just one answer.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维树**：一种用于在文本生成中获得更好结果的策略，例如ChatGPT，可以通过指示它解决一个问题并提供多个替代方案来实现。这可以通过说“写四个替代方案，评估它们并加以改进”来实现。这个简单的指令告诉模型要具备创造力，生成四个替代方案来替代已给出的解决方案，评估它们，并鼓励模型输出一个改进后的解决方案，而不仅仅是一个答案。'
- en: This results in much more accurate output and can be chained and done multiple
    times. For instance, I was working on a new neural cell network prototype and
    asked ChatGPT to help me with the data transformer method that would receive a
    string (text) and apply it to multiple matrixes. The first result was bad and
    wasn’t even correct Python code, but after three or four iterations of saying
    “Write 4 alternatives that may improve that code and improve its strategy, assess
    them, rate them from 1-10, rank them, then improve,” this resulted in very clean
    code and it even gave me improvement ideas on how to make the code more performant
    after the second iteration, which it wouldn’t have done if I just asked it straight
    away.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样可以产生更准确的输出，并且可以进行多次迭代。例如，我在开发一个新的神经元单元网络原型时，请求ChatGPT帮助我设计一个数据转换方法，该方法会接收一个字符串（文本）并将其应用到多个矩阵上。第一次的结果不好，甚至不是正确的Python代码，但经过三四次迭代，每次说“写四个可能改进该代码的替代方案并改进其策略，评估它们，给它们打分1到10，排名，然后改进”，最终得到了非常干净的代码，甚至在第二次迭代后，它还给了我一些提高代码性能的改进建议，这些是我如果直接要求它的话，它是不会提供的。
- en: '**Forest of thought**: This one builds on top of the principle of the tree
    of thought but as the name already suggests, you have multiple instances that
    think like a group of people. A fantastic explanation can be found in this video
    I watched recently: [https://www.youtube.com/watch?v=y6SVA3aAfco](https://www.youtube.com/watch?v=y6SVA3aAfco).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维森林**：这一概念建立在思维树的原则基础上，但正如其名称所示，它有多个实例，像一群人一样进行思考。我最近观看的这个视频中有一个精彩的解释：[https://www.youtube.com/watch?v=y6SVA3aAfco](https://www.youtube.com/watch?v=y6SVA3aAfco)。'
- en: '**Neural network**: A neural network is a type of model that consists of interconnected
    units called **neurons**. Each neuron can perform a simple computation on its
    inputs and produce an output. By combining neurons in different layers and configurations,
    a neural network can learn complex patterns and relationships from data. GPT,
    for instance, has multiple neural networks running that all have different tasks
    and consist of multiple layers of neural networks.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络**：神经网络是一种由互联的单元（称为**神经元**）组成的模型。每个神经元可以对输入执行简单的计算并生成输出。通过在不同层次和配置中组合神经元，神经网络可以从数据中学习复杂的模式和关系。例如，GPT就有多个神经网络在运行，它们各自有不同的任务，并且由多个神经网络层次组成。'
- en: '**Deep learning**: Developed by OpenAI, **Generative Pre-Trained Transformer
    3** (**GPT-3**) stands as a monumental figure in the realm of NLP. This deep learning
    model, boasting a staggering 175 billion parameters and a vast training dataset
    of 45 terabytes, is renowned for its text generation capabilities, offering coherence
    and versatility across a myriad of topics, genres, and styles. Despite anticipation
    surrounding its successor, GPT-4, which promises enhanced context understanding
    and logical processing, GPT-3 remains a formidable tool, especially for smaller
    tasks. Its recent upgrade to process up to 16 K tokens has notably enhanced output
    quality, although it is advised to avoid overwhelming the model with excessive
    input data to prevent confusion.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习**：由OpenAI开发的**生成预训练变换器3**（**GPT-3**）是自然语言处理领域的一个里程碑。这一深度学习模型具有惊人的1750亿个参数，并拥有45TB的庞大训练数据集，以其文本生成能力而著称，能够在各种话题、体裁和风格中提供连贯性和多样性。尽管人们对其继任者GPT-4充满期待，GPT-4承诺增强上下文理解和逻辑处理能力，但GPT-3仍然是一个强大的工具，特别适用于较小的任务。最近的升级使其能够处理多达16K的tokens，显著提升了输出质量，尽管建议避免给模型输入过多数据，以免导致混乱。'
- en: '**GPT-3**: GPT-3 is a deep learning model for NLP that was developed by OpenAI.
    It is one of the largest and most powerful models for text generation, with 175
    billion parameters and 45 terabytes of training data. GPT-3 can generate coherent
    and diverse text for almost any topic, genre, or style. It is continuously improved
    by OpenAI, and although the successor GPT-4 may have more capability in terms
    of context size and logic, it is a faster model and still very useful for small
    tasks. It can now process 16 K tokens, but I found that this strength is more
    useful on outputs and not input data. This means the model gets confused quickly
    when too much information is provided at once.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-3**：GPT-3是由OpenAI开发的一种深度学习自然语言处理模型。它是文本生成领域最大、最强大的模型之一，拥有1750亿个参数和45TB的训练数据。GPT-3能够为几乎任何主题、类型或风格生成连贯且多样的文本。OpenAI不断改进该模型，尽管后继的GPT-4在上下文处理能力和逻辑推理方面可能更强大，但它仍然是一个更快速、非常适用于小型任务的模型。它现在可以处理16K个tokens，但我发现这个优势更多体现在输出而非输入数据上。这意味着当一次提供过多信息时，模型会很快感到困惑。'
- en: '**GPT-4**: This is a successor to GPT-3, which is far more powerful for text
    generation. It has 170 trillion parameters, almost 1,000 times more than GPT-3\.
    This model receives all plugins and a Bing browser functionality, which allows
    it to research information on its own. OpenAI is being very secretive about some
    details, as it is yet unknown how it works in detail. Some resources and papers
    suggest that it works recursively and learns with each input it gets.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4**：这是GPT-3的继任者，在文本生成方面更强大。它有170万亿个参数，是GPT-3的近1,000倍。这个模型支持所有插件，并具备Bing浏览器功能，使其能够自主进行信息搜索。OpenAI在一些细节上非常保密，目前尚不清楚它具体是如何工作的。一些资源和论文表明，它是递归运作的，并且随着每次输入不断学习。'
- en: '**Auto-GPT**: Auto-GPT is a tool that automates the process of text generation
    using OpenAI’s Chat Completion API, mainly with GPT-4\. It allows you to specify
    your input text and parameters that control the output text, such as length, tone,
    format, and keywords. Auto-GPT then sends your input text and parameters to the
    GPT-3 model via the OpenAI API and receives the generated text as a response.
    Auto-GPT also supplies features to help you edit and improve the generated text,
    such as suggestions, feedback, and rewriting:'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Auto-GPT**：Auto-GPT是一个自动化文本生成工具，使用OpenAI的聊天完成API，主要与GPT-4一起使用。它允许你指定输入文本和控制输出文本的参数，如长度、语气、格式和关键词。Auto-GPT随后通过OpenAI
    API将你的输入文本和参数发送给GPT-3模型，并获取生成的文本作为回应。Auto-GPT还提供了一些功能，帮助你编辑和改进生成的文本，例如建议、反馈和重写：'
- en: '**Plugins**: Extensions that can be loaded into Auto-GPT to add more functionality.'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插件**：可以加载到Auto-GPT中的扩展程序，用以增加更多功能。'
- en: '**Headless browser**: A web browser without a graphical user interface, used
    for automated tasks.'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无头浏览器**：一种没有图形用户界面的网页浏览器，用于自动化任务。'
- en: '**Workspace**: The directory where Auto-GPT saves files and data.'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作空间**：Auto-GPT保存文件和数据的目录。'
- en: '**API key**: An API key is a unique identifier used to authenticate a user,
    developer, or calling program during an API request. This key helps in tracking
    and controlling how the API is being used, to prevent abuse and ensure security.
    Essentially, it acts as a password that grants access to specific services or
    data, facilitating seamless and secure communication between different software
    components. It is paramount that API keys are kept confidential to prevent unauthorized
    access and potential misuse.'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API密钥**：API密钥是一个用于在API请求中验证用户、开发者或调用程序的唯一标识符。这个密钥有助于跟踪和控制API的使用，防止滥用并确保安全。它本质上就像一个密码，允许访问特定服务或数据，促进不同软件组件之间的无缝和安全的通信。必须将API密钥保密，以防止未经授权的访问和潜在的滥用。'
- en: First run of Auto-GPT on your machine
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在你的机器上首次运行Auto-GPT
- en: 'To run Auto-GPT, you need to use one of the commands, depending on your OS.
    Use `run.sh` for Linux or macOS, and `run.bat` for Windows. Alternatively, you
    can just run the following on your console. Navigate into the Auto-GPT folder
    (not the one inside – I know the folder structure can be misleading sometimes),
    and execute the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行Auto-GPT，你需要根据操作系统使用不同的命令。Linux或macOS使用`run.sh`，Windows使用`run.bat`。另外，你也可以直接在控制台中运行以下命令。进入Auto-GPT文件夹（不是里面的那个——我知道文件结构有时可能让人误解），然后执行以下命令：
- en: '[PRE9]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You may also execute the “autogpt.bat” or “autogpt.sh” script inside the “autogpts/autogpt”
    folder.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在“autogpts/autogpt”文件夹内执行“autogpt.bat”或“autogpt.sh”脚本。
- en: 'If you are not sure whether your default Python is Python 3.10, or if the preceding
    command returns an error, you can check that with the `python –V` command. Should
    you get anything but Python 3.10, you can run this instead:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不确定默认的 Python 是否是 Python 3.10，或者如果前面的命令返回错误，可以使用 `python –V` 命令检查。如果返回的是除
    Python 3.10 以外的内容，你可以运行以下命令：
- en: '[PRE10]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For any OS, you can also use `docker-compose` if you have Docker installed.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何操作系统，如果你已安装 Docker，还可以使用 `docker-compose`。
- en: 'You can also pass some arguments to customize your Auto-GPT experience, such
    as the following:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以传递一些参数来定制你的 Auto-GPT 体验，例子包括：
- en: '`–gpt3only` to use GPT-3.5 instead of GPT-4'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–gpt3only` 使用 GPT-3.5 代替 GPT-4'
- en: '`–speak` to enable text-to-speech output'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–speak` 启用语音输出'
- en: '`–continuous` to run Auto-GPT without user authorization (not recommended)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–continuous` 用于在没有用户授权的情况下运行 Auto-GPT（不推荐）'
- en: '`–debug` to print out debug logs and more'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–debug` 打印调试日志及更多信息'
- en: You can use `–help` to see the full list of arguments
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用 `–help` 查看完整的参数列表
- en: You can also change the Auto-GPT settings in your `.env` file, such as `SMART_LLM_MODEL`
    to choose the language model, `DISABLED_COMMAND_CATEGORIES` to disable command
    groups such as `auto`, and more. You can find the template and explanation of
    each setting in your `.``env.template` file.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在 `.env` 文件中更改 Auto-GPT 设置，例如 `SMART_LLM_MODEL` 选择语言模型，`DISABLED_COMMAND_CATEGORIES`
    禁用如 `auto` 等命令组，等等。你可以在 `.env.template` 文件中找到每个设置的模板和说明。
- en: When you first start Auto-GPT, you’ll be prompted to provide a name, AI role,
    and goals. These fields are automated by default, meaning you can issue commands
    directly.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当你首次启动 Auto-GPT 时，系统会提示你提供名称、AI 角色和目标。默认情况下，这些字段是自动填充的，意味着你可以直接发出命令。
- en: 'For example, to research Wladastic, the author of *Unlocking the Power of Auto-GPT
    and its Plugins*, and write the results into a text file, you could issue the
    following command:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要研究 *Unlocking the Power of Auto-GPT and its Plugins* 的作者 Wladastic，并将结果写入文本文件，你可以发出以下命令：
- en: '[PRE11]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Auto-GPT will then try to generate the `ai_settings.yaml` file; if it fails,
    you will be asked to supply the name of the instance, five main goals of `ai_settings`,
    and the role that influences the behavior of the instance.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，Auto-GPT 会尝试生成 `ai_settings.yaml` 文件；如果失败，你将被要求提供实例的名称、`ai_settings` 的五个主要目标以及影响实例行为的角色。
- en: Make sure to be extremely specific and detailed in your prompts. When using
    Auto-GPT, I tend to edit the `ai_settings.yaml` file manually and it works very
    well with longer instructions as well as more than 5 goals (this is just a default
    thing, as it was developed when only GPT-3.5 was available, which has a much lower
    token limit)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在提示中非常具体和详细。使用 Auto-GPT 时，我倾向于手动编辑 `ai_settings.yaml` 文件，它对于较长的指令以及超过 5 个目标非常有效（这是默认设置，因为它是在只有
    GPT-3.5 可用时开发的，GPT-3.5 的令牌限制要低得多）。
- en: Feel free to research ChatGPT prompting guides to learn how to make Auto-GPT
    as efficient as possible. Unclear and “too short” prompts may result in Auto-GPT
    hallucinating or just doing very wrong stuff such as “research for my homework,”
    which may result in various steps such as asking the user (you) about what exactly
    you want, and this will all generate costs on your OpenAI account.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 可以自由查阅 ChatGPT 提示指南，了解如何让 Auto-GPT 达到最高效率。模糊或“过于简短”的提示可能导致 Auto-GPT 出现幻觉或执行错误的操作，比如“为我的作业做研究”，这可能会导致多个步骤，例如询问用户（你）具体想要什么，这些操作将会在你的
    OpenAI 账户上产生费用。
- en: Summary
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: In this comprehensive chapter, we delved into the installation and setup of
    Auto-GPT across various OSs, including Windows, macOS, and Linux, equipping you
    with the essential knowledge to get started. We began by outlining the system
    requirements for each platform and provided detailed instructions for installing
    Python 3.10, which is crucial for running Auto-GPT. Our guide included different
    methods to obtain Auto-GPT, such as cloning the repository via Git or downloading
    it from GitHub as a ZIP file.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章节中，我们深入探讨了如何在各种操作系统上安装和设置 Auto-GPT，包括 Windows、macOS 和 Linux，帮助你掌握启动所需的基本知识。我们首先概述了每个平台的系统要求，并提供了详细的
    Python 3.10 安装说明，这对于运行 Auto-GPT 至关重要。我们的指南还包括了获取 Auto-GPT 的不同方法，比如通过 Git 克隆仓库或从
    GitHub 下载 ZIP 文件。
- en: Once you had Auto-GPT on your system, we led you through its installation using
    Docker (recommended), Git, or without either. We also explained the process of
    configuring your `.env` file with your unique OpenAI API key and settings for
    GPT models in the `FAST_LLM_MODEL` and `SMART_LLM_MODEL` attributes.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在系统上安装了 Auto-GPT，我们将带你通过使用 Docker（推荐）、Git 或不使用任何工具的方式进行安装。我们还解释了如何配置 `.env`
    文件，输入你独特的 OpenAI API 密钥，并在 `FAST_LLM_MODEL` 和 `SMART_LLM_MODEL` 属性中设置 GPT 模型。
- en: After successfully setting up Auto-GPT, we introduced the fundamental concepts
    of text generation models such as GPT-3/GPT-4 from OpenAI, discussing neural networks,
    deep learning models for NLP, and the text generation tasks these models perform.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功设置 Auto-GPT 后，我们介绍了文本生成模型的基本概念，如 OpenAI 的 GPT-3/GPT-4，讨论了神经网络、用于自然语言处理（NLP）的深度学习模型，以及这些模型执行的文本生成任务。
- en: The chapter further explored additional Auto-GPT features, including plugins
    that enhance its functionality, headless browsers for automated tasks, workspaces
    for file management, and API keys for secure access to OpenAI’s services.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 本章进一步探讨了额外的 Auto-GPT 功能，包括增强其功能的插件、用于自动化任务的无头浏览器、用于文件管理的工作区以及用于安全访问 OpenAI 服务的
    API 密钥。
- en: Finally, we demonstrated running your first AI-generated task with Auto-GPT,
    highlighting its ease of use and power as a tool. We concluded the chapter by
    preparing you for our next sections, which will dive deeper into advanced Auto-GPT
    features, such as customization for specific needs and working with various plugins
    to broaden its capabilities. By mastering these aspects and effectively harnessing
    the power of AI-generated text, you’ll be well equipped for a range of tasks,
    from automating content creation to generating engaging narratives based on prompts.
    Stay tuned as we continue exploring the full potential of Auto-GPT in our upcoming
    chapters.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们演示了如何使用 Auto-GPT 执行第一个 AI 生成的任务，突出了其作为工具的易用性和强大功能。我们以为你准备好接下来的章节作为结束，接下来的章节将深入探讨高级
    Auto-GPT 功能，比如针对特定需求的定制和与各种插件的协作，以扩展其能力。通过掌握这些方面，并有效利用 AI 生成文本的力量，你将能够胜任一系列任务，从自动化内容创作到根据提示生成引人入胜的叙述。敬请期待我们即将发布的章节，继续探索
    Auto-GPT 的全部潜力。
- en: Building upon the foundational knowledge acquired about installing and configuring
    Auto-GPT, as well as understanding text generation models, the next chapter we
    will explore is titled *Mastering Prompt Generation and Understanding How Auto-GPT
    Generates Prompts*. This chapter promises to deepen your understanding of prompt
    generation, a crucial skill for maximizing the potential of Auto-GPT. It will
    demystify the mechanics behind Auto-GPT’s prompt generation and offer guidance
    on crafting effective prompts to enhance your interactions with this advanced
    language model.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了安装和配置 Auto-GPT 的基础知识，并了解了文本生成模型后，接下来我们将探索的章节标题是 *掌握提示生成并理解 Auto-GPT 如何生成提示*。本章将加深你对提示生成的理解，这是最大化
    Auto-GPT 潜力的关键技能。它将揭开 Auto-GPT 提示生成背后的机制，并提供有效构建提示的指导，从而增强你与这个高级语言模型的互动。
