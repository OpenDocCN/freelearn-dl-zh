- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Image Classification with Neural Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络进行图像分类
- en: 'Up until this point, we have built models to solve both regression and classification
    problems on structured data with much success. The next question that comes to
    mind is: can we build models that can tell the difference between a dog and a
    cat, or a car and a plane? Today, with the aid of frameworks such as **TensorFlow**
    and **PyTorch**, developers can now build such ML solutions with a few lines of
    code.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经成功地构建了用于解决结构化数据的回归和分类问题的模型。接下来的问题是：我们能否构建能够区分狗和猫，或者汽车和飞机的模型？如今，在**TensorFlow**和**PyTorch**等框架的帮助下，开发人员可以仅用几行代码构建这样的机器学习解决方案。
- en: In this chapter, we will explore the anatomy of **neural networks** and learn
    how we can apply them to building models for computer vision problems. We will
    start by examining what a neural network is and the architecture of a multilayer
    neural network. We will look at some important ideas such as forward propagation,
    backward propagation, optimizers, loss function, learning rate, and activation
    functions, and where and how they fit in.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索**神经网络**的构造，并学习如何将它们应用于计算机视觉问题的模型构建。我们将首先了解什么是神经网络，以及多层神经网络的架构。我们还将探讨一些重要的概念，如前向传播、反向传播、优化器、损失函数、学习率和激活函数，以及它们在网络中的作用和位置。
- en: After we build a solid base in the core fundamentals, we will build an image
    classifier using a custom dataset from TensorFlow. Here, we will walk through
    the end-to-end process of model building using the TensorFlow dataset. The good
    part of using these custom datasets is that the bulk of the preprocessing steps
    are already done, and our data can be modeled without any blockers. So, we will
    use this dataset to build a neural network with a few lines of code in TensorFlow
    with the **Keras** API, so that our model will be able to tell the difference
    between a bag and a shirt, and a shoe and a coat.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们扎实掌握核心基础后，我们将使用TensorFlow中的自定义数据集构建图像分类器。在这里，我们将通过TensorFlow数据集的端到端过程来构建模型。使用这些自定义数据集的好处是，大部分预处理步骤已经完成，我们可以毫无障碍地对数据进行建模。因此，我们将使用这个数据集，在TensorFlow的**Keras**
    API下通过几行代码构建一个神经网络，使我们的模型能够区分包和衬衫，鞋子和外套。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The anatomy of neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的构造
- en: Building an image classifier with a neural network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络构建图像分类器
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be using `python >= 3.8.0`, along with the following packages that
    can be installed using the `pip` `install` command:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`python >= 3.8.0`，并配合以下可以通过`pip install`命令安装的包：
- en: '`tensorflow>=2.7.0`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow>=2.7.0`'
- en: '`tensorflow-datasets==4.4.0`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow-datasets==4.4.0`'
- en: '`pillow==8.4.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pillow==8.4.0`'
- en: '`pandas==1.3.4`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas==1.3.4`'
- en: '`numpy==1.21.4`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy==1.21.4`'
- en: '`matplotlib >=3.4.0`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib >=3.4.0`'
- en: The code for this chapter is available at [https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205).
    Also, solutions to all exercises can be found in the GitHub repository itself.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205)找到。此外，所有练习的解答也可以在GitHub仓库中找到。
- en: The anatomy of neural networks
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的构造
- en: 'In the first section of this book, we talked about models. These models that
    we spoke about and used for various use cases are neural networks. A neural network
    is a deep learning algorithm inspired by the functionality of the human brain,
    but by no means does it operate like the human brain. It learns useful representation
    of the input data using a layered approach, as shown in *Figure 5**.1*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一部分，我们讨论了模型。我们所讲解和使用的这些模型是神经网络。神经网络是一种深度学习算法，受到人脑功能的启发，但它并不完全像人脑那样运作。它通过分层的方法学习输入数据的有用表示，如*图
    5.1*所示：
- en: '![Figure 5.1 – Neural network](img/B18118_05_001.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1 – 神经网络](img/B18118_05_001.jpg)'
- en: Figure 5.1 – Neural network
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 神经网络
- en: Neural networks are ideal for tackling complex problems due to their ability
    to identify very complex patterns in data. This makes them well suited for building
    solutions around text and image data (unstructured data), tasks that traditional
    machine learning algorithms struggle with. Neural networks develop rules to map
    input data to the target or labels using layered representation. When we train
    them on labeled data, they learn the patterns and use this knowledge to map the
    new input data to their corresponding labels.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络非常适合解决复杂问题，因为它们能够识别数据中非常复杂的模式。这使得它们特别适合围绕文本和图像数据（非结构化数据）构建解决方案，而这些是传统机器学习算法难以处理的任务。神经网络通过分层表示，开发规则将输入数据映射到目标或标签。当我们用标记数据训练它们时，它们学习模式，并利用这些知识将新的输入数据映射到相应的标签。
- en: In *Figure 5**.1*, we see all the neurons of the input layer are connected to
    the neurons of the first hidden layer, and all the neurons of the first hidden
    layer are connected to all the neurons of the second hidden layer. The same applies
    from the second hidden layer to the outer layer. This type of network, where each
    layer’s neurons are fully connected to the neurons of the next layer, is called
    a **fully connected neural network**. A neural network with more than two hidden
    layers is called a **deep neural network** (**DNN**) and the depth of the network
    is determined by its number of layers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 5.1*中，我们看到输入层的所有神经元都与第一隐藏层的神经元相连接，第一隐藏层的所有神经元都与第二隐藏层的神经元相连接。从第二隐藏层到外层也同样如此。这种每一层的神经元都与下一层的神经元完全连接的网络，被称为**全连接神经网络**。拥有两个以上隐藏层的神经网络被称为**深度神经网络**（**DNN**），网络的深度由其层数决定。
- en: 'Let’s take a deep dive into the individual layers of a neural network architecture:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨神经网络架构中的各个层：
- en: '**Input layer**: This is the layer through which we fed the input data (text,
    image, tabular data) into the network. Here, we have to specify the right input
    shape, something we have done previously in our regression case study in [*Chapter
    3*](B18118_03.xhtml#_idTextAnchor065)*, Linear Regression With TensorFlow*, and
    in our classification case study in [*Chapter 4*](B18118_04.xhtml#_idTextAnchor085)*,
    Classification With TensorFlow*. It is important to note that the input data will
    be presented to our neural network in numerical format. In this layer, no computation
    takes place. It’s more of a passthrough layer to the hidden layer.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入层**：这是我们将输入数据（文本、图像、表格数据）输入网络的层。在这里，我们必须指定正确的输入形状，之前在我们的回归案例研究中，[*第3章*](B18118_03.xhtml#_idTextAnchor065)*，TensorFlow线性回归*，以及在我们的分类案例研究中，[*第4章*](B18118_04.xhtml#_idTextAnchor085)*，TensorFlow分类*中都已经做过这种操作。需要注意的是，输入数据将以数字格式呈现给我们的神经网络。在这一层，不会进行任何计算。这更像是一个将数据传递到隐藏层的通道层。'
- en: '**Hidden layer**: This is the next layer and it lies between the input and
    output layers. It is referred to as hidden because it is not visible to external
    systems. Here, lots of computation takes place to extract patterns from our input
    data. The more layers we add to the hidden layer, the more complex our model becomes
    and the more time it takes to process our data.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐藏层**：这是下一个层，位于输入层和输出层之间。之所以称为隐藏层，是因为它对外部系统不可见。在这里，进行大量计算以从输入数据中提取模式。我们在隐藏层中添加的层数越多，我们的模型就会变得越复杂，处理数据所需的时间也越长。'
- en: '**Output layer**: This layer produces the output of the neural network. The
    number of output layer neurons is determined by the task at hand. If we have a
    binary classification task, we will use one output neuron, while for multiclass
    classification, such as in our case study where we had 10 different labels, we
    will have 10 neurons, one for each of the classes in our data.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层**：该层生成神经网络的输出。输出层神经元的数量由当前任务决定。如果我们有一个二分类任务，我们将使用一个输出神经元；而对于多类分类任务，例如我们的案例研究中有10个不同的标签，我们将有10个神经元，每个标签对应一个神经元。'
- en: 'We now know the layers of a neural network, but the key questions are: how
    does a neural network work, and what enables it to take a special position in
    machine learning?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道神经网络的各层，但关键问题是：神经网络是如何工作的，它是如何在机器学习中占据特殊地位的？
- en: Neural networks solve complex tasks by the application of both forward and backward
    propagation. Let’s start by examining forward propagation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通过前向传播和反向传播的结合解决复杂任务。我们先从前向传播开始。
- en: Forward propagation
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向传播
- en: Imagine we want to teach our neural network to effectively identify the images
    shown in *Figure 5**.2*. We will pass lots of representative samples of each of
    the images we want our neural network to recognize. The idea here is that our
    neural network will learn from the samples and use what it has learned to identify
    new items within the sample space. Let’s say, for example, we want our model to
    recognize shirts; we will pass shirts of different colors and sizes. Our model
    will learn what defines a shirt, irrespective of its color, size, or style. This
    learned representation of the core attributes of a shirt is what the model will
    use to identify new shirts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望训练神经网络有效地识别*图 5.2*中的图像。我们将传递大量我们希望神经网络识别的图像代表性样本。这里的想法是，我们的神经网络将从这些样本中学习，并利用所学知识识别样本空间中的新项。比如，假设我们希望模型识别衬衫，我们将传递不同颜色和大小的衬衫。我们的模型将学习衬衫的定义，而不论其颜色、尺寸或样式如何。模型所学到的衬衫核心属性的表示将用于识别新衬衫。
- en: '![Figure 5.2 – Sample images from Fashion MNIST dataset](img/B18118_05_002.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – 来自 Fashion MNIST 数据集的示例图像](img/B18118_05_002.jpg)'
- en: Figure 5.2 – Sample images from Fashion MNIST dataset
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 来自 Fashion MNIST 数据集的示例图像
- en: Let us look at what happens under the hood. In our training data, we pass the
    images (*X*) through our model f(x) . . →  ˆ y , where  ˆ y  is the model’s predicted
    output. Here, the neural network randomly initializes weights that are used to
    predict the output ( ˆ y ). This process is called **forward propagation** or
    **forward pass** and is depicted in *Figure 5**.3*.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下幕后发生了什么。在我们的训练数据中，我们将图像（*X*）传入模型 f(x) . . → ˆ y，其中 ˆ y 是模型的预测输出。这里，神经网络随机初始化权重，用于预测输出（ˆ
    y）。这个过程被称为**前向传播**或**前向传递**，如*图 5.3*所示。
- en: Note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Weights are trainable parameters that are updated during the training process.
    After training, the model’s weights are optimized to the specific dataset it is
    trained on. If we tune the weight properly during training, we can develop a well-performing
    model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 权重是可训练的参数，会在训练过程中进行更新。训练完成后，模型的权重会根据其训练数据集进行优化。如果我们在训练过程中适当地调整权重，就能开发出一个表现良好的模型。
- en: 'As input data flows through the network, it experiences transformations due
    to the impact of the node’s weight and bias, as shown in *Figure 5**.3*, thus
    producing a new set of information that will now pass through an *activation function*.
    If the new information learned is desired, the activation function triggers an
    output signal that serves as input to the next layer. This process continues until
    an output is generated in the output layer:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入数据流经网络时，数据会受到节点的权重和偏置的影响而发生变换，如*图 5.3*所示，从而产生一组新的信息，这些信息将通过*激活函数*。如果希望得到新的学习信息，激活函数将触发一个输出信号，作为下一个层的输入。这一过程持续进行，直到在输出层生成输出：
- en: '![Figure 5.3 – Forward propagation of a neural network](img/B18118_05_003.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – 神经网络的前向传播](img/B18118_05_003.jpg)'
- en: Figure 5.3 – Forward propagation of a neural network
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 神经网络的前向传播
- en: Let’s talk a bit more about activation functions and what they do in our neural
    network.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再谈谈激活函数及其在神经网络中的作用。
- en: Activation functions
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活函数
- en: Imagine you had to pick the good apples from a basket of apples. By inspecting
    the apples, you can pick the good ones and drop the bad ones. This is how an activation
    function works – it plays the role of a separator and thus defines what will pass
    through, which in our case is the useful representation it has learned, and drops
    the non-useful data. In essence, it helps to extract useful information, such
    as the good apples, and drop the useless data, which in our scenario are the bad
    apples. Now, the activation function determines which connected neuron of the
    next layer will be activated. It uses mathematical operations to determine whether
    a learned representation is useful enough for the next layer or not.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你需要从一篮苹果中挑选出好苹果。通过检查这些苹果，你可以挑出好苹果并丢掉坏苹果。这就像激活函数的作用——它充当了一个分隔器，定义了哪些信息会通过，在我们的例子中，这就是它学到的有用表示，并丢弃不必要的数据。从本质上讲，它帮助提取有用信息，就像挑选出好苹果一样，丢弃无用的数据，而在我们的场景中，坏苹果就是无用的数据。现在，激活函数决定了下一层哪个连接的神经元将被激活。它通过数学运算判断一个学习到的表示是否足够有用，能够供下一层使用。
- en: 'Activation functions can add nonlinearity to our neural network, a characteristic
    that is required for neural networks to learn complex patterns. There are different
    activation functions; for output layers, the selection of activation function
    depends on the type of task at hand:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数可以为我们的神经网络添加非线性，这是神经网络学习复杂模式所必需的特性。激活函数有多种选择；对于输出层，激活函数的选择取决于手头任务的类型：
- en: For binary classification, we usually use sigmoid function because it maps the
    input to output values between 0 and 1, representing the probability of belonging
    to a particular class. We usually set the threshold point as 0.5, hence values
    above this point are set to 1 and values below it is set to 0.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于二分类问题，我们通常使用 sigmoid 函数，因为它将输入映射到介于 0 和 1 之间的输出值，表示属于某个特定类别的概率。我们通常将阈值设置为
    0.5，因此大于此点的值设置为 1，小于此点的值设置为 0。
- en: 'For multiclass classification, we use **softmax** **activation** as the output
    layer’s activation function. Let’s say we want to build an image classifier to
    classify four fruits (apples, grapes, mangoes, and oranges) as illustrated in
    *Figure 5**.4.* One neuron is assigned in the output layer to each of the fruits
    and we will apply the softmax activation function to generate the likelihood of
    the output being one of the fruits we want to predict. When we sum up the probabilities
    of it being an apple, grape, mango, and orange, we get 1\. For classification,
    we select the class with highest probability of the four fruits as the output
    label from the probabilities generated by the Softmax activation function. In
    this case, the output with the highest probability is an orange:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多分类问题，我们使用 **Softmax** **激活** 作为输出层的激活函数。假设我们想要构建一个图像分类器，将四种水果（苹果、葡萄、芒果和橙子）进行分类，如图
    *5.4* 所示。每种水果在输出层分配一个神经元，并且我们会应用 Softmax 激活函数来生成输出属于我们希望预测的水果之一的概率。当我们将苹果、葡萄、芒果和橙子的概率加起来时，结果为
    1。对于分类任务，我们选择概率最大的水果类别作为从 Softmax 激活函数生成的概率中的输出标签。在这种情况下，概率最大的输出是橙子：
- en: '![Figure 5.4 – Application of the SoftMax activation function](img/B18118_05_004.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – SoftMax 激活函数的应用](img/B18118_05_004.jpg)'
- en: Figure 5.4 – Application of the SoftMax activation function
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – SoftMax 激活函数的应用
- en: For hidden layers, we will use the **rectified linear unit** (**ReLU**) activation
    function. This activation function removes negative values (useless representations),
    while it passes learned representations with values greater than 0\. ReLU offers
    excellent performance for hidden layers as it converges quickly as well as supports
    backward propagation, a concept we will be discussing next.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于隐藏层，我们将使用 **修正线性单元**（**ReLU**）激活函数。这个激活函数去除了负值（无用的表示），同时保留了大于 0 的学习表示。ReLU
    在隐藏层表现出色，因为它收敛快速并且支持反向传播，这是我们接下来将要讨论的概念。
- en: Note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: It is more efficient to use sigmoid for binary classification, when we do this,
    we have one output neuron as against two output neurons which would be the case
    when we use Softmax. Also, it is easier to understand that we are working on a
    case of binary classification when we read the code.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在二分类问题中，使用 sigmoid 函数更加高效，这时我们只有一个输出神经元，而使用 Softmax 时会有两个输出神经元。此外，当我们阅读代码时，更容易理解我们处理的是二分类问题。
- en: Backward propagation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: 'When we begin training a model, the weights are initially random, making it
    more likely that the model will guess wrongly that the fruit in *Figure 5**.4*
    is an orange. Here comes the intelligence of our neural network; it autocorrects
    itself, as shown in *Figure 5**.5*:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始训练模型时，权重最初是随机的，这使得模型更容易错误地猜测图 *5.4* 中的水果是橙子。此时神经网络的智能就体现出来了；它会自动修正自己，如图
    *5.5* 所示：
- en: '![Figure 5.5 – Forward and backward propagations of a neural network](img/B18118_05_005.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 神经网络的前向传播与反向传播](img/B18118_05_005.jpg)'
- en: Figure 5.5 – Forward and backward propagations of a neural network
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 神经网络的前向传播与反向传播
- en: Here, the neural network measures how correct the predicted output ( ˆ y ) is
    in comparison to the ground truth (*y*). This loss is computed by the **loss function**,
    which can also be referred to as the **cost function**. This information is passed
    on to an **optimizer**, whose job is to update the weights of the layers in the
    neural network with the aim of reducing the loss over the next iterations, thus
    getting our prediction closer to the ground truth. This process continues until
    we achieve **convergence**. Convergence occurs when the model is trained such
    that the loss is at its barest minimum.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，神经网络衡量预测输出（ˆy）与真实值（*y*）的比较结果的准确性。这个损失是通过**损失函数**计算的，损失函数也可以称为**代价函数**。这些信息会传递给**优化器**，其任务是更新神经网络中各层的权重，目的是在接下来的迭代中减少损失，从而使我们的预测更接近真实值。这个过程会持续，直到我们实现**收敛**。收敛发生在模型训练过程中，损失达到了最小值。
- en: The loss function is applied with respect to the task at hand. When we are working
    on a binary classification task, we use **binary cross-entropy**; for multiclass
    classification, if the target labels are integer values (for example, 0 to 9)
    we use **sparse categorical cross-entropy**, whereas we use **categorical cross-entropy**
    if we decide to one-hot encode our target labels. Like loss functions, we also
    have different types of optimizers; however, we will experiment with **stochastic
    gradient descent** (**SGD**) and the **Adam optimizer**, which is an improved
    version of SGD. Hence, we will use this as our default optimizer.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数的应用依赖于当前任务。当我们处理二分类任务时，我们使用**二元交叉熵**；对于多分类任务，如果目标标签是整数值（例如，0到9），我们使用**稀疏分类交叉熵**，而如果我们决定对目标标签进行独热编码，则使用**分类交叉熵**。与损失函数类似，我们也有不同类型的优化器；然而，我们将尝试使用**随机梯度下降法**（**SGD**）和**Adam优化器**，它是SGD的改进版。因此，我们将使用它作为我们的默认优化器。
- en: Learning rate
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习率
- en: 'We now know that weights are randomly initialized, and optimizers aim to use
    this information about the loss function to update the weights with a view to
    achieving convergence. Neural networks use optimizers to iteratively update the
    weights until the loss function is at a minimum, as shown in *Figure 5**.6*. Optimizers
    let you set an important hyperparameter called the **learning rate**, which controls
    the speed of convergence and is how our model learns. To get to the bottom of
    the slope, we will have to take steps toward the base (see *Figure 5**.6*):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道权重是随机初始化的，而优化器的目的是利用关于损失函数的信息来更新权重，从而实现收敛。神经网络使用优化器迭代更新权重，直到损失函数达到最小值，如*图5.6*所示。优化器允许你设置一个重要的超参数——**学习率**，它控制收敛的速度，并且是我们模型学习的方式。为了到达斜率的底部，我们必须朝着底部迈出步伐（见*图5.6*）：
- en: '![Figure 5.6 – Gradient descent](img/B18118_05_006.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6 – 梯度下降](img/B18118_05_006.jpg)'
- en: Figure 5.6 – Gradient descent
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – 梯度下降
- en: The step size we take will determine how quickly we get to the base. If we take
    very small steps, it will take too long to reach the base and lead to slower convergence,
    and there is also a risk that the optimization process could get stuck along the
    way to the minimum point. On the flip side, if the steps are too large, there
    is a risk we may overshoot the minimum and experience erratic and unstable training
    behavior. The right step size will get us to the base of the slope in time without
    overshooting the minimum point. This step size we refer to here is the learning
    rate.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采取的步伐大小将决定我们到达底部的速度。如果我们走得步伐太小，将需要很长时间才能到达底部，且会导致收敛变慢，甚至存在优化过程可能在到达最小值的过程中卡住的风险。反之，如果步伐太大，则可能会错过最小值，并出现不稳定和异常的训练行为。正确的步伐大小将帮助我们及时到达斜率的底部而不会错过最小点。这里提到的步伐大小就是学习率。
- en: We have now covered the intuition behind neural networks at a high level. Let
    us proceed and look at our case study, directly applying what we have just learned.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经高层次地了解了神经网络的直觉。接下来，让我们进行案例研究，直接应用我们刚刚学到的内容。
- en: Building an image classifier with a neural network
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用神经网络构建图像分类器
- en: We are back at our fictional company, and we want to use the intuition of neural
    networks to build an image classifier. Here, we are to teach computers to identify
    clothing. Thankfully, we do not need to find data in the wild; we have TensorFlow
    datasets that include the fashion dataset. In our case study, our aim is to classify
    a fashion dataset made up of 28 x 28 grayscale images into 10 classes (from 0
    to 9) with pixel values between 0 and 255, using a well-known dataset called the
    *Fashion MNIST dataset*. This dataset is made up of 60,000 training images and
    10,000 test images. Our dataset has all the images in the same shape, so we have
    little preprocessing to do. The idea here is for us to build a neural network
    quickly with little preprocessing complexities.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到了虚构的公司，现在我们希望利用神经网络的直觉来构建一个图像分类器。在这里，我们要教计算机识别服装。幸运的是，我们不需要在野外寻找数据；我们有 TensorFlow
    数据集，其中包括时尚数据集。在我们的案例研究中，我们的目标是将一个由 28 x 28 灰度图像组成的时尚数据集分类为 10 类（从 0 到 9），每个像素值介于
    0 到 255 之间，使用一个广为人知的数据集——*Fashion MNIST 数据集*。该数据集由 60,000 张训练图像和 10,000 张测试图像组成。我们的数据集中的所有图像都是相同的形状，因此我们几乎不需要做什么预处理。这里的想法是，我们可以快速构建一个神经网络，而不需要复杂的预处理。
- en: To train the neural network, we will pass the training images with the idea
    that our neural network will learn to map the images (*X*) to their corresponding
    labels (*y*). After we have concluded the training process, we will use our test
    set to evaluate the model on new unseen images. Again, the idea is that the model
    will correctly identify test images based on what it has learned throughout the
    training process. Let’s begin.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练神经网络，我们将传递训练图像，假设我们的神经网络将学习将图像（*X*）映射到它们相应的标签（*y*）。在完成训练过程后，我们将使用测试集对模型在新图像上的表现进行评估。同样，目的是让模型根据它在训练过程中学到的知识，正确识别测试图像。让我们开始吧。
- en: Loading the data
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Here, we will start with learning how to work with images using TensorFlow
    datasets. In [*Chapter 7*](B18118_07.xhtml#_idTextAnchor146)*,**Image Classification
    with Convolutional Neural Networks*, we will work on real-world images that will
    require more work to model our data; however, it will build on what we will learn
    here. That said, let us see how we can load our custom dataset from TensorFlow:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将首先学习如何使用 TensorFlow 数据集处理图像。在 [*第 7 章*](B18118_07.xhtml#_idTextAnchor146)*，**卷积神经网络进行图像分类*，我们将处理需要更多建模工作以使用的真实世界图像；不过，它将基于我们在这里学到的内容。话虽如此，让我们看看如何从
    TensorFlow 加载自定义数据集：
- en: 'Before we can load our data, we need to load the necessary libraries. Let’s
    do that here:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在加载数据之前，我们需要加载必要的库。我们在这里做这件事：
- en: '[PRE0]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we import the `fashion_mnist` dataset from TensorFlow and create our
    training and testing dataset using the `load_data()` method:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们从 TensorFlow 导入 `fashion_mnist` 数据集，并使用 `load_data()` 方法创建我们的训练集和测试集：
- en: '[PRE7]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If everything goes according to plan, we should get an output as shown in *Figure
    5**.7*:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果一切按计划进行，我们应该会得到如 *图 5.7* 所示的输出：
- en: '![Figure 5.7 – Data import from TensorFlow datasets](img/B18118_05_007.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.7 – 从 TensorFlow 数据集中导入数据](img/B18118_05_007.jpg)'
- en: Figure 5.7 – Data import from TensorFlow datasets
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 从 TensorFlow 数据集中导入数据
- en: 'Now, rather than using numeric labels, let us create labels that match our
    data such that we can call a dress a dress, rather than call it number 3\. We
    will do that by creating a list of our labels, which we will map to the corresponding
    numeric values:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们不再使用数字标签，而是创建与数据匹配的标签，这样我们可以把一件衣服叫做“衣服”，而不是叫它编号3。我们将通过创建一个标签列表，并将其映射到相应的数字值来实现这一点：
- en: '[PRE12]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now that we have our data, let us explore the data and see what we can find.
    Rather than agree with everything we are told, let’s explore the data to verify
    the size, the shape, and the data distributions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了数据，让我们探索数据，看看能发现什么。与其盲目接受所说的每一件事，不如探索数据以验证大小、形状和数据分布。
- en: Performing exploratory data analysis
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行探索性数据分析
- en: 'After we load the data, the next step is to examine it to get a sense of what
    the data is. Of course, in this instance, we have some basic information from
    TensorFlow about the data distribution. Also, we have the data already available
    in training and test sets. However, let us confirm all the details using code,
    as well as view the class distribution of our target label:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 加载完数据后，下一步是检查数据，了解数据的基本情况。当然，在这个实例中，我们已经从 TensorFlow 获得了一些关于数据分布的基本信息。同时，我们的数据已经以训练集和测试集的形式准备好了。然而，让我们通过代码确认所有细节，并查看我们目标标签的类别分布：
- en: 'We will use the `matplotlib` library to generate image samples at index `i`,
    where `i` falls within the 60,000 training samples:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`matplotlib`库生成索引为`i`的图像样本，其中`i`在 60,000 个训练样本中：
- en: '[PRE15]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We run the code using index `7`, which returns a top as seen in *Figure 5**.7*:'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用索引`7`运行代码，返回了如*图 5.7*所示的上衣：
- en: '![Figure 5.8 – A photo of a pullover at index 7 of the Fashion MNIST dataset](img/B18118_05_008.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.8 – Fashion MNIST 数据集索引为 7 的一件套头衫照片](img/B18118_05_008.jpg)'
- en: Figure 5.8 – A photo of a pullover at index 7 of the Fashion MNIST dataset
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – Fashion MNIST 数据集索引为 7 的一件套头衫照片
- en: We can switch the index values to see other apparels within the dataset; however,
    that is not the goal here. So, let’s proceed with our exploratory data analysis.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以切换索引值，查看数据集中其他的服装；不过，这并不是我们这里的目标。所以，让我们继续进行探索性数据分析。
- en: 'Let’s look at the sample of our data:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看一下我们数据的样本：
- en: '[PRE20]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As expected, we can see the training images consist of 60,000 28 x 28 images,
    and the test images are 10,000 in number and 28 x 28 in resolution:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如预期的那样，我们可以看到训练图像由 60,000 张 28 x 28 的图像组成，而测试图像有 10,000 张，分辨率为 28 x 28：
- en: '[PRE22]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, let us check the distribution of the data. It’s best practice to see
    how your data is distributed to ensure there is enough representation for each
    class of clothing we want to train the model on. Let’s do that here:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们检查数据的分布情况。最好先了解数据的分布情况，以确保每个我们希望训练模型的服装类别都有足够的样本。让我们在这里进行检查：
- en: '[PRE23]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This returns a `DataFrame` as shown in *Figure 5**.9*. We can see that all
    the labels have the same number of samples:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将返回如*图 5.9*所示的`DataFrame`。我们可以看到所有标签的样本数是相同的：
- en: '![Figure 5.9 – DataFrame showing labels and their counts](img/B18118_05_009.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – 显示标签及其计数的 DataFrame](img/B18118_05_009.jpg)'
- en: Figure 5.9 – DataFrame showing labels and their counts
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 显示标签及其计数的 DataFrame
- en: Of course, this type of data is more likely to be found in a controlled setting
    such as academia.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种类型的数据更可能出现在受控环境下，比如学术界。
- en: 'Let us visualize some sample images from the training data here. Let’s look
    at 16 samples from our training data:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在这里可视化一些训练数据中的样本图像。让我们来看 16 个来自训练数据的样本：
- en: '[PRE29]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'When we run the code, we get the image in *Figure 5**.10*:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们得到了*图 5.10*中的图像：
- en: '![Figure 5.10 – 16 randomly selected images from the Fashion MNIST dataset](img/B18118_05_010.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – 从 Fashion MNIST 数据集中随机选取的 16 张图像](img/B18118_05_010.jpg)'
- en: Figure 5.10 – 16 randomly selected images from the Fashion MNIST dataset
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 从 Fashion MNIST 数据集中随机选取的 16 张图像
- en: 'Now we have confirmed the data size, the data distribution, and the shape,
    and seen some sample images and labels. Before we proceed with building and training
    our image classifier, recall our data is made up of grayscale images with values
    from 0 to 255\. To bring the data to scale, we will have to normalize the data
    to improve the performance of our model during training. We can do this by simply
    dividing the training and testing data by 255:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确认了数据大小、数据分布和形状，并查看了一些样本图像和标签。在我们开始构建和训练图像分类器之前，回顾一下我们的数据由灰度图像组成，值范围从
    0 到 255。为了对数据进行归一化并提升模型在训练过程中的表现，我们需要对数据进行归一化处理。我们可以通过简单地将训练数据和测试数据除以 255 来实现这一点：
- en: '[PRE38]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Now that we have normalized our data, we are all set for modeling it. Let’s
    proceed with building our image classifier next.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对数据进行了归一化处理，接下来就可以进行建模了。让我们继续构建图像分类器。
- en: Building the model
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建模型
- en: 'Let us put everything we have learned so far in this chapter into action:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将到目前为止在本章中学到的所有知识付诸实践：
- en: '[PRE39]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The code we use to build our model is similar to what we used in *Part 1* of
    this book. We start by creating a sequential model using the Sequential API to
    define the number of layers we want to connect sequentially. If you are a keen
    observer, you will notice our first layer is a flatten layer. This is used to
    flatten the image data into a 1D array that will be passed into the hidden layer.
    The input layer has no neurons; it works as a data preprocessing layer, presenting
    the hidden layer with data flattened into a 1D array.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来构建模型的代码与本书*第一部分*中使用的代码类似。我们首先使用 Sequential API 创建一个顺序模型，以定义我们想要按顺序连接的层数。如果你是一个细心的观察者，你会注意到我们的第一层是一个展平层。这个层用于将图像数据展平为一个
    1D 数组，然后传递给隐藏层。输入层没有神经元，它充当数据预处理层，将数据展平为 1D 数组后传递给隐藏层。
- en: Next, we have one hidden layer of 64 neurons, and we apply a ReLU activation
    function to this hidden layer. Finally, we have an output layer of 10 neurons
    – one neuron for each output. We use a softmax function since we are working on
    multiclass classification. Softmax returns results in the form of probabilities
    across all classes. If you recall from the *Activation functions* section, the
    sum of the output probabilities adds up to 1, and the output with the largest
    probability value is the predicted label.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有一个64个神经元的隐藏层，并对该隐藏层应用ReLU激活函数。最后，我们有一个包含10个神经元的输出层——每个输出一个神经元。由于我们处理的是多类分类问题，因此使用softmax函数。Softmax返回的是所有类别的概率结果。如果你还记得*激活函数*部分，输出概率的总和为1，概率值最大的输出就是预测标签。
- en: Now that we are done with model building, let us proceed with compiling our
    model.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们完成了模型构建，接下来继续编译模型。
- en: Compiling the model
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编译模型
- en: 'The next step is to compile the model. We will use the `compile` method to
    do so. Here, we pass in the optimizer we wish to use; in this case, we apply **Adam**,
    which is our default optimizer. We also specify the loss and the evaluation metrics.
    We use sparse categorical cross-entropy for our loss since our labels are numeric
    values. For our evaluation metrics, we use accuracy, since our dataset is balanced.
    The accuracy metric will give a true reflection of our model’s performance:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是编译模型。我们将使用`compile`方法来完成这个操作。在这里，我们传入我们希望使用的优化器；在这种情况下，我们使用**Adam**，它是我们的默认优化器。我们还指定了损失函数和评估指标。由于我们的标签是数字值，因此我们使用稀疏分类交叉熵作为损失函数。对于评估指标，我们使用准确率，因为我们的数据集是平衡的。准确率指标将真实反映我们模型的性能：
- en: '[PRE40]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Before we proceed to fitting our model, let’s look at some ways of visualizing
    our model and its parameters.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始拟合模型之前，先来看一下几种可视化模型及其参数的方法。
- en: Model visualization
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型可视化
- en: 'To visualize our model, we use the `summary()` method. This provides us with
    a detailed visual representation of the model’s architecture, the layers, the
    number of parameters (trainable and non-trainable), and the output shape:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化我们的模型，我们使用`summary()`方法。这将为我们提供一个详细的视觉表示，展示模型的架构、各层、参数数量（可训练和不可训练）以及输出形状：
- en: '[PRE41]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'When we run the code, it returns the model’s details as illustrated in *Figure
    5**.11*:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，它将返回模型的详细信息，如*图 5.11*所示：
- en: '![Figure 5.11 – Model summary](img/B18118_05_011.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11 – 模型摘要](img/B18118_05_011.jpg)'
- en: Figure 5.11 – Model summary
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 – 模型摘要
- en: From *Figure 5**.11*, we can see that the input layer has no parameters but
    an output shape of 784, which is the result of flattening our 28 × 28 image to
    a 1D array. To get the number of parameters of the dense layer, it’s 784 × 64
    + 64 = 50240 (recall , where *X* is the input data, *w* is the weights, and *b*
    is the bias). The output layer (`dense_1`) has a shape of 10, with one neuron
    representing each class and 650 parameters. Recall the output from one layer serves
    as the input to the next layer. So, 64 × 10 + 10 = 650, where 64 is the output
    shape of the hidden layer and the input shape of the output layer.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 5.11*中，我们可以看到输入层没有参数，但输出形状为784，这是将28 × 28的图像展平为一维数组的结果。要计算全连接层的参数数量，它是784
    × 64 + 64 = 50240（回想一下，*X*是输入数据，*w*是权重，*b*是偏置）。输出层（`dense_1`）的形状为10，其中每个神经元代表一个类别，共有650个参数。回想一下，一个层的输出作为下一个层的输入。因此，64
    × 10 + 10 = 650，其中64是隐藏层的输出形状，也是输出层的输入形状。
- en: 'On the other hand, we can also display our model as a flowchart, as seen in
    *Figure 5**.12*, by using the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们还可以通过以下代码将模型显示为流程图，如*图 5.12*所示：
- en: '[PRE42]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![Figure 5.12 – Model’s flowchart](img/B18118_05_012.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12 – 模型流程图](img/B18118_05_012.jpg)'
- en: Figure 5.12 – Model’s flowchart
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 模型流程图
- en: This also gives us a sense of our model’s structure. The plot we generated will
    be saved with the filename `model_plot.png`. Here, we set `show_shapes` to `true`;
    this will display the output shapes of each layer in the plot. We also set the
    `show_layer_name` to `true` to show the names of the layers in the plot, as illustrated
    in *Figure 5**.12.*
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这也让我们对模型的结构有了一个大致了解。我们生成的图表将保存为文件名`model_plot.png`。在这里，我们将`show_shapes`设置为`true`；这将在图中显示每一层的输出形状。我们还将`show_layer_name`设置为`true`，以在图中显示各层的名称，正如*图
    5.12*所示。
- en: Next, let us fit our model to the training data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将模型拟合到训练数据中。
- en: Model fitting
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型拟合
- en: 'By now, you should be familiar with this process. With a single line of code,
    we can use the `fit` method to fit our training images (*X*) and training labels
    (*y*):'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经熟悉这个过程。通过一行代码，我们可以使用`fit`方法来拟合我们的训练图像(*X*)和训练标签(*y*)：
- en: '[PRE43]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Here, we fit the data for five epochs. Our model returns the loss and accuracy:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将数据训练了五个 epoch。我们的模型返回了损失和准确率：
- en: '[PRE44]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We can see that in just five epochs, our model has achieved an accuracy of `0.8850`.
    This is a good start considering we trained our model for a very small number
    of epochs. Next, let us observe our model’s performance during training by plotting
    the loss and accuracy plots.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在仅仅五个 epoch 后，我们的模型达到了`0.8850`的准确率。考虑到我们只训练了非常少的 epoch，这是一个不错的开始。接下来，让我们通过绘制损失和准确率图来观察模型在训练过程中的表现。
- en: Training monitoring
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练监控
- en: 'We return a `history` object when we fit our training data. Here, we use the
    `history` object to create a loss and accuracy curve. Here is the code to make
    the plots:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在拟合训练数据时返回一个`history`对象。在这里，我们使用`history`对象来创建损失和准确率曲线。以下是绘制图表的代码：
- en: '[PRE45]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'When we run the code, we get back two plots as shown in *Figure 5**.13*. We
    can see the training accuracy is still rising at the end of the fifth epoch, while
    the loss is still falling, although the rate is not rapid as it moves closer to
    0:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们得到两个图表，如*图 5.13*所示。我们可以看到，在第五个 epoch 结束时，训练准确率仍在上升，而损失仍在下降，尽管随着接近
    0，下降的速度不再那么快：
- en: '![Figure 5.13 – Accuracy and loss plots](img/B18118_05_013.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.13 – 准确率和损失图](img/B18118_05_013.jpg)'
- en: Figure 5.13 – Accuracy and loss plots
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – 准确率和损失图
- en: Perhaps if we train for longer, we could see an improved performance. In the
    next chapter, we will examine what happens if we do train for longer, as well
    as look at other approaches to improve our model’s performance. Here, the aim
    is to understand what the plot means and gain enough information to direct our
    next line of action. Let’s evaluate our model on the test set.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 或许如果我们训练更长时间，可能会看到更好的表现。在下一章中，我们将探讨如果我们延长训练时间会发生什么，并且还会查看其他提高模型表现的方法。在这里，目标是理解图表的含义，并获取足够的信息来指导我们接下来的行动。让我们在测试集上评估我们的模型。
- en: Evaluating the model
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'We evaluate the overall performance of our model on the test set as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在测试集上评估我们模型的整体表现如下：
- en: '[PRE46]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We get an accuracy of `0.8567` on the test set. The difference between the training
    accuracy and the test accuracy is a common problem in machine learning that we
    refer to as **overfitting**. Overfitting is a key issue in machine learning, and
    we will look at overfitting and various ways of handling it in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*,*
    *Handling Overfitting*.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在测试集上得到了`0.8567`的准确率。训练准确率和测试准确率之间的差异是机器学习中常见的问题，我们称之为**过拟合**。过拟合是机器学习中的一个关键问题，我们将在[*第
    8 章*](B18118_08.xhtml#_idTextAnchor186)中探讨过拟合及其处理方法，*过拟合处理*。
- en: Next, let us make some predictions with our trained neural network.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们用我们训练过的神经网络做一些预测。
- en: Model prediction
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型预测
- en: 'To make predictions on the model, we use the `model.predict()` method on unseen
    data from our test set. Let’s look at what the model predicts on the first instance
    of our test data:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要对模型进行预测，我们在测试集的未见数据上使用`model.predict()`方法。让我们看看模型在测试数据的第一个实例上的预测：
- en: '[PRE47]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'When we run the code, we get back an array of probabilities:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行代码时，我们得到一个概率数组：
- en: '[PRE48]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'If we inspect the probabilities, we see that the probability is highest at
    the ninth element. So, there is a 70% chance that this is our label. We will use
    `np.argmax` to extract the label and compare it to the test label at index `0`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查概率，会发现在第九个元素的概率最高。因此，这个标签的概率为 70%。我们将使用`np.argmax`来提取标签，并将其与索引为`0`的测试标签进行比较：
- en: '[PRE49]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We see that both the predicted label and test label return a value of `9`.
    Our model got this prediction right. Next, let us plot 16 random images and compare
    the predicted results with the ground label. This time, rather than returning
    the numeric values of our labels, we will return the labels themselves for visual
    clarity:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到预测标签和测试标签的值都是`9`。我们的模型正确预测了这一点。接下来，让我们绘制 16 张随机图片，并将预测结果与真实标签进行比较。这次，我们不会返回标签的数值，而是返回标签本身，以便更清晰地展示：
- en: '[PRE50]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The result is shown in *Figure 5**.14*. Although the model was able to classify
    10 items correctly, it failed on one sample where it classified a shirt as a pullover:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如*图 5.14*所示。尽管模型能够正确分类 10 个项目，但它在一个样本上失败了，将一件衬衫误分类为套头衫：
- en: '![Figure 5.14 – Visualizing the model’s prediction on test data](img/B18118_05_014.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.14 – 可视化模型在测试数据上的预测](img/B18118_05_014.jpg)'
- en: Figure 5.14 – Visualizing the model’s prediction on test data
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14 – 可视化模型在测试数据上的预测
- en: In just a few lines of code, we have trained an image classifier. We reached
    an accuracy of 88.50% on our training data in five epochs and 85.67% on our test
    data. It is important to note that this is a toy dataset that is great for learning;
    however, real-world images are more complex and the training will take much longer
    and, in many instances, a more complex model architecture will be required.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 仅用几行代码，我们就训练了一个图像分类器。在五个训练周期内，我们在训练数据上的准确率达到了88.50%，在测试数据上的准确率为85.67%。需要注意的是，这是一个用于学习的玩具数据集，尽管它非常适合学习，但实际世界中的图像更为复杂，训练将需要更长时间，且在许多情况下，需要更复杂的模型架构。
- en: In this chapter, we have covered a lot of new concepts that will be very useful
    in later chapters and in the exams as well.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们介绍了许多新概念，这些概念在后续章节以及考试中都会非常有用。
- en: Summary
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed image classification modeling. Now, you should
    be able to explain what a neural network is, as well as forward and backward propagation.
    You should know the role of loss functions, activation functions, and optimizers
    in a neural network. Also, you should be able to find your way around loading
    data from a TensorFlow dataset. Finally, you should be familiar with how to build,
    compile, fit, and train a neural network for image classification as well as evaluate
    the model, plot the loss and accuracy curves, and interpret these visualizations.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们讨论了图像分类建模。现在，你应该能够解释什么是神经网络，以及前向传播和反向传播的原理。你应该了解损失函数、激活函数和优化器在神经网络中的作用。此外，你应该能够熟练加载TensorFlow数据集中的数据。最后，你应该了解如何构建、编译、拟合和训练一个用于图像分类的神经网络，并评估模型，绘制损失和准确率曲线，解读这些可视化结果。
- en: In the next chapter, we will explore several ideas we can apply to improve our
    model’s performance.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨几种方法，用于提高我们模型的性能。
- en: Questions
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Let’s test what we learned in this chapter:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来测试一下我们在这一章中学到的内容：
- en: What is the function of the activation function?
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活函数的作用是什么？
- en: How does backward propagation work?
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反向传播是如何工作的？
- en: What is the purpose of the input, hidden, and output layers?
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入层、隐藏层和输出层的作用是什么？
- en: Using a TensorFlow dataset, load a handwritten digits dataset after which you
    will build, compile, train, and evaluate an image classifier. It’s a similar exercise
    to our case study. Go for it.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用TensorFlow数据集，加载一个手写数字数据集，然后你将构建、编译、训练并评估一个图像分类器。这与我们的案例研究类似。加油！
- en: Further reading
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more, you can check out the following resources:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解更多信息，你可以查看以下资源：
- en: 'Amr, T., 2020\. *Hands-On Machine Learning with scikit-learn and Scientific
    Python Toolkits*. [S.l.]: Packt Publishing.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Amr, T., 2020\. *深入学习与scikit-learn和科学Python工具包的实践*。 [S.l.]: Packt Publishing.'
- en: Vasilev, I., 2019\. *Advanced Deep Learning with Python*. 1st ed. Packt Publishing.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vasilev, I., 2019\. *Python深度学习进阶*。第1版。Packt Publishing.
- en: Raschka, S. and Mirjalili, V., 2019\. *Python Machine Learning*. 3rd ed. Packt
    Publishing.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raschka, S. 和 Mirjalili, V., 2019\. *Python机器学习*。第3版。Packt Publishing.
- en: 'Gulli, A., Kapoor, A. and Pal, S., 2019\. *Deep Learning with TensorFlow 2
    and Keras*. Birmingham: Packt Publishing.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulli, A., Kapoor, A. 和 Pal, S., 2019\. *使用TensorFlow 2和Keras的深度学习*。伯明翰：Packt
    Publishing.
- en: '*TensorFlow* *Guide* [https://www.TensorFlow.org/guide](https://www.TensorFlow.org/guide)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TensorFlow* *指南* [https://www.TensorFlow.org/guide](https://www.TensorFlow.org/guide)'
