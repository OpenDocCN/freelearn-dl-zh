- en: Creating Your First Deep Learning Web Application
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建你的第一个深度学习 web 应用
- en: After developing an understanding of neural networks and their setup for use
    in real-world projects, the natural next step is to develop a web-based deep learning
    application. This chapter is dedicated to creating a complete web application—albeit
    a very simplistic one—that, in a very simple way, demonstrates how the integration
    of deep learning in applications is done.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解神经网络及其在实际项目中的设置后，下一步自然是开发一个基于 web 的深度学习应用。本章将致力于创建一个完整的 web 应用——尽管是一个非常简单的应用——它通过一种非常简单的方式展示了如何将深度学习集成到应用中。
- en: This chapter will introduce several terms that will be used throughout this
    book, and so it is a recommended read even for those of you who already have a
    basic understanding of deep learning web applications so that you are able to
    understand the terms used in future chapters. We will begin by structuring a deep
    learning web application and learning how to understand datasets. We will then
    implement a simple neural network using Python and create a Flask API to work
    with server-side Python.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍一些本书中将使用的术语，因此即使是那些已经对深度学习 web 应用有基本理解的读者，也建议阅读此章，以便能理解未来章节中使用的术语。我们将首先构建一个深度学习
    web 应用，并学习如何理解数据集。接下来，我们将使用 Python 实现一个简单的神经网络，并创建一个与服务器端 Python 配合工作的 Flask API。
- en: 'In this chapter, the following topics will be covered:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Structuring a deep learning web application
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建深度学习 web 应用
- en: Understanding datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据集
- en: Implementing a simple neural network using Python
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 实现一个简单的神经网络
- en: Creating a Flask API that works with server-side Python
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个与服务器端 Python 配合工作的 Flask API
- en: Using cURL and the web client with Flask
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 cURL 和 Flask 的 web 客户端
- en: Improving the deep learning backend
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进深度学习后端
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can access the code used in this chapter at [https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-web/tree/master/Chapter3](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter3).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以访问本章中使用的代码，链接在此：[https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-web/tree/master/Chapter3](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter3)。
- en: 'For this chapter, you''ll need the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章你将需要以下内容：
- en: Python 3.6+
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.6+
- en: Flask 1.1.0+
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flask 1.1.0+
- en: TensorFlow 2.0+
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 2.0+
- en: Structuring a deep learning web application
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建深度学习 web 应用
- en: When solving a jigsaw puzzle, it is important that the parts fit, rather than
    them being forced together. Similarly, when developing a software solution, the
    parts of the solution must seamlessly work together and their interaction must
    be simple to understand. Good software requires proper software planning. Hence,
    providing a solid structure to the software is essential for its long-term use
    and for easy future maintenance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 解决拼图问题时，重要的是各个部分要匹配，而不是强行拼接。同样，在开发软件解决方案时，解决方案的各个部分必须无缝协作，它们的交互必须易于理解。好的软件需要合理的规划。因此，给软件提供一个坚实的结构对于其长期使用和未来的易于维护至关重要。
- en: Before we begin creating our first deep learning application that works on the
    web, we must chalk out a blueprint of the solution, keeping in mind the problems
    we wish to solve and the solutions to them. This is much like how we plan authentication
    systems or pass form values from one page to another during website development.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始创建第一个可以在 web 上运行的深度学习应用之前，我们必须规划出解决方案的蓝图，牢记我们希望解决的问题及其对应的解决方案。这就像我们在开发网站时规划身份验证系统或从一个页面传递表单值到另一个页面一样。
- en: 'A general deep learning web solution would need the following components:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个通用的深度学习 web 解决方案需要以下组件：
- en: A server that can store data and respond with queries
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以存储数据并响应查询的服务器
- en: A system that can use the stored data and process it to produce deep learning-based
    responses to queries
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以使用存储的数据并处理它，以生成基于深度学习的查询响应的系统
- en: A client that can send data to the server for storage, send queries with new
    data, and finally, accept and use the responses the server sends after querying
    the deep learning system
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以向服务器发送数据以进行存储、发送带有新数据的查询，并最终接受并使用服务器在查询深度学习系统后返回的响应的客户端
- en: Let's try to visualize this structure using a diagram.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过图示来可视化这个结构。
- en: A structure diagram of a general deep learning web application
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个通用深度学习 web 应用的结构图
- en: 'The following diagram depicts the interaction between the web client, web server,
    and the deep learning model:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示描绘了网页客户端、网页服务器和深度学习模型之间的交互：
- en: '![](img/f8763b49-1e75-456b-85d4-6b65ae1d8286.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f8763b49-1e75-456b-85d4-6b65ae1d8286.png)'
- en: We will be creating three software parts—the client, the server, and the deep
    learning model—which will all work together. To do so, the client will make HTTP
    requests to the server and the server, in return, will produce output fetched
    from the separately trained deep learning model. This model may or may not be
    executed in the files present on the server that respond to the HTTP requests
    made by the client. In most cases, the deep learning model is separated from the
    file that handles the HTTP requests.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建三个软件部分——客户端、服务器和深度学习模型——它们将共同工作。为此，客户端将向服务器发出 HTTP 请求，服务器将返回从单独训练的深度学习模型中提取的输出。该模型可能会在响应客户端
    HTTP 请求的服务器文件中执行，也可能不会。在大多数情况下，深度学习模型与处理 HTTP 请求的文件是分开的。
- en: In the example presented in this chapter, we will present the server, the client,
    and the deep learning model in separate files. Our client will send simple HTTP
    requests to the server, such as a page-load request or a `GET` request for URLs,
    which will produce the output from the deep learning model based on the queries
    passed. However, it is very common practice for the client to communicate with
    the server via REST APIs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中提供的示例中，我们将分别在不同文件中呈现服务器、客户端和深度学习模型。我们的客户端将向服务器发送简单的 HTTP 请求，例如页面加载请求或 `GET`
    请求 URL，这些请求将根据传入的查询产生深度学习模型的输出。然而，客户端通过 REST API 与服务器通信是非常常见的做法。
- en: Let's now move on to understanding the dataset that our application will work
    on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续了解我们的应用程序将要处理的数据集。
- en: Understanding datasets
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据集
- en: It is of the utmost importance that we properly understand the dataset that
    we are working on in order to produce the best results—in terms of execution time
    and space for the data—with the most efficient code. The dataset we will be using
    here is probably the most popular dataset when it comes to using neural networks
    with images—the MNIST database of handwritten digits.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在执行时间和数据空间上产生最佳结果，并使用最有效的代码，我们必须充分理解正在使用的数据集。我们在这里使用的数据集可能是最流行的手写数字图像神经网络数据集——MNIST
    数据集。
- en: The MNIST dataset of handwritten digits
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MNIST 手写数字数据集
- en: This dataset was created by a team made up of Yann LeCun, Corinna Cortes, and
    Christopher J.C. Burges. It is a large collection of images of handwritten digits,
    containing 60,000 training samples and 10,000 testing samples. The dataset is
    publicly available for download at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
    where it is present in the form of four `.gz` compressed files.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集由 Yann LeCun、Corinna Cortes 和 Christopher J.C. Burges 组成的团队创建。它是一个包含手写数字图像的大型数据集，包含
    60,000 个训练样本和 10,000 个测试样本。该数据集可以在 [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
    上公开下载，文件以四个 `.gz` 压缩文件的形式提供。
- en: 'The four files are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个文件如下：
- en: '`train-images-idx3-ubyte.gz`: The training set images. These images will be
    used to train the neural network classifier.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train-images-idx3-ubyte.gz`：训练集图像。这些图像将用于训练神经网络分类器。'
- en: '`train-labels-idx1-ubyte.gz`: The training set labels. Every image in the training
    set will have a label associated with it, which is the corresponding digit visible
    in that image.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train-labels-idx1-ubyte.gz`：训练集标签。训练集中的每个图像都有一个关联标签，该标签是该图像中可见的相应数字。'
- en: '`t10k-images-idx3-ubyte.gz`: The test set images. We will use these images
    to test our neural network prediction accuracy.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t10k-images-idx3-ubyte.gz`：测试集图像。我们将使用这些图像来测试神经网络的预测准确性。'
- en: '`t10k-labels-idx1-ubyte.gz`: The labels for the images in the test set. When
    our neural network makes predictions on the test set, we will compare them against
    these values to check our results.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t10k-labels-idx1-ubyte.gz`：测试集图像的标签。当我们的神经网络对测试集进行预测时，我们将与这些值进行比较，以检查结果。'
- en: 'The images stored in this dataset are not directly available for viewing due
    to their custom format. The developer working on the dataset is expected to create
    their own simple viewer for the images. Once you have done this, you will be able
    to see the images, which look something like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其自定义格式，数据集中的图像无法直接查看。开发者在处理该数据集时需要自己创建一个简单的图像查看器。完成此操作后，您将能够看到图像，其样子大致如下：
- en: '![](img/b1fb5c7a-789d-4a36-88df-0aab844dd80a.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1fb5c7a-789d-4a36-88df-0aab844dd80a.png)'
- en: Let's talk about the images in a bit more depth. They are, as you can see, a
    little over the 25 pixels mark on both axes. To be exact, the images are all in
    the form of 28 x 28 pixels. Now, since the images are grayscale, it is possible
    for them to be stored in a single layer 28 x 28 matrix. Hence, we have a total
    of 784 values, ranging from 0 to 1, where 0 represents an entirely dark pixel
    and 1 represents a white pixel. Anything inside that range is a shade of black.
    In the MNIST dataset, these images are present in the form of a flattened array
    of 784 floating point numbers. In order to view these images, you need to convert
    the single dimension array into a two-dimensional array with a 28 x 28 shape and
    then plot the image using any self-developed or publicly available tools, such
    as Matplotlib or the Pillow library.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地讨论这些图像。正如你所看到的，它们在两个轴上的像素数略超过25。准确来说，图像的尺寸是28 x 28像素。由于图像是灰度的，因此可以将它们存储在一个单层的28
    x 28矩阵中。因此，我们总共有784个值，范围从0到1，其中0表示完全黑的像素，1表示白色像素。范围内的任何数值表示不同深浅的黑色。在MNIST数据集中，这些图像以一个扁平的784个浮点数组的形式存在。为了查看这些图像，你需要将单维数组转换为28
    x 28的二维数组，然后使用任何自定义开发或公开可用的工具（例如Matplotlib或Pillow库）绘制图像。
- en: Let's discuss this method in the upcoming section.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的章节中讨论这个方法。
- en: Exploring the dataset
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据集
- en: 'Let''s begin by downloading all four files from the MNIST dataset web page,
    available at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist).
    Once downloaded, extract all the files and you should have folders that resemble
    the names in the following list:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从MNIST数据集网页下载这四个文件，网址为：[http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)。下载完成后，解压所有文件，你应该会看到类似以下名称的文件夹：
- en: '`train-images.idx3-ubyte`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train-images.idx3-ubyte`'
- en: '`train-labels.idx1-ubyte`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train-labels.idx1-ubyte`'
- en: '`t10k-images.idx3-ubyte`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t10k-images.idx3-ubyte`'
- en: '`t10k-labels.idx1-ubyte`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t10k-labels.idx1-ubyte`'
- en: Keep these files in your working directory. We will now create a Jupyter notebook
    to perform **exploratory data analysis** (**EDA**) on the dataset files we have
    extracted.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些文件保存在你的工作目录中。接下来，我们将创建一个Jupyter笔记本，对我们提取的数据集文件进行**探索性数据分析**（**EDA**）。
- en: 'Open your Jupyter Notebook environment in your browser and create a new Python
    notebook. Let''s begin by importing the necessary modules:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中打开你的Jupyter Notebook环境，并创建一个新的Python笔记本。首先，导入必要的模块：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding lines import the `numpy` module and `matplotlib.pyplot` to the
    project. The `numpy` module provides high-performance mathematical functions in
    Python while the `matplotlib.pyplot` module provides a simple interface to plot
    and visualize graphs and images. In order to view all the output from this library
    in the Jupyter notebook, add the following line of code:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码行导入了`numpy`模块和`matplotlib.pyplot`模块。`numpy`模块提供了Python中的高性能数学函数，而`matplotlib.pyplot`模块提供了一个简单的接口，用于绘制和可视化图表和图像。为了在Jupyter笔记本中查看此库的所有输出，请添加以下代码行：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you are on Windows, to extract a `.gz` file you can use the 7-zip software,
    which is an excellent compression/decompression tool that is available to download
    for free at [https://www.7-zip.org](https://www.7-zip.org).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是Windows系统，要解压`.gz`文件，可以使用7-zip软件，这是一个出色的压缩/解压工具，可以免费下载，网址是：[https://www.7-zip.org](https://www.7-zip.org)。
- en: Creating functions to read the image files
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建读取图像文件的函数
- en: 'As mentioned earlier, it is not possible to directly view the images in your
    downloaded image files. So, we will now create a function in Python that the `matplotlib`
    module will be able to use to display the images in the files:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，无法直接查看下载的图像文件中的图像。因此，我们将创建一个Python函数，`matplotlib`模块将使用该函数显示文件中的图像：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding `loadImageFile` function takes a single parameter, which is the
    name of the file that contains the images. We have two such files available for
    us in our downloaded files folder: `train-images-idx3-ubyte` and `t10k-images-idx3-ubyte`.
    The output of the preceding function is a `numpy` array of images. We can store
    the result in a Python variable, as shown:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的`loadImageFile`函数接受一个参数，即包含图像的文件名称。在我们下载的文件夹中，有两个这样的文件：`train-images-idx3-ubyte`和`t10k-images-idx3-ubyte`。前面函数的输出是一个`numpy`数组，包含图像数据。我们可以将结果存储在一个Python变量中，如下所示：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, to view the images that are in the variable holding the `numpy` array
    of images, we can define another function that takes a single image''s pixel array
    of 784 floating point numbers and plots them into a single image. The function
    can be defined as shown:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了查看变量中保存着`numpy`图像数组的图像，我们可以定义另一个函数，该函数以784个浮点数的单个图像像素数组作为输入，并将它们绘制成一幅图像。该函数定义如下：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, say we want to display the first of the test images; because we have stored
    the `numpy` array of images in the `test_images` variable, we can run the following
    code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想显示测试图像集中的第一张图像；因为我们已经将`numpy`图像数组存储在`test_images`变量中，我们可以运行以下代码：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We are able to see the following output:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够看到以下输出：
- en: '![](img/67d8fcf8-1084-4a0e-aa5e-39b2ee798280.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/67d8fcf8-1084-4a0e-aa5e-39b2ee798280.png)'
- en: Now that we are able to view the images, we can proceed to building a function
    that will allow us to extract the corresponding digit from the labels.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够查看图像后，可以继续构建一个函数，以允许我们从标签中提取相应的数字。
- en: Creating functions to read label files
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建读取标签文件的函数
- en: 'There are two label files available to us in the MNIST dataset: `train-labels-idx1-ubyte`
    and `t10k-labels-idx1-ubyte`. To view these files, we can use the following function,
    which takes input of the filename as an argument and produces an array of one-hot-encoded
    labels:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在MNIST数据集中，我们有两个标签文件可用：`train-labels-idx1-ubyte`和`t10k-labels-idx1-ubyte`。为了查看这些文件，我们可以使用下面的函数，该函数以文件名作为参数输入，并生成一个独热编码标签的数组：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This function returns a `numpy` array of labels in one-hot encoding, with the
    dimensions of the number of samples in the dataset times by 10\. Let''s observe
    a single entry in order to understand the nature of one-hot encoding. Run the
    following code, which essentially makes a print of the one-hot-encoded label set
    from the first sample in the test set:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数返回一个`numpy`数组，其中包含独热编码的标签，维度为数据集中的样本数乘以10。让我们观察单个条目，以了解独热编码的性质。运行以下代码，从测试集的第一个样本中打印独热编码的标签集：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We get the following output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can understand this by noting that since the digit at the seventh index is
    `1`, the label of the first image in the test dataset is `7`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过注意到第七个索引处的数字为`1`，我们可以理解测试数据集中第一幅图像的标签为`7`。
- en: A summary of the dataset
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集摘要
- en: After a very concise exploration of the available dataset, we are able to come
    up with the following results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在对可用数据集进行非常简明的探索后，我们得出以下结果。
- en: 'The training dataset contains 60,000 images with a dimension of 60,000 x 784,
    where each image is 28 x 28 pixels. The distribution of samples among the digits
    are as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集包含60,000张图像，维度为60,000 x 784，每幅图像为28 x 28像素。各个数字的样本分布如下：
- en: '| **Digit** | **Number of Samples** | **Digit** | **Number of Samples** |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| **数字** | **样本数量** | **数字** | **样本数量** |'
- en: '| 0 | 5,923 | 5 | 5,421 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 5,923 | 5 | 5,421 |'
- en: '| 1 | 6,742 | 6 | 5,918 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 6,742 | 6 | 5,918 |'
- en: '| 2 | 5,958 | 7 | 6,265 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 5,958 | 7 | 6,265 |'
- en: '| 3 | 6,131 | 8 | 5,851 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 6,131 | 8 | 5,851 |'
- en: '| 4 | 5,842 | 9 | 5,949 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 5,842 | 9 | 5,949 |'
- en: Observe that digit `5` has a smaller number of samples than digit `1`. So, it
    is quite possible that a model that isn't finely trained will make mistakes in
    recognizing digit `5`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，数字`5`的样本数量比数字`1`少。因此，模型如果训练不够精细，可能会在识别数字`5`时犯错。
- en: The summary of the number of labels present tells us that all 60,000 samples
    have their corresponding labels and none of their labels are missing.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 标签总数摘要告诉我们，所有60,000个样本都有相应的标签，并且没有缺少任何标签。
- en: 'Similarly, on the test dataset, we have 10,000 images and labels and the distribution
    of the number of samples is as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，测试数据集中有10,000张图像和标签，样本数量的分布如下：
- en: '| **Digit** | **Number of Samples** | **Digit** | **Number of Samples** |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| **数字** | **样本数量** | **数字** | **样本数量** |'
- en: '| 0 | 980 | 5 | 892 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 980 | 5 | 892 |'
- en: '| 1 | 1,135 | 6 | 958 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1,135 | 6 | 958 |'
- en: '| 2 | 1,032 | 7 | 1,028 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1,032 | 7 | 1,028 |'
- en: '| 3 | 1,010 | 8 | 974 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1,010 | 8 | 974 |'
- en: '| 4 | 982 | 9 | 1,009 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 982 | 9 | 1,009 |'
- en: The number of samples in the test dataset is quite evenly spread.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集中样本数分布相当均匀。
- en: Implementing a simple neural network using Python
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python实现一个简单的神经网络
- en: After doing a very basic data analysis, we can move on to coding our first neural
    network in Python. You can revise the concepts of neural networks in [Chapter
    2](9a68dbce-f50e-4c5a-80e2-2b7f40e082ca.xhtml), *Getting Started With Deep Learning
    Using Python*, before moving on. We will now be creating a **convolutional neural
    network** (**CNN**), which will predict the handwritten digit labels.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行了一些基本的数据分析后，我们可以开始用 Python 编写我们的第一个神经网络。你可以在[第 2 章](9a68dbce-f50e-4c5a-80e2-2b7f40e082ca.xhtml)中复习神经网络的概念，*使用
    Python 入门深度学习*，然后继续前进。我们现在将创建一个**卷积神经网络**（**CNN**），该网络将预测手写数字标签。
- en: We start by creating a new Jupyter notebook. You could name this `Model.ipynb`
    for convention. This notebook will be used to develop a **pickled** version of
    the deep learning model, which will later be put in a script that will generate
    predictions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个新的 Jupyter notebook。按照惯例，你可以将其命名为 `Model.ipynb`。这个 notebook 将用于开发一个**已保存**版本的深度学习模型，之后会将其放入一个脚本中以生成预测。
- en: Importing the necessary modules
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入所需的模块
- en: 'The modules that will be needed for `Model.ipynb` are imported as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`Model.ipynb` 中将需要的模块如下导入：'
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `keras` module is required to quickly implement high-performance neural
    networks with the TensorFlow backend. We have talked about Keras in earlier chapters.
    To install Keras, you can use the following command:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`keras` 模块用于快速实现具有 TensorFlow 后端的高性能神经网络。我们在前面的章节中讨论过 Keras。要安装 Keras，可以使用以下命令：'
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The preceding command will install Keras.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将安装 Keras。
- en: Reusing our functions to load the image and label files
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重用我们加载图像和标签文件的函数
- en: Remember the `loadImageFile` and `loadLabelFile` functions we created during
    the exploration of the dataset? We will need them again and so we will copy those
    same functions into this notebook.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在探索数据集时创建的 `loadImageFile` 和 `loadLabelFile` 函数吗？我们将再次需要它们，因此我们将把这些函数复制到此
    notebook 中。
- en: 'Together, they produce two cells of code for each of the functions:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 它们共同生成两个代码单元，每个函数各一个：
- en: The `loadImageFile()` method
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loadImageFile()` 方法'
- en: The `loadLabelFile()` method
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loadLabelFile()` 方法'
- en: 'In a new code cell, we create the `loadImageFile()` function:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的代码单元中，我们创建 `loadImageFile()` 函数：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In another new code cell, the `loadLabelFile()` function is created:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个新的代码单元中，创建 `loadLabelFile()` 函数：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can then import the images and label files in the form of `numpy` arrays
    by using the following lines of code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过以下代码行将图像和标签文件导入为 `numpy` 数组：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This creates the `train_images`, `train_labels`, `test_images`, and `test_labels`
    NumPy arrays. We can observe their shape and we get the following output for `train_images`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建 `train_images`、`train_labels`、`test_images` 和 `test_labels` 的 NumPy 数组。我们可以观察它们的形状，`train_images`
    的输出如下：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next, we will learn how to reshape the arrays for processing with Keras.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何重塑数组以便使用 Keras 进行处理。
- en: Reshaping the arrays for processing with Keras
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为 Keras 处理重塑数组
- en: The current shape of the image arrays are not Keras-friendly. We must convert
    the image arrays into a shape of `(60000, 28, 28, 1)` and `(10000, 28, 28, 1)`,
    respectively.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的图像数组形状不适合 Keras。我们必须将图像数组转换为形状 `(60000, 28, 28, 1)` 和 `(10000, 28, 28, 1)`。
- en: 'To do so, we use the following lines of code:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们使用以下代码行：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, if we observe the shape of `x_train`, we get an output as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们观察 `x_train` 的形状，我们将得到如下输出：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We have no changes to make in the labels arrays and so we directly assign them
    to `y_train` and `y_test`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无需对标签数组进行任何更改，因此直接将其赋值给 `y_train` 和 `y_test`：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Next, we will create a neural network using Keras.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 Keras 创建一个神经网络。
- en: Creating a neural network using Keras
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras 创建神经网络
- en: 'Now, we are ready to proceed with the creation of the neural network:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备好继续创建神经网络：
- en: 'We will first create a `Sequential` neural network model in Keras:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先在 Keras 中创建一个 `Sequential` 神经网络模型：
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To add a neuron layer to the network, we use the following code:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要向网络中添加一个神经元层，我们使用以下代码：
- en: '[PRE19]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This adds a two-dimensional convolutional neuron layer to the network with an
    input shape that is the same as the shape of the images.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这将向网络中添加一个二维卷积神经元层，输入形状与图像的形状相同。
- en: 'Now, let''s add the activation layer with `relu` as the activation function:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加激活层，并将 `relu` 作为激活函数：
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After adding the activation layer, we can perform a batch normalization. During
    training, the data passes through several computational layers and may become
    too large or too small. This is known as the **covariate shift** and batch normalization
    helps bring back the data to a central region. This helps the neural network train
    faster:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加激活层后，我们可以执行批量归一化。在训练过程中，数据会通过多个计算层，可能会变得过大或过小。这被称为**协方差偏移**，而批量归一化有助于将数据重新调整到中心区域。这有助于神经网络更快地训练：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s now add more hidden layers to the model:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们在模型中添加更多的隐藏层：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'At the last layer of the neural network, we need an output of 10 values, in
    the form of one-hot encoding, to denote the digit that has been predicted. To
    do this, we add a final layer of `10` neurons. This will hold 10 values in the
    continuous range of `0` to `1`:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在神经网络的最后一层，我们需要输出`10`个值，采用独热编码（one-hot encoding）形式，以表示预测的数字。为此，我们添加了最后一层`10`个神经元。这将包含`0`到`1`之间的10个值：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, to convert these 10 floating point values to a one-hot encoding, we
    use a `softmax` activation:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，为了将这10个浮动值转换为独热编码，我们使用`softmax`激活函数：
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Let's now compile and train the Keras neural network.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编译并训练Keras神经网络。
- en: Compiling and training a Keras neural network
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编译和训练Keras神经网络
- en: 'We are now ready to compile and train the neural network. To compile the neural
    network, we use the following code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好编译并训练神经网络。要编译神经网络，我们使用以下代码：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In our model, which we compiled in the previous block of code, we have set categorical
    cross-entropy as the `loss` function; the optimizer function used is the `Adam`
    optimizer and the metric for evaluation is `accuracy`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们模型中（在前面的代码块中已编译），我们设置了分类交叉熵作为`loss`函数；使用的优化器函数是`Adam`优化器，评估指标是`accuracy`。
- en: 'We then train the neural network with the `fit()` method of the Keras model
    object:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用Keras模型对象的`fit()`方法来训练神经网络：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It is recommended that you perform a split of the training data into further
    validation and training data, while leaving the test set untouched but for this
    dataset, it is fine.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 建议将训练数据进一步拆分为验证数据和训练数据，同时保持测试集不变，但对于这个数据集来说，这样是可以的。
- en: The training is done for 10 batches and the batch size is of 100 samples.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成，共进行了10个批次，每批次包含100个样本。
- en: Evaluating and storing the model
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估和存储模型
- en: 'After training the model, we are now ready to evaluate its accuracy. To do
    so, we will use the following code:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完模型后，我们现在准备好评估它的准确性。为此，我们将使用以下代码：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will get the following output for the preceding code:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获得以下输出，基于之前的代码：
- en: '![](img/523c24c1-f2c0-4d35-88e5-10b86c746140.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/523c24c1-f2c0-4d35-88e5-10b86c746140.png)'
- en: 'We get 99% accuracy, which is a very good accuracy score. Now, we can save
    the model, which will be used in the future to make predictions for user input
    through the web portal. We will split the model into two parts—the model structure
    and the model weights. To save the structure, we will use the JSON format, as
    shown:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了99%的准确率，这是一个非常好的准确率分数。现在，我们可以保存模型，它将在未来通过网页门户用于对用户输入进行预测。我们将把模型分为两部分——模型结构和模型权重。为了保存结构，我们将使用JSON格式，如下所示：
- en: '[PRE28]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, to save the weights of the Keras model, we use the `save_weights()` method
    for the object:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了保存Keras模型的权重，我们使用`save_weights()`方法来保存该对象：
- en: '[PRE29]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Next, we will create a Flask API to work with server-side Python.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个Flask API，以便与服务器端的Python协作。
- en: Creating a Flask API to work with server-side Python
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个Flask API，以便与服务器端的Python协作
- en: We have completed our deep learning model and stored its structure in the `model.json`
    file and the weights for the model in the `weights.h5` file. We are now ready
    to wrap the model data in an API so that we can expose the model to web-based
    calls via the `GET` or `POST` methods. Here, we will be discussing the `POST`
    method. Let's begin with the required setup on the server.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了深度学习模型，并将其结构存储在`model.json`文件中，将模型的权重存储在`weights.h5`文件中。现在我们准备将模型数据封装成API，以便通过`GET`或`POST`方法将模型暴露给基于Web的调用。这里，我们将讨论`POST`方法。让我们从服务器端的必要设置开始。
- en: Setting up the environment
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置环境
- en: 'In the server, we will require the Flask module—which will be service requests—which
    in turn will be running code that requires Keras (and so, TensorFlow), NumPy,
    and many other modules. In order to quickly set up the environment for our project,
    we follow these steps:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器中，我们将需要Flask模块——它将处理服务请求——而这些请求将运行需要Keras（以及TensorFlow）、NumPy和许多其他模块的代码。为了快速设置我们项目的环境，我们按照以下步骤进行操作：
- en: Install Anaconda.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Anaconda。
- en: Install TensorFlow and Keras.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装TensorFlow和Keras。
- en: Install Pillow.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Pillow。
- en: Install Flask.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Flask。
- en: 'You can refer to the following block of commands to install TensorFlow, Keras,
    Pillow, and Flask:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下命令块来安装TensorFlow、Keras、Pillow和Flask：
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We are now ready to start developing our API.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始开发我们的API。
- en: Uploading the model structure and weights
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上传模型结构和权重
- en: The model structure file, `model.json`, and the weights file, `weights.h5`,
    need to be present in the working directory. You can copy the files to a new folder—say,
    `flask_api`—or upload them to the correct path if you are using a remote server.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 模型结构文件`model.json`和权重文件`weights.h5`需要存在于工作目录中。你可以将这些文件复制到一个新文件夹中，比如`flask_api`，或者如果使用远程服务器，可以将它们上传到正确的路径。
- en: Creating our first Flask server
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建我们的第一个Flask服务器
- en: 'Create a new file in the working directory and name it `flask_app.py`. This
    file will be the one that handles all requests made to the server. Put the following
    code in the file:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作目录中创建一个新文件，命名为`flask_app.py`。这个文件将处理所有发送到服务器的请求。将以下代码放入该文件：
- en: '[PRE31]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The preceding code first imports the necessary modules into the script. Then,
    it sets the app as the Flask server object and defines the `index` function with
    a directive of handling all the requests made to the `"/"` address, regardless
    of the type of request. At the end of the script, the `run()` method of the Flask
    object app is used to bind the script to a specified port on the system.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码首先将必要的模块导入到脚本中。然后，它将应用程序设置为Flask服务器对象，并定义`index`函数，指示其处理所有发送到`"/"`地址的请求，无论请求类型如何。在脚本的末尾，使用Flask对象`app`的`run()`方法将脚本绑定到系统的指定端口。
- en: 'We can now deploy this simple *Hello World* Flask server. We run the following
    command in a Terminal:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以部署这个简单的*Hello World* Flask服务器了。我们在终端中运行以下命令：
- en: '[PRE32]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Now, when we open the `http://localhost/` URL in the browser, we are greeted
    with a page presenting *Hello World*. The `index` function handles the requests
    made at the root of the server, since it's route is set to `"/"`. Let's now extend
    this example toward creating an API that can handle requests specifically for
    prediction.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们在浏览器中打开`http://localhost/`网址时，我们看到一个页面，展示了*Hello World*。`index`函数处理发送到服务器根目录的请求，因为它的路由设置为`"/"`。接下来，我们将扩展这个示例，创建一个可以专门处理预测请求的API。
- en: Importing the necessary modules
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入必要的模块
- en: 'In the preceding example, we will extend the `flask import` statement to import
    an additional method, `request`, which will allow us how to handle the `POST`
    requests made to the server. The line then looks as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们将扩展`flask import`语句，导入一个额外的方法`request`，该方法将允许我们处理发送到服务器的`POST`请求。该行代码如下所示：
- en: '[PRE33]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We then import the modules necessary for the reading and storing of the images.
    Also, the `numpy` module is imported as in the following code snippet:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们导入读取和存储图像所需的模块。同时，还导入了`numpy`模块，如下所示：
- en: '[PRE34]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Finally, we import the `model_from_json()` method of the Keras module to load
    the saved model files. We then import `tensorflow`, as Keras is dependent on it
    to execute:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们导入Keras模块的`model_from_json()`方法来加载保存的模型文件。然后，我们导入`tensorflow`，因为Keras依赖于它来执行：
- en: '[PRE35]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Next, we load data into the script runtime.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数据加载到脚本运行时。
- en: Loading data into the script runtime and setting the model
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据到脚本运行时并设置模型
- en: 'Once we have imported the necessary modules, we load the saved model JSON and
    weights, as in the following code snippet:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们导入了必要的模块，就会加载保存的模型JSON和权重，代码如下所示：
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Note that we have also created a default `graph` item for the session ahead.
    This was implicitly created during the model training but is not carried over
    in the saved `model` and `weights` files, so we must explicitly create it here.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们还为会话提前创建了一个默认的`graph`项。该项是在模型训练期间隐式创建的，但不会保存在保存的`model`和`weights`文件中，因此我们必须在此处显式创建它。
- en: Setting the app and index function
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置应用程序和索引函数
- en: 'Now, we set the `app` variable to a Flask object and set the `"/"` route to
    be handled by the `index` function, which actually produces no meaningful output.
    This is because we will be using the `/predict` route to serve our prediction
    API as shown:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将`app`变量设置为Flask对象，并将`"/"`路由设置为由`index`函数处理，该函数实际上不会产生任何有意义的输出。这是因为我们将使用`/predict`路由来提供我们的预测API，如下所示：
- en: '[PRE37]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We will cover the convert image function in the next section.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中介绍图像转换功能。
- en: Converting the image function
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换图像功能
- en: 'We might sometimes get images in the form of `base64` encoded strings if the
    user makes an image `POST` request with a suitable setting. We can create a function
    to handle that:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，如果用户使用合适的设置发起图像 `POST` 请求，我们可能会收到 `base64` 编码的字符串形式的图像。我们可以创建一个函数来处理它：
- en: '[PRE38]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We use the `re` module for regex to determine whether the data passed is in
    the form of a `base64` string. The `base64` module is needed to decode the string
    and then the file is saved as `image.png`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `re` 模块进行正则表达式判断，以确定传入的数据是否为 `base64` 字符串形式。需要使用 `base64` 模块解码字符串，然后将文件保存为
    `image.png`。
- en: Prediction APIs
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测 API
- en: 'Now, let''s define the `/predict` route, which will be our API to respond to
    the predicted digit with:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义 `/predict` 路由，这将是我们的 API，用于响应预测的数字：
- en: '[PRE39]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Here, the `predict()` function takes in a `POST` method input, makes a check
    on the format that the file is passed in, and then saves it to the disk with the
    name of `image.png`. Then, the image is read into the program and resized to 28
    x 28 dimensions. Next, the image array is reshaped, such that it can be put into
    the Keras model for prediction. Then, we use the `predict()` method of the Keras
    model and get a one-hot-encoded output with the predicted digit's index set to
    `1`, while the rest remains as `0`. We determine the digit and send it to the
    output of the API.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`predict()` 函数接收一个 `POST` 方法的输入，检查传入文件的格式，然后将其保存为名为 `image.png` 的文件。接着，图像被读取到程序中并调整为
    28 x 28 的尺寸。接下来，图像数组被重塑，以便可以输入到 Keras 模型进行预测。然后，我们使用 Keras 模型的 `predict()` 方法，获得一个一热编码的输出，其中预测数字的索引被设置为
    `1`，其余部分保持为 `0`。我们确定数字并将其发送到 API 的输出。
- en: 'Now, we must, at the end of the file, add the code to bind the server to a
    port and set the required configuration:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须在文件的末尾添加代码，将服务器绑定到一个端口并设置所需的配置：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We have set the `debug=True` parameter in order to be able to see—in the server's
    console—whether any error occurs on the server. This is always a good idea during
    development but in production, this line of code can be skipped.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置了 `debug=True` 参数，以便在服务器的控制台中查看是否发生任何错误。在开发过程中，启用此选项总是个好主意，但在生产环境中，这行代码可以跳过。
- en: 'A final step before we run the application is to update the code for the `''/''`
    route. We will load the `index.html` item that we created whenever a person calls
    this route, as shown:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们运行应用程序之前的最后一步是更新 `'/'` 路由的代码。每当有人访问这个路由时，我们将加载我们创建的 `index.html` 文件，如下所示：
- en: '[PRE41]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We are now all set to start up the server and check whether it is working correctly.
    We use the same command as used previously to start up the server:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经准备好启动服务器并检查它是否正常工作。我们使用之前使用的相同命令来启动服务器：
- en: '[PRE42]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The preceding command will start up the server.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将启动服务器。
- en: Using the API via cURL and creating a web client using Flask
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 cURL 使用 API 并使用 Flask 创建一个 Web 客户端
- en: 'With our server running, we can send `POST` requests to it with the image content
    and expect a predicted digit in the output. Two ways to test any API without any
    third-party tools are as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的服务器运行时，我们可以向其发送 `POST` 请求，包含图像内容，并期望在输出中得到一个预测的数字。测试任何 API 而不使用第三方工具的两种方法如下：
- en: Use cURL.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 cURL。
- en: Develop a client to call the API.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个客户端来调用 API。
- en: We will be covering both of these methods.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖这两种方法。
- en: Using the API via cURL
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 cURL 使用 API
- en: Before we develop a client to send `POST` requests to the API server, let's
    test the API via cURL, which is a command-line tool used to simulate `GET` and
    `POST` requests to URLs.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开发客户端发送 `POST` 请求到 API 服务器之前，让我们通过 cURL 测试 API，cURL 是一个命令行工具，用于模拟对 URL 的
    `GET` 和 `POST` 请求。
- en: 'Use the following command in Terminal or Command Prompt to make a `curl` request
    to your prediction API:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端或命令提示符中使用以下命令向您的预测 API 发出 `curl` 请求：
- en: '[PRE43]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Here, the `-F` flag is used to indicate that the `POST` request will contain
    files. The name of the `POST` variable that will hold the file is `img`,`path_to_file`
    should be replaced with the full path to the file that you wish to send to the
    server for the image that the prediction is to be made on.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`-F` 标志用于表示 `POST` 请求将包含文件。将包含文件的 `POST` 变量名为 `img`，`path_to_file` 应该替换为您希望发送到服务器的文件的完整路径，该文件用于进行预测。
- en: Let's see how the API works with an example.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来看看 API 是如何工作的。
- en: 'Say we have the following image with the `self2.png` filename and dimensions
    of 275 x 275:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个名为 `self2.png`，尺寸为 275 x 275 的图像：
- en: '![](img/c1178ecc-74c4-4240-9fa9-5fa0ff8e6c67.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c1178ecc-74c4-4240-9fa9-5fa0ff8e6c67.png)'
- en: 'Clearly, the image dimensions on the serverside must be adjusted. To make the
    request, we use the following command:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，服务器端的图像尺寸必须进行调整。为了发出请求，我们使用以下命令：
- en: '![](img/a9e4c932-14ec-410e-81ec-255822daa48e.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9e4c932-14ec-410e-81ec-255822daa48e.png)'
- en: The output of the API is a single integer—`2`. So, the API works successfully.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: API的输出是一个整数——`2`。因此，API成功运行。
- en: Creating a simple web client for the API
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为API创建一个简单的网页客户端
- en: 'We will now be creating a bare-bones web Client to call the API. To do so,
    we must modify our current code. In `flask_app.py`, first change the `import`
    statement for Flask in order to extend it to another module—`render_template`—as
    shown:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建一个简单的网页客户端来调用API。为此，我们必须修改当前的代码。在`flask_app.py`中，首先修改Flask的`import`语句，以便将其扩展到另一个模块——`render_template`，如下所示：
- en: '[PRE44]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, we create a folder, `templates`, in the working directory and add a file,
    `index.html`, to it with the following code:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在工作目录中创建一个文件夹`templates`，并在其中添加一个文件`index.html`，文件内容如下：
- en: '[PRE45]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Essentially, all we do here is create a form with a single input element of
    the file type, called `img`. We then add jQuery to the page and create a link
    to a static file, `index.js`, which is served in the `static` folder of the server.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们在这里所做的只是创建一个表单，其中有一个类型为文件的输入元素，命名为`img`。然后，我们将jQuery添加到页面，并创建一个指向静态文件`index.js`的链接，该文件在服务器的`static`文件夹中提供。
- en: 'Let''s create the `index.js` file. First, create a folder, `static`, in the
    root directory and then create a new file, `index.js`, with the following code:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建`index.js`文件。首先，在根目录下创建一个文件夹`static`，然后创建一个新文件`index.js`，并写入以下代码：
- en: '[PRE46]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The preceding jQuery code makes a `POST` request to the `/predict/` route and
    then updates the `result` divide on the page with the value that is returned from
    the server.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的jQuery代码向`/predict/`路由发送一个`POST`请求，然后更新页面上的`result`区域，显示从服务器返回的值。
- en: 'Let''s take a sample run on this web client. First, we need to restart the
    Flask server. Then, we open `http://localhost/` in the browser to get a web page
    that looks like this:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这个网页客户端上进行一次示例运行。首先，我们需要重新启动Flask服务器。然后，我们在浏览器中打开`http://localhost/`，就会看到如下的网页：
- en: '![](img/216dfe04-0135-4771-979f-4cd732b1d1e5.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/216dfe04-0135-4771-979f-4cd732b1d1e5.png)'
- en: 'Say we choose a file named `mnist7.png`, which is essentially the first image
    of the test dataset and looks like this:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们选择一个名为`mnist7.png`的文件，它本质上是测试数据集中第一张图片，长这样：
- en: '![](img/3ea2f8b5-6d27-47cc-9670-0bb3f2e5e4f9.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ea2f8b5-6d27-47cc-9670-0bb3f2e5e4f9.png)'
- en: 'The expected output is `7`. After clicking Submit, we get the following output
    on the page:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的输出是`7`。点击提交后，我们在页面上获得如下输出：
- en: '![](img/0ac49e88-f2b8-4b42-b530-eaffc91dcb4a.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ac49e88-f2b8-4b42-b530-eaffc91dcb4a.png)'
- en: We can observe that that is the correct output and conclude that the web client
    works correctly.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到这是正确的输出，并得出结论：网页客户端工作正常。
- en: Improving the deep learning backend
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进深度学习后端
- en: 'The simple model we have trained here is hardly one that we can claim is close
    to a perfect model. There are several methods that we can use to extend this model
    to make it better. For instance, some of the most basic steps that we can take
    to improve our deep learning model are as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里训练的简单模型，几乎无法称之为一个接近完美的模型。有几种方法可以扩展这个模型，使其更好。例如，我们可以采取以下一些最基本的步骤来改进我们的深度学习模型：
- en: '**Increase training epochs**: We have only trained our model for 10 epochs,
    which is usually a very small value for any deep learning model. Increasing the
    number of training epochs can improve the accuracy of the model. However, it can
    also lead to overfitting and so the number of epochs must be experimented with.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加训练轮次**：我们只训练了模型10轮，这通常是一个非常小的值，对于任何深度学习模型来说都不够。增加训练轮次可以提高模型的准确性，但也可能导致过拟合，因此训练轮次需要通过实验来调整。'
- en: '**More training samples**: Our web client currently doesn''t do much more than
    show the predicted value. However, we could extend it to get feedback from the
    user on whether the prediction we made was correct. We can then add the user''s
    input image to the training samples and train with the user-provided label for
    the image. We must, however, take caution against spammy user input images and
    labels and only provide this feature to trusted users or beta testers for our
    web app.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更多的训练样本**：我们的网页客户端目前的功能仅限于显示预测值。但是，我们可以扩展它，让用户提供反馈，确认我们做出的预测是否正确。然后，我们可以将用户提供的输入图像添加到训练样本中，并用用户提供的标签来训练。不过，我们必须小心用户提交的垃圾输入图像和标签，因此此功能应仅提供给可信的用户或我们的网页应用的Beta测试人员。'
- en: '**Create a deeper network**: We could increase the number of hidden layers
    in the network to make the predictions more accurate. Again, this method is susceptible
    to overfitting and must be carefully experimented with.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建更深的网络**：我们可以增加网络中的隐藏层数量，以提高预测的准确性。但这种方法容易导致过拟合，因此必须小心实验。'
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter covered, in complete detail, how you can create a deep learning
    model and then facilitate its usage through an API via a web client or using cURL.
    The chapter began by discussing how deep learning web applications are structured,
    the various components of such applications, and how they interact with each other.
    Then, a short discussion and exploration of the MNIST handwritten digits dataset
    was presented. This led us on to the next section, where we built a deep learning
    model and stored it in files for future use. These files were then imported to
    the server API scripts and executed there whenever the API was called. Finally,
    the chapter presented a very basic client for the API and also instructed you
    on how to use the API over cURL through the command-line interface.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细介绍了如何创建深度学习模型，并通过 API 使其在 Web 客户端或通过 cURL 使用。本章首先讨论了深度学习 Web 应用程序的结构、这些应用程序的各个组成部分以及它们如何相互作用。接着，简要介绍并探索了
    MNIST 手写数字数据集。这为我们进入下一部分铺平了道路，在那里我们构建了一个深度学习模型并将其存储为文件以备将来使用。随后，这些文件被导入到服务器 API
    脚本中，并在每次调用 API 时执行。最后，本章展示了一个非常基础的 API 客户端，并指导你如何通过命令行界面使用 cURL 来调用该 API。
- en: In the next chapter, we will discuss how deep learning can be performed within
    the browser window using TensorFlow.js.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论如何使用 TensorFlow.js 在浏览器窗口内执行深度学习。
