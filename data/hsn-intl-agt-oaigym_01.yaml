- en: Introduction to Intelligent Agents and Learning Environments
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 智能体与学习环境简介
- en: Greetings! Welcome to the first chapter of this book. This book will introduce
    you to the awesome OpenAI Gym learning environment and guide you through an exciting
    journey to get you equipped with enough skills to train state-of-the-art, artificial
    intelligence agent-based systems. This book will help you develop hands-on experience
    with reinforcement learning and deep reinforcement learning through practical
    projects ranging from developing an autonomous, self-driving car to developing
    Atari game-playing agents that can surpass human performance. By the time you
    complete the book, you will be in a position to explore the endless possibilities
    of using artificial intelligence to solve algorithmic tasks, play games, and fix
    control problems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎！欢迎来到本书的第一章。本书将向你介绍令人兴奋的 OpenAI Gym 学习环境，并引导你踏上令人兴奋的旅程，帮助你掌握足够的技能，以训练基于人工智能智能体的先进系统。本书将通过从开发自动驾驶汽车到开发能够超越人类表现的
    Atari 游戏代理等实用项目，帮助你获得强化学习和深度强化学习的实践经验。完成本书后，你将能够探索使用人工智能解决算法任务、玩游戏和修复控制问题的无限可能性。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding intelligent agents and learning environments
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解智能体与学习环境
- en: Understanding what OpenAI Gym is all about
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解 OpenAI Gym 的基本概念
- en: Different categories of tasks/environments that are available, with a brief
    description of what each category is suitable for
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种任务/环境的类别，并简要描述每个类别适用于什么场景
- en: Understanding the key features of OpenAI Gym
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 OpenAI Gym 的关键特性
- en: Getting an idea about what you can do with the OpenAI Gym toolkit
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解使用 OpenAI Gym 工具包可以做什么
- en: Creating and visualizing your first Gym environment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建并可视化你的第一个 Gym 环境
- en: Let's start our journey by understanding what an intelligent agent is.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解智能体是什么开始我们的旅程。
- en: What is an intelligent agent?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是智能体？
- en: A major goal of artificial intelligence is to build intelligent agents. Perceiving
    their environment, understanding, reasoning and learning to plan, and making decisions
    and acting upon them are essential characteristics of intelligent agents. We will
    begin our first chapter by understanding what an intelligent agent is, from the
    basic definition of agents, to adding intelligence on top of that.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的一个主要目标是构建智能体。感知环境、理解、推理、学习计划、做出决策并付诸实践是智能体的基本特征。我们将在第一章开始时，通过了解智能体是什么，从智能体的基本定义入手，逐步扩展到如何在此基础上增加智能。
- en: An *agent* is an entity that acts based on the observation (perception) of its
    environment. Humans and robots are examples of agents with physical forms.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*代理*是一个基于对其环境的观察（感知）采取行动的实体。人类和机器人是具有物理形态的代理的例子。'
- en: A human, or an animal, is an example of an agent that uses its organs (eyes,
    ears, nose, skin, and so on) as sensors to observe/perceive its environment and
    act using their physical body (arms, hands, legs, head, and so on). A robot uses
    its sensors (cameras, microphones, LiDAR, radar, and so on) to observe/perceive
    its environment and act using its physical robotic body (robotic arms, robotic
    hands/grippers, robotic legs, speakers, and so on).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人类或动物是一个例子，作为代理通过使用其器官（眼睛、耳朵、鼻子、皮肤等）作为传感器来观察/感知环境，并通过其物理身体（手臂、手、腿、头等）来采取行动。机器人使用其传感器（摄像头、麦克风、LiDAR、雷达等）来观察/感知环境，并通过其物理机器人身体（机械臂、机械手/抓手、机械腿、扬声器等）来采取行动。
- en: '*Software agents* are computer programs that are capable of making decisions
    and taking actions through interaction with their environment. A software agent
    can be embodied in a physical form, such as a robot. *Autonomous agents* are entities
    that make decisions autonomously and take actions based on their understanding
    of and reasoning about their observations of their environment.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*软件代理*是能够通过与环境互动来做出决策并采取行动的计算机程序。软件代理可以通过物理形式表现出来，如机器人。*自主代理*是那些根据对环境观察的理解和推理，自动做出决策并采取行动的实体。'
- en: An *intelligent agent* is an autonomous entity that can learn and improve based
    on its interactions with its environment. An intelligent agent is capable of analyzing
    its own behavior and performance using its observations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*智能体*是一个自主实体，能够根据与环境的互动进行学习和改进。智能体能够通过观察自我行为和表现进行分析。'
- en: In this book, we will develop intelligent agents to solve sequential decision-making
    problems that can be solved using a sequence of (independent) decisions/actions
    in a (loosely) Markovian environment, where feedback in the form of reward signals
    is available (through percepts), at least in some environmental conditions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将开发智能代理来解决序列决策问题，这些问题可以通过在（松散的）马尔可夫环境中一系列（独立的）决策/行动来解决，在某些环境条件下，至少可以通过感知获取奖励信号作为反馈。
- en: Learning environments
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习环境
- en: A learning environment is an integral component of a system where an intelligent
    agent can be trained to develop intelligent systems. The learning environment
    defines the problem or the task for the agent to complete.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 学习环境是一个系统的重要组成部分，在该环境中，智能代理可以被训练来开发智能系统。学习环境定义了代理需要完成的问题或任务。
- en: 'A problem or task in which the outcome depends on a sequence of decisions made
    or actions taken is a sequential decision-making problem. Here are some of the
    varieties of learning environments:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于一系列决策或采取的行动而产生结果的问题或任务被称为序列决策问题。以下是一些学习环境的种类：
- en: Fully observable versus partially observable
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全可观察与部分可观察
- en: Deterministic versus stochastic
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定性与随机性
- en: Episodic versus sequential
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经验性与序列性
- en: Static versus dynamic
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态与动态
- en: Discrete versus continuous
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散与连续
- en: Discrete state space versus continuous state space
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散状态空间与连续状态空间
- en: Discrete action space versus continuous action space
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散行动空间与连续行动空间
- en: In this book, we will be using learning environments implemented using the OpenAI
    Gym Python library, as it provides a simple and standard interface and environment
    implementations, along with the ability to implement new custom environments.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用使用 OpenAI Gym Python 库实现的学习环境，因为它提供了一个简单且标准的接口和环境实现，同时还支持实现新的自定义环境。
- en: In the following subsections, we will get a glimpse of the OpenAI Gym toolkit.
    This section is geared towards familiarizing a complete newbie with the OpenAI
    Gym toolkit. No prior knowledge or experience is assumed. We will first try to
    get a feel for the Gym toolkit and walk through the various environments that
    are available under different categories. We will then discuss the features of
    Gym that might be of interest to you, irrespective of the application domain that
    you are interested in. We'll then briefly discuss what the value proposition of
    the Gym toolkit is and how you can utilize it. We will be building several cool
    and intelligent agents in subsequent chapters, building on top of the Gym toolkit.
    So, this chapter is really the foundation for all that. We will also be quickly
    creating and visualizing our first OpenAI Gym environment towards the end of this
    chapter. Excited? Let's jump right in.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子章节中，我们将简要了解 OpenAI Gym 工具包。本节旨在帮助完全的新手熟悉 OpenAI Gym 工具包。我们假设读者没有任何先前的知识或经验。我们首先尝试了解
    Gym 工具包，并浏览不同类别下可用的各种环境。接下来，我们将讨论 Gym 中可能引起你兴趣的特性，无论你关注的是哪个应用领域。然后，我们将简要讨论 Gym
    工具包的价值主张以及如何利用它。在随后的章节中，我们将基于 Gym 工具包构建多个酷炫且智能的代理。因此，本章实际上是所有这些的基础。我们还将在本章末尾快速创建并可视化我们的第一个
    OpenAI Gym 环境。兴奋吗？那我们就开始吧。
- en: What is OpenAI Gym?
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 OpenAI Gym？
- en: OpenAI Gym is an open source toolkit that provides a diverse collection of tasks,
    called environments, with a common interface for developing and testing your intelligent
    agent algorithms. The toolkit introduces a standard **Application Programming
    Interface** (**API**) for interfacing with environments designed for reinforcement
    learning. Each environment has a version attached to it, which ensures meaningful
    comparisons and reproducible results with the evolving algorithms and the environments
    themselves.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Gym 是一个开源工具包，提供了多种任务集合，称为环境，并为开发和测试智能代理算法提供了统一的接口。该工具包引入了一个标准的**应用程序编程接口**（**API**），用于与为强化学习设计的环境进行交互。每个环境都有一个版本号，这确保了随着算法和环境本身的发展，能够进行有意义的比较并获得可复现的结果。
- en: The Gym toolkit, through its various environments, provides an episodic setting
    for reinforcement learning, where an agent's experience is broken down into a
    series of episodes. In each episode, the initial state of the agent is randomly
    sampled from a distribution, and the interaction between the agent and the environment
    proceeds until the environment reaches a terminal state. Do not worry if you are
    not familiar with reinforcement learning. You will be introduced to reinforcement
    learning in [Chapter 2](part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12),
    *Reinforcement Learning and Deep Reinforcement Learning*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Gym 工具包通过其各种环境提供了一个强化学习的情境，在该情境中，智能体的经验被分解为一系列的回合。在每个回合中，智能体的初始状态是从一个分布中随机抽取的，智能体与环境的互动一直进行到环境达到终止状态。如果你不熟悉强化学习也没关系。在[第二章](part0033.html#VF2I0-22c7fc7f93b64d07be225c00ead6ce12)中，我们将介绍强化学习和深度强化学习，*强化学习与深度强化学习*。
- en: 'Some of the basic environments available in the OpenAI Gym library are shown
    in the following screenshot:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 OpenAI Gym 库中可用的一些基本环境的截图：
- en: '![](img/00005.jpeg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00005.jpeg)'
- en: Examples of basic environments available in the OpenAI Gym with a short description
    of the task
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Gym 中可用的基本环境示例，并简要描述任务
- en: 'At the time of writing this book, the OpenAI Gym natively has about 797 environments spread
    over different categories of tasks. The famous Atari category has the largest
    share with about 116 (half with screen inputs and half with RAM inputs) environments!
    The categories of tasks/environments supported by the toolkit are listed here:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书撰写时，OpenAI Gym 原生支持大约797个环境，分布在不同任务类别中。著名的 Atari 类别占有最大份额，约有116个环境（其中一半使用屏幕输入，另一半使用
    RAM 输入）！该工具包支持的任务/环境类别如下所示：
- en: Algorithmic
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法
- en: Atari
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atari
- en: Board games
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 棋类游戏
- en: Box2D
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Box2D
- en: Classic control
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典控制
- en: Doom (unofficial)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doom（非官方）
- en: Minecraft (unofficial)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minecraft（非官方）
- en: MuJoCo
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MuJoCo
- en: Soccer
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 足球
- en: Toy text
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玩具文本
- en: Robotics (newly added)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人（新增加的）
- en: The various types of environment (or tasks) available under the different categories,
    along with a brief description of each environment, is given next. Keep in mind
    that you may need some additional tools and packages installed on your system
    to run environments in each of these categories. Do not worry! We will go over
    every single step you need to do to get any environment up and running in the
    upcoming chapters. Stay tuned!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来将介绍在不同类别下可用的各种类型的环境（或任务），并简要描述每个环境。请记住，运行这些类别下的环境可能需要你在系统上安装一些额外的工具和软件包。别担心！在接下来的章节中，我们将逐步讲解如何让每个环境运行起来，敬请期待！
- en: 'We will now see the previously mentioned categories in detail, as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将详细查看前面提到的各类内容，如下所示：
- en: '**Algorithmic environments**: They provide tasks that require an agent to perform
    computations, such as the addition of multi-digit numbers, copying data from an
    input sequence, reversing sequences, and so on.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法环境**：这些环境提供需要智能体执行计算的任务，例如多位数相加、从输入序列中复制数据、反转序列等。'
- en: '**Atari environments**: These offer interfaces to several classic Atari console
    games. These environment interfaces are wrappers on top of the **Arcade Learning
    Environment** (**ALE**). They provide the game''s screen images or RAM as input
    to train your agents.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Atari 环境**：这些环境提供了几个经典 Atari 游戏的接口。这些环境接口是 **街机学习环境**（**ALE**）的封装。它们提供游戏的屏幕图像或
    RAM 作为输入，用于训练智能体。'
- en: '**Board games**: This category has the environment for the popular game Go
    on 9 x 9 and 19 x 19 boards. For those of you who have been following the recent
    breakthroughs by Google''s DeepMind in the game of Go, this might be very interesting.
    DeepMind developed an agent named AlphaGo, which used reinforcement learning and
    other learning and planning techniques, including Monte Carlo tree search, to
    beat the top-ranked human Go players in the world, including Fan Hui and Lee Sedol.
    DeepMind also published their work on AlphaGo Zero, which was trained from scratch,
    unlike the original AlphaGo, which used sample games played by humans. AlphaGo
    Zero surpassed the original AlphaGo''s performance. Later, AlphaZero was published;
    it is an autonomous system that learned to play chess, Go, and Shogi using self-play
    (without any human supervision for training) and reached performance levels higher
    than the previous systems developed.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**棋盘游戏**：这一类别包含了9x9和19x19围棋的环境。如果你一直在关注谷歌DeepMind最近在围棋领域的突破，那么这可能会非常有趣。DeepMind开发了一个名为AlphaGo的智能体，使用强化学习和其他学习与规划技术，包括蒙特卡洛树搜索，击败了世界顶尖的围棋选手，包括范辉和李世石。DeepMind还发布了AlphaGo
    Zero的研究成果，它从零开始进行训练，与原始的AlphaGo不同，后者是通过人类下的棋局来进行训练的。AlphaGo Zero的表现超越了原始AlphaGo。之后，AlphaZero也被发布，它是一个自主系统，使用自我对弈（不需要任何人工监督的训练）学习下棋、围棋和将棋，并达到了比之前开发的系统更高的表现。'
- en: '**Box2D**: This is an open source physics engine used for simulating rigid
    bodies in 2D. The Gym toolkit has a few continuous control tasks that are developed
    using the Box2D simulator:'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Box2D**：这是一个开源的物理引擎，用于模拟二维刚体。Gym工具包有一些使用Box2D模拟器开发的连续控制任务：'
- en: '![](img/00006.jpeg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00006.jpeg)'
- en: A sample list of environments built using the Box2D simulator
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Box2D模拟器构建的环境示例列表
- en: The tasks include training a bipedal robot to walk, navigating a lunar lander
    to its landing pad, and training a race car to drive around a race track. Exciting!
    In this book, we will train an AI agent using reinforcement learning to drive
    a race car around the track autonomously! Stay tuned.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务包括训练一个双足机器人行走、引导月球着陆器到达着陆平台，以及训练赛车在赛道上行驶。激动人心！在本书中，我们将使用强化学习训练一个AI代理，使其能够自主驾驶赛车绕赛道行驶！敬请期待。
- en: '**Classic control**: This category has many tasks developed for it and was
    used widely in reinforcement learning literature in the past. These tasks formed
    the basis for some of the early development and benchmarking of reinforcement
    learning algorithms. For example, one of the environments available under the
    classic control category is the Mountain Car environment, which was first introduced
    in 1990 by Andrew Moore (Dean of the School of Computer Science at CMU, and Pittsburgh
    founder) in his PhD thesis. This environment is still used sometimes as a test
    bed for reinforcement learning algorithms. You will create your first OpenAI Gym
    environment from this category in just a few moments towards the end of this chapter!'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**经典控制**：这一类别包含了许多已开发的任务，过去在强化学习文献中得到了广泛应用。这些任务为强化学习算法的一些早期开发和基准测试奠定了基础。例如，经典控制类别下的一个环境是Mountain
    Car环境，它最早由安德鲁·摩尔（CMU计算机科学学院院长、Pittsburgh创始人）在1990年他的博士论文中提出。这个环境至今仍然有时被作为强化学习算法的测试平台。你将在本章的最后几页创建你第一个来自该类别的OpenAI
    Gym环境！'
- en: '**Doom**: This category provides an environment interface for the popular first-person
    shooter game Doom. It is an unofficial, community-created Gym environment category
    and is based on ViZDoom, which is a Doom-based AI research platform providing
    an easy-to-use API suitable for developing intelligent agents from raw visual
    inputs. It enables the development of AI bots that can play several challenging
    rounds of the Doom game using only the screen buffer! If you have played this
    game, you know how thrilling and difficult it is to progress through some of the
    rounds without losing lives in the game! Although this is not a game with cool
    graphics like some of the new first-person shooter games, the visuals aside, it
    is a great game. In recent times, several studies in machine learning, especially
    in deep reinforcement learning, have utilized the ViZDoom platform and have developed
    new algorithms to tackle the goal-directed navigation problems encountered in
    the game. You can visit ViZDoom''s research web page ([http://vizdoom.cs.put.edu.pl/research](http://vizdoom.cs.put.edu.pl/research))
    for a list of research studies that use this platform. The following screenshot
    lists some of the missions that are available as separate environments in the
    Gym for training your agents:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Doom**：这个类别为流行的第一人称射击游戏Doom提供了一个环境接口。它是一个非官方的、社区创建的Gym环境类别，基于ViZDoom构建，ViZDoom是一个基于Doom的AI研究平台，提供了一个易于使用的API，适合从原始视觉输入开发智能代理。它使得开发能够通过仅使用屏幕缓冲区来进行多个具有挑战性的Doom游戏回合的AI机器人成为可能！如果你玩过这个游戏，你就知道在某些回合中没有失去生命地前进是多么刺激和困难！虽然这款游戏的图像可能不如一些新的第一人称射击游戏那样炫酷，但放在一边，这仍然是一款很棒的游戏。近年来，机器学习，尤其是深度强化学习的多项研究，已经利用ViZDoom平台，开发出新的算法，来解决游戏中遇到的目标导向导航问题。你可以访问ViZDoom的研究网页（[http://vizdoom.cs.put.edu.pl/research](http://vizdoom.cs.put.edu.pl/research)），查看使用该平台的研究研究列表。以下截图列出了一些在Gym中可作为单独环境供你训练代理的任务：'
- en: '![](img/00007.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00007.jpeg)'
- en: List of missions or rounds available in Doom environments
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Doom环境中可用的任务或回合列表
- en: '**MineCraft**: This is another great platform. Game AI developers especially
    might be very much interested in this environment. MineCraft is a popular video
    game among hobbyists. The MineCraft Gym environment was built using Microsoft''s
    Malmo project, which is a platform for artificial intelligence experimentation
    and research built on top of Minecraft. Some of the missions that are available
    as environments in the OpenAI Gym are shown in the following screenshot. These
    environments provide inspiration for developing solutions to challenging new problems
    presented by this unique environment:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MineCraft**：这是另一个很棒的平台。游戏AI开发者可能对这个环境尤其感兴趣。MineCraft是一个在爱好者中非常受欢迎的电子游戏。MineCraft
    Gym环境是基于微软的Malmo项目构建的，Malmo是一个基于Minecraft的人工智能实验和研究平台。以下截图展示了一些作为环境在OpenAI Gym中可用的任务。这些环境为开发解决方案，解决这个独特环境中呈现的挑战性新问题提供了灵感：'
- en: '![](img/00008.jpeg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00008.jpeg)'
- en: Environments in MineCraft available in OpenAI Gym
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Gym中可用的MineCraft环境
- en: '**MuJoCo**: Are you interested in robotics? Do you dream of developing algorithms
    that can make a humanoid walk and run, or do a backflip like Boston Dynamic''s
    Atlas Robot? You can! You will be able to apply the reinforcement learning methods
    you will learn in this book in the OpenAI Gym MuJoCo environment to develop your
    own algorithm that can make a 2D robot walk, run, swim, or hop, or make a 3D multi-legged
    robot walk or run! In the following screenshot, there are some cool, real-world,
    robot-like environments available under the MuJoCo environment:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MuJoCo**：你对机器人技术感兴趣吗？你是否梦想开发能够让类人机器人走路、奔跑，或像波士顿动力的Atlas机器人一样做后空翻的算法？你可以做到！你将能够在本书中学习的强化学习方法，应用于OpenAI
    Gym的MuJoCo环境中，开发自己的算法，让2D机器人走路、奔跑、游泳或跳跃，甚至让3D多足机器人走路或奔跑！在以下截图中，你可以看到一些在MuJoCo环境中可用的酷炫、现实世界的机器人类环境：'
- en: '![](img/00009.jpeg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00009.jpeg)'
- en: '**Soccer**: This an environment suitable for training multiple agents that
    can cooperate together. The soccer environments available through the Gym toolkit
    have continuous state and action spaces. Wondering what that means? You will learn
    all about it when we talk about reinforcement learning in the next chapter. For
    now, here is a simple explanation: a continuous state and action space means that
    the action that an agent can take and the input that the agent receives are both
    continuous values. This means that they can take any real number value between,
    say, *0* and *1* (*0.5*, *0.005*, and so on), rather than being limited to a few
    discrete sets of values, such as {1, 2, 3}. There are three types of environment.
    The plain soccer environment initializes a single opponent on the field and gives
    a reward of *+1* for scoring a goal and *0* otherwise. In order for an agent to
    score a goal, it will need to learn to identify the ball, approach the ball, and
    kick the ball towards the goal. Sound simple enough? But it is really hard for
    a computer to figure that out on its own, especially when all you say is *+1*
    when it scores a goal and *0* in any other case. It does not have any other clues!
    You can develop agents that will learn all about soccer by themselves and learn
    to score goals using the methods that you will learn in this book.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**足球**：这是一个适用于训练可以协作的多个代理的环境。通过 Gym 工具包提供的足球环境具有连续的状态和动作空间。想知道这是什么意思吗？当我们在下一章讨论强化学习时，你会学到所有关于它的内容。现在，简单解释一下：连续的状态和动作空间意味着代理可以采取的动作和代理接收到的输入都是连续的值。这意味着它们可以取任意实数值，例如
    *0* 和 *1* 之间的任意数值（如 *0.5*、*0.005* 等），而不是被限制在几个离散的值集合中，如 {1, 2, 3}。环境有三种类型。普通的足球环境初始化一个单一的对手，并在进球时给予
    *+1* 的奖励，其他情况下奖励为 *0*。为了让代理进球，它需要学会识别球、接近球并将球踢向球门。听起来很简单，对吧？但对于计算机来说，要自己弄明白这一点是非常困难的，尤其是当你只告诉它进球时奖励
    *+1*，其他情况下奖励 *0*。它没有其他线索！你可以开发出能够通过自学足球并学会进球的代理，使用本书中介绍的方法。'
- en: '**Toy text**:OpenAI Gym also has some simple text-based environments under
    this category. These include some classic problems such as Frozen Lake, where
    the goal is to find a safe path to cross a grid of ice and water tiles. It is
    categorized under toy text because it uses a simpler environment representation—mostly
    through text.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**玩具文本**：OpenAI Gym 在此类别下还提供一些简单的基于文本的环境。这些包括一些经典问题，例如 Frozen Lake，其中的目标是找到一条安全的路径穿越冰雪和水域的方格。它被归类为玩具文本，因为它使用了更简单的环境表示方式——主要通过文本。'
- en: With that, you have a very good overview of all the different categories and
    types of environment that are available as part of the OpenAI Gym toolkit. It
    is worth noting that the release of the OpenAI Gym toolkit was accompanied by
    an OpenAI Gym website ([gym.openai.com](http://gym.openai.com)), which maintained
    a scoreboard for every algorithm that was submitted for evaluation. It showcased
    the performance of user-submitted algorithms, and some submissions were also accompanied
    by detailed explanations and source code. Unfortunately, OpenAI decided to withdraw
    support for the evaluation website. The service went offline in September 2017.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，你就能对作为 OpenAI Gym 工具包一部分的所有不同类别和类型的环境有一个非常好的概览。值得注意的是，OpenAI Gym 工具包的发布伴随着一个
    OpenAI Gym 网站（[gym.openai.com](http://gym.openai.com)），该网站维护了每个提交用于评估的算法的排行榜。它展示了用户提交算法的性能，并且一些提交还附有详细的解释和源代码。不幸的是，OpenAI
    决定停止对评估网站的支持，该服务于 2017 年 9 月下线。
- en: Now you have a good picture of the various categories of environment available
    in OpenAI Gym and what each category provides you with. Next, we will look at
    the key features of OpenAI Gym that make it an indispensable component in many
    of today's advancements in intelligent agent development, especially those that
    use reinforcement learning or deep reinforcement learning.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对 OpenAI Gym 中可用的各种环境类别和每个类别为你提供的内容有了清晰的了解。接下来，我们将看一下 OpenAI Gym 的关键特性，这些特性使其成为今天许多智能代理开发进展中不可或缺的组成部分，特别是那些使用强化学习或深度强化学习的进展。
- en: Understanding the features of OpenAI Gym
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 OpenAI Gym 的特点
- en: In this section, we will take a look at the key features that have made the
    OpenAI Gym toolkit very popular in the reinforcement learning community and led
    to it becoming widely adopted.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将重点介绍 OpenAI Gym 工具包在强化学习社区中非常受欢迎的关键特性，并且导致它被广泛采用。
- en: Simple environment interface
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单的环境接口
- en: OpenAI Gym provides a simple and common Python interface to environments. Specifically,
    it takes an action as input and provides *observation, reward, done *and an optional `info` object,
    based on the action as the output at each step. If this does not make perfect
    sense to you yet, do not worry. We will go over the interface again in a more
    detailed manner to help you understand. This paragraph is just to give you an
    overview of the interface to make it clear how simple it is. This provides great
    flexibility for users as they can design and develop their agent algorithms based
    on any paradigm they like, and not be constrained to use any particular paradigm
    because of this simple and convenient interface.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Gym 提供了一个简单且通用的 Python 环境接口。具体来说，它以动作作为输入，并在每一步基于动作提供观察、奖励、是否完成以及一个可选的`info`对象作为输出。如果这对你来说还不是很明显，别担心。我们会以更详细的方式再次讲解接口，帮助你理解。这段话只是为了概述接口，让你明白它有多简单。这为用户提供了极大的灵活性，因为他们可以根据喜欢的任何范式设计和开发他们的代理算法，而不受限于使用任何特定的范式。
- en: Comparability and reproducibility
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可比性和可复现性
- en: We intuitively feel that we should be able to compare the performance of an
    agent or an algorithm in a particular task to the performance of another agent
    or algorithm in the same task. For example, if an agent gets a score of *1,000*
    on average in the Atari game of Space Invaders, we should be able to tell that
    this agent is performing worse than an agent that scores *5000* on average in
    the Space Invaders game in the same amount of training time. But what happens
    if the scoring system for the game is slightly changed? Or if the environment
    interface was modified to include additional information about the game states
    that will provide an advantage to the second agent? This would make the score-to-score
    comparison unfair, right?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们直觉地感觉应该能够比较一个任务中代理或算法的表现与同一任务中另一个代理或算法的表现。例如，如果一个代理在太空侵略者的 Atari 游戏中平均得分为*1,000*，我们应该能够说这个代理比同样训练时间下平均得分为*5000*的代理表现更差。但是，如果游戏的评分系统略有变化会怎么样呢？或者如果环境接口被修改以包含关于游戏状态的额外信息，从而为第二个代理提供优势呢？这将使得分对比不公平，对吧？
- en: To handle such changes in the environment, OpenAI Gym uses strict versioning
    for environments. The toolkit guarantees that if there is any change to an environment,
    it will be accompanied by a different version number. Therefore, if the original
    version of the Atari Space Invaders game environment was named `SpaceInvaders-v0`
    and there were some changes made to the environment to provide more information
    about the game states, then the environment's name would be changed to `SpaceInvaders-v1`.
    This simple versioning system makes sure we are always comparing performance measured
    on the exact same environment setup. This way, the results obtained are comparable
    and reproducible.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理环境的这些变化，OpenAI Gym 对环境使用严格的版本控制。该工具包保证如果环境发生任何变化，都会伴随着一个不同的版本号。因此，如果原始的
    Atari 太空侵略者游戏环境的名称是`SpaceInvaders-v0`，并且对环境进行了一些修改以提供更多关于游戏状态的信息，那么环境的名称将更改为`SpaceInvaders-v1`。这种简单的版本控制系统确保我们始终在相同的环境设置上比较性能。这样，得到的结果是可比较和可复现的。
- en: Ability to monitor progress
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控进展能力
- en: All the environments available as part of the Gym toolkit are equipped with
    a monitor. This monitor logs every time step of the simulation and every reset
    of the environment. What this means is that the environment automatically keeps
    track of how our agent is learning and adapting with every step. You can even
    configure the monitor to automatically record videos of the game while your agent
    is learning to play. How cool is that?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Gym 工具包提供的所有环境都配备了监视器。该监视器记录模拟的每一个时间步骤和环境的每一次重置。这意味着环境会自动跟踪我们的代理在每一步中是如何学习和适应的。你甚至可以配置监视器，在代理学习玩游戏时自动记录视频。多么酷！
- en: What can you do with the OpenAI Gym toolkit?
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI Gym 工具包能做什么呢？
- en: 'The Gym toolkit provides a standardized way of defining the interface for environments
    developed for problems that can be solved using reinforcement learning. If you
    are familiar with or have heard of the **ImageNet Large Scale Visual Recognition
    Challenge** (**ILSVRC**), you may realize how much of an impact a standard benchmarking
    platform can have on accelerating research and development. For those of you who
    are not familiar with ILSVRC, here is a brief summary: it is a competition where
    the participating teams evaluate the supervised learning algorithms they have
    developed for the given dataset and compete to achieve higher accuracy with several
    visual recognition tasks. This common platform, coupled with the success of deep
    neural network-based algorithms popularized by AlexNet ([https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)),
    paved the way for the deep learning era we are in at the moment.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Gym 工具包提供了一种标准化的方式来定义为可以使用强化学习解决的问题开发的环境接口。如果你熟悉或听说过**ImageNet 大规模视觉识别挑战**（**ILSVRC**），你可能意识到标准化基准平台对加速研究和开发的影响有多大。对于那些对
    ILSVRC 不熟悉的人，这里是一个简要总结：这是一个竞赛，参与团队评估他们为给定数据集开发的监督学习算法，并竞争在几个视觉识别任务中取得更高的准确性。这个共同平台，再加上由
    AlexNet 推广的基于深度神经网络的算法的成功（[https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)），为我们目前所处的深度学习时代铺平了道路。
- en: In a similar way, the Gym toolkit provides a common platform to benchmark reinforcement
    learning algorithms and encourages researchers and engineers to develop algorithms
    that can achieve higher rewards for several challenging tasks. In short, the Gym
    toolkit is to reinforcement learning what ILSVRC is to supervised learning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，Gym 工具包提供了一个共同平台来对强化学习算法进行基准测试，并鼓励研究人员和工程师开发能在多个具有挑战性的任务中获得更高奖励的算法。简而言之，Gym
    工具包对强化学习而言就像 ILSVRC 对监督学习一样重要。
- en: Creating your first OpenAI Gym environment
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建您的第一个 OpenAI Gym 环境
- en: We will be going over the steps to set up the OpenAI Gym dependencies and other
    tools required for training your reinforcement learning agents in detail in [Chapter
    3](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12), *Getting Started with
    OpenAI Gym and Deep Reinforcement Learning*. This section provides a quick way
    to get started with the OpenAI Gym Python API on Linux and macOS using `virtualenv`
    so that you can get a sneak peak into the Gym!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将详细介绍设置 OpenAI Gym 依赖项和其他训练强化学习代理所需工具的步骤，详见[第 3 章](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12)，*开始使用
    OpenAI Gym 和深度强化学习*。本节提供了在 Linux 和 macOS 上使用`virtualenv`快速开始使用 OpenAI Gym Python
    API 的方法，以便您可以快速了解 Gym 的功能！
- en: 'MacOS and Ubuntu Linux systems come with Python installed by default. You can
    check which version of Python is installed by running `python --version` from
    a terminal window. If this returns `python` followed by a version number, then
    you are good to proceed to the next steps! If you get an error saying the Python command
    was not found, then you have to install Python. Please refer to the detailed installation
    section in [Chapter 3](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12),
    *Getting Started with OpenAI Gym and Deep Reinforcement Learning* of this book:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: MacOS 和 Ubuntu Linux 系统默认安装了 Python。您可以通过在终端窗口中运行`python --version`来检查安装的 Python
    版本。如果返回`python`后跟一个版本号，则可以继续进行下一步！如果出现 Python 命令未找到的错误，则需要安装 Python。请参阅本书的[第 3
    章](part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12)，*开始使用 OpenAI Gym 和深度强化学习*中的详细安装部分：
- en: 'Install `virtualenv`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`virtualenv`：
- en: '[PRE0]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If **pip** is not installed on your system, you can install it by typing `sudo
    easy_install pip`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的系统未安装**pip**，您可以通过输入`sudo easy_install pip`来安装它。
- en: 'Create a virtual environment named `openai-gym` using the virtualenv tool:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 virtualenv 工具创建名为`openai-gym`的虚拟环境：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Activate the `openai-gym` virtual environment:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活`openai-gym`虚拟环境：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Install all the packages for the Gym toolkit from upstream:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从上游安装 Gym 工具包的所有软件包：
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you get permission denied or failed with error code 1 when you run the `pip
    install` command, it is most likely because the permissions on the directory you
    are trying to install the package to (the `openai-gym` directory inside `virtualenv`
    in this case) needs special/root privileges. You can either run `sudo -H pip install
    -U gym[all]` to solve the issue or change permissions on the `openai-gym` directory
    by running `sudo chmod -R o+rw ~/openai-gym`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在运行 `pip install` 命令时遇到权限被拒绝或错误代码为 1 的失败，通常是因为你尝试安装包的目录（在本例中是 `virtualenv`
    中的 `openai-gym` 目录）需要特殊的/root 权限。你可以通过运行 `sudo -H pip install -U gym[all]` 来解决这个问题，或者通过运行
    `sudo chmod -R o+rw ~/openai-gym` 更改 `openai-gym` 目录的权限。
- en: 'Test to make sure the installation is successful:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试以确保安装成功：
- en: '[PRE4]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Creating and visualizing a new Gym environment
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和可视化一个新的 Gym 环境
- en: In just a minute or two, you have created an instance of an OpenAI Gym environment
    to get started!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 只需一分钟或两分钟，你就创建了一个 OpenAI Gym 环境实例，准备开始使用！
- en: 'Let''s open a new Python promptand import the `gym` module:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开一个新的 Python 提示符并导入 `gym` 模块：
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once the `gym` module is imported, we can use the `gym.make` method to create
    our new environment like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦导入了 `gym` 模块，我们可以使用 `gym.make` 方法像这样创建我们的新环境：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will bring up a window like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这将弹出一个类似这样的窗口：
- en: '![](img/00010.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00010.jpeg)'
- en: Hooray!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congrats on completing the first chapter! Hope you had fun creating your own
    environment. In this chapter, you learned what OpenAI Gym is all about, what features
    it provides, and what you can do with the toolkit. You now have a very good idea
    about OpenAI Gym. In the next chapter, we will go over the basics of reinforcement
    learning to give you a good foundation, which will help you build your cool intelligent
    agents as you progress through the book. Excited? Move on to the next chapter!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了第一章！希望你在创建自己的环境时感到有趣。在这一章中，你了解了 OpenAI Gym 的基本概念、它提供的功能，以及你可以用这个工具包做什么。现在，你对
    OpenAI Gym 有了很好的了解。在下一章，我们将介绍强化学习的基础知识，为你打下坚实的基础，帮助你在书中不断进步，构建你酷炫的智能代理。兴奋吗？快进入下一章吧！
