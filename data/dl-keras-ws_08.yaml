- en: 8\. Transfer Learning and Pre-Trained Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8. 迁移学习与预训练模型
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter introduces the concept of pre-trained models and utilizing them
    for different applications from those for which they were trained, known as transfer
    learning. By the end of this chapter, you will be able to apply feature extraction
    to pre-trained models, exploit pre-trained models for image classification, and
    apply fine-tuning to pre-trained models to classify images of flowers and cars
    into their respective classes. We will see that this achieves the same task that
    we completed in the previous chapter but with greater accuracy and shorter training
    times.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了预训练模型的概念及其在不同应用中的使用，这种应用不同于它们最初训练时的目标，被称为迁移学习。到本章结束时，你将能够将特征提取应用于预训练模型，利用预训练模型进行图像分类，并通过微调预训练模型，将花卉和汽车图像分类到各自的类别中。我们将看到，这样做能够完成与上一章相同的任务，但准确度更高且训练时间更短。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, we learned how to create a **Convolutional Neural Network**
    (**CNN**) from scratch with Keras. We experimented with different architectures
    by adding more convolutional and Dense layers and changing the activation function.
    We compared the performance of each model by classifying images of cars and flowers
    into their respective classes and comparing their accuracies.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用Keras从头创建**卷积神经网络**（**CNN**）。我们通过添加更多卷积层和全连接层、修改激活函数，来实验不同的架构。我们通过将汽车和花卉的图像分类到各自类别，并比较它们的准确率，来评估每个模型的性能。
- en: In real-world projects, however, you almost never code a convolutional neural
    network from scratch. You always tweak and train them as per the requirements.
    This chapter will introduce you to the important concepts of **transfer learning**
    and **pre-trained networks** (also known as **pre-trained models**), both of which
    are used in the industry.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实际项目中，你几乎从不从头开始编码一个卷积神经网络。你总是根据需求对其进行调整和训练。本章将向你介绍**迁移学习**和**预训练网络**（也称为**预训练模型**）这两个在行业中使用的重要概念。
- en: We will use images and, rather than building a CNN from scratch, we will match
    these images on pre-trained models to try and classify them. We will also tweak
    our models to make them more flexible. The models we will use in this chapter
    are called **VGG16** and **ResNet50**, and we will discuss them later in this
    chapter. Before we start working on pre-trained models, we need to understand
    transfer learning.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用图像，并且不是从头开始构建CNN，而是将这些图像与预训练模型匹配，尝试对其进行分类。我们还将调整模型，使其更加灵活。本章将使用的模型是**VGG16**和**ResNet50**，我们将在本章后续部分讨论它们。在开始使用预训练模型之前，我们需要了解迁移学习。
- en: Pre-Trained Sets and Transfer Learning
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练集与迁移学习
- en: Humans learn by experience. We apply the knowledge we gain in one situation
    to similar situations we face in the future. Suppose you want to learn how to
    drive an SUV. You have never driven an SUV; all you know is how to drive a small
    hatchback car.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人类通过经验学习。我们将从一个情境中获得的知识应用到未来面对的类似情境中。假设你想学习如何驾驶SUV，你从未驾驶过SUV，你所知道的仅仅是如何驾驶一辆小型掀背车。
- en: The dimensions of the SUV are considerably larger than the hatchback, so navigating
    the SUV in traffic will surely be a challenge. Still, some basic systems (such
    as the clutch, accelerator, and brakes) remain similar to that of the hatchback.
    So, knowing how to drive a hatchback will surely be of great help to you when
    you are learning to drive the SUV. All the knowledge that you acquired while driving
    a hatchback can be used when you learn to drive a big SUV.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: SUV的尺寸比掀背车大得多，因此在交通中驾驶SUV肯定是一个挑战。不过，一些基本系统（如离合器、油门和刹车）与掀背车相似。所以，学习驾驶SUV时，掌握了如何驾驶掀背车的技能肯定会对你大有帮助。在学习驾驶大型SUV时，所有你在驾驶掀背车时获得的知识都可以派上用场。
- en: This is precisely what transfer learning is. By definition, transfer learning
    is a concept in machine learning in which we store and use the knowledge gained
    in one activity while learning another similar activity. The hatchback-SUV model
    fits this definition perfectly.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是迁移学习的概念。迁移学习在机器学习中是指在学习一个类似的活动时，我们存储并使用在另一个活动中获得的知识。从掀背车到SUV的学习模式完全符合这一定义。
- en: Suppose we want to know whether a picture is of a dog or a cat; here, we can
    have two approaches. One is building a deep learning model from scratch and then
    passing on the new pictures to the networks. Another option is to use a pre-trained
    deep learning neural network model that has already been built by using cats'
    and dogs' images, instead of creating a neural network from scratch.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想知道一张照片是狗还是猫；在这种情况下，我们可以有两种方法。其一是从头开始构建一个深度学习模型，然后将新的图片传递给网络。另一种选择是使用一个已经通过猫狗图片构建好的预训练深度学习神经网络模型，而不是从零开始创建神经网络。
- en: Using the pre-trained model saves us computational time and resources. There
    can be some unforeseen advantages of using a pre-trained network. For example,
    almost all the pictures of dogs and cats will have some more objects in the picture,
    such as trees, the sky, and furniture. We can even use this pre-trained network
    to identify objects such as trees, the sky, and furniture.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练模型可以节省计算时间和资源。使用预训练网络可能会带来一些意想不到的好处。例如，几乎所有的狗和猫的照片中都会包含一些其他物体，如树木、天空和家具。我们甚至可以使用这个预训练网络来识别树木、天空和家具等物体。
- en: So, a pre-trained network is a saved network (a neural network, in the case
    of deep learning) that was trained on a very large dataset, mostly on image classification
    problems. To work on a pre-trained network, we need to understand the concepts
    of feature extraction and fine-tuning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，预训练网络是一个保存的网络（在深度学习的情况下是神经网络），它是在一个非常大的数据集上训练的，主要用于图像分类问题。要使用预训练网络，我们需要理解特征提取和微调的概念。
- en: Feature Extraction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征提取
- en: To understand feature extraction, we need to revisit the architecture of a convolutional
    neural network.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解特征提取，我们需要回顾卷积神经网络的架构。
- en: 'You may recall that the full architecture of a `CNN`, at a high level, consists
    of the following components:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得，`CNN`的完整架构在高层次上由以下几个部分组成：
- en: A **convolution layer**
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**卷积层**
- en: A **pooling and flattening layer**
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**池化和扁平化层**
- en: An **Artificial Neural Network** (**ANN**)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**人工神经网络**（**ANN**）
- en: 'The following figure shows a complete CNN architecture:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了完整的 CNN 架构：
- en: '![Figure 8.1: CNN architecture'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.1: CNN 架构'
- en: '](img/B15777_08_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_08_01.jpg)'
- en: 'Figure 8.1: CNN architecture'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.1: CNN 架构'
- en: 'Now, let''s divide this architecture into two parts. The first part contains
    everything but the `ANN`, while the second part only contains the `ANN`. The following
    figure shows a split `CNN` architecture:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这个架构分为两个部分。第一部分包含除`ANN`之外的所有内容，而第二部分仅包含`ANN`。下图展示了一个拆分的`CNN`架构：
- en: '![Figure 8.2: CNN split architecture – convolutional base and classifier'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.2: CNN 拆分架构 - 卷积基础层和分类器'
- en: '](img/B15777_08_02.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_08_02.jpg)'
- en: 'Figure 8.2: CNN split architecture – convolutional base and classifier'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.2: CNN 拆分架构 - 卷积基础层和分类器'
- en: The first part is called a **convolutional base** while the second part is called
    the **classifier**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分称为**卷积基础层**，而第二部分称为**分类器**。
- en: 'In feature extraction, we keep reusing the convolutional base, and the classifier
    is changed. So, we preserve the learnings of the convolutional layer, and we can
    pass different classifiers on top of the convolutional layer. A classifier can
    be dog versus cat, bikes versus cars, or even medical X-ray images to classify
    tumors, infections, and so on. The following diagram shows some convolutional
    base layers that are used for different classifiers:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征提取中，我们不断重用卷积基础层，而分类器则被替换。所以，我们保留了卷积层的学习成果，并可以将不同的分类器添加到卷积层之上。分类器可以是狗与猫、摩托车与汽车，甚至是医学X光图像来分类肿瘤、感染等。下图展示了一些用于不同分类器的卷积基础层：
- en: '![Figure 8.3: Reusable convolutional base layer'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.3: 可重用的卷积基础层'
- en: '](img/B15777_08_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_08_03.jpg)'
- en: 'Figure 8.3: Reusable convolutional base layer'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8.3: 可重用的卷积基础层'
- en: The obvious next question is, can't we reuse the classifier too, like the base
    layer? The general answer is no. The reason is that learning from the convolutional
    base is likely to be more generic and, therefore, more reusable. However, the
    learning of the classifier is mostly specific to the classes that the model was
    trained on. Therefore, it is advisable to only reuse the convolutional base layer
    and not the classifier.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见的下一个问题是，难道我们不能像基础层那样重用分类器吗？一般来说，答案是否定的。原因在于，从卷积基础部分学习可能更为通用，因此更具可重用性。然而，分类器的学习通常是特定于模型训练时所用的类别。因此，建议仅重用卷积基础层，而不是分类器。
- en: The amount of generalized learning from a convolutional base layer depends on
    the depth of the layer. For example, in the case of a cat, the initial layers
    of the model learn about general traits such as edges and the background, while
    the higher layers may learn more about specific details such as eyes, ears, or
    the shape of the nose. So, if your new dataset is something very different from
    the original dataset—for example, if you wish to identify fruit instead of cats—then
    it is better to only use some initial layers of the convolutional base layer rather
    than using the whole layer.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从卷积基础层获得的泛化学习量取决于该层的深度。例如，在猫的情况下，模型的初始层学习一般的特征，如边缘和背景，而更高层可能学习更具体的细节，如眼睛、耳朵或鼻子的形状。因此，如果你的新数据集与原始数据集非常不同——例如，如果你想识别水果而不是猫——那么最好只使用卷积基础层的一些初始层，而不是使用整个层。
- en: '`CNN`), many Dense layers on top of the network are randomly initialized, and
    there may be cases where, due to backpropagation, the learning of the initial
    layers of the network will be totally destroyed.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`CNN`)，网络顶部的许多全连接层是随机初始化的，并且可能由于反向传播的原因，网络的初始层学习会被完全破坏。'
- en: To avoid this information decay, we freeze some layers. This is done by making
    the layers non-trainable. The process of freezing some layers and training others
    is called fine-tuning a network.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免信息衰减，我们冻结了一些层。这是通过将这些层设为不可训练来实现的。冻结一些层并训练其他层的过程称为微调网络。
- en: Fine-Tuning a Pre-Trained Network
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调预训练网络
- en: Fine-tuning means tweaking our neural network in such a way that it becomes
    more relevant to the task at hand. We can freeze some of the initial layers of
    the network so that we don't lose information stored in those layers. The information
    stored there is generic and useful. However, if we can freeze those layers while
    our classifier is learning and then unfreeze them, we can tweak them a little
    so that they fit even better to the problem at hand. Suppose we have a pre-trained
    network that identifies animals. If we want to identify specific animals, such
    as dogs and cats, we can tweak the layers a little bit so that they can learn
    what dogs and cats look like. This is like using the whole pre-trained network
    and then adding a new layer that consists of images of dogs and cats. We will
    be doing a similar activity by using a pre-built network and adding a classifier
    on top of it, which will be trained on pictures of dogs and cats.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 微调意味着调整我们的神经网络，使其更适应当前的任务。我们可以冻结网络的一些初始层，这样就不会丢失存储在这些层中的信息。这些信息是通用且有用的。然而，如果我们可以在分类器学习的同时冻结这些层，然后再解冻它们，我们可以稍微调整它们，使其更好地适应当前的问题。假设我们有一个预训练网络，可以识别动物。如果我们想要识别特定的动物，比如狗和猫，我们可以稍微调整这些层，让它们学习狗和猫的外观。这就像是使用整个预训练网络，然后在其上添加一个新层，其中包含狗和猫的图像。我们将通过使用一个预构建的网络并在其上添加一个分类器来做类似的活动，分类器将基于狗和猫的图片进行训练。
- en: 'There is a three-point system to working with fine-tuning:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个三步法则来进行微调：
- en: Add a classifier (`ANN`) on top of a pre-trained system.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在预训练系统的顶部添加一个分类器（`ANN`）。
- en: Freeze the `convolutional base` and train the network.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 冻结 `卷积基础` 并训练网络。
- en: Train the added `classifier` and the unfrozen part of the `convolutional base`
    jointly.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 联合训练已添加的`分类器`和未冻结的`卷积基础`部分。
- en: The ImageNet Dataset
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ImageNet 数据集
- en: In real practical work experience, you almost never need to build a base convolutional
    model on your own. You will always use pre-trained models. But where do you get
    the data from? For visual computing, the answer is ImageNet. The ImageNet dataset
    is a large visual database that is used in visual object recognition. It consists
    of more than 14 million labeled images with object names. ImageNet contains more
    than 20,000 categories.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际工作经验中，你几乎永远不需要自己构建基础卷积模型。你总是会使用预训练模型。但数据从哪里来呢？对于视觉计算，答案是 ImageNet。ImageNet
    数据集是一个大型视觉数据库，用于视觉对象识别。它包含超过 1400 万张标注图像及其对象名称。ImageNet 包含超过 20,000 个类别。
- en: Some Pre-Trained Networks in Keras
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras 中的一些预训练网络
- en: 'The following pre-trained networks can be thought of as the base convolutional
    layers. You use these networks and fit a classifier (ANN):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下预训练网络可以被视为基础卷积层。你可以使用这些网络并为其拟合一个分类器（ANN）：
- en: '`VGG16`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VGG16`'
- en: '`Inception V3`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Inception V3`'
- en: '`Xception`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Xception`'
- en: '`ResNet50`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ResNet50`'
- en: '`MobileNet`'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MobileNet`'
- en: Different vendors have created the preceding pre-trained networks. For example,
    `ResNet50` was created by `Microsoft`, while `Inception V3` and `MobileNet` were
    created by `Google`. In this chapter, we will be working with the `VGG16` and
    `ResNet50` models.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的供应商创建了前面的预训练网络。例如，`ResNet50`是由`Microsoft`创建的，而`Inception V3`和`MobileNet`是由`Google`创建的。在本章中，我们将使用`VGG16`和`ResNet50`模型。
- en: '`VGG16` is a convolutional neural network model with 16 layers and was proposed
    by K. Simonyan and A. Zisserman from the University of Oxford. The model was submitted
    to the `ImageNet Large Scale Visual Recognition Challenge` (`ILSVRC`) in 2014—a
    challenge used to test state-of-the-art models that use the `ImageNet` dataset.
    `ResNet50` is another convolutional neural network that was trained on the `ImageNet`
    dataset that has 50 layers and won first place in the `ILSVRC` in 2015.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`VGG16`是一个具有16层的卷积神经网络模型，由牛津大学的K. Simonyan和A. Zisserman提出。该模型于2014年提交到`ImageNet大规模视觉识别挑战赛`（`ILSVRC`）——这是一个用于测试最新技术的模型的挑战，模型使用了`ImageNet`数据集。`ResNet50`是另一种在`ImageNet`数据集上训练的卷积神经网络，具有50层，并在2015年的`ILSVRC`中获得了第一名。'
- en: Now that we understand what these networks are, we will practice utilizing these
    pre-trained neural networks to classify an image of a slice of pizza with the
    `VGG16` model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了这些网络的原理，我们将练习利用这些预训练的神经网络，使用`VGG16`模型来分类一张披萨片的图像。
- en: Note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All the exercises and activities in this chapter will be developed in Jupyter
    notebooks. Please download this book's GitHub repository, along with all the prepared
    templates, from [https://packt.live/2uI63CC](https://packt.live/2uI63CC).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有练习和活动都将在Jupyter笔记本中开发。请从[https://packt.live/2uI63CC](https://packt.live/2uI63CC)下载本书的GitHub仓库以及所有准备好的模板。
- en: 'Exercise 8.01: Identifying an Image Using the VGG16 Network'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习8.01：使用VGG16网络识别图像
- en: 'We have a picture of a slice of pizza. We will use the `VGG16` network to process
    and identify the image. Before completing the following steps, ensure you have
    downloaded the `pizza` image from GitHub and saved it to your working directory:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一张披萨片的图片。我们将使用`VGG16`网络来处理并识别这张图像。在完成以下步骤之前，请确保从GitHub下载了`pizza`图像并将其保存到你的工作目录中：
- en: 'Import the libraries:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE0]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Initiate the model (this may take a while):'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化模型（这可能需要一些时间）：
- en: '[PRE1]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The last layer of predictions (`Dense`) has 1,000 values. This means that `VGG16`
    has a total of 1,000 labels and our image will be one out of those 1,000 labels.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预测的最后一层（`Dense`）有1000个值。这意味着`VGG16`总共有1000个标签，我们的图像将是这1000个标签中的一个。
- en: 'Load the image. `''../Data/Prediction/pizza.jpg.jpg''` is the path of the image
    on our system; it may be different on your system:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像。`'../Data/Prediction/pizza.jpg.jpg'`是我们系统中图像的路径；在你的系统中可能会有所不同：
- en: '[PRE2]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了前面代码的输出：
- en: '![Figure 8.4: An image of a slice of pizza'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图8.4：披萨片的图像'
- en: '](img/B15777_08_04.jpg)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_04.jpg)'
- en: 'Figure 8.4: An image of a slice of pizza'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8.4：披萨片的图像
- en: The target size should be `224x224` since `VGG16` only accepts (`224,224`).
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标大小应该是`224x224`，因为`VGG16`仅接受（`224,224`）大小。
- en: 'Change the image to an array by using the `img_to_array` function:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`img_to_array`函数将图像转换为数组：
- en: '[PRE3]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code produces the following output:'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '[PRE4]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The image has to be in a four-dimensional form for `VGG16` to allow further
    processing. Expand the dimension of the image, as follows:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像必须是四维形式，以便`VGG16`能够进行进一步处理。扩展图像的维度，如下所示：
- en: '[PRE5]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code produces the following output:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '[PRE6]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Preprocess the image using the `preprocess_input` function:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`preprocess_input`函数对图像进行预处理：
- en: '[PRE7]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了前面代码的输出：
- en: '![Figure 8.5: A screenshot of image preprocessing'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图8.5：图像预处理的屏幕截图'
- en: '](img/B15777_08_05.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_05.jpg)'
- en: 'Figure 8.5: A screenshot of image preprocessing'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8.5：图像预处理的屏幕截图
- en: 'Create the `predictor` variable:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`predictor`变量：
- en: '[PRE8]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Check the shape of the image. It should be (`1,1000`). It''s `1000` because
    the `ImageNet` database has `1000` categories of images. The predictor variable
    shows the probability of our image being one of those images:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查图像的形状。它应该是（`1,1000`）。`1000`是因为`ImageNet`数据库有`1000`个类别的图像。预测变量显示了我们图像属于这些图像之一的概率：
- en: '[PRE9]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code produces the following output:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '[PRE10]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Print the top five probabilities of what our image is using the `decode_predictions`
    function and pass the function of the predictor variable, `y_pred`, and the number
    of predictions and corresponding labels to output:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`decode_predictions`函数打印出我们的图像是什么的前五个概率，并传递预测变量`y_pred`的函数和预测数量及相应的标签输出：
- en: '[PRE11]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code produces the following output:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前述代码生成以下输出：
- en: '[PRE12]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first column of the array is the internal code number. The second is the
    possible label, while the third is the probability of the image being the label.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组的第一列是内部代码编号。第二列是可能的标签，第三列是图片为该标签的概率。
- en: 'Put the predictions in a human-readable form. Print the most probable label
    from the output from the result of the `decode_predictions` function:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果以人类可读的形式呈现。从`decode_predictions`函数的输出中打印出最有可能的标签：
- en: '[PRE13]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding code produces the following output:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前述代码生成以下输出：
- en: '[PRE14]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this exercise, we predicted an image that says (with `97.68%` probability)
    that the picture is pizza. Clearly, higher accuracy here means a relatively similar
    object to our picture is present in the ImageNet database, and our algorithm has
    successfully identified the image.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们预测了一个图片，显示（以`97.68%`的概率）这张图片是披萨。显然，更高的准确率意味着我们的图片在ImageNet数据库中存在一个相对相似的对象，并且我们的算法成功识别了这张图片。
- en: Note
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3dXqdsQ](https://packt.live/3dXqdsQ).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本节的源代码，请参阅[https://packt.live/3dXqdsQ](https://packt.live/3dXqdsQ)。
- en: You can also run this example online at [https://packt.live/3dZMZAq](https://packt.live/3dZMZAq).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在[https://packt.live/3dZMZAq](https://packt.live/3dZMZAq)上在线运行这个示例。
- en: In the following activity, we will put our knowledge to practice by using the
    `VGG16` network to classify an image of a motorbike.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的活动中，我们将通过使用`VGG16`网络来对不在ImageNet数据库中的图片进行分类，将我们的知识付诸实践。
- en: 'Activity 8.01: Using the VGG16 Network to Train a Deep Learning Network to
    Identify Images'
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 8.01：使用VGG16网络训练深度学习网络以识别图像
- en: 'You are given an image of a motorbike. Use the `VGG16` network to predict the
    image. Before you start, ensure that you have downloaded the image (`test_image_1`)
    to your working directory. To complete this activity, follow these steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一张摩托车的图片。使用`VGG16`网络来预测这张图片。在开始之前，请确保已将图片（`test_image_1`）下载到你的工作目录中。要完成这个活动，请按照以下步骤操作：
- en: Import the required libraries, along with the `VGG16` network.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库，包括`VGG16`网络。
- en: Initiate the pre-trained `VGG16` model.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化预训练的`VGG16`模型。
- en: Load the image that is going to be classified.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载将要分类的图片。
- en: Preprocess the image by applying the transformations.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过应用转换来预处理图片。
- en: Create a predictor variable to predict the image.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个预测变量来预测图像。
- en: Label the image and classify it.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给图片贴上标签并进行分类。
- en: Note
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 444.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第444页找到。
- en: With that, we have completed this activity. Unlike in *Chapter 7*, *Computer
    Vision with Convolutional Neural Networks*, we did not build a `CNN` from scratch.
    Instead, we used a pre-trained model. We just uploaded a picture that needs to
    be classified. From this, we can see that, with `84.33%` accuracy, it is predicted
    to be a moped. In the next exercise, we'll work with an image for which there
    is no matching image in the ImageNet database.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，我们完成了这个活动。与*第7章*的*使用卷积神经网络进行计算机视觉*不同，我们没有从头开始构建`CNN`。相反，我们使用了一个预训练的模型。我们刚刚上传了一张需要分类的图片。从中可以看出，以`84.33%`的准确率预测它是一辆踏板车。在下一个练习中，我们将使用ImageNet数据库中没有匹配图片的图片。
- en: 'Exercise 8.02: Classifying Images That Are Not Present in the ImageNet Database'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 8.02：对不在ImageNet数据库中的图片进行分类
- en: 'Now, let''s work with an image that is not part of the `1000` labels in our
    `VGG16` network. In this exercise, we will work with an image of a stick insect,
    and there are no labels for stick insects in our pre-trained network. Let''s see
    what results we get:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们处理一张不在`VGG16`网络的`1000`个标签中的图像。在这个练习中，我们将处理一张竹节虫的图片，而我们的预训练网络中没有竹节虫的标签。让我们看看我们得到什么结果：
- en: 'Import the `numpy` library and the necessary `Keras` libraries:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库和必要的`Keras`库：
- en: '[PRE15]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Initiate the model and print a summary of the model:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化模型并打印模型的摘要：
- en: '[PRE16]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`classifier.summary()` shows us the architecture of the network. The following
    are the points to be noted – it has a four-dimensional input shape (`None, 224,
    224, 3`) and it has three convolutional layers. The following figure shows the
    last four layers of the output:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`classifier.summary()`显示了网络的架构。以下是需要注意的点 - 它具有四维输入形状（`None, 224, 224, 3`），并且具有三个卷积层。以下图显示了输出的最后四层：'
- en: '![Figure 8.6: Summary of the image using the VGG16 classifier'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.6：使用VGG16分类器对图像的摘要'
- en: '](img/B15777_08_06.jpg)'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_06.jpg)'
- en: 'Figure 8.6: Summary of the image using the VGG16 classifier'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.6：使用VGG16分类器对图像的摘要
- en: Note
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The last layer of predictions (`Dense`) has `1000` values. This means that `VGG16`
    has a total of `1000` labels and that our image will be one out of those `1000`
    labels.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预测的最后一层（`Dense`）有`1000`个值。这意味着`VGG16`有`1000`个标签，而我们的图像将是这些标签中的一个。
- en: 'Load the image. `''../Data/Prediction/stick_insect.jpg''` is the path of the
    image on our system. It will be different on your system:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像。`'../Data/Prediction/stick_insect.jpg'`是我们系统上的图像路径。在您的系统上可能会有所不同：
- en: '[PRE17]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 8.7: Sample stick insect image for prediction'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.7：用于预测的示例竹节虫图像'
- en: '](img/B15777_08_07.jpg)'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_07.jpg)'
- en: 'Figure 8.7: Sample stick insect image for prediction'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.7：用于预测的示例竹节虫图像
- en: The target size should be `224x224` since `VGG16` only accepts (`224,224`).
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标大小应为`224x224`，因为`VGG16`仅接受（`224,224`）。
- en: 'Change the image to an array by using the `img_to_array` function:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`img_to_array`函数将图像转换为数组：
- en: '[PRE18]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The image must be in a four-dimensional form for `VGG16` to allow further processing.
    Expand the dimension of the image along the 0th axis using the `expand_dims` function:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像必须以四维形式存在，以便`VGG16`允许进一步处理。使用`expand_dims`函数沿着第0轴扩展图像的维度：
- en: '[PRE19]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Preprocess the image using the `preprocess_input` function:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`preprocess_input`函数预处理图像：
- en: '[PRE20]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 8.8: Screenshot showing a few instances of image preprocessing'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.8：显示图像预处理的几个实例'
- en: '](img/B15777_08_08.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_08.jpg)'
- en: 'Figure 8.8: Screenshot showing a few instances of image preprocessing'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.8：显示图像预处理的几个实例
- en: 'Create the `predictor` variable:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`predictor`变量：
- en: '[PRE21]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 8.9: Creating the predictor variable'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.9：创建预测变量'
- en: '](img/B15777_08_09.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_09.jpg)'
- en: 'Figure 8.9: Creating the predictor variable'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.9：创建预测变量
- en: 'Check the shape of the image. It should be (`1,1000`). It''s `1000` because,
    as we mentioned previously, the ImageNet database has `1000` categories of images.
    The predictor variable shows the probabilities of our image being one of those
    images:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查图像的形状。它应该是（`1,1000`）。这是因为，正如我们之前提到的，ImageNet数据库有`1000`个图像类别。预测变量显示了我们的图像属于这些图像之一的概率：
- en: '[PRE22]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code produces the following code:'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下代码：
- en: '[PRE23]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Select the top five probabilities of what our image label is out of the `1000`
    labels that the `VGG16` network has:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择出`VGG16`网络具有的`1000`个标签中，我们图像标签的前五个最高概率：
- en: '[PRE24]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The preceding code produces the following code:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下代码：
- en: '[PRE25]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The first column of the array is an internal code number. The second is the
    label, while the third is the probability of the image being the label.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组的第一列是内部代码编号。第二列是标签，而第三列是图像成为该标签的概率。
- en: 'Put the predictions in a human-readable format. Print the most probable label
    from the output from the result of the `decode_predictions` function:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果以人类可读的格式呈现出来。从`decode_predictions`函数的输出中打印出最可能的标签：
- en: '[PRE26]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding code produces the following code:'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下代码：
- en: '[PRE27]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here, you can see that the network predicted that our image was a walking stick
    with `30.52%` accuracy. Clearly, the image is not a walking stick but a stick
    insect; out of all the labels that the `VGG16` network contains, a walking stick
    is the closest thing to a stick insect. The following image is that of a walking
    stick:'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，您可以看到网络预测我们的图像是竹节虫，准确率为`30.52%`。显然，这张图像不是竹节虫，而是一只竹节虫；在`VGG16`网络包含的所有标签中，竹节虫是最接近的事物。以下图片展示了一只竹节虫：
- en: '![Figure 8.10: Walking stick'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.10：竹节虫'
- en: '](img/B15777_08_10.jpg)'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_10.jpg)'
- en: 'Figure 8.10: Walking stick'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10：竹节虫
- en: To avoid such outputs, we could freeze the existing layer of `VGG16` and add
    our own layer. We could also add a layer that contains images of walking sticks
    and stick insects so that we can obtain better output.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种输出，我们可以冻结`VGG16`现有的层，并添加我们自己的层。我们还可以添加一个包含拐杖和竹节虫图像的层，以便我们能够获得更好的输出。
- en: If you have a large number of a walking stick and stick insect images, you could
    perform a similar task to improve the model's ability to classify images into
    their respective classes. You could then test it by rerunning the previous exercise.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有大量的拐杖和竹节虫的图像，你可以进行类似的操作来提升模型在分类这些图像时的能力。然后你可以通过重新运行之前的练习来测试它。
- en: Note
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31I7bnR](https://packt.live/31I7bnR).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参见 [https://packt.live/31I7bnR](https://packt.live/31I7bnR)。
- en: You can also run this example online at [https://packt.live/31Hv1QE](https://packt.live/31Hv1QE).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过在线运行这个例子，访问 [https://packt.live/31Hv1QE](https://packt.live/31Hv1QE)。
- en: To understand this in detail, let's work on a different example, where we freeze
    the last layer of the network and add our own layer with images of cars and flowers.
    This will help the network improve its accuracy in classifying images of cars
    and flowers.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更详细地理解这一点，我们来看一个不同的例子，在这个例子中，我们冻结网络的最后一层，并添加自己的层，包含汽车和花卉的图像。这将帮助网络提高分类汽车和花卉图像的准确性。
- en: 'Exercise 8.03: Fine-Tuning the VGG16 Model'
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习8.03：微调VGG16模型
- en: Let's work on fine-tuning the `VGG16` model. In this exercise, we will freeze
    the network and remove the last layer of `VGG16`, which has `1000` labels in it.
    After removing the last layer, we will build a new flower-car classifier `ANN`,
    just like we did in *Chapter 7*, *Computer Vision with Convolutional Neural Networks*,
    and will connect this `ANN` to `VGG16` instead of the original one with `1000`
    labels. Essentially, what we will do is replace the last layer of `VGG16` with
    a user-defined layer.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来进行`VGG16`模型的微调。在这个练习中，我们将冻结网络并移除`VGG16`的最后一层，该层包含`1000`个标签。移除最后一层后，我们将建立一个新的花卉-汽车分类器`ANN`，就像我们在*第7章*《卷积神经网络与计算机视觉》中做的那样，并将这个`ANN`连接到`VGG16`，而不是原始的具有`1000`个标签的模型。基本上，我们所做的就是用用户自定义的层替换`VGG16`的最后一层。
- en: Before we begin, ensure you have downloaded the image datasets from this book's
    GitHub repository to your own working directory. You will need a `training_set`
    folder and a `test_set` folder to test your model. Each of these folders will
    contain a `cars` folder, containing car images, and a `flowers` folder, containing
    flower images.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保你已经从本书的GitHub仓库下载了图像数据集到自己的工作目录。你将需要一个`training_set`文件夹和一个`test_set`文件夹来测试你的模型。每个文件夹里都会包含一个`cars`文件夹，里面是汽车图像，还有一个`flowers`文件夹，里面是花卉图像。
- en: 'The steps for completing this exercise are as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此练习的步骤如下：
- en: Note
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Unlike the original new model, which had `1000` labels (`100` different object
    categories), this new fine-tuned model will only have images of flowers or cars.
    So, whatever image you provide as an input to the model, it will categorize it
    as a flower or car based on its prediction probability.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 与原始的新模型（具有`1000`个标签，涵盖`100`个不同的物体类别）不同，这个新的微调模型仅包含花卉或汽车的图像。因此，不管你向模型输入什么图像，它都会根据预测概率将其分类为花卉或汽车。
- en: 'Import the `numpy` library, TensorFlow''s `random` library, and the necessary
    `Keras` libraries:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库、TensorFlow的`random`库以及所需的`Keras`库：
- en: '[PRE28]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Initiate the `VGG16` model:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动`VGG16`模型：
- en: '[PRE29]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Check the model `summary`:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查模型`summary`：
- en: '[PRE30]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前述代码的输出：
- en: '![Figure 8.11: Model summary after initiating the model'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图8.11：启动模型后的模型总结'
- en: '](img/B15777_08_11.jpg)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_11.jpg)'
- en: 'Figure 8.11: Model summary after initiating the model'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8.11：启动模型后的模型总结
- en: 'Remove the last layer, `labeled predictions` in the preceding image, from the
    model summary. Create a new Keras model of the sequential class and iterate through
    all the layers of the VGG model. Add all of them to the new model, except for
    the last layer:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从模型总结中移除最后一层，即前述图像中的`labeled predictions`。创建一个新的Keras顺序模型，并遍历VGG模型的所有层。将所有层添加到新模型中，除了最后一层：
- en: '[PRE31]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, we have created a new model name's classifier instead of `vgg_model`.
    All the layers, except the last layer, that is, `vgg_model`, have been included
    in the classifier.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个新的模型分类器名称，而不是`vgg_model`。所有层，除了最后一层，即`vgg_model`，都已经包含在分类器中。
- en: 'Print the `summary` of the newly created model:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印新创建模型的`summary`：
- en: '[PRE32]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了上述代码的输出：
- en: '![Figure 8.12: Rechecking the summary after removing the last layer'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.12：移除最后一层后重新检查摘要'
- en: '](img/B15777_08_12.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_12.jpg)'
- en: 'Figure 8.12: Rechecking the summary after removing the last layer'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.12：移除最后一层后重新检查摘要
- en: The last layer of prediction (`Dense`) has been deleted.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后一层的预测层（`Dense`）已被删除。
- en: 'Freeze the layers by iterating through the layers and setting the `trainable`
    parameter to `False`:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过遍历各层并将`trainable`参数设置为`False`来冻结这些层：
- en: '[PRE33]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Add a new output layer of size `1` with a `sigmoid` activation function and
    print the model summary:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个大小为`1`的新输出层，使用`sigmoid`激活函数并打印模型摘要：
- en: '[PRE34]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following function shows the output of the preceding code:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下函数显示了上述代码的输出：
- en: '![Figure 8.13: Rechecking the summary after adding the new layer'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.13：添加新层后重新检查摘要'
- en: '](img/B15777_08_13.jpg)'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_13.jpg)'
- en: 'Figure 8.13: Rechecking the summary after adding the new layer'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.13：添加新层后重新检查摘要
- en: Now, the last layer is the newly created user-defined layer.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，最后一层是新创建的用户定义层。
- en: 'Compile the network with an `adam` optimizer and binary cross-entropy loss
    and compute the `accuracy` during training:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`adam`优化器和二元交叉熵损失函数来编译网络，并在训练过程中计算`accuracy`：
- en: '[PRE35]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Create some training and test data generators, just like we did in *Chapter
    7*, *Computer Vision with Convolutional Neural Networks*. Rescale the training
    and test images by `1/255` so that all the values are between `0` and `1`. Set
    the following parameters for the training data generators only: `shear_range=0.2`,
    `zoom_range=0.2`, and `horizontal_flip=True`.'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建一些训练和测试数据生成器，就像我们在*第七章*，*使用卷积神经网络进行计算机视觉*中所做的那样。将训练和测试图像重新缩放为`1/255`，确保所有值都在`0`和`1`之间。仅为训练数据生成器设置以下参数：`shear_range=0.2`、`zoom_range=0.2`
    和 `horizontal_flip=True`。
- en: Next, create a training set from the `training set` folder. `../Data/dataset/training_set`
    is the folder where our data is placed. Our CNN model has an image size of `224x224`,
    so the same size should be passed here too. `batch_size` is the number of images
    in a single batch, which is `32`. `class_mode` is binary since we are creating
    a binary classifier.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，从`training set`文件夹中创建训练集。`../Data/dataset/training_set`是我们存放数据的文件夹。我们的CNN模型的图像大小为`224x224`，所以这里也应该传入相同的大小。`batch_size`是每个批次中的图像数量，即`32`。`class_mode`是二进制的，因为我们正在创建一个二分类器。
- en: '[PRE36]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'There are 100 training images here, so set `steps_per_epoch =100`, set `validation_steps=30`,
    and set `shuffle=False`:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里有100张训练图像，所以设置`steps_per_epoch = 100`，设置`validation_steps=30`，并设置`shuffle=False`：
- en: '[PRE37]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Predict the new image (the code is the same as it was in *Chapter 7*, *Computer
    Vision with Convolutional Neural Networks*). First, load the image from `'../Data/Prediction/test_image_2.jpg'`
    and set the target size to (`224, 224`) since the `VGG16` model accepts images
    of that size.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测新图像（代码与*第七章*，*使用卷积神经网络进行计算机视觉*中的相同）。首先，从`'../Data/Prediction/test_image_2.jpg'`加载图像，并将目标大小设置为（`224,
    224`），因为`VGG16`模型接受该大小的图像。
- en: '[PRE38]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: At this point, you can view the image by executing the code `new_image` and
    the class labels by running `training_dataset.class_indices`.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此时，你可以通过执行代码`new_image`来查看图像，通过运行`training_dataset.class_indices`来查看类标签。
- en: 'Next, preprocess the image, first by converting the image into an array using
    the `img_to_array` function, then by adding another dimension along the 0th axis
    using the `expand_dims` function. Finally, make the prediction using the `predict`
    method of the classifier and printing the output in human-readable format:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，先通过`img_to_array`函数将图像转换为数组，再使用`expand_dims`函数沿着第0轴添加一个新的维度。最后，使用分类器的`predict`方法进行预测，并以人类可读格式打印输出：
- en: '[PRE39]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The preceding code produces the following output:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE40]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: As a final step, you can save the classifier by running `classifier.save('car-flower-classifier.h5')`.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步，你可以通过运行`classifier.save('car-flower-classifier.h5')`来保存分类器。
- en: Here, we can see that the algorithm has done the correct image classification
    by identifying the image of the car. We just used a pre-built `VGG16` model for
    image classification by tweaking its layers and molding it as per our requirements.
    This is a very powerful technique for image classification.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到算法通过识别汽车图像完成了正确的图像分类。我们仅使用了一个预先构建的`VGG16`模型，通过调整其层并根据我们的需求进行定制，完成了图像分类。这是一种非常强大的图像分类技术。
- en: Note
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2ZxCqzA](https://packt.live/2ZxCqzA)
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考[https://packt.live/2ZxCqzA](https://packt.live/2ZxCqzA)
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线交互示例，需要在本地运行。
- en: In the next exercise, we will utilize a different pre-trained model, known as
    `ResNet50`, and demonstrate how to classify images with this model.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将使用另一个预训练模型 `ResNet50`，并展示如何使用该模型进行图像分类。
- en: 'Exercise 8.04: Image Classification with ResNet'
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 8.04：使用 ResNet 进行图像分类
- en: 'Finally, before closing this chapter, let''s work on an exercise with the `ResNet50`
    network. We''ll use an image of a Nascar racer and try to predict it through the
    network. Follow these steps to complete this exercise:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在结束本章之前，让我们来做一个关于 `ResNet50` 网络的练习。我们将使用一张纳斯卡赛车手的图像并尝试通过网络预测。按照以下步骤完成该练习：
- en: 'Import the necessary libraries:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库：
- en: '[PRE41]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Initiate the `ResNet50` model and print the `summary` of the model:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 `ResNet50` 模型并打印该模型的 `summary`：
- en: '[PRE42]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图表显示了前面代码的输出：
- en: '![Figure 8.14: A summary of the model'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.14：模型的总结'
- en: '](img/B15777_08_14.jpg)'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_14.jpg)'
- en: 'Figure 8.14: A summary of the model'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.14：模型的总结
- en: 'Load the image. `''../Data/Prediction/test_image_3.jpg''` is the path of the
    image on our system. It will be different on your system:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像。`'../Data/Prediction/test_image_3.jpg'` 是我们系统中图像的路径。您系统中的路径会有所不同：
- en: '[PRE43]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图表显示了前面代码的输出：
- en: '![Figure 8.15: Sample Nascar racer image for prediction'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.15：用于预测的纳斯卡赛车手图像示例'
- en: '](img/B15777_08_15.jpg)'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_15.jpg)'
- en: 'Figure 8.15: Sample Nascar racer image for prediction'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.15：用于预测的纳斯卡赛车手图像示例
- en: Note that the target size should be `224x224` since `ResNet50` only accepts
    (`224,224`).
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，目标大小应为 `224x224`，因为 `ResNet50` 仅接受 (`224,224`) 的输入。
- en: 'Change the image to an array by using the `img_to_array` function:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `img_to_array` 函数将图像转换为数组：
- en: '[PRE44]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The image has to be in a four-dimensional form for `ResNet50` to allow further
    processing. Expand the dimension along the 0th axis using the `expand_dims` function:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了让 `ResNet50` 进行进一步处理，图像必须是四维形式。使用 `expand_dims` 函数沿着第 0 轴扩展维度：
- en: '[PRE45]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Preprocess the image using the `preprocess_input` function:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `preprocess_input` 函数预处理图像：
- en: '[PRE46]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Create the predictor variable by using the classifier to predict the image
    using its `predict` method:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用分类器的 `predict` 方法创建预测变量，通过该方法预测图像：
- en: '[PRE47]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Check the shape of the image. It should be (`1,1000`):'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查图像的形状。它应该是 (`1,1000`)：
- en: '[PRE48]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The preceding code produces the following output:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码会产生以下输出：
- en: '[PRE49]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Select the top five probabilities of what our image is using the `decode_predictions`
    function and by passing the predictor variable, `y_pred`, as the argument and
    the top number of predictions and corresponding labels:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `decode_predictions` 函数选择图像的前五个概率，并通过传递预测变量 `y_pred` 作为参数，得到前几个预测和相应的标签：
- en: '[PRE50]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding code produces the following output:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码会产生以下输出：
- en: '[PRE51]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The first column of the array is an internal code number. The second is the
    label, while the third is the probability of the image being the label.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组的第一列是内部代码编号，第二列是标签，第三列是图像为该标签的概率。
- en: 'Put the predictions in a human-readable format. Print the most probable label
    from the output from the result of the `decode_predictions` function:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果以人类可读的格式输出。从 `decode_predictions` 函数的结果中打印最可能的标签：
- en: '[PRE52]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The preceding code produces the following output:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码会产生以下输出：
- en: '[PRE53]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Here, the model clearly shows (with a probability of `80.13%`) that the picture
    is that of a racer. This is the power of pre-trained models, and Keras gives us
    the flexibility to use and tweak these models.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，模型明确显示（概率为`80.13%`）图片是赛车手的照片。这就是预训练模型的强大之处，Keras 使我们可以灵活地使用和调整这些模型。
- en: Note
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2BzvTMK](https://packt.live/2BzvTMK).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考[https://packt.live/2BzvTMK](https://packt.live/2BzvTMK)。
- en: You can also run this example online at [https://packt.live/3eWelJh](https://packt.live/3eWelJh).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3eWelJh](https://packt.live/3eWelJh) 上在线运行此示例。
- en: In the next activity, we will classify another image using the pre-trained `ResNet50`
    model.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个活动中，我们将使用预训练的 `ResNet50` 模型分类另一张图像。
- en: 'Activity 8.02: Image Classification with ResNet'
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 8.02：使用 ResNet 进行图像分类
- en: 'Now, let''s work on an activity that uses another pre-trained network, known
    as `ResNet`. We have an image of television located at `../Data/Prediction/test_image_4`.
    We will use the `ResNet50` network to predict the image. To implement the activity,
    follow these steps:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进行一个使用另一个预训练网络（`ResNet`）的活动。我们有一张电视图像，位于`../Data/Prediction/test_image_4`。我们将使用`ResNet50`网络来预测这张图像。要实现该活动，请按以下步骤操作：
- en: Import the required libraries.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库。
- en: Initiate the `ResNet` model.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动`ResNet`模型。
- en: Load the image that needs to be classified.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载需要分类的图像。
- en: Preprocess the image by applying the appropriate transformations.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过应用适当的转换来预处理图像。
- en: Create a predictor variable to predict the image.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个预测变量来预测图像。
- en: Label the image and classify it.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给图像贴上标签并进行分类。
- en: Note
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 448.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第448页找到。
- en: So, the network says, with close to `100%` accuracy, that the image is that
    of a television. This time, we used a `ResNet50` pre-trained model to classify
    the image of television and obtained similar results to those we obtained using
    the `VGG16` model to predict the image of a slice of pizza.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，网络以接近`100%`的准确率判断这张图像是电视的图像。这次，我们使用了`ResNet50`预训练模型来对电视图像进行分类，获得了与使用`VGG16`模型预测披萨切片图像时相似的结果。
- en: Summary
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the concept of transfer learning and how is it related
    to pre-trained networks. We utilized this knowledge by using the pre-trained deep
    learning networks `VGG16` and `ResNet50` to predict various images. We practiced
    how to take advantage of such pre-trained networks using techniques such as feature
    extraction and fine-tuning to train models faster and more accurately. Finally,
    we learned the powerful technique of tweaking existing models and making them
    work according to our dataset. This technique of building our own `ANN` over an
    existing `CNN` is one of the most powerful techniques used in the industry.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讲解了迁移学习的概念以及它与预训练网络的关系。我们通过使用预训练的深度学习网络`VGG16`和`ResNet50`来预测各种图像，应用了这些知识。我们练习了如何利用预训练网络，通过特征提取和微调等技术，加速模型训练并提高准确性。最后，我们学习了通过调整现有模型并使其根据我们的数据集工作这一强大技术。构建自己的`ANN`基于现有的`CNN`，是业界最强大的技术之一。
- en: In the next chapter, we will learn about sequential modeling and sequential
    memory by looking at some real-life cases with Google Assistant. Furthermore,
    we will learn how sequential modeling is related to `Recurrent Neural Networks`
    (`RNN`). We will learn about the vanishing gradient problem in detail and how
    using an `LSTM` is better than a simple `RNN` to overcome the vanishing gradient
    problem. We will apply what we have learned to time series problems by predicting
    stock trends that come out as fairly accurate.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将通过研究一些 Google Assistant 的真实案例来学习顺序建模和顺序记忆。此外，我们还将学习顺序建模与`循环神经网络`（`RNN`）的关系。我们将详细了解消失梯度问题，并学习如何使用`LSTM`比简单的`RNN`更好地克服消失梯度问题。我们将把所学应用于时间序列问题，通过预测股票趋势，得出相当准确的结果。
