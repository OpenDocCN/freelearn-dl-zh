

# ç¬¬äºŒç« ï¼šæ­ç§˜ RAG

åœ¨ä¸Šä¸€ç« ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº† LLM çš„æ¼”å˜ä»¥åŠå®ƒä»¬å¦‚ä½•æ”¹å˜ GenAI çš„æ ¼å±€ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†ä¸€äº›å®ƒä»¬çš„é™·é˜±ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•ä½¿ç”¨ **Retrieval-Augmented Generation** ï¼ˆ**RAG**ï¼‰æ¥é¿å…è¿™äº›é™·é˜±ã€‚æˆ‘ä»¬å°†æ¢è®¨ RAG çš„å«ä¹‰ã€å…¶æ¶æ„ä»¥åŠå®ƒåœ¨æ„å»ºæ”¹è¿›çš„æ™ºèƒ½åº”ç”¨ç¨‹åºçš„ LLM å·¥ä½œæµç¨‹ä¸­çš„ä½ç½®ã€‚

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹ä¸»è¦ä¸»é¢˜ï¼š

+   ç†è§£ RAG çš„åŠ›é‡

+   è§£æ„ RAG æµç¨‹

+   ä¸ºæ‚¨çš„ RAG æ£€ç´¢å¤–éƒ¨ä¿¡æ¯

+   æ„å»ºç«¯åˆ°ç«¯ RAG æµç¨‹

# æŠ€æœ¯è¦æ±‚

æœ¬ç« éœ€è¦ç†Ÿæ‚‰ Python ç¼–ç¨‹è¯­è¨€ï¼ˆå»ºè®®ä½¿ç”¨ç‰ˆæœ¬ `3.6` æˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰ä»¥åŠæ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€‚

æˆ‘ä»¬å°†åˆ©ç”¨æµè¡Œçš„ AI å·¥å…·åŒ…ï¼Œå¦‚ Hugging Face çš„ Transformers åº“ ([`huggingface.co/docs/transformers/en/index`](https://huggingface.co/docs/transformers/en/index)) æ¥æ„å»ºå’Œå®éªŒ RAGã€‚è™½ç„¶ä¸æ˜¯å¼ºåˆ¶æ€§çš„ï¼Œä½†å…·å¤‡ Git ç‰ˆæœ¬æ§åˆ¶çš„åŸºæœ¬ç†è§£å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ã€‚

Git å…è®¸æ‚¨è½»æ¾åœ°å…‹éš†æœ¬ç« çš„ä»£ç å­˜å‚¨åº“å¹¶è·Ÿè¸ªæ‚¨æ‰€åšçš„ä»»ä½•æ›´æ”¹ã€‚æ— éœ€æ‹…å¿ƒè‡ªå·±å¯»æ‰¾æˆ–è¾“å…¥ä»£ç ï¼æˆ‘ä»¬å·²ç»åœ¨ GitHub ä¸Šåˆ›å»ºäº†ä¸€ä¸ªä¸“é—¨çš„å…¬å…±å­˜å‚¨åº“ï¼Œ[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch2`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch2)ï¼Œæ‚¨å¯ä»¥é€šè¿‡å®ƒè½»æ¾åœ°å…‹éš†å¹¶è·Ÿéšæœ¬ç« çš„åŠ¨æ‰‹ç»ƒä¹ ã€‚

æœ¬å­˜å‚¨åº“åŒ…å«å®ç° RAG æ¨¡å‹ä»¥åŠå°† Neo4j ä¸é«˜çº§çŸ¥è¯†å›¾è°±åŠŸèƒ½é›†æˆçš„æ‰€æœ‰å¿…è¦è„šæœ¬ã€æ–‡ä»¶å’Œé…ç½®ã€‚

ä¸ºäº†è·Ÿä¸Šè¿›åº¦ï¼Œè¯·ç¡®ä¿æ‚¨åœ¨ç¯å¢ƒä¸­å®‰è£…äº†ä»¥ä¸‹ Python åº“ï¼š

+   **Transformers**ï¼šå®‰è£… Hugging Face Transformers åº“ä»¥å¤„ç†æ¨¡å‹ç›¸å…³åŠŸèƒ½ï¼š`pip install transformers`ã€‚

+   **PyTorch**ï¼šå°† PyTorch ä½œä¸ºè®¡ç®—çš„åç«¯è¿›è¡Œå®‰è£…ã€‚æŒ‰ç…§ [`pytorch.org/get-started/locally/`](https://pytorch.org/get-started/locally/) ä¸Šçš„è¯´æ˜å®‰è£…é€‚åˆæ‚¨ç³»ç»Ÿçš„ç›¸åº”ç‰ˆæœ¬ã€‚

+   **scikit-learn**ï¼šå¯¹äºç›¸ä¼¼åº¦è®¡ç®—ï¼Œä½¿ç”¨ `pip install scikit-learn` å‘½ä»¤å®‰è£… `scikit-learn`ã€‚

+   **NumPy**ï¼šå®‰è£… NumPy ä»¥è¿›è¡Œæ•°å€¼è¿ç®—ï¼š`pip install numpy`ã€‚

+   **SentencePiece**ï¼šæŸäº›æ¨¡å‹éœ€è¦ SentencePiece è¿›è¡Œæ–‡æœ¬åˆ†è¯ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®˜æ–¹ GitHub å­˜å‚¨åº“ä¸­æä¾›çš„è¯´æ˜è¿›è¡Œå®‰è£…ï¼š[`github.com/google/sentencepiece#installation`](https://github.com/google/sentencepiece#installation)ã€‚å¯¹äºå¤§å¤šæ•° Python ç¯å¢ƒï¼Œæ‚¨å¯ä»¥é€šè¿‡ `pip` å®‰è£…å®ƒï¼š`pip install sentencepiece`ã€‚

+   **rank_bm25**ï¼šå®ç°åŸºäºå…³é”®å­—çš„æ£€ç´¢çš„ BM25 ç®—æ³•éœ€è¦ `rank_bm25` åº“ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `pip` å®‰è£…å®ƒï¼š`pip install rank_bm25`ã€‚

+   **æ•°æ®é›†**ï¼šHugging Face çš„`datasets`åº“æä¾›äº†é«˜æ•ˆçš„å·¥å…·ï¼Œç”¨äºåŠ è½½æ•°æ®é›†ã€å¤„ç†å’Œè½¬æ¢æ•°æ®é›†ã€‚å®ƒæ”¯æŒä½¿ç”¨æœ€å°å†…å­˜ä½¿ç”¨é‡å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`pip install datasets`è¿›è¡Œå®‰è£…ã€‚

+   **pandas**ï¼š`pandas`æ˜¯ Python ä¸­ä¸€ä¸ªå¼ºå¤§çš„æ•°æ®åˆ†æåº“ï¼Œç”¨äºæ“ä½œè¡¨æ ¼æ•°æ®ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå®ƒé€šè¿‡å°†å…¶è½¬æ¢ä¸º DataFrame æ¥å¸®åŠ©é¢„å¤„ç†æ•°æ®é›†ï¼Œä»¥ä¾¿æ›´å®¹æ˜“åœ°è¿›è¡Œæ“ä½œã€‚ä½¿ç”¨`pip install pandas`è¿›è¡Œå®‰è£…ã€‚

+   **faiss-CPU**ï¼š`faiss-cpu`æ˜¯ä¸€ä¸ªç”¨äºé«˜æ•ˆæœç´¢å’Œèšç±»å¯†é›†å‘é‡çš„åº“ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå®ƒç”¨äºæ„å»ºåœ¨æ¨ç†æœŸé—´æ£€ç´¢ç›¸å…³æ®µè½çš„æ£€ç´¢å™¨ã€‚è®¿é—® Faiss çš„ GitHub ä»“åº“ï¼ˆ[`github.com/facebookresearch/faiss`](https://github.com/facebookresearch/faiss)ï¼‰ä»¥è·å–æ–‡æ¡£å’Œç¤ºä¾‹ã€‚ä½¿ç”¨`pip`è¿›è¡Œå®‰è£…ï¼š`pip install faiss-cpu`ã€‚

+   **åŠ é€Ÿ**ï¼šåŠ é€Ÿæ˜¯ Hugging Face çš„ä¸€ä¸ªåº“ï¼Œå®ƒç®€åŒ–äº†åˆ†å¸ƒå¼è®­ç»ƒå’Œæ¨ç†ã€‚å®ƒç¡®ä¿äº†åœ¨ CPUã€GPU å’Œå¤šèŠ‚ç‚¹è®¾ç½®ä¸­ç¡¬ä»¶åˆ©ç”¨çš„æœ€ä¼˜åŒ–ã€‚ä½¿ç”¨`pip install accelerate`è¿›è¡Œå®‰è£…ã€‚

é€šè¿‡ç¡®ä¿æ‚¨çš„ç¯å¢ƒé…ç½®äº†è¿™äº›å·¥å…·ï¼Œæ‚¨å¯ä»¥æ— ç¼æ¢ç´¢æœ¬ç« æä¾›çš„åŠ¨æ‰‹ç»ƒä¹ ã€‚

**æ³¨æ„**

æœ¬ç« çš„æ‰€æœ‰éƒ¨åˆ†éƒ½ä¸“æ³¨äºç›¸å…³çš„ä»£ç ç‰‡æ®µã€‚

å®Œæ•´ä»£ç ï¼Œè¯·å‚é˜…æœ¬ä¹¦çš„ GitHub ä»“åº“ï¼š[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch2`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch2)ã€‚

# ç†è§£ RAG çš„åŠ›é‡

RAG æ˜¯ç”± Meta ç ”ç©¶äººå‘˜åœ¨ 2020 å¹´å¼•å…¥çš„ï¼ˆ[`arxiv.org/abs/2005.11401v4`](https://arxiv.org/abs/2005.11401v4)ï¼‰ï¼Œä½œä¸ºä¸€ä¸ªæ¡†æ¶ï¼Œå…è®¸ GenAI æ¨¡å‹åˆ©ç”¨æ¨¡å‹è®­ç»ƒä¹‹å¤–çš„å¤–éƒ¨æ•°æ®æ¥å¢å¼ºè¾“å‡ºã€‚

ä¼—æ‰€å‘¨çŸ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹æ˜“äº§ç”Ÿå¹»è§‰ã€‚ä¸€ä¸ªç»å…¸çš„ LLMs äº§ç”Ÿå¹»è§‰çš„çœŸå®ä¸–ç•Œä¾‹å­æ˜¯ Levidow, Levidow & Oberman å¾‹å¸ˆäº‹åŠ¡æ‰€ï¼Œè¯¥å¾‹æ‰€åœ¨ä¸å“¥ä¼¦æ¯”äºšèˆªç©ºå…¬å¸ Avianca çš„æ¡ˆä»¶ä¸­æäº¤äº†ä¸€ä»½åŒ…å«ç”± OpenAI çš„ ChatGPT ç”Ÿæˆçš„è™šå‡å¼•ç”¨çš„æ³•å¾‹ç®€æŠ¥ï¼Œå› æ­¤è¢«ç½šæ¬¾ã€‚ä»–ä»¬éšåè¢«ç½šæ¬¾æ•°åƒç¾å…ƒï¼Œå¹¶ä¸”å¯èƒ½å› å£°èª‰å—æŸè€ŒæŸå¤±æ›´å¤šã€‚æ›´å¤šå…³äºæ­¤äº‹çš„ä¿¡æ¯ï¼Œè¯·å‚é˜…æ­¤å¤„ï¼š[`news.sky.com/story/lawyers-fined-after-citing-bogus-cases-from-chatgpt-research-12908318`](https://news.sky.com/story/lawyers-fined-after-citing-bogus-cases-from-chatgpt-research-12908318)ã€‚

LLM çš„å¹»è§‰å¯èƒ½ç”±ä»¥ä¸‹å‡ ä¸ªå› ç´ å¼•èµ·ï¼š

+   **è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒLLM å¯èƒ½ä¼šè¿‡åº¦æ‹Ÿåˆåˆ°è®­ç»ƒæ•°æ®ä¸­çš„ç»Ÿè®¡æ¨¡å¼ã€‚è¿™å¯èƒ½å¯¼è‡´æ¨¡å‹ä¼˜å…ˆå¤åˆ¶è¿™äº›æ¨¡å¼ï¼Œè€Œä¸æ˜¯ç”Ÿæˆäº‹å®å‡†ç¡®çš„å†…å®¹ã€‚

+   **ç¼ºä¹å› æœæ¨ç†èƒ½åŠ›**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«è¯è¯­ä¹‹é—´çš„ç»Ÿè®¡å…³ç³»æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å¯èƒ½éš¾ä»¥ç†è§£å› æœå…³ç³»ã€‚è¿™å¯èƒ½å¯¼è‡´è¾“å‡ºåœ¨è¯­æ³•ä¸Šæ­£ç¡®ä½†åœ¨äº‹å®ä¸Šä¸å¯ä¿¡ã€‚

+   **æ¸©åº¦é…ç½®**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥é€šè¿‡ä¸€ä¸ªåä¸º**æ¸©åº¦**çš„å‚æ•°è¿›è¡Œé…ç½®ï¼Œè¿™æ˜¯ä¸€ä¸ªä»‹äº`0`å’Œ`1`ä¹‹é—´çš„æ•°å­—ï¼Œå®ƒæ§åˆ¶æ–‡æœ¬ç”Ÿæˆçš„éšæœºæ€§ã€‚è¾ƒé«˜çš„æ¸©åº¦å¢åŠ äº†åˆ›é€ åŠ›ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹åç¦»é¢„æœŸå“åº”å¹¶äº§ç”Ÿå¹»è§‰çš„å¯èƒ½æ€§ã€‚

+   **ç¼ºå¤±ä¿¡æ¯**ï¼šå¦‚æœç”Ÿæˆå‡†ç¡®å“åº”æ‰€éœ€çš„ä¿¡æ¯æœªåŒ…å«åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼Œæ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆå¬èµ·æ¥åˆç†ä½†å®é™…ä¸Šé”™è¯¯çš„ç­”æ¡ˆã€‚

+   **æœ‰ç¼ºé™·æˆ–å­˜åœ¨åå·®çš„è®­ç»ƒæ•°æ®**ï¼šè®­ç»ƒè¿‡ç¨‹çš„è´¨é‡èµ·ç€é‡è¦ä½œç”¨ã€‚å¦‚æœæ•°æ®é›†åŒ…å«åå·®æˆ–ä¸å‡†ç¡®æ€§ï¼Œæ¨¡å‹å¯èƒ½ä¼šæŒç»­è¿™äº›é—®é¢˜ï¼Œå¯¼è‡´å¹»è§‰ã€‚

è™½ç„¶å¹»è§‰æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œä½†å‡ ç§æ–¹æ³•å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¸®åŠ©å‡è½»å®ƒä»¬ï¼š

+   **æç¤ºå·¥ç¨‹**ï¼šè¿™æ¶‰åŠç²¾å¿ƒè®¾è®¡å’Œè¿­ä»£ä¼˜åŒ–æä¾›ç»™å¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤æˆ–æŸ¥è¯¢ï¼Œä»¥äº§ç”Ÿä¸€è‡´å’Œå‡†ç¡®çš„å“åº”ã€‚ä¾‹å¦‚ï¼Œå‘ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹æé—®

    ```py
     List five key benefits of Neo4j for knowledge graphs 
    ```

ç›¸æ¯”äºåƒâ€œ**æç¤ºå·¥ç¨‹**â€è¿™æ ·çš„å®½æ³›æŸ¥è¯¢ï¼Œå®ƒæä¾›äº†æ›´å¤šçš„ç»“æ„å’Œç²¾ç¡®æ€§ï¼š

```py
Tell me about Neo4j 
```

å‰è€…æŸ¥è¯¢æŒ‡å®šäº†é¢„æœŸçš„è¾“å‡ºï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨ä¸€ä¸ªç®€æ´ä¸”ç›¸å…³çš„åˆ©ç›Šåˆ—è¡¨ï¼Œè€Œåè€…å¯èƒ½äº§ç”Ÿå†—é•¿æˆ–ç¦»é¢˜çš„å›ç­”ã€‚æç¤ºå·¥ç¨‹æœ‰åŠ©äºå¼•å¯¼æ¨¡å‹ä¿æŒåœ¨æ‰€éœ€çš„ä¿¡æ¯èŒƒå›´å†…ï¼Œå¹¶å‡å°‘å…¶äº§ç”Ÿä¸ç›¸å…³æˆ–è™šæ„è¾“å‡ºçš„å¯èƒ½æ€§ã€‚æœ‰å…³æç¤ºå·¥ç¨‹æŠ€æœ¯å’Œæœ€ä½³å®è·µçš„è¯¦ç»†æ¢è®¨ï¼Œè¯·å‚é˜…æ­¤æŒ‡å—ï¼š[`cloud.google.com/discover/what-is-prompt-engineering`](https://cloud.google.com/discover/what-is-prompt-engineering)ã€‚

+   **æƒ…å¢ƒå­¦ä¹ **ï¼ˆ**å°‘æ ·æœ¬æç¤º**ï¼‰ï¼šåœ¨æ­¤æ–¹æ³•ä¸­ï¼Œç¤ºä¾‹åŒ…å«åœ¨æç¤ºä¸­ï¼Œä»¥å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹å‘å‡†ç¡®ã€ç‰¹å®šä»»åŠ¡çš„å“åº”ã€‚ä¾‹å¦‚ï¼Œå½“è¦æ±‚äº§å“æ¯”è¾ƒæ—¶ï¼Œåœ¨æç¤ºä¸­æä¾›å‡ ä¸ªç»“æ„è‰¯å¥½çš„æ¯”è¾ƒç¤ºä¾‹æœ‰åŠ©äºæ¨¡å‹æ¨¡ä»¿è¯¥æ¨¡å¼ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†æ¨¡å‹æ¨æ–­æƒ…å¢ƒå¹¶æ ¹æ®ç»™å®šç¤ºä¾‹è°ƒæ•´å…¶å“åº”çš„èƒ½åŠ›ï¼Œä½¿å…¶åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­éå¸¸æœ‰æ•ˆã€‚

+   **å¾®è°ƒ**ï¼šè¿™æ¶‰åŠåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒå·²ç»é¢„è®­ç»ƒçš„ LLMï¼Œä»¥é€‚åº”ç‰¹å®šé¢†åŸŸæˆ–ä»»åŠ¡ã€‚è¿™ä¸ªè¿‡ç¨‹å¢å¼ºäº†æ¨¡å‹ç”Ÿæˆç‰¹å®šé¢†åŸŸã€ç›¸å…³å’Œå‡†ç¡®å“åº”çš„èƒ½åŠ›ã€‚å¾®è°ƒçš„ä¸€ç§æµè¡Œæ–¹æ³•æ˜¯**å¼ºåŒ–å­¦ä¹ ä¸äººåé¦ˆï¼ˆRLHF**ï¼‰ï¼Œå…¶ä¸­äººç±»è¯„ä¼°è€…é€šè¿‡è¯„åˆ†æ¨¡å‹çš„è¾“å‡ºæ¥å¼•å¯¼æ¨¡å‹ã€‚è¿™äº›è¯„åˆ†ç”¨äºè°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä½¿å…¶ä¸äººç±»æœŸæœ›ä¿æŒä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œåœ¨å…¬å¸çš„å†…éƒ¨æ–‡æ¡£ä¸Šå¾®è°ƒ LLM å¯ä»¥ç¡®ä¿å®ƒäº§ç”Ÿå‡†ç¡®ä¸”ç›¸å…³çš„è¾“å‡ºï¼Œä»¥æ»¡è¶³ç»„ç»‡çš„ç‰¹å®šéœ€æ±‚ã€‚å¦‚æœæç¤ºï¼š

    ```py
    Explain the onboarding process for new hires 
    ```

ä¸€ä¸ªå¾®è°ƒåçš„æ¨¡å‹å¯èƒ½ä¼šæä¾›ä¸€ä¸ªä¸å…¬å¸æ”¿ç­–ä¸€è‡´è¯¦ç»†è§£é‡Šï¼Œè€Œä¸€ä¸ªé€šç”¨æ¨¡å‹å¯èƒ½ä¼šæä¾›æ¨¡ç³Šæˆ–ä¸ç›¸å…³çš„å“åº”ã€‚è®©æˆ‘ä»¬å†ä¸¾ä¸€ä¸ªä¾‹å­åœºæ™¯ï¼Œä»¥äº†è§£å¦‚ä½•ä½¿ç”¨ RLHF æ¥æ”¹è¿›å“åº”ã€‚

å‡è®¾æœ€åˆ LLM è¢«è¯¢é—®ï¼š

```py
What are the benefits of using XYZ software? 
```

å“åº”å¯èƒ½åŒ…æ‹¬ä¸è½¯ä»¶ç‹¬ç‰¹åŠŸèƒ½ä¸åŒ¹é…çš„é€šç”¨å¥½å¤„ã€‚ä½¿ç”¨ RLHFï¼Œäººç±»è¯„ä¼°è€…æ ¹æ®å‡†ç¡®æ€§ã€ç›¸å…³æ€§å’Œå®Œæ•´æ€§è¯„åˆ†å“åº”ã€‚ä¾‹å¦‚ï¼Œåˆå§‹å“åº”å¯èƒ½æ˜¯ï¼š

```py
XYZ software improves productivity, enhances collaboration, and reduces costs. 
```

åé¦ˆå¯èƒ½åŒ…æ‹¬ï¼š

```py
Too generic; lacks specifics about XYZ software. 
```

åœ¨ç»è¿‡äººç±»åé¦ˆçš„å¾®è°ƒåï¼Œç»“æœå¯èƒ½æ˜¯ä¸€ä¸ªæ›´å‡†ç¡®å’Œå®šåˆ¶çš„å“åº”ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
XYZ software offers real-time data synchronization, customizable workflows, and advanced security features, making it ideal for enterprise resource planning. 
```

RLHF åœ¨å‡å°‘å¹»è§‰æ–¹é¢ç‰¹åˆ«æœ‰ä»·å€¼ï¼Œå› ä¸ºå®ƒå¼ºè°ƒä»äººç±»ç¼–è¾‘çš„åé¦ˆä¸­å­¦ä¹ ã€‚

å°½ç®¡è¿™äº›æ–¹æ³•æä¾›äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œä½†å®ƒä»¬åœ¨å…³é”®é¢†åŸŸä»æœ‰æ‰€ä¸è¶³ï¼šä½¿ç»„ç»‡èƒ½å¤Ÿåˆ©ç”¨ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†å¿«é€Ÿæ„å»ºå‡†ç¡®ã€ä¸Šä¸‹æ–‡ç›¸å…³ä¸”å¯è§£é‡Šçš„é€šç”¨äººå·¥æ™ºèƒ½åº”ç”¨ã€‚è§£å†³æ–¹æ¡ˆåœ¨äº**æ‰æ ¹**â€”â€”ä¸€ä¸ªå°†æ¨¡å‹çš„å“åº”ä¸çœŸå®ä¸–ç•Œçš„äº‹å®æˆ–æ•°æ®è”ç³»èµ·æ¥çš„æ¦‚å¿µã€‚è¿™ç§æ–¹æ³•æ„æˆäº†æ–‡æœ¬ç”Ÿæˆæ–°èŒƒå¼çš„åŸºç¡€ï¼Œç§°ä¸º RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ã€‚é€šè¿‡ä»å¯é çš„çŸ¥è¯†æºåŠ¨æ€æ£€ç´¢äº‹å®ä¿¡æ¯ï¼ŒRAG ç¡®ä¿è¾“å‡ºæ—¢å‡†ç¡®åˆä¸ä¸Šä¸‹æ–‡ä¸€è‡´ã€‚RAG é€šè¿‡ç»“åˆæ¥è‡ªäº‹å®çŸ¥è¯†åº“çš„ç›¸å…³ä¿¡æ¯æ¥å°è¯•è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹»è§‰é—®é¢˜ã€‚

æœ¯è¯­æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼‰ï¼Œç®€ç§° RAGï¼Œé¦–æ¬¡ç”±**Facebook AI Researchï¼ˆFAIR**ï¼‰çš„ç ”ç©¶äººå‘˜åœ¨ 2020 å¹´ 5 æœˆæäº¤çš„ä¸€ç¯‡é¢˜ä¸ºã€ŠRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasksã€‹çš„è®ºæ–‡ä¸­æå‡ºï¼š[`arxiv.org/abs/2005.11401`](https://arxiv.org/abs/2005.11401)ã€‚

è®ºæ–‡æå‡ºäº† RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ä½œä¸ºä¸€ç§æ··åˆæ¶æ„ï¼ˆå‚è§å›¾ 2.1ï¼‰ï¼Œå®ƒç»“åˆäº†ä¸€ä¸ªç¥ç»æ£€ç´¢å™¨å’Œä¸€ä¸ªåºåˆ—åˆ°åºåˆ—ç”Ÿæˆå™¨ã€‚**æ£€ç´¢å™¨**ä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œç„¶åè¿™äº›æ–‡æ¡£è¢«ç”¨ä½œç”Ÿæˆå™¨çš„ä¸Šä¸‹æ–‡ï¼Œä»¥äº§ç”ŸåŸºäºäº‹å®æ•°æ®çš„è¾“å‡ºã€‚è¿™ç§æ–¹æ³•å·²è¢«è¯æ˜å¯ä»¥æ˜¾è‘—æé«˜çŸ¥è¯†å¯†é›†å‹ NLP ä»»åŠ¡ï¼ˆå¦‚å¼€æ”¾åŸŸé—®ç­”å’Œå¯¹è¯ç³»ç»Ÿï¼‰çš„æ€§èƒ½ï¼Œé€šè¿‡å‡å°‘å¯¹æ¨¡å‹å†…éƒ¨çŸ¥è¯†çš„ä¾èµ–å¹¶æé«˜äº‹å®å‡†ç¡®æ€§ã€‚RAG é€šè¿‡å¼•å…¥ä¸€ä¸ªå…³é”®å…ƒç´ æ¥è§£å†³ä¹‹å‰æåˆ°çš„ LLM çš„ä¸è¶³ï¼šä»è¡¥å……æˆ–ç‰¹å®šé¢†åŸŸçš„æ•°æ®æºä¸­æ£€ç´¢ç›¸å…³çŸ¥è¯†çš„èƒ½åŠ›ã€‚

![å›¾ 2.1 â€” FAIR åœ¨â€œæ£€ç´¢å¢å¼ºç”Ÿæˆç”¨äºçŸ¥è¯†å¯†é›†å‹ NLP ä»»åŠ¡â€ç ”ç©¶è®ºæ–‡ä¸­æå‡ºçš„ RAG æ¶æ„](img/B31107_02_1.png)

å›¾ 2.1 â€” FAIR åœ¨â€œæ£€ç´¢å¢å¼ºç”Ÿæˆç”¨äºçŸ¥è¯†å¯†é›†å‹ NLP ä»»åŠ¡â€ç ”ç©¶è®ºæ–‡ä¸­æå‡ºçš„ RAG æ¶æ„

æ­¤å¤–ï¼ŒRAG ç®¡é“æä¾›äº†åœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶å‡å°‘æ¨¡å‹å¤§å°çš„æ½œåŠ›ã€‚è€Œä¸æ˜¯å°†æ‰€æœ‰çŸ¥è¯†åµŒå…¥åˆ°æ¨¡å‹çš„å‚æ•°ä¸­â€”â€”è¿™å°†éœ€è¦å¤§é‡èµ„æºâ€”â€”RAG å…è®¸æ¨¡å‹åŠ¨æ€æ£€ç´¢ä¿¡æ¯ï¼Œä¿æŒå…¶è½»é‡çº§å’Œå¯æ‰©å±•æ€§ã€‚

æœ¬ç« ä¸‹ä¸€èŠ‚å°†æ·±å…¥æ¢è®¨ RAG çš„å†…éƒ¨å·¥ä½œåŸç†ï¼Œæ¢è®¨å®ƒæ˜¯å¦‚ä½•å¼¥åˆåŸå§‹ç”Ÿæˆå’ŒåŸºäºçŸ¥è¯†æ–‡æœ¬ç”Ÿäº§ä¹‹é—´çš„å·®è·ã€‚

# è§£æ„ RAG æµç¨‹

è®©æˆ‘ä»¬ç°åœ¨è§£æ„ RAG æ¨¡å‹çš„æ„å»ºå—ï¼Œå¹¶å¸®åŠ©æ‚¨äº†è§£å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹å¸¸è§„ LLM åº”ç”¨æµç¨‹ã€‚*å›¾ 2.2*å±•ç¤ºäº†è¿™ä¸ªåŸºæœ¬æµç¨‹ã€‚

![å›¾ 2.2 â€” å¸¦æœ‰ LLM çš„èŠå¤©åº”ç”¨ä¸­çš„ä¿¡æ¯åŸºæœ¬æµç¨‹](img/B31107_02_2.png)

å›¾ 2.2 â€” å¸¦æœ‰ LLM çš„èŠå¤©åº”ç”¨ä¸­çš„ä¿¡æ¯åŸºæœ¬æµç¨‹

å½“ç”¨æˆ·å‘ LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰æå‡ºè¯·æ±‚æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆæƒ…å†µã€‚

1.  **ç”¨æˆ·å‘é€æç¤º**ï¼šè¿™ä¸ªè¿‡ç¨‹ä»ç”¨æˆ·å‘ LLM èŠå¤© API å‘é€æç¤ºå¼€å§‹ã€‚è¿™ä¸ªæç¤ºå¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜ã€ä¸€ä¸ªæŒ‡ä»¤æˆ–ä»»ä½•å…¶ä»–è¯·æ±‚ä¿¡æ¯æˆ–å†…å®¹ç”Ÿæˆçš„è¯·æ±‚ã€‚

1.  **LLM API å¤„ç†æç¤º**ï¼šLLM èŠå¤© API æ¥æ”¶ç”¨æˆ·çš„æç¤ºå¹¶å°†å…¶ä¼ è¾“ç»™ LLMã€‚LLM æ˜¯ç»è¿‡å¤§é‡æ–‡æœ¬æ•°æ®è®­ç»ƒçš„ AI æ¨¡å‹ï¼Œå…è®¸å®ƒä»¬å¯¹å¹¿æ³›çš„æç¤ºå’Œé—®é¢˜è¿›è¡Œæ²Ÿé€šå¹¶ç”Ÿæˆç±»ä¼¼äººç±»çš„æ–‡æœ¬ã€‚

1.  **LLM ç”Ÿæˆå“åº”**ï¼šç„¶å LLM å¤„ç†æç¤ºå¹¶åˆ¶å®šä¸€ä¸ªå“åº”ã€‚è¿™ä¸ªå“åº”è¢«å‘é€å› LLM èŠå¤© APIï¼Œç„¶åå°†å…¶ä¼ è¾“ç»™ç”¨æˆ·ã€‚

ä»è¿™ä¸ªæµç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° LLM è´Ÿè´£æä¾›ç­”æ¡ˆï¼Œä¸­é—´æ²¡æœ‰å…¶ä»–è¿‡ç¨‹ã€‚è¿™æ˜¯æ²¡æœ‰ RAG çš„è¯·æ±‚-å“åº”æµç¨‹ä¸­æœ€å¸¸è§çš„ç”¨æ³•ã€‚

ç°åœ¨æˆ‘ä»¬æ¥çœ‹çœ‹ RAG åœ¨è¿™ä¸ªå·¥ä½œæµç¨‹ä¸­æ˜¯å¦‚ä½•å®šä½çš„ã€‚

![å›¾ 2.3 â€” å¸¦æœ‰ RAG æ¨¡å‹çš„èŠå¤©åº”ç”¨ä¸­çš„ä¿¡æ¯æµç¨‹](img/B31107_02_3.png)

å›¾ 2.3 â€” å¸¦æœ‰ RAG æ¨¡å‹çš„èŠå¤©åº”ç”¨ä¸­çš„ä¿¡æ¯æµ

æˆ‘ä»¬å¯ä»¥ä»*å›¾ 2.3*ä¸­çœ‹åˆ°ï¼Œåœ¨è°ƒç”¨å®é™…çš„ LLM æœåŠ¡ä¹‹å‰ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªä¸­é—´æ•°æ®æºï¼Œå®ƒå¯ä»¥æä¾› LLM è¯·æ±‚çš„ä¸Šä¸‹æ–‡ï¼š

1.  **ç”¨æˆ·å‘é€æç¤º**ï¼šè¯¥è¿‡ç¨‹ä»ç”¨æˆ·é€šè¿‡èŠå¤©ç•Œé¢å‘é€æç¤ºæˆ–é—®é¢˜å¼€å§‹ã€‚è¿™ä¸ªæç¤ºå¯èƒ½æ˜¯ç”¨æˆ·æƒ³è¦äº†è§£çš„ä»»ä½•ä¿¡æ¯æˆ–éœ€è¦å¸®åŠ©çš„å†…å®¹ã€‚

1.  **RAG æ¨¡å‹å¤„ç†æç¤º**ï¼šæç¤ºè¢«èŠå¤© API æ¥æ”¶ï¼Œç„¶åå°†å…¶è½¬å‘ç»™ RAG æ¨¡å‹ã€‚RAG æ¨¡å‹æœ‰ä¸¤ä¸ªä¸»è¦ç»„ä»¶ååŒå·¥ä½œï¼š*æ£€ç´¢å™¨*ï¼ˆåœ¨ç¬¬*3*æ­¥ä¸­è®¨è®ºï¼‰å’Œ*ç¼–ç å™¨-è§£ç å™¨*ï¼ˆåœ¨ç¬¬*4*æ­¥ä¸­è®¨è®ºï¼‰ã€‚

1.  **æ£€ç´¢å™¨**ï¼šè¯¥ç»„ä»¶åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ï¼Œå¯èƒ½åŒ…æ‹¬éç»“æ„åŒ–æ–‡æ¡£ã€æ®µè½æˆ–å¦‚è¡¨æ ¼æˆ–çŸ¥è¯†å›¾è°±ä¹‹ç±»çš„ç»“æ„åŒ–æ•°æ®ã€‚å…¶ä½œç”¨æ˜¯å®šä½å¤„ç†ç”¨æˆ·æç¤ºæ‰€éœ€çš„æœ€ç›¸å…³ä¿¡æ¯ã€‚

æˆ‘ä»¬å°†æ¶µç›–æ£€ç´¢å™¨ç»„ä»¶çš„ä¸€ä¸ªç®€å•ç¤ºä¾‹ã€‚ä½ å¯ä»¥åœ¨[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/dpr.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/dpr.py)æŸ¥çœ‹å®Œæ•´çš„ä»£ç ã€‚

```py
context encoder model and *tokenizer* from Hugging Faceâ€™s Transformers library:
```

1.  è®©æˆ‘ä»¬å®šä¹‰ä¸€ç»„æˆ‘ä»¬æƒ³è¦å­˜å‚¨åœ¨æ–‡æ¡£å­˜å‚¨ä¸­çš„æ–‡æ¡£ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€äº›é¢„å®šä¹‰çš„å¥å­æ¥æ¼”ç¤ºï¼š

    ```py
    documents = [
    Â Â Â Â "The IPL 2024 was a thrilling season with unexpected results.",
    .....
    Â Â Â Â "Dense Passage Retrieval (') is a state-of-the-art technique for information retrieval."
    ] 
    ```

1.  æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä¹‹å‰å®šä¹‰çš„å†…å®¹å­˜å‚¨åœ¨å†…å®¹å­˜å‚¨ä¸­ã€‚ç„¶åæˆ‘ä»¬å°†ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆä¸€ä¸ªåµŒå…¥å¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨å†…å®¹å­˜å‚¨ä¸­ï¼š

    ```py
    def encode_documents(documents):
    Â Â Â Â inputs = tokenizer(
    Â Â Â Â Â Â Â Â documents, return_tensors='pt', 
    Â Â Â Â Â Â Â Â padding=True, truncation=True)
    Â Â Â Â with torch.no_grad():
    Â Â Â Â Â Â Â Â outputs = model(**inputs)
    Â Â Â Â return outputs.pooler_output.numpy()

    document_embeddings = encode_documents(documents) 
    ```

1.  ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€ç§æ–¹æ³•ï¼Œæ ¹æ®æŸ¥è¯¢è¾“å…¥ä»æ–‡æ¡£å­˜å‚¨ä¸­æ£€ç´¢å†…å®¹ã€‚æˆ‘ä»¬å°†ç”Ÿæˆè¯·æ±‚çš„åµŒå…¥å¹¶æŸ¥è¯¢å†…å®¹å­˜å‚¨ä»¥æ£€ç´¢ç›¸å…³ç»“æœã€‚æˆ‘ä»¬åœ¨è¿™é‡Œåˆ©ç”¨å‘é‡æœç´¢æ¥è·å–ç›¸å…³ç»“æœï¼š

    ```py
    def retrieve_documents(query, num_results=3):
    Â Â Â Â inputs = tokenizer(query, return_tensors='pt', 
    Â Â Â Â Â Â Â Â padding=True, truncation=True)
    Â Â Â Â with torch.no_grad():
    Â Â Â Â Â Â Â Â query_embedding = model(**inputs).pooler_output
    Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â .numpy()
    Â Â Â Â similarity_scores = cosine_similarity(
    Â Â Â Â Â Â Â Â query_embedding, document_embeddings).flatten()
    Â Â Â Â top_indices = similarity_scores.argsort()[-num_results:]
    Â Â Â Â Â Â Â Â [::-1]
    Â Â Â Â top_docs = [
    Â Â Â Â Â Â Â Â (documents[i], similarity_scores[i]) 
    Â Â Â Â Â Â Â Â for i in top_indices]
    Â Â Â Â return top_doc 
    ```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¯¹äºç»™å®šçš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬ä¼šæ”¶åˆ°ä»€ä¹ˆæ ·çš„è¾“å‡ºä½œä¸ºç¤ºä¾‹ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å…¥ï¼š

```py
Query: What is Dense Passage Retrieval? 
```

ä¸‹é¢æ˜¯ç¤ºä¾‹è¾“å‡ºï¼š

```py
Top Results:
Score: 0.7777, Document: Dense Passage Retrieval (') is a state-of-the-art technique for information retrieval.
... 
```

**æ³¨æ„**

æ£€ç´¢å™¨å®ç°å¯èƒ½ç›¸å½“å¤æ‚ã€‚å®ƒä»¬å¯èƒ½æ¶‰åŠ

ä½¿ç”¨é«˜æ•ˆçš„æœç´¢ç®—æ³•ï¼Œå¦‚ BM25ã€TF-IDF æˆ–ç¥ç»æ£€ç´¢å™¨

ä¾‹å¦‚**å¯†é›†æ®µè½æ£€ç´¢**ã€‚ä½ å¯ä»¥åœ¨[`github.com/facebookresearch/`](https://github.com/facebookresearch/)äº†è§£æ›´å¤šä¿¡æ¯ã€‚

1.  **ç¼–ç å™¨-è§£ç å™¨/å¢å¼ºç”Ÿæˆ**ï¼šè¯¥ç»„ä»¶çš„ç¼–ç å™¨éƒ¨åˆ†å¤„ç†æç¤ºä»¥åŠæ£€ç´¢åˆ°çš„ä¿¡æ¯â€”â€”æ— è®ºæ˜¯ç»“æ„åŒ–è¿˜æ˜¯éç»“æ„åŒ–â€”â€”ä»¥åˆ›å»ºä¸€ä¸ªå…¨é¢çš„è¡¨ç¤ºã€‚ç„¶åè§£ç å™¨ä½¿ç”¨è¿™ä¸ªè¡¨ç¤ºæ¥ç”Ÿæˆä¸€ä¸ªå‡†ç¡®ã€è¯­å¢ƒä¸°å¯Œä¸”é’ˆå¯¹ç”¨æˆ·æç¤ºçš„å“åº”ã€‚

è¿™æ¶‰åŠåˆ°ä½¿ç”¨è¾“å…¥æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡ä¿¡æ¯è°ƒç”¨ LLM APIã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯è°ƒç”¨æŸ¥è¯¢ã€‚è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº† T5Tokenizer æ¨¡å‹çš„ä½¿ç”¨ï¼š

1.  è®©æˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸ª LLMã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Hugging Face çš„ T5 æ¨¡å‹ï¼š

    ```py
    tokenizer = T5Tokenizer.from_pretrained('t5-small', 
    Â Â Â Â legacy=False)
    model = T5ForConditionalGeneration.from_pretrained(
    Â Â Â Â 't5-small') 
    ```

1.  å®šä¹‰ RAG æµç¨‹çš„æŸ¥è¯¢å’Œæ–‡æ¡£ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬åˆ©ç”¨æ£€ç´¢å™¨è¿›è¡Œ RAG æµç¨‹ã€‚åœ¨è¿™é‡Œï¼Œä¸ºäº†æ¼”ç¤ºç›®çš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¡¬ç¼–ç çš„å€¼ï¼š

    ```py
    query = "What are the benefits of solar energy?"
    retrieved_passages = """
    Solar energy is a renewable resource and reduces electricity bills.
    ......
    """ 
    ```

1.  æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œå®ƒæ¥å—è¾“å…¥æŸ¥è¯¢å’Œæ£€ç´¢åˆ°çš„æ®µè½ï¼Œä»¥ä½¿ç”¨ LLM API æ¥æ¼”ç¤º RAG æ–¹æ³•ï¼š

    ```py
    def generate_response(query, retrieved_passages):
    Â Â Â Â Â Â Â Â input_text = f"Answer this question based on the provided context: {query} Context: {retrieved_passages}" 
    Â Â Â Â inputs = tokenizer(input_text, return_tensors='pt', 
    Â Â Â Â Â Â Â Â padding=True, 
    Â Â Â Â Â Â Â Â truncation=True, max_length=512
    Â Â Â Â ).to(device)
    Â Â Â Â with torch.no_grad():
    Â Â Â Â Â Â Â Â outputs = model.generate(
    Â Â Â Â Â Â Â Â Â Â Â Â **inputs,
    Â Â Â Â Â Â Â Â Â Â Â Â max_length=300,Â Â # Allow longer responses
    Â Â Â Â Â Â Â Â Â Â Â Â num_beams=3,Â Â Â Â Â # Use beam search for better results
    Â Â Â Â Â Â Â Â Â Â Â Â early_stopping=True
    Â Â Â Â Â Â Â Â )
    Â Â Â Â return tokenizer.decode(outputs[0], 
    Â Â Â Â Â Â Â Â skip_special_tokens=True) 
    ```

**æ³¨æ„**

æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨**T5 æ¨¡å‹**çš„æŸæœç´¢è§£ç æ¥ç”Ÿæˆ

å‡†ç¡®ä¸”ä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„å“åº”ã€‚**æŸæœç´¢è§£ç **æ˜¯ä¸€ç§åœ¨æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­å¯»æ‰¾æœ€å¯èƒ½åºåˆ—ï¼ˆå•è¯ï¼‰çš„æœç´¢ç®—æ³•ã€‚ä¸è´ªå©ªè§£ç ä¸åŒï¼Œè´ªå©ªè§£ç é€‰æ‹©æœ€

åœ¨æ¯ä¸ªæ­¥éª¤ä¸­ï¼ŒæŸæœç´¢ç»´æŠ¤å¤šä¸ªæ½œåœ¨çš„

åºåˆ—ï¼ˆç§°ä¸º**æŸ**ï¼‰å¹¶åŒæ—¶æ¢ç´¢å®ƒä»¬ã€‚æ­¤

å¢åŠ äº†æ‰¾åˆ°é«˜è´¨é‡ç»“æœçš„æœºä¼šï¼Œå› ä¸ºå®ƒé¿å…äº†åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è¿‡æ—©åœ°åšå‡ºæ¬¡ä¼˜é€‰æ‹©ã€‚ä½ å¯ä»¥åœ¨æœ¬æ–‡ä¸­äº†è§£æ›´å¤šå…³äº Transformers ä¸­æŸæœç´¢çš„ä¿¡æ¯ï¼š[`huggingface.co/blog/constrained-beam-search`](https://huggingface.co/blog/constrained-beam-search)ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬è°ƒç”¨æ­¤æ–¹æ³•å¹¶å®¡æŸ¥å“åº”ã€‚

1.  **èŠå¤© API æä¾›å“åº”**ï¼šä»¥ä¸‹ä»£ç å°†è°ƒç”¨`generate_response`æ–¹æ³•ï¼Œå¹¶ä¸ºè¾“å…¥æŸ¥è¯¢æä¾›èŠå¤©å“åº”ï¼š

    ```py
    response = generate_response(query, retrieved_passages) 
    print("Query:", query) 
    print("Retrieved Passages:", retrieved_passages) 
    print("Generated Response:", response) 
    ```

å½“æˆ‘ä»¬è¿è¡Œè¿™ä¸ªç¤ºä¾‹æ—¶ï¼Œç»“æœå¦‚ä¸‹ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å…¥ï¼š

```py
Query: What are the benefits of solar energy? 
```

æ£€ç´¢åˆ°çš„æ®µè½å¦‚ä¸‹ï¼š

```py
Solar energy is a renewable resource and reduces electricity bills.
...... 
```

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å‡ºï¼š

```py
Generated Response: it is environmentally friendly and helps combat climate change 
```

ä½ å¯ä»¥åœ¨[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/augmented_generation.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/augmented_generation.py)æ‰¾åˆ°è¿™ä¸ªç¤ºä¾‹çš„å®Œæ•´ä»£ç ã€‚

1.  **é›†æˆå’Œå¾®è°ƒ**ï¼šç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªä»£ç ç‰‡æ®µï¼Œå®ƒå°†æ£€ç´¢å™¨å’Œ LLM è°ƒç”¨ç»“åˆèµ·æ¥ï¼Œä½œä¸ºå®Œæ•´çš„ RAG æµç¨‹ã€‚ä»¥ä¸‹ä»£ç å±•ç¤ºäº†è¿™ä¸€ç‚¹ï¼š

    ```py
    def rag_pipeline(query):
    Â Â Â Â retrieved_docs = retrieve_documents(query)
    Â Â Â Â response = generate_response(query, retrieved_docs)
    Â Â Â Â return response

    query = "How does climate change affect biodiversity?"
    generated_text = rag_pipeline(query)
    print("Final Generated Text:", generated_text) 
    ```

ä»ä»£ç ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æµç¨‹å¾ˆç®€å•ã€‚æˆ‘ä»¬ä½¿ç”¨æ£€ç´¢å™¨æ£€ç´¢åˆ©ç”¨ RAG æµç¨‹æ‰€éœ€çš„æ–‡æ¡£ï¼Œå¹¶å°†è¾“å…¥æŸ¥è¯¢å’Œæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¼ é€’ç»™ LLM API è°ƒç”¨ã€‚

åœ¨è¿™æ¬¡å¯¹ RAG æ¶æ„çš„æ·±å…¥ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨äº†å…¶æœºåˆ¶ï¼Œå¹¶å±•ç¤ºäº†å…¶æ ¸å¿ƒç»„ä»¶çš„åŠŸèƒ½ã€‚é€šè¿‡ç»“åˆé«˜æ•ˆçš„ä¿¡æ¯æ£€ç´¢å’Œé«˜çº§è¯­è¨€ç”Ÿæˆæ¨¡å‹ï¼ŒRAG äº§ç”Ÿäº†ä¸Šä¸‹æ–‡ç›¸å…³ä¸”çŸ¥è¯†ä¸°å¯Œçš„å“åº”ã€‚éšç€æˆ‘ä»¬è¿‡æ¸¡åˆ°ä¸‹ä¸€èŠ‚ï¼Œæˆ‘ä»¬å°†è®¨è®º**æ£€ç´¢è¿‡ç¨‹**ã€‚

# ä¸ºä½ çš„ RAG æ£€ç´¢å¤–éƒ¨ä¿¡æ¯

ç†è§£ RAG å¦‚ä½•åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†å¯¹äºæ¬£èµå…¶ç”Ÿæˆäº‹å®å‡†ç¡®å’Œå¯Œæœ‰ä¿¡æ¯æ€§çš„å“åº”çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚æœ¬èŠ‚è®¨è®ºäº†å„ç§**æ£€ç´¢æŠ€æœ¯**ã€æ•´åˆæ£€ç´¢ä¿¡æ¯çš„ç­–ç•¥ï¼Œä»¥åŠè¯´æ˜è¿™äº›æ¦‚å¿µçš„å®ä¾‹ã€‚

## ç†è§£æ£€ç´¢æŠ€æœ¯å’Œç­–ç•¥

RAG æ¨¡å‹çš„æˆåŠŸå–å†³äºå…¶ä½¿ç”¨å¸¸ç”¨æ£€ç´¢æŠ€æœ¯ä¹‹ä¸€ä»åºå¤§çš„å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯çš„èƒ½åŠ›ã€‚è¿™äº›æ£€ç´¢æ–¹æ³•å¯¹äºä»å¤§å‹æ•°æ®é›†ä¸­è·å–ç›¸å…³ä¿¡æ¯è‡³å…³é‡è¦ã€‚å¸¸è§çš„æŠ€æœ¯åŒ…æ‹¬ä¼ ç»Ÿçš„ BM25 æ–¹æ³•ä»¥åŠç°ä»£çš„ DPR ç¥ç»ç½‘ç»œæ–¹æ³•ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›æŠ€æœ¯å¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼š**å‘é‡ç›¸ä¼¼åº¦æœç´¢**ã€**å…³é”®è¯åŒ¹é…**å’Œ**æ®µè½æ£€ç´¢**ã€‚æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹å°èŠ‚ä¸­è®¨è®ºæ¯ä¸ªæŠ€æœ¯ã€‚

### å‘é‡ç›¸ä¼¼åº¦æœç´¢

æ‚¨ä¼ é€’ç»™ LLM çš„æ–‡æœ¬æˆ–æŸ¥è¯¢è¢«è½¬æ¢æˆä¸€ä¸ªç§°ä¸º**åµŒå…¥**çš„å‘é‡è¡¨ç¤ºã€‚å‘é‡ç›¸ä¼¼åº¦æœç´¢é€šè¿‡æ¯”è¾ƒå‘é‡åµŒå…¥æ¥æ£€ç´¢æœ€æ¥è¿‘çš„åŒ¹é…é¡¹ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯ç›¸å…³å’Œç›¸ä¼¼æ–‡æœ¬å°†å…·æœ‰ç›¸ä¼¼çš„åµŒå…¥ã€‚è¯¥æŠ€æœ¯çš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š

1.  æ„å»ºè¾“å…¥æŸ¥è¯¢çš„åµŒå…¥ã€‚æˆ‘ä»¬å¯¹è¾“å…¥æŸ¥è¯¢è¿›è¡Œåˆ†è¯ï¼Œå¹¶ç”Ÿæˆå…¶å‘é‡åµŒå…¥è¡¨ç¤ºï¼š

    ```py
    query_inputs = question_tokenizer(query, return_tensors="pt")
    with torch.no_grad():
    Â Â query_embeddings = question_encoder(
    Â Â Â Â Â Â Â Â **query_inputs
    Â Â Â Â ).pooler_output 
    ```

1.  æ„å»ºæ–‡æ¡£çš„åµŒå…¥ã€‚æˆ‘ä»¬ä½¿ç”¨åˆ†è¯å™¨ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆä¸€ä¸ªåµŒå…¥ï¼Œå¹¶å°†æ¯ä¸ªåµŒå…¥ä¸å…¶å¯¹åº”çš„æ–‡æ¡£å…³è”ï¼š

    ```py
    for doc in documents:
    Â Â Â Â doc_inputs = context_tokenizer(doc, return_tensors="pt")
    Â Â Â Â with torch.no_grad():
    Â Â Â Â Â Â Â Â doc_embeddings.append(
    Â Â Â Â Â Â Â Â Â Â Â Â context_encoder(**doc_inputs).pooler_output)
    doc_embeddings = torch.cat(doc_embeddings) 
    ```

1.  ä½¿ç”¨ç‚¹ç§¯è®¡ç®—æŸ¥æ‰¾ç›¸ä¼¼æ–‡æ¡£ã€‚æ­¤æ­¥éª¤ä½¿ç”¨è¾“å…¥æŸ¥è¯¢åµŒå…¥å¹¶åœ¨æ–‡æ¡£åµŒå…¥ä¸­æœç´¢ä¸è¾“å…¥æŸ¥è¯¢ç›¸ä¼¼çš„æ–‡æ¡£ï¼š

    ```py
    scores = torch.matmul(query_embeddings, doc_embeddings.T).squeeze() 
    ```

1.  æŒ‰ç›¸å…³æ€§åˆ†æ•°å¯¹æ–‡æ¡£è¿›è¡Œæ’åºå¹¶è¿”å›ç»“æœã€‚ç»“æœåŒ…å«åŒ¹é…çš„æ–‡æ¡£ä»¥åŠä¸€ä¸ªè¡¨ç¤ºå…¶ä¸è¾“å…¥æŸ¥è¯¢ç›¸ä¼¼åº¦çš„åˆ†æ•°ã€‚æˆ‘ä»¬å°†æŒ‰ç…§æ‰€éœ€çš„é¡ºåºå¯¹ç»“æœè¿›è¡Œæ’åºï¼Œä»æœ€ç›¸ä¼¼åˆ°æœ€ä¸ç›¸ä¼¼ï¼š

    ```py
    ranked_docs = sorted(
    Â Â Â Â zip(documents, scores), key=lambda x: x[1], reverse=True) 
    ```

è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªç¤ºä¾‹ï¼Œçœ‹çœ‹ç»“æœä¼šæ˜¯ä»€ä¹ˆæ ·å­ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å…¥æŸ¥è¯¢ï¼š

```py
What are the benefits of solar energy? 
```

ä»¥ä¸‹ä¸ºç¤ºä¾‹è¾“å‡ºï¼ˆæŒ‰ç›¸å…³æ€§æ’åºçš„æ–‡æ¡£ï¼‰ï¼š

```py
Document: Solar energy is a renewable source of power., Score: 80.8264
....
Document: Graph databases like Neo4j are used to model complex relationships., Score: 52.8945 
```

ä¸Šè¿°ä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ DPR å°†æŸ¥è¯¢å’Œä¸€ç»„æ–‡æ¡£ç¼–ç æˆé«˜ç»´å‘é‡è¡¨ç¤ºã€‚é€šè¿‡è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œä¾‹å¦‚æŸ¥è¯¢å‘é‡ä¸æ–‡æ¡£å‘é‡ä¹‹é—´çš„ç‚¹ç§¯ï¼Œæ¨¡å‹è¯„ä¼°æ¯ä¸ªæ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚ç„¶åæ ¹æ®ç›¸ä¼¼åº¦åˆ†æ•°å¯¹æ–‡æ¡£è¿›è¡Œæ’åºï¼Œæœ€ç›¸å…³çš„æ–‡æ¡£å°†å‡ºç°åœ¨é¡¶éƒ¨ã€‚è¿™ä¸ªè¿‡ç¨‹çªå‡ºäº†åŸºäºå‘é‡çš„æ£€ç´¢åœ¨æœ‰æ•ˆè¯†åˆ«æ¥è‡ªå„ç§æ–‡æ¡£çš„ä¸Šä¸‹æ–‡ç›¸å…³ä¿¡æ¯æ–¹é¢çš„å¼ºå¤§åŠŸèƒ½ï¼Œå³ä½¿è¿™äº›æ–‡æ¡£åŒ…å«ç›¸å…³å’Œä¸ç›¸å…³çš„æ··åˆå†…å®¹ã€‚

æœ¬ä¾‹çš„å®Œæ•´ç‰ˆæœ¬å¯åœ¨ GitHub ä»“åº“ä¸­æ‰¾åˆ°ï¼š[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/vector_similarity_search.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/vector_similarity_search.py)ã€‚

### å…³é”®è¯åŒ¹é…

**å…³é”®è¯åŒ¹é…**æ˜¯ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•ï¼Œå®ƒè¯†åˆ«åŒ…å«ç”¨æˆ·æç¤ºä¸­å…³é”®è¯çš„æ–‡æ¡£ã€‚è™½ç„¶æ•ˆç‡é«˜ï¼Œä½†å¯èƒ½å®¹æ˜“å—åˆ°å™ªå£°çš„å½±å“ï¼Œå¹¶é”™è¿‡åŒ…å«ç›¸å…³åŒä¹‰è¯çš„æ–‡æ¡£ã€‚BM25 æ˜¯ä¸€ç§åŸºäºå…³é”®è¯çš„æ¦‚ç‡æ£€ç´¢å‡½æ•°ï¼Œå®ƒæ ¹æ®æ¯ä¸ªæ–‡æ¡£ä¸­å‡ºç°çš„æŸ¥è¯¢è¯å¯¹æ–‡æ¡£è¿›è¡Œè¯„åˆ†ï¼Œè€ƒè™‘è¯é¢‘å’Œæ–‡æ¡£é•¿åº¦ã€‚è¿™ç§æ–¹æ³•çš„åŸºæœ¬æµç¨‹å¦‚ä¸‹ï¼š

1.  ä½¿ç”¨æ–‡æ¡£æ„å»º BM25 è¯­æ–™åº“ã€‚æˆ‘ä»¬å°†å¯¹æ–‡æ¡£è¿›è¡Œåˆ†è¯å¹¶ä»è¿™äº›æ–‡æ¡£ä¸­æ„å»ºè¯­æ–™åº“ã€‚æˆ‘ä»¬å°†æ„å»º BM25 è¯­æ–™åº“ï¼š

    ```py
    tokenized_corpus = [doc.split() for doc in corpus]
    # Initialize BM25 with the tokenized corpus
    bm25 = BM25Okapi(tokenized_corpus, k1=1.5, b=0.75) 
    ```

1.  å°†æŸ¥è¯¢åˆ†è¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæœç´¢ï¼š

    ```py
    tokenized_query = query.split() 
    ```

1.  ä½¿ç”¨åˆ†è¯æŸ¥è¯¢æŸ¥è¯¢ BM25 è¯­æ–™åº“ã€‚è¿™å°†è¿”å›åŒ¹é…æ–‡æ¡£çš„åˆ†æ•°ï¼š

    ```py
    scores = bm25.get_scores(tokenized_query) 
    ```

1.  æˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›åˆ†æ•°ï¼ŒæŒ‰æ‰€éœ€é¡ºåºæ’åˆ—æ–‡æ¡£ï¼Œå¹¶è¿”å›å®ƒä»¬ï¼š

    ```py
    ranked_docs = sorted(zip(corpus, scores), key=lambda x: x[1], 
    Â Â Â Â reverse=True) 
    ```

å½“æˆ‘ä»¬è¿è¡Œæ­¤ç¤ºä¾‹æ—¶ï¼Œå¯¹äºç»™å®šçš„è¾“å…¥ï¼Œç»“æœå°†å¦‚ä¸‹æ‰€ç¤ºã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å…¥æŸ¥è¯¢ï¼š

```py
quick fox 
```

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å‡ºï¼š

```py
Ranked Documents:
Document: The quick brown fox jumps over the lazy dog., Score: 0.6049
.....
Document: Artificial intelligence is transforming the world., Score: 0.0000 
```

BM25 ç®—æ³•æ ¹æ®æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹æ–‡æ¡£è¿›è¡Œæ’åã€‚å®ƒä¾èµ–äºè¯é¢‘ï¼ˆå…³é”®è¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„é¢‘ç‡ï¼‰å’Œæ–‡æ¡£é•¿åº¦ï¼Œåº”ç”¨æ¦‚ç‡è¯„åˆ†å‡½æ•°æ¥è¯„ä¼°ç›¸å…³æ€§ã€‚ä¸å°†æŸ¥è¯¢å’Œæ–‡æ¡£éƒ½è¡¨ç¤ºä¸ºé«˜ç»´ç©ºé—´ä¸­å¯†é›†æ•°å€¼å‘é‡çš„å‘é‡ç›¸ä¼¼åº¦æœç´¢ä¸åŒï¼Œå®ƒä½¿ç”¨å¦‚ç‚¹ç§¯ç­‰æ•°å­¦å‡½æ•°æ¥è¡¡é‡ç›¸ä¼¼åº¦ï¼ŒBM25 ç›´æ¥åœ¨ç¦»æ•£å•è¯åŒ¹é…ä¸Šæ“ä½œã€‚è¿™æ„å‘³ç€ BM25 æ•ˆç‡é«˜ä¸”å¯è§£é‡Šï¼Œä½†å¯èƒ½åœ¨å¤„ç†è¯­ä¹‰å…³ç³»æ–¹é¢é‡åˆ°å›°éš¾ï¼Œå› ä¸ºå®ƒæ— æ³•è¯†åˆ«åŒä¹‰è¯æˆ–ä¸Šä¸‹æ–‡å«ä¹‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼Œå¦‚ DPRï¼Œåœ¨è¯†åˆ«å³ä½¿ç²¾ç¡®å…³é”®è¯ä¸åŒæ—¶ä¹Ÿèƒ½è¯†åˆ«æ¦‚å¿µç›¸ä¼¼æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè¿™ä½¿å¾—å®ƒæ›´é€‚åˆéœ€è¦æ·±åº¦è¯­ä¹‰ç†è§£çš„ä»»åŠ¡ã€‚æ­¤ä»£ç ç‰‡æ®µè¯´æ˜äº† BM25 åœ¨ç®€å•å…³é”®è¯åŒ¹é…ä»»åŠ¡ä¸­çš„å®ç”¨æ€§ï¼Œå…¶ä¸­æ•ˆç‡å’Œå¯è§£é‡Šæ€§è‡³å…³é‡è¦ã€‚

å®Œæ•´ç¤ºä¾‹å¯åœ¨ GitHub ä»“åº“ä¸­æ‰¾åˆ°ï¼š[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/keyword_matching.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/keyword_matching.py)ã€‚

### æ®µè½æ£€ç´¢

ä¸æ£€ç´¢æ•´ä¸ªæ–‡æ¡£ä¸åŒï¼ŒRAG å¯ä»¥ä¸“æ³¨äºæ–‡æ¡£ä¸­ç›´æ¥é’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢çš„å…·ä½“æ®µè½ã€‚è¿™å…è®¸è¿›è¡Œæ›´ç²¾ç¡®çš„ä¿¡æ¯æå–ã€‚è¿™ç§æ–¹æ³•çš„åŸºæœ¬æµç¨‹ä¸å‘é‡æœç´¢æ–¹æ³•éå¸¸ç›¸ä¼¼ã€‚æˆ‘ä»¬ä½¿ç”¨å‘é‡æœç´¢ä¸­æ˜¾ç¤ºçš„æ–¹æ³•è·å–æ’åé å‰çš„æ–‡æ¡£ï¼Œç„¶åå¦‚ä»¥ä¸‹ä»£ç ç‰‡æ®µæ‰€ç¤ºæå–ç›¸å…³æ®µè½ï¼š

```py
# Extract passages for the reader
passages = [doc for doc, score in ranked_docs]

# Prepare inputs for the reader
inputs = reader_tokenizer(
Â Â Â Â questions=query,
Â Â Â Â titles=["Passage"] * len(passages),
Â Â Â Â texts=passages,
Â Â Â Â return_tensors="pt",
Â Â Â Â padding=True,
Â Â Â Â truncation=True
)
# Use the reader to extract the most relevant passage
with torch.no_grad():
Â Â Â Â outputs = reader(**inputs)
# Extract the passage with the highest score
max_score_index = torch.argmax(outputs.relevance_logits)
most_relevant_passage = passages[max_score_index] 
```

å½“æˆ‘ä»¬é’ˆå¯¹ç»™å®šçš„è¾“å…¥æŸ¥è¯¢è¿è¡Œæ­¤ç¤ºä¾‹æ—¶ï¼Œç»“æœå¦‚ä¸‹æ‰€ç¤ºã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å…¥æŸ¥è¯¢ï¼š

```py
What are the benefits of solar energy? 
```

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å‡ºï¼š

```py
Ranked Documents:
Document: Solar energy is a renewable source of power., Score: 80.8264
.....
Document: It has low maintenance costs., Score: 57.9905

Most Relevant Passage: Solar panels help combat climate change and reduce carbon footprint. 
```

ä¸Šè¿°ç¤ºä¾‹è¯´æ˜äº†**æ®µè½æ£€ç´¢æ–¹æ³•**ï¼Œå®ƒæ¯”æ–‡æ¡£çº§æ£€ç´¢æ›´ç»†ç²’åº¦ï¼Œä¸“æ³¨äºæå–ç›´æ¥é’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢çš„ç‰¹å®šæ®µè½ã€‚é€šè¿‡ç»“åˆä½¿ç”¨**è¯»è€…æ¨¡å‹**å’Œ**æ£€ç´¢å™¨**ï¼Œè¿™ç§æ–¹æ³•å¢å¼ºäº†ç›¸å…³æ€§å’Œç‰¹å¼‚æ€§ï¼Œå› ä¸ºå®ƒä¸ä»…ç¡®å®šäº†æœ€ç›¸å…³çš„æ–‡æ¡£ï¼Œè¿˜ç¡®å®šäº†å…¶ä¸­æœ€ä½³å›ç­”æŸ¥è¯¢çš„ç¡®åˆ‡æ®µè½ã€‚

å³ä½¿ä¸€ä¸ªæ®µè½çš„æ£€ç´¢å™¨åˆ†æ•°ç•¥ä½ï¼Œè¯»è€…ä¹Ÿå¯èƒ½ä¼˜å…ˆè€ƒè™‘å®ƒï¼Œå› ä¸ºå®ƒåœ¨è¯å’Œè·¨åº¦çº§åˆ«ä¸Šæ›´ç²¾ç¡®åœ°è¯„ä¼°ç›¸å…³æ€§ï¼Œè€ƒè™‘äº†ä¸Šä¸‹æ–‡ç»†å¾®å·®åˆ«ã€‚æ£€ç´¢å™¨é€šå¸¸ä½¿ç”¨æŸ¥è¯¢å’Œæ®µè½åµŒå…¥çš„ç‚¹ç§¯æ¥è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼š

![](img/B21107_02_001.png)

è¿™é‡Œï¼Œğ‘æ˜¯æŸ¥è¯¢åµŒå…¥ï¼Œ![](img/B21107_02_002.png)æ˜¯![](img/B21107_02_003.png)æ®µè½çš„åµŒå…¥ï¼Œğ‘‘æ˜¯åµŒå…¥çš„ç»´åº¦ã€‚

ç„¶è€Œï¼Œè¯»è€…é€šè¿‡åˆ†ææ¯ä¸ªæ®µè½çš„æ–‡æœ¬å†…å®¹è¿›ä¸€æ­¥ç»†åŒ–è¿™ä¸€è¿‡ç¨‹ã€‚å®ƒæ ¹æ®ç»™å®šæ®µè½åŒ…å«ç­”æ¡ˆçš„å¯èƒ½æ€§åˆ†é…ä¸€ä¸ª**ç›¸å…³æ€§åˆ†æ•°**æˆ–**logit**ï¼ˆä¹Ÿç§°ä¸º**ç½®ä¿¡åº¦åˆ†æ•°**ï¼‰ã€‚è¿™ä¸ªç›¸å…³æ€§åˆ†æ•°æ˜¯ä»è¯»è€…æ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼ˆlogitsï¼‰ä¸­è®¡ç®—å‡ºæ¥çš„ï¼Œè¯¥æ¨¡å‹è€ƒè™‘äº†æŸ¥è¯¢ä¸æ®µè½ä¹‹é—´çš„è¯çº§å’Œè·¨åº¦çº§äº¤äº’ã€‚ç›¸å…³æ€§åˆ†æ•°çš„å…¬å¼å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š

![](img/B21107_02_004.png)

è¿™é‡Œï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹å†…å®¹ï¼š

+   logits(![](img/B21107_02_002.png))æŒ‡çš„æ˜¯è¯»è€…åˆ†é…ç»™æ®µè½![](img/B21107_02_002.png)çš„åŸå§‹åˆ†æ•°ã€‚

+   softmax å°†è¿™äº›åŸå§‹åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œå¼ºè°ƒæœ€æœ‰å¯èƒ½ç›¸å…³çš„æ®µè½([`pytorch.org/docs/stable/generated/torch.nn.Softmax.html`](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))

é€šè¿‡ç»“åˆä¸¤ä¸ªé˜¶æ®µï¼Œç³»ç»Ÿå¯ä»¥è¯†åˆ«å‡ºä¸ä»…è¯­ä¹‰ç›¸ä¼¼ï¼ˆæ£€ç´¢å™¨é˜¶æ®µï¼‰ï¼Œè€Œä¸”ä¸æŸ¥è¯¢æ„å›¾ä¸Šä¸‹æ–‡å¯¹é½çš„æ®µè½ï¼ˆè¯»è€…é˜¶æ®µï¼‰ã€‚

è¿™ä¸ªåŒé˜¶æ®µè¿‡ç¨‹çªå‡ºäº†æ®µè½æ£€ç´¢åœ¨ä¿¡æ¯æ£€ç´¢ç®¡é“ä¸­ç”Ÿæˆé«˜åº¦é’ˆå¯¹æ€§çš„å“åº”çš„ä¼˜åŠ¿ã€‚

å®Œæ•´ç¤ºä¾‹å¯åœ¨ GitHub ä»“åº“ä¸­æ‰¾åˆ°ï¼š[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/passage_retrieval.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/passage_retrieval.py)ã€‚

## é›†æˆæ£€ç´¢ä¿¡æ¯

åœ¨ RAG æµç¨‹çš„æœ€åä¸€æ­¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å¦‚ä½•ä»¥ç»¼åˆä¸Šä¸‹æ–‡ç›¸å…³ä¸”è¿è´¯çš„å“åº”çš„æ–¹å¼å°†æ£€ç´¢å™¨ä¿¡æ¯ä¸ç”Ÿæˆæ¨¡å‹ç›¸ç»“åˆã€‚ä¸æ—©æœŸç¤ºä¾‹ä¸åŒï¼Œè¿™ç§æ–¹æ³•æ˜ç¡®åœ°å°†å¤šä¸ªæ£€ç´¢åˆ°çš„æ®µè½ä¸æŸ¥è¯¢ç›¸ç»“åˆã€‚é€šè¿‡è¿™æ ·åšï¼Œå®ƒä¸ºç”Ÿæˆæ¨¡å‹åˆ›å»ºäº†ä¸€ä¸ªå•ä¸€è¾“å…¥ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿç»¼åˆå‡ºä¸€ä¸ªç»Ÿä¸€ä¸”ä¸°å¯Œçš„å“åº”ï¼Œè€Œä¸ä»…ä»…æ˜¯é€‰æ‹©æˆ–æ’åºæ®µè½ï¼š

```py
def integrate_and_generate(query, retrieved_docs):
Â Â Â Â # Combine query and retrieved documents into a single input
Â Â Â Â input_text = f"Answer this question based on the following context: {query} Context: {' '.join(retrieved_docs)}"

Â Â Â Â # Tokenize input for T5
Â Â Â Â inputs = t5_tokenizer(input_text, return_tensors="pt", 
Â Â Â Â Â Â Â Â padding=True, truncation=True, max_length=512)

Â Â Â Â # Generate a response
Â Â Â Â with torch.no_grad():
Â Â Â Â Â Â Â Â outputs = t5_model.generate(**inputs, max_length=100)

Â Â Â Â # Decode and return the generated response
Â Â Â Â return t5_tokenizer.decode(outputs[0], skip_special_tokens=True) 
```

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å…¥æŸ¥è¯¢ï¼š

```py
What are the benefits of solar energy? 
```

ä»¥ä¸‹ä¸ºç¤ºä¾‹è¾“å‡ºï¼š

```py
Ranked Documents:
Document: Solar energy is a renewable source of power., Score: 80.8264
....
Document: It has low maintenance costs., Score: 57.9905

Most Relevant Passage: Solar panels help combat climate change and reduce carbon footprint. 
sized response. The generate() function processes the combined input (query and passages) through the encoder to produce contextual embeddings, *â„*. These embeddings are then used by the decoder, which generates each token sequentially based on probabilities:
```

![](img/B21107_02_007.png)

è¿™é‡Œï¼Œ![](img/B21107_02_008.png) æ˜¯ä½ç½® ![](img/B21107_02_009.png) çš„æ ‡è®°ï¼Œ![](img/B21107_02_010.png) æ˜¯éšè—çŠ¶æ€ï¼Œè€Œ ![](img/B21107_02_011.png) æ˜¯æ¨¡å‹çš„æƒé‡çŸ©é˜µã€‚Beam æœç´¢é€šè¿‡æœ€å¤§åŒ–è·¨æ ‡è®°çš„æ•´ä½“æ¦‚ç‡æ¥ç¡®ä¿é€‰æ‹©æœ€å¯èƒ½çš„åºåˆ—ã€‚ä¸å‰é¢ç¤ºä¾‹ä¸­å•ç‹¬é€‰æ‹©æˆ–æ’åºæ®µè½ä¸åŒï¼Œæ­¤ä»£ç æ˜ç¡®åœ°å°†å¤šä¸ªæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸æŸ¥è¯¢ç»„åˆæˆä¸€ä¸ªå•ä¸€è¾“å…¥ã€‚è¿™ä½¿å¾— T5 æ¨¡å‹èƒ½å¤Ÿå…¨é¢å¤„ç†ç»„åˆä¸Šä¸‹æ–‡ï¼Œå¹¶äº§ç”Ÿä¸€ä¸ªåŒ…å«æ¥è‡ªå¤šä¸ªæ¥æºä¿¡æ¯çš„è¿è´¯å“åº”ï¼Œè¿™ä½¿å¾—å®ƒåœ¨éœ€è¦è·¨å¤šä¸ªæ®µè½ç»¼åˆæˆ–æ€»ç»“æŸ¥è¯¢æ—¶ç‰¹åˆ«æœ‰æ•ˆã€‚

è¦å‚è€ƒæ­¤ä»£ç çš„å®Œæ•´ç‰ˆæœ¬ï¼Œè¯·å‚é˜…ï¼š[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/integrate_and_generate.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/integrate_and_generate.py)

é€šè¿‡æ¢ç´¢å„ç§æ£€ç´¢æŠ€æœ¯å’Œå®ƒä»¬ä¸ç”Ÿæˆæ¨¡å‹çš„é›†æˆï¼Œæˆ‘ä»¬çœ‹åˆ°äº† RAG æ¶æ„å¦‚ä½•åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥äº§ç”Ÿå‡†ç¡®å’Œæœ‰ä¿¡æ¯é‡çš„å“åº”ã€‚

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä»æºè¯»å–è¾“å…¥æ–‡æ¡£å¹¶åˆ©ç”¨è¿™äº›æ–‡æ¡£è¿›è¡Œæ£€ç´¢æµç¨‹çš„æ•´ä½“æµç¨‹ï¼Œè€Œä¸æ˜¯æœ¬èŠ‚ç¤ºä¾‹ä¸­æŸ¥çœ‹çš„ç®€å•ç¡¬ç¼–ç å¥å­ã€‚

# æ„å»ºç«¯åˆ°ç«¯ RAG æµç¨‹

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ç®€å•çš„æ•°æ®æ·±å…¥æ¢è®¨äº† RAG æµç¨‹ä¸­çš„å„ä¸ªæ­¥éª¤ä»¥å±•ç¤ºç”¨æ³•ã€‚é€€ä¸€æ­¥ä½¿ç”¨ä¸€ä¸ªçœŸå®ä¸–ç•Œçš„æ•°æ®é›†ï¼ˆå°½ç®¡å¾ˆç®€å•ï¼‰æ¥å®Œæˆæ•´ä¸ªæµç¨‹æ˜¯ä¸ªä¸é”™çš„ä¸»æ„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ GitHub çš„é—®é¢˜æ•°æ®é›†ï¼ˆ[`huggingface.co/datasets/lewtun/github-issues`](https://huggingface.co/datasets/lewtun/github-issues)ï¼‰ã€‚æˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•è¯»å–è¿™äº›æ•°æ®å¹¶åœ¨ RAG æµç¨‹ä¸­ä½¿ç”¨å®ƒä»¬ã€‚è¿™å°†ä¸ºåç»­ç« èŠ‚ä¸­å®Œæ•´ç«¯åˆ°ç«¯ RAG æµç¨‹çš„å®ç°å¥ å®šåŸºç¡€ã€‚

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†åŠ è½½ GitHub æ³¨é‡Šä»¥å›ç­”è¯¸å¦‚å¦‚ä½•ç¦»çº¿åŠ è½½æ•°æ®ç­‰é—®é¢˜ã€‚æˆ‘ä»¬éœ€è¦éµå¾ªä»¥ä¸‹æ­¥éª¤æ¥åŠ è½½æ•°æ®å¹¶è®¾ç½®æ£€ç´¢å™¨ï¼š

1.  **å‡†å¤‡æ•°æ®**ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡æˆ‘ä»¬çš„æ•°æ®é›†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Hugging Face `datasets` åº“ï¼š

    ```py
    # Load the GitHub issues dataset
    issues_dataset = load_dataset("lewtun/github-issues", split="train")

    # Filter out pull requests and keep only issues with comments
    issues_dataset = issues_dataset.filter(
    Â Â Â Â lambda x: not x["is_pull_request"] and len(x["comments"]) > 0) 
    ```

1.  **é€‰æ‹©ç›¸å…³åˆ—**ï¼šä»…ä¿ç•™åˆ†ææ‰€éœ€åˆ—ï¼š

    ```py
    # Define columns to keep
    columns_to_keep = ["title", "body", "html_url", "comments"]
    columns_to_remove = set(issues_dataset.column_names) - \ 
    Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â set(columns_to_keep)
    # Remove unnecessary columns
    issues_dataset = issues_dataset.remove_columns(columns_to_remove) 
    ```

1.  **å°†æ•°æ®é›†è½¬æ¢ä¸º pandas DataFrame**ï¼šå°†æ•°æ®é›†è½¬æ¢ä¸º `pandas` DataFrame ä»¥ä¾¿äºæ“ä½œï¼š

    ```py
    # Set format to pandas and convert the dataset
    issues_dataset.set_format("pandas")
    df = issues_dataset[:] 
    ```

1.  **çˆ†ç‚¸æ³¨é‡Šï¼Œå°†å®ƒä»¬è½¬æ¢å›æ•°æ®é›†ï¼Œå¹¶å¤„ç†**ï¼šå°†æ³¨é‡Šå±•å¼€æˆå•ç‹¬çš„è¡Œï¼Œå°† DataFrame è½¬æ¢å›æ•°æ®é›†ï¼Œå¹¶è®¡ç®—æ¯æ¡æ³¨é‡Šçš„é•¿åº¦ã€‚è¿™ä¸€æ­¥ä½¿å¾—æ•°æ®æ›´é€‚åˆä¸æ£€ç´¢æµç¨‹ä¸€èµ·ä½¿ç”¨ï¼š

    ```py
    # Explode comments into separate rows
    comments_df = df.explode("comments", ignore_index=True) 
    # Convert the DataFrame back to a Dataset
    comments_dataset = Dataset.from_pandas(comments_df)

    # Compute the length of each comment
    comments_dataset = comments_dataset.map(
    Â Â Â Â lambda x: {"comment_length": len(x["comments"].split())}, 
    Â Â Â Â num_proc=1)
    # Filter out short comments
    comments_dataset = comments_dataset.filter(
    Â Â Â Â lambda x: x["comment_length"] > 15) 
    ```

1.  **æ‹¼æ¥æ–‡æœ¬ä»¥ç”ŸæˆåµŒå…¥**ï¼šè®©æˆ‘ä»¬é€šè¿‡æ‹¼æ¥ç›¸å…³æ–‡æœ¬å­—æ®µæ¥å‡†å¤‡æ–‡æ¡£æ–‡æœ¬ã€‚æˆ‘ä»¬å°†ä»æ¯ä¸€è¡Œä¸­æå–å•ä¸ªå­—æ®µï¼Œå¹¶å‡†å¤‡ä»£è¡¨è¯¥è¡Œæ–‡æ¡£æ–‡æœ¬çš„æ–‡æœ¬ã€‚è¿™äº›æ–‡æ¡£å­˜å‚¨åœ¨åµŒå…¥å­˜å‚¨ä¸­ï¼Œç”¨äºæ£€ç´¢å™¨ä½¿ç”¨ï¼š

    ```py
    # Function to concatenate text fields
    def concatenate_text(examples):
    Â Â Â Â return {
    Â Â Â Â Â Â Â "text": examples["title"] + " \n " + 
    Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â examples["body"] + " \n " + 
    Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â examples["comments"]
    Â Â Â Â }
    # Apply the function to create a text field
    comments_dataset = comments_dataset.map(concatenate_text, 
    Â Â Â Â num_proc=1) 
    ```

1.  **åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨**ï¼šè®©æˆ‘ä»¬åŠ è½½ LLMï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒå°†æ–‡æ¡£è½¬æ¢ä¸ºåµŒå…¥å¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨åµŒå…¥å­˜å‚¨ä¸­ä»¥ç”¨äºæ£€ç´¢å™¨æµç¨‹ï¼š

    ```py
    # Load pre-trained model and tokenizer
    model_ckpt = "sentence-transformers/all-MiniLM-L6-v2"
    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)
    model = AutoModel.from_pretrained(model_ckpt).to("cpu") 
    ```

1.  **å®šä¹‰åµŒå…¥å‡½æ•°**ï¼šå®šä¹‰ä¸€ä¸ªåµŒå…¥å‡½æ•°ï¼Œè¯¥å‡½æ•°åˆ©ç”¨æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„æ¨¡å‹æ¥ç”ŸæˆåµŒå…¥ã€‚æˆ‘ä»¬å¯ä»¥è¿­ä»£åœ°è°ƒç”¨æ­¤æ–¹æ³•ï¼Œä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªæ–‡æ¡£çš„æ‰€æœ‰åµŒå…¥ï¼š

    ```py
    # Function to get embeddings for a list of texts
    def get_embeddings(text_list):
    Â Â Â Â encoded_input = tokenizer(text_list, padding=True, 
    Â Â Â Â Â Â Â Â truncation=True, return_tensors="pt").to("cpu")
    Â Â Â Â with torch.no_grad():
    Â Â Â Â Â Â Â Â model_output = model(**encoded_input)
    Â Â Â Â return cls_pooling(model_output).numpy() 
    ```

1.  **è®¡ç®—åµŒå…¥**ï¼šä¸ºæ•°æ®é›†è®¡ç®—åµŒå…¥ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»å®šä¹‰äº†åµŒå…¥å‡½æ•°ï¼Œè®©æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„è¯„è®ºæ•°æ®é›†ä¸­çš„æ‰€æœ‰æ–‡æ¡£è°ƒç”¨å®ƒã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ­£åœ¨å°†åµŒå…¥å­˜å‚¨åœ¨åŒä¸€æ•°æ®é›†çš„æ–°åˆ—`embedding`ä¸­ï¼š

    ```py
    # Compute embeddings for the dataset
    comments_dataset = comments_dataset.map(
    Â Â Â Â lambda batch: {"embeddings": [get_embeddings([text])[0] 
            for text in batch["text"]]},
    Â Â Â Â batched=True,
    Â Â Â Â batch_size=100,
    Â Â Â Â num_proc=1
    ) 
    ```

1.  **æ‰§è¡Œè¯­ä¹‰æœç´¢**ï¼šè®©æˆ‘ä»¬ä¸ºé—®é¢˜æ‰§è¡Œæ£€ç´¢å™¨æµç¨‹ã€‚è¿™å°†æ£€ç´¢ä¸æˆ‘ä»¬æ‰€æé—®é¢˜ç›¸å…³çš„æ‰€æœ‰é—®é¢˜ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›æ–‡æ¡£æ ¹æ®éœ€è¦æ”¹è¿›å“åº”ï¼š

    ```py
    # Define a query
    question = "How can I load a dataset offline?"
    # Compute the embedding for the query
    query_embedding = get_embeddings([question]).reshape(1, -1) 
    # Find the nearest examples
    embeddings = np.vstack(comments_dataset["embeddings"])
    similarities = cosine_similarity(
    Â Â Â Â query_embedding, embeddings
    ).flatten()
    # Display the results
    top_indices = np.argsort(similarities)[::-1][:5]
    for idx in top_indices:
    Â Â Â Â result = comments_dataset[int(idx)]Â Â # Convert NumPy integer to native Python integer
    Â Â Â Â print(f"COMMENT: {result['comments']}")
    Â Â Â Â print(f"SCORE: {similarities[idx]}")
    Â Â Â Â print(f"TITLE: {result['title']}")
    Â Â Â Â print(f"URL: {result['html_url']}")
    Â Â Â Â print("=" * 50) 
    ```

å‰é¢çš„ä»£ç å±•ç¤ºäº†å®Œæ•´çš„æµç¨‹ï¼Œä»æˆ‘ä»¬å°†æ•°æ®åŠ è½½åˆ°æ•°æ®å­˜å‚¨ä¸­ï¼Œè¿™å¯ä»¥æˆä¸ºæ£€ç´¢å™¨çš„åŸºç¡€ï¼Œåˆ°æ£€ç´¢æ–‡æ¡£ï¼Œè¿™äº›æ–‡æ¡£å¯ä»¥ç”¨äºåœ¨ LLM ç”Ÿæˆç­”æ¡ˆæ—¶æä¾›æ›´å¤šä¸Šä¸‹æ–‡ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¿è¡Œæ­¤åº”ç”¨ç¨‹åºæ—¶çš„è¾“å‡ºçœ‹èµ·æ¥å¦‚ä½•ã€‚ç¤ºä¾‹ä»£ç ä¸­ç¡¬ç¼–ç äº†é—®é¢˜ï¼Œå®ƒæ˜¯ï¼š

```py
How can I load a dataset offline?. 
```

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹è¾“å‡ºï¼š

```py
COMMENT: Yes currently you need an internet connection because the lib tries to check for the etag of the dataset script ...
SCORE: 0.9054292969045314
TITLE: Downloaded datasets are not usable offline
URL: https://github.com/huggingface/datasets/issues/761
==================================================
COMMENT: Requiring online connection is a deal breaker in some cases ...
SCORE: 0.9052456782359709
TITLE: Discussion using datasets in offline mode
URL: https://github.com/huggingface/datasets/issues/824
================================================== 
```

è¿™ä¸ªåŠ¨æ‰‹å®éªŒå±•ç¤ºäº†ç«¯åˆ°ç«¯ RAG æ¶æ„çš„å®é™…åº”ç”¨ï¼Œåˆ©ç”¨å¼ºå¤§çš„æ£€ç´¢æŠ€æœ¯æ¥å¢å¼ºè¯­è¨€ç”Ÿæˆã€‚å‰é¢çš„ä»£ç æ˜¯ä» Hugging Face NLP è¯¾ç¨‹ä¸­æ”¹ç¼–çš„ï¼Œå¯åœ¨[`huggingface.co/learn/nlp-course/chapter5/6?fw=tf`](https://huggingface.co/learn/nlp-course/chapter5/6?fw=tf)æ‰¾åˆ°ã€‚

å®Œæ•´çš„ Python æ–‡ä»¶ä»¥åŠå¦‚ä½•è¿è¡Œçš„è¯¦ç»†è¯´æ˜å¯åœ¨[`github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/full_rag_pipeline.py`](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch2/full_rag_pipeline.py)æ‰¾åˆ°ã€‚

# æ‘˜è¦

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº† RAG æ¨¡å‹çš„ä¸–ç•Œã€‚æˆ‘ä»¬é¦–å…ˆç†è§£äº† RAG çš„æ ¸å¿ƒåŸåˆ™ä»¥åŠå®ƒä»¬ä¸ä¼ ç»Ÿç”Ÿæˆå¼ AI æ¨¡å‹çš„ä¸åŒä¹‹å¤„ã€‚è¿™ç§åŸºç¡€æ€§çŸ¥è¯†è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä¸ºæ¬£èµ RAG å¸¦æ¥çš„å¢å¼ºåŠŸèƒ½å¥ å®šäº†åŸºç¡€ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ›´è¯¦ç»†åœ°ç ”ç©¶äº† RAG æ¨¡å‹çš„æ¶æ„ï¼Œé€šè¿‡è¯¦ç»†çš„ä»£ç ç¤ºä¾‹æ¥åˆ†è§£å…¶ç»„ä»¶ã€‚é€šè¿‡æ£€æŸ¥ç¼–ç å™¨ã€æ£€ç´¢å™¨å’Œè§£ç å™¨ï¼Œä½ äº†è§£äº†è¿™äº›æ¨¡å‹çš„å†…éƒ¨å·¥ä½œåŸç†ä»¥åŠå®ƒä»¬å¦‚ä½•æ•´åˆæ£€ç´¢ä¿¡æ¯ä»¥äº§ç”Ÿæ›´å…·æœ‰ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œè¿è´¯æ€§çš„è¾“å‡ºã€‚

æˆ‘ä»¬éšåæ¢è®¨äº† RAG å¦‚ä½•åˆ©ç”¨ä¿¡æ¯æ£€ç´¢çš„åŠ›é‡ã€‚è¿™äº›æŠ€æœ¯å¸®åŠ© RAG æœ‰æ•ˆåœ°åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æºæ¥æé«˜ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€‚è¿™å¯¹äºéœ€è¦é«˜ç²¾åº¦å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åº”ç”¨å°¤å…¶æœ‰ç”¨ã€‚ä½ è¿˜å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨åƒ Transformers å’Œ Hugging Face è¿™æ ·çš„æµè¡Œåº“æ„å»ºä¸€ä¸ªç®€å•çš„ RAG æ¨¡å‹ã€‚

éšç€æˆ‘ä»¬è¿ˆå‘ä¸‹ä¸€ç« èŠ‚*ç¬¬ä¸‰ç« *ï¼Œæˆ‘ä»¬å°†åœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­å‰è¿›ã€‚ä½ å°†äº†è§£å›¾æ•°æ®å»ºæ¨¡ä»¥åŠå¦‚ä½•ä½¿ç”¨ Neo4j åˆ›å»ºçŸ¥è¯†å›¾è°±ã€‚
