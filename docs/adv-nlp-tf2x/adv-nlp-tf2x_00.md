# 前言

2017 年是**自然语言处理**（**NLP**）的一个分水岭，基于 Transformer 和注意力机制的网络崭露头角。过去几年对于 NLP 的变革性影响，就像 2012 年 AlexNet 对计算机视觉的影响一样巨大。NLP 取得了巨大的进展，我们现在正在从研究实验室走向应用。

这些进展跨越了**自然语言理解**（**NLU**）、**自然语言生成**（**NLG**）和**自然语言互动**（**NLI**）等领域。鉴于这些领域中有如此多的研究，要理解 NLP 的激动人心的进展可能是一项艰巨的任务。

本书专注于 NLP、语言生成和对话系统领域的前沿应用。它涵盖了使用流行库（如 Stanford NLP 和 spaCy）对文本进行预处理的概念，如分词、**词性**（**POS**）标注和词形还原。**命名实体识别**（**NER**）模型通过构建**双向长短期记忆网络**（**BiLSTMs**）、**条件随机场**（**CRFs**）和维特比解码器从零开始实现。采用非常实用、聚焦应用的视角，本书还涵盖了生成文本以用于句子补全和文本摘要、多模态网络通过为图像生成说明文字连接图像和文本、以及管理聊天机器人对话方面的内容。本书还讲解了 NLP 近期进展背后的一个重要原因——迁移学习和微调。未标注的文本数据容易获取，但对这些数据进行标注是昂贵的。本书提供了简化文本数据标注的实用技巧。

到本书结束时，我希望您能掌握用于解决复杂 NLP 问题的工具、技术和深度学习架构的高级知识。本书将涵盖编码器-解码器网络、**长短期记忆网络**（**LSTMs**）和 BiLSTMs、CRFs、BERT、GPT-2、GPT-3、Transformer 等关键技术，并使用 TensorFlow 进行讲解。

本书还涵盖了构建高级模型所需的高级 TensorFlow 技术：

+   构建自定义模型和层

+   构建自定义损失函数

+   实现学习率退火

+   使用`tf.data`高效加载数据

+   模型检查点以支持长时间训练（通常需要几天）

本书包含可根据您自身使用场景进行调整的可工作代码。我希望通过本书的学习，您甚至能够利用所学技能进行前沿的研究。

# 本书适合哪些人群

本书假设读者对深度学习的基础知识和自然语言处理（NLP）的基本概念有所了解。本书重点讲解高级应用和构建能够解决复杂任务的 NLP 系统。各种读者都能够跟随本书的内容，但从本书中受益最大的读者包括：

+   熟悉监督学习和深度学习技术基础的中级**机器学习**（**ML**）开发者

+   已经使用 TensorFlow/Python 进行数据科学、机器学习、研究、分析等工作的专业人士，并能从更扎实的高级 NLP 技术理解中获益

# 本书内容概述

*第一章*，*NLP 基础知识*，概述了 NLP 中的各种话题，如分词、词干提取、词形还原、词性标注、向量化等。本章将介绍常见的 NLP 库，如 spaCy、Stanford NLP 和 NLTK，并提供它们的关键功能和使用场景。我们还将构建一个简单的垃圾邮件分类器。

*第二章*，*使用 BiLSTM 理解自然语言中的情感*，涵盖了情感分析的自然语言理解（NLU）用例，介绍了**循环神经网络**（**RNNs**）、LSTM 和 BiLSTM，它们是现代 NLP 模型的基本构建模块。我们还将使用`tf.data`高效利用 CPU 和 GPU，提升数据流水线和模型训练的速度。

*第三章*，*使用 BiLSTM、CRF 和维特比解码的命名实体识别（NER）*，聚焦于命名实体识别（NER）这一自然语言理解（NLU）的核心问题，NER 是任务导向型聊天机器人的基本构建模块。我们将为 CRF 构建一个自定义层，以提高 NER 的准确性，并介绍维特比解码方案，它通常应用于深度模型中，以提高输出质量。

*第四章*，*使用 BERT 进行迁移学习*，涵盖了现代深度 NLP 中的若干重要概念，如迁移学习的类型、预训练词向量、Transformer 的概述，以及 BERT 及其在改进*第二章*中情感分析任务中的应用，*使用 BiLSTM 理解自然语言中的情感*。

*第五章*，*使用 RNN 和 GPT-2 生成文本*，专注于使用自定义的基于字符的 RNN 生成文本，并通过 Beam Search 进行改进。我们还将介绍 GPT-2 架构，并简要讨论 GPT-3。

*第六章*，*使用 Seq2seq 注意力机制和 Transformer 网络进行文本摘要*，挑战性地探讨了抽象文本摘要任务。BERT 和 GPT 是完整编码器-解码器模型的两部分。我们将它们结合在一起，构建一个用于生成新闻文章标题的 seq2seq 模型。还会介绍如何使用 ROUGE 指标评估摘要效果。

*第七章*，*使用 ResNet 和 Transformer 进行多模态网络和图像描述*，将计算机视觉和 NLP 结合在一起，看看一张图片是否真能表达千言万语！我们将从零开始构建一个自定义的 Transformer 模型，并训练它生成图像的描述。

*第八章*，*使用 Snorkel 进行分类的弱监督学习*，聚焦于一个关键问题——数据标注。虽然 NLP 领域有大量未标注的数据，但标注数据是一项非常昂贵的任务。本章介绍了`snorkel`库，并展示如何快速标注大量数据。

*第九章*，*使用深度学习构建对话式 AI 应用程序*，结合了书中讲解的各种技术，展示了如何构建不同类型的聊天机器人，如问答机器人或槽位填充机器人。

*第十章*，*代码安装和配置说明*，介绍了安装和配置系统以运行本书随附代码的所有必要步骤。

# 为了最大限度地利用本书

+   了解深度学习模型和 TensorFlow 的基础知识是个不错的主意。

+   强烈建议使用 GPU。一些模型，尤其是后续章节中的模型，规模较大且复杂。它们在 CPU 上训练可能需要数小时甚至数天。没有 GPU 的情况下，RNN 的训练速度非常慢。你可以在 Google Colab 上免费访问 GPU，相关操作说明在第一章中提供。

## 下载示例代码文件

本书的代码包托管在 GitHub 上，网址为 [`github.com/PacktPublishing/Advanced-Natural-Language-Processing-with-TensorFlow-2`](https://github.com/PacktPublishing/Advanced-Natural-Language-Processing-with-TensorFlow-2)。我们还提供了来自我们丰富图书和视频目录的其他代码包，网址为 [`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)。请查看！

## 下载彩色图片

我们还提供了一个 PDF 文件，包含本书中使用的截图/图表的彩色图片。你可以在这里下载：[`static.packt-cdn.com/downloads/9781800200937_ColorImages.pdf`](https://static.packt-cdn.com/downloads/9781800200937_ColorImages.pdf)。

## 使用的约定

本书中使用了许多文本约定。

`CodeInText`：表示文本中的代码词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟网址、用户输入和 Twitter 用户名。例如：“在 `num_capitals()` 函数中，执行了对英语中大写字母的替换。”

代码块如下所示：

```py
en = snlp.Pipeline(lang='en')
def word_counts(x, pipeline=en):
  doc = pipeline(x)
  count = sum([len(sentence.tokens) for sentence in doc.sentences])
  return count 
```

当我们希望引起你对代码块中特定部分的注意时，相关的行或项将以粗体显示：

```py
en = snlp.Pipeline(lang='en')
def word_counts(x, pipeline=en):
  **doc = pipeline(x)**
  count = sum([len(sentence.tokens) for sentence in doc.sentences])
  return count 
```

任何命令行输入或输出都将如下所示：

```py
!pip install gensim 
```

**粗体**：表示一个新术语、一个重要的词或你在屏幕上看到的词，例如在菜单或对话框中，也会以这种方式出现在文本中。例如：“从 **管理** 面板中选择 **系统信息**。”

警告或重要说明将以这种形式出现。

提示和技巧将以这种形式出现。

# 联系我们

我们始终欢迎读者的反馈。

**一般反馈**：如果你对本书的任何方面有疑问，请在邮件主题中提及书名，并通过电子邮件联系 Packt，邮箱地址是 `customercare@packtpub.com`。

**勘误表**：尽管我们已尽一切努力确保内容准确无误，但错误偶尔也会发生。如果你在本书中发现了错误，我们将不胜感激您向我们报告。请访问 [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)，选择您的书籍，点击 **Errata Submission Form** 链接并输入详细信息。

**盗版**：如果你在任何形式的互联网上发现我们作品的非法副本，我们将不胜感激您提供位置地址或网站名称。请通过链接`copyright@packtpub.com`与我们联系。

**如果你对成为一名作者感兴趣**：如果你有专业知识并且有意编写或贡献书籍，请访问 [`authors.packtpub.com`](http://authors.packtpub.com)。

## 评论

请留下你的评论。阅读并使用本书后，请考虑在购买书籍的网站上留下您的评论。潜在读者可以看到并使用你的客观意见来做出购买决定，我们在 Packt 可以了解到你对我们产品的看法，而我们的作者也能看到你对他们书籍的反馈。谢谢！

欲了解更多有关 Packt 的信息，请访问 [packtpub.com](http://packtpub.com)。
