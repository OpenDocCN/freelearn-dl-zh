# 第十一章：讨论、当前趋势和展望

深度神经网络作为**深度学习**（**DL**）的核心，使得由多个处理层组成的计算模型能够学习数据的多层次抽象表示。这些方法极大地提升了语音识别、多媒体（图像/音频/视频）分析、自然语言处理、图像处理与分割、视觉物体识别、物体检测以及许多生命科学领域（如癌症基因组学、药物发现、个性化医学和生物医学影像）的前沿技术。

在整本书中，我们展示了如何使用基于 JVM 的深度学习库来开发涵盖这些领域的应用程序。我承认，某些项目并不那么全面，无法商业化部署，但需要一些额外的努力。尽管如此，展示如何部署这些模型并不在本书的范围之内。然而，至少这些项目为我们提供了一些核心的见解。

现在，我们已经结束了这段关于使用不同 Java 库进行深度学习的小旅程，是时候总结一切了。但在此之前，在本章中，我们将讨论已完成的项目和一些抽象的收获。接着，我们会提出一些改进建议。此外，我们还将涵盖其他实际深度学习项目的扩展指南。总的来说，本章将覆盖以下内容：

+   对项目的讨论、展望、未来改进与扩展

+   当前监督学习与无监督学习深度学习算法的趋势

+   常见问题解答（FAQ）

# 讨论与展望

在整本书中，我们涵盖了 10 个端到端的项目。从深度学习的介绍开始，到基于因式分解机的电影推荐系统项目结束。在这一部分，我们将简要回顾这些项目，讨论潜在的局限性，并提供一些未来的改进和扩展方向。

# 对已完成项目的讨论

在此过程中，我们尽力涵盖了多个来自不同领域的实际项目，如医疗保健、自然语言处理中的情感分析、迁移学习、图像和视频分类、分布式深度学习与训练、强化学习、在线交易以及视频中的实际物体检测。具体如下：

+   使用 MLP 和 LSTM 网络进行泰坦尼克号生还预测

+   使用递归网络进行癌症类型预测

+   使用卷积神经网络进行多标签图像分类

+   使用 Word2Vec 和 LSTM 网络进行情感分析

+   使用迁移学习进行图像分类

+   使用 YOLO、JavaCV 和 DL4J 进行实时物体检测

+   使用 LSTM 网络进行股票价格预测

+   使用卷积 LSTM 进行视频分类的分布式深度学习

+   使用深度强化学习进行 GridWorld 游戏

+   使用因式分解机开发电影推荐系统

现在我们将讨论改进这些项目以进行可能扩展的优缺点和未来方向。

# 泰坦尼克号生存预测使用 MLP 和 LSTM 网络

在这个项目中，我们的主要目标是熟悉 Apache Spark ML 库，然后基本介绍机器学习、深度学习它们的类型、架构和框架。

我们无法获得更高的准确性。然后，在第二章，*使用递归类型网络进行癌症类型预测*，我们重新审视了同一个项目，但是使用了一个强大的递归 LSTM 网络，显示了更高的准确性。要点是学习如何通过考虑大多数特征来准备数据集，并将其馈送到基于 Spark 和 DL4J 的 MLP 分类器中。

此外，这个数据集并不是很高维，所以应用深度学习方法并不是一个好主意。因此，我建议使用其他树集成方法，如随机森林和梯度提升树进行建模和部署。

# 癌症类型预测使用递归类型网络

我们解决了一个有趣的项目，在这个项目中，我们成功地根据癌症类型对癌症患者进行了分类。为此，我们使用了 LSTM 网络。我们使用了一个非常高维的基因表达数据集。我们将数据集转换为序列格式，并为每个样本的每个时间步训练了 LSTM 网络。

这个项目还展示了深度结构如 LSTM 的稳健性，证明即使没有应用降维，该模型也可以处理非常高维的数据集。

此方法的潜在限制之一是我们仅考虑了基因表达数据集，因此无法用于现实生活的预后和诊断，而其他数据集如**拷贝数变异**（**CNV**）、DNA 甲基化和与生存相关的临床结果必须考虑在内。尽管如此，需要来自生物医学工程师和医生的领域专业知识，以提出一个集成解决方案。

最后，要点是至少显示了如何处理至少一种癌症基因组数据集。因此，同样的技术也可以应用于其他数据类型。然后，在部署之前，必须通过获取来自领域专家的输入，例如 AI 专家系统，来开发一个多模态网络。

# 使用卷积神经网络进行图像分类

在这个项目中，我们看到了如何解决多标签图像分类问题。我们使用了真实的 Yelp 图像。然后，我们训练了一个 CNN 来预测每个标记图像的类别。在这个项目中，最具挑战性的部分是特征工程，因为我们不仅要处理图像，还要处理不同的标签和元数据。不幸的是，我们无法达到非常高的准确性。

关键收获是，类似的方法可以应用于解决具有多标签的其他图像数据集。然而，一个多分类问题也可以以最小的努力解决。你所需要做的就是准备数据集，使得基于 CNN 的模型能够处理它。除了这个前景外，第五章中的项目《使用迁移学习进行图像分类》可以扩展到解决类似问题。

# 使用 Word2Vec 和 LSTM 网络进行情感分析

在这个项目中，我们展示了如何使用 Word2Vec 和 LSTM 开发情感分析应用程序。我们还讨论了如何将非结构化文本转换为神经词嵌入，并进一步将其转换为训练 LSTM 网络所需的序列形式。接着，我们使用每个时间步长对应文本的序列训练 LSTM。

本项目还解决了一个二分类问题，并取得了非常高的准确性。同样，这个应用可以扩展到分类其他问题，例如垃圾邮件与非垃圾邮件分类、电影或产品评论分类。最后，在常见问题解答（FAQ）部分，我们讨论了如何使用 CNN 解决相同的问题，这同样可以达到与 LSTM 类似的准确性。

# 使用迁移学习进行图像分类

在本章中，我们使用迁移学习技术解决了一个有趣的猫与狗分类问题。我们使用了一个预训练的 VGG16 模型及其权重，随后用 Kaggle 提供的实际猫狗数据集对训练进行了微调。

一旦训练完成，我们保存了训练好的模型以实现模型持久化并进行后续重用。我们看到，训练过的模型能够成功地检测并区分猫和狗的图像，无论它们的大小、质量和形状差异多大。

训练好的模型/分类器可以用来解决现实生活中的猫与狗问题。最后，收获是，这种类似的技术只需最小的努力，就可以扩展并用于解决类似的图像分类问题；这适用于二分类和多分类问题。

# 使用 YOLO、JavaCV 和 DL4J 进行实时物体检测

在这个项目中，我们再次使用了迁移学习技术来解决另一个有趣的问题，即从视频片段中进行实时物体检测。我们使用了预训练的 YOLOv2 模型、JavaCV 和 DL4J 库来解决这个问题。

如本章所述，我们将图像识别理念扩展以解决这个问题。也就是说，我们的技术将视频帧作为图像生成，然后使用边界框方法从帧中识别物体。要点是，尽管我们使用了一个视频片段来展示评估，但它仍然显示出非常高的准确性。从提供的演示中，任何人都可以观察到视频中的大多数物体都被准确识别。因此，类似的技术可以扩展到实时物体检测。

在这方面，我们看到了一些收集实时视频的技巧，可以通过网络摄像头、视频摄像机（甚至是手机）收集视频，并通过 JavaCV 库将它们输入到我们的 YOLOv2 模型中。

# 使用 LSTM 网络进行股票价格预测

在这个项目中，我们展示了如何开发一个预测股票价格的示范项目，预测五个类别的股票价格：开盘价（OPEN）、收盘价（CLOSE）、最低价（LOW）、最高价（HIGH）和交易量（VOLUME）。然而，这个结果也缺乏实际的信号；你的网络所做的只是生成一个类似于上一输入价格的值。

如果我们将你的预测结果作为下一个预测的输入，我们发现结果非常糟糕。我知道这种方法有一些严重的缺点。不过，我们没有使用足够的数据，这可能限制了这种模型的表现。

了解了这个项目的缺点后，最大的收获是将比特币或其他加密货币的价格预测扩展到更广泛的范围。正如在 FAQ 部分所建议的，可以从 Kaggle 下载历史比特币数据。然后，可以使用与本项目类似的特征工程来准备序列数据集。不过，也可以使用基于 CNN 的方法。

# 分布式深度学习——使用卷积-LSTM 网络进行视频分类

在这个项目中，我们开发了一个完整的深度学习应用程序，用于分类来自 UCF101 数据集的大量视频数据集。我们应用了结合 CNN 和 LSTM 的网络，利用**deeplearning4j**（**DL4J**），克服了单独使用 CNN 或 RNN **长短期记忆**（**LSTM**）网络的局限性。

最后，我们展示了如何在 AWS EC2 AMI 9.0 实例上跨多个设备（包括 CPU 和 GPU）进行并行和分布式训练。我们在一个`p2.8xlarge`实例上进行并行和分布式训练，该实例配备了 8 个 GPU、32 个计算核心和 488 GB 的 RAM。

本章的一个重要收获是，这个端到端项目可以作为从视频中进行人类活动识别的入门项目。其次，我们没有取得高准确度，因为我们没有使用所有可用的视频片段来训练模型。

因此，使用完整的视频数据集对网络进行训练，并进行超参数调优，肯定能够提高准确性。在这种情况下，部署改进后的模型是商业上可行的。最后，如果你想让训练更快，可以配置一个 Hadoop 集群，将训练分布到 GPU 和 Spark 上。

# 使用深度强化学习进行 GridWorld 训练

在这个项目中，我们展示了如何使用 DL4J 和神经网络 Q 学习（Neural QLearning）开发一个示范性的 GridWorld 游戏，Q 函数在其中起到了重要作用。我们还提供了一些基本的理论背景，帮助开发 DQN 来玩 GridWorld 游戏。然而，我们没有开发一个模块来可视化智能体在整个过程中所做的动作。我承认，这是这个项目的最大缺点。不过，我在 FAQ 部分讨论了一些改进的建议。

从这个项目中得到的启示是，将这个应用扩展为可视化模型，或者甚至开发其他基于强化学习的游戏，比如《毁灭战士》和 ALE，将是一个不错的想法。其次，最后，我们也可以考虑开发另一个有趣的在线交易强化学习项目。

# 使用因式分解机的电影推荐系统

在这个项目中，我们展示了如何使用因式分解机（FMs）开发电影推荐系统。因式分解机是一组算法，通过引入矩阵分解算法中缺失的二阶特征交互，以监督方式增强线性模型的性能。

然而，在深入使用基于 RankSys 库的因式分解机（FMs）实现项目之前，我们了解了一些推荐系统的理论背景，包括矩阵分解和协同过滤。这个项目不仅涵盖了单个用户的电影评分预测，还讨论了排名预测。因此，我们还使用了因式分解机来预测电影的排名。

然而，这个库的潜在限制是，它不具备良好的可扩展性和结构性。我的建议是尝试基于 Python 的因式分解机库，这样会更好。最后，最大的收获是将这个应用扩展到使用 Python-based FM 库，从 MovieLens 或 IMDb 等更大的电影数据集，这一点是推荐的。

# 当前趋势与展望

作为一名研究人员，我在多个会议中担任**程序委员会**（**PC**）成员，如 WWW'2018、ISWC'2018、ESWC'2017/2018 和 ESWC SemDeep'2018 国际研讨会。除此之外，我还担任《国际语义网期刊》、《云计算期刊》和《生物信息学简报》的客座编辑。

在审阅了许多会议和期刊的论文后，我发现研究人员并没有局限于使用原始的 RNN、CNN、DBN 或自编码器来开发新兴的应用案例和分析解决方案。他们通过将这些架构组合起来，提出了跨领域的创新思路。

# 当前趋势

正如在第一章中讨论的，*深度学习入门*，研究人员最近提出了许多新兴的深度学习架构。这些架构不仅包括改进 CNN/RNN 及其变种，还包括一些其他特殊类型的架构：**深度时空神经网络**（**DST-NNs**）、**多维循环神经网络**（**MD-RNNs**）、**卷积自编码器**（**CAEs**）、深度嵌入聚类等。

然而，仍然有一些新兴的网络，如 CapsNets，这是 Hinton 等人提出的 CNN 改进版，旨在消除常规 CNN 的缺点。接下来是用于图像识别的残差神经网络和用于简单图像生成的**生成对抗网络**（**GANs**）。

除了这些趋势和应用场景，深度学习的不同新兴架构正在被应用于多媒体分析、计算机视觉（特别是语义图像分割）、物联网、图像和网络流量中的异常检测、自然语言处理中的神经机器翻译以及知识图谱与神经网络的集成。

# 新兴深度学习架构的前景

在本小节中，我们将讨论一些新兴架构及其变体，重点介绍一些应用场景。

# 残差神经网络

由于与它们相关的数百万亿的超参数以及其他实际问题，训练深度神经网络变得非常困难。为了解决这个问题，何凯明等人（详见 [`arxiv.org/abs/1512.03385v1`](https://arxiv.org/abs/1512.03385v1)）提出了**残差学习框架**（**RNN**），以简化比以往更深层的网络的训练。现在，根据原始论文：

“在这个网络设置中，我们不是期望每一层堆叠直接拟合一个期望的底层映射，而是明确地让这些层拟合一个残差映射。原始映射被重新表述为 F(x)+x。我们假设，优化残差映射比优化原始的、未引用的映射更容易。极端情况下，如果恒等映射是最优的，那么将残差推向零比通过堆叠非线性层拟合恒等映射要容易得多。”

通过这种方式，RNN 比其他深度神经网络架构更容易优化，并且可以从显著增加的深度中获得更高的准确性。缺点是，通过简单地堆叠残差块来构建网络，难免会限制其优化能力。为了解决这个问题，张科等人还提出了使用多层残差网络（详见 [`arxiv.org/abs/1608.02908`](https://arxiv.org/abs/1608.02908)）。

因此，残差网络被应用于解决许多新兴的应用场景，包括：

+   *基于骨架的动作识别，结合空间推理和时间堆栈学习*（更多信息见 [`arxiv.org/pdf/1805.02335`](https://arxiv.org/pdf/1805.02335)）。

+   最近，袁等人提出了*基于空间-光谱深度残差卷积神经网络的高光谱图像去噪*（详见 [`arxiv.org/pdf/1806.00183`](https://arxiv.org/pdf/1806.00183)）。

+   *使用改进的 DRN 进行交通流量预测的动态模型*（更多信息见 [`arxiv.org/pdf/1805.00868`](https://arxiv.org/pdf/1805.00868)）

+   *使用宽残差网络分类模拟的无线电信号，以用于寻找外星智能*（更多信息见 [`arxiv.org/pdf/1803.08624`](https://arxiv.org/pdf/1803.08624)）

# 生成对抗网络（GANs）

GAN 是由两网络相互对抗组成的深度神经网络架构（因此得名“对抗”）。Ian Goodfellow 等人首次在论文中介绍了 GAN（详细内容请见[`arxiv.org/abs/1406.2661v1`](https://arxiv.org/abs/1406.2661v1)）。GAN 是 AI 领域最好的研究成果之一，它可以学习模仿任何数据分布。训练好的 GAN 可以用于创建与我们世界相似的虚拟世界，特别是图像、音乐、语音或散文等方面。

尽管原始的 GAN 论文主要针对简单的图像生成（如 DCGAN、BEGAN 等），但人们正在将这一理念扩展到字体生成、动漫角色生成、互动图像生成、文本到图像生成、2D 物体生成、人体姿态估计等领域。以下是一些具体的研究导向应用案例：

+   使用 LSTM 从描述中生成图像序列（详细内容请见[`arxiv.org/pdf/1806.03027`](https://arxiv.org/pdf/1806.03027)） 

+   用于**脑电图**（**EEG**）脑信号的生成对抗网络（详细内容请见[`arxiv.org/pdf/1806.01875`](https://arxiv.org/pdf/1806.01875)）

+   用于电子健康记录的自然语言生成（详细内容请见[`arxiv.org/pdf/1806.01353`](https://arxiv.org/pdf/1806.01353)）

+   用于胸部 X 光分割（详细内容请见[`arxiv.org/pdf/1806.00600`](https://arxiv.org/pdf/1806.00600)）

# 胶囊网络（CapsNet）

如第一章所述，*深入学习入门*，CNN 在分类优质图像方面表现良好。然而，如果图像有旋转、倾斜或其他不同的方向，CNN 的表现会非常差。即使是 CNN 中的池化操作，在位置不变性方面也帮助有限。

为了克服 CNN 的局限性，Geoffrey Hinton 等人提出了一种突破性思路，称为**胶囊网络（CapsNet）**，它特别擅长处理不同类型的视觉刺激，并能编码诸如姿势（位置、大小和方向）、形变、速度、反射率、色调、纹理等信息。

在常规的 DNN 中，我们不断增加层数（更多的层意味着更深的网络）。而在 CapsNet 中，思路是将更多的层添加到单一层内。通过这种方式，CapsNet 是一个嵌套的神经网络层集合。在 CapsNet 中，最大池化层的局限性被克服，并用**基于协议的路由（RBA）**替代，以捕获低层次的视觉信息。

不幸的是，原始论文过于理论化。因此，研究人员正试图将 CapsNet 的理念扩展到不同的 AI 和数据科学项目中，包括图像分类、GAN 改进以及改善基于强化学习的游戏体验。以下是一些示例应用案例：

+   *使用胶囊进行目标定位和运动迁移学习*（详细内容请见[`arxiv.org/pdf/1805.07706`](https://arxiv.org/pdf/1805.07706)）

+   *一种基于注意力的 Bi-GRU-CapsNet 模型用于复合实体之间的上位词检测*（详情见[`arxiv.org/pdf/1805.04827`](https://arxiv.org/pdf/1805.04827)）

+   *通过胶囊网络进行脑肿瘤类型分类*（详情见[`arxiv.org/pdf/1802.10200`](https://arxiv.org/pdf/1802.10200)）

+   *CapsuleGAN: 生成对抗胶囊网络*（详情见[`arxiv.org/pdf/1802.06167`](https://arxiv.org/pdf/1802.06167)）

+   *使用胶囊网络的深度强化学习在高级游戏环境中的应用*（详情见[`arxiv.org/pdf/1801.09597`](https://arxiv.org/pdf/1801.09597)）

除了这些新兴的架构外，研究人员还尝试使用 GAN 架构通过 CapsNet 进行图像合成（见[`arxiv.org/pdf/1806.03796`](https://arxiv.org/pdf/1806.03796)）。此外，研究人员还使用了对抗性自编码器进行基于语音的情感识别（见[`arxiv.org/pdf/1806.02146`](https://arxiv.org/pdf/1806.02146)）。最后，我建议读者通过[`arxiv.org/list/cs.AI/recent`](https://arxiv.org/list/cs.AI/recent)了解人工智能、机器学习和深度学习的最新趋势。

# 语义图像分割

图像分割是将图像划分为若干个连贯部分的方法，但*并不*尝试理解这些部分代表什么。语义分割则试图将图像划分为语义上有意义的部分，并将每个部分分类到预定的类别中。

这种将原始脑部图像分割成灰质、白质和脑脊液的语义分割有助于根据分割区域对其进行分类。基于深度学习的技术，如**堆叠去噪自编码器**（**SDAE**），已被成功应用。

然而，基于循环的全卷积网络正在被用于高分辨率遥感图像的语义分割（详情见[`arxiv.org/pdf/1805.02091`](https://arxiv.org/pdf/1805.02091)）。这类图像分割技术已被应用于新兴领域，如盆腔磁共振成像分析、自动驾驶汽车的物体检测、地理空间图像分类（见[`www.semantic-web-journal.net/system/files/swj1862.pdf`](http://www.semantic-web-journal.net/system/files/swj1862.pdf)）等。

# 深度学习在聚类分析中的应用

聚类分析是最广泛使用的数据驱动任务之一。迄今为止，现有的聚类分析技术采用了经典的聚类算法，如 k-means、二分 k-means 或高斯混合模型。特别是，k-means 聚类算法及其多个变体已被提出，以解决高维输入空间中的问题。

然而，它们本质上限于线性嵌入。因此，它们无法建模非线性关系。然而，这些方法中的微调仅基于聚类分配硬化损失。因此，无法实现细粒度的聚类准确性。

简而言之，针对基于深度学习的表示学习和聚类分析的研究相对较少。然而，k-means 的质量依赖于数据分布。深度架构可以帮助模型从数据空间学习到映射到低维特征空间，在该空间中，它反复优化聚类目标。

考虑到这些限制和动机，研究人员提出了基于深度学习的聚类技术，用于聚类非常高维的数据和非线性对象。在这些方法中，k-means 与深度架构相结合，其中同时优化聚类分配硬化损失（来自 k-means）和重构损失（来自 DNN）。这些方法包括：

+   *无监督深度嵌入聚类分析*，由 Xie 等人撰写（参见[`arxiv.org/pdf/1511.06335.pdf`](https://arxiv.org/pdf/1511.06335.pdf)）

+   *基于神经网络的聚类，使用成对约束*，由 Hsu 等人撰写（参见更多内容：[`arxiv.org/abs/1511.06321`](https://arxiv.org/abs/1511.06321)）

+   *判别性增强聚类（DBC）*，由 Liu 等人撰写（参见更多内容：[`dataclustering.cse.msu.edu/papers/boost_cluster.pdf`](http://dataclustering.cse.msu.edu/papers/boost_cluster.pdf)）

+   *深度学习聚类：分类与新方法*，由 Elie 等人撰写（参见更多内容：[`arxiv.org/abs/1801.07648`](https://arxiv.org/abs/1801.07648)）

+   *用于基因型聚类和种族预测的递归深度嵌入网络*，由 Karim 等人撰写（参见更多内容：[`arxiv.org/pdf/1805.12218.pdf`](https://arxiv.org/pdf/1805.12218.pdf)）

# 常见问题（FAQ）

我们已经分析了完成的项目并观察了近期趋势。基于这些，可能会有一些问题出现在你脑海中。在这一节中，我将尝试设计一些这样的问答，并提供示例答案：

1.  在本章中，我们认为，利用 GAN，我们可以解决许多研究问题。在 DL4J 中有 GAN 的实现吗？

1.  在本章中，我们认为，使用 CapsNet 处理具有不同形状和方向的图像是一个更好的选择。在 DL4J 中有 CapsNet 的实现吗？

1.  在第一章，*深度学习入门*中，我们讨论了 DBN 和限制玻尔兹曼机作为其基本构建块。然而，在任何已完成的项目中，我们都没有使用 DBN。这是什么原因呢？

1.  在本章中，我们认为，利用来自物联网传感器数据或图像的无监督异常检测是一个新兴的研究应用场景。在 DL4J 中有这方面的例子吗？

1.  在 DL4J 中，有没有开发推荐引擎的例子？

1.  考虑到如今智能手机非常强大，我们可以在智能手机上开发图像/物体检测应用吗？

1.  如何将深度学习应用打包成一个网页应用？

1.  在运行项目时遇到了一些问题。此外，我在配置开发环境时也遇到困难（例如，在 Eclipse/IntelliJ IDEA 上配置 CUDA/CuDNN）。我该怎么办？

# 问题答案

**问题 1 的答案**：这方面存在一个未解决的问题。感兴趣的读者可以查看[`github.com/deeplearning4j/deeplearning4j/issues/1737`](https://github.com/deeplearning4j/deeplearning4j/issues/1737)来了解当前的更新情况。然而，讨论的热度不是很高。

**问题 2 的答案**：据我所知，DL4J 中没有 CapsNet 的实现。而且，我没有看到这个话题有任何公开的讨论或问题。我在 DL4J Gitter 频道提问了，但没有人回复。

**问题 3 的答案**：无监督预训练和有监督微调都可以使用 DBN 来进行。这意味着，如果我们没有足够的标记数据，但仍然希望进行基于神经网络的训练，这种概率网络是一个明智的选择。

**问题 4 的答案**：是的，使用变分自编码器和重建概率进行异常检测的示例已经有了，适用于 MNIST 数据。可以查看 DL4J 示例：[`github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection`](https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/java/org/deeplearning4j/examples/unsupervised/anomalydetection)。不过，这个示例也可以扩展到其他数据集。

**问题 5 的答案**：这个链接中有一个推荐引擎的实例，适用于 Well-Dressed 推荐：[`deeplearning4j.org/welldressed-recommendation-engine`](https://deeplearning4j.org/welldressed-recommendation-engine)。

**问题 6 的答案**：深度学习和神经网络也可以部署在 Android 设备上。更多信息，请参考[`deeplearning4j.org/android`](https://deeplearning4j.org/android)。

**问题 7 的答案**：一旦神经网络训练完成，网络就可以用于推理，或者说是对它看到的数据进行预测。推理过程通常计算量较小。然后，可以使用 Spring Boot 或其他框架将应用打包成一个网页应用。可以参考一些指南：[`deeplearning4j.org/build_vgg_webapp`](https://deeplearning4j.org/build_vgg_webapp)。

**问题 8 的答案**：你应该按照我在章节中提供的指示操作。此外，本书的代码可以在 GitHub 上找到，你可以自由提交 PR 或创建新的问题，我会尽快修复它们。关于任何新的问题，你可以通过 DL4J Gitter 实时频道提出：[`gitter.im/deeplearning4j/deeplearning4j`](https://gitter.im/deeplearning4j/deeplearning4j)。
