前言

多年来，那些一直在忠实从事机器学习工作的人们见证了这一领域的成长与繁荣，带来了惊人的技术成果，甚至可能引发彻底的社会变革。然而，对于那些希望加入我们并研究这一领域的人来说，这可能看起来有些令人望而生畏。当然，网上有大量的内容，而且越来越难以在各种论文和代码中找到可靠的入门资料，尤其是对于那些希望加入深度学习领域的人来说。虽然有许多关于机器学习的入门书籍，但大多数书籍未能有效地满足那些特别希望从事深度学习工作并且具备最低限度的数学、算法和编程技能的人的需求。

本书旨在帮助那些初学深度学习的人，建立使用公认方法构建深度学习模型所需的基础知识。如果这听起来像是你需要的内容，那么本书或许正是你所需要的。这本书假设读者没有神经网络和深度学习的广泛经验，从复习深度学习所需的机器学习基础开始。然后，本书解释如何通过清洗和预处理数据为深度学习做好准备，并逐步介绍神经网络及流行的监督神经网络架构，如**卷积神经网络**（**CNNs**）、**递归神经网络**（**RNNs**）和**生成对抗网络**（**GANs**），以及无监督架构，如**自编码器**（**AEs**）、**变分自编码器**（**VAEs**）和**限制玻尔兹曼机**（**RBMs**）。每章结束时，你将有机会测试自己对概念的理解并反思自己的成长。

本书结束时，你将理解深度学习的概念和方法，并能够区分哪些算法适合不同的任务。

# 第一章：适合人群

本书面向有志成为数据科学家和深度学习工程师的人，旨在帮助他们从深度学习和神经网络的基本原理入手。现在，关于要求：

+   不需要事先接触过深度学习或机器学习，但有基础的人会更好。

+   只需要对线性代数和 Python 编程有一定的了解，就可以开始。

本书适合那些珍惜自己时间的人，他们想要直接进入重点，学习实现*目标*所需的深度学习方法。

如果你不懂基础，深度学习可能会让人感到害怕。许多人因为跟不上术语或示例程序而感到沮丧。这导致他们在选择深度学习算法时做出错误的决策，并使他们无法预见这些选择的后果。因此，本书适合那些：

+   重视对深度学习概念的良好定义

+   想要一个有结构的方法从零开始学习深度学习

+   渴望了解基本概念并真正理解它们

+   想了解如何预处理数据，以便用于深度学习算法

+   对一些高级深度学习算法感到好奇

有关各章内容的详细信息，请阅读下一节。

# 本书所涵盖的内容

第一章，*机器学习简介*，概述了机器学习。它介绍了机器学习背后的动机以及该领域常用的术语。它还介绍了深度学习及其在人工智能领域中的位置。

第二章，*深度学习框架的设置与介绍*，帮助你设置 TensorFlow 和 Keras，并介绍它们在深度学习中的用途和目的。本章还简要介绍了其他深度学习库，让你对它们有一些初步了解。

第三章，*数据准备*，介绍了数据处理的主要概念，使其在深度学习中能够发挥作用。它将涵盖格式化分类数据或实值数据的输入和输出的基本概念，并探索数据增强或降维技术。

第四章，*从数据中学习*，介绍了深度学习理论的最基本概念，包括回归和分类中的性能测量，以及过拟合的识别。它还提出了一些关于优化超参数的警告。

第五章，*训练单个神经元*，介绍了神经元的概念，并将其与感知器模型连接，后者以简单的方式从数据中学习。感知器模型是理解基本神经模型的关键，这些模型从数据中学习。它还揭示了非线性可分数据的问题。

第六章，*训练多层神经元*，使你面对使用多层感知机算法进行深度学习的首次挑战，如用于误差最小化的梯度下降技术，以及通过超参数优化来实现泛化。

第七章，*自编码器*，通过解释编码层和解码层的必要性来描述自编码器模型。它探讨了与自编码器问题相关的损失函数，并将其应用于降维问题和数据可视化。

第八章，*深度自编码器*，介绍了深度信念网络的概念及其在深度无监督学习中的重要性。通过引入深度自编码器并与浅层自编码器进行对比，解释了这些概念。

第九章，*变分自编码器*，介绍了无监督深度学习领域生成模型的理念及其在生成抗噪声模型中的重要性。该章节将变分自编码器（VAE）呈现为处理扰动数据时比深度自编码器（AE）更好的选择。

第十章，*限制玻尔兹曼机*，通过介绍 RBMs，补充了本书对深度信念模型的覆盖。章节介绍了 RBMs 的前向-反向性质，并将其与仅前向传播的自编码器（AEs）进行对比。该章节通过减少数据维度的视觉表示来比较 RBMs 和 AEs 在这一问题上的表现。

第十一章，*深度与宽度神经网络*，解释了深度神经网络与宽度神经网络在性能和复杂性上的区别。章节介绍了稠密网络和稀疏网络的概念，重点讨论神经元之间的连接方式。

第十二章，*卷积神经网络*，介绍了卷积神经网络（CNNs），从卷积操作开始，接着介绍了通过多个卷积层组合的方式来学习作用于数据的过滤器。章节最后展示了如何可视化所学习到的过滤器。

第十三章，*递归神经网络*，介绍了递归网络的最基本概念，揭示了它们的不足之处，从而说明了长短期记忆模型的存在和成功。该章节探讨了顺序模型，并展示了其在图像处理和自然语言处理中的应用。

第十四章，*生成对抗网络*，介绍了生成对抗网络（GANs）的半监督学习方法，GANs 属于对抗学习家族。章节解释了生成器和判别器的概念，并讲解了为何对训练数据分布的良好近似能够促使模型在例如从随机噪声生成数据时取得成功。

第十五章，*深度学习的未来展望*，简要介绍了深度学习中令人兴奋的新主题和机会。如果你希望继续学习，这里会提供来自 Packt 出版的一些其他资源，帮助你在这个领域继续前进。

# 为了最大限度地利用本书

你需要确保你有一个互联网浏览器，并能访问 Google Colabs，网址是：[`colab.research.google.com/`](http://colab.research.google.com/)。

尽管本书假设读者没有深度学习或机器学习的基础，但你需要对线性代数和 Python 编程有一定的了解，才能最大程度地利用本书。

为确保与未来发布的 Python 机器学习和深度学习库兼容，我们在本书的代码包和 GitHub 仓库中包含了通过`!pip freeze`命令生成的当前版本列表；然而，这些仅供参考和未来兼容性使用——请记住，Google Colabs 已经配置好了所有必要的环境。

我们的丰富书籍和视频目录中还有其他代码包可供下载，访问 **[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)**。快去看看吧！再次提醒，库列表仅供参考，但 Google Colabs 已经包含了最新的设置。

**如果你使用的是本书的数字版本，我们建议你手动输入代码，或通过 GitHub 仓库访问代码（下节会提供链接）。这样可以避免因复制和粘贴代码而产生的潜在错误。**

当你完成本书的学习旅程时，庆祝一下，并仔细阅读本书的最后一章，它将为你指引新的方向。记住，保持持续学习是成功的关键之一。

## 下载示例代码文件

你可以从你在[www.packt.com](http://www.packt.com)的账户中下载本书的示例代码文件。如果你是从其他地方购买的本书，可以访问[www.packtpub.com/support](https://www.packtpub.com/support)，注册后将文件直接通过邮件发送给你。

你可以按照以下步骤下载代码文件：

1.  登录或注册账户，访问[www.packt.com](http://www.packt.com)。

1.  选择“支持”选项卡。

1.  点击代码下载。

1.  在搜索框中输入书名，并按照屏幕上的指示操作。

文件下载后，请确保使用最新版本的工具解压或提取文件夹：

+   WinRAR/7-Zip for Windows

+   Zipeg/iZip/UnRarX for Mac

+   7-Zip/PeaZip for Linux

本书的代码包也托管在 GitHub 上，链接为 [`github.com/PacktPublishing/Deep-Learning-for-Beginners`](https://github.com/PacktPublishing/Deep-Learning-for-Beginners)。如果代码有更新，将会在现有的 GitHub 仓库中更新。

## 下载彩色图像

我们还提供了一个 PDF 文件，包含本书中使用的截图/图表的彩色图像。你可以在这里下载： [`static.packt-cdn.com/downloads/9781838640859_ColorImages.pdf`](https://static.packt-cdn.com/downloads/9781838640859_ColorImages.pdf)。

## 使用的规范

本书中使用了若干文本规范。

`CodeInText`：指示文本中的代码词语、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。例如：“`predict()`方法在潜在编码器模型、`latent_ncdr`和`autoencoder`模型中产生指定层的输出。”

代码块的设置如下：

```py
x = np.array([[1., 1., 0., 1., 1., 0., 0., 0.]]) #216

encdd = latent_ncdr.predict(x)
x_hat = autoencoder.predict(x)

print(encdd)
print(x_hat)
print(np.mean(np.square(x-x_hat))) 
```

当我们希望您注意代码块的特定部分时，相关行或项目将加粗显示：

```py
import matplotlib.pyplot as plt

plt.plot(hist.history['loss'])
plt.title('Model reconstruction loss')
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.show()
```

任何命令行输入或输出如下所示：

```py
$ pip install tensorflow-gpu
```

**粗体**：表示新术语、重要词汇或您在屏幕上看到的词汇。例如，菜单或对话框中的词汇会以这种方式显示在文本中。这里是一个例子：“第一个重要的事情是一个叫做 **双曲正切** 的新激活函数。”

警告或重要说明将以这种方式出现。

提示和技巧如下所示。

# 联系我们

我们欢迎读者的反馈。

**一般反馈**：如果您对本书的任何部分有疑问，请在邮件主题中注明书名，并通过 `customercare@packtpub.com` 与我们联系。

**勘误**：虽然我们已尽一切努力确保内容的准确性，但错误仍然可能发生。如果您在本书中发现错误，我们将不胜感激，如果您能将此问题报告给我们。请访问 [www.packtpub.com/support/errata](https://www.packtpub.com/support/errata)，选择您的书籍，点击勘误提交表格链接，并填写相关信息。

**盗版**：如果您在互联网上发现任何形式的非法复制作品，我们将不胜感激，如果您能提供该作品的位置地址或网站名称。请通过 `copyright@packt.com` 与我们联系，并提供相关链接。

**如果您有兴趣成为作者**：如果您在某个领域有专业知识并且有兴趣撰写或参与编写书籍，请访问 [authors.packtpub.com](http://authors.packtpub.com/)。

## 书评

请留下评论。当您阅读并使用完本书后，为什么不在您购买本书的网站上留下评论呢？潜在读者可以看到并使用您的公正意见来做出购买决定，我们也能了解您对我们产品的看法，作者们也能看到您对他们书籍的反馈。感谢您！

如需了解更多关于 Packt 的信息，请访问 [packt.com](http://www.packt.com/)。
