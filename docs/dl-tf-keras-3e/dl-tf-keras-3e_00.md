# 前言

*深度学习与 TensorFlow 和 Keras，第 3 版* 是一本简明而全面的现代神经网络、人工智能和深度学习技术的介绍，专为软件工程师和数据科学家设计。本书是之前由同一作者编写的 *深度学习与 Keras* [1] 和 *TensorFlow 1.x 深度学习实用手册* [2] 的自然延续。

本书提供了过去六年间学习技术演变的非常详细的全景图。书中展示了使用 TensorFlow 2.x 编写的几十个深度神经网络，这是一种基于 Keras 风格 API 的模块化网络库 [1]。

**人工智能**（**AI**）为本书讨论的所有内容奠定了基础。**机器学习**（**ML**）是人工智能的一个分支，而**深度学习**（**DL**）又是机器学习的一个子集。本节将简要讨论这三个概念，您将在本书的其余部分中经常遇到它们。

人工智能指的是机器模仿通常由人类展示的智能行为的任何活动。更正式地说，它是一个研究领域，旨在让机器复制认知能力，如学习行为、与环境的主动互动、推理和推断、计算机视觉、语音识别、问题解决、知识表示和感知。人工智能建立在计算机科学、数学、统计学，以及心理学和其他研究人类行为的科学的基础上。构建人工智能有多种策略。在 20 世纪 70 年代和 80 年代，“专家”系统变得非常流行。这些系统的目标是通过使用大量手动定义的“如果-那么”规则来表示知识，进而解决复杂问题。这种方法在特定领域的小问题中有效，但无法扩展到更大规模的问题和多个领域。后来，人工智能越来越多地转向基于统计方法的机器学习方法。

机器学习（ML）是人工智能的一个子学科，专注于教会计算机如何学习，而无需为特定任务编写程序。机器学习背后的核心理念是，可以创建从数据中学习并进行预测的算法。机器学习有三种不同的广泛类别：

+   **监督学习**，其中机器会接收输入数据和期望的输出，目标是从这些训练样本中学习，以便对机器从未见过的数据做出有意义的预测。

+   **无监督学习**，其中机器只接收输入数据，机器随后必须自己找到某些有意义的结构，没有外部监督或输入。

+   **强化学习**，在这种学习方式中，机器作为一个代理与环境进行交互。机器会根据预期的行为给予“奖励”，而不期望的行为则会受到“惩罚”。机器通过学习如何调整自己的行为来最大化奖励。

深度学习在 2012 年席卷全球。那一年，ImageNet 2012 挑战赛启动，目标是通过一个大型人工标注数据集的子集来预测照片的内容。一种名为 AlexNet 的深度学习模型在此挑战中达到了 15.3%的 Top-5 错误率，相比之前的最新技术成果取得了显著提升。据《经济学人》报道，*突然间，人们开始关注这个领域，不仅仅是人工智能社区，整个技术行业都开始关注它*。

这仅仅是个开始。今天，深度学习技术已经成功应用于众多不同的领域，包括但不限于医疗、环境、绿色能源、计算机视觉、文本分析、多媒体、金融、零售、游戏、模拟、工业、机器人和自动驾驶汽车。在这些领域中，深度学习技术能够解决的问题，准确度远超过以往的方法。

回顾过去的八年，深度学习（DL）对科学和工业的贡献令人着迷且振奋人心。没有理由相信接下来的八年里，深度学习的贡献会减少；事实上，随着深度学习领域的不断进步，我们预期会看到深度学习带来更多令人兴奋和迷人的贡献。

本书将带你进入深度学习的魔力世界。我们将从简单的模型开始，逐步介绍越来越复杂的模型。整个过程将始终以实践为主，配以适量的代码供你操作。

# 本书适合人群

如果你是一个有机器学习经验的数据科学家，或是一个接触过神经网络的人工智能程序员，那么你会发现本书是一个很好的深度学习入门书籍。如果你是一个对深度学习浪潮日益感兴趣的软件工程师，本书将为你提供一个扎实的基础，帮助你拓宽相关知识。阅读本书需要具备一定的 Python 基础。

# 本书内容涵盖

*第一章*，*使用 TensorFlow 的神经网络基础*，我们将在这里学习 TensorFlow 的基础知识，这是 Google 为机器学习和深度学习开发的开源库。此外，我们还将介绍神经网络和深度学习的基础知识，这两者是近几年在机器学习领域取得巨大进展的方向。本章的目标是提供进行基础但完全实践的深度学习所需的所有工具。

*第二章*，*回归与分类*，集中讲解机器学习技术中的基本任务：回归和分类。我们将学习如何使用 TensorFlow 构建简单的单变量、多变量回归模型。我们还将使用逻辑回归解决多类别分类问题。

*第三章*，*卷积神经网络*，讲解了如何使用深度学习卷积神经网络（ConvNets）高精度地识别 MNIST 手写字符。我们使用 CIFAR 10 数据集构建一个包含 10 个类别的深度学习分类器，并使用 ImageNet 数据集构建一个包含 1,000 个类别的高精度分类器。此外，我们还研究了如何使用大型深度学习网络，如 VGG16，以及非常深的网络，如 InceptionV3。最后，我们将讨论迁移学习。

*第四章*，*词向量*，描述了分布式表示和词向量的起源与理论，并描绘了从静态的基于词的词向量到更动态且富有表现力的基于句子和段落的词向量的进展。我们还探讨了如何将词向量的理念扩展到包括非词序列，例如图中的节点或 Web 应用中的用户会话。本章还包含了多种类型的词向量使用示例。

*第五章*，*递归神经网络*，描述了一个重要的神经网络架构子类，专门用于处理序列数据，如自然语言或时间序列。我们将介绍该领域的重要架构，例如**LSTM**（**长短期记忆网络**）和**GRU**（**门控递归单元**），并展示如何将它们扩展以处理双向状态和跨批次的状态。我们还提供了使用不同拓扑结构的 RNN 的示例，用于特定任务，如文本生成、情感分析和词性标注。我们还描述了流行的 seq2seq 架构，该架构使用一对 RNN 在编码器-解码器管道中解决多种 NLP 任务。

*第六章*，*变压器*，讲解了变压器，这是一种深度学习架构，彻底改变了传统的自然语言处理领域。我们首先回顾了该架构背后的关键直觉和各种变压器类别，并深入分析最流行的模型。接着，我们重点讨论了基于原始架构和流行库（如 Hugging Face 和 TensorFlow Hub）的实现。之后，我们简要讨论了评估、优化以及使用变压器时常见的最佳实践。最后一部分专门讨论了如何将变压器应用于计算机视觉任务，这是一个与 NLP 完全不同的领域，这需要仔细定义注意力机制。最终，注意力就是你所需要的！而在注意力的核心，除了向量之间的余弦相似度，别无他物。

*第七章*，*无监督学习*，深入探讨无监督学习模型。将涵盖聚类和降维所需的技术，如 PCA、k-means 和自组织映射。还将详细讲解玻尔兹曼机及其在 TensorFlow 中的实现。所涵盖的概念将进一步扩展，构建**限制玻尔兹曼机**（**RBMs**）。

*第八章*，*自编码器*，描述了自编码器，这是一类神经网络，试图将输入重建为目标。将介绍不同种类的自编码器，如稀疏自编码器、卷积自编码器和去噪自编码器。该章将训练一个去噪自编码器，从输入图像中去除噪声。将演示如何使用自编码器创建 MNIST 数字。还将介绍构建 LSTM 自编码器以生成句子向量的步骤。最后，我们将学习如何构建变分自编码器来生成图像。

*第九章*，*生成模型*，聚焦于**生成对抗网络**（**GANs**）。我们从第一个提出的 GAN 模型开始，利用它生成 MNIST 字符。该章展示了如何使用深度卷积 GAN 创建名人图像。还讨论了各种 GAN 架构，如 SRGAN、InfoGAN 和 CycleGAN。该章介绍了各种有趣的 GAN 应用。最后，章节以 TensorFlow 实现的 CycleGAN 来转换冬夏图像作结。

*第十章*，*自监督学习*，概述了在计算机视觉、音频和自然语言处理领域中用于自监督学习的各种策略。涵盖了通过自回归生成、掩码生成、关系预测等策略进行自预测，及其混合方法。还将介绍对比学习，这是一种流行的自监督学习技术，并将其应用于各种预设任务中的不同领域。

*第十一章*，*强化学习*，聚焦于强化学习，涵盖 Q 学习算法和贝尔曼方程。该章讨论了折扣奖励、探索与开发、以及折扣因子。它解释了基于策略和基于模型的强化学习。我们将构建**深度 Q 学习网络**（**DQN**）来玩 Atari 游戏。最后，我们将学习如何使用策略梯度算法训练智能体。

*第十二章*，*概率 TensorFlow*，介绍了 TensorFlow Probability，这是一个建立在 TensorFlow 之上的库，用于执行概率推理和统计分析。该章演示了如何使用 TensorFlow Probability 生成合成数据。我们将构建贝叶斯网络并进行推理。该章还介绍了不确定性、偶然性和认知不确定性的概念，并讲解如何计算训练模型的不确定性。

*第十三章*，*AutoML 简介*，介绍了 AutoML，其目标是让那些不熟悉机器学习技术的领域专家也能轻松使用 ML 技术。我们将在简要讨论基础知识后，进行一个使用 Google Cloud Platform 的实操练习，并做大量的动手操作。该章节涵盖了自动数据准备、自动特征工程和自动模型生成。然后，我们将介绍 AutoKeras 和 Google Cloud AutoML，它提供了多种针对表格、视觉、文本、翻译和视频处理的解决方案。

*第十四章*，*深度学习背后的数学*，讲解了深度学习背后的数学原理。这个话题相当高级，并不一定是从业者所必需的。然而，作为了解我们在操作神经网络时“引擎盖下”发生了什么的推荐阅读，它非常重要。我们从历史背景介绍开始，然后复习高中时学过的导数和梯度的概念，并介绍梯度下降法和反向传播算法，这两种通常用于优化深度学习网络的算法。

*第十五章*，*张量处理单元*，讨论了 TPU。TPU 是 Google 开发的专用 ASIC 芯片，用于以超快的速度执行神经网络的数学运算。其计算核心是一个流水线乘法器，可以并行计算多个点积（行 * 列），从而加速基本深度学习操作的计算。可以把 TPU 看作是专门用于深度学习的协处理器，专注于矩阵或张量运算。我们将回顾迄今为止的四代 TPU，以及针对物联网的 Edge TPU。

*第十六章*，*其他有用的深度学习库*，介绍了其他深度学习框架。我们将探索 Hugging Face、OpenAI 的 GPT-3 和 DALL-E 2。该章节还介绍了另一种非常流行的深度学习框架——PyTorch。我们还会讨论 H2O.ai 及其 AutoML 模块。章节最后简要讨论了 ONNX 深度学习模型的开源格式。

*第十七章*，*图神经网络*，介绍了图和图机器学习，特别强调了图神经网络和流行的**深度图库**（**DGL**）。我们描述了在图神经网络中常用的各种图层的理论（以及 DGL 中可用的图层），并提供了用于节点分类、链接预测和图分类的 GNN 示例。我们还展示了如何使用自己的图数据集并定制图层来创建新的 GNN 架构。接着，我们将讨论图机器学习领域的一些前沿进展，例如异构图和时序图。

*第十八章*，*机器学习最佳实践*，关注在训练和生产过程中获取最佳模型的策略和实践。该章节从两个不同的角度讨论最佳实践：数据最佳实践和模型最佳实践。

*第十九章*，*TensorFlow 2 生态系统*，介绍了 TensorFlow 生态系统的不同组件。我们介绍了 TensorFlow Hub，这是一个用于预训练深度学习模型的仓库。章节还讨论了 TensorFlow Datasets —— 一个现成数据集的集合。我们还将讨论 TensorFlow Lite 和 TensorFlow JS —— 针对移动和嵌入式系统以及 Web 的框架。最后，本章介绍了联邦学习，一种去中心化的机器学习框架。

*第二十章*，*高级卷积神经网络*，展示了**卷积神经网络**（**CNNs**）的更多高级应用。我们将探索如何在计算机视觉、视频、文本文档、音频和音乐等领域应用 CNN。最后，我们将总结卷积操作的部分内容。

## 下载示例代码文件

本书的代码包托管在 GitHub 上，地址为[`packt.link/dltf`](https://packt.link/dltf)。我们还有来自丰富书籍和视频目录的其他代码包，您可以在[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)找到。快来看看吧！

## 下载彩色图像

我们还提供了一个 PDF 文件，包含本书中使用的截图/图表的彩色图像。您可以在此下载：[`static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf`](https://static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf)。

## 使用的约定

本书中使用了多种文本约定。

`CodeInText`：表示文本中的代码词汇、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。例如：“每个神经元都可以通过`'kernel_initializer'`参数初始化特定的权重。”

一块代码设置如下：

```py
# Build the model.
model = tf.keras.models.Sequential()
model.add(keras.layers.Dense(NB_CLASSES,
            input_shape=(RESHAPED,),
            name='dense_layer', 
            activation='softmax')) 
```

当我们希望引起您对代码块中特定部分的注意时，相关的行或项将被突出显示：

```py
# Build the model.
model = tf.keras.models.Sequential()
model.add(keras.layers.Dense(NB_CLASSES,
            input_shape=(RESHAPED,),
            **name=****'****dense_layer'****,** 
            **activation=****'softmax'****))** 
```

任何命令行输入或输出如下所示：

```py
pip install gym 
```

**粗体**：表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词会以这种方式出现在文本中。例如：“一个**深度卷积神经网络**（**DCNN**）由多个神经网络层组成。”

警告或重要提示如下所示。

提示和技巧如下所示。

# 联系我们

我们始终欢迎读者的反馈。

**一般反馈**：请发送电子邮件至`feedback@packtpub.com`，并在邮件主题中注明书名。如果您对本书的任何内容有疑问，请通过`questions@packtpub.com`与我们联系。

**勘误表**：尽管我们已尽最大努力确保内容的准确性，但错误仍然会发生。如果您在本书中发现了错误，我们将非常感激您向我们报告。请访问[`www.packtpub.com/submit-errata`](http://www.packtpub.com/submit-errata)，点击**提交勘误**，并填写表单。

**盗版**：如果你在互联网上发现我们作品的任何非法复制品，请提供相关地址或网站名称。请通过 `copyright@packtpub.com` 与我们联系，并附上材料的链接。

**如果你有兴趣成为作者**：如果你在某个领域有专长，并且有兴趣写书或为书籍贡献内容，请访问 [`authors.packtpub.com`](http://authors.packtpub.com)。

# 参考文献

1.  *《用 Keras 深度学习：用 Python 的强大功能实现深度学习模型和神经网络》*，平装本 – 2017 年 4 月 26 日，安东尼奥·古利，苏吉特·帕尔

1.  *《TensorFlow 1.x 深度学习宝典》*：*通过 Python 解决人工智能驱动问题的 90 多个独特实例*，安东尼奥·古利，阿米塔·卡普尔

# 分享你的想法

阅读完 *《用 TensorFlow 和 Keras 深度学习，第三版》* 后，我们很想听听你的想法！请 [点击这里直接访问亚马逊评论页面](https://packt.link/r/1803232919) 并分享你的反馈。

你的评论对我们和技术社区都很重要，它将帮助我们确保提供优质的内容。
