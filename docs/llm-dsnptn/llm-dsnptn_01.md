

# 第一章：LLM 设计模式简介

**大型语言模型**（LLMs）是能够理解和生成类似人类文本的机器学习模型，涵盖多个领域。它们开辟了前所未有的可能性，同时也带来了独特的挑战。

在本章中，我们将介绍 LLMs 的世界以及**设计模式**在它们发展中的关键作用。您将了解语言模型的演变，探索推动现代 LLMs 的核心原则，并检查它们的惊人能力和局限性。我们将揭示设计模式的重要性——经过时间考验的软件开发中常见问题的解决方案——以及它们如何被调整和应用来解决 LLM 项目特有的挑战。

在本章中，我们将涵盖以下主题：

+   理解 LLMs

+   理解设计模式

+   LLM 开发的设计模式

+   LLM 模式及其发展的未来方向

# 理解 LLMs

在本节中，我们将突出 LLMs 的核心概念，探讨它们的演变、潜在原则以及它们对人工智能领域产生的变革性影响。我们将检查构成 LLMs 那么强大的关键组件，它们所提出的挑战，以及塑造它们未来的持续发展。

## 语言模型的发展

现代 LLMs 的旅程被自然语言处理中的重大范式转变所标记，如图 *图 1**.1* 所示的时间线所示：

![图 1.1 – 语言模型演变](img/B31249_01_01.jpg)

图 1.1 – 语言模型演变

尽管早期的统计方法具有开创性，但在捕捉人类语言细微差别方面存在局限性。**神经网络**的出现，尤其是**循环神经网络**（RNNs）和**长短期记忆**（LSTM）网络，使得处理序列数据的能力得到提升，并改善了捕捉文本中长期依赖关系的能力。在文本中捕捉长期依赖关系对于理解更广泛的上下文和保持长段落的一致性至关重要。由于无法考虑跨越长序列的单词或概念之间的关系，早期的统计方法在这方面遇到了困难。神经网络的发展，尤其是 RNNs 和 LSTM 网络，显著提高了捕捉这些依赖关系的能力。然而，即使有了这些进步，仅仅捕捉长期依赖关系是不够的；这些模型在管理复杂上下文和确保长文本序列的一致性方面仍然面临挑战。

2017 年，**变换器架构**的引入彻底改变了该领域，为更大、更强大的语言模型铺平了道路。（关于变换器架构的更多内容，请参阅下一节。）这一突破迎来了预训练模型如**BERT**和**GPT**系列的时代，它们利用大量未标记的文本数据，在各种自然语言处理（NLP）任务上实现了前所未有的性能。

注意

想要全面了解语言模型的发展历程，包括对统计模型、神经网络和基于变换器方法的详细讨论，请参阅丹·朱尔法斯基（Dan Jurafsky）和詹姆斯·H·马丁（James H. Martin）合著的书籍《语音与语言处理》（Speech and Language Processing）。在线手稿经常更新，可在[`web.stanford.edu/~jurafsky/slp3`](https://web.stanford.edu/~jurafsky/slp3)找到。

## LLM 的核心特性

本节介绍了 LLM 的核心特性，重点关注其变换器架构、规模、少样本学习、语言理解和生成以及多语言能力。

### 变换器架构

任何大型语言模型（LLM）的关键组成部分是其**变换器架构**。变换器架构利用**自注意力机制**，允许模型在处理每个元素时，根据输入的不同部分的重要性进行加权。在基于变换器的 LLM 中，输入文本首先被标记化为更小的单元，通常是单词或子词。然后，这些标记被嵌入到一个高维向量空间中，其中每个标记都表示为一个密集向量。

稠密向量是一种数学对象，在包括人工智能在内的多个领域中使用，用于在紧凑、高维空间中表示数据。简单来说，它是一系列数字（或值），当结合在一起时，形成对某物（如单词、图像或其他类型的数据）的表示。向量中的这些数字可以被视为多维空间中的坐标，其中每个数字都对数据点的描述做出贡献。

自注意力机制作用于这些向量表示，允许模型捕捉输入序列中不同部分之间的复杂关系。这是通过计算序列中每对标记之间的注意力分数来实现的。这些分数决定了每个标记在计算其上下文表示时应该关注其他每个标记的程度。这允许模型捕捉文本中的长距离依赖和复杂关系，克服了先前顺序模型的局限性（*Attention Is All You Need*，[`arxiv.org/abs/1706.03762`](https://arxiv.org/abs/1706.03762)）。

Transformer 架构由多层自注意力机制和前馈神经网络组成。每一层都细化了输入标记的表示，捕捉越来越抽象和上下文相关的信息。**多头注意力机制**是 Transformer 的另一个关键组件，它允许模型同时关注输入的不同方面，进一步增强了其捕捉数据中复杂模式的能力。

Transformer 中的多头注意力是一种机制，允许模型同时关注输入序列的不同位置，以实现更好的表示学习。模型不是执行单个注意力函数，而是将查询、键和值投影到多个低维空间（头），在每个这些空间中独立执行注意力操作，然后在对这些结果进行最终线性变换之前将它们连接起来。这种方法使得模型能够同时关注来自不同表示子空间和位置的信息，捕捉序列元素之间关系的各个方面——如句法依赖、语义相似性或上下文相关性——这显著增强了模型理解数据中的复杂模式和关系的能力。

### 规模和计算资源

LLMs 的一个显著特征是其前所未有的规模，这既体现在模型大小上，也体现在它们训练所使用的数据量上。在 LLMs 中，“大”不仅指这些模型的复杂性，还包括训练和运行它们所需的庞大计算资源。现代 LLMs 可以拥有数百亿个参数，这需要巨大的内存和处理能力。

模型大小和训练数据的这种扩展是由对各种任务性能持续改进的实证观察所驱动的，随着模型变得更大，这些改进通常遵循可预测的扩展定律，其中性能指标如困惑度或准确度随着模型大小和计算预算的**幂律**函数而提高（参见《神经语言模型的扩展定律》[`arxiv.org/pdf/2001.08361`](https://arxiv.org/pdf/2001.08361)）。这一现象导致了一场构建更大模型的竞赛，一些最近的 LLMs 甚至拥有万亿个参数。

### 少样本学习能力

LLMs 的**少样本学习能力**代表了自然语言处理领域的一项进步。传统的机器学习方法通常需要为每个特定任务收集大量标记数据。相比之下，LLMs 通常只需要几个示例或甚至仅需要任务的天然语言描述（**零样本学习**）就能执行新任务。这种灵活性源于模型对语言的广泛理解以及它们在不同上下文中泛化模式的能力。

例如，一个预训练的 LLM 可能能够在没有明确进行情感分析训练的情况下，通过提供一些正面和负面评论的例子，对产品评论进行情感分析。这种能力为将 AI 应用于广泛的语言任务开辟了新的可能性，尤其是在那些没有大量特定任务标记数据的领域。

### 语言理解和生成

LLMs 最引人注目的能力之一是它们理解和生成类似人类文本的能力，涵盖广泛的风格、主题和格式。在理解方面，这些模型能够处理和解释复杂的文本输入，以高度复杂的方式提取意义和上下文，在很多情况下模仿人类类似的理解。这种能力扩展到各种子任务，如情感分析、命名实体识别和主题分类。LLMs 通常能够辨别细微的语气差异，识别隐含信息，并识别复杂的语言模式。

在生成方面，LLMs 展示了前所未有的能力，能够生成连贯、上下文适当的文本。它们可以生成从创意小说和诗歌到技术文档和代码的一切内容。这种生成文本的质量通常表现出高度的流畅性、语法正确性和上下文相关性。这种生成能力为内容创作、自动写作辅助和对话式人工智能等领域开辟了新的可能性。

### 多语言和跨语言能力

许多现代大型语言模型（LLMs）展现出强大的多语言和跨语言能力。当在多样化的多语言语料库上训练时，这些模型能够理解和生成多种语言中的文本。一些模型已经展示了执行跨语言任务的能力，例如在它们没有明确训练的语言对之间进行翻译，或者根据另一语言中提供的内容来回答问题。

这些能力为打破语言障碍和促进更具包容性的全球沟通开辟了可能性。然而，需要注意的是，LLMs 在不同语言上的性能可能会有很大差异。模型在它们训练数据中表现最好的通常是那些广泛使用的语言，这通常有利于英语等广泛使用的语言。目前正在努力开发更公平的多语言模型，并提高在低资源语言上的性能。

经过对 LLM 的核心特征进行考察，下一节将转向设计模式在 LLM 项目结构和指导中的作用。设计模式源于软件工程，提供了可重用的解决方案，有助于管理复杂性、提高协作，并支持可扩展、可维护的架构。理解它们的演变和原则为在 LLM 开发背景下有效地应用它们奠定了基础。

# 理解设计模式

设计模式最初作为一种捕捉和共享重复性设计问题解决方案的方法而出现。最初根植于面向对象编程，它们通过识别增强代码清晰度、可重用性和可维护性的可重复策略，提供了一种构建软件的结构化方法。随着时间的推移，设计模式已经超越了其原始的背景，影响了包括 LLM 开发在内的广泛开发实践和系统架构。以下讨论将追溯设计模式的起源，并概述塑造它们在不同编程范式和应用领域持续相关性的原则。

## 起源和演变

软件工程中的设计模式概念在 20 世纪 90 年代获得了显著的关注，这主要归功于 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 合著的书籍《设计模式：可重用面向对象软件元素》，通常被称为**四人帮**。这部开创性的工作识别并编目了面向对象软件设计中的常见模式，提供了一种词汇和最佳实践集合，这些很快成为该领域的基石([`books.google.com/books/about/Design_Patterns.html?id=6oHuKQe3TjQC`](https://books.google.com/books/about/Design_Patterns.html?id=6oHuKQe3TjQC))。

这些模式源于软件开发者的集体经验，代表了在各种项目和环境中证明有效的解决方案。它们提供了一种高效地捕捉和传达复杂设计思想的方法，使开发者能够建立在前辈的智慧之上，而不是重新发明解决重复问题的方案。

设计模式的概念最初专注于面向对象编程，但现在已经扩展到涵盖广泛的软件开发范式和领域。随着软件系统在复杂性和规模上的增长，设计模式的重要性也只增不减，提供了一种管理这种复杂性的手段，并促进更可维护、可扩展和稳健的软件架构。

## 设计模式的核心原则

在其核心，设计模式体现了几个关键原则，使它们在软件开发中具有价值。首先，它们促进了代码重用和模块化。通过封装常见问题的解决方案，模式允许开发者应用经过验证的方法，而无需重复代码或重新发明解决方案。这种模块化也增强了软件系统的可维护性，因为变化通常可以局部化到实现模式的特定组件。

第二，设计模式为开发者提供了一种共享的词汇。这种共同的语言促进了开发团队内部以及项目之间的沟通。当开发者使用一个广为人知的设计模式来描述解决方案时，它立即向熟悉该模式的其他开发者传达了大量关于该解决方案结构和行为的信息。

第三，模式通常体现了良好的软件设计原则，例如松散耦合和高内聚。它们鼓励开发者思考组件之间的关系以及他们系统的整体结构，从而产生更深思熟虑且结构良好的解决方案。

最后，设计模式通常是灵活和可适应的。虽然它们提供了一个解决问题的通用结构，但它们并不是僵化的规定。开发者可以——并且应该——根据项目的具体上下文和需求调整模式，以便在经过验证的框架内发挥创造力。

# LLM 开发的设计模式

随着开发基于智能 LLM 的应用需求增长，我们看到出现了专门针对这些复杂系统独特挑战的设计模式。这些模式与传统软件设计模式有显著差异，专注于 LLM 整个生命周期内在的方面——从数据准备和模型训练到评估、部署和复杂应用设计。

本书深入探讨了**29 个实用的 LLM 设计模式**，这些模式在*第二章*至*第三十章*中进行了详细探讨。开发者和研究人员可以使用这些设计模式来导航构建 LLM 系统的复杂性：

+   **建立坚实的数据基础（第二章至第六章）**：通过掌握数据清洗（第二章）、数据增强（第三章）、处理大型数据集（第四章）、实施数据版本控制（第五章）和确保有效的数据集标注（第六章）的模式来为高质量模型打下基础。这些实践提高了输入质量和可管理性，从而直接影响了模型性能。

+   **优化训练和模型效率（第 7-13 章）**：通过用于健壮**训练流程**(*第七章*)、有效的**超参数调整**(*第八章*)、**正则化**技术(*第九章*)、可靠的**检查点**(*第十章*)、特定任务的**微调**(*第十一章*)，以及通过**模型剪枝**(*第十二章*)和**量化**(*第十三章*)提高效率的模式，简化核心模型构建过程。

+   **解决模型质量和对齐问题（第 14-19 章）**：通过应用严格的**评估指标**(*第十四章*)和**交叉验证**(*第十五章*)建立对模型的信心，增强**可解释性**(*第十六章*)，积极解决**公平性和偏差**(*第十七章*)，提高**对抗鲁棒性**(*第十八章*)，并使用**从人类反馈中学习强化学习**(**RLHF**)(*第十九章*)将模型与人类偏好对齐。

+   **增强推理和解决问题的能力（第 20-25 章）**：通过高级提示和推理策略，如**思维链**(*第二十章*)、**思维树**(*第二十一章*)、**Reason and Act** (**ReAct**) **模式**(*第二十二章*)、**无需观察的推理**(*第二十三章*)、**反思**技术(*第二十四章*)，以及启用**自动多步推理和工具使用**(*第二十五章*)，解锁更复杂的模型行为。

+   **将外部知识与 RAG 集成（第 26-29 章）**：通过使用**检索增强生成**(**RAG**)(*第二十六章*)，探索如**基于图的 RAG**(*第二十七章*)和**高级 RAG 技术**(*第二十八章*)的变体，以及学习如何有效地**评估 RAG 系统**(*第二十九章*)。

+   **开发具有代理能力的 AI 应用(*第三十章*)**：通过理解和实现**代理模式**(*第三十章*)，朝着创建更独立的应用迈进，使大型语言模型能够自主规划、使用工具和执行任务。

## LLM 设计模式的益处

LLM 开发的设计模式提供了显著的好处，首先是从建立强大的数据基础开始。数据清洗确保了数据质量的提升，从而提高了模型精度，减少了训练时间，并减轻了偏差。数据增强增强了模型的鲁棒性和泛化能力，使得模型在未见过的数据上表现更佳，同时处理大数据集释放了捕捉复杂模式和提升模型能力潜力。数据版本控制使得实验和模型训练运行的可重复性成为可能，而数据集标注为监督学习任务提供了高质量的标签，提高了模型精度和效率。

此外，优化训练和模型效率提供了实质性的优势。鲁棒的训练流程自动化了训练过程，导致开发周期更快，性能更一致。超参数调整优化了模型性能，提高了精度和泛化能力，而正则化技术防止过拟合并提高了鲁棒性。可靠的检查点允许保存模型权重，便于实验和调试。针对特定任务的微调优化了预训练的 LLM 以适应特定任务，以少量资源提高性能。模型剪枝减少了 LLM 的大小和复杂性，导致推理更快，提高了部署效率，而量化进一步减少了模型大小并加快了推理速度，使得在边缘设备上部署成为可能。

解决模型质量和对齐问题对于构建可信赖的 LLM 至关重要。严格的评估指标提供了对模型性能的全面评估，使得决策更加明智。交叉验证提高了模型评估的可靠性，并提供了更准确的泛化性能估计。可解释性使得模型的决策过程更加透明和易于理解，而公平性和偏差缓解减少了模型预测中的偏差。对抗鲁棒性使得模型对对抗攻击更具抵抗力，提高了安全性，而强化学习与人类偏好对齐（RLHF）改善了用户满意度和信任度。

增强推理和解决问题的能力可以解锁更复杂的模型行为。思维链使模型能够分解复杂问题，提高推理和准确性。思维树通过允许模型探索多个推理路径来扩展思维链，增强复杂任务的解决问题的能力。ReAct 集成了推理和行动能力，使模型能够与环境交互并解决现实世界的问题。无观察推理允许模型在没有明确数据的情况下应用推理技能，而反思技术赋予模型评估自身推理过程并改进的能力。自动多步推理和工具使用自动化推理和工具使用的过程，使模型能够解决复杂任务。

最后，将外部知识整合到 RAG 中可以增强模型的知识和准确性。RAG 从外部来源检索相关信息，克服了模型预训练知识的局限性。基于图的 RAG 使用知识图谱来表示和检索信息，从而实现更复杂的推理。高级 RAG 技术进一步精炼 RAG 系统，并提高检索信息的质量、相关性和准确性。评估 RAG 系统涉及评估 RAG 系统性能的方法，从而实现优化和改进。使用代理模式可以创建自主的 AI 代理，这些代理可以独立地规划、使用工具和执行任务，从而带来更强大和通用的应用。

*表 1.1* 总结了 LLM 设计模式的优势，按类别组织。

| **类别** | **设计模式** | **关键优势** |
| --- | --- | --- |
| **数据基础** | 数据清洗 | 更高质量的见解；更准确的预测；更快的模型迭代；降低结果偏差。 |
|  | 数据增强 | 更可靠和可泛化的模型；在多种情况下的性能改进；对噪声数据的更强鲁棒性。 |
|  | 处理大型数据集 | 能够提取更深入的见解；更高的性能潜力；更广泛的应用范围；更健壮的模型。 |
|  | 数据版本控制 | 结果的信心增加；更容易调试和审计；降低数据损坏的风险；更快地从错误中恢复；改进数据驱动的决策。 |
|  | 数据集标注 | 更精确和有效的模型；更快的学习率；与预期结果的更好对齐。 |
| **训练** **和效率** | 强健的训练流程 | 更快的模型开发；更一致的结果；减少人工努力；更高的生产力。 |
|  | 超参数调整 | 优化模型性能；更高的准确性；更快的训练收敛速度；更有效的资源利用。 |
|  | 正则化技术 | 更稳定和可泛化的模型；降低过拟合的风险；在未见数据上的性能改进。 |
|  | 可靠的检查点 | 降低丢失进度的风险；加快实验速度；改进模型开发工作流程。 |
|  | 任务特定微调 | 显著提高目标任务的性能；缩短上市时间；更有效地使用资源。 |
|  | 模型剪枝 | 加快的推理速度；降低存储需求；降低计算成本；使资源受限设备上的部署成为可能。 |
|  | 量化 | 减少模型大小；加速推理；降低内存占用；提高能源效率；更广泛的部署可能性。 |
| **质量和对齐** | 严格的评估指标 | 数据驱动决策；改进模型选择；更好地理解模型的优势和劣势。 |
|  | 交叉验证 | 更可靠的性能估计；降低过拟合风险；提高模型泛化能力。 |
|  | 可解释性 | 增加对模型预测的信任；更容易识别错误；提高模型理解；便于调试和改进。 |
|  | 公平性和偏见缓解 | 更公平和道德的结果；降低歧视风险；提高用户信任。 |
|  | 对抗鲁棒性 | 提高安全性；在不可预测环境中的可靠性改善；抵御恶意攻击。 |
|  | 从人类反馈中进行强化学习 | 与人类价值观一致的模式；改善用户体验；提高安全性和可靠性。 |
| **推理和问题解决** | 思维链 | 增强问题解决能力；提高准确性；决策透明度增加。 |
|  | 思维树 | 提高处理复杂和模糊问题的能力；更稳健的解决方案。 |
|  | ReAct | 有效解决现实世界问题的能力；提高适应性；增强学习和推理。 |
|  | 无观察推理 | 在数据稀缺环境中的问题解决能力增强；在信息不完整的情况下改善决策。 |
|  | 反思技术 | 更自我意识和可靠的模型；提高准确性；增强学习和适应能力。 |
|  | 自动多步推理 | 能够自主解决复杂任务；提高效率；减少对人工干预的需求。 |
| **知识集成（RAG**） | 检索增强生成 | 访问最新信息；减少对预训练知识的依赖；提高准确性和相关性。 |
|  | 基于图的 RAG | 更复杂的推理；在复杂知识领域中的准确性提高；增强对关系的理解。 |
|  | 高级 RAG 技术 | 更高质量和更相关的信息；提高结果准确性和可靠性。 |
|  | 评估 RAG 系统 | 优化的 RAG 系统；更高的用户满意度；更高质量的结果。 |
| **代理式 AI** | 代理模式 | 能够创建自主系统；提高效率；减少人工干预；启用新应用。 |

表 1.1 – LLM 设计模式的好处

## 将设计模式应用于 LLM 的挑战

虽然设计模式在 LLM 开发中的好处是显而易见的，但它们的运用并非没有重大挑战。LLM 系统的独特性质、它们的快速演变以及这些模式涵盖的广泛领域（从基础数据处理到复杂的代理系统）都带来了几个障碍：

+   **快速技术进步**：LLM 领域中持续快速发展的速度仍然是主要挑战之一。新的模型架构、训练方法、复杂的提示策略、知识检索技术和代理框架不断涌现。这种快速变化意味着，即使是最近建立的用于优化训练或增强推理的模式，也可能需要频繁的调整；否则，它们可能会迅速变得不那么优化。开发者需要灵活的心态，在需要稳定实践（如纪律性的数据管理）和整合突破的敏捷性之间取得平衡。

+   **复杂性、规模和不可预测性**：大型语言模型（LLMs）本质上复杂，在巨大规模上运行，并且常常表现出非确定性行为。这在整个模式谱系中带来了挑战：

    +   **数据和训练**：应用管理大型数据集、构建训练管道或有效调整超参数的模式需要管理巨大的计算资源和数据量。

    +   **行为控制**：LLMs 的随机性质使得应用旨在确保期望结果的模式（如解决公平性、偏见、对抗鲁棒性，甚至逐步推理和行动的高级技术）变得复杂。实现一致、可预测的行为比传统软件更难。

    +   **错误处理和调试**：由于模型的不透明性，在使用涉及多步推理链或自主代理行为的复杂模式时，定位失败可能极其困难。

+   **评估困难**：衡量应用许多 LLM 设计模式的有效性是一个主要挑战。虽然存在定义评估指标和验证过程的模式，但评估细微方面（如生成的推理路径的质量、RAG 系统中检索到的上下文的真正有用性，或代理的整体鲁棒性和任务成功率）通常需要比标准基准更多的内容。为这些高级模式开发可靠和全面的评估策略是一个持续的研究领域。

+   **成本和资源限制**：实施许多 LLM 模式可能在各种方式上消耗资源：

    +   **数据成本**：彻底的数据标注和准备可能既昂贵又耗时。

    +   **计算成本**：核心模型训练、广泛的微调、大规模的超参数搜索或运行复杂检索增强或代理系统的推理需要大量的计算能力。

    +   **优化权衡**：旨在模型优化的模式，如剪枝或量化，旨在降低成本，但涉及自己的复杂性和潜在的性能权衡。成本因素可能限制了预算受限的团队对某些模式的实际应用性。

+   **LLM 开发的跨学科性质**：构建有效的 LLM 系统需要不同角色之间的协作——软件工程师、机器学习研究人员、数据科学家、提示工程师、领域专家、伦理学家等。在这些学科之间建立共同的理解和一致的应用模式至关重要但具有挑战性。例如，确保每个人都对数据管理实践达成一致、对评估结果有相同的解读或理解旨在确保公平性的模式的影响，需要刻意努力和清晰的沟通。

# 摘要

本章提供了对 LLMs 的基础理解，并介绍了设计模式在它们开发中的作用。它追溯了语言模型从早期的统计方法到今天基于 transformer 架构的 LLMs 的演变，强调了诸如自注意力机制、规模和计算资源的重要性、少样本学习、语言理解和生成能力以及多语言能力等关键特征。

然后，本章转向了设计模式的重要性，将其与软件工程中已确立的角色进行类比。这突出了将设计模式应用于 LLM 开发的益处，概述了一种结构化的方法来提高数据质量、优化训练、解决模型质量和一致性、增强推理能力、通过 RAG（检索增强生成）整合外部知识以及开发代理应用。然后，概述了本书中将探讨的 29 种模式，以及它们关注的 LLM 生命周期阶段。

最后，本章承认了将设计模式应用于 LLMs（大型语言模型）所面临的挑战，所有这些挑战都源于技术的快速演变、复杂性、规模、评估困难、成本限制以及 LLM 开发的跨学科性质。

在本书的剩余部分，我们将使用设计模式引导您通过 LLM 开发的生命周期，从构建坚实的基础数据（第二章至第六章）和优化模型训练（第七章至第十三章）开始。然后，我们将专注于确保模型质量、一致性和鲁棒性（第十四章至第十九章），在探索高级推理和问题解决能力（第二十章至第二十五章）之前。最后，我们将涵盖将外部知识整合到 RAG（第二十六章至第二十九章），并深入探讨具有代理人工智能的 LLM 的未来（第三十章），从而为构建智能应用提供一个全面的工具包。
