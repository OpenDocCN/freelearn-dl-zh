# 前言

**强化学习**（**RL**）是人工智能的一个领域，用于创建自学习的自主智能体。本书采取务实的方法，通过真实的商业和行业问题中的实际例子来教授你强化学习技巧。

从强化学习元素的概述开始，你将掌握马尔可夫链和马尔可夫决策过程（MDP），它们是建模强化学习问题的数学基础。接下来，你将学习蒙特卡罗方法和**时间差分**(**TD**)学习方法，它们被用于解决强化学习问题。然后，你将了解深度 Q 学习、策略梯度算法、演员-评论家方法、基于模型的方法和多智能体强化学习。随着学习的深入，你将探讨许多新颖的算法，并利用现代 Python 库实现高级功能。你还将了解如何实施强化学习来解决现实世界中的挑战，例如自主系统、供应链管理、游戏、金融、智慧城市和网络安全等领域的问题。最后，你将清楚了解该使用哪种方法以及何时使用，如何避免常见的陷阱，并克服在实施强化学习过程中遇到的挑战。

到本书的结尾，你将掌握如何训练和部署你自己的 RL 智能体，以解决强化学习问题。

# 本书适合谁阅读

本书适合有经验的机器学习从业者和深度学习研究人员，特别是那些希望在现实世界项目中实现高级强化学习概念的人。本书还将吸引那些希望通过自学习智能体解决复杂序列决策问题的强化学习专家。需要具备 Python 编程、机器学习基础知识和之前的强化学习经验。

# 本书内容概述

*第一章*，*强化学习介绍*，提供了强化学习的介绍，给出激励性的例子和成功故事，并探讨了强化学习在行业中的应用。接着，书中给出了强化学习概念的基本定义，并以软件和硬件设置部分作为总结。

*第二章*，*多臂赌博机*，介绍了一个相对简单的强化学习（RL）设定，即没有上下文的赌博机问题，这在工业界有着巨大的应用前景，是传统 A/B 测试的替代方法。本章还作为对一个非常基础的强化学习概念——探索与利用（exploration versus exploitation）的介绍。我们还通过四种不同的方法解决了一个原型在线广告案例。

*第三章*，*上下文赌博者*，通过为决策过程添加上下文并引入深度神经网络参与决策，使多臂赌博机问题（MABs）达到了一个更高级的层次。我们将来自美国人口普查的真实数据集应用于在线广告问题。最后，我们通过讨论赌博问题在工业和商业中的应用来结束本章内容。

*第四章*，*马尔可夫决策过程的构建*，构建了我们用来建模强化学习问题的数学理论。我们从马尔可夫链开始，描述状态的类型、遍历性、转移行为和稳态行为。接着我们讨论马尔可夫奖励过程和决策过程。在过程中，我们介绍了回报、折扣、策略和价值函数，以及贝尔曼最优性，这些都是强化学习理论中的关键概念，将在后续章节中频繁提及。最后，我们讨论了部分可观察马尔可夫决策过程。在整个章节中，我们使用一个网格世界的例子来说明这些概念。

*第五章*，*解决强化学习问题*，介绍了动态规划（DP）方法，这些方法是理解如何解决马尔可夫决策过程（MDP）问题的基础。介绍并说明了诸如策略评估、策略迭代和价值迭代等关键概念。整个章节通过解决一个库存补货问题来进行演示。最后，我们讨论了在现实世界例子中使用动态规划时遇到的问题。

*第六章*，*大规模深度 Q 学习*，提供了深度强化学习的介绍，并涵盖了从头到尾的深度 Q 学习。我们首先讨论为什么需要深度强化学习，然后介绍流行且可扩展的 RL 库——RLlib。在介绍完将要使用的案例研究（一个简单的、一个中等难度的以及一个视频游戏例子）之后，我们将从拟合 Q 迭代、DQN 到 Rainbow 构建深度 Q 学习方法。接着，我们将进入更高级的话题，讨论分布式 DQN（APEX）、连续 DQN，并讨论需要调整的重要超参数。对于经典的 DQN，你将使用 TensorFlow 实现；而对于 Rainbow，我们将使用 RLlib。

*第七章*，*基于策略的方法*，介绍了强化学习方法的第二大类：基于策略的方法。你将首先了解它们与其他方法的不同之处以及它们的必要性。接着，我们将深入探讨几种最先进的策略梯度和信赖域方法。最后，我们将讨论演员-评论员算法。我们主要依赖 RLlib 对这些算法的实现，并关注如何以及何时使用这些算法，而不是详细的实现细节。

*第八章*, *基于模型的方法*，展示了基于模型的方法所做的假设以及它们相较于其他方法的优势。我们还讨论了著名的 AlphaGo Zero 背后的模型。本章的最后，我们通过一个使用基于模型算法的练习来总结这一章。章节内容包括手动和 RLlib 实现的结合使用。

*第九章*, *多智能体强化学习*，为你提供了一个框架，用以建模多智能体 RL 问题，并介绍了 MADDPG 来解决此类问题。章节中使用了 RLlib 的 MADDPG 实现。

*第十章*, *机器教学*，讨论了机器教学方法，如何将复杂问题分解为更小的部分，并使其可解。该方法对于许多现实生活中的问题是必需的，你将学到一些实用的技巧，如何设计一个 RL 模型，并超越算法选择来解决 RL 问题。

*第十一章*, *泛化与领域随机化*，讨论了部分可观察性和 sim2real 差距为何成为问题，并介绍了如何通过使用 LSTM-like 模型和领域随机化来克服这些问题。

*第十二章*, *元强化学习*，介绍了使我们能够为多个任务使用单一模型的方法。由于样本效率是 RL 中的一个主要问题，本章让你了解了 RL 中的一个非常重要的未来方向。

*第十三章*, *其他高级主题*，介绍了前沿的 RL 研究。到目前为止讨论的许多方法都有一定的假设和局限性。本章讨论的主题解决了这些局限性，并给出了如何克服它们的思路。在本章结束时，你将了解到当你遇到我们在前面章节中讨论的算法的局限性时，应该关注哪些方法。

*第十四章*, *自主系统*，探讨了 RL 在创建现实世界自主系统方面的潜力。我们涵盖了成功案例和自主机器人以及自动驾驶汽车的样本问题。

*第十五章*, *供应链管理*，让你亲身体验库存规划和箱子装配问题。我们将这些问题建模为 RL 问题，并解决一些样本案例。

*第十六章*, *营销、个性化和金融*，涵盖了 RL 在营销、广告、推荐系统和金融中的应用。本章将帮助你广泛了解 RL 在商业中的应用，以及其机会与局限性。在本章中，我们还讨论了上下文多臂赌博机问题的例子。

*第十七章*，*智慧城市与网络安全*，涵盖了智慧城市和网络安全领域的示例问题，如交通控制、服务提供监管和入侵检测。我们还讨论了多智能体方法如何在这些应用中发挥作用。

*第十八章*，*强化学习的挑战与未来方向*，详细探讨了这些挑战是什么以及最前沿的研究提出了如何克服它们的建议。本章教你如何评估 RL 方法在特定问题中的可行性。

# 为了充分利用本书

**如果你使用的是本书的电子版，建议你手动输入代码，或者通过 GitHub 仓库（下节中会提供链接）访问代码。这样可以避免因复制粘贴代码而导致的潜在错误。**

# 下载示例代码文件

你可以从[www.packt.com](http://www.packt.com)账户中下载本书的示例代码文件。如果你在其他地方购买了本书，可以访问[www.packtpub.com/support](http://www.packtpub.com/support)，注册后将文件直接发送给你。

你可以按照以下步骤下载代码文件：

1.  登录或注册账号，访问[www.packt.com](http://www.packt.com)。

1.  选择**支持**标签。

1.  点击**代码下载**。

1.  在**搜索**框中输入书名，并按照屏幕上的指示操作。

下载完成后，请确保使用以下最新版本的工具解压或提取文件夹：

+   Windows 下的 WinRAR/7-Zip

+   Mac 下的 Zipeg/iZip/UnRarX

+   Linux 下的 7-Zip/PeaZip

本书的代码包也托管在 GitHub 上，地址为[`github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python`](https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python)。如果代码有更新，更新内容将会同步到现有的 GitHub 仓库中。

我们还提供了其他丰富书籍和视频的代码包，地址为[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)。赶快去看看吧！

# 下载彩色图像

我们还提供了一个 PDF 文件，其中包含本书中使用的截图/图表的彩色图像。你可以在此下载：[`static.packt-cdn.com/downloads/9781838644147_ColorImages.pdf`](https://static.packt-cdn.com/downloads/9781838644147_ColorImages.pdf)。

# 使用的约定

本书中使用了一些文本约定。

`文本中的代码`：表示文本中的代码词、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。例如：“例如，使用`sudo apt-get install nvidia-modprobe`命令安装 NVIDIA Modprobe。”

代码块如下所示：

```py
ug = UserGenerator()
visualize_bandits(ug)
```

当我们希望引起您对代码块的特定部分的注意时，相关行或条目将以粗体显示：

```py
./run_local.sh [Game] [Agent] [Num. actors] 
./run_local.sh atari r2d2 4
```

提示或重要说明

Appear like this.

# 联系我们

我们始终欢迎读者的反馈。

**一般反馈**：如果您对本书的任何方面有疑问，请在邮件主题中提及书名，并发送邮件至 customercare@packtpub.com。

**勘误**：尽管我们已经尽一切努力确保内容的准确性，但错误确实会发生。如果您发现了本书中的错误，请向我们报告。请访问 [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)，选择您的书籍，点击勘误提交表单链接，并输入详细信息。

**盗版**：如果您在互联网上发现我们作品的任何形式的非法拷贝，请向我们提供位置地址或网站名称。请通过链接 copyright@packt.com 联系我们。

**如果您有兴趣成为作者**：如果您对某个您擅长的主题感兴趣，并且有意撰写或贡献一本书，请访问 [authors.packtpub.com](http://authors.packtpub.com)。

# 评论

请留下评论。在阅读和使用本书后，为什么不在购买它的网站上留下评论呢？潜在的读者可以看到并使用您的客观意见来做购买决策，我们在 Packt 可以了解您对我们产品的看法，而我们的作者可以看到您对他们书籍的反馈。谢谢！

有关 Packt 的更多信息，请访问 [packt.com](http://packt.com)。
