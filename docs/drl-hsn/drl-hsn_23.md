# 第二十三章：参考文献

[Sut88]

Richard S Sutton. “通过时间差方法学习预测”。发表于：机器学习 3 (1988)，第 9–44 页。

[HS96]

Sepp Hochreiter 和 Jürgen Schmidhuber. “LSTM 可以解决难度较大的长时延问题”。发表于：神经信息处理系统进展 9 (1996)。

[RK04]

Reuven Y Rubinstein 和 Dirk P Kroese. 《交叉熵方法：组合优化、蒙特卡洛模拟与机器学习的统一方法》。第 133 卷，Springer 出版社，2004 年。

[SL08]

Alexander L Strehl 和 Michael L Littman. “基于模型的马尔科夫决策过程区间估计分析”。发表于：计算机与系统科学杂志 74.8 (2008)，第 1309–1331 页。

[Kro+11]

Dirk P Kroese 等. “交叉熵方法”。发表于：欧洲运筹学杂志 31 (2011)，第 276–283 页。

[LS11]

Joel Lehman 和 Kenneth O Stanley. “放弃目标：仅通过寻找新奇性进化”。发表于：进化计算 19.2 (2011)，第 189–223 页。

[Mni13]

Volodymyr Mnih. “通过深度强化学习玩 Atari 游戏”。发表于：arXiv 预印本 arXiv:1312.5602 (2013)。

[Sil+14]

David Silver 等. “确定性策略梯度算法”。发表于：国际机器学习会议。PMLR。2014 年，第 387–395 页。

[Lil15]

TP Lillicrap. “通过深度强化学习进行连续控制”。发表于：arXiv 预印本 arXiv:1509.02971 (2015)。

[MG15]

James Martens 和 Roger Grosse. “通过克罗内克分解近似曲率优化神经网络”。发表于：国际机器学习会议。PMLR。2015 年，第 2408–2417 页。

[Mni+15]

Volodymyr Mnih 等. “通过深度强化学习实现人类级控制”。发表于：自然期刊 518.7540 (2015)，第 529–533 页。

[Sch+15]

Tom Schaul 等. “优先经验回放”。发表于：(2015)。arXiv: [1511.05952 [cs.LG]](https://arxiv.org/abs/1511.05952)。网址: [`arxiv.org/abs/1511.05952`](https://arxiv.org/abs/1511.05952)。

[Sch15]

John Schulman. “信任区域策略优化”。发表于：arXiv 预印本 arXiv:1502.05477 (2015)。

[VGS16]

Hado Van Hasselt, Arthur Guez, 和 David Silver. “基于双 Q 学习的深度强化学习”。发表于：人工智能 AAAI 会议论文集。第 30 卷，1 号，2016 年。

[Wan+16]

Ziyu Wang 等. “用于深度强化学习的对抗性网络架构”。发表于：国际机器学习会议。PMLR。2016 年，第 1995–2003 页。

[BDM17]

Marc G Bellemare, Will Dabney, 和 Rémi Munos. “从分布视角看强化学习”。发表于：国际机器学习会议。PMLR。2017 年，第 449–458 页。

[Chr+17]

Paul Christiano 等. 《基于人类偏好的深度强化学习》。2017 年。电子印本: arXiv:1706.03741。

[For+17]

Meire Fortunato 等. “探索中的噪声网络”。发表于：(2017)。arXiv: [1706.10295 [cs.LG]](https://arxiv.org/abs/1706.10295)。网址: [`arxiv.org/abs/1706.10295`](https://arxiv.org/abs/1706.10295)。

[Mar+17]

Jarryd Martin 等人。“基于计数的特征空间探索用于强化学习”。收录于：arXiv 预印本 arXiv:1706.08090 (2017)。

[Ost+17]

Georg Ostrovski 等人。“基于计数的探索与神经密度模型”。收录于：国际机器学习会议。PMLR。2017 年，页码：2721–2730。

[Sal+17]

Tim Salimans 等人。“进化策略：作为强化学习的可扩展替代方法”。收录于：arXiv 预印本 arXiv:1703.03864 (2017)。

[Sch+17]

John Schulman 等人。“近端策略优化算法”。收录于：arXiv 预印本 arXiv:1707.06347 (2017)。

[SSa17]

David Silver、Julian Schrittwieser 和 Karen Simonyan 等人。无需人类知识的围棋游戏掌握。2017\. eprint: 10.1038/nature24270。

[Sil+17]

David Silver 等人。通过自我对弈与通用强化学习算法掌握国际象棋和将棋。2017\. arXiv: [1712.01815 [cs.AI]](https://arxiv.org/abs/1712.01815)。网址：[`arxiv.org/abs/1712.01815`](https://arxiv.org/abs/1712.01815)。

[Suc+17]

Felipe Petroski Such 等人。“深度神经进化：遗传算法是训练深度神经网络进行强化学习的竞争性替代方法”。收录于：arXiv 预印本 arXiv:1712.06567 (2017)。

[Vas17]

A Vaswani。“注意力即你所需要的”。收录于：神经信息处理系统进展 (2017)。

[Wu+17]

Yuhuai Wu 等人。“基于克罗内克近似的可扩展信任域方法用于深度强化学习”。收录于：神经信息处理系统进展 30 (2017)。

[Bar+18]

Gabriel Barth-Maron 等人。“分布式分布式确定性策略梯度”。收录于：arXiv 预印本 arXiv:1804.08617 (2018)。

[Bur+18]

Yuri Burda 等人。“通过随机网络蒸馏进行探索”。收录于：arXiv 预印本 arXiv:1810.12894 (2018)。

[Haa+18]

Tuomas Haarnoja 等人。“软演员-评论家：具有随机演员的非策略最大熵深度强化学习”。收录于：国际机器学习会议。PMLR。2018 年，页码：1861–1870。

[Hes+18]

Matteo Hessel 等人。“彩虹：结合深度强化学习的改进”。收录于：人工智能学会年会论文集。第 32 卷，第 1 期，2018 年。

[McA+18]

Stephen McAleer 等人。“无需人类知识解决魔方”。收录于：arXiv 预印本 arXiv:1805.07470 (2018)。

[Bak+20]

Bowen Baker 等人。来自多智能体自动课程的工具使用演化。2020\. arXiv: [1909.07528 [cs.LG]](https://arxiv.org/abs/1909.07528)。网址：[`arxiv.org/abs/1909.07528`](https://arxiv.org/abs/1909.07528)。

[FS20]

Alexander H Frey Jr 和 David Singmaster。“立方体数学手册”。出版于：（2020）。

[Sch+20]

Julian Schrittwieser 等人。“通过规划与学习的模型掌握 Atari、围棋、国际象棋和将棋”。发表于：Nature 588.7839 (2020 年 12 月)，页码：604–609\. issn: 1476-4687\. doi: [10.1038/s41586-020-03051-4](https://doi.org/10.1038/s41586-020-03051-4)。网址：[`dx.doi.org/10.1038/s41586-020-03051-4`](http://dx.doi.org/10.1038/s41586-020-03051-4)。

[BDR23]

Marc G Bellemare, Will Dabney, and Mark Rowland. 分布式强化学习. MIT Press, 2023.

![图片](img/file0.png)

[www.packt.com](https://www.packt.com)

订阅我们的在线数字图书馆，全面访问超过 7,000 本书籍和视频，以及行业领先的工具，帮助您规划个人发展并推动职业发展。如需更多信息，请访问我们的网站。

# 为什么要订阅？

+   减少学习时间，更多时间编码，享受来自 4000 多位行业专家的实用电子书和视频

+   通过为您量身定制的技能计划提升学习效果

+   每月获取一本免费的电子书或视频

+   完全可搜索，轻松访问关键信息

+   复制、粘贴、打印和收藏内容

在[www.packt.com](https://www.packt.com)，您还可以阅读一系列免费的技术文章，订阅各种免费的新闻通讯，并获得 Packt 图书和电子书的独家折扣和优惠。

# 您可能会喜欢的其他书籍

如果您喜欢这本书，您可能会对 Packt 的这些其他书籍感兴趣：

![图片](https://www.packtpub.com/en-us/product/mastering-pytorch-9781801074308)

《掌握 PyTorch》

Ashish Ranjan Jha

ISBN: 9781801074308

+   使用 PyTorch 实现文本、视觉和音乐生成模型

+   在 PyTorch 中构建深度 Q 网络（DQN）模型

+   在移动设备（Android 和 iOS）上部署 PyTorch 模型

+   熟练使用 PyTorch 和 fastai 进行快速原型设计

+   使用 AutoML 高效进行神经网络架构搜索

+   使用 Captum 轻松解读机器学习模型

+   设计 ResNets、LSTMs 和图神经网络（GNNs）

+   使用 Hugging Face 创建语言和视觉转换器模型

![图片](https://www.packtpub.com/en-us/product/python-for-algorithmic-trading-cookbook-9781835084700)

《算法交易食谱中的 Python》

Jason Strimpel

ISBN: 9781835084700

+   使用 OpenBB 平台获取并处理自由可用的市场数据

+   构建一个研究环境，并用金融市场数据填充它

+   使用机器学习识别阿尔法因子并将其转化为信号

+   使用 VectorBT 通过步进优化找到策略参数

+   使用 Zipline Reloaded 构建生产级回测并评估因子表现

+   设置代码框架以连接并向 Interactive Brokers 发送订单

# Packt 正在寻找像您这样的作者

如果您有兴趣成为 Packt 的作者，请访问[authors.packtpub.com](https://authors.packtpub.com)并立即申请。我们与成千上万的开发人员和技术专业人士合作，帮助他们与全球技术社区分享见解。您可以进行一般申请，申请特定的热门话题，或提交您自己的创意。
