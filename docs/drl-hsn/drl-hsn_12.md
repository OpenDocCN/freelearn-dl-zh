

# ç¬¬åäºŒç« ï¼šæ¼”å‘˜-è¯„è®ºå‘˜æ–¹æ³•ï¼šA2C å’Œ A3C

åœ¨ç¬¬åä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å¼€å§‹ç ”ç©¶ä¸€ç§åŸºäºç­–ç•¥çš„æ–¹æ³•ï¼Œä½œä¸ºä¼ ç»Ÿå€¼åŸºæ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬é‡ç‚¹å…³æ³¨äº†åä¸º REINFORCE çš„æ–¹æ³•åŠå…¶ä¿®æ”¹ç‰ˆï¼Œè¯¥æ–¹æ³•ä½¿ç”¨æŠ˜æ‰£å¥–åŠ±æ¥è·å¾—ç­–ç•¥çš„æ¢¯åº¦ï¼ˆè¯¥æ¢¯åº¦å‘Šè¯‰æˆ‘ä»¬æ”¹å–„ç­–ç•¥çš„æ–¹å‘ï¼‰ã€‚è¿™ä¸¤ç§æ–¹æ³•åœ¨å°å‹çš„ CartPole é—®é¢˜ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ›´å¤æ‚çš„ Pong ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰å¾—åˆ°æ”¶æ•›ã€‚

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦ä¸€ç§å¯¹æ™®é€šç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„æ‰©å±•ï¼Œå®ƒç¥å¥‡åœ°æ”¹å–„äº†è¯¥æ–¹æ³•çš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚å°½ç®¡è¿™ç§ä¿®æ”¹åªæ˜¯å¾®å°çš„ï¼Œä½†æ–°æ–¹æ³•æœ‰äº†è‡ªå·±çš„åå­—â€”â€”æ¼”å‘˜-è¯„è®ºå‘˜ï¼Œå®ƒæ˜¯æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­æœ€å¼ºå¤§çš„æ–¹æ³•ä¹‹ä¸€ã€‚

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ï¼š

+   æ¢ç´¢åŸºå‡†æ–¹æ³•å¦‚ä½•å½±å“ç»Ÿè®¡æ•°æ®å’Œæ¢¯åº¦çš„æ”¶æ•›æ€§

+   æ‰©å±•åŸºå‡†æ–¹æ³•çš„æ¦‚å¿µ

+   å®ç°ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå‘˜ï¼ˆA2Cï¼‰æ–¹æ³•ï¼Œå¹¶åœ¨ Pong ç¯å¢ƒä¸­è¿›è¡Œæµ‹è¯•

+   ä½¿ç”¨ä¸¤ç§ä¸åŒçš„æ–¹æ³•ï¼šæ•°æ®å¹¶è¡Œå’Œæ¢¯åº¦å¹¶è¡Œï¼Œä¸º A2C æ–¹æ³•å¢åŠ å¼‚æ­¥æ‰§è¡Œ

# æ–¹å·®å‡å°‘

åœ¨å‰ä¸€ç« ä¸­ï¼Œæˆ‘ç®€è¦æåˆ°è¿‡ï¼Œæ”¹å–„ç­–ç•¥æ¢¯åº¦æ–¹æ³•ç¨³å®šæ€§çš„ä¸€ç§æ–¹å¼æ˜¯å‡å°‘æ¢¯åº¦çš„æ–¹å·®ã€‚ç°åœ¨è®©æˆ‘ä»¬å°è¯•ç†è§£ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼Œä»¥åŠå‡å°‘æ–¹å·®æ„å‘³ç€ä»€ä¹ˆã€‚åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œæ–¹å·®æ˜¯éšæœºå˜é‡ä¸è¯¥å˜é‡çš„æœŸæœ›å€¼ä¹‹é—´çš„å¹³æ–¹åå·®çš„æœŸæœ›å€¼ï¼š

![Ï€ (a |s) = P[At = a|St = s] ](img/eq44.png)

æ–¹å·®å±•ç¤ºäº†æ•°å€¼ä¸å‡å€¼ä¹‹é—´çš„åˆ†æ•£ç¨‹åº¦ã€‚å½“æ–¹å·®è¾ƒé«˜æ—¶ï¼Œéšæœºå˜é‡å¯èƒ½ä¼šå–åˆ°ä¸å‡å€¼ç›¸å·®è¾ƒå¤§çš„å€¼ã€‚åœ¨ä¸‹å›¾ä¸­ï¼Œå­˜åœ¨ä¸€ä¸ªå‡å€¼ä¸ºÎ¼ = 10 çš„æ­£æ€ï¼ˆé«˜æ–¯ï¼‰åˆ†å¸ƒï¼Œä½†å…¶æ–¹å·®å€¼ä¸åŒã€‚

![PIC](img/B22150_12_01.png)

å›¾ 12.1ï¼šæ–¹å·®å¯¹é«˜æ–¯åˆ†å¸ƒçš„å½±å“

ç°åœ¨è®©æˆ‘ä»¬å›åˆ°ç­–ç•¥æ¢¯åº¦ã€‚å‰ä¸€ç« ä¸­æåˆ°è¿‡ï¼Œç­–ç•¥æ¢¯åº¦çš„æ ¸å¿ƒæ€æƒ³æ˜¯æé«˜è‰¯å¥½åŠ¨ä½œçš„æ¦‚ç‡å¹¶é™ä½ä¸è‰¯åŠ¨ä½œçš„æ¦‚ç‡ã€‚åœ¨æ•°å­¦è¡¨ç¤ºä¸­ï¼Œæˆ‘ä»¬çš„ç­–ç•¥æ¢¯åº¦è¢«å†™ä¸ºâˆ‡J â‰ˆğ”¼[Q(s,a)âˆ‡log Ï€(a|s)]ã€‚ç¼©æ”¾å› å­ Q(s,a)æŒ‡å®šäº†æˆ‘ä»¬å¸Œæœ›åœ¨ç‰¹å®šçŠ¶æ€ä¸‹å¢åŠ æˆ–å‡å°‘åŠ¨ä½œæ¦‚ç‡çš„å¤šå°‘ã€‚åœ¨ REINFORCE æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æŠ˜æ‰£æ€»å¥–åŠ±ä½œä¸ºæ¢¯åº¦çš„ç¼©æ”¾å› å­ã€‚ä¸ºäº†æé«˜ REINFORCE çš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬ä»æ¢¯åº¦çš„ç¼©æ”¾å› å­ä¸­å‡å»äº†å¹³å‡å¥–åŠ±ã€‚

ä¸ºäº†ç†è§£ä¸ºä»€ä¹ˆè¿™æœ‰å¸®åŠ©ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªéå¸¸ç®€å•çš„ä¼˜åŒ–æ­¥éª¤åœºæ™¯ï¼Œåœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸‰ç§åŠ¨ä½œï¼Œå®ƒä»¬çš„æ€»æŠ˜æ‰£å¥–åŠ±ä¸åŒï¼šQ[1]ã€Q[2]å’Œ Q[3]ã€‚ç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥åœ¨å…³äºè¿™äº› Q[s]çš„ç›¸å¯¹å€¼çš„æƒ…å†µä¸‹ï¼Œç­–ç•¥æ¢¯åº¦ä¼šå‘ç”Ÿä»€ä¹ˆã€‚

ä½œä¸ºç¬¬ä¸€ä¸ªä¾‹å­ï¼Œå‡è®¾ Q[1]å’Œ Q[2]éƒ½ç­‰äºæŸä¸ªå°çš„æ­£æ•°ï¼Œè€Œ Q[3]æ˜¯ä¸€ä¸ªè¾ƒå¤§çš„è´Ÿæ•°ã€‚å› æ­¤ï¼Œç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥çš„è¡ŒåŠ¨è·å¾—äº†ä¸€äº›å°çš„å¥–åŠ±ï¼Œä½†ç¬¬ä¸‰æ­¥çš„ç»“æœå¹¶ä¸ç†æƒ³ã€‚æ‰€æœ‰ä¸‰æ­¥çš„ç»¼åˆæ¢¯åº¦å°†å°è¯•å°†æˆ‘ä»¬çš„ç­–ç•¥è¿œç¦»ç¬¬ä¸‰æ­¥çš„è¡ŒåŠ¨ï¼Œå¹¶ç¨å¾®æ¨åŠ¨å®ƒæœç€ç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥çš„è¡ŒåŠ¨æ–¹å‘å‘å±•ï¼Œè¿™å®Œå…¨æ˜¯åˆç†çš„åšæ³•ã€‚

ç°åœ¨è®©æˆ‘ä»¬å‡è®¾æˆ‘ä»¬çš„å¥–åŠ±å§‹ç»ˆä¸ºæ­£ä¸”åªæœ‰æ•°å€¼ä¸åŒã€‚è¿™ç›¸å½“äºåœ¨å‰ä¸€ä¸ªä¾‹å­ä¸­çš„æ¯ä¸ªå¥–åŠ±å€¼ä¸Šæ·»åŠ ä¸€ä¸ªå¸¸é‡ï¼šQ[1]ã€Q[2]å’Œ Q[3]ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒQ[1]å’Œ Q[2]å°†å˜ä¸ºå¤§çš„æ­£æ•°ï¼Œè€Œ Q[3]å°†å…·æœ‰ä¸€ä¸ªå°çš„æ­£å€¼ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„ç­–ç•¥æ›´æ–°å°†å˜å¾—ä¸åŒï¼æˆ‘ä»¬å°†åŠªåŠ›å°†ç­–ç•¥æ¨å‘ç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥çš„è¡ŒåŠ¨ï¼Œå¹¶ç¨å¾®æ¨å‘ç¬¬ä¸‰æ­¥çš„è¡ŒåŠ¨ã€‚å› æ­¤ï¼Œä¸¥æ ¼æ¥è¯´ï¼Œå°½ç®¡ç›¸å¯¹å¥–åŠ±ç›¸åŒï¼Œæˆ‘ä»¬ä¸å†è¯•å›¾é¿å…ç¬¬ä¸‰æ­¥çš„è¡ŒåŠ¨ã€‚

æˆ‘ä»¬çš„ç­–ç•¥æ›´æ–°ä¾èµ–äºæ·»åŠ åˆ°å¥–åŠ±ä¸­çš„å¸¸é‡ï¼Œè¿™å¯èƒ½ä¼šæ˜¾è‘—å‡ç¼“è®­ç»ƒè¿›åº¦ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½éœ€è¦æ›´å¤šçš„æ ·æœ¬æ¥å¹³æ»‘è¿™ç§ç­–ç•¥æ¢¯åº¦çš„å˜åŒ–ã€‚æ›´ç³Ÿçš„æ˜¯ï¼Œéšç€æˆ‘ä»¬æ€»çš„æŠ˜æ‰£å¥–åŠ±éšæ—¶é—´å˜åŒ–ï¼Œä»£ç†ä¸æ–­å­¦ä¹ å¦‚ä½•åšå¾—æ›´å¥½ï¼Œæˆ‘ä»¬çš„ç­–ç•¥æ¢¯åº¦æ–¹å·®ä¹Ÿå¯èƒ½å‘ç”Ÿå˜åŒ–ã€‚ä¾‹å¦‚ï¼Œåœ¨ Atari Pong ç¯å¢ƒä¸­ï¼Œå¼€å§‹æ—¶çš„å¹³å‡å¥–åŠ±æ˜¯âˆ’21...âˆ’20ï¼Œå› æ­¤æ‰€æœ‰çš„è¡ŒåŠ¨çœ‹èµ·æ¥å‡ ä¹åŒæ ·ç³Ÿç³•ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåœ¨ä¸Šä¸€ç« ä¸­ï¼Œæˆ‘ä»¬ä» Q å€¼ä¸­å‡å»äº†æ€»å¥–åŠ±çš„å‡å€¼ï¼Œå¹¶ç§°è¿™ä¸ªå‡å€¼ä¸ºåŸºå‡†ã€‚è¿™ä¸€æŠ€å·§å°†æˆ‘ä»¬çš„ç­–ç•¥æ¢¯åº¦å½’ä¸€åŒ–ï¼šä¾‹å¦‚ï¼Œå½“å¹³å‡å¥–åŠ±ä¸ºâˆ’21 æ—¶ï¼Œè·å¾—âˆ’20 çš„å¥–åŠ±çœ‹èµ·æ¥åƒæ˜¯ä»£ç†çš„èƒœåˆ©ï¼Œè¿™å°†æ¨åŠ¨å…¶ç­–ç•¥æœç€é‡‡å–çš„è¡ŒåŠ¨æ–¹å‘å‘å±•ã€‚

# CartPole æ–¹å·®

ä¸ºäº†åœ¨å®è·µä¸­éªŒè¯è¿™ä¸ªç†è®ºç»“è®ºï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶åŸºå‡†ç‰ˆæœ¬å’Œä¸ä½¿ç”¨åŸºå‡†ç‰ˆæœ¬çš„è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç­–ç•¥æ¢¯åº¦æ–¹å·®ã€‚å®Œæ•´ç¤ºä¾‹ä½äº Chapter12/01_cartpole_pg.pyï¼Œä¸”å¤§éƒ¨åˆ†ä»£ç ä¸ç¬¬åä¸€ç« ç›¸åŒã€‚è¯¥ç‰ˆæœ¬çš„ä¸åŒä¹‹å¤„å¦‚ä¸‹ï¼š

+   å®ƒç°åœ¨æ¥å—å‘½ä»¤è¡Œé€‰é¡¹`--baseline`ï¼Œå¯ç”¨ä»å¥–åŠ±ä¸­å‡å»å‡å€¼ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸ä½¿ç”¨åŸºå‡†ã€‚

+   åœ¨æ¯ä¸ªè®­ç»ƒå¾ªç¯ä¸­ï¼Œæˆ‘ä»¬ä»ç­–ç•¥æŸå¤±ä¸­è·å–æ¢¯åº¦ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ•°æ®æ¥è®¡ç®—æ–¹å·®ã€‚

ä¸ºäº†ä»…æ”¶é›†æ¥è‡ªç­–ç•¥æŸå¤±çš„æ¢¯åº¦ï¼Œå¹¶æ’é™¤ä¸ºäº†æ¢ç´¢è€Œæ·»åŠ çš„ç†µå¥–åŠ±çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬éœ€è¦åˆ†ä¸¤é˜¶æ®µè®¡ç®—æ¢¯åº¦ã€‚å¹¸è¿çš„æ˜¯ï¼ŒPyTorch ä½¿å¾—è¿™ä¸€æ“ä½œå˜å¾—ç®€å•ã€‚ä»¥ä¸‹ä»£ç ä¸­ä»…åŒ…å«äº†è®­ç»ƒå¾ªç¯çš„ç›¸å…³éƒ¨åˆ†ï¼Œç”¨äºè¯´æ˜è¿™ä¸€æ€è·¯ï¼š

```py
 optimizer.zero_grad() 
        logits_v = net(states_v) 
        log_prob_v = F.log_softmax(logits_v, dim=1) 
        log_p_a_v = log_prob_v[range(BATCH_SIZE), batch_actions_t] 
        log_prob_actions_v = batch_scale_v * log_p_a_v 
        loss_policy_v = -log_prob_actions_v.mean()
```

æˆ‘ä»¬åƒä»¥å‰ä¸€æ ·è®¡ç®—ç­–ç•¥æŸå¤±ï¼Œé€šè¿‡è®¡ç®—å·²é‡‡å–åŠ¨ä½œçš„æ¦‚ç‡çš„å¯¹æ•°å¹¶å°†å…¶ä¹˜ä»¥ç­–ç•¥å°ºåº¦ï¼ˆå¦‚æœæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨åŸºå‡†çº¿ï¼Œå®ƒæ˜¯æ€»æŠ˜æ‰£å¥–åŠ±ï¼Œæˆ–è€…æ˜¯æ€»å¥–åŠ±å‡å»åŸºå‡†çº¿ï¼‰ã€‚

åœ¨ä¸‹ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬è¯·æ±‚ PyTorch åå‘ä¼ æ’­ç­–ç•¥æŸå¤±ï¼Œè®¡ç®—æ¢¯åº¦å¹¶å°†å®ƒä»¬ä¿å­˜åœ¨æ¨¡å‹çš„ç¼“å†²åŒºä¸­ï¼š

```py
 loss_policy_v.backward(retain_graph=True)
```

ç”±äºæˆ‘ä»¬ä¹‹å‰æ‰§è¡Œäº† optimizer.zero_grad()ï¼Œè¿™äº›ç¼“å†²åŒºå°†åªåŒ…å«æ¥è‡ªç­–ç•¥æŸå¤±çš„æ¢¯åº¦ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªæ£˜æ‰‹çš„åœ°æ–¹æ˜¯æˆ‘ä»¬åœ¨è°ƒç”¨ backward() æ—¶ä½¿ç”¨äº† retain_graph=True é€‰é¡¹ã€‚å®ƒæŒ‡ç¤º PyTorch ä¿ç•™å˜é‡çš„å›¾ç»“æ„ã€‚é€šå¸¸ï¼Œè°ƒç”¨ backward() æ—¶ä¼šé”€æ¯å›¾ç»“æ„ï¼Œä½†åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå½“æˆ‘ä»¬éœ€è¦åœ¨è°ƒç”¨ä¼˜åŒ–å™¨ä¹‹å‰å¤šæ¬¡åå‘ä¼ æ’­æŸå¤±æ—¶ï¼Œä¿ç•™å›¾ç»“æ„å¯èƒ½ä¼šå¾ˆæœ‰ç”¨ï¼Œå°½ç®¡è¿™ä¸æ˜¯ä¸€ç§éå¸¸å¸¸è§çš„æƒ…å†µã€‚

ç„¶åï¼Œæˆ‘ä»¬éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰å‚æ•°ï¼ˆæ¨¡å‹çš„æ¯ä¸ªå‚æ•°éƒ½æ˜¯ä¸€ä¸ªåŒ…å«æ¢¯åº¦çš„å¼ é‡ï¼‰ï¼Œå¹¶å°†å®ƒä»¬çš„ grad å­—æ®µæå–åˆ°ä¸€ä¸ªå±•å¹³çš„ NumPy æ•°ç»„ä¸­ï¼š

```py
 grads = np.concatenate([p.grad.data.numpy().flatten() 
                                for p in net.parameters() 
                                if p.grad is not None])
```

è¿™ä¼šç»™æˆ‘ä»¬ä¸€ä¸ªåŒ…å«æ¨¡å‹å˜é‡ä¸­æ‰€æœ‰æ¢¯åº¦çš„é•¿æ•°ç»„ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„å‚æ•°æ›´æ–°ä¸ä»…åº”è¯¥è€ƒè™‘ç­–ç•¥æ¢¯åº¦ï¼Œè¿˜åº”è€ƒè™‘ç”±ç†µå¥–åŠ±æä¾›çš„æ¢¯åº¦ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬è®¡ç®—ç†µæŸå¤±å¹¶å†æ¬¡è°ƒç”¨ backward()ã€‚ä¸ºäº†èƒ½å¤Ÿç¬¬äºŒæ¬¡æ‰§è¡Œè¿™ä¸€æ“ä½œï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’ retain_graph=Trueã€‚

åœ¨ç¬¬äºŒæ¬¡è°ƒç”¨ backward() æ—¶ï¼ŒPyTorch å°†åå‘ä¼ æ’­æˆ‘ä»¬çš„ç†µæŸå¤±ï¼Œå¹¶å°†æ¢¯åº¦æ·»åŠ åˆ°å†…éƒ¨æ¢¯åº¦ç¼“å†²åŒºä¸­ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨éœ€è¦åšçš„å°±æ˜¯è¯·æ±‚ä¼˜åŒ–å™¨ä½¿ç”¨è¿™äº›åˆå¹¶çš„æ¢¯åº¦æ‰§è¡Œä¼˜åŒ–æ­¥éª¤ï¼š

```py
 prob_v = F.softmax(logits_v, dim=1) 
        entropy_v = -(prob_v * log_prob_v).sum(dim=1).mean() 
        entropy_loss_v = -ENTROPY_BETA * entropy_v 
        entropy_loss_v.backward() 
        optimizer.step()
```

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦åšçš„å”¯ä¸€äº‹æƒ…å°±æ˜¯å°†æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç»Ÿè®¡æ•°æ®å†™å…¥ TensorBoardï¼š

```py
 g_l2 = np.sqrt(np.mean(np.square(grads))) 
        g_max = np.max(np.abs(grads)) 
        writer.add_scalar("grad_l2", g_l2, step_idx) 
        writer.add_scalar("grad_max", g_max, step_idx) 
        writer.add_scalar("grad_var", np.var(grads), step_idx)
```

é€šè¿‡è¿è¡Œè¿™ä¸ªç¤ºä¾‹ä¸¤æ¬¡ï¼Œä¸€æ¬¡ä½¿ç”¨ --baseline å‘½ä»¤è¡Œé€‰é¡¹ï¼Œä¸€æ¬¡ä¸ä½¿ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ç­–ç•¥æ¢¯åº¦çš„æ–¹å·®å›¾ã€‚ä»¥ä¸‹å›¾è¡¨æ˜¾ç¤ºäº†å¹³æ»‘çš„å¥–åŠ±ï¼ˆè¿‡å» 100 é›†çš„å¹³å‡å€¼ï¼‰å’Œæ–¹å·®ï¼ˆä½¿ç”¨çª—å£ 20 å¹³æ»‘ï¼‰ï¼š

![PIC](img/B22150_12_02.png)

å›¾ 12.2ï¼šå¹³æ»‘å¥–åŠ±ï¼ˆå·¦ï¼‰å’Œæ–¹å·®ï¼ˆå³ï¼‰

æ¥ä¸‹æ¥çš„ä¸¤ä¸ªå›¾è¡¨æ˜¾ç¤ºäº†æ¢¯åº¦çš„å¤§å°ï¼ˆL2 èŒƒæ•°ï¼‰å’Œæœ€å¤§å€¼ã€‚æ‰€æœ‰å€¼éƒ½ç»è¿‡çª—å£ 20 å¹³æ»‘å¤„ç†ï¼š

![PIC](img/B22150_12_03.png)

å›¾ 12.3ï¼šæ¢¯åº¦çš„ L2 èŒƒæ•°ï¼ˆå·¦ï¼‰å’Œæœ€å¤§å€¼ï¼ˆå³ï¼‰

å¦‚æ‚¨æ‰€è§ï¼Œå¸¦æœ‰åŸºå‡†çº¿çš„ç‰ˆæœ¬çš„æ–¹å·®æ¯”æ²¡æœ‰åŸºå‡†çº¿çš„ç‰ˆæœ¬ä½ä¸¤ä¸ªåˆ°ä¸‰ä¸ªæ•°é‡çº§ï¼Œè¿™æœ‰åŠ©äºç³»ç»Ÿæ›´å¿«åœ°æ”¶æ•›ã€‚

# ä¼˜åŠ¿è¡Œä¸ºè€…-è¯„è®ºå‘˜ï¼ˆA2Cï¼‰

å‡å°‘æ–¹å·®çš„ä¸‹ä¸€æ­¥æ˜¯ä½¿æˆ‘ä»¬çš„åŸºå‡†çŠ¶æ€ä¾èµ–æ€§ï¼ˆè¿™æ˜¯ä¸ªå¥½ä¸»æ„ï¼Œå› ä¸ºä¸åŒçš„çŠ¶æ€å¯èƒ½å…·æœ‰éå¸¸ä¸åŒçš„åŸºå‡†ï¼‰ã€‚å®é™…ä¸Šï¼Œä¸ºäº†å†³å®šæŸä¸ªçŠ¶æ€ä¸‹æŸä¸ªåŠ¨ä½œçš„é€‚ç”¨æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨è¯¥åŠ¨ä½œçš„æŠ˜æ‰£æ€»å¥–åŠ±ã€‚ç„¶è€Œï¼Œæ€»å¥–åŠ±æœ¬èº«å¯ä»¥è¡¨ç¤ºä¸ºçŠ¶æ€çš„å€¼åŠ ä¸ŠåŠ¨ä½œçš„ä¼˜åŠ¿ï¼šQ(s,a) = V (s) + A(s,a)ã€‚ä½ åœ¨ç¬¬å…«ç« ä¸­è§è¿‡è¿™ç§æ–¹æ³•ï¼Œå½“æ—¶æˆ‘ä»¬è®¨è®ºäº† DQN çš„ä¿®æ”¹ï¼Œç‰¹åˆ«æ˜¯å¯¹æŠ— DQNã€‚

é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½ç”¨ V(s) ä½œä¸ºåŸºå‡†å‘¢ï¼Ÿåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ¢¯åº¦è§„æ¨¡å°†åªæ˜¯ä¼˜åŠ¿ A(s,a)ï¼Œè¡¨ç¤ºæ­¤åŠ¨ä½œç›¸å¯¹äºå¹³å‡çŠ¶æ€å€¼çš„æ”¹å–„ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åšï¼Œè¿™å¯¹äºæ”¹è¿›ç­–ç•¥æ¢¯åº¦æ–¹æ³•æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„ä¸»æ„ã€‚å”¯ä¸€çš„é—®é¢˜æ˜¯æˆ‘ä»¬ä¸çŸ¥é“éœ€è¦ä»æŠ˜æ‰£æ€»å¥–åŠ± Q(s,a) ä¸­å‡å»çš„çŠ¶æ€å€¼ V(s)ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨å¦ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå®ƒå°†ä¸ºæ¯ä¸ªè§‚æµ‹å€¼è¿‘ä¼¼ V(s)ã€‚ä¸ºäº†è®­ç»ƒå®ƒï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨åœ¨ DQN æ–¹æ³•ä¸­ä½¿ç”¨çš„ç›¸åŒè®­ç»ƒè¿‡ç¨‹ï¼šæˆ‘ä»¬å°†æ‰§è¡Œè´å°”æ›¼æ­¥éª¤ï¼Œç„¶åæœ€å°åŒ–å‡æ–¹è¯¯å·®æ¥æ”¹è¿› V(s) çš„è¿‘ä¼¼ã€‚

å½“æˆ‘ä»¬çŸ¥é“ä»»ä½•çŠ¶æ€çš„å€¼ï¼ˆæˆ–è‡³å°‘æœ‰ä¸€äº›è¿‘ä¼¼å€¼ï¼‰æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å®ƒæ¥è®¡ç®—ç­–ç•¥æ¢¯åº¦ï¼Œå¹¶æ›´æ–°æˆ‘ä»¬çš„ç­–ç•¥ç½‘ç»œï¼Œä»¥å¢åŠ å…·æœ‰è‰¯å¥½ä¼˜åŠ¿å€¼çš„åŠ¨ä½œçš„æ¦‚ç‡ï¼Œå¹¶å‡å°‘å…·æœ‰ä¸è‰¯ä¼˜åŠ¿å€¼çš„åŠ¨ä½œçš„æœºä¼šã€‚ç­–ç•¥ç½‘ç»œï¼ˆè¿”å›åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒï¼‰è¢«ç§°ä¸ºæ¼”å‘˜ï¼ˆactorï¼‰ï¼Œå› ä¸ºå®ƒå‘Šè¯‰æˆ‘ä»¬è¯¥åšä»€ä¹ˆã€‚å¦ä¸€ä¸ªç½‘ç»œç§°ä¸ºè¯„è®ºå‘˜ï¼ˆcriticï¼‰ï¼Œå› ä¸ºå®ƒé€šè¿‡è¿”å› V(s) è®©æˆ‘ä»¬äº†è§£æˆ‘ä»¬çš„åŠ¨ä½œæœ‰å¤šå¥½ã€‚è¿™ç§æ”¹è¿›æœ‰ä¸€ä¸ªç‹¬ç«‹çš„åç§°ï¼Œç§°ä¸ºä¼˜åŠ¿æ¼”å‘˜-è¯„è®ºå‘˜æ–¹æ³•ï¼Œé€šå¸¸ç¼©å†™ä¸º A2Cã€‚å›¾ 12.4 æ˜¯å…¶æ¶æ„çš„ç¤ºæ„å›¾ï¼š

![PVoalliuceynneett OÏ€Vbs((((eacrasrci|s)vtt)aoictr))ions ](img/B22150_12_04.png)

å›¾ 12.4ï¼šA2C æ¶æ„

å®é™…ä¸Šï¼Œç­–ç•¥ç½‘ç»œå’Œå€¼ç½‘ç»œéƒ¨åˆ†é‡å ï¼Œä¸»è¦æ˜¯å‡ºäºæ•ˆç‡å’Œæ”¶æ•›æ€§çš„è€ƒè™‘ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç­–ç•¥å’Œå€¼è¢«å®ç°ä¸ºç½‘ç»œçš„ä¸åŒâ€œå¤´éƒ¨â€ï¼Œå®ƒä»¬ä»å…±äº«çš„ä¸»ä½“è·å–è¾“å‡ºï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒå’Œä¸€ä¸ªè¡¨ç¤ºçŠ¶æ€å€¼çš„å•ä¸€æ•°å­—ã€‚

è¿™æœ‰åŠ©äºä¸¤ä¸ªç½‘ç»œå…±äº«ä½å±‚æ¬¡ç‰¹å¾ï¼ˆä¾‹å¦‚ Atari ä»£ç†ä¸­çš„å·ç§¯æ»¤æ³¢å™¨ï¼‰ï¼Œä½†ä»¥ä¸åŒçš„æ–¹å¼å°†å®ƒä»¬ç»“åˆèµ·æ¥ã€‚ä¸‹å›¾å±•ç¤ºäº†è¿™ç§æ¶æ„ï¼š

![CPVooamllmiuocenynneetntet OÏ€Vbs((((e(acrasrbci|s)vott)adoictyr))io)ns ](img/B22150_12_05.png)

å›¾ 12.5ï¼šå¸¦æœ‰å…±äº«ç½‘ç»œä¸»ä½“çš„ A2C æ¶æ„

ä»è®­ç»ƒçš„è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

1.  ç”¨éšæœºå€¼åˆå§‹åŒ–ç½‘ç»œå‚æ•°ï¼Œğœƒã€‚

1.  åœ¨ç¯å¢ƒä¸­æ‰§è¡Œ N æ­¥ï¼Œä½¿ç”¨å½“å‰ç­–ç•¥ Ï€[ğœƒ]ï¼Œå¹¶ä¿å­˜çŠ¶æ€ s[t]ã€åŠ¨ä½œ a[t] å’Œå¥–åŠ± r[t]ã€‚

1.  å¦‚æœåˆ°è¾¾å›åˆç»“æŸæˆ– V ğœƒï¼Œåˆ™è®¾ç½® R â† 0ã€‚

1.  å¯¹äº i = t âˆ’ 1â€¦t[start]ï¼ˆæ³¨æ„æ­¥éª¤æ˜¯é€†å‘å¤„ç†çš„ï¼‰ï¼š

    +   R â†r[i] + Î³R

    +   ç´¯ç§¯ç­–ç•¥æ¢¯åº¦ï¼š

        ![Ï€ (a |s) = P[At = a|St = s] ](img/eq45.png)

    +   ç´¯ç§¯å€¼æ¢¯åº¦ï¼š

        ![Ï€ (a |s) = P[At = a|St = s] ](img/eq46.png)

1.  ä½¿ç”¨ç´¯ç§¯çš„æ¢¯åº¦æ›´æ–°ç½‘ç»œå‚æ•°ï¼Œæ²¿ç€ç­–ç•¥æ¢¯åº¦ âˆ‚ğœƒ[Ï€] çš„æ–¹å‘ç§»åŠ¨ï¼Œåæ–¹å‘åˆ™æ˜¯å€¼æ¢¯åº¦ âˆ‚ğœƒ[v]ã€‚

1.  ä»ç¬¬ 2 æ­¥å¼€å§‹é‡å¤ï¼Œç›´åˆ°æ”¶æ•›ã€‚

è¿™ä¸ªç®—æ³•åªæ˜¯ä¸€ä¸ªå¤§è‡´çš„æ¡†æ¶ï¼Œç±»ä¼¼äºé€šå¸¸åœ¨ç ”ç©¶è®ºæ–‡ä¸­æ‰“å°çš„å†…å®¹ã€‚å®é™…ä¸Šï¼Œå¯èƒ½ä¼šä½¿ç”¨ä¸€äº›æ‰©å±•æ–¹æ³•æ¥æé«˜è¯¥æ–¹æ³•çš„ç¨³å®šæ€§ï¼š

+   é€šå¸¸ä¼šæ·»åŠ ä¸€ä¸ªç†µå¥–åŠ±æ¥æ”¹å–„æ¢ç´¢ã€‚è¿™é€šå¸¸è¡¨ç°ä¸ºä¸€ä¸ªç†µå€¼ï¼Œæ·»åŠ åˆ°æŸå¤±å‡½æ•°ä¸­ï¼š

    ![Ï€ (a |s) = P[At = a|St = s] ](img/eq47.png)

    å½“æ¦‚ç‡åˆ†å¸ƒæ˜¯å‡åŒ€æ—¶ï¼Œè¿™ä¸ªå‡½æ•°æœ‰ä¸€ä¸ªæœ€å°å€¼ï¼Œå› æ­¤é€šè¿‡å°†å…¶æ·»åŠ åˆ°æŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è®©æ™ºèƒ½ä½“é¿å…å¯¹è‡ªå·±çš„åŠ¨ä½œè¿‡äºç¡®å®šã€‚Î² çš„å€¼æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨æ¥ç¼©æ”¾ç†µå¥–åŠ±å¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜å…ˆè¿›è¡Œæ¢ç´¢ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œå®ƒæ˜¯å¸¸æ•°æˆ–åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çº¿æ€§é€’å‡çš„ã€‚

+   æ¢¯åº¦ç´¯ç§¯é€šå¸¸ä½œä¸ºä¸€ä¸ªæŸå¤±å‡½æ•°å®ç°ï¼Œç»“åˆäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼šç­–ç•¥æŸå¤±ã€å€¼æŸå¤±å’Œç†µæŸå¤±ã€‚ä½ åº”è¯¥æ³¨æ„è¿™äº›æŸå¤±çš„ç¬¦å·ï¼Œå› ä¸ºç­–ç•¥æ¢¯åº¦æ˜¾ç¤ºäº†ç­–ç•¥æ”¹è¿›çš„æ–¹å‘ï¼Œä½†å€¼æŸå¤±å’Œç†µæŸå¤±åº”è¯¥æœ€å°åŒ–ã€‚

+   ä¸ºäº†æé«˜ç¨³å®šæ€§ï¼Œå€¼å¾—ä½¿ç”¨å¤šä¸ªç¯å¢ƒï¼Œæä¾›å¹¶è¡Œçš„è§‚å¯Ÿæ•°æ®ï¼ˆå½“ä½ æœ‰å¤šä¸ªç¯å¢ƒæ—¶ï¼Œè®­ç»ƒæ‰¹æ¬¡å°†ä»è¿™äº›è§‚å¯Ÿæ•°æ®ä¸­åˆ›å»ºï¼‰ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« åç»­è®¨è®º A3C æ–¹æ³•æ—¶æ¢è®¨å‡ ç§å®ç°æ–¹å¼ã€‚

å‰é¢æ–¹æ³•çš„ç‰ˆæœ¬ï¼Œé€šè¿‡å¹¶è¡Œè¿è¡Œå¤šä¸ªç¯å¢ƒæ¥å®ç°ï¼Œç§°ä¸ºä¼˜åŠ¿å¼‚æ­¥æ¼”å‘˜-è¯„è®ºå‘˜æ–¹æ³•ï¼Œä¹Ÿè¢«ç§°ä¸º A3Cã€‚A3C æ–¹æ³•å°†åœ¨åç»­è®¨è®ºï¼Œä½†ç°åœ¨ï¼Œæˆ‘ä»¬å…ˆå®ç° A2Cã€‚

## A2C åœ¨ Pong ä¸­çš„åº”ç”¨

åœ¨ä¸Šä¸€ç« ä¸­ï¼Œä½ çœ‹åˆ°äº†ä¸€æ¬¡ï¼ˆä¸å¤ªæˆåŠŸçš„ï¼‰å°è¯•ï¼Œä½¿ç”¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•è§£å†³æˆ‘ä»¬æœ€å–œæ¬¢çš„ Pong ç¯å¢ƒã€‚è®©æˆ‘ä»¬å†å°è¯•ä¸€ä¸‹ï¼Œæ‰‹å¤´æœ‰æ¼”å‘˜-è¯„è®ºå‘˜æ–¹æ³•ã€‚å®Œæ•´çš„æºä»£ç å¯ä»¥åœ¨ Chapter12/02_pong_a2c.py ä¸­æ‰¾åˆ°ã€‚

æˆ‘ä»¬åƒå¾€å¸¸ä¸€æ ·ï¼Œä»å®šä¹‰è¶…å‚æ•°å¼€å§‹ï¼ˆçœç•¥äº†å¯¼å…¥éƒ¨åˆ†ï¼‰ï¼š

```py
GAMMA = 0.99 
LEARNING_RATE = 0.001 
ENTROPY_BETA = 0.01 
BATCH_SIZE = 128 
NUM_ENVS = 50 

REWARD_STEPS = 4 
CLIP_GRAD = 0.1
```

è¿™äº›å€¼å¹¶æœªè°ƒæ•´ï¼Œè¿™éƒ¨åˆ†ç•™ç»™è¯»è€…è‡ªå·±å®Œæˆã€‚è¿™é‡Œæœ‰ä¸€ä¸ªæ–°çš„å€¼ï¼šCLIP_GRADã€‚è¿™ä¸ªè¶…å‚æ•°æŒ‡å®šäº†æ¢¯åº¦è£å‰ªçš„é˜ˆå€¼ï¼ŒåŸºæœ¬ä¸Šå®ƒé˜²æ­¢äº†åœ¨ä¼˜åŒ–é˜¶æ®µæ¢¯åº¦å˜å¾—è¿‡å¤§ï¼Œä»è€Œä½¿æˆ‘ä»¬çš„ç­–ç•¥è¿‡äºåç¦»ã€‚è£å‰ªæ˜¯ä½¿ç”¨ PyTorch çš„åŠŸèƒ½å®ç°çš„ï¼Œä½†è¿™ä¸ªæ¦‚å¿µéå¸¸ç®€å•ï¼šå¦‚æœæ¢¯åº¦çš„ L2 èŒƒæ•°å¤§äºè¿™ä¸ªè¶…å‚æ•°ï¼Œåˆ™æ¢¯åº¦å‘é‡ä¼šè¢«è£å‰ªåˆ°è¿™ä¸ªå€¼ã€‚

REWARD_STEPS è¶…å‚æ•°ç¡®å®šæˆ‘ä»¬å°†å‘å‰èµ°å¤šå°‘æ­¥ï¼Œä»¥è¿‘ä¼¼æ¯ä¸ªè¡ŒåŠ¨çš„æ€»æŠ˜æ‰£å¥–åŠ±ã€‚

åœ¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¤§çº¦ 10 æ­¥ï¼Œä½†åœ¨ A2C ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æˆ‘ä»¬çš„å€¼è¿‘ä¼¼æ¥è·å¾—è¿›ä¸€æ­¥æ­¥éª¤çš„çŠ¶æ€å€¼ï¼Œå› æ­¤å‡å°‘æ­¥æ•°æ˜¯å¯ä»¥çš„ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„ç½‘ç»œæ¶æ„ï¼š

```py
class AtariA2C(nn.Module): 
    def __init__(self, input_shape: tt.Tuple[int, ...], n_actions: int): 
        super(AtariA2C, self).__init__() 

        self.conv = nn.Sequential( 
            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4), 
            nn.ReLU(), 
            nn.Conv2d(32, 64, kernel_size=4, stride=2), 
            nn.ReLU(), 
            nn.Conv2d(64, 64, kernel_size=3, stride=1), 
            nn.ReLU(), 
            nn.Flatten(), 
        ) 

        size = self.conv(torch.zeros(1, *input_shape)).size()[-1] 
        self.policy = nn.Sequential( 
            nn.Linear(size, 512), 
            nn.ReLU(), 
            nn.Linear(512, n_actions) 
        ) 
        self.value = nn.Sequential( 
            nn.Linear(size, 512), 
            nn.ReLU(), 
            nn.Linear(512, 1) 
        )
```

å®ƒå…·æœ‰å…±äº«çš„å·ç§¯ä½“å’Œä¸¤ä¸ªå¤´éƒ¨ï¼šç¬¬ä¸€ä¸ªè¿”å›åŒ…å«æˆ‘ä»¬è¡ŒåŠ¨æ¦‚ç‡åˆ†å¸ƒçš„ç­–ç•¥ï¼Œç¬¬äºŒä¸ªå¤´éƒ¨è¿”å›ä¸€ä¸ªå•ä¸€æ•°å­—ï¼Œè¯¥æ•°å­—å°†è¿‘ä¼¼äºçŠ¶æ€çš„å€¼ã€‚å®ƒå¯èƒ½çœ‹èµ·æ¥ä¸æˆ‘ä»¬åœ¨ç¬¬å…«ç« ä¸­æåˆ°çš„å¯¹æŠ—æ€§ DQN æ¶æ„ç›¸ä¼¼ï¼Œä½†æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹ä¸åŒã€‚

ç½‘ç»œçš„å‰å‘ä¼ é€’è¿”å›ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå¼ é‡çš„å…ƒç»„â€”â€”ç­–ç•¥å’Œå€¼ï¼š

```py
 def forward(self, x: torch.ByteTensor) -> tt.Tuple[torch.Tensor, torch.Tensor]: 
        xx = x / 255 
        conv_out = self.conv(xx) 
        return self.policy(conv_out), self.value(conv_out)
```

ç°åœ¨æˆ‘ä»¬éœ€è¦è®¨è®ºä¸€ä¸ªé‡è¦çš„å¤§å‡½æ•°ï¼Œå®ƒæ¥å—ç¯å¢ƒè½¬ç§»çš„æ‰¹æ¬¡å¹¶è¿”å›ä¸‰ä¸ªå¼ é‡ï¼šçŠ¶æ€æ‰¹æ¬¡ã€é‡‡å–çš„è¡ŒåŠ¨æ‰¹æ¬¡å’Œä½¿ç”¨å…¬å¼ Q(s,a) = âˆ‘ [i=0]^(Nâˆ’1)Î³^ir[i] + Î³^NV(s[N])è®¡ç®—çš„ Q å€¼æ‰¹æ¬¡ã€‚è¿™ä¸ª Q å€¼å°†åœ¨ä¸¤ä¸ªåœ°æ–¹ä½¿ç”¨ï¼šè®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æŸå¤±ä»¥æ”¹å–„å€¼çš„è¿‘ä¼¼ï¼Œå°±åƒ DQN ä¸€æ ·ï¼›ä»¥åŠè®¡ç®—è¡ŒåŠ¨çš„ä¼˜åŠ¿ã€‚

```py
def unpack_batch(batch: tt.List[ExperienceFirstLast], net: AtariA2C, 
                 device: torch.device, gamma: float, reward_steps: int): 
    states = [] 
    actions = [] 
    rewards = [] 
    not_done_idx = [] 
    last_states = [] 
    for idx, exp in enumerate(batch): 
        states.append(np.asarray(exp.state)) 
        actions.append(int(exp.action)) 
        rewards.append(exp.reward) 
        if exp.last_state is not None: 
            not_done_idx.append(idx) 
            last_states.append(np.asarray(exp.last_state))
```

ä¸€å¼€å§‹ï¼Œæˆ‘ä»¬åªéœ€è¦éå†æˆ‘ä»¬çš„è½¬ç§»æ‰¹æ¬¡å¹¶å°†å®ƒä»¬çš„å­—æ®µå¤åˆ¶åˆ°åˆ—è¡¨ä¸­ã€‚æ³¨æ„ï¼Œå¥–åŠ±å€¼å·²ç»åŒ…å«äº† REWARD_STEPS çš„æŠ˜æ‰£å¥–åŠ±ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº† ptan.ExperienceSourceFirstLast ç±»ã€‚æˆ‘ä»¬è¿˜éœ€è¦å¤„ç†å›åˆç»“æŸçš„æƒ…å†µï¼Œå¹¶è®°ä½éç»ˆæ­¢å›åˆçš„æ‰¹æ¬¡æ¡ç›®ç´¢å¼•ã€‚

åœ¨ä»¥ä¸‹ä»£ç ä¸­ï¼Œæˆ‘ä»¬å°†æ”¶é›†åˆ°çš„çŠ¶æ€å’ŒåŠ¨ä½œè½¬æ¢ä¸º PyTorch å¼ é‡ï¼Œå¹¶æ ¹æ®éœ€è¦å°†å…¶å¤åˆ¶åˆ°å›¾å½¢å¤„ç†å•å…ƒï¼ˆGPUï¼‰ä¸­ï¼š

```py
 states_t = torch.FloatTensor(np.asarray(states)).to(device) 
    actions_t = torch.LongTensor(actions).to(device)
```

åœ¨è¿™é‡Œï¼Œå¯¹ np.asarray()çš„é¢å¤–è°ƒç”¨å¯èƒ½çœ‹èµ·æ¥æ˜¯å¤šä½™çš„ï¼Œä½†æ²¡æœ‰å®ƒï¼Œå¼ é‡åˆ›å»ºçš„æ€§èƒ½ä¼šé™ä½ 5 åˆ° 10 å€ã€‚è¿™åœ¨ PyTorch ä¸­è¢«ç§°ä¸º[é—®é¢˜ #13918](https://github.com/pytorch/pytorch/issues/13918)ï¼Œå¹¶ä¸”åœ¨å†™ä½œæ—¶å°šæœªè§£å†³ï¼Œå› æ­¤ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯ä¼ é€’ä¸€ä¸ªå•ä¸€çš„ NumPy æ•°ç»„ï¼Œè€Œä¸æ˜¯æ•°ç»„åˆ—è¡¨ã€‚

å‡½æ•°çš„å…¶ä½™éƒ¨åˆ†è®¡ç®— Q å€¼ï¼Œè€ƒè™‘äº†ç»ˆæ­¢å›åˆçš„æƒ…å†µï¼š

```py
 rewards_np = np.array(rewards, dtype=np.float32) 
    if not_done_idx: 
        last_states_t = torch.FloatTensor( 
            np.asarray(last_states)).to(device) 
        last_vals_t = net(last_states_t)[1] 
        last_vals_np = last_vals_v.data.cpu().numpy()[:, 0] 
        last_vals_np *= gamma ** reward_steps 
        rewards_np[not_done_idx] += last_vals_np
```

ä¸Šé¢çš„ä»£ç å‡†å¤‡äº†å˜é‡ï¼Œå­˜å‚¨æˆ‘ä»¬è½¬ç§»é“¾ä¸­çš„æœ€åä¸€ä¸ªçŠ¶æ€ï¼Œå¹¶æŸ¥è¯¢æˆ‘ä»¬çš„ç½‘ç»œä»¥è·å– V(s)çš„è¿‘ä¼¼å€¼ã€‚ç„¶åï¼Œå°†è¯¥å€¼ä¹˜ä»¥æŠ˜æ‰£å› å­å¹¶åŠ ä¸Šå³æ—¶å¥–åŠ±ã€‚

åœ¨å‡½æ•°çš„æœ«å°¾ï¼Œæˆ‘ä»¬å°† Q å€¼æ‰“åŒ…åˆ°å¼ é‡ä¸­å¹¶è¿”å›ï¼š

```py
 ref_vals_t = torch.FloatTensor(rewards_np).to(device) 
    return states_t, actions_t, ref_vals_t
```

åœ¨ä»¥ä¸‹ä»£ç ä¸­ï¼Œä½ å¯ä»¥æ³¨æ„åˆ°ä¸€ç§æ–°çš„åˆ›å»ºç¯å¢ƒçš„æ–¹å¼ï¼Œä½¿ç”¨ç±» gym.vector.SyncVectorEnvï¼Œå®ƒä¼ å…¥ä¸€ä¸ªåŒ…å«åˆ›å»ºåº•å±‚ç¯å¢ƒçš„ lambda å‡½æ•°çš„åˆ—è¡¨ï¼š

```py
if __name__ == "__main__": 
    parser = argparse.ArgumentParser() 
    parser.add_argument("--dev", default="cpu", help="Device to use, default=cpu") 
    parser.add_argument("--use-async", default=False, action=â€™store_trueâ€™, 
                        help="Use async vector env (A3C mode)") 
    parser.add_argument("-n", "--name", required=True, help="Name of the run") 
    args = parser.parse_args() 
    device = torch.device(args.dev) 

    env_factories = [ 
        lambda: ptan.common.wrappers.wrap_dqn(gym.make("PongNoFrameskip-v4")) 
        for _ in range(NUM_ENVS) 
    ] 
    if args.use_async: 
        env = gym.vector.AsyncVectorEnv(env_factories) 
    else: 
        env = gym.vector.SyncVectorEnv(env_factories) 
    writer = SummaryWriter(comment="-pong-a2c_" + args.name)
```

ç±» gym.vector.SyncVectorEnv æ˜¯ Gymnasium æä¾›çš„ï¼Œå…è®¸å°†å¤šä¸ªç¯å¢ƒå°è£…æˆä¸€ä¸ªå•ä¸€çš„â€œå‘é‡åŒ–â€ç¯å¢ƒã€‚åº•å±‚ç¯å¢ƒå¿…é¡»å…·æœ‰ç›¸åŒçš„åŠ¨ä½œç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ï¼Œè¿™ä½¿å¾—å‘é‡åŒ–ç¯å¢ƒèƒ½å¤Ÿæ¥å—ä¸€ç»„åŠ¨ä½œå¹¶è¿”å›ä¸€æ‰¹è§‚å¯Ÿå’Œå¥–åŠ±ã€‚ä½ å¯ä»¥åœ¨ Gymnasium æ–‡æ¡£ä¸­æ‰¾åˆ°æ›´å¤šç»†èŠ‚ï¼š[`gymnasium.farama.org/api/vector/`](https://gymnasium.farama.org/api/vector/)ã€‚

åŒæ­¥å‘é‡åŒ–ç¯å¢ƒï¼ˆSyncVectorEnv ç±»ï¼‰å‡ ä¹ä¸æˆ‘ä»¬åœ¨ç¬¬ä¹ç« â€œå¤šä¸ªç¯å¢ƒâ€éƒ¨åˆ†ä¸­ä½¿ç”¨çš„ä¼˜åŒ–å®Œå…¨ç›¸åŒï¼Œå½“æ—¶æˆ‘ä»¬å°†å¤šä¸ª gym ç¯å¢ƒä¼ å…¥ç»éªŒæºä»¥æé«˜ DQN è®­ç»ƒçš„æ€§èƒ½ã€‚

ä½†åœ¨å‘é‡åŒ–ç¯å¢ƒçš„æƒ…å†µä¸‹ï¼Œå¿…é¡»ä½¿ç”¨ä¸åŒçš„ç»éªŒæºç±»ï¼šVectorExperienceSourceFirstLastï¼Œå®ƒè€ƒè™‘äº†å‘é‡åŒ–ï¼Œå¹¶ä¼˜åŒ–äº†ä»£ç†å¯¹è§‚å¯Ÿçš„åº”ç”¨ã€‚ä»å¤–éƒ¨çœ‹ï¼Œè¿™ä¸ªç»éªŒæºçš„æ¥å£ä¸ä¹‹å‰å®Œå…¨ç›¸åŒã€‚

å‘½ä»¤è¡Œå‚æ•°--use-asyncï¼ˆå®ƒå°†æˆ‘ä»¬çš„åŒ…è£…ç±»ä» SyncVectorEnv åˆ‡æ¢ä¸º AsyncVectorEnvï¼‰ç›®å‰ä¸ç›¸å…³â€”â€”æˆ‘ä»¬ç¨åä¼šä½¿ç”¨å®ƒï¼Œåœ¨è®¨è®º A3C æ–¹æ³•æ—¶ã€‚

ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºç½‘ç»œã€ä»£ç†å’Œç»éªŒæºï¼š

```py
 net = common.AtariA2C(env.single_observation_space.shape, 
                          env.single_action_space.n).to(device) 
    print(net) 

    agent = ptan.agent.PolicyAgent(lambda x: net(x)[0], apply_softmax=True, device=device) 
    exp_source = VectorExperienceSourceFirstLast( 
        env, agent, gamma=GAMMA, steps_count=REWARD_STEPS) 

    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)
```

è¿™é‡Œæœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„ç»†èŠ‚æ˜¯å°† eps å‚æ•°ä¼ é€’ç»™ä¼˜åŒ–å™¨ã€‚å¦‚æœä½ ç†Ÿæ‚‰ Adam ç®—æ³•ï¼Œä½ å¯èƒ½çŸ¥é“ epsilon æ˜¯ä¸€ä¸ªåŠ åˆ°åˆ†æ¯ä¸Šçš„å°æ•°ï¼Œç”¨æ¥é˜²æ­¢é›¶é™¤é”™è¯¯ã€‚é€šå¸¸ï¼Œè¿™ä¸ªå€¼è®¾ç½®ä¸ºä¸€äº›å°æ•°å­—ï¼Œå¦‚ 10^(-8)æˆ– 10^(-10)ï¼Œä½†åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œè¿™äº›å€¼å¤ªå°äº†ã€‚æˆ‘æ²¡æœ‰ä¸¥æ ¼çš„æ•°å­¦è§£é‡Šï¼Œä½†ä½¿ç”¨é»˜è®¤çš„ epsilon å€¼æ—¶ï¼Œæ–¹æ³•æ ¹æœ¬æ— æ³•æ”¶æ•›ã€‚å¾ˆå¯èƒ½ï¼Œé™¤ä»¥ä¸€ä¸ªå°å€¼ 10^(-8)ä¼šå¯¼è‡´æ¢¯åº¦è¿‡å¤§ï¼Œè¿™å¯¹è®­ç»ƒç¨³å®šæ€§æ¥è¯´æ˜¯è‡´å‘½çš„ã€‚

å¦ä¸€ä¸ªç»†èŠ‚æ˜¯ä½¿ç”¨ VectorExperienceSourceFirstLast è€Œä¸æ˜¯ ExperienceSourceFirstLastã€‚è¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºå‘é‡åŒ–ç¯å¢ƒå°†å¤šä¸ªæ™®é€šçš„ Atari ç¯å¢ƒå°è£…åœ¨ä¸€èµ·ã€‚å‘é‡åŒ–ç¯å¢ƒè¿˜æš´éœ²äº† single_observation_space å’Œ single_action_space è¿™ä¸¤ä¸ªå±æ€§ï¼Œå®ƒä»¬åˆ†åˆ«æ˜¯å•ä¸ªç¯å¢ƒçš„è§‚å¯Ÿç©ºé—´å’ŒåŠ¨ä½œç©ºé—´ã€‚

åœ¨è®­ç»ƒå¾ªç¯ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªåŒ…è£…å™¨ï¼š

```py
 batch = [] 

    with common.RewardTracker(writer, stop_reward=18) as tracker: 
        with TBMeanTracker(writer, batch_size=10) as tb_tracker: 
            for step_idx, exp in enumerate(exp_source): 
                batch.append(exp) 

                new_rewards = exp_source.pop_total_rewards() 
                if new_rewards: 
                    if tracker.reward(new_rewards[0], step_idx): 
                        break 

                if len(batch) < BATCH_SIZE: 
                    continue
```

ä»£ç ä¸­çš„ç¬¬ä¸€ä¸ªåŒ…è£…å™¨ä½ å·²ç»å¾ˆç†Ÿæ‚‰ï¼šcommon.RewardTrackerï¼Œå®ƒè®¡ç®—æœ€å 100 ä¸ªå›åˆçš„å¹³å‡å¥–åŠ±ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬å½“è¿™ä¸ªå¹³å‡å¥–åŠ±è¶…è¿‡æ‰€éœ€é˜ˆå€¼æ—¶ã€‚å¦ä¸€ä¸ªåŒ…è£…å™¨ TBMeanTracker æ¥è‡ª PTAN åº“ï¼Œè´Ÿè´£å°†æœ€å 10 æ­¥ä¸­æµ‹é‡çš„å‚æ•°çš„å¹³å‡å€¼å†™å…¥ TensorBoardã€‚è¿™æ˜¯éå¸¸æœ‰å¸®åŠ©çš„ï¼Œå› ä¸ºè®­ç»ƒå¯èƒ½éœ€è¦ä¸Šç™¾ä¸‡æ­¥ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›æ¯ä¸€æ­¥éƒ½å†™å…¥ TensorBoardï¼Œè€Œæ˜¯æ¯ 10 æ­¥å†™å…¥å¹³æ»‘åçš„å€¼ã€‚

ä¸‹ä¸€æ®µä»£ç è´Ÿè´£æˆ‘ä»¬è®¡ç®—æŸå¤±çš„éƒ¨åˆ†ï¼Œè¿™æ˜¯ A2C æ–¹æ³•çš„æ ¸å¿ƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ä¹‹å‰æè¿°çš„å‡½æ•°è§£åŒ…æ‰¹æ¬¡ï¼Œå¹¶è¦æ±‚ç½‘ç»œè¿”å›è¯¥æ‰¹æ¬¡çš„ç­–ç•¥å’Œå€¼ï¼š

```py
 states_t, actions_t, vals_ref_t = common.unpack_batch( 
                    batch, net, device=device, gamma=GAMMA, reward_steps=REWARD_STEPS) 
                batch.clear() 

                optimizer.zero_grad() 
                logits_t, value_t = net(states_t)
```

ç­–ç•¥ä»¥æœªå½’ä¸€åŒ–çš„å½¢å¼è¿”å›ï¼Œå› æ­¤ä¸ºäº†å°†å…¶è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬éœ€è¦å¯¹å…¶åº”ç”¨ softmaxã€‚ç”±äºç­–ç•¥æŸå¤±éœ€è¦æ¦‚ç‡åˆ†å¸ƒçš„å¯¹æ•°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ log_softmax å‡½æ•°ï¼Œè¿™æ¯”å…ˆè°ƒç”¨ softmax å†å–å¯¹æ•°æ›´åŠ ç¨³å®šã€‚

åœ¨ä»·å€¼æŸå¤±éƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¡ç®—ç½‘ç»œè¿”å›çš„å€¼ä¸æˆ‘ä»¬é€šè¿‡å±•å¼€å››æ­¥çš„è´å°”æ›¼æ–¹ç¨‹æ‰€è¿›è¡Œçš„è¿‘ä¼¼ä¹‹é—´çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼š

```py
 loss_value_t = F.mse_loss(value_t.squeeze(-1), vals_ref_t)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¡ç®—ç­–ç•¥æŸå¤±ä»¥è·å¾—ç­–ç•¥æ¢¯åº¦ï¼š

```py
 log_prob_t = F.log_softmax(logits_t, dim=1) 
                adv_t = vals_ref_t - value_t.detach() 
                log_act_t = log_prob_t[range(BATCH_SIZE), actions_t] 
                log_prob_actions_t = adv_t * log_act_t 
                loss_policy_t = -log_prob_actions_t.mean()
```

å‰ä¸¤æ­¥è·å¾—æˆ‘ä»¬ç­–ç•¥çš„æ—¥å¿—å¹¶è®¡ç®—è¡ŒåŠ¨çš„ä¼˜åŠ¿ï¼Œä¼˜åŠ¿ A(s,a) = Q(s,a) âˆ’V (s)ã€‚è°ƒç”¨ value_t.detach() å¾ˆé‡è¦ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›å°†ç­–ç•¥æ¢¯åº¦ä¼ æ’­åˆ°æˆ‘ä»¬çš„ä»·å€¼è¿‘ä¼¼å¤´éƒ¨ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯¹é‡‡å–çš„è¡ŒåŠ¨çš„æ¦‚ç‡å–å¯¹æ•°ï¼Œå¹¶ç”¨ä¼˜åŠ¿å¯¹å…¶è¿›è¡Œç¼©æ”¾ã€‚æˆ‘ä»¬çš„ç­–ç•¥æ¢¯åº¦æŸå¤±å€¼å°†ç­‰äºè¯¥ç¼©æ”¾åçš„ç­–ç•¥å¯¹æ•°çš„è´Ÿå‡å€¼ï¼Œå› ä¸ºç­–ç•¥æ¢¯åº¦å¼•å¯¼æˆ‘ä»¬æœç€ç­–ç•¥æ”¹è¿›çš„æ–¹å‘ï¼Œä½†æŸå¤±å€¼åº”è¯¥æœ€å°åŒ–ã€‚

æˆ‘ä»¬æŸå¤±å‡½æ•°çš„æœ€åä¸€éƒ¨åˆ†æ˜¯ç†µæŸå¤±ï¼š

```py
 prob_t = F.softmax(logits_t, dim=1) 
                entropy_loss_t = ENTROPY_BETA * (prob_t * log_prob_t).sum(dim=1).mean()
```

ç†µæŸå¤±ç­‰äºæˆ‘ä»¬ç­–ç•¥çš„ç¼©æ”¾ç†µï¼Œå¹¶å–å…¶ç›¸åç¬¦å·ï¼ˆç†µçš„è®¡ç®—å…¬å¼æ˜¯ H(Ï€) = âˆ’âˆ‘ Ï€ log Ï€ï¼‰ã€‚

åœ¨æ¥ä¸‹æ¥çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—å¹¶æå–æˆ‘ä»¬ç­–ç•¥çš„æ¢¯åº¦ï¼Œè¿™äº›æ¢¯åº¦å°†ç”¨äºè¿½è¸ªæœ€å¤§æ¢¯åº¦ã€å…¶æ–¹å·®å’Œ L2 èŒƒæ•°ï¼š

```py
 loss_policy_t.backward(retain_graph=True) 
                grads = np.concatenate([ 
                    p.grad.data.cpu().numpy().flatten() 
                    for p in net.parameters() if p.grad is not None 
                ])
```

ä½œä¸ºè®­ç»ƒçš„æœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬åå‘ä¼ æ’­ç†µæŸå¤±å’Œä»·å€¼æŸå¤±ï¼Œè£å‰ªæ¢¯åº¦ï¼Œå¹¶è¦æ±‚ä¼˜åŒ–å™¨æ›´æ–°ç½‘ç»œï¼š

```py
 loss_v = entropy_loss_t + loss_value_t 
                loss_v.backward() 
                nn_utils.clip_grad_norm_(net.parameters(), CLIP_GRAD) 
                optimizer.step() 
                loss_v += loss_policy_t
```

åœ¨è®­ç»ƒå¾ªç¯çš„æœ€åï¼Œæˆ‘ä»¬è¿½è¸ªæ‰€æœ‰éœ€è¦åœ¨ TensorBoard ä¸­ç›‘æ§çš„å€¼ï¼š

```py
 tb_tracker.track("advantage", adv_t, step_idx) 
                tb_tracker.track("values", value_t, step_idx) 
                tb_tracker.track("batch_rewards", vals_ref_t, step_idx) 
                tb_tracker.track("loss_entropy", entropy_loss_t, step_idx) 
                tb_tracker.track("loss_policy", loss_policy_t, step_idx) 
                tb_tracker.track("loss_value", loss_value_t, step_idx) 
                tb_tracker.track("loss_total", loss_v, step_idx) 
                tb_tracker.track("grad_l2", np.sqrt(np.mean(np.square(grads))), step_idx) 
                tb_tracker.track("grad_max", np.max(np.abs(grads)), step_idx) 
                tb_tracker.track("grad_var", np.var(grads), step_idx)
```

æœ‰å¾ˆå¤šå€¼éœ€è¦ç›‘æ§ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­è®¨è®ºå®ƒä»¬ã€‚

## ç»“æœ

è¦å¼€å§‹è®­ç»ƒï¼Œè¯·è¿è¡Œ 02_pong_a2c.py å¹¶ä½¿ç”¨ --devï¼ˆè¡¨ç¤ºä½¿ç”¨ GPUï¼‰å’Œ -n é€‰é¡¹ï¼ˆä¸º TensorBoard æä¾›ä¸€ä¸ªè¿è¡Œåç§°ï¼‰ï¼š

```py
Chapter12$ ./02_pong_a2c.py --dev cuda -n tt 
A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7) 
[Powered by Stella] 
AtariA2C( 
Â Â (conv): Sequential( 
Â Â Â (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4)) 
Â Â Â (1): ReLU() 
Â Â Â (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2)) 
Â Â Â (3): ReLU() 
Â Â Â (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1)) 
Â Â Â (5): ReLU() 
Â Â Â (6): Flatten(start_dim=1, end_dim=-1) 
Â Â ) 
Â Â (policy): Sequential( 
Â Â Â (0): Linear(in_features=3136, out_features=512, bias=True) 
Â Â Â (1): ReLU() 
Â Â Â (2): Linear(in_features=512, out_features=6, bias=True) 
Â Â ) 
Â Â (value): Sequential( 
Â Â Â (0): Linear(in_features=3136, out_features=512, bias=True) 
Â Â Â (1): ReLU() 
Â Â Â (2): Linear(in_features=512, out_features=1, bias=True) 
Â Â ) 
) 
37850: done 1 games, mean reward -21.000, speed 1090.79 f/s 
39250: done 2 games, mean reward -21.000, speed 1111.24 f/s 
39550: done 3 games, mean reward -21.000, speed 1118.06 f/s 
40000: done 4 games, mean reward -21.000, speed 1083.18 f/s 
40300: done 5 games, mean reward -21.000, speed 1141.46 f/s 
40750: done 6 games, mean reward -21.000, speed 1077.44 f/s 
40850: done 7 games, mean reward -21.000, speed 940.09 f/s 
...
```

ä½œä¸ºè­¦å‘Šï¼Œè®­ç»ƒè¿‡ç¨‹æ¯”è¾ƒæ¼«é•¿ã€‚ä½¿ç”¨åŸå§‹è¶…å‚æ•°ï¼Œå®ƒå¤§çº¦éœ€è¦ 1000 ä¸‡å¸§æ¥è§£å†³é—®é¢˜ï¼Œå¤§çº¦åœ¨ GPU ä¸Šéœ€è¦ä¸‰ä¸ªå°æ—¶ã€‚

æœ¬ç« åé¢ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹ A2C æ–¹æ³•çš„å¼‚æ­¥ç‰ˆæœ¬ï¼Œå®ƒåœ¨ä¸€ä¸ªå•ç‹¬çš„è¿›ç¨‹ä¸­æ‰§è¡Œç¯å¢ƒï¼ˆè¿™æé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ€§èƒ½ï¼‰ã€‚ä½†é¦–å…ˆï¼Œè®©æˆ‘ä»¬é›†ä¸­å…³æ³¨ TensorBoard ä¸­çš„å›¾è¡¨ã€‚

å¥–åŠ±åŠ¨æ€æ¯”ä¸Šä¸€ç« çš„ç¤ºä¾‹è¦å¥½å¾—å¤šï¼š

![PIC](img/B22150_12_06.png)

å›¾Â 12.6ï¼šå¹³æ»‘å¥–åŠ±ï¼ˆå·¦ä¾§ï¼‰å’Œå¹³å‡æ‰¹æ¬¡å€¼ï¼ˆå³ä¾§ï¼‰

å·¦ä¾§çš„å›¾æ˜¯è¿‡å» 100 ä¸ªè®­ç»ƒå›åˆçš„å¹³å‡å¥–åŠ±ã€‚å³ä¾§çš„å›¾ï¼Œâ€œæ‰¹æ¬¡å€¼â€ï¼Œå±•ç¤ºäº†ä½¿ç”¨è´å°”æ›¼æ–¹ç¨‹è¿‘ä¼¼çš„ Q å€¼ä»¥åŠ Q è¿‘ä¼¼çš„æ•´ä½“æ­£å‘åŠ¨æ€ã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹åœ¨æ—¶é—´ä¸ŠåŸºæœ¬ä¸Šæ˜¯æŒç»­æ”¹è¿›çš„ã€‚

æ¥ä¸‹æ¥çš„å››ä¸ªå›¾ä¸æˆ‘ä»¬çš„æŸå¤±ç›¸å…³ï¼ŒåŒ…å«äº†å„ä¸ªæŸå¤±ç»„ä»¶å’Œæ€»æŸå¤±ï¼š

![PIC](img/B22150_12_07.png)

å›¾Â 12.7ï¼šç†µæŸå¤±ï¼ˆå·¦ä¾§ï¼‰å’Œç­–ç•¥æŸå¤±ï¼ˆå³ä¾§ï¼‰

![PIC](img/B22150_12_08.png)

å›¾Â 12.8ï¼šä»·å€¼æŸå¤±ï¼ˆå·¦ä¾§ï¼‰å’Œæ€»æŸå¤±ï¼ˆå³ä¾§ï¼‰

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¿…é¡»æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š

+   é¦–å…ˆï¼Œæˆ‘ä»¬çš„ä»·å€¼æŸå¤±ï¼ˆå›¾Â 12.8ï¼Œåœ¨å·¦ä¾§ï¼‰æŒç»­å‡å°‘ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬çš„ V(s)è¿‘ä¼¼å€¼åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾—åˆ°äº†æ”¹å–„ã€‚

+   ç¬¬äºŒä¸ªè§‚å¯Ÿç»“æœæ˜¯æˆ‘ä»¬çš„ç†µæŸå¤±ï¼ˆå›¾Â 12.7ï¼Œå·¦ä¾§ï¼‰åœ¨è®­ç»ƒçš„ä¸­æœŸå¢é•¿ï¼Œä½†å®ƒåœ¨æ€»æŸå¤±ä¸­å¹¶ä¸å ä¸»å¯¼åœ°ä½ã€‚è¿™åŸºæœ¬ä¸Šæ„å‘³ç€éšç€ç­–ç•¥å˜å¾—ä¸å†å‡åŒ€ï¼Œæˆ‘ä»¬çš„ä»£ç†åœ¨å…¶åŠ¨ä½œä¸Šå˜å¾—æ›´åŠ è‡ªä¿¡ã€‚

+   è¿™é‡Œæœ€åéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç­–ç•¥æŸå¤±ï¼ˆå›¾Â 12.7ï¼Œå³ä¾§ï¼‰å¤§å¤šæ•°æ—¶å€™åœ¨å‡å°‘ï¼Œå¹¶ä¸”ä¸æ€»æŸå¤±ç›¸å…³è”ï¼Œè¿™æ˜¯å¥½çš„ï¼Œå› ä¸ºæˆ‘ä»¬é¦–å…ˆå…³æ³¨çš„æ˜¯æˆ‘ä»¬ç­–ç•¥çš„æ¢¯åº¦ã€‚

æœ€åä¸€ç»„å›¾æ˜¾ç¤ºäº†ä¼˜åŠ¿å€¼å’Œç­–ç•¥æ¢¯åº¦åº¦é‡ï¼š

![PIC](img/B22150_12_09.png)

å›¾Â 12.9ï¼šä¼˜åŠ¿ï¼ˆå·¦ä¾§ï¼‰å’Œæ¢¯åº¦çš„ L2 èŒƒæ•°ï¼ˆå³ä¾§ï¼‰

![PIC](img/B22150_12_10.png)

å›¾Â 12.10ï¼šæ¢¯åº¦çš„æœ€å¤§å€¼ï¼ˆå·¦ä¾§ï¼‰å’Œæ¢¯åº¦æ–¹å·®ï¼ˆå³ä¾§ï¼‰

ä¼˜åŠ¿æ˜¯æˆ‘ä»¬ç­–ç•¥æ¢¯åº¦çš„å°ºåº¦ï¼Œå®ƒç­‰äº Q(s,a) âˆ’ V(s)ã€‚æˆ‘ä»¬æœŸæœ›å®ƒåœ¨ 0 å‘¨å›´æ³¢åŠ¨ï¼ˆå› ä¸ºä»å¹³å‡è€Œè¨€ï¼Œå•ä¸€åŠ¨ä½œå¯¹çŠ¶æ€å€¼çš„å½±å“ä¸åº”è¯¥å¾ˆå¤§ï¼‰ï¼Œè€Œå›¾è¡¨ç¬¦åˆæˆ‘ä»¬çš„é¢„æœŸã€‚æ¢¯åº¦å›¾è¡¨è¡¨æ˜æˆ‘ä»¬çš„æ¢¯åº¦æ—¢ä¸å¤ªå°ä¹Ÿä¸å¤ªå¤§ã€‚æ–¹å·®åœ¨è®­ç»ƒçš„æœ€åˆé˜¶æ®µï¼ˆå‰ 200 ä¸‡å¸§ï¼‰éå¸¸å°ï¼Œä½†åæ¥å¼€å§‹å¢é•¿ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„ç­–ç•¥åœ¨å‘ç”Ÿå˜åŒ–ã€‚

# å¼‚æ­¥ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå‘˜ï¼ˆA3Cï¼‰

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ‰©å±• A2C æ–¹æ³•ã€‚è¿™ä¸ªæ‰©å±•åŠ å…¥äº†çœŸæ­£çš„å¼‚æ­¥ç¯å¢ƒäº¤äº’ï¼Œè¢«ç§°ä¸ºå¼‚æ­¥ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå‘˜ï¼ˆA3Cï¼‰ã€‚è¯¥æ–¹æ³•æ˜¯ RL å®è·µè€…æœ€å¹¿æ³›ä½¿ç”¨çš„ç®—æ³•ä¹‹ä¸€ã€‚

æˆ‘ä»¬å°†ä»‹ç»ä¸¤ç§ä¸ºåŸºç¡€ A2C æ–¹æ³•æ·»åŠ å¼‚æ­¥è¡Œä¸ºçš„æ–¹å¼ï¼šæ•°æ®çº§å¹¶è¡Œå’Œæ¢¯åº¦çº§å¹¶è¡Œã€‚å®ƒä»¬æœ‰ä¸åŒçš„èµ„æºéœ€æ±‚å’Œç‰¹ç‚¹ï¼Œè¿™ä½¿å¾—å®ƒä»¬é€‚ç”¨äºä¸åŒçš„æƒ…å†µã€‚

## ç›¸å…³æ€§ä¸æ ·æœ¬æ•ˆç‡

æ”¹è¿›ç­–ç•¥æ¢¯åº¦æ–¹æ³•ç¨³å®šæ€§çš„ä¸€ç§æ–¹å¼æ˜¯ä½¿ç”¨å¤šä¸ªç¯å¢ƒå¹¶è¡Œè®­ç»ƒã€‚å…¶èƒŒåçš„åŸå› æ˜¯æˆ‘ä»¬åœ¨ç¬¬å…­ç« ä¸­è®¨è®ºçš„åŸºæœ¬é—®é¢˜ï¼Œå³æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œè¿™ç ´åäº†ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆiidï¼‰å‡è®¾ï¼Œè€Œè¿™ä¸ªå‡è®¾å¯¹äºéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ä¼˜åŒ–è‡³å…³é‡è¦ã€‚ç›¸å…³æ€§çš„è´Ÿé¢å½±å“æ˜¯æ¢¯åº¦æ–¹å·®éå¸¸å¤§ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„è®­ç»ƒæ‰¹æ¬¡åŒ…å«äº†éå¸¸ç›¸ä¼¼çš„æ ·æœ¬ï¼Œå®ƒä»¬éƒ½ä¼šå°†æˆ‘ä»¬çš„ç½‘ç»œæ¨å‘ç›¸åŒçš„æ–¹å‘ã€‚ç„¶è€Œï¼Œè¿™ä¸ªæ–¹å‘åœ¨å…¨å±€ä¸Šå¯èƒ½å®Œå…¨æ˜¯é”™è¯¯çš„ï¼Œå› ä¸ºæ‰€æœ‰è¿™äº›æ ·æœ¬å¯èƒ½æ¥è‡ªåŒä¸€ä¸ªå¹¸è¿æˆ–ä¸å¹¸è¿çš„å›åˆã€‚

ä½¿ç”¨æˆ‘ä»¬çš„æ·±åº¦ Q ç½‘ç»œï¼ˆDQNï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨é‡æ”¾ç¼“å†²åŒºä¸­å­˜å‚¨å¤§é‡çš„å†å²çŠ¶æ€ï¼Œå¹¶ä»è¿™ä¸ªç¼“å†²åŒºä¸­æŠ½å–è®­ç»ƒæ‰¹æ¬¡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœç¼“å†²åŒºè¶³å¤Ÿå¤§ï¼Œä»ä¸­éšæœºæŠ½å–çš„æ ·æœ¬å°†æ›´å¥½åœ°ä»£è¡¨çŠ¶æ€çš„æ•´ä½“åˆ†å¸ƒã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™ä¸ªæ–¹æ³•ä¸èƒ½åº”ç”¨äºç­–ç•¥æ¢¯åº¦æ–¹æ³•ã€‚è¿™æ˜¯å› ä¸ºå¤§å¤šæ•°ç­–ç•¥æ¢¯åº¦æ–¹æ³•æ˜¯åŸºäºå½“å‰ç­–ç•¥è¿›è¡Œè®­ç»ƒçš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨å½“å‰ç­–ç•¥ç”Ÿæˆçš„æ ·æœ¬æ¥è®­ç»ƒï¼Œå› æ­¤ä¸èƒ½å†è®°ä½æ—§çš„è½¬æ¢ã€‚ä½ å¯ä»¥å°è¯•è¿™æ ·åšï¼Œä½†æœ€ç»ˆå¾—åˆ°çš„ç­–ç•¥æ¢¯åº¦ä¼šæ˜¯åŸºäºæ—§ç­–ç•¥ç”Ÿæˆæ ·æœ¬çš„æ¢¯åº¦ï¼Œè€Œä¸æ˜¯ä½ æƒ³æ›´æ–°çš„å½“å‰ç­–ç•¥ã€‚

ç ”ç©¶äººå‘˜å·²ç»ç ”ç©¶è¿™ä¸ªé—®é¢˜å¤šå¹´ï¼Œæå‡ºäº†å‡ ç§è§£å†³æ–¹æ¡ˆï¼Œä½†è¿™ä¸ªé—®é¢˜ä»è¿œæœªè§£å†³ã€‚æœ€å¸¸ç”¨çš„è§£å†³æ–¹æ¡ˆæ˜¯é€šè¿‡å¤šä¸ªå¹¶è¡Œç¯å¢ƒæ”¶é›†è½¬æ¢ï¼Œè¿™äº›ç¯å¢ƒéƒ½åˆ©ç”¨å½“å‰çš„ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•æ‰“ç ´äº†å•ä¸€å›åˆä¸­çš„ç›¸å…³æ€§ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨æ˜¯åœ¨å¤šä¸ªä¸åŒç¯å¢ƒä¸­æ”¶é›†çš„å¤šä¸ªå›åˆä¸Šè¿›è¡Œè®­ç»ƒã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¾ç„¶ä½¿ç”¨å½“å‰çš„ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªé‡å¤§ç¼ºç‚¹æ˜¯æ ·æœ¬æ•ˆç‡ä½ï¼Œå› ä¸ºæˆ‘ä»¬åŸºæœ¬ä¸Šä¼šä¸¢å¼ƒåœ¨å•ä¸€è®­ç»ƒè½®æ¬¡ä¸­è·å¾—çš„æ‰€æœ‰ç»éªŒã€‚

å°† DQN ä¸ç­–ç•¥æ¢¯åº¦æ–¹æ³•è¿›è¡Œæ¯”è¾ƒéå¸¸ç®€å•ã€‚ä¾‹å¦‚ï¼Œå¯¹äº DQNï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ 100 ä¸‡ä¸ªå›æ”¾ç¼“å†²åŒºæ ·æœ¬ï¼Œæ¯ä¸ªæ–°å¸§çš„è®­ç»ƒæ‰¹é‡å¤§å°ä¸º 32 ä¸ªæ ·æœ¬ï¼Œé‚£ä¹ˆæ¯ä¸ªè¿‡æ¸¡çŠ¶æ€å¤§çº¦ä¼šåœ¨ä»ç»éªŒå›æ”¾ä¸­æ¨é€ä¹‹å‰è¢«ä½¿ç”¨ 32 æ¬¡ã€‚å¯¹äºä¼˜å…ˆå›æ”¾ç¼“å†²åŒºï¼ˆåœ¨ç¬¬å…«ç« è®¨è®ºè¿‡ï¼‰ï¼Œè¿™ä¸ªæ•°å­—å¯èƒ½ä¼šé«˜å¾—å¤šï¼Œå› ä¸ºæ ·æœ¬çš„é€‰æ‹©æ¦‚ç‡ä¸æ˜¯å‡åŒ€çš„ã€‚åœ¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„æƒ…å†µä¸‹ï¼Œä»ç¯å¢ƒä¸­è·å¾—çš„æ¯ä¸ªç»éªŒåªèƒ½ä½¿ç”¨ä¸€æ¬¡ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ–¹æ³•éœ€è¦æ–°é²œçš„æ•°æ®ï¼Œå› æ­¤ç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„æ•°æ®æ•ˆç‡å¯èƒ½æ¯”åŸºäºä»·å€¼çš„ç¦»çº¿æ–¹æ³•ä½ä¸€ä¸ªæ•°é‡çº§ã€‚

å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬çš„ A2C ä»£ç†åœ¨ Pong ä¸Šæ”¶æ•›ç”¨äº† 800 ä¸‡å¸§ï¼Œè¿™ä»…æ˜¯ç¬¬å…­ç« å’Œç¬¬å…«ç« ä¸­åŸºæœ¬ DQN çš„ 100 ä¸‡å¸§çš„å…«å€ã€‚å› æ­¤ï¼Œè¿™å‘æˆ‘ä»¬å±•ç¤ºäº†ç­–ç•¥æ¢¯åº¦æ–¹æ³•å¹¶éå®Œå…¨æ— ç”¨ï¼›å®ƒä»¬åªæ˜¯ä¸åŒçš„ï¼Œå¹¶ä¸”æœ‰å…¶è‡ªèº«çš„ç‰¹ç‚¹ï¼Œä½ åœ¨é€‰æ‹©æ–¹æ³•æ—¶éœ€è¦è€ƒè™‘è¿™äº›ç‰¹ç‚¹ã€‚å¦‚æœä½ çš„ç¯å¢ƒåœ¨ä»£ç†äº¤äº’æ–¹é¢æ˜¯â€œä¾¿å®œâ€çš„ï¼ˆç¯å¢ƒå“åº”å¿«é€Ÿï¼Œå†…å­˜å ç”¨ä½ï¼Œæ”¯æŒå¹¶è¡ŒåŒ–ç­‰ï¼‰ï¼Œé‚£ä¹ˆç­–ç•¥æ¢¯åº¦æ–¹æ³•å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœç¯å¢ƒâ€œæ˜‚è´µâ€ï¼Œå¹¶ä¸”è·å–å¤§é‡ç»éªŒå¯èƒ½ä¼šå‡æ…¢è®­ç»ƒè¿‡ç¨‹ï¼Œé‚£ä¹ˆåŸºäºä»·å€¼çš„æ–¹æ³•å¯èƒ½æ˜¯æ›´èªæ˜çš„é€‰æ‹©ã€‚

## å‘ A2C ä¸­æ·»åŠ é¢å¤–çš„â€œAâ€

ä»å®è·µè§’åº¦çœ‹ï¼Œä¸å¤šä¸ªå¹¶è¡Œç¯å¢ƒè¿›è¡Œé€šä¿¡æ˜¯ç®€å•çš„ã€‚æˆ‘ä»¬å·²ç»åœ¨ç¬¬ä¹ç« å’Œå½“å‰ç« èŠ‚çš„å‰é¢éƒ¨åˆ†åšè¿‡è¿™ä»¶äº‹ï¼Œä½†å¹¶æ²¡æœ‰æ˜ç¡®è¯´æ˜ã€‚åœ¨ A2C ä»£ç†ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€ä¸ª Gym ç¯å¢ƒçš„æ•°ç»„ä¼ é€’ç»™ ExperienceSource ç±»ï¼Œè¯¥ç±»å°†å…¶åˆ‡æ¢ä¸ºè½®è¯¢æ•°æ®æ”¶é›†æ¨¡å¼ã€‚è¿™æ„å‘³ç€æ¯æ¬¡æˆ‘ä»¬ä»ç»éªŒæºè¯·æ±‚è¿‡æ¸¡æ—¶ï¼Œè¯¥ç±»ä¼šä½¿ç”¨æˆ‘ä»¬æ•°ç»„ä¸­çš„ä¸‹ä¸€ä¸ªç¯å¢ƒï¼ˆå½“ç„¶ï¼Œä¼šä¸ºæ¯ä¸ªç¯å¢ƒä¿æŒçŠ¶æ€ï¼‰ã€‚è¿™ç§ç®€å•çš„æ–¹æ³•ç›¸å½“äºä¸ç¯å¢ƒè¿›è¡Œå¹¶è¡Œé€šä¿¡ï¼Œä½†æœ‰ä¸€ä¸ªå°å°çš„åŒºåˆ«ï¼šé€šä¿¡ä¸æ˜¯ä¸¥æ ¼æ„ä¹‰ä¸Šçš„å¹¶è¡Œï¼Œè€Œæ˜¯ä»¥ä¸²è¡Œçš„æ–¹å¼è¿›è¡Œã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„ç»éªŒæºä¸­çš„æ ·æœ¬æ˜¯æ‰“ä¹±çš„ã€‚è¿™ä¸ªæ€è·¯åœ¨ä¸‹å›¾ä¸­å±•ç¤ºï¼š

![PIC](img/B22150_12_11.png)

å›¾ 12.11ï¼šä¸€ä¸ªä»£ç†åœ¨å¤šä¸ªç¯å¢ƒä¸­å¹¶è¡Œè®­ç»ƒ

è¿™ç§æ–¹æ³•è¿è¡Œè‰¯å¥½ï¼Œå¹¶å¸®åŠ©æˆ‘ä»¬åœ¨ A2C æ–¹æ³•ä¸­è¾¾åˆ°äº†æ”¶æ•›ï¼Œä½†åœ¨è®¡ç®—èµ„æºåˆ©ç”¨æ–¹é¢ä»ä¸å®Œç¾ï¼Œå› ä¸ºæ‰€æœ‰å¤„ç†éƒ½æ˜¯é¡ºåºè¿›è¡Œçš„ã€‚å³ä½¿æ˜¯ç°åœ¨çš„ä¸€å°æ™®é€šå·¥ä½œç«™ï¼Œä¹Ÿæ‹¥æœ‰å¤šä¸ª CPU æ ¸å¿ƒï¼Œå¯ä»¥ç”¨äºè®¡ç®—ï¼Œå¦‚è®­ç»ƒå’Œç¯å¢ƒäº¤äº’ã€‚å¦ä¸€æ–¹é¢ï¼Œå¹³è¡Œç¼–ç¨‹æ¯”ä¼ ç»ŸèŒƒå¼æ›´éš¾ï¼Œå½“ä½ æœ‰ä¸€ä¸ªæ¸…æ™°çš„æ‰§è¡Œæµæ—¶ï¼Œä¼ ç»Ÿæ–¹æ³•ç›¸å¯¹æ›´ç®€å•ã€‚å¹¸è¿çš„æ˜¯ï¼ŒPython æ˜¯ä¸€ç§éå¸¸å…·æœ‰è¡¨è¾¾åŠ›å’Œçµæ´»æ€§çš„è¯­è¨€ï¼Œæ‹¥æœ‰å¤§é‡çš„ç¬¬ä¸‰æ–¹åº“ï¼Œå…è®¸ä½ è½»æ¾è¿›è¡Œå¹³è¡Œç¼–ç¨‹ã€‚æˆ‘ä»¬å·²ç»åœ¨ç¬¬Â 9 ç« ä¸­çœ‹åˆ°è¿‡ torch.multiprocessing åº“çš„ç¤ºä¾‹ï¼Œåœ¨ DQN è®­ç»ƒä¸­æˆ‘ä»¬å¹³è¡ŒåŒ–äº†ä»£ç†çš„æ‰§è¡Œã€‚ä½†è¿˜æœ‰å…¶ä»–æ›´é«˜çº§çš„åº“ï¼Œå¦‚ rayï¼Œå®ƒå…è®¸æˆ‘ä»¬å¹³è¡ŒåŒ–ä»£ç æ‰§è¡Œï¼Œéšè—åº•å±‚çš„é€šä¿¡ç»†èŠ‚ã€‚

å…³äºæ¼”å‘˜-è¯„è®ºå®¶å¹¶è¡ŒåŒ–ï¼Œæœ‰ä¸¤ç§æ–¹æ³•ï¼š

1.  æ•°æ®å¹¶è¡Œæ€§ï¼šæˆ‘ä»¬å¯ä»¥æœ‰å¤šä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹ä¸ä¸€ä¸ªæˆ–å¤šä¸ªç¯å¢ƒè¿›è¡Œé€šä¿¡ï¼Œå¹¶æä¾›è¿‡æ¸¡æ•°æ®ï¼ˆs,r,a,sâ€²ï¼‰ã€‚æ‰€æœ‰è¿™äº›æ ·æœ¬å°†æ±‡èšåˆ°ä¸€ä¸ªå•ç‹¬çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®¡ç®—æŸå¤±å¹¶æ‰§è¡Œ SGD æ›´æ–°ã€‚ç„¶åï¼Œæ›´æ–°åçš„ç¥ç»ç½‘ç»œï¼ˆNNï¼‰å‚æ•°éœ€è¦å¹¿æ’­åˆ°æ‰€æœ‰å…¶ä»–è¿›ç¨‹ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„ç¯å¢ƒé€šä¿¡ä¸­ä½¿ç”¨ã€‚è¿™ä¸ªæ¨¡å‹åœ¨å›¾Â 12.12 ä¸­æœ‰æ‰€è¯´æ˜ã€‚

1.  æ¢¯åº¦å¹¶è¡Œæ€§ï¼šç”±äºè®­ç»ƒè¿‡ç¨‹çš„ç›®æ ‡æ˜¯è®¡ç®—æ¢¯åº¦æ¥æ›´æ–°æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œï¼ˆNNï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰å¤šä¸ªè¿›ç¨‹åœ¨å„è‡ªçš„è®­ç»ƒæ ·æœ¬ä¸Šè®¡ç®—æ¢¯åº¦ã€‚ç„¶åï¼Œè¿™äº›æ¢¯åº¦å¯ä»¥æ±‡æ€»åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­æ‰§è¡Œ SGD æ›´æ–°ã€‚å½“ç„¶ï¼Œæ›´æ–°åçš„ NN æƒé‡ä¹Ÿå¿…é¡»ä¼ æ’­å›æ‰€æœ‰å·¥ä½œè¿›ç¨‹ï¼Œä»¥ä¿æŒæ•°æ®çš„ä¸€è‡´æ€§ã€‚è¿™åœ¨å›¾Â 12.13 ä¸­æœ‰æ‰€è¯´æ˜ã€‚

![PIC](img/B22150_12_12.png)

å›¾Â 12.12ï¼šç¬¬ä¸€ç§æ¼”å‘˜-è¯„è®ºå®¶å¹¶è¡ŒåŒ–æ–¹æ³•ï¼ŒåŸºäºåˆ†å¸ƒå¼è®­ç»ƒæ ·æœ¬çš„æ±‡é›†

![PIC](img/B22150_12_13.png)

å›¾Â 12.13ï¼šç¬¬äºŒç§å¹¶è¡ŒåŒ–æ–¹æ³•ï¼Œä¸ºæ¨¡å‹æ±‡é›†æ¢¯åº¦

è¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„å·®å¼‚ä»å›¾è¡¨ä¸Šçœ‹å¯èƒ½å¹¶ä¸ååˆ†æ˜¾è‘—ï¼Œä½†ä½ éœ€è¦æ„è¯†åˆ°è®¡ç®—æˆæœ¬çš„å·®å¼‚ã€‚A2C ä¼˜åŒ–ä¸­çš„æœ€é‡æ“ä½œæ˜¯è®­ç»ƒè¿‡ç¨‹ï¼Œå®ƒåŒ…æ‹¬ä»æ•°æ®æ ·æœ¬ä¸­è®¡ç®—æŸå¤±ï¼ˆå‰å‘ä¼ æ’­ï¼‰ä»¥åŠæ ¹æ®è¯¥æŸå¤±è®¡ç®—æ¢¯åº¦ã€‚SGD ä¼˜åŒ–æ­¥éª¤ç›¸å¯¹è½»é‡â€”â€”åŸºæœ¬ä¸Šåªæ˜¯å°†ç¼©æ”¾åçš„æ¢¯åº¦åŠ åˆ°ç¥ç»ç½‘ç»œï¼ˆNNï¼‰çš„æƒé‡ä¸Šã€‚é€šè¿‡å°†ç¬¬äºŒç§æ–¹æ³•ï¼ˆæ¢¯åº¦å¹¶è¡Œï¼‰ä¸­çš„æŸå¤±è®¡ç®—å’Œæ¢¯åº¦è®¡ç®—ä»ä¸­å¤®å¤„ç†è¿‡ç¨‹ç§»å‡ºï¼Œæˆ‘ä»¬æ¶ˆé™¤äº†ä¸»è¦çš„æ½œåœ¨ç“¶é¢ˆï¼Œå¹¶ä½¿æ•´ä¸ªè¿‡ç¨‹å˜å¾—æ›´åŠ å¯æ‰©å±•ã€‚

å®é™…ä¸Šï¼Œé€‰æ‹©å“ªç§æ–¹æ³•ä¸»è¦å–å†³äºä½ çš„èµ„æºå’Œç›®æ ‡ã€‚å¦‚æœä½ æœ‰ä¸€ä¸ªå•ä¸€çš„ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶ä¸”æ‹¥æœ‰å¤§é‡åˆ†å¸ƒå¼è®¡ç®—èµ„æºï¼Œæ¯”å¦‚åœ¨ç½‘ç»œä¸­åˆ†å¸ƒçš„æ•°åä¸ª GPUï¼Œé‚£ä¹ˆæ¢¯åº¦å¹¶è¡Œå°†æ˜¯åŠ é€Ÿè®­ç»ƒçš„æœ€ä½³æ–¹æ³•ã€‚

ç„¶è€Œï¼Œå¦‚æœåªæœ‰ä¸€ä¸ª GPUï¼Œä¸¤ç§æ–¹æ³•ä¼šæä¾›ç±»ä¼¼çš„æ€§èƒ½ï¼Œä½†ç¬¬ä¸€ç§æ–¹æ³•é€šå¸¸æ›´æ˜“äºå®ç°ï¼Œå› ä¸ºä½ æ— éœ€å¤„ç†ä½çº§åˆ«çš„æ¢¯åº¦å€¼ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡æˆ‘ä»¬æœ€å–œæ¬¢çš„ Pong æ¸¸æˆæ¯”è¾ƒè¿™ä¸¤ç§æ–¹æ³•ï¼Œçœ‹çœ‹å®ƒä»¬çš„å·®å¼‚ï¼Œå¹¶æ¢ç´¢ PyTorch çš„å¤šè¿›ç¨‹èƒ½åŠ›ã€‚

## A3C ä¸æ•°æ®å¹¶è¡Œ

æˆ‘ä»¬å°†æ£€æŸ¥çš„ A3C å¹¶è¡ŒåŒ–çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬ï¼ˆå¦‚å›¾ 12.12 æ‰€ç¤ºï¼‰æœ‰ä¸€ä¸ªä¸»è¦è¿›ç¨‹è´Ÿè´£æ‰§è¡Œè®­ç»ƒï¼Œå¤šä¸ªå­è¿›ç¨‹ä¸ç¯å¢ƒè¿›è¡Œé€šä¿¡å¹¶æ”¶é›†ç»éªŒè¿›è¡Œè®­ç»ƒã€‚

äº‹å®ä¸Šï¼Œæˆ‘ä»¬åœ¨ç¬¬ä¹ç« ä¸­å·²ç»å®ç°äº†è¿™ä¸ªç‰ˆæœ¬ï¼Œå½“æ—¶æˆ‘ä»¬åœ¨å­è¿›ç¨‹ä¸­è¿è¡Œå¤šä¸ªä»£ç†ï¼Œè®­ç»ƒ DQN æ¨¡å‹ï¼ˆé‚£æ—¶æˆ‘ä»¬åœ¨ FPS æ–¹é¢è·å¾—äº† 27%çš„åŠ é€Ÿï¼‰ã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä¸ä¼šç”¨ A3C æ–¹æ³•é‡æ–°å®ç°ç›¸åŒçš„æ–¹æ³•ï¼Œè€Œæ˜¯æƒ³å±•ç¤ºâ€œåº“çš„åŠ›é‡â€ã€‚

æˆ‘ä»¬å·²ç»ç®€è¦æåˆ°è¿‡ Gymnasium ä¸­çš„ç±»`gym.vector.SyncVectorEnv`ï¼ˆå®ƒä»…å­˜åœ¨äº Farama çš„åˆ†æ”¯ä¸­ï¼Œè€Œä¸åœ¨åŸå§‹çš„ OpenAI Gym ä¸­ï¼‰å’Œ PTAN ç»éªŒæºï¼Œå®ƒæ”¯æŒâ€œå‘é‡åŒ–â€ç¯å¢ƒï¼š`VectorExperienceSourceFirstLast`ã€‚ç±»`SyncVectorEnv`æŒ‰é¡ºåºå¤„ç†å°è£…çš„ç¯å¢ƒï¼Œä½†æœ‰ä¸€ä¸ªæ›¿ä»£ç±»`AsyncVectorEnv`ï¼Œå®ƒä½¿ç”¨`mp.multiprocessing`å¤„ç†å­ç¯å¢ƒã€‚æ‰€ä»¥ï¼Œä¸ºäº†è·å¾— A2C æ–¹æ³•çš„æ•°æ®å¹¶è¡Œç‰ˆæœ¬ï¼Œæˆ‘ä»¬åªéœ€è¦å°†`SyncVectorEnv`æ›¿æ¢ä¸º`AsyncVectorEnv`ï¼Œè¿™æ ·å°±å®Œæˆäº†ã€‚

ç¬¬åäºŒç« çš„ä»£ç ï¼ˆChapter12/02_pong_a2c.pyï¼‰å·²ç»æ”¯æŒè¿™ä¸ªæ›¿æ¢æ“ä½œï¼Œæ–¹æ³•æ˜¯ä¼ é€’`--use-async`å‘½ä»¤è¡Œé€‰é¡¹ã€‚

### ç»“æœ

å¼‚æ­¥ç‰ˆæœ¬åœ¨ 50 ä¸ªç¯å¢ƒä¸‹å±•ç¤ºäº† 2000 FPS çš„æ€§èƒ½ï¼Œæ¯”é¡ºåºç‰ˆæœ¬æé«˜äº† 2 å€ã€‚ä»¥ä¸‹å›¾è¡¨æ¯”è¾ƒäº†è¿™ä¸¤ä¸ªç‰ˆæœ¬çš„æ€§èƒ½å’Œå¥–åŠ±åŠ¨æ€ï¼š

![PIC](img/B22150_12_14.png)

å›¾ 12.14ï¼šA2C å’Œ A3C åœ¨å¥–åŠ±ï¼ˆå·¦ï¼‰å’Œé€Ÿåº¦ï¼ˆå³ï¼‰ä¸Šçš„æ¯”è¾ƒ

## A3C ä¸æ¢¯åº¦å¹¶è¡Œ

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è€ƒè™‘ä¸€ç§å¹¶è¡ŒåŒ– A2C å®ç°çš„æ–¹æ³•ï¼Œå®ƒå°†æœ‰å¤šä¸ªå­è¿›ç¨‹ï¼Œä½†å®ƒä»¬ä¸æ˜¯å°†è®­ç»ƒæ•°æ®ä¼ é€’ç»™ä¸­å¤®è®­ç»ƒå¾ªç¯ï¼Œè€Œæ˜¯ä½¿ç”¨å®ƒä»¬æœ¬åœ°çš„è®­ç»ƒæ•°æ®è®¡ç®—æ¢¯åº¦ï¼Œå¹¶å°†è¿™äº›æ¢¯åº¦å‘é€ç»™ä¸­å¤®ä¸»è¿›ç¨‹ã€‚è¿™ä¸ªä¸»è¿›ç¨‹è´Ÿè´£å°†è¿™äº›æ¢¯åº¦åˆå¹¶ï¼ˆåŸºæœ¬ä¸Šå°±æ˜¯æ±‚å’Œï¼‰å¹¶å¯¹å…±äº«ç½‘ç»œè¿›è¡Œ SGD æ›´æ–°ã€‚

è¿™ä¸ªå·®å¼‚çœ‹èµ·æ¥å¯èƒ½å¾®ä¸è¶³é“ï¼Œä½†è¿™ç§æ–¹æ³•çš„å¯æ‰©å±•æ€§æ›´å¼ºï¼Œç‰¹åˆ«æ˜¯å½“ä½ æœ‰å¤šä¸ªå¼ºå¤§çš„èŠ‚ç‚¹å¹¶ä¸”è¿™äº›èŠ‚ç‚¹é€šè¿‡å¤šä¸ª GPU è¿æ¥åˆ°ç½‘ç»œæ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®å¹¶è¡Œæ¨¡å‹ä¸­çš„ä¸­å¤®å¤„ç†è¿‡ç¨‹å¾ˆå¿«å°±ä¼šæˆä¸ºç“¶é¢ˆï¼Œå› ä¸ºæŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­æ˜¯è®¡ç®—å¯†é›†å‹çš„ã€‚æ¢¯åº¦å¹¶è¡ŒåŒ–å¯ä»¥å°†è´Ÿè½½åˆ†é…åˆ°å¤šä¸ª GPU ä¸Šï¼Œåœ¨ä¸­å¤®ä½ç½®ä»…æ‰§è¡Œç›¸å¯¹ç®€å•çš„æ¢¯åº¦ç»„åˆæ“ä½œã€‚

### å®ç°

å®Œæ•´çš„ç¤ºä¾‹åœ¨ Chapter12/03_a3c_grad.py æ–‡ä»¶ä¸­ï¼Œå¹¶ä¸”ä½¿ç”¨æˆ‘ä»¬å·²ç»çœ‹åˆ°çš„ Chapter12/lib/common.py æ¨¡å—ã€‚

å’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬é¦–å…ˆå®šä¹‰è¶…å‚æ•°ï¼š

```py
GAMMA = 0.99 
LEARNING_RATE = 0.001 
ENTROPY_BETA = 0.01 
REWARD_STEPS = 4 
CLIP_GRAD = 0.1 

PROCESSES_COUNT = 4 
NUM_ENVS = 8 
GRAD_BATCH = 64 
TRAIN_BATCH = 2 

ENV_NAME = "PongNoFrameskip-v4" 
NAME = â€™pongâ€™ 
REWARD_BOUND = 18
```

è¿™äº›ä¸ä¹‹å‰çš„ç¤ºä¾‹å¤§è‡´ç›¸åŒï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯ BATCH_SIZE è¢«ä¸¤ä¸ªå‚æ•°å–ä»£ï¼šGRAD_BATCH å’Œ TRAIN_BATCHã€‚GRAD_BATCH çš„å€¼å®šä¹‰äº†æ¯ä¸ªå­è¿›ç¨‹ç”¨äºè®¡ç®—æŸå¤±å¹¶è·å–æ¢¯åº¦å€¼çš„æ‰¹æ¬¡å¤§å°ã€‚ç¬¬äºŒä¸ªå‚æ•° TRAIN_BATCH æŒ‡å®šäº†æ¯ä¸ª SGD è¿­ä»£ä¸­å°†ç»“åˆæ¥è‡ªå­è¿›ç¨‹çš„å¤šå°‘ä¸ªæ¢¯åº¦æ‰¹æ¬¡ã€‚æ¯ä¸ªç”±å­è¿›ç¨‹äº§ç”Ÿçš„æ¡ç›®å…·æœ‰ä¸æˆ‘ä»¬çš„ç½‘ç»œå‚æ•°ç›¸åŒçš„å½¢çŠ¶ï¼Œæˆ‘ä»¬å°†å…¶ TRAIN_BATCH çš„å€¼ç›¸åŠ ã€‚å› æ­¤ï¼Œå¯¹äºæ¯ä¸€æ­¥ä¼˜åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ TRAIN_BATCH * GRAD_BATCH ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ç”±äºæŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­æ˜¯ç›¸å½“ç¹é‡çš„æ“ä½œï¼Œæˆ‘ä»¬ä½¿ç”¨è¾ƒå¤§çš„ GRAD_BATCH æ¥æé«˜å®ƒä»¬çš„æ•ˆç‡ã€‚

ç”±äºè¿™ä¸ªå¤§æ‰¹æ¬¡ï¼Œæˆ‘ä»¬åº”è¯¥ä¿æŒç›¸å¯¹è¾ƒä½çš„ TRAIN_BATCHï¼Œä»¥ä¿æŒç½‘ç»œçš„ç­–ç•¥æ›´æ–°ã€‚

ç°åœ¨æˆ‘ä»¬æœ‰ä¸¤ä¸ªå‡½æ•°â€”â€”make_env()ï¼Œç”¨äºåˆ›å»ºä¸€ä¸ªå°è£…çš„ Pong ç¯å¢ƒï¼Œä»¥åŠ grads_func()ï¼Œå®ƒæ›´åŠ å¤æ‚ï¼Œå®ç°äº†æˆ‘ä»¬é€šå¸¸åœ¨è®­ç»ƒå¾ªç¯ä¸­æ‰§è¡Œçš„å¤§éƒ¨åˆ†è®­ç»ƒé€»è¾‘ã€‚ä½œä¸ºè¡¥å¿ï¼Œä¸»è¿›ç¨‹ä¸­çš„è®­ç»ƒå¾ªç¯å˜å¾—å‡ ä¹æ˜¯å¾®ä¸è¶³é“çš„ï¼š

```py
def make_env() -> gym.Env: 
    return ptan.common.wrappers.wrap_dqn(gym.make("PongNoFrameskip-v4")) 

def grads_func(proc_name: str, net: common.AtariA2C, device: torch.device, 
               train_queue: mp.Queue): 
    env_factories = [make_env for _ in range(NUM_ENVS)] 
    env = gym.vector.SyncVectorEnv(env_factories) 

    agent = ptan.agent.PolicyAgent(lambda x: net(x)[0], device=device, apply_softmax=True) 
    exp_source = VectorExperienceSourceFirstLast( 
        env, agent, gamma=GAMMA, steps_count=REWARD_STEPS) 

    batch = [] 
    frame_idx = 0 
    writer = SummaryWriter(comment=proc_name)
```

åœ¨åˆ›å»ºå­è¿›ç¨‹æ—¶ï¼Œæˆ‘ä»¬å°†å‡ ä¸ªå‚æ•°ä¼ é€’ç»™ grads_func() å‡½æ•°ï¼š

+   ç”¨äºåˆ›å»º TensorBoard å†™å…¥å™¨çš„è¿›ç¨‹åç§°ã€‚åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæ¯ä¸ªå­è¿›ç¨‹éƒ½å†™å…¥è‡ªå·±çš„ TensorBoard æ•°æ®é›†ã€‚

+   å…±äº«ç¥ç»ç½‘ç»œã€‚

+   ä¸€ä¸ª torch.device å®ä¾‹ï¼Œç”¨äºæŒ‡å®šè®¡ç®—è®¾å¤‡ã€‚

+   ç”¨äºå°†è®¡ç®—å‡ºçš„æ¢¯åº¦ä¼ é€’ç»™ä¸­å¤®å¤„ç†è¿‡ç¨‹çš„é˜Ÿåˆ—ã€‚

æˆ‘ä»¬çš„å­è¿›ç¨‹å‡½æ•°ä¸æ•°æ®å¹¶è¡Œç‰ˆæœ¬ä¸­çš„ä¸»è®­ç»ƒå¾ªç¯éå¸¸ç›¸ä¼¼ï¼Œè¿™å¹¶ä¸ä»¤äººæƒŠè®¶ï¼Œå› ä¸ºæˆ‘ä»¬çš„å­è¿›ç¨‹æ‰¿æ‹…çš„è´£ä»»å¢åŠ äº†ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰è¦æ±‚ä¼˜åŒ–å™¨æ›´æ–°ç½‘ç»œï¼Œè€Œæ˜¯æ”¶é›†æ¢¯åº¦å¹¶å°†å…¶å‘é€åˆ°é˜Ÿåˆ—ä¸­ã€‚å…¶ä½™çš„ä»£ç å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼š

```py
 with common.RewardTracker(writer, REWARD_BOUND) as tracker: 
        with TBMeanTracker(writer, 100) as tb_tracker: 
            for exp in exp_source: 
                frame_idx += 1 
                new_rewards = exp_source.pop_total_rewards() 
                if new_rewards and tracker.reward(new_rewards[0], frame_idx): 
                    break 

                batch.append(exp) 
                if len(batch) < GRAD_BATCH: 
                    continue
```

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»æ”¶é›†äº†åŒ…å«è½¬æ¢çš„æ‰¹æ¬¡å¹¶å¤„ç†äº†å›åˆç»“æŸçš„å¥–åŠ±ã€‚

åœ¨å‡½æ•°çš„ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä»è®­ç»ƒæ•°æ®ä¸­è®¡ç®—ç»„åˆæŸå¤±å¹¶æ‰§è¡ŒæŸå¤±çš„åå‘ä¼ æ’­ï¼š

```py
 data = common.unpack_batch(batch, net, device=device, gamma=GAMMA, 
                                           reward_steps=REWARD_STEPS) 
                states_v, actions_t, vals_ref_v = data 
                batch.clear() 

                net.zero_grad() 
                logits_v, value_v = net(states_v) 
                loss_value_v = F.mse_loss(value_v.squeeze(-1), vals_ref_v) 

                log_prob_v = F.log_softmax(logits_v, dim=1) 
                adv_v = vals_ref_v - value_v.detach() 
                log_p_a = log_prob_v[range(GRAD_BATCH), actions_t] 
                log_prob_actions_v = adv_v * log_p_a 
                loss_policy_v = -log_prob_actions_v.mean() 

                prob_v = F.softmax(logits_v, dim=1) 
                ent = (prob_v * log_prob_v).sum(dim=1).mean() 
                entropy_loss_v = ENTROPY_BETA * ent 

                loss_v = entropy_loss_v + loss_value_v + loss_policy_v 
                loss_v.backward()
```

åœ¨æ¥ä¸‹æ¥çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å°†ä¼ é€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¦ç›‘è§†çš„ä¸­é—´å€¼åˆ° TensorBoardï¼š

```py
 tb_tracker.track("advantage", adv_v, frame_idx) 
                tb_tracker.track("values", value_v, frame_idx) 
                tb_tracker.track("batch_rewards", vals_ref_v, frame_idx) 
                tb_tracker.track("loss_entropy", entropy_loss_v, frame_idx) 
                tb_tracker.track("loss_policy", loss_policy_v, frame_idx) 
                tb_tracker.track("loss_value", loss_value_v, frame_idx) 
                tb_tracker.track("loss_total", loss_v, frame_idx)
```

åœ¨å¾ªç¯ç»“æŸæ—¶ï¼Œæˆ‘ä»¬éœ€è¦å‰ªè£æ¢¯åº¦ï¼Œå¹¶å°†å…¶ä»ç½‘ç»œçš„å‚æ•°ä¸­æå–åˆ°ä¸€ä¸ªå•ç‹¬çš„ç¼“å†²åŒºä¸­ï¼ˆä»¥é˜²å®ƒä»¬è¢«ä¸‹æ¬¡å¾ªç¯çš„è¿­ä»£æŸåï¼‰ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®é™…ä¸Šå°†æ¢¯åº¦å­˜å‚¨åœ¨æ¯ä¸ªç½‘ç»œå‚æ•°çš„`tensor.grad`å­—æ®µä¸­ã€‚è¿™å¯ä»¥åœ¨ä¸éœ€è¦ä¸å…¶ä»–å·¥ä½œè¿›ç¨‹åŒæ­¥çš„æƒ…å†µä¸‹å®Œæˆï¼Œå› ä¸ºæˆ‘ä»¬çš„ç½‘ç»œå‚æ•°æ˜¯å…±äº«çš„ï¼Œä½†æ¢¯åº¦æ˜¯ç”±æ¯ä¸ªè¿›ç¨‹æœ¬åœ°åˆ†é…çš„ï¼š

```py
 nn_utils.clip_grad_norm_( 
                    net.parameters(), CLIP_GRAD) 
                grads = [ 
                    param.grad.data.cpu().numpy() if param.grad is not None else None 
                    for param in net.parameters() 
                ] 
                train_queue.put(grads) 

    train_queue.put(None)
```

`grads_func`ä¸­çš„æœ€åä¸€è¡Œå°† None æ”¾å…¥é˜Ÿåˆ—ï¼Œè¡¨ç¤ºè¯¥å­è¿›ç¨‹å·²è¾¾åˆ°æ¸¸æˆè§£å†³çŠ¶æ€ï¼Œè®­ç»ƒåº”å½“åœæ­¢ã€‚

ä¸»è¿›ç¨‹ä»åˆ›å»ºç½‘ç»œå¹¶å…±äº«å…¶æƒé‡å¼€å§‹ï¼š

```py
if __name__ == "__main__": 
    mp.set_start_method(â€™spawnâ€™) 
    os.environ[â€™OMP_NUM_THREADSâ€™] = "1" 
    parser = argparse.ArgumentParser() 
    parser.add_argument("--dev", default="cpu", help="Device to use, default=cpu") 
    parser.add_argument("-n", "--name", required=True, help="Name of the run") 
    args = parser.parse_args() 
    device = torch.device(args.dev) 

    env = make_env() 
    net = common.AtariA2C(env.observation_space.shape, env.action_space.n).to(device) 
    net.share_memory()
```

åœ¨è¿™é‡Œï¼Œä¸å‰ä¸€éƒ¨åˆ†ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦ä¸º`torch.multiprocessing`è®¾ç½®å¯åŠ¨æ–¹æ³•ï¼Œå¹¶é™åˆ¶ OpenMP å¯åŠ¨çš„çº¿ç¨‹æ•°é‡ã€‚è¿™æ˜¯é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡`OMP_NUM_THREADS`æ¥å®Œæˆçš„ï¼Œè¯¥å˜é‡å‘Šè¯‰ OpenMP åº“å¯ä»¥å¯åŠ¨çš„çº¿ç¨‹æ•°ã€‚OpenMPï¼ˆ[`www.openmp.org/`](https://www.openmp.org/)ï¼‰è¢« Gym å’Œ OpenCV åº“å¹¿æ³›ä½¿ç”¨ï¼Œä»¥åœ¨å¤šæ ¸ç³»ç»Ÿä¸Šæä¾›åŠ é€Ÿï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹è¿™æ˜¯å¥½äº‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä½¿ç”¨ OpenMP çš„è¿›ç¨‹ä¼šä¸ºç³»ç»Ÿä¸­çš„æ¯ä¸ªæ ¸å¿ƒå¯åŠ¨ä¸€ä¸ªçº¿ç¨‹ã€‚ä½†åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼ŒOpenMP çš„æ•ˆæœæ­£å¥½ç›¸åï¼šç”±äºæˆ‘ä»¬æ­£åœ¨å®ç°è‡ªå·±çš„å¹¶è¡ŒåŒ–ï¼Œé€šè¿‡å¯åŠ¨å¤šä¸ªè¿›ç¨‹ï¼Œé¢å¤–çš„çº¿ç¨‹ä¼šé€šè¿‡é¢‘ç¹çš„ä¸Šä¸‹æ–‡åˆ‡æ¢ç»™æ ¸å¿ƒå¸¦æ¥è´Ÿæ‹…ï¼Œä»è€Œå¯¹æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ã€‚ä¸ºé¿å…è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬æ˜ç¡®å°†çº¿ç¨‹æ•°é™åˆ¶ä¸ºä¸€ä¸ªçº¿ç¨‹ã€‚å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥è‡ªå·±å°è¯•è°ƒæ•´è¿™ä¸ªå‚æ•°ã€‚åœ¨æˆ‘çš„ç³»ç»Ÿä¸Šï¼Œæ²¡æœ‰è®¾ç½®è¯¥ç¯å¢ƒå˜é‡æ—¶ï¼Œæˆ‘ä½“éªŒåˆ°äº† 3-4 å€çš„æ€§èƒ½ä¸‹é™ã€‚

ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºé€šä¿¡é˜Ÿåˆ—å¹¶ç”Ÿæˆæ‰€éœ€æ•°é‡çš„å­è¿›ç¨‹ï¼š

```py
 optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3) 

    train_queue = mp.Queue(maxsize=PROCESSES_COUNT) 
    data_proc_list = [] 
    for proc_idx in range(PROCESSES_COUNT): 
        proc_name = f"-a3c-grad_pong_{args.name}#{proc_idx}" 
        p_args = (proc_name, net, device, train_queue) 
        data_proc = mp.Process(target=grads_func, args=p_args) 
        data_proc.start() 
        data_proc_list.append(data_proc)
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›å…¥è®­ç»ƒå¾ªç¯ï¼š

```py
 batch = [] 
    step_idx = 0 
    grad_buffer = None 

    try: 
        while True: 
            train_entry = train_queue.get() 
            if train_entry is None: 
                break
```

ä¸æ•°æ®å¹¶è¡Œç‰ˆæœ¬çš„ A3C ç›¸æ¯”ï¼Œä¸»è¦çš„åŒºåˆ«åœ¨äºè®­ç»ƒå¾ªç¯ï¼Œè¿™é‡Œæ›´åŠ ç®€å•ï¼Œå› ä¸ºå­è¿›ç¨‹å·²ç»ä¸ºæˆ‘ä»¬å®Œæˆäº†æ‰€æœ‰ç¹é‡çš„è®¡ç®—ã€‚åœ¨å¾ªç¯å¼€å§‹æ—¶ï¼Œæˆ‘ä»¬å¤„ç†å½“æŸä¸ªè¿›ç¨‹å·²è¾¾åˆ°æ‰€éœ€çš„å¹³å‡å¥–åŠ±æ—¶çš„æƒ…å†µï¼ˆæ­¤æ—¶é˜Ÿåˆ—ä¸­ä¸º Noneï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç›´æ¥é€€å‡ºå¾ªç¯ä»¥åœæ­¢è®­ç»ƒã€‚

æˆ‘ä»¬å°†æ‰€æœ‰ç½‘ç»œå‚æ•°çš„æ¢¯åº¦åŠ æ€»åœ¨ä¸€èµ·ï¼š

```py
 step_idx += 1 

            if grad_buffer is None: 
                grad_buffer = train_entry 
            else: 
                for tgt_grad, grad in zip(grad_buffer, train_entry): 
                    tgt_grad += grad
```

å½“æˆ‘ä»¬ç´¯ç§¯äº†è¶³å¤Ÿçš„æ¢¯åº¦ç‰‡æ®µåï¼Œæˆ‘ä»¬å°†æ¢¯åº¦æ€»å’Œè½¬æ¢ä¸º PyTorch çš„ FloatTensorï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™ç½‘ç»œå‚æ•°çš„`grad`å­—æ®µã€‚ä¸ºäº†å¯¹ä¸åŒå­è¿›ç¨‹çš„æ¢¯åº¦è¿›è¡Œå¹³å‡ï¼Œæˆ‘ä»¬ä¼šä¸ºæ¯ä¸ªè·å–åˆ°çš„`TRAIN_BATCH`æ¢¯åº¦è°ƒç”¨ä¼˜åŒ–å™¨çš„ step()å‡½æ•°ã€‚å¯¹äºä¸­é—´æ­¥éª¤ï¼Œæˆ‘ä»¬ä»…ä»…å°†å¯¹åº”çš„æ¢¯åº¦åŠ åœ¨ä¸€èµ·ï¼š

```py
 if step_idx % TRAIN_BATCH == 0: 
                for param, grad in zip(net.parameters(), grad_buffer): 
                    param.grad = torch.FloatTensor(grad).to(device) 

                nn_utils.clip_grad_norm_(net.parameters(), CLIP_GRAD) 
                optimizer.step() 
                grad_buffer = None
```

ä¹‹åï¼Œæˆ‘ä»¬æ‰€éœ€è¦åšçš„å°±æ˜¯è°ƒç”¨ä¼˜åŒ–å™¨çš„ step()æ–¹æ³•ï¼Œé€šè¿‡ç´¯ç§¯çš„æ¢¯åº¦æ›´æ–°ç½‘ç»œå‚æ•°ã€‚

å½“é€€å‡ºè®­ç»ƒå¾ªç¯æ—¶ï¼Œæˆ‘ä»¬åœæ­¢æ‰€æœ‰å­è¿›ç¨‹ï¼Œä»¥ç¡®ä¿å®ƒä»¬å·²è¢«ç»ˆæ­¢ï¼Œå³ä½¿æŒ‰ä¸‹ Ctrl + C åœæ­¢ä¼˜åŒ–ï¼š

```py
 finally: 
        for p in data_proc_list: 
            p.terminate() 
            p.join()
```

è¿™ä¸ªæ­¥éª¤æ˜¯ä¸ºäº†é˜²æ­¢åƒµå°¸è¿›ç¨‹å ç”¨ GPU èµ„æºã€‚

### ç»“æœ

è¿™ä¸ªç¤ºä¾‹å¯ä»¥åƒä¹‹å‰çš„ç¤ºä¾‹ä¸€æ ·å¯åŠ¨ï¼Œè¿‡ä¸€æ®µæ—¶é—´åï¼Œåº”è¯¥å¼€å§‹æ˜¾ç¤ºé€Ÿåº¦å’Œå¹³å‡å¥–åŠ±ã€‚ç„¶è€Œï¼Œä½ éœ€è¦æ³¨æ„ï¼Œæ˜¾ç¤ºçš„ä¿¡æ¯å¯¹äºæ¯ä¸ªå­è¿›ç¨‹éƒ½æ˜¯å±€éƒ¨çš„ï¼Œè¿™æ„å‘³ç€é€Ÿåº¦ã€å®Œæˆçš„æ¸¸æˆæ•°é‡å’Œå¸§æ•°éœ€è¦ä¹˜ä»¥è¿›ç¨‹çš„æ•°é‡ã€‚æˆ‘çš„åŸºå‡†æµ‹è¯•æ˜¾ç¤ºæ¯ä¸ªå­è¿›ç¨‹çš„é€Ÿåº¦å¤§çº¦æ˜¯ 500-600 FPSï¼Œæ€»è®¡å¤§çº¦æ˜¯ 2,000-2,400 FPSã€‚

æ”¶æ•›åŠ¨æ€ä¸å…ˆå‰ç‰ˆæœ¬éå¸¸ç›¸ä¼¼ã€‚æ€»çš„è§‚å¯Ÿæ¬¡æ•°å¤§çº¦ä¸º 800 ä¸‡åˆ° 1000 ä¸‡ï¼Œå®Œæˆè¿™äº›éœ€è¦å¤§çº¦ 1.5 å°æ—¶ã€‚å·¦ä¾§çš„å¥–åŠ±å›¾æ˜¾ç¤ºäº†å„ä¸ªè¿›ç¨‹ï¼Œå³ä¾§çš„é€Ÿåº¦å›¾æ˜¾ç¤ºäº†æ‰€æœ‰è¿›ç¨‹çš„æ€»å’Œã€‚å¦‚ä½ æ‰€è§ï¼Œæ¢¯åº¦å¹¶è¡Œæ¯”æ•°æ®å¹¶è¡Œç•¥å¾®æé«˜äº†æ€§èƒ½ï¼š

![å›¾ç‰‡](img/B22150_12_15.png)

å›¾ 12.15ï¼šA2C å’Œ A3C åœ¨å¥–åŠ±ï¼ˆå·¦ï¼‰å’Œé€Ÿåº¦ï¼ˆå³ï¼‰æ–¹é¢çš„æ¯”è¾ƒ

# æ€»ç»“

åœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­æœ€å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•ä¹‹ä¸€ï¼šA2Cï¼Œè¯¥æ–¹æ³•å·§å¦™åœ°å°†ç­–ç•¥æ¢¯åº¦æ›´æ–°ä¸çŠ¶æ€è¿‘ä¼¼å€¼ç»“åˆèµ·æ¥ã€‚æˆ‘ä»¬åˆ†æäº†åŸºå‡†ï¼ˆbaselineï¼‰å¯¹ç»Ÿè®¡é‡å’Œæ¢¯åº¦æ”¶æ•›çš„å½±å“ã€‚ç„¶åï¼Œæˆ‘ä»¬æ£€æŸ¥äº†åŸºå‡†æ€æƒ³çš„æ‰©å±•ï¼šA2Cï¼Œå…¶ä¸­ä¸€ä¸ªç‹¬ç«‹çš„ç½‘ç»œå¤´ä¸ºæˆ‘ä»¬æä¾›å½“å‰çŠ¶æ€çš„åŸºå‡†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸ºä»€ä¹ˆå¯¹äºç­–ç•¥æ¢¯åº¦æ–¹æ³•æ¥è¯´ï¼Œä»å¤šä¸ªç¯å¢ƒæ”¶é›†è®­ç»ƒæ•°æ®éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒä»¬æ˜¯åŸºäºç­–ç•¥çš„ï¼ˆon-policyï¼‰ã€‚æˆ‘ä»¬è¿˜å®ç°äº†ä¸¤ç§ä¸åŒçš„ A3C æ–¹æ³•ï¼Œä»¥å®ç°è®­ç»ƒè¿‡ç¨‹çš„å¹¶è¡ŒåŒ–å’Œç¨³å®šåŒ–ã€‚å¹¶è¡ŒåŒ–å°†åœ¨æœ¬ä¹¦ä¸­å†æ¬¡å‡ºç°ï¼Œæˆ‘ä»¬å°†åœ¨è®¨è®ºé»‘ç›’æ–¹æ³•æ—¶æåˆ°ï¼ˆç¬¬åä¸ƒç« ï¼‰ã€‚

åœ¨æ¥ä¸‹æ¥çš„ä¸¤ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä½¿ç”¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•å¯ä»¥è§£å†³çš„å®é™…é—®é¢˜ï¼Œè¿™ä¹Ÿå°†æ€»ç»“æœ¬ä¹¦å…³äºç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„éƒ¨åˆ†å†…å®¹ã€‚

# åŠ å…¥æˆ‘ä»¬åœ¨ Discord ä¸Šçš„ç¤¾åŒº

ä¸å…¶ä»–ç”¨æˆ·ã€æ·±åº¦å­¦ä¹ ä¸“å®¶ä»¥åŠä½œè€…æœ¬äººä¸€èµ·é˜…è¯»æœ¬ä¹¦ã€‚æé—®ï¼Œå‘å…¶ä»–è¯»è€…æä¾›è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡â€œé—®æˆ‘ä»»ä½•é—®é¢˜â€ï¼ˆAsk Me Anythingï¼‰ç¯èŠ‚ä¸ä½œè€…äº¤æµï¼Œç­‰ç­‰ã€‚æ‰«æäºŒç»´ç æˆ–è®¿é—®é“¾æ¥åŠ å…¥ç¤¾åŒºã€‚[`packt.link/rl`](https://packt.link/rl)

![å›¾ç‰‡](img/file1.png)
