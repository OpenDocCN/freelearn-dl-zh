# 前言

本书中回顾的概念和模型将帮助构建并有效地将深度网络从监督学习任务（如图像分类）带入到具有创造性能力的无监督学习领域。

运用基本的生成网络概念，您将学会如何从无标签数据中生成真实图像，如何从文本描述合成图像，以及如何发掘不同领域之间的关系进行风格迁移。

# 本书内容概述

第一章，*深度学习简介*，用简单的方式讲解了与深度学习相关的基础概念和术语，避免过多的数学公式和方程式。同时，本章还展示了深度学习网络如何随着时间的推移不断演变，以及它们如何通过生成模型的出现，在无监督领域取得突破。

第二章，*使用 GAN 进行无监督学习*，展示了生成对抗网络（GAN）的工作原理，并讲解了 GAN 的基本构成元素。本章还展示了如何在半监督领域使用深度学习网络，并将其应用于图像生成和创造性工作。由于 GAN 的训练较为困难，本章探讨了一些改进训练和学习过程的技术。

第三章，*跨多个领域转移图像风格*，介绍了如何利用简单但强大的 CGAN 和 CycleGAN 模型进行创造性工作。它解释了如何使用条件生成对抗网络（Conditional GAN）基于特定特征或条件生成图像。本章还讨论了如何通过使用 BEGAN 稳定网络训练来克服模型崩溃问题。最后，本章还讲解了如何使用 CycleGAN 进行跨不同领域的风格迁移（如苹果到橙子，马到斑马）。

第四章，*从文本生成真实图像*，介绍了将生成对抗网络（GAN）分阶段堆叠的最新方法，利用 StackGAN 将文本到图像合成的问题分解为两个更易管理的子问题。本章还展示了 DiscoGAN 如何成功地跨多个领域转换风格，从给定的鞋子图像生成手袋图像，或进行名人图像的性别转化。

第五章，*使用各种生成模型生成图像*，介绍了预训练模型的概念，并讨论了如何在大规模分布式系统中使用 Apache Spark 运行深度学习和生成模型。然后，我们将使用预训练的 GAN 模型提高低质量图像的分辨率。最后，我们将学习其他种类的生成模型，如 DeepDream 和 VAE，用于图像生成和风格化。

第六章，*将机器学习投入生产*，描述了将基于机器学习和深度学习的智能应用部署到生产环境中的各种方法，涵盖了数据中心和云端，采用基于微服务的容器化或无服务器技术。

# 本书所需的内容

本书中使用的所有工具、库和数据集都是开源的，免费提供。一些书中使用的云环境也提供免费试用供评估。通过本书以及一定程度的机器学习（或深度学习）基础，读者将能够通过生成对抗网络深入了解深度学习的创造性。

您需要安装 Python 和一些额外的 Python 包，并使用`pip`来有效地运行本书中呈现的代码示例。

# 本书适合的人群

本书的目标读者是那些希望探索生成模型的强大功能，利用无标签原始数据或噪声生成逼真图像的机器学习专家和数据科学家。

拥有足够机器学习和神经网络知识，并接触过 Python 编程语言的读者，可以使用本书学习如何从文本合成图像，或自动发现相似领域之间的关系，并通过基于深度学习的生成架构探索无监督领域。

# 约定

本书中，您将看到多种文本样式，它们区分不同类型的信息。以下是这些样式的一些示例及其含义的解释。

导入必要的包和库模块的代码块如下所示：

```py
<div class="packt_code">
nsamples=6
Z_sample = sample_Z(nsamples, noise_dim)
y_sample = np.zeros(shape=[nsamples, num_labels])
y_sample[:, 7] = 1 # generating image based on label
samples = sess.run(G_sample, feed_dict={Z: Z_sample, Y:y_sample})
</div>
```

**新术语**和**重要词汇**用粗体显示。例如，您在屏幕上看到的、菜单或对话框中的词汇，文本中会像这样出现：“点击**下一步**按钮将您带到下一个页面。”

### 注意

警告或重要说明会以这样的框形式出现。

### 提示

提示和技巧像这样显示。

# 读者反馈

我们始终欢迎读者的反馈。让我们知道您对本书的看法——您喜欢什么，或者可能不喜欢什么。读者反馈对我们开发能够真正让您获益的书籍至关重要。

要发送一般反馈，只需发送电子邮件至`<feedback@packtpub.com>`，并通过邮件主题提及书名。

如果您在某个领域拥有专业知识，并且有兴趣编写或为书籍做出贡献，请查看我们在[www.packtpub.com/authors](http://www.packtpub.com/authors)上的作者指南。

# 客户支持

现在，作为 Packt 书籍的自豪拥有者，我们提供了许多资源帮助您充分利用您的购买。

## 下载示例代码

您可以从[`www.packtpub.com`](http://www.packtpub.com)的账户中下载您购买的所有 Packt 书籍的示例代码文件。如果您在其他地方购买了这本书，您可以访问[`www.packtpub.com/support`](http://www.packtpub.com/support)，并注册以便直接通过电子邮件收到文件。

您可以按照以下步骤下载代码文件：

1.  使用您的电子邮件地址和密码登录或注册我们的网站。

1.  将鼠标指针悬停在顶部的**支持**标签上。

1.  点击**代码下载与勘误**。

1.  在**搜索**框中输入书籍名称。

1.  选择您希望下载代码文件的书籍。

1.  从下拉菜单中选择你购买此书的地点。

1.  点击**代码下载**。

您也可以通过点击本书页面上的**代码文件**按钮下载代码文件。可以通过在**搜索**框中输入书名来访问该页面。请注意，您需要登录到您的 Packt 账户。

文件下载完成后，请确保使用以下最新版本的工具解压或提取文件夹：

+   适用于 Windows 的 WinRAR / 7-Zip。

+   适用于 Mac 的 Zipeg / iZip / UnRarX。

+   适用于 Linux 的 7-Zip / PeaZip。

本书的代码包也托管在 GitHub 上，链接为[`github.com/PacktPublishing/Learning–Generative–Adversarial–Networks`](https://github.com/PacktPublishing/Learning–Generative–Adversarial–Networks)。我们还有其他丰富的书籍和视频代码包，可以在[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)找到，快来看看吧！

## 下载本书的彩色图像

我们还为您提供了一份 PDF 文件，包含本书中使用的截图/图表的彩色图像。彩色图像将帮助您更好地理解输出结果的变化。您可以从[`www.packtpub.com/sites/default/files/downloads/LearningGenerativeAdversarialNetworks_ColorImages.pdf`](https://www.packtpub.com/sites/default/files/downloads/LearningGenerativeAdversarialNetworks_ColorImages.pdf)下载该文件。

## 勘误

尽管我们已尽最大努力确保内容的准确性，但错误仍然会发生。如果您在本书中发现错误——例如文本或代码中的错误——我们将非常感激您向我们报告。通过这样做，您可以避免其他读者的困扰，并帮助我们改进本书的后续版本。如果您发现任何勘误，请访问[`www.packtpub.com/submit-errata`](http://www.packtpub.com/submit-errata)报告，选择您的书籍，点击**勘误提交表单**链接，并输入勘误的详细信息。一旦勘误被验证，您的提交将被接受，并且勘误将上传到我们的网站，或添加到该书籍的现有勘误列表中。

要查看先前提交的勘误表，请访问 [`www.packtpub.com/books/content/support`](https://www.packtpub.com/books/content/support) 并在搜索框中输入书名。所需信息将显示在**勘误表**部分下。

## 盗版

互联网上侵犯版权材料的盗版问题是所有媒体的持续问题。在 Packt，我们非常重视版权和许可的保护。如果您在互联网上发现我们作品的任何非法副本，请立即提供地址或网站名称，以便我们采取措施。

请通过 `<copyright@packtpub.com>` 联系我们，提供涉嫌侵权材料的链接。

我们感谢您在保护我们的作者和为您带来有价值的内容方面提供的帮助。

## 问题

如果您对本书的任何方面有问题，可以通过 `<questions@packtpub.com>` 联系我们，我们将尽力解决问题。
