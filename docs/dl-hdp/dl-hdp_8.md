# 附录 1. 参考文献

[1] Hsu, F.-H. (2002). 《深蓝背后：打造击败世界象棋冠军的计算机》. 普林斯顿大学出版社，普林斯顿，新泽西州，美国。 [2] Geoffrey E. Hinton, Simon Osindero, 和 Yee-Whye Teh. 2006 年. 《深度信念网络的快速学习算法》。神经计算，18(7)（2006 年 7 月），1527-1554。 [3] Bengio, Yoshua，等人. "深度网络的贪心层训练"。《神经信息处理系统进展》 19 (2007): 153。 [4] Krizhevsky, Alex, Ilya Sutskever 和 Geoffrey E. Hinton. "使用深度卷积神经网络进行 ImageNet 分类。"《神经信息处理系统进展》，2012 年。 [5] 《机器学习》，Tom Mitchell，McGraw Hill，1997 年。 [6] 《机器学习：一种概率视角》（自适应计算与机器学习系列），Kevin P. Murphy [7] O. Chapelle，B. Scholkopf 和 A. Zien 主编，"半监督学习（Chapelle，O. 等人，主编；2006 年）[书评]"，《IEEE 神经网络学报》，第 20 卷，第 3 期，542-542 页，2009 年 3 月。 [8] Y. Bengio. 《为人工智能学习深度架构》。载于《机器学习基础与趋势》，2(1):1–127，2009 年。 [9] G. Dahl，D. Yu，L. Deng 和 A. Acero. "基于上下文的 DBNHMMs 在大词汇量连续语音识别中的应用"。国际声学、语音与信号处理会议（ICASSP）论文集，2011 年。 [10] A. Mohamed，G. Dahl 和 G. Hinton. "使用深度信念网络进行声学建模"。《IEEE 音频、语音与语言处理学报》，20(1)，2012 年 1 月。 [11] A. Mohamed，D. Yu 和 L. Deng. "深度信念网络全序列训练在语音识别中的应用研究"。国际语音学会会议论文集，2010 年。 [12] Indyk, Piotr 和 Rajeev Motwani. "近似最近邻：消除维度灾难的尝试"。第 30 届 ACM 计算理论年会论文集，ACM，1998 年。 [13] Friedman, Jerome H. "关于偏差、方差、0/1 损失和维度灾难"。《数据挖掘与知识发现》 1.1 (1997): 55-77。 [14] Keogh, Eamonn 和 Abdullah Mueen. "维度灾难"。《机器学习百科全书》，Springer US，2011 年，257-258 页。 [15] Hughes, G.F. (1968 年 1 月). "关于统计模式识别器的平均准确率"。《IEEE 信息理论学报》，14(1): 55–63。 [16] Bengio, Yoshua, Patrice Simard 和 Paolo Frasconi. "使用梯度下降学习长期依赖关系是困难的"。《IEEE 神经网络学报》5.2 (1994): 157-166。

[17] Ivakhnenko, Alexey (1965). Cybernetic Predicting Devices. Kiev: Naukova Dumka. [18] Ivakhnenko, Alexey (1971). "Polynomial theory of complex systems". IEEE Transactions on Systems, Man and Cybernetics (4): 364–378. [19] X. Glorot 和 Y. Bengio。理解深度前馈神经网络训练的困难。在人工智能和统计学会议论文集（AISTATS）中的论文。2010 年。[20] G. Hinton 和 R. Salakhutdinov。利用神经网络减少数据的维度。科学，313(5786)：504–507，2006 年 7 月[21] M. Ranzato, C. Poultney, S. Chopra 和 Y. LeCun。利用基于能量的模型高效学习稀疏表示。在神经信息处理系统（NIPS）会议论文集中。2006 年。[22] I. Goodfellow, M. Mirza, A. Courville 和 Y. Bengio。多预测深度玻尔兹曼机。在神经信息处理系统（NIPS）会议论文集中。2013 年。[23] R. Salakhutdinov 和 G. Hinton。深度玻尔兹曼机。在人工智能和统计学会议（AISTATS）论文集中。2009 年。[24] R. Salakhutdinov 和 G. Hinton。预训练深度玻尔兹曼机的更好方法。在神经信息处理系统（NIPS）会议论文集中。2012 年。[25] N. Srivastava 和 R. Salakhutdinov。多模态学习与深度玻尔兹曼机。在神经信息处理系统（NIPS）会议论文集中。2012 年。[26] H. Poon 和 P. Domingos。总-产品网络：一种新的深度架构。在不确定性人工智能会议论文集中。2011 年。[27] R. Gens 和 P. Domingo。总-产品网络的判别学习。神经信息处理系统（NIPS），2012 年。[28] R. Gens 和 P. Domingo。总-产品网络的判别学习。神经信息处理系统（NIPS），2012 年。[29] S. Hochreiter。动态神经网络研究。技术大学慕尼黑，计算机学院，1991 年。毕业论文。[30] J.Martens。使用无 Hessian 优化的深度学习。在国际机器学习大会（ICML）论文集中。2010 年。[31] Y. Bengio。代表性的深度学习：展望。在统计语言和语音处理中，页 1–37。斯普林格出版社，2013 年。[32] I. Sutskever。训练递归神经网络。多伦多大学，博士论文，2013 年。[33] J. Ngiam, Z. Chen, P. Koh 和 A. Ng。学习深度能量模型。在国际机器学习大会（ICML）论文集中。2011 年。[34] Y. LeCun, S. Chopra, M. Ranzato 和 F. Huang。文件识别和计算机视觉中的基于能量的模型。在国际文档分析和识别大会（ICDAR）论文集中。2007 年。[35] R. Chengalvarayan 和 L. Deng。利用最小分类错误学习进行语音轨迹判别。IEEE 语音和音频处理交易，6(6)：505–515，1998 年。

[36] M. Gibson 和 T. Hain. 错误逼近与最小电话错误声学模型估计。IEEE 音频、语音与语言处理学报，18(6)：1269–1279，2010 年 8 月。[37] X. He, L. Deng 和 W. Chou. 序列模式识别中的判别学习—面向优化的语音识别统一综述。IEEE 信号处理杂志，25：14–36，2008 年。[38] H. Jiang 和 X. Li. 使用凸优化的统计模型参数估计：一种面向语音和语言处理的先进判别训练方法。IEEE 信号处理杂志，27(3)：115–127，2010 年。[39] B.-H. Juang, W. Chou 和 C.-H. Lee. 语音识别的最小分类错误率方法。IEEE 语音与音频处理学报，5：257–265，1997 年。[40] D. Povey 和 P. Woodland. 最小电话错误与 I 平滑用于改进判别训练。在国际声学、语音与信号处理会议（ICASSP）上发表，2002 年。[41] D. Yu, L. Deng, X. He 和 X. Acero. 面向大规模语音识别任务的“大间隔最小分类错误训练”。在国际声学、语音与信号处理会议（ICASSP）上发表，2007 年。[42] A. Robinson. 循环神经网络在电话概率估计中的应用。IEEE 神经网络学报，5：298–305，1994 年。[43] A. Graves. 使用循环神经网络的序列转导。国际机器学习会议（ICML）表征学习研讨会，2012 年。[44] A. Graves, S. Fernandez, F. Gomez 和 J. Schmidhuber. 连接主义时序分类：使用循环神经网络标注未分段序列数据。在国际机器学习会议（ICML）上发表，2006 年。[45] A. Graves, N. Jaitly 和 A. Mohamed. 使用深度双向 LSTM 的混合语音识别。在自动语音识别与理解研讨会（ASRU）上发表，2013 年。[46] A. Graves, A. Mohamed 和 G. Hinton. 使用深度循环神经网络的语音识别。在国际声学、语音与信号处理会议（ICASSP）上发表，2013 年。[47] K. Lang, A. Waibel 和 G. Hinton. 用于孤立词识别的时延神经网络架构。神经网络，3(1)：23–43，1990 年。[48] A. Waibel, T. Hanazawa, G. Hinton, K. Shikano 和 K. Lang. 使用时延神经网络的音素识别。IEEE 声学、语音与信号处理学报，37：328–339，1989 年。[50] Moore, Gordon E. (1965-04-19). "将更多组件集成到集成电路中"。电子学。2016-07-01 检索。[51] [`www.emc.com/collateral/analyst-reports/idc-the-digital-universe-in-2020.pdf`](http://www.emc.com/collateral/analyst-reports/idc-the-digital-universe-in-2020.pdf) [52] D. Beaver, S. Kumar, H. C. Li, J. Sobel 和 P. Vajgel, “在干草堆中找针：Facebook 的照片存储”，在 OSDI，2010 年，第 47-60 页。[53] Michele Banko 和 Eric Brill. 2001 年。大规模语料库在自然语言歧义消解中的扩展。在第 39 届计算语言学年会（ACL '01）上发表。计算语言学协会，美国宾夕法尼亚州斯特劳兹堡，26-33 页。[54] [`www.huffingtonpost.in/entry/big-data-and-deep-learnin_b_3325352`](http://www.huffingtonpost.in/entry/big-data-and-deep-learnin_b_3325352) [55] X. W. Chen 和 X. Lin, "大数据深度学习：挑战与展望," 在 IEEE Access，第 2 卷，第 X 期，514-525 页，2014 年。[56] Bengio Y, LeCun Y (2007) 将学习算法扩展至人工智能。In: Bottou L, Chapelle O, DeCoste D, Weston J (编). 大规模核机器。麻省理工学院出版社，美国剑桥，第 34 卷。第 321–360 页。[`www.iro.umontreal.ca/~lisa/pointeurs/bengio+lecun_chapter2007.pdf`](http://www.iro.umontreal.ca/~lisa/pointeurs/bengio+lecun_chapter2007.pdf) [57] A. Coats, B. Huval, T. Wng, D. Wu 和 A. Wu, “使用 COTS HPS 系统的深度学习，”J. Mach. Learn. Res., 第 28 卷，第 3 期，第 1337-1345 页，2013 年。[58] J.Wang 和 X. Shen, "大间隔半监督学习," J. Mach. Learn. Res., 第 8 卷，第 8 期，第 1867-1891 页，2007 年。[59] R. Fergus, Y. Weiss 和 A. Torralba, “在庞大的图像集合中进行半监督学习”，在 NIPS 会议论文集（2009 年）中，第 522-530 页。[60] J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee 和 A. Ng, “多模态深度学习”，在第 28 届国际机器学习大会（2011 年）上发表，美国华盛顿州贝尔维尤。[61] N. Srivastava 和 R. Salakhutdinov, “使用深度玻尔兹曼机的多模态学习”，在 NIPS 会议论文集（2012 年）中发表。[62] L. Bottou, “在线算法与随机逼近”，在《神经网络中的在线学习》，D. Saad（编）。剑桥大学出版社，英国剑桥，1998 年。[63] A. Blum 和 C. Burch, “在线学习与度量任务系统问题”，在第 10 届计算学习理论年会（1997 年）上发表，第 45-53 页。[64] N. Cesa-Bianchi, Y. Freund, D. Helmbold 和 M. Warmuth, “在线预测与对话策略”，在欧罗科尔特计算学习理论会议论文集，第 53 卷。英国牛津，1994 年，第 205-216 页。[65] Y. Freund 和 R. Schapire, “博弈论、在线预测与提升”，在第 9 届计算学习理论年会（1996 年）上发表，第 325-332 页。[66] Q. Le 等，“使用大规模无监督学习构建高级特征”，在国际机器学习会议论文集，2012 年。[67] C. P. Lim 和 R. F. Harrison, “使用多个神经网络系统的在线模式分类：一项实验研究”，IEEE 系统、人工智能与控制学报，C 卷，33(2)：235-247，2003 年 5 月。[68] P. Riegler 和 M. Biehl, “两层神经网络中的在线反向传播”，J. Phys. A，第 28 卷，第 20 期，第 L507-L513 页，1995 年。[69] M. Rattray 和 D. Saad, “多层神经网络的全局最优在线学习规则”，J. Phys. A，数学一般，第 30 卷，第 22 期，第 L771-776 页，1997 年。

[70] P. Campolucci, A. Uncini, F. Piazza 和 B. Rao，``针对局部递归神经网络的在线学习算法，''IEEE Trans. Neural Netw.，第 10 卷，第 2 期，页 253-271，1999 年 3 月。[71] N. Liang, G. Huang, P. Saratchandran 和 N. Sundararajan，``一种快速且准确的前馈网络在线顺序学习算法，''IEEE Trans. Neural Netw.，第 17 卷，第 6 期，页 1411-1423，2006 年 11 月。[72] L. Bottou 和 O. Bousequet，``神经网络中的随机梯度学习，''在 Neuro-Nimes 会议论文集，1991 年。[73] S. Shalev-Shwartz, Y. Singer 和 N. Srebro，``Pegasos：SVM 的原始估计子梯度求解器，''在国际机器学习会议论文集，2007 年。[74] D. Scherer, A. Müller 和 S. Behnke，``卷积架构中池化操作的评估用于物体识别，''在国际人工神经网络会议论文集，2010 年，页 92-101。[75] J. Chien 和 H. Hsieh，``使用顺序和变分贝叶斯学习进行非平稳源分离，''IEEE Trans. Neural Netw. Learn. Syst.，第 24 卷，第 5 期，页 681-694，2013 年 5 月。[76] W. de Oliveira，``Rosenblatt 贝叶斯算法在非平稳环境中的学习，''IEEE Trans. Neural Netw.，第 18 卷，第 2 期，页 584-588，2007 年 3 月。[77] Hadoop 分布式文件系统，[`hadoop.apache.org/2012`](http://hadoop.apache.org)。[78] T. White. 2009 年\. 《Hadoop：权威指南》。O'Reilly Media, Inc. 2009 年 6 月。[79] Shvachko, K.; Hairong Kuang; Radia, S.; Chansler, R.，2010 年 5 月\. 《Hadoop 分布式文件系统》，2010 年 IEEE 第 26 届大容量存储系统与技术研讨会（MSST）。卷，无，页 1，10。[80] Hadoop 分布式文件系统，[`hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/`](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/)。[81] Dev, Dipayan 和 Ripon Patgiri. "Dr. Hadoop: 一种无限可扩展的 Hadoop 元数据管理——小象如何变得永生。" 《信息技术与电子工程前沿》17（2016 年）：15-31。[82] [`deeplearning4j.org/`](http://deeplearning4j.org/) [83] Dean, Jeffrey 和 Sanjay Ghemawat. "MapReduce: 简化大规模集群数据处理。" 《ACM 通讯》51.1（2008 年）：107-113。[84] [`deeplearning.net/software/theano/`](http://deeplearning.net/software/theano/) [85] [`torch.ch/`](http://torch.ch/) [86] Borthakur, Dhruba. "Hadoop 分布式文件系统：架构与设计。" Hadoop 项目网站 11.2007（2007 年）：21。[87] Borthakur, Dhruba. "HDFS 架构指南。" HADOOP APACHE PROJECT [`hadoop.apache.org/docs/r1.2.1/hdfs_design.pdf`](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.pdf)（2008 年）：39。[88] [`deeplearning4j.org/quickstart`](http://deeplearning4j.org/quickstart)

[89] LeCun, Yann 和 Yoshua Bengio。"用于图像、语音和时间序列的卷积网络。"大脑理论和神经网络手册 3361.10（1995 年）：1995。 [90] LeCun, Y.、Bottou, L.、Bengio, Y.和 Haffner, P.（1998）。基于梯度的文档识别应用学习。IEEE 86, 2278-2324。doi:10.1109/5.726791 [91] Gao, H.、Mao, J.、Zhou, J.、Huang, Z.、Wang, L.和 Xu, W.（2015）。您在与机器交谈吗？多语言图像问答的数据集和方法。arXiv 预印本 arXiv:1505.05612。 [92] Srinivas, Suraj 等人。"计算机视觉深度卷积神经网络的分类学。"arXiv 预印本 arXiv:1601.06615（2016）。 [93] Zhou, Y-T.等人。"使用神经网络进行图像恢复。"IEEE 声学、语音和信号处理期刊 36.7（1988）：1141-1151。 [94] Maas, Andrew L.、Awni Y. Hannun 和 Andrew Y. Ng。"整流器非线性改进神经网络声学模型。"Proc. ICML。Vol. 30。No. 1。2013。 [95] He, Kaiming 等人。"深入研究整流器：超越图像分类上的人类水平性能。"IEEE 国际计算机视觉会议论文集。2015。 [96] [`web.engr.illinois.edu/~slazebni/spring14/lec24_cnn.pdf`](http://web.engr.illinois.edu/~slazebni/spring14/lec24_cnn.pdf) [97] Zeiler, Matthew D.和 Rob Fergus。"可视化和理解卷积网络。"欧洲计算机视觉会议。斯普林格国际出版社，2014 年。 [98] Simonyan, Karen 和 Andrew Zisserman。"用于大规模图像识别的非常深的卷积网络。"arXiv 预印本 arXiv:1409.1556（2014）。 [99] Szegedy, Christian 等人。"通过卷积更深入地挖掘。"IEEE 计算机视觉与模式识别会议论文集。2015。 [100] He, Kaiming 等人。"用于图像识别的深度残余学习。"arXiv 预印本 arXiv:1512.03385（2015）。 [101] Krizhevsky, Alex。"并行化卷积神经网络的一个奇怪的技巧。"arXiv 预印本 arXiv:1404.5997（2014）。 [102] S. Hochreiter 和 J. Schmidhuber。长短期记忆。神经计算，9（8）：1735-1780，1997。 [103] Mikolov, Tomas 等人。"基于递归神经网络的语言模型。"Interspeech。Vol. 2。2010。 [104] Rumelhart, D. E.、Hinton, G. E.和 Williams, R. J.（1986）。通过反向传播学习表示。自然，323，533-536。 [105] Mikolov, T.、Sutskever, I.、Chen, K.、Corrado, G.和 Dean, J.（2013a）。单词和短语的分布式表示及其组合性。在神经信息处理系统 26 的进展中，页面 3111-3119。 [106] Graves, A.（2013）。使用递归神经网络生成序列。arXiv:1308.0850 [cs.NE]。 [107] Pascanu, R.、Mikolov, T.和 Bengio, Y.（2013a）。训练递归神经网络的困难。在 ICML’2013。

[108] Mikolov, T., Sutskever, I., Deoras, A., Le, H., Kombrink, S., 和 Cernocky, J. (2012a)。使用神经网络的子词语言建模。未发表的[109] Graves, A., Mohamed, A., 和 Hinton, G. (2013)。深度递归神经网络的语音识别。ICASSP[110] Graves, A., Liwicki, M., Fernandez, S., Bertolami, R., Bunke, H., 和 Schmidhuber, J. (2009)。一种新型的连接主义系统，用于改善无约束手写识别。IEEE 模式分析与机器智能汇刊。[111] [`karpathy.github.io/2015/05/21/rnn-effectiveness/`](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) [112] [`web.stanford.edu/group/pdplab/pdphandbook/handbookch8.html`](https://web.stanford.edu/group/pdplab/pdphandbook/handbookch8.html) [113] Schuster, Mike, 和 Kuldip K. Paliwal。"双向递归神经网络"。IEEE 信号处理汇刊 45.11 (1997): 2673-2681。[114] Graves, Alan, Navdeep Jaitly, 和 Abdel-rahman Mohamed。"基于深度双向 LSTM 的混合语音识别"。自动语音识别与理解（ASRU），2013 IEEE 研讨会。IEEE，2013[115] Baldi, Pierre, 等。"在蛋白质二级结构预测中利用过去和未来"。生物信息学 15.11 (1999): 937-946[116] Hochreiter, Sepp, 和 Jürgen Schmidhuber。"长短时记忆"。神经计算 9.8 (1997): 1735-1780。[117] A. Graves, M. Liwicki, S. Fernandez, R. Bertolami, H. Bunke, J. Schmidhuber。改进的无约束手写识别的新型连接主义系统。IEEE 模式分析与机器智能汇刊，31 卷，第 5 期，2009 年。[118] 使用 QuickType，苹果公司希望做的不仅仅是猜测你的下一条文本。它还想给你一个 AI。"WIRED"。2016 年 6 月 16 日检索。[119] Sak, Hasim, Andrew W. Senior, 和 Françoise Beaufays。"用于大规模声学建模的长短时记忆递归神经网络架构"。INTERSPEECH。2014 年。[120] Poultney, Christopher, Sumit Chopra, 和 Yann L. Cun。"利用基于能量的模型进行稀疏表示的高效学习"。神经信息处理系统进展。2006 年。[121] LeCun, Yann, 等。"关于基于能量的学习的教程"。结构化数据预测 1 (2006): 0。[122] Ackley, David H., Geoffrey E. Hinton, 和 Terrence J. Sejnowski。"Boltzmann 机的学习算法"。认知科学 9.1 (1985): 147-169。[123] Desjardins, G. 和 Bengio, Y. (2008)。卷积 RBM 在视觉中的经验评估。技术报告 1327，蒙特利尔大学计算机科学与运筹学系。[124] Hinton, G. E., Osindero, S., 和 Teh, Y. (2006)。一种快速学习算法，用于深度置信网络。神经计算，18，1527–1554。[125] Hinton, G. E. (2007b)。学习多层表示。认知科学趋势，11(10)，428–434。

[126] Bengio, Yoshua 等人. "深度网络的贪婪分层训练." 《神经信息处理系统进展》19 (2007): 153. [127] A.-R. Mohamed, T. N. Sainath, G. Dahl, B. Ramabhadran, G. E. Hinton 和 M. A. Picheny, ``使用判别特征进行电话识别的深度信念网络,'' 见《IEEE ICASSP 会议论文集》，2011 年 5 月，pp. 5060-5063. [128] R. Salakhutdinov 和 G. Hinton, ``语义哈希,'' 《近似推理国际期刊》，第 50 卷，第 7 期，pp. 969-978，2009 年. [129] G. W. Taylor, G. E. Hinton 和 S. T. Roweis, ``使用二进制潜变量建模人类运动,'' 见《神经信息处理系统进展》. 美国马萨诸塞州剑桥: MIT 出版社, 2006 年，pp. 1345-1352. [130] Zhang, Kunlei 和 Xue-Wen Chen. "大规模深度信念网络与 MapReduce." 《IEEE Access》2 (2014): 395-403.

[131] Yoshua Bengio, Aaron Courville 和 Pascal Vincent. 表示学习：回顾与新视角. 技术报告，arXiv:1206.5538，2012b. [132] Makhzani, Alireza 和 Brendan Frey. "k-稀疏自编码器." arXiv 预印本 arXiv:1312.5663 (2013). [133] Hinton, Geoffrey E. 和 Ruslan R. Salakhutdinov. "使用神经网络减少数据的维度." 《科学》313.5786 (2006): 504-507. [134] Vincent, Pascal 等人. "堆叠去噪自编码器：在具有局部去噪准则的深度网络中学习有用的表示." 《机器学习研究期刊》11.12 (2010): 3371-3408. [135] Salakhutdinov, Ruslan 和 Geoffrey Hinton. "语义哈希." RBM 500.3 (2007): 500. [136] Nesi, Paolo, Gianni Pantaleo 和 Gianmarco Sanesi. "基于 Hadoop 的平台用于网页和文档的自然语言处理." 《视觉语言与计算期刊》31 (2015): 130-138.
