# 第八章：下一步是什么？

我们做到了！我们创建了六个不同的神经网络项目，每个项目都有其独特的架构。在本章的最后，我们将回顾我们所取得的成就。我们还将看看一些近期在神经网络和深度学习方面的进展，这些进展在前几章中并未涉及。最后，我们将展望未来，看看神经网络和人工智能的前景。

具体来说，以下是我们将在本章中讨论的主题：

+   本书中使用的不同神经网络回顾

+   神经网络关键概念回顾

+   神经网络的前沿进展

+   神经网络的局限性

+   人工智能与机器学习的未来

+   跟上机器学习的步伐

+   最喜爱的机器学习工具

+   你将创造什么？

# 将一切整合在一起

我们在本书中已经完成了很多工作。让我们快速回顾一下每一章中所构建的项目，以及支持它们的神经网络架构。本节也为我们在本书中涉及的关键神经网络概念提供了一个快速复习。

# 机器学习与神经网络基础

在第一章，*机器学习与神经网络基础*，我们从构建最简单的单层神经网络——**感知器**开始。从本质上讲，感知器只是一个数学函数，它接收一组输入，执行一些数学运算，然后输出计算结果。对于感知器，数学运算就是将权重与输入进行相乘。

因此，正确的权重集决定了我们的神经网络性能的好坏。一开始，神经网络的权重是随机初始化的。调整神经网络的权重以最大化模型性能的过程叫做**模型训练**。在训练过程中，神经网络的权重不断被调整，以最小化**损失函数**。损失函数只是一个数学函数，允许我们量化神经网络的表现。我们用来调整权重以最小化损失函数的算法称为**梯度下降**。

我们从零开始创建了我们的第一个神经网络，没有使用像 Keras 或 scikit-learn 这样的机器学习库。我们将这个简单的神经网络应用于一个玩具示例，在这个示例中，神经网络需要学习二元（即 1 或 0）预测。我们使用平方和误差作为损失函数来训练我们的神经网络，其中如果预测错误，误差为 1，如果预测正确，误差为 0。然后，我们对每个个体数据点的误差进行求和，得到平方和误差。我们看到我们的神经网络能够从训练示例中学习，并为测试数据提供准确的预测。

在理解了神经网络的概念后，我们接着讨论了 Python 中最重要的神经网络和机器学习库。我们了解到，在处理表格数据（即来自 CSV 文件的数据）时，`pandas` 是不可或缺的工具，并且它也可以用于数据可视化。更重要的是，我们讨论了 Keras，这是在 Python 中进行神经网络和深度学习工作时的核心库。

我们讨论了 Keras 中的基本构建模块——`层`。Keras 中有多种类型的`层`，但最重要的两种是`卷积层`和`全连接层`，它们是我们书中讨论的所有神经网络的构建模块。

# 多层感知机预测糖尿病

在第二章，*使用多层感知机预测糖尿病*，我们通过创建一个神经网络，开始了第一个项目，目标是预测患者是否有糖尿病风险。具体来说，我们使用了一个称为 MLP（多层感知机）的神经网络来进行这种分类预测。我们使用了 Pima 印第安人糖尿病数据集来进行这一问题的研究。该数据集包含 768 个不同的数据点，每个数据点有 8 个特征和一个标签。

作为机器学习工作流的一部分，在使用该数据集进行神经网络训练之前，我们需要进行数据预处理。我们需要填补缺失值、进行数据标准化，并将数据集分为训练集和测试集。

在这一章中，我们还用 Keras 构建了我们的第一个神经网络。我们展示了如何使用 Keras 中的 `Sequential` 类，一层一层地构建神经网络，就像将乐高积木一个个堆叠起来一样。我们还研究了 **ReLU** 和 **sigmoid 激活** 函数，这两种是最常用的激活函数。

我们通过使用 **混淆矩阵** 和 **ROC 曲线** 等度量指标，评估了神经网络的表现，这些工具对于帮助我们理解神经网络的性能非常重要。

# 使用深度前馈神经网络预测出租车费用

在第三章，*使用深度前馈神经网络预测出租车费用*，我们在一个 **回归** **预测** 问题中，使用了 **深度前馈神经网络**，任务是预测纽约市出租车费用的美元金额，基于拾取和放下地点等特征。在这个项目中，我们需要处理一个包含缺失数据和数据异常的嘈杂数据集。我们了解到，数据可视化对于帮助我们识别数据集中的异常值，以及发现数据集中的重要趋势至关重要。

这个项目也是第一次进行特征工程的项目。利用现有特征，我们创建了其他特征，提升了神经网络的准确性。最后，我们使用自己的数据集，在 Keras 中创建并训练了一个深度前馈神经网络，最终得到了令人印象深刻的均方误差 3.50。

# 猫狗大战 – 使用 CNN 进行图像分类

在 第四章，*猫狗大战 – 使用 CNN 进行图像分类*，我们开始了第一个图像识别和计算机视觉领域的神经网络项目。具体来说，我们创建了一个能够分类猫狗图像的 CNN。

我们看到数字图像本质上是二维数组（对于灰度图像），每个数组值代表每个像素的强度。CNN 是解决大多数图像识别问题的首选神经网络架构。CNN 中的 **过滤** 和 **卷积** 操作用于识别图像中的重要空间特征，这使得它非常适用于图像识别问题。多年来，CNN 经历了多次迭代和改进。LeNet 在 1998 年首次出现，随后更复杂的神经网络如 VGG16 和 ResNet 在 2010 年代相继开发出来。

我们在 Keras 中创建了自己的 CNN，并使用 Keras 的 `ImageDataGenerator` 和 `flow_from_directory` 方法来训练神经网络，当数据集（猫狗图片）太大，无法一次性加载到内存时。我们创建的简单 CNN 达到了 80% 的准确率。我们还使用了 **迁移学习**，利用预训练的 VGG16 神经网络来解决猫狗分类问题。这种方法展示了 VGG16 模型的复杂性，达到了 90% 的准确率。

# 使用自编码器去除图像噪声

在 第五章，*使用自编码器去除图像噪声*，我们研究了 **自编码器**，一种特殊的神经网络，它学习输入的 **潜在表示**。自编码器有一个 **编码器** 部件，它将输入压缩为潜在表示，还有一个 **解码器** 部件，它使用潜在表示重建输入。

在自编码器中，用于潜在表示的隐藏层大小是一个重要的超参数，需要仔细调整。潜在表示的大小应该足够小，以表示输入特征的压缩表示，同时也要足够 *大*，使得解码器能够重建输入，而不会有太多损失。我们训练了一个自编码器来压缩 MNIST 图像。我们通过使用 32 × 1 的隐藏层大小，达到了 24.5 的压缩率，同时确保重建的图像与原始输入图像相似。

我们还研究了如何使用自编码器进行**图像** **去噪**。通过使用噪声图像作为输入，清晰图像作为输出，我们可以训练自编码器识别不属于噪声的图像特征。这样，我们就可以应用自编码器从图像中去除噪声。这样的自编码器被称为**去噪自编码器**。我们训练并应用了一个去噪自编码器，针对包含脏污办公文件扫描图像的去噪办公文件数据集。在去噪自编码器中使用深度卷积层后，我们成功地几乎完全去除了办公文件中的噪声。

# 使用 LSTM 进行电影评论情感分析

在第六章《使用 LSTM 进行电影评论情感分析》中，我们探讨了情感分析，它是**自然语言处理**（**NLP**）领域中的一个序列问题。我们看到，情感分析对人类来说也是一个具有挑战性的问题，因为词语在不同语境中传递的意义不同。RNN 被认为是处理情感分析等序列问题的最佳神经网络形式。然而，传统的递归神经网络存在长期依赖问题，这使得它不适用于处理长篇文本。

一种变种的递归神经网络，称为 LSTM 网络，旨在克服长期依赖问题。LSTM 的直觉是，由于其能够为特定词语分配权重，我们可以有选择性地忘记不重要的词语，而记住更重要的词语。

我们还研究了如何通过词嵌入将词语表示为向量。词嵌入将词语转化为较低维度的特征空间，将相似的词语放置在彼此靠近的位置，而将不相似的词语放置得更远。

我们在 Keras 中创建并训练了一个 LSTM 网络，用于对 IMDB 电影评论数据集进行情感分析，同时研究了一些在训练 LSTM 网络时需要调整的重要超参数。特别是，我们看到了优化器对 LSTM 网络性能的显著影响。我们最终的 LSTM 网络在分类 IMDB 电影评论情感时达到了 85%的准确率。

# 使用神经网络实现面部识别系统

在第七章《*使用神经网络实现人脸识别系统*》中，我们使用 Siamese 神经网络创建了一个人脸识别系统。Siamese 神经网络是一类特殊的神经网络，具有共享的、联结的组件。Siamese 神经网络接受一对图像作为输入，并可以训练输出与两张图像相似度成反比的距离。这构成了使用 Siamese 神经网络进行人脸识别的基本思路。如果输入图像对中的两张人脸属于同一人物，那么输出的距离应该很小，反之亦然。通过使用对比损失训练 Siamese 神经网络，输入正对（属于同一人物的人脸）和负对（属于不同人物的人脸），它最终会学会为正对和负对输出适当的距离。

我们还讨论了人脸检测，它是人脸识别的重要前提。人脸检测用于从原始图像中隔离和提取人脸，提取后的图像会传递给神经网络进行人脸识别。人脸检测通常使用 Viola-Jones 算法，它利用 Haar 特征来检测图像中的面部特征。为了创建我们的人脸识别系统，我们结合了 OpenCV，它利用计算机摄像头的视频流进行人脸检测，以及我们训练的人脸识别 Siamese 神经网络。

# 神经网络的前沿进展

正如我们在前一节中看到的，本书涉及了很多内容。然而，神经网络的可能性实际上是无穷无尽的。还有一些重要的神经网络类型，我们在本书中还没有讨论。为了完整起见，我们将在本节中讨论它们。正如你将看到的，这些神经网络与我们到目前为止看到的非常不同，它应该会为你提供一个全新的视角。

# 生成对抗网络

**生成对抗网络**（**GANs**）是一类生成神经网络。要理解生成模型，重要的是将它们与判别模型进行对比。在本书之前的内容中，我们只关注了判别模型。判别模型关注学习特征到标签的映射。例如，当我们创建一个卷积神经网络（CNN）来分类猫狗图像时，CNN 是一个判别模型，它学习特征（图像）到标签（猫或狗）的映射。

另一方面，生成模型关注于在给定标签的情况下生成适当的特征。例如，给定标注为猫和狗的图像，生成模型将学习为每个标签生成适当的特征。换句话说，生成模型学会合成猫狗的图像！

GAN 是近年来人工智能领域最令人兴奋的发展之一。事实上，Yann LeCun 曾称 GAN 是*过去 10 年中机器学习最有趣的想法*。那么，GAN 是如何工作的呢？直观地讲，GAN 由两个部分组成——生成器和判别器。生成器的作用是生成特征（例如图像），判别器的作用是评估生成的特征与原始特征的相似度。在训练 GAN 时，我们将生成器与判别器对立起来（这也是 GAN 中“*对抗*”一词的来源）。最终，生成器会变得如此强大，以至于判别器无法区分生成的特征与原始特征，GAN 就能生成栩栩如生的图像。

为了了解 GAN 的强大程度，请查看以下由 NVIDIA 研究人员发布的论文：

[`arxiv.org/pdf/1812.04948.pdf`](https://arxiv.org/pdf/1812.04948.pdf)

在这篇论文中，你将看到一些由 GAN 生成的面孔样本，这些面孔与真实的人类面孔无法区分。GAN 的进步速度令人惊讶，现在我们已经能够生成超真实的人类面孔。

GAN 已被应用于几个有趣的案例。例如，研究人员已找到一种将 GAN 应用于风格迁移的方法。在风格迁移中，GAN 学习给定图像的艺术风格，并将其应用到另一幅图像上。例如，我们可以使用 GAN 来学习文森特·梵高著名的*星夜*画作的艺术风格，并将其应用于任何任意图像。可以访问[`github.com/jcjohnson/neural-style`](https://github.com/jcjohnson/neural-style)查看风格迁移的示例。

# 深度强化学习

强化学习是机器学习的一个分支，旨在学习在任何给定状态下采取最佳行动，以最大化未来的奖励。强化学习已被应用于象棋等游戏。在象棋中，棋盘上棋子的布局代表了我们所处的状态。强化学习的作用是学习在任何给定状态下应采取的最佳行动（即，应该移动哪些棋子）。

如果我们将任何任意状态下应采取的最佳行动表示为一个数学函数（称之为行动价值函数），那么我们可以使用神经网络来学习这个行动价值函数。一旦这个函数被学习出来，我们的神经网络就可以用来预测在任何给定状态下应该采取的最佳行动——本质上，我们的神经网络就成了一个无敌的棋手！将深度神经网络应用于强化学习的过程称为深度强化学习。

深度强化学习在游戏中取得了很多成功。2017 年，使用深度强化学习训练的 AI 游戏玩家 AlphaGo 成功战胜了世界顶级围棋选手之一柯洁。AlphaGo 的胜利引发了广泛的关注和讨论，尤其是关于人工智能未来的讨论。

2018 年，深度强化学习迎来了又一次飞跃，当时 OpenAI Five（由五个神经网络组成的团队）成功击败了 Dota 2 的业余玩家。Dota 2 是一款多人在线游戏，曾被认为是人工智能无法攻克的领域，原因是游戏的复杂性和动态性极高。职业 Dota 2 玩家是公认的明星，全球顶尖 Dota 2 玩家因其思维敏捷和反应迅速而深受粉丝喜爱。如今，OpenAI Five 不断突破其在 Dota 2 中的能力边界。OpenAI Five 每天通过自我对战进行训练，积累 180 年的游戏经验。OpenAI Five 将游戏状态视为由 20,000 个数字组成的数组，然后从中决定采取最佳行动。

要了解更多关于 OpenAI Five 的信息，并尝试互动演示，请访问 OpenAI 的官网：

[`blog.openai.com/openai-five/`](https://blog.openai.com/openai-five/)

除了游戏玩法，深度强化学习也为自动驾驶汽车做出了重要贡献。自动驾驶汽车通过计算机视觉算法来抽象周围的世界。这种抽象表示了车辆当前的状态。然后，深度强化学习根据车辆的状态选择最佳行动（例如，加速或刹车）。

# 神经网络的局限性

神经网络的潜力似乎是无限的，但实际上，神经网络和机器学习在一般情况下也有其局限性。

首先，神经网络的可解释性较差。换句话说，神经网络通常作为黑箱算法工作，难以*解释*神经网络产生的结果。以我们在第二章中的项目《使用多层感知机预测糖尿病》为例，我们使用神经网络预测患糖尿病风险的患者。神经网络输入数据，如血糖水平、血压、年龄等，并输出患者是否有糖尿病风险的预测。尽管神经网络能够高精度地做出预测，但我们实际上并不清楚哪些因素影响这些预测。这对于医生来说可能是不够的，因为他们可能希望为患者制定干预计划。

在实际应用中，这种缺乏可解释性的问题对商业用户来说是一个真实的担忧，因为他们可能不愿意使用黑箱算法。除了模型的性能之外，商业用户还希望了解模型的工作原理，以及哪些因素影响着与业务相关的目标变量。

提高神经网络可解释性是研究人员正在努力的领域之一。特别是，研究人员正在致力于在深度神经网络应用于计算机视觉问题时，生成可解释的结果。为此，一些研究人员提出将 CNN 的卷积层减少到图形模型，表示神经网络内部隐藏的语义层次结构。

神经网络的第二个局限性是，当应用于图像识别时，它们很容易被欺骗。在第四章，*猫与狗—使用卷积神经网络进行图像分类*中，我们在使用卷积神经网络（CNN）对猫和狗的图像进行分类时，达到了高精度（90%）。虽然 CNN 被认为是图像识别领域的最先进技术，但它们的致命弱点是容易受到恶意代理的欺骗。

近日，Nguyen 等人的一项研究表明，由于神经网络感知图像的方式与人类不同，一张人类完全无法识别的图像可以用来欺骗神经网络，从而导致神经网络做出错误预测。有关这些对人类无法识别，但可以用来欺骗神经网络的合成图像的示例，请参阅 Nguyen 等人的论文：

[`arxiv.org/pdf/1412.1897.pdf`](https://arxiv.org/pdf/1412.1897.pdf)

此外，研究人员表明，通过将这些合成图像以人类无法察觉的方式与现有图像结合，神经网络可以被欺骗，从而产生错误的预测。

这一发现对使用神经网络的计算机视觉安全系统的可行性产生了重大影响。恶意代理有可能向神经网络提供精心制作的输入图像，从而欺骗神经网络，绕过安全系统。

很显然，神经网络远非完美，它们绝不是解决我们所有问题的魔法方案。然而，仍然有理由保持乐观，因为每天都有新的突破不断被发现，这些突破提高了我们对神经网络的理解。

# 人工智能和机器学习的未来

接下来，让我们讨论一下人工智能和机器学习的未来。依我看，在未来几十年内，我们将看到以下几个关键发展的崛起：

+   人工通用智能

+   自动化机器学习

# 人工通用智能

**人工通用智能**（**AGI**）被定义为*一种人工智能代理，具有执行任何人类能够完成的智力任务的能力*。一些研究者区分了弱人工智能与强人工智能，其中弱人工智能用来描述当今的 AI 水平。现在的 AI 代理主要专注于执行单一任务。例如，我们训练 AI 代理预测患者是否有糖尿病风险，另一个 AI 代理则用来分类猫和狗的图像。这些 AI 代理是独立的，训练来执行某一特定任务的 AI 代理不能用来执行其他任务。这种狭隘的 AI 视角被称为弱人工智能。  

另一方面，强人工智能指的是能够执行任何任务的通用 AI 代理。一个强人工智能代理可能是一个自我意识的、类人化的 AI 助手。目前，强人工智能还属于科幻领域。在我看来，目前我们掌握的机器学习算法（例如神经网络、决策树）不足以实现 AGI。正如**弗朗索瓦·肖莱**（Keras 的开发者）所说：

*“仅仅通过扩大现有的深度学习技术，无法实现通用智能。”*  

- **弗朗索瓦·肖莱**  

要实现 AGI，需要一个重大的突破——类似于神经网络和深度学习曾经定义了我们今天所知的*弱人工智能*的那种突破。  

# 自动化机器学习  

尽管数据科学家被称为**21 世纪最性感的职业**，但现实情况是，大多数数据科学家花费了大量的时间在一些费时的任务上，如数据预处理和超参数调优。为了应对这个问题，像谷歌这样的公司正在开发工具来自动化机器学习过程。谷歌最近推出了**AutoML**，这是一种使用神经网络设计神经网络的解决方案。谷歌认为，AutoML 可以将目前数据科学家所拥有的专业知识进行打包，并通过云端按需提供这些专业知识作为服务。  

当然，一些数据科学家对他们可能会被 AI 取代的想法感到不满，并声称自动化机器学习永远不可能成为现实。我的个人观点是，真相介于两者之间。如今，已经有一些 Python 库可以帮助我们自动化一些更为耗时的任务，比如超参数调优。这些库可以通过暴力搜索一系列超参数，选择最大化结果的一组超参数。甚至有一些 Python 库可以自动可视化数据集，自动绘制最相关的图表。随着这些库的逐步普及，我认为数据科学家将花费更少的时间在这些繁琐的活动上，更多的时间将用于其他有影响力的任务，如模型设计和特征工程。  

# 跟上机器学习的步伐  

机器学习和人工智能领域在不断发展，新的知识不断被发现。我们如何在这个不断变化的领域保持更新呢？就个人而言，我通过阅读书籍、科学期刊以及在真实数据集上进行实践来保持更新。

# 书籍

你正在阅读这本书，说明你已经致力于提升自己的知识！但遗憾的是，我们无法在本书中涵盖所有机器学习的每个话题。如果你喜欢本书，你可能会想参考 Packt 的图书目录。你会发现 Packt 在几乎每一个机器学习话题上都有书籍。Packt 团队还通过不断出版关于最新技术的书籍，确保读者能够与机器学习领域的最新发展保持同步。

Packt 的目录可以在 [`www.packtpub.com/all`](https://www.packtpub.com/all) 找到。

# 科学期刊

人工智能研究人员一直相信开放共享。他们认为知识应该自由共享，社区成长的最佳方式就是通过分享。因此，大多数前沿的人工智能和机器学习科学论文都可以在网上免费找到。尤其是，许多 AI 研究人员会在以下网站分享他们的研究成果：

[`arxiv.org`](https://arxiv.org)

**Arxiv** 是一个开放获取的科学期刊存储库。大多数前沿研究成果一经发布，便会自由分享在 arxiv 上。这促使了快速的发展，思想不断在上一个基础上迭代。

# 在真实数据集上练习

最后，作为机器学习从业者，保持我们的技能锋利至关重要，定期练习是非常必要的。**Kaggle** 是一个举办数据科学竞赛的网站，使用真实的世界数据集。竞赛有不同的难度级别，初学者和专家都可以找到适合自己水平的内容。数据集的类型也各不相同，从表格数据到图像（计算机视觉问题），再到文本（自然语言处理问题）。

Kernels 可能是 Kaggle 上最有用的功能之一。通过 Kaggle Kernels，用户可以公开分享他们的代码和方法。这确保了结果的可重复性，通常你会学到一些自己之前不知道的技巧。Kaggle 还提供了一个免费的云环境来运行你的代码，包括 GPU 支持。如果你想挑战自己的技能，读完本书后，Kaggle 是一个很好的起点。

# 最喜爱的机器学习工具

在本书中，我使用了大量的 Python 和 Keras。除此之外，还有一些我认为很有用的机器学习工具：

+   **Jupyter Notebook**：Jupyter Notebook 是交互式笔记本，通常在机器学习项目的早期阶段使用。使用 Jupyter Notebook 的优势在于，它允许我们迭代地编写交互式代码。与`.py`的 Python 文件不同，代码可以分块执行，输出（例如图表）可以与代码一起显示。

+   **Google Colab**：Google Colab 是一个免费的云平台，允许我们在云端编写 Jupyter Notebook 代码。所有的修改都会自动同步，团队成员可以在同一个笔记本上进行协作。Google Colab 的最大优势是，你可以在云端使用 GPU 实例运行代码，而这些实例是 Google 免费提供的！这意味着我们可以从世界任何地方高效地训练深度神经网络，即使我们没有强大的 GPU。

# 总结

在本章中，我们快速回顾了本书中涉及的所有不同类型的神经网络和关键概念。接着，我们探讨了一些神经网络的前沿发展，包括生成对抗网络和深度强化学习。尽管神经网络的潜力有时看起来无穷无尽，但我们必须记住，当前神经网络的状态也有其局限性。接下来，我们概述了机器学习和人工智能的整体发展，并展示了人工智能在不久的未来可能呈现的样貌。我们还给读者提供了一些关于如何跟上机器学习这一不断发展的领域的建议。

最后，我想通过提问来结束本书——你将创造什么？我们生活在一个高度先进的科技时代，信息可以自由获取。无论你现在处于什么水平，无论你是经验丰富的机器学习专家还是刚入门的初学者，你都拥有成功所需的所有资源。我鼓励你保持好奇心，始终渴望知识。许多这个领域的发现来自像你我一样的好奇者。我们每个人都能做出贡献。你将创造什么？
