# 前言

**人工智能**（**AI**）自诞生以来已经走过了漫长的历程，从一个未来主义的概念转变为渗透我们生活方方面面的普及技术。从医疗健康、金融到公共和私人部门的决策过程，AI 系统已成为我们日常生活中不可或缺的一部分。随着以 ChatGPT 为代表的 AI 驱动应用成为个人和企业的基本工具，我们必须高度重视随之而来的伦理、社会和技术挑战。

本书的动机源于我们的信念：现在，比任何时候都更需要为一个 AI 能够成为推动社会进步的积极力量的未来打下基础。随着 AI 不断塑造我们的世界，本书旨在为 AI 工程师、商业领袖、政策制定者以及其他利益相关者提供关于负责任且值得信赖的 AI 系统开发与实施的全面指导。

在这本全面的书籍中，我们将探讨负责任 AI 的各个方面，包括**机器学习**（**ML**）模型的脆弱性、对抗性攻击的易受性以及强有力安全措施的重要性。我们将深入研究以安全性和可靠性为优先的风险规避方法，尽量减少潜在的危害和意外后果。本书还将探讨各国采取的政策框架和策略，以确保 AI 的伦理开发与部署，并涉及数据隐私的关键问题，提供保护用户信息的技术和最佳实践，以维护对 AI 系统的信任。此外，我们将讨论 AI 模型评估、不可预见性和验证的方法；MLOps 和 AutoML 在企业环境中推动高效、可扩展且负责任的 AI 实践的作用；以及 AI 公平性的重要性，解决数据收集、预处理和模型优化中的挑战，减少偏差，确保公正的结果。我们还将讨论 AI 系统中的透明度和可解释性的必要性，伦理治理和监督，并介绍构建适应性强、经过校准的 AI 模型的技术，使其能够有效应对不断变化的环境和需求。此外，我们将深入探讨可持续特征库的概念，促进在负责任 AI 模型开发中的效率和一致性，并展示多个行业中负责任 AI 的实际案例研究和应用，展示其影响和好处。

本书旨在成为一本全面的资源，帮助那些希望利用人工智能（AI）力量的读者，同时应对其所带来的关键伦理和社会挑战。我们希望本书能激励你加入负责任的 AI 发展行列，并在自己的职业和个人事业中应用其原则和实践。

# 本书的目标读者

本书面向有经验的机器学习专业人士，帮助他们了解机器学习模型和框架的风险及数据泄露，如何通过设计实现公正，并学习如何开发和使用可复用组件，从而减少设置和维护 AI 生态系统的工作量和成本。

# 本书内容概述

*第一章*，*机器学习模型的风险与攻击*，详细概述了与机器学习模型可能遭遇的不同类型攻击相关的关键术语，帮助读者初步理解攻击者如何设计机器学习攻击。本章中，你将了解直接和间接的攻击，这些攻击会危及系统的隐私。在此背景下，本章突出了由于敏感信息丧失给组织带来的损失，以及个人如何容易将机密信息暴露给对手。

*第二章*，*风险规避方法学与框架的出现*，全面介绍了风险评估框架、工具和方法学，这些可以直接应用于评估模型风险。本章中，你将了解数据平台中包含的工具和模型设计技术，帮助降低大规模应用中的风险。本章的主要目标是提高数据匿名化和验证技术的意识，同时介绍与隐私相关的不同术语和措施。

*第三章*，*关于可信 AI 的法规与政策*，介绍了各国通过的不同法律，以保护和防止客户敏感信息的丧失。你将了解不同伦理专家小组的形成、政府举措以及正在制定的政策，以确保所有 AI 解决方案的伦理性与合规性。

*第四章*，*大数据与模型设计管道中的隐私管理*，详细介绍了与大数据系统相关的不同组件，这些组件作为构建块，帮助我们有效部署 AI 模型。本章介绍了如何在基于微服务的架构中处理合规性问题，以确保没有信息泄露。本章中，你将了解单个微服务中所需的不同安全原则，以及在大规模部署机器学习模型时需要在云中纳入的安全措施。

*第五章*，*机器学习管道、模型评估与不确定性处理*，介绍了人工智能/机器学习工作流。该章节深入探讨了用于分类、回归、生成和强化学习的不同机器学习算法。章节还讨论了与这些算法的可靠性和可信度相关的问题。我们从介绍机器学习管道的各种组件开始。接着，章节简要探索了分类、回归和聚类任务中重要的人工智能/机器学习算法。此外，我们还讨论了各种类型的不确定性、其成因及量化不确定性的技术。

*第六章*，*超参数调优、MLOps 与 AutoML*，在上一章的基础上继续讲解了机器学习管道中持续训练的必要性。构建机器学习模型是一个迭代过程，且由于存在如此多的模型，每个模型都有大量的超参数，这对初学者来说无疑增加了复杂性。本章简要介绍了当前的 AutoML 选项，适用于你的机器学习工作流。它扩展了无代码/低代码解决方案的适用场景。还探讨了主要云服务提供商在易用性、功能和模型可解释性方面提供的解决方案。此外，本章还涉及了编排工具，如 Kubeflow 和 Vertex AI，用于管理机器学习模型的持续训练和部署。

*第七章*，*公平性概念与公平数据生成*，提出了由于缺乏标准化，针对不同类型数据、知识本体、词汇等的非公平数据收集问题。本章的主要目的是强调数据质量的重要性，因为偏见数据集可能会在机器学习模型中引入隐性偏见。该章重点介绍了全球范围内需要实践的更好的数据收集、管理和监控指导原则。你还将进一步了解评估策略的初步步骤如何帮助构建无偏数据集，从而为基于机器学习的预测提供新的人工智能分析和数字化转型之旅。

*第八章*，*模型优化中的公平性*，介绍了优化和获得公平机器学习模型所必需的不同优化约束和技术。本章的重点是通过研究揭示的不同新定制优化器，帮助你构建监督式、无监督式和半监督式的公平机器学习模型。从更广泛的角度来看，本章为你准备了创建和定义模型约束的基础步骤，这些约束可以在训练过程中被不同的优化器使用。你还将理解如何通过适当的度量评估这些基于约束的模型，以及优化技术所产生的额外训练开销，这些都将使得模型能够设计出自己的算法。

*第九章*，*模型可解释性*，介绍了可以用来揭开机器学习模型“黑箱”之谜的不同方法。我们将讨论为什么需要能够解释模型的预测结果。本章涵盖了诸如 SHAP 和 LIME 等算法和技术，以便为现有模型增加可解释性组件。我们还将探索像 DoWhy 和 CausalNex 这样的库，来查看最终用户可用的可解释性功能。我们还将深入研究 Vertex AI、SageMaker 和 H2O.ai 提供的可解释性功能。

*第十章*，*伦理与模型治理*，强调了在生产环境中需要建立的伦理治理流程，以便快速识别与模型开发和部署相关的所有风险。本章还涵盖了监控所有模型的最佳实践，包括那些处于库存中的模型。你将深入了解模型生命周期不同阶段出现的风险的实际细微差别，以及这些风险在模型存放于库存中时如何得到缓解。在这里，你还将了解不同的风险分类程序，以及它们如何帮助最小化由低性能模型导致的业务损失。此外，你还将详细了解如何在数据聚合、模型训练的迭代轮次和超参数调优过程中建立适当的治理。

*第十一章*，*模型适应性的伦理学*，重点讨论了为生产中的模型建立伦理治理流程，旨在快速检测模型失败或输出预测中的任何偏差迹象。通过阅读本章，您将更深入地理解监控模型性能和上下文模型预测的实际细节，方法是通过不断审查数据并与过去进行基准对比，从而制定适当的可操作的短期和长期计划。此外，您还将详细了解导致模型重训练的条件以及拥有完美校准模型的重要性。本章还突出了公平性和模型校准之间的权衡。

*第十二章*，*构建可持续的企业级 AI 平台*，重点讨论了组织目标、举措以及领导层支持如何帮助我们构建可持续的伦理 AI 平台。本章的目标是强调组织将伦理 AI 原则与本地价值观、人权、社会规范和解决方案所运行社区的行为相联系的重要性。在此背景下，本章突出了大规模 AI 解决方案对环境的影响，以及在使用联邦学习进行模型训练和部署时需要纳入的正确程序。本章进一步深入探讨了重要概念，强烈强调了保持社会责任感的必要性，以及能够设计软件、模型和平台的重要性。

*第十三章*，*可持续模型生命周期管理、特征库和模型校准*，探讨了在模型开发生命周期中需要遵循的最佳实践，这些实践有助于创建可持续的特征库。本章将强调实施隐私保护的重要性，以便在不妥协安全和隐私方面的前提下，最大化特征库的重用和团队之间的协作。本章还深入探讨了不同的模型校准技术，这些技术对于构建可扩展的可持续机器学习平台至关重要。在这里，您还将了解如何设计适应性强的特征库，以及我们如何在联邦学习中最好地融入监控和治理。

*第十四章*，*行业广泛的应用案例*，提供了各行业不同应用案例的详细概述。此章节的主要目的是向来自不同行业领域的读者介绍如何将伦理和合规性集成到他们的系统中，以构建公平公正的人工智能系统，并赢得最终用户的信任与信心。您还将有机会将前几章学习的算法和工具应用于不同的业务问题。此外，您将了解如何在不同的行业领域中重复使用伦理设计模式。

# 最大化利用本书

每章有不同的要求，已经在各自的章节中说明。

您应该具备基本的机器学习（ML）、Python、scikit-learn、PyTorch 和 TensorFlow 知识，以更好地理解本书中的概念。

# 下载示例代码文件

您可以从 GitHub 上下载本书的示例代码文件，网址为 [`github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI`](https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI)。如果代码有更新，将会在 GitHub 仓库中进行更新。

我们还在我们的丰富书籍和视频目录中提供其他代码包，您可以访问 [`github.com/PacktPublishing/`](https://github.com/PacktPublishing/) 查看！

# 使用的约定

本书中使用了多种文本约定。

`文本中的代码`：表示文本中的代码词汇、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。例如：“Atlas 提供了在动态创建分类时的巨大灵活性，如 PII、`EXPIRES_ON`、`DATA_QUALITY` 和 `SENSITIVE`，并支持 `EXPIRES_ON` 分类中的 `expiry_date` 属性。”

代码块设置如下：

```py
model.compile(optimizer='rmsprop', loss=aleatoric_loss, metrics=['mae'])
```

所有命令行输入或输出按如下格式书写：

```py
roc_auc_score(y_test, y_pred_uncal)
>>> 0\. 9185432154389126
```

**粗体**：表示新术语、重要单词或屏幕上的词汇。例如，菜单或对话框中的词语通常以 **粗体** 显示。以下是一个例子：“此外，我们可以通过进入 **RBAC** | **策略管理** | **发现** | **设置** | **实时控制** 来查看可以遵循的顺序安全控制，以增强我们的安全堆栈。”

提示或重要说明

如此显示。

# 联系我们

我们非常欢迎读者的反馈。

**一般反馈**：如果您对本书的任何部分有疑问，请通过电子邮件联系我们，地址是 customercare@packtpub.com，并在邮件主题中注明书名。

**勘误**：尽管我们已经尽力确保内容的准确性，但错误仍然会发生。如果您在本书中发现任何错误，我们将非常感激您能向我们报告。请访问 [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata) 并填写表格。

**盗版**：如果您在互联网上发现我们作品的任何非法版本，我们将非常感激您提供其位置地址或网站名称。请通过版权@packt.com 联系我们，并附上该材料的链接。

**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并有兴趣撰写或为书籍贡献内容，请访问[authors.packtpub.com](http://authors.packtpub.com)。

# 分享您的想法

阅读完*负责任的 AI 平台和模型设计*后，我们很想听听您的想法！请[点击此处直接访问亚马逊评论页面](https://packt.link/r/1803237074)并分享您的反馈。

您的评论对我们和技术社区都非常重要，并将帮助我们确保提供优质内容。

# 下载本书的免费 PDF 副本

感谢您购买本书！

您是否喜欢随时随地阅读，但又无法携带纸质书籍？您的电子书购买是否与您选择的设备不兼容？

不用担心，现在每本 Packt 书籍都提供无 DRM 的 PDF 版本，您可以免费获取。

在任何地方、任何设备上随时阅读。直接从您最喜欢的技术书籍中搜索、复制并粘贴代码到您的应用程序中。

福利不仅仅到此为止，您还可以获得独家折扣、新闻简报以及每天送到您收件箱的精彩免费内容。

按照以下简单步骤即可享受这些福利：

1.  扫描二维码或访问以下链接

![](img/B18681_QR_Free_PDF.jpg)

[`packt.link/free-ebook/9781803237077`](https://packt.link/free-ebook/9781803237077)

1.  提交您的购买证明

1.  就是这样！我们将直接把您的免费 PDF 和其他福利发送到您的电子邮件。

# 第一部分：全球环境下的风险评估与机器学习框架

本部分详细介绍了生产中的机器学习模型所面临的风险、威胁和挑战。在本部分中，您将了解对手可以实施的各种攻击类型，以及保护模型免受此类攻击的重要性。本部分还涵盖了全球各大委员会设立的指南和标准，以促进国家和组织层面的各种行动和倡议。

本部分由以下章节组成：

+   *第一章*，*机器学习模型的风险与攻击*

+   *第二章*，*风险规避方法论和框架的出现*

+   *第三章*，*可信 AI 的监管与政策*
