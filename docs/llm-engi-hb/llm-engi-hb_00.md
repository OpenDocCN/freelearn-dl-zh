# 前言

**LLM** 工程领域迅速成为人工智能和机器学习中的一个关键领域。随着 LLM 继续革命性地改变自然语言处理和生成，能够有效地在现实场景中实施、优化和部署这些模型的专业人员的需求呈指数级增长。LLM 工程涵盖了从数据准备和模型微调到推理优化和生产部署的广泛学科，需要软件工程、机器学习专业知识和领域知识的独特融合。

**机器学习运维**（**MLOps**）在 LLM 在生产环境中的成功实施中扮演着至关重要的角色。MLOps 将 DevOps 的原则扩展到机器学习项目中，专注于自动化和简化整个 ML 生命周期。对于 LLM 来说，MLOps 尤为重要，因为这些模型具有复杂性和规模。它解决了管理大型数据集、处理模型版本控制、确保可重复性和维护模型性能随时间变化等挑战。通过采用 MLOps 实践，LLM 项目可以实现更高的效率、可靠性和可扩展性，最终导致更成功和有影响力的部署。

**《LLM 工程师手册》** 是应用最佳实践到新兴领域 LLM 工程的全面指南。在整个章节中，读者将找到简化后的关键概念、实用技术和专家在每个 LLM 生命周期阶段的建议。本书涵盖了数据工程、监督微调、模型评估、推理优化以及 **检索增强生成**（**RAG**）管道开发等主题。

为了说明这些概念在实际中的应用，本书将开发一个名为 LLM Twin 的端到端项目，贯穿全书，目标是模仿某人的写作风格和个性。这个用例将展示如何构建一个最小可行产品来解决特定问题，使用 LLM 工程和 MLOps 的各个方面。

读者可以期待更深入地了解如何收集和准备数据供 LLM 使用，针对特定任务微调模型，优化推理性能，并实施 RAG 管道。他们将学习如何评估 LLM 性能，使模型与人类偏好保持一致，并部署基于 LLM 的应用程序。本书还涵盖了 MLOps 的基本原则和实践，使读者能够构建可扩展、可重复和健壮的 LLM 应用程序。

# 这本书面向谁

本书面向对 LLM 的实际应用感兴趣的各种技术专业人士和爱好者。它非常适合希望转向 AI 项目的软件工程师。虽然对软件开发有一定的了解是有益的，但本书从零开始解释了许多概念，即使是对 AI 和机器学习新手也易于理解。

对于那些已经在机器学习领域工作的人来说，这本书将增强你在实现和部署基于 LLM 的系统方面的技能。我们深入探讨了 MLOps 的基础知识，指导你使用开源 LLM 创建最小可行产品来解决现实世界问题。

# 本书涵盖的内容

*第一章*，*理解 LLM Twin 概念和架构*，介绍了 LLM Twin 项目，该项目在整本书中作为生产级 LLM 应用的端到端示例，并定义了 FTI 架构用于构建可扩展的 ML 系统，并将其应用于 LLM Twin 用例。

*第二章*，*工具和安装*，展示了用于构建现实世界 LLM 应用的 Python、MLOps 和云工具，例如协调器、实验跟踪器、提示监控和 LLM 评估工具。它展示了如何在本地上安装和使用它们进行测试和开发。

*第三章*，*数据工程*，展示了实现一个数据收集管道，该管道抓取多个网站，如 Medium、GitHub 和 Substack，并将原始数据存储在数据仓库中。它强调在现实世界的 ML 应用中，从动态来源收集原始数据而非静态数据集的重要性。

*第四章*，*RAG 特征管道*，介绍了 RAG 的基本概念，如嵌入、vanilla RAG 框架、向量数据库以及如何优化 RAG 应用。它通过架构和实现 LLM Twin 的 RAG 特征管道，并采用软件最佳实践，应用了 RAG 理论。

*第五章*，*监督微调*，探讨了使用指令-答案对对预训练语言模型进行特定任务微调的过程。它涵盖了创建高质量数据集、实现全微调、LoRA 和 QLoRA 等微调技术，并提供了在自定义数据集上微调 Llama 3.1 8B 模型的实用演示。

*第六章*，*偏好对齐的微调技术*，介绍了将语言模型与人类偏好对齐的技术，重点关注**直接偏好优化**（**DPO**）。它涵盖了创建自定义偏好数据集、实现 DPO，并提供了使用 Unsloth 库对 TwinLlama-3.1-8B 模型进行对齐的实用演示。

*第七章*，*评估 LLM*，详细介绍了评估语言模型和 LLM 系统性能的各种方法。它介绍了通用和领域特定评估，并讨论了流行的基准。本章包括使用多个标准对 TwinLlama-3.1-8B 模型进行实际评估。

*第八章*，*推理优化*，涵盖了关键的优化策略，如投机解码、模型并行性和权重量化。它讨论了如何提高推理速度、减少延迟和最小化内存使用，并介绍了流行的推理引擎及其特性比较。

第九章，*RAG 推理管道*，通过从头实现自我查询、重新排序和过滤向量搜索等方法，探讨了高级 RAG 技术。它涵盖了设计和实现 LLM Twin 的 RAG 推理管道以及一个类似于在流行的框架如 LangChain 中看到的自定义检索模块。

第十章，*推理管道部署*，介绍了 ML 部署策略，如在线、异步和批量推理，这些策略有助于构建和部署 LLM Twin 微调模型到 AWS SageMaker，并构建一个 FastAPI 微服务以将 RAG 推理管道作为 RESTful API 公开。

第十一章，*MLOps 和 LLMOps*，介绍了 LLMOps 是什么，从其在 DevOps 和 MLOps 的根源开始。本章解释了如何将 LLM Twin 项目部署到云端，例如将 ML 管道部署到 AWS，并展示了如何使用 Docker 容器化代码以及构建 CI/CD/CT 管道。它还在 LLM Twin 推理管道之上添加了一个提示监控层。

附录，*MLOps 原则*，涵盖了用于构建可扩展、可重复和健壮的 ML 应用的六个 MLOps 原则。

# 为了充分利用本书

为了最大限度地提高您的学习体验，您至少需要具备软件开发原则和实践的基础知识。熟悉 Python 编程特别有益，因为本书的示例和代码片段主要是用 Python 编写的。虽然具备机器学习概念的经验是有益的，但并非绝对必要，因为本书提供了许多基本 AI 和 ML 概念的说明。然而，您应该熟悉基本的数据结构和算法，并且有一些使用 API 和云服务的经验。

假设您熟悉版本控制系统如 Git，因为本书有一个用于代码示例的 GitHub 仓库。虽然本书旨在让那些对 AI 和 LLM 新手友好，但如果您在这些领域有一些背景知识，您会发现理解我们提出的更高级的概念和技术更容易。

## 下载示例代码文件

该书的代码包托管在 GitHub 上，网址为[`github.com/PacktPublishing/LLM-Engineers-Handbook`](https://github.com/PacktPublishing/LLM-Engineers-Handbook)。我们还有其他来自我们丰富图书和视频目录的代码包，可在[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)找到。查看它们吧！

## 下载彩色图像

我们还提供了一个包含本书中使用的截图/图表的彩色图像的 PDF 文件。您可以从这里下载：[`packt.link/gbp/9781836200079`](https://packt.link/gbp/9781836200079)。

## 使用的约定

本书使用了一些文本约定。

`CodeInText`：表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 昵称。例如：“在`format_samples`函数中，我们将 Alpaca 聊天模板应用于每条单独的消息。”

代码块如下设置：

```py
def format_samples(example):
    example["prompt"] = alpaca_template.format(example["prompt"])
    example["chosen"] = example['chosen'] + EOS_TOKEN
    example["rejected"] = example['rejected'] + EOS_TOKEN
    return {"prompt": example["prompt"], "chosen": example["chosen"], "rejected": example["rejected"]} 
```

当我们希望将您的注意力引到代码块的一个特定部分时，相关的行或项目将以粗体显示：

```py
def format_samples(example):
    example["prompt"] = alpaca_template.format(example["prompt"])
    example["chosen"] = example['chosen'] + EOS_TOKEN
    example["rejected"] = example['rejected'] + EOS_TOKEN
    **return** **{****"prompt"****: example[****"prompt"****],** **"chosen"****:** example["chosen"], "rejected": example["rejected"]} 
```

任何命令行输入或输出都如下所示：

```py
poetry install --without aws 
```

**粗体**：表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词在文本中显示如下。例如：“要这样做，请转到 GitHub 分叉仓库顶部的**设置**选项卡。在左侧面板中，在**安全**部分，点击**秘密和变量**切换，最后点击**操作**。”

警告或重要注释看起来像这样。

技巧和窍门看起来像这样。

# 联系我们

我们欢迎读者的反馈。

**一般反馈**：请发送电子邮件至`feedback@packtpub.com`，并在邮件主题中提及书籍的标题。如果您对本书的任何方面有疑问，请通过`questions@packtpub.com`发送电子邮件给我们。

**勘误表**：尽管我们已经尽一切努力确保内容的准确性，但错误仍然可能发生。如果您在这本书中发现了错误，如果您能向我们报告，我们将不胜感激。请访问[`www.packtpub.com/submit-errata`](http://www.packtpub.com/submit-errata)，点击**提交勘误**，并填写表格。

**盗版**：如果您在互联网上以任何形式遇到我们作品的非法副本，如果您能提供位置地址或网站名称，我们将不胜感激。请通过`copyright@packtpub.com`与我们联系，并提供材料的链接。

**如果您想成为一名作者**：如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[`authors.packtpub.com`](http://authors.packtpub.com)。

# 分享您的想法

一旦您阅读了*LLM 工程师手册，第一版*，我们很乐意听到您的想法！请[点击此处直接访问此书的 Amazon 评论页面](https://packt.link/r/1836200072)并分享您的反馈。

您的评论对我们和科技社区都很重要，并将帮助我们确保我们提供高质量的内容。

# 下载此书的免费 PDF 副本

感谢您购买此书！

你喜欢在旅途中阅读，但无法随身携带你的印刷书籍吗？

您的电子书购买是否与您选择的设备不兼容？

不要担心，现在，您每购买一本 Packt 书籍，都可以免费获得该书的 DRM 免费 PDF 版本。

在任何地方、任何设备上阅读。直接从你喜欢的技术书籍中搜索、复制和粘贴代码到你的应用程序中。

优惠不仅限于此，您还可以获得独家折扣、时事通讯和丰富的免费内容，每天直接发送到您的邮箱。

按照以下简单步骤获取优惠：

1.  扫描下面的二维码或访问以下链接：

![](img/B31105_Free_PDF_QR.png)

[`packt.link/free-ebook/9781836200079`](https://packt.link/free-ebook/9781836200079)

1.  提交您的购买证明。

1.  就这样！我们将直接将免费 PDF 和其他优惠发送到您的邮箱。
