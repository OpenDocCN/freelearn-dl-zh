["```py\nimport torch\nfrom transformers import BertTokenizer, BertModel\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef visualize_attention(model, tokenizer, text):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    outputs = model(inputs, output_attentions=True)\n    attention = outputs.attentions[-1].squeeze().detach().numpy()\n    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(attention, xticklabels=tokens,\n        yticklabels=tokens, cmap=\"YlGnBu\")\n    plt.title(\"Attention Visualization\")\n    plt.show()\n# Example usage\nmodel_name = \"bert-base-uncased\"\nmodel = BertModel.from_pretrained(model_name)\ntokenizer = BertTokenizer.from_pretrained(model_name)\ntext = \"The cat sat on the mat.\"\nvisualize_attention(model, tokenizer, text)\n```", "```py\nimport torch\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\ndef probe_bert_layers(model, tokenizer, texts, labels, layer_nums):\n    # Get BERT embeddings for each layer\n    def get_embeddings(text):\n        inputs = tokenizer(text, return_tensors=\"pt\",\n            padding=True, truncation=True)\n        with torch.no_grad():\n            outputs = model(inputs, output_hidden_states=True)\n        return outputs.hidden_states\n    results = {}\n    for layer in layer_nums:\n        embeddings = [\n            get_embeddings(text)[layer]\n            .squeeze()\n            .mean(dim=0)\n            .numpy() for text in texts\n        ]\n        # Split data\n        X_train, X_test, y_train, y_test = train_test_split(\n        embeddings, labels, test_size=0.2, random_state=42\n    )\n        # Train and evaluate probe\n        probe = LogisticRegression(random_state=42)\n        probe.fit(X_train, y_train)\n        y_pred = probe.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        results[f\"Layer_{layer}\"] = accuracy\n    return results\n# Example usage\nmodel_name = \"bert-base-uncased\"\nmodel = BertModel.from_pretrained(model_name)\ntokenizer = BertTokenizer.from_pretrained(model_name)\ntexts = [\"The cat sat on the mat.\", \"The dog chased the ball.\", ...]  # Add more examples\nlabels = [0, 1, ...]  # Corresponding labels (e.g., 0 for simple, 1 for complex sentences)\nlayer_nums = [1, 6, 12]  # Layers to probe\nprobe_results = probe_bert_layers(model, tokenizer, texts, labels,\n    layer_nums)\nfor layer, accuracy in probe_results.items():\n    print(f\"{layer} Accuracy: {accuracy:.2f}\")\n```", "```py\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef integrated_gradients(\n    model, tokenizer, text, target_class, steps=50\n):\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n    baseline_ids = torch.zeros_like(input_ids)\n    alphas = torch.linspace(0, 1, steps)\n    delta = input_ids - baseline_ids\n    accumulated_grads = 0\n    for alpha in alphas:\n        interpolated_ids = baseline_ids + alpha * delta\n        interpolated_ids.requires_grad_()\n        outputs = model(interpolated_ids)\n        pred = outputs.logits[:, target_class]\n        model.zero_grad()\n        pred.backward()\n        accumulated_grads += interpolated_ids.grad\n    attributions = \\\n        (input_ids - baseline_ids) * accumulated_grads / steps\n    return attributions.squeeze().detach().numpy()\n# Example usage\nmodel_name = \"bert-base-uncased\"\nmodel = BertForSequenceClassification.from_pretrained(model_name)\ntokenizer = BertTokenizer.from_pretrained(model_name)\ntext = \"This movie was fantastic!\"\ntarget_class = 1  # Assuming 1 is the positive sentiment class\nattributions = integrated_gradients(model, tokenizer, text,\n    target_class)\n# Visualize attributions\ntokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(text))\nplt.figure(figsize=(10, 5))\nplt.bar(range(len(tokens)), attributions)\nplt.xticks(range(len(tokens)), tokens, rotation=45)\nplt.title(\"Integrated Gradients Attribution\")\nplt.show()\n```", "```py\nimport torch\nfrom transformers import BertTokenizer, BertModel\nimport matplotlib.pyplot as plt\ndef analyze_multihead_attention(model, tokenizer, text):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    outputs = model(inputs, output_attentions=True)\n    attention = outputs.attentions[-1].squeeze().detach().numpy()\n    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n    num_heads = attention.shape[0]\n    fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n    axs = axs.ravel()\n    for i in range(num_heads):\n        sns.heatmap(attention[i], xticklabels=tokens,\n            yticklabels=tokens, ax=axs[i], cmap=\"YlGnBu\")\n        axs[i].set_title(f\"Head {i+1}\")\n    plt.tight_layout()\n    plt.show()\n# Example usage\nmodel_name = \"bert-base-uncased\"\nmodel = BertModel.from_pretrained(model_name)\ntokenizer = BertTokenizer.from_pretrained(model_name)\ntext = \"The president of the United States visited Paris last week.\"\nanalyze_multihead_attention(model, tokenizer, text)\n```", "```py\n    import torch\n    import torch.nn as nn\n    class InterpretableTransformer(nn.Module):\n        def __init__(self, vocab_size, d_model, nhead, num_layers):\n            super().__init__()\n            self.embedding = nn.Embedding(vocab_size, d_model)\n            encoder_layer = nn.TransformerEncoderLayer(\n                d_model, nhead, batch_first=True\n            )\n            self.transformer = nn.TransformerEncoder(encoder_layer,\n                num_layers)\n            self.fc = nn.Linear(d_model, vocab_size)\n    ```", "```py\n    def get_attention_patterns(self, x):\n        \"\"\"Extract attention weights from each layer\"\"\"\n        x = self.embedding(x)\n        attention_patterns = []\n        for layer in self.transformer.layers:\n            # Register a hook to capture attention weights\n            attention_weights = None\n            def hook(module, input, output):\n                nonlocal attention_weights\n                attention_weights = output[1]  # attention weights\n            handle = layer.self_attn.register_forward_hook(hook)\n            x = layer(x)\n            attention_patterns.append(attention_weights)\n            handle.remove()\n        return attention_patterns\n    ```", "```py\n    def analyze_neuron_activations(self, x, layer_idx):\n        \"\"\"Analyze individual neuron activations in a specific layer\"\"\"\n        activations = []\n        def hook(module, input, output):\n            activations.append(output.detach())\n        # Register hook on specific layer\n        handle = list(self.transformer.layers)[layer_idx]\\\n            .register_forward_hook(hook)\n        # Forward pass\n        with torch.no_grad():\n            self(x)\n        handle.remove()\n        layer_activations = activations[0]\n        # Find most active neurons\n        mean_activation = layer_activations.mean(dim=(0,1))  # Average across batch and sequence\n        top_neurons = torch.topk(mean_activation, k=10)\n        return top_neurons.indices, top_neurons.values\n    ```", "```py\n    def intervention_study(self, x, layer_idx, neuron_idx):\n        \"\"\"Study how zeroing out specific neurons affects the output\"\"\"\n        original_output = None\n        modified_output = None\n        def hook_original(module, input, output):\n            nonlocal original_output\n            original_output = output.detach()\n        def hook_modified(module, input, output):\n            nonlocal modified_output\n            modified = output.clone()\n            modified[:,:,neuron_idx] = 0  # Zero out specific neuron\n            modified_output = modified\n            return modified\n        layer = list(self.transformer.layers)[layer_idx]\n        # Get original output\n        handle = layer.register_forward_hook(hook_original)\n        self(x)\n        handle.remove()\n        # Get modified output\n        handle = layer.register_forward_hook(hook_modified)\n        self(x)\n        handle.remove()\n        return original_output, modified_output\n    ```", "```py\n    import matplotlib.pyplot as plt\n    def visualize_attention(attention_weights, tokens=None):\n        \"\"\"Visualize attention patterns\"\"\"\n        plt.figure(figsize=(10, 8))\n        plt.imshow(attention_weights[0].cpu(), cmap='viridis')\n        if tokens is not None:\n            plt.xticks(range(len(tokens)), tokens, rotation=45)\n            plt.yticks(range(len(tokens)), tokens)\n        plt.colorbar()\n        plt.title('Attention Pattern')\n        plt.show()\n    ```", "```py\n# Initialize model\nmodel = InterpretableTransformer(vocab_size=1000,\n    d_model=256, nhead=8, num_layers=4)\n# Sample input\ninput_ids = torch.randint(0, 1000, (1, 20))  # Batch size 1, sequence length 20\n# Get attention patterns\nattention_patterns = model.get_attention_patterns(input_ids)\n# Analyze neuron activations\ntop_neurons, activation_values = model.analyze_neuron_activations(\n    input_ids, layer_idx=0\n)\n# Perform intervention study\noriginal, modified = model.intervention_study(input_ids,\n    layer_idx=0, neuron_idx=42)\n# Visualize attention\nvisualize_attention(attention_patterns[0])  # Visualize first layer's attention\n```", "```py\nimport torch\nfrom transformers import (\n    BertForSequenceClassification,\n    DistilBertForSequenceClassification,\n    BertTokenizer)\ndef distill_bert(\n    teacher_model, student_model, tokenizer, texts, temperature=2.0\n):\n    teacher_model.eval()\n    student_model.train()\n    optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-4)\n    loss_fn = torch.nn.KLDivLoss(reduction=\"batchmean\")\n    for text in texts:\n        inputs = tokenizer(\n            text, return_tensors=\"pt\", padding=True, truncation=True\n        )\n        with torch.no_grad():\n            teacher_outputs = teacher_model(inputs)\n            teacher_logits = teacher_outputs.logits / temperature\n        student_outputs = student_model(inputs)\n        student_logits = student_outputs.logits / temperature\n        loss = loss_fn(torch.log_softmax(student_logits, dim=-1),\n                       torch.softmax(teacher_logits, dim=-1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    return student_model\n# Example usage\nteacher_model = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\")\nstudent_model = DistilBertForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\"\n)\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\ntexts = [\"This movie was great!\", \"I didn't like the book.\", ...]  # Add more examples\ndistilled_model = distill_bert(\n    teacher_model, student_model, tokenizer, texts\n)\n```"]