<html><head></head><body>
		<div id="_idContainer061">
			<h1 class="chapter-number" id="_idParaDest-99"><a id="_idTextAnchor137"/><a id="_idTextAnchor138"/>6</h1>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor139"/>AI/ML Application Design</h1>
			<p>As the landscape of intelligent applications evolves, their architectural design becomes pivotal for efficiency, scalability, operability, and security. This chapter provides a guide on key topics to consider as you embark on creating robust and responsive <span class="No-Break">AI/ML applications.</span></p>
			<p>The chapter begins with <strong class="bold">data modeling</strong>, examining how to organize data in a way that maximizes effectiveness for three different consumers: humans, applications, and AI models. You will learn about <strong class="bold">data storage</strong>, considering the impact of different data types and determining the best storage technology. You will estimate storage needs and determine the best MongoDB Atlas cluster configuration for your <span class="No-Break">example application.</span></p>
			<p>As you learn about <strong class="bold">data flow</strong>, you will explore the detailed movement of data through ingestion, processing, and output to maintain integrity and velocity. This chapter also addresses <strong class="bold">data lifecycle management</strong>, including updates, aging, and retention, ensuring that data remains relevant <span class="No-Break">and compliant.</span></p>
			<p>Security concerns are stretched further for AI/ML applications due to the risks of exposing data or logic to AI models. This chapter discusses security measures and <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) to protect sensitive data and logic integrity. You will also learn the best principles for data storage, flow, modeling, and security, providing practical advice to avoid <span class="No-Break">common pitfalls.</span></p>
			<p>Throughout the chapter, you will use a fictitious news application called <strong class="bold">MongoDB Developer News</strong> (<strong class="bold">MDN</strong>), which will be like Medium.com, equipping you to create intelligent applications by using a <span class="No-Break">practical example.</span></p>
			<p>This chapter will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li><span class="No-Break">Data modeling</span></li>
				<li><span class="No-Break">Data storage</span></li>
				<li><span class="No-Break">Data flow</span></li>
				<li>Freshness <span class="No-Break">and retention</span></li>
				<li>Security <span class="No-Break">and RBAC</span></li>
				<li><span class="No-Break">Best practices</span></li>
			</ul>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor140"/>Technical requirements</h1>
			<p>The following are the prerequisites to follow along with the code in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>A MongoDB Atlas cluster <strong class="source-inline">M0</strong> tier (free) should <span class="No-Break">be sufficient</span></li>
				<li>An OpenAI account and API key with access to the <span class="No-Break"><strong class="source-inline">text-embedding-3-large</strong></span><span class="No-Break"> model</span></li>
				<li>A Python 3 <span class="No-Break">working environment</span></li>
				<li>Installed Python libraries for MongoDB, LangChain, <span class="No-Break">and OpenAI</span></li>
				<li>Atlas Search indexes and Vector Search indexes created on the MongoDB <span class="No-Break">Atlas cluster</span></li>
			</ul>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor141"/>Data modeling</h1>
			<p>This section delves into the diverse types of data required by AI/ML systems, including structured, unstructured, and semi-structured data, and how these are applied to MDN’s news articles. The following are short descriptions of each to set a <span class="No-Break">basic understanding:</span></p>
			<ul>
				<li><strong class="bold">Structured data</strong> conforms to a predefined schema and is traditionally stored in relational databases for transactional information. It powers systems of engagement <span class="No-Break">and intelligence.</span></li>
				<li><strong class="bold">Unstructured data</strong> includes binary assets, such as PDFs, images, videos, and others. Object stores such as Amazon S3 allow storing these under a flexible directory structure at a <span class="No-Break">lower cost.</span></li>
				<li><strong class="bold">Semi-structured data</strong>, such as JSON documents, allow each document to define its schema, accommodating both common and unique data points, or even the absence of <span class="No-Break">some data.</span></li>
			</ul>
			<p>MDN will store news articles, subscriber profiles, billing information, and more. For simplicity, in this chapter, you will focus on the data about each news article and related binary content (which would be images). <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.1</em> describes the data model of the <span class="No-Break"><strong class="source-inline">articles</strong></span><span class="No-Break"> collection.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer055">
					<img alt="" role="presentation" src="image/B22495_06_01.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1: Schema for the articles collection</p>
			<p>The articles collection represents a news article with metadata, including creation details, tags, and contributors. All documents feature a title, summary, body content in HTML and plain text, and associated media elements such <span class="No-Break">as images.</span></p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor142"/>Enriching data with embeddings</h2>
			<p>To complete the MDN data model, you need to consider data that will also be represented and stored via embeddings. <strong class="bold">Text embeddings</strong> for article titles and summaries will enable semantic search, while <strong class="bold">image embeddings</strong> will help find similar artwork used across articles. <em class="italic">Table 6.1</em> describes the data fields, embedding models to use, and their <span class="No-Break">vector sizes.</span></p>
			<table class="No-Table-Style" id="table001-4">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Type</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Field(s)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Embedding model</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Vector size</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Text</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">title</strong></span></p>
						</td>
						<td class="No-Table-Style" rowspan="2">
							<p><span class="No-Break">OpenAI </span><span class="No-Break"><strong class="source-inline">text-embedding-3-large</strong></span></p>
						</td>
						<td class="No-Table-Style" rowspan="2">
							<p><span class="No-Break">1,024</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Text</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">summary</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Image</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">contents</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">OpenAI CLIP</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">768</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.1: Embeddings for the articles collection</p>
			<p>Each article has a title and summary. Instead of embedding them separately, you will concatenate them and create one text embedding for simplicity. Ideally, for images, you would store the embedding with each content object in the <strong class="source-inline">contents</strong> array. However, support for fields inside arrays of objects for vector indexes is not available today in MongoDB Atlas and leads to the <strong class="bold">anti-pattern of bloated documents</strong>. The best practice is to store image embeddings in a separate collection and use the <strong class="bold">extended reference schema design pattern</strong>. You can learn more about indexing arrays with MongoDB, bloated documents, and the extended reference pattern from the links given in the <em class="italic">Further Reading</em> chapter of this book. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.2</em> shows the updated <span class="No-Break">data model.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer056">
					<img alt="" role="presentation" src="image/B22495_06_02.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2: Schema for articles with embeddings</p>
			<p><em class="italic">Table 6.2</em> shows the corresponding <span class="No-Break">vector indexes.</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table002-2">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Collection</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">articles</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Collection</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">article_content_embeddings</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Vector </strong><span class="No-Break"><strong class="bold">index</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">semantic_embedding_vix</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Vector </strong><span class="No-Break"><strong class="bold">index</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">content_embedding_vix</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
{</pre>							<pre class="source-code">
  "fields": [</pre>							<pre class="source-code">
	{</pre>							<pre class="source-code">
  	"numDimensions": 1024,</pre>							<pre class="source-code">
  	"path": "semantic_embedding",</pre>							<pre class="source-code">
  	"similarity": "cosine",</pre>							<pre class="source-code">
  	"type": "vector"</pre>							<pre class="source-code">
	}</pre>							<pre class="source-code">
  ]</pre>							<pre class="source-code">
}</pre>						</td>
						<td class="No-Table-Style">
							<pre class="source-code">
{</pre>							<pre class="source-code">
  "fields": [</pre>							<pre class="source-code">
	{</pre>							<pre class="source-code">
  	"numDimensions": 768,</pre>							<pre class="source-code">
  	"path": "content_embedding",</pre>							<pre class="source-code">
  	"similarity": "cosine",</pre>							<pre class="source-code">
  	"type": "vector"</pre>							<pre class="source-code">
	}</pre>							<pre class="source-code">
  ]</pre>							<pre class="source-code">
}</pre>						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.2: Vector search index definitions</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor143"/>Considering search use cases</h2>
			<p>Before finalizing the data model, let’s consider search use cases for articles, and adapt the model once more. Here are some broader search <span class="No-Break">use cases:</span></p>
			<ul>
				<li><strong class="bold">Find articles by matching lexically or semantically on title and summary, allowing filtering by brand and subscription type</strong>: This use case is called hybrid search and is covered in <a href="B22495_05.xhtml#_idTextAnchor115"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><em class="italic">, Vector Databases</em>. It combines semantic and lexical searches using reciprocal rank fusion. You can create a search index covering the <strong class="source-inline">title</strong> and <strong class="source-inline">summary</strong> fields for text search, and the <strong class="source-inline">brand</strong> and <strong class="source-inline">subscription_type</strong> fields <span class="No-Break">for filtering.</span></li>
				<li><strong class="bold">Same as the first one and extend to include tags</strong>: For this use case, you can use the same index and add the <strong class="source-inline">tags</strong> field. You will also need a vector search index to cover the <strong class="source-inline">title + </strong><span class="No-Break"><strong class="source-inline">summary</strong></span><span class="No-Break"> embedding.</span></li>
				<li><strong class="bold">Find other articles that use similar images, filtering by brand and subscription type</strong>: For this use case, vector search indexes on MongoDB Atlas support adding traditional fields for filtering. Since the image embeddings are stored in another collection, you will need to duplicate the article’s <strong class="source-inline">_id</strong>, <strong class="source-inline">brand</strong>, and <strong class="source-inline">subscription_type</strong> fields from the <strong class="source-inline">articles</strong> collection into the <strong class="source-inline">article_content_embeddings</strong> collection. Since there is already an <strong class="source-inline">_id</strong> field in this collection, you can create a composite primary key that includes the <strong class="source-inline">_id</strong> of the article and the <strong class="source-inline">_id</strong> of the content. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.3</em> shows the updated <span class="No-Break">data model.</span></li>
			</ul>
			<div>
				<div class="IMG---Figure" id="_idContainer057">
					<img alt="" role="presentation" src="image/B22495_06_03.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3: Updated schema for articles with embeddings</p>
			<p><em class="italic">Table 6.3</em> shows updated <span class="No-Break">vector indexes.</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table003">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Collection</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">articles</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Collection</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">article_content_embeddings</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Vector </strong><span class="No-Break"><strong class="bold">index</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">semantic_embedding_vix</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Vector </strong><span class="No-Break"><strong class="bold">index</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">content_embedding_vix</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
{</pre>							<pre class="source-code">
  "fields": [</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "numDimensions": 1024,</pre>							<pre class="source-code">
      "path": "semantic_embedding",</pre>							<pre class="source-code">
      "similarity": "cosine",</pre>							<pre class="source-code">
      "type": "vector"</pre>							<pre class="source-code">
    },</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "path": "brand",</pre>							<pre class="source-code">
      "type": "filter"</pre>							<pre class="source-code">
    },</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "path": "subscription_type",</pre>							<pre class="source-code">
      "type": "filter"</pre>							<pre class="source-code">
    }</pre>							<pre class="source-code">
  ]</pre>							<pre class="source-code">
}</pre>						</td>
						<td class="No-Table-Style">
							<pre class="source-code">
{</pre>							<pre class="source-code">
  "fields": [</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "numDimensions": 768,</pre>							<pre class="source-code">
      "path": "content_embedding",</pre>							<pre class="source-code">
      "similarity": "cosine",</pre>							<pre class="source-code">
      "type": "vector"</pre>							<pre class="source-code">
    },</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "path": "brand",</pre>							<pre class="source-code">
      "type": "filter"</pre>							<pre class="source-code">
    },</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "path": "subscription_type",</pre>							<pre class="source-code">
      "type": "filter"</pre>							<pre class="source-code">
    },</pre>							<pre class="source-code">
    {</pre>							<pre class="source-code">
      "path": "_id.article_id",</pre>							<pre class="source-code">
      "type": "filter"</pre>							<pre class="source-code">
    }</pre>							<pre class="source-code">
  ]</pre>							<pre class="source-code">
}</pre>						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.3: Updated vector search index definitions</p>
			<p><em class="italic">Table 6.4</em> shows the new text <span class="No-Break">search index.</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table004">
				<colgroup>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Collection</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">articles</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Search </strong><span class="No-Break"><strong class="bold">index</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">lexical_six</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
{</pre>							<pre class="source-code">
  "mappings": {</pre>							<pre class="source-code">
    "dynamic": false,</pre>							<pre class="source-code">
    "fields": {</pre>							<pre class="source-code">
      "brand": {</pre>							<pre class="source-code">
        "normalizer": "lowercase",</pre>							<pre class="source-code">
        "type": "token"</pre>							<pre class="source-code">
      },</pre>							<pre class="source-code">
      "subscription_type": {</pre>							<pre class="source-code">
        "normalizer": "lowercase",</pre>							<pre class="source-code">
        "type": "token"</pre>							<pre class="source-code">
      },</pre>							<pre class="source-code">
      "summary": {</pre>							<pre class="source-code">
        "type": "string"</pre>							<pre class="source-code">
      },</pre>							<pre class="source-code">
      "tags": {</pre>							<pre class="source-code">
        "normalizer": "lowercase",</pre>							<pre class="source-code">
        "type": "token"</pre>							<pre class="source-code">
      },</pre>							<pre class="source-code">
      "title": {</pre>							<pre class="source-code">
        "type": "string"</pre>							<pre class="source-code">
      }</pre>							<pre class="source-code">
    }</pre>							<pre class="source-code">
  }</pre>							<pre class="source-code">
}</pre>						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.4: Text search index definition</p>
			<p>You learned about writing vector search queries in <a href="B22495_04.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic">, Embedding Models</em>. To learn more about hybrid search queries, you can refer to the tutorial <span class="No-Break">at </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/"><span class="No-Break"><span class="P---URL">https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/</span></span></a><span class="No-Break">.</span></p>
			<p>Now that you understand your data model and the indexes required, you need to consider the number of articles MDN will bear (including the sizes of embeddings and indexes), peak daily times, and more to determine the overall storage and database <span class="No-Break">cluster requirements.</span></p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor144"/>Data storage</h1>
			<p>In this section, you will perform sizing, which is an educated estimate, for storage requirements. You will consider not just volume size and speed, but also several other aspects of the database cluster that are needed for harnessing the data of your application while following expected data <span class="No-Break">access patterns.</span></p>
			<p>MDN plans to publish 100 articles daily. Keeping the articles from the last 5 years, the number of articles would total 182,500. With 48 million subscribers and 24 million daily active users, peak access occurs for 30 minutes daily across three major time zones, as shown in <span class="No-Break"><em class="italic">Figure 6</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer058">
					<img alt="" role="presentation" src="image/B22495_06_04.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4: MDN subscriber time zones and peak times</p>
			<p>First, you will estimate the total data size. Each article has one 1,024-dimension embedding for semantic search and five 768-dimension embeddings for image search, totaling 40 KB uncompressed (dimensions use the double type). With the <strong class="source-inline">title</strong>, <strong class="source-inline">summary</strong>, <strong class="source-inline">body</strong> (with and without markup), and other fields, the average article size will be about 300 <span class="No-Break">KB uncompressed.</span></p>
			<p>Five years of articles will require about 100 GB uncompressed. With MongoDB’s <strong class="bold">WiredTiger </strong>compression (Snappy, zlib, and zstd are also available as compression options), this reduces to about 50 GB on disk. The defined vector indexes add about 3.6 GB. Images and binary assets will be stored in Amazon S3. For simplicity, you will not estimate the size of search and traditional indexes. You can safely say that MDN will need 80 to 100 GB on disk in MongoDB Atlas, which is very manageable by today’s cloud <span class="No-Break">computing standards.</span></p>
			<p>Now, you will determine the most suitable MongoDB Atlas <span class="No-Break">cluster configuration.</span></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor145"/>Determining the type of database cluster</h2>
			<p>MongoDB Atlas provides two main <span class="No-Break">cluster types:</span></p>
			<ul>
				<li><strong class="bold">Replica sets</strong> have a primary node for writes and secondary nodes for high availability, which can also be used for reads. These sets scale vertically and can also scale horizontally for reads by adding more nodes in the same or different <span class="No-Break">cloud regions.</span></li>
				<li><strong class="bold">Sharded clusters</strong> consist of multiple shards, each being a part of the overall dataset, and each being a replica set. They scale vertically and horizontally for both reads and writes. Shards can be placed in different cloud regions to enhance data locality <span class="No-Break">and compliance.</span></li>
			</ul>
			<p>So, how can you determine whether a replica set is sufficient or a sharded cluster is needed? Key factors include the size of the dataset or the throughput of applications that can challenge the capacity of a single server. For example, high query rates can exhaust the server’s CPU capacity and working set sizes larger than the system’s RAM can stress the I/O capacity of disk drives. MDN publishes 100 articles per day, so sharding is not necessary for <span class="No-Break">this reason.</span></p>
			<p>Other reasons for sharding include data governance and compliance and <strong class="bold">recovery point objective</strong> (<strong class="bold">RPO</strong>) and <strong class="bold">recovery time objective</strong> (<strong class="bold">RTO</strong>) policies, which are key metrics in disaster recovery and business continuity planning. None of these are applicable <span class="No-Break">to MDN.</span></p>
			<p>Considering the small number of writes per second and manageable data size, it makes sense to use a replica set. You will now need to determine the amount of RAM and IOPS needed; both are key components for fast <span class="No-Break">response times.</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor146"/>Determining IOPS</h2>
			<p>MDN is a low-write, high-read use case. With only 100 articles added per day, there is minimal pressure on the storage system for writes. <em class="italic">Table 6.5</em> shows the storage and IOPS options provided by <span class="No-Break">MongoDB Atlas.</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table005">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Storage types</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Lowest IOPS/storage</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Highest IOPS/storage</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Standard IOPS</span></p>
						</td>
						<td class="No-Table-Style">
							<p>3,000 <span class="No-Break">IOPS/10 GB</span></p>
						</td>
						<td class="No-Table-Style">
							<p>12,288 <span class="No-Break">IOP</span><span class="No-Break">S/4</span><span class="No-Break"> TB</span>
16,000 <span class="No-Break">IOPS/14 TB*</span></p>
							<p>*Extended <span class="No-Break">storage enabled</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Provisioned IOPS</span></p>
						</td>
						<td class="No-Table-Style">
							<p>100 <span class="No-Break">IOPS/10 GB</span></p>
						</td>
						<td class="No-Table-Style">
							<p>64,000 <span class="No-Break">IOPS/4 TB</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">NVMe</span></p>
						</td>
						<td class="No-Table-Style">
							<p>100,125 100% random <span class="No-Break">read IOPS</span></p>
							<p>35,000 write IOPS <span class="No-Break">380 GB</span></p>
						</td>
						<td class="No-Table-Style">
							<p>3,300,000 100% random <span class="No-Break">read IOPS</span></p>
							<p>1,400,000 write IOPS <span class="No-Break">4,000 GB</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.5: MongoDB Atlas storage types on AWS</p>
			<p>As shown in <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.4</em>, there will be a 30-minutes peak period, during which 24 million users are expected to be active daily. So, you need to provision 6,000 IOPS, as shown in <em class="italic">Table 6.6</em>. This is based on subscriber distribution, memory versus disk reads, and each article requiring 3 IOPS for disk reads (150 KB compressed ÷ 64 KB I/O size of <span class="No-Break">Amazon EBS).</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table006">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Region</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Allocation</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">DAU</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">20% reads </strong><span class="No-Break"><strong class="bold">from disk</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Disk reads/sec during </strong><span class="No-Break"><strong class="bold">peak time</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">IOPS required</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">AMER</strong></span><span class="No-Break">^</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">40%</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">9,600,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,920,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,067</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3,200^</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">EMEA</strong></span><span class="No-Break">^</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">20%</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">4,800,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">960,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">533</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,600^</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">APAC</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">25%</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">6,000,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,200,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">667</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">2,000</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">LATAM</strong></span><span class="No-Break">^</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">15%</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">3,600,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">720,000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">400</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,200^</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>^ Zones overlapping at <span class="No-Break">peak time</span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break">Peak IOPS</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">6,000</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.6: MDN global subscriber distribution</p>
			<p>The minimum standard IOPS on any Atlas cluster on AWS is 3,000. To achieve 6,000 IOPS you would need to use an Atlas <strong class="source-inline">M50</strong> tier with 2TB disk, which feels over-provisioned and would not provide low latency to all readers if deployed in a single cloud region. To address this, MDN will deploy the application stack in major geographies, enabling regional provisioning, workload distribution, and local reads for an optimal <span class="No-Break">customer experience.</span></p>
			<p>With MongoDB Atlas, you can place vector search nodes across regions. The <strong class="source-inline">S40</strong> tier offers 26,875 read IOPS, which is sufficient for this example, and a 2-node minimum per region, which ensures <span class="No-Break">high availability.</span></p>
			<p>While Vector Search nodes will handle lexical, semantic, and image search, the full JSON document must be fetched from a MongoDB data node after matching. To fully support local reads, we must provision read-only nodes in the same regions and meet IOPS requirements. We can do this with the Atlas <strong class="source-inline">M40</strong> tier. Having determined the IOPS needed, you now need to <span class="No-Break">estimate RAM.</span></p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor147"/>Determining RAM</h2>
			<p>For data nodes, the Atlas <strong class="source-inline">M40</strong> tier provides 16 GB of RAM. The MongoDB WiredTiger storage engine reserves 50% of (RAM - 1 GB) for its cache. With documents averaging 300 KB in size, the cache can hold approximately 28,000 documents. Keep in mind that traditional index sizes might slightly reduce this number. Given the addition of 100 new articles daily, the cache on an <strong class="source-inline">M40</strong> tier can accommodate data for about 280 days, or roughly 9 months, which is more than sufficient for <span class="No-Break">this example.</span></p>
			<p>The Search <strong class="source-inline">S40</strong> tier offers 16 GB of RAM, 2 vCPUs, and 100 GB of storage. The HNSW graph, or the vector index, must fit in <span class="No-Break">the memory.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">You learned about <strong class="bold">HNSW</strong> or <strong class="bold">hierarchical navigable small worlds</strong> in <a href="B22495_05.xhtml#_idTextAnchor115"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <span class="No-Break"><em class="italic">Vector Databases</em></span><span class="No-Break">.</span></p>
			<p>One article uses 1 x 1,024 vector + 5 x 768 vectors = 19.5 KB. With 3.5 GB needed for 182,500 articles, 16 GB of RAM is more than sufficient for vector search and leaves room for the lexical search index. The <strong class="source-inline">S30</strong> tier, which offers 4 GB of RAM, 1 vCPU, and 50 GB storage, is less costly, but note that more CPUs allows more <span class="No-Break">concurrent searches.</span></p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor148"/>Final cluster configuration</h2>
			<p>You have now determined the cluster configuration for MDN. <em class="italic">Table 6.7</em> describes the MDN global cloud architecture, detailing the distribution of Atlas nodes across different regions. The <strong class="source-inline">AMER</strong> region, identified as the primary region, uses <strong class="source-inline">M40</strong> tier nodes and <strong class="source-inline">S30</strong> vector search nodes to serve writes and searches for the Americas, while the <strong class="source-inline">EMEA</strong>, <strong class="source-inline">APAC</strong>, and <strong class="source-inline">LATAM</strong> regions use <strong class="source-inline">M40</strong> read-only nodes and <strong class="source-inline">S30</strong> vector search nodes to serve local searches only for their respective region. Each region will need a deployment of the MDN application stack, as pictured in the global map in <span class="No-Break"><em class="italic">Table 6.7</em></span><span class="No-Break">.</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table007">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Region</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Atlas base </strong><span class="No-Break"><strong class="bold">tier nodes</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Atlas </strong><span class="No-Break"><strong class="bold">read-only nodes</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Atlas Vector </strong><span class="No-Break"><strong class="bold">Search nodes</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">AMER</strong></span></p>
							<p>(<span class="No-Break">primary region)</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">M40</strong></span></p>
							<p>(<span class="No-Break">three included)</span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">S30</strong></span><span class="No-Break"> x2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">EMEA</strong></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">M40</strong></span><span class="No-Break"> x2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">S30</strong></span><span class="No-Break"> x2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">APAC</strong></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">M40</strong></span><span class="No-Break"> x2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">S30</strong></span><span class="No-Break"> x2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">LATAM</strong></span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">M40</strong></span><span class="No-Break"> x2</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">S30</strong></span><span class="No-Break"> x2</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style" colspan="4">
							<p><strong class="bold">MDN global </strong><span class="No-Break"><strong class="bold">cloud architecture</strong></span></p>
							<div>
								<div class="IMG---Figure" id="_idContainer059">
									<img alt="" role="presentation" src="image/B22495_Table_6.7.jpg"/>
								</div>
							</div>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.7: MongoDB Atlas cluster configuration for MDN</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor149"/>Performance and availability versus cost</h2>
			<p>Notice that additional read-only nodes were not provisioned in the <strong class="source-inline">AMER</strong> region, using the two secondary nodes as read-only instead. This saves costs due to MDN’s low write profile, despite potential resource competition. Provisioning only one <strong class="source-inline">M40</strong> read-only node in other regions saves more costs but increases latency during maintenance windows, as reads will <span class="No-Break">be rerouted.</span></p>
			<p>To protect against a complete <strong class="source-inline">AMER</strong> outage while adhering to best practices, consider provisioning five nodes across three regions and deploying the application stack in the two regions with two electable <span class="No-Break">nodes each.</span></p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor150"/>Data flow</h1>
			<p><strong class="bold">Data flow</strong> involves the movement of data through a system, affecting the accuracy, relevance, and speed of the results delivered to consumers, which, in turn, influences their engagement. This section explores design considerations for handling data sources, processing data, prompting LLMs, and embedding models to enrich data using MDN as an example. <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.5</em> illustrates <span class="No-Break">this flow.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer060">
					<img alt="" role="presentation" src="image/B22495_06_06.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5: Typical data flow in an AI/ML application</p>
			<p>Let's us begin with the design for handling data sources. Data can be ingested into MongoDB Atlas either statically (at rest) from files as it is, or dynamically (in motion), allowing for continuous updates, data transformation, and <span class="No-Break">logic execution.</span></p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor151"/>Handling static data sources</h2>
			<p>The simplest way to import static data is to use <strong class="source-inline">mongoimport</strong>, which supports JSON, CSV, and TSV formats. It is ideal for initial loads or bulk updates as it can handle large datasets. Moreover, increasing the number of insertion workers to match the host’s vCPUs can boost <span class="No-Break">import speed.</span></p>
			<p><strong class="source-inline">mongoimport</strong> can also be used dynamically to update externally sourced data. You can build invocation commands at runtime and execute them as out-of-process tasks. Some video game companies use this method to update player profiles with purchase data from mobile <span class="No-Break">app stores.</span></p>
			<p>Using MDN as an example, users can provide their GitHub ID when subscribing. With GitHub’s API, you can create a list of the programming languages used in the repositories that users own or have contributed to. A scheduled job can fetch this data periodically. The list of languages can then imported and merged into their profiles to recommend articles later. <em class="italic">Table 6.8</em> demonstrates how you can <span class="No-Break">do this.</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table008">
				<colgroup>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">File</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">github-20240719.json</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
{ "github_id" : "user1", "languages" : ["python", "csharp"], …}</pre>							<pre class="source-code">
{ "github_id" : "user2", "languages" : ["python", "cpp"], …}…</pre>						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Collection</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">mdn.subscribers</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
{ "_id" : ObjectId("669…ab8"), "github_id" : "user1", … }</pre>							<pre class="source-code">
{ "_id" : ObjectId("669…ab9"), "github_id" : "user2", … }…</pre>						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>The <strong class="source-inline">mongoimport</strong> invocation to merge data matching on the <span class="No-Break"><strong class="source-inline">github_id</strong></span><span class="No-Break"> field</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
mongoimport --uri=&lt;connection string to Atlas cluster&gt;</pre>							<pre class="source-code">
--db=mdn --collection=subscribers --mode=merge</pre>							<pre class="source-code">
--file=github-20240719.json --upsertFields=github_id</pre>							<pre class="source-code">
--numInsertionWorkers=4</pre>						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Collection</strong>: <strong class="source-inline">mdn.subscribers</strong> <span class="No-Break">after merge</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<pre class="source-code">
{ "_id" : ObjectId("669…ab8"), "github_id" : "user1", "languages" : ["python", "csharp"], … }</pre>							<pre class="source-code">
{ "_id" : ObjectId("669…ab9"), "github_id" : "user2", "languages" : ["python", "cpp"], … }…</pre>						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.8: Example of using mongoimport to merge data</p>
			<p>While <strong class="source-inline">mongoimport</strong> is a versatile tool for various data import needs, it does not support continuous synchronization, logic execution, or data transformations. You will now explore some methods that do support <span class="No-Break">these functions.</span></p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor152"/>Storing operational data enriched with vector embeddings</h2>
			<p>When original representations are stored or updated, their corresponding vector embeddings must be refreshed to accurately reflect the content. This can be done in the <span class="No-Break">following ways:</span></p>
			<ul>
				<li><strong class="bold">Synchronously</strong>: Obtains the updated vector embedding before the database operation, writing both data and embedding together. This method is suitable for fast, simple embedding models or when the model is locally hosted. However, it may fail if the response times of the embedding <span class="No-Break">model vary.</span></li>
				<li><strong class="bold">Asynchronously</strong>: Ensures immediate consistency of primary data and allows for prompting the embedding model afterward. While this offers scalability and handles unpredictable models, it introduces latency during which embeddings are <span class="No-Break">temporarily outdated.</span></li>
			</ul>
			<p>You can keep embeddings up to date asynchronously in MongoDB using the following <span class="No-Break">four methods:</span></p>
			<ul>
				<li><strong class="bold">Kafka connector</strong>: You can facilitate data flow from Apache Kafka into MongoDB collections through the Kafka connector. It is a Confluent-verified connector and allows data to flow from Apache Kafka topics into MongoDB as a <strong class="bold">data sink</strong> and publishes changes from MongoDB to Kafka topics as a <strong class="bold">data source</strong>. To keep embeddings up to date, you would use the sink connector and develop a post-processor in Java. You can learn more about sink post-processors <span class="No-Break">here: </span><a href="https://www.mongodb.com/docs/kafka-connector/v1.3/sink-connector/fundamentals/post-processors/#sink-connector-post-processors"><span class="No-Break"><span class="P---URL">https://www.mongodb.com/docs/kafka-connector/v1.3/sink-connector/fundamentals/post-processors/#sink-connector-post-processors</span></span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">Atlas Stream Processing</strong>: This method handles complex data streams with the same query API as MongoDB Atlas databases. It enables continuous aggregation and includes schema validation for message integrity and timely issue detection. Processed data can be written to Atlas collections, and they are integrated into Atlas projects and independent of Atlas clusters. Atlas Stream Processing logic is programmed in JavaScript using MongoDB aggregation syntax. For an example of using Atlas Stream Processing to handle embedding data, <span class="No-Break">see </span><a href="https://www.mongodb.com/solutions/solutions-library/rag-applications"><span class="No-Break"><span class="P---URL">https://www.mongodb.com/solutions/solutions-library/rag-applications</span></span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">Atlas Triggers</strong>: Atlas Triggers execute application and database logic by responding to events or following predefined schedules. Each Trigger listens for specific event types and is linked to an Atlas Function. When a matching event occurs, the Trigger fires and passes the event object to the linked Function. Triggers can respond to various events, such as specific operations in a collection, authentication events such as user creation or deletion, and scheduled times. They are fully managed instances of change streams but limited to JavaScript. For an example of using Atlas Triggers to keep embeddings up to date, <span class="No-Break">see </span><a href="https://www.mongodb.com/developer/products/atlas/semantic-search-mongodb-atlas-vector-search/"><span class="No-Break"><span class="P---URL">https://www.mongodb.com/developer/products/atlas/semantic-search-mongodb-atlas-vector-search/</span></span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">Change streams</strong>: This method provides real-time access to data changes. Applications can subscribe to changes in a collection, database, or entire deployment and react immediately, with events processed in order and being resumable? Using the aggregation framework, change streams allow filtering and transforming notifications. They can be used with any programming language supported by an official MongoDB driver. However, they are not fully managed, requiring a running host to be maintained alongside the <span class="No-Break">main application.</span></li>
			</ul>
			<p>Given that this book is written for Python developers, you will learn how to use a change stream written in Python. <em class="italic">Table 6.9</em> shows a Python 3 change stream using LangChain and OpenAI to embed the title and summary of an MDN article. It is triggered for new articles or changes to the title or summary following the data model from <span class="No-Break"><em class="italic">Figure 6</em></span><em class="italic">.3</em> and the vector index from <span class="No-Break"><em class="italic">Table 6.3</em></span><span class="No-Break">.</span></p>
			<pre class="source-code">
import os
from langchain_openai import OpenAIEmbeddings
from pymongo import MongoClient
from pymongo.errors import PyMongoError
# Set the OpenAI API key as an environment variable
os.environ["OPENAI_API_KEY"] = "YOUR-OPENAI-API-KEY"
# Define the MongoDB Atlas connection string
ATLAS_CONNECTION_STRING = "YOUR-MONGODB_ATLAS-CONNSTRING"
# Create a MongoClient instance to connect to MongoDB Atlas
client = MongoClient(
    ATLAS_CONNECTION_STRING, tls=True, tlsAllowInvalidCertificates=True
)
# Select the 'articles' collection from the 'mdn' database
coll = client["mdn"]["articles"]
# Instantiate the OpenAIEmbeddings model with specified parameters
embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-large", dimensions=1024, disallowed_special=()
)
# Define a function to handle changes detected in the MongoDB collection
def handle_changes(change):
    # Extract the document ID from the change event
    doc_id = change["documentKey"]["_id"]
    # Create a filter to identify the document in the collection
    doc_filter = {
        "_id": doc_id
    }
    # Combine the title and summary of the document into a single text string
    text = [change["fullDocument"]["title"] + " " + change["fullDocument"]["summary"]]
    # Generate embeddings for the text
    embeddings = embedding_model.embed_documents(text)
    # Create an update document to set the 'semantic_embedding' field with the generated embeddings
    set_fields = {
        "$set": {
            "semantic_embedding": embeddings[0]
        }
    }
    # Update the document in the collection with the new embeddings
    coll.update_one(doc_filter, set_fields)
    print(f"Updated embeddings for document {doc_id}")
# Start monitoring the MongoDB collection for changes
try:
    # Define a stream filter to match insert and update operations affecting the title or summary fields
    stream_filter = [
        {
            "$match": {
                "$or": [
                    {"operationType": "insert"},
                    {
                        "$and": [
                            {"operationType": "update"},
                            {
                                "$or": [
                                    {
                                        "updateDescription.updatedFields.title": {
                                            "$exists": True
                                        }
                                    },
                                    {
                                        "updateDescription.updatedFields.summary": {
                                            "$exists": True
                                        }
                                    },
                                ]
                            },
                        ]
                    },
                ]
            }
        }
    ]
    # Open a change stream to watch for changes in the collection
    with coll.watch(stream_filter, full_document="updateLookup") as stream:
        print("Listening for changes...")
        for change in stream:
            print(f"Change detected: {change}. Processing")
            handle_changes(change)
except PyMongoError as e:
    # Print an error message if a PyMongoError occurs
    print(f"An error occurred: {e}")
finally:
    # Close the MongoDB client connection
    client.close()</pre>			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.9: Change stream written in Python to set or update embeddings</p>
			<p>Now that you have learned how to handle the data flow for setting or updating embeddings, you will learn about data freshness and retention, which are essential for delivering relevant and <span class="No-Break">timely content.</span></p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor153"/>Freshness and retention</h1>
			<p>Fresh data and effective retention strategies ensure that your content is relevant and delivered on time. <strong class="bold">Freshness</strong> keeps users engaged with the latest articles, comments, and recommendations. <strong class="bold">Retention strategies</strong> manage the data lifecycle, preserving valuable historical data for analytics while purging obsolete data. This section explores methods for ensuring up-to-date content and efficient <span class="No-Break">data flow.</span></p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor154"/>Real-time updates</h2>
			<p>The primary concern is to ingest and update new data in real time, making it available across all cloud regions. For the news site, this means new articles and their vector embeddings should be promptly persisted and replicated for <span class="No-Break">global access.</span></p>
			<p>To achieve this with a distributed data model and application, use an ACID transaction to ensure that the article and its content embeddings are written together as a single unit. For an example of creating MongoDB transactions in Python, <span class="No-Break">see </span><a href="https://learn.mongodb.com/learn/course/mongodb-crud-operations-in-python/lesson-6-creating-mongodb-transactions-in-python-applications/learn?page=2"><span class="No-Break"><span class="P---URL">https://learn.mongodb.com/learn/course/mongodb-crud-operations-in-python/lesson-6-creating-mongodb-transactions-in-python-applications/learn?page=2</span></span></a><span class="No-Break">.</span></p>
			<p>Next, balance data reliability, consistency, and performance in a distributed setup using MongoDB’s tunable consistency with <strong class="source-inline">writeConcern</strong>, <strong class="source-inline">readConcern</strong>, and <strong class="source-inline">readPreference</strong>. These modifiers help to ensure data integrity and quick access. The following is an explanation of these modifiers, but for a deeper understanding, you can <span class="No-Break">visit </span><a href="https://www.mongodb.com/docs/manual/core/causal-consistency-read-write-concerns/"><span class="No-Break"><span class="P---URL">https://www.mongodb.com/docs/manual/core/causal-consistency-read-write-concerns/</span></span></a><span class="No-Break">:</span></p>
			<ul>
				<li><strong class="source-inline">writeConcern:majority</strong> ensures data consistency and durability by acknowledging write operations only after data is written to the majority of replica set members, reducing the risk of data loss during failures. It is the default <span class="No-Break">write concern.</span></li>
				<li><strong class="source-inline">readConcern:majority</strong> provides read consistency by ensuring that read operations return the most recent data acknowledged by the majority of the replica set members, providing a consistent view of the data across <span class="No-Break">the application.</span></li>
				<li><strong class="source-inline">readPreference:nearest</strong> optimizes latency by directing read operations to the replica set member with the lowest network latency. For MDN, this minimizes response times by allowing each regional application deployment to read from the nearest MongoDB data and vector nodes, and balancing consistency <span class="No-Break">and performance.</span></li>
			</ul>
			<p>Now that you have learned how to ensure data availability and speed, the next focus is on data lifecycle management, a key aspect of data freshness <span class="No-Break">and retention.</span></p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor155"/>Data lifecycle</h2>
			<p><strong class="bold">Data lifecycle</strong> refers to the various stages data goes through from creation to deletion, and how it may traverse and change systems or storage formats, including when data is archived or deleted. As latest content is added, older content may become <span class="No-Break">less relevant.</span></p>
			<p>For example, older articles can be moved to an archive database or cold storage, reducing storage costs and optimizing active database performance. However, moving data to cold storage may reduce search capabilities compared to the operational database. Here are three approaches for handling the data lifecycle, along with <span class="No-Break">their trade-offs:</span></p>
			<ul>
				<li><strong class="bold">All data in the operational cluster</strong>: Keeping all data in the operational cluster is the most performant but costly approach, suitable for scenarios where most data is frequently accessed, such as global online games, authentication providers, or financial platforms. MongoDB Atlas supports this with sharded clusters and global clusters. Global clusters allocate <em class="italic">data zones</em> to cloud regions for capacity management and <span class="No-Break">data locality.</span></li>
				<li><strong class="bold">Active and historic operational data clusters</strong>: This involves using high-performance hardware for recent data and less capable hardware for older data, balancing functionality, and cost savings. With MongoDB Atlas, data can be moved from active to historic cluster(s) using Cluster-to-Cluster Sync and TTL indexes. Other platforms such as Apache Kafka, Confluent, and Striim also support <span class="No-Break">this method.</span></li>
				<li><strong class="bold">Active data cluster and historical storage</strong>: Full historical data can be offloaded to cold storage while retaining key fields in the operational cluster, allowing for full or limited query and search capabilities. For MDN, this ensures that users can find historical articles through lexical semantic searches, with full articles stored in cold storage and accessed when needed. With MongoDB Atlas, this can be achieved using Online Archive and Data Federation. <strong class="bold">Online Archive</strong> automatically moves data from the cluster to lower-cost cloud storage based on the set expiration. <strong class="bold">Data Federation</strong> allows transparent querying of both clusters and the archive, regardless of <span class="No-Break">the source.</span></li>
			</ul>
			<p>This section covered data lifecycle management, emphasizing how data is managed from creation to archival. You learned about three strategies: maintaining all data in the operational cluster for maximum performance, separating active and historical data to balance cost and performance, and offloading historical data to cold storage while retaining some search functionality. Now, you will learn about upgrading <span class="No-Break">embedding models.</span></p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor156"/>Adopting new embedding models</h2>
			<p>OpenAI superseded the <strong class="source-inline">text-search-davinci-*-001</strong> model with <strong class="source-inline">text-embedding-ada-002</strong> on December 15, 2022, and subsequently with <strong class="source-inline">text-embedding-small/large</strong> on January 25, 2024. It is likely that by the time you read this book, these models will be <span class="No-Break">replaced too.</span></p>
			<p>As you learned in the <a href="B22495_04.xhtml#_idTextAnchor061"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Embedding Models</em>, embeddings from one model are not compatible with another. Re-embedding previously indexed data may be necessary as newer models are adopted. This is a resource-intensive activity that requires design <span class="No-Break">considerations upfront.</span></p>
			<p>You will need to choose an approach toward adopting new embedding models. You can either continue using the existing vector fields and perform lengthy all-or-nothing upgrades, double-embed for a period, or implement a gradual upgrade. Let's explore these <span class="No-Break">three approaches:</span></p>
			<ul>
				<li><strong class="bold">Use existing vector fields</strong>: This approach keeps the application code intact but requires downtime to re-embed data and replace vector indexes. This approach is suitable if the re-embedding and re-indexing time fits within your allowable <span class="No-Break">downtime windows.</span></li>
				<li><strong class="bold">Double-embed temporarily</strong>: This approach double embeds fields for new or modified data using the old and new model. It uses a background job to add new embeddings for data that is not modified. When all data has double embeddings, the application will be updated and deployed to use the new embeddings. Once stable, the deprecated vectors and indexes can be removed with another background job. Ensure sufficient disk space and memory for when two sets of vectors coexist. This approach is suitable if the downtime windows are small and only accommodate application <span class="No-Break">deployment times.</span></li>
				<li><strong class="bold">Gradual upgrade</strong>: This approach is architecturally complex. Vector creation and search can be moved to a microservice. By leveraging MongoDB’s flexible data model, the service adds new vectors and retires old ones when documents change (such as a non-blocking lazy schema change). A background job handles untouched documents. For searches, results from searching using both vectors are combined (such as the reciprocal rank fusion approach). Using the <strong class="source-inline">filter</strong> type of MongoDB’s vector indexes (shown in <em class="italic">Table 6.3</em>), you can introduce a new field to distinguish between documents with old and new vectors and implement the union. Eventually, old vectors and indexes can be dropped, and you can remove unneeded logic. This approach is suitable if no downtime <span class="No-Break">is allowed.</span></li>
			</ul>
			<p>By addressing these three main concerns—data ingestion and real-time updates, managing the data lifecycle and aging, and upgrading embedding models—your application can ensure that its data remains fresh and relevant, providing an optimal platform and striving for the best user experience. Now, you will learn about security and its considerations for <span class="No-Break">AI-intensive applications.</span></p>
			<h1 id="_idParaDest-118"><a id="_idTextAnchor157"/>Security and RBAC</h1>
			<p><strong class="bold">Security measures</strong> protect data from unauthorized access and breaches, while RBAC ensures appropriate access levels based on roles. Here are key security and RBAC strategies to protect data integrity <span class="No-Break">and privacy:</span></p>
			<ul>
				<li><strong class="bold">Data encryption and secure storage</strong>: Encrypting data at rest and in transit is crucial for securing an application. Encryption at rest protects data from unauthorized access, while encryption in transit secures data as it moves between users and the application. MongoDB Atlas offers built-in integration with <strong class="bold">AWS Key Management Service</strong> (<strong class="bold">AWS KMS</strong>) for encryption at rest and TLS/SSL out of the box for data <span class="No-Break">in transit.</span></li>
				<li><strong class="bold">Access controls and user authentication</strong>: RBAC manages permissions, ensuring that users access only necessary data and functionalities. In the case of MDN, separate roles, such as editors and readers, require various levels of access. Different database users on MongoDB can be set up with distinct levels of permissions following the principle of least privilege. For example, only the application identity used by the microservice that embeds data would have write permissions to the collections where embeddings are stored, while the application identity used by human actors would only have <span class="No-Break">read permissions.</span></li>
				<li><strong class="bold">Monitoring and auditing</strong>: Continuous monitoring and auditing detect and respond to security incidents in real time. Monitoring tools and audit logs track user activities and identify unusual access patterns. MongoDB Atlas offers advanced monitoring and alerting capabilities, allowing administrators to set up alerts for suspicious activities. Regularly reviewing audit logs ensures compliance with security policies and provides insights for <span class="No-Break">improving security.</span></li>
				<li><strong class="bold">Data backup and recovery</strong>: Maintain data integrity and availability with regular backups to minimize downtime and loss during security breaches or incidents. MongoDB Atlas offers automated backup solutions with snapshots, ensuring quick recovery. If encryption at rest is enabled (for example, AWS KMS), embeddings and operational data are encrypted under the same key in both volumes <span class="No-Break">and backups.</span></li>
			</ul>
			<p>While there are many security-related concerns, the ones just covered should suffice to start building AI applications. Ensuring security is a continuous effort that organizations must adopt and enforce to maintain compliance, foster user trust, and safeguard <span class="No-Break">application integrity.</span></p>
			<h1 id="_idParaDest-119"><a id="_idTextAnchor158"/>Best practices for AI/ML application design</h1>
			<p>This section covers best practices for the five concerns covered in this chapter—data modeling, data storage, data flow, data freshness and retention, and security and RBAC. These guidelines will help ensure that your application is efficient, scalable, and secure, providing a solid foundation for building reliable and high-performing AI apps. Here are the top two best practices for each aspect of your AI/ML <span class="No-Break">application design.</span></p>
			<ol>
				<li><strong class="bold">Data modeling</strong>: The following techniques ensure efficiency and performance for <span class="No-Break">handling embeddings:</span><ul><li><strong class="bold">Embeddings in separate collections</strong>: Store embeddings in a separate collection to avoid bloated documents, especially when multiple embeddings and nested indexing limitations are involved. Duplicate fields to ensure efficient filtering and maintain <span class="No-Break">performant searches.</span></li><li><strong class="bold">Hybrid search</strong>: Combine semantic and lexical searches using reciprocal rank fusion. This hybrid approach boosts search functionality by leveraging the strengths <span class="No-Break">of both.</span></li></ul></li>
				<li><strong class="bold">Data storage</strong>: To optimize database cluster sizing, implement the following <span class="No-Break">best practices:</span><ul><li><strong class="bold">Sufficient IOPS and RAM based on peak usage</strong>: Calculate required IOPS based on peak access times and application read/write patterns. Ensure data and search nodes have enough RAM to handle the caching and indexing needs of the most <span class="No-Break">requested data.</span></li><li><strong class="bold">Local reads</strong>: Deploying nodes across regions helps minimize read latency and enhances the user experience. Ensure that each region has all the nodes required to fully serve <span class="No-Break">data locally.</span></li></ul></li>
				<li><strong class="bold">Data flow</strong>: Consider the following strategies for harnessing data <span class="No-Break">flow effectively:</span><ul><li><strong class="bold">Asynchronous embedding updates</strong>: Ensure primary data consistency by updating vector embeddings asynchronously. This method accommodates scalability and unpredictable model response times, although it introduces <span class="No-Break">temporary latency.</span></li><li><strong class="bold">Dynamic data handling</strong>: Leverage technologies such as change streams, Atlas Triggers, Kafka, and Atlas Stream Processing to handle continuous updates, transformations, and <span class="No-Break">logic execution.</span></li></ul></li>
				<li><strong class="bold">Data freshness and retention</strong>: The following best practices can ensure that your application is relevant <span class="No-Break">and prompt:</span><ul><li><strong class="bold">Up-to-date embedding models</strong>: Embeddings from one model are not compatible with another. Plan for model upgrades during downtime if possible, or consider gradual upgrades, which are architecturally complex but require no downtime. Leverage MongoDB’s flexible data model to transition <span class="No-Break">between embeddings.</span></li><li><strong class="bold">Data tiering</strong>: Implement a data aging strategy by moving older data to an archive cluster or cold storage while keeping recent data in high-performance clusters. Use broader MongoDB Atlas features such as Online Archive, Data Federation, and more for effective <span class="No-Break">data tiering.</span></li></ul></li>
				<li><strong class="bold">Security and RBAC</strong>: Following are the best practices for ensuring the security of <span class="No-Break">your data:</span><ul><li><strong class="bold">RBAC</strong>: Assign role-based permissions and follow the <strong class="bold">principle of least privilege</strong> (<strong class="bold">PoLP</strong>), ensuring that users and entities access only necessary data and actions. For instance, code embedding data should have write access only to <span class="No-Break">embedding collections.</span></li><li><strong class="bold">Encryption and storage</strong>: Turn on encryption at rest and integrate with KMS to ensure that all data volumes and backups are encrypted with your <span class="No-Break">own key.</span></li></ul></li>
			</ol>
			<p>Implementing these best practices boosts the efficiency, scalability, and security of your AI/ML applications. Though just a starting point, these guidelines lay a solid foundation for building reliable, high-performing systems. With these best practices, you can navigate the complexities of modern AI and prepare your applications for long-term success and adaptability in a rapidly evolving <span class="No-Break">tech landscape.</span></p>
			<h1 id="_idParaDest-120"><a id="_idTextAnchor159"/>Summary</h1>
			<p>This chapter covered critical architectural considerations for developing intelligent applications. You learned about data modeling and how to evolve your model to fulfill use cases, address technical limitations, and consider patterns and anti-patterns. This approach ensures that data is not only useful but also accessible and optimally utilized across various components of your <span class="No-Break">AI/ML system.</span></p>
			<p>Data storage was another key aspect of this chapter, focusing on the selection of appropriate storage technologies based on different data types and the specific needs of the application. It highlighted the importance of accurately estimating storage requirements and other aspects of choosing the right MongoDB Atlas cluster configuration. The fictitious example of the MDN application served as a practical case study, illustrating how to apply these principles in a <span class="No-Break">real-world scenario.</span></p>
			<p>The chapter also explored the flow of data through ingestion, processing, and output to ensure data integrity and maintain the velocity of data operations. This chapter also addressed data lifecycle management, including the importance of data freshness and retention. You learned strategies for managing updates and changing embedding models used by <span class="No-Break">your application.</span></p>
			<p>Security is a paramount concern in AI/ML applications, and you learned brief but important points about protecting the integrity of data and application logic. Concluding with a compilation of best practices, this chapter summarized key principles from data modeling, storage, flow, and security, offering practical advice to avoid common pitfalls and enhance the development of robust <span class="No-Break">AI/ML applications.</span></p>
			<p>In the next chapter, you will explore different AI/ML frameworks, Python libraries, and publicly available APIs and <span class="No-Break">other tools.</span></p>
		</div>
	

		<div>
			<div id="_idContainer062">
			</div>
		</div>
		<div id="_idContainer063">
			<h1 id="_idParaDest-121"><a id="_idTextAnchor160"/>Part 2</h1>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor161"/>Building Your Python Application: Frameworks, Libraries, APIs, and Vector Search</h1>
			<p>This following set of chapters will equip you with the necessary tools for AI development through detailed instructions and examples on enhancing developer and user experience with Python and <span class="No-Break">retrieval-augmented generation.</span></p>
			<p>This part of the book includes the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B22495_07.xhtml#_idTextAnchor162"><em class="italic">Chapter 7</em></a>, <em class="italic">Useful Frameworks, Libraries, and APIs</em></li>
				<li><a href="B22495_08.xhtml#_idTextAnchor180"><em class="italic">Chapter 8</em></a>, <em class="italic">Implementing Vector Search in AI Applications</em></li>
			</ul>
		</div>
	</body></html>