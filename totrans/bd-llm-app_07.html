<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer135">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">7</span></h1>
<h1 class="chapterTitle" id="_idParaDest-96"><span class="koboSpan" id="kobo.2.1">Search and Recommendation Engines with LLMs</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">In the previous chapter, we covered the core steps involved in building conversational applications. </span><span class="koboSpan" id="kobo.3.2">We started with a plain vanilla chatbot, then added more complex components, such as memory, non-parametric knowledge, and external tools. </span><span class="koboSpan" id="kobo.3.3">All of this was made straightforward with the pre-built components of LangChain, as well as Streamlit for UI rendering. </span><span class="koboSpan" id="kobo.3.4">Even though conversational applications are often seen as the “comfort zone” of generative AI and LLMs, those models do embrace a wider spectrum of applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.4.1">In this chapter, we are going to cover how LLMs can enhance recommendation systems, using both embeddings and generative models. </span><span class="koboSpan" id="kobo.4.2">We will learn how to create our own recommendation system application leveraging state-of-the-art LLMs using LangChain as the framework.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.5.1">Throughout this chapter, we will cover the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.6.1">Definition and evolutions of recommendation systems</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.7.1">How LLMs are impacting this field of research</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.8.1">Building recommendation systems with LangChain</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-97"><span class="koboSpan" id="kobo.9.1">Technical requirements</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.10.1">To complete the tasks in this book, you will need the following:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.11.1">Hugging Face account and a user access token.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.12.1">OpenAI account and a user access token.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.13.1">Python version 3.7.1 or later.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.14.1">Make sure to have the following Python packages installed: </span><code class="inlineCode"><span class="koboSpan" id="kobo.15.1">langchain</span></code><span class="koboSpan" id="kobo.16.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.17.1">python-dotenv</span></code><span class="koboSpan" id="kobo.18.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.19.1"> huggingface_hub</span></code><span class="koboSpan" id="kobo.20.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.21.1">streamlit</span></code><span class="koboSpan" id="kobo.22.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.23.1">lancedb</span></code><span class="koboSpan" id="kobo.24.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.25.1">openai</span></code><span class="koboSpan" id="kobo.26.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.27.1">tiktoken</span></code><span class="koboSpan" id="kobo.28.1">. </span><span class="koboSpan" id="kobo.28.2">These can be easily installed via </span><code class="inlineCode"><span class="koboSpan" id="kobo.29.1">pip install</span></code><span class="koboSpan" id="kobo.30.1"> in your terminal.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.31.1">You’ll find the code for this chapter in the book’s GitHub repository at </span><a href="Chapter_07.xhtml"><span class="url"><span class="koboSpan" id="kobo.32.1">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</span></span></a><span class="koboSpan" id="kobo.33.1">.</span></p>
<h1 class="heading-1" id="_idParaDest-98"><span class="koboSpan" id="kobo.34.1">Introduction to recommendation systems</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.35.1">A recommendation system is a computer</span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.36.1"> program that recommends items for users of digital platforms such as e-commerce websites and social networks. </span><span class="koboSpan" id="kobo.36.2">It uses large datasets to develop models of users’ likes and interests, and then recommends similar items to individual users.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.37.1">There are different types of recommendation systems, depending on the methods and data they use. </span><span class="koboSpan" id="kobo.37.2">Some of the common types are:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.38.1">Collaborative filtering</span></strong><span class="koboSpan" id="kobo.39.1">: This type of recommendation</span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.40.1"> system uses the ratings or feedback of other users</span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.41.1"> who have similar preferences to the target user. </span><span class="koboSpan" id="kobo.41.2">It assumes that users who liked certain items in the past will like similar items in the future. </span><span class="koboSpan" id="kobo.41.3">For example, if user A and user B both liked movies X and Y, then the algorithm may recommend movie Z to user A if user B also liked it.</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.42.1">Collaborative filtering can be further divided into two subtypes: user-based and item-based:</span></p>
<ul>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.43.1">User-based collaborative filtering</span></strong><span class="koboSpan" id="kobo.44.1"> finds similar users to the target</span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.45.1"> user and recommends items that they liked.</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.46.1">Item-based collaborative filtering</span></strong><span class="koboSpan" id="kobo.47.1"> finds similar items to the ones</span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.48.1"> that the target user liked and recommends them.</span></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.49.1">Content-based filtering</span></strong><span class="koboSpan" id="kobo.50.1">: This type of recommendation system</span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.51.1"> uses the features or attributes </span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.52.1">of the items themselves to recommend items that are similar to the ones that the target user has liked or interacted with before. </span><span class="koboSpan" id="kobo.52.2">It assumes that users who liked certain features of an item will like other items with similar features. </span><span class="koboSpan" id="kobo.52.3">The main difference with item-based collaborative filtering is that, while this latter item-based uses patterns of user behavior to make recommendations, content-based filtering uses information about the items themselves. </span><span class="koboSpan" id="kobo.52.4">For example, if user A liked movie X, which is a comedy with actor Y, then the algorithm may recommend movie Z, which is also a comedy</span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.53.1"> with actor Y.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.54.1">Hybrid filtering</span></strong><span class="koboSpan" id="kobo.55.1">: This type of recommendation</span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.56.1"> system combines both collaborative</span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.57.1"> and content-based filtering methods to overcome some of their limitations and provide more accurate and diverse recommendations. </span><span class="koboSpan" id="kobo.57.2">For example, YouTube uses hybrid filtering to recommend videos based on both the ratings and views of other users who have watched similar videos, and the features and categories of the videos themselves.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.58.1">Knowledge-based filtering</span></strong><span class="koboSpan" id="kobo.59.1">: This type of recommendation</span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.60.1"> system uses explicit knowledge</span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.61.1"> or rules about the domain and the user’s needs or preferences to recommend items that satisfy certain criteria or constraints. </span><span class="koboSpan" id="kobo.61.2">It does not rely on ratings or feedback from other users, but rather on the user’s input or query. </span><span class="koboSpan" id="kobo.61.3">For example, if user A wants to buy a laptop with certain specifications and budget, then the algorithm may recommend a laptop that satisfies those criteria. </span><span class="koboSpan" id="kobo.61.4">Knowledge-based recommender systems work well when there is no or little rating history available, or when the items are complex and customizable.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.62.1">Within the above frameworks, there are then various machine learning techniques that can be used, which we will cover in the next section.</span></p>
<h1 class="heading-1" id="_idParaDest-99"><span class="koboSpan" id="kobo.63.1">Existing recommendation systems</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.64.1">Modern recommendation systems use </span><strong class="keyWord"><span class="koboSpan" id="kobo.65.1">machine learning</span></strong><span class="koboSpan" id="kobo.66.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.67.1">ML</span></strong><span class="koboSpan" id="kobo.68.1">) techniques to make</span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.69.1"> better predictions about users’ preferences, based on the available data such as the following:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.70.1">User behavior data</span></strong><span class="koboSpan" id="kobo.71.1">:</span><strong class="keyWord"> </strong><span class="koboSpan" id="kobo.72.1">Insights about user interaction</span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.73.1"> with a product. </span><span class="koboSpan" id="kobo.73.2">This data can be acquired from factors like user ratings, clicks, and purchase records.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.74.1">User demographic data</span></strong><span class="koboSpan" id="kobo.75.1">: This refers to personal information</span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.76.1"> about users, including details like age, educational background, income level, and geographical location.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.77.1">Product attribute data</span></strong><span class="koboSpan" id="kobo.78.1">: This involves information</span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.79.1"> about the characteristics of a product, such as genres of books, casts of movies, or specific cuisines in the context of food.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.80.1">As of today, some of the most popular ML techniques are K-nearest neighbors, dimensionality reduction, and neural networks. </span><span class="koboSpan" id="kobo.80.2">Let’s look at these methods in detail.</span></p>
<h2 class="heading-2" id="_idParaDest-100"><span class="koboSpan" id="kobo.81.1">K-nearest neighbors</span></h2>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.82.1">K-nearest neighbors</span></strong><span class="koboSpan" id="kobo.83.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.84.1">KNN</span></strong><span class="koboSpan" id="kobo.85.1">) is an ML algorithm that can be used</span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.86.1"> for both classification and regression problems. </span><span class="koboSpan" id="kobo.86.2">It works by finding the </span><em class="italic"><span class="koboSpan" id="kobo.87.1">k</span></em><span class="koboSpan" id="kobo.88.1"> closest data points (where </span><em class="italic"><span class="koboSpan" id="kobo.89.1">k</span></em><span class="koboSpan" id="kobo.90.1"> refers to the number of nearest data point you want to find, and is set by the user before initializing the algorithm) to a new data point and using their labels or values to make a prediction. </span><span class="koboSpan" id="kobo.90.2">KNN is based on the assumption that similar data points are likely to have similar labels or values.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.91.1">KNN can be applied to recommendation systems in the context of collaborative filtering, both user-based and item-based:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.92.1">User-based KNN is a type of collaborative</span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.93.1"> filtering, which uses the ratings or feedback of other users who have similar tastes or preferences to the target user.</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.94.1">For example, let’s say we have three users: Alice, Bob, and Charlie. </span><span class="koboSpan" id="kobo.94.2">They all buy books online and rate them. </span><span class="koboSpan" id="kobo.94.3">Alice and Bob both liked (rated highly) the series, </span><em class="italic"><span class="koboSpan" id="kobo.95.1">Harry Potter</span></em><span class="koboSpan" id="kobo.96.1">, and the book, </span><em class="italic"><span class="koboSpan" id="kobo.97.1">The Hobbit</span></em><span class="koboSpan" id="kobo.98.1">. </span><span class="koboSpan" id="kobo.98.2">The system sees this pattern and considers Alice and Bob to be similar.</span></p>
<p class="normal-one"><span class="koboSpan" id="kobo.99.1">Now, if Bob also liked the book </span><em class="italic"><span class="koboSpan" id="kobo.100.1">A Game of Thrones</span></em><span class="koboSpan" id="kobo.101.1">, which Alice hasn’t read yet, the system will recommend </span><em class="italic"><span class="koboSpan" id="kobo.102.1">A Game of Thrones</span></em><span class="koboSpan" id="kobo.103.1"> to Alice. </span><span class="koboSpan" id="kobo.103.2">This is because it assumes that since Alice and Bob have similar tastes, Alice might also like </span><em class="italic"><span class="koboSpan" id="kobo.104.1">A Game of Thrones</span></em><span class="koboSpan" id="kobo.105.1">.</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.106.1">Item-based KNN is another type of collaborative</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.107.1"> filtering, which uses the attributes or features of the items to recommend similar items to the target user.</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.108.1">For example, let’s consider the same users and their ratings for the books. </span><span class="koboSpan" id="kobo.108.2">The system notices that the </span><em class="italic"><span class="koboSpan" id="kobo.109.1">Harry Potter</span></em><span class="koboSpan" id="kobo.110.1"> series and the book, </span><em class="italic"><span class="koboSpan" id="kobo.111.1">The Hobbit</span></em><span class="koboSpan" id="kobo.112.1"> are both liked by Alice and Bob. </span><span class="koboSpan" id="kobo.112.2">So, it considers these two books to be similar.</span></p>
<p class="normal-one"><span class="koboSpan" id="kobo.113.1">Now, if Charlie reads and likes </span><em class="italic"><span class="koboSpan" id="kobo.114.1">Harry Potter</span></em><span class="koboSpan" id="kobo.115.1">, the system will recommend </span><em class="italic"><span class="koboSpan" id="kobo.116.1">The Hobbit</span></em><span class="koboSpan" id="kobo.117.1"> to Charlie. </span><span class="koboSpan" id="kobo.117.2">This is because</span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.118.1"> it assumes that since </span><em class="italic"><span class="koboSpan" id="kobo.119.1">Harry Potter</span></em><span class="koboSpan" id="kobo.120.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.121.1">The Hobbit</span></em><span class="koboSpan" id="kobo.122.1"> are similar (both liked by the same users), Charlie might also like </span><em class="italic"><span class="koboSpan" id="kobo.123.1">The Hobbit</span></em><span class="koboSpan" id="kobo.124.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.125.1">KNN is a popular technique in recommendation systems, but it has</span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.126.1"> some pitfalls:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.127.1">Scalability</span></strong><span class="koboSpan" id="kobo.128.1">: KNN can become computationally expensive and slow when dealing with large datasets, as it requires calculating distances between all pairs of items or users.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.129.1">Cold-start problem</span></strong><span class="koboSpan" id="kobo.130.1">: KNN struggles with new items or users that have limited or no interaction history, as it relies on finding neighbors based on historical data.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.131.1">Data sparsity</span></strong><span class="koboSpan" id="kobo.132.1">: KNN performance can degrade in sparse datasets where there are many missing values, making it challenging to find meaningful neighbors.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.133.1">Feature relevance</span></strong><span class="koboSpan" id="kobo.134.1">: KNN treats all features equally and assumes that all features contribute equally to similarity calculations. </span><span class="koboSpan" id="kobo.134.2">This may not hold true in scenarios where some features are more relevant than others.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.135.1">Choice of K</span></strong><span class="koboSpan" id="kobo.136.1">: Selecting the appropriate value of K (number of neighbors) can be subjective and impact the quality of recommendations. </span><span class="koboSpan" id="kobo.136.2">A small K may result in noise, while a large K may lead to overly broad recommendations.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.137.1">Generally speaking, KNN is recommended in scenarios with small datasets with minimal noise (so that outliers, missing values and other noises do not impact the distance metric) and dynamic data (KNN is an instance-based method that doesn’t require retraining and can adapt to changes quickly).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.138.1">Additionally, further techniques are widely used in the file of recommendation systems, such as matrix factorization.</span></p>
<h2 class="heading-2" id="_idParaDest-101"><span class="koboSpan" id="kobo.139.1">Matrix factorization</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.140.1">Matrix factorization is a technique</span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.141.1"> used in recommendation systems to analyze and predict user preferences or behaviors based on historical data. </span><span class="koboSpan" id="kobo.141.2">It involves decomposing a large matrix into two or more smaller matrices to uncover latent features that contribute to the observed data patterns and address the so-called “curse of dimensionality.”</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.142.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.143.1">The curse of dimensionality</span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.144.1"> refers to challenges that arise when dealing with high-dimensional data. </span><span class="koboSpan" id="kobo.144.2">It leads to increased complexity, sparse data, and difficulties in analysis and modeling due to the exponential growth of data requirements and potential overfitting.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.145.1">In the context of recommendation </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.146.1">systems, this technique is employed to predict missing values in the user-item interaction matrix, which represents users’ interactions with various items (such as movies, products, or books).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.147.1">Let’s consider the following example. </span><span class="koboSpan" id="kobo.147.2">Imagine you have a matrix where rows represent users, columns represent movies, and the cells contain ratings (from 1 as lowest to 5 as highest). </span><span class="koboSpan" id="kobo.147.3">However, not all users have rated all movies, resulting in a matrix with many missing entries:</span></p>
<table class="table-container" id="table001-2">
<tbody>
<tr>
<td class="table-cell"/>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.148.1">Movie 1</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.149.1">Movie 2</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.150.1">Movie 3</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.151.1">Movie 4</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.152.1">User 1</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.153.1">4</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.154.1">-</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.155.1">5</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.156.1">-</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.157.1">User 2</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.158.1">-</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.159.1">3</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.160.1">-</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.161.1">2</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.162.1">User 3</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.163.1">5</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.164.1">4</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.165.1">-</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.166.1">3</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.167.1">Table 7.1: Example of a dataset with missing data</span></p>
<p class="normal"><span class="koboSpan" id="kobo.168.1">Matrix factorization aims to break down this matrix into two matrices: one for users and another for movies, with a reduced number of dimensions (latent factors). </span><span class="koboSpan" id="kobo.168.2">These latent factors could represent attributes like genre preferences or specific movie characteristics. </span><span class="koboSpan" id="kobo.168.3">By multiplying these matrices, you can predict the missing ratings and recommend movies that the users might enjoy.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.169.1">There are different algorithms</span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.170.1"> for matrix factorization, including the following:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.171.1">Singular value decomposition </span></strong><span class="koboSpan" id="kobo.172.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.173.1">SVD</span></strong><span class="koboSpan" id="kobo.174.1">) decomposes a matrix</span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.175.1"> into three separate matrices, where the middle matrix contains singular values that represent the importance of different components in the data. </span><span class="koboSpan" id="kobo.175.2">It’s widely used in data compression, dimensionality reduction, and collaborative filtering</span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.176.1"> in recommendation systems.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.177.1">Principal component analysis </span></strong><span class="koboSpan" id="kobo.178.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.179.1">PCA</span></strong><span class="koboSpan" id="kobo.180.1">) is a technique to reduce the dimensionality</span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.181.1"> of data by transforming it into a new coordinate system aligned with the principal components. </span><span class="koboSpan" id="kobo.181.2">These components capture the most significant variability in the data, allowing efficient analysis and visualization.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.182.1">Non-negative matrix factorization </span></strong><span class="koboSpan" id="kobo.183.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.184.1">NMF</span></strong><span class="koboSpan" id="kobo.185.1">) decomposes a matrix into two matrices with non-negative</span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.186.1"> values. </span><span class="koboSpan" id="kobo.186.2">It’s often used for topic modeling, image processing, and feature extraction, where the components represent non-negative</span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.187.1"> attributes.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.188.1">In the context of recommendation</span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.189.1"> systems, probably the most popular technique is SVD (thanks to its interpretability, flexibility, and ability to handle missing values and performance), so let’s use this one to go on with our example. </span><span class="koboSpan" id="kobo.189.2">We will use the Python </span><code class="inlineCode"><span class="koboSpan" id="kobo.190.1">numpy</span></code><span class="koboSpan" id="kobo.191.1"> module to apply SVD as follows:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.192.1">import</span></span><span class="koboSpan" id="kobo.193.1"> numpy </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.194.1">as</span></span><span class="koboSpan" id="kobo.195.1"> np
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.196.1"># Your user-movie rating matrix (replace with your actual data)</span></span><span class="koboSpan" id="kobo.197.1">
user_movie_matrix = np.array([
    [</span><span class="hljs-number"><span class="koboSpan" id="kobo.198.1">4</span></span><span class="koboSpan" id="kobo.199.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.200.1">0</span></span><span class="koboSpan" id="kobo.201.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.202.1">5</span></span><span class="koboSpan" id="kobo.203.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.204.1">0</span></span><span class="koboSpan" id="kobo.205.1">],
    [</span><span class="hljs-number"><span class="koboSpan" id="kobo.206.1">0</span></span><span class="koboSpan" id="kobo.207.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.208.1">3</span></span><span class="koboSpan" id="kobo.209.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.210.1">0</span></span><span class="koboSpan" id="kobo.211.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.212.1">2</span></span><span class="koboSpan" id="kobo.213.1">],
    [</span><span class="hljs-number"><span class="koboSpan" id="kobo.214.1">5</span></span><span class="koboSpan" id="kobo.215.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.216.1">4</span></span><span class="koboSpan" id="kobo.217.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.218.1">0</span></span><span class="koboSpan" id="kobo.219.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.220.1">3</span></span><span class="koboSpan" id="kobo.221.1">]
])
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.222.1"># Apply SVD</span></span><span class="koboSpan" id="kobo.223.1">
U, s, V = np.linalg.svd(user_movie_matrix, full_matrices=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.224.1">False</span></span><span class="koboSpan" id="kobo.225.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.226.1"># Number of latent factors (you can choose this based on your preference)</span></span><span class="koboSpan" id="kobo.227.1">
num_latent_factors = </span><span class="hljs-number"><span class="koboSpan" id="kobo.228.1">2</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.229.1"># Reconstruct the original matrix using the selected latent factors</span></span><span class="koboSpan" id="kobo.230.1">
reconstructed_matrix = U[:, :num_latent_factors] @ np.diag(s[:num_latent_factors]) @ V[:num_latent_factors, :]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.231.1"># Replace negative values with 0</span></span><span class="koboSpan" id="kobo.232.1">
reconstructed_matrix = np.maximum(reconstructed_matrix, </span><span class="hljs-number"><span class="koboSpan" id="kobo.233.1">0</span></span><span class="koboSpan" id="kobo.234.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.235.1">print</span></span><span class="koboSpan" id="kobo.236.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.237.1">"Reconstructed Matrix:"</span></span><span class="koboSpan" id="kobo.238.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.239.1">print</span></span><span class="koboSpan" id="kobo.240.1">(reconstructed_matrix)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.241.1">The following is the output:</span></p>
<pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.242.1">Reconstructed Matrix:
[[4.2972542  0.         </span><span class="koboSpan" id="kobo.242.2">4.71897811 0.        </span><span class="koboSpan" id="kobo.242.3">]
 [1.08572801 2.27604748 0.         </span><span class="koboSpan" id="kobo.242.4">1.64449028]
 [4.44777253 4.36821972 0.52207171 3.18082082]]
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.243.1">In this example, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.244.1">U</span></code><span class="koboSpan" id="kobo.245.1"> matrix contains user-related information, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.246.1">s</span></code><span class="koboSpan" id="kobo.247.1"> matrix contains singular values, and the </span><code class="inlineCode"><span class="koboSpan" id="kobo.248.1">V</span></code><span class="koboSpan" id="kobo.249.1"> matrix contains movie-related information. </span><span class="koboSpan" id="kobo.249.2">By selecting a certain number of latent factors (</span><code class="inlineCode"><span class="koboSpan" id="kobo.250.1">num_latent_factors</span></code><span class="koboSpan" id="kobo.251.1">), you can reconstruct the original matrix with reduced dimensions, while setting the </span><code class="inlineCode"><span class="koboSpan" id="kobo.252.1">full_matrices=False</span></code><span class="koboSpan" id="kobo.253.1"> parameter in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.254.1">np.linalg.svd</span></code><span class="koboSpan" id="kobo.255.1"> function ensures that the decomposed matrices are truncated to have dimensions consistent with the selected number of latent factors.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.256.1">These predicted ratings can then be used to recommend movies with higher predicted ratings to users. </span><span class="koboSpan" id="kobo.256.2">Matrix factorization enables recommendation systems to uncover hidden patterns in user preferences and make personalized recommendations based on those patterns.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.257.1">Matrix factorization has been a widely</span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.258.1"> used technique in recommendation systems, especially when dealing with large datasets containing a substantial number of users and items, since it efficiently captures latent factors even in such scenarios; or when you want personalized recommendations based on latent factors, since it learns unique latent representations for each user and item. </span><span class="koboSpan" id="kobo.258.2">However, it has some pitfalls (some similar to the KNN’s technique):</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.259.1">Cold-start problem</span></strong><span class="koboSpan" id="kobo.260.1">: Similar to KNN, matrix factorization</span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.261.1"> struggles with new items or users that have limited or no interaction history. </span><span class="koboSpan" id="kobo.261.2">Since it relies on historical data, it can’t effectively provide recommendations for new items or users.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.262.1">Data sparsity</span></strong><span class="koboSpan" id="kobo.263.1">: As the number of users and items grows, the user-item interaction matrix becomes increasingly sparse, leading to challenges in accurately predicting missing values.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.264.1">Scalability</span></strong><span class="koboSpan" id="kobo.265.1">: For large datasets, performing matrix factorization can be computationally expensive and time-consuming.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.266.1">Limited context</span></strong><span class="koboSpan" id="kobo.267.1">: Matrix factorization typically only considers user-item interactions, ignoring contextual information like time, location, or additional</span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.268.1"> user attributes.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.269.1">Hence, </span><strong class="keyWord"><span class="koboSpan" id="kobo.270.1">neural networks </span></strong><span class="koboSpan" id="kobo.271.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.272.1">NNs</span></strong><span class="koboSpan" id="kobo.273.1">) have been explored as an alternative</span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.274.1"> to mitigate these pitfalls in recent years.</span></p>
<h2 class="heading-2" id="_idParaDest-102"><span class="koboSpan" id="kobo.275.1">Neural networks</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.276.1">NNs are used in recommendation</span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.277.1"> systems to improve the accuracy and personalization of recommendations by learning intricate patterns from data. </span><span class="koboSpan" id="kobo.277.2">Here’s how neural networks are commonly applied in this context:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.278.1">Collaborative filtering with neural networks</span></strong><span class="koboSpan" id="kobo.279.1">: Neural networks can model</span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.280.1"> user-item interactions by embedding users and items into continuous vector spaces. </span><span class="koboSpan" id="kobo.280.2">These embeddings capture latent features that represent user preferences and item characteristics. </span><span class="koboSpan" id="kobo.280.3">Neural collaborative filtering models combine these embeddings with neural network architectures to predict ratings or interactions between users and items.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.281.1">Content-based recommendations</span></strong><span class="koboSpan" id="kobo.282.1">: In content-based recommendation</span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.283.1"> systems, neural networks can learn representations of item content, such as text, images, or audio. </span><span class="koboSpan" id="kobo.283.2">These representations capture</span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.284.1"> item characteristics and user preferences. </span><span class="koboSpan" id="kobo.284.2">Neural networks like </span><strong class="keyWord"><span class="koboSpan" id="kobo.285.1">convolutional neural networks</span></strong><span class="koboSpan" id="kobo.286.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.287.1">CNNs</span></strong><span class="koboSpan" id="kobo.288.1">) and </span><strong class="keyWord"><span class="koboSpan" id="kobo.289.1">recurrent neural networks</span></strong><span class="koboSpan" id="kobo.290.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.291.1">RNNs</span></strong><span class="koboSpan" id="kobo.292.1">) are used to process and learn</span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.293.1"> from item content, enabling personalized content-based recommendations.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.294.1">Sequential models</span></strong><span class="koboSpan" id="kobo.295.1">: In scenarios where user interactions</span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.296.1"> have a temporal sequence, such as clickstreams or browsing history, RNNs or variants such as </span><strong class="keyWord"><span class="koboSpan" id="kobo.297.1">long short-term memory </span></strong><span class="koboSpan" id="kobo.298.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.299.1">LSTM</span></strong><span class="koboSpan" id="kobo.300.1">) networks can capture temporal</span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.301.1"> dependencies in the user behavior and make sequential recommendations.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.302.1">Autoencoders and variational autoencoders </span></strong><span class="koboSpan" id="kobo.303.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.304.1">VAEs</span></strong><span class="koboSpan" id="kobo.305.1">) can be used to learn low-dimensional</span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.306.1"> representations</span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.307.1"> of users and items.</span></li>
</ul>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.308.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.309.1">Autoencoders are a type of neural</span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.310.1"> network architecture used for unsupervised learning and dimensionality reduction. </span><span class="koboSpan" id="kobo.310.2">They consist of an encoder and a decoder. </span><span class="koboSpan" id="kobo.310.3">The encoder maps the input data into a lower-dimensional latent space representation, while the decoder attempts to reconstruct the original input data from the encoded representation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.311.1">VAEs</span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.312.1"> are an extension of traditional autoencoders that introduce probabilistic elements. </span><span class="koboSpan" id="kobo.312.2">VAEs not only learn to encode the input data into a latent space but also model the distribution of this latent space using probabilistic methods. </span><span class="koboSpan" id="kobo.312.3">This allows for the generation of new data samples from the learned latent space. </span><span class="koboSpan" id="kobo.312.4">VAEs are used for generative tasks like image synthesis, anomaly detection, and data imputation.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.313.1">In both autoencoders and VAEs, the idea is to learn</span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.314.1"> a compressed and meaningful representation of the input data in the latent space, which can be useful for various tasks including feature extraction, data generation, and dimensionality reduction.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.315.1">These representations can then be used to make recommendations by identifying similar users and items in the latent space. </span><span class="koboSpan" id="kobo.315.2">In fact, the unique architecture that features</span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.316.1"> NNs allows for the following techniques:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.317.1">Side information integration</span></strong><span class="koboSpan" id="kobo.318.1">: NNs can incorporate additional user and item attributes, such as demographic information, location, or social connections, to improve recommendations by learning from diverse data sources.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.319.1">Deep reinforcement learning</span></strong><span class="koboSpan" id="kobo.320.1">: In certain scenarios, deep reinforcement learning can be used to optimize recommendations over time, learning from user feedback to suggest actions that maximize long-term rewards.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.321.1">NNs offer flexibility and the ability to capture complex patterns in data, making them well suited for recommendation systems. </span><span class="koboSpan" id="kobo.321.2">However, they also require careful design, training, and tuning to achieve optimal performance. </span><span class="koboSpan" id="kobo.321.3">NNs also bring their own challenges, including</span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.322.1"> the following:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.323.1">Increased complexity</span></strong><span class="koboSpan" id="kobo.324.1">: NNs, especially </span><strong class="keyWord"><span class="koboSpan" id="kobo.325.1">deep neural networks</span></strong><span class="koboSpan" id="kobo.326.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.327.1">DNNs</span></strong><span class="koboSpan" id="kobo.328.1">), can become incredibly complex</span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.329.1"> due to their layered architecture. </span><span class="koboSpan" id="kobo.329.2">As we add more hidden layers and neurons, the model’s capacity to learn intricate patterns increases.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.330.1">Training requirements</span></strong><span class="koboSpan" id="kobo.331.1">: NNs are heavy models whose training requires special hardware requirements including GPUs, which might be very expensive.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.332.1">Potential overfitting</span></strong><span class="koboSpan" id="kobo.333.1">: Overfitting occurs when an ANN learns to perform exceptionally</span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.334.1"> well on the training data but fails to generalize to unseen data</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.335.1">Selecting appropriate architectures, handling large datasets, and tuning hyperparameters are essential to effectively use NNs in recommendation systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.336.1">Even though relevant advancements have been made in recent years, the aforementioned techniques still suffer from some pitfalls, primarily their being task-specific. </span><span class="koboSpan" id="kobo.336.2">For example, a rating-prediction recommendation system will not be able to tackle a task where we need to recommend the top </span><em class="italic"><span class="koboSpan" id="kobo.337.1">k</span></em><span class="koboSpan" id="kobo.338.1"> items that likely match the user’s taste. </span><span class="koboSpan" id="kobo.338.2">Actually, if we extend this limitation to other “pre-LLMs” AI solutions, we might see some similarities: it is indeed the task-specific situation that LLMs and, more generally, Large Foundation Models are revolutionizing, being highly generalized and adaptable to various tasks, depending on user’s prompts and instructions. </span><span class="koboSpan" id="kobo.338.3">Henceforth, extensive research in the field of recommendation systems is being done into what extent LLMs can enhance</span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.339.1"> the current models. </span><span class="koboSpan" id="kobo.339.2">In the following sections, we will cover the theory behind these new approaches referring to recent papers and blogs about this emerging domain.</span></p>
<h1 class="heading-1" id="_idParaDest-103"><span class="koboSpan" id="kobo.340.1">How LLMs are changing recommendation systems</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.341.1">We saw in previous chapters</span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.342.1"> how LLMs can be customized in three main ways: pre-training, fine-tuning, and prompting. </span><span class="koboSpan" id="kobo.342.2">According to the paper </span><em class="italic"><span class="koboSpan" id="kobo.343.1">Recommender systems in the Era of Large Language Models (LLMs)</span></em><span class="koboSpan" id="kobo.344.1"> from Wenqi Fan et al., these techniques can also be used to tailor an LLM to be a recommender system:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.345.1">Pre-training</span></strong><span class="koboSpan" id="kobo.346.1">: Pre-training LLMs for recommender systems</span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.347.1"> is an important step to enable LLMs to acquire extensive world knowledge and user preferences, and to adapt to different recommendation tasks with zero or few shots.</span></li>
</ul>
<div class="note-one">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.348.1">Note</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.349.1">An example of a recommendation</span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.350.1"> system LLM is P5, introduced by Shijie Gang et al. </span><span class="koboSpan" id="kobo.350.2">in their paper </span><em class="italic"><span class="koboSpan" id="kobo.351.1">Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5)</span></em><span class="koboSpan" id="kobo.352.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.353.1">P5 is a unified text-to-text paradigm</span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.354.1"> for building recommender systems using </span><strong class="keyWord"><span class="koboSpan" id="kobo.355.1">large language models</span></strong><span class="koboSpan" id="kobo.356.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.357.1">LLMs</span></strong><span class="koboSpan" id="kobo.358.1">). </span><span class="koboSpan" id="kobo.358.2">It consists of three steps:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.359.1">Pretrain: A foundation language model based on T5 architecture is pretrained on a large-scale web corpus and fine-tuned on recommendation tasks.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.360.1">Personalized prompt: A personalized prompt is generated for each user based on their behavior data and contextual features.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.361.1">Predict: The personalized prompt is fed into the pretrained language model to generate recommendations.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.362.1">P5 is based on the idea that LLMs can encode extensive world knowledge and user preferences and can be adapted to different recommendation tasks with zero or few shots.</span></p>
</div>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.363.1">Fine-tuning</span></strong><span class="koboSpan" id="kobo.364.1">: Training an LLM from scratch</span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.365.1"> is a highly computational-intensive activity. </span><span class="koboSpan" id="kobo.365.2">An alternative and less intrusive approach to customize an LLM for recommendation systems might be fine-tuning.</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.366.1">More specifically, the authors of the paper review two main strategies for fine-tuning LLMs:</span></p>
<ul>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.367.1">Full-model fine-tuning</span></strong><span class="koboSpan" id="kobo.368.1"> involves changing</span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.369.1"> the entire model’s weights based on task-specific recommendation datasets.</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.370.1">Parameter-efficient fine-tuning</span></strong><span class="koboSpan" id="kobo.371.1"> aims to change</span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.372.1"> only a small part of weights or develop trainable adapters to fit specific tasks.</span></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.373.1">Prompting</span></strong><span class="koboSpan" id="kobo.374.1">: The third and “lightest” way of tailoring</span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.375.1"> LLMs to be recommender systems is prompting. </span><span class="koboSpan" id="kobo.375.2">According to the authors, there are three main techniques for prompting LLMs:</span><ul>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.376.1">Conventional prompting </span></strong><span class="koboSpan" id="kobo.377.1">aims to unify downstream tasks into language generation tasks by designing text templates or providing a few input-output examples.</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.378.1">In-context learning </span></strong><span class="koboSpan" id="kobo.379.1">enables LLMs to learn new tasks based on contextual information without fine-tuning.</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.380.1">Chain-of-thought</span></strong><span class="koboSpan" id="kobo.381.1"> enhances the reasoning abilities of LLMs by providing multiple demonstrations to describe the chain of thought as examples within the prompt. </span><span class="koboSpan" id="kobo.381.2">The authors also discuss the advantages and challenges of each technique and provide some examples of existing methods that adopt them.</span></li>
</ul>
</li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.382.1">Regardless of the typology, prompting is the fastest way to test whether a general-purpose LLM</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.383.1"> can tackle recommendation systems’ tasks.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.384.1">The application of LLMs within the recommendation system domain is raising interest in the research field, and there is already some interesting evidence of the results as seen above.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.385.1">In the next section, we are going to implement our own recommendation application using the prompting approach and leveraging the capabilities of LangChain as an AI orchestrator.</span></p>
<h1 class="heading-1" id="_idParaDest-104"><span class="koboSpan" id="kobo.386.1">Implementing an LLM-powered recommendation system</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.387.1">Now that we have covered some theory</span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.388.1"> about recommendation systems and emerging research on how LLMs can enhance them, let’s start building our recommendation app, which will be a movie</span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.389.1"> recommender system called MovieHarbor. </span><span class="koboSpan" id="kobo.389.2">The goal will be to make it as general as possible, meaning that we want our app to be able to address various recommendations tasks with a conversational interface. </span><span class="koboSpan" id="kobo.389.3">The scenario we are going to simulate</span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.390.1"> will be that of the so-called “cold start,” concerning the first interaction of a user with the recommendation system where we do not have the user’s preference history. </span><span class="koboSpan" id="kobo.390.2">We will leverage a movie database with textual descriptions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.391.1">For this purpose, we will </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.392.1">use the </span><em class="italic"><span class="koboSpan" id="kobo.393.1">Movie recommendation data</span></em><span class="koboSpan" id="kobo.394.1"> dataset, available on Kaggle at </span><a href="https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data"><span class="url"><span class="koboSpan" id="kobo.395.1">https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data</span></span></a><span class="koboSpan" id="kobo.396.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.397.1">The reason for using a dataset with a textual description of each movie (alongside information such as ratings and movie titles) is so that we can get the embeddings of the text. </span><span class="koboSpan" id="kobo.397.2">So let’s start building our MovieHarbor application.</span></p>
<h2 class="heading-2" id="_idParaDest-105"><span class="koboSpan" id="kobo.398.1">Data preprocessing</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.399.1">In order to apply LLMs</span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.400.1"> to our dataset, we first need to preprocess the data. </span><span class="koboSpan" id="kobo.400.2">The initial dataset included several columns; however, the ones we are interested in are the following:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.401.1">Genres</span></strong><span class="koboSpan" id="kobo.402.1">: A list of applicable genres for the movie.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.403.1">Title</span></strong><span class="koboSpan" id="kobo.404.1">: The movie’s title.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.405.1">Overview</span></strong><span class="koboSpan" id="kobo.406.1">: Textual description of the plot.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.407.1">Vote_average</span></strong><span class="koboSpan" id="kobo.408.1">: A rating from 1 to 10 for a given movie</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.409.1">Vote_count</span></strong><span class="koboSpan" id="kobo.410.1">: The number of votes for a given movie.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.411.1">I won’t report here the whole code (you can find it in the GitHub repo of this book at </span><a href="Chapter_07.xhtml"><span class="url"><span class="koboSpan" id="kobo.412.1">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</span></span></a><span class="koboSpan" id="kobo.413.1">), however, I will share the main steps of data preprocessing:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.414.1">First, we format the </span><code class="inlineCode"><span class="koboSpan" id="kobo.415.1">genres</span></code><span class="koboSpan" id="kobo.416.1"> column into a </span><code class="inlineCode"><span class="koboSpan" id="kobo.417.1">numpy</span></code><span class="koboSpan" id="kobo.418.1"> array, which is easier to handle than the original dictionary format in the dataset:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.419.1">import</span></span><span class="koboSpan" id="kobo.420.1"> pandas </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.421.1">as</span></span><span class="koboSpan" id="kobo.422.1"> pd
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.423.1">import</span></span><span class="koboSpan" id="kobo.424.1"> ast
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.425.1"># Convert string representation of dictionaries to actual dictionaries</span></span><span class="koboSpan" id="kobo.426.1">
md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.427.1">'genres'</span></span><span class="koboSpan" id="kobo.428.1">] = md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.429.1">'genres'</span></span><span class="koboSpan" id="kobo.430.1">].apply(ast.literal_eval)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.431.1"># Transforming the 'genres' column</span></span><span class="koboSpan" id="kobo.432.1">
md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.433.1">'genres'</span></span><span class="koboSpan" id="kobo.434.1">] = md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.435.1">'genres'</span></span><span class="koboSpan" id="kobo.436.1">].apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.437.1">lambda</span></span><span class="koboSpan" id="kobo.438.1"> x: [genre[</span><span class="hljs-string"><span class="koboSpan" id="kobo.439.1">'name'</span></span><span class="koboSpan" id="kobo.440.1">] </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.441.1">for</span></span><span class="koboSpan" id="kobo.442.1"> genre </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.443.1">in</span></span><span class="koboSpan" id="kobo.444.1"> x])
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.445.1">Next, we merge the </span><code class="inlineCode"><span class="koboSpan" id="kobo.446.1">vote_average</span></code><span class="koboSpan" id="kobo.447.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.448.1">vote_count</span></code><span class="koboSpan" id="kobo.449.1"> columns into a single column, which is the weighted ratings with respect to the number of votes. </span><span class="koboSpan" id="kobo.449.2">I’ve also limited the rows to the 95</span><sup class="superscript"><span class="koboSpan" id="kobo.450.1">th</span></sup><span class="koboSpan" id="kobo.451.1"> percentile of the number of votes, so that we can get rid of minimum vote counts to prevent skewed results:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.452.1"># Calculate weighted rate (IMDb formula)</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.453.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.454.1">calculate_weighted_rate</span></span><span class="koboSpan" id="kobo.455.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.456.1">vote_average, vote_count, min_vote_count=</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.457.1">10</span></span><span class="koboSpan" id="kobo.458.1">):
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.459.1">return</span></span><span class="koboSpan" id="kobo.460.1"> (vote_count / (vote_count + min_vote_count)) * vote_average + (min_vote_count / (vote_count + min_vote_count)) * </span><span class="hljs-number"><span class="koboSpan" id="kobo.461.1">5.0</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.462.1"># Minimum vote count to prevent skewed results</span></span><span class="koboSpan" id="kobo.463.1">
vote_counts = md[md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.464.1">'vote_count'</span></span><span class="koboSpan" id="kobo.465.1">].notnull()][</span><span class="hljs-string"><span class="koboSpan" id="kobo.466.1">'vote_count'</span></span><span class="koboSpan" id="kobo.467.1">].astype(</span><span class="hljs-string"><span class="koboSpan" id="kobo.468.1">'int'</span></span><span class="koboSpan" id="kobo.469.1">)
min_vote_count = vote_counts.quantile(</span><span class="hljs-number"><span class="koboSpan" id="kobo.470.1">0.95</span></span><span class="koboSpan" id="kobo.471.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.472.1"># Create a new column 'weighted_rate'</span></span><span class="koboSpan" id="kobo.473.1">
md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.474.1">'weighted_rate'</span></span><span class="koboSpan" id="kobo.475.1">] = md.apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.476.1">lambda</span></span><span class="koboSpan" id="kobo.477.1"> row: calculate_weighted_rate(row[</span><span class="hljs-string"><span class="koboSpan" id="kobo.478.1">'vote_average'</span></span><span class="koboSpan" id="kobo.479.1">], row[</span><span class="hljs-string"><span class="koboSpan" id="kobo.480.1">'vote_count'</span></span><span class="koboSpan" id="kobo.481.1">], min_vote_count), axis=</span><span class="hljs-number"><span class="koboSpan" id="kobo.482.1">1</span></span><span class="koboSpan" id="kobo.483.1">)
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.484.1">Next, we create</span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.485.1"> a new column called </span><code class="inlineCode"><span class="koboSpan" id="kobo.486.1">combined_info</span></code><span class="koboSpan" id="kobo.487.1"> where we are going to merge all the elements that will be provided as context to the LLMs. </span><span class="koboSpan" id="kobo.487.2">Those elements are the movie title, overview, genres, and ratings:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.488.1">md_final[</span><span class="hljs-string"><span class="koboSpan" id="kobo.489.1">'combined_info'</span></span><span class="koboSpan" id="kobo.490.1">] = md_final.apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.491.1">lambda</span></span><span class="koboSpan" id="kobo.492.1"> row: </span><span class="hljs-string"><span class="koboSpan" id="kobo.493.1">f"Title: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.494.1">{row[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.495.1">'title'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.496.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.497.1">. </span><span class="koboSpan" id="kobo.497.2">Overview: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.498.1">{row[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.499.1">'overview'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.500.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.501.1"> Genres: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.502.1">{</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.503.1">', '</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.504.1">.join(row[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.505.1">'genres'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.506.1">])}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.507.1">. </span><span class="koboSpan" id="kobo.507.2">Rating: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.508.1">{row[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.509.1">'weighted_rate'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.510.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.511.1">"</span></span><span class="koboSpan" id="kobo.512.1">, axis=</span><span class="hljs-number"><span class="koboSpan" id="kobo.513.1">1</span></span><span class="koboSpan" id="kobo.514.1">).astype(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.515.1">str</span></span><span class="koboSpan" id="kobo.516.1">)
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.517.1">We tokenize the movie </span><code class="inlineCode"><span class="koboSpan" id="kobo.518.1">combined_info</span></code><span class="koboSpan" id="kobo.519.1"> so that we will get better results while embedding:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.520.1">import</span></span><span class="koboSpan" id="kobo.521.1"> pandas </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.522.1">as</span></span><span class="koboSpan" id="kobo.523.1"> pd
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.524.1">import</span></span><span class="koboSpan" id="kobo.525.1"> tiktoken
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.526.1">import</span></span><span class="koboSpan" id="kobo.527.1"> os
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.528.1">import</span></span><span class="koboSpan" id="kobo.529.1"> openai
openai.api_key = os.environ[</span><span class="hljs-string"><span class="koboSpan" id="kobo.530.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.531.1">OPENAI_API_KEY"</span></span><span class="koboSpan" id="kobo.532.1">]
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.533.1">from</span></span><span class="koboSpan" id="kobo.534.1"> openai.embeddings_utils </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.535.1">import</span></span><span class="koboSpan" id="kobo.536.1"> get_embedding
embedding_encoding = </span><span class="hljs-string"><span class="koboSpan" id="kobo.537.1">"cl100k_base"</span></span> <span class="hljs-comment"><span class="koboSpan" id="kobo.538.1"># this the encoding for text-embedding-ada-002</span></span><span class="koboSpan" id="kobo.539.1">
max_tokens = </span><span class="hljs-number"><span class="koboSpan" id="kobo.540.1">8000</span></span> <span class="hljs-comment"><span class="koboSpan" id="kobo.541.1"># the maximum for text-embedding-ada-002 is 8191</span></span><span class="koboSpan" id="kobo.542.1">
encoding = tiktoken.get_encoding(embedding_encoding)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.543.1"># omit reviews that are too long to embed</span></span><span class="koboSpan" id="kobo.544.1">
md_final[</span><span class="hljs-string"><span class="koboSpan" id="kobo.545.1">"n_tokens"</span></span><span class="koboSpan" id="kobo.546.1">] = md_final.combined_info.apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.547.1">lambda</span></span><span class="koboSpan" id="kobo.548.1"> x: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.549.1">len</span></span><span class="koboSpan" id="kobo.550.1">(encoding.encode(x)))
md_final = md_final[md_final.n_tokens &lt;= max_tokens]
</span></code></pre>
</li>
</ol>
<div class="note-one">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.551.1">Definition</span></strong></p>
<p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.552.1">cl100k_base</span></code><span class="koboSpan" id="kobo.553.1"> is the name of a tokenizer used by OpenAI’s embeddings API. </span><span class="koboSpan" id="kobo.553.2">A tokenizer is a tool that splits a text</span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.554.1"> string into units called tokens, which can then be processed by a neural network. </span><span class="koboSpan" id="kobo.554.2">Different tokenizers have different rules and vocabularies for how to split the text and what tokens to use.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.555.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.556.1">cl100k_base</span></code><span class="koboSpan" id="kobo.557.1"> tokenizer is based on the </span><strong class="keyWord"><span class="koboSpan" id="kobo.558.1">byte pair encoding</span></strong><span class="koboSpan" id="kobo.559.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.560.1">BPE</span></strong><span class="koboSpan" id="kobo.561.1">) algorithm, which learns</span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.562.1"> a vocabulary of subword units from a large corpus of text. </span><span class="koboSpan" id="kobo.562.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.563.1">cl100k_base</span></code><span class="koboSpan" id="kobo.564.1"> tokenizer has a vocabulary of 100,000 tokens, which are mostly common words and word pieces, but also include some special tokens for punctuation, formatting, and control. </span><span class="koboSpan" id="kobo.564.2">It can handle texts in multiple languages and domains, and can encode up to 8,191 tokens per input.</span></p>
</div>
<ol>
<li class="numberedList" value="5"><span class="koboSpan" id="kobo.565.1">We embed the text</span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.566.1"> with </span><code class="inlineCode"><span class="koboSpan" id="kobo.567.1">text-embedding-ada-002</span></code><span class="koboSpan" id="kobo.568.1">:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.569.1">md_final[</span><span class="hljs-string"><span class="koboSpan" id="kobo.570.1">"embedding"</span></span><span class="koboSpan" id="kobo.571.1">] = md_final.overview.apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.572.1">lambda</span></span><span class="koboSpan" id="kobo.573.1"> x: get_embedding(x, engine=embedding_model))
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.574.1">After changing some columns’ names and dropping unnecessary columns, the final dataset looks as follows:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.575.1"><img alt="" role="presentation" src="../Images/B21714_07_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.576.1">Figure 7.1: Sample of the final movies dataset</span></p>
<p class="normal-one"><span class="koboSpan" id="kobo.577.1">Let’s have a look at a random row of text:</span></p>
<pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.578.1">md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.579.1">'text'</span></span><span class="koboSpan" id="kobo.580.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.581.1">0</span></span><span class="koboSpan" id="kobo.582.1">]
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.583.1">The following output is obtained:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.584.1">'Title: GoldenEye. </span><span class="koboSpan" id="kobo.584.2">Overview: James Bond must unmask the mysterious head of the Janus Syndicate and prevent the leader from utilizing the GoldenEye weapons system to inflict devastating revenge on Britain. </span><span class="koboSpan" id="kobo.584.3">Genres: Adventure, Action, Thriller. </span><span class="koboSpan" id="kobo.584.4">Rating: 6.173464373464373'
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.585.1">The last change we will make is modifying some naming conventions and data types as follows:</span></p>
<pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.586.1">md_final.rename(columns = {</span><span class="hljs-string"><span class="koboSpan" id="kobo.587.1">'embedding'</span></span><span class="koboSpan" id="kobo.588.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.589.1">'vector'</span></span><span class="koboSpan" id="kobo.590.1">}, inplace = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.591.1">True</span></span><span class="koboSpan" id="kobo.592.1">)
md_final.rename(columns = {</span><span class="hljs-string"><span class="koboSpan" id="kobo.593.1">'combined_info'</span></span><span class="koboSpan" id="kobo.594.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.595.1">'text'</span></span><span class="koboSpan" id="kobo.596.1">}, inplace = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.597.1">True</span></span><span class="koboSpan" id="kobo.598.1">)
md_final.to_pickle(</span><span class="hljs-string"><span class="koboSpan" id="kobo.599.1">'movies.pkl'</span></span><span class="koboSpan" id="kobo.600.1">)
</span></code></pre>
<ol>
<li class="numberedList" value="6"><span class="koboSpan" id="kobo.601.1">Now that we have our final dataset, we need to store it in a VectorDB. </span><span class="koboSpan" id="kobo.601.2">For this purpose, we</span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.602.1"> are going to leverage </span><strong class="keyWord"><span class="koboSpan" id="kobo.603.1">LanceDB</span></strong><span class="koboSpan" id="kobo.604.1">, an open-source database for vector-search built with persistent storage, which greatly simplifies the retrieval, filtering, and management of embeddings and also offers a native integration with LangChain. </span><span class="koboSpan" id="kobo.604.2">You can easily install LanceDB via </span><code class="inlineCode"><span class="koboSpan" id="kobo.605.1">pip install lancedb</span></code><span class="koboSpan" id="kobo.606.1">:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.607.1">import</span></span><span class="koboSpan" id="kobo.608.1"> lancedb
uri = </span><span class="hljs-string"><span class="koboSpan" id="kobo.609.1">"data/sample-lancedb"</span></span><span class="koboSpan" id="kobo.610.1">
db = lancedb.connect(uri)
table = db.create_table(</span><span class="hljs-string"><span class="koboSpan" id="kobo.611.1">"movies"</span></span><span class="koboSpan" id="kobo.612.1">, md)
</span></code></pre>
</li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.613.1">Now that we have all our ingredients, we can start working with those embeddings and start building our recommendation</span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.614.1"> system. </span><span class="koboSpan" id="kobo.614.2">We will start with a simple task in a cold-start scenario, adding progressive layers of complexity with LangChain components. </span><span class="koboSpan" id="kobo.614.3">Afterwards, we will also try a content-based scenario to challenge our LLMs with diverse tasks.</span></p>
<h2 class="heading-2" id="_idParaDest-106"><span class="koboSpan" id="kobo.615.1">Building a QA recommendation chatbot in a cold-start scenario</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.616.1">In previous sections, we saw</span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.617.1"> how the cold-start</span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.618.1"> scenario – that means interacting with a user for the first time without their backstory – is a problem often encountered by recommendation systems. </span><span class="koboSpan" id="kobo.618.2">The less information we have about a user, the harder it is to match the recommendations to their preferences.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.619.1">In this section, we are going to simulate a cold-start scenario with LangChain and OpenAI’s LLMs with the following high-level architecture:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.620.1"><img alt="A diagram of a computer  Description automatically generated" src="../Images/B21714_07_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.621.1">Figure 7.2: High-level architecture of recommendation system in a cold-start scenario</span></p>
<p class="normal"><span class="koboSpan" id="kobo.622.1">In the previous section, we’ve already saved our embeddings in LanceDB. </span><span class="koboSpan" id="kobo.622.2">Now, we are going to build a LangChain RetrievalQA retriever, a chain component designed for question-answering against an index. </span><span class="koboSpan" id="kobo.622.3">In our case, we will use the vector store as our index retriever. </span><span class="koboSpan" id="kobo.622.4">The idea is that the chain returns the top </span><em class="italic"><span class="koboSpan" id="kobo.623.1">k</span></em><span class="koboSpan" id="kobo.624.1"> most similar movies upon the user’s query, using cosine similarity as the distance metric (which is the default).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.625.1">So, let’s start building the chain:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.626.1">We are using only the movie overview as information input:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.627.1">from</span></span><span class="koboSpan" id="kobo.628.1"> langchain.embeddings </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.629.1">import</span></span><span class="koboSpan" id="kobo.630.1"> OpenAIEmbeddings
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.631.1">from</span></span><span class="koboSpan" id="kobo.632.1"> langchain.vectorstores </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.633.1">import</span></span><span class="koboSpan" id="kobo.634.1"> LanceDB
os.environ[</span><span class="hljs-string"><span class="koboSpan" id="kobo.635.1">"OPENAI_API_KEY"</span></span><span class="koboSpan" id="kobo.636.1">]
embeddings = OpenAIEmbeddings()
docsearch = LanceDB(connection = table, embedding = embeddings)
query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.637.1">"I'm looking for an animated action movie. </span><span class="koboSpan" id="kobo.637.2">What could you suggest to me?"</span></span><span class="koboSpan" id="kobo.638.1">
docs = docsearch.similarity_search(query)
docs
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.639.1">The following is the corresponding</span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.640.1"> output (I will display a truncated version of the output, showing</span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.641.1"> only the first out of four document sources):</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.642.1">[Document(page_content='Title: Hitman: Agent 47. </span><span class="koboSpan" id="kobo.642.2">Overview: An assassin teams up with a woman to help her find her father and uncover the mysteries of her ancestry. </span><span class="koboSpan" id="kobo.642.3">Genres: Action, Crime, Thriller. </span><span class="koboSpan" id="kobo.642.4">Rating: 5.365800865800866', metadata={'genres': array(['Action', 'Crime', 'Thriller'], dtype=object), 'title': 'Hitman: Agent 47', 'overview': 'An assassin teams up with a woman to help her find her father and uncover the mysteries of her ancestry.', 'weighted_rate': 5.365800865800866, 'n_tokens': 52, 'vector': array([-0.00566491, -0.01658553, […]
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.643.1">As you can see, alongside each </span><code class="inlineCode"><span class="koboSpan" id="kobo.644.1">Document</span></code><span class="koboSpan" id="kobo.645.1">, all variables are reported as metadata, plus the distance is also reported as a score. </span><span class="koboSpan" id="kobo.645.2">The lower the distance, the greater the proximity between the user’s query and the movie’s text embedding.</span></p>
<ol>
<li class="numberedList" value="2"><span class="koboSpan" id="kobo.646.1">Once we have gathered the most similar documents, we want a conversational response. </span><span class="koboSpan" id="kobo.646.2">For this goal, in addition to the embedding models, we will also use OpenAI’s completion model GPT-3 and combine it in RetrievalQA:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.647.1">qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.648.1">"stuff"</span></span><span class="koboSpan" id="kobo.649.1">, retriever=docsearch.as_retriever(), return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.650.1">True</span></span><span class="koboSpan" id="kobo.651.1">)
query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.652.1">"I'm looking for an animated action movie. </span><span class="koboSpan" id="kobo.652.2">What could you suggest to me?"</span></span><span class="koboSpan" id="kobo.653.1">
result = qa({</span><span class="hljs-string"><span class="koboSpan" id="kobo.654.1">"query"</span></span><span class="koboSpan" id="kobo.655.1">: query})
result['result']
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.656.1">Let’s look at the output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.657.1">' I would suggest Transformers. </span><span class="koboSpan" id="kobo.657.2">It is an animated action movie with genres of Adventure, Science Fiction, and Action, and a rating of 6.'
</span></code></pre>
<ol>
<li class="numberedList" value="3"><span class="koboSpan" id="kobo.658.1">Since we set</span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.659.1"> the </span><code class="inlineCode"><span class="koboSpan" id="kobo.660.1">return_source_documents=True</span></code><span class="koboSpan" id="kobo.661.1"> parameter, we can</span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.662.1"> also retrieve the document sources:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.663.1">result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.664.1">'source_documents'</span></span><span class="koboSpan" id="kobo.665.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.666.1">0</span></span><span class="koboSpan" id="kobo.667.1">]
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.668.1">The following is the output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.669.1">Document(page_content='Title: Hitman: Agent 47. </span><span class="koboSpan" id="kobo.669.2">Overview: An assassin teams up with a woman to help her find her father and uncover the mysteries of her ancestry. </span><span class="koboSpan" id="kobo.669.3">Genres: Action, Crime, Thriller. </span><span class="koboSpan" id="kobo.669.4">Rating: 5.365800865800866', metadata={'genres': array(['Action', 'Crime', 'Thriller'], dtype=object), 'title': 'Hitman: Agent 47', 'overview': 'An assassin teams up with a woman to help her find her father and uncover the mysteries of her ancestry.', 'weighted_rate': 5.365800865800866, 'n_tokens': 52, 'vector': array([-0.00566491, -0.01658553, -0.02255735, ..., -0.01242317,
       -0.01303058, -0.00709073], dtype=float32), '_distance': 0.42414575815200806})
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.670.1">Note that the first document reported is not the one the model suggested. </span><span class="koboSpan" id="kobo.670.2">This occurred probably because of the rating, which is lower than Transformers (which was only the third result). </span><span class="koboSpan" id="kobo.670.3">This is a great example of how the LLM was able to consider multiple factors, on top of similarity, to suggest a movie to the user.</span></p>
<ol>
<li class="numberedList" value="4"><span class="koboSpan" id="kobo.671.1">The model was able to generate a conversational answer, however, it is still using only a part of the available information – the textual overview. </span><span class="koboSpan" id="kobo.671.2">What if we want our MovieHarbor system to also leverage the other variables? </span><span class="koboSpan" id="kobo.671.3">We can approach the task in two ways:</span><ul>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.672.1">The “filter” way</span></strong><span class="koboSpan" id="kobo.673.1">: This approach consists </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.674.1">of adding some filters as </span><strong class="keyWord"><span class="koboSpan" id="kobo.675.1">kwargs</span></strong><span class="koboSpan" id="kobo.676.1"> to our retriever, which</span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.677.1"> might be required by the application before responding to the user. </span><span class="koboSpan" id="kobo.677.2">Those questions might be, for example, about the genre of a movie.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.678.1">For example, let’s say</span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.679.1"> we want to provide</span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.680.1"> results featuring only those movies for which the genre is tagged as comedy. </span><span class="koboSpan" id="kobo.680.2">You can achieve this with the following code:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.681.1">df_filtered = md[md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.682.1">'genres'</span></span><span class="koboSpan" id="kobo.683.1">].apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.684.1">lambda</span></span><span class="koboSpan" id="kobo.685.1"> x: </span><span class="hljs-string"><span class="koboSpan" id="kobo.686.1">'Comedy'</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.687.1">in</span></span><span class="koboSpan" id="kobo.688.1"> x)]
qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.689.1">"stuff"</span></span><span class="koboSpan" id="kobo.690.1">,
    retriever=docsearch.as_retriever(search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.691.1">'data'</span></span><span class="koboSpan" id="kobo.692.1">: df_filtered}), return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.693.1">True</span></span><span class="koboSpan" id="kobo.694.1">)
query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.695.1">"I'm looking for a movie with animals and an adventurous plot."</span></span><span class="koboSpan" id="kobo.696.1">
result = qa({</span><span class="hljs-string"><span class="koboSpan" id="kobo.697.1">"query"</span></span><span class="koboSpan" id="kobo.698.1">: query})
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.699.1">The filter can also operate at the metadata level, as shown in the following example, where</span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.700.1"> we want to filter only results with a rating above 7:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.701.1">qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.702.1">"stuff"</span></span><span class="koboSpan" id="kobo.703.1">,
    retriever=docsearch.as_retriever(search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.704.1">'filter'</span></span><span class="koboSpan" id="kobo.705.1">: {weighted_rate__gt:</span><span class="hljs-number"><span class="koboSpan" id="kobo.706.1">7</span></span><span class="koboSpan" id="kobo.707.1">}}), return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.708.1">True</span></span><span class="koboSpan" id="kobo.709.1">)
</span></code></pre>
<ul>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.710.1">The “agentic” way</span></strong><span class="koboSpan" id="kobo.711.1">: This is probably the most</span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.712.1"> innovative way to approach the problem. </span><span class="koboSpan" id="kobo.712.2">Making our chain agentic means converting the retriever to a tool that the agent can leverage if needed, including the additional variables. </span><span class="koboSpan" id="kobo.712.3">By doing so, it would be sufficient for the user to provide their preferences in natural language so that the agent can retrieve the most promising recommendation if needed.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.713.1">Let’s see how to implement this with code, asking specifically for an action movie (thus filtering on the </span><code class="inlineCode"><span class="koboSpan" id="kobo.714.1">genre</span></code><span class="koboSpan" id="kobo.715.1"> variable):</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.716.1">from</span></span><span class="koboSpan" id="kobo.717.1"> langchain.agents.agent_toolkits </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.718.1">import</span></span><span class="koboSpan" id="kobo.719.1"> create_retriever_tool
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.720.1">from</span></span><span class="koboSpan" id="kobo.721.1"> langchain.agents.agent_toolkits </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.722.1">import</span></span><span class="koboSpan" id="kobo.723.1"> create_conversational_retrieval_agent
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.724.1">from</span></span><span class="koboSpan" id="kobo.725.1"> langchain.chat_models </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.726.1">import</span></span><span class="koboSpan" id="kobo.727.1"> ChatOpenAI
llm = ChatOpenAI(temperature = </span><span class="hljs-number"><span class="koboSpan" id="kobo.728.1">0</span></span><span class="koboSpan" id="kobo.729.1">)
retriever = docsearch.as_retriever(return_source_documents = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.730.1">True</span></span><span class="koboSpan" id="kobo.731.1">)
tool = create_retriever_tool(
    retriever,
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.732.1">"movies"</span></span><span class="koboSpan" id="kobo.733.1">,
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.734.1">"Searches and returns recommendations about movies."</span></span><span class="koboSpan" id="kobo.735.1">
)
tools = [tool]
agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.736.1">True</span></span><span class="koboSpan" id="kobo.737.1">)
result = agent_executor({</span><span class="hljs-string"><span class="koboSpan" id="kobo.738.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.739.1">input"</span></span><span class="koboSpan" id="kobo.740.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.741.1">"suggest me some action movies"</span></span><span class="koboSpan" id="kobo.742.1">})
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.743.1">Let’s see a glimpse</span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.744.1"> of the chain of thoughts</span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.745.1"> and the output produced (always based on the four most similar movies according to cosine similarity):</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.746.1">&gt; Entering new AgentExecutor chain...
</span><span class="koboSpan" id="kobo.746.2">Invoking: `movies` with `{'genre': 'action'}`
[Document(page_content='The action continues from [REC], […]
Here are some action movies that you might enjoy:
1. </span><span class="koboSpan" id="kobo.746.3">[REC]² - The action continues from [REC], with a medical officer and a SWAT team sent into a sealed-off apartment to control the situation. </span><span class="koboSpan" id="kobo.746.4">It is a thriller/horror movie.
</span><span class="koboSpan" id="kobo.746.5">2. </span><span class="koboSpan" id="kobo.746.6">The Boondock Saints - Twin brothers Conner and Murphy take swift retribution into their own hands to rid Boston of criminals. </span><span class="koboSpan" id="kobo.746.7">It is an action/thriller/crime movie.
</span><span class="koboSpan" id="kobo.746.8">3. </span><span class="koboSpan" id="kobo.746.9">The Gamers - Four clueless players are sent on a quest to rescue a princess and must navigate dangerous forests, ancient ruins, and more. </span><span class="koboSpan" id="kobo.746.10">It is an action/comedy/thriller/foreign movie.
</span><span class="koboSpan" id="kobo.746.11">4. </span><span class="koboSpan" id="kobo.746.12">Atlas Shrugged Part III: Who is John Galt? </span><span class="koboSpan" id="kobo.746.13">- In a collapsing economy, one man has the answer while others try to control or save him. </span><span class="koboSpan" id="kobo.746.14">It is a drama/science fiction/mystery movie.
</span><span class="koboSpan" id="kobo.746.15">Please note that these recommendations are based on the genre "action" and may vary in terms of availability and personal preferences.
</span><span class="koboSpan" id="kobo.746.16">&gt; Finished chain.
</span></code></pre>
<ol>
<li class="numberedList" value="5"><span class="koboSpan" id="kobo.747.1">Finally, we might also want</span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.748.1"> to make our application</span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.749.1"> more tailored toward its goal of being a recommender system. </span><span class="koboSpan" id="kobo.749.2">To do so, we need to do some prompt engineering.</span></li>
</ol>
<div class="note-one">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.750.1">Note</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.751.1">One of the advantages</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.752.1"> of using LangChain’s pre-built components, such as the RetrievalQA chain, is that they come with a pre-configured, well-curated prompt template. </span><span class="koboSpan" id="kobo.752.2">Before overriding the existing prompt, it’s a good practice to inspect it, so that you can also see which variables (within </span><code class="inlineCode"><span class="koboSpan" id="kobo.753.1">{}</span></code><span class="koboSpan" id="kobo.754.1">) are already expected from the component.</span></p>
</div>
<p class="normal-one"><span class="koboSpan" id="kobo.755.1">To explore the existing prompt, you can run the following code:</span></p>
<pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.756.1">print</span></span><span class="koboSpan" id="kobo.757.1">(qa.combine_documents_chain.llm_chain.prompt.template)
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.758.1">Here is the output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.759.1">Use the following pieces of context to answer the question at the end. </span><span class="koboSpan" id="kobo.759.2">If you don't know the answer, just say that you don't know, don't try to make up an answer.
</span><span class="koboSpan" id="kobo.759.3">{context}
Question: {question}
Helpful Answer:
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.760.1">Let’s say, for example, that we want</span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.761.1"> our system to return</span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.762.1"> three suggestions for each user’s request, with a short description of the plot and the reason why the user might like it. </span><span class="koboSpan" id="kobo.762.2">The following is a sample prompt that could match this goal:</span></p>
<pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.763.1">from</span></span><span class="koboSpan" id="kobo.764.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.765.1">import</span></span><span class="koboSpan" id="kobo.766.1"> PromptTemplate
template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.767.1">"""You are a movie recommender system that help users to find movies that match their preferences.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.768.1">Use the following pieces of context to answer the question at the end.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.769.1">For each question, suggest three movies, with a short description of the plot and the reason why the user migth like it.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.770.1">If you don't know the answer, just say that you don't know, don't try to make up an answer.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.771.1">{context}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.772.1">Question: {question}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.773.1">Your response:"""</span></span><span class="koboSpan" id="kobo.774.1">
 
PROMPT = PromptTemplate(
    template=template, input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.775.1">"context"</span></span><span class="koboSpan" id="kobo.776.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.777.1">"question"</span></span><span class="koboSpan" id="kobo.778.1">])
</span></code></pre>
<ol>
<li class="numberedList" value="6"><span class="koboSpan" id="kobo.779.1">Now we need to pass it into our chain:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.780.1">PROMPT = PromptTemplate(
    template=template, input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.781.1">"context"</span></span><span class="koboSpan" id="kobo.782.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.783.1">"question"</span></span><span class="koboSpan" id="kobo.784.1">])
chain_type_kwargs = {</span><span class="hljs-string"><span class="koboSpan" id="kobo.785.1">"prompt"</span></span><span class="koboSpan" id="kobo.786.1">: PROMPT}
qa = RetrievalQA.from_chain_type(llm=OpenAI(),
    chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.787.1">"stuff"</span></span><span class="koboSpan" id="kobo.788.1">,
    retriever=docsearch.as_retriever(),
    return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.789.1">True</span></span><span class="koboSpan" id="kobo.790.1">,
    chain_type_kwargs=chain_type_kwargs)
query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.791.1">"I'm looking for a funny action movie, any suggestion?"</span></span><span class="koboSpan" id="kobo.792.1">
result = qa({</span><span class="hljs-string"><span class="koboSpan" id="kobo.793.1">'query'</span></span><span class="koboSpan" id="kobo.794.1">:query})
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.795.1">print</span></span><span class="koboSpan" id="kobo.796.1">(result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.797.1">'result'</span></span><span class="koboSpan" id="kobo.798.1">])
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.799.1">The following</span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.800.1"> output is </span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.801.1">obtained:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.802.1">1. </span><span class="koboSpan" id="kobo.802.2">A Good Day to Die Hard: An action-packed comedy directed by John Moore, this movie follows Iconoclastic, take-no-prisoners cop John McClane as he travels to Moscow to help his wayward son Jack. </span><span class="koboSpan" id="kobo.802.3">With the Russian underworld in pursuit, and battling a countdown to war, the two McClanes discover that their opposing methods make them unstoppable heroes.
</span><span class="koboSpan" id="kobo.802.4">2. </span><span class="koboSpan" id="kobo.802.5">The Hidden: An alien is on the run in America and uses the bodies of anyone in its way as a hiding place. </span><span class="koboSpan" id="kobo.802.6">With lots of innocent people dying in the chase, this action-packed horror movie is sure to keep you laughing.
</span><span class="koboSpan" id="kobo.802.7">3. </span><span class="koboSpan" id="kobo.802.8">District B13: Set in the ghettos of Paris in 2010, this action-packed science fiction movie follows an undercover cop and ex-thug as they try to infiltrate a gang in order to defuse a neutron bomb. </span><span class="koboSpan" id="kobo.802.9">A thrilling comedy that will keep you laughing.
</span></code></pre>
<ol>
<li class="numberedList" value="7"><span class="koboSpan" id="kobo.803.1">Another thing that we might</span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.804.1"> want to implement in our prompt is the information gathered with the conversational</span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.805.1"> preliminary questions that we might want to set as a welcome page. </span><span class="koboSpan" id="kobo.805.2">For example, before letting the user input their natural language question, we might want to ask their age, gender, and favorite movie genre. </span><span class="koboSpan" id="kobo.805.3">To do so, we can insert in our prompt a section where we can format the input variables with those shared by the user, and then combine this prompt chunk in the final prompt we are going to pass to the chain. </span><span class="koboSpan" id="kobo.805.4">Below you can find an example (for simplicity, we are going to set the variables without asking the user):
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.806.1">from</span></span><span class="koboSpan" id="kobo.807.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.808.1">import</span></span><span class="koboSpan" id="kobo.809.1"> PromptTemplate
template_prefix = </span><span class="hljs-string"><span class="koboSpan" id="kobo.810.1">"""You are a movie recommender system that help users to find movies that match their preferences.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.811.1">Use the following pieces of context to answer the question at the end.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.812.1">If you don't know the answer, just say that you don't know, don't try to make up an answer.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.813.1">{context}"""</span></span><span class="koboSpan" id="kobo.814.1">
user_info = </span><span class="hljs-string"><span class="koboSpan" id="kobo.815.1">"""This is what we know about the user, and you can use this information to better tune your research:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.816.1">Age: {age}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.817.1">Gender: {gender}"""</span></span><span class="koboSpan" id="kobo.818.1">
template_suffix= </span><span class="hljs-string"><span class="koboSpan" id="kobo.819.1">"""Question: {question}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.820.1">Your response:"""</span></span><span class="koboSpan" id="kobo.821.1">
user_info = user_info.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.822.1">format</span></span><span class="koboSpan" id="kobo.823.1">(age = </span><span class="hljs-number"><span class="koboSpan" id="kobo.824.1">18</span></span><span class="koboSpan" id="kobo.825.1">, gender = </span><span class="hljs-string"><span class="koboSpan" id="kobo.826.1">'female'</span></span><span class="koboSpan" id="kobo.827.1">)
COMBINED_PROMPT = template_prefix +</span><span class="hljs-string"><span class="koboSpan" id="kobo.828.1">'\n'</span></span><span class="koboSpan" id="kobo.829.1">+ user_info +</span><span class="hljs-string"><span class="koboSpan" id="kobo.830.1">'\n'</span></span><span class="koboSpan" id="kobo.831.1">+ template_suffix
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.832.1">print</span></span><span class="koboSpan" id="kobo.833.1">(COMBINED_PROMPT)
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.834.1">Here is</span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.835.1"> the </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.836.1">output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.837.1">You are a movie recommender system that help users to find movies that match their preferences.
</span><span class="koboSpan" id="kobo.837.2">Use the following pieces of context to answer the question at the end.
</span><span class="koboSpan" id="kobo.837.3">If you don't know the answer, just say that you don't know, don't try to make up an answer.
</span><span class="koboSpan" id="kobo.837.4">{context}
This is what we know about the user, and you can use this information to better tune your research:
Age: 18
Gender: female
Question: {question}
Your response:
</span></code></pre>
<ol>
<li class="numberedList" value="8"><span class="koboSpan" id="kobo.838.1">Now let’s format the prompt and pass it into our chain:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.839.1">PROMPT = PromptTemplate(
    template=COMBINED_PROMPT, input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.840.1">"context"</span></span><span class="koboSpan" id="kobo.841.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.842.1">"question"</span></span><span class="koboSpan" id="kobo.843.1">])
chain_type_kwargs = {</span><span class="hljs-string"><span class="koboSpan" id="kobo.844.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.845.1">prompt"</span></span><span class="koboSpan" id="kobo.846.1">: PROMPT}
qa = RetrievalQA.from_chain_type(llm=OpenAI(),
    chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.847.1">"stuff"</span></span><span class="koboSpan" id="kobo.848.1">,
    retriever=docsearch.as_retriever(),
    return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.849.1">True</span></span><span class="koboSpan" id="kobo.850.1">,
    chain_type_kwargs=chain_type_kwargs)
result = qa({</span><span class="hljs-string"><span class="koboSpan" id="kobo.851.1">'query'</span></span><span class="koboSpan" id="kobo.852.1">:query})
result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.853.1">'result'</span></span><span class="koboSpan" id="kobo.854.1">]
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.855.1">We receive the following output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.856.1">' Sure, I can suggest some action movies for you. </span><span class="koboSpan" id="kobo.856.2">Here are a few examples: A Good Day to Die Hard, Goldfinger, Ong Bak 2, and The Raid 2. </span><span class="koboSpan" id="kobo.856.3">All of these movies have high ratings and feature thrilling action elements. </span><span class="koboSpan" id="kobo.856.4">I hope you find something that you enjoy!'
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.857.1">As you can see, the system considered</span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.858.1"> the user’s information</span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.859.1"> provided. </span><span class="koboSpan" id="kobo.859.2">When we build the front-end of MovieHarbor, we will make this information dynamic as preliminary questions proposed to the user.</span></p>
<h2 class="heading-2" id="_idParaDest-107"><span class="koboSpan" id="kobo.860.1">Building a content-based system</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.861.1">In the previous section, we covered </span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.862.1">the cold-start scenario where the system knew nothing about the user. </span><span class="koboSpan" id="kobo.862.2">Sometimes, recommender systems already have some backstory about users, and it is extremely useful to embed this knowledge in our application. </span><span class="koboSpan" id="kobo.862.3">Let’s imagine, for example, that we have a users database where the system has stored all the registered user’s information (such as age, gender, country, etc.) as well as the movies the user has already watched alongside their rating.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.863.1">To do so, we will need to set a custom prompt that is able to retrieve this information from a source. </span><span class="koboSpan" id="kobo.863.2">For simplicity, we will create a sample dataset with users’ information with just two records, corresponding to two users. </span><span class="koboSpan" id="kobo.863.3">Each user will exhibit the following variables: username, age, gender, and a dictionary containing movies already watched alongside with the rating they gave to them.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.864.1">The high-level architecture is represented by the following diagram:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.865.1"><img alt="A diagram of a computer flowchart  Description automatically generated" src="../Images/B21714_07_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.866.1">Figure 7.3: High-level architecture of a content-based recommendation system</span></p>
<p class="normal"><span class="koboSpan" id="kobo.867.1">Let’s break down this architecture</span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.868.1"> and examine each step to build the final chat for this content-based system, starting from the available users’ data:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.869.1">As discussed earlier, we now have a bit of information about our users’ preferences. </span><span class="koboSpan" id="kobo.869.2">More specifically, imagine we have a dataset containing users’ attributes (name, age, gender) along with their reviews (a score from 1 to 10) of some movies. </span><span class="koboSpan" id="kobo.869.3">The following is the code used to create the dataset:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.870.1">import</span></span><span class="koboSpan" id="kobo.871.1"> pandas </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.872.1">as</span></span><span class="koboSpan" id="kobo.873.1"> pd
data = {
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.874.1">"username"</span></span><span class="koboSpan" id="kobo.875.1">: [</span><span class="hljs-string"><span class="koboSpan" id="kobo.876.1">"Alice"</span></span><span class="koboSpan" id="kobo.877.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.878.1">"Bob"</span></span><span class="koboSpan" id="kobo.879.1">],
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.880.1">"age"</span></span><span class="koboSpan" id="kobo.881.1">: [</span><span class="hljs-number"><span class="koboSpan" id="kobo.882.1">25</span></span><span class="koboSpan" id="kobo.883.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.884.1">32</span></span><span class="koboSpan" id="kobo.885.1">],
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.886.1">"gender"</span></span><span class="koboSpan" id="kobo.887.1">: [</span><span class="hljs-string"><span class="koboSpan" id="kobo.888.1">"F"</span></span><span class="koboSpan" id="kobo.889.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.890.1">"M"</span></span><span class="koboSpan" id="kobo.891.1">],
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.892.1">"movies"</span></span><span class="koboSpan" id="kobo.893.1">: [
        [(</span><span class="hljs-string"><span class="koboSpan" id="kobo.894.1">"Transformers: The Last Knight"</span></span><span class="koboSpan" id="kobo.895.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.896.1">7</span></span><span class="koboSpan" id="kobo.897.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.898.1">"Pokémon: Spell of the Unknown"</span></span><span class="koboSpan" id="kobo.899.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.900.1">5</span></span><span class="koboSpan" id="kobo.901.1">)],
        [(</span><span class="hljs-string"><span class="koboSpan" id="kobo.902.1">"Bon Cop Bad Cop 2"</span></span><span class="koboSpan" id="kobo.903.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.904.1">8</span></span><span class="koboSpan" id="kobo.905.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.906.1">"Goon: Last of the Enforcers"</span></span><span class="koboSpan" id="kobo.907.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.908.1">9</span></span><span class="koboSpan" id="kobo.909.1">)]
    ]
}
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.910.1"># Convert the "movies" column into dictionaries</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.911.1">for</span></span><span class="koboSpan" id="kobo.912.1"> i, row_movies </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.913.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.914.1">enumerate</span></span><span class="koboSpan" id="kobo.915.1">(data[</span><span class="hljs-string"><span class="koboSpan" id="kobo.916.1">"movies"</span></span><span class="koboSpan" id="kobo.917.1">]):
    movie_dict = {}
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.918.1">for</span></span><span class="koboSpan" id="kobo.919.1"> movie, rating </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.920.1">in</span></span><span class="koboSpan" id="kobo.921.1"> row_movies:
        movie_dict[movie] = rating
    data[</span><span class="hljs-string"><span class="koboSpan" id="kobo.922.1">"movies"</span></span><span class="koboSpan" id="kobo.923.1">][i] = movie_dict
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.924.1"># Create a pandas DataFrame</span></span><span class="koboSpan" id="kobo.925.1">
df = pd.DataFrame(data)
df.head()
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.926.1">The following output is obtained:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.927.1"><img alt="A black and white screen with white text  Description automatically generated" src="../Images/B21714_07_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.928.1">Figure 7.4: Sample users dataset</span></p>
<ol>
<li class="numberedList" value="2"><span class="koboSpan" id="kobo.929.1">What we want to do now is apply</span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.930.1"> the same logic of the prompt of the cold start with the formatting with variables. </span><span class="koboSpan" id="kobo.930.2">The difference here is that, rather than asking the user to provide the values for those variables, we will directly collect them from our user dataset. </span><span class="koboSpan" id="kobo.930.3">So, we first define our prompt chunks:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.931.1">template_prefix = </span><span class="hljs-string"><span class="koboSpan" id="kobo.932.1">"""You are a movie recommender system that help users to find movies that match their preferences.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.933.1">Use the following pieces of context to answer the question at the end.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.934.1">If you don't know the answer, just say that you don't know, don't try to make up an answer.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.935.1">{context}"""</span></span><span class="koboSpan" id="kobo.936.1">
user_info = </span><span class="hljs-string"><span class="koboSpan" id="kobo.937.1">"""This is what we know about the user, and you can use this information to better tune your research:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.938.1">Age: {age}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.939.1">Gender: {gender}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.940.1">Movies already seen alongside with rating: {movies}"""</span></span><span class="koboSpan" id="kobo.941.1">
template_suffix= </span><span class="hljs-string"><span class="koboSpan" id="kobo.942.1">"""Question: {question}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.943.1">Your response:"""</span></span>
</code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.944.1">We then format the </span><code class="inlineCode"><span class="koboSpan" id="kobo.945.1">user_info</span></code><span class="koboSpan" id="kobo.946.1"> chunk</span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.947.1"> as follows (assuming that the user interacting with the system is </span><code class="inlineCode"><span class="koboSpan" id="kobo.948.1">Alice</span></code><span class="koboSpan" id="kobo.949.1">):
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.950.1">age = df.loc[df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.951.1">'username'</span></span><span class="koboSpan" id="kobo.952.1">]==</span><span class="hljs-string"><span class="koboSpan" id="kobo.953.1">'Alice'</span></span><span class="koboSpan" id="kobo.954.1">][</span><span class="hljs-string"><span class="koboSpan" id="kobo.955.1">'age'</span></span><span class="koboSpan" id="kobo.956.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.957.1">0</span></span><span class="koboSpan" id="kobo.958.1">]
gender = df.loc[df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.959.1">'username'</span></span><span class="koboSpan" id="kobo.960.1">]==</span><span class="hljs-string"><span class="koboSpan" id="kobo.961.1">'Alice'</span></span><span class="koboSpan" id="kobo.962.1">][</span><span class="hljs-string"><span class="koboSpan" id="kobo.963.1">'gender'</span></span><span class="koboSpan" id="kobo.964.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.965.1">0</span></span><span class="koboSpan" id="kobo.966.1">]
movies = </span><span class="hljs-string"><span class="koboSpan" id="kobo.967.1">''</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.968.1"># Iterate over the dictionary and output movie name and rating</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.969.1">for</span></span><span class="koboSpan" id="kobo.970.1"> movie, rating </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.971.1">in</span></span><span class="koboSpan" id="kobo.972.1"> df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.973.1">'movies'</span></span><span class="koboSpan" id="kobo.974.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.975.1">0</span></span><span class="koboSpan" id="kobo.976.1">].items():
    output_string = </span><span class="hljs-string"><span class="koboSpan" id="kobo.977.1">f"Movie: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.978.1">{movie}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.979.1">, Rating: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.980.1">{rating}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.981.1">"</span></span><span class="koboSpan" id="kobo.982.1"> + </span><span class="hljs-string"><span class="koboSpan" id="kobo.983.1">"\n"</span></span><span class="koboSpan" id="kobo.984.1">
    movies+=output_string
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.985.1">#print(output_string)</span></span><span class="koboSpan" id="kobo.986.1">
user_info = user_info.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.987.1">format</span></span><span class="koboSpan" id="kobo.988.1">(age = age, gender = gender, movies = movies)
COMBINED_PROMPT = template_prefix +</span><span class="hljs-string"><span class="koboSpan" id="kobo.989.1">'\n'</span></span><span class="koboSpan" id="kobo.990.1">+ user_info +</span><span class="hljs-string"><span class="koboSpan" id="kobo.991.1">'\n'</span></span><span class="koboSpan" id="kobo.992.1">+ template_suffix
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.993.1">print</span></span><span class="koboSpan" id="kobo.994.1">(COMBINED_PROMPT)
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.995.1">Here is the output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.996.1">You are a movie recommender system that help users to find movies that match their preferences.
</span><span class="koboSpan" id="kobo.996.2">Use the following pieces of context to answer the question at the end.
</span><span class="koboSpan" id="kobo.996.3">If you don't know the answer, just say that you don't know, don't try to make up an answer.
</span><span class="koboSpan" id="kobo.996.4">{context}
This is what we know about the user, and you can use this information to better tune your research:
Age: 25
Gender: F
Movies already seen alongside with rating: Movie: Transformers: The Last Knight, Rating: 7
Movie: Pokémon: Spell of the Unknown, Rating: 5
Question: {question}
Your response:
</span></code></pre>
<ol>
<li class="numberedList" value="4"><span class="koboSpan" id="kobo.997.1">Let’s now use this prompt</span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.998.1"> within our chain:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.999.1">PROMPT = PromptTemplate(
    template=COMBINED_PROMPT, input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1000.1">"context"</span></span><span class="koboSpan" id="kobo.1001.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1002.1">"question"</span></span><span class="koboSpan" id="kobo.1003.1">])
chain_type_kwargs = {</span><span class="hljs-string"><span class="koboSpan" id="kobo.1004.1">"prompt"</span></span><span class="koboSpan" id="kobo.1005.1">: PROMPT}
qa = RetrievalQA.from_chain_type(llm=OpenAI(),
    chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1006.1">"stuff"</span></span><span class="koboSpan" id="kobo.1007.1">,
    retriever=docsearch.as_retriever(),
    return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1008.1">True</span></span><span class="koboSpan" id="kobo.1009.1">,
    chain_type_kwargs=chain_type_kwargs)
query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1010.1">"Can you suggest me some action movie based on my background?"</span></span><span class="koboSpan" id="kobo.1011.1">
result = qa({</span><span class="hljs-string"><span class="koboSpan" id="kobo.1012.1">'query'</span></span><span class="koboSpan" id="kobo.1013.1">:query})
result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1014.1">'result'</span></span><span class="koboSpan" id="kobo.1015.1">]
</span></code></pre>
</li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.1016.1">We then obtain the following output:</span></p>
<pre class="programlisting con-one"><code class="hljs-con"><span class="koboSpan" id="kobo.1017.1">" Based on your age, gender, and the movies you've already seen, I would suggest the following action movies: The Raid 2 (Action, Crime, Thriller; Rating: 6.71), Ong Bak 2 (Adventure, Action, Thriller; Rating: 5.24), Hitman: Agent 47 (Action, Crime, Thriller; Rating: 5.37), and Kingsman: The Secret Service (Crime, Comedy, Action, Adventure; Rating: 7.43)."
</span><span class="koboSpan" id="kobo.1017.2">'
</span></code></pre>
<p class="normal-one"><span class="koboSpan" id="kobo.1018.1">As you can see, the model is now able to recommend a list of movies to Alice based on the user’s information about past preferences, retrieved as context within the model’s metaprompt.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1019.1">Note that, in this scenario, we used as dataset a simple pandas dataframe. </span><span class="koboSpan" id="kobo.1019.2">In production scenarios, a best practice for storing variables related to a task to be addressed (such as a recommendation task) is that of using a feature store. </span><span class="koboSpan" id="kobo.1019.3">Feature stores are data systems that are designed to support machine learning workflows. </span><span class="koboSpan" id="kobo.1019.4">They allow data teams to store, manage, and access features</span><a id="_idIndexMarker561"/><span class="koboSpan" id="kobo.1020.1"> that are used for training and deploying machine learning models.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1021.1">Furthermore, LangChain offers native integrations towards some of the most popular features stores:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1022.1">Feast:</span></strong><span class="koboSpan" id="kobo.1023.1"> This is an open-source feature</span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.1024.1"> store for machine learning. </span><span class="koboSpan" id="kobo.1024.2">It allows teams to define, manage, discover, and serve features. </span><span class="koboSpan" id="kobo.1024.3">Feast supports batch and streaming data sources and integrates with various data processing and storage systems. </span><span class="koboSpan" id="kobo.1024.4">Feast uses BigQuery for offline features and BigTable or Redis for online features.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1025.1">Tecton: </span></strong><span class="koboSpan" id="kobo.1026.1">This is a managed feature</span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.1027.1"> platform that provides a complete solution for building, deploying, and using features for machine learning. </span><span class="koboSpan" id="kobo.1027.2">Tecton allows users to define features in code, version control them, and deploy them to production with best practices. </span><span class="koboSpan" id="kobo.1027.3">Furthermore, it integrates with existing data infrastructure and ML platforms like SageMaker and Kubeflow, and it uses Spark for feature transformations and DynamoDB for online feature serving.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1028.1">Featureform: </span></strong><span class="koboSpan" id="kobo.1029.1">This is a virtual feature</span><a id="_idIndexMarker564"/><span class="koboSpan" id="kobo.1030.1"> store that transforms existing data infrastructure into a feature store. </span><span class="koboSpan" id="kobo.1030.2">Featureform allows users to create, store, and access features using standard feature definitions and a Python SDK. </span><span class="koboSpan" id="kobo.1030.3">It orchestrates and manages the data pipelines required for feature engineering and materialization, and it is compatible with a wide range of data systems, such as Snowflake, Redis, Spark, and Cassandra.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1031.1">AzureML Managed Feature Store: </span></strong><span class="koboSpan" id="kobo.1032.1">This is a new type of workspace</span><a id="_idIndexMarker565"/><span class="koboSpan" id="kobo.1033.1"> that lets users discover, create, and operationalize features. </span><span class="koboSpan" id="kobo.1033.2">This service integrates with existing data stores, feature pipelines, and ML platforms like Azure Databricks and Kubeflow. </span><span class="koboSpan" id="kobo.1033.3">Plus, it uses SQL, PySpark, SnowPark, or Python for feature transformations and Parquet/S3 or Cosmos DB for feature storage.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1034.1">You can read more</span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.1035.1"> about LangChain’s integration with features at </span><a href="https://blog.langchain.dev/feature-stores-and-llms/"><span class="url"><span class="koboSpan" id="kobo.1036.1">https://blog.langchain.dev/feature-stores-and-llms/</span></span></a><span class="koboSpan" id="kobo.1037.1">.</span></p>
<h1 class="heading-1" id="_idParaDest-108"><span class="koboSpan" id="kobo.1038.1">Developing the front-end with Streamlit</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1039.1">Now that we have seen the logic</span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.1040.1"> behind an LLM-powered recommendation</span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.1041.1"> system, it is time to give a GUI to our MovieHarbor. </span><span class="koboSpan" id="kobo.1041.2">To do so, we will once again leverage Streamlit, and we will assume the cold-start scenario. </span><span class="koboSpan" id="kobo.1041.3">As always, you can find the whole Python code in the GitHub book repository at </span><a href="Chapter_07.xhtml"><span class="url"><span class="koboSpan" id="kobo.1042.1">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</span></span></a><span class="koboSpan" id="kobo.1043.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1044.1">As per the Globebotter application in </span><em class="chapterRef"><span class="koboSpan" id="kobo.1045.1">Chapter 6</span></em><span class="koboSpan" id="kobo.1046.1">, in this case also you need to create a </span><code class="inlineCode"><span class="koboSpan" id="kobo.1047.1">.py</span></code><span class="koboSpan" id="kobo.1048.1"> file to run in your terminal via </span><code class="inlineCode"><span class="koboSpan" id="kobo.1049.1">streamlit run file.py</span></code><span class="koboSpan" id="kobo.1050.1">. </span><span class="koboSpan" id="kobo.1050.2">In our case, the file will be named </span><code class="inlineCode"><span class="koboSpan" id="kobo.1051.1">movieharbor.py</span></code><span class="koboSpan" id="kobo.1052.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1053.1">Let’s now summarize the key steps to build the app with the front-end:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1054.1">Configure the application webpage:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1055.1">import</span></span><span class="koboSpan" id="kobo.1056.1"> streamlit </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1057.1">as</span></span><span class="koboSpan" id="kobo.1058.1"> st
st.set_page_config(page_title=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1059.1">"GlobeBotter"</span></span><span class="koboSpan" id="kobo.1060.1">, page_icon=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1061.1">"</span></span><span class="koboSpan" id="kobo.1062.1"><img alt="" role="presentation" src="../Images/Icon.png"/></span><span class="hljs-string"><span class="koboSpan" id="kobo.1063.1">"</span></span><span class="koboSpan" id="kobo.1064.1">)
st.header(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1065.1">'</span></span><span class="koboSpan" id="kobo.1066.1"><img alt="" role="presentation" src="../Images/Icon.png"/></span><span class="hljs-string"><span class="koboSpan" id="kobo.1067.1"> Welcome to MovieHarbor, your favourite movie recommender'</span></span><span class="koboSpan" id="kobo.1068.1">)
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.1069.1">Import the credentials and establish the connection to LanceDB:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.1070.1">load_dotenv()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1071.1">#os.environ["HUGGINGFACEHUB_API_TOKEN"]</span></span><span class="koboSpan" id="kobo.1072.1">
openai_api_key = os.environ[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1073.1">'OPENAI_API_KEY'</span></span><span class="koboSpan" id="kobo.1074.1">]
embeddings = OpenAIEmbeddings()
uri = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1075.1">"data/sample-lancedb"</span></span><span class="koboSpan" id="kobo.1076.1">
db = lancedb.connect(uri)
table = db.open_table(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1077.1">'movies'</span></span><span class="koboSpan" id="kobo.1078.1">)
docsearch = LanceDB(connection = table, embedding = embeddings)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1079.1"># Import the movie dataset</span></span><span class="koboSpan" id="kobo.1080.1">
md = pd.read_pickle(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1081.1">'movies.pkl'</span></span><span class="koboSpan" id="kobo.1082.1">)
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.1083.1">Create some widgets for the user to define their features and movies preferences:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1084.1"># Create a sidebar for user input</span></span><span class="koboSpan" id="kobo.1085.1">
st.sidebar.title(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1086.1">"Movie Recommendation System"</span></span><span class="koboSpan" id="kobo.1087.1">)
st.sidebar.markdown(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1088.1">"Please enter your details and preferences below:"</span></span><span class="koboSpan" id="kobo.1089.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1090.1"># Ask the user for age, gender and favourite movie genre</span></span><span class="koboSpan" id="kobo.1091.1">
age = st.sidebar.slider(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1092.1">"What is your age?"</span></span><span class="koboSpan" id="kobo.1093.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1094.1">1</span></span><span class="koboSpan" id="kobo.1095.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1096.1">100</span></span><span class="koboSpan" id="kobo.1097.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1098.1">25</span></span><span class="koboSpan" id="kobo.1099.1">)
gender = st.sidebar.radio(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1100.1">"What is your gender?"</span></span><span class="koboSpan" id="kobo.1101.1">, (</span><span class="hljs-string"><span class="koboSpan" id="kobo.1102.1">"Male"</span></span><span class="koboSpan" id="kobo.1103.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1104.1">"Female"</span></span><span class="koboSpan" id="kobo.1105.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1106.1">"Other"</span></span><span class="koboSpan" id="kobo.1107.1">))
genre = st.sidebar.selectbox(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1108.1">"What is your favourite movie genre?"</span></span><span class="koboSpan" id="kobo.1109.1">, md.explode(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1110.1">'genres'</span></span><span class="koboSpan" id="kobo.1111.1">)[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1112.1">"genres"</span></span><span class="koboSpan" id="kobo.1113.1">].unique())
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1114.1"># Filter the movies based on the user input</span></span><span class="koboSpan" id="kobo.1115.1">
df_filtered = md[md[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1116.1">'genres'</span></span><span class="koboSpan" id="kobo.1117.1">].apply(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1118.1">lambda</span></span><span class="koboSpan" id="kobo.1119.1"> x: genre </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1120.1">in</span></span><span class="koboSpan" id="kobo.1121.1"> x)]
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.1122.1">Define the</span><a id="_idIndexMarker569"/><span class="koboSpan" id="kobo.1123.1"> parametrized</span><a id="_idIndexMarker570"/><span class="koboSpan" id="kobo.1124.1"> prompt chunks:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.1125.1">template_prefix = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1126.1">"""You are a movie recommender system that help users to find movies that match their preferences.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1127.1">Use the following pieces of context to answer the question at the end.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1128.1">If you don't know the answer, just say that you don't know, don't try to make up an answer.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1129.1">{context}"""</span></span><span class="koboSpan" id="kobo.1130.1">
user_info = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1131.1">"""This is what we know about the user, and you can use this information to better tune your research:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1132.1">Age: {age}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1133.1">Gender: {gender}"""</span></span><span class="koboSpan" id="kobo.1134.1">
template_suffix= </span><span class="hljs-string"><span class="koboSpan" id="kobo.1135.1">"""Question: {question}</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1136.1">Your response:"""</span></span><span class="koboSpan" id="kobo.1137.1">
user_info = user_info.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1138.1">format</span></span><span class="koboSpan" id="kobo.1139.1">(age = age, gender = gender)
COMBINED_PROMPT = template_prefix +</span><span class="hljs-string"><span class="koboSpan" id="kobo.1140.1">'\n'</span></span><span class="koboSpan" id="kobo.1141.1">+ user_info +</span><span class="hljs-string"><span class="koboSpan" id="kobo.1142.1">'\n'</span></span><span class="koboSpan" id="kobo.1143.1">+ template_suffix
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1144.1">print</span></span><span class="koboSpan" id="kobo.1145.1">(COMBINED_PROMPT)
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.1146.1">Set up the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1147.1">RetrievalQA</span></code><span class="koboSpan" id="kobo.1148.1"> chain:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1149.1">#setting up the chain</span></span><span class="koboSpan" id="kobo.1150.1">
qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1151.1">"stuff"</span></span><span class="koboSpan" id="kobo.1152.1">,
    retriever=docsearch.as_retriever(search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1153.1">'data'</span></span><span class="koboSpan" id="kobo.1154.1">: df_filtered}), return_source_documents=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1155.1">True</span></span><span class="koboSpan" id="kobo.1156.1">)
</span></code></pre>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.1157.1">Insert the search bar for the user:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.1158.1">query = st.text_input(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1159.1">'Enter your question:'</span></span><span class="koboSpan" id="kobo.1160.1">, placeholder = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1161.1">'What action movies do you suggest?'</span></span><span class="koboSpan" id="kobo.1162.1">)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1163.1">if</span></span><span class="koboSpan" id="kobo.1164.1"> query:
    result = qa({</span><span class="hljs-string"><span class="koboSpan" id="kobo.1165.1">"query"</span></span><span class="koboSpan" id="kobo.1166.1">: query})
    st.write(result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1167.1">'result'</span></span><span class="koboSpan" id="kobo.1168.1">])
</span></code></pre>
</li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1169.1">And that’s it! </span><span class="koboSpan" id="kobo.1169.2">You can run the final result in your terminal with </span><code class="inlineCode"><span class="koboSpan" id="kobo.1170.1">streamlit run movieharbor.py</span></code><span class="koboSpan" id="kobo.1171.1">. </span><span class="koboSpan" id="kobo.1171.2">It looks like the following:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1172.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B21714_07_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1173.1">Figure 7.5: Sample front-end for Movieharbor with Streamlit</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1174.1">So, you can see, in just few lines</span><a id="_idIndexMarker571"/><span class="koboSpan" id="kobo.1175.1"> of code we were able</span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.1176.1"> to set up a webapp for our MovieHarbor. </span><span class="koboSpan" id="kobo.1176.2">Starting from this template, you can customize your layout with Streamlit’s components, as well as tailor it to content-based scenarios. </span><span class="koboSpan" id="kobo.1176.3">Plus, you can customize your prompts in such a way that the recommender acts as you prefer.</span></p>
<h1 class="heading-1" id="_idParaDest-109"><span class="koboSpan" id="kobo.1177.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1178.1">In this chapter, we explored how LLMs could change the way we approach a recommendation system task. </span><span class="koboSpan" id="kobo.1178.2">We started from the analysis of the current strategies and algorithms for building recommendation applications, differentiating between various scenarios (collaborative filtering, content-based, cold start, etc.) as well as different techniques (KNN, matrix factorization, and NNs).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1179.1">We then moved to the new, emerging field of research into how to apply the power of LLMs to this field, and explored the various experiments that have been done in recent months.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1180.1">Leveraging this knowledge, we built a movie recommender application powered by LLMs, using LangChain as the AI orchestrator and Streamlit as the front-end, showing how LLMs can revolutionize this field thanks to their reasoning capabilities as well as their generalization. </span><span class="koboSpan" id="kobo.1180.2">This was just one example of how LLMs not only can open new frontiers, but can also enhance existing fields of research.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1181.1">In the next chapter, we will see what these powerful models can do when working with structured data.</span></p>
<h1 class="heading-1" id="_idParaDest-110"><span class="koboSpan" id="kobo.1182.1">References</span></h1>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1183.1">Recommendation as Language Processing</span></strong><span class="koboSpan" id="kobo.1184.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1185.1">RLP</span></strong><span class="koboSpan" id="kobo.1186.1">): A Unified </span><strong class="keyWord"><span class="koboSpan" id="kobo.1187.1">Pretrain, Personalized Prompt &amp; Predict Paradigm</span></strong><span class="koboSpan" id="kobo.1188.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1189.1">P5</span></strong><span class="koboSpan" id="kobo.1190.1">). </span><a href="https://arxiv.org/abs/2203.13366"><span class="url"><span class="koboSpan" id="kobo.1191.1">https://arxiv.org/abs/2203.13366</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1192.1">LangChain’s blog about featurestores. </span><a href="https://blog.langchain.dev/feature-stores-and-llms/"><span class="url"><span class="koboSpan" id="kobo.1193.1">https://blog.langchain.dev/feature-stores-and-llms/</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1194.1">Feast. </span><a href="https://docs.feast.dev/"><span class="url"><span class="koboSpan" id="kobo.1195.1">https://docs.feast.dev/</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1196.1">Tecton. </span><a href="https://www.tecton.ai/"><span class="url"><span class="koboSpan" id="kobo.1197.1">https://www.tecton.ai/</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1198.1">FeatureForm. </span><a href="https://www.featureform.com/"><span class="url"><span class="koboSpan" id="kobo.1199.1">https://www.featureform.com/</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1200.1">Azure Machine Learning feature store. </span><a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-what-is-managed-feature-store?view=azureml-api-2"><span class="url"><span class="koboSpan" id="kobo.1201.1">https://learn.microsoft.com/en-us/azure/machine-learning/concept-what-is-managed-feature-store?view=azureml-api-2</span></span></a></li>
</ul>
<h1 class="heading-1"><span class="koboSpan" id="kobo.1202.1">Join our community on Discord</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1203.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
<p class="normal"><a href="https://packt.link/llm "><span class="url"><span class="koboSpan" id="kobo.1204.1">https://packt.link/llm</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.1205.1"><img alt="" role="presentation" src="../Images/QR_Code214329708533108046.png"/></span></p>
</div>
</body></html>