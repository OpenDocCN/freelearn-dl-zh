["```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\"\n).to(\"cuda:0\")\n# generate an image\nprompt =\"high resolution, a photograph of an astronaut riding a horse\"\nimage = text2img_pipe(\n    prompt = prompt,\n    generator = torch.Generator(\"cuda:0\").manual_seed(1)\n).images[0]\nimage\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype = torch.bfloat16 # <- load float16 version weight\n).to(\"cuda:0\")\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype = torch.float16       # <- load float16 version weight\n).to(\"cuda:0\")\ntext2img_pipe.enable_vae_tiling()       # < Enable VAE Tiling\nprompt =\"high resolution, a photograph of an astronaut riding a horse\"\nimage = text2img_pipe(\n    prompt = prompt,\n    generator = torch.Generator(\"cuda:0\").manual_seed(1),\n    width = 1024,\n    height= 1024\n).images[0]\nimage\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype = torch.float16       # <- load float16 version weight\n).to(\"cuda:0\")\ntext2img_pipe.enable_xformers_memory_efficient_attention()  # < Enable \n# xformers\nprompt =\"high resolution, a photograph of an astronaut riding a horse\"\nimage = text2img_pipe(\n    prompt = prompt,\n    generator = torch.Generator(\"cuda:0\").manual_seed(1)\n).images[0]\nimage\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype = torch.float16\n).to(\"cuda:0\")\n# generate an image\ntext2img_pipe.enable_sequential_cpu_offload() # <- Enable sequential \n# CPU offload\nprompt =\"high resolution, a photograph of an astronaut riding a horse\"\nimage = text2img_pipe(\n    prompt = prompt,\n    generator = torch.Generator(\"cuda:0\").manual_seed(1)\n).images[0]\nimage\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype = torch.float16\n)                 # .to(\"cuda\") is removed here\n# generate an image\ntext2img_pipe.enable_model_cpu_offload()    # <- enable model offload\nprompt =\"high resolution, a photograph of an astronaut riding a horse\"\nimage = text2img_pipe(\n    prompt = prompt,\n    generator = torch.Generator(\"cuda:0\").manual_seed(1)\n).images[0]\nimage\n```", "```py\npipe.to(\"cpu\")\ntorch.cuda.empty_cache()\n```", "```py\npip install tomesd\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\nimport tomesd\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype = torch.float16\n).to(\"cuda:0\")\ntomesd.apply_patch(text2img_pipe, ratio=0.5)\n# generate an image\nprompt =\"high resolution, a photograph of an astronaut riding a horse\"\nimage = text2img_pipe(\n    prompt = prompt,\n    generator = torch.Generator(\"cuda:0\").manual_seed(1)\n).images[0]\nimage\n```"]