- en: '*Chapter 14*: Line-Following with a Camera in Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第14章*：使用Python进行相机线跟踪'
- en: In the last chapter, we saw how to use a camera to follow and track objects.
    In this chapter, we will be extending the camera code to create line-sensing behavior.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用相机来追踪和跟踪物体。在本章中，我们将扩展相机代码以创建线感应行为。
- en: We will look at where robots use line following and how it is useful. We will
    also learn about some of the different approaches taken to following paths in
    different robots, along with their trade-offs. You will see how to build a simple
    line-following track.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨机器人使用线跟踪的地方以及它的有用性。我们还将了解不同机器人中跟踪路径的不同方法，以及它们的权衡。你将看到如何构建一个简单的线跟踪轨道。
- en: We will learn about some different algorithms to use and then choose a simple
    one. We will make a data flow diagram to see how it works, collect sample images
    to test it with, and then tune its performance based on the sample images. Along
    the way, we'll see more ways to approach computer vision and extract useful data
    from it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将了解一些不同的算法来使用，然后选择一个简单的算法。我们将制作一个数据流图来查看其工作原理，收集样本图像进行测试，并根据样本图像调整其性能。在这个过程中，我们将看到更多处理计算机视觉和从中提取有用数据的方法。
- en: We will enhance our PID code, build our line detection algorithm into robot
    driving behavior, and see the robot running with this. The chapter closes with
    ideas on how you can take this further.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将增强我们的PID代码，将我们的线检测算法集成到机器人驾驶行为中，并看到机器人使用这种方式运行。本章结束时，我们将讨论如何进一步发展这一想法。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introduction to line following
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线跟踪简介
- en: Making a line-follower test track
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作线跟踪测试轨道
- en: A line-following computer vision pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线跟踪计算机视觉流程
- en: Trying computer vision with test images
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用测试图像尝试计算机视觉
- en: Line following with the PID algorithm
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PID算法进行线跟踪
- en: Finding a line again
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次找到线条
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要以下物品：
- en: The robot and code from [*Chapter 13*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283),
    *Robot Vision – Using a Pi Camera and OpenCV*
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人及其代码来自[*第13章*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283)，*机器人视觉 –
    使用Pi相机和OpenCV*
- en: Some white or some black insulating tape
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些白色或黑色绝缘胶带
- en: Some A2 paper or boards – the opposite color to the insulating tape
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些A2纸或板子 – 与绝缘胶带相反的颜色
- en: A pair of scissors
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一把剪刀
- en: Good lighting
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 良好的照明
- en: The code for this section can be found at [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter14](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter14).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本节代码可在[https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter14](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter14)找到。
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/3slLzbQ](https://bit.ly/3slLzbQ)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际应用：[https://bit.ly/3slLzbQ](https://bit.ly/3slLzbQ)
- en: Introduction to line following
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线跟踪简介
- en: Before we start building code, let's find out about line-following robot behaviors,
    where and how systems use them, and the different techniques for doing so.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始编写代码之前，让我们了解一下线跟踪机器人的行为，这些系统在哪里以及如何使用它们，以及不同的实现技术。
- en: What is line following?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是线跟踪？
- en: Some robots are required to stay on specific paths within their tasks. It is
    simpler for a robot to navigate a line than to plan and map whole rooms or buildings.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器人需要在任务中保持特定的路径。对于机器人来说，导航线条比规划整个房间或建筑物的地图要简单。
- en: In simple terms, line following is being able to follow a marked path autonomously.
    These can be visual markers, such as blue tape or a white line on a black road.
    As the robot drives along the line, it will continually be looking for where the
    line ahead is and correcting its course to follow that line.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，线跟踪是指能够自主地跟随标记路径。这些可以是视觉标记，例如蓝色胶带或黑色道路上的一条白色线条。当机器人沿着线条行驶时，它将不断寻找前方线条的位置，并纠正航向以跟随该线条。
- en: In robot competitions, racing on lines is a common challenge, with speed being
    critical after accuracy.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器人竞赛中，沿着线条进行比赛是一个常见的挑战，准确性之后速度至关重要。
- en: Usage in industry
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工业应用
- en: 'By far the most common usage of line-following behavior is in industry. Robots
    known as **automated guided vehicles** (**AGVs**) need to follow set paths for
    many reasons. These tasks can be warehouse robots staying on tracks between aisles
    of stacked products or factory robots staying on paths clear of other work areas.
    The line may mark a route between a storage shelf and a loading bay or a robot
    charging station and the robot''s work area:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 线路跟踪行为最常见的使用场景是工业领域。被称为**自动导引车**（**AGVs**）的机器人需要因多种原因遵循既定路径。这些任务可以是仓库机器人保持在堆叠产品通道之间的轨道上，或者工厂机器人保持在远离其他工作区域的路径上。线路可能标记了存储货架和装货区或机器人充电站和机器人工作区之间的路线：
- en: '![](img/B15660_14_01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_01.jpg)'
- en: Figure 14.1 – IntellCart – a line-following industrial robot by Mukeshhrs [Public
    domain]
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1 – IntellCart – Mukeshhrs的线路跟踪工业机器人[公有领域]
- en: IntelliCart, shown in *Figure 14.1*, uses bright blue guide tape, although,
    in most industrial applications, robots use under-floor magnetic tracks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图14.1*所示的IntelliCart使用明亮的蓝色引导胶带，尽管在大多数工业应用中，机器人使用地板下的磁轨。
- en: The route may include choice points, with multiple lines coming from a particular
    location. Depending on their task, the robot may need extra clues to sense that
    it has reached these points. An engineer can set up a repeated path for a fully
    automated system.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 路线可能包括选择点，从特定位置发出多条线路。根据其任务，机器人可能需要额外的线索来感知它已经到达这些点。工程师可以为完全自动化的系统设置重复路径。
- en: Having these demarcated means that you can set safety boundaries and be clear
    on where humans and robots do or do not interact; this means that robots will
    rarely operate outside of well-understood areas.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些明确的标记意味着你可以设置安全边界，并清楚地了解人类和机器人是否互动；这意味着机器人很少会在人们不太了解的区域外操作。
- en: Types of line following
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线路跟踪类型
- en: There are a few major branches of line following and related systems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 线路跟踪和相关系统有几个主要分支。
- en: '**Visual line following** is by far the most commonly practiced and easy-to-set-up
    line following technique. It consists of a painted, drawn, or taped visual line
    that robots detect. Optical lines are simple, but surface dirt and light conditions
    can make this unreliable. How it is detected falls into a couple of major categories:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**视觉线路跟踪**是目前最常见且易于设置的线路跟踪技术。它由机器人检测到的涂画、绘制或贴上的视觉线路组成。光学线路简单，但表面污垢和光照条件可能会使其不可靠。检测方式主要分为以下几类：'
- en: '**Detected with light sensors**: In this case, we''d attach small sensors to
    a robot''s underside close to the line. They are tuned to output a binary on/off
    signal or analog signal. They usually have lights to shine off the surface. These
    are small and cheap but require extra I/O.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过光传感器检测**：在这种情况下，我们将小型传感器附着在机器人底部靠近线路的位置。它们被调整以输出二进制开/关信号或模拟信号。它们通常有灯光照射到表面。这些传感器体积小且价格低廉，但需要额外的I/O。'
- en: '**Detected with a camera**: This will save space if you already use a camera,
    along with I/O pins. It saves complexity in mounting them and wiring them. However,
    it comes at a trade-off cost of software complexity, as your robot needs computer
    vision algorithms to analyze this.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过摄像头检测**：如果你已经使用摄像头，并且有I/O引脚，这将节省空间。它简化了安装和布线的复杂性。然而，这需要在软件复杂性上做出权衡，因为你的机器人需要计算机视觉算法来分析这些。'
- en: '**Magnetic line following** is used when the line needs to be protected against
    the elements. Also, for some variations of this, you can guide a robot on multiple
    paths. There are the following variants:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**磁性线路跟踪**用于需要保护线路免受外界因素影响的情况。对于这种变化的某些变体，你可以引导机器人在多条路径上。以下是一些变体：'
- en: Running a magnetic strip along a floor allows Hall-effect sensors (such as the
    magnetometer in [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251),
    *IMU Programming with Python*) to detect where the strip is. A series of these
    sensors can determine the direction of a line and follow it. This can be easier
    to alter than painting a line but can be a trip hazard.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在地板上运行磁条，可以让霍尔效应传感器（如[*第12章*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251)，*使用Python进行IMU编程*）检测磁条的位置。一系列这样的传感器可以确定线路的方向并跟随它。这比画线路更容易更改，但可能成为绊脚石。
- en: Running a wire with some current through it along or under a floor will achieve
    the same effect. With multiple wires and some different circuits for them, systems
    can steer a robot onto different paths.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在地板上或其下方运行带有电流的电线，可以达到相同的效果。通过多条电线和一些不同的电路，系统可以将机器人引导到不同的路径上。
- en: Concealing the line under a floor removes the trip hazard but means that you
    need to paint warnings for humans on paths that industrial robots follow.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在地板下隐藏线条消除了绊倒危险，但意味着您需要在工业机器人跟随的路径上为人类画上警告标记。
- en: 'Now, you have seen the two major types of line following; it''s worth giving
    an honorable mention to some other ways to determine a robot''s path in the real
    world:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经看到了两种主要的线跟踪类型；值得提一下其他一些在现实世界中确定机器人路径的方法：
- en: '**Beacons**: Ultrasonic, light-emitting, or radio-emitting beacons can be placed
    around an environment to determine the path of a robot. These could just be reflectors
    for laser or other light.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信标**：超声波、发光或无线电发射的信标可以放置在环境中以确定机器人的路径。这些可能是激光或其他光线的反射器。'
- en: '**Visual clues**: If you place QR codes or other visible markers on walls and
    posts, they can encode an exact position.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉线索**：如果您在墙壁和柱子上放置二维码或其他可见标记，它们可以编码一个精确的位置。'
- en: You've seen how a robot can perform line sensing with visible lines and hidden
    lines, such as wires under a floor and magnetic sensors. Because it is easier,
    we will use visible lines.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到了机器人如何通过可见线条和隐藏线条（如地板下的电线和磁传感器）进行线感应。因为它更容易，我们将使用可见线条。
- en: The simple optical sensors require additional wiring, but if we already have
    a camera capable of this, why not make use of it?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的光学传感器需要额外的布线，但如果我们已经有一个能够做到这一点的相机，为什么不利用它呢？
- en: In this chapter, we will be focusing on using the camera we already have with
    a visual track and following the lines there. We will accept the code complexity
    while simplifying the hardware aspects of our robot.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于使用我们已有的相机和视觉轨道进行跟踪，并跟随那里的线条。我们将接受代码的复杂性，同时简化我们机器人的硬件方面。
- en: Now that you have some idea of the different types of line following and where
    to use them, let's create a test track that our robot can follow.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经对不同的线跟踪类型及其使用场合有了些了解，让我们创建一个机器人可以跟随的测试轨道。
- en: Making a line-follower test track
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 制作一条线跟踪测试轨道
- en: Since you will be making your robot follow a line, we need to start with a section
    of line to follow. The track will be used at the beginning to test our line detection
    algorithm and can then be extended to more exciting tracks when we turn on the
    motors and start driving along the line. What I will show you in this section
    is easy to make and extendable. It allows you to experiment with different line
    shapes and curves and see how the robot responds.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您将使您的机器人跟随一条线，我们需要从一个要跟随的线条部分开始。该轨道最初将用于测试我们的线检测算法，然后当我们打开电机并开始沿着线条行驶时，可以将其扩展到更令人兴奋的轨道。在本节中，我将向您展示的是易于制作和可扩展的。它允许您尝试不同的线条形状和曲线，并观察机器人如何响应。
- en: You can even experiment with different color and contrast options.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您甚至可以尝试不同的颜色和对比度选项。
- en: Getting the test track materials in place
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备测试轨道材料
- en: 'The following photo shows the main materials required:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下照片显示了所需的主要材料：
- en: '![](img/B15660_14_02.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15660_14_02.jpg)'
- en: Figure 14.2 – Materials for making a test track
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2 – 制作测试轨道的材料
- en: 'The photo in *Figure 14.2* shows a roll of black electrical tape on a large
    sheet of white paper. For this section, you''ll need the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.2*中的照片显示了一卷黑色电气胶带铺在一张大白纸上。对于本节，您需要以下材料：'
- en: Some A2 plain white paper or board.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些A2纯白色纸张或板。
- en: Some black electrical insulation tape or painter's tape. Make sure this tape
    is opaque.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些黑色电气绝缘胶带或油漆工胶带。确保这种胶带是不透明的。
- en: A pair of scissors.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一把剪刀。
- en: You could replace the paper with boards if they are white-painted.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它们是白色涂漆的，您可以用板子替换纸张。
- en: You can also swap things around by using dark or black paper and white tape.
    This tape must not be see-through so that it makes a good strong contrast against
    the background.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以通过使用黑色或深色纸张和白色胶带来更换物品。这种胶带必须是半透明的，以便与背景形成良好的强烈对比。
- en: Making a line
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 制作一条线
- en: 'Lay the sheet of paper flat. Then, make a line along the middle of the paper
    with the tape:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 将纸张平铺。然后，用胶带在纸张中间画一条线：
- en: '![](img/B15660_14_03.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15660_14_03.jpg)'
- en: Figure 14.3 – Smoothing the tape on the paper
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3 – 在纸张上平滑胶带
- en: The photos in *Figure 14.3* show the paper with the tape line and me smoothing
    the tape with my finger. Be sure to smooth the tape down. You do not need to worry
    about making it perfectly straight, as the whole point of this system is to follow
    lines even when they curve.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.3*中的照片显示了带有胶带线条的纸张和我用手指抚平胶带的情景。确保将胶带抚平。你不需要担心使其完全笔直，因为这个系统的整个目的就是在线条弯曲时也能跟随线条。'
- en: 'Once you have a few lengths of this tape on sheet, why not make a few interesting
    pieces, such as the ones in the following figure:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在纸上贴上几段这样的胶带，为什么不制作一些有趣的部件，比如以下图中的那些：
- en: '![](img/B15660_14_04.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_04.jpg)'
- en: Figure 14.4 – Some different shapes adjoining a straight line
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4 – 一些与直线相邻的不同形状
- en: As *Figure 14.4* shows, you can experiment with curves and intentionally not-quite-straight
    lines. You can join these together with the straight lines to make whole sections,
    like a robotic train set! These will be fun to test with later as you further
    tune and play with the line-following code.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图14.4*所示，你可以尝试曲线和故意不完全直的线条。你可以将这些线条与直线结合起来，形成整个区域，就像一个机器人火车套装！这些线条在后续调整和玩转跟随代码时将会很有趣。
- en: Now that we have a test track ready, we can think about how we can visually
    process the line.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了测试轨道，我们可以考虑如何视觉处理线条。
- en: Line-following computer vision pipeline
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟随线条的计算机视觉流程
- en: As we did with the previous computer vision tasks, we will visualize this as
    a pipeline. Before we do, there are many methods for tracking a line with computer
    vision.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在之前的计算机视觉任务中所做的那样，我们将将其视为一个流程。在我们这样做之前，有许多使用计算机视觉跟踪线条的方法。
- en: Camera line-tracking algorithms
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摄像头线条跟踪算法
- en: It is in our interests to pick one of the simplest ones, but as always, there
    is a trade-off, in that others will cope with more tricky situations or anticipate
    curves better than ours.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有兴趣选择其中最简单的一个，但就像往常一样，总有一个权衡，那就是其他算法可以处理更复杂的情况或比我们的算法更好地预测曲线。
- en: 'Here is a small selection of methods we could use:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些我们可以使用的方法：
- en: '**Using edge detection**: An edge detection algorithm, such as the Canny edge
    detector, can be run across the image, turning any transitions it finds into edges.
    OpenCV has a built-in edge detection system if we wanted to use this. The system
    can detect dark-to-light and light-to-dark edges. It is more tolerant of less
    sharp edges.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用边缘检测**: 可以运行边缘检测算法，例如Canny边缘检测器，对图像进行处理，将找到的任何过渡转换为边缘。如果我们想使用这个系统，OpenCV内置了边缘检测系统。该系统可以检测从暗到亮和从亮到暗的边缘。它对不太尖锐的边缘更加宽容。'
- en: '**Finding differences along lines**: This is like cheeky edge detection, but
    only on a particular row. By finding the difference between each pixel along a
    row in the image, any edges will show significant differences. It''s simpler and
    cheaper than the Canny algorithm; it can cope with edges going either way but
    requires sharp contrasts.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**沿线条寻找差异**: 这就像 cheeky 边缘检测，但只针对特定的一行。通过在图像中每一行的每个像素之间找到差异，任何边缘都会显示出显著差异。它比Canny算法简单且成本低；它可以处理任意方向的边缘，但需要尖锐的对比度。'
- en: '**Finding brightness and using a region over an absolute brightness as the
    line**: This is very cheap but a little too simplistic to give good results. It''s
    not tolerant to inversions but isn''t tracking edges, so doesn''t need sharp contrasts.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**寻找亮度和使用绝对亮度区域作为线条**: 这非常简单，但过于简单，难以给出好的结果。它对反转不敏感，但不需要跟踪边缘，因此不需要尖锐的对比度。'
- en: Using one of the preceding three methods, you can find the line in one picture
    area and simply aim at that. This means you won't be able to pre-empt course changes.
    It is the easiest way. The chosen area could be a single row near the bottom of
    the screen.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面三种方法中的一种，你可以在一个图片区域找到线条，并直接瞄准那里。这意味着你将无法预先预测路线变化。这是最简单的方法。所选区域可能是屏幕底部的单行。
- en: Alternatively, you can use the preceding methods to detect the line throughout
    the camera image and make a trajectory for it. This is more complex but better
    able to cope with steeper turns.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以使用前面的方法来检测摄像头图像中的线条并为其绘制轨迹。这更复杂，但更能应对更陡峭的转弯。
- en: It's worth noting that we could make a more efficient but more complicated algorithm
    using the raw YUV data from the Pi Camera. For simplicity, we will stick to the
    simple one. As you trade further up in complexity and understanding, you can find
    far faster and more accurate methods for this.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们可以使用Pi摄像头的原始YUV数据制作一个更高效但更复杂的算法。为了简单起见，我们将坚持使用简单的算法。随着你在复杂性和理解上的进一步交易，你可以找到更快、更准确的方法。
- en: Another major limitation of our system is the view width of the camera. You
    could use lenses to let a camera take in a wide visual field so that the robot
    will not lose the line so often.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统的另一个主要限制是摄像头的视野宽度。你可以使用镜头让摄像头捕捉更宽的视觉范围，这样机器人就不会经常丢失线条。
- en: The method we will use is finding the differences along lines due to its simplicity
    and ability to cope with different line colors. We are also going to simply look
    along a single column, which results in more straightforward math.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的方法是沿着线条寻找差异，因为它简单且能够应对不同的线条颜色。我们还将简单地沿着单列查找，这导致数学更加直接。
- en: The pipeline
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道
- en: 'We can visualize the way we process data as a pipeline. Before we can, let''s
    quickly explain discrete differences. The brightness of each pixel is a number
    between 0 (black) and 255 (white). To get the difference, you subtract each pixel
    from the pixel to the right of it:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将数据处理方式视为一个管道。在我们这样做之前，让我们快速解释一下离散差异。每个像素的亮度是一个介于0（黑色）和255（白色）之间的数字。为了得到差异，你从每个像素减去它右侧的像素：
- en: '![](img/B15660_14_05.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_05.jpg)'
- en: Figure 14.5 – Discrete differences between pixels
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5 – 像素之间的离散差异
- en: 'In *Figure 14.5*, there are six sets of pixels in varying shades:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图14.5*中，有六组不同色调的像素：
- en: The first shows two white pixels. There is no difference between them.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一幅图显示了两个白色像素。它们之间没有差异。
- en: Where there is a gray pixel followed by a white one, it produces a small difference.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当灰色像素后面跟着白色像素时，会产生一个小的差异。
- en: A black pixel followed by a white pixel produces a large difference.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 黑色像素后面跟着白色像素会产生一个大的差异。
- en: A white pixel followed by a black pixel produces a large negative difference.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 白色像素后面跟着黑色像素会产生一个大的负差异。
- en: A black pixel followed by a black pixel will produce no difference.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 黑色像素后面跟着黑色像素不会产生差异。
- en: A gray pixel followed by a black pixel will produce a small negative difference.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 灰色像素后面跟着黑色像素会产生一个小的负差异。
- en: It should be easy to see that a contrasting line edge will produce the largest
    differences, positive or negative. Our code will look for these.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 应该很容易看出，对比度高的线条边缘会产生最大的差异，无论是正的还是负的。我们的代码将寻找这些差异。
- en: 'The following diagram shows how we process camera data for this method:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了我们如何处理该方法的摄像头数据：
- en: '![](img/B15660_14_06.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_06.jpg)'
- en: Figure 14.6 – Image processing pipeline for finding a line
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6 – 寻找线条的图像处理管道
- en: In *Figure 14.6*, we show the process of finding a line to follow. It starts
    with the **camera**, from which we **capture images** at a 320-by-240-pixel resolution.
    The next step in the pipeline is to **convert to grayscale** – we are only interested
    in brightness right now.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图14.6*中，我们展示了寻找跟随线条的过程。它从**摄像头**开始，我们从320×240像素分辨率的摄像头**捕获图像**。管道中的下一步是将图像**转换为灰度**
    – 我们现在只对亮度感兴趣。
- en: Because images can have noise or grain, we **blur** it; this is not strictly
    necessary and depends on how clear the environment you are taking pictures from
    is.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像可能有噪声或颗粒，我们**模糊**它；这并不是严格必要的，这取决于你从哪个清晰的环境中拍照。
- en: We take that image and **slice out a candidate row**; this shouldn't be too
    high in the picture, as that line may be too far away or there may be random things
    above the horizon depending on the camera position. The row shouldn't be too low
    as it will then be too close to the robot for it to react in time. Above the **slice
    out candidate row** box is an example showing the sliced-out row and the image
    it came from.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从这个图像中**切出候选行**；这个行不应该太高，因为那条线可能太远，或者根据摄像头的位置，地平线以上可能有随机的东西。行也不应该太低，因为它会离机器人太近，以至于它无法及时反应。在**切出候选行**框上方是一个示例，展示了切出的行和它来自的图像。
- en: We then treat this row as a set of numbers and **get the discrete difference
    across** them. The graph above the **discrete difference** box shows a large negative
    spike as the row goes from light gray to black, followed by a large positive spike
    as the row goes from black to light gray again. Notice that much of the graph
    shows a line along zero as patches of color have no difference.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后将这一行视为一组数字，并**获取它们之间的离散差异**。在**离散差异**框上方的图表显示，当行从浅灰色变为黑色时，出现一个大的负峰值，随后当行再次从黑色变为浅灰色时，出现一个大的正峰值。注意，图表的大部分显示为零线，因为颜色块之间没有差异。
- en: The next step is to **find the maximum and minimum positions**, specifically
    where in the row they are. We want the position/index of the highest point above
    zero and the lowest point below zero. We now know where the boundaries of our
    line probably are.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是**找到最大和最小位置**，具体来说是在行中的哪个位置。我们想要的是高于零的最高点的位置/索引和低于零的最低点的位置/索引。现在我们知道了我们线条的边界可能在哪里。
- en: We can **find the position between** these boundaries to find the center of
    the line, by adding them together and dividing by 2; this would be an *X* position
    of the line relative to the middle of the camera image.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将这些边界**之间的位置**相加并除以2来找到线条的中心，这将是一个相对于相机图像中间的*X*位置。
- en: Now, you've seen the pipeline with some test images. It's time to get some test
    images of your own and try this algorithm out with some code.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经看到了一些测试图像的流程。是时候获取一些自己的测试图像，并尝试使用一些代码来运行这个算法了。
- en: Trying computer vision with test images
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试使用测试图像进行计算机视觉
- en: In this section, we will look out how and why to use test images. We will write
    our first chunk of code for this behavior and try it on test images from our robot's
    camera. These tests will prepare us for using the code to drive the robot.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨如何以及为什么使用测试图像。我们将为这种行为编写我们的第一段代码，并在机器人的相机测试图像上尝试它。这些测试将为我们使用代码来控制机器人做准备。
- en: Why use test images?
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么使用测试图像？
- en: So far, our computer vision work has been written directly with robot behaviors;
    this is the end goal of them, but sometimes, you want to try the visual processing
    code in isolation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的计算机视觉工作都是直接与机器人行为一起编写的；这是它们的目标，但有时，您可能想要单独尝试视觉处理代码。
- en: Perhaps you want to get it working or work out bugs in it, or you may want to
    see whether you can make the code faster and time it. To do this, it makes sense
    to run that particular code away from the robot control systems.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 可能您想要让它工作或找出其中的错误，或者您可能想要看看您是否可以使代码更快并对其进行计时。为此，在机器人控制系统之外运行该特定代码是有意义的。
- en: It also makes sense to use test images. So, instead of running the camera and
    needing light conditions, you can run with test images you've already captured
    and compare them against the result you expected from them.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用测试图像也是合理的。因此，您不必运行相机并需要光照条件，您可以使用您已经捕捉到的测试图像，并将它们与您从它们期望的结果进行比较。
- en: For performance testing, trying the same image 100 times or the same set of
    images will give consistent results for performance measures to be meaningful.
    Avoid using new data every time, as these could result in unexpected or potentially
    noisy results. However, adding new test images to see what would happen is fascinating.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于性能测试，尝试同一图像100次或同一组图像将给出一致的结果，以便性能指标有意义。避免每次都使用新数据，因为这些可能会导致意外或可能是有噪声的结果。然而，添加新的测试图像以查看会发生什么是非常有趣的。
- en: So now that we know why we use them, let's try capturing some test images.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们现在知道了为什么使用它们，让我们尝试捕捉一些测试图像。
- en: Capturing test images
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捕捉测试图像
- en: You may recall, from the previous chapter, using `raspistill` to capture an
    image. We are going to do the same here. First, we want to put our camera into
    a new position, facing down, so we are looking down onto the line.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得，在前一章中，我们使用`raspistill`来捕捉图像。我们在这里也将这样做。首先，我们想要将我们的相机放置到一个新的位置，朝下，这样我们就可以俯视线条。
- en: This section requires the setup from the chapter [*Chapter 13*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283),
    *Robot Vision – Using a Pi Camera and OpenCV* and code from [*Chapter 9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171),
    *Programming RGB Strips in Python*.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 本节需要从第[*第13章*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283)的设置中获取，*使用Pi相机和OpenCV进行机器人视觉*，以及从[*第9章*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171)的代码，*在Python中编程RGB条带*。
- en: 'Turn the motor power on to the Raspberry Pi, then with an `ssh` session into
    the Raspberry Pi on the robot, type the following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 将电机功率打开到Raspberry Pi上，然后在机器人上的Raspberry Pi上通过`ssh`会话，输入以下命令：
- en: 'We start Python by typing `python3`:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过键入`python3`开始Python：
- en: '[PRE0]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, we need to import our robot object and create it so that we can interact
    with it:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要导入我们的机器人对象并创建它，以便我们可以与之交互：
- en: '[PRE1]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s create the robot object:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建机器人对象：
- en: '[PRE2]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, use this to set the pan servo to the middle:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用此方法将水平伺服机构设置为中间位置：
- en: '[PRE3]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The pan servo should center the camera.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 水平伺服机构应该使相机居中。
- en: 'Next, we set the tilt servo to face down to look at the line:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将倾斜伺服机构设置为向下，以便观察线条：
- en: '[PRE4]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The servo should look straight down here. It should not be straining or clicking.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 伺服机构应该在这里直视下方。它不应该过度拉伸或发出咔哒声。
- en: Now, you can exit Python (and release the motors) by pressing *Ctrl* + *D*.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以通过按*Ctrl* + *D*退出Python（并释放电机）。
- en: The camera is facing downward. You can now turn off the motor switch and put
    this robot onto your test track. Try to position the robot so that the camera
    is right above the line.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相机面向下方。现在您可以关闭电机开关，并将这个机器人放到您的测试轨道上。尽量将机器人定位，使相机正好位于线条上方。
- en: 'In the `ssh` terminal, type the following to capture a test image:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`ssh`终端中，键入以下内容以捕获测试图像：
- en: '[PRE5]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can now download this image to your PC using FileZilla, as discussed in
    the book''s earlier chapters. The next figure shows a test image, also used for
    the preceding examples:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以使用FileZilla（正如本书前面的章节所讨论的）将此图像下载到您的PC上。下一张图显示了一个测试图像，也用于前面的示例：
- en: '![](img/B15660_14_07.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_07.jpg)'
- en: Figure 14.7 – A test image of a line
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7 – 一条线的测试图像
- en: '*Figure 14.7* shows one of my test images. Note that the line is roughly starting
    in the middle of the picture, but it isn''t exact and doesn''t need to be. Note
    also that the lighting is a bit rough and is creating shadows. These are worth
    watching out for as they could confuse the system.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.7* 展示了我的一张测试图像。请注意，线条大致从图片中间开始，但并不精确，也不需要精确。还要注意，光线有点粗糙，产生了阴影。这些值得注意，因为它们可能会使系统混淆。'
- en: Capture a few images of the line at different angles to the robot and slightly
    left or slightly right of the camera.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 从不同的角度捕捉机器人几条线的图像，稍微向左或向右偏离相机。
- en: Now that we have test images, we can write code to test them with!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了测试图像，我们可以编写代码来测试它们！
- en: Writing Python to find the edges of the line
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写Python代码以找到线条的边缘
- en: We are ready to start writing code, using our test images and the preceding
    pipeline diagram. We can make the results quite visual so that we can see what
    the algorithm is doing.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备开始编写代码，使用我们的测试图像和前面的流程图。我们可以使结果非常直观，以便我们可以看到算法正在做什么。
- en: Tip
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: In computer vision, it's useful to use the lowest resolution you can to do the
    job. Every additional pixel adds more memory and processing to cope with. At 320*200,
    this is 76,800 pixels. The Raspberry Pi camera can record at 1920 x 1080 – 2,073,600
    pixels – 27 times as much data! We need this to be quick, so we keep the resolution
    low.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中，使用最低的分辨率来完成工作是有用的。每个额外的像素都会增加更多的内存和处理能力。在320*200的分辨率下，这是76,800个像素。树莓派相机可以以1920
    x 1080的分辨率记录 – 2,073,600个像素 – 这是27倍的数据！我们需要它快速，所以我们保持低分辨率。
- en: 'The code in this section will run on the Raspberry Pi, but you can also run
    it on a PC with Python 3, NumPy, Matplotlib, and Python OpenCV installed:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的代码将在树莓派上运行，但您也可以在安装了Python 3、NumPy、Matplotlib和Python OpenCV的PC上运行：
- en: Create a file called `test_line_find.py`.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`test_line_find.py`的文件。
- en: 'We will need to import NumPy to process the image numerically, OpenCV to manipulate
    the image, and Matplotlib to graph the results:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将需要导入NumPy以数值处理图像，OpenCV以操作图像，以及Matplotlib以绘制结果：
- en: '[PRE6]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we load the image. OpenCV can load `jpg` images, but if there is a problem
    in doing so, it produces an empty image. So, we need to check that it loaded something:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们加载图像。OpenCV可以加载`jpg`图像，但如果在加载过程中出现问题，它会产生一个空图像。因此，我们需要检查它是否加载了某些内容：
- en: '[PRE7]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The captured image will be at the large default resolution of the camera. To
    keep this fast, we resize it to a smaller image:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 捕获的图像将是相机的大默认分辨率。为了保持快速，我们将它调整到更小的图像：
- en: '[PRE8]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We also only want grayscale; we aren''t interested in the other colors for
    this exercise:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还只想使用灰度；对于这个练习，我们不感兴趣的其他颜色：
- en: '[PRE9]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we''ll pick out the row; for now, we''ll use 180 as that is fairly low
    on an image with a height of 240\. The images are stored such that row 0 is the
    top. Note that we are telling NumPy to convert this into an `int32` type:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将选择行；目前，我们将使用180，因为这在240像素高的图像上相当低。图像是存储的，使得行0是顶部。请注意，我们正在告诉NumPy将其转换为`int32`类型：
- en: '[PRE10]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can get a list of differences for every pixel of this row. NumPy makes this
    easy:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We are going to plot this `diff` list. We will need the *x*-axis to be the
    pixel number; let''s create a NumPy range from 0 to that range:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s plot the `diff` variable against the pixel index (`x`), and save the
    result:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Pointing at my test picture, I get the following graph:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_14_08.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: Figure 14.8 – Graph of differences without blurring
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'The graph in *Figure 14.8* has the column number as the *x* axis and the difference
    as the *y* axis. The line has a lot of noise in it. There are two distinct peaks
    – one below the zero line at around column 145 and one above the line at around
    240\. The noise here doesn''t affect this too much as the peaks are very distinct:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try adding the blurring to see how that changes things. Make the following
    change to the code. The bold areas show changed sections:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this code, we add the additional blurring step, blurring 5-by-5 chunks a
    little.
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'So that we can see different graphs, let''s change the name of our output file:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Blurring a little should reduce noise without affecting our sharp peaks too
    much. Indeed, the following figure shows how effective this is:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_14_09.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: Figure 14.9 – The diff graph after blurring
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The graph in *Figure 14.9* is similar to *Figure 14.8*. The axes are the same,
    and it has the same peaks. However, there is far less noise around the line at
    0, showing that blurring makes the difference clearer. The question about this
    will be whether it changes the outcome. Looking at the position and size of the
    peaks, I would say not so much. So, we can leave it out of the final follow for
    a little extra speed. Every operation will cost a little time.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the two peaks, let's use them to find the location of the line.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Locating the line from the edges
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Those peaks are markers of our line edges. To find the middle of something,
    you add its left and right coordinates, then divide them by 2:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must pick up the coordinates. Let''s write code to ask for the maximum
    and minimum. We''ll add this code between the analysis code and the chart output
    code:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'These are values, but not locations. We now need to find the index of the locations.
    NumPy has an `np.where` function to get indexes from arrays:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To find the middle, we need to add these together and divide them by 2:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now that we have found it, we should display it in some way. We can plot this
    on our graph with three lines. Matplotlib can specify the color and style for
    a plot. Let''s start with the middle line:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can do the same for the `highest` and `lowest` locations, this time using
    `g--` for a green dashed line:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As we did for blurring, let''s change the name of the output graph so that
    we can compare them:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Running this should output the following figure:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_14_10.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: Figure 14.10 – Graph showing the highest, lowest, and middle line
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The graph in *Figure 14.10* shows that we have found the middle line and the
    two nice clear peaks. This code looks usable for our robot.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.10*中的图表显示我们已经找到了中线以及两个清晰的峰值。这段代码看起来对我们的机器人是可用的。'
- en: However, what happens when things are not so clear?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当事情并不那么清晰时会发生什么？
- en: Trying test pictures without a clear line
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试没有清晰线条的测试图片
- en: Let's see what our line-finding code does with a very different test picture.
    We will see what happens here, so we aren't so surprised by how the robot will
    behave and weed out some simple bugs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的线条查找代码在非常不同的测试图片上的表现。我们将看到这里会发生什么，这样我们就不那么惊讶于机器人的行为，并排除一些简单的错误。
- en: For example, what about putting our line on a very noisy surface, such as a
    carpet? Or how about the paper without a line, or the carpet without a line?
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，把我们的线条放在一个非常嘈杂的表面上，比如地毯上？或者没有线条的纸张，或者没有线条的地毯呢？
- en: '![](img/B15660_14_11.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15660_14_11.jpg)'
- en: Figure 14.11 – diff graphs under noisier conditions
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.11 – 在更嘈杂条件下的差分图
- en: With a set of graphs such as those in *Figure 14.11*, we learn much about our
    system.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 通过像*图14.11*中的一系列图表，我们对我们系统了解了很多。
- en: The top three images show the original photos. The next three graphs show what
    those images look like when finding the difference and middles without blurring.
    The bottom three graphs show what happens when enabling the blur.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 最上面的三张图片显示了原始照片。接下来的三张图表显示了在没有模糊的情况下寻找差异和中线时的图像外观。最下面的三张图表显示了启用模糊时会发生什么。
- en: First, when things get as noisy as the first image (and this is pushing it past
    what line following should cope with), the blur makes the difference between finding
    the line and a random artifact; although, in the second graph, a random artifact
    with a similar downward peak size was a close contender. In this case, making
    a larger *Y* blur might smooth out that artifact, leaving only the line.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，当事情变得像第一张图片那样嘈杂（这已经超出了循线应该应对的范围），模糊使得找到线条和随机伪影之间的差异；尽管如此，在第二个图表中，一个具有类似向下峰值大小的随机伪影是一个接近的竞争者。在这种情况下，制作更大的*Y*模糊可能会平滑掉那个伪影，只留下线条。
- en: Looking closely, the scale of those graphs is also not the same. The plain paper
    graph measures a difference with peaks of +10/-10 without blurring, and +1/-1
    with blurring. So, when the differences are that low, should we even be looking
    for a peak? The story is similar in the carpet-only graphs.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察，那些图表的刻度尺也不相同。普通纸张图表在没有模糊的情况下测量+10/-10的峰值，而在模糊的情况下为+1/-1。因此，当差异如此之低时，我们甚至应该寻找峰值吗？地毯-only图表中的情况也类似。
- en: We can make a few changes to our system to make it consider these as not-lines.
    The simplest is to add a condition that filters out a minimum above -5 and a maximum
    below 10\. I say -5 since this would otherwise filter out the line in the first
    graph completely. However, a larger blur area might help with that.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对系统进行一些更改，使其将这些视为非线条。最简单的是添加一个条件，过滤掉-5以上的最小值和10以下的最大值。我说-5，因为否则会完全过滤掉第一张图中的线条。然而，更大的模糊区域可能会有所帮助。
- en: Depending on the noisiness of the conditions, we will want to enable the blur.
    On a nicely lit track, the blur is probably not needed.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 根据条件的嘈杂程度，我们可能需要启用模糊。在光线充足的轨道上，模糊可能不是必需的。
- en: 'The next figure shows our line on the carpet, with a blur set to (5, 40), blurring
    further between rows and filtering out noise further:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了我们的线条在地毯上，模糊设置为（5，40），进一步在行之间模糊并过滤掉更多的噪声：
- en: '![](img/B15660_14_12.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15660_14_12.jpg)'
- en: Figure 14.12 – The line on carpet with a larger blur
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.12 – 带有更大模糊的地毯上的线条
- en: The graph in *Figure 14.12* has far less noise than before, with the blur smoothing
    out noise spikes a lot, while the actual line spikes remain. We would only want
    to do this in a noisy environment, as it risks being slower.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.12*中的图表比之前有更少的噪声，模糊处理大大平滑了噪声尖峰，而实际的线条尖峰仍然存在。我们只会在嘈杂的环境中这样做，因为它可能会使速度变慢。'
- en: As you can see, testing the code on test images has allowed us to learn a lot
    about the system. By taking the same pictures and trying different parameters
    and pipeline changes, you can optimize this for different scenarios. As you experiment
    more with computer vision, make this a habit.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在测试图像上测试代码使我们对我们系统了解了很多。通过拍摄相同的照片并尝试不同的参数和管道更改，您可以针对不同的场景进行优化。随着您在计算机视觉方面的实验越来越多，养成这个习惯。
- en: Now we have tried our visual processing code on test images, it's time to put
    it on a robot behavior!
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经尝试在我们的测试图像上运行我们的视觉处理代码，是时候将其应用于机器人行为上了！
- en: Line following with the PID algorithm
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PID算法的循线
- en: In this section, we will combine the visual processing seen previously with
    the PID control loops and camera streaming seen in [*Chapter 13*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283),
    *Robot Vision – Using a Pi Camera and OpenCV*. Please start from the code in that
    chapter.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将结合之前看到的视觉处理、PID控制循环和相机流，以及在第13章中看到的[*第13章*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283)，*机器人视觉
    - 使用Pi相机和OpenCV*。请从该章节中的代码开始。
- en: 'The files you will need are as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要的文件如下：
- en: '`pid_controller.py`'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pid_controller.py`'
- en: '`robot.py`'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`robot.py`'
- en: '`servos.py`'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`servos.py`'
- en: '`camera_stream.py`'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`camera_stream.py`'
- en: '`image_app_core.py`'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_app_core.py`'
- en: '`leds_led_shim.py`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leds_led_shim.py`'
- en: '`encoder_counter.py`'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoder_counter.py`'
- en: The templates folder
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模板文件夹
- en: We will use the same template for displaying this, but we are going to add a
    quick and cheeky way of rendering the `diff` graphs in OpenCV onto our output
    frame. Matplotlib would be too slow for this.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同的模板来显示这个，但我们将添加一种快速而巧妙的方法，将OpenCV上的`diff`图渲染到输出帧上。Matplotlib对于这个来说太慢了。
- en: Creating the behavior flow diagram
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建行为流程图
- en: Before we build a new behavior, creating a data flow diagram will help us get
    a picture of what happens to the data after we've processed it.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们构建新的行为之前，创建一个数据流图将帮助我们了解处理数据后数据发生了什么。
- en: 'The system will look familiar, as it is very similar to those we made in [*Chapter
    13*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283), *Robot Vision – Using a
    Pi Camera and OpenCV*. Take a look at the following figure:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 系统看起来很熟悉，因为它与我们第13章中制作的非常相似[*第13章*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283)，*机器人视觉
    - 使用Pi相机和OpenCV*。看看下面的图：
- en: '![](img/B15660_14_13_NEW.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_13_NEW.jpg)'
- en: Figure 14.13 – The line-following behavior
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.13 – 跟线行为
- en: In *Figure 14.13*, we have camera images going through to the **get line from
    image** block. This block outputs an object's *X* position (the middle of the
    line), which goes to our PID. Note that image data also goes from the get line
    to the image queue so that you can see these in a browser.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图14.13*中，相机图像通过到**从图像获取线**块。该块输出对象的*X*位置（线的中间），它进入我们的PID。请注意，图像数据也从获取线到图像队列，这样你就可以在浏览器中看到这些数据。
- en: The PID control also takes a reference middle point, where the middle of the
    camera should be. It uses the error between these to calculate the offset and
    uses that to drive the motors.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: PID控制还取一个参考中间点，即相机的中间。它使用这些之间的误差来计算偏移，并使用该偏移来驱动电机。
- en: The figure shows the motors with a feedback line to the camera, as the indirect
    effects of moving those are that the view changes, so we will see a different
    line.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了带有反馈线到摄像头的电机，因为这些移动的间接影响是视图发生变化，所以我们将看到不同的线。
- en: Before that, we are going to make our PID controller a little smarter again.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们将使我们的PID控制器变得更聪明一些。
- en: Adding time to our PID controller
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将时间添加到我们的PID控制器
- en: 'Our robot behaviors have involved processing frames, then sending error data
    to the PID whenever the process has completed a cycle. There is much going on
    in a cycle, and that timing might vary. When we create the integral, we have been
    adding the data as if the time was constant. For a somewhat more accurate picture,
    we should be multiplying that by the time:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的机器人行为包括处理帧，然后在过程完成一个周期时将错误数据发送到PID。一个周期中有很多事情发生，时间可能会变化。当我们创建积分时，我们一直像时间恒定一样添加数据。为了得到一个更准确的图像，我们应该乘以时间：
- en: Open up the `pid_controller.py` file.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`pid_controller.py`文件。
- en: 'In the `handle_integral` method, change the parameters to take `delta_time`:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`handle_integral`方法中，将参数更改为接受`delta_time`：
- en: '[PRE22]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We will then use this when adding in the integral term:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将使用这个方法来添加积分项：
- en: '[PRE23]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We usually update the PID with the `get_value` method; however, since we already
    have code using this, we should make it behave as it did before for them. To do
    this, we will add a `delta_time` parameter but with a default value of `1`:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通常使用`get_value`方法来更新PID；然而，由于我们已经有使用这个方法的代码，我们应该让它对这些代码的行为保持不变。为此，我们将添加一个`delta_time`参数，但默认值为`1`：
- en: '[PRE24]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'When this `get_value` method calls `handle_integral`, it should always pass
    the new `delta_time` parameter:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当这个`get_value`方法调用`handle_integral`时，它应该始终传递新的`delta_time`参数：
- en: '[PRE25]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: While this was not a big change, it will mean we can account for time variations
    between updates to the PID code.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这不是一个很大的变化，但它意味着我们可以计算PID代码更新之间的时间变化。
- en: We can now use this in our behavior.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在我们的行为中使用这个方法。
- en: Writing the initial behavior
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写初始行为
- en: 'We can take all the elements we have and combine them to create our line-following
    behavior:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将所有这些元素组合起来，创建我们的循线行为：
- en: Create a file named `line_follow_behavior.py`.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`line_follow_behavior.py`的文件。
- en: 'Start this with imports for `image_app_core`, NumPy, OpenCV, the camera stream,
    the PID controller, and the robot. We also have `time`, so we can later compute
    the delta time:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入`image_app_core`、NumPy、OpenCV、摄像头流、PID控制器和机器人。我们还有`time`模块，这样我们就可以稍后计算时间差：
- en: '[PRE26]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let''s make the behavior class. The constructor, as before, takes the robot:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建行为类。构造函数，就像之前一样，接受机器人作为参数：
- en: '[PRE27]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, we need variables in the constructor to track our behavior. First, we
    should set the row we will look for the differences in and a threshold (under
    which we will not consider it a line):'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要在构造函数中添加变量来跟踪我们的行为。首先，我们应该设置我们将要查找差异的行和阈值（低于该阈值我们不将其视为线条）：
- en: '[PRE28]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'As with our previous camera behaviors, we have a set point for the center,
    a variable to say whether the motors should be running, and a speed to go forward
    at:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像我们之前的摄像头行为一样，我们有一个中心点的设定值，一个变量来表示电机是否应该运行，以及一个前进的速度：
- en: '[PRE29]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We are going to make some interesting displays. We will store the colors we
    plan to use here too – a green crosshair, red for the middle line, and light blue
    for the graph. These are BGR as OpenCV expects that:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将要创建一些有趣的显示。我们也会在这里存储我们计划使用的颜色——一个绿色的十字准线，红色用于中线，浅蓝色用于图表。这些是BGR格式，因为OpenCV期望这样：
- en: '[PRE30]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: That is the constructor complete for the behavior.
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这就是行为构造函数的完整内容。
- en: 'Now, we need the control to say whether the system is running or should exit.
    This code should be familiar as it is similar to the other camera control behaviors:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要控制变量来表示系统是否正在运行或应该退出。这段代码应该很熟悉，因为它与其他摄像头控制行为相似：
- en: '[PRE31]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we''ll make the `run` method, which will perform the main PID loop and
    drive the robot. We are setting the tilt servo to `90` and the pan servo to `0`,
    so it is looking straight down. We''ll set up the camera too:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建`run`方法，它将执行主要的PID循环并驱动机器人。我们将倾斜伺服器设置为`90`，将俯仰伺服器设置为`0`，这样它就会直视下方。我们也会设置摄像头：
- en: '[PRE32]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we set up the PID for the direction. These values aren''t final and may
    need tuning. We have a low proportional value as the directional error can be
    quite large compared with the motor speeds:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们为方向设置PID。这些值不是最终的，可能需要调整。我们有一个低比例值，因为方向误差与电机速度相比可能相当大：
- en: '[PRE33]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We sleep for a second so that the camera can initialize and the servos reach
    their position:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们暂停一秒钟，以便摄像头可以初始化，伺服器达到其位置：
- en: '[PRE34]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We stop the servos so that they won't be pulling further power once they've
    reached position.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们停止伺服器，这样一旦它们达到位置，就不会再消耗更多电力。
- en: 'Since we are going to be keeping track of time, we store the last time value
    here. The time is a floating-point number in seconds:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将跟踪时间，我们在这里存储最后的时间值。时间是秒为单位的浮点数：
- en: '[PRE35]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We start the camera loop and feed the frame to a `process_frame` method (which
    we''ll write shortly). We can also process a control instruction:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动摄像头循环并将帧传递给`process_frame`方法（我们很快就会编写）。我们还可以处理控制指令：
- en: '[PRE36]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: From processing a frame, we expect to get an *X* value, and the magnitude is
    the difference between the highest and lowest value in the differences. The gap
    between the peaks helps detect whether it's actually a line and not just noise.
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从处理一个帧中，我们期望得到一个*X*值，幅度是差异中的最高值和最低值之间的差异。峰值之间的差距有助于检测它是否真的是线条而不是噪声。
- en: 'Now, for the movement, we need to check that the robot is running and that
    the magnitude we found was bigger than the threshold:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，对于移动，我们需要检查机器人是否正在运行，以及我们找到的幅度是否大于阈值：
- en: '[PRE37]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If so, we start the PID behavior:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果是这样，我们开始PID行为：
- en: '[PRE38]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We now log this and use the value to change the heading of the robot. We set
    the motor speeds to our base speed, and then add/subtract the motors'' PID output:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在记录这个信息并使用这个值来改变机器人的航向。我们将电机速度设置为基本速度，然后添加或减去电机的PID输出：
- en: '[PRE39]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now we''ve handled what happens when we have detected a line. What about when
    we don''t? `else` stops the motors running and resets the PID, so it doesn''t
    accumulate odd values:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经处理了检测到线条时会发生什么。那么，当我们没有检测到线条时呢？`else`会停止电机运行并重置PID，这样它就不会累积异常值：
- en: '[PRE40]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Notice how we are still keeping the last time up to date here. Otherwise, there
    would be a big gap between stops and starts, which would feed odd values into
    the PID.
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意我们在这里仍然在更新最后的时间。否则，在停止和开始之间会有很大的差距，这会导致PID输入异常值。
- en: 'Next, we need to fill in what happens when we process a frame. Let''s add our
    `process_frame` method:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要填写处理框架时发生的事情。让我们添加我们的 `process_frame` 方法：
- en: '[PRE41]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This code should all look familiar; it is the code we made previously for our
    test code.
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码看起来都应该很熟悉；这是我们之前为测试代码编写的代码。
- en: 'We should test to see that our readings have put us on either side of the zero
    line, and that we found two different locations. The maximum should not be below
    zero, and the minimum should not be above it. If they fail this, stop here – the
    main loop will consider this not a line:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该测试看看我们的读数是否使我们位于零线的两侧，并且我们找到了两个不同的位置。最大值不应该低于零，最小值也不应该高于它。如果它们失败了，就停止在这里——主循环将考虑这不是一条线：
- en: '[PRE42]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We will find the locations on the row as we did before, along with their midpoint:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将像之前一样找到行上的位置，以及它们的中间点：
- en: '[PRE43]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'So that we can use it to determine that we''ve got a positive match, we''ll
    calculate the magnitude of the difference between the min and max, making sure
    we aren''t picking up something faint:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这样我们就可以用它来确定我们得到了一个正匹配，我们将计算最小值和最大值之间差异的幅度，确保我们没有捕捉到微弱的东西：
- en: '[PRE44]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We will want to display something useful to the user here. So, this method
    calls a `make_display` method, just like the other camera behaviors. We pass it
    some variables to plot onto that display:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们希望在这里向用户展示一些有用的信息。因此，这个方法调用了一个 `make_display` 方法，就像其他相机行为一样。我们传递一些变量到这个显示上进行绘图：
- en: '[PRE45]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We then return the middle point and the magnitude:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们返回中间点和幅度：
- en: '[PRE46]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This code will drive our robot, but we''ll have a hard time tuning it if we
    can''t see what is going on. So, let''s create the `make_display` method to handle
    that:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码将驱动我们的机器人，但如果我们不能看到正在发生的事情，我们将很难调整它。所以，让我们创建一个 `make_display` 方法来处理这个问题：
- en: '[PRE47]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The first thing we want in the display is the center reference. Let''s make
    a crosshair about the center and the chosen row:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在显示中首先想要的是中心参考。让我们在中心和选定的行上制作一个十字准线：
- en: '[PRE48]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Next, we show where we found the middle in another color:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们用另一种颜色显示我们找到的中间位置：
- en: '[PRE49]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'So that we can find it, we also plot the bars for the `lowest` and `highest`
    around it, in a different color again:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了找到它，我们还围绕它绘制了 `lowest` 和 `highest` 的条形图，颜色不同：
- en: '[PRE50]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, we are going to graph `diff` across a new empty frame. Let''s make an
    empty frame – this is just a NumPy array:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将要在一个新的空框架上绘制 `diff`。让我们创建一个空框架——这只是一个 NumPy 数组：
- en: '[PRE51]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The array dimensions are rows then columns, so we swap the camera size *X* and
    *Y* values.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组维度是行然后是列，所以我们将摄像机的 *X* 和 *Y* 值交换。
- en: 'We will then use a method to make a simple graph. We''ll implement this further
    down. Its parameters are the frame to draw the graph into and the *Y* values for
    the graph. The simple graph method implies the *X* values as column numbers:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将使用一个方法来制作一个简单的图表。我们将在下面进一步实现它。它的参数是要绘制图表的框架和图表的 *Y* 值。简单的图表方法暗示了 *X* 值为列号：
- en: '[PRE52]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now that we have the frame and the graph frame, we need to concatenate these,
    as we did for our frames in the color-detecting code:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了框架和图表框架，我们需要将它们连接起来，就像我们在颜色检测代码中的框架一样：
- en: '[PRE53]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We can now encode these bytes and put them on the output queue:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以对这些字节进行编码并将它们放入输出队列：
- en: '[PRE54]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The next thing we will need to implement is this `make_cv2_simple_graph` method.
    It''s a bit cheeky but draws lines between *Y* points along an *x* axis:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来需要实现的是这个 `make_cv2_simple_graph` 方法。它有点厚颜无耻，但在 *x* 轴上绘制了 *Y* 点之间的线条：
- en: '[PRE55]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We need to store the last value we were at, so the code plots the next value
    relative to this – giving a line graph. We start with item 0\. We also set a slightly
    arbitrary middle *Y* point for the graph. Remember that we know the `diff` values
    can be negative:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要存储我们最后所在的位置，这样代码就可以相对于这个位置绘制下一个值，从而得到一个线图。我们从项目 0 开始。我们还为图表设置了一个稍微任意的中间
    *Y* 点。记住，我们知道 `diff` 值可以是负数：
- en: '[PRE56]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Next, we should enumerate the data to plot each item:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们应该枚举要绘制的数据，以便绘制每个项目：
- en: '[PRE57]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Now, we can plot a line from the last item *Y* position to the current position
    on the next *X* location. Notice how we offset each item by that graph middle:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以从上一个项目 *Y* 位置绘制到下一个 *X* 位置的当前位置的线条。注意我们是如何通过图表中间偏移每个项目的：
- en: '[PRE58]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We then need to update the last item to this current one:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们需要更新最后一个项目到当前这个：
- en: '[PRE59]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Okay – nearly there; that will plot the graph on our frame.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 好了——几乎完成了；这将把图表绘制在我们的框架上。
- en: 'Our behavior is complete; we just need the outer code to run it! This code
    should also be similar to the previous camera examples:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的行为已经完成；我们只需要外部代码来运行它！这段代码也应该类似于之前的相机示例：
- en: '[PRE60]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: You can now upload this to your robot. Then, switch the motors on and run it.
    Because this is web-based, point a browser at `http://myrobot.local:5001`.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以将其上传到您的机器人。然后，打开电机并运行它。因为这是基于网络的，请将浏览器指向 `http://myrobot.local:5001`。
- en: 'You should see the following:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下内容：
- en: '![](img/B15660_14_14.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15660_14_14.jpg)'
- en: Figure 14.14 – Screenshot of the line-following behavior output
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.14 – 跟随线条行为输出的截图
- en: The screenshot in *Figure 14.14* shows the title above two pictures. On the
    left is the camera picture of the line. Drawn onto this frame is a green crosshair
    showing where the center point is. Also, there is a large red bar showing the
    middle of the line, and either side of this, two shorter red bars showing the
    sides of it. To the right is the graph plotting the intensity differences after
    blurring. The up peak and down peak are visible in the graph.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14.14* 中的截图显示了上方两张图片的标题。在左边是线条的相机图片。在这个框架上画了一个绿色的十字线，显示了中心点位置。还有一个大红色的条形，显示了线条的中间，以及这个条形两侧的两个较短的红色条形，显示了线条的两侧。在右边是绘制模糊后强度差异的图表。图表中可见上峰值和下峰值。'
- en: Below this are the **Start**, **Stop**, and **Exit** buttons.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之下是 **开始**、**停止** 和 **退出** 按钮。
- en: Place the robot onto the line, with good lighting. If it looks like the preceding
    display, press the **Start** button to see it go. It should start shakily driving
    along the line.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器人放置在直线上，光线充足。如果看起来像前面的显示，请按 **开始** 按钮以查看它运行。它应该开始不稳定地沿着线条行驶。
- en: Tuning the PID
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整 PID
- en: 'You can get a little bolder with trying to track curved lines and find its
    limit. The robot will sometimes overshoot or understeer, which is where the PID
    tuning comes in:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试跟踪曲线线条并找到其极限时，您可以稍微大胆一些。机器人有时会超调或欠调，这就是 PID 调节发挥作用的地方：
- en: If it seems to be turning far too slowly, try increasing the proportional constant
    a little. Conversely, if it is oversteering, try lowering the proportional constant
    a fraction.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它似乎转得太慢，尝试稍微增加比例常数。相反，如果它过度转向，尝试稍微降低比例常数。
- en: If it had a slight continuous error, try increasing the integral constant.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存在轻微的连续误差，尝试增加积分常数。
- en: PID tuning is a repeating process and requires a lot of patience and testing.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: PID 调节是一个重复的过程，需要大量的耐心和测试。
- en: Troubleshooting
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除
- en: 'If the behavior isn''t quite working, please try the following steps:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 如果行为不太正常，请尝试以下步骤：
- en: If the tilt servo doesn't look straight down when set to 90 degrees, it may
    not be calibrated correctly. Change the `deflect_90_in_ms` value parameter to
    the `Servos` object – increase in 0.1 increments to get this to 90 degrees.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果将倾斜伺服设置为 90 度时看起来不垂直向下，可能没有正确校准。将 `deflect_90_in_ms` 值参数更改为 `Servos` 对象 –
    以 0.1 的增量增加，以使其达到 90 度。
- en: If it is having trouble getting a clear line, ensure that the lighting is adequate,
    that the surface it is on is plain, such as paper, and the line is well contrasting.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它难以获得清晰的线条，请确保光线充足，它所在的表面是平坦的，例如纸张，并且线条对比度良好。
- en: If it is still struggling to find a line, increase the vertical blurring amount
    in steps of 5.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它仍然难以找到线条，以 5 为增量增加垂直模糊量。
- en: If it's struggling to turn in time for the line, try reducing the speed in increments
    of 10.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它难以按时转向直线，尝试以 10 为增量降低速度。
- en: 'If you find the camera is wobbling horizontally, you can remove the `self.robot.servos.stop_all()`
    line from `line_follow_behavior`. Beware: this comes at the cost of motor battery
    life.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您发现相机在水平方向上晃动，可以从 `line_follow_behavior` 中移除 `self.robot.servos.stop_all()`
    这一行。注意：这会以牺牲电机电池寿命为代价。
- en: If the robot is finding too much other random junk that isn't the line, try
    increasing the vertical blurring. Also, try increasing the threshold in steps
    of 1 or 2\. The sharper the contrast in brightness, the less you should need to
    do this.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器人发现太多其他随机垃圾而不是线条，尝试增加垂直模糊度。此外，尝试以 1 或 2 的步长增加阈值。亮度对比度越尖锐，您需要做的就越少。
- en: Ensure that you double-check the code and that you have got the previous examples
    here and from [*Chapter 13*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283),
    *Robot Vision – Using a Pi Camera and OpenCV*, to work.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您已经双重检查了代码，并且您已经在这里以及从 [*第 13 章*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283)，*机器人视觉
    – 使用 Pi 相机和 OpenCV* 中找到了之前的例子。
- en: Finding a line again
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 再次找到线条
- en: An important thing to consider is what the robot should do if it has lost the
    line. Coming back to our examples of an industrial setting, this could be a safety
    measure.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的一个重要问题是，如果机器人失去了线条，它应该做什么。回到我们工业环境的例子，这可能是一个安全措施。
- en: Our current robot stops. That requires you to put it back on the line. However,
    when you do so, the robot immediately starts moving again. This behavior is fine
    for our little robot, but it could be a dangerous hazard for a large robot.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Another behavior that you could consider is to spin until the robot finds the
    line again. Losing a line can be because the robot has under/oversteered off the
    line and couldn't find it again, or it could be because the robot has gone past
    the end of a line. This behavior is suitable perhaps for small robot competitions.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: We need to consider things like this carefully and where you would use the robot.
    Note that for competition-type robots, or industrial robots, they will have either
    multiple sensors at different angles or a wider angled sensor – so, they are far
    less likely to lose the line like ours. Also, spinning for a larger robot, even
    slowly, could be very hazardous behavior. For this reason, let's implement a simple
    additional safety-type feature.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: 'When it fails to find the line, it doesn''t just stop the motors; it will set
    the running flag to false, so you need to start it manually again:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: Open the `line_follow_behavior.py` file again.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the `run` method and find the `else:` statement.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we can modify the content of this statement:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Save the code to the robot, and run it until it loses the line. This could be
    by going off course or by reaching the end of the line. The robot should stop.
    It should wait for you to press the start button before trying to move again.
    Notice that you'll need to place it back on the line and press start for it to
    go again.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: This robot now handles a lost line condition more predictably.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you saw how to use the camera to detect a line and how to plot
    data showing what it found. You then saw how to take this data and put it into
    driving behavior so that the robot follows the line. You added to your OpenCV
    knowledge, and I showed you a sneaky way to put graphs into frames rendered on
    the camera stream output. You saw how to tune the PID to make the line following
    more accurate and how to ensure the robot stops predictably when it has lost the
    line.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to communicate with our robot via a voice
    agent, Mycroft. You will add a microphone and speakers to a Raspberry Pi, then
    add speech recognition software. This will let us speak commands to a Raspberry
    Pi to send to the robot, and Mycroft will respond to let us know what it has done.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''ve got this to work, there are ways we could enhance the system
    and make it more interesting:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Could you use `cv2.putText` to draw values such as the PID data onto the frames
    in the `make_display` method?
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider writing the PID and error data versus time to a file, then loading
    it into another Python file, using Matplotlib to show what happened. This change
    might make the under/oversteer clearer in retrospect.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You could modify the motor handling code to go faster when the line is closer
    to the middle and slow down when it is further.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以修改电机处理代码，当线条靠近中间时加速，远离中间时减速。
- en: A significant enhancement would be to check two rows and find the angle between
    them. You then know how far the line is from the middle, but you also know which
    way the line is headed and could use that to guide your steering further.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个重要的改进是检查两行并找出它们之间的角度。这样你就知道线条离中间有多远，同时你也知道线条的方向，可以利用这一点来进一步引导你的转向。
- en: These exercises should give you some interesting ways to play and experiment
    with the things you've built and learned in this chapter.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习应该会给你一些有趣的玩法和实验你在这章中学到的构建和知识的方法。
- en: Further reading
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The following should help you look further into line following:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容可以帮助你进一步了解跟随线条：
- en: Read about an alternative approach for line processing in the Go language on
    the Raspberry Pi from Pi Wars legend Brian Starkey at [https://blog.usedbytes.com/2019/02/autonomous-challenge-blast-off/](https://blog.usedbytes.com/2019/02/autonomous-challenge-blast-off/).
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Pi Wars传奇人物布莱恩·斯塔基的博客中了解Go语言在树莓派上处理线的替代方法：[https://blog.usedbytes.com/2019/02/autonomous-challenge-blast-off/](https://blog.usedbytes.com/2019/02/autonomous-challenge-blast-off/).
- en: 'Here is another line-following robot, using an approach like ours but more
    sophisticated: [https://www.raspberrypi.org/blog/an-image-processing-robot-for-robocup-junior/](https://www.raspberrypi.org/blog/an-image-processing-robot-for-robocup-junior/).'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这里还有一个使用类似我们方法但更为复杂的跟随线条的机器人：[https://www.raspberrypi.org/blog/an-image-processing-robot-for-robocup-junior/](https://www.raspberrypi.org/blog/an-image-processing-robot-for-robocup-junior/).
