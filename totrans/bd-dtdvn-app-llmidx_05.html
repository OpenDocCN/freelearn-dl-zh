<html><head></head><body><html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Indexing data – a bird’s-eye view&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-108">&#13;
    Indexing data – a bird’s-eye view&#13;
   </html:h1>&#13;
   <html:div id="_idContainer052">&#13;
    <html:p>&#13;
     We briefly discussed the importance&#13;
     <html:a id="_idIndexMarker362">&#13;
     </html:a>&#13;
     and general functioning of Indexes in a RAG application in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 3&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     , in the section titled&#13;
     <html:em class="italic">&#13;
      Uncovering the essential building blocks of LlamaIndex – documents, nodes, indexes&#13;
     </html:em>&#13;
     . Now, it is time to have a closer look at the different indexing methods available in LlamaIndex with their advantages, disadvantages, and specific&#13;
     <html:span class="No-Break">&#13;
      use cases.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In principle, data can be accessed even without an Index. But it’s like reading a book without a table of contents. As long as it’s about a story that has continuity and can be read sequentially, section by section, and chapter by chapter, reading will be a pleasure. However, things change when we need to quickly search for a specific topic in that book. Without a table of contents, the search process will be slow&#13;
     <html:span class="No-Break">&#13;
      and cumbersome.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In LlamaIndex, however,&#13;
     <html:strong class="bold">&#13;
      Indexes&#13;
     </html:strong>&#13;
     represent more than just&#13;
     <html:a id="_idIndexMarker363">&#13;
     </html:a>&#13;
     a simple table of contents. An Index provides not only the necessary structure for navigation but also the concrete mechanisms to update or access it. That includes the logic for the&#13;
     <html:strong class="bold">&#13;
      retrievers&#13;
     </html:strong>&#13;
     and the mechanisms used for fetching&#13;
     <html:a id="_idIndexMarker364">&#13;
     </html:a>&#13;
     data, which we will discuss in detail during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 6&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Querying Our Data, Part 1 –&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Context Retrieval&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this book, I’ve kept things simple, giving you the basics of how Indexes work and providing some examples to help you understand their usage. Exploring every possible way to use and mix these Indexes would be a huge task and that’s not what we’re&#13;
     <html:span class="No-Break">&#13;
      about here.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’ll talk later about what makes each type of Index unique, but first, let’s see what they all have&#13;
     <html:span class="No-Break">&#13;
      in common.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor108">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-109">&#13;
     Common features of all Index types&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Each type of Index in LlamaIndex has its own characteristics and functions, but because all of them inherit the&#13;
     <html:code class="literal">&#13;
      BaseIndex&#13;
     </html:code>&#13;
     class, there are certain features and parameters they share, which can be customized&#13;
     <html:a id="_idIndexMarker365">&#13;
     </html:a>&#13;
     for any kind&#13;
     <html:span class="No-Break">&#13;
      of Index:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Nodes&#13;
      </html:strong>&#13;
      : All Indexes are based on nodes and we can choose which Nodes are included in the Index. Plus, all Index types provide methods to insert new Nodes or delete existing ones, allowing for dynamic updates to the Index as your data changes. We can either build an Index from pre-existing Nodes by providing the Nodes directly to the Index constructor like this&#13;
      <html:code class="literal">&#13;
       vector_index = VectorStoreIndex(nodes)&#13;
      </html:code>&#13;
      or we can provide a list of documents as an input using&#13;
      <html:code class="literal">&#13;
       from_documents()&#13;
      </html:code>&#13;
      and let the Index extract the Nodes by itself. Keep in mind that we can use&#13;
      <html:code class="literal">&#13;
       Settings&#13;
      </html:code>&#13;
      – before actually building the Index – to customize its underlying mechanics. As we discussed during&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Chapter 3&#13;
        </html:em>&#13;
       </html:span>&#13;
      </html:a>&#13;
      in the&#13;
      <html:em class="italic">&#13;
       Understanding how settings can be used for customization&#13;
      </html:em>&#13;
      section, this simple class allows for different settings such as changing the LLM, embedding model, or default Node parser used by&#13;
      <html:span class="No-Break">&#13;
       an Index.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       The storage context&#13;
      </html:strong>&#13;
      : The storage context defines how and where the data (documents and nodes) for the Index is stored. This customization is crucial for managing data storage efficiently, depending on the&#13;
      <html:span class="No-Break">&#13;
       application’s requirements.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Progress display&#13;
      </html:strong>&#13;
      : The&#13;
      <html:code class="literal">&#13;
       show_progress&#13;
      </html:code>&#13;
      option lets us choose whether to display progress bars during long-running operations such as building the Index. Implemented using the&#13;
      <html:code class="literal">&#13;
       tqdm&#13;
      </html:code>&#13;
      Python library, this feature can be useful for monitoring the progress of large&#13;
      <html:span class="No-Break">&#13;
       indexing tasks.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Different retrieval modes&#13;
      </html:strong>&#13;
      : Each Index allows for different pre-defined retrieval modes, which can be set to match the specific needs of your application. And you can also customize or extend the Retriever classes to change how queries are processed and how results are retrieved from the Index. More on that during&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Chapter 6&#13;
        </html:em>&#13;
       </html:span>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Querying Our Data, Part 1 –&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Context Retrieval.&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Asynchronous operations&#13;
      </html:strong>&#13;
      : The&#13;
      <html:code class="literal">&#13;
       use_async&#13;
      </html:code>&#13;
      parameter implemented by some of the Indexes determines whether certain operations should be performed asynchronously. Asynchronous processing allows the system to manage multiple operations concurrently, rather than waiting for each operation to be completed sequentially. This can be important for performance optimization, especially&#13;
      <html:a id="_idIndexMarker366">&#13;
      </html:a>&#13;
      when dealing with large datasets or&#13;
      <html:span class="No-Break">&#13;
       complex operations.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p class="callout-heading">&#13;
     Quick note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     An important thing to consider before diving further and starting to tinker with the sample code is that indexing often relies on LLM calls for summarizing or embedding purposes. Just like in the case of metadata extraction, which we covered in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 4&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Ingesting Data into Our RAG Workflow&#13;
     </html:em>&#13;
     , indexing in LlamaIndex may also raise cost and privacy concerns. Make sure you read the cost-related section at the end of this chapter before running any large-scale experiments to test&#13;
     <html:span class="No-Break">&#13;
      your ideas.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s start with our first and most frequently used&#13;
     <html:span class="No-Break">&#13;
      Index type.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor109">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Understanding the VectorStoreIndex&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 class="H1---Chapter" id="_idParaDest-110">&#13;
    Understanding the VectorStoreIndex&#13;
   </html:h1>&#13;
   <html:div id="_idContainer052">&#13;
    from llama_index.core import VectorStoreIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index = VectorStoreIndex.from_documents(documents)&#13;
print("Index created successfully!")&#13;
    pip install llama-index-embeddings-huggingface&#13;
    from llama_index.embeddings.huggingface import HuggingFaceEmbedding&#13;
embedding_model = HuggingFaceEmbedding(&#13;
    model_name="WhereIsAI/UAE-Large-V1"&#13;
)&#13;
embeddings = embedding_model.get_text_embedding(&#13;
    "The quick brown fox jumps over the lazy cat!"&#13;
)&#13;
print(embeddings[:15])&#13;
    <html:p style="font-style:italic;">&#13;
     As this ebook edition doesn't have fixed pagination, the page numbers below are hyperlinked for reference only, based on the printed edition of this book.&#13;
    </html:p>&#13;
    <html:p>&#13;
     In LlamaIndex, the&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     stands out&#13;
     <html:a id="_idIndexMarker367">&#13;
     </html:a>&#13;
     as the workhorse, being the most commonly utilized type&#13;
     <html:span class="No-Break">&#13;
      of Index.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For most RAG applications, a&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     might be the best solution because it facilitates the construction&#13;
     <html:a id="_idIndexMarker368">&#13;
     </html:a>&#13;
     of Indexes on collections of Documents where&#13;
     <html:strong class="bold">&#13;
      embeddings&#13;
     </html:strong>&#13;
     for the input text chunks&#13;
     <html:a id="_idIndexMarker369">&#13;
     </html:a>&#13;
     are stored within the&#13;
     <html:strong class="bold">&#13;
      Vector Store&#13;
     </html:strong>&#13;
     of the Index. Once constructed, this Index can be used for efficient&#13;
     <html:a id="_idIndexMarker370">&#13;
     </html:a>&#13;
     querying because it allows for&#13;
     <html:strong class="bold">&#13;
      similarity searches&#13;
     </html:strong>&#13;
     over the embedded representations of the text, making it highly suitable for applications requiring fast retrieval of relevant information from a large collection of data. Don’t worry if you’re not yet familiar with terms such as embeddings, vector store, or similarity searching, because we’ll cover them in the following sections. The&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     class in LlamaIndex supports these operations by default and also allows for asynchronous calls and progress tracking, which can improve performance and user experience&#13;
     <html:a id="_idIndexMarker371">&#13;
     </html:a>&#13;
     in typical&#13;
     <html:span class="No-Break">&#13;
      RAG scenarios.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor110">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-111">&#13;
     A simple usage example for the VectorStoreIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Here’s the most basic&#13;
     <html:a id="_idIndexMarker372">&#13;
     </html:a>&#13;
     way of constructing&#13;
     <html:span class="No-Break">&#13;
      a&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       VectorStoreIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As you can see, in just a few lines of code, we have ingested the Documents and the&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     took care of everything. Note that using this approach, we have skipped the Node parsing step entirely, because the Index did that by itself by using&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       from_documents()&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      method.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There are several parameters&#13;
     <html:a id="_idIndexMarker373">&#13;
     </html:a>&#13;
     that we can customize for&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       VectorStoreIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       use_async&#13;
      </html:code>&#13;
      : This parameter enables asynchronous calls. By default, it is set&#13;
      <html:span class="No-Break">&#13;
       to&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        False&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       show_progress&#13;
      </html:code>&#13;
      : This parameter shows progress bars during Index construction. The default value&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        False&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       store_nodes_override&#13;
      </html:code>&#13;
      : This parameter forces LlamaIndex to store Node objects in the Index store and document store, even if the vector store keeps text. This can be useful in scenarios where you need direct access to Node objects, even if their content is already stored in the vector store. We’ll talk in more detail about the Index store, document store, and vector store later in this chapter. The default setting for this parameter&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        False&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Let’s have a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .1&#13;
     </html:em>&#13;
     for a visual representation of this type&#13;
     <html:span class="No-Break">&#13;
      of Index:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer040">&#13;
      <html:img src="img/B21861_05_1.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.1 – The structure of a VectorStoreIndex&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     took the ingested Documents, breaking them down into Nodes. It used the default parameters for text splitter, chunk size, chunk overlap, and so on. Of course, we could have customized all these parameters if we&#13;
     <html:span class="No-Break">&#13;
      wanted to.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     <html:strong class="bold">&#13;
      Fixed-size chunking&#13;
     </html:strong>&#13;
     simply splits text into same-sized&#13;
     <html:a id="_idIndexMarker374">&#13;
     </html:a>&#13;
     chunks, optionally with some overlap. Although computationally cheap and simple to implement, this simple chunking may not always be the best approach. Performance testing various chunk sizes is key to optimizing for an application’s&#13;
     <html:span class="No-Break">&#13;
      particular needs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The nodes containing chunks&#13;
     <html:a id="_idIndexMarker375">&#13;
     </html:a>&#13;
     of the original text were then&#13;
     <html:em class="italic">&#13;
      embedded&#13;
     </html:em>&#13;
     into a high-dimensional vector space using a language model. The embedded vectors were stored within the vector store component of the Index. Next, when a query is made, the query text will be similarly embedded and compared against&#13;
     <html:a id="_idIndexMarker376">&#13;
     </html:a>&#13;
     the stored vectors using a&#13;
     <html:strong class="bold">&#13;
      similarity measure&#13;
     </html:strong>&#13;
     identified with a method called&#13;
     <html:strong class="bold">&#13;
      cosine similarity&#13;
     </html:strong>&#13;
     . The most similar&#13;
     <html:a id="_idIndexMarker377">&#13;
     </html:a>&#13;
     vectors – and thus the most relevant document chunks – will be returned as the query result. This process enables rapid, semantically aware retrieval of information, leveraging the mathematical properties of vector spaces to find the documents that best answer the&#13;
     <html:span class="No-Break">&#13;
      user’s query.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Sounds a bit confusing? Let’s go through these concepts together in the&#13;
     <html:span class="No-Break">&#13;
      next section.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor111">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-112">&#13;
     Understanding embeddings&#13;
    </html:h2>&#13;
    <html:p>&#13;
     In simple terms,&#13;
     <html:strong class="bold">&#13;
      vector embeddings&#13;
     </html:strong>&#13;
     represent a machine-understandable&#13;
     <html:a id="_idIndexMarker378">&#13;
     </html:a>&#13;
     data format. They capture meaning and may conceptually represent a word, an entire document, or even non-textual information such as images and sounds. In a way, embeddings represent a standard language of thought for an LLM. In the context of an LLM, they serve as a foundational representation through which the model understands and processes information. They transform diverse and complex data into a uniform, high-dimensional space where the LLM can perform operations such as comparison, association, and prediction more effectively.&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .2&#13;
     </html:em>&#13;
     provides an illustration of the process of&#13;
     <html:span class="No-Break">&#13;
      embedding data:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer041">&#13;
      <html:img src="img/B21861_05_2.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.2 – How an embedding model converts data into numerical representations&#13;
    </html:p>&#13;
    <html:p>&#13;
     Because it’s all about math under the hood. And math works well with numbers – more precisely, large lists of floating-point numbers, where each number represents a dimension in a hypothetical vector space. The LLM can work with these arrays of numbers to understand, interpret, and generate responses based on the input it receives. Essentially, these numbers in the vector embeddings allow the LLM to&#13;
     <html:em class="italic">&#13;
      see&#13;
     </html:em>&#13;
     and&#13;
     <html:em class="italic">&#13;
      think&#13;
     </html:em>&#13;
     about the data in a way that’s meaningful&#13;
     <html:span class="No-Break">&#13;
      and structured.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The beauty of this system lies in its ability to handle ambiguity and complexity. The model can understand semantic relationships between words, such as synonyms, antonyms, and more complex linguistic patterns. In the case of polysemous words, the same word can have different meanings in different contexts. For example, the word&#13;
     <html:em class="italic">&#13;
      bank&#13;
     </html:em>&#13;
     can refer to the side of a river or a financial institution. Vector embeddings help the LLM understand these nuances by providing context-sensitive representations. So, in one situation,&#13;
     <html:em class="italic">&#13;
      bank&#13;
     </html:em>&#13;
     might be closely associated with words such as&#13;
     <html:em class="italic">&#13;
      river&#13;
     </html:em>&#13;
     and&#13;
     <html:em class="italic">&#13;
      shore&#13;
     </html:em>&#13;
     , while in another, it’s more closely linked to&#13;
     <html:em class="italic">&#13;
      money&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      and&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       account&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Quick note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     An important factor to consider is that the size of text chunks being embedded impacts precision – too small and context is lost; too large and all that additional detail may dilute&#13;
     <html:span class="No-Break">&#13;
      the meaning.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In case you’re not very familiar with embeddings yet, the following example could be useful to get a better grasp of the concept. Let’s assign some&#13;
     <html:em class="italic">&#13;
      arbitrary&#13;
     </html:em>&#13;
     vector embeddings to three randomly&#13;
     <html:span class="No-Break">&#13;
      chosen sentences:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Sentence 1&#13;
      </html:strong>&#13;
      : The quick brown fox jumps over the&#13;
      <html:span class="No-Break">&#13;
       lazy dog&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Sentence 2&#13;
      </html:strong>&#13;
      : A fast dark-colored fox leaps above a&#13;
      <html:span class="No-Break">&#13;
       sleepy canine&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Sentence 3&#13;
      </html:strong>&#13;
      : Apples are sweet&#13;
      <html:span class="No-Break">&#13;
       and crunchy&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     In a real-world scenario, the embeddings associated with each of these sentences&#13;
     <html:a id="_idIndexMarker379">&#13;
     </html:a>&#13;
     would be calculated automatically by using an&#13;
     <html:strong class="bold">&#13;
      embedding model&#13;
     </html:strong>&#13;
     . This is a specialized artificial intelligence model used to convert complex data such as text, images, or graphs into a numerical format. The embeddings would also normally be high-dimensional, but for the sake of explanation, I’ll use simple, three-dimensional, arbitrarily chosen vectors. Here are the hypothetical embeddings for the&#13;
     <html:span class="No-Break">&#13;
      three sentences:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Sentence 1 Embedding&#13;
      </html:strong>&#13;
      : [0.8,&#13;
      <html:span class="No-Break">&#13;
       0.1, 0.3]&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Sentence 2 Embedding&#13;
      </html:strong>&#13;
      : [0.79,&#13;
      <html:span class="No-Break">&#13;
       0.14, 0.32]&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Sentence 3 Embedding&#13;
      </html:strong>&#13;
      : [0.2,&#13;
      <html:span class="No-Break">&#13;
       0.9, 0.5]&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     These numbers are purely&#13;
     <html:a id="_idIndexMarker380">&#13;
     </html:a>&#13;
     conceptual and are meant to show that sentences 1 and 2, which have similar meanings, have embeddings that are closer to each other in vector space.&#13;
     <html:em class="italic">&#13;
      Sentence 3&#13;
     </html:em>&#13;
     , which has a different meaning, has an embedding that is farther away from the first two. Have a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .3&#13;
     </html:em>&#13;
     for a straightforward visual comparison of the&#13;
     <html:span class="No-Break">&#13;
      three embeddings:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer042">&#13;
      <html:img src="img/B21861_05_3.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.3 – A comparison of the three embedded sentences in a 3D space&#13;
    </html:p>&#13;
    <html:p>&#13;
     When we visualize them in a three-dimensional space, sentences 1 and 2 are plotted near each other, while sentence 3 will be plotted at a distance. This spatial representation is what allows machine learning models to determine&#13;
     <html:span class="No-Break">&#13;
      semantic similarity.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     When you search using a query on a vector store Index in order to retrieve useful context, LlamaIndex converts your search terms into a similar embedding and then finds the closest matches among the pre-computed embeddings of your&#13;
     <html:span class="No-Break">&#13;
      text chunks.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We call this process&#13;
     <html:strong class="bold">&#13;
      similarity&#13;
     </html:strong>&#13;
     or&#13;
     <html:strong class="bold">&#13;
      distance search&#13;
     </html:strong>&#13;
     . So, when you encounter&#13;
     <html:a id="_idIndexMarker381">&#13;
     </html:a>&#13;
     the term&#13;
     <html:strong class="bold">&#13;
      top-k similarity search&#13;
     </html:strong>&#13;
     , you should know that it relies&#13;
     <html:a id="_idIndexMarker382">&#13;
     </html:a>&#13;
     on an algorithm&#13;
     <html:a id="_idIndexMarker383">&#13;
     </html:a>&#13;
     that calculates&#13;
     <html:a id="_idIndexMarker384">&#13;
     </html:a>&#13;
     the similarity between vector embeddings. It takes a vector embedding as an input and returns the most similar&#13;
     <html:em class="italic">&#13;
      k&#13;
     </html:em>&#13;
     number of vectors found in the vector store. Because the initial vector and the&#13;
     <html:em class="italic">&#13;
      top-k&#13;
     </html:em>&#13;
     returned neighbors are similar to each other, we can consider their meanings to be conceptually similar. Now you understand why&#13;
     <html:a id="_idIndexMarker385">&#13;
     </html:a>&#13;
     I have previously called embeddings a&#13;
     <html:em class="italic">&#13;
      standard language of thought&#13;
     </html:em>&#13;
     for an LLM. It doesn’t really matter anymore whether they represent text, images, or any other types of information. We measure their similarity&#13;
     <html:span class="No-Break">&#13;
      in numbers.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The only thing that may be implemented differently, depending on our use case, is the actual formula for defining&#13;
     <html:a id="_idIndexMarker386">&#13;
     </html:a>&#13;
     that distance&#13;
     <html:span class="No-Break">&#13;
      or similarity.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Spoiler alert: a bit of mathematical concepts&#13;
     <html:span class="No-Break">&#13;
      up next.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor112">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-113">&#13;
     Understanding similarity search&#13;
    </html:h2>&#13;
    <html:p>&#13;
     In the realms of machine learning&#13;
     <html:a id="_idIndexMarker387">&#13;
     </html:a>&#13;
     and deep learning, the concept of similarity search is very important. It forms the backbone of many applications, from recommendation systems and information retrieval to clustering and classification tasks. As models and systems interact with high-dimensional data, identifying patterns and relationships between data points becomes essential. This involves measuring how&#13;
     <html:em class="italic">&#13;
      close&#13;
     </html:em>&#13;
     or&#13;
     <html:em class="italic">&#13;
      similar&#13;
     </html:em>&#13;
     data elements are, a task that often takes place in a vector space where each item is represented as&#13;
     <html:span class="No-Break">&#13;
      a vector.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Locating points in this space that are near each other enables machines to assess similarity and, by extension, to make decisions, draw inferences, or, in our case, retrieve information based on that assessment of closeness. With the advent of embeddings in deep learning, the need for effective similarity search has grown. As embeddings capture the semantic meaning of the data they represent, performing similarity searches on these vectors allows machines to understand content at a level approaching&#13;
     <html:span class="No-Break">&#13;
      human cognition.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s explore the methods that LlamaIndex currently employs to measure the similarity between vectors, each with its unique advantages&#13;
     <html:span class="No-Break">&#13;
      and applicability.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Cosine similarity&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This method measures&#13;
     <html:a id="_idIndexMarker388">&#13;
     </html:a>&#13;
     the cosine&#13;
     <html:a id="_idIndexMarker389">&#13;
     </html:a>&#13;
     of&#13;
     <html:em class="italic">&#13;
      the angle&#13;
     </html:em>&#13;
     between two vectors. Imagine two arrows pointing in different directions; the smaller the angle between them, the more similar&#13;
     <html:span class="No-Break">&#13;
      they are.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Have a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .4&#13;
     </html:em>&#13;
     , which depicts a cosine similarity comparison between&#13;
     <html:span class="No-Break">&#13;
      two vectors:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer043">&#13;
      <html:img src="img/B21861_05_4.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.4 – How a cosine similarity comparison would look&#13;
    </html:p>&#13;
    <html:p>&#13;
     In terms of embeddings, a small angle (or a high cosine similarity score, close to 1) indicates that the content they represent is similar. This method is particularly useful in text analysis because it is less affected by the length of the documents and focuses more on their direction&#13;
     <html:a id="_idIndexMarker390">&#13;
     </html:a>&#13;
     or orientation&#13;
     <html:a id="_idIndexMarker391">&#13;
     </html:a>&#13;
     in the&#13;
     <html:span class="No-Break">&#13;
      vector space.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Cosine similarity is also the default method used by LlamaIndex for calculating similarity&#13;
     <html:span class="No-Break">&#13;
      between embeddings.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Dot product&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Also called the&#13;
     <html:strong class="bold">&#13;
      scalar product&#13;
     </html:strong>&#13;
     , because it is represented&#13;
     <html:a id="_idIndexMarker392">&#13;
     </html:a>&#13;
     by a single value, this&#13;
     <html:a id="_idIndexMarker393">&#13;
     </html:a>&#13;
     is another method&#13;
     <html:a id="_idIndexMarker394">&#13;
     </html:a>&#13;
     of calculating how well two vectors align with each other. To calculate the scalar product of two vectors, the algorithm multiplies the corresponding elements of the vectors and then sums&#13;
     <html:span class="No-Break">&#13;
      these products.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s take a simple example of&#13;
     <html:em class="italic">&#13;
      vector A&#13;
     </html:em>&#13;
     : [2,3] and&#13;
     <html:em class="italic">&#13;
      vector B&#13;
     </html:em>&#13;
     : [4,1]. The&#13;
     <html:strong class="bold">&#13;
      dot product&#13;
     </html:strong>&#13;
     is calculated by multiplying their corresponding elements: (2×4) + (3×1), which gives us 8 + 3 = 11. Thus, the dot product of these two vectors&#13;
     <html:span class="No-Break">&#13;
      is 11.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .5&#13;
     </html:em>&#13;
     exemplifies&#13;
     <html:span class="No-Break">&#13;
      this concept:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer044">&#13;
      <html:img src="img/B21861_05_5.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.5 – Calculating similarity using the dot product method&#13;
    </html:p>&#13;
    <html:p>&#13;
     In the preceding diagram, the dot product is visualized by projecting one vector onto the other. This projection illustrates the geometric interpretation of the dot product. It’s calculated by projecting the components of one vector in the direction of the other and then multiplying these projected components by the corresponding components of the second vector. The sum of these products gives us the dot product. This visualization helps us understand that the dot product is not just a measure of how vectors point in the same direction; it also incorporates&#13;
     <html:span class="No-Break">&#13;
      their lengths.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Higher values of the dot product mean higher similarities between vectors. In contrast with the cosine method, the dot&#13;
     <html:a id="_idIndexMarker395">&#13;
     </html:a>&#13;
     product is sensitive both to the length&#13;
     <html:a id="_idIndexMarker396">&#13;
     </html:a>&#13;
     of the two vectors compared and their relative direction. Unlike the dot product, cosine similarity normalizes the dot product by the magnitudes of the vectors. This normalization makes cosine similarity solely a measure of the directional alignment between vectors, independent of&#13;
     <html:span class="No-Break">&#13;
      their lengths.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The longer the vectors, the higher the result, and this is an important thing to consider in a RAG scenario. Longer vectors, which might represent longer documents or more detailed information, could dominate the retrieved results due to their inherently larger dot product values. This could bias the system toward retrieving longer&#13;
     <html:a id="_idIndexMarker397">&#13;
     </html:a>&#13;
     documents, even if they&#13;
     <html:a id="_idIndexMarker398">&#13;
     </html:a>&#13;
     are not the&#13;
     <html:span class="No-Break">&#13;
      most relevant.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Euclidean distance&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This method is different&#13;
     <html:a id="_idIndexMarker399">&#13;
     </html:a>&#13;
     from the dot product and cosine similarity&#13;
     <html:a id="_idIndexMarker400">&#13;
     </html:a>&#13;
     methods. While those methods look at the angle or alignment between vectors,&#13;
     <html:strong class="bold">&#13;
      Euclidean distance&#13;
     </html:strong>&#13;
     is all about how close the actual values of the vectors are to each other. This can be especially useful when the values in the vectors represent actual counts or measurements, especially where the vector dimensions have real-world&#13;
     <html:span class="No-Break">&#13;
      physical interpretations.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Take a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .6&#13;
     </html:em>&#13;
     for a visual representation of&#13;
     <html:span class="No-Break">&#13;
      Euclidean distance:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer045">&#13;
      <html:img src="img/B21861_05_6.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.6 – The Euclidean distance between two vectors&#13;
    </html:p>&#13;
    <html:p>&#13;
     You should now have a foundational understanding of embeddings, how vector similarity works, and, in particular, how they are implemented in LlamaIndex. If you want to familiarize yourself better with this concept, you can find more information on&#13;
     <html:span class="No-Break">&#13;
      the web.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here are some&#13;
     <html:a id="_idIndexMarker401">&#13;
     </html:a>&#13;
     suggested&#13;
     <html:a id="_idIndexMarker402">&#13;
     </html:a>&#13;
     additional reading resources&#13;
     <html:a id="_idIndexMarker403">&#13;
     </html:a>&#13;
     you could start&#13;
     <html:span class="No-Break">&#13;
      with:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://developers.google.com/machine-learning/clustering/similarity/measuring-similarity&#13;
      </html:span>&#13;
     </html:a>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor113">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-114">&#13;
     OK, but how does LlamaIndex generate these embeddings?&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The short answer is,&#13;
     <html:em class="italic">&#13;
      however, you prefer&#13;
     </html:em>&#13;
     . By default, the framework&#13;
     <html:a id="_idIndexMarker404">&#13;
     </html:a>&#13;
     is configured to rely on OpenAI’s&#13;
     <html:code class="literal">&#13;
      text-embedding-ada-002&#13;
     </html:code>&#13;
     model. This model has been trained to produce embeddings that effectively capture semantic meanings of the text, enabling applications such as semantic search, topic clustering, anomaly detection, and others. It provides a very good balance between quality, performance, and cost. LlamaIndex uses this model by default to embed documents during Index construction as well as for&#13;
     <html:span class="No-Break">&#13;
      query embeddings.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Sometimes, though, when you may want to index large volumes of data, the cost associated with a hosted model such as this one may be too high for your budget. In other instances, you might be concerned about the privacy of your proprietary data and prefer to use a local model instead. Or maybe, in some cases, you may want to use more specialized models for a particular topic or&#13;
     <html:span class="No-Break">&#13;
      technical domain.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The great news is that LlamaIndex also supports a variety of other embedding models. For example, if you wish to use local models, you can set the service context to use a local embedding, which uses a well-balanced&#13;
     <html:a id="_idIndexMarker405">&#13;
     </html:a>&#13;
     default model provided by&#13;
     <html:em class="italic">&#13;
      Hugging Face&#13;
     </html:em>&#13;
     (&#13;
     <html:a>&#13;
      https://huggingface.co/BAAI/bge-small-en-v1.5&#13;
     </html:a>&#13;
     ). This can be particularly useful if you aim to reduce costs or have requirements to process&#13;
     <html:span class="No-Break">&#13;
      data locally.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A brief introduction to Hugging Face&#13;
    </html:h3>&#13;
    <html:p>&#13;
     <html:strong class="bold">&#13;
      Hugging Face&#13;
     </html:strong>&#13;
     is a very important resource&#13;
     <html:a id="_idIndexMarker406">&#13;
     </html:a>&#13;
     in the AI field, primarily known&#13;
     <html:a id="_idIndexMarker407">&#13;
     </html:a>&#13;
     for its extensive collection&#13;
     <html:a id="_idIndexMarker408">&#13;
     </html:a>&#13;
     of pre-trained machine learning models, especially in&#13;
     <html:strong class="bold">&#13;
      natural&#13;
     </html:strong>&#13;
     <html:strong class="bold">&#13;
      language processing&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      NLP&#13;
     </html:strong>&#13;
     ). Its importance lies in democratizing access to state-of-the-art AI models, tools, and techniques, enabling developers and researchers to implement advanced AI functionalities&#13;
     <html:a id="_idIndexMarker409">&#13;
     </html:a>&#13;
     with relative ease. Similar to GitHub, Hugging Face embraces&#13;
     <html:a id="_idIndexMarker410">&#13;
     </html:a>&#13;
     a community-driven approach, where users can share, collaborate on, and improve AI models, much like developers share and contribute to code repositories on GitHub. This community-centric model accelerates innovation and dissemination of&#13;
     <html:span class="No-Break">&#13;
      AI advancements.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Before running the next sample, make sure you install the&#13;
     <html:span class="No-Break">&#13;
      necessary integration:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This example will show you how to set up a local&#13;
     <html:span class="No-Break">&#13;
      embedding model:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     On the first run, the code will download the&#13;
     <html:code class="literal">&#13;
      Universal AnglE Embedding&#13;
     </html:code>&#13;
     model from Hugging Face. This is one of the best-performing embedding models at the moment, offering great overall performance and&#13;
     <html:span class="No-Break">&#13;
      quality balance.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     More info is available&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://huggingface.co/WhereIsAI/UAE-Large-V1&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     After downloading and initializing the embedding model, the script calculates the embeddings for the sentence and displays the first 15 values of&#13;
     <html:span class="No-Break">&#13;
      the vector.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For advanced users or specific applications, LlamaIndex makes it easy to integrate custom embedding models. You can simply extend the&#13;
     <html:code class="literal">&#13;
      BaseEmbedding&#13;
     </html:code>&#13;
     class provided by LlamaIndex and implement your own logic for&#13;
     <html:span class="No-Break">&#13;
      generating embeddings.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here, you can find&#13;
     <html:a id="_idIndexMarker411">&#13;
     </html:a>&#13;
     an example of how to define your custom embedding&#13;
     <html:span class="No-Break">&#13;
      class:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/examples/embeddings/custom_embeddings.html&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Apart from OpenAI and local&#13;
     <html:a id="_idIndexMarker412">&#13;
     </html:a>&#13;
     models, there are integrations with Langchain, enabling&#13;
     <html:a id="_idIndexMarker413">&#13;
     </html:a>&#13;
     you to use any embedding model they offer. You also have the option to use embedding models from Azure, CohereAI, and other providers through additional integrations offered by LlamaIndex. This great flexibility ensures that no matter your needs or constraints, you can configure LlamaIndex to use an embedding model that is suitable for&#13;
     <html:span class="No-Break">&#13;
      your application.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor114">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-115">&#13;
     How do I decide which embedding model I should use?&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The choice of embedding model&#13;
     <html:a id="_idIndexMarker414">&#13;
     </html:a>&#13;
     can significantly affect the performance, quality, and cost of your RAG app. Here are some key points to consider when choosing a&#13;
     <html:span class="No-Break">&#13;
      particular model:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Qualitative performance&#13;
      </html:strong>&#13;
      : Different embedding models may encode the semantics of the text in different ways. While embeddings of models such as OpenAI’s Ada are designed to have a broad understanding of text, other models might be fine-tuned on specific domains or tasks and would outperform in those scenarios. Domain-specific models could lead to more accurate representations of&#13;
      <html:span class="No-Break">&#13;
       specialized topics&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Quantitative performance&#13;
      </html:strong>&#13;
      : This includes factors such as how well the model captures semantic similarity, its performance on benchmarks, and generalization to unseen data. This can vary considerably between different models and domains of application. For a general benchmark&#13;
      <html:a id="_idIndexMarker415">&#13;
      </html:a>&#13;
      of the most popular models, you can consult the&#13;
      <html:strong class="bold">&#13;
       Massive Text Embedding Benchmark&#13;
      </html:strong>&#13;
      <html:em class="italic">&#13;
      </html:em>&#13;
      (&#13;
      <html:strong class="bold">&#13;
       MTEB&#13;
      </html:strong>&#13;
      ) Leaderboard (&#13;
      <html:a>&#13;
       https://huggingface.co/spaces/mteb/leaderboard&#13;
      </html:a>&#13;
      ) on the Hugging&#13;
      <html:span class="No-Break">&#13;
       Face website.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Latency and throughput&#13;
      </html:strong>&#13;
      : For applications with real-time constraints or large volumes of data, the speed of the embedding model could be a deciding factor. Also consider the maximum input chunk sizes that models can handle, which impacts how text is divided for embedding. Keep in mind that your Nodes will have embeddings computed during ingestion, so that will not affect your overall application performance. However, during retrieval, each query will have to be embedded in real time so that similarity can be measured and the relevant nodes can be retrieved. This is where latency and throughput&#13;
      <html:span class="No-Break">&#13;
       become important.&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       To get an idea of how different embedding models may perform, have a look at this&#13;
       <html:span class="No-Break">&#13;
        article:&#13;
       </html:span>&#13;
       <html:a>&#13;
        <html:span class="No-Break">&#13;
         https://blog.getzep.com/text-embedding-latency-a-semi-scientific-look/&#13;
        </html:span>&#13;
       </html:a>&#13;
       <html:span class="No-Break">&#13;
        .&#13;
       </html:span>&#13;
      </html:p>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Multilingual support&#13;
      </html:strong>&#13;
      : Embedding models can be multilingual or trained for a specific language. Depending on your use case, this can also become an important decision factor. For example, smaller models such as&#13;
      <html:code class="literal">&#13;
       Mistral&#13;
      </html:code>&#13;
      could provide excellent results on par with hosted models such as GPT 3.5 for English data, but their performance in other languages is&#13;
      <html:span class="No-Break">&#13;
       clearly inferior&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Resource requirements&#13;
      </html:strong>&#13;
      : Embedding models can vary greatly in size and computational expense. Large models might provide more accurate embeddings but may require substantially more computational resources and thus lead to&#13;
      <html:span class="No-Break">&#13;
       higher costs.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Availability&#13;
      </html:strong>&#13;
      : Some embedding models may only be available through certain APIs or require specific software to be installed, which could affect ease of integration and usage. Fortunately, you have a high degree of customization available&#13;
      <html:span class="No-Break">&#13;
       in LlamaIndex.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       On-device or local usage&#13;
      </html:strong>&#13;
      : You may prefer to use a local model when data privacy is a concern or when operating in an environment with limited or no&#13;
      <html:span class="No-Break">&#13;
       internet access.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Usage cost&#13;
      </html:strong>&#13;
      : Consider the cost associated with API calls for cloud-based, hosted embedding models&#13;
      <html:a id="_idIndexMarker416">&#13;
      </html:a>&#13;
      versus the computational and storage costs of local&#13;
      <html:span class="No-Break">&#13;
       embedding models.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     The good news is that LlamaIndex supports many out-of-the-box embedding models and provides flexibility to use&#13;
     <html:span class="No-Break">&#13;
      various embeddings.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     By the way, a complete list&#13;
     <html:a id="_idIndexMarker417">&#13;
     </html:a>&#13;
     of supported models can be found&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#list-of-supported-embeddings&#13;
      </html:span>&#13;
     </html:a>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For most use cases, though, OpenAI’s default embedding model –&#13;
     <html:code class="literal">&#13;
      text-embedding-ada-002&#13;
     </html:code>&#13;
     – will provide you with a good balance between all the parameters we’ve discussed. However, if you have specific needs or constraints, you might benefit from exploring and benchmarking different models to see which provides the best outcomes for your&#13;
     <html:span class="No-Break">&#13;
      particular application.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Now that we know about embeddings, let us shift our focus to how to store and&#13;
     <html:span class="No-Break">&#13;
      reuse them.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor115">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Persisting and reusing Indexes&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-116">&#13;
    Persisting and reusing Indexes&#13;
   </html:h1>&#13;
   <html:div id="_idContainer052">&#13;
    from llama_index.core import VectorStoreIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader("data").load_data()&#13;
index = VectorStoreIndex.from_documents(documents)&#13;
    index.storage_context.persist(persist_dir="index_cache")&#13;
print("Index persisted to disk.")&#13;
    from llama_index.core import StorageContext, load_index_from_storage&#13;
storage_context = StorageContext.from_defaults(&#13;
    persist_dir="index_cache")&#13;
index = load_index_from_storage(storage_context)&#13;
print("Index loaded successfully!")&#13;
    pip install chromadb&#13;
    import chromadb&#13;
from llama_index.vector_stores.chroma import ChromaVectorStore&#13;
from llama_index.core import (&#13;
    VectorStoreIndex, SimpleDirectoryReader, StorageContext)&#13;
    db = chromadb.PersistentClient(path="chroma_database")&#13;
chroma_collection = db.get_or_create_collection(&#13;
    "my_chroma_store"&#13;
)&#13;
    vector_store = ChromaVectorStore(&#13;
    chroma_collection=chroma_collection&#13;
)&#13;
storage_context = StorageContext.from_defaults(&#13;
    vector_store=vector_store&#13;
)&#13;
    documents = SimpleDirectoryReader("files").load_data()&#13;
index = VectorStoreIndex.from_documents(&#13;
    documents=documents,&#13;
    storage_context=storage_context&#13;
)&#13;
    results = chroma_collection.get()&#13;
print(results)&#13;
    index = VectorStoreIndex.from_vector_store(&#13;
    vector_store=vector_store,&#13;
    storage_context=storage_context&#13;
)&#13;
    <html:p>&#13;
     An important question&#13;
     <html:a id="_idIndexMarker418">&#13;
     </html:a>&#13;
     arises – where exactly&#13;
     <html:a id="_idIndexMarker419">&#13;
     </html:a>&#13;
     can we store the vector embeddings generated during the&#13;
     <html:span class="No-Break">&#13;
      indexing process?&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Storing them is important&#13;
     <html:a id="_idIndexMarker420">&#13;
     </html:a>&#13;
     for&#13;
     <html:span class="No-Break">&#13;
      multiple reasons:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Avoid the computational cost of re-embedding documents and rebuilding Indexes in every session. Generating high-quality embeddings for large document collections requires significant processing that can become costly over time. Persisting Indexes preserves these&#13;
      <html:span class="No-Break">&#13;
       precomputed artifacts&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Enable low-latency processing. Avoiding runtime embedding and indexing by loading the already computed embeddings allows applications to get up and running&#13;
      <html:span class="No-Break">&#13;
       much faster&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Maintain query consistency and accuracy. Reloading an Index guarantees we reuse the exact vectors and structure used in the previous sessions. This promises consistent and accurate&#13;
      <html:span class="No-Break">&#13;
       query execution&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     If we want to avoid regenerating them on each run, these vector embeddings need to reside somewhere – a repository, if you will – that allows for efficient storage&#13;
     <html:span class="No-Break">&#13;
      and retrieval.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This is the job of a vector store&#13;
     <html:span class="No-Break">&#13;
      within LlamaIndex.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     By default, LlamaIndex uses an in-memory vector store, but for persistence, it offers a straightforward approach using the&#13;
     <html:code class="literal">&#13;
      .persist()&#13;
     </html:code>&#13;
     method available for any type of Index. This method writes all data to disk at a specified location,&#13;
     <html:span class="No-Break">&#13;
      ensuring persistence.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s see how we can persist and then load the vector embeddings. First, we create our Index, which handles the embedding&#13;
     <html:span class="No-Break">&#13;
      of documents:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     To persist this data, we use&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       persist()&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      method:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This saves the entire Index data to disk. In future sessions, we can easily reload&#13;
     <html:span class="No-Break">&#13;
      the data:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     By rebuilding a&#13;
     <html:code class="literal">&#13;
      StorageContext&#13;
     </html:code>&#13;
     from&#13;
     <html:a id="_idIndexMarker421">&#13;
     </html:a>&#13;
     the persisted&#13;
     <html:a id="_idIndexMarker422">&#13;
     </html:a>&#13;
     directory and using&#13;
     <html:code class="literal">&#13;
      load_index_from_storage&#13;
     </html:code>&#13;
     , we can effectively reconstitute our Index without needing to re-index&#13;
     <html:span class="No-Break">&#13;
      our data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor116">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-117">&#13;
     Understanding the StorageContext&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      StorageContext&#13;
     </html:code>&#13;
     serves as the unifying custodian&#13;
     <html:a id="_idIndexMarker423">&#13;
     </html:a>&#13;
     over configurable storage components&#13;
     <html:a id="_idIndexMarker424">&#13;
     </html:a>&#13;
     used during indexing and querying. Its key components are&#13;
     <html:span class="No-Break">&#13;
      as follows:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      The&#13;
      <html:strong class="bold">&#13;
       Document store&#13;
      </html:strong>&#13;
      (&#13;
      <html:code class="literal">&#13;
       docstore&#13;
      </html:code>&#13;
      ): This manages the storage&#13;
      <html:a id="_idIndexMarker425">&#13;
      </html:a>&#13;
      of documents. The data is locally stored in a file&#13;
      <html:span class="No-Break">&#13;
       named&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        docstore.json&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      The&#13;
      <html:strong class="bold">&#13;
       Index Store&#13;
      </html:strong>&#13;
      (&#13;
      <html:code class="literal">&#13;
       index_store&#13;
      </html:code>&#13;
      ): This manages the storage&#13;
      <html:a id="_idIndexMarker426">&#13;
      </html:a>&#13;
      of Index structures. Indexes are stored locally in a file&#13;
      <html:span class="No-Break">&#13;
       called&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        index_store.json&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Vector Stores&#13;
      </html:strong>&#13;
      (&#13;
      <html:code class="literal">&#13;
       vector_stores&#13;
      </html:code>&#13;
      ): This is a dictionary managing&#13;
      <html:a id="_idIndexMarker427">&#13;
      </html:a>&#13;
      multiple vector stores, each potentially serving a different purpose. The vector stores are stored locally&#13;
      <html:span class="No-Break">&#13;
       in&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        vector_store.json&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      The&#13;
      <html:strong class="bold">&#13;
       Graph Store&#13;
      </html:strong>&#13;
      (&#13;
      <html:code class="literal">&#13;
       graph_store&#13;
      </html:code>&#13;
      ): This manages the storage&#13;
      <html:a id="_idIndexMarker428">&#13;
      </html:a>&#13;
      of graph data structures. A file named&#13;
      <html:code class="literal">&#13;
       graph_store.json&#13;
      </html:code>&#13;
      is automatically created by LlamaIndex for storing&#13;
      <html:span class="No-Break">&#13;
       the graphs.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      StorageContext&#13;
     </html:code>&#13;
     class encapsulates document, vector, index, and graph data stores under one umbrella. The files mentioned in the previous list for locally storing the data are automatically created by LlamaIndex when we invoke the&#13;
     <html:code class="literal">&#13;
      persist()&#13;
     </html:code>&#13;
     method. If we prefer not to save them in the current folder, we can provide a specific persistence location from where we can load them in&#13;
     <html:span class="No-Break">&#13;
      future sessions.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Out-of-the-box, LlamaIndex offers basic local stores, but we can swap them with more capable persistence solutions such as&#13;
     <html:em class="italic">&#13;
      AWS S3,&#13;
     </html:em>&#13;
     <html:em class="italic">&#13;
      Pinecone&#13;
     </html:em>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      MongoDB&#13;
     </html:em>&#13;
     ,&#13;
     <html:span class="No-Break">&#13;
      and others.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As an example, let’s explore customizing vector storage using ChromaDB, an efficient open source&#13;
     <html:span class="No-Break">&#13;
      vector engine.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     First, make sure&#13;
     <html:a id="_idIndexMarker429">&#13;
     </html:a>&#13;
     you install&#13;
     <html:code class="literal">&#13;
      chromadb&#13;
     </html:code>&#13;
     <html:span class="No-Break">&#13;
      using pip:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The first part of the code takes care of the&#13;
     <html:span class="No-Break">&#13;
      necessary imports:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We then continue by initializing the Chroma client and creating a collection within Chroma to store&#13;
     <html:span class="No-Break">&#13;
      our data:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In ChromaDB, we create&#13;
     <html:strong class="bold">&#13;
      collections&#13;
     </html:strong>&#13;
     to store data. These are similar&#13;
     <html:a id="_idIndexMarker430">&#13;
     </html:a>&#13;
     to&#13;
     <html:em class="italic">&#13;
      tables&#13;
     </html:em>&#13;
     in relational databases. The&#13;
     <html:code class="literal">&#13;
      my_chroma_store&#13;
     </html:code>&#13;
     collection will hold&#13;
     <html:span class="No-Break">&#13;
      our embeddings.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Next, we initialize a tailored vector store using&#13;
     <html:code class="literal">&#13;
      ChromaVectorStore&#13;
     </html:code>&#13;
     and wire it into&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       StorageContext&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’re now ready to ingest our documents and build&#13;
     <html:span class="No-Break">&#13;
      the Index:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We can now use the&#13;
     <html:code class="literal">&#13;
      get()&#13;
     </html:code>&#13;
     method to display the entire contents of the&#13;
     <html:span class="No-Break">&#13;
      Chroma collection:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Subsequently, restoring this Index in future sessions is also&#13;
     <html:span class="No-Break">&#13;
      very simple:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We just rebuilt our&#13;
     <html:span class="No-Break">&#13;
      original Index.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     By wrapping&#13;
     <html:strong class="bold">&#13;
      vector databases&#13;
     </html:strong>&#13;
     such as ChromaDB, LlamaIndex&#13;
     <html:a id="_idIndexMarker431">&#13;
     </html:a>&#13;
     makes enterprise-scale vector storage accessible through a simple storage abstraction. The complexity is concealed, enabling you to focus on your application logic while still leveraging industrial-strength&#13;
     <html:span class="No-Break">&#13;
      data infrastructure.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In summary, LlamaIndex&#13;
     <html:a id="_idIndexMarker432">&#13;
     </html:a>&#13;
     provides flexibility in vector storage – from a simple in-memory store for testing to cloud-hosted databases for large, real-world deployments. And through storage&#13;
     <html:a id="_idIndexMarker433">&#13;
     </html:a>&#13;
     integrations, swapping any component is&#13;
     <html:span class="No-Break">&#13;
      a breeze!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor117">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-118">&#13;
     The difference between vector stores and vector databases&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The terms vector store and vector database&#13;
     <html:a id="_idIndexMarker434">&#13;
     </html:a>&#13;
     are often used in the context of managing and querying large sets of vectors, which are commonly used in machine learning, particularly in applications involving NLP, image recognition, and similar tasks. You may have already noticed that I’m using them quite often in this chapter, sometimes implying they are similar concepts. However, there is a subtle distinction between&#13;
     <html:span class="No-Break">&#13;
      the two:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Vector store&#13;
      </html:strong>&#13;
      : This generally refers to a storage system or repository where vectors are stored. The vectors are high-dimensional and represent complex data such as text, images, or audio in a format that can be processed by machine learning models. A vector store focuses primarily on the efficient storage of these vectors. It might not have advanced capabilities for querying or analyzing the data and its main purpose is to maintain a large repository of vectors that can be retrieved and used for various machine&#13;
      <html:span class="No-Break">&#13;
       learning tasks&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Vector database&#13;
      </html:strong>&#13;
      : A vector database, on the other hand, is a more sophisticated system that not only stores vectors but also provides advanced functionalities for querying and analyzing them. This includes the ability to perform similarity searches and other complex operations that are useful in machine learning and data analysis. A vector database is designed to handle the nuances of vector data, such as their high dimensionality and the need for specialized indexing techniques to enable efficient search and retrieval. In&#13;
      <html:span class="No-Break">&#13;
       a nutshell&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     While a vector store is more about&#13;
     <html:a id="_idIndexMarker435">&#13;
     </html:a>&#13;
     the storage aspect, a vector database encompasses both storage and the complex querying capabilities required for vector data. This makes vector databases particularly important in applications where it’s necessary to search through large volumes of vectorized data quickly&#13;
     <html:span class="No-Break">&#13;
      and accurately.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     One distinguishing feature usually representative of a vector database and less often provided&#13;
     <html:a id="_idIndexMarker436">&#13;
     </html:a>&#13;
     by vector stores is the support for&#13;
     <html:code class="literal">&#13;
      CRUD&#13;
     </html:code>&#13;
     (&#13;
     <html:code class="literal">&#13;
      create&#13;
     </html:code>&#13;
     <html:strong class="bold">&#13;
      ,&#13;
     </html:strong>&#13;
     <html:code class="literal">&#13;
      read&#13;
     </html:code>&#13;
     <html:strong class="bold">&#13;
      ,&#13;
     </html:strong>&#13;
     <html:code class="literal">&#13;
      update&#13;
     </html:code>&#13;
     <html:strong class="bold">&#13;
      ,&#13;
     </html:strong>&#13;
     <html:code class="literal">&#13;
      delete&#13;
     </html:code>&#13;
     ) functions. Whether or not a vector store offers&#13;
     <html:code class="literal">&#13;
      CRUD&#13;
     </html:code>&#13;
     functions can vary depending on the specific implementation and design of the store. However, in general, a vector store, especially if it’s a simplified or basic form of storage for vector data, might not support all the&#13;
     <html:code class="literal">&#13;
      CRUD&#13;
     </html:code>&#13;
     operations in the same way a traditional database system would. Let’s break down the&#13;
     <html:span class="No-Break">&#13;
      typical operations:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Create&#13;
      </html:strong>&#13;
      : The ability to add new vectors&#13;
      <html:a id="_idIndexMarker437">&#13;
      </html:a>&#13;
      to the store is usually a fundamental feature. This is essential for building up the&#13;
      <html:span class="No-Break">&#13;
       vector repository.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Read&#13;
      </html:strong>&#13;
      : Reading or retrieving vectors based on some form of identifier or criterion is also a common feature. In a basic vector store, this might be limited to simple retrieval rather than&#13;
      <html:span class="No-Break">&#13;
       complex queries.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Update&#13;
      </html:strong>&#13;
      : Updating existing vectors in a vector store might not be as straightforward or as commonly supported as in traditional databases. This is because vector data, often used in machine learning and similar applications, is usually generated in a fixed form and not&#13;
      <html:span class="No-Break">&#13;
       frequently updated.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Delete&#13;
      </html:strong>&#13;
      : The capability to delete vectors may be supported, but like updating, it may not be a primary feature, depending on the use case of the&#13;
      <html:span class="No-Break">&#13;
       vector store.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     In many machine learning and AI applications, once vectors are created and stored, they are not frequently updated or deleted, which is why some vector stores might focus more on efficient storage and retrieval (create and read operations) rather than full&#13;
     <html:span class="No-Break">&#13;
      CRUD functionality.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In contrast to a simple vector store, a vector database, which is more sophisticated, is more likely to offer complete CRUD&#13;
     <html:a id="_idIndexMarker438">&#13;
     </html:a>&#13;
     capabilities, allowing for more dynamic and flexible management of the&#13;
     <html:span class="No-Break">&#13;
      vector data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here’s a good starting point in your journey&#13;
     <html:a id="_idIndexMarker439">&#13;
     </html:a>&#13;
     toward a better understanding of vector&#13;
     <html:span class="No-Break">&#13;
      databases:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor118">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Exploring other index types in LlamaIndex&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 class="H1---Chapter" id="_idParaDest-119">&#13;
    Exploring other index types in LlamaIndex&#13;
   </html:h1>&#13;
   <html:div id="_idContainer052">&#13;
    from llama_index.core import SummaryIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index = SummaryIndex.from_documents(documents)&#13;
query_engine = index.as_query_engine()&#13;
response = query_engine.query("How many documents have you loaded?")&#13;
print(response)&#13;
    I have loaded two documents.&#13;
    from llama_index.core import (&#13;
    DocumentSummaryIndex, SimpleDirectoryReader)&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index = DocumentSummaryIndex.from_documents(&#13;
    documents,&#13;
    show_progress=True&#13;
)&#13;
    summary1 = index.get_document_summary(documents[0].doc_id)&#13;
summary2 = index.get_document_summary(documents[1].doc_id)&#13;
print("\n Summary of the first document: " + summary1)&#13;
print("\n Summary of the second document: " + summary2)&#13;
    from llama_index.core import KeywordTableIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index = KeywordTableIndex.from_documents(documents)&#13;
query_engine = index.as_query_engine()&#13;
response = query_engine.query("&#13;
    What famous buildings were in ancient Rome?")&#13;
print(response)&#13;
    from llama_index.core import TreeIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index = TreeIndex.from_documents(documents)&#13;
query_engine = index.as_query_engine()&#13;
response = query_engine.query("Tell me about dogs")&#13;
print(response)&#13;
    from llama_index.core import (&#13;
    KnowledgeGraphIndex, SimpleDirectoryReader)&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index = KnowledgeGraphIndex.from_documents(&#13;
    documents, max_triplets_per_chunk=2, use_async=True)&#13;
query_engine = index.as_query_engine()&#13;
response = query_engine.query("Tell me about dogs.")&#13;
print(response)&#13;
    <html:p style="font-style:italic;">&#13;
     As this ebook edition doesn't have fixed pagination, the page numbers below are hyperlinked for reference only, based on the printed edition of this book.&#13;
    </html:p>&#13;
    <html:p>&#13;
     While the&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     may be the star&#13;
     <html:a id="_idIndexMarker440">&#13;
     </html:a>&#13;
     of the show in most of our RAG scenarios, LlamaIndex provides many other useful indexing tools. They all have specific features and use cases and the following section will explore them in&#13;
     <html:span class="No-Break">&#13;
      more detail.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor119">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-120">&#13;
     The SummaryIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     offers&#13;
     <html:a id="_idIndexMarker441">&#13;
     </html:a>&#13;
     a straightforward&#13;
     <html:a id="_idIndexMarker442">&#13;
     </html:a>&#13;
     yet powerful way of indexing data for retrieval purposes. Unlike the&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     , which focuses on embeddings within a vector store, the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     is based on a simple data structure where nodes are stored in a sequence. You’ll find a simple depiction of the structure of the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     in&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       .7&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer046">&#13;
      <html:img src="img/B21861_05_7.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.7 – The structure of a SummaryIndex&#13;
    </html:p>&#13;
    <html:p>&#13;
     When building the Index, it ingests a collection of documents, splits them into smaller chunks, and then compiles these chunks into a sequential list. Everything runs locally, without involving an LLM&#13;
     <html:a id="_idIndexMarker443">&#13;
     </html:a>&#13;
     or any&#13;
     <html:span class="No-Break">&#13;
      embedding&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:a id="_idIndexMarker444">&#13;
      </html:a>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      model.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Practical use case&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Imagine we would create&#13;
     <html:a id="_idIndexMarker445">&#13;
     </html:a>&#13;
     a documentation search tool within a software development project. Often, software projects accumulate extensive documentation over time, including technical specifications, API documentation, user guides, and developer notes. Keeping track of this information can become challenging, especially when the team needs to quickly reference specific details. Implementing a&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     for the project’s documentation repository allows developers to perform quick searches across all documents. For example, a developer could query&#13;
     <html:em class="italic">&#13;
      What are the error handling procedures for the payment gateway API?&#13;
     </html:em>&#13;
     The&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     would scan through the indexed documentation to retrieve relevant sections where error handling is discussed, without the need for complex embedding models or intensive computational resources. This Index would be particularly useful in environments where maintaining an extensive vector store would not be viable due to resource constraints or where simplicity and speed&#13;
     <html:span class="No-Break">&#13;
      are prioritized.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     is particularly effective for applications where a linear scan through data is sufficient or where complex embedding-based retrieval is not required. It’s a more basic form of indexing but still versatile enough for various use cases, especially in scenarios&#13;
     <html:a id="_idIndexMarker446">&#13;
     </html:a>&#13;
     where you need a simple way to index&#13;
     <html:span class="No-Break">&#13;
      your data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A simple usage model for the SummaryIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Creating a&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     is a&#13;
     <html:span class="No-Break">&#13;
      straightforward&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:a id="_idIndexMarker447">&#13;
      </html:a>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      process:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here, Nodes are created from our sample files and the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     is instantiated with these Nodes. This simple model enables quick setup without the complexity of embedding or using&#13;
     <html:span class="No-Break">&#13;
      vector storage.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If you have correctly cloned the structure of our book’s GitHub repository and have a&#13;
     <html:code class="literal">&#13;
      files&#13;
     </html:code>&#13;
     subfolder containing two text&#13;
     <html:a id="_idIndexMarker448">&#13;
     </html:a>&#13;
     files, the output of the previous code snippet should be&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Understanding the inner workings of the SummaryIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Internally, the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     operates by storing&#13;
     <html:a id="_idIndexMarker449">&#13;
     </html:a>&#13;
     each node in a list-like structure. When a query is executed, the Index iterates through this list to find relevant nodes. While this process is less complex than embedding-based searches in&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     , it’s still effective for&#13;
     <html:span class="No-Break">&#13;
      many applications.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The Index can be used with various retrievers such as&#13;
     <html:code class="literal">&#13;
      SummaryIndexRetriever&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      SummaryIndexEmbeddingRetriever&#13;
     </html:code>&#13;
     , and&#13;
     <html:code class="literal">&#13;
      SummaryIndexLLMRetriever&#13;
     </html:code>&#13;
     , each providing different mechanisms for searching and retrieving data. During queries, the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     employs a&#13;
     <html:em class="italic">&#13;
      create and refine&#13;
     </html:em>&#13;
     approach to formulate responses. Initially, it assembles a preliminary answer based on the first chunk of text. This initial response is subsequently refined by incorporating additional text chunks as contextual information. The refinement process involves either maintaining the initial answer, slightly modifying it, or entirely&#13;
     <html:a id="_idIndexMarker450">&#13;
     </html:a>&#13;
     rephrasing the original response. We’ll cover the retrieval part in detail during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 6&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Querying Our Data, Part 1 –&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Context Retrieval&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor120">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-121">&#13;
     The DocumentSummaryIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     LlamaIndex’s arsenal&#13;
     <html:a id="_idIndexMarker451">&#13;
     </html:a>&#13;
     of indexing tools&#13;
     <html:a id="_idIndexMarker452">&#13;
     </html:a>&#13;
     extends beyond its well-regarded&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     , encompassing a variety of specialized Indexes designed for diverse applications. Among these, the&#13;
     <html:code class="literal">&#13;
      DocumentSummaryIndex&#13;
     </html:code>&#13;
     stands out for its unique approach to document management&#13;
     <html:span class="No-Break">&#13;
      and retrieval.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     At its core, the&#13;
     <html:code class="literal">&#13;
      DocumentSummaryIndex&#13;
     </html:code>&#13;
     is designed to optimize information retrieval by summarizing Documents and mapping these summaries to their corresponding Nodes within the Index. This process facilitates efficient data retrieval, using the summaries to quickly identify&#13;
     <html:span class="No-Break">&#13;
      relevant Documents.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .8&#13;
     </html:em>&#13;
     provides a visual representation of&#13;
     <html:span class="No-Break">&#13;
      this mechanism:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer047">&#13;
      <html:img src="img/B21861_05_8.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.8 – The DocumentSummaryIndex&#13;
    </html:p>&#13;
    <html:p>&#13;
     This Index operates by first creating a summary for each ingested Document. These summaries are then linked to the Document’s Nodes, forming a structured Index that enables fast and accurate&#13;
     <html:span class="No-Break">&#13;
      data retrieval.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      DocumentSummaryIndex&#13;
     </html:code>&#13;
     is particularly useful for handling queries where a succinct overview of the document content can significantly narrow down the search space, making it a great tool for applications requiring quick access to specific Documents in a large and&#13;
     <html:span class="No-Break">&#13;
      diverse dataset.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For example, a practical&#13;
     <html:a id="_idIndexMarker453">&#13;
     </html:a>&#13;
     use case for the&#13;
     <html:code class="literal">&#13;
      DocumentSummaryIndex&#13;
     </html:code>&#13;
     is in the development of a knowledge&#13;
     <html:a id="_idIndexMarker454">&#13;
     </html:a>&#13;
     management system within a large organization. In such an environment, employees often need quick access to a vast array of documents, including reports, research papers, policy documents, and technical manuals. These documents are typically stored across different departments and may be extensive in length, making it challenging to quickly find specific information relevant to a user’s query. In addition, multiple documents may contain similar chunks of text, making a simple embedding-based retrieval impractical over the&#13;
     <html:span class="No-Break">&#13;
      entire dataset.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Several parameters&#13;
     <html:a id="_idIndexMarker455">&#13;
     </html:a>&#13;
     can be customized for this&#13;
     <html:span class="No-Break">&#13;
      particular Index:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       response_synthesizer&#13;
      </html:code>&#13;
      : This parameter allows you to specify a response synthesizer that is responsible for generating summaries. By customizing this parameter, you can control the summarization process, adjusting it to fit specific needs or preferences in how summaries&#13;
      <html:span class="No-Break">&#13;
       are generated.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       summary_query&#13;
      </html:code>&#13;
      : This parameter is used to define the query that guides the summarization process. Essentially, it tells the response synthesizer what kind of summary to generate for each Document. The default query asks for a summary that describes what the Document is about and what questions it can answer. Adjusting this query allows you to tailor the focus and style of the summaries, making them more relevant to the specific use cases of&#13;
      <html:span class="No-Break">&#13;
       the Index.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       show_progress&#13;
      </html:code>&#13;
      : This Boolean parameter determines whether to display progress bars during operations that can take a significant amount of time. Setting this to&#13;
      <html:code class="literal">&#13;
       True&#13;
      </html:code>&#13;
      provides visual feedback on the progress of&#13;
      <html:span class="No-Break">&#13;
       these operations.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       embed_summaries&#13;
      </html:code>&#13;
      : When set to&#13;
      <html:code class="literal">&#13;
       True&#13;
      </html:code>&#13;
      – which is the default – this parameter indicates that the summaries should be embedded. Embedded summaries can then be used for similarity comparisons and retrieval in an embedding-based search. This is particularly useful for scenarios where you want to retrieve Nodes based on the similarity between the Document summary content and the user&#13;
      <html:a id="_idIndexMarker456">&#13;
      </html:a>&#13;
      query. We’ll cover this in more detail during&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Chapter 6&#13;
        </html:em>&#13;
       </html:span>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Querying Our Data, Part 1 –&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Context Retrieval&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        .&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Let’s now see how to use&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       DocumentSummaryIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A simple usage model for the DocumentSummaryIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Creating a&#13;
     <html:code class="literal">&#13;
      DocumentSummaryIndex&#13;
     </html:code>&#13;
     involves a series&#13;
     <html:a id="_idIndexMarker457">&#13;
     </html:a>&#13;
     of steps, starting with the aggregation of Documents and their subsequent summarization. The following code snippet demonstrates the basic setup for creating&#13;
     <html:span class="No-Break">&#13;
      this Index:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This process involves reading documents from a directory, parsing them into Nodes, summarizing the Documents, and then associating the corresponding Nodes with these summaries for quick retrieval. Next, let’s observe the summaries that were generated in&#13;
     <html:span class="No-Break">&#13;
      the process:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The second part of the code sample displays the summaries that were generated for each Document. These summaries were associated with the underlying Nodes for each Document. During retrieval, this association will allow extracting only the relevant Nodes, based on the user query and the summary of&#13;
     <html:span class="No-Break">&#13;
      each Document.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Internally, the&#13;
     <html:code class="literal">&#13;
      DocumentSummaryIndex&#13;
     </html:code>&#13;
     supports both embedding-based and LLM-based retrievers, allowing&#13;
     <html:a id="_idIndexMarker458">&#13;
     </html:a>&#13;
     for flexible retrieval mechanisms that cater to different needs. By default, the Index also generates embeddings for each summary in order to facilitate embedding-based retrieval, which is particularly useful for&#13;
     <html:span class="No-Break">&#13;
      similarity searches.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor121">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-122">&#13;
     The KeywordTableIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     in LlamaIndex implements&#13;
     <html:a id="_idIndexMarker459">&#13;
     </html:a>&#13;
     a clever&#13;
     <html:a id="_idIndexMarker460">&#13;
     </html:a>&#13;
     architecture – similar to a glossary of terms – for rapidly matching queries to relevant nodes based on important terms. Unlike complex embedding spaces, this structure relies on a straightforward keyword table, yet proves highly effective for targeted factual lookup. This Index extracts keywords from documents and constructs a keyword-to-node mapping, offering a highly efficient&#13;
     <html:span class="No-Break">&#13;
      search mechanism.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     It’s particularly useful in scenarios where precise keyword matching is vital for retrieving relevant information. These keywords become the reference keys in a central lookup table, each one pointing to associated nodes such as a glossary definition. During retrieval, just like scanning a glossary for entries of interest, relevant nodes containing a particular keyword are identified&#13;
     <html:a id="_idIndexMarker461">&#13;
     </html:a>&#13;
     and returned. See&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .9&#13;
     </html:em>&#13;
     for a&#13;
     <html:span class="No-Break">&#13;
      visual representation:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer048">&#13;
      <html:img src="img/B21861_05_9.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.9 – The structure of a KeywordTableIndex&#13;
    </html:p>&#13;
    <html:p>&#13;
     The customizable&#13;
     <html:a id="_idIndexMarker462">&#13;
     </html:a>&#13;
     parameters for the&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     are&#13;
     <html:span class="No-Break">&#13;
      as follows:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       keyword_extract_template&#13;
      </html:code>&#13;
      : This is an optional prompt template used for keyword extraction. Custom prompts can be specified to change how keywords are extracted from text, allowing for tailored keyword extraction strategies. We’ll talk more about prompt customization during&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Chapter 10&#13;
        </html:em>&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        .&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       max_keywords_per_chunk&#13;
      </html:code>&#13;
      : This sets the maximum number of keywords to extract from each text chunk. By using this parameter, we can make sure the keyword table remains manageable and focused on the most relevant keywords. The default value&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        10&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       use_async&#13;
      </html:code>&#13;
      : This determines whether to use asynchronous calls. This can improve performance, especially when handling large datasets or complex operations. Its default&#13;
      <html:a id="_idIndexMarker463">&#13;
      </html:a>&#13;
      setting&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        False&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Next up, we will create&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       KeywordTableIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A simple usage model for the KeywordTableIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Creating a&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     is&#13;
     <html:span class="No-Break">&#13;
      very&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:a id="_idIndexMarker464">&#13;
      </html:a>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      straightforward:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here, the Index automatically extracts keywords from your data and sets up a keyword table, streamlining the process of setting up a keyword-based&#13;
     <html:span class="No-Break">&#13;
      retrieval system.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Just like in the previous example, if you have correctly cloned the structure of our GitHub repository and have a&#13;
     <html:code class="literal">&#13;
      files&#13;
     </html:code>&#13;
     subfolder containing two text files, the output of the previous code snippet should be something along the lines of&#13;
     <html:em class="italic">&#13;
      The Colosseum and the Pantheon were famous buildings in&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       ancient Rome&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     How does the KeywordTableIndex operate?&#13;
    </html:h3>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     builds and operates&#13;
     <html:a id="_idIndexMarker465">&#13;
     </html:a>&#13;
     a keyword table, akin to a glossary, where each keyword is linked to relevant nodes. The Index initially processes a collection of documents, breaking them down into smaller chunks. For each chunk, the Index uses the LLM with a specially designed prompt to identify and extract relevant keywords. These keywords, which may range from simple terms to short phrases, are subsequently cataloged in the keyword table. Each keyword in this table is directly linked to the chunk of text from which it&#13;
     <html:span class="No-Break">&#13;
      was derived.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Upon receiving a query, the Index identifies keywords within it and matches them with the table entries, enabling rapid and accurate retrieval of related chunks containing those keywords. It supports various retrieval modes, including simple keyword matching and advanced&#13;
     <html:a id="_idIndexMarker466">&#13;
     </html:a>&#13;
     techniques such as&#13;
     <html:strong class="bold">&#13;
      RAKE&#13;
     </html:strong>&#13;
     or LLM-based keyword extraction and matching. We’ll talk more about these retrieval modes during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 6&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Querying Our Data, Part 1 –&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Context Retrieval&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Quick note on the RAKE extraction method&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     This method is particularly effective&#13;
     <html:a id="_idIndexMarker467">&#13;
     </html:a>&#13;
     in identifying phrases or keywords that are significant within a body of text. The key idea behind RAKE is that keywords often consist of multiple words but rarely include punctuation, stop words, or words with minimal lexical meaning. The&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     has two similar alternatives that are designed to operate without the assistance of an LLM:&#13;
     <html:code class="literal">&#13;
      SimpleKeywordTableIndex&#13;
     </html:code>&#13;
     , which uses a simple regex extractor, and&#13;
     <html:code class="literal">&#13;
      RAKEKeywordTableIndex&#13;
     </html:code>&#13;
     , which relies on a RAKE keyword extractor based on the&#13;
     <html:code class="literal">&#13;
      rake_nltk&#13;
     </html:code>&#13;
     (Natural Language Toolkit)&#13;
     <html:span class="No-Break">&#13;
      Python package.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You should know that, just like the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     , the&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     also uses a&#13;
     <html:em class="italic">&#13;
      create and refine&#13;
     </html:em>&#13;
     approach when synthesizing&#13;
     <html:a id="_idIndexMarker468">&#13;
     </html:a>&#13;
     the final response. The adaptability of the&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     makes it a versatile tool for diverse applications where keyword precision&#13;
     <html:span class="No-Break">&#13;
      is key.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor122">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-123">&#13;
     The TreeIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     introduces a&#13;
     <html:a id="_idIndexMarker469">&#13;
     </html:a>&#13;
     hierarchical approach&#13;
     <html:a id="_idIndexMarker470">&#13;
     </html:a>&#13;
     to information organization and retrieval. Unlike a simple list, this structure organizes data in a hierarchical&#13;
     <html:span class="No-Break">&#13;
      tree format.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Have a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .10&#13;
     </html:em>&#13;
     for a diagram depicting the structure of&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       TreeIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer049">&#13;
      <html:img src="img/B21861_05_10.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.10 – The structure of a TreeIndex&#13;
    </html:p>&#13;
    <html:p>&#13;
     Each node in this tree can represent a piece of data or information, similar to a branch or leaf on a real tree. This structural formation allows for efficient handling and querying of data. The&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     first takes in a set of documents as input. It then builds up a tree in a bottom-up fashion; each parent node is able to summarize the child nodes using a general summarization prompt, and each intermediate node contains text summarizing the components below it. This summary is generated using an LLM based on a prompt template that can be customized with the&#13;
     <html:code class="literal">&#13;
      summary_prompt&#13;
     </html:code>&#13;
     parameter.&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     acts like an organizer&#13;
     <html:a id="_idIndexMarker471">&#13;
     </html:a>&#13;
     and summarizer, taking lots of individual pieces of data, grouping them together, and creating a summary&#13;
     <html:a id="_idIndexMarker472">&#13;
     </html:a>&#13;
     that captures&#13;
     <html:span class="No-Break">&#13;
      their essence.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Customizable parameters for the TreeIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Apart from the general customization&#13;
     <html:a id="_idIndexMarker473">&#13;
     </html:a>&#13;
     inherited from the&#13;
     <html:code class="literal">&#13;
      BaseIndex&#13;
     </html:code>&#13;
     class, the&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     provides the&#13;
     <html:span class="No-Break">&#13;
      following parameters:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       summary_template&#13;
      </html:code>&#13;
      : This is a prompt for summarization, used during Index construction. This prompt can be customized for better control of the&#13;
      <html:span class="No-Break">&#13;
       summarization process.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       insert_prompt&#13;
      </html:code>&#13;
      : This is a prompt used by the Index for tree insertion, facilitating Index construction. This prompt facilitates the insertion of nodes into the tree. It guides how new information is integrated into the existing tree structure. We’ll cover details about prompt customization during&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Chapter 10&#13;
        </html:em>&#13;
       </html:span>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Prompt Engineering Guidelines and&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Best Practices.&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       num_children&#13;
      </html:code>&#13;
      : This defines the maximum number of child nodes each node should have. This parameter controls the breadth of the tree, impacting its level of detail at each node. By default, this is set&#13;
      <html:span class="No-Break">&#13;
       to&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        10&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       build_tree&#13;
      </html:code>&#13;
      : This is a Boolean indicating whether to build the tree during Index construction. If we don’t use the default value – which is&#13;
      <html:code class="literal">&#13;
       True&#13;
      </html:code>&#13;
      – the Index will build its tree during query time instead of building it during the Index construction. Setting the&#13;
      <html:code class="literal">&#13;
       build_tree&#13;
      </html:code>&#13;
      parameter to&#13;
      <html:code class="literal">&#13;
       False&#13;
      </html:code>&#13;
      could be useful in scenarios where you might want to manually control the tree-building process or modify the tree structure after&#13;
      <html:span class="No-Break">&#13;
       initial construction.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       use_async&#13;
      </html:code>&#13;
      : This determines whether asynchronous&#13;
      <html:a id="_idIndexMarker474">&#13;
      </html:a>&#13;
      operation mode should&#13;
      <html:span class="No-Break">&#13;
       be used.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Next, let’s create a&#13;
     <html:span class="No-Break">&#13;
      simple&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       TreeIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A simple usage model for the TreeIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     To implement a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     , you can&#13;
     <html:a id="_idIndexMarker475">&#13;
     </html:a>&#13;
     follow this&#13;
     <html:span class="No-Break">&#13;
      simple example:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This process involves the&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     taking in documents, structuring them hierarchically, and then allowing for queries&#13;
     <html:a id="_idIndexMarker476">&#13;
     </html:a>&#13;
     that leverage this structure for efficient&#13;
     <html:span class="No-Break">&#13;
      data retrieval.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     The inner mechanics of the TreeIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     The index-building process&#13;
     <html:a id="_idIndexMarker477">&#13;
     </html:a>&#13;
     is recursive. After the first level of parent nodes is created, the builder can repeat the process, summarizing these parent nodes into higher-level nodes, and so on. This creates multiple levels in the tree, with each level abstracting and summarizing the information from the level below it. Also, for large datasets, the Index can handle data asynchronously with&#13;
     <html:code class="literal">&#13;
      use_async&#13;
     </html:code>&#13;
     . This means it can process multiple parts of the data simultaneously, making the building process faster and&#13;
     <html:span class="No-Break">&#13;
      more efficient.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     By using LLMs for summaries, the&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     can encapsulate a nuanced understanding of the data. This is particularly useful for complex datasets where relationships and&#13;
     <html:span class="No-Break">&#13;
      context matter.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     For example, in organizations&#13;
    </html:h3>&#13;
    <html:p>&#13;
     In organizations with complex hierarchical data&#13;
     <html:a id="_idIndexMarker478">&#13;
     </html:a>&#13;
     such as reports, memos, and research papers, a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     can organize this information efficiently, allowing for quick retrieval of specific data points within their knowledge&#13;
     <html:span class="No-Break">&#13;
      management systems.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     operates by building a tree where each node is a summarized representation of its children, offering a clear and organized view of&#13;
     <html:span class="No-Break">&#13;
      the data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This Index supports&#13;
     <html:a id="_idIndexMarker479">&#13;
     </html:a>&#13;
     several&#13;
     <html:span class="No-Break">&#13;
      retrieval modes:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       TreeSelectLeafRetriever&#13;
      </html:code>&#13;
      : This traverses the tree to find leaf nodes that can best answer a query. It involves choosing a specific number of child nodes at each level&#13;
      <html:span class="No-Break">&#13;
       for traversal.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       TreeSelectLeafEmbeddingRetriever&#13;
      </html:code>&#13;
      : This utilizes embedding similarity between the query and node text to traverse the tree, selecting leaf nodes based on&#13;
      <html:span class="No-Break">&#13;
       this similarity.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       TreeRootRetriever&#13;
      </html:code>&#13;
      : This directly retrieves answers from the root nodes of the tree. This method assumes the graph already stores the answer, so it doesn’t parse information down&#13;
      <html:span class="No-Break">&#13;
       the tree.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       TreeAllLeafRetriever&#13;
      </html:code>&#13;
      : This builds a query-specific tree from all leaf nodes to return a response. It rebuilds the tree for each query, making it suitable for scenarios&#13;
      <html:a id="_idIndexMarker480">&#13;
      </html:a>&#13;
      where the tree structure doesn’t need to be built&#13;
      <html:span class="No-Break">&#13;
       during initialization.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     During query time, the tree Index&#13;
     <html:a id="_idIndexMarker481">&#13;
     </html:a>&#13;
     operates in the&#13;
     <html:span class="No-Break">&#13;
      following way:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      First, the provided query string is processed to extract&#13;
      <html:span class="No-Break">&#13;
       relevant keywords&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Beginning from the root Node, the Index navigates through the&#13;
      <html:span class="No-Break">&#13;
       tree structure&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      At each Node, it determines whether the keywords are found in the&#13;
      <html:span class="No-Break">&#13;
       Node’s summary&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      If keywords are found, the Index proceeds to explore the Node’s&#13;
      <html:span class="No-Break">&#13;
       child Nodes&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      If the keywords are absent, the Index advances to the&#13;
      <html:span class="No-Break">&#13;
       subsequent Node&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      This process persists until a leaf Node is encountered or all Nodes in the tree have&#13;
      <html:span class="No-Break">&#13;
       been examined&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     The reached leaf Nodes represent the context with the highest likelihood of relevance to the&#13;
     <html:span class="No-Break">&#13;
      given query.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’ll cover the retrievers in more detail during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 6&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Querying Our Data, Part 1 –&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Context Retrieval&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Some potential drawbacks of using the TreeIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Using a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     in our RAG workflow&#13;
     <html:a id="_idIndexMarker482">&#13;
     </html:a>&#13;
     can potentially be less advantageous compared to simpler retrieval methods. Here are a few&#13;
     <html:span class="No-Break">&#13;
      reasons why:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Increased computation&#13;
      </html:em>&#13;
      : Building and maintaining a&#13;
      <html:code class="literal">&#13;
       TreeIndex&#13;
      </html:code>&#13;
      requires additional computational resources. During the Index construction phase, the tree structure needs to be created by recursively summarizing and organizing the Nodes. This process involves applying summarization using LLM calls and constructing the hierarchical structure, which can be computationally intensive, especially for&#13;
      <html:span class="No-Break">&#13;
       large datasets.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Recursive retrieval&#13;
      </html:em>&#13;
      : When querying the Index, the retrieval process involves traversing the tree structure from the root nodes down to the relevant leaf nodes. This recursive traversal can require multiple steps and computations, especially if the tree is deep or if multiple branches need to be explored. Each step in the traversal may involve comparing the query with the Node summaries and making decisions on which branches to follow. This recursive process can be more computationally expensive compared to retrieving from a&#13;
      <html:span class="No-Break">&#13;
       flat Index.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Summarization overhead&#13;
      </html:em>&#13;
      : This Index relies on summarizing the content of each node to provide a concise representation of its child Nodes. The summarization process needs to be performed during Index construction and potentially during updates or insertions, adding to the overall&#13;
      <html:span class="No-Break">&#13;
       computational overhead.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Storage requirements&#13;
      </html:em>&#13;
      : Storing a&#13;
      <html:code class="literal">&#13;
       TreeIndex&#13;
      </html:code>&#13;
      requires additional storage compared to a flat Index. The Index needs to store the tree structure, Node summaries, and metadata associated with each Node. This extra storage overhead can increase storage costs, especially for&#13;
      <html:span class="No-Break">&#13;
       large-scale datasets.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Maintenance and updates&#13;
      </html:em>&#13;
      : Maintaining a&#13;
      <html:code class="literal">&#13;
       TreeIndex&#13;
      </html:code>&#13;
      requires regular updates and re-organization as new data is added or existing data is modified. Inserting new nodes or updating existing nodes in the tree structure may trigger a cascading effect, requiring updates to the parent nodes and their summaries. This maintenance process can be more complex and time-consuming compared to&#13;
      <html:span class="No-Break">&#13;
       other Indexes.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     However, it’s important to note that the higher costs associated with using a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     can be justified in certain scenarios. If the RAG application deals with a large-scale dataset and requires efficient and context-aware retrieval, the benefits of using this type of Index may outweigh the additional costs. Its hierarchical structure and summarization capabilities can lead to improved retrieval performance, reduced search space, and better response generation quality. By traversing the tree from the root Nodes and selectively exploring relevant branches, the model can quickly narrow down the search to the most promising Nodes. This can lead to faster retrieval times and improved efficiency compared to searching through a flat&#13;
     <html:span class="No-Break">&#13;
      Index structure.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The key is to assess&#13;
     <html:a id="_idIndexMarker483">&#13;
     </html:a>&#13;
     the specific requirements, scale, and constraints of the RAG scenario to determine whether the benefits of using a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     justify the potential increase in costs. Careful evaluation and benchmarking can help in making an informed decision based on the trade-offs between retrieval efficiency, generation quality, and computational and&#13;
     <html:span class="No-Break">&#13;
      storage costs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor123">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-124">&#13;
     The KnowledgeGraphIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      KnowledgeGraphIndex&#13;
     </html:code>&#13;
     enhances query&#13;
     <html:a id="_idIndexMarker484">&#13;
     </html:a>&#13;
     processing&#13;
     <html:a id="_idIndexMarker485">&#13;
     </html:a>&#13;
     by constructing a&#13;
     <html:strong class="bold">&#13;
      knowledge graph&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      KG&#13;
     </html:strong>&#13;
     ) from extracted&#13;
     <html:strong class="bold">&#13;
      triplets&#13;
     </html:strong>&#13;
     . This type of Index primarily&#13;
     <html:a id="_idIndexMarker486">&#13;
     </html:a>&#13;
     relies on the LLM&#13;
     <html:a id="_idIndexMarker487">&#13;
     </html:a>&#13;
     to extract triplets from text, but it also provides flexibility to use custom extraction functions&#13;
     <html:span class="No-Break">&#13;
      if needed.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     KG Indexes excel in scenarios where understanding complex, interlinked relationships and contextual information is important. They are very good at capturing intricate connections between entities and concepts, thus offering better insights and context-aware responses to queries. Among other use cases, KGs are ideal for answering multifaceted questions that require an understanding of the relationships between different entities.&#13;
     <html:em class="italic">&#13;
      Yes, I’m talking about our tutor project,&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       PITS, here.&#13;
      </html:em>&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s get a visual of how KGs work in&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       .11&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer050">&#13;
      <html:img src="img/B21861_05_11.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.11 – The structure of a KnowledgeGraphIndex&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Practical use case&#13;
    </html:h3>&#13;
    <html:p>&#13;
     An interesting use case&#13;
     <html:a id="_idIndexMarker488">&#13;
     </html:a>&#13;
     for a KG could be, for example, a news aggregation app, where large volumes of text are ingested every day from various sources such as newspapers, blogs, and social media platforms. In such a scenario, KGs could be used to represent entities such as people, organizations, locations, and so on, and their relationships over time. This would allow users to explore historical trends, breaking news events, and related entities based on the graph structure and&#13;
     <html:span class="No-Break">&#13;
      traversal algorithms.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Sounds good, right? We will now take a look at how you can work&#13;
     <html:span class="No-Break">&#13;
      with&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       KnowledgeGraphIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Customizable parameters for the KnowledgeGraphIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     You can customize&#13;
     <html:a id="_idIndexMarker489">&#13;
     </html:a>&#13;
     the&#13;
     <html:span class="No-Break">&#13;
      following parameters:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       kg_triple_extract_template&#13;
      </html:code>&#13;
      : This is a prompt template for extracting triplets. It can be customized to change how triplets (subject-predicate-object) are identified, enabling tailored extraction strategies based on specific&#13;
      <html:span class="No-Break">&#13;
       use cases.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       max_triplets_per_chunk&#13;
      </html:code>&#13;
      : This limits the number of triplets extracted per text chunk. Setting this value helps manage the size and complexity of the KG. The default value&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        10&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       graph_store&#13;
      </html:code>&#13;
      : This defines the storage type for the graph. Different storage types can be used to optimize performance and scalability based on the&#13;
      <html:span class="No-Break">&#13;
       application’s requirements.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       include_embeddings&#13;
      </html:code>&#13;
      : This decides whether to include embeddings in the Index. This is useful for scenarios where embeddings can enhance the retrieval process, such as similarity searches or advanced&#13;
      <html:span class="No-Break">&#13;
       query understanding.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       max_object_length&#13;
      </html:code>&#13;
      : This sets the maximum length – in characters – for the object in a triplet. It prevents overly long or complex objects that could complicate the graph’s structure and the retrieval process. Its default value&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        128&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       kg_triplet_extract_fn&#13;
      </html:code>&#13;
      : A custom function for triplet extraction can be provided, offering the flexibility to use specialized or proprietary methods for extracting triplets&#13;
      <html:a id="_idIndexMarker490">&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       from text.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Let’s create a simple&#13;
     <html:span class="No-Break">&#13;
      KG next.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A basic usage model for KnowledgeGraphIndex&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Here’s a simple way&#13;
     <html:a id="_idIndexMarker491">&#13;
     </html:a>&#13;
     of constructing and querying&#13;
     <html:span class="No-Break">&#13;
      a KG:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this setup, the Index builds a KG by extracting triplets from documents, enabling complex relationship queries. Notice that we configured the Index to run the build process in asynchronous mode by setting&#13;
     <html:code class="literal">&#13;
      use_async&#13;
     </html:code>&#13;
     to&#13;
     <html:code class="literal">&#13;
      True&#13;
     </html:code>&#13;
     . Of course, for the two small documents that we’re using as an example in our case, this won’t make too much difference in the total execution time. However, when working with large datasets, enabling asynchronous operation&#13;
     <html:a id="_idIndexMarker492">&#13;
     </html:a>&#13;
     for this Index may provide an important&#13;
     <html:span class="No-Break">&#13;
      performance boost.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     How does the KnowledgeGraphIndex build its structure?&#13;
    </html:h3>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      KnowledgeGraphIndex&#13;
     </html:code>&#13;
     operates by extracting subject-predicate-object triplets from text data, forming&#13;
     <html:span class="No-Break">&#13;
      a KG.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There are two main ways in which&#13;
     <html:a id="_idIndexMarker493">&#13;
     </html:a>&#13;
     this Index can build&#13;
     <html:span class="No-Break">&#13;
      its structure:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       The default, built-in approach&#13;
      </html:em>&#13;
      : In its default implementation, the Index uses an internal method to extract triplets from text. This method takes the text content of each Node and passes it through a pre-defined prompt template –&#13;
      <html:code class="literal">&#13;
       DEFAULT_KG_TRIPLET_EXTRACT_PROMPT&#13;
      </html:code>&#13;
      or a custom template provided during initialization through the&#13;
      <html:code class="literal">&#13;
       kg_triple_extract_template&#13;
      </html:code>&#13;
      argument. The prompt template is designed to instruct the LLM to extract knowledge triplets from the given text. The LLM’s response is then parsed by a specialized internal method to extract the subject, predicate, and object of each triplet. This method extracts knowledge triplets in the format of&#13;
      <html:em class="italic">&#13;
       subject, predicate, object&#13;
      </html:em>&#13;
      . It applies various checks and string manipulations to ensure the validity and consistency of the extracted triplets. Finally, the method returns a list of cleaned and well-formatted triplets that can be added to the&#13;
      <html:span class="No-Break">&#13;
       KG Index.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       The second approach involves a custom triplet extraction function&#13;
      </html:em>&#13;
      : If a custom&#13;
      <html:code class="literal">&#13;
       kg_triplet_extract_fn&#13;
      </html:code>&#13;
      function is provided during initialization, it will be used instead of the LLM-based method. This allows us to define our own function to extract triplets from text based on their specific requirements or&#13;
      <html:span class="No-Break">&#13;
       domain knowledge.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Regardless of whether we’re using the first or the second approach to generate the triplets, the inner components of the Index are responsible for building the actual KG from the given Nodes. They iterate over each Node, extract triplets using either the LLM-based method or the custom extraction function and add the triplets to the&#13;
     <html:span class="No-Break">&#13;
      Index structure.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If the&#13;
     <html:code class="literal">&#13;
      include_embeddings&#13;
     </html:code>&#13;
     flag is set to&#13;
     <html:code class="literal">&#13;
      True&#13;
     </html:code>&#13;
     , the Index will also generate embeddings for each triplet using the specified embedding model. These embeddings are stored in the&#13;
     <html:code class="literal">&#13;
      embedding_dict&#13;
     </html:code>&#13;
     of the&#13;
     <html:span class="No-Break">&#13;
      Index structure.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      upsert_triplet()&#13;
     </html:code>&#13;
     method allows the manual insertion of triplets into the KG. It adds the triplet to the graph store and also optionally generates embeddings for the triplet if&#13;
     <html:code class="literal">&#13;
      include_embeddings&#13;
     </html:code>&#13;
     are set&#13;
     <html:span class="No-Break">&#13;
      to&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       True&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     During querying, the Index leverages the KG to retrieve relevant data and help provide context-rich responses. There are three distinct retrievers available for this Index:&#13;
     <html:code class="literal">&#13;
      KGTableRetriever&#13;
     </html:code>&#13;
     for keyword-focused queries,&#13;
     <html:code class="literal">&#13;
      KnowledgeGraphRAGRetriever&#13;
     </html:code>&#13;
     for retrieving sub-graphs based on extracted entities and synonyms, and a hybrid mode that combines both keyword and embedding strategies for a comprehensive&#13;
     <html:a id="_idIndexMarker494">&#13;
     </html:a>&#13;
     approach. More details about these retrieval capabilities will be explored during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 6&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Querying Our Data, Part 1 –&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Context Retrieval&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor124">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Building Indexes on top of other Indexes with ComposableGraph&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-125">&#13;
    Building Indexes on top of other Indexes with ComposableGraph&#13;
   </html:h1>&#13;
   <html:div id="_idContainer052">&#13;
    from llama_index.core import (&#13;
    ComposableGraph, SimpleDirectoryReader, &#13;
    TreeIndex, SummaryIndex)&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
index1 = TreeIndex.from_documents([documents[0]])&#13;
index2 = TreeIndex.from_documents([documents[1]])&#13;
summary1 = "A short introduction to ancient Rome"&#13;
summary2 = "Some facts about dogs"&#13;
graph = ComposableGraph.from_indices(&#13;
    SummaryIndex, [index1, index2],&#13;
    index_summaries=[summary1, summary2]&#13;
)&#13;
query_engine = graph.as_query_engine()&#13;
response = query_engine.query("What can you tell me?")&#13;
print(response)&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     in LlamaIndex represents&#13;
     <html:a id="_idIndexMarker495">&#13;
     </html:a>&#13;
     a sophisticated way&#13;
     <html:a id="_idIndexMarker496">&#13;
     </html:a>&#13;
     to structure information by&#13;
     <html:strong class="bold">&#13;
      stacking Indexes&#13;
     </html:strong>&#13;
     on top of&#13;
     <html:span class="No-Break">&#13;
      each other.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .12&#13;
     </html:em>&#13;
     provides an overview of&#13;
     <html:span class="No-Break">&#13;
      a&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       ComposableGraph&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer051">&#13;
      <html:img src="img/B21861_05_12.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 5.12 – The structure of a ComposableGraph&#13;
    </html:p>&#13;
    <html:p>&#13;
     This approach allows for the construction&#13;
     <html:a id="_idIndexMarker497">&#13;
     </html:a>&#13;
     of Indexes within individual documents – lower-level Indexes – and the aggregation of these Indexes into higher-order ones over a collection of documents. For example, you can build a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     for the text within each document and a&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     that encompasses each&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     in&#13;
     <html:span class="No-Break">&#13;
      a collection.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor125">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-126">&#13;
     How to use the ComposableGraph&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Here’s a simple code example demonstrating&#13;
     <html:a id="_idIndexMarker498">&#13;
     </html:a>&#13;
     the usage&#13;
     <html:span class="No-Break">&#13;
      of&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       ComposableGraph&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this example, the&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     facilitates the organization of detailed information within Documents and the summarization&#13;
     <html:span class="No-Break">&#13;
      across Documents.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We first load our two test Documents: one related to ancient Rome and the other one describing dogs. We then create a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     for&#13;
     <html:span class="No-Break">&#13;
      each Document.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We also define the summaries&#13;
     <html:a id="_idIndexMarker499">&#13;
     </html:a>&#13;
     of the&#13;
     <html:span class="No-Break">&#13;
      two Documents.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Pro tip&#13;
    </html:h3>&#13;
    <html:p>&#13;
     As an alternative to manually&#13;
     <html:a id="_idIndexMarker500">&#13;
     </html:a>&#13;
     defining the summaries, we could have also queried each individual Index to automatically generate the content summary or used&#13;
     <html:code class="literal">&#13;
      SummaryExtractor&#13;
     </html:code>&#13;
     to accomplish the&#13;
     <html:span class="No-Break">&#13;
      same purpose.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In the next step, we build a&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     containing the two tree Indexes along with their summaries. For this example, the output of the code should be something similar to the following:&#13;
     <html:em class="italic">&#13;
      I can tell you about the ancient Roman civilization and dogs and their various breeds, traits,&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       and personalities.&#13;
      </html:em>&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Once the&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     has been built, the root&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     will have an overview of the contents of the individual Indexes for&#13;
     <html:span class="No-Break">&#13;
      each document.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor126">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-127">&#13;
     A more detailed description of this concept&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Under the hood, a&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     enables the creation&#13;
     <html:a id="_idIndexMarker501">&#13;
     </html:a>&#13;
     of hierarchical structures by stacking Indexes on top of each other. This allows for the organization of detailed information within individual Documents using lower-level Indexes and the aggregation of these Indexes into higher-order ones over a collection&#13;
     <html:span class="No-Break">&#13;
      of Documents.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The process begins by creating individual Indexes for each Document to capture the detailed information within the Documents. Additionally, summaries are defined for&#13;
     <html:span class="No-Break">&#13;
      each Document.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     is then constructed&#13;
     <html:a id="_idIndexMarker502">&#13;
     </html:a>&#13;
     using the&#13;
     <html:code class="literal">&#13;
      from_indices()&#13;
     </html:code>&#13;
     class method. It takes the root Index class (in our example, the&#13;
     <html:code class="literal">&#13;
      SummaryIndex&#13;
     </html:code>&#13;
     ), the child Indexes (in our example, the two&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     instances), and their corresponding summaries as input. The method creates&#13;
     <html:code class="literal">&#13;
      IndexNodes&#13;
     </html:code>&#13;
     instances for each child Index, associating the summary with the respective Index. These&#13;
     <html:code class="literal">&#13;
      IndexNodes&#13;
     </html:code>&#13;
     instances are then used to construct the&#13;
     <html:span class="No-Break">&#13;
      root Index.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     During a query, the&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     starts with the top-level summary Index, where each Node corresponds to an underlying lower-level Index. The query is executed recursively, starting from the root Index, and traversing through the sub-Indexes. The&#13;
     <html:code class="literal">&#13;
      ComposableGraphQueryEngine&#13;
     </html:code>&#13;
     is responsible for this recursive&#13;
     <html:span class="No-Break">&#13;
      querying process.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The query engine retrieves relevant Nodes from the root Index based on the query. For each relevant Node, it identifies the corresponding child Index using the&#13;
     <html:code class="literal">&#13;
      index_id&#13;
     </html:code>&#13;
     stored in the Node’s relationships. It then queries the child Index with the original query to obtain more detailed information. This process continues recursively until all relevant sub-Indexes have&#13;
     <html:span class="No-Break">&#13;
      been queried.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Custom query engines can be configured for each Index within the&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     , allowing for tailored retrieval strategies at different levels of the hierarchy. This enables a deep, hierarchical understanding of complex datasets by seamlessly integrating information from various levels&#13;
     <html:span class="No-Break">&#13;
      of Indexes.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Overall, the&#13;
     <html:code class="literal">&#13;
      ComposableGraph&#13;
     </html:code>&#13;
     allows for the efficient retrieval of relevant information from both high-level summaries and detailed, low-level Indexes, enabling a comprehensive understanding&#13;
     <html:a id="_idIndexMarker503">&#13;
     </html:a>&#13;
     of the&#13;
     <html:span class="No-Break">&#13;
      underlying data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Now that we have covered the Indexes available for our RAG implementation, it’s time to address the elephant in the room –&#13;
     <html:span class="No-Break">&#13;
      <html:strong class="bold">&#13;
       cost&#13;
      </html:strong>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor127">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Estimating the potential cost of building and querying Indexes&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-128">&#13;
    Estimating the potential cost of building and querying Indexes&#13;
   </html:h1>&#13;
   <html:div id="_idContainer052">&#13;
    import tiktoken&#13;
from llama_index.core import (&#13;
    TreeIndex, SimpleDirectoryReader, Settings)&#13;
from llama_index.core.llms.mock import MockLLM&#13;
from llama_index.core.callbacks import (&#13;
    CallbackManager, TokenCountingHandler)&#13;
    llm = MockLLM(max_tokens=256)&#13;
token_counter = TokenCountingHandler(&#13;
    tokenizer=tiktoken.encoding_for_model("gpt-3.5-turbo").encode&#13;
)&#13;
callback_manager = CallbackManager([token_counter])&#13;
Settings.callback_manager=callback_manager&#13;
Settings.llm=llm&#13;
    tiktoken.encoding_for_model("gpt-3.5-turbo").encode).&#13;
    documents = SimpleDirectoryReader(&#13;
    "cost_prediction_samples").load_data()&#13;
    index = TreeIndex.from_documents(&#13;
    documents=documents,&#13;
    num_children=2,&#13;
    show_progress=True)&#13;
print("Total LLM Token Count:", token_counter.total_llm_token_count)&#13;
    import tiktoken&#13;
from llama_index.core import (&#13;
    MockEmbedding, VectorStoreIndex,&#13;
    SimpleDirectoryReader, Settings)&#13;
from llama_index.core.callbacks import (&#13;
    CallbackManager, TokenCountingHandler)&#13;
from llama_index.core.llms.mock import MockLLM&#13;
    embed_model = MockEmbedding(embed_dim=1536)&#13;
llm = MockLLM(max_tokens=256)&#13;
token_counter = TokenCountingHandler(&#13;
    tokenizer=tiktoken.encoding_for_model("gpt-3.5-turbo").encode&#13;
)&#13;
callback_manager = CallbackManager([token_counter])&#13;
Settings.embed_model=embed_model&#13;
Settings.llm=llm&#13;
Settings.callback_manager=callback_manager&#13;
    documents = SimpleDirectoryReader(&#13;
    "cost_prediction_samples").load_data()&#13;
index = VectorStoreIndex.from_documents(&#13;
    documents=documents,&#13;
    show_progress=True)&#13;
print("Embedding Token Count:", &#13;
    token_counter.total_embedding_token_count)&#13;
    query_engine = index.as_query_engine(service_context=service_context)&#13;
response = query_engine.query("What's the cat's name?")&#13;
print("Query LLM Token Count:", token_counter.total_llm_token_count)&#13;
print("Query Embedding Token Count:",&#13;
    token_counter.total_embedding_token_count)&#13;
    <html:p>&#13;
     In a similar manner to metadata&#13;
     <html:a id="_idIndexMarker504">&#13;
     </html:a>&#13;
     extractors, Indexes pose issues related to costs and data privacy. That is because, as we have seen in this chapter, most Indexes rely on LLMs to some extent – during building&#13;
     <html:span class="No-Break">&#13;
      and/or querying.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Repeatedly calling LLMs&#13;
     <html:a id="_idIndexMarker505">&#13;
     </html:a>&#13;
     to process large volumes of text can quickly break your budget if you’re not paying attention to your potential costs. For example, if you are building a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     or&#13;
     <html:code class="literal">&#13;
      KeywordTableIndex&#13;
     </html:code>&#13;
     from thousands of documents, those constant LLM invocations during Index construction will carry a significant cost. Embeddings can also rely on calls to external models; therefore, the&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     is another important source of costs. In my experience, prevention and prediction are the best ways to avoid nasty surprises and keep your&#13;
     <html:span class="No-Break">&#13;
      expenses low.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Just like with metadata extraction, I’d start first by observing and applying some&#13;
     <html:span class="No-Break">&#13;
      best practices:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Use Indexes with no LLM calls during building where possible, such as&#13;
      <html:code class="literal">&#13;
       SummaryIndex&#13;
      </html:code>&#13;
      or&#13;
      <html:code class="literal">&#13;
       SimpleKeywordTableIndex&#13;
      </html:code>&#13;
      . This eliminates Index&#13;
      <html:span class="No-Break">&#13;
       building costs.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Use cheaper LLM models. If full accuracy isn’t critical, cheaper LLM models with lower computational demands can be used but be aware of possible&#13;
      <html:span class="No-Break">&#13;
       quality trade-offs.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Cache and reuse Indexes. Avoid rebuilding Indexes by caching and reusing previously&#13;
      <html:span class="No-Break">&#13;
       constructed ones.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Optimize query parameters to minimize LLM calls during your search. For example, reducing&#13;
      <html:code class="literal">&#13;
       similarity_top_k&#13;
      </html:code>&#13;
      in&#13;
      <html:code class="literal">&#13;
       VectorStoreIndex&#13;
      </html:code>&#13;
      will reduce your&#13;
      <html:span class="No-Break">&#13;
       query cost.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Use local models. To further manage costs and maintain data privacy when using Indexes in LlamaIndex, consider utilizing local LLM and embedding models instead of relying on hosted services. This approach not only offers more control over data privacy but also helps in reducing the dependency on external services, which can be costly. Using local models can significantly cut down on expenses, particularly when handling large volumes of data or when operating within strict&#13;
      <html:span class="No-Break">&#13;
       budget constraints.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p class="callout-heading">&#13;
     Important side note regarding local AI models&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Always remember that RAG&#13;
     <html:a id="_idIndexMarker506">&#13;
     </html:a>&#13;
     introduces additional knowledge and contextual information into the model’s processing, effectively bridging the gap caused by a smaller training dataset. So, even for models that haven’t been trained on extensive or diverse data, RAG allows them to access a broader range of information beyond their initial training set, thus enhancing their performance and&#13;
     <html:span class="No-Break">&#13;
      output quality.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     These guidelines will definitely&#13;
     <html:a id="_idIndexMarker507">&#13;
     </html:a>&#13;
     help you reduce costs, but it’s still a good idea to estimate before indexing&#13;
     <html:span class="No-Break">&#13;
      larger datasets.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here is a basic example of how we can estimate the LLM costs of building a&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     using&#13;
     <html:span class="No-Break">&#13;
      a&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       MockLLM&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In the previous part, we first took care of the necessary imports. If you’re unfamiliar with the reasons to use&#13;
     <html:code class="literal">&#13;
      tiktoken&#13;
     </html:code>&#13;
     as a tokenizer here, head back to&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 4&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Ingesting Data into Our RAG Workflow&#13;
     </html:em>&#13;
     where we discussed estimating the potential cost of using metadata extractors. Let’s set up the&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       MockLLM&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      next:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We just created a&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     instance with a specified maximum token limit acting as a worst-case maximal cost. We then initialized&#13;
     <html:code class="literal">&#13;
      TokenCountingHandler&#13;
     </html:code>&#13;
     with a tokenizer that matches our real LLM model using&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This handler will track token usage. This construct simulates an LLM without actually calling the&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       gpt-3.5-turbo&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      API:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’ve loaded our documents and are now ready to build&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       TreeIndex&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     After building the Index, the script&#13;
     <html:a id="_idIndexMarker508">&#13;
     </html:a>&#13;
     displays the&#13;
     <html:code class="literal">&#13;
      total_llm_token_count&#13;
     </html:code>&#13;
     value stored in&#13;
     <html:span class="No-Break">&#13;
      the&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       TokenCountingHandler&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this example, we’re only using the&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     class because there are no embeddings used for building the&#13;
     <html:code class="literal">&#13;
      TreeIndex&#13;
     </html:code>&#13;
     . This allows us to estimate the worst-case LLM token cost before actually building the Index and invoking the real LLM. The same method can be applied to estimate&#13;
     <html:span class="No-Break">&#13;
      query costs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     The main lesson here?&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     While Indexes unlock many capabilities, overuse without optimization can greatly impact costs. Always estimate token usage before indexing&#13;
     <html:span class="No-Break">&#13;
      larger datasets.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here is a second example. It’s similar to the previous one, but this time, we’re first estimating the embedding costs of building a&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     and after that, the total cost of querying&#13;
     <html:span class="No-Break">&#13;
      the Index:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The first part took care&#13;
     <html:a id="_idIndexMarker509">&#13;
     </html:a>&#13;
     of the imports. Next, we set up the&#13;
     <html:code class="literal">&#13;
      MockEmbedding&#13;
     </html:code>&#13;
     and&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       MockLLM&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      objects:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     After initializing the&#13;
     <html:code class="literal">&#13;
      MockEmbedding&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     objects, we defined a&#13;
     <html:code class="literal">&#13;
      TokenCountingHandler&#13;
     </html:code>&#13;
     and a&#13;
     <html:code class="literal">&#13;
      CallbackManager&#13;
     </html:code>&#13;
     and wrapped them into the custom&#13;
     <html:code class="literal">&#13;
      Settings&#13;
     </html:code>&#13;
     . It’s now time to load our sample documents and build the&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     using the&#13;
     <html:span class="No-Break">&#13;
      custom&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       Settings&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If you have successfully cloned the book’s GitHub repo, the&#13;
     <html:code class="literal">&#13;
      cost_prediction_samples&#13;
     </html:code>&#13;
     subfolder in the&#13;
     <html:code class="literal">&#13;
      ch5&#13;
     </html:code>&#13;
     folder should contain a file with a fictional story about&#13;
     <html:code class="literal">&#13;
      Fluffy the cat&#13;
     </html:code>&#13;
     . The&#13;
     <html:code class="literal">&#13;
      VectorStoreIndex&#13;
     </html:code>&#13;
     uses an embedding model to encode document text into vectors during indexing. In our second example, we estimated the token costs of those embedding calls by using&#13;
     <html:code class="literal">&#13;
      MockEmbedding&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      TokenCountingHandler&#13;
     </html:code>&#13;
     . The embedding token count provides an indication of how expensive it will be to build this Index per document based on the&#13;
     <html:span class="No-Break">&#13;
      text lengths.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     To have a complete view, we can take this a step further and also estimate&#13;
     <html:span class="No-Break">&#13;
      search costs:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This shows the potential search fees as well by counting tokens for embedding lookups and synthesizing the response. We also had to use&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     to catch the LLM tokens hypothetically consumed during&#13;
     <html:span class="No-Break">&#13;
      response synthesis.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     So, in summary, follow preventive&#13;
     <html:a id="_idIndexMarker510">&#13;
     </html:a>&#13;
     best practices and always forecast your Index build and query expenses before unleashing them on your full&#13;
     <html:span class="No-Break">&#13;
      document collection!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     It’s time to make some progress with our project. Let’s revisit our&#13;
     <html:span class="No-Break">&#13;
      PITS project.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor128">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html></body></html>