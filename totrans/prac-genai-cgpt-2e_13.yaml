- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Leveraging OpenAI’s Models for Enterprise-Scale Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 OpenAI 模型进行企业级应用
- en: In this chapter, we’ll focus on the enterprise-level applications of **generative
    AI** (**GenAI**) and, more specifically, of OpenAI’s models. We will see how different
    industries have been massively impacted by GenAI in recent years, and what kinds
    of trending patterns and applications have emerged.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章，我们将重点关注企业级应用 **生成式人工智能**（**GenAI**）以及更具体地说，OpenAI 的模型。我们将看到不同行业近年来如何受到 GenAI
    的巨大影响，以及出现了哪些趋势模式和应用程序。
- en: 'In this chapter, we will discuss the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将讨论以下主题：
- en: The latest advancements in various industries (including healthcare, financial
    services, retail, and more), driven by the outstanding capabilities of powerful
    LLMs, highlighting the most trending use cases
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由强大的 LLMs 驱动的各个行业（包括医疗保健、金融服务、零售等）的最新进展，突出了最热门的应用案例
- en: The architectural framework behind custom applications powered by OpenAI’s models,
    unveiling the versatility and adoption of the models’ APIs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 模型驱动的自定义应用程序背后的架构框架，揭示模型 API 的多功能性和采用情况
- en: Introduction to Azure OpenAI, the Microsoft cloud-based service that mirrors
    OpenAI’s Playground and offers OpenAI’s models directly within the perimeter of
    Azure subscriptions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure OpenAI 介绍，这是微软基于云的服务，它反映了 OpenAI 的游乐场，并在 Azure 订阅范围内直接提供 OpenAI 的模型
- en: By the end of this chapter, you will have learned about the main GenAI patterns
    across various industries, and how to leverage OpenAI’s models’ APIs within your
    own applications. Plus, you will have a clearer understanding of the cloud-scale
    service of Azure OpenAI and how to incorporate ethical considerations when developing
    AI-based solutions.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解各个行业中主要的 GenAI 模式，以及如何在你的应用程序中利用 OpenAI 模型的 API。此外，你将对 Azure OpenAI
    的云规模服务有一个更清晰的理解，以及如何在开发基于 AI 的解决方案时考虑道德因素。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following are the technical requirements for this chapter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为本章的技术要求：
- en: An OpenAI account, chat model, and embedding model deployments
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 账户、聊天模型和嵌入模型部署
- en: '[Optional] An Azure subscription and Azure OpenAI instance, with chat model
    and embedding model deployments'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可选] 一个 Azure 订阅和 Azure OpenAI 实例，包括聊天模型和嵌入模型部署'
- en: Python 3.7.1 or a later version
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7.1 或更高版本
- en: 'You can refer to the following repository for the OpenAI Python SDKs: https://github.com/openai/openai-python.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下存储库以获取 OpenAI Python SDKs：https://github.com/openai/openai-python。
- en: How GenAI is disrupting industries
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GenAI 如何颠覆行业
- en: LLMs, and GenAI in general, are revolutionizing various industries by introducing
    unprecedented levels of automation, creativity, and efficiency. In recent years,
    we’ve witnessed a huge wave of innovation across different industries that all
    agree that not seizing the GenAI opportunity would mean falling behind in a competitive
    market.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 和 GenAI 在一般意义上正在通过引入前所未有的自动化、创造力和效率来改变各个行业。近年来，我们见证了不同行业创新浪潮的巨大浪潮，所有这些行业都认为，如果不抓住
    GenAI 机会，就意味着在竞争激烈的市场中落后。
- en: Let’s see some examples.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些例子。
- en: Healthcare
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 医疗保健
- en: 'In healthcare, GenAI and LLMs are enhancing diagnostics, personalized medicine,
    and administrative tasks:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在医疗保健领域，通用人工智能（GenAI）和大型语言模型（LLMs）正在增强诊断、个性化医疗和行政任务：
- en: '**Diagnostics**: LLMs like GPT-4 are being used to analyze medical images,
    predict diseases, and suggest treatment plans. For instance, AI-powered tools
    can now analyze radiology images with high accuracy, identifying early signs of
    conditions like cancer or heart disease, often outperforming human radiologists
    in speed and consistency. A great example of the latest advancements in the computer
    vision field is given in an article by Tyler J. Bradshaw et al., “Large Language
    Models and Large Multimodal Models in Medical Imaging: A Primer for Physicians”,
    published in *The Journal of Nuclear Medicine* (you can find it at https://jnm.snmjournals.org/content/early/2025/01/16/jnumed.124.268072).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**诊断**：LLMs 如 GPT-4 正被用于分析医学图像、预测疾病和提出治疗方案。例如，AI 驱动的工具现在可以以高精度分析放射学图像，识别癌症或心脏病等疾病的早期迹象，通常在速度和一致性方面优于人类放射科医生。在
    Tyler J. Bradshaw 等人发表在《核医学杂志》（https://jnm.snmjournals.org/content/early/2025/01/16/jnumed.124.268072）上的文章中，给出了计算机视觉领域最新进展的一个很好的例子，“大型语言模型和大型多模态模型在医学成像中的应用：为医生提供入门指南”。'
- en: '**Personalized medicine**: GenAI is helping in the development of personalized
    treatment plans by analyzing patient data, including genetic information. This
    has led to tailored therapies that improve outcomes.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化医疗**：通用人工智能（GenAI）通过分析包括遗传信息在内的患者数据，帮助开发个性化治疗方案。这导致了定制疗法，从而改善了结果。'
- en: '**Administrative efficiency**: LLMs are streamlining administrative tasks such
    as patient record management and appointment scheduling. AI chatbots can handle
    patient queries, reducing the workload on medical staff.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行政效率**：大型语言模型（LLMs）正在简化行政任务，如患者记录管理和预约安排。AI聊天机器人可以处理患者查询，减轻医疗人员的工作负担。'
- en: Case study
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: OpenAI has partnered with Summer Health, a healthcare service that provides
    fast and convenient access to pediatric care through text messaging. The collaboration
    aims to enhance the capabilities of Summer Health’s platform by integrating OpenAI’s
    advanced language models. This integration enables more efficient and accurate
    responses to parents’ healthcare inquiries, providing quick, reliable medical
    advice for children’s health concerns. This has led to increased efficiency and
    improved timeliness, with data being kept anonymous. The AI-driven platform helps
    streamline communication between parents and healthcare professionals, improving
    the overall experience and accessibility of pediatric care.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI与Summer Health合作，Summer Health是一家提供通过短信快速便捷获取儿科护理的健康服务公司。这次合作旨在通过整合OpenAI的高级语言模型来增强Summer
    Health平台的功能。这种集成使得对父母医疗咨询的响应更加高效和准确，为儿童的健康问题提供快速、可靠的医疗建议。这导致了效率的提高和及时性的改善，同时数据保持匿名。由AI驱动的平台帮助简化父母和医疗专业人员之间的沟通，提高了儿科护理的整体体验和可及性。
- en: '*Source:* https://openai.com/index/summer-health/.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*来源:* https://openai.com/index/summer-health/.'
- en: Finance
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 金融
- en: 'In finance, GenAI and LLMs are transforming risk management, customer service,
    and investment strategies:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，通用人工智能（GenAI）和大型语言模型（LLMs）正在改变风险管理、客户服务和投资策略：
- en: '**Claim management**: LLMs are employed to automate the summarization, review,
    triage, and adjudication of claims. For instance, Munich Re developed an LLM-powered
    solution for claim management that led to a streamlined claims process, reduced
    manual effort, and improved decision-making accuracy (https://www.munichre.com/us-life/en/insights/future-of-risk/large-language-models-in-underwriting-and-claims.html).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**索赔管理**：大型语言模型（LLMs）被用于自动化索赔的总结、审查、分类和裁决。例如，慕尼黑再保险公司开发了一个由LLM驱动的索赔管理解决方案，该方案使索赔流程简化，减少了人工工作量，并提高了决策准确性（https://www.munichre.com/us-life/en/insights/future-of-risk/large-language-models-in-underwriting-and-claims.html）。'
- en: '**Customer service**: AI-driven chatbots and virtual assistants are now common
    in the finance sector, handling customer inquiries, processing transactions, and
    providing financial advice. ING’s AI assistant is a prime example of a virtual
    assistant that helps customers manage their finances by providing insights, reminders,
    and transaction details (https://www.mckinsey.com/industries/financial-services/how-we-help-clients/banking-on-innovation-how-ing-uses-generative-ai-to-put-people-first).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户服务**：在金融领域，由AI驱动的聊天机器人和虚拟助手现在很常见，它们处理客户咨询、处理交易并提供财务建议。ING的AI助手是一个典型的虚拟助手示例，它通过提供见解、提醒和交易详情来帮助客户管理他们的财务（https://www.mckinsey.com/industries/financial-services/how-we-help-clients/banking-on-innovation-how-ing-uses-generative-ai-to-put-people-first）。'
- en: '**Investment strategies**: Hedge funds and investment firms are using GenAI
    to create predictive models that inform trading decisions. AI algorithms analyze
    market data to identify patterns and make real-time trading decisions. BlackRock’s
    Aladdin platform is one such example, leveraging AI to manage investments and
    assess market risks (https://www.blackrock.com/aladdin/solutions/aladdin-copilot).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资策略**：对冲基金和投资公司正在使用通用人工智能（GenAI）来创建预测模型，这些模型为交易决策提供信息。AI算法分析市场数据以识别模式并做出实时交易决策。BlackRock的Aladdin平台就是这样一个例子，它利用AI来管理投资和评估市场风险（https://www.blackrock.com/aladdin/solutions/aladdin-copilot）。'
- en: Case study
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: Moody’s Corporation, a leading global provider of credit ratings, research,
    and risk analysis, has partnered with Microsoft to develop enhanced risk data
    analytics and research solutions powered by GenAI. This collaboration combines
    Moody’s vast expertise in financial risk and data analytics with Microsoft’s advanced
    AI technology. The result is a set of tools that offer real-time insights into
    financial risks, enabling more precise decision-making and improved risk management
    for financial institutions and other stakeholders.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 标准普尔评级公司（Moody’s Corporation），作为全球领先的信用评级、研究和风险分析提供商，已与微软合作开发由GenAI驱动的增强风险数据分析和研究解决方案。这次合作将标准普尔在金融风险和数据分析方面的广泛专业知识与微软先进的AI技术相结合。结果是提供实时洞察金融风险的工具集，使金融机构和其他利益相关者能够做出更精确的决策并改善风险管理。
- en: 'Source: https://news.microsoft.com/2023/06/29/moodys-and-microsoft-develop-enhanced-risk-data-analytics-research-and-collaboration-solutions-powered-by-generative-ai/?msockid=2dc01bb6f864693933ed0eb3f9a668dc.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：https://news.microsoft.com/2023/06/29/moodys-and-microsoft-develop-enhanced-risk-data-analytics-research-and-collaboration-solutions-powered-by-generative-ai/?msockid=2dc01bb6f864693933ed0eb3f9a668dc.
- en: Retail and e-commerce
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零售和电子商务
- en: 'In retail and e-commerce, GenAI and LLMs are enhancing customer experience,
    inventory management, and personalized marketing:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在零售和电子商务领域，GenAI和LLMs正在提升客户体验、库存管理和个性化营销：
- en: '**Customer experience**: AI-powered chatbots provide personalized customer
    service, helping shoppers find products, resolve issues, and make purchases.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户体验**：AI驱动的聊天机器人提供个性化客户服务，帮助购物者找到产品、解决问题并完成购买。'
- en: '**Inventory management**: LLMs help retailers predict demand and optimize inventory
    levels by analyzing sales data, seasonal trends, and customer behavior.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库存管理**：LLMs通过分析销售数据、季节性趋势和客户行为，帮助零售商预测需求并优化库存水平。'
- en: '**Personalized marketing**: GenAI is enabling hyper-personalized marketing
    campaigns. By analyzing customer data, AI can create targeted advertisements and
    product recommendations.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化营销**：通用人工智能（GenAI）正在推动超个性化营销活动。通过分析客户数据，AI可以创建有针对性的广告和产品推荐。'
- en: Case study
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: Coca-Cola has launched an innovative initiative inviting digital artists to
    create unique artworks using a new AI-powered platform developed in collaboration
    with **Google Cloud Platform** (**GCP**). This platform allows artists to generate
    digital content by blending Coca-Cola’s iconic branding elements with their creativity.
    The initiative, called “Create Real Magic,” leverages advanced AI tools to inspire
    and empower artists, facilitating the creation of digital art that resonates with
    Coca-Cola’s brand ethos. This project highlights how AI can be used to bridge
    creativity and technology in the retail and consumer goods industry.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 可口可乐公司推出了一项创新计划，邀请数字艺术家使用与**谷歌云平台**（**GCP**）合作开发的新AI平台创作独特的艺术作品。该平台允许艺术家通过结合可口可乐的标志性品牌元素和他们的创造力来生成数字内容。名为“创造真实魔法”的这项计划利用先进的AI工具激发和赋权艺术家，促进与可口可乐品牌理念产生共鸣的数字艺术创作。该项目突显了AI如何在零售和消费品行业中架起创造力和技术之间的桥梁。
- en: 'Source: https://brandthechange.com/creativity/create-real-magic-inside-coca-colas-first-ai-powered-campaign/#:~:text=The%20Coca-Cola%20Company%20has%20partnered%20with%20OpenAI%20and,using%20iconic%20creative%20assets%20from%20the%20Coca-Cola%20archives.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：https://brandthechange.com/creativity/create-real-magic-inside-coca-colas-first-ai-powered-campaign/#:~:text=The%20Coca-Cola%20Company%20has%20partnered%20with%20OpenAI%20and%2Cusing%20iconic%20creative%20assets%20from%20the%20Coca-Cola%20archives.
- en: Manufacturing
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 制造业
- en: 'In manufacturing, GenAI and LLMs are driving automation, quality control, and
    supply chain optimization:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在制造业中，GenAI和LLMs正在推动自动化、质量控制和供应链优化：
- en: '**Automation**: AI-powered robots and systems are automating repetitive tasks,
    such as assembly line work and material handling.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化**：AI驱动的机器人和系统正在自动化重复性任务，如装配线工作和物料处理。'
- en: '**Quality control**: LLMs are used to monitor production processes in real
    time, identifying defects or inefficiencies. AI systems can analyze data from
    sensors and cameras to detect anomalies in products, ensuring higher quality.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量控制**：大型语言模型（LLMs）用于实时监控生产过程，识别缺陷或不效率。AI系统可以分析传感器和摄像头数据，以检测产品中的异常，确保更高的质量。'
- en: '**Supply chain optimization**: AI models help manufacturers optimize their
    supply chains by predicting demand, managing inventory, and selecting suppliers.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应链优化**：AI模型通过预测需求、管理库存和选择供应商，帮助制造商优化其供应链。'
- en: Case study
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: Iveco Group, a leading global manufacturer of commercial vehicles, has partnered
    with Microsoft to integrate Azure OpenAI Service into its business processes.
    The customer developed an internal smart chatbot called “Chat IVG”, which can
    be used for questions and answers and to extract information from the organization’s
    own data and documents. Plus, numerous use cases and autonomous projects are being
    developed and deployed in production, either leveraging Chat IVG’s specific customizations
    or using its architecture as a foundation. Chat IVG is driving significant impact
    by enhancing internal business user experiences, boosting productivity across
    various business units, and enabling faster, more efficient [customer support.](https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Iveco集团，全球领先的商用车制造商，已与微软合作，将 Azure OpenAI 服务整合到其业务流程中。客户开发了一个名为“Chat IVG”的内部智能聊天机器人，可用于问答以及从组织自己的数据和文档中提取信息。此外，还在开发和部署大量用例和自主项目，这些项目要么利用
    Chat IVG 的特定定制，要么以 Chat IVG 的架构为基础。Chat IVG 通过提升内部业务用户体验、提高各个业务单元的生产力以及实现更快、更高效的[客户支持](https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy)产生了重大影响。
- en: '[Source: https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-](https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy)service-manufacturing-italy.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源：https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-](https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy)service-manufacturing-italy.'
- en: Media and entertainment
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 媒体和娱乐
- en: 'In media and entertainment, GenAI and LLMs are revolutionizing content creation,
    audience engagement, and media distribution:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在媒体和娱乐领域，生成式AI和LLMs正在革命性地改变内容创作、受众参与和媒体分发：
- en: '**Content creation**: GenAI is being used to generate content, from writing
    articles to composing music. For example, The Washington Post uses AI to write
    short news articles and reports, freeing up journalists to focus on more complex
    stories. In music, AI platforms like OpenAI’s MuseNet can compose original music
    tracks in various styles, aiding musicians in the creative process.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容创作**：生成式AI被用于生成内容，从撰写文章到创作音乐。例如，《华盛顿邮报》使用AI撰写简短的新闻文章和报道，让记者能够专注于更复杂的故事。在音乐领域，像OpenAI的MuseNet这样的AI平台可以创作各种风格的原声音乐曲目，帮助音乐家在创作过程中。'
- en: '**Audience engagement**: LLMs analyze user data to deliver personalized content
    recommendations, keeping audiences engaged. Netflix uses AI to recommend movies
    and TV shows based on viewers’ preferences, significantly increasing viewer retention.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**受众参与**：LLMs 通过分析用户数据来提供个性化的内容推荐，保持受众的参与度。Netflix 使用 AI 根据观众的偏好推荐电影和电视剧，显著提高了观众的留存率。'
- en: '**Media distribution**: AI is also optimizing media distribution by analyzing
    audience demographics and consumption patterns. Spotify uses AI to curate personalized
    playlists, ensuring that users discover new music tailored to their tastes.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体分发**：AI 通过分析受众人口统计和消费模式，也在优化媒体分发。Spotify 使用 AI 来创建个性化的播放列表，确保用户发现符合他们口味的全新音乐。'
- en: Case study
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: Microsoft’s Xbox division has announced a multi-year partnership with Inworld
    AI to develop advanced GenAI tools for game development. This collaboration aims
    to enhance character dialogue and narrative creation by integrating Inworld’s
    expertise in GenAI with Microsoft’s Azure OpenAI Service and insights from Microsoft
    Research. The goal is to empower game developers to create more dynamic and immersive
    gaming experiences.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的Xbox部门宣布与Inworld AI签订了一项多年合作协议，旨在开发用于游戏开发的先进生成式AI工具。这次合作旨在通过整合Inworld在生成式AI方面的专业知识与微软的Azure
    OpenAI服务和微软研究洞察力，来提升角色对话和叙事创作。目标是赋予游戏开发者创造更动态和沉浸式游戏体验的能力。
- en: 'Source: https://developer.microsoft.com/en-us/games/articles/2023/11/xbox-and-inworld-ai-partnership-announcement/.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：https://developer.microsoft.com/en-us/games/articles/2023/11/xbox-and-inworld-ai-partnership-announcement/.
- en: Legal services
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 法律服务
- en: 'In the legal industry, GenAI and LLMs are transforming research, contract analysis,
    and case prediction:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在法律行业，生成式AI和LLMs正在改变研究、合同分析和案例预测：
- en: '**Legal research**: AI tools are accelerating legal research by analyzing vast
    amounts of legal documents, case laws, and statutes. For example, ROSS Intelligence
    uses AI to provide lawyers with relevant case laws and legal precedents in seconds,
    which would otherwise take hours to find manually.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律研究**：AI工具通过分析大量法律文件、案例法和法规来加速法律研究。例如，ROSS Intelligence利用AI在几秒钟内为律师提供相关的案例法和法律先例，这原本需要手动查找数小时。'
- en: '**Contract analysis**: LLMs are used to review and analyze contracts, identifying
    key terms, risks, and compliance issues. This helps in speeding up negotiations
    and ensuring that contracts are airtight. Kira Systems is one example where AI
    reviews contracts for due diligence, identifying clauses and potential risks.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合同分析**：LLMs被用于审查和分析合同，识别关键条款、风险和合规问题。这有助于加快谈判并确保合同无懈可击。Kira Systems就是一个例子，它使用AI审查合同以进行尽职调查，识别条款和潜在风险。'
- en: '**Case prediction**: GenAI is being used to predict the outcomes of legal cases
    based on historical data. By analyzing past cases, AI can provide lawyers with
    insights into likely judgments, helping them strategize better. Lex Machina, for
    example, uses AI to predict how judges might rule in intellectual property disputes.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例预测**：GenAI正在被用于根据历史数据预测法律案件的结果。通过分析过去的案例，AI可以为律师提供可能判决的见解，帮助他们更好地制定策略。例如，Lex
    Machina使用AI预测法官在知识产权纠纷中可能如何判决。'
- en: Case study
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: Ironclad, a leading digital contracting platform, has partnered with OpenAI
    to integrate advanced AI capabilities into its legal workflows. By leveraging
    OpenAI’s language models, Ironclad enhances its platform’s ability to automate
    contract analysis, generate and review legal documents, and provide insights to
    legal teams more efficiently.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Ironclad，一家领先的数字合同平台，已与OpenAI合作，将其高级AI功能集成到其法律工作流程中。通过利用OpenAI的语言模型，Ironclad增强了其平台自动化合同分析、生成和审查法律文件以及更高效地向法律团队提供见解的能力。
- en: This integration allows for faster, more accurate contract processing, reducing
    the time spent on manual reviews and enabling legal teams to focus on higher-value
    tasks. The collaboration underscores the growing role of AI in transforming the
    legal industry by improving accuracy and productivity in contract management.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这种集成使得合同处理更快、更准确，减少了手动审查所需的时间，并使法律团队能够专注于更高价值的工作。这种合作凸显了AI在通过提高合同管理中的准确性和生产力来转型法律行业中所日益增长的作用。
- en: Education
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 教育
- en: 'In education, GenAI and LLMs are transforming learning experiences, personalized
    education, and administrative tasks:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在教育领域，GenAI和LLMs正在改变学习体验、个性化教育和行政任务：
- en: '**Learning experiences**: AI-driven platforms are creating personalized learning
    paths for students based on their strengths and weaknesses. For instance, platforms
    like Coursera use AI to recommend courses and resources tailored to each learner’s
    progress and preferences.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习体验**：AI驱动的平台正在根据学生的优势和劣势为学生创建个性化的学习路径。例如，Coursera等平台使用AI推荐课程和资源，这些课程和资源是根据每个学习者的进度和偏好定制的。'
- en: '**Personalized education**: LLMs can tutor students by answering questions,
    explaining concepts, and providing feedback on assignments. Khan Academy’s AI-powered
    tutor is an example, offering personalized help to students struggling with specific
    topics.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化教育**：LLMs可以通过回答问题、解释概念和提供作业反馈来辅导学生。Khan Academy的AI辅导老师就是一个例子，为在特定主题上遇到困难的学生提供个性化帮助。'
- en: '**Administrative tasks**: AI is also being used to automate administrative
    tasks such as grading and scheduling. For instance, Turnitin uses AI to grade
    essays and detect plagiarism, saving educators time and ensuring academic integrity.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行政任务**：AI还被用于自动化诸如评分和排程等行政任务。例如，Turnitin使用AI来评分和检测剽窃，节省了教育者的时间并确保了学术诚信。'
- en: Case study
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: Khan Academy has partnered with OpenAI to incorporate advanced AI capabilities
    into its educational platform. By integrating OpenAI’s language models, Khan Academy
    is able to provide personalized tutoring, answer student queries, and assist with
    learning in a more interactive and dynamic way. This collaboration aims to enhance
    the educational experience by offering students real-time assistance and tailored
    support, making learning more accessible and effective. The AI-powered tools help
    students grasp complex concepts, provide instant feedback, and adapt to individual
    learning styles, further democratizi[ng education through technology.](https://openai.com/index/khan-academy/)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 可汗学院与 OpenAI 合作，将先进的 AI 功能整合到其教育平台上。通过集成 OpenAI 的语言模型，可汗学院能够提供个性化辅导，回答学生问题，并以更互动和动态的方式协助学习。这次合作旨在通过提供实时帮助和定制支持，增强教育体验，使学习更加便捷和有效。AI
    驱动的工具帮助学生掌握复杂概念，提供即时反馈，并适应个人学习风格，进一步通过技术民主化教育。[更多信息](https://openai.com/index/khan-academy/)
- en: '[Sourc](https://openai.com/index/khan-academy/)e: https://openai.com/index/khan-academy/.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://openai.com/index/khan-academy/)'
- en: 'The above examples are just a subset of the possibilities that GenAI has enabled
    in various industries. However, there is an element that unites all the examples
    covered: in each scenario, a custom application was built leveraging an LLM API.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上述例子只是 GenAI 在各个行业中实现的可能性的一个子集。然而，有一个元素将所有涵盖的例子统一起来：在每个场景中，都通过利用 LLM API 构建了定制应用程序。
- en: Understanding OpenAI models’ APIs
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 OpenAI 模型 API
- en: 'In *Chapter 1* of this book, we saw how LLMs have introduced a paradigm shift
    in the landscape of AI: different from the tailored, highly specialized models
    that featured AI in the “before ChatGPT era,” LLMs are now able to be generalized
    and tackle different tasks depending on the user’s query.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的**第一章**中，我们看到了 LLM 如何在 AI 领域中引入范式转变：与“ChatGPT 时代之前”以 AI 为特色的定制、高度专业化的模型不同，LLM
    现在能够被泛化并根据用户的查询处理不同的任务。
- en: 'Furthermore, there is one additional element that sets LLMs apart from previous
    models: in fact, LLMs typically come as pre-trained objects that anyone – even
    without any experience in the field of AI – can use with the easiest way of interacting:
    natural language.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个额外的元素将 LLM 与之前的模型区分开来：实际上，LLM 通常作为预训练对象提供，任何人——即使没有任何 AI 领域的经验——也可以通过最简单的方式与之交互：自然语言。
- en: 'Of course, no one is stopping you from designing and training your LLM from
    scratch, but be aware that this will require, at least:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，没有人阻止你从头开始设计和训练你的大型语言模型（LLM），但请注意，这至少需要：
- en: Technical knowledge on how to design the model
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计模型的技术知识
- en: A huge amount of training data
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量的训练数据
- en: Specialized infrastructure that can support the training and inference stages
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持训练和推理阶段的专业基础设施
- en: A lot of time to invest in the project
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在项目中投入大量时间
- en: If the above elements used to be a barrier to entry for many AI developers in
    the past, now the paradigm has shifted. The new focus, in fact, is how to efficiently
    build everything that lives *around* an LLM, such as the system message, **vector
    databases** (**VectorDBs**), plugins, and so forth. That’s the reason why using
    LLMs’ APIs is now the validated pattern for building GenAI applications.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上述元素过去曾是许多 AI 开发者进入该领域的障碍，那么现在范式已经转变。实际上，新的焦点是如何高效地构建围绕 LLM 的所有内容，例如系统消息、**向量数据库**（**VectorDBs**）、插件等等。这就是为什么现在使用
    LLM 的 API 已经成为构建 GenAI 应用程序的验证模式。
- en: What is a model API?
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是模型 API？
- en: Before talking about OpenAI models’ APIs, let’s first refresh our definition
    of what an API is.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论 OpenAI 模型 API 之前，让我们首先刷新一下 API 的定义。
- en: An **application programming interface** (**API**) is a set of rules and tools
    that allows different software applications to communicate with each other. It’s
    like a translator that helps different programs or systems work together by sharing
    data and functionality in a standardized way. For example, when you use an app
    to check the weather, the app uses an API to get the weather information from
    a weather service.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用程序编程接口**（**API**）是一套规则和工具，允许不同的软件应用程序之间相互通信。它就像一个翻译者，通过以标准化的方式共享数据和功能，帮助不同的程序或系统协同工作。例如，当你使用应用程序检查天气时，该应用程序使用
    API 从天气服务获取天气信息。'
- en: '![](img/B31559_10_01.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_10_01.png)'
- en: 'Figure 10.1: A weather app using an API to gather information'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1：使用 API 收集信息的天气应用程序
- en: 'Now, when it comes to LLMs’ APIs, the mechanism is similar. More specifically,
    LLMs’ APIs fall within the category of **Representational State Transfer** (**REST**)
    APIs, meaning that they:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当涉及到 LLMs 的 API 时，机制是相似的。更具体地说，LLMs 的 API 属于 **表示状态转移**（**REST**）API 的范畴，这意味着它们：
- en: Use standard HTTP methods (POST for sending prompts, GET for retrieving data).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用标准 HTTP 方法（POST 用于发送提示，GET 用于检索数据）。
- en: Communicate over HTTP/HTTPS.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 HTTP/HTTPS 进行通信。
- en: Return responses in JSON format.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以 JSON 格式返回响应。
- en: Follow a stateless model, meaning each request is independent.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵循无状态模型，意味着每个请求都是独立的。
- en: '**Definition**'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**定义**'
- en: A **REST API** is a web-based API that follows REST principles, using HTTP methods
    like GET, POST, PUT, and DELETE to interact with resources via URLs. It is stateless,
    meaning each request is independent, and it typically exchanges data in JSON format.
    Other types of APIs include **SOAP**, which relies on XML for structured messaging
    and strict security; **GraphQL**, which allows clients to request specific data
    for more flexibility; **gRPC**, which uses Protocol Buffers for efficient microservice
    communication; **WebSockets**, which enables real-time, two-way communication;
    and **Streaming APIs**, which provide continuous data flow, often used for AI
    responses and stock market feeds.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**REST API** 是遵循 REST 原则的基于 Web 的 API，使用 HTTP 方法如 GET、POST、PUT 和 DELETE 通过
    URL 与资源交互。它是无状态的，意味着每个请求都是独立的，并且通常以 JSON 格式交换数据。其他类型的 API 包括 **SOAP**，它依赖于 XML
    进行结构化消息和严格的安全；**GraphQL**，它允许客户端请求特定数据以获得更多灵活性；**gRPC**，它使用 Protocol Buffers 进行高效的微服务通信；**WebSockets**，它使实时双向通信成为可能；以及
    **流式 API**，它提供连续数据流，常用于 AI 响应和股市信息流。'
- en: 'Let’s explore how you might use an OpenAI model’s API to create a marketing
    assistant. This assistant helps marketers generate content like social media posts,
    email drafts, ad copy, or blog post ideas. Let’s break down the whole process:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨您如何使用 OpenAI 模型的 API 来创建一个营销助理。这个助理帮助营销人员生成内容，如社交媒体帖子、电子邮件草稿、广告文案或博客文章想法。让我们分解整个过程：
- en: '**Sending a request**:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**发送请求**：'
- en: A marketer using your application might type a prompt like, “Create a social
    media post promoting our new eco-friendly product line.”
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用您应用程序的营销人员可能会输入一个提示，例如：“创建一篇推广我们新环保产品系列的社交媒体帖子。”
- en: Your marketing assistant sends this prompt to the OpenAI model’s API as part
    of a request. The request includes the prompt and any specific instructions, including
    the model to use – let’s say, the GPT-4o.
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的市场助理将此提示作为请求的一部分发送到 OpenAI 模型的 API。该请求包括提示和任何特定指令，包括要使用的模型——比如说，GPT-4o。
- en: '**Processing by the model**:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型处理**：'
- en: The OpenAI API receives the request and processes the prompt using the specified
    model (in our case, the GPT-4o).
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI API 接收请求并使用指定的模型（在我们的例子中是 GPT-4o）处理提示。
- en: The model generates a response by analyzing the input and drawing on its extensive
    knowledge base. It considers factors like the target audience, common marketing
    phrases, and the desired tone to create relevant content.
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型通过分析输入并利用其广泛的知识库生成响应。它考虑因素如目标受众、常见营销用语和期望的语气，以创建相关内容。
- en: '**Receiving the response**:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**接收响应**：'
- en: The API sends the generated content back to your marketing assistant application
    as a response.
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 将生成的内容作为响应发送回您的营销助理应用程序。
- en: 'For instance, the model might generate something like: “Excited to launch our
    new eco-friendly product line! Sustainable, stylish, and perfect for the conscious
    consumer. Join us in making a positive impact—shop now and save the planet, one
    product at a time! #EcoFriendly #Sustainability.”'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '例如，模型可能会生成类似以下内容：“兴奋地推出我们新的环保产品系列！可持续、时尚，完美适合有意识的消费者。加入我们，共同创造积极影响——现在购物并拯救地球，一次一个产品！#环保友好
    #可持续性。”'
- en: '**Displaying the response**:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**显示响应**：'
- en: Your application receives the content from the API and displays it to the marketer.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的应用程序从 API 接收内容并将其显示给营销人员。
- en: The marketer can then review, edit, and publish the content as needed, saving
    time and effort in the content creation process.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 营销人员可以随后根据需要审查、编辑和发布内容，从而在内容创作过程中节省时间和精力。
- en: '**Additional features**:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**附加功能**：'
- en: '**Customization**: The marketer can further customize the request. For example,
    they might ask for a series of posts or request variations to test different marketing
    angles.'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定制**：营销人员可以进一步定制请求。例如，他们可能会要求一系列帖子或请求变化以测试不同的营销角度。'
- en: '**Feedback loop**: The application might also allow the marketer to rate the
    generated content. This feedback could be used to fine-tune future requests, improving
    the relevance and quality of the content over time.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈循环**：应用程序可能还允许营销人员对生成的内容进行评分。这种反馈可以用于微调未来的请求，随着时间的推移提高内容的关联性和质量。'
- en: '**Behind the scenes**:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**幕后**：'
- en: '**API key and authentication**: To use the OpenAI API, your application needs
    an API key (a unique alphanumeric string used to authenticate and identify applications
    or projects making requests to an API), which ensures that only authorized users
    can access the service.'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API密钥和身份验证**：要使用OpenAI API，您的应用程序需要一个API密钥（一个用于验证和识别向API发送请求的应用程序或项目的唯一字母数字字符串），这确保只有授权用户可以访问该服务。'
- en: '**Handling multiple requests**: The OpenAI API is designed to handle multiple
    requests at once, meaning it can serve many marketers simultaneously without slowing
    down.'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理多个请求**：OpenAI API被设计为可以同时处理多个请求，这意味着它可以在不减速的情况下同时为许多营销人员提供服务。'
- en: '**Rate limits and cost**: Depending on the API usage, there might be rate limits
    (e.g., how many requests can be sent per minute) and costs associated with the
    amount of text processed. Your application would need to manage these factors,
    perhaps by prioritizing certain requests or batching them.'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速率限制和成本**：根据API使用情况，可能会有速率限制（例如，每分钟可以发送多少请求）以及与处理文本数量相关的成本。您的应用程序需要管理这些因素，可能通过优先处理某些请求或批量处理它们。'
- en: The possibility of consuming OpenAI models via APIs gives developers great flexibility
    when it comes to customizing the application logic around the LLM. In the next
    section, we are going to see how to leverage those APIs in practice with Python.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通过API消耗OpenAI模型为开发者提供了在自定义围绕LLM的应用逻辑方面的巨大灵活性。在下一节中，我们将看到如何使用Python实际利用这些API。
- en: How to use OpenAI models’ APIs with the Python SDK
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用Python SDK调用OpenAI模型的API
- en: To use OpenAI models’ APIs in your programming IDE, you first need to create
    an access token from your OpenAI account.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的编程IDE中使用OpenAI模型的API，您首先需要从您的OpenAI账户创建一个访问令牌。
- en: '**Note**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'When consuming OpenAI’s APIs, you will incur a cost that is proportional to
    the model’s usage. More specifically, OpenAI’s pricing model is **per token**,
    where a token represents a chunk of text (about 4 characters in English). To estimate
    your tokens’ consumption – hence your cost – you can refer to this articl[e: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-t](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)hem.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在消耗OpenAI的API时，您将承担与模型使用成比例的费用。更具体地说，OpenAI的定价模式是**按令牌计费**，其中令牌代表一段文本（大约4个英文字符）。为了估算您的令牌消耗——因此您的费用——您可以参考这篇文章[链接：https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)。
- en: Each API request consumes tokens based on input (prompt) and output (response).
    Pricing varies by model, with **more powerful models costing more per token.**
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 每个API请求都会根据输入（提示）和输出（响应）消耗令牌。价格因模型而异，**更强大的模型每令牌的成本更高**。
- en: You can find OpenAI’s pricing model at https://openai.com/api/pricing/.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在https://openai.com/api/pricing/找到OpenAI的定价模型。
- en: 'To do so, you can follow these steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要这样做，您可以遵循以下步骤：
- en: Navigat[e to https://platform.openai.com/api](https://platform.openai.com/api-keys)-keys.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 https://platform.openai.com/api-keys
- en: 'Click on `+ Create new secret key`:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`+ 创建新的密钥`：
- en: '![](img/B31559_10_02.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_10_02.png)'
- en: 'Figure 10.2: OpenAI API platform'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：OpenAI API平台
- en: This will create a new API key that you can save in a key vault of your choice.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将创建一个新的API密钥，您可以将它保存在您选择的密钥库中。
- en: 'Once you create the API key, you can use it to consume your model with the
    following script:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您创建了API密钥，您就可以使用以下脚本使用它来消耗您的模型：
- en: '[PRE0]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The above example leverages the Python SDK. However, you can also do your call
    with Node.js or curl, as specified in the OpenAI documentation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例使用了Python SDK。然而，您也可以按照OpenAI文档中的说明使用Node.js或curl进行调用。
- en: Note
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'The schema of your client might vary depending on the model you are using and
    the data format you are passing as a prompt. For example, if you are using the
    gpt-4o-mini for image processing, your client will look like the following:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您客户端的架构可能因您使用的模型和数据格式而异。例如，如果您使用gpt-4o-mini进行图像处理，您的客户端将类似于以下结构：
- en: response = client.chat.completions.create(
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: response = client.chat.completions.create(
- en: model=”gpt-4o-mini”,
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: model=”gpt-4o-mini”,
- en: messages=[
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: messages=[
- en: '{'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '“role”: “user”,'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '“role”: “user”,'
- en: '“content”: ['
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '“content”: ['
- en: '{“type”: “text”, “text”: prompt},'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '{“type”: “text”, “text”: prompt},'
- en: '{'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '“type”: “image_url”,'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '“type”: “image_url”,'
- en: '“image_url”: {“url”: f”data:{img_type};base64,{img_b64_str}”},'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '“image_url”: {“url”: f”data:{img_type};base64,{img_b64_str}”},'
- en: '},'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '},'
- en: '],'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '],'
- en: '}'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '],'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '],'
- en: )
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'You can find the OpenAI Python library at the following GitHub repos[itory:
    https://github.com/openai/openai](https://github.com/openai/openai-python)-python.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下GitHub仓库[https://github.com/openai/openai](https://github.com/openai/openai-python)找到OpenAI
    Python库。
- en: 'Let’s inspect how the response is built (I truncated the content of the response):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查响应是如何构建的（我截断了响应的内容）：
- en: '[PRE1]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, there are many components that make up the response object:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有许多组件构成了响应对象：
- en: '`id`: This is a unique identifier for the API call. In this case, `chatcmpl-9znQeWUbRyGmy3pWf7VfFWAppMCo7`
    is the specific ID associated with this particular chat completion request.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id`: 这是API调用的唯一标识符。在这种情况下，`chatcmpl-9znQeWUbRyGmy3pWf7VfFWAppMCo7`是与这个特定的聊天完成请求相关联的特定ID。'
- en: '`choices`: This is an array containing the different possible responses (choices)
    generated by the model. In this response, there’s only one choice (`index 0`),
    which is typical for most single-response completions:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`choices`: 这是一个包含模型生成的不同可能响应（选择）的数组。在这个响应中，只有一个选择（`index 0`），这对于大多数单响应完成来说是典型的：'
- en: '`index`: Indicates the position of this particular choice in the list of choices
    (in this case, `0`).'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index`: 表示此特定选择在选择列表中的位置（在这种情况下，`0`）。'
- en: '`finish_reason`: Indicates why the model stopped generating tokens. **stop**
    usually means the model naturally reached the end of its response without needing
    to be cut off.'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`finish_reason`: 表示模型停止生成令牌的原因。**stop**通常意味着模型自然到达其响应的末尾，无需截断。'
- en: '`logprobs`: If enabled, this would contain the log probabilities of each token
    in the completion. It is `None` here, indicating that you did not request this
    information.'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logprobs`: 如果启用，这将包含完成中每个令牌的对数概率。这里为`None`，表示你没有请求此信息。'
- en: '`message`: Contains the content of the response (`''content''`) and the role
    of the speaker (`''role''`):'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`message`: 包含响应的内容（`''content''`）和说话者的角色（`''role''`）：'
- en: '`content`: The actual text generated by the assistant, which in this case is
    a response regarding Azure AI services that support customer-managed keys'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`content`: 辅助生成的实际文本，在这个例子中是关于支持客户管理密钥的Azure AI服务的响应'
- en: '`role`: The role of the speaker in the conversation, which is ‘assistant’ here,
    indicating the response came from the AI assistant'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`role`: 对话中说话者的角色，这里为‘assistant’，表示响应来自AI助手'
- en: '`content_filter_results`: This contains the content filtering results for the
    response, checking for any harmful content in categories like hate, self-harm,
    sexual content, and violence. In this case, all categories are marked as `''safe''`
    and `''filtered'': False`, indicating no problematic content was detected.'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`content_filter_results`: 这包含响应的内容过滤结果，检查类别如仇恨、自残、性内容和暴力中的任何有害内容。在这种情况下，所有类别都被标记为`''safe''`和`''filtered'':
    False`，表示未检测到任何问题内容。'
- en: '`created`: This is a timestamp representing when the response was generated.
    The number `1724515040` is the UNIX timestamp (seconds since January 1, 1970).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`created`: 这是一个表示响应生成时间的戳记。数字`1724515040`是UNIX时间戳（自1970年1月1日起的秒数）。'
- en: '`model`: This indicates the version of the model that generated the response.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`: 这表示生成响应的模型的版本。'
- en: '`object`: This indicates the type of object returned. In this case, `''chat.completion''`
    signifies that this is a completion from the chat API.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`object`: 这表示返回的对象类型。在这种情况下，`''chat.completion''`表示这是一个来自聊天API的完成。'
- en: '`system_fingerprint`: This is an internal identifier used by OpenAI for tracking
    or diagnosing the system that handled the request. `''fp_abc28019ad''` is the
    specific fingerprint for this transaction.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`system_fingerprint`: 这是一个OpenAI用于跟踪或诊断处理请求的系统的内部标识符。`''fp_abc28019ad''`是此交易的特定指纹。'
- en: '`usage`: This object tracks the token usage for the API call:'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`usage`: 此对象跟踪API调用的令牌使用情况：'
- en: '`completion_tokens`: The number of tokens used in the generated response (193
    tokens)'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`completion_tokens`: 生成响应中使用的令牌数（193个令牌）'
- en: '`prompt_tokens`: The number of tokens used in the input prompt (55 tokens)'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_tokens`: 输入提示中使用的令牌数（55个令牌）'
- en: '`total_tokens`: The total number of tokens consumed in the request, which is
    the sum of the prompt and completion tokens (248 tokens)'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`total_tokens`: 请求中消耗的总令牌数，这是提示和完成令牌的总和（248个令牌）'
- en: '`prompt_filter_results`: This array contains the results of content filtering
    applied to the input prompt before generating the response. It ensures that the
    prompt does not contain harmful content. Like the `content_filter_results` in
    the choices section, it includes checks for hate, self-harm, sexual content, and
    violence. All are marked as `''safe''` and `''filtered'': False`, indicating no
    issues were found.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_filter_results`：这个数组包含在生成响应之前应用于输入提示的内容过滤结果。它确保提示不包含有害内容。与选择部分中的`content_filter_results`一样，它包括对仇恨、自残、色情内容和暴力的检查。所有这些都标记为`''safe''`和`''filtered'':
    False`，表示未发现任何问题。'
- en: Among all the output parameters, the `content_filter_results` might be particularly
    relevant when it comes to managing potentially harmful results. In fact, you might
    want to enforce a more conservative approach when it comes to potentially harmful
    content, in either input or output. If this is the case, you could simply enforce
    a deterministic rule that prevents the model from further processing any request
    that triggers a given level of risk.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有输出参数中，当涉及到管理可能有害的结果时，`content_filter_results`可能特别相关。事实上，你可能希望对可能有害的内容采取更加保守的方法，无论是输入还是输出。如果是这种情况，你可以简单地实施一个确定性规则，防止模型进一步处理任何触发特定风险级别的请求。
- en: This is a meaningful example of how leveraging OpenAI models’ APIs allows for
    great flexibility when it comes to building application logic around LLMs.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有意义的例子，说明了利用OpenAI模型API如何为围绕LLM构建应用逻辑提供极大的灵活性。
- en: Architectural patterns to build applications with models’ APIs
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用模型API构建应用的架构模式
- en: The rise of GenAI and LLMs paved the way for a revolution in the field of software
    development. In fact, from “modern applications” – referring to microservices-based
    architectures and rapid innovation with CI/CD – we now talk about “intelligent
    applications” that are infused with GenAI models defined by natural language interaction,
    data-driven experience, and velocity of adaptation to new models’ releases.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通用人工智能（GenAI）和大型语言模型（LLMs）的兴起为软件开发领域带来了革命性的变革。事实上，从“现代应用”——指的是基于微服务架构和CI/CD的快速创新——我们现在谈论的是“智能应用”，这些应用通过自然语言交互、数据驱动体验和新模型发布速度注入了GenAI模型。
- en: 'An intelligent app can be described with the following illustration:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一个智能应用可以用以下插图来描述：
- en: '![A diagram of a computer network  Description automatically generated with
    medium confidence](img/B31559_10_03.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![计算机网络的示意图  描述由中等置信度自动生成](img/B31559_10_03.png)'
- en: 'Figure 10.3: Anatomy of an intelligent application powered by an LLM'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：由LLM提供动力的智能应用的解剖结构
- en: 'In the above architecture, we depict the anatomy of an intelligent application
    with the following features:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述架构中，我们用以下特性描述了智能应用的解剖结构：
- en: It has a natural language interface (it might be text- or voice-based).
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有自然语言界面（可能是基于文本或语音的）。
- en: It is powered by an LLM that acts as the “brain” of the app.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它由一个作为应用“大脑”的LLM提供动力。
- en: It has a knowledge base that the model can query, typically with **retrieval
    augmented generation** (**RAG**) techniques.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有一个模型可以查询的知识库，通常使用**检索增强生成**（**RAG**）技术。
- en: It has a set of tools or plugins that it can use to interact with the external
    environment.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有一套工具或插件，可以用来与外部环境交互。
- en: This new paradigm of software development brings a set of new application components
    that are typical of AI-powered applications. Let’s explore these new components
    in more detail.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这种软件开发的新范式带来了一组典型的人工智能应用的新应用组件。让我们更详细地探讨这些新组件。
- en: New application components
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新的应用组件
- en: 'The main shift in terms of AI development refers to the way we work with models:
    from producing models, now the trend is consuming models that, as we mentioned
    several times, are nothing but APIs.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI开发方面，主要的转变是指我们与模型合作的方式：从生产模型，现在的趋势是消费模型，正如我们多次提到的，这些模型不过是API。
- en: 'This shift leads to a series of new software components (or adjustments of
    existing components) in the landscape of development:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变导致了一系列新的软件开发组件（或现有组件的调整）在开发领域的出现：
- en: '**Models**: The model is simply the type of LLM we decide to embed in our application.
    There are two main categories of models:'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：模型就是我们决定嵌入到我们应用中的LLM类型。主要有两种模型类别：'
- en: '**Proprietary LLMs**: Models that are owned by specific companies or organizations.
    Examples include GPT-4o, developed by OpenAI, or Gemini, developed by Google.
    As their source code and architecture are not available, those models cannot be
    re-trained from scratch on custom data, but they can be fine-tuned if needed.'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专有LLM**：由特定公司或组织拥有的模型。例如，由OpenAI开发的GPT-4o，或由Google开发的Gemini。由于它们的源代码和架构不可用，这些模型不能从头开始使用自定义数据进行重新训练，但在需要时可以进行微调。'
- en: '**Open-source**: Models with code and architecture freely available and distributed,
    hence they can also be trained from scratch on custom data. Examples include Falcon
    LLM, developed by Abu Dhabi’s **Technology Innovation Institute** (**TII**), and
    Llama, developed by Meta.'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源**：具有代码和架构自由可用和分发的模型，因此它们也可以从零开始使用自定义数据进行训练。例如，由阿布扎比的**技术创新研究所**（**TII**）开发的Falcon
    LLM，以及由Meta开发的Llama。'
- en: '**System message**: This is the set of instructions that we provide the model
    with, and that influence the style and behavior of our AI app. There are many
    features that we can shape directly within the meta-prompt, including:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统消息**：这是我们提供给模型的指令集，它会影响我们AI应用的风格和行为。我们可以在元提示中直接塑造许多功能，包括：'
- en: Reducing hallucination by specifying that the model only refers to the provided
    knowledge base (this process is called “grounding”)
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过指定模型只引用提供的知识库来减少幻觉（这个过程被称为“扎根”）
- en: Implementing responsible AI practices by specifying, for example, not to respond
    to malicious queries or not to generate potentially harmful responses
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过指定，例如，不响应恶意查询或不要生成可能有害的响应来实施负责任的AI实践
- en: Instructing the model to always ask an additional question to consolidate the
    context before answering
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示模型在回答之前总是提出一个额外的问题来巩固上下文
- en: '**Memory and VectorDB**: When we talk about memory in the context of AI apps,
    we need to differentiate between two types of memory:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记忆与VectorDB**：当我们谈论AI应用中的记忆时，我们需要区分两种类型的记忆：'
- en: '**Short-term memory**: This is the capability of the app to keep the interactions
    between the user and LLMs in a context window. It means that each message feeds
    the existing meta-prompt of the model, without the user repeating something already
    mentioned.'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短期记忆**：这是应用保持用户与LLM之间交互在上下文窗口中的能力。这意味着每条消息都会为模型的现有元提示提供输入，而无需用户重复已经提到的内容。'
- en: '**Long-term memory**: This type of memory refers to the external knowledge
    base we provide the model with using embeddings. When this is the case, we typically
    leverage VectorDBs, a new type of database (or new feature of an existing database)
    that stores the numerical representations of the provided documents.'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长期记忆**：这种类型的记忆指的是我们使用嵌入提供的模型的外部知识库。在这种情况下，我们通常利用VectorDBs，这是一种新型数据库（或现有数据库的新功能），它存储了提供的文档的数值表示。'
- en: '**Definition**'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**定义**'
- en: A VectorDB is a type of database that stores and retrieves information based
    on vectorized embeddings, the numerical representations that capture the meaning
    and context of text. By using a VectorDB, you can perform semantic search and
    retrieval based on the similarity of meanings rather than keywords. Some examples
    of a VectorDB are Chroma, FAISS, Elasticsearch, Milvus, Pinecone, Qdrant, and
    Weaviate.
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: VectorDB是一种基于向量嵌入存储和检索信息的数据库类型，这些嵌入是捕获文本意义和上下文的数值表示。通过使用VectorDB，你可以根据意义的相似性而不是关键词进行语义搜索和检索。一些VectorDB的例子包括Chroma、FAISS、Elasticsearch、Milvus、Pinecone、Qdrant和Weaviate。
- en: '**Tools/plugins**: These can be seen as additional modules or components that
    can be integrated into the LLM to extend its functionality or adapt it to specific
    tasks and applications. These plugins act as add-ons, enhancing the capabilities
    of the LLM beyond its core language generation or comprehension abilities.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具/插件**：这些可以被视为可以集成到LLM（大型语言模型）中的附加模块或组件，以扩展其功能或适应特定的任务和应用。这些插件作为附加组件，增强了LLM在核心语言生成或理解能力之外的特性。'
- en: The idea behind plugins is to make LLMs more versatile and adaptable, allowing
    developers and users to customize the behavior of the language model for their
    specific needs. Plugins can be created to perform various tasks, and they can
    be seamlessly incorporated into the LLM’s architecture.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 插件的背后理念是使LLM更加灵活和适应性强，允许开发者和用户根据他们的特定需求定制语言模型的行为。可以创建执行各种任务的插件，并且它们可以无缝地集成到LLM的架构中。
- en: 'The following is an illustration of the main components of an LLM-powered application:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个由 LLM 驱动的应用程序的主要组件的说明：
- en: '![A diagram of a computer program  Description automatically generated](img/B31559_10_04.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![计算机程序图  自动生成的描述](img/B31559_10_04.png)'
- en: 'Figure 10.4: High-level architecture of LLM-powered applications'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4：LLM 驱动应用程序的高级架构
- en: As you can see from the picture above, the core of the high-level architecture
    is the **AI orchestrator**. With the AI orchestrator, we refer to lightweight
    libraries that make it easier to embed and orchestrate LLMs within applications.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，高级架构的核心是 **AI 调度器**。通过 AI 调度器，我们指的是使嵌入和调度 LLM 在应用程序中变得更容易的轻量级库。
- en: AI orchestrators
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI 调度器
- en: 'Since LLMs went viral toward the end of 2022, many libraries have begun to
    arise in the market. In the next sections, we are going to focus on three of them:
    LangChain, Semantic Kernel, and Haystack.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 LLM 在 2022 年底走红，市场上已经出现了许多库。在接下来的几节中，我们将重点关注其中的三个：LangChain、Semantic Kernel
    和 Haystack。
- en: LangChain
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LangChain
- en: '**LangChain** was launched as an open-source project by Harrison Chase, in
    October 2022\. It can be used in both Python and JS/TS.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**LangChain** 是由 Harrison Chase 在 2022 年 10 月作为开源项目推出的。它可以在 Python 和 JS/TS
    中使用。'
- en: LangChain is a framework for developing applications powered by language models,
    making them data-aware (with grounding) and agentic – meaning able to interact
    with external environments.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个用于开发由语言模型驱动的应用程序的框架，使其具备数据感知（具有扎根）和代理性——意味着能够与外部环境交互。
- en: LangChain provides modular abstractions for the components necessary to work
    with language models that we previously mentioned, such as prompts, memory, and
    plugins. Alongside those components, LangChain also offers pre-built **chains**,
    which are structured concatenations of components. These chains can be pre-built
    for specific use cases or be customized.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 为我们之前提到的与语言模型一起工作的组件提供了模块化抽象，例如提示、记忆和插件。除了这些组件之外，LangChain 还提供了预构建的
    **链**，这些链是组件的结构化连接。这些链可以是针对特定用例预构建的，也可以是定制的。
- en: 'Overall, LangChain has the following core modules:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，LangChain 具有以下核心模块：
- en: '**Models**: These are the LLMs or large foundation models that will be the
    engine of the application. LangChain supports proprietary models, such as those
    available in OpenAI and Azure OpenAI, and open-source models consumable from the
    **Hugging Face Hub**.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：这些是将成为应用程序引擎的 LLM 或大型基础模型。LangChain 支持专有模型，例如 OpenAI 和 Azure OpenAI
    中可用的模型，以及可以从 **Hugging Face Hub** 消费的开源模型。'
- en: '**Definition**'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Hugging Face is a company and a community that builds and shares state-of-the-art
    models and tools for **natural language processing** (**NLP**) and other machine
    learning domains. It developed the Hugging Face Hub, a platform where people can
    create, discover, and collaborate on machine learning models and LLMs, datasets,
    and demos. The Hugging Face Hub hosts over 120k models, 20k datasets, and 50k
    demos in various domains and tasks, such as audio, vision, and language.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Hugging Face 是一家公司和社区，它构建和分享自然语言处理（**NLP**）和其他机器学习领域的最先进模型和工具。它开发了 Hugging Face
    Hub，这是一个人们可以创建、发现和协作机器学习模型、LLM、数据集和演示的平台。Hugging Face Hub 在各个领域和任务中托管了超过 120k
    个模型、20k 个数据集和 50k 个演示，例如音频、视觉和语言。
- en: Alongside models, LangChain also offers many prompt-related components that
    make it easier to manage the prompt flow.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模型之外，LangChain 还提供了许多与提示相关的组件，使管理提示流程变得更容易。
- en: '**Data connections**: These refer to the building blocks needed to retrieve
    the additional non-parametric knowledge we want to provide the model with. Examples
    of data connections are document loaders or text embedding models.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据连接**：这些是指构建块，用于检索我们希望提供给模型的额外非参数化知识。数据连接的例子包括文档加载器或文本嵌入模型。'
- en: '**Memory**: It allows the application to keep references to the user’s interactions,
    in both the short and long term. It is typically based on vectorized embeddings
    stored in a VectorDB.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记忆**：它允许应用程序在短期和长期内保留对用户交互的引用。它通常基于存储在 VectorDB 中的矢量嵌入。'
- en: '**Chains**: These are predetermined sequences of actions and calls to LLMs
    that make it easier to build complex applications that require chaining LLMs with
    each other or with other components. An example of a chain might be: take the
    user query, chunk it into smaller pieces, embed those chunks, search for similar
    embeddings in a VectorDB, use the top three most similar chunks in the VectorDB
    as context to provide the answer, generate the answer.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**链**：这些是预定的一系列动作和对 LLM 的调用，这使得构建需要将 LLM 与彼此或其他组件链接的复杂应用程序变得更容易。链的一个例子可能是：获取用户查询，将其分成更小的部分，嵌入这些部分，在
    VectorDB 中搜索相似的嵌入，使用 VectorDB 中最相似的三个部分作为上下文来提供答案，生成答案。'
- en: '**Agents**: Agents are entities that drive decision-making within LLM-powered
    applications. They have access to a suite of tools and can decide which tool to
    call based on the user input and the context. Agents are dynamic and adaptive,
    meaning that they can change or adjust their actions based on the situation or
    the goal.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理**：代理是驱动 LLM 驱动的应用程序中决策的实体。它们可以访问一系列工具，并根据用户输入和上下文决定调用哪个工具。代理是动态和自适应的，这意味着它们可以根据情况或目标改变或调整其行为。'
- en: Haystack
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**干草堆**'
- en: '**Haystack** is a Python-based framework developed by *deepset*, a startup
    founded in 2018 in Berlin by Milos Rusic, Malte Pietsch, and Timo Möller. deepset
    provides developers with the tools to build an NLP-based application, and with
    the introduction of Haystack, they are taking it to the next level.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '**干草堆**是一个基于 Python 的框架，由 *deepset* 开发，*deepset* 是一家成立于 2018 年的柏林初创公司，由 Milos
    Rusic、Malte Pietsch 和 Timo Möller 创立。deepset 为开发者提供构建基于 NLP 的应用程序的工具，随着干草堆的引入，他们将其提升到了新的水平。'
- en: 'Haystack has the following core components:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 干草堆具有以下核心组件：
- en: '**Nodes**: These are components that perform a specific task or function, such
    as a retriever, a reader, a generator, a summarizer, etc. Nodes can be LLMs or
    other utilities that interact with LLMs or other resources. Among LLMs, Haystack
    supports proprietary models, such as those available in OpenAI and Azure OpenAI,
    and open-source models consumable from the Hugging Face Hub.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点**：这些是执行特定任务或功能的组件，例如检索器、阅读器、生成器、摘要器等。节点可以是 LLM 或其他与 LLM 或其他资源交互的实用工具。在
    LLM 中，干草堆支持专有模型，例如 OpenAI 和 Azure OpenAI 中可用的模型，以及来自 Hugging Face Hub 的开源模型。'
- en: '**Pipelines**: These are sequences of calls to nodes that perform natural language
    tasks or interact with other resources. Pipelines can be querying pipelines or
    indexing pipelines, depending on whether they perform searches on a set of documents
    or prepare documents for search. Pipelines are predetermined and hardcoded, meaning
    that they do not change or adapt based on the user input or the context.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**：这些是调用执行自然语言任务或与其他资源交互的节点的序列。管道可以是查询管道或索引管道，这取决于它们是在一组文档上执行搜索还是为搜索准备文档。管道是预先确定和硬编码的，这意味着它们不会根据用户输入或上下文进行更改或适应。'
- en: '**Agent**: This is an entity that uses LLMs to generate accurate responses
    to complex queries. An agent has access to a set of tools, which can be pipelines
    or nodes, and it can decide which tool to call based on the user input and the
    context. An agent is dynamic and adaptive, meaning that it can change or adjust
    its actions based on the situation or the goal.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理**：这是一个使用 LLM 生成对复杂查询准确响应的实体。代理可以访问一系列工具，这些工具可以是管道或节点，并且可以根据用户输入和上下文决定调用哪个工具。代理是动态和自适应的，这意味着它可以根据情况或目标改变或调整其行为。'
- en: '**Tools**: There are functions that an agent can call to perform natural language
    tasks or interact with other resources. Tools can be pipelines or nodes that are
    available to the agent and they can be grouped into toolkits, which are sets of
    tools that can accomplish specific objectives.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具**：代理可以调用的函数，用于执行自然语言任务或与其他资源交互。工具可以是代理可用的管道或节点，它们可以分组到工具包中，工具包是一组可以完成特定目标的工具集。'
- en: '**DocumentStores**: These are backends that store and retrieve documents for
    search. DocumentStores can be based on different technologies, including VectorDBs
    (such as FAISS, Milvus, or Elasticsearch).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档存储**：这些是存储和检索用于搜索的文档的后端。文档存储可以基于不同的技术，包括 VectorDB（例如 FAISS、Milvus 或 Elasticsearch）。'
- en: Haystack is renowned for its simplicity and ease of use, featuring a modular
    architecture that allows developers to construct customizable pipelines for tasks
    like semantic search and question-answering. This design makes it particularly
    suitable for **RAG** applications, where efficient data retrieval is crucial.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Haystack以其简单易用而闻名，具有模块化架构，允许开发者构建用于语义搜索和问答等任务的定制管道。这种设计使其特别适合**RAG**应用，其中高效的数据检索至关重要。
- en: Semantic Kernel
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Semantic Kernel
- en: '**Semantic Kernel** is the third open-source SDK we are going to explore in
    this chapter. It was developed by Microsoft, originally in C#, and is now also
    available in Python.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '**Semantic Kernel**是我们将在本章中探索的第三个开源SDK。它由微软开发，最初是用C#编写的，现在也提供了Python版本。'
- en: This framework takes its name from the concept of a “kernel,” which, generally
    speaking, refers to the core or essence of a system. In the context of this framework,
    a kernel is meant to act as the engine that addresses users’ input by chaining
    and concatenating a series of components into pipelines, encouraging **function
    composition.**
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这个框架的名字来源于“内核”的概念，一般而言，内核指的是系统的核心或本质。在这个框架的上下文中，内核的作用是作为引擎，通过链式和串联一系列组件形成管道，鼓励**函数复合**。
- en: '**Definition**'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: In mathematics, function composition is a way to combine two functions to create
    a new function. The idea is to use the output of one function as the input to
    another function, forming a chain of functions. The composition of two functions,
    f and g, is denoted as![](img/B31559_10_001.png), where the function ![](img/B31559_10_001.png)
    is applied first, followed by the function ![](img/B31559_10_002.png).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，函数复合是将两个函数组合起来创建一个新函数的方法。其思想是使用一个函数的输出作为另一个函数的输入，形成一个函数链。两个函数 f 和 g 的复合表示为![](img/B31559_10_001.png)，其中首先应用函数![](img/B31559_10_001.png)，然后是函数![](img/B31559_10_002.png)。
- en: Function composition in computer science is a powerful concept that allows for
    the creation of more sophisticated and reusable code by combining smaller functions
    into larger ones. It enhances modularity and code organization, making programs
    easier to read and maintain.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学中的函数复合是一个强大的概念，通过将较小的函数组合成较大的函数，可以创建更复杂和可重用的代码。它增强了模块化和代码组织，使程序更容易阅读和维护。
- en: 'Semantic Kernel has the following main components:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Semantic Kernel具有以下主要组件：
- en: '**Models**: These are the LLMs or large foundation models that will be the
    engine of the application. Semantic Kernel supports proprietary models, such as
    those available in OpenAI and Azure OpenAI, and open-source models consumable
    from the Hugging Face Hub.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：这些是作为应用引擎的LLM或大型基础模型。Semantic Kernel支持专有模型，例如OpenAI和Azure OpenAI中可用的模型，以及可以从Hugging
    Face Hub获取的开源模型。'
- en: '**Memory**: This allows the application to keep references to the user’s interactions,
    in both the short and long term. Within the framework of Semantic Kernel, memories
    can be accessed in three ways:'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存**：这允许应用程序在短期和长期内保持对用户交互的引用。在Semantic Kernel的框架内，可以通过三种方式访问记忆：'
- en: '**Key**-**value pairs**: This consists of saving environment variables that
    store simple information, such as names or dates.'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**键值对**：这包括保存存储简单信息的环境变量，例如名称或日期。'
- en: '**Local storage**: This consists of saving information to a file that can be
    retrieved by its filename, such as a CSV or JSON file.'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地存储**：这包括将信息保存到可以按其文件名检索的文件中，例如CSV或JSON文件。'
- en: '**Semantic memory search**: This is similar to LangChain’s and Haystack’s memory,
    as it uses embeddings to represent and search for text information based on its
    meaning.'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义记忆搜索**：这与LangChain和Haystack的记忆相似，因为它使用嵌入来表示和基于其意义搜索文本信息。'
- en: '**Functions**: Functions can be seen as skills that mix LLM prompts and code,
    with the goal of making users’ requests interpretable and actionable. There are
    two types of functions:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**函数**：函数可以看作是混合LLM提示和代码的技能，目的是使用户的请求可解释和可操作。有两种类型的函数：'
- en: '**Semantic functions**: These are basically a templated prompt, which is a
    natural language query that specifies the input and output format for the LLM,
    also incorporating prompt configuration, which sets the parameters for the LLM.'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义函数**：这些基本上是一个模板化的提示，它是一个自然语言查询，指定了LLM的输入和输出格式，同时也结合了提示配置，该配置设置了LLM的参数。'
- en: '**Native functions**: These refer to the native computer code that can route
    the intent captured by the semantic function and perform the related task.'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原生函数**：这些是指可以路由语义函数捕获的意图并执行相关任务的本地计算机代码。'
- en: To give an example, a semantic function could ask the LLM to write a short paragraph
    about AI, while a native function could actually post it on social media like
    LinkedIn.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，一个语义函数可能会要求LLM写一段关于AI的短段落，而一个原生函数实际上可以在LinkedIn等社交媒体上发布。
- en: '**Plugins**: These are connectors toward external sources or systems that are
    meant to provide additional information or the ability to perform autonomous actions.
    Semantic Kernel offers out-of-the-box plugins, such as the Microsoft Graph connector
    kit, but you can build a custom plugin by leveraging functions (both native and
    semantic, or a mix of the two).'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插件**：这些是连接到外部来源或系统的连接器，旨在提供额外的信息或执行自主操作的能力。语义内核提供了现成的插件，例如Microsoft Graph连接器套件，但您可以通过利用函数（无论是原生还是语义，或者两者的混合）来构建自定义插件。'
- en: '**Planner**: As LLMs can be seen as reasoning engines, they can also be leveraged
    to auto-create chains or pipelines to address new users’ needs. This goal is achieved
    with a planner, which is a function that takes as input a user’s task and produces
    the set of actions, plugins, and functions needed to achieve the goal.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规划器**：由于LLM可以被视为推理引擎，它们也可以被用来自动创建链或管道以满足新用户的需求。这个目标是通过一个规划器实现的，它是一个接受用户任务作为输入并产生实现目标所需的一组动作、插件和函数的函数。'
- en: 'Below is an illustration of the anatomy of Semantic Kernel:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是语义内核解剖结构的插图：
- en: '![Technical perspective of what''s happening](img/B31559_10_05.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![技术视角下的发生情况](img/B31559_10_05.png)'
- en: 'Figure 10.5: Anatomy of Semantic Kernel. Source: https://learn.microsoft.com/en-us/semantic-kernel/overview/'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：语义内核的解剖结构。来源：https://learn.microsoft.com/en-us/semantic-kernel/overview/
- en: Overall, the three frameworks offer more or less similar core components, sometimes
    called a different taxonomy, yet covering all the blocks illustrated within the
    concept of the copilot system. So, a natural question might be, “Which one should
    I use to build my LLM-powered application?”
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这三个框架提供了更多或更少的类似核心组件，有时被称为不同的分类法，但涵盖了协同系统概念中所示的所有块。因此，一个自然的问题可能是，“我应该使用哪一个来构建我的LLM驱动应用程序？”
- en: 'Below are some criteria you might want to consider:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些您可能想要考虑的标准：
- en: '**The programming language you are comfortable with or prefer to use**. Different
    frameworks may support different programming languages or have different levels
    of compatibility or integration with them. For example, Semantic Kernel supports
    C#, Python, and Java, while LangChain and Haystack are mainly based on Python
    (even though LangChain also introduced JS/TS support). You may want to choose
    a framework that matches your existing skills or preferences, or that allows you
    to use the language that is most suitable for your application domain or environment.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您熟悉或更愿意使用的编程语言**。不同的框架可能支持不同的编程语言或具有不同程度的兼容性或集成。例如，语义内核支持C#、Python和Java，而LangChain和Haystack主要基于Python（尽管LangChain也引入了JS/TS支持）。您可能希望选择一个与您的现有技能或偏好相匹配的框架，或者允许您使用最适合您的应用领域或环境的语言。'
- en: '**The type and complexity of the natural language tasks you want to perform
    or support**. Different frameworks may have different capabilities or features
    for handling various natural language tasks, such as summarization, generation,
    translation, reasoning, etc. For example, LangChain and Haystack provide utilities
    and components for orchestrating and executing natural language tasks, while Semantic
    Kernel allows you to use natural language semantic functions to invoke LLMs and
    services. You may want to choose a framework that offers the functionality and
    flexibility you need or want for your application goals or scenarios.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您想要执行或支持的自然语言任务类型和复杂性**。不同的框架可能具有不同的能力或特性来处理各种自然语言任务，例如摘要、生成、翻译、推理等。例如，LangChain和Haystack提供了编排和执行自然语言任务的实用工具和组件，而语义内核允许您使用自然语言语义函数来调用LLM和服务。您可能希望选择一个提供您应用目标或场景所需的功能和灵活性的框架。'
- en: '**The level of customization and control you need or want over the LLMs and
    their parameters or options**. Different frameworks may have different ways of
    accessing, configuring, and fine-tuning the LLMs and their parameters or options,
    such as model selection, prompt design, inference speed, output format, etc. For
    example, Semantic Kernel provides connectors that make it easy to add memories
    and models to your AI app, while LangChain and Haystack allow you to plug in different
    components for the DocumentStore, retriever, reader, generator, summarizer, and
    evaluator. You may want to choose a framework that gives you the level of customization
    and control you need or want over the LLMs and their parameters or options.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您需要或希望对LLMs及其参数或选项进行定制和控制的程度**。不同的框架可能有不同的方式来访问、配置和微调LLMs及其参数或选项，例如模型选择、提示设计、推理速度、输出格式等。例如，Semantic
    Kernel提供了连接器，使得向你的AI应用添加记忆和模型变得容易，而LangChain和Haystack允许你将不同的组件插入到DocumentStore、检索器、阅读器、生成器、摘要器和评估器中。你可能希望选择一个能够提供你对LLMs及其参数或选项所需或希望达到的定制和控制程度的框架。'
- en: '**The availability and quality of the documentation, tutorials, examples, and
    community support for the framework**. Different frameworks may have different
    levels of documentation, tutorials, examples, and community support that can help
    you learn, use, and troubleshoot the framework. For example, Semantic Kernel has
    a website with documentation, tutorials, examples, and a Discord community; LangChain
    has a GitHub repository with documentation, examples, and issues; Haystack has
    a website with documentation, tutorials, demos, blog posts, and a Slack community.
    You may want to choose a framework that has the availability and quality of documentation,
    tutorials, examples, and community support that can help you get started and solve
    problems with the framework.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**框架的文档、教程、示例和社区支持的可获得性和质量**。不同的框架可能具有不同水平的文档、教程、示例和社区支持，这些支持可以帮助你学习、使用和调试框架。例如，Semantic
    Kernel有一个包含文档、教程、示例和Discord社区的网站；LangChain有一个包含文档、示例和问题的GitHub仓库；Haystack有一个包含文档、教程、演示、博客文章和Slack社区的网站。你可能希望选择一个具有文档、教程、示例和社区支持的可获得性和质量，这可以帮助你开始使用框架并解决相关问题的框架。'
- en: Well, there is no right or wrong answer! All three orchestrators discussed above
    are extremely valid. However, some features might be more relevant to specific
    use cases or developers’ preferences. Make your choice based on that.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，没有正确或错误的答案！上面讨论的三个编排器都非常有效。然而，某些功能可能更适合特定的用例或开发者的偏好。根据这一点做出你的选择。
- en: 'Introducing the public cloud: Azure OpenAI'
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍公共云：Azure OpenAI
- en: In 2016, OpenAI agreed to leverage Microsoft’s Azure cloud infrastructure to
    run its AI experiments, which led, in 2019, to a $1 billion investment from the
    tech giant [into Sam Altman’s company (https://new](https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/)upercomputing-technologies/).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年，OpenAI同意利用微软的Azure云基础设施来运行其AI实验，这导致了2019年科技巨头对萨姆·奥特曼的公司（[https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/](https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/)）投资了10亿美元。
- en: 'This marked the beginning of a strategic partnership between the two companies,
    aiming at developing AI models and technologies that can be used for the benefit
    of humanity. This partnership is based on the following three main pillars:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着两家公司之间战略合作的开始，旨在开发对人类有益的AI模型和技术。这个合作基于以下三个主要支柱：
- en: Microsoft and OpenAI will jointly build new Azure supercomputing infrastructure
    to train AI models.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软和OpenAI将共同构建新的Azure超级计算基础设施来训练AI模型。
- en: OpenAI will make its models and technologies consumable from the Azure cloud.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI将从Azure云中提供其模型和技术。
- en: Microsoft will become OpenAI’s preferred partner for commercializing new AI
    solutions to the market.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软将成为OpenAI在市场上商业化新AI解决方案的首选合作伙伴。
- en: 'Since then, the two companies kept investing and researching, and finally,
    in January 2023, OpenAI models were made available on Microsoft Azure as a managed
    service: **Azure OpenAI Service** (in short, **AOAI**).'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时起，两家公司一直持续投资和研究，最终在2023年1月，OpenAI模型作为托管服务在Microsoft Azure上提供：**Azure OpenAI
    Service**（简称，**AOAI**）。
- en: With the general availability of the AOAI Service, a new milestone was reached,
    and the Microsoft AI portfolio has been extended with the powerful LLMs of OpenAI.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 AOAI 服务的全面上市，我们达到了一个新的里程碑，并且微软的人工智能产品组合通过 OpenAI 强大的 LLMs 得到了扩展。
- en: AOAI Service
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AOAI 服务
- en: 'The AOAI Service is a product of Microsoft that provides both a playground
    and APIs to interact and consume all of OpenAI’s powerful language models. It
    is important to highlight that the models are exactly the same: the only difference
    is that, if you are consuming them via AOAI, you are leveraging your own Azure
    subscription and automatically inheriting all the enterprise features that are
    typical of the Microsoft public cloud, including security, role-based access control,
    data privacy, and so on.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 服务是微软的一个产品，它提供了一个游乐场和 API，用于与 OpenAI 的所有强大语言模型进行交互和消费。重要的是要强调，模型是完全相同的：唯一的区别是，如果您通过
    AOAI 消费它们，您将利用自己的 Azure 订阅，并自动继承所有典型的微软公共云企业功能，包括安全、基于角色的访问控制、数据隐私等。
- en: 'To create your AOAI resource, follow these instructions:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建您的 AOAI 资源，请按照以下说明操作：
- en: Navig[ate to your Azure portal at](https://ms.portal.azure.com/) https://ms.portal.azure.com.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导航到您的 Azure 站点 [https://ms.portal.azure.com/](https://ms.portal.azure.com/)。
- en: Click on **Create a Resource**.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击**创建资源**。
- en: Type *azure openai* and click on **Create**.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入 *azure openai* 并点击**创建**。
- en: Fill in the required information and click on **Review + create**.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填写所需信息并点击**Review + create**。
- en: 'This is shown in the following screenshot:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 如下截图所示：
- en: '![](img/B31559_10_06.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B31559_10_06.png](img/B31559_10_06.png)'
- en: 'Figure 10.6: Steps to create an AOAI resource'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6：创建 AOAI 资源步骤
- en: 'This process might take a few minutes. Once it is ready, you can directly jump
    to its user-friendly interface, the AOAI Studio, to test your models before deploying
    them:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程可能需要几分钟。一旦准备就绪，您可以直接跳转到其用户友好的界面 AOAI Studio，在部署之前测试您的模型：
- en: '![](img/B31559_10_07.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B31559_10_07.png](img/B31559_10_07.png)'
- en: 'Figure 10.7: AOAI Studio and chat playground'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7：AOAI Studio 和聊天游乐场
- en: To use AOAI models, you have to initiate a deployment, which is a serverless
    compute instance you can attach to a model.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AOAI 模型，您必须启动一个部署，这是一个可以附加到模型的无服务器计算实例。
- en: '![A screenshot of a computer  Description automatically generated](img/B31559_10_08.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图，描述自动生成](img/B31559_10_08.png)'
- en: 'Figure 10.8: Creating a new AOAI deployment via the Azure OpenAI portal'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8：通过 Azure OpenAI 站点创建新的 AOAI 部署
- en: 'Lastly, exactly like we did for OpenAI models’ APIs in the previous section,
    from the AOAI Studio, you can consume your deployed models via APIs. For a quick
    start, you can navigate to the **Chat playground** and click on the **View Code**
    button. A script will be ready to be copied and pasted into your favorite programming
    IDE, along with the secret keys needed to access the resource:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，就像我们在上一节中为 OpenAI 模型 API 所做的那样，从 AOAI Studio，您可以通过 API 消费您已部署的模型。为了快速入门，您可以导航到**聊天游乐场**并点击**查看代码**按钮。一个脚本将准备好复制粘贴到您喜欢的编程
    IDE 中，以及访问资源所需的秘密密钥：
- en: '![](img/B31559_10_09.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B31559_10_09.png](img/B31559_10_09.png)'
- en: 'Figure 10.9: Consuming deployed models via APIs'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9：通过 API 消费已部署的模型
- en: By doing so, you can seamlessly incorporate your Azure OpenAI’s LLMs within
    your own application.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，您可以将 Azure OpenAI 的 LLMs 无缝地集成到您自己的应用程序中。
- en: Summary
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: At the beginning of this chapter, we had an overview of how GenAI is disrupting
    industries, from increasing the efficiency of internal processes to enhancing
    customers’ journeys with personalized experiences. Many of these applications
    can be achieved through a high margin of customization, and pre-built, consumer-facing
    applications like ChatGPT might not be enough.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，我们概述了 GenAI 如何颠覆行业，从提高内部流程的效率到通过个性化体验增强客户的旅程。许多这些应用可以通过高度的定制来实现，而预构建的面向消费者的应用程序，如
    ChatGPT，可能就不够了。
- en: That’s why we introduced OpenAI models’ APIs. With the models’ APIs, you can
    leverage the power of the model behind ChatGPT within your own application, tailored
    to your own industry and scenarios. Developing AI-powered applications, however,
    requires a new set of components that have also marked a new paradigm in software
    development.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，我们引入了 OpenAI 模型 API。通过模型 API，您可以在自己的应用程序中利用 ChatGPT 背后模型的力量，根据您自己的行业和场景进行定制。然而，开发
    AI 驱动的应用程序需要一套新的组件，这也标志着软件开发领域的新范式。
- en: 'Finally, we saw how, from 2023, OpenAI models (both in Playground and via APIs)
    have been made available through Microsoft Azure as a managed service: Azure OpenAI.
    This has paved the way for a new wave of adoption from large enterprises that
    benefit from all the security and governance layers that already exist within
    the public cloud (which is, by design, enterprise-ready).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们看到从 2023 年起，OpenAI 模型（无论是在游乐场中还是在通过 API 中）已通过 Microsoft Azure 作为托管服务：Azure
    OpenAI 提供使用。这为大型企业采用新的一波铺平了道路，这些企业可以从公共云中已有的所有安全和治理层中受益（按设计，企业级就绪）。
- en: In the next chapter, we will provide a recap of everything covered in this book,
    including the latest announcements and releases that have occurred. We will also
    focus on reflections and final thoughts about the exponential growth of generative
    AI technologies in just a few months and what to expect in the near future.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将回顾本书涵盖的所有内容，包括最新的公告和发布。我们还将关注在短短几个月内生成式 AI 技术的指数级增长以及未来可以期待的内容。
- en: References
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'OpenAI Forms Exclusive Computing Partnership with Microsoft to Build New Azure
    AI Supercomputing Technologies: https://news.microsoft.com/20[19/07/22/openai-forms-exclusive-computing-partnership-with-](https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/)-ai-supercomputing-technologies/'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 与微软建立独家计算合作伙伴关系，共同构建新的 Azure AI 超级计算技术：[OpenAI 与微软建立独家计算合作伙伴关系](https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/)
- en: 'General Availability of Azure OpenAI Service Expands Access to Large, Advanced
    AI Models with Added Enterprise Benefits: https://azure.microsoft.com/[en-us/blog/general-availability-of-azure-openai-service-expa](https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/)-with-added-enterprise-benefits/'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure OpenAI 服务全面上市，扩大了对大型、先进 AI 模型的访问，并增加了企业级优势：[Azure OpenAI 服务全面上市](https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/)-with-added-enterprise-benefits/
- en: 'Microsoft CEO Satya Nadella: Humans and A.I. Can Work Together to Solve Society’s
    Challenges: https://slate.com/technology/2016/06/microsoft-ceo-satya-nadella-humans-and-a-i-can-work-together-to-solve-societys-challenges.html'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软首席执行官萨提亚·纳德拉：人类和人工智能可以共同努力解决社会的挑战：[微软首席执行官萨提亚·纳德拉：人类和人工智能可以共同努力解决社会的挑战](https://slate.com/technology/2016/06/microsoft-ceo-satya-nadella-humans-and-a-i-can-work-together-to-solve-societys-challenges.html)
- en: 'Microsoft Calls for Government Regulation of Facial Recognition Technology:
    https://www.geekwire.com/[2018/microsoft-calls-government-regulatio](https://www.geekwire.com/2018/microsoft-calls-government-regulation-facial-recognition-technology/)n-facial-recognition-technology/'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软呼吁政府对面部识别技术进行监管：[微软呼吁政府对面部识别技术进行监管](https://www.geekwire.com/2018/microsoft-calls-government-regulation-facial-recognition-technology/)
- en: 'Six Principles to Guide Micros[oft’s Facial Recognition Work: https://blogs.microso](https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/)rosofts-facial-recognition-work/'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指导微软面部识别工作的六个原则：[微软面部识别工作的六个原则](https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/)
- en: 'Responsible AI Principles and Approach: https://www.microsoft.com/en-us/ai/principles-and-approach'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负责任 AI 原则和方法：[负责任 AI 原则和方法](https://www.microsoft.com/en-us/ai/principles-and-approach)
- en: Mic[rosoft Responsible AI Toolbox:](https://responsibleaitoolbox.ai/) https://responsibleaitoolbox.ai/
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软负责任 AI 工具箱：[微软负责任 AI 工具箱](https://responsibleaitoolbox.ai/)
- en: 'Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention:
    https://www.microsoft.com/e[n-us/research/publication/human-parity-on-commonsenseqa-augmenti](https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/)tention-with-external-attention/'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CommonsenseQA 上的常识平等：通过外部注意力增强自注意力：[通过外部注意力增强自注意力](https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/)
- en: 'Customize a Model with Azure OpenAI Service: https://learn.microsoft.com/en-gb/[azure/cognitive-services/openai/how-to/fine-tuning?pivots=pro](https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio&openai-cli-data-preparation-tool)openai-cli-data-preparation-tool'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Azure OpenAI服务定制模型：https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio&openai-cli-data-preparation-tool
- en: 'Moody’s and Microsoft Develop Enhanced Risk, Data, Analytics, Research and
    Collaboration Solut[ions Powered by Generative AI: https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Power](https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Powered-by-Generative-AI/default.aspx)ed-by-Generative-AI/default.aspx'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惠誉与微软开发由生成式AI驱动的增强风险、数据、分析、研究和协作解决方案：https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Powered-by-Generative-AI/default.aspx
- en: 'Increasing Accu[racy of Pediatric Visit Notes: https:/](https://openai.com/index/summer-health/)/openai.com/index/summer-health/'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高儿科就诊记录的准确性：https://openai.com/index/summer-health/
- en: 'Coca-Cola Invites Digital Artists to ‘Create Real [Magic’ Using New AI Platform:
    https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-](https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform)real-magic-using-new-ai-platform'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可口可乐邀请数字艺术家使用新的AI平台“创造真实[魔法]”：https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform
- en: 'IVECO Group Uses Azure OpenAI Servi[ce to Transform Manufacturing: https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-op](https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy)enai-service-manufacturing-italy'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IVECO集团利用Azure OpenAI服务转型制造：https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy
- en: 'Ir[onclad and OpenAI Partnership: ht](https://openai.com/index/ironclad/)tps://openai.com/index/ironclad/'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ironclad与OpenAI合作：https://openai.com/index/ironclad/
- en: 'Inworl[d AI and OpenAI Collaboration: http](https://openai.com/index/inworld-ai/)s://openai.com/index/inworld-ai/'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Inworld AI与OpenAI合作：https://openai.com/index/inworld-ai/
- en: 'Khan Academy and OpenAI Partnership: https://openai.com/index/khan-academy/'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可汗学院与OpenAI合作：https://openai.com/index/khan-academy/
- en: Join our communities on Discord and Reddit
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord和Reddit社区
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](Chapter_10.xhtml)
    and our Reddit channel at [https://packt.link/jwAmA](Chapter_10.xhtml) to connect,
    share, and collaborate with like-minded enthusiasts.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 对这本书有疑问或想参与关于生成式AI和LLMs的讨论？加入我们的Discord服务器[https://packt.link/I1tSU](Chapter_10.xhtml)和Reddit频道[https://packt.link/jwAmA](Chapter_10.xhtml)，与志同道合的爱好者连接、分享和协作。
- en: '![](img/Discord.png) ![](img/QR_Code757615820155951000.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Discord.png) ![](img/QR_Code757615820155951000.png)'
