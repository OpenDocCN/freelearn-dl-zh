- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Using Textual Inversion
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用文本反转
- en: '**Textual inversion** (**TI**) is another way to provide additional capabilities
    to a pretrained model. Unlike **Low-Rank Adaptation** (**LoRA**), discussed in
    [*Chapter 8*](B21263_08.xhtml#_idTextAnchor153), which is a fine-tuning technique
    applied to the text encoder and the UNet attention weights, TI is a technique
    to add new **embedding** space based on the trained data.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本反转**（**TI**）是向预训练模型提供额外功能的一种方式。与在[*第8章*](B21263_08.xhtml#_idTextAnchor153)中讨论的**低秩自适应**（**LoRA**）不同，LoRA是一种应用于文本编码器和UNet注意力权重的微调技术，TI是一种基于训练数据添加新**嵌入**空间的技术。'
- en: In the context of Stable Diffusion, **text embedding** refers to the representation
    of text data as numerical vectors in a high dimensional space, allowing for manipulation
    and processing by machine learning algorithms. Specifically, in the case of Stable
    Diffusion, text embeddings are typically created using the **Contrastive Language-Image
    Pretraining** (**CLIP**) [6] model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在Stable Diffusion的上下文中，**文本嵌入**指的是将文本数据表示为高维空间中的数值向量，以便通过机器学习算法进行操作和处理。具体来说，在Stable
    Diffusion的情况下，文本嵌入通常使用**对比语言-图像预训练**（**CLIP**）[6]模型创建。
- en: To train a TI model, you only need a minimal set of three to five images, resulting
    in a compact `pt` or `bin` file, typically just a few kilobytes in size. This
    makes TI a highly efficient method for incorporating new elements, concepts, or
    styles into your pretrained checkpoint model while maintaining exceptional portability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练一个TI模型，你只需要三到五张最小图像集，结果是一个紧凑的`pt`或`bin`文件，通常只有几KB大小。这使得TI成为将新元素、概念或风格融入预训练检查点模型的同时保持卓越便携性的高效方法。
- en: In this chapter, we will first start using TI with the TI loader from the `diffusers`
    package, then delve into the core of TI to uncover how it works internally, and
    finally build a custom TI loader to have the TI weight applied to the image generation.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先使用来自`diffusers`包的TI加载器使用TI，然后深入TI的核心以揭示其内部工作原理，最后构建一个自定义TI加载器以将TI权重应用于图像生成。
- en: 'Here are the topics we are going to cover:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们将要讨论的主题：
- en: Diffusers inference using TI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TI进行扩散器推理
- en: How TI works
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TI是如何工作的
- en: Build a custom TI loader
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建自定义TI加载器
- en: By the end of this chapter, you will be able to start using any type of TI shared
    by the community and also build your application to load TI.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够开始使用社区共享的任何类型的TI，并构建你的应用程序以加载TI。
- en: Let’s start leveraging the power of Stable Diffusion TI.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始利用Stable Diffusion TI的力量。
- en: Diffusers inference using TI
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TI进行扩散器推理
- en: Before diving into how TI works internally, let’s take a look at how to use
    TI using Diffusers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解TI内部工作原理之前，让我们看看如何使用Diffusers来使用TI。
- en: 'There are countless pretrained TIs shared in the Hugging Face’s Stable Diffusion
    concepts library [3] and CIVITAI [4]. For example, one of the most downloaded
    TIs from the Stable Diffusion concepts library is `sd-concepts-library/midjourney-style`
    [5]. We can start using it by simply referencing this name in the code; Diffusers
    will download the model data automatically:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hugging Face的Stable Diffusion概念库[3]和CIVITAI[4]中共享了无数预训练的TI。例如，从Stable Diffusion概念库中最受欢迎的TI之一是`sd-concepts-library/midjourney-style`[5]。我们可以通过在代码中简单地引用此名称来开始使用它；Diffusers将自动下载模型数据：
- en: 'Let’s initialize a Stable Diffusion pipeline:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们初始化一个Stable Diffusion管道：
- en: '[PRE0]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Generate an image without TI involved:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不使用TI生成图像：
- en: '[PRE8]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the prompt, `midjourney-style` is used, which will be given as the name
    of the TI. Without applying the name, we will see an image generated, as shown
    in *Figure 9**.1*:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在提示中，使用了`midjourney-style`，这将是TI的名称。如果没有应用名称，我们将看到生成的图像，如图*图9.1*所示：
- en: '![Figure 9.1: A futuristic city in deep space without TI](img/B21263_09_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1：没有TI的深空未来城市](img/B21263_09_01.jpg)'
- en: 'Figure 9.1: A futuristic city in deep space without TI'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1：没有TI的深空未来城市
- en: Generate an image with TI involved.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用TI生成图像。
- en: 'Now, let’s load the TI into the Stable Diffusion pipeline and give it a name,
    `midjourney-style`, to represent the newly added embeddings:'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，让我们将TI加载到Stable Diffusion管道中，并给它命名为`midjourney-style`，以表示新添加的嵌入：
- en: '[PRE17]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code will download the TI automatically and then add it to the
    pipeline model. Execute the same prompt and pipeline again, and we will get a
    completely new image, as shown in *Figure 9**.2*:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码将自动下载TI并将其添加到管道模型中。再次执行相同的提示和管道，我们将得到一个全新的图像，如图*图9.2*所示：
- en: '![Figure 9.2: A futuristic city in deep space with TI](img/B21263_09_02.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图9.2：深空中带有TI的未来城市](img/B21263_09_02.jpg)'
- en: 'Figure 9.2: A futuristic city in deep space with TI'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：深空中带有TI的未来城市
- en: 'Yes, it looks and feels like an image generated by Midjourney, but it is actually
    generated by Stable Diffusion. The “*inversion*” in the name of the TI indicates
    that we can inverse any new name to the new embeddings, for example, if we give
    a new token a name such as `colorful-magic-style`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，它看起来和感觉就像Midjourney生成的图像，但实际上是由Stable Diffusion生成的。TI名称中的“*反转*”表示我们可以将任何新名称逆转换为新嵌入，例如，如果我们给一个新标记命名为`colorful-magic-style`：
- en: '[PRE21]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We will get the same image because we use `midjourney-style` as the name of
    the TI. This time, we “inverse” `colorful-magic-style` into the new embeddings.
    However, the `load_textual_inversion` function provided by Diffusers does not
    provide a `weight` parameter for users to load a TI with a certain weight. We
    will add the weighted TI in our own TI loader later in this chapter.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用 `midjourney-style` 作为TI的名称，我们将得到相同的图像。这次，我们将 `colorful-magic-style` “反转”到新嵌入中。然而，Diffusers提供的
    `load_textual_inversion` 函数没有为用户提供 `weight` 参数来加载具有特定权重的TI。我们将在本章后面添加加权TI到我们自己的TI加载器中。
- en: Before that, let’s dig into the heart of TI and see how it works internally.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，让我们深入TI的核心，看看它是如何内部工作的。
- en: How TI works
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TI是如何工作的
- en: 'Simply put, training a TI is finding a text embedding that matches the target
    image the best, such as its style, object, or face. The key is to find a new embedding
    that never existed in the current text encoder. As *Figure 9**.3*, from its original
    paper [1], shows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，训练TI就是找到一个与目标图像最佳匹配的文本嵌入，例如其风格、物体或面部。关键是找到一个在当前文本编码器中从未存在的新嵌入。正如*图9**.3*，从其原始论文[1]所示：
- en: '![Figure 9.3: The outline of the text embedding and inversion process](img/B21263_09_03.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3：文本嵌入和反转过程的概述](img/B21263_09_03.jpg)'
- en: 'Figure 9.3: The outline of the text embedding and inversion process'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3：文本嵌入和反转过程的概述
- en: The only job of the training is to find a new embedding represented by v *.
    and use S * as the token string placeholder; the string can be replaced by any
    string that does not exist in the tokenizer later. Once the new corresponding
    embedding vector is founded, the train is done. The output of the training is
    usually a vector with 768 numbers. That is why the TI file is tiny; it is just
    a couple of kilobytes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的唯一任务是找到一个由 v * 表示的新嵌入，并使用 S * 作为标记字符串占位符；字符串可以替换为任何在分词器中不存在的字符串。一旦找到新的对应嵌入向量，训练就完成了。训练的输出通常是一个包含768个数字的向量。这就是为什么TI文件如此小巧；它只是几千字节。
- en: It is like the pretrained UNet is a pile of matrix magic boxes, one key (embedding)
    can unlock a box to have a pattern, a style, or an object. The number of boxes
    is way more than the limited keys from the text encoder provided. The training
    of a TI is done by providing a new key to unlock the unknown magic box. Throughout
    the training and inferencing, the original checkpoint model is untouched.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 就像预训练的UNet是一堆矩阵魔法盒子，一个密钥（嵌入）可以解锁一个盒子，以获得一个图案、一种风格或一个物体。盒子的数量远远多于文本编码器提供的有限密钥。TI的训练是通过提供一个新密钥来解锁未知的魔法盒子来完成的。在整个训练和推理过程中，原始检查点模型保持不变。
- en: 'In a precise way, the finding of the new embedding can be defined as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 精确地说，新嵌入的寻找可以定义为以下：
- en: v * = arg v min E z∼E(x),y,ϵ∼N(0,1),t[||ϵ − ϵ θ(z t, t, c θ(y))|| 2 2]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: v * = arg v min E z∼E(x),y,ϵ∼N(0,1),t[||ϵ − ϵ θ(z t, t, c θ(y))|| 2 2]
- en: 'Let’s go through the formula from left to right, one by one:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个从左到右解释公式：
- en: v * denotes the new embedding we are looking for.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: v * 表示我们正在寻找的新嵌入。
- en: 'The arg : min notation is often used in statistics and optimization to denote
    the set of values that minimize a function. It is a useful notation because it
    allows us to talk about the minimum value of a function without having to specify
    the actual value of the minimum.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: arg min 符号常用于统计学和优化，表示最小化一个函数的值集合。这是一个有用的符号，因为它允许我们讨论函数的最小值，而无需指定最小值的实际值。
- en: The (E) is the loss expectation.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (E) 是损失期望。
- en: z ∼ E(x) denotes that the input image will be encoded to latent space.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: z ∼ E(x) 表示输入图像将被编码到潜在空间。
- en: y is the input text.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y 是输入文本。
- en: e ∼ N(0,1) says that the initial noise latent is a strict Gaussian with `0`
    mean and `1` variance.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: e ∼ N(0,1) 表示初始噪声潜在值是一个具有 `0` 均值和 `1` 方差的严格高斯分布。
- en: c θ(y) represents a text encoder model that maps an input text string y into
    embedding vectors.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: c θ(y) 代表一个将输入文本字符串 y 映射到嵌入向量的文本编码器模型。
- en: ϵ θ(z t, t, c θ(y)) means that we provide the noised latent image z in the t
    step, step t itself and text embeddings c θ(y), and then generate noise vector
    from the UNet model.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ϵ θ(z t, t, c θ(y))表示我们在t步骤提供带噪声的潜在图像z，t本身和文本嵌入c θ(y)，然后从UNet模型生成噪声向量。
- en: The 2 in || 2 means the square of the Euclidean distance. The 2 in || 2 means
    the data is in 2 dimensions.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2在|| 2中表示欧几里得距离的平方。2在|| 2中表示数据在2维。
- en: Together, the formula shows how we can use Stable Diffusion’s training process
    to approximate a new embedding, v *, that generates the minimum loss.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一起，公式显示了我们可以如何使用Stable Diffusion的训练过程来近似一个新嵌入v *，它生成最小损失。
- en: Next, let’s build a custom TI loader function.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们构建一个自定义TI加载器函数。
- en: Building a custom TI loader
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建自定义TI加载器
- en: In this section, we are going to build a TI loader by implementing the preceding
    understanding into code and giving a TI weight parameter for the loader function.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过将前面的理解转化为代码，并为加载函数提供一个TI权重参数来构建一个TI加载器。
- en: Before writing the function code, let’s first take a look at how a TI looks
    internally. Before running the following code, you will need to first download
    the TI file to your storage.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写函数代码之前，我们先来了解一下TI的内部结构。在运行以下代码之前，您需要先将TI文件下载到您的存储设备中。
- en: TI in the pt file format
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pt文件格式的TI
- en: 'Load a TI in the `pt` file format:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以`pt`文件格式加载TI：
- en: '[PRE22]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We can clearly see the key and paired value from the TI file:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到TI文件中的键和配对值：
- en: '[PRE23]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The most important value is the `tensor` object with the `string_to_param`
    key. We can take the tensor value out of it by using the following code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的值是具有`string_to_param`键的`tensor`对象。我们可以使用以下代码从中提取张量值：
- en: '[PRE24]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: TI in bin file format
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: bin文件格式的TI
- en: 'Most of the TI from the Hugging Face concepts library is in the `bin` format.
    The `bin` structure is even simpler than the `pt` one:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face概念库中的大多数TI都是`bin`格式。`bin`结构比`pt`结构更简单：
- en: '[PRE25]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We will see this – a dictionary with just one key and one value:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到这个——只有一个键和一个值的字典：
- en: '[PRE26]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Extracting the tensor object is as simple as doing the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 提取张量对象就像执行以下操作一样简单：
- en: '[PRE27]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Detailed steps to build a TI loader
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建TI加载器的详细步骤
- en: 'Here are the detailed steps to load a TI with weight:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是加载带有权重的TI的详细步骤：
- en: '`emb_params` key to store the embedding tensor.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`emb_params`键用于存储嵌入张量。'
- en: 'Use this function to load a TI in the model initialization stage or image generation
    stage:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用此函数在模型初始化阶段或图像生成阶段加载TI：
- en: '[PRE28]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let’s break down the preceding code:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们分析前面的代码：
- en: '`torch.load(learned_embeds_path, map_location=device)` loads the learned embeddings
    from the specified file using PyTorch’s `torch.load` function'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.load(learned_embeds_path, map_location=device)`使用PyTorch的`torch.load`函数从指定的文件加载学习嵌入'
- en: '`if "string_to_token" in loaded_learned_embeds` then checks for a specific
    file structure where embeddings are stored in a dictionary with the `string_to_token`
    and `string_to_param` keys, and extracts the token and embeddings from this structure'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if "string_to_token" in loaded_learned_embeds`检查一个特定的文件结构，其中嵌入存储在一个具有`string_to_token`和`string_to_param`键的字典中，并从这个结构中提取令牌和嵌入'
- en: '`elif "emb_params" in loaded_learned_embeds` then handles a different structure
    where embeddings are directly stored under the `emb_params` key'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`elif "emb_params" in loaded_learned_embeds`则处理一个不同的结构，其中嵌入直接存储在`emb_params`键下'
- en: '`else:` then handles a generic structure by assuming the embeddings are stored
    under the first key of the dictionary'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`else:`处理一个通用结构，假设嵌入存储在字典的第一个键下'
- en: In essence, the weight serves as a multiplier for each element of the embedding
    vector, fine-tuning the intensity of the TI effect. For example, a weight value
    of `1.0` would apply the TI at full strength, while a value of `0.5` would apply
    it at half strength.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实质上，权重作为嵌入向量的每个元素的乘数，微调TI效果强度。例如，权重值为`1.0`将应用TI的全强度，而值为`0.5`将应用半强度。
- en: 'Cast data to the same type of Stable Diffusion text encoder:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据转换为与Stable Diffusion文本编码器相同的类型：
- en: '[PRE53]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Add the token to the tokenizer:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将令牌添加到分词器中：
- en: '[PRE55]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The code will raise an exception if the added token already exists to prevent
    overriding existing tokens.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果添加的令牌已存在，代码将引发异常以防止覆盖现有令牌。
- en: 'Get the token ID and add the new embedding to the text encoder:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取令牌ID并将新的嵌入添加到文本编码器中：
- en: '[PRE63]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: That is all the code needs to load most of the existing TI from both the Hugging
    Face and Civitai.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是加载大多数现有TI（来自Hugging Face和Civitai）所需的全部代码。
- en: Putting all of the code together
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有代码放在一起
- en: 'Let’s put all of the code blocks together into one function – `load_textual_inversion`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把所有的代码块合并到一个函数中——`load_textual_inversion`：
- en: '[PRE64]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'To use it, we need to have both `tokenizer` and `text_encoder` from the pipeline
    object:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用它，我们需要从管道对象中获取`tokenizer`和`text_encoder`：
- en: '[PRE65]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Then load it by calling the newly created function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过调用新创建的函数来加载它：
- en: '[PRE66]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Now, use the same inference code to generate an image. Note that this time,
    we are using TI with a weight of `0.5`, so, let’s see whether anything is different
    compared with the original one with a weight of `1.0`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用相同的推理代码生成图像。请注意，这次我们使用的是权重为`0.5`的TI，让我们看看与原始权重为`1.0`的图像相比是否有任何不同：
- en: '[PRE67]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The result seems quite good (see *Figure 9**.4*):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来相当不错（见图9**.4**）：
- en: '![Figure 9.4: A futuristic city in deep space, with TI loaded by a custom function](img/B21263_09_04.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图9.4：通过自定义函数加载TI的深空未来城市](img/B21263_09_04.jpg)'
- en: 'Figure 9.4: A futuristic city in deep space, with TI loaded by a custom function'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4：通过自定义函数加载TI的深空未来城市
- en: The result seems even better than the one using Diffusers’ one-line TI loader.
    Another advantage of our custom loader is that we can now freely give weight to
    the loaded model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 结果似乎比使用Diffusers的单行TI加载器更好。我们自定义加载器的另一个优点是，我们现在可以自由地为加载的模型分配权重。
- en: Summary
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter discussed what Stable Diffusion TI is and the difference between
    it and LoRA. Then, we introduced a quick way to load any TI into Diffusers to
    apply a new pattern, style, or object in the generation pipeline.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了稳定扩散TI是什么以及它与LoRA之间的区别。然后，我们介绍了一种快速将任何TI加载到Diffusers中的方法，以便在生成管道中应用新的图案、风格或对象。
- en: Then, we dove into the core of TI and learned about how it is trained and how
    it works. Based on the understanding of how it works, we went a step further to
    implement a TI loader with the capability of accepting a TI weight.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们深入TI的核心，了解了它是如何训练和工作的。基于对它工作原理的理解，我们进一步实现了一个具有接受TI权重的TI加载器。
- en: Lastly, we provided a piece of sample code to call the custom TI loader and
    then generate an image with a weight of `0.5`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们提供了一段示例代码，用于调用自定义TI加载器，然后以`0.5`的权重生成图像。
- en: In the next chapter, we'll explore ways to maximize the power of prompts and
    unlock their full potential.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何最大化提示词的力量并解锁它们的全部潜力。
- en: References
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Rinon et al., *An Image is Worth One Word: Personalizing Text-to-Image Generation
    using Textual Inversion*: [https://arxiv.org/abs/2208.01618](https://arxiv.org/abs/2208.01618)
    and [https://textual-inversion.github.io/](https://textual-inversion.github.io/'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Rinon 等人，*一张图片胜过千言万语：使用文本反转个性化文本到图像生成*：[https://arxiv.org/abs/2208.01618](https://arxiv.org/abs/2208.01618)
    和 [https://textual-inversion.github.io/](https://textual-inversion.github.io/)
- en: )
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Hugging Face, *Textual* *Inversion*: [https://huggingface.co/docs/diffusers/main/en/training/text_inversion#how-it-works](https://huggingface.co/docs/diffusers/main/en/training/text_inversion#how-it-works)'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hugging Face，*文本反转*：[https://huggingface.co/docs/diffusers/main/en/training/text_inversion#how-it-works](https://huggingface.co/docs/diffusers/main/en/training/text_inversion#how-it-works)
- en: 'St*able Diffusion concepts library*: [https://huggingface.co/sd-concepts-library](https://huggingface.co/sd-concepts-library)'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**稳定扩散概念库**：[https://huggingface.co/sd-concepts-library](https://huggingface.co/sd-concepts-library)'
- en: 'Civitai: [https://civitai.com](https://civitai.com'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Civitai：[https://civitai.com](https://civitai.com
- en: )
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '*Midjourney style on Stable* *Diffusion*: [https://huggingface.co/sd-concepts-library/midjourney-style](https://huggingface.co/sd-concepts-library/midjourney-style'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在稳定扩散上应用Midjourney风格*：[https://huggingface.co/sd-concepts-library/midjourney-style](https://huggingface.co/sd-concepts-library/midjourney-style'
- en: )
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'OpenAI’s CLIP: [https://github.com/openai/CLIP](https://github.com/openai/CLIP)'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI的CLIP：[https://github.com/openai/CLIP](https://github.com/openai/CLIP)
