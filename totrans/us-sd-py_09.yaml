- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Textual Inversion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Textual inversion** (**TI**) is another way to provide additional capabilities
    to a pretrained model. Unlike **Low-Rank Adaptation** (**LoRA**), discussed in
    [*Chapter 8*](B21263_08.xhtml#_idTextAnchor153), which is a fine-tuning technique
    applied to the text encoder and the UNet attention weights, TI is a technique
    to add new **embedding** space based on the trained data.'
  prefs: []
  type: TYPE_NORMAL
- en: In the context of Stable Diffusion, **text embedding** refers to the representation
    of text data as numerical vectors in a high dimensional space, allowing for manipulation
    and processing by machine learning algorithms. Specifically, in the case of Stable
    Diffusion, text embeddings are typically created using the **Contrastive Language-Image
    Pretraining** (**CLIP**) [6] model.
  prefs: []
  type: TYPE_NORMAL
- en: To train a TI model, you only need a minimal set of three to five images, resulting
    in a compact `pt` or `bin` file, typically just a few kilobytes in size. This
    makes TI a highly efficient method for incorporating new elements, concepts, or
    styles into your pretrained checkpoint model while maintaining exceptional portability.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will first start using TI with the TI loader from the `diffusers`
    package, then delve into the core of TI to uncover how it works internally, and
    finally build a custom TI loader to have the TI weight applied to the image generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the topics we are going to cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Diffusers inference using TI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How TI works
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a custom TI loader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to start using any type of TI shared
    by the community and also build your application to load TI.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start leveraging the power of Stable Diffusion TI.
  prefs: []
  type: TYPE_NORMAL
- en: Diffusers inference using TI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before diving into how TI works internally, let’s take a look at how to use
    TI using Diffusers.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are countless pretrained TIs shared in the Hugging Face’s Stable Diffusion
    concepts library [3] and CIVITAI [4]. For example, one of the most downloaded
    TIs from the Stable Diffusion concepts library is `sd-concepts-library/midjourney-style`
    [5]. We can start using it by simply referencing this name in the code; Diffusers
    will download the model data automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s initialize a Stable Diffusion pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate an image without TI involved:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the prompt, `midjourney-style` is used, which will be given as the name
    of the TI. Without applying the name, we will see an image generated, as shown
    in *Figure 9**.1*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.1: A futuristic city in deep space without TI](img/B21263_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: A futuristic city in deep space without TI'
  prefs: []
  type: TYPE_NORMAL
- en: Generate an image with TI involved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let’s load the TI into the Stable Diffusion pipeline and give it a name,
    `midjourney-style`, to represent the newly added embeddings:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code will download the TI automatically and then add it to the
    pipeline model. Execute the same prompt and pipeline again, and we will get a
    completely new image, as shown in *Figure 9**.2*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.2: A futuristic city in deep space with TI](img/B21263_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: A futuristic city in deep space with TI'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yes, it looks and feels like an image generated by Midjourney, but it is actually
    generated by Stable Diffusion. The “*inversion*” in the name of the TI indicates
    that we can inverse any new name to the new embeddings, for example, if we give
    a new token a name such as `colorful-magic-style`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We will get the same image because we use `midjourney-style` as the name of
    the TI. This time, we “inverse” `colorful-magic-style` into the new embeddings.
    However, the `load_textual_inversion` function provided by Diffusers does not
    provide a `weight` parameter for users to load a TI with a certain weight. We
    will add the weighted TI in our own TI loader later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before that, let’s dig into the heart of TI and see how it works internally.
  prefs: []
  type: TYPE_NORMAL
- en: How TI works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Simply put, training a TI is finding a text embedding that matches the target
    image the best, such as its style, object, or face. The key is to find a new embedding
    that never existed in the current text encoder. As *Figure 9**.3*, from its original
    paper [1], shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3: The outline of the text embedding and inversion process](img/B21263_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: The outline of the text embedding and inversion process'
  prefs: []
  type: TYPE_NORMAL
- en: The only job of the training is to find a new embedding represented by v *.
    and use S * as the token string placeholder; the string can be replaced by any
    string that does not exist in the tokenizer later. Once the new corresponding
    embedding vector is founded, the train is done. The output of the training is
    usually a vector with 768 numbers. That is why the TI file is tiny; it is just
    a couple of kilobytes.
  prefs: []
  type: TYPE_NORMAL
- en: It is like the pretrained UNet is a pile of matrix magic boxes, one key (embedding)
    can unlock a box to have a pattern, a style, or an object. The number of boxes
    is way more than the limited keys from the text encoder provided. The training
    of a TI is done by providing a new key to unlock the unknown magic box. Throughout
    the training and inferencing, the original checkpoint model is untouched.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a precise way, the finding of the new embedding can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: v * = arg v min E z∼E(x),y,ϵ∼N(0,1),t[||ϵ − ϵ θ(z t, t, c θ(y))|| 2 2]
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go through the formula from left to right, one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: v * denotes the new embedding we are looking for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The arg : min notation is often used in statistics and optimization to denote
    the set of values that minimize a function. It is a useful notation because it
    allows us to talk about the minimum value of a function without having to specify
    the actual value of the minimum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The (E) is the loss expectation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: z ∼ E(x) denotes that the input image will be encoded to latent space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: y is the input text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: e ∼ N(0,1) says that the initial noise latent is a strict Gaussian with `0`
    mean and `1` variance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: c θ(y) represents a text encoder model that maps an input text string y into
    embedding vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ϵ θ(z t, t, c θ(y)) means that we provide the noised latent image z in the t
    step, step t itself and text embeddings c θ(y), and then generate noise vector
    from the UNet model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The 2 in || 2 means the square of the Euclidean distance. The 2 in || 2 means
    the data is in 2 dimensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, the formula shows how we can use Stable Diffusion’s training process
    to approximate a new embedding, v *, that generates the minimum loss.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s build a custom TI loader function.
  prefs: []
  type: TYPE_NORMAL
- en: Building a custom TI loader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to build a TI loader by implementing the preceding
    understanding into code and giving a TI weight parameter for the loader function.
  prefs: []
  type: TYPE_NORMAL
- en: Before writing the function code, let’s first take a look at how a TI looks
    internally. Before running the following code, you will need to first download
    the TI file to your storage.
  prefs: []
  type: TYPE_NORMAL
- en: TI in the pt file format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Load a TI in the `pt` file format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can clearly see the key and paired value from the TI file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The most important value is the `tensor` object with the `string_to_param`
    key. We can take the tensor value out of it by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: TI in bin file format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most of the TI from the Hugging Face concepts library is in the `bin` format.
    The `bin` structure is even simpler than the `pt` one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see this – a dictionary with just one key and one value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Extracting the tensor object is as simple as doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Detailed steps to build a TI loader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the detailed steps to load a TI with weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '`emb_params` key to store the embedding tensor.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use this function to load a TI in the model initialization stage or image generation
    stage:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s break down the preceding code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`torch.load(learned_embeds_path, map_location=device)` loads the learned embeddings
    from the specified file using PyTorch’s `torch.load` function'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`if "string_to_token" in loaded_learned_embeds` then checks for a specific
    file structure where embeddings are stored in a dictionary with the `string_to_token`
    and `string_to_param` keys, and extracts the token and embeddings from this structure'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`elif "emb_params" in loaded_learned_embeds` then handles a different structure
    where embeddings are directly stored under the `emb_params` key'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`else:` then handles a generic structure by assuming the embeddings are stored
    under the first key of the dictionary'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In essence, the weight serves as a multiplier for each element of the embedding
    vector, fine-tuning the intensity of the TI effect. For example, a weight value
    of `1.0` would apply the TI at full strength, while a value of `0.5` would apply
    it at half strength.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Cast data to the same type of Stable Diffusion text encoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the token to the tokenizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The code will raise an exception if the added token already exists to prevent
    overriding existing tokens.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Get the token ID and add the new embedding to the text encoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: That is all the code needs to load most of the existing TI from both the Hugging
    Face and Civitai.
  prefs: []
  type: TYPE_NORMAL
- en: Putting all of the code together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s put all of the code blocks together into one function – `load_textual_inversion`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'To use it, we need to have both `tokenizer` and `text_encoder` from the pipeline
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Then load it by calling the newly created function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, use the same inference code to generate an image. Note that this time,
    we are using TI with a weight of `0.5`, so, let’s see whether anything is different
    compared with the original one with a weight of `1.0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The result seems quite good (see *Figure 9**.4*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4: A futuristic city in deep space, with TI loaded by a custom function](img/B21263_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: A futuristic city in deep space, with TI loaded by a custom function'
  prefs: []
  type: TYPE_NORMAL
- en: The result seems even better than the one using Diffusers’ one-line TI loader.
    Another advantage of our custom loader is that we can now freely give weight to
    the loaded model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discussed what Stable Diffusion TI is and the difference between
    it and LoRA. Then, we introduced a quick way to load any TI into Diffusers to
    apply a new pattern, style, or object in the generation pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we dove into the core of TI and learned about how it is trained and how
    it works. Based on the understanding of how it works, we went a step further to
    implement a TI loader with the capability of accepting a TI weight.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we provided a piece of sample code to call the custom TI loader and
    then generate an image with a weight of `0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll explore ways to maximize the power of prompts and
    unlock their full potential.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rinon et al., *An Image is Worth One Word: Personalizing Text-to-Image Generation
    using Textual Inversion*: [https://arxiv.org/abs/2208.01618](https://arxiv.org/abs/2208.01618)
    and [https://textual-inversion.github.io/](https://textual-inversion.github.io/'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Hugging Face, *Textual* *Inversion*: [https://huggingface.co/docs/diffusers/main/en/training/text_inversion#how-it-works](https://huggingface.co/docs/diffusers/main/en/training/text_inversion#how-it-works)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'St*able Diffusion concepts library*: [https://huggingface.co/sd-concepts-library](https://huggingface.co/sd-concepts-library)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Civitai: [https://civitai.com](https://civitai.com'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '*Midjourney style on Stable* *Diffusion*: [https://huggingface.co/sd-concepts-library/midjourney-style](https://huggingface.co/sd-concepts-library/midjourney-style'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI’s CLIP: [https://github.com/openai/CLIP](https://github.com/openai/CLIP)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
