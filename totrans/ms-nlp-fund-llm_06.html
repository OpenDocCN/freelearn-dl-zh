<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-117"><a id="_idTextAnchor209" class="calibre5 pcalibre1 pcalibre"/>6</h1>
<h1 id="_idParaDest-118" class="calibre4"><a id="_idTextAnchor210" class="calibre5 pcalibre1 pcalibre"/>Text Classification Reimagined: Delving Deep into Deep Learning Language Models</h1>
<p class="calibre6">In this chapter, we delve<a id="_idIndexMarker541" class="calibre5 pcalibre1 pcalibre"/> into the realm of <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) and its application in <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>), specifically focusing<a id="_idIndexMarker542" class="calibre5 pcalibre1 pcalibre"/> on the groundbreaking<a id="_idIndexMarker543" class="calibre5 pcalibre1 pcalibre"/> transformer-based models such as <strong class="bold">Bidirectional Encoder Representations from Transformers</strong> (<strong class="bold">BERT</strong>) and <strong class="bold">generative pretrained transformer</strong> (<strong class="bold">GPT</strong>). We begin by introducing<a id="_idIndexMarker544" class="calibre5 pcalibre1 pcalibre"/> the fundamentals of DL, elucidating its powerful capability to learn intricate patterns from large amounts of data, making it the cornerstone of state-of-the-art NLP systems.</p>
<p class="calibre6">Following this, we delve into transformers, a novel architecture that has revolutionized NLP by offering a more effective method<a id="_idIndexMarker545" class="calibre5 pcalibre1 pcalibre"/> of handling sequence data compared to traditional <strong class="bold">recurrent neural networks</strong> (<strong class="bold">RNNs</strong>) and <strong class="bold">convolutional neural networks</strong> (<strong class="bold">CNNs</strong>). We unpack the transformer’s unique<a id="_idIndexMarker546" class="calibre5 pcalibre1 pcalibre"/> characteristics, including its attention mechanisms, which allow it to focus on different parts of the input sequence to better understand the context.</p>
<p class="calibre6">Then, we turn our attention to BERT and GPT, transformer-based language models that leverage these strengths to create highly nuanced language representations. We provide a detailed breakdown of the BERT architecture, discussing its innovative use of bidirectional training to generate contextually rich word embeddings. We will demystify the inner workings of BERT and explore its pretraining process, which leverages a large corpus of text to learn language semantics.</p>
<p class="calibre6">Finally, we discuss how BERT can be fine-tuned for specific tasks, such as text classification. We walk you through the steps, from data preprocessing and model configuration to training and evaluation, providing a hands-on understanding of how to leverage BERT’s power for text classification.</p>
<p class="calibre6">This chapter provides a thorough exploration of DL in NLP, moving from foundational concepts to practical applications, equipping you with the knowledge to harness the capabilities of BERT and transformer models for your text classification tasks.</p>
<p class="calibre6">The following topics are covered in this cha<a id="_idTextAnchor211" class="calibre5 pcalibre1 pcalibre"/>pter:</p>
<ul class="calibre14">
<li class="calibre15">Understanding deep learning b<a id="_idTextAnchor212" class="calibre5 pcalibre1 pcalibre"/>asics</li>
<li class="calibre15">The architecture of different neural networks</li>
<li class="calibre15">Transformers</li>
<li class="calibre15">Language models</li>
<li class="calibre15">The challenges of training neural networks</li>
<li class="calibre15">BERT</li>
<li class="calibre15">GPT</li>
<li class="calibre15">How to use language models for classification</li>
<li class="calibre15">NLP-ML system design ex<a id="_idTextAnchor213" class="calibre5 pcalibre1 pcalibre"/>ample</li>
</ul>
<h1 id="_idParaDest-119" class="calibre4"><a id="_idTextAnchor214" class="calibre5 pcalibre1 pcalibre"/>Technical requirements</h1>
<p class="calibre6">To successfully navigate through this chapter, certain technical prerequisites are necessary, as foll<a id="_idTextAnchor215" class="calibre5 pcalibre1 pcalibre"/>ows:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Programming knowledge</strong>: A strong understanding of Python is essential, as it’s the primary language used for most DL and NLP librar<a id="_idTextAnchor216" class="calibre5 pcalibre1 pcalibre"/>ies.</li>
<li class="calibre15"><strong class="bold">Machine learning fundamentals</strong>: A good grasp of basic ML concepts such as training/testing data, overfitting, underfitting, accuracy, precision, recall, and F1 score will be valu<a id="_idTextAnchor217" class="calibre5 pcalibre1 pcalibre"/>able.</li>
<li class="calibre15"><strong class="bold">DL basics</strong>: Familiarity with <strong class="bold">DL</strong> concepts and architectures, including neural networks, backpropagation, activation functions, and loss functions, will be essential. Knowledge of RNNs and CNNs would be advantageous but not strictly necessary as we will focus more on transformer architect<a id="_idTextAnchor218" class="calibre5 pcalibre1 pcalibre"/>ures.</li>
<li class="calibre15"><strong class="bold">NLP basics</strong>: Some understanding of basic NLP concepts such as tokenization, stemming, lemmatization, and word embeddings (such as <strong class="bold">Word2Vec </strong>or <strong class="bold">GloVe</strong>) would be benefi<a id="_idTextAnchor219" class="calibre5 pcalibre1 pcalibre"/>cial.</li>
<li class="calibre15"><strong class="bold">Libraries and frameworks</strong>: Experience with libraries such as <strong class="bold">TensorFlow </strong>and <strong class="bold">PyTorch</strong> for building and training neural models is crucial. Familiarity with NLP libraries such as <strong class="bold">NLTK </strong>or <strong class="bold">SpaCy</strong> can also be beneficial. For working with BERT specifically, knowledge of the <strong class="source-inline1">transformers</strong> library from <strong class="bold">Hugging Face</strong> would be very hel<a id="_idTextAnchor220" class="calibre5 pcalibre1 pcalibre"/>pful.</li>
<li class="calibre15"><strong class="bold">Hardware requirements</strong>: DL models, especially transformer-based models such as BERT, are computationally intensive and typically require a modern <strong class="bold">graphics processing unit</strong> (<strong class="bold">GPU)</strong> to train in a reasonable amount of time. Access to a high-performance computer or cloud-based solutions with GPU capabilities is highly recomme<a id="_idTextAnchor221" class="calibre5 pcalibre1 pcalibre"/>nded.</li>
<li class="calibre15"><strong class="bold">Mathematics</strong>: A good understanding of linear algebra, calculus, and probability is helpful for understanding the inner workings of these models, but most of the chapter can be understood without in-depth mathematical knowledge.</li>
</ul>
<p class="calibre6">These prerequisites are intended to equip you with the necessary background to understand and implement the concepts discussed in the chapter. With these in place, you should be well-prepared to delve into the fascinating world of DL for text classification using <a id="_idTextAnchor222" class="calibre5 pcalibre1 pcalibre"/><strong class="bold">BERT</strong>.</p>
<h1 id="_idParaDest-120" class="calibre4"><a id="_idTextAnchor223" class="calibre5 pcalibre1 pcalibre"/>Understanding deep learning basics</h1>
<p class="calibre6">In this part, we explain what<a id="_idIndexMarker547" class="calibre5 pcalibre1 pcalibre"/> neural network and deep neural networks are, what is the motivation for using them, and the different types (architectures) of deep learning mo<a id="_idTextAnchor224" class="calibre5 pcalibre1 pcalibre"/>dels.</p>
<h2 id="_idParaDest-121" class="calibre7"><a id="_idTextAnchor225" class="calibre5 pcalibre1 pcalibre"/>What is a neural network?</h2>
<p class="calibre6">Neural networks<a id="_idIndexMarker548" class="calibre5 pcalibre1 pcalibre"/> are a subfield of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) and ML that focuses on algorithms<a id="_idIndexMarker549" class="calibre5 pcalibre1 pcalibre"/> inspired by the structure and function of the brain. It is also known as “deep” learning because these neural networks often consist of many repetitive layers, creating a deep architecture.</p>
<p class="calibre6">These DL models<a id="_idIndexMarker550" class="calibre5 pcalibre1 pcalibre"/> are capable of “learning” from large volumes of complex, high-dimensional, and unstructured data. The term “learning” refers to the ability of the model to automatically learn and improve from experience without being explicitly programmed to do so for any one particular task of the tasks it learns.</p>
<p class="calibre6">DL can be supervised, semi-supervised, or unsupervised. It’s used in numerous applications, including NLP, speech recognition, image recognition, and even playing games. The models can identify patterns and make data-driven predictions or decisions.</p>
<p class="calibre6">One of the critical advantages<a id="_idIndexMarker551" class="calibre5 pcalibre1 pcalibre"/> of DL is its ability to process and model data of various types, including text, images, sound, and more. This versatility has led to a vast range of applications, from self-driving cars to sophisticated web search algorithms and highly responsive speech recognition systems.</p>
<p class="calibre6">It’s worth noting that DL, despite its high potential, also requires significant computational power and large amounts of high-quality data to train effectively, which can be a challenge.</p>
<p class="calibre6">In essence, DL is a powerful<a id="_idIndexMarker552" class="calibre5 pcalibre1 pcalibre"/> and transformative technology that is at the forefront of many of today’s technological ad<a id="_idTextAnchor226" class="calibre5 pcalibre1 pcalibre"/>vancements.</p>
<h3 class="calibre8">The motivation for using neural networks</h3>
<p class="calibre6">Neural networks are used for a variety of reasons in the field of ML and artificial intelligence. Here are some<a id="_idIndexMarker553" class="calibre5 pcalibre1 pcalibre"/> of the key <a id="_idTextAnchor227" class="calibre5 pcalibre1 pcalibre"/>motivations:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Nonlinearity</strong>: Neural networks, with their intricate structure and use of activation functions, can capture nonlinear relationships in data. Many real-world phenomena are nonlinear in nature, and neural networks offer a way to model these c<a id="_idTextAnchor228" class="calibre5 pcalibre1 pcalibre"/>omplexities.</li>
<li class="calibre15"><strong class="bold">Universal approximation theorem</strong>: This theorem states that a neural network with enough hidden units can approximate virtually any function with a high degree of accuracy. This makes them highly flexible and adaptable to a wide ran<a id="_idTextAnchor229" class="calibre5 pcalibre1 pcalibre"/>ge of tasks.</li>
<li class="calibre15"><strong class="bold">Ability to handle high dimensional data</strong>: Neural networks can handle data with a large number of features or dimensions effectively, which makes them useful for tasks such as image or speech recognition, where data is highly <a id="_idTextAnchor230" class="calibre5 pcalibre1 pcalibre"/>dimensional.</li>
<li class="calibre15"><strong class="bold">Pattern recognition and prediction</strong>: Neural networks excel at identifying patterns and trends within large datasets, making them especially useful for prediction tasks, such as forecasting sales or predicting stock ma<a id="_idTextAnchor231" class="calibre5 pcalibre1 pcalibre"/>rket trends.</li>
<li class="calibre15"><strong class="bold">Parallel processing</strong>: Neural networks’ architecture allows them to perform many operations simultaneously, making them highly efficient when implemented on mode<a id="_idTextAnchor232" class="calibre5 pcalibre1 pcalibre"/>rn hardware.</li>
<li class="calibre15"><strong class="bold">Learning from data</strong>: Neural networks can improve their performance as they are exposed to more data. This ability to learn from data makes them highly effective for tasks where large amounts of data ar<a id="_idTextAnchor233" class="calibre5 pcalibre1 pcalibre"/>e available.</li>
<li class="calibre15"><strong class="bold">Robustness</strong>: Neural networks can handle noise in the input data and are robust to small variations<a id="_idIndexMarker554" class="calibre5 pcalibre1 pcalibre"/> in the input.</li>
</ul>
<p class="calibre6">Additionally, neural networks are extensively used in NLP tasks due to several reasons. Here are some of the primary<a id="_idTextAnchor234" class="calibre5 pcalibre1 pcalibre"/> motivations:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Handling sequential data</strong>: Natural language is inherently sequential (words follow one another to make coherent sentences). RNNs and their advanced<a id="_idIndexMarker555" class="calibre5 pcalibre1 pcalibre"/> versions, such as <strong class="bold">long short-term memory</strong> (<strong class="bold">LSTM</strong>) and <strong class="bold">gated recurrent units</strong> (<strong class="bold">GRUs</strong>), are types of neural networks<a id="_idIndexMarker556" class="calibre5 pcalibre1 pcalibre"/> that are capable of processing sequential data by maintaining a form of internal state or memory about the previous steps i<a id="_idTextAnchor235" class="calibre5 pcalibre1 pcalibre"/>n the sequence.</li>
<li class="calibre15"><strong class="bold">Context understanding</strong>: Neural networks, especially recurrent types, are capable of understanding the context in a sentence by taking into account the surrounding words or even previous sentences, which is crucia<a id="_idTextAnchor236" class="calibre5 pcalibre1 pcalibre"/>l in NLP tasks.</li>
<li class="calibre15"><strong class="bold">Semantic hashing</strong>: Neural networks, through the use of word embeddings (such as Word2Vec and GloVe), can encode words in a way that preserves their semantic meaning. Words with similar meanings are placed closer together in the vector space, which is highly valuable for <a id="_idTextAnchor237" class="calibre5 pcalibre1 pcalibre"/>many NLP tasks.</li>
<li class="calibre15"><strong class="bold">End-to-end learning</strong>: Neural networks can learn directly from raw data. For example, in image classification, a neural network can learn features from the pixel level without needing any manual feature extraction steps. This is a significant advantage, as the feature extraction process can be time-consuming and require domain expertise.<p class="calibre6">Similarly, neural networks can learn to perform NLP tasks from raw text data without the need for manual feature extraction. This is a big advantage in NLP, where creating hand-engineered features can be challenging and <a id="_idTextAnchor238" class="calibre5 pcalibre1 pcalibre"/>time-consuming.</p></li>
<li class="calibre15"><strong class="bold">Performance</strong>: Neural networks, especially with the advent of transformer-based architectures such as BERT, GPT, and so on., have been shown to achieve state-of-the-art results in many NLP tasks, including but not limited to machine translation, text summarization, sentiment analysis, and ques<a id="_idTextAnchor239" class="calibre5 pcalibre1 pcalibre"/>tion answering.</li>
<li class="calibre15"><strong class="bold">Handling large vocabularies</strong>: Neural networks can effectively handle large vocabularies and continuous text streams, which is typical in man<a id="_idTextAnchor240" class="calibre5 pcalibre1 pcalibre"/>y <strong class="bold">NLP</strong> problems.</li>
<li class="calibre15"><strong class="bold">Learning hierarchical features</strong>: Deep neural networks can learn hierarchical representations. In the context of NLP, lower layers often learn to represent simple things such as n-grams, whereas higher layers can represent complex concepts<a id="_idIndexMarker557" class="calibre5 pcalibre1 pcalibre"/> such as sentiment.</li>
</ul>
<p class="calibre6">Despite these advantages, it’s worth noting that neural networks also have their challenges, including their “black box” nature, which makes their decision-making process difficult to interpret, and their need for large amounts of data and computational resources for training. However, the benefits they provide in terms of performance and their ability to learn from raw text data and model complex relationships make them a go-to choice for<a id="_idTextAnchor241" class="calibre5 pcalibre1 pcalibre"/> many NLP tasks.</p>
<h2 id="_idParaDest-122" class="calibre7"><a id="_idTextAnchor242" class="calibre5 pcalibre1 pcalibre"/>The basic design of a neural network</h2>
<p class="calibre6">A neural network consists<a id="_idIndexMarker558" class="calibre5 pcalibre1 pcalibre"/> of multiple layers of interconnected nodes, or “neurons,” each of which performs a simple computation on the data it receives, passing its output to the neurons of the next layer. Each connection between neurons has an associated weight that is adjusted during the learning process.</p>
<p class="calibre6">The architecture of a basic neural network consists of three types of layers, as shown in <em class="italic">Figure 6</em><em class="italic">.1</em>:</p>
<div><div><img alt="Figure 6.1 – Basic architecture of neural networks" src="img/B18949_06_001.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Basic architecture of neural networks</p>
<p class="calibre6">In the following list, we explain each layer of the mode<a id="_idTextAnchor243" class="calibre5 pcalibre1 pcalibre"/>l in more detail:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Input layer</strong>: This is where the network<a id="_idIndexMarker559" class="calibre5 pcalibre1 pcalibre"/> receives its input. If the network is designed to process an image with dimensions of 28x28 pixels, for instance, there would be 784 neurons in the input layer, each representing the va<a id="_idTextAnchor244" class="calibre5 pcalibre1 pcalibre"/>lue of one pixel.</li>
<li class="calibre15"><strong class="bold">Hidden layer(s)</strong>: These are the layers <a id="_idIndexMarker560" class="calibre5 pcalibre1 pcalibre"/>between the input and output layers. Each neuron in a hidden layer takes the outputs of the neurons from the previous layer, multiplies each of these by the weight of the respective connection, and sums these values up. This sum is then passed through an “activation function” to introduce nonlinearity into the model, which helps the network learn complex patterns. There can be any number of hidden layers in a neural network, and a network with<a id="_idIndexMarker561" class="calibre5 pcalibre1 pcalibre"/> many hidden layers<a id="_idIndexMarker562" class="calibre5 pcalibre1 pcalibre"/> is often referred to as a “d<a id="_idTextAnchor245" class="calibre5 pcalibre1 pcalibre"/>eep” neural network.</li>
<li class="calibre15"><strong class="bold">Output layer</strong>: This is the final layer<a id="_idIndexMarker563" class="calibre5 pcalibre1 pcalibre"/> in the network. The neurons in this layer produce the final output of the network. For a classification problem, for instance, you might design the network to have one output neuron for each class in the problem, with each neuron outputting a value indicating the probability that the input belongs to its respective class.</li>
</ul>
<p class="calibre6">The neurons in the network are interconnected. The weights of these connections, which are initially set to random values, represent what the network has learned once it has been trained on data.</p>
<p class="calibre6">During the training process, an algorithm such as backpropagation is used to adjust the weights of the connections in the network in response to the difference between the network’s output and the desired output. This process is repeated many times, and the network gradually improves its performance on the training data.</p>
<p class="calibre6">To provide a simple visual idea, imagine<a id="_idIndexMarker564" class="calibre5 pcalibre1 pcalibre"/> three sets of circles (representing neurons) arranged in columns (representing layers). The first column is the input layer, the last column is the output layer and any columns in between are the hidden layers. Then, imagine lines connecting every circle in each column to every circle in the next column, representing the weighted connections between neurons. That’s a basic visual representation of a neural network.</p>
<p class="calibre6">In the next part, we are going to describe the common terms relate<a id="_idTextAnchor246" class="calibre5 pcalibre1 pcalibre"/>d to neural networks.</p>
<h2 id="_idParaDest-123" class="calibre7"><a id="_idTextAnchor247" class="calibre5 pcalibre1 pcalibre"/>Neural network common terms</h2>
<p class="calibre6">In the following subsections, we'll look at some of the most commonly used terms in the conte<a id="_idTextAnchor248" class="calibre5 pcalibre1 pcalibre"/>xt of neural networks.</p>
<h3 class="calibre8">Neuron (or node)</h3>
<p class="calibre6">This is the basic unit of computation<a id="_idIndexMarker565" class="calibre5 pcalibre1 pcalibre"/> in a neural network; typically, a simple computation involves inputs, weights, a bias, and an activation function. A neuron, also known as a node or unit, is a fundamental element<a id="_idIndexMarker566" class="calibre5 pcalibre1 pcalibre"/> in a neural network. It receives input from some other nodes or from an external source if the neuron is in the input layer. The neuron then computes an output based on this input.</p>
<p class="calibre6">Each input has an associated weight (<em class="italic">w</em>), which is assigned based on its relative importance to other inputs. The neuron applies a weight to the inputs, sums them up, and then applies an activation function to the sum plus a bias value (<em class="italic">b</em>).</p>
<p class="calibre6">Here’s a<a id="_idTextAnchor249" class="calibre5 pcalibre1 pcalibre"/> step-by-step breakdown:</p>
<ol class="calibre16">
<li class="calibre15"><strong class="bold">Weighted sum</strong>: Each input (<em class="italic">x</em>) to the neuron<a id="_idIndexMarker567" class="calibre5 pcalibre1 pcalibre"/> is multiplied by a corresponding weight (<em class="italic">w</em>). These weighted inputs are then summed together with a bias term (<em class="italic">b</em>). The bias term allows for the activation function to be shifted to the left or the right, helping the neuron model a wider range of patterns. Mathematically, this step can be represented as follows:<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/297.png" class="calibre296"/></p></li>
<li class="calibre15"><strong class="bold">Activation function</strong>: The result of the weighted<a id="_idIndexMarker568" class="calibre5 pcalibre1 pcalibre"/> sum is then passed through an activation function. The purpose of the activation function is to introduce nonlinearity into the output of a neuron. This nonlinearity allows the network to learn from errors and make adjustments, which is essential when it comes to performing complex tasks such as language translation or image recognition. Common choices<a id="_idIndexMarker569" class="calibre5 pcalibre1 pcalibre"/> for activation functions include<a id="_idIndexMarker570" class="calibre5 pcalibre1 pcalibre"/> the sigmoid function, hyperbolic <strong class="bold">tangent</strong> (<strong class="bold">tanh</strong>), and <strong class="bold">rectified linear unit</strong> (<strong class="bold">ReLU</strong>), among others.<p class="calibre6">The output of the neuron is the result of the activation function. It serves as the input to the neurons in the next layer of the network.</p><p class="calibre6">The weights and bias in the neuron<a id="_idIndexMarker571" class="calibre5 pcalibre1 pcalibre"/> are learnable parameters. In other words, their values are learned over time as the neura<a id="_idTextAnchor250" class="calibre5 pcalibre1 pcalibre"/>l network is trained on data:</p><ul class="calibre17"><li class="calibre15"><strong class="bold">Weights</strong>: The strength or amplitude<a id="_idIndexMarker572" class="calibre5 pcalibre1 pcalibre"/> of the connection between two neurons. During the training phase, the neural network learns the correct weights that better map inputs to outputs. Weight is used in t<a id="_idTextAnchor251" class="calibre5 pcalibre1 pcalibre"/>he neuron, as explained previously.</li><li class="calibre15"><strong class="bold">Bias</strong>: An additional parameter in the neuron<a id="_idIndexMarker573" class="calibre5 pcalibre1 pcalibre"/> that allows for the activation function to be shifted to the left or right, which can be critical for successful lear<a id="_idTextAnchor252" class="calibre5 pcalibre1 pcalibre"/>ning (also used in the neuron).</li></ul></li>
</ol>
<h3 class="calibre8">Activation function</h3>
<p class="calibre6">The function (in each neuron) that determines<a id="_idIndexMarker574" class="calibre5 pcalibre1 pcalibre"/> the output a neuron<a id="_idIndexMarker575" class="calibre5 pcalibre1 pcalibre"/> should produce given its input is called an activation function. Common examples include sigmoid, ReLU and tanh.</p>
<p class="calibre6">Here are some of the most common types of activation functions:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Sigmoid function</strong>: This is where we’re essentially <a id="_idIndexMarker576" class="calibre5 pcalibre1 pcalibre"/>classifying the input<a id="_idIndexMarker577" class="calibre5 pcalibre1 pcalibre"/> as either 0 or 1. The sigmoid function takes a real-valued input and squashes it to range between 0 and 1. It’s often used in the output layer of a binary classification network:<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/298.png" class="calibre297"/></p><p class="calibre6">However, it has two major drawbacks: <strong class="bold">the vanishing gradients problem</strong> (gradients are very small<a id="_idIndexMarker578" class="calibre5 pcalibre1 pcalibre"/> for large positive or negative inputs, which can slow down learning during<a id="_idIndexMarker579" class="calibre5 pcalibre1 pcalibre"/> backpropagation) and the <strong class="bold">outputs are </strong><strong class="bold">not zero-centered</strong>.</p></li>
<li class="calibre15"><strong class="bold">Hyperbolic tanh function</strong>: The tanh function also takes<a id="_idIndexMarker580" class="calibre5 pcalibre1 pcalibre"/> a real-valued input<a id="_idIndexMarker581" class="calibre5 pcalibre1 pcalibre"/> and squashes it to range between -1 and 1. Unlike the sigmoid function, its output is zero-centered because its range is symmetric around the origin:<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/299.png" class="calibre298"/></p><p class="calibre6">It also suffers from the vanishing gradients<a id="_idIndexMarker582" class="calibre5 pcalibre1 pcalibre"/> problem, as does the sigmoid function.</p></li>
<li class="calibre15"><strong class="bold">ReLU function</strong>: The ReLU function has become<a id="_idIndexMarker583" class="calibre5 pcalibre1 pcalibre"/> very popular in recent<a id="_idIndexMarker584" class="calibre5 pcalibre1 pcalibre"/> years. It computes the function as follows:<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/300.png" class="calibre299"/></p><p class="calibre6">In other words, the activation is simply the input if the input is positive; otherwise, it’s zero.</p><p class="calibre6">It doesn’t activate all the neurons at the same time, meaning that the neurons will only be deactivated if the output of the linear transformation is less than 0. This makes the network sparse and efficient. However, ReLU units can be fragile during training and can “die” (they stop learning completely) if a large gradient flows through them.</p></li>
<li class="calibre15"><strong class="bold">Leaky ReLU</strong>: Leaky ReLU is a variant of ReLU<a id="_idIndexMarker585" class="calibre5 pcalibre1 pcalibre"/> that addresses<a id="_idIndexMarker586" class="calibre5 pcalibre1 pcalibre"/> the “dying ReLU” problem. Instead of defining the function as <em class="italic">0</em> for negative <em class="italic">x</em>, we define it as a small linear component of <em class="italic">x</em>:<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0.01&lt;/mn&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/301.png" class="calibre300"/></p><p class="calibre6">This allows the function to “leak” some information when the input is negative and helps to mitigate<a id="_idIndexMarker587" class="calibre5 pcalibre1 pcalibre"/> the dying ReLU problem.</p></li>
<li class="calibre15"><strong class="bold">Exponential linear unit (ELU)</strong>: ELU is also a variant of ReLU<a id="_idIndexMarker588" class="calibre5 pcalibre1 pcalibre"/> that modifies the function<a id="_idIndexMarker589" class="calibre5 pcalibre1 pcalibre"/> to be a non-zero value for negative <em class="italic">x</em>, which can help the learning process:<p class="calibre6">f(x) = x if x &gt; 0, else </p><p class="calibre6">α(exp(x) − 1)</p><p class="calibre6">Here alpha (<em class="italic">α</em>) is a constant that defines function smoothness when inputs are negative. ELU tends to converge cost to zero faster and produce more accurate results. However, it can be slower to compute because of the use of the exponential operation.</p></li>
<li class="calibre15"><strong class="bold">Softmax function</strong>: The softmax function is often used <a id="_idIndexMarker590" class="calibre5 pcalibre1 pcalibre"/>in the output layer<a id="_idIndexMarker591" class="calibre5 pcalibre1 pcalibre"/> of a classifier where we’re trying to assign the input to one of several classes. It gives the probability that any given input belongs to each of the possible classes:</li>
</ul>
<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/302.png" class="calibre301"/></p>
<p class="calibre6">The denominator normalizes the probabilities, so they all sum up to 1 across all classes. The softmax function is also used in multinomial logistical regression.</p>
<p class="calibre6">Each of these activation functions<a id="_idIndexMarker592" class="calibre5 pcalibre1 pcalibre"/> has pros and cons, and the choice of activation function can depend on the specif<a id="_idTextAnchor253" class="calibre5 pcalibre1 pcalibre"/>ic application and context of the problem at hand.</p>
<h4 class="calibre135">Layer</h4>
<p class="calibre6">A set of neurons that process<a id="_idIndexMarker593" class="calibre5 pcalibre1 pcalibre"/> signals at the same level of abstraction. The first layer is the input layer, the last layer<a id="_idIndexMarker594" class="calibre5 pcalibre1 pcalibre"/> is the output layer,<a id="_idTextAnchor254" class="calibre5 pcalibre1 pcalibre"/> and all layers in between are called hidden layers.</p>
<h3 class="calibre8">Epoch</h3>
<p class="calibre6">In the context of<a id="_idIndexMarker595" class="calibre5 pcalibre1 pcalibre"/> training a neural<a id="_idIndexMarker596" class="calibre5 pcalibre1 pcalibre"/> network, an epoch is a term used to denote one complete pass through the entire training dataset. During an epoch, the neural network’s weights are updated in an attempt to minimize the loss function.</p>
<p class="calibre6">The number of epochs hyperparameter sets how many times the deep learning algorithm processes the entire training dataset. Too many epochs can cause overfitting, where the model performs well on training data but poorly on new data. Conversely, training for too few epochs may mean the model is underfitting—it could improve with further training.</p>
<p class="calibre6">It’s also important to note that the concept of an epoch is more relevant in the batch and mini-batch variants of gradient descent. In stochastic gradient descent, the model’s weights are updated after seeing each individual exampl<a id="_idTextAnchor255" class="calibre5 pcalibre1 pcalibre"/>e, so the concept of an epoch<a id="_idIndexMarker597" class="calibre5 pcalibre1 pcalibre"/> is less straightforward.</p>
<h3 class="calibre8">Batch size</h3>
<p class="calibre6">The number of<a id="_idIndexMarker598" class="calibre5 pcalibre1 pcalibre"/> training instances<a id="_idIndexMarker599" class="calibre5 pcalibre1 pcalibre"/> used in one iteration. Batch size refers to the number of training examples used in one iteration.</p>
<p class="calibre6">When you start training a neural network, you have a cou<a id="_idTextAnchor256" class="calibre5 pcalibre1 pcalibre"/>ple of options for how you feed your data into the model:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Batch gradient descent</strong>: Here, the entire training dataset is used to compute the gradient of the loss function for each iteration of the optimizer (as with gradient descent). In this case, the batch size is equal<a id="_idTextAnchor257" class="calibre5 pcalibre1 pcalibre"/> to the total number of examples in the training dataset.</li>
<li class="calibre15"><strong class="bold">Stochastic gradient descent (SGD)</strong>: SGD uses a single example at each iteration <a id="_idTextAnchor258" class="calibre5 pcalibre1 pcalibre"/>of the optimizer. Therefore, the batch size for SGD is <em class="italic">1</em>.</li>
<li class="calibre15"><strong class="bold">Mini-batch gradient descent</strong>: This is a compromise between batch gradient descent and SGD. In mini-batch gradient descent, the batch size is usually between 10 and 1,000 and is chosen depending on the computational resources you have.</li>
</ul>
<p class="calibre6">The batch size can significantly<a id="_idIndexMarker600" class="calibre5 pcalibre1 pcalibre"/> impact the learning process. Larger batch sizes result in faster progress in training but don’t always converge as fast. Smaller batch sizes update the model frequently but the progress in training is slower.</p>
<p class="calibre6">Moreover, smaller batch sizes have a regularizing effect and can help the model generalize better, leading to better performance on unseen data. However, using a batch size that is too small can lead to unstable training, less accurate estimates of the gradient, and, ultimately, a model with worse performance.</p>
<p class="calibre6">Choosing the right batch size<a id="_idIndexMarker601" class="calibre5 pcalibre1 pcalibre"/> is a matter of trial and error and depends on th<a id="_idTextAnchor259" class="calibre5 pcalibre1 pcalibre"/>e specific problem and the computational resources at hand:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Iterations</strong>: The number of batches of data the algorithm has<a id="_idTextAnchor260" class="calibre5 pcalibre1 pcalibre"/> seen (or the number of passes it has made on the dataset).</li>
<li class="calibre15"><strong class="bold">Learning rate</strong>: A hyperparameter that controls the speed of convergence of the learning algorithm by ad<a id="_idTextAnchor261" class="calibre5 pcalibre1 pcalibre"/>justing the weight update rate based on the loss gradient.</li>
<li class="calibre15"><strong class="bold">Loss function (cost function)</strong>: The loss function evaluates the neural network’s performance on the dataset. Higher deviations between predictions and actual results result in a larger output from the loss function. The goal is to minimize<a id="_idIndexMarker602" class="calibre5 pcalibre1 pcalibre"/> this <a id="_idTextAnchor262" class="calibre5 pcalibre1 pcalibre"/>output, which will give the model more accurate predictions.</li>
<li class="calibre15"><strong class="bold">Backpropagation</strong>: The primary algorithm for performing gradient descent on neural networks. It calculates the gradient of the loss function at the output layer and distributes it back through the layers of the network, updat<a id="_idTextAnchor263" class="calibre5 pcalibre1 pcalibre"/>ing the weights and biases in a way that minimizes the loss.</li>
<li class="calibre15"><strong class="bold">Overfitting</strong>: A situation where a model learns<a id="_idIndexMarker603" class="calibre5 pcalibre1 pcalibre"/> the detail and noise in the training da<a id="_idTextAnchor264" class="calibre5 pcalibre1 pcalibre"/>ta to the extent that it performs poorly on new, unseen data.</li>
<li class="calibre15"><strong class="bold">Underfitting</strong>: A situation where a model is too simple to learn the underlying structure of the d<a id="_idTextAnchor265" class="calibre5 pcalibre1 pcalibre"/>ata and, thus, performs poorly on both training and new data.</li>
<li class="calibre15"><strong class="bold">Regularization</strong>: A technique used to prevent overfitting by adding a penalty term to the loss fun<a id="_idTextAnchor266" class="calibre5 pcalibre1 pcalibre"/>ction, which, in turn, constrains the weights of the network.</li>
<li class="calibre15"><strong class="bold">Dropout</strong>: A regularization technique where randomly selected neurons are<a id="_idTextAnchor267" class="calibre5 pcalibre1 pcalibre"/> ignored during training, which helps to prevent overfitting.</li>
<li class="calibre15"><strong class="bold">CNN</strong>: A type of neural netwo<a id="_idTextAnchor268" class="calibre5 pcalibre1 pcalibre"/>rk well-suited to image processing and computer vision tasks.</li>
<li class="calibre15"><strong class="bold">RNN</strong>: A type of neural network designed to recognize patterns<a id="_idIndexMarker604" class="calibre5 pcalibre1 pcalibre"/> in sequences of data, such as time <a id="_idIndexMarker605" class="calibre5 pcalibre1 pcalibre"/>series or text.</li>
</ul>
<p class="calibre6">Let’s<a id="_idTextAnchor269" class="calibre5 pcalibre1 pcalibre"/> move on to the architecture of different neural networks next.</p>
<h1 id="_idParaDest-124" class="calibre4"><a id="_idTextAnchor270" class="calibre5 pcalibre1 pcalibre"/>The architecture of different neural networks</h1>
<p class="calibre6">Neural networks come in various<a id="_idIndexMarker606" class="calibre5 pcalibre1 pcalibre"/> types, each with a specific architecture suited to a different kind of task. The following list<a id="_idTextAnchor271" class="calibre5 pcalibre1 pcalibre"/> contains general descriptions of some of the most common types:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Feedforward neural network (FNN)</strong>: This is the most straightforward<a id="_idIndexMarker607" class="calibre5 pcalibre1 pcalibre"/> type of neural<a id="_idIndexMarker608" class="calibre5 pcalibre1 pcalibre"/> network. Information in this network moves in one direction only, from the input layer through any hidden layers to the output layer. There are no cycles or loops in the network; it’s a straight<a id="_idTextAnchor272" class="calibre5 pcalibre1 pcalibre"/>, “feedforward” path.</li>
</ul>
<div><div><img alt="Figure 6.2 – Feedforward neural network" src="img/B18949_06_002.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Feedforward neural network</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Multilayer perceptron (MLP)</strong>: An MLP is a type of feedforward <a id="_idIndexMarker609" class="calibre5 pcalibre1 pcalibre"/>network that has at<a id="_idIndexMarker610" class="calibre5 pcalibre1 pcalibre"/> least one hidden layer in addition to its input and output layers. The layers are fully connected, meaning each neuron in a layer connects with every neuron in the next layer. MLPs can model complex patterns and are widely used for tasks such as image recognition, classification, speech recognition, and other types of machine learning tasks. The MLP is a feedforward network with layers of neurons arranged sequentially. Information flows from the input layer through hidden layers<a id="_idIndexMarker611" class="calibre5 pcalibre1 pcalibre"/> to the o<a id="_idTextAnchor273" class="calibre5 pcalibre1 pcalibre"/>utput layer<a id="_idIndexMarker612" class="calibre5 pcalibre1 pcalibre"/> in one direction:</li>
</ul>
<div><div><img alt="Figure 6.3 – Multilayer perceptron" src="img/B18949_06_003.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Multilayer perceptron</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">CNN</strong>: A CNN is particularly well-suited<a id="_idIndexMarker613" class="calibre5 pcalibre1 pcalibre"/> to tasks involving<a id="_idIndexMarker614" class="calibre5 pcalibre1 pcalibre"/> spatial data, such as images. Its architecture includes three main types of layers: convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply a series of filters to the input, which allows the network to automatically and adaptively learn spatial hierarchies of features. Pooling layers decrease the spatial size of the representation, thereby reducing parameters and computation in the network to control overfitting and decrease the computation cost in the following layers. Fully connected layers get the output of the pooling layer and conduct high-level<a id="_idTextAnchor274" class="calibre5 pcalibre1 pcalibre"/> reasoning on the output.</li>
</ul>
<div><div><img alt="Figure 6.4 – ﻿Convolutional neural network" src="img/B18949_06_004.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Convolutional neural network</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Recurrent neural network (RNN)</strong>: Unlike feedforward networks, RNNs have connections<a id="_idIndexMarker615" class="calibre5 pcalibre1 pcalibre"/> that form directed <a id="_idIndexMarker616" class="calibre5 pcalibre1 pcalibre"/>cycles. This architecture allows them to use information from their previous outputs as inputs, making them ideal for tasks involving sequential data, such<a id="_idIndexMarker617" class="calibre5 pcalibre1 pcalibre"/> as time series prediction or NLP. A significant variation of RNNs is the LSTM network, which uses special units in addition to standard units. RNN units include a "memory cell" that can maintain information in memory for long periods of time, a feature that is particularly useful for tasks that require learning from long-distance dependencies in the data, such as handwri<a id="_idTextAnchor275" class="calibre5 pcalibre1 pcalibre"/>ting or speech recognition.</li>
</ul>
<div><div><img alt="Figure 6.5 – Recurrent neural network" src="img/B18949_06_005.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Recurrent neural network</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Autoencoder (AE)</strong>: An AE is a type<a id="_idIndexMarker618" class="calibre5 pcalibre1 pcalibre"/> of neural network<a id="_idIndexMarker619" class="calibre5 pcalibre1 pcalibre"/> used to learn the efficient coding of input data. It has a symmetrical architecture and is designed to apply backpropagation, setting the target values to be equal to the inputs. Autoencoders are typically used for feature extraction, learning representations of data, and dimensionality reduction. They’re also used in generative models, noise removal, <a id="_idTextAnchor276" class="calibre5 pcalibre1 pcalibre"/>and recommendation systems.</li>
</ul>
<div><div><img alt="Figure 6.6 – Autoencoder architecture" src="img/B18949_06_006.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.6 – Autoencoder architecture</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Generative adversarial network (GAN)</strong>: A GAN consists of two<a id="_idIndexMarker620" class="calibre5 pcalibre1 pcalibre"/> parts, a generator<a id="_idIndexMarker621" class="calibre5 pcalibre1 pcalibre"/> and a discriminator, which are both neural networks. The generator creates data instances that aim to come from the same distribution as the training dataset. The discriminator’s goal is to distinguish between instances from the true distribution and instances from the generator. The generator and the discriminator are trained together, with the goal that the generator produces better instances as training progresses, whereas the discriminator becomes better at distinguishing true instances from generated ones.</li>
</ul>
<div><div><img alt="Figure 6.7 – Generative adversarial network in computer vision" src="img/B18949_06_007.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.7 – Generative adversarial network in computer vision</p>
<p class="calibre6">These are just a few examples of neural network architectures, and many variations and combinations exist. The architecture you choose for a task<a id="_idTextAnchor277" class="calibre5 pcalibre1 pcalibre"/> will depend on the specific requirements and constraints of your task.</p>
<h1 id="_idParaDest-125" class="calibre4"><a id="_idTextAnchor278" class="calibre5 pcalibre1 pcalibre"/>The challenges of training neural networks</h1>
<p class="calibre6">Training neural networks is a complex task and comes with challenges during the training, such as local minima and vanishing/exploding gradients, as well as computational costs and int<a id="_idTextAnchor279" class="calibre5 pcalibre1 pcalibre"/>erpretability. All challenges<a id="_idIndexMarker622" class="calibre5 pcalibre1 pcalibre"/> are explained in detail in the following points:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Local minima</strong>: The objective of training a neural network is to find the set of weights that minimizes the loss function. This is a high-dimensional optimization problem, and there are many points (sets of weights) where the loss function has local minima. A suboptimal local minimum is a point where the loss is lower than for the nearby points but higher than the global minimum, which is the overall lowest possible loss. The training process can get stuck in such suboptimal local minima. It’s important to remember that the local minima problem exists even in convex loss functions d<a id="_idTextAnchor280" class="calibre5 pcalibre1 pcalibre"/>ue to the discrete representation that is a part of digital computation.</li>
<li class="calibre15"><strong class="bold">Vanishing/exploding gradients</strong>: This is a difficulty encountered, especially when training deep neural networks. The gradients of the loss function may become very small (vanish) or very large (explode) in deeper layers of the network during the backpropagation process. Vanishing gradients make it hard for the network to learn from the data because the weight updates become very small. Exploding gradients can cause the training process to fail because weig<a id="_idTextAnchor281" class="calibre5 pcalibre1 pcalibre"/>ht updates become too large, and the loss becomes undefined (e.g., NaN).</li>
<li class="calibre15"><strong class="bold">Overfitting</strong>: One of the common problems in training machine learning models is when our model is too complex, and we train it too much. In this case, the model learns even the noises in the training data a<a id="_idTextAnchor282" class="calibre5 pcalibre1 pcalibre"/>nd works very well on training data but poorly on the unseen test data.</li>
<li class="calibre15"><strong class="bold">Underfitting</strong>: Conversely, underfitting occurs when the model is too simple and can’t capture the underlying structure of the data. Both overfitting and underfitting can be mitigated by using proper model complexi<a id="_idTextAnchor283" class="calibre5 pcalibre1 pcalibre"/>ty, regularization techniques, and a sufficient amount of training data.</li>
<li class="calibre15"><strong class="bold">Computational resources</strong>: Training neural<a id="_idIndexMarker623" class="calibre5 pcalibre1 pcalibre"/> networks, particularly deep networks, requires significant computational resources (CPU/GPU power and memory). They also often require a large amount of training data <a id="_idTextAnchor284" class="calibre5 pcalibre1 pcalibre"/>to perform well, which can be a problem when such data are not available.</li>
<li class="calibre15"><strong class="bold">Lack of interpretability</strong>: While not strictly a training issue, the lack of interpretability of neural networks is a significant problem. They are often referred to as “black boxes” because it i<a id="_idTextAnchor285" class="calibre5 pcalibre1 pcalibre"/>s challenging<a id="_idIndexMarker624" class="calibre5 pcalibre1 pcalibre"/> to understand why they are making the predictions they do.</li>
<li class="calibre15"><strong class="bold">Difficulty in selecting appropriate architecture and hyperparameters</strong>: There are many types of neural network architectures to choose from (such as CNN and RNN), and each has a set of hyperparameters that need to be tuned (such as learning rate, batch size, number of layers, and number of units per layer). Selecting the best architecture and tuning these hyperpar<a id="_idTextAnchor286" class="calibre5 pcalibre1 pcalibre"/>ameters for a given problem can be a challenging and time-consuming task.</li>
<li class="calibre15"><strong class="bold">Data preprocessing</strong>: Neural networks often require the input data to be in a specific format. For instance, data might need to be normalized, categorical variables might need to be one-hot encoded, and missing values might need to be imputed. This preprocessing can be a complex and time-consuming step.</li>
</ul>
<p class="calibre6">These challenges make training neural networks<a id="_idIndexMarker625" class="calibre5 pcalibre1 pcalibre"/> a non-trivial task, often requiring a combin<a id="_idTextAnchor287" class="calibre5 pcalibre1 pcalibre"/>ation of technical expertise, computational resources, and trial and error.</p>
<h1 id="_idParaDest-126" class="calibre4"><a id="_idTextAnchor288" class="calibre5 pcalibre1 pcalibre"/>Language models</h1>
<p class="calibre6">A language model is a statistical<a id="_idIndexMarker626" class="calibre5 pcalibre1 pcalibre"/> model in NLP that is designed to learn and understand the structure of human language. More specifically, it is a probabilistic model that is trained to estimate the likelihood of words when provided with a given word scenario. For instance, a language model could be trained to predict the next word in a sentence, given the previous words.</p>
<p class="calibre6">Language models are fundamental to many NLP tasks. They are used in machine translation, speech recognition, part-of-speech tagging, and named entity recognition, among other things. More recently, they have been used to create conversational AI models such as chatbots and personal assistants and to generate human-like text.</p>
<p class="calibre6">Traditional language models were often based on explicitly statistical methods, such as n-gram models, which consider <a id="_idIndexMarker627" class="calibre5 pcalibre1 pcalibre"/>only the previous n words when predicting the next word, or <strong class="bold">hidden Markov </strong><strong class="bold">models</strong> (<strong class="bold">HMMs</strong>).</p>
<p class="calibre6">More recently, neural networks have become popular for creating language models, leading to the rise of neural language models. These models use the power of neural networks to consider the context of each word when making predictions, resulting in higher accuracy and fluency. Examples of neural language models include RNNs, the transformer model, and various transformer-based architectures such as BERT and GPT.</p>
<p class="calibre6">Language models are essential for understanding, generating, and interpreting human language in a computational setting, and they play a vital role in many <a id="_idTextAnchor289" class="calibre5 pcalibre1 pcalibre"/>applications of NLP.</p>
<p class="calibre6">Here are several motivations<a id="_idIndexMarker628" class="calibre5 pcalibre1 pcalibre"/> for using language models:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Machine translation</strong>: Language models are a crucial component in systems that translate text from one language to another. They can assess the fluency o<a id="_idTextAnchor290" class="calibre5 pcalibre1 pcalibre"/>f translated sentences and help choose between multiple possible translations.</li>
<li class="calibre15"><strong class="bold">Speech recognition</strong>: Language models are used in speech recognition systems to help distinguish between words and phrases that sound similar. By predicting what word is like<a id="_idTextAnchor291" class="calibre5 pcalibre1 pcalibre"/>ly to come next in a sentence, they can improve the accuracy of transcription.</li>
<li class="calibre15"><strong class="bold">Information retrieval</strong>: When you search for something on the internet, language models help to determine what documents are relevant to your query. They can under<a id="_idTextAnchor292" class="calibre5 pcalibre1 pcalibre"/>stand the semantic similarity between your search terms and potential results.</li>
<li class="calibre15"><strong class="bold">Text generation</strong>: Language models can generate human-like text, which is useful in various applications such as chatbots, writing assistants, and content creation tools. For example, a chatb<a id="_idTextAnchor293" class="calibre5 pcalibre1 pcalibre"/>ot can use a language model to generate appropriate responses to user queries.</li>
<li class="calibre15"><strong class="bold">Sentiment analysis</strong>: By understanding the structure of language, language models can help determine whether the sentiment of a piece of text is positive, negative, or neutral. This is useful in <a id="_idTextAnchor294" class="calibre5 pcalibre1 pcalibre"/>areas such as social media monitoring, product reviews, and customer feedback.</li>
<li class="calibre15"><strong class="bold">Grammar checking</strong>: Language models can predict what word should come next <a id="_idTextAnchor295" class="calibre5 pcalibre1 pcalibre"/>in a sentence, which can help identify grammatical errors or awkward phrasing.</li>
<li class="calibre15"><strong class="bold">Named entity recognition</strong>: Language models can help identify named entities in text, such as people, organizations, locations, and more. This can b<a id="_idTextAnchor296" class="calibre5 pcalibre1 pcalibre"/>e useful for tasks such as information extraction and automated summarization.</li>
<li class="calibre15"><strong class="bold">Understanding context</strong>: Language models, especially recent models based on <strong class="bold">DL</strong>, such as transformers, are excellent at understanding the context of words and sentences. This capability is vital for many <strong class="bold">NLP</strong> tasks, such as question answering, summarization, and dialogue<a id="_idIndexMarker629" class="calibre5 pcalibre1 pcalibre"/> systems.</li>
</ul>
<p class="calibre6">All these motivations stem from a central theme: language models help machines understand and generate human language more effectively, which is crucial for many applications in today’s data-driven world.</p>
<p class="calibre6">In the following section, we introduce the different types of learning and <a id="_idTextAnchor297" class="calibre5 pcalibre1 pcalibre"/>then explain how one can use self-supervised learning to train language models.</p>
<h2 id="_idParaDest-127" class="calibre7"><a id="_idTextAnchor298" class="calibre5 pcalibre1 pcalibre"/>Semi-supervised learning</h2>
<p class="calibre6">Semi-supervised learning<a id="_idIndexMarker630" class="calibre5 pcalibre1 pcalibre"/> is a type of ML<a id="_idIndexMarker631" class="calibre5 pcalibre1 pcalibre"/> approach that utilizes both labeled and unlabeled data for training. It is particularly useful when you have a small amount of labeled data and a large amount of unlabeled data. The strategy here is to use the labeled data to train an initial model and then use this model to predict labels for the unlabeled data. The model is th<a id="_idTextAnchor299" class="calibre5 pcalibre1 pcalibre"/>en retrained using the newly labeled data, improving its accuracy in the process.</p>
<h2 id="_idParaDest-128" class="calibre7"><a id="_idTextAnchor300" class="calibre5 pcalibre1 pcalibre"/>Unsupervised learning</h2>
<p class="calibre6">Unsupervised learning, on<a id="_idIndexMarker632" class="calibre5 pcalibre1 pcalibre"/> the other<a id="_idIndexMarker633" class="calibre5 pcalibre1 pcalibre"/> hand, involves training models entirely on unlabeled data. The goal here is to find underlying patterns or structures in the data. Unsupervised learning includes techniques such as clustering (where the aim is to group similar instances together) and dimensionality red<a id="_idTextAnchor301" class="calibre5 pcalibre1 pcalibre"/>uction (where the aim is to simplify the data without losing too much information).</p>
<h3 class="calibre8">Using self-supervised learning to train language models</h3>
<p class="calibre6">Self-supervised learning<a id="_idIndexMarker634" class="calibre5 pcalibre1 pcalibre"/> is a form of unsupervised learning<a id="_idIndexMarker635" class="calibre5 pcalibre1 pcalibre"/> where the data provides the supervision. In other words, the model learns to predict certain parts of the input data from other parts of the same input data. It does not require explicit labels provided by humans, hence the term “self-supervised.”</p>
<p class="calibre6">In the context of language models, self-supervision is typically implemented by predicting parts of a sentence when given other parts. For example, given the sentence “The cat is on the __,” the model<a id="_idIndexMarker636" class="calibre5 pcalibre1 pcalibre"/> would be trained<a id="_idIndexMarker637" class="calibre5 pcalibre1 pcalibre"/> to predict the missing word (“mat,” in this case).</p>
<p class="calibre6">Let’s look at a c<a id="_idTextAnchor302" class="calibre5 pcalibre1 pcalibre"/>ouple of popular self-supervised learning strategies for training language models next.</p>
<h4 class="calibre135">Masked language modeling (MLM)</h4>
<p class="calibre6">This strategy, used in the training<a id="_idIndexMarker638" class="calibre5 pcalibre1 pcalibre"/> of BERT, randomly masks some percentage of the input tokens and tasks the model with predicting the masked words based on the context provided by the unmasked words. For instance, in the sentence “The cat is on the mat,” we could mask “cat,” and the model’s job would be to predict this word. Please note that more than one word can also be masked.</p>
<p class="calibre6">Mathematically, the objective of an MLM is to maximize the following likelihood:</p>
<p class="calibre6"><img alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;L&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:munder&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;∑&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:munder&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;;&lt;/mml:mo&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;" src="img/303.png" class="calibre302"/></p>
<p class="calibre6">where <em class="italic">w</em>_i i<a id="_idTextAnchor303" class="calibre5 pcalibre1 pcalibre"/>s a masked word, <em class="italic">w</em>_{-i} are the non-masked words, and <em class="italic">θ</em> represents the model parameters.</p>
<h4 class="calibre135">Autoregressive language modeling</h4>
<p class="calibre6">In autoregressive language modeling, which is used<a id="_idIndexMarker639" class="calibre5 pcalibre1 pcalibre"/> in models such as GPT, the model predicts the next word in a sentence given all the preceding words. It’s trained to maximize the likelihood of a word given its previous words in the sentence.</p>
<p class="calibre6">The objective of an autoregressive language model is to maximize</p>
<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/304.png" class="calibre303"/></p>
<p class="calibre6">where <em class="italic">w_</em>i is the current word, <img alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;-&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" src="img/305.png" class="calibre304"/> are the previous words, and <em class="italic">θ</em> represents the model parameters.</p>
<p class="calibre6">These strategies enable language<a id="_idIndexMarker640" class="calibre5 pcalibre1 pcalibre"/> models to obtain a rich understanding of language syntax and semantics directly from raw text without the need for explicit labels. The models can then be fine-tuned for various tasks such as text classification, sentiment analysis, and more<a id="_idTextAnchor304" class="calibre5 pcalibre1 pcalibre"/>, leveraging the language understanding gained from the self-supervised pretraining phase.</p>
<h2 id="_idParaDest-129" class="calibre7"><a id="_idTextAnchor305" class="calibre5 pcalibre1 pcalibre"/>Transfer learning</h2>
<p class="calibre6">Transfer learning is an ML<a id="_idIndexMarker641" class="calibre5 pcalibre1 pcalibre"/> technique<a id="_idIndexMarker642" class="calibre5 pcalibre1 pcalibre"/> where a pretrained model is reused as the starting point for a different but related problem. Compared to traditional ML approaches, where you start with initializing your model with random weights, transfer learning has the advantage of kick-starting the learning process from patterns that have been learned from a related task, which can both speed up the training process and improve the performance of the model, especially when you have limited labeled training data.</p>
<p class="calibre6">In transfer learning, a model is typically trained on a large-scale task, and then parts of the model are used as a starting point for another task. The large-scale task is often chosen to be broad enough that the learned representations are useful for many different tasks. This process works particularly well when the input data for both tasks are of the same type and the tasks are related.</p>
<p class="calibre6">There are several ways to apply transfer learning, and the best approach can depend on how much data you ha<a id="_idTextAnchor306" class="calibre5 pcalibre1 pcalibre"/>ve for your task and how similar your task is to the original task the model was trained on.</p>
<h3 class="calibre8">Feature extraction</h3>
<p class="calibre6">The pretrained model acts<a id="_idIndexMarker643" class="calibre5 pcalibre1 pcalibre"/> as a feature extractor. You remove the last layer or several layers of the model, leaving the rest of the network intact. Then, you pass your data through this truncated mode<a id="_idTextAnchor307" class="calibre5 pcalibre1 pcalibre"/>l and use the output as input to a new, smaller model that is trained for your specific task.</p>
<h3 class="calibre8">Fine-tuning</h3>
<p class="calibre6">You use the pretrained model as a starting<a id="_idIndexMarker644" class="calibre5 pcalibre1 pcalibre"/> point and update all or some of the model’s parameters for your new task. In other words, you continue the training where it left off, allowing the model to adjust from generic feature extraction to features more specific to your task. Often, a lower learning rate is used during fine-tuning to avoid overwriting the prelearned features entirely during training.</p>
<p class="calibre6">Transfer learning is a powerful technique that can be used to improve the performance of ML models. It is particularly useful for tasks where there are limited labeled data available. It is commonly used in DL applications. For instance, it’s almost a standard in image classification problems where pretrained models on ImageNet, a large-scale annotated image dataset (ResNet, VGG, Inception, and so on), are used as the starting point. The features learned by these models are generic for image classification and can be fine-tuned on a specific image classification task with a smaller amount of data.</p>
<p class="calibre6">Here are some examples<a id="_idIndexMarker645" class="calibre5 pcalibre1 pcalibre"/> of how transfer learning can be used:</p>
<ul class="calibre14">
<li class="calibre15">A model trained to classify images of cats and dogs can be used to fine-tune a model to classify images of other animals, such as birds or fish</li>
<li class="calibre15">A model trained to translate text from English to Spanish can be used to fine-tune a model to translate text from Spanish to French</li>
<li class="calibre15">A model trained to predict the price of a house can be used to fine-tune a model to predict the price of a car</li>
</ul>
<p class="calibre6">Similarly, in natural language processing, large pretrained models, such as BERT or GPT, are often used as the starting <a id="_idIndexMarker646" class="calibre5 pcalibre1 pcalibre"/>point for a wide range of tasks. These models are pretrained on a large corpus of text and learn a rich representation of language that can be fine-tuned f<a id="_idTextAnchor308" class="calibre5 pcalibre1 pcalibre"/>or specific tasks such as text classification, sentiment analysis, question answering, and more.</p>
<h1 id="_idParaDest-130" class="calibre4"><a id="_idTextAnchor309" class="calibre5 pcalibre1 pcalibre"/>Understanding transformers</h1>
<p class="calibre6">Transformers are a type<a id="_idIndexMarker647" class="calibre5 pcalibre1 pcalibre"/> of neural network architecture that was introduced in a paper called <em class="italic">Attention is All You Need</em> by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin (<em class="italic">Advances in neural information processing systems 30</em> (2017),  Harvard). They have been very influential in the field of NLP and have formed the basis for state-of-the-art models such as BERT and GPT.</p>
<p class="calibre6">The key innovation in transformers is the self-attention mechanism, which allows the model to weigh the relevance of each word in the input when producing an output, thereby considering the context of each word. This is unlike previous models such as RNNs or RNNs, which process the input seq<a id="_idTextAnchor310" class="calibre5 pcalibre1 pcalibre"/>uentially and, therefore, have a harder time capturing the long-range dependencies<a id="_idIndexMarker648" class="calibre5 pcalibre1 pcalibre"/> between words.</p>
<h2 id="_idParaDest-131" class="calibre7"><a id="_idTextAnchor311" class="calibre5 pcalibre1 pcalibre"/>Architecture of transformers</h2>
<p class="calibre6">A transformer is composed<a id="_idIndexMarker649" class="calibre5 pcalibre1 pcalibre"/> of an encoder and a decoder, both of which are made up of several identical layers, as shown in <em class="italic">Figure 6</em><em class="italic">.8</em>. Each layer in the encoder contains two sub-layers: a self-attention mechanism and a position-wise fully connected feedforward network. A residual connection is employed around each of the two sub-layers, followed by layer normalization:</p>
<div><div><img alt="Figure 6.8 – Self-attention mechanism" src="img/B18949_06_008.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.8 – Self-attention mechanism</p>
<p class="calibre6">Similarly, each layer in the decoder has three sub-layers. The first is a self-attention layer, the second is a cross-attention layer that attends to the output of the encoder stack, and the third is a position-wise fully connected feedforward network. Like the encoder, each of these sub-layers has a residual connection around it, followed by layer normalization. Please<a id="_idIndexMarker650" class="calibre5 pcalibre1 pcalibre"/> note that in the <a id="_idTextAnchor312" class="calibre5 pcalibre1 pcalibre"/>figure, just one head is being shown, and we can have multiple heads working in parallel (<em class="italic">N</em> heads).</p>
<h3 class="calibre8">Self-attention mechanism</h3>
<p class="calibre6">The self-attention<a id="_idIndexMarker651" class="calibre5 pcalibre1 pcalibre"/> mechanism, or scaled dot-product attention, calculates<a id="_idIndexMarker652" class="calibre5 pcalibre1 pcalibre"/> the relevance<a id="_idIndexMarker653" class="calibre5 pcalibre1 pcalibre"/> of each word in the sequence to the current word being processed. The input to the self-attention layer is a sequence of word embeddings, each of which is split into a <strong class="bold">query</strong> (<em class="italic">Q</em>), a <strong class="bold">key</strong> (<em class="italic">K</em>), and a <strong class="bold">value</strong> (<em class="italic">V</em>) using separately learned linear transformations.</p>
<p class="calibre6">The attention score for each word is then calculated as follows:</p>
<p class="calibre6"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;﻿&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;T&lt;/mi&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;_&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="img/306.png" class="calibre305"/></p>
<p class="calibre6">Where <em class="italic">d_k</em> is the dimensionality of the queries and keys, which is used to scale the dot product to prevent it from growing too large. The softmax operation ensures that the attention scores are normalized and sum to 1. These scores represent the weight given to each word’s value when producing the output for the current word.</p>
<p class="calibre6">The output of the self-attention layer is a new sequence of vectors, where the output for eac<a id="_idTextAnchor313" class="calibre5 pcalibre1 pcalibre"/>h word is a weighted sum of all the input values, with the weights determined by the attention scores.</p>
<h3 class="calibre8">Positional encoding</h3>
<p class="calibre6">Since the self-attention mechanism<a id="_idIndexMarker654" class="calibre5 pcalibre1 pcalibre"/> does not take into<a id="_idIndexMarker655" class="calibre5 pcalibre1 pcalibre"/> account the position of the words in the sequence, the transformer adds a positional encoding to the input embeddings at the bottom of the encoder and decoder stacks. This encoding is a fixed function of the position and allows the model to learn to use the order of the words.</p>
<p class="calibre6">In the original transformer paper, positional encoding is a sinusoidal function o<a id="_idTextAnchor314" class="calibre5 pcalibre1 pcalibre"/>f the position and the dimension, although learned positional encodings<a id="_idIndexMarker656" class="calibre5 pcalibre1 pcalibre"/> have also been<a id="_idIndexMarker657" class="calibre5 pcalibre1 pcalibre"/> used effectively.</p>
<h2 id="_idParaDest-132" class="calibre7"><a id="_idTextAnchor315" class="calibre5 pcalibre1 pcalibre"/>Applications of transformers</h2>
<p class="calibre6">Since their introduction, transformers<a id="_idIndexMarker658" class="calibre5 pcalibre1 pcalibre"/> have been used to achieve state-of-the-art results on a wide range of NLP tasks, including machine translation, text summarization, sentiment analysis, and more. They have also been adapted for other domains, such as computer vision and reinforcement learning.</p>
<p class="calibre6">The introduction of transformers has led to a shift in the NLP field towards pretraining large transformer models on a large corpus of text and then fine-tuning them on specific tasks, which is an effect<a id="_idTextAnchor316" class="calibre5 pcalibre1 pcalibre"/>ive form of transfer learning. This approach has been used in models such as BERT, GPT-2, GPT-3, and GPT-4.</p>
<h1 id="_idParaDest-133" class="calibre4"><a id="_idTextAnchor317" class="calibre5 pcalibre1 pcalibre"/>Learning more about large language models</h1>
<p class="calibre6">Large language models<a id="_idIndexMarker659" class="calibre5 pcalibre1 pcalibre"/> are a class of ML models that have been trained on a broad range of internet text.</p>
<p class="calibre6">The term “large” in “large language models” refers to the number of parameters that these models have. For example, GPT-3 has 175 billion parameters. These models are trained using self-supervised learning on a large corpus of text, which means they predict the next word in a sentence (such as GPT) or a word based on surrounding words (such as BERT, which is also trained to predict whether a pair of sentences is sequential). Because they are exposed to such a large amount of text, these models learn grammar, facts about the world, reasoning abilities, and also biases in the data they’re trained on.</p>
<p class="calibre6">These models are transformer-based, meaning they leverage the transformer architecture, which uses self-attention mechanisms to weigh the importance of words in input data. This architecture allows these models to process long-range dependencies in text, making them very effective for a wide range of NLP tasks.</p>
<p class="calibre6">Large language models can be fine-tuned on specific tasks to achieve high performance. Fine-tuning involves additional training on a smaller, task-specific dataset and allows the model to adapt its general language understanding abilities to the specifics of the task. This approach has been used to achieve state-of-the-art results on many NLP benchmarks.</p>
<p class="calibre6">While large language models have demonstrated impressive abilities, they also raise important challenges. For example, because they’re trained on internet text, they can reproduce and amplify biases present in the data. They can also generate outputs that are harmful or misleading. Additionally, due to their size, these models require significant computational resources to train and deploy, which raises issues around cost and environmental impact.</p>
<p class="calibre6">Despite these challenges, large<a id="_idIndexMarker660" class="calibre5 pcalibre1 pcalibre"/> language models represent a significant advance in the field of AI and are a powerful tool for a wide<a id="_idTextAnchor318" class="calibre5 pcalibre1 pcalibre"/> range of applications, including translation, summarization, content creation, question answering, and more.</p>
<h1 id="_idParaDest-134" class="calibre4"><a id="_idTextAnchor319" class="calibre5 pcalibre1 pcalibre"/>The challenges of training language models</h1>
<p class="calibre6">Training large language mo<a id="_idTextAnchor320" class="calibre5 pcalibre1 pcalibre"/>dels<a id="_idIndexMarker661" class="calibre5 pcalibre1 pcalibre"/> is a complex and resource-intensive task that poses several challenges. Here are some of the key issues:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Computational resources</strong>: The training of large language models requires substantial computational resources. These models have billions of parameters that need to be updated during training, which involves performing a large amount of computation over an extensive dataset. This computation is usually carrie<a id="_idTextAnchor321" class="calibre5 pcalibre1 pcalibre"/>d out on high-performance GPUs or <strong class="bold">tensor processing units</strong> (<strong class="bold">TPUs</strong>), and the costs associated can be prohibitive.</li>
<li class="calibre15"><strong class="bold">Memory limitations</strong>: As the size of the model increases, the amount of memory required to store the model parameters, intermediate activations, and gradients during training also increases. This can lead to memory issues on even the most advanced hardware. Techniques such as model parallelism, gradient checkp<a id="_idTextAnchor322" class="calibre5 pcalibre1 pcalibre"/>ointing, and offloading can be used to mitigate these issues, but they add complexity to the training process.</li>
<li class="calibre15"><strong class="bold">Dataset size and quality</strong>: Large language models are trained on extensive text corpora. Finding, cleaning, and structurally organizing such massive datasets can be challenging. Moreover, the quality of the dataset directly impacts the performance of the model. Since these models l<a id="_idTextAnchor323" class="calibre5 pcalibre1 pcalibre"/>earn from the data they’re trained on, biases or errors in the data can lead to a biased or error-prone model.</li>
<li class="calibre15"><strong class="bold">Overfitting</strong>: While large models have a high capacity to learn complex patterns, they can also be overfitted to the training data, especially when the amount of available data is limited compared to the size of the model. Overfitting leads to poor generalization of unseen data. Re<a id="_idTextAnchor324" class="calibre5 pcalibre1 pcalibre"/>gularization techniques, such as weight decay, dropout, and early stopping, can be used to combat overfitting.</li>
<li class="calibre15"><strong class="bold">Training stability</strong>: As models get larger, stably training them becomes more difficult. The challenges incl<a id="_idTextAnchor325" class="calibre5 pcalibre1 pcalibre"/>ude managing learning rates and batch sizes and dealing with issues such as vanishing or exploding gradients.</li>
<li class="calibre15"><strong class="bold">Evaluation and fine-tuning</strong>: Evaluating the performance of these models can also be challenging due to their size. Moreover, fine-tuning these models on a specific task <a id="_idTextAnchor326" class="calibre5 pcalibre1 pcalibre"/>can be tricky, as it can lead to “catastrophic forgetting,” where the model forgets the pretraining knowledge.</li>
<li class="calibre15"><strong class="bold">Ethical and safety concerns</strong>: Large language models can generate content that is harmful or inappropriate. They can also propagate and amplify biases present in the training data. These issues necessitate the development of robust methods to control<a id="_idIndexMarker662" class="calibre5 pcalibre1 pcalibre"/> the behavior of the model, both during training and at runtime.</li>
</ul>
<p class="calibre6">Despite these challenges, progress continues in the field of large language models. Researchers are <a id="_idTextAnchor327" class="calibre5 pcalibre1 pcalibre"/>developing new strategies to mitigate these issues and to train large models more effectively and responsibly.</p>
<h2 id="_idParaDest-135" class="calibre7">Specific designs of langua<a id="_idTextAnchor328" class="calibre5 pcalibre1 pcalibre"/>ge models</h2>
<p class="calibre6">Here, we are going to explain two popular architectures of language models, BERT and GPT, in detail.</p>
<h3 class="calibre8">BERT</h3>
<p class="calibre6">BERT, which we mentioned<a id="_idIndexMarker663" class="calibre5 pcalibre1 pcalibre"/> already and will <a id="_idIndexMarker664" class="calibre5 pcalibre1 pcalibre"/>now expand on, is a transformer-based ML technique for NLP tasks. It was developed by Google and introduced in a paper by Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova titled <em class="italic">Bert: Pre-training of deep bidirectional transformers for language understanding</em>, arXiv preprint arXiv:1810.04805 (2018).</p>
<p class="calibre6">BERT is designed to pretrain deep bidirectional representations from the unlabeled text by joint conditioning on both left and right contexts in all layers. This is in contrast to previous methods, such as GPT and ELMo, which pretrain text representations from only the left context or from left and right contexts separately.<a id="_idTextAnchor329" class="calibre5 pcalibre1 pcalibre"/> This bi-directionality allows BERT to understand the context and the semantic meaning of a word more accurately.</p>
<h4 class="calibre135">BERT’s design</h4>
<p class="calibre6">BERT is based on the transformer<a id="_idIndexMarker665" class="calibre5 pcalibre1 pcalibre"/> model architecture, which is shown in <em class="italic">Figure 6</em><em class="italic">.8</em>, originally introduced by Vaswani et al. in the paper <em class="italic">Attention is All You Need</em>. The model architecture consists of stacked self-attention and point-wise fully connected layers.</p>
<p class="calibre6">BERT comes in two sizes: <strong class="bold">BERT Base</strong> and <strong class="bold">BERT Large</strong>. BERT Base is composed of 12 transformer<a id="_idIndexMarker666" class="calibre5 pcalibre1 pcalibre"/> layers, each<a id="_idIndexMarker667" class="calibre5 pcalibre1 pcalibre"/> with 12 self-attention heads, and a total of 110 million parameters. BERT Large is much bigger and has 24 transformer layers, each with 16 self-attention heads, for a total of 340 million parameters.</p>
<p class="calibre6">BERT’s training process involves two steps: <strong class="bold">pretraining</strong> and <strong class="bold">fine-tuning</strong>.</p>
<p class="calibre6">The very first step in trai<a id="_idTextAnchor330" class="calibre5 pcalibre1 pcalibre"/>ning or using a language model is to create or load its dictionary. We usually use a tokenizer to achieve this goal.</p>
<h4 class="calibre135">Tokenizer</h4>
<p class="calibre6">In order to use the language<a id="_idIndexMarker668" class="calibre5 pcalibre1 pcalibre"/> models efficiently, we need to use a tokenizer that converts the input<a id="_idIndexMarker669" class="calibre5 pcalibre1 pcalibre"/> text into a limited number<a id="_idIndexMarker670" class="calibre5 pcalibre1 pcalibre"/> of tokens. Subword tokenization algorithms, such as <strong class="bold">byte pair encoding</strong> (<strong class="bold">BPE</strong>), <strong class="bold">unigram language model</strong> (<strong class="bold">ULM</strong>), and <strong class="bold">WordPiece</strong>, split words into smaller<a id="_idIndexMarker671" class="calibre5 pcalibre1 pcalibre"/> subword units. This is useful for handling out-of-vocabulary words and allows the model to learn meaningful representations for subword parts that often carry semantic meaning.</p>
<p class="calibre6">The BERT tokenizer is a critical component of the BERT model, performing the initial preprocessing of text data necessary for input into the model. BERT uses WordPiece tokenization, a subword tokenization algorithm that breaks words into smaller parts, allowing BERT<a id="_idIndexMarker672" class="calibre5 pcalibre1 pcalibre"/> to handle out-of-vocabulary words, reduce the size of the vocabulary, and deal with the richness and diversity of languages.</p>
<p class="calibre6">Here’s a detailed breakdown of how the BERT tokenizer works:</p>
<ol class="calibre16">
<li class="calibre15"><strong class="bold">Basic tokenization</strong>: First, the BERT tokenizer performs basic tokenization, breaking text into individual words by splitting on whitespace and punctuation. This is similar to what you might find in other tokenization methods.</li>
<li class="calibre15"><strong class="bold">WordPiece tokenization</strong>: After basic tokenization, the BERT tokenizer applies WordPiece tokenization. This step breaks words into smaller subword units or “WordPieces.” If a word isn’t in the BERT vocabulary, the tokenizer will iteratively break the word down into smaller sub words until it finds a match in the vocabulary or until it has to resort to character-level representation.<p class="calibre6">For example, the word “unhappiness” might be broken down into two WordPieces: “un” and “##happiness”. The “##” symbol is used to denote sub-words that are part of a larger word and not a whole word on their own.</p></li>
<li class="calibre15"><strong class="bold">Special tokens addition</strong>: The <strong class="bold">BERT</strong> tokenizer then adds special tokens necessary for specific <strong class="bold">BERT</strong> functionalities. The [<strong class="source-inline1">CLS</strong>] token is appended at the beginning of each sentence, serving as an aggregate representation for classification tasks. The [<strong class="source-inline1">SEP</strong>] token is added at the end of each sentence to signify sentence boundaries. If two sentences are inputted (for tasks that require sentence pairs), they are separated by this [<strong class="source-inline1">SEP</strong>] token.</li>
<li class="calibre15"><strong class="bold">Token to ID conversion</strong>: Finally, each token is mapped to an integer ID corresponding to its index in the <strong class="bold">BERT</strong> vocabulary. These IDs are what the <strong class="bold">BERT</strong> model actually uses as input.</li>
</ol>
<p class="calibre6">So, in summary, the BERT tokenizer works by first tokenizing the text into words, then further breaking these words down into WordPieces (if necessary), adding special tokens, and finally converting these tokens into IDs. This process allows the model to understand and generate<a id="_idIndexMarker673" class="calibre5 pcalibre1 pcalibre"/> meaningful re<a id="_idTextAnchor331" class="calibre5 pcalibre1 pcalibre"/>presentations for a wide variety of words and sub-words, contributing to BERT’s powerful performance on various NLP tasks.</p>
<h4 class="calibre135">Pretraining</h4>
<p class="calibre6">During pretraining, <strong class="bold">BERT</strong> was trained on a large<a id="_idIndexMarker674" class="calibre5 pcalibre1 pcalibre"/> corpus of text (the entire English Wikipedia and BooksCorpus are used in the original paper). The model was trained to predict masked words in a sentence (masked language model) and to distinguish whether two sentences come in order in the text (next sentence prediction), as explained here:</p>
<ul class="calibre14">
<li class="calibre15"><strong class="bold">Masked language model</strong>: In this task, 15% of the words in a sentence are replaced by a [<strong class="source-inline1">MASK</strong>] token, and the model is trained to predict the original word from the context provided by the non-masked words.</li>
<li class="calibre15"><strong class="bold">Next sentence prediction</strong>: When the model is<a id="_idTextAnchor332" class="calibre5 pcalibre1 pcalibre"/> given a pair of two sentences, it is also trained to predict whether sentence <em class="italic">B</em> is the next sentence following sentence <em class="italic">A</em>.</li>
</ul>
<h4 class="calibre135">Fine-tuning</h4>
<p class="calibre6">After pretraining, BERT<a id="_idIndexMarker675" class="calibre5 pcalibre1 pcalibre"/> can be fine-tuned on a specific task with a significantly smaller amount of training data. Fine-tuning involves adding an additional output layer to BERT and training the entire model end-to-end on the specific task. This approach has been shown to achieve state-of-the-art results on a wide range of NLP tasks, including question answering, named entity recognition, sentiment analysis, and more.</p>
<p class="calibre6">BERT’s design<a id="_idIndexMarker676" class="calibre5 pcalibre1 pcalibre"/> and its pretraining/fine-tuning approach revolutionized the field of NL<a id="_idTextAnchor333" class="calibre5 pcalibre1 pcalibre"/>P and have led to a shift toward training large models on a broad range of data and then fine-tuning them on specific tasks.</p>
<h4 class="calibre135">How to fine-tune BERT for text classification</h4>
<p class="calibre6">As mentioned, BERT has been pretrained<a id="_idIndexMarker677" class="calibre5 pcalibre1 pcalibre"/> on a large corpus of text data, and the learned<a id="_idIndexMarker678" class="calibre5 pcalibre1 pcalibre"/> representations can be fine-tuned for <a id="_idTextAnchor334" class="calibre5 pcalibre1 pcalibre"/>specific tasks, including text classification. Here is a step-by-step process on how to fine-tune BERT for text classification:</p>
<ol class="calibre16">
<li class="calibre15"><strong class="bold">Preprocessing input data</strong>: BERT requires a specific format for input data. The sentences need to be tokenized into sub-words using BERT’s own tokenizer, and special tokens such as [CLS] (classification) and [SEP] (separation) need to be added. The [CLS] token is added at the beginning of each example and is used as the aggregate sequence representation for classification tasks. The [SEP] token is added at t<a id="_idTextAnchor335" class="calibre5 pcalibre1 pcalibre"/>he end of each sentence to denote sentence boundaries. All sequences are then padded to a fixed length to form a uniform input.</li>
<li class="calibre15"><strong class="bold">Loading the pretrained BERT model</strong>: BERT has several pretrained models, and the right one should be chosen based on the task at hand. The models differ in terms of the size of the model and the language of the pretrain<a id="_idTextAnchor336" class="calibre5 pcalibre1 pcalibre"/>ing data. Once the pretrained BERT model is loaded, it can be used to create contextualized word embeddings for the input data.</li>
<li class="calibre15"><strong class="bold">Adding a classification layer</strong>: A classification layer, also known as the classification head, is added<a id="_idIndexMarker679" class="calibre5 pcalibre1 pcalibre"/> on top of the pretrained BERT model. This layer will be trained to make predictions for the text classification task. Usually, this layer is a fully connected neural network layer th<a id="_idTextAnchor337" class="calibre5 pcalibre1 pcalibre"/>at takes the representation corresponding to the [CLS] token as input and outputs the probability distribution over the classes.</li>
<li class="calibre15"><strong class="bold">Fine-tuning the model</strong>: Fine-tuning involves training the model on the specific task (in this case, text classification) using the labeled data. This process can be done in multiple ways. The more common approach is to update the weights of the pretrained BERT model and the newly added classification layer to minimize a loss function, typically the cross-entropy loss for classification tasks. It is important to use a lower learning rate during fine-tuning, as larger rates can destabilize the prelearned weights. Additionally, the number of recommended epochs is two to four, so the model learns the task but does not overfit. The benefit of this approach is that the model weights will be adj<a id="_idTextAnchor338" class="calibre5 pcalibre1 pcalibre"/>usted to perform well on specific tasks. Alternatively, we can freeze BERT layers and just update the classifier layer weights.</li>
<li class="calibre15"><strong class="bold">Evaluating the model</strong>: Once the model has been fine-tuned, it can be evaluated on a validation set to assess its performance. This involves calculating metrics such as accuracy, precision, recall,<a id="_idTextAnchor339" class="calibre5 pcalibre1 pcalibre"/> and F1 score. During the training and evaluation task, similar to other ML and DL models, we can perform hyperparameter tuning.</li>
<li class="calibre15"><strong class="bold">Applying the model</strong>: The fine-tuned model can now be used to make predictions on new, unseen text data. As with the training data, this new data also need to be preprocessed into the format that BERT expects.</li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">Note that working with <strong class="bold">BERT</strong> requires considerable computational resources, as the model has a large number of parameters. A GPU is typically recommended for fine-tuning and applying BERT models. There are some models that are lighter than BERT with slightly lower performance, such as DistilBERT, that we can use in the case of being constrained by the computation or memory resources. Additionally, BERT is able to process 512 tokens, which limits the length of our input text. If we want to process longer text, Longformer or BigBird are good choices. What we explained here works for similar language models such as RoBERTa, XLNet, and so on.</p>
<p class="calibre6">In summary, fine-tuning<a id="_idIndexMarker680" class="calibre5 pcalibre1 pcalibre"/> BERT<a id="_idIndexMarker681" class="calibre5 pcalibre1 pcalibre"/> for text classification involves preprocessing the input data, loading the pretrained BERT model, adding a classification layer, fine-tuning the model on the labeled data, and then evaluating<a id="_idIndexMarker682" class="calibre5 pcalibre1 pcalibre"/> and applying<a id="_idIndexMarker683" class="calibre5 pcalibre1 pcalibre"/> the model.</p>
<p class="calibre6">We will demonstrate the preceding paradigm of fine-tuning <a id="_idTextAnchor340" class="calibre5 pcalibre1 pcalibre"/>BERT and then apply it at the end of this chapter. You will have the opportunity to employ it firsthand and adjust it to your needs.</p>
<h3 class="calibre8">GPT-3</h3>
<p class="calibre6"><strong class="bold">GPT-3</strong>, short for <strong class="bold">generative</strong><strong class="bold"><a id="_idIndexMarker684" class="calibre5 pcalibre1 pcalibre"/></strong><strong class="bold"> pretrained transformer 3</strong>, is an<a id="_idIndexMarker685" class="calibre5 pcalibre1 pcalibre"/> autoregressive language model developed by OpenAI that uses DL techniques to generate human-like text. It is the third version of the GPT series. <a id="_idTextAnchor341" class="calibre5 pcalibre1 pcalibre"/>The GPT versions that followed it, GPT-3.5 and GPT-4, will be covered in the next chapter, as we will expand on large language models.</p>
<h4 class="calibre135">Design and architecture of GPT-3</h4>
<p class="calibre6">GPT-3 extends the transformer<a id="_idIndexMarker686" class="calibre5 pcalibre1 pcalibre"/> model architecture<a id="_idIndexMarker687" class="calibre5 pcalibre1 pcalibre"/> used by its predecessors. The architecture is based on a transformer model that uses layers of transformer blocks, where each block is composed of self-attention and feedforward neural network layers.</p>
<p class="calibre6">GPT-3 is massive compared to the previous versions. It consists of 175 billion ML parameters. These parameters are learned during the training phase, where the model learns to predict the next word in a sequence of words.</p>
<p class="calibre6">GPT-3’s transformer model is designed to process sequences of data (in this case, sequences of words or tokens in text), making it well-suited for language tasks. It processes input data sequentially from left to right and generates predictions for the next item in the sequence. This is the difference between BERT and GPT, where, in BERT, words from both sides are used <a id="_idTextAnchor342" class="calibre5 pcalibre1 pcalibre"/>to predict masked words, but in GPT, just the previous words are used for prediction, which makes it a good choice for generative tasks.</p>
<h4 class="calibre135">Pretraining <a id="_idTextAnchor343" class="calibre5 pcalibre1 pcalibre"/>and fine-tuning</h4>
<p class="calibre6">Similar to BERT and<a id="_idIndexMarker688" class="calibre5 pcalibre1 pcalibre"/> other transformer-based<a id="_idIndexMarker689" class="calibre5 pcalibre1 pcalibre"/> models, GPT-3 also involves a two-step process: <strong class="bold">pretraining</strong> and <strong class="bold">fine-tuning</strong>.</p>
<h4 class="calibre135">Pretraining</h4>
<p class="calibre6">In this phase, GPT-3 is trained<a id="_idIndexMarker690" class="calibre5 pcalibre1 pcalibre"/> on a large corpus of text data. It learns to predict the next word in a sentence. However, un<a id="_idTextAnchor344" class="calibre5 pcalibre1 pcalibre"/>like BERT, which uses a bidirectional context for prediction, GPT-3 only uses the left context (i.e., the previous words in the sentence).</p>
<h4 class="calibre135">Fine-tuning</h4>
<p class="calibre6">After the pretraining <a id="_idIndexMarker691" class="calibre5 pcalibre1 pcalibre"/>phase, GPT-3 can be fine-tuned on a specific task using a smaller amount of <a id="_idTextAnchor345" class="calibre5 pcalibre1 pcalibre"/>task-specific training data. This could be any NLP task, such as text completion, translation, summarization, question answering, and so on.</p>
<h4 class="calibre135">Zero-shot, one-shot, and few-shot learning</h4>
<p class="calibre6">One of the impressive features<a id="_idIndexMarker692" class="calibre5 pcalibre1 pcalibre"/> of GPT-3 is its <a id="_idIndexMarker693" class="calibre5 pcalibre1 pcalibre"/>capability to perform few-shot learning. When given a task and a few examples of that task, GPT-3 can often learn to perform the task accurately.</p>
<p class="calibre6">In the zero-shot setting, the model<a id="_idIndexMarker694" class="calibre5 pcalibre1 pcalibre"/> is given a task wit<a id="_idTextAnchor346" class="calibre5 pcalibre1 pcalibre"/>hout any prior examples. In the one-shot setting, it’s given one example, and in the few-shot setting, it’s given a few examples to learn from.</p>
<h1 id="_idParaDest-136" class="calibre4"><a id="_idTextAnchor347" class="calibre5 pcalibre1 pcalibre"/>Challenges of using GPT-3</h1>
<p class="calibre6">Despite its impressive<a id="_idIndexMarker695" class="calibre5 pcalibre1 pcalibre"/> capabilities, GPT-3 also presents some challenges. Due to its large size, it requires substantial computational resources to train. It can sometimes generate incorrect or nonsensical responses, and it can reflect biases present in the training d<a id="_idTextAnchor348" class="calibre5 pcalibre1 pcalibre"/>ata. It also struggles with tasks that require a deep understanding of the world or common sense reasoning beyond what can be learned from text.</p>
<h2 id="_idParaDest-137" class="calibre7"><a id="_idTextAnchor349" class="calibre5 pcalibre1 pcalibre"/>Reviewing our use case – ML/DL system design for NLP classification in a Jupyter Notebook</h2>
<p class="calibre6">In this section, we are going to work<a id="_idIndexMarker696" class="calibre5 pcalibre1 pcalibre"/> on a real-world problem and see how we can use an NLP pipeline to solve it. The code for this pa<a id="_idTextAnchor350" class="calibre5 pcalibre1 pcalibre"/>rt is shared as a Google Colab notebook at <a href="https://colab.research.google.com/drive/1HVD2fvxHup6OsPi2mKxNS_nfCRZ0iGCw?usp=sharing" class="calibre5 pcalibre1 pcalibre">Ch6_Text_Classification_DL.ipynb</a>.</p>
<h2 id="_idParaDest-138" class="calibre7"><a id="_idTextAnchor351" class="calibre5 pcalibre1 pcalibre"/>The business objective</h2>
<p class="calibre6">In this scenario, we are<a id="_idIndexMarker697" class="calibre5 pcalibre1 pcalibre"/> in the healthca<a id="_idTextAnchor352" class="calibre5 pcalibre1 pcalibre"/>re sector. Our objective is to develop a general medical knowledge engine that is very up to date with recent findings in the world of healthcare.</p>
<h2 id="_idParaDest-139" class="calibre7"><a id="_idTextAnchor353" class="calibre5 pcalibre1 pcalibre"/>The technical objective</h2>
<p class="calibre6">The CTO derives several technical objectives<a id="_idIndexMarker698" class="calibre5 pcalibre1 pcalibre"/> from the business objective. One objective is for the ML team: given the growing collection of conclusions that correspond to medica<a id="_idTextAnchor354" class="calibre5 pcalibre1 pcalibre"/>l publications, identify the ones that represent advice. This will allow us to identify the medical advice that stems from the underlying research.</p>
<h2 id="_idParaDest-140" class="calibre7"><a id="_idTextAnchor355" class="calibre5 pcalibre1 pcalibre"/>The pipeline</h2>
<p class="calibre6">Let’s review the parts<a id="_idIndexMarker699" class="calibre5 pcalibre1 pcalibre"/> of the pipeline, as depicted in <em class="italic">Figure 6</em><em class="italic">.9</em>:</p>
<div><div><img alt="Figure 6.9 – The structure of a typical exploration and model pipeline﻿" src="img/B18949_06_009.jpg" class="calibre3"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.9 – The structure of a typical exploration and model pipeline</p>
<p class="calibre6">Notice how this design is different from the design we saw in <em class="italic">Figure 5</em><em class="italic">.2</em>. There, the exploration and evaluation parts leverage the same feature engineering technique that is later used by the ML models. Here, with LMs, feature engineering is not a part of the preparation for the modeling. The pretrained model, and particularly the tokenizer, performs feature engineering, which yields very different and less interpretable features than the binary, BoW, or TF-IDF features.</p>
<p class="callout-heading">Note</p>
<p class="callout">Code parts: From “Settings” through “Generating Results of the Traditional ML Models.<a id="_idTextAnchor356" class="calibre5 pcalibre1 pcalibre"/>”</p>
<p class="calibre6">These parts are identical in their nature <a id="_idIndexMarker700" class="calibre5 pcalibre1 pcalibre"/>to the analog parts discussed in <a href="B18949_05_split_000.xhtml#_idTextAnchor130" class="calibre5 pcalibre1 pcalibre"><em class="italic">Chapter 5</em></a>. The only differences relate to the differences in the data.</p>
<h3 class="calibre8">Deep learning</h3>
<p class="calibre6">In this part of the code, we employ<a id="_idIndexMarker701" class="calibre5 pcalibre1 pcalibre"/> a deep learning<a id="_idIndexMarker702" class="calibre5 pcalibre1 pcalibre"/> language model.</p>
<p class="calibre6">When looking to apply transfer learning via LMs and fine-tuning them per our objective and data, there are several stacks to choose from. The ones that stand out the most are Google’s TensorFlow, and Meta’s PyTorch. A package called <strong class="bold">Transformers</strong> was built as a wrapper<a id="_idIndexMarker703" class="calibre5 pcalibre1 pcalibre"/> around these stacks to allow for a simpler implementation of the code. In this example, we leverage the simplicity and richness of transformers models.</p>
<p class="calibre6">It is worth highlighting the company that built and supports the Transformers package: Hugging Face. Hugging Face took it upon themselves to create an entire ecosystem around the collection and sharing of free, open source DL models, which includes the many components that accommodate for implementing these models. The most actionable tool is the Transformers package, which is a Python package dedicated to picking, importing, training, and employing a large and growing set of DL models.</p>
<p class="calibre6">The<a id="_idTextAnchor357" class="calibre5 pcalibre1 pcalibre"/> code we are reviewing<a id="_idIndexMarker704" class="calibre5 pcalibre1 pcalibre"/> here provides more than just<a id="_idIndexMarker705" class="calibre5 pcalibre1 pcalibre"/> an example of ML/DL system design in the real world; it also showcases Hugging F<a id="_idTextAnchor358" class="calibre5 pcalibre1 pcalibre"/>ace’s Transformers.</p>
<h3 class="calibre8">Formatting the data</h3>
<p class="calibre6">Here, we set the data up in a format<a id="_idIndexMarker706" class="calibre5 pcalibre1 pcalibre"/> that suits the Transformers library. The column names must be very specific.</p>
<h3 class="calibre8">Evaluation metric</h3>
<p class="calibre6">We decided which metric<a id="_idIndexMarker707" class="calibre5 pcalibre1 pcalibre"/> we wished to optimize and plugged it into the training process. For this prob<a id="_idTextAnchor359" class="calibre5 pcalibre1 pcalibre"/>lem of binary classification, we optimized for accuracy and evaluated our result<a id="_idIndexMarker708" class="calibre5 pcalibre1 pcalibre"/> in comparison to the dataset’s baseline accuracy, also known as the prior.</p>
<h3 class="calibre8">Trainer object</h3>
<p class="calibre6">This is the core object<a id="_idIndexMarker709" class="calibre5 pcalibre1 pcalibre"/> for training<a id="_idIndexMarker710" class="calibre5 pcalibre1 pcalibre"/> the LM in Transformers. It holds a set of predefined configurations. Some of the key training configurations are the following:</p>
<ul class="calibre14">
<li class="calibre15">The neural net’s mathematical<a id="_idIndexMarker711" class="calibre5 pcalibre1 pcalibre"/> learning hyperparameters, such the following:<ul class="calibre17"><li class="calibre15">The learning rate</li><li class="calibre15">The gradient decent settings</li></ul></li>
<li class="calibre15">The <a id="_idTextAnchor360" class="calibre5 pcalibre1 pcalibre"/>number of training epochs</li>
<li class="calibre15">The computation hardware usage</li>
<li class="calibre15">Logging setting for capturing<a id="_idIndexMarker712" class="calibre5 pcalibre1 pcalibre"/> the progression of the objective metric throughout the<a id="_idIndexMarker713" class="calibre5 pcalibre1 pcalibre"/> training process</li>
</ul>
<h4 class="calibre135">Fine-tuning the neural network parameters</h4>
<p class="calibre6">The fundamental concept<a id="_idIndexMarker714" class="calibre5 pcalibre1 pcalibre"/> around fine-tuning LMs<a id="_idIndexMarker715" class="calibre5 pcalibre1 pcalibre"/> is transfer learning. Neural networks lend themselves so well to transfer learning because one can simply strip any number of layers from the end of the structure and replace them with untrained layers that would be trained based on the underlying problem. The rest of the layers that weren’t removed and aren’t trained continue to operate exactly in the same way they did when the LM was originally trained (when it was originally built). If we replace the last layer but leave the rest of the original layers, then we could view those layers as supervised feature engineering or, conversely, as an embedding mechanism. This trait reflects the concept of transfer learning. Ideally, the model is expected to lend itself well to our underlying problem so that we will choose to keep the vast majority of the original layers, and only a small minority would be replaced and trained. In this way, a large DL model that took many weeks to be pretrained can be transferred and adapted to a new problem in minutes.</p>
<p class="calibre6">In our code, we set the model up in a way that we dictate exactly which of its layers we are looking to fine-tune. It is a design choice for us for this to be based on performance and also computation resources. One choice is to fine-tune the last layer right before the final<a id="_idIndexMarker716" class="calibre5 pcalibre1 pcalibre"/> output, also known as the classification head. The alternative is to fine-tune all the layers. In our code, we explicitly call the model’s configuration, which controls which layer is fine-tuned, so the code can be changed in any way that suits the design.</p>
<p class="calibre6">We configure the trainer to log the performance of the training in real time. It prints those logs out for us in a table so we can observe and monitor them. When the training is complete, we plot the progress of the training and the evaluation. This helps us see the relation between the evolution of the training results and the evaluation results. Since the <a id="_idTextAnchor361" class="calibre5 pcalibre1 pcalibre"/>evaluation set that the trainer uses can be viewed as a held-out set in the context of the trainer, this plot allows us to investigate underfitting and overfitting.</p>
<h4 class="calibre135">Generating the training results – used for design choices</h4>
<p class="calibre6">We reviewed the results of the training<a id="_idIndexMarker717" class="calibre5 pcalibre1 pcalibre"/> set, along with the logs that the trainer printed out. We compared them to the baseline accuracy and observed an increase in accuracy. We learned about the quality of our design by iterating over several different design choices and comparing them. That process of iterating over many sets of design parameters would be automated into code to allow for a systematic evaluation of the optimal setting. We did<a id="_idTextAnchor362" class="calibre5 pcalibre1 pcalibre"/>n’t do that in our notebook just to keep things simple in the example. Once we believed we had found the optimal setting, we could say that the process was finished.</p>
<h4 class="calibre135">Generating the testing results – used for presenting performance</h4>
<p class="calibre6">As with the code in <a href="B18949_05_split_000.xhtml#_idTextAnchor130" class="calibre5 pcalibre1 pcalibre"><em class="italic">Chapter 5</em></a>, here, too, we finished<a id="_idIndexMarker718" class="calibre5 pcalibre1 pcalibre"/> by reviewing the test results. It is worth noting the difference between the evaluation set and the test set. One could suggest that since the trainer doesn’t use the evaluation set for training, it could be used as a held-out test set, thus saving the need to exclude so many observations from training and supplying the model with more labeled data. However, while the trainer didn’t use the evaluation set, we did use it to make our design decisions. For instance, we observed the plot from the preceding section and judged which number of epochs is optimal to achieve optimal fit<a id="_idTextAnchor363" class="calibre5 pcalibre1 pcalibre"/>ting. In <a href="B18949_05_split_000.xhtml#_idTextAnchor130" class="calibre5 pcalibre1 pcalibre"><em class="italic">Chapter 5</em></a>, an evaluation set was used too, but we didn’t need to explicitly define it; it was carried out as a part of the K-fold cross-validation mechanism.</p>
<h1 id="_idParaDest-141" class="calibre4"><a id="_idTextAnchor364" class="calibre5 pcalibre1 pcalibre"/>Summary</h1>
<p class="calibre6">In this enlightening chapter, we embarked on a comprehensive exploration of DL and its remarkable application to text classification tasks through language models. We began with an overview of DL, revealing its profound ability to learn complex patterns from vast amounts of data and its indisputable role in advancing state-of-the-art NLP systems.</p>
<p class="calibre6">We then delved into the transformative world of transformer models, which have revolutionized NLP by providing an effective alternative to traditional RNNs and CNNs for processing sequence data. By unpacking the attention mechanism—a key feature in transformers—we highlighted its capacity to focus on different parts of the input sequence, hence facilitating a better understanding of context.</p>
<p class="calibre6">Our journey continued with an in-depth exploration of the BERT model. We detailed its architecture, emphasizing its pioneering use of bidirectional training to generate contextually rich word embeddings, and we highlighted its pretraining process, which learns language semantics from a large text corpus.</p>
<p class="calibre6">However, our exploration did not end there; we also introduced GPT, another transformative model that leverages the power of transformers in a slightly different way—focusing on generating human-like text. By comparing BERT and GPT, we shed light on their distinct strengths and use cases.</p>
<p class="calibre6">The chapter culminated in a practical guide on how to design and implement a text classification model using these advanced models. We walked you through all the stages of this process, from data preprocessing and model configuration to training, evaluation, and finally, making predictions on unseen data.</p>
<p class="calibre6">In essence, this chapter provided a well-rounded understanding of DL in NLP, transitioning from fundamental principles to hands-on applications. With this knowledge, you are now equipped to leverage the capabilities of transformer models, BERT, and GPT for your text classification tasks. Whether you are looking to delve further into the world of NLP or apply these skills in a practical setting, this chapter has equipped you with a firm foundation on which to build.</p>
<p class="calibre6">In this chapter, we introduced you to large language models. In the next chapter, we dive deeper into these models to learn more about them.</p>
</div>
</body></html>