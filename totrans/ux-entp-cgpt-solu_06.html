<html><head></head><body>
		<div><h1 id="_idParaDest-108" class="chapter-number"><a id="_idTextAnchor108" class="pcalibre pcalibre1 calibre6"/>5</h1>
			<h1 id="_idParaDest-109" class="calibre5"><a id="_idTextAnchor109" class="pcalibre pcalibre1 calibre6"/>Defining the  Desired Experience</h1>
			<p class="calibre3">To define the desired experience, the first decision is which experiences demand attention. This is the prioritization discussion started in the last chapter. Knowing where these use cases are to appear helps with scope, planning, and follow-through. Some require building traditional conversational experiences; shockingly, these can be called classic now! Others will use channels (such as Slack, Teams, or a web experience) that can handle interactive elements, such as GUI components. Some will extend features within existing channels to include LLMs in the workflow to solve a limited use case. That last one is a powerful incremental approach. Others will build single-purpose bots or voice-only interfaces. Each of these experiences has unique and general considerations.</p>
			<p class="calibre3">This chapter will cover the highest-priority enterprise user experiences one can develop with ChatGPT, along with three overarching design elements: accessibility, internationalization, and trust. Get ready for the following topics:</p>
			<ul class="calibre7">
				<li class="calibre8">Designing chat experiences</li>
				<li class="calibre8">Designing hybrid UI/chat experiences</li>
				<li class="calibre8">Creating voice-only experiences</li>
				<li class="calibre8">Designing a recommender and behind-the-scenes experiences</li>
				<li class="calibre8">Overarching considerations</li>
			</ul>
			<h1 id="_idParaDest-110" class="calibre5"><a id="_idTextAnchor110" class="pcalibre pcalibre1 calibre6"/>Designing chat experiences</h1>
			<p class="calibre3">An LLM-powered chat<a id="_idIndexMarker254" class="pcalibre pcalibre1 calibre6"/> experience comes in a few flavors: a straight chat-only experience, such as OpenAI’s chat UI, or a chat window that is part of a more extensive GUI experience. Each has unique issues, and both have a collection of issues to address. A traditional chat-only experience is an excellent place to start.</p>
			<h2 id="_idParaDest-111" class="calibre9"><a id="_idTextAnchor111" class="pcalibre pcalibre1 calibre6"/>Chat-only experiences</h2>
			<p class="calibre3">Many, if not most, readers will <a id="_idIndexMarker255" class="pcalibre pcalibre1 calibre6"/>have this use case: a conversational experience backed with a ChatGPT solution. It might support a traditional conversational AI platform (Salesforce, Oracle’s Digital Assistant, Alexa, Google Assistant, or one of the dozens of other vendors) or eventually replace them. However, the primary interaction is via a chat window with chat responses. This means the channel SMS (text messaging), WhatsApp, WeChat, Facebook, LinkedIn, a web experience, Slack, Teams, or other services depend on the technology those channels support for integrations, backend services, security, and user experience.</p>
			<p class="calibre3">This example chat experience, as shown in <em class="italic">Figure 5</em><em class="italic">.1</em>, is direct from OpenAI’s UI:</p>
			<div><div><img src="img/B21964_05_01.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.1 – A traditional chat UI from OpenAI</p>
			<p class="calibre3">It is typical to have a message input area with a <strong class="bold">Submit</strong> button, a single-threaded discussion, the ability to download the discussion, and visual affordance for the customer input and the AI response. It is more robust than most because, as an authenticated user, it keeps track of previous conversations, which is a nice touch. It has room because it is a whole browser window and is mobile-friendly. An enterprise experience will likely embed a chat framework into a website, portal, or app. Some UIs include features such as file attachment, clearing the field, or closing or moving the window.</p>
			<p class="calibre3">OpenAI’s iPhone client <a id="_idIndexMarker256" class="pcalibre pcalibre1 calibre6"/>has one nice UX feature similar to what was introduced at Oracle: scrolling only a little for long answers. Working with Kevin Mullet, we coined the problem “over-scrolling.” The window should <strong class="bold">not</strong> scroll to the end of the response when the AI returns a message longer than the window size. If this happens, the user must scroll backward to find where the message started and then scroll forward to read. This is a headache for accessibility and just annoying for everyone else. As in <em class="italic">Figure 5</em><em class="italic">.2,</em> the first chunk of a message in the OpenAI mobile UI is returned with the arrow. The entire message is returned once the user clicks the arrow, so the user still has to return to where they left off. They almost got it right!</p>
			<div><div><img src="img/B21964_05_02.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.2 – The OpenAI chat message is sent (left), then pauses when the window is full (center). Clicking the continue arrow shows the entire message (right)</p>
			<p class="calibre3">See whether your chat client is smart enough with long messages. Does the scroll bar grow, but the screen doesn’t scroll as additional details are still not yet exposed? Can the user read messages in one scrolling motion, starting from the beginning of the response? <em class="italic">All chat UIs should have support for over-scrolling</em>. Slack, for example, shows a <strong class="bold">missed messages</strong> button, so it will take the user to where they last left the conversation. This is another good <strong class="bold">micro-interaction</strong> pattern for solving this problem and relieving users from the stress of not knowing what they missed.</p>
			<p class="calibre3">When designing a chat <a id="_idIndexMarker257" class="pcalibre pcalibre1 calibre6"/>experience, consider all these micro-interactions and the elements needed to be exposed. Micro-interactions are those small but critical elements that make UI moments seamless and enjoyable. It can be as simple as the button changing color when hovering the mouse over it, giving an affordance that it can be clicked, or the typing indicator to help anticipate the arrival of a message from a friend. They can be used to update the user on system status, encourage behaviors to avoid error, reinforce brand identity, drive the user to a specific task or engagement, or improve the interaction. They are generally very lightweight, following a “less is more” approach. Consider these when creating the UIs, recommenders, or how ChatGPT responds, provides next steps, or interacts with services. A user can enjoy a little delight from a micro-interaction. These are the basics. Here is a little deeper journey.</p>
			<p class="calibre3">Article: <a href="https://www.interaction-design.org/literature/article/micro-interactions-ux" class="pcalibre pcalibre1 calibre6">The Role of Micro-interactions in Modern UX</a> (<a href="https://www.interaction-design.org/literature/article/micro-interactions-ux" class="pcalibre pcalibre1 calibre6">https://www.interaction-design.org/literature/article/micro-interactions-ux</a>)</p>
			<p class="calibre3">If the plan is to integrate ChatGPT into<a id="_idIndexMarker258" class="pcalibre pcalibre1 calibre6"/> an existing chat UI, some basics should be in the original chat experience. Covering a few basics next can’t hurt.</p>
			<h2 id="_idParaDest-112" class="calibre9"><a id="_idTextAnchor112" class="pcalibre pcalibre1 calibre6"/>Integrating ChatGPT into an existing chat experience</h2>
			<p class="calibre3">Consider whether ChatGPT is the primary mechanism for customer interaction and what other services and data would support it. In the enterprise space, there is something unique and valuable inside the data. The goal is not to repackage the existing ChatGPT service while emphasizing the user experience. What should be considered when integrating ChatGPT into chat? How should it be done? Let’s explore the options:</p>
			<ul class="calibre7">
				<li class="calibre8">Use a simple chat window with ChatGPT as the primary actor with knowledge indexed using <strong class="bold">Retrieval Augmented Generation</strong> (<strong class="bold">RAG</strong>) (RAG is covered in <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content is King</em>) or other services <a id="_idIndexMarker259" class="pcalibre pcalibre1 calibre6"/>linked to database integration or interfaces with other company services.</li>
				<li class="calibre8">Supplement an existing Chat “Bot” experience. Enhance the existing deterministic flows (wizards or chat flows) with ChatGPT to improve comprehension, entity recognition, world language support, image recognition, or other abilities.</li>
				<li class="calibre8">Supplement human agent experiences by gathering data or solving problems before being handed off to a human. This is to make the agent more efficient or to provide additional services, marketing, or feedback.</li>
				<li class="calibre8">ChatGPT is used after a human agent has experience handling confidential information, surveys, or feedback.</li>
				<li class="calibre8">Using ChatGPT<a id="_idIndexMarker260" class="pcalibre pcalibre1 calibre6"/> as a third party in a human conversation (an AI team assistant, supporting an agent, a user, or a team). This can be used as a resource in a group setting. Consider any security implications, where the requestor might have permission to access some data while other members might not.</li>
				<li class="calibre8">Use different LLMs and prompts to support pieces of workflows. Chaining models to improve model output from the previous steps is common and will be covered extensively in the following chapters.</li>
			</ul>
			<p class="calibre3">This list can’t be exhaustive. The growth rate of creative use for LLMs is exploding. But all of them, if they are going to be chat-centric, have some basic functionality one would expect. The existing chat UI could be ready for some enhanced components.</p>
			<h2 id="_idParaDest-113" class="calibre9"><a id="_idTextAnchor113" class="pcalibre pcalibre1 calibre6"/>Enabling components for a chat experience</h2>
			<p class="calibre3">With a chat window, there is a decision point for what features make sense to support the interactions in the chat window. Most of these elements would be the same if the chat were between two humans or a human and an LLM. However, many developers need to be guided by a suitable set of features:</p>
			<ul class="calibre7">
				<li class="calibre8">Message input window (the typing window for input)</li>
				<li class="calibre8">Threaded response area (the conversation)</li>
				<li class="calibre8">Submit button (to send a message and attachment)</li>
				<li class="calibre8">Visual indicators for the message owner: bubbles, avatars, left/right alignment, and so on (something is required)</li>
				<li class="calibre8">Accessibility compliance: screen reader support, keyboard navigation, alt text for images, high contrast mode, and so on</li>
				<li class="calibre8">Optional components to<a id="_idIndexMarker261" class="pcalibre pcalibre1 calibre6"/> enhance the overall experience:<ul class="calibre19"><li class="calibre8">Download, Print, Export, Clear, and Close (when applicable)</li><li class="calibre8">Timestamps (as needed and used intelligently; only timestamp some messages)</li><li class="calibre8">A movable window</li><li class="calibre8">Previous message history</li><li class="calibre8">Short-cut suggestions that appear to help finish a thought or action</li><li class="calibre8">Search in the thread (supported by browsers, consider for applications)</li><li class="calibre8">Support for not over-scrolling</li><li class="calibre8">Help, tours, or tutorials</li><li class="calibre8">An emoji picker</li><li class="calibre8">Short-cut panels (useful for professional users to quickly insert popular items or fill in common commands and statements)</li><li class="calibre8">The ability to escalate to an agent (for support use cases, typically done online in the chat or with a button)</li><li class="calibre8">Customer feedback (optional as a UI element; also supported in chat)</li><li class="calibre8">Omni-channel integration (so other channels have this context)</li><li class="calibre8">Typing indicator (recommended if a multi-user UI is used; less critical if the session is only with ChatGPT since it should reply immediately)</li></ul></li>
			</ul>
			<p class="calibre3">A good experience will <a id="_idIndexMarker262" class="pcalibre pcalibre1 calibre6"/>consider all these options but only implement some. Consider the importance of each requirement. Use the <strong class="bold">Weighted Shortest Job First</strong> (<strong class="bold">WSJF</strong>) score introduced in <a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 4</em></a><em class="italic">, Scoring Stories,</em> to decide what part of these requirements<a id="_idIndexMarker263" class="pcalibre pcalibre1 calibre6"/> are needed. Look at the use case and score these options. A few of these are more valuable than others. And other than links and maybe images, there is very little richness from a <em class="italic">chat-only</em> experience. Handling links and images is covered in the next section on hybrid UIs.</p>
			<h2 id="_idParaDest-114" class="calibre9"><a id="_idTextAnchor114" class="pcalibre pcalibre1 calibre6"/>Designing hybrid UI/chat experiences</h2>
			<p class="calibre3"><strong class="bold">Hybrid UIs</strong> combine <a id="_idIndexMarker264" class="pcalibre pcalibre1 calibre6"/>chat with a traditional GUI. This experience can include forms, tables, or interactive elements in a chat stream or merge chat into an existing GUI. Sometimes, chat is in its panel using the graphical UX as content to interact conversationally with the data. Examples like this have been available over the years, but the power of LLMs allows for more robust and accurate interactions. These multi-modal experiences can blend GUIs, voice, speech-to-text, text-to-speech, and LLMs into one solution.</p>
			<p class="calibre3">This is the latest version of <strong class="bold">Rich Internet Application</strong> (<strong class="bold">RIA</strong>), coined around 2002 at Macromedia. I read a paper by Kevin <a id="_idIndexMarker265" class="pcalibre pcalibre1 calibre6"/>Mullet (written for Macromedia) and found it shockingly consistent with today’s experience.</p>
			<p class="calibre3">Article: <a href="https://darmano.typepad.com/for_blog/essence_of_ria.pdf" class="pcalibre pcalibre1 calibre6">The Essence of Effective Rich Internet Applications</a> (<a href="https://darmano.typepad.com/for_blog/essence_of_ria.pdf" class="pcalibre pcalibre1 calibre6">https://darmano.typepad.com/for_blog/essence_of_ria.pdf</a>)</p>
			<p class="author-quote">In software design, the complexities of interactive control remain the most significant impediment to a satisfying user experience. – Kevin Mullet (The Essence of Effective Rich Internet Applications)</p>
			<p class="calibre3">The images in the article are outdated, but the underlying problems are still the same, with a few new concepts (voice and LLMs) added to the mix. While much has changed, much has stayed the same.</p>
			<p class="calibre3">For example, the functionality of the Microsoft Word <strong class="bold">Format</strong> menu is mostly unchanged, as shown in <em class="italic">Figure 5</em><em class="italic">.3</em>. The underlying problems of finding and using the breadth of Word’s features haven’t changed and have barely improved in decades. We bring this up because of the well-understood use cases found in Word.</p>
			<div><div><img src="img/B21964_05_03.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Similarity between the circa 2003 Windows (left) and 2024 Macintosh (right) Format menu</p>
			<p class="calibre3">The exciting part about applying AI to Word is that the user’s needs should be well known. The most valuable use cases should be easy to determine (but might be hard to realize). It is up to the product people to understand customers’ pain points, recognize the LLM’s value, and see a path forward.</p>
			<p class="calibre3">Getting an order right in a drive-through ordering system is challenging. I am constantly reminded to check the bag before leaving a restaurant. A modern version for solving complex auditory conditions and ordering problems is a multi-modal solution for a drive-through experience from SoundHound. The customer speaks the order; the screen confirms and validates the order with AI audio responses. This demo shows the power of multi-modal interactions. At the time of this video, it did not use an LLM, but it is impressive because of the speed of multi-modal interactions. The display updates at a drive-up kiosk as fast as the user speaks and displays order corrections. <em class="italic">Figure 5</em><em class="italic">.4</em> is a screenshot from the SoundHound ordering demo.</p>
			<div><div><img src="img/B21964_05_04.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Screenshot from the SoundHound ordering demo</p>
			<p class="calibre3">Video: <a href="https://www.soundhound.com/voice-ai-solutions/restaurant-food-ordering/" class="pcalibre pcalibre1 calibre6">Restaurant ordering via voice</a> (<a href="https://www.soundhound.com/voice-ai-solutions/restaurant-food-ordering/" class="pcalibre pcalibre1 calibre6">https://www.soundhound.com/voice-ai-solutions/restaurant-food-ordering/</a>)</p>
			<p class="calibre3">Voice is the input and the display updates with changes. At walk-up kiosks, touch can supplement voice interactions, interchangeably interacting via touch and speech. At the same time, the conversation goes on without turn-taking (you<a id="_idIndexMarker266" class="pcalibre pcalibre1 calibre6"/> can interject in the speech output and don’t have to wait for a pause in conversation). It is a fascinating application because it affords the restaurant more flexibility in language understanding and better feedback for the user as they see their order and can change it. More direct experiences like this are coming, where typing (or voice) directly supports interactions with the interface, including on desktop and mobile apps. As voice interactions become faster for the LLM (in the 10s millisecond response time range), they are fast enough to be natural, pause, or interrupt, just like humans.</p>
			<p class="calibre3">Another exciting application of ChatGPT is to supplement and support the interaction experience for creating content. Suppose the use cases include writing emails, generating marketing materials, or writing job descriptions. In that case, you can get a big leg up by gathering and using the material created to develop the next piece of content. For example, an intelligent assistant accessing all the material on a screen can provide many supportive capabilities. With a wealth of quality vetted material, new material can be trained to be in the style and tone of the existing material. Or, with one change to a prompt, an entirely new tone can be developed, but still based on the expertise and content supplied.</p>
			<p class="calibre3">The classic example for defining the design space for an application is the integration of generative AI with <em class="italic">deterministic</em> models to fill in forms or perform tasks. The current crop of chat assistants is based on coding for specific tasks, with specific responses, predictable behavior, and limited flexibility. These straightforward deterministic experiences work well for repetitive tasks with predictable inputs and outputs. However, they have gaps, typically with complex integrations, interactions not accounted for in the coding, and the need for many languages. These platforms are being reworked with LLM integration to address these shortcomings. Many assistants faced some real challenges around natural language processing <a id="_idIndexMarker267" class="pcalibre pcalibre1 calibre6"/>and recognition. A design can unlock additional value by combining a GUI’s visual nature and precise communication abilities with LLM understanding. <em class="italic">Figure 5</em><em class="italic">.5</em> shows a simulated example of a chat experience with a GUI.</p>
			<div><div><img src="img/B21964_05_05.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Filling out a hybrid UX with conversational intelligence</p>
			<p class="calibre3">This UI appears to be a simple form, but it is in a chat window. A customer interacts with the form or by chatting. In the middle screen, the user typed (or used voice) entering input to manipulate the form. The form was updated on the right, the error was removed, and a message was returned. An LLM can contribute intelligence on how to parse these messages better than traditional chatbot software. They can also be used to quickly adapt the UIs to support more languages than are typically backed by vendors using their internal training models. The current models, such as ChatGPT 4o-mini, continue to improve in these areas.</p>
			<p class="calibre3">I want to point out a few micro-interactions that appeared in <em class="italic">Figure 5</em><em class="italic">.5</em>:</p>
			<ul class="calibre7">
				<li class="calibre8">The AI understands<a id="_idIndexMarker268" class="pcalibre pcalibre1 calibre6"/> the missing or misunderstood information in the submitted expense or receipt scan (prior to this screen, it would have triggered this response) and presents the errors with a traditional in-line error message. In the future, I could see the LLM asking the user to visually mark something on the receipt that it didn’t understand (e.g., circling a number it didn’t understand and asking for help). This could drive a workflow for improvement without significantly burdening the user. Don’t turn customers into testers, but sometimes you need all the help you can get.</li>
				<li class="calibre8">The form clearly shows what is missing and allows the user to edit with text, voice, or interaction with the form (the keyboard is hidden for this mockup).</li>
				<li class="calibre8">The AI understood “Saturday” as the previous Saturday and entered the information in the correct format, avoiding opening the calendar, viewing, picking the month, and clicking on the date.</li>
				<li class="calibre8">The UI is dynamically updated, acknowledges the added data, removes missing details and errors, and allows users to submit with a button or text.</li>
			</ul>
			<p class="calibre3">So, in this hybrid GUI example, ChatGPT can do a lot to interpret the user input format and submit it as the correct fields. Imagine doing this entire interaction without receipt scanning and no form. It would be very tedious and slow. The system and GUI patterns did some heavy lifting to create the complete experience. Similar flows using existing chat platforms might already be in production. Still, they could use assistance in understanding human language, distinguishing entities (specific elements, such as names, businesses, and values), and expanding language support. ChatGPT can enhance and improve these parts of the experience without throwing out the existing intelligence and expertise built up in designing these business-critical tasks.</p>
			<p class="calibre3">In addition, scanning a meal receipt in the flow might be an additional area for improvement. Training visual foundation models to understand images of business documents and classify and extract critical information from them seems like a whole world for organizations to explore. Many companies already use AI for expense receipts, invoices, bills, quality control images, counting and determining inventory, disaster scenes, and car insurance. The quality of these processes will go up with more advanced models. This book focuses on ChatGPT’s textual and written abilities. However, I encourage exploring image-based use cases when they apply. Models such as ChatGPT 4o-mini can handle images as well (the model can classify images uploaded, for example), and by integrating with other services such as OpenAI’s Whisper,  transcribed audio can be pulled into a workflow.</p>
			<p class="calibre3">Integrating ChatGPT into a workflow is fundamental today. In another example, the product might support writing emails or content for a website. Adding a <strong class="bold">Generate Post</strong> or <strong class="bold">Write Description</strong> button and having ChatGPT gather the information and inject the copy into an existing window is not too hard. One gotcha: <em class="italic">always support the editing of this material before submitting it</em>. It might be inaccurate, too specific, or not specific enough based on the content used in generation. Consider also capturing the suggestion and the final submitted (and edited) version that the human changed. Use this as data to help improve the model. The difference between this and the previous marketing content example is that deciding what has ground truth is essential. With the marketing content, what is good content is known, and it can be supplemented with field data on how well customers responded to different campaigns. When writing emails or website content, it might be more challenging to identify high-quality writing to train the model. Otherwise, a generic model will only be provided based on its original training; sometimes, that is fine. You can always ask the model to adapt the language. Even the generic 40-mini can-do tasks like this.</p>
			<p class="calibre3">Write a thank-you to my</p>
			<p class="calibre3">customer in less than 100 words.</p>
			<pre class="source-code">
Dear Frank Jones,
Thank you for your recent purchase! Your support means a lot to us, and we are thrilled to have you as a valued customer. If you have any questions or need further assistance, please don't hesitate to reach out. We look forward to serving you again soon.
Best regards,
Richard Miller
Alligiance</pre>			<p class="calibre3">Re-write it in a more</p>
			<p class="calibre3">casual tone, he is family.</p>
			<pre class="source-code">
Hey Frank,
Thanks a bunch for your recent purchase! It means a lot to us. If you have any questions or need anything, just give me a shout. Looking forward to catching up soon.
Cheers,
Richard
Alligiance</pre>			<p class="calibre3">Suppose the use case requires a sidebar experience where AI can supplement a traditional UI. It could start as a glorified intelligent search, but this can be leveraged to quickly gain previously buried or unavailable insight from current content. It might have an <strong class="bold">Analyze</strong> button (or generate some recommendations automatically), know what has happened in the thread, provide a <strong class="bold">Generate a Reply</strong> option or do tasks that any human assistant might do to help a team member. Each application will have its use cases, just like any enterprise company in automotive, education, financials, manufacturing, healthcare, government, real estate, sales, service, and a dozen other verticals. Companies that provide enterprise software have a head start because they can work with and adapt complex components.</p>
			<p class="calibre3">Oracle’s Digital Assistant does an excellent job of advancing the state of the art, as shown in <em class="italic">Figure 5</em><em class="italic">.6</em>, with a sidebar experience.</p>
			<div><div><img src="img/B21964_05_06.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.6 – Oracle’s Digital Assistant sidebar inside Oracle Sales</p>
			<p class="calibre3">This shows how a traditional web enterprise application can be supplemented with a conversational generative AI based on understanding the page’s context and all the related data. The demo <a id="_idIndexMarker269" class="pcalibre pcalibre1 calibre6"/>goes into other details, but the point is that existing services can be supplemented with an LLM. Check out the Oracle demo, which starts at 46 minutes and shows how the co-pilot pattern can work embedded with an existing UI.</p>
			<p class="calibre3">Video: <a href="https://www.youtube.com/watch?v=9CEfru54Oyw" class="pcalibre pcalibre1 calibre6">A generative AI co-pilot feature in a GUI</a> by Oracle (<a href="https://www.youtube.com/watch?v=9CEfru54Oyw" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=9CEfru54Oyw</a>) </p>
			<p class="calibre3">Besides providing insight, consider interactions with the sidebar that can influence or address problems. In the preceding example, the chat is used to supplement the experience with issues related to the customer, as shown in the dashboard. This page has a wealth of context so that conversational AI could offer proactive suggestions based on the evaluation of the data.</p>
			<p class="calibre3">For example, the team is building a sales enablement page that reviews customer accounts and deals. In that case, the sidebar can allow questions about this customer that might be buried in other systems or offer recommendations for the next step in the process. Order status, customer care experience, open trouble tickets, and additional customer history information offer value when on the sales page. However, exposing the generative AI as a resource supplements the common understanding with these details. But don’t stop there; use hyperlinks to wrap the text so they can drill down into the enterprise data to further their understanding. Allow the customer to use the generative AI to enhance their editing, posting updates, or drilling down further into insights held by all of this information. Help the user understand the scope of the options the user has at this point. Sometimes, buttons such as <strong class="bold">Edit</strong>, <strong class="bold">Open Details</strong>, <strong class="bold">Send Email,</strong> or <strong class="bold">Change Status</strong> are used. Whatever the use cases, consider going deeper into exploiting generative AI models to enhance these steps.</p>
			<p class="calibre3">This focus on creating<a id="_idIndexMarker270" class="pcalibre pcalibre1 calibre6"/> the desired experience by addressing ChatGPT’s unique complexities can’t cover all UX design guidelines for GUIs. There are dozens of books and websites available. Focus on the fact that UX design within a conversational experience is slightly different. While you might have a traditional web form (with fields and drop menus) in a GUI, what would make that different when placed into a conversational experience? For example, in the <strong class="bold">Oracle Digital Assistant</strong> (<strong class="bold">ODA</strong>) example shown in <em class="italic">Figure 5</em><em class="italic">.6</em>, notice<a id="_idIndexMarker271" class="pcalibre pcalibre1 calibre6"/> a small table in the chat and a very different table on the main page. It is easy to realize that a chat form factor table can’t handle everything a big table can do. Let’s review some essential tips to consider when designing hybrid conversational experiences.</p>
			<h2 id="_idParaDest-115" class="calibre9"><a id="_idTextAnchor115" class="pcalibre pcalibre1 calibre6"/>Chat window size and location</h2>
			<p class="calibre3">Chat windows are typically <a id="_idIndexMarker272" class="pcalibre pcalibre1 calibre6"/>vertically oriented and small on web pages, so the main page can still be used. Depending on the target window size, a typical default chat window can take up 11% to 25% of the screen real estate (and less for folks with two monitors). The example in <em class="italic">Figure 5</em><em class="italic">.7</em> is based on standard desktop screen sizes for August 2024. This data changes very slowly. Changes in the last year varied by less than one percent.</p>
			<div><div><img src="img/B21964_05_07.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Comparison of desktop screen resolutions to a typical chat window (August 2024)</p>
			<p class="calibre3">Article: <a href="https://gs.statcounter.com/screen-resolution-stats/desktop/worldwide" class="pcalibre pcalibre1 calibre6">Current Desktop addressable sizes</a> (<a href="https://gs.statcounter.com/screen-resolution-stats/desktop/worldwide" class="pcalibre pcalibre1 calibre6">https://gs.statcounter.com/screen-resolution-stats/desktop/worldwide</a>)</p>
			<p class="calibre3">It would be best to examine customer data to get a more accurate estimate of screen resolutions. I used to run this analysis every year or so to influence all kinds of web application design decisions. Enterprise customers’ screens were always significantly larger than in consumer data.</p>
			<p class="calibre3">If the primary experience is chat, such as Slack or Teams, size constraints are not an issue on the desktop. There is <a id="_idIndexMarker273" class="pcalibre pcalibre1 calibre6"/>room for large tables, maps, and good-sized images, forms, and other interactive experiences. For those where chat is a secondary element, provide enough space to support necessary interactions but not so big as to interfere with the primary windows. There is no one-size-fits-all answer. Consider the use cases; the less complex the cases, the less space is needed.</p>
			<p class="calibre3">Text-only seems to work fine for the phones of the world, with roughly only 40 characters across (as customers increase font size for accessibility, this number goes down). And the context of use is essential. If the customers are mobile, the width of typical phones or even their specific phone is known (from web analytics). Don’t try to do anything else on the screen along with the chat. Horizontal scroll bars should only be used with extreme caution. If it is in a window, consider notifying the user that they have unread messages while away from the chat. Review examples of unread message interactions on any social media platform (LinkedIn, Facebook, Instagram, etc.).</p>
			<p class="calibre3">One last example for desktop experiences (web or native). Look at the demographics of users and their browser sizes and desktop sizes (web logging tools such as Adobe Analytics or Google Analytics report this information). Use this to decide how much space the user typically needs for the main application window and how much real estate can be shared with the chat window. Consider the responsiveness of the application window. The ability of the main content window to support good flow and <a id="_idIndexMarker274" class="pcalibre pcalibre1 calibre6"/>even a mobile-friendly view (even on the desktop) allows support for a sidebar view, knowing that the main content can adapt.</p>
			<p class="calibre3">A list of objects is one of the most relevant patterns in enterprise applications that need a lot of space. Sometimes, in tables or card views. We can now address how a chat experience impacts tables.</p>
			<h2 id="_idParaDest-116" class="calibre9"><a id="_idTextAnchor116" class="pcalibre pcalibre1 calibre6"/>Tables</h2>
			<p class="calibre3">Consider the mobile experience’s design<a id="_idIndexMarker275" class="pcalibre pcalibre1 calibre6"/> space when considering what is done in a typical chat window. Tables in desktop windows need to be adapted to a narrower chat width. Either use a different layout or limit the number of columns. For example, email on a desktop is in columns, as in <em class="italic">Figure 5</em><em class="italic">.8</em>, while on a phone, a card view is displayed, as in <em class="italic">Figure 5</em><em class="italic">.9</em>. If the model will return cards for results or small tables, realize more room is needed to present comprehensive information directly.</p>
			<div><div><img src="img/B21964_05_08.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.8 – A traditional table view won’t work well in a small chat window</p>
			<div><div><img src="img/B21964_05_09.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.9 – A card view would work in a chat window</p>
			<p class="calibre3">Consider format and content when presenting tables. Models such as ChatGPT 4o-mini (the “o” is for Omni, so I guess they think it knows everything) are very good at formatting data. However, a mobile user will still have the same window size issues as those in pre-ChatGPT experiences. And because this has a scrolling window, scroll bars show up. But never have double scroll bars. While a scroll bar would be fine on the desktop, use a next function to show more data since there is already one scroll bar in the scrolling window. Or find another alternative. If an existing table component is mobile-friendly, it might automatically adjust to a card view in the tight confines of the chat panel. It all depends on how <a id="_idIndexMarker276" class="pcalibre pcalibre1 calibre6"/>the model models support the user experience. If the chat from OpenAI is the UI, there is no option to create richer interactive experiences. If the team owns the client, the world is your oyster, and call on OpenAI models to fill in the pieces to create rich experiences. Even with recommender UIs, there are places to provide feedback for the recommender to make more refined decisions. Prompt the user for information to fill in the blanks in the model’s understanding to improve the results. This is on your plate, not the AIs. <em class="italic">Figure 5</em><em class="italic">.10</em> compares the traditional table format with a poorly implemented horizontal scroll bar. By changing the prompt to provide the results in a more mobile-friendly format, we get more readable (but less comparable) data.</p>
			<div><div><img src="img/B21964_05_10.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.10 – A table view (left and center) compared to a mobile-friendly list view (right)</p>
			<p class="calibre3">The horizontal scroll bar is not even in view (and when scrolling, as shown in the middle pane, the player’s name <a id="_idIndexMarker277" class="pcalibre pcalibre1 calibre6"/>will scroll off-screen; it is not frozen or locked like in a spreadsheet), making analysis hard and the right-most columns impossible to associate with the player. Try prompts such as this on ChatGPT, use a phone, or resize the browser window to the smallest size possible, and try to review and use the table data:</p>
			<pre class="source-code">
Show me a list of the top NFL passers in 2022 and their statistics in a table
Show me a list of the top NFL passers and their statistics, and link the name of the player to their Wikipedia page</pre>			<p class="calibre3">Consider the use cases, how the data should be best presented, and the channel in which the user absorbs the results. Links in the table allow the user to dive further into the data. This is typical on a web display of data. Understand that they might already have interactive richness on the traditional website.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If more room is needed and there is more room (e.g., if in a small chat window in a larger desktop window), build the ability to expand the window. Consider opening the table in a new window if a table-heavy use case demands it. It is possible to identify that the data isn’t fitting in the space and offer the user a way to see it all, such as sending a file, opening the data in a new window, or other innovative solutions.</p>
			<p class="calibre3">As for the table content, please keep it to a minimum. Summarize tables and support drill-downs. To interact with one of the results, consider how to select it and expand the details. Does it make sense to bring that object into a main browser window, where there is plenty of room, or expand the details in the conversation? There is no one correct answer. Let the use case guide you. In the preceding example with American football statistics, a robust experience around table data could have links on data to drill into details, columns that can be sorted, or access to richer analytics on<a id="_idIndexMarker278" class="pcalibre pcalibre1 calibre6"/> players’ names and teams. There are lots of options to explore.  Unfortunately, the tools and patterns that the enterprise supports might be limited. Always remember the end state so improvements and new patterns can be prioritized for the chat channel. Editing in a form (and, more recently, in tables) is fundamental to enterprise interactions with data and tasks. A drill down into forms helps us understand some of the complexities when done within a chat experience.</p>
			<h2 id="_idParaDest-117" class="calibre9"><a id="_idTextAnchor117" class="pcalibre pcalibre1 calibre6"/>Forms</h2>
			<p class="calibre3">Fortunately, if created for a mobile-friendly experience, most forms are ready for a chat experience. Only a few customizations should be considered.</p>
			<p class="calibre3">First, consider how big the<a id="_idIndexMarker279" class="pcalibre pcalibre1 calibre6"/> form is now. Can it fit in a chat window? Does it need many pages of fields to be filled out? A crazy long form might not do well in a chat experience. Then, consider what happens when the form is submitted. Since the chat should persist, what does the form look like after submission? I usually suggest converting it to a card. This transition serves as an affordance to the form that was submitted. Also, it is essential to consider when mistakes are made and how the user can re-edit the information. Like including an <strong class="bold">Edit</strong> button or link to return to the form, make the change, and then save, returning to the card view. As a little preview of <a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 9</em></a><em class="italic">, Guidelines and Heuristics</em>, supporting the edit affordance and undo are two items that should be addressed in a heuristic evaluation. That chapter<em class="italic"> </em>will dive deep into using heuristics to understand and classify user experience issues.</p>
			<p class="calibre3">Recall the Starbucks expense in the expense assistant example. After “Submit this expense,” as in <em class="italic">Figure 5</em><em class="italic">.11</em>, should the user continue to see the editable form in the chat’s history?</p>
			<div><div><img src="img/B21964_05_11.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.11 – Using visual affordances to turn a submitted expense into a card</p>
			<p class="calibre3">A traditional GUI <a id="_idIndexMarker280" class="pcalibre pcalibre1 calibre6"/>would remove the edited form when submitting the expense item. So, persisting this editing view conversationally also doesn’t make sense. Disabling the form is one option, but using the <strong class="bold">Cancel</strong> option at the top of the image on the right and updating the existing form to the submitted expense version is better. This ability to revisit and edit existing items on the chat history might be a challenge, depending on the ownership of the chat window technology. With a card display, the content looks finalized; it will feel complete. To edit it further, the AI should allow that conversationally or consider a button. Notice the <strong class="bold">Edit</strong> icon on the meal in <em class="italic">Figure 5</em><em class="italic">.11</em>. Editing conversationally before submitting the entire expense report, including this single expense, is allowed.</p>
			<p class="calibre3">Also, consider form elements that are robust or complex, such as a search experience. One component in the form might want to use space allowed by the width or height of the chat window. For example, searching for a product name sometimes product names can take a long time in the enterprise. Consider wrapping the results to a second line instead of truncating. The problem with truncating on a mobile phone or small window is that it is hard to show the full name. And if a few items differ only by the last few<a id="_idIndexMarker281" class="pcalibre pcalibre1 calibre6"/> characters, how would a customer tell them apart? This isn’t specific to LLMs; it is just a good design for small windows, such as <strong class="bold">Chat</strong>.</p>
			<p class="calibre3">For example, if they are looking for a product demo to download and search for <code>Agile Product Lifecycle</code>, which returns two products, it would be impossible to tell them apart if the search results were in a small window or drop menu and truncated:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Agile Product </strong><strong class="bold">Lifecycle Management…</strong></li>
				<li class="calibre8"><strong class="bold">Agile Product </strong><strong class="bold">Lifecycle Management…</strong></li>
			</ul>
			<p class="calibre3">If the full text of the items is wrapped, they can select the correct one:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Agile Product </strong><strong class="bold">Lifecycle Management</strong><p class="calibre3"><strong class="bold">Integration Pack for Lavasoft </strong><strong class="bold">E-Business Suite</strong></p></li>
				<li class="calibre8"><strong class="bold">Agile Product </strong><strong class="bold">Lifecycle Management</strong><p class="calibre3"><strong class="bold">Integration Pack for Fission </strong><strong class="bold">Application Suite</strong></p></li>
			</ul>
			<p class="calibre3">So, consider how this small viewing area impacts components. If components are already mobile-friendly, then most of the problems are solved. However, there is still a difference between components <em class="italic">built</em> for a small screen and those <em class="italic">designed</em> for a small screen. The truncation problem I just shared is far too common.</p>
			<p class="calibre3">The last consideration is how to interact with the form or card when conversing. Let’s look again at the form and card concept shown in <em class="italic">Figure 5</em><em class="italic">.12</em>.</p>
			<div><div><img src="img/B21964_05_12.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.12 – The form and card views when starting to edit conversationally</p>
			<p class="calibre3">If the user enters <code>Change the amount to $9.45</code>, does the amount element in the existing form update (left example), or do they have to re-render a new form and hopefully remove or hide the now old and<a id="_idIndexMarker282" class="pcalibre pcalibre1 calibre6"/> incorrect form or card? <em class="italic">Don’t show the wrong information to the user</em>, and updating the card with a visual micro-interaction might be better than scrolling another form onto the screen. The micro-interaction could be a twinkle and an animation showing the amount changing and maybe the message updating. Then, the user saves scrolling through the entire screen to invalidate the old form and create the new form. There is no need to show old or multiple editable forms in the history. Showing errors on an old form when the information is corrected is a terrible look.</p>
			<p class="calibre3">With the form submitted and a card appearing, update the card directly with a twinkle and animation and update the text to show the change is accepted. These patterns are not readily available on any platform. It is fair to point out that conversational interaction<a id="_idIndexMarker283" class="pcalibre pcalibre1 calibre6"/> patterns are still immature. Many kinds of interactions will need to be invented, tested, and matured.</p>
			<p class="calibre3">Let’s summarize:</p>
			<ul class="calibre7">
				<li class="calibre8">Make forms sensitive to the edit via text or direct edit.</li>
				<li class="calibre8">Use a card to show the completed state of the object.</li>
				<li class="calibre8">It is unnecessary to show all the information from the form on the card. Consider how important it is for the user to recognize (and not recall) that this object has an invisible element.</li>
				<li class="calibre8">Consider whether the use cases require editing everything in the chat AI. Some objects are complex and would be hard to edit conversationally, and the form would also be massive. There are use cases here that a larger viewable area might best serve.</li>
				<li class="calibre8">Create a mechanism for complete components to work in the tiny chat window confines for the parts of use cases that make sense.</li>
				<li class="calibre8">Allow for conversational edits of the form and how to update the card or form with those edits.</li>
				<li class="calibre8">Don’t show forms in the wrong state.</li>
				<li class="calibre8">If making direct changes to a card or form, use an affordance to highlight the change.</li>
			</ul>
			<p class="calibre3">Sometimes, a form is used to generate a chart. Now, let’s cover a few critical ideas around using charts in ChatGPT solution.</p>
			<h2 id="_idParaDest-118" class="calibre9"><a id="_idTextAnchor118" class="pcalibre pcalibre1 calibre6"/>Charts</h2>
			<p class="calibre3">A chart presented in enterprise use cases should be interactive when displayed for exploration. Selecting and drilling into a data point, viewing more details, or exploring data segments to answer a different question is all within reason. This is similar to our discussion about tables. The accessible version of a chart is typically a table, so it should<a id="_idIndexMarker284" class="pcalibre pcalibre1 calibre6"/> follow the same conventions. Conversational analytics requires charts to be more than static images; not every toolkit can support this. Consider the context for the chart so conversational interactions might tease new insights from what is presented, such as <code>Show me the breakdown of the 1st quarter by salesperson</code>. The chart is a steppingstone to further the conversation with the LLM.</p>
			<p class="calibre3">For example, consider the axes. Don’t default to a scale or unit the customer doesn’t want: <code>Show me the sales in Euros, not dollars</code>, or <code>Set the salary axis starting at zero and change the range to the last five years</code>. Conversing with data gets complex.</p>
			<p class="calibre3">If the user explicitly asks for a chart, give it to them, but a more innovative experience could be providing them with a chart because it makes sense. Suppose the LLM knows the user is visually impaired (because it was told or from profile information). In that case, showing a chart without the ability to show the data in a table is a problem because the screen readers will have an easier time with a table than a chart (but I suspect LLMs will be solving this as well). <code>Change the table to a chart</code> would be a logical response if the AI didn’t realize the user’s abilities. This knowledge might be used to drive subsequent interactions. Accessibility considerations will also be covered later, but it is helpful to keep accessibility concerns in mind.</p>
			<p class="calibre3">When presenting these charts, one should consider what charts and design elements should be used. There is a wealth of bad charts, including not starting an axis at zero, rotating labels, using excessive colors, not using redundant coding for colored bars, lack of labels, too many pie slices, misusing line charts, and many other fails. The basic chart should also be designed, or the LLM should craft it from instructions. If this is new to you, ask ChatGPT for advice:</p>
			<pre class="source-code">
What are some UX failures when it comes to designing charts and graphs?
Explain the top 10 ways to make charts and graphics high-quality.
How does an LLM decide to design a chart when asked for data?</pre>			<p class="calibre3">Currently, only the paid versions of ChatGPT allow charts to be created, but that won’t be an issue for enterprise customers. Interacting with data is more interesting than just presenting static charts, which only tend to drive more questions than answers. And not to mention asking ChatGPT questions about the data that the chart might not reveal. Making data (and thus charts) conversationally interactive will be a massive space for enterprise use cases. Knowing how to design exceptional visuals is critical to effective communication. And being able to generate conversational insights from data is likely more important. The instructions provided to the LLM must instill some of that expertise if the results don’t match expectations. To explore the fundamentals of effective chart design, read the collection of Edward Tufte’s classic books linked on the reference page.</p>
			<p class="calibre3">Books: <a href="https://uxdforai.com/references#C13" class="pcalibre pcalibre1 calibre6">The work of Edward Tufte</a> (<a href="https://uxdforai.com/references#C13" class="pcalibre pcalibre1 calibre6">https://uxdforai.com/references</a>#Tufte)</p>
			<p class="calibre3"> Now that we have dabbled in charts, it also makes sense to talk about static images.</p>
			<h2 id="_idParaDest-119" class="calibre9"><a id="_idTextAnchor119" class="pcalibre pcalibre1 calibre6"/>Graphics and images</h2>
			<p class="calibre3">The enterprise world has two kinds of images: decorative and functional. Showing “pretty” graphics can jazz up the user experience or give it style and character. These decorative images are not required and, thus, don’t require any support regarding<a id="_idIndexMarker285" class="pcalibre pcalibre1 calibre6"/> accessibility and might not even impact usability. However, they can influence the customer’s mood, affecting the user’s experience. The second, being more critical, are images that provide a function. Avatars, background color coding, and bubbles help communicate the user’s content in the thread. Icons grab the eye to make a feature or status stand out. Given the smaller size of most chat windows, this is a valuable application of imagery. Generally, it would be best to have some affordance to the conversational back-and-forth elements, but not every affordance. Sometimes, images are the application’s primary purpose, such as with inventory apps, social media, online ordering, or image generators.</p>
			<p class="calibre3">Suppose the application is an AI image generator. Consider how much space is available to render images and the resolutions available to download. In this use case, it is better to generate an image in the size that makes sense for the display because this can be 10x smaller than a “full size” image and thus faster to display. Choose the download size with a drop menu or UI element. The major image library sites use this pattern.</p>
			<p class="callout-heading">Legal caution</p>
			<p class="callout">Generative images are a new frontier of issues. Legal issues can arise if models are trained on copywritten and trademarked material, resulting in images that are generated too close to the source. This space will mature, but be aware of it. The base model was sourced from the Internet. This will also be an issue with text, voice, and music. Avoid famous people’s voices and likenesses. James Earl Jones, Christopher Walken, Scarlett Johansson, or any celebrities’ legal counsel will put offenders in their crosshairs.</p>
			<p class="calibre3">Suppose the application generates an image to include in a workflow, such as creating an advertising image of a product or a marketing image. If the model is trained on enterprise material and told to use those materials, it might address any legal concerns.  To constrain the end-user, the instructions for the model could be set to constrain the image within a corporate standard style. Users should not have to do this every time. Once they approve the image, consider storing it with the resulting workflow and the messages used to generate it; this knowledge can help further model training. If the user needs to edit, they can quickly restart from the same message and tweak it further without retyping and, more importantly, having to remember what they typed.</p>
			<p class="calibre3">In a chat-only experience, such as SMS messaging or a chat channel that doesn’t yet have component support, images are likely supported to some extent. So, look at the framework to see whether images can be tagged with a meta-data label for accessibility or if an explanation has to be written out in the channel as text. An LLM can be used behind the scenes or even in batch mode to generate descriptions for images and captions for tables and figures. Use LLMs as tools in a business workflow and understand what the channel supports to give customers control and usability around images.</p>
			<p class="calibre3">Icons are a unique set of images. They are used in the design of hybrid UI, have some use in pure chat experiences and recommender, and have no place in a back-end UI. I haven’t explored using an LLM to generate icons, but from experience, it is excellent for brainstorming but not yet for the fine details needed at the pixel level. This conversation will thus be constrained to using icons in hybrid experiences.</p>
			<p class="calibre3">Icons are used to convey an action or state or for visual feedback. Sometimes, they support words (such as a button with an icon and label) and, in some cases, are just icons. The label may be available on a mouseover or in a wider-screen view. In this case, consider the visual style and tone the collection of icons represents and whether there is a chat or conversational capability to interact with the icon. For <a id="_idIndexMarker286" class="pcalibre pcalibre1 calibre6"/>example, if an icon shows the user is online (like a green dot in the corner by the username), there is presumably a way to go offline or into another state. If this is a support application that thousands of chat and phone agents use, there is typically a multiple-step process to take them offline or online. Is this something that they can do conversationally? It comes down to the use cases. A driver clicks buttons in a car to set the temperature, but it is much easier and less distracting to say to the car, “Turn on the A/C to 68 degrees.” GUIs and voice interaction can work hand in hand.</p>
			<p class="calibre3">And since interactive elements such as icons and images, their siblings, buttons, menus, and choice lists are worth some explanation.</p>
			<h2 id="_idParaDest-120" class="calibre9"><a id="_idTextAnchor120" class="pcalibre pcalibre1 calibre6"/>Buttons, menus, and choice lists</h2>
			<p class="calibre3">In some traditional chats with autonomous agents, the experiences could be more conversational. They <em class="italic">look</em> like a <a id="_idIndexMarker287" class="pcalibre pcalibre1 calibre6"/>chat but only offer clicking buttons; the user can’t type. <em class="italic">Avoid this </em><em class="italic"><a id="_idIndexMarker288" class="pcalibre pcalibre1 calibre6"/></em><em class="italic">use case at all costs</em>. It is a red flag and will derail any <a id="_idIndexMarker289" class="pcalibre pcalibre1 calibre6"/>goodwill with the customer. They become trapped in a poor experience. However, in an actual conversational AI, it is sometimes helpful to offer suggestions or hints. The primary issue with conversational AI comes from one of the primary heuristics of “recognition over recall,” covered in <a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 9</em></a><em class="italic">, Guidelines and Heuristics</em>. This means it is faster for users to pick from choices and <a id="_idIndexMarker290" class="pcalibre pcalibre1 calibre6"/>recognize something than to pull from their memory and recall items.</p>
			<p class="callout-heading">A quick primer on recognition over recall</p>
			<p class="callout">Article: <a href="https://www.nngroup.com/articles/recognition-and-recall/" class="pcalibre pcalibre1 calibre6">Recognition over recall</a> (<a href="https://www.nngroup.com/articles/recognition-and-recall/" class="pcalibre pcalibre1 calibre6">https://www.nngroup.com/articles/recognition-and-recall/</a>)</p>
			<p class="calibre3">This tenet applies to so many places in user experiences, such as menus. Although some applications have many features, finding a function takes time and effort. It is well known that picking <a id="_idIndexMarker291" class="pcalibre pcalibre1 calibre6"/>from a list is more accessible than recalling a menu command. Now, with ChatGPT, the exact name of a command to activate a function is not needed. Questions can be asked without using the precise words of a command and still find good results. This helps mitigate some of the problems with text entry experiences. This is a beautiful change and makes chat experiences possible in the first place. However, it is still helpful to reduce the user’s cognitive overhead. So, if there are just a few choices or you have a good idea of what is next, it is reasonable to offer suggestions. Sometimes, those appear dynamically on a typeahead bar. Like in text messaging, it tries to predict what word will be typed, as shown on the left in <em class="italic">Figure 5</em><em class="italic">.13</em>. This predictive text is precisely how LLMs work, so it is the perfect place to assist users with LLMs as long as they can keep up with their typing speed. Sometimes, the responses are more robust than word or button choices in the response to submitting the prompt, as in the example on the right of the figure.</p>
			<div><div><img src="img/B21964_05_13.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Predictive typeahead buttons in Messages on an iPhone (left) versus the suggestion buttons in-line after a prompt (right)</p>
			<p class="calibre3">Use predictive completion in three cases: when what is next is understood and when the user is lost or needs guidance. All possible paths are too many. Even three or four choices are enough. Consider the data. If the data can predict with 90% certainty that one of four items is correct, then it makes sense to offer suggestions. If four options give a 30% of success, don’t offer them. And don’t forget to gather this data to help future models and decide how to improve the UI. Generally, it would be best to consider what happens<a id="_idIndexMarker292" class="pcalibre pcalibre1 calibre6"/> when the menus or buttons are selected. The elements should be removed after clicking them. The same style of any GUI buttons can be used to create consistently, but in most UIs, buttons don’t disappear when <a id="_idIndexMarker293" class="pcalibre pcalibre1 calibre6"/>clicked. However, in a chat UI, the buttons should not appear available, and disabling the buttons is a partial solution, but why waste the space? Generally, buttons are removed after selection. Choice lists or drop-down menus offer more options in less space but with the additional headache of having to open the menu to see the possibilities. If there are a lot of choices, then it is more complex to deal with search or scroll bars. Follow existing guidelines to use these correctly, then remove them from the UI display when done.</p>
			<p class="calibre3">In a GUI, there is room for buttons with large labels, maybe to draw the user’s attention to something on a large<a id="_idIndexMarker294" class="pcalibre pcalibre1 calibre6"/> screen, but there isn’t room for them in a chat window, so keep menu<a id="_idIndexMarker295" class="pcalibre pcalibre1 calibre6"/> labels short. Buttons are suitable for actions; use links for navigation.</p>
			<h2 id="_idParaDest-121" class="calibre9"><a id="_idTextAnchor121" class="pcalibre pcalibre1 calibre6"/>Links</h2>
			<p class="calibre3">Links are the basis of web applications, but linking is expected for <a id="_idIndexMarker296" class="pcalibre pcalibre1 calibre6"/>any app. Tables of contents in documents are the old-school version, and menus are a version of links on a desktop. Links are valuable in hybrid UIs and are among the few UI elements available in any traditional chat experience. Hybrid, chat, and recommender UIs can use the links, and there are a few tips to consider regarding how the links should be handled.</p>
			<h3 class="calibre11">Linking to outside sources</h3>
			<p class="calibre3">Linking provides URLs to services or content that can’t be offered inline. Links can give a reference, provide more details with an article, access a form or service not within the control of the chat, or open a new window or<a id="_idIndexMarker297" class="pcalibre pcalibre1 calibre6"/> panel for the user. Determine how to present links to the user. If the experience opens a new window, will the user return to the first window to continue the conversation? If the chat is in a side window or panel to support what is happening in a main window, will the experience update if the links resolve in the main window so any subsequent conversations know about the change? Make decisions around these interactions.</p>
			<p class="calibre3">Labels on links should be clear and indicative of their purpose. As shown in <em class="italic">Table 5.1,</em> instead of showing long links in the output (left), use a well-defined label (center).</p>
			<table id="table001-4" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Don’t </strong><strong class="bold">Do This</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Readable &amp; </strong><strong class="bold">Manageable</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Explanation</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">Hi Richard. A new Explanation of Benefits (EOB) is ready. It may include time-sensitive or other important information.</p>
							<p class="calibre3">https://click.edelivery.uhc.com/?qs=7b10282 356f8afb07d1e82e239f9722d466ca
84134771c3c35ee1b60c735d8940b3 2b169349bc53c30141f6c40140989f75b8589cd2af251</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1) Hi Richard. Please review your new Explanation of Benefits (EOB). It may include time-sensitive or other important information.</p>
							<p class="calibre3">2) Hi Richard. I can take you to the Explanation of Benefits (EOB)➚. This link is outside the portal, sign in is required.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1) Readable links are more direct and take up less space. Avoid “Click here”.</p>
							<p class="calibre3">2) Alternative text when chat supports navigating the main window, but this link opens elsewhere.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 5.1 – Use well-defined labels for links in the conversational output</p>
			<p class="calibre3">Don’t expose URLs if the client can support a label. It is familiar enough for users to right-click and copy the URL. Focus on the use case and what makes the most sense for links. If this is a co-navigate UI (use links in the chat to control the page they are on) <em class="italic">and</em> has links to outside sources, consider how to communicate the difference between these two types of links, as I show in the second example output in the middle of <em class="italic">Table 5.1</em>. Will it make sense and be apparent to users that they have co-navigated? They might click multiple times without an affordance, not<a id="_idIndexMarker298" class="pcalibre pcalibre1 calibre6"/> knowing the page behind the chat window has changed. Also, sometimes, the legal department gets in the way. There are websites where an intermediate screen opens after clicking a link, letting the user know they are leaving the site. This warning seems too complex for a UI, likely written by lawyers or because customers are confused by the link. Clarifying these interactions without the extra page and warning would be nice.</p>
			<h3 class="calibre11">Link color</h3>
			<p class="calibre3">I strongly encourage following HTML and web norms with links when building a client. Specifically, aging the link color after someone has clicked it. Typically, a blue link means unvisited and purple once visited. It is immensely valuable, even as subtle as it is, to keep track of which links were clicked, especially if a collection of links is being shared in a conversation.</p>
			<p class="calibre3">Look carefully at Google search, as shown in <em class="italic">Figure 5</em><em class="italic">.14</em>; isn’t it great to return to the results list and it shows links that were visited? Use this pattern for all links. Customers might not notice it overtly, but it will be more usable. This is accessible for screen readers, as it communicates that the link was visited.</p>
			<div><div><img src="img/B21964_05_14.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.14 – Purple indicates a visited link and is fundamental to providing context</p>
			<h3 class="calibre11">Opening windows</h3>
			<p class="calibre3">Opening a new window is typical for a web link if it doesn’t replace the current page. Opening a new window is required<a id="_idIndexMarker299" class="pcalibre pcalibre1 calibre6"/> for a chat window because it can’t replace the current small window with a web page. But realize that if the user goes off-site to return to the experience, they must figure out the window containing this chat. If they close the newly opened window, they should be returned to where they started, but this doesn’t happen as often as expected.</p>
			<p class="calibre3">If the link opens a new window on the same site, there will be a different problem to solve. Can the chat window reopen and be reconstructed to pick up where the user left off in the previous window? Or there are now two windows open that have the same chat. And this can continue, so can the site handle 3, 4, or 10 open browser windows, all with the same chat? Can it keep up with the changes across windows? As this depends on the chat platform. Chat vendors should provide the solution. Just make sure to understand the requirements so either the team manages the problem or has the vendor address it.</p>
			<p class="calibre3">Since a regular link in a chat window is expected to open in a new window, no additional affordance is needed. However, a sidebar must provide an affordance to help the user understand that it will open in the same window. Don’t use a link in a chat window to start a process; this is why buttons exist. Keep links for navigation.</p>
			<p class="calibre3">These considerations allow for smoother, more engaging, consistent, and natural ChatGPT hybrid and chat-only experiences. The hybrid experience is the most robust and complex use case because it has to account for all the traditional user experience interactions and then layer in the additional complexity of chat. Stepping away from a graphical user experience, another vertical worth our attention is a voice experience, such as those found when calling a company and using their phone tree. Let’s review some tips to create compelling voice-only experiences.</p>
			<h1 id="_idParaDest-122" class="calibre5"><a id="_idTextAnchor122" class="pcalibre pcalibre1 calibre6"/>Creating voice-only experiences</h1>
			<p class="calibre3">Phone calls or smart-speaker devices without a display are a few voice-only experiences. Voice-only was very limiting, and there are still human factors to consider, but technology has come a long way. ChatGPT 4o-mini takes empathy and tone to a new level, and because it is better at following instructions, prompts can control answers to be short to accommodate the capacity of a human to process voice in small pieces. There is nothing else to interact with because it is voice only. We don’t need to consider voice-only <em class="italic">within</em> a chat or hybrid experience; that is really voice-optional. A smartphone allows you to type or use voice and then translate the speech into text. All models behind these services will improve with LLM models behind the scenes. But we are not here to talk about enhancing speech-to-text. Let’s focus on a voice-only channel.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">When designing for a smart device, the vendors emphasize that only some devices have displays, but even if they do, the experience should work with voice only. Not all use cases make sense to interact physically with the device, even though it is supported. For example, an Alexa device in the kitchen might allow interaction with the display to go to the next step of a recipe, but the user might want to avoid touching it with messy hands, or it might just be out of reach.</p>
			<p class="calibre3">As with chat experiences, decide whether a generative solution replaces or supplements the <a id="_idIndexMarker300" class="pcalibre pcalibre1 calibre6"/>experience. Everyone has headaches with phone trees, the hierarchical prompts that lead to a leaf on the tree when calling a business, requiring pressing <em class="italic">1</em>, <strong class="bold">2</strong>, or <strong class="bold">3</strong> to navigate down the <em class="italic">tree</em> of options. A positive of a well-designed phone tree is that it focuses on results based on choices. This is also why desktop software has menus. It limits the number of options at each turn: walking down some trees is more straightforward than directly recalling or accessing a specific node.</p>
			<p class="calibre3">Replacing a tree by starting with an open-ended “ask me anything” approach can be tricky. If I ask for “help with batteries” in a phone tree at Costco, a big-box retailer, do I want to go to “Automotive,” “Hearing Aids,” or maybe see whether household batteries such as AAs are in stock or on sale? In a phone tree, the user makes selections focusing on limited areas (Automotive, Hearing Aids, or Shopping), and then the correct choice is clearer.</p>
			<p class="calibre3">Consider the choice to introduce text-to-speech listening with generative AI at the root level (“Tell me how I can help”) or use it at the next level, “What is your question for the automotive service team?”. Generative AI will be more successful with robust content, knowledge, and APIs for a specific part of the problem space. Getting that detail takes time and effort. So, doing it for a particular department might be an excellent first step to limit scope. Draw on the first few chapters to learn which department would have a use case that is best suited. Determine which use case would have the highest WSJF score!</p>
			<p class="calibre3">The closer to the top of the call tree ChatGPT is added, the more general and, thus, the more complex the solution. Customers who think it can answer anything will be more likely to ask. For example, a common question for a big-box retailer is a stock check. “<em class="italic">Does my local Costco have any Pampers in size 6?</em>” Without access to APIs to answer this question, the model can still understand this request, chat about it, and then transfer it to a human agent. Then, solve the problem of requiring the user to ask the human agent the same question. Give the agent the recorded question or transcription with a head start while the user is being transferred. So now the agent can answer the call and say, “<em class="italic">I am checking on the size 6 Pampers; one </em><em class="italic">moment, please.</em>”</p>
			<p class="calibre3">Not having to repeat the request would be a breakthrough and an actual omnichannel moment, even if the automation couldn’t directly answer the question. Or what about a stock check system that <em class="italic">only</em> interacted with the LLM while humans only proved the results to the software, thus reserving additional agent time for <a id="_idIndexMarker301" class="pcalibre pcalibre1 calibre6"/>more pressing and complex interactions?  “<em class="italic">I have asked a team member to check on the Pampers. It might take a few minutes. Is there anything else I can help you with while we wait?</em>” At least until the company gets the necessary APIs to automate stock checks.</p>
			<p class="calibre3">The point is to create the best experience within the system while pushing for the necessary capabilities at the same time. If there are no stock check APIs and it is 15% of inbound call volume, then it is probably a problem worth investigating. With a simple phone tree and a team not ready to expand to the questions that will come with an open-ended experience, don’t bother adding ChatGPT at the top. The value comes from improving customer service and decreasing hold time for human agents for those common questions that could be answered by combining data sources with ChatGPT. There is a wealth of examples of inadequate implementation of AI. Don’t be the company that added ChatGPT, which worsened the experience.</p>
			<p class="calibre3">Considering that  the user’s phone number is known in many cases for existing customers (a good thing to have an API for), a lookup around this customer’s profile and history can generally reveal various opportunities for a customized experience:</p>
			<ul class="calibre7">
				<li class="calibre8">Order status and tracking:<p class="calibre3">The user is known, so if open orders exist, immediately prompt and assist with details on those orders or route the call correctly to a human agent giving the order as context. <em class="italic">Are you calling about the online order that included the Shipley 4-piece bedroom set? It is scheduled to be </em><em class="italic">delivered tomorrow.</em></p></li>
				<li class="calibre8">Nearest store details:<p class="calibre3">Starting with details about their typical store would be reasonable, especially on known holidays. <em class="italic">Happy 4th of July! Your Foster City store is currently open. It will close at </em><em class="italic">6 p.m.</em></p></li>
				<li class="calibre8">Support for <a id="_idIndexMarker302" class="pcalibre pcalibre1 calibre6"/>purchases:<p class="calibre3">If they just bought a TV, use that information when they ask for support. <em class="italic">I see you just purchased a 65-inch Vizio Smart TV. Is that the product you need </em><em class="italic">assistance with?</em></p></li>
				<li class="calibre8">Technical support:<p class="calibre3">An existing open ticket is a likely candidate for further conversation. Of course, they might have dozens of available tickets in the enterprise space, so consider the scale of the issue when deciding how to interact with the customers. <em class="italic">I see your support ticket from yesterday was updated. Are you here for help with your credit card being </em><em class="italic">charged twice?</em></p></li>
			</ul>
			<p class="calibre3">Map the customer’s phone number to their company history to enable personalized assistance until more is known on the call. You have probably experienced this with messages like, “<em class="italic">I see you have called us, Richard, from this number before. If this is you, press one or stay on the line.</em>” Still, I suspect every vendor is working to improve. If you use a third-party solution, evaluate its ability to engage users, review logs and usage to identify opportunities for enhancing routing and responses, and use the methods from the prior chapter to prioritize improvements.</p>
			<p class="calibre3">Here are a few short bits that can be helpful with voice experiences.</p>
			<ul class="calibre7">
				<li class="calibre8">If disambiguation is needed to understand the situation (as in the example asking what kind of batteries were in stock), keep prompts short and straightforward.</li>
				<li class="calibre8">Offer secondary channels for complex interactions that would be difficult to conduct on a phone call (such as sending an email to complete a task later on a phone or computer).</li>
				<li class="calibre8">Log and track all errors or navigation issues that the user reports.</li>
				<li class="calibre8">Monitor path analytics (Funnel reports) to understand where customers hang up or get lost. This can expose opportunities for an LLM.</li>
				<li class="calibre8">Ensure the voice persona suits the audience. Test and get feedback. Use A/B testing to consider alternatives. Advanced users could use a different persona.</li>
				<li class="calibre8">If using multiple personas, associate the right persona with specific user groups, such as new users, experienced customers, or VIPs.</li>
			</ul>
			<p class="calibre3">This covers experiences with interaction. What about cases where there are little or no interactions? Are there things to do to create high-quality experiences? Let’s cover bot-only or behind-the-scenes experiences next.</p>
			<h2 id="_idParaDest-123" class="calibre9"><a id="_idTextAnchor123" class="pcalibre pcalibre1 calibre6"/>Designing a recommender and behind-the-scenes experiences</h2>
			<p class="calibre3">Sometimes, ChatGPT is used to analyze data, make recommendations, offer suggestions, or display results. That is an excellent use of this technology, and because the experience is simple, ensure the output is also simple. These experiences are not <a id="_idIndexMarker303" class="pcalibre pcalibre1 calibre6"/>conversationally interactive or hide the use of the LLM. They might be called “headless” because only a recommendation is provided, and there is no front-end experience, such as a chat window.</p>
			<p class="calibre3">The following are some of the examples of bot-only or behind-the-scenes experiences:</p>
			<ul class="calibre7">
				<li class="calibre8">A recommendation flag or marker based on a ChatGPT analysis. This could be an icon showing <strong class="bold">Urgent</strong> or <strong class="bold">Warning</strong> on the cloud service dashboard or a <strong class="bold">Call Now</strong> flag for a sales lead. The user might not even know that an LLM is now behind this notification. Traditionally, this was handled by a simple rule, maybe some machine learning, and now an LLM. This is because the LLM can deliver more accuracy, address more complex situations, or be more timely.</li>
				<li class="calibre8">A call to action:<strong class="bold"> Call the customer by Thursday; they are 30% more likely to close </strong><strong class="bold">this deal.</strong></li>
				<li class="calibre8">A process improvement:<strong class="bold"> Response time dropped 11% last week. To return to the previous service level, increase call center staff by three agents during </strong><strong class="bold">business hours.</strong></li>
				<li class="calibre8">A task recommendation: <strong class="bold">Ship this package using DHL for the most </strong><strong class="bold">cost-effective solution.</strong></li>
				<li class="calibre8">A virtual non-player character in a video game interacts more naturally and dynamically with players.</li>
				<li class="calibre8">Idea generation. Offer suggestions for new ideas to solve problems.</li>
				<li class="calibre8">Editing: Integrate with built-in authoring tools for marketing or coding that offer better suggestions than traditional deterministic spelling and grammar solutions.</li>
			</ul>
			<p class="calibre3">In these cases, there is no direct interaction with the model; at best, you accept or don’t accept the options or recommendations. In many cases, UIs already had these experiences, but the sophistication of a generation<a id="_idIndexMarker304" class="pcalibre pcalibre1 calibre6"/> AI solution did not power them.</p>
			<h3 class="calibre11">Guidelines for bot-only experiences</h3>
			<p class="calibre3">There is such a wide range of use cases this is just general guidance:</p>
			<ul class="calibre7">
				<li class="calibre8">Use data logging to <a id="_idIndexMarker305" class="pcalibre pcalibre1 calibre6"/>understand whether recommendations are being followed.</li>
				<li class="calibre8">Create a mechanism to get feedback on use while considering any data from logging. Don’t ask questions to which the answer is known. For example, from call logs, the system knows that an agent called the customer when recommended, so don’t ask whether they made the follow-up call. Use survey expertise to ask the right questions.</li>
				<li class="calibre8">Don’t require feedback.</li>
				<li class="calibre8">Keep suggestions short and to the point.</li>
				<li class="calibre8">Consider secondarily exposing recommendation details, learn more about this recommendation feature, or analyze what factors led to the recommendation.</li>
				<li class="calibre8">Don’t overuse recommendations. If every row of data has the same recommendation, then the value of the recommendation will be lost.</li>
				<li class="calibre8">Monitor and revisit recommendations. Creating metrics on their success or failure will help position investment in future improvements. Without monitoring, it is unknown if it was a waste to develop it. I know one client uses ChatGPT to update resumes to be better suited to get through the automated screening tools that review resumes. It was suggested that feedback be incorporated against actual vendor tools, not just relying on whether the resume writer edited the resume further after getting adjusted by the AI. The correct analytic focuses on whether the edited resume passed screeners and resulted in the applicant making it to the next step. <em class="italic">Asking the right question and building the right metric </em><em class="italic">is key.</em></li>
			</ul>
			<p class="calibre3">Sometimes, revealing more details of what is happening behind the scenes is helpful.</p>
			<h3 class="calibre11">Exposing ChatGPT when it is working behind the scenes</h3>
			<p class="calibre3">The exciting thing about ChatGPT is it can appear anywhere. The user typically doesn’t need to know the details of a behind-the-scenes solution. Usually, details are not exposed, but there can be some exceptions in AI cases. It is generally accepted as good behavior not to pretend to be human. In the <a id="_idIndexMarker306" class="pcalibre pcalibre1 calibre6"/>case of a chat UI, the LLM doesn’t impersonate a human. Customers are told they are talking to a virtual assistant. It can also benefit the user to know this; they might be more forthcoming and will know they will get a quick response. In a hybrid experience that includes a GUI, or in the case of a Chat AI participating in a group conversation, it should be clear when the AI is participating, and it should be clear whether there are any guardrails preventing the AI from listening.</p>
			<p class="calibre3">In a bot example, where a simple recommendation is offered, machine learning and algorithmic recommendations in UIs appeared more than a decade ago. The behind-the-scenes algorithms are not explained and might be proprietary (like credit scores). It is unnecessary to clarify whether it uses or includes results from ChatGPT. Decide based on the use case. Get feedback on recommendations, and this is encouraged to happen with some regularity. It might help and can hurt to explain some details if feedback is provided. Even the simple feedback mechanism could be powered by AI. Imagine a purpose-built model whose job is only focused on getting feedback. Having a direct feedback request with possible follow-up can be sufficient. One upside of exposing “<strong class="bold">Powered by AI</strong>” is that it might help engage customers to provide feedback. Position this as the user helping themselves because their feedback will be used to improve results. And folks do like being heard. Customers might consider this help-free consulting or be annoyed thinking the AI is in “beta.” However, I think this opinion will soften as users recognize the value of a well-trained generative AI solution.</p>
			<p class="calibre3">Hopefully, for all the <a id="_idIndexMarker307" class="pcalibre pcalibre1 calibre6"/>solutions that can be invented, most enterprise ChatGPT solutions will be covered within one of the types of experiences discussed. There are a few overarching areas to consider for all experiences.</p>
			<h1 id="_idParaDest-124" class="calibre5"><a id="_idTextAnchor124" class="pcalibre pcalibre1 calibre6"/>Overarching considerations</h1>
			<p class="calibre3">Some topics apply more universally, regardless of the type of experience. Accessibility, internationalization, and security are three essential items worth discussing.</p>
			<h2 id="_idParaDest-125" class="calibre9"><a id="_idTextAnchor125" class="pcalibre pcalibre1 calibre6"/>Accessibility</h2>
			<p class="calibre3">It should not be surprising that I call out <strong class="bold">accessibility</strong>, also called <strong class="bold">A11y</strong> (because who wants to type all those letters). Large multinationals tend to have contracts with government entities in the <a id="_idIndexMarker308" class="pcalibre pcalibre1 calibre6"/>enterprise space, and they require A11y. Each country or region can have its own rules; sometimes, those roles can be broken if well documented, but our goal should be to make an accessible experience. Some <a id="_idIndexMarker309" class="pcalibre pcalibre1 calibre6"/>forms of accessibility are more challenging than others. All customers can benefit from design thinking applied to A11y. For example, keyboard shortcuts and navigation are required for those with visual impairments, but many computer experts use them extensively. Closed captioning was introduced in 1979 for people who are hard of hearing. Still, bars have them on, and others use closed captioning to learn a new language or to help improve understanding because of a wide range of audio issues from streaming and cable services. Voice recognition was developed for those with mobility impairments. Without that history, Siri, Alexa, and the voice assistants of the world would not exist. The examples go on and on. Consider the use case and ensure a solid A11y solution. Sometimes, the framework, such as an Apple iPhone, has considerable accessibility support. So much is handled by the framework; lucky for your team!</p>
			<p class="calibre3">Use the<a id="_idIndexMarker310" class="pcalibre pcalibre1 calibre6"/> existing standards and learn how they are applied in AI use cases. GUIs, chat, and voice all have A11y concerns. Even if you are in a country where they might not apply, you can learn much from them. We don’t want accessible experiences; we want <em class="italic">usable,</em> accessible experiences. The first three references have the broadest impact:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Web Content Accessibility </strong><strong class="bold">Guidelines</strong> (<strong class="bold">WCAG</strong>):<p class="calibre3">Article: <a href="https://www.w3.org/WAI/WCAG21/quickref/" class="pcalibre pcalibre1 calibre6">WCAG</a> (<a href="https://www.w3.org/WAI/WCAG21/quickref/" class="pcalibre pcalibre1 calibre6">https://www.w3.org/WAI/WCAG21/quickref/</a>)</p><p class="calibre3">Developed by the <strong class="bold">World Wide Web Consortium</strong> (<strong class="bold">W3C</strong>), WCAG (pronounced “double u-cag”) is a guide<a id="_idIndexMarker311" class="pcalibre pcalibre1 calibre6"/> for web content accessibility. The foundational<a id="_idIndexMarker312" class="pcalibre pcalibre1 calibre6"/> guidelines are widely adopted and used as a basis for other standards. For example, California mandates WCAG 2.1 Level AA and Section 508 for their public websites. WCAG 2.0 is also referenced as the standard ISO/IEC 40500:2012.</p></li>
				<li class="calibre8"><strong class="bold">Section 508:</strong><p class="calibre3">Article: <a href="https://www.section508.gov/" class="pcalibre pcalibre1 calibre6">Section 508 Government standards</a> (<a href="https://www.section508.gov/" class="pcalibre pcalibre1 calibre6">https://www.section508.gov/</a>)</p><p class="calibre3">Section 508 outlines accessibility requirements for electronic and information technology used by the federal government of the United States. Compliance with 508 is typical for more extensive enterprise solutions sold to the federal government, while sales to state governments might also reference this in their project requirements.</p></li>
				<li class="calibre8"><strong class="bold">Accessible Rich Internet </strong><strong class="bold">Applications</strong> (<strong class="bold">ARIA</strong>):<p class="calibre3">Article: <a href="https://www.w3.org/WAI/standards-guidelines/aria/" class="pcalibre pcalibre1 calibre6">ARIA guidelines</a> (<a href="https://www.w3.org/WAI/standards-guidelines/aria/" class="pcalibre pcalibre1 calibre6">https://www.w3.org/WAI/standards-guidelines/aria/</a>)</p><p class="calibre3">ARIA is a set of <a id="_idIndexMarker313" class="pcalibre pcalibre1 calibre6"/>attributes that define ways to make web content and applications more accessible, especially for dynamic content and advanced user interfaces. This is important when doing intelligent or live updates on a page.</p></li>
				<li class="calibre8"><strong class="bold">Americans with Disabilities </strong><strong class="bold">Act</strong> (<strong class="bold">ADA</strong>):<p class="calibre3">Article: <a href="https://www.ada.gov/" class="pcalibre pcalibre1 calibre6">ADA website</a> (<a href="https://www.ada.gov/" class="pcalibre pcalibre1 calibre6">https://www.ada.gov/</a>)</p><p class="calibre3">The ADA mandates that <a id="_idIndexMarker314" class="pcalibre pcalibre1 calibre6"/>public entities, including digital services, web applications, and sites, be accessible to people with disabilities. As the ADA is not a standard, compliance often aligns with WCAG guidelines. The guidelines specifically call out algorithms and AI regarding hiring practices.</p><p class="calibre3">Article: <a href="https://www.ada.gov/resources/ai-guidance/" class="pcalibre pcalibre1 calibre6">AI Guidance</a> (<a href="https://www.ada.gov/resources/ai-guidance/" class="pcalibre pcalibre1 calibre6">https://www.ada.gov/resources/ai-guidance/</a>)</p></li>
				<li class="calibre8"><strong class="bold">European Standard EN </strong><strong class="bold">301 549:</strong><p class="calibre3">Article: <a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf" class="pcalibre pcalibre1 calibre6">European Standards</a> (<a href="https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf" class="pcalibre pcalibre1 calibre6">https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01_60/en_301549v030201p.pdf</a>)</p><p class="calibre3">This European standard is based on WCAG and provides additional requirements to meet public<a id="_idIndexMarker315" class="pcalibre pcalibre1 calibre6"/> procurement needs for <strong class="bold">Information and Communication Technology</strong> (<strong class="bold">ICT</strong>) products and services. Some of their standards, such as this one for “videotelephony” (video calls), are very technical:</p><p class="calibre3">Article: <a href="https://www.etsi.org/deliver/etsi_etr/200_299/297/01_60/etr_297e01p.pdf" class="pcalibre pcalibre1 calibre6">Human Factors in Videotelephony</a> (<a href="https://www.etsi.org/deliver/etsi_etr/200_299/297/01_60/etr_297e01p.pdf" class="pcalibre pcalibre1 calibre6">https://www.etsi.org/deliver/etsi_etr/200_299/297/01_60/etr_297e01p.pdf</a>)</p></li>
				<li class="calibre8"><strong class="bold">ITU-T F.922:</strong><p class="calibre3">Article: <a href="https://www.itu.int/rec/T-REC-F.922-202008-I/en" class="pcalibre pcalibre1 calibre6">ITU-T F.922 Guidelines</a> (<a href="https://www.itu.int/rec/T-REC-F.922-202008-I/en" class="pcalibre pcalibre1 calibre6">https://www.itu.int/rec/T-REC-F.922-202008-I/en</a>)</p><p class="calibre3">The <strong class="bold">International Telecommunication Union</strong> (<strong class="bold">ITU</strong>) standard provides guidelines for accessible <a id="_idIndexMarker316" class="pcalibre pcalibre1 calibre6"/>user interfaces on telecommunication devices. This specific one is for visually impaired persons, but other standards in the same section might also be valuable.</p></li>
			</ul>
			<p class="calibre3">It would be best to understand and, when needed, refer to the specific standards relevant to the target audience. If this is your first chat UI, then consider how a screen reader reads the conversation, how to deal with the LLM coming back<a id="_idIndexMarker317" class="pcalibre pcalibre1 calibre6"/> with a response that might be delayed (how to notify the user if they are in another window, for example), and to make sure that any GUI elements have the same support as they would if they were on a web page.</p>
			<p class="calibre3">If you have been building existing UIs to A11y standards, do test suites already exist for the models? Compliance and even exceeding mandates and standards help create a more inclusive experience for all users, and speaking of all users leads us to think about a worldwide audience.</p>
			<h2 id="_idParaDest-126" class="calibre9"><a id="_idTextAnchor128" class="pcalibre pcalibre1 calibre6"/>Internationalization</h2>
			<p class="calibre3">This is another one<a id="_idIndexMarker318" class="pcalibre pcalibre1 calibre6"/> of those long words written as <strong class="bold">I18n</strong> (skipping those <a id="_idIndexMarker319" class="pcalibre pcalibre1 calibre6"/>annoying 18 characters between the <em class="italic">I</em> and the <em class="italic">n</em>). The world of ChatGPT has opened the doors to communicating with the audience in their native language. That is fantastic news. Can the enterprise handle working in their language? It isn’t just a matter of turning on translation. That might lead to a worse situation than if the language wasn’t enabled because it is only one piece of supporting the customer in that language, at least to some extent. Define what level of support makes sense. If there is a ChatGPT conversational solution for asking knowledge questions, the next step would be to support the customer’s follow-up questions or escalate to a live agent in that language. Many companies are not good at that.</p>
			<p class="calibre3">Internationalization, the overarching development effort for language support, includes localizing text translation and considering locale-specific elements.</p>
			<h3 class="calibre11">Example of using in-conversation translation</h3>
			<p class="calibre3">Even the largest support companies sometimes have minimal multi-language support outside their native language. In one<a id="_idIndexMarker320" class="pcalibre pcalibre1 calibre6"/> large multinational, even when another language is supported (such as the Asian languages, where English is typically not an option for this company), a team translates each service request. Then, the translated request is sent to the engineering team, and each response is translated back into the customer’s language. It is a game of telephone, and these intermediate steps cause noise and confusion.</p>
			<p class="calibre3">Could this process be improved by putting a real-time machine or LLM translation service into the loop? Would the technical nature of the requests and conversation confuse the participants? This technology is coming, but getting there will be hard work. It is one thing to ask for directions to the train station. It is quite another to get into the details when asking what specific SGA parameters and configurations need to be adjusted or optimized to enhance the performance and throughput of a highly transactional Oracle database system, considering factors such as concurrent transactions, response time, and resource utilization. Will the translation keep up with the differences between <code>BUFFER_POOL_KEEP</code>, <code>BUFFER_POOL_RECYCLE</code>, <code>JAVA_POOL_SIZE</code>, and the eight other properties? A far cry from, “When is the next train to the city?”</p>
			<p class="calibre3">If conversations are less technical than this crazy database example, that is good news. But this is why enterprise solutions are needed. We aim to build on the knowledge within the company and presumably use this to expand communication capabilities in customers’ native languages. It makes it evident that monitoring, debugging, and improving the machine or human-in-the-loop translation services are critical to success.</p>
			</div>
	

<div><h3 class="calibre11">Translating knowledge</h3>
			<p class="calibre3">Translating knowledge into<a id="_idIndexMarker321" class="pcalibre pcalibre1 calibre6"/> other languages is a start. The cost was traditionally expensive. Each article goes through an editorial process as part of any automation; this allows for a high-quality experience. Technically savvy translators must build up experience to translate complex or technical material. Guidelines and translation dictionaries are needed to maintain consistency and quality. Even with all the advances in automation, deciding the quality and cost trade-off threshold is still required. Machine translation might be <a id="_idIndexMarker322" class="pcalibre pcalibre1 calibre6"/>cheap (or free) and fast. Determine if it is good.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">There is an adage in the tech world, “Cheap, fast, and good, choose two.” If it is cheap and fast, it is likely not good. As shown in <em class="italic">Figure 5</em><em class="italic">.15</em>, it is probably not cheap if it is fast and good. And if it is cheap and good, it is probably not fast. There is an argument for design that some of these are untenable options. There are use cases for all of these, but they might not be best for the business.</p>
			<div><div><img src="img/B21964_05_15.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="callout">Figure 5.15 – Cheap, fast, and good, choose two</p>
			<p class="callout">Everyone wants cheap, fast, and good. It seems to be a unicorn, magical and non-existent. Please prove me wrong, gladly. I have always considered this adage a truth for product development. Let me share Benek Lisefski’s counterpoint for some additional reading on this.</p>
			<p class="callout">Article: <a href="https://solowork.co/story/the-big-lie-of-good-fast-cheap" class="pcalibre pcalibre1 calibre6">The Big Lie of Good, Fast, and Cheap</a> (<a href="https://solowork.co/story/the-big-lie-of-good-fast-cheap" class="pcalibre pcalibre1 calibre6">https://solowork.co/story/the-big-lie-of-good-fast-cheap</a>)</p>
			<p class="calibre3">Pick your battles. There are fast improvements in LLM-based translation, and the cost of quality translation is falling rapidly. Automate or allow some of this on the fly, but always check or spot-check the results. At least for popular articles, pay for professional review and <a id="_idIndexMarker323" class="pcalibre pcalibre1 calibre6"/>editing even if the LLM did the primary translation. However, for less popular articles or lesser-used languages, could it be enough to let the user know this article has been offered in their language but still might have errors? And don’t translate an article more than once. If the system translates on a pay-as-you-go approach for older articles, cache the results so you don’t have to hit the model again the next time the article is requested. Automation can help batch translate and reduce costs, but because of the complex nature of the company languages, this process requires checks and balances. Here is an approach to using LLMs in translation situations.</p>
			<h3 class="calibre11">How to decide what languages to support</h3>
			<p class="calibre3">Sometimes, the decision is made for you. A salesperson pre-sells the product in a specific language. I have seen<a id="_idIndexMarker324" class="pcalibre pcalibre1 calibre6"/> this happen; the customer is still waiting years later. It is easier said than done. This is not as common in large companies because no one deal is typically big enough to force this hand. However, this can be a deal breaker in smaller companies, or it is mandated to enter a new territory because of a strategic partnership or country-specific laws. If you are involved in deciding what languages to support and how much to help them, here is an outline to get started. Adjust as needed.</p>
			<p class="calibre3">There are four buckets to define: primary, fully, partially, and not supported. The company has a primary language, the base languages for the company; English is used for this example. A process is needed to define each resource the customers will touch, the cost of support, and the quality goals for that language. It is tough to achieve close to native quality. The cost to professionally translate technical knowledge might be prohibitive using traditional methods, but this would ensure that complex descriptions are explained correctly. Having native-speaker-level language quality in more than a few languages is challenging. ChatGPT’s translation cost is multiple orders of magnitude less expensive, maybe achieving 80–90% of the value with the proper monitoring and fine-tuning. Is that worth being able to expand markets?</p>
			<p class="calibre3">Some languages would have partial support; some things won’t be done in those languages. And there will always be languages that are not supported.</p>
			<p class="calibre3">All of this depends on the languages the LLM supports. This is still a maturing space. Although many models talk about supporting dozens of languages, training will improve their expertise in those languages. The quality of each language varies considerably.</p>
			<p class="calibre3">Many pieces of the solution can include design elements for supporting languages. What happens when they<a id="_idIndexMarker325" class="pcalibre pcalibre1 calibre6"/> have a ChatGPT conversational experience in German and then escalate to a support center that doesn’t speak German? What is the plan? What is the customer’s expectation? Consider how ChatGPT can support language needs in the customer’s journey. In <em class="italic">Table 5.2</em>, I have shown some examples (<strong class="bold">in bold</strong>) where an LLM can enhance or extend language support.</p>
			<table id="table002-4" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2"/>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Primary Language</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Fully Supported </strong><strong class="bold">Languages</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Partially Supported </strong><strong class="bold">Languages</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Not Supported </strong><strong class="bold">Languages</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Use Case </strong><strong class="bold">for User</strong></p>
						</td>
						<td class="no-table-style2" colspan="2">
							<p class="calibre3">Expects high-quality responses in their native language with the most up-to-date language, details, and tone</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Expects good quality experiences with localization</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The least popular language should get the best effort from machine translation</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Percent of </strong><strong class="bold">User Base</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Primary</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Greater than 5% of I18n users</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">From 1% to 5% of I18n users</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Less than 1% of I18n users</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Language</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">English</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Japanese, French, German, Spanish, Italian, Brazilian-
Portuguese</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Finnish, Dutch, Hebrew, Swedish, Arabic, Chinese, Korean</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Thai, Icelandic, Slovak, Romanian</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">User Interface &amp; </strong><strong class="bold">Help</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Complete</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Complete, Professionally Translated</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Complete, LLM translated with a </strong><strong class="bold">fine-tuned model</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Auto-Translated with LLMs, cached </strong><strong class="bold">after translated</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Knowledge</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Complete, Active Updates</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Key Knowledge, Quickly Updated</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">LLM-based batch translation, </strong><strong class="bold">with fine-tuning</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Auto-Translated with LLMs, cached </strong><strong class="bold">after translated</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Conversational </strong><strong class="bold">Assistant</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Full Support</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Full Support</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">LLM Based on Translated Sources</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Real-time LLM translation (</strong><strong class="bold">if available)</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tier </strong><strong class="bold">1 Agents</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Native Speakers</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Native Speakers</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Supported with Translation</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Not Available</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tier </strong><strong class="bold">2 Agents</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Native Speakers</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Limited, <strong class="bold">LLM Support</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Very Limited, <strong class="bold">LLM Support</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Not Available</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Milestones</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Timely</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Quickly, by Q2</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Slower, by EOY</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Not Supported</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Cost</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">N/A</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The incremental backlog cost is 1.25M, 100K/Qtr. ongoing</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The incremental KnowledgeBase cost is 125K and 15K/Qtr for new material</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">UI language cost is new and is about 15K per language</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Extenuating Circumstances </strong><strong class="bold">and Notes</strong></p>
						</td>
						<td class="no-table-style2"/>
						<td class="no-table-style2">
							<p class="calibre3">Contractually obligated to Arabic Tier 1 in Dec 2026</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Dutch customers mostly speak English, so defer</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Romanian agents speak supported European or English languages</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 5.2 – Hypothetical comparison of support levels and strategic plan for languages</p>
			<p class="calibre3">This is just an example of how to consider the impact of language support. This table is hypothetical. Clone it, expand it, and consider the implications for each box on the business language strategy. When designing for I18n, there are also details to work out. Let’s explore a few considerations.</p>
			<h3 class="calibre11">Accounting for I18n when designing</h3>
			<p class="calibre3">One of the most significant issues for<a id="_idIndexMarker326" class="pcalibre pcalibre1 calibre6"/> internationalization likely comes from the knowledge base. Is the content ready to be translated? Is it organized in a way that lends itself to translation? Will culturally specific idiomatic phrases fail automated translation? Consider <em class="italic">garbage in, garbage out</em> (even that phrase is idiomatic). It is incredible how well the current models understand idioms. Chat GPT continues to impress me with its results.</p>
			<p class="calibre3">What happens if I ask you to translate</p>
			<p class="calibre3">an idiom like "Your back is up against</p>
			<p class="calibre3">the wall" into German? Will it be</p>
			<p class="calibre3">a literal translation, or can you</p>
			<p class="calibre3">translate the idiomatic meaning?</p>
			<p class="calibre3">If you ask me to translate an idiom</p>
			<p class="calibre3">like "Es geht gleich los runter"</p>
			<p class="calibre3">into German, I will provide a translation</p>
			<p class="calibre3">that conveys the idiomatic meaning rather</p>
			<p class="calibre3">than a literal translation. The</p>
			<p class="calibre3">idiomatic meaning of "Your back is up</p>
			<p class="calibre3">against the wall" is that someone is</p>
			<p class="calibre3">in a difficult or desperate situation</p>
			<p class="calibre3">with few or no options left.</p>
			<p class="calibre3">In German, a common equivalent idiom is:</p>
			<p class="calibre3">"Du bist mit dem Rücken zur Wand."</p>
			<p class="calibre3">This phrase captures the same sense</p>
			<p class="calibre3">of being in a difficult, constrained situation.</p>
			<p class="calibre3">ChatGPT would take something like, “It’s raining cats and dogs.” Instead of translating it literally, it understands that it is raining heavily. It translates it more accurately using the German word for streams: “It’s raining in streams (heavily)” (Es regnet in Strömen). In Knowledge bases, we hope not to see these problems, but it is challenging to avoid idioms. I have used dozens in this book, and I feel it makes it more fun. But I have done my readers a disservice if they don’t translate well. Related to idioms is jargon.</p>
			<h3 class="calibre11">Jargon doesn’t translate well</h3>
			<p class="calibre3">Remember that some terms in your world might be well understood in other languages because they use the same word and don’t translate it. But don’t count on that as a strategy. Consider how technical jargon, shortcuts, acronyms, and initialisms play out in other languages. For example, <em class="italic">PIN</em> is short for <em class="italic">Personal Identification Number</em> for an ATM. In Germany, the<a id="_idIndexMarker327" class="pcalibre pcalibre1 calibre6"/> Geldautomat still uses a <em class="italic">Persönliche</em> <em class="italic">Identifikationsnummer</em>, and some form of PIN and ATM are typically understood. However, if the company’s vocabulary is not universal, account for it in the models, knowledge, or dictionaries. Related to this is how to speak to customers. It would be best to learn how to address them. Handling language jargon is slightly different than handling technical jargon. It might be well-known in <em class="italic">Database</em> circles to talk about <strong class="bold">DB </strong>or <strong class="bold">RDBMS</strong> (which stands for <strong class="bold">Relational Database Management System</strong>), so those might translate just as the letters, but generic language jargon should<a id="_idIndexMarker328" class="pcalibre pcalibre1 calibre6"/> be avoided. <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a><em class="italic">, Prompt Engineering,</em> helps address this to control the LLMs output. It is hard to catch these issues because we are so used to language. <em class="italic">Not seeing the forest for the trees</em> can be a challenge. Oops! There I go, using an idiomatic expression without even noticing.</p>
			<p class="calibre3">UI issues in LLM solutions can be addressed just like traditional GUIs. Topics such as right-to-left language and icon direction, using colors not to offend certain groups, and even removing culturally offensive imagery can be addressed. Still, thousands or millions of articles could generate a profound amount of rework to get them ready for translation. This is a cost hog.</p>
			<p class="calibre3">As designers and product leaders, we control the user experience, but we know those upstream knowledge sources will likely significantly impact it. So, spend the time making those ready for an international audience. Let’s review a few more language-related areas, starting with punctuation.</p>
			<h3 class="calibre11">Punctuation and grammar</h3>
			<p class="calibre3">A<a id="_idIndexMarker329" class="pcalibre pcalibre1 calibre6"/> funny story can make a point.</p>
			<p class="calibre3"><em class="italic">A panda walks into a bar. He orders a sandwich, eats it, then draws a gun and fires two shots in </em><em class="italic">the air.</em></p>
			<p class="calibre3"><em class="italic">“Why? Why are you behaving in this strange, un-panda-like fashion?” asks the confused waiter as the panda walks towards the exit. The panda produces a badly punctuated wildlife manual and tosses it over </em><em class="italic">his shoulder.</em></p>
			<p class="calibre3"><em class="italic">I’m a panda,” he says at the door. “Look it up.” The waiter turns to the relevant entry and, sure enough, finds </em><em class="italic">an explanation.</em></p>
			<p class="calibre3"><em class="italic">“Panda. Large black-and-white bear-like mammal native to China. Eats, shoots and leaves.”</em> – Lynne Truss (<em class="italic">Eats, Shoots &amp; </em><em class="italic">Leaves</em>)</p>
			<p class="calibre3">We do not control ChatGPT. So how does this help? Of course, each response from ChatGPT is not controlled by humans. Quality can be expected by ensuring the resources given are well written and monitoring its output to verify that it works as expected. We can’t expect ChatGPT to return a quality answer if the content shared is not written well. If it wasn’t clear, the statement should have been punctuated to explain that the panda “eats (bamboo) shoots and (tree) leaves.”</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If writing is not your strong suit, go beyond the required manuals of style reading. The book is also included in the online library.</p>
			<p class="callout">Book:<a href="https://amzn.to/3M7x8DH" class="pcalibre pcalibre1 calibre6"> Eats, Shoots &amp; Leaves: The Zero Tolerance Approach to Punctuation</a> by Lynne Truss (<a href="https://amzn.to/3M7x8DH" class="pcalibre pcalibre1 calibre6">https://amzn.to/3M7x8DH</a>) </p>
			<p class="calibre3">Grammar also applies to recommendations UIs. An LLM can be used behind the scenes to generate the data or text to insert into recommendations. Grammar and other issues, such as plurality, come into play. Consider the length of the messages and communications when writing these statements or messaging prompts to write well-written prose.</p>
			<h3 class="calibre11">Length of labels and strings</h3>
			<p class="calibre3">Test UIs for text expansion. For<a id="_idIndexMarker330" class="pcalibre pcalibre1 calibre6"/> example, if ChatGPT writes a notification, account for the length of the message. It is not unreasonable to see more than a 200% increase in word length when coming from English. The button <em class="italic">Edit,</em> in German, uses the word Bearbeiten. It is 150% longer. In Hungarian, Szerkesztése, clocks in at 200% longer. With ChatGPT powering a recommendation engine, ensure the UI has enough room to write the English and translated versions. Prompt engineering can be used to create instructions that limit the size of responses. In <em class="italic">Table 5.3</em>, the Hungarian translation is up to 53% longer. That is not too bad.</p>
			<table id="table003-4" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">String</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Language Details</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tip: Edit the bills for this Employee ID by the end of the day, or the state penalties </strong><strong class="bold">will accrue.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">English</p>
							<p class="calibre3">100 Characters</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tipp: A nap végéig szerkeszd meg ennek az alkalmazott azonosítójához tartozó számlákat, különben az állami </strong><strong class="bold">büntetések felhalmozódnak.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hungarian</p>
							<p class="calibre3">133 Characters</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tipp: Szerkeszd meg ennek az alkalmazottnak az azonosítójához tartozó számlákat a nap végéig, különben állami </strong><strong class="bold">büntetések keletkeznek.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hungarian (Google)</p>
							<p class="calibre3">136 Characters</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tipp: Szerkessze meg a számlákat ezzel a Munkavállalói Azonosítóval a nap végéig, különben az állami </strong><strong class="bold">büntetések felhalmozódnak.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hungarian (ChatGPT 3.5)</p>
							<p class="calibre3">147 Characters</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tipp: Szerkessze meg a számlákat az alábbi Munkavállalói azonosítóhoz a nap végéig, különben az állami bírságok </strong><strong class="bold">emelkedni fognak.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hungarian (ChatGPT 4o)</p>
							<p class="calibre3">153 Characters</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">请注意：请在今天结束之前编辑此雇员ID的账单，否则将会累积州的罚款。</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Chinese</p>
							<p class="calibre3">34 Characters</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Hinweis: Bearbeiten Sie die Rechnungen für diese Mitarbeiter-ID bis zum Ende des Tages, sonst werden staatliche </strong><strong class="bold">Strafen anfallen.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">German (ChatGPT 4o)</p>
							<p class="calibre3">142 Characters</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 5.3 – Comparison of English to Hungarian, Chinese, and German translations</p>
			<p class="calibre3">Sometimes, the opposite is true, and another language can be shorter. In Chinese, as shown, the character count is 34, but the double-byte character set takes up more space. Still, the issue with wrapping<a id="_idIndexMarker331" class="pcalibre pcalibre1 calibre6"/> and truncation typically occurs with longer text. For messages that are sentence length or longer, account for at least 50% growth; for shorter items such as labels, consider 100–200%, depending on the languages supported. A reasonable guideline is a minimum of 30% plus two extra characters. However, if the design can accommodate larger text, there is no harm in most cases. If there are tables where excessive wrapping would result, consider creating layouts for the other languages to accommodate their unique situation. For A11y, consider customers zooming in and scaling text, which can also make wrapping and truncation an issue. This can also impact how fields appear with their text. In some languages, such as German, compound words have unique rules for where to wrap. For example, in a human resource solution, there are labels for absence batch parameters, so when an absence job (vacation, holidays, or sick time) was run on a schedule, it knew the properties to use. The translation from an AI can vary dramatically:</p>
			<ul class="calibre7">
				<li class="calibre8">Absence batch parameters (English)</li>
				<li class="calibre8">Abwesenheits-Sammelverarbeitungsparameter (literal in German)</li>
				<li class="calibre8">Fehlzeitenerfassung im Stapel-Modus Einstellungen (descriptive version)</li>
				<li class="calibre8">Einstellungen für die Stapelverarbeitung von Abwesenheitszeiten (descriptive focusing on the batch process)</li>
				<li class="calibre8">Stapelverarbeitung von Abwesenheitszeiträumen (common in HR software)</li>
				<li class="calibre8">Mitarbeiter-Abwesenheiten Sammelbearbeitung (emphasis on the employee)</li>
			</ul>
			<p class="calibre3">A human <a id="_idIndexMarker332" class="pcalibre pcalibre1 calibre6"/>translator might settle on Abwesenheitsbatchparameter; notice there are no spaces, so wrapping in a UI might be an issue. If words are not wrapped correctly for the language, the customer will view it as a bug.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Consider whether abbreviations can cause displays to be off. Not all languages have the concept of abbreviations. Understand how to translate these as whole words and have room for them in Chinese or Arabic. Some languages might not recognize a character as a word to translate (“#” for number, “Q1” for quarter one, “ft” (feet) might be better calculated in meters outside of the USA, “info” might not translate as “information,” etc.). FYI, GPT 4o-mini understands <em class="italic">#</em> and <em class="italic">Q1</em> in translations and converts them correctly to <em class="italic">number</em> and <em class="italic">first quarter</em>.</p>
			<p class="calibre3">Leave ample space to avoid using ellipses with truncation. Ellipses must be used if a word is truncated, but try to prevent truncation. Be sure the user can read the entire label or text. I have seen many UIs that show truncation with ellipses (<strong class="bold">…</strong>), but there is no way to read what is there; not all components have a tooltip. And worse, when translated, the order of words can be different. “<strong class="bold">Customer Number</strong>” might be truncated in English as “<strong class="bold">Customer N..</strong>” leaving helpful information. In Spanish, the truncated version of “<strong class="bold">Número de cliente</strong>” is “<strong class="bold">Número de ..</strong>”, leaving nothing of value in the visible label. That is a failure for the user experience and frustrating for the customer.</p>
			<p class="calibre3">I created a simple Google sheet, as shown in <em class="italic">Figure 5</em><em class="italic">.16</em>, to test length issues. Enter a string into the spreadsheet, and the tool will highlight the languages with much larger lengths. This is good for understanding how small words or phrases can grow in length. This is not perfect, as this is Google’s translation, but it is fast and cheap. Clone this for your<a id="_idIndexMarker333" class="pcalibre pcalibre1 calibre6"/> purposes.</p>
			<p class="calibre3">Tool: <a href="https://docs.google.com/spreadsheets/d/1P-FLn8Kc4wcOgFbUfGuCamAL7O6IXvF_qkDAhvS8QdA/edit#gid=0" class="pcalibre pcalibre1 calibre6">Translation length tester</a> (<a href="https://docs.google.com/spreadsheets/d/1P-FLn8Kc4wcOgFbUfGuCamAL7O6IXvF_qkDAhvS8QdA/edit#gid=0" class="pcalibre pcalibre1 calibre6">https://docs.google.com/spreadsheets/d/1P-FLn8Kc4wcOgFbUfGuCamAL7O6IXvF_qkDAhvS8QdA/edit#gid=0</a>)</p>
			<p class="calibre3">If you are using an LLM for UI text, make sure there is plenty of room in the UI for these long translations.</p>
			<div><div><img src="img/B21964_05_16.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.16 – Example of the Google sheet you can use for quick length checking</p>
			<h3 class="calibre11">Concatenation</h3>
			<p class="calibre3">One great trick in ChatGPT could be to combine a defined statement template with the output from ChatGPT. In examples such as “<code>It is recommended to " + &lt;ChatGPT response&gt;</code>, or <code>"Refill the shipping container by " + &lt;ChatGPT response of a time&gt; + " today."</code>, this will experience translation problems. The structure of a sentence in English is not the same for other languages. This static part of the text might be at the end of the sentence. Break up the answer into two distinct pieces. Create the recommendation title with static text and then generate the <em class="italic">entire</em> recommendation from the model. In these examples, put that recommendation in a box labeled <code>Recommended Actions</code>. Or label the time <code>Today's Refill Container Deadline</code> so the output “<code>3:45 PM</code>” stands alone.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Ask ChatGPT to translate the entire string. That is better than writing code to create the formatting for each language.</p>
			<p class="calibre3">Let me explore the complexities of translation a little more. Plurals are one of the most well-known language problems.</p>
			<h3 class="calibre11">Plurals</h3>
			<p class="calibre3">Plurals are one of the more complex issues with translations. With a chat experience,  ChatGPT handles this, and this topic can be skipped. However, if the bot is recommended with <em class="italic">templates</em> to fill in pieces of text coming from ChatGPT, this situation can get complex. In English, there are simple rules; we can use a notification alerting the user to their vacation balance as an example:</p>
			<ul class="calibre7">
				<li class="calibre8">Zero: You have no days off remaining.</li>
				<li class="calibre8">One: You have 1 day off remaining.<ul class="calibre19"><li class="calibre8">You have one day off remaining. (alternative)</li></ul></li>
				<li class="calibre8">Many: You have 23 days off remaining.</li>
			</ul>
			<p class="calibre3">English has three cases for plurality. A special rule for zero is useful (so the cleaner textual <em class="italic">no</em> can be used instead of a zero). The singular word <em class="italic">day</em> is used for one, and all other numbers use plural <em class="italic">days</em>.</p>
			<p class="calibre3">It is easy to write a rule in software to account for this:</p>
			<pre class="source-code">
if days == 0:
    print("You have no days off remaining.")
elif days == 1:
    print("You have one day off remaining.")
else:
    print("You have " +str(days)+ " days off remaining.")</pre>			<p class="calibre3">This could work for negative balances, but a good UX person would get one more condition added. This gets more complex when doing this logic in other languages because many languages have different rules. To accommodate languages, there are software and standards to account for zero, one, two, a few, many, and other use cases. In addition to one noun form for the singular and another noun form for the plural, as in English, different languages have unique noun forms when the count of the object is two (“dual”) or a few (“paucal”), or when the number ends in one or ends in zero… There are many special rules! As shown in the preceding example, spell words for small numbers (1 to 9) in English. This can make every solution grammatically correct but more effort to code. To go deeper into the complexity of using numbers, see this reference:</p>
			<p class="calibre3">Article: <a href="https://www.masterclass.com/articles/when-to-spell-out-numbers-explained" class="pcalibre pcalibre1 calibre6">When to spell out numbers</a> (<a href="https://www.masterclass.com/articles/when-to-spell-out-numbers-explained" class="pcalibre pcalibre1 calibre6">https://www.masterclass.com/articles/when-to-spell-out-numbers-explained</a>)</p>
			<p class="calibre3">As mentioned, if ChatGPT outputs a complete thought, it should follow the correct rules. Work is needed to create a hybrid experience where the output includes numbers in static messages, such as recommendation text. The resources listed later in this section provide some more detailed explanations. Here is an example of English and Czech, which is not even that complex.</p>
			<pre class="source-code">
You have {COUNT, plural, one {# mail} other {# mails}} in your inbox.
You have {COUNT, plural, one {# mail} few {# mails} many {# mails} other {# mails}} in your inbox.
V doručené poště máte {COUNT, plural, one {# zprávu} few {# zprávy} many {# zprávy} other {# zpráv}}.</pre>			<p class="calibre3">This format shows how the translated strings support the corresponding plural forms. Don’t expect to inject numbers directly into ChatGPT responses. Either let it do it correctly or write the code. <em class="italic">Table 5.4</em> shows one end-to-end example, including what not to do, what to do, and how it will look when done.</p>
			<table id="table004-3" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Don’t </strong><strong class="bold">Do This</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Readable &amp; </strong><strong class="bold">Translatable</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Example Output</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">I’m ready to submit your invoice with {0} and {1}. What should we name the invoice?</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">I’m ready to submit your report with {NUM_ITEMS, plural, =1 {1 item for} one {# items totaling} other {# items totaling}} {AMOUNT} {CURRENCY} and {NUM_ITEMS1, plural, one {# foreign currency items} other {# foreign currency items}}. What should we name the invoice?</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">I’m ready to submit your invoice with 5 items totaling 140 USD and 1 foreign currency item. What should we name the invoice?</p>
							<p class="calibre3">I’m ready to submit your invoice with five items totaling 140 USD and one foreign currency item. What should we name the invoice?</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 5.4 – Example of a string to be written in ICU format for translation</p>
			<p class="calibre3">Notice that the variables are readable, not just 0s and 1s. Do this to validate that the statements are readable quickly. Good design thinking extends into the code sometimes. Whether these variables are numbers or words must be known to translate or validate. The specific number needs to be known if they are numbers so the code can generate the correct format. Notice I provided two example outputs, one using numbers and one using number words (the written form). I prefer numerals for numbers<a id="_idIndexMarker334" class="pcalibre pcalibre1 calibre6"/> below 10 in UIs, even though they are not grammatically correct in English. It helps these values stand out and prevents the user from having to read the entire text. People don’t read!</p>
			<p class="callout-heading">Additional references for plural resources</p>
			<p class="callout">Article: <a href="https://lingohub.com/blog/pluralization" class="pcalibre pcalibre1 calibre6">Pluralization</a> (<a href="https://lingohub.com/blog/pluralization" class="pcalibre pcalibre1 calibre6">https://lingohub.com/blog/pluralization</a>)</p>
			<p class="callout">Article: Plural<a href="https://cldr.unicode.org/index/cldr-spec/plural-rules" class="pcalibre pcalibre1 calibre6"> Rules for Internationalization</a> (<a href="https://cldr.unicode.org/index/cldr-spec/plural-rules" class="pcalibre pcalibre1 calibre6">https://cldr.unicode.org/index/cldr-spec/plural-rules</a>)</p>
			<p class="calibre3">How to handle caps in design may be less exciting and less well-known. This is not specific to conversational AI, but it is still helpful to realize when someone wants to use them in recommendations.</p>
			<h3 class="calibre11">ALL CAPS</h3>
			<p class="calibre3">Don’t ask ChatGPT to return output in ALL CAPS. To format for emphasis, use <strong class="bold">Bold</strong>, for example. Not only <a id="_idIndexMarker335" class="pcalibre pcalibre1 calibre6"/>are all caps harder to read in English, but there are also languages where this is not acceptable (French and Greek) and has no equivalent in some languages (Chinese and Arabic). Avoid this problem by not using all caps and telling the LLM to avoid it. STRINGS IN UPPERCASE ARE SIGNIFICANTLY HARDER TO READ. It is not suggested even for titles, tables, or labels. Use Title Case, as used in newspaper headlines. For database fields that are stored in uppercase, change it, edit the strings, or, as a last resort, force them to be lowercase. The 5–10% improvement in readability is worth it.</p>
			<p class="callout-heading">Work and letter recognition</p>
			<p class="callout">Learn more about some of the research on word and letter recognition:</p>
			<p class="callout">Article: <a href="https://learn.microsoft.com/en-us/typography/develop/word-recognition" class="pcalibre pcalibre1 calibre6">The Science of Word Recognition</a> (<a href="https://learn.microsoft.com/en-us/typography/develop/word-recognition" class="pcalibre pcalibre1 calibre6">https://learn.microsoft.com/en-us/typography/develop/word-recognition</a>)</p>
			<h3 class="calibre11">Accounting for locales</h3>
			<p class="calibre3">Designing for locales involves considering how a specific region or country handles something. For example, if building a scheduling service and someone asks, “<em class="italic">Book a hotel for this weekend</em>,” what nights would that booking be for? In the US, it would be for Friday and Saturday nights. Makes sense? However, different countries have different definitions of<a id="_idIndexMarker336" class="pcalibre pcalibre1 calibre6"/> the weekend. In some Muslim countries in the Middle East, it would be for Thursday and Friday, while in Iran, the weekend is only Friday night, as they observe a six-day work week. ChatGPT understands these concepts to some extent, but make sure integrations also have this understanding. Many ideas and words can be locale-specific. For example, when working on the design of an expense assistant, it understands the expense of a car, taxi, Uber, Lyft, Limo, etc. But there are Didi, BlaBlaCar, Cabify, and many other services in various countries. Ensuring models support the locale-specific concepts will make the experience more robust. Sometimes, it is not just a country-specific product or service; it could be jargon covered earlier in the chapter. If the UI will handle understanding the customer’s work week, it should likely learn how to address the customer properly.</p>
			<h3 class="calibre11">Addressing a customer and vocative case</h3>
			<p class="calibre3">Many UIs start with “Hello, Max!” or “Welcome, Madison.” A direct translation will not<a id="_idIndexMarker337" class="pcalibre pcalibre1 calibre6"/> work because, in some cultures, addressing someone by their first name is inappropriate.</p>
			<p class="calibre3">My friend shared an excellent example of how formal or complex it is to speak to the customer in their name. I have shared this in <em class="italic">Table 5.5</em>. So be sure to have enough information to accommodate their first name, last name, or various forms of their names (the fancy term is vocative declension), depending on the language.</p>
			<table id="table005-2" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Language</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Problem</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Basic Name</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Example</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">English</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">None</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Mark Stevens</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hello, Mark</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Japanese</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Requires last name + honorific</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Yoko Ono</p>
							<p class="calibre3">Akira Kurosawa</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hello, <strong class="bold">Ono-san</strong></p>
							<p class="calibre3">Welcome, <strong class="bold">Kurosawa-san</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Arabic</strong></p>
							<p class="calibre3"><strong class="bold">(Latvian, </strong><strong class="bold">Lithuanian, Vietnamese)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Prefers polite address</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Mohamed Hassan</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Hello Mr. Mohamed (suitable for a welcome screen)</p>
							<p class="calibre3">Dear <strong class="bold">Mr.</strong> Mohamed,</p>
							<p class="calibre3">Alt: Dear <strong class="bold">Mr. Hassan</strong> (for email)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Czech, Polish</strong></p>
							<p class="calibre3"><strong class="bold">(Greek, </strong><strong class="bold">Latvian, Lithuanian)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Requires vocative declension</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Petr<strong class="bold">a</strong> Lukáš</p>
							<p class="calibre3">Mar<strong class="bold">ek</strong> Martin</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Vitejte, Petr<strong class="bold">o</strong></p>
							<p class="calibre3">Dobrý den, Lukáš<strong class="bold">i</strong></p>
							<p class="calibre3">Milý Mar<strong class="bold">ku</strong></p>
							<p class="calibre3">Martin<strong class="bold">e</strong>, jak vám mohu pomoci?</p>
							<p class="calibre3">(notice o, i, u, and e at name ends)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 5.5 – Direct address in various languages that can cause issues</p>
			<p class="calibre3">If all else fails, <em class="italic">don’t use it at all, or don’t use it in those languages</em>. One workaround is to use an email address. I don’t recommend it. It is better to say “Hello” than “Hello, jill@miller.com.” Software can be used to build declensions (changes to the ending of words, in this case, for the person’s name) for specific languages. I asked ChatGPT to do it for Hungarian, and it generated Python code. It doesn’t have to be a design problem; it is something to be aware of when using people’s names in the experience:</p>
			<pre class="source-code">
def decline_name(name, case):
    declensions = {
        'nominative': '',
        'accusative': 't',
        'dative': 'nak/nek',
        'genitive': 'é',
        # Add other cases as needed
    }
    # Handle special cases or irregular declensions
    special_cases = {
        'János': {
            'accusative': 'Jánost',
            'dative': 'Jánosnak'
        }
        # Add other special cases
    }
    if name in special_cases and case in special_cases[name]:
        return special_cases[name][case]
    suffix = declensions.get(case, '')
    # Apply vowel harmony rules or other specific rules
    if case == 'dative':
        if name[-1] in 'aeiou':
            suffix = 'nak'
        else:
            suffix = 'nek'
    return name + suffix
# Example usage
name = "János"
case = "dative"
print(decline_name(name, case)) # Output: Jánosnak</pre>			<p class="calibre3">One nice thing about a ChatGPT solution is that it can ask how they want to be addressed. Even if ChatGPT can’t remember this from one session to the next, store it in a setup variable and then remind ChatGPT how to address this customer. ChatGPT will see enterprise data with people’s names when helping to compose customer emails. If <a id="_idIndexMarker338" class="pcalibre pcalibre1 calibre6"/>working in an international arena, ensure this is handled correctly. Addressing the customers is not the only cultural-specific issue.</p>
			<h3 class="calibre11">Cultural and bi-directional hiccups</h3>
			<p class="calibre3">If customers use Arabic or Hebrew, be reminded that responses that include images or icons might not work as well or as intended without a flipped<a id="_idIndexMarker339" class="pcalibre pcalibre1 calibre6"/> version. These languages are read from right to left. If an arrow is a pointer to a list of items (or any icon representing forward motion), it will look odd, with the arrow pointing the wrong way. Icons such as text bubbles, arrows, toggle icons, audio controls, pagination, progress indicators, and drop-down menu icons must be orientated for reading from right to left. There are issues with some icons in some cultures. These issues still apply in conversational AI. Thumbs up in some cultures is offensive. I learned that the hard way!</p>
			<p class="calibre3">Article: <a href="https://material.io/blog/localization-principles-techniques" class="pcalibre pcalibre1 calibre6">Cultural design</a> (<a href="https://material.io/blog/localization-principles-techniques" class="pcalibre pcalibre1 calibre6">https://material.io/blog/localization-principles-techniques</a>)</p>
			<p class="calibre3">A deeper dive into the bi-directional issues can be found here:</p>
			<p class="calibre3">Article: <a href="https://m2.material.io/design/usability/bidirectionality.html#mirroring-layout" class="pcalibre pcalibre1 calibre6">Bidirectionality issues</a> (<a href="https://m2.material.io/design/usability/bidirectionality.html#mirroring-layout" class="pcalibre pcalibre1 calibre6">https://m2.material.io/design/usability/bidirectionality.html#mirroring-layout</a>)</p>
			<p class="calibre3">Be aware of cultural differences when generating solutions with ChatGPT. Use prompts and verify culturally appropriate answers with native speakers or a trusted model. The more the design supports these small things, the more customer trust is built.</p>
			<h2 id="_idParaDest-127" class="calibre9"><a id="_idTextAnchor129" class="pcalibre pcalibre1 calibre6"/>Trust</h2>
			<p class="calibre3">We have all heard about trust issues. If the AI provides bad or wrong data, this can quickly derail a conversation and cause the customer to lose trust in the AI. This is the same as when working with a human agent. As soon as a human agent says something so silly and wrong, it derails<a id="_idIndexMarker340" class="pcalibre pcalibre1 calibre6"/> the conversation, and the tone of the interaction will immediately change.  The goal is to mitigate these errors and issues. This next part might feel like a TV show, but here are the top 10 ways to improve trust in a ChatGPT experience, in reverse order.</p>
			<h3 class="calibre11">10. Regular updates</h3>
			<p class="calibre3">When appropriate, let folks <a id="_idIndexMarker341" class="pcalibre pcalibre1 calibre6"/>know the staleness of results. For example, if they ask a time-dependent question that can be easily changed based on recent information, tell them when the model was last updated. “<em class="italic">I see that the answer to this question has changed repeatedly, but as of July 5, 2024, it is…</em>”, and “<em class="italic">My information is up to date as of last week…</em>”. Do not let customers think they have the most current answer; they will act on that. It would be better not to answer at all. Even recommendations might need some supporting info to be clear that the recommendation is based on the latest information. This also applies to backend services. Sometimes, it is worth showing what data was last ingested or the last update time and name of the file. <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a>, <em class="italic">Prompt Engineering</em>, can address this. These little things can help build trust.</p>
			<h3 class="calibre11">9. Empower users</h3>
			<p class="calibre3">With tools to <a id="_idIndexMarker342" class="pcalibre pcalibre1 calibre6"/>customize the experience, make it apparent this is an option and how to adjust. They will trust the system differently if they feel in control regarding the UI, privacy, data storage, and other essential factors. This is about understanding and then implementing use cases that empower the user. Speaking in their language using terms they are comfortable with is an empowering feeling.</p>
			<h3 class="calibre11">8. Ethics</h3>
			<p class="calibre3">As mentioned, most <a id="_idIndexMarker343" class="pcalibre pcalibre1 calibre6"/>enterprise use cases don’t delve into ethical concerns. However, in problematic areas around medical decisions, legal ramifications, lending practices, driving decisions, government practices, personal privacy, mental health, or other answer spaces where ethics is essential, know that the answers might not be the right choice. Avoid these topics, when possible, implement extensive safeguards, and consistently monitor this. Lawyers will likely get involved in providing lengthy disclaimers. That is the way of the world. Prompt chaining, by using one ChatGPT to check the work of another one’s output, can help to verify the output.</p>
			<h3 class="calibre11">7. Bias</h3>
			<p class="calibre3">Regularly monitor and address biases in responses. Implement measures to minimize biased outputs and ensure fair<a id="_idIndexMarker344" class="pcalibre pcalibre1 calibre6"/> treatment of all users, regardless of demographics. Consider whether the knowledge base contains these biases. <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content is King</em> is next and will go deeper into this subject. Use emerging tools to check and monitor output for bias.</p>
			<h3 class="calibre11">6. Privacy and security</h3>
			<p class="calibre3">Recall how<a id="_idIndexMarker345" class="pcalibre pcalibre1 calibre6"/> easy it is for someone to share data with a general public model without realizing the implications. The more significant consideration in enterprise models might be at the company level. Does company A’s model impact other customers’ models? Does the business run on a model affected by all customer engagements? Product owners must ensure that company-sensitive data is not making its way to other companies. By siloing customer data and with independent model updates, then a good chance of protection at the company level. This also means either a lot more work to help every customer’s model improve, outsourcing this improvement to the customer or third parties, automation, or ignoring the problem. The reason why so many first-generation chatbots failed is that they ignored the problem. Don’t fail. Put checks in place so systems can’t be manipulated to share the wrong data. Some platforms, such as Salesforce, cover this extensively.</p>
			<p class="calibre3">Ensuring that only the right people in the company have the correct access is still a challenge. Just because someone works for the same company doesn’t mean they deserve access. Sales, acquisitions, financials, and human resources all demand security. Salesforce goes out of its way to remind people that “Your data is your data. Your data is not our product.” This would seem a pretty clear line. The downside can mean less competent models without sharing data across companies. It is possible that improvements learned in one data silo might not work in another. So, there is more to monitoring and improving. A real challenge to scale for the enterprise.</p>
			<p class="calibre3">The bigger the company, the more it has to lose and the less risk it is willing to take. Security is a big deal, and I suggest <a id="_idIndexMarker346" class="pcalibre pcalibre1 calibre6"/>spending the extra time and effort on <a id="_idIndexMarker347" class="pcalibre pcalibre1 calibre6"/>security audits, <strong class="bold">penetration</strong> (<strong class="bold">PEN</strong>) testing, performance tuning, and usability testing.</p>
			<h3 class="calibre11">5. User feedback</h3>
			<p class="calibre3">The general feeling <a id="_idIndexMarker348" class="pcalibre pcalibre1 calibre6"/>of user feedback is that it goes into a black hole when given. Sometimes, feedback is anonymous, so it is hard to communicate directly with the user. Occasionally, customers are asked for follow-up or to provide their information if further questions are needed. One way to build trust is to listen to and communicate feedback. If they provided their email, do more than send automated emails that their feedback was sent. That doesn’t build much trust. Even this step could be automated with an LLM to provide a more thoughtful version of a “we are looking at your issue” response.  A model can respond in a few ways:</p>
			<ul class="calibre7">
				<li class="calibre8">That a feature request is in the works by comparing the request to existing published plans</li>
				<li class="calibre8">Sharing existing bugs filed, comparing against existing bugs</li>
				<li class="calibre8">Provide a link to monitor an existing bug or community threads</li>
				<li class="calibre8">Provide alternatives based on a knowledge search</li>
			</ul>
			<p class="calibre3">All ideas support the idea that there is a loop in the feedback process. Let the humans do the more complex work and let the LLM assistant handle minor interactions.</p>
			<p class="calibre3">For anonymous feedback, point users to documentation or help sites that collect and communicate about the feedback. If they see that people like them are being listened to, they may gain some trust in the solution.</p>
			<p class="calibre3">It is wonderful to ask users for feedback proactively. Very few customers will respond, and it can be unpleasant to ask, especially if the user is in the middle of something important. Although covered in <a href="B21964_02_split_000.xhtml#_idTextAnchor031" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 2</em></a><em class="italic">, Conducting Effective User Research</em>, it is an excellent time to remind folks with some tips for gathering feedback:</p>
			<ul class="calibre7">
				<li class="calibre8">Don’t require feedback. Don’t request feedback at every turn or for every customer (use sampling).</li>
				<li class="calibre8">Keep feedback simple, such as “<em class="italic">Did we help solve your problem today?</em>” Based on the answer, probe why not.</li>
				<li class="calibre8">Someone (the LLM?) must follow up if they were asked for contact information.</li>
				<li class="calibre8">Log the context of feedback. If they are prompted while <em class="italic">creating</em> an urgent service request , "Is your problem solved?", the answer is no. Consider <em class="italic">when</em> to request feedback so relevant questions are asked.</li>
			</ul>
			<h3 class="calibre11">4. Consistent style and tone</h3>
			<p class="calibre3">This book spends a lot of time on style and tone, which impact trust. Maintaining a consistent communication style lets customers know what is expected. However, this doesn’t mean the style and tone can’t be changed. If the situation calls for it, then the tone should be understandable for that context. Again, it becomes part of the instructions shared with the LLM, covered starting in <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a><em class="italic">, </em><em class="italic">Prompt Engineering</em>.</p>
			<h3 class="calibre11">3. Explainability</h3>
			<p class="calibre3">In a conversational UI, this is the way, while in a GUI or bot use case, they might have an <strong class="bold">Info</strong> button, more details, or <a id="_idIndexMarker349" class="pcalibre pcalibre1 calibre6"/>some element to <em class="italic">please explain</em>. I used the <strong class="bold">Info</strong> (i) icon for a decade next to simple recommendations to link to more details or provide it in a window. Sometimes, people want to know more details and the reasoning behind a decision. This can build trust to expose the reasoning; if the reasoning is sound, it can enhance that trust factor. The UI can use this to help guide the customer, building trust again. This is covered in <a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 9</em></a><em class="italic">, Guidelines </em><em class="italic">and Heuristics</em>.</p>
			<h3 class="calibre11">2. Transparency</h3>
			<p class="calibre3">This is more important for a <a id="_idIndexMarker350" class="pcalibre pcalibre1 calibre6"/>Chat AI than a bot or recommendation. Be clear communication is with an AI when in an actual conversation. When a UI pops up a simple recommendation or suggestion, it is a less compelling need to say precisely <em class="italic">how</em> this was generated. And it is likely already a combination of AI and other tools. An earlier section in this chapter, <em class="italic">Designing a recommender and behind-the-scenes experiences</em>, details communicating with an AI behind the scenes. See the section earlier in this chapter.</p>
			<h3 class="calibre11">1. Accuracy and relevance</h3>
			<p class="calibre3">There is a reason why this is<a id="_idIndexMarker351" class="pcalibre pcalibre1 calibre6"/> number one. And because this is only an ordered list, it is not apparent how much more important this is than the nine previous items. If you read the previous chapter’s discussion on ranking versus scoring, now this might make more sense. Accuracy and relevance could be as important as <em class="italic">all the other issues combined</em>. Without accurate and relevant answers, the solution is doomed. There can be some flexibility with other trust issues, but not so much with wrong answers. Sometimes, the problem can be much worse if they trust it is the correct answer and do not understand enough to recognize it is wrong. That is the worst problem to have. An incorrect answer allows the customer to dismiss the answer, ignore the answer, and possibly leave disgruntled. However, a wrong answer that looks right can cause downstream repercussions based on customer decisions. Include the right resources to formulate answers and create test cases to detect issues (more on testing in <a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 10</em></a><em class="italic">, Monitoring and Evaluation</em>). LLM solutions require care and feeding to uncover these concerns rapidly. User feedback can only catch known errors; it won’t catch unknown errors. Those are hard. Build <a id="_idIndexMarker352" class="pcalibre pcalibre1 calibre6"/>expertise to tune your radar to find unknown errors. The following chapters on prompt engineering and fine-tuning provide techniques to be accurate. Given that the goal is to build trust, security can go a long way to help with trust. It is logical to finish this chapter on this important topic.</p>
			<h2 id="_idParaDest-128" class="calibre9"><a id="_idTextAnchor130" class="pcalibre pcalibre1 calibre6"/>Security</h2>
			<p class="calibre3">Security takes many forms. At a <a id="_idIndexMarker353" class="pcalibre pcalibre1 calibre6"/>minimum, conversations should be end-to-end encrypted; the user already gets point-to-point encryption with the typical web HTTPS interaction. Custom applications should not do less, while some channels like SMS are already inherently insecure. Vendors make a point of promoting security in their apps. Consider what happens to the data within the enterprise network after the HTTPS connection has landed and information is shared with backend services or a database.</p>
			<p class="calibre3">Is this data safe from prying eyes? For example, some companies don’t allow staff to accept credit card information over the phone. Shield this information from insider exploitation using a virtual agent to receive and confirm payment information. This might even feel safer to customers; the virtual agent can be used to market trust.</p>
			<p class="calibre3">Consider how models are being updated and with what data. Customer data must be isolated in the enterprise and can’t leak into other customers’ models. This book is for applying UX-centric design methods to enterprise solutions; our advice in this space is limited to making sure the customer’s data is secure and communicating this detail to the customer. This is the same for any prompt engineering efforts where instructions must include details so the user’s prompt has context. <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a><em class="italic">, Prompt Engineering,</em> covers this. The design also has to account for when this data is unavailable because the user is not permitted to access it. For example, create context around sales deals so that users can ask more detailed questions about the deal. Some salespeople might not have full access to the details, so consider this when framing the prompts.</p>
			<p class="calibre3">The takeaway concerning security is to be the customer’s advocate and ensure that the conversation is safe and will not fall into the wrong hands. Not all data and content will be stored in a secure channel. Integrations with other services, or even access to some knowledge, might be limited to specific audiences, and LLM integration needs to <a id="_idIndexMarker354" class="pcalibre pcalibre1 calibre6"/>account for this. Integrations become even more critical in the next section, which discusses the hybrid UI/chat experience issues.</p>
			<h1 id="_idParaDest-129" class="calibre5"><a id="_idTextAnchor131" class="pcalibre pcalibre1 calibre6"/>Summary</h1>
			<p class="calibre3">Learn the capabilities of the tools in your framework, or better yet, help find the right tools to move the user experience bar forward. Every tool has capabilities and limitations. For any experience, the UX implications of accessibility, trust security, language, and internationalization support are likely a given. We hope the guidance, tricks, and tips help create a <strong class="bold">Functional, Usable, Necessary, and Engaging</strong> (<strong class="bold">FUN-E</strong>) experience. Strive for all four attributes (remember it as <em class="italic">funny</em>).</p>
			<p class="calibre3">It is time to build a ChatGPT solution. Use cases should be ready to develop, and the context of use should be known. The context of most experiences is easy to figure out. In many cases, the context of use is not a choice. If the company provides phone support, a voice-only experience is a given. This is where we change gears and go from UI-centric discussions about generative AI solutions to model-centric discussions with an eye toward UI practices. Integrating enterprise data, like knowledge, databases, and other services, is next.</p>
			<h1 id="_idParaDest-130" class="calibre5"><a id="_idTextAnchor132" class="pcalibre pcalibre1 calibre6"/>References</h1>
			<table id="table006" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div><div><img src="img/B21964_QR.jpg" alt="" role="presentation" class="calibre4"/>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The links, book recommendations, and GitHub files in this chapter are posted on the reference page.</p>
							<p class="calibre3">Web Page: <a href="https://uxdforai.com/references#C5" class="pcalibre pcalibre1 calibre6">Chapter 5 References</a> (<a href="https://uxdforai.com/references#C5" class="pcalibre pcalibre1 calibre6">https://uxdforai.com/references#C5</a>)</p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>