["```py\n    import sqlite3\n    import pandas as pd\n    ## creating a connection\n    database = 'chinook.db'\n    conn = sqlite3.connect(database)\n    ## importing tables\n    tables = pd.read_sql(\"\"\"SELECT name, type\n                            FROM sqlite_master\n                             WHERE type IN (\"table\", \"view\");\"\"\", conn) \n    ```", "```py\npd.read_sql(\"PRAGMA table_info(customers);\", conn)\nprint(customer_columns) \n```", "```py\n    pd.read_sql(\"\"\"\n    SELECT c.country AS Country, SUM(i.total) AS Sales\n    FROM customer c\n    JOIN invoice i ON c.customer_id = i.customer_id\n    GROUP BY Country\n    ORDER BY Sales DESC\n    LIMIT 5;\n    \"\"\", conn) \n    ```", "```py\n    import matplotlib.pyplot as plt\n    # Define the SQL query\n    sql = \"\"\"\n    SELECT g.Name AS Genre, COUNT(t.track_id) AS Tracks\n    FROM genre g\n    JOIN track t ON g.genre_id = t.genre_id\n    GROUP BY Genre\n    ORDER BY Tracks DESC;\n    \"\"\"\n    # Read the data into a dataframe\n    data = pd.read_sql(sql, conn)\n    # Plot the data as a bar chart\n    plt.bar(data.Genre, data.Tracks)\n    plt.title(\"Number of Tracks by Genre\")\n    plt.xlabel(\"Genre\")\n    plt.ylabel(\"Tracks\")\n    plt.xticks(rotation=90)\n    plt.show() \n    ```", "```py\n    from langchain.agents import create_sql_agent\n    from langchain.llms import OpenAI\n    from langchain.chat_models import ChatOpenAI\n    from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n    from langchain.sql_database import SQLDatabase\n    from langchain.llms.openai import OpenAI\n    from langchain.agents import AgentExecutor\n    from langchain.agents.agent_types import AgentType\n    from langchain.chat_models import ChatOpenAI\n    llm = OpenAI()\n    db = SQLDatabase.from_uri('sqlite:///chinook.db')\n    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n    agent_executor = create_sql_agent(\n        llm=llm,\n        toolkit=toolkit,\n        verbose=True,\n        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    ) \n    ```", "```py\n    [tool.name for tool in toolkit.get_tools()] \n    ```", "```py\n['sql_db_query', 'sql_db_schema', 'sql_db_list_tables', 'sql_db_query_checker'] \n```", "```py\n    agent_executor.run(\"Describe the playlisttrack table\") \n    ```", "```py\n> Entering new AgentExecutor chain...\nAction: sql_db_list_tables\nAction Input:\nObservation: album, artist, customer, employee, genre, invoice, invoice_line, media_type, playlist, playlist_track, track\nThought: The table I need is playlist_track\nAction: sql_db_schema\nAction Input: playlist_track\nObservation:\nCREATE TABLE playlist_track (\n[...]\n> Finished chain.\n'The playlist_track table contains the playlist_id and track_id columns. It has a primary key of playlist_id and track_id. There is also a foreign key reference to the track and playlist tables. Sample rows include (1, 3402), (1, 3389), and (1, 3390).' \n```", "```py\nprint(agent_executor.agent.llm_chain.prompt.template) \n```", "```py\nYou are an agent designed to interact with a SQL database.\nGiven an input question, create a syntactically correct sqlite query to run, then look at the results of the query and return the answer.\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\nYou have access to tools for interacting with the database.\nOnly use the below tools. Only use the information returned by the below tools to construct your final answer.\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\nIf the question does not seem related to the database, just return \"I don't know\" as the answer.\nsql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', using sql_db_schema to query the correct table fields.\nsql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. \nBe sure that the tables actually exist by calling sql_db_list_tables first! Example Input: 'table1, table2, table3'\nsql_db_list_tables: Input is an empty string, output is a comma separated list of tables in the database.\nsql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\nUse the following format:\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker]\nAction Input: the input to the action\n...\nQuestion: {input}\nThought: I should look at the tables in the database to see what I can query.  Then I should query the schema of the most relevant tables.\n{agent_scratchpad} \n```", "```py\nagent_executor.run('what is the total number of tracks and the average length of tracks by genre?') \n```", "```py\n> Entering new AgentExecutor chain...\nAction: sql_db_list_tables\nAction Input:\nObservation: album, artist, customer, employee, genre, invoice, invoice_line, media_type, playlist, playlist_track, track\nThought: I should look at the schema of the track and genre tables.\nAction: sql_db_schema\nAction Input: track, genre\n[…] \n```", "```py\n'The top 10 genres by track count and average track length are Rock (1297 tracks with an average length of 283910.04 ms), Latin (579 tracks with an average length of 232859.26 ms), Metal (374 tracks with an average length of 309749.44 ms), Alternative & Punk (332 tracks with an average length of 234353.85 ms), Jazz (130 tracks with an average length of 291755.38 ms), TV Shows (93 tracks with an average length of 2145041.02 ms), Blues (81 tracks with an average length of 270359.78 ms), Classical (74 tracks with an average length of 293867.57 ms), Drama (64 tracks with an average length of 2575283.78 ms), and R&B/Soul (61 tracks with an average length of 220066.85 ms).' \n```", "```py\n    prefix: 'str' = 'You are an agent designed to interact with a SQL database.\\nGiven an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\\nYou can order the results by a relevant column to return the most interesting examples in the database.\\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\\nYou have access to tools for interacting with the database.\\nOnly use the below tools. Only use the information returned by the below tools to construct your final answer.\\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n\\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\nIf the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n', \n    ```", "```py\nAs part of your final answer, ALWAYS include an explanation of how to got to the final answer, including the SQL query you run. Include the explanation and the SQL query in the section that starts with \"Explanation:\". \n```", "```py\n    Explanation:\n    <===Beginning of an Example of Explanation:\n    I joined the invoices and customers tables on the customer_id column, which is the common key between them. This will allowed me to access the Total and Country columns from both tables. Then I grouped the records by the country column and calculate the sum of the Total column for each country, ordered them in descending order and limited the SELECT to the top 5.\n    ```", "```pysql\n    ===>End of an Example of Explanation \n    ```", "```py\nagent_executor = create_sql_agent(\n    prefix=prompt_prefix,\n    format_instructions = prompt_format_instructions,\n    llm=llm,\n    toolkit=toolkit,\n    verbose=True,\n    top_k=10\n)\nresult = agent_executor.run(\"What are the top 5 best-selling albums and their artists?\")\nprint(result) \n```", "```py\nThe top 5 best-selling albums and their artists are 'A Matter of Life and Death' by Iron Maiden, 'BBC Sessions [Disc 1] [live]' by Led Zeppelin, 'MK III The Final Concerts [Disc 1]' by Deep Purple, 'Garage Inc. (Disc 1)' by Metallica and 'Achtung Baby' by U2.\nExplanation: I joined the album and invoice tables on the album_id column and joined the album and artist tables on the artist_id column. This allowed me to access the title and artist columns from the album table and the total column from the invoice table. Then I grouped the records by the artist column and calculated the sum of the Total column for each artist, ordered them in descending order and limited the SELECT to the top 5.\n```", "```py\n\nNow, in our result, we have a clear explanation of the thought process as well as the printed query our agent made for us. This is key if we want to double-check the correctness of the reasoning procedure happening in the backend of our agent.\n\nThis is already extremely useful, but we want to bring it to the next level: we want our DBCopilot to also be able to generate graphs and save results in our local file system. To achieve this goal, we need to add tools to our agent, and we are going to do so in the next section.\n\n## Adding further tools\n\nIn order to make our DBCopilot more versatile, there are two further capabilities we need to add:\n\n*   **PythonREPLTool**: This tool allows you to interact with the Python programming language using natural language. You can use this tool to write, run, and debug Python code without having to use a script file or an IDE. You can also use this tool to access and manipulate various Python modules, libraries, and data structures. **We will need this tool to produce the matplotlib graphs from the SQL query’s results.**\n\n**Definition**\n\nREPL is an acronym for read-eval-print loop, which is a term that describes an interactive shell or environment that allows you to execute code and see the results immediately. REPL is a common feature of many programming languages, such as Python, Ruby, and Lisp.\n\nIn the context of LangChain, REPL is a feature that allows you to interact with LangChain agents and tools using natural language. You can use REPL in LangChain to test, debug, or experiment with different agents and tools without having to write and run a script file. You can also use REPL in LangChain to access and manipulate various data sources, such as databases, APIs, and web pages.\n\n*   **FileManagementToolkit**: This is a set of tools, or toolkit, that allows you to interact with the file system of your computer or device using natural language. You can use this toolkit to perform various operations on files and directories, such as creating, deleting, renaming, copying, moving, searching, reading, and writing. You can also use this toolkit to access and manipulate the metadata and attributes of files and directories, such as name, size, type, date, and permissions.\n\nWe will need this toolkit to save the graphs generated by our agent in our working directory.\n\nNow, let’s see how we can add these tools to our DBCopilot:\n\n1.  First, we define the list of tools for our agent:\n\n    ```", "```py\n\n2.  In order to leverage that heterogeneous set of tools – SQL Database, Python REPL, and File System ([https://python.langchain.com/v0.1/docs/integrations/tools/filesystem/](https://python.langchain.com/v0.1/docs/integrations/tools/filesystem/)) – we cannot work anymore with the SQL Database-specific agent, since its default configurations are meant to only accept SQL-related contents. Henceforth, we need to set up an agnostic agent that is able to use all of the tools that we provide it with. For this purpose, we are going to use the `STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION` agent type, which is able to use a multi-tool input.\n\nLet’s first start with initializing the agent and asking it to produce a bar chart and save it in the current working directory for the top five countries for sales (note that, for this purpose, I’ve used a chat model as best suited for the type of agent in use):\n\n```", "```py\n\nWe then receive the following output, showing how, in this case, the agent was also able to dynamically orchestrate the available tools to generate the final answer (I will report here just the main actions of the chain – you can see the whole code in the GitHub repository of the book):\n\n```", "```py\n{\n  \"action\": \"sql_db_query\",\n  \"action_input\": \"SELECT billing_country as Country, SUM(total) as Sales FROM invoices GROUP BY billing_country ORDER BY Sales DESC LIMIT 5\"\n}\n```", "```py\n{\n  \"action\": \"Python_REPL\",\n  \"action_input\": \"import matplotlib.pyplot as plt\\nsales_data = [('USA', 10405.89), ('Canada', 5489.55), ('Brazil', 4059.0), ('France', 3972.87), ('Germany', 3441.24)]\\n\\nx = [item[0] for item in sales_data]\\ny = [item[1] for item in sales_data]\\nplt.bar(x, y)\\nplt.xlabel('Country')\\nplt.ylabel('Sales')\\nplt.title('Top 5 Countries for Sales')\\nplt.show()\"\n}\n```", "```py\n\nThe following is the generated chart of the top five countries by sales, as requested:\n\n![A graph of blue bars  Description automatically generated](img/B21714_08_07.png)\n\nFigure 8.7: Bar chart of top five countries by sales\n\nGreat! The agent was able to first invoke the SQL tool to retrieve the relevant information, then it used the Python tool to generate the `matplotlib` bar chart. Then, it used the file system tool to save the result as PNG.\n\nAlso, in this case, we can modify the prompt of the agent. For example, we might want the agent to provide an explanation not only of the SQL query but also of the Python code. To do so, we need to define the `prompt_prefix` and `prompt_format_instructions` variables to be passed as `kgwargs` to the agent as follows:\n\n```", "```py\n\nThanks to LangChain’s tools components, we were able to extend our DBCopilot capabilities and make it more versatile, depending upon the user’s query.\n\nWith the same logic, we can tailor our agents to any domain, adding or removing tools so that we can control its perimeter of actions. Plus, thanks to the prompt customization, we can always refine the agent’s backend logic to make it more customized.\n\n# Developing the front-end with Streamlit\n\nNow that we have seen the logic behind an LLM-powered DBCopilot, it is time to give a GUI to our application. To do so, we will once again leverage Streamlit. As always, you can find the whole Python code in the GitHub book repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_08.xhtml).\n\nAs per the previous sections, you need to create a `.py` file to run in your terminal via `streamlit run file.py`. In our case, the file will be named `dbcopilot.py`.\n\nHere are the main steps to set up the frontend:\n\n1.  Configure the application web page:\n\n    ```", "```py\n\n2.  Import the credentials and establish the connection with the Chinook database:\n\n    ```", "```py\n\n3.  Initialize the LLM and the toolkit:\n\n    ```", "```py\n\n4.  Initialize the Agent using the prompt variables defined in the previous sections:\n\n    ```", "```py\n\n5.  Define Streamlit’s session states to make it conversational and memory aware:\n\n    ```", "```py\n\n6.  Finally, define the logic of the application whenever a user makes a query:\n\n    ```"]