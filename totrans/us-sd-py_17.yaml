- en: '17'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '17'
- en: Building Optimized Prompts for Stable Diffusion
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Stable Diffusion构建优化提示
- en: In Stable Diffusion V1.5 (SD V1.5), crafting prompts to generate ideal images
    can be challenging. It is not uncommon to see impressive images emerge from complex
    and unusual word combinations. This is largely due to the language text encoder
    used in Stable Diffusion V1.5 – OpenAI’s CLIP model. CLIP is trained using captioned
    images from the internet, many of which are tags rather than structured sentences.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在Stable Diffusion V1.5（SD V1.5）中，制作提示以生成理想的图像可能具有挑战性。看到由复杂和不寻常的词组合产生的令人印象深刻的图像并不罕见。这主要归因于Stable
    Diffusion V1.5中使用的语言文本编码器——OpenAI的CLIP模型。CLIP使用来自互联网的带标题图像进行训练，其中许多是标签而不是结构化句子。
- en: When using SD v1.5, we must not only memorize a plethora of “magical” keywords
    but also combine these tagging words effectively. For SDXL, its dual-language
    encoders, CLIP and OpenCLIP, are much more advanced and intelligent than those
    in the previous SD v1.5\. However, we still need to follow certain guidelines
    to write effective prompts.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用SD v1.5时，我们不仅要记住大量的“魔法”关键词，还要有效地组合这些标签词。对于SDXL，其双语言编码器CLIP和OpenCLIP比之前SD
    v1.5中的要先进和智能得多。然而，我们仍然需要遵循某些指南来编写有效的提示。
- en: 'In this chapter, we will cover the fundamental principles for creating dedicated
    prompts and then explore powerful **large language model** (**LLM**) techniques
    to help us generate prompts automatically. Here are the topics we are going to
    cover in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍创建专用提示的基本原则，然后探讨强大的**大型语言模型**（**LLM**）技术，以帮助我们自动生成提示。以下是本章将要涉及的主题：
- en: What makes a good prompt?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是一个好的提示？
- en: Using LLM as the prompt generator
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLM作为提示生成器
- en: Let’s begin.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: What makes a good prompt?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是一个好的提示？
- en: Some say using Stable Diffusion is like being a magician, where tiny tricks
    and alterations make a huge difference. Writing good prompts for Stable Diffusion
    is essential for getting the most out of this powerful text-to-image AI model.
    Let me introduce some best practices that will make your prompts more effective.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有人说使用Stable Diffusion就像是一个魔术师，微小的技巧和改动就能产生巨大的影响。为Stable Diffusion编写好的提示对于充分利用这个强大的文本到图像AI模型至关重要。让我介绍一些最佳实践，这些实践将使你的提示更加有效。
- en: In the long run, AI models will understand natural language better and better,
    but for now, let’s put in a bit of extra effort to make our prompts work better.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，AI模型将更好地理解自然语言，但就目前而言，让我们付出额外的努力，让我们的提示工作得更好。
- en: In the code files associated with this chapter, you will find that Stable Diffusion
    v1.5 is much more sensitive to prompts, as different prompts will significantly
    impact the outcome’s image quality. Meanwhile, Stable Diffusion XL is much improved
    and is not so sensitive to prompts. In other words, a short prompt description
    for Stable Diffusion XL will generate relatively stable-quality images.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在与本章相关的代码文件中，你会发现Stable Diffusion v1.5对提示非常敏感，不同的提示将显著影响图像质量。同时，Stable Diffusion
    XL得到了很大改进，对提示不太敏感。换句话说，为Stable Diffusion XL编写简短的提示描述将生成相对稳定的图像质量。
- en: You can also find the code that generates all images in the code repository
    that comes with this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在本章附带代码库中找到生成所有图像的代码。
- en: Be clear and specific
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清晰具体
- en: The more specific you are with your prompts, the more accurate the images you
    get from Stable Diffusion will be.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你的提示越具体，从Stable Diffusion获得的图像就越准确。
- en: 'Here’s an original prompt:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个原始提示：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From Stable Diffusion V1.5, we might get images such as those shown in *Figure
    17**.1*:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从Stable Diffusion V1.5开始，我们可能会得到如图*图17.1*所示的图像：
- en: '![Figure 17.1: Images generated using SD V1.5 from the prompt “A painting of
    cool sci-fi”](img/B21263_17_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图17.1：使用SD V1.5从提示“一幅酷炫的科幻画”生成的图像](img/B21263_17_01.jpg)'
- en: 'Figure 17.1: Images generated using SD V1.5 from the prompt “A painting of
    cool sci-fi”'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.1：使用SD V1.5从提示“一幅酷炫的科幻画”生成的图像
- en: It gives us animated human faces with advanced devices, but it is far from the
    “sci-fi” concept we might want.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 它给我们带来了带有先进设备的动画人脸，但它离我们可能想要的“科幻”概念还远。
- en: 'From Stable Diffusion XL, the “sci-fi” concept is much more enriched, as shown
    in *Figure 17**.2*:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从Stable Diffusion XL开始，“科幻”概念得到了更丰富的体现，如图*图17.2*所示：
- en: '![Figure 17.2: Images generated using SDXL from the prompt “A painting of cool
    sci-fi”](img/B21263_17_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图17.2：使用SDXL从提示“一幅酷炫的科幻画”生成的图像](img/B21263_17_02.jpg)'
- en: 'Figure 17.2: Images generated using SDXL from the prompt “A painting of cool
    sci-fi”'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.2：使用 SDXL 从提示“一幅酷科幻画”生成的图像
- en: The paintings are indeed cool, but short prompts generate images that are either
    not what we want or less controlled.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些画作确实很酷，但简短的提示生成的图像要么不是我们想要的，要么控制度不够。
- en: 'Now let’s rewrite the prompt, adding more specific elements:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们重写提示，添加更多具体元素：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With the improved prompt, SD V1.5 gives a much more accurate result than the
    original one, as shown in *Figure 17**.3*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用改进的提示，SD V1.5 给出的结果比原始结果更准确，如图 *图 17.3* 所示：
- en: '![Figure 17.3: Images generated using SD V1.5 from a prompt with specific elements
    added](img/B21263_17_03.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.3：使用 SD V1.5 从添加特定元素的提示生成的图像](img/B21263_17_03.jpg)'
- en: 'Figure 17.3: Images generated using SD V1.5 from a prompt with specific elements
    added'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.3：使用 SD V1.5 从添加特定元素的提示生成的图像
- en: 'SDXL also improves its output, reflecting the given prompt, as shown in *Figure
    17**.4*:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SDXL 也改进了其输出，反映了给定的提示，如图 *图 17.4* 所示：
- en: '![Figure 17.4: Images generated using SDXL from a prompt with specific elements
    added](img/B21263_17_04.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.4：使用 SDXL 从添加特定元素的提示生成的图像](img/B21263_17_04.jpg)'
- en: 'Figure 17.4: Images generated using SDXL from a prompt with specific elements
    added'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.4：使用 SDXL 从添加特定元素的提示生成的图像
- en: Unless you purposefully let Stable Diffusion make its own decision, a good prompt
    clearly defines the desired outcome, leaving little room for ambiguity. It should
    specify the subject, style, and any additional details that characterize the image
    you envision.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你故意让 Stable Diffusion 做出自己的决定，一个好的提示清楚地定义了期望的结果，几乎没有模糊的空间。它应指定主题、风格以及任何描述你想象中的图像的额外细节。
- en: Be descriptive
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述性描述
- en: Descriptively describe the subject. This is similar to the *clear and specific*
    rule; not only should it be specific, but the more input and details we provide
    to the SD model, the better the result we will get. This is particularly effective
    for generating portrait images.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性地描述主题。这与 *清晰具体* 规则类似；不仅应该具体，而且我们提供给 SD 模型的输入和细节越多，我们得到的结果就越好。这对于生成肖像图像尤其有效。
- en: 'Say we want to generate a female portrait with the following prompt:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要生成一张以下提示的女性肖像：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here are the results we get from SD V1.5:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们从 SD V1.5 得到的结果：
- en: '![Figure 17.5: Images generated using SD V1.5 from the prompt “A beautiful
    woman”](img/B21263_17_05.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.5：使用 SD V1.5 从提示“一位美丽的女士”生成的图像](img/B21263_17_05.jpg)'
- en: 'Figure 17.5: Images generated using SD V1.5 from the prompt “A beautiful woman”'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.5：使用 SD V1.5 从提示“一位美丽的女士”生成的图像
- en: 'The image is good overall but lacks details and seems half-painted, half-photo.
    SDXL generates better images with this short prompt, as shown in *Figure 17**.6*:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 整体来说，这张图片不错，但细节不足，看起来像是半画半照片。SDXL 使用这个简短的提示生成了更好的图像，如图 *图 17.6* 所示：
- en: '![Figure 17.6: Images generated using SDXL from the prompt “A beautiful woman”](img/B21263_17_06.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.6：使用 SDXL 从提示“一位美丽的女士”生成的图像](img/B21263_17_06.jpg)'
- en: 'Figure 17.6: Images generated using SDXL from the prompt “A beautiful woman”'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.6：使用 SDXL 从提示“一位美丽的女士”生成的图像
- en: 'But the outcome is random: sometimes a full-body image, sometimes fully face-focused.
    To better control the result, let’s improve the prompt as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但结果却是随机的：有时是全身图像，有时是专注于脸部。为了更好地控制结果，让我们改进提示如下：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'With this prompt, SD V1.5 returns better and more consistent images, as shown
    in *Figure 17**.7*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个提示，SD V1.5 返回了更好、更一致的图像，如图 *图 17.7* 所示：
- en: '![Figure 17.7: Images generated using SD V1.5 from an enhanced descriptive
    prompt](img/B21263_17_07.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.7：使用 SD V1.5 从增强描述性提示生成的图像](img/B21263_17_07.jpg)'
- en: 'Figure 17.7: Images generated using SD V1.5 from an enhanced descriptive prompt'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.7：使用 SD V1.5 从增强描述性提示生成的图像
- en: 'Similarly, SDXL also provides images scoped by the prompt instead of generating
    wild, out-of-control images, as shown in *Figure 17**.8*:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，SDXL 也提供了由提示范围限定的图像，而不是生成野性、失控的图像，如图 *图 17.8* 所示：
- en: '![Figure 17.8: Images generated using SDXL from an enhanced descriptive prompt](img/B21263_17_08.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.8：使用 SDXL 从增强描述性提示生成的图像](img/B21263_17_08.jpg)'
- en: 'Figure 17.8: Images generated using SDXL from an enhanced descriptive prompt'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.8：使用 SDXL 从增强描述性提示生成的图像
- en: Mention details such as clothing, accessories, facial features, and the surrounding
    environment; the more, the better. Descriptiveness is crucial for guiding Stable
    Diffusion toward the desired image. Use descriptive language to paint a vivid
    picture in the Stable Diffusion model’s “mind.”
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 提及细节，如服装、配饰、面部特征和周围环境；越多越好。描述性对于引导Stable Diffusion生成期望的图像至关重要。使用描述性语言在Stable
    Diffusion模型的“心中”描绘一幅生动的画面。
- en: Using consistent terminology
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用一致的术语
- en: Make sure the prompt is consistent throughout the context. Contradictory terminology
    will output unexpected results unless you are willing to be surprised by Stable
    Diffusion.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在整个上下文中提示的一致性。除非你愿意被Stable Diffusion的惊喜所吸引，否则术语的矛盾将导致意外的结果。
- en: 'Say we give the following prompt, wanting to generate a man wearing a blue
    suit, but we also give `colorful cloth` as part of the keywords:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们给出以下提示，想要生成一个穿着蓝色西装的男人，但我们也将`彩色布料`作为关键词的一部分：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This description is contradictory, and the SD model will be confused about
    what to generate: a blue suit or a colorful suit? The result is unknown. With
    this prompt, SDXL generated the two images shown in *Figure 17**.9*:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这种描述是矛盾的，SD模型将不清楚要生成什么：蓝色西装还是彩色西装？结果是未知的。使用这个提示，SDXL生成了*图17.9*中显示的两个图像：
- en: "![Figure 17.9: Images generated using SD V1.5 from the prompt “A man wear\uFEFF\
    s blue suit, he wear\uFEFFs colorful cloth”](img/B21263_17_09.jpg)"
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图17.9：使用SD V1.5从提示“一个男人穿着蓝色西装，他穿着彩色布料”生成的图像](img/B21263_17_09.jpg)'
- en: 'Figure 17.9: Images generated using SD V1.5 from the prompt “A man wears blue
    suit, he wears colorful cloth”'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.9：使用SD V1.5从提示“一个男人穿着蓝色西装，他穿着彩色布料”生成的图像
- en: 'One image with a blue suit, another with a colorful suit. Let’s improve the
    prompt to tell Stable Diffusion that we want a blue suit with a colorful scarf:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一张穿着蓝色西装的图像，另一张穿着彩色西装的图像。让我们改进提示，告诉Stable Diffusion我们想要一件蓝色西装搭配彩色围巾：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, the result is much better and more consistent, as shown in *Figure 17**.10*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，结果要好得多，更一致，如*图17.10*所示：
- en: '![Figure 17.10: Images generated using SD V1.5 from a refined consistent prompt](img/B21263_17_10.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图17.10：使用SD V1.5从经过细化的统一提示生成的图像](img/B21263_17_10.jpg)'
- en: 'Figure 17.10: Images generated using SD V1.5 from a refined consistent prompt'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.10：使用SD V1.5从经过细化的统一提示生成的图像
- en: Maintain consistency in the terminology you use to avoid confusing the model.
    If you refer to a key concept in the first part of a prompt, don’t suddenly change
    to another in the latter part.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在你使用的术语中保持一致性，以避免混淆模型。如果你在提示的第一部分提到了一个关键概念，不要突然在后面部分改变到另一个概念。
- en: Reference artworks and styles
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考艺术作品和风格
- en: Reference specific artworks or artistic styles to guide the AI in replicating
    the desired aesthetic. Mention notable characteristics of the style, such as brushstrokes,
    color palettes, or compositional elements, which will heavily impact the generated
    results.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 参考特定的艺术作品或艺术风格以引导AI复制期望的美学。提及该风格显著的特征，如笔触、色彩搭配或构图元素，这些将严重影响生成结果。
- en: 'Let’s generate an image of a night sky without mentioning Van Gogh’s *Starry
    Night*:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们生成一张不提梵高的*星夜*的夜空图像：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Stable Diffusion V1.5 generates images with a cartoonish style, as shown in
    *Figure 17**.11*:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion V1.5生成具有卡通风格的图像，如*图17.11*所示：
- en: '![Figure 17.11: Images generated using SD V1.5 from a prompt without specifying
    a style or reference artwork](img/B21263_17_11.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图17.11：使用SD V1.5从未指定风格或参考作品的提示生成的图像](img/B21263_17_11.jpg)'
- en: 'Figure 17.11: Images generated using SD V1.5 from a prompt without specifying
    a style or reference artwork'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.11：使用SD V1.5从未指定风格或参考作品的提示生成的图像
- en: 'Let’s add `Van Gogh''s Starry Night` to the prompt:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在提示中添加`梵高的星夜`：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The swirling style from Van Gogh is more dominant in the painting, as shown
    in *Figure 17**.12*:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图17.12*所示，梵高的旋转风格在画作中更为突出：
- en: "![Figure 17.12: Images generated using SD V1.5 from a prompt with a style and\
    \ reference artwor\uFEFFk specified](img/B21263_17_12.jpg)"
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图17.12：使用SD V1.5从指定了风格和参考作品的提示生成的图像](img/B21263_17_12.jpg)'
- en: 'Figure 17.12: Images generated using SD V1.5 from a prompt with a style and
    reference artwork specified'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.12：使用SD V1.5从指定了风格和参考作品的提示生成的图像
- en: Incorporate negative prompts
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结合负面提示
- en: Stable Diffusion also provides a negative prompt input so that we can define
    elements that we don’t want to be added to the image. Negative prompts function
    well in many situations.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 还提供了一个负面提示输入，以便我们可以定义不希望添加到图像中的元素。负面提示在许多情况下都表现良好。
- en: 'We will use the following prompt, without applying a negative prompt:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下提示，不应用负面提示：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Stable Diffusion will generate images as shown in *Figure 17**.13*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 将生成如图 *图 17.13* 所示的图像：
- en: '![Figure 17.13: Images generated using SD V1.5 from a prompt without a negative
    prompt](img/B21263_17_13.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.13：使用 SD V1.5 从不带负面提示的提示中生成的图像](img/B21263_17_13.jpg)'
- en: 'Figure 17.13: Images generated using SD V1.5 from a prompt without a negative
    prompt'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.13：使用 SD V1.5 从不带负面提示的提示中生成的图像
- en: 'This is not that bad, but far from good. Let’s say we provide some negative
    prompts as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不算太糟糕，但离好还差得远。让我们假设我们提供以下一些负面提示：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The generated images are much improved, as shown in *Figure 17**.14*:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像有了很大的改进，如图 *图 17.14* 所示：
- en: '![Figure 17.14: Images generated using SD V1.5 from a prompt with negative
    prompts](img/B21263_17_14.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.14：使用 SD V1.5 从带有负面提示的提示中生成的图像](img/B21263_17_14.jpg)'
- en: 'Figure 17.14: Images generated using SD V1.5 from a prompt with negative prompts'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.14：使用 SD V1.5 从带有负面提示的提示中生成的图像
- en: Positive prompts add more attention to the target object for the Stable Diffusion
    model’s UNet, while negative prompts take away the “attention” of the object displayed.
    Sometimes, simply adding appropriate negatives can greatly improve image quality.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 正面提示会增加 Stable Diffusion 模型的 UNet 对目标对象的关注，而负面提示则减少了显示对象的“关注”。有时，简单地添加适当的负面提示可以极大地提高图像质量。
- en: Iterate and refine
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代和细化
- en: Don’t be afraid to experiment with different prompts and see what works best.
    It often takes some trial and error to get the perfect result.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 不要害怕尝试不同的提示并看看哪个效果最好。通常需要一些尝试和错误才能得到完美的结果。
- en: However, manually creating prompts that meet these requirements is hard, not
    to mention a prompt that includes a subject, style, artist, resolution, details,
    color, and lighting information.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，手动创建满足这些要求的提示很困难，更不用说包含主题、风格、艺术家、分辨率、细节、颜色和照明信息的提示了。
- en: Next, we are going to employ an LLM as a prompt-generation helper.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 LLM 作为提示生成助手。
- en: Using LLMs to generate better prompts
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LLM 生成更好的提示
- en: All of the preceding rules or tips are helpful for a better understanding of
    how Stable Diffusion works with prompts. Since this is a book about using Stable
    Diffusion with Python, we don’t want to handle these tasks by ourselves manually;
    the ultimate goal is to automate the whole process.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的上述规则或技巧都有助于更好地理解 Stable Diffusion 如何与提示一起工作。由于这是一本关于使用 Python 与 Stable Diffusion
    一起使用的书，我们不希望手动处理这些任务；最终目标是自动化整个过程。
- en: 'Stable Diffusion is evolving fast, and its cousins, the LLM and multi-modality
    community, are no slower. In this section, we are going to leverage LLMs to help
    us generate prompts with some keyword input. The following prompt will work for
    various kinds of LLM: ChatGPT, GPT-4, Google Bard, or any other capable open source
    LLM.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 发展迅速，其近亲 LLM 和多模态社区也毫不逊色。在本节中，我们将利用 LLM 帮助我们根据一些关键词输入生成提示。以下提示适用于各种类型的
    LLM：ChatGPT、GPT-4、Google Bard 或任何其他有能力的开源 LLM。
- en: 'First, let’s tell the LLM what it is going to do:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们告诉 LLM 它将要做什么：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With the preceding prompt, the LLM knows what to do with the input; next, let’s
    teach it a bit about Stable Diffusion. Without that, the LLM might have no idea
    what Stable Diffusion is:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的提示下，LLM 知道如何处理输入；接下来，让我们教它一些关于 Stable Diffusion 的知识。没有这些，LLM 可能对 Stable
    Diffusion 一无所知：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We also need to tell the LLM the definitions of some terms:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要告诉 LLM 一些术语的定义：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the preceding definitions, we are teaching the LLM about the guidelines
    from the *What makes a good* *prompt?* section:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的定义，我们正在教 LLM 关于 *什么是一个好的提示？* 部分的指南：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Exclude any sexual or nude prompts:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 排除任何涉及性或裸露的提示：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Provide an example to the LLM as few-shot learning [1] material:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为 LLM 提供一个少样本学习 [1] 材料的示例：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, teach LLM how to output a negative prompt:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，教 LLM 如何输出负面提示：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Remind the LLM that there is a token limitation; here, you can change `150`
    to some other number. The sample code associated with this chapter uses `lpw_stable_diffusion`,
    created by SkyTNT [3], and `lpw_stable_diffusion_xl`, created by Andrew Zhu, the
    author of this book:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒LLM注意存在标记限制；在这里，你可以将`150`改为其他数字。本章相关的示例代码使用了由SkyTNT [3]创建的`lpw_stable_diffusion`，以及由本书作者Andrew
    Zhu创建的`lpw_stable_diffusion_xl`：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Put all prompts together in one chunk:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有提示合并到一个块中：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Simply copy and paste the preceding prompt into ChatGPT, Bard, or any other
    serviceable LLM. Then, input any subject you want Stable Diffusion to generate:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地将前面的提示复制粘贴到ChatGPT、Bard或其他任何可用的LLM中。然后，输入你想要Stable Diffusion生成的任何主题：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The LLM (Google Bard in this case) will provide us with a new prompt:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（在本例中为Google Bard）将为我们提供一个新的提示：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Using the original prompt `a realistic photo of a woman standing by the side
    of a river`, Stable Diffusion V1.5 generated the images shown in *Figure 17**.15*:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原始提示`一位女士站在河边`，Stable Diffusion V1.5生成了*图17.15*中所示的图像：
- en: '![Figure 17.15: Images generated using SD V1.5 from the original prompt “a
    realistic photo of a woman standing by the side of a river”](img/B21263_17_15.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图17.15：使用SD V1.5从原始提示“一位女士站在河边”生成的图像](img/B21263_17_15.jpg)'
- en: 'Figure 17.15: Images generated using SD V1.5 from the original prompt “a realistic
    photo of a woman standing by the side of a river”'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.15：使用SD V1.5从原始提示“一位女士站在河边”生成的图像
- en: 'With the new positive and negative prompts generated by the LLM, SD V1.5 generated
    the images shown in *Figure 17**.16*:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM生成的新的正面和负面提示，SD V1.5生成了*图17.16*中所示的图像：
- en: '![Figure 17.16: Images generated using SD V1.5 from an LLM-generated prompt](img/B21263_17_16.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图17.16：使用SD V1.5从LLM生成的提示生成的图像](img/B21263_17_16.jpg)'
- en: 'Figure 17.16: Images generated using SD V1.5 from an LLM-generated prompt'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.16：使用SD V1.5从LLM生成的提示生成的图像
- en: 'The improvements apply to SDXL too. With the original prompt, SDXL generated
    the images shown in *Figure 17**.17*:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这些改进也适用于SDXL。使用原始提示，SDXL生成了*图17.17*中所示的图像：
- en: '![Figure 17.17: Images generated using SDXL from the original prompt “a realistic
    photo of a woman standing by the side of a river”](img/B21263_17_17.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图17.17：使用SDXL从原始提示“一位女士站在河边”生成的图像](img/B21263_17_17.jpg)'
- en: 'Figure 17.17: Images generated using SDXL from the original prompt “a realistic
    photo of a woman standing by the side of a river”'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.17：使用SDXL从原始提示“一位女士站在河边”生成的图像
- en: 'Using the LLM-generated positive and negative prompts, SDXL generated the images
    shown in *Figure 17**.18*:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM生成的正面和负面提示，SDXL生成了*图17.18*中所示的图像：
- en: '![Figure 17.18: Images generated using SDXL from LLM-generated prompts](img/B21263_17_18.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图17.18：使用SDXL从LLM生成的提示生成的图像](img/B21263_17_18.jpg)'
- en: 'Figure 17.18: Images generated using SDXL from LLM-generated prompts'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.18：使用SDXL从LLM生成的提示生成的图像
- en: The images are undoubtedly better than the ones from the original prompt and
    prove that LLM-generated prompts can improve the quality of generated images.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像无疑比原始提示生成的图像要好，证明了LLM生成的提示可以提高生成图像的质量。
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we first discussed the challenges of composing prompts for
    Stable Diffusion to generate high-quality images. We then covered some fundamental
    rules for writing effective prompts for Stable Diffusion.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先讨论了为Stable Diffusion编写提示以生成高质量图像的挑战。然后，我们介绍了一些编写有效Stable Diffusion提示的基本规则。
- en: Taking it a step further, we summarized the rules of prompt writing and incorporated
    them into an LLM prompt. This approach not only works with ChatGPT [4] but also
    with other LLMs.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步来说，我们总结了提示编写的规则，并将它们纳入LLM提示中。这种方法不仅适用于ChatGPT [4]，也适用于其他LLM。
- en: With the help of predefined prompts and LLMs, we can fully automate the image-generation
    process. There’s no need to carefully write and tune prompts manually; simply
    ask the AI what you want to generate, and the LLM will provide sophisticated prompts
    and negative prompts. If set up correctly, Stable Diffusion can automatically
    execute the prompt and deliver the result without any human intervention.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在预定义提示和LLM的帮助下，我们可以完全自动化图像生成过程。无需手动仔细编写和调整提示；只需告诉AI你想要生成的内容，LLM就会提供复杂的提示和负面提示。如果设置正确，Stable
    Diffusion可以自动执行提示并交付结果，无需任何人为干预。
- en: We understand that the development speed of AI is rapid. In the near future,
    you will be able to add more of your own LLM prompts to make the process even
    smarter and more powerful. This will further enhance the capabilities of Stable
    Diffusion and LLMs, allowing you to generate stunning images with minimal effort.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们理解AI的发展速度非常快。在不久的将来，你将能够添加更多自己的LLM提示，使过程更加智能和强大。这将进一步增强Stable Diffusion和LLM的功能，让你能够以最小的努力生成令人惊叹的图像。
- en: In the next chapter, we’ll use the knowledge we learned from the previous chapters
    to build useful applications using Stable Diffusion.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将利用前几章学到的知识，使用Stable Diffusion构建有用的应用。
- en: References
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Language Models are Few-Shot* *Learners*: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*语言模型是少样本学习者*: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
- en: '*Best text prompt for creating Stable diffusion prompts through ChatGPT or
    a local LLM model? What do you use that is better?*: [https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/](https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/)'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*通过ChatGPT或本地LLM模型创建Stable diffusion提示的最佳文本是什么？你使用的是什么更好的？*: [https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/](https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/)'
- en: 'SkyTNT: [https://github.com/SkyTNT?tab=repositories](https://github.com/SkyTNT?tab=repositories'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'SkyTNT: [https://github.com/SkyTNT?tab=repositories](https://github.com/SkyTNT?tab=repositories)'
- en: )
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'ChatGPT: [https://chat.openai.com/](https://chat.openai.com/)'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'ChatGPT: [https://chat.openai.com/](https://chat.openai.com/)'
- en: Part 4 – Building Stable Diffusion into an Application
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4部分 – 将Stable Diffusion构建到应用中
- en: Throughout this book, we’ve explored the vast potential of Stable Diffusion,
    from its fundamental concepts to advanced applications and customization techniques.
    Now, it’s time to bring everything together and integrate Stable Diffusion into
    real-world applications, making its power accessible to users and unlocking new
    possibilities for creative expression and problem-solving.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们探讨了Stable Diffusion的巨大潜力，从其基本概念到高级应用和定制技术。现在，是时候将所有内容整合起来，将Stable Diffusion应用于现实世界，使其力量对用户可用，并解锁新的创意表达和解决问题的可能性。
- en: In this final part, we’ll focus on building practical applications that showcase
    the versatility and impact of Stable Diffusion. You’ll learn how to develop innovative
    solutions such as object editing and style transferring, enabling users to manipulate
    images in unprecedented ways. We’ll also cover the importance of data persistence,
    demonstrating how to save image generation prompts and parameters directly within
    the generated PNG images.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本最终部分，我们将专注于构建展示Stable Diffusion多功能性和影响力的实用应用。你将学习如何开发创新解决方案，如对象编辑和风格迁移，使用户能够以前所未有的方式操作图像。我们还将讨论数据持久性的重要性，展示如何直接在生成的PNG图像中保存图像生成提示和参数。
- en: Furthermore, you’ll discover how to create interactive user interfaces using
    popular frameworks such as Gradio, making it easy for users to engage with Stable
    Diffusion models. Additionally, we’ll delve into the realm of transfer learning,
    guiding you through the process of training a Stable Diffusion LoRA from scratch.
    Finally, we’ll conclude with a broader discussion on the future of Stable Diffusion,
    AI, and the importance of staying informed about the latest developments in this
    rapidly evolving field.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你将发现如何使用Gradio等流行框架创建交互式用户界面，使用户能够轻松地与Stable Diffusion模型互动。此外，我们还将深入探讨迁移学习领域，指导你从头开始训练Stable
    Diffusion LoRA。最后，我们将对Stable Diffusion、AI的未来以及关注这个快速发展的领域最新发展的必要性进行更广泛的讨论。
- en: By the end of this part, you’ll be equipped with the knowledge and skills necessary
    to integrate Stable Diffusion into a wide range of applications, from creative
    tools to productivity-enhancing software. The possibilities are endless, and it’s
    time to unleash the full potential of Stable Diffusion!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 到本部分结束时，你将具备将Stable Diffusion集成到各种应用中的知识和技能，从创意工具到提高生产力的软件。可能性是无限的，现在是时候释放Stable
    Diffusion的全部潜力了！
- en: 'This part contains the following chapters:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 18*](B21263_18.xhtml#_idTextAnchor357)*, Applications – Object Editing
    and Style Transferring*'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第18章*](B21263_18.xhtml#_idTextAnchor357)*，应用 – 对象编辑和风格迁移*'
- en: '[*Chapter 19*](B21263_19.xhtml#_idTextAnchor375)*, Generation Data Persistence*'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第19章*](B21263_19.xhtml#_idTextAnchor375)*，生成数据持久性*'
- en: '[*Chapter 20*](B21263_20.xhtml#_idTextAnchor387)*, Creating Interactive User
    Interfaces*'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第20章*](B21263_20.xhtml#_idTextAnchor387)*，创建交互式用户界面*'
- en: '[*Chapter 21*](B21263_21.xhtml#_idTextAnchor405)*, Diffusion Model Transfer
    Learning*'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第21章*](B21263_21.xhtml#_idTextAnchor405)*，扩散模型迁移学习*'
- en: '[*Chapter 22*](B21263_22.xhtml#_idTextAnchor443)*, Exploring Beyond Stable
    Diffusion*'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第22章*](B21263_22.xhtml#_idTextAnchor443)*，探索超越稳定扩散*'
