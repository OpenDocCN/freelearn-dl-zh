- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building Optimized Prompts for Stable Diffusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Stable Diffusion V1.5 (SD V1.5), crafting prompts to generate ideal images
    can be challenging. It is not uncommon to see impressive images emerge from complex
    and unusual word combinations. This is largely due to the language text encoder
    used in Stable Diffusion V1.5 – OpenAI’s CLIP model. CLIP is trained using captioned
    images from the internet, many of which are tags rather than structured sentences.
  prefs: []
  type: TYPE_NORMAL
- en: When using SD v1.5, we must not only memorize a plethora of “magical” keywords
    but also combine these tagging words effectively. For SDXL, its dual-language
    encoders, CLIP and OpenCLIP, are much more advanced and intelligent than those
    in the previous SD v1.5\. However, we still need to follow certain guidelines
    to write effective prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the fundamental principles for creating dedicated
    prompts and then explore powerful **large language model** (**LLM**) techniques
    to help us generate prompts automatically. Here are the topics we are going to
    cover in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What makes a good prompt?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using LLM as the prompt generator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s begin.
  prefs: []
  type: TYPE_NORMAL
- en: What makes a good prompt?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some say using Stable Diffusion is like being a magician, where tiny tricks
    and alterations make a huge difference. Writing good prompts for Stable Diffusion
    is essential for getting the most out of this powerful text-to-image AI model.
    Let me introduce some best practices that will make your prompts more effective.
  prefs: []
  type: TYPE_NORMAL
- en: In the long run, AI models will understand natural language better and better,
    but for now, let’s put in a bit of extra effort to make our prompts work better.
  prefs: []
  type: TYPE_NORMAL
- en: In the code files associated with this chapter, you will find that Stable Diffusion
    v1.5 is much more sensitive to prompts, as different prompts will significantly
    impact the outcome’s image quality. Meanwhile, Stable Diffusion XL is much improved
    and is not so sensitive to prompts. In other words, a short prompt description
    for Stable Diffusion XL will generate relatively stable-quality images.
  prefs: []
  type: TYPE_NORMAL
- en: You can also find the code that generates all images in the code repository
    that comes with this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Be clear and specific
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The more specific you are with your prompts, the more accurate the images you
    get from Stable Diffusion will be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an original prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'From Stable Diffusion V1.5, we might get images such as those shown in *Figure
    17**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.1: Images generated using SD V1.5 from the prompt “A painting of
    cool sci-fi”](img/B21263_17_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.1: Images generated using SD V1.5 from the prompt “A painting of
    cool sci-fi”'
  prefs: []
  type: TYPE_NORMAL
- en: It gives us animated human faces with advanced devices, but it is far from the
    “sci-fi” concept we might want.
  prefs: []
  type: TYPE_NORMAL
- en: 'From Stable Diffusion XL, the “sci-fi” concept is much more enriched, as shown
    in *Figure 17**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.2: Images generated using SDXL from the prompt “A painting of cool
    sci-fi”](img/B21263_17_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.2: Images generated using SDXL from the prompt “A painting of cool
    sci-fi”'
  prefs: []
  type: TYPE_NORMAL
- en: The paintings are indeed cool, but short prompts generate images that are either
    not what we want or less controlled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s rewrite the prompt, adding more specific elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With the improved prompt, SD V1.5 gives a much more accurate result than the
    original one, as shown in *Figure 17**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.3: Images generated using SD V1.5 from a prompt with specific elements
    added](img/B21263_17_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.3: Images generated using SD V1.5 from a prompt with specific elements
    added'
  prefs: []
  type: TYPE_NORMAL
- en: 'SDXL also improves its output, reflecting the given prompt, as shown in *Figure
    17**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.4: Images generated using SDXL from a prompt with specific elements
    added](img/B21263_17_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.4: Images generated using SDXL from a prompt with specific elements
    added'
  prefs: []
  type: TYPE_NORMAL
- en: Unless you purposefully let Stable Diffusion make its own decision, a good prompt
    clearly defines the desired outcome, leaving little room for ambiguity. It should
    specify the subject, style, and any additional details that characterize the image
    you envision.
  prefs: []
  type: TYPE_NORMAL
- en: Be descriptive
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Descriptively describe the subject. This is similar to the *clear and specific*
    rule; not only should it be specific, but the more input and details we provide
    to the SD model, the better the result we will get. This is particularly effective
    for generating portrait images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say we want to generate a female portrait with the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the results we get from SD V1.5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.5: Images generated using SD V1.5 from the prompt “A beautiful
    woman”](img/B21263_17_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.5: Images generated using SD V1.5 from the prompt “A beautiful woman”'
  prefs: []
  type: TYPE_NORMAL
- en: 'The image is good overall but lacks details and seems half-painted, half-photo.
    SDXL generates better images with this short prompt, as shown in *Figure 17**.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.6: Images generated using SDXL from the prompt “A beautiful woman”](img/B21263_17_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.6: Images generated using SDXL from the prompt “A beautiful woman”'
  prefs: []
  type: TYPE_NORMAL
- en: 'But the outcome is random: sometimes a full-body image, sometimes fully face-focused.
    To better control the result, let’s improve the prompt as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'With this prompt, SD V1.5 returns better and more consistent images, as shown
    in *Figure 17**.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.7: Images generated using SD V1.5 from an enhanced descriptive
    prompt](img/B21263_17_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.7: Images generated using SD V1.5 from an enhanced descriptive prompt'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, SDXL also provides images scoped by the prompt instead of generating
    wild, out-of-control images, as shown in *Figure 17**.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.8: Images generated using SDXL from an enhanced descriptive prompt](img/B21263_17_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.8: Images generated using SDXL from an enhanced descriptive prompt'
  prefs: []
  type: TYPE_NORMAL
- en: Mention details such as clothing, accessories, facial features, and the surrounding
    environment; the more, the better. Descriptiveness is crucial for guiding Stable
    Diffusion toward the desired image. Use descriptive language to paint a vivid
    picture in the Stable Diffusion model’s “mind.”
  prefs: []
  type: TYPE_NORMAL
- en: Using consistent terminology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make sure the prompt is consistent throughout the context. Contradictory terminology
    will output unexpected results unless you are willing to be surprised by Stable
    Diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say we give the following prompt, wanting to generate a man wearing a blue
    suit, but we also give `colorful cloth` as part of the keywords:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This description is contradictory, and the SD model will be confused about
    what to generate: a blue suit or a colorful suit? The result is unknown. With
    this prompt, SDXL generated the two images shown in *Figure 17**.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 17.9: Images generated using SD V1.5 from the prompt “A man wear\uFEFF\
    s blue suit, he wear\uFEFFs colorful cloth”](img/B21263_17_09.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.9: Images generated using SD V1.5 from the prompt “A man wears blue
    suit, he wears colorful cloth”'
  prefs: []
  type: TYPE_NORMAL
- en: 'One image with a blue suit, another with a colorful suit. Let’s improve the
    prompt to tell Stable Diffusion that we want a blue suit with a colorful scarf:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the result is much better and more consistent, as shown in *Figure 17**.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.10: Images generated using SD V1.5 from a refined consistent prompt](img/B21263_17_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.10: Images generated using SD V1.5 from a refined consistent prompt'
  prefs: []
  type: TYPE_NORMAL
- en: Maintain consistency in the terminology you use to avoid confusing the model.
    If you refer to a key concept in the first part of a prompt, don’t suddenly change
    to another in the latter part.
  prefs: []
  type: TYPE_NORMAL
- en: Reference artworks and styles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reference specific artworks or artistic styles to guide the AI in replicating
    the desired aesthetic. Mention notable characteristics of the style, such as brushstrokes,
    color palettes, or compositional elements, which will heavily impact the generated
    results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s generate an image of a night sky without mentioning Van Gogh’s *Starry
    Night*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Stable Diffusion V1.5 generates images with a cartoonish style, as shown in
    *Figure 17**.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.11: Images generated using SD V1.5 from a prompt without specifying
    a style or reference artwork](img/B21263_17_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.11: Images generated using SD V1.5 from a prompt without specifying
    a style or reference artwork'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add `Van Gogh''s Starry Night` to the prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The swirling style from Van Gogh is more dominant in the painting, as shown
    in *Figure 17**.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 17.12: Images generated using SD V1.5 from a prompt with a style and\
    \ reference artwor\uFEFFk specified](img/B21263_17_12.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.12: Images generated using SD V1.5 from a prompt with a style and
    reference artwork specified'
  prefs: []
  type: TYPE_NORMAL
- en: Incorporate negative prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stable Diffusion also provides a negative prompt input so that we can define
    elements that we don’t want to be added to the image. Negative prompts function
    well in many situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the following prompt, without applying a negative prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Stable Diffusion will generate images as shown in *Figure 17**.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.13: Images generated using SD V1.5 from a prompt without a negative
    prompt](img/B21263_17_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.13: Images generated using SD V1.5 from a prompt without a negative
    prompt'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is not that bad, but far from good. Let’s say we provide some negative
    prompts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The generated images are much improved, as shown in *Figure 17**.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.14: Images generated using SD V1.5 from a prompt with negative
    prompts](img/B21263_17_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.14: Images generated using SD V1.5 from a prompt with negative prompts'
  prefs: []
  type: TYPE_NORMAL
- en: Positive prompts add more attention to the target object for the Stable Diffusion
    model’s UNet, while negative prompts take away the “attention” of the object displayed.
    Sometimes, simply adding appropriate negatives can greatly improve image quality.
  prefs: []
  type: TYPE_NORMAL
- en: Iterate and refine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Don’t be afraid to experiment with different prompts and see what works best.
    It often takes some trial and error to get the perfect result.
  prefs: []
  type: TYPE_NORMAL
- en: However, manually creating prompts that meet these requirements is hard, not
    to mention a prompt that includes a subject, style, artist, resolution, details,
    color, and lighting information.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to employ an LLM as a prompt-generation helper.
  prefs: []
  type: TYPE_NORMAL
- en: Using LLMs to generate better prompts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of the preceding rules or tips are helpful for a better understanding of
    how Stable Diffusion works with prompts. Since this is a book about using Stable
    Diffusion with Python, we don’t want to handle these tasks by ourselves manually;
    the ultimate goal is to automate the whole process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stable Diffusion is evolving fast, and its cousins, the LLM and multi-modality
    community, are no slower. In this section, we are going to leverage LLMs to help
    us generate prompts with some keyword input. The following prompt will work for
    various kinds of LLM: ChatGPT, GPT-4, Google Bard, or any other capable open source
    LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s tell the LLM what it is going to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'With the preceding prompt, the LLM knows what to do with the input; next, let’s
    teach it a bit about Stable Diffusion. Without that, the LLM might have no idea
    what Stable Diffusion is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to tell the LLM the definitions of some terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'With the preceding definitions, we are teaching the LLM about the guidelines
    from the *What makes a good* *prompt?* section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Exclude any sexual or nude prompts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Provide an example to the LLM as few-shot learning [1] material:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, teach LLM how to output a negative prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Remind the LLM that there is a token limitation; here, you can change `150`
    to some other number. The sample code associated with this chapter uses `lpw_stable_diffusion`,
    created by SkyTNT [3], and `lpw_stable_diffusion_xl`, created by Andrew Zhu, the
    author of this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Put all prompts together in one chunk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Simply copy and paste the preceding prompt into ChatGPT, Bard, or any other
    serviceable LLM. Then, input any subject you want Stable Diffusion to generate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The LLM (Google Bard in this case) will provide us with a new prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the original prompt `a realistic photo of a woman standing by the side
    of a river`, Stable Diffusion V1.5 generated the images shown in *Figure 17**.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.15: Images generated using SD V1.5 from the original prompt “a
    realistic photo of a woman standing by the side of a river”](img/B21263_17_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.15: Images generated using SD V1.5 from the original prompt “a realistic
    photo of a woman standing by the side of a river”'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the new positive and negative prompts generated by the LLM, SD V1.5 generated
    the images shown in *Figure 17**.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.16: Images generated using SD V1.5 from an LLM-generated prompt](img/B21263_17_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.16: Images generated using SD V1.5 from an LLM-generated prompt'
  prefs: []
  type: TYPE_NORMAL
- en: 'The improvements apply to SDXL too. With the original prompt, SDXL generated
    the images shown in *Figure 17**.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.17: Images generated using SDXL from the original prompt “a realistic
    photo of a woman standing by the side of a river”](img/B21263_17_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.17: Images generated using SDXL from the original prompt “a realistic
    photo of a woman standing by the side of a river”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the LLM-generated positive and negative prompts, SDXL generated the images
    shown in *Figure 17**.18*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.18: Images generated using SDXL from LLM-generated prompts](img/B21263_17_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.18: Images generated using SDXL from LLM-generated prompts'
  prefs: []
  type: TYPE_NORMAL
- en: The images are undoubtedly better than the ones from the original prompt and
    prove that LLM-generated prompts can improve the quality of generated images.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we first discussed the challenges of composing prompts for
    Stable Diffusion to generate high-quality images. We then covered some fundamental
    rules for writing effective prompts for Stable Diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: Taking it a step further, we summarized the rules of prompt writing and incorporated
    them into an LLM prompt. This approach not only works with ChatGPT [4] but also
    with other LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: With the help of predefined prompts and LLMs, we can fully automate the image-generation
    process. There’s no need to carefully write and tune prompts manually; simply
    ask the AI what you want to generate, and the LLM will provide sophisticated prompts
    and negative prompts. If set up correctly, Stable Diffusion can automatically
    execute the prompt and deliver the result without any human intervention.
  prefs: []
  type: TYPE_NORMAL
- en: We understand that the development speed of AI is rapid. In the near future,
    you will be able to add more of your own LLM prompts to make the process even
    smarter and more powerful. This will further enhance the capabilities of Stable
    Diffusion and LLMs, allowing you to generate stunning images with minimal effort.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll use the knowledge we learned from the previous chapters
    to build useful applications using Stable Diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Language Models are Few-Shot* *Learners*: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Best text prompt for creating Stable diffusion prompts through ChatGPT or
    a local LLM model? What do you use that is better?*: [https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/](https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SkyTNT: [https://github.com/SkyTNT?tab=repositories](https://github.com/SkyTNT?tab=repositories'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'ChatGPT: [https://chat.openai.com/](https://chat.openai.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Part 4 – Building Stable Diffusion into an Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we’ve explored the vast potential of Stable Diffusion,
    from its fundamental concepts to advanced applications and customization techniques.
    Now, it’s time to bring everything together and integrate Stable Diffusion into
    real-world applications, making its power accessible to users and unlocking new
    possibilities for creative expression and problem-solving.
  prefs: []
  type: TYPE_NORMAL
- en: In this final part, we’ll focus on building practical applications that showcase
    the versatility and impact of Stable Diffusion. You’ll learn how to develop innovative
    solutions such as object editing and style transferring, enabling users to manipulate
    images in unprecedented ways. We’ll also cover the importance of data persistence,
    demonstrating how to save image generation prompts and parameters directly within
    the generated PNG images.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, you’ll discover how to create interactive user interfaces using
    popular frameworks such as Gradio, making it easy for users to engage with Stable
    Diffusion models. Additionally, we’ll delve into the realm of transfer learning,
    guiding you through the process of training a Stable Diffusion LoRA from scratch.
    Finally, we’ll conclude with a broader discussion on the future of Stable Diffusion,
    AI, and the importance of staying informed about the latest developments in this
    rapidly evolving field.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this part, you’ll be equipped with the knowledge and skills necessary
    to integrate Stable Diffusion into a wide range of applications, from creative
    tools to productivity-enhancing software. The possibilities are endless, and it’s
    time to unleash the full potential of Stable Diffusion!
  prefs: []
  type: TYPE_NORMAL
- en: 'This part contains the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 18*](B21263_18.xhtml#_idTextAnchor357)*, Applications – Object Editing
    and Style Transferring*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 19*](B21263_19.xhtml#_idTextAnchor375)*, Generation Data Persistence*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 20*](B21263_20.xhtml#_idTextAnchor387)*, Creating Interactive User
    Interfaces*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 21*](B21263_21.xhtml#_idTextAnchor405)*, Diffusion Model Transfer
    Learning*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 22*](B21263_22.xhtml#_idTextAnchor443)*, Exploring Beyond Stable
    Diffusion*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
