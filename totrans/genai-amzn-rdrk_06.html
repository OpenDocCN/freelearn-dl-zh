<html><head></head><body>
<div id="_idContainer107">
<h1 class="chapter-number" id="_idParaDest-113"><a id="_idTextAnchor117"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-114"><a id="_idTextAnchor118"/><span class="koboSpan" id="kobo.2.1">Generating and Summarizing Text with Amazon Bedrock</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we will explore architecture patterns for generating and summarizing text with Amazon Bedrock. </span><span class="koboSpan" id="kobo.3.2">You will learn about applications of text generation and how text generation works with Amazon Bedrock. </span><span class="koboSpan" id="kobo.3.3">Then, we will use some prompt engineering techniques, including contextual prompting, and orchestration using LangChain. </span><span class="koboSpan" id="kobo.3.4">After, we will explore text summarization using small texts/files, summarizing large articles and books, and discover use cases and patterns for </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">text summarization.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">By the end of this chapter, you will be able to understand and implement text generation and summarization with Amazon Bedrock in real-world </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">use cases.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">Here are the key topics that will be covered in </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">this chapter:</span></span></p>
<ul>
<li><a id="_idTextAnchor119"/><a id="_idTextAnchor120"/><span class="No-Break"><span class="koboSpan" id="kobo.9.1">Generating text</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.10.1">Summarizing text</span></span><a id="_idTextAnchor121"/></li>
<li><span class="koboSpan" id="kobo.11.1">Creating a secure </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">serverless solution</span></span></li>
</ul>
<h1 id="_idParaDest-115"><a id="_idTextAnchor122"/><span class="koboSpan" id="kobo.13.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.14.1">This chapter requires you to have access to an AWS account. </span><span class="koboSpan" id="kobo.14.2">If you don’t have one already, you can go to </span><a href="https://aws.amazon.com/getting-started/"><span class="koboSpan" id="kobo.15.1">https://aws.amazon.com/getting-started/</span></a><span class="koboSpan" id="kobo.16.1"> and </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">create one.</span></span></p>
<p><span class="koboSpan" id="kobo.18.1">Secondly, you will need to install and configure the AWS CLI (</span><a href="https://aws.amazon.com/cli/"><span class="koboSpan" id="kobo.19.1">https://aws.amazon.com/cli/</span></a><span class="koboSpan" id="kobo.20.1">). </span><span class="koboSpan" id="kobo.20.2">You will use this to access Amazon Bedrock FMs from your local machine. </span><span class="koboSpan" id="kobo.20.3">Since the majority of the code cells we will be executing are based in Python, setting up an AWS Python SDK (Boto3) (</span><a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html"><span class="koboSpan" id="kobo.21.1">https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html</span></a><span class="koboSpan" id="kobo.22.1">) would be beneficial at this point. </span><span class="koboSpan" id="kobo.22.2">You can carry out the Python setup in any way: install it on your local machine, or use AWS Cloud9, or utilize AWS Lambda, or leverage Amazon SageMaker. </span><span class="koboSpan" id="kobo.22.3">If you’re using Jupyter Notebook with the AWS Python SDK to interact with Amazon Bedrock, make sure you run the following code cell in the notebook to import the essential libraries and create a Bedrock </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">runtime client:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.24.1">
#Ensure you have the latest version of boto3 &amp; langchain
!pip install -U boto3 langchain-community
#import the main packages and libraries
import boto3
import json
#Create bedrock runtime client
bedrock_client = boto3.client('bedrock-runtime') #Select the desired region</span></pre>
<p class="callout-heading"><span class="koboSpan" id="kobo.25.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.26.1">There will be a charge associated with invoking and customizing the FMs of Amazon Bedrock. </span><span class="koboSpan" id="kobo.26.2">Please refer to </span><a href="https://aws.amazon.com/bedrock/pricing/"><span class="koboSpan" id="kobo.27.1">https://aws.amazon.com/bedrock/pricing/</span></a><span class="koboSpan" id="kobo.28.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">learn more.</span></span></p>
<h1 id="_idParaDest-116"><a id="_idTextAnchor123"/><span class="koboSpan" id="kobo.30.1">Generating text</span></h1>
<p><span class="koboSpan" id="kobo.31.1">Text generation </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.32.1">plays a crucial role in various sectors, from marketing and advertising to journalism and creative writing. </span><span class="koboSpan" id="kobo.32.2">The significance of this technique lies in its capacity to streamline content creation processes, boost productivity, and unlock new realms </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">of creativity.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">One of the key advantages of text generation is its potential to save valuable time and resources. </span><span class="koboSpan" id="kobo.34.2">Traditional content creation methods can be time-consuming and labor-intensive, often requiring extensive research, writing, and editing efforts. </span><span class="koboSpan" id="kobo.34.3">But by using generative AI models, businesses and individuals can quickly produce initial drafts, outlines, or complete pieces of content, freeing up valuable time for </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">other tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">Furthermore, text generation empowers content creators to explore new narrative avenues and push the boundaries of their creativity. </span><span class="koboSpan" id="kobo.36.2">By providing a starting point or a framework, these tools can spark fresh ideas and facilitate the exploration of unconventional storytelling techniques or unique writing styles. </span><span class="koboSpan" id="kobo.36.3">This capability is particularly valuable in industries where originality and distinctiveness are highly prized, such as fiction writing, advertising campaigns, or brand </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">storytelling initiatives.</span></span></p>
<p><span class="koboSpan" id="kobo.38.1">In addition to creative applications, text generation also holds immense potential in fields that demand high volumes of informative and factual content. </span><span class="koboSpan" id="kobo.38.2">For instance, news reporting, scientific publications, technical documentation, and text generation can aid in the rapid dissemination of accurate and up-to-date information. </span><span class="koboSpan" id="kobo.38.3">By leveraging vast data repositories and subject matter expertise, these tools can generate comprehensive reports, summaries, or articles, ensuring that relevant information is readily available to the </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">intended audience.</span></span></p>
<p><span class="koboSpan" id="kobo.40.1">Moreover, text generation offers exciting opportunities for personalization and customization. </span><span class="koboSpan" id="kobo.40.2">By analyzing user preferences, demographics, and contextual data, these tools can tailor content so that it resonates with specific target audiences, enhancing engagement and</span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.41.1"> fostering stronger connections with readers </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">or customers.</span></span></p>
<p><span class="koboSpan" id="kobo.43.1">Let’s look at some real-world applications of text generation </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">in detail.</span></span></p>
<h2 id="_idParaDest-117"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.45.1">Text generation applications</span></h2>
<p><span class="koboSpan" id="kobo.46.1">While the </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.47.1">applications of text generation are endless, here are a few examples to get </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">you started:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.49.1">Generating product descriptions</span></strong><span class="koboSpan" id="kobo.50.1">: Amazon Bedrock’s text generation capabilities can be leveraged to automate the creation of product descriptions for marketing teams. </span><span class="koboSpan" id="kobo.50.2">By inputting the product’s features, specifications, and key benefits, the FM can generate compelling and SEO-optimized descriptions that highlight the unique selling points of the product. </span><span class="koboSpan" id="kobo.50.3">This can significantly streamline the process of creating product descriptions, saving time and resources for </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">marketing teams.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.52.1">The generated descriptions can be tailored to different target audiences, tone, and style preferences, ensuring a consistent and engaging brand voice across various channels. </span><span class="koboSpan" id="kobo.52.2">Additionally, the FM can be customized on existing product descriptions, allowing it to learn and mimic the desired writing style </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">and formatting.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.54.1">Media articles and marketing campaigns generation</span></strong><span class="koboSpan" id="kobo.55.1">: Amazon Bedrock’s text generation capabilities can be utilized for creating high-quality content for media articles, blog posts, and marketing campaigns. </span><span class="koboSpan" id="kobo.55.2">By providing relevant information, data, and guidelines, the FM can generate well-structured and coherent articles that can be used for content marketing, thought leadership, or </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">news dissemination.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.57.1">The FM can be trained on existing content, enabling it to understand and mimic the tone, style, and formatting preferences of specific publications or brands. </span><span class="koboSpan" id="kobo.57.2">It can also generate attention-grabbing headlines, engaging introductions, and compelling </span><strong class="bold"><span class="koboSpan" id="kobo.58.1">calls to action</span></strong><span class="koboSpan" id="kobo.59.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.60.1">CTAs</span></strong><span class="koboSpan" id="kobo.61.1">) for</span><a id="_idIndexMarker491"/> <span class="No-Break"><span class="koboSpan" id="kobo.62.1">marketing campaigns.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.63.1">Personalized email and message composition</span></strong><span class="koboSpan" id="kobo.64.1">: Amazon Bedrock can be utilized to compose personalized emails, messages, and other written communications for customer outreach, marketing campaigns, or even internal communications. </span><span class="koboSpan" id="kobo.64.2">By </span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.65.1">leveraging customer data and preferences, the FM can generate highly tailored and engaging content, enhancing customer experience and increasing </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">brand loyalty.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.67.1">Healthcare</span></strong><span class="koboSpan" id="kobo.68.1">: Clinical documentation is a critical aspect of healthcare, but it can be time-consuming and prone to errors. </span><span class="koboSpan" id="kobo.68.2">Bedrock can assist healthcare professionals in streamlining the note-taking and documentation process by generating accurate and comprehensive clinical notes based on conversations or dictations during patient encounters. </span><span class="koboSpan" id="kobo.68.3">Amazon offers another service called </span><em class="italic"><span class="koboSpan" id="kobo.69.1">AWS HealthScribe</span></em><span class="koboSpan" id="kobo.70.1"> that’s powered by Amazon Bedrock and is specifically designed to do that. </span><span class="koboSpan" id="kobo.70.2">To learn more about AWS HealthScribe, go </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">to </span></span><a href="https://aws.amazon.com/healthscribe/"><span class="No-Break"><span class="koboSpan" id="kobo.72.1">https://aws.amazon.com/healthscribe/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.73.1">.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.74.1">Bedrock can be employed to generate personalized health and wellness recommendations tailored to an individual’s unique health profile, lifestyle, and preferences. </span><span class="koboSpan" id="kobo.74.2">By analyzing data from various sources, such as </span><strong class="bold"><span class="koboSpan" id="kobo.75.1">electronic health records</span></strong><span class="koboSpan" id="kobo.76.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.77.1">EHRs</span></strong><span class="koboSpan" id="kobo.78.1">), wearable </span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.79.1">devices, and self-reported information, Bedrock can provide tailored </span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.80.1">recommendations for diet, exercise, stress management, and </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">preventive care.</span></span></p></li>
</ul>
<h2 id="_idParaDest-118"><a id="_idTextAnchor125"/><span class="koboSpan" id="kobo.82.1">Text generation systems with Amazon Bedrock</span></h2>
<p><span class="koboSpan" id="kobo.83.1">If you have</span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.84.1"> been following the previous </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.85.1">chapters, you may have already tried generating text on Amazon Bedrock. </span><span class="koboSpan" id="kobo.85.2">But just as a reminder, a simple text generation system looks </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">like this:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer093">
<span class="koboSpan" id="kobo.87.1"><img alt="Figure 6.1 – Simple text generation system" src="image/B22045_06_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.88.1">Figure 6.1 – Simple text generation system</span></p>
<p><span class="koboSpan" id="kobo.89.1">You provide a prompt to the model and say something like </span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1">Compose an email to a customer support team</span></strong><span class="koboSpan" id="kobo.91.1">. </span><span class="koboSpan" id="kobo.91.2">Even if you don’t provide any context, the model will generate a sample email for you (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.92.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.93.1">.2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer094">
<span class="koboSpan" id="kobo.95.1"><img alt="Figure 6.2 – Generating an email" src="image/B22045_06_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.96.1">Figure 6.2 – Generating an email</span></p>
<p><span class="koboSpan" id="kobo.97.1">In your Jupyter Notebook environment with the AWS Python SDK, run the following sample script</span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.98.1"> to invoke the AI21 Jurassic model. </span><span class="koboSpan" id="kobo.98.2">Make</span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.99.1"> sure you import the essential libraries and create the Bedrock runtime client first, as mentioned in the </span><em class="italic"><span class="koboSpan" id="kobo.100.1">Technical </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.101.1">requirements</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.102.1"> section:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.103.1">
prompt_data = """Human: Compose an email to a customer support team.
</span><span class="koboSpan" id="kobo.103.2">Assistant:
"""
body = json.dumps({"prompt": prompt_data, "maxTokens": 200})
modelId = "ai21.j2-mid-v1"  # change this to use a different version from the model provider
accept = «application/json»
contentType = «application/json»
response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)
response_body = json.loads(response.get("body").read())
print(response_body.get("completions")[0].get("data").get("text"))</span></pre>
<p><span class="koboSpan" id="kobo.104.1">Now, based on the model that you select, the response’s structure and output may vary. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.105.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.106.1">.3</span></em><span class="koboSpan" id="kobo.107.1"> shows the response from the AI21 </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">Jurassic model:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer095">
<span class="koboSpan" id="kobo.109.1"><img alt="Figure 6.3 – AI21 Jurassic output" src="image/B22045_06_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.110.1">Figure 6.3 – AI21 Jurassic output</span></p>
<p><span class="koboSpan" id="kobo.111.1">Here, we provided a simple prompt without providing any context or information. </span><span class="koboSpan" id="kobo.111.2">Now, let’s move on to </span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.112.1">the advanced architecture </span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.113.1">patterns of text generation and understand </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">contextual prompting.</span></span></p>
<h2 id="_idParaDest-119"><a id="_idTextAnchor126"/><span class="koboSpan" id="kobo.115.1">Generating text using prompt engineering</span></h2>
<p><span class="koboSpan" id="kobo.116.1">In the previous</span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.117.1"> section, we</span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.118.1"> looked at a pattern of text generation where we did not provide any context or information to the model. </span><span class="koboSpan" id="kobo.118.2">Let’s use some of the prompt engineering techniques we learned about in </span><a href="B22045_03.xhtml#_idTextAnchor053"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.119.1">Chapter 3</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.120.1">:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.121.1">Zero-shot contextual prompting</span></strong><span class="koboSpan" id="kobo.122.1">: Here, we will provide detailed context in the prompt in a </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">zero-shot fashion:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.124.1">
prompt = """</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.125.1">
Human: Write a descriptive and engaging travel guide section about a lesser-known but beautiful destination, capturing the local culture, cuisine, and must-see attractions in a way that inspires wanderlust.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.126.1">
Assistant:"""</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.127.1">
body = json.dumps({"prompt": prompt,"max_tokens_to_sample": 500})</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.128.1">
modelId = "anthropic.claude-v2"  # change this to use a different version from the model provider</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.129.1">
accept = «application/json»</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.130.1">
contentType = «application/json»</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.131.1">
response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.132.1">
response_body = json.loads(response.get("body").read())</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.133.1">
print(response_body.get("completion"))</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.134.1">Running the</span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.135.1"> preceding </span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.136.1">code will generate a response similar to the one shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.137.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.138.1">.4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">:</span></span></p></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer096">
<span class="koboSpan" id="kobo.140.1"><img alt="Figure 6.4 – Zero-shot contextual prompt response" src="image/B22045_06_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.141.1">Figure 6.4 – Zero-shot contextual prompt response</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.142.1">In the preceding scenario, we used the Amazon Bedrock API – </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">invoke_model</span></strong><span class="koboSpan" id="kobo.144.1"> – and passed the prompt, configuration parameters, and model ID. </span><span class="koboSpan" id="kobo.144.2">If you want to learn more about the various Bedrock APIs that are available, you are encouraged to revisit </span><a href="B22045_02.xhtml#_idTextAnchor034"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.145.1">Chapter 2</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.146.1">.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.147.1">Few-shot contextual prompting</span></strong><span class="koboSpan" id="kobo.148.1">: Here, we will provide some examples in our prompt </span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.149.1">so that the model can start to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">reasonable continuations:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.151.1">
prompt = """</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.152.1">
Human: Here are some examples of product descriptions:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.153.1">
Example 1:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.154.1">
Product: Apple iPhone 13 Pro</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.155.1">
Description: The iPhone 13 Pro is a smartphone designed and manufactured by Apple Inc. </span><span class="koboSpan" id="kobo.155.2">It features a 6.1-inch Super Retina XDR display, a powerful A15 Bionic chip, and an advanced triple-camera system with improved low-light performance and 3x optical zoom. </span><span class="koboSpan" id="kobo.155.3">The phone also boasts 5G connectivity, longer battery life, and a durable Ceramic Shield front cover.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.156.1">
Example 2:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.157.1">
Product: Sony WH-1000XM4 Noise Cancelling Headphones</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.158.1">
Description: Experience exceptional audio quality with the Sony WH-1000XM4 Noise Cancelling Headphones. </span><span class="koboSpan" id="kobo.158.2">These over-ear headphones feature industry-leading noise cancellation technology, allowing you to immerse yourself in your music without distractions. </span><span class="koboSpan" id="kobo.158.3">The responsive touch controls and long-lasting battery life make them ideal for everyday use, while the comfortable design ensures hours of listening pleasure.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.159.1">
Example 3:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.160.1">
Product: Instant Pot Duo Crisp + Air Fryer</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.161.1">
Description: The Instant Pot Duo Crisp + Air Fryer is a versatile kitchen appliance that combines the functions of an electric pressure cooker, air fryer, and more. </span><span class="koboSpan" id="kobo.161.2">With its EvenCrisp technology, you can achieve crispy, golden results using little to no oil. </span><span class="koboSpan" id="kobo.161.3">The easy-to-use control panel and 11 built-in smart programs allow you to cook a wide variety of dishes with ease, making it a must-have for any modern kitchen.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.162.1">
Your task: Generate a product description for the following product:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.163.1">
Product: Sony A7 III Mirrorless Camera</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.164.1">
Assistant:"""</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.165.1">
body = json.dumps({"prompt": prompt, "max_tokens_to_sample": 500})</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.166.1">
modelId = "anthropic.claude-v2"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.167.1">
accept = "application/json"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.168.1">
contentType = "application/json"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.169.1">
response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.170.1">
response_body = json.loads(response.get("body").read())</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.171.1">
print(response_body.get("completion"))</span></pre></li>
</ul>
<p><span class="koboSpan" id="kobo.172.1">Here, we provided </span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.173.1">three examples in </span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.174.1">our prompt to tell the model how our response should look. </span><span class="koboSpan" id="kobo.174.2">Then, we invoked the model to generate a product description for </span><strong class="source-inline"><span class="koboSpan" id="kobo.175.1">Sony A7 III Mirrorless Camera</span></strong><span class="koboSpan" id="kobo.176.1">. </span><span class="koboSpan" id="kobo.176.2">We received the response shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.177.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.178.1">.5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer097">
<span class="koboSpan" id="kobo.180.1"><img alt="Figure 6.5 – Few-shot contextual prompting response" src="image/B22045_06_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.181.1">Figure 6.5 – Few-shot contextual prompting response</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.182.1">Zero-shot prompting with LangChain</span></strong><span class="koboSpan" id="kobo.183.1">: Here, we will use LangChain’s integration of Bedrock API. </span><span class="koboSpan" id="kobo.183.2">LangChain acts as an abstraction layer, simplifying the interaction </span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.184.1">with the </span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.185.1">Bedrock API before routing your request to the appropriate API endpoint (the Amazon Bedrock </span><strong class="source-inline"><span class="koboSpan" id="kobo.186.1">invoke_model</span></strong><span class="koboSpan" id="kobo.187.1"> API in </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">this case):</span></span></li>
</ul>
<p class="callout-heading"><span class="koboSpan" id="kobo.189.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.190.1">At the time of writing, we used </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">langchain_community.llms</span></strong><span class="koboSpan" id="kobo.192.1"> library to import </span><em class="italic"><span class="koboSpan" id="kobo.193.1">Bedrock</span></em><span class="koboSpan" id="kobo.194.1">. </span><span class="koboSpan" id="kobo.194.2">However, based on the updates from the LangChain community, it may be susceptible to change. </span><span class="koboSpan" id="kobo.194.3">For updated information on importing the LangChain package, please </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">visit </span></span><a href="https://python.langchain.com/v0.2/docs/integrations/platforms/"><span class="No-Break"><span class="koboSpan" id="kobo.196.1">https://python.langchain.com/v0.2/docs/integrations/platforms/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.197.1">.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.198.1">
from langchain_community.llms import Bedrock
inference_modifier = {"max_tokens_to_sample": 4096, "temperature": 0.5, "top_k": 250, "top_p": 1, "stop_sequences": ["\n\nHuman"],}
llm = Bedrock(model_id="anthropic.claude-v2",  client=bedrock_client, model_kwargs=inference_modifier,)
response = llm("""
Human: Write a descriptive and engaging travel guide section about a lesser-known but beautiful destination, capturing the local culture, cuisine, and must-see attractions in a way that inspires wanderlust.
</span><span class="koboSpan" id="kobo.198.2">Assistant:""")
print(response)</span></pre>
<p class="list-inset"><span class="koboSpan" id="kobo.199.1">Upon running the preceding code snippet, we can see that the model can generate a descriptive response, as requested (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.200.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.201.1">.6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer098">
<span class="koboSpan" id="kobo.203.1"><img alt="Figure 6.6 – Zero-shot prompting with LangChain" src="image/B22045_06_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.204.1">Figure 6.6 – Zero-shot prompting with LangChain</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.205.1">Contextual generation with LangChain</span></strong><span class="koboSpan" id="kobo.206.1">: Here, we will provide instructions and </span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.207.1">context in </span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.208.1">our prompts before sending them to </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">the model:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.210.1">
from langchain_community.llms import Bedrock</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.211.1">
inference_modifier = {'max_tokens_to_sample':4096, "temperature":0.5, "top_k":250, "top_p":1, "stop_sequences": ["\n\nHuman"]}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.212.1">
llm = Bedrock(model_id = "anthropic.claude-v2", client = boto3_bedrock, model_kwargs = inference_modifier)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.213.1">
from langchain.prompts import PromptTemplate</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.214.1">
product_description_prompt = PromptTemplate(   input_variables=["product_name", "product_category", "key_features"],</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.215.1">
    template="""</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.216.1">
You are a professional copywriter tasked with creating an engaging and informative product description for a new Amazon product.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.217.1">
Product Name: {product_name}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.218.1">
Product Category: {product_category}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.219.1">
Key Features: {key_features}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.220.1">
Write a compelling product description that highlights the key features and benefits of the product, while keeping the tone engaging and persuasive for potential customers.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.221.1">
Product Description:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.222.1">
«»»</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.223.1">
)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.224.1">
prompt = product_description_prompt.format(</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.225.1">
    product_name="Smart Home Security Camera",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.226.1">
    product_category="Home Security",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.227.1">
    key_features="- 1080p HD video recording\n- Motion detection alerts\n- Two-way audio communication\n- Night vision capabilities\n- Cloud storage for recorded footage")</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.228.1">
response = llm(prompt)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.229.1">
product = response[response.index('\n')+1:]</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.230.1">
print(product)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.231.1">In this scenario, we used the LangChain implementation of Bedrock. </span><span class="koboSpan" id="kobo.231.2">We defined a prompt template for creating a product description and invoked the Anthropic Claude model to generate a product description of a smart home security camera. </span><span class="koboSpan" id="kobo.231.3">The prompt template is essentially a reusable template for constructing prompts. </span><span class="koboSpan" id="kobo.231.4">Within the prompt template, you can provide the context, input variables, task, and some few-shot examples for the model to reference. </span><span class="koboSpan" id="kobo.231.5">To learn more </span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.232.1">about prompt</span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.233.1"> templates, go </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">to </span></span><a href="https://python.langchain.com/v0.2/docs/concepts/#prompt-templates"><span class="No-Break"><span class="koboSpan" id="kobo.235.1">https://python.langchain.com/v0.2/docs/concepts/#prompt-templates</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.236.1">.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.237.1">The following figure shows the response from providing the preceding </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">code snippet:</span></span></p></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer099">
<span class="koboSpan" id="kobo.239.1"><img alt="Figure 6.7 – Contextual generation with LangChain" src="image/B22045_06_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.240.1">Figure 6.7 – Contextual generation with LangChain</span></p>
<p><span class="koboSpan" id="kobo.241.1">Now that we’ve</span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.242.1"> looked at various text</span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.243.1"> generation patterns, let’s look at how we can perform summarization using </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">Amazon Bedrock.</span></span></p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor127"/><span class="koboSpan" id="kobo.245.1">Summarizing text</span></h1>
<p><span class="koboSpan" id="kobo.246.1">Text summarization is </span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.247.1">a highly sought-after capability that holds immense value across diverse domains. </span><span class="koboSpan" id="kobo.247.2">It involves the intricate task of condensing lengthy text documents into concise and coherent summaries that capture the essence of the original content. </span><span class="koboSpan" id="kobo.247.3">These summaries aim to preserve the most salient information while omitting redundant or irrelevant details, thereby enabling efficient consumption and comprehension of extensive </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">textual data.</span></span></p>
<p><span class="koboSpan" id="kobo.249.1">Text summarization finds applications in a wide range of sectors, from research and academia to journalism, business intelligence, and legal documentation. </span><span class="koboSpan" id="kobo.249.2">With the exponential growth of textual data generated daily, the need for effective summarization techniques has become increasingly paramount. </span><span class="koboSpan" id="kobo.249.3">Imagine sifting through voluminous reports, news articles, or legal documents – text summarization emerges as a powerful tool to distill the core information, saving time and cognitive effort for professionals and </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">researchers alike.</span></span></p>
<p><span class="koboSpan" id="kobo.251.1">Let’s look at some of the</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.252.1"> real-world applications of </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">text summarization:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.254.1">Content curation</span></strong><span class="koboSpan" id="kobo.255.1">: In today’s information-rich world, text summarization plays a pivotal role in curating and condensing vast amounts of data. </span><span class="koboSpan" id="kobo.255.2">This allows users to quickly grasp the essence of lengthy articles, reports, or online content without having to read </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">every word.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.257.1">News aggregation</span></strong><span class="koboSpan" id="kobo.258.1">: News aggregators and media platforms can leverage text summarization to provide concise summaries of breaking news stories, enabling users to stay informed about the latest developments without getting bogged down by </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">extensive details.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.260.1">Research assistance</span></strong><span class="koboSpan" id="kobo.261.1">: Researchers and academics can benefit from text summarization techniques to quickly identify the most pertinent information from a vast corpus of literature, saving them valuable time </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">and effort.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.263.1">Customer service</span></strong><span class="koboSpan" id="kobo.264.1">: Text summarization can enhance customer service by automatically generating concise summaries of lengthy customer inquiries or feedback, allowing support agents to quickly comprehend the crux of the issue and provide </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">timely responses.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.266.1">Legal and financial domains</span></strong><span class="koboSpan" id="kobo.267.1">: In industries where accurate representation of original text is critical, such as legal or financial sectors, text summarization techniques can be employed to generate summaries of contracts, agreements, or reports, ensuring that key information is </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">not overlooked.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.269.1">Email management</span></strong><span class="koboSpan" id="kobo.270.1">: Email clients or productivity tools can leverage text summarization to provide concise overviews of long email threads or conversations, helping users quickly grasp the key points without having to read through </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">every message.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.272.1">Meeting recap</span></strong><span class="koboSpan" id="kobo.273.1">: Text summarization can be applied to meeting transcripts or notes, generating succinct summaries that capture the most important discussions, decisions, and action items, enabling participants to quickly review and follow up on </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">critical points.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.275.1">Social media monitoring</span></strong><span class="koboSpan" id="kobo.276.1">: Businesses and organizations can utilize text summarization to analyze and summarize vast amounts of social media data, such as customer</span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.277.1"> feedback, product reviews, or brand mentions, enabling them to stay informed about public sentiment and </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">respond promptly.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.279.1">Knowledge extraction</span></strong><span class="koboSpan" id="kobo.280.1">: Text summarization techniques can be used to extract and summarize relevant knowledge from large datasets or knowledge bases, making it easier to access and leverage valuable information for various applications, such as decision-making or knowledge </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">management systems.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.282.1">Educational resources</span></strong><span class="koboSpan" id="kobo.283.1">: Text summarization can be applied to educational materials, such as textbooks or online courses, to generate concise summaries or study aids, helping students grasp key concepts and prepare for exams </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">more efficiently.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.285.1">While the list of applications is endless and spans across every industry, let’s look at how summarization systems work with Amazon Bedrock. </span><span class="koboSpan" id="kobo.285.2">We will learn about </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">two approaches:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.287.1">Summarization of </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">small files</span></span></li>
<li><span class="koboSpan" id="kobo.289.1">Summarization of </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">large files</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.291.1">By small files, we mean pieces of text that fit into the context length of the model. </span><span class="koboSpan" id="kobo.291.2">This could range from a couple of sentences to a few paragraphs. </span><span class="koboSpan" id="kobo.291.3">On the other hand, by large files, we mean large documents or book(s) worth of information that does not fit into the context length of the model. </span><span class="koboSpan" id="kobo.291.4">It is important to note that there is no one-size-fits-all that works </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.292.1">across all models. </span><span class="koboSpan" id="kobo.292.2">Every model, including their different versions, might have a different context length. </span><span class="koboSpan" id="kobo.292.3">For example, Cohere Command R+ has a context length of 128K tokens, while Cohere Command Light has a context length of </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">4,000 tokens.</span></span></p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor128"/><span class="koboSpan" id="kobo.294.1">Summarization of small files</span></h2>
<p><span class="koboSpan" id="kobo.295.1">Small files can include </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.296.1">meeting notes, blog posts, news articles, email messages, and call transcripts. </span><span class="koboSpan" id="kobo.296.2">These files are then used as a context for the prompt and sent to the model. </span><span class="koboSpan" id="kobo.296.3">The prompt here could be as simple as </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">Summarize the content</span></strong><span class="koboSpan" id="kobo.298.1">. </span><span class="koboSpan" id="kobo.298.2">The model then processes the file and provides you with the summarized response. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.299.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.300.1">.8</span></em><span class="koboSpan" id="kobo.301.1"> shows the process of small </span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">file summarization:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer100">
<span class="koboSpan" id="kobo.303.1"><img alt="Figure 6.8 – Small file summarization" src="image/B22045_06_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.304.1">Figure 6.8 – Small file summarization</span></p>
<p><span class="koboSpan" id="kobo.305.1">Let’s consider an example of a news article from Yahoo! </span><span class="koboSpan" id="kobo.305.2">Finance. </span><span class="koboSpan" id="kobo.305.3">Since the news article fits into the context length of the model, we will use that as a context in the prompt, </span><strong class="source-inline"><span class="koboSpan" id="kobo.306.1">Summarize the following news article</span></strong><span class="koboSpan" id="kobo.307.1">, and send it to the model. </span><span class="koboSpan" id="kobo.307.2">The model will then process the request and provide the summarized response, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.308.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.309.1">.9</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer101">
<span class="koboSpan" id="kobo.311.1"><img alt="Figure 6.9 – Summarization of a news article" src="image/B22045_06_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.312.1">Figure 6.9 – Summarization of a news article</span></p>
<p><span class="koboSpan" id="kobo.313.1">There are a couple </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.314.1">of ways to summarize small files in Bedrock. </span><span class="koboSpan" id="kobo.314.2">If you’re using the AWS Python SDK, you can pass the small file text into the prompt directly, as shown in the following code. </span><span class="koboSpan" id="kobo.314.3">However, if you would like to summarize a couple of paragraphs, you can utilize </span><em class="italic"><span class="koboSpan" id="kobo.315.1">prompt templates</span></em><span class="koboSpan" id="kobo.316.1"> to place the text dynamically within the prompts and use LangChain to invoke </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">the model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.318.1">
prompt = """
Today we're going to take a look at the well-established Amazon.com, Inc. </span><span class="koboSpan" id="kobo.318.2">(NASDAQ:AMZN). </span><span class="koboSpan" id="kobo.318.3">The company's stock led the NASDAQGS gainers with a relatively large price hike in the past couple of weeks. </span><span class="koboSpan" id="kobo.318.4">The recent jump in the share price has meant that the company is trading at close to its 52-week high. </span><span class="koboSpan" id="kobo.318.5">With many analysts covering the large-cap stock, we may expect any price-sensitive announcements have already been factored into the stock's share price. </span><span class="koboSpan" id="kobo.318.6">But what if there is still an opportunity to buy? </span><span class="koboSpan" id="kobo.318.7">Let's take a look at Amazon.com's outlook and value based on the most recent financial data to see if the opportunity still exists.
</span><span class="koboSpan" id="kobo.318.8">Check out our latest analysis for Amazon.com
What's The Opportunity In Amazon.com?
</span><span class="koboSpan" id="kobo.318.9">Great news for investors – Amazon.com is still trading at a fairly cheap price. </span><span class="koboSpan" id="kobo.318.10">According to our valuation, the intrinsic value for the stock is $238.66, but it is currently trading at US$174 on the share market, meaning that there is still an opportunity to buy now. </span><span class="koboSpan" id="kobo.318.11">What's more interesting is that, Amazon.com's share price is quite volatile, which gives us more chances to buy since the share price could sink lower (or rise higher) in the future. </span><span class="koboSpan" id="kobo.318.12">This is based on its high beta, which is a good indicator for how much the stock moves relative to the rest of the market.
</span><span class="koboSpan" id="kobo.318.13">Can we expect growth from Amazon.com?
</span><span class="koboSpan" id="kobo.318.14">earnings-and-revenue-growth
earnings-and-revenue-growth
Future outlook is an important aspect when you're looking at buying a stock, especially if you are an investor looking for growth in your portfolio. </span><span class="koboSpan" id="kobo.318.15">Buying a great company with a robust outlook at a cheap price is always a good investment, so let's also take a look at the company's future expectations. </span><span class="koboSpan" id="kobo.318.16">With profit expected to more than double over the next couple of years, the future seems bright for Amazon.com. </span><span class="koboSpan" id="kobo.318.17">It looks like higher cash flow is on the cards for the stock, which should feed into a higher share valuation.
</span><span class="koboSpan" id="kobo.318.18">What This Means For You
Are you a shareholder? </span><span class="koboSpan" id="kobo.318.19">Since AMZN is currently undervalued, it may be a great time to accumulate more of your holdings in the stock. </span><span class="koboSpan" id="kobo.318.20">With a positive outlook on the horizon, it seems like this growth has not yet been fully factored into the share price. </span><span class="koboSpan" id="kobo.318.21">However, there are also other factors such as financial health to consider, which could explain the current undervaluation.
</span><span class="koboSpan" id="kobo.318.22">Are you a potential investor? </span><span class="koboSpan" id="kobo.318.23">If you've been keeping an eye on AMZN for a while, now might be the time to enter the stock. </span><span class="koboSpan" id="kobo.318.24">Its buoyant future outlook isn't fully reflected in the current share price yet, which means it's not too late to buy AMZN. </span><span class="koboSpan" id="kobo.318.25">But before you make any investment decisions, consider other factors such as the strength of its balance sheet, in order to make a well-informed investment decision.
</span><span class="koboSpan" id="kobo.318.26">Diving deeper into the forecasts for Amazon.com mentioned earlier will help you understand how analysts view the stock going forward. </span><span class="koboSpan" id="kobo.318.27">Luckily, you can check out what analysts are forecasting by clicking here.
</span><span class="koboSpan" id="kobo.318.28">If you are no longer interested in Amazon.com, you can use our free platform to see our list of over 50 other stocks with a high growth potential.
</span><span class="koboSpan" id="kobo.318.29">"""
body = json.dumps({"inputText": prompt,
                   "textGenerationConfig":{
                       "maxTokenCount":4096,
                       "stopSequences":[],
                       "temperature":0,
                       "topP":1
                   },
                  })
modelId = 'amazon.titan-tg1-large' # change this to use a different version from the model provider
accept = 'application/json'
contentType = 'application/json'
response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)
response_body = json.loads(response.get('body').read())
print(response_body.get('results')[0].get('outputText'))</span></pre>
<p><span class="koboSpan" id="kobo.319.1">The response is shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.320.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.321.1">.10</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer102">
<span class="koboSpan" id="kobo.323.1"><img alt="Figure 6.10 – Small file summarization response" src="image/B22045_06_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.324.1">Figure 6.10 – Small file summarization response</span></p>
<p><span class="koboSpan" id="kobo.325.1">We have parsed a news article (</span><a href="https://finance.yahoo.com/news/us-174-time-put-amazon-110026932.html"><span class="koboSpan" id="kobo.326.1">https://finance.yahoo.com/news/us-174-time-put-amazon-110026932.html</span></a><span class="koboSpan" id="kobo.327.1">) from Yahoo! </span><span class="koboSpan" id="kobo.327.2">Finance as a sample context to the prompt and invoked the Titan text model to generate the summarized response, as shown in the </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">preceding</span></span><span class="No-Break"><a id="_idIndexMarker522"/></span><span class="No-Break"><span class="koboSpan" id="kobo.329.1"> figure.</span></span></p>
<p><span class="koboSpan" id="kobo.330.1">Now, let’s look at the techniques for summarizing </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">large files.</span></span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor129"/><span class="koboSpan" id="kobo.332.1">Summarization of large files</span></h2>
<p><span class="koboSpan" id="kobo.333.1">Large files ca</span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.334.1">n include large documents or book(s) worth</span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.335.1"> of information that do not fit into the context length of the model. </span><span class="koboSpan" id="kobo.335.2">When we say large documents, this includes 10-K reports, </span><strong class="bold"><span class="koboSpan" id="kobo.336.1">Federal Open Market Committee</span></strong><span class="koboSpan" id="kobo.337.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.338.1">FOMC</span></strong><span class="koboSpan" id="kobo.339.1">) reports, public </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.340.1">health reports, clinical study reports, e-magazines, service documentation, and more. </span><span class="koboSpan" id="kobo.340.2">The 10-K report for Amazon is an example of a large </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">file: </span></span><a href="https://www.sec.gov/Archives/edgar/data/1018724/000101872424000008/amzn-20231231.htm"><span class="No-Break"><span class="koboSpan" id="kobo.342.1">https://www.sec.gov/Archives/edgar/data/1018724/000101872424000008/amzn-20231231.htm</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.343.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.344.1">When working with large files for summarizing text, several challenges </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">are involved:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.346.1">Context length limitations</span></strong><span class="koboSpan" id="kobo.347.1">: All FMs, such as the ones used in Amazon Bedrock, have a maximum context length or input size that they can process at once. </span><span class="koboSpan" id="kobo.347.2">This limit varies from model to model, but it is typically in the range of a few thousand tokens (words or word pieces). </span><span class="koboSpan" id="kobo.347.3">For example, you can find FMs such as the Anthropic Claude 3 family with 200k tokens. </span><span class="koboSpan" id="kobo.347.4">When working with large documents that exceed this context length, it becomes impossible to summarize the entire document accurately and coherently. </span><span class="koboSpan" id="kobo.347.5">The model may miss important information or fail to capture the overall context and nuances present in the </span><span class="No-Break"><span class="koboSpan" id="kobo.348.1">original text.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.349.1">Hallucinations</span></strong><span class="koboSpan" id="kobo.350.1">: Hallucination is a phenomenon where models generate output that is</span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.351.1"> not grounded in the input data or contains factual inconsistencies. </span><span class="koboSpan" id="kobo.351.2">This issue can become more prevalent when dealing with large documents as the model might struggle to maintain coherence and faithfulness to the original text. </span><span class="koboSpan" id="kobo.351.3">As the</span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.352.1"> input </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.353.1">size increases, the model may start generating plausible-sounding but factually incorrect information, potentially leading to </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">inaccurate summaries.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.355.1">Memory and computational constraints</span></strong><span class="koboSpan" id="kobo.356.1">: Summarizing large documents can be computationally intensive and may require significant memory resources. </span><span class="koboSpan" id="kobo.356.2">Generative AI models need to process and store the entire input text, as well as intermediate representations and generated outputs. </span><span class="koboSpan" id="kobo.356.3">When working with very large documents, you might experience performance degradation due to the high computational demands if they’re not handled with dedicated compute capacity (see the </span><em class="italic"><span class="koboSpan" id="kobo.357.1">Provisioned throughput architecture</span></em><span class="koboSpan" id="kobo.358.1"> section in </span><a href="B22045_12.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.359.1">Chapter 12</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.360.1">).</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.361.1">Context understanding</span></strong><span class="koboSpan" id="kobo.362.1">: Large documents often contain complex structures, such as sections, subsections, and cross-references. </span><span class="koboSpan" id="kobo.362.2">Generative AI models may struggle to accurately capture and understand the relationships and dependencies between different parts of the document. </span><span class="koboSpan" id="kobo.362.3">This can lead to summaries that lack coherence or fail to accurately represent the overall structure and flow of the </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">original content.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.364.1">Topic drift and coherence</span></strong><span class="koboSpan" id="kobo.365.1">: As the length of the input text increases, it becomes more challenging for the models to maintain focus and coherence throughout the summarization process. </span><span class="koboSpan" id="kobo.365.2">The model may drift away from the main topic or fail to properly connect and transition between different aspects of the document, resulting in summaries that lack cohesion </span><span class="No-Break"><span class="koboSpan" id="kobo.366.1">or clarity.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.367.1">To address these </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.368.1">challenges, let’s look at </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.369.1">summarizing large files </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">using LangChain.</span></span></p>
<h3><span class="koboSpan" id="kobo.371.1">Text summarization using LangChain’s summarization chain</span></h3>
<p><span class="koboSpan" id="kobo.372.1">Using LangChain, we </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.373.1">are going to </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.374.1">break down large files into smaller, more manageable chunks and process them sequentially. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.375.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.376.1">.11</span></em><span class="koboSpan" id="kobo.377.1"> shows the architecture of large text summarization </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">using LangChain:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer103">
<span class="koboSpan" id="kobo.379.1"><img alt="Figure 6.11 – Large file summarization in LangChain" src="image/B22045_06_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.380.1">Figure 6.11 – Large file summarization in LangChain</span></p>
<p><span class="koboSpan" id="kobo.381.1">Here’s how the </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">process works:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.383.1">Data ingestion</span></strong><span class="koboSpan" id="kobo.384.1">: The first step in the process is to load a large document or file into the system. </span><span class="koboSpan" id="kobo.384.2">This involves loading the file from an Amazon S3 bucket or downloading it directly from the internet. </span><span class="koboSpan" id="kobo.384.3">The files you can provide can be in the form of text, PDF, Word documents, </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">and more.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.386.1">Chunking</span></strong><span class="koboSpan" id="kobo.387.1">: Once the document has been loaded, the LangChain utility is employed to split the content into multiple smaller chunks. </span><span class="koboSpan" id="kobo.387.2">The chunking process can be based on various criteria, such as character or word count, sentence boundaries, or even semantic segmentation techniques. </span><span class="koboSpan" id="kobo.387.3">The size of the chunks is typically determined by the limitations of the model being used for summarization. </span><span class="koboSpan" id="kobo.387.4">Even though there are a variety of chunking techniques, </span><strong class="source-inline"><span class="koboSpan" id="kobo.388.1">RecursiveCharacterTextSplitter</span></strong><span class="koboSpan" id="kobo.389.1"> is recommended for general text, as per the LangChain </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">documentation: </span></span><a href="https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/"><span class="No-Break"><span class="koboSpan" id="kobo.391.1">https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.392.1">.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.393.1">It recursively splits the text into smaller chunks until each chunk’s size falls below a specified threshold. </span><span class="koboSpan" id="kobo.393.2">The splitting process leverages separators (</span><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">"\n\n"</span></strong><span class="koboSpan" id="kobo.395.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.396.1">"\n"</span></strong><span class="koboSpan" id="kobo.397.1">), which ensures that individual paragraphs remain intact within a single chunk, rather </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.398.1">than </span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.399.1">being fragmented across </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">multiple chunks.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.401.1">Summarization chain</span></strong><span class="koboSpan" id="kobo.402.1">: The next step is to use the chunks and perform summarization. </span><span class="koboSpan" id="kobo.402.2">LangChain provides three summarization chains – </span><em class="italic"><span class="koboSpan" id="kobo.403.1">stuff</span></em><span class="koboSpan" id="kobo.404.1">, </span><em class="italic"><span class="koboSpan" id="kobo.405.1">map_reduce</span></em><span class="koboSpan" id="kobo.406.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.407.1">refine</span></em><span class="koboSpan" id="kobo.408.1">. </span><span class="koboSpan" id="kobo.408.2">Let’s take a </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">closer look:</span></span><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.410.1">stuff</span></strong><span class="koboSpan" id="kobo.411.1">: As the name suggests, this chain stuffs all the chunks into a </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">single prompt.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">map_reduce</span></strong><span class="koboSpan" id="kobo.414.1">: The map-reduce chain is a powerful pattern that allows you to split a large task into smaller subtasks, process them independently, and then combine the results. </span><span class="koboSpan" id="kobo.414.2">In the context of text summarization, this chain type is used to break down a long text document into smaller chunks, summarize each chunk independently using an LLM, and then combine the summaries into a final </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">summarized output.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.416.1">refine</span></strong><span class="koboSpan" id="kobo.417.1">: This chain starts by summarizing the first chunk. </span><span class="koboSpan" id="kobo.417.2">Then, </span><strong class="source-inline"><span class="koboSpan" id="kobo.418.1">refine</span></strong><span class="koboSpan" id="kobo.419.1"> takes this summary and combines it with the second chunk to generate a new summary that encompasses both pieces of information. </span><span class="koboSpan" id="kobo.419.2">This process continues, where the latest summary is combined with the next chunk, and a new summary is generated. </span><span class="koboSpan" id="kobo.419.3">This iterative approach repeats until all the chunks have been incorporated into the </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">final summary.</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.421.1">To load any of these summarization chains, you can call </span><strong class="source-inline"><span class="koboSpan" id="kobo.422.1">load_summarize_chain</span></strong><span class="koboSpan" id="kobo.423.1"> and provide the </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">chain type:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.425.1">
from langchain.chains.summarize import load_summarize_chain</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.426.1">
summary_chain = load_summarize_chain(llm=llm, chain_type="map_reduce", verbose=False)</span></pre></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.427.1">Final summary</span></strong><span class="koboSpan" id="kobo.428.1">: Based on the summarization chain you select and once all the chunks have been processed, the final summary represents a condensed version of the entire </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">original document.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.430.1">The notebook at </span><a href="https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/06_OpenSource_examples/00_Langchain_TextGeneration_examples/05_long-text-summarization-titan%20Langchain.ipynb"><span class="koboSpan" id="kobo.431.1">https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/06_OpenSource_examples/00_Langchain_TextGeneration_examples/05_long-text-summarization-titan%20Langchain.ipynb</span></a><span class="koboSpan" id="kobo.432.1"> showcases the use of long text </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.433.1">summarization</span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.434.1"> using LangChain. </span><span class="koboSpan" id="kobo.434.2">In this example, it uses </span><strong class="source-inline"><span class="koboSpan" id="kobo.435.1">map_reduce</span></strong><span class="koboSpan" id="kobo.436.1"> as the chain type. </span><span class="koboSpan" id="kobo.436.2">We recommend that you try out different chain types and provide any blog posts, files, or news articles as </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">a prompt.</span></span></p>
<p><span class="koboSpan" id="kobo.438.1">Now that we’ve summarized large files using the LangChain chain type, let’s say we want to summarize a whole book or multiple books’ worth of information. </span><span class="koboSpan" id="kobo.438.2">In such scenarios, where large manuscripts or books need to be summarized, the RAG approach can be potentially beneficial. </span><span class="koboSpan" id="kobo.438.3">However, please note that the summarized response might not contain some essential elements from the book – in other words, there could be information loss. </span><span class="koboSpan" id="kobo.438.4">Various advanced RAG techniques, such as query refinement, can be utilized to retrieve the summarized response and essential elements from the text. </span><span class="koboSpan" id="kobo.438.5">To learn more about query refinement for RAG, please take a look at the paper </span><em class="italic"><span class="koboSpan" id="kobo.439.1">RQ-RAG: Learning to Refine Queries for Retrieval Augmented </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.440.1">Generation</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.441.1"> (</span></span><a href="https://arxiv.org/html/2404.00610v1"><span class="No-Break"><span class="koboSpan" id="kobo.442.1">https://arxiv.org/html/2404.00610v1</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.443.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.444.1">To learn more about how RAG works and some advanced RAG techniques, please refer to </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.445.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.446.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.447.1">Next, we’ll look at </span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.448.1">text summarization</span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.449.1"> via Amazon Bedrock </span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">Knowledge Base.</span></span></p>
<h3><span class="koboSpan" id="kobo.451.1">Amazon Bedrock Knowledge Base</span></h3>
<p><span class="koboSpan" id="kobo.452.1">In </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.453.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.454.1">, we</span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.455.1"> looked at how </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.456.1">Amazon Bedrock Knowledge Base works and how to set it up. </span><span class="koboSpan" id="kobo.456.2">Let’s see an example of summarization using </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">Knowledge Base.</span></span></p>
<p><span class="koboSpan" id="kobo.458.1">We have put the </span><em class="italic"><span class="koboSpan" id="kobo.459.1">Attention is All You Need</span></em><span class="koboSpan" id="kobo.460.1"> research paper in our data store Amazon S3 bucket and synced it with our Bedrock Knowledge base, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.461.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.462.1">.12</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer104">
<span class="koboSpan" id="kobo.464.1"><img alt="Figure 6.12 – Knowledge Base data source" src="image/B22045_06_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.465.1">Figure 6.12 – Knowledge Base data source</span></p>
<p><span class="koboSpan" id="kobo.466.1">Select the model and provide a prompt to summarize the content. </span><span class="koboSpan" id="kobo.466.2">You will see the response from the LLM, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.467.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.468.1">.13</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer105">
<span class="koboSpan" id="kobo.470.1"><img alt="Figure 6.13 – Test Knowledge base" src="image/B22045_06_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.471.1">Figure 6.13 – Test Knowledge base</span></p>
<p><span class="koboSpan" id="kobo.472.1">If you would like to try this via APIs, you can</span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.473.1"> call the </span><strong class="bold"><span class="koboSpan" id="kobo.474.1">Retrieve</span></strong><span class="koboSpan" id="kobo.475.1"> API or the </span><strong class="bold"><span class="koboSpan" id="kobo.476.1">RetrieveAndGenerate</span></strong><span class="koboSpan" id="kobo.477.1"> API. </span><span class="koboSpan" id="kobo.477.2">The</span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.478.1"> Retrieve API accesses and retrieves the relevant data from Knowledge Base, whereas the RetrieveAndGenerate API, in addition to retrieving the data, generates the response based on the retrieved results. </span><span class="koboSpan" id="kobo.478.2">For more details on Amazon Bedrock Knowledge Base, please refer to </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.479.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.480.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.481.1">In this section, we discussed how to utilize text summarization systems with Amazon Bedrock. </span><span class="koboSpan" id="kobo.481.2">Summarizing small files is straightforward and involves utilizing the model’s context length. </span><span class="koboSpan" id="kobo.481.3">However, summarizing large files requires chunking and specialized techniques such as LangChain’s summarization chains, RAG, or Amazon Bedrock Knowledge Base to handle context length limitations, hallucination, computational constraints, and </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1">coherence issues.</span></span></p>
<p><span class="koboSpan" id="kobo.483.1">Now that we have looked at generating and summarizing text using Amazon Bedrock, let’s look at how </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.484.1">organizations</span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.485.1"> can use these techniques and create a secure serverless solution involving other </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">AWS services.</span></span></p>
<h1 id="_idParaDest-123"><a id="_idTextAnchor130"/><span class="koboSpan" id="kobo.487.1">Creating a secure serverless solution</span></h1>
<p><span class="koboSpan" id="kobo.488.1">When working</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.489.1"> with Generative AI</span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.490.1"> models from Amazon Bedrock, organizations can develop an application that is secure and serverless. </span><span class="koboSpan" id="kobo.490.2">Instead of interacting directly with Amazon Bedrock using SDKs, they can have an interactive chatbot that abstracts away any complexity, provides a rich customer experience, and boosts </span><span class="No-Break"><span class="koboSpan" id="kobo.491.1">overall productivity.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.492.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.493.1">.14</span></em><span class="koboSpan" id="kobo.494.1"> shows an architecture diagram of how the user can interact with the web-based chatbot developed via AWS Amplify and have conversations, generate text in various forms, and perform language translation, text summarization, </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">and more:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer106">
<span class="koboSpan" id="kobo.496.1"><img alt="Figure 6.14 – Serverless enterprise application with Amazon Bedrock" src="image/B22045_06_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.497.1">Figure 6.14 – Serverless enterprise application with Amazon Bedrock</span></p>
<p><span class="koboSpan" id="kobo.498.1">Let’s take a closer look at </span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">this process:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.500.1">User interaction with the chatbot on AWS Amplify</span></strong><span class="koboSpan" id="kobo.501.1">: AWS Amplify is a comprehensive set of tools and services that simplify the development and deployment of full-stack cloud-powered web and mobile applications. </span><span class="koboSpan" id="kobo.501.2">The user initiates the workflow by interacting with a chatbot integrated into a web application developed using </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">AWS Amplify.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.503.1">User authentication and authorization with Amazon Cognito</span></strong><span class="koboSpan" id="kobo.504.1">: Amazon Cognito is a robust user identity management service provided by AWS. </span><span class="koboSpan" id="kobo.504.2">When the user interacts with the chatbot, AWS communicates with Amazon Cognito to perform user authentication and authorization. </span><span class="koboSpan" id="kobo.504.3">Amazon Cognito supports various authentication methods, including traditional username/password combinations, social identity providers (for example, Google or Facebook), and multi-factor authentication. </span><span class="koboSpan" id="kobo.504.4">It also provides features for user registration, account recovery, and secure storage of </span><span class="No-Break"><span class="koboSpan" id="kobo.505.1">user data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.506.1">API Gateway as a centralized entry point</span></strong><span class="koboSpan" id="kobo.507.1">: Once the user has been authenticated and authorized, their request is routed through an API gateway, which acts as a centralized entry point for APIs. </span><span class="koboSpan" id="kobo.507.2">API Gateway is a fully managed service that simplifies the process of creating, publishing, maintaining, monitoring, and </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">securing APIs.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.509.1">Text generation with AWS Lambda and Amazon Bedrock LLMs</span></strong><span class="koboSpan" id="kobo.510.1">: For text generation, API Gateway sends the request (</span><strong class="source-inline"><span class="koboSpan" id="kobo.511.1">/text</span></strong><span class="koboSpan" id="kobo.512.1">) to an AWS Lambda function that performs invocation calls to Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">Bedrock LLMs:</span></span><ol><li class="upper-roman"><span class="koboSpan" id="kobo.514.1">This Lambda function will take the user’s input or prompt and pass it to Amazon</span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.515.1"> Bedrock</span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.516.1"> LLMs to generate relevant and coherent text. </span><span class="koboSpan" id="kobo.516.2">For example, the user can ask to generate an email or prepare a travel itinerary for a </span><span class="No-Break"><span class="koboSpan" id="kobo.517.1">particular destination.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.518.1">Once the Amazon Bedrock LLMs have generated the requested text, the Lambda function receives the response and sends it back to the user through API Gateway. </span><span class="koboSpan" id="kobo.518.2">Here, API Gateway acts as an intermediary, facilitating the communication between the client (that is, the chatbot) and the backend services (Lambda functions and Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.519.1">Bedrock LLMs).</span></span></li></ol></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.520.1">Text summarization with AWS Lambda and Amazon Bedrock LLMs</span></strong><span class="koboSpan" id="kobo.521.1">: For text summarization, API Gateway sends a separate request (</span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1">/summarize</span></strong><span class="koboSpan" id="kobo.523.1">) to another AWS Lambda function specifically designed to perform invocation calls to Amazon Bedrock LLMs for </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">summarization tasks:</span></span><ol><li class="upper-roman"><span class="koboSpan" id="kobo.525.1">This Lambda function performs invocation calls to Amazon Bedrock LLMs to summarize text based on the user’s input or prompt and the provided context (small or </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">large files).</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.527.1">After the Amazon Bedrock LLM has generated the summarized text, the Lambda function receives the response and sends it back to the user via </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">API Gateway.</span></span></li></ol></li>
</ol>
<p><span class="koboSpan" id="kobo.529.1">By separating the text generation and summarization tasks into different Lambda functions and API Gateway routes, the application can efficiently handle different types of requests and leverage the specialized capabilities of Amazon Bedrock LLMs for </span><span class="No-Break"><span class="koboSpan" id="kobo.530.1">each task.</span></span></p>
<p><span class="koboSpan" id="kobo.531.1">This workflow highlights the flexibility and modular nature of AWS services, allowing multiple components to be integrated to build complex applications. </span><span class="koboSpan" id="kobo.531.2">AWS Lambda functions act as computational engines that make invocation calls to Amazon Bedrock LLMs to perform text generation </span><span class="No-Break"><span class="koboSpan" id="kobo.532.1">and summarization.</span></span></p>
<p><span class="koboSpan" id="kobo.533.1">By breaking down the application into smaller, independent components, developers can easily maintain, update, and scale individual parts of the system without affecting the </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">entire application.</span></span></p>
<p><span class="koboSpan" id="kobo.535.1">If you’re curious about trying out the serverless chatbot with Amazon Bedrock, check </span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">out </span></span><a href="https://github.com/aws-samples/amazon-serverless-chatbot-using-bedrock"><span class="No-Break"><span class="koboSpan" id="kobo.537.1">https://github.com/aws-samples/amazon-serverless-chatbot-using-bedrock</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.538.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.539.1">At this point, you</span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.540.1"> should</span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.541.1"> understand and be able to implement text generation and summarization with Amazon Bedrock in real-world </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">use cases.</span></span></p>
<h1 id="_idParaDest-124"><a id="_idTextAnchor131"/><span class="koboSpan" id="kobo.543.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.544.1">In this chapter, we dived into the architecture patterns for generating and summarizing text using Amazon Bedrock. </span><span class="koboSpan" id="kobo.544.2">The first part of this chapter covered text generation. </span><span class="koboSpan" id="kobo.544.3">We looked at the fundamentals of text generation through prompt engineering techniques, in-line context training, and orchestration with LangChain. </span><span class="koboSpan" id="kobo.544.4">Then, we explored various use cases and patterns for text generation that you can apply to </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">real-world scenarios.</span></span></p>
<p><span class="koboSpan" id="kobo.546.1">The second part of this chapter covered text summarization. </span><span class="koboSpan" id="kobo.546.2">We discussed both extractive and abstractive summarization approaches and their respective applications. </span><span class="koboSpan" id="kobo.546.3">Furthermore, we examined the systems and techniques that can be employed for text summarization using </span><span class="No-Break"><span class="koboSpan" id="kobo.547.1">Amazon Bedrock.</span></span></p>
<p><span class="koboSpan" id="kobo.548.1">In the next chapter, we will explore building question-answering and </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">conversational interfaces.</span></span></p>
</div>
</body></html>