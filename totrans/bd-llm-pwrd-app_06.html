<html><head></head><body>
<div class="calibre1" id="_idContainer121">
<h1 class="chapternumber"><span class="kobospan" id="kobo.1.1">6</span></h1>
<h1 class="chaptertitle" id="_idParaDest-86"><span class="kobospan" id="kobo.2.1">Building Conversational Applications</span></h1>
<p class="normal"><span class="kobospan" id="kobo.3.1">With this chapter, we embark on the hands-on section of this book, with our first concrete implementation of LLM-powered applications. </span><span class="kobospan" id="kobo.3.2">Throughout this chapter, we will cover a step-by-step implementation of a conversational application, using LangChain and its components, building on the knowledge you’ve gained from the previous chapters. </span><span class="kobospan" id="kobo.3.3">By the end of this chapter, you will be able to set up your own conversational application project with just a few lines of code.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.4.1">We will cover the following key topics:</span></p>
<ul class="calibre14">
<li class="bulletlist"><span class="kobospan" id="kobo.5.1">Configuring the schema of a simple chatbot</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.6.1">Adding the memory component</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.7.1">Adding non-parametric knowledge</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.8.1">Adding tools and making the chatbot “agentic”</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.9.1">Developing the front-end with Streamlit</span></li>
</ul>
<h1 class="heading" id="_idParaDest-87"><span class="kobospan" id="kobo.10.1">Technical requirements</span></h1>
<p class="normal"><span class="kobospan" id="kobo.11.1">To complete the tasks in this chapter, you will need the following:</span></p>
<ul class="calibre14">
<li class="bulletlist"><span class="kobospan" id="kobo.12.1">A Hugging Face account and user access token.</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.13.1">An OpenAI account and user access token.</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.14.1">Python 3.7.1 or a later version.</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.15.1">Python packages – make sure to have the following Python packages installed: </span><code class="inlinecode"><span class="kobospan" id="kobo.16.1">langchain</span></code><span class="kobospan" id="kobo.17.1">, </span><code class="inlinecode"><span class="kobospan" id="kobo.18.1">python-dotenv</span></code><span class="kobospan" id="kobo.19.1">, </span><code class="inlinecode"><span class="kobospan" id="kobo.20.1">huggingface_hub, streamlit</span></code><span class="kobospan" id="kobo.21.1">, </span><code class="inlinecode"><span class="kobospan" id="kobo.22.1">openai</span></code><span class="kobospan" id="kobo.23.1">, </span><code class="inlinecode"><span class="kobospan" id="kobo.24.1">pypdf</span></code><span class="kobospan" id="kobo.25.1">, </span><code class="inlinecode"><span class="kobospan" id="kobo.26.1">tiktoken</span></code><span class="kobospan" id="kobo.27.1">, </span><code class="inlinecode"><span class="kobospan" id="kobo.28.1">faiss-cpu</span></code><span class="kobospan" id="kobo.29.1">, and </span><code class="inlinecode"><span class="kobospan" id="kobo.30.1">google-search-results.</span></code><span class="kobospan" id="kobo.31.1"> They can be easily installed via </span><code class="inlinecode"><span class="kobospan" id="kobo.32.1">pip install</span></code><span class="kobospan" id="kobo.33.1"> in your terminal.</span></li>
</ul>
<p class="normal1"><span class="kobospan" id="kobo.34.1">You’ll find the code for this chapter in the book’s GitHub repository at </span><a href="Chapter_06.xhtml" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.35.1">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</span></span></a><span class="kobospan" id="kobo.36.1">.</span></p>
<h1 class="heading" id="_idParaDest-88"><span class="kobospan" id="kobo.37.1">Getting started with conversational applications</span></h1>
<p class="normal"><span class="kobospan" id="kobo.38.1">A conversational application</span><a id="_idIndexMarker420" class="calibre3"/><span class="kobospan" id="kobo.39.1"> is a type of software that can interact with users using natural language. </span><span class="kobospan" id="kobo.39.2">It can be used for various purposes, such as providing information, assistance, entertainment, or transactions. </span><span class="kobospan" id="kobo.39.3">Generally speaking, a conversational application can use different modes of communication, such as text, voice, graphics, or even touch. </span><span class="kobospan" id="kobo.39.4">A conversational application can also use different platforms, such as messaging apps, websites, mobile devices, or smart speakers.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.40.1">Today, conversational applications are being taken to the next level thanks to LLMs. </span><span class="kobospan" id="kobo.40.2">Let’s look at some of the benefits</span><a id="_idIndexMarker421" class="calibre3"/><span class="kobospan" id="kobo.41.1"> that they provide:</span></p>
<ul class="calibre14">
<li class="bulletlist"><span class="kobospan" id="kobo.42.1">Not only do LLMs provide a new level of natural language interactions, but they can also enable applications to perform reasoning based on the best responses, given users’ preferences.</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.43.1">As we saw in previous chapters, LLMs can leverage their parametric knowledge, but are also enriched with non-parametric knowledge, thanks to embeddings and plug-ins.</span></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.44.1">Finally, LLMs are also able to keep track of the conversation thanks to different types of memory.</span></li>
</ul>
<p class="normal1"><span class="kobospan" id="kobo.45.1">The following image shows what the architecture of a conversational bot might look like:</span></p>
<figure class="mediaobject"><span class="kobospan" id="kobo.46.1"><img alt="A diagram of a computer program  Description automatically generated" src="../Images/B21714_06_01.png" class="calibre4"/></span></figure>
<p class="packt_figref"><span class="kobospan" id="kobo.47.1">Figure 6.1: Sample architecture of a conversational bot</span></p>
<p class="normal1"><span class="kobospan" id="kobo.48.1">Throughout this chapter, we will build from scratch a text conversational application that is able to help users plan their vacations. </span><span class="kobospan" id="kobo.48.2">We will call this app GlobeBotter. </span><span class="kobospan" id="kobo.48.3">We will add incremental layers of complexity</span><a id="_idIndexMarker422" class="calibre3"/><span class="kobospan" id="kobo.49.1"> to make the app as enjoyable as possible for the end user.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.50.1">So, let’s start with the basics behind a conversational app architecture.</span></p>
<h2 class="heading1" id="_idParaDest-89"><span class="kobospan" id="kobo.51.1">Creating a plain vanilla bot</span></h2>
<p class="normal"><span class="kobospan" id="kobo.52.1">To start with, let’s initialize</span><a id="_idIndexMarker423" class="calibre3"/><span class="kobospan" id="kobo.53.1"> our LLM and set the schema for our bot. </span><span class="kobospan" id="kobo.53.2">The schema refers to the type</span><a id="_idIndexMarker424" class="calibre3"/><span class="kobospan" id="kobo.54.1"> of messages the bot is able to receive. </span><span class="kobospan" id="kobo.54.2">In our case, we will have three types of messages:</span></p>
<ul class="calibre14">
<li class="bulletlist"><strong class="screentext"><span class="kobospan" id="kobo.55.1">System message</span></strong><span class="kobospan" id="kobo.56.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.57.1">The instructions we give the bot so that it behaves as a travel assistant.</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.58.1">AI Message</span></strong><span class="kobospan" id="kobo.59.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.60.1">The message generated by the LLM</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.61.1">Human Message</span></strong><span class="kobospan" id="kobo.62.1">: The user’s query</span></li>
</ul>
<p class="normal1"><span class="kobospan" id="kobo.63.1">Let’s start with a simple configuration:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.64.1">from</span></span><span class="kobospan" id="kobo.65.1"> langchain.schema </span><span class="hljs-keyword"><span class="kobospan" id="kobo.66.1">import</span></span><span class="kobospan" id="kobo.67.1"> (
    AIMessage,
    HumanMessage,
    SystemMessage
)
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.68.1">from</span></span><span class="kobospan" id="kobo.69.1"> langchain.chains </span><span class="hljs-keyword"><span class="kobospan" id="kobo.70.1">import</span></span><span class="kobospan" id="kobo.71.1"> LLMChain, ConversationChain
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.72.1">from</span></span><span class="kobospan" id="kobo.73.1"> langchain.chat_models </span><span class="hljs-keyword"><span class="kobospan" id="kobo.74.1">import</span></span><span class="kobospan" id="kobo.75.1"> ChatOpenAI
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.76.1">from</span></span><span class="kobospan" id="kobo.77.1"> langchain.chat_models </span><span class="hljs-keyword"><span class="kobospan" id="kobo.78.1">import</span></span><span class="kobospan" id="kobo.79.1"> ChatOpenAI
chat = ChatOpenAI()
messages = [
    SystemMessage(content=</span><span class="hljs-string"><span class="kobospan" id="kobo.80.1">"You are a helpful assistant that help the user to plan an optimized itinerary."</span></span><span class="kobospan" id="kobo.81.1">),
    HumanMessage(content=</span><span class="hljs-string"><span class="kobospan" id="kobo.82.1">"I'm going to Rome for 2 days, what can I visit?"</span></span><span class="kobospan" id="kobo.83.1">)]
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.84.1">We can then save and print</span><a id="_idIndexMarker425" class="calibre3"/><span class="kobospan" id="kobo.85.1"> the output as follows:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.86.1">output = chat(messages)
</span><span class="hljs-built_in"><span class="kobospan" id="kobo.87.1">print</span></span><span class="kobospan" id="kobo.88.1">(output.content)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.89.1">Here is the output:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.90.1">In Rome, there are many famous attractions to visit. </span><span class="kobospan" id="kobo.90.2">Here's an optimized itinerary for your two-day trip:
Day 1:
 1. </span><span class="kobospan" id="kobo.90.3">Start your day by visiting the Colosseum, one of the world's most iconic ancient landmarks.
 </span><span class="kobospan" id="kobo.90.4">2. </span><span class="kobospan" id="kobo.90.5">Next, explore the nearby Roman Forum, an ancient Roman marketplace.
 </span><span class="kobospan" id="kobo.90.6">3. </span><span class="kobospan" id="kobo.90.7">Afterward, head to the Pantheon, a well-preserved Roman temple with a stunning dome.
</span><span class="kobospan" id="kobo.90.8">4. </span><span class="kobospan" id="kobo.90.9">Take a stroll through the historic district of Trastevere, known for its charming streets and authentic Roman atmosphere.
</span><span class="kobospan" id="kobo.90.10">5. </span><span class="kobospan" id="kobo.90.11">In the evening, visit the Trevi Fountain and toss a coin to ensure your return to Rome.
</span><span class="kobospan" id="kobo.90.12">Day 2:
1. </span><span class="kobospan" id="kobo.90.13">Begin your day at Vatican City, the smallest independent state in the world. </span><span class="kobospan" id="kobo.90.14">Visit St. </span><span class="kobospan" id="kobo.90.15">Peter's Basilica and admire Michelangelo's masterpiece, the Sistine Chapel.
</span><span class="kobospan" id="kobo.90.16">2. </span><span class="kobospan" id="kobo.90.17">Explore the Vatican Museums, home to an extensive collection of art and historical artifacts.
</span><span class="kobospan" id="kobo.90.18">3. </span><span class="kobospan" id="kobo.90.19">Enjoy a leisurely walk along the Tiber River and cross over to the picturesque neighborhood of Castel Sant'Angelo.
</span><span class="kobospan" id="kobo.90.20">4. </span><span class="kobospan" id="kobo.90.21">Visit the Spanish Steps, a popular meeting point with a beautiful view of the city.
</span><span class="kobospan" id="kobo.90.22">5. </span><span class="kobospan" id="kobo.90.23">End your day by exploring the charming neighborhood of Piazza Navona, known for its baroque architecture and lively atmosphere.
</span><span class="kobospan" id="kobo.90.24">Remember to check the opening hours and availability of tickets for the attractions in advance. </span><span class="kobospan" id="kobo.90.25">Enjoy your trip to Rome!
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.91.1">As you can see, the model was pretty good at generating an itinerary in Rome with only one piece of information from our side, the number of days.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.92.1">However, we might want to keep interacting</span><a id="_idIndexMarker426" class="calibre3"/><span class="kobospan" id="kobo.93.1"> with the bot, so that we can further optimize the itinerary, providing more information about our preferences and habits. </span><span class="kobospan" id="kobo.93.2">To achieve that, we need to add memory to our bot.</span></p>
<h2 class="heading1" id="_idParaDest-90"><span class="kobospan" id="kobo.94.1">Adding memory</span></h2>
<p class="normal"><span class="kobospan" id="kobo.95.1">As we’re creating a conversational bot</span><a id="_idIndexMarker427" class="calibre3"/><span class="kobospan" id="kobo.96.1"> with relatively short messages, in this scenario, a </span><code class="inlinecode"><span class="kobospan" id="kobo.97.1">ConversationBufferMemory</span></code><span class="kobospan" id="kobo.98.1"> could be suitable. </span><span class="kobospan" id="kobo.98.2">To make the configuration easier, let’s also initialize a </span><code class="inlinecode"><span class="kobospan" id="kobo.99.1">ConversationChain</span></code><span class="kobospan" id="kobo.100.1"> to combine the LLM and the memory components.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.101.1">Let’s first initialize our memory and chain (I’m keeping </span><code class="inlinecode"><span class="kobospan" id="kobo.102.1">verbose = True</span></code><span class="kobospan" id="kobo.103.1"> so that you can see the bot keeping track of previous messages):</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.104.1">from</span></span><span class="kobospan" id="kobo.105.1"> langchain.memory </span><span class="hljs-keyword"><span class="kobospan" id="kobo.106.1">import</span></span><span class="kobospan" id="kobo.107.1"> ConversationBufferMemory
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.108.1">from</span></span><span class="kobospan" id="kobo.109.1"> langchain.chains </span><span class="hljs-keyword"><span class="kobospan" id="kobo.110.1">import</span></span><span class="kobospan" id="kobo.111.1"> ConversationChain
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=chat, verbose=</span><span class="hljs-literal"><span class="kobospan" id="kobo.112.1">True</span></span><span class="kobospan" id="kobo.113.1">, memory=memory
)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.114.1">Great, now let’s have some interactions with our bot:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.115.1">conversation.run(</span><span class="hljs-string"><span class="kobospan" id="kobo.116.1">"Hi there!"</span></span><span class="kobospan" id="kobo.117.1">)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.118.1">The following is the output:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.119.1">&gt; Entering new ConversationChain chain...
</span><span class="kobospan" id="kobo.119.2">Prompt after formatting:
The following is a friendly conversation between a human and an AI. </span><span class="kobospan" id="kobo.119.3">The AI is talkative and provides lots of specific details from its context. </span><span class="kobospan" id="kobo.119.4">If the AI does not know the answer to a question, it truthfully says it does not know.
</span><span class="kobospan" id="kobo.119.5">Current conversation:
Human: Hi there!
</span><span class="kobospan" id="kobo.119.6">AI:
&gt; Finished chain.
</span><span class="kobospan" id="kobo.119.7">'Hello! </span><span class="kobospan" id="kobo.119.8">How can I assist you today?'
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.120.1">Next, we provide</span><a id="_idIndexMarker428" class="calibre3"/><span class="kobospan" id="kobo.121.1"> the following input:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.122.1">conversation.run(</span><span class="hljs-string"><span class="kobospan" id="kobo.123.1">"</span></span><span class="hljs-string"><span class="kobospan" id="kobo.124.1">what is the most iconic place in Rome?"</span></span><span class="kobospan" id="kobo.125.1">)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.126.1">Here is the corresponding output:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.127.1">&gt; Entering new ConversationChain chain...
</span><span class="kobospan" id="kobo.127.2">Prompt after formatting:
The following is a friendly conversation between a human and an AI. </span><span class="kobospan" id="kobo.127.3">The AI is talkative and provides lots of specific details from its context. </span><span class="kobospan" id="kobo.127.4">If the AI does not know the answer to a question, it truthfully says it does not know.
</span><span class="kobospan" id="kobo.127.5">Current conversation:
Human: Hi there!
</span><span class="kobospan" id="kobo.127.6">AI: Hello! </span><span class="kobospan" id="kobo.127.7">How can I assist you today?
</span><span class="kobospan" id="kobo.127.8">Human: what is the most iconic place in Rome?
</span><span class="kobospan" id="kobo.127.9">AI:
&gt; Finished chain.
</span><span class="kobospan" id="kobo.127.10">'The most iconic place in Rome is probably the Colosseum. </span><span class="kobospan" id="kobo.127.11">It is a magnificent amphitheater that was built in the first century AD and is one of the most recognizable symbols of ancient Rome. </span><span class="kobospan" id="kobo.127.12">The Colosseum was used for gladiatorial contests, public spectacles, and other events. </span><span class="kobospan" id="kobo.127.13">Today, it is a major tourist attraction and a UNESCO World Heritage site.'
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.128.1">As you can see from the chain, it is keeping track of the previous interactions. </span><span class="kobospan" id="kobo.128.2">Let’s challenge it and ask something related to the previous context:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.129.1">conversation.run(</span><span class="hljs-string"><span class="kobospan" id="kobo.130.1">"What kind of other events?"</span></span><span class="kobospan" id="kobo.131.1">)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.132.1">The following is the output that we receive:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.133.1">&gt; Entering new ConversationChain chain...
</span><span class="kobospan" id="kobo.133.2">Prompt after formatting:
The following is a friendly conversation between a human and an AI. </span><span class="kobospan" id="kobo.133.3">The AI is talkative and provides lots of specific details from its context. </span><span class="kobospan" id="kobo.133.4">If the AI does not know the answer to a question, it truthfully says it does not know.
</span><span class="kobospan" id="kobo.133.5">Current conversation:
Human: Hi there!
</span><span class="kobospan" id="kobo.133.6">AI: Hello! </span><span class="kobospan" id="kobo.133.7">How can I assist you today?
</span><span class="kobospan" id="kobo.133.8">Human: what is the most iconic place in Rome?
</span><span class="kobospan" id="kobo.133.9">AI: The most iconic place in Rome is probably the Colosseum. </span><span class="kobospan" id="kobo.133.10">It is a magnificent amphitheater that was built in the first century AD and is one of the most recognizable symbols of ancient Rome. </span><span class="kobospan" id="kobo.133.11">The Colosseum was used for gladiatorial contests, public spectacles, and other events. </span><span class="kobospan" id="kobo.133.12">Today, it is a major tourist attraction and a UNESCO World Heritage site.
</span><span class="kobospan" id="kobo.133.13">Human: What kind of other events?
</span><span class="kobospan" id="kobo.133.14">AI:
&gt; Finished chain.
</span><span class="kobospan" id="kobo.133.15">'Other events that took place at the Colosseum include mock sea battles, animal hunts, and reenactments of famous battles. </span><span class="kobospan" id="kobo.133.16">The Colosseum was also used for executions and religious ceremonies. </span><span class="kobospan" id="kobo.133.17">It was a versatile venue that could accommodate a variety of events and entertainments.'
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.134.1">The bot was able to understand</span><a id="_idIndexMarker429" class="calibre3"/><span class="kobospan" id="kobo.135.1"> that our request was related to its previous answer. </span><span class="kobospan" id="kobo.135.2">We can also retrieve the message history with the </span><code class="inlinecode"><span class="kobospan" id="kobo.136.1">memory.load_memory_variables()</span></code><span class="kobospan" id="kobo.137.1"> method (you can see the full output in the GitHub repository). </span><span class="kobospan" id="kobo.137.2">Here is a snippet of the output:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.138.1">{'history': 'Human: Hi there!\nAI: Hello! </span><span class="kobospan" id="kobo.138.2">How can I assist you today?\nHuman: what is the most iconic place in Rome?....
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.139.1">Rather than running the conversation.run method at every interaction, I’ve coded a </span><code class="inlinecode"><span class="kobospan" id="kobo.140.1">while</span></code><span class="kobospan" id="kobo.141.1"> cycle to make it interactive. </span><span class="kobospan" id="kobo.141.2">The following is a snapshot of the whole conversation (you can find it in the book’s GitHub repository):</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.142.1">while</span></span> <span class="hljs-literal"><span class="kobospan" id="kobo.143.1">True</span></span><span class="kobospan" id="kobo.144.1">:
    query = </span><span class="hljs-built_in"><span class="kobospan" id="kobo.145.1">input</span></span><span class="kobospan" id="kobo.146.1">(</span><span class="hljs-string"><span class="kobospan" id="kobo.147.1">'you: '</span></span><span class="kobospan" id="kobo.148.1">)
    </span><span class="hljs-keyword"><span class="kobospan" id="kobo.149.1">if</span></span><span class="kobospan" id="kobo.150.1"> query == </span><span class="hljs-string"><span class="kobospan" id="kobo.151.1">'q'</span></span><span class="kobospan" id="kobo.152.1">:
        </span><span class="hljs-keyword"><span class="kobospan" id="kobo.153.1">break</span></span><span class="kobospan" id="kobo.154.1">
    output = conversation({</span><span class="hljs-string"><span class="kobospan" id="kobo.155.1">"input"</span></span><span class="kobospan" id="kobo.156.1">: query})
    </span><span class="hljs-built_in"><span class="kobospan" id="kobo.157.1">print</span></span><span class="kobospan" id="kobo.158.1">(</span><span class="hljs-string"><span class="kobospan" id="kobo.159.1">'User: '</span></span><span class="kobospan" id="kobo.160.1">, query)
    </span><span class="hljs-built_in"><span class="kobospan" id="kobo.161.1">print</span></span><span class="kobospan" id="kobo.162.1">(</span><span class="hljs-string"><span class="kobospan" id="kobo.163.1">'AI system: '</span></span><span class="kobospan" id="kobo.164.1">, output['response'])
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.165.1">The following is a truncated sample from the output (you can find the whole output in the book’s GitHub repository):</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.166.1">User:  hello
AI system:  Hello! </span><span class="kobospan" id="kobo.166.2">How can I assist you today?
</span><span class="kobospan" id="kobo.166.3">User:  I'm planning a 1-day trip in Venice. </span><span class="kobospan" id="kobo.166.4">What should I visit?
</span><span class="kobospan" id="kobo.166.5">AI system:  That sounds like a wonderful plan! </span><span class="kobospan" id="kobo.166.6">In Venice, there are several must-visit attractions that you can explore in a day. </span><span class="kobospan" id="kobo.166.7">Here's a suggested itinerary for your 1-day trip in Venice:
1. </span><span class="kobospan" id="kobo.166.8">St. </span><span class="kobospan" id="kobo.166.9">Mark's Square (Piazza San Marco): [...] Enjoy your trip to Venice!
</span><span class="kobospan" id="kobo.166.10">User:  thanks! </span><span class="kobospan" id="kobo.166.11">I'm planning to be around also the next day, and I love hiking. </span><span class="kobospan" id="kobo.166.12">Do you have any suggestion nearby?
</span><span class="kobospan" id="kobo.166.13">AI system:  Certainly! </span><span class="kobospan" id="kobo.166.14">If you enjoy hiking and want to explore the natural beauty around Venice, there are a few options you can consider for the next day:
1. </span><span class="kobospan" id="kobo.166.15">The Dolomites: [...]
User:  which one is closer to Milan?
</span><span class="kobospan" id="kobo.166.16">AI system:  If you're looking for a hiking destination closer to Milan, the best option would be the Lombardy region [...]
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.167.1">As you can see, now the AI assistant</span><a id="_idIndexMarker430" class="calibre3"/><span class="kobospan" id="kobo.168.1"> is capable of keeping track of the whole conversation. </span><span class="kobospan" id="kobo.168.2">In the next section, we are going to add yet another layer of complexity: an external knowledge base.</span></p>
<h2 class="heading1" id="_idParaDest-91"><span class="kobospan" id="kobo.169.1">Adding non-parametric knowledge</span></h2>
<p class="normal"><span class="kobospan" id="kobo.170.1">Imagine that you also want your GlobeBotter</span><a id="_idIndexMarker431" class="calibre3"/><span class="kobospan" id="kobo.171.1"> to have access to exclusive documentation about itineraries that are not part of its parametric knowledge.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.172.1">To do so, we can either embed the documentation in a VectorDB or directly use a retriever to do the job. </span><span class="kobospan" id="kobo.172.2">In this case, we will use a vector-store-backed retriever using a particular chain, </span><code class="inlinecode"><span class="kobospan" id="kobo.173.1">ConversationalRetrievalChain.</span></code><span class="kobospan" id="kobo.174.1"> This type of chain leverages a retriever over the provided knowledge base that has the chat history, which can be passed as a parameter using the desired type of memory previously seen.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.175.1">With this goal in mind, we will use a sample Italy travel guide PDF downloaded from </span><a href="https://www.minube.net/guides/italy" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.176.1">https://www.minube.net/guides/italy</span></span></a><span class="kobospan" id="kobo.177.1">.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.178.1">The following Python code</span><a id="_idIndexMarker432" class="calibre3"/><span class="kobospan" id="kobo.179.1"> shows how to initialize all the ingredients we need, which are:</span></p>
<ul class="calibre14">
<li class="bulletlist"><strong class="screentext"><span class="kobospan" id="kobo.180.1">Document Loader</span></strong><span class="kobospan" id="kobo.181.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.182.1">Since the document is in PDF format, we will use </span><code class="inlinecode"><span class="kobospan" id="kobo.183.1">PyPDFLoader</span></code><span class="kobospan" id="kobo.184.1">.</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.185.1">Text splitter</span></strong><span class="kobospan" id="kobo.186.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.187.1">We will use a </span><code class="inlinecode"><span class="kobospan" id="kobo.188.1">RecursiveCharacterTextSplitter</span></code><span class="kobospan" id="kobo.189.1">, which splits text by recursively looking at characters to find one that works.</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.190.1">Vector store</span></strong><span class="kobospan" id="kobo.191.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.192.1">We will use the </span><code class="inlinecode"><span class="kobospan" id="kobo.193.1">FAISS</span></code><span class="kobospan" id="kobo.194.1"> VectorDB.</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.195.1">Memory</span></strong><span class="kobospan" id="kobo.196.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.197.1">We will use a </span><code class="inlinecode"><span class="kobospan" id="kobo.198.1">ConversationBufferMemory</span></code><span class="kobospan" id="kobo.199.1">.</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.200.1">LLMs</span></strong><span class="kobospan" id="kobo.201.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.202.1">We will use the </span><code class="inlinecode"><span class="kobospan" id="kobo.203.1">gpt-3.5-turbo</span></code><span class="kobospan" id="kobo.204.1"> model for conversations.</span></li>
<li class="bulletlist1"><strong class="screentext"><span class="kobospan" id="kobo.205.1">Embeddings</span></strong><span class="kobospan" id="kobo.206.1">:</span><strong class="screentext"> </strong><span class="kobospan" id="kobo.207.1">We will use the </span><code class="inlinecode"><span class="kobospan" id="kobo.208.1">text-embedding-ada-002</span></code><span class="kobospan" id="kobo.209.1">.</span></li>
</ul>
<p class="normal1"><span class="kobospan" id="kobo.210.1">Let’s take a look at the code:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.211.1">from</span></span><span class="kobospan" id="kobo.212.1"> langchain.llms </span><span class="hljs-keyword"><span class="kobospan" id="kobo.213.1">import</span></span><span class="kobospan" id="kobo.214.1"> OpenAI
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.215.1">from</span></span><span class="kobospan" id="kobo.216.1"> langchain.chat_models </span><span class="hljs-keyword"><span class="kobospan" id="kobo.217.1">import</span></span><span class="kobospan" id="kobo.218.1"> ChatOpenAI
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.219.1">from</span></span><span class="kobospan" id="kobo.220.1"> langchain.embeddings.openai </span><span class="hljs-keyword"><span class="kobospan" id="kobo.221.1">import</span></span><span class="kobospan" id="kobo.222.1"> OpenAIEmbeddings
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.223.1">from</span></span><span class="kobospan" id="kobo.224.1"> langchain.text_splitter </span><span class="hljs-keyword"><span class="kobospan" id="kobo.225.1">import</span></span><span class="kobospan" id="kobo.226.1"> RecursiveCharacterTextSplitter
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.227.1">from</span></span><span class="kobospan" id="kobo.228.1"> langchain.vectorstores </span><span class="hljs-keyword"><span class="kobospan" id="kobo.229.1">import</span></span><span class="kobospan" id="kobo.230.1"> FAISS
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.231.1">from</span></span><span class="kobospan" id="kobo.232.1"> langchain.document_loaders </span><span class="hljs-keyword"><span class="kobospan" id="kobo.233.1">import</span></span><span class="kobospan" id="kobo.234.1"> PyPDFLoader
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.235.1">from</span></span><span class="kobospan" id="kobo.236.1"> langchain.chains </span><span class="hljs-keyword"><span class="kobospan" id="kobo.237.1">import</span></span><span class="kobospan" id="kobo.238.1"> ConversationalRetrievalChain
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.239.1">from</span></span><span class="kobospan" id="kobo.240.1"> langchain.memory </span><span class="hljs-keyword"><span class="kobospan" id="kobo.241.1">import</span></span><span class="kobospan" id="kobo.242.1"> ConversationBufferMemory
text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=</span><span class="hljs-number"><span class="kobospan" id="kobo.243.1">1500</span></span><span class="kobospan" id="kobo.244.1">,
            chunk_overlap=</span><span class="hljs-number"><span class="kobospan" id="kobo.245.1">200</span></span><span class="kobospan" id="kobo.246.1">
        )
raw_documents = PyPDFLoader(</span><span class="hljs-string"><span class="kobospan" id="kobo.247.1">'italy_travel.pdf'</span></span><span class="kobospan" id="kobo.248.1">).load()
documents = text_splitter.split_documents(raw_documents)
db = FAISS.from_documents(documents, OpenAIEmbeddings())
memory = ConversationBufferMemory(
            memory_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.249.1">'chat_history'</span></span><span class="kobospan" id="kobo.250.1">,
            return_messages=</span><span class="hljs-literal"><span class="kobospan" id="kobo.251.1">True</span></span><span class="kobospan" id="kobo.252.1">
        )
llm = ChatOpenAI()
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.253.1">Let’s now interact with the chain:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.254.1">qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=db.as_retriever(), memory=memory, verbose=</span><span class="hljs-literal"><span class="kobospan" id="kobo.255.1">True</span></span><span class="kobospan" id="kobo.256.1">)
qa_chain.run({</span><span class="hljs-string"><span class="kobospan" id="kobo.257.1">'question'</span></span><span class="kobospan" id="kobo.258.1">:</span><span class="hljs-string"><span class="kobospan" id="kobo.259.1">'Give me some review about the Pantheon'</span></span><span class="kobospan" id="kobo.260.1">})
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.261.1">The following is the output (I’m reporting a truncated version. </span><span class="kobospan" id="kobo.261.2">You can</span><a id="_idIndexMarker433" class="calibre3"/><span class="kobospan" id="kobo.262.1"> see the whole output in the book’s GitHub repository):</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.263.1">&gt; Entering new StuffDocumentsChain chain...
</span><span class="kobospan" id="kobo.263.2">&gt; Entering new LLMChain chain...
</span><span class="kobospan" id="kobo.263.3">Prompt after formatting:
System: Use the following pieces of context to answer the users question.
</span><span class="kobospan" id="kobo.263.4">If you don't know the answer, just say that you don't know, don't try to make up an answer.
</span><span class="kobospan" id="kobo.263.5">----------------
cafes in the square. </span><span class="kobospan" id="kobo.263.6">The most famous are the Quadri and
Florian.
</span><span class="kobospan" id="kobo.263.7">Piazza San Marco,
Venice
4
Historical Monuments
Pantheon
Miskita:
"Angelic and non-human design," was how
Michelangelo described the Pantheon 14 centuries after its
construction. </span><span class="kobospan" id="kobo.263.8">The highlights are the gigantic dome, the upper
eye, the sheer size of the place, and the harmony of the
whole building. </span><span class="kobospan" id="kobo.263.9">We visited with a Roman guide which is
...
</span><span class="kobospan" id="kobo.263.10">&gt; Finished chain.
</span><span class="kobospan" id="kobo.263.11">'Miskita:\n"Angelic and non-human design," was how Michelangelo described the Pantheon 14 centuries after its construction. </span><span class="kobospan" id="kobo.263.12">The highlights
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.264.1">Note that, by default, the </span><code class="inlinecode"><span class="kobospan" id="kobo.265.1">ConversationalRetrievalChain</span></code><span class="kobospan" id="kobo.266.1"> uses a prompt template called </span><code class="inlinecode"><span class="kobospan" id="kobo.267.1">CONDENSE_QUESTION_PROMPT</span></code><span class="kobospan" id="kobo.268.1">, which merges the last user’s query with the chat history, so that it results as just one query to the retriever. </span><span class="kobospan" id="kobo.268.2">If you want to pass a custom prompt, you can do so using the </span><code class="inlinecode"><span class="kobospan" id="kobo.269.1">condense_question_prompt</span></code><span class="kobospan" id="kobo.270.1"> parameter in the </span><code class="inlinecode"><span class="kobospan" id="kobo.271.1">ConversationalRetrievalChain.from_llm</span></code><span class="kobospan" id="kobo.272.1"> module.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.273.1">Even though the bot was able</span><a id="_idIndexMarker434" class="calibre3"/><span class="kobospan" id="kobo.274.1"> to provide an answer based on the documentation, we still have a limitation. </span><span class="kobospan" id="kobo.274.2">In fact, with such a configuration, our GlobeBotter will only look at the provided documentation, but what if we want it to also use its parametric knowledge? </span><span class="kobospan" id="kobo.274.3">For example, we might want the bot to be able to understand whether it could integrate with the provided documentation or simply answer </span><em class="italic"><span class="kobospan" id="kobo.275.1">freely</span></em><span class="kobospan" id="kobo.276.1">. </span><span class="kobospan" id="kobo.276.2">To do so, we need to make our GlobeBotter </span><em class="italic"><span class="kobospan" id="kobo.277.1">agentic</span></em><span class="kobospan" id="kobo.278.1">, meaning that we want to leverage the LLM’s reasoning capabilities to orchestrate and invoke the available tools without a fixed order, but rather following the best approach given the user’s query.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.279.1">To do so, we will use two main components:</span></p>
<ul class="calibre14">
<li class="bulletlist"><code class="inlinecode"><span class="kobospan" id="kobo.280.1">create_retriever_tool</span></code><span class="kobospan" id="kobo.281.1">: This method creates a custom tool that acts as a retriever for an agent. </span><span class="kobospan" id="kobo.281.2">It will need a database to retrieve from, a name, and a short description, so that the model can understand when to use it.</span></li>
<li class="bulletlist1"><code class="inlinecode"><span class="kobospan" id="kobo.282.1">create_conversational_retrieval_agent</span></code><span class="kobospan" id="kobo.283.1">: This method initializes a conversational agent that is configured to work with retrievers and chat models. </span><span class="kobospan" id="kobo.283.2">It will need an LLM, a list of tools (in our case, the retriever), and a memory key to keep track of the previous chat history.</span></li>
</ul>
<p class="normal1"><span class="kobospan" id="kobo.284.1">The following code illustrates how to initialize the agent:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.285.1">from</span></span><span class="kobospan" id="kobo.286.1"> langchain.agents.agent_toolkits </span><span class="hljs-keyword"><span class="kobospan" id="kobo.287.1">import</span></span><span class="kobospan" id="kobo.288.1"> create_retriever_tool
tool = create_retriever_tool(
    db.as_retriever(),
    </span><span class="hljs-string"><span class="kobospan" id="kobo.289.1">"italy_travel"</span></span><span class="kobospan" id="kobo.290.1">,
    </span><span class="hljs-string"><span class="kobospan" id="kobo.291.1">"Searches and returns documents regarding Italy."</span></span><span class="kobospan" id="kobo.292.1">
)
tools = [tool]
memory = ConversationBufferMemory(
            memory_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.293.1">'chat_history'</span></span><span class="kobospan" id="kobo.294.1">,
            return_messages=</span><span class="hljs-literal"><span class="kobospan" id="kobo.295.1">True</span></span><span class="kobospan" id="kobo.296.1">
        )
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.297.1">from</span></span><span class="kobospan" id="kobo.298.1"> langchain.agents.agent_toolkits </span><span class="hljs-keyword"><span class="kobospan" id="kobo.299.1">import</span></span><span class="kobospan" id="kobo.300.1"> create_conversational_retrieval_agent
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.301.1">from</span></span><span class="kobospan" id="kobo.302.1"> langchain.chat_models </span><span class="hljs-keyword"><span class="kobospan" id="kobo.303.1">import</span></span><span class="kobospan" id="kobo.304.1"> ChatOpenAI
llm = ChatOpenAI(temperature = </span><span class="hljs-number"><span class="kobospan" id="kobo.305.1">0</span></span><span class="kobospan" id="kobo.306.1">)
agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.307.1">'chat_history'</span></span><span class="kobospan" id="kobo.308.1">, verbose=</span><span class="hljs-literal"><span class="kobospan" id="kobo.309.1">True</span></span><span class="kobospan" id="kobo.310.1">)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.311.1">Great, now let’s see the thought process </span><a id="_idIndexMarker435" class="calibre3"/><span class="kobospan" id="kobo.312.1">of the agent with two different questions (I will report only the chain of thoughts and truncate the output, but you can find the whole code in the GitHub repo):</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.313.1">agent_executor({</span><span class="hljs-string"><span class="kobospan" id="kobo.314.1">"input"</span></span><span class="kobospan" id="kobo.315.1">: </span><span class="hljs-string"><span class="kobospan" id="kobo.316.1">"Tell me something about Pantheon"</span></span><span class="kobospan" id="kobo.317.1">})
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.318.1">Here is the output:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.319.1">&gt; Entering new AgentExecutor chain...
</span><span class="kobospan" id="kobo.319.2">Invoking: `italy_travel` with `Pantheon`
[Document(page_content='cafes in the square. </span><span class="kobospan" id="kobo.319.3">The most famous are the Quadri and\nFlorian. </span><span class="kobospan" id="kobo.319.4">[…]
&gt; Finished chain.
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.320.1">Let’s now try with a question not related to the document:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="kobospan" id="kobo.321.1">output = agent_executor({</span><span class="hljs-string"><span class="kobospan" id="kobo.322.1">"input"</span></span><span class="kobospan" id="kobo.323.1">: </span><span class="hljs-string"><span class="kobospan" id="kobo.324.1">"what can I visit in India in 3 days?"</span></span><span class="kobospan" id="kobo.325.1">})
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.326.1">The following is the output that we receive:</span></p>
<pre class="programlisting1"><code class="hljs-con"><span class="kobospan" id="kobo.327.1">&gt; Entering new AgentExecutor chain...
</span><span class="kobospan" id="kobo.327.2">In India, there are numerous incredible places to visit, each with its own unique attractions and cultural experiences. </span><span class="kobospan" id="kobo.327.3">While three days is a relatively short time to explore such a vast and diverse country, here are a few suggestions for places you can visit:
1. </span><span class="kobospan" id="kobo.327.4">Delhi: Start your trip in the capital city of India, Delhi. </span><span class="kobospan" id="kobo.327.5">[…]
&gt; Finished chain.
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.328.1">As you can see, when I asked the agent something about Italy, it immediately invoked the provided document, while this was not done in the last question.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.329.1">The last thing we want to add to our GlobeBotter</span><a id="_idIndexMarker436" class="calibre3"/><span class="kobospan" id="kobo.330.1"> is the capability to navigate the web, since, as travelers, we want to have up-to-date information about the country we are traveling to. </span><span class="kobospan" id="kobo.330.2">Let’s implement it with LangChain’s tools.</span></p>
<h2 class="heading1" id="_idParaDest-92"><span class="kobospan" id="kobo.331.1">Adding external tools</span></h2>
<p class="normal"><span class="kobospan" id="kobo.332.1">The tool we are going</span><a id="_idIndexMarker437" class="calibre3"/><span class="kobospan" id="kobo.333.1"> to add here is the Google SerpApi tool, so that our bot will be able to navigate the internet.</span></p>
<div class="note">
<p class="normal1"><strong class="screentext"><span class="kobospan" id="kobo.334.1">Note</span></strong></p>
<p class="normal1"><span class="kobospan" id="kobo.335.1">SerpApi is a real-time API</span><a id="_idIndexMarker438" class="calibre3"/><span class="kobospan" id="kobo.336.1"> designed to access Google search results. </span><span class="kobospan" id="kobo.336.2">It simplifies the process of data scraping by handling complexities such as managing proxies, solving CAPTCHAs, and parsing structured data from search engine results pages.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.337.1">LangChain offers a pre-built tool that wraps SerpApi to make it easier to integrate it within your agents. </span><span class="kobospan" id="kobo.337.2">To enable</span><a id="_idIndexMarker439" class="calibre3"/><span class="kobospan" id="kobo.338.1"> SerpApi, you need to sign in at </span><a href="https://serpapi.com/users/sign_up" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.339.1">https://serpapi.com/users/sign_up</span></span></a><span class="kobospan" id="kobo.340.1">, then go to the dashboard under the tab </span><strong class="screentext"><span class="kobospan" id="kobo.341.1">API key</span></strong><span class="kobospan" id="kobo.342.1">.</span></p>
</div>
<p class="normal1"><span class="kobospan" id="kobo.343.1">Since we don’t want our GlobeBotter to be focused only on the web, we will add the SerpApi tool to the previous one, so that the agent will be able to pick the most useful tool to answer the question – or use no tool if not necessary.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.344.1">Let’s initialize our tools and agent (you learned about this and other LangChain components in </span><em class="italic"><span class="kobospan" id="kobo.345.1">Chapter 5</span></em><span class="kobospan" id="kobo.346.1">):</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.347.1">from</span></span><span class="kobospan" id="kobo.348.1"> langchain </span><span class="hljs-keyword"><span class="kobospan" id="kobo.349.1">import</span></span><span class="kobospan" id="kobo.350.1"> SerpAPIWrapper
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.351.1">import</span></span><span class="kobospan" id="kobo.352.1"> os
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.353.1">from</span></span><span class="kobospan" id="kobo.354.1"> dotenv </span><span class="hljs-keyword"><span class="kobospan" id="kobo.355.1">import</span></span><span class="kobospan" id="kobo.356.1"> load_dotenv
load_dotenv()
os.environ[</span><span class="hljs-string"><span class="kobospan" id="kobo.357.1">"SERPAPI_API_KEY"</span></span><span class="kobospan" id="kobo.358.1">]
search = SerpAPIWrapper()
tools = [
    Tool.from_function(
        func=search.run,
        name=</span><span class="hljs-string"><span class="kobospan" id="kobo.359.1">"Search"</span></span><span class="kobospan" id="kobo.360.1">,
        description=</span><span class="hljs-string"><span class="kobospan" id="kobo.361.1">"useful for when you need to answer questions about current events"</span></span><span class="kobospan" id="kobo.362.1">
    ),
    create_retriever_tool(
        db.as_retriever(),
        </span><span class="hljs-string"><span class="kobospan" id="kobo.363.1">"italy_travel"</span></span><span class="kobospan" id="kobo.364.1">,
        </span><span class="hljs-string"><span class="kobospan" id="kobo.365.1">"Searches and returns documents regarding Italy."</span></span><span class="kobospan" id="kobo.366.1">
    )
    ]
agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.367.1">'chat_history'</span></span><span class="kobospan" id="kobo.368.1">, verbose=</span><span class="hljs-literal"><span class="kobospan" id="kobo.369.1">True</span></span><span class="kobospan" id="kobo.370.1">)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.371.1">Great, now let’s test</span><a id="_idIndexMarker440" class="calibre3"/><span class="kobospan" id="kobo.372.1"> it with three different questions (here, again, the output has been truncated):</span></p>
<ul class="calibre14">
<li class="bulletlist"><span class="kobospan" id="kobo.373.1">“What can I visit in India in 3 days?”
        </span><pre class="programlisting3"><code class="hljs-con"><span class="kobospan" id="kobo.374.1">&gt; Entering new AgentExecutor chain...
</span><span class="kobospan" id="kobo.374.2">India is a vast and diverse country with numerous attractions to explore. </span><span class="kobospan" id="kobo.374.3">While it may be challenging to cover all the highlights in just three days, here are some popular destinations that you can consider visiting:
1. </span><span class="kobospan" id="kobo.374.4">Delhi: Start your trip in the capital city of India, Delhi. </span><span class="kobospan" id="kobo.374.5">[…]
&gt; Finished chain.
</span></code></pre>
</li>
</ul>
<p class="normal-one"><span class="kobospan" id="kobo.375.1">In this case, the model doesn’t need external knowledge to answer the question, hence it is responding without invoking any tool.</span></p>
<ul class="calibre14">
<li class="bulletlist"><span class="kobospan" id="kobo.376.1">“What is the weather currently in Delhi?”
        </span><pre class="programlisting3"><code class="hljs-con"><span class="kobospan" id="kobo.377.1">&gt; Entering new AgentExecutor chain...
</span><span class="kobospan" id="kobo.377.2">Invoking: `Search` with `{'query': 'current weather in Delhi'}`
Current Weather · 95°F Mostly sunny · RealFeel® 105°. </span><span class="kobospan" id="kobo.377.3">Very Hot. </span><span class="kobospan" id="kobo.377.4">RealFeel Guide. </span><span class="kobospan" id="kobo.377.5">Very Hot. </span><span class="kobospan" id="kobo.377.6">101° to 107°. </span><span class="kobospan" id="kobo.377.7">Caution advised. </span><span class="kobospan" id="kobo.377.8">Danger of dehydration, heat stroke, heat ...The current weather in Delhi is 95°F (35°C) with mostly sunny conditions. </span><span class="kobospan" id="kobo.377.9">The RealFeel® temperature is 105°F (41°C), indicating that it feels very hot. </span><span class="kobospan" id="kobo.377.10">Caution is advised as there is a danger of dehydration, heat stroke, and heat-related issues. </span><span class="kobospan" id="kobo.377.11">It is important to stay hydrated and take necessary precautions if you are in Delhi or planning to visit.
</span><span class="kobospan" id="kobo.377.12">&gt; Finished chain.
</span></code></pre>
</li>
</ul>
<p class="normal-one"><span class="kobospan" id="kobo.378.1">Note how the agent is invoking</span><a id="_idIndexMarker441" class="calibre3"/><span class="kobospan" id="kobo.379.1"> the search tool; this is due to the reasoning capability of the underlying gpt-3.5-turbo model, which captures the user’s intent and dynamically understands which tool to use to accomplish the request.</span></p>
<ul class="calibre14">
<li class="bulletlist"><span class="kobospan" id="kobo.380.1">“I’m traveling to Italy. </span><span class="kobospan" id="kobo.380.2">Can you give me some suggestions for the main attractions to visit?”
        </span><pre class="programlisting3"><code class="hljs-con"><span class="kobospan" id="kobo.381.1">&gt; Entering new AgentExecutor chain...
</span><span class="kobospan" id="kobo.381.2">Invoking: `italy_travel` with `{'query': 'main attractions in Italy'}`
[Document(page_content='ITALY\nMINUBE TRAVEL GUIDE\nThe best must-see places for your travels, […]
Here are some suggestions for main attractions in Italy:
1. </span><span class="kobospan" id="kobo.381.3">Parco Sempione, Milan: This is one of the most important parks in Milan. </span><span class="kobospan" id="kobo.381.4">It offers a green space in the city where you can relax, workout, or take a leisurely walk. </span><span class="kobospan" id="kobo.381.5">[…]
&gt; Finished chain.
</span></code></pre>
</li>
</ul>
<p class="normal-one"><span class="kobospan" id="kobo.382.1">Note how the agent is invoking the document retriever to provide the preceding output.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.383.1">Overall, our GlobeBotter</span><a id="_idIndexMarker442" class="calibre3"/><span class="kobospan" id="kobo.384.1"> is now able to provide up-to-date information, as well as retrieving specific knowledge from curated documentation. </span><span class="kobospan" id="kobo.384.2">The next step will be that of building a front-end. </span><span class="kobospan" id="kobo.384.3">We will do so by building a web app using Streamlit.</span></p>
<h1 class="heading" id="_idParaDest-93"><span class="kobospan" id="kobo.385.1">Developing the front-end with Streamlit</span></h1>
<p class="normal"><span class="kobospan" id="kobo.386.1">Streamlit is a Python library that allows </span><a id="_idIndexMarker443" class="calibre3"/><span class="kobospan" id="kobo.387.1">you to create</span><a id="_idIndexMarker444" class="calibre3"/><span class="kobospan" id="kobo.388.1"> and share web apps. </span><span class="kobospan" id="kobo.388.2">It is designed to be easy and fast to use, without requiring any front-end experience or knowledge. </span><span class="kobospan" id="kobo.388.3">You can write your app in pure Python, using simple commands to add widgets, charts, tables, and other elements.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.389.1">In addition to its native capabilities, in July 2023, Streamlit announced an initial integration and its future plans with LangChain. </span><span class="kobospan" id="kobo.389.2">At the core of this initial integration, there is the ambition of making it easier to build a GUI for conversational applications, as well as showing all the steps LangChain’s agents take before producing the final response.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.390.1">To achieve this goal, the main module that Streamlit introduced is the Streamlit callback handler. </span><span class="kobospan" id="kobo.390.2">This module provides a class called </span><code class="inlinecode"><span class="kobospan" id="kobo.391.1">StreamlitCallbackHandler</span></code><span class="kobospan" id="kobo.392.1"> that implements the </span><code class="inlinecode"><span class="kobospan" id="kobo.393.1">BaseCallbackHandler</span></code><span class="kobospan" id="kobo.394.1"> interface from LangChain. </span><span class="kobospan" id="kobo.394.2">This class can handle various events that occur during the execution of a LangChain pipeline, such as tool start, tool end, tool error, LLM token, agent action, agent finish, etc.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.395.1">The class can also create and update Streamlit elements, such as containers, expanders, text, progress bars, etc., to display the output of the pipeline in a user-friendly way. </span><span class="kobospan" id="kobo.395.2">You can use the Streamlit callback handler to create Streamlit apps that showcase the capabilities of LangChain and interact with the user through natural language. </span><span class="kobospan" id="kobo.395.3">For example, you can create an app that takes a user prompt and runs it through an agent that uses different tools and models to generate a response. </span><span class="kobospan" id="kobo.395.4">You can use the Streamlit callback handler to show the agent’s thought process and the results of each tool in real time.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.396.1">To start building your application, you need to create a </span><code class="inlinecode"><span class="kobospan" id="kobo.397.1">.py</span></code><span class="kobospan" id="kobo.398.1"> file to run in your terminal via </span><code class="inlinecode"><span class="kobospan" id="kobo.399.1">streamlit run file.py</span></code><span class="kobospan" id="kobo.400.1">. </span><span class="kobospan" id="kobo.400.2">In our case, the file will be named </span><code class="inlinecode"><span class="kobospan" id="kobo.401.1">globebotter.py</span></code><span class="kobospan" id="kobo.402.1">.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.403.1">The following are the main building blocks of the application:</span></p>
<ol class="calibre15">
<li class="bulletlist1" value="1"><span class="kobospan" id="kobo.404.1">Setting the configuration of the webpage:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.405.1">import</span></span><span class="kobospan" id="kobo.406.1"> streamlit </span><span class="hljs-keyword"><span class="kobospan" id="kobo.407.1">as</span></span><span class="kobospan" id="kobo.408.1"> st
st.set_page_config(page_title=</span><span class="hljs-string"><span class="kobospan" id="kobo.409.1">"GlobeBotter"</span></span><span class="kobospan" id="kobo.410.1">, page_icon=</span><span class="hljs-string"><span class="kobospan" id="kobo.411.1">"</span><span class="kobospan" id="kobo.412.1"><img alt="" role="presentation" src="../Images/Globe.png" class="calibre4"/></span><span class="kobospan" id="kobo.413.1">"</span></span><span class="kobospan" id="kobo.414.1">)
st.header(</span><span class="hljs-string"><span class="kobospan" id="kobo.415.1">'</span><span class="kobospan" id="kobo.416.1"><img alt="" role="presentation" src="../Images/Globe.png" class="calibre4"/></span><span class="kobospan" id="kobo.417.1"> Welcome to Globebotter, your travel assistant with Internet access. </span><span class="kobospan" id="kobo.417.2">What are you planning for your next trip?'</span></span><span class="kobospan" id="kobo.418.1">)
</span></code></pre>
</li>
<li class="bulletlist1"><span class="kobospan" id="kobo.419.1">Initializing the LangChain</span><a id="_idIndexMarker445" class="calibre3"/><span class="kobospan" id="kobo.420.1"> backbone components</span><a id="_idIndexMarker446" class="calibre3"/><span class="kobospan" id="kobo.421.1"> we need. </span><span class="kobospan" id="kobo.421.2">The code is the same as the one in the previous section, so I will share here only the initialization code, without all the preliminary steps:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="kobospan" id="kobo.422.1">search = SerpAPIWrapper()
text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=</span><span class="hljs-number"><span class="kobospan" id="kobo.423.1">1500</span></span><span class="kobospan" id="kobo.424.1">,
            chunk_overlap=</span><span class="hljs-number"><span class="kobospan" id="kobo.425.1">200</span></span><span class="kobospan" id="kobo.426.1">
        )
raw_documents = PyPDFLoader(</span><span class="hljs-string"><span class="kobospan" id="kobo.427.1">'italy_travel.pdf'</span></span><span class="kobospan" id="kobo.428.1">).load()
documents = text_splitter.split_documents(raw_documents)
db = FAISS.from_documents(documents, OpenAIEmbeddings())
memory = ConversationBufferMemory(
    return_messages=</span><span class="hljs-literal"><span class="kobospan" id="kobo.429.1">True</span></span><span class="kobospan" id="kobo.430.1">,
    memory_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.431.1">"chat_history"</span></span><span class="kobospan" id="kobo.432.1">,
    output_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.433.1">"output"</span></span><span class="kobospan" id="kobo.434.1">
)
llm = ChatOpenAI()
tools = [
    Tool.from_function(
        func=search.run,
        name=</span><span class="hljs-string"><span class="kobospan" id="kobo.435.1">"Search"</span></span><span class="kobospan" id="kobo.436.1">,
        description=</span><span class="hljs-string"><span class="kobospan" id="kobo.437.1">"useful for when you need to answer questions about current events"</span></span><span class="kobospan" id="kobo.438.1">
    ),
    create_retriever_tool(
        db.as_retriever(),
        </span><span class="hljs-string"><span class="kobospan" id="kobo.439.1">"italy_travel"</span></span><span class="kobospan" id="kobo.440.1">,
        </span><span class="hljs-string"><span class="kobospan" id="kobo.441.1">"Searches and returns documents regarding Italy."</span></span><span class="kobospan" id="kobo.442.1">
    )
    ]
agent = create_conversational_retrieval_agent(llm, tools, memory_key=</span><span class="hljs-string"><span class="kobospan" id="kobo.443.1">'chat_history'</span></span><span class="kobospan" id="kobo.444.1">, verbose=</span><span class="hljs-literal"><span class="kobospan" id="kobo.445.1">True</span></span><span class="kobospan" id="kobo.446.1">)
</span></code></pre>
</li>
<li class="bulletlist1"><span class="kobospan" id="kobo.447.1">Setting the input box for the user with a placeholder question:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="kobospan" id="kobo.448.1">user_query = st.text_input(
    </span><span class="hljs-string"><span class="kobospan" id="kobo.449.1">"**Where are you planning your next vacation?**"</span></span><span class="kobospan" id="kobo.450.1">,
    placeholder=</span><span class="hljs-string"><span class="kobospan" id="kobo.451.1">"Ask me anything!"</span></span><span class="kobospan" id="kobo.452.1">
)
</span></code></pre>
</li>
<li class="bulletlist1"><span class="kobospan" id="kobo.453.1">Setting Streamlit’s session</span><a id="_idIndexMarker447" class="calibre3"/><span class="kobospan" id="kobo.454.1"> states. </span><span class="kobospan" id="kobo.454.2">Session state</span><a id="_idIndexMarker448" class="calibre3"/><span class="kobospan" id="kobo.455.1"> is a way to share variables between reruns, for each user session. </span><span class="kobospan" id="kobo.455.2">In addition to the ability to store and persist state, Streamlit also exposes the ability to manipulate state using callbacks. </span><span class="kobospan" id="kobo.455.3">Session state also persists across apps inside a multipage app. </span><span class="kobospan" id="kobo.455.4">You can use the session state API to initialize, read, update, and delete variables in the session state. </span><span class="kobospan" id="kobo.455.5">In the case of our GlobeBotter, we want two main states: </span><code class="inlinecode"><span class="kobospan" id="kobo.456.1">messages</span></code><span class="kobospan" id="kobo.457.1"> and </span><code class="inlinecode"><span class="kobospan" id="kobo.458.1">memory</span></code><span class="kobospan" id="kobo.459.1">:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.460.1">if</span></span> <span class="hljs-string"><span class="kobospan" id="kobo.461.1">"messages"</span></span> <span class="hljs-keyword"><span class="kobospan" id="kobo.462.1">not</span></span> <span class="hljs-keyword"><span class="kobospan" id="kobo.463.1">in</span></span><span class="kobospan" id="kobo.464.1"> st.session_state:
    st.session_state[</span><span class="hljs-string"><span class="kobospan" id="kobo.465.1">"messages"</span></span><span class="kobospan" id="kobo.466.1">] = [{</span><span class="hljs-string"><span class="kobospan" id="kobo.467.1">"</span></span><span class="hljs-string"><span class="kobospan" id="kobo.468.1">role"</span></span><span class="kobospan" id="kobo.469.1">: </span><span class="hljs-string"><span class="kobospan" id="kobo.470.1">"assistant"</span></span><span class="kobospan" id="kobo.471.1">, </span><span class="hljs-string"><span class="kobospan" id="kobo.472.1">"content"</span></span><span class="kobospan" id="kobo.473.1">: </span><span class="hljs-string"><span class="kobospan" id="kobo.474.1">"How can I help you?"</span></span><span class="kobospan" id="kobo.475.1">}]
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.476.1">if</span></span> <span class="hljs-string"><span class="kobospan" id="kobo.477.1">"memory"</span></span> <span class="hljs-keyword"><span class="kobospan" id="kobo.478.1">not</span></span> <span class="hljs-keyword"><span class="kobospan" id="kobo.479.1">in</span></span><span class="kobospan" id="kobo.480.1"> st.session_state:
    st.session_state[</span><span class="hljs-string"><span class="kobospan" id="kobo.481.1">'memory'</span></span><span class="kobospan" id="kobo.482.1">] = memory
</span></code></pre>
</li>
<li class="bulletlist1"><span class="kobospan" id="kobo.483.1">Making sure to display the whole conversation. </span><span class="kobospan" id="kobo.483.2">To do so, I created a for loop that iterates over the list of messages stored in </span><code class="inlinecode"><span class="kobospan" id="kobo.484.1">st.session_state["messages"].</span></code><span class="kobospan" id="kobo.485.1"> For each message, it creates a Streamlit element called </span><code class="inlinecode"><span class="kobospan" id="kobo.486.1">st.chat_message</span></code><span class="kobospan" id="kobo.487.1"> that displays a chat message in a nice format:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.488.1">for</span></span><span class="kobospan" id="kobo.489.1"> msg </span><span class="hljs-keyword"><span class="kobospan" id="kobo.490.1">in</span></span><span class="kobospan" id="kobo.491.1"> st.session_state[</span><span class="hljs-string"><span class="kobospan" id="kobo.492.1">"messages"</span></span><span class="kobospan" id="kobo.493.1">]:
    st.chat_message(msg[</span><span class="hljs-string"><span class="kobospan" id="kobo.494.1">"role"</span></span><span class="kobospan" id="kobo.495.1">]).write(msg[</span><span class="hljs-string"><span class="kobospan" id="kobo.496.1">"content"</span></span><span class="kobospan" id="kobo.497.1">])
</span></code></pre>
</li>
<li class="bulletlist1"><span class="kobospan" id="kobo.498.1">Configuring the AI assistant to respond when given a user’s query. </span><span class="kobospan" id="kobo.498.2">In this first example, we will keep the whole chain visible and printed to the screen:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.499.1">if</span></span><span class="kobospan" id="kobo.500.1"> user_query:
    st.session_state.messages.append({</span><span class="hljs-string"><span class="kobospan" id="kobo.501.1">"role"</span></span><span class="kobospan" id="kobo.502.1">: </span><span class="hljs-string"><span class="kobospan" id="kobo.503.1">"user"</span></span><span class="kobospan" id="kobo.504.1">, </span><span class="hljs-string"><span class="kobospan" id="kobo.505.1">"</span></span><span class="hljs-string"><span class="kobospan" id="kobo.506.1">content"</span></span><span class="kobospan" id="kobo.507.1">: user_query})
    st.chat_message(</span><span class="hljs-string"><span class="kobospan" id="kobo.508.1">"user"</span></span><span class="kobospan" id="kobo.509.1">).write(user_query)
    </span><span class="hljs-keyword"><span class="kobospan" id="kobo.510.1">with</span></span><span class="kobospan" id="kobo.511.1"> st.chat_message(</span><span class="hljs-string"><span class="kobospan" id="kobo.512.1">"assistant"</span></span><span class="kobospan" id="kobo.513.1">):
        st_cb = StreamlitCallbackHandler(st.container())
        response = agent(user_query, callbacks=[st_cb])
        st.session_state.messages.append({</span><span class="hljs-string"><span class="kobospan" id="kobo.514.1">"role"</span></span><span class="kobospan" id="kobo.515.1">: </span><span class="hljs-string"><span class="kobospan" id="kobo.516.1">"assistant"</span></span><span class="kobospan" id="kobo.517.1">, </span><span class="hljs-string"><span class="kobospan" id="kobo.518.1">"content"</span></span><span class="kobospan" id="kobo.519.1">: response})
        st.write(response)
</span></code></pre>
</li>
<li class="bulletlist1"><span class="kobospan" id="kobo.520.1">Finally, adding a button</span><a id="_idIndexMarker449" class="calibre3"/><span class="kobospan" id="kobo.521.1"> to clear the history of the conversation</span><a id="_idIndexMarker450" class="calibre3"/><span class="kobospan" id="kobo.522.1"> and start from scratch:
        </span><pre class="programlisting2"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.523.1">if</span></span><span class="kobospan" id="kobo.524.1"> st.sidebar.button(</span><span class="hljs-string"><span class="kobospan" id="kobo.525.1">"Reset chat history"</span></span><span class="kobospan" id="kobo.526.1">):
    st.session_state.messages = []
</span></code></pre>
</li>
</ol>
<p class="normal1"><span class="kobospan" id="kobo.527.1">The final product looks as follows:</span></p>
<figure class="mediaobject"><span class="kobospan" id="kobo.528.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B21714_06_02.png" class="calibre4"/></span></figure>
<p class="packt_figref"><span class="kobospan" id="kobo.529.1">Figure 6.2: Front-end of GlobeBotter with Streamlit</span></p>
<p class="normal1"><span class="kobospan" id="kobo.530.1">From the expander, we can see</span><a id="_idIndexMarker451" class="calibre3"/><span class="kobospan" id="kobo.531.1"> that the agent used</span><a id="_idIndexMarker452" class="calibre3"/><span class="kobospan" id="kobo.532.1"> the </span><code class="inlinecode"><span class="kobospan" id="kobo.533.1">Search</span></code><span class="kobospan" id="kobo.534.1"> tool (provided with the SerpApi). </span><span class="kobospan" id="kobo.534.2">We can also expand </span><code class="inlinecode"><span class="kobospan" id="kobo.535.1">chat_history</span></code><span class="kobospan" id="kobo.536.1"> or </span><code class="inlinecode"><span class="kobospan" id="kobo.537.1">intermediate_steps</span></code><span class="kobospan" id="kobo.538.1"> as follows:</span></p>
<figure class="mediaobject"><span class="kobospan" id="kobo.539.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B21714_06_03.png" class="calibre4"/></span></figure>
<p class="packt_figref"><span class="kobospan" id="kobo.540.1">Figure 6.3: Example of Streamlit expander</span></p>
<p class="normal1"><span class="kobospan" id="kobo.541.1">Of course, we can also decide</span><a id="_idIndexMarker453" class="calibre3"/><span class="kobospan" id="kobo.542.1"> to only show the output rather than the whole</span><a id="_idIndexMarker454" class="calibre3"/><span class="kobospan" id="kobo.543.1"> chain of thoughts, by specifying in the code to return only </span><code class="inlinecode"><span class="kobospan" id="kobo.544.1">response['output']</span></code><span class="kobospan" id="kobo.545.1">. </span><span class="kobospan" id="kobo.545.2">You can see the whole code in the book’s GitHub repository.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.546.1">Before we wrap up, let’s discuss how you can give your users a streaming experience while interacting with your chatbot. </span><span class="kobospan" id="kobo.546.2">You can leverage the </span><code class="inlinecode"><span class="kobospan" id="kobo.547.1">BaseCallbackHandler</span></code><span class="kobospan" id="kobo.548.1"> class to create a custom callback handler in your Streamlit app:</span></p>
<pre class="programlisting"><code class="hljs-code"><span class="hljs-keyword"><span class="kobospan" id="kobo.549.1">from</span></span><span class="kobospan" id="kobo.550.1"> langchain.callbacks.base </span><span class="hljs-keyword"><span class="kobospan" id="kobo.551.1">import</span></span><span class="kobospan" id="kobo.552.1"> BaseCallbackHandler
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.553.1">from</span></span><span class="kobospan" id="kobo.554.1"> langchain.schema </span><span class="hljs-keyword"><span class="kobospan" id="kobo.555.1">import</span></span><span class="kobospan" id="kobo.556.1"> ChatMessage
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.557.1">from</span></span><span class="kobospan" id="kobo.558.1"> langchain_openai </span><span class="hljs-keyword"><span class="kobospan" id="kobo.559.1">import</span></span><span class="kobospan" id="kobo.560.1"> ChatOpenAI
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.561.1">import</span></span><span class="kobospan" id="kobo.562.1"> streamlit </span><span class="hljs-keyword"><span class="kobospan" id="kobo.563.1">as</span></span><span class="kobospan" id="kobo.564.1"> st
</span><span class="hljs-keyword"><span class="kobospan" id="kobo.565.1">class</span></span> <span class="hljs-title"><span class="kobospan" id="kobo.566.1">StreamHandler</span></span><span class="kobospan" id="kobo.567.1">(</span><span class="hljs-title"><span class="kobospan" id="kobo.568.1">BaseCallbackHandler</span></span><span class="kobospan" id="kobo.569.1">):
    </span><span class="hljs-keyword"><span class="kobospan" id="kobo.570.1">def</span></span> <span class="hljs-title"><span class="kobospan" id="kobo.571.1">__init__</span></span><span class="kobospan" id="kobo.572.1">(</span><span><span class="kobospan" id="kobo.573.1">self, container, initial_text=</span></span><span class="hljs-string"><span class="kobospan" id="kobo.574.1">""</span></span><span class="kobospan" id="kobo.575.1">):
        </span><span class="hljs-number"><span class="kobospan" id="kobo.576.1">self</span></span><span class="kobospan" id="kobo.577.1">.container = container
        </span><span class="hljs-number"><span class="kobospan" id="kobo.578.1">self</span></span><span class="kobospan" id="kobo.579.1">.text = initial_text
    </span><span class="hljs-keyword"><span class="kobospan" id="kobo.580.1">def</span></span> <span class="hljs-title"><span class="kobospan" id="kobo.581.1">on_llm_new_token</span></span><span class="kobospan" id="kobo.582.1">(</span><span><span class="kobospan" id="kobo.583.1">self, token: </span></span><span class="hljs-built_in"><span class="kobospan" id="kobo.584.1">str</span></span><span><span class="kobospan" id="kobo.585.1">, **kwargs</span></span><span class="kobospan" id="kobo.586.1">) -&gt; </span><span class="hljs-literal"><span class="kobospan" id="kobo.587.1">None</span></span><span class="kobospan" id="kobo.588.1">:
        </span><span class="hljs-number"><span class="kobospan" id="kobo.589.1">self</span></span><span class="kobospan" id="kobo.590.1">.text += token
        </span><span class="hljs-number"><span class="kobospan" id="kobo.591.1">self</span></span><span class="kobospan" id="kobo.592.1">.container.markdown(</span><span class="hljs-number"><span class="kobospan" id="kobo.593.1">self</span></span><span class="kobospan" id="kobo.594.1">.text)
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.595.1">The </span><code class="inlinecode"><span class="kobospan" id="kobo.596.1">StreamHandler</span></code><span class="kobospan" id="kobo.597.1"> is designed to capture and display streaming data, such as text or other content, in a designated container. </span><span class="kobospan" id="kobo.597.2">Then, you can use it as follows in your Streamlit app, making sure to set </span><code class="inlinecode"><span class="kobospan" id="kobo.598.1">streaming=True</span></code><span class="kobospan" id="kobo.599.1"> while initializing your OpenAI LLM.</span></p>
<pre class="programlisting"><code class="hljs-code"> <span class="hljs-keyword"><span class="kobospan" id="kobo.600.1">with</span></span><span class="kobospan" id="kobo.601.1"> st.chat_message(</span><span class="hljs-string"><span class="kobospan" id="kobo.602.1">"assistant"</span></span><span class="kobospan" id="kobo.603.1">):
        stream_handler = StreamHandler(st.empty())
        llm = ChatOpenAI(streaming=</span><span class="hljs-literal"><span class="kobospan" id="kobo.604.1">True</span></span><span class="kobospan" id="kobo.605.1">, callbacks=[stream_handler])
        response = llm.invoke(st.session_state.messages)
        st.session_state.messages.append(ChatMessage(role=</span><span class="hljs-string"><span class="kobospan" id="kobo.606.1">"assistant"</span></span><span class="kobospan" id="kobo.607.1">, content=response.content))
</span></code></pre>
<p class="normal1"><span class="kobospan" id="kobo.608.1">You can refer</span><a id="_idIndexMarker455" class="calibre3"/><span class="kobospan" id="kobo.609.1"> to the original code on LangChain’s GitHub</span><a id="_idIndexMarker456" class="calibre3"/><span class="kobospan" id="kobo.610.1"> repo at </span><a href="https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.611.1">https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py</span></span></a><span class="kobospan" id="kobo.612.1">.</span></p>
<h1 class="heading" id="_idParaDest-94"><span class="kobospan" id="kobo.613.1">Summary</span></h1>
<p class="normal"><span class="kobospan" id="kobo.614.1">In this chapter, we approached the end-to-end implementation of a conversational application, leveraging LangChain’s modules and progressively adding layers of complexity. </span><span class="kobospan" id="kobo.614.2">We started with a plain vanilla chatbot with no memory, then moved on to more complex systems with the ability to keep traces of past interactions. </span><span class="kobospan" id="kobo.614.3">We’ve also seen how to add non-parametric knowledge to our application with external tools, making it more “agentic” so that it is able to determine which tool to use, depending on the user’s query. </span><span class="kobospan" id="kobo.614.4">Finally, we introduced Streamlit as the front-end framework to build the web app for our GlobeBotter.</span></p>
<p class="normal1"><span class="kobospan" id="kobo.615.1">In the next chapter, we will focus on a more specific domain where LLMs add value and demonstrate emerging behaviors, that is, recommendation systems.</span></p>
<h1 class="heading" id="_idParaDest-95"><span class="kobospan" id="kobo.616.1">References</span></h1>
<ul class="calibre16">
<li class="bulletlist"><span class="kobospan" id="kobo.617.1">Example of a context-aware chatbot. </span><a href="https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.618.1">https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py</span></span></a></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.619.1">Knowledge base for the AI travel assistant. </span><a href="https://www.minube.net/guides/italy" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.620.1">https://www.minube.net/guides/italy</span></span></a></li>
<li class="bulletlist1"><span class="kobospan" id="kobo.621.1">LangChain repository. </span><a href="https://github.com/langchain-ai" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.622.1">https://github.com/langchain-ai</span></span></a></li>
</ul>
<h1 class="heading"><span class="kobospan" id="kobo.623.1">Join our community on Discord</span></h1>
<p class="normal"><span class="kobospan" id="kobo.624.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
<p class="normal1"><a href="https://packt.link/llm" class="calibre3"><span class="calibre3"><span class="kobospan" id="kobo.625.1">https://packt.link/llm</span></span></a></p>
<p class="normal1"><span class="kobospan" id="kobo.626.1"><img alt="" role="presentation" src="../Images/QR_Code214329708533108046.png" class="calibre4"/></span></p>
</div>
</body></html>