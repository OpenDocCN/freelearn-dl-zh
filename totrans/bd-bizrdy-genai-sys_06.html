<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer180">
    <h1 class="chapterNumber"><a id="_idTextAnchor166"/>6</h1>
    <h1 class="chapterTitle" id="_idParaDest-160"><a id="_idTextAnchor167"/>Reasoning E-Marketing AI Agents</h1>
    <p class="normal">The foundational concept of a successful advertising campaign is <em class="italic">memory</em>. Think about the advertisements you saw yesterday. What about those from one year ago or even several years ago? The ads you remember most vividly are the ones most effective for you, but perhaps not for someone else. The primary challenge for any advertising agency is designing promotional content that triggers positive reactions in diverse individuals. More crucially, successful marketing campaigns strive to make consumers remember brands, products, and services.</p>
    <p class="normal">The Nielsen Neuroscience team (Brandt &amp; Nieuwenhuis, 2017) explains why memory is so important in advertising. They demonstrate that memory decays significantly after just 24 hours, making it difficult for advertisements to have lasting effects. Several factors, including repetition and the emotional or intellectual impact of the content, can enhance memory retention. The emergence of agentic systems such as the GenAISys has reshaped the marketing landscape because these systems can replicate human-like expert marketing reasoning.</p>
    <p class="normal">In this chapter, we will enhance the GenAISys we’ve been building throughout previous chapters. First, we’ll design a <strong class="keyWord">consumer memory agent</strong> tailored to a specific market segment. The goal of this agent is to analyze how consumers encode promotional messages. We’ll begin by exploring why memory matters and how it is structured, examining key memory categories such as short-term, long-term, explicit, and implicit memory, as well as important dimensions such as intellectual and emotional encoding. Next, we’ll expand the architecture of the GenAISys by integrating a deeper understanding of consumer memory into its knowledge base. We’ll then develop a strategic consumer memory agent leveraging the multimodal capabilities introduced in earlier chapters. This agent will employ a neuroscience-inspired approach to craft customized marketing messages. By introducing <strong class="keyWord">meta-cognition</strong> through OpenAI’s advanced <strong class="keyWord">o3 reasoning model</strong>, we will enable the agent to perform sophisticated, near-human self-reflection within its multistep CoT reasoning process.</p>
    <p class="normal">Further, we will transform our generative AI model into a neuroscientific-like agent capable of analytic reasoning rather than mere content generation. Complex systems—like the human brain—are more than the sum of their parts, and the same applies to machine intelligence. The strategic consumer memory agent using OpenAI’s o3 reasoning model will apply complex neuroscience-informed prompts to analyze consumer memory encoding patterns in hotel reviews. The resulting insights will feed into a multimodal <strong class="keyWord">thread-of-reasoning pipeline</strong>, building upon the CoT framework introduced in <a href="Chapter_5.xhtml#_idTextAnchor140"><em class="italic">Chapter 5</em></a><em class="italic">, Adding Multimodal, Multifunctional Reasoning with Chain of Thought</em>. Ultimately, the GenAISys will leverage this detailed memory analysis to produce tailored marketing content using GPT-4o, accompanied by images generated by DALL-E.</p>
    <p class="normal">Finally, we’ll further enhance the IPython interactive interface by adding new features, including a widget capable of triggering agentic meta-cognition for memory analysis and customer service tasks. Users will have the option to analyze various types of content for memory-related insights or initiate customer-service-oriented CoT interactions.</p>
    <p class="normal">By the end of this chapter, you will have learned how to build a customized, reasoning-driven GenAISys applicable to any domain based on the architecture of our consumer memory agent. We’ll construct it step by step.</p>
    <p class="normal">This chapter covers the following topics:</p>
    <ul>
      <li class="bulletList">The importance of consumer memory in marketing</li>
      <li class="bulletList">The high-level structure of human memory</li>
      <li class="bulletList">Building a strategic CoT consumer memory agent</li>
      <li class="bulletList">Analyzing hotel reviews with CoT</li>
      <li class="bulletList">Designing neuroscientific-like complex prompts</li>
      <li class="bulletList">Using o3, OpenAI’s reasoning model that can analyze content in depth</li>
      <li class="bulletList">Using OpenAI’s GPT-4o to generate content and DALL-E to generate images</li>
      <li class="bulletList">Assembling reasoning and generation in a thread-of-reasoning function</li>
      <li class="bulletList">Generalizing the consumer memory agent CoT to any content</li>
      <li class="bulletList">Enhancing the IPython interactive interface</li>
    </ul>
    <p class="normal">Let’s begin by designing the enhanced GenAISys interface and its AI-driven functionalities.</p>
    <h1 class="heading-1" id="_idParaDest-161"><a id="_idTextAnchor168"/>Designing the consumer GenAISys memory agent</h1>
    <p class="normal">Consumer neuroscience<a id="_idIndexMarker394"/> can significantly enhance brand memorability through emotionally resonant, personalized messaging. In this chapter, we begin by analyzing how consumers encode memories. Nicks and Carriou (2016) demonstrate that effective consumer neuroscience leverages storytelling through narrative transportation, where consumers become emotionally engaged and vividly remember promotional messages.</p>
    <p class="normal">In our implementation, we’ll deeply analyze how consumers encode memories, maintaining an authentic approach. If a consumer expresses dissatisfaction with a service, our system will tailor <a id="_idIndexMarker395"/>messages to emphasize improved offerings. Our goal is to create genuine connections through memorable, emotionally resonant messages.</p>
    <p class="normal">In this section, we will describe how we enhance the GenAISys we have been building in the previous chapters:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Consumer-memory agent use case</strong>: Shows how an AI-driven agent can apply memory principles—drawn from short-term <a id="_idIndexMarker396"/>and <strong class="keyWord">long-term memory</strong> (<strong class="keyWord">LTM</strong>) frameworks—to interpret consumer feedback.</li>
      <li class="bulletList"><strong class="keyWord">Defining memory structures</strong>: This extends beyond the basic categories of <strong class="keyWord">short-term memory</strong> (<strong class="keyWord">STM</strong>), LTM, episodic<a id="_idIndexMarker397"/> memory, and semantic memory that we previously examined and introduces new categories and dimensions, providing a deeper analysis of the input.</li>
      <li class="bulletList"><strong class="keyWord">Enhancing the architecture of the GenAISys</strong>: This adds new functionality to trigger the AI agent and integrates a new CoT scenario.</li>
    </ul>
    <p class="normal">Let’s first explore the consumer memory agent use case.</p>
    <h2 class="heading-2" id="_idParaDest-162"><a id="_idTextAnchor169"/>Consumer-memory agent use case</h2>
    <p class="normal">The <a id="_idIndexMarker398"/>use case in this chapter demonstrates how the GenAISys can be enhanced with a CoT consumer memory agent. Our goal is to understand a specific consumer’s needs when selecting a hotel, using detailed analyses of hotel reviews. The system we develop performs comprehensive content analysis, evaluates sentiment, and generates personalized marketing content. The CoT agent initiates this process with a detailed memory and sentiment analysis of a hotel review. It identifies psychological features, emotional markers, and specific memory tags, assigning a sentiment score to each analyzed segment. These scores are combined to produce an overall sentiment score and a scaled rating (0–5). Through this approach, the agent effectively captures how particular hotel experiences are perceived, emotionally processed, and retained in a consumer’s memory.</p>
    <p class="normal">Based on these extracted insights and the resulting cognitive profile, the agent uses the scaled rating to determine the appropriate marketing strategy. Ultimately, the consumer memory agent produces tailored promotional content, including a customized message accompanied by a relevant image. For instance, if the analysis reveals a customer who generally dislikes hotels, the travel agency can emphasize alternative accommodations or improved services that the customer has previously mentioned positively. In such cases, the agent generates a personalized message with an engaging image, as illustrated in <em class="italic">Figure 6.1</em>.</p>
    <figure class="mediaobject"><img alt="Figure 6.1: Custom content-based image generated by DALL-E" src="../Images/B32304_06_1.png"/></figure>
    <p class="packt_figref">Figure 6.1: Custom content-based image generated by DALL-E</p>
    <p class="normal">The <a id="_idIndexMarker399"/>agent crafts a warm, personalized message by analyzing the cognitive profile identified from customer hotel reviews:</p>
    <pre class="programlisting con"><code class="hljs-con">Customer message: Dear Customer,
We invite you to consider a unique vacation experience that goes beyond the typical hotel stay. Imagine the warmth and comfort of staying with family or friends, where every moment is filled with genuine connections and cherished memories. From waking up to the aroma of freshly brewed coffee made just the way you like it to sharing home-cooked meals and laughter around a family table, this experience offers a heartfelt alternative to the impersonal nature of hotels. Embrace the spontaneity and freedom of living in the moment, surrounded by those who matter most. Whether it's a cozy evening of board games or a relaxed afternoon in the backyard, staying with loved ones provides a true home away from home. This vacation, choose the warmth of a family home and create memories that will last a lifetime. Book your stay with loved ones today and rediscover the true meaning of home.
Warm regards,
[Your Company Name]
</code></pre>
    <div class="note">
      <p class="normal"> Generative AI is stochastic, so the same input will not necessarily generate the same output. The response may thus change from one run to another.</p>
    </div>
    <p class="normal">Let’s now define the memory structure that the consumer memory agent will use.</p>
    <h2 class="heading-2" id="_idParaDest-163"><a id="_idTextAnchor170"/>Defining memory structures</h2>
    <p class="normal">Let’s now<a id="_idIndexMarker400"/> expand upon the memory categories introduced in <a href="Chapter_1.xhtml#_idTextAnchor021"><em class="italic">Chapter 1</em></a> by outlining the human memory structures essential for <a id="_idIndexMarker401"/>building our consumer memory agent. Human memory is<a id="_idIndexMarker402"/> multifaceted: <strong class="keyWord">STM</strong> temporarily captures the information necessary for immediate tasks or emotional processing, quickly fading without reinforcement; <strong class="keyWord">LTM</strong> stores <a id="_idIndexMarker403"/>significant events, knowledge, and experiences over <a id="_idIndexMarker404"/>extended periods; <strong class="keyWord">semantic memory</strong> stores general knowledge and facts, independent of personal experience; <strong class="keyWord">episodic memory</strong> captures <a id="_idIndexMarker405"/>personally experienced events with context and detail; <strong class="keyWord">procedural memory</strong> enables<a id="_idIndexMarker406"/> unconscious retrieval of tasks, such as walking or <a id="_idIndexMarker407"/>driving; <strong class="keyWord">emotional memory</strong> categorizes experiences based on emotional intensity—positive or negative; and <strong class="keyWord">explicit memory</strong> involves<a id="_idIndexMarker408"/> conscious <a id="_idIndexMarker409"/>recall, whereas <strong class="keyWord">implicit memory</strong> operates unconsciously.</p>
    <p class="normal">Our consumer memory agent will analyze consumer content using a flexible combination of these memory categories, as shown in <em class="italic">Figure 6.2</em>. The categorization provides the o3 OpenAI reasoning model sufficient freedom to interpret consumer data effectively.</p>
    <figure class="mediaobject"><img alt="Figure 6.2: The memory categories of the memory agent" src="../Images/B32304_06_2.png"/></figure>
    <p class="packt_figref">Figure 6.2: The memory categories of the memory agent</p>
    <p class="normal">The main categories at the upper level are the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Memoryless</strong> for <a id="_idIndexMarker410"/>systems or humans that do not remember information from a past event. These are events that we most forget, such as how many times we blinked yesterday.</li>
      <li class="bulletList"><strong class="keyWord">Short-Term Memory</strong> for<a id="_idIndexMarker411"/> the temporary storage of information to perform a task or the process of emotion. This memory decays rapidly if no event stimulates it again. It could be the working memory of reading a long text.</li>
      <li class="bulletList"><strong class="keyWord">Long-Term Memory</strong> for <a id="_idIndexMarker412"/>information we store over long periods, from days to years. This is a vital memory, such as knowing which country we are in, our age, and who our family members are.</li>
      <li class="bulletList"><strong class="keyWord">Reality Memory</strong> is <a id="_idIndexMarker413"/>what we know for sure related to actual events or facts, and the external world.</li>
      <li class="bulletList"><strong class="keyWord">Fiction Memory</strong> includes <a id="_idIndexMarker414"/>imagined or hypothetical internal events or narratives.</li>
      <li class="bulletList"><strong class="keyWord">Time Memory</strong> is <a id="_idIndexMarker415"/>critical to distinguish past, present, and future events. Otherwise, we would think that we had already eaten what we were going to eat for lunch tomorrow.</li>
    </ul>
    <p class="normal">Notice how<a id="_idIndexMarker416"/> memoryless, short-term, and long-term memory form a subset (light green), and reality, fiction, and time memory (light orange) are all connected. These categories aren’t isolated; they interconnect dynamically in real life. Our memory, in other words, doesn’t function in subsets but with what we can call <em class="italic">tags </em>in AI. A memory can be a combination of multiple tags:</p>
    <ul>
      <li class="bulletList">A memoryless fiction, such as a dream</li>
      <li class="bulletList">A short-term reality, such as reading the news</li>
      <li class="bulletList">A long-term fiction, such as a novel we read a long time ago</li>
    </ul>
    <p class="normal">When examining these memory subcategories, we quickly realize the vast number of possible tag combinations with the main memory categories—such as semantic STM or episodic LTM. Additionally, memories can seamlessly blend subcategories; for instance, the phrase “I visited Rome last year” combines episodic, semantic, and temporal memory tags simultaneously. Moreover, our memories range from implicit (subconsciously blinking our eyes all day) to explicit (intentionally blinking due to an irritation).</p>
    <p class="normal">In our consumer memory agent, we will request a thorough analysis of content, assigning appropriate memory tags to each text segment. However, even this detailed tagging is not sufficient by itself. To effectively capture consumer experiences, we will enrich each memory tag with three analytical dimensions:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Intellectual dimension</strong>: Identifies thoughts, logic, and reasoning within the text.</li>
      <li class="bulletList"><strong class="keyWord">Emotional dimension</strong>: Pinpoints emotions, feelings, and overall mood—critical for effective consumer engagement—and provides a quantifiable sentiment score ranging from 0 to 1, scalable to a familiar 1–5 rating used in customer satisfaction forms.</li>
      <li class="bulletList"><strong class="keyWord">Physical dimension</strong>: Highlights sensory experiences and physical sensations, such as “it was too cold to go swimming” or “my back hurt after sleeping in that hotel bed.”</li>
    </ul>
    <p class="normal">With these <a id="_idIndexMarker417"/>enhancements in mind, let’s now explore how we’ll integrate them into the architecture of our evolving GenAISys.</p>
    <h2 class="heading-2" id="_idParaDest-164"><a id="_idTextAnchor171"/>Enhancing the architecture of the GenAISys</h2>
    <p class="normal">In this <a id="_idIndexMarker418"/>chapter, we will build <a id="_idIndexMarker419"/>upon the existing three-layer architecture of the GenAISys, as illustrated previously in <em class="italic">Figure 5.3</em> and reproduced here:</p>
    <figure class="mediaobject"><img alt="Figure 6.3: The three layers of the event-driven GenAISys" src="../Images/B32304_06_3.png"/></figure>
    <p class="packt_figref">Figure 6.3: The three layers of the event-driven GenAISys</p>
    <p class="normal">Our approach will be bottom-up, starting from the foundational functions and proceeding upward through the AI agent to the GenAISys interface:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Layer 3 (functions and agents)</strong>: Here, we will introduce additional functionalities into our custom OpenAI library (<code class="inlineCode">reason.py</code>), specifically tailored for the consumer memory agent and CoT reasoning. We will also develop a standalone memory analysis function that provides neuroscientific-like analyses applicable to any content.</li>
      <li class="bulletList"><strong class="keyWord">Layer 2 (AI agent)</strong>: This layer manages the behavior and decisions of our GenAISys. We will establish clear input triggers and naming conventions to activate and control the AI agent effectively.</li>
      <li class="bulletList"><strong class="keyWord">Layer 1 (IPython interface)</strong>: The interactive interface will be expanded to facilitate user interaction. We will add a new widget, allowing users to conveniently select how<a id="_idIndexMarker420"/> the consumer <a id="_idIndexMarker421"/>memory agent is invoked. Initially, we will focus on hotel reviews and subsequently generalize to any form of input.</li>
    </ul>
    <p class="normal">Let’s now begin building the consumer memory agent.</p>
    <h1 class="heading-1" id="_idParaDest-165"><a id="_idTextAnchor172"/>Building the consumer memory agent</h1>
    <p class="normal">In this section, we <a id="_idIndexMarker422"/>take our GenAISys to the next level by equipping it with neuroscientific capabilities for analyzing hotel reviews. The consumer memory agent will capture a user’s cognitive, emotional, and physical mindset, decoding each review segment through a six-step CoT process, as illustrated in <em class="italic">Figure 6.4</em>:</p>
    <figure class="mediaobject"><img alt="Figure 6.4: Chain-of-thought process of the memory agent" src="../Images/B32304_06_4.png"/></figure>
    <p class="packt_figref">Figure 6.4: Chain-of-thought process of the memory agent</p>
    <p class="normal">The consumer memory agent’s CoT will use OpenAI’s o3, GPT-4o, and DALL-E to run its six steps:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Step 1: Memory and Sentiment Analysis</strong>: The agent will analyze the content of the hotel review with a complex memory structure system message. It will analyze and tag the content segment by segment.</li>
      <li class="bulletList"><strong class="keyWord">Step 2: Extract Scores</strong>: The agent processes the output of <em class="italic">Step 1 </em>to extract the sentiment scores of each content segment.</li>
      <li class="bulletList"><strong class="keyWord">Step 3: Statistical Analysis</strong>:<em class="italic"> </em>The agent uses the scores of all the tagged segments to produce an overall cognitive score for the content.</li>
      <li class="bulletList"><strong class="keyWord">Step 4: Creating Content</strong>:<em class="italic"> </em>The agent now has a decision to make based on the score. If the score exceeds a positive threshold, it will generate a message encouraging the consumer to select hotels. However, if the score is negative, a guest house message will be created. Once the decision is made, the agent will use the consumer’s memory tags to create a tailored promotional message.</li>
      <li class="bulletList"><strong class="keyWord">Step 5: Image Creation</strong>: The agent now uses the output of <em class="italic">Step 4</em> to create an image that will fit the consumer’s mindset.</li>
      <li class="bulletList"><strong class="keyWord">Step 6: Message Creation</strong>: The agent now has all the information necessary to generate a custom message for the consumer.</li>
    </ul>
    <p class="normal">After developing <a id="_idIndexMarker423"/>these steps individually, we’ll integrate them fully in the upcoming section, <em class="italic">GenAISys interface: From complexity to simplicity</em>, aiming to generalize the CoT functionality beyond hotel reviews.</p>
    <p class="normal">To begin our journey, open the <code class="inlineCode">1_Building_the_Consumer_Memory_Agent.ipynb</code> notebook, which reuses previously built functionality, within the Chapter06 directory on GitHub (<a href="https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main"><span class="url">https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main</span></a>). We will first download a dataset of hotel reviews to provide inputs to the AI agent.</p>
    <h2 class="heading-2" id="_idParaDest-166"><a id="_idTextAnchor173"/>The dataset: Hotel reviews</h2>
    <p class="normal">We will be <a id="_idIndexMarker424"/>using synthetic hotel reviews to build the memory agent. In this chapter, we will process hotel reviews but also generalize the memory structure of the agent to other content we wish to analyze. For copyright reasons, the dataset we are using is a synthetic dataset of reviews created manually and with a generative AI copilot.</p>
    <p class="normal">If you wish to explore more datasets, you can use a similar dataset containing TripAdvisor hotel reviews available on Kaggle for non-commercial private implementations at <a href="https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews"><span class="url">https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews</span></a>.</p>
    <p class="normal">Run the <em class="italic">Setting up the Environment</em> section on GitHub, identical to <a href="Chapter_5.xhtml#_idTextAnchor140"><em class="italic">Chapter 5</em></a>, and download the dataset directly from the GitHub repository:</p>
    <pre class="programlisting code"><code class="hljs-code">download(<span class="hljs-string">"Chapter06"</span>,<span class="hljs-string">"hotel_reviews.csv"</span>)
</code></pre>
    <div class="packt_tip">
      <p class="normal"><img alt="" src="../Images/3-PPMUMLAP0325.png"/><strong class="keyWord">Quick tip</strong>: Enhance your coding experience with the <strong class="keyWord">AI Code Explainer</strong> and <strong class="keyWord">Quick Copy</strong> features. Open this book in the next-gen Packt Reader. Click the <strong class="keyWord">Copy</strong> button</p>
      <p class="normal">(<strong class="keyWord">1</strong>) to quickly copy code into your coding environment, or click the <strong class="keyWord">Explain</strong> button</p>
      <p class="normal">(<strong class="keyWord">2</strong>) to get the AI assistant to explain a block of code to you.</p>
      <p class="normal"><img alt="A white background with a black text  AI-generated content may be incorrect." src="../Images/image_%282%29.png"/></p>
      <p class="normal"><img alt="" src="../Images/4.png"/><strong class="keyWord">The next-gen Packt Reader </strong>is included for free with the purchase of this book. Scan the QR code OR visit <a href="http://packtpub.com/unlock"><span class="url">packtpub.com/unlock</span></a>, then use the search bar to find this book by name. Double-check the edition shown to make sure you get the right one.</p>
      <p class="normal"><img alt="A qr code on a white background  AI-generated content may be incorrect." src="../Images/Unlock_Code1.png"/></p>
    </div>
    <p class="normal">We will process the dataset with a pandas DataFrame. The program now loads the CSV file and displays the data:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-comment"># Load the CSV file into a Pandas DataFrame</span>
dfta = pd.read_csv(<span class="hljs-string">'/content/hotel_reviews.csv'</span>,sep=<span class="hljs-string">','</span>)
<span class="hljs-comment"># display the DataFrame</span>
dfta
</code></pre>
    <p class="normal">This dataset contains two primary columns: <code class="inlineCode">Review</code> and <code class="inlineCode">Rating</code>. For instance, record 0 has a relatively constructive rating of 3, while record 1 shows a clearly positive rating of 5:</p>
    <figure class="mediaobject"><img alt="Figure 6.5: Excerpt of the hotel review dataset" src="../Images/B32304_06_5.png"/></figure>
    <p class="packt_figref">Figure 6.5: Excerpt of the hotel review dataset</p>
    <p class="normal">Ratings alone, however, don’t provide sufficient depth—we require a nuanced sentiment analysis to <a id="_idIndexMarker425"/>fully grasp why a customer was satisfied or dissatisfied. We will choose a challenging review to begin our analysis:</p>
    <pre class="programlisting code"><code class="hljs-code">index_number = <span class="hljs-number">0</span>  <span class="hljs-comment"># Specify the index number</span>
</code></pre>
    <p class="normal">The program now extracts the review and its rating:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-comment"># Extract the desired fields</span>
    review = row[<span class="hljs-string">'Review'</span>]
    rating = row[<span class="hljs-string">'Rating'</span>]
    <span class="hljs-comment"># Display the results</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Review: </span><span class="hljs-subst">{review}</span><span class="hljs-string">"</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Rating: </span><span class="hljs-subst">{rating}</span><span class="hljs-string">"</span>)
<span class="hljs-keyword">except</span> IndexError:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Error: Index </span><span class="hljs-subst">{index_number}</span><span class="hljs-string"> is out of bounds for the DataFrame."</span>)
<span class="hljs-keyword">except</span> KeyError <span class="hljs-keyword">as</span> e:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Error: Column '</span><span class="hljs-subst">{e}</span><span class="hljs-string">'</span><span class="hljs-string"> not found in the DataFrame."</span>)
</code></pre>
    <p class="normal">The output displays the review and its rating:</p>
    <pre class="programlisting con"><code class="hljs-con">Review: We got a nice hotel. The parking was rather expensive. However, we got a good deal for my birthday. We arrived in during the night because of a late flight but the parking was open 24hours The check in was rapid. The room was a large size. Cool. But we didn't get the view expected. The bed was super comfortable and got a nice sleep for a few hours but then there was a raucous of a noisy crowd going to bed late. Anyway the price was acceptable and we made it to the shopping mall next to the hotel which reminded me of the one we had at home.
Rating: 3
</code></pre>
    <p class="normal">We have chosen a difficult review because it contains both negative and positive sentiment. The negative<a id="_idIndexMarker426"/> aspect of the review will challenge the agent to generate constructive solutions. Before continuing, analyze the memory tags, sentiment scores, and dimensions of each review segment yourself. This exercise clarifies memory category usage and provides a benchmark for comparing your insights to the agent’s analysis. Set the extracted review as the initial input:</p>
    <pre class="programlisting code"><code class="hljs-code">input1=review
</code></pre>
    <p class="normal">We will now design a complex system message for <em class="italic">Step 1</em> for <code class="inlineCode">input1</code>.</p>
    <h2 class="heading-2" id="_idParaDest-167"><a id="_idTextAnchor174"/>Step 1: Memory and sentiment analysis</h2>
    <p class="normal">This step <a id="_idIndexMarker427"/>introduces advanced reasoning to our consumer memory agent by incorporating meta-cognition and meta-reasoning through the OpenAI o3 reasoning model. In other words, the agent won’t simply process text—it will actively reflect on its internal reasoning, performing a segment-by-segment analysis to categorize memory types and assign sentiment scores.</p>
    <p class="normal">Specifically, the o3 model will operate within our carefully structured system message, which we will design in detail. This system message guides the model clearly, prompting deep reasoning and ensuring it assigns memory tags accurately based on human-like cognitive processes. We are definitely in the era of reasoning and self-reflecting AI!</p>
    <p class="normal">In this section, we will do the following:</p>
    <ul>
      <li class="bulletList">Design a complex system message that incorporates the detailed memory structures defined earlier. This message, called <code class="inlineCode">system_message_s1</code>, will be stored separately in a Python file for modularity.</li>
      <li class="bulletList">Rely on the reasoning abilities of OpenAI’s o3 to do the heavy lifting and execute detailed segment-level analysis, relieving us from manual interpretation.</li>
    </ul>
    <div class="note">
      <p class="normal"> Note that we use o1 as an umbrella term to signal to the LLM its role as a reasoning model. Additionally, the LLM may refer to o1 itself in responses though we call o3 as much as possible in the API.</p>
    </div>
    <p class="normal">Let’s now construct this detailed system message step by step.</p>
    <h3 class="heading-3" id="_idParaDest-168"><a id="_idTextAnchor175"/>Designing a complex system message for Step 1</h3>
    <p class="normal">We <a id="_idIndexMarker428"/>must design a system message comprehensive enough for the model to deeply understand and execute a neuroscience-inspired memory analysis. To achieve this, we carefully structure the message into clearly labeled sections, each guiding the agent through different aspects of the analysis.</p>
    <h4 class="heading-4">0. Model introduction and role of the agent</h4>
    <p class="normal">The first line sets <a id="_idIndexMarker429"/>the tone for the agent at<a id="_idIndexMarker430"/> two levels. The first level provides the agent with the necessary concepts to understand advanced memory analysis for this task. The second level describes the role of the agent in detail:</p>
    <pre class="programlisting code"><code class="hljs-code">You are a generative AI model, an advanced memory-analysis model. Your role is to examine **each segment** of an incoming text and generate a set of "memory encoding tags," similar to how the human brain encodes memories in neuroscience. For every segment in the input, you will identify which categories apply, discuss the rationale, and assign additional metadata (dimension, sentiment, etc.).
</code></pre>
    <p class="normal">Now, let’s go through the instructions to grasp what the agent is learning through this first part of the message:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">generative AI model, an advanced memory-analysis model</code>: We are setting the role of the system in a special way. We are asking the model to think, not just to generate text. For this task, we don’t want the model to be created but to analyze and reason.</li>
      <li class="bulletList"><code class="inlineCode">examine **each segment**</code>: We are teaching the model to replicate a neuroscience approach. Our brain encodes information in discrete packages. In this case, we are asking the model to mimic human memory processes. Each segment of text can be a sentence, a sentence piece, or a paragraph. This way, the model will analyze the text in a manner similar to how a human brain encodes information in independent packages.</li>
      <li class="bulletList"><code class="inlineCode">generate a set of "memory encoding tags," similar to how the human brain encodes memories</code>: Human brains encode memories with <em class="italic">tags</em>, a term we can use at a high level without going into the biological process. Our brains apply tags to every bit of information that they encode to differentiate a past event from a future event, for example, from semantic data or personal emotional experiences. These tags represent the categories of memory we are looking for in human-generated text.</li>
      <li class="bulletList"><code class="inlineCode">discuss the rationale, and assign additional metadata</code>: The model must explain the rationale behind the category of memory it tags. Each category, such as STM or LTM, must be explained. We need to know why a memory tag was attributed to the segment. The model is asked to add dimensions to its description, including<a id="_idIndexMarker431"/> intellectual and emotional reasons.</li>
    </ul>
    <div class="note">
      <p class="normal"> You might notice a Markdown divider (<code class="inlineCode">---</code>) in the code. It shows the model that we are now moving to another topic. This may seem unimportant, but we need to emphasize topic changes as we do when giving instructions to humans. Now, we will give the model a purpose.</p>
    </div>
    <h4 class="heading-4">1. Purpose</h4>
    <p class="normal">Line 3 is a header<a id="_idIndexMarker432"/> that shows the model that we are entering the first significant section of the message:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### 1. Purpose</span>
</code></pre>
    <p class="normal">Line 4 defines the goal of o3, OpenAI’s reasoning model:</p>
    <pre class="programlisting code"><code class="hljs-code">The goal is for you, O1, to perform an **in-depth memory analysis** of each segment of the text. In other words, you will classify and label each segment you find using specific memory categories (also called "memory encoding tags"). This process provides insight into how different parts of the text might be encoded in human memory.
</code></pre>
    <p class="normal">Note that the message contains “o1,” which is used as an umbrella term for OpenAI’s reasoning models here. The main idea is for the API to understand that we expect reasoning. This instruction will activate reasoning no matter which reasoning model you select. The key parts of this <em class="italic">Purpose</em> section insist on what we expect:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">in-depth memory analysis</code>: We do not want a classical analysis but a reflection that goes into the details of each segment.</li>
      <li class="bulletList"><code class="inlineCode">Classify and label each segment you find using specific memory categories</code>: This is a strong indicator of the memory categories the model is expected to tag. Once again, we remind the agent that we don’t want to generate text but to classify and label segments.</li>
      <li class="bulletList"><code class="inlineCode">provides insight into how different parts of the text might be encoded in human memory</code>: This is an explicit indication that we expect human-like thinking and replicates the way a brain encodes memories.</li>
    </ul>
    <p class="normal">We now need to give the agent the heading it needs to learn the categories. The first lines provide clear instructions. Now, we have reached section 2 of the message.</p>
    <h4 class="heading-4">2. Memory encoding tags</h4>
    <p class="normal">We now teach<a id="_idIndexMarker433"/> the agent how to recognize different categories of human encoding tags. We are getting to the core of human memory encoding. The memory categories are those discussed in the <em class="italic">Defining memory structures</em> section of this chapter:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### 2. Memory Encoding Tags (Categories)</span>
</code></pre>
    <p class="normal">This heading is vital as the agent will learn the tags we expect by taking a hint from this heading. Now, the agent has absorbed the heading. We then give the model a clear explanation of what actions we expect:</p>
    <pre class="programlisting code"><code class="hljs-code">Below is a list of memory categories you must use. Consider them your "tagging schema." A single segment may exhibit one or more categories. If no category seems relevant, you may provide the special tag "memoryless" to indicate no significant memory encoding.
</code></pre>
    <p class="normal">Let’s focus on the key parts of this message:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">tagging schema</code>: Aligns the model with the way the human brain encodes different categories of memory, distinguishing the past from the present using <em class="italic">tags</em></li>
      <li class="bulletList"><code class="inlineCode">A single segment may exhibit one or more categories</code>: Explains to the model that a memory can be encoded in more than one category, just like in a human brain</li>
      <li class="bulletList"><code class="inlineCode">If no category seems relevant … memoryless</code>: Tells the model that it should assign a memoryless tag if it cannot determine a category of a memory</li>
    </ul>
    <p class="normal">We then clearly define the categories (e.g., STM, LTM, episodic memory, semantic memory, time memory, reality memory, fiction memory, memoryless), as previously discussed:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-number">1.</span> **Short Term Memory (STM)**
   - Used <span class="hljs-keyword">for</span> information that seems fleeting, recently introduced, <span class="hljs-keyword">or</span> relevant only <span class="hljs-keyword">in</span> the immediate context.
…
<span class="hljs-number">8.</span> **Memoryless**
  - If a segment does <span class="hljs-keyword">not</span> appear to connect to <span class="hljs-built_in">any</span> memory encoding <span class="hljs-keyword">or</span> <span class="hljs-keyword">is</span> purely functional text (e.g., disclaimers, random filler), label it "memoryless."
</code></pre>
    <p class="normal">The memory tags have been described but are insufficient to capture human memory, which relies on other dimensions to encode events.</p>
    <h4 class="heading-4">3. Dimensions</h4>
    <p class="normal">The<a id="_idIndexMarker434"/> dimensions section adds intellectual, emotional, and physical features to the agent’s investigation. The descriptions of these dimensions in the following message were described in the <em class="italic">Defining memory structures </em>section earlier:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="codeHighlighted" style="font-weight: bold;">Dimension Descriptions</code>
  1. <code class="codeHighlighted" style="font-weight: bold;">Intellectual</code>
  2. Logical, analytical, or factual thought processes.
      - <code class="codeHighlighted" style="font-weight: bold;">Explanation</code>: If the text focuses on reasoned arguments, data, 
        or factual details, it should be labeled "Intellectual."
  3. <code class="codeHighlighted" style="font-weight: bold;">Emotional</code>
  4. Feelings, mood, or affective elements.
      - <code class="codeHighlighted" style="font-weight: bold;">Explanation</code>: If the text displays happiness, sadness, or other 
        strong emotional content, "Emotional" is assigned.
  5. <code class="codeHighlighted" style="font-weight: bold;">Physical (with Sensations</code>
</code></pre>
    <p class="normal">With that, we have defined the memory categories and additional dimensions. However, we also need a more refined analysis of emotions.</p>
    <h4 class="heading-4">4. Sentiment score</h4>
    <p class="normal">As <a id="_idIndexMarker435"/>defined in the <em class="italic">Defining memory structures </em>section, the sentiment score measures the emotional value of a segment. It provides a numerical score between 0 (negative) and 1 (positive), or 0.5 (neutral) if no sentiment can be detected:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### 4. Sentiment Score</span>
Assign each segment a **sentiment score** between **<span class="hljs-number">0.0</span>** <span class="hljs-keyword">and</span> **<span class="hljs-number">1.0</span>**, where:
  - **<span class="hljs-number">0.0</span>** = very negative
  - **<span class="hljs-number">0.5</span>** = neutral
  - **<span class="hljs-number">1.0</span>** = very positive
If a segment <span class="hljs-keyword">is</span> purely factual <span class="hljs-keyword">with</span> no emotional valence, use <span class="hljs-number">0.5</span> (neutral).
</code></pre>
    <div class="note">
      <p class="normal"> Note that each section in the message begins and ends with clear Markdown indicators that show a change in topic.</p>
    </div>
    <p class="normal">Next, we are going to ask for a specific response format.</p>
    <h4 class="heading-4">5. Response format</h4>
    <p class="normal">We need the<a id="_idIndexMarker436"/> response to clearly display each segment of the original text, provide memory tags for each segment, determine the dimension (intellectual, emotional, or physical) of each segment, provide a sentiment score, and provide a brief explanation to justify the analysis:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### 5. Format of the Response</span>
For **each segment** <span class="hljs-keyword">in</span> the incoming text:
  <span class="hljs-number">1.</span> Show the segment excerpt <span class="hljs-keyword">or</span> a short summary.
  <span class="hljs-number">2.</span> **Memory Tags**: <span class="hljs-built_in">list</span> <span class="hljs-built_in">any</span> relevant categories.
  <span class="hljs-number">3.</span> **Dimension**: choose intellectual, emotional, <span class="hljs-keyword">or</span> physical.
  <span class="hljs-number">4.</span> **Sentiment Score**: <span class="hljs-number">0.0</span> → <span class="hljs-number">1.0</span>.
  <span class="hljs-number">5.</span> **Brief Explanation**: why these tags/dimensions.
</code></pre>
    <p class="normal">To make sure the model understands what we are asking for, we provide an example format:</p>
    <pre class="programlisting code"><code class="hljs-code">Example <span class="hljs-built_in">format</span>:
Segment <span class="hljs-number">1</span>: <span class="hljs-string">"Excerpt..."</span>
  - Memory Tags: [Time Memory Past, Reality Memory]
  - Dimension: Emotional
  - Sentiment Score: <span class="hljs-number">0.7</span>
  - Explanation: The speaker refers to a past real event <span class="hljs-keyword">with</span> positive affect.
</code></pre>
    <p class="normal">If we were writing a traditional generative AI model message, we could stop here. However, this is a complex message, so we need to add instructions to <em class="italic">insist on</em> what we expect.</p>
    <h4 class="heading-4">6. Additional instructions</h4>
    <p class="normal">We avoided <a id="_idIndexMarker437"/>overloading the previous sections of the message. If we try to squeeze too many instructions in, the model might get confused. Let’s remind the system that we always want a segment-by-segment analysis. We insist that if the model doesn’t find a category, we want a “memoryless” tag and not a hallucination. Additionally, we only want short and clear explanations:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### 6. Additional Instructions</span>
  - Always analyze segment-by-segment.
  - If no memory category applies, use "memoryless."
  - Use a short but clear explanation.
</code></pre>
    <p class="normal">Now comes the tricky part. We told the model that if it didn’t find a category at all, to use a “memoryless” tag. However, if the model has an idea but is not 100% sure, then it is allowed to pick the most probable memory tag along with a mandatory sentiment score:</p>
    <pre class="programlisting code"><code class="hljs-code">  - If uncertain about the correct memory category, pick the most likely.
  - Always include a sentiment score.
</code></pre>
    <p class="normal">At this point, we have provided the model with numerous instructions. Let’s make sure it remembers its primary task.</p>
    <h4 class="heading-4">7. Primary task recall</h4>
    <p class="normal">After all the <a id="_idIndexMarker438"/>instructions we have given the model, we will remind the model that its primary task is a memory tag analysis of text segments. We also expect the format of the output to be structured as defined:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### 7. Primary Task</span>
When I provide multisegment text, you must do a thorough memory-tag analysis for each segment. Return the results in the structured format above.
[End of System Prompt]
</code></pre>
    <p class="normal">Note that we added <code class="inlineCode">[End of System Prompt]</code> to make sure that the model understands that the message part of the global prompt is now completely defined. We use the term <code class="inlineCode">prompt</code> to make sure that it understands it as a set of instructions, not just a general message.</p>
    <p class="normal">We are now ready to run the memory analysis.</p>
    <h3 class="heading-3" id="_idParaDest-169"><a id="_idTextAnchor176"/>Running the memory analysis</h3>
    <p class="normal">The complex <a id="_idIndexMarker439"/>system message we designed is stored in a variable named <code class="inlineCode">system_message_s1 </code>in <code class="inlineCode">cot_message_c6.py</code> in the <code class="inlineCode">commons</code> directory of the GitHub repository. The goal is to keep this message and those for other steps separate from the function calls so that the AI agent of the GenAISys can repurpose the function in this step or other steps for different tasks.</p>
    <p class="normal">We first download the file that contains the messages:</p>
    <pre class="programlisting code"><code class="hljs-code">download(<span class="hljs-string">"commons"</span>,<span class="hljs-string">"cot_messages_c6.py"</span>)
</code></pre>
    <p class="normal">Then we import the <code class="inlineCode">system_message_s1</code> message and the messages we will need for <em class="italic">Step 4</em>, which we will discuss later:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> cot_messages_c6 <span class="hljs-keyword">import</span> (
<span class="hljs-keyword">    </span>system_message_s1, generation,imcontent4,imcontent4b)
<span class="hljs-built_in">print</span>(system_message_s1) <span class="hljs-comment"># Print to verify</span>
</code></pre>
    <p class="normal">The <code class="inlineCode">print</code> function is uncommented and will display the message we just created. It can be commented and used at any time to verify whether the message is correctly imported. We now prepare the messages for o3:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Step 1 : Memory and sentiment analysis</span>
mrole= system_message_s1
user_text=review
</code></pre>
    <ul>
      <li class="bulletList"><code class="inlineCode">mrole</code> is <code class="inlineCode">system_message_s1</code>, the system message we designed</li>
      <li class="bulletList"><code class="inlineCode">user_text </code>is <code class="inlineCode">review</code>, the review selected from the hotel reviews dataset</li>
    </ul>
    <p class="normal">We now call o3 and store the result in a variable:</p>
    <pre class="programlisting code"><code class="hljs-code">retres=reason.make_openai_reasoning_call(user_text, mrole)
</code></pre>
    <p class="normal"><code class="inlineCode">make_openai_reasoning_call</code> is located in <code class="inlineCode">reason</code>, the AI library of the GenAISys. It takes the two<a id="_idIndexMarker440"/> arguments we just defined, creates an OpenAI client, makes the request, and returns the response:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Implemented in Chapter06</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">make_openai_reasoning_call</span>(<span class="hljs-params">user_text, mrole</span>):
    system_prompt=mrole
    client = OpenAI()
    rmodel = <span class="hljs-string">"o3-mini"</span> <span class="hljs-comment"># o1 or other models. model defined in this file in /commons to make a global change to all the notebooks in the repo when there is an OpenAI update</span>
    response = client.chat.completions.create(
        model=rmodel,
        messages=[
            {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: system_prompt},
            {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: user_text}
        ],
    )
    <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].message.content
</code></pre>
    <p class="normal">For this call, we chose the <code class="inlineCode">o3-mini</code> version of the <code class="inlineCode">o3</code> reasoning model series. Other versions and reasoning models can be chosen. The program displays the output received in <code class="inlineCode">retres</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Print the generated output (memory analysis)</span>
<span class="hljs-built_in">print</span>(retres)
</code></pre>
    <p class="normal">The output shows the depth of the system message and the o3 reasoning model. The AI model has broken the content down into segments and decoded the memory tags subconsciously used by the human reviewer, as shown in the first segment.</p>
    <p class="normal">The model first provides the segment number and the content of that segment. Let’s focus on segment 7, which requires our attention:</p>
    <pre class="programlisting con"><code class="hljs-con">Segment 7: "But we didn't get the view expected."
</code></pre>
    <p class="normal">It also provides the memory tags that encoded this segment:</p>
    <pre class="programlisting con"><code class="hljs-con">- Memory Tags: [Episodic Memory, Reality Memory]
</code></pre>
    <p class="normal">It continues by providing the dimension, which is as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">• Dimension: Emotional
</code></pre>
    <p class="normal">It then gives a sentiment score, which is as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">• Sentiment Score: 0.4
</code></pre>
    <p class="normal">Finally, it <a id="_idIndexMarker441"/>produces an explanation that sums up its analysis:</p>
    <pre class="programlisting con"><code class="hljs-con"> - Explanation: The disappointment regarding the view introduces a negative emotional element to this real-life account, impacting the overall perception of the stay.
</code></pre>
    <p class="normal">The model then continues its analysis for all the segments of the review.<code class="inlineCode"> </code>We have now performed a complex memory analysis that sets the stage for the subsequent steps. Let’s proceed to extract the sentiment scores.</p>
    <h2 class="heading-2" id="_idParaDest-170"><a id="_idTextAnchor177"/>Step 2: Extract sentiment scores</h2>
    <p class="normal">From this <a id="_idIndexMarker442"/>point on, the original input stored in <code class="inlineCode">review</code> is not used again. The CoT process relies on the output of the previous step, which will continually vary depending on the context. The next step involves extracting the sentiment scores for all segments produced in <em class="italic">Step 1: Memory and sentiment analysis</em>. We will need this information to make decisions for <em class="italic">Step 4: Content creation</em>.</p>
    <p class="normal">To extract the scores, we first create an <code class="inlineCode">extraction</code> function and provide detailed instructions:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">extract</span>(<span class="hljs-params">tasks_response</span>):
    umessage = <span class="hljs-string">"""</span>
<span class="hljs-string">    1) Read the following text analysis that returns detailed memory tags for each part of the text</span>
<span class="hljs-string">    2) Then return the list of memory tags with absolutely no other text</span>
<span class="hljs-string">    3) Use no formatting, no hashtags, no markdown. Just answer in plain text</span>
<span class="hljs-string">    4) Also provide the sentiment analysis score for each tag in this format(no brackets) : memory tag sentiment Score</span>
<span class="hljs-string">    """</span>
</code></pre>
    <p class="normal">We have clearly instructed our GenAISys to provide the sentiment scores in a clean format only. We will now call GPT-4o with <code class="inlineCode">reason.make_openai_api_call</code>, defined previously, and add <code class="inlineCode">reason.py</code>, the AI library we began building in the previous chapters. The input to the API call is the output of the last step, <code class="inlineCode">retres</code>, appended to the instruction message, <code class="inlineCode">umessage</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">    umessage+=retres
</code></pre>
    <p class="normal">The <code class="inlineCode">system</code> role reminds the agent of its psychological marketing function:</p>
    <pre class="programlisting code"><code class="hljs-code">    mrole = <span class="hljs-string">"system"</span>
    mcontent = <span class="hljs-string">"You are a marketing expert specialized in the psychological analysis of content"</span>
</code></pre>
    <p class="normal">The <code class="inlineCode">user</code> role<a id="_idIndexMarker443"/> introduces the user message, <code class="inlineCode">umessage</code>, and the API call is made:</p>
    <pre class="programlisting code"><code class="hljs-code">    user_role = <span class="hljs-string">"user"</span>
    task_response = reason.make_openai_api_call(
        umessage,mrole,mcontent,user_role
    )
    <span class="hljs-keyword">return</span> task_response
</code></pre>
    <p class="normal">The agent returns <code class="inlineCode">task_response</code>, from which we will extract the memory sentiment scores, process, and verify:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Step 2: Extract scores</span>
task_response=extract(retres)
<span class="hljs-built_in">print</span>(task_response)
</code></pre>
    <p class="normal">The output is the list of scores per segment we expected for each memory tag:</p>
    <pre class="programlisting con"><code class="hljs-con">Reality Memory sentiment 0.8
Episodic Memory sentiment 0.8
Reality Memory sentiment 0.4
Episodic Memory sentiment 0.4
Episodic Memory sentiment 0.8
Reality Memory sentiment 0.8
Time Memory Past sentiment 0.8
Episodic Memory sentiment 0.5…
</code></pre>
    <p class="normal">We now need <a id="_idIndexMarker444"/>to consolidate these scores to use them for decision-making.</p>
    <h2 class="heading-2" id="_idParaDest-171"><a id="_idTextAnchor178"/>Step 3: Statistics</h2>
    <p class="normal">We will <a id="_idIndexMarker445"/>use a simple non-AI <strong class="keyWord">regular expressions</strong> (<strong class="keyWord">re</strong>) module for this function for pattern matching and extraction. This shows that a GenAISys CoT can contain non-AI functions that expand its scope beyond generative AI models.</p>
    <p class="normal">The text to analyze is the output of the previous step:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Input text</span>
text=task_response
</code></pre>
    <p class="normal">We are looking for decimals:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Regular expression to extract sentiment scores</span>
pattern = <span class="hljs-string">r"(\d+\.\d+)"</span>
scores = [<span class="hljs-built_in">float</span>(<span class="hljs-keyword">match</span>) <span class="hljs-keyword">for</span> <span class="hljs-keyword">match</span> <span class="hljs-keyword">in</span> re.findall(pattern, text)]
</code></pre>
    <p class="normal">We then display the scores:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Output the extracted scores</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Extracted sentiment scores:"</span>, scores)
</code></pre>
    <p class="normal">The output contains the scores:</p>
    <pre class="programlisting con"><code class="hljs-con">Extracted sentiment scores: [0.8, 0.8, 0.4, 0.4, 0.8, 0.8, 0.8, 0.5, 0.5, 0.5, 0.7,…
</code></pre>
    <p class="normal">We first <a id="_idIndexMarker446"/>calculate an overall score if the function returned scores:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Optional: calculate the overall score and scaled rating</span>
<span class="hljs-keyword">if</span> scores:
    overall_score = <span class="hljs-built_in">sum</span>(scores) / <span class="hljs-built_in">len</span>(scores)
</code></pre>
    <p class="normal">Then we scale the score from 1 to 5:</p>
    <pre class="programlisting code"><code class="hljs-code">scaled_rating = overall_score * <span class="hljs-number">5</span>
</code></pre>
    <p class="normal">Finally, we display the overall score and the scaled score:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">"Overall score (0–1):"</span>, <span class="hljs-built_in">round</span>(overall_score, <span class="hljs-number">2</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Scaled rating (0–5):"</span>, <span class="hljs-built_in">round</span>(scaled_rating, <span class="hljs-number">2</span>))
</code></pre>
    <p class="normal">The output is what we expected:</p>
    <pre class="programlisting con"><code class="hljs-con">Overall score (0–1): 0.63
Scaled rating (0–5): 3.14
</code></pre>
    <p class="normal">The output requires some human analysis:</p>
    <ul>
      <li class="bulletList">In real-life projects, this process might not go so smoothly! Maybe the AI agent will not produce what we expect at all; perhaps it will for one step but not for the scores. When that occurs, we have to work on alternative steps. Building a GenAISys, as with any AI system, is an iterative process.</li>
      <li class="bulletList">The original rating in the hotel dataset for this review was 3, and we obtained 3.14, which is more refined. Online ratings are subjective and may not accurately reflect the content of the review. An AI agent will provide a more nuanced rating through advanced analysis processes similar to the one in this section. We could average the hotel review and ours. However, our goal is to generate a tailored message for the consumer. In a real-life project, we would reach out to consumers in marketing panels, utilizing<a id="_idIndexMarker447"/> the consumer memory agent, and obtain real-time feedback.</li>
    </ul>
    <p class="normal">For now, however, we have the information we need to determine the content to create.</p>
    <h2 class="heading-2" id="_idParaDest-172"><a id="_idTextAnchor179"/>Step 4: Content creation</h2>
    <p class="normal">Before deciding <a id="_idIndexMarker448"/>on the content to create, the agent reads the information messages. The first message is <code class="inlineCode">umessage4</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> cot_messages_c6 <span class="hljs-keyword">import</span> umessage4
</code></pre>
    <p class="normal">The message contains instructions on how to create a promotional campaign. We are keeping the message in a variable so that the function can be called with different prompts depending on the task.</p>
    <p class="normal">The agent must first use the memory tags analyzed to generate, not analyze, a text:</p>
    <pre class="programlisting code"><code class="hljs-code">umessage4 = <span class="hljs-string">"""</span>
<span class="hljs-string">1) Your task is to generate an engaging text  for a customer based on a memory analysis of a text</span>
<span class="hljs-string">2) The analysis of the text is provided in the following format: text segment, memory tags, dimension, sentiment score, and explanation</span>
<span class="hljs-string">The text also contains the overall sentiment score and the list of memory tags in the text</span>
<span class="hljs-string">3) Use no other memory tags than those provided to generate your engaging text</span>
</code></pre>
    <p class="normal">Then, the agent receives instructions on the sentiment analysis:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-string">4) Use the overall sentiment score to give the tone of your response</span>
<span class="hljs-string">If the overall sentiment score is positive write an engaging text addressing each segment with its memory tag and sentiment score</span>
<span class="hljs-string">If the overall sentiment score is negative analyze why and find ideas and solutions to find a way to satisfy the customer</span>
<span class="hljs-string">If the overall sentiment score is negative analyze make sure to show empathy for this negative feeling and then make the transition from negative to positive</span>
<span class="hljs-string">4) Focus on the topic provided that begins with the term the topic which focuses on the core topic of the text to make the customer happy</span>
</code></pre>
    <p class="normal">Then, the agent receives final instructions on the content to generate:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-string">5) Use your training to suggest named entities for that topic to make sure that the customer receives a message tailored to the memory tags and sentiment score</span>
</code></pre>
    <p class="normal">We now create the input by adding the scaled rating we obtained and the memory tags the agent found:</p>
    <pre class="programlisting code"><code class="hljs-code">ugeneration=generation + <span class="hljs-string">"The advanced memory analysis of each segment of a text with a sentiment score:"</span> + retres + <span class="hljs-string">" the scaled overall rating: "</span>+ <span class="hljs-built_in">str</span>(scaled_rating)+ <span class="hljs-string">" and the list of memory tags of the text "</span>+ task_response
</code></pre>
    <p class="normal">The agent <a id="_idIndexMarker449"/>now has a complete representation of the task expected. We explain the agent’s role with <code class="inlineCode">imcontent4</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">imcontent4 = <span class="hljs-string">"You are a marketing expert specialized in the psychological analysis of content"</span>
</code></pre>
    <p class="normal">The agent is now ready to run the generation with the <code class="inlineCode">make_openai_api_call</code> call:</p>
    <pre class="programlisting code"><code class="hljs-code">ugeneration=generation + …
mrole4 = <span class="hljs-string">"system"</span>
mcontent4 = imcontent4
user_role = <span class="hljs-string">"</span><span class="hljs-string">user"</span>
pre_creation_response = make_openai_api_call(
    ugeneration,mrole4,mcontent4,user_role
)
<span class="hljs-built_in">print</span>(pre_creation_response)
</code></pre>
    <p class="normal">The response is a <code class="inlineCode">pre_creation_response</code> response that is empathetic if the sentiment is negative or adapts it to the tone of the review otherwise:</p>
    <pre class="programlisting con"><code class="hljs-con">**Segment 7: "But we didn't get the view expected."**
Memory Tags: [Episodic Memory, Reality Memory]
Sentiment Score: 0.4
It's understandable to feel a bit let down when expectations aren't met. For future stays, …
</code></pre>
    <p class="normal">The output is in a cognitive format. We’re going to run the same call but with a message to clean up and prepare the content for image generation:</p>
    <pre class="programlisting code"><code class="hljs-code">umessage4b=<span class="hljs-string">"Clean and simplify the following text for use as a DALL-E prompt. Focus on converting the detailed analysis into a concise visual description suitable for generating an engaging promotional image"</span> + pre_creation_response
mrole4b = <span class="hljs-string">"system"</span>
mcontent4b = imcontent4b
user_role4b = <span class="hljs-string">"user"</span>
creation_response = make_openai_api_call(
    umessage4b,mrole4b,mcontent4b,user_role4b
)
<span class="hljs-built_in">print</span>(creation_response)
</code></pre>
    <p class="normal">The output is a clear instruction to create an image with an exciting <em class="italic">luxurious </em>offer that is always appreciated:</p>
    <pre class="programlisting con"><code class="hljs-con">"Luxurious hotel stay with spacious rooms and swift check-in; enjoy a comfortable bed and convenient 24-hour parking. Celebrate with special deals and nearby shopping reminiscent of home. Despite minor noise and view issues, the overall experience is positive and memorable."
</code></pre>
    <p class="normal">The output of the<a id="_idIndexMarker450"/> message may vary each time we run the requests, but the tone should remain the same. Also, we can adapt the instructions to other content to generate. In this case, the agent is all set to use this instruction to create an image.</p>
    <h2 class="heading-2" id="_idParaDest-173"><a id="_idTextAnchor180"/>Step 5: Creating an image</h2>
    <p class="normal">At this stage, the <a id="_idIndexMarker451"/>consumer memory agent uses the instructions (<code class="inlineCode">creation_response</code>) generated during <em class="italic">Step 4: Content creation</em> to create a tailored promotional image using OpenAI’s DALL-E:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Step 5: Creating an image</span>
<span class="hljs-keyword">import</span> requests
prompt=creation_response
image_url = reason.generate_image(prompt)
</code></pre>
    <p class="normal">The <code class="inlineCode">generate_image(prompt)</code> function is reused from the previous chapter. By consistently reusing functions, we reduce the development overhead and ensure code maintainability. As in<em class="italic"> </em><a href="Chapter_5.xhtml#_idTextAnchor140"><em class="italic">Chapter 5</em></a>, the image is generated and stored in a file as <code class="inlineCode">c_image.png</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">save_path = <span class="hljs-string">"c_image.png"</span>
image_data = requests.get(image_url).content
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">"wb"</span>) <span class="hljs-keyword">as</span> file:
    file.write(image_data)
</code></pre>
    <p class="normal">The image is now ready to accompany our final personalized message. We will display the image at the end of the process.</p>
    <h2 class="heading-2" id="_idParaDest-174"><a id="_idTextAnchor181"/>Step 6: Creating a custom message</h2>
    <p class="normal">With the<a id="_idIndexMarker452"/> promotional image prepared, we now generate a concise and engaging customer message. First, we confirm that <code class="inlineCode">creation_response</code> from <em class="italic">Step 5: Creating an image</em> is available:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> creation_response != <span class="hljs-string">""</span>:
    umessage = <span class="hljs-string">"""</span>
<span class="hljs-string">    1) Read the following text carefully</span>
<span class="hljs-string">    2) Then sum it up in a paragraphs without numbering the lines</span>
<span class="hljs-string">    3) They output should be a text to send to a customer</span>
<span class="hljs-string">    """</span>
</code></pre>
    <p class="normal">The output from the agent provides a polished message, suitable for customer communication:</p>
    <pre class="programlisting con"><code class="hljs-con">Dear Customer,
Experience a luxurious hotel stay with spacious rooms and a swift check-in process. Enjoy a comfortable bed and the convenience of 24-hour parking. Take advantage of special deals and nearby shopping that feels like home. While there may be minor noise and view issues, the overall experience remains positive and memorable.
Best regards,
</code></pre>
    <p class="normal">We can <a id="_idIndexMarker453"/>now display the output in another format if we wish to, with Python’s <code class="inlineCode">textwrap</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> Image, display
<span class="hljs-keyword">import</span> textwrap
<span class="hljs-comment"># Set the desired width for each line</span>
line_width = <span class="hljs-number">70</span>
<span class="hljs-comment"># Wrap the text to the specified width</span>
wrapped_message = textwrap.fill(process_response, width=line_width)
<span class="hljs-built_in">print</span>(wrapped_message)
</code></pre>
    <p class="normal">The displayed message is clear, professional, and suitable for direct customer outreach:</p>
    <pre class="programlisting con"><code class="hljs-con">Dear Customer,  Experience a luxurious hotel stay with spacious rooms
and a swift check-in process. …
</code></pre>
    <p class="normal">To enhance this message, you might adjust the prompt to omit references to AI or any internal system details, focusing purely on customer-oriented language.</p>
    <p class="normal">Finally, the system displays the generated image alongside the message to create an appealing, personalized promotional package:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Define the image path</span>
image_path = <span class="hljs-string">"/content/c_image.png"</span>
<span class="hljs-comment"># Check if the image file exists</span>
<span class="hljs-keyword">if</span> os.path.exists(image_path):
    <span class="hljs-comment"># Display the image</span>
    display(Image(filename=image_path))
<span class="hljs-keyword">else</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Image file </span><span class="hljs-subst">{image_path}</span><span class="hljs-string"> not found."</span>)
</code></pre>
    <p class="normal">The resulting visual emphasizes the hotel’s upgraded, luxurious offering, perfectly aligned with the <a id="_idIndexMarker454"/>customer’s expectations based on their review analysis:</p>
    <figure class="mediaobject"><img alt="Figure 6.6: An upgrade for a stay in the hotel for a customer" src="../Images/B32304_06_6.png"/></figure>
    <p class="packt_figref">Figure 6.6: An upgrade for a stay in the hotel for a customer</p>
    <p class="normal">You can now experiment with additional reviews, testing the depth and flexibility of the agent. We have successfully developed a sophisticated, neuroscience-inspired CoT consumer memory agent. In the next section, we’ll integrate this full process into the <code class="inlineCode">reason.py</code> AI library and further enhance our GenAISys framework.</p>
    <h1 class="heading-1" id="_idParaDest-175"><a id="_idTextAnchor182"/>GenAISys interface: From complexity to simplicity</h1>
    <p class="normal">Our <a id="_idIndexMarker455"/>journey in this chapter has taken us deeper into the era of self-reflecting, reasoning, and meta-cognitive agentic AI. In this final section, we shift from the intricate inner workings of our consumer-memory CoT to a clean, intuitive user experience. We’ll add a CoT widget that lets any user trigger memory analysis or full content generation on arbitrary text. We’ll then extend the AI agent so it reacts to that widget’s options. Finally, we’ll demonstrate the generalized workflow on a flight review to show how the same memory logic applies to new domains.</p>
    <p class="normal">Open the <code class="inlineCode">2_Running_the_Reasoning_GenAISys.ipynb</code> notebook on GitHub. Then run the <em class="italic">Setting up the Environment</em> section, which is identical to the notebook in <a href="Chapter_5.xhtml#_idTextAnchor140"><em class="italic">Chapter 5</em></a>. We will begin by adding a CoT widget to the IPython interface.</p>
    <h2 class="heading-2" id="_idParaDest-176"><a id="_idTextAnchor183"/>Adding the CoT widget</h2>
    <p class="normal">To make the <a id="_idIndexMarker456"/>memory agent simple and intuitive, we introduce a straightforward drop-down menu (<em class="italic">Figure 6.6</em>). Users can effortlessly select the task they wish the GenAISys agent to perform:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">None</strong> (default): No reasoning task is activated</li>
      <li class="bulletList"><strong class="screenText">Analysis</strong>: Activates a standalone memory-analysis function</li>
      <li class="bulletList"><strong class="screenText">Generation</strong>: Executes the full consumer memory agent workflow (<em class="italic">Steps 1–6</em>), including sentiment analysis, content generation, and custom message creation</li>
    </ul>
    <p class="normal">This streamlined user interaction significantly reduces complexity for the end user, shifting the sophisticated internal operations into the background.</p>
    <figure class="mediaobject"><img alt="Figure 6.7: Choosing the reasoning task" src="../Images/B32304_06_7.png"/></figure>
    <p class="packt_figref">Figure 6.7: Choosing the reasoning task</p>
    <p class="normal">The widget is implemented in three steps—adding the widget, adding an observer, and sending the options to the AI agent:</p>
    <ol>
      <li class="numberedList" value="1">Adding the widget is done in a few lines. We define the drop-down menu (<code class="inlineCode">instruct_selector</code>) within the IPython interface:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Ensure 'Instructions' exists in the memory_selector options</span>
instruct_selector = Dropdown(
    options=[<span class="hljs-string">"None"</span>,<span class="hljs-string">"Analysis"</span>, <span class="hljs-string">"Generation"</span>],
    value=<span class="hljs-string">"None"</span>,  <span class="hljs-comment"># Ensure default active_memory is in the options</span>
    description=<span class="hljs-string">'Reasoning:'</span>,
    layout=Layout(width=<span class="hljs-string">'50%'</span>)
)
</code></pre>
      </li>
    </ol>
    <p class="normal">The dropdown provides clear options, ensuring users easily understand their choices: <strong class="screenText">None</strong>, <strong class="screenText">Analysis</strong>, or <strong class="screenText">Generation</strong>. Next, we incorporate <code class="inlineCode">instruct_selector</code> into the existing interface layout (<code class="inlineCode">VBox</code>):</p>
    <pre class="programlisting code"><code class="hljs-code">VBox:
Box(
                [user_selector, input_box, agent_checkbox,
                    tts_checkbox, files_checkbox,instruct_selector],
                layout=Layout(display=<span class="hljs-string">'flex'</span>, flex_flow=<span class="hljs-string">'column'</span>,
                    align_items=<span class="hljs-string">'flex-start'</span>, width=<span class="hljs-string">'100%'</span>)
</code></pre>
    <p class="normal">When <a id="_idIndexMarker457"/>the user submits their choice, a handler updates the output messages for the user to see that the choice has been taken into account using standard submission code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">handle_submit</span>(<span class="hljs-params">sender</span>):
    user_message = sender.value
    <span class="hljs-keyword">if</span> user_message.strip():
        sender.value = <span class="hljs-string">""</span>  <span class="hljs-comment"># Clear the input box</span>
        <span class="hljs-comment"># Check if instruct_selector is "Analysis" or "Generation"</span>
        <span class="hljs-keyword">if</span> instruct_selector.value <span class="hljs-keyword">in</span> [<span class="hljs-string">"Analysis"</span>, <span class="hljs-string">"Generation"</span>]:
            <span class="hljs-keyword">with</span> reasoning_output:
                reasoning_output.clear_output(wait=<span class="hljs-literal">True</span>)
                <span class="hljs-built_in">print</span>(<span class="hljs-string">"Thinking..."</span>)  <span class="hljs-comment"># Display "Thinking..." only when</span>
            <span class="hljs-built_in">print</span>(<span class="hljs-string">"Reasoning activated"</span>)  <span class="hljs-comment"># Restore default message…</span>
</code></pre>
    <p class="normal">We want “Thinking…” to be displayed to signal to the user that the system is working.</p>
    <ol>
      <li class="numberedList" value="2">The second step is to insert an observer that will detect a change the user makes and update the display. The <code class="inlineCode">instruct_selector</code> is called by <code class="inlineCode">instruct_selector.observe</code>:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Ensure 'Instructions' exists in the memory_selector options</span>
instruct_selector = Dropdown(
    options=[<span class="hljs-string">"None"</span>,<span class="hljs-string">"Analysis"</span>, <span class="hljs-string">"Generation"</span>],
    value=<span class="hljs-string">"None"</span>,  <span class="hljs-comment"># Ensure default active_memory is in the options</span>
    description=<span class="hljs-string">'Reasoning:'</span>,
    layout=Layout(width=<span class="hljs-string">'50%'</span>)
instruct_selector.observe(on_instruct_change, names=<span class="hljs-string">'value'</span>)
</code></pre>
      </li>
      <li class="numberedList">Finally, we forward the user’s selection seamlessly into the AI agent call. The chosen reasoning mode (<code class="inlineCode">active_instruct</code>) is integrated into the agent’s execution path:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> agent_checkbox.value:
        pfiles = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> files_checkbox.value <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        active_instruct = instruct_selector.value  <span class="hljs-comment"># Retrieve the selected instruction</span>
        response = chat_with_gpt(user_histories[active_user],
            user_message, pfiles, active_instruct)
</code></pre>
      </li>
    </ol>
    <p class="normal">By clearly <a id="_idIndexMarker458"/>integrating these few lines, the AI agent dynamically activates the appropriate reasoning mode without additional user complexity. We can now enhance the AI agent.</p>
    <h2 class="heading-2" id="_idParaDest-177"><a id="_idTextAnchor184"/>Enhancing the AI agent</h2>
    <p class="normal">The<a id="_idIndexMarker459"/> AI agent will now receive the user’s widget selection in a new argument named <code class="inlineCode">active_instruct</code> that will trigger its decisions:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">chat_with_gpt</span>(<span class="hljs-params">messages, user_message,files_status,active_instruct</span>):
</code></pre>
    <p class="normal">When the user selects <strong class="screenText">Analysis</strong>, the AI agent triggers the previously built reasoning function, <code class="inlineCode">make_openai_reasoning_call</code>, to perform memory analysis:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> active_instruct==<span class="hljs-string">"Analysis"</span> <span class="hljs-keyword">and</span> continue_functions==<span class="hljs-literal">True</span>:
        <span class="hljs-keyword">from</span> cot_messages_c6 <span class="hljs-keyword">import</span> (
<span class="hljs-keyword">            </span>system_message_s1, generation,imcontent4,imcontent4b)
        mrole= system_message_s1
        reasoning_steps=reason.make_openai_reasoning_call(
            user_message, mrole
        )
        aug_output=reasoning_steps
        continue_functions=<span class="hljs-literal">False</span>
</code></pre>
    <p class="normal">Similarly, when <strong class="screenText">Generation</strong> is selected, the agent runs the complete memory agent workflow using the custom <code class="inlineCode">memory_reasoning_thread</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> active_instruct==<span class="hljs-string">"Generation"</span> <span class="hljs-keyword">and</span> continue_functions==<span class="hljs-literal">True</span>:
        <span class="hljs-keyword">from</span> cot_messages_c6 <span class="hljs-keyword">import</span> (
            system_message_s1, generation,imcontent4,imcontent4b)
        reasoning_steps = reason.memory_reasoning_thread(
            user_message,system_message_s1,
            generation,imcontent4,imcontent4b
        )
        aug_output=reasoning_steps
        continue_functions=<span class="hljs-literal">False</span>
</code></pre>
    <p class="normal">With these straightforward integrations, the GenAISys interface now provides powerful reasoning capabilities transparently.</p>
    <h2 class="heading-2" id="_idParaDest-178"><a id="_idTextAnchor185"/>Generalizing the GenAISys capabilities</h2>
    <p class="normal">With<a id="_idIndexMarker460"/> the enhanced interface, users can easily apply memory agent reasoning to diverse content beyond hotel reviews. Let’s illustrate this flexibility with a general user comment regarding a flight. The user simply selects <strong class="screenText">Analysis</strong>, then submits a flight review without additional instructions:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="codeHighlighted" style="font-weight: bold;">User01</code>: The flight <span class="hljs-keyword">from</span> Tokyo to Honolulu was nice <span class="hljs-keyword">in</span> general but the food was awful!
</code></pre>
    <p class="normal">The GenAISys instantly returns a detailed, segment-by-segment memory analysis:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="code-highlight"><strong class="hljs-con-slc">Agent:</strong></span> Segment 1: "The flight from Tokyo to Honolulu was nice in general"
- Memory Tags: [Reality Memory, Time Memory Past]
- Dimension: Emotional
- Sentiment Score: 0.7
- Explanation: This segment recounts a real past experience (a flight) and expresses a positive emotional evaluation ("nice"). The reference to a completed event classifies it under reality and past time memory…
</code></pre>
    <p class="normal">The user then reenters the sentence, but this time with the <strong class="screenText">Generation</strong> option and the <strong class="screenText">Files</strong> option checked, so that the image generated with the text will be displayed. All the user has to do is select the option, enter the text, and submit it. Once again, the experience is seamless, no additional instructions are required on the part of the user, and the response is complete: the fully analysis, process, and final customer message as we designed in the previous section—beginning with memory analysis, proceeding to sentiment scoring, content generation, and concluding with a tailored customer message and an engaging image (see <em class="italic">Figure 6.8</em>) that will be displayed if <code class="inlineCode">Files</code> is checked in the interface:</p>
    <pre class="programlisting con"><code class="hljs-con">Process: Performing memory and sentiment analysis.
Memory analysis result: Segment 1: "The flight from Tokyo to Honolulu was nice in general but the food was awful!"
- Memory Tags: [Reality Memory, Episodic Memory, Time Memory Past]
- Dimension: Emotional
- Sentiment Score: 0.4
- Explanation: This segment recounts a specific past travel event (a flight between two cities), embedding personal experience and subjective evaluation (positive about the flight overall and strongly negative about the food). The use of experiential details and judgment indicates that the experience is encoded as a real, episodic, past memory with an emotional emphasis, resulting in an overall slightly negative sentiment.
…
Dear Customer,
Experience a serene flight from Tokyo to Honolulu while enjoying a gourmet meal inspired by the renowned Chef Nobu Matsuhisa. Indulge in diverse and vibrant dishes crafted to enhance your journey.
Best regards,
</code></pre>
    <figure class="mediaobject"><img alt="Figure 6.8: An engaging customer image to match the personalized message" src="../Images/B32304_06_8.png"/></figure>
    <p class="packt_figref">Figure 6.8: An engaging customer image to match the personalized message</p>
    <p class="normal">We can see<a id="_idIndexMarker461"/> that from a user perspective, our GenAISys is running seamlessly. We are giving the user the illusion that everything in generative AI is simple. Of course, in a real-life project, we would have to spend resources trying all types of texts, finding the limitations, and solving the issues to cover edge cases and refine outputs. Let’s now sum up our journey in this chapter and take the GenAISys to yet another level.</p>
    <h1 class="heading-1" id="_idParaDest-179"><a id="_idTextAnchor186"/>Summary</h1>
    <p class="normal">This chapter pushed our GenAISys far beyond classical AI, into the realm of meta-cognitive, self-reflective reasoning. We defined a pragmatic memory model combining primary categories (short-term, long-term, reality, fiction, and time) with semantic and episodic tags, then layered intellectual, emotional, and physical dimensions on top. Using this framework, we built a six-step CoT agent that decodes each review segment, tags memory categories, quantifies sentiment, and produces an overall cognitive score. Based on the cognitive profile and sentiment score, the agent generated personalized promotional text and created a matching DALL-E image—then wrapped everything into a polished customer message.</p>
    <p class="normal">A new drop-down widget now lets users choose <strong class="screenText">None</strong>, <strong class="screenText">Analysis</strong>, or <strong class="screenText">Generation</strong>, making sophisticated reasoning tasks a single-click experience. Behind the scenes, the AI agent routes requests to either a standalone memory analysis or the full consumer-memory workflow. We finally demonstrated the agent on a flight review, showing it can analyze, score, and respond to any text—extending GenAISys from hospitality into broader customer service scenarios.</p>
    <p class="normal">With these advances, the GenAISys is ready for real-time, production-grade decision-making. The next chapter will focus on scaling the functionality of our GenAISys architecture for immediate, high-throughput AI operations.</p>
    <h1 class="heading-1" id="_idParaDest-180"><a id="_idTextAnchor187"/>Questions</h1>
    <ol>
      <li class="numberedList" value="1">Emotional memory is a key factor in e-marketing. (True or False)</li>
      <li class="numberedList">OpenAI’s o3 is a reasoning model that can perform complex tasks. (True or False)</li>
      <li class="numberedList">Long-term memory does not include emotional factors. (True or False)</li>
      <li class="numberedList">A generative AI model cannot analyze complex memory structures. (True or False)</li>
      <li class="numberedList">A generative AI model can not only analyze sentiments but also provide numerical scores between 0 and 1. (True or False)</li>
      <li class="numberedList">A Pinecone index can produce complex instructions based on system queries. (True or False)</li>
      <li class="numberedList">A thread-of-reasoning agent can think through complex prompts and perform multiple coordinated tasks. (True or False)</li>
      <li class="numberedList">A thread-of-reasoning scenario can be triggered with a user input. (True or False)</li>
      <li class="numberedList">A reasoning agent can process reviews from sites such as TripAdvisor and generate custom messages. (True or False)</li>
      <li class="numberedList">A generative AI system cannot process thread-of-reasoning agents. (True or False)</li>
    </ol>
    <h1 class="heading-1" id="_idParaDest-181"><a id="_idTextAnchor188"/>References</h1>
    <ul>
      <li class="bulletList">Brandt, Denise, and Ilja Nieuwenhuis. 2017. Understanding Memory in Advertising. Nielsen. February. <a href="https://www.nielsen.com/insights/2017/understanding-memory-in-advertising/"><span class="url">https://www.nielsen.com/insights/2017/understanding-memory-in-advertising/</span></a><a href="https://www.nielsen.com/insights/2017/understanding-memory-in-advertising/ "/></li>
      <li class="bulletList">Nielsen Homepage: <a href="https://www.nielsen.com/"><span class="url">https://www.nielsen.com/</span></a></li>
      <li class="bulletList">Nicks, Guillaume, and Yannick Carriou. 2016. Emotion, Attention and Memory in Advertising. Ipsos Knowledge Centre. <a href="https://www.ipsos.com/sites/default/files/2017-07/Emotion-Attention-and-Memory-in-Ads.pdf"><span class="url">https://www.ipsos.com/sites/default/files/2017-07/Emotion-Attention-and-Memory-in-Ads.pdf</span></a></li>
      <li class="bulletList">Ipsos Homepage: <a href="https://www.ipsos.com/"><span class="url">https://www.ipsos.com/</span></a></li>
      <li class="bulletList">OpenAI. 2024. OpenAI o3 System Card: A Comprehensive Evaluation of the o3 Model Series, Outlining Advancements in Safety, Reasoning, and Robustness. OpenAI. <a href="https://openai.com/index/o3-mini-system-card/"><span class="url">https://openai.com/index/o3-mini-system-card/</span></a></li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-182"><a id="_idTextAnchor189"/>Further reading</h1>
    <ul>
      <li class="bulletList">Woodside, Arch G., Sanjay Sood, and Kimberly E. Miller. 2008. “When Consumers and Brands Talk: Storytelling Theory and Research in Psychology and Marketing.” Psychology &amp; Marketing 25 (2): 97–145. <a href="https://www.researchgate.net/publication/229889043_When_consumers_and_brands_talk_Storytelling_theory_and_research_in_psychology_and_marketing"><span class="url">https://www.researchgate.net/publication/229889043_When_consumers_and_brands_talk_Storytelling_theory_and_research_in_psychology_and_marketing</span></a></li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-183"><a id="_idTextAnchor190"/>Subscribe for a Free eBook</h1>
    <p class="normal">New frameworks, evolving architectures, research drops, production breakdowns—<em class="italic">AI_Distilled</em> filters the noise into a weekly briefing for engineers and researchers working hands-on with LLMs and GenAI systems. Subscribe now and receive a free eBook, along with weekly insights that help you stay focused and informed.</p>
    <p class="normal">Subscribe at <a href="Chapter_6.xhtml"><span class="url">https://packt.link/TRO5B</span></a> or scan the QR code below.</p>
    <p class="normal"><img alt="" src="../Images/Newsletter_QR_Code1.png"/></p>
  </div>
</body></html>