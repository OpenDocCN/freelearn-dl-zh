<html><head></head><body>
<div id="_idContainer185">
<h1 class="chapter-number" id="_idParaDest-194"><a id="_idTextAnchor207"/><span class="koboSpan" id="kobo.1.1">11</span></h1>
<h1 id="_idParaDest-195"><a id="_idTextAnchor208"/><span class="koboSpan" id="kobo.2.1">Evaluating and Monitoring Models with Amazon Bedrock</span></h1>
<p><span class="koboSpan" id="kobo.3.1">To work with the best-performing model for your generative AI solution, you need to evaluate the models that are available to you. </span><span class="koboSpan" id="kobo.3.2">This chapter explores various techniques to assess the performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">different models.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">The chapter introduces two primary evaluation methods provided by Amazon Bedrock: automatic model evaluation and human evaluation. </span><span class="koboSpan" id="kobo.5.2">We will do a detailed walk-through of these two methods. </span><span class="koboSpan" id="kobo.5.3">In addition, we will look at open source tools such as </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">Foundation Models Evaluation</span></strong><span class="koboSpan" id="kobo.7.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.8.1">FMEval</span></strong><span class="koboSpan" id="kobo.9.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.10.1">RAG Assessment</span></strong><span class="koboSpan" id="kobo.11.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.12.1">Ragas</span></strong><span class="koboSpan" id="kobo.13.1">) for model</span><a id="_idIndexMarker896"/><span class="koboSpan" id="kobo.14.1"> evaluation</span><a id="_idIndexMarker897"/><span class="koboSpan" id="kobo.15.1"> and evaluating </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">RAG pipelines.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1">The second part of the chapter goes into monitoring. </span><span class="koboSpan" id="kobo.17.2">We will explore how to leverage Amazon CloudWatch for real-time monitoring of model performance, latency, and token counts. </span><span class="koboSpan" id="kobo.17.3">We will further look at model invocation logging to capture requests, responses, and metadata for model invocations. </span><span class="koboSpan" id="kobo.17.4">Furthermore, we will highlight the integration of Amazon Bedrock with AWS CloudTrail for auditing API calls and with Amazon EventBridge for event-driven monitoring and automation of model </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">customization jobs.</span></span></p>
<p><span class="koboSpan" id="kobo.19.1">By the end of this chapter, you will be able to understand how to evaluate FMs and monitor </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">their performance.</span></span></p>
<p><span class="koboSpan" id="kobo.21.1">Here are the key topics that will be covered in </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">this chapter:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.23.1">Evaluating models</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Monitoring </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">Amazon Bedroc</span><a id="_idTextAnchor209"/><a id="_idTextAnchor210"/><a id="_idTextAnchor211"/><span class="koboSpan" id="kobo.26.1">k</span></span></li>
</ul>
<h1 id="_idParaDest-196"><a id="_idTextAnchor212"/><span class="koboSpan" id="kobo.27.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.28.1">This chapter requires you to have access to an AWS account. </span><span class="koboSpan" id="kobo.28.2">If you don’t have it already, you can go to </span><a href="https://aws.amazon.com/getting-started/"><span class="koboSpan" id="kobo.29.1">https://aws.amazon.com/getting-started/</span></a><span class="koboSpan" id="kobo.30.1"> and create an </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">AWS account.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">Secondly, you will need to set up AWS Python SDK (</span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">Boto3): </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html"><span class="No-Break"><span class="koboSpan" id="kobo.34.1">https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html</span></span></a></p>
<p><span class="koboSpan" id="kobo.35.1">You can carry out the Python setup in any way: install it on your local machine, or use AWS Cloud9, or utilize AWS Lambda, or leverage </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">Amazon SageMaker.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.37.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.38.1">There will be a charge associated with the invocation and customization of the FMs of Amazon Bedrock. </span><span class="koboSpan" id="kobo.38.2">Please refer to </span><a href="https://aws.amazon.com/bedrock/pricing/"><span class="koboSpan" id="kobo.39.1">https://aws.amazon.com/bedrock/pricing/</span></a><span class="koboSpan" id="kobo.40.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">learn more.</span></span></p>
<h1 id="_idParaDest-197"><a id="_idTextAnchor213"/><span class="koboSpan" id="kobo.42.1">Evaluating models</span></h1>
<p><span class="koboSpan" id="kobo.43.1">By now, we have</span><a id="_idIndexMarker898"/><span class="koboSpan" id="kobo.44.1"> gained a comprehensive understanding of Amazon Bedrock’s capabilities, exploring techniques such as prompt engineering, RAG, and model customization. </span><span class="koboSpan" id="kobo.44.2">We have also examined various architectural design patterns and analyzed the responses generated by different models. </span><span class="koboSpan" id="kobo.44.3">With the vast selection of FMs available within Amazon Bedrock, identifying the most suitable option for your specific use case and business requirements can be challenging. </span><span class="koboSpan" id="kobo.44.4">To address this, we will now focus on the topic of model evaluation and how to compare the outputs of different models to choose the one that best meets the needs of your application and business. </span><span class="koboSpan" id="kobo.44.5">This is a critical initial phase in implementing any generative </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">AI solution.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer164">
<span class="koboSpan" id="kobo.46.1"><img alt="Figure 11.1 – The generative AI life cycle" src="image/B22045_11_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.47.1">Figure 11.1 – The generative AI life cycle</span></p>
<p><span class="koboSpan" id="kobo.48.1">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.49.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.50.1">.1</span></em><span class="koboSpan" id="kobo.51.1">, after defining the specific business use case that you’re aiming to solve with generative AI, the </span><strong class="bold"><span class="koboSpan" id="kobo.52.1">choice</span></strong><span class="koboSpan" id="kobo.53.1"> stage</span><a id="_idIndexMarker899"/><span class="koboSpan" id="kobo.54.1"> involves both selecting potential models from the available options and rigorously evaluating these candidate models. </span><span class="koboSpan" id="kobo.54.2">Following </span><a id="_idIndexMarker900"/><span class="koboSpan" id="kobo.55.1">this, the </span><strong class="bold"><span class="koboSpan" id="kobo.56.1">responsible AI</span></strong><span class="koboSpan" id="kobo.57.1"> stage focuses on ensuring data privacy and security, as well as implementing guardrails for responsible model behavior, which we will cover in </span><a href="B22045_12.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.58.1">Chapter 12</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.59.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">Before talking about model evaluation, one quick way to compare the responses from the models on Amazon</span><a id="_idIndexMarker901"/><span class="koboSpan" id="kobo.61.1"> Bedrock’s </span><strong class="bold"><span class="koboSpan" id="kobo.62.1">Chat playground</span></strong><span class="koboSpan" id="kobo.63.1"> screen is to use the </span><strong class="bold"><span class="koboSpan" id="kobo.64.1">Compare </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.65.1">mode</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.66.1"> toggle.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer165">
<span class="koboSpan" id="kobo.67.1"><img alt="Figure 11.2 – Compare mode in Bedrock’s Chat playground" src="image/B22045_11_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.68.1">Figure 11.2 – Compare mode in Bedrock’s Chat playground</span></p>
<div>
<div class="IMG---Figure" id="_idContainer166">
<span class="koboSpan" id="kobo.69.1"><img alt="Figure 11.3 – Model metrics in Compare mode" src="image/B22045_11_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.70.1">Figure 11.3 – Model metrics in Compare mode</span></p>
<p><span class="koboSpan" id="kobo.71.1">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.72.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.73.1">.2</span></em><span class="koboSpan" id="kobo.74.1">, you can enable compare mode in </span><strong class="bold"><span class="koboSpan" id="kobo.75.1">Chat playground</span></strong><span class="koboSpan" id="kobo.76.1"> and add up to three models to view a side-by-side comparison of model responses to the same prompt. </span><span class="koboSpan" id="kobo.76.2">In addition, you can view the metrics of each of the selected models (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.77.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.78.1">.3</span></em><span class="koboSpan" id="kobo.79.1">) and compare latency, input token count, output token count, and the associated cost. </span><span class="koboSpan" id="kobo.79.2">We will</span><a id="_idIndexMarker902"/><span class="koboSpan" id="kobo.80.1"> cover the model metrics in depth in the </span><em class="italic"><span class="koboSpan" id="kobo.81.1">Monitoring Amazon </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.82.1">Bedrock</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.83.1"> section.</span></span></p>
<h2 id="_idParaDest-198"><a id="_idTextAnchor214"/><span class="koboSpan" id="kobo.84.1">Using Amazon Bedrock</span></h2>
<p><span class="koboSpan" id="kobo.85.1">Within Amazon</span><a id="_idIndexMarker903"/><span class="koboSpan" id="kobo.86.1"> Bedrock, you </span><a id="_idIndexMarker904"/><span class="koboSpan" id="kobo.87.1">can create model evaluation jobs to compare the responses from the models for use cases such as text generation, summarization, Q&amp;A, and </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.89.1">Model evaluation within Amazon Bedrock primarily consists of </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">two options:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.91.1">Automatic </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">model evaluation</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.93.1">Human evaluation</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.94.1">Let us dive deeper into both of these </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">evaluation techniques.</span></span></p>
<h2 id="_idParaDest-199"><a id="_idTextAnchor215"/><span class="koboSpan" id="kobo.96.1">Automatic model evaluation</span></h2>
<p><span class="koboSpan" id="kobo.97.1">With automatic</span><a id="_idIndexMarker905"/><span class="koboSpan" id="kobo.98.1"> model evaluation, an evaluation algorithm script is run behind the scenes on either Amazon Bedrock’s </span><a id="_idIndexMarker906"/><span class="koboSpan" id="kobo.99.1">provided </span><strong class="bold"><span class="koboSpan" id="kobo.100.1">built-in dataset </span></strong><span class="koboSpan" id="kobo.101.1">or on a </span><strong class="bold"><span class="koboSpan" id="kobo.102.1">custom dataset</span></strong><span class="koboSpan" id="kobo.103.1"> that you provide</span><a id="_idIndexMarker907"/><span class="koboSpan" id="kobo.104.1"> for the recommended metrics (accuracy, toxicity, and robustness). </span><span class="koboSpan" id="kobo.104.2">Let us go through the steps for creating an automatic model </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">evaluation job:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.106.1">Evaluation name</span></strong><span class="koboSpan" id="kobo.107.1">: This refers to choosing a descriptive name that accurately reflects the purpose of the job. </span><span class="koboSpan" id="kobo.107.2">This name should be unique within your AWS account in the specific </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">AWS region.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.109.1">Model selector</span></strong><span class="koboSpan" id="kobo.110.1">: Select the model that you would like to evaluate (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.111.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.112.1">.4</span></em><span class="koboSpan" id="kobo.113.1">). </span><span class="koboSpan" id="kobo.113.2">At the time of writing this book, automatic model evaluation is carried out on a </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">single model.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer167">
<span class="koboSpan" id="kobo.115.1"><img alt="Figure 11.4 – Model selector" src="image/B22045_11_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.116.1">Figure 11.4 – Model selector</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.117.1">Within </span><strong class="bold"><span class="koboSpan" id="kobo.118.1">Model selector</span></strong><span class="koboSpan" id="kobo.119.1">, you can optionally modify the inference parameters, such as </span><strong class="bold"><span class="koboSpan" id="kobo.120.1">Temperature</span></strong><span class="koboSpan" id="kobo.121.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.122.1">Top P</span></strong><span class="koboSpan" id="kobo.123.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.124.1">Response length</span></strong><span class="koboSpan" id="kobo.125.1">, and so on (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.126.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.127.1">.5</span></em><span class="koboSpan" id="kobo.128.1">). </span><span class="koboSpan" id="kobo.128.2">You can get this screen by clicking on </span><strong class="bold"><span class="koboSpan" id="kobo.129.1">Inference configuration: </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.130.1">Default update</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.132.1">Modifying the values of this inference configuration will alter the output of the model. </span><span class="koboSpan" id="kobo.132.2">To learn more</span><a id="_idIndexMarker908"/><span class="koboSpan" id="kobo.133.1"> about the inference configuration</span><a id="_idIndexMarker909"/><span class="koboSpan" id="kobo.134.1"> parameters, you can go back to </span><a href="B22045_02.xhtml#_idTextAnchor034"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.135.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.136.1"> of </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">this book.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer168">
<span class="koboSpan" id="kobo.138.1"><img alt="Figure 11.5 – Inference configuration" src="image/B22045_11_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.139.1">Figure 11.5 – Inference configuration</span></p>
<ol>
<li value="3"><strong class="bold"><span class="koboSpan" id="kobo.140.1">Task type</span></strong><span class="koboSpan" id="kobo.141.1">: Currently, the following task types are supported while using Amazon Bedrock </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">Model evaluation:</span></span><ul><li><span class="koboSpan" id="kobo.143.1">General </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">text generation</span></span></li><li><span class="No-Break"><span class="koboSpan" id="kobo.145.1">Text summarization</span></span></li><li><span class="koboSpan" id="kobo.146.1">Question </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">and answer</span></span></li><li><span class="No-Break"><span class="koboSpan" id="kobo.148.1">Text classification</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.149.1">Metrics and datasets</span></strong><span class="koboSpan" id="kobo.150.1">: There are a total of three metrics provided by Amazon Bedrock that you can choose to use to measure the performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">the model:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.152.1">Accuracy</span></strong><span class="koboSpan" id="kobo.153.1">: The capability to encode factual knowledge about the real world is a critical aspect of generative AI models. </span><span class="koboSpan" id="kobo.153.2">This metric evaluates the model’s ability </span><a id="_idIndexMarker910"/><span class="koboSpan" id="kobo.154.1">to generate outputs that align with established facts and data. </span><span class="koboSpan" id="kobo.154.2">It assesses</span><a id="_idIndexMarker911"/><span class="koboSpan" id="kobo.155.1"> the model’s understanding of the subject matter and its ability to synthesize information accurately. </span><span class="koboSpan" id="kobo.155.2">A high accuracy score indicates that the model’s outputs are reliable and can be trusted for tasks that require </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">factual precision.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.157.1">Toxicity</span></strong><span class="koboSpan" id="kobo.158.1">: This refers to the propensity of the model to generate harmful, offensive, or inappropriate content. </span><span class="koboSpan" id="kobo.158.2">This metric gauges the model’s tendency to produce outputs that could be considered unethical, biased, or discriminatory. </span><span class="koboSpan" id="kobo.158.3">Evaluating toxicity is crucial for ensuring the responsible and ethical deployment of AI systems, particularly in applications that involve direct interaction with users or the dissemination of information to </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">the public.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.160.1">Robustness</span></strong><span class="koboSpan" id="kobo.161.1">: Robustness is a measure of the model’s resilience to minor, semantic-preserving changes in the input data. </span><span class="koboSpan" id="kobo.161.2">It assesses the degree to which the model’s output remains consistent and reliable when faced with slight variations or perturbations in the input. </span><span class="koboSpan" id="kobo.161.3">This metric is particularly important for generative AI models that operate in dynamic or noisy environments, where the input data may be subject to minor fluctuations or disturbances. </span><span class="koboSpan" id="kobo.161.4">A robust model is less likely to produce erratic or inconsistent outputs in</span><a id="_idIndexMarker912"/><span class="koboSpan" id="kobo.162.1"> response to small </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">input changes.</span></span></li></ul></li>
</ol>
<p><span class="koboSpan" id="kobo.164.1">The text classification task supports the accuracy and robustness metrics, while the other tasks support all </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">three metrics.</span></span></p>
<p><span class="koboSpan" id="kobo.166.1">For every task type and metric that you choose, Amazon Bedrock provides you with built-in datasets. </span><span class="koboSpan" id="kobo.166.2">For example, for the general text generation task type, you will get the following </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">built-in datasets:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.168.1">TREX: </span></span><a href="https://hadyelsahar.github.io/t-rex/"><span class="No-Break"><span class="koboSpan" id="kobo.169.1">https://hadyelsahar.github.io/t-rex/</span></span></a></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.170.1">BOLD: </span></span><a href="https://github.com/amazon-science/bold"><span class="No-Break"><span class="koboSpan" id="kobo.171.1">https://github.com/amazon-science/bold</span></span></a></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.172.1">WikiText2: </span></span><a href="https://huggingface.co/datasets/wikitext"><span class="No-Break"><span class="koboSpan" id="kobo.173.1">https://huggingface.co/datasets/wikitext</span></span></a></li>
<li><span class="koboSpan" id="kobo.174.1">English </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1">Wikipedia: </span></span><a href="https://en.wikipedia.org/wiki/Wikipedia:Database_download"><span class="No-Break"><span class="koboSpan" id="kobo.176.1">https://en.wikipedia.org/wiki/Wikipedia:Database_download</span></span></a></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.177.1">RealToxicityPrompts: </span></span><a href="https://github.com/allenai/real-toxicity-prompts"><span class="No-Break"><span class="koboSpan" id="kobo.178.1">https://github.com/allenai/real-toxicity-prompts</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.179.1">For a complete list of built-in datasets based on different metrics and task types, you can go </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">through </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets-builtin.html"><span class="No-Break"><span class="koboSpan" id="kobo.181.1">https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets-builtin.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.182.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.183.1">If you would like </span><a id="_idIndexMarker913"/><span class="koboSpan" id="kobo.184.1">to use your own custom dataset, it needs to be </span><em class="italic"><span class="koboSpan" id="kobo.185.1">JSON line</span></em><span class="koboSpan" id="kobo.186.1"> (</span><em class="italic"><span class="koboSpan" id="kobo.187.1">.jsonl</span></em><span class="koboSpan" id="kobo.188.1">) format. </span><span class="koboSpan" id="kobo.188.2">Each line within the dataset must be a valid JSON object and you can include up to 1,000 prompts per </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">evaluation job.</span></span></p>
<p><span class="koboSpan" id="kobo.190.1">To construct your custom prompt dataset, you’ll need to incorporate the </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">following keys:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.192.1">prompt</span></strong><span class="koboSpan" id="kobo.193.1">: This key is mandatory and serves as the input for various tasks, such as general text generation, question answering, text summarization, and classification. </span><span class="koboSpan" id="kobo.193.2">Depending on the task, the value associated with this key will vary – it could be a prompt for the model to respond to, a question to answer, text to summarize, or content </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">to classify.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.195.1">referenceResponse</span></strong><span class="koboSpan" id="kobo.196.1">: Another mandatory key, </span><strong class="source-inline"><span class="koboSpan" id="kobo.197.1">referenceResponse</span></strong><span class="koboSpan" id="kobo.198.1"> is required to provide the ground truth response against which your model’s output will be evaluated. </span><span class="koboSpan" id="kobo.198.2">For tasks such as question answering, accuracy evaluation, and robustness testing, this key will hold the correct answer or </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">expected response.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.200.1">category</span></strong><span class="koboSpan" id="kobo.201.1"> (optional): If you wish to generate evaluation scores that are categorized by specific criteria, you can leverage the </span><strong class="source-inline"><span class="koboSpan" id="kobo.202.1">category</span></strong><span class="koboSpan" id="kobo.203.1"> key. </span><span class="koboSpan" id="kobo.203.2">This optional key allows you to group prompts and their corresponding reference responses, enabling a more granular analysis of your model’s performance across different domains </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">or categories.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.205.1">To illustrate the </span><a id="_idIndexMarker914"/><span class="koboSpan" id="kobo.206.1">usage of these keys, consider the following example for a question </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">answering task:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.208.1">
{"prompt":"What is the process that converts raw materials into finished goods?", "category":"Manufacturing", "referenceResponse":"Manufacturing"}
{"prompt":"What is the study of methods to improve workplace efficiency?", "category":"Manufacturing", "referenceResponse":"Industrial Engineering"}
{"prompt":"What is the assembly of parts into a final product?", "category":"Manufacturing", "referenceResponse":"Assembly"}
{"prompt":"A computerized system that monitors and controls production processes is called", "category":"Manufacturing", "referenceResponse":"SCADA"}
{"prompt":"A system that minimizes waste and maximizes efficiency is called", "category":"Manufacturing", "referenceResponse":"Lean Manufacturing"}</span></pre>
<p><span class="koboSpan" id="kobo.209.1">In this JSON line, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.210.1">prompt</span></strong><span class="koboSpan" id="kobo.211.1"> key contains the </span><strong class="source-inline"><span class="koboSpan" id="kobo.212.1">What is the process that converts raw materials into finished goods?</span></strong><span class="koboSpan" id="kobo.213.1"> question, while the </span><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">referenceResponse</span></strong><span class="koboSpan" id="kobo.215.1"> key holds the correct answer, </span><strong class="source-inline"><span class="koboSpan" id="kobo.216.1">Manufacturing</span></strong><span class="koboSpan" id="kobo.217.1">. </span><span class="koboSpan" id="kobo.217.2">Additionally, the category key is set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">Manufacturing</span></strong><span class="koboSpan" id="kobo.219.1">, allowing you to group this prompt and response with others related </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">to manufacturing.</span></span></p>
<p><span class="koboSpan" id="kobo.221.1">Once you have created a custom prompt dataset, you will need to store the dataset file in an Amazon S3 bucket and specify the correct S3 path (such as </span><strong class="bold"><span class="koboSpan" id="kobo.222.1">s3://test/data/</span></strong><span class="koboSpan" id="kobo.223.1">) when creating the model evaluation job (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.224.1">Figure 11</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.225.1">.6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">).</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer169">
<span class="koboSpan" id="kobo.227.1"><img alt="Figure 11.6 – Choosing a prompt dataset" src="image/B22045_11_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.228.1">Figure 11.6 – Choosing a prompt dataset</span></p>
<p><span class="koboSpan" id="kobo.229.1">Please note that the S3 </span><a id="_idIndexMarker915"/><span class="koboSpan" id="kobo.230.1">bucket should have the </span><a id="_idIndexMarker916"/><span class="koboSpan" id="kobo.231.1">following </span><strong class="bold"><span class="koboSpan" id="kobo.232.1">Cross-Origin Resource Sharing</span></strong><span class="koboSpan" id="kobo.233.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.234.1">CORS</span></strong><span class="koboSpan" id="kobo.235.1">) </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">policy attached:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.237.1">
[{
"AllowedHeaders": ["*"],
"AllowedMethods": ["GET","POST","PUT","DELETE"],
"AllowedOrigins": ["*"],
"ExposeHeaders": ["Access-Control-Allow-Origin"]
}]</span></pre>
<p><span class="koboSpan" id="kobo.238.1">The CORS policy is a set of rules that specify which origins (domains or websites) are allowed to access the S3 bucket. </span><span class="koboSpan" id="kobo.238.2">To learn more about CORS, you can </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">check </span></span><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html"><span class="No-Break"><span class="koboSpan" id="kobo.240.1">https://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.241.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.242.1">By meticulously crafting your custom prompt dataset, you can ensure that your LLMs are thoroughly evaluated against a diverse range of scenarios, covering various tasks, domains, and </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">complexity levels.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer170">
<span class="koboSpan" id="kobo.244.1"><img alt="Figure 11.7 – Metrics and datasets" src="image/B22045_11_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.245.1">Figure 11.7 – Metrics and datasets</span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.246.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.247.1">.7</span></em><span class="koboSpan" id="kobo.248.1"> depicts </span><a id="_idIndexMarker917"/><span class="koboSpan" id="kobo.249.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.250.1">Metrics and Datasets</span></strong><span class="koboSpan" id="kobo.251.1"> options for the general text generation </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">task type.</span></span></p>
<p><span class="koboSpan" id="kobo.253.1">Let us look at the other parameters that you can specify while creating the model </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">evaluation job:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.255.1">Evaluation results</span></strong><span class="koboSpan" id="kobo.256.1">: Here, you</span><a id="_idIndexMarker918"/><span class="koboSpan" id="kobo.257.1"> can specify the S3 path where the results of the evaluation job should be stored. </span><span class="koboSpan" id="kobo.257.2">We will cover the evaluation results in the </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">next section.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.259.1">IAM role and KMS key</span></strong><span class="koboSpan" id="kobo.260.1">: Certain permissions are required to perform actions such as accessing data from an S3 bucket or storing the evaluation results. </span><span class="koboSpan" id="kobo.260.2">Here is the policy that is needed, at minimum, for an automatic model </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">evaluation job:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.262.1">
{</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.263.1">
    "Version": "2012-10-17",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.264.1">
    "Statement": [</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.265.1">
        {</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.266.1">
            "Sid": "BedrockConsole",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.267.1">
            "Effect": "Allow",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.268.1">
            "Action": [</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.269.1">
               "bedrock:CreateEvaluationJob",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.270.1">
               "bedrock:GetEvaluationJob",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.271.1">
               "bedrock:ListEvaluationJobs",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.272.1">
               "bedrock:StopEvaluationJob",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.273.1">
               "bedrock:GetCustomModel",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.274.1">
               "bedrock:ListCustomModels",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.275.1">
               "bedrock:CreateProvisionedModel</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.276.1">
Throughput",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.277.1">
               "bedrock:UpdateProvisionedModel</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.278.1">
Throughput",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.279.1">
               "bedrock:GetProvisionedModel</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.280.1">
Throughput",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.281.1">
               "bedrock:ListProvisionedModel</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.282.1">
Throughputs",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.283.1">
               "bedrock:ListTagsForResource",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.284.1">
               "bedrock:UntagResource",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.285.1">
               "bedrock:TagResource"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.286.1">
            ],</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.287.1">
            "Resource": "*"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.288.1">
        },</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.289.1">
        {</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.290.1">
            "Sid": "AllowConsoleS3AccessForModelEvaluation",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.291.1">
            "Effect": "Allow",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.292.1">
            "Action": [</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.293.1">
              "s3:GetObject",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.294.1">
              "s3:GetBucketCORS",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.295.1">
              "s3:ListBucket",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.296.1">
              "s3:ListBucketVersions",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.297.1">
              "s3:GetBucketLocation"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.298.1">
            ],</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.299.1">
            "Resource": "*"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.300.1">
        }</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.301.1">
    ]</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.302.1">
}</span></pre></li>
</ul>
<p><span class="koboSpan" id="kobo.303.1">You can find details on the</span><a id="_idIndexMarker919"/><span class="koboSpan" id="kobo.304.1"> permissions needed for a model evaluation job </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">at </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security.html?icmpid=docs_bedrock_help_panel_model_evaluation"><span class="No-Break"><span class="koboSpan" id="kobo.306.1">https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security.html?icmpid=docs_bedrock_help_panel_model_evaluation</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.307.1">.</span></span></p>
<h2 id="_idParaDest-200"><a id="_idTextAnchor216"/><span class="koboSpan" id="kobo.308.1">Model evaluation results</span></h2>
<p><span class="koboSpan" id="kobo.309.1">Once you start the </span><a id="_idIndexMarker920"/><span class="koboSpan" id="kobo.310.1">model evaluation job, you can view the results for each of the metrics as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.311.1">Figure 11</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.312.1">.8</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer171">
<span class="koboSpan" id="kobo.314.1"><img alt="Figure 11.8 – An evaluation summary" src="image/B22045_11_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.315.1">Figure 11.8 – An evaluation summary</span></p>
<p><span class="koboSpan" id="kobo.316.1">In addition, the metrics results are stored in the S3 bucket that you have specified, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.317.1">Figure 11</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.318.1">.9</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer172">
<span class="koboSpan" id="kobo.320.1"><img alt="Figure 11.9 – Metrics results in the S3 bucket" src="image/B22045_11_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.321.1">Figure 11.9 – Metrics results in the S3 bucket</span></p>
<p><span class="koboSpan" id="kobo.322.1">Let us understand how the evaluation is performed for each of the </span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">task types.</span></span></p>
<h3><span class="koboSpan" id="kobo.324.1">Text generation</span></h3>
<p><span class="koboSpan" id="kobo.325.1">For text generation</span><a id="_idIndexMarker921"/><span class="koboSpan" id="kobo.326.1"> task type, here is how the evaluation </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">is performed:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.328.1">Accuracy</span></strong><span class="koboSpan" id="kobo.329.1">: This metric is evaluated using the </span><strong class="bold"><span class="koboSpan" id="kobo.330.1">Real World Knowledge</span></strong><span class="koboSpan" id="kobo.331.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.332.1">RWK</span></strong><span class="koboSpan" id="kobo.333.1">) score, which </span><a id="_idIndexMarker922"/><span class="koboSpan" id="kobo.334.1">assesses the model’s ability to understand the real world. </span><span class="koboSpan" id="kobo.334.2">The RWK score measures the extent to which a language model can produce output that is consistent with real-world facts and common sense. </span><span class="koboSpan" id="kobo.334.3">It assesses the model’s ability to reason about the physical world, understand social norms, and avoid generating nonsensical or contradictory statements. </span><span class="koboSpan" id="kobo.334.4">A high RWK score indicates that the model is </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">performing accurately.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.336.1">Robustness</span></strong><span class="koboSpan" id="kobo.337.1">: Semantic robustness is</span><a id="_idIndexMarker923"/><span class="koboSpan" id="kobo.338.1"> the metric used to measure robustness in this task type. </span><span class="koboSpan" id="kobo.338.2">It is calculated using the word error rate, which quantifies how much the model’s output changes in response to minor, semantic-preserving perturbations in the input. </span><span class="koboSpan" id="kobo.338.3">A low semantic robustness score signifies that the model is performing well, as it is robust to </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">such perturbations.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.340.1">Toxicity</span></strong><span class="koboSpan" id="kobo.341.1">: This metric is calculated using the detoxify algorithm (</span><a href="https://github.com/unitaryai/detoxify"><span class="koboSpan" id="kobo.342.1">https://github.com/unitaryai/detoxify</span></a><span class="koboSpan" id="kobo.343.1">), which measures the presence of toxic content in the model’s output. </span><span class="koboSpan" id="kobo.343.2">A low toxicity value indicates that the selected model is not</span><a id="_idIndexMarker924"/><span class="koboSpan" id="kobo.344.1"> generating a significant amount of harmful or </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">offensive content.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.346.1">Text summarization</span></h3>
<p><span class="koboSpan" id="kobo.347.1">For text summarization </span><a id="_idIndexMarker925"/><span class="koboSpan" id="kobo.348.1">task type, here is how the evaluation </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">is performed:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.350.1">Accuracy</span></strong><span class="koboSpan" id="kobo.351.1">: The BERTScore is used to evaluate accuracy in this task type. </span><span class="koboSpan" id="kobo.351.2">It is calculated using pre-trained contextual embeddings from BERT models and matches words in candidate and reference sentences by </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">cosine similarity.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.353.1">Robustness</span></strong><span class="koboSpan" id="kobo.354.1">: This metric is expressed as a percentage and is calculated by taking the difference between the BERTScores of a perturbed prompt and the original prompt, which is then divided by the BERTScore of the original prompt and multiplied by 100. </span><span class="koboSpan" id="kobo.354.2">The lower the score, the more robust the selected </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">model is.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.356.1">Toxicity</span></strong><span class="koboSpan" id="kobo.357.1">: As with the general text generation task type, the detoxify algorithm is used to calculate the toxicity of the model’s output, with a low value indicating minimal toxic </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">content generation.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.359.1">Question and answer</span></h3>
<p><span class="koboSpan" id="kobo.360.1">For question and answer </span><a id="_idIndexMarker926"/><span class="koboSpan" id="kobo.361.1">task type, here is how the evaluation </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">is performed:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.363.1">Accuracy</span></strong><span class="koboSpan" id="kobo.364.1">: The F1 score is used to evaluate accuracy in this task type. </span><span class="koboSpan" id="kobo.364.2">It is calculated by dividing the precision score (the ratio of correct predictions to all predictions) by the recall score (the ratio of correct predictions to the total number of relevant predictions). </span><span class="koboSpan" id="kobo.364.3">Higher F1 scores indicate </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">better performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.366.1">Robustness</span></strong><span class="koboSpan" id="kobo.367.1">: This metric is expressed as a percentage and is calculated by taking the difference between the F1 scores of a perturbed prompt and the original prompt, which is then divided by the F1 score of the original prompt and multiplied by 100. </span><span class="koboSpan" id="kobo.367.2">A lower score indicates that the selected model is </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">more robust.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.369.1">Toxicity</span></strong><span class="koboSpan" id="kobo.370.1">: As with the other task types, the detoxify algorithm is used to calculate the toxicity of the model’s output, with a low value indicating minimal toxic </span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">content generation.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.372.1">Text classification</span></h3>
<p><span class="koboSpan" id="kobo.373.1">For text classification</span><a id="_idIndexMarker927"/><span class="koboSpan" id="kobo.374.1"> task type, here is how the evaluation </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">is performed:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.376.1">Accuracy</span></strong><span class="koboSpan" id="kobo.377.1">: In this task type, accuracy is calculated by comparing the predicted class to its ground truth label. </span><span class="koboSpan" id="kobo.377.2">A higher accuracy score indicates that the model is correctly classifying text based on the provided ground </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">truth labels.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.379.1">Robustness</span></strong><span class="koboSpan" id="kobo.380.1">: This metric is expressed as a percentage and is calculated by taking the difference between the classification accuracy scores of a perturbed prompt and the original prompt, which is then divided by the classification accuracy score of the original prompt and multiplied by 100. </span><span class="koboSpan" id="kobo.380.2">A lower score indicates that the selected model is </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">more robust.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.382.1">Let us analyze the output of the accuracy and robustness metrics for the built-in dataset from </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">T-Rex: (</span></span><a href="https://hadyelsahar.github.io/t-rex/"><span class="No-Break"><span class="koboSpan" id="kobo.384.1">https://hadyelsahar.github.io/t-rex/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.385.1">):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.386.1">
{"automatedEvaluationResult":{"scores":[{"metricName":"Accuracy","result":1},{"metricName":"Robustness","result":0.0828}]},"inputRecord":{"prompt":"al-Hira is the capital of","referenceResponse":"Lakhmid"},"modelResponses":[{"response":" Al-Hira was an ancient city in Mesopotamia located south of what is now Kufa in modern-day Iraq. </span><span class="koboSpan" id="kobo.386.2">It served as the capital of the Arab Lakhmids from the 3rd to the 6th century CE.\n\nSome key facts about al-Hira:\n\n- It was founded in the 3rd century CE and served as the capital of the Lakhmids, who were Arab vassals of the Sassanian Persian Empire. </span><span class="koboSpan" id="kobo.386.3">\n\n- Under the leadership of the Lakhmid kings, al-Hira flourished as a center of Arab culture and politics in pre-Islamic Arabia. </span><span class="koboSpan" id="kobo.386.4">It was a major center of Nestorian Christianity in the region.\n\n- The city was located along important trade routes linking Mesopotamia to the Arabian peninsula. </span><span class="koboSpan" id="kobo.386.5">Its markets attracted merchants from throughout Arabia and beyond.\n\n- Al-Hira and the Lakhmids were defeated by the Sassanians in 602 CE. </span><span class="koboSpan" id="kobo.386.6">The city subsequently went into decline and was eventually abandoned. </span><span class="koboSpan" id="kobo.386.7">\n\n- The ruins of al-Hira are located about 94 km south of modern-day Baghdad, Iraq. </span><span class="koboSpan" id="kobo.386.8">Sections of its walls and some buildings have been excavated by archaeologists.\n\nSo in summary, al-Hira functioned as the capital of the Arab Lakhmids kingdom for several centuries until its downfall in the early 7th century CE. </span><span class="koboSpan" id="kobo.386.9">Its ruins stand as an","modelIdentifier":"anthropic.claude-v2"}]}</span></pre>
<p><span class="koboSpan" id="kobo.387.1">The output shows that a prompt (</span><strong class="source-inline"><span class="koboSpan" id="kobo.388.1">al-Hira is the capital of</span></strong><span class="koboSpan" id="kobo.389.1">) is provided to the Anthropic Claude v2 model, and that the model’s response (</span><strong class="source-inline"><span class="koboSpan" id="kobo.390.1">Al-Hira was an ancient city in Mesopotamia...</span></strong><span class="koboSpan" id="kobo.391.1">) is assessed against a reference response (</span><strong class="source-inline"><span class="koboSpan" id="kobo.392.1">Lakhmid</span></strong><span class="koboSpan" id="kobo.393.1">). </span><span class="koboSpan" id="kobo.393.2">The</span><a id="_idIndexMarker928"/><span class="koboSpan" id="kobo.394.1"> evaluation computes scores for metrics such as accuracy and robustness, providing insights into the model’s performance on this </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">specific input.</span></span></p>
<h2 id="_idParaDest-201"><a id="_idTextAnchor217"/><span class="koboSpan" id="kobo.396.1">Using human evaluation</span></h2>
<p><span class="koboSpan" id="kobo.397.1">Human evaluation </span><a id="_idIndexMarker929"/><span class="koboSpan" id="kobo.398.1">allows you to incorporate human input into</span><a id="_idIndexMarker930"/><span class="koboSpan" id="kobo.399.1"> the evaluation process, so the models are not only accurate but also align with real-world expectations and requirements. </span><span class="koboSpan" id="kobo.399.2">There are two types of </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">human evaluation:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.401.1">Bringing your own </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">work team</span></span></li>
<li><span class="koboSpan" id="kobo.403.1">Using an AWS-managed </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">work team</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.405.1">Bringing your own work team</span></h3>
<p><span class="koboSpan" id="kobo.406.1">Similar to automatic </span><a id="_idIndexMarker931"/><span class="koboSpan" id="kobo.407.1">model evaluation, when you choose human evaluation with your own work team, Amazon Bedrock guides you through a straightforward setup process, allowing you to select the models you want to evaluate, the task type (for example, text summarization), and the evaluation metrics. </span><span class="koboSpan" id="kobo.407.2">It also shows you how to upload your custom prompt dataset. </span><span class="koboSpan" id="kobo.407.3">Let us consider the step-by-step process for setting up human evaluation by bringing your </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">own team:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.409.1">Evaluation name</span></strong><span class="koboSpan" id="kobo.410.1">: Choose a</span><a id="_idIndexMarker932"/><span class="koboSpan" id="kobo.411.1"> descriptive name that accurately represents the purpose of the job. </span><span class="koboSpan" id="kobo.411.2">This name should be unique within your AWS account in the specific AWS region. </span><span class="koboSpan" id="kobo.411.3">Along with the name, you can optionally provide the description </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">and tags.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.413.1">Model selector</span></strong><span class="koboSpan" id="kobo.414.1">: Select the model that you would like to evaluate (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.415.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.416.1">.10</span></em><span class="koboSpan" id="kobo.417.1">). </span><span class="koboSpan" id="kobo.417.2">At the time of writing this book, human model evaluation with bringing your own team can only performed on up to two models. </span><span class="koboSpan" id="kobo.417.3">Within the model selector, you can optionally modify the inference parameters such as temperature, Top P, response length, and </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">so on.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer173">
<span class="koboSpan" id="kobo.419.1"><img alt="Figure 11.10 – The model selector" src="image/B22045_11_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.420.1">Figure 11.10 – The model selector</span></p>
<ol>
<li value="3"><strong class="bold"><span class="koboSpan" id="kobo.421.1">Task Type</span></strong><span class="koboSpan" id="kobo.422.1">: Currently, the</span><a id="_idIndexMarker933"/><span class="koboSpan" id="kobo.423.1"> following task types are supported in </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">this mode:</span></span><ul><li><span class="koboSpan" id="kobo.425.1">General </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">text</span></span><span class="No-Break"><a id="_idIndexMarker934"/></span><span class="No-Break"><span class="koboSpan" id="kobo.427.1"> generation</span></span></li><li><span class="No-Break"><span class="koboSpan" id="kobo.428.1">Text summarization</span></span></li><li><span class="koboSpan" id="kobo.429.1">Question </span><span class="No-Break"><span class="koboSpan" id="kobo.430.1">and answer</span></span></li><li><span class="No-Break"><span class="koboSpan" id="kobo.431.1">Text classification</span></span></li><li><span class="No-Break"><span class="koboSpan" id="kobo.432.1">Custom</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.433.1">The last task type of these, Custom, allows you to specify custom evaluation metrics that the human workers </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">can use.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.435.1">Based on the task type, you will see the list of evaluation metrics and rating methods that you would have to choose from, as shown in </span><em class="italic"><span class="koboSpan" id="kobo.436.1">Figures 11.11</span></em> <span class="No-Break"><span class="koboSpan" id="kobo.437.1">and </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.438.1">11.12</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.439.1">.</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer174">
<span class="koboSpan" id="kobo.440.1"><img alt="Figure 11.11 – Evaluation metrics" src="image/B22045_11_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.441.1">Figure 11.11 – Evaluation metrics</span></p>
<div>
<div class="IMG---Figure" id="_idContainer175">
<span class="koboSpan" id="kobo.442.1"><img alt="Figure 11.12 – Rating method options" src="image/B22045_11_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.443.1">Figure 11.12 – Rating method options</span></p>
<ol>
<li value="4"><strong class="bold"><span class="koboSpan" id="kobo.444.1">Specifying paths</span></strong><span class="koboSpan" id="kobo.445.1">: Next, you will need to specify the s3 path to your custom prompt dataset. </span><span class="koboSpan" id="kobo.445.2">As we have seen in the previous subsection, a custom prompt dataset needs to be in the </span><em class="italic"><span class="koboSpan" id="kobo.446.1">.jsonl</span></em><span class="koboSpan" id="kobo.447.1"> format. </span><span class="koboSpan" id="kobo.447.2">Here is an example of the custom </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">prompt dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.449.1">
{"prompt":"What is the process that converts raw materials into finished goods?", "category":"Manufacturing", "referenceResponse":"Manufacturing"}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.450.1">
{"prompt":"What is the study of methods to improve workplace efficiency?", "category":"Manufacturing", "referenceResponse":"Industrial Engineering"}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.451.1">
{"prompt":"What is the assembly of parts into a final product?", "category":"Manufacturing", "referenceResponse":"Assembly"}</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.452.1">Please note that </span><a id="_idIndexMarker935"/><span class="koboSpan" id="kobo.453.1">the s3 path to your dataset</span><a id="_idIndexMarker936"/><span class="koboSpan" id="kobo.454.1"> requires you to have your </span><strong class="bold"><span class="koboSpan" id="kobo.455.1">Cross Origin Resource Sharing (CORS)</span></strong><span class="koboSpan" id="kobo.456.1"> settings configured as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.457.1">Figure 11</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.458.1">.13</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.459.1">.</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer176">
<span class="koboSpan" id="kobo.460.1"><img alt="Figure 11.13 – The CORS policy window" src="image/B22045_11_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.461.1">Figure 11.13 – The CORS policy window</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.462.1">To learn more, you can </span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">visit </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security-cors.html"><span class="No-Break"><span class="koboSpan" id="kobo.464.1">https://docs.aws.amazon.com/bedrock/latest/userguide/model-eva</span><span id="_idTextAnchor218"/><span class="koboSpan" id="kobo.465.1">luation-security-cors.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.466.1">.</span></span></p>
<ol>
<li value="5"><strong class="bold"><span class="koboSpan" id="kobo.467.1">IAM role and KMS key</span></strong><span class="koboSpan" id="kobo.468.1">: Certain </span><a id="_idIndexMarker937"/><span class="koboSpan" id="kobo.469.1">permissions are required to perform actions such as accessing data from an S3 bucket or storing the evaluation results. </span><span class="koboSpan" id="kobo.469.2">You can find more details on the IAM permissions needed for the model evaluation job </span><span class="No-Break"><span class="koboSpan" id="kobo.470.1">at </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security.html?icmpid=docs_bedrock_help_panel_model_evaluation"><span class="No-Break"><span class="koboSpan" id="kobo.471.1">https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security.html?icmpid=docs_bedrock_help_panel_model_evaluation</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.472.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.473.1">Setting up a work team</span></strong><span class="koboSpan" id="kobo.474.1">: Next, you will need to set up a work team (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.475.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.476.1">.14</span></em><span class="koboSpan" id="kobo.477.1">). </span><span class="koboSpan" id="kobo.477.2">This involves inviting the appropriate team members. </span><span class="koboSpan" id="kobo.477.3">The console provides you with sample email templates for inviting new workers and existing workers, which you can use as a reference when sending out the invitations. </span><span class="koboSpan" id="kobo.477.4">The </span><a id="_idIndexMarker938"/><span class="koboSpan" id="kobo.478.1">worker receives the link to the private worker portal where they complete the </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1">labeling task.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer177">
<span class="koboSpan" id="kobo.480.1"><img alt="Figure 11.14 – Setting up a custom work team" src="image/B22045_11_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.481.1">Figure 11.14 – Setting up a custom work team</span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.482.1">Next, you would need to specify the instructions (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.483.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.484.1">.15</span></em><span class="koboSpan" id="kobo.485.1">) of the task to the </span><a id="_idIndexMarker939"/><span class="koboSpan" id="kobo.486.1">workers. </span><span class="koboSpan" id="kobo.486.2">These instructions will be visible to the human workers in the private worker </span><a id="_idIndexMarker940"/><span class="koboSpan" id="kobo.487.1">portal where they will perform the </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1">labeling task.</span></span></li>
</ol>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer178">
<span class="koboSpan" id="kobo.489.1"><img alt="Figure 11.15 – Providing instructions to human workers" src="image/B22045_11_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.490.1">Figure 11.15 – Providing instructions to human workers</span></p>
<p><span class="koboSpan" id="kobo.491.1">After you have reviewed and created the job, the human worker team will receive an email along with the link to the portal to perform the task. </span><span class="koboSpan" id="kobo.491.2">Once the task has been completed by the workers, Amazon Bedrock will provide an evaluation report card. </span><span class="koboSpan" id="kobo.491.3">Let us understand the report card </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">in detail:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.493.1">Likert scale</span></strong><span class="koboSpan" id="kobo.494.1">: A Likert scale </span><a id="_idIndexMarker941"/><span class="koboSpan" id="kobo.495.1">allows evaluators to rate model responses on a predefined scale, typically ranging from </span><strong class="source-inline"><span class="koboSpan" id="kobo.496.1">1</span></strong><span class="koboSpan" id="kobo.497.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.498.1">5</span></strong><span class="koboSpan" id="kobo.499.1">. </span><span class="koboSpan" id="kobo.499.2">When using this method, it is essential to provide clear instructions that define the meaning of each rating point. </span><span class="koboSpan" id="kobo.499.3">For instance, a rating of </span><strong class="source-inline"><span class="koboSpan" id="kobo.500.1">1</span></strong><span class="koboSpan" id="kobo.501.1"> could indicate a poor or irrelevant response, while a rating of </span><strong class="source-inline"><span class="koboSpan" id="kobo.502.1">5</span></strong><span class="koboSpan" id="kobo.503.1"> could signify an excellent and highly relevant output. </span><span class="koboSpan" id="kobo.503.2">The results are then presented as a histogram showcasing the distribution of ratings across </span><span class="No-Break"><span class="koboSpan" id="kobo.504.1">the dataset:</span></span><ul><li><span class="koboSpan" id="kobo.505.1">Define the scale points explicitly (for example, 1 = poor, 2 = fair, 3 = good, 4 = very good, 5 = </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1">excellent)</span></span></li><li><span class="koboSpan" id="kobo.507.1">Provide clear guidelines for evaluators on how to interpret and apply </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">the scale</span></span></li><li><span class="koboSpan" id="kobo.509.1">Present the results as a histogram, allowing for easy visual interpretation of the </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">rating distribution</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.511.1">Choice buttons</span></strong><span class="koboSpan" id="kobo.512.1">: When you choose the choice buttons method, evaluators are presented with two model responses and asked to select their preferred option. </span><span class="koboSpan" id="kobo.512.2">This approach is particularly useful when comparing the performance of multiple models on the same task. </span><span class="koboSpan" id="kobo.512.3">The results are typically reported as a percentage, indicating</span><a id="_idIndexMarker942"/><span class="koboSpan" id="kobo.513.1"> the proportion of responses that evaluators preferred for </span><span class="No-Break"><span class="koboSpan" id="kobo.514.1">each model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.515.1">Ordinal rank</span></strong><span class="koboSpan" id="kobo.516.1">: The ordinal rank method, also known as </span><strong class="bold"><span class="koboSpan" id="kobo.517.1">preference rank</span></strong><span class="koboSpan" id="kobo.518.1">, requires evaluators to rank the model responses in order of preference, starting from </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">1</span></strong><span class="koboSpan" id="kobo.520.1"> (most preferred). </span><span class="koboSpan" id="kobo.520.2">This method provides a more nuanced understanding of the relative performance of different models. </span><span class="koboSpan" id="kobo.520.3">The results are presented as a histogram showing the distribution of rankings across </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">the dataset.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.522.1">Thumbs up/down</span></strong><span class="koboSpan" id="kobo.523.1">: Evaluators rate each response as acceptable or unacceptable. </span><span class="koboSpan" id="kobo.523.2">The final report showcases the percentage of responses that received a </span><strong class="bold"><span class="koboSpan" id="kobo.524.1">thumbs-up</span></strong><span class="koboSpan" id="kobo.525.1"> rating for each model, enabling a straightforward assessment </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">of acceptability.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.527.1">Another form of </span><a id="_idIndexMarker943"/><span class="koboSpan" id="kobo.528.1">human evaluation method is through an AWS-managed </span><span class="No-Break"><span class="koboSpan" id="kobo.529.1">work team.</span></span></p>
<h3><span class="koboSpan" id="kobo.530.1">Using an AWS-managed work team</span></h3>
<p><span class="koboSpan" id="kobo.531.1">If you opt for an</span><a id="_idIndexMarker944"/><span class="koboSpan" id="kobo.532.1"> AWS-managed </span><a id="_idIndexMarker945"/><span class="koboSpan" id="kobo.533.1">team, you can simply describe your model evaluation needs, including the task type, expertise level required, and approximate number of prompts. </span><span class="koboSpan" id="kobo.533.2">Based on these details, an AWS expert will then reach out to discuss your project requirements in detail, providing a custom quote and project timeline tailored to your </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">specific needs.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.535.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.536.1">.16</span></em><span class="koboSpan" id="kobo.537.1"> shows how you can create a managed workforce with all the details such as task type and </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1">expertise required.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer179">
<span class="koboSpan" id="kobo.539.1"><img alt="Figure 11.16 – AWS-managed team for model evaluation" src="image/B22045_11_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.540.1">Figure 11.16 – AWS-managed team for model evaluation</span></p>
<p><span class="koboSpan" id="kobo.541.1">An AWS-managed workforce is useful when you do not want to manage or assign tasks to your own workforce and when you require an AWS team to perform evaluations on </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">your behalf.</span></span></p>
<p><span class="koboSpan" id="kobo.543.1">Aside from using </span><a id="_idIndexMarker946"/><span class="koboSpan" id="kobo.544.1">Bedrock’s model </span><a id="_idIndexMarker947"/><span class="koboSpan" id="kobo.545.1">evaluation job, there are other open source techniques that you can utilize for model evaluation, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.546.1">fmeval</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.547.1">and Ragas.</span></span></p>
<h3><span class="koboSpan" id="kobo.548.1">FMEval</span></h3>
<p><span class="koboSpan" id="kobo.549.1">FMEval is</span><a id="_idIndexMarker948"/><span class="koboSpan" id="kobo.550.1"> the open </span><a id="_idIndexMarker949"/><span class="koboSpan" id="kobo.551.1">source library made available by AWS, which you can access </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">at </span></span><a href="https://github.com/aws/fmeval"><span class="No-Break"><span class="koboSpan" id="kobo.553.1">https://github.com/aws/fmeval</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.554.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.555.1">This library enables comprehensive evaluation of LLMs across various aspects such as accuracy, toxicity, semantic robustness, and prompt stereotyping. </span><span class="koboSpan" id="kobo.555.2">It offers a range of algorithms tailored for assessing LLMs’ performance on different tasks, ensuring a thorough understanding of their capabilities </span><span class="No-Break"><span class="koboSpan" id="kobo.556.1">and limitations.</span></span></p>
<p><span class="koboSpan" id="kobo.557.1">If you plan to use your own dataset for evaluation, you’ll need to configure a </span><strong class="source-inline"><span class="koboSpan" id="kobo.558.1">DataConfig</span></strong><span class="koboSpan" id="kobo.559.1"> object, like in the following code block. </span><span class="koboSpan" id="kobo.559.2">This object specifies the dataset name, URI, and MIME type, as well as the locations of the input prompts, target outputs, and other relevant columns. </span><span class="koboSpan" id="kobo.559.3">By customizing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.560.1">DataConfig</span></strong><span class="koboSpan" id="kobo.561.1"> object, you can tailor the evaluation </span><a id="_idIndexMarker950"/><span class="koboSpan" id="kobo.562.1">process to your specific dataset and </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">task requirements:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.564.1">
from fmeval.data_loaders.data_config import DataConfig
from fmeval.constants import MIME_TYPE_JSONLINES
from fmeval.model_runners.bedrock_model_runner import BedrockModelRunner
fmconfig = DataConfig(
    dataset_name="dataset",
    dataset_uri="dataset.jsonl",
    dataset_mime_type=MIME_TYPE_JSONLINES,
    model_input_location="question",
    target_output_location="answer",
)</span></pre>
<p><span class="koboSpan" id="kobo.565.1">The library provides a flexible </span><strong class="source-inline"><span class="koboSpan" id="kobo.566.1">ModelRunner</span></strong><span class="koboSpan" id="kobo.567.1"> interface, allowing for seamless integration with Amazon Bedrock, and is used to perform invocations on the model. </span><span class="koboSpan" id="kobo.567.2">The following code block shows how an invocation can be </span><span class="No-Break"><span class="koboSpan" id="kobo.568.1">carried out:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.569.1">
bedrock_model_runner = BedrockModelRunner(
    model_id='anthropic.claude-v2',
    output='completion',
    content_template='{"prompt": $prompt, "max_tokens_to_sample": 500}'
)</span></pre>
<p><span class="koboSpan" id="kobo.570.1">If you want to learn more about </span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1">fmeval</span></strong><span class="koboSpan" id="kobo.572.1">, you can </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">visit </span></span><a href="https://github.com/aws/fmeval/tree/main"><span class="No-Break"><span class="koboSpan" id="kobo.574.1">https://github.com/aws/fmeval/tree/main</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.575.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.576.1">In addition, you can try out </span><strong class="source-inline"><span class="koboSpan" id="kobo.577.1">fmeval</span></strong><span class="koboSpan" id="kobo.578.1"> with Amazon Bedrock. </span><span class="koboSpan" id="kobo.578.2">Here are some sample examples</span><a id="_idIndexMarker951"/><span class="koboSpan" id="kobo.579.1"> that </span><a id="_idIndexMarker952"/><span class="koboSpan" id="kobo.580.1">you can test with Anthropic </span><span class="No-Break"><span class="koboSpan" id="kobo.581.1">Claude v2:</span></span></p>
<ul>
<li><a href="https://github.com/aws/fmeval/blob/main/examples/bedrock-claude-factual-knowledge.ipynb"><span class="No-Break"><span class="koboSpan" id="kobo.582.1">https://github.com/aws/fmeval/blob/main/examples/bedrock-claude-factual-knowledge.ipynb</span></span></a></li>
<li><a href="https://github.com/aws/fmeval/blob/main/examples/bedrock-claude-summarization-accuracy.ipynb"><span class="No-Break"><span class="koboSpan" id="kobo.583.1">https://github.com/aws/fmeval/blob/main/examples/bedrock-claude-summarization-accuracy.ipynb</span></span></a></li>
</ul>
<h3><span class="koboSpan" id="kobo.584.1">Ragas</span></h3>
<p><span class="koboSpan" id="kobo.585.1">Ragas is a framework </span><a id="_idIndexMarker953"/><span class="koboSpan" id="kobo.586.1">designed to assess the performance of </span><a id="_idIndexMarker954"/><span class="koboSpan" id="kobo.587.1">your RAG pipelines, which combine language models with external data sources to enhance their output. </span><span class="koboSpan" id="kobo.587.2">It offers practical tools grounded in the latest research to analyze the text generated by your language model, giving you valuable insights into the effectiveness of your </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1">RAG pipeline.</span></span></p>
<p><span class="koboSpan" id="kobo.589.1">Here are some key features and benefits of </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">using Ragas:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.591.1">Automated evaluation metrics</span></strong><span class="koboSpan" id="kobo.592.1">: Ragas </span><a id="_idIndexMarker955"/><span class="koboSpan" id="kobo.593.1">offers a suite of automated metrics tailored specifically for assessing the quality of RAG-generated text. </span><span class="koboSpan" id="kobo.593.2">These metrics go beyond traditional measures such as perplexity and BLEU, providing a more nuanced understanding of the generated output’s coherence, relevance, and </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">factual accuracy.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.595.1">Customizable evaluation strategies</span></strong><span class="koboSpan" id="kobo.596.1">: Recognizing that every RAG pipeline is unique, Ragas allows for flexible and customizable evaluation strategies. </span><span class="koboSpan" id="kobo.596.2">You can tailor the evaluation process to align with your specific use case, data domain, and </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1">performance requirements.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.598.1">Integration with CI/CD pipelines</span></strong><span class="koboSpan" id="kobo.599.1">: Ragas is designed to integrate with </span><strong class="bold"><span class="koboSpan" id="kobo.600.1">CI/CD</span></strong><span class="koboSpan" id="kobo.601.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.602.1">Continuous Integration and Continuous Deployment</span></strong><span class="koboSpan" id="kobo.603.1">) pipelines. </span><span class="koboSpan" id="kobo.603.2">This integration</span><a id="_idIndexMarker956"/><span class="koboSpan" id="kobo.604.1"> enables continuous monitoring and evaluation of your RAG pipeline’s performance, ensuring that any deviations or regressions are promptly detected </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">and addressed.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.606.1">Interpretable insights</span></strong><span class="koboSpan" id="kobo.607.1">: Ragas generates interpretable and actionable insights, highlighting areas where your RAG pipeline excels and identifying potential weaknesses or bottlenecks. </span><span class="koboSpan" id="kobo.607.2">These insights can guide your optimization efforts, helping you refine</span><a id="_idIndexMarker957"/><span class="koboSpan" id="kobo.608.1"> and enhance your pipeline’s </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1">performance iteratively.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.610.1">Ragas provides a</span><a id="_idIndexMarker958"/><span class="koboSpan" id="kobo.611.1"> list of metrics that you can import. </span><span class="koboSpan" id="kobo.611.2">Here </span><span class="No-Break"><span class="koboSpan" id="kobo.612.1">is how:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.613.1">
from ragas.metrics import (
    context_precision,
    faithfulness,
    context_recall,
)
from ragas.metrics.critique import harmfulness
metrics = [
    faithfulness,
    context_recall,
    context_precision,
    harmfulness,
]</span></pre>
<p><span class="koboSpan" id="kobo.614.1">These metrics can then be passed to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.615.1">evaluate</span></strong><span class="koboSpan" id="kobo.616.1"> function in Ragas, along with the Bedrock model and embeddings. </span><span class="koboSpan" id="kobo.616.2">Here </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1">is how:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.618.1">
from ragas import evaluate
results = evaluate(
    df["eval"].select(range(3)),
    metrics=metrics,
    llm=bedrock_model,
    embeddings=bedrock_embeddings,
)
results</span></pre>
<p><span class="koboSpan" id="kobo.619.1">In the preceding code snippet, </span><strong class="source-inline"><span class="koboSpan" id="kobo.620.1">df</span></strong><span class="koboSpan" id="kobo.621.1"> is assumed to be a pandas DataFrame containing the data you want to evaluate. </span><span class="koboSpan" id="kobo.621.2">Note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.622.1">llm=bedrock_model</span></strong><span class="koboSpan" id="kobo.623.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.624.1">embeddings=bedrock_embeddings</span></strong><span class="koboSpan" id="kobo.625.1"> are the instances of the Bedrock and embeddings models, respectively, that we have </span><span class="No-Break"><span class="koboSpan" id="kobo.626.1">created beforehand.</span></span></p>
<p><span class="koboSpan" id="kobo.627.1">For the complete tutorial on how to use Amazon Bedrock with Ragas, you can go </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">to </span></span><a href="https://docs.ragas.io/en/stable/howtos/customisations/aws-bedrock.html"><span class="No-Break"><span class="koboSpan" id="kobo.629.1">https://docs.ragas.io/en/stable/howtos/customisations/aws-bedrock.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.630.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.631.1">Now that we have seen various techniques to perform Amazon Bedrock model evaluation, let us </span><a id="_idIndexMarker959"/><span class="koboSpan" id="kobo.632.1">look at monitoring and logging solutions integrated with </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1">Amazon Bedrock.</span></span></p>
<h1 id="_idParaDest-202"><a id="_idTextAnchor219"/><span class="koboSpan" id="kobo.634.1">Monitoring Amazon Bedrock</span></h1>
<p><span class="koboSpan" id="kobo.635.1">Monitoring the</span><a id="_idIndexMarker960"/><span class="koboSpan" id="kobo.636.1"> performance and usage of your generative AI applications is crucial for ensuring optimal functionality, maintaining security and privacy standards, and gaining insights for future enhancements. </span><span class="koboSpan" id="kobo.636.2">Amazon Bedrock seamlessly integrates with Amazon CloudWatch, CloudTrail, and EventBridge, which provides a comprehensive monitoring and </span><span class="No-Break"><span class="koboSpan" id="kobo.637.1">logging solution.</span></span></p>
<h2 id="_idParaDest-203"><a id="_idTextAnchor220"/><span class="koboSpan" id="kobo.638.1">Amazon CloudWatch</span></h2>
<p><span class="koboSpan" id="kobo.639.1">Amazon CloudWatch</span><a id="_idIndexMarker961"/><span class="koboSpan" id="kobo.640.1"> is a monitoring and observability</span><a id="_idIndexMarker962"/><span class="koboSpan" id="kobo.641.1"> service that collects and visualizes data from various AWS resources, including Amazon Bedrock. </span><span class="koboSpan" id="kobo.641.2">By leveraging CloudWatch, you can gain valuable insights into your Bedrock models’ performance so you can identify and address potential issues proactively. </span><span class="koboSpan" id="kobo.641.3">Through CloudWatch, you can track usage metrics and construct tailored dashboards for auditing purposes, ensuring transparency and accountability throughout the AI model </span><span class="No-Break"><span class="koboSpan" id="kobo.642.1">development process.</span></span></p>
<p><span class="koboSpan" id="kobo.643.1">One of the key features of using CloudWatch with Amazon Bedrock is that you can gain insights into model usage across multiple accounts and FMs within a single account. </span><span class="koboSpan" id="kobo.643.2">You can monitor critical aspects such as model invocations and token counts, so you can make informed decisions and optimize resource allocation effectively. </span><span class="koboSpan" id="kobo.643.3">If you would like to configure monitoring across multiple accounts in one or more regions, you can check the Amazon CloudWatch documentation </span><span class="No-Break"><span class="koboSpan" id="kobo.644.1">at </span></span><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Cross-Account-Methods.html"><span class="No-Break"><span class="koboSpan" id="kobo.645.1">https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Cross-Account-Methods.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.646.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.647.1">This provides all the steps that you will need to take to enable </span><span class="No-Break"><span class="koboSpan" id="kobo.648.1">this feature.</span></span></p>
<p><span class="koboSpan" id="kobo.649.1">Furthermore, Bedrock offers a feature called model </span><em class="italic"><span class="koboSpan" id="kobo.650.1">invocation logging</span></em><span class="koboSpan" id="kobo.651.1">. </span><span class="koboSpan" id="kobo.651.2">This functionality allows users to collect metadata, requests, and responses for all model invocations within the account. </span><span class="koboSpan" id="kobo.651.3">While this feature is disabled by default, you can easily enable it by going to </span><strong class="bold"><span class="koboSpan" id="kobo.652.1">Settings</span></strong><span class="koboSpan" id="kobo.653.1"> in the Bedrock console and toggling </span><strong class="bold"><span class="koboSpan" id="kobo.654.1">Model invocation logging</span></strong><span class="koboSpan" id="kobo.655.1">. </span><span class="koboSpan" id="kobo.655.2">By enabling this, you allow Bedrock to publish invocation logs for enhanced visibility </span><span class="No-Break"><span class="koboSpan" id="kobo.656.1">and analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.657.1">Let us look at how CloudWatch can be leveraged to monitor Bedrock in near real-time, utilizing metrics and logs to trigger alarms and initiate actions when predefined thresholds </span><span class="No-Break"><span class="koboSpan" id="kobo.658.1">are exceeded.</span></span></p>
<h2 id="_idParaDest-204"><a id="_idTextAnchor221"/><span class="koboSpan" id="kobo.659.1">Bedrock metrics</span></h2>
<p><span class="koboSpan" id="kobo.660.1">Amazon Bedrock’s CloudWatch</span><a id="_idIndexMarker963"/><span class="koboSpan" id="kobo.661.1"> metrics cover a wide range of performance indicators, including the number of invocations, invocation latency, invocation client and server errors, invocation throttling instances, input and output tokens, and much more. </span><span class="koboSpan" id="kobo.661.2">You can see the full list of supported metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1">at </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/monitoring-cw.html#runtime-cloudwatch-metrics"><span class="No-Break"><span class="koboSpan" id="kobo.663.1">https://docs.aws.amazon.com/bedrock/latest/userguide/monitoring-cw.html#runtime-cloudwatch-metrics</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.664.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.665.1">With these metrics, you can compare latency between different models and measure token counts to assist in purchasing provisioned throughput, as well as detect and alert for </span><span class="No-Break"><span class="koboSpan" id="kobo.666.1">throttling events.</span></span></p>
<p><span class="koboSpan" id="kobo.667.1">When you are using a chat playground, you can view these metrics after running the prompt, as </span><a id="_idIndexMarker964"/><span class="koboSpan" id="kobo.668.1">shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.669.1">Figure 11</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.670.1">.17</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.671.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer180">
<span class="koboSpan" id="kobo.672.1"><img alt="Figure 11.17 – Model metrics" src="image/B22045_11_17.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.673.1">Figure 11.17 – Model metrics</span></p>
<p><span class="koboSpan" id="kobo.674.1">In addition, you can define metric criteria, which allow you to provide specific conditions or thresholds for the model metrics. </span><span class="koboSpan" id="kobo.674.2">You can set criteria such as </span><strong class="bold"><span class="koboSpan" id="kobo.675.1">latency less than 100ms</span></strong><span class="koboSpan" id="kobo.676.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.677.1">output token count greater than 500</span></strong><span class="koboSpan" id="kobo.678.1"> based on your requirements. </span><span class="koboSpan" id="kobo.678.2">These criteria can be used to evaluate and compare the performance of different models against your desired metrics. </span><span class="koboSpan" id="kobo.678.3">When comparing multiple models, setting metric criteria helps identify which models meet or fail to meet your specified conditions, which helps in the selection of the most suitable model for your </span><span class="No-Break"><span class="koboSpan" id="kobo.679.1">use case.</span></span></p>
<p><span class="koboSpan" id="kobo.680.1">Let us also look at these metrics in the CloudWatch </span><span class="No-Break"><span class="koboSpan" id="kobo.681.1">metrics dashboard.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer181">
<span class="koboSpan" id="kobo.682.1"><img alt="Figure 11.18 – The CloudWatch metrics dashboard" src="image/B22045_11_18.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.683.1">Figure 11.18 – The CloudWatch metrics dashboard</span></p>
<p><span class="koboSpan" id="kobo.684.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.685.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.686.1">.18</span></em><span class="koboSpan" id="kobo.687.1">, you can </span><a id="_idIndexMarker965"/><span class="koboSpan" id="kobo.688.1">see the CloudWatch metrics for the Anthropic Claude 3 Sonnet model: </span><strong class="bold"><span class="koboSpan" id="kobo.689.1">Invocations</span></strong><span class="koboSpan" id="kobo.690.1"> (sample count), </span><strong class="bold"><span class="koboSpan" id="kobo.691.1">InvocationLatency</span></strong><span class="koboSpan" id="kobo.692.1"> (in milliseconds), </span><strong class="bold"><span class="koboSpan" id="kobo.693.1">OutputTokenCount</span></strong><span class="koboSpan" id="kobo.694.1"> (sample count), and </span><strong class="bold"><span class="koboSpan" id="kobo.695.1">InputTokenCount</span></strong><span class="koboSpan" id="kobo.696.1"> (sample count). </span><span class="koboSpan" id="kobo.696.2">Let us understand what these terminologies (metrics and </span><span class="No-Break"><span class="koboSpan" id="kobo.697.1">statistics) mean:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.698.1">Sample count</span></strong><span class="koboSpan" id="kobo.699.1">: This statistic represents total data points or observations recorded within a </span><span class="No-Break"><span class="koboSpan" id="kobo.700.1">specified timeframe.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.701.1">Invocations</span></strong><span class="koboSpan" id="kobo.702.1">: The metric represents the total count of requests made to </span><strong class="source-inline"><span class="koboSpan" id="kobo.703.1">Converse</span></strong><span class="koboSpan" id="kobo.704.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.705.1">ConverseStream</span></strong><span class="koboSpan" id="kobo.706.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.707.1">InvokeModel</span></strong><span class="koboSpan" id="kobo.708.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.709.1">InvokeModelWithResponseStream</span></strong><span class="koboSpan" id="kobo.710.1"> APIs within a given </span><span class="No-Break"><span class="koboSpan" id="kobo.711.1">time frame.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.712.1">InvocationLatency</span></strong><span class="koboSpan" id="kobo.713.1">: This metric refers to the delay or amount of time that has elapsed between when the invocation request is made and when the response </span><span class="No-Break"><span class="koboSpan" id="kobo.714.1">is received.</span></span></li>
</ul>
<p><strong class="bold"><span class="koboSpan" id="kobo.715.1">OutputTokenCount</span></strong><span class="koboSpan" id="kobo.716.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.717.1">InputTokenCount</span></strong><span class="koboSpan" id="kobo.718.1"> are useful metrics when you are analyzing and calculating the cost of model invocations. </span><span class="koboSpan" id="kobo.718.2">A token is essentially a small group of characters from an input prompt and the response. </span><strong class="bold"><span class="koboSpan" id="kobo.719.1">OutputTokenCount</span></strong><span class="koboSpan" id="kobo.720.1"> signifies the total count of tokens in the response provided by the model, whereas </span><strong class="bold"><span class="koboSpan" id="kobo.721.1">InputTokenCount</span></strong><span class="koboSpan" id="kobo.722.1"> signifies the total count of tokens in the input and prompt provided to </span><span class="No-Break"><span class="koboSpan" id="kobo.723.1">the model.</span></span></p>
<p><span class="koboSpan" id="kobo.724.1">To streamline </span><a id="_idIndexMarker966"/><span class="koboSpan" id="kobo.725.1">monitoring and analysis, Bedrock’s logs and metrics can be presented in a single view using CloudWatch dashboards. </span><span class="koboSpan" id="kobo.725.2">These dashboards provide a comprehensive overview of the same KPIs, including the number of invocations over time by model, invocation latency by model, and token counts for input and output. </span><span class="koboSpan" id="kobo.725.3">The following figure shows the dashboard view of the metrics in a one-week time frame for the two models, Anthropic Claude v2 and Anthropic Claude </span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">v3 Sonnet.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer182">
<span class="koboSpan" id="kobo.727.1"><img alt="Figure 11.19 – The CloudWatch dashboard" src="image/B22045_11_19.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.728.1">Figure 11.19 – The CloudWatch dashboard</span></p>
<p><span class="koboSpan" id="kobo.729.1">For organizations with multiple AWS accounts, Bedrock supports CloudWatch cross-account observability, enabling the creation of rich cross-account dashboards in monitoring</span><a id="_idIndexMarker967"/><span class="koboSpan" id="kobo.730.1"> accounts. </span><span class="koboSpan" id="kobo.730.2">This feature ensures a centralized view of performance metrics across various accounts, facilitating better oversight </span><span class="No-Break"><span class="koboSpan" id="kobo.731.1">and decision-making.</span></span></p>
<h2 id="_idParaDest-205"><a id="_idTextAnchor222"/><span class="koboSpan" id="kobo.732.1">Model invocation logging</span></h2>
<p><span class="koboSpan" id="kobo.733.1">Model invocation</span><a id="_idIndexMarker968"/><span class="koboSpan" id="kobo.734.1"> logging allows you to capture and analyze the requests and responses generated by the models, along with the metadata of all the invocation calls that are made. </span><span class="koboSpan" id="kobo.734.2">It provides a comprehensive view of how your models are utilized, enabling you to monitor their performance, identify potential issues, and optimize </span><span class="No-Break"><span class="koboSpan" id="kobo.735.1">their usage.</span></span></p>
<p><span class="koboSpan" id="kobo.736.1">Enabling model invocation logging is a straightforward process. </span><span class="koboSpan" id="kobo.736.2">You can configure it through the Amazon Bedrock console or via </span><span class="No-Break"><span class="koboSpan" id="kobo.737.1">the API.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer183">
<span class="koboSpan" id="kobo.738.1"><img alt="Figure 11.20 – Enabling model invocation logging" src="image/B22045_11_20.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.739.1">Figure 11.20 – Enabling model invocation logging</span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.740.1">Figure 11</span></em></span><em class="italic"><span class="koboSpan" id="kobo.741.1">.20</span></em><span class="koboSpan" id="kobo.742.1"> shows the console view of </span><strong class="bold"><span class="koboSpan" id="kobo.743.1">Model invocation logging</span></strong><span class="koboSpan" id="kobo.744.1"> in the Amazon Bedrock console. </span><span class="koboSpan" id="kobo.744.2">You will need to enable the feature. </span><span class="koboSpan" id="kobo.744.3">The first step is to choose the type of data you want to log, such as text, images, or embeddings. </span><span class="koboSpan" id="kobo.744.4">Next, you’ll need to select the destination for your logs, which can be Amazon S3, Amazon CloudWatch Logs, or both, and provide </span><span class="No-Break"><span class="koboSpan" id="kobo.745.1">the path.</span></span></p>
<p><span class="koboSpan" id="kobo.746.1">If you opt for Amazon S3, your logs will be stored as compressed JSON files, each containing a batch of invocation records. </span><span class="koboSpan" id="kobo.746.2">These files can be queried using Amazon Athena or sent to various AWS services such as Amazon EventBridge. </span><span class="koboSpan" id="kobo.746.3">On the other hand, if you choose Amazon CloudWatch Logs, your invocation logs will be delivered to a specified log group as JSON events. </span><span class="koboSpan" id="kobo.746.4">This allows you to leverage CloudWatch log insights for querying and analyzing your logs in </span><span class="No-Break"><span class="koboSpan" id="kobo.747.1">real time.</span></span></p>
<p><span class="koboSpan" id="kobo.748.1">One of the key advantages of model invocation logging is its ability to capture large input and output data. </span><span class="koboSpan" id="kobo.748.2">For data exceeding 100 KB , or data in binary formats (for example, images, audio, and so on), Amazon Bedrock automatically uploads it to your designated Amazon S3 bucket. </span><span class="koboSpan" id="kobo.748.3">This ensures that no valuable information is lost, even for large or </span><span class="No-Break"><span class="koboSpan" id="kobo.749.1">non-text data.</span></span></p>
<p><span class="koboSpan" id="kobo.750.1">By leveraging thi</span><a id="_idIndexMarker969"/><span class="koboSpan" id="kobo.751.1">s feature, you can optimize your models, identify potential issues, and ensure that your systems are operating efficiently </span><span class="No-Break"><span class="koboSpan" id="kobo.752.1">and effectively.</span></span></p>
<p><span class="koboSpan" id="kobo.753.1">Here is a sample model invocation logs in the CloudWatch </span><span class="No-Break"><span class="koboSpan" id="kobo.754.1">logs console:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.755.1">
{
    "schemaType": "ModelInvocationLog",
    "schemaVersion": "1.0",
    "timestamp": "2024-06-01T02:26:35Z",
    "accountId": "123456789012",
    "identity": {
        "arn": "arn:aws:sts::123456789012:assumed-role/Xyz/Abc"
    },
    "region": "us-east-1",
    "requestId": "9e0ff76a-7cac-67gg-43rg-5g643qwer85r",
    "operation": "ConverseStream",
    "modelId": "anthropic.claude-v2",
    "input": {
        "inputContentType": "application/json",
        "inputBodyJson": {
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "text": "Write a poem on stock market"
                        }
                    ]
                }
            ],
            "inferenceConfig": {
                "maxTokens": 2048,
                "temperature": 0.5,
                "topP": 1,
                "stopSequences": [
                    "\n\nHuman:"
                ]
            },
            "additionalModelRequestFields": {
                "top_k": 250
            }
        },
        "inputTokenCount": 15
    },
    "output": {
        "outputContentType": "application/json",
        "outputBodyJson": {
            "output": {
                "message": {
                    "role": "assistant",
                    "content": [
                        {
                            "text": "Here is a poem about the stock market:\n\nThe Stocks Go Up and Down\n\nThe stocks go up and the stocks go down\nGains and losses all around\nSome days are green, some days are red\nWondering where this rollercoaster will lead\n\nBuy low and sell high, that's what they say\nBut the market has a mind of its own each day\nOne wrong move and your profits fade away\nPatience and research are the prudent way\n\nBulls charge ahead with optimism bright  \nWhile bears retreat in a fearful plight\nAnalysts and investors try to read the signs\nOf economic trends and corporate lines\n\nThe risky trader seeks a quick buck\nWhile the long-term holder trusts in luck \nDay by day the tickers rise and fall\nAs we check our portfolios, hoping they won't stall\n\nSo place your bets and say your prayers\nThe market gods will judge what's fair\nBut one truth will always remain\nIn the stock market, uncertainty reigns"
                        }
                    ]
                }
            },
            "stopReason": "end_turn",
            "metrics": {
                "latencyMs": 8619
            },
            "usage": {
                "inputTokens": 15,
                "outputTokens": 218,
                "totalTokens": 233
            }
        },
        "outputTokenCount": 218
    }
}</span></pre>
<p><span class="koboSpan" id="kobo.756.1">The preceding log snippet provides the </span><strong class="source-inline"><span class="koboSpan" id="kobo.757.1">ConverseStream</span></strong><span class="koboSpan" id="kobo.758.1"> conversational request made to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.759.1">anthropic.claude-v2</span></strong><span class="koboSpan" id="kobo.760.1"> model. </span><span class="koboSpan" id="kobo.760.2">It captures various data points such as the input prompt, output response, performance metrics, and usage statistics. </span><span class="koboSpan" id="kobo.760.3">With this comprehensive</span><a id="_idIndexMarker970"/><span class="koboSpan" id="kobo.761.1"> logging, you can perform effective analysis and evaluation of the model’s capabilities </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">and behavior.</span></span></p>
<h2 id="_idParaDest-206"><a id="_idTextAnchor223"/><span class="koboSpan" id="kobo.763.1">AWS CloudTrail</span></h2>
<p><span class="koboSpan" id="kobo.764.1">AWS CloudTrail is </span><a id="_idIndexMarker971"/><span class="koboSpan" id="kobo.765.1">a compliance and auditing service that </span><a id="_idIndexMarker972"/><span class="koboSpan" id="kobo.766.1">allows you to capture and analyze all API calls made within your AWS environment. </span><span class="koboSpan" id="kobo.766.2">Here’s how you can leverage CloudTrail to gain </span><span class="No-Break"><span class="koboSpan" id="kobo.767.1">invaluable insights.</span></span></p>
<p><span class="koboSpan" id="kobo.768.1">Amazon Bedrock seamlessly integrates with AWS CloudTrail, capturing every API call as an event. </span><span class="koboSpan" id="kobo.768.2">These events encompass actions initiated from the Amazon Bedrock console, as well as programmatic calls made through the Amazon Bedrock API operations. </span><span class="koboSpan" id="kobo.768.3">In CloudTrail, you gain a comprehensive record of who initiated the request, the source IP address, the timestamp, and additional details surrounding </span><span class="No-Break"><span class="koboSpan" id="kobo.769.1">the request.</span></span></p>
<p><span class="koboSpan" id="kobo.770.1">Amazon Bedrock logs two distinct categories of events with CloudTrail: data events and management events. </span><span class="koboSpan" id="kobo.770.2">When it comes to data events, CloudTrail doesn’t log Amazon Bedrock Runtime API operations (</span><strong class="source-inline"><span class="koboSpan" id="kobo.771.1">InvokeModel</span></strong><span class="koboSpan" id="kobo.772.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.773.1">InvokeModelWithResponseStream</span></strong><span class="koboSpan" id="kobo.774.1">) as data events by default. </span><span class="koboSpan" id="kobo.774.2">However, it does log all actions related to agents for Amazon Bedrock Runtime API operations, categorized as </span><span class="No-Break"><span class="koboSpan" id="kobo.775.1">data events:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.776.1">To log </span><strong class="source-inline"><span class="koboSpan" id="kobo.777.1">InvokeAgent</span></strong><span class="koboSpan" id="kobo.778.1"> calls, you would need to configure advanced event selectors on the CloudTrail trail to record data events for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.779.1">AWS::Bedrock::AgentAlias</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.780.1">resource type.</span></span></li>
<li><span class="koboSpan" id="kobo.781.1">To log </span><strong class="source-inline"><span class="koboSpan" id="kobo.782.1">Retrieve</span></strong><span class="koboSpan" id="kobo.783.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.784.1">RetrieveAndGenerate</span></strong><span class="koboSpan" id="kobo.785.1"> calls, configure advanced event selectors to record data events for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.786.1">AWS::Bedrock::KnowledgeBase</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.787.1">resource type.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.788.1">Advanced Event Selector enables the creation of precision and granular filters for monitoring and managing CloudTrail activities related to both management and </span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">data events.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.790.1">Data events</span></strong><span class="koboSpan" id="kobo.791.1"> provide</span><a id="_idIndexMarker973"/><span class="koboSpan" id="kobo.792.1"> insights into resource operations such as reading or writing to resources such as Amazon Bedrock Knowledge Bases or agent aliases. </span><span class="koboSpan" id="kobo.792.2">These events are not logged by default due to their high volume but logging can be enabled through advanced </span><span class="No-Break"><span class="koboSpan" id="kobo.793.1">event selectors.</span></span></p>
<p><span class="koboSpan" id="kobo.794.1">On the other hand, </span><strong class="bold"><span class="koboSpan" id="kobo.795.1">management events</span></strong><span class="koboSpan" id="kobo.796.1"> capture control plane operations such as API calls for creating, updating, or</span><a id="_idIndexMarker974"/><span class="koboSpan" id="kobo.797.1"> deleting Amazon Bedrock resources. </span><span class="koboSpan" id="kobo.797.2">CloudTrail automatically logs these management events, providing a comprehensive audit trail of administrative activities within your Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.798.1">Bedrock environment.</span></span></p>
<p><span class="koboSpan" id="kobo.799.1">If you would like to learn more about CloudTrail, please check the AWS </span><span class="No-Break"><span class="koboSpan" id="kobo.800.1">documentation: </span></span><a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html"><span class="No-Break"><span class="koboSpan" id="kobo.801.1">https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.802.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.803.1">Leveraging AWS CloudTrail in conjunction with Amazon Bedrock provides you with a powerful auditing and monitoring solution. </span><span class="koboSpan" id="kobo.803.2">By capturing and analyzing API calls, you can maintain</span><a id="_idIndexMarker975"/><span class="koboSpan" id="kobo.804.1"> visibility </span><a id="_idIndexMarker976"/><span class="koboSpan" id="kobo.805.1">in your Amazon Bedrock environment, ensure adherence to best practices, and promptly address any potential security or </span><span class="No-Break"><span class="koboSpan" id="kobo.806.1">operational concerns.</span></span></p>
<h2 id="_idParaDest-207"><a id="_idTextAnchor224"/><span class="koboSpan" id="kobo.807.1">EventBridge</span></h2>
<p><span class="koboSpan" id="kobo.808.1">Amazon EventBridge provides a solution for tracking and responding to events in near-real time. </span><span class="koboSpan" id="kobo.808.2">It acts </span><a id="_idIndexMarker977"/><span class="koboSpan" id="kobo.809.1">as a centralized event bus, ingesting and</span><a id="_idIndexMarker978"/><span class="koboSpan" id="kobo.810.1"> processing state change data from various sources including Amazon Bedrock. </span><span class="koboSpan" id="kobo.810.2">Whenever there’s a shift in the status of a model customization job you’ve initiated, Bedrock publishes a new event to EventBridge. </span><span class="koboSpan" id="kobo.810.3">This event contains detailed information about the job, such as its current state, output model ARN, and any </span><span class="No-Break"><span class="koboSpan" id="kobo.811.1">failure messages.</span></span></p>
<p><span class="koboSpan" id="kobo.812.1">Here’s how you can harness the power of Amazon EventBridge to monitor Amazon Bedrock </span><span class="No-Break"><span class="koboSpan" id="kobo.813.1">events effectively:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.814.1">Event streaming and delivery</span></strong><span class="koboSpan" id="kobo.815.1">: Amazon Bedrock emits events on a best-effort basis whenever there’s a state change in a model customization job you’ve initiated. </span><span class="koboSpan" id="kobo.815.2">These events are streamed to Amazon EventBridge, which acts as a centralized event bus, ingesting and processing event data from various AWS services and </span><span class="No-Break"><span class="koboSpan" id="kobo.816.1">external sources.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.817.1">Event pattern matching</span></strong><span class="koboSpan" id="kobo.818.1">: Within Amazon EventBridge, you can create rules that define event patterns based on specific criteria such as the source service, event type, or job status. </span><span class="koboSpan" id="kobo.818.2">By crafting rules tailored to your needs, you can filter and capture only the events that are relevant to your Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.819.1">Bedrock workflows.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.820.1">Automated responses and integrations</span></strong><span class="koboSpan" id="kobo.821.1">: Once an event matches a rule you’ve defined, Amazon EventBridge routes it to one or more targets you’ve specified. </span><span class="koboSpan" id="kobo.821.2">These targets can be various AWS services such as AWS Lambda functions, Amazon </span><strong class="bold"><span class="koboSpan" id="kobo.822.1">Simple Queue Service</span></strong><span class="koboSpan" id="kobo.823.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.824.1">SQS</span></strong><span class="koboSpan" id="kobo.825.1">) queues, or </span><a id="_idIndexMarker979"/><span class="koboSpan" id="kobo.826.1">Amazon </span><strong class="bold"><span class="koboSpan" id="kobo.827.1">Simple Notification Service</span></strong><span class="koboSpan" id="kobo.828.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.829.1">SNS</span></strong><span class="koboSpan" id="kobo.830.1">) topics. </span><span class="koboSpan" id="kobo.830.2">With this</span><a id="_idIndexMarker980"/><span class="koboSpan" id="kobo.831.1"> flexibility, you can trigger automated actions, invoke downstream workflows, or receive notifications based on </span><span class="No-Break"><span class="koboSpan" id="kobo.832.1">event data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.833.1">Monitoring and alerting</span></strong><span class="koboSpan" id="kobo.834.1">: One common use case for Amazon EventBridge is setting up alerting mechanisms for critical events. </span><span class="koboSpan" id="kobo.834.2">For instance, you can configure a rule to send an email notification to a designated address whenever a model customization job fails, enabling you to promptly investigate and address </span><span class="No-Break"><span class="koboSpan" id="kobo.835.1">the issue.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.836.1">Event data enrichment</span></strong><span class="koboSpan" id="kobo.837.1">: The event data emitted by Amazon Bedrock contains valuable information about the model customization job, such as the job ARN, output model ARN, job status, and failure messages (if applicable). </span><span class="koboSpan" id="kobo.837.2">By leveraging this data, you can build robust monitoring and alerting systems tailored to your </span><span class="No-Break"><span class="koboSpan" id="kobo.838.1">specific requirements.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.839.1">To receive and process Amazon Bedrock events through Amazon EventBridge, you will need to create </span><em class="italic"><span class="koboSpan" id="kobo.840.1">rules</span></em><span class="koboSpan" id="kobo.841.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.842.1">targets</span></em><span class="koboSpan" id="kobo.843.1">. </span><span class="koboSpan" id="kobo.843.2">Rules define the event patterns to match, while targets specify the</span><a id="_idIndexMarker981"/><span class="koboSpan" id="kobo.844.1"> actions </span><a id="_idIndexMarker982"/><span class="koboSpan" id="kobo.845.1">to be taken when an event matches a rule. </span><span class="koboSpan" id="kobo.845.2">Let’s learn more about how to </span><span class="No-Break"><span class="koboSpan" id="kobo.846.1">do this:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.847.1">To create a rule, follow the </span><span class="No-Break"><span class="koboSpan" id="kobo.848.1">ensuing steps:</span></span><ol><li class="upper-roman"><span class="koboSpan" id="kobo.849.1">Open the Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.850.1">EventBridge console.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.851.1">Choose </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.852.1">Create rule</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.853.1">.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.854.1">Provide a name for </span><span class="No-Break"><span class="koboSpan" id="kobo.855.1">your rule.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.856.1">Select </span><strong class="bold"><span class="koboSpan" id="kobo.857.1">Event pattern</span></strong><span class="koboSpan" id="kobo.858.1">, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.859.1">Figure 11</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.860.1">.21</span></em></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.861.1">Define the event pattern to match Amazon Bedrock events (for instance, set </span><strong class="bold"><span class="koboSpan" id="kobo.862.1">source</span></strong><span class="koboSpan" id="kobo.863.1"> to </span><strong class="bold"><span class="koboSpan" id="kobo.864.1">aws.bedrock</span></strong><span class="koboSpan" id="kobo.865.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.866.1">detail-type</span></strong><span class="koboSpan" id="kobo.867.1"> to </span><strong class="bold"><span class="koboSpan" id="kobo.868.1">Model Customization Job </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.869.1">State Change</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.870.1">).</span></span></li></ol></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer184">
<span class="koboSpan" id="kobo.871.1"><img alt="Figure 11.21 – The Event pattern window" src="image/B22045_11_21.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.872.1">Figure 11.21 – The Event pattern window</span></p>
<ul>
<li><span class="koboSpan" id="kobo.873.1">Follow the ensuing steps for </span><span class="No-Break"><span class="koboSpan" id="kobo.874.1">configuring targets:</span></span><ol><li class="upper-roman" value="1"><span class="koboSpan" id="kobo.875.1">Choose the target type (for example, AWS Lambda, Amazon SNS, </span><span class="No-Break"><span class="koboSpan" id="kobo.876.1">Amazon SQS).</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.877.1">Specify the target resource (for example, a Lambda function ARN or an SNS </span><span class="No-Break"><span class="koboSpan" id="kobo.878.1">topic ARN).</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.879.1">Optionally, add additional configurations or transformations for </span><span class="No-Break"><span class="koboSpan" id="kobo.880.1">the target.</span></span></li></ol></li>
</ul>
<p><span class="koboSpan" id="kobo.881.1">One practical </span><a id="_idIndexMarker983"/><span class="koboSpan" id="kobo.882.1">use case</span><a id="_idIndexMarker984"/><span class="koboSpan" id="kobo.883.1"> is to receive email notifications whenever there is a change in the status of your model customization jobs. </span><span class="koboSpan" id="kobo.883.2">Here’s how you can set </span><span class="No-Break"><span class="koboSpan" id="kobo.884.1">it up:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.885.1">Create an Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.886.1">SNS topic.</span></span></li>
<li><span class="koboSpan" id="kobo.887.1">Subscribe your email address to the </span><span class="No-Break"><span class="koboSpan" id="kobo.888.1">SNS topic.</span></span></li>
<li><span class="koboSpan" id="kobo.889.1">Create an Amazon EventBridge rule with the following </span><span class="No-Break"><span class="koboSpan" id="kobo.890.1">event pattern:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.891.1">
   ```</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.892.1">
   {</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.893.1">
     "source": ["aws.bedrock"],</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.894.1">
     "detail-type": ["Model Customization Job State Change"]</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.895.1">
   }</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.896.1">
   ```</span></pre></li>
<li><span class="koboSpan" id="kobo.897.1">Set the SNS topic as the target for </span><span class="No-Break"><span class="koboSpan" id="kobo.898.1">the rule.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.899.1">With this set up, you’ll receive email notifications whenever there is a state change in your Amazon Bedrock model customization jobs, keeping you informed about job progress and </span><span class="No-Break"><span class="koboSpan" id="kobo.900.1">potential failures.</span></span></p>
<p><span class="koboSpan" id="kobo.901.1">Additionally, the Amazon EventBridge integration with Amazon Bedrock opens up various advanced use cases, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.902.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.903.1">Triggering Lambda functions to perform custom actions based on job events (for example, sending notifications to a Slack channel, updating a dashboard, or triggering </span><span class="No-Break"><span class="koboSpan" id="kobo.904.1">downstream workflows)</span></span></li>
<li><span class="koboSpan" id="kobo.905.1">Integrating with Amazon Step Functions to orchestrate complex workflows based on </span><span class="No-Break"><span class="koboSpan" id="kobo.906.1">job events</span></span></li>
<li><span class="koboSpan" id="kobo.907.1">Sending job events to Amazon Kinesis data streams for real-time processing </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">and analysis</span></span></li>
<li><span class="koboSpan" id="kobo.909.1">Archiving job events in Amazon S3 or Amazon CloudWatch logs for auditing and </span><span class="No-Break"><span class="koboSpan" id="kobo.910.1">compliance purposes</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.911.1">By leveraging</span><a id="_idIndexMarker985"/><span class="koboSpan" id="kobo.912.1"> Amazon</span><a id="_idIndexMarker986"/><span class="koboSpan" id="kobo.913.1"> EventBridge to monitor and respond to Amazon Bedrock events, you can enhance the security, automation, and visibility of your machine learning operations. </span><span class="koboSpan" id="kobo.913.2">With the ability to define custom rules and integrate with various AWS services, you can create a robust and secure environment tailored to your </span><span class="No-Break"><span class="koboSpan" id="kobo.914.1">specific needs.</span></span></p>
<h1 id="_idParaDest-208"><a id="_idTextAnchor225"/><span class="koboSpan" id="kobo.915.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.916.1">In this chapter, we learned about various methods for evaluating and monitoring the Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.917.1">Bedrock models.</span></span></p>
<p><span class="koboSpan" id="kobo.918.1">We began by exploring the two primary model evaluation methods offered by Amazon Bedrock: automatic model evaluation and human evaluation. </span><span class="koboSpan" id="kobo.918.2">The automatic model evaluation process involves running an evaluation algorithm script on either a built-in or custom dataset, assessing metrics such as accuracy, toxicity, and robustness. </span><span class="koboSpan" id="kobo.918.3">Human evaluation, on the other hand, incorporates human input into the evaluation process, ensuring that the models not only deliver accurate results but also that those results align with real-world expectations </span><span class="No-Break"><span class="koboSpan" id="kobo.919.1">and requirements.</span></span></p>
<p><span class="koboSpan" id="kobo.920.1">Furthermore, we discussed open source tools such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.921.1">fmeval</span></strong><span class="koboSpan" id="kobo.922.1"> and Ragas, which provide additional evaluation capabilities that are specifically tailored for LLMs and </span><span class="No-Break"><span class="koboSpan" id="kobo.923.1">RAG pipelines.</span></span></p>
<p><span class="koboSpan" id="kobo.924.1">Moving on to the section on monitoring, we discussed how Amazon CloudWatch can be leveraged to gain valuable insights into model performance, latency, and token counts. </span><span class="koboSpan" id="kobo.924.2">We explored the various metrics provided by Amazon Bedrock and considered how they can be visualized and monitored through CloudWatch dashboards. </span><span class="koboSpan" id="kobo.924.3">Additionally, we covered model invocation logging, a powerful feature that allows you to capture and analyze requests, responses, and metadata for all model invocations. </span><span class="koboSpan" id="kobo.924.4">Next, we looked at the integration of Amazon Bedrock with AWS CloudTrail and EventBridge. </span><span class="koboSpan" id="kobo.924.5">CloudTrail provides a comprehensive audit trail of API calls made within your AWS environment, enabling you to monitor and ensure adherence to best practices. </span><span class="koboSpan" id="kobo.924.6">EventBridge, on the other hand, allows you to track and respond to events in near-real time, enabling automated responses and integrations based on the state changes of your model </span><span class="No-Break"><span class="koboSpan" id="kobo.925.1">customization jobs.</span></span></p>
<p><span class="koboSpan" id="kobo.926.1">Ensuring security and privacy is the top priority at Amazon and also in today’s digital landscape. </span><span class="koboSpan" id="kobo.926.2">In the next chapter, we are going to look at how security and privacy can be ensured in </span><span class="No-Break"><span class="koboSpan" id="kobo.927.1">Amazon Bedrock.</span></span></p>
</div>
</body></html>