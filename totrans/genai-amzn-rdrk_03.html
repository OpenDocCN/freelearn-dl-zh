<html><head></head><body>
<div id="_idContainer054">
<h1 class="chapter-number" id="_idParaDest-53"><a id="_idTextAnchor053"/><span class="koboSpan" id="kobo.1.1">3</span></h1>
<h1 id="_idParaDest-54"><a id="_idTextAnchor054"/><span class="koboSpan" id="kobo.2.1">Engineering Prompts for Effective Model Usage</span></h1>
<p><span class="koboSpan" id="kobo.3.1">This chapter begins with an overview of prompt engineering and its importance. </span><span class="koboSpan" id="kobo.3.2">We will walk through various prompt engineering techniques and the ability to incorporate them while prompting any model on Amazon Bedrock, primarily focusing on designing and analyzing effective prompt techniques to get the desired outcome from the Bedrock models. </span><span class="koboSpan" id="kobo.3.3">This chapter also entails some of the best practices associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">prompt engineering.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">By the end of this chapter, you will have developed a clear understanding of the practical aspects of prompt engineering and be able to craft effective prompts while following the best practices to get the desired outcome from the models available on </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">Amazon Bedrock.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">In this chapter, we’re going to cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">What is </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">prompt engineering?</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Unlocking prompt </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">engineering techniques</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Designing prompts for Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">Bedrock models</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Understanding best practices in </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">prompt engineering</span></span></li>
</ul>
<h1 id="_idParaDest-55"><a id="_idTextAnchor055"/><span class="koboSpan" id="kobo.17.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.18.1">To complete this chapter, you need to have access to the </span><em class="italic"><span class="koboSpan" id="kobo.19.1">AWS</span></em><span class="koboSpan" id="kobo.20.1"> console so that you can navigate to Amazon Bedrock Playground to execute prompt engineering techniques. </span><span class="koboSpan" id="kobo.20.2">Here’s the web page to access the </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">console: </span></span><a href="https://console.aws.amazon.com/"><span class="No-Break"><span class="koboSpan" id="kobo.22.1">https://console.aws.amazon.com/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.23.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.24.1">Secondly, you need to have the right permissions to invoke Amazon Bedrock models from your local machine using </span><em class="italic"><span class="koboSpan" id="kobo.25.1">Amazon Bedrock APIs</span></em><span class="koboSpan" id="kobo.26.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.27.1">Bedrock Python SDK</span></em><span class="koboSpan" id="kobo.28.1"> so that you can execute the prompts. </span><span class="koboSpan" id="kobo.28.2">To learn more, go </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">to </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html"><span class="No-Break"><span class="koboSpan" id="kobo.30.1">https://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.31.1">.</span></span></p>
<h1 id="_idParaDest-56"><a id="_idTextAnchor056"/><span class="koboSpan" id="kobo.32.1">What is prompt engineering?</span></h1>
<p><span class="koboSpan" id="kobo.33.1">Since we have </span><a id="_idIndexMarker210"/><span class="koboSpan" id="kobo.34.1">been discussing Amazon Bedrock models and how to invoke them, we need to dive into prompt engineering. </span><span class="koboSpan" id="kobo.34.2">Essentially, in a way that a particular child asks their parents questions about anything and everything, we can also ask an LLM anything under the Sun! </span><span class="koboSpan" id="kobo.34.3">However, to get the best and most precise outputs possible, we must train ourselves to ask the model the right questions in the </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">right manner.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">With the increasing popularity of LLMs, users are actively striving to refine their way of asking the model different kinds of questions to attain a desired response. </span><span class="koboSpan" id="kobo.36.2">For instance, we can simply ask an LLM questions such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.37.1">Who was the first person to land on the Moon?</span></strong><span class="koboSpan" id="kobo.38.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.39.1">How many moons does Jupiter have?</span></strong><span class="koboSpan" id="kobo.40.1">. </span><span class="koboSpan" id="kobo.40.2">Based on these questions, the language model can respond to the user’s queries either factually or provide an inadequate/incorrect response based on the LLM’s knowledge, which is the data it has been </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">trained on.</span></span></p>
<p><span class="koboSpan" id="kobo.42.1">Incorrect responses that the users get without fact-checking are what we refer to as </span><strong class="bold"><span class="koboSpan" id="kobo.43.1">hallucinations</span></strong><span class="koboSpan" id="kobo.44.1">. </span><span class="koboSpan" id="kobo.44.2">It is often seen that if the user asks an ambiguous question or a particularly complex math problem that the model hasn’t been trained to answer, it will determine a probabilistic answer that may or may not be factually accurate. </span><span class="koboSpan" id="kobo.44.3">This can also occur with large vision models such as text-to-image models, where the model ends up providing an undesirable image as the </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">prompted response.</span></span></p>
<p><span class="koboSpan" id="kobo.46.1">Hence, how we ask questions to the model and how effectively we can provide a description regarding our question becomes a crucial factor for the model to generate a </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">desirable output.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">The method of prompting the model in the right manner while avoiding any ambiguity in your prompts becomes the essence of effective </span><strong class="bold"><span class="koboSpan" id="kobo.49.1">prompt engineering</span></strong><span class="koboSpan" id="kobo.50.1">. </span><span class="koboSpan" id="kobo.50.2">This is not just applicable to the technical </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">community anymore!</span></span></p>
<p><span class="koboSpan" id="kobo.52.1">Even people with varying technical backgrounds can use LLMs for a range of tasks. </span><span class="koboSpan" id="kobo.52.2">Based on the user prompts, the models can offer basic tips on entrepreneurship or provide fundamental insights into website creation through detailed, </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">informative conversations.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">Effective prompt engineering techniques pave the way for users to get the desired responses. </span><span class="koboSpan" id="kobo.54.2">Furthermore, some companies have been offering high-paying jobs for researchers and personas who can write or adopt effective prompt engineering to get their model to perform responsible actions, thereby enhancing the company’s productivity to execute their functions/tasks at an </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">accelerated pace.</span></span></p>
<p><span class="koboSpan" id="kobo.56.1">This chapter will explain how effective prompt engineering techniques can be applied to LLMs. </span><span class="koboSpan" id="kobo.56.2">But first, let’s </span><a id="_idIndexMarker211"/><span class="koboSpan" id="kobo.57.1">dive into the structure of a prompt and some key ideas that focus on effective </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">prompt techniques.</span></span></p>
<h2 id="_idParaDest-57"><a id="_idTextAnchor057"/><span class="koboSpan" id="kobo.59.1">Components of prompts</span></h2>
<p><span class="koboSpan" id="kobo.60.1">How you write </span><a id="_idIndexMarker212"/><span class="koboSpan" id="kobo.61.1">a prompt plays a crucial role in guiding the behavior of the model. </span><span class="koboSpan" id="kobo.61.2">Prompts contain a few key elements. </span><span class="koboSpan" id="kobo.61.3">Let’s understand those elements through an example (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.62.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.63.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer036">
<span class="koboSpan" id="kobo.65.1"><img alt="Figure 3.1 – Components of a prompt" src="image/B22045_03_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.66.1">Figure 3.1 – Components of a prompt</span></p>
<p><span class="koboSpan" id="kobo.67.1">Let’s take a closer look at the terms highlighted in the </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">preceding figure:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.69.1">Instruction</span></strong><span class="koboSpan" id="kobo.70.1">: With an instruction, you provide a clear and concise description or instruction to the model on how it should perform the task, whether it be summarizing text, translating languages, composing music, or any number of other things. </span><span class="koboSpan" id="kobo.70.2">In the preceding figure, you can see that we have asked the model to act as a specialist in quantum computing and answer the user’s question in detail and in layman’s terms, along </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">with examples.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.72.1">Context</span></strong><span class="koboSpan" id="kobo.73.1">: Context refers to the relevant background information that you provide to the model to enhance its performance. </span><span class="koboSpan" id="kobo.73.2">This can include any relevant data, past experiences, or domain-specific knowledge. </span><span class="koboSpan" id="kobo.73.3">In the preceding figure, in terms of context, we stated that the model has recently completed a PhD and has been asked to be part of an interview on a talk show that explains complex topics in layman’s terms. </span><span class="koboSpan" id="kobo.73.4">This primes the model with </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">pertinent knowledge.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.75.1">Input data</span></strong><span class="koboSpan" id="kobo.76.1"> (or </span><strong class="bold"><span class="koboSpan" id="kobo.77.1">user input</span></strong><span class="koboSpan" id="kobo.78.1">): This is the actual question or input that the model needs to process and base its output on. </span><span class="koboSpan" id="kobo.78.2">It can be in the form of text, images, audio, and so on, and it can be as simple as a short question, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.79.1">What is Quantum Computing?</span></strong><span class="koboSpan" id="kobo.80.1">. </span><span class="koboSpan" id="kobo.80.2">As depicted in the preceding figure, the input question that goes to the model is </span><strong class="source-inline"><span class="koboSpan" id="kobo.81.1">Can you provide me your thoughts on Quantum </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.82.1">Machine Learning?</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.84.1">Output indicator</span></strong><span class="koboSpan" id="kobo.85.1">: This is the layout or an indicator that the model should provide its output in. </span><span class="koboSpan" id="kobo.85.2">It could be as simple as </span><strong class="source-inline"><span class="koboSpan" id="kobo.86.1">Quantum Ninja</span></strong><span class="koboSpan" id="kobo.87.1">, as depicted in the preceding figure, so that the model understands that its output should be in this layout, or it could be in a specific format, such as text, JSON, an audio clip, and so on. </span><span class="koboSpan" id="kobo.87.2">Special </span><a id="_idIndexMarker213"/><span class="koboSpan" id="kobo.88.1">syntax such as </span><em class="italic"><span class="koboSpan" id="kobo.89.1">&lt;|endoftext|&gt;</span></em><span class="koboSpan" id="kobo.90.1"> signals the end of the input and the beginning of the model’s output. </span><span class="koboSpan" id="kobo.90.2">This special syntax can vary on a </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">per-model basis.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.92.1">Although prompts need not have all four elements, their form depends on the task. </span><span class="koboSpan" id="kobo.92.2">Let’s examine a few </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">sample prompts:</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.94.1">Example 1: </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.95.1">SQL query</span></strong></span></p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<span class="koboSpan" id="kobo.96.1"><img alt="Figure 3.2 – SQL query prompt" src="image/B22045_03_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.97.1">Figure 3.2 – SQL query prompt</span></p>
<p><span class="koboSpan" id="kobo.98.1">As shown</span><a id="_idIndexMarker214"/><span class="koboSpan" id="kobo.99.1"> in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.100.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.101.1">.2</span></em><span class="koboSpan" id="kobo.102.1">, we </span><a id="_idIndexMarker215"/><span class="koboSpan" id="kobo.103.1">are specifying the following prompt elements to the Titan Text G1 – </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">Premier model:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.105.1">Context</span></strong><span class="koboSpan" id="kobo.106.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.107.1">You are querying a database with the following schema: Customers(id, name, age) and Orders(id, cust_id, </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.108.1">product, amount).</span></strong></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.109.1">Input</span></strong><span class="koboSpan" id="kobo.110.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.111.1">List all customers who have placed more than 1 order, along with their total </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.112.1">order amounts.</span></strong></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.113.1">Output</span></strong><span class="koboSpan" id="kobo.114.1">: </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.115.1">SQL query:</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.116.1">This prompt provides clear instructions, relevant schema context, a sample input, and output indicators to produce a suitable </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">SQL query.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.118.1">Example 2: </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.119.1">Recipe generation</span></strong></span></p>
<p><span class="koboSpan" id="kobo.120.1">Here is another example (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.121.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.122.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer038">
<span class="koboSpan" id="kobo.124.1"><img alt="Figure 3.3 – Recipe prompt" src="image/B22045_03_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.125.1">Figure 3.3 – Recipe prompt</span></p>
<p><span class="koboSpan" id="kobo.126.1">Let’s take a </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">closer look:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.128.1">Context</span></strong><span class="koboSpan" id="kobo.129.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.130.1">Baked salmon is a healthy weeknight dinner option perfect with roasted potatoes or rice. </span><span class="koboSpan" id="kobo.130.2">The fresh dill adds an </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.131.1">aromatic flavor.</span></strong></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.132.1">Input data</span></strong><span class="koboSpan" id="kobo.133.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.134.1">Salmon fillet, dill, lemon, salt, pepper, </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.135.1">olive oil</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.137.1">Output </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.138.1">indicator</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">: </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.140.1">&lt;|endoftext|&gt;</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.142.1">The preceding prompt provides the model with the recipe’s title, introductory context, ingredients </span><a id="_idIndexMarker216"/><span class="koboSpan" id="kobo.143.1">as input data, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.144.1">&lt;|endoftext|&gt;</span></strong><span class="koboSpan" id="kobo.145.1"> as an output indicator, which signals where the recipe steps </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">should begin.</span></span></p>
<h2 id="_idParaDest-58"><a id="_idTextAnchor058"/><span class="koboSpan" id="kobo.147.1">Prompt engineering applications</span></h2>
<p><span class="koboSpan" id="kobo.148.1">Now that we understand</span><a id="_idIndexMarker217"/><span class="koboSpan" id="kobo.149.1"> how we can communicate with the model, let’s learn about some prompt engineering techniques that can aid us in getting better responses from </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">the model.</span></span></p>
<p><span class="koboSpan" id="kobo.151.1">However, primarily, we need to understand that the optimal prompt engineering approach for any given use case is heavily reliant on the task at hand, as well as the data on which it has </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">been trained.</span></span></p>
<p><span class="koboSpan" id="kobo.153.1">Some of the tasks that the models on Bedrock excel at are </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.155.1">Classification</span></strong><span class="koboSpan" id="kobo.156.1">: LLMs exhibit </span><a id="_idIndexMarker218"/><span class="koboSpan" id="kobo.157.1">prowess in text classification, a supervised learning technique for assigning categories to text. </span><span class="koboSpan" id="kobo.157.2">For instance, sentiment analysis involves discerning whether an input passage conveys positive or negative emotion. </span><span class="koboSpan" id="kobo.157.3">Some LLMs available via Amazon Bedrock, such as the Amazon Titan models, can also identify toxic, harmless, or fact-based content. </span><span class="koboSpan" id="kobo.157.4">Their deep contextual understanding aids the judgment of subtle </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">linguistic cues.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.159.1">Question-answering</span></strong><span class="koboSpan" id="kobo.160.1">: The models can answer questions accurately without external context due to their vast parameters gained from ingesting hundreds of billions of words during pre-training. </span><span class="koboSpan" id="kobo.160.2">When provided with relevant documents, their performance further improves by reasoning over the </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">additional context.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.162.1">Summarization</span></strong><span class="koboSpan" id="kobo.163.1">: The models condense lengthy texts into concise summaries that preserve key details, learning to differentiate salient points. </span><span class="koboSpan" id="kobo.163.2">Adding such a prompt facilitates rapid analysis </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">of documents.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.165.1">Text generation</span></strong><span class="koboSpan" id="kobo.166.1">: The model can generate original coherent text given a short prompt. </span><span class="koboSpan" id="kobo.166.2">Their fluency and semantic consistency allow realistic synthesis of stories, poems, scripts, </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">and more.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.168.1">Code generation</span></strong><span class="koboSpan" id="kobo.169.1">: For a textual description of a programming need, the models can generate executable code in languages such as SQL and Python. </span><span class="koboSpan" id="kobo.169.2">For example, a prompt could request text-to-SQL or Python code generation, thereby accomplishing the outlined </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">computational goal.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.171.1">Mathematical reasoning</span></strong><span class="koboSpan" id="kobo.172.1">: The models exhibit an aptitude for mathematical problems provided in text form. </span><span class="koboSpan" id="kobo.172.2">This includes numerical calculations, logical deduction, and geometric reasoning. </span><span class="koboSpan" id="kobo.172.3">They can further justify solutions with </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">step-by-step explanations.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.174.1">The breadth of natural language tasks that can be mastered by LLMs on Amazon Bedrock exemplifies their versatility. </span><span class="koboSpan" id="kobo.174.2">Their adaptive capacity promises to expand application domains </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1">even further.</span></span></p>
<p><span class="koboSpan" id="kobo.176.1">Now that we’ve gained insights into applications of prompt engineering in the real world, let’s try to</span><a id="_idIndexMarker219"/><span class="koboSpan" id="kobo.177.1"> unlock some of the most common prompt </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">engineering techniques.</span></span></p>
<h1 id="_idParaDest-59"><a id="_idTextAnchor059"/><span class="koboSpan" id="kobo.179.1">Unlocking prompt engineering techniques</span></h1>
<p><span class="koboSpan" id="kobo.180.1">The field of </span><a id="_idIndexMarker220"/><span class="koboSpan" id="kobo.181.1">prompt engineering is an active area of research and innovation with new techniques and patterns emerging frequently, driven by the pursuit to improve the performance of the models and generate more natural human-like responses. </span><span class="koboSpan" id="kobo.181.2">In this section, we are going to look at some of the most </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">common patterns.</span></span></p>
<h2 id="_idParaDest-60"><a id="_idTextAnchor060"/><span class="koboSpan" id="kobo.183.1">Zero-shot prompting</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.184.1">Zero-shot</span></strong><span class="koboSpan" id="kobo.185.1"> refers to</span><a id="_idIndexMarker221"/><span class="koboSpan" id="kobo.186.1"> the ability of LLMs </span><a id="_idIndexMarker222"/><span class="koboSpan" id="kobo.187.1">to generate reasonable responses to prompts that it has not been explicitly trained on. </span><span class="koboSpan" id="kobo.187.2">It relies solely on a descriptive prompt to specify the desired output, as depicted in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.188.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.189.1">.4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<span class="koboSpan" id="kobo.191.1"><img alt="Figure 3.4 – Zero-shot prompting" src="image/B22045_03_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.192.1">Figure 3.4 – Zero-shot prompting</span></p>
<p><span class="koboSpan" id="kobo.193.1">For instance, a zero-shot prompt to get a poem could be </span><strong class="source-inline"><span class="koboSpan" id="kobo.194.1">Write a rhyming poem with 4 stanzas about </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.195.1">seasons changing</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.197.1">The main advantage of this method is that it’s easier; prompt crafting can be done without providing examples in the input. </span><span class="koboSpan" id="kobo.197.2">However, output quality can vary without concrete examples to </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">base on.</span></span></p>
<h2 id="_idParaDest-61"><a id="_idTextAnchor061"/><span class="koboSpan" id="kobo.199.1">Few-shot prompting</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.200.1">Few-shot prompting</span></strong><span class="koboSpan" id="kobo.201.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.202.1">few-shot learning</span></strong><span class="koboSpan" id="kobo.203.1"> builds </span><a id="_idIndexMarker223"/><span class="koboSpan" id="kobo.204.1">on zero-shot’s </span><a id="_idIndexMarker224"/><span class="koboSpan" id="kobo.205.1">capabilities. </span><span class="koboSpan" id="kobo.205.2">As depicted</span><a id="_idIndexMarker225"/><span class="koboSpan" id="kobo.206.1"> in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.207.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.208.1">.5</span></em><span class="koboSpan" id="kobo.209.1">, on top of instructions/questions, you can provide a few examples that establish a concept or scenario, at which point models can start to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">reasonable continuations:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer040">
<span class="koboSpan" id="kobo.211.1"><img alt="Figure 3.5 – Few-shot prompting" src="image/B22045_03_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.212.1">Figure 3.5 – Few-shot prompting</span></p>
<p><span class="koboSpan" id="kobo.213.1">For instance, after showing two or three examples of short conversations about booking a doctor’s appointment, LLMs can produce an appointment booking dialog without needing thousands of examples. </span><span class="koboSpan" id="kobo.213.2">The key benefit over zero-shot is that few-shot examples help narrow down the context and constrain the generation process, making outputs </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">more precise.</span></span></p>
<p><span class="koboSpan" id="kobo.215.1">Let’s look at some of the examples of few-shot prompting. </span><span class="koboSpan" id="kobo.215.2">The following are two inputs that we can use in the poem writing task from the previous sub-section that we can give to the model </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">as examples.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.217.1">Example 1</span></strong><span class="koboSpan" id="kobo.218.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.219.1">Roses are red, violets are blue, spring brings </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.220.1">life anew.</span></strong></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.221.1">Example 2</span></strong><span class="koboSpan" id="kobo.222.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.223.1">Summer sun shining bright, long days full </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.224.1">of light.</span></strong></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">Now you write a rhyming poem about autumn </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.226.1">changing leaves.</span></strong></span></p>
<p><span class="koboSpan" id="kobo.227.1">By analyzing these examples, LLMs can learn the pattern of rhyming four-line stanzas about seasons. </span><span class="koboSpan" id="kobo.227.2">It can then follow the template to generate an autumn poem. </span><span class="koboSpan" id="kobo.227.3">Balancing creativity and </span><a id="_idIndexMarker226"/><span class="koboSpan" id="kobo.228.1">guidance is key in </span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">few-shot</span></span><span class="No-Break"><a id="_idIndexMarker227"/></span><span class="No-Break"><span class="koboSpan" id="kobo.230.1"> prompts.</span></span></p>
<p><span class="koboSpan" id="kobo.231.1">Additional examples of few-shot prompting are available </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">here: </span></span><a href="https://www.promptingguide.ai/techniques/fewshot"><span class="No-Break"><span class="koboSpan" id="kobo.233.1">https://www.promptingguide.ai/techniques/fewshot</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.234.1">.</span></span></p>
<h2 id="_idParaDest-62"><a id="_idTextAnchor062"/><span class="koboSpan" id="kobo.235.1">Chain-of-thought prompting</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.236.1">Chain of thought</span></strong><span class="koboSpan" id="kobo.237.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.238.1">CoT</span></strong><span class="koboSpan" id="kobo.239.1">) </span><strong class="bold"><span class="koboSpan" id="kobo.240.1">prompting</span></strong><span class="koboSpan" id="kobo.241.1"> aims</span><a id="_idIndexMarker228"/><span class="koboSpan" id="kobo.242.1"> to elicit reasoning chains from language models. </span><span class="koboSpan" id="kobo.242.2">It </span><a id="_idIndexMarker229"/><span class="koboSpan" id="kobo.243.1">involves providing the LLM with a prompt that lays out a reasoning chain or train of thought for the model to follow (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.244.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.245.1">.6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">).</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer041">
<span class="koboSpan" id="kobo.247.1"><img alt="Figure 3.6 – Chain-of-thought prompting" src="image/B22045_03_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.248.1">Figure 3.6 – Chain-of-thought prompting</span></p>
<p><span class="koboSpan" id="kobo.249.1">A prompt may start with background context, state a hypothesis or problem, provide reasoning steps, and end with a conclusion to be expanded on. </span><span class="koboSpan" id="kobo.249.2">The model then tries to continue the chain of reasoning coherently in its </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">generated text:</span></span></p>
<p><span class="koboSpan" id="kobo.251.1">Here’s an example of a </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">CoT prompt:</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.253.1">Recycling is beneficial for the environment because it reduces waste sent to landfills. </span><span class="koboSpan" id="kobo.253.2">Landfills produce methane, a potent greenhouse gas. </span><span class="koboSpan" id="kobo.253.3">They also take up large amounts of space. </span><span class="koboSpan" id="kobo.253.4">Recycling reduces landfill contributions by reusing materials. </span><span class="koboSpan" id="kobo.253.5">In conclusion, recycling helps fight climate change by reducing landfill methane and space requirements. </span><span class="koboSpan" id="kobo.253.6">The main environmental benefits of </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.254.1">recycling are...</span></strong></span></p>
<p><span class="koboSpan" id="kobo.255.1">This prompting style guides the LLM to follow the provided reasoning chain and elaborate further on the conclusion statement. </span><span class="koboSpan" id="kobo.255.2">The generated text will likely discuss reduced methane emissions and land use from increased recycling in more detail. </span><span class="koboSpan" id="kobo.255.3">Hence, chaining further encourages step-by-step logical thinking that focuses on the end goal over open-ended, </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">meandering text.</span></span></p>
<p><span class="koboSpan" id="kobo.257.1">Let’s look at some </span><a id="_idIndexMarker230"/><span class="koboSpan" id="kobo.258.1">examples of CoT</span><a id="_idIndexMarker231"/><span class="koboSpan" id="kobo.259.1"> prompting and </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">the responses:</span></span></p>
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.261.1">Example 1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">:</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.263.1">Write a story about a professor exploring a </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.264.1">mysterious artifact</span></strong></span></p>
<pre class="console"><span class="koboSpan" id="kobo.265.1">
Dr. </span><span class="koboSpan" id="kobo.265.2">Jones entered the temple, brushing cobwebs out of her face. </span><span class="koboSpan" id="kobo.265.3">In the center of the room sat a small stone box...</span></pre>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.266.1">As she opens the box, a glowing light emerges, illuminating symbols on </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.267.1">the walls</span></strong></span></p>
<pre class="console"><span class="koboSpan" id="kobo.268.1">
Squinting in the sudden brightness, Dr. </span><span class="koboSpan" id="kobo.268.2">Jones sees the symbols represent a long-lost ancient language. </span><span class="koboSpan" id="kobo.268.3">She reaches towards the box and feels an energy pulling at her fingertips...</span></pre>
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.269.1">Example 2</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">:</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.271.1">What are the pros and cons of renewable </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.272.1">energy sources?</span></strong></span></p>
<pre class="console"><span class="koboSpan" id="kobo.273.1">
Some pros of renewable energies are...</span></pre>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.274.1">You missed one major renewable source. </span><span class="koboSpan" id="kobo.274.2">Please include geothermal energy when comparing the pros </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.275.1">and cons.</span></strong></span></p>
<pre class="console"><span class="koboSpan" id="kobo.276.1">
Some pros of renewable energies like solar, wind, geothermal and hydroelectric power are low pollution...</span></pre>
<p><span class="koboSpan" id="kobo.277.1">In this approach, the human can guide and shape the overall narrative or analysis by inserting additional prompts whenever they want to redirect, refine, or expand the model’s response. </span><span class="koboSpan" id="kobo.277.2">It allows for a more conversational flow based on an initial theme or direction provided by </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">the human.</span></span></p>
<p><span class="koboSpan" id="kobo.279.1">Additional </span><a id="_idIndexMarker232"/><span class="koboSpan" id="kobo.280.1">examples of </span><a id="_idIndexMarker233"/><span class="koboSpan" id="kobo.281.1">CoT prompting are available </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">at </span></span><a href="https://www.promptingguide.ai/techniques/cot"><span class="No-Break"><span class="koboSpan" id="kobo.283.1">https://www.promptingguide.ai/techniques/cot</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.284.1">.</span></span></p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor063"/><span class="koboSpan" id="kobo.285.1">ReAct prompting</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.286.1">Reasoning and Acting</span></strong><span class="koboSpan" id="kobo.287.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.288.1">ReAct</span></strong><span class="koboSpan" id="kobo.289.1">) prompting </span><a id="_idIndexMarker234"/><span class="koboSpan" id="kobo.290.1">is derived </span><a id="_idIndexMarker235"/><span class="koboSpan" id="kobo.291.1">from the ReAct framework, as introduced in the paper </span><em class="italic"><span class="koboSpan" id="kobo.292.1">ReAct: Synergizing Reasoning and Acting in Language </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.293.1">Models</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.294.1"> (</span></span><a href="https://arxiv.org/abs/2210.03629"><span class="No-Break"><span class="koboSpan" id="kobo.295.1">https://arxiv.org/abs/2210.03629</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.296.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer042">
<span class="koboSpan" id="kobo.297.1"><img alt="Figure 3.7 – ReAct prompting" src="image/B22045_03_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.298.1">Figure 3.7 – ReAct prompting</span></p>
<p><span class="koboSpan" id="kobo.299.1">This framework generates various reasoning traces. </span><span class="koboSpan" id="kobo.299.2">Then, based on those traces, it performs relevant actions. </span><span class="koboSpan" id="kobo.299.3">Through this process of reasoning and acting, you can also allow the application to have access to the organization’s internal data stores and APIs, or external sources from various tools, websites, web searches, and more, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.300.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.301.1">.7</span></em><span class="koboSpan" id="kobo.302.1">. </span><span class="koboSpan" id="kobo.302.2">This process of generating reasoning traces and performing actions is iterative and occurs until the LLM finds the answer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">user’s prompt.</span></span></p>
<p><span class="koboSpan" id="kobo.304.1">We will discuss ReAct prompting in more detail in </span><a href="B22045_10.xhtml#_idTextAnchor192"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.305.1">Chapter 10</span></em></span></a><span class="koboSpan" id="kobo.306.1">. </span><span class="koboSpan" id="kobo.306.2">For now, let’s create a ReAct-SQL tool for deriving a comprehensive response from </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">the model.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.308.1">Prompt from human</span></strong><span class="koboSpan" id="kobo.309.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.310.1">Provide an updated financial summary report </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.311.1">for AnyCompany</span></strong></span></p>
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.312.1">Assistant response:</span></strong></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.313.1">Thought</span></em><span class="koboSpan" id="kobo.314.1">: The user is asking for financial information about AnyCompany. </span><span class="koboSpan" id="kobo.314.2">To answer this, I need to do </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.316.1">Query the database to find financial records </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">for AnyCompany</span></span></li>
<li><span class="koboSpan" id="kobo.318.1">Write a summary of the financial </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">information obtained</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.320.1">So, I will need</span><a id="_idIndexMarker236"/><span class="koboSpan" id="kobo.321.1"> to</span><a id="_idIndexMarker237"/><span class="koboSpan" id="kobo.322.1"> use the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.323.1">sql_db_query</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.324.1"> tool.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.325.1">Action</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">: </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.327.1">sql_db_query</span></strong></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.328.1">Action input</span></em><span class="koboSpan" id="kobo.329.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.330.1">SELECT * FROM financial_db WHERE company = '</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">AnyCompany';</span></strong></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.332.1">[(260B, 55B, </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">321B, 2.2T)]</span></strong></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.334.1">Answer</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.336.1">
AnyCompany has demonstrated strong financial performance with revenue of $260 billion. </span><span class="koboSpan" id="kobo.336.2">With net income of $55 billion, AnyCompany has a 21% net profit margin, indicating it is highly profitable. </span><span class="koboSpan" id="kobo.336.3">AnyCompany also has a considerable asset base of $321 billion, providing the company with significant financial resources. </span><span class="koboSpan" id="kobo.336.4">With a market capitalization of $2.2 trillion, AnyCompany is the most valuable public company, suggesting investors are confident in AnyCompany continued growth and profitability. </span><span class="koboSpan" id="kobo.336.5">Overall, AnyCompany's finances appear very healthy.</span></pre>
<p><span class="koboSpan" id="kobo.337.1">Similar to the preceding form of prompting patterns, new prompt engineering techniques and patterns are burgeoning these days. </span><span class="koboSpan" id="kobo.337.2">More details on prompt engineering can be found in the prompt engineering guide </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">at </span></span><a href="https://www.promptingguide.ai/techniques"><span class="No-Break"><span class="koboSpan" id="kobo.339.1">https://www.promptingguide.ai/techniques</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.340.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.341.1">In this section, we uncovered several prompt engineering techniques that are being leveraged in the</span><a id="_idIndexMarker238"/><span class="koboSpan" id="kobo.342.1"> realm of building Generative AI applications for various use cases. </span><span class="koboSpan" id="kobo.342.2">Next, we will work on designing prompts</span><a id="_idIndexMarker239"/><span class="koboSpan" id="kobo.343.1"> for Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">Bedrock </span></span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">FMs.</span></span></p>
<h1 id="_idParaDest-64"><a id="_idTextAnchor064"/><span class="koboSpan" id="kobo.346.1">Designing prompts for Amazon Bedrock models</span></h1>
<p><span class="koboSpan" id="kobo.347.1">In this section, we’re </span><a id="_idIndexMarker240"/><span class="koboSpan" id="kobo.348.1">going to cover prompt guidance for some of the models available via Amazon Bedrock. </span><span class="koboSpan" id="kobo.348.2">We will kick things off with the Anthropic Claude model and provide details around prompt guidance for this. </span><span class="koboSpan" id="kobo.348.3">The majority of the learning for prompt guidance can be inherited from Claude models. </span><span class="koboSpan" id="kobo.348.4">Furthermore, for the sake of striking a balance between brevity and detail, we will shine a light on the models from Amazon Titan, AI21 Labs, and Stability AI Stable Diffusion. </span><span class="koboSpan" id="kobo.348.5">This will sum up our prompt guidance and associated prompt recommendations for invoking Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">Bedrock models.</span></span></p>
<h2 id="_idParaDest-65"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.350.1">Prompting Anthropic Claude 3</span></h2>
<p><span class="koboSpan" id="kobo.351.1">Here are some things </span><a id="_idIndexMarker241"/><span class="koboSpan" id="kobo.352.1">to </span><a id="_idIndexMarker242"/><span class="koboSpan" id="kobo.353.1">keep in mind while prompting the Anthropic Claude </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">3 model:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.355.1">Assigning a role/persona via prompts</span></strong><span class="koboSpan" id="kobo.356.1">: Assigning roles or personas to the Claude models aids in improving model performance in several scenarios, which, in turn, improves the model’s tonality. </span><span class="koboSpan" id="kobo.356.2">For instance, you can assign an expert role for executing a certain task, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.357.1">You are a seasoned Children's Book Author</span></strong><span class="koboSpan" id="kobo.358.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.359.1">You are a </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.360.1">Business Expert</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">.</span></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.362.1">Example</span></strong><span class="koboSpan" id="kobo.363.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.364.1">Imagine you are a kindergarten teacher and have to provide an explanation for rainbows in the sky to </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.365.1">the children.</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.366.1">:</span></span></p></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer043">
<span class="koboSpan" id="kobo.367.1"><img alt="Figure 3.8 – Anthropic Claude 3 Haiku – simple prompting" src="image/B22045_03_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.368.1">Figure 3.8 – Anthropic Claude 3 Haiku – simple prompting</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.369.1">Without assigning a </span><a id="_idIndexMarker243"/><span class="koboSpan" id="kobo.370.1">role/persona, the </span><a id="_idIndexMarker244"/><span class="koboSpan" id="kobo.371.1">answer may be complex to understand, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.372.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.373.1">.8</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.375.1">After adding the role/persona, you can see that the output response aligns more with a child’s complexity level in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.376.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.377.1">.9</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<span class="koboSpan" id="kobo.379.1"><img alt="Figure 3.9 – Anthropic Claude 3 Haiku – assigning role personas" src="image/B22045_03_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.380.1">Figure 3.9 – Anthropic Claude 3 Haiku – assigning role personas</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.381.1">Providing clear and direct instructions to Claude</span></strong><span class="koboSpan" id="kobo.382.1">: It is always advisable to provide simple, clear </span><a id="_idIndexMarker245"/><span class="koboSpan" id="kobo.383.1">instructions </span><a id="_idIndexMarker246"/><span class="koboSpan" id="kobo.384.1">to the model to generate the desired output. </span><span class="koboSpan" id="kobo.384.2">Adding emphasis to skip any additional content/preamble in the output avoids any unnecessary information in the output. </span><span class="koboSpan" id="kobo.384.3">For instance, take a look at the input prompts in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.385.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.386.1">.10</span></em><span class="koboSpan" id="kobo.387.1">. </span><span class="koboSpan" id="kobo.387.2">One contains an additional sentence on skipping the preamble and the other doesn’t provide any further clarification to the input prompt. </span><span class="koboSpan" id="kobo.387.3">Since the </span><strong class="source-inline"><span class="koboSpan" id="kobo.388.1">Temperature</span></strong><span class="koboSpan" id="kobo.389.1"> parameter can be set to a higher value, the output that’s generated might be different, as shown here. </span><span class="koboSpan" id="kobo.389.2">However, the clear instructions in the latter provide a more direct output without any additional context, as desired by </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">the user:</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer045">
<span class="koboSpan" id="kobo.391.1"><img alt="Figure 3.10 – Providing clear and direct instructions" src="image/B22045_03_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.392.1">Figure 3.10 – Providing clear and direct instructions</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.393.1">Few-shot prompt examples</span></strong><span class="koboSpan" id="kobo.394.1">: Providing </span><a id="_idIndexMarker247"/><span class="koboSpan" id="kobo.395.1">examples (as</span><a id="_idIndexMarker248"/><span class="koboSpan" id="kobo.396.1"> covered in the </span><em class="italic"><span class="koboSpan" id="kobo.397.1">Few-shot prompting</span></em><span class="koboSpan" id="kobo.398.1"> section) of some common scenarios aids in the overall performance gain of the model and generating succinct responses with </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1">proper formatting.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.400.1">XML tags</span></strong><span class="koboSpan" id="kobo.401.1">: Usage of XML tags, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.402.1">&lt;tag&gt;content&lt;/tag&gt;</span></strong><span class="koboSpan" id="kobo.403.1">, can assist in providing a definitive structure in the prompt and the output response. </span><span class="koboSpan" id="kobo.403.2">We can provide additional context and clarification to Claude stating a piece of information can be found within the tags to be leveraged for generating the output. </span><span class="koboSpan" id="kobo.403.3">In such a way, Claude understands how to frame the output response, by extracting the key relevant information from </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">the tags.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.405.1">It’s also recommended to separate the input data from the instructions to generate a more structured prompt for easier and more performant processing by </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">the model.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.407.1">Here’s an example </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">of tags:</span></span></p></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer046">
<span class="koboSpan" id="kobo.409.1"><img alt="Figure 3.11 – XML tags" src="image/B22045_03_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.410.1">Figure 3.11 – XML tags</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.411.1">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.412.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.413.1">.11</span></em><span class="koboSpan" id="kobo.414.1">, we provided a </span><strong class="source-inline"><span class="koboSpan" id="kobo.415.1">&lt;email&gt;</span></strong><span class="koboSpan" id="kobo.416.1"> tag, which generated a more structured </span><a id="_idIndexMarker249"/><span class="koboSpan" id="kobo.417.1">output</span><a id="_idIndexMarker250"/><span class="koboSpan" id="kobo.418.1"> response from </span><span class="No-Break"><span class="koboSpan" id="kobo.419.1">the model.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.420.1">Response limiters and defining the output format</span></strong><span class="koboSpan" id="kobo.421.1">: Anthropic Claude models (especially the 100K and 200K token length models) are capable of providing comprehensive and verbose responses. </span><span class="koboSpan" id="kobo.421.2">The user can limit the response length by explicitly stating the word limit, or character count, as part of the prompt to provide a more succinct and relevant output. </span><span class="koboSpan" id="kobo.421.3">Let’s look at </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">an example:</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer047">
<span class="koboSpan" id="kobo.423.1"><img alt="Figure 3.12 – Response limiters" src="image/B22045_03_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.424.1">Figure 3.12 – Response limiters</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.425.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.426.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.427.1">.12</span></em><span class="koboSpan" id="kobo.428.1">, we have set the response limiter to 100 words as part of the prompt. </span><span class="koboSpan" id="kobo.428.2">Furthermore, specifying the desired output format – be it a list, JSON, paragraph, Markdown, and so on – can lead to more performant and precise output, as desired by the user, which aids in eliminating any irrelevant verbiage from </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">chatty models.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.430.1">Explicit unknown disclaimers</span></strong><span class="koboSpan" id="kobo.431.1">: Providing explicit expressions as disclaimers such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1">If you don't know the answer, respond with the following format – My sincere apologies, I'm not aware of the answer</span></strong><span class="koboSpan" id="kobo.433.1"> can aid in avoiding any form of hallucination from chatty Claude models. </span><span class="koboSpan" id="kobo.433.2">Guardrails </span><a id="_idIndexMarker251"/><span class="koboSpan" id="kobo.434.1">for the</span><a id="_idIndexMarker252"/><span class="koboSpan" id="kobo.435.1"> topics can also be added such that Claude doesn’t respond to unwanted inputs. </span><span class="koboSpan" id="kobo.435.2">This concept will also be discussed in </span><a href="B22045_12.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.436.1">Chapter 12</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.437.1">.</span></span></li>
</ul>
<h2 id="_idParaDest-66"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.438.1">Prompting Mistral models</span></h2>
<p><span class="koboSpan" id="kobo.439.1">Similar to other </span><a id="_idIndexMarker253"/><span class="koboSpan" id="kobo.440.1">models, when</span><a id="_idIndexMarker254"/><span class="koboSpan" id="kobo.441.1"> working with Mistral models, crafting well-designed prompts is crucial to obtaining high-quality and relevant outputs. </span><span class="koboSpan" id="kobo.441.2">Here are some key points to keep in mind while designing the prompts for </span><span class="No-Break"><span class="koboSpan" id="kobo.442.1">Mistral models:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.443.1">Clearly define the task or objective you want the model to accomplish through the prompt. </span><span class="koboSpan" id="kobo.443.2">Are you looking for text classification, summarization, personalization, or </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">something else?</span></span></li>
<li><span class="koboSpan" id="kobo.445.1">Provide relevant context, examples, or background information to ground the model’s understanding before stating the core prompt. </span><span class="koboSpan" id="kobo.445.2">Context helps the model better comprehend </span><span class="No-Break"><span class="koboSpan" id="kobo.446.1">the prompt.</span></span></li>
<li><span class="koboSpan" id="kobo.447.1">Use clear formatting and delimiters such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1">#</span></strong><span class="koboSpan" id="kobo.449.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.450.1">###</span></strong><span class="koboSpan" id="kobo.451.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.452.1">&lt;&lt;&lt; &gt;&gt;&gt;</span></strong><span class="koboSpan" id="kobo.453.1"> to separate different sections of the prompt, such as instructions, examples, and the main query. </span><span class="koboSpan" id="kobo.453.2">This enhances the </span><span class="No-Break"><span class="koboSpan" id="kobo.454.1">prompt’s structure.</span></span></li>
<li><span class="koboSpan" id="kobo.455.1">When possible, demonstrate the desired output through examples in a </span><em class="italic"><span class="koboSpan" id="kobo.456.1">few-shot</span></em><span class="koboSpan" id="kobo.457.1"> learning style. </span><span class="koboSpan" id="kobo.457.2">Showing examples guides the model toward the </span><span class="No-Break"><span class="koboSpan" id="kobo.458.1">expected format.</span></span></li>
<li><span class="koboSpan" id="kobo.459.1">Specify the role the model should take on, such as a customer service agent or technical writer. </span><span class="koboSpan" id="kobo.459.2">Defining a persona makes responses </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">more tailored.</span></span></li>
<li><span class="koboSpan" id="kobo.461.1">For an open-ended</span><a id="_idIndexMarker255"/><span class="koboSpan" id="kobo.462.1"> generation, provide </span><a id="_idIndexMarker256"/><span class="koboSpan" id="kobo.463.1">clear instructions on the desired output length and structure through numeric targets such as word counts or the number </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">of sentences/paragraphs.</span></span></li>
<li><span class="koboSpan" id="kobo.465.1">Ask the model to include confidence scores or assessments when generating outputs to gauge its </span><span class="No-Break"><span class="koboSpan" id="kobo.466.1">certainty levels.</span></span></li>
<li><span class="koboSpan" id="kobo.467.1">Consider chaining multiple Mistral models in a sequence, where the output from one model feeds into the next for </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">enhanced capabilities.</span></span></li>
<li><span class="koboSpan" id="kobo.469.1">Test and iterate on prompt designs through evaluations to find optimal </span><span class="No-Break"><span class="koboSpan" id="kobo.470.1">prompting strategies.</span></span></li>
</ul>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.471.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.472.1">.13</span></em><span class="koboSpan" id="kobo.473.1"> shows the Mixtral 8x7B Instruct model being invoked in Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">Bedrock Playground.</span></span></p>
<p><span class="koboSpan" id="kobo.475.1">Please note that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.476.1">&lt;s&gt;</span></strong><span class="koboSpan" id="kobo.477.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">&lt;/s&gt;</span></strong><span class="koboSpan" id="kobo.479.1"> tokens are utilized to</span><a id="_idIndexMarker257"/><span class="koboSpan" id="kobo.480.1"> denote</span><a id="_idIndexMarker258"/><span class="koboSpan" id="kobo.481.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.482.1">beginning of string</span></strong><span class="koboSpan" id="kobo.483.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.484.1">BOS</span></strong><span class="koboSpan" id="kobo.485.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.486.1">end of string</span></strong><span class="koboSpan" id="kobo.487.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.488.1">EOS</span></strong><span class="koboSpan" id="kobo.489.1">), respectively, signifying the start and conclusion of the text input. </span><span class="koboSpan" id="kobo.489.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1">[INST]</span></strong><span class="koboSpan" id="kobo.491.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.492.1">[/INST]</span></strong><span class="koboSpan" id="kobo.493.1"> strings tell the model that the content enclosed between them constitutes instructions that the model should </span><span class="No-Break"><span class="koboSpan" id="kobo.494.1">adhere to:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer048">
<span class="koboSpan" id="kobo.495.1"><img alt="Figure 3.13 – Prompting the Mixtral 8x7B Instruct model" src="image/B22045_03_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.496.1">Figure 3.13 – Prompting the Mixtral 8x7B Instruct model</span></p>
<p><span class="koboSpan" id="kobo.497.1">The key is to </span><a id="_idIndexMarker259"/><span class="koboSpan" id="kobo.498.1">carefully </span><a id="_idIndexMarker260"/><span class="koboSpan" id="kobo.499.1">structure prompts with clear context, examples, instructions, and formatting to steer Mistral models to generate high-quality, tailored outputs matching </span><span class="No-Break"><span class="koboSpan" id="kobo.500.1">your needs.</span></span></p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.501.1">Prompt guidance for Amazon Titan text models</span></h2>
<p><span class="koboSpan" id="kobo.502.1">As we learned in </span><a href="B22045_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.503.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.504.1">, Amazon</span><a id="_idIndexMarker261"/><span class="koboSpan" id="kobo.505.1"> Titan text </span><a id="_idIndexMarker262"/><span class="koboSpan" id="kobo.506.1">models are well suited for a plethora of </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">use cases:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.508.1">Dialog and </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">roleplay systems</span></span></li>
<li><span class="koboSpan" id="kobo.510.1">Text summarization </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">and Q&amp;A</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.512.1">Machine translation</span></span></li>
<li><span class="koboSpan" id="kobo.513.1">Metadata extraction </span><span class="No-Break"><span class="koboSpan" id="kobo.514.1">and analysis</span></span></li>
<li><span class="koboSpan" id="kobo.515.1">RAG (This will be covered in detail in </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.516.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.517.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.518.1">Code </span><span class="No-Break"><span class="koboSpan" id="kobo.519.1">generation approaches</span></span></li>
<li><span class="koboSpan" id="kobo.520.1">Text and </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">content generation</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.522.1">When generating text outputs with the model, it is often recommended to provide clear instructions on the desired output length and structure to get optimal results. </span><span class="koboSpan" id="kobo.522.2">Here are some additional tips for Titan </span><span class="No-Break"><span class="koboSpan" id="kobo.523.1">text models:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.524.1">Focus prompts on concise, directed questions to get targeted answers </span><span class="No-Break"><span class="koboSpan" id="kobo.525.1">by default.</span></span></li>
<li><span class="koboSpan" id="kobo.526.1">Systems perform best on single sentences or </span><span class="No-Break"><span class="koboSpan" id="kobo.527.1">short paragraphs.</span></span></li>
<li><span class="koboSpan" id="kobo.528.1">For longer inputs, place instructions at the end to guide </span><span class="No-Break"><span class="koboSpan" id="kobo.529.1">high-quality responses.</span></span></li>
<li><span class="koboSpan" id="kobo.530.1">Adding explicit instructions in the prompt produces more </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">tailored results.</span></span></li>
<li><span class="koboSpan" id="kobo.532.1">Specify an exact number of words, sentences, bullet points, or paragraphs you want the AI to generate in the prompt. </span><span class="koboSpan" id="kobo.532.2">Providing a numerical range (for example, 100-200 words) can also work well. </span><span class="koboSpan" id="kobo.532.3">This gives the model a clear target to </span><span class="No-Break"><span class="koboSpan" id="kobo.533.1">aim for.</span></span></li>
<li><span class="koboSpan" id="kobo.534.1">Avoid vague instructions such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.535.1">keep it short</span></strong><span class="koboSpan" id="kobo.536.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.537.1">summarize briefly</span></strong><span class="koboSpan" id="kobo.538.1">. </span><span class="koboSpan" id="kobo.538.2">These are open to interpretation by the AI. </span><span class="koboSpan" id="kobo.538.3">Precise numbers </span><span class="No-Break"><span class="koboSpan" id="kobo.539.1">remove ambiguity.</span></span></li>
<li><span class="koboSpan" id="kobo.540.1">Word count alone may not sufficiently guide output length as sentence lengths can vary. </span><span class="koboSpan" id="kobo.540.2">Specifying the number of sentences/paragraphs provides more </span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">robust control.</span></span></li>
<li><span class="koboSpan" id="kobo.542.1">If the model seems unable to generate a quality response for a prompt, program it to default to a message such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.543.1">Unsure about answer</span></strong><span class="koboSpan" id="kobo.544.1"> rather than attempt to force a poor response. </span><span class="koboSpan" id="kobo.544.2">Here’s an example of such a prompt: </span><strong class="source-inline"><span class="koboSpan" id="kobo.545.1">Tell me about Quantum Computing. </span><span class="koboSpan" id="kobo.545.2">Respond with Unsure about the answer or I don't know in case you are not sure about the question </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.546.1">being asked</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.547.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.548.1">When relevant, provide context paragraphs for the AI to reference before asking a question. </span><span class="koboSpan" id="kobo.548.2">This provides knowledge for an </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">informed response.</span></span></li>
<li><span class="koboSpan" id="kobo.550.1">Test different output length instructions to find the right balance between conciseness and adequate detail for your use case. </span><span class="koboSpan" id="kobo.550.2">Err on the side of more specificity </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">with numbers.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.552.1">You can go back </span><a id="_idIndexMarker263"/><span class="koboSpan" id="kobo.553.1">to</span><a id="_idIndexMarker264"/><span class="koboSpan" id="kobo.554.1"> the </span><em class="italic"><span class="koboSpan" id="kobo.555.1">Amazon Titan FMs</span></em><span class="koboSpan" id="kobo.556.1"> section in </span><a href="B22045_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.557.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.558.1"> if you wish to look at example prompts and responses in </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">Titan models.</span></span></p>
<h2 id="_idParaDest-68"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.560.1">AI21 Labs – instruct models</span></h2>
<p><span class="koboSpan" id="kobo.561.1">AI21 Labs models work v</span><a id="_idIndexMarker265"/><span class="koboSpan" id="kobo.562.1">ery well with languages</span><a id="_idIndexMarker266"/><span class="koboSpan" id="kobo.563.1"> other than English, such as Spanish, French, German, Portuguese, Italian, and Dutch. </span><span class="koboSpan" id="kobo.563.2">The model is proficient in text summarization, text generation, and Q&amp;A tasks. </span><span class="koboSpan" id="kobo.563.3">In this section, we will walk through a few key concepts to be inculcated with AI21 models available via </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">Amazon Bedrock:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.565.1">Output length</span></strong><span class="koboSpan" id="kobo.566.1">: To generate desirable responses from AI12 models, it is advisable to specify the output length – that is, the number of paragraphs, items, and so on or an approximation of the same – instead of </span><span class="No-Break"><span class="koboSpan" id="kobo.567.1">using words/characters.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.568.1">Provide short yet detailed task descriptions</span></strong><span class="koboSpan" id="kobo.569.1">: Craft clear, detailed task descriptions to minimize ambiguity. </span><span class="koboSpan" id="kobo.569.2">AI21 models excel at following precise instructions for even </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">complex jobs.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.571.1">Avoid negative prompting</span></strong><span class="koboSpan" id="kobo.572.1">: Directly state the target outcome. </span><span class="koboSpan" id="kobo.572.2">Avoid negatives such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.573.1">no more than x statements</span></strong><span class="koboSpan" id="kobo.574.1">. </span><span class="koboSpan" id="kobo.574.2">It is always recommended to state requirements directly </span><span class="No-Break"><span class="koboSpan" id="kobo.575.1">and affirmatively.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.576.1">Header usage</span></strong><span class="koboSpan" id="kobo.577.1">: Provide context upfront using an </span><strong class="source-inline"><span class="koboSpan" id="kobo.578.1">Instruction:</span></strong><span class="koboSpan" id="kobo.579.1"> header to clarify the prompt. </span><span class="koboSpan" id="kobo.579.2">Separate prompt sections with newlines to highlight distinct pieces and for </span><span class="No-Break"><span class="koboSpan" id="kobo.580.1">readability purposes.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.581.1">Evaluate multiple prompting patterns</span></strong><span class="koboSpan" id="kobo.582.1">: Try both zero-shot and few-shot learning. </span><span class="koboSpan" id="kobo.582.2">Pick an ideal approach for your use case. </span><span class="koboSpan" id="kobo.582.3">For instance, as depicted in the zero-shot and few-shot examples shown in this chapter, depending on the use case under consideration, you may initiate by providing zero examples and determining the response, and simultaneously compare the response generated from the model </span><a id="_idIndexMarker267"/><span class="koboSpan" id="kobo.583.1">after providing </span><a id="_idIndexMarker268"/><span class="koboSpan" id="kobo.584.1">certain examples to guide the output. </span><span class="koboSpan" id="kobo.584.2">In some cases, there may not be a need to provide a ton of examples if the model can generate a </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">desirable response.</span></span></li>
</ul>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.586.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.587.1">.14</span></em><span class="koboSpan" id="kobo.588.1"> depicts a product description summarization example from AI21 Jurassic-2 Ultra within </span><span class="No-Break"><span class="koboSpan" id="kobo.589.1">Amazon Bedrock:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer049">
<span class="koboSpan" id="kobo.590.1"><img alt="Figure 3.14 – Prompting the AI21 Jurassic-2 Ultra model" src="image/B22045_03_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.591.1">Figure 3.14 – Prompting the AI21 Jurassic-2 Ultra model</span></p>
<p><span class="koboSpan" id="kobo.592.1">Further details on</span><a id="_idIndexMarker269"/><span class="koboSpan" id="kobo.593.1"> prompt engineering and design</span><a id="_idIndexMarker270"/><span class="koboSpan" id="kobo.594.1"> with AI21 models, along with examples, can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">at </span></span><a href="https://docs.ai21.com/docs/prompt-engineering"><span class="No-Break"><span class="koboSpan" id="kobo.596.1">https://docs.ai21.com/docs/prompt-engineering</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.597.1">.</span></span></p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.598.1">Prompting Meta Llama models</span></h2>
<p><span class="koboSpan" id="kobo.599.1">Similar to any other </span><a id="_idIndexMarker271"/><span class="koboSpan" id="kobo.600.1">LLM, effective </span><a id="_idIndexMarker272"/><span class="koboSpan" id="kobo.601.1">prompting is essential for getting the most out of Llama models. </span><span class="koboSpan" id="kobo.601.2">Since the following is standard prompt guidance for any LLM, we will cover some of the best </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">practices here:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.603.1">Clarity </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.604.1">and specificity</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">:</span></span><ul><li><span class="koboSpan" id="kobo.606.1">Ensure that your prompts are clear, concise, </span><span class="No-Break"><span class="koboSpan" id="kobo.607.1">and unambiguous</span></span></li><li><span class="koboSpan" id="kobo.608.1">Provide sufficient context and details to guide the model toward the </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1">desired output</span></span></li><li><span class="koboSpan" id="kobo.610.1">Use precise language and avoid vague or </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">open-ended statements</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.612.1">Structure </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.613.1">and formatting</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">:</span></span><ul><li><span class="koboSpan" id="kobo.615.1">Organize your prompts logically and structure them in a way that aligns with the desired </span><span class="No-Break"><span class="koboSpan" id="kobo.616.1">output format</span></span></li><li><span class="koboSpan" id="kobo.617.1">Utilize formatting elements such as bullet points, numbered lists, or headings to enhance readability </span><span class="No-Break"><span class="koboSpan" id="kobo.618.1">and comprehension</span></span></li><li><span class="koboSpan" id="kobo.619.1">Consider providing examples or templates to illustrate the expected format of </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">the output</span></span></li></ul></li>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.621.1">Task framing</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.622.1">:</span></span><ul><li><span class="koboSpan" id="kobo.623.1">Frame your</span><a id="_idIndexMarker273"/><span class="koboSpan" id="kobo.624.1"> prompts</span><a id="_idIndexMarker274"/><span class="koboSpan" id="kobo.625.1"> as specific tasks or instructions for the model </span><span class="No-Break"><span class="koboSpan" id="kobo.626.1">to follow</span></span></li><li><span class="koboSpan" id="kobo.627.1">Clearly specify the desired action, such as summarizing, generating, </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">or analyzing</span></span></li><li><span class="koboSpan" id="kobo.629.1">Provide context about the intended use case or audience for </span><span class="No-Break"><span class="koboSpan" id="kobo.630.1">the output</span></span></li></ul></li>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.631.1">Iterative refinement</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">:</span></span><ul><li><span class="koboSpan" id="kobo.633.1">Prompting is an iterative process, and you may need to refine your prompts based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.634.1">model’s responses</span></span></li><li><span class="koboSpan" id="kobo.635.1">Analyze the output and identify areas for improvement </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">or clarification</span></span></li><li><span class="koboSpan" id="kobo.637.1">Incorporate feedback and adjust the prompt accordingly to steer the model toward </span><span class="No-Break"><span class="koboSpan" id="kobo.638.1">better results</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.639.1">Fine-tuning </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.640.1">and customization</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.641.1">:</span></span><ul><li><span class="koboSpan" id="kobo.642.1">Explore the possibility of fine-tuning the Llama model on domain-specific data </span><span class="No-Break"><span class="koboSpan" id="kobo.643.1">or examples</span></span></li><li><span class="koboSpan" id="kobo.644.1">Customize the model’s behavior and outputs by incorporating specific instructions or constraints in </span><span class="No-Break"><span class="koboSpan" id="kobo.645.1">the prompt</span></span></li><li><span class="koboSpan" id="kobo.646.1">Leverage techniques such as prompting with few-shot examples or demonstrations to </span><span class="No-Break"><span class="koboSpan" id="kobo.647.1">improve performance</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.648.1">Ethical and </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.649.1">safety considerations</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.650.1">:</span></span><ul><li><span class="koboSpan" id="kobo.651.1">Be mindful of potential biases or harmful outputs that the model </span><span class="No-Break"><span class="koboSpan" id="kobo.652.1">could generate</span></span></li><li><span class="koboSpan" id="kobo.653.1">Incorporate explicit instructions or filters to mitigate risks and ensure the model’s responses align with ethical and </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">safety guidelines</span></span></li><li><span class="koboSpan" id="kobo.655.1">Monitor and evaluate the model’s outputs for any concerning or </span><span class="No-Break"><span class="koboSpan" id="kobo.656.1">inappropriate content</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.657.1">Llama models also</span><a id="_idIndexMarker275"/><span class="koboSpan" id="kobo.658.1"> consider </span><a id="_idIndexMarker276"/><span class="koboSpan" id="kobo.659.1">special kinds of tokens. </span><span class="koboSpan" id="kobo.659.2">For Llama 3, the following tokens </span><span class="No-Break"><span class="koboSpan" id="kobo.660.1">are used:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.661.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.662.1">&lt;|begin_of_text|&gt;</span></strong><span class="koboSpan" id="kobo.663.1"> token represents the </span><span class="No-Break"><span class="koboSpan" id="kobo.664.1">BOS token.</span></span></li>
<li><span class="koboSpan" id="kobo.665.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.666.1">&lt;|eot_id|&gt;</span></strong><span class="koboSpan" id="kobo.667.1"> token indicates the end of the current turn </span><span class="No-Break"><span class="koboSpan" id="kobo.668.1">or message.</span></span></li>
<li><span class="koboSpan" id="kobo.669.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.670.1">&lt;|start_header_id|&gt;{role}&lt;|end_header_id|&gt;</span></strong><span class="koboSpan" id="kobo.671.1"> token encloses the role for a particular message, which can be either </span><strong class="bold"><span class="koboSpan" id="kobo.672.1">system</span></strong><span class="koboSpan" id="kobo.673.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.674.1">user</span></strong><span class="koboSpan" id="kobo.675.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.676.1">or </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.677.1">assistant</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.678.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.679.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.680.1">&lt;|end_of_text|&gt;</span></strong><span class="koboSpan" id="kobo.681.1"> token is equivalent to the EOS token. </span><span class="koboSpan" id="kobo.681.2">Upon generating this token, Llama 3 will stop producing any </span><span class="No-Break"><span class="koboSpan" id="kobo.682.1">further tokens.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.683.1">For more details on prompt formats, go </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">to </span></span><a href="https://llama.meta.com/docs/model-cards-and-prompt-formats"><span class="No-Break"><span class="koboSpan" id="kobo.685.1">https://llama.meta.com/docs/model-cards-and-prompt-formats</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.686.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer050">
<span class="koboSpan" id="kobo.687.1"><img alt="Figure 3.15 – Prompting the Llama2 Chat 70B model" src="image/B22045_03_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.688.1">Figure 3.15 – Prompting the Llama2 Chat 70B model</span></p>
<p><span class="koboSpan" id="kobo.689.1">As shown </span><a id="_idIndexMarker277"/><span class="koboSpan" id="kobo.690.1">in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.691.1">Figure 3</span></em></span><em class="italic"><span class="koboSpan" id="kobo.692.1">.15</span></em><span class="koboSpan" id="kobo.693.1">, the</span><a id="_idIndexMarker278"/><span class="koboSpan" id="kobo.694.1"> Llama 2 Chat 70B model is being invoked in Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.695.1">Bedrock Playground.</span></span></p>
<p><span class="koboSpan" id="kobo.696.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.697.1">[INST]</span></strong><span class="koboSpan" id="kobo.698.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.699.1">[/INST]</span></strong><span class="koboSpan" id="kobo.700.1"> strings tell the model that the content enclosed between them constitutes instructions that the model should </span><span class="No-Break"><span class="koboSpan" id="kobo.701.1">adhere to.</span></span></p>
<p><span class="koboSpan" id="kobo.702.1">If you’d like to learn about the different examples and templates for invoking various models, including any new models being added to Amazon Bedrock, go </span><span class="No-Break"><span class="koboSpan" id="kobo.703.1">to </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-templates-and-examples.html"><span class="No-Break"><span class="koboSpan" id="kobo.704.1">https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-templates-and-examples.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.705.1">.</span></span></p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.706.1">Prompt guidance for Stability AI – Stable Diffusion</span></h2>
<p><span class="koboSpan" id="kobo.707.1">Stable Diffusion</span><a id="_idIndexMarker279"/><span class="koboSpan" id="kobo.708.1"> models (along with Amazon Titan image models) have been gaining popularity</span><a id="_idIndexMarker280"/><span class="koboSpan" id="kobo.709.1"> in image generation use cases.  </span><span class="koboSpan" id="kobo.709.2">Here are some key tips for crafting effective prompts when using Stability AI’s Stable Diffusion for </span><span class="No-Break"><span class="koboSpan" id="kobo.710.1">image generation:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.711.1">Specify the subject clearly</span></strong><span class="koboSpan" id="kobo.712.1">: Start your prompt with a clear description of the desired subject or main element of the image – for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.713.1">A photo of a cat</span></strong><span class="koboSpan" id="kobo.714.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.715.1">An illustration of a robot</span></strong><span class="koboSpan" id="kobo.716.1">. </span><span class="koboSpan" id="kobo.716.2">Being more specific usually produces </span><span class="No-Break"><span class="koboSpan" id="kobo.717.1">better results.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.718.1">Indicate the style</span></strong><span class="koboSpan" id="kobo.719.1">: After the subject, specify the desired art style, medium, or aesthetic, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.720.1">in impressionist style</span></strong><span class="koboSpan" id="kobo.721.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.722.1">a cartoon drawing of</span></strong><span class="koboSpan" id="kobo.723.1">. </span><span class="koboSpan" id="kobo.723.2">Styles help steer </span><span class="No-Break"><span class="koboSpan" id="kobo.724.1">the output.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.725.1">Use text weights</span></strong><span class="koboSpan" id="kobo.726.1">: Give elements different emphasis by assigning weights, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.727.1">cat:1.5, sitting:1.2, couch:1</span></strong><span class="koboSpan" id="kobo.728.1">. </span><span class="koboSpan" id="kobo.728.2">Higher weights make elements </span><span class="No-Break"><span class="koboSpan" id="kobo.729.1">more prominent.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.730.1">Add negative prompts</span></strong><span class="koboSpan" id="kobo.731.1">: Adding phrases that should not appear in the image, prefixed by </span><strong class="source-inline"><span class="koboSpan" id="kobo.732.1">-</span></strong><span class="koboSpan" id="kobo.733.1">, improves quality by excluding unwanted elements. </span><span class="koboSpan" id="kobo.733.2">For example, if you provide </span><strong class="source-inline"><span class="koboSpan" id="kobo.734.1">Cars racing on racetrack</span></strong><span class="koboSpan" id="kobo.735.1"> as a prompt and give </span><strong class="source-inline"><span class="koboSpan" id="kobo.736.1">red car</span></strong><span class="koboSpan" id="kobo.737.1"> as a negative prompt, it will exclude red cars from the image’s output, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.738.1">Figure 3</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.739.1">.16</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.740.1">:</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer051">
<span class="koboSpan" id="kobo.741.1"><img alt="Figure 3.16 – Negative prompt example" src="image/B22045_03_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.742.1">Figure 3.16 – Negative prompt example</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.743.1">Be detailed and specific</span></strong><span class="koboSpan" id="kobo.744.1">: Using more descriptive and distinctive words, rather than general terms, produces more </span><span class="No-Break"><span class="koboSpan" id="kobo.745.1">tailored results.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.746.1">Adjust parameters</span></strong><span class="koboSpan" id="kobo.747.1">: Parameters such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.748.1">--ar</span></strong><span class="koboSpan" id="kobo.749.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.750.1">--v</span></strong><span class="koboSpan" id="kobo.751.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.752.1">--n</span></strong><span class="koboSpan" id="kobo.753.1"> control the aspect ratio, vividness, and level of detail, respectively. </span><span class="koboSpan" id="kobo.753.2">Tweak them to refine </span><span class="No-Break"><span class="koboSpan" id="kobo.754.1">the output.</span></span></li>
<li><span class="koboSpan" id="kobo.755.1">Providing additional descriptive details always aids the model in being more performant. </span><span class="koboSpan" id="kobo.755.2">The following are examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">such aspects:</span></span><ul><li><span class="koboSpan" id="kobo.757.1">Specify</span><a id="_idIndexMarker281"/><span class="koboSpan" id="kobo.758.1"> the </span><a id="_idIndexMarker282"/><span class="koboSpan" id="kobo.759.1">medium (painting, drawing, CGI, and </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">so on)</span></span></li><li><span class="koboSpan" id="kobo.761.1">Define </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">colors used</span></span></li><li><span class="koboSpan" id="kobo.763.1">Describe lighting </span><span class="No-Break"><span class="koboSpan" id="kobo.764.1">and shadows</span></span></li><li><span class="koboSpan" id="kobo.765.1">Include the artist’s name if mimicking </span><span class="No-Break"><span class="koboSpan" id="kobo.766.1">a style</span></span></li><li><span class="koboSpan" id="kobo.767.1">Mention the website if you’re reproducing a </span><span class="No-Break"><span class="koboSpan" id="kobo.768.1">specific image</span></span></li><li><span class="koboSpan" id="kobo.769.1">Add any other descriptive remarks </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">or adjectives</span></span></li><li><span class="koboSpan" id="kobo.771.1">Specify the desired resolution if needed for print or </span><span class="No-Break"><span class="koboSpan" id="kobo.772.1">digital use</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.773.1">Let’s look at </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1">an example.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.775.1">Prompt</span></strong><span class="koboSpan" id="kobo.776.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.777.1">Portrait photo of an Indian old warrior chief, tribal panther make up, front profile, looking straight into the camera, serious eyes, 50mm portrait photography, hard rim lighting photography–beta –ar </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.778.1">2:3 –beta</span></strong></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.779.1">Output response from </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.780.1">SDXL 1.0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.781.1">:</span></span></p>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<span class="koboSpan" id="kobo.782.1"><img alt="Figure 3.17 – Image generation output from SDXL 1.0" src="image/B22045_03_17.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.783.1">Figure 3.17 – Image generation output from SDXL 1.0</span></p>
<p><span class="koboSpan" id="kobo.784.1">When prompted </span><a id="_idIndexMarker283"/><span class="koboSpan" id="kobo.785.1">with the </span><a id="_idIndexMarker284"/><span class="koboSpan" id="kobo.786.1">same input, the output response from the Titan Image Generator G1 model is </span><span class="No-Break"><span class="koboSpan" id="kobo.787.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer053">
<span class="koboSpan" id="kobo.788.1"><img alt="Figure 3.18 – Image generation output from Titan Image Generator" src="image/B22045_03_18.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.789.1">Figure 3.18 – Image generation output from Titan Image Generator</span></p>
<p><span class="koboSpan" id="kobo.790.1">Providing this level of detail and context will help produce a more accurate image that matches your vision. </span><span class="koboSpan" id="kobo.790.2">Adjust prompts iteratively to </span><span class="No-Break"><span class="koboSpan" id="kobo.791.1">refine results.</span></span></p>
<p><span class="koboSpan" id="kobo.792.1">You might be wondering why the same prompt generated different outputs from two models. </span><span class="koboSpan" id="kobo.792.2">The reason for this is that SDXL is trained on a different set of data than Titan Image Generator, so the output you will see from these models will differ. </span><span class="koboSpan" id="kobo.792.3">Think of it this way: SDXL and Titan are two people, who learn from two different books for an exam. </span><span class="koboSpan" id="kobo.792.4">During the exam, when they were asked the same question, they would have two different viewpoints, and their answer would be based on the books </span><span class="No-Break"><span class="koboSpan" id="kobo.793.1">they read.</span></span></p>
<p><span class="koboSpan" id="kobo.794.1">If you are trying these prompts in your environment, you might also notice another thing. </span><span class="koboSpan" id="kobo.794.2">The output image that you are seeing in your environment might differ from the one shown here, even if you provide the same prompts. </span><span class="koboSpan" id="kobo.794.3">The reason for this is to do with the added degree of randomness. </span><span class="koboSpan" id="kobo.794.4">These models will generate output based on the inference parameters, such as </span><em class="italic"><span class="koboSpan" id="kobo.795.1">Prompt Strength</span></em><span class="koboSpan" id="kobo.796.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.797.1">Seed</span></em><span class="koboSpan" id="kobo.798.1">. </span><span class="koboSpan" id="kobo.798.2">We will cover these parameters in detail in </span><a href="B22045_09.xhtml#_idTextAnchor171"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.799.1">Chapter 9</span></em></span></a><span class="koboSpan" id="kobo.800.1">. </span><span class="koboSpan" id="kobo.800.2">However, in short, prompt strength controls how you want the model output to be influenced by the prompt, and the seed is a way to randomize an </span><span class="No-Break"><span class="koboSpan" id="kobo.801.1">output image.</span></span></p>
<p><span class="koboSpan" id="kobo.802.1">Now that you have a good understanding of prompt guidance for FMs provided by </span><a id="_idIndexMarker285"/><span class="koboSpan" id="kobo.803.1">Amazon </span><a id="_idIndexMarker286"/><span class="koboSpan" id="kobo.804.1">Bedrock, in the next section, we will try to sum up some of the key principles and techniques you must follow when it comes to prompt engineering in various </span><span class="No-Break"><span class="koboSpan" id="kobo.805.1">use cases.</span></span></p>
<h1 id="_idParaDest-71"><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.806.1">Understanding best practices in prompt engineering</span></h1>
<p><span class="koboSpan" id="kobo.807.1">To summarize, when</span><a id="_idIndexMarker287"/><span class="koboSpan" id="kobo.808.1"> crafting prompts, you must adhere to the following </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">key principles:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.810.1">Tailor prompts to your model</span></strong><span class="koboSpan" id="kobo.811.1">: Prompts can contain instructions, context, input, and output indicators. </span><span class="koboSpan" id="kobo.811.2">Account for factors such as model size, input data, moderation policies, and more. </span><span class="koboSpan" id="kobo.811.3">What works for one model may fail </span><span class="No-Break"><span class="koboSpan" id="kobo.812.1">for another:</span></span><ul><li><span class="koboSpan" id="kobo.813.1">Be clear, concise, and straightforward to avoid </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">any ambiguity.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.815.1">Output usage in the prompt</span></em><span class="koboSpan" id="kobo.816.1">: It is often useful to mention the requested output at the end of the prompt – for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.817.1">What are the use cases of renewable resources? </span><span class="koboSpan" id="kobo.817.2">List 5 </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.818.1">key points</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.819.1">.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.820.1">Language emphasis</span></em><span class="koboSpan" id="kobo.821.1">: Using simple flowing language with coherent sentences assists in crafting a better prompt and avoiding </span><span class="No-Break"><span class="koboSpan" id="kobo.822.1">isolated phrases.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.823.1">Get into the model’s head</span></em><span class="koboSpan" id="kobo.824.1">: Craft prompts to nudge it toward helpful behaviors. </span><span class="koboSpan" id="kobo.824.2">Think of it as someone who has all the right answers but only for correctly </span><span class="No-Break"><span class="koboSpan" id="kobo.825.1">articulated questions.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.826.1">Iteratively refine prompts</span></strong><span class="koboSpan" id="kobo.827.1">: Treat initial prompts as hypotheses and revise them based on model output. </span><span class="koboSpan" id="kobo.827.2">The best prompts emerge through an </span><span class="No-Break"><span class="koboSpan" id="kobo.828.1">ongoing give-and-take:</span></span><ul><li><em class="italic"><span class="koboSpan" id="kobo.829.1">Use directives</span></em><span class="koboSpan" id="kobo.830.1">: If you want the output to be in a particular form, specify it directly within the prompt – for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.831.1">Summarize the chapter in </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.832.1">500 words</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.833.1">.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.834.1">Provide example responses</span></em><span class="koboSpan" id="kobo.835.1">: Adding some example responses within the prompt with the expected output can refine the responses more desirably – for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.836.1">Summarize this chapter in one paragraph (1000 characters): [New study shows decreasing activity in region X leads to impairment.]</span></strong><span class="koboSpan" id="kobo.837.1">. </span><span class="koboSpan" id="kobo.837.2">Surrounding the example response in brackets indicates the model adheres to the guidelines set </span><a id="_idIndexMarker288"/><span class="koboSpan" id="kobo.838.1">by the user while responding in the </span><span class="No-Break"><span class="koboSpan" id="kobo.839.1">desired format.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.840.1">Add constraints</span></em><span class="koboSpan" id="kobo.841.1">: Constraining prompt responses by format, additional information inclusion, length, and more can lead to more </span><span class="No-Break"><span class="koboSpan" id="kobo.842.1">controlled output.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.843.1">Strike the right detail balance</span></strong><span class="koboSpan" id="kobo.844.1">: Too little detail fails to guide the model adequately while excessive verbosity limits creative flourishes. </span><span class="koboSpan" id="kobo.844.2">Distill prompts down to </span><span class="No-Break"><span class="koboSpan" id="kobo.845.1">concise essence:</span></span><ul><li><em class="italic"><span class="koboSpan" id="kobo.846.1">Complex </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.847.1">task handling</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.848.1">:</span></span><ul><li><span class="koboSpan" id="kobo.849.1">FMs can hallucinate when dealing with complex tasks. </span><span class="koboSpan" id="kobo.849.2">It is advisable to break down the complex task into subtasks or even consider splitting complex tasks into </span><span class="No-Break"><span class="koboSpan" id="kobo.850.1">multiple prompts.</span></span></li><li><span class="koboSpan" id="kobo.851.1">Provide emphasis by using keywords to ask the model to think step-by-step or provide logical reasoning as it is crafting the output. </span><span class="koboSpan" id="kobo.851.2">Provide some key examples in the input for </span><span class="No-Break"><span class="koboSpan" id="kobo.852.1">complex tasks.</span></span></li></ul></li><li><em class="italic"><span class="koboSpan" id="kobo.853.1">Rinse, lather, repeat</span></em><span class="koboSpan" id="kobo.854.1">: Iteratively break down and try different prompts to optimize model responses for your goals. </span><span class="koboSpan" id="kobo.854.2">Continue adjusting while testing and experimenting to achieve the </span><span class="No-Break"><span class="koboSpan" id="kobo.855.1">desired results.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.856.1">Continuous evaluation</span></em><span class="koboSpan" id="kobo.857.1">: Iteratively reviewing the model’s responses to provide the desired quality is a must when it comes to handling different use cases and </span><span class="No-Break"><span class="koboSpan" id="kobo.858.1">complex scenarios.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.859.1">Prompts unlock Generative AI’s capabilities but require thoughtfulness to construct properly. </span><span class="koboSpan" id="kobo.859.2">Learn your target model’s strengths and limitations, iterate carefully on prompt phrasings, and appreciate these systems’ ever-evolving nature. </span><span class="koboSpan" id="kobo.859.3">Wield prompts judiciously and enjoy the fruits of AI’s </span><span class="No-Break"><span class="koboSpan" id="kobo.860.1">burgeoning creativity!</span></span></p>
<p><span class="koboSpan" id="kobo.861.1">Complexity arises in structuring the right prompts to handle intricate goals. </span><span class="koboSpan" id="kobo.861.2">But when done well, prompts unlock AI like a skeleton key, opening doors to breathtaking new generative</span><a id="_idIndexMarker289"/><span class="koboSpan" id="kobo.862.1"> capabilities. </span><span class="koboSpan" id="kobo.862.2">The prompt contains the potential; our role is to shape and guide it with </span><span class="No-Break"><span class="koboSpan" id="kobo.863.1">thoughtful prompts.</span></span></p>
<h1 id="_idParaDest-72"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.864.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.865.1">In this chapter, we learned about several prompt engineering techniques to gain a deeper understanding of prompting patterns and uncovered insights while considering examples of said prompting patterns. </span><span class="koboSpan" id="kobo.865.2">Then, we dived into prompt guidance with Amazon Bedrock models for Anthropic Claude, AI21 Labs, Amazon Titan, and Stability AI’s </span><span class="No-Break"><span class="koboSpan" id="kobo.866.1">Stable Diffusion.</span></span></p>
<p><span class="koboSpan" id="kobo.867.1">Lastly, we summarized the practical approach to prompt guidance while looking at Amazon Bedrock models that can be applied to various use cases. </span><span class="koboSpan" id="kobo.867.2">Through various examples, we learned how to craft the most </span><span class="No-Break"><span class="koboSpan" id="kobo.868.1">effective prompts.</span></span></p>
<p><span class="koboSpan" id="kobo.869.1">At this point, you should have a good understanding of the importance of prompt engineering. </span><span class="koboSpan" id="kobo.869.2">Furthermore, you should be able to analyze various prompt techniques and best practices involved in prompt engineering in the context of building Generative </span><span class="No-Break"><span class="koboSpan" id="kobo.870.1">AI applications.</span></span></p>
<p><span class="koboSpan" id="kobo.871.1">In the next chapter, we’ll learn how to customize a model using fine-tuning and continued pretraining techniques. </span><span class="koboSpan" id="kobo.871.2">We will delve into how fine-tuning works, look at various APIs, analyze the results, and perform inference on our </span><span class="No-Break"><span class="koboSpan" id="kobo.872.1">fine-tuned model.</span></span></p>
</div>
</body></html>