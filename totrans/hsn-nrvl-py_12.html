<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Co-Evolution and the SAFE Method</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In this chapter, we introduce the concept of co-evolution and explain how it can be used to co-evolve the solver and the objective function that optimizes the evolution of the solver. We then discuss the <strong>Solution and Fitness Evolution</strong> (<strong>SAFE</strong>) method and provide a brief overview of different co-evolution strategies. You will learn how to use co-evolution with neuroevolution-based methods. You will also get practical experience with the implementation of a modified maze-solving experiment.</span></p>
<p class="p1"><span class="s1">In this chapter, we will cover the following topics:</span></p>
<ul class="ul1">
<li class="li1"><span class="s1">Co-evolution basics and common co-evolution strategies</span></li>
<li class="li1"><span class="s1">SAFE method basics</span></li>
<li class="li1"><span class="s1">Modified maze-solving experiment</span></li>
<li class="li1"><span class="s1">Discussion about the results of the experiment</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">The following technical requirements should be met to execute the experiments described in this chapter:</span></p>
<ul class="ul1">
<li class="li3"><span class="s1">Windows 8/10, macOS 10.13 or newer, or modern Linux</span></li>
<li class="li3"><span class="s1">Anaconda Distribution version 2019.03 or newer</span></li>
</ul>
<p>The code for this chapter can be found at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter9">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter9</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Common co-evolution strategies</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">The natural evolution of biological systems cannot be considered separately from the concept of co-evolution. Co-evolution is one of the central evolutionary drives that leads to the current state of the biosphere, with the diversity of organisms that we can perceive around us.</span></p>
<p class="p3"><span class="s1">We can define co-evolution as a mutually beneficial strategy of the simultaneous evolution of multiple genealogies of different organisms. The evolution of one species cannot be possible without other species. During evolution, the co-evolving species mutually interact, and these inter-species relations shape their evolutionary strategy.</span></p>
<p class="p1"><span class="s1">There are three main types of co-evolution:</span></p>
<ul class="ul1">
<li class="li1"><span class="s1"><strong>Mutualism</strong> is when two or more species coexist and mutually benefit each other.</span></li>
<li class="li1"><span class="s1"><strong>Competitive co-evolution</strong>:</span>
<ul class="ul1">
<li class="li1"><span class="s1"><strong>Predation</strong> is when one organism kills another and consumes its resources.</span></li>
<li class="li1"><span class="s1"><strong>Parasitism</strong> is when one organism exploits the resources of another but does not kill it.</span></li>
</ul>
</li>
<li class="li1"><span class="s1"><strong>Commensalism</strong> is when the members of one species benefit from another species without causing harm or benefits to the other species.</span></li>
</ul>
<p class="p1"><span class="s1">Each type of co-evolution strategy has been explored by researchers, and they have pros and cons for use as guiding principles of the neuroevolution process. However, a group of researchers recently explored the commensalism strategy as a guiding principle for neuroevolution and achieved promising results. They created the</span> SAFE<span class="s1"> algorithm, which we will discuss in this chapter.</span></p>
<div class="p1 packt_infobox"><span class="s1">For more details on the SAFE algorithm, please refer to the original publication at <a href="https://doi.org/10.1007/978-3-030-16670-0_10"><span class="s2">https://doi.org/10.1007/978-3-030-16670-0_10</span></a>.</span></div>
<p>Now that we have covered the common types of co-evolution, let's discuss the SAFE method in detail.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SAFE method</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">As the name suggests, the SAFE method is about the co-evolution of the solution and the fitness function, which guides the solution search optimization. The SAFE method is built around the <em>commensalistic</em> co-evolution strategy of two populations:</span></p>
<ul>
<li class="p1"><span class="s1">The population of potential solutions, which evolve to solve the problem at hand</span></li>
<li class="p1"><span class="s1">The population of objective function candidates, which evolve to guide the evolution of the solution population</span></li>
</ul>
<p class="p1"><span class="s1">In this book, we have already discussed several search optimization strategies that can be used to guide the evolution of potential solution candidates. These strategies are objective-based fitness optimization and Novelty Search optimization. The former optimization strategy is perfect in situations when we have a plain fitness function landscape and can concentrate our optimization search on the ultimate goal. In this case, we can use the objective-based metric, which evaluates, in each epoch of evolution, how close our current solution is to the destination.</span></p>
<p class="p1"><span class="s1">The Novelty Search optimization strategy is different. In this strategy, we are not interested in the proximity to the ultimate goal, but instead, we are concerned mostly about the path that the candidate solutions take. The central idea behind the Novelty Search method is to gradually explore the stepping stones, which finally lead to the destination. This optimization strategy is ideal for situations in which we have an intricate fitness function landscape with many deceptive dead ends and local optima.</span></p>
<p class="p1"><span class="s1">Thus, the main idea behind the SAFE method is to benefit from both search optimization methods mentioned here. Hereafter, we will discuss the modified maze experiment, which uses both search optimization methods mentioned here to guide the neuroevolution process.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modified maze experiment</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">We have already discussed in this book how to apply either the objective-based search optimization or Novelty Search optimization methods to the problem of solving a maze. In this chapter, we introduce a modified maze-solving experiment in which we try to combine both search optimization methods using the SAFE algorithm.</span></p>
<p class="p1"><span class="s1">We introduce the co-evolution of two populations: a population of maze-solving agents and a population of objective function candidates. Following the SAFE method, we use a commensalistic co-evolution strategy in our experiment. Let's first discuss the maze-solving agent.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The maze-solving agent</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">The maze-solving agent is equipped with a set of sensors, allowing it to perceive the maze environment and to know the direction to the maze exit at each step. The configuration of the sensors is shown in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-799 image-border" src="assets/2fa62210-89a3-4c3e-83eb-2ea33a48e645.png" style="width:15.33em;height:15.25em;"/></p>
<div class="p1 packt_figref CDPAlignCenter CDPAlign"><span class="s1">The maze-solving agent's sensor configuration</span></div>
<p class="p1"><span class="s1">In the preceding diagram, the dark arrows define the range-finder sensors allowing the agent to perceive obstacles and find the distance to the obstacle in the given direction. The four sectors drawn around the robot's body are pie-slice radars, which detect the direction to the maze exit in each time step. The light arrow inside the robot's body determines the direction in which the robot is facing.</span></p>
<p class="p1"><span class="s1">Also, the robot has two actuators: one to change its angular velocity (rotation) and another to change its linear velocity.</span></p>
<p class="p1"><span class="s1">We use the same robot configuration that we used in <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>. Thus, you should refer to that chapter for more details. Now that we have covered the maze-solving agent, let's look at the maze environment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The maze environment</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The maze is defined as an area enclosed by walls from the outside. Inside the maze, multiple internal walls create multiple dead ends with local fitness optima, which makes objective-oriented optimization search not very effective. Furthermore, due to the local fitness optima, objective-based search agents can get stuck inside a particular dead end, halting the evolution process completely. The dead ends are shown in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-800 image-border" src="assets/d638be6b-cb23-4f8c-85b4-2cceb6bb9397.png" style="width:16.25em;height:16.25em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The local optima areas within the maze</span></div>
<p class="p1"><span class="s1">In the preceding diagram, the solving agent's starting position is marked by a filled circle in the bottom-left corner, and the maze exit is marked by the filled circle in the top-left corner. The deceptive local fitness optima values are shown as filled sectors the agent's start position.</span></p>
<p class="p1"><span class="s1">The maze environment is defined through the configuration file, and we have implemented the simulator to simulate the solving agent's traversal through the maze. We discussed the maze simulator environment implementation in <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>, and you can refer to it for the particulars.</span></p>
<p class="p1"><span class="s1">In this chapter, we discuss the modifications that were introduced into the original experiment to implement the SAFE optimization strategy. The most critical difference is how the fitness function is defined, and we discuss that in the next section.</span></p>
<div class="p1 packt_infobox"><span class="s1">You can check out the complete implementation details of the maze simulator environment in the source code at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/maze_environment.py"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/maze_environment.py</span></a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitness function definition</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The SAFE method is about the co-evolution of solution candidates and the objective function candidates, that is, we have two co-evolving populations of species. Thus, we need to define two fitness functions: one for the solution candidates (maze solvers) and another for objective function candidates. In this section, we discuss both variants.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitness function for maze solvers</h1>
                </header>
            
            <article>
                
<p class="p2"><span class="s2">In every generation of the evolution, each solution individual (maze solver) is evaluated against all objective function candidates. We use the maximum fitness score obtained during the evaluation of a maze solver against each objective function candidate as a fitness score of the solution.</span></p>
<p class="p2"><span class="s2">The fitness function of the maze solver is an aggregate of two metrics—the distance from the maze exit (the objective-based score) and the novelty of the solver's final position (the novelty score). These scores are arithmetically combined using a pair of coefficients obtained as an output from the particular individual in the <span>objective function candidate's </span>population.</span></p>
<p class="p2"><span class="s2">The following formula gives the combination of these scores as a fitness score:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/99dd6cf2-6a2e-4556-8ed8-5425e150abf8.png" style="width:14.67em;height:2.83em;"/></p>
<p class="p1"><span class="s1"><img class="fm-editor-equation" src="assets/3503325b-6d31-41e2-b0f0-6a834628f697.png" style="width:2.58em;height:1.08em;"/> is the fitness values obtained by the evaluation of the solution candidate, <img class="fm-editor-equation" src="assets/123669da-9593-4d08-8241-5ff4cfac875e.png" style="width:0.75em;height:0.92em;"/>, against the objective function, <img class="fm-editor-equation" src="assets/e453f8b3-5790-49f1-a05f-0c51d6a62f68.png" style="width:1.17em;height:1.08em;"/>. The pair of the coefficients <span>used, </span><img class="fm-editor-equation" src="assets/53c7b36c-1a65-4a9f-8595-ca7a756e87a3.png" style="width:1.75em;height:1.08em;"/>, is the output of the particular objective function candidate. This pair determines how the distance to the maze exit (<img class="fm-editor-equation" src="assets/624adf98-48ae-4495-99e3-5530a8419e25.png" style="width:1.25em;height:1.00em;"/>) and the behavioral novelty (<img class="fm-editor-equation" src="assets/d029abbb-a6c9-40ab-9c34-a925f61ccac2.png" style="width:1.92em;height:1.00em;"/>) of the <span>solution </span>influence the ultimate fitness score of the maze solver<span> at the end of the trajectory</span>.</span></p>
<p class="p1"><span class="s1">The distance to the maze exit (<img class="fm-editor-equation" src="assets/da936b97-ef1d-4664-b1c0-5b345b1d4584.png" style="width:1.17em;height:1.00em;"/>) is determined as the Euclidean distance between the maze solver's final coordinates and the maze exit coordinates. This is shown in the following formula:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6f31a6a7-a7d2-4f25-8104-1dde6650c8d4.png" style="width:14.92em;height:2.17em;"/></p>
<p class="p1"><span class="s1"><img class="fm-editor-equation" src="assets/3e37f415-f49c-4e25-b2b7-bc6da6ba6cb5.png" style="width:1.33em;height:1.00em;"/> and <img class="fm-editor-equation" src="assets/3867c95c-8ab2-45a4-a478-67c68f75eef7.png" style="width:1.08em;height:1.00em;"/> are the final coordinates of the maze solver, and <img class="fm-editor-equation" src="assets/2f68814d-b56a-4612-beda-2b10ad0268fd.png" style="width:1.75em;height:1.00em;"/> and <img class="fm-editor-equation" src="assets/969ad1ef-bfbf-4e2d-a978-e474b87b9d20.png" style="width:1.50em;height:1.00em;"/> are the coordinates of the maze exit.</span></p>
<p class="p1"><span class="s1">The novelty score, <img class="fm-editor-equation" src="assets/04896aaa-ddc1-4b2a-a092-523c6d720d2f.png" style="width:1.92em;height:1.08em;"/>, of each maze solver is determined by its final position in the maze (point <img class="fm-editor-equation" src="assets/e73f9cc2-2135-4af1-a181-cf88e46c68e6.png" style="width:0.83em;height:0.83em;"/>). It is calculated as the average distance from this point to the k-nearest neighbor points, which are the final positions of the other maze solvers.</span></p>
<p class="p1"><span class="s1">The following formula gives the novelty score value at point <em>x</em> of the behavioral space:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8a0e787f-c22c-48ee-9cf9-c45937899fcc.png" style="width:12.92em;height:3.92em;"/></p>
<p class="p1"><span class="s1"><img class="fm-editor-equation" src="assets/ee826d80-17a8-43ca-b909-3da2823ca5e6.png" style="width:1.17em;height:1.00em;"/> is the i-th nearest neighbor of <img class="fm-editor-equation" src="assets/ba9a13e6-7f4d-4fa9-90a9-b46b55b0734b.png" style="width:0.83em;height:0.83em;"/>, and <img class="fm-editor-equation" src="assets/669712d0-2d48-42c2-9474-6e2c62206052.png" style="width:4.75em;height:1.25em;"/> is the distance between <img class="fm-editor-equation" src="assets/1bae89af-0a10-4b72-ad2d-576c0ae140a1.png" style="width:0.83em;height:0.83em;"/> and <img class="fm-editor-equation" src="assets/a9776135-ca81-445d-b2fd-a900c50f2d65.png" style="width:1.08em;height:0.92em;"/>.</span></p>
<p class="p1"><span class="s1">The distance between two points is the novelty metric measuring how different the current solution (<img class="fm-editor-equation" src="assets/7178d7f4-99f7-4bb3-bbc1-5b18e3af1c14.png" style="width:0.83em;height:0.83em;"/>) is from another (<img class="fm-editor-equation" src="assets/21fafe7a-1559-41b7-b414-fcfa2f9bdb4a.png" style="width:1.00em;height:0.83em;"/>) produced by different maze solvers. The novelty metric is calculated as the Euclidean distance between two points:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/217974f3-7c7b-4cbc-8fa3-8f326324d2af.png" style="width:16.42em;height:4.67em;"/></p>
<p class="p1"><span class="s1"><img class="fm-editor-equation" src="assets/5d45a339-7baa-4ae5-9d60-ab120d7b2472.png" style="width:1.17em;height:1.00em;"/> and <img class="fm-editor-equation" src="assets/4b5ba532-39df-4eba-b232-393c6597ed1b.png" style="width:1.17em;height:1.00em;"/> are the values at position <img class="fm-editor-equation" src="assets/19ab567e-e72f-438e-b07c-799a073fbe44.png" style="width:0.42em;height:1.00em;"/> of the coordinate vectors holding coordinates of the <img class="fm-editor-equation" src="assets/8f5c16cc-d11d-4bc6-b4f4-c89d32720229.png" style="width:0.58em;height:0.83em;"/> and <img class="fm-editor-equation" src="assets/32cb7134-f8c8-4fd1-8305-87feb5b67701.png" style="width:0.83em;height:0.83em;"/> points correspondingly.</span></p>
<p class="p1"><span class="s1">Next, we discuss how to define the fitness function for the optimization of the objective function candidates.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitness function for the objective function candidates</h1>
                </header>
            
            <article>
                
<p class="p2"><span class="s2">The SAFE method is based on a commensalistic co-evolutionary approach, which means that one of the co-evolving populations neither benefits nor is harmed during the evolution. In our experiment, the <span>commensalistic </span>population is the population of the objective function candidates. For this population, we need to define a fitness function that is independent of the performance of the maze-solver population.</span></p>
<p class="p2"><span class="s2">A suitable candidate for such a function is a fitness function that uses the novelty score as the fitness score to be optimized. The formula to calculate the novelty score of each objective function candidate is the same as given for the maze solvers. The only difference is that in the case of the objective function candidates, we calculate the novelty score using vectors with the output values of each individual. After that, we use the novelty score value as the fitness score of the individual.</span></p>
<p class="p2"><span class="s2">This method of novelty score estimation is a part of the modified <strong>Novelty Search</strong> (<strong>NS</strong>) method, which we discuss in the next section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modified Novelty Search</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">We presented the NS method in <a href="62301923-b398-43da-b773-c8b1fe383f1d.xhtml" target="_blank">Chapter 6</a>, <em>Novelty Search Optimization Method</em>. In the current experiment, we use a slightly modified version of the NS method, which we discuss next.</span></p>
<p class="p3"><span class="s1">The modifications to the NS method that we will present in this experiment relate to a new way of maintaining the archive of novelty points. The novelty point holds <span>the maze solver's location in the maze at the end of the trajectory, which is combined with the novelty score</span>.</span></p>
<p class="p3"><span class="s1">In the more traditional version of the NS method, the size of the novelty archive is dynamic, allowing the addition of a specific novel point if its novelty score exceeds a certain threshold (the novelty threshold). Also, the novelty threshold can be adjusted during runtime, taking into account how fast the new novelty points are discovered during the evolution. These adjustments allow us to control the maximum size of the archive (to some extent). However, we need to start with an initial novelty threshold value, and this choice is not an obvious one.</span></p>
<p class="p3"><span class="s1">The modified NS method introduces the fixed-size novelty archive to address the issue of choosing the correct novelty threshold value.<span class="Apple-converted-space"> </span>The new novelty points are added to the archive until it becomes full. After that, a novelty point is added to the archive only if its novelty score exceeds the current minimum score of the archive by replacing the current point with a minimal score. Thus, we can maintain the fixed size of the novelty archive and store in it only the most valuable novelty points discovered during the evolution.</span></p>
<div class="p3 packt_infobox"><span class="s1">The source code of the modified novelty archive implementation can be found at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/novelty_archive.py"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/novelty_archive.py</span></a>.</span></div>
<p class="p3"><span class="s1">Next, let's discuss the most interesting parts of the implementation.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The _add_novelty_item function</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">This function allows the addition of new novelty points to the archive while maintaining its size. It has the following implementation:</span></p>
<pre>        if len(self.novel_items) &gt;= MAXNoveltyArchiveSize:<br/>            # check if this item has higher novelty than  <br/>            # last item in the archive (minimal novelty)<br/>            if item &gt; self.novel_items[-1]:<br/>                # replace it<br/>                self.novel_items[-1] = item<br/>        else:<br/>            # just add new item<br/>            self.novel_items.append(item)<br/><br/>        # sort items array in descending order by novelty score<br/>        self.novel_items.sort(reverse=True)</pre>
<p class="p1"><span class="s1">The code first checks whether the size of the novelty archive has not been exceeded yet and directly appends a new novelty point to it in this case. Otherwise, a new novelty point replaces the last item in the archive, which is the item with the smallest novelty score. We can be sure that the last item in the archive has the smallest novelty score because after adding a new item to the archive, we sort it in descending order of novelty score value.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The evaluate_novelty_score function</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This function provides a mechanism to evaluate the novelty score of the novelty item against all items already collected in the novelty archive and all the novelty items discovered in the current population. We calculate the novelty score as the average distance to the <em>k=15</em> nearest neighbors by following these steps:</span></p>
<ol>
<li><span class="s1">We need to collect the distances from the provided novelty item to all items in the novelty archive:</span></li>
</ol>
<pre style="padding-left: 60px">        distances = []<br/>        for n in self.novel_items:<br/>            if n.genomeId != item.genomeId:<br/>                distances.append(self.novelty_metric(n, item))<br/>            else:<br/>                print("Novelty Item is already in archive: %d" % <br/>                       n.genomeId)</pre>
<ol start="2">
<li>After that, we add the distances from the provided novelty item to all items in the current population:</li>
</ol>
<pre style="padding-left: 60px">        for p_item in n_items_list:<br/>            if p_item.genomeId != item.genomeId:<br/>                distances.append(self.novelty_metric(p_item, item))</pre>
<ol start="3">
<li>Finally, we can estimate the average k-nearest neighbors value:</li>
</ol>
<pre style="padding-left: 60px">        distances = sorted(distances) <br/>        item.novelty = sum(distances[:KNN])/KNN</pre>
<p class="p1"><span class="s1">We sort the list with the distances in ascending order to guarantee that the closest items are first in the list. After that, we calculate the sum of the first <em>k=15</em> items in the list and divide it by the count of summed values. Thus, we obtain the value of the average distance to the <em>k-nearest neighbors</em>.</span></p>
<p class="p1"><span class="s1">The modified NS optimization method is at the core of the fitness score evaluation for both the population of maze solvers and the population of objective function candidates. We use it extensively in the implementation of the experiment runner, which we discuss in the next section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modified maze experiment implementation</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">The implementation of the experiment runner is based on the MultiNEAT Python library, which we have used in several experiments in this book. The evolution of each co-evolving population is controlled by the basic NEAT algorithm, which was discussed in <a href="7acd0cf5-c389-4e55-93d7-9438fcaa1390.xhtml" target="_blank">Chapter 3</a>, <em>Using NEAT for XOR Solver Optimization</em>, <a href="34913ccd-6aac-412a-8f54-70d1900cef41.xhtml" target="_blank">Chapter 4</a>, <em>Pole-Balancing Experiments</em>, and <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>.</span></p>
<p class="p3"><span class="s1">However, in this section, we demonstrate how to use the NEAT algorithm to maintain the co-evolution of two independent populations of species: the maze solvers and the objective function candidates.</span></p>
<p class="p3"><span class="s1">Next, we discuss the essential parts of the modified maze experiment runner.</span></p>
<div class="p3 packt_infobox"><span class="s1">For more details, please refer to the source code at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/maze_experiment_safe.py"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/maze_experiment_safe.py</span></a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creation of co-evolving populations</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">In this experiment, we need to create two co-evolving populations of species with different initial genotype configurations to meet the phenotypic requirements of the produced species.</span></p>
<p class="p3"><span class="s1">The phenotype of the maze solver has 11 input nodes to receive signals from the sensors and two output nodes to produce control signals. At the same time, the phenotype of the objective function candidate has one input node receiving the fixed value (<kbd>0.5</kbd>), which is converted into two output values that are used as the fitness function coefficients of the maze solver.</span></p>
<p class="p3"><span class="s1">We start with a discussion of how to create the population of the objective function candidates.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creation of the population of the objective function candidates</h1>
                </header>
            
            <article>
                
<p class="p2"><span class="s2">The genotype encoding the phenotype of the objective function candidates must produce phenotype configurations that have at least one input node and two output nodes, as discussed previously. We implement the population creation in the <kbd>create_objective_fun</kbd> function as follows:</span></p>
<pre>    params = create_objective_fun_params()<br/>    # Genome has one input (0.5) and two outputs (a and b)<br/>    genome = NEAT.Genome(0, 1, 1, 2, False, <br/>        NEAT.ActivationFunction.TANH, # hidden layer activation<br/>        NEAT.ActivationFunction.UNSIGNED_SIGMOID, # output layer activation<br/>        1, params, 0)<br/>    pop = NEAT.Population(genome, params, True, 1.0, seed)<br/>    pop.RNG.Seed(seed)<br/><br/>    obj_archive = archive.NoveltyArchive(<br/>                             metric=maze.maze_novelty_metric_euclidean)<br/>    obj_fun = ObjectiveFun(archive=obj_archive, <br/>                             genome=genome, population=pop)</pre>
<p class="p1"><span class="s1">In this code, we create the NEAT genotype with one input node, two output nodes, and one hidden node. The hidden node is pre-seeded into the initial genome to boost the evolution with the pre-defined non-linearity. The activation function type of the hidden layer is selected to be hyperbolic tangent to support negative output values. This feature is essential for our task. A negative value of one of the coefficients produced by the objective function candidate can indicate that a particular component of the maze solver fitness function has a negative influence, and this sends a signal that the evolution needs to try other paths.</span></p>
<p class="p1"><span class="s1">In the end, we create the <kbd>ObjectiveFun</kbd> object to maintain an evolving population of the objective function candidates.</span></p>
<p class="p3"><span class="s1">Next, we discuss how the population of maze solvers is created.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the population of maze solvers</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The maze-solver agent needs to get inputs from 11 sensors and generate two control signals, which affect the angular and linear velocity of the robot. Thus, the genome encoding the phenotype of the maze solver must yield phenotype configurations that include 11 input nodes and two output nodes. You can see how the creation of the initial population of genomes for the maze-solver agent is implemented by taking a look at the <kbd>create_robot</kbd> function:</span></p>
<pre>    params = create_robot_params()<br/>    # Genome has 11 inputs and two outputs<br/>    genome = NEAT.Genome(0, 11, 0, 2, False, <br/>                        NEAT.ActivationFunction.UNSIGNED_SIGMOID, <br/>                        NEAT.ActivationFunction.UNSIGNED_SIGMOID, <br/>                        0, params, 0)<br/>    pop = NEAT.Population(genome, params, True, 1.0, seed)<br/>    pop.RNG.Seed(seed)<br/><br/>    robot_archive = archive.NoveltyArchive(metric=maze.maze_novelty_metric)<br/>    robot = Robot(maze_env=maze_env, archive=robot_archive, genome=genome, <br/>                  population=pop)</pre>
<p class="p1"><span class="s1">In the code, we obtain the appropriate NEAT hyperparameters from the <kbd>create_robot_params</kbd> function. After that, we use them to create an initial NEAT genotype with the corresponding number of input and output nodes. Finally, we create a <kbd>Robot</kbd> object, which encapsulates all the data related to the maze-solver population, along with the maze simulator environment.</span></p>
<p class="p1"><span class="s1">Now, when we have created the two co-evolving populations, we need to implement the fitness score evaluation for individuals in both populations. We discuss the implementation details of the fitness score evaluation in the next section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The fitness evaluation of the co-evolving populations</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Having </span><span>defined the </span><span>two co-evolving populations, we need to create functions to evaluate the fitness scores of the individuals in each population. As we have already mentioned, the fitness scores of the individuals in the maze-solver population depend on the outputs produced by the population of objective function candidates. At the same time, the fitness score of each objective function candidate is wholly determined by the novelty score of that individual.</span></p>
<p class="p1"><span class="s1">Thus, we have two different approaches to the evaluation of <span>fitness scores</span>, and we need to implement two different functions. Hereafter, we discuss both implementations.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitness evaluation of objective function candidates</h1>
                </header>
            
            <article>
                
<p class="p2"><span class="s2">The fitness score of each individual in the population of the objective function candidates is determined by its novelty score, which is calculated as we discussed previously. The implementation of the fitness score evaluation is divided between two functions: <kbd>evaluate_obj_functions</kbd> and <kbd>evaluate_individ_obj_function</kbd>.</span></p>
<p class="p2"><span class="s2">Next, we discuss the implementations of both functions.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The evaluate_obj_functions function implementation</h1>
                </header>
            
            <article>
                
<p class="p2"><span class="s2">This function accepts the <kbd>ObjectiveFun</kbd> object, which holds the population of the objective function candidates, and uses it to estimate the fitness score of each individual in the population by following these steps:</span></p>
<ol class="ol1">
<li class="li1"><span class="s1">First, we iterate over all genomes in the population and collect the novelty points for each genome:</span></li>
</ol>
<pre style="padding-left: 60px">    obj_func_genomes = NEAT.GetGenomeList(obj_function.population)<br/>    for genome in obj_func_genomes:<br/>        n_item = evaluate_individ_obj_function(genome=genome, <br/>                                            generation=generation)<br/>        n_items_list.append(n_item)<br/>        obj_func_coeffs.append(n_item.data)</pre>
<p class="p1" style="padding-left: 60px"><span class="s1">In the code, the novelty points obtained from the <kbd>evaluate_individ_obj_function</kbd> function are appended to the list of novelty points in the population. Also, we append novelty point data to the list of coefficient pairs. The list of coefficient pairs later will be used to estimate the fitness scores of the individual maze solvers.</span></p>
<ol start="2">
<li>Next, we iterate over the list of population genomes and evaluate the novelty score of each genome using the novelty points collected in the previous step:</li>
</ol>
<pre style="padding-left: 60px">    max_fitness = 0<br/>    for i, genome in enumerate(obj_func_genomes):<br/>        fitness = obj_function.archive.evaluate_novelty_score(<br/>               item=n_items_list[i],n_items_list=n_items_list)<br/>        genome.SetFitness(fitness)<br/>        max_fitness = max(max_fitness, fitness)</pre>
<p class="p1"><span class="s1">The novelty score estimated using the novelty points are already collected in the novelty archive and the list of the novelty points created for the current population. After that, we set the estimated novelty score as the fitness score of the corresponding genome. Furthermore, we find the maximum value of the fitness score and return it, along with the list of coefficient pairs.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The evaluate_individ_obj_function function implementation</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This function accepts the individual NEAT genome of the objective function candidate and returns the novelty point evaluation results. We implement it as follows:</span></p>
<pre>    n_item = archive.NoveltyItem(generation=generation, genomeId=genome_id)<br/>    # run the simulation<br/>    multi_net = NEAT.NeuralNetwork()<br/>    genome.BuildPhenotype(multi_net)<br/>    depth = 2<br/>    try:<br/>        genome.CalculateDepth()<br/>        depth = genome.GetDepth()<br/>    except:<br/>        pass<br/>    obj_net = ANN(multi_net, depth=depth)<br/><br/>    # set inputs and get outputs ([a, b])<br/>    output = obj_net.activate([0.5])<br/><br/>    # store coefficients<br/>    n_item.data.append(output[0])<br/>    n_item.data.append(output[1])</pre>
<p class="p1"><span class="s1">We start with the creation of a <kbd>NoveltyItem</kbd> object to hold the novelty point data for a given genome. After that, we build a phenotype ANN and activate it with an input of <kbd>0.5</kbd>. Finally, we use the outputs from the ANN to create the novelty point.</span></p>
<p class="p3"><span class="s1">In the next section, we discuss the fitness score evaluation of the individuals in the maze-solver population.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitness evaluation of the maze-solver agents</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">We estimate the fitness score of each individual in the maze-solver population as a compound consisting of two components: the novelty score and the distance to the maze exit at the end of the trajectory. The influence of each component is controlled by a coefficient pair produced by the individuals from the population of the objective function candidates.</span></p>
<p class="p1"><span class="s1">The fitness score evaluation is divided into three functions, which we are going to discuss next.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The evaluate_solutions function implementation</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">The <kbd>evaluate_solutions</kbd> function receives the <kbd>Robot</kbd> object <span>as an input parameter</span>, which maintains the population of the maze-solver agent and the maze environment simulator. Also, it receives a list of the coefficient pairs generated during the evaluation of the population of objective function candidates.</span></p>
<p class="p3"><span class="s1">We use the input parameters of the function to evaluate each genome in the population and to estimate its fitness function. Here, we discuss the essential implementation details:</span></p>
<ol class="ol1">
<li class="li1"><span class="s1">First, we evaluate each individual in the population against the maze simulator and find the distance to the maze exit at the end of the trajectory:</span></li>
</ol>
<pre style="padding-left: 60px">    robot_genomes = NEAT.GetGenomeList(robot.population)<br/>    for genome in robot_genomes:<br/>        found, distance, n_item = evaluate_individual_solution(<br/>            genome=genome, generation=generation, robot=robot)<br/>        # store returned values<br/>        distances.append(distance)<br/>        n_items_list.append(n_item)</pre>
<ol start="2">
<li class="p1">Next, we iterate over all genomes in the population and estimate the novelty score of each individual. Also, we use the corresponding distance to the maze exit collected before and combine it with the calculated novelty score to evaluate genome fitness:</li>
</ol>
<pre style="padding-left: 60px">    for i, n_item in enumerate(n_items_list):<br/>        novelty = robot.archive.evaluate_novelty_score(item=n_item, <br/>                                         n_items_list=n_items_list)<br/>        # The sanity check<br/>        assert robot_genomes[i].GetID() == n_item.genomeId<br/><br/>        # calculate fitness<br/>        fitness, coeffs = evaluate_solution_fitness(distances[i], <br/>                                        novelty, obj_func_coeffs)<br/>        robot_genomes[i].SetFitness(fitness)</pre>
<p class="p1" style="padding-left: 60px"><span class="s1">In the first half of the code, we use the <kbd>robot.archive.evaluate_novelty_score</kbd> function to estimate the novelty score of each individual in the population. The second half invokes the <kbd>evaluate_solution_fitness</kbd> function to estimate the fitness score of each individual using the novelty score and the distance to the maze exit.</span></p>
<ol start="3">
<li>Finally, we collect evaluation statistics about the performance of the best maze-solver genome in the population:</li>
</ol>
<pre style="padding-left: 60px">        if not solution_found:<br/>            # find the best genome in population<br/>            if max_fitness &lt; fitness:<br/>                max_fitness = fitness<br/>                best_robot_genome = robot_genomes[i]<br/>                best_coeffs = coeffs<br/>                best_distance = distances[i]<br/>                best_novelty = novelty<br/>        elif best_robot_genome.GetID() == n_item.genomeId:<br/>            # store fitness of winner solution<br/>            max_fitness = fitness<br/>            best_coeffs = coeffs<br/>            best_distance = distances[i]<br/>            best_novelty = novelty</pre>
<p class="p1"><span class="s1">In the end, all statistics collected during population evaluation are returned by the function.</span></p>
<p class="p1"><span class="s1">Hereafter, we discuss how the individual maze-solver genome is evaluated against the maze environment simulator.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The evaluate_individual_solution function implementation</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This is the function that evaluates the performance of a particular maze solver against the maze environment simulator. It is implemented as follows:</span></p>
<ol class="ol1">
<li class="li1"><span class="s1">First, we create the phenotype ANN of the maze solver and use it as a controller to guide the robot through the maze:</span></li>
</ol>
<pre style="padding-left: 60px">    n_item = archive.NoveltyItem(generation=generation, <br/>                                 genomeId=genome_id)<br/>    # run the simulation<br/>    maze_env = copy.deepcopy(robot.orig_maze_environment)<br/>    multi_net = NEAT.NeuralNetwork()<br/>    genome.BuildPhenotype(multi_net)<br/>    depth = 8<br/>    try:<br/>        genome.CalculateDepth()<br/>        depth = genome.GetDepth()<br/>    except:<br/>        pass<br/>    control_net = ANN(multi_net, depth=depth)<br/>    distance = maze.maze_simulation_evaluate(<br/>        env=maze_env, net=control_net, <br/>        time_steps=SOLVER_TIME_STEPS, n_item=n_item)</pre>
<p class="p1" style="padding-left: 60px"><span class="s1">In the code, we create a <kbd>NoveltyItem</kbd> object to hold the novelty point, which is defined by the robot's <span>final </span>position in the maze. After that, we create the phenotype ANN and run the maze simulator, using it as the control ANN for a given number of time steps (400). After a simulation completes, we receive the distance between the final position of the maze solver and the maze exit.</span></p>
<ol start="2">
<li>Next, we save the simulation statistics into the <kbd>AgentRecord</kbd> object that we analyze at the end of the experiment:</li>
</ol>
<pre style="padding-left: 60px">    record = agent.AgenRecord(generation=generation, <br/>                              agent_id=genome_id)<br/>    record.distance = distance<br/>    record.x = maze_env.agent.location.x<br/>    record.y = maze_env.agent.location.y<br/>    record.hit_exit = maze_env.exit_found<br/>    record.species_id = robot.get_species_id(genome)<br/>    robot.record_store.add_record(record)</pre>
<p class="p1"><span class="s1">After that, the function returns a tuple with the following values: a flag indicating whether we have found a solution, the distance to the maze exit at the end of the robot's trajectory, and the <kbd>NoveltyItem</kbd> object encapsulating information about the novelty point discovered.</span></p>
<p class="p1"><span class="s1">In the next section, we discuss the implementation of the maze-solver fitness function.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The evaluate_solution_fitness function implementation</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This function is an implementation of the maze-solver fitness function that we discussed earlier. This function receives the distance to the maze exit, the novelty score, and the list of coefficient pairs generated by the current generation of the objective function candidates. Next, it uses the received input parameters to calculate the fitness score as follows:</span></p>
<pre>    normalized_novelty = novelty<br/>    if novelty &gt;= 1.00:<br/>        normalized_novelty = math.log(novelty)<br/>    norm_distance = math.log(distance)<br/><br/>    max_fitness = 0<br/>    best_coeffs = [-1, -1]<br/>    for coeff in obj_func_coeffs:<br/>        fitness = coeff[0] / norm_distance + coeff[1] * normalized_novelty<br/>        if fitness &gt; max_fitness:<br/>            max_fitness = fitness<br/>            best_coeffs[0] = coeff[0]<br/>            best_coeffs[1] = coeff[1]</pre>
<p class="p1"><span class="s1">First, we need to normalize the distance and the novelty score values using the natural logarithm. This normalization will guarantee that the distance and novelty score values are always on the same scale. It is essential to have these values on the same scale because the coefficient pair is always in the range <kbd>[0,1]</kbd>. Thus, if the values of distance and novelty score have different scales, a pair of coefficients will not be unable to influence the significance of each value when calculating the fitness score.</span></p>
<p class="p1"><span class="s1">The code iterates over the list of coefficients pairs and, for each pair of coefficients, it calculates the fitness score by combining the distance and the novelty score values.</span></p>
<p class="p1"><span class="s1">The ultimate fitness score of the maze solver is the maximum among all found fitness scores. This value and the corresponding pair of coefficients are then returned by the function.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The modified maze experiment runner</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Now, when we have implemented all the necessary routines to create co-evolving populations and to evaluate the fitness of individuals within these populations, we are ready to start implementing the experiment runner loop.</span></p>
<div class="p1 packt_infobox"><span class="s1">The complete details can be found in the <kbd>run_experiment</kbd> function in the <kbd>maze_experiment_safe.py</kbd> file at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/maze_experiment_safe.py"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/maze_experiment_safe.py</span></a>.</span></div>
<p><span>Here, we discuss the essential details of the implementation:</span></p>
<ol>
<li class="p1"><span class="s1">We start with the creation of the corresponding populations of the co-evolving species:</span></li>
</ol>
<pre style="padding-left: 60px">    robot = create_robot(maze_env, seed=seed)<br/>    obj_func = create_objective_fun(seed)</pre>
<ol start="2">
<li>Next, we start the evolution loop and evaluate both populations as follows:</li>
</ol>
<pre style="padding-left: 60px">    for generation in range(n_generations):<br/>        # evaluate objective function population<br/>        obj_func_coeffs, max_obj_func_fitness = \<br/>                    evaluate_obj_functions(obj_func, generation)<br/>        # evaluate robots population<br/>        robot_genome, solution_found, robot_fitness, distances, \<br/>        obj_coeffs, best_distance, best_novelty = \<br/>          evaluate_solutions(robot=robot, <br/>          obj_func_coeffs=obj_func_coeffs, generation=generation)</pre>
<ol start="3">
<li>After evaluating the populations, we save the results as statistics of the current generation of the evolution:</li>
</ol>
<pre style="padding-left: 60px">        stats.post_evaluate(max_fitness=robot_fitness, <br/>                            errors=distances)<br/>        # store the best genome<br/>        best_fitness = robot.population.GetBestFitnessEver()<br/>        if solution_found or best_fitness &lt; robot_fitness:<br/>            best_robot_genome_ser = pickle.dumps(robot_genome)<br/>            best_robot_id = robot_genome.GetID()<br/>            best_obj_func_coeffs = obj_coeffs<br/>            best_solution_novelty = best_novelty</pre>
<ol start="4">
<li>At the end of the evolution loop, we signal to both populations to advance to the next epoch if the solution has not been found in the current generation:</li>
</ol>
<pre style="padding-left: 60px">        if solution_found:<br/>            print('Solution found at generation: %d, best fitness: %f, species count: %d' % (generation, robot_fitness, len(pop.Species)))<br/>            break<br/>        # advance to the next generation<br/>        robot.population.Epoch()<br/>        obj_func.population.Epoch()</pre>
<ol start="5">
<li>After the evolution loop completes its iteration over a specified number of generations, we visualize the collected maze records:</li>
</ol>
<pre style="padding-left: 60px">        if args is None:<br/>            visualize.draw_maze_records(maze_env, <br/>                       robot.record_store.records, <br/>                       view=show_results)<br/>        else:<br/>            visualize.draw_maze_records(maze_env, <br/>                      robot.record_store.records, <br/>                      view=show_results, width=args.width, <br/>                      height=args.height,<br/>                      filename=os.path.join(trial_out_dir, <br/>                                     'maze_records.svg'))</pre>
<p class="p1" style="padding-left: 60px"><span class="s1">The maze records mentioned here hold the statistics of the evaluation of each maze-solver genome in the maze simulator collected during the evolution as <kbd>AgentRecord</kbd> objects. In the visualization, we render the final position of each evaluated maze solver with the maze.</span></p>
<ol start="6">
<li>Next, we simulate maze solving with the control ANN, which was created using the best solver genome found during the evolution. The trajectory of the maze solver during the simulation can be visualized as follows:</li>
</ol>
<pre style="padding-left: 60px">        multi_net = NEAT.NeuralNetwork()<br/>        best_robot_genome.BuildPhenotype(multi_net)<br/><br/>        control_net = ANN(multi_net, depth=depth)<br/>        path_points = []<br/>        distance = maze.maze_simulation_evaluate(<br/>                                    env=maze_env, <br/>                                    net=control_net, <br/>                                    time_steps=SOLVER_TIME_STEPS,<br/>                                    path_points=path_points)<br/>        print("Best solution distance to maze exit: %.2f, novelty: %.2f" % (distance, best_solution_novelty))<br/>        visualize.draw_agent_path(robot.orig_maze_environment, <br/>                          path_points, best_robot_genome,<br/>                          view=show_results, width=args.width, <br/>                          height=args.height, <br/>                          filename=os.path.join(trial_out_dir,<br/>                                      'best_solver_path.svg'))</pre>
<p class="p1" style="padding-left: 60px"><span class="s1">At first, the code creates a phenotype ANN from the best solver genome. Next, it runs the maze simulator using the created phenotype ANN as the maze solver controller. We then render the collected trajectory points of the maze solver.</span></p>
<ol start="7">
<li>Finally, we render the plot with the average fitness scores per generation as follows:</li>
</ol>
<pre style="padding-left: 60px">        visualize.plot_stats(stats, ylog=False, view=show_results, <br/>           filename=os.path.join(trial_out_dir,'avg_fitness.svg'))</pre>
<p class="p1"><span class="s1">All the visualizations mentioned here are also saved into the local filesystem as SVG files and can be used later for result analysis.</span></p>
<p class="p1"><span class="s1">In the next section, we discuss how to run the modified maze experiment and the results of the experiment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modified maze experiment</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">We are almost ready to start the experiment with co-evolution using the modified maze experiment. However, before that, we need to discuss the hyperparameter selection for each co-evolving population.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameters for the maze-solver population</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">For this experiment, we choose to use the MultiNEAT Python library, which uses the <kbd>Parameters</kbd> Python class to maintain a list of all supported hyperparameters. The initialization of the hyperparameters for the population of maze solvers is defined in the <kbd>create_robot_params</kbd> function. Next, we discuss the essential hyperparameters and the reasons behind choosing particular values for them:</span></p>
<ol class="ol1">
<li class="li1"><span class="s1">We decided to have a medium-sized population providing sufficient population diversity from the very beginning:</span></li>
</ol>
<pre style="padding-left: 60px">    params.PopulationSize = 250</pre>
<ol start="2">
<li>We are interested in producing a compact genome topology during the evolution and limiting the number of species within the population. Thus, we have defined tiny probabilities for adding new nodes and connections during the evolution:</li>
</ol>
<pre style="padding-left: 60px">    params.MutateAddNeuronProb = 0.03<br/>    params.MutateAddLinkProb = 0.05</pre>
<ol start="3">
<li>The novelty score rewards finding unique positions in the maze. One way to achieve this is to intensify the numerical dynamics within the phenotype. Thus, we have increased the range of connection weights:</li>
</ol>
<pre style="padding-left: 60px">    params.MaxWeight = 30.0<br/>    params.MinWeight = -30.0</pre>
<ol start="4">
<li>To support the evolutionary process, we choose to introduce elitism by defining the ratio of the genomes to be transferred to the next generation:</li>
</ol>
<pre style="padding-left: 60px">    params.Elitism = 0.1</pre>
<p class="p1"><span class="s1">The elitism value determines that about one-tenth of the individuals will be carried to the next generation</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameters for the objective function candidates population</h1>
                </header>
            
            <article>
                
<p class="p3"><span class="s1">We create the hyperparameters for the evolution of the population of objective function candidates in the <kbd>create_objective_fun_params</kbd> function. Here, we discuss the most critical hyperparameters:</span></p>
<ol>
<li class="p3"><span class="s1">We decided to start with a small population to reduce computational costs. Also, the genotypes of the objective function candidate are not expected to be very complicated. Thus, a small population should be sufficient:</span></li>
</ol>
<pre style="padding-left: 60px">    params.PopulationSize = 100</pre>
<ol start="2">
<li>As with the maze solvers, we are interested in producing compact genomes. Thus, the probabilities of adding new nodes and connections are kept very small:</li>
</ol>
<pre style="padding-left: 60px">    params.MutateAddNeuronProb = 0.03<br/>    params.MutateAddLinkProb = 0.05</pre>
<p class="p1"><span class="s1">We are not expecting a complicated topology of genomes in the population of the objective function candidates. Thus, most of the hyperparameters are set to default values.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working environment setup</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In this experiment, we use the MultiNEAT Python library. Thus, we need to create an appropriate Python environment, which includes this library and other dependencies. You can set up the Python environment with the help of Anaconda with the following commands:</span></p>
<pre><strong>$ conda create --name maze_co python=3.5</strong><br/><strong>$ conda activate maze_co</strong><br/><strong>$ conda install -c conda-forge multineat </strong><br/><strong>$ conda install matplotlib</strong><br/><strong>$ conda install graphviz</strong><br/><strong>$ conda install python-graphviz</strong></pre>
<p class="p1"><span class="s1">These commands create the <kbd>maze_co</kbd> virtual environment with Python 3.5 and install all necessary dependencies into it.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the modified maze experiment</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Now, we are ready to run the experiment in the newly created virtual environment. You can start the experiment by cloning the corresponding Git repository and running the script with the following commands:</span></p>
<pre><strong>$ git clone https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python.git</strong><br/><strong>$ cd Hands-on-Neuroevolution-with-Python/Chapter9</strong><br/><strong>$ python maze_experiment_safe.py -t 1 -g 150 -m medium</strong></pre>
<div class="p1 packt_infobox"><span class="s1">Do not forget to activate the appropriate virtual environment with the <span><kbd>conda activate maze_co</kbd> </span>command.<br/></span></div>
<p class="p1"><span class="s1">The preceding command starts one trial of the experiment for <kbd>150</kbd> generations of evolution using the medium-complexity maze configuration. After about <kbd>100</kbd> generations of evolution, a successful solution is discovered by the neuroevolution process, and you should be able to see the <span>following </span>output in the console:</span></p>
<pre><strong>****** Generation: 105 ******</strong><br/><br/><strong>Maze solved in 338 steps</strong><br/><br/><strong>Solution found at generation: 105, best fitness: 3.549289, species count: 7</strong><br/><br/><strong>==================================</strong><br/><strong>Record store file: out/maze_medium_safe/5/data.pickle</strong><br/><strong>Random seed: 1571021768</strong><br/><strong>Best solution fitness: 3.901621, genome ID: 26458</strong><br/><strong>Best objective func coefficients: [0.7935419704765059, 0.9882050653334634]</strong><br/><strong>------------------------------</strong><br/><strong>Maze solved in 338 steps</strong><br/><strong>Best solution distance to maze exit: 3.56, novelty: 19.29</strong><br/><strong>------------------------</strong><br/><strong>Trial elapsed time: 4275.705 sec</strong><br/><strong>==================================</strong></pre>
<p class="p1"><span class="s1">From the output presented here, you can see that a successful maze solver was found at generation <kbd>105</kbd> and was able to solve the maze in 338 steps from the allotted 400. Also, it is interesting to note that the coefficient pair produced by the best objective function candidate gives slightly more importance to the novelty score component of the maze-solver fitness function.</span></p>
<p class="p1"><span class="s1">It is interesting to take a look at the plot of the best fitness scores per generation:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-838 image-border" src="assets/812c2596-9516-4ca5-a854-6f90a391fa61.png" style="width:37.17em;height:27.50em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The fitness scores per generation</span></div>
<p class="p1"><span class="s1">In the preceding plot, you can see that the best fitness score has a maximum in the early generations of evolution. This is due to the high novelty score values, which are easier to obtain at the beginning of the evolution because there are many maze areas that have not been explored. Another essential point to note is that the average distance to the maze exit remains almost at the same level for most of the </span><span>generations of </span><span>evolution. Thus, we can assume that the correct solution was found not by gradual improvements, but rather by a quality leap of the champion genome. This conclusion is also supported by the next plot, where we render the collected maze records per species:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-801 image-border" src="assets/c3c0e7fd-8a02-43b7-a9f3-df8e4e59c386.png" style="width:25.00em;height:26.08em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The maze records with final maze solvers positions</span></div>
<p class="p1"><span class="s1">The preceding plot has two parts: the top for species with an objective fitness score (based on the distance from the maze exit) greater than <strong>0.8</strong>, and the bottom for other species. You can see that only one species produced a maze-solver genome that was able to reach the vicinity of the maze exit. Also, you can see that the genomes belonging to that species demonstrate very explorative behavior by exploring more maze areas than all other species combined.</span></p>
<p class="p1"><span class="s1">Finally, we discuss the path of the successful maze solver through the maze, which is shown in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-802 image-border" src="assets/70fc92ee-1779-4fef-b8a6-4ea935d83d97.png" style="width:21.83em;height:11.33em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The path of the successful maze solver through the maze</span></div>
<p class="p1"><span class="s1">The path of the successful maze solver is near-optimal for the given maze configuration.</span></p>
<p class="p1"><span class="s1">This experiment also demonstrates the importance of the initial conditions in finding a successful solution. The initial conditions are defined by the random seed value that we choose before running the experiment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercises</h1>
                </header>
            
            <article>
                
<ol class="ol1">
<li class="li3"><span class="s1">We have included the hard-to-solve maze configuration into the experiment source code at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/hard_maze.txt"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter9/hard_maze.txt</span></a>. You can try to solve the hard maze configuration by using the following command: <kbd>python maze_experiment_safe.py -g 120 -t 5 -m hard --width 200 --height 200</kbd></span>.</li>
<li class="li3"><span class="s1">We have found a successful solution using <kbd>1571021768</kbd> as a random seed value. Try to find another random seed value producing a successful solution. How many generations did it take to find it?</span></li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="p2"><span class="s1">In this chapter, we discussed the co-evolution of two populations of species. You learned how commensalistic co-evolution can be implemented to produce a population of successful maze solvers. We introduced you to an exciting approach of implementing a fitness function of the maze solver that combines the objective-based score and the novelty score using coefficients produced by the population of the objective function candidates. Also, you have learned about the modified Novelty Search method and how it differs from the original method, which we discussed in <a href="62301923-b398-43da-b773-c8b1fe383f1d.xhtml" target="_blank">Chapter 6</a>, <em>Novelty Search Optimization Method</em>.</span></p>
<p>Using the knowledge gained in this chapter, you will be able to apply a commensalistic co-evolution approach to your work or research tasks that have no clear fitness function definition.</p>
<p class="p2"><span class="s1">In the next chapter, you will learn about the deep neuroevolution method and how to use it to evolve agents that are able to play classic Atari games.</span></p>


            </article>

            
        </section>
    </body></html>