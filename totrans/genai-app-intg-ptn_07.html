<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer044">
<h1 class="chapterNumber">7</h1>
<h1 class="chapterTitle" id="_idParaDest-77">Integration Pattern: Real-Time Intent Classification</h1>
<p class="normal">In previous chapters, we discussed the batch-processing integration pattern, where we focused on efficiently processing large volumes of data and generating data to be used by downstream <a id="_idIndexMarker230"/>systems. In this chapter, we will shift our focus to <strong class="keyWord">real-time integration patterns</strong>.</p>
<p class="normal">Real-time interactions require applications to be optimized for latency, rather than processing large batch requests efficiently. In other words, we need to ensure that the output is generated as quickly as possible to provide an optimized user experience. The most common use case for this pattern is real-time agents exposed through chat or voice interfaces.</p>
<p class="normal">Let’s consider <a id="_idIndexMarker231"/>an intent classification use case, which is a common scenario for chatbots. In this context, an <strong class="keyWord">artificial intelligence</strong> (<strong class="keyWord">AI</strong>) system is responsible for identifying the user’s intent, such as checking a balance, scheduling an appointment, or making a purchase. Based on the identified intent, the system can then perform the appropriate tasks or provide relevant responses.</p>
<p class="normal">In today’s application experiences, customers expect seamless and personalized experiences when interacting with businesses. One way to achieve this is by implementing an intelligent system that can accurately interpret user intents based on natural language inputs. This capability is particularly valuable in customer service, e-commerce, and conversational AI applications, where understanding the user’s intent is crucial for providing relevant and contextual responses.</p>
<p class="normal">In this chapter, we’ll explore a real-time intent classification use case, leveraging the power of Google’s <strong class="keyWord">Gemini Pro</strong>, <em class="italic">a state-of-the-art</em> generative AI model, to build a system that can <a id="_idIndexMarker232"/>accurately categorize user inputs into predefined intents. </p>
<p class="normal">We’ll walk through the entire process, from data preparation to deployment and integration with downstream systems, following the integration framework discussed in previous chapters.</p>
<p class="normal">In this chapter, we will cover:</p>
<ul>
<li class="bulletList">Use case definition</li>
<li class="bulletList">Architecture</li>
<li class="bulletList">Entry point</li>
<li class="bulletList">Prompt pre-processing</li>
<li class="bulletList">Inference</li>
<li class="bulletList">Result post-processing</li>
<li class="bulletList">Result presentation</li>
<li class="bulletList">Full code</li>
</ul>
<h1 class="heading-1" id="_idParaDest-78">Use case definition</h1>
<p class="normal">Let’s consider a scenario where we’re working with an e-commerce company that wants to improve its <a id="_idIndexMarker233"/>customer service experience. The company receives a large volume of customer inquiries through various channels, such as email, chat, and social media. Currently, these inquiries are handled manually by a team of customer service representatives, which can be time-consuming and prone to inconsistencies.</p>
<p class="normal">By integrating intent classification into customer engagement flows, companies can optimize their customer service operations. This advanced natural language processing technique automatically categorizes incoming customer inquiries into predefined intents, such as “order status,” “product inquiry,” “return request,” or “general feedback.” The classification layer acts as an intelligent entry point for customer service interactions, enabling more efficient and accurate routing of inquiries.</p>
<p class="normal">This automated categorization serves as the foundation for a scalable customer service infrastructure. Once an inquiry is classified, it can be seamlessly directed to the most appropriate team or agent, ensuring that customers receive expert assistance tailored to their specific needs. For high-volume, straightforward inquiries, the system can even trigger automated responses, providing instant solutions to common issues. This not only dramatically improves response times but also enhances overall customer satisfaction by delivering quick, relevant assistance.</p>
<p class="normal">Additionally, the implementation of intent classification significantly improves the quality of life for customer service agents. </p>
<p class="normal">By receiving pre-categorized inquiries, organizations can leverage specialist agents to focus on their areas of expertise, reducing the cognitive load of constantly switching between different types of issues. This specialization allows agents to provide more in-depth, high-quality support, leading to better resolution rates and increased job satisfaction.</p>
<p class="normal">There is an <a id="_idIndexMarker234"/>additional benefit in terms of analytics, as the data gathered from intent classification can offer valuable insights into customer needs and pain points, enabling companies to continually refine their products, services, and support strategies to better meet customer expectations.</p>
<p class="normal">In the following section, we will dive deep into an approach that will get you started on an intent classification example using GenAI.</p>
<h1 class="heading-1" id="_idParaDest-79">Architecture</h1>
<p class="normal">To build <a id="_idIndexMarker235"/>our intent classification system, we’ll <a id="_idIndexMarker236"/>leverage a serverless, event-driven architecture built on <strong class="keyWord">Google Cloud</strong> (for example: <a href="https://cloud.google.com/architecture/serverless-functions-blueprint"><span class="url">https://cloud.google.com/architecture/serverless-functions-blueprint</span></a>). This approach aligns with cloud-native principles and allows for seamless integration with other cloud services.</p>
<figure class="mediaobject"><img alt="" height="464" src="../Images/B22175_07_01.png" width="825"/></figure>
<p class="packt_figref">Figure 7.1: Intent classification example architecture diagram</p>
<p class="normal">The architecture consists of the following key components:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Ingestion layer</strong>: This layer is responsible for accepting incoming user inputs from <a id="_idIndexMarker237"/>various channels, such as web forms, chat interfaces, or <a id="_idIndexMarker238"/>API endpoints. We’ll use <strong class="keyWord">Google Cloud Functions</strong> as the <a id="_idIndexMarker239"/>entry point for our system, which <a id="_idIndexMarker240"/>can be <a id="_idIndexMarker241"/>triggered by events from services like <strong class="keyWord">Cloud Storage</strong>, <strong class="keyWord">Pub/Sub</strong>, or <strong class="keyWord">Cloud Run</strong>.</li>
<li class="bulletList"><strong class="keyWord">AI processing layer</strong>: In <a id="_idIndexMarker242"/>this layer, we’ll integrate Google’s Gemini Pro through <strong class="keyWord">Vertex AI</strong>. Vertex AI <a id="_idIndexMarker243"/>provides a managed environment for deploying and scaling machine learning models, ensuring high availability and performance.</li>
<li class="bulletList"><strong class="keyWord">Intent classification model</strong>: This <a id="_idIndexMarker244"/>is the core component of our system, responsible for analyzing the user input and determining the corresponding intent. We’ll leverage Google Gemini Pro’s natural language understanding capabilities for our intent classification model.</li>
<li class="bulletList"><strong class="keyWord">Orchestration and routing</strong>: Based on the classified intent, we’ll need to route <a id="_idIndexMarker245"/>the user input to the appropriate downstream <a id="_idIndexMarker246"/>system or service. This could involve integrating with <strong class="keyWord">customer relationship management</strong> (<strong class="keyWord">CRM</strong>) systems, knowledge bases, or other enterprise applications. We’ll use Cloud Functions or Cloud Run to orchestrate this routing process.</li>
<li class="bulletList"><strong class="keyWord">Monitoring and logging</strong>: To <a id="_idIndexMarker247"/>ensure the reliability and <a id="_idIndexMarker248"/>performance of our system, we’ll implement robust monitoring and logging <a id="_idIndexMarker249"/>mechanisms. We’ll leverage <a id="_idIndexMarker250"/>services like <strong class="keyWord">Cloud Logging</strong>, <strong class="keyWord">Cloud Monitoring</strong>, and <strong class="keyWord">Cloud Operations</strong> to gain visibility into our system’s behavior and quickly identify and resolve any issues.</li>
</ul>
<p class="normal">By adopting this architecture, the intent classification system won’t just be scalable but also flexible enough to adapt to varying workloads and integration requirements. We’ll be able to handle high volumes of customer inquiries in real time and deliver swift and consistent responses that improve the overall customer experience.</p>
<p class="normal">The <a id="_idIndexMarker251"/>serverless nature of this architecture brings several additional benefits. It allows for automatic scaling based on demand, ensuring that we can handle sudden spikes in customer inquiries without manual intervention. This elasticity not only improves system reliability but also optimizes costs, as we only pay for the resources we actually use.</p>
<p class="normal">This event-driven design facilitates easy integration with other systems and services. As our customer service ecosystem evolves, we can easily add new triggers or outputs to our intent classification system. </p>
<p class="normal">This could include integrating with new communication channels, connecting to additional backend systems, or incorporating advanced analytics for deeper insights into customer behavior and preferences.</p>
<p class="normal">In the following sections, we’ll dive deeper into each component of our architecture, exploring the specific Google Cloud services we’ll use, best practices for implementation, and strategies for optimizing performance and cost-efficiency. We’ll also discuss a concrete example that will help you get started.</p>
<h2 class="heading-2" id="_idParaDest-80">Entry point</h2>
<p class="normal">For real-time interactive applications, the entry points where prompts originate need to be highly <a id="_idIndexMarker252"/>streamlined, with simplicity and ease of use in mind. These prompts often originate from unpredictable contexts, so interfaces have to feel natural across device types and usage scenarios.</p>
<p class="normal">In our use case, the entry point could be a web form, chat interface, or API endpoint where customers submit their inquiries. These inputs will be sent to a cloud function, which acts as the ingestion layer for our system.</p>
<p class="normal">Let’s start with a sample user query:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#In this case we will simulate the input from a chat interface</span>
message = <span class="hljs-string">"I want to open an account"</span>
</code></pre>
<h2 class="heading-2" id="_idParaDest-81">Prompt pre-processing</h2>
<p class="normal">In a real-time system, every step in the prompt pre-processing workflow adds precious latency, commonly measured in milliseconds or microseconds depending on your application’s SLAs, to the overall response time. Higher-latency experiences can be detrimental to the user experience. Therefore, pre-processing should be kept as lightweight as possible.</p>
<p class="normal">For <a id="_idIndexMarker253"/>our intent classification use case, the prompt pre-processing may involve simple text normalization, such as removing punctuation, converting to lowercase, or handling abbreviations. Additionally, we may apply some basic filtering to remove any potentially harmful or inappropriate content before sending the prompt to the model.</p>
<p class="normal">Let’s dive deep into an example prompt:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#In this section we define the prompt, as the task is to perform intent </span>
<span class="hljs-comment">#classification we will identify the intent by exposing</span>
<span class="hljs-comment">#the possible values to the LLM</span>
prompt_template = <span class="hljs-string">"""</span>
<span class="hljs-string">You are a helpful assistant for an online financial services company that allows users to check their balances, invest in certificates of deposit (CDs), and perform other financial transactions.</span>
<span class="hljs-string">Your task is to identify what your customers are trying to do and return a well formed JSON object.</span>
<span class="hljs-string">1. Carefully analyze the content of the message.</span>
<span class="hljs-string">2. Classify what the user is trying to do within these options:</span>
<span class="hljs-string">   * New Account: The user is trying to sign up. Return {{"intent": "signup", "content":"null"}}</span>
<span class="hljs-string">   * Change Password: The user needs to reset their password. Return {{"intent":"change_password", "content":"null"}}</span>
<span class="hljs-string">   * Check Balance: The user needs to check their balance. Return {{"intent": "check_balance", "content":"null"}}</span>
<span class="hljs-string">   * Invest in CD: The user wants to invest in a certificate of deposit. Return {{"intent": "invest_cd", "content": "Extract relevant information such as investment amount and term"}}</span>
<span class="hljs-string">   * Withdraw Funds: The user wants to withdraw money. Return {{"intent": "withdraw_funds", "content": "Extract information like amount and withdrawal method"}}</span>
<span class="hljs-string">   * Transfer Funds: The user wants to transfer money between accounts. Return {{"intent": "transfer_funds", "content": "Extract information like amount, source account, and destination account"}}</span>
<span class="hljs-string">   * Account Information: The user wants to access or update their account information. Return {{"intent": "account_info", "content": "Identify the specific information the user needs"}}</span>
<span class="hljs-string">   * Lost/Stolen Card: The user wants to report a lost or stolen card. Return {{"intent": "lost_card", "content": "null"}}</span>
<span class="hljs-string">   * Support: The user needs help and is not sure what to do. Return {{"intent": "support", "content": "null"}}</span>
<span class="hljs-string">   * Other: For other queries, politely decline to answer and clarify what you can help with.</span>
<span class="hljs-string">3. Only return the proper JSON result from your classification.</span>
<span class="hljs-string">4. Always think step by step.</span>
<span class="hljs-string">User question: {query}</span>
<span class="hljs-string">JSON:</span>
<span class="hljs-string">"""</span>
</code></pre>
<p class="normal">The <a id="_idIndexMarker254"/>previous prompt defines the template for the intent classification task. The prompt provides context that explains that the assistant is helping users of an online financial services company perform various actions, such as signing up, checking balances, investing in CDs, withdrawing funds, and more.</p>
<p class="normal">Additionally, this prompt instructs the model to carefully analyze the user’s input message and classify the intent into one of the predefined categories. For each intent category, the prompt specifies the JSON object that should be returned, including any additional information that needs to be extracted from the user’s message.</p>
<p class="normal">For example, if the user’s intent is to invest in a CD, the assistant should return the JSON object in the following format:</p>
<pre class="programlisting code"><code class="hljs-code">{
   <span class="hljs-string">"intent"</span>: <span class="hljs-string">"invest_cd"</span>,
   <span class="hljs-string">"content"</span>: <span class="hljs-string">"Extract relevant information such as investment amount and term"</span>
}
</code></pre>
<p class="normal">This <a id="_idIndexMarker255"/>means that the virtual assistant should not only identify the intent as <code class="inlineCode">"invest_cd"</code> but also extract relevant information like the investment amount and term from the user’s message and include it in the <code class="inlineCode">"content"</code> field.</p>
<p class="normal">The prompt also provides instructions for handling intents that do not fall into any of the predefined categories (the <code class="inlineCode">"Other"</code> case).</p>
<p class="normal">By providing this detailed prompt template, the system can effectively guide the language model to perform the intent classification task for financial services scenarios, ensuring that the model’s responses are structured and formatted correctly.</p>
<h2 class="heading-2" id="_idParaDest-82">Inference</h2>
<p class="normal">At the inference stage, we’ll leverage Google’s Gemini Pro model hosted on Vertex AI. Within <a id="_idIndexMarker256"/>the cloud function triggered by the user input, we’ll invoke the Vertex AI endpoint hosting the Gemini Pro model, passing the pre-processed input as the prompt.</p>
<p class="normal">Gemini Pro will process the input and return the predicted intent, leveraging its natural language understanding capabilities. Since we’re using an out-of-the-box model, the underlying infrastructure and resource allocation are abstracted away, ensuring that individual requests are processed efficiently while adhering to the service’s performance and cost objectives:</p>
<pre class="programlisting code"><code class="hljs-code">generation_config = {
   <span class="hljs-string">"max_output_tokens"</span>: <span class="hljs-number">8192</span>,
   <span class="hljs-string">"temperature"</span>: <span class="hljs-number">0</span>,
   <span class="hljs-string">"top_p"</span>: <span class="hljs-number">0.95</span>,
}
safety_settings = {
   generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
   generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
   generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
   generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
}
<span class="hljs-keyword">def</span> <span class="hljs-title">generate</span>(<span class="hljs-params">prompt</span>):
 vertexai.init(project=PROJECT, location=LOCATION)
 model = GenerativeModel(MODEL)
 responses = model.generate_content(
     [prompt],
     generation_config=generation_config,
     safety_settings=safety_settings,
     stream=<span class="hljs-literal">False</span>,
 )
 <span class="hljs-keyword">return</span>(responses)
result = generate(prompt_template.<span class="hljs-built_in">format</span>(query=message))
</code></pre>
<h2 class="heading-2" id="_idParaDest-83">Result post-processing</h2>
<p class="normal">For our intent classification use case, the post-processing step may involve formatting the <a id="_idIndexMarker257"/>predicted intent into a suitable response format, such as JSON or a human-readable string. Additionally, we may apply some basic filtering or ranking mechanisms to ensure that the most relevant and helpful responses are prioritized.</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">### Sometimes model return markdown friendly content, in this case we will implement a function to filter this.</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">extract_json</span>(<span class="hljs-params">text</span>):
 <span class="hljs-string">"""</span>
<span class="hljs-string"> Extracts the JSON portion from a string containing backticks.</span>
<span class="hljs-string"> Args:</span>
<span class="hljs-string">   text: The string containing JSON data within backticks.</span>
<span class="hljs-string"> Returns:</span>
<span class="hljs-string">   A dictionary representing the extracted JSON, or None if no valid JSON is found.</span>
<span class="hljs-string"> """</span>
 start_index = text.find(<span class="hljs-string">"```json"</span>)
 end_index = text.find(<span class="hljs-string">"```"</span>, start_index + <span class="hljs-number">7</span>)  <span class="hljs-comment"># +7 to skip "```json"</span>
 <span class="hljs-keyword">if</span> start_index != -<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> end_index != -<span class="hljs-number">1</span>:
   json_string = text[start_index + <span class="hljs-number">7</span>: end_index]  <span class="hljs-comment"># Extract the JSON string</span>
 <span class="hljs-keyword">else</span>:
   json_string = text
 <span class="hljs-keyword">try</span>:
   json_data = json.loads(json_string)
   <span class="hljs-keyword">return</span> json_data
 <span class="hljs-keyword">except</span> json.JSONDecodeError:
   <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
</code></pre>
<p class="normal">The previous code snippet defines a function called <code class="inlineCode">extract_json</code> that is designed to handle <a id="_idIndexMarker258"/>cases where the language model’s output contains JSON data wrapped in backticks: <code class="inlineCode">json```</code>. This is a common practice in Markdown-friendly environments, where backticks are used to delineate code blocks or structured data.</p>
<p class="normal">The <code class="inlineCode">extract_json</code> function takes <a id="_idIndexMarker259"/>a string text as input and attempts to extract the JSON portion from within the backticks. Here’s a breakdown of how the function works:</p>
<ol>
<li class="numberedList" value="1">The function first looks for the string <code class="inlineCode">"```json"</code> in the input text using the <code class="inlineCode">find</code> method. This is the marker that indicates the start of a JSON block.</li>
<li class="numberedList">If the <code class="inlineCode">start</code> marker is found, the function then looks for the closing <code class="inlineCode">""</code> marker by searching for it from the end of the <code class="inlineCode">json</code> marker (<code class="inlineCode">start_index + 7</code>). If both the start and end markers are found, the function extracts the JSON string by slicing the input text between these markers. If no start or end markers are found, the function assumes that the entire input text is the JSON string.</li>
<li class="numberedList">The function then attempts to parse the extracted JSON string using the <code class="inlineCode">json.loads</code> method from the <code class="inlineCode">json</code> module. If the parsing is successful, the function returns the resulting JSON data as a dictionary. If the parsing fails (for example, due to invalid JSON syntax), the function returns <code class="inlineCode">None</code>. By incorporating this function into the post-processing stage, the system can handle cases where the language model’s output contains JSON data wrapped in backticks. This functionality can be particularly useful when working with Markdown-friendly environments or when integrating the intent classification system with other components that expect JSON-formatted data.</li>
<li class="numberedList">The post-processing stage can then proceed to format the extracted JSON data into a suitable response format, apply filtering or ranking mechanisms, and render the final response for display to the user.</li>
</ol>
<p class="normal-one">The <code class="inlineCode">process_intent</code> function is <a id="_idIndexMarker260"/>designed to handle the JSON data returned by the intent classification model. It takes a dictionary intent as input, which is expected to have an “intent” key with a value representing the predicted intent category.</p>
<pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">process_intent</span>(<span class="hljs-params">intent</span>):
 <span class="hljs-keyword">if</span> intent[<span class="hljs-string">"</span><span class="hljs-string">intent"</span>] == <span class="hljs-string">"signup"</span>:
   <span class="hljs-comment">#If a user is trying to sign up you could </span>
<span class="hljs-comment">   #redirect the to a sign up page for example.</span>
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Sign up process"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"change_password"</span>:
   <span class="hljs-comment">#If a user is looking into changing their password, </span>
<span class="hljs-comment">   #you could either do it through the chatbot, </span>
<span class="hljs-comment">   #or redirect to a password change page.</span>
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"</span><span class="hljs-string">Change password"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"check_balance"</span>:
   <span class="hljs-comment">#In this case you could have a function that </span>
<span class="hljs-comment">   #would query a database to obtain the </span>
<span class="hljs-comment">   #balance (as long as the user is logged in or not)</span>
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Check account balance"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"invest_cd"</span>:
   <span class="hljs-comment">#For the investment intent, this could redirect </span>
<span class="hljs-comment">   #to a page where investment options can be selected.</span>
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Invest in a CD"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"withdraw_funds"</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Withdraw funds"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"</span><span class="hljs-string">transfer_funds"</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Transfer funds"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"account_info"</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Account information"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"</span><span class="hljs-string">lost_card"</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Report lost card"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"support"</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Contact support"</span>)
 <span class="hljs-keyword">elif</span> intent[<span class="hljs-string">"intent"</span>] == <span class="hljs-string">"</span><span class="hljs-string">other"</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"Other kind of intent"</span>)
 <span class="hljs-keyword">else</span>:
   <span class="hljs-keyword">return</span>(<span class="hljs-string">"If a intent was classified as something else you should investigate what is going on."</span>)
intent = process_intent(extract_json(result.text))
</code></pre>
<p class="normal">The <code class="inlineCode">process_intent</code> function checks the value of the <code class="inlineCode">"intent"</code> key in the input dictionary. Depending on the intent category, the function performs a specific action or returns a corresponding message. </p>
<p class="normal">For example, if the intent is <code class="inlineCode">"signup"</code>, the function returns the string <code class="inlineCode">"Sign up process"</code>, which could be used to redirect the user to a sign-up page or initiate the sign-up process. Similarly, if the intent is <code class="inlineCode">"change_password"</code>, the function returns <code class="inlineCode">"Change password"</code>, which <a id="_idIndexMarker261"/>could trigger a password reset process or redirect the user to a password change page.</p>
<p class="normal">For intents like <code class="inlineCode">"check_balance"</code>, <code class="inlineCode">"invest_cd"</code>, <code class="inlineCode">"withdraw_funds"</code>, <code class="inlineCode">"transfer_funds"</code>, <code class="inlineCode">"account_info"</code>, <code class="inlineCode">"lost_card"</code>, and <code class="inlineCode">"support"</code>, the function returns corresponding messages that could be used to initiate the relevant processes or provide instructions to the user.</p>
<p class="normal">If the intent is <code class="inlineCode">"other"</code>, the function returns <code class="inlineCode">"Other kind of intent"</code>, indicating that the user’s query did not match any of the predefined intent categories.</p>
<p class="normal">If the intent does not match any of the cases handled by the function, it returns a message suggesting that further investigation is needed to understand the intent.</p>
<p class="normal">Finally, the last line of code <code class="inlineCode">intent = process_intent(extract_json(result.text))</code> combines the <code class="inlineCode">extract_json</code> and <code class="inlineCode">process_intent</code> functions. It first extracts the JSON data from the <code class="inlineCode">result.text</code> string using <code class="inlineCode">extract_json</code>. Then, it passes the extracted JSON data to the <code class="inlineCode">process_intent</code> function, which processes the intent and returns an appropriate message or action.</p>
<p class="normal">This code snippet demonstrates how the intent classification system can be integrated with further processing steps to handle different user intents. The <code class="inlineCode">process_intent</code> function can be extended or modified to include additional logic or actions based on the specific requirements of the application.</p>
<h2 class="heading-2" id="_idParaDest-84">Result presentation</h2>
<p class="normal">The result presentation stage for real-time applications demands instantaneous updates, often server-rendered or via data-binding frameworks.</p>
<p class="normal">In <a id="_idIndexMarker262"/>our use case, the formatted response containing the predicted intent can be sent back to the customer through the channel from which the inquiry originated (for example, web form, chat interface, or API response). This response can then be used to route the inquiry to the appropriate downstream system or provide an automated response for common intents.</p>
<p class="normal">In this <a id="_idIndexMarker263"/>example, we will use a Gradio interface to render the replies in a visually appealing UI. Gradio (<a href="https://www.gradio.app/"><span class="url">https://www.gradio.app/</span></a>) is an open-source Python package that allows you to quickly create easy-to-use, customizable UI components for your ML model, any API, or even an arbitrary Python function using a few lines of code.</p>
<div class="note">
<p class="normal">You can find more information about Gradio using the following links:</p>
<p class="normal">Docs: <a href="https://www.gradio.app/docs%0D%0A"><span class="url">https://www.gradio.app/docs</span></a></p>
<p class="normal">GitHub: <a href="https://github.com/gradio-app/gradio"><span class="url">https://github.com/gradio-app/gradio</span></a></p>
</div>
<p class="normal">The following code provides an example that creates a Gradio interface:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr
<span class="hljs-keyword">def</span> <span class="hljs-title">chat</span>(<span class="hljs-params">message, history</span>):
   response = generate(prompt_template.<span class="hljs-built_in">format</span>(query=message))
   intent_action = process_intent(extract_json(response.text))
   history.append((message, intent_action))
   <span class="hljs-keyword">return</span> <span class="hljs-string">""</span>, history
<span class="hljs-keyword">with</span> gr.Blocks() <span class="hljs-keyword">as</span> demo:
 gr.Markdown(<span class="hljs-string">"Fintech Assistant"</span>)
 chatbot = gr.Chatbot(show_label=<span class="hljs-literal">False</span>)
 message = gr.Textbox(placeholder=<span class="hljs-string">"Enter your question"</span>)
 message.submit(chat, [message, chatbot],[message, chatbot]  )
demo.launch(debug=<span class="hljs-literal">True</span>)
</code></pre>
<p class="normal">The previous code illustrates the result presentation stage for the intent classification system using the Gradio library. </p>
<p class="normal">In our <a id="_idIndexMarker264"/>example, the <code class="inlineCode">chat(message, history)</code> function is the core of the chatbot interface. It takes two arguments: <code class="inlineCode">message</code> (the user’s input message) and <code class="inlineCode">history</code> (a list containing the previous messages and responses). Here’s what the function does:</p>
<ol>
<li class="numberedList" value="1">It calls the <code class="inlineCode">generate</code> function (not shown in the provided code) to get the response from the intent classification model, passing the user’s message as part of the prompt template. It then processes the model’s response using the <code class="inlineCode">extract_json</code> function (not shown) to extract the predicted intent data.</li>
<li class="numberedList">The extracted intent data is passed to the <code class="inlineCode">process_intent</code> function (which is not shown) to determine the appropriate action or response based on the predicted intent. The user’s message and the generated response are appended to the history list, which keeps track of the conversation.</li>
<li class="numberedList">The function returns an empty string for the response message and the updated history list.</li>
<li class="numberedList">The code then creates a Gradio interface using the <code class="inlineCode">gr.Blocks</code> context manager. Inside the context, it does the following:<ul>
<li class="bulletList level-2">Displays a title using the gr.Markdown component.</li>
<li class="bulletList level-2">Creates a <code class="inlineCode">gr.Chatbot</code> component to display the conversation history.</li>
<li class="bulletList level-2">Creates a <code class="inlineCode">gr.Textbox</code> component for the user to enter their message.</li>
<li class="bulletList level-2">Binds the chat function to the <code class="inlineCode">submit</code> event of the <code class="inlineCode">Textbox</code> component. When the user submits their message, the chat function is called with the user’s message and the current history as arguments.</li>
<li class="bulletList level-2">Updates the <code class="inlineCode">Textbox</code> and <code class="inlineCode">Chatbot</code> components with the new message and updated history, respectively.</li>
<li class="bulletList level-2">Launches the Gradio interface in debug mode using <code class="inlineCode">demo.launch(debug=True)</code>.</li>
</ul>
</li>
</ol>
<p class="normal">The <a id="_idIndexMarker265"/>result is an interactive chatbot interface where users can enter their messages as illustrated in <em class="italic">Figure 7.2</em>, and the system will process the message, predict the intent, and provide an appropriate response based on the <code class="inlineCode">process_intent</code> function. The conversation history is displayed in the <code class="inlineCode">Chatbot</code> component, allowing users to track the flow of the conversation.</p>
<figure class="mediaobject"><img alt="" height="465" src="../Images/B22175_07_02.png" width="825"/></figure>
<p class="packt_figref">Figure 7.2: Example Gradio interface</p>
<h2 class="heading-2" id="_idParaDest-85">Logging and monitoring</h2>
<p class="normal">Real-time systems require tight instrumentation around per-request metrics, such as latencies, errors, and resource usage.</p>
<p class="normal">In <a id="_idIndexMarker266"/>our architecture, we’ll <a id="_idIndexMarker267"/>leverage services like Cloud Logging (<a href="https://cloud.google.com/logging/docs/overview"><span class="url">https://cloud.google.com/logging/docs/overview</span></a>) and Cloud Monitoring (<a href="https://cloud.google.com/monitoring/docs/monitoring-overview"><span class="url">https://cloud.google.com/monitoring/docs/monitoring-overview</span></a>) to gain visibility into the <a id="_idIndexMarker268"/>system’s behavior and quickly identify and resolve any issues. We can monitor metrics like request latency, error rates, and resource utilization, and set up alerts for anomalies or performance degradation.</p>
<p class="normal">By following this integration pattern and leveraging the power of Google’s Gemini Pro, businesses can unlock the power of generative AI to build intelligent systems that accurately classify user intents, enhance customer experiences, and streamline operations.</p>
<p class="normal">Refer to the GitHub directory of this chapter for the complete code that demonstrates how all the pieces described above fit together.</p>
<h1 class="heading-1" id="_idParaDest-86">Summary</h1>
<p class="normal">In this chapter, we discussed the integration pattern for building a real-time intent classification system using Google’s Gemini Pro generative AI model. We started by introducing the concept of real-time integration patterns, which prioritize low latency over efficiency and volume, as opposed to batch-processing integration patterns.</p>
<p class="normal">The use case we developed is an e-commerce company that wants to improve its customer service experience by automatically categorizing incoming customer inquiries into predefined intents, such as order status, product inquiry, return request, or general feedback. This classification can then be used to route the inquiry to the appropriate team or provide automated responses for common issues.</p>
<p class="normal">The architecture proposed is a serverless, event-driven architecture on Google Cloud, consisting of an ingestion layer (Cloud Functions), an AI processing layer (Vertex AI with Gemini Pro), an intent classification model, orchestration and routing (Cloud Functions or Cloud Run), and monitoring and logging (Cloud Logging, Cloud Monitoring, and Cloud Operations).</p>
<p class="normal">In the next chapter, we will dive deep into another very important real-time use case, a <strong class="keyWord">Retrieval Augmented Generation</strong> (<strong class="keyWord">RAG</strong>) example where we are going to leverage generative AI to answer questions based on documents provided by us.</p>
<h1 class="heading-1">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the authors and other readers:</p>
<p class="normal"><a href="Chapter_07.xhtml"><span class="url">https://packt.link/genpat</span></a></p>
<p class="normal"><img alt="" height="177" src="../Images/QR_Code134841911667913109.png" width="177"/></p>
</div>
</div></body></html>