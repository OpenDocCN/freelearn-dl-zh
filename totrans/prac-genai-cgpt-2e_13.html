<html><head></head><body>
<div><h1 class="chapterNumber">10</h1>
<h1 class="chapterTitle" id="_idParaDest-136">Leveraging OpenAI’s Models for Enterprise-Scale Applications</h1>
<p class="normal">In this chapter, we’ll focus on the enterprise-level applications of <strong class="keyWord">generative AI</strong> (<strong class="keyWord">GenAI</strong>) and, more specifically, of OpenAI’s models. We will see how different industries have been massively <a id="_idIndexMarker519"/>impacted by GenAI in recent years, and what kinds of trending patterns and applications have emerged.</p>
<p class="normal">In this chapter, we will discuss the following topics:</p>
<ul>
<li class="bulletList">The latest advancements in various industries (including healthcare, financial services, retail, and more), driven by the outstanding capabilities of powerful LLMs, highlighting the most trending use cases</li>
<li class="bulletList">The architectural framework behind custom applications powered by OpenAI’s models, unveiling the versatility and adoption of the models’ APIs</li>
<li class="bulletList">Introduction to Azure OpenAI, the Microsoft cloud-based service that mirrors OpenAI’s Playground and offers OpenAI’s models directly within the perimeter of Azure subscriptions</li>
</ul>
<p class="normal">By the end of this chapter, you will have learned about the main GenAI patterns across various industries, and how to leverage OpenAI’s models’ APIs within your own applications. Plus, you will have a clearer understanding of the cloud-scale service of Azure OpenAI and how to incorporate ethical considerations when developing AI-based solutions.</p>
<h1 class="heading-1" id="_idParaDest-137">Technical requirements</h1>
<p class="normal">The following are the technical requirements for this chapter:</p>
<ul>
<li class="bulletList">An OpenAI account, chat model, and embedding model deployments</li>
<li class="bulletList">[Optional] An Azure subscription and Azure OpenAI instance, with chat model and embedding model deployments</li>
<li class="bulletList">Python 3.7.1 or a later version</li>
</ul>
<p class="normal">You can refer to the following repository for the OpenAI Python SDKs: https://github.com/openai/openai-python.</p>
<h1 class="heading-1" id="_idParaDest-138">How GenAI is disrupting industries</h1>
<p class="normal">LLMs, and GenAI in general, are revolutionizing various industries by introducing unprecedented <a id="_idIndexMarker520"/>levels of automation, creativity, and efficiency. In recent years, we’ve witnessed a huge wave of innovation across different industries that all agree that not seizing the GenAI opportunity would mean falling behind in a competitive market.</p>
<p class="normal">Let’s see some examples.</p>
<h2 class="heading-2" id="_idParaDest-139">Healthcare</h2>
<p class="normal">In healthcare, GenAI <a id="_idIndexMarker521"/>and LLMs are enhancing diagnostics, personalized <a id="_idIndexMarker522"/>medicine, and administrative tasks:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Diagnostics</strong>: LLMs like GPT-4 are being used to analyze medical images, predict diseases, and <a id="_idIndexMarker523"/>suggest treatment plans. For instance, AI-powered tools can now analyze radiology images with high accuracy, identifying early signs of conditions like cancer or heart disease, often outperforming human radiologists in speed and consistency. A great example of the latest advancements in the computer vision field is given in an article by Tyler J. Bradshaw et al., “Large Language Models and Large Multimodal Models in Medical Imaging: A Primer for Physicians”, published in <em class="italic">The Journal of Nuclear Medicine</em> (you can find it at https://jnm.snmjournals.org/content/early/2025/01/16/jnumed.124.268072).</li>
<li class="bulletList"><strong class="keyWord">Personalized medicine</strong>: GenAI is helping in the development of personalized treatment <a id="_idIndexMarker524"/>plans by analyzing patient data, including genetic information. This has led to tailored therapies that improve outcomes.</li>
<li class="bulletList"><strong class="keyWord">Administrative efficiency</strong>: LLMs <a id="_idIndexMarker525"/>are streamlining administrative tasks such as patient record management and appointment scheduling. AI chatbots can handle patient queries, reducing the workload on medical staff.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-140">Case study</h3>
<p class="normal">OpenAI has partnered with Summer Health, a healthcare service that provides fast and convenient <a id="_idIndexMarker526"/>access to pediatric care through text messaging. The collaboration aims to enhance the capabilities of Summer Health’s platform by integrating OpenAI’s advanced language models. This integration enables more efficient and accurate responses to parents’ healthcare inquiries, providing quick, reliable medical advice for children’s health concerns. This has led to increased efficiency and improved timeliness, with data being kept anonymous. The AI-driven platform helps streamline communication between parents and healthcare professionals, improving the overall experience and accessibility of pediatric care.</p>
<p class="normal"><em class="italic">Source: </em>https://openai.com/index/summer-health/.</p>
<h2 class="heading-2" id="_idParaDest-141">Finance</h2>
<p class="normal">In finance, GenAI <a id="_idIndexMarker527"/>and LLMs are transforming risk management, customer <a id="_idIndexMarker528"/>service, and investment strategies:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Claim management</strong>: LLMs are employed to automate the summarization, review, triage, and adjudication of claims. For instance, Munich Re developed an LLM-powered <a id="_idIndexMarker529"/>solution for claim management that led to a streamlined claims process, reduced manual effort, and improved decision-making accuracy (https://www.munichre.com/us-life/en/insights/future-of-risk/large-language-models-in-underwriting-and-claims.html).</li>
<li class="bulletList"><strong class="keyWord">Customer service</strong>: AI-driven chatbots and virtual assistants are now common in the <a id="_idIndexMarker530"/>finance sector, handling customer inquiries, processing transactions, and providing financial advice. ING’s AI assistant is a prime example of a virtual assistant that helps customers manage their finances by providing insights, reminders, and transaction details (https://www.mckinsey.com/industries/financial-services/how-we-help-clients/banking-on-innovation-how-ing-uses-generative-ai-to-put-people-first).</li>
<li class="bulletList"><strong class="keyWord">Investment strategies</strong>: Hedge funds and investment firms are using GenAI to create <a id="_idIndexMarker531"/>predictive models that inform trading decisions. AI algorithms analyze market data to identify patterns and make real-time trading decisions. BlackRock’s Aladdin platform is one such example, leveraging AI to manage investments and assess market risks (https://www.blackrock.com/aladdin/solutions/aladdin-copilot).</li>
</ul>
<h3 class="heading-3" id="_idParaDest-142">Case study</h3>
<p class="normal">Moody’s Corporation, a leading global provider of credit ratings, research, and risk analysis, has partnered <a id="_idIndexMarker532"/>with Microsoft to develop enhanced risk data analytics and research solutions powered by GenAI. This collaboration combines Moody’s vast expertise in financial risk and data analytics with Microsoft’s advanced AI technology. The result is a set of tools that offer real-time insights into financial risks, enabling more precise decision-making and improved risk management for financial institutions and other stakeholders.</p>
<p class="normal">Source: https://news.microsoft.com/2023/06/29/moodys-and-microsoft-develop-enhanced-risk-data-analytics-research-and-collaboration-solutions-powered-by-generative-ai/?msockid=2dc01bb6f864693933ed0eb3f9a668dc.</p>
<h2 class="heading-2" id="_idParaDest-143">Retail and e-commerce</h2>
<p class="normal">In retail <a id="_idIndexMarker533"/>and e-commerce, GenAI and LLMs are enhancing customer <a id="_idIndexMarker534"/>experience, inventory management, and personalized marketing:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Customer experience</strong>: AI-powered <a id="_idIndexMarker535"/>chatbots provide personalized customer service, helping shoppers find products, resolve issues, and make purchases.</li>
<li class="bulletList"><strong class="keyWord">Inventory management</strong>: LLMs <a id="_idIndexMarker536"/>help retailers predict demand and optimize inventory levels by analyzing sales data, seasonal trends, and customer behavior.</li>
<li class="bulletList"><strong class="keyWord">Personalized marketing</strong>: GenAI <a id="_idIndexMarker537"/>is enabling hyper-personalized marketing campaigns. By analyzing customer data, AI can create targeted advertisements and product recommendations.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-144">Case study</h3>
<p class="normal">Coca-Cola <a id="_idIndexMarker538"/>has launched an innovative initiative inviting <a id="_idIndexMarker539"/>digital artists to create unique artworks using a new AI-powered platform developed in collaboration with <strong class="keyWord">Google Cloud Platform</strong> (<strong class="keyWord">GCP</strong>). This platform allows artists to generate digital content by blending Coca-Cola’s iconic branding elements with their creativity. The initiative, called “Create Real Magic,” leverages advanced AI tools to inspire and empower artists, facilitating the creation of digital art that resonates with Coca-Cola’s brand ethos. This project highlights how AI can be used to bridge creativity and technology in the retail and consumer goods industry.</p>
<p class="normal">Source: https://brandthechange.com/creativity/create-real-magic-inside-coca-colas-first-ai-powered-campaign/#:~:text=The%20Coca-Cola%20Company%20has%20partnered%20with%20OpenAI%20and,using%20iconic%20creative%20assets%20from%20the%20Coca-Cola%20archives.</p>
<h2 class="heading-2" id="_idParaDest-145">Manufacturing</h2>
<p class="normal">In manufacturing, GenAI <a id="_idIndexMarker540"/>and LLMs are driving automation, quality <a id="_idIndexMarker541"/>control, and supply chain optimization:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Automation</strong>: AI-powered <a id="_idIndexMarker542"/>robots and systems are automating repetitive tasks, such as assembly line work and material handling.</li>
<li class="bulletList"><strong class="keyWord">Quality control</strong>: LLMs are used to monitor production processes in real time, identifying <a id="_idIndexMarker543"/>defects or inefficiencies. AI systems can analyze data from sensors and cameras to detect anomalies in products, ensuring higher quality.</li>
<li class="bulletList"><strong class="keyWord">Supply chain optimization</strong>: AI <a id="_idIndexMarker544"/>models help manufacturers optimize their supply chains by predicting demand, managing inventory, and selecting suppliers.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-146">Case study</h3>
<p class="normal">Iveco Group, a leading global manufacturer of commercial vehicles, has partnered with Microsoft <a id="_idIndexMarker545"/>to integrate Azure OpenAI Service into its business processes. The customer developed an internal smart chatbot called “Chat IVG”, which can be used for questions and answers and to extract information from the organization’s own data and documents. Plus, numerous use cases and autonomous projects are being developed and deployed in production, either leveraging Chat IVG’s specific customizations or using its architecture as a foundation. Chat IVG is driving significant impact by enhancing internal business user experiences, boosting productivity across various business units, and enabling faster, more efficient<a href="https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy"> customer support.</a></p>
<p class="normal"><a href="https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy">Source: https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-</a>service-manufacturing-italy.</p>
<h2 class="heading-2" id="_idParaDest-147">Media and entertainment</h2>
<p class="normal">In media <a id="_idIndexMarker546"/>and entertainment, GenAI and LLMs are revolutionizing <a id="_idIndexMarker547"/>content creation, audience engagement, and media distribution:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Content creation</strong>: GenAI is being used to generate content, from writing articles to <a id="_idIndexMarker548"/>composing music. For example, The Washington Post uses AI to write short news articles and reports, freeing up journalists to focus on more complex stories. In music, AI platforms like OpenAI’s MuseNet can compose original music tracks in various styles, aiding musicians in the creative process.</li>
<li class="bulletList"><strong class="keyWord">Audience engagement</strong>: LLMs <a id="_idIndexMarker549"/>analyze user data to deliver personalized content recommendations, keeping audiences engaged. Netflix uses AI to recommend movies and TV shows based on viewers’ preferences, significantly increasing viewer retention.</li>
<li class="bulletList"><strong class="keyWord">Media distribution</strong>: AI is also optimizing media distribution by analyzing audience <a id="_idIndexMarker550"/>demographics and consumption patterns. Spotify uses AI to curate personalized playlists, ensuring that users discover new music tailored to their tastes.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-148">Case study</h3>
<p class="normal">Microsoft’s Xbox division has announced a multi-year partnership with Inworld AI to develop advanced <a id="_idIndexMarker551"/>GenAI tools for game development. This collaboration aims to enhance character dialogue and narrative creation by integrating Inworld’s expertise in GenAI with Microsoft’s Azure OpenAI Service and insights from Microsoft Research. The goal is to empower game developers to create more dynamic and immersive gaming experiences.</p>
<p class="normal">Source: https://developer.microsoft.com/en-us/games/articles/2023/11/xbox-and-inworld-ai-partnership-announcement/.</p>
<h2 class="heading-2" id="_idParaDest-149">Legal services</h2>
<p class="normal">In the <a id="_idIndexMarker552"/>legal industry, GenAI and LLMs are transforming research, contract analysis, and case prediction:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Legal research</strong>: AI tools are accelerating legal research by analyzing vast amounts of legal documents, case laws, and statutes. For example, ROSS Intelligence uses AI to provide lawyers with relevant case laws and legal precedents in seconds, which would otherwise take hours to find manually.</li>
<li class="bulletList"><strong class="keyWord">Contract analysis</strong>: LLMs are used to review and analyze contracts, identifying key terms, risks, and compliance issues. This helps in speeding up negotiations and ensuring <a id="_idIndexMarker553"/>that contracts are airtight. Kira Systems is one example where AI reviews contracts for due diligence, identifying clauses and potential risks.</li>
<li class="bulletList"><strong class="keyWord">Case prediction</strong>: GenAI is being used to predict the outcomes of legal cases based on historical data. By analyzing past cases, AI can provide lawyers with insights into likely judgments, helping them strategize better. Lex Machina, for example, uses AI to predict how judges might rule in intellectual property disputes.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-150">Case study</h3>
<p class="normal">Ironclad, a leading digital contracting platform, has partnered with OpenAI to integrate advanced AI capabilities into its legal workflows. By leveraging OpenAI’s language models, Ironclad <a id="_idIndexMarker554"/>enhances its platform’s ability to automate contract analysis, generate and review legal documents, and provide insights to legal teams more efficiently. </p>
<p class="normal">This integration allows for faster, more accurate contract processing, reducing the time spent on manual reviews and enabling legal teams to focus on higher-value tasks. The collaboration underscores the growing role of AI in transforming the legal industry by improving accuracy and productivity in contract management.</p>
<h2 class="heading-2" id="_idParaDest-151">Education</h2>
<p class="normal">In education, GenAI <a id="_idIndexMarker555"/>and LLMs are transforming learning <a id="_idIndexMarker556"/>experiences, personalized education, and administrative tasks:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Learning experiences</strong>: AI-driven platforms are creating personalized learning paths <a id="_idIndexMarker557"/>for students based on their strengths and weaknesses. For instance, platforms like Coursera use AI to recommend courses and resources tailored to each learner’s progress and preferences.</li>
<li class="bulletList"><strong class="keyWord">Personalized education</strong>: LLMs <a id="_idIndexMarker558"/>can tutor students by answering questions, explaining concepts, and providing feedback on assignments. Khan Academy’s AI-powered tutor is an example, offering personalized help to students struggling with specific topics.</li>
<li class="bulletList"><strong class="keyWord">Administrative tasks</strong>: AI is also being used to automate administrative tasks such as grading and scheduling. For instance, Turnitin uses AI to grade essays and detect plagiarism, saving educators time and ensuring academic integrity.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-152">Case study</h3>
<p class="normal">Khan Academy has partnered with OpenAI to incorporate advanced AI capabilities into its educational <a id="_idIndexMarker559"/>platform. By integrating OpenAI’s language models, Khan Academy is able to provide personalized tutoring, answer student queries, and assist with learning in a more interactive and dynamic way. This collaboration aims to enhance the educational experience by offering students real-time assistance and tailored support, making learning more accessible and effective. The AI-powered tools help students grasp complex concepts, provide instant feedback, and adapt to individual learning styles, further democratizi<a href="https://openai.com/index/khan-academy/">ng education through technology.</a></p>
<p class="normal"><a href="https://openai.com/index/khan-academy/">Sourc</a>e: https://openai.com/index/khan-academy/.</p>
<p class="normal">The above examples are just a subset of the possibilities that GenAI has enabled in various industries. However, there is an element that unites all the examples covered: in each scenario, a custom application was built leveraging an LLM API.</p>
<h1 class="heading-1" id="_idParaDest-153">Understanding OpenAI models’ APIs</h1>
<p class="normal">In <em class="italic">Chapter 1</em> of this book, we saw how LLMs have introduced a paradigm shift in the landscape of AI: different <a id="_idIndexMarker560"/>from the tailored, highly specialized models that featured AI in the “before ChatGPT era,” LLMs are now able to be generalized and tackle different tasks depending on the user’s query.</p>
<p class="normal">Furthermore, there is one additional element that sets LLMs apart from previous models: in fact, LLMs typically come as pre-trained objects that anyone – even without any experience in the field of AI – can use with the easiest way of interacting: natural language.</p>
<p class="normal">Of course, no one is stopping you from designing and training your LLM from scratch, but be aware that this will require, at least:</p>
<ul>
<li class="bulletList">Technical knowledge on how to design the model</li>
<li class="bulletList">A huge amount of training data</li>
<li class="bulletList">Specialized infrastructure that can support the training and inference stages</li>
<li class="bulletList">A lot of time to invest in the project</li>
</ul>
<p class="normal">If the above elements used to be a barrier to entry for many AI developers in the past, now the paradigm has shifted. The new focus, in fact, is how to efficiently build everything that lives <em class="italic">around</em> an LLM, such as the system message, <strong class="keyWord">vector databases</strong> (<strong class="keyWord">VectorDBs</strong>), plugins, and so forth. That’s the reason why using LLMs’ APIs is now the validated pattern for building GenAI applications.</p>
<h2 class="heading-2" id="_idParaDest-154">What is a model API?</h2>
<p class="normal">Before talking <a id="_idIndexMarker561"/>about OpenAI models’ APIs, let’s first refresh our definition of what an API is.</p>
<p class="normal">An <strong class="keyWord">application programming interface</strong> (<strong class="keyWord">API</strong>) is a set of rules and tools that allows different software applications to communicate with each other. It’s like a translator that helps different programs <a id="_idIndexMarker562"/>or systems work together by sharing data and functionality in a standardized way. For example, when you use an app to check the weather, the app uses an API to get the weather information from a weather service.</p>
<figure class="mediaobject"><img alt="" src="img/B31559_10_01.png"/></figure>
<p class="packt_figref">Figure 10.1: A weather app using an API to gather information</p>
<p class="normal">Now, when it <a id="_idIndexMarker563"/>comes to LLMs’ APIs, the mechanism is similar. More specifically, LLMs’ APIs fall within the category of <strong class="keyWord">Representational State Transfer</strong> (<strong class="keyWord">REST</strong>) APIs, meaning that they:</p>
<ul>
<li class="bulletList">Use standard HTTP methods (POST for sending prompts, GET for retrieving data).</li>
<li class="bulletList">Communicate over HTTP/HTTPS.</li>
<li class="bulletList">Return responses in JSON format.</li>
<li class="bulletList">Follow a stateless model, meaning each request is independent.<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">A <strong class="keyWord">REST API</strong> is a <a id="_idIndexMarker564"/>web-based API that follows REST principles, using HTTP methods like GET, POST, PUT, and DELETE to interact with resources via URLs. It is stateless, meaning each request is independent, and it typically exchanges data in JSON format. Other types of APIs include <strong class="keyWord">SOAP</strong>, which relies <a id="_idIndexMarker565"/>on XML for structured messaging and strict security; <strong class="keyWord">GraphQL</strong>, which <a id="_idIndexMarker566"/>allows clients to request <a id="_idIndexMarker567"/>specific data for more flexibility; <strong class="keyWord">gRPC</strong>, which uses Protocol Buffers for efficient microservice communication; <strong class="keyWord">WebSockets</strong>, which enables <a id="_idIndexMarker568"/>real-time, two-way communication; and <strong class="keyWord">Streaming APIs</strong>, which <a id="_idIndexMarker569"/>provide continuous data flow, often used for AI responses and stock market feeds.</p>
</div>
</li>
</ul>
<p class="normal">Let’s explore <a id="_idIndexMarker570"/>how you might use an OpenAI model’s API to create a marketing assistant. This assistant helps marketers generate content like social media posts, email drafts, ad copy, or blog post ideas. Let’s break down the whole process:</p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord">Sending a request</strong>:<ul>
<li class="bulletList">A marketer using your application might type a prompt like, “Create a social media post promoting our new eco-friendly product line.”</li>
<li class="bulletList">Your marketing assistant sends this prompt to the OpenAI model’s API as part of a request. The request includes the prompt and any specific instructions, including the model to use – let’s say, the GPT-4o.</li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord">Processing by the model</strong>:<ul>
<li class="bulletList">The OpenAI API receives the request and processes the prompt using the specified model (in our case, the GPT-4o).</li>
<li class="bulletList">The model generates a response by analyzing the input and drawing on its extensive knowledge base. It considers factors like the target audience, common marketing phrases, and the desired tone to create relevant content.</li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord">Receiving the response</strong>:<ul>
<li class="bulletList">The API sends the generated content back to your marketing assistant application as a response.</li>
<li class="bulletList">For instance, the model might generate something like: “Excited to launch our new eco-friendly product line! Sustainable, stylish, and perfect for the conscious consumer. Join us in making a positive impact—shop now and save the planet, one product at a time! #EcoFriendly #Sustainability.”</li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord">Displaying the response</strong>:<ul>
<li class="bulletList">Your application receives the content from the API and displays it to the marketer.</li>
<li class="bulletList">The marketer can then review, edit, and publish the content as needed, saving time and effort in the content creation process.</li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord">Additional features</strong>:<ul>
<li class="bulletList"><strong class="keyWord">Customization</strong>: The marketer can further customize the request. For example, they might ask for a series of posts or request variations to test different marketing angles.</li>
<li class="bulletList"><strong class="keyWord">Feedback loop</strong>: The application might also allow the marketer to rate the generated content. This feedback could be used to fine-tune future requests, improving the relevance and quality of the content over time.</li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord">Behind the scenes</strong>:<ul>
<li class="bulletList"><strong class="keyWord">API key and authentication</strong>: To use the OpenAI API, your application needs an API key (a unique alphanumeric string used to authenticate and identify <a id="_idIndexMarker571"/>applications or projects making requests to an API), which ensures that only authorized users can access the service.</li>
<li class="bulletList"><strong class="keyWord">Handling multiple requests</strong>: The OpenAI API is designed to handle multiple requests at once, meaning it can serve many marketers simultaneously without slowing down.</li>
<li class="bulletList"><strong class="keyWord">Rate limits and cost</strong>: Depending on the API usage, there might be rate limits (e.g., how many requests can be sent per minute) and costs associated with the amount of text processed. Your application would need to manage these factors, perhaps by prioritizing certain requests or batching them.</li>
</ul>
</li>
</ol>
<p class="normal">The possibility of consuming OpenAI models via APIs gives developers great flexibility when it comes to customizing the application logic around the LLM. In the next section, we are going to see how to leverage those APIs in practice with Python.</p>
<h2 class="heading-2" id="_idParaDest-155">How to use OpenAI models’ APIs with the Python SDK</h2>
<p class="normal">To use <a id="_idIndexMarker572"/>OpenAI models’ APIs in your programming <a id="_idIndexMarker573"/>IDE, you first need to create an access token from your OpenAI account.</p>
<div><p class="normal"><strong class="keyWord">Note</strong></p>
<p class="normal">When consuming OpenAI’s APIs, you will incur a cost that is proportional to the model’s usage. More specifically, OpenAI’s pricing model is <strong class="keyWord">per token</strong>, where a token represents a chunk of text (about 4 characters in English). To estimate your tokens’ consumption – hence your cost – you can refer to this articl<a href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them">e: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-t</a>hem.</p>
<p class="normal">Each <a id="_idIndexMarker574"/>API request consumes tokens based on input (prompt) and output (response). Pricing varies by model, with <strong class="keyWord">more powerful models costing more per token.</strong></p>
<p class="normal">You can find OpenAI’s pricing model at https://openai.com/api/pricing/.</p>
</div>
<p class="normal">To do <a id="_idIndexMarker575"/>so, you can follow these steps:</p>
<ol>
<li class="numberedList" value="1">Navigat<a href="https://platform.openai.com/api-keys">e to https://platform.openai.com/api</a>-keys.</li>
<li class="numberedList">Click on <code class="inlineCode">+ Create new secret key</code>:</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_10_02.png"/></figure>
<p class="packt_figref">Figure 10.2: OpenAI API platform</p>
<ol>
<li class="numberedList" value="3">This will create a new API key that you can save in a key vault of your choice.</li>
</ol>
<p class="normal">Once you create the API key, you can use it to consume your model with the following script:</p>
<pre class="programlisting code"><code class="hljs-code">from openai import OpenAI
client = OpenAI(api_key = "xxx")
response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is the recipe for Margherita Pizza?"}
  ]
)
</code></pre>
<p class="normal">The above <a id="_idIndexMarker576"/>example leverages the Python <a id="_idIndexMarker577"/>SDK. However, you can also do your call with Node.js or curl, as specified in the OpenAI documentation.</p>
<div><p class="normal">Note</p>
<p class="normal">The schema of your client might vary depending on the model you are using and the data format you are passing as a prompt. For example, if you are using the gpt-4o-mini for image processing, your client will look like the following:</p>
<p class="normal">response = client.chat.completions.create(</p>
<p class="normal"> model=”gpt-4o-mini”,</p>
<p class="normal"> messages=[</p>
<p class="normal"> {</p>
<p class="normal"> “role”: “user”,</p>
<p class="normal"> “content”: [</p>
<p class="normal"> {“type”: “text”, “text”: prompt},</p>
<p class="normal"> {</p>
<p class="normal"> “type”: “image_url”,</p>
<p class="normal"> “image_url”: {“url”: f”data:{img_type};base64,{img_b64_str}”},</p>
<p class="normal"> },</p>
<p class="normal"> ],</p>
<p class="normal"> }</p>
<p class="normal"> ],</p>
<p class="normal">)</p>
</div>
<p class="normal">You can find the OpenAI Python library at the following GitHub repos<a href="https://github.com/openai/openai-python">itory: https://github.com/openai/openai</a>-python.</p>
<p class="normal">Let’s inspect how the response is built (I truncated the content of the response):</p>
<pre class="programlisting code"><code class="hljs-code">response.to_dict()
{'id': 'chatcmpl-9znQeWUbRyGmy3pWf7VfFWAppMCo7',
 'choices': [{'finish_reason': 'stop',
   'index': 0,
   'logprobs': None,
   'message': {'content': 'To make Margherita Pizza […]
    'role': 'assistant'},
   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},
    'self_harm': {'filtered': False, 'severity': 'safe'},
    'sexual': {'filtered': False, 'severity': 'safe'},
    'violence': {'filtered': False, 'severity': 'safe'}}}],
 'created': 1724515040,
 'model': 'gpt-4o-2024-05-13',
 'object': 'chat.completion',
 'system_fingerprint': 'fp_abc28019ad',
 'usage': {'completion_tokens': 193, 'prompt_tokens': 55, 'total_tokens': 248},
 'prompt_filter_results': [{'prompt_index': 0,
   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},
    'self_harm': {'filtered': False, 'severity': 'safe'},
    'sexual': {'filtered': False, 'severity': 'safe'},
    'violence': {'filtered': False, 'severity': 'safe'}}}]}
</code></pre>
<p class="normal">As you <a id="_idIndexMarker578"/>can see, there are many components <a id="_idIndexMarker579"/>that make up the response object:</p>
<ul>
<li class="bulletList"><code class="inlineCode">id</code>: This is a unique identifier for the API call. In this case, <code class="inlineCode">chatcmpl-9znQeWUbRyGmy3pWf7VfFWAppMCo7</code> is the specific ID associated with this particular chat completion request.</li>
<li class="bulletList"><code class="inlineCode">choices</code>: This is an array containing the different possible responses (choices) generated by the model. In this response, there’s only one choice (<code class="inlineCode">index 0</code>), which is typical for most single-response completions:<ul>
<li class="bulletList"><code class="inlineCode">index</code>: Indicates the position of this particular choice in the list of choices (in this case, <code class="inlineCode">0</code>).</li>
<li class="bulletList"><code class="inlineCode">finish_reason</code>: Indicates why the model stopped generating tokens. <strong class="keyWord">stop</strong> usually means the model naturally reached the end of its response without needing to be cut off.</li>
<li class="bulletList"><code class="inlineCode">logprobs</code>: If enabled, this would contain the log probabilities of each token in the completion. It is <code class="inlineCode">None</code> here, indicating that you did not request this information.</li>
<li class="bulletList"><code class="inlineCode">message</code>: Contains the content of the response (<code class="inlineCode">'content'</code>) and the role of the speaker (<code class="inlineCode">'role'</code>):<ul>
<li class="bulletList"><code class="inlineCode">content</code>: The actual text generated by the assistant, which in this case is a response regarding Azure AI services that support customer-managed keys</li>
<li class="bulletList"><code class="inlineCode">role</code>: The role of the speaker in the conversation, which is ‘assistant’ here, indicating the response came from the AI assistant</li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode">content_filter_results</code>: This contains the content filtering results for the response, checking for any harmful content in categories like hate, self-harm, sexual content, and violence. In this case, all categories are marked as <code class="inlineCode">'safe'</code> and <code class="inlineCode">'filtered': False</code>, indicating no problematic content was detected.</li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode">created</code>: This is <a id="_idIndexMarker580"/>a timestamp representing <a id="_idIndexMarker581"/>when the response was generated. The number <code class="inlineCode">1724515040</code> is the UNIX timestamp (seconds since January 1, 1970).</li>
<li class="bulletList"><code class="inlineCode">model</code>: This indicates the version of the model that generated the response.</li>
<li class="bulletList"><code class="inlineCode">object</code>: This indicates the type of object returned. In this case, <code class="inlineCode">'chat.completion'</code> signifies that this is a completion from the chat API.</li>
<li class="bulletList"><code class="inlineCode">system_fingerprint</code>: This is an internal identifier used by OpenAI for tracking or diagnosing the system that handled the request. <code class="inlineCode">'fp_abc28019ad'</code> is the specific fingerprint for this transaction.</li>
<li class="bulletList"><code class="inlineCode">usage</code>: This object tracks the token usage for the API call:<ul>
<li class="bulletList"><code class="inlineCode">completion_tokens</code>: The number of tokens used in the generated response (193 tokens)</li>
<li class="bulletList"><code class="inlineCode">prompt_tokens</code>: The number of tokens used in the input prompt (55 tokens)</li>
<li class="bulletList"><code class="inlineCode">total_tokens</code>: The total number of tokens consumed in the request, which is the sum of the prompt and completion tokens (248 tokens)</li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode">prompt_filter_results</code>: This array contains the results of content filtering applied to the input prompt before generating the response. It ensures that the prompt does not contain harmful content. Like the <code class="inlineCode">content_filter_results</code> in the choices section, it includes checks for hate, self-harm, sexual content, and violence. All are marked as <code class="inlineCode">'safe'</code> and <code class="inlineCode">'filtered': False</code>, indicating no issues were found.</li>
</ul>
<p class="normal">Among all the output parameters, the <code class="inlineCode">content_filter_results</code> might be particularly relevant when <a id="_idIndexMarker582"/>it comes to managing potentially <a id="_idIndexMarker583"/>harmful results. In fact, you might want to enforce a more conservative approach when it comes to potentially harmful content, in either input or output. If this is the case, you could simply enforce a deterministic rule that prevents the model from further processing any request that triggers a given level of risk.</p>
<p class="normal">This is a meaningful example of how leveraging OpenAI models’ APIs allows for great flexibility when it comes to building application logic around LLMs.</p>
<h1 class="heading-1" id="_idParaDest-156">Architectural patterns to build applications with models’ APIs</h1>
<p class="normal">The rise <a id="_idIndexMarker584"/>of GenAI and LLMs <a id="_idIndexMarker585"/>paved the way for a revolution in the field of software development. In fact, from “modern applications” – referring to microservices-based architectures and rapid innovation with CI/CD – we now talk about “intelligent applications” that are infused with GenAI models defined by natural language interaction, data-driven experience, and velocity of adaptation to new models’ releases.</p>
<p class="normal">An intelligent app can be described with the following illustration:</p>
<figure class="mediaobject"><img alt="A diagram of a computer network  Description automatically generated with medium confidence" src="img/B31559_10_03.png"/></figure>
<p class="packt_figref">Figure 10.3: Anatomy of an intelligent application powered by an LLM</p>
<p class="normal">In the <a id="_idIndexMarker586"/>above architecture, we <a id="_idIndexMarker587"/>depict the anatomy of an intelligent application with the following features:</p>
<ul>
<li class="bulletList">It has a natural language interface (it might be text- or voice-based).</li>
<li class="bulletList">It is powered by an LLM that acts as the “brain” of the app.</li>
<li class="bulletList">It has <a id="_idIndexMarker588"/>a knowledge base that the model can query, typically with <strong class="keyWord">retrieval augmented generation</strong> (<strong class="keyWord">RAG</strong>) techniques.</li>
<li class="bulletList">It has a set of tools or plugins that it can use to interact with the external environment.</li>
</ul>
<p class="normal">This new paradigm of software development brings a set of new application components that are typical of AI-powered applications. Let’s explore these new components in more detail.</p>
<h2 class="heading-2" id="_idParaDest-157">New application components</h2>
<p class="normal">The main shift in terms of AI development refers to the way we work with models: from producing <a id="_idIndexMarker589"/>models, now the trend is consuming models that, as we mentioned several times, are nothing but APIs.</p>
<p class="normal">This shift leads to a series of new software components (or adjustments of existing components) in the landscape of development:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Models</strong>: The model is simply the type of LLM we decide to embed in our application. There are two main categories of models:<ul>
<li class="bulletList"><strong class="keyWord">Proprietary LLMs</strong>: Models that are owned by specific companies or organizations. Examples include GPT-4o, developed by OpenAI, or Gemini, developed by Google. As their source code and architecture are not available, those models cannot be re-trained from scratch on custom data, but they can be fine-tuned if needed.</li>
<li class="bulletList"><strong class="keyWord">Open-source</strong>: Models with code and architecture freely available and distributed, hence they can also be trained from scratch on custom data. Examples <a id="_idIndexMarker590"/>include Falcon LLM, developed by Abu Dhabi’s <strong class="keyWord">Technology Innovation Institute</strong> (<strong class="keyWord">TII</strong>), and Llama, developed by Meta.</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">System message</strong>: This is the set of instructions that we provide the model with, and that <a id="_idIndexMarker591"/>influence the style and behavior of our AI app. There are many features that we can shape directly within the meta-prompt, including:<ul>
<li class="bulletList">Reducing hallucination by specifying that the model only refers to the provided knowledge base (this process is called “grounding”)</li>
<li class="bulletList">Implementing responsible AI practices by specifying, for example, not to respond to malicious queries or not to generate potentially harmful responses</li>
<li class="bulletList">Instructing the model to always ask an additional question to consolidate the context before answering</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">Memory and VectorDB</strong>: When we talk about memory in the context of AI apps, we need to differentiate between two types of memory:<ul>
<li class="bulletList"><strong class="keyWord">Short-term memory</strong>: This is the capability of the app to keep the interactions between the user and LLMs in a context window. It means that each message feeds the existing meta-prompt of the model, without the user repeating something already mentioned.</li>
<li class="bulletList"><strong class="keyWord">Long-term memory</strong>: This type of memory refers to the external knowledge base we provide the model with using embeddings. When this is the case, we typically leverage VectorDBs, a new type of database (or new feature of an existing database) that stores the numerical representations of the provided documents.<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">A VectorDB is a type <a id="_idIndexMarker592"/>of database that stores and retrieves information based on vectorized embeddings, the numerical representations that capture the meaning and context of text. By using a VectorDB, you can perform semantic search and retrieval based on the similarity of meanings rather than keywords. Some examples of a VectorDB are Chroma, FAISS, Elasticsearch, Milvus, Pinecone, Qdrant, and Weaviate.</p>
</div>
</li>
</ul>
</li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">Tools/plugins</strong>: These can be seen as additional modules or components that can be integrated into the LLM to extend its functionality or adapt it to specific tasks and applications. These plugins act as add-ons, enhancing the capabilities of the LLM beyond its core language generation or comprehension abilities.</li>
</ul>
<p class="normal">The idea <a id="_idIndexMarker593"/>behind plugins is to make LLMs more versatile and adaptable, allowing developers and users to customize the behavior of the language model for their specific needs. Plugins can be created to perform various tasks, and they can be seamlessly incorporated into the LLM’s architecture.</p>
<p class="normal">The following is an illustration of the main components of an LLM-powered application:</p>
<figure class="mediaobject"><img alt="A diagram of a computer program  Description automatically generated" src="img/B31559_10_04.png"/></figure>
<p class="packt_figref">Figure 10.4: High-level architecture of LLM-powered applications</p>
<p class="normal">As you can see from the picture above, the core of the high-level architecture is the <strong class="keyWord">AI orchestrator</strong>. With the AI orchestrator, we refer to lightweight libraries that make it easier to embed and orchestrate LLMs within applications.</p>
<h2 class="heading-2" id="_idParaDest-158">AI orchestrators</h2>
<p class="normal">Since LLMs <a id="_idIndexMarker594"/>went viral toward the end of 2022, many <a id="_idIndexMarker595"/>libraries have begun to arise in the market. In the next sections, we are going to focus on three of them: LangChain, Semantic Kernel, and Haystack.</p>
<h3 class="heading-3" id="_idParaDest-159">LangChain</h3>
<p class="normal"><strong class="keyWord">LangChain</strong> was launched <a id="_idIndexMarker596"/>as an open-source project by Harrison Chase, in October 2022. It can be used in both Python and JS/TS.</p>
<p class="normal">LangChain is <a id="_idIndexMarker597"/>a framework for developing applications powered by language models, making them data-aware (with grounding) and agentic – meaning able to interact with external environments.</p>
<p class="normal">LangChain provides modular abstractions for the components necessary to work with language models that we previously mentioned, such as prompts, memory, and plugins. Alongside those components, LangChain also offers pre-built <strong class="keyWord">chains</strong>, which are structured concatenations of components. These chains can be pre-built for specific use cases or be customized.</p>
<p class="normal">Overall, LangChain has the following core modules:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Models</strong>: These are <a id="_idIndexMarker598"/>the LLMs or large foundation models that will be the engine of the application. LangChain supports proprietary models, such as those available in OpenAI and Azure OpenAI, and open-source models <a id="_idIndexMarker599"/>consumable from the <strong class="keyWord">Hugging Face Hub</strong>.<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">Hugging Face is a <a id="_idIndexMarker600"/>company and a community that builds and shares state-of-the-art models and tools for <strong class="keyWord">natural language processing</strong> (<strong class="keyWord">NLP</strong>) and other machine learning domains. It developed the Hugging Face Hub, a platform where people can create, discover, and collaborate on machine learning models and LLMs, datasets, and demos. The Hugging Face Hub hosts over 120k models, 20k datasets, and 50k demos in various domains and tasks, such as audio, vision, and language.</p>
</div>
</li>
</ul>
<p class="normal">Alongside models, LangChain also offers many prompt-related components that make it easier to manage the prompt flow.</p>
<ul>
<li class="bulletList"><strong class="keyWord">Data connections</strong>: These refer to the building blocks needed to retrieve the additional <a id="_idIndexMarker601"/>non-parametric knowledge we want to provide the model with. Examples of data connections are document loaders or text embedding models.</li>
<li class="bulletList"><strong class="keyWord">Memory</strong>: It allows <a id="_idIndexMarker602"/>the application to keep references to the user’s interactions, in both the short and long term. It is typically based on vectorized embeddings stored in a VectorDB.</li>
<li class="bulletList"><strong class="keyWord">Chains</strong>: These are <a id="_idIndexMarker603"/>predetermined sequences of actions and calls to LLMs that make it easier to build complex applications that require chaining LLMs with each other or with other components. An example of a chain might be: take the user query, chunk it into smaller pieces, embed those chunks, search for similar embeddings in a VectorDB, use the top three most similar chunks in the VectorDB as context to provide the answer, generate the answer.</li>
<li class="bulletList"><strong class="keyWord">Agents</strong>: Agents are <a id="_idIndexMarker604"/>entities that drive decision-making within LLM-powered applications. They have access to a suite of tools and can decide which tool to call based on the user input and the context. Agents are dynamic and adaptive, meaning that they can change or adjust their actions based on the situation or the goal.</li>
</ul>
<h3 class="heading-3" id="_idParaDest-160">Haystack</h3>
<p class="normal"><strong class="keyWord">Haystack</strong> is a Python-based <a id="_idIndexMarker605"/>framework developed by <em class="italic">deepset</em>, a startup <a id="_idIndexMarker606"/>founded in 2018 in Berlin by Milos Rusic, Malte Pietsch, and Timo Möller. deepset provides developers with the tools to build an NLP-based application, and with the introduction of Haystack, they are taking it to the next level.</p>
<p class="normal">Haystack has the following core components:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Nodes</strong>: These are <a id="_idIndexMarker607"/>components that perform a specific task or function, such as a retriever, a reader, a generator, a summarizer, etc. Nodes can be LLMs or other utilities that interact with LLMs or other resources. Among LLMs, Haystack supports proprietary models, such as those available in OpenAI and Azure OpenAI, and open-source models consumable from the Hugging Face Hub.</li>
<li class="bulletList"><strong class="keyWord">Pipelines</strong>: These are <a id="_idIndexMarker608"/>sequences of calls to nodes that perform natural language tasks or interact with other resources. Pipelines can be querying pipelines or indexing pipelines, depending on whether they perform searches on a set of documents or prepare documents for search. Pipelines are predetermined and hardcoded, meaning that they do not change or adapt based on the user input or the context.</li>
<li class="bulletList"><strong class="keyWord">Agent</strong>: This is an <a id="_idIndexMarker609"/>entity that uses LLMs to generate accurate responses to complex queries. An agent has access to a set of tools, which can be pipelines or nodes, and it can decide which tool to call based on the user input and the context. An agent is dynamic and adaptive, meaning that it can change or adjust its actions based on the situation or the goal.</li>
<li class="bulletList"><strong class="keyWord">Tools</strong>: There are <a id="_idIndexMarker610"/>functions that an agent can call to perform natural language tasks or interact with other resources. Tools can be pipelines or nodes that are available to the agent and they can be grouped into toolkits, which are sets of tools that can accomplish specific objectives.</li>
<li class="bulletList"><strong class="keyWord">DocumentStores</strong>: These <a id="_idIndexMarker611"/>are backends that store and retrieve documents for search. DocumentStores can be based on different technologies, including VectorDBs (such as FAISS, Milvus, or Elasticsearch).</li>
</ul>
<p class="normal">Haystack is renowned for its simplicity and ease of use, featuring a modular architecture that allows developers to construct customizable pipelines for tasks like semantic search and question-answering. This design makes it particularly suitable for <strong class="keyWord">RAG</strong> applications, where efficient data retrieval is crucial.</p>
<h3 class="heading-3" id="_idParaDest-161">Semantic Kernel</h3>
<p class="normal"><strong class="keyWord">Semantic Kernel</strong> is the <a id="_idIndexMarker612"/>third open-source SDK we are going to explore in <a id="_idIndexMarker613"/>this chapter. It was developed by Microsoft, originally in C#, and is now also available in Python.</p>
<p class="normal">This framework takes its name from the concept of a “kernel,” which, generally speaking, refers to the core or essence of a system. In the context of this framework, a kernel is meant to act as the engine that addresses users’ input by chaining and concatenating a series of components <a id="_idIndexMarker614"/>into pipelines, encouraging <strong class="keyWord">function composition.</strong></p>
<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">In mathematics, function composition is a way to combine two functions to create a new function. The idea is to use the output of one function as the input to another function, forming a chain of functions. The composition of two functions, f and g, is denoted as<a id="_idIndexMarker615"/><img alt="" src="img/B31559_10_001.png"/>, where the function <a id="_idIndexMarker616"/><img alt="" src="img/B31559_10_001.png"/> is applied first, followed by the function <a id="_idIndexMarker617"/><img alt="" src="img/B31559_10_002.png"/>.</p>
</div>
<p class="normal">Function composition in computer science is a powerful concept that allows for the creation of more sophisticated and reusable code by combining smaller functions into larger ones. It enhances modularity and code organization, making programs easier to read and maintain.</p>
<p class="normal">Semantic Kernel has the following main components:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Models</strong>: These <a id="_idIndexMarker618"/>are the LLMs or large foundation models that will be the engine of the application. Semantic Kernel supports proprietary models, such as those available in OpenAI and Azure OpenAI, and open-source models consumable from the Hugging Face Hub.</li>
<li class="bulletList"><strong class="keyWord">Memory</strong>: This <a id="_idIndexMarker619"/>allows the application to keep references to the user’s interactions, in both the short and long term. Within the framework of Semantic Kernel, memories can be accessed in three ways:<ul>
<li class="bulletList"><strong class="keyWord">Key</strong>-<strong class="keyWord">value pairs</strong>: This <a id="_idIndexMarker620"/>consists of saving environment variables that store simple information, such as names or dates.</li>
<li class="bulletList"><strong class="keyWord">Local storage</strong>: This <a id="_idIndexMarker621"/>consists of saving information to a file that can be retrieved by its filename, such as a CSV or JSON file.</li>
<li class="bulletList"><strong class="keyWord">Semantic memory search</strong>: This <a id="_idIndexMarker622"/>is similar to LangChain’s and Haystack’s memory, as it uses embeddings to represent and search for text information based on its meaning.</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">Functions</strong>: Functions <a id="_idIndexMarker623"/>can be seen as skills that mix LLM prompts and code, with the goal of making users’ requests interpretable and actionable. There are two types of functions:<ul>
<li class="bulletList"><strong class="keyWord">Semantic functions</strong>: These <a id="_idIndexMarker624"/>are basically a templated prompt, which is a natural language query that specifies the input and output format for the LLM, also incorporating prompt configuration, which sets the parameters for the LLM.</li>
<li class="bulletList"><strong class="keyWord">Native functions</strong>: These <a id="_idIndexMarker625"/>refer to the native computer code that can route the intent captured by the semantic function and perform the related task.</li>
</ul>
</li>
</ul>
<p class="normal">To give an example, a semantic function could ask the LLM to write a short paragraph about AI, while a native function could actually post it on social media like LinkedIn.</p>
<ul>
<li class="bulletList"><strong class="keyWord">Plugins</strong>: These are <a id="_idIndexMarker626"/>connectors toward external sources or systems that are meant to provide additional information or the ability to perform autonomous actions. Semantic Kernel offers out-of-the-box plugins, such as the Microsoft Graph connector kit, but you can build a custom plugin by leveraging functions (both native and semantic, or a mix of the two).</li>
<li class="bulletList"><strong class="keyWord">Planner</strong>: As LLMs <a id="_idIndexMarker627"/>can be seen as reasoning engines, they can also be leveraged to auto-create chains or pipelines to address new users’ needs. This goal is achieved with a planner, which is a function that takes as input a user’s task and produces the set of actions, plugins, and functions needed to achieve the goal.</li>
</ul>
<p class="normal">Below is <a id="_idIndexMarker628"/>an illustration <a id="_idIndexMarker629"/>of the anatomy of Semantic Kernel:</p>
<figure class="mediaobject"><img alt="Technical perspective of what's happening" src="img/B31559_10_05.png"/></figure>
<p class="packt_figref">Figure 10.5: Anatomy of Semantic Kernel. Source: https://learn.microsoft.com/en-us/semantic-kernel/overview/</p>
<p class="normal">Overall, the three frameworks offer more or less similar core components, sometimes called a different taxonomy, yet covering all the blocks illustrated within the concept of the copilot system. So, a natural question might be, “Which one should I use to build my LLM-powered application?”</p>
<p class="normal">Below are some criteria you might want to consider:</p>
<ul>
<li class="bulletList"><strong class="keyWord">The programming language you are comfortable with or prefer to use</strong>. Different frameworks may support different programming languages or have different levels of compatibility or integration with them. For example, Semantic Kernel supports C#, Python, and Java, while LangChain and Haystack are mainly based on Python (even though LangChain also introduced JS/TS support). You may want <a id="_idIndexMarker630"/>to choose a framework that matches your <a id="_idIndexMarker631"/>existing skills or preferences, or that allows you to use the language that is most suitable for your application domain or environment.</li>
<li class="bulletList"><strong class="keyWord">The type and complexity of the natural language tasks you want to perform or support</strong>. Different frameworks may have different capabilities or features for handling various natural language tasks, such as summarization, generation, translation, reasoning, etc. For example, LangChain and Haystack provide utilities and components for orchestrating and executing natural language tasks, while Semantic Kernel allows you to use natural language semantic functions to invoke LLMs and services. You may want to choose a framework that offers the functionality and flexibility you need or want for your application goals or scenarios.</li>
<li class="bulletList"><strong class="keyWord">The level of customization and control you need or want over the LLMs and their parameters or options</strong>. Different frameworks may have different ways of accessing, configuring, and fine-tuning the LLMs and their parameters or options, such as model selection, prompt design, inference speed, output format, etc. For example, Semantic Kernel provides connectors that make it easy to add memories and models to your AI app, while LangChain and Haystack allow you to plug in different components for the DocumentStore, retriever, reader, generator, summarizer, and evaluator. You may want to choose a framework that gives you the level of customization and control you need or want over the LLMs and their parameters or options.</li>
<li class="bulletList"><strong class="keyWord">The availability and quality of the documentation, tutorials, examples, and community support for the framework</strong>. Different frameworks may have different levels of documentation, tutorials, examples, and community support that can help you learn, use, and troubleshoot the framework. For example, Semantic Kernel has a website with documentation, tutorials, examples, and a Discord community; LangChain has a GitHub repository with documentation, examples, and issues; Haystack has a website with documentation, tutorials, demos, blog posts, and a Slack community. You may want to choose a framework that has the availability and quality of documentation, tutorials, examples, and community support that can help you get started and solve problems with the framework.</li>
</ul>
<p class="normal">Well, there is <a id="_idIndexMarker632"/>no right or wrong answer! All three orchestrators discussed <a id="_idIndexMarker633"/>above are extremely valid. However, some features might be more relevant to specific use cases or developers’ preferences. Make your choice based on that.</p>
<h1 class="heading-1" id="_idParaDest-162">Introducing the public cloud: Azure OpenAI</h1>
<p class="normal">In 2016, OpenAI agreed <a id="_idIndexMarker634"/>to leverage Microsoft’s Azure cloud infrastructure to run its AI experiments, which led, in 2019, to a $1 billion investment from the tech giant <a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/">into Sam Altman’s company (https://new</a><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"/><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"/>upercomputing-technologies/). </p>
<p class="normal">This marked the beginning of a strategic partnership between the two companies, aiming at developing AI models and technologies that can be used for the benefit of humanity. This partnership is based on the following three main pillars:</p>
<ul>
<li class="bulletList">Microsoft and OpenAI will jointly build new Azure supercomputing infrastructure to train AI models.</li>
<li class="bulletList">OpenAI will make its models and technologies consumable from the Azure cloud.</li>
<li class="bulletList">Microsoft will become OpenAI’s preferred partner for commercializing new AI solutions to the market.</li>
</ul>
<p class="normal">Since then, the two companies kept investing and researching, and finally, in January 2023, OpenAI models were made available on Microsoft Azure as a managed service: <strong class="keyWord">Azure OpenAI Service</strong> (in short, <strong class="keyWord">AOAI</strong>).</p>
<p class="normal">With the general availability of the AOAI Service, a new milestone was reached, and the Microsoft AI portfolio has been extended with the powerful LLMs of OpenAI.</p>
<h2 class="heading-2" id="_idParaDest-163">AOAI Service</h2>
<p class="normal">The AOAI Service is a product of Microsoft that provides both a playground and APIs to interact and consume <a id="_idIndexMarker635"/>all of OpenAI’s powerful language models. It is important to highlight that the models are exactly the same: the only difference is that, if you are consuming them via AOAI, you are leveraging your own Azure subscription and automatically inheriting all the enterprise features that are typical of the Microsoft public cloud, including security, role-based access control, data privacy, and so on.</p>
<p class="normal">To create your AOAI resource, follow these instructions:</p>
<ul>
<li class="bulletList">Navig<a href="https://ms.portal.azure.com/">ate to your Azure portal at</a> https://ms.portal.azure.com.</li>
<li class="bulletList">Click on <strong class="screenText">Create a Resource</strong>.</li>
<li class="bulletList">Type <em class="italic">azure openai</em> and click on <strong class="screenText">Create</strong>.</li>
<li class="bulletList">Fill in the required information and click on <strong class="screenText">Review + create</strong>.</li>
</ul>
<p class="normal">This is <a id="_idIndexMarker636"/>shown in the following screenshot:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_10_06.png"/></figure>
<p class="packt_figref">Figure 10.6: Steps to create an AOAI resource</p>
<p class="normal">This process might take a few minutes. Once it is ready, you can directly jump to its user-friendly interface, the AOAI Studio, to test your models before deploying them:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_10_07.png"/></figure>
<p class="packt_figref">Figure 10.7: AOAI Studio and chat playground</p>
<p class="normal">To use AOAI models, you have to initiate a deployment, which is a serverless compute instance you can attach to a model.</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_10_08.png"/></figure>
<p class="packt_figref">Figure 10.8: Creating a new AOAI deployment via the Azure OpenAI portal</p>
<p class="normal">Lastly, exactly like <a id="_idIndexMarker637"/>we did for OpenAI models’ APIs in the previous section, from the AOAI Studio, you can consume your deployed models via APIs. For a quick start, you can navigate to the <strong class="screenText">Chat playground </strong>and click on the <strong class="screenText">View Code</strong> button. A script will be ready to be copied and pasted into your favorite programming IDE, along with the secret keys needed to access the resource:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_10_09.png"/></figure>
<p class="packt_figref">Figure 10.9: Consuming deployed models via APIs</p>
<p class="normal">By doing so, you can <a id="_idIndexMarker638"/>seamlessly incorporate your Azure OpenAI’s LLMs within your own application.</p>
<h1 class="heading-1" id="_idParaDest-164">Summary</h1>
<p class="normal">At the beginning of this chapter, we had an overview of how GenAI is disrupting industries, from increasing the efficiency of internal processes to enhancing customers’ journeys with personalized experiences. Many of these applications can be achieved through a high margin of customization, and pre-built, consumer-facing applications like ChatGPT might not be enough.</p>
<p class="normal">That’s why we introduced OpenAI models’ APIs. With the models’ APIs, you can leverage the power of the model behind ChatGPT within your own application, tailored to your own industry and scenarios. Developing AI-powered applications, however, requires a new set of components that have also marked a new paradigm in software development.</p>
<p class="normal">Finally, we saw how, from 2023, OpenAI models (both in Playground and via APIs) have been made available through Microsoft Azure as a managed service: Azure OpenAI. This has paved the way for a new wave of adoption from large enterprises that benefit from all the security and governance layers that already exist within the public cloud (which is, by design, enterprise-ready).</p>
<p class="normal">In the next chapter, we will provide a recap of everything covered in this book, including the latest announcements and releases that have occurred. We will also focus on reflections and final thoughts about the exponential growth of generative AI technologies in just a few months and what to expect in the near future.</p>
<h1 class="heading-1" id="_idParaDest-165">References</h1>
<ul>
<li class="bulletList">OpenAI Forms Exclusive Computing Partnership with Microsoft to Build New Azure AI Supercomputing Technologies: https://news.microsoft.com/20<a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/">19/07/22/openai-forms-exclusive-computing-partnership-with-</a><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"/>-ai-supercomputing-technologies/</li>
<li class="bulletList">General Availability of Azure OpenAI Service Expands Access to Large, Advanced AI Models with Added Enterprise Benefits: https://azure.microsoft.com/<a href="https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/">en-us/blog/general-availability-of-azure-openai-service-expa</a><a href="https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/"/>-with-added-enterprise-benefits/</li>
<li class="bulletList">Microsoft CEO Satya Nadella: Humans and A.I. Can Work Together to Solve Society’s Challenges: https://slate.com/technology/2016/06/microsoft-ceo-satya-nadella-humans-and-a-i-can-work-together-to-solve-societys-challenges.html</li>
<li class="bulletList">Microsoft Calls for Government Regulation of Facial Recognition Technology: https://www.geekwire.com/<a href="https://www.geekwire.com/2018/microsoft-calls-government-regulation-facial-recognition-technology/">2018/microsoft-calls-government-regulatio</a>n-facial-recognition-technology/</li>
<li class="bulletList">Six Principles to Guide Micros<a href="https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/">oft’s Facial Recognition Work: https://blogs.microso</a><a href="https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/"/>rosofts-facial-recognition-work/</li>
<li class="bulletList">Responsible AI Principles and Approach: https://www.microsoft.com/en-us/ai/principles-and-approach</li>
<li class="bulletList">Mic<a href="https://responsibleaitoolbox.ai/">rosoft Responsible AI Toolbox: </a>https://responsibleaitoolbox.ai/</li>
<li class="bulletList">Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention: https://www.microsoft.com/e<a href="https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/">n-us/research/publication/human-parity-on-commonsenseqa-augmenti</a><a href="https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/"/>tention-with-external-attention/</li>
<li class="bulletList">Customize a Model with Azure OpenAI Service: https://learn.microsoft.com/en-gb/<a href="https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio&amp;openai-cli-data-preparation-tool">azure/cognitive-services/openai/how-to/fine-tuning?pivots=pro</a><a href="https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio&amp;openai-cli-data-preparation-tool"/>openai-cli-data-preparation-tool</li>
<li class="bulletList">Moody’s and Microsoft Develop Enhanced Risk, Data, Analytics, Research and Collaboration Solut<a href="https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Powered-by-Generative-AI/default.aspx">ions Powered by Generative AI: https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Power</a>ed-by-Generative-AI/default.aspx</li>
<li class="bulletList">Increasing Accu<a href="https://openai.com/index/summer-health/">racy of Pediatric Visit Notes: https:/</a>/openai.com/index/summer-health/</li>
<li class="bulletList">Coca-Cola Invites Digital Artists to ‘Create Real<a href="https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform"> Magic’ Using New AI Platform: https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-</a>real-magic-using-new-ai-platform</li>
<li class="bulletList">IVECO Group Uses Azure OpenAI Servi<a href="https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy">ce to Transform Manufacturing: https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-op</a>enai-service-manufacturing-italy</li>
<li class="bulletList">Ir<a href="https://openai.com/index/ironclad/">onclad and OpenAI Partnership: ht</a>tps://openai.com/index/ironclad/</li>
<li class="bulletList">Inworl<a href="https://openai.com/index/inworld-ai/">d AI and OpenAI Collaboration: http</a>s://openai.com/index/inworld-ai/</li>
<li class="bulletList">Khan Academy and OpenAI Partnership: https://openai.com/index/khan-academy/</li>
</ul>
<h1 class="heading-1">Join our communities on Discord and Reddit</h1>
<p class="normal">Have questions about the book or want to contribute to discussions on Generative AI and LLMs? Join our Discord server at <a href="Chapter_10.xhtml">https://packt.link/I1tSU</a> and our Reddit channel at <a href="Chapter_10.xhtml">https://packt.link/jwAmA</a> to connect, share, and collaborate with like-minded enthusiasts.</p>
<p class="normal"><img alt="" src="img/Discord.png"/> <img alt="" src="img/QR_Code757615820155951000.png"/></p>
</div>
</body></html>