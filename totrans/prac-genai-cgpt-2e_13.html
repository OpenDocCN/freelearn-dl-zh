<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer326">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">10</span></h1>
<h1 class="chapterTitle" id="_idParaDest-136"><span class="koboSpan" id="kobo.2.1">Leveraging OpenAI’s Models for Enterprise-Scale Applications</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">In this chapter, we’ll focus on the enterprise-level applications of </span><strong class="keyWord"><span class="koboSpan" id="kobo.4.1">generative AI</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.6.1">GenAI</span></strong><span class="koboSpan" id="kobo.7.1">) and, more specifically, of OpenAI’s models. </span><span class="koboSpan" id="kobo.7.2">We will see how different industries have been massively </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.8.1">impacted by GenAI in recent years, and what kinds of trending patterns and applications have emerged.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.9.1">In this chapter, we will discuss the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.10.1">The latest advancements in various industries (including healthcare, financial services, retail, and more), driven by the outstanding capabilities of powerful LLMs, highlighting the most trending use cases</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.11.1">The architectural framework behind custom applications powered by OpenAI’s models, unveiling the versatility and adoption of the models’ APIs</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.12.1">Introduction to Azure OpenAI, the Microsoft cloud-based service that mirrors OpenAI’s Playground and offers OpenAI’s models directly within the perimeter of Azure subscriptions</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.13.1">By the end of this chapter, you will have learned about the main GenAI patterns across various industries, and how to leverage OpenAI’s models’ APIs within your own applications. </span><span class="koboSpan" id="kobo.13.2">Plus, you will have a clearer understanding of the cloud-scale service of Azure OpenAI and how to incorporate ethical considerations when developing AI-based solutions.</span></p>
<h1 class="heading-1" id="_idParaDest-137"><span class="koboSpan" id="kobo.14.1">Technical requirements</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.15.1">The following are the technical requirements for this chapter:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.16.1">An OpenAI account, chat model, and embedding model deployments</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.17.1">[Optional] An Azure subscription and Azure OpenAI instance, with chat model and embedding model deployments</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.18.1">Python 3.7.1 or a later version</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.19.1">You can refer to the following repository for the OpenAI Python SDKs: </span><span class="url"><span class="koboSpan" id="kobo.20.1">https://github.com/openai/openai-python</span></span><span class="koboSpan" id="kobo.21.1">.</span></p>
<h1 class="heading-1" id="_idParaDest-138"><span class="koboSpan" id="kobo.22.1">How GenAI is disrupting industries</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.23.1">LLMs, and GenAI in general, are revolutionizing various industries by introducing unprecedented </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.24.1">levels of automation, creativity, and efficiency. </span><span class="koboSpan" id="kobo.24.2">In recent years, we’ve witnessed a huge wave of innovation across different industries that all agree that not seizing the GenAI opportunity would mean falling behind in a competitive market.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.25.1">Let’s see some examples.</span></p>
<h2 class="heading-2" id="_idParaDest-139"><span class="koboSpan" id="kobo.26.1">Healthcare</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.27.1">In healthcare, GenAI </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.28.1">and LLMs are enhancing diagnostics, personalized </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.29.1">medicine, and administrative tasks:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.30.1">Diagnostics</span></strong><span class="koboSpan" id="kobo.31.1">: LLMs like GPT-4 are being used to analyze medical images, predict diseases, and </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.32.1">suggest treatment plans. </span><span class="koboSpan" id="kobo.32.2">For instance, AI-powered tools can now analyze radiology images with high accuracy, identifying early signs of conditions like cancer or heart disease, often outperforming human radiologists in speed and consistency. </span><span class="koboSpan" id="kobo.32.3">A great example of the latest advancements in the computer vision field is given in an article by Tyler J. </span><span class="koboSpan" id="kobo.32.4">Bradshaw et al., “Large Language Models and Large Multimodal Models in Medical Imaging: A Primer for Physicians”, published in </span><em class="italic"><span class="koboSpan" id="kobo.33.1">The Journal of Nuclear Medicine</span></em><span class="koboSpan" id="kobo.34.1"> (you can find it at </span><span class="url"><span class="koboSpan" id="kobo.35.1">https://jnm.snmjournals.org/content/early/2025/01/16/jnumed.124.268072</span></span><span class="koboSpan" id="kobo.36.1">).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.37.1">Personalized medicine</span></strong><span class="koboSpan" id="kobo.38.1">: GenAI is helping in the development of personalized treatment </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.39.1">plans by analyzing patient data, including genetic information. </span><span class="koboSpan" id="kobo.39.2">This has led to tailored therapies that improve outcomes.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.40.1">Administrative efficiency</span></strong><span class="koboSpan" id="kobo.41.1">: LLMs </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.42.1">are streamlining administrative tasks such as patient record management and appointment scheduling. </span><span class="koboSpan" id="kobo.42.2">AI chatbots can handle patient queries, reducing the workload on medical staff.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-140"><span class="koboSpan" id="kobo.43.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.44.1">OpenAI has partnered with Summer Health, a healthcare service that provides fast and convenient </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.45.1">access to pediatric care through text messaging. </span><span class="koboSpan" id="kobo.45.2">The collaboration aims to enhance the capabilities of Summer Health’s platform by integrating OpenAI’s advanced language models. </span><span class="koboSpan" id="kobo.45.3">This integration enables more efficient and accurate responses to parents’ healthcare inquiries, providing quick, reliable medical advice for children’s health concerns. </span><span class="koboSpan" id="kobo.45.4">This has led to increased efficiency and improved timeliness, with data being kept anonymous. </span><span class="koboSpan" id="kobo.45.5">The AI-driven platform helps streamline communication between parents and healthcare professionals, improving the overall experience and accessibility of pediatric care.</span></p>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.46.1">Source: </span></em><span class="url"><span class="koboSpan" id="kobo.47.1">https://openai.com/index/summer-health/</span></span><span class="koboSpan" id="kobo.48.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-141"><span class="koboSpan" id="kobo.49.1">Finance</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.50.1">In finance, GenAI </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.51.1">and LLMs are transforming risk management, customer </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.52.1">service, and investment strategies:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.53.1">Claim management</span></strong><span class="koboSpan" id="kobo.54.1">: LLMs are employed to automate the summarization, review, triage, and adjudication of claims. </span><span class="koboSpan" id="kobo.54.2">For instance, Munich Re developed an LLM-powered </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.55.1">solution for claim management that led to a streamlined claims process, reduced manual effort, and improved decision-making accuracy (</span><span class="url"><span class="koboSpan" id="kobo.56.1">https://www.munichre.com/us-life/en/insights/future-of-risk/large-language-models-in-underwriting-and-claims.html</span></span><span class="koboSpan" id="kobo.57.1">).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.58.1">Customer service</span></strong><span class="koboSpan" id="kobo.59.1">: AI-driven chatbots and virtual assistants are now common in the </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.60.1">finance sector, handling customer inquiries, processing transactions, and providing financial advice. </span><span class="koboSpan" id="kobo.60.2">ING’s AI assistant is a prime example of a virtual assistant that helps customers manage their finances by providing insights, reminders, and transaction details (</span><span class="url"><span class="koboSpan" id="kobo.61.1">https://www.mckinsey.com/industries/financial-services/how-we-help-clients/banking-on-innovation-how-ing-uses-generative-ai-to-put-people-first</span></span><span class="koboSpan" id="kobo.62.1">).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.63.1">Investment strategies</span></strong><span class="koboSpan" id="kobo.64.1">: Hedge funds and investment firms are using GenAI to create </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.65.1">predictive models that inform trading decisions. </span><span class="koboSpan" id="kobo.65.2">AI algorithms analyze market data to identify patterns and make real-time trading decisions. </span><span class="koboSpan" id="kobo.65.3">BlackRock’s Aladdin platform is one such example, leveraging AI to manage investments and assess market risks (</span><span class="url"><span class="koboSpan" id="kobo.66.1">https://www.blackrock.com/aladdin/solutions/aladdin-copilot</span></span><span class="koboSpan" id="kobo.67.1">).</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-142"><span class="koboSpan" id="kobo.68.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.69.1">Moody’s Corporation, a leading global provider of credit ratings, research, and risk analysis, has partnered </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.70.1">with Microsoft to develop enhanced risk data analytics and research solutions powered by GenAI. </span><span class="koboSpan" id="kobo.70.2">This collaboration combines Moody’s vast expertise in financial risk and data analytics with Microsoft’s advanced AI technology. </span><span class="koboSpan" id="kobo.70.3">The result is a set of tools that offer real-time insights into financial risks, enabling more precise decision-making and improved risk management for financial institutions and other stakeholders.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.71.1">Source: </span><span class="url"><span class="koboSpan" id="kobo.72.1">https://news.microsoft.com/2023/06/29/moodys-and-microsoft-develop-enhanced-risk-data-analytics-research-and-collaboration-solutions-powered-by-generative-ai/?msockid=2dc01bb6f864693933ed0eb3f9a668dc</span></span><span class="koboSpan" id="kobo.73.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-143"><span class="koboSpan" id="kobo.74.1">Retail and e-commerce</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.75.1">In retail </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.76.1">and e-commerce, GenAI and LLMs are enhancing customer </span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.77.1">experience, inventory management, and personalized marketing:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.78.1">Customer experience</span></strong><span class="koboSpan" id="kobo.79.1">: AI-powered </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.80.1">chatbots provide personalized customer service, helping shoppers find products, resolve issues, and make purchases.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.81.1">Inventory management</span></strong><span class="koboSpan" id="kobo.82.1">: LLMs </span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.83.1">help retailers predict demand and optimize inventory levels by analyzing sales data, seasonal trends, and customer behavior.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.84.1">Personalized marketing</span></strong><span class="koboSpan" id="kobo.85.1">: GenAI </span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.86.1">is enabling hyper-personalized marketing campaigns. </span><span class="koboSpan" id="kobo.86.2">By analyzing customer data, AI can create targeted advertisements and product recommendations.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-144"><span class="koboSpan" id="kobo.87.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.88.1">Coca-Cola </span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.89.1">has launched an innovative initiative inviting </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.90.1">digital artists to create unique artworks using a new AI-powered platform developed in collaboration with </span><strong class="keyWord"><span class="koboSpan" id="kobo.91.1">Google Cloud Platform</span></strong><span class="koboSpan" id="kobo.92.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.93.1">GCP</span></strong><span class="koboSpan" id="kobo.94.1">). </span><span class="koboSpan" id="kobo.94.2">This platform allows artists to generate digital content by blending Coca-Cola’s iconic branding elements with their creativity. </span><span class="koboSpan" id="kobo.94.3">The initiative, called “Create Real Magic,” leverages advanced AI tools to inspire and empower artists, facilitating the creation of digital art that resonates with Coca-Cola’s brand ethos. </span><span class="koboSpan" id="kobo.94.4">This project highlights how AI can be used to bridge creativity and technology in the retail and consumer goods industry.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.95.1">Source: </span><span class="url"><span class="koboSpan" id="kobo.96.1">https://brandthechange.com/creativity/create-real-magic-inside-coca-colas-first-ai-powered-campaign/#:~:text=The%20Coca-Cola%20Company%20has%20partnered%20with%20OpenAI%20and,using%20iconic%20creative%20assets%20from%20the%20Coca-Cola%20archives</span></span><span class="koboSpan" id="kobo.97.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-145"><span class="koboSpan" id="kobo.98.1">Manufacturing</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.99.1">In manufacturing, GenAI </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.100.1">and LLMs are driving automation, quality </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.101.1">control, and supply chain optimization:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.102.1">Automation</span></strong><span class="koboSpan" id="kobo.103.1">: AI-powered </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.104.1">robots and systems are automating repetitive tasks, such as assembly line work and material handling.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.105.1">Quality control</span></strong><span class="koboSpan" id="kobo.106.1">: LLMs are used to monitor production processes in real time, identifying </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.107.1">defects or inefficiencies. </span><span class="koboSpan" id="kobo.107.2">AI systems can analyze data from sensors and cameras to detect anomalies in products, ensuring higher quality.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.108.1">Supply chain optimization</span></strong><span class="koboSpan" id="kobo.109.1">: AI </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.110.1">models help manufacturers optimize their supply chains by predicting demand, managing inventory, and selecting suppliers.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-146"><span class="koboSpan" id="kobo.111.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.112.1">Iveco Group, a leading global manufacturer of commercial vehicles, has partnered with Microsoft </span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.113.1">to integrate Azure OpenAI Service into its business processes. </span><span class="koboSpan" id="kobo.113.2">The customer developed an internal smart chatbot called “Chat IVG”, which can be used for questions and answers and to extract information from the organization’s own data and documents. </span><span class="koboSpan" id="kobo.113.3">Plus, numerous use cases and autonomous projects are being developed and deployed in production, either leveraging Chat IVG’s specific customizations or using its architecture as a foundation. </span><span class="koboSpan" id="kobo.113.4">Chat IVG is driving significant impact by enhancing internal business user experiences, boosting productivity across various business units, and enabling faster, more efficient</span><a href="https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy"><span class="koboSpan" id="kobo.114.1"> customer support.</span></a></p>
<p class="normal"><a href="https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy"><span class="koboSpan" id="kobo.115.1">Source: </span><span class="url"><span class="koboSpan" id="kobo.116.1">https://www.microsoft.com/en/customers/story/1706380538888475836-iveco-group-azure-openai-</span></span></a><span class="url"><span class="koboSpan" id="kobo.117.1">service-manufacturing-italy</span></span><span class="koboSpan" id="kobo.118.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-147"><span class="koboSpan" id="kobo.119.1">Media and entertainment</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.120.1">In media </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.121.1">and entertainment, GenAI and LLMs are revolutionizing </span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.122.1">content creation, audience engagement, and media distribution:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.123.1">Content creation</span></strong><span class="koboSpan" id="kobo.124.1">: GenAI is being used to generate content, from writing articles to </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.125.1">composing music. </span><span class="koboSpan" id="kobo.125.2">For example, The Washington Post uses AI to write short news articles and reports, freeing up journalists to focus on more complex stories. </span><span class="koboSpan" id="kobo.125.3">In music, AI platforms like OpenAI’s MuseNet can compose original music tracks in various styles, aiding musicians in the creative process.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.126.1">Audience engagement</span></strong><span class="koboSpan" id="kobo.127.1">: LLMs </span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.128.1">analyze user data to deliver personalized content recommendations, keeping audiences engaged. </span><span class="koboSpan" id="kobo.128.2">Netflix uses AI to recommend movies and TV shows based on viewers’ preferences, significantly increasing viewer retention.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.129.1">Media distribution</span></strong><span class="koboSpan" id="kobo.130.1">: AI is also optimizing media distribution by analyzing audience </span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.131.1">demographics and consumption patterns. </span><span class="koboSpan" id="kobo.131.2">Spotify uses AI to curate personalized playlists, ensuring that users discover new music tailored to their tastes.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-148"><span class="koboSpan" id="kobo.132.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.133.1">Microsoft’s Xbox division has announced a multi-year partnership with Inworld AI to develop advanced </span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.134.1">GenAI tools for game development. </span><span class="koboSpan" id="kobo.134.2">This collaboration aims to enhance character dialogue and narrative creation by integrating Inworld’s expertise in GenAI with Microsoft’s Azure OpenAI Service and insights from Microsoft Research. </span><span class="koboSpan" id="kobo.134.3">The goal is to empower game developers to create more dynamic and immersive gaming experiences.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.135.1">Source: </span><span class="url"><span class="koboSpan" id="kobo.136.1">https://developer.microsoft.com/en-us/games/articles/2023/11/xbox-and-inworld-ai-partnership-announcement/</span></span><span class="koboSpan" id="kobo.137.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-149"><span class="koboSpan" id="kobo.138.1">Legal services</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.139.1">In the </span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.140.1">legal industry, GenAI and LLMs are transforming research, contract analysis, and case prediction:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.141.1">Legal research</span></strong><span class="koboSpan" id="kobo.142.1">: AI tools are accelerating legal research by analyzing vast amounts of legal documents, case laws, and statutes. </span><span class="koboSpan" id="kobo.142.2">For example, ROSS Intelligence uses AI to provide lawyers with relevant case laws and legal precedents in seconds, which would otherwise take hours to find manually.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.143.1">Contract analysis</span></strong><span class="koboSpan" id="kobo.144.1">: LLMs are used to review and analyze contracts, identifying key terms, risks, and compliance issues. </span><span class="koboSpan" id="kobo.144.2">This helps in speeding up negotiations and ensuring </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.145.1">that contracts are airtight. </span><span class="koboSpan" id="kobo.145.2">Kira Systems is one example where AI reviews contracts for due diligence, identifying clauses and potential risks.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.146.1">Case prediction</span></strong><span class="koboSpan" id="kobo.147.1">: GenAI is being used to predict the outcomes of legal cases based on historical data. </span><span class="koboSpan" id="kobo.147.2">By analyzing past cases, AI can provide lawyers with insights into likely judgments, helping them strategize better. </span><span class="koboSpan" id="kobo.147.3">Lex Machina, for example, uses AI to predict how judges might rule in intellectual property disputes.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-150"><span class="koboSpan" id="kobo.148.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.149.1">Ironclad, a leading digital contracting platform, has partnered with OpenAI to integrate advanced AI capabilities into its legal workflows. </span><span class="koboSpan" id="kobo.149.2">By leveraging OpenAI’s language models, Ironclad </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.150.1">enhances its platform’s ability to automate contract analysis, generate and review legal documents, and provide insights to legal teams more efficiently. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.151.1">This integration allows for faster, more accurate contract processing, reducing the time spent on manual reviews and enabling legal teams to focus on higher-value tasks. </span><span class="koboSpan" id="kobo.151.2">The collaboration underscores the growing role of AI in transforming the legal industry by improving accuracy and productivity in contract management.</span></p>
<h2 class="heading-2" id="_idParaDest-151"><span class="koboSpan" id="kobo.152.1">Education</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.153.1">In education, GenAI </span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.154.1">and LLMs are transforming learning </span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.155.1">experiences, personalized education, and administrative tasks:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.156.1">Learning experiences</span></strong><span class="koboSpan" id="kobo.157.1">: AI-driven platforms are creating personalized learning paths </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.158.1">for students based on their strengths and weaknesses. </span><span class="koboSpan" id="kobo.158.2">For instance, platforms like Coursera use AI to recommend courses and resources tailored to each learner’s progress and preferences.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.159.1">Personalized education</span></strong><span class="koboSpan" id="kobo.160.1">: LLMs </span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.161.1">can tutor students by answering questions, explaining concepts, and providing feedback on assignments. </span><span class="koboSpan" id="kobo.161.2">Khan Academy’s AI-powered tutor is an example, offering personalized help to students struggling with specific topics.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.162.1">Administrative tasks</span></strong><span class="koboSpan" id="kobo.163.1">: AI is also being used to automate administrative tasks such as grading and scheduling. </span><span class="koboSpan" id="kobo.163.2">For instance, Turnitin uses AI to grade essays and detect plagiarism, saving educators time and ensuring academic integrity.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-152"><span class="koboSpan" id="kobo.164.1">Case study</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.165.1">Khan Academy has partnered with OpenAI to incorporate advanced AI capabilities into its educational </span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.166.1">platform. </span><span class="koboSpan" id="kobo.166.2">By integrating OpenAI’s language models, Khan Academy is able to provide personalized tutoring, answer student queries, and assist with learning in a more interactive and dynamic way. </span><span class="koboSpan" id="kobo.166.3">This collaboration aims to enhance the educational experience by offering students real-time assistance and tailored support, making learning more accessible and effective. </span><span class="koboSpan" id="kobo.166.4">The AI-powered tools help students grasp complex concepts, provide instant feedback, and adapt to individual learning styles, further democratizi</span><a href="https://openai.com/index/khan-academy/"><span class="koboSpan" id="kobo.167.1">ng education through technology.</span></a></p>
<p class="normal"><a href="https://openai.com/index/khan-academy/"><span class="koboSpan" id="kobo.168.1">Sourc</span></a><span class="koboSpan" id="kobo.169.1">e: </span><span class="url"><span class="koboSpan" id="kobo.170.1">https://openai.com/index/khan-academy/</span></span><span class="koboSpan" id="kobo.171.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.172.1">The above examples are just a subset of the possibilities that GenAI has enabled in various industries. </span><span class="koboSpan" id="kobo.172.2">However, there is an element that unites all the examples covered: in each scenario, a custom application was built leveraging an LLM API.</span></p>
<h1 class="heading-1" id="_idParaDest-153"><span class="koboSpan" id="kobo.173.1">Understanding OpenAI models’ APIs</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.174.1">In </span><em class="italic"><span class="koboSpan" id="kobo.175.1">Chapter 1</span></em><span class="koboSpan" id="kobo.176.1"> of this book, we saw how LLMs have introduced a paradigm shift in the landscape of AI: different </span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.177.1">from the tailored, highly specialized models that featured AI in the “before ChatGPT era,” LLMs are now able to be generalized and tackle different tasks depending on the user’s query.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.178.1">Furthermore, there is one additional element that sets LLMs apart from previous models: in fact, LLMs typically come as pre-trained objects that anyone – even without any experience in the field of AI – can use with the easiest way of interacting: natural language.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.179.1">Of course, no one is stopping you from designing and training your LLM from scratch, but be aware that this will require, at least:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.180.1">Technical knowledge on how to design the model</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.181.1">A huge amount of training data</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.182.1">Specialized infrastructure that can support the training and inference stages</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.183.1">A lot of time to invest in the project</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.184.1">If the above elements used to be a barrier to entry for many AI developers in the past, now the paradigm has shifted. </span><span class="koboSpan" id="kobo.184.2">The new focus, in fact, is how to efficiently build everything that lives </span><em class="italic"><span class="koboSpan" id="kobo.185.1">around</span></em><span class="koboSpan" id="kobo.186.1"> an LLM, such as the system message, </span><strong class="keyWord"><span class="koboSpan" id="kobo.187.1">vector databases</span></strong><span class="koboSpan" id="kobo.188.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.189.1">VectorDBs</span></strong><span class="koboSpan" id="kobo.190.1">), plugins, and so forth. </span><span class="koboSpan" id="kobo.190.2">That’s the reason why using LLMs’ APIs is now the validated pattern for building GenAI applications.</span></p>
<h2 class="heading-2" id="_idParaDest-154"><span class="koboSpan" id="kobo.191.1">What is a model API?</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.192.1">Before talking </span><a id="_idIndexMarker561"/><span class="koboSpan" id="kobo.193.1">about OpenAI models’ APIs, let’s first refresh our definition of what an API is.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.194.1">An </span><strong class="keyWord"><span class="koboSpan" id="kobo.195.1">application programming interface</span></strong><span class="koboSpan" id="kobo.196.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.197.1">API</span></strong><span class="koboSpan" id="kobo.198.1">) is a set of rules and tools that allows different software applications to communicate with each other. </span><span class="koboSpan" id="kobo.198.2">It’s like a translator that helps different programs </span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.199.1">or systems work together by sharing data and functionality in a standardized way. </span><span class="koboSpan" id="kobo.199.2">For example, when you use an app to check the weather, the app uses an API to get the weather information from a weather service.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.200.1"><img alt="" src="../Images/B31559_10_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.201.1">Figure 10.1: A weather app using an API to gather information</span></p>
<p class="normal"><span class="koboSpan" id="kobo.202.1">Now, when it </span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.203.1">comes to LLMs’ APIs, the mechanism is similar. </span><span class="koboSpan" id="kobo.203.2">More specifically, LLMs’ APIs fall within the category of </span><strong class="keyWord"><span class="koboSpan" id="kobo.204.1">Representational State Transfer</span></strong><span class="koboSpan" id="kobo.205.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.206.1">REST</span></strong><span class="koboSpan" id="kobo.207.1">) APIs, meaning that they:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.208.1">Use standard HTTP methods (POST for sending prompts, GET for retrieving data).</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.209.1">Communicate over HTTP/HTTPS.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.210.1">Return responses in JSON format.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.211.1">Follow a stateless model, meaning each request is independent.</span><div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.212.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.213.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.214.1">REST API</span></strong><span class="koboSpan" id="kobo.215.1"> is a </span><a id="_idIndexMarker564"/><span class="koboSpan" id="kobo.216.1">web-based API that follows REST principles, using HTTP methods like GET, POST, PUT, and DELETE to interact with resources via URLs. </span><span class="koboSpan" id="kobo.216.2">It is stateless, meaning each request is independent, and it typically exchanges data in JSON format. </span><span class="koboSpan" id="kobo.216.3">Other types of APIs include </span><strong class="keyWord"><span class="koboSpan" id="kobo.217.1">SOAP</span></strong><span class="koboSpan" id="kobo.218.1">, which relies </span><a id="_idIndexMarker565"/><span class="koboSpan" id="kobo.219.1">on XML for structured messaging and strict security; </span><strong class="keyWord"><span class="koboSpan" id="kobo.220.1">GraphQL</span></strong><span class="koboSpan" id="kobo.221.1">, which </span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.222.1">allows clients to request </span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.223.1">specific data for more flexibility; </span><strong class="keyWord"><span class="koboSpan" id="kobo.224.1">gRPC</span></strong><span class="koboSpan" id="kobo.225.1">, which uses Protocol Buffers for efficient microservice communication; </span><strong class="keyWord"><span class="koboSpan" id="kobo.226.1">WebSockets</span></strong><span class="koboSpan" id="kobo.227.1">, which enables </span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.228.1">real-time, two-way communication; and </span><strong class="keyWord"><span class="koboSpan" id="kobo.229.1">Streaming APIs</span></strong><span class="koboSpan" id="kobo.230.1">, which </span><a id="_idIndexMarker569"/><span class="koboSpan" id="kobo.231.1">provide continuous data flow, often used for AI responses and stock market feeds.</span></p>
</div>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.232.1">Let’s explore </span><a id="_idIndexMarker570"/><span class="koboSpan" id="kobo.233.1">how you might use an OpenAI model’s API to create a marketing assistant. </span><span class="koboSpan" id="kobo.233.2">This assistant helps marketers generate content like social media posts, email drafts, ad copy, or blog post ideas. </span><span class="koboSpan" id="kobo.233.3">Let’s break down the whole process:</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.234.1">Sending a request</span></strong><span class="koboSpan" id="kobo.235.1">:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.236.1">A marketer using your application might type a prompt like, “Create a social media post promoting our new eco-friendly product line.”</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.237.1">Your marketing assistant sends this prompt to the OpenAI model’s API as part of a request. </span><span class="koboSpan" id="kobo.237.2">The request includes the prompt and any specific instructions, including the model to use – let’s say, the GPT-4o.</span></li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.238.1">Processing by the model</span></strong><span class="koboSpan" id="kobo.239.1">:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.240.1">The OpenAI API receives the request and processes the prompt using the specified model (in our case, the GPT-4o).</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.241.1">The model generates a response by analyzing the input and drawing on its extensive knowledge base. </span><span class="koboSpan" id="kobo.241.2">It considers factors like the target audience, common marketing phrases, and the desired tone to create relevant content.</span></li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.242.1">Receiving the response</span></strong><span class="koboSpan" id="kobo.243.1">:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.244.1">The API sends the generated content back to your marketing assistant application as a response.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.245.1">For instance, the model might generate something like: “Excited to launch our new eco-friendly product line! </span><span class="koboSpan" id="kobo.245.2">Sustainable, stylish, and perfect for the conscious consumer. </span><span class="koboSpan" id="kobo.245.3">Join us in making a positive impact—shop now and save the planet, one product at a time! </span><span class="koboSpan" id="kobo.245.4">#EcoFriendly #Sustainability.”</span></li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.246.1">Displaying the response</span></strong><span class="koboSpan" id="kobo.247.1">:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.248.1">Your application receives the content from the API and displays it to the marketer.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.249.1">The marketer can then review, edit, and publish the content as needed, saving time and effort in the content creation process.</span></li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.250.1">Additional features</span></strong><span class="koboSpan" id="kobo.251.1">:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.252.1">Customization</span></strong><span class="koboSpan" id="kobo.253.1">: The marketer can further customize the request. </span><span class="koboSpan" id="kobo.253.2">For example, they might ask for a series of posts or request variations to test different marketing angles.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.254.1">Feedback loop</span></strong><span class="koboSpan" id="kobo.255.1">: The application might also allow the marketer to rate the generated content. </span><span class="koboSpan" id="kobo.255.2">This feedback could be used to fine-tune future requests, improving the relevance and quality of the content over time.</span></li>
</ul>
</li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.256.1">Behind the scenes</span></strong><span class="koboSpan" id="kobo.257.1">:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.258.1">API key and authentication</span></strong><span class="koboSpan" id="kobo.259.1">: To use the OpenAI API, your application needs an API key (a unique alphanumeric string used to authenticate and identify </span><a id="_idIndexMarker571"/><span class="koboSpan" id="kobo.260.1">applications or projects making requests to an API), which ensures that only authorized users can access the service.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.261.1">Handling multiple requests</span></strong><span class="koboSpan" id="kobo.262.1">: The OpenAI API is designed to handle multiple requests at once, meaning it can serve many marketers simultaneously without slowing down.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.263.1">Rate limits and cost</span></strong><span class="koboSpan" id="kobo.264.1">: Depending on the API usage, there might be rate limits (e.g., how many requests can be sent per minute) and costs associated with the amount of text processed. </span><span class="koboSpan" id="kobo.264.2">Your application would need to manage these factors, perhaps by prioritizing certain requests or batching them.</span></li>
</ul>
</li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.265.1">The possibility of consuming OpenAI models via APIs gives developers great flexibility when it comes to customizing the application logic around the LLM. </span><span class="koboSpan" id="kobo.265.2">In the next section, we are going to see how to leverage those APIs in practice with Python.</span></p>
<h2 class="heading-2" id="_idParaDest-155"><span class="koboSpan" id="kobo.266.1">How to use OpenAI models’ APIs with the Python SDK</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.267.1">To use </span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.268.1">OpenAI models’ APIs in your programming </span><a id="_idIndexMarker573"/><span class="koboSpan" id="kobo.269.1">IDE, you first need to create an access token from your OpenAI account.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.270.1">Note</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.271.1">When consuming OpenAI’s APIs, you will incur a cost that is proportional to the model’s usage. </span><span class="koboSpan" id="kobo.271.2">More specifically, OpenAI’s pricing model is </span><strong class="keyWord"><span class="koboSpan" id="kobo.272.1">per token</span></strong><span class="koboSpan" id="kobo.273.1">, where a token represents a chunk of text (about 4 characters in English). </span><span class="koboSpan" id="kobo.273.2">To estimate your tokens’ consumption – hence your cost – you can refer to this articl</span><a href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them"><span class="koboSpan" id="kobo.274.1">e: </span><span class="url"><span class="koboSpan" id="kobo.275.1">https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-t</span></span></a><span class="url"><span class="koboSpan" id="kobo.276.1">hem</span></span><span class="koboSpan" id="kobo.277.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.278.1">Each </span><a id="_idIndexMarker574"/><span class="koboSpan" id="kobo.279.1">API request consumes tokens based on input (prompt) and output (response). </span><span class="koboSpan" id="kobo.279.2">Pricing varies by model, with </span><strong class="keyWord"><span class="koboSpan" id="kobo.280.1">more powerful models costing more per token.</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.281.1">You can find OpenAI’s pricing model at </span><span class="url"><span class="koboSpan" id="kobo.282.1">https://openai.com/api/pricing/</span></span><span class="koboSpan" id="kobo.283.1">.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.284.1">To do </span><a id="_idIndexMarker575"/><span class="koboSpan" id="kobo.285.1">so, you can follow these steps:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.286.1">Navigat</span><a href="https://platform.openai.com/api-keys"><span class="koboSpan" id="kobo.287.1">e to </span><span class="url"><span class="koboSpan" id="kobo.288.1">https://platform.openai.com/api</span></span></a><span class="url"><span class="koboSpan" id="kobo.289.1">-keys</span></span><span class="koboSpan" id="kobo.290.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.291.1">Click on </span><code class="inlineCode"><span class="koboSpan" id="kobo.292.1">+ Create new secret key</span></code><span class="koboSpan" id="kobo.293.1">:</span></li>
</ol>
<figure class="mediaobject"><span class="koboSpan" id="kobo.294.1"><img alt="" src="../Images/B31559_10_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.295.1">Figure 10.2: OpenAI API platform</span></p>
<ol>
<li class="numberedList" value="3"><span class="koboSpan" id="kobo.296.1">This will create a new API key that you can save in a key vault of your choice.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.297.1">Once you create the API key, you can use it to consume your model with the following script:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.298.1">from</span></span><span class="koboSpan" id="kobo.299.1"> openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.300.1">import</span></span><span class="koboSpan" id="kobo.301.1"> OpenAI
client = OpenAI(api_key = </span><span class="hljs-string"><span class="koboSpan" id="kobo.302.1">"xxx"</span></span><span class="koboSpan" id="kobo.303.1">)
response = client.chat.completions.create(
  model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.304.1">"gpt-4o"</span></span><span class="koboSpan" id="kobo.305.1">,
  messages=[
    {</span><span class="hljs-string"><span class="koboSpan" id="kobo.306.1">"role"</span></span><span class="koboSpan" id="kobo.307.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.308.1">"system"</span></span><span class="koboSpan" id="kobo.309.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.310.1">"content"</span></span><span class="koboSpan" id="kobo.311.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.312.1">"You are a helpful assistant."</span></span><span class="koboSpan" id="kobo.313.1">},
    {</span><span class="hljs-string"><span class="koboSpan" id="kobo.314.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.315.1">role"</span></span><span class="koboSpan" id="kobo.316.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.317.1">"user"</span></span><span class="koboSpan" id="kobo.318.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.319.1">"content"</span></span><span class="koboSpan" id="kobo.320.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.321.1">"What is the recipe for Margherita Pizza?"</span></span><span class="koboSpan" id="kobo.322.1">}
  ]
)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.323.1">The above </span><a id="_idIndexMarker576"/><span class="koboSpan" id="kobo.324.1">example leverages the Python </span><a id="_idIndexMarker577"/><span class="koboSpan" id="kobo.325.1">SDK. </span><span class="koboSpan" id="kobo.325.2">However, you can also do your call with Node.js or curl, as specified in the OpenAI documentation.</span></p>
<div class="note">
<p class="normal"><span class="koboSpan" id="kobo.326.1">Note</span></p>
<p class="normal"><span class="koboSpan" id="kobo.327.1">The schema of your client might vary depending on the model you are using and the data format you are passing as a prompt. </span><span class="koboSpan" id="kobo.327.2">For example, if you are using the gpt-4o-mini for image processing, your client will look like the following:</span></p>
<p class="normal"><span class="koboSpan" id="kobo.328.1">response = client.chat.completions.create(</span></p>
<p class="normal"><span class="koboSpan" id="kobo.329.1"> model=”gpt-4o-mini”,</span></p>
<p class="normal"><span class="koboSpan" id="kobo.330.1"> messages=[</span></p>
<p class="normal"><span class="koboSpan" id="kobo.331.1"> {</span></p>
<p class="normal"><span class="koboSpan" id="kobo.332.1"> “role”: “user”,</span></p>
<p class="normal"><span class="koboSpan" id="kobo.333.1"> “content”: [</span></p>
<p class="normal"><span class="koboSpan" id="kobo.334.1"> {“type”: “text”, “text”: prompt},</span></p>
<p class="normal"><span class="koboSpan" id="kobo.335.1"> {</span></p>
<p class="normal"><span class="koboSpan" id="kobo.336.1"> “type”: “image_url”,</span></p>
<p class="normal"><span class="koboSpan" id="kobo.337.1"> “image_url”: {“url”: f”data:{img_type};base64,{img_b64_str}”},</span></p>
<p class="normal"><span class="koboSpan" id="kobo.338.1"> },</span></p>
<p class="normal"><span class="koboSpan" id="kobo.339.1"> ],</span></p>
<p class="normal"><span class="koboSpan" id="kobo.340.1"> }</span></p>
<p class="normal"><span class="koboSpan" id="kobo.341.1"> ],</span></p>
<p class="normal"><span class="koboSpan" id="kobo.342.1">)</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.343.1">You can find the OpenAI Python library at the following GitHub repos</span><a href="https://github.com/openai/openai-python"><span class="koboSpan" id="kobo.344.1">itory: </span><span class="url"><span class="koboSpan" id="kobo.345.1">https://github.com/openai/openai</span></span></a><span class="url"><span class="koboSpan" id="kobo.346.1">-python</span></span><span class="koboSpan" id="kobo.347.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.348.1">Let’s inspect how the response is built (I truncated the content of the response):</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.349.1">response.to_dict()
{</span><span class="hljs-string"><span class="koboSpan" id="kobo.350.1">'id'</span></span><span class="koboSpan" id="kobo.351.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.352.1">'chatcmpl-9znQeWUbRyGmy3pWf7VfFWAppMCo7'</span></span><span class="koboSpan" id="kobo.353.1">,
 </span><span class="hljs-string"><span class="koboSpan" id="kobo.354.1">'choices'</span></span><span class="koboSpan" id="kobo.355.1">: [{</span><span class="hljs-string"><span class="koboSpan" id="kobo.356.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.357.1">finish_reason'</span></span><span class="koboSpan" id="kobo.358.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.359.1">'stop'</span></span><span class="koboSpan" id="kobo.360.1">,
   </span><span class="hljs-string"><span class="koboSpan" id="kobo.361.1">'index'</span></span><span class="koboSpan" id="kobo.362.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.363.1">0</span></span><span class="koboSpan" id="kobo.364.1">,
   </span><span class="hljs-string"><span class="koboSpan" id="kobo.365.1">'logprobs'</span></span><span class="koboSpan" id="kobo.366.1">: </span><span class="hljs-literal"><span class="koboSpan" id="kobo.367.1">None</span></span><span class="koboSpan" id="kobo.368.1">,
   </span><span class="hljs-string"><span class="koboSpan" id="kobo.369.1">'message'</span></span><span class="koboSpan" id="kobo.370.1">: {</span><span class="hljs-string"><span class="koboSpan" id="kobo.371.1">'content'</span></span><span class="koboSpan" id="kobo.372.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.373.1">'To make Margherita Pizza […]</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.374.1">    '</span></span><span class="koboSpan" id="kobo.375.1">role</span><span class="hljs-string"><span class="koboSpan" id="kobo.376.1">': '</span></span><span class="koboSpan" id="kobo.377.1">assistant</span><span class="hljs-string"><span class="koboSpan" id="kobo.378.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.379.1">},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.380.1">   '</span></span><span class="koboSpan" id="kobo.381.1">content_filter_results</span><span class="hljs-string"><span class="koboSpan" id="kobo.382.1">': {'</span></span><span class="koboSpan" id="kobo.383.1">hate</span><span class="hljs-string"><span class="koboSpan" id="kobo.384.1">': {'</span></span><span class="koboSpan" id="kobo.385.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.386.1">': False, '</span></span><span class="koboSpan" id="kobo.387.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.388.1">': '</span></span><span class="koboSpan" id="kobo.389.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.390.1">'},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.391.1">    '</span></span><span class="koboSpan" id="kobo.392.1">self_harm</span><span class="hljs-string"><span class="koboSpan" id="kobo.393.1">': {'</span></span><span class="koboSpan" id="kobo.394.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.395.1">': False, '</span></span><span class="koboSpan" id="kobo.396.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.397.1">': '</span></span><span class="koboSpan" id="kobo.398.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.399.1">'},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.400.1">    '</span></span><span class="koboSpan" id="kobo.401.1">sexual</span><span class="hljs-string"><span class="koboSpan" id="kobo.402.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.403.1">: {'</span></span><span class="koboSpan" id="kobo.404.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.405.1">': False, '</span></span><span class="koboSpan" id="kobo.406.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.407.1">': '</span></span><span class="koboSpan" id="kobo.408.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.409.1">'},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.410.1">    '</span></span><span class="koboSpan" id="kobo.411.1">violence</span><span class="hljs-string"><span class="koboSpan" id="kobo.412.1">': {'</span></span><span class="koboSpan" id="kobo.413.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.414.1">': False, '</span></span><span class="koboSpan" id="kobo.415.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.416.1">': '</span></span><span class="koboSpan" id="kobo.417.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.418.1">'}}}],</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.419.1"> '</span></span><span class="koboSpan" id="kobo.420.1">created</span><span class="hljs-string"><span class="koboSpan" id="kobo.421.1">': 1724515040,</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.422.1"> '</span></span><span class="koboSpan" id="kobo.423.1">model</span><span class="hljs-string"><span class="koboSpan" id="kobo.424.1">': '</span></span><span class="koboSpan" id="kobo.425.1">gpt-4o-</span><span class="hljs-number"><span class="koboSpan" id="kobo.426.1">2024</span></span><span class="koboSpan" id="kobo.427.1">-05-</span><span class="hljs-number"><span class="koboSpan" id="kobo.428.1">13</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.429.1">',</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.430.1"> '</span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.431.1">object</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.432.1">': '</span></span><span class="koboSpan" id="kobo.433.1">chat.completion</span><span class="hljs-string"><span class="koboSpan" id="kobo.434.1">',</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.435.1"> '</span></span><span class="koboSpan" id="kobo.436.1">system_fingerprint</span><span class="hljs-string"><span class="koboSpan" id="kobo.437.1">': '</span></span><span class="koboSpan" id="kobo.438.1">fp_abc28019ad</span><span class="hljs-string"><span class="koboSpan" id="kobo.439.1">',</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.440.1"> '</span></span><span class="koboSpan" id="kobo.441.1">usage</span><span class="hljs-string"><span class="koboSpan" id="kobo.442.1">': {'</span></span><span class="koboSpan" id="kobo.443.1">completion_tokens</span><span class="hljs-string"><span class="koboSpan" id="kobo.444.1">': 193, '</span></span><span class="koboSpan" id="kobo.445.1">prompt_tokens</span><span class="hljs-string"><span class="koboSpan" id="kobo.446.1">': 55, '</span></span><span class="koboSpan" id="kobo.447.1">total_tokens</span><span class="hljs-string"><span class="koboSpan" id="kobo.448.1">': 248},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.449.1"> '</span></span><span class="koboSpan" id="kobo.450.1">prompt_filter_results</span><span class="hljs-string"><span class="koboSpan" id="kobo.451.1">': [{'</span></span><span class="koboSpan" id="kobo.452.1">prompt_index</span><span class="hljs-string"><span class="koboSpan" id="kobo.453.1">': 0,</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.454.1">   '</span></span><span class="koboSpan" id="kobo.455.1">content_filter_results</span><span class="hljs-string"><span class="koboSpan" id="kobo.456.1">': {'</span></span><span class="koboSpan" id="kobo.457.1">hate</span><span class="hljs-string"><span class="koboSpan" id="kobo.458.1">': {'</span></span><span class="koboSpan" id="kobo.459.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.460.1">': False, '</span></span><span class="koboSpan" id="kobo.461.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.462.1">': '</span></span><span class="koboSpan" id="kobo.463.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.464.1">'},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.465.1">    '</span></span><span class="koboSpan" id="kobo.466.1">self_harm</span><span class="hljs-string"><span class="koboSpan" id="kobo.467.1">': {'</span></span><span class="koboSpan" id="kobo.468.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.469.1">': False, '</span></span><span class="koboSpan" id="kobo.470.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.471.1">': '</span></span><span class="koboSpan" id="kobo.472.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.473.1">'},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.474.1">    '</span></span><span class="koboSpan" id="kobo.475.1">sexual</span><span class="hljs-string"><span class="koboSpan" id="kobo.476.1">': {'</span></span><span class="koboSpan" id="kobo.477.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.478.1">': False, '</span></span><span class="koboSpan" id="kobo.479.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.480.1">': '</span></span><span class="koboSpan" id="kobo.481.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.482.1">'},</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.483.1">    '</span></span><span class="koboSpan" id="kobo.484.1">violence</span><span class="hljs-string"><span class="koboSpan" id="kobo.485.1">': {'</span></span><span class="koboSpan" id="kobo.486.1">filtered</span><span class="hljs-string"><span class="koboSpan" id="kobo.487.1">': False, '</span></span><span class="koboSpan" id="kobo.488.1">severity</span><span class="hljs-string"><span class="koboSpan" id="kobo.489.1">': '</span></span><span class="koboSpan" id="kobo.490.1">safe</span><span class="hljs-string"><span class="koboSpan" id="kobo.491.1">'}}}]}</span></span>
</code></pre>
<p class="normal"><span class="koboSpan" id="kobo.492.1">As you </span><a id="_idIndexMarker578"/><span class="koboSpan" id="kobo.493.1">can see, there are many components </span><a id="_idIndexMarker579"/><span class="koboSpan" id="kobo.494.1">that make up the response object:</span></p>
<ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.495.1">id</span></code><span class="koboSpan" id="kobo.496.1">: This is a unique identifier for the API call. </span><span class="koboSpan" id="kobo.496.2">In this case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.497.1">chatcmpl-9znQeWUbRyGmy3pWf7VfFWAppMCo7</span></code><span class="koboSpan" id="kobo.498.1"> is the specific ID associated with this particular chat completion request.</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.499.1">choices</span></code><span class="koboSpan" id="kobo.500.1">: This is an array containing the different possible responses (choices) generated by the model. </span><span class="koboSpan" id="kobo.500.2">In this response, there’s only one choice (</span><code class="inlineCode"><span class="koboSpan" id="kobo.501.1">index 0</span></code><span class="koboSpan" id="kobo.502.1">), which is typical for most single-response completions:</span><ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.503.1">index</span></code><span class="koboSpan" id="kobo.504.1">: Indicates the position of this particular choice in the list of choices (in this case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.505.1">0</span></code><span class="koboSpan" id="kobo.506.1">).</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.507.1">finish_reason</span></code><span class="koboSpan" id="kobo.508.1">: Indicates why the model stopped generating tokens. </span><strong class="keyWord"><span class="koboSpan" id="kobo.509.1">stop</span></strong><span class="koboSpan" id="kobo.510.1"> usually means the model naturally reached the end of its response without needing to be cut off.</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.511.1">logprobs</span></code><span class="koboSpan" id="kobo.512.1">: If enabled, this would contain the log probabilities of each token in the completion. </span><span class="koboSpan" id="kobo.512.2">It is </span><code class="inlineCode"><span class="koboSpan" id="kobo.513.1">None</span></code><span class="koboSpan" id="kobo.514.1"> here, indicating that you did not request this information.</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.515.1">message</span></code><span class="koboSpan" id="kobo.516.1">: Contains the content of the response (</span><code class="inlineCode"><span class="koboSpan" id="kobo.517.1">'content'</span></code><span class="koboSpan" id="kobo.518.1">) and the role of the speaker (</span><code class="inlineCode"><span class="koboSpan" id="kobo.519.1">'role'</span></code><span class="koboSpan" id="kobo.520.1">):</span><ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.521.1">content</span></code><span class="koboSpan" id="kobo.522.1">: The actual text generated by the assistant, which in this case is a response regarding Azure AI services that support customer-managed keys</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.523.1">role</span></code><span class="koboSpan" id="kobo.524.1">: The role of the speaker in the conversation, which is ‘assistant’ here, indicating the response came from the AI assistant</span></li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.525.1">content_filter_results</span></code><span class="koboSpan" id="kobo.526.1">: This contains the content filtering results for the response, checking for any harmful content in categories like hate, self-harm, sexual content, and violence. </span><span class="koboSpan" id="kobo.526.2">In this case, all categories are marked as </span><code class="inlineCode"><span class="koboSpan" id="kobo.527.1">'safe'</span></code><span class="koboSpan" id="kobo.528.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.529.1">'filtered': False</span></code><span class="koboSpan" id="kobo.530.1">, indicating no problematic content was detected.</span></li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.531.1">created</span></code><span class="koboSpan" id="kobo.532.1">: This is </span><a id="_idIndexMarker580"/><span class="koboSpan" id="kobo.533.1">a timestamp representing </span><a id="_idIndexMarker581"/><span class="koboSpan" id="kobo.534.1">when the response was generated. </span><span class="koboSpan" id="kobo.534.2">The number </span><code class="inlineCode"><span class="koboSpan" id="kobo.535.1">1724515040</span></code><span class="koboSpan" id="kobo.536.1"> is the UNIX timestamp (seconds since January 1, 1970).</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.537.1">model</span></code><span class="koboSpan" id="kobo.538.1">: This indicates the version of the model that generated the response.</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.539.1">object</span></code><span class="koboSpan" id="kobo.540.1">: This indicates the type of object returned. </span><span class="koboSpan" id="kobo.540.2">In this case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.541.1">'chat.completion'</span></code><span class="koboSpan" id="kobo.542.1"> signifies that this is a completion from the chat API.</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.543.1">system_fingerprint</span></code><span class="koboSpan" id="kobo.544.1">: This is an internal identifier used by OpenAI for tracking or diagnosing the system that handled the request. </span><code class="inlineCode"><span class="koboSpan" id="kobo.545.1">'fp_abc28019ad'</span></code><span class="koboSpan" id="kobo.546.1"> is the specific fingerprint for this transaction.</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.547.1">usage</span></code><span class="koboSpan" id="kobo.548.1">: This object tracks the token usage for the API call:</span><ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.549.1">completion_tokens</span></code><span class="koboSpan" id="kobo.550.1">: The number of tokens used in the generated response (193 tokens)</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.551.1">prompt_tokens</span></code><span class="koboSpan" id="kobo.552.1">: The number of tokens used in the input prompt (55 tokens)</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.553.1">total_tokens</span></code><span class="koboSpan" id="kobo.554.1">: The total number of tokens consumed in the request, which is the sum of the prompt and completion tokens (248 tokens)</span></li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.555.1">prompt_filter_results</span></code><span class="koboSpan" id="kobo.556.1">: This array contains the results of content filtering applied to the input prompt before generating the response. </span><span class="koboSpan" id="kobo.556.2">It ensures that the prompt does not contain harmful content. </span><span class="koboSpan" id="kobo.556.3">Like the </span><code class="inlineCode"><span class="koboSpan" id="kobo.557.1">content_filter_results</span></code><span class="koboSpan" id="kobo.558.1"> in the choices section, it includes checks for hate, self-harm, sexual content, and violence. </span><span class="koboSpan" id="kobo.558.2">All are marked as </span><code class="inlineCode"><span class="koboSpan" id="kobo.559.1">'safe'</span></code><span class="koboSpan" id="kobo.560.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.561.1">'filtered': False</span></code><span class="koboSpan" id="kobo.562.1">, indicating no issues were found.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.563.1">Among all the output parameters, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.564.1">content_filter_results</span></code><span class="koboSpan" id="kobo.565.1"> might be particularly relevant when </span><a id="_idIndexMarker582"/><span class="koboSpan" id="kobo.566.1">it comes to managing potentially </span><a id="_idIndexMarker583"/><span class="koboSpan" id="kobo.567.1">harmful results. </span><span class="koboSpan" id="kobo.567.2">In fact, you might want to enforce a more conservative approach when it comes to potentially harmful content, in either input or output. </span><span class="koboSpan" id="kobo.567.3">If this is the case, you could simply enforce a deterministic rule that prevents the model from further processing any request that triggers a given level of risk.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.568.1">This is a meaningful example of how leveraging OpenAI models’ APIs allows for great flexibility when it comes to building application logic around LLMs.</span></p>
<h1 class="heading-1" id="_idParaDest-156"><span class="koboSpan" id="kobo.569.1">Architectural patterns to build applications with models’ APIs</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.570.1">The rise </span><a id="_idIndexMarker584"/><span class="koboSpan" id="kobo.571.1">of GenAI and LLMs </span><a id="_idIndexMarker585"/><span class="koboSpan" id="kobo.572.1">paved the way for a revolution in the field of software development. </span><span class="koboSpan" id="kobo.572.2">In fact, from “modern applications” – referring to microservices-based architectures and rapid innovation with CI/CD – we now talk about “intelligent applications” that are infused with GenAI models defined by natural language interaction, data-driven experience, and velocity of adaptation to new models’ releases.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.573.1">An intelligent app can be described with the following illustration:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.574.1"><img alt="A diagram of a computer network  Description automatically generated with medium confidence" src="../Images/B31559_10_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.575.1">Figure 10.3: Anatomy of an intelligent application powered by an LLM</span></p>
<p class="normal"><span class="koboSpan" id="kobo.576.1">In the </span><a id="_idIndexMarker586"/><span class="koboSpan" id="kobo.577.1">above architecture, we </span><a id="_idIndexMarker587"/><span class="koboSpan" id="kobo.578.1">depict the anatomy of an intelligent application with the following features:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.579.1">It has a natural language interface (it might be text- or voice-based).</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.580.1">It is powered by an LLM that acts as the “brain” of the app.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.581.1">It has </span><a id="_idIndexMarker588"/><span class="koboSpan" id="kobo.582.1">a knowledge base that the model can query, typically with </span><strong class="keyWord"><span class="koboSpan" id="kobo.583.1">retrieval augmented generation</span></strong><span class="koboSpan" id="kobo.584.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.585.1">RAG</span></strong><span class="koboSpan" id="kobo.586.1">) techniques.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.587.1">It has a set of tools or plugins that it can use to interact with the external environment.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.588.1">This new paradigm of software development brings a set of new application components that are typical of AI-powered applications. </span><span class="koboSpan" id="kobo.588.2">Let’s explore these new components in more detail.</span></p>
<h2 class="heading-2" id="_idParaDest-157"><span class="koboSpan" id="kobo.589.1">New application components</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.590.1">The main shift in terms of AI development refers to the way we work with models: from producing </span><a id="_idIndexMarker589"/><span class="koboSpan" id="kobo.591.1">models, now the trend is consuming models that, as we mentioned several times, are nothing but APIs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.592.1">This shift leads to a series of new software components (or adjustments of existing components) in the landscape of development:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.593.1">Models</span></strong><span class="koboSpan" id="kobo.594.1">: The model is simply the type of LLM we decide to embed in our application. </span><span class="koboSpan" id="kobo.594.2">There are two main categories of models:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.595.1">Proprietary LLMs</span></strong><span class="koboSpan" id="kobo.596.1">: Models that are owned by specific companies or organizations. </span><span class="koboSpan" id="kobo.596.2">Examples include GPT-4o, developed by OpenAI, or Gemini, developed by Google. </span><span class="koboSpan" id="kobo.596.3">As their source code and architecture are not available, those models cannot be re-trained from scratch on custom data, but they can be fine-tuned if needed.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.597.1">Open-source</span></strong><span class="koboSpan" id="kobo.598.1">: Models with code and architecture freely available and distributed, hence they can also be trained from scratch on custom data. </span><span class="koboSpan" id="kobo.598.2">Examples </span><a id="_idIndexMarker590"/><span class="koboSpan" id="kobo.599.1">include Falcon LLM, developed by Abu Dhabi’s </span><strong class="keyWord"><span class="koboSpan" id="kobo.600.1">Technology Innovation Institute</span></strong><span class="koboSpan" id="kobo.601.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.602.1">TII</span></strong><span class="koboSpan" id="kobo.603.1">), and Llama, developed by Meta.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.604.1">System message</span></strong><span class="koboSpan" id="kobo.605.1">: This is the set of instructions that we provide the model with, and that </span><a id="_idIndexMarker591"/><span class="koboSpan" id="kobo.606.1">influence the style and behavior of our AI app. </span><span class="koboSpan" id="kobo.606.2">There are many features that we can shape directly within the meta-prompt, including:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.607.1">Reducing hallucination by specifying that the model only refers to the provided knowledge base (this process is called “grounding”)</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.608.1">Implementing responsible AI practices by specifying, for example, not to respond to malicious queries or not to generate potentially harmful responses</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.609.1">Instructing the model to always ask an additional question to consolidate the context before answering</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.610.1">Memory and VectorDB</span></strong><span class="koboSpan" id="kobo.611.1">: When we talk about memory in the context of AI apps, we need to differentiate between two types of memory:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.612.1">Short-term memory</span></strong><span class="koboSpan" id="kobo.613.1">: This is the capability of the app to keep the interactions between the user and LLMs in a context window. </span><span class="koboSpan" id="kobo.613.2">It means that each message feeds the existing meta-prompt of the model, without the user repeating something already mentioned.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.614.1">Long-term memory</span></strong><span class="koboSpan" id="kobo.615.1">: This type of memory refers to the external knowledge base we provide the model with using embeddings. </span><span class="koboSpan" id="kobo.615.2">When this is the case, we typically leverage VectorDBs, a new type of database (or new feature of an existing database) that stores the numerical representations of the provided documents.</span><div class="note-one">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.616.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.617.1">A VectorDB is a type </span><a id="_idIndexMarker592"/><span class="koboSpan" id="kobo.618.1">of database that stores and retrieves information based on vectorized embeddings, the numerical representations that capture the meaning and context of text. </span><span class="koboSpan" id="kobo.618.2">By using a VectorDB, you can perform semantic search and retrieval based on the similarity of meanings rather than keywords. </span><span class="koboSpan" id="kobo.618.3">Some examples of a VectorDB are Chroma, FAISS, Elasticsearch, Milvus, Pinecone, Qdrant, and Weaviate.</span></p>
</div>
</li>
</ul>
</li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.619.1">Tools/plugins</span></strong><span class="koboSpan" id="kobo.620.1">: These can be seen as additional modules or components that can be integrated into the LLM to extend its functionality or adapt it to specific tasks and applications. </span><span class="koboSpan" id="kobo.620.2">These plugins act as add-ons, enhancing the capabilities of the LLM beyond its core language generation or comprehension abilities.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.621.1">The idea </span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.622.1">behind plugins is to make LLMs more versatile and adaptable, allowing developers and users to customize the behavior of the language model for their specific needs. </span><span class="koboSpan" id="kobo.622.2">Plugins can be created to perform various tasks, and they can be seamlessly incorporated into the LLM’s architecture.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.623.1">The following is an illustration of the main components of an LLM-powered application:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.624.1"><img alt="A diagram of a computer program  Description automatically generated" src="../Images/B31559_10_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.625.1">Figure 10.4: High-level architecture of LLM-powered applications</span></p>
<p class="normal"><span class="koboSpan" id="kobo.626.1">As you can see from the picture above, the core of the high-level architecture is the </span><strong class="keyWord"><span class="koboSpan" id="kobo.627.1">AI orchestrator</span></strong><span class="koboSpan" id="kobo.628.1">. </span><span class="koboSpan" id="kobo.628.2">With the AI orchestrator, we refer to lightweight libraries that make it easier to embed and orchestrate LLMs within applications.</span></p>
<h2 class="heading-2" id="_idParaDest-158"><span class="koboSpan" id="kobo.629.1">AI orchestrators</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.630.1">Since LLMs </span><a id="_idIndexMarker594"/><span class="koboSpan" id="kobo.631.1">went viral toward the end of 2022, many </span><a id="_idIndexMarker595"/><span class="koboSpan" id="kobo.632.1">libraries have begun to arise in the market. </span><span class="koboSpan" id="kobo.632.2">In the next sections, we are going to focus on three of them: LangChain, Semantic Kernel, and Haystack.</span></p>
<h3 class="heading-3" id="_idParaDest-159"><span class="koboSpan" id="kobo.633.1">LangChain</span></h3>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.634.1">LangChain</span></strong><span class="koboSpan" id="kobo.635.1"> was launched </span><a id="_idIndexMarker596"/><span class="koboSpan" id="kobo.636.1">as an open-source project by Harrison Chase, in October 2022. </span><span class="koboSpan" id="kobo.636.2">It can be used in both Python and JS/TS.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.637.1">LangChain is </span><a id="_idIndexMarker597"/><span class="koboSpan" id="kobo.638.1">a framework for developing applications powered by language models, making them data-aware (with grounding) and agentic – meaning able to interact with external environments.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.639.1">LangChain provides modular abstractions for the components necessary to work with language models that we previously mentioned, such as prompts, memory, and plugins. </span><span class="koboSpan" id="kobo.639.2">Alongside those components, LangChain also offers pre-built </span><strong class="keyWord"><span class="koboSpan" id="kobo.640.1">chains</span></strong><span class="koboSpan" id="kobo.641.1">, which are structured concatenations of components. </span><span class="koboSpan" id="kobo.641.2">These chains can be pre-built for specific use cases or be customized.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.642.1">Overall, LangChain has the following core modules:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.643.1">Models</span></strong><span class="koboSpan" id="kobo.644.1">: These are </span><a id="_idIndexMarker598"/><span class="koboSpan" id="kobo.645.1">the LLMs or large foundation models that will be the engine of the application. </span><span class="koboSpan" id="kobo.645.2">LangChain supports proprietary models, such as those available in OpenAI and Azure OpenAI, and open-source models </span><a id="_idIndexMarker599"/><span class="koboSpan" id="kobo.646.1">consumable from the </span><strong class="keyWord"><span class="koboSpan" id="kobo.647.1">Hugging Face Hub</span></strong><span class="koboSpan" id="kobo.648.1">.</span><div class="note-one">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.649.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.650.1">Hugging Face is a </span><a id="_idIndexMarker600"/><span class="koboSpan" id="kobo.651.1">company and a community that builds and shares state-of-the-art models and tools for </span><strong class="keyWord"><span class="koboSpan" id="kobo.652.1">natural language processing</span></strong><span class="koboSpan" id="kobo.653.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.654.1">NLP</span></strong><span class="koboSpan" id="kobo.655.1">) and other machine learning domains. </span><span class="koboSpan" id="kobo.655.2">It developed the Hugging Face Hub, a platform where people can create, discover, and collaborate on machine learning models and LLMs, datasets, and demos. </span><span class="koboSpan" id="kobo.655.3">The Hugging Face Hub hosts over 120k models, 20k datasets, and 50k demos in various domains and tasks, such as audio, vision, and language.</span></p>
</div>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.656.1">Alongside models, LangChain also offers many prompt-related components that make it easier to manage the prompt flow.</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.657.1">Data connections</span></strong><span class="koboSpan" id="kobo.658.1">: These refer to the building blocks needed to retrieve the additional </span><a id="_idIndexMarker601"/><span class="koboSpan" id="kobo.659.1">non-parametric knowledge we want to provide the model with. </span><span class="koboSpan" id="kobo.659.2">Examples of data connections are document loaders or text embedding models.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.660.1">Memory</span></strong><span class="koboSpan" id="kobo.661.1">: It allows </span><a id="_idIndexMarker602"/><span class="koboSpan" id="kobo.662.1">the application to keep references to the user’s interactions, in both the short and long term. </span><span class="koboSpan" id="kobo.662.2">It is typically based on vectorized embeddings stored in a VectorDB.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.663.1">Chains</span></strong><span class="koboSpan" id="kobo.664.1">: These are </span><a id="_idIndexMarker603"/><span class="koboSpan" id="kobo.665.1">predetermined sequences of actions and calls to LLMs that make it easier to build complex applications that require chaining LLMs with each other or with other components. </span><span class="koboSpan" id="kobo.665.2">An example of a chain might be: take the user query, chunk it into smaller pieces, embed those chunks, search for similar embeddings in a VectorDB, use the top three most similar chunks in the VectorDB as context to provide the answer, generate the answer.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.666.1">Agents</span></strong><span class="koboSpan" id="kobo.667.1">: Agents are </span><a id="_idIndexMarker604"/><span class="koboSpan" id="kobo.668.1">entities that drive decision-making within LLM-powered applications. </span><span class="koboSpan" id="kobo.668.2">They have access to a suite of tools and can decide which tool to call based on the user input and the context. </span><span class="koboSpan" id="kobo.668.3">Agents are dynamic and adaptive, meaning that they can change or adjust their actions based on the situation or the goal.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-160"><span class="koboSpan" id="kobo.669.1">Haystack</span></h3>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.670.1">Haystack</span></strong><span class="koboSpan" id="kobo.671.1"> is a Python-based </span><a id="_idIndexMarker605"/><span class="koboSpan" id="kobo.672.1">framework developed by </span><em class="italic"><span class="koboSpan" id="kobo.673.1">deepset</span></em><span class="koboSpan" id="kobo.674.1">, a startup </span><a id="_idIndexMarker606"/><span class="koboSpan" id="kobo.675.1">founded in 2018 in Berlin by Milos Rusic, Malte Pietsch, and Timo Möller. </span><span class="koboSpan" id="kobo.675.2">deepset provides developers with the tools to build an NLP-based application, and with the introduction of Haystack, they are taking it to the next level.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.676.1">Haystack has the following core components:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.677.1">Nodes</span></strong><span class="koboSpan" id="kobo.678.1">: These are </span><a id="_idIndexMarker607"/><span class="koboSpan" id="kobo.679.1">components that perform a specific task or function, such as a retriever, a reader, a generator, a summarizer, etc. </span><span class="koboSpan" id="kobo.679.2">Nodes can be LLMs or other utilities that interact with LLMs or other resources. </span><span class="koboSpan" id="kobo.679.3">Among LLMs, Haystack supports proprietary models, such as those available in OpenAI and Azure OpenAI, and open-source models consumable from the Hugging Face Hub.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.680.1">Pipelines</span></strong><span class="koboSpan" id="kobo.681.1">: These are </span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.682.1">sequences of calls to nodes that perform natural language tasks or interact with other resources. </span><span class="koboSpan" id="kobo.682.2">Pipelines can be querying pipelines or indexing pipelines, depending on whether they perform searches on a set of documents or prepare documents for search. </span><span class="koboSpan" id="kobo.682.3">Pipelines are predetermined and hardcoded, meaning that they do not change or adapt based on the user input or the context.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.683.1">Agent</span></strong><span class="koboSpan" id="kobo.684.1">: This is an </span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.685.1">entity that uses LLMs to generate accurate responses to complex queries. </span><span class="koboSpan" id="kobo.685.2">An agent has access to a set of tools, which can be pipelines or nodes, and it can decide which tool to call based on the user input and the context. </span><span class="koboSpan" id="kobo.685.3">An agent is dynamic and adaptive, meaning that it can change or adjust its actions based on the situation or the goal.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.686.1">Tools</span></strong><span class="koboSpan" id="kobo.687.1">: There are </span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.688.1">functions that an agent can call to perform natural language tasks or interact with other resources. </span><span class="koboSpan" id="kobo.688.2">Tools can be pipelines or nodes that are available to the agent and they can be grouped into toolkits, which are sets of tools that can accomplish specific objectives.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.689.1">DocumentStores</span></strong><span class="koboSpan" id="kobo.690.1">: These </span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.691.1">are backends that store and retrieve documents for search. </span><span class="koboSpan" id="kobo.691.2">DocumentStores can be based on different technologies, including VectorDBs (such as FAISS, Milvus, or Elasticsearch).</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.692.1">Haystack is renowned for its simplicity and ease of use, featuring a modular architecture that allows developers to construct customizable pipelines for tasks like semantic search and question-answering. </span><span class="koboSpan" id="kobo.692.2">This design makes it particularly suitable for </span><strong class="keyWord"><span class="koboSpan" id="kobo.693.1">RAG</span></strong><span class="koboSpan" id="kobo.694.1"> applications, where efficient data retrieval is crucial.</span></p>
<h3 class="heading-3" id="_idParaDest-161"><span class="koboSpan" id="kobo.695.1">Semantic Kernel</span></h3>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.696.1">Semantic Kernel</span></strong><span class="koboSpan" id="kobo.697.1"> is the </span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.698.1">third open-source SDK we are going to explore in </span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.699.1">this chapter. </span><span class="koboSpan" id="kobo.699.2">It was developed by Microsoft, originally in C#, and is now also available in Python.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.700.1">This framework takes its name from the concept of a “kernel,” which, generally speaking, refers to the core or essence of a system. </span><span class="koboSpan" id="kobo.700.2">In the context of this framework, a kernel is meant to act as the engine that addresses users’ input by chaining and concatenating a series of components </span><a id="_idIndexMarker614"/><span class="koboSpan" id="kobo.701.1">into pipelines, encouraging </span><strong class="keyWord"><span class="koboSpan" id="kobo.702.1">function composition.</span></strong></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.703.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.704.1">In mathematics, function composition is a way to combine two functions to create a new function. </span><span class="koboSpan" id="kobo.704.2">The idea is to use the output of one function as the input to another function, forming a chain of functions. </span><span class="koboSpan" id="kobo.704.3">The composition of two functions, f and g, is denoted as</span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.705.1"><img alt="" src="../Images/B31559_10_001.png"/></span><span class="koboSpan" id="kobo.706.1">, where the function </span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.707.1"><img alt="" src="../Images/B31559_10_001.png"/></span><span class="koboSpan" id="kobo.708.1"> is applied first, followed by the function </span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.709.1"><img alt="" src="../Images/B31559_10_002.png"/></span><span class="koboSpan" id="kobo.710.1">.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.711.1">Function composition in computer science is a powerful concept that allows for the creation of more sophisticated and reusable code by combining smaller functions into larger ones. </span><span class="koboSpan" id="kobo.711.2">It enhances modularity and code organization, making programs easier to read and maintain.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.712.1">Semantic Kernel has the following main components:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.713.1">Models</span></strong><span class="koboSpan" id="kobo.714.1">: These </span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.715.1">are the LLMs or large foundation models that will be the engine of the application. </span><span class="koboSpan" id="kobo.715.2">Semantic Kernel supports proprietary models, such as those available in OpenAI and Azure OpenAI, and open-source models consumable from the Hugging Face Hub.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.716.1">Memory</span></strong><span class="koboSpan" id="kobo.717.1">: This </span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.718.1">allows the application to keep references to the user’s interactions, in both the short and long term. </span><span class="koboSpan" id="kobo.718.2">Within the framework of Semantic Kernel, memories can be accessed in three ways:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.719.1">Key</span></strong><span class="koboSpan" id="kobo.720.1">-</span><strong class="keyWord"><span class="koboSpan" id="kobo.721.1">value pairs</span></strong><span class="koboSpan" id="kobo.722.1">: This </span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.723.1">consists of saving environment variables that store simple information, such as names or dates.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.724.1">Local storage</span></strong><span class="koboSpan" id="kobo.725.1">: This </span><a id="_idIndexMarker621"/><span class="koboSpan" id="kobo.726.1">consists of saving information to a file that can be retrieved by its filename, such as a CSV or JSON file.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.727.1">Semantic memory search</span></strong><span class="koboSpan" id="kobo.728.1">: This </span><a id="_idIndexMarker622"/><span class="koboSpan" id="kobo.729.1">is similar to LangChain’s and Haystack’s memory, as it uses embeddings to represent and search for text information based on its meaning.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.730.1">Functions</span></strong><span class="koboSpan" id="kobo.731.1">: Functions </span><a id="_idIndexMarker623"/><span class="koboSpan" id="kobo.732.1">can be seen as skills that mix LLM prompts and code, with the goal of making users’ requests interpretable and actionable. </span><span class="koboSpan" id="kobo.732.2">There are two types of functions:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.733.1">Semantic functions</span></strong><span class="koboSpan" id="kobo.734.1">: These </span><a id="_idIndexMarker624"/><span class="koboSpan" id="kobo.735.1">are basically a templated prompt, which is a natural language query that specifies the input and output format for the LLM, also incorporating prompt configuration, which sets the parameters for the LLM.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.736.1">Native functions</span></strong><span class="koboSpan" id="kobo.737.1">: These </span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.738.1">refer to the native computer code that can route the intent captured by the semantic function and perform the related task.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.739.1">To give an example, a semantic function could ask the LLM to write a short paragraph about AI, while a native function could actually post it on social media like LinkedIn.</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.740.1">Plugins</span></strong><span class="koboSpan" id="kobo.741.1">: These are </span><a id="_idIndexMarker626"/><span class="koboSpan" id="kobo.742.1">connectors toward external sources or systems that are meant to provide additional information or the ability to perform autonomous actions. </span><span class="koboSpan" id="kobo.742.2">Semantic Kernel offers out-of-the-box plugins, such as the Microsoft Graph connector kit, but you can build a custom plugin by leveraging functions (both native and semantic, or a mix of the two).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.743.1">Planner</span></strong><span class="koboSpan" id="kobo.744.1">: As LLMs </span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.745.1">can be seen as reasoning engines, they can also be leveraged to auto-create chains or pipelines to address new users’ needs. </span><span class="koboSpan" id="kobo.745.2">This goal is achieved with a planner, which is a function that takes as input a user’s task and produces the set of actions, plugins, and functions needed to achieve the goal.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.746.1">Below is </span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.747.1">an illustration </span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.748.1">of the anatomy of Semantic Kernel:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.749.1"><img alt="Technical perspective of what's happening" src="../Images/B31559_10_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.750.1">Figure 10.5: Anatomy of Semantic Kernel. </span><span class="koboSpan" id="kobo.750.2">Source: https://learn.microsoft.com/en-us/semantic-kernel/overview/</span></p>
<p class="normal"><span class="koboSpan" id="kobo.751.1">Overall, the three frameworks offer more or less similar core components, sometimes called a different taxonomy, yet covering all the blocks illustrated within the concept of the copilot system. </span><span class="koboSpan" id="kobo.751.2">So, a natural question might be, “Which one should I use to build my LLM-powered application?”</span></p>
<p class="normal"><span class="koboSpan" id="kobo.752.1">Below are some criteria you might want to consider:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.753.1">The programming language you are comfortable with or prefer to use</span></strong><span class="koboSpan" id="kobo.754.1">. </span><span class="koboSpan" id="kobo.754.2">Different frameworks may support different programming languages or have different levels of compatibility or integration with them. </span><span class="koboSpan" id="kobo.754.3">For example, Semantic Kernel supports C#, Python, and Java, while LangChain and Haystack are mainly based on Python (even though LangChain also introduced JS/TS support). </span><span class="koboSpan" id="kobo.754.4">You may want </span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.755.1">to choose a framework that matches your </span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.756.1">existing skills or preferences, or that allows you to use the language that is most suitable for your application domain or environment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.757.1">The type and complexity of the natural language tasks you want to perform or support</span></strong><span class="koboSpan" id="kobo.758.1">. </span><span class="koboSpan" id="kobo.758.2">Different frameworks may have different capabilities or features for handling various natural language tasks, such as summarization, generation, translation, reasoning, etc. </span><span class="koboSpan" id="kobo.758.3">For example, LangChain and Haystack provide utilities and components for orchestrating and executing natural language tasks, while Semantic Kernel allows you to use natural language semantic functions to invoke LLMs and services. </span><span class="koboSpan" id="kobo.758.4">You may want to choose a framework that offers the functionality and flexibility you need or want for your application goals or scenarios.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.759.1">The level of customization and control you need or want over the LLMs and their parameters or options</span></strong><span class="koboSpan" id="kobo.760.1">. </span><span class="koboSpan" id="kobo.760.2">Different frameworks may have different ways of accessing, configuring, and fine-tuning the LLMs and their parameters or options, such as model selection, prompt design, inference speed, output format, etc. </span><span class="koboSpan" id="kobo.760.3">For example, Semantic Kernel provides connectors that make it easy to add memories and models to your AI app, while LangChain and Haystack allow you to plug in different components for the DocumentStore, retriever, reader, generator, summarizer, and evaluator. </span><span class="koboSpan" id="kobo.760.4">You may want to choose a framework that gives you the level of customization and control you need or want over the LLMs and their parameters or options.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.761.1">The availability and quality of the documentation, tutorials, examples, and community support for the framework</span></strong><span class="koboSpan" id="kobo.762.1">. </span><span class="koboSpan" id="kobo.762.2">Different frameworks may have different levels of documentation, tutorials, examples, and community support that can help you learn, use, and troubleshoot the framework. </span><span class="koboSpan" id="kobo.762.3">For example, Semantic Kernel has a website with documentation, tutorials, examples, and a Discord community; LangChain has a GitHub repository with documentation, examples, and issues; Haystack has a website with documentation, tutorials, demos, blog posts, and a Slack community. </span><span class="koboSpan" id="kobo.762.4">You may want to choose a framework that has the availability and quality of documentation, tutorials, examples, and community support that can help you get started and solve problems with the framework.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.763.1">Well, there is </span><a id="_idIndexMarker632"/><span class="koboSpan" id="kobo.764.1">no right or wrong answer! </span><span class="koboSpan" id="kobo.764.2">All three orchestrators discussed </span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.765.1">above are extremely valid. </span><span class="koboSpan" id="kobo.765.2">However, some features might be more relevant to specific use cases or developers’ preferences. </span><span class="koboSpan" id="kobo.765.3">Make your choice based on that.</span></p>
<h1 class="heading-1" id="_idParaDest-162"><span class="koboSpan" id="kobo.766.1">Introducing the public cloud: Azure OpenAI</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.767.1">In 2016, OpenAI agreed </span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.768.1">to leverage Microsoft’s Azure cloud infrastructure to run its AI experiments, which led, in 2019, to a $1 billion investment from the tech giant </span><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"><span class="koboSpan" id="kobo.769.1">into Sam Altman’s company (</span><span class="url"><span class="koboSpan" id="kobo.770.1">https://new</span></span></a><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"/><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"/><span class="url"><span class="koboSpan" id="kobo.771.1">upercomputing-technologies/</span></span><span class="koboSpan" id="kobo.772.1">). </span></p>
<p class="normal"><span class="koboSpan" id="kobo.773.1">This marked the beginning of a strategic partnership between the two companies, aiming at developing AI models and technologies that can be used for the benefit of humanity. </span><span class="koboSpan" id="kobo.773.2">This partnership is based on the following three main pillars:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.774.1">Microsoft and OpenAI will jointly build new Azure supercomputing infrastructure to train AI models.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.775.1">OpenAI will make its models and technologies consumable from the Azure cloud.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.776.1">Microsoft will become OpenAI’s preferred partner for commercializing new AI solutions to the market.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.777.1">Since then, the two companies kept investing and researching, and finally, in January 2023, OpenAI models were made available on Microsoft Azure as a managed service: </span><strong class="keyWord"><span class="koboSpan" id="kobo.778.1">Azure OpenAI Service</span></strong><span class="koboSpan" id="kobo.779.1"> (in short, </span><strong class="keyWord"><span class="koboSpan" id="kobo.780.1">AOAI</span></strong><span class="koboSpan" id="kobo.781.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.782.1">With the general availability of the AOAI Service, a new milestone was reached, and the Microsoft AI portfolio has been extended with the powerful LLMs of OpenAI.</span></p>
<h2 class="heading-2" id="_idParaDest-163"><span class="koboSpan" id="kobo.783.1">AOAI Service</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.784.1">The AOAI Service is a product of Microsoft that provides both a playground and APIs to interact and consume </span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.785.1">all of OpenAI’s powerful language models. </span><span class="koboSpan" id="kobo.785.2">It is important to highlight that the models are exactly the same: the only difference is that, if you are consuming them via AOAI, you are leveraging your own Azure subscription and automatically inheriting all the enterprise features that are typical of the Microsoft public cloud, including security, role-based access control, data privacy, and so on.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.786.1">To create your AOAI resource, follow these instructions:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.787.1">Navig</span><a href="https://ms.portal.azure.com/"><span class="koboSpan" id="kobo.788.1">ate to your Azure portal at</span></a> <span class="url"><span class="koboSpan" id="kobo.789.1">https://ms.portal.azure.com</span></span><span class="koboSpan" id="kobo.790.1">.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.791.1">Click on </span><strong class="screenText"><span class="koboSpan" id="kobo.792.1">Create a Resource</span></strong><span class="koboSpan" id="kobo.793.1">.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.794.1">Type </span><em class="italic"><span class="koboSpan" id="kobo.795.1">azure openai</span></em><span class="koboSpan" id="kobo.796.1"> and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.797.1">Create</span></strong><span class="koboSpan" id="kobo.798.1">.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.799.1">Fill in the required information and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.800.1">Review + create</span></strong><span class="koboSpan" id="kobo.801.1">.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.802.1">This is </span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.803.1">shown in the following screenshot:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.804.1"><img alt="" src="../Images/B31559_10_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.805.1">Figure 10.6: Steps to create an AOAI resource</span></p>
<p class="normal"><span class="koboSpan" id="kobo.806.1">This process might take a few minutes. </span><span class="koboSpan" id="kobo.806.2">Once it is ready, you can directly jump to its user-friendly interface, the AOAI Studio, to test your models before deploying them:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.807.1"><img alt="" src="../Images/B31559_10_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.808.1">Figure 10.7: AOAI Studio and chat playground</span></p>
<p class="normal"><span class="koboSpan" id="kobo.809.1">To use AOAI models, you have to initiate a deployment, which is a serverless compute instance you can attach to a model.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.810.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B31559_10_08.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.811.1">Figure 10.8: Creating a new AOAI deployment via the Azure OpenAI portal</span></p>
<p class="normal"><span class="koboSpan" id="kobo.812.1">Lastly, exactly like </span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.813.1">we did for OpenAI models’ APIs in the previous section, from the AOAI Studio, you can consume your deployed models via APIs. </span><span class="koboSpan" id="kobo.813.2">For a quick start, you can navigate to the </span><strong class="screenText"><span class="koboSpan" id="kobo.814.1">Chat playground </span></strong><span class="koboSpan" id="kobo.815.1">and click on the </span><strong class="screenText"><span class="koboSpan" id="kobo.816.1">View Code</span></strong><span class="koboSpan" id="kobo.817.1"> button. </span><span class="koboSpan" id="kobo.817.2">A script will be ready to be copied and pasted into your favorite programming IDE, along with the secret keys needed to access the resource:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.818.1"><img alt="" src="../Images/B31559_10_09.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.819.1">Figure 10.9: Consuming deployed models via APIs</span></p>
<p class="normal"><span class="koboSpan" id="kobo.820.1">By doing so, you can </span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.821.1">seamlessly incorporate your Azure OpenAI’s LLMs within your own application.</span></p>
<h1 class="heading-1" id="_idParaDest-164"><span class="koboSpan" id="kobo.822.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.823.1">At the beginning of this chapter, we had an overview of how GenAI is disrupting industries, from increasing the efficiency of internal processes to enhancing customers’ journeys with personalized experiences. </span><span class="koboSpan" id="kobo.823.2">Many of these applications can be achieved through a high margin of customization, and pre-built, consumer-facing applications like ChatGPT might not be enough.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.824.1">That’s why we introduced OpenAI models’ APIs. </span><span class="koboSpan" id="kobo.824.2">With the models’ APIs, you can leverage the power of the model behind ChatGPT within your own application, tailored to your own industry and scenarios. </span><span class="koboSpan" id="kobo.824.3">Developing AI-powered applications, however, requires a new set of components that have also marked a new paradigm in software development.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.825.1">Finally, we saw how, from 2023, OpenAI models (both in Playground and via APIs) have been made available through Microsoft Azure as a managed service: Azure OpenAI. </span><span class="koboSpan" id="kobo.825.2">This has paved the way for a new wave of adoption from large enterprises that benefit from all the security and governance layers that already exist within the public cloud (which is, by design, enterprise-ready).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.826.1">In the next chapter, we will provide a recap of everything covered in this book, including the latest announcements and releases that have occurred. </span><span class="koboSpan" id="kobo.826.2">We will also focus on reflections and final thoughts about the exponential growth of generative AI technologies in just a few months and what to expect in the near future.</span></p>
<h1 class="heading-1" id="_idParaDest-165"><span class="koboSpan" id="kobo.827.1">References</span></h1>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.828.1">OpenAI Forms Exclusive Computing Partnership with Microsoft to Build New Azure AI Supercomputing Technologies: </span><span class="url"><span class="koboSpan" id="kobo.829.1">https://news.microsoft.com/20</span></span><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"><span class="url"><span class="koboSpan" id="kobo.830.1">19/07/22/openai-forms-exclusive-computing-partnership-with-</span></span></a><a href="https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/"/><span class="url"><span class="koboSpan" id="kobo.831.1">-ai-supercomputing-technologies/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.832.1">General Availability of Azure OpenAI Service Expands Access to Large, Advanced AI Models with Added Enterprise Benefits: </span><span class="url"><span class="koboSpan" id="kobo.833.1">https://azure.microsoft.com/</span></span><a href="https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/"><span class="url"><span class="koboSpan" id="kobo.834.1">en-us/blog/general-availability-of-azure-openai-service-expa</span></span></a><a href="https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/"/><span class="url"><span class="koboSpan" id="kobo.835.1">-with-added-enterprise-benefits/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.836.1">Microsoft CEO Satya Nadella: Humans and A.I. </span><span class="koboSpan" id="kobo.836.2">Can Work Together to Solve Society’s Challenges: </span><span class="url"><span class="koboSpan" id="kobo.837.1">https://slate.com/technology/2016/06/microsoft-ceo-satya-nadella-humans-and-a-i-can-work-together-to-solve-societys-challenges.html</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.838.1">Microsoft Calls for Government Regulation of Facial Recognition Technology: </span><span class="url"><span class="koboSpan" id="kobo.839.1">https://www.geekwire.com/</span></span><a href="https://www.geekwire.com/2018/microsoft-calls-government-regulation-facial-recognition-technology/"><span class="url"><span class="koboSpan" id="kobo.840.1">2018/microsoft-calls-government-regulatio</span></span></a><span class="url"><span class="koboSpan" id="kobo.841.1">n-facial-recognition-technology/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.842.1">Six Principles to Guide Micros</span><a href="https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/"><span class="koboSpan" id="kobo.843.1">oft’s Facial Recognition Work: </span><span class="url"><span class="koboSpan" id="kobo.844.1">https://blogs.microso</span></span></a><a href="https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/"/><span class="url"><span class="koboSpan" id="kobo.845.1">rosofts-facial-recognition-work/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.846.1">Responsible AI Principles and Approach: </span><span class="url"><span class="koboSpan" id="kobo.847.1">https://www.microsoft.com/en-us/ai/principles-and-approach</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.848.1">Mic</span><a href="https://responsibleaitoolbox.ai/"><span class="koboSpan" id="kobo.849.1">rosoft Responsible AI Toolbox: </span></a><span class="url"><span class="koboSpan" id="kobo.850.1">https://responsibleaitoolbox.ai/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.851.1">Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention: </span><span class="url"><span class="koboSpan" id="kobo.852.1">https://www.microsoft.com/e</span></span><a href="https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/"><span class="url"><span class="koboSpan" id="kobo.853.1">n-us/research/publication/human-parity-on-commonsenseqa-augmenti</span></span></a><a href="https://www.microsoft.com/en-us/research/publication/human-parity-on-commonsenseqa-augmenting-self-attention-with-external-attention/"/><span class="url"><span class="koboSpan" id="kobo.854.1">tention-with-external-attention/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.855.1">Customize a Model with Azure OpenAI Service: </span><span class="url"><span class="koboSpan" id="kobo.856.1">https://learn.microsoft.com/en-gb/</span></span><a href="https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio&amp;openai-cli-data-preparation-tool"><span class="url"><span class="koboSpan" id="kobo.857.1">azure/cognitive-services/openai/how-to/fine-tuning?pivots=pro</span></span></a><a href="https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/fine-tuning?pivots=programming-language-studio&amp;openai-cli-data-preparation-tool"/><span class="url"><span class="koboSpan" id="kobo.858.1">openai-cli-data-preparation-tool</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.859.1">Moody’s and Microsoft Develop Enhanced Risk, Data, Analytics, Research and Collaboration Solut</span><a href="https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Powered-by-Generative-AI/default.aspx"><span class="koboSpan" id="kobo.860.1">ions Powered by Generative AI: </span><span class="url"><span class="koboSpan" id="kobo.861.1">https://ir.moodys.com/press-releases/news-details/2023/Moodys-and-Microsoft-Develop-Enhanced-Risk-Data-Analytics-Research-and-Collaboration-Solutions-Power</span></span></a><span class="url"><span class="koboSpan" id="kobo.862.1">ed-by-Generative-AI/default.aspx</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.863.1">Increasing Accu</span><a href="https://openai.com/index/summer-health/"><span class="koboSpan" id="kobo.864.1">racy of Pediatric Visit Notes: </span><span class="url"><span class="koboSpan" id="kobo.865.1">https:/</span></span></a><span class="url"><span class="koboSpan" id="kobo.866.1">/openai.com/index/summer-health/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.867.1">Coca-Cola Invites Digital Artists to ‘Create Real</span><a href="https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform"><span class="koboSpan" id="kobo.868.1"> Magic’ Using New AI Platform: </span><span class="url"><span class="koboSpan" id="kobo.869.1">https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-</span></span></a><span class="url"><span class="koboSpan" id="kobo.870.1">real-magic-using-new-ai-platform</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.871.1">IVECO Group Uses Azure OpenAI Servi</span><a href="https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-openai-service-manufacturing-italy"><span class="koboSpan" id="kobo.872.1">ce to Transform Manufacturing: </span><span class="url"><span class="koboSpan" id="kobo.873.1">https://customers.microsoft.com/en-us/story/1706380538888475836-iveco-group-azure-op</span></span></a><span class="url"><span class="koboSpan" id="kobo.874.1">enai-service-manufacturing-italy</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.875.1">Ir</span><a href="https://openai.com/index/ironclad/"><span class="koboSpan" id="kobo.876.1">onclad and OpenAI Partnership: </span><span class="url"><span class="koboSpan" id="kobo.877.1">ht</span></span></a><span class="url"><span class="koboSpan" id="kobo.878.1">tps://openai.com/index/ironclad/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.879.1">Inworl</span><a href="https://openai.com/index/inworld-ai/"><span class="koboSpan" id="kobo.880.1">d AI and OpenAI Collaboration: </span><span class="url"><span class="koboSpan" id="kobo.881.1">http</span></span></a><span class="url"><span class="koboSpan" id="kobo.882.1">s://openai.com/index/inworld-ai/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.883.1">Khan Academy and OpenAI Partnership: </span><span class="url"><span class="koboSpan" id="kobo.884.1">https://openai.com/index/khan-academy/</span></span></li>
</ul>
<h1 class="heading-1"><span class="koboSpan" id="kobo.885.1">Join our communities on Discord and Reddit</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.886.1">Have questions about the book or want to contribute to discussions on Generative AI and LLMs? </span><span class="koboSpan" id="kobo.886.2">Join our Discord server at </span><a href="Chapter_10.xhtml"><span class="url"><span class="koboSpan" id="kobo.887.1">https://packt.link/I1tSU</span></span></a><span class="koboSpan" id="kobo.888.1"> and our Reddit channel at </span><a href="Chapter_10.xhtml"><span class="url"><span class="koboSpan" id="kobo.889.1">https://packt.link/jwAmA</span></span></a><span class="koboSpan" id="kobo.890.1"> to connect, share, and collaborate with like-minded enthusiasts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.891.1"><img alt="" src="../Images/Discord.png"/></span> <span class="koboSpan" id="kobo.892.1"><img alt="" src="../Images/QR_Code757615820155951000.png"/></span></p>
</div>
</body></html>