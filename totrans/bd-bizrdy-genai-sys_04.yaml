- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building the AI Controller Orchestration Interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Businesses today need to design, produce, and deliver goods and services at
    a speed never attained before. Responsiveness has become key in nearly every field,
    from online cloud services to delivering food, medication, clothing, and so on.
    Such an event-driven economy produces an endless stream of tasks, and only an
    equally event-driven, human-centered **generative AI system** (**GenAISys**) can
    keep pace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Human judgment still anchors even the most automated workflows: when fires
    break out, storms destroy infrastructure, or supply chains falter, teams—not algorithms
    alone—must act. An advanced GenAISys that leaves people out of the loop is a myth.
    This chapter, therefore, begins by outlining an architecture that tears down the
    walls between users and AI to create a collaborative, multi-user chatbot.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we sketch the event-driven GenAISys interface at a high level, showing
    how the building blocks from earlier chapters—short-term, episodic, and long-term
    memory, the multi-turn conversational agent, and twin RAG pipelines for instruction
    scenarios and data—fit together. To then implement the responsive system, we must
    code the processes of the GenAISys and then the conversational agent that will
    manage the generative AI agent. Once our GenAISys interface is built, we will
    run a multi-user, multi-turn conversation with three users working in an online
    travel agency. Their online meeting will include a conversational AI agent as
    a participant.
  prefs: []
  type: TYPE_NORMAL
- en: These users will be able to have an online meeting with or without the AI agent.
    They will be able to utilize RAG to find instruction scenarios or simply ask the
    generative AI agent to answer a question. By the end of the chapter, we will have
    a fully working GenAISys interface ready for the multimodal chain-of-thought extensions
    in [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140).
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, this chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: A high-level view of the architecture of an event-driven GenAISys interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A low-level, hands-on flowchart of the GenAISys interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing response widgets for inputs, the AI agent, and active users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chatbot’s event-driven flow in a multi-turn conversation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-user GenAISys conversation with an AI agent as a participant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The response RAG features of the conversational agent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The orchestration capabilities of the GenAISys interface and AI agent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our first task is to define an event-driven GenAISys interface.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of an event-driven GenAISys interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our event-driven GenAISys interface integrates the functionality we built in
    the previous chapters. The interface will leverage the flexibility of IPython
    widgets to create a reactive event-driven environment in which the following apply:'
  prefs: []
  type: TYPE_NORMAL
- en: The high-level tasks will be event-driven, triggered by user inputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI tasks will trigger generative AI agent functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will first examine the program we are building at a high level, as represented
    in *Figure 4.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1: High-level architecture of the GenAISys interface](img/B32304_04_1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: High-level architecture of the GenAISys interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go through the functions we have already built in the previous chapters
    and also list the key ones we are adding in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**I1 – AI controller**: This chapter’s main new component is the generative
    AI Python interface with responsive widgets, which will be run as an AI controller
    and orchestrator'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I2 – Multi-user chatbot**: The chat surface through which several users interact
    concurrently'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F1 – Generative AI model**: Inherited from all the previous chapters, especially
    [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085), in which we ran generative AI
    calls with GPT-4o'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F2 – Memory retention**: Inherited from [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021),
    which introduced different types of memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F3 – Modular RAG**: The instruction-and-data pipelines inherited from [*Chapter
    3*](Chapter_3.xhtml#_idTextAnchor085)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F4 – Multifunctional capabilities**: Semantic and sentiment analysis from
    *Chapters* *2* and *3*, to be expanded in [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140)
    with image, audio, web search, and ML features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To build this architecture, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Build the processes of an event-driven GenAISys interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement the conversational agent with GPT-4o and an OpenAI embedding model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run a multi-user, multi-turn session exploring the main features of the GenAISys
    AI controller and orchestrator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The decision to present the main components of the GenAISys architecture (in
    this chapter and the next) without arrows is a deliberate choice designed to convey
    a core concept: modularity and architectural flexibility. The figure is not a
    rigid blueprint but rather a conceptual toolkit. It shows you the powerful components
    at your disposal—**I1\. AI controller**, **I2\. Multi-user chatbot**, **F1\. Generative
    AI model**, **F2\. Memory retention**, **F3\. Modular RAG**, and **F4\. Multifunctional
    capabilities**—as independent, interoperable blocks. This empowers you, illustrating
    that you are free to design your own system architecture. For instance, a user
    could choose to run some functional components, such as **F4\. Multifunctional
    capabilities**, as independent, distributed agents that are called upon by the
    controller. Alternatively, they could implement a completely different interface
    or even run the system headlessly without one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the focus of this architecture is on demonstrating a human-centered
    GenAISys. In this configuration, **I1\. AI controller** (the generative AI IPython
    interface) serves as the central hub and orchestrator. This human-centered architecture
    guarantees full control and transparency. This is essential to build trust in
    risk-averse corporate environments. The control flow, while not drawn with arrows,
    is implicit: user interactions from **I2\. Multi-user chatbot** are managed by
    the AI controller, which then strategically delegates tasks to the various functional
    components (**F1** to **F4**) to generate responses, access memory, perform RAG,
    or execute specific functions. This approach provides a clear, stable, and explainable
    pathway to building a business-ready generative AI system.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first explore scenario-driven task execution.
  prefs: []
  type: TYPE_NORMAL
- en: Building the processes of an event-driven GenAISys interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s begin by building the GenAISys interface shown in *Figure 4.2*, using
    IPython widgets to create a responsive, event-driven environment. The result will
    be a dynamic multi-user chat surface with drop-down menus, text-input fields,
    and a checkbox—everything needed for real-time collaboration between people/users
    and the generative AI agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `Event-driven_GenAISys_framework.ipynb` notebook within the Chapter04
    directory on GitHub ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    Setting up the environment is the same as described in the previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up OpenAI, refer to [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021),
    including the custom OpenAI API call used here: `openai_api.make_openai_api_call`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085) for setting up Pinecone,
    connecting to the index, and querying it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An additional package (`ipython`) is required for the notebook environment.
    IPython is pre-installed in Google Colab; if needed, install it using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The code we’ll build demonstrates core concepts such as event-driven interactions,
    dynamic content updating, and modular function organization. By the end of this
    section, you will have learned how to bridge the gap between AI functionality
    and end user engagement.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2: The flowchart of an event-driven GenAISys interface](img/B32304_04_2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: The flowchart of an event-driven GenAISys interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main groups of functions required to build this interface are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Initializing widgets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling user input and selection changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing chat messages, including triggering functions and exit commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating and processing AI responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating the UI dynamically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving the conversation history
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before diving into the code from a developer’s perspective, let’s keep the user’s
    point of view in mind. We must build an intuitive interface that can seamlessly
    execute the flow outlined in *Figure 4.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3: GenAISys from a user’s perspective](img/B32304_04_3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: GenAISys from a user’s perspective'
  prefs: []
  type: TYPE_NORMAL
- en: '![A magnifying glass on a black background  AI-generated content may be incorrect.](img/1.png)**Quick
    tip**: Need to see a high-resolution version of this image? Open this book in
    the next-gen Packt Reader or view it in the PDF/ePub copy.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2.png)**The next-gen Packt Reader** is included for free with the purchase
    of this book. Scan the QR code OR go to [packtpub.com/unlock](http://packtpub.com/unlock),
    then use the search bar to find this book by name. Double-check the edition shown
    to make sure you get the right one.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A qr code on a white background  AI-generated content may be incorrect.](img/Unlock_Code1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The UI contains only three widgets: an input box for entering prompts, a drop-down
    list for selecting active users, and a checkbox for activating and deactivating
    the conversational AI agent.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through the process of setting up and running this interactive GenAISys
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Start
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The program starts from the *Multi-user conversation with the agent as a participant*
    cell. We first import the modules and libraries we need, starting with `IPython`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s go through each functionality we will be implementing in Google Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: '`display` and `HTML` to display objects such as widgets, images, and rich HTML
    outputs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clear_output` to clear the output of a cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we import `ipywidgets` managed by the Jupyter project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`ipywidgets` is the core component of the interactive interface in this notebook,
    in which we will use the following widgets:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Dropdown`: A drop-down widget to select a value from a list of options'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Text`: A widget for text input from a user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Checkbox`: A widget for Boolean checked/unchecked input'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Vbox`: A container widget to arrange child widgets in a vertical box layout'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Layout`: To customize the style of the widgets with layout properties such
    as width, height, and margin'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we import JSON, used to store multi-user conversation histories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We then initialize the conversation histories for all users, define the first
    active user, and set the active conversation to `True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We are thus, from the start, initializing a multi-user collaborative GenAISys
    in which the users can be human prompts and system prompts. For example, a “user”
    could be a message from another system and triggered in this interface by an event
    that reads pending messages. The user list can be expanded, stored in variables,
    or utilized in any user management system that suits a project’s needs, including
    access rights, passwords, and roles for various applications. Next, we initialize
    the widgets themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Initialize widgets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code now sets up the `Dropdown`, `Text`, and `Checkbox` widgets we need.
    The widgets are also linked to event handlers. The `Dropdown` widget for the users
    defines the three users initialized at the start of the conversation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The selector has four parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`options` lists the available users that can be expanded and can access any
    user management repository as needed for your project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value` determines the active user. The program started with `User01` as the
    initial user. This can be automated when an authorized user first connects to
    the GenAISys.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`description` provides a label for the drop-down list that will be displayed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`layout` sets the width of the widget that will be displayed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that we are creating a core GenAISys, not a platform. The goal is to grasp
    the inner workings of a GenAISys. Once it works as expected, we can then add the
    classical layers of user management (names, roles, and rights). In this case,
    we are remaining focused on the flexible core concepts of GenAISys, not how they
    will be encapsulated in a specific platform and framework. We are learning how
    to be generative AI agentic architects, not operators of a specific framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to insert an event handler. In this case, it is an event listener
    that will detect when the value of `user_selector` changes. When another user
    is selected, the `on_user_change` function is automatically called, and `value`
    becomes the new user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This dynamic change in users within a GenAISys conversation represents a major
    evolution from the one-on-one chatbots. It introduces a whole new dimension to
    collaborative teamwork with AI as a co-participant.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second widget to activate is the input widget:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The input can be any text and will occupy 100% of the UI layout. The conversation
    ends when a user enters `exit` or `quit`. When the text is typed and the *Enter*
    button is pressed, the event handler takes over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`on_submit` is a method of the `input_box` widget. `handle_submit` is a callback
    function that we can write as we wish and will be described later in this section.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The third widget is the checkbox for the AI conversational agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The checkbox displays the description label, which is an agent in this case.
    The layout will occupy 20% of the UI. If `value` is set to `True`, then the conversational
    AI agent will be activated. We will build the AI agent in the *Conversational
    agent* section of this chapter. The AI agent will also be event-driven.
  prefs: []
  type: TYPE_NORMAL
- en: The UI box is now ready to be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Display the UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The UI container widget now combines the three event-driven widgets we defined
    in `VBox` (`V` stands for vertical; i.e., in a vertical box). The three widgets
    are in brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The layout is then defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameters of this responsive UI are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`display=''flex''` activates the CSS flexbox model for layouts dynamically
    without specifying the sizes of the items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flex_flow=''column''` arranges the child widgets vertically'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`align_items=''flex-start''` aligns the widgets to the start (left side) of
    the UI (left side) container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width=''100%''` makes the container take up the full width of the available
    space'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, the UI is ready. We can choose to begin with any of the three widgets.
    The user selector can be run before the input, as well as the AI agent checkbox.
    In this case, the user selector was set to a default value, `User01`, and the
    AI agent checkbox was set to the default value, `True`.
  prefs: []
  type: TYPE_NORMAL
- en: The three widgets and their processes can be built into any classical web or
    software interface, depending on your project’s needs. Since there is no default
    value for the input, let’s continue with the input widget.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Input box event
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The input text is managed by the UI described in the previous section, which
    triggers `input_box.on_submit(handle_submit)` when a user enters text. In turn,
    the `submit` method calls the `handle_submit` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the function does three things:'
  prefs: []
  type: TYPE_NORMAL
- en: '`user_message = sender.value` processes the text received from the input widget'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`if user_message.strip()` checks whether there is a message and clears the
    input box for the next input with `sender.value = "" # Clear the input box`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chat(user_message)` is called if there is a message'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chat(user_message)` is the next process and a key event processing hub for
    the GenAISys. Let’s go through it.'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. chat(user_message) function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `chat(user_message)` function is an *orchestrator* component of our event-driven
    GenAISys. It should remain human-centered for critical human control. Once the
    system has gained the trust of the users and after careful consideration, some
    of the actions it manages can be triggered by system messages. The orchestrator
    contains important decisions when it processes the user message it receives from
    the `handle_submit(sender)` function. It encapsulates several choices and functions,
    as represented in *Figure 4.2*: deciding whether to continue the conversation,
    appending or saving the conversation history to a file, determining whether to
    call the AI conversational agent, and updating the UI display.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It first inherits the global status of the conversation variable (`conversation_active
    = True`) we initialized at the start of the conversation (in node **1** of *Figure
    4.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'It continues to determine whether the multiple-turn conversation is over or
    not by checking whether the user has exited or quit the conversation (see **6**
    in *Figure 4.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see what happens if the user chooses to exit the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. If ‘exit’ is chosen
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose the user enters `exit` or `quit`; then the `conversation_active` variable
    we set to `True` at the start of the conversation (in node **1** of *Figure 4.2*)
    will now be set to `False`. The system now knows that there is no need to update
    the display anymore. It then tells the `clear_output` function to wait until the
    next conversation turn to clear the output to avoid flickering effects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The exit process continues by displaying a message signaling the end of the
    conversation and indicating that the conversation history is being saved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The exit process ends by calling the *save* function of the conversation, which
    will save all history to a file (see node **7** in *Figure 4.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The conversation is thus saved at the end of the session for further use (for
    a new session or a meeting summary), as shown in node **7** of *Figure 4.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s go through the process when the user(s) chooses to continue the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. If user(s) continue the conversation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the user input does not contain `exit` or `quit`, then the multi-turn, multi-user
    conversation will continue. We have some big decisions to make with this function,
    however. Do we append it to each user request or not? If we append it to each
    user request, at some point, the context window will be complete, but the number
    of tokens we send through the API will increase processing time and costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to append the history of the conversation we initialized
    at the start (in node **1** of *Figure 4.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: So, in the hybrid scenario of this notebook, at this point, we will save the
    user history in memory until the end of the session, and we will thus augment
    each user’s input with their input history, as seen in node **11** of *Figure
    4.2*. If the user input does not contain `exit` or `quit`, then the multi-turn,
    multi-user conversation will continue. It will append the user message to the
    history (in node **8** of *Figure 4.2*) of the user.
  prefs: []
  type: TYPE_NORMAL
- en: However, if we don’t want to append a user request to it but still want to keep
    a record of the entire conversation for context, we can also summarize the conversation
    at the midpoint or the end. If we summarize it during the conversation, we can
    add a function to append it to the user input each time. If we summarize after
    the end of a session, we can continue with a new, fresh session with a summary
    of the previous session’s history.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this notebook, we will implement a hybrid short- and long-term memory process.
    We can continue the conversation by not entering `''quit''` or `''exit''`. Now,
    the `chat(user_message)` function will check the conversational agent’s checkbox
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This verification is shown in node **9** in *Figure 4.2*. If the checkbox is
    checked, then the functions we created in the previous chapters are activated
    by calling `chat_with_gpt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the response is returned, it is appended to the history of the response
    described previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We now have an entry-point memory framework. The program then calls `update_display()`,
    another key function that is shown in node **14** of *Figure 4.2*. If the agent
    checkbox is checked, `chat_with_gpt` will be called.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Generate bot response
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `chat_with_gpt` function assembles the work we did in the previous chapters
    to create a conversational AI agent with the Pinecone-based RAG functionality.
    We will fully implement this integration in the *Conversational agent* section
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '`chat_with_gpt` orchestrates the AI conversational agent by providing information,
    enabling it to be dynamic and responsive. The user history of this conversation
    and the user message are sent to the `chat_with_gpt` conversational agent function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Once the response is returned, the `update_display` function is called from
    `chat(user_message)`.
  prefs: []
  type: TYPE_NORMAL
- en: 9\. Update display
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `update_display` function refreshes the UI with the updated conversation
    history and also displays the status of the widgets. It first tells the UI to
    wait until a new output arrives by setting `wait` to `True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The function then filters and displays the active user’s history (see node
    **15** of *Figure 4.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If the conversation is active, the UI `VBox` is displayed along with the status
    of the widgets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The input box is cleared, the agent checkbox has been checked independently
    by the user, and the system has verified its status. The active user will be displayed
    based on the independent decision of the user. In this case, the active user,
    `active_user`, who was initialized at the start (**1**) of the conversation, remains
    the same. If the user changed, the `on_user_change` drop-down event(**13**) would
    have been triggered by the `observe` method of the `user_selector` widget:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In that case, `user_selector.observe` will independently call the `update active_user`
    function (**14**) and first make sure that the active user is a global variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, it will make the new user the active user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, it will call the `update_display` function we built in this subsection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our dynamic UI and event-driven functions in place, let’s implement
    the conversational agent logic called by `chat_with_gpt`.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We implemented an AI conversational agent in *Chapters 1* and *2* and built
    the query Pinecone functionality in [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085).
    Go to the *Conversational agent* section of the notebook. If needed, take the
    time to revisit those chapters before proceeding. In this section, it’s time we
    integrate those components, preparing our GenAISys conversational agent for multi-user
    sessions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by importing OpenAI and initializing the client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we make a decision to store or not to store all of the user’s conversation
    history for each call to optimize context window size for cost and clarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The memory setting should be strategically monitored in production environments.
    For example, here we set `user_memory` to `True`, but we avoid applying it during
    RAG queries, as historical context could confuse the Pinecone similarity searches.
    We then define the `chat_with_gpt` function, which is called in node **10** of
    *Figure 4.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The function first searches the input text for a keyword to trigger a RAG retrieval
    from the Pinecone index as implemented in `Query_Pinecone.ipynb` and described
    in [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085). The code first determines
    the namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'If the user message contains “Pinecone,” the query will target the `genaisys`
    namespace, which contains the instruction scenarios. The `genaisys` namespace
    implementation departs from static data retrieval and takes us into agentic, dynamic
    decision-making to trigger an instruction or a task. If the user message contains
    “RAG,” the query will target the `data01` namespace, which contains static data.
    The queries and content of the Pinecone index are those implemented in [*Chapter
    3*](Chapter_3.xhtml#_idTextAnchor085):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the query result is returned, we append the user message to it to augment
    the input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The message parameters and the OpenAI API call are described in the *Setting
    up the environment* section of [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021).
    The OpenAI response is stored in `task response`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The response returned by the OpenAI API call, augmented with the result of
    the Pinecone query, is stored in `aug_output`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If the user message does not contain a keyword to trigger the RAG function,
    the user request will be sent directly to the OpenAI API call, and the response
    will be stored in `aug_output`. However, the system must first check whether `user_memory`
    is `True` or not. The system must also extract the text content of `user_message`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `umessage` now contains a concatenation of the conversation history
    of the active user extracted and stored in `combined_user_messages` and the user
    message itself in `user_message`. The generative AI model now has complete context
    about the dialogue with this user.
  prefs: []
  type: TYPE_NORMAL
- en: The strategy for managing conversation history will depend heavily on each real-world
    use case. For example, we might choose to extract the history of all users involved
    in a session or only specific users. Alternatively, a team could decide to use
    a single shared username throughout an entire conversation. Generally, the best
    practice is to organize workshops with end users to define and configure the conversation-memory
    strategies that best fit their workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, we might decide to ignore the conversation history altogether.
    In that scenario, we set the `user_memory` parameter to `False`, and the system
    disregards prior exchanges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `umessage` variable is now ready to be sent directly to the generative
    AI model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The response from the OpenAI API call is then returned to the `chat_with_gpt`
    function (in node **10** of *Figure 4.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'If the OpenAI API call fails, an exception is raised and returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: And with that, we have assembled the generative AI functionalities developed
    across the previous three chapters. At this stage, we’ve built a responsive GenAISys
    interface and integrated a generative agent, together forming a cohesive AI controller
    and orchestrator. Let’s now put our GenAISys into motion.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-user, multi-turn GenAISys session
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now have a responsive, event-driven GenAISys capable of executing multiple
    tasks in diverse ways, as illustrated in *Figure 4.4*. We will explore the flexibility
    of this GenAISys interface we built using IPython and assemble the OpenAI and
    Pinecone components from previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4: Summing up the components we have built and assembled in this
    chapter](img/B32304_04_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4: Summing up the components we have built and assembled in this chapter'
  prefs: []
  type: TYPE_NORMAL
- en: Since the functions within GenAISys are event-driven, a user (human or system)
    or a group of users can leverage this framework to address multiple cross-domain
    tasks. The system is human-centric, creating a collaborative, frictionless environment
    between humans and a generative AI agent. Importantly, there is no competition
    between humans and AI in this framework. Teams can maintain human social relationships
    with co-workers while using the GenAISys to boost their performance and productivity
    exponentially. This human-centric approach is one I have always advocated throughout
    my decades of experience providing AI-driven automation solutions for global corporations,
    mid-sized businesses, and smaller organizations. When teams adopt AI as a collaborative
    tool rather than a competitor, it fosters a positive atmosphere that leads to
    quick wins—demonstrating the combined effectiveness of teamwork and technology.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we look deeper into how the GenAISys framework can be leveraged in teamwork
    scenarios, we can establish several fundamental sequences of events typically
    needed in real-world projects:'
  prefs: []
  type: TYPE_NORMAL
- en: User selection => Input => Agent checked => RAG instruction => GenAI agent =>
    Output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: User selection => Input => Agent checked => RAG data => GenAI agent => Output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: User selection => Input => Agent checked => User history => GenAI agent => Output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: User selection => Input => Agent checked => No user history => GenAI agent =>
    Output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: User selection => Input => Agent unchecked => Output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These basic sequences constitute a set of sequences, **S**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B32304_Equation.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To achieve a goal for a single user or a group of users, the sequences can
    be assembled as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '{a, b}: Running a sentiment analysis with RAG, followed by the retrieval of
    an episodic memory of a past meeting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '{d, e}: Running an OpenAI API request and then making a comment for other users.
    The novelty in this case is that the AI agent remains a co-worker in a team and
    sometimes doesn’t express itself, allowing the team to ponder the ideas it suggested.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These sequences can be arranged into longer session flows as required by the
    specific tasks and scenarios. Because sequences can repeat themselves, we have
    an indefinite number of possible dynamic combinations. For instance, here’s a
    glimpse into the flexibility that this provides:'
  prefs: []
  type: TYPE_NORMAL
- en: Set of three members, such as {a, c, e}, {b, d, e}, {a, b, c}
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set of four members, such as {a, b, c, d}, {b, c, d, e}, {a, c, d, e}
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set of five members, such as {a, b, c, d, e}
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could add exiting the session and summarizing to these sequences, as well
    as reloading a saved file and continuing the session. There can also be a repetition
    of sets, sets with different users, and sets with more functions. In the following
    chapters, we will add new features, including image generation, audio, web search,
    and ML, that will expand the scope of the GenAISys framework we have built.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, however, we will run a session with two users in a simple sequence
    of events. Then, we will run a scenario with multiple users and some basic sequences.
    Let’s begin with a straightforward sequence of events.
  prefs: []
  type: TYPE_NORMAL
- en: A session with two users
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example session, two users collaborate to brainstorm ideas for attractive
    travel destinations they could recommend to customers on their online travel website.
    We start by running an interface session, then display the conversation history,
    and finally summarize the discussion. To begin the session, open `Event-driven_GenAISys_framework.ipynb`
    and run these sections of cells:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting up the environment**: Run all cells'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conversational agent**: Run the single cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Running the interface in the GenAISys IPython interface**: This will initialize
    the conversation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the stochastic nature of generative AI models, the outputs might vary
    slightly with each execution. Likewise, minor differences may appear between this
    notebook and the printed chapter, as multiple runs are performed during quality
    control.
  prefs: []
  type: TYPE_NORMAL
- en: With the conversation initialized, let’s now run the interactive session.
  prefs: []
  type: TYPE_NORMAL
- en: The interactive conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The conversation starts with `User01` by default, displaying the input box and
    the activated agent checkbox. The sequence of events and functions triggered in
    this scenario is illustrated in *Figure 4.5*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5: The GenAI agent performs a task with the user’s history](img/B32304_04_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.5: The GenAI agent performs a task with the user’s history'
  prefs: []
  type: TYPE_NORMAL
- en: 'The flow follows this sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: User selection => Input => Agent checked => User history => GenAI agent => Output
  prefs: []
  type: TYPE_NORMAL
- en: To the user, this process is seamless, as illustrated in *Figure 4.6*. However,
    the underlying functions required careful design and development to produce this
    smooth effect.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6: UI with the GenAI agent checked](img/B32304_04_6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.6: UI with the GenAI agent checked'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the user’s perspective, the process is straightforward. `User01` types
    a prompt into the input box: `What is the capital of France?`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7: User entering a simple prompt](img/B32304_04_7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: User entering a simple prompt'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output will be displayed above the input widget, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8: Output is displayed above the input box](img/B32304_04_8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.8: Output is displayed above the input box'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, even an untrained user can intuitively run the GenAISys with
    the basic information provided in a one-page document. `User01` continues with
    a follow-up question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the user history option is set to `True` in the conversational agent,
    the agent knows that the question is about Paris and provides information on some
    iconic locations to visit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '`User02` now enters the dialogue by selecting **User02** in the drop-down menu,
    as shown in *Figure 4.9*. **User02** then asks what the capital of Spain is, the
    agent responds, and the output is displayed above the input box.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9: Input: Another user can enter the conversation](img/B32304_04_9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.9: Input: Another user can enter the conversation'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, the GenAISys core framework is set, and we will progressively
    enhance it in subsequent chapters by addressing features such as security, user
    access controls, and data privacy. `User02` goes further and asks about the places
    worth visiting. The agent responds correctly because the user history option is
    activated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Now, a key feature comes into play. `User02` deactivates the AI agent, as shown
    in *Figure 4.10*, and directly addresses `User01`, similar to an interaction on
    social media or remote collaboration platforms.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10: Direct communication in a team without an AI agent](img/B32304_04_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.10: Direct communication in a team without an AI agent'
  prefs: []
  type: TYPE_NORMAL
- en: '`User01` responds informally: “Yes, that’s a good idea, but let’s think it
    over.” Subsequently, `User01` ends the session by typing `exit`. This capability,
    as illustrated in *Figure 4.11*, takes our GenAISys to a new level for the use
    cases we will explore in this book, such as the following configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: A user can communicate with GenAISys alone in a one-to-one conversation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A team can work together, enhancing their performance with the AI agent as a
    collaborator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The users can be AI agents playing the role of managers from different locations
    when the human managers are not available
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The users can be systems providing information in real-time to human users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.11: A team communicates directly and then ends the session](img/B32304_04_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.11: A team communicates directly and then ends the session'
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon exiting, the session ends, and the conversation history is saved to the
    `conversation_history.json` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12: Saving and concluding the conversation](img/B32304_04_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.12: Saving and concluding the conversation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like all other features in this framework, the exit behavior can be customized
    for individual projects. Take the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: The conversation history can be saved or not
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only parts of the conversation history can be saved
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The name of the saved conversation history file can contain a timestamp
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going `"…to the next cell"` is optional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are decisions to make for each use case. They will not modify the overall
    framework of the GenAISys but allow for a high level of customization.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the team wants to display the conversation they just had.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and displaying the conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The code for this function is a standard IPython display function to convert
    the JSON file, `conversation_history.json`, into Markdown format. Let’s first
    check whether the conversation history parameter and/or the summary parameter
    is activated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the conversation history and the summary function are both activated.
    Now, we will check whether a conversation history file is present or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'If a file exists, `display_conversation_history` will be set to `True` and
    `summary=True` (even if it was set to `False` previously). A message will signal
    that the file exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'If `display_conversation_history==True`, then the conversation will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is nicely formatted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The team has displayed the conversation but wants to take the process further
    and summarize this online meeting that included an AI agent as a participant.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and summarizing the conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The conversation we are summarizing shows how to merge an AI agent into an existing
    human team to boost productivity. In some cases, the GenAISys will have worked
    on automated tasks alone. In other cases, the GenAISys will be the copilot of
    one or several users. In others, in the many critical moments of the life of an
    organization, teams of humans and AI agents will be able to work together to make
    decisions.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will ask the AI agent to summarize the conversation. We
    will integrate this feature as a function in the GenAISys in the following chapters.
    For the moment, we will run it separately after displaying the conversation, as
    shown in *Figure 4.13*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.13: Displaying and summarizing a conversation](img/B32304_04_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.13: Displaying and summarizing a conversation'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code first loads the `conversation_history.json` file as in the display
    function. Then, we define a function that converts the conversation history content
    into an optimal format for the OpenAI API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The function to construct the full conversation history is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we prepare the complete message for the custom GenAISys API call built
    for the system and imported in the *OpenAI* subsection of the *Setting the environment*
    section in our notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we call the GenAISys OpenAI function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The API response code will be displayed in Markdown format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, everything is ready. We can call the summarizing function if `summary==True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that in Google Colab, `/content/` is the default directory. So, the following
    file paths point to the same directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: In another environment, you may need absolute paths.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is a summary of the conversation history that contains an introduction
    and then a detailed summary. The prompt for this summary can be modified to request
    shorter or longer lengths. We can also design a prompt asking the generative AI
    model to target part of the conversation or design any other specific prompt for
    a given project. In this case, the output is satisfactory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: By running through the many possible sequences of tasks and events, we have
    seen the flexibility that the GenAISys offers us. Let’s run a more complex multi-user
    session.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-user session
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will run a technical session that activates the main functions
    we have built in the previous chapters and this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic and sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RAG for episodic memory retrieval
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dialogue without an AI conversational agent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading, displaying, and summarizing the conversation history
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you haven’t interrupted the previous session, then simply run the *Running
    the interface section in the GenAISys IPython interface* cell again in our notebook,
    which will start a new conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are starting from scratch, then to start the session, open `Event-driven_GenAISys_framework.ipynb`
    and run the following sections of cells:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up the environment: All the cells'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conversational agent: Contains one cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Running the interface in the GenAISys IPython interface: Will start the conversation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are ready to explore some advanced features of the GenAISys. We will highlight
    the events and functions that are activated by each prompt. The first sequence
    in the session is semantic and sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic and sentiment analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To perform semantic and sentiment analysis, we will need to run the following
    sequence orchestrated by the GenAISys as shown in *Figure 4.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. User selection** is not activated because `User01` is the default user
    at the beginning of a session. We could call this user the “host” if we wish,
    depending on the use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`User01` enters an input at **2\. Input**triggering **3\. Agent checked**,
    which is checked as the default value when the session starts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AI conversational AI controller takes over, parses the prompt, finds the
    `Pinecone` keyword in the prompt, triggers a Pinecone query in the instruction
    scenario namespace, augments the prompt, and triggers **4\. GenAI agent**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4\. GenAI agent** triggers an API call to GPT-4o and returns the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5\. Output** triggers the updating of the display. The system is ready for
    a new input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.14: The sequence of events and functions to perform semantic and
    semantic analysis](img/B32304_04_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.14: The sequence of events and functions to perform semantic and semantic
    analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompt that triggers this sequence of functions and events is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The generative AI controller correctly identified `Pinecone` as a trigger to
    query the instruction scenario namespace, which GPT-4o used to produce a satisfactory
    response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Note that the AI agent begins the response with `genaisys`, signaling that the
    proper namespace was queried. This is an optional quality control feature that
    is good practice to implement when developing the GenAISys.
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompt 2 sentiment analysis sequence represented in *Figure 4.15* is identical
    to the semantic analysis sequence with two differences:'
  prefs: []
  type: TYPE_NORMAL
- en: The **1\. User selection** event is activated because `User02` is selected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The prompt will contain an allusion to sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.15: Task orchestration for sentiment analysis](img/B32304_04_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.15: Task orchestration for sentiment analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompt contains the `Pinecone` keyword to activate a Pinecone query and
    the word `sentiment`, which is an indicator for similarity search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: We could add an explicit drop-down list for all the tasks requested, and we
    will in some cases. But in this case, we are relying on implicit keyword searches.
    The balance between explicit (choosing the task in a drop-down list, for example)
    and implicit (using a keyword or relying on the content of the prompt) should
    be decided in workshops with the users.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the `Pinecone` keyword `genaisys` namespace is selected, and
    the output is satisfactory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The session continues to trigger episodic memory retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: RAG for episodic memory retrieval
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The sequence for episodic memory retrieval will search the Pinecone index for
    a personal memory of the team members. The memory is related to a past meeting
    that was saved and upserted to the Pinecone index in the `data01` namespace. `User03`
    will trigger the following sequence of functions and events, as represented in
    *Figure 4.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. User selection** is triggered independently because the user has changed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2\. Input** triggers the verification of **3\. Agent checked**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3\. Agent checked** triggers the conversational AI agent controller, which
    in turn triggers **3.2\. RAG data** retrieval in the `data01` namespace based
    on the `RAG` keyword in the prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the generative AI agent, GPT-4o, runs a request with the augmented
    input and returns an output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4\. Output** will trigger a display update, and the system is ready for a
    new turn in the conversation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.16: Episodic memory retrieval](img/B32304_04_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.16: Episodic memory retrieval'
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompt clearly refers to a past event that is related to the personal experience
    of the team. The trace of this event is an episodic memory stored in the Pinecone
    index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent’s response is satisfactory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the agent correctly found the namespace and also uses the phrase
    `your CTO mentioned`, recognizing that this is an event linked to the personal
    experience of the team, not impersonal semantic data.
  prefs: []
  type: TYPE_NORMAL
- en: The session continues with ideation.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI agent for ideation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The session continues with ideation. We want to leverage the power of the generative
    AI model, GPT-4o, in this case, to give us ideas. As such, the sequence will not
    use the Pinecone index to retrieve instructions or data, as shown in *Figure 4.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: The user remains unchanged, **2\. Input** goes directly to **3\. Agent checked**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system then ignores the Pinecone index but takes **3.2\. User history**
    into account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, **4\. GenAI agent** triggers the generative AI call and returns the
    output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5\. Output** triggers the display update and the system is ready for another
    conversation turn.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.17: GenAISys as an ideation generator](img/B32304_04_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.17: GenAISys as an ideation generator'
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompt asks the AI agent for help to get some ideas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The AI agent inherits episodic memory since it refers to the CTO’s reflections
    in the conversation history and now gives its suggestions based on the history
    of the conversation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The GenAISys has provided ideas for the team. Now, the team wants to think these
    ideas over.
  prefs: []
  type: TYPE_NORMAL
- en: Dialogue without an AI conversational agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The team has now had a short conversation that could have continued as long
    as they needed to. `User01` takes over and communicates directly with the team.
    The GenAISys is now used as a collaborative remote meeting tool, as shown in *Figure
    4.18*:'
  prefs: []
  type: TYPE_NORMAL
- en: User selection is triggered because `User01` is stepping in.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`User01` unchecks the **Agent** widget.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A message is entered, but the prompt is for other users, not the AI agent
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, `User01` ends the conversation, which is saved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.18: A dialogue without an AI agent](img/B32304_04_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.18: A dialogue without an AI agent'
  prefs: []
  type: TYPE_NORMAL
- en: '`User01` enters a message for the others:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4.19* shows that `User01` has unchecked the AI agent to send the message
    and is now ready to end the session by entering `exit`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.19: The user ends the conversation](img/B32304_04_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.19: The user ends the conversation'
  prefs: []
  type: TYPE_NORMAL
- en: The GenAISys displays the *conversation ended* message, as shown in *Figure
    4.20*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.20: Conversation ends](img/B32304_04_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.20: Conversation ends'
  prefs: []
  type: TYPE_NORMAL
- en: '![A magnifying glass on a black background  AI-generated content may be incorrect.](img/1.png)**Quick
    tip**: Need to see a high-resolution version of this image? Open this book in
    the next-gen Packt Reader or view it in the PDF/ePub copy.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2.png)**The next-gen Packt Reader** is included for free with the purchase
    of this book. Scan the QR code OR go to [packtpub.com/unlock](http://packtpub.com/unlock),
    then use the search bar to find this book by name. Double-check the edition shown
    to make sure you get the right one.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A qr code on a white background  AI-generated content may be incorrect.](img/Unlock_Code1.png)'
  prefs: []
  type: TYPE_IMG
- en: The message instructs the users to proceed to the next cell to display and summarize
    the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: Loading, displaying, and summarizing the conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The display and summarization of a conversation will be integrated into the
    functions of the GenAISys framework in [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140),
    *Adding Multimodal, Multifunctional Reasoning with Chain of Thought*.
  prefs: []
  type: TYPE_NORMAL
- en: In this notebook, we will proceed to the next cells as described in the *A session
    with two users* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the display function provides Markdown text of the conversation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: We built the fundamental structure of the GenAISys framework we will be enhancing
    throughout the next chapters. We also ran some basic conversations. Let’s summarize
    this chapter and move up to the next level.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A complex, event-driven, fast-moving economy requires powerful automation for
    the hundreds of tasks generated by just-in-time consumer needs. A GenAISys can
    satisfy those requirements with a responsive interface and generative AI capabilities.
    The challenge is providing a dynamic, intuitive system. No matter how generative
    AI automates tasks—and they can be tremendously automated—the final decisions
    will be made by humans. Humans need to communicate in meetings, whether they are
    organized physically or online. The challenge then evolves to provide an organization
    with multi-user GenAISys.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we first explored a high-level framework to build multi-user,
    multi-turn, multifunctional, and RAG features. The framework includes real-time
    memory features and long-term knowledge stored in a vector store. The overall
    ChatGPT-like system requires a response interface and conversational agent that
    we will enhance in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We then build an event-driven GenAISys response interface with IPython. The
    interface was seamless for an end user who can use the system with three widgets.
    The first widget managed the users’ input, the second one the active user, and
    the third an agent checkbox to activate or deactivate the AI conversational agent
    built with GPT-4o.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we ran a multi-user, multi-turn GenAISys session centered on traveling
    for an online travel agency team. The first goal was to run a seamless GenAISys
    for the users with three widgets. The second goal was to explore the scope of
    short-term, long-term, semantic, and episodic memory. The third goal was to run
    RAG to retrieve instructions and data. Finally, the goal was to let the users
    communicate with or without the AI agent. We concluded the session by saving and
    summarizing it.
  prefs: []
  type: TYPE_NORMAL
- en: We now have a framework that we can configure and enhance in the following chapters,
    starting by adding multimodal functions and external extensions to the GenAISys
    in [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140), *Adding Multimodal, Multifunctional
    Reasoning with Chain of Thought*.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The interface of a GenAISys must be seamless for the users. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: IPython is the only tool available to build a GenAISys interface. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The AI conversational AI agent built with GPT-4o must be enhanced with RAG.
    (True or False).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GPT-4o can provide sufficient information and perform tasks quite well. (True
    or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pinecone can be used to retrieve instruction scenarios. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A namespace is only for data in Pinecone. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A vector store such as Pinecone is a good way to store episodic memory. (True
    or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We don’t need an agent checkbox option. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Querying Pinecone is done by the user in a GenAISys. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GenAISys is a complex system that should be seamless for the user. (True or
    False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'IPython documentation: [https://ipython.org/](https://ipython.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenAI multi-turn conversations: [https://platform.openai.com/docs/guides/audio/multi-turn-conversations/](https://platform.openai.com/docs/guides/audio/multi-turn-conversations/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Colab functionality: [https://colab.research.google.com/](https://colab.research.google.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Liu, J., Tan, Y. K., Fu, B., & Lim, K. H. (n.d.). *Balancing accuracy and efficiency
    in multi-turn intent classification for LLM-powered dialog systems in production*:
    [https://arxiv.org/abs/2411.12307](https://arxiv.org/abs/2411.12307)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscribe for a Free eBook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New frameworks, evolving architectures, research drops, production breakdowns—*AI_Distilled*
    filters the noise into a weekly briefing for engineers and researchers working
    hands-on with LLMs and GenAI systems. Subscribe now and receive a free eBook,
    along with weekly insights that help you stay focused and informed.
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe at [https://packt.link/TRO5B](Chapter_4.xhtml) or scan the QR code
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Newsletter_QR_Code1.png)'
  prefs: []
  type: TYPE_IMG
