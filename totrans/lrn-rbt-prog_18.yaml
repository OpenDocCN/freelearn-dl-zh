- en: '*Chapter 15*: Voice Communication with a Robot Using Mycroft'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using our voice to ask a robot to do something and receiving a voice response
    has been seen as a sign of intelligence for a long time. Devices around us, such
    as those using Alexa and Google Assistant, have these tools. Being able to program
    our system to integrate with these tools gives us access to a powerful voice assistant
    system. Mycroft is a Python-based open source voice system. We will get this running
    on the Raspberry Pi by connecting it to a speaker and microphone, and then we
    will run instructions on our robot based on the words we speak.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will have an overview of Mycroft and then learn how to add
    a speaker/microphone board to a Raspberry Pi. We will then install and configure
    a Raspberry Pi to run Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: We'll also extend our use of Flask programming, building a Flask API with more
    control points.
  prefs: []
  type: TYPE_NORMAL
- en: Toward the end of the chapter, we will create our own skills code to connect
    a voice assistant to our robot. You will be able to take this knowledge and use
    it to create further voice agent skills.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Mycroft – understanding voice agent terminology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations of listening for speech on a robot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to add a speaker/microphone board to a Raspberry Pi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to install and configure a Raspberry Pi to run Mycroft
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Programming a Flask control API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create our own skills code to connect a voice assistant to our robot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will require the following hardware for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: An additional Raspberry Pi 4 (model B).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An SD card (at least 8 GB).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A PC that can write the card (with the balenaEtcher software).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ReSpeaker 2-Mics Pi HAT.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mini Audio Magnet Raspberry Pi Speaker—a tiny speaker with a JST connector or
    a speaker with a 3.5 mm jack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may be helpful to have a Micro-HDMI to HDMI cable for troubleshooting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Micro USB power supply.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The robot from the previous chapters (after all, we intend to get this moving).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code for this chapter is available on GitHub at [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter15](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter15).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/2N5bXqr](https://bit.ly/2N5bXqr)'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Mycroft – understanding voice agent terminology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Mycroft** is a software suite known as a **voice assistant**. Mycroft listens
    for voice commands and takes actions based on those commands. Mycroft code is
    written in Python and is open source and free. It performs most of its voice processing
    in the cloud. After the commands are processed, Mycroft will use a voice to respond
    to the human.'
  prefs: []
  type: TYPE_NORMAL
- en: Mycroft is documented online and has a community of users. There are alternatives
    that you could consider after you've experimented with Mycroft – for example,
    Jasper, Melissa-AI, and Google Assistant.
  prefs: []
  type: TYPE_NORMAL
- en: So, what are the concepts of a voice assistant? Let's look at them in the following
    subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Speech to text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Speech to text** (**STT**) describes systems that take audio containing human
    speech and turn it into a series of words that a computer can then process.'
  prefs: []
  type: TYPE_NORMAL
- en: These can run locally, or they can run in the cloud on far more powerful machines.
  prefs: []
  type: TYPE_NORMAL
- en: Wake words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Voice assistants usually have a **wake word** – a phrase or word that is spoken
    before the rest of a command to get the attention of the voice assistant. Examples
    are the *Hey Siri*, *Hi Google*, and *Alexa* utterances. Mycroft uses the word
    *Mycroft* or the phrase *Hey Mycroft,* but that can be changed.
  prefs: []
  type: TYPE_NORMAL
- en: A voice assistant is usually only listening for wake words and ignores all other
    audio input until woken. The wake word is recognized locally on the device. The
    sounds it samples after the wake word are sent to a speech-to-text system for
    recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Utterances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An **utterance** is a term for something a user says. Voice assistants use vocabulary
    you define to match an utterance to a skill. The specific vocabulary will cause
    Mycroft to invoke the intent handler.
  prefs: []
  type: TYPE_NORMAL
- en: The vocabulary in Mycroft comprises lists of interchangeable phrases in a file.
  prefs: []
  type: TYPE_NORMAL
- en: 'A good example of an utterance is asking Mycroft about the weather: *Hey Mycroft,
    what is the weather?*'
  prefs: []
  type: TYPE_NORMAL
- en: Intent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An **intent** is a task that the voice assistant can do, such as finding out
    what today's weather is. We will build intents to interact with our robot. An
    intent is part of a skill, defining the handler code for what it does and choosing
    a dialog to respond.
  prefs: []
  type: TYPE_NORMAL
- en: Using the weather skill as an example, the utterance *What is the weather?*
    triggers an intent to fetch the current weather for the configured location and
    then speak the details of this back to the user. An example for our robot is *ask
    the robot to test LEDs*, with an intent that starts the LED rainbow behavior (from
    [*Chapter 9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171), *Programming RGB
    Strips in Python*) on the robot.
  prefs: []
  type: TYPE_NORMAL
- en: Dialog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Mycroft terminology, **dialogs** are phrases that Mycroft speaks to the user.
    An example would be *OK, the robot has been started*, or *Today, the weather is
    clear*.
  prefs: []
  type: TYPE_NORMAL
- en: A skill has a collection of dialogs. These have sets of synonymous words to
    say and can use different languages.
  prefs: []
  type: TYPE_NORMAL
- en: Vocabulary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Utterances you speak, once converted into text, are matched to **vocabulary**.
    Vocabulary files, like dialogs, are parts of an intent, matching utterances to
    action. The vocabulary files contain synonymous phrases and can be organized into
    language sets to make your skill multi-lingual.
  prefs: []
  type: TYPE_NORMAL
- en: This would make phrases like *what is the weather?*, *is it sunny?*, *do I need
    an umbrella?* or *will it rain?* synonymous. You may have things split – for example,
    *ask the robot to* as one vocabulary item and *drive forward* as another.
  prefs: []
  type: TYPE_NORMAL
- en: Skills
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Skills** are containers for a whole set of vocabulary for utterances, dialogs
    to speak, and *intents*. A skill for alarms might contain intents such as setting
    an alarm, listing the alarms, deleting an alarm, or changing an alarm. It would
    contain a dialog to say the alarm setting is complete or to confirm each alarm.'
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, we will build a `MyRobot` skill with intents to make
    it move and stop.
  prefs: []
  type: TYPE_NORMAL
- en: Now you've learned a bit about the terminology and parts of a voice agent. We
    next need to consider what we will build. Where would we put a speaker and microphone?
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of listening for speech on a robot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start to build this, we should consider what we are going to make.
    Should the speaker and microphone be on the robot or somewhere else? Will the
    processing be local or in the cloud?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some considerations to keep in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Noise**: A robot with motors is a noisy environment. Having a microphone
    anywhere near the motors will make it close to useless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power**: The voice assistant is continuously listening. The robot has many
    demands for power already with the other sensors that are running on it. This
    power demand applies both in terms of battery power and the CPU power needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Size and physical location**: The speaker and voice HAT would add height
    and wiring complications to an already busy robot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A microphone and speaker combination could be on a stalk for a large robot –
    a tall standoff with a second Raspberry Pi there. But this is unsuitable for this
    small and simple robot. We will create a separate voice assistant board that will
    communicate with our robot, but we won't be putting it directly on the robot.
    The voice assistant will be a second Raspberry Pi.
  prefs: []
  type: TYPE_NORMAL
- en: We will also be using a system that goes to the cloud to process the speech.
    While a fully local system would have better privacy and could respond quicker,
    at the time of writing, there is not a complete packaged voice assistant that
    works this way for a Raspberry Pi. The Mycroft software gives us flexibility in
    using our own skills and has a pluggable backend for voice processing, so that
    one day it may run locally.
  prefs: []
  type: TYPE_NORMAL
- en: Now we've chosen how we will make our voice agent with Mycroft and a second
    Raspberry Pi, it's time to start building it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding sound input and output to the Raspberry Pi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can use a voice processing/voice assistant, we need to give the Raspberry
    Pi some speakers and a microphone. A few Raspberry Pi add-ons provide this. My
    recommendation, with a microphone array (for better recognition) and a connection
    to speakers, is the ReSpeaker 2-Mics Pi HAT, which is widely available.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next photograph shows the ReSpeaker 2-Mics Pi HAT:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_15_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.1 – The ReSpeaker 2-Mics Pi HAT
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 15.1* shows a photo of a ReSpeaker 2-Mics Pi HAT mounted on a Raspberry
    Pi. On the left, I''ve labeled the left microphone. The hat has two microphones,
    which are two tiny rectangular metal parts on each side. The next label is for
    3 RGB LEDs and a button connected to a GPIO pin. After this are the two ways of
    connecting speakers – a 3.5mm jack or a JST connector. I recommend you connect
    a speaker to hear output from this HAT. Then, the last label highlights the right
    microphone.'
  prefs: []
  type: TYPE_NORMAL
- en: I've chosen the ReSpeaker 2-Mic Pi HAT because it is an inexpensive device to
    get started on voice recognition. Very cheap USB microphones will not work well
    for this. There are expensive devices better supported in Mycroft, but they do
    not sit on the Pi as a hat. This ReSpeaker 2-Mics Pi HAT is a trade-off – great
    for hardware simplicity and cost but with some more software setup. Let's now
    look at how we physically install this HAT.
  prefs: []
  type: TYPE_NORMAL
- en: Physical installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ReSpeaker 2-Mics HAT will sit directly on the Raspberry Pi 4 headers with
    the board overhanging the Pi.
  prefs: []
  type: TYPE_NORMAL
- en: 'The speakers will have either a tiny two-pin connector (JST) type that fits
    the single two-pin socket on the board or a 3.5 mm jack. The next photograph shows
    the speaker plugged into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_15_02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.2 – The Mycroft Voice Assistant ReSpeaker setup
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 15.2* shows my Mycroft setup with the ReSpeaker 2-Mics Pi HAT set up
    on my desk. It is powered up, and the Raspberry Pi is lit. I''ve connected a speaker
    to it as well.'
  prefs: []
  type: TYPE_NORMAL
- en: You could use a Raspberry Pi case or project box but ensure that the microphones
    are not covered up.
  prefs: []
  type: TYPE_NORMAL
- en: You also need an SD card and a power supply.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For the next few sections, I recommend using a mains power supply. Do not plug
    it in and power it up yet.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have the hardware prepared, and it has speakers and a microphone. In
    the next section, we will set up Raspbian and the voice agent software.
  prefs: []
  type: TYPE_NORMAL
- en: Installing a voice agent on a Raspberry Pi
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Mycroft has a Raspbian distribution prepared for this. Let''s put that on an
    SD card:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the Mycroft website to download the *Picroft* image: [https://mycroft-ai.gitbook.io/docs/using-mycroft-ai/get-mycroft/picroft](https://mycroft-ai.gitbook.io/docs/using-mycroft-ai/get-mycroft/picroft)
    – this is based on Raspbian Buster. Select **stable disk image**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the SD card into your computer. Use the procedures from [*Chapter 3*](B15660_03_Final_ASB_ePub.xhtml#_idTextAnchor050),
    *Exploring the Raspberry Pi*, in the *Flashing the card in balenaEtcher* section.
    Be sure to select the Picroft image instead of Raspbian.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make sure this image works headlessly, enabling SSH and Wi-Fi as we did in [*Chapter
    4*](B15660_04_Final_ASB_ePub.xhtml#_idTextAnchor063), *Preparing a Headless Raspberry
    Pi for a Robot*, in the *Setting up wireless on the Raspberry Pi and enabling
    SSH* section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With this SD card ready, it's time to try it out. Insert it into the voice assistant
    Raspberry Pi and power it up using the USB micro socket on the ReSpeaker 2-Mics
    Pi HAT (not the Pi).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Ensure you supply power via the ReSpeaker 2-Mics Pi HAT and not the Pi. This
    board requires power to drive its speaker. The documentation for the board suggests
    that if you power it through the Pi you don't get output from the speaker. See
    [https://wiki.seeedstudio.com/ReSpeaker_2_Mics_Pi_HAT/#hardware-overview](https://wiki.seeedstudio.com/ReSpeaker_2_Mics_Pi_HAT/#hardware-overview)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: Its hostname starts as `picroft.local`. You use the username `pi` and password
    `mycroft`. Ensure it is connected to Wi-Fi, and you can reach it via SSH (PuTTY).
    With the Raspberry Pi started, you can start to set up Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the ReSpeaker software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you log on, Mycroft will show you an installation guide. This will ask
    you some questions as listed:'
  prefs: []
  type: TYPE_NORMAL
- en: When asked if you want a guided setup, press *Y* for yes. The Mycroft installation
    will download a load of updates. Leave it for 30 minutes to an hour to do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Mycroft will now ask for your audio output device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Press *Ctrl* + *C* to leave the guided setup and return to the `$` prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the installation to work, we'll need the software on the SD card to be updated.
    At the prompt, type `sudo apt update -y && sudo apt upgrade -y`. The update will
    take some time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reboot the Pi (with `sudo reboot`) for the updates to take effect. After you
    reboot the Pi, `ssh` in. You will be at the guided setup again. Press *Ctrl* +
    *C* again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following commands to install the audio drivers for the ReSpeaker 2-Mics
    Pi HAT:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Git clone may take a minute or two. This board uses the WM8960 sound chip.
    The install script will take 20-30 minutes to finish.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Reboot again. Press *Ctrl* + *C* after to leave the guided mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before we move on, it's a good idea to test that we are getting audio here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Type `aplay -l` to list playback devices. In the output, you should see the
    following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This shows that it has found our card.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can now test this card will play audio by getting it to play an audio file.
    Use this command: `aplay -Dplayback /usr/share/sounds/alsa/Front_Left.wav`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This command specifies the device named `playback` with the device `-D` flag,
    and then the file to play. The `playback` device is a default ALSA handler that
    ensures mixing is done and avoids issues with bitrate and channel number mismatches.
    There are other test audio files in `/usr/share/sounds/alsa`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can then check for recording devices with `arecord -l`. In the following
    output, we can see that `arecord` has found the card:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The card is now ready for use. Next, we need to show the Mycroft system how
    to choose this card for use.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you haven''t got audio output, there are some things you can check:'
  prefs: []
  type: TYPE_NORMAL
- en: First, type `sudo poweroff` to turn off the Raspberry Pi. When it is off, check
    the connections. Ensure that the board is connected fully to the GPIO header on
    the Pi. Make sure you've connected the speaker to the correct port on the ReSpeaker
    2-Mics Pi HAT.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you power it again, ensure that you are using the power connector on the
    ReSpeaker 2-Mics Pi HAT, and not the Raspberry Pi.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are using the headphone slot instead of the speaker slot, you may need
    to increase the volume. Type `alsamixer`, select the WM8960 sound card, and turn
    the headphone volume up. Then try the playback tests again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make sure you have performed the `apt update` and the `apt upgrade` steps. The
    installation of the drivers will not work without it. You will need to reboot
    after this and then try reinstalling the driver.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When installing the driver, if the Git step fails, double-check the address
    you have fetched.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When attempting playback, the `-D` flag is case-sensitive. A lowercase `d` will
    not work here.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If these steps still do not help, please go to the [https://github.com/waveshare/WM8960-Audio-HAT](https://github.com/waveshare/WM8960-Audio-HAT)
    website, read their documentation, or raise an issue.
  prefs: []
  type: TYPE_NORMAL
- en: Now we've checked this, let's try to link the sound card with Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Mycroft to talk to the sound card
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now you need to connect Mycroft and the sound card. Do this by editing the
    Mycroft configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Mycroft config file as root using `sudo nano /etc/mycroft/mycroft.conf`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The file has lines describing various aspects of Mycroft. However, we are interested
    in two lines only:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit both occurrences of `hw:0,0` to be the term `playback`. The two lines
    should look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Press *Ctrl* + *X* to write out and exit. Type *Y* for yes when asked to write
    out the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reboot one more time; when you return, do not exit the guided mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mycroft will ask to test the device. Press *T* to test the speaker. It may take
    a few seconds, but you will hear Mycroft speak to you. If it is a little quiet,
    try typing the number `9`, and test it again. An exciting moment! Press *D* to
    say you have done the test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The guided installer will next ask about the microphone. Select **4** for **Other
    USB Microphone** and try the sound test. The installer will ask you to speak to
    the microphone, and it should play your voice back to you. Press *1* if this sounds
    good.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The guided installation will ask you about using the recommendations; select
    *1* to confirm you want that. There will be a series of questions about your password
    settings. I recommend not adding a sudo password but changing the default password
    for the Pi to something unique.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mycroft will launch with a large section of purple installation text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You have Mycroft configured and starting up. It can record your voice and play
    that back to you, and you have heard it speak a test word too. Now, it's time
    to start using Mycroft and see what it can do.
  prefs: []
  type: TYPE_NORMAL
- en: Starting to use Mycroft
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's get to know Mycroft a little, and then try talking with it. We will start
    with the debug interface, the Mycroft client, which shows you what is going on
    with the system, and then we'll get into talking to it.
  prefs: []
  type: TYPE_NORMAL
- en: The Mycroft client
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you connect to Mycroft, you will see a display like the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_15_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.3 – The Mycroft client interface
  prefs: []
  type: TYPE_NORMAL
- en: The screenshot in *Figure 15.3* is the Mycroft client. It allows you to see
    what Mycroft is doing, but you don't need to connect to this for Mycroft to listen
    to you. The top right shows how many messages there are and how many you can see.
    In the screenshot, you can see messages **0-10**, out of a total of **10** messages.
  prefs: []
  type: TYPE_NORMAL
- en: The main middle section shows the messages. *Red* and *purple* messages come
    from the Mycroft system and plugins. If many *purple* messages are flashing by,
    Mycroft is installing plugins and updates, so you may need to leave it until it
    finishes. *Green* messages show Mycroft interacting with a user. It shows when
    it detects a wake word, when it starts to record, when it ends the recording,
    and the utterance it thinks you said. The messages are useful as if it isn't quite
    responding, you can check whether it's picking up the wake word and that the utterance
    matches what you are trying to say.
  prefs: []
  type: TYPE_NORMAL
- en: Below this, on the left, is the history. In the history, what Mycroft has processed
    from your utterance is in *blue*. The dialog Mycroft speaks is in *yellow*. You
    should hear *yellow* text repeated on the speaker; however, it can take a while
    if it is very busy. On the right, it shows a legend that matches colors to a log
    file. Further right is a microphone speaker level meter, and unless Mycroft is
    busy, or you are very quiet, you should see this moving up and down as it picks
    up noise in the room. Note – too much noise, and you may have trouble talking
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: At the bottom of the screen is an input area, where you can type commands for
    Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: Give the system about 30-40 minutes to finish all the installations. If it is
    not responsive, it is not hung but is usually installing and compiling additional
    components.
  prefs: []
  type: TYPE_NORMAL
- en: Mycroft will then tell you it needs to be paired at [mycroft.ai](http://mycroft.ai).
    You will need to register the device using the code it gives you; which you can
    do while Mycroft is installing. You will need to create an account there to do
    so (or log in if this is a second device/attempt). Please complete this before
    proceeding.
  prefs: []
  type: TYPE_NORMAL
- en: When you've paired Mycroft, and it finishes installing things, you can start
    to interact.
  prefs: []
  type: TYPE_NORMAL
- en: Talking to Mycroft
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now you should be able to speak to your voice assistant:'
  prefs: []
  type: TYPE_NORMAL
- en: First, to get its attention, you must use the wake word *Hey Mycroft*. If it's
    ready (and not still busy), it will issue a speaker tone to show *Mycroft* is
    listening. You need to stand within about a meter of the microphones on the Raspberry
    Pi. It may respond with *Please wait a moment while I finish booting up*. Give
    it a minute and try again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you hear the tone, you can now ask it to do something. A good starting point
    is to tell it: *Say hello*. Mycroft should respond with *Hello* from the speaker
    after about 10 seconds. You will need to speak as clearly as possible. I''ve found
    that it needs you to pronounce each syllable; those *t* and *n* sounds are essential.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that this works, you can have some fun with it! You can shorten *Hey Mycroft*
    to just *Mycroft*. Other things you can say include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Hey Mycroft, what is the weather?*: This will use the weather skill and tell
    you the weather. It may be for the wrong location; use the [mycroft.ai](http://mycroft.ai)
    website to configure your device to your location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mycroft, what is 23 times 76*: This will use the Wolfram skill, which can
    handle mathematical questions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mycroft, wiki banana*: This will use a Wikipedia skill, and Mycroft will tell
    you what it has found out about the banana.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try these out to get used to talking to Mycroft so it responds. It may say *I
    don't understand*, and the log will tell you what it heard, which can help you
    try to tune how you pronounce things for it.
  prefs: []
  type: TYPE_NORMAL
- en: We can now create a skill to connect Mycroft to our robot. But first, let's
    check for problems.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are not able to get Mycroft to speak or recognize talking, try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you are close enough to the microphone/loud enough. This can be checked
    by observing whether the mic (microphone) level goes above the dashed line in
    the Mycroft console.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure you have a good network connection from your Raspberry Pi. Mycroft is
    only going to work where you can reach the internet. See the Mycroft documentation
    for handling proxies. Mycroft can fail to boot correctly if the internet connection
    isn't great. Fixing the connection and rebooting it can help.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attaching a monitor while the Pi is booting may reveal error messages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mycroft has a troubleshooting system starting with: *Troubleshooting and Known
    errors* ([https://mycroft.ai/documentation/troubleshooting/](https://mycroft.ai/documentation/troubleshooting/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mycroft is under active development. Taking the latest Picroft image and applying
    the ReSpeaker driver may help. In short, getting this installed and running is
    subject to change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With Mycroft talking and responding, we need to prepare the robot for Mycroft
    to talk to it.
  prefs: []
  type: TYPE_NORMAL
- en: Programming a Flask API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter aims to control our robot with Mycroft. To do so, we need to give
    our robot some way to receive commands from other systems. An **Application Programming
    Interface** (**API**) on a server lets us decouple systems like this to send commands
    across the network to another and receive a response. The Flask system is ideally
    suited to building this.
  prefs: []
  type: TYPE_NORMAL
- en: Web-based APIs have endpoints that other systems make their requests to and
    roughly map to functions or methods in a Python module. As you'll see, we map
    our API endpoints directly to functions in the Python `robot_modes` module.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get into building much, let's look at the design of this thing – it
    will also reveal how Mycroft works.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Mycroft controlling the robot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following diagram shows how a user controls a robot via Mycroft:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_15_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.4 – Overview of the robot skill
  prefs: []
  type: TYPE_NORMAL
- en: 'The diagram in *Figure 15.4* shows how data flows in this system:'
  prefs: []
  type: TYPE_NORMAL
- en: On the left, it starts with the user speaking an instruction to Mycroft.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On recognizing the wake word, Mycroft sends the sound to the Google STT engine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Google STT returns text, an utterance, which Mycroft matches against vocabulary
    in skills/intents. We'll dig more into these later.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This triggers intents in the robot skill, which we will build. The robot skill
    will send a request to the Raspberry Pi in the robot, on the right, as a request
    to a Flask control API (web) server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That control API server will start the robot processes and respond to say it's
    done so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The robot skill will choose dialog to say it has completed and sends this to
    Mycroft.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mycroft will then speak this response to the user.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, we are going to build the Flask server on the robot. You have
    seen Flask before in the visual processing chapters and have already installed
    this library.
  prefs: []
  type: TYPE_NORMAL
- en: Starting a behavior remotely
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use HTTP and a web server for this, as it's simple to send requests
    to, so we can build other ways to control the robot remotely. HTTP sends requests
    in a URL—first, the `http://` protocol identifier; a server hostname, `myrobot.local`;
    a path, `/mode/foo`; and it may have additional parameters after that. We use
    the path of the URL to determine what our robot does.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have done with other systems, we create a few logical sections and blocks
    to handle different aspects of this:'
  prefs: []
  type: TYPE_NORMAL
- en: Code to manage the robot's modes and to start and stop known scripts. It can
    also give us a list of those known scripts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web server to handle requests over the network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll need to build the mode manager first.
  prefs: []
  type: TYPE_NORMAL
- en: Managing robot modes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can manage modes by starting and stopping our behavior scripts as subprocesses.
    Let''s make a configuration to tell the mode manager about the modes. This configuration
    maps a mode name to a file—a Python file. Note that we are specifying a list of
    files and not inferring it. Although we could take our mode/path section and add
    `.py` to get a file, this would be bad for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It would couple us directly to script names; it would be nice if we could change
    underlying scripts for the same mode name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the robot is not a secure environment, allowing arbitrary subprocesses
    to run is very bad; restricting it keeps the robot a little more secure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s start building it:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a file called `robot_modes.py`. This file contains a class called `RobotModes`
    that handles robot processes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The file starts with some imports and the top of the class definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a few mode mappings, mapping a mode name to a filename:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The mode name is a short name, also known as a *slug*, a compromise between
    human-readable and machine-readable – they are usually restricted to lowercase
    and underscore characters and are shorter than a full English description. Our
    filenames are relatively close to slug names already.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With the fixed configuration aside, this class is also managing running behaviors
    as processes. It should only run one at a time. Therefore, we need a member variable
    to keep track of the current process and check whether it is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should be able to check whether something is already running or it has completed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next function is running a process. The function parameters include a mode
    name. The function checks whether a process is running, and if not, starts a process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The class needs a way to ask it to stop a process. Note that this doesn''t
    try to stop a process when it is not running. When we stop the scripts, we can
    use Unix signals, which let us ask them to stop in a way that allows their `atexit`
    code to run. It sends the `SIGINT` signal, which is the equivalent of the *Ctrl*
    + *C* keyboard combination:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After we have signaled the process, we set the current process to `None` – throwing
    away the handle.
  prefs: []
  type: TYPE_NORMAL
- en: We now have code to start and stop processes, which also maps names to scripts.
    We need to wrap it in a web service that the voice agent can use.
  prefs: []
  type: TYPE_NORMAL
- en: Programming the Flask control API server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We've used Flask previously to make the web server for our visual processing
    behaviors. We are going to use it for something a bit simpler this time, though.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw with the start and stop buttons in the image servers, Flask lets us
    set up handlers for links to perform tasks. Let's make a script that acts as our
    control web service, which uses `Flask` and our `RobotModes` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build this by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a script called `control_server.py`. We can start by importing Flask
    and our robot modes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create a Flask app to contain the routes and an instance of our `RobotModes`
    class from before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we need a route, or API endpoint, to run the app. It takes the mode name
    as part of the route:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We return a running confirmation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We also need another API endpoint to stop the running process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we need to start the server up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Power up the robot and copy both the `control_server.py` and `robot_modes.py`
    files to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SSH into the robot and start the control server with `python3 control_server.py`.
    You should see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now create another `ssh` window into the Mycroft Raspberry Pi – we can test
    that one talks to the other. Press *Ctrl* + *C* once into `pi@picroft.local` to
    get to the Linux command line (the `$` prompt).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `curl` command is frequently used on Linux systems like the Raspberry Pi
    to test servers like this. It makes requests to web servers, sending/receiving
    data, and displaying the result. It's perfect for testing HTTP control APIs like
    this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We intend to make a `post` request. Type this command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should start the rainbows turning on and off, using the code from [*Chapter
    9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171), *Programming RGB Strips
    in Python*. The `curl` command specifies that we are using the `POST` method to
    make a request, then a URL with the port, the robot hostname, then the instruction
    `run`, and then the mode name.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can stop the LEDs with `curl -X POST http://myrobot.local:5000/stop`. This
    URL has the instruction `stop`. The robot LED rainbow should stop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice how both these URLs have `http://myrobot.local:5000/` at their start.
    The address may be different for your robot, depending on your hostname. This
    is a base URL for this control server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can press *Ctrl* + *C* to stop this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can use this to build our Mycroft behaviors, but let's check for any problems
    before carrying on.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If this isn''t working for you, we can check a few things to see what happened:'
  prefs: []
  type: TYPE_NORMAL
- en: If you receive any syntax errors, check your code and try again.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Please verify that your robot and the device you are testing from have internet
    availability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when we are starting the subprocess, we are starting Python 3\. Without
    the `3`, other unexpected things will happen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, remember the control server is running on the Raspberry Pi 3A+ on the
    robot. You will need to substitute it for your robot's address in the `curl` commands.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure you have installed Flask, as shown in [*Chapter 13*](B15660_13_Final_ASB_ePub.xhtml#_idTextAnchor283),
    *Robot Vision – Using a Pi Camera and OpenCV*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure you have copied both the control server and the robot mode scripts
    to the robot. You will also need the code from [*Chapter 9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171),
    *Programming RGB Strips in Python* installed on the robot to run this test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we've tested the control server, you can power down the Pi. There's some
    more code to write! Let's tie this into Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: Programming a voice agent with Mycroft on the Raspberry Pi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The robot backend provided by the Flask control system is good enough to create
    our Mycroft skill with.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 15.4*, you saw that after you say something with the wake word, upon
    waking, Mycroft will transmit the sound you made to the Google STT system. Google
    STT will then return the text.
  prefs: []
  type: TYPE_NORMAL
- en: Mycroft will then match this against vocabulary files for the region you are
    in and match that with intents set up in the skills. Once matched, Mycroft will
    invoke an intent in a skill. Our robot skill has intents that will make network
    (HTTP) requests to the Flask control server we created for our robot. When the
    Flask server responds to say that it has processed the request (perhaps the behavior
    is started), the robot skill will choose a dialog to speak back to the user to
    confirm that it has successfully carried out the request or found a problem.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start with a simple skill, with a basic intent, and then you can expand
    this to perform more. I've picked the rainbow LEDs test (`test_leds` from [*Chapter
    9*](B15660_09_Final_ASB_ePub.xhtml#_idTextAnchor171), *Programming RGB Strips
    in Python*) because it is simple.
  prefs: []
  type: TYPE_NORMAL
- en: It's worth noting that the time taken to get the speech processed by Google
    means that this is not suitable for stopping a robot in a hurry; the voice recognition
    can take some time. You could consider using `GPIOZero` in the intent and a `when_pressed`
    handler to trigger the control server's stop handler.
  prefs: []
  type: TYPE_NORMAL
- en: Building the intent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can start with the intent, then look at some vocabulary. To build it, we
    will use a library built into Mycroft named `adapt`:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a folder called `my-robot-skill`, which we will work in to build the
    Mycroft skill.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The main intent file will be an `__init__.py` file in this folder. This filename
    means that Python will treat the whole folder like a Python library, called a
    `my-robot-skill/__init__.py`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will define our skill from the `MycroftSkill` base. It needs to set
    up its parent and prepare settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next thing we need is to define an intent. We do so with a `handle_test_rainbow`
    method – but you need to decorate it using `@intent_handler`. In Python, decorating
    wraps a method in further handling – in this case, making it suitable for Mycroft:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, this skill should make the request to the robot – using `requests.post`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need Mycroft to say something, to say that it has told the robot to do something
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This request could fail for a few reasons, hence the `try` in the code snippet
    before last. We need an `except` to handle this and speak a dialog for the user.
    We also `LOG` an exception to the Mycroft console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This file then needs to provide a `create_skill` function outside of the class,
    which Mycroft expects to find in skill files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The code is one part of this system, but we need to configure this before using
    it.
  prefs: []
  type: TYPE_NORMAL
- en: The settings file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our intent started by loading a setting. We will put this in `my-robot-skill/settingsmeta.json`,
    and it defines the base URL for our control server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please use the hostname/address of your robot Raspberry Pi if it is different.
    This file is a little long for this one setting, but will mean that you can configure
    the URL later if need be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We have now set which base URL to use, but we need to configure Mycroft to load
    our skill.
  prefs: []
  type: TYPE_NORMAL
- en: The requirements file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our skill uses the `requests` library. When Mycroft encounters our skill, we
    should tell it to expect this. In Python, requirements files are the standard
    way to do this. Put the following in `my-robot-skill/requirements.txt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This file is not unique to Mycroft and is used with many Python systems to install
    libraries needed by an application.
  prefs: []
  type: TYPE_NORMAL
- en: Now we need to tell Mycroft what to listen for, with vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the vocabulary files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To define vocabularies, we need to define vocabulary files. You need to put
    them in a folder following the format `my-robot-skill/vocab/<IETF language and
    locale>`. A language/locale means we should be able to define a vocabulary for
    variants such as `en-us` for American English and `zn-cn` for simplified Chinese;
    however, at the time of writing, `en-us` is the most supported Mycroft language.
    Parts of the community are working on support for other languages.
  prefs: []
  type: TYPE_NORMAL
- en: You define each intent with one or more vocabulary parts matching vocabulary
    files. Vocabulary files have lines representing ways to phrase the intended utterance.
    These allow a human to naturally vary the way they say things, something people
    notice when a machine fails to respond to a slightly different way of asking for
    something. There is a bit of a trick in thinking up similar phrases for the vocabulary
    files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need two vocabulary files for our intent—one for `robot` synonyms and one
    for `TestRainbow` synonyms:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the folder `vocab` under `my-robot-skill`, and then the `en-us` folder
    under that.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a file there with the path and name `my-robot-skill/vocab/en-us/robot.voc`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add some phrases for *asking the robot to do something*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create the vocabulary for testing the rainbow. Put it into `my-robot-skill/vocab/en-us/TestRainbow.voc`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that the vocabulary filename's capitalization must match the intent builder;
    I've then used the convention of capitalizing the non-shared vocab parts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Inevitably, when you test this, you will eventually try to say a sensible sounding
    phrase that isn't there. Mycroft will tell you *Sorry, I don't understand*, and
    you will add another expression to the vocabularies above.
  prefs: []
  type: TYPE_NORMAL
- en: Dialog files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We also want to define the phrases Mycroft will say back to you. We have three
    phrases that our intent requires so far. These go into the `my-robot-skill/dialog/en-us`
    folder with a similar structure to vocabulary files. Let''s build them:'
  prefs: []
  type: TYPE_NORMAL
- en: Under `my-robot-skill`, create the folder `dialog`, and then under this, the
    folder `en-us`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the folder, create the file with the path `my-robot-skill/dialog/en-us/Robot.dialog`.
    We can add some phrases for that here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next dialog we need is `TestRainbow.dialog` in the same folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Since we have an error handler, we should also create `UnableToReach.dialog`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By defining multiple possible dialogs, Mycroft will randomly pick one to make
    itself less repetitive. We've now seen how to make vocabulary phrases and dialog
    phrases. Let's just recap what we should have.
  prefs: []
  type: TYPE_NORMAL
- en: Current skill folder
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our skill folder should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_15_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.5 – Screenshot of the robot skill folder
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 15.5,* we see a screenshot showing the skill in a folder called `my-robot-skill`.
    This skill folder has the `dialog` folder, with the `en-us` subfolder and the
    three dialog files here. Below that is the `vocab` folder, with the `en-us` folder
    and two vocab files. Below the `vocab` folder, we have `__init__.py` defining
    the intents, requirements for Mycroft to install it, and a settings file. Whew
    – we've created a lot here, but it will be worth it!
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to now need to upload this whole folder structure to our robot:'
  prefs: []
  type: TYPE_NORMAL
- en: Using SFTP (FileZilla), upload this folder to your Mycroft Pi, in the `/opt/mycroft/skills`
    folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mycroft will automatically load this skill; you will see purple text for this
    flash past as it does the install.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you need to update the code, uploading the files to this location again will
    cause Mycroft to reload it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any problems loading or using the skill will be shown on the Mycroft output.
    You can also find the result in `/var/log/mycroft/skills.log`—the `less` Linux
    tool is useful for looking at log output like this, using *Shift* + *G* to jump
    to the end of the file or typing `/myrobot` to jump to its output.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also use `tail -f /var/log/mycroft/skills.log` to see problems as they
    happen. Use *Ctrl* + *C* to stop.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, power up the robot, `ssh` in, and start the control server with `python3
    control_server.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can then try out your skill with Mycroft: *Tell the robot to turn on the
    lights*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mycroft should beep to show the user it's awake and, once it has got the words
    from speech to text, it will send `/run/test_rainbow` to the control server on
    the robot. You should hear Mycroft say one of the dialog phrases, such as *The
    robot is testing rainbows* and see the LEDs light up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you encounter problems making the intent respond, please try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: First, check the syntax and indenting of the previous Python code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that your robot and the voice assistant Raspberry Pi are on the same
    network; I've found this problematic with some Wi-Fi extenders, and IP addresses
    are needed instead of `myrobot.local`. Use the `settingsmeta.json` file to configure
    this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure you have copied over the whole structure – with the `vocab`, `dialog`,
    `settingsmeta.json`, and `__init__.py` – to the `/opt/mycroft/skills` folder on
    the voice assistant Raspberry Pi.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your settings were incorrect, you will need to change them on the [https://account.mycroft.ai/skills](https://account.mycroft.ai/skills)
    page. Look for the `My Robot` skill and change it here. You will need to save
    the change and may need to restart Mycroft or wait a few minutes for this to take
    effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure the way you have spoken to Mycroft matches your vocabulary files – it
    will not recognize your words otherwise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also type phrases into the Mycroft console if you are having trouble
    with it recognizing your voice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've got our first intent to work! You've been able to speak to a voice assistant,
    and it has instructed the robot what to do. However, we've now started the LEDs
    flashing, and the only way to stop them is with that inconvenient `curl` command.
    We should probably fix that by adding another intent.
  prefs: []
  type: TYPE_NORMAL
- en: Adding another intent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we have our skill, adding a second intent for it to stop becomes relatively
    easy, using another of the endpoints in our robot's control server.
  prefs: []
  type: TYPE_NORMAL
- en: Vocabulary and dialog
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We need to add the vocabulary and dialog so our new intent can understand what
    we are saying and has a few things to say back:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will need to create the `stop` vocabulary; we can put this in `my-robot-skill/vocab/en-us/stop.voc`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need a dialog file for Mycroft to tell us the robot is stopping in `my-robot-skill/dialog/en-us/stopping.dialog`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These will do, but you can add more synonyms if you think of them.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we need to add the intent code to our skill:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will put this into the `MyRobot` class in `my-robot-skill/__init__.py`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the same file, add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The two intents now become far simpler. Change them to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Adding new intents is now easier as we can reuse `handle_control`.
  prefs: []
  type: TYPE_NORMAL
- en: Running with the new intent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can now upload the folder structure again—since the `vocab`, `dialog`, and
    `__init__` files have changed. When you do so, note that Mycroft will automatically
    reload the changed skill (or show any problems trying to do so), so it is immediately
    ready to use.
  prefs: []
  type: TYPE_NORMAL
- en: Try this out by saying *Mycroft, tell the robot to stop*.
  prefs: []
  type: TYPE_NORMAL
- en: You've now added a second intent to the system, defining further vocabulary
    and dialogs. You've also refactored this code, having seen some repetition. You've
    now got the beginnings of voice control for your robot.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about voice assistant terminology, speech to text,
    wake words, intents, skills, utterances, vocabulary, and dialog. You considered
    where you would install microphones and speakers and whether they should be on
    board a robot.
  prefs: []
  type: TYPE_NORMAL
- en: You then saw how to physically install a speaker/microphone combination onto
    a Raspberry Pi, then prepare software to get the Pi to use it. You installed Picroft
    – a Mycroft Raspbian environment, getting the voice agent software.
  prefs: []
  type: TYPE_NORMAL
- en: You were then able to play with Mycroft and get it to respond to different voice
    commands and register it with its base.
  prefs: []
  type: TYPE_NORMAL
- en: You then saw how to make a robot ready for an external agent, such as a voice
    agent to control it with a Flask API. You were able to create multiple skills
    that communicate with a robot, with a good starting point for creating more.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will bring back out the IMU we introduced in [*Chapter
    12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251), *IMU Programming with Python*,
    and get it to do more interesting things – we will smooth and calibrate the sensors
    and then combine them to get a heading for the robot, programming the robot to
    always turn north.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Try these exercises to get more out of this chapter and expand your experience:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Try installing some other Mycroft skills from the Mycroft site and playing
    with them. Hint: say *Hey Mycroft, install pokemon*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The robot mode system has a flaw; it assumes that a process you've asked to
    stop does stop. Should it wait and check the return code to see if it has stopped?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative way to implement the robot modes might be to update all the behaviors
    to exit cleanly so you could import them instead of running in subprocesses. How
    tricky would this be?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While testing the interactions, did you find the vocabulary wanting? Perhaps
    extend it with phrases you might find more natural to start the different behaviors.
    Similarly, you could make dialogs more interesting too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add more intents to the skill, for example, wall avoiding. You could add a stop
    intent, although the response time may make this less than ideal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could the RGB LEDs on the ReSpeaker 2-Mics Pi HAT be used? The project [https://github.com/respeaker/mic_hat](https://github.com/respeaker/mic_hat)
    has an LED demonstration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these ideas, there is plenty of room to explore this concept more. Further
    reading will help too.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please refer to the following for more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Raspberry Pi Robotic Projects*, *Dr. Richard Grimmett*, *Packt Publishing*,
    has a chapter on providing speech input and output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Voice User Interface Projects*, *Henry Lee*, *Packt Publishing*, focuses entirely
    on voice interfaces to systems. It shows you how to build chatbots and applications
    with the Alexa and Google Home voice agents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mycroft AI – Introduction Voice Stack* – a whitepaper from Mycroft AI gives
    more detail on how the Mycroft stack works and its components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mycroft has a large community that supports and discusses the technology at
    [https://community.mycroft.ai/](https://community.mycroft.ai/). I recommend consulting
    the troubleshooting information of this community. Mycroft is under active development
    and has both many quirks and many new features. It's also an excellent place to
    share skills you build for it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seeed Studio, the ReSpeaker 2-Mics Pi HAT creators, host documentation and code
    for this device, along with bigger four and six-microphone versions at [https://github.com/respeaker/seeed-voicecard](https://github.com/respeaker/seeed-voicecard).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
