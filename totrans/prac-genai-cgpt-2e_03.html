<html><head></head><body>
<div><h1 class="chapterNumber">2</h1>
<h1 class="chapterTitle" id="_idParaDest-33">OpenAI and ChatGPT: Beyond the Market Hype</h1>
<p class="normal">This chapter provides an overview of OpenAI and its most notable development – ChatGPT – highlighting its history, technology, and capabilities.</p>
<p class="normal">We will also explore OpenAI’s achievements in the field of Generative AI, beyond ChatGPT – from speech-to-text models to image generation – which will provide you with a broader awareness of the state of the art of some of the most advanced Generative AI technologies.</p>
<p class="normal">More specifically, we will cover the following topics:</p>
<ul>
<li class="bulletList">What is OpenAI?</li>
<li class="bulletList">An overview of OpenAI model families</li>
<li class="bulletList">Getting started with ChatGPT</li>
</ul>
<p class="normal">By the end of this chapter, you will have a solid foundation on ChatGPT and how to use it and its technological capabilities, as well as a wired understanding of OpenAI’s model families.</p>
<h1 class="heading-1" id="_idParaDest-34">Technical requirements</h1>
<p class="normal">To be able to test the example in this chapter, you will need an OpenAI account.</p>
<p class="normal">You may refer to the <em class="italic">Creating an OpenAI account </em>section if you need any help.</p>
<h1 class="heading-1" id="_idParaDest-35">What is OpenAI?</h1>
<p class="normal">OpenAI is a <a id="_idIndexMarker091"/>research organization founded in 2015 by Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, Wojciech Zaremba, and John Schulman. As stated on the OpenAI web page, its mission is “<em class="italic">to ensure that Artificial General Intelligence (AGI) [...] benefits all of humanity</em>” (<a href="https://openai.com/index/planning-for-agi-and-beyond/">https://openai.com/index/planning-for-agi-and-beyond/</a>. In recent years, OpenAI has <a id="_idIndexMarker092"/>formed strategic partnerships to further its research and deployment efforts. Notably, Microsoft has invested significantly in OpenAI, providing resources to support the development of advanced AI technologies. OpenAI continues to be a leading entity in AI research, striving to balance innovation with ethical considerations to ensure that the development of AI technologies aligns with the broader interests of society.</p>
<p class="normal"><strong class="keyWord">Artificial general intelligence</strong> (<strong class="keyWord">AGI</strong>) is <a id="_idIndexMarker093"/>a conceptual type of AI capable of comprehending, learning, and utilizing knowledge across diverse tasks with a proficiency comparable to human intelligence. In contrast to narrow AI systems, which are tailored for specific purposes, AGI would demonstrate human-like cognitive adaptability, allowing it to perform any intellectual task that a human can accomplish.</p>
<h2 class="heading-2" id="_idParaDest-36">The origins of OpenAI</h2>
<p class="normal">Since its <a id="_idIndexMarker094"/>establishment, OpenAI has focused its research on <strong class="keyWord">deep reinforcement learning </strong>(<strong class="keyWord">DRL</strong>), a subset <a id="_idIndexMarker095"/>of <strong class="keyWord">machine learning </strong>(<strong class="keyWord">ML</strong>) that <a id="_idIndexMarker096"/>combines <strong class="keyWord">reinforcement learning </strong>(<strong class="keyWord">RL</strong>) with <strong class="keyWord">deep neural networks</strong> (<strong class="keyWord">DNNs</strong>).</p>
<p class="normal">RL is <a id="_idIndexMarker097"/>an ML paradigm where an agent learns to make decisions by <a id="_idIndexMarker098"/>interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions and aims to maximize cumulative rewards over time.</p>
<p class="normal">Deep RL is the integration of RL and deep neural networks, or DNNs (the latter is a type of artificial neural network with multiple layers between the input and output).</p>
<p class="normal">In DRL, DNNs are used to approximate value functions, policies, or models of the environment, enabling agents to handle complex, high-dimensional state and action spaces. By combining the strengths of RL and DNNs, DRL has been successfully applied to tasks such as playing video games, robotic control, and autonomous driving, where traditional methods struggle with scalability and feature extraction.</p>
<p class="normal">OpenAI’s first contribution in that field traces back to 2016 when the company released OpenAI Gym, a toolkit for researchers to develop and test RL<strong class="keyWord"> </strong>algorithms. </p>
<p class="normal">The primary goal of Gym (now called Gymnasium) was to standardize how environments are defined in AI research, making published research more easily reproducible and providing users with a simple interface for interacting with these environments. OpenAI kept researching and contributing in that field, but its most notable achievements are related to generative models – <strong class="keyWord">Generative Pre-trained Transformers </strong>(<strong class="keyWord">GPTs</strong>).</p>
<p class="normal">A <strong class="keyWord">GPT</strong> is an advanced AI model designed <a id="_idIndexMarker099"/>to process and generate human-like text. It operates by learning patterns, structures, and context from a vast dataset of written language during its training phase. This training enables GPT to predict and generate coherent and contextually relevant text, allowing it to understand and respond to prompts in a highly natural way.</p>
<p class="normal">The “Pre-trained” aspect refers to its initial training on a broad range of language data, equipping it with a <a id="_idIndexMarker100"/>general understanding of grammar, syntax, semantics, and various styles of communication. The “Generative” capability means it can create new text that aligns with the given input, rather than simply analyzing or classifying data.</p>
<p class="normal">The “Transformer” aspect refers to a specific architectural design, featuring an advanced mechanism – called “attention” – to efficiently understand relationships between words and phrases, enabling it to handle complex language tasks with a high degree of accuracy.</p>
<h2 class="heading-2" id="_idParaDest-37">The emergence of ChatGPT</h2>
<p class="normal">OpenAI introduced their first GPT model in their paper <em class="italic">Improving Language Understanding by Generative Pre-Training</em> and christened it <strong class="keyWord">GPT-1</strong>,<strong class="keyWord"> </strong>designed to demonstrate that a language model could <a id="_idIndexMarker101"/>be pre-trained on a large corpus of text and then fine-tuned for specific tasks, achieving significant improvements in various<em class="italic"> </em><strong class="keyWord">natural language processing</strong> (<strong class="keyWord">NLP</strong>) applications.</p>
<p class="normal">Fine-tuning is the process of adapting a pre-trained model to a new task. In fine-tuning, the parameters of the pre-trained model are altered, either by adjusting the existing parameters or by adding new parameters so that they fit the data for the new task. This is done by training the model on a smaller labeled dataset that is specific to the new task. The key idea behind fine-tuning is to leverage the knowledge learned from the pre-trained model and fine-tune it to the new task, rather than training a model from scratch.</p>
<p class="normal">Soon after, OpenAI researchers released, in 2019, its successor, GPT-2. This version of the GPT was trained <a id="_idIndexMarker102"/>on a corpus called <strong class="keyWord">WebText</strong>, which at the time contained slightly over 8 million documents with a total of 40 GB of text from URLs shared in Reddit submissions with at least 3 upvotes. It had 1.2 billion parameters – ten times as many as its predecessor.</p>
<p class="normal">In the context of artificial neural networks – including GPTs – <strong class="keyWord">parameter</strong> refer to the internal variables that <a id="_idIndexMarker103"/>a model learns and adjusts during training. These parameters are crucial as they define how input data is processed through the network’s layers to produce the desired output.</p>
<p class="normal">Then, in 2020, OpenAI first announced and then released GPT-3, which, with its 175 billion parameters (roughly 21 times the entire population of Earth!), dramatically improved benchmark results over GPT-2. It was with the GPT-3 model – more precisely, with its fine-tuned version called GPT-3.5 – that we entered the era of ChatGPT in November 2022 (at its first release, ChatGPT was powered by GPT-3.5).</p>
<p class="normal">From that <a id="_idIndexMarker104"/>moment to today, OpenAI has released many new versions of its GPT series: GPT-4, GPT-4 Turbo, GPT-4 Vision (the first multimodal model), and GPT-4o, where the “o” stands for “Omni,” referring to its multimodal capabilities. At the time of writing this book (January 2025), the latest OpenAI chat models are part of the o1 family, which feature advanced reasoning capabilities that make them suitable for complex tasks or mathematical problems.</p>
<p class="normal">Starting from the next section and in the upcoming chapters, we will mainly focus on OpenAI chat models available in ChatGPT with some examples of image generation as well.</p>
<h1 class="heading-1" id="_idParaDest-38">An overview of OpenAI model families</h1>
<p class="normal">Over the last few years, OpenAI has made huge advancements in the field of model development, releasing <a id="_idIndexMarker105"/>newer model versions at great speed. In this section, we will look at the main models divided by domain:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Language models</strong>: OpenAI’s GPTs are advanced language models designed to generate <a id="_idIndexMarker106"/>text based on given prompts. They are versatile and can be used for various NLP tasks, such as text completion, translation, summarization, and coding. This is the field where OpenAI demonstrates outstanding performance, thanks to its flagship model family: the GPTs. Since November 2022, when ChatGPT was launched, OpenAI has released the following models:<ul>
<li class="bulletList">GPT-3.5-turbo, the model behind the first version of ChatGPT</li>
<li class="bulletList">GPT-4 (the first model to be able to process images as well) and GPT-4 Turbo (optimized for chats and assistants)</li>
<li class="bulletList">GPT-4o and GPT-4o mini (different in the number of parameters trained), where the letter “o” stands for “Omni,” meaning that the model can receive diverse data as input (text, images, voice)</li>
<li class="bulletList">o1 and o1 mini (different in the number of parameters), a model series that represents a significant advancement, particularly in enhanced reasoning capabilities</li>
<li class="bulletList">o3 series, built upon <a id="_idIndexMarker107"/>the capabilities of its predecessor (the o1 series), which has demonstrated superior performance on benchmarks (<a href="https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/">https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/</a>) and is very promising for future applications</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">Image models</strong>: OpenAI’s image models, like DALL-E, are designed to generate and manipulate <a id="_idIndexMarker108"/>images from textual descriptions. DALL-E models can create highly detailed and imaginative visuals, enabling users to produce unique artwork, design concepts, and more. For instance, DALL-E 3 (the latest version of the model at the time of writing) is capable of creating intricate and creative images based on detailed prompts, pushing the boundaries of what AI can do in the field of visual arts. These models are particularly useful in creative industries, digital marketing, and any field that benefits from high-quality, custom visuals (we are going to cover DALL-E in detail in <em class="italic">Chapter 8</em>).</li>
<li class="bulletList"><strong class="keyWord">Text-to-speech and speech-to-text models</strong>: OpenAI’s Whisper is a <strong class="keyWord">speech-to-text </strong>(<strong class="keyWord">STT</strong>) system. It <a id="_idIndexMarker109"/>was introduced on September 21, 2022. Trained <a id="_idIndexMarker110"/>on 680,000 hours of multilingual and multitasking data, it excels in transcribing speech across various languages and translating non-English speech into English. In addition to that, OpenAI also developed <strong class="keyWord">text-to-speech</strong> (<strong class="keyWord">TTS</strong>) models to convert written text into spoken language, providing high-quality audio outputs that are intelligible, expressive, and natural-sounding, making them suitable for a wide range of applications, from customer service bots to educational tools.<ul>
<li class="bulletList"><strong class="keyWord">STT</strong> technology converts spoken language into written text. It is <a id="_idIndexMarker111"/>commonly used in applications such as transcription services, voice assistants, and accessibility tools. Examples include converting dictated words into text on a computer or transcribing meeting recordings.</li>
<li class="bulletList"><strong class="keyWord">TTS</strong> technology <a id="_idIndexMarker112"/>converts written text into spoken words. It is widely used for accessibility (e.g., screen readers for visually impaired users), interactive voice response systems, and content narration. Examples include digital assistants reading messages or books aloud.</li>
</ul>
</li>
</ul>
<p class="normal">These models are helpful for creating voice assistants, improving accessibility for visually impaired users, and generating automated announcements.</p>
<ul>
<li class="bulletList"><strong class="keyWord">Text-to-video models</strong>: With the announcement of<strong class="keyWord"> </strong>Sora, OpenAI revealed its cutting-edge <a id="_idIndexMarker113"/>text-to-video model capable of generating realistic and imaginative video scenes from text descriptions. By adapting techniques from DALL-E and incorporating transformers, Sora can create high-fidelity videos up to one minute long. It excels in maintaining 3D consistency, object permanence, and simulating interactions within videos. While still facing challenges like accurately modeling complex physics, Sora holds significant potential for creative industries, offering new possibilities in video production and storytelling.</li>
<li class="bulletList"><strong class="keyWord">Embeddings models</strong>: Embedding models from OpenAI transform text into numerical <a id="_idIndexMarker114"/>representations called vectors (or embeddings) that capture the semantic meaning and are projected in a multi-dimensional vector space.</li>
</ul>
<p class="normal">In <em class="italic">Chapter 1</em>, we explored <a id="_idIndexMarker115"/>the role of embedding in <strong class="keyWord">retrieval augmented generation</strong> (<strong class="keyWord">RAG</strong>) scenarios and, more broadly, how this pattern is reshaping knowledge mining.</p>
<p class="normal">OpenAI’s <a id="_idIndexMarker116"/>embedding models, <strong class="keyWord">text-embedding-ada-002</strong> and <strong class="keyWord">text-embedding-3-large</strong>, offer <a id="_idIndexMarker117"/>state-of-the-art performance in tasks such as text similarity, text search, and code search by creating dense vector representations of text. These embeddings allow for the efficient and effective comparison of large text datasets, improving search accuracy and relevance.</p>
<ul>
<li class="bulletList"><strong class="keyWord">Moderation models</strong>: OpenAI’s moderation models are designed to detect and filter out <a id="_idIndexMarker118"/>inappropriate, harmful, or unsafe content in text. These models are integral to maintaining safe and respectful online environments by identifying potentially offensive or harmful language. The latest moderation model, released in <a id="_idIndexMarker119"/>September 2024, is <strong class="keyWord">omni-moderation-latest</strong>, built on top of GPT-4o, and it is capable of filtering both text and images. It helps developers and companies enforce community guidelines and prevent the spread of harmful content, thereby promoting safer digital interactions.</li>
</ul>
<p class="normal">Some of these models – specifically, language, image generation, and TTS/STT – can be used in ChatGPT, probably the most popular product that OpenAI has released as a consumer application. We are going to cover it in the next section.</p>
<h1 class="heading-1" id="_idParaDest-39">Getting started with ChatGPT</h1>
<p class="normal">In November 2022, OpenAI released the web preview of its conversational AI system, ChatGPT, to <a id="_idIndexMarker120"/>the general public. This generated a huge amount of hype among subject matter experts, organizations, and general users – to the point that, after only 5 days, the service reached 1 million users!</p>
<p class="normal">Before writing about ChatGPT, I will let it introduce itself, using a snapshot taken a few days after the launch:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_01.png"/></figure>
<p class="packt_figref">Figure 2.1: ChatGPT introducing itself in November 2022</p>
<p class="normal">It is important to <a id="_idIndexMarker121"/>note that ChatGPT is not a <strong class="keyWord">large language model</strong> (<strong class="keyWord">LLM</strong>) by itself, but rather an application through which users can interact with the underlying models. In fact, ChatGPT is, at its core, an AI-powered chatbot designed to simulate human-like conversations. It supports a variety of tasks, including writing, coding, and providing information on diverse topics. Powered by cutting-edge language models developed by OpenAI, ChatGPT has progressed through iterations like GPT-3, GPT-4, GPT-4o, and o1, continually improving its ability to understand and generate natural language. </p>
<p class="normal">In addition to the integration of the latest and greatest models, ChatGPT also extended its capabilities by incorporating external tools (like web search) and becoming an actual developer <a id="_idIndexMarker122"/>platform to build your own “GPTs,” but we will cover all those topics in the upcoming chapters.</p>
<p class="normal">As mentioned earlier, the first release of ChatGPT was built on top of an advanced language model – a fine-tuned version of GPT-3 specifically optimized for handling conversations. This fine-tuned version <a id="_idIndexMarker123"/>is called GPT-3.5 Turbo. The optimization process involved <strong class="keyWord">reinforcement learning with human feedback</strong> (<strong class="keyWord">RLHF</strong>) (<a href="https://arxiv.org/pdf/2009.01325">https://arxiv.org/pdf/2009.01325</a>), a technique <a id="_idIndexMarker124"/>that leverages human input to train the model to exhibit desirable conversational behaviors.</p>
<p class="normal">We can define RLHF as an ML approach where an algorithm learns to perform a task by receiving feedback from a human. The algorithm is trained to make decisions that maximize a reward signal provided by the human, and the human provides additional feedback to improve the algorithm’s performance. This approach is useful when the task is too complex for traditional programming or when the desired outcome is difficult to specify in advance.</p>
<p class="normal">The relevant differentiator here is that ChatGPT has been trained with humans in the loop so that it is aligned with its users. By incorporating RLHF, ChatGPT has been designed to better understand and respond to human language in a natural and engaging way.</p>
<p class="normal">Let’s now see how to start using ChatGPT.</p>
<h2 class="heading-2" id="_idParaDest-40">Creating an OpenAI account</h2>
<p class="normal">ChatGPT is available as a free application that anyone can use; however, since February 2023, OpenAI <a id="_idIndexMarker125"/>announced a series of paid programs, offering <a id="_idIndexMarker126"/>subscribers several advantages, including access to the latest models, the fastest response time, a great set of plugins, and the possibility to create your own Assistant in the GPTs playground. You can find an overview of the pricing at <a href="http://openai.com/chatgpt/pricing/">openai.com/chatgpt/pricing/</a>. In the upcoming chapters, I’ll be using the Plus version, but the majority of the hands-on examples can be replicated with the free version as well.</p>
<p class="normal">Regardless of the version you choose, to follow along with the upcoming sections you will need an OpenAI account. To create an account on OpenAI, follow these steps:</p>
<ol>
<li class="numberedList" value="1">Open a web browser and go to the OpenAI website at <a href="https://platform.openai.com/signup/">https://platform.openai.com/signup/</a>.</li>
<li class="numberedList">Provide your <a id="_idIndexMarker127"/>email address and create a password.</li>
<li class="numberedList">Once your account is created, you can start using the free version of ChatGPT.</li>
</ol>
<h2 class="heading-2" id="_idParaDest-41">ChatGPT Plus tour</h2>
<p class="normal">Let’s have <a id="_idIndexMarker128"/>a quick tour of the ChatGPT user interface at the time of writing:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_02.png"/></figure>
<p class="packt_figref">Figure 2.2: Landing page of ChatGPT at chatgpt.com</p>
<p class="normal">Let’s explore each numbered section in <em class="italic">Figure 2.2</em>:</p>
<ol>
<li class="numberedList" value="1">You can decide on the model to use behind ChatGPT. In my case, I have set GPT-4o, which is only available with a paid subscription. This is the model we are going to use throughout this book.</li>
<li class="numberedList">A set of pre-built prompts is proposed to help you familiarize yourself with the application.</li>
<li class="numberedList">The text box is the place where you can input your prompt. Note that there is a small voice icon in the right-hand corner: it indicates the possibility of interacting with the model with your voice rather than typing.</li>
<li class="numberedList">On the left-hand sidebar, you can see the list of previous chats (mine are covered) you had with ChatGPT. This is an extremely useful tool, since in each chat, through the various rounds of interactions you had with the model, you created a context ChatGPT is aware of. This means that, if you want to continue a previously <a id="_idIndexMarker129"/>started conversation, you can open the related chat and start talking with the model without describing the whole scenario again.</li>
<li class="numberedList">A nice, recently added feature of ChatGPT Plus is the possibility of having Projects, which offer a streamlined way to organize files and chats for personal use, making it easier to manage tasks that span multiple conversations. By keeping chats, files, and custom instructions all in one place, Projects help maintain order and focus.</li>
<li class="numberedList">ChatGPT Plus offers the possibility of creating GPTs, which are personalized assistants you can tailor for specific functions. You can decide to keep your GPT private or publish it in the GPTs store, where anyone can use and rate it. We are going to cover GPTs in <em class="italic">Chapter 9</em>.</li>
<li class="numberedList">Finally, ChatGPT in its Plus version now offers a set of tools that you can leverage while interacting with the model.</li>
</ol>
<p class="normal">At the time of writing this book (January 2025), the provided tools are:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Attach files</strong> to analyze custom file uploaded by the user</li>
<li class="bulletList"><strong class="keyWord">Web Search</strong> to integrate ChatGPT’s model knowledge with up-to-date information from the web</li>
<li class="bulletList">DALL-E to create images based on a query in natural language</li>
<li class="bulletList">The Canvas feature to provide a side-by-side workspace, enabling users to collaboratively draft, edit, and receive feedback on writing and coding projects alongside ChatGPT</li>
</ul>
<p class="normal">Throughout this book, we will leverage ChatGPT Plus to showcase the capabilities of the latest models and features; nevertheless, the majority of the examples that we will cover can be achieved with the free version of ChatGPT as well (which is currently powered by GPT-3.5 Turbo).</p>
<p class="normal">The ongoing developments and improvements in ChatGPT’s architecture and training methods promise to push the boundaries of language processing even further.</p>
<h3 class="heading-3" id="_idParaDest-42">The art of the possible with ChatGPT</h3>
<p class="normal">Starting from <em class="italic">Chapter 4</em>, we will cover many practical examples of how ChatGPT can be leveraged for <a id="_idIndexMarker130"/>both personal productivity and domain-specific tasks (like research, marketing, and coding). However, before landing there, let’s have a glimpse of the art of the possible with ChatGPT, starting with an example of the o1 model. A distinctive feature of the o1 models is their ability to reveal their “thinking” process. When you submit a query, a “thinking” indicator appears, and by clicking on it, you can view the steps the model took to arrive at its response. This is particularly helpful for gaining insight into how the model handles complex queries.</p>
<h3 class="heading-3" id="_idParaDest-43">Image understanding and generation</h3>
<p class="normal">The latest models available in ChatGPT are multimodal, meaning that they are capable of receiving <a id="_idIndexMarker131"/>diverse data (text and images).</p>
<p class="normal">In the context of Generative AI, <strong class="keyWord">multimodality </strong>refers <a id="_idIndexMarker132"/>to the ability of AI systems to handle, comprehend, and produce content across various forms of data, or modalities, including text, images, audio, and video. This functionality allows AI to integrate and interpret diverse inputs, resulting in more comprehensive and contextually relevant outputs.</p>
<p class="normal">Let’s consider the following example:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_03.png"/></figure>
<p class="packt_figref">Figure 2.3: Image understanding and text generation</p>
<p class="normal">In this case, I asked <a id="_idIndexMarker133"/>ChatGPT to describe the provided picture, and the model was able to generate a detailed and scientific explanation of the reason for the two liquids not mixing with each other. This implies a deep understanding of the picture, as well as a general knowledge of physics.</p>
<p class="normal">Based on this first analysis, we can also go ahead and ask it to evaluate additional scenarios:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_04.png"/></figure>
<p class="packt_figref">Figure 2.4: Going deeper into evaluation</p>
<p class="normal">These are just <a id="_idIndexMarker134"/>a few examples of the current capabilities of ChatGPT. Once again, it is important to mention that ChatGPT can be consumed with different models, and some of them don’t exhibit all the available features (for example, GPT-3.5 doesn’t take images as input). The decision of which model to use highly depends on the kind of task you want ChatGPT to address.</p>
<h3 class="heading-3" id="_idParaDest-44">Mathematical thinking</h3>
<p class="normal">Originally, LLMs used <a id="_idIndexMarker135"/>to struggle when it came to solving mathematical tasks. Nevertheless, OpenAI’s o1 model series, introduced in September 2024, has demonstrated significant advancements in mathematical reasoning compared to its predecessor, GPT-4o. For example, the o1 model (while still in preview) achieved a success rate of 83% in the <strong class="keyWord">International Mathematics Olympiad</strong> (<strong class="keyWord">IMO</strong>) qualifying exam (<a href="https://openai.com/index/introducing-openai-o1-preview/">https://openai.com/index/introducing-openai-o1-preview/</a>), a substantial improvement over GPT-4o’s 13%.</p>
<p class="normal">Let’s consider the following example:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_05.png"/></figure>
<p class="packt_figref">Figure 2.5: Mathematical ability of ChatGPT</p>
<p class="normal">As you can see, the model was not only able to read and understand the provided image but also correctly addressed the problem with smaller reasoning steps.</p>
<h3 class="heading-3" id="_idParaDest-45">Analytical skills</h3>
<p class="normal">In the previous example, we provided the model with an image, but we can go further and attach a <a id="_idIndexMarker136"/>more complex, structured file to be quantitatively analyzed. For example, we can attach to ChatGPT (powered by GPT-4o) a <code class="inlineCode">.xls</code> file and ask it to perform some financial analysis (in my case, I used a sample file available here: <a href="https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download">https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download</a>).</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_06.png"/></figure>
<p class="packt_figref">Figure 2.6: Analytical prowess exhibited by ChatGPT</p>
<p class="normal">In addition to the above answer in text format, ChatGPT can also generate graphs:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_07.png"/></figure>
<p class="packt_figref">Figure 2.7: Generating graphs using ChatGPT</p>
<p class="normal">Note that, to execute <a id="_idIndexMarker137"/>this particular task, ChatGPT leveraged a feature called Code Interpreter, which allows it to generate Python code to analyze data and run it directly against the uploaded file. An important thing to note is that you can visualize the generated code by clicking on the <strong class="keyWord">[&gt;_]</strong> icon:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_02_08.png"/></figure>
<p class="packt_figref">Figure 2.8: Code Interpreter</p>
<p class="normal">The Code Interpreter feature is extremely powerful and versatile when it comes to structured data, and it can also be leveraged to import and train advanced ML models to then make predictions on data.</p>
<h1 class="heading-1" id="_idParaDest-46">Summary</h1>
<p class="normal">In this chapter, we went through the history of OpenAI, its research fields, and the latest developments, up to ChatGPT. We also had a glimpse of the art of the possible with ChatGPT, from reasoning over complex images to executing analytical tasks.</p>
<p class="normal">In the next chapter, we begin <em class="italic">Part 2 </em>of this book, where we will see ChatGPT in action in various domains and how to unlock its potential. You will learn how to get the highest value from ChatGPT by properly designing your prompts, how to boost your daily productivity, and how it can be a great project assistant for any consumer.</p>
<h1 class="heading-1" id="_idParaDest-47">References</h1>
<ul>
<li class="bulletList">Radford, A. &amp; Narasimhan, K. (2018). <em class="italic">Improving language understanding by generative pre-training</em>. <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li>
<li class="bulletList">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). <em class="italic">Attention Is All You Need</em>. arXiv. <a href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a> </li>
<li class="bulletList">OpenAI. <em class="italic">Fine-Tuning Guide</em>. OpenAI platform documentation. https:// <a href="http://platform.openai.com/docs/guides/fine-tuning">platform.openai.com/docs/guides/fine-tuning</a></li>
</ul>
<h1 class="heading-1">Join our communities on Discord and Reddit</h1>
<p class="normal">Have questions about the book or want to contribute to discussions on Generative AI and LLMs? Join our Discord server at <a href="Chapter_2.xhtml">https://packt.link/I1tSU</a> and our Reddit channel at <a href="Chapter_2.xhtml">https://packt.link/jwAmA</a> to connect, share, and collaborate with like-minded enthusiasts.</p>
<p class="normal"><img alt="" src="img/Discord.png"/> <img alt="" src="img/QR_Code757615820155951000.png"/></p>
</div>
</body></html>