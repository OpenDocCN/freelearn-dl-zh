<html><head></head><body>
		<div><div></div>
		</div>
		<div><h1 id="_idParaDest-134"><a id="_idTextAnchor136"/>6. Computer Vision and Image Processing</h1>
		</div>
		<div><p class="callout-heading">Overview</p>
			<p class="callout">This chapter describes the Amazon Rekognition service for analyzing the content of images using various techniques. You will be introduced to the Rekognition service for image analysis using computer vision, through which you will be able to detect objects and scenes in images. You will learn how to analyze faces and recognize celebrities in images. You will also be able to compare faces in different images to see how closely they match with each other.</p>
			<p class="callout">By the end of this chapter, you will be able to apply the Amazon vision and image processing AI services in fields such as biolog<a id="_idTextAnchor137"/>y, astronomy, security, and so on.</p>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor138"/>Introduction</h1>
			<p>In the preceding chapters, you have done lots of interesting exercises and activities with the <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) <strong class="bold">Artificial Intelligence</strong> (<strong class="bold">AI</strong>) and <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) services. You combined the serverless computing paradigm and conversational AI to construct chatbots, as well as a fully functional contact center that enables anyone to converse with the chatbots through a voice interface that's available by dialing a local phone number. You also learned about text analysis and topic modeling, all using the AWS services.</p>
			<p>In this chapter, you will use the Amazon Rekognition service to perform various image processing tasks. First, you will identify objects and scenes within images. Then, you will test whether images should be flagged as needing content moderation. Next, you will analyze faces using Rekognition. You will also recognize celebrities and well-known people in images. You will compare faces that appear in different images and settings (for example, in groups or isolation) and recognize the same people in different images. Finally, you will extract text from images that might have some text displayed in them.</p>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor139"/>Amazon Rekognition Basics</h1>
			<p>Amazon Rekognition is a deep learning-based visual analysis service from AWS that allows you to perform image analysis on pictures and videos using machine learning. It is built on the same scalable infrastructure as AWS itself and uses deep learning technology to be able to analyze billions of images daily if required. It is also being updated constantly by Amazon and is learning new labels and features.</p>
			<p>Some of the use cases for Amazon Rekognition are as follows:</p>
			<ul>
				<li>Searching across a library of image content using text keywords.</li>
				<li>Confirming user identities by comparing live images with reference ones.</li>
				<li>Analyzing trends based on public images, including the sentiments and emotions of the people in the images.</li>
				<li>Detecting explicit or suggestive content and automatically filtering it for your purposes.</li>
				<li>Detecting and retrieving text from images.<p class="callout-heading">Note</p><p class="callout">Amazon Rekognition is also a <strong class="bold">HIPAA</strong>-eligible service for healthcare applications. If you wish to protect your data under HIPAA, you will need to contact Amazon customer support and fill out a <strong class="bold">Business Associate Addendum </strong>(<strong class="bold">BAA</strong>). For more information about HIPAA, go to the following link: <a href="https://aws.amazon.com/compliance/hipaa-compliance/">https://aws.amazon.com/compliance/hipaa-compliance/</a>.</p></li>
			</ul>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor140"/>Free Tier Information on Amazon Rekognition</h2>
			<p>For this book, you will be using the free tier services of Amazon Rekognition. Be aware of the limits of the free tier services and the pricing options. These are the free services you can use for image processing: </p>
			<ul>
				<li>New Amazon Rekognition clients can break down up to 5,000 pictures a year.</li>
				<li>With the complimentary plan, you can utilize all of Amazon Rekognition's APIs and use up to 1,000 images that have faces free of charge.<p class="callout-heading">Note</p><p class="callout">You should not need to use more than the free tier limits, but if you do go beyond the limits of the free tier, you will get charged by Amazon at the rates published at this link: <a href="https://aws.amazon.com/rekognition/pricing/">https://aws.amazon.com/rekognition/pricing/</a>.</p></li>
			</ul>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor141"/>Rekognition and Deep Learning</h1>
			<p>Deep learning is a branch of artificial intelligence and a subfield of machine learning. Deep learning works by inferring high-level abstractions from raw data by using a deep neural network graph with many layers of processing.</p>
			<p>Deep learning structures such as <strong class="bold">Convolutional Neural Networks</strong> (<strong class="bold">CNNs</strong>) and <strong class="bold">Recurrent Neural Networks </strong>(<strong class="bold">RNNs</strong>) have been employed in natural language processing, audio recognition, speech recognition, and computer vision to deliver significant results. <strong class="bold">Neural Machine Translation</strong> has replaced all human-curated translation engines, object detection in autonomous cars uses CNN-based architectures extensively, and conversational AI is powering a variety of customerÂ interactions.</p>
			<p>The Rekognition service employs deep learning to provide its various features behind the scenes. It uses pre-trained models so that users do not have to train the system. The exact details are proprietary and confidential to Amazon, but we will learn how it works and how to use Rekognition in this chapter. As we mentioned earlier, one interesting aspect of Amazon Rekognition is the fact that the algorithms are monitored and trained periodically to increase their accuracy and capabilities. It can also be extended with custom labels and models trained with your images.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For any questions you have, the Amazon Rekognition FAQ page (<a href="https://aws.amazon.com/rekognition/faqs/">https://aws.amazon.com/rekognition/faqs/</a>) is an excellent resource.</p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor142"/>Detecting Objects and Scenes in Images</h2>
			<p>Amazon Rekognition provides a feature that can detect objects and scenes in an image and label them. This label may be an object, scene, or concept such as a person, water, sand, a beach (scene), and the outdoors (concept).</p>
			<p>Each label comes with a confidence score, which measures, on a scale from 0 to 100, the probability that the service got the correct answer for that label. This allows you or your application to judge the threshold against which to allow or discard results for itself.</p>
			<p>Rekognition supports thousands of labels from categories such as those shown in the following table:</p>
			<div><div><img src="img/B16061_06_01.jpg" alt="Figure 6.1: Labels supported by Amazon Rekognition&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1: Labels supported by Amazon Rekognition</p>
			<p>Additionally, Amazon is continuously training the system to recognize new ones, and you can request labels that you might wish to use that are not in the system through Amazon customer support.</p>
			<p>To create an Amazon Rekognition analysis of a sample image, you can do the following:</p>
			<ol>
				<li>Navigate to the Amazon Rekognition Service web page in the <code>AWS Management Console</code> and click <code>Services</code> at the top of the left-hand side. It also has a search box:<div><img src="img/B16061_06_02.jpg" alt="Figure 6.2: Selecting the Rekognition service in the AWS Management Console&#13;&#10;"/></div><p class="figure-caption">Figure 6.2: Selecting the Rekognition service in the AWS Management Console</p></li>
				<li>You can find Rekognition under the <code>Machine Learning</code> section. When you are on the Rekognition page, click on the <code>Object and scene detection</code> link in the left-hand side toolbar to navigate to the <code>Object and scene detection</code> page:<div><img src="img/B16061_06_03.jpg" alt="Figure 6.3: Amazon Rekognition service page&#13;&#10;"/></div><p class="figure-caption">Figure 6.3: Amazon Rekognition service page</p></li>
				<li>Next, choose the textbox under the <code>Use your own image</code> panel and enter the following URL: <a href="https://images.unsplash.com/photo-1540253208288-6a6c32573092?w=800">https://images.unsplash.com/photo-1540253208288-6a6c32573092?w=800</a>:<div><img src="img/B16061_06_04.jpg" alt="Figure 6.4: Use the image URL input textbox&#13;&#10;"/></div><p class="figure-caption">Figure 6.4: Use the image URL input textbox</p><p>The result for the image is as follows:</p><p> </p><div><img src="img/B16061_06_05.jpg" alt="Figure 6.5: Results for the sample image&#13;&#10;"/></div><p class="figure-caption">Figure 6.5: Results for the sample image</p></li>
				<li>You can see that, within the image, the objects that have been detected with greater than 90% confidence are as follows:<p><code>Nature</code></p><p><code>Outdoors</code></p><p><code>Sky</code></p><p><code>Sun</code></p><p><code>Dawn</code></p><p><code>Sunset</code></p></li>
				<li>Click the <code>Show more</code> link to show more results with lower confidence levels. This will show more objects have been detected:<div><img src="img/B16061_06_06.jpg" alt="Figure 6.6: Full set of labels for our sample image from Object and scene detection&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.6: Full set of labels for our sample image from Object and scene detection</p>
			<p>You can choose the threshold amount of the confidence level at which you would like to cut off the results for your application.</p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor143"/>Exercise 6.01: Detecting Objects and Scenes Using Your Images</h2>
			<p>In this exercise, we will detect objects and scenes of custom images using Amazon Rekognition. The custom images can be either taken from online sources, or you can upload them from your local machine. The following are the steps for detecting objects and scenes:</p>
			<ol>
				<li value="1">Navigate to the Amazon Rekognition service page from the AWS Management Console or go directly to the following URL: <a href="https://console.aws.amazon.com/rekognition">https://console.aws.amazon.com/rekognition</a>.</li>
				<li>Click the <code>Object and scene detection</code> link in the toolbar to navigate to the <code>Object and scene detection</code> page.</li>
				<li>Next, choose the textbox under the <code>Use your own image</code> panel.</li>
				<li>Enter the following URL so that you have an image to analyze: <a href="https://images.unsplash.com/photo-1522874160750-0faa95a48073?w=800">https://images.unsplash.com/photo-1522874160750-0faa95a48073?w=800</a>. The following is the image on the Rekognition page. You can see that it was able to zero-in on the image:<div><img src="img/B16061_06_07.jpg" alt="Figure 6.7: The first test image for Object and scene detection &#13;&#10;"/></div><p class="figure-caption">Figure 6.7: The first test image for Object and scene detection </p><p class="callout-heading">Note</p><p class="callout">We have collected images from a stock photo site called <a href="https://unsplash.com/">https://unsplash.com/</a>, which contains photos that can be downloaded for free and used without restrictions for this book. Always obey copyright laws and be mindful of any restrictions or licensing fees that might apply in the jurisdiction where you reside (if applicable). You may view the license for images from unsplash.com here: <a href="https://unsplash.com/license">https://unsplash.com/license</a>.</p></li>
				<li>You may view the results of the object detection under the <code>Results</code> panel on the right-hand side of the image. In this case, it is an image of a camera, and the results should look as follows:<div><img src="img/B16061_06_08.jpg" alt="Figure 6.8: Results for the first test image from Object and scene detection&#13;&#10;"/></div><p class="figure-caption">Figure 6.8: Results for the first test image from Object and scene detection</p></li>
				<li>As you can see, the results are quite accurate. Next, you can try the following images and verify that the results are as shown in the tables that immediately follow each image, that is, <a href="https://images.unsplash.com/photo-1517941875027-6321f98198ed?w=800">https://images.unsplash.com/photo-1517941875027-6321f98198ed?w=800</a> and <a href="https://images.unsplash.com/photo-1500111709600-7761aa8216c7?w=800">https://images.unsplash.com/photo-1500111709600-7761aa8216c7?w=800</a>.<p>The following are the images. This is the second test image:</p><div><img src="img/B16061_06_09.jpg" alt="Figure 6.9: The second test image for Object and scene detection&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.9: The second test image for Object and scene detection</p>
			<p>The following are the results of the second image provided:</p>
			<div><div><img src="img/B16061_06_10.jpg" alt="Figure 6.10: Results for the second test image from Object and scene detection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.10: Results for the second test image from Object and scene detection</p>
			<p>This is the third test image:</p>
			<div><div><img src="img/B16061_06_11.jpg" alt="Figure 6.11: The third test image for Object and scene detection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.11: The third test image for Object and scene detection</p>
			<p>The following are the results of the third image provided:</p>
			<div><div><img src="img/B16061_06_12.jpg" alt="Figure 6.12: Results for the third test image from Object and scene detection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.12: Results for the third test image from Object and scene detection</p>
			<p>The results for the second image did indicate it was a human head with &gt; <code>83%</code> confidence. Looking at the third image of the Golden Gate Bridge, it had more classes before <code>Bridge</code> with <code>96.5%</code> confidence.</p>
			<h1 id="_idParaDest-141"><a id="_idTextAnchor144"/>Image Moderation</h1>
			<p>In addition to object and scene detection, Rekognition also provides the ability to filter out objectionable content. You can use moderation labels to give point-by-point subclassifications, enabling you to tweak the channels that you use to figure out what sorts of pictures you consider satisfactory or shocking. <code>DetectModerationLabels</code> operation to detect unsafe content inÂ images.</p>
			<p>You can utilize this component to enhance photograph-sharing destinations, gatherings, dating applications, content stages for youngsters, online business stages and commercial centers, and more. In this book, we will not use any adult or nude images, but we can show the use of this feature with content that may be considered racy or suggestive in some locales featuring women in revealing clothing such as swimsuits or clubwear. </p>
			<p>The images are blurred by default in this section, so you do not have to view them unless you press the <code>View Content</code> button.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you find any racy or suggestive images offensive, please skip this section based on your own personal, moral, religious, or cultural norms.</p>
			<p>Amazon Rekognition uses a hierarchical taxonomy to label categories of explicit and suggestive content. The two top-level categories are <strong class="bold">Explicit Nudity</strong> and <strong class="bold">Suggestive</strong>. Each top-level category has many second-level categories. The types of content that are detected and flagged using this feature are as follows:</p>
			<div><div><img src="img/B16061_06_13.jpg" alt="Figure 6.13: Content type categories&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.13: Content type categories</p>
			<p>To create an <code>Image Moderation</code> of a sample image, you can do the following:</p>
			<ol>
				<li value="1">Navigate to the Amazon Rekognition service page in the AWS Management Console or go directly to the following URL: <a href="https://console.aws.amazon.com/rekognition">https://console.aws.amazon.com/rekognition</a>.</li>
				<li>Click the <code>Image Moderation</code> link in the toolbar to navigate to the <code>Image Moderation</code> page.</li>
				<li>You will see sample images on the bottom left. Click one of them.</li>
				<li>You will notice right away that the content is blurred, as shown in the following screenshot. The image being analyzed is the first image to the left, which was already selected. You will see that the service has correctly identified <code>Suggestive</code> content in the image of the <code>Female Swimwear Or Underwear</code> type with a confidence of <code>94.9%:</code><div><img src="img/B16061_06_14.jpg" alt="Figure 6.14: Results for image moderation&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.14: Results for image moderation</p>
			<p>With this, we've seen how Amazon Rekognition can filter out suggestive content, but let's see how it does when it comes to detecting objectionable content in images.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor145"/>Exercise 6.02: Detecting Objectionable Content in Images</h2>
			<p>In this exercise, we will detect objectionable content in images. You can try this service on your images. We have selected three images that we will try out with this feature. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Copy and paste or type the following URL into the <code>Use image URL</code> textbox under the <code>Use your own image</code> section at the bottom of the page, and press the <code>Go</code> button to receive results from the service â <a href="https://images.unsplash.com/photo-1525287957446-e64af7954611?w=800">https://images.unsplash.com/photo-1525287957446-e64af7954611?w=800</a>:<div><img src="img/B16061_06_04.jpg" alt="Figure 6.15: Use image URL upload textbox&#13;&#10;"/></div><p class="figure-caption">Figure 6.15: Use image URL upload textbox</p></li>
				<li>You should receive a result stating that the service has found <code>Female Swimwear Or Underwear</code> content with a 99.4% degree of confidence:<div><div><img src="img/B16061_06_16.jpg" alt="Figure 6.16: Result that the image moderation service has found&#13;&#10;"/></div><p class="figure-caption">Figure 6.16: Result that the image moderation service has found</p></li>
				<li>The image <code>URL</code> to provide to the service is <a href="https://images.unsplash.com/photo-1509670811615-bb8b07cb3caf?w=800">https://images.unsplash.com/photo-1509670811615-bb8b07cb3caf?w=800</a>.</li>
				<li>Just as before, enter it in the <code>Use image URL</code> textbox and press the <code>Go</code> button. This image has no objectionable content:<div><img src="img/B16061_06_17.jpg" alt="Figure 6.17: First test image for image moderation&#13;&#10;"/></div><p class="figure-caption">Figure 6.17: First test image for image moderation</p><p>You should see that Rekognition correctly returns no results:</p><div><img src="img/B16061_06_18.jpg" alt="Figure 6.18: Results of the first test image from image moderation&#13;&#10;"/></div><p class="figure-caption">Figure 6.18: Results of the first test image from image moderation</p></li>
				<li>Finally, we will use an image that should, again, return some results: <a href="https://images.unsplash.com/photo-1518489913881-199b7c7a081d?w=800">https://images.unsplash.com/photo-1518489913881-199b7c7a081d?w=800</a>.<p>This one should have, once again, correctly been identified as containing content with <code>Female Swimwear Or Underwear</code> with a 99.6% degree of confidence:</p><div><img src="img/B16061_06_19.jpg" alt="Figure 6.19: Results of the second provided image for image moderation&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.19: Results of the second provided image for image moderation</p>
			<p>As you've seen, Amazon Rekognition has powerful image analysis capabilities â including content moderation. As a suggestion, you can try some more images that may or may not be suggestive and check the results. You might find some gaps in the object detection deep learning algorithms.</p>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor146"/>Facial Analysis</h1>
			<p>Rekognition can perform a more detailed analysis of faces as well. Given an image with a detectable face, it can tell whether the face is male or female, the age range of the face, whether or not the person is smiling and appears to be happy, and whether they are wearing glasses or not.</p>
			<p>It can also detect more detailed information, such as whether the eyes and mouth are open or closed, and whether or not the person has a mustache or a beard.</p>
			<p>To create a facial analysis of a sample image, you can do the following: </p>
			<p class="callout-heading">Note</p>
			<p class="callout">Click on the <code>Facial Analysis</code> link in the left toolbar to navigate to the <code>Facial Analysis</code> page.</p>
			<ol>
				<li value="1">We will use the upload capability to upload images and analyze the images:<div><img src="img/B16061_06_20.jpg" alt="Figure 6.20: The image upload button&#13;&#10;"/></div><p class="figure-caption">Figure 6.20: The image upload button</p></li>
				<li>The first image to be analyzed can be found at <a href="https://packt.live/3f5ipH0">https://packt.live/3f5ipH0</a>.<p>You can either save the image onto your disk or download this book's GitHub repository, as we covered in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</p></li>
				<li>Click <code>Upload</code>; you will be shown the standard explorer window. Navigate to the directory where you have the <code>Chapter06</code> folder and select the <code>Rekognition-05.jpeg</code> file:<div><img src="img/B16061_06_21.jpg" alt="Figure 6.21: The explorer with the upload window&#13;&#10;"/></div><p class="figure-caption">Figure 6.21: The explorer with the upload window</p></li>
				<li>For this image, you will see that the main image box displays a bounding rectangle that shows the region in which the face was detected. Within the bounding box, there are also three dots to identify the locations of key facial features â the mouth and nose:<div><img src="img/B16061_06_22.jpg" alt="Figure 6.22: First sample image for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.22: First sample image for facial analysis</p></li>
				<li>Under the <code>Results</code> section to the right of the image, you will see that Rekognition has detected the following attributes of the face in the image:<div><img src="img/B16061_06_23.jpg" alt="Figure 6.23: Results of the first sample image for facial analysis&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.23: Results of the first sample image for facial analysis</p>
			<p>You can click the <code>Show more</code> link in order to look at the other attributes that have also been identified.</p>
			<p>All these identified qualities have an extremely high degree of confidence, showing that the service is very confident about its findings.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor147"/>Exercise 6.03: Analyzing Faces with Your Own Images</h2>
			<p>In this exercise, you have been provided with three images in the book's GitHub repository (<a href="https://packt.live/31X6w1Z">https://packt.live/31X6w1Z</a>) so that you can try out the Amazon Rekognition service with sample images. The images are provided courtesy of <a href="https://unsplash.com/">https://unsplash.com/</a> and Pinterest. Let's find out if they can identify the prominent facial attributes. Follow these steps to complete this exercise:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Click the <code>Facial Analysis</code> link in the left toolbar to navigate to the <code>Facial Analysis</code> page.</p>
			<ol>
				<li value="1">We will use the upload capability to upload images and analyze them:<div><img src="img/B16061_06_24.jpg" alt="Figure 6.24: The image upload button&#13;&#10;"/></div><p class="figure-caption">Figure 6.24: The image upload button</p></li>
				<li>The first image to be analyzed can be found at <a href="https://packt.live/3edZZCx">https://packt.live/3edZZCx</a>.<p>You can either save the image onto your disk or download this book's GitHub repository, as we covered in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</p></li>
				<li>Click <code>Upload</code> and it will show the standard explorer window. Navigate to the directory where you have the <code>Chapter06</code> folder and select the <code>Rekognition-01.jpeg</code> file:<div><img src="img/B16061_06_25.jpg" alt="Figure 6.25: The explorer with the upload window&#13;&#10;"/></div><p class="figure-caption">Figure 6.25: The explorer with the upload window</p></li>
				<li>You can see from the bounding box and the dots that Rekognition is able to recognize the face easily:<div><img src="img/B16061_06_26.jpg" alt="Figure 6.26: Bounding box for the first image provided for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.26: Bounding box for the first image provided for facial analysis</p></li>
				<li>Under the <code>Results</code> section, it quite accurately displays the attributes of the face in the image as well:<div><img src="img/B16061_06_27.jpg" alt="Figure 6.27: Results for the first image provided for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.27: Results for the first image provided for facial analysis</p></li>
				<li>Let's see if Recognition can detect multiple faces and the facial features of each face. The second image contains multiple faces. The file can be found at <a href="https://packt.live/3gDSzu5">https://packt.live/3gDSzu5</a>.</li>
				<li>Click <code>Upload</code> and it will show the standard explorer window. Navigate to the directory where you have the <code>Chapter06</code> folder and select the <code>Rekognition-02.jpeg</code> file.</li>
				<li>Rekognition once again does a good job of identifying the faces:<div><img src="img/B16061_06_28.jpg" alt="Figure 6.28: Bounding box for the second image provided for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.28: Bounding box for the second image provided for facial analysis</p></li>
				<li>Now, the <code>Results</code> view has a right arrow button and shows the first face:<div><img src="img/B16061_06_29.jpg" alt="Figure 6.29: Results for the second image provided for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.29: Results for the second image provided for facial analysis</p></li>
				<li>Click the right arrow and you will get the details of the second face:<div><img src="img/B16061_06_30.jpg" alt="Figure 6.30: Results for the second image provided for facial analysis â second face.&#13;&#10;"/></div><p class="figure-caption">Figure 6.30: Results for the second image provided for facial analysis â second face.</p></li>
				<li>Finally, we will give Rekognition an image with a neutral emotion to see how it does. We will be using the image at the following link â <a href="https://images.unsplash.com/photo-1472099645785-5658abf4ff4e?w=1000">https://images.unsplash.com/photo-1472099645785-5658abf4ff4e?w=1000</a>:<div><img src="img/B16061_06_31.jpg" alt="Figure 6.31: Third image provided for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.31: Third image provided for facial analysis</p></li>
				<li>As expected, the service can recognize both males and females. It identifies the face with the bounding box:<div><img src="img/B16061_06_32.jpg" alt="Figure 6.32: Bounding box for the third image provided for facial analysis&#13;&#10;"/></div><p class="figure-caption">Figure 6.32: Bounding box for the third image provided for facial analysis</p></li>
				<li>It also displays results with a high degree of confidence (<code>97.7</code>%) that the face is male. It also updates the age range accordingly:<div><img src="img/B16061_06_33.jpg" alt="Figure 6.33: Results for the third image provided for facial analysis&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.33: Results for the third image provided for facial analysis</p>
			<p>It is <code>84.2%</code> confident that the man is not smiling, and we can see from the image that he is not smiling very much, if at all. Finally, the service is <code>97.5%</code> sure that he is wearing glasses, but it also says with <code>90.2% </code>confidence that he is not wearing sunglasses. It shows that there is still room for lots of improvement and we should apply human logic and rules to validate the results from the image detection services. In this case, we can take the one with the larger confidence score (that is, <code>wearing glasses</code>) to show that we can use the relative score to evaluate the results.</p>
			<p>As we all know, humans are born with extremely good object detection and image analysis capabilities, which we enhance as we grow. But this is very hard for machines as they do not have the capability to reason or perform semantic analysis. The image analysis domain is relatively new, with the bulk of advances coming in the last 5 to 6 years. New algorithms are being researched, new ways of training are being explored, and optimizations are being sought. Therefore, Amazon Rekognition is extremely effectiveâit has wrapped the algorithms and mechanisms in a set of useful and practical interfaces, masking the underlying algorithmic and computer theoretic complexities, and Rekognition learns and evolves by leveraging the current best practices and research. In this section, you were introduced to the capabilities of Amazon Rekognition's image analysis service. You will see more regarding this service in the following sections.</p>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor148"/>Celebrity Recognition</h1>
			<p>Rekognition provides us with the ability to recognize and label celebrities and other famous people in images. This includes well-known individuals from a variety of fields, such as sports, business, politics, media, and entertainment.</p>
			<p>It is important to remember that Rekognition can only recognize faces that it has been trained on, and so does not cover a full, exhaustive list of celebrities. However, since Amazon continues to train the system, it is constantly adding new faces to the service.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Click the <code>Celebrity recognition</code> link in the left toolbar to navigate to the <code>Celebrity recognition</code> page.</p>
			<p>To create a celebrity recognition of a sample image, you can do the following: </p>
			<ol>
				<li value="1">Click the <code>Upload</code> button. We will use a picture whose file can be found at <a href="https://packt.live/38CmbVM">https://packt.live/38CmbVM</a>. You can either save the image onto your disk or download this book's GitHub repository, as described in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</li>
				<li>It will show the standard explorer window. Navigate to the directory where you have the <code>Chapter06</code> folder and select the <code>Rekognition-04.jpeg</code> file:<div><img src="img/B16061_06_34.jpg" alt="Figure 6.34: The explorer with the upload window&#13;&#10;"/></div><p class="figure-caption">Figure 6.34: The explorer with the upload window</p></li>
				<li>Amazon Rekognition does an excellent job of recognizing Nichelle Nichols (famous for playing Lieutenant Nyota Uhura in the Star Trek movies):<div><img src="img/B16061_06_35.jpg" alt="Figure 6.35: First sample image for celebrity recognition, with results&#13;&#10;"/></div><p class="figure-caption">Figure 6.35: First sample image for celebrity recognition, with results</p></li>
				<li>Clicking the <code>Learn More</code> link in the <code>Results</code> box takes you to the IMDb page for Nichelle Nichols:<div><img src="img/B16061_06_36.jpg" alt="Figure 6.36: The Learn More link for the first sample image&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.36: The Learn More link for the first sample image</p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor149"/>Exercise 6.04: Recognizing Celebrities in Your Images</h2>
			<p>In this exercise, we will use another site that has a larger collection of celebrity images. You can also use these for free without restrictions. You can also try out this service on your own images. We have selected three images that we will try out with this feature.</p>
			<p>You may view the license for images from pexels.com here: <a href="https://www.pexels.com/creative-commons-images/">https://www.pexels.com/creative-commons-images/</a>. Follow these steps to complete this exercise:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Click the <code>Celebrity recognition</code> link in the left toolbar to navigate to the <code>Celebrity recognition</code> page.</p>
			<ol>
				<li value="1">Copy and paste or type a <code>URL</code> into the <code>Use image URL</code> textbox under the <code>Use your own image</code> section at the bottom of the page, and press the <code>Go</code> button to receive results from the service:<div><img src="img/B16061_06_04.jpg" alt="Figure 6.37: The Use image URL input textbox&#13;&#10;"/></div><p class="figure-caption">Figure 6.37: The Use image URL input textbox</p></li>
				<li>The first URL to enter into the textbox is <a href="https://images.pexels.com/photos/276046/pexels-photo-276046.jpeg">https://images.pexels.com/photos/276046/pexels-photo-276046.jpeg</a>:<div><img src="img/B16061_06_38.jpg" alt="Figure 6.38: First image provided for celebrity recognition&#13;&#10;"/></div><p class="figure-caption">Figure 6.38: First image provided for celebrity recognition</p></li>
				<li>This is an image of the well-known actress Charlize Theron. The <code>Results</code> section will display her name and a <code>Learn More</code> link, which will take you to her IMDb page:<div><img src="img/B16061_06_39.jpg" alt="Figure 6.39: The Learn More link for the first image provided for celebrity recognition&#13;&#10;"/></div><p class="figure-caption">Figure 6.39: The Learn More link for the first image provided for celebrity recognition</p></li>
				<li>The second image you can enter in the textbox can be found at <a href="https://images.pexels.com/photos/2281/man-person-suit-united-states-of-america.jpg?w=800">https://images.pexels.com/photos/2281/man-person-suit-united-states-of-america.jpg?w=800</a> and gives us the following image:<div><img src="img/B16061_06_40.jpg" alt="Figure 6.40: The second image provided for celebrity recognition&#13;&#10;"/></div><p class="figure-caption">Figure 6.40: The second image provided for celebrity recognition</p></li>
				<li>This image displays former US President Barack Obama. Rekognition can easily detect him as well and displays his name in the <code>Results</code> section. The <code>Learn More</code> link, once again, links to his IMDb page:<div><img src="img/B16061_06_41.jpg" alt="Figure 6.41: The Learn More link for the second image provided for celebrity recognition&#13;&#10;"/></div><p class="figure-caption">Figure 6.41: The Learn More link for the second image provided for celebrity recognition</p></li>
				<li>The final image contains multiple famous people. Enter the following URL into Rekognition: <a href="https://images.pexels.com/photos/70550/pope-benedict-xvi-president-george-bush-laura-bush-andrews-afb-70550.jpeg?w=800">https://images.pexels.com/photos/70550/pope-benedict-xvi-president-george-bush-laura-bush-andrews-afb-70550.jpeg?w=800</a>. This gives us the following image:<div><img src="img/B16061_06_42.jpg" alt="Figure 6.42: The third image provided for celebrity recognition, with three bounding boxes&#13;&#10;"/></div><p class="figure-caption">Figure 6.42: The third image provided for celebrity recognition, with three bounding boxes</p></li>
				<li>In the <code>Results</code> section, you can see that Rekognition recognizes all three famous people in the image:<ul><li>George W Bush</li><li>Pope Benedict XVI</li><li>Laura Bush<p>The following image shows the result of celebrity recognition:</p><div><img src="img/B16061_06_43.jpg" alt="Figure 6.43: Results of the third image provided for celebrity recognition&#13;&#10;"/></div></li></ul></li>
			</ol>
			<p class="figure-caption">Figure 6.43: Results of the third image provided for celebrity recognition</p>
			<p>The <code>Learn More</code> links under their names go to their respective IMDb pages. As we have done previously, we can verify this by clicking on them.</p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor150"/>Face Comparison</h1>
			<p>Rekognition allows you to compare faces in two images. This is mainly for the purpose of identifying which faces are the same in both images. As an example use case, this can also be used for comparing images with people against their personnel photo.</p>
			<p>This section demonstrates industry standards so that you can utilize Amazon Rekognition to analyze faces inside an arrangement of pictures with different faces in them. When you indicate a <code>Reference face</code> (source) and a <code>Comparison face</code> (target) picture, Rekognition thinks about the biggest face in the source picture (that is, the reference) with up to 100 countenances recognized in the objective picture (that is, the examination images) and, after that, discovers how intently the face in the source picture matches with the appearances in the target picture. The closeness score for every examination is shown in the <code>Results</code> sheet.</p>
			<p>Some restrictions on the usage of this feature are as follows:</p>
			<ul>
				<li>If the source image contains multiple faces, the largest face is used to compare against the target image.</li>
				<li>The target image can contain up to 15 faces. The detected face in the source image is compared against each of the faces detected in the target image.<p class="callout-heading">Note</p><p class="callout">Click the <code>Face comparison</code> link in the left toolbar to navigate to the <code>Face comparison</code> page.</p></li>
			</ul>
			<p>With the face comparison feature, there are two sections with images, side by side. You can choose to compare images in the left-hand section with images in the right-hand section. To create a facial analysis of a sample image, you can do the following: </p>
			<ol>
				<li value="1">Go to the textbox under the <code>Use your own image</code> panel on the left-hand side.</li>
				<li>Enter the following URL to get an image to analyze: <a href="https://images.unsplash.com/photo-1524788038240-5fa05b5ee256?w=800">https://images.unsplash.com/photo-1524788038240-5fa05b5ee256?w=800</a>.</li>
				<li>Go to the textbox under the <code>Use your own image</code> panel on the right-hand side.</li>
				<li>Enter the following URL to get an image to analyze â <a href="https://images.unsplash.com/photo-1524290266577-e90173d9072a?w=800">https://images.unsplash.com/photo-1524290266577-e90173d9072a?w=800</a>.<div><img src="img/B16061_06_44.jpg" alt="Figure 6.44: First sample images provided for face comparison&#13;&#10;"/></div><p class="figure-caption">Figure 6.44: First sample images provided for face comparison</p></li>
				<li>With the default selections, in the <code>Results</code> section, you will see that it identifies the girl in the left image on the right-hand side with a <code>99.8%</code> degree of confidence, as shown here:<div><img src="img/B16061_06_45.jpg" alt="Figure 6.45: Results for the first sample images provided for face comparison&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.45: Results for the first sample images provided for face comparison</p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor151"/>Activity 6.01: Creating and Analyzing Different Faces in Rekognition</h2>
			<p>In this activity, you can try out Rekognition with your own images. For example, we have provided links to two sets of images that display the same people. You can enter the sets of images into the left- (comparison) and right-hand (comparison) sides by using the <code>Upload</code> button. Remember that there are two this time, so there are two <code>Go</code> buttons to press as well. Follow these steps to complete this activity:</p>
			<ol>
				<li value="1">Navigate to the Amazon Recognition service from the Amazon Management Console and choose <code>Face comparison</code> from the left toolbar.</li>
				<li>You will see two sets of <code>Upload</code> buttons, as shown in the following screenshot:<div><img src="img/B16061_06_46.jpg" alt="Figure 6.46: Upload buttons for face comparison&#13;&#10;"/></div><p class="figure-caption">Figure 6.46: Upload buttons for face comparison</p></li>
				<li>Upload the first set of images to Rekognition so that it can recognize and compare the faces. We have three images, <code>face-01-01</code>, <code>face-02-02</code>, and <code>face-01-03</code>, under different lighting conditions and angles. Interestingly, Rekognition can detect that they are all the same face!<p>The images to be analyzed can be found in the <a href="https://packt.live/31X6IP6">https://packt.live/31X6IP6</a> and <a href="https://packt.live/3ebuSYz">https://packt.live/3ebuSYz</a>, <a href="https://packt.live/2ZLseUd">https://packt.live/2ZLseUd</a> files.</p><p>You can either save the images onto your disk or download this book's GitHub repository, as we covered in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>:</p><div><img src="img/B16061_06_47.jpg" alt="Figure 6.47: The explorer with the upload window&#13;&#10;"/></div><p class="figure-caption">Figure 6.47: The explorer with the upload window</p></li>
				<li>Upload <a href="https://packt.live/31X6IP6">https://packt.live/31X6IP6</a> and <a href="https://packt.live/2ZLseUd">https://packt.live/2ZLseUd</a>.</li>
				<li>Compare the first set of images with the following parameters:<ul><li>Degree of confidence</li><li>Comparing with different angles</li><li>Lighting</li><li>Position of glasses on the face</li></ul></li>
				<li>Compare the second set of images for face similarity parameters.<p class="callout-heading">Additional Challenge</p><p class="callout">As an additional challenge you can try the same steps on these two images from Unsplash as well: <a href="https://images.unsplash.com/photo-1526510747491-58f928ec870f">https://images.unsplash.com/photo-1526510747491-58f928ec870f</a> and <a href="https://images.unsplash.com/photo-1529946179074-87642f6204d7">https://images.unsplash.com/photo-1529946179074-87642f6204d7</a>:</p></li>
			</ol>
			<p>The expected output is the degree of confidence that the corresponding two images from the image sets are of the same person, even with different angles, lighting, and the position of the face. You will see that in the results section. This activity shows the image analysis capabilities of the Amazon Rekognition service.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found on page 348.</p>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor152"/>Text in Images</h1>
			<p>In the previous chapters, you learned how to extract text from scanned documents such as tax returns and company statements. Amazon Rekognition can detect and extract text from images as wellâfor example, street signs, posters, product names, and license plates. Of course, this feature is made to work with real-world images instead of document images. The <code>Text in image</code> link, which is accessible from the left toolbar, is where this capability resides in Amazon Rekognition.</p>
			<p>For each image provided, the service returns a text label and bounding box, along with a confidence score. This can be extremely useful for searching text across a collection of images. Each image can be tagged with the corresponding text metadata based on the results from this and other capabilities of the service.</p>
			<p>For now, the only texts that are supported are Latin scripts and numbers (Western script). Up to 50 sequences of characters can be recognized per image. The text must be horizontal with +/- 90 degrees rotation.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Click on the <code>Text in image</code> link in the left toolbar to navigate to the <code>Text in image</code> page.</p>
			<p>To identify a "text in image" of a sample image, you can do the following:</p>
			<ol>
				<li value="1">Go to the textbox under the <code>Use your own image</code> panel on the left-hand side.</li>
				<li>Enter the following URL of an image to analyze: <a href="https://images.unsplash.com/photo-1527174744973-fc9ce02c141d?w=800">https://images.unsplash.com/photo-1527174744973-fc9ce02c141d?w=800</a>. You will see the following image:<div><img src="img/B16061_06_48.jpg" alt="Figure 6.48: The first sample image provided for text in image&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.48: The first sample image provided for text in image</p>
			<p>Rekognition surrounds the detected text with borders so that you can identify which text regions it has recognized. You can see the results of text extraction in the <code>Results</code> section:</p>
			<div><div><img src="img/B16061_06_49.jpg" alt="Figure 6.49: Results for the first sample image provided for text in image&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.49: Results for the first sample image provided for text in image</p>
			<p>Rekognition was able to find text in the image and put a box around it; then, it was able to "read" the text and even understand that there are two words! The Rekognition service has extracted text from the image with separators (<code>|</code>) between words in separate regions. Even though the sign's font is unique, with shadows, it was still able to extract the text.  </p>
			<p>Next, let's try out this capability with our own images from different real-life situations such as storefronts and license plates at different angles. As you will see, Amazon Rekognition does very well on photos taken from below store signs, as well as on photos taken at an angle above license plates.</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor153"/>Exercise 6.05: Extracting Text from Your Own Images</h2>
			<p>In this exercise, you will extract text from your own images. Let's see how well Amazon Rekognition works with a variety of different text in images. We have provided three royalty-free images for you to use. Follow these steps to complete thisÂ exercise:</p>
			<ol>
				<li value="1">Click on the <code>Text in image</code> link in the left toolbar to navigate to the <code>Text in image</code> page.</li>
				<li>Copy and paste or type the following URL into the <code>Use image URL</code> textbox under the <code>Use your own image</code> section at the bottom of the page: <a href="https://images.unsplash.com/photo-1521431974017-2521d1cdcd65?w=800">https://images.unsplash.com/photo-1521431974017-2521d1cdcd65?w=800</a>. You will see the following image:<div><img src="img/B16061_06_50.jpg" alt="Figure 6.50: The first image provided for text in image&#13;&#10;"/></div><p class="figure-caption">Figure 6.50: The first image provided for text in image</p><p class="callout-heading">Note</p><p class="callout">Your results may not be as precise as the ones that we've got here.</p><p>You can see the bounding boxes around the image, which signify that Rekognition has recognized the text in the image. The results can be viewed in the <code>Results</code> panel to the right of the image. It did miss one hyphen between N and OUT, but didn't miss the I in IN, which is barely in the picture and slanted:</p><div><img src="img/B16061_06_51.jpg" alt="Figure 6.51: Results of the first image provided for text in image&#13;&#10;"/></div><p class="figure-caption">Figure 6.51: Results of the first image provided for text in image</p></li>
				<li>The next image can be found at the following URL. Copy and paste or type it into the <code>Use image URL</code> textbox as before: <a href="https://images.unsplash.com/photo-1528481958642-cd4b4efb1ae1?w=800">https://images.unsplash.com/photo-1528481958642-cd4b4efb1ae1?w=800</a>. You will see the following image:<div><img src="img/B16061_06_52.jpg" alt="Figure 6.52: The second image provided for text in image&#13;&#10;"/></div><p class="figure-caption">Figure 6.52: The second image provided for text in image</p><p>You can see that Rekognition has recognized the main text in the window of the shop: <code>OCEAN GIFTS SPORTFISHING WHALE WATCHING</code> and the separation between the words:</p><div><img src="img/B16061_06_53.jpg" alt="Figure 6.53: Results of the second image provided for text in image&#13;&#10;"/></div><p class="figure-caption">Figure 6.53: Results of the second image provided for text in image</p><p>Even though the results are extremely good, Rekognition can get confused. This is something you should be aware of and watch out for in your results. It is possible for Rekognition to get confused and return spurious results.</p></li>
				<li>Finally, copy and paste or type the following URL into the <code>Use image URL</code> textbox: <a href="https://images.unsplash.com/photo-1456668609474-b579f17cf693?w=800">https://images.unsplash.com/photo-1456668609474-b579f17cf693?w=800</a>. You will see the following image:<div><img src="img/B16061_06_54.jpg" alt="Figure 6.54: The third image provided for text in image&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.54: The third image provided for text in image</p>
			<p>This is another example of a license plate. The results are as follows:</p>
			<div><div><img src="img/B16061_06_55.jpg" alt="Figure 6.55: Results of the third image provided for text in image&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.55: Results of the third image provided for text in image</p>
			<p>It has done a good job isolating the number plate.</p>
			<p>In this exercise, we learned that Amazon Rekognition can pick out text from images, even with different angles, fonts, shadows, and so forth. You should try this feature out with multiple images with different angles, lighting, and sizes.</p>
			<h1 id="_idParaDest-151"><a id="_idTextAnchor154"/>Summary</h1>
			<p>In this chapter, you learned how to use various features of the Amazon Rekognition service and applied this to images. First, you used the service to recognize objects and scenes in images. Next, you moderated images that might have objectionable content by using Rekognition to recognize the objectionable content in the images.</p>
			<p>You were able to analyze faces with Rekognition and were also able to identify their gender, age range, whether they were smiling, and whether they were wearingÂ glasses.</p>
			<p>You also recognized celebrities and famous people with the service and compared faces in different images to see whether they were the same. Finally, you were able to extract text that was displayed in images.</p>
			<p>With this, we have come to the end of this chapter and this book. We hope it was an interesting journey discovering the enormous capabilities of serverless computing, Amazon AI and ML services, text analysis, image analysis, and so forth.</p>
			<p>These types of features would have seemed unbelievable just a few years ago. The nature of machine learning and artificial intelligence is such that immense strides have been made, and will continue to be made in the foreseeable future, in terms of what computers are going to be able to doâand AWS will be able to provide these services for you and your applications.</p>
		</div>
		<div><div></div>
		</div>
	</body></html>