- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Boosting RAG Performance with Expert Human Feedback
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过专家人类反馈提升RAG性能
- en: '**Human feedback** (**HF**) is not just useful for generative AI—it’s essential,
    especially when it comes to models using RAG. A generative AI model uses information
    from datasets with various documents during training. The data that trained the
    AI model is set in stone in the model’s parameters; we can’t change it unless
    we train it again. However, in the world of retrieval-based text and multimodal
    datasets, there is information we can see and tweak. That is where HF comes in.
    By providing feedback on what the AI model pulls from its datasets, HF can directly
    influence the quality of its future responses. Engaging with this process makes
    humans an active player in the RAG’s development. It adds a new dimension to AI
    projects: adaptive RAG.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类反馈**（**HF**）不仅对生成式AI有用，而且是必不可少的，尤其是在使用RAG的模型中。生成式AI模型在训练期间使用来自包含各种文档的数据集的信息。训练AI模型的数据在模型参数中是固定的；除非我们再次训练它，否则我们无法更改它。然而，在基于检索的文本和多模态数据集的世界中，我们有信息可以查看和调整。这就是HF的用武之地。通过提供关于AI模型从其数据集中提取的信息的反馈，HF可以直接影响其未来响应的质量。参与这一过程使人类成为RAG发展的积极参与者。它为AI项目添加了一个新的维度：自适应RAG。'
- en: We have explored and implemented naïve, advanced, and modular RAG so far. Now,
    we will add adaptive RAG to our generative AI toolbox. We know that even the best
    generative AI system with the best metrics cannot convince a dissatisfied user
    that it is helpful if it isn’t. We will introduce adaptive RAG with an HF loop.
    The system thus becomes adaptive because the documents used for retrieval are
    updated. Integrating HF in RAG leads to a pragmatic hybrid approach because it
    involves humans in an otherwise automated generative process. We will thus leverage
    HF, which we will use to build a hybrid adaptive RAG program in Python from scratch,
    going through the key steps of building a RAG-driven generative AI system from
    the ground up. By the end of this chapter, you will have a theoretical understanding
    of the adaptive RAG framework and practical experience in building an AI model
    based on HF.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探索并实现了朴素、高级和模块化的RAG。现在，我们将添加自适应RAG到我们的生成式AI工具箱中。我们知道，即使是最优秀的生成式AI系统，如果它不令人满意，也无法说服用户它是有用的。我们将通过引入HF循环来介绍自适应RAG。因此，系统变得自适应，因为用于检索的文档被更新了。在RAG中集成HF导致了一种实用性的混合方法，因为它涉及人类在原本自动化的生成过程中。因此，我们将利用HF，我们将从零开始使用Python构建一个混合自适应RAG程序，通过从头开始构建RAG驱动的生成式AI系统的关键步骤。到本章结束时，你将理解自适应RAG框架的理论，并在基于HF构建AI模型方面获得实践经验。
- en: 'This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: Defining the adaptive RAG ecosystem
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义自适应RAG生态系统
- en: Applying adaptive RAG to augmented retrieval queries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自适应RAG应用于增强检索查询
- en: Automating augmented generative AI inputs with HF
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用HF自动化增强生成式AI输入
- en: Automating end-user feedback rankings to trigger expert HF
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化终端用户反馈排名以触发专家HF
- en: Creating an automated feedback system for a human expert
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为人类专家创建一个自动化的反馈系统
- en: Integrating HF with adaptive RAG for GPT-4o
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将HF与自适应RAG集成到GPT-4o中
- en: Let’s begin by defining adaptive RAG.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先定义自适应RAG。
- en: Adaptive RAG
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自适应RAG
- en: No, RAG cannot solve all our problems and challenges. RAG, just like any generative
    model, can also produce irrelevant and incorrect output! RAG might be a useful
    option, however, because we feed pertinent documents to the generative AI model
    that inform its responses. Nonetheless, the quality of RAG outputs depends on
    the accuracy and relevance of the underlying data, which calls for verification!
    That’s where adaptive RAG comes in. Adaptive RAG introduces human, real-life,
    pragmatic feedback that will improve a RAG-driven generative AI ecosystem.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 不，RAG不能解决我们所有的问题和挑战。RAG，就像任何生成模型一样，也可能产生无关和错误的结果！尽管如此，RAG可能是一个有用的选项，因为我们向生成AI模型提供了相关的文档，这些文档可以告知其响应。然而，RAG输出的质量取决于底层数据的准确性和相关性，这需要验证！这就是自适应RAG的用武之地。自适应RAG引入了人类、现实生活中的实用反馈，这将改善由RAG驱动的生成式AI生态系统。
- en: The core information in a generative AI model is parametric (stored as weights).
    But in the context of RAG, this data can be visualized and controlled, as we saw
    in *Chapter 2*, *RAG Embedding Vector Stores with Deep Lake and OpenAI*. Despite
    this, challenges remain; for example, the end-user might write fuzzy queries,
    or the RAG data retrieval might be faulty. An HF process is, therefore, highly
    recommended to ensure the system’s reliability.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型的核心信息是参数化的（存储为权重）。但在RAG的上下文中，这些数据可以可视化并受控，正如我们在*第二章*中看到的，*使用Deep Lake和OpenAI的RAG嵌入向量存储*。尽管如此，仍然存在挑战；例如，最终用户可能会编写模糊的查询，或者RAG的数据检索可能存在故障。因此，高度推荐使用HF过程来确保系统的可靠性。
- en: '*Figure 1.3* from *Chapter 1*, *Why Retrieval Augmented Generation?*, represents
    the complete RAG framework and ecosystem. Let’s zoom in on the adaptive RAG ecosystem
    and focus on the key processes that come into play, as shown in the following
    figure:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.3*来自*第一章*，*为什么是检索增强生成？*，代表了完整的RAG框架和生态系统。让我们放大自适应RAG生态系统并关注以下图中起作用的关键流程：'
- en: '![A diagram of a process  Description automatically generated](img/B31169_05_01.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![一个流程图，描述自动生成](img/B31169_05_01.png)'
- en: 'Figure 5.1: A variant of an adaptive RAG ecosystem'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：自适应RAG生态系统的变体
- en: 'The variant of an adaptive RAG ecosystem in this chapter includes the following
    components, as shown in *Figure 5.1*, for the retriever:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中自适应RAG生态系统的变体包括以下组件，如图5.1所示，对于检索器：
- en: '**D1**: **Collect and process** Wikipedia articles on LLMs by fetching and
    cleaning the data'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D1**: **收集和处理**关于LLMs的维基百科文章，通过获取和清理数据'
- en: '**D4**: **Retrieval query** to query the retrieval dataset'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D4**: **检索查询**查询检索数据集'
- en: 'The generator’s components are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的组件包括：
- en: '**G1**: **Input** entered by an end-user'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**G1**: **输入**由最终用户输入'
- en: '**G2**: **Augmented input with HF** that will augment the user’s initial input
    and **prompt engineering** to configure the GPT-4o model’s prompt'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**G2**: **增强输入与HF**，这将增强用户的初始输入并**提示工程**以配置GPT-4o模型的提示'
- en: '**G4**: **Generation and output** to run the generative AI model and obtain
    a response'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**G4**: **生成和输出**以运行生成式AI模型并获得响应'
- en: 'The evaluator’s components are:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 评估者的组件包括：
- en: '**E1**: **Metrics** to apply a cosine similarity measurement'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**E1**: **指标**应用余弦相似度测量'
- en: '**E2**: **Human feedback** to obtain and process the ultimate measurement of
    a system through end-user and expert feedback'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**E2**: **人工反馈**通过最终用户和专家反馈来获取和处理系统的最终测量值'
- en: In this chapter, we will illustrate adaptive RAG by building a hybrid adaptive
    RAG program in Python on Google Colab. We will build this program from scratch
    to acquire a clear understanding of an adaptive process, which may vary depending
    on a project’s goals, but the underlying principles remain the same. Through this
    hands-on experience, you will learn how to develop and customize a RAG system
    when a ready-to-use one fails to meet the users’ expectations. This is important
    because human users can be dissatisfied with a response no matter what the performance
    metrics show. We will also explore the incorporation of human user rankings to
    gather expert feedback on our RAG-driven generative AI system. Finally, we will
    implement an automated ranking system that will decide how to augment the user
    input for the generative model, offering practical insights into how a RAG-driven
    system can be successfully implemented in a company.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过在Google Colab上构建一个混合自适应RAG程序来展示自适应RAG。我们将从头开始构建这个程序，以获得对自适应过程清晰的理解，这个过程可能因项目目标的不同而有所不同，但基本原理保持不变。通过这次动手实践，您将学习如何在现成的RAG系统无法满足用户期望时开发和定制RAG系统。这很重要，因为无论性能指标如何，人类用户都可能对响应不满意。我们还将探讨将人类用户排名纳入以收集对我们由RAG驱动的生成式AI系统的专家反馈。最后，我们将实现一个自动排名系统，该系统将决定如何增强生成模型的用户输入，为如何在公司中成功实施RAG驱动的系统提供实用见解。
- en: We will develop a proof of concept for a hypothetical company called *Company
    C*. This company would like to deploy a conversational agent that explains what
    AI is. The goal is for the employees of this company to understand the basic terms,
    concepts, and applications of AI. The ML engineer in charge of this RAG-driven
    generative AI example would like future users to acquire a better knowledge of
    AI while implementing other AI projects across the sales, production, and delivery
    domains.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为一个名为*Company C*的假设公司开发一个概念验证。这家公司希望部署一个解释AI是什么的对话代理。目标是让该公司的员工了解AI的基本术语、概念和应用。负责这个RAG驱动的生成式AI示例的机器学习工程师希望未来的用户在实施其他AI项目（如销售、生产和交付领域）时，能够更好地了解AI。
- en: Company C currently faces serious issues with customer support. With a growing
    number of products and services, their product line of smartphones of the C-phone
    series has been experiencing technical problems with too many customer requests.
    The IT department would like to set up a conversational agent for these customers.
    However, the teams are not convinced. The IT department has thus decided to first
    set up a conversational agent to explain what an LLM is and how it can be helpful
    in the C-phone series customer support service.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: C公司目前面临着严重的客户支持问题。随着产品和服务数量的增长，C系列智能手机的产品线已经因为客户请求过多而出现了技术问题。IT部门希望为这些客户设置一个对话代理。然而，团队并不确信。因此，IT部门决定首先设置一个对话代理来解释什么是LLM以及它如何有助于C系列智能手机的客户支持服务。
- en: 'The program will be hybrid and adaptive to fulfill the needs of Company C:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序将采用混合和自适应的方式以满足C公司的需求：
- en: '**Hybrid**: Real-life scenarios go beyond theoretical frameworks and configurations.
    The system is hybrid because we are integrating HF within the retrieval process
    that can be processed in real time. However, we will not parse the content of
    the documents with a keyword alone. We will label the documents (which are Wikipedia
    URLs in this case), which can be done automatically, controlled, and improved
    *by a human*, if necessary. As we show in this chapter, some documents will be
    replaced by human-expert feedback and relabeled. The program will automatically
    retrieve human-expert feedback documents and raw retrieved documents to form a
    hybrid (human-machine) *dynamic* RAG system.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合**：现实场景超越了理论框架和配置。该系统是混合的，因为我们正在将HF整合到可以实时处理的信息检索过程中。然而，我们不会仅用关键词来解析文档内容。我们将对文档（在本例中是维基百科URL）进行标记，这可以自动完成，也可以由人控制并改进，如果需要的话。正如我们在本章中展示的，一些文档将被替换为人类专家反馈并重新标记。程序将自动检索人类专家反馈文档和原始检索文档，形成一个混合（人机）*动态*
    RAG系统。'
- en: '**Adaptive**: We will introduce human user ranking, expert feedback, and automated
    document re-ranking. This HF loop takes us deep into modular RAG and adaptive
    RAG. Adaptive RAG leverages the flexibility of a RAG system to adapt its responses
    to the queries. In this case, we want HF to be triggered to improve the quality
    of the output.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自适应**：我们将引入人类用户排名、专家反馈和自动文档重新排序。这个HF循环将我们带入模块化RAG和自适应RAG的深处。自适应RAG利用RAG系统的灵活性来适应其响应。在这种情况下，我们希望触发HF来提高输出质量。'
- en: 'Real-life projects will inevitably require an ML engineer to go beyond the
    boundaries of pre-determined categories. Pragmatism and necessity encourage creative
    and innovative solutions. For example, for the hybrid, dynamic, and adaptive aspects
    of the system, ML engineers could imagine any process that works with any type
    of algorithm: classical software functions, ML clustering algorithms, or any function
    that works. In real-life AI, what works, works!'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现实生活中的项目不可避免地需要机器学习工程师超越预先确定的类别边界。实用主义和必要性鼓励创新和创造性的解决方案。例如，对于系统的混合、动态和自适应方面，机器学习工程师可以想象任何与任何类型的算法一起工作的过程：经典软件功能、机器学习聚类算法或任何可以工作的函数。在现实生活中的AI中，什么有效，就做什么！
- en: 'It’s time to build a proof of concept to show Company C’s management how hybrid
    adaptive RAG-driven generative AI can successfully help their teams by:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候构建一个概念验证来向C公司管理层展示混合自适应RAG驱动的生成式AI如何成功帮助他们的团队，具体方法如下：
- en: Proving that AI can work with a proof of concept before scaling and investing
    in a project
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在扩展和投资于项目之前，证明AI可以通过概念验证工作
- en: Showing that an AI system can be customized for a specific project
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示一个AI系统可以被定制以适应特定项目
- en: Developing solid ground-up skills to face any AI challenge
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 培养扎实的技能基础以应对任何AI挑战
- en: Building the company’s data governance and control of AI systems
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建公司数据治理和 AI 系统的控制
- en: Laying solid grounds to scale the system by solving the problems that will come
    up during the proof of concept
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为通过概念验证阶段解决可能出现的问题，打下系统扩展的坚实基础
- en: Let’s go to our keyboards!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始敲击键盘！
- en: Building hybrid adaptive RAG in Python
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Python 中构建混合自适应 RAG
- en: Let’s now start building the proof of concept of a hybrid adaptive RAG-driven
    generative AI configuration. Open `Adaptive_RAG.ipynb` on GitHub. We will focus
    on HF and, as such, will not use an existing framework. We will build our own
    pipeline and introduce HF.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始构建混合自适应 RAG 驱动的生成式 AI 配置的概念验证。在 GitHub 上打开 `Adaptive_RAG.ipynb`。我们将专注于
    HF，因此不会使用现有的框架。我们将构建自己的管道并引入 HF。
- en: 'As established earlier, the program is divided into three separate parts: the
    **retriever**, **generator**, and **evaluator** functions, which can be separate
    agents in a real-life project’s pipeline. Try to separate these functions from
    the start because, in a project, several teams might be working in parallel on
    separate aspects of the RAG framework.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，程序分为三个独立的部分：**检索器**、**生成器**和**评估器**函数，这些可以在实际项目管道中作为独立的代理。尝试从一开始就分离这些函数，因为在项目中，多个团队可能会并行工作在
    RAG 框架的不同方面。
- en: The titles of each of the following sections correspond exactly to the names
    of each section in the program on GitHub. The retriever functionality comes first.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下各节的标题与 GitHub 上程序中每个节的名称完全对应。检索器功能排在首位。
- en: 1\. Retriever
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 检索器
- en: We will first outline the initial steps required to set up the environment for
    a RAG-driven generative AI model. This process begins with the installation of
    essential software components and libraries that facilitate the retrieval and
    processing of data. We specifically cover the downloading of crucial files and
    the installation of packages needed for effective data retrieval and web scraping.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先概述设置 RAG 驱动的生成式 AI 模型环境所需的初始步骤。这个过程从安装促进数据检索和处理的必要软件组件和库开始。我们特别涵盖了下载关键文件和安装用于有效数据检索和网页抓取所需的包。
- en: 1.1\. Installing the retriever’s environment
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1\. 安装检索器的环境
- en: Let’s begin by downloading `grequests.py` from the `commons` directory of the
    GitHub repository. This repository contains resources that can be common to several
    programs in the repository, thus avoiding redundancy.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从下载 GitHub 仓库的 `commons` 目录下的 `grequests.py` 开始。这个仓库包含可以用于仓库中多个程序的资源，从而避免冗余。
- en: 'The download is standard and built around the request:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 下载是标准的，围绕请求构建：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will only need two packages for the retriever since we are building a RAG-driven
    generative AI model from scratch. We will install:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于检索器，我们只需要两个包，因为我们是从零开始构建 RAG 驱动的生成式 AI 模型。我们将安装：
- en: '`requests`, the HTTP library to retrieve Wikipedia documents:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`，用于检索维基百科文档的 HTTP 库：'
- en: '[PRE1]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`beautifulsoup4`, to scrape information from web pages:'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beautifulsoup4`，用于从网页抓取信息：'
- en: '[PRE2]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We now need a dataset.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要一个数据集。
- en: 1.2.1\. Preparing the dataset
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1\. 准备数据集
- en: 'For this proof of concept, we will retrieve Wikipedia documents by scraping
    them through their URLs. The dataset will contain automated or human-crafted labels
    for each document, which is the first step toward indexing the documents of a
    dataset:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个概念验证，我们将通过抓取它们的 URL 来检索维基百科文档。数据集将包含每个文档的自动化或人工创建的标签，这是将数据集的文档索引化的第一步：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: One or more labels precede each URL. This approach might be sufficient for a
    relatively small dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 URL 前面都有一个或多个标签。这种方法可能对于相对较小的数据集来说是足够的。
- en: For specific projects, including a proof of concept, this approach can provide
    a solid first step to go from naïve RAG (content search with keywords) to searching
    a dataset with indexes (the labels in this case). We now have to process the data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定的项目，包括概念验证，这种方法可以提供一个坚实的第一步，从简单的 RAG（基于关键词的内容搜索）过渡到使用索引搜索数据集（在这种情况下是标签）。我们现在需要处理数据。
- en: 1.2.2\. Processing the data
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2\. 处理数据
- en: 'We first apply a standard scraping and text-cleaning function to the document
    that will be retrieved:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先对将要检索的文档应用标准的抓取和文本清理函数：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code fetches the document’s content based on its URL, which is, in turn,
    based on its label. This straightforward approach may satisfy a project’s needs
    depending on its goals. An ML engineer or developer must always be careful not
    to overload a system with costly and unprofitable functions. Moreover, labeling
    website URLs can guide a retriever pipeline to the correct locations to process
    data, regardless of the techniques (load balancing, API call optimization, etc.)
    applied. In the end, each project or sub-project will require one or several techniques,
    depending on its specific needs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 代码根据其URL获取文档内容，而URL又基于其标签。这种简单的方法可能满足项目的需求，取决于其目标。机器学习工程师或开发者必须始终小心，不要用昂贵且无利可图的函数超载系统。此外，对网站URL进行标记可以引导检索器管道到正确的位置处理数据，无论应用了哪些技术（负载均衡、API调用优化等）。最终，每个项目或子项目将根据其具体需求需要一种或几种技术。
- en: Once the fetching and cleaning function is ready, we can implement the retrieval
    process for the user’s input.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦准备就绪，我们可以实现针对用户输入的检索过程。
- en: 1.3\. Retrieval process for user input
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3. 用户输入的检索过程
- en: 'The first step here involves identifying a keyword within the user’s input.
    The function `process_query` takes two parameters: `user_input` and `num_words`.
    The number of words to retrieve is restricted by factors like the input limitations
    of the model, cost considerations, and overall system performance:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步涉及在用户输入中识别一个关键词。`process_query`函数接受两个参数：`user_input`和`num_words`。要检索的单词数量受限于模型输入限制、成本考虑和整体系统性能等因素：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Upon finding a match between a keyword in the user input and the keywords associated
    with URLs, the following functions for fetching and cleaning the data are triggered:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在找到用户输入中的关键词与URL关联的关键词之间的匹配后，将触发以下用于获取和清理数据的函数：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `num_words` parameter helps in chunking the text. While this basic approach
    may work for use cases with a manageable volume of data, it’s recommended to embed
    the data into vectors for more complex scenarios.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`num_words`参数有助于对文本进行分块。虽然这种基本方法可能适用于数据量可管理的用例，但在更复杂的情况下，建议将数据嵌入到向量中。'
- en: 'The cleaned and truncated text is then formatted for display:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 清理并截断后的文本随后被格式化以供显示：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that the function ultimately returns the first `n` words, providing a concise
    and relevant snippet of information based on the user’s query. This design allows
    the system to manage data retrieval efficiently while also maintaining user engagement.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，该函数最终返回前`n`个单词，根据用户的查询提供简洁且相关的信息片段。这种设计允许系统在保持用户参与度的同时，高效地管理数据检索。
- en: 2\. Generator
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 生成器
- en: 'The generator ecosystem contains several components, several of which overlap
    with the retriever functions and user interfaces in the RAG-driven generative
    AI frameworks:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器生态系统包含多个组件，其中许多与RAG驱动的生成式AI框架中的检索器功能和用户界面重叠：
- en: '**2.1\. Adaptive RAG selection based on human rankings**: This will be based
    on the ratings of a user panel over time. In a real-life pipeline, this functionality
    could be a separate program.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2.1. 根据人类排名进行自适应RAG选择**：这将基于用户面板随时间的变化而变化的评分。在实际的管道中，这个功能可能是一个独立的程序。'
- en: '**2.2\. Input**: In a real-life project, a **user interface** (**UI**) will
    manage the input. This interface and the associated process should be carefully
    designed in collaboration with the users, ideally in a workshop setting where
    their needs and preferences can be fully understood.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2.2. 输入**：在实际项目中，一个**用户界面**（**UI**）将管理输入。这个界面及其相关流程应与用户合作精心设计，理想情况下在一个工作坊环境中，可以充分理解他们的需求和偏好。'
- en: '**2.3\. Mean ranking simulation scenario**: Calculating the mean value of the
    user evaluation scores and functionality.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2.3. 均值排名模拟场景**：计算用户评估分数的平均值和功能。'
- en: '**2.4\. Checking the input before running the generator**: Displaying the input.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2.4. 在运行生成器之前检查输入**：显示输入。'
- en: '**2.5\. Installing the generative AI environment**: The installation of the
    generative AI model’s environment, in this case, OpenAI, can be part of another
    environment in the pipeline in which other team members may be working, implementing,
    and deploying in production independently of the retriever functionality.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2.5. 安装生成式AI环境**：在这个案例中，生成式AI模型的环境（OpenAI）可以是管道中另一个环境的一部分，其他团队成员可能正在该环境中工作、实施和独立于检索器功能部署。'
- en: '**2.6\. Content generation**: In this section of the program, an OpenAI model
    will process the input and provide a response that will be evaluated by the evaluator.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2.6\. 内容生成**：在这个程序部分，一个OpenAI模型将处理输入并提供一个由评估者评估的响应。'
- en: Let’s begin by describing the adaptive RAG system.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先描述自适应RAG系统。
- en: 2.1\. Integrating HF-RAG for augmented document inputs
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 集成HF-RAG用于增强文档输入
- en: The dynamic nature of information retrieval and the necessity for contextually
    relevant data augmentation in generative AI models require a flexible system capable
    of adapting to varying levels of input quality. We introduce an **adaptive RAG
    selection system**, which employs HF scores to determine the optimal retrieval
    strategy for document implementation within the RAG ecosystem. Adaptive functionality
    takes us beyond naïve RAG and constitutes a hybrid RAG system.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索的动态性质和生成人工智能模型中需要上下文相关数据增强的必要性要求一个能够适应不同输入质量水平的灵活系统。我们引入了一个**自适应RAG选择系统**，该系统使用HF评分来确定RAG生态系统中文档实现的最佳检索策略。自适应功能使我们超越了简单的RAG，构成了一个混合RAG系统。
- en: 'Human evaluators assign mean scores ranging from 1 to 5 to assess the relevance
    and quality of documents. These scores trigger distinct operational modes, as
    shown in the following figure:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 人类评估者分配1到5的平均分数，以评估文档的相关性和质量。这些分数触发不同的操作模式，如下面的图所示：
- en: '![A diagram of a system  Description automatically generated](img/B31169_05_02.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![系统图，描述自动生成](img/B31169_05_02.png)'
- en: 'Figure 5.2: Automated RAG triggers'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：自动RAG触发器
- en: '**Scores of 1 to 2** indicate a lack of compensatory capability by the RAG
    system, suggesting the need for maintenance or possibly model fine-tuning. RAG
    will be temporarily deactivated until the system is improved. The user input will
    be processed but there will be no retrieval.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1到2分的评分**表明RAG系统缺乏补偿能力，表明需要维护或可能需要模型微调。RAG将暂时停用，直到系统得到改进。用户输入将被处理，但不会有检索。'
- en: '**Scores of 3 to 4** initiate an augmentation with human-expert feedback only,
    utilizing flashcards or snippets to refine the output. Document-based RAG will
    be deactivated, but the human-expert feedback data will augment the input.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3到4分的评分**将启动仅使用人类专家反馈的增强，利用闪卡或片段来完善输出。基于文档的RAG将被停用，但人类专家反馈数据将增强输入。'
- en: '**Scores of 5** initiate keyword-search RAG enhanced by previously gathered
    HF when necessary, utilizing flashcards or targeted information snippets to refine
    the output. The user is not required to provide new feedback in this case.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**5分的评分**将启动关键字搜索RAG，当需要时利用之前收集的HF进行增强，利用闪卡或目标信息片段来完善输出。在这种情况下，用户不需要提供新的反馈。'
- en: This program implements one of many scenarios. The scoring system, score levels,
    and triggers will vary from one project to another, depending on the specification
    goals to attain. It is recommended to organize workshops with a panel of users
    to decide how to implement this adaptive RAG system.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序实现了许多场景之一。评分系统、评分级别和触发器将根据要达到的特定目标而有所不同。建议组织用户小组研讨会，以决定如何实施这种自适应的RAG系统。
- en: This adaptive approach aims to optimize the balance between automated retrieval
    and human insight, ensuring the generative model’s outputs are of the highest
    possible relevance and accuracy. Let’s now enter the input.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这种自适应方法旨在优化自动化检索和人类洞察力之间的平衡，确保生成模型的输出具有最高可能的相关性和准确性。现在让我们输入。
- en: 2.2\. Input
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 输入
- en: 'A user of Company C is prompted to enter a question:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: C公司的一名用户被提示输入一个问题：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In this example and program, we will focus on one question and topic: `What
    is an LLM?`. The question appears and is memorized by the model:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例和程序中，我们将关注一个问题和一个主题：`什么是大型语言模型？`。问题出现并被模型记住：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This program is a proof of concept with a strategy and example for the panel
    of users in Company C who wish to understand an LLM. Other topics can be added,
    and the program can be expanded to meet further needs. It is recommended to organize
    workshops with a panel of users to decide the next steps.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序是一个概念验证，包含策略和示例，供C公司用户小组了解大型语言模型。可以添加其他主题，并且程序可以扩展以满足进一步的需求。建议组织用户小组研讨会，以决定下一步行动。
- en: We have prepared the environment and will now activate a RAG scenario.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好了环境，现在将激活一个RAG场景。
- en: 2.3\. Mean ranking simulation scenario
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 平均排名模拟场景
- en: For the sake of this program, let’s assume that the human user feedback panel
    has been evaluating the hybrid adaptive RAG system for some time with the functions
    provided in sections *3.2\. Human user rating* and *3.3\. Human-expert evaluation*.
    The user feedback panel ranks the responses a number of times, which automatically
    updates by calculating the mean of the ratings and storing it in a ranking variable
    named `ranking`. The `ranking` score will help the management team decide whether
    to downgrade the rank of a document, upgrade it, or suppress documents through
    manual or automated functions. You can even simulate one of the scenarios described
    in the section *2.1\. Integrating HF-RAG for augmented document inputs*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本程序，让我们假设人类用户反馈面板已经使用第*3.2*节“人类用户评分”和*3.3*节“人类专家评估”中提供的功能评估了混合自适应RAG系统一段时间。用户反馈面板对响应进行了多次排名，这些排名通过计算评分的平均值并存储在名为`ranking`的排名变量中自动更新。`ranking`评分将帮助管理层决定是否通过手动或自动功能降低文档的排名、提升它或抑制文档。您甚至可以模拟第*2.1*节“集成HF-RAG以增强文档输入”中描述的场景之一。
- en: 'We will begin with a 1 to 5 ranking, which will deactivate RAG so that we can
    see the native response of the generative model:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从1到5的排名开始，这将禁用RAG，以便我们可以看到生成模型的原始响应：
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Then, we will modify this value to activate RAG without additional human-expert
    feedback with `ranking=5`. Finally, we will modify this value to activate human
    feedback RAG without retrieving documents with `ranking=3`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将修改此值以激活RAG，而无需额外的专家反馈，`ranking=5`。最后，我们将修改此值以激活无需检索文档的人类反馈RAG，`ranking=3`。
- en: 'In a real-life environment, these rankings will be triggered automatically
    with the functionality described in sections *3.2* and *3.3* after user feedback
    panel workshops are organized to define the system’s expected behavior. If you
    wish to run the three scenarios described in section *2.1*, make sure to initialize
    the `text_input` variable that the generative model processes to respond:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实环境中，这些排名将在组织用户反馈面板研讨会以定义系统预期行为后，根据第*3.2*节和*3.3*节中描述的功能自动触发。如果您想运行第*2.1*节中描述的三个场景，请确保初始化生成模型处理以响应的`text_input`变量：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Each time you switch scenarios, make sure to come back and reinitialize `text_input`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 每次切换场景时，请确保重新初始化`text_input`。
- en: Due to its probabilistic nature, the generative AI model’s output may vary from
    one run to another.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其概率性质，生成式AI模型的输出可能因运行而异。
- en: Let’s go through the three rating categories described in section *2.1*.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下第*2.1*节中描述的三个评分类别。
- en: 'Ranking 1–2: No RAG'
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 排名1-2：无RAG
- en: 'The ranking of the generative AI’s output is very low. All RAG functionality
    is deactivated until the management team can analyze and improve the system. In
    this case, `text_input` is equal to `user_input`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI输出的排名非常低。直到管理层能够分析和改进系统之前，所有RAG功能都将被禁用。在这种情况下，`text_input`等于`user_input`：
- en: '[PRE12]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The generative AI model, in this case, GPT-4o, will generate the following
    output in section *2.6\. Content generation*:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，生成式AI模型GPT-4o将在*2.6*节“内容生成”中生成以下输出：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This output cannot satisfy the user panel of Company C in this particular use
    case. They cannot relate this explanation to their customer service issues. Furthermore,
    many users will not bother going further since they have described their needs
    to the management team and expect pertinent responses. Let’s see what human-expert
    feedback RAG can provide.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这种输出无法满足C公司在特定用例中的用户面板需求。他们无法将这种解释与他们的客户服务问题联系起来。此外，许多用户不会进一步操作，因为他们已经向管理层描述了他们的需求，并期待得到相应的回应。让我们看看RAG（人类专家反馈）能提供什么。
- en: 'Ranking 3–4: Human-expert feedback RAG'
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 排名3-4：人类专家反馈RAG
- en: In this scenario, human-expert feedback (see *section 3.4\. Human-expert evaluation*)
    was triggered by poor user feedback ratings with automated RAG documents `(ranking=5)`
    and without RAG `(ranking 1-2)`. The human-expert panel has filled in a flashcard,
    which has now been stored as an expert-level RAG document.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，由于自动RAG文档（排名=5）和没有RAG（排名1-2）的用户反馈评分不佳，触发了人类专家反馈（见*3.4*节“人类专家评估”）。人类专家面板填写了一张闪卡，现在它已被存储为专家级别的RAG文档。
- en: 'The program first checks the ranking and activates HF retrieval:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 程序首先检查排名并激活HF检索：
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The program will then fetch the proper document from an expert panel (selected
    experts within a corporation) dataset based on keywords, embeddings, or other
    search methods that fit the goals of a project. In this case, we assume we have
    found the right flashcard and download it:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 程序将根据关键词、嵌入或其他适合项目目标的项目搜索方法，从专家小组（公司内的选定专家）数据集中检索适当的文档。在这种情况下，我们假设我们已经找到了正确的闪卡并下载了它：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We verify if the file exists and load its content, clean it, store it in `content`,
    and assign it to `text_input` for the GPT-4 model:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证文件是否存在，加载其内容，清理它，将其存储在`content`中，并将其分配给`text_input`以供GPT-4模型使用：
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The content of the file explains both what an LLM is and how it can help Company
    C improve customer support:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的内容解释了什么是LLM以及它如何帮助C公司提高客户支持：
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If you now run sections *2.4* and *2.5* once and section *2.6* to generate
    the content based on this `text_input`, the response will be satisfactory:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在运行第*2.4*和*2.5*节一次，以及第*2.6*节来根据这个`text_input`生成内容，那么响应将是令人满意的：
- en: '[PRE18]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding response is now much better since it defines LLMs and also shows
    how to improve customer service for Company C’s C-phone series.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的响应现在要好得多，因为它定义了LLMs，并展示了如何提高C公司C-phone系列的客户服务。
- en: 'We will take this further in *Chapter 9*, *Empowering AI Models: Fine-Tuning
    RAG Data and Human Feedback*, in which we will fine-tune a generative model daily
    (or as frequently as possible) to improve its responses, thus alleviating the
    volume of RAG data. But for now, let’s see what the system can achieve without
    HF but with RAG documents.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第9章*，*赋予AI模型能力：微调RAG数据和人类反馈*中进一步探讨，我们将每天（或尽可能频繁地）微调生成模型以提高其响应，从而减轻RAG数据的量。但到目前为止，让我们看看系统在没有HF但有RAG文档的情况下能取得什么成果。
- en: 'Ranking 5: RAG with no human-expert feedback documents'
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 排名5：没有人类专家反馈文档的RAG
- en: Some users do not require RAG documents that include human-expert RAG flashcards,
    snippets, or documents. This might be the case, particularly, if software engineers
    are the users.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一些用户不需要包含人类专家RAG闪卡、片段或文档的RAG文档。这种情况可能尤其如此，尤其是如果软件工程师是用户的话。
- en: 'In this case, the maximum number of words is limited to 100 to optimize API
    costs, but can be modified as you wish using the following code:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最大词数限制为100，以优化API成本，但可以根据你的意愿使用以下代码进行修改：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'When we run the generative AI model, a reasonable output is produced that software
    engineers can relate to their business:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行生成式AI模型时，会产生一个合理的输出，软件工程师可以将其与他们的业务联系起来：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can see that the output refers to March 2024 data, although GPT-4-turbo’s
    training cutoff date was in December 2023, as explained in OpenAI’s documentation:
    [https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到输出指的是2024年3月的数据，尽管GPT-4-turbo的训练截止日期是在2023年12月，如OpenAI的文档中所述：[https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4)。
- en: In production, at the end-user level, the error in the output can come from
    the data retrieved or the generative AI model. This shows the importance of HF.
    In this case, this error will hopefully be corrected in the retrieval documents
    or by the generative AI model. But we left the error in to illustrate that HF
    is not an option but a necessity.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，在最终用户层面，输出的错误可能来自检索到的数据或生成式AI模型。这显示了HF的重要性。在这种情况下，这个错误有望在检索文档或通过生成式AI模型中得到纠正。但我们将错误保留下来，以说明HF不是一种选择，而是一种必需品。
- en: These temporal RAG augmentations clearly justify the need for RAG-driven generative
    AI. However, it remains up to the users to decide if these types of outputs are
    sufficient or require more corporate customization in closed environments, such
    as within or for a company.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这些时间相关的RAG增强清楚地证明了RAG驱动的生成式AI的需求。然而，用户仍然需要决定这些类型的输出是否足够，或者是否需要在封闭环境中进行更多企业定制，例如在公司内部或为公司。
- en: For the remainder of this program, let’s assume `ranking>=5` for the next steps
    to show how the evaluator is implemented in the *Evaluator* section. Let’s install
    the generative AI environment to generate content based on the user input and
    the document retrieved.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本程序的剩余部分，让我们假设`ranking>=5`以展示评估器在*评估器*部分是如何实现的。让我们安装生成式AI环境，根据用户输入和检索到的文档生成内容。
- en: 2.4.–2.5\. Installing the generative AI environment
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.–2.5\. 安装生成式AI环境
- en: '*2.4\. Checking the input before running the generator* displays the user input
    and retrieved document before augmenting the input with this information. Then
    we continue to *2.5\. Installing the generative AI environment*.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*2.4\. 在运行生成器之前检查输入* 显示了在用此信息增强输入之前用户输入和检索到的文档。然后我们继续到 *2.5\. 安装生成式AI环境*。'
- en: Only run this section once. If you modified the scenario in section *2.3*, you
    can skip this section to run the generative AI model again. This installation
    is not at the top of this notebook because a project team may choose to run this
    part of the program in another environment or even another server in production.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 只需运行这一节一次。如果你在第 *2.3* 节中修改了场景，你可以跳过这一节以再次运行生成式AI模型。这个安装不是在这个笔记本的顶部，因为项目团队可能会选择在另一个环境中运行这个程序的这部分，甚至是在生产中的另一台服务器上。
- en: It is recommended to separate the retriever and generator functions as much
    as possible since they might be activated by different programs and possibly at
    different times. One development team might only work on the retriever functions
    while another team works on the generator functions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 建议尽可能地将检索器和生成器函数分开，因为它们可能由不同的程序激活，甚至可能在不同的时间激活。一个开发团队可能只专注于检索器函数，而另一个团队则专注于生成器函数。
- en: 'We first install OpenAI:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先安装OpenAI：
- en: '[PRE21]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, we retrieve the API key. Store your OpenAI key in a safe location. In
    this case, it is stored on Google Drive:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们检索API密钥。将你的OpenAI密钥存储在安全的位置。在这种情况下，它存储在Google Drive上：
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We are now all set for content generation.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为内容生成做好了准备。
- en: 2.6\. Content generation
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6\. 内容生成
- en: 'To generate content, we first import and set up what we need. We’ve introduced
    `time` to measure the speed of the response and have chosen `gpt-4o` as our conversational
    model:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成内容，我们首先导入并设置我们需要的。我们引入了 `time` 来测量响应速度，并选择了 `gpt-4o` 作为我们的对话模型：
- en: '[PRE23]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We then define a standard Gpt-4o prompt, giving it enough information to respond
    and leaving the rest up to the model and RAG data:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后定义了一个标准的Gpt-4o提示，给它足够的信息来响应，其余的则留给模型和RAG数据：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The code then formats the output:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然后代码格式化输出：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The response is satisfactory in this case, as we saw in section *2.3*. In the
    `ranking=5` scenario, which is the one we are now evaluating, we get the following
    output:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，响应是令人满意的，正如我们在第 *2.3* 节中看到的那样。在 `ranking=5` 的场景中，这是我们目前正在评估的场景，我们得到以下输出：
- en: '[PRE26]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The response looks fine, but is it really accurate? Let’s run the evaluator
    to find out.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 响应看起来不错，但它真的准确吗？让我们运行评估器来找出答案。
- en: 3\. Evaluator
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 评估器
- en: 'Depending on each project’s specifications and needs, we can implement as many
    mathematical and human evaluation functions as necessary. In this section, we
    will implement two automatic metrics: response time and cosine similarity score.
    We will then implement two interactive evaluation functions: human user rating
    and human-expert evaluation.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 根据每个项目的规格和需求，我们可以实现所需的所有数学和人工评估函数。在本节中，我们将实现两个自动指标：响应时间和余弦相似度分数。然后我们将实现两个交互式评估函数：人工用户评分和人工专家评估。
- en: 3.1\. Response time
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 响应时间
- en: 'The response time was calculated and displayed in the API call with:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 响应时间是通过以下API调用计算并显示的：
- en: '[PRE27]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In this case, we can display the response time without further development:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以显示响应时间而无需进一步开发：
- en: '[PRE28]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output will vary depending on internet connectivity and the capacity of
    OpenAI’s servers. In this case, the output is:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将根据互联网连接性和OpenAI服务器的容量而变化。在这种情况下，输出如下：
- en: '[PRE29]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: It seems long, but online conversational agents take some time to answer as
    well. Deciding if this performance is sufficient remains a management decision.
    Let’s run the cosine similarity score next.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来时间很长，但在线对话代理回答也需要一些时间。决定这种性能是否足够仍然是管理层的决定。让我们接下来运行余弦相似度分数。
- en: 3.2\. Cosine similarity score
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 余弦相似度分数
- en: Cosine similarity measures the cosine of the angle between two non-zero vectors.
    In the context of text analysis, these vectors are typically **TF-IDF** (**Term
    Frequency-Inverse Document Frequency**) representations of the text, which weigh
    terms based on their importance relative to the document and a corpus.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度衡量两个非零向量之间角度的余弦值。在文本分析的情况下，这些向量通常是文本的 **TF-IDF** （**词频-逆文档频率**）表示，这些表示根据相对于文档和语料库的重要性来权衡术语。
- en: GPT-4o’s input, which is `text_input`, and the model’s response, which is `gpt4_response`,
    are treated by TF-IDF as two separate “documents.” The `vectorizer` transforms
    the documents into vectors. Then, vectorization considers how terms are shared
    and emphasized between the input and the response with the `vectorizer.fit_transform([text1,
    text2])`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o的输入`text_input`和模型的响应`gpt4_response`被TF-IDF视为两个独立的“文档”。`vectorizer`将文档转换为向量。然后，向量化考虑输入和响应之间术语的共享和强调，使用`vectorizer.fit_transform([text1,
    text2])`。
- en: 'The goal is to quantify the thematic and lexical overlap through the following
    function:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是通过以下函数量化主题和词汇的重叠：
- en: '[PRE30]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Cosine similarity relies on `TfidfVectorizer` to transform the two documents
    into TF-IDF vectors. The `cosine_similarity` function then calculates the similarity
    between these vectors. A result of `1` indicates identical texts, while `0` shows
    no similarity. The output of the function is:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度依赖于`TfidfVectorizer`将两个文档转换为TF-IDF向量。然后`cosine_similarity`函数计算这些向量之间的相似度。结果为`1`表示文本完全相同，而`0`表示没有相似性。函数的输出如下：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The score shows a strong similarity between the input and the output of the
    model. But how will a human user rate this response? Let’s find out.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 分数显示模型输入和输出之间存在强烈的相似性。但人类用户会如何评价这个响应呢？让我们来看看。
- en: 3.3\. Human user rating
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3. 人类用户评分
- en: The human user rating interface provides human user feedback. As reiterated
    throughout this chapter, I recommend designing this interface and process after
    fully understanding user needs through a workshop with them. In this section,
    we will assume that the human user panel is a group of software developers testing
    the system.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 人类用户评分界面提供了人类用户的反馈。正如本章反复强调的，我建议在与他们一起通过研讨会充分了解用户需求后设计这个界面和流程。在本节中，我们将假设人类用户小组是一组正在测试系统的软件开发者。
- en: 'The code begins with the interface’s parameters:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 代码从界面的参数开始：
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In this simulation, the parameters show that the system has computed human
    feedback:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模拟中，参数显示系统已经计算了人类反馈：
- en: '`counter=20` shows the number of ratings already entered by the users'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`counter=20` 显示用户已经输入的评分数量'
- en: '`score_history=60` shows the total score of the 20 ratings'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score_history=60` 显示20个评分的总分'
- en: '`threshold=4` states the minimum mean rating, `score_history/counter`, to obtain
    without triggering a human-expert feedback request'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threshold=4` 表示获得最小平均评分，`score_history/counter`，而不触发人类专家反馈请求'
- en: We will now run the interface to add an instance to these parameters. The provided
    Python code defines the `evaluate_response` function, designed to assess the relevance
    and coherence of responses generated by a language model such as GPT-4\. Users
    rate the generated text on a scale from `1` (poor) to `5` (excellent), with the
    function ensuring valid input through recursive checks. The code calculates statistical
    metrics like mean scores to gauge the model’s performance over multiple evaluations.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将运行界面以添加一个实例到这些参数中。提供的Python代码定义了`evaluate_response`函数，该函数旨在评估由GPT-4等语言模型生成的响应的相关性和连贯性。用户在从`1`（差）到`5`（优秀）的范围内对生成的文本进行评分，该函数通过递归检查确保有效输入。代码计算统计指标，如平均分数，以衡量模型在多次评估中的性能。
- en: 'The evaluation function is a straightforward feedback request to obtain values
    between `1` and `5`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 评估函数是一个简单的反馈请求，以获得介于`1`和`5`之间的值：
- en: '[PRE33]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We then call the function:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后调用这个函数：
- en: '[PRE34]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The function first displays the response, as shown in the following excerpt:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 函数首先显示响应，如下面的摘录所示：
- en: '[PRE35]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then, the user enters an evaluation score between 1 and 5, which is `1` in
    this case:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，用户输入一个介于1到5之间的评价分数，在这个例子中是`1`：
- en: '[PRE36]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The code then computes the statistics:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 然后代码计算统计信息：
- en: '[PRE37]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output shows a relatively very low rating:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示一个相对非常低的评分：
- en: '[PRE38]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The evaluator score is `3`, the overall ranking is `3`, and the score history
    is `3` also! Yet, the cosine similarity was positive. The human-expert evaluation
    request will be triggered because we set the threshold to `4`:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 评估者的分数是`3`，整体排名是`3`，评分历史也是`3`！然而，余弦相似度是正的。由于我们将阈值设置为`4`，将触发人类专家评估请求：
- en: '[PRE39]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: What’s going on? Let’s ask an expert and find out!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么？让我们询问一个专家并找出答案！
- en: 3.4\. Human-expert evaluation
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4. 人类专家评估
- en: Metrics such as cosine similarity indeed measure similarity but not in-depth
    accuracy. Time performance will not determine the accuracy of a response either.
    But if the rating is too low, why is that? Because the user is not satisfied with
    the response!
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 指标如余弦相似度确实衡量相似度，但并非深入准确性。时间性能也不会决定响应的准确性。但如果评分太低，那又是为什么呢？因为用户对响应不满意！
- en: 'The code first downloads thumbs-up and thumbs-down images for the human-expert
    user:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 代码首先为人类专家用户下载竖起大拇指和竖起中指的图像：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The parameters to trigger an expert’s feedback are `counter_threshold` and
    `score_threshold`. The number of user ratings must exceed the expert’s threshold
    counter, which is `counter_threshold=10`. The threshold of the mean score of the
    ratings is `4` in this scenario: `score_threshold=4`. We can now simulate the
    triggering of an expert feedback request:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 触发专家反馈的参数是`counter_threshold`和`score_threshold`。用户评分的数量必须超过专家的阈值计数器，即`counter_threshold=10`。在这种情况下，评分的平均值阈值为`4`：`score_threshold=4`。我们现在可以模拟触发专家反馈请求：
- en: '[PRE41]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In this case, the output will confirm the expert feedback loop because of the
    poor mean ratings and the number of times the users rated the response:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，输出将确认专家反馈循环，因为平均评分较低和用户对响应的评分次数：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The code will display the icons shown in the following figure. If the expert
    user presses the thumbs-down icon, they will be prompted to enter feedback.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将显示以下图中的图标。如果专家用户按下竖起中指图标，他们将被提示输入反馈。
- en: '![A thumbs down and thumbs down  Description automatically generated](img/B31169_05_03.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![一个竖起大拇指和一个竖起中指的图标，描述自动生成](img/B31169_05_03.png)'
- en: 'Figure 5.3: Feedback icons'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：反馈图标
- en: 'You can add a function for thumbs-down meaning that the response was incorrect
    and that the management team has to communicate with the user panel or add a prompt
    to the user feedback interface. This is a management decision, of course. In our
    scenario, the human expert pressed the thumbs-down icon and was prompted to enter
    a response:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为竖起中指添加一个函数，表示响应是错误的，管理层必须与用户面板沟通或向用户反馈界面添加提示。这是一个管理决策，当然。在我们的场景中，人类专家按下了竖起中指图标，并被提示输入响应：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_05_04.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成](img/B31169_05_04.png)'
- en: 'Figure 5.4: “Enter feedback” prompt'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：“输入反馈”提示
- en: 'The human expert provided the response, which was saved in `''/content/expert_feedback.txt''`.
    Through this, we have finally discovered the inaccuracy, which is in the content
    of the file displayed in the following cell:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 人类专家提供了响应，该响应保存在`'/content/expert_feedback.txt'`中。通过这种方式，我们最终发现了不准确之处，它位于以下单元格显示的文件内容中：
- en: '[PRE44]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The preceding expert’s feedback can then be used to improve the RAG dataset.
    With this, we have explored the depths of HF-RAG interactions. Let’s summarize
    our journey and move on to the next steps.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的专家反馈可以用来改进RAG数据集。通过这种方式，我们已经探索了HF-RAG交互的深度。让我们总结我们的旅程，并继续下一步。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: As we wrap up our hands-on approach to pragmatic AI implementations, it’s worth
    reflecting on the transformative journey we’ve embarked on together, exploring
    the dynamic world of adaptive RAG. We first examined how HF not only complements
    but also critically enhances generative AI, making it a more powerful tool customized
    to real-world needs. We described the adaptive RAG ecosystem and then went hands-on,
    building from the ground up. Starting with data collection, processing, and querying,
    we integrated these elements into a RAG-driven generative AI system. Our approach
    wasn’t just about coding; it was about adding adaptability to AI through continuous
    HF loops.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们结束对实用主义AI实现的动手实践，值得反思我们一起踏上的变革之旅，探索自适应RAG的动态世界。我们首先考察了HF不仅补充了生成AI，而且从关键上增强了它，使其成为一个更强大的、针对现实世界需求定制的工具。我们描述了自适应RAG生态系统，然后从头开始构建。从数据收集、处理和查询开始，我们将这些元素整合到一个由RAG驱动的生成AI系统中。我们的方法不仅仅是编码；它是通过持续的HF循环为AI增加适应性。
- en: By augmenting GPT-4’s capabilities with expert insights from previous sessions
    and end-user evaluations, we demonstrated the practical application and significant
    impact of HF. We implemented a system where the output is not only generated but
    also ranked by end-users. Low rankings triggered an expert feedback loop, emphasizing
    the importance of human intervention in refining AI responses. Building an adaptive
    RAG program from scratch ensured a deep understanding of how integrating HF can
    shift a standard AI system to one that evolves and improves over time.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将GPT-4的能力与之前会话中的专家见解和最终用户评估相结合，我们展示了HF（人类反馈）的实用应用和重大影响。我们实施了一个系统，其中输出不仅由用户生成，而且由用户进行排序。低排名触发了专家反馈循环，强调了在改进AI响应中人类干预的重要性。从头开始构建自适应RAG程序确保了对如何整合HF将标准AI系统转变为随时间演变和改进的系统有深入理解。
- en: This chapter wasn’t just about learning; it was about doing, reflecting, and
    transforming theoretical knowledge into practical skills. We are now ready to
    scale RAG-driven AI to production-level volumes and complexity in the next chapter.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不仅仅关于学习，还关于实践、反思，以及将理论知识转化为实际技能。我们现在准备将RAG驱动的AI扩展到下一章的生产级规模和复杂性。
- en: Questions
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions with *Yes* or *No*:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 用*是*或*否*回答以下问题：
- en: Is human feedback essential in improving RAG-driven generative AI systems?
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人类反馈对于改进由RAG驱动的生成型AI系统是否至关重要？
- en: Can the core data in a generative AI model be changed without retraining the
    model?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在不重新训练模型的情况下，生成型AI模型的核心数据可以更改吗？
- en: Does Adaptive RAG involve real-time human feedback loops to improve retrieval?
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自适应RAG是否涉及实时人类反馈循环以改进检索？
- en: Is the primary focus of Adaptive RAG to replace all human input with automated
    responses?
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自适应RAG的主要焦点是否是用自动响应取代所有人类输入？
- en: Can human feedback in Adaptive RAG trigger changes in the retrieved documents?
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自适应RAG中的人类反馈能否触发检索文档的变化？
- en: Does Company C use Adaptive RAG solely for customer support issues?
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 公司C是否仅将自适应RAG用于客户支持问题？
- en: Is human feedback used only when the AI responses have high user ratings?
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人类反馈是否仅在AI响应获得高用户评分时使用？
- en: Does the program in this chapter provide only text-based retrieval outputs?
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章的程序是否只提供基于文本的检索输出？
- en: Is the Hybrid Adaptive RAG system static, meaning it cannot adjust based on
    feedback?
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混合自适应RAG系统是否是静态的，意味着它不能根据反馈进行调整？
- en: Are user rankings completely ignored in determining the relevance of AI responses?
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在确定AI响应的相关性时，用户排名是否完全被忽略？
- en: References
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts*
    by Evgenii Kortukov, Alexander Rubinstein, Elisa Nguyen, Seong Joon Oh: [https://arxiv.org/abs/2404.16032](https://arxiv.org/abs/2404.16032)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Evgenii Kortukov、Alexander Rubinstein、Elisa Nguyen、Seong Joon Oh所著的《在现实知识冲突下研究大型语言模型行为》：[https://arxiv.org/abs/2404.16032](https://arxiv.org/abs/2404.16032)
- en: 'OpenAI models: [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI模型：[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
- en: Further reading
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information on the vectorizer and cosine similarity functionality
    implemented in this chapter, use the following links:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有关本章中实现的向量化器和余弦相似度功能的更多信息，请使用以下链接：
- en: 'Feature extraction – `TfidfVectorizer`: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取 – `TfidfVectorizer`：[https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- en: '`sklearn.metrics` – `cosine_similarity`: [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.metrics` – `cosine_similarity`：[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)'
- en: Join our community on Discord
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的Discord空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code50409000288080484.png)'
