<html><head></head><body>
<div id="_idContainer070">
<h1 class="chapter-number" id="_idParaDest-73"><a id="_idTextAnchor073"/><span class="koboSpan" id="kobo.1.1">4</span></h1>
<h1 id="_idParaDest-74"><a id="_idTextAnchor074"/><span class="koboSpan" id="kobo.2.1">Customizing Models for Enhanced Performance</span></h1>
<p><span class="koboSpan" id="kobo.3.1">When general-purpose models fall short of delivering satisfactory results for your domain-specific use case, customizing FMs becomes crucial. </span><span class="koboSpan" id="kobo.3.2">This chapter delves into the process of customizing FMs while using techniques such as fine-tuning and continued pre-training to enhance their performance. </span><span class="koboSpan" id="kobo.3.3">We’ll begin by examining the rationale behind customizing the base FM and exploring the mechanics of fine-tuning. </span><span class="koboSpan" id="kobo.3.4">Subsequently, we will delve into data preparation techniques to ensure our data is formatted appropriately for creating a custom model using both the AWS console and APIs. </span><span class="koboSpan" id="kobo.3.5">We will understand various components within model customization and different customization APIs that you can call from </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">your application.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Furthermore, we will analyze the model’s behavior and perform inference. </span><span class="koboSpan" id="kobo.5.2">Finally, we will conclude this chapter by discussing guidelines and best practices for customizing </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">Bedrock models.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">By the end of this chapter, you will be able to understand the importance and process of customizing a model for your domain-specific </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">use case.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">The following key topics will be covered in </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">this chapter:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.11.1">Why is customizing </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">FMs important?</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">model customization</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Preparing </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">the data</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Creating a </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">custom model</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">Analyzing </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">the results</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Guidelines and </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">best practices</span></span><a id="_idTextAnchor075"/></li>
</ul>
<h1 id="_idParaDest-75"><a id="_idTextAnchor076"/><span class="koboSpan" id="kobo.23.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.24.1">For this chapter, you need to have access to an </span><em class="italic"><span class="koboSpan" id="kobo.25.1">AWS</span></em><span class="koboSpan" id="kobo.26.1"> account. </span><span class="koboSpan" id="kobo.26.2">If you don’t have one, you can go to </span><a href="https://aws.amazon.com/getting-started/"><span class="koboSpan" id="kobo.27.1">https://aws.amazon.com/getting-started/</span></a><span class="koboSpan" id="kobo.28.1"> and create an </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">AWS account.</span></span></p>
<p><span class="koboSpan" id="kobo.30.1">Once you have access to an AWS account, you will need to install and configure the AWS CLI (</span><a href="https://aws.amazon.com/cli/"><span class="koboSpan" id="kobo.31.1">https://aws.amazon.com/cli/</span></a><span class="koboSpan" id="kobo.32.1">) so that you can access Amazon Bedrock FMs from your local machine. </span><span class="koboSpan" id="kobo.32.2">In addition, you will need to set up the AWS Python SDK (Boto3) since the majority of the code cells we will be executing require it (</span><a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html"><span class="koboSpan" id="kobo.33.1">https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html</span></a><span class="koboSpan" id="kobo.34.1">). </span><span class="koboSpan" id="kobo.34.2">You can set up Python by installing it on your local machine, using AWS Cloud9, utilizing AWS Lambda, or leveraging </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">Amazon SageMaker.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.36.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.37.1">There will be a charge associated with invocating and customizing the FMs of Amazon Bedrock. </span><span class="koboSpan" id="kobo.37.2">Please refer to </span><a href="https://aws.amazon.com/bedrock/pricing/"><span class="koboSpan" id="kobo.38.1">https://aws.amazon.com/bedrock/pricing/</span></a><span class="koboSpan" id="kobo.39.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">learn more.</span></span></p>
<h1 id="_idParaDest-76"><a id="_idTextAnchor077"/><span class="koboSpan" id="kobo.41.1">Why is customizing FMs important?</span></h1>
<p><span class="koboSpan" id="kobo.42.1">In the previous </span><a id="_idIndexMarker290"/><span class="koboSpan" id="kobo.43.1">chapter, we looked at several prompt engineering techniques to improve the performance of a model. </span><span class="koboSpan" id="kobo.43.2">As we also saw in </span><a href="B22045_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.44.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.45.1"> (and shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.46.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.47.1">.1</span></em><span class="koboSpan" id="kobo.48.1">), these FMs are trained on massive amounts of data (GBs, TBs, or PBs) with millions to billions of parameters, allowing them to understand relationships between words in context to predict </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">subsequent sequences:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<span class="koboSpan" id="kobo.50.1"><img alt="Figure 4.1 – Training an FM" src="image/B22045_04_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.51.1">Figure 4.1 – Training an FM</span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.52.1">So, why do we need to customize </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.53.1">these models?</span></em></span></p>
<p><span class="koboSpan" id="kobo.54.1">That’s a fair question since a lot of use cases can be directly solved by using prompt engineering and RAG techniques (which we will cover in </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.55.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.56.1">). </span><span class="koboSpan" id="kobo.56.2">However, consider a situation where</span><a id="_idIndexMarker291"/><span class="koboSpan" id="kobo.57.1"> you require the model to adhere to a particular writing style, output format, or domain-specific terminology. </span><span class="koboSpan" id="kobo.57.2">For instance, you may need the model to analyze financial earnings reports or medical records accurately. </span><span class="koboSpan" id="kobo.57.3">In such cases, the pre-trained models might not have been exposed to the desired writing style or specialized vocabularies, limiting their performance despite effective prompt crafting or </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">RAG implementation.</span></span></p>
<p><span class="koboSpan" id="kobo.59.1">To bridge this gap and enhance the model’s domain-specific language understanding and generation capabilities, customization becomes essential. </span><span class="koboSpan" id="kobo.59.2">By fine-tuning the pre-trained models on domain-specific data or adapting them to the desired writing style or output format, you can tailor their performance to meet your unique requirements, ensuring more accurate and </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">relevant responses:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<span class="koboSpan" id="kobo.61.1"><img alt="Figure 4.2 – Generative AI performance techniques" src="image/B22045_04_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.62.1">Figure 4.2 – Generative AI performance techniques</span></p>
<p><span class="koboSpan" id="kobo.63.1">If you look at the spectrum of generative AI performance techniques shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.64.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.65.1">.2</span></em><span class="koboSpan" id="kobo.66.1"> for improving the performance of FMs, it ranges from prompt engineering to training the model from scratch. </span><span class="koboSpan" id="kobo.66.2">For domain-specific data, prompt engineering techniques may provide low accuracy, but they involve less effort and are cost-effective. </span><span class="koboSpan" id="kobo.66.3">Prompt engineering is a better option if you have a simple task and don’t need a new domain-specific dataset. </span><span class="koboSpan" id="kobo.66.4">If you would like to understand how prompt engineering works, please go back to </span><a href="B22045_03.xhtml#_idTextAnchor053"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.67.1">Chapter 3</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.68.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.69.1">Next on the spectrum with a little bit of increasing complexity, cost, and accuracy is RAG. </span><span class="koboSpan" id="kobo.69.2">This technique fetches data from outside the language model, such as from internal knowledge bases or external sources. </span><span class="koboSpan" id="kobo.69.3">It is a particularly useful technique when you have large corpora of documents that do not fit the context length of the model. </span><span class="koboSpan" id="kobo.69.4">We will discuss RAG in more detail in </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.70.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.71.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.72.1">Further on the </span><a id="_idIndexMarker292"/><span class="koboSpan" id="kobo.73.1">spectrum, customizing the model is essentially more time-consuming and costly. </span><span class="koboSpan" id="kobo.73.2">However, it provides greater accuracy to your specialized </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">use case.</span></span></p>
<p><span class="koboSpan" id="kobo.75.1">There are two customization techniques within Amazon Bedrock: fine-tuning and </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">continued pretraining.</span></span></p>
<p><span class="koboSpan" id="kobo.77.1">In </span><em class="italic"><span class="koboSpan" id="kobo.78.1">fine-tuning</span></em><span class="koboSpan" id="kobo.79.1">, the model is trained with the labeled dataset – a supervised learning approach. </span><span class="koboSpan" id="kobo.79.2">The labeled dataset that you provide will be specific to your use case. </span><span class="koboSpan" id="kobo.79.3">Whether you’re working in healthcare, finance, or any other field, you can fine-tune your model to become an expert in that particular domain. </span><span class="koboSpan" id="kobo.79.4">In healthcare, for example, the model can be fine-tuned for medical specialization, allowing it to understand and interpret medical records with greater accuracy. </span><span class="koboSpan" id="kobo.79.5">Similarly, a financial analysis model can be fine-tuned for niche financial analysis, enabling it to identify patterns and trends in financial data that may be missed by </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">traditional algorithms.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">To fine-tune a model using your own data, you need to have a sufficient amount of high-quality data that is relevant to the task you want to perform. </span><span class="koboSpan" id="kobo.81.2">This data should be labeled and annotated to provide the model with the necessary information for training. </span><span class="koboSpan" id="kobo.81.3">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.82.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.83.1">.3</span></em><span class="koboSpan" id="kobo.84.1">, we can use this labeled dataset to fine-tune the base FM, which then generates a custom model. </span><span class="koboSpan" id="kobo.84.2">You can then use the custom model to generate responses that are tailored to your specific domain and </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">use case:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<span class="koboSpan" id="kobo.86.1"><img alt="Figure 4.3 – Fine-tuning" src="image/B22045_04_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.87.1">Figure 4.3 – Fine-tuning</span></p>
<p><span class="koboSpan" id="kobo.88.1">For example, let’s say you work in the medical industry and would like to summarize a dialog between two doctors discussing the medical report of the patient, extract the information to</span><a id="_idIndexMarker293"/><span class="koboSpan" id="kobo.89.1"> be put into medical forms, and maybe write it in </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">layman’s terms.</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">In this case, the base FMs might not be trained on the domain-specific dataset. </span><span class="koboSpan" id="kobo.91.2">Hence, this is an example scenario where when we perform fine-tuning, we will provide the model with labeled examples of how the prompt and response should </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">look like.</span></span></p>
<p><span class="koboSpan" id="kobo.93.1">In </span><em class="italic"><span class="koboSpan" id="kobo.94.1">continued pre-training</span></em><span class="koboSpan" id="kobo.95.1">, we</span><a id="_idIndexMarker294"/><span class="koboSpan" id="kobo.96.1"> adapt to a new domain or train the model to learn the terminologies of an unfamiliar domain. </span><span class="koboSpan" id="kobo.96.2">This involves providing additional continuous training to an FM while utilizing large amounts of unlabeled data. </span><span class="koboSpan" id="kobo.96.3">When we say unlabeled data, we mean that there is no target label, and the model will learn the patterns from the provided texts. </span><span class="koboSpan" id="kobo.96.4">This contrasts with fine-tuning, which involves using smaller quantities of labeled data. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.97.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.98.1">.4</span></em><span class="koboSpan" id="kobo.99.1"> highlights the difference between the labeled and unlabeled data that’s required for continued pre-training and </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">fine-tuning, respectively:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<span class="koboSpan" id="kobo.101.1"><img alt="Figure 4.4 – Unlabeled versus labeled data" src="image/B22045_04_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.102.1">Figure 4.4 – Unlabeled versus labeled data</span></p>
<p><span class="koboSpan" id="kobo.103.1">Examples of continued pre-training can include training the model to learn the terminologies of the financial industry so that it can understand financial reports, or training the model to learn quantum physics by giving it abundant information from books so that it will be able to evaluate/predict the tokens associated with string theory with greater accuracy. </span><span class="koboSpan" id="kobo.103.2">Let’s say that two physicists are having a dialog around string theory, and we </span><a id="_idIndexMarker295"/><span class="koboSpan" id="kobo.104.1">pass that dialog as a context to the base FM (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.105.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.106.1">.5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<span class="koboSpan" id="kobo.108.1"><img alt="Figure 4.5 – Quantum physicist dialog and question" src="image/B22045_04_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.109.1">Figure 4.5 – Quantum physicist dialog and question</span></p>
<p><span class="koboSpan" id="kobo.110.1">It could be possible that the base FM we are using here isn’t familiar with quantum physics – that is, the base FM hasn’t been trained on a dataset related to </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">quantum physics.</span></span></p>
<p><span class="koboSpan" id="kobo.112.1">So, when we ask the model a question such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.113.1">What are E8 x E8 symmetry groups?</span></strong><span class="koboSpan" id="kobo.114.1">, the model hallucinates and doesn’t explain this concept since it doesn’t know about </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">string theory.</span></span></p>
<p><span class="koboSpan" id="kobo.116.1">With continued pre-training, we train the model on an unfamiliar domain by providing the base FM with a large amount of unlabeled datasets. </span><span class="koboSpan" id="kobo.116.2">For example, we could train the model on textbooks about quantum computing in the desired format, as explained in the </span><em class="italic"><span class="koboSpan" id="kobo.117.1">Preparing the data</span></em><span class="koboSpan" id="kobo.118.1"> section, which</span><a id="_idIndexMarker296"/><span class="koboSpan" id="kobo.119.1"> then creates a custom model (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.120.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.121.1">.6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<span class="koboSpan" id="kobo.123.1"><img alt="Figure 4.6 – Continued pre-training" src="image/B22045_04_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.124.1">Figure 4.6 – Continued pre-training</span></p>
<p><span class="koboSpan" id="kobo.125.1">Continued pre-training presents certain challenges. </span><span class="koboSpan" id="kobo.125.2">As we are training the entire model, the weights and biases are what demand heavy computational resources and diverse unlabeled </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">text data.</span></span></p>
<p><span class="koboSpan" id="kobo.127.1">When you’re deciding whether to use custom models over other methods, such as prompt engineering and RAG, several factors come into play. </span><span class="koboSpan" id="kobo.127.2">These include the task that you are working on, the availability of data, computational resources, and cost. </span><span class="koboSpan" id="kobo.127.3">Here are some guidelines to help you make an </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">informed decision:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.129.1">Complexity level</span></strong><span class="koboSpan" id="kobo.130.1">: Creating custom models is particularly useful when you have tasks that are complex and require the model to understand </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">intricate details.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.132.1">Specialized data</span></strong><span class="koboSpan" id="kobo.133.1">: Having a sufficient amount of specialized data for creating custom models will provide remarkable results. </span><span class="koboSpan" id="kobo.133.2">Make sure your data is clean (free from errors, inconsistencies, and duplicates) and prepared (formatted, transformed, and split into appropriate subsets) before you start the </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">training process.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.135.1">Computational resources and cost</span></strong><span class="koboSpan" id="kobo.136.1">: When you create custom models, you’ll need to purchase Provisioned Throughput, which gives you a dedicated capacity to deploy the model. </span><span class="koboSpan" id="kobo.136.2">Make sure you review the pricing based on the model type and commitment terms. </span><span class="koboSpan" id="kobo.136.3">We will discuss Provisioned Throughput in detail in the </span><em class="italic"><span class="koboSpan" id="kobo.137.1">Analyzing the results</span></em><span class="koboSpan" id="kobo.138.1"> section of </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">this chapter.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.140.1">In addition, creating custom models provides you with greater control over how you want the model to respond. </span><span class="koboSpan" id="kobo.140.2">You can customize it precisely to your needs, making it suitable for tasks that </span><a id="_idIndexMarker297"/><span class="koboSpan" id="kobo.141.1">require fine-grained customization, such as responding in a specific tone, dialect, or </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">inclusive language.</span></span></p>
<p><span class="koboSpan" id="kobo.143.1">Let’s understand some key concepts of model customization before we start our first model </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">customization job.</span></span></p>
<h1 id="_idParaDest-77"><a id="_idTextAnchor078"/><span class="koboSpan" id="kobo.145.1">Understanding model customization</span></h1>
<p><span class="koboSpan" id="kobo.146.1">The principle behind fine-tuning </span><a id="_idIndexMarker298"/><span class="koboSpan" id="kobo.147.1">and continued pre-training comes from the broad concept of </span><strong class="bold"><span class="koboSpan" id="kobo.148.1">transfer learning</span></strong><span class="koboSpan" id="kobo.149.1">, which, as</span><a id="_idIndexMarker299"/><span class="koboSpan" id="kobo.150.1"> its name suggests, entails transferring knowledge that’s been acquired from one problem to other often related but distinct problems. </span><span class="koboSpan" id="kobo.150.2">This practice is widely employed in the field of </span><strong class="bold"><span class="koboSpan" id="kobo.151.1">machine learning</span></strong><span class="koboSpan" id="kobo.152.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.153.1">ML</span></strong><span class="koboSpan" id="kobo.154.1">) to </span><a id="_idIndexMarker300"/><span class="koboSpan" id="kobo.155.1">enhance the performance of models on new tasks </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">or domains.</span></span></p>
<p><span class="koboSpan" id="kobo.157.1">Model customization is a </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">five-step process:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.159.1">Identify your use case and data</span></strong><span class="koboSpan" id="kobo.160.1">: Identifying the use case/task and how it solves your organization’s business objectives is a critical step. </span><span class="koboSpan" id="kobo.160.2">Do you want to summarize legal documents, perform Q&amp;A on medical reports, or do something else? </span><span class="koboSpan" id="kobo.160.3">Once you’ve identified the use case, you must gather enough relevant datasets that you can use for model customization. </span><span class="koboSpan" id="kobo.160.4">The dataset should contain examples that the model can learn intricate details from. </span><span class="koboSpan" id="kobo.160.5">Remember, how your custom model performs on your task-specific use case depends on the quality of the dataset that you provide </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">for training.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.162.1">Prepare the dataset</span></strong><span class="koboSpan" id="kobo.163.1">: Once you’ve gathered the dataset, you have to clean and preprocess it. </span><span class="koboSpan" id="kobo.163.2">For fine-tuning, you need to have labeled examples in </span><strong class="bold"><span class="koboSpan" id="kobo.164.1">JSON lines</span></strong><span class="koboSpan" id="kobo.165.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.166.1">JSONL</span></strong><span class="koboSpan" id="kobo.167.1">) format. </span><span class="koboSpan" id="kobo.167.2">For continued</span><a id="_idIndexMarker301"/><span class="koboSpan" id="kobo.168.1"> pre-training, you need to have unlabeled examples in JSONL format. </span><span class="koboSpan" id="kobo.168.2">We will discuss this in more detail in the </span><em class="italic"><span class="koboSpan" id="kobo.169.1">Preparing the </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.170.1">data</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.171.1"> section.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.172.1">Select the base pre-trained model</span></strong><span class="koboSpan" id="kobo.173.1">: Once the dataset has been prepared, you have to select an existing base pretrained model that you would like to fine-tune. </span><span class="koboSpan" id="kobo.173.2">You can look at the website of the model provider to understand the model attributes. </span><span class="koboSpan" id="kobo.173.3">If it is fit for your use case, try prompt engineering techniques to check which </span><a id="_idIndexMarker302"/><span class="koboSpan" id="kobo.174.1">model responds closest to what you are looking for, and also evaluate the FMs</span><a id="_idIndexMarker303"/><span class="koboSpan" id="kobo.175.1"> using </span><strong class="bold"><span class="koboSpan" id="kobo.176.1">Model evaluation</span></strong><span class="koboSpan" id="kobo.177.1"> within Amazon Bedrock or </span><a id="_idIndexMarker304"/><span class="koboSpan" id="kobo.178.1">using </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.179.1">Model leaderboards</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">:</span></span><ul><li><em class="italic"><span class="koboSpan" id="kobo.181.1">Model evaluation</span></em><span class="koboSpan" id="kobo.182.1">: Bedrock provides two distinct evaluation methods: automatic evaluation and human evaluation. </span><span class="koboSpan" id="kobo.182.2">Automatic evaluation utilizes predefined metrics such as accuracy, robustness, and toxicity screening, whereas with human evaluation, you can define custom metrics such as friendliness, stylistic adherence, or alignment with brand voice. </span><span class="koboSpan" id="kobo.182.3">We will have a more detailed discussion on model evaluation in </span><a href="B22045_11.xhtml#_idTextAnchor207"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.183.1">Chapter 11</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.184.1">.</span></span></li><li><em class="italic"><span class="koboSpan" id="kobo.185.1">Model leaderboards</span></em><span class="koboSpan" id="kobo.186.1">: Several leaderboards are available that rank models based on their performance on various tasks, such as text generation, summarization, sentiment analysis, and more. </span><span class="koboSpan" id="kobo.186.2">Some of the most popular leaderboards</span><a id="_idIndexMarker305"/><span class="koboSpan" id="kobo.187.1"> include </span><strong class="bold"><span class="koboSpan" id="kobo.188.1">General Language Understanding Evaluation</span></strong><span class="koboSpan" id="kobo.189.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.190.1">GLUE</span></strong><span class="koboSpan" id="kobo.191.1">), SuperGLUE, HELM, and OpenLLM </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">by HuggingFace.</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.193.1">Please note that although it’s good to understand the performance of the FM through leaderboards, for real-world use cases, you have to be cautious and not rely solely on leaderboards as they may lack the robustness required to mirror the complexity of </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">real-world use.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.195.1">Configure and start the fine-tuning job</span></strong><span class="koboSpan" id="kobo.196.1">: Once you’ve identified the base FM and the dataset is ready, you can configure the fine-tuning job by specifying hyperparameters, the input and output S3 path for the dataset and store metrics, respectively, and networking and security settings. </span><span class="koboSpan" id="kobo.196.2">We will discuss this in more detail in the </span><em class="italic"><span class="koboSpan" id="kobo.197.1">Creating a custom </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.198.1">model</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.199.1"> section.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.200.1">Evaluate and iterate</span></strong><span class="koboSpan" id="kobo.201.1">: Once the model is ready, you can evaluate and analyze it based on the metrics and logs stored by the model. </span><span class="koboSpan" id="kobo.201.2">To do so, you can put aside a validation set that provides the performance metric of the custom model you’ve created. </span><span class="koboSpan" id="kobo.201.3">We will discuss this in more detail in the </span><em class="italic"><span class="koboSpan" id="kobo.202.1">Analyzing the </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.203.1">results</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.204.1"> section.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.205.1">When we are customizing a </span><a id="_idIndexMarker306"/><span class="koboSpan" id="kobo.206.1">model, Amazon Bedrock creates a copy of the base FM, on which we essentially update its model weights. </span><strong class="bold"><span class="koboSpan" id="kobo.207.1">Weights</span></strong><span class="koboSpan" id="kobo.208.1"> are</span><a id="_idIndexMarker307"/><span class="koboSpan" id="kobo.209.1"> key </span><a id="_idIndexMarker308"/><span class="koboSpan" id="kobo.210.1">components in </span><strong class="bold"><span class="koboSpan" id="kobo.211.1">artificial neural networks</span></strong><span class="koboSpan" id="kobo.212.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.213.1">ANNs</span></strong><span class="koboSpan" id="kobo.214.1">) and are attached to the inputs (or features). </span><span class="koboSpan" id="kobo.214.2">These weights define which features are important in predicting the output and getting better at specific tasks. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.215.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.216.1">.7</span></em><span class="koboSpan" id="kobo.217.1"> shows a simplified ANN architecture where these inputs, along with their weights, are processed by </span><strong class="bold"><span class="koboSpan" id="kobo.218.1">summation</span></strong><span class="koboSpan" id="kobo.219.1"> and the </span><strong class="bold"><span class="koboSpan" id="kobo.220.1">activation function</span></strong><span class="koboSpan" id="kobo.221.1"> (both</span><a id="_idIndexMarker309"/><span class="koboSpan" id="kobo.222.1"> defined in the model algorithm) to get the </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">output (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.224.1">Y</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">).</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<span class="koboSpan" id="kobo.226.1"><img alt="Figure 4.7 – Simplified ANN" src="image/B22045_04_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.227.1">Figure 4.7 – Simplified ANN</span></p>
<p><span class="koboSpan" id="kobo.228.1">For a deeper dive into ANNs, there are numerous online tutorials and courses available that provide in-depth explanations and examples of neural network concepts, architectures, and training techniques. </span><span class="koboSpan" id="kobo.228.2">Additionally, textbook classics such as </span><em class="italic"><span class="koboSpan" id="kobo.229.1">Neural Networks and Deep Learning, Michael Nielsen, Determination Press</span></em><span class="koboSpan" id="kobo.230.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.231.1">Deep Learning, Ian Goodfellow, Yoshua Bengio, and Aaron Courville, MIT Press</span></em><span class="koboSpan" id="kobo.232.1"> offer comprehensive theoretical and </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">mathematical foundations.</span></span></p>
<p><span class="koboSpan" id="kobo.234.1">When we perform model customization (fine-tuning or continued pre-training), we update the model weights. </span><span class="koboSpan" id="kobo.234.2">While updating the model weights, a common problem can occur called </span><strong class="bold"><span class="koboSpan" id="kobo.235.1">catastrophic forgetting</span></strong><span class="koboSpan" id="kobo.236.1">. </span><span class="koboSpan" id="kobo.236.2">This is </span><a id="_idIndexMarker310"/><span class="koboSpan" id="kobo.237.1">when the model starts to forget some information it was originally trained on due to weight modifications, which can lead to degraded performance on more generalized tasks. </span><span class="koboSpan" id="kobo.237.2">In general, this can happen due to overfitting the training data, which means the model provides an accurate response to the training data but can’t generalize well and provides degraded performance on new information. </span><span class="koboSpan" id="kobo.237.3">In addition, customizing the model can be costly and resource-intensive, something that requires extensive </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">memory utilization.</span></span></p>
<p><span class="koboSpan" id="kobo.239.1">To overcome these challenges, a technique called </span><strong class="bold"><span class="koboSpan" id="kobo.240.1">Parameter-efficient Fine-tuning</span></strong><span class="koboSpan" id="kobo.241.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.242.1">PEFT</span></strong><span class="koboSpan" id="kobo.243.1">) was introduced in the paper </span><em class="italic"><span class="koboSpan" id="kobo.244.1">Parameter-Efficient Transfer Learning for </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.245.1">NLP</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.246.1"> (</span></span><a href="https://arxiv.org/pdf/1902.00751"><span class="No-Break"><span class="koboSpan" id="kobo.247.1">https://arxiv.org/pdf/1902.00751</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.248.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.249.1">Note that at the</span><a id="_idIndexMarker311"/><span class="koboSpan" id="kobo.250.1"> time of writing, Bedrock does not support PEFT. </span><span class="koboSpan" id="kobo.250.2">However, it’s good to have an understanding of the </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">PEFT technique.</span></span></p>
<h2 id="_idParaDest-78"><a id="_idTextAnchor079"/><span class="koboSpan" id="kobo.252.1">PEFT</span></h2>
<p><span class="koboSpan" id="kobo.253.1">In PEFT, you</span><a id="_idIndexMarker312"/><span class="koboSpan" id="kobo.254.1"> don’t </span><a id="_idIndexMarker313"/><span class="koboSpan" id="kobo.255.1">need to fine-tune all the model parameters, something that can be quite time-consuming, resource-intensive, and costly. </span><span class="koboSpan" id="kobo.255.2">Instead, it freezes much of the model weights and you only need to train a small number of them. </span><span class="koboSpan" id="kobo.255.3">This makes it memory and compute-efficient, less susceptible to catastrophic forgetting, and cheaper to store the model on </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">the hardware.</span></span></p>
<p><span class="koboSpan" id="kobo.257.1">When fine-tuning LLMs, various techniques can reduce the number of trainable parameters to improve efficiency. </span><span class="koboSpan" id="kobo.257.2">We can categorize these PEFT methods into three </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">main classes:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.259.1">Selective methods</span></strong><span class="koboSpan" id="kobo.260.1">: These</span><a id="_idIndexMarker314"/><span class="koboSpan" id="kobo.261.1"> update only certain components or layers of the original LLM during fine-tuning. </span><span class="koboSpan" id="kobo.261.2">This allows you to focus on the most relevant parts of the model. </span><span class="koboSpan" id="kobo.261.3">However, it can result in suboptimal performance compared to </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">full fine-tuning.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.263.1">Reparameterization methods</span></strong><span class="koboSpan" id="kobo.264.1">: These introduce low-rank matrices to compress the original weights. </span><span class="koboSpan" id="kobo.264.2">Examples include such as </span><strong class="bold"><span class="koboSpan" id="kobo.265.1">Low-Rank Adaptation of Large Language Models</span></strong><span class="koboSpan" id="kobo.266.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.267.1">LoRA</span></strong><span class="koboSpan" id="kobo.268.1">). </span><span class="koboSpan" id="kobo.268.2">This </span><a id="_idIndexMarker315"/><span class="koboSpan" id="kobo.269.1">reduces parameters while still modifying the whole model. </span><span class="koboSpan" id="kobo.269.2">The trade-off is increased memory usage </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">during training.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.271.1">Additive methods</span></strong><span class="koboSpan" id="kobo.272.1">: These keep the original weights of the LLM frozen and add new trainable layers for task-specific adaptation. </span><span class="koboSpan" id="kobo.272.2">Additive methods such as </span><strong class="bold"><span class="koboSpan" id="kobo.273.1">adapters</span></strong><span class="koboSpan" id="kobo.274.1"> add the </span><a id="_idIndexMarker316"/><span class="koboSpan" id="kobo.275.1">trainable layer inside the encoder or decoder component of the </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">transformer architecture.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.277.1">The choice of the PEFT approach involves balancing metrics such as parameter and memory efficiency against model quality, training speed, and cost. </span><span class="koboSpan" id="kobo.277.2">Selectively updating parts of a model offers one end of this trade-off, while adapters and prompts maximize parameter </span><a id="_idIndexMarker317"/><span class="koboSpan" id="kobo.278.1">efficiency at the cost of some </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">architectural </span></span><span class="No-Break"><a id="_idIndexMarker318"/></span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">changes.</span></span></p>
<p><span class="koboSpan" id="kobo.281.1">With that, we’ve covered PEFT and its techniques at a very high level. </span><span class="koboSpan" id="kobo.281.2">However, if you are interested in learning more about it, go to </span><a href="https://github.com/huggingface/peft"><span class="koboSpan" id="kobo.282.1">https://github.com/huggingface/peft</span></a><span class="koboSpan" id="kobo.283.1">. </span><span class="koboSpan" id="kobo.283.2">In addition, the </span><em class="italic"><span class="koboSpan" id="kobo.284.1">Generative AI with Large Language Models</span></em><span class="koboSpan" id="kobo.285.1"> course provides in-depth information about PEFT </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">methods: </span></span><a href="https://www.deeplearning.ai/courses/generative-ai-with-llms/"><span class="No-Break"><span class="koboSpan" id="kobo.287.1">https://www.deeplearning.ai/courses/generative-ai-with-llms/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.288.1">.</span></span></p>
<h2 id="_idParaDest-79"><a id="_idTextAnchor080"/><span class="koboSpan" id="kobo.289.1">Hyperparameter tuning</span></h2>
<p><span class="koboSpan" id="kobo.290.1">In addition to fine-tuning</span><a id="_idIndexMarker319"/><span class="koboSpan" id="kobo.291.1"> techniques such as PEFT, </span><strong class="bold"><span class="koboSpan" id="kobo.292.1">hyperparameter tuning</span></strong><span class="koboSpan" id="kobo.293.1"> also </span><a id="_idIndexMarker320"/><span class="koboSpan" id="kobo.294.1">plays a big role in ensuring a model retains its pretrained knowledge. </span><span class="koboSpan" id="kobo.294.2">Hyperparameters are configuration settings that control the model training process, much like knobs that can be tweaked and tuned. </span><span class="koboSpan" id="kobo.294.3">Models have various hyperparameters, including the learning rate, number of epochs, batch size, beta, gamma, and more. </span><span class="koboSpan" id="kobo.294.4">Each model may require a different set of optimal hyperparameter values, found through experimentation, to achieve the best performance </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">and accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.296.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.297.1">learning rate</span></strong><span class="koboSpan" id="kobo.298.1"> hyperparameter</span><a id="_idIndexMarker321"/><span class="koboSpan" id="kobo.299.1"> controls how quickly the model is adapted to the task. </span><span class="koboSpan" id="kobo.299.2">It also controls how much the model’s parameters are adjusted during each iteration of the training process. </span><span class="koboSpan" id="kobo.299.3">It determines the step size at which the model’s parameters are updated based on the calculated gradients (which represent the direction and magnitude of the changes needed to minimize the </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">loss function).</span></span></p>
<p><span class="koboSpan" id="kobo.301.1">Let’s consider an analogy that might help you visualize the </span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">learning rate.</span></span></p>
<p><span class="koboSpan" id="kobo.303.1">Imagine that you’re trying to find the lowest point in a hilly landscape, but you’re blindfolded. </span><span class="koboSpan" id="kobo.303.2">You can only sense the steepness of the slope you’re standing on (the gradient) and take steps accordingly. </span><span class="koboSpan" id="kobo.303.3">The learning rate determines how big or small those steps </span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">should be:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.305.1">If the learning rate is too high, you might overshoot the lowest point and end up on the other side of the hill, continually overshooting and never converging to the </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">optimal solution</span></span></li>
<li><span class="koboSpan" id="kobo.307.1">If the learning rate is too low, you might take tiny steps and get stuck on a plateau or make painfully slow progress toward the </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">lowest point</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.309.1">The ideal learning rate allows you to take reasonably sized steps that bring you progressively closer to the lowest point (the optimal set of model parameters) without overshooting or </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">getting stuck.</span></span></p>
<p><span class="koboSpan" id="kobo.311.1">In practice, finding the optimal learning rate is often a matter of experimentation and tuning. </span><span class="koboSpan" id="kobo.311.2">Different models and datasets may require different learning rates for the training process to </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">converge effectively.</span></span></p>
<p><span class="koboSpan" id="kobo.313.1">Now that we understand the concepts behind fine-tuning, let’s start the customization process by</span><a id="_idIndexMarker322"/><span class="koboSpan" id="kobo.314.1"> preparing</span><a id="_idIndexMarker323"/> <span class="No-Break"><span class="koboSpan" id="kobo.315.1">the data.</span></span></p>
<h1 id="_idParaDest-80"><a id="_idTextAnchor081"/><span class="koboSpan" id="kobo.316.1">Preparing the data</span></h1>
<p><span class="koboSpan" id="kobo.317.1">We’ve already </span><a id="_idIndexMarker324"/><span class="koboSpan" id="kobo.318.1">seen why customizing the model is important to improve its accuracy and performance. </span><span class="koboSpan" id="kobo.318.2">We’ve also seen that continued pre-training is an unsupervised learning approach that needs unlabeled data, whereas fine-tuning is a supervised learning approach that needs </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">labeled data.</span></span></p>
<p><span class="koboSpan" id="kobo.320.1">The type of data we provide to the model can change the way the model responds. </span><span class="koboSpan" id="kobo.320.2">If the data is biased or has highly correlated features, you might not get the right responses from the trained custom model. </span><span class="koboSpan" id="kobo.320.3">This is true for any ML models you are training, so it is essential to provide high-quality data. </span><span class="koboSpan" id="kobo.320.4">While I won’t cover data processing and feature engineering concepts in this book, I wanted to highlight their importance. </span><span class="koboSpan" id="kobo.320.5">If you wish to learn more about these concepts, you can go through any ML courses and books, such as </span><em class="italic"><span class="koboSpan" id="kobo.321.1">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</span></em><span class="koboSpan" id="kobo.322.1"> by Aurélien Géron, and </span><em class="italic"><span class="koboSpan" id="kobo.323.1">Feature Engineering for Machine Learning</span></em><span class="koboSpan" id="kobo.324.1"> by Alice Zheng and </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">Amanda Casari.</span></span></p>
<p><span class="koboSpan" id="kobo.326.1">The dataset that you need for continued pre-training and fine-tuning should be in JSONL format. </span><span class="koboSpan" id="kobo.326.2">The following documentation explains what JSONL format is, its requirements, sample examples, and its </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">validator: </span></span><a href="https://jsonlines.org/"><span class="No-Break"><span class="koboSpan" id="kobo.328.1">https://jsonlines.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.329.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.330.1">Now, let’s look at the data preparation techniques we can use for </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">both methods.</span></span></p>
<p><span class="koboSpan" id="kobo.332.1">Continued pre-training expects the data to be in </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">{"input": "&lt;raw_text&gt;"}</span></strong><span class="koboSpan" id="kobo.334.1"> format, whereas fine-tuning expects the data to be in </span><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">{"prompt": "&lt;prompt text&gt;", "completion": "&lt;expected generated </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.336.1">text&gt;"}</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.337.1"> format.</span></span></p>
<p><span class="koboSpan" id="kobo.338.1">Here are </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">some examples:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.340.1">Continued pre-training</span></strong><span class="koboSpan" id="kobo.341.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.342.1">{"input": "EBITDA stands for Earnings Before Interest, Tax, Depreciation </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.343.1">and Amortization"}</span></strong></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.344.1">Fine-tuning</span></strong><span class="koboSpan" id="kobo.345.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.346.1">{"prompt": "What's EBITDA?", "completion": "Earnings Before Interest, Tax, Depreciation </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">and Amortization"}</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.348.1">If your dataset comprises images, then you can fine-tune the text-to-image or image-to-embedding model using Titan Image Generator as the base model. </span><span class="koboSpan" id="kobo.348.2">At the time of writing, continued pre-training only supports text-to-text models, not </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">image-generation models.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">For image data, fine-tuning expects the data to be in </span><strong class="source-inline"><span class="koboSpan" id="kobo.351.1">{"image-ref": "s3://path/file1.png", "caption": "caption </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.352.1">text"}</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.353.1"> format.</span></span></p>
<p><span class="koboSpan" id="kobo.354.1">Once you’ve prepared the data, you must split it into train and validation datasets and store it in </span><a id="_idIndexMarker325"/><span class="koboSpan" id="kobo.355.1">an Amazon S3 bucket. </span><span class="koboSpan" id="kobo.355.2">Once you’ve done this, you can create a </span><span class="No-Break"><span class="koboSpan" id="kobo.356.1">custom model.</span></span></p>
<h1 id="_idParaDest-81"><a id="_idTextAnchor082"/><span class="koboSpan" id="kobo.357.1">Creating a custom model</span></h1>
<p><span class="koboSpan" id="kobo.358.1">To create a custom</span><a id="_idIndexMarker326"/><span class="koboSpan" id="kobo.359.1"> model via the AWS console, go to </span><strong class="bold"><span class="koboSpan" id="kobo.360.1">Custom models</span></strong><span class="koboSpan" id="kobo.361.1"> on the Amazon Bedrock console page (</span><a href="https://console.aws.amazon.com/bedrock/home"><span class="koboSpan" id="kobo.362.1">https://console.aws.amazon.com/bedrock/home</span></a><span class="koboSpan" id="kobo.363.1">). </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.364.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.365.1">.8</span></em><span class="koboSpan" id="kobo.366.1"> shows what the </span><strong class="bold"><span class="koboSpan" id="kobo.367.1">Custom models</span></strong><span class="koboSpan" id="kobo.368.1"> page looks like. </span><span class="koboSpan" id="kobo.368.2">It provides information on how the customization process works, as well as two tabs called </span><strong class="bold"><span class="koboSpan" id="kobo.369.1">Models</span></strong><span class="koboSpan" id="kobo.370.1"> and </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.371.1">Training jobs</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.372.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<span class="koboSpan" id="kobo.373.1"><img alt="Figure 4.8 – The Bedrock console – Custom models" src="image/B22045_04_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.374.1">Figure 4.8 – The Bedrock console – Custom models</span></p>
<p><span class="koboSpan" id="kobo.375.1">Under </span><strong class="bold"><span class="koboSpan" id="kobo.376.1">Customize model</span></strong><span class="koboSpan" id="kobo.377.1"> in the </span><strong class="bold"><span class="koboSpan" id="kobo.378.1">Models</span></strong><span class="koboSpan" id="kobo.379.1"> tab, you can select </span><strong class="bold"><span class="koboSpan" id="kobo.380.1">Create Fine-tuning job</span></strong><span class="koboSpan" id="kobo.381.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.382.1">Create Continued Pre-training job</span></strong><span class="koboSpan" id="kobo.383.1">. </span><span class="koboSpan" id="kobo.383.2">When you select either of these options, you can view details about </span><a id="_idIndexMarker327"/><span class="koboSpan" id="kobo.384.1">the job, including its status, under the </span><strong class="bold"><span class="koboSpan" id="kobo.385.1">Training </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.386.1">jobs</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.387.1"> tab.</span></span></p>
<h2 id="_idParaDest-82"><a id="_idTextAnchor083"/><span class="koboSpan" id="kobo.388.1">Components of model customization</span></h2>
<p><span class="koboSpan" id="kobo.389.1">The main components</span><a id="_idIndexMarker328"/><span class="koboSpan" id="kobo.390.1"> of model customization (fine-tuning or continued pre-training) include the source model, hyperparameters, and input data, as demonstrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.391.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.392.1">.9</span></em><span class="koboSpan" id="kobo.393.1">. </span><span class="koboSpan" id="kobo.393.2">These inputs are used to create a training job, which outputs the custom model alongside its metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.394.1">and logs:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<span class="koboSpan" id="kobo.395.1"><img alt="Figure 4.9 – Components of customization job" src="image/B22045_04_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.396.1">Figure 4.9 – Components of customization job</span></p>
<p><span class="koboSpan" id="kobo.397.1">Let’s learn more </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">about these:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.399.1">Source model</span></strong><span class="koboSpan" id="kobo.400.1">: A key component of any customization job is selecting the source model that you wish to customize. </span><span class="koboSpan" id="kobo.400.2">You can find a list of all the supported models under the </span><strong class="bold"><span class="koboSpan" id="kobo.401.1">Model details</span></strong><span class="koboSpan" id="kobo.402.1"> section of the </span><strong class="bold"><span class="koboSpan" id="kobo.403.1">Create Fine-tuning job</span></strong><span class="koboSpan" id="kobo.404.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.405.1">Create Continued Pre-training job</span></strong><span class="koboSpan" id="kobo.406.1"> pages, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.407.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.408.1">.10</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">:</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer064">
<span class="koboSpan" id="kobo.410.1"><img alt="Figure 4.10 – Selecting a model for a customization job" src="image/B22045_04_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.411.1">Figure 4.10 – Selecting a model for a customization job</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.412.1">Hyperparameters</span></strong><span class="koboSpan" id="kobo.413.1">: Along with the source models, you can specify a set of hyperparameters. </span><span class="koboSpan" id="kobo.413.2">These act like external knobs that control how the model is trained. </span><span class="koboSpan" id="kobo.413.3">These are different from inference parameters, which are set during the </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">inference process.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.415.1">Input data</span></strong><span class="koboSpan" id="kobo.416.1">: The dataset that is used to train the model is in JSONL format, and it’s prepared and </span><a id="_idIndexMarker329"/><span class="koboSpan" id="kobo.417.1">stored in an Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">S3 bucket.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.419.1">Training job</span></strong><span class="koboSpan" id="kobo.420.1">: The inputs (source model, hyperparameters, and input data) are used to create a training job. </span><span class="koboSpan" id="kobo.420.2">There are other configuration details, such as VPC settings, which you can use to securely control access to the data in an Amazon S3 bucket, an IAM service role, which provides access to Bedrock to write to an S3 bucket, and model encryption, which you can use encrypt the custom model at rest using a KMS key. </span><span class="koboSpan" id="kobo.420.3">We will cover security and privacy in Amazon Bedrock in </span><a href="B22045_12.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.421.1">Chapter 12</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.422.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.423.1">Custom model</span></strong><span class="koboSpan" id="kobo.424.1">: Once the training process is completed, the custom model is stored in the AWS account owned by the AWS Bedrock </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">Service team.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.426.1">Metrics and logs</span></strong><span class="koboSpan" id="kobo.427.1">: While creating the customization job, you provide the S3 output path where the metrics and logs are stored by the training job. </span><span class="koboSpan" id="kobo.427.2">You will see the </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">step_wise_training_metrics.csv</span></strong><span class="koboSpan" id="kobo.429.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">validation_metrics.csv</span></strong><span class="koboSpan" id="kobo.431.1"> files inside the S3 output path. </span><span class="koboSpan" id="kobo.431.2">We will learn how to evaluate and analyze results in the </span><em class="italic"><span class="koboSpan" id="kobo.432.1">Analyzing the </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.433.1">results</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.434.1"> section.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.435.1">For now, let’s look </span><a id="_idIndexMarker330"/><span class="koboSpan" id="kobo.436.1">at the API calls we can use to create a </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">custom model.</span></span></p>
<h2 id="_idParaDest-83"><a id="_idTextAnchor084"/><span class="koboSpan" id="kobo.438.1">APIs</span></h2>
<p><span class="koboSpan" id="kobo.439.1">Amazon Bedrock </span><a id="_idIndexMarker331"/><span class="koboSpan" id="kobo.440.1">provides several APIs that allow you to create, monitor, and</span><a id="_idIndexMarker332"/><span class="koboSpan" id="kobo.441.1"> stop customization jobs. </span><span class="koboSpan" id="kobo.441.2">This section will examine some of these key APIs: </span><strong class="bold"><span class="koboSpan" id="kobo.442.1">CreateModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.443.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.444.1">ListModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.445.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.446.1">GetModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.447.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">and </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.449.1">StopModelCustomizationJob</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.451.1"> Let’s dive deeper into each of these </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">API calls:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.453.1">CreateModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.454.1">: This API is used to create a customization job that will start the training process and create a custom model. </span><span class="koboSpan" id="kobo.454.2">In this API, you can specify various parameters – for example, you can set </span><strong class="source-inline"><span class="koboSpan" id="kobo.455.1">customizationType</span></strong><span class="koboSpan" id="kobo.456.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.457.1">FINE_TUNING</span></strong><span class="koboSpan" id="kobo.458.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.459.1">CONTINUED_PRE_TRAINING</span></strong><span class="koboSpan" id="kobo.460.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.461.1">baseModelIdentifier</span></strong><span class="koboSpan" id="kobo.462.1"> as the source model you wish to use, relevant hyperparameters, and the input data (training and validation dataset). </span><span class="koboSpan" id="kobo.462.2">Here’s an example of the job being used in the Python </span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">SDK (Boto3):</span></span><pre class="source-code"><span class="koboSpan" id="kobo.464.1">
import boto3</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.465.1">
import json</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.466.1">
llm = boto3.client(service_name='bedrock')</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.467.1">
# Setting customization type</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.468.1">
customizationType = "FINE_TUNING"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.469.1">
# Creating customization job</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.470.1">
llm.create_model_customization_job(</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.471.1">
    jobName="fine-tuning-job",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.472.1">
    customModelName="fine-tuned model",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.473.1">
    roleArn="arn:aws:iam::arn-for-MyBedrockModelCustomizationRole",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.474.1">
    baseModelIdentifier="arn:aws:bedrock:us-east-1::foundation-model/foundation-model-id",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.475.1">
    hyperParameters={</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.476.1">
        "epochCount": "1",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.477.1">
        "batchSize": "1",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.478.1">
        "learningRate": "0.007",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.479.1">
        "learningRateWarmupSteps": "0"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.480.1">
    },</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.481.1">
    trainingDataConfig={"s3Uri": "s3://bucket/path/to/train.jsonl"},</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.482.1">
    validationDataConfig={</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.483.1">
        "validators": [{</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.484.1">
            "s3Uri": "s3://bucket/folder/validation-file.jsonl"</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.485.1">
        }]</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.486.1">
    },</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.487.1">
    outputDataConfig={"s3Uri": "s3://bucket/folder/outputdataconfig/"}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.488.1">
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.489.1">Once you </span><a id="_idIndexMarker333"/><span class="koboSpan" id="kobo.490.1">run</span><a id="_idIndexMarker334"/><span class="koboSpan" id="kobo.491.1"> the preceding code, the training job </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">will start.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.493.1">ListModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.494.1">: You can use this API call to retrieve a list of all the customization jobs that you </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">are running:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.496.1">
import boto3</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.497.1">
llm = boto3.client(service_name='bedrock')</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.498.1">
llm.list_model_customization_jobs()</span></pre></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.499.1">GetModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.500.1">: This API call retrieves detailed information about the customization job. </span><span class="koboSpan" id="kobo.500.2">Here, you can view the status of the job; it can be </span><strong class="source-inline"><span class="koboSpan" id="kobo.501.1">IN_PROGRESS</span></strong><span class="koboSpan" id="kobo.502.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.503.1">STOPPED</span></strong><span class="koboSpan" id="kobo.504.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.505.1">FAILED</span></strong><span class="koboSpan" id="kobo.506.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.507.1">COMPLETE</span></strong><span class="koboSpan" id="kobo.508.1">. </span><span class="koboSpan" id="kobo.508.2">If the model has a status of </span><strong class="source-inline"><span class="koboSpan" id="kobo.509.1">FAILED</span></strong><span class="koboSpan" id="kobo.510.1">, you will </span><em class="italic"><span class="koboSpan" id="kobo.511.1">not</span></em> <span class="No-Break"><span class="koboSpan" id="kobo.512.1">be charged:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.513.1">
import boto3</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.514.1">
llm = boto3.client(service_name='bedrock')</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.515.1">
fine_tune_job = llm.get_model_customization_job(jobIdentifier='arn:aws:bedrock:job-arn-from-create-model-customization')</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.516.1">
print(fine_tune_job['status'])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.517.1">Amazon Bedrock also has integration with Amazon EventBridge, where you can receive a notification whenever there is a status change. </span><span class="koboSpan" id="kobo.517.2">We will dive deeper into the EventBridge integration in </span><a href="B22045_11.xhtml#_idTextAnchor207"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.518.1">Chapter 11</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.519.1">.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.520.1">StopModelCustomizationJob</span></strong><span class="koboSpan" id="kobo.521.1">: If the customization job is </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1">IN_PROGRESS</span></strong><span class="koboSpan" id="kobo.523.1">, and you would like to stop the job for any reason, you can run this </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">API call:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.525.1">
import boto3</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.526.1">
llm = boto3.client(service_name='bedrock')</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.527.1">
llm.stop_model_customization_job(jobIdentifier='arn:aws:bedrock:job-arn-from-create-model-customization')</span></pre></li>
</ul>
<p><span class="koboSpan" id="kobo.528.1">Once you start the customization job, the time it takes to complete will vary depending on the size of the training dataset you provide. </span><span class="koboSpan" id="kobo.528.2">If your dataset contains a few thousand records, the training job can take about an hour, while if the dataset contains millions of records, the </span><a id="_idIndexMarker335"/><span class="koboSpan" id="kobo.529.1">training</span><a id="_idIndexMarker336"/><span class="koboSpan" id="kobo.530.1"> job can take a few days </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">to complete.</span></span></p>
<p><span class="koboSpan" id="kobo.532.1">Once the customization job has been completed and a custom model has been created, we can analyze the </span><a id="_idIndexMarker337"/><span class="koboSpan" id="kobo.533.1">results </span><a id="_idIndexMarker338"/><span class="koboSpan" id="kobo.534.1">and perform inference on </span><span class="No-Break"><span class="koboSpan" id="kobo.535.1">our model.</span></span></p>
<h1 id="_idParaDest-84"><a id="_idTextAnchor085"/><span class="koboSpan" id="kobo.536.1">Analyzing the results</span></h1>
<p><span class="koboSpan" id="kobo.537.1">As mentioned </span><a id="_idIndexMarker339"/><span class="koboSpan" id="kobo.538.1">previously, when creating a customization job, we provide an output S3 path, where the metrics and logs are stored by the training job. </span><span class="koboSpan" id="kobo.538.2">You will see the </span><strong class="source-inline"><span class="koboSpan" id="kobo.539.1">step_wise_training_metrics.csv</span></strong><span class="koboSpan" id="kobo.540.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.541.1">validation_metrics.csv</span></strong><span class="koboSpan" id="kobo.542.1"> files inside the S3 output path. </span><span class="koboSpan" id="kobo.542.2">Within these files, you will see information such as the step number, epoch number, loss, and perplexity. </span><span class="koboSpan" id="kobo.542.3">You will see these details in both the training and validation sets. </span><span class="koboSpan" id="kobo.542.4">Although providing a validation set is optional, doing so allows the performance metrics of the custom model that’s been created to </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">be evaluated.</span></span></p>
<p><span class="koboSpan" id="kobo.544.1">Depending on the size of the dataset, you can decide how much of the validation dataset you would like to hold. </span><span class="koboSpan" id="kobo.544.2">If your dataset is small (for example, it contains hundreds or thousands of records), you can use 90% as the training set and 10% as the validation set. </span><span class="koboSpan" id="kobo.544.3">If your dataset size is large (for example, it contains hundreds of thousands of records), you can reduce the validation set. </span><span class="koboSpan" id="kobo.544.4">So, if you have hundreds of thousands of records, you can use 99% of them as the training set and 1% as the </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">validation set.</span></span></p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor086"/><span class="koboSpan" id="kobo.546.1">Metrics for training and validation</span></h2>
<p><span class="koboSpan" id="kobo.547.1">There are two</span><a id="_idIndexMarker340"/><span class="koboSpan" id="kobo.548.1"> key types of metrics that provide valuable insights into how well the model is learning: loss and perplexity. </span><span class="koboSpan" id="kobo.548.2">Let’s take a </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">closer look:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.550.1">Loss</span></strong><span class="koboSpan" id="kobo.551.1">: This ranges from 0 to infinity. </span><span class="koboSpan" id="kobo.551.2">The loss value that’s calculated during training indicates how well the model fits the training data. </span><span class="koboSpan" id="kobo.551.3">Meanwhile, the validation loss shows how effectively the model generalizes to new, unseen examples after training is completed. </span><span class="koboSpan" id="kobo.551.4">Loss is one of the most commonly used metrics for evaluating the performance of a model during training. </span><span class="koboSpan" id="kobo.551.5">In general, lower loss values are preferable and indicate that the model is fitting the data well. </span><span class="koboSpan" id="kobo.551.6">Higher loss values suggest that the model’s prediction is far off from the actual response and it’s making a lot </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">of errors.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.553.1">Perplexity</span></strong><span class="koboSpan" id="kobo.554.1">: This ranges from 1 to infinity. </span><span class="koboSpan" id="kobo.554.2">It measures a language model’s ability to accurately predict the next token in a sequence. </span><span class="koboSpan" id="kobo.554.3">A lower perplexity score corresponds to better predictions and the </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">model’s capabilities.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.556.1">Both loss and perplexity are important metrics for data scientists to analyze when training models with Bedrock. </span><span class="koboSpan" id="kobo.556.2">A well-performing training run will show the training and validation loss</span><a id="_idIndexMarker341"/><span class="koboSpan" id="kobo.557.1"> values converging over time. </span><span class="koboSpan" id="kobo.557.2">This convergence indicates that the model is learning from the training data </span><span class="No-Break"><span class="koboSpan" id="kobo.558.1">without overfitting.</span></span></p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor087"/><span class="koboSpan" id="kobo.559.1">Inference</span></h2>
<p><span class="koboSpan" id="kobo.560.1">Once the job is successful</span><a id="_idIndexMarker342"/><span class="koboSpan" id="kobo.561.1"> and we’ve verified the training and validation metrics, we are ready to perform inference on our model. </span><span class="koboSpan" id="kobo.561.2">The first thing we need to do is purchase Provisioned Throughput, which gives us a dedicated capacity to deploy the model. </span><span class="koboSpan" id="kobo.561.3">At the time of writing, custom Bedrock models can only be deployed through Provisioned Throughput. </span><span class="koboSpan" id="kobo.561.4">However, you can also use Provisioned Throughput for base FMs supported </span><span class="No-Break"><span class="koboSpan" id="kobo.562.1">by Bedrock.</span></span></p>
<p><span class="koboSpan" id="kobo.563.1">At the time of writing, three commitment terms are available </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">with Bedrock.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.565.1">No commitment</span></strong><span class="koboSpan" id="kobo.566.1"> (</span><span class="No-Break"><span class="koboSpan" id="kobo.567.1">priced hourly)</span></span></li>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.568.1">1 month</span></strong></span></li>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.569.1">6 months</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">:</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer065">
<span class="koboSpan" id="kobo.571.1"><img alt="Figure 4.11 – Model units &amp; commitment term" src="image/B22045_04_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.572.1">Figure 4.11 – Model units &amp; commitment term</span></p>
<p><span class="koboSpan" id="kobo.573.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.574.1">No commitment</span></strong><span class="koboSpan" id="kobo.575.1"> option is only available for custom models with </span><strong class="bold"><span class="koboSpan" id="kobo.576.1">Model units</span></strong><span class="koboSpan" id="kobo.577.1"> set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.578.1">1</span></strong><span class="koboSpan" id="kobo.579.1">. </span><strong class="bold"><span class="koboSpan" id="kobo.580.1">Model units</span></strong><span class="koboSpan" id="kobo.581.1"> are</span><a id="_idIndexMarker343"/><span class="koboSpan" id="kobo.582.1"> a way to define a throughput that’s measured in terms of the maximum number of input and output tokens processed </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">per minute:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer066">
<span class="koboSpan" id="kobo.584.1"><img alt="Figure 4.12 – Provisioned Throughput" src="image/B22045_04_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.585.1">Figure 4.12 – Provisioned Throughput</span></p>
<p><span class="koboSpan" id="kobo.586.1">Once you’ve purchased Provisioned Throughput, you can see its details in the Bedrock console and via the </span><strong class="bold"><span class="koboSpan" id="kobo.587.1">ListProvisionedModelThroughputs</span></strong><span class="koboSpan" id="kobo.588.1"> and </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.589.1">GetProvisionedModelThroughput</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.590.1"> APIs.</span></span></p>
<p><span class="koboSpan" id="kobo.591.1">Once Provisioned Throughput has an </span><em class="italic"><span class="koboSpan" id="kobo.592.1">Active</span></em><span class="koboSpan" id="kobo.593.1"> status, the custom model that you’ve created will be</span><a id="_idIndexMarker344"/><span class="koboSpan" id="kobo.594.1"> deployed to an endpoint. </span><span class="koboSpan" id="kobo.594.2">At this point, you can perform inference on the model using either the playground experience or through an API. </span><span class="koboSpan" id="kobo.594.3">Both options will be </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">discussed next.</span></span></p>
<h3><span class="koboSpan" id="kobo.596.1">Amazon Bedrock playground</span></h3>
<p><span class="koboSpan" id="kobo.597.1">Performing inference</span><a id="_idIndexMarker345"/><span class="koboSpan" id="kobo.598.1"> via the </span><a id="_idIndexMarker346"/><span class="koboSpan" id="kobo.599.1">playground experience is pretty straightforward and similar to how you perform inference on </span><span class="No-Break"><span class="koboSpan" id="kobo.600.1">base FMs.</span></span></p>
<p><span class="koboSpan" id="kobo.601.1">Instead of using the base model, you can select the custom model that you’ve created, at which point you’re ready to ask questions or provide a prompt to your model. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.602.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.603.1">.13</span></em><span class="koboSpan" id="kobo.604.1"> depicts the process of selecting the </span><strong class="bold"><span class="koboSpan" id="kobo.605.1">custom-titan-1705116361</span></strong><span class="koboSpan" id="kobo.606.1"> model from the Bedrock playground, where it can be fine-tuned on user-provisioned </span><span class="No-Break"><span class="koboSpan" id="kobo.607.1">training data:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer067">
<span class="koboSpan" id="kobo.608.1"><img alt="Figure 4.13 – Select model" src="image/B22045_04_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.609.1">Figure 4.13 – Select model</span></p>
<h3><span class="koboSpan" id="kobo.610.1">Amazon Bedrock API</span></h3>
<p><span class="koboSpan" id="kobo.611.1">Bedrock also </span><a id="_idIndexMarker347"/><span class="koboSpan" id="kobo.612.1">provides the </span><strong class="bold"><span class="koboSpan" id="kobo.613.1">InvokeModel</span></strong><span class="koboSpan" id="kobo.614.1"> API. </span><span class="koboSpan" id="kobo.614.2">This is </span><a id="_idIndexMarker348"/><span class="koboSpan" id="kobo.615.1">the same API we used to invoke the base model in </span><a href="B22045_02.xhtml#_idTextAnchor034"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.616.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.617.1">. </span><span class="koboSpan" id="kobo.617.2">The only difference here is that in </span><strong class="source-inline"><span class="koboSpan" id="kobo.618.1">modelId</span></strong><span class="koboSpan" id="kobo.619.1">, we should provide the </span><strong class="source-inline"><span class="koboSpan" id="kobo.620.1">arn</span></strong><span class="koboSpan" id="kobo.621.1"> model of the provisioned endpoint. </span><span class="koboSpan" id="kobo.621.2">You can attain this from the </span><strong class="bold"><span class="koboSpan" id="kobo.622.1">Bedrock Console – Provisioned Throughput</span></strong><span class="koboSpan" id="kobo.623.1"> tab or via the </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.624.1">GetProvisionedModelThroughput</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.625.1"> API:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.626.1">
Bedrock_runtime.invoke_model(
    modelId=arn-provisioned-throughput,
    body="""
{
  "inputText": "Classify this statement as Positive, Neutral, or Negative:\\n'I really do not like this!'",
  "textGenerationConfig":{
    "maxTokenCount": 1,
    "stopSequences": [],
    "temperature": 1,
    "topP": 0.9
  }
"""
)
response_body = response["body"].read().decode('utf8')
print(response_body)
print(json.loads(response_body)["results"][0]["outputText"])</span></pre>
<p><span class="koboSpan" id="kobo.627.1">Now that we understand how to fine-tune models with Amazon Bedrock and leverage Provisioned Throughput, let’s learn how to import selective </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">custom models.</span></span></p>
<h3><span class="koboSpan" id="kobo.629.1">Importing custom models in Amazon Bedrock</span></h3>
<p><span class="koboSpan" id="kobo.630.1">To leverage </span><a id="_idIndexMarker349"/><span class="koboSpan" id="kobo.631.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.632.1">Import Models</span></strong><span class="koboSpan" id="kobo.633.1"> capability </span><a id="_idIndexMarker350"/><span class="koboSpan" id="kobo.634.1">within Amazon Bedrock, navigate to the Bedrock console. </span><span class="koboSpan" id="kobo.634.2">On the left-hand side panel, under </span><strong class="bold"><span class="koboSpan" id="kobo.635.1">Foundation models</span></strong><span class="koboSpan" id="kobo.636.1">, click </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.637.1">Imported models</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.638.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.639.1">Once you land on the </span><strong class="bold"><span class="koboSpan" id="kobo.640.1">Imported models</span></strong><span class="koboSpan" id="kobo.641.1"> page, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.642.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.643.1">.14</span></em><span class="koboSpan" id="kobo.644.1">, you will be able to create a custom model by importing a model directly from Amazon SageMaker (where you might have customized FMs already) or by importing the model files from an Amazon </span><span class="No-Break"><span class="koboSpan" id="kobo.645.1">S3 bucket:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer068">
<span class="koboSpan" id="kobo.646.1"><img alt="Figure 4.14 – Imported models" src="image/B22045_04_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.647.1">Figure 4.14 – Imported models</span></p>
<p><span class="koboSpan" id="kobo.648.1">At the time of writing, importing a model into Amazon Bedrock creates a custom model that supports the </span><span class="No-Break"><span class="koboSpan" id="kobo.649.1">following patterns:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.650.1">Continued pre-training or fine-tuned model</span></strong><span class="koboSpan" id="kobo.651.1">: As explained previously, you can refine the pre-trained model by utilizing proprietary data while the maintaining structural integrity of the original </span><span class="No-Break"><span class="koboSpan" id="kobo.652.1">model configuration.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.653.1">Domain adaptation</span></strong><span class="koboSpan" id="kobo.654.1">: You can tailor the custom-imported model to a specific domain. </span><span class="koboSpan" id="kobo.654.2">This adaptation process will enhance the model’s performance within a target domain by addressing domain-specific variations. </span><span class="koboSpan" id="kobo.654.3">For instance, language adaptation can be undertaken so that responses can be generated in regional dialects or languages, such as Tamil </span><span class="No-Break"><span class="koboSpan" id="kobo.655.1">or Portuguese.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.656.1">Pre-training from scratch</span></strong><span class="koboSpan" id="kobo.657.1">: As you are aware by now, this approach extends beyond merely customizing weights and vocabulary. </span><span class="koboSpan" id="kobo.657.2">This approach provides you with the opportunity to modify fundamental model parameters, including the number of attention heads, hidden layers, or context length. </span><span class="koboSpan" id="kobo.657.3">Additionally, techniques such as post-training quantization or integrating base and adapter weights enable further refinement and optimization of the </span><span class="No-Break"><span class="koboSpan" id="kobo.658.1">model’s architecture.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.659.1">To initiate the </span><strong class="bold"><span class="koboSpan" id="kobo.660.1">Import model</span></strong><span class="koboSpan" id="kobo.661.1"> job, you can provide the model details, including a relevant model name, import job name, and model </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1">import settings.</span></span></p>
<p><span class="koboSpan" id="kobo.663.1">At the time of writing this book, the imported model can support the Mistral, Flan, Llama2, and Llama3 architectures. </span><span class="koboSpan" id="kobo.663.2">As the generative AI landscape evolves, Bedrock may expand the list of supported architectures for model import in </span><span class="No-Break"><span class="koboSpan" id="kobo.664.1">the future.</span></span></p>
<p><span class="koboSpan" id="kobo.665.1">Once a model import job has been completed successfully, the imported model will be listed on the </span><strong class="bold"><span class="koboSpan" id="kobo.666.1">Models</span></strong><span class="koboSpan" id="kobo.667.1"> tab of the </span><strong class="bold"><span class="koboSpan" id="kobo.668.1">Imported models</span></strong><span class="koboSpan" id="kobo.669.1"> page. </span><span class="koboSpan" id="kobo.669.2">Here, you can view key details about the imported model, such as its ARN, model ID, and status. </span><span class="koboSpan" id="kobo.669.3">From this page, you can also use the</span><a id="_idIndexMarker351"/><span class="koboSpan" id="kobo.670.1"> imported model for </span><a id="_idIndexMarker352"/><span class="koboSpan" id="kobo.671.1">inference by invoking it through the </span><span class="No-Break"><span class="koboSpan" id="kobo.672.1">Bedrock API.</span></span></p>
<p><span class="koboSpan" id="kobo.673.1">Detailed information regarding the different model types and open source architectures that Amazon Bedrock’s custom model capability supports can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.674.1">at </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html#model-customization-import-model-architecture"><span class="No-Break"><span class="koboSpan" id="kobo.675.1">https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html#model-customization-import-model-architecture</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.676.1">.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.677.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.678.1">Please ensure that your account has sufficient quota limits to execute the </span><strong class="bold"><span class="koboSpan" id="kobo.679.1">CreateModelImportJob</span></strong><span class="koboSpan" id="kobo.680.1"> action. </span><span class="koboSpan" id="kobo.680.2">If it</span><a id="_idIndexMarker353"/><span class="koboSpan" id="kobo.681.1"> doesn’t, the following error will </span><span class="No-Break"><span class="koboSpan" id="kobo.682.1">be displayed:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer069">
<span class="koboSpan" id="kobo.683.1"><img alt="Figure 4.15 – Error" src="image/B22045_04_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.684.1">Figure 4.15 – Error</span></p>
<p><span class="koboSpan" id="kobo.685.1">You can request for your quota limit to be increased by navigating </span><span class="No-Break"><span class="koboSpan" id="kobo.686.1">to </span></span><a href="https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas"><span class="No-Break"><span class="koboSpan" id="kobo.687.1">https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.688.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.689.1">Throughout this chapter, we’ve learned how to prepare a dataset, customize an FM, and then check its performance and perform inference. </span><span class="koboSpan" id="kobo.689.2">Now, let’s look at some of the guidelines and best </span><a id="_idIndexMarker354"/><span class="koboSpan" id="kobo.690.1">practices we need to consider </span><a id="_idIndexMarker355"/><span class="koboSpan" id="kobo.691.1">while trying to customize </span><span class="No-Break"><span class="koboSpan" id="kobo.692.1">a model.</span></span></p>
<h1 id="_idParaDest-87"><a id="_idTextAnchor088"/><span class="koboSpan" id="kobo.693.1">Guidelines and best practices</span></h1>
<p><span class="koboSpan" id="kobo.694.1">While customizing a </span><a id="_idIndexMarker356"/><span class="koboSpan" id="kobo.695.1">model, it’s ideal to consider the following practices for </span><span class="No-Break"><span class="koboSpan" id="kobo.696.1">optimal results:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.697.1">Providing the dataset</span></strong><span class="koboSpan" id="kobo.698.1">: The most important thing in ML is the dataset. </span><span class="koboSpan" id="kobo.698.2">Most of the time, how your model performs depends on the dataset you provide to train the model. </span><span class="koboSpan" id="kobo.698.3">So, providing quality data that’s aligned with your use case is important. </span><span class="koboSpan" id="kobo.698.4">If you’ve studied ML in university or worked in this field, you might have learned about various feature engineering and data processing techniques you can use to clean and process the data. </span><span class="koboSpan" id="kobo.698.5">For example, you can handle missing values in the dataset, make sure you don’t provide biased data, or ensure that the dataset follows the format that the model expects. </span><span class="koboSpan" id="kobo.698.6">If you would like to learn more about providing quality data, please read </span><em class="italic"><span class="koboSpan" id="kobo.699.1">Feature Engineering for Machine Learning</span></em><span class="koboSpan" id="kobo.700.1"> by Alice Zheng and Amanda Casari. </span><span class="koboSpan" id="kobo.700.2">This same principle applies to generative AI since it is essentially a subset </span><span class="No-Break"><span class="koboSpan" id="kobo.701.1">of ML.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.702.1">Choosing the right FM</span></strong><span class="koboSpan" id="kobo.703.1">: Next, you need to select the base FM that you are looking to customize. </span><span class="koboSpan" id="kobo.703.2">Make sure you look at its attributes, how many tokens it supports, what type of data it’s been trained on, and the size of the model. </span><span class="koboSpan" id="kobo.703.3">Go through the model cards in the Bedrock console, read through the websites of these models, and look at their performance by using standardized benchmarks such as GLUE, SuperGLUE, HELM, and OpenLLM by HuggingFace. </span><span class="koboSpan" id="kobo.703.4">However, keep in mind that you shouldn’t completely rely on these benchmark tools as they may not represent the complexity and diversity of </span><span class="No-Break"><span class="koboSpan" id="kobo.704.1">real-world applications.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.705.1">Identifying hyperparameters</span></strong><span class="koboSpan" id="kobo.706.1">: Once you have a quality dataset and the right base model has been selected, you need to identify the right hyperparameters for customization. </span><span class="koboSpan" id="kobo.706.2">Your goal should be to avoid overfitting; the model should be able to generalize well to the new unseen information. </span><span class="koboSpan" id="kobo.706.3">There are several hyperparameters that you can adjust, such as the number of epochs, batch size, learning rate, early stopping, and others. </span><span class="koboSpan" id="kobo.706.4">You can find a list of hyperparameters that all the Bedrock models support </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1">at </span></span><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html"><span class="No-Break"><span class="koboSpan" id="kobo.708.1">https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.709.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.710.1">Evaluating performance</span></strong><span class="koboSpan" id="kobo.711.1">: Once you’ve fine-tuned the model, evaluate its performance using the validation dataset. </span><span class="koboSpan" id="kobo.711.2">The </span><strong class="bold"><span class="koboSpan" id="kobo.712.1">validation dataset</span></strong><span class="koboSpan" id="kobo.713.1"> is the dataset </span><a id="_idIndexMarker357"/><span class="koboSpan" id="kobo.714.1">that’s held back from training the model and is used for evaluating it instead. </span><span class="koboSpan" id="kobo.714.2">To learn more about data splitting, go to </span><a href="https://mlu-explain.github.io/train-test-validation/"><span class="koboSpan" id="kobo.715.1">https://mlu-explain.github.io/train-test-validation/</span></a><span class="koboSpan" id="kobo.716.1">. </span><span class="koboSpan" id="kobo.716.2">Here, you can look at different metrics, such as loss and perplexity, or use techniques such as accuracy, </span><strong class="bold"><span class="koboSpan" id="kobo.717.1">Bilingual Evaluation Understudy</span></strong><span class="koboSpan" id="kobo.718.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.719.1">BLEU</span></strong><span class="koboSpan" id="kobo.720.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.721.1">Recall-Oriented Understudy for Gisting Evaluation</span></strong><span class="koboSpan" id="kobo.722.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.723.1">ROUGE</span></strong><span class="koboSpan" id="kobo.724.1">) scores. </span><span class="koboSpan" id="kobo.724.2">For context, BLEU scores </span><a id="_idIndexMarker358"/><span class="koboSpan" id="kobo.725.1">indicate the quality assessment </span><a id="_idIndexMarker359"/><span class="koboSpan" id="kobo.726.1">of machine-generated translations compared to reference translations set provided by human translators. </span><span class="koboSpan" id="kobo.726.2">The ROUGE score is useful for text summarization tasks, wherein evaluation is conducted based on the quality of machine-generated summaries compared to the respective reference summaries created by humans.  </span><span class="koboSpan" id="kobo.726.3">If the model doesn’t provide the desired performance results, you have to readjust the hyperparameters or bring in more datasets. </span><span class="koboSpan" id="kobo.726.4">Once the model is ready to be used and provides the desired evaluation results, you can perform inference on </span><span class="No-Break"><span class="koboSpan" id="kobo.727.1">the model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.728.1">Adapting the model for specific domains</span></strong><span class="koboSpan" id="kobo.729.1">: Customizing the model to a business domain is a promising approach for improving productivity and efficiency. </span><span class="koboSpan" id="kobo.729.2">By tailoring the model to the specific needs of a particular industry, we can enable it to perform tasks that were previously impossible or inefficient and create a more competitive and </span><span class="No-Break"><span class="koboSpan" id="kobo.730.1">successful business.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.731.1">Adopting these </span><a id="_idIndexMarker360"/><span class="koboSpan" id="kobo.732.1">practices can help you make the most of customizing an FM and harnessing the true power of </span><span class="No-Break"><span class="koboSpan" id="kobo.733.1">generative AI.</span></span></p>
<h1 id="_idParaDest-88"><a id="_idTextAnchor089"/><span class="koboSpan" id="kobo.734.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.735.1">In this chapter, we explored two model customization techniques, fine-tuning and continued pre-training, the need to customize a model, and understood the concepts behind fine-tuning and continued pre-training. </span><span class="koboSpan" id="kobo.735.2">Further, we prepared our dataset, created a custom model, evaluated the model, and </span><span class="No-Break"><span class="koboSpan" id="kobo.736.1">performed inference.</span></span></p>
<p><span class="koboSpan" id="kobo.737.1">Lastly, we discussed some of the guidelines and best practices you need to consider when customizing </span><span class="No-Break"><span class="koboSpan" id="kobo.738.1">your FM.</span></span></p>
<p><span class="koboSpan" id="kobo.739.1">In the next chapter, we’re going to uncover the power of RAG in solving real-world business problems by using an external data source. </span><span class="koboSpan" id="kobo.739.2">We will delve into the various use cases and sample architectures and implement RAG with </span><span class="No-Break"><span class="koboSpan" id="kobo.740.1">Amazon Bedrock.</span></span></p>
</div>
</body></html>