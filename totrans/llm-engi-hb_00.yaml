- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The field of **LLM** engineering has rapidly emerged as a critical area in artificial
    intelligence and machine learning. As LLMs continue to revolutionize natural language
    processing and generation, the demand for professionals who can effectively implement,
    optimize, and deploy these models in real-world scenarios has grown exponentially.
    LLM engineering encompasses a wide range of disciplines, from data preparation
    and model fine-tuning to inference optimization and production deployment, requiring
    a unique blend of software engineering, machine learning expertise, and domain
    knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine Learning Operations** (**MLOps**) plays a crucial role in the successful
    implementation of LLMs in production environments. MLOps extends the principles
    of DevOps to machine learning projects, focusing on automating and streamlining
    the entire ML lifecycle. For LLMs, MLOps is particularly important due to the
    complexity and scale of these models. It addresses challenges such as managing
    large datasets, handling model versioning, ensuring reproducibility, and maintaining
    model performance over time. By incorporating MLOps practices, LLM projects can
    achieve greater efficiency, reliability, and scalability, ultimately leading to
    more successful and impactful deployments.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The LLM Engineer’s Handbook** is a comprehensive guide to applying best practices
    to the new field of LLM engineering. Throughout the chapters, readers will find
    simplified key concepts, practical techniques, and experts tips for every stage
    of the LLM lifecycle. The book covers topics such as data engineering, supervised
    fine-tuning, model evaluation, inference optimization, and **Retrieval-Augmented
    Generation** (**RAG**) pipeline development.'
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate these concepts in action, an end-to-end project called the LLM
    Twin will be developed throughout the book., with the goal of imitating someone’s
    writing style and personality. This use case will demonstrate how to build a minimum
    viable product to solve a specific problem, using various aspects of LLM engineering
    and MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: Readers can expect to gain a deeper understanding of how to collect and prepare
    data for LLMs, fine-tune models for specific tasks, optimize inference performance,
    and implement RAG pipelines. They will learn how to evaluate LLM performance,
    align models with human preferences, and deploy LLM-based applications. The book
    also covers essential MLOps principles and practices, enabling readers to build
    scalable, reproducible, and robust LLM applications.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is intended for a wide range of technology professionals and enthusiasts
    interested in the practical applications of LLMs. It’s ideal for software engineers
    aiming to transition into AI projects. While some familiarity with software development
    is beneficial, the book explains many concepts from the ground up, making it accessible
    even to those who are new to AI and machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: For those already working with machine learning , this book will enhance your
    skills in implementing and deploying LLM-based systems. We provide a deep dive
    into the fundamentals of MLOps, guiding you through the process of creating a
    minimum viable product using an open-source LLM to solve real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Chapter 1*, *Understanding the LLM Twin Concept and Architecture*, introduces
    the LLM Twin project, which is used throughout the book as an end-to-end example
    of a production-level LLM application, and defines the FTI architecture for building
    scalable ML systems and applies it to the LLM Twin use case.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 2*, *Tooling and Installation*, presents Python, MLOps, and cloud
    tools used to build real-world LLM applications, such as an orchestrator, experiment
    tracker, prompt monitoring and LLM evaluation tool. It shows how to use and install
    them locally for testing and development.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 3*, *Data Engineering*, shows the implementation of a data collection
    pipeline that scrapes multiple sites, such as Medium, GitHub and Substack and
    stores the raw data in a data warehouse. It emphasizes collecting raw data from
    dynamic sources over static datasets for real-world ML applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 4*, *RAG Feature Pipeline*, introduces RAG fundamental concepts, such
    as embeddings, the vanilla RAG framework, vector databases, and how to optimize
    RAG applications. It applies the RAG theory by architecting and implementing LLM
    Twin’s RAG feature pipeline using software best practices.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 5*, *Supervised Fine-Tuning*, explores the process of refining pre-trained
    language models for specific tasks using instruction-answer pairs. It covers creating
    high-quality datasets, implementing fine-tuning techniques like full fine-tuning,
    LoRA, and QLoRA, and provides a practical demonstration of fine-tuning a Llama
    3.1 8B model on a custom dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 6*, *Fine-Tuning with Preference Alignment*, introduces techniques
    for aligning language models with human preferences, focusing on **Direct Preference
    Optimization** (**DPO**). It covers creating custom preference datasets, implementing
    DPO, and provides a practical demonstration of aligning the TwinLlama-3.1-8B model
    using the Unsloth library.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 7*, *Evaluating LLMs*, details various methods for assessing the performance
    of language models and LLM systems. It introduces general-purpose and domain-specific
    evaluations and discusses popular benchmarks. The chapter includes a practical
    evaluation of the TwinLlama-3.1-8B model using multiple criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 8*, *Inference Optimization*, covers key optimization strategies such
    as speculative decoding, model parallelism, and weight quantization. It discusses
    how to improve inference speed, reduce latency, and minimize memory usage, introducing
    popular inference engines and comparing their features.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 9*, *RAG Inference Pipeline*, explores advanced RAG techniques by
    implementing methods such as self-query, reranking, and filtered vector search
    from scratch. It covers designing and implementing the LLM Twin’s RAG inference
    pipeline and a custom retrieval module similar to what you see in popular frameworks
    such as LangChain.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 10*, *Inference Pipeline Deployment*, introduces ML deployment strategies,
    such as online, asynchronous and batch inference, which will help in architecting
    and deploying the LLM Twin fine-tuned model to AWS SageMaker and building a FastAPI
    microservice to expose the RAG inference pipeline as a RESTful API.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 11*, *MLOps and LLMOps*, presents what LLMOps is, starting with its
    roots in DevOps and MLOps. This chapter explains how to deploy the LLM Twin project
    to the cloud, such as the ML pipelines to AWS and shows how to containerize the
    code using Docker and build a CI/CD/CT pipeline. It also adds a prompt monitoring
    layer on top of LLM Twin’s inference pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Appendix*, *MLOps Principles*, covers the six MLOps principles used to build
    scalable, reproducible, and robust ML applications.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To maximize your learning experience, you are expected to have, at the very
    least, a foundational understanding of software development principles and practices.
    Familiarity with Python programming is particularly beneficial, as the book’s
    examples and code snippets are predominantly in Python. While prior experience
    with machine learning concepts is advantageous, it is not strictly necessary,
    as the book provides explanations for many fundamental AI and ML concepts. However,
    you should be comfortable with basic data structures, algorithms, and have some
    experience working with APIs and cloud services.
  prefs: []
  type: TYPE_NORMAL
- en: Familiarity with version control systems like Git is assumed, as this book has
    a GitHub repository for code examples. While this book is designed to be accessible
    to those who are new to AI and LLMs, if you have some background in these areas,
    you will find it easier to grasp the more advanced concepts and techniques we
    present.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code bundle for the book is hosted on GitHub at [https://github.com/PacktPublishing/LLM-Engineers-Handbook](https://github.com/PacktPublishing/LLM-Engineers-Handbook).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://packt.link/gbp/9781836200079](https://packt.link/gbp/9781836200079).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    For example: “In the `format_samples` function, we apply the Alpaca chat template
    to each individual message.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    the screen. For instance, words in menus or dialog boxes appear in the text like
    this. For example: “To do so, go to the **Settings** tab at the top of the forked
    repository in GitHub. In the left panel, in the **Security** section, click on
    the **Secrets and Variables** toggle and, finally, click on **Actions**.”'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings or important notes appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book’s
    title in the subject of your message. If you have questions about any aspect of
    this book, please email us at `questions@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you reported this to us. Please visit [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    click **Submit Errata**, and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [http://authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share your thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *LLM Engineer’s Handbook, First Edition*, we’d love to hear
    your thoughts! Please [click here to go straight to the Amazon review page](https://packt.link/r/1836200072)
    for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scan the QR code or visit the link below:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B31105_Free_PDF_QR.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/9781836200079](https://packt.link/free-ebook/9781836200079)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
