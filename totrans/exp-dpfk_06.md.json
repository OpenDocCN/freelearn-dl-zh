["```py\nimport torch\nfrom torch import nn\n```", "```py\n    class Upscale(nn.Module):\n      \"\"\" Upscale block to double the width/height from depth. \"\"\"\n      def __init__(self, size):\n        super().__init__()\n    ```", "```py\n    self.conv = nn.Conv2d(size * 2, size * 2 * 2, kernel_size=3,\n      padding=\"same\")\n    self.shuffle = nn.PixelShuffle(2)\n    ```", "```py\n    def forward(self, x):\n      \"\"\" Upscale forward pass \"\"\"\n      x = self.conv(x)\n      x = self.shuffle(x)\n      return x\n    ```", "```py\n    class OriginalEncoder(nn.Module):\n        \"\"\" Face swapping encoder\n        Shared to create encodings for both the faces\n        \"\"\"\n    ```", "```py\n    def __init__(self):\n      super().__init__()\n    ```", "```py\n    self.activation = nn.LeakyReLU(.1)\n    ```", "```py\n    self.conv_tower = nn.Sequential(\n      nn.Conv2d(3, 128, kernel_size=5, stride=2, padding=2),\n      self.activation,\n      nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),\n      self.activation,\n      nn.Conv2d(256, 512, kernel_size=5, stride=2, padding=2),\n      self.activation,\n      nn.Conv2d(512, 1024, kernel_size=5, stride=2, padding=2),\n      self.activation)\n    ```", "```py\n    self.flatten = nn.Flatten()\n    ```", "```py\n    self.dense1 = nn.Linear(4 * 4 * 1024, 1024)\n    self.dense2 = nn.Linear(1024, 4 * 4 * 1024)\n    ```", "```py\n    self.upscale = Upscale(512)\n    ```", "```py\n    def forward(self, x):\n      \"\"\" Encoder forward pass \"\"\"\n    ```", "```py\n    batch_size = x.shape[0]\n    ```", "```py\n    x = self.conv_tower(x)\n    x = self.flatten(x)\n    x = self.dense1(x)\n    x = self.dense2(x)\n    x = torch.reshape(x, [batch_size, 1024, 4, 4])\n    x = self.upscale(x)\n    x = self.activation(x)\n    return x\n    ```", "```py\n    class OriginalDecoder(nn.Module):\n      \"\"\" Face swapping decoder\n      An instance for each face to decode the shared encodings.\n      \"\"\"\n      def __init__(self):\n        super().__init__()\n    ```", "```py\n    self.activation = nn.LeakyReLU(.1)\n    ```", "```py\n    self.upscale_tower = nn.Sequential(Upscale(256),\n      self.activation,\n      Upscale(128),\n      self.activation,\n      Upscale(64),\n      self.activation)\n    ```", "```py\n    self.output = nn.Conv2d(64, 3, 5, padding=\"same\")\n    ```", "```py\n    def forward(self, x):\n      \"\"\" Decoder forward pass \"\"\"\n      x = self.upscale_tower(x)\n      x = self.output(x)\n      x = torch.sigmoid(x)\n      return x\n    ```", "```py\n    from glob import glob\n    import os\n    import random\n    from argparse import ArgumentParser\n    import cv2\n    import numpy as np\n    from tqdm import tqdm\n    import torch\n    from lib.models import OriginalEncoder, OriginalDecoder\n    ```", "```py\n    If __name__ == \"__main__\":\n      # Train a deepfake model from two folders of face images.\n      #    Example CLI:\n      #    ------------\n      #    python c6-train.py \"C:/media/face1\"\n                              \"C:/media/face2\"\n    ```", "```py\n    parser = ArgumentParser()\n    parser.add_argument(\"patha\",\n      help=\"folder of images of face a\")\n    parser.add_argument(\"pathb\",\n      help=\"folder of images of face b\")\n    parser.add_argument(\"--cpu\",\n      action=\"store_true\",\n      help=\"Force CPU usage\")\n    parser.add_argument(\"--batchsize\",\n      type=int, default=16,\n      help=\"Number of images to include in a batch\")\n    parser.add_argument(\"--iterations\", type=int, default=100000,\n      help=\"Number of iterations to process before stopping\")\n    parser.add_argument(\"--learning-rate\",\n      type=float, default=.000001,\n      help=\"Number of images to include in a batch\")\n    parser.add_argument(\"--save_freq\",\n      type=int, default=1000,\n      help=\"Number of iterations to save between\")\n    parser.add_argument(\"--out_path\",\n      default=\"model/\",\n      help=\"folder to place models\")\n    ```", "```py\n    opt = parser.parse_args()\n    main(opt)\n    ```", "```py\n    def main(opt):\n      \"\"\" Train a deepfake model from two folders of face images.\n      \"\"\"\n      device = \"cuda\" if torch.cuda.is_available() and not opt.cpu else \"cpu\"\n    os.makedirs(opt.out_path, exist_ok=True)\n    ```", "```py\n    encoder = OriginalEncoder()\n    decodera = OriginalDecoder()\n    decoderb = OriginalDecoder()\n    ```", "```py\n    if os.path.exists(os.path.join(opt.out_path,\"encoder.pth\")):\n      encoder.load_state_dict( torch.load(\n        os.path.join(opt.out_path, \"encoder.pth\")).state_dict())\n      decodera.load_state_dict( torch.load(\n        os.path.join(opt.out_path,\"decodera.pth\")).state_dict())\n      decoderb.load_state_dict( torch.load(\n        os.path.join(opt.out_path,\"decoderb.pth\")).state_dict())\n    ```", "```py\n    imagesa = glob(os.path.join(opt.patha, \"face_aligned_*.png\"))\n    imagesb = glob(os.path.join(opt.pathb, \"face_aligned_*.png\"))\n    ```", "```py\n    img_tensora = torch.zeros([opt.batchsize, 3, 64, 64])\n    img_tensorb = torch.zeros([opt.batchsize, 3, 64, 64])\n    mask_tensora = torch.zeros([opt.batchsize, 1, 64, 64])\n    mask_tensorb = torch.zeros([opt.batchsize, 1, 64, 64])\n    ```", "```py\n    encoder_optimizer = torch.optim.Adam(\n      encoder.parameters(), lr=opt.learning_rate/2)\n    decodera_optimizer = torch.optim.Adam(\n      decodera.parameters(), lr=opt.learning_rate)\n    decoderb_optimizer = torch.optim.Adam(\n      decoderb.parameters(), lr=opt.learning_rate)\n    loss_function = torch.nn.MSELoss()\n    ```", "```py\n    if device == \"cuda\":\n      encoder = encoder.cuda()\n      decodera = decodera.cuda()\n      decoderb = decoderb.cuda()\n      img_tensora = img_tensora.cuda()\n      img_tensorb = img_tensorb.cuda()\n      mask_tensora = mask_tensora.cuda()\n      mask_tensorb = mask_tensorb.cuda()\n    ```", "```py\n    pbar = tqdm(range(opt.iterations))\n    for iteration in pbar:\n    ```", "```py\n    images = random.sample(imagesa, opt.batchsize)\n    for imgnum, imagefile in enumerate(images):\n      img = cv2.imread(imagefile)\n      img = cv2.resize(image, (64, 64))\n      mask = cv2.imread(imagefile.replace(\"aligned\", \"mask\"), 0)\n      mask = cv2.resize(mask, (64, 64))\n      if np.random.rand() > .5:\n        image = cv2.flip(img, 1)\n        mask = cv2.flip(mask, 1)\n      img_tensor = torch.tensor(img[...,::-1]/255).permute(2,0,1)\n      mask_tensor = torch.where(torch.tensor(mask) > 200, 1, 0)\n      if device == \"cuda\":\n        img_tensor = img_tensor.cuda()\n        mask_tensor = mask_tensor.cuda()\n      img_tensora[imgnum] = img_tensor\n      mask_tensora[imgnum] = mask_tensor\n    ```", "```py\n    images = random.sample(imagesb, opt.batchsize)\n    for imgnum, imagefile in enumerate(images):\n      img = cv2.imread(imagefile)\n      img = cv2.resize(image, (64, 64))\n      mask = cv2.imread(imagefile.replace(\"aligned\", \"mask\"), 0)\n      mask = cv2.resize(mask, (64, 64))\n      if np.random.rand() > .5:\n        image = cv2.flip(img, 1)\n        mask = cv2.flip(mask, 1)\n      img_tensor = torch.tensor(img[...,::-1]/255).permute(2,0,1)\n      mask_tensor = torch.where(torch.tensor(mask) > 200, 1, 0)\n      if device == \"cuda\":\n        img_tensor = img_tensor.cuda()\n        mask_tensor = mask_tensor.cuda()\n      img_tensorb[imgnum] = img_tensor\n      mask_tensorb[imgnum] = mask_tensor\n    ```", "```py\n    Encoder_optimizer.zero_grad()\n    decodera_optimizer.zero_grad()\n    ```", "```py\n    Outa = decodera(encoder(img_tensora))\n    ```", "```py\n    Lossa = loss_function(\n      outa * mask_tensora, img_tensora * mask_tensora)\n    lossa.backward()\n    encoder_optimizer.step()\n    decodera_optimizer.step()\n    ```", "```py\n    encoder_optimizer.zero_grad()\n    decoderb_optimizer.zero_grad()\n    outb = decoderb(encoder(img_tensorb))\n    lossb = loss_function(\n      outb * mask_tensorb, img_tensorb * mask_tensorb)\n    lossb.backward()\n    encoder_optimizer.step()\n    decoderb_optimizer.step()\n    ```", "```py\n    pbar.set_description(f\"A: {lossa.detach().cpu().numpy():.6f} \"\n      f\"B: {lossb.detach().cpu().numpy():.6f}\")\n    ```", "```py\n    if iteration % opt.save_freq == 0:\n      with torch.no_grad():\n        outa = decodera(encoder(img_tensora[:1]))\n        outb = decoderb(encoder(img_tensorb[:1]))\n        swapa = decoderb(encoder(img_tensora[:1]))\n        swapb = decodera(encoder(img_tensorb[:1]))\n    ```", "```py\n    example = np.concatenate([\n      img_tensora[0].permute(1, 2, 0).detach().cpu().numpy(),\n      outa[0].permute(1, 2, 0).detach().cpu().numpy(),\n      swapa[0].permute(1, 2, 0).detach().cpu().numpy(),\n      img_tensorb[0].permute(1, 2, 0).detach().cpu().numpy(),\n      outb[0].permute(1, 2, 0).detach().cpu().numpy(),\n      swapb[0].permute(1, 2, 0).detach().cpu().numpy()\n      ],axis=1)\n    ```", "```py\n    cv2.imwrite(\n      os.path.join(opt.out_path, f\"preview_{iteration}.png\"),\n      example[...,::-1]*255)\n    ```", "```py\n    torch.save(encoder,\n      os.path.join(opt.out_path, \"encoder.pth\"))\n    torch.save(decodera,\n      os.path.join(opt.out_path, \"decodera.pth\"))\n    torch.save(decoderb,\n      os.path.join(opt.out_path, \"decoderb.pth\"))\n    ```", "```py\n    torch.save(encoder,\n      os.path.join(opt.out_path, \"encoder.pth\"))\n    torch.save(decodera,\n      os.path.join(opt.out_path, \"decodera.pth\"))\n    torch.save(decoderb,\n      os.path.join(opt.out_path, \"decoderb.pth\"))\n    ```"]