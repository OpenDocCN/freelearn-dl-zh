<html><head></head><body>
		<div id="_idContainer122" class="calibre2">
			<h1 id="_idParaDest-167" class="chapter-number"><a id="_idTextAnchor172" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1.1">8</span></h1>
			<h1 id="_idParaDest-168" class="calibre5"><a id="_idTextAnchor173" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.2.1">Fine-Tuning</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.3.1">What happens when prompt engineering efforts have gone as far as they can go? </span><span class="kobospan" id="kobo.3.2">If higher quality results are still needed, examples are overwhelming the prompt, performance issues appear, or token costs are excessive because of a large prompt, </span><strong class="bold"><span class="kobospan" id="kobo.4.1">fine-tuning</span></strong><span class="kobospan" id="kobo.5.1"> comes into </span><span><span class="kobospan" id="kobo.6.1">the picture.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.7.1">As mentioned in the last chapter, solutions sometimes require overlapping approaches such as </span><strong class="bold"><span class="kobospan" id="kobo.8.1">Retrieval-Augmented Generation</span></strong><span class="kobospan" id="kobo.9.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.10.1">RAG</span></strong><span class="kobospan" id="kobo.11.1">), prompt engineering, and fine-tuning. </span><span class="kobospan" id="kobo.11.2">Fine-tuning helps the model improve its understanding. </span><span class="kobospan" id="kobo.11.3">We will focus on a few critical deliverables before contextualizing them by completing the Wove case study started in </span><a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.12.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.13.1">, </span><em class="italic"><span class="kobospan" id="kobo.14.1">Gathering Data – Content </span></em><span><em class="italic"><span class="kobospan" id="kobo.15.1">is King</span></em></span><span><span class="kobospan" id="kobo.16.1">:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span><span class="kobospan" id="kobo.17.1">Fine-tuning 101</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.18.1">Creating </span><span><span class="kobospan" id="kobo.19.1">fine-tuned models</span></span></li>
				<li class="calibre8"><span><span class="kobospan" id="kobo.20.1">Fine-tuning tips</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.21.1">Wove case </span><span><span class="kobospan" id="kobo.22.1">study, continued</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.23.1">Regardless of the tools, the team must care and feed the </span><strong class="bold"><span class="kobospan" id="kobo.24.1">large language model</span></strong><span class="kobospan" id="kobo.25.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.26.1">LLM</span></strong><span class="kobospan" id="kobo.27.1">) to improve the output. </span><span class="kobospan" id="kobo.27.2">Though the methods discussed in the book can reach limits, fine-tuning is another </span><span><span class="kobospan" id="kobo.28.1">excellent trick.</span></span></p>
			<h1 id="_idParaDest-169" class="calibre5"><a id="_idTextAnchor174" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.29.1">Fine-tuning 101</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.30.1">Think of fine-tuning as teaching the solution how to approach a problem. </span><span class="kobospan" id="kobo.30.2">You are not telling it the exact answers. </span><span class="kobospan" id="kobo.30.3">That is for RAG. </span><span class="kobospan" id="kobo.30.4">You coach the LLM on approaching issues, thinking about the solution, and </span><a id="_idIndexMarker553" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.31.1">how it should respond. </span><span class="kobospan" id="kobo.31.2">Even though specific examples are used in fine-tuning, don’t expect it to use that exact example </span><em class="italic"><span class="kobospan" id="kobo.32.1">ever</span></em><span class="kobospan" id="kobo.33.1">. </span><span class="kobospan" id="kobo.33.2">It is just an example. </span><span class="kobospan" id="kobo.33.3">Imagine we need it to be like a science teacher, so the LLM is told in prompts to </span><em class="italic"><span class="kobospan" id="kobo.34.1">be a science teacher</span></em><span class="kobospan" id="kobo.35.1">, but if it needs to </span><em class="italic"><span class="kobospan" id="kobo.36.1">sound like</span></em><span class="kobospan" id="kobo.37.1"> an 8</span><span class="superscript"><span class="kobospan1" id="kobo.38.1">th</span></span><span class="kobospan" id="kobo.39.1">-grade science teacher, share examples of what it is expected to sound like. </span><span class="kobospan" id="kobo.39.2">Then, when these examples are added to the models, compare them against output examples and decide whether they are doing a good job. </span><span class="kobospan" id="kobo.39.3">We will do this work using fine-tuning in the ChatGPT playground, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.40.1">Figure 8</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.41.1">.1</span></em></span><span><span class="kobospan" id="kobo.42.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer105" class="img---figure">
					<span class="kobospan" id="kobo.43.1"><img src="image/B21964_08_01.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.44.1">Figure 8.1 – Fine-tuning in ChatGPT</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.45.1">We will walk through an example. </span><span class="kobospan" id="kobo.45.2">This will give a feel for what is being built, how to contribute examples for training and testing, and what the results are when the model is improved </span><span><span class="kobospan" id="kobo.46.1">with fine-tuning.</span></span></p>
			<h2 id="_idParaDest-170" class="calibre9"><a id="_idTextAnchor175" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.47.1">Prompt engineering or fine-tuning? </span><span class="kobospan" id="kobo.47.2">Where to spend resources</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.48.1">We already know you</span><a id="_idIndexMarker554" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.49.1"> need both, but if examples are added to the prompts, each use of the prompt will incur a cost because the input tokens cost money every time they are sent to the model. </span><span class="kobospan" id="kobo.49.2">One trick is to move training data from prompts to fine-tuning. </span><span class="kobospan" id="kobo.49.3">As new examples or edge cases are discovered, add them to improve </span><span><span class="kobospan" id="kobo.50.1">the model.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.51.1">Start with prompt engineering and move on to fine-tuning</span></p>
			<p class="callout"><span class="kobospan" id="kobo.52.1">The prompt engineering tools in </span><a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.53.1">Chapter 7</span></em></span></a><span class="kobospan" id="kobo.54.1">, </span><em class="italic"><span class="kobospan" id="kobo.55.1">Prompt Engineering,</span></em><span class="kobospan" id="kobo.56.1"> give value and include a faster feedback loop than the more technical efforts needed for fine-tuning. </span><span class="kobospan" id="kobo.56.2">Creating datasets and running</span><a id="_idIndexMarker555" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.57.1"> training jobs takes more effort and time to see results. </span><span class="kobospan" id="kobo.57.2">In enterprise use cases, both will be required. </span><span class="kobospan" id="kobo.57.3">Responding to a fine-tuned model can be much less expensive and faster than responding to a large prompt with many examples to process </span><span><span class="kobospan" id="kobo.58.1">each turn.</span></span></p>
			<h2 id="_idParaDest-171" class="calibre9"><a id="_idTextAnchor176" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.59.1">Token costs do matter</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.60.1">It is expected to start with growing prompts by including examples of how the model should respond. </span><span class="kobospan" id="kobo.60.2">There can be </span><a id="_idIndexMarker556" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.61.1">significant costs if large prompts are used tens of millions of times as each customer interacts with the LLM. </span><span class="kobospan" id="kobo.61.2">Compare the following prompts with learning examples to a fine-tuned model that contains the </span><span><span class="kobospan" id="kobo.62.1">same examples:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.63.1">
Classify what we give you into a positive or negative statement. </span><span class="kobospan1" id="kobo.63.2">Here are some examples.
</span><span class="kobospan1" id="kobo.63.3">You are a bad driver -- Negative
Your hair looks amazing -- Positive
The sunrise is beautiful – Positive
(Truncated. </span><span class="kobospan1" id="kobo.63.4">50 examples total)</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.64.1">Remove these from the prompt and add them to a fine-tuned model behind the scenes with the exact examples. </span><span class="kobospan" id="kobo.64.2">This leaves the prompt </span><span><span class="kobospan" id="kobo.65.1">like this:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.66.1">
Classify what we give you into a positive or negative statement.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.67.1">The former includes about 500 tokens, using just 50 examples, while the prompt alone is 14 tokens. </span><span class="kobospan" id="kobo.67.2">By moving the examples into a fine-tuned model, each turn will save 97% in input tokens. </span><span class="kobospan" id="kobo.67.3">A fine-tuning model can cost more than a generic model. </span><span class="kobospan" id="kobo.67.4">We can compare the input costs, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.68.1">Table 8.1</span></em></span><span><span class="kobospan" id="kobo.69.1">.</span></span></p>
			<table id="table001-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.70.1">Model</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.71.1">Costs</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.72.1">Cost for 10,000 prompts @ 500 tokens </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.73.1">per prompt</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.74.1">Cost for 10,000 prompts @ 14 tokens </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.75.1">per prompt</span></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.76.1">GPT-3.5 </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.77.1">Turbo fine-tuned</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.78.1">$3.00 / 1M </span><span><span class="kobospan" id="kobo.79.1">input tokens</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.80.1">$</span><span><span class="kobospan" id="kobo.81.1">15.00</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.82.1">(</span><span><span class="kobospan" id="kobo.83.1">good results)</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.84.1">$</span></strong><span><strong class="bold"><span class="kobospan" id="kobo.85.1">0.42</span></strong></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.86.1">(savings </span><span><span class="kobospan" id="kobo.87.1">of 97%)</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.88.1">(</span><span><span class="kobospan" id="kobo.89.1">good results)</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.90.1">GPT-3.5 Turbo</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.91.1">$0.50 / 1M </span><span><span class="kobospan" id="kobo.92.1">input tokens</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.93.1">$</span></strong><span><strong class="bold"><span class="kobospan" id="kobo.94.1">2.50</span></strong></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.95.1">(hard to </span><span><span class="kobospan" id="kobo.96.1">improve results)</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.97.1">$</span><span><span class="kobospan" id="kobo.98.1">0.07</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.99.1">(hard to </span><span><span class="kobospan" id="kobo.100.1">improve results)</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.101.1">GPT-4o mini</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.102.1">$0.15 / 1M </span><span><span class="kobospan" id="kobo.103.1">input tokens</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.104.1">$</span><span><span class="kobospan" id="kobo.105.1">0.75</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.106.1">$0.021 (a little over </span><span><span class="kobospan" id="kobo.107.1">2 cents)</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.108.1">Table 8.1 – Comparison of costs for models using fine-tuning and reducing prompt size</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.109.1">The generic model won’t be able to return the robustness of the fine-tuned model. </span><span class="kobospan" id="kobo.109.2">Yet, the generic mode, with the collection of examples in the prompt, is still five </span><a id="_idIndexMarker557" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.110.1">times more expensive in this trivial example ($2.50 compared to 42 cents). </span><span class="kobospan" id="kobo.110.2">Prompting is faster and great for getting started, but fine-tuning will be how to customize the model in many cases. </span><span class="kobospan" id="kobo.110.3">Recall that a solution can include generic (cheap) models in conjunction with fine-tuned models. </span><span class="kobospan" id="kobo.110.4">This is reasonable. </span><span class="kobospan" id="kobo.110.5">The token cost for a prompt can be calculated using the </span><span><span class="kobospan" id="kobo.111.1">OpenAI tokenizer.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.112.1">Demo: </span><a href="https://platform.openai.com/tokenizer" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.113.1">Tokenizer</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.114.1">(</span></span></span><a href="https://platform.openai.com/tokenizer" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.115.1">https://platform.openai.com/tokenizer</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.116.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.117.1">Even though cost will be considered, many use cases require a fine-tuned model. </span><span class="kobospan" id="kobo.117.2">In this example, if the quality is there with GPT-4o mini with the small prompt and no training examples, then costs can be dramatically smaller. </span><span class="kobospan" id="kobo.117.3">The use case will dictate the extent to which examples are needed for training. </span><span class="kobospan" id="kobo.117.4">Let’s get started by learning how to build a fine-tuned model. </span><span class="kobospan" id="kobo.117.5">The Playground supports this </span><span><span class="kobospan" id="kobo.118.1">without coding.</span></span></p>
			<h1 id="_idParaDest-172" class="calibre5"><a id="_idTextAnchor177" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.119.1">Creating fine-tuned models</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.120.1">Every model will have different needs. </span><span class="kobospan" id="kobo.120.2">With GPT-3.5 Turbo, a start might be 50 to 100 examples. </span><span class="kobospan" id="kobo.120.3">After reaching the end of a good return on investment from prompt engineering, prompt chaining, and even function calling, we wind up here at fine-tuning. </span><span class="kobospan" id="kobo.120.4">Because so many enterprise use</span><a id="_idIndexMarker558" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.121.1"> cases will have at least some requirement for fine-tuned models, the best you can do is optimize for small context windows in exchange for more fine-tuning examples. </span><span class="kobospan" id="kobo.121.2">The fine-tuned model costs the same, with 50 examples or 5000. </span><span class="kobospan" id="kobo.121.3">So, if you take a 3000 token prompt, move all the examples into the model, and leave a prompt of 300 tokens (a few paragraphs), that is a significant saving for each interaction. </span><span class="kobospan" id="kobo.121.4">To put this in perspective, this paragraph has 173 tokens (</span><span><span class="kobospan" id="kobo.122.1">766 characters).</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.123.1">If fine-tuning doesn’t improve the model, the data science folks will likely have to figure out a different way of restructuring the model (OpenAI doesn’t give an example, but if all of these methods fail, ask ChatGPT for </span><span><span class="kobospan" id="kobo.124.1">fine-tuning tips).</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.125.1">Article:</span><a href="https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.126.1"> When to use </span><span><span class="kobospan" id="kobo.127.1">fine-tuning</span></span></a><span><span class="kobospan" id="kobo.128.1"> (</span></span><a href="https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.129.1">https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning</span></span></a><span><span class="kobospan" id="kobo.130.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.131.1">Anyone can assist in fine-tuning. </span><span class="kobospan" id="kobo.131.2">It takes more effort than prompt engineering, but the formats are accessible, and effort needs to be put into the content. </span><span class="kobospan" id="kobo.131.3">As designers, writers, linguists, and product people, put on the customer content hat and </span><span><span class="kobospan" id="kobo.132.1">get going.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.133.1">Each model might have different formats. </span><span class="kobospan" id="kobo.133.2">Here is the format for </span><span><span class="kobospan" id="kobo.134.1">GPT-3.5 Turbo:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.135.1">
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is very business-like."}, {"role": "user", "content": "What is the maximum withdrawal amount from my IRA?"}, {"role": "assistant", "content": "That is a complex question. </span><span class="kobospan1" id="kobo.135.2">I need a little more information to give you an accurate answer."}]}
{"messages": [{"role": "system", "content": "Marv is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What's the capital of France?"}, {"role": "assistant", "content": "Paris, as if everyone doesn't know that already."}]}</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.136.1">These are easy to model in a spreadsheet and can be reviewed by others and edited quickly. </span><span class="kobospan" id="kobo.136.2">OpenAI also provides an example of multi-turn training data. </span><span class="kobospan" id="kobo.136.3">Notice the weight key in their example. </span><span class="kobospan" id="kobo.136.4">A weight of </span><strong class="source-inline"><span class="kobospan" id="kobo.137.1">0</span></strong><span class="kobospan" id="kobo.138.1"> means the model will ignore that </span><span><span class="kobospan" id="kobo.139.1">specific message:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.140.1">
{"messages": [{"role": "system", "content": "Marv is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What's the capital of France?"}, {"role": "assistant", "content": "Paris", "weight": 0}, {"role": "user", "content": "Can you be more sarcastic?"}, {"role": "assistant", "content": "Paris, as if everyone doesn't know that already.", "weight": 1}]}</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.141.1">We will use the Playground for examples, but the development team will build a pipeline to manage the testing and training data in real life. </span><span class="kobospan" id="kobo.141.2">Split example data between training</span><a id="_idIndexMarker559" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.142.1"> and testing examples. </span><span class="kobospan" id="kobo.142.2">Don’t include testing examples in the training set, or test results will be wrong. </span><span class="kobospan" id="kobo.142.3">Hold out about 20% of the data for testing. </span><span class="kobospan" id="kobo.142.4">You need to know whether the model is improving, and this data can be used to provide </span><span><span class="kobospan" id="kobo.143.1">a benchmark.</span></span></p>
			<h2 id="_idParaDest-173" class="calibre9"><a id="_idTextAnchor178" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.144.1">Fine-tuning for style and tone</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.145.1">Take prompt engineering</span><a id="_idIndexMarker560" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.146.1"> as far as possible to train the system, but style and tone, format, and other qualitative features can be expressed with examples. </span><span class="kobospan" id="kobo.146.2">In </span><a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.147.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.148.1">, </span><em class="italic"><span class="kobospan" id="kobo.149.1">Recognizing the Power of Design in ChatGPT</span></em><span class="kobospan" id="kobo.150.1">, there is an example of a surf shop being compared to a bank. </span><span class="kobospan" id="kobo.150.2">Instructions on talking like a surfer or performing tasks as a trusted business advisor for a prestigious international financial company will help. </span><span class="kobospan" id="kobo.150.3">However, examples of how interactions sound and feel for a surf shop and a bank can help tweak that style, tone, and sophistication for the </span><span><span class="kobospan" id="kobo.151.1">LLM persona.</span></span></p>
			<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.152.1">Round 1</span></em><span class="kobospan" id="kobo.153.1"> is the first experiment for fine-tuning a model with ten training examples. </span><span class="kobospan" id="kobo.153.2">There is nothing special about this example. </span><span class="kobospan" id="kobo.153.3">We need to showcase how fine-tuning works and how to read the results from the output. </span><span class="kobospan" id="kobo.153.4">As this hands-on activity progresses, keep your use cases in mind. </span><span class="kobospan" id="kobo.153.5">For actual work, start with prompt engineering and learn what doesn’t work there. </span><span class="kobospan" id="kobo.153.6">Then, think about how to apply fine-tuning. </span><span class="kobospan" id="kobo.153.7">Let’s get started with </span><span><span class="kobospan" id="kobo.154.1">the example:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.155.1">Head to the playground and go to the fine-tuning </span><span><span class="kobospan" id="kobo.156.1">tab:</span></span><span><span> </span></span><a href="https://platform.openai.com/finetune" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.157.1">https://platform.openai.com/finetune</span></span></a><span><span class="kobospan" id="kobo.158.1">.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.159.1">Click the </span><strong class="bold"><span class="kobospan" id="kobo.160.1">+ Create</span></strong><span class="kobospan" id="kobo.161.1"> button to add a new </span><span><span class="kobospan" id="kobo.162.1">data set.</span></span><p class="calibre3"><span class="kobospan" id="kobo.163.1">This is the first file used that includes the </span><span><span class="kobospan" id="kobo.164.1">training data:</span></span></p><p class="calibre3"><span class="kobospan" id="kobo.165.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.166.1">Training Data with ten </span><span><span class="kobospan" id="kobo.167.1">examples</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.168.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.169.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.170.1">)</span></span></span></p><p class="calibre3"><span class="kobospan" id="kobo.171.1">The example follows previous instructions for Alli, the </span><span><span class="kobospan" id="kobo.172.1">sarcastic chatbot:</span></span></p><pre class="source-code"><span class="kobospan1" id="kobo.173.1">
Alli is a factual chatbot that is also sarcastic
How far is the Moon from Earth</span></pre><p class="calibre3"><span class="kobospan" id="kobo.174.1">Far. </span><span class="kobospan" id="kobo.174.2">Like a quarter million</span></p><p class="calibre3"><span class="kobospan" id="kobo.175.1">miles. </span><span class="kobospan" id="kobo.175.2">Or about how far you</span></p><p class="calibre3"><span class="kobospan" id="kobo.176.1">might drive in a lifetime.</span></p></li>				<li class="calibre8"><span class="kobospan" id="kobo.177.1">Create the model within the </span><strong class="bold"><span class="kobospan" id="kobo.178.1">Create a fine-tuned model</span></strong><span class="kobospan" id="kobo.179.1"> dialog box. </span><span><em class="italic"><span class="kobospan" id="kobo.180.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.181.1">.2</span></em><span class="kobospan" id="kobo.182.1"> shows selecting the </span><strong class="bold"><span class="kobospan" id="kobo.183.1">Base Model</span></strong><span class="kobospan" id="kobo.184.1"> (feel free to use the</span><a id="_idIndexMarker561" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.185.1"> latest models; the cost won’t be an issue for this experiment), selecting the training data file, and the form is ready to submit. </span><span class="kobospan" id="kobo.185.2">Notice that, at this point, the optional parameters are left alone. </span><span class="kobospan" id="kobo.185.3">We will explain them in the upcoming </span><em class="italic"><span class="kobospan" id="kobo.186.1">Fine-tuning tips</span></em><span class="kobospan" id="kobo.187.1"> section. </span><span class="kobospan" id="kobo.187.2">For now, don't include any validation data to test </span><span><span class="kobospan" id="kobo.188.1">the</span></span><span><span class="kobospan" id="kobo.189.1"> model.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer106" class="img---figure">
					<span class="kobospan" id="kobo.190.1"><img src="image/B21964_08_02.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.191.1">Figure 8.2 – Setting up a fine-tuning job in OpenAI</span></p>
			<ol class="calibre12">
				<li value="4" class="calibre8"><span class="kobospan" id="kobo.192.1">You will be returned to the fine-tuning page, and the job will take a few minutes to complete. </span><span class="kobospan" id="kobo.192.2">The</span><a id="_idIndexMarker562" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.193.1"> results should look similar to </span><span><em class="italic"><span class="kobospan" id="kobo.194.1">Figure 8</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.195.1">.3</span></em></span><span><span class="kobospan" id="kobo.196.1">.</span></span></li>
			</ol>
			<p class="calibre3"> </p>
			<div class="calibre2">
				<div id="_idContainer107" class="img---figure">
					<span class="kobospan" id="kobo.197.1"><img src="image/B21964_08_03.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.198.1">Figure 8.3 – Results from a fine-tuning job with ten examples (Round 1)</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.199.1">Notice the training chart. </span><span class="kobospan" id="kobo.199.2">We aim for it to tend to zero as it moves to the right. </span><span class="kobospan" id="kobo.199.3">The number of entries in the chart equals the number of training examples times the number of epochs or a single pass through</span><a id="_idIndexMarker563" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.200.1"> the training data. </span><span class="kobospan" id="kobo.200.2">The </span><strong class="bold"><span class="kobospan" id="kobo.201.1">epochs</span></strong><span class="kobospan" id="kobo.202.1">, or a single pass through the training data, is </span><strong class="source-inline"><span class="kobospan" id="kobo.203.1">10</span></strong><span class="kobospan" id="kobo.204.1">. </span><span class="kobospan" id="kobo.204.2">We will consider this number of iterations very</span><a id="_idIndexMarker564" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.205.1"> high and a function of having so few training examples. </span><span class="kobospan" id="kobo.205.2">We will explain this in more detail as this testing </span><span><span class="kobospan" id="kobo.206.1">process continues.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.207.1">Failure is an option</span></p>
			<p class="callout"><span class="kobospan" id="kobo.208.1">Although the file shared work, the first time I did a fine-tuning job, it took me five tries to debug the typos. </span><span class="kobospan" id="kobo.208.2">If the job fails, it will provide feedback. </span><span class="kobospan" id="kobo.208.3">Fix it and try again. </span><span class="kobospan" id="kobo.208.4">We will discuss third-party tools later in the chapter that help us avoid file formatting issues. </span><span class="kobospan" id="kobo.208.5">To be fair to this process, the results are as shown. </span><span class="kobospan" id="kobo.208.6">I have not gone back and made the results better or tweaked anything. </span><span class="kobospan" id="kobo.208.7">The intent is to appreciate </span><span><span class="kobospan" id="kobo.209.1">the process.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.210.1">Now that the basics are working, it is time to explain what happened. </span><span class="kobospan" id="kobo.210.2">A base model with billions of parameters was selected and fine-tuned to understand how to respond in the manner defined in the file. </span><span class="kobospan" id="kobo.210.3">You can test this model at any time on the </span><strong class="bold"><span class="kobospan" id="kobo.211.1">Playground</span></strong><span class="kobospan" id="kobo.212.1"> | </span><strong class="bold"><span class="kobospan" id="kobo.213.1">Chat</span></strong><span class="kobospan" id="kobo.214.1"> window by selecting it by the name assigned in the output model field. </span><span class="kobospan" id="kobo.214.2">You can even copy the name to make it easier to find in the </span><strong class="bold"><span class="kobospan" id="kobo.215.1">Chat</span></strong><span class="kobospan" id="kobo.216.1"> drop menu, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.217.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.218.1">.4</span></em><span class="kobospan" id="kobo.219.1">. </span><span class="kobospan" id="kobo.219.2">You will need to enter the system instructions; </span><em class="italic"><span class="kobospan" id="kobo.220.1">Alli is a factual chatbot that is also sarcastic</span></em><span class="kobospan" id="kobo.221.1">. </span><span class="kobospan" id="kobo.221.2">This is ignored by the model, even though it is in the </span><span><span class="kobospan" id="kobo.222.1">training file.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer108" class="img---figure">
					<span class="kobospan" id="kobo.223.1"><img src="image/B21964_08_04.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.224.1">Figure 8.4 – Copy and paste the fine-tuned model name into the Chat window</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.225.1">Now, re-run the same set of tests, but this time, include this file for the validation data with the same training </span><a id="_idIndexMarker565" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.226.1">data as in </span><span><em class="italic"><span class="kobospan" id="kobo.227.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.228.1">.5</span></em><span class="kobospan" id="kobo.229.1">. </span><em class="italic"><span class="kobospan" id="kobo.230.1">Round 2</span></em><span class="kobospan" id="kobo.231.1"> will take a few </span><span><span class="kobospan" id="kobo.232.1">more minutes.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.233.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.234.1">20 validation </span><span><span class="kobospan" id="kobo.235.1">examples</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.236.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.237.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.238.1">)</span></span></span></p>
			<div class="calibre2">
				<div id="_idContainer109" class="img---figure">
					<span class="kobospan" id="kobo.239.1"><img src="image/B21964_08_05.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.240.1">Figure 8.5 – Creating a model with training data</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.241.1">The validation file is a collection that is </span><em class="italic"><span class="kobospan" id="kobo.242.1">not</span></em><span class="kobospan" id="kobo.243.1"> used for training but by the model to compare its results to what is expected. </span><span class="kobospan" id="kobo.243.2">The validation data is very human-like, oddly similar to the training date, and not very logical, or clearly defined, such as classifying service requests by priority or determining sentiment. </span><span class="kobospan" id="kobo.243.3">This means getting the charts to tend to zero will </span><span><span class="kobospan" id="kobo.244.1">be hard.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.245.1">We can view the results and see what to do as the next steps in </span><span><em class="italic"><span class="kobospan" id="kobo.246.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.247.1">.6</span></em><span class="kobospan" id="kobo.248.1">. </span><span class="kobospan" id="kobo.248.2">We will take time to explain what is happening, but there are still a few </span><span><span class="kobospan" id="kobo.249.1">training rounds.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer110" class="img---figure">
					<span class="kobospan" id="kobo.250.1"><img src="image/B21964_08_06.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.251.1">Figure 8.6 – Results from a fine-tuning job with a validation set (Round 2)</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.252.1">Please open the file on GitHub and look at the examples; they are single-turn interactions. </span><span class="kobospan" id="kobo.252.2">The</span><a id="_idIndexMarker566" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.253.1"> user prompts, and the system responds. </span><span class="kobospan" id="kobo.253.2">Each row looks </span><span><span class="kobospan" id="kobo.254.1">like this:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.255.1">
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "Can I speak with a financial advisor?"}, {"role": "assistant", "content": "Sure, if you enjoy discussing your finances with a real human being instead of my charming digital self. </span><span class="kobospan1" id="kobo.255.2">Just give them a call."}]}</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.256.1">A multi-turn conversation (without the JSON formatting) would look like this example from </span><span><span class="kobospan" id="kobo.257.1">ChatGPT 4o:</span></span></p>
			<pre class="source-code-right"><span class="kobospan1" id="kobo.258.1">How do I open a new account?
</span><span class="kobospan1" id="kobo.258.2">You can open a new account by
filling out an application form and
providing the required documentation.
</span><span class="kobospan1" id="kobo.258.3">This process can be completed online
or at a branch office.Can I do this online?
</span><span class="kobospan1" id="kobo.258.4">Yes, you can complete the application
process online. </span><span class="kobospan1" id="kobo.258.5">Please visit our
website and follow the instructions
for opening a new account.How long does it take to openan account and start trading?
</span><span class="kobospan1" id="kobo.258.6">The account opening process typically
takes a few days if all provided
information and documentation
are correct. </span><span class="kobospan1" id="kobo.258.7">Once your account is
approved, you can begin trading immediately.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.259.1">The model can be trained using the same basic format with multi-turn conversational interactions. </span><span class="kobospan" id="kobo.259.2">In this</span><a id="_idIndexMarker567" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.260.1"> OpenAI example, we highlighted the user and assistant responses that create a multi-turn interaction. </span><span class="kobospan" id="kobo.260.2">Here is what it would look like when included in a </span><span><span class="kobospan" id="kobo.261.1">training file:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.262.1">
{"messages": [{"role": "system", "content": "You are a happy assistant that puts a positive spin on everything."}, {"role": "</span><strong class="bold1"><span class="kobospan1" id="kobo.263.1">user</span></strong><span class="kobospan1" id="kobo.264.1">", "content": "How do I open a new account?"}, {"role": "</span><strong class="bold1"><span class="kobospan1" id="kobo.265.1">assistant</span></strong><span class="kobospan1" id="kobo.266.1">", "content": " You can open a new account by filling out an application form and providing the required documentation. </span><span class="kobospan1" id="kobo.266.2">This process can be completed online or at a branch office."},{"role": "</span><strong class="bold1"><span class="kobospan1" id="kobo.267.1">user</span></strong><span class="kobospan1" id="kobo.268.1">", "content": "Can I do this online?"}, {"role": "</span><strong class="bold1"><span class="kobospan1" id="kobo.269.1">assistant</span></strong><span class="kobospan1" id="kobo.270.1">", "content": "Yes, you can complete the application process online. </span><span class="kobospan1" id="kobo.270.2">Please visit our website and follow the instructions for opening a new account."}, {"role": "</span><strong class="bold1"><span class="kobospan1" id="kobo.271.1">user</span></strong><span class="kobospan1" id="kobo.272.1">", "content": " How long does it take to open an account and start trading?"}, {"role": "</span><strong class="bold1"><span class="kobospan1" id="kobo.273.1">assistant</span></strong><span class="kobospan1" id="kobo.274.1">", "content": "The account opening process typically takes a few days if all provided information and documentation are correct. </span><span class="kobospan1" id="kobo.274.2">Once your account is approved, you can begin trading immediately."}]}</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.275.1">This example set is not complex. </span><span class="kobospan" id="kobo.275.2">Suppose the use case calls for multi-turn or extended examples to showcase how the model should react. </span><span class="kobospan" id="kobo.275.3">Each entry should reflect a coherent dialogue that teaches the model to handle context over </span><span><span class="kobospan" id="kobo.276.1">several interactions.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.277.1">That is the input. </span><span class="kobospan" id="kobo.277.2">Let’s review </span><span><span class="kobospan" id="kobo.278.1">the output.</span></span></p>
			<h2 id="_idParaDest-174" class="calibre9"><a id="_idTextAnchor179" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.279.1">Using the fine-tuned model</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.280.1">Once the fine-tuned model is ready, test it. </span><span class="kobospan" id="kobo.280.2">You can see a </span><strong class="bold"><span class="kobospan" id="kobo.281.1">Playground</span></strong><span class="kobospan" id="kobo.282.1"> button on the bottom right of the fine-tuning </span><a id="_idIndexMarker568" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.283.1">job. </span><span class="kobospan" id="kobo.283.2">You can also go to </span><strong class="bold"><span class="kobospan" id="kobo.284.1">Chat</span></strong><span class="kobospan" id="kobo.285.1"> in the left tab and then select the name of the </span><span><span class="kobospan" id="kobo.286.1">fine-tuning job.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.287.1">Optionally, there is a </span><strong class="bold"><span class="kobospan" id="kobo.288.1">Compare</span></strong><span class="kobospan" id="kobo.289.1"> button to manually test the model and compare it to previous model versions (or other models entirely). </span><span class="kobospan" id="kobo.289.2">Be sure to copy the exact instructions in the </span><strong class="bold"><span class="kobospan" id="kobo.290.1">SYSTEM</span></strong><span class="kobospan" id="kobo.291.1"> field. </span><span class="kobospan" id="kobo.291.2">We just clicked the </span><strong class="bold"><span class="kobospan" id="kobo.292.1">Playground</span></strong><span class="kobospan" id="kobo.293.1"> button to open the chat, selecting the fine-tuned model, as in </span><span><em class="italic"><span class="kobospan" id="kobo.294.1">Figure 8</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.295.1">.7</span></em></span><span><span class="kobospan" id="kobo.296.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer111" class="img---figure">
					<span class="kobospan" id="kobo.297.1"><img src="image/B21964_08_07.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.298.1">Figure 8.7 – Selecting the fine-tuned job to interact with the new model</span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.299.1">Gotcha</span></p>
			<p class="callout"><span class="kobospan" id="kobo.300.1">We can’t do both the file retrieval demo (to incorporate the 100s of FAQs from the Alli demo) </span><em class="italic"><span class="kobospan" id="kobo.301.1">and</span></em><span class="kobospan" id="kobo.302.1"> fine-tune the model in the Playground. </span><span class="kobospan" id="kobo.302.2">This is a current limitation. </span><span class="kobospan" id="kobo.302.3">We will use this time to focus on fine-tuning improvements, knowing a production system can address </span><span><span class="kobospan" id="kobo.303.1">this shortcoming.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.304.1">Because of this limitation, this focus is on learning about fine-tuning rather than fine-tuning the RAG model. </span><span class="kobospan" id="kobo.304.2">Comparing outputs, the foundation model is wordy, and neither has specific results from our FAQs; the model must be trained with FAQS. </span><span class="kobospan" id="kobo.304.3">Compare the results in </span><em class="italic"><span class="kobospan" id="kobo.305.1">Table 8.2</span></em><span class="kobospan" id="kobo.306.1"> with the </span><span><span class="kobospan" id="kobo.307.1">trained FAQs.</span></span></p>
			<table id="table002-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.308.1">Model</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.309.1">Response</span></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.310.1">1) GPT-3.5 Turbo trained with </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.311.1">the FAQs</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.312.1">To lower your advisory fee, you can consider the </span><span><span class="kobospan" id="kobo.313.1">following options:</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.314.1">* Consolidating assets: The more you invest with us, the lower your advisory fee </span><span><span class="kobospan" id="kobo.315.1">could be.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.316.1">* Grouping accounts together: You can also lower the advisory fee percentage for your immediate family members by grouping accounts </span><span><span class="kobospan" id="kobo.317.1">together [1].</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.318.1">2) GPT-3.5-turbo-1105+ </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.319.1">fine-tuned</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.320.1">You should contact customer service for that. </span><span class="kobospan" id="kobo.320.2">They can escalate to the appropriate department </span><span><span class="kobospan" id="kobo.321.1">if necessary.</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.322.1">3) GPT-4o No fine-tuning and no FAQs </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.323.1">as resources</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.324.1">Optimizing advisory fees can lead to significant savings over time. </span><span class="kobospan" id="kobo.324.2">Here are several strategies </span><span><span class="kobospan" id="kobo.325.1">to consider:</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.326.1">1. </span><span class="kobospan" id="kobo.326.2">**Compare Advisors**: Research and compare fees among different advisors. </span><span class="kobospan" id="kobo.326.3">Look for advisors with transparent </span><span><span class="kobospan" id="kobo.327.1">fee structures.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.328.1">2. </span><span class="kobospan" id="kobo.328.2">**Consider Fee-only Advisors**: Fee-only advisors charge a flat rate or </span><a id="_idIndexMarker569" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.329.1">an hourly fee rather than a percentage of your assets. </span><span class="kobospan" id="kobo.329.2">This can sometimes be </span><span><span class="kobospan" id="kobo.330.1">more cost-effective.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.331.1">3. </span><span class="kobospan" id="kobo.331.2">**Negotiate Fees**: Don’t be afraid to negotiate. </span><span class="kobospan" id="kobo.331.3">Advisors might be willing to reduce their fees to retain you as </span><span><span class="kobospan" id="kobo.332.1">a client.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.333.1">4. </span><span class="kobospan" id="kobo.333.2">**Bundled Services**: Some advisors offer packaged services that might come at a lower total cost than à la </span><span><span class="kobospan" id="kobo.334.1">carte services.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.335.1">5. </span><span class="kobospan" id="kobo.335.2">**Review Fee Structure**, 6. </span><span class="kobospan" id="kobo.335.3">**Use Robo-Advisors**, 7. </span><span class="kobospan" id="kobo.335.4">**DIY Approach**, 8. </span><span class="kobospan" id="kobo.335.5">**Regular Fee. </span><span class="kobospan" id="kobo.335.6">(5 to 8 are truncated </span><span><span class="kobospan" id="kobo.336.1">for brevity)</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.337.1">4) GTP-3.5 1106 with fine-tuning </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.338.1">78 examples</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.339.1">Negotiate</span><a id="_idIndexMarker570" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.340.1"> a lower fee or invest more money with me; I’m sure I can find a way to help you </span><span><span class="kobospan" id="kobo.341.1">with that.</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.342.1">5) Best match from 78 </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.343.1">fine-tuning examples</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.344.1">No question existed close to this question. </span><span class="kobospan" id="kobo.344.2">Only one question even discussed advisory, and it was an unrelated question, “Can I pay Portfolio Advisory Service or other Alligiance-managed account fees using mobile </span><span><span class="kobospan" id="kobo.345.1">check deposit?”</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.346.1">6) </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.347.1">Source Answer</span></strong></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.348.1">FAQ 86. </span><span class="kobospan" id="kobo.348.2">How can Iower my </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.349.1">advisory fee?</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.350.1">consider the benefits of consolidating assets. </span><span class="kobospan" id="kobo.350.2">the more you invest with us, the lower your advisory fee could be. </span><span class="kobospan" id="kobo.350.3">you can also lower the advisory fee percentage for your immediate family members (whether or not they live with you) by grouping accounts together. </span><span class="kobospan" id="kobo.350.4">for additional details, please ask a Alligiance representative for details or view the fee aggregation policy </span><span><span class="kobospan" id="kobo.351.1">and form.</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.352.1">Table 8.2 – Output for “How can I lower my advisory fee?” </span><span class="kobospan" id="kobo.352.2">with different models</span></p>
			<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.353.1">We must have the FAQs to offer specific business data</span></em><span class="kobospan" id="kobo.354.1">. </span><span class="kobospan" id="kobo.354.2">Fine-tuning will only help present results in a particular way. </span><span class="kobospan" id="kobo.354.3">Only the model (1) with the FAQs could match the source material. </span><span class="kobospan" id="kobo.354.4">RAG (or, in this case, the proxy for RAG – File Search) can handle the factual data. </span><span class="kobospan" id="kobo.354.5">The other models can hallucinate (2) or be long-winded (3). </span><span class="kobospan" id="kobo.354.6">The fine-tuned model (4) was slightly sarcastic but couldn’t return a valid answer without the knowledge. </span><span class="kobospan" id="kobo.354.7">It isn’t trained on the answer, as the closest example wasn’t close (5), and it can’t invent the facts from the source FAQ (6). </span><span class="kobospan" id="kobo.354.8">The size of the result should be noted. </span><span class="kobospan" id="kobo.354.9">Because training was with short responses, the model (5) returned </span><span><span class="kobospan" id="kobo.355.1">short responses.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.356.1">Since ChatGPT-3.5 wants at least 10, if not 100, examples, </span><em class="italic"><span class="kobospan" id="kobo.357.1">Round 3</span></em><span class="kobospan" id="kobo.358.1"> will re-run the build with double the examples. </span><span class="kobospan" id="kobo.358.2">Doubling examples is a typical strategy to increase quality by the same amount </span><a id="_idIndexMarker571" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.359.1">as the last doubling. </span><span class="kobospan" id="kobo.359.2">Ten was too small in this case, so now it is 20. </span><span class="kobospan" id="kobo.359.3">In hindsight, this experiment should have started at 50. </span><span class="kobospan" id="kobo.359.4">We used the exact simple system instructions. </span><span class="kobospan" id="kobo.359.5">You need to copy and paste the instructions again when testing; they are ignored in the playground when uploading examples. </span><span class="kobospan" id="kobo.359.6">Include this training set and reuse the same </span><span><span class="kobospan" id="kobo.360.1">validation data:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.361.1">
Alli is a factual chatbot that is also sarcastic.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.362.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.363.1">Training Data with 30 </span><span><span class="kobospan" id="kobo.364.1">examples</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.365.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.366.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.367.1">)</span></span></span></p>
			<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.368.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.369.1">.8</span></em><span class="kobospan" id="kobo.370.1"> shows the results of </span><em class="italic"><span class="kobospan" id="kobo.371.1">Round 3</span></em><span class="kobospan" id="kobo.372.1">. </span><span class="kobospan" id="kobo.372.2">We can now start to examine the metrics </span><span><span class="kobospan" id="kobo.373.1">more closely.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer112" class="img---figure">
					<span class="kobospan" id="kobo.374.1"><img src="image/B21964_08_08.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.375.1">Figure 8.8 – Improving the model with double the training examples (Round 3)</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.376.1">We can explain a few more concepts with the validation data and then do one more round of training. </span><span class="kobospan" id="kobo.376.2">Let’s review what the </span><span><span class="kobospan" id="kobo.377.1">chart means:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.378.1">The red dot represents the end of an epoch, which is one round of training. </span><span class="kobospan" id="kobo.378.2">Because the last example had 29 examples, one epoch was 29 tests long. </span><span class="kobospan" id="kobo.378.3">Because it decided it needed three runs, it did 87 tests. </span><span class="kobospan" id="kobo.378.4">The red dot represents the average validation loss across that group. </span><span class="kobospan" id="kobo.378.5">We are progressing since the validation loss is decreasing, and the training loss is tending </span><span><span class="kobospan" id="kobo.379.1">to zero.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.380.1">We still see many ups and downs along the way. </span><span class="kobospan" id="kobo.380.2">This model compares the expected outcome to its generated outcome. </span><span class="kobospan" id="kobo.380.3">Once it improves with suitable matches, the graph tends to zero. </span><span class="kobospan" id="kobo.380.4">When there is a big difference, the graph shows jumps. </span><span class="kobospan" id="kobo.380.5">The large validation loss still needs to be solved. </span><span class="kobospan" id="kobo.380.6">It still needs to converge </span><span><span class="kobospan" id="kobo.381.1">towards zero.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.382.1">This model is looking a little volatile compared to Round 1. </span><span class="kobospan" id="kobo.382.2">I suspect the training data is too similar to the validation data, which is causing this issue. </span><span class="kobospan" id="kobo.382.3">This would have to be reviewed and tested. </span><span class="kobospan" id="kobo.382.4">A real solution might take dozens to hundreds of rounds </span><span><span class="kobospan" id="kobo.383.1">of iteration.</span></span><p class="calibre3"><span class="kobospan" id="kobo.384.1">Don't generalize from the following Boolean classifier visualization. </span><span class="kobospan" id="kobo.384.2">Graphs</span><a id="_idIndexMarker572" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.385.1"> from simple Boolean classifiers (whether data is true or false, positive or negative sentiment, etc.) might not be helpful. </span><span class="kobospan" id="kobo.385.2">If items are easy to classify, the graph will be like </span><span><em class="italic"><span class="kobospan" id="kobo.386.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.387.1">.9</span></em><span class="kobospan" id="kobo.388.1">. </span><span class="kobospan" id="kobo.388.2">Michael Cacic at </span><a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.389.1">https://miha.academy/</span></a><span class="kobospan" id="kobo.390.1"> provided this example. </span><span class="kobospan" id="kobo.390.2">Only a little can be learned from this chart. </span><span class="kobospan" id="kobo.390.3">This model is </span><span><span class="kobospan" id="kobo.391.1">working well.</span></span></p></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer113" class="img---figure">
					<span class="kobospan" id="kobo.392.1"><img src="image/B21964_08_09.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.393.1">Figure 8.9 – A fine-tuning graph for a classifier task that is doing well</span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.394.1">For complex data, like the Round 3 results, it is hopeful that the trend will be toward zero and that validation loss will decrease. </span><span class="kobospan" id="kobo.394.2">Since there was a lack of convergence in the early run, add </span><a id="_idIndexMarker573" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.395.1">more varied examples to continue trending down. </span><span class="kobospan" id="kobo.395.2">Improving the diversity of the validation examples (not done in this demo) would </span><span><span class="kobospan" id="kobo.396.1">likely help.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.397.1">Refrain from relying only on the graph for complex data. </span><span class="kobospan" id="kobo.397.2">Review results and score them for quality. </span><span class="kobospan" id="kobo.397.3">We discussed this in </span><a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.398.1">Chapter 4</span></em></span></a><span class="kobospan" id="kobo.399.1">, </span><em class="italic"><span class="kobospan" id="kobo.400.1">Scoring Stories</span></em><span class="kobospan" id="kobo.401.1">, and continue discussing measuring and monitoring in </span><a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.402.1">Chapter 10</span></em></span></a><span class="kobospan" id="kobo.403.1">, </span><em class="italic"><span class="kobospan" id="kobo.404.1">Monitoring </span></em><span><em class="italic"><span class="kobospan" id="kobo.405.1">and Evaluation</span></em></span><span><span class="kobospan" id="kobo.406.1">.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.407.1">Remember, the goal is to improve the model’s reasoning, not to teach it knowledge. </span><span class="kobospan" id="kobo.407.2">Use RAG for memory and scope. </span><span class="kobospan" id="kobo.407.3">Use fine-tuning to hone how the model thinks </span><span><span class="kobospan" id="kobo.408.1">and responds.</span></span></li>
			</ul>
			<p class="callout-heading"><span class="kobospan" id="kobo.409.1">Be careful about non-enterprise data intrusions</span></p>
			<p class="callout"><span class="kobospan" id="kobo.410.1">In instructions and</span><a id="_idIndexMarker574" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.411.1"> prompting, specify to use the data provided in RAG. </span><span class="kobospan" id="kobo.411.2">This protects from pulling facts from the model that might confuse customers. </span><span class="kobospan" id="kobo.411.3">Although “Alli” is the short name for the fictional financial services model example, hallucinations occurred when the instructions, “Only provide answers from the attached document,” were removed from the file attached model. </span><span class="kobospan" id="kobo.411.4">During some additional research for the book, this model assumed Alli was </span><em class="italic"><span class="kobospan" id="kobo.412.1">Ally</span></em><span class="kobospan" id="kobo.413.1">, a bank in Pennsylvania. </span><span class="kobospan" id="kobo.413.2">This error will only be found in the field by monitoring logs. </span><span class="kobospan" id="kobo.413.3">Customers will complain about these errors, but it would be tragic to find this out </span><em class="italic"><span class="kobospan" id="kobo.414.1">after</span></em><span class="kobospan" id="kobo.415.1"> your customer mailed a large check to the wrong address because the foundational model used some random address. </span><span class="kobospan" id="kobo.415.2">Every model vendor is working on this problem. </span><span class="kobospan" id="kobo.415.3">It will get better but still watch </span><span><span class="kobospan" id="kobo.416.1">for it.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.417.1">Fine-tuning is well-suited for getting the style and tone right. </span><span class="kobospan" id="kobo.417.2">Yes, good results can come from instructions, but fine-tuning is just that: it is fine; it is more granular and specific. </span><em class="italic"><span class="kobospan" id="kobo.418.1">General</span></em><span class="kobospan" id="kobo.419.1"> goals are in the prompts, while examples that could have been in the prompt can be moved to fine-tuning. </span><span class="kobospan" id="kobo.419.2">These </span><em class="italic"><span class="kobospan" id="kobo.420.1">specific</span></em><span class="kobospan" id="kobo.421.1"> examples extend how the model should always respond. </span><span class="kobospan" id="kobo.421.2">This is why the sarcastic example is so good. </span><span class="kobospan" id="kobo.421.3">It was only trained on a few dozen examples, but it can </span><a id="_idIndexMarker575" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.422.1">now use those examples to drive its personality. </span><span class="kobospan" id="kobo.422.2">Another use of fine-tuning is for manipulating data and </span><span><span class="kobospan" id="kobo.423.1">transforming information.</span></span></p>
			<h2 id="_idParaDest-175" class="calibre9"><a id="_idTextAnchor180" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.424.1">Fine-tuning for structuring output</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.425.1">In cases where tables, lists, or other</span><a id="_idIndexMarker576" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.426.1"> formatting is essential to the results, feed the fine-tuning system with examples to give it an edge in providing structured output. </span><span class="kobospan" id="kobo.426.2">This is perfect for those who deal with table data, like in the Wove use case. </span><span class="kobospan" id="kobo.426.3">It is helpful for any structured data, even with the expense examples. </span><span class="kobospan" id="kobo.426.4">It is also beneficial to train on the name: value pattern (e.g., Amount: $12.34). </span><span class="kobospan" id="kobo.426.5">Fine-tuning can be used for integrations, where you move data from one system to another and specify the format for the input for the next step. </span><span class="kobospan" id="kobo.426.6">You might need XML, JSON, CSV, colon-delimited, or other formats to ensure your downstream system can accept </span><span><span class="kobospan" id="kobo.427.1">the input.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.428.1">Tip for generating examples for fine-tuning</span></p>
			<p class="callout"><span class="kobospan" id="kobo.429.1">ChatGPT can be used to generate examples to build a training model. </span><span class="kobospan" id="kobo.429.2">Not only can it do the examples, but it can generate the structured format needed for the file. </span><span class="kobospan" id="kobo.429.3">So, now ChatGPT is training itself. </span><span class="kobospan" id="kobo.429.4">The output can be reviewed </span><span><span class="kobospan" id="kobo.430.1">and tweaked.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.431.1">It also helps our tutorial to introduce another concept. </span><span class="kobospan" id="kobo.431.2">You can instruct an LLM to create more examples. </span><span class="kobospan" id="kobo.431.3">We call this </span><strong class="bold"><span class="kobospan" id="kobo.432.1">synthetic data</span></strong><span class="kobospan" id="kobo.433.1">. </span><span class="kobospan" id="kobo.433.2">This can be tried</span><a id="_idIndexMarker577" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.434.1"> in the Playground. </span><span class="kobospan" id="kobo.434.2">Notice the context, tone, and </span><span><span class="kobospan" id="kobo.435.1">data format:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.436.1">
I will provide you with three examples of structured data that represent the back-and-forth between a factual chatbot that is also sarcastic and the user. </span><span class="kobospan1" id="kobo.436.2">Please generate seven more examples in a similar tone, focused on financial services questions. </span><span class="kobospan1" id="kobo.436.3">{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "How far is the Moon from Earth?"}, {"role": "assistant", "content": "Far. </span><span class="kobospan1" id="kobo.436.4">Like a quarter million miles. </span><span class="kobospan1" id="kobo.436.5">Or about how far you might drive in a lifetime."}]}</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.437.1">More examples were provided; they are just truncated here. </span><span class="kobospan" id="kobo.437.2">The model returned the results, and the next prompt was given to the model to make it easier to copy and paste the results. </span><span class="kobospan" id="kobo.437.3">The </span><span><span class="kobospan" id="kobo.438.1">prompt was:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.439.1">
merge these messages into one file-one line at a time</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.440.1">It returned a single file, making copying much easier, with results </span><span><span class="kobospan" id="kobo.441.1">like this:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.442.1">
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "How do I open a new account?"}, {"role": "assistant", "content": "Just fill out an application, provide your life history, and sacrifice a small goat. </span><span class="kobospan1" id="kobo.442.2">Kidding. </span><span class="kobospan1" id="kobo.442.3">No goats. </span><span class="kobospan1" id="kobo.442.4">But it is a lot of paperwork."}]}
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What is the interest rate on savings accounts?"}, {"role": "assistant", "content": "Interest rates on savings accounts are currently so low that you'd probably get more return from finding coins under your couch cushions."}]}</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.443.1">Impressive. </span><span class="kobospan" id="kobo.443.2">ChatGPT can help generate structured output but can’t generate factual information about my</span><a id="_idIndexMarker578" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.444.1"> business. </span><span class="kobospan" id="kobo.444.2">It saves a lot of time. </span><span class="kobospan" id="kobo.444.3">We can use this method to scale up test cases. </span><span class="kobospan" id="kobo.444.4">We can manually review for quality, saving 90% or more of </span><span><span class="kobospan" id="kobo.445.1">our effort.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.446.1">This is a tiny example. </span><span class="kobospan" id="kobo.446.2">Transforming data to move between disparate systems has been an ongoing enterprise problem. </span><span class="kobospan" id="kobo.446.3">This back-end process has various uses, including presenting data in a UI in a format or with a helpful structure for customers to interpret. </span><span class="kobospan" id="kobo.446.4">The use cases in this space abound. </span><span class="kobospan" id="kobo.446.5">But it will only be apparent when this problem strikes you. </span><span class="kobospan" id="kobo.446.6">From my experience, it is not common. </span><span class="kobospan" id="kobo.446.7">It is just critical when it comes up. </span><span class="kobospan" id="kobo.446.8">Even though ChatGPT can generate data, it doesn’t </span><span><span class="kobospan" id="kobo.447.1">guarantee quality.</span></span></p>
			<h2 id="_idParaDest-176" class="calibre9"><a id="_idTextAnchor181" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.448.1">Generating data should still need a check and balance</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.449.1">You can use a variety of </span><a id="_idIndexMarker579" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.450.1">methods to generate data. </span><span class="kobospan" id="kobo.450.2">This synthetic data could be similar to what real humans might have done. </span><span class="kobospan" id="kobo.450.3">Or it might not. </span><span class="kobospan" id="kobo.450.4">This is a place where human-in-the-loop analysis can be valuable. </span><span class="kobospan" id="kobo.450.5">A model can generate examples very quickly. </span><span class="kobospan" id="kobo.450.6">It only took a few minutes with the LLM to create many examples. </span><span class="kobospan" id="kobo.450.7">Even with the time to review the results, it was much easier than writing them </span><span><span class="kobospan" id="kobo.451.1">by hand.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.452.1">You can do this with Google Sheets, Microsoft Excel, and third-party fine-tuning tools that support generation. </span><span class="kobospan" id="kobo.452.2">A wealth of integrations are available to help with this process. </span><span class="kobospan" id="kobo.452.3">Regardless of the tool, review results and decide whether to include the content in training or validation examples. </span><span class="kobospan" id="kobo.452.4">You might accept them outright, edit them to make them better or reject them. </span><span class="kobospan" id="kobo.452.5">Depending on the solution’s robustness, consider a workflow that scores results, as discussed in </span><a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.453.1">Chapter 4</span></em></span></a><span class="kobospan" id="kobo.454.1">, </span><em class="italic"><span class="kobospan" id="kobo.455.1">Scoring Stories</span></em><span class="kobospan" id="kobo.456.1">. </span><span class="kobospan" id="kobo.456.2">Scoring tools can help evaluate what to keep, reject, and tweak. </span><span class="kobospan" id="kobo.456.3">Then, plan a course of action to improve based on how you feel about the results. </span><span class="kobospan" id="kobo.456.4">We see some options in </span><span><em class="italic"><span class="kobospan" id="kobo.457.1">Table 8.3</span></em></span><span><span class="kobospan" id="kobo.458.1">.</span></span></p>
			<table id="table003-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.459.1">Fine </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.460.1">Tuning Status</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.461.1">Plan</span></strong></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.462.1">Happy </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.463.1">with results</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.464.1">Do nothing</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.465.1">Works well, but is expensive </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.466.1">or slow</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.467.1">Chain a fine-tuned lighter model (GPT-3.5) on all of the completions of a more expensive </span><span><span class="kobospan" id="kobo.468.1">model (GPT-4)</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.469.1">Results are </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.470.1">not consistent</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.471.1">Chain a fine-tuned lighter model (GPT-3.5) on all of the best completions of a more expensive </span><span><span class="kobospan" id="kobo.472.1">model (GPT-4)</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.473.1">Results are close to what I want but the style and tone </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.474.1">are off</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.475.1">Manually edit examples to the desired quality, or edit the prompt to </span><span><span class="kobospan" id="kobo.476.1">adjust results</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.477.1">I don’t have a model, or can’t create </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.478.1">one easily</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.479.1">Fine-tune a model with manually generated </span><span><span class="kobospan" id="kobo.480.1">high-quality examples</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.481.1">Table 8.3 – Courses of action when tuning is not going as planned</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.482.1">Even this part of fine-tuning can</span><a id="_idIndexMarker580" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.483.1"> undergo multiple care and feeding cycles. </span><span class="kobospan" id="kobo.483.2">You might loop back around and find an even lighter model or something needing more editing. </span><span class="kobospan" id="kobo.483.3">Iteration is fundamental to every step of the generative </span><span><span class="kobospan" id="kobo.484.1">AI journey.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.485.1">Spreadsheet user tips</span></p>
			<p class="callout"><span class="kobospan" id="kobo.486.1">The format for fine-tuning has changed over time. </span><span class="kobospan" id="kobo.486.2">Each model can use different formats. </span><span class="kobospan" id="kobo.486.3">Just adapt the data to the model format. </span><span class="kobospan" id="kobo.486.4">You can use a spreadsheet to maintain the source content and then use the tools in spreadsheets to build strings combining source content with the correct formatting, </span><span><span class="kobospan" id="kobo.487.1">for example:</span></span></p>
			<p class="callout"><strong class="source-inline1"><span class="kobospan" id="kobo.488.1">A1 cell = ' {"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "</span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.489.1">content": "'</span></strong></span></p>
			<p class="callout"><strong class="source-inline1"><span class="kobospan" id="kobo.490.1">B1 cell = </span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.491.1">question</span></strong></span></p>
			<p class="callout"><strong class="source-inline1"><span class="kobospan" id="kobo.492.1">C1 cell = '"}, {"role": "assistant", "</span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.493.1">content": "'</span></strong></span></p>
			<p class="callout"><strong class="source-inline1"><span class="kobospan" id="kobo.494.1">D1 contains the </span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.495.1">synthetic string</span></strong></span></p>
			<p class="callout"><strong class="source-inline1"><span class="kobospan" id="kobo.496.1">E1 cell = ' "}]}'</span></strong></p>
			<p class="callout"><strong class="source-inline1"><span class="kobospan" id="kobo.497.1">So F1 = A1 &amp; B1 &amp; C1 &amp; D1 &amp; E1 then </span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.498.1">export F1</span></strong></span></p>
			<p class="callout"><span class="kobospan" id="kobo.499.1">Excel and Google Sheets have ChatGPT (and other LLM) integrations to generate synthetic data. </span><span class="kobospan" id="kobo.499.2">Spreadsheet integration with ChatGPT has all kinds of uses. </span><span class="kobospan" id="kobo.499.3">It helps this process and can improve </span><span><span class="kobospan" id="kobo.500.1">personal productivity.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.501.1">One great trick is not rebuilding the </span><a id="_idIndexMarker581" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.502.1">model from scratch each time examples are added. </span><span class="kobospan" id="kobo.502.2">After reviewing the generated results and fixing some formatting errors, 49 more examples were incorporated from a separate file to add to the model. </span><span class="kobospan" id="kobo.502.3">In total, there are now 78 examples and 20 </span><span><span class="kobospan" id="kobo.503.1">test cases.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.504.1">Re-use the model from </span><em class="italic"><span class="kobospan" id="kobo.505.1">Round 3</span></em><span class="kobospan" id="kobo.506.1">. </span><span class="kobospan" id="kobo.506.2">The training will go faster. </span><span class="kobospan" id="kobo.506.3">As shown in </span><span><em class="italic"><span class="kobospan" id="kobo.507.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.508.1">.10,</span></em><span class="kobospan" id="kobo.509.1"> pick the previous fine-tuned </span><a id="_idIndexMarker582" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.510.1">model in the </span><strong class="source-inline"><span class="kobospan" id="kobo.511.1">Base Model</span></strong><span class="kobospan" id="kobo.512.1"> menu to create a revised fine-tuned model. </span><span class="kobospan" id="kobo.512.2">You are picking up where you left off. </span><span class="kobospan" id="kobo.512.3">Only upload the incrementally new rows in the data for </span><span><em class="italic"><span class="kobospan" id="kobo.513.1">Round 4</span></em></span><span><span class="kobospan" id="kobo.514.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer114" class="img---figure">
					<span class="kobospan" id="kobo.515.1"><img src="image/B21964_08_10.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.516.1">Figure 8.10 – Appending to an existing fine-tuned base model to continue fine-tuning</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.517.1">GitHub:</span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.518.1"> 49 training </span><span><span class="kobospan" id="kobo.519.1">examples</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.520.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.521.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.522.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.523.1">We can now view the training, which </span><a id="_idIndexMarker583" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.524.1">shows the results from Round 4 in </span><span><em class="italic"><span class="kobospan" id="kobo.525.1">Figure 8</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.526.1">.11</span></em></span><span><span class="kobospan" id="kobo.527.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer115" class="img---figure">
					<span class="kobospan" id="kobo.528.1"><img src="image/B21964_08_11.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.529.1">Figure 8.11 – The final fine-tuning run for ChatGPT-3.5 9 compared to ChatGPT-4o mini, including synthetic data (Round 4)</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.530.1">Chat GPT 3.5 (on the top </span><a id="_idIndexMarker584" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.531.1">of the image) was improved by adding more examples. </span><span class="kobospan" id="kobo.531.2">At least 50 to 100 examples were suggested; this is in the middle of that range. </span><span class="kobospan" id="kobo.531.3">Take the 78 examples, double the training set, extend the testing set to 20%, review and clean up overlapping concepts, and test again. </span><span class="kobospan" id="kobo.531.4">See if the next round will get the</span><a id="_idIndexMarker585" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.532.1"> validation loss closer to zero. </span><span class="kobospan" id="kobo.532.2">Looking at the results, it is better but not perfect. </span><span class="kobospan" id="kobo.532.3">The slope of validation loss is trending down, but not as much as in more </span><span><span class="kobospan" id="kobo.533.1">realistic data.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.534.1">The output for ChatGPT-4o mini with the same data is included for comparison. </span><span class="kobospan" id="kobo.534.2">The training loss is almost zero. </span><span class="kobospan" id="kobo.534.3">The validation loss is still high and only slightly trending down (the red dots). </span><span class="kobospan" id="kobo.534.4">Because OpenAI changed the vertical scale (bad design!) look carefully to compare the results. </span><span class="kobospan" id="kobo.534.5">The second chart is scale is 25% different and thus the data is better than from ChatGPT-3.5. </span><span class="kobospan" id="kobo.534.6">Without more testing, it is hard to tell if this is acceptable for the data we trained </span><span><span class="kobospan" id="kobo.535.1">it on.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.536.1">If the results are not good, try other techniques. </span><span class="kobospan" id="kobo.536.2">Consider some of these </span><span><span class="kobospan" id="kobo.537.1">expert moves:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.538.1">You can compare and test along the way. </span><span class="kobospan" id="kobo.538.2">Each epoch generates a checkpoint. </span><span class="kobospan" id="kobo.538.3">This file compares one checkpoint to another or even a different model. </span><span class="kobospan" id="kobo.538.4">ChatGPT saves the last three checkpoints. </span><span><em class="italic"><span class="kobospan" id="kobo.539.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.540.1">.12</span></em><span class="kobospan" id="kobo.541.1"> zooms in on the checkpoints section. </span><span class="kobospan" id="kobo.541.2">They are listed in the fine-tuning job and can then be selected, cut, and pasted into the chat, or mouse over them and jump directly into the playground using </span><span><span class="kobospan" id="kobo.542.1">the link.</span></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer116" class="img---figure">
					<span class="kobospan" id="kobo.543.1"><img src="image/B21964_08_12.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.544.1">Figure 8.12 – Checkpoints can be directly opened in the playground</span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.545.1">Notice that the final checkpoint </span><a id="_idIndexMarker586" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.546.1">was selected and copied to the clipboard. </span><span class="kobospan" id="kobo.546.2">Clicking the </span><strong class="bold"><span class="kobospan" id="kobo.547.1">Playground</span></strong><span class="kobospan" id="kobo.548.1"> link on the first checkpoint opens it in the playground; a comparison model can be selected, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.549.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.550.1">.13</span></em><span class="kobospan" id="kobo.551.1">. </span><span class="kobospan" id="kobo.551.2">You can now paste the model path from the final checkpoint into the field as </span><span><span class="kobospan" id="kobo.552.1">a shortcut.</span></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer117" class="img---figure">
					<span class="kobospan" id="kobo.553.1"><img src="image/B21964_08_13.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.554.1">Figure 8.13 – Model names can be pasted into the model select field even in a comparison</span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.555.1">Now, you can compare results from the two models. </span><span class="kobospan" id="kobo.555.2">The demo won’t reveal any exciting results, but this method is helpful for comparisons with large </span><span><span class="kobospan" id="kobo.556.1">data sets.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.557.1">Increase the default Epochs from 2 to 3 or 4 for a strict classifier. </span><span class="kobospan" id="kobo.557.2">However, consider this only after it has </span><span><span class="kobospan" id="kobo.558.1">enough examples.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.559.1">If the model is too loose, increase the epochs for </span><span><span class="kobospan" id="kobo.560.1">additional training.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.561.1">In this last round, the training loss increased. </span><span class="kobospan" id="kobo.561.2">When re-running this model in Chat GPT-4o mini, the loss was much better (closer to zero). </span><span class="kobospan" id="kobo.561.3">Look at more and better data to stick with this model and decrease training loss. </span><span class="kobospan" id="kobo.561.4">As mentioned, the data is very similar and at risk of overfitting. </span><span class="kobospan" id="kobo.561.5">Use synonyms, introduce more variation, and insert or</span><a id="_idIndexMarker587" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.562.1"> delete words in the statement to scale up the variety and number of examples. </span><span class="kobospan" id="kobo.562.2">The data scientists have far more approaches at their fingertips. </span><span class="kobospan" id="kobo.562.3">These are too advanced for this book. </span><span class="kobospan" id="kobo.562.4">But the intern knows the answer. </span><span><span class="kobospan" id="kobo.563.1">Ask ChatGPT.</span></span><pre class="source-code"><span class="kobospan1" id="kobo.564.1">
How should I reduce training loss when building a fine-tuned LLM?</span></pre></li>			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.565.1">Adding examples and expanding test cases will improve results. </span><span class="kobospan" id="kobo.565.2">Continue to explore, grow test cases, improve </span><a id="_idIndexMarker588" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.566.1">the quality of the examples, play with the parameters, and learn. </span><span class="kobospan" id="kobo.566.2">The best resource in my journey, outside of ChatGPT itself, was a four-hour training masterclass from Mihael Cacic. </span><span class="kobospan" id="kobo.566.3">It was the most valuable of all resources, and it is recommended (I am not compensated for this; I was just a student). </span><span class="kobospan" id="kobo.566.4">It is perfect for product people. </span><span class="kobospan" id="kobo.566.5">It is the right level for an introduction class. </span><span class="kobospan" id="kobo.566.6">Check </span><span><span class="kobospan" id="kobo.567.1">it out.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.568.1">Training:</span><a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.569.1"> Miha’s training </span><span><span class="kobospan" id="kobo.570.1">website</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.571.1">(</span></span></span><a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.572.1">https://miha.academy/</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.573.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.574.1">Entry Point, his company, also has tools that support speeding up the training process and experimenting with fine-tuning jobs across multiple LLMs. </span><span class="kobospan" id="kobo.574.2">You can use Entry Point, connect to OpenAI and other LLM vendors, and never deal with the JSON format for fine-tuning. </span><span class="kobospan" id="kobo.574.3">Keep this in mind: tools help reduce the complexity of model management. </span><span class="kobospan" id="kobo.574.4">New tools are becoming available </span><span><span class="kobospan" id="kobo.575.1">every day.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.576.1">Look at Vijay’s article for more on fine-tuning and the different types of losses. </span><span class="kobospan" id="kobo.576.2">It discusses metrics, is a good resource, and only takes a few minutes </span><span><span class="kobospan" id="kobo.577.1">to read.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.578.1">Article: </span><a href="https://medium.com/@penpencil.blr/what-is-the-difference-between-training-loss-validation-loss-and-evaluation-loss-c169ddeccd59" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.579.1">Training vs. </span><span class="kobospan" id="kobo.579.2">Validation Loss</span></a><span class="kobospan" id="kobo.580.1"> by Vijay M </span><span class="hidden1"><span class="kobospan" id="kobo.581.1">(</span></span><span><span class="hidden1"><span class="kobospan" id="kobo.582.1">https://medium.com/@penpencil.blr/what-is-the-difference-between-training-loss-validation-loss-and-evaluation-loss-c169ddeccd59</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.583.1">Having gone end to end with a fine-tuning model, there are other areas to explore besides conversational style and tone. </span><span class="kobospan" id="kobo.583.2">In the enterprise, connecting to different data </span><a id="_idIndexMarker589" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.584.1">sources to gather information and push results also exists. </span><span class="kobospan" id="kobo.584.2">You will need </span><span><span class="kobospan" id="kobo.585.1">function calling.</span></span></p>
			<h2 id="_idParaDest-177" class="calibre9"><a id="_idTextAnchor182" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.586.1">Fine-tuning for function and tool calling</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.587.1">When passing data back and forth from existing systems, it is typical to conform to the other systems’ formats because these legacy systems are likely to stay the same for you. </span><span class="kobospan" id="kobo.587.2">The most recent models </span><a id="_idIndexMarker590" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.588.1">are getting better at matching the </span><strong class="bold"><span class="kobospan" id="kobo.589.1">function signature</span></strong><span class="kobospan" id="kobo.590.1"> to improve the reliability of these connections. </span><span class="kobospan" id="kobo.590.2">The</span><a id="_idIndexMarker591" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.591.1"> function signature is the description of the way to communicate to and from a service. </span><span class="kobospan" id="kobo.591.2">OpenAI and the interaction designer on any team will recommend valuation and confirmation steps to allow the user to understand and edit the information before submitting updates to these services. </span><span class="kobospan" id="kobo.591.3">When ChatGPT is aware of a function, its default is to enable it to decide whether it needs to call the function. </span><span class="kobospan" id="kobo.591.4">This parameter is </span><strong class="source-inline"><span class="kobospan" id="kobo.592.1">tool_choice</span></strong><span class="kobospan" id="kobo.593.1">, and it is set to </span><strong class="source-inline"><span class="kobospan" id="kobo.594.1">auto</span></strong><span class="kobospan" id="kobo.595.1">. </span><span class="kobospan" id="kobo.595.2">You can force this process by setting it to </span><strong class="source-inline"><span class="kobospan" id="kobo.596.1">required</span></strong><span class="kobospan" id="kobo.597.1">, specifying a specific named function, or telling it </span><strong class="source-inline"><span class="kobospan" id="kobo.598.1">none</span></strong><span class="kobospan" id="kobo.599.1"> to </span><span><span class="kobospan" id="kobo.600.1">disable it.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.601.1">There is little for us to do on the product side here. </span><span class="kobospan" id="kobo.601.2">It is included for completeness. </span><span class="kobospan" id="kobo.601.3">Of course, these interactions should be monitored to ensure the proper functions are called. </span><span class="kobospan" id="kobo.601.4">This requires additional training data to differentiate between similar functions, making sure that data is mapped to the correct fields when there is a collection of similar fields (for example, total price, discounted price, itemized prices, tax, and other dollar values), and to verify that the model extracted data correctly (not too much, not too little, but </span><span><span class="kobospan" id="kobo.602.1">just right).</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.603.1">Product people should be aware of one neat trick: </span><strong class="bold"><span class="kobospan" id="kobo.604.1">parallel function calling</span></strong><span class="kobospan" id="kobo.605.1">. </span><span class="kobospan" id="kobo.605.2">This allows multiple queries to</span><a id="_idIndexMarker592" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.606.1"> be sent in parallel, dramatically reducing the response time with no additional model cost. </span><em class="italic"><span class="kobospan" id="kobo.607.1">There is no such thing as a slow, good user interface</span></em><span class="kobospan" id="kobo.608.1">. </span><span class="kobospan" id="kobo.608.2">People today </span><span><span class="kobospan" id="kobo.609.1">are impatient.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.610.1">One gotcha. </span><span class="kobospan" id="kobo.610.2">OpenAI suggests that SQL generation is “not perfectly reliable.” </span><span class="kobospan" id="kobo.610.3">Therefore, use caution and extensive testing and monitoring. </span><span class="kobospan" id="kobo.610.4">I have not had success building AI SQL generators from text input, but this will improve </span><span><span class="kobospan" id="kobo.611.1">over time.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.612.1">Documentation: </span><a href="https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.613.1">Calling functions with chat </span><span><span class="kobospan" id="kobo.614.1">models</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.615.1">(</span></span></span><a href="https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.616.1">https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.617.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.618.1">Of all the ways to use fine-tuning, plenty of tips can help with this process. </span><span class="kobospan" id="kobo.618.2">We cover some of the </span><span><span class="kobospan" id="kobo.619.1">critical items.</span></span></p>
			<h1 id="_idParaDest-178" class="calibre5"><a id="_idTextAnchor183" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.620.1">Fine-tuning tips</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.621.1">You must care for and feed the fine-tuned set to improve training quality (based on the metrics or experience with certain test cases). </span><span class="kobospan" id="kobo.621.2">Here is a summary of OpenAI’s suggestions </span><span><span class="kobospan" id="kobo.622.1">for fine-tuning:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.623.1">Review existing examples for issues</span></strong><span class="kobospan" id="kobo.624.1">: You might have introduced style, logic, or grammar issues</span><a id="_idIndexMarker593" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.625.1"> into the dataset, including examples with errors. </span><span class="kobospan" id="kobo.625.2">Review the material against how the model performed before and after adding the data. </span><span class="kobospan" id="kobo.625.3">You can use the epoch checkpoints as </span><span><span class="kobospan" id="kobo.626.1">a tool.</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.627.1">Gather more examples to fill the gaps</span></strong><span class="kobospan" id="kobo.628.1">: Additional training examples might show the model how to address gaps in its abilities. </span><span class="kobospan" id="kobo.628.2">It is always hard to say how much is </span><span><span class="kobospan" id="kobo.629.1">too much.</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.630.1">Include examples with errors</span></strong><span class="kobospan" id="kobo.631.1">: Sometimes, it is best to learn from the master. </span><span class="kobospan" id="kobo.631.2">Let’s ask ChatGPT about including mistakes in </span><span><span class="kobospan" id="kobo.632.1">fine-tuned examples:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.633.1">
Should fine-tuning examples
include intentional errors
that might be expected
from real customers?
</span><span class="kobospan1" id="kobo.633.2">Yes, it's beneficial to include
intentional errors in fine-tuning
examples. </span><span class="kobospan1" id="kobo.633.3">This approach enhances
the model's robustness, making it
better equipped to handle the
kinds of mistakes real customers
might make, such as typos or
grammatical errors. </span><span class="kobospan1" id="kobo.633.4">By training
on these, the model can learn to
respond accurately even when
inputs aren't perfect. </span><span class="kobospan1" id="kobo.633.5">It prepares
the model for real-world
interactions, improving its
ability to correct, clarify, or
ignore errors as needed, ultimately
leading to a better user experience.</span></pre></li>				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.634.1">Look for imbalance and the need for more diversity in data</span></strong><span class="kobospan" id="kobo.635.1">: Does the data set provide a range of examples? </span><span class="kobospan" id="kobo.635.2">Refrain from biasing data with one kind of answer. </span><span class="kobospan" id="kobo.635.3">It is not helpful to rephrase the same question. </span><span class="kobospan" id="kobo.635.4">Think about the expense examples. </span><span class="kobospan" id="kobo.635.5">Not just </span><a id="_idIndexMarker594" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.636.1">data format but style, idiomatic language, lack of data, too much data, and even irrelevant data. </span><span class="kobospan" id="kobo.636.2">Even the 78 sarcastic examples for the four rounds of testing were a little homogenous. </span><span class="kobospan" id="kobo.636.3">This is something the team has </span><span><span class="kobospan" id="kobo.637.1">to notice.</span></span></li>
			</ol>
			<p class="callout-heading"><span class="kobospan" id="kobo.638.1">Imbalance example</span></p>
			<p class="callout"><span class="kobospan" id="kobo.639.1">I had a case that puzzled me for a while. </span><span class="kobospan" id="kobo.639.2">We had two primary tasks that a conversational assistant did. </span><span class="kobospan" id="kobo.639.3">It did expenses and time reporting. </span><span class="kobospan" id="kobo.639.4">However, both were needed in the same assistant. </span><span class="kobospan" id="kobo.639.5">The training data was biased toward the expense assistant’s round numbers and needed the correct numbers in the time reporting model. </span><span class="kobospan" id="kobo.639.6">While a customer might say “15 minutes,” “30 minutes,” or “an hour and 45 minutes” for a time record, most expenses are not “$15,” “$30,” or “$45”, so by overweighting on those round numbers in expenses it pushed understanding for the typical time units towards the expense model. </span><span class="kobospan" id="kobo.639.7">This bias can be improved by using better data for the expense model and ensuring the time model has the right balance </span><span><span class="kobospan" id="kobo.640.1">of examples.</span></span></p>
			<ol class="calibre12">
				<li value="5" class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.641.1">Match the training examples to expectations</span></strong><span class="kobospan" id="kobo.642.1">: If it is expected that most people will give the information needed to ask a question, fill out a form, or move forward, then training examples should mirror </span><span><span class="kobospan" id="kobo.643.1">those examples.</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.644.1">Validate the consistency of the examples when coming from multiple sources</span></strong><span class="kobospan" id="kobo.645.1">: Even humans are expected to disagree on specific values when labeling data. </span><span class="kobospan" id="kobo.645.2">If one </span><a id="_idIndexMarker595" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.646.1">person tags a company name as “The Business Center” and the other as “Business Center,” then the model can likely have </span><span><span class="kobospan" id="kobo.647.1">similar issues.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.648.1">Training examples should be in the </span><span><span class="kobospan" id="kobo.649.1">same format.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.650.1">Judge improvements based on </span><span><span class="kobospan" id="kobo.651.1">previous improvements.</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.652.1">Edge case issues take work to include</span></strong><span class="kobospan" id="kobo.653.1">: As a rule of thumb, expect a similar improvement for each doubling of quality training data. </span><span class="kobospan" id="kobo.653.2">But it is more work to find the edge cases than the happy paths. </span><span class="kobospan" id="kobo.653.3">Take the time to express those edge cases. </span><span class="kobospan" id="kobo.653.4">It will make the fine-tuned model more robust. </span><span class="kobospan" id="kobo.653.5">Edge cases could be in several attributes: length of the question, use of multiple languages in one question, multi-part complex questions, lots of chit chat with a small portion for the actual question, the use of data that is not well formatted or in a format not expected (military time, currencies with extra numbers), written words for numbers, or just plain wrong information. </span><span class="kobospan" id="kobo.653.6">Judge this by comparing the testing results between the fully tuned model and one using one-half of the training data. </span><span class="kobospan" id="kobo.653.7">Use this to judge future </span><span><span class="kobospan" id="kobo.654.1">stepwise improvements.</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.655.1">Specify and adjust the hyperparameters</span></strong><span class="kobospan" id="kobo.656.1">: Start with the defaults set by OpenAI. </span><span class="kobospan" id="kobo.656.2">If the model doesn’t follow the training data, increase epochs by one or two. </span><span class="kobospan" id="kobo.656.3">Notice how they were at five in the Wove case study coming up next. </span><span class="kobospan" id="kobo.656.4">This is more typical for classification, entity, extraction, or structured parsing tasks. </span><span class="kobospan" id="kobo.656.5">All of these have a known answer. </span><span class="kobospan" id="kobo.656.6">With more wide-ranging model tasks, decrease the epochs by 1 or 2 to see if that </span><span><span class="kobospan" id="kobo.657.1">improves diversity.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.658.1">If the model isn’t converging, increase</span><a id="_idIndexMarker596" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.659.1"> the </span><strong class="bold"><span class="kobospan" id="kobo.660.1">learning rate</span></strong><span class="kobospan" id="kobo.661.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.662.1">LR</span></strong><span class="kobospan" id="kobo.663.1">) multiplier. </span><span class="kobospan" id="kobo.663.2">The graphs from the Wove case study are in the next section. </span><span><em class="italic"><span class="kobospan" id="kobo.664.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.665.1">.5</span></em><span class="kobospan" id="kobo.666.1"> shows this convergence issue, as does the Wove example, which is covered shortly. </span><span class="kobospan" id="kobo.666.2">Only make small changes at one time. </span><span class="kobospan" id="kobo.666.3">Here is </span><span><span class="kobospan" id="kobo.667.1">some background:</span></span><p class="calibre3"><span class="kobospan" id="kobo.668.1">Article: </span><a href="https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.669.1">Learning </span><span><span class="kobospan" id="kobo.670.1">Rate</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.671.1">(</span></span></span><a href="https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.672.1">https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.673.1">)</span></span></span></p></li>
				<li class="calibre8"><span class="kobospan" id="kobo.674.1">One issue is overfitting. </span><span class="kobospan" id="kobo.674.2">Mihael from Entry Point provided the example in </span><span><em class="italic"><span class="kobospan" id="kobo.675.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.676.1">.14</span></em><span class="kobospan" id="kobo.677.1">, in which the validation loss continued to grow while the training loss was </span><a id="_idIndexMarker597" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.678.1">acceptable. </span><span class="kobospan" id="kobo.678.2">This is a classic </span><span><span class="kobospan" id="kobo.679.1">overfitting example.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer118" class="img---figure">
					<span class="kobospan" id="kobo.680.1"><img src="image/B21964_08_14.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.681.1">Figure 8.14 – An example of overfitting is shown with the increase in validation loss</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.682.1">The analogy is studying for a test by memorizing the exact questions and answers from a practice test. </span><span class="kobospan" id="kobo.682.2">Then, in the actual test, none of the questions are similar enough to allow the taker to answer correctly. </span><span class="kobospan" id="kobo.682.3">Aligned too closely with the study material, fails to translate to </span><span><span class="kobospan" id="kobo.683.1">answering correctly.</span></span></p>
			<ol class="calibre12">
				<li value="13" class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.684.1">Use a second model to verify a fine-tuned model</span></strong><span class="kobospan" id="kobo.685.1">: One approach is to use a second model to </span><a id="_idIndexMarker598" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.686.1">test the first model to confirm results. </span><span class="kobospan" id="kobo.686.2">The second model might be the same or completely different fine-tuned or off-the-shelf LLM. </span><span class="kobospan" id="kobo.686.3">Set a quality threshold; if the AI answer fails, it might route the request to a human customer service agent. </span><span class="kobospan" id="kobo.686.4">It takes some experience to figure </span><span><span class="kobospan" id="kobo.687.1">this out.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.688.1">If, after all this work, the assistants’ style or tone needs to change, all of the examples don’t necessarily have to change. </span><span class="kobospan" id="kobo.688.2">Consider tweaking the prompts to override the examples. </span><span class="kobospan" id="kobo.688.3">If it is just a tweak, the fine-tuning is not going to waste; it is still helping give it </span><span><span class="kobospan" id="kobo.689.1">the experience.</span></span></li>
			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.690.1">This is a vast area for research, testing, and learning. </span><span class="kobospan" id="kobo.690.2">This is only a start to ensure you can apply these skills at the</span><a id="_idIndexMarker599" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.691.1"> team level. </span><span class="kobospan" id="kobo.691.2">We hope it is easy to appreciate how much the discussion impacts the quality of the user experience. </span><span class="kobospan" id="kobo.691.3">Here is one more resource as a companion to the earlier OpenAI </span><span><span class="kobospan" id="kobo.692.1">Fine-tuning documentation:</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.693.1">Article: </span><a href="https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.694.1">ChatGPT Fine Tuning </span><span><span class="kobospan" id="kobo.695.1">Documentation</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.696.1">(</span></span></span><a href="https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.697.1">https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.698.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.699.1">We want to examine how everything learned about prompt engineering and fine-tuning works for the Wove </span><span><span class="kobospan" id="kobo.700.1">use case.</span></span></p>
			<h1 id="_idParaDest-179" class="calibre5"><a id="_idTextAnchor184" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.701.1">Wove case study, continued</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.702.1">In </span><a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.703.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.704.1">, </span><em class="italic"><span class="kobospan" id="kobo.705.1">Gathering Data – Content is King,</span></em><span class="kobospan" id="kobo.706.1"> the Wove case study on data cleansing for rate sheets used by freight forwarders was kicked off. </span><span class="kobospan" id="kobo.706.2">They had to scrub the data before ingesting it to output a clean, unified view of all the rates from many carriers. </span><span class="kobospan" id="kobo.706.3">Now, it is time to explore their </span><a id="_idIndexMarker600" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.707.1">prompt engineering (we covered the basics in </span><a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.708.1">Chapter 7</span></em></span></a><span class="kobospan" id="kobo.709.1">, </span><em class="italic"><span class="kobospan" id="kobo.710.1">Prompt Engineering</span></em><span class="kobospan" id="kobo.711.1">) and fine-tuning efforts for </span><span><span class="kobospan" id="kobo.712.1">this solution.</span></span></p>
			<h2 id="_idParaDest-180" class="calibre9"><a id="_idTextAnchor185" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.713.1">Prompt engineering</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.714.1">They want the LLM to think like a</span><a id="_idIndexMarker601" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.715.1"> customer who does this step manually. </span><span class="kobospan" id="kobo.715.2">They created the prompt for the spreadsheets during the ingestion process (this early version was shared with us to maintain the proprietary nature of their </span><span><span class="kobospan" id="kobo.716.1">latest efforts):</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.717.1">
You are an expert at table understanding. </span><span class="kobospan1" id="kobo.717.2">You will be given a snippet of text and a row number for the header row. </span><span class="kobospan1" id="kobo.717.3">Your task is to determine where the data for the table starts and what range of rows make up the header for the table. </span><span class="kobospan1" id="kobo.717.4">If the header has ambiguous columns (such as many of the same columns), there may be a row around the header row that can provide additional context. </span><span class="kobospan1" id="kobo.717.5">Include these in your range for the header if so. </span><span class="kobospan1" id="kobo.717.6">Your response should be in YAML format like this: (example truncated)</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.718.1">Let’s review a few highlights from </span><span><span class="kobospan" id="kobo.719.1">this prompt:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.720.1">It sets the stage for the persona to </span><span><span class="kobospan" id="kobo.721.1">be adopted.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.722.1">It gives context for </span><span><span class="kobospan" id="kobo.723.1">understanding tables.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.724.1">It explains the input (snippets of text and </span><span><span class="kobospan" id="kobo.725.1">more details)</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.726.1">It helps with some exceptions (</span><span><span class="kobospan" id="kobo.727.1">ambiguous columns)</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.728.1">It defined the response </span><a id="_idIndexMarker602" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.729.1">format (</span><strong class="bold"><span class="kobospan" id="kobo.730.1">Yet Another Markup </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.731.1">Language</span></strong></span><span><span class="kobospan" id="kobo.732.1"> (</span></span><span><strong class="bold"><span class="kobospan" id="kobo.733.1">YAML</span></strong></span><span><span class="kobospan" id="kobo.734.1">))</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.735.1">Great job following the </span><a id="_idIndexMarker603" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.736.1">guidance! </span><span class="kobospan" id="kobo.736.2">Honestly, they were already following this same advice. </span><span class="kobospan" id="kobo.736.3">They use a lot of fine-tuned models, so examples don’t appear in their prompts. </span><span class="kobospan" id="kobo.736.4">One small thing: where is the idea of an emotive prompt? </span><span class="kobospan" id="kobo.736.5">They should explore if that helps their quality. </span><span class="kobospan" id="kobo.736.6">We can talk to them </span><span><span class="kobospan" id="kobo.737.1">about that!</span></span></p>
			<h2 id="_idParaDest-181" class="calibre9"><a id="_idTextAnchor186" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.738.1">Fine-Tuning for Wove</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.739.1">As discussed in the last chapter, Wove has a collection of models to perform specific tasks in cleaning the</span><a id="_idIndexMarker604" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.740.1"> spreadsheet data. </span><span class="kobospan" id="kobo.740.2">The fine-tuning process adapts generic models to improve the understanding of rate spreadsheets critical to Wove’s customers. </span><span class="kobospan" id="kobo.740.3">It is similar to teaching a 5</span><span class="superscript"><span class="kobospan1" id="kobo.741.1">th</span></span><span class="kobospan" id="kobo.742.1"> grader a new subject. </span><span class="kobospan" id="kobo.742.2">A 5</span><span class="superscript"><span class="kobospan1" id="kobo.743.1">th</span></span><span class="kobospan" id="kobo.744.1"> grader knows the basic language and can answer simple questions—they might even be into ships and trains and understand the concept of moving goods, but no 5</span><span class="superscript"><span class="kobospan1" id="kobo.745.1">th</span></span><span class="kobospan" id="kobo.746.1"> grader has ever seen a </span><span><span class="kobospan" id="kobo.747.1">rate sheet.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.748.1">We know that a model can only provide so much. </span><span class="kobospan" id="kobo.748.2">ChatGPT recommends starting with prompt engineering before going to fine-tuning. </span><span class="kobospan" id="kobo.748.3">In conversations, Kevin Mullet suggested an excellent way to remember this: “</span><em class="italic"><span class="kobospan" id="kobo.749.1">First</span></em><span class="kobospan" id="kobo.750.1">, figure out what to say, </span><em class="italic"><span class="kobospan" id="kobo.751.1">then</span></em><span class="kobospan" id="kobo.752.1"> figure out how to say it.” </span><span class="kobospan" id="kobo.752.2">We have shown how this can help, but this extra effort </span><span><span class="kobospan" id="kobo.753.1">is needed.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.754.1">Here are some checks that Wove does to verify that the data is being processed correctly. </span><span class="kobospan" id="kobo.754.2">This covers data quality, prompt quality, </span><span><span class="kobospan" id="kobo.755.1">and fine-tuning:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.756.1">They manually review the interpretation of the data to look </span><span><span class="kobospan" id="kobo.757.1">for hallucinations.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.758.1">They look for validation and training loss converging to zero. </span><span class="kobospan" id="kobo.758.2">They run additional evaluation data sets using OpenAI Evals to ensure that models pass established tests. </span><span class="kobospan" id="kobo.758.3">OpenAI provides a collection of templates to evaluate models using standard measures. </span><span class="kobospan" id="kobo.758.4">The evals allow judgment of how different model versions and prompts impact usage. </span><span class="kobospan" id="kobo.758.5">Here is a good introduction: </span><p class="calibre3"><span class="kobospan" id="kobo.759.1">Article: </span><a href="https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.760.1">Getting Started with OpenAI </span><span><span class="kobospan" id="kobo.761.1">Evals</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.762.1">(</span></span></span><a href="https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.763.1">https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.764.1">)</span></span></span></p></li>
				<li class="calibre8"><span class="kobospan" id="kobo.765.1">They use multiple steps in a chain and different models to focus on doing one thing well. </span><span class="kobospan" id="kobo.765.2">They</span><a id="_idIndexMarker605" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.766.1"> regularly revisit models to adopt newer and </span><span><span class="kobospan" id="kobo.767.1">cheaper ones.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.768.1">In one of the models, they do location mapping and use over 600 training examples. </span><span class="kobospan" id="kobo.768.2">10% is for validation data, but for some models, they bump up to 20%, depending on how expensive it is to generate </span><span><span class="kobospan" id="kobo.769.1">the data.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.770.1">Their training graph in </span><span><em class="italic"><span class="kobospan" id="kobo.771.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.772.1">.15</span></em><span class="kobospan" id="kobo.773.1"> looks good. </span><span class="kobospan" id="kobo.773.2">It is converging to zero for training loss. </span><span class="kobospan" id="kobo.773.3">They have a validation test set that works well and uses what appear to be </span><span><span class="kobospan" id="kobo.774.1">default parameters.</span></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer119" class="img---figure">
					<span class="kobospan" id="kobo.775.1"><img src="image/B21964_08_15.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.776.1">Figure 8.15 – An example of a training model converging</span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.777.1">Initially, they had learning rate issues. </span><span class="kobospan" id="kobo.777.2">In machine learning and statistics, the learning rate is a</span><a id="_idIndexMarker606" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.778.1"> tuned parameter in an optimization algorithm that determines the iteration step size while moving toward a minimum </span><span><span class="kobospan" id="kobo.779.1">loss function.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.780.1">Even if trained again, it never quite gets to the optimal point. </span><span class="kobospan" id="kobo.780.2">Sometimes, there is poor convergence or overfitting, as discussed. </span><span><em class="italic"><span class="kobospan" id="kobo.781.1">Figure 8</span></em></span><em class="italic"><span class="kobospan" id="kobo.782.1">.16</span></em><span class="kobospan" id="kobo.783.1"> shows an earlier run showing a lack </span><span><span class="kobospan" id="kobo.784.1">of convergence.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer120" class="img---figure">
					<span class="kobospan" id="kobo.785.1"><img src="image/B21964_08_16.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.786.1">Figure 8.16 – An example of an early Wove training model that didn’t converge</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.787.1">If there is bouncing and the lines do not quite converge, retrain with a lower learning rate. </span><span class="kobospan" id="kobo.787.2">Convergence will be much slower if the initial weights are too high. </span><span class="kobospan" id="kobo.787.3">To put models in perspective, the four rounds for the sarcastic chatbot experiment ran with less than 5000 training tokens for each round. </span><span class="kobospan" id="kobo.787.4">The Wove model above used over 500,000 training tokens for this one piece of their solution. </span><span class="kobospan" id="kobo.787.5">Bigger doesn’t </span><span><span class="kobospan" id="kobo.788.1">guarantee convergence.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.789.1">Our friends at Wove have</span><a id="_idIndexMarker607" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.790.1"> a few more tips for those </span><span><span class="kobospan" id="kobo.791.1">ingesting spreadsheets:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.792.1">They use expensive models to fine-tune cheaper models. </span><span class="kobospan" id="kobo.792.2">For example, Anthropic’s Opus 3 Claude is (at this time of writing) about 30 to 50 times more costly than OpenAI 3.5. </span><span class="kobospan" id="kobo.792.3">Opus 3 is 15$/1M input and 75$/1M output tokens versus ChatGPT 3.5 turbo-0125 at $0.50/1M input and $1.50/1M output tokens. </span><span class="kobospan" id="kobo.792.4">This is an essential point for the product team. </span><span class="kobospan" id="kobo.792.5">You want to get the best bang for the buck, especially when dealing with customers who will use the model more often if it provides excellent service. </span><span class="kobospan" id="kobo.792.6">They found significantly better quality from fine-tuning ChatGPT 4.0 than earlier 3.5 models. </span><span class="kobospan" id="kobo.792.7">Chat GPT-4o mini is now </span><span><span class="kobospan" id="kobo.793.1">being incorporated.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.794.1">They started using a higher learning rate, which they could reduce when they made significant steps. </span><span class="kobospan" id="kobo.794.2">The amount of data impacts the learning rate steps (e.g., 0.5, 0.1, and 0.01). </span><span class="kobospan" id="kobo.794.3">This can be tweaked based on the size of the data set and other factors. </span><span class="kobospan" id="kobo.794.4">The goal is to refine so the training loss decreases in an orderly fashion without wild swings </span><span><span class="kobospan" id="kobo.795.1">or divergence.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.796.1">Working around the context window, they started with a 4K context window and grew to support 16K. </span><span class="kobospan" id="kobo.796.2">They can preprocess data and use other tools to deal with smaller chunks. </span><span class="kobospan" id="kobo.796.3">Even at 16K, this is small for handling </span><span><span class="kobospan" id="kobo.797.1">large spreadsheets.</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.798.1">Make sure the data is accurate</span></strong><span class="kobospan" id="kobo.799.1">: With good input data, success is more likely. </span><span class="kobospan" id="kobo.799.2">If the trained data isn’t tagged correctly or has missing data, the data team will have issues. </span><span class="kobospan" id="kobo.799.3">This real example is for an early Wove’s table end detection version. </span><span class="kobospan" id="kobo.799.4">You </span><a id="_idIndexMarker608" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.800.1">can see this in the chart bouncing all over the place compared to earlier examples. </span><span class="kobospan" id="kobo.800.2">You don’t see </span><span><span class="kobospan" id="kobo.801.1">a convergence.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.802.1">We can look at one example of a hallucination and how they corrected it in the part of the flow where they took the text version of the spreadsheet (left column) and asked ChatGPT to define (understand) the row’s context (middle column). </span><span class="kobospan" id="kobo.802.2">This is </span><em class="italic"><span class="kobospan" id="kobo.803.1">Step 1</span></em><span class="kobospan" id="kobo.804.1">. </span><span class="kobospan" id="kobo.804.2">Then, they edited this output, completing the process with the final output (right column) shown in </span><span><em class="italic"><span class="kobospan" id="kobo.805.1">Table 8.4</span></em></span><span><span class="kobospan" id="kobo.806.1">.</span></span></p>
			<table id="table004-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.807.1">Input File</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.808.1">Intermediary output </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.809.1">from ChatGPT</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.810.1">Final normalized file </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.811.1">from ChatGPT</span></strong></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.812.1">The table on the sheets “Rate Sheet”, is from the VN to US </span><span><span class="kobospan" id="kobo.813.1">UPDATE file.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.814.1">The table has </span><span><span class="kobospan" id="kobo.815.1">these columns:</span></span><span class="kobospan" id="kobo.816.1">
- </span><span><span class="kobospan" id="kobo.817.1">id: 0</span></span></p>
							<p class="calibre3">  <span><span class="kobospan" id="kobo.818.1">name: POL</span></span></p>
							<p class="calibre3">  <span><span class="kobospan" id="kobo.819.1">Examples:</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.820.1">  - DA </span><span><span class="kobospan" id="kobo.821.1">NANG, VIETNAM</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.822.1">  - HO CHI MINH </span><span><span class="kobospan" id="kobo.823.1">CITY, VIETNAM</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.824.1">  - </span><span><span class="kobospan" id="kobo.825.1">HAIPHONG, VIETNAM</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.826.1">  - VUNG </span><span><span class="kobospan" id="kobo.827.1">TAU, VIETNAM</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.828.1">Purpose: This table provides ocean freight rates and details from various ports in Vietnam to destination in the United States, carriers and services, valid for a certain </span><span><span class="kobospan" id="kobo.829.1">date range.</span></span>
<span><span class="kobospan" id="kobo.830.1">columns:</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.831.1">-   </span><span><span class="kobospan" id="kobo.832.1">id: 0</span></span></p>
							<p class="calibre3">  <span><span class="kobospan" id="kobo.833.1">name: POL</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.834.1">  description: The port of loading in Vietnam, such as De NANG, HAIPHONG, QUI NHON, or </span><span><span class="kobospan" id="kobo.835.1">VUNG TAU.</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.836.1">examples:</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.837.1">  - DA </span><span><span class="kobospan" id="kobo.838.1">NANG, VIETNAM</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.839.1">  - </span><span><span class="kobospan" id="kobo.840.1">HAIPHONG, VIETNAM</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.841.1">  - VUNG </span><span><span class="kobospan" id="kobo.842.1">TAU, VIETNAM</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.843.1">carrier: 7</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.844.1">service_line: 4</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.845.1">origin: 0</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.846.1">origin_country: Vietnam</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.847.1">origin_via: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.848.1">origin_via_country: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.849.1">destination: 1</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.850.1">destination_country: </span><span><span class="kobospan" id="kobo.851.1">United States</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.852.1">destination_via: 2</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.853.1">destination_via_county: </span><span><span class="kobospan" id="kobo.854.1">United States</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.855.1">loading_port: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.856.1">loading_port_country: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.857.1">unloading_port: null</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<table id="table005-3" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.858.1">Input File</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.859.1">Intermediary output </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.860.1">from ChatGPT</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.861.1">Final normalized file </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.862.1">from ChatGPT</span></strong></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.863.1">- </span><span><span class="kobospan" id="kobo.864.1">id: 2</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.865.1">name: Dest (</span><span><span class="kobospan" id="kobo.866.1">Via Port)</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span><span class="kobospan" id="kobo.867.1">examples:</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.868.1">- </span><span><span class="kobospan" id="kobo.869.1">OAKLAND, CA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.870.1">- </span><span><span class="kobospan" id="kobo.871.1">NORFOLK, VA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.872.1">- LOS </span><span><span class="kobospan" id="kobo.873.1">ANGELES, CA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.874.1">- </span><span><span class="kobospan" id="kobo.875.1">SAVANNAH, GA</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.876.1">VANCOUVER, CANADA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.877.1">- </span><span><span class="kobospan" id="kobo.878.1">None</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.879.1">- </span><span><span class="kobospan" id="kobo.880.1">TACOMA, WA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.881.1">- </span><span><span class="kobospan" id="kobo.882.1">BALTIMORE, MD</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.883.1">- </span><span><span class="kobospan" id="kobo.884.1">CHARLESTON, SC</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.885.1">- NEW </span><span><span class="kobospan" id="kobo.886.1">YORK, NY</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.887.1">- </span><span><span class="kobospan" id="kobo.888.1">id: 1</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span><span class="kobospan" id="kobo.889.1">name: Destination</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.890.1">description: The destination city and state in the United States, such as LONG BEACH, CA, SEATTLE, WA, or </span><span><span class="kobospan" id="kobo.891.1">CLEVELAND, OH</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.892.1">examples:</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.893.1">- </span><span><span class="kobospan" id="kobo.894.1">ATLANTA, GA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.895.1">- </span><span><span class="kobospan" id="kobo.896.1">PITTSBURGH, PA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.897.1">- </span><span><span class="kobospan" id="kobo.898.1">CHARLOTTE, NC</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.899.1">- </span><span><span class="kobospan" id="kobo.900.1">CLEVELAND, OH</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.901.1">- </span><span><span class="kobospan" id="kobo.902.1">id: 2</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.903.1">name: Dest (</span><span><span class="kobospan" id="kobo.904.1">via Port)</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.905.1">description: The port in the United States that the shipment will go to reaching its final destination, such as NORFOLK, VA, SEATTLE,WA or LOS ANGELES, CA. </span><span class="kobospan" id="kobo.905.2">Can also be “None” if the shipping direct to </span><span><span class="kobospan" id="kobo.906.1">the destination.</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.907.1">examples:</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.908.1">- </span><span><span class="kobospan" id="kobo.909.1">NORFOLK, VA</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.910.1">- </span><span><span class="kobospan" id="kobo.911.1">SAVANNAH, GA</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.912.1">unloading_port_country: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.913.1">effective_date: 8</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.914.1">expiry_date: 9</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.915.1">container_dry_or_reefer: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.916.1">commodity: null</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.917.1">rates:</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.918.1">- </span><span><span class="kobospan" id="kobo.919.1">id: 10</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.920.1">currency: null</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.921.1">type: total</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.922.1">container_size: “20ft”</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.923.1">- </span><span><span class="kobospan" id="kobo.924.1">id: 11</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.925.1">currency: null</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.926.1">type: total</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.927.1">container_size: “40ft”</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span><span class="kobospan" id="kobo.928.1">- </span><span><span class="kobospan" id="kobo.929.1">id: 12</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.930.1">currency: null</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.931.1">type: total</span></span></p>
							<p class="calibre3"><span lang="hi-IN" xml:lang="hi-IN">  </span>  <span><span class="kobospan" id="kobo.932.1">container_size: “40ft_hc”</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.933.1">Table 8.4 – Wove file improvement steps (some data are truncated)</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.934.1">The table shows the description of the destination, aka dest (via port), generated in the middle column: “The port in</span><a id="_idIndexMarker609" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.935.1"> the United States that the shipment will go…”. </span><span class="kobospan" id="kobo.935.2">However, the data includes Vancouver, Canada. </span><span class="kobospan" id="kobo.935.3">Although the destination is always the US, the port it goes via might be outside </span><span><span class="kobospan" id="kobo.936.1">the US.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.937.1">To improve the model, this hallucination needs to be corrected. </span><span class="kobospan" id="kobo.937.2">It could be decided that the correct answer is to edit this to be “North America,” or better is to remove the “in the United States” entirely, making the description more generic. </span><span class="kobospan" id="kobo.937.3">This means that the output file in the next step also needs correction. </span><span class="kobospan" id="kobo.937.4">The </span><strong class="source-inline"><span class="kobospan" id="kobo.938.1">destination_via_country</span></strong><span class="kobospan" id="kobo.939.1"> field will be changed from United States to </span><strong class="source-inline"><span class="kobospan" id="kobo.940.1">null</span></strong><span class="kobospan" id="kobo.941.1">. </span><span class="kobospan" id="kobo.941.2">This file on the right is a second round of ChatGPT generation, creating the unified model that makes all the spreadsheet data a consistent, normalized output. </span><span class="kobospan" id="kobo.941.3">It is vital to catch these errors. </span><span class="kobospan" id="kobo.941.4">With this final output file, they re-run the test data to see whether the </span><span><span class="kobospan" id="kobo.942.1">quality improves.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.943.1">Overall, this fine-tuning process </span><a id="_idIndexMarker610" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.944.1">requires many iterations on the prompts, editing of the tags, and evaluating against their test data. </span><span class="kobospan" id="kobo.944.2">We can’t expose all of Wove’s secret sauce, but hopefully, this gives a sense. </span><span class="kobospan" id="kobo.944.3">A modeler’s work is never done. </span><span class="kobospan" id="kobo.944.4">Although ongoing effort might be reduced, work will not be done. </span><span class="kobospan" id="kobo.944.5">Format changes can occur, including new vendors, normalizations, better, cheaper, and faster models, and everyone’s favorite, bugs will require rework. </span><span class="kobospan" id="kobo.944.6">The point is to be involved and invested in these steps to ensure quality. </span><span class="kobospan" id="kobo.944.7">Readers can imagine the next steps for Wove once all this data is normalized and available. </span><span class="kobospan" id="kobo.944.8">Customers will want to ask questions about the best route based on shipping characteristics. </span><span class="kobospan" id="kobo.944.9">They will not want to pour through even a normalized sheet </span><span><span class="kobospan" id="kobo.945.1">of rates.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.946.1">This is an exciting use case because it starts as a backend solution, still needs product understanding and feedback to be successful, and will likely lead to even more UX efforts when (inevitability) a customer-facing chat experience will converse with customers to help shop rates. </span><span class="kobospan" id="kobo.946.2">Product and UX efforts will be </span><span><span class="kobospan" id="kobo.947.1">needed there.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.948.1">Wove used a series of models to understand the complexities of tables. </span><span class="kobospan" id="kobo.948.2">Picking and chaining suitable models is part of the prompt engineering and </span><span><span class="kobospan" id="kobo.949.1">fine-tuning process.</span></span></p>
			<h1 id="_idParaDest-182" class="calibre5"><a id="_idTextAnchor187" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.950.1">Summary</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.951.1">Fine-tuning is the most technical piece of this book. </span><span class="kobospan" id="kobo.951.2">With this little glimpse into this world, there is much to cover. </span><span class="kobospan" id="kobo.951.3">Your data scientists and engineers will go deeper. </span><span class="kobospan" id="kobo.951.4">When building production-ready systems, mix and match fine-tuned and generic models with internal software and third-party tools to balance speed of delivery, price, and performance (recall the saying, </span><em class="italic"><span class="kobospan" id="kobo.952.1">cheap, fast, or good, choose two</span></em><span class="kobospan" id="kobo.953.1">). </span><span class="kobospan" id="kobo.953.2">Innovative solutions have workflow steps that allow the solution to bail out if the AI isn’t performing, use a function to solve or address a specific problem, or use a more deterministic element to provide a robust solution. </span><span class="kobospan" id="kobo.953.3">Injecting the suitable model and prompts for the correct part of a use case is one of the most critical decisions. </span><span class="kobospan" id="kobo.953.4">Do this work before embarking on the </span><span><span class="kobospan" id="kobo.954.1">fine-tuning approach.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.955.1">Contribute to the process by helping define and improve these task flows through use case expertise, editing and improving prompts, creating, verifying, and editing fine-tuning examples, and monitoring if changes are moving the solution in the right direction. </span><span class="kobospan" id="kobo.955.2">Go forth </span><span><span class="kobospan" id="kobo.956.1">and tune!</span></span></p>
			<p class="calibre3"><a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.957.1">Chapter 9</span></em></span></a><span class="kobospan" id="kobo.958.1">, </span><em class="italic"><span class="kobospan" id="kobo.959.1">Guidelines and Heuristics,</span></em><span class="kobospan" id="kobo.960.1"> will cover guidelines and heuristics to support prompting and fine-tuning efforts based on well-documented techniques in the design community to help explain conversational </span><span><span class="kobospan" id="kobo.961.1">AI’s usability.</span></span></p>
			<h1 id="_idParaDest-183" class="calibre5"><a id="_idTextAnchor188" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.962.1">References</span></h1>
			<table id="table006-1" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div class="calibre2">
								<div id="_idContainer121" class="img---figure">
									<span class="kobospan" id="kobo.963.1"><img src="image/B21964_08_QR.jpg" alt="" role="presentation" class="calibre4"/></span>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.964.1">The links, book recommendations, and GitHub files in this chapter are posted on the </span><span><span class="kobospan" id="kobo.965.1">reference page.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.966.1">Web Page: </span><a href="https://uxdforai.com/references#C8" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.967.1">Chapter 8</span></span> <span><span class="kobospan" id="kobo.968.1">References</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.969.1">(</span></span></span><a href="https://uxdforai.com/references#C8" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.970.1">https://uxdforai.com/references#C8</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.971.1">)</span></span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>