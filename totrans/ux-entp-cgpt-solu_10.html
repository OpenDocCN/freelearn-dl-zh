<html><head></head><body>
		<div><h1 id="_idParaDest-167" class="chapter-number"><a id="_idTextAnchor172" class="pcalibre pcalibre1 calibre6"/>8</h1>
			<h1 id="_idParaDest-168" class="calibre5"><a id="_idTextAnchor173" class="pcalibre pcalibre1 calibre6"/>Fine-Tuning</h1>
			<p class="calibre3">What happens when prompt engineering efforts have gone as far as they can go? If higher quality results are still needed, examples are overwhelming the prompt, performance issues appear, or token costs are excessive because of a large prompt, <strong class="bold">fine-tuning</strong> comes into the picture.</p>
			<p class="calibre3">As mentioned in the last chapter, solutions sometimes require overlapping approaches such as <strong class="bold">Retrieval-Augmented Generation</strong> (<strong class="bold">RAG</strong>), prompt engineering, and fine-tuning. Fine-tuning helps the model improve its understanding. We will focus on a few critical deliverables before contextualizing them by completing the Wove case study started in <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content </em><em class="italic">is King</em>:</p>
			<ul class="calibre7">
				<li class="calibre8">Fine-tuning 101</li>
				<li class="calibre8">Creating fine-tuned models</li>
				<li class="calibre8">Fine-tuning tips</li>
				<li class="calibre8">Wove case study, continued</li>
			</ul>
			<p class="calibre3">Regardless of the tools, the team must care and feed the <strong class="bold">large language model</strong> (<strong class="bold">LLM</strong>) to improve the output. Though the methods discussed in the book can reach limits, fine-tuning is another excellent trick.</p>
			<h1 id="_idParaDest-169" class="calibre5"><a id="_idTextAnchor174" class="pcalibre pcalibre1 calibre6"/>Fine-tuning 101</h1>
			<p class="calibre3">Think of fine-tuning as teaching the solution how to approach a problem. You are not telling it the exact answers. That is for RAG. You coach the LLM on approaching issues, thinking about the solution, and <a id="_idIndexMarker553" class="pcalibre pcalibre1 calibre6"/>how it should respond. Even though specific examples are used in fine-tuning, don’t expect it to use that exact example <em class="italic">ever</em>. It is just an example. Imagine we need it to be like a science teacher, so the LLM is told in prompts to <em class="italic">be a science teacher</em>, but if it needs to <em class="italic">sound like</em> an 8th-grade science teacher, share examples of what it is expected to sound like. Then, when these examples are added to the models, compare them against output examples and decide whether they are doing a good job. We will do this work using fine-tuning in the ChatGPT playground, as shown in <em class="italic">Figure 8</em><em class="italic">.1</em>.</p>
			<div><div><img src="img/B21964_08_01.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Fine-tuning in ChatGPT</p>
			<p class="calibre3">We will walk through an example. This will give a feel for what is being built, how to contribute examples for training and testing, and what the results are when the model is improved with fine-tuning.</p>
			<h2 id="_idParaDest-170" class="calibre9"><a id="_idTextAnchor175" class="pcalibre pcalibre1 calibre6"/>Prompt engineering or fine-tuning? Where to spend resources</h2>
			<p class="calibre3">We already know you<a id="_idIndexMarker554" class="pcalibre pcalibre1 calibre6"/> need both, but if examples are added to the prompts, each use of the prompt will incur a cost because the input tokens cost money every time they are sent to the model. One trick is to move training data from prompts to fine-tuning. As new examples or edge cases are discovered, add them to improve the model.</p>
			<p class="callout-heading">Start with prompt engineering and move on to fine-tuning</p>
			<p class="callout">The prompt engineering tools in <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a>, <em class="italic">Prompt Engineering,</em> give value and include a faster feedback loop than the more technical efforts needed for fine-tuning. Creating datasets and running<a id="_idIndexMarker555" class="pcalibre pcalibre1 calibre6"/> training jobs takes more effort and time to see results. In enterprise use cases, both will be required. Responding to a fine-tuned model can be much less expensive and faster than responding to a large prompt with many examples to process each turn.</p>
			<h2 id="_idParaDest-171" class="calibre9"><a id="_idTextAnchor176" class="pcalibre pcalibre1 calibre6"/>Token costs do matter</h2>
			<p class="calibre3">It is expected to start with growing prompts by including examples of how the model should respond. There can be <a id="_idIndexMarker556" class="pcalibre pcalibre1 calibre6"/>significant costs if large prompts are used tens of millions of times as each customer interacts with the LLM. Compare the following prompts with learning examples to a fine-tuned model that contains the same examples:</p>
			<pre class="source-code">
Classify what we give you into a positive or negative statement. Here are some examples.
You are a bad driver -- Negative
Your hair looks amazing -- Positive
The sunrise is beautiful – Positive
(Truncated. 50 examples total)</pre>			<p class="calibre3">Remove these from the prompt and add them to a fine-tuned model behind the scenes with the exact examples. This leaves the prompt like this:</p>
			<pre class="source-code">
Classify what we give you into a positive or negative statement.</pre>			<p class="calibre3">The former includes about 500 tokens, using just 50 examples, while the prompt alone is 14 tokens. By moving the examples into a fine-tuned model, each turn will save 97% in input tokens. A fine-tuning model can cost more than a generic model. We can compare the input costs, as shown in <em class="italic">Table 8.1</em>.</p>
			<table id="table001-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Model</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Costs</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Cost for 10,000 prompts @ 500 tokens </strong><strong class="bold">per prompt</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Cost for 10,000 prompts @ 14 tokens </strong><strong class="bold">per prompt</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">GPT-3.5 </strong><strong class="bold">Turbo fine-tuned</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$3.00 / 1M input tokens</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$15.00</p>
							<p class="calibre3">(good results)</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">$</strong><strong class="bold">0.42</strong></p>
							<p class="calibre3">(savings of 97%)</p>
							<p class="calibre3">(good results)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">GPT-3.5 Turbo</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$0.50 / 1M input tokens</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">$</strong><strong class="bold">2.50</strong></p>
							<p class="calibre3">(hard to improve results)</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$0.07</p>
							<p class="calibre3">(hard to improve results)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">GPT-4o mini</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$0.15 / 1M input tokens</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$0.75</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$0.021 (a little over 2 cents)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 8.1 – Comparison of costs for models using fine-tuning and reducing prompt size</p>
			<p class="calibre3">The generic model won’t be able to return the robustness of the fine-tuned model. Yet, the generic mode, with the collection of examples in the prompt, is still five <a id="_idIndexMarker557" class="pcalibre pcalibre1 calibre6"/>times more expensive in this trivial example ($2.50 compared to 42 cents). Prompting is faster and great for getting started, but fine-tuning will be how to customize the model in many cases. Recall that a solution can include generic (cheap) models in conjunction with fine-tuned models. This is reasonable. The token cost for a prompt can be calculated using the OpenAI tokenizer.</p>
			<p class="calibre3">Demo: <a href="https://platform.openai.com/tokenizer" class="pcalibre pcalibre1 calibre6">Tokenizer</a> (<a href="https://platform.openai.com/tokenizer" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/tokenizer</a>)</p>
			<p class="calibre3">Even though cost will be considered, many use cases require a fine-tuned model. In this example, if the quality is there with GPT-4o mini with the small prompt and no training examples, then costs can be dramatically smaller. The use case will dictate the extent to which examples are needed for training. Let’s get started by learning how to build a fine-tuned model. The Playground supports this without coding.</p>
			<h1 id="_idParaDest-172" class="calibre5"><a id="_idTextAnchor177" class="pcalibre pcalibre1 calibre6"/>Creating fine-tuned models</h1>
			<p class="calibre3">Every model will have different needs. With GPT-3.5 Turbo, a start might be 50 to 100 examples. After reaching the end of a good return on investment from prompt engineering, prompt chaining, and even function calling, we wind up here at fine-tuning. Because so many enterprise use<a id="_idIndexMarker558" class="pcalibre pcalibre1 calibre6"/> cases will have at least some requirement for fine-tuned models, the best you can do is optimize for small context windows in exchange for more fine-tuning examples. The fine-tuned model costs the same, with 50 examples or 5000. So, if you take a 3000 token prompt, move all the examples into the model, and leave a prompt of 300 tokens (a few paragraphs), that is a significant saving for each interaction. To put this in perspective, this paragraph has 173 tokens (766 characters).</p>
			<p class="calibre3">If fine-tuning doesn’t improve the model, the data science folks will likely have to figure out a different way of restructuring the model (OpenAI doesn’t give an example, but if all of these methods fail, ask ChatGPT for fine-tuning tips).</p>
			<p class="calibre3">Article:<a href="https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning" class="pcalibre pcalibre1 calibre6"> When to use fine-tuning</a> (<a href="https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning</a>)</p>
			<p class="calibre3">Anyone can assist in fine-tuning. It takes more effort than prompt engineering, but the formats are accessible, and effort needs to be put into the content. As designers, writers, linguists, and product people, put on the customer content hat and get going.</p>
			<p class="calibre3">Each model might have different formats. Here is the format for GPT-3.5 Turbo:</p>
			<pre class="source-code">
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is very business-like."}, {"role": "user", "content": "What is the maximum withdrawal amount from my IRA?"}, {"role": "assistant", "content": "That is a complex question. I need a little more information to give you an accurate answer."}]}
{"messages": [{"role": "system", "content": "Marv is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What's the capital of France?"}, {"role": "assistant", "content": "Paris, as if everyone doesn't know that already."}]}</pre>			<p class="calibre3">These are easy to model in a spreadsheet and can be reviewed by others and edited quickly. OpenAI also provides an example of multi-turn training data. Notice the weight key in their example. A weight of <code>0</code> means the model will ignore that specific message:</p>
			<pre class="source-code">
{"messages": [{"role": "system", "content": "Marv is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What's the capital of France?"}, {"role": "assistant", "content": "Paris", "weight": 0}, {"role": "user", "content": "Can you be more sarcastic?"}, {"role": "assistant", "content": "Paris, as if everyone doesn't know that already.", "weight": 1}]}</pre>			<p class="calibre3">We will use the Playground for examples, but the development team will build a pipeline to manage the testing and training data in real life. Split example data between training<a id="_idIndexMarker559" class="pcalibre pcalibre1 calibre6"/> and testing examples. Don’t include testing examples in the training set, or test results will be wrong. Hold out about 20% of the data for testing. You need to know whether the model is improving, and this data can be used to provide a benchmark.</p>
			<h2 id="_idParaDest-173" class="calibre9"><a id="_idTextAnchor178" class="pcalibre pcalibre1 calibre6"/>Fine-tuning for style and tone</h2>
			<p class="calibre3">Take prompt engineering<a id="_idIndexMarker560" class="pcalibre pcalibre1 calibre6"/> as far as possible to train the system, but style and tone, format, and other qualitative features can be expressed with examples. In <a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 1</em></a>, <em class="italic">Recognizing the Power of Design in ChatGPT</em>, there is an example of a surf shop being compared to a bank. Instructions on talking like a surfer or performing tasks as a trusted business advisor for a prestigious international financial company will help. However, examples of how interactions sound and feel for a surf shop and a bank can help tweak that style, tone, and sophistication for the LLM persona.</p>
			<p class="calibre3"><em class="italic">Round 1</em> is the first experiment for fine-tuning a model with ten training examples. There is nothing special about this example. We need to showcase how fine-tuning works and how to read the results from the output. As this hands-on activity progresses, keep your use cases in mind. For actual work, start with prompt engineering and learn what doesn’t work there. Then, think about how to apply fine-tuning. Let’s get started with the example:</p>
			<ol class="calibre12">
				<li class="calibre8">Head to the playground and go to the fine-tuning tab: <a href="https://platform.openai.com/finetune" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/finetune</a>.</li>
				<li class="calibre8">Click the <strong class="bold">+ Create</strong> button to add a new data set.<p class="calibre3">This is the first file used that includes the training data:</p><p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl" class="pcalibre pcalibre1 calibre6">Training Data with ten examples</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl</a>)</p><p class="calibre3">The example follows previous instructions for Alli, the sarcastic chatbot:</p><pre class="source-code">
Alli is a factual chatbot that is also sarcastic
How far is the Moon from Earth</pre><p class="calibre3">Far. Like a quarter million</p><p class="calibre3">miles. Or about how far you</p><p class="calibre3">might drive in a lifetime.</p></li>				<li class="calibre8">Create the model within the <strong class="bold">Create a fine-tuned model</strong> dialog box. <em class="italic">Figure 8</em><em class="italic">.2</em> shows selecting the <strong class="bold">Base Model</strong> (feel free to use the<a id="_idIndexMarker561" class="pcalibre pcalibre1 calibre6"/> latest models; the cost won’t be an issue for this experiment), selecting the training data file, and the form is ready to submit. Notice that, at this point, the optional parameters are left alone. We will explain them in the upcoming <em class="italic">Fine-tuning tips</em> section. For now, don't include any validation data to test the model.</li>
			</ol>
			<div><div><img src="img/B21964_08_02.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.2 – Setting up a fine-tuning job in OpenAI</p>
			<ol class="calibre12">
				<li value="4" class="calibre8">You will be returned to the fine-tuning page, and the job will take a few minutes to complete. The<a id="_idIndexMarker562" class="pcalibre pcalibre1 calibre6"/> results should look similar to <em class="italic">Figure 8</em><em class="italic">.3</em>.</li>
			</ol>
			<p class="calibre3"> </p>
			<div><div><img src="img/B21964_08_03.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Results from a fine-tuning job with ten examples (Round 1)</p>
			<p class="calibre3">Notice the training chart. We aim for it to tend to zero as it moves to the right. The number of entries in the chart equals the number of training examples times the number of epochs or a single pass through<a id="_idIndexMarker563" class="pcalibre pcalibre1 calibre6"/> the training data. The <code>10</code>. We will consider this number of iterations very<a id="_idIndexMarker564" class="pcalibre pcalibre1 calibre6"/> high and a function of having so few training examples. We will explain this in more detail as this testing process continues.</p>
			<p class="callout-heading">Failure is an option</p>
			<p class="callout">Although the file shared work, the first time I did a fine-tuning job, it took me five tries to debug the typos. If the job fails, it will provide feedback. Fix it and try again. We will discuss third-party tools later in the chapter that help us avoid file formatting issues. To be fair to this process, the results are as shown. I have not gone back and made the results better or tweaked anything. The intent is to appreciate the process.</p>
			<p class="calibre3">Now that the basics are working, it is time to explain what happened. A base model with billions of parameters was selected and fine-tuned to understand how to respond in the manner defined in the file. You can test this model at any time on the <strong class="bold">Playground</strong> | <strong class="bold">Chat</strong> window by selecting it by the name assigned in the output model field. You can even copy the name to make it easier to find in the <strong class="bold">Chat</strong> drop menu, as shown in <em class="italic">Figure 8</em><em class="italic">.4</em>. You will need to enter the system instructions; <em class="italic">Alli is a factual chatbot that is also sarcastic</em>. This is ignored by the model, even though it is in the training file.</p>
			<div><div><img src="img/B21964_08_04.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Copy and paste the fine-tuned model name into the Chat window</p>
			<p class="calibre3">Now, re-run the same set of tests, but this time, include this file for the validation data with the same training <a id="_idIndexMarker565" class="pcalibre pcalibre1 calibre6"/>data as in <em class="italic">Figure 8</em><em class="italic">.5</em>. <em class="italic">Round 2</em> will take a few more minutes.</p>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl" class="pcalibre pcalibre1 calibre6">20 validation examples</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl</a>)</p>
			<div><div><img src="img/B21964_08_05.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Creating a model with training data</p>
			<p class="calibre3">The validation file is a collection that is <em class="italic">not</em> used for training but by the model to compare its results to what is expected. The validation data is very human-like, oddly similar to the training date, and not very logical, or clearly defined, such as classifying service requests by priority or determining sentiment. This means getting the charts to tend to zero will be hard.</p>
			<p class="calibre3">We can view the results and see what to do as the next steps in <em class="italic">Figure 8</em><em class="italic">.6</em>. We will take time to explain what is happening, but there are still a few training rounds.</p>
			<div><div><img src="img/B21964_08_06.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.6 – Results from a fine-tuning job with a validation set (Round 2)</p>
			<p class="calibre3">Please open the file on GitHub and look at the examples; they are single-turn interactions. The<a id="_idIndexMarker566" class="pcalibre pcalibre1 calibre6"/> user prompts, and the system responds. Each row looks like this:</p>
			<pre class="source-code">
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "Can I speak with a financial advisor?"}, {"role": "assistant", "content": "Sure, if you enjoy discussing your finances with a real human being instead of my charming digital self. Just give them a call."}]}</pre>			<p class="calibre3">A multi-turn conversation (without the JSON formatting) would look like this example from ChatGPT 4o:</p>
			<pre class="source-code-right">How do I open a new account?
You can open a new account by
filling out an application form and
providing the required documentation.
This process can be completed online
or at a branch office.Can I do this online?
Yes, you can complete the application
process online. Please visit our
website and follow the instructions
for opening a new account.How long does it take to openan account and start trading?
The account opening process typically
takes a few days if all provided
information and documentation
are correct. Once your account is
approved, you can begin trading immediately.</pre>			<p class="calibre3">The model can be trained using the same basic format with multi-turn conversational interactions. In this<a id="_idIndexMarker567" class="pcalibre pcalibre1 calibre6"/> OpenAI example, we highlighted the user and assistant responses that create a multi-turn interaction. Here is what it would look like when included in a training file:</p>
			<pre class="source-code">
{"messages": [{"role": "system", "content": "You are a happy assistant that puts a positive spin on everything."}, {"role": "<strong class="bold1">user</strong>", "content": "How do I open a new account?"}, {"role": "<strong class="bold1">assistant</strong>", "content": " You can open a new account by filling out an application form and providing the required documentation. This process can be completed online or at a branch office."},{"role": "<strong class="bold1">user</strong>", "content": "Can I do this online?"}, {"role": "<strong class="bold1">assistant</strong>", "content": "Yes, you can complete the application process online. Please visit our website and follow the instructions for opening a new account."}, {"role": "<strong class="bold1">user</strong>", "content": " How long does it take to open an account and start trading?"}, {"role": "<strong class="bold1">assistant</strong>", "content": "The account opening process typically takes a few days if all provided information and documentation are correct. Once your account is approved, you can begin trading immediately."}]}</pre>			<p class="calibre3">This example set is not complex. Suppose the use case calls for multi-turn or extended examples to showcase how the model should react. Each entry should reflect a coherent dialogue that teaches the model to handle context over several interactions.</p>
			<p class="calibre3">That is the input. Let’s review the output.</p>
			<h2 id="_idParaDest-174" class="calibre9"><a id="_idTextAnchor179" class="pcalibre pcalibre1 calibre6"/>Using the fine-tuned model</h2>
			<p class="calibre3">Once the fine-tuned model is ready, test it. You can see a <strong class="bold">Playground</strong> button on the bottom right of the fine-tuning <a id="_idIndexMarker568" class="pcalibre pcalibre1 calibre6"/>job. You can also go to <strong class="bold">Chat</strong> in the left tab and then select the name of the fine-tuning job.</p>
			<p class="calibre3">Optionally, there is a <strong class="bold">Compare</strong> button to manually test the model and compare it to previous model versions (or other models entirely). Be sure to copy the exact instructions in the <strong class="bold">SYSTEM</strong> field. We just clicked the <strong class="bold">Playground</strong> button to open the chat, selecting the fine-tuned model, as in <em class="italic">Figure 8</em><em class="italic">.7</em>.</p>
			<div><div><img src="img/B21964_08_07.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.7 – Selecting the fine-tuned job to interact with the new model</p>
			<p class="callout-heading">Gotcha</p>
			<p class="callout">We can’t do both the file retrieval demo (to incorporate the 100s of FAQs from the Alli demo) <em class="italic">and</em> fine-tune the model in the Playground. This is a current limitation. We will use this time to focus on fine-tuning improvements, knowing a production system can address this shortcoming.</p>
			<p class="calibre3">Because of this limitation, this focus is on learning about fine-tuning rather than fine-tuning the RAG model. Comparing outputs, the foundation model is wordy, and neither has specific results from our FAQs; the model must be trained with FAQS. Compare the results in <em class="italic">Table 8.2</em> with the trained FAQs.</p>
			<table id="table002-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Model</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Response</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">1) GPT-3.5 Turbo trained with </strong><strong class="bold">the FAQs</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">To lower your advisory fee, you can consider the following options:</p>
							<p class="calibre3">* Consolidating assets: The more you invest with us, the lower your advisory fee could be.</p>
							<p class="calibre3">* Grouping accounts together: You can also lower the advisory fee percentage for your immediate family members by grouping accounts together [1].</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">2) GPT-3.5-turbo-1105+ </strong><strong class="bold">fine-tuned</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">You should contact customer service for that. They can escalate to the appropriate department if necessary.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">3) GPT-4o No fine-tuning and no FAQs </strong><strong class="bold">as resources</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Optimizing advisory fees can lead to significant savings over time. Here are several strategies to consider:</p>
							<p class="calibre3">1. **Compare Advisors**: Research and compare fees among different advisors. Look for advisors with transparent fee structures.</p>
							<p class="calibre3">2. **Consider Fee-only Advisors**: Fee-only advisors charge a flat rate or <a id="_idIndexMarker569" class="pcalibre pcalibre1 calibre6"/>an hourly fee rather than a percentage of your assets. This can sometimes be more cost-effective.</p>
							<p class="calibre3">3. **Negotiate Fees**: Don’t be afraid to negotiate. Advisors might be willing to reduce their fees to retain you as a client.</p>
							<p class="calibre3">4. **Bundled Services**: Some advisors offer packaged services that might come at a lower total cost than à la carte services.</p>
							<p class="calibre3">5. **Review Fee Structure**, 6. **Use Robo-Advisors**, 7. **DIY Approach**, 8. **Regular Fee. (5 to 8 are truncated for brevity)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">4) GTP-3.5 1106 with fine-tuning </strong><strong class="bold">78 examples</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Negotiate<a id="_idIndexMarker570" class="pcalibre pcalibre1 calibre6"/> a lower fee or invest more money with me; I’m sure I can find a way to help you with that.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">5) Best match from 78 </strong><strong class="bold">fine-tuning examples</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">No question existed close to this question. Only one question even discussed advisory, and it was an unrelated question, “Can I pay Portfolio Advisory Service or other Alligiance-managed account fees using mobile check deposit?”</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">6) </strong><strong class="bold">Source Answer</strong></p>
							<p class="calibre3"><strong class="bold">FAQ 86. How can Iower my </strong><strong class="bold">advisory fee?</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">consider the benefits of consolidating assets. the more you invest with us, the lower your advisory fee could be. you can also lower the advisory fee percentage for your immediate family members (whether or not they live with you) by grouping accounts together. for additional details, please ask a Alligiance representative for details or view the fee aggregation policy and form.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 8.2 – Output for “How can I lower my advisory fee?” with different models</p>
			<p class="calibre3"><em class="italic">We must have the FAQs to offer specific business data</em>. Fine-tuning will only help present results in a particular way. Only the model (1) with the FAQs could match the source material. RAG (or, in this case, the proxy for RAG – File Search) can handle the factual data. The other models can hallucinate (2) or be long-winded (3). The fine-tuned model (4) was slightly sarcastic but couldn’t return a valid answer without the knowledge. It isn’t trained on the answer, as the closest example wasn’t close (5), and it can’t invent the facts from the source FAQ (6). The size of the result should be noted. Because training was with short responses, the model (5) returned short responses.</p>
			<p class="calibre3">Since ChatGPT-3.5 wants at least 10, if not 100, examples, <em class="italic">Round 3</em> will re-run the build with double the examples. Doubling examples is a typical strategy to increase quality by the same amount <a id="_idIndexMarker571" class="pcalibre pcalibre1 calibre6"/>as the last doubling. Ten was too small in this case, so now it is 20. In hindsight, this experiment should have started at 50. We used the exact simple system instructions. You need to copy and paste the instructions again when testing; they are ignored in the playground when uploading examples. Include this training set and reuse the same validation data:</p>
			<pre class="source-code">
Alli is a factual chatbot that is also sarcastic.</pre>			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl" class="pcalibre pcalibre1 calibre6">Training Data with 30 examples</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl</a>)</p>
			<p class="calibre3"><em class="italic">Figure 8</em><em class="italic">.8</em> shows the results of <em class="italic">Round 3</em>. We can now start to examine the metrics more closely.</p>
			<div><div><img src="img/B21964_08_08.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.8 – Improving the model with double the training examples (Round 3)</p>
			<p class="calibre3">We can explain a few more concepts with the validation data and then do one more round of training. Let’s review what the chart means:</p>
			<ul class="calibre7">
				<li class="calibre8">The red dot represents the end of an epoch, which is one round of training. Because the last example had 29 examples, one epoch was 29 tests long. Because it decided it needed three runs, it did 87 tests. The red dot represents the average validation loss across that group. We are progressing since the validation loss is decreasing, and the training loss is tending to zero.</li>
				<li class="calibre8">We still see many ups and downs along the way. This model compares the expected outcome to its generated outcome. Once it improves with suitable matches, the graph tends to zero. When there is a big difference, the graph shows jumps. The large validation loss still needs to be solved. It still needs to converge towards zero.</li>
				<li class="calibre8">This model is looking a little volatile compared to Round 1. I suspect the training data is too similar to the validation data, which is causing this issue. This would have to be reviewed and tested. A real solution might take dozens to hundreds of rounds of iteration.<p class="calibre3">Don't generalize from the following Boolean classifier visualization. Graphs<a id="_idIndexMarker572" class="pcalibre pcalibre1 calibre6"/> from simple Boolean classifiers (whether data is true or false, positive or negative sentiment, etc.) might not be helpful. If items are easy to classify, the graph will be like <em class="italic">Figure 8</em><em class="italic">.9</em>. Michael Cacic at <a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6">https://miha.academy/</a> provided this example. Only a little can be learned from this chart. This model is working well.</p></li>
			</ul>
			<div><div><img src="img/B21964_08_09.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.9 – A fine-tuning graph for a classifier task that is doing well</p>
			<ul class="calibre7">
				<li class="calibre8">For complex data, like the Round 3 results, it is hopeful that the trend will be toward zero and that validation loss will decrease. Since there was a lack of convergence in the early run, add <a id="_idIndexMarker573" class="pcalibre pcalibre1 calibre6"/>more varied examples to continue trending down. Improving the diversity of the validation examples (not done in this demo) would likely help.</li>
				<li class="calibre8">Refrain from relying only on the graph for complex data. Review results and score them for quality. We discussed this in <a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 4</em></a>, <em class="italic">Scoring Stories</em>, and continue discussing measuring and monitoring in <a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring </em><em class="italic">and Evaluation</em>.</li>
				<li class="calibre8">Remember, the goal is to improve the model’s reasoning, not to teach it knowledge. Use RAG for memory and scope. Use fine-tuning to hone how the model thinks and responds.</li>
			</ul>
			<p class="callout-heading">Be careful about non-enterprise data intrusions</p>
			<p class="callout">In instructions and<a id="_idIndexMarker574" class="pcalibre pcalibre1 calibre6"/> prompting, specify to use the data provided in RAG. This protects from pulling facts from the model that might confuse customers. Although “Alli” is the short name for the fictional financial services model example, hallucinations occurred when the instructions, “Only provide answers from the attached document,” were removed from the file attached model. During some additional research for the book, this model assumed Alli was <em class="italic">Ally</em>, a bank in Pennsylvania. This error will only be found in the field by monitoring logs. Customers will complain about these errors, but it would be tragic to find this out <em class="italic">after</em> your customer mailed a large check to the wrong address because the foundational model used some random address. Every model vendor is working on this problem. It will get better but still watch for it.</p>
			<p class="calibre3">Fine-tuning is well-suited for getting the style and tone right. Yes, good results can come from instructions, but fine-tuning is just that: it is fine; it is more granular and specific. <em class="italic">General</em> goals are in the prompts, while examples that could have been in the prompt can be moved to fine-tuning. These <em class="italic">specific</em> examples extend how the model should always respond. This is why the sarcastic example is so good. It was only trained on a few dozen examples, but it can <a id="_idIndexMarker575" class="pcalibre pcalibre1 calibre6"/>now use those examples to drive its personality. Another use of fine-tuning is for manipulating data and transforming information.</p>
			<h2 id="_idParaDest-175" class="calibre9"><a id="_idTextAnchor180" class="pcalibre pcalibre1 calibre6"/>Fine-tuning for structuring output</h2>
			<p class="calibre3">In cases where tables, lists, or other<a id="_idIndexMarker576" class="pcalibre pcalibre1 calibre6"/> formatting is essential to the results, feed the fine-tuning system with examples to give it an edge in providing structured output. This is perfect for those who deal with table data, like in the Wove use case. It is helpful for any structured data, even with the expense examples. It is also beneficial to train on the name: value pattern (e.g., Amount: $12.34). Fine-tuning can be used for integrations, where you move data from one system to another and specify the format for the input for the next step. You might need XML, JSON, CSV, colon-delimited, or other formats to ensure your downstream system can accept the input.</p>
			<p class="callout-heading">Tip for generating examples for fine-tuning</p>
			<p class="callout">ChatGPT can be used to generate examples to build a training model. Not only can it do the examples, but it can generate the structured format needed for the file. So, now ChatGPT is training itself. The output can be reviewed and tweaked.</p>
			<p class="calibre3">It also helps our tutorial to introduce another concept. You can instruct an LLM to create more examples. We call this <strong class="bold">synthetic data</strong>. This can be tried<a id="_idIndexMarker577" class="pcalibre pcalibre1 calibre6"/> in the Playground. Notice the context, tone, and data format:</p>
			<pre class="source-code">
I will provide you with three examples of structured data that represent the back-and-forth between a factual chatbot that is also sarcastic and the user. Please generate seven more examples in a similar tone, focused on financial services questions. {"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "How far is the Moon from Earth?"}, {"role": "assistant", "content": "Far. Like a quarter million miles. Or about how far you might drive in a lifetime."}]}</pre>			<p class="calibre3">More examples were provided; they are just truncated here. The model returned the results, and the next prompt was given to the model to make it easier to copy and paste the results. The prompt was:</p>
			<pre class="source-code">
merge these messages into one file-one line at a time</pre>			<p class="calibre3">It returned a single file, making copying much easier, with results like this:</p>
			<pre class="source-code">
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "How do I open a new account?"}, {"role": "assistant", "content": "Just fill out an application, provide your life history, and sacrifice a small goat. Kidding. No goats. But it is a lot of paperwork."}]}
{"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What is the interest rate on savings accounts?"}, {"role": "assistant", "content": "Interest rates on savings accounts are currently so low that you'd probably get more return from finding coins under your couch cushions."}]}</pre>			<p class="calibre3">Impressive. ChatGPT can help generate structured output but can’t generate factual information about my<a id="_idIndexMarker578" class="pcalibre pcalibre1 calibre6"/> business. It saves a lot of time. We can use this method to scale up test cases. We can manually review for quality, saving 90% or more of our effort.</p>
			<p class="calibre3">This is a tiny example. Transforming data to move between disparate systems has been an ongoing enterprise problem. This back-end process has various uses, including presenting data in a UI in a format or with a helpful structure for customers to interpret. The use cases in this space abound. But it will only be apparent when this problem strikes you. From my experience, it is not common. It is just critical when it comes up. Even though ChatGPT can generate data, it doesn’t guarantee quality.</p>
			<h2 id="_idParaDest-176" class="calibre9"><a id="_idTextAnchor181" class="pcalibre pcalibre1 calibre6"/>Generating data should still need a check and balance</h2>
			<p class="calibre3">You can use a variety of <a id="_idIndexMarker579" class="pcalibre pcalibre1 calibre6"/>methods to generate data. This synthetic data could be similar to what real humans might have done. Or it might not. This is a place where human-in-the-loop analysis can be valuable. A model can generate examples very quickly. It only took a few minutes with the LLM to create many examples. Even with the time to review the results, it was much easier than writing them by hand.</p>
			<p class="calibre3">You can do this with Google Sheets, Microsoft Excel, and third-party fine-tuning tools that support generation. A wealth of integrations are available to help with this process. Regardless of the tool, review results and decide whether to include the content in training or validation examples. You might accept them outright, edit them to make them better or reject them. Depending on the solution’s robustness, consider a workflow that scores results, as discussed in <a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 4</em></a>, <em class="italic">Scoring Stories</em>. Scoring tools can help evaluate what to keep, reject, and tweak. Then, plan a course of action to improve based on how you feel about the results. We see some options in <em class="italic">Table 8.3</em>.</p>
			<table id="table003-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Fine </strong><strong class="bold">Tuning Status</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Plan</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Happy </strong><strong class="bold">with results</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Do nothing</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Works well, but is expensive </strong><strong class="bold">or slow</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Chain a fine-tuned lighter model (GPT-3.5) on all of the completions of a more expensive model (GPT-4)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Results are </strong><strong class="bold">not consistent</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Chain a fine-tuned lighter model (GPT-3.5) on all of the best completions of a more expensive model (GPT-4)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Results are close to what I want but the style and tone </strong><strong class="bold">are off</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Manually edit examples to the desired quality, or edit the prompt to adjust results</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">I don’t have a model, or can’t create </strong><strong class="bold">one easily</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Fine-tune a model with manually generated high-quality examples</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 8.3 – Courses of action when tuning is not going as planned</p>
			<p class="calibre3">Even this part of fine-tuning can<a id="_idIndexMarker580" class="pcalibre pcalibre1 calibre6"/> undergo multiple care and feeding cycles. You might loop back around and find an even lighter model or something needing more editing. Iteration is fundamental to every step of the generative AI journey.</p>
			<p class="callout-heading">Spreadsheet user tips</p>
			<p class="callout">The format for fine-tuning has changed over time. Each model can use different formats. Just adapt the data to the model format. You can use a spreadsheet to maintain the source content and then use the tools in spreadsheets to build strings combining source content with the correct formatting, for example:</p>
			<p class="callout"><strong class="source-inline1">A1 cell = ' {"messages": [{"role": "system", "content": "Alli is a factual chatbot that is also sarcastic."}, {"role": "user", "</strong><strong class="source-inline1">content": "'</strong></p>
			<p class="callout"><strong class="source-inline1">B1 cell = </strong><strong class="source-inline1">question</strong></p>
			<p class="callout"><strong class="source-inline1">C1 cell = '"}, {"role": "assistant", "</strong><strong class="source-inline1">content": "'</strong></p>
			<p class="callout"><strong class="source-inline1">D1 contains the </strong><strong class="source-inline1">synthetic string</strong></p>
			<p class="callout"><strong class="source-inline1">E1 cell = ' "}]}'</strong></p>
			<p class="callout"><strong class="source-inline1">So F1 = A1 &amp; B1 &amp; C1 &amp; D1 &amp; E1 then </strong><strong class="source-inline1">export F1</strong></p>
			<p class="callout">Excel and Google Sheets have ChatGPT (and other LLM) integrations to generate synthetic data. Spreadsheet integration with ChatGPT has all kinds of uses. It helps this process and can improve personal productivity.</p>
			<p class="calibre3">One great trick is not rebuilding the <a id="_idIndexMarker581" class="pcalibre pcalibre1 calibre6"/>model from scratch each time examples are added. After reviewing the generated results and fixing some formatting errors, 49 more examples were incorporated from a separate file to add to the model. In total, there are now 78 examples and 20 test cases.</p>
			<p class="calibre3">Re-use the model from <em class="italic">Round 3</em>. The training will go faster. As shown in <em class="italic">Figure 8</em><em class="italic">.10,</em> pick the previous fine-tuned <a id="_idIndexMarker582" class="pcalibre pcalibre1 calibre6"/>model in the <code>Base Model</code> menu to create a revised fine-tuned model. You are picking up where you left off. Only upload the incrementally new rows in the data for <em class="italic">Round 4</em>.</p>
			<div><div><img src="img/B21964_08_10.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.10 – Appending to an existing fine-tuned base model to continue fine-tuning</p>
			<p class="calibre3">GitHub:<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl" class="pcalibre pcalibre1 calibre6"> 49 training examples</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl</a>)</p>
			<p class="calibre3">We can now view the training, which <a id="_idIndexMarker583" class="pcalibre pcalibre1 calibre6"/>shows the results from Round 4 in <em class="italic">Figure 8</em><em class="italic">.11</em>.</p>
			<div><div><img src="img/B21964_08_11.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.11 – The final fine-tuning run for ChatGPT-3.5 9 compared to ChatGPT-4o mini, including synthetic data (Round 4)</p>
			<p class="calibre3">Chat GPT 3.5 (on the top <a id="_idIndexMarker584" class="pcalibre pcalibre1 calibre6"/>of the image) was improved by adding more examples. At least 50 to 100 examples were suggested; this is in the middle of that range. Take the 78 examples, double the training set, extend the testing set to 20%, review and clean up overlapping concepts, and test again. See if the next round will get the<a id="_idIndexMarker585" class="pcalibre pcalibre1 calibre6"/> validation loss closer to zero. Looking at the results, it is better but not perfect. The slope of validation loss is trending down, but not as much as in more realistic data.</p>
			<p class="calibre3">The output for ChatGPT-4o mini with the same data is included for comparison. The training loss is almost zero. The validation loss is still high and only slightly trending down (the red dots). Because OpenAI changed the vertical scale (bad design!) look carefully to compare the results. The second chart is scale is 25% different and thus the data is better than from ChatGPT-3.5. Without more testing, it is hard to tell if this is acceptable for the data we trained it on.</p>
			<p class="calibre3">If the results are not good, try other techniques. Consider some of these expert moves:</p>
			<ul class="calibre7">
				<li class="calibre8">You can compare and test along the way. Each epoch generates a checkpoint. This file compares one checkpoint to another or even a different model. ChatGPT saves the last three checkpoints. <em class="italic">Figure 8</em><em class="italic">.12</em> zooms in on the checkpoints section. They are listed in the fine-tuning job and can then be selected, cut, and pasted into the chat, or mouse over them and jump directly into the playground using the link.</li>
			</ul>
			<div><div><img src="img/B21964_08_12.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.12 – Checkpoints can be directly opened in the playground</p>
			<ul class="calibre7">
				<li class="calibre8">Notice that the final checkpoint <a id="_idIndexMarker586" class="pcalibre pcalibre1 calibre6"/>was selected and copied to the clipboard. Clicking the <strong class="bold">Playground</strong> link on the first checkpoint opens it in the playground; a comparison model can be selected, as shown in <em class="italic">Figure 8</em><em class="italic">.13</em>. You can now paste the model path from the final checkpoint into the field as a shortcut.</li>
			</ul>
			<div><div><img src="img/B21964_08_13.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.13 – Model names can be pasted into the model select field even in a comparison</p>
			<ul class="calibre7">
				<li class="calibre8">Now, you can compare results from the two models. The demo won’t reveal any exciting results, but this method is helpful for comparisons with large data sets.</li>
				<li class="calibre8">Increase the default Epochs from 2 to 3 or 4 for a strict classifier. However, consider this only after it has enough examples.</li>
				<li class="calibre8">If the model is too loose, increase the epochs for additional training.</li>
				<li class="calibre8">In this last round, the training loss increased. When re-running this model in Chat GPT-4o mini, the loss was much better (closer to zero). Look at more and better data to stick with this model and decrease training loss. As mentioned, the data is very similar and at risk of overfitting. Use synonyms, introduce more variation, and insert or<a id="_idIndexMarker587" class="pcalibre pcalibre1 calibre6"/> delete words in the statement to scale up the variety and number of examples. The data scientists have far more approaches at their fingertips. These are too advanced for this book. But the intern knows the answer. Ask ChatGPT.<pre class="source-code">
How should I reduce training loss when building a fine-tuned LLM?</pre></li>			</ul>
			<p class="calibre3">Adding examples and expanding test cases will improve results. Continue to explore, grow test cases, improve <a id="_idIndexMarker588" class="pcalibre pcalibre1 calibre6"/>the quality of the examples, play with the parameters, and learn. The best resource in my journey, outside of ChatGPT itself, was a four-hour training masterclass from Mihael Cacic. It was the most valuable of all resources, and it is recommended (I am not compensated for this; I was just a student). It is perfect for product people. It is the right level for an introduction class. Check it out.</p>
			<p class="calibre3">Training:<a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6"> Miha’s training website</a> (<a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6">https://miha.academy/</a>)</p>
			<p class="calibre3">Entry Point, his company, also has tools that support speeding up the training process and experimenting with fine-tuning jobs across multiple LLMs. You can use Entry Point, connect to OpenAI and other LLM vendors, and never deal with the JSON format for fine-tuning. Keep this in mind: tools help reduce the complexity of model management. New tools are becoming available every day.</p>
			<p class="calibre3">Look at Vijay’s article for more on fine-tuning and the different types of losses. It discusses metrics, is a good resource, and only takes a few minutes to read.</p>
			<p class="calibre3">Article: <a href="https://medium.com/@penpencil.blr/what-is-the-difference-between-training-loss-validation-loss-and-evaluation-loss-c169ddeccd59" class="pcalibre pcalibre1 calibre6">Training vs. Validation Loss</a> by Vijay M (https://medium.com/@penpencil.blr/what-is-the-difference-between-training-loss-validation-loss-and-evaluation-loss-c169ddeccd59</p>
			<p class="calibre3">Having gone end to end with a fine-tuning model, there are other areas to explore besides conversational style and tone. In the enterprise, connecting to different data <a id="_idIndexMarker589" class="pcalibre pcalibre1 calibre6"/>sources to gather information and push results also exists. You will need function calling.</p>
			<h2 id="_idParaDest-177" class="calibre9"><a id="_idTextAnchor182" class="pcalibre pcalibre1 calibre6"/>Fine-tuning for function and tool calling</h2>
			<p class="calibre3">When passing data back and forth from existing systems, it is typical to conform to the other systems’ formats because these legacy systems are likely to stay the same for you. The most recent models <a id="_idIndexMarker590" class="pcalibre pcalibre1 calibre6"/>are getting better at matching the <code>tool_choice</code>, and it is set to <code>auto</code>. You can force this process by setting it to <code>required</code>, specifying a specific named function, or telling it <code>none</code> to disable it.</p>
			<p class="calibre3">There is little for us to do on the product side here. It is included for completeness. Of course, these interactions should be monitored to ensure the proper functions are called. This requires additional training data to differentiate between similar functions, making sure that data is mapped to the correct fields when there is a collection of similar fields (for example, total price, discounted price, itemized prices, tax, and other dollar values), and to verify that the model extracted data correctly (not too much, not too little, but just right).</p>
			<p class="calibre3">Product people should be aware of one neat trick: <strong class="bold">parallel function calling</strong>. This allows multiple queries to<a id="_idIndexMarker592" class="pcalibre pcalibre1 calibre6"/> be sent in parallel, dramatically reducing the response time with no additional model cost. <em class="italic">There is no such thing as a slow, good user interface</em>. People today are impatient.</p>
			<p class="calibre3">One gotcha. OpenAI suggests that SQL generation is “not perfectly reliable.” Therefore, use caution and extensive testing and monitoring. I have not had success building AI SQL generators from text input, but this will improve over time.</p>
			<p class="calibre3">Documentation: <a href="https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models" class="pcalibre pcalibre1 calibre6">Calling functions with chat models</a> (<a href="https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models" class="pcalibre pcalibre1 calibre6">https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models</a>)</p>
			<p class="calibre3">Of all the ways to use fine-tuning, plenty of tips can help with this process. We cover some of the critical items.</p>
			<h1 id="_idParaDest-178" class="calibre5"><a id="_idTextAnchor183" class="pcalibre pcalibre1 calibre6"/>Fine-tuning tips</h1>
			<p class="calibre3">You must care for and feed the fine-tuned set to improve training quality (based on the metrics or experience with certain test cases). Here is a summary of OpenAI’s suggestions for fine-tuning:</p>
			<ol class="calibre12">
				<li class="calibre8"><strong class="bold">Review existing examples for issues</strong>: You might have introduced style, logic, or grammar issues<a id="_idIndexMarker593" class="pcalibre pcalibre1 calibre6"/> into the dataset, including examples with errors. Review the material against how the model performed before and after adding the data. You can use the epoch checkpoints as a tool.</li>
				<li class="calibre8"><strong class="bold">Gather more examples to fill the gaps</strong>: Additional training examples might show the model how to address gaps in its abilities. It is always hard to say how much is too much.</li>
				<li class="calibre8"><strong class="bold">Include examples with errors</strong>: Sometimes, it is best to learn from the master. Let’s ask ChatGPT about including mistakes in fine-tuned examples:<pre class="source-code">
Should fine-tuning examples
include intentional errors
that might be expected
from real customers?
Yes, it's beneficial to include
intentional errors in fine-tuning
examples. This approach enhances
the model's robustness, making it
better equipped to handle the
kinds of mistakes real customers
might make, such as typos or
grammatical errors. By training
on these, the model can learn to
respond accurately even when
inputs aren't perfect. It prepares
the model for real-world
interactions, improving its
ability to correct, clarify, or
ignore errors as needed, ultimately
leading to a better user experience.</pre></li>				<li class="calibre8"><strong class="bold">Look for imbalance and the need for more diversity in data</strong>: Does the data set provide a range of examples? Refrain from biasing data with one kind of answer. It is not helpful to rephrase the same question. Think about the expense examples. Not just <a id="_idIndexMarker594" class="pcalibre pcalibre1 calibre6"/>data format but style, idiomatic language, lack of data, too much data, and even irrelevant data. Even the 78 sarcastic examples for the four rounds of testing were a little homogenous. This is something the team has to notice.</li>
			</ol>
			<p class="callout-heading">Imbalance example</p>
			<p class="callout">I had a case that puzzled me for a while. We had two primary tasks that a conversational assistant did. It did expenses and time reporting. However, both were needed in the same assistant. The training data was biased toward the expense assistant’s round numbers and needed the correct numbers in the time reporting model. While a customer might say “15 minutes,” “30 minutes,” or “an hour and 45 minutes” for a time record, most expenses are not “$15,” “$30,” or “$45”, so by overweighting on those round numbers in expenses it pushed understanding for the typical time units towards the expense model. This bias can be improved by using better data for the expense model and ensuring the time model has the right balance of examples.</p>
			<ol class="calibre12">
				<li value="5" class="calibre8"><strong class="bold">Match the training examples to expectations</strong>: If it is expected that most people will give the information needed to ask a question, fill out a form, or move forward, then training examples should mirror those examples.</li>
				<li class="calibre8"><strong class="bold">Validate the consistency of the examples when coming from multiple sources</strong>: Even humans are expected to disagree on specific values when labeling data. If one <a id="_idIndexMarker595" class="pcalibre pcalibre1 calibre6"/>person tags a company name as “The Business Center” and the other as “Business Center,” then the model can likely have similar issues.</li>
				<li class="calibre8">Training examples should be in the same format.</li>
				<li class="calibre8">Judge improvements based on previous improvements.</li>
				<li class="calibre8"><strong class="bold">Edge case issues take work to include</strong>: As a rule of thumb, expect a similar improvement for each doubling of quality training data. But it is more work to find the edge cases than the happy paths. Take the time to express those edge cases. It will make the fine-tuned model more robust. Edge cases could be in several attributes: length of the question, use of multiple languages in one question, multi-part complex questions, lots of chit chat with a small portion for the actual question, the use of data that is not well formatted or in a format not expected (military time, currencies with extra numbers), written words for numbers, or just plain wrong information. Judge this by comparing the testing results between the fully tuned model and one using one-half of the training data. Use this to judge future stepwise improvements.</li>
				<li class="calibre8"><strong class="bold">Specify and adjust the hyperparameters</strong>: Start with the defaults set by OpenAI. If the model doesn’t follow the training data, increase epochs by one or two. Notice how they were at five in the Wove case study coming up next. This is more typical for classification, entity, extraction, or structured parsing tasks. All of these have a known answer. With more wide-ranging model tasks, decrease the epochs by 1 or 2 to see if that improves diversity.</li>
				<li class="calibre8">If the model isn’t converging, increase<a id="_idIndexMarker596" class="pcalibre pcalibre1 calibre6"/> the <strong class="bold">learning rate</strong> (<strong class="bold">LR</strong>) multiplier. The graphs from the Wove case study are in the next section. <em class="italic">Figure 8</em><em class="italic">.5</em> shows this convergence issue, as does the Wove example, which is covered shortly. Only make small changes at one time. Here is some background:<p class="calibre3">Article: <a href="https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/" class="pcalibre pcalibre1 calibre6">Learning Rate</a> (<a href="https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/" class="pcalibre pcalibre1 calibre6">https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/</a>)</p></li>
				<li class="calibre8">One issue is overfitting. Mihael from Entry Point provided the example in <em class="italic">Figure 8</em><em class="italic">.14</em>, in which the validation loss continued to grow while the training loss was <a id="_idIndexMarker597" class="pcalibre pcalibre1 calibre6"/>acceptable. This is a classic overfitting example.</li>
			</ol>
			<div><div><img src="img/B21964_08_14.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.14 – An example of overfitting is shown with the increase in validation loss</p>
			<p class="calibre3">The analogy is studying for a test by memorizing the exact questions and answers from a practice test. Then, in the actual test, none of the questions are similar enough to allow the taker to answer correctly. Aligned too closely with the study material, fails to translate to answering correctly.</p>
			<ol class="calibre12">
				<li value="13" class="calibre8"><strong class="bold">Use a second model to verify a fine-tuned model</strong>: One approach is to use a second model to <a id="_idIndexMarker598" class="pcalibre pcalibre1 calibre6"/>test the first model to confirm results. The second model might be the same or completely different fine-tuned or off-the-shelf LLM. Set a quality threshold; if the AI answer fails, it might route the request to a human customer service agent. It takes some experience to figure this out.</li>
				<li class="calibre8">If, after all this work, the assistants’ style or tone needs to change, all of the examples don’t necessarily have to change. Consider tweaking the prompts to override the examples. If it is just a tweak, the fine-tuning is not going to waste; it is still helping give it the experience.</li>
			</ol>
			<p class="calibre3">This is a vast area for research, testing, and learning. This is only a start to ensure you can apply these skills at the<a id="_idIndexMarker599" class="pcalibre pcalibre1 calibre6"/> team level. We hope it is easy to appreciate how much the discussion impacts the quality of the user experience. Here is one more resource as a companion to the earlier OpenAI Fine-tuning documentation:</p>
			<p class="calibre3">Article: <a href="https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations" class="pcalibre pcalibre1 calibre6">ChatGPT Fine Tuning Documentation</a> (<a href="https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations</a>)</p>
			<p class="calibre3">We want to examine how everything learned about prompt engineering and fine-tuning works for the Wove use case.</p>
			<h1 id="_idParaDest-179" class="calibre5"><a id="_idTextAnchor184" class="pcalibre pcalibre1 calibre6"/>Wove case study, continued</h1>
			<p class="calibre3">In <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content is King,</em> the Wove case study on data cleansing for rate sheets used by freight forwarders was kicked off. They had to scrub the data before ingesting it to output a clean, unified view of all the rates from many carriers. Now, it is time to explore their <a id="_idIndexMarker600" class="pcalibre pcalibre1 calibre6"/>prompt engineering (we covered the basics in <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a>, <em class="italic">Prompt Engineering</em>) and fine-tuning efforts for this solution.</p>
			<h2 id="_idParaDest-180" class="calibre9"><a id="_idTextAnchor185" class="pcalibre pcalibre1 calibre6"/>Prompt engineering</h2>
			<p class="calibre3">They want the LLM to think like a<a id="_idIndexMarker601" class="pcalibre pcalibre1 calibre6"/> customer who does this step manually. They created the prompt for the spreadsheets during the ingestion process (this early version was shared with us to maintain the proprietary nature of their latest efforts):</p>
			<pre class="source-code">
You are an expert at table understanding. You will be given a snippet of text and a row number for the header row. Your task is to determine where the data for the table starts and what range of rows make up the header for the table. If the header has ambiguous columns (such as many of the same columns), there may be a row around the header row that can provide additional context. Include these in your range for the header if so. Your response should be in YAML format like this: (example truncated)</pre>			<p class="calibre3">Let’s review a few highlights from this prompt:</p>
			<ul class="calibre7">
				<li class="calibre8">It sets the stage for the persona to be adopted.</li>
				<li class="calibre8">It gives context for understanding tables.</li>
				<li class="calibre8">It explains the input (snippets of text and more details)</li>
				<li class="calibre8">It helps with some exceptions (ambiguous columns)</li>
				<li class="calibre8">It defined the response <a id="_idIndexMarker602" class="pcalibre pcalibre1 calibre6"/>format (<strong class="bold">Yet Another Markup </strong><strong class="bold">Language</strong> (<strong class="bold">YAML</strong>))</li>
			</ul>
			<p class="calibre3">Great job following the <a id="_idIndexMarker603" class="pcalibre pcalibre1 calibre6"/>guidance! Honestly, they were already following this same advice. They use a lot of fine-tuned models, so examples don’t appear in their prompts. One small thing: where is the idea of an emotive prompt? They should explore if that helps their quality. We can talk to them about that!</p>
			<h2 id="_idParaDest-181" class="calibre9"><a id="_idTextAnchor186" class="pcalibre pcalibre1 calibre6"/>Fine-Tuning for Wove</h2>
			<p class="calibre3">As discussed in the last chapter, Wove has a collection of models to perform specific tasks in cleaning the<a id="_idIndexMarker604" class="pcalibre pcalibre1 calibre6"/> spreadsheet data. The fine-tuning process adapts generic models to improve the understanding of rate spreadsheets critical to Wove’s customers. It is similar to teaching a 5th grader a new subject. A 5th grader knows the basic language and can answer simple questions—they might even be into ships and trains and understand the concept of moving goods, but no 5th grader has ever seen a rate sheet.</p>
			<p class="calibre3">We know that a model can only provide so much. ChatGPT recommends starting with prompt engineering before going to fine-tuning. In conversations, Kevin Mullet suggested an excellent way to remember this: “<em class="italic">First</em>, figure out what to say, <em class="italic">then</em> figure out how to say it.” We have shown how this can help, but this extra effort is needed.</p>
			<p class="calibre3">Here are some checks that Wove does to verify that the data is being processed correctly. This covers data quality, prompt quality, and fine-tuning:</p>
			<ul class="calibre7">
				<li class="calibre8">They manually review the interpretation of the data to look for hallucinations.</li>
				<li class="calibre8">They look for validation and training loss converging to zero. They run additional evaluation data sets using OpenAI Evals to ensure that models pass established tests. OpenAI provides a collection of templates to evaluate models using standard measures. The evals allow judgment of how different model versions and prompts impact usage. Here is a good introduction: <p class="calibre3">Article: <a href="https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals" class="pcalibre pcalibre1 calibre6">Getting Started with OpenAI Evals</a> (<a href="https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals" class="pcalibre pcalibre1 calibre6">https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals</a>)</p></li>
				<li class="calibre8">They use multiple steps in a chain and different models to focus on doing one thing well. They<a id="_idIndexMarker605" class="pcalibre pcalibre1 calibre6"/> regularly revisit models to adopt newer and cheaper ones.</li>
				<li class="calibre8">In one of the models, they do location mapping and use over 600 training examples. 10% is for validation data, but for some models, they bump up to 20%, depending on how expensive it is to generate the data.</li>
				<li class="calibre8">Their training graph in <em class="italic">Figure 8</em><em class="italic">.15</em> looks good. It is converging to zero for training loss. They have a validation test set that works well and uses what appear to be default parameters.</li>
			</ul>
			<div><div><img src="img/B21964_08_15.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.15 – An example of a training model converging</p>
			<ul class="calibre7">
				<li class="calibre8">Initially, they had learning rate issues. In machine learning and statistics, the learning rate is a<a id="_idIndexMarker606" class="pcalibre pcalibre1 calibre6"/> tuned parameter in an optimization algorithm that determines the iteration step size while moving toward a minimum loss function.</li>
			</ul>
			<p class="calibre3">Even if trained again, it never quite gets to the optimal point. Sometimes, there is poor convergence or overfitting, as discussed. <em class="italic">Figure 8</em><em class="italic">.16</em> shows an earlier run showing a lack of convergence.</p>
			<div><div><img src="img/B21964_08_16.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.16 – An example of an early Wove training model that didn’t converge</p>
			<p class="calibre3">If there is bouncing and the lines do not quite converge, retrain with a lower learning rate. Convergence will be much slower if the initial weights are too high. To put models in perspective, the four rounds for the sarcastic chatbot experiment ran with less than 5000 training tokens for each round. The Wove model above used over 500,000 training tokens for this one piece of their solution. Bigger doesn’t guarantee convergence.</p>
			<p class="calibre3">Our friends at Wove have<a id="_idIndexMarker607" class="pcalibre pcalibre1 calibre6"/> a few more tips for those ingesting spreadsheets:</p>
			<ul class="calibre7">
				<li class="calibre8">They use expensive models to fine-tune cheaper models. For example, Anthropic’s Opus 3 Claude is (at this time of writing) about 30 to 50 times more costly than OpenAI 3.5. Opus 3 is 15$/1M input and 75$/1M output tokens versus ChatGPT 3.5 turbo-0125 at $0.50/1M input and $1.50/1M output tokens. This is an essential point for the product team. You want to get the best bang for the buck, especially when dealing with customers who will use the model more often if it provides excellent service. They found significantly better quality from fine-tuning ChatGPT 4.0 than earlier 3.5 models. Chat GPT-4o mini is now being incorporated.</li>
				<li class="calibre8">They started using a higher learning rate, which they could reduce when they made significant steps. The amount of data impacts the learning rate steps (e.g., 0.5, 0.1, and 0.01). This can be tweaked based on the size of the data set and other factors. The goal is to refine so the training loss decreases in an orderly fashion without wild swings or divergence.</li>
				<li class="calibre8">Working around the context window, they started with a 4K context window and grew to support 16K. They can preprocess data and use other tools to deal with smaller chunks. Even at 16K, this is small for handling large spreadsheets.</li>
				<li class="calibre8"><strong class="bold">Make sure the data is accurate</strong>: With good input data, success is more likely. If the trained data isn’t tagged correctly or has missing data, the data team will have issues. This real example is for an early Wove’s table end detection version. You <a id="_idIndexMarker608" class="pcalibre pcalibre1 calibre6"/>can see this in the chart bouncing all over the place compared to earlier examples. You don’t see a convergence.</li>
			</ul>
			<p class="calibre3">We can look at one example of a hallucination and how they corrected it in the part of the flow where they took the text version of the spreadsheet (left column) and asked ChatGPT to define (understand) the row’s context (middle column). This is <em class="italic">Step 1</em>. Then, they edited this output, completing the process with the final output (right column) shown in <em class="italic">Table 8.4</em>.</p>
			<table id="table004-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Input File</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Intermediary output </strong><strong class="bold">from ChatGPT</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Final normalized file </strong><strong class="bold">from ChatGPT</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">The table on the sheets “Rate Sheet”, is from the VN to US UPDATE file.</p>
							<p class="calibre3">The table has these columns:
- id: 0</p>
							<p class="calibre3">  name: POL</p>
							<p class="calibre3">  Examples:</p>
							<p class="calibre3">  - DA NANG, VIETNAM</p>
							<p class="calibre3">  - HO CHI MINH CITY, VIETNAM</p>
							<p class="calibre3">  - HAIPHONG, VIETNAM</p>
							<p class="calibre3">  - VUNG TAU, VIETNAM</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Purpose: This table provides ocean freight rates and details from various ports in Vietnam to destination in the United States, carriers and services, valid for a certain date range.
columns:</p>
							<p class="calibre3">-   id: 0</p>
							<p class="calibre3">  name: POL</p>
							<p class="calibre3">  description: The port of loading in Vietnam, such as De NANG, HAIPHONG, QUI NHON, or VUNG TAU.</p>
							<p class="calibre3">examples:</p>
							<p class="calibre3">  - DA NANG, VIETNAM</p>
							<p class="calibre3">  - HAIPHONG, VIETNAM</p>
							<p class="calibre3">  - VUNG TAU, VIETNAM</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">carrier: 7</p>
							<p class="calibre3">service_line: 4</p>
							<p class="calibre3">origin: 0</p>
							<p class="calibre3">origin_country: Vietnam</p>
							<p class="calibre3">origin_via: null</p>
							<p class="calibre3">origin_via_country: null</p>
							<p class="calibre3">destination: 1</p>
							<p class="calibre3">destination_country: United States</p>
							<p class="calibre3">destination_via: 2</p>
							<p class="calibre3">destination_via_county: United States</p>
							<p class="calibre3">loading_port: null</p>
							<p class="calibre3">loading_port_country: null</p>
							<p class="calibre3">unloading_port: null</p>
						</td>
					</tr>
				</tbody>
			</table>
			<table id="table005-3" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Input File</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Intermediary output </strong><strong class="bold">from ChatGPT</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Final normalized file </strong><strong class="bold">from ChatGPT</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">- id: 2</p>
							<p class="calibre3">  name: Dest (Via Port)</p>
							<p class="calibre3">  examples:</p>
							<p class="calibre3">  - OAKLAND, CA</p>
							<p class="calibre3">  - NORFOLK, VA</p>
							<p class="calibre3">  - LOS ANGELES, CA</p>
							<p class="calibre3">  - SAVANNAH, GA</p>
							<p class="calibre3">VANCOUVER, CANADA</p>
							<p class="calibre3">  - None</p>
							<p class="calibre3">  - TACOMA, WA</p>
							<p class="calibre3">  - BALTIMORE, MD</p>
							<p class="calibre3">  - CHARLESTON, SC</p>
							<p class="calibre3">  - NEW YORK, NY</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">- id: 1</p>
							<p class="calibre3">  name: Destination</p>
							<p class="calibre3">  description: The destination city and state in the United States, such as LONG BEACH, CA, SEATTLE, WA, or CLEVELAND, OH</p>
							<p class="calibre3">examples:</p>
							<p class="calibre3">  - ATLANTA, GA</p>
							<p class="calibre3">  - PITTSBURGH, PA</p>
							<p class="calibre3">  - CHARLOTTE, NC</p>
							<p class="calibre3">  - CLEVELAND, OH</p>
							<p class="calibre3">- id: 2</p>
							<p class="calibre3">  name: Dest (via Port)</p>
							<p class="calibre3">  description: The port in the United States that the shipment will go to reaching its final destination, such as NORFOLK, VA, SEATTLE,WA or LOS ANGELES, CA. Can also be “None” if the shipping direct to the destination.</p>
							<p class="calibre3">examples:</p>
							<p class="calibre3">  - NORFOLK, VA</p>
							<p class="calibre3">  - SAVANNAH, GA</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">unloading_port_country: null</p>
							<p class="calibre3">effective_date: 8</p>
							<p class="calibre3">expiry_date: 9</p>
							<p class="calibre3">container_dry_or_reefer: null</p>
							<p class="calibre3">commodity: null</p>
							<p class="calibre3">rates:</p>
							<p class="calibre3">  - id: 10</p>
							<p class="calibre3">    currency: null</p>
							<p class="calibre3">    type: total</p>
							<p class="calibre3">    container_size: “20ft”</p>
							<p class="calibre3">  - id: 11</p>
							<p class="calibre3">    currency: null</p>
							<p class="calibre3">    type: total</p>
							<p class="calibre3">    container_size: “40ft”</p>
							<p class="calibre3">  - id: 12</p>
							<p class="calibre3">    currency: null</p>
							<p class="calibre3">    type: total</p>
							<p class="calibre3">    container_size: “40ft_hc”</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 8.4 – Wove file improvement steps (some data are truncated)</p>
			<p class="calibre3">The table shows the description of the destination, aka dest (via port), generated in the middle column: “The port in<a id="_idIndexMarker609" class="pcalibre pcalibre1 calibre6"/> the United States that the shipment will go…”. However, the data includes Vancouver, Canada. Although the destination is always the US, the port it goes via might be outside the US.</p>
			<p class="calibre3">To improve the model, this hallucination needs to be corrected. It could be decided that the correct answer is to edit this to be “North America,” or better is to remove the “in the United States” entirely, making the description more generic. This means that the output file in the next step also needs correction. The <code>destination_via_country</code> field will be changed from United States to <code>null</code>. This file on the right is a second round of ChatGPT generation, creating the unified model that makes all the spreadsheet data a consistent, normalized output. It is vital to catch these errors. With this final output file, they re-run the test data to see whether the quality improves.</p>
			<p class="calibre3">Overall, this fine-tuning process <a id="_idIndexMarker610" class="pcalibre pcalibre1 calibre6"/>requires many iterations on the prompts, editing of the tags, and evaluating against their test data. We can’t expose all of Wove’s secret sauce, but hopefully, this gives a sense. A modeler’s work is never done. Although ongoing effort might be reduced, work will not be done. Format changes can occur, including new vendors, normalizations, better, cheaper, and faster models, and everyone’s favorite, bugs will require rework. The point is to be involved and invested in these steps to ensure quality. Readers can imagine the next steps for Wove once all this data is normalized and available. Customers will want to ask questions about the best route based on shipping characteristics. They will not want to pour through even a normalized sheet of rates.</p>
			<p class="calibre3">This is an exciting use case because it starts as a backend solution, still needs product understanding and feedback to be successful, and will likely lead to even more UX efforts when (inevitability) a customer-facing chat experience will converse with customers to help shop rates. Product and UX efforts will be needed there.</p>
			<p class="calibre3">Wove used a series of models to understand the complexities of tables. Picking and chaining suitable models is part of the prompt engineering and fine-tuning process.</p>
			<h1 id="_idParaDest-182" class="calibre5"><a id="_idTextAnchor187" class="pcalibre pcalibre1 calibre6"/>Summary</h1>
			<p class="calibre3">Fine-tuning is the most technical piece of this book. With this little glimpse into this world, there is much to cover. Your data scientists and engineers will go deeper. When building production-ready systems, mix and match fine-tuned and generic models with internal software and third-party tools to balance speed of delivery, price, and performance (recall the saying, <em class="italic">cheap, fast, or good, choose two</em>). Innovative solutions have workflow steps that allow the solution to bail out if the AI isn’t performing, use a function to solve or address a specific problem, or use a more deterministic element to provide a robust solution. Injecting the suitable model and prompts for the correct part of a use case is one of the most critical decisions. Do this work before embarking on the fine-tuning approach.</p>
			<p class="calibre3">Contribute to the process by helping define and improve these task flows through use case expertise, editing and improving prompts, creating, verifying, and editing fine-tuning examples, and monitoring if changes are moving the solution in the right direction. Go forth and tune!</p>
			<p class="calibre3"><a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 9</em></a>, <em class="italic">Guidelines and Heuristics,</em> will cover guidelines and heuristics to support prompting and fine-tuning efforts based on well-documented techniques in the design community to help explain conversational AI’s usability.</p>
			<h1 id="_idParaDest-183" class="calibre5"><a id="_idTextAnchor188" class="pcalibre pcalibre1 calibre6"/>References</h1>
			<table id="table006-1" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div><div><img src="img/B21964_08_QR.jpg" alt="" role="presentation" class="calibre4"/>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The links, book recommendations, and GitHub files in this chapter are posted on the reference page.</p>
							<p class="calibre3">Web Page: <a href="https://uxdforai.com/references#C8" class="pcalibre pcalibre1 calibre6">Chapter 8 References</a> (<a href="https://uxdforai.com/references#C8" class="pcalibre pcalibre1 calibre6">https://uxdforai.com/references#C8</a>)</p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>