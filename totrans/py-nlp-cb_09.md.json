["```py\n    from transformers import (\n        pipeline, BertForQuestionAnswering, BertTokenizer)\n    import torch\n    ```", "```py\n    device = torch.device(\"cuda\" if torch.cuda.is_available() \n        else \"cpu\")\n    qa_model = BertForQuestionAnswering.from_pretrained(\n        'bert-large-uncased-whole-word-masking-finetuned-squad',\n        device_map=device)\n    qa_tokenizer = BertTokenizer.from_pretrained(\n        'bert-large-uncased-whole-word-masking-finetuned-squad',\n        device=device)\n    ```", "```py\n    question_answer_pipeline = pipeline(\n        \"question-answering\", model=qa_model,\n        tokenizer=qa_tokenizer)\n    ```", "```py\n    context = \"The cat had no business entering the neighbors garage, but she was there to help. The neighbor, who asked not to be identified, said she didn't know what to make of the cat's behavior. She said it seemed like it was trying to get into her home, and that she was afraid for her life. The neighbor said that when she went to check on her cat, it ran into the neighbor's garage and hit her in the face, knocking her to the ground.\"\n    ```", "```py\n    question = \"Where was the cat trying to enter?\"\n    result = question_answer_pipeline(question=question, \n        context=context)\n    ```", "```py\n    print(result)\n    ```", "```py\n{'score': 0.25, 'start': 33, 'end': 54, 'answer': 'the neighbors garage,'}\n```", "```py\n    print(result['answer'])\n    ```", "```py\nthe neighbors garage,\n```", "```py\n    question = \"What did the cat do after entering the garage\"\n    result = question_answer_pipeline(\n        question=question, context=context)\n    print(result['answer'])\n    ```", "```py\nhit her in the face, knocking her to the ground.\n```", "```py\npython -m deeppavlov install kbqa_cq_en\n```", "```py\n    from deeppavlov import build_model\n    ```", "```py\n    kbqa_model = build_model('kbqa_cq_en', download=True)\n    ```", "```py\n    result = kbqa_model(['What is the capital of Egypt?', \n        'Who is Bill Clinton\\'s wife?'])\n    ```", "```py\n    [['Cairo', 'Hillary Clinton']]\n    ```", "```py\n    import os\n    from haystack.document_stores import InMemoryDocumentStore\n    from haystack.nodes import BM25Retriever, FARMReader\n    from haystack.pipelines import ExtractiveQAPipeline\n    from haystack.pipelines.standard_pipelines import( \n        TextIndexingPipeline)\n    from haystack.utils import (fetch_archive_from_http, \n        print_answers)\n    ```", "```py\n    doc_dir = \"data/got_dataset\"\n    fetch_archive_from_http(\n        url=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip\",\n        output_dir=doc_dir,\n        )\n    files_to_index = [doc_dir + \"/\" + f for f in os.listdir(\n        doc_dir)]\n    print(len(files_to_index))\n    183\n    ```", "```py\n    document_store = InMemoryDocumentStore(use_bm25=True)\n    indexing_pipeline = TextIndexingPipeline(document_store)\n    indexing_pipeline.run_batch(file_paths=files_to_index)\n    ```", "```py\n    retriever = BM25Retriever(document_store=document_store)\n    reader = FARMReader(\n        model_name_or_path=\"deepset/roberta-base-squad2\",\n        use_gpu=True)\n    ```", "```py\n        pipe = ExtractiveQAPipeline(reader, retriever)\n        prediction = pipe.run(\n            query=\"Who is the father of Arya Stark?\",\n            params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n        )\n        ```", "```py\n    print_answers(prediction, details=\"all\")\n    'Query: Who is the father of Arya Stark?'\n    'Answers:'\n    [<Answer {'answer': 'Eddard',\n    'type': 'extractive',\n    'score': 0.993372917175293,\n    'context': \"s Nymeria after a legendary warrior queen. She travels with her father, Eddard, to King's Landing when he is made Hand of the King. Before she leaves,\", 'offsets_in_document': [{'start': 207, 'end': 213}], 'offsets_in_context': [{'start': 72, 'end': 78}], 'document_ids': ['9e3c863097d66aeed9992e0b6bf1f2f4'], 'meta': {'_split_id': 3}}>,\n    <Answer {'answer': 'Ned',\n    'type': 'extractive',\n    'score': 0.9753613471984863,\n    'context': \"k in the television series.\\n\\n====Season 1====\\nArya accompanies her father Ned and her sister Sansa to King's Landing. Before their departure, Arya's h\", 'offsets_in_document': [{'start': 630, 'end': 633}], 'offsets_in_context': [{'start': 74, 'end': 77}], 'document_ids': ['7d3360fa29130e69ea6b2ba5c5a8f9c8'], 'meta': {'_split_id': 10}}>,\n    <Answer {'answer': 'Lord Eddard Stark',\n    'type': 'extractive',\n    'score': 0.9177322387695312,\n    'context': 'rk daughters.\\n\\nDuring the Tourney of the Hand to honour her father Lord Eddard Stark, Sansa Stark is enchanted by the knights performing in the event.', 'offsets_in_document': [{'start': 280, 'end': 297}], 'offsets_in_context': [{'start': 67, 'end': 84}], 'document_ids': ['5dbccad397381605eba063f71dd500a6'], 'meta': {'_split_id': 3}}>,\n    <Answer {'answer': 'Ned',\n    'type': 'extractive',\n    'score': 0.8396496772766113,\n    'context': \" girl disguised as a boy all along and is surprised to learn she is Arya, Ned Stark's daughter. After the Goldcloaks get help from Ser Amory Lorch and\", 'offsets_in_document': [{'start': 848, 'end': 851}], 'offsets_in_context': [{'start': 74, 'end': 77}], 'document_ids': ['257088f56d2faba55e2ef2ebd19502dc'], 'meta': {'_split_id': 31}}>,\n    <Answer {'answer': 'King Robert',\n    'type': 'extractive',\n    'score': 0.6922298073768616,\n    'context': \"en refuses to yield Gendry, who is actually a bastard son of the late King Robert, to the Lannisters.  The Night's Watch convoy is overrun and massacr\", 'offsets_in_document': [{'start': 579, 'end': 590}], 'offsets_in_context': [{'start': 70, 'end': 81}], 'document_ids': ['4d51b1876e8a7eac8132b97e2af04401'], 'meta': {'_split_id': 4}}>]\n    ```", "```py\n source). There are techniques to generate an abstractive answer too, which is more readable by end users compared to an extractive one.\n```", "```py\n    from datasets import load_dataset\n    from haystack.document_stores import InMemoryDocumentStore\n    from haystack.nodes import (\n        BM25Retriever, PromptNode,\n        PromptTemplate, AnswerParser)\n    from haystack.pipelines import Pipeline\n    ```", "```py\n    dataset = load_dataset(\"bilgeyucel/seven-wonders\", \n        split=\"train\")\n    document_store = InMemoryDocumentStore(use_bm25=True)\n    document_store.write_documents(dataset)\n    retriever = BM25Retriever(document_store=document_store)\n    ```", "```py\n    rag_prompt = PromptTemplate(\n        prompt=\"\"\"Synthesize a comprehensive answer from the following text for the given question.\n            Provide a clear and concise response that summarizes the key points and information presented in the text.\n            Your answer should be in your own words and be no longer than 50 words.\n            \\n\\n Related text: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n        output_parser=AnswerParser(),\n    )\n    prompt_node = PromptNode(\n        model_name_or_path=\"google/flan-t5-large\",\n        default_prompt_template=rag_prompt, use_gpu=True)\n    ```", "```py\n    pipe = Pipeline()\n    pipe.add_node(component=retriever, name=\"retriever\", \n        inputs=[\"Query\"])\n    pipe.add_node(component=prompt_node,\n        name=\"prompt_node\", inputs=[\"retriever\"])\n    ```", "```py\n    output = pipe.run(query=\"What is the Great Pyramid of Giza?\")\n    print(output[\"answers\"][0].answer)\n    output = pipe.run(query=\"Where are the hanging gardens?\")\n    print(output[\"answers\"][0].answer)\n    ```", "```py\nThe Great Pyramid of Giza was built in the early 26th century BC during a period of around 27 years.[3]\nThe Hanging Gardens of Semiramis are the only one of the Seven Wonders for which the location has not been definitively established.\n```", "```py\n    from transformers import pipeline\n    ```", "```py\n    passage = \"The color of animals is by no means a matter of chance; it depends on many considerations, but in the majority of cases tends to protect the animal from danger by rendering it less conspicuous. Perhaps it may be said that if coloring is mainly protective, there ought to be but few brightly colored animals. There are, however, not a few cases in which vivid colors are themselves protective. The kingfisher itself, though so brightly colored, is by no means easy to see. The blue harmonizes with the water, and the bird as it darts along the stream looks almost like a flash of sunlight.\"\n    passage_length = len(passage.split(' '))\n    pipeline_instance = pipeline(\"summarization\", model=\"t5-large\")\n    ```", "```py\n    pipeline_result = pipeline_instance(\n        passage, max_length=passage_length)\n    ```", "```py\n    result = pipeline_result[0][\"summary_text\"]\n    print(result)\n    ```", "```py\nthe color of animals is by no means a matter of chance; it depends on many considerations . in the majority of cases, coloring tends to protect the animal from danger . there are, however, not a few cases in which vivid colors are themselves protective .\n```", "```py\nfrom transformers import pipeline\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npassage = \"The color of animals is by no means a matter of chance; it depends on many considerations, but in the majority of cases tends to protect the animal from danger by rendering it less conspicuous. Perhaps it may be said that if coloring is mainly protective, there ought to be but few brightly colored animals. There are, however, not a few cases in which vivid colors are themselves protective. The kingfisher itself, though so brightly colored, is by no means easy to see. The blue harmonizes with the water, and the bird as it darts along the stream looks almost like a flash of sunlight.\"\n```", "```py\npipeline_instance = pipeline(\"summarization\", \n    model=\"facebook/bart-large-cnn\", device=device)\npipeline_result = pipeline_instance(passage, \n    max_length=passage_length)\nresult = pipeline_result[0][\"summary_text\"]\nprint(result)\nThe color of animals is by no means a matter of chance; it depends on many considerations, but in the majority of cases tends to protect the animal from danger by rendering it less conspicuous. There are, however, not a few cases in which vivid colors are themselves protective. The blue harmonizes with the water, and the bird as it darts along the stream looks almost like a flash of sunlight.\n```", "```py\npipeline_instance = pipeline(\"summarization\", \n    model=\"google/pegasus-large\", device=device)\npipeline_result = pipeline_instance([passage, passage], \n    max_length=passage_length)\nresult = pipeline_result[0][\"summary_text\"]\nprint(result)\nPerhaps it may be said that if coloring is mainly protective, there ought to be but few brightly colored animals.\n```", "```py\n    import torch\n    from transformers import T5Tokenizer, T5ForConditionalGeneration\n    ```", "```py\n    device = torch.device(\"cuda\" if torch.cuda.is_available() \n        else \"cpu\")\n    tokenizer = T5Tokenizer.from_pretrained(\n        't5-small', legacy=False, device=device)\n    model = T5ForConditionalGeneration.from_pretrained(\n        't5-small', return_dict=True, device_map=device)\n    ```", "```py\n    premise = \"The corner coffee shop serves the most awesome coffee I have ever had.\"\n    hypothesis = \"I love the coffee served by the corner coffee shop.\"\n    ```", "```py\n    input_ids = tokenizer(\n        \"mnli premise: \" + premise + \" hypothesis: \" + hypothesis,\n        return_tensors=\"pt\").input_ids\n    entailment_ids = model.generate(input_ids.to(device), \n        max_new_tokens=20)\n    ```", "```py\n    prediction = tokenizer.decode(\n        entailment_ids[0], skip_special_tokens=True, device=device)\n    print(prediction)\n    ```", "```py\nentailment\n```", "```py\npremise = [\"The corner coffee shop serves the most awesome coffee I have ever had.\", \"The corner coffee shop serves the most awesome coffee I have ever had.\"]\nhypothesis = [\"I love the coffee served by the corner coffee shop.\", \"I find the coffee served by the corner coffee shop too bitter for my taste.\"]\n```", "```py\npremises_and_hypotheses = [f\"mnli premise: {pre} \n    hypothesis: {hyp}\" for pre, hyp in zip(premise, hypothesis)]\ninput_ids = tokenizer(\n    text=premises_and_hypotheses, padding=True,\n    return_tensors=\"pt\").input_ids\n```", "```py\nentailment_ids = model.generate(input_ids.to(device), \n    max_new_tokens=20)\nfor _tensor in entailment_ids:\n    entailment = tokenizer.decode(_tensor,\n        skip_special_tokens=True, device=device)\n    print(entailment)\n```", "```py\n    import numpy as np\n    import torch\n    from lime.lime_text import LimeTextExplainer\n    from transformers import pipeline\n    ```", "```py\n    device = torch.device(\n        \"cuda\" if torch.cuda. is_available() else \"cpu\")\n    roberta_pipe = pipeline(\n        \"sentiment-analysis\",\n        model=\"siebert/sentiment-roberta-large-english\",\n        tokenizer=\"siebert/sentiment-roberta-large-english\",\n        top_k=1,\n        device=device\n    )\n    ```", "```py\n    sample_text = \"I really liked the Oppenheimer movie and found it truly entertaining and full of substance.\"\n    np.set_printoptions(suppress = True,\n        formatter = {'float_kind':'{:f}'.format},\n        precision = 2)\n    ```", "```py\n    def predict_prob(texts):\n        preds = roberta_pipe(texts)\n        preds = np.array([\n            [label[0]['score'], 1 - label[0]['score']]\n            if label[0]['label'] == 'NEGATIVE'\n            else [1 - label[0]['score'], label[0]['score']]\n            for label in preds\n        ])\n        return preds\n    ```", "```py\n    explainer = LimeTextExplainer(\n        class_names=['NEGATIVE', 'POSITIVE'])\n    exp = explainer.explain_instance(\n        text_instance=sample_text,\n        classifier_fn=predict_prob)\n    ```", "```py\n    original_prediction = predict_prob(sample_text)\n    print(original_prediction)\n    ```", "```py\n[[0.001083 0.998917]]\n```", "```py\n    print(np.array(exp.as_list()))\n    ```", "```py\n[['liked' '0.02466976195824297']\n ['entertaining' '0.023293546246506702']\n ['and' '0.018718510660163126']\n ['truly' '0.015312955730851004']\n ['Oppenheimer' '-0.012689413190611268']\n ['substance' '0.011282896692531665']\n ['of' '-0.007935237702088416']\n ['movie' '0.00665836523527015']\n ['it' '0.004033408096240486']\n ['found' '0.003214157926470171']]\n```", "```py\n    modified_text = \"I found the Oppenheimer movie very slow, boring and veering on being too scientific.\"\n    ```", "```py\n    new_prediction = predict_prob(modified_text)\n    print(new_prediction)\n    ```", "```py\n[[0.999501 0.000499]]\n```", "```py\n    exp = explainer.explain_instance(\n        text_instance=modified_text,\n        classifier_fn=predict_prob)\n    print(np.array(exp.as_list()))\n    ```", "```py\n[['boring' '-0.1541527292742657']\n ['slow' '-0.13677434672789646']\n ['too' '-0.07536450832681185']\n ['veering' '-0.06154593708589755']\n ['Oppenheimer' '-0.021333762714731672']\n ['found' '0.015601753307753232']\n ['movie' '0.011810474276051267']\n ['I' '0.01014260838624105']\n ['the' '-0.008070326804220167']\n ['scientific' '-0.006083605323956207']]\n```", "```py\n    exp = explainer.explain_instance(text_instance=sample_text,\n        classifier_fn=predict_prob)\n    _ = exp.as_pyplot_figure()\n    ```", "```py\n    exp.show_in_notebook()\n    ```", "```py\npython3 -m spacy download en_core_web_sm\n```", "```py\n    import numpy as np\n    import spacy\n    import time\n    import torch\n    from anchor import anchor_text\n    from transformers import pipeline\n    ```", "```py\n    nlp = spacy.load('en_core_web_sm')\n    ```", "```py\n    device = torch.device(\"cuda\" if torch.cuda.is_available(# Load model directly\n    from transformers import( AutoTokenizer, \n        AutoModelForSequenceClassification)\n    tokenizer = AutoTokenizer.from_pretrained(\n        \"jonathanfernandes/imdb_model\")\n    model = AutoModelForSequenceClassification.from_pretrained(\n        \"jonathanfernandes/imdb_model\")) else \"cpu\")\n    classifier = pipeline(\n        \"sentiment-analysis\",\n        model=\"siebert/sentiment-roberta-large-english\",\n        tokenizer=\"siebert/sentiment-roberta-large-english\",\n        top_k=1,\n        device=device)\n    ```", "```py\n    def predict_prob(texts):\n        preds = classifier(texts)\n        preds = np.array([\n            0 if label[0]['label'] == 'NEGATIVE' else 1\n            for label in preds])\n        spacy pipeline, the class labels, and use_unk_distribution as true. The class labels in this case are NEGATIVE and POSITIVE. The use_unk_distribution parameter specifies that the explainer uses the UNK token for masked words when it generates text for explanability.explainer = anchor_text.AnchorText(nlp, [‘NEGATIVE’, ‘POSITIVE’], use_unk_distribution=True)\n    ```", "```py\n    text = 'The little mermaid is a good story.'\n    pred = explainer.class_names[predict_prob([text])[0]]\n    print('Prediction: %s' % pred)\n    Prediction: POSITIVE\n    ```", "```py\n    print('Anchor: %s' % (' AND '.join(exp.names())))\n    print('Precision: %.2f' % exp.precision())\n    ```", "```py\nAnchor: good AND a AND is\nPrecision: 1.00\n```", "```py\n    print('\\n'.join([x[0] for x in exp.examples(\n        only_same_prediction=True)]))\n    ```", "```py\nThe little UNK is a good UNK .\nThe UNK mermaid is a good story .\nThe UNK UNK is a good story UNK\nUNK little mermaid is a good story UNK\nThe UNK mermaid is a good UNK .\nUNK little UNK is a good UNK .\nThe little mermaid is a good story UNK\nThe UNK UNK is a good UNK .\nThe little UNK is a good UNK .\nThe little mermaid is a good UNK .\n```", "```py\n    print('\\n'.join([x[0] for x in exp.examples(\n        only_different_prediction=True)]))\n    ```", "```py\n    explainer = anchor_text.AnchorText(nlp, \n        ['negative', 'positive'],\n        use_unk_distribution=False)\n    exp = explainer.explain_instance(text, \n        predict_prob, threshold=0.95)\n    ```", "```py\n    print('\\n'.join([x[0] for x in exp.examples(\n        only_same_prediction=True)]))\n    ```", "```py\nthe weeping mermaid gives his good story .\nMe ##rmaid mermaid : a good story .\nrainbow moon mermaid theater \" good story \"\nmy little mermaid tells a good story .\nPretty little mermaid tells a good story .\nMy black mermaid song sweet good story ;\n\" little mermaid : very good story .\nThis damned mermaid gives a good story .\n| \" mermaid \" : good story .\nMe ##rmaid mermaid : very good story .\n```", "```py\n    print('\\n'.join([x[0] for x in exp.examples(\n        only_different_prediction=True)]))\n    ```", "```py\n' til mermaid brings a good story …\nonly little mermaid : too good story ##book\nsmash hit mermaid with any good story ...\nnor did mermaid tell a good story !\n† denotes mermaid side / good story .\nno native mermaid has a good story .\nno ordinary mermaid is a good story .\nVery little mermaid ain any good story yet\nmiss rainbow mermaid made a good story .\nThe gorgeous mermaid ain your good story (\n```"]