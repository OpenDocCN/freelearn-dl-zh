- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: 'The Rise of Generative AI: From Language Models to Agents'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI的崛起：从语言模型到智能体
- en: 'The gap between experimental and production-ready agents is stark. According
    to LangChain’s State of Agents report, performance quality is the #1 concern among
    51% of companies using agents, yet only 39.8% have implemented proper evaluation
    systems. Our book bridges this gap on two fronts: first, by demonstrating how
    LangChain and LangSmith provide robust testing and observability solutions; second,
    by showing how LangGraph’s state management enables complex, reliable multi-agent
    systems. You’ll find production-tested code patterns that leverage each tool’s
    strengths for enterprise-scale implementation and extend basic RAG into robust
    knowledge systems.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 实验性和生产就绪智能体之间的差距非常明显。根据LangChain的智能体状态报告，性能质量是51%使用智能体的公司最关心的问题，但只有39.8%的公司实施了适当的评估系统。我们的书籍从两个前沿领域弥合了这一差距：首先，通过展示LangChain和LangSmith如何提供强大的测试和可观察性解决方案；其次，通过展示LangGraph的状态管理如何使复杂、可靠的智能体系统成为可能。您将找到经过生产测试的代码模式，这些模式利用每个工具的优势，以企业规模实施，并将基本的RAG扩展到强大的知识系统。
- en: LangChain accelerates time-to-market with readily available building blocks,
    unified vendor APIs, and detailed tutorials. Furthermore, LangChain and LangSmith
    debugging and tracing functionalities simplify the analysis of complex agent behavior.
    Finally, LangGraph has excelled in executing its philosophy behind agentic AI
    – it allows a developer to give a **large language model** (**LLM**) partial control
    flow over the workflow (and to manage the level of how much control an LLM should
    have), while still making agentic workflows reliable and well-performant.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain通过提供现成的构建块、统一的供应商API和详细的教程，加速了产品的上市时间。此外，LangChain和LangSmith的调试和跟踪功能简化了复杂智能体行为的分析。最后，LangGraph在执行其智能体AI背后的哲学方面表现出色——它允许开发者对工作流程中的**大型语言模型**（**LLM**）进行部分控制流（以及管理LLM应拥有的控制级别），同时仍然使智能体工作流程可靠且性能良好。
- en: In this chapter, we’ll explore how LLMs have evolved into the foundation for
    agentic AI systems and how frameworks like LangChain and LangGraph transform these
    models into production-ready applications. We’ll also examine the modern LLM landscape,
    understand the limitations of raw LLMs, and introduce the core concepts of agentic
    applications that form the basis for the hands-on development we’ll tackle throughout
    this book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨LLM如何演变成智能体AI系统的基石，以及像LangChain和LangGraph这样的框架如何将这些模型转化为生产就绪的应用。我们还将检查现代LLM的格局，了解原始LLM的限制，并介绍构成本书中我们将要解决的手动开发基础的智能体应用的核心概念。
- en: 'In a nutshell, the following topics will be covered in this book:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本书将涵盖以下主题：
- en: The modern LLM landscape
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代LLM格局
- en: From models to agentic applications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从模型到智能体应用
- en: Introducing LangChain
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍LangChain
- en: The modern LLM landscape
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代LLM格局
- en: '**Artificial intelligence** (**AI**) has long been a subject of fascination
    and research, but recent advancements in generative AI have propelled it into
    mainstream adoption. Unlike traditional AI systems that classify data or make
    predictions, generative AI can create new content—text, images, code, and more—by
    leveraging vast amounts of training data.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）长期以来一直是人们着迷和研究的话题，但最近在生成式AI方面的进步已经推动了其主流的采用。与传统的AI系统不同，这些系统对数据进行分类或做出预测，生成式AI可以通过利用大量的训练数据来创建新的内容——文本、图像、代码等等。'
- en: 'The generative AI revolution was catalyzed by the 2017 introduction of the
    transformer architecture, which enabled models to process text with unprecedented
    understanding of context and relationships. As researchers scaled these models
    from millions to billions of parameters, they discovered something remarkable:
    larger models didn’t just perform incrementally better—they exhibited entirely
    new emergent capabilities like few-shot learning, complex reasoning, and creative
    generation that weren’t explicitly programmed. Eventually, the release of ChatGPT
    in 2022 marked a turning point, demonstrating these capabilities to the public
    and sparking widespread adoption.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI革命是由2017年引入的transformer架构所催化的，它使模型能够以前所未有的对上下文和关系的理解来处理文本。随着研究人员将这些模型从数百万参数扩展到数十亿参数，他们发现了一些令人瞩目的事情：更大的模型不仅仅是渐进式地更好——它们还表现出全新的涌现能力，如少样本学习、复杂推理和创造性生成，这些能力并非明确编程。最终，2022年ChatGPT的发布标志着转折点，向公众展示了这些能力，并引发了广泛的应用。
- en: The landscape shifted again with the open-source revolution led by models like
    Llama and Mistral, democratizing access to powerful AI beyond the major tech companies.
    However, these advanced capabilities came with significant limitations—models
    couldn’t reliably use tools, reason through complex problems, or maintain context
    across interactions. This gap between raw model power and practical utility created
    the need for specialized frameworks like LangChain that transform these models
    from impressive text generators into functional, production-ready agents capable
    of solving real-world problems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在Llama和Mistral等模型引领的开源革命中，格局再次发生转变，将强大的AI访问权民主化，超越了主要科技公司。然而，这些高级功能伴随着重大的局限性——模型无法可靠地使用工具，通过复杂问题进行推理，或在交互过程中保持情境。这种原始模型力量和实际效用之间的差距产生了对像LangChain这样的专用框架的需求，这些框架将这些模型从令人印象深刻的文本生成器转变为功能齐全、生产就绪的代理，能够解决现实世界的问题。
- en: '**Key terminologies**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键术语**'
- en: '**Tools**: External utilities or functions that AI models can use to interact
    with the world. Tools allow agents to perform actions like searching the web,
    calculating values, or accessing databases to overcome LLMs’ inherent limitations.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**工具**：AI模型可以用来与世界交互的外部实用程序或函数。工具允许代理执行搜索网络、计算值或访问数据库等操作，以克服LLMs固有的局限性。'
- en: '**Memory**: Systems that allow AI applications to store and retrieve information
    across interactions. Memory enables contextual awareness in conversations and
    complex workflows by tracking previous inputs, outputs, and important information.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**记忆**：允许AI应用在交互过程中存储和检索信息的系统。通过跟踪之前的输入、输出和重要信息，记忆使对话和复杂工作流程具有情境意识。'
- en: '**Reinforcement learning from human feedback** (**RLHF**): A training technique
    where AI models learn from direct human feedback, optimizing their performance
    to align with human preferences. RLHF helps create models that are more helpful,
    safe, and aligned with human values.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于人类反馈的强化学习（RLHF**）：一种训练技术，其中AI模型从直接的人类反馈中学习，优化其性能以符合人类偏好。RLHF有助于创建更帮助性、更安全且与人类价值观一致的模型。'
- en: '**Agents**: AI systems that can perceive their environment, make decisions,
    and take actions to accomplish goals. In LangChain, agents use LLMs to interpret
    tasks, choose appropriate tools, and execute multi-step processes with minimal
    human intervention.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理**：能够感知其环境、做出决策并采取行动以实现目标的AI系统。在LangChain中，代理使用LLMs来解释任务、选择适当的工具，并在最小化人工干预的情况下执行多步骤过程。'
- en: '| **Yea****r** | **Development** | **Key Features** |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **年** | **发展** | **关键特性** |'
- en: '| 1990s | IBM Alignment Models | Statistical machine translation |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 1990年代 | IBM对齐模型 | 统计机器翻译 |'
- en: '| 2000s | Web-scale datasets | Large-scale statistical models |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 2000年代 | 网络规模数据集 | 大规模统计模型 |'
- en: '| 2009 | Statistical models dominate | Large-scale text ingestion |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 2009 | 统计模型主导 | 大规模文本摄入 |'
- en: '| 2012 | Deep learning gains traction | Neural networks outperform statistical
    models |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 2012 | 深度学习获得动力 | 神经网络优于统计模型 |'
- en: '| 2016 | Neural Machine Translation (NMT) | Seq2seq deep LSTMs replace statistical
    methods |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 2016 | 神经机器翻译（NMT） | Seq2seq深度LSTMs取代统计方法 |'
- en: '| 2017 | Transformer architecture | Self-attention revolutionizes NLP |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 2017 | Transformer架构 | 自注意力革命性地改变了NLP |'
- en: '| 2018 | BERT and GPT-1 | Transformer-based language understanding and generation
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | BERT和GPT-1 | 基于Transformer的语言理解和生成 |'
- en: '| 2019 | GPT-2 | Large-scale text generation, public awareness increases |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | GPT-2 | 大规模文本生成，公众意识提高 |'
- en: '| 2020 | GPT-3 | API-based access, state-of-the-art performance |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | GPT-3 | 基于API的访问，最先进的性能 |'
- en: '| 2022 | ChatGPT | Mainstream adoption of LLMs |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 2022 | ChatGPT | LLMs的广泛应用 |'
- en: '| 2023 | Large Multimodal Models (LMMs) | AI models process text, images, and
    audio |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 2023 | 大型多模态模型（LMMs） | AI模型处理文本、图像和音频 |'
- en: '|'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '2024'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '2024'
- en: '| OpenAI o1 | Stronger reasoning capabilities |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| OpenAI o1 | 更强的推理能力 |'
- en: '| 2025 | DeepSeek R1 | Open-weight, large-scale AI model |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 2025 | DeepSeek R1 | 开放式、大规模AI模型 |'
- en: 'Table 1.1: A timeline of major developments in language models'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1：语言模型主要发展的时间线
- en: The field of LLMs is rapidly evolving, with multiple models competing in terms
    of performance, capabilities, and accessibility. Each provider brings distinct
    advantages, from OpenAI’s advanced general-purpose AI to Mistral’s open-weight,
    high-efficiency models. Understanding the differences between these models helps
    practitioners make informed decisions when integrating LLMs into their applications.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs领域正在迅速发展，多个模型在性能、能力和可访问性方面展开竞争。每个提供商都带来独特的优势，从OpenAI的高级通用人工智能到Mistral的开源、高效模型。了解这些模型之间的差异有助于实践者在将LLMs集成到其应用程序时做出明智的决定。
- en: Model comparison
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型比较
- en: 'The following points outline key factors to consider when comparing different
    LLMs, focusing on their accessibility, size, capabilities, and specialization:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下要点概述了比较不同LLMs时需要考虑的关键因素，重点关注其可访问性、规模、能力和专业化：
- en: '**Open-source vs. closed-source models**: Open-source models like Mistral and
    LLaMA provide transparency and the ability to run locally, while closed-source
    models like GPT-4 and Claude are accessible through APIs. Open-source LLMs can
    be downloaded and modified, enabling developers and researchers to investigate
    and build upon their architectures, though specific usage terms may apply.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源模型与闭源模型**：开源模型如Mistral和LLaMA提供透明度和本地运行的能力，而闭源模型如GPT-4和Claude则可以通过API访问。开源LLMs可以被下载和修改，使开发人员和研究人员能够调查和基于其架构进行构建，尽管可能适用特定的使用条款。'
- en: '**Size and capabilities**: Larger models generally offer better performance
    but require more computational resources. This makes smaller models great for
    use on devices with limited computing power or memory, and can be significantly
    cheaper to use. **Small language models** (**SLMs**) have a relatively small number
    of parameters, typically using millions to a few billion parameters, as opposed
    to LLMs, which can have hundreds of billions or even trillions of parameters.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模和能力**：较大的模型通常提供更好的性能，但需要更多的计算资源。这使得较小的模型非常适合在计算能力或内存有限的设备上使用，并且使用成本可以显著降低。**小型语言模型（SLMs**）的参数数量相对较少，通常使用数百万到数十亿个参数，而大型语言模型（LLMs）可以拥有数百亿甚至数千亿的参数。'
- en: '**Specialized models**: Some LLMs are optimized for specific tasks, such as
    code generation (for example, Codex) or mathematical reasoning (e.g., Minerva).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用模型**：一些大型语言模型（LLMs）针对特定任务进行了优化，例如代码生成（例如，Codex）或数学推理（例如，Minerva）。'
- en: The increase in the scale of language models has been a major driving force
    behind their impressive performance gains. However, recently there has been a
    shift in architecture and training methods that has led to better parameter efficiency
    in terms of performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型规模的增加是它们令人印象深刻的性能提升的主要驱动力。然而，最近在架构和训练方法上出现的变化导致了在性能方面的参数效率的提高。
- en: '**Model scaling laws**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型缩放定律**'
- en: Empirically derived scaling laws predict the performance of LLMs based on the
    given training budget, dataset size, and the number of parameters. If true, this
    means that highly powerful systems will be concentrated in the hands of Big Tech,
    however, we have seen a significant shift over recent months.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 经验推导的缩放定律根据给定的训练预算、数据集大小和参数数量预测LLMs的性能。如果这是真的，这意味着高度强大的系统将集中在大型科技公司手中，然而，我们在最近几个月看到了显著的转变。
- en: The **KM scaling law**, proposed by Kaplan et al., derived through empirical
    analysis and fitting of model performance with varied data sizes, model sizes,
    and training compute, presents power-law relationships, indicating a strong codependence
    between model performance and factors such as model size, dataset size, and training
    compute.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kaplan等人提出的**KM缩放定律**，通过经验分析和拟合模型性能与不同数据大小、模型大小和训练计算之间的关系，呈现幂律关系，表明模型性能与模型大小、数据集大小和训练计算等因素之间存在强烈的相互依赖性。
- en: The **Chinchilla scaling law**, proposed by the Google DeepMind team, involved
    experiments with a wider range of model sizes and data sizes. It suggests an optimal
    allocation of compute budget to model size and data size, which can be determined
    by optimizing a specific loss function under a constraint.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Google DeepMind团队提出的**Chinchilla缩放定律**涉及对更广泛范围的模型大小和数据大小的实验。它建议对计算预算进行最优分配，以适应模型大小和数据大小，这可以通过在约束下优化特定的损失函数来确定。
- en: However, future progress may depend more on model architecture, data cleansing,
    and model algorithmic innovation rather than sheer size. For example, models such
    as phi, first presented in *Textbooks Are All You Need* (2023, Gunasekar et al.),
    with about 1 billion parameters, showed that models can – despite a smaller scale
    – achieve high accuracy on evaluation benchmarks. The authors suggest that improving
    data quality can dramatically change the shape of scaling laws.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，未来的进步可能更多地取决于模型架构、数据清洗和模型算法创新，而不是单纯的大小。例如，phi模型，首次在*《教科书都是你需要的一切》*（2023年，Gunasekar等人）中提出，大约有10亿个参数，表明模型即使规模较小，也能在评估基准上实现高精度。作者建议提高数据质量可以显著改变扩展定律的形状。
- en: Further, there is a body of work on simplified model architectures, which have
    substantially fewer parameters and only modestly drop accuracy (for example, *One
    Wide Feedforward is All You Need*, Pessoa Pires et al., 2023). Additionally, techniques
    such as fine-tuning, quantization, distillation, and prompting techniques can
    enable smaller models to leverage the capabilities of large foundations without
    replicating their costs. To compensate for model limitations, tools like search
    engines and calculators have been incorporated into agents, and multi-step reasoning
    strategies, plugins, and extensions may be increasingly used to expand capabilities.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有关于简化模型架构的研究，这些模型具有显著更少的参数，并且仅略微降低精度（例如，*只需要一个宽前馈网络*，Pessoa Pires等人，2023年）。此外，微调、量化、蒸馏和提示技术等技术可以使较小的模型利用大型基础模型的能力，而无需复制其成本。为了弥补模型限制，搜索引擎和计算器等工具已被纳入代理中，多步推理策略、插件和扩展可能越来越多地被用来扩展功能。
- en: The future could see the co-existence of massive, general models with smaller
    and more accessible models that provide faster and cheaper training, maintenance,
    and inference.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 未来可能会看到大型通用模型与较小且更易于访问的模型的共存，这些模型提供更快、更便宜的培训、维护和推理。
- en: Let’s now discuss a comparative overview of various LLMs, highlighting their
    key characteristics and differentiating factors. We’ll delve into aspects such
    as open-source vs. closed-source models, model size and capabilities, and specialized
    models. By understanding these distinctions, you can select the most suitable
    LLM for your specific needs and applications.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下各种LLM的比较概述，突出它们的关键特性和差异化因素。我们将探讨开源与闭源模型、模型大小和能力以及专用模型等方面。通过了解这些区别，您可以选择最适合您特定需求和应用的LLM。
- en: LLM provider landscape
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM提供商格局
- en: You can access LLMs from major providers like OpenAI, Google, and Anthropic,
    along with a growing number of others, through their websites or APIs. As the
    demand for LLMs grows, numerous providers have entered the space, each offering
    models with unique capabilities and trade-offs. Developers need to understand
    the various access options available for integrating these powerful models into
    their applications. The choice of provider will significantly impact development
    experience, performance characteristics, and operational costs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过OpenAI、谷歌和Anthropic等主要提供商的网站或API访问LLM，以及其他越来越多的提供商。随着对LLM的需求增长，许多提供商已进入该领域，每个都提供具有独特功能和权衡的模型。开发者需要了解可用于将强大模型集成到其应用程序中的各种访问选项。提供商的选择将显著影响开发体验、性能特征和运营成本。
- en: 'The table below provides a comparative overview of leading LLM providers and
    examples of the models they offer:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下表提供了领先的大型语言模型（LLM）提供商及其提供的模型示例的比较概述：
- en: '| **Provider** | **Notable models** | **Key features and strengths** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| **提供商** | **知名模型** | **关键特性和优势** |'
- en: '| **OpenAI** | GPT-4o, GPT-4.5; o1; o3-mini | Strong general performance, proprietary
    models, advanced reasoning; multimodal reasoning across text, audio, vision, and
    video in real time |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| **OpenAI** | GPT-4o, GPT-4.5；o1；o3-mini | 强大的通用性能，专有模型，高级推理；在实时跨文本、音频、视觉和视频中进行多模态推理
    |'
- en: '| **Anthropic** | Claude 3.7 Sonnet; Claude 3.5 Haiku | Toggle between real-time
    responses and extended “thinking” phases; outperforms OpenAI’s o1 in coding benchmarks
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **Anthropic** | Claude 3.7 Sonnet; Claude 3.5 Haiku | 在实时响应和扩展的“思考”阶段之间切换；在编码基准测试中优于OpenAI的o1
    |'
- en: '| **Google** | Gemini 2.5, 2.0 (flash and pro), Gemini 1.5 | Low latency and
    costs, large context window (up to 2M tokens), multimodal inputs and outputs,
    reasoning capabilities |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| **谷歌** | Gemini 2.5, 2.0（闪存和专业版），Gemini 1.5 | 低延迟和成本，大上下文窗口（高达2M个标记），多模态输入和输出，推理能力
    |'
- en: '| **Cohere** | Command R, Command R Plus | Retrieval-augmented generation,
    enterprise AI solutions |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| **Cohere** | Command R，Command R Plus | 检索增强生成，企业AI解决方案 |'
- en: '| **Mistral AI** | Mistral Large; Mistral 7B | Open weights, efficient inference,
    multilingual support |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| **Mistral AI** | Mistral Large；Mistral 7B | 开放权重，高效推理，多语言支持 |'
- en: '| **AWS** | Titan | Enterprise-scale AI models, optimized for the AWS cloud
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| **AWS** | Titan | 企业级AI模型，优化用于AWS云 |'
- en: '|'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**DeepSeek**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**DeepSeek**'
- en: '| R1 | Maths-first: solves Olympiad-level problems; cost-effective, optimized
    for multilingual and programming tasks |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| R1 | 以数学为先：解决奥林匹克级别的难题；成本效益高，优化用于多语言和编程任务 |'
- en: '| **Together AI** | Infrastructure for running open models | Competitive pricing;
    growing marketplace of models |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **Together AI** | 运行开源模型的基础设施 | 具有竞争力的定价；模型市场正在增长 |'
- en: 'Table 1.2: Comparative overview of major LLM providers and their flagship models
    for LangChain implementation'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.2：主要LLM提供商及其用于LangChain实现的旗舰模型的比较概述
- en: Other organizations develop LLMs but do not necessarily provide them through
    **application programming interfaces** (**APIs**) to developers. For example,
    Meta AI develops the very influential Llama model series, which has strong reasoning,
    code-generation capabilities, and is released under an open-source license.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 其他组织开发LLM，但并不一定通过**应用程序编程接口**（**APIs**）向开发者提供。例如，Meta AI开发了非常有影响力的Llama模型系列，该系列具有强大的推理和代码生成能力，并以开源许可证发布。
- en: There is a whole zoo of open-source models that you can access through Hugging
    Face or through other providers. You can even download these open-source models,
    fine-tune them, or fully train them. We’ll try this out practically starting in
    [*Chapter 2*](E_Chapter_2.xhtml#_idTextAnchor044).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过Hugging Face或其他提供商访问一系列开源模型。你甚至可以下载这些开源模型，微调它们，或完全训练它们。我们将在[*第二章*](E_Chapter_2.xhtml#_idTextAnchor044)中实际尝试这一点。
- en: Once you’ve selected an appropriate model, the next crucial step is understanding
    how to control its behavior to suit your specific application needs. While accessing
    a model gives you computational capability, it’s the choice of generation parameters
    that transforms raw model power into tailored output for different use cases within
    your applications.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了合适的模型，下一个关键步骤就是了解如何控制其行为以满足你特定的应用需求。虽然访问模型为你提供了计算能力，但生成参数的选择将把原始模型的力量转化为适用于你应用程序中不同用例的定制输出。
- en: 'Now that we’ve covered the LLM provider landscape, let’s discuss another critical
    aspect of LLM implementation: licensing considerations. The licensing terms of
    different models significantly impact how you can use them in your applications.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了LLM提供商的格局，让我们讨论LLM实施中的另一个关键方面：许可证考虑。不同模型的许可证条款在很大程度上影响了你在应用程序中使用它们的方式。
- en: Licensing
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 许可证
- en: LLMs are available under different licensing models that impact how they can
    be used in practice. Open-source models like Mixtral and BERT can be freely used,
    modified, and integrated into applications. These models allow developers to run
    them locally, investigate their behavior, and build upon them for both research
    and commercial purposes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在不同的许可证模型下可用，这影响了它们在实际中的使用方式。开源模型如Mixtral和BERT可以自由使用、修改并集成到应用程序中。这些模型允许开发者本地运行它们，研究其行为，并在研究和商业目的上在此基础上构建。
- en: In contrast, proprietary models like GPT-4 and Claude are accessible only through
    APIs, with their internal workings kept private. While this ensures consistent
    performance and regular updates, it means depending on external services and typically
    incurring usage costs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，像GPT-4和Claude这样的专有模型只能通过API访问，其内部工作原理保持私密。虽然这确保了性能的一致性和定期更新，但也意味着依赖于外部服务，并且通常会产生使用费用。
- en: 'Some models like Llama 2 take a middle ground, offering permissive licenses
    for both research and commercial use while maintaining certain usage conditions.
    For detailed information about specific model licenses and their implications,
    refer to the documentation of each model or consult the model openness framework:
    [https://isitopen.ai/](https://isitopen.ai/).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型，如Llama 2，采取折中方案，为研究和商业用途提供宽松的许可证，同时保持某些使用条件。有关特定模型许可证及其影响的详细信息，请参阅每个模型的文档或咨询模型开放框架：[https://isitopen.ai/](https://isitopen.ai/).
- en: The **model openness framework** (**MOF**) evaluates language models based on
    criteria such as access to model architecture details, training methodology and
    hyperparameters, data sourcing and processing information, documentation around
    development decisions, ability to evaluate model workings, biases, and limitations,
    code modularity, published model card, availability of servable model, option
    to run locally, source code availability, and redistribution rights.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型开放框架**（**MOF**）根据诸如访问模型架构细节、训练方法及超参数、数据来源和处理信息、开发决策的文档、评估模型运作、偏见和局限性的能力、代码模块化、发布的模型卡片、可服务模型的可用性、本地运行选项、源代码可用性和再分发权利等标准评估语言模型。'
- en: In general, open-source licenses promote wide adoption, collaboration, and innovation
    around the models, benefiting both research and commercial development. Proprietary
    licenses typically give companies exclusive control but may limit academic research
    progress. Non-commercial licenses often restrict commercial use while enabling
    research.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，开源许可促进了对模型的广泛采用、协作和创新，这对研究和商业开发都有益。专有许可通常给予公司独家控制权，但可能限制学术研究进展。非商业许可通常限制商业用途，同时允许研究。
- en: By making knowledge and knowledge work more accessible and adaptable, generative
    AI models have the potential to level the playing field and create new opportunities
    for people from all walks of life.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使知识和知识工作更加易于获取和适应，生成式AI模型有可能使竞争场域公平，并为各行各业的人创造新的机会。
- en: The evolution of AI has brought us to a pivotal moment where AI systems can
    not only process information but also take autonomous action. The next section
    explores the transformation from basic language models to more complex, and finally,
    fully agentic applications.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的演变使我们达到了一个关键时刻，AI系统不仅可以处理信息，还可以采取自主行动。下一节将探讨从基本语言模型到更复杂，最终到完全代理应用的转变。
- en: The information provided about AI model licensing is for educational purposes
    only and does not constitute legal advice. Licensing terms vary significantly
    and evolve rapidly. Organizations should consult qualified legal counsel regarding
    specific licensing decisions for their AI implementations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 关于AI模型许可提供的信息仅用于教育目的，并不构成法律建议。许可条款差异很大且发展迅速。组织应咨询合格的法律顾问，以了解其AI实施的具体许可决策。
- en: From models to agentic applications
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从模型到代理应用
- en: As discussed so far, LLMs have been demonstrating remarkable fluency in natural
    language processing. However, as impressive as they are, they remain fundamentally
    *reactive* rather than *proactive*. They lack the ability to take independent
    actions, interact meaningfully with external systems, or autonomously achieve
    complex objectives.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，LLMs已经在自然语言处理中展现出非凡的流畅性。然而，尽管它们令人印象深刻，但它们仍然本质上是**反应性的**而不是**主动性的**。它们缺乏采取独立行动、有意义地与外部系统交互或自主实现复杂目标的能力。
- en: To unlock the next phase of AI capabilities, we need to move beyond passive
    text generation and toward **agentic AI**—systems that can plan, reason, and take
    action to accomplish tasks with minimal human intervention. Before exploring the
    potential of agentic AI, it’s important to first understand the core limitations
    of LLMs that necessitate this evolution.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解锁AI能力的下一阶段，我们需要超越被动的文本生成，转向**代理AI**——能够规划、推理并采取行动以最小化人类干预完成任务的系统。在探索代理AI的潜力之前，首先了解LLMs的核心局限性，这些局限性是这种演变所必需的。
- en: Limitations of traditional LLMs
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统LLMs的局限性
- en: 'Despite their advanced language capabilities, LLMs have inherent constraints
    that limit their effectiveness in real-world applications:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLMs具有高级的语言能力，但它们固有的限制限制了它们在现实世界应用中的有效性：
- en: '**Lack of true understanding**: LLMs generate human-like text by predicting
    the next most likely word based on statistical patterns in training data. However,
    they do not understand meaning in the way humans do. This leads to hallucinations—confidently
    stating false information as fact—and generating plausible but incorrect, misleading,
    or nonsensical outputs. As Bender et al. (2021) describe, LLMs function as “stochastic
    parrots”—repeating patterns without genuine comprehension.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缺乏真正的理解**：大型语言模型（LLMs）通过根据训练数据中的统计模式预测下一个最可能出现的单词来生成类似人类的文本。然而，它们并不像人类那样理解意义。这导致幻觉——自信地将错误信息当作事实陈述——以及生成看似合理但实际上错误、误导或不合逻辑的输出。正如Bender等人（2021）所描述的，LLMs作为“随机鹦鹉”——重复模式而没有真正的理解。'
- en: '**Struggles with complex reasoning and problem-solving**: While LLMs excel
    at retrieving and reformatting knowledge, they struggle with multi-step reasoning,
    logical puzzles, and mathematical problem-solving. They often fail to break down
    problems into sub-tasks or synthesize information across different contexts. Without
    explicit prompting techniques like chain-of-thought reasoning, their ability to
    deduce or infer remains unreliable.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在复杂推理和问题解决上的挑战**：虽然LLMs在检索和重新格式化知识方面表现出色，但它们在多步推理、逻辑谜题和数学问题解决上存在困难。它们通常无法将问题分解为子任务或在不同上下文中综合信息。没有像思维链推理这样的明确提示技术，它们推断或推理的能力仍然不可靠。'
- en: '**Outdated knowledge and limited external access**: LLMs are trained on static
    datasets and do not have real-time access to current events, dynamic databases,
    or live information sources. This makes them unsuitable for tasks requiring up-to-date
    knowledge, such as financial analysis, breaking news summaries, or scientific
    research requiring the latest findings.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**知识过时和外部访问有限**：LLMs是在静态数据集上训练的，并且没有实时访问当前事件、动态数据库或实时信息源。这使得它们不适合需要最新知识的任务，例如财务分析、突发新闻摘要或需要最新发现的科学研究。'
- en: '**No native tool use or action-taking abilities**: LLMs operate in isolation—they
    cannot interact with APIs, retrieve live data, execute code, or modify external
    systems. This lack of tool integration makes them less effective in scenarios
    that require real-world actions, such as conducting web searches, automating workflows,
    or controlling software systems.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**没有原生的工具使用或行动能力**：LLMs 在独立状态下运行——它们无法与API交互、检索实时数据、执行代码或修改外部系统。这种缺乏工具集成使得它们在需要现实世界行动的场景中效果较差，例如进行网络搜索、自动化工作流程或控制软件系统。'
- en: '**Bias, ethical concerns, and reliability issues:** Because LLMs learn from
    large datasets that may contain biases, they can unintentionally reinforce ideological,
    social, or cultural biases. Importantly, even with open-source models, accessing
    and auditing the complete training data to identify and mitigate these biases
    remains challenging for most practitioners. Additionally, they can generate misleading
    or harmful information without understanding the ethical implications of their
    outputs.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**偏见、伦理担忧和可靠性问题**：由于LLMs从可能包含偏见的庞大数据集中学习，它们可能会无意中加强意识形态、社会或文化偏见。重要的是，即使对于开源模型，对于大多数从业者来说，访问和审计完整训练数据以识别和减轻这些偏见仍然具有挑战性。此外，它们可能会在没有理解其输出伦理影响的情况下生成误导性或有害信息。'
- en: '**Computational costs and efficiency challenges**: Deploying and running LLMs
    at scale requires **significant** computational resources, making them costly
    and energy-intensive. Larger models can also introduce latency, slowing response
    times in real-time applications.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算成本和效率挑战**：大规模部署和运行LLMs需要**大量**的计算资源，这使得它们成本高昂且能耗密集。更大的模型也可能引入延迟，减慢实时应用的响应时间。'
- en: To overcome these limitations, AI systems must evolve from passive text generators
    into active agents that can plan, reason, and interact with their environment.
    This is where agentic AI comes in—integrating LLMs with tool use, decision-making
    mechanisms, and autonomous execution capabilities to enhance their functionality.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些限制，AI系统必须从被动的文本生成器进化为能够规划、推理并与环境交互的主动代理。这正是代理AI发挥作用的地方——将LLMs与工具使用、决策机制和自主执行能力集成，以增强其功能。
- en: While frameworks like LangChain provide comprehensive solutions to LLM limitations,
    understanding fundamental prompt engineering techniques remains valuable. Approaches
    like few-shot learning, chain-of-thought, and structured prompting can significantly
    enhance model performance for specific tasks. [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107)
    will cover these techniques in detail, showing how LangChain helps standardize
    and optimize prompting patterns while minimizing the need for custom prompt engineering
    in every application.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然像LangChain这样的框架为LLMs的局限性提供了全面的解决方案，但理解基本的提示工程技术仍然很有价值。像少样本学习、思维链和结构化提示这样的方法可以显著提高模型在特定任务上的性能。[第3章](E_Chapter_3.xhtml#_idTextAnchor107)将详细介绍这些技术，展示LangChain如何帮助标准化和优化提示模式，同时最大限度地减少在每个应用中需要定制提示工程的需求。
- en: The next section explores how agentic AI extends the capabilities of traditional
    LLMs and unlocks new possibilities for automation, problem-solving, and intelligent
    decision-making.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将探讨代理AI如何扩展传统LLMs的功能，并为自动化、问题解决和智能决策解锁新的可能性。
- en: Understanding LLM applications
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解LLM应用
- en: 'LLM applications represent the bridge between raw model capability and practical
    business value. While LLMs possess impressive language processing abilities, they
    require thoughtful integration to deliver real-world solutions. These applications
    broadly fall into two categories: complex integrated applications and autonomous
    agents.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应用代表了原始模型能力与实际商业价值之间的桥梁。虽然LLM拥有令人印象深刻的语言处理能力，但它们需要深思熟虑的整合才能提供现实世界的解决方案。这些应用大致分为两大类：复杂集成应用和自主代理。
- en: '**Complex integrated applications** enhance human workflows by integrating
    LLMs into existing processes, including:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**复杂集成应用**通过将大型语言模型（LLM）整合到现有流程中，增强了人类工作流程，包括：'
- en: Decision support systems that provide analysis and recommendations
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供分析和建议的决策支持系统
- en: Content generation pipelines with human review
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有人类审查的内容生成管道
- en: Interactive tools that augment human capabilities
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增强人类能力的交互式工具
- en: Workflow automation with human oversight
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在人类监督下的工作流程自动化
- en: '**Autonomous agents** operate with minimal human intervention, further augmenting
    workflows through LLM integration. Examples include:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**自主代理**在最小的人为干预下运行，通过LLM的整合进一步增强了工作流程。例如：'
- en: Task automation agents that execute defined workflows
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行定义工作流程的任务自动化代理
- en: Information gathering and analysis systems
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息收集和分析系统
- en: Multi-agent systems for complex task coordination
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于复杂任务协调的多代理系统
- en: LangChain provides frameworks for both integrated applications and autonomous
    agents, offering flexible components that support various architectural choices.
    This book will explore both approaches, demonstrating how to build reliable, production-ready
    systems that match your specific requirements.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain为集成应用和自主代理提供框架，提供灵活的组件，支持各种架构选择。本书将探讨这两种方法，展示如何构建符合您特定要求的可靠、生产就绪的系统。
- en: Autonomous systems of agents are potentially very powerful, and it’s therefore
    worthwhile exploring them a bit more.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的自主系统可能非常强大，因此值得进一步探索。
- en: Understanding AI agents
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解AI代理
- en: It is sometimes joked that AI is just a fancy word for ML, or AI is ML in a
    suit, as illustrated in this image; however, there’s more to it, as we’ll see.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有时人们开玩笑说AI只是ML的华丽辞藻，或者AI是穿着西装的ML，如图所示；然而，这背后还有更多内容，我们将看到。
- en: '![Figure 1.1: ML in a suit. Generated by a model on replicate.com, Diffusers
    Stable Diffusion v2.1](img/B32363_01_01.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1：穿着西装的ML。由replicate.com上的模型生成，Diffusers Stable Diffusion v2.1](img/B32363_01_01.png)'
- en: 'Figure 1.1: ML in a suit. Generated by a model on replicate.com, Diffusers
    Stable Diffusion v2.1'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：穿着西装的ML。由replicate.com上的模型生成，Diffusers Stable Diffusion v2.1
- en: An AI agent represents the bridge between raw cognitive capability and practical
    action. While an LLM possesses vast knowledge and processing ability, it remains
    fundamentally reactive without agency. AI agents transform this passive capability
    into active utility through structured workflows that parse requirements, analyze
    options, and execute actions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一个AI代理代表了从原始认知能力到实际行动的桥梁。虽然LLM拥有庞大的知识和处理能力，但它仍然缺乏主动性，本质上仍然是反应性的。AI代理通过结构化的工作流程将这种被动能力转化为主动效用，这些工作流程解析需求、分析选项并执行行动。
- en: Agentic AI enables autonomous systems to make decisions and act independently,
    with minimal human intervention. Unlike deterministic systems that follow fixed
    rules, agentic AI relies on patterns and likelihoods to make informed choices.
    It functions through a network of autonomous software components called agents,
    which learn from user behavior and large datasets to improve over time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 代理式AI使自主系统能够在最小的人为干预下做出决策和独立行动。与遵循固定规则的确定性系统不同，代理式AI依赖于模式和可能性来做出明智的选择。它通过一个称为代理的自主软件组件网络来运行，这些代理从用户行为和大量数据集中学习，以随着时间的推移不断改进。
- en: '*Agency* in AI refers to a system’s ability to act independently to achieve
    goals. True agency means an AI system can perceive its environment, make decisions,
    act, and adapt over time by learning from interactions and feedback. The distinction
    between raw AI and agents parallels the difference between knowledge and expertise.
    Consider a brilliant researcher who understands complex theories but struggles
    with practical application. An agent system adds the crucial element of purposeful
    action, turning abstract capability into concrete results.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: AI中的*代理*指的是系统独立行动以实现目标的能力。真正的代理意味着AI系统可以通过学习交互和反馈来感知其环境、做出决策、行动并适应。原始AI与代理之间的区别与知识和专业知识之间的区别相似。考虑一位理解复杂理论的杰出研究人员，但在实际应用上却遇到困难。代理系统增加了有目的行动的关键要素，将抽象能力转化为具体成果。
- en: In the context of LLMs, agentic AI involves developing systems that act autonomously,
    understand context, adapt to new information, and collaborate with humans to solve
    complex challenges. These AI agents leverage LLMs to process information, generate
    responses, and execute tasks based on defined objectives.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM的背景下，代理AI涉及开发能够自主行动、理解情境、适应新信息并与人类协作解决复杂挑战的系统。这些AI代理利用LLM来处理信息、生成响应并根据定义的目标执行任务。
- en: 'Particularly, AI agents extend the capabilities of LLMs by integrating memory,
    tool use, and decision-making frameworks. These agents can:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是AI代理通过整合记忆、工具使用和决策框架来扩展LLM的能力。这些代理可以：
- en: Retain and recall information across interactions.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在交互中保留和回忆信息。
- en: Utilize external tools, APIs, and databases.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用外部工具、API和数据库。
- en: Plan and execute multi-step workflows.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划和执行多步骤工作流程。
- en: The value of agency lies in reducing the need for constant human oversight.
    Instead of manually prompting an LLM for every request, an agent can proactively
    execute tasks, react to new data, and integrate with real-world applications.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的价值在于减少对持续人类监督的需求。而不是为每个请求手动提示LLM，代理可以主动执行任务，对新数据进行反应，并与现实世界应用集成。
- en: AI agents are systems designed to act on behalf of users, leveraging LLMs alongside
    external tools, memory, and decision-making frameworks. The hope behind AI agents
    is that they can automate complex workflows, reducing human effort while increasing
    efficiency and accuracy. By allowing systems to act autonomously, agents promise
    to unlock new levels of automation in AI-driven applications. But are the hopes
    justified?
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理是代表用户行动的系统，利用LLM以及外部工具、记忆和决策框架。AI代理背后的希望是它们可以自动化复杂的工作流程，减少人力，同时提高效率和准确性。通过允许系统自主行动，代理承诺在AI驱动应用中解锁新的自动化水平。但这些希望是合理的吗？
- en: 'Despite their potential, AI agents face significant challenges:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们具有潜力，但AI代理面临着重大的挑战：
- en: '**Reliability**: Ensuring agents make correct, context-aware decisions without
    supervision is difficult.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性**：确保代理在无监督的情况下做出正确、情境感知的决策是困难的。'
- en: '**Generalization**: Many agents work well in narrow domains but struggle with
    open-ended, multi-domain tasks.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**泛化**：许多代理在狭窄领域表现良好，但在开放性、多领域任务上却遇到困难。'
- en: '**Lack of trust**: Users must trust that agents will act responsibly, avoid
    unintended actions, and respect privacy constraints.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏信任**：用户必须相信代理将负责任地行动，避免意外行为，并尊重隐私限制。'
- en: '**Coordination complexity**: Multi-agent systems often suffer from inefficiencies
    and miscommunication when executing tasks collaboratively.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协调复杂性**：多代理系统在协作执行任务时往往效率低下，存在沟通不畅的问题。'
- en: 'Production-ready agent systems must address not just theoretical challenges
    but practical implementation hurdles like:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于生产的代理系统必须解决不仅仅是理论上的挑战，还包括实际实施障碍，如：
- en: Rate limitations and API quotas
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 速率限制和API配额
- en: Token context overflow errors
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令牌上下文溢出错误
- en: Hallucination management
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幻觉管理
- en: Cost optimization
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本优化
- en: LangChain and LangSmith provide robust solutions for these challenges, which
    we’ll explore in depth in [*Chapter 8*](E_Chapter_8.xhtml#_idTextAnchor390) and
    [*Chapter 9*](E_Chapter_9.xhtml#_idTextAnchor448). These chapters will cover how
    to build reliable, observable AI systems that can operate at an enterprise scale.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain和LangSmith为这些挑战提供了稳健的解决方案，我们将在[*第8章*](E_Chapter_8.xhtml#_idTextAnchor390)和[*第9章*](E_Chapter_9.xhtml#_idTextAnchor448)中深入探讨。这两章将涵盖如何构建可靠、可观察的AI系统，这些系统能在企业规模上运行。
- en: 'When developing agent-based systems, therefore, several key factors require
    careful consideration:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在开发基于代理的系统时，需要仔细考虑几个关键因素：
- en: '**Value generation**: Agents must provide a clear utility that outweighs their
    costs in terms of setup, maintenance, and necessary human oversight. This often
    means starting with well-defined, high-value tasks where automation can demonstrably
    improve outcomes.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值创造**：代理必须提供明确的效用，其成本（包括设置、维护和必要的人类监督）低于其价值。这通常意味着从定义明确、价值高的任务开始，自动化可以明显改善结果。'
- en: '**Trust and safety**: As agents take on more responsibility, establishing and
    maintaining user trust becomes crucial. This encompasses both technical reliability
    and transparent operation that allows users to understand and predict agent behavior.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信任和安全**：随着代理承担更多责任，建立和维护用户信任变得至关重要。这包括技术可靠性和透明的操作，使用户能够理解和预测代理的行为。'
- en: '**Standardization**: As the agent ecosystem grows, standardized interfaces
    and protocols become essential for interoperability. This parallels the development
    of web standards that enabled the growth of internet applications.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化**：随着代理生态系统的增长，标准化的接口和协议对于互操作性变得至关重要。这类似于网络标准的开发，这些标准促进了互联网应用程序的增长。'
- en: While early AI systems focused on pattern matching and predefined templates,
    modern AI agents demonstrate emergent capabilities such as reasoning, problem-solving,
    and long-term planning. Today’s AI agents integrate LLMs with interactive environments,
    enabling them to function autonomously in complex domains.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然早期的 AI 系统专注于模式匹配和预定义模板，但现代 AI 代理展示了涌现能力，如推理、问题解决和长期规划。今天的 AI 代理将 LLM 与交互式环境集成，使其能够在复杂领域自主运行。
- en: The development of agent-based AI is a natural progression from statistical
    models to deep learning and now to reasoning-based systems. Modern AI agents leverage
    multimodal capabilities, reinforcement learning, and memory-augmented architectures
    to adapt to diverse tasks. This evolution marks a shift from predictive models
    to truly autonomous systems capable of dynamic decision-making.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的 AI 的发展是从统计模型到深度学习，再到基于推理的系统的一种自然演进。现代 AI 代理利用多模态能力、强化学习和记忆增强架构来适应各种任务。这种演进标志着从预测模型到真正自主的系统，这些系统能够进行动态决策的转变。
- en: Looking ahead, AI agents will continue to refine their ability to reason, plan,
    and act within structured and unstructured environments. The rise of open-weight
    models, combined with advances in agent-based AI, will likely drive the next wave
    of innovations in AI, expanding its applications across science, engineering,
    and everyday life.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，AI 代理将继续完善其在结构和非结构化环境中的推理、规划和行动能力。开放权重模型的出现，结合基于代理的 AI 的进步，很可能会推动 AI 下一个创新浪潮，扩大其在科学、工程和日常生活中的应用。
- en: With frameworks like LangChain, developers can build complex and agentic structured
    systems that overcome the limitations of raw LLMs. It offers built-in solutions
    for memory management, tool integration, and multi-step reasoning that align with
    the ecosystem model presented here. In the next section we will explore how LangChain
    facilitates the development of production-ready AI agents.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像 LangChain 这样的框架，开发者可以构建复杂且具有代理能力的结构化系统，克服原始 LLM 的局限性。它提供了内置的内存管理、工具集成和多步推理解决方案，与这里提出的生态系统模型相一致。在下一节中，我们将探讨
    LangChain 如何促进生产就绪 AI 代理的开发。
- en: Introducing LangChain
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 LangChain
- en: LangChain exists as both an open-source framework and a venture-backed company.
    The framework, introduced in 2022 by Harrison Chase, streamlines the development
    of LLM-powered applications with support for multiple programming languages including
    Python, JavaScript/TypeScript, Go, Rust, and Ruby.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 作为一个开源框架和风险投资支持的公司存在。该框架由 Harrison Chase 于 2022 年推出，通过支持包括 Python、JavaScript/TypeScript、Go、Rust
    和 Ruby 在内的多种编程语言，简化了 LLM 驱动应用程序的开发。
- en: The company behind the framework, LangChain, Inc., is based in San Francisco
    and has secured significant venture funding through multiple rounds, including
    a Series A in February 2024\. With 11-50 employees, the company maintains and
    expands the framework while offering enterprise solutions for LLM application
    development.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 框架背后的公司 LangChain, Inc. 位于旧金山，并通过多轮融资获得了显著的风险投资，包括 2024 年 2 月的 A 轮融资。拥有
    11-50 名员工，该公司维护和扩展框架，同时提供企业级 LLM 应用程序开发解决方案。
- en: 'While the core framework remains open source, the company provides additional
    enterprise features and support for commercial users. Both share the same mission:
    accelerating LLM application development by providing robust tools and infrastructure.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然核心框架仍然是开源的，但公司为商业用户提供额外的企业功能和支持。两者拥有相同的使命：通过提供强大的工具和基础设施来加速LLM应用开发。
- en: Modern LLMs are undeniably powerful, but their practical utility in production
    applications is constrained by several inherent limitations. Understanding these
    challenges is essential for appreciating why frameworks like LangChain have become
    indispensable tools for AI developers.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现代LLMs无疑是强大的，但它们在生产应用中的实际效用受到几个固有局限性的限制。理解这些挑战对于理解为什么像LangChain这样的框架成为AI开发者不可或缺的工具至关重要。
- en: Challenges with raw LLMs
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原始LLMs的挑战
- en: 'Despite their impressive capabilities, LLMs face fundamental constraints that
    create significant hurdles for developers building real-world applications:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们的性能令人印象深刻，但大型语言模型（LLMs）面临着一些基本限制，这些限制为开发者构建现实世界应用设置了重大障碍：
- en: '**Context window limitations**: LLMs process text as tokens (subword units),
    not complete words. For example, “LangChain” might be processed as two tokens:
    “Lang” and “Chain.” Every LLM has a fixed context window—the maximum number of
    tokens it can process at once—typically ranging from 2,000 to 128,000 tokens.
    This creates several practical challenges:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**上下文窗口限制**：LLMs将文本作为令牌（子词单元）处理，而不是完整的单词。例如，“LangChain”可能被处理为两个令牌：“Lang”和“Chain”。每个LLM都有一个固定的上下文窗口——它一次可以处理的令牌最大数量——通常在2,000到128,000个令牌之间。这带来了几个实际挑战：'
- en: '**Document processing**: Long documents must be chunked effectively to fit
    within context limits'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档处理**：长文档必须有效地分块，以适应上下文限制'
- en: '**Conversation history**: Maintaining information across extended conversations
    requires careful memory management'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对话历史**：在长时间对话中保持信息需要仔细的记忆管理'
- en: '**Cost management**: Most providers charge based on token count, making efficient
    token use a business imperative'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成本管理**：大多数提供商根据令牌数量收费，因此高效使用令牌成为一项商业必要条件'
- en: These constraints directly impact application architecture, making techniques
    like RAG (which we’ll explore in [*Chapter 4*](E_Chapter_4.xhtml#_idTextAnchor152))
    essential for production systems.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这些限制直接影响了应用架构，使得像RAG（我们将在[*第4章*](E_Chapter_4.xhtml#_idTextAnchor152))这样的技术对于生产系统变得至关重要。
- en: '**Limited tool orchestration**: While many modern LLMs offer native tool-calling
    capabilities, they lack the infrastructure to discover appropriate tools, execute
    complex workflows, and manage tool interactions across multiple turns. Without
    this orchestration layer, developers must build custom solutions for each integration.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**有限的工具编排**：虽然许多现代LLMs提供了原生的工具调用功能，但它们缺乏发现适当工具、执行复杂工作流程和管理跨多个回合的工具交互的基础设施。没有这个编排层，开发者必须为每个集成构建定制的解决方案。'
- en: '**Task coordination challenges**: Managing multi-step workflows with LLMs requires
    structured control mechanisms. Without them, complex processes involving sequential
    reasoning or decision-making become difficult to implement reliably.'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**任务协调挑战**：使用LLMs管理多步骤工作流程需要结构化的控制机制。没有这些机制，涉及顺序推理或决策的复杂过程难以可靠地实施。'
- en: 'Tools in this context refer to functional capabilities that extend an LLM’s
    reach: web browsers for searching the internet, calculators for precise mathematics,
    coding environments for executing programs, or APIs for accessing external services
    and databases. Without these tools, LLMs remain confined to operating within their
    training knowledge, unable to perform real-world actions or access current information.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 工具在此上下文中指的是扩展LLM功能的能力：用于搜索互联网的网页浏览器、用于精确数学的计算机、用于执行程序的编码环境或用于访问外部服务和数据库的API。没有这些工具，LLMs将局限于在其训练知识范围内操作，无法执行现实世界的行动或访问当前信息。
- en: These fundamental limitations create three key challenges for developers working
    with raw LLM APIs, as demonstrated in the following table.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基本限制为使用原始LLM API的开发者带来了三个关键挑战，如下表所示。
- en: '| **Challenge** | **Description** | **Impact** |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| **挑战** | **描述** | **影响** |'
- en: '| **Reliability** | Detecting hallucinations and validating outputs | Inconsistent
    results that may require human verification |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| **可靠性** | 检测幻觉并验证输出 | 可能需要人工验证的不一致结果 |'
- en: '| **Resource Management** | Handling context windows and rate limits | Implementation
    complexity and potential cost overruns |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| **资源管理** | 处理上下文窗口和速率限制 | 实现复杂性和潜在的成本超支 |'
- en: '| **Integration Complexity** | Building connections to external tools and data
    sources | Extended development time and maintenance burden |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| **集成复杂性** | 建立与外部工具和数据源的联系 | 延长的开发时间和维护负担 |'
- en: 'Table 1.3: Three key developer challenges'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.3：三个关键的开发者挑战
- en: LangChain addresses these challenges by providing a structured framework with
    tested solutions, simplifying AI application development and enabling more sophisticated
    use cases.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain通过提供具有测试解决方案的结构化框架，简化了AI应用开发，并使更复杂的使用案例成为可能。
- en: How LangChain enables agent development
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain如何实现代理开发
- en: 'LangChain provides the foundational infrastructure for building sophisticated
    AI applications through its modular architecture and composable patterns. With
    the evolution to version 0.3, LangChain has refined its approach to creating intelligent
    systems:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain通过其模块化架构和可组合模式，为构建复杂的AI应用提供了基础基础设施。随着版本0.3的演进，LangChain对其创建智能系统的方法进行了优化：
- en: '**Composable workflows**: The **LangChain Expression Language** (**LCEL**)
    allows developers to break down complex tasks into modular components that can
    be assembled and reconfigured. This composability enables systematic reasoning
    through the orchestration of multiple processing steps.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可组合工作流程**：**LangChain表达式语言**（**LCEL**）允许开发者将复杂任务分解为模块化组件，这些组件可以组装和重新配置。这种可组合性通过多个处理步骤的编排，实现了系统性的推理。'
- en: '**Integration ecosystem**: LangChain offers battle-tested abstract interfaces
    for all generative AI components (LLMs, embeddings, vector databases, document
    loaders, search engines). This lets you build applications that can easily switch
    between providers without rewriting core logic.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成生态系统**：LangChain为所有生成式AI组件（LLMs、嵌入、向量数据库、文档加载器、搜索引擎）提供了经过实战检验的抽象接口。这使得您能够构建可以轻松在提供者之间切换而无需重写核心逻辑的应用程序。'
- en: '**Unified model access**: The framework provides consistent interfaces to diverse
    language and embedding models, allowing seamless switching between providers while
    maintaining application logic.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一模型访问**：该框架为各种语言和嵌入模型提供了一致的接口，允许在保持应用程序逻辑的同时，在提供者之间无缝切换。'
- en: 'While earlier versions of LangChain handled memory management directly, version
    0.3 takes a more specialized approach to application development:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LangChain的早期版本直接处理内存管理，但版本0.3采用了更专业的方法来开发应用程序：
- en: '**Memory and state management**: For applications requiring persistent context
    across interactions, LangGraph now serves as the recommended solution. LangGraph
    maintains conversation history and application state with purpose-built persistence
    mechanisms.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存和状态管理**：对于需要跨交互持久上下文的应用程序，LangGraph现在作为推荐解决方案。LangGraph使用专门设计的持久机制维护对话历史和应用程序状态。'
- en: '**Agent architecture**: Though LangChain contains agent implementations, LangGraph
    has become the preferred framework for building sophisticated agents. It provides:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理架构**：尽管LangChain包含代理实现，但LangGraph已成为构建复杂代理的首选框架。它提供：'
- en: Graph-based workflow definition for complex decision paths
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于图的复杂决策路径工作流程定义
- en: Persistent state management across multiple interactions
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多次交互中的持久状态管理
- en: Streaming support for real-time feedback during processing
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理过程中的实时反馈流支持
- en: Human-in-the-loop capabilities for validation and corrections
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工验证和校正能力
- en: Together, LangChain and its companion projects like LangGraph and LangSmith
    form a comprehensive ecosystem that transforms LLMs from simple text generators
    into systems capable of sophisticated real-world tasks, combining strong abstractions
    with practical implementation patterns optimized for production use.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 与其配套项目如LangGraph和LangSmith一起，LangChain形成了一个全面的生态系统，将LLM从简单的文本生成器转变为能够执行复杂现实任务的系统，结合了强大的抽象和针对生产使用优化的实用实现模式。
- en: Exploring the LangChain architecture
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索LangChain架构
- en: 'LangChain’s philosophy centers on composability and modularity. Rather than
    treating LLMs as standalone services, LangChain views them as components that
    can be combined with other tools and services to create more capable systems.
    This approach is built on several principles:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain的哲学核心在于可组合性和模块化。它不是将LLM视为独立的服务，而是将其视为可以与其他工具和服务结合以创建更强大系统的组件。这种方法基于几个原则：
- en: '**Modular architecture**: Every component is designed to be reusable and interchangeable,
    allowing developers to integrate LLMs seamlessly into various applications. This
    modularity extends beyond LLMs to include numerous building blocks for developing
    complex generative AI applications.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模块化架构**：每个组件都设计为可重用和可互换的，使开发者能够无缝地将 LLMs 集成到各种应用中。这种模块化不仅限于 LLMs，还包括开发复杂生成式
    AI 应用程序的大量构建块。'
- en: '**Support for agentic workflows**: LangChain offers best-in-class APIs that
    allow you to develop sophisticated agents quickly. These agents can make decisions,
    use tools, and solve problems with minimal development overhead.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持代理工作流程**：LangChain 提供了业界领先的 API，允许您快速开发复杂的代理。这些代理可以做出决策，使用工具，并以最小的开发开销解决问题。'
- en: '**Production readiness**: The framework provides built-in capabilities for
    tracing, evaluation, and deployment of generative AI applications, including robust
    building blocks for managing memory and persistence across interactions.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产就绪**：该框架提供了内置的跟踪、评估和部署生成式 AI 应用程序的能力，包括管理交互中内存和持久性的强大构建块。'
- en: '**Broad vendor ecosystem**: LangChain offers battle-tested abstract interfaces
    for all generative AI components (LLMs, embeddings, vector databases, document
    loaders, search engines, etc.). Vendors develop their own integrations that comply
    with these interfaces, allowing you to build applications on top of any third-party
    provider and easily switch between them.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛的供应商生态系统**：LangChain 为所有生成式 AI 组件（LLMs、嵌入、向量数据库、文档加载器、搜索引擎等）提供了经过实战检验的抽象接口。供应商开发自己的集成，以符合这些接口，允许您在任意第三方提供商之上构建应用程序，并轻松地在它们之间切换。'
- en: It’s worth noting that there’ve been major changes since LangChain version 0.1
    when the first edition of this book was written. While early versions attempted
    to handle everything, LangChain version 0.3 focuses on excelling at specific functions
    with companion projects handling specialized needs. LangChain manages model integration
    and workflows, while LangGraph handles stateful agents and LangSmith provides
    observability.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，自从本书第一版撰写时 LangChain 版本 0.1 以来，已经发生了重大变化。虽然早期版本试图处理所有事情，但 LangChain 版本
    0.3 专注于在特定功能上表现出色，而伴随项目则处理专门需求。LangChain 负责模型集成和工作流程管理，LangGraph 负责有状态的代理，LangSmith
    提供可观察性。
- en: LangChain’s memory management, too, has gone through major changes. Memory mechanisms
    within the base LangChain library have been deprecated in favor of LangGraph for
    persistence, and while agents are present, LangGraph is the recommended approach
    for their creation in version 0.3\. However, models and tools continue to be fundamental
    to LangChain’s functionality. In [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107),
    we’ll explore LangChain and LangGraph’s memory mechanisms.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的内存管理也经历了重大变化。基 LangChain 库内的内存机制已被弃用，转而使用 LangGraph 进行持久化，尽管存在代理，但在版本
    0.3 中，LangGraph 是创建代理的首选方法。然而，模型和工具仍然是 LangChain 功能的基础。在 [*第 3 章*](E_Chapter_3.xhtml#_idTextAnchor107)
    中，我们将探讨 LangChain 和 LangGraph 的内存机制。
- en: To translate model design principles into practical tools, LangChain has developed
    a comprehensive ecosystem of libraries, services, and applications. This ecosystem
    provides developers with everything they need to build, deploy, and maintain sophisticated
    AI applications. Let’s examine the components that make up this thriving environment
    and how they’ve gained adoption across the industry.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将模型设计原则转化为实用工具，LangChain 开发了一个全面的库、服务和应用程序生态系统。这个生态系统为开发者提供了构建、部署和维护复杂 AI
    应用程序所需的一切。让我们来审视构成这个繁荣环境的组件，以及它们如何在整个行业中得到采用。
- en: Ecosystem
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生态系统
- en: LangChain has achieved impressive ecosystem metrics, demonstrating strong market
    adoption with over 20 million monthly downloads and powering more than 100,000
    applications. Its open-source community is thriving, evidenced by 100,000+ GitHub
    stars and contributions from over 4,000 developers. This scale of adoption positions
    LangChain as a leading framework in the AI application development space, particularly
    for building reasoning-focused LLM applications. The framework’s modular architecture
    (with components like LangGraph for agent workflows and LangSmith for monitoring)
    has clearly resonated with developers building production AI systems across various
    industries.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain已经实现了令人印象深刻的生态系统指标，显示出强大的市场采用度，月下载量超过2000万次，并支持超过10万个应用。其开源社区蓬勃发展，由10万多个GitHub星标和来自4000多名开发者的贡献所证明。这种采用规模使LangChain成为AI应用开发领域的领先框架，尤其是在构建以推理为重点的LLM应用方面。该框架的模块化架构（如LangGraph用于代理工作流程和LangSmith用于监控）显然与各行各业构建生产级AI系统的开发者产生了共鸣。
- en: '**Core libraries**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**核心库**'
- en: 'LangChain (Python): Reusable components for building LLM applications'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain（Python）：构建LLM应用的可重用组件
- en: 'LangChain.js: JavaScript/TypeScript implementation of the framework'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain.js：框架的JavaScript/TypeScript实现
- en: 'LangGraph (Python): Tools for building LLM agents as orchestrated graphs'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangGraph（Python）：构建LLM代理作为编排图的工具
- en: 'LangGraph.js: JavaScript implementation for agent workflows'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangGraph.js：用于代理工作流程的JavaScript实现
- en: '**Platform services**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**平台服务**'
- en: 'LangSmith: Platform for debugging, testing, evaluating, and monitoring LLM
    applications'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangSmith：用于调试、测试、评估和监控LLM应用的平台
- en: 'LangGraph: Infrastructure for deploying and scaling LangGraph agents'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangGraph：部署和扩展LangGraph代理的基础设施
- en: '**Applications and extensions**'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用和扩展**'
- en: 'ChatLangChain: Documentation assistant for answering questions about the framework'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatLangChain：框架问答文档助手
- en: 'Open Canvas: Document and chat-based UX for writing code/markdown (TypeScript)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Open Canvas：基于文档和聊天的代码/Markdown编写UX（TypeScript）
- en: 'OpenGPTs: Open source implementation of OpenAI’s GPTs API'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenGPTs：OpenAI的GPTs API的开源实现
- en: 'Email assistant: AI tool for email management (Python)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邮件助手：用于电子邮件管理的AI工具（Python）
- en: 'Social media agent: Agent for content curation and scheduling (TypeScript)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体代理：内容整理和排程代理（TypeScript）
- en: 'The ecosystem provides a complete solution for building reasoning-focused AI
    applications: from core building blocks to deployment platforms to reference implementations.
    This architecture allows developers to use components independently or stack them
    for fuller and more complete solutions.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 该生态系统为构建以推理为重点的AI应用提供了一套完整的解决方案：从核心构建块到部署平台再到参考实现。这种架构允许开发者独立使用组件，或将它们堆叠以获得更全面和完整的解决方案。
- en: From customer testimonials and company partnerships, LangChain is being adopted
    by enterprises like Rakuten, Elastic, Ally, and Adyen. Organizations report using
    LangChain and LangSmith to identify optimal approaches for LLM implementation,
    improve developer productivity, and accelerate development workflows.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 来自客户评价和公司合作，LangChain正在被Rakuten、Elastic、Ally和Adyen等企业采用。组织报告称，他们使用LangChain和LangSmith来确定LLM实施的优化方法，提高开发人员生产力，并加速开发工作流程。
- en: 'LangChain also offers a full stack for AI application development:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain还提供了一套完整的AI应用开发栈：
- en: '**Build**: with the composable framework'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建**：使用可组合框架'
- en: '**Run**: deploy with LangGraph Platform'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行**：使用LangGraph平台部署'
- en: '**Manage**: debug, test, and monitor with LangSmith'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理**：使用LangSmith进行调试、测试和监控'
- en: 'Based on our experience building with LangChain, here are some of its benefits
    we’ve found especially helpful:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们使用LangChain构建的经验，以下是一些我们认为特别有帮助的益处：
- en: '**Accelerated development cycles**: LangChain dramatically speeds up time-to-market
    with ready-made building blocks and unified APIs, eliminating weeks of integration
    work.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加速开发周期**：LangChain通过现成的构建块和统一的API，显著缩短了上市时间，消除了数周集成工作。'
- en: '**Superior observability**: The combination of LangChain and LangSmith provides
    unparalleled visibility into complex agent behavior, making trade-offs between
    cost, latency, and quality more transparent.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卓越的可观察性**：LangChain与LangSmith的结合为复杂代理行为提供了无与伦比的可见性，使成本、延迟和质量之间的权衡更加透明。'
- en: '**Controlled agency balance**: LangGraph’s approach to agentic AI is particularly
    powerful—allowing developers to give LLMs partial control flow over workflows
    while maintaining reliability and performance.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**受控代理平衡**: LangGraph 对代理式 AI 的方法特别强大——允许开发者赋予 LLMs 对工作流程的部分控制流，同时保持可靠性和性能。'
- en: '**Production-ready patterns**: Our implementation experience has proven that
    LangChain’s architecture delivers enterprise-grade solutions that effectively
    reduce hallucinations and improve system reliability.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产就绪模式**: 我们的实施经验证明，LangChain 的架构提供了企业级解决方案，有效减少了幻觉并提高了系统可靠性。'
- en: '**Future-proof flexibility**: The framework’s vendor-agnostic design creates
    applications that can adapt as the LLM landscape evolves, preventing technological
    lock-in.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未来兼容的灵活性**: 框架的供应商无关设计创建的应用程序可以随着 LLM 领域的发展而适应，防止技术锁定。'
- en: These advantages stem directly from LangChain’s architectural decisions, which
    prioritize modularity, observability, and deployment flexibility for real-world
    applications.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这些优势直接源于 LangChain 的架构决策，这些决策优先考虑了模块化、可观察性和实际应用的部署灵活性。
- en: Modular design and dependency management
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模块化设计和依赖管理
- en: LangChain evolves rapidly, with approximately 10-40 pull requests merged daily.
    This fast-paced development, combined with the framework’s extensive integration
    ecosystem, presents unique challenges. Different integrations often require specific
    third-party Python packages, which can lead to dependency conflicts.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 发展迅速，每天大约合并 10-40 个拉取请求。这种快速的开发节奏，加上框架广泛的集成生态系统，带来了独特的挑战。不同的集成通常需要特定的第三方
    Python 包，这可能导致依赖项冲突。
- en: LangChain’s package architecture evolved as a direct response to scaling challenges.
    As the framework rapidly expanded to support hundreds of integrations, the original
    monolithic structure became unsustainable—forcing users to install unnecessary
    dependencies, creating maintenance bottlenecks, and hindering contribution accessibility.
    By dividing into specialized packages with lazy loading of dependencies, LangChain
    elegantly solved these issues while preserving a cohesive ecosystem. This architecture
    allows developers to import only what they need, reduces version conflicts, enables
    independent release cycles for stable versus experimental features, and dramatically
    simplifies the contribution path for community developers working on specific
    integrations.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的包架构是作为对扩展挑战的直接回应而演化的。随着框架迅速扩展以支持数百个集成，原始的单体结构变得不可持续——迫使用户安装不必要的依赖项，造成维护瓶颈，并阻碍了贡献的可达性。通过划分为具有依赖项懒加载的专用包，LangChain
    优雅地解决了这些问题，同时保持了统一的生态系统。这种架构允许开发者仅导入他们需要的部分，减少版本冲突，为稳定与实验性功能提供独立的发布周期，并极大地简化了社区开发者针对特定集成的工作贡献路径。
- en: 'The LangChain codebase follows a well-organized structure that separates concerns
    while maintaining a cohesive ecosystem:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的代码库遵循一个组织良好的结构，在分离关注点的同时保持一个统一的生态系统：
- en: '**Core structure**'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**核心结构**'
- en: '`docs/`: Documentation resources for developers'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docs/`: 为开发者提供的文档资源'
- en: '`libs/`: Contains all library packages in the monorepo'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`libs/`: 包含 monorepo 中的所有库包'
- en: '**Library organization**'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**库组织**'
- en: '`langchain-core/`: Foundational abstractions and interfaces that define the
    framework'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-core/`: 定义框架的基础抽象和接口'
- en: '`langchain/`: The main implementation library with core components:'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain/`: 包含核心组件的主要实现库：'
- en: '`vectorstores/`: Integrations with vector databases (Pinecone, Chroma, etc.)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vectorstores/`: 与向量数据库（Pinecone、Chroma 等）的集成'
- en: '`chains/`: Pre-built chain implementations for common workflows'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chains/`: 为常见工作流程预构建的链实现'
- en: Other component directories for retrievers, embeddings, etc.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 其他用于检索器、嵌入等组件的组件目录
- en: '`langchain-experimental/`: Cutting-edge features still under development'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-experimental/`: 正在开发中的前沿特性'
- en: '**langchain-community**: Houses third-party integrations maintained by the
    LangChain community. This includes most integrations for components like LLMs,
    vector stores, and retrievers. Dependencies are optional to maintain a lightweight
    package.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**langchain-community**: 由 LangChain 社区维护的第三方集成。这包括大多数针对 LLMs、向量存储和检索器的集成。依赖项是可选的，以保持轻量级的包。'
- en: '**Partner packages**: Popular integrations are separated into dedicated packages
    (e.g., **langchain-openai**, **langchain-anthropic**) to enhance independent support.
    These packages reside outside the LangChain repository but within the GitHub “langchain-ai”
    organization (see [github.com/orgs/langchain-ai](https://github.com/langchain-ai)).
    A full list is available at [python.langchain.com/v0.3/docs/integrations/platforms/](https://python.langchain.com/docs/integrations/providers/).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合作伙伴包**：流行的集成被分离到专门的包中（例如，**langchain-openai**，**langchain-anthropic**）以增强独立支持。这些包位于
    LangChain 存储库之外，但在 GitHub “langchain-ai” 组织内（见 [github.com/orgs/langchain-ai](https://github.com/langchain-ai)）。完整列表可在
    [python.langchain.com/v0.3/docs/integrations/platforms/](https://python.langchain.com/docs/integrations/providers/)
    上找到。'
- en: '**External partner packages**: Some partners maintain their integration packages
    independently. For example, several packages from the Google organization ([github.com/orgs/googleapis/repositories?q=langchain](https://github.com/orgs/googleapis/repositories?q=langchain)),
    such as the `langchain-google-cloud-sql-mssql` package, are developed and maintained
    outside the LangChain ecosystem.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部合作伙伴包**：一些合作伙伴独立维护他们的集成包。例如，来自 Google 组织的几个包（[github.com/orgs/googleapis/repositories?q=langchain](https://github.com/orgs/googleapis/repositories?q=langchain)），如
    `langchain-google-cloud-sql-mssql` 包，是在 LangChain 生态系统之外开发和维护的。'
- en: '![Figure 1.2: Integration ecosystem map](img/B32363_01_02.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2：集成生态系统图](img/B32363_01_02.png)'
- en: 'Figure 1.2: Integration ecosystem map'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：集成生态系统图
- en: 'For full details on the dozens of available modules and packages, refer to
    the comprehensive LangChain API reference: [https://api.python.langchain.com/](https://api.python.langchain.com/).
    There are also hundreds of code examples demonstrating real-world use cases: [https://python.langchain.com/v0.1/docs/use_cases/](https://python.langchain.com/v0.1/docs/use_cases/).'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数十个可用模块和包的详细信息，请参阅全面的 LangChain API 参考文档：[https://api.python.langchain.com/](https://api.python.langchain.com/).
    此外，还有数百个代码示例展示了实际应用场景：[https://python.langchain.com/v0.1/docs/use_cases/](https://python.langchain.com/v0.1/docs/use_cases/).
- en: LangGraph, LangSmith, and companion tools
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LangGraph、LangSmith 和配套工具
- en: 'LangChain’s core functionality is extended by the following companion projects:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的核心功能通过以下配套项目得到扩展：
- en: '**LangGraph**: An orchestration framework for building stateful, multi-actor
    applications with LLMs. While it integrates smoothly with LangChain, it can also
    be used independently. LangGraph facilitates complex applications with cyclic
    data flows and supports streaming and human-in-the-loop interactions. We’ll talk
    about LangGraph in more detail in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LangGraph**：一个用于构建具有状态、多参与者应用的编排框架，使用 LLMs。虽然它与 LangChain 集成顺畅，但也可以独立使用。LangGraph
    促进了具有循环数据流的复杂应用程序，并支持流式传输和人工交互。我们将在[*第 3 章*](E_Chapter_3.xhtml#_idTextAnchor107)中更详细地讨论
    LangGraph。'
- en: '**LangSmith**: A platform that complements LangChain by providing robust debugging,
    testing, and monitoring capabilities. Developers can inspect, monitor, and evaluate
    their applications, ensuring continuous optimization and confident deployment.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LangSmith**：一个通过提供强大的调试、测试和监控功能来补充 LangChain 的平台。开发者可以检查、监控和评估他们的应用程序，确保持续优化和自信部署。'
- en: These extensions, along with the core framework, provide a comprehensive ecosystem
    for developing, managing, and visualizing LLM applications, each with unique capabilities
    that enhance functionality and user experience.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这些扩展以及核心框架提供了一套全面的生态系统，用于开发、管理和可视化 LLM 应用程序，每个都具有独特的功能，增强了功能和用户体验。
- en: LangChain also has an extensive array of tool integrations, which we’ll discuss
    in detail in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231). New integrations
    are added regularly, expanding the framework’s capabilities across domains.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 还拥有广泛的工具集成，我们将在[*第 5 章*](E_Chapter_5.xhtml#_idTextAnchor231)中详细讨论。新集成定期添加，扩展了框架在各个领域的功能。
- en: Third-party applications and visual tools
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第三方应用程序和可视化工具
- en: 'Many third-party applications have been built on top of or around LangChain.
    For example, LangFlow and Flowise introduce visual interfaces for LLM development,
    with UIs that allow for the drag-and-drop assembly of LangChain components into
    executable workflows. This visual approach enables rapid prototyping and experimentation,
    lowering the barrier to entry for complex pipeline creation, as illustrated in
    the following screenshot of Flowise:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 许多第三方应用都是基于LangChain构建的。例如，LangFlow和Flowise引入了LLM开发的可视化界面，具有允许将LangChain组件拖放到可执行工作流程中的UI。这种可视化方法使得快速原型设计和实验成为可能，降低了创建复杂管道的门槛，如下面的Flowise截图所示：
- en: '![Figure 1.3: Flowise UI with an agent that uses an LLM, a calculator, and
    a search tool (Source: https://github.com/FlowiseAI/Flowise)](img/B32363_01_03.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3：使用LLM、计算器和搜索工具的代理的Flowise UI（来源：https://github.com/FlowiseAI/Flowise）](img/B32363_01_03.png)'
- en: 'Figure 1.3: Flowise UI with an agent that uses an LLM, a calculator, and a
    search tool (Source: https://github.com/FlowiseAI/Flowise)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：使用LLM、计算器和搜索工具的代理的Flowise UI（来源：https://github.com/FlowiseAI/Flowise）
- en: In the UI above, you can see an agent connected to a search interface (Serp
    API), an LLM, and a calculator. LangChain and similar tools can be deployed locally
    using libraries like Chainlit, or on various cloud platforms, including Google
    Cloud.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的UI中，你可以看到一个连接到搜索界面（Serp API）、LLM和计算器的代理。LangChain和类似工具可以使用Chainlit等库在本地部署，或者在包括Google
    Cloud在内的各种云平台上部署。
- en: In summary, LangChain simplifies the development of LLM applications through
    its modular design, extensive integrations, and supportive ecosystem. This makes
    it an invaluable tool for developers looking to build sophisticated AI systems
    without reinventing fundamental components.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，LangChain通过其模块化设计、广泛的集成和支持性生态系统简化了LLM应用的开发。这使得它成为开发者构建复杂人工智能系统而不必重新发明基本组件的无价之宝。
- en: Summary
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced the modern LLM landscape and positioned LangChain as
    a powerful framework for building production-ready AI applications. We explored
    the limitations of raw LLMs and then showed how these frameworks transform models
    into reliable, agentic systems capable of solving complex real-world problems.
    We also examined the LangChain ecosystem’s architecture, including its modular
    components, package structure, and companion projects that support the complete
    development lifecycle. By understanding the relationship between LLMs and the
    frameworks that extend them, you’re now equipped to build applications that go
    beyond simple text generation.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了现代LLM的格局，并将LangChain定位为构建生产就绪人工智能应用的有力框架。我们探讨了原始LLM的限制，然后展示了这些框架如何将模型转化为可靠、智能的系统，能够解决复杂现实世界问题。我们还考察了LangChain生态系统架构，包括其模块化组件、包结构和支持完整开发生命周期的配套项目。通过理解LLM及其扩展框架之间的关系，你现在可以构建超越简单文本生成的应用。
- en: In the next chapter, we’ll set up our development environment and take our first
    steps with LangChain, translating the conceptual understanding from this chapter
    into working code. You’ll learn how to connect to various LLM providers, create
    your first chains, and begin implementing the patterns that form the foundation
    of enterprise-grade AI applications.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将设置我们的开发环境，并使用LangChain迈出第一步，将本章的概念理解转化为实际代码。你将学习如何连接到各种LLM提供商，创建你的第一个链，并开始实现构成企业级人工智能应用基础的模式。
- en: Questions
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the three primary limitations of raw LLMs that impact production applications,
    and how does LangChain address each one?
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原始LLM的三个主要限制是什么，它们如何影响生产应用，以及LangChain如何解决每一个问题？
- en: Compare and contrast open-source and closed-source LLMs in terms of deployment
    options, cost considerations, and use cases. When might you choose each type?
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从部署选项、成本考虑和使用案例等方面比较开源和闭源LLM。你可能在什么情况下选择每种类型？
- en: What is the difference between a LangChain chain and a LangGraph agent? When
    would you choose one over the other?
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain链和LangGraph代理之间的区别是什么？在什么情况下你会选择其中一个而不是另一个？
- en: Explain how LangChain’s modular architecture supports the rapid development
    of AI applications. Provide an example of how this modularity might benefit an
    enterprise use case.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释LangChain模块化架构如何支持人工智能应用的快速开发。提供一个例子说明这种模块化如何使企业用例受益。
- en: What are the key components of the LangChain ecosystem, and how do they work
    together to support the development lifecycle from building to deployment to monitoring?
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain生态系统的关键组件是什么，它们是如何协同工作以支持从构建到部署再到监控的开发生命周期的？
- en: How does agentic AI differ from traditional LLM applications? Describe a business
    scenario where an agent would provide significant advantages over a simple chain.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理式AI与传统LLM应用有何不同？描述一个代理相对于简单链能提供显著优势的商业场景。
- en: What factors should you consider when selecting an LLM provider for a production
    application? Name at least three considerations beyond just model performance.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在为生产应用程序选择LLM提供商时，应考虑哪些因素？请列出至少三个除了模型性能之外的考虑因素。
- en: How does LangChain help address common challenges like hallucinations, context
    limitations, and tool integration that affect all LLM applications?
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain如何帮助解决所有LLM应用程序都面临的常见挑战，如幻觉、上下文限制和工具集成？
- en: Explain how the LangChain package structure (`langchain-core`, `langchain`,
    `langchain-community`) affects dependency management and integration options in
    your applications.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释LangChain包结构（`langchain-core`，`langchain`，`langchain-community`）如何影响应用程序中的依赖管理和集成选项。
- en: What role does LangSmith play in the development lifecycle of production LangChain
    applications?
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangSmith在生产LangChain应用程序的生命周期中扮演什么角色？
