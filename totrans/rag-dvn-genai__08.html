<html><head></head><body>
  <div id="_idContainer090" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">8</span></h1>
    <h1 id="_idParaDest-203" class="chapterTitle"><span class="koboSpan" id="kobo.2.1">Dynamic RAG with Chroma and Hugging Face Llama</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.3.1">This chapter will take you into the pragmatism of dynamic RAG. </span><span class="koboSpan" id="kobo.3.2">In today’s rapidly evolving landscape, the ability to make swift, informed decisions is more crucial than ever. </span><span class="koboSpan" id="kobo.3.3">Decision-makers across various fields—from healthcare and scientific research to customer service management—increasingly require real-time data that is relevant only within the short period it is needed. </span><span class="koboSpan" id="kobo.3.4">A meeting may only require temporary yet highly prepared data. </span><span class="koboSpan" id="kobo.3.5">Hence, the concept of data permanence is shifting. </span><span class="koboSpan" id="kobo.3.6">Not all information must be stored indefinitely; instead, in many cases, the focus is shifting toward using precise, pertinent data tailored for specific needs at specific times, such as daily briefings or critical meetings.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.4.1">This chapter introduces an innovative and efficient approach to handling such data through the embedding and creation of temporary Chroma collections. </span><span class="koboSpan" id="kobo.4.2">Each morning, a new collection is assembled containing just the necessary data for that day’s meetings, effectively avoiding long-term data accumulation and management overhead. </span><span class="koboSpan" id="kobo.4.3">This data might include medical reports for a healthcare team discussing patient treatments, customer interactions for service teams strategizing on immediate issues, or the latest scientific research data for researchers making day-to-day experimental decisions. </span><span class="koboSpan" id="kobo.4.4">We will then build a Python program to support dynamic and efficient decision-making in daily meetings, applying a methodology using a hard science (any of the natural or physical sciences) dataset for a daily meeting. </span><span class="koboSpan" id="kobo.4.5">This approach will highlight the flexibility and efficiency of modern data management. </span><span class="koboSpan" id="kobo.4.6">In this case, the team wants to obtain pertinent scientific information without searching the web or interacting with online AI assistants. </span><span class="koboSpan" id="kobo.4.7">The constraint is to have a free, open-source assistant that anyone can use, which is why we will use Chroma and Hugging Face resources.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.5.1">The first step is to create a temporary Chroma collection. </span><span class="koboSpan" id="kobo.5.2">We will simulate the processing of a fresh dataset compiled daily, tailored to the specific agenda of upcoming meetings, ensuring relevance and conciseness. </span><span class="koboSpan" id="kobo.5.3">In this case, we will download the SciQ dataset from Hugging Face, which contains thousands of crowdsourced science questions, such as those related to physics, chemistry, and biology. </span><span class="koboSpan" id="kobo.5.4">Then, the program will embed the relevant data required for the day, guaranteeing that all discussion points are backed by the latest, most relevant data. </span></p>
    <p class="normal"><span class="koboSpan" id="kobo.6.1">A user might choose to run queries before the meetings to confirm their accuracy and alignment with the day’s objective. </span><span class="koboSpan" id="kobo.6.2">Finally, as meetings progress, any arising questions trigger real-time data retrieval, augmented through </span><strong class="keyWord"><span class="koboSpan" id="kobo.7.1">Large Language Model Meta AI</span></strong><span class="koboSpan" id="kobo.8.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.9.1">Llama</span></strong><span class="koboSpan" id="kobo.10.1">) technology to generate dynamic flashcards. </span><span class="koboSpan" id="kobo.10.2">These flashcards provide quick and precise responses to ensure discussions are both productive and informed. </span><span class="koboSpan" id="kobo.10.3">By the end of this chapter, you will have acquired the skills to implement open-source free dynamic RAG in a wide range of domains.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.11.1">To sum that up, this chapter covers the following topics:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.12.1">The architecture of dynamic RAG</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.13.1">Preparing a dataset for dynamic RAG</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.14.1">Creating a Chroma collection</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.15.1">Embedding and upserting data in a Chroma collection</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.16.1">Batch-querying a collection</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.17.1">Querying a collection with a user request</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.18.1">Augmenting the input with the output of a query</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.19.1">Configuring Hugging Face’s framework for Meta Llama</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.20.1">Generating a response based on the augmented input</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.21.1">Let’s begin by going through the architecture of dynamic RAG.</span></p>
    <h1 id="_idParaDest-204" class="heading-1"><span class="koboSpan" id="kobo.22.1">The architecture of dynamic RAG</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.23.1">Imagine you’re in a</span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.24.1"> dynamic environment in which information changes daily. </span><span class="koboSpan" id="kobo.24.2">Each morning, you gather a fresh batch of 10,000+ questions and validated answers from across the globe. </span><span class="koboSpan" id="kobo.24.3">The challenge is to access this information quickly and effectively during meetings without needing long-term storage or complicated infrastructure.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.25.1">This dynamic RAG method allows us to maintain a lean, responsive system that provides up-to-date information without the burden of ongoing data storage. </span><span class="koboSpan" id="kobo.25.2">It’s perfect for environments where data relevance is short-lived but critical for decision-making.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.26.1">We will be applying this to a</span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.27.1"> hard science dataset. </span><span class="koboSpan" id="kobo.27.2">However, this dynamic approach isn’t limited to our specific example. </span><span class="koboSpan" id="kobo.27.3">It has broad applications across various domains, such as:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.28.1">Customer support</span></strong><span class="koboSpan" id="kobo.29.1">: Daily</span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.30.1"> updated FAQs can be accessed in real-time to provide quick responses to customer inquiries.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.31.1">Healthcare</span></strong><span class="koboSpan" id="kobo.32.1">: During meetings, medical teams can use the latest research and patient data to answer complex health-related questions.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.33.1">Finance</span></strong><span class="koboSpan" id="kobo.34.1">: Financial analysts can query the latest market data to make informed decisions on investments and strategies.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.35.1">Education</span></strong><span class="koboSpan" id="kobo.36.1">: Educators can access the latest educational resources and research to answer questions and enhance learning.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.37.1">Tech support</span></strong><span class="koboSpan" id="kobo.38.1">: IT teams can use updated technical documentation to solve issues and guide users effectively.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.39.1">Sales and marketing</span></strong><span class="koboSpan" id="kobo.40.1">: Teams can quickly access the latest product information and market trends to answer client queries and strategize.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.41.1">This chapter implements one type of a dynamic RAG ecosystem. </span><span class="koboSpan" id="kobo.41.2">Your imagination is the limit, so feel free to apply this ecosystem to your own projects in different ways. </span><span class="koboSpan" id="kobo.41.3">For now, let’s see how the dynamic RAG components fit into the ecosystem we described in </span><em class="chapterRef"><span class="koboSpan" id="kobo.42.1">Chapter 1</span></em><span class="koboSpan" id="kobo.43.1">, </span><em class="italic"><span class="koboSpan" id="kobo.44.1">Why Retrieval Augmented Generation?</span></em><span class="koboSpan" id="kobo.45.1">, in the </span><em class="italic"><span class="koboSpan" id="kobo.46.1">RAG ecosystem</span></em><span class="koboSpan" id="kobo.47.1"> section.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.48.1">We will streamline the integration and use of dynamic information in real-time decision-making contexts, such as daily meetings, in Python. </span><span class="koboSpan" id="kobo.48.2">Here’s a breakdown of this innovative strategy for each component and its ecosystem component label:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.49.1"><img src="../Images/B31169_08_01.png" alt="A diagram of a diagram  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.50.1">Figure 8.1: The dynamic RAG system</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.51.1">Temporary Chroma collection creation (D1, D2, D3, E2)</span></strong><span class="koboSpan" id="kobo.52.1">: Every morning, a temporary Chroma collection is set up specifically for that day’s meeting. </span><span class="koboSpan" id="kobo.52.2">This collection is not </span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.53.1">meant to be saved post-meeting, serving only the day’s immediate needs and ensuring that data does not clutter the system in the long term.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.54.1">Embedding relevant data (D1, D2, D3, E2)</span></strong><span class="koboSpan" id="kobo.55.1">: The collection embeds critical data, such as customer support interactions, medical reports, or scientific facts. </span><span class="koboSpan" id="kobo.55.2">This embedding process tailors the content specifically to the meeting agenda, ensuring that all pertinent information is at the fingertips of the meeting participants. </span><span class="koboSpan" id="kobo.55.3">The data could include human feedback from documents and possibly other generative AI systems.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.56.1">Pre-meeting data validation (D4)</span></strong><span class="koboSpan" id="kobo.57.1">: Before the meeting begins, a batch of queries is run against this temporary Chroma collection to ensure that all data is accurate and appropriately aligned with the meeting’s objectives, thereby facilitating a smooth and informed discussion.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.58.1">Real-time query handling (G1, G2, G3, G4)</span></strong><span class="koboSpan" id="kobo.59.1">: During the meeting, the system is designed to handle spontaneous queries from participants. </span><span class="koboSpan" id="kobo.59.2">A single question can trigger the retrieval of specific information, which is then used to augment Llama’s input, enabling it to generate flashcards dynamically. </span><span class="koboSpan" id="kobo.59.3">These flashcards are utilized to provide concise, accurate responses during the meeting, enhancing the efficiency and productivity of the discussion.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.60.1">We will be using Chroma, a powerful, open-source, AI-native vector database designed to store, manage, and search embedded vectors in collections. </span><span class="koboSpan" id="kobo.60.2">Chroma contains everything we need to start, and we can run it on our machine. </span><span class="koboSpan" id="kobo.60.3">It is also very suitable for applications involving LLMs. </span><span class="koboSpan" id="kobo.60.4">Chroma collections are thus suitable for a temporary, cost-effective, and real-time RAG system. </span><span class="koboSpan" id="kobo.60.5">The dynamic RAG architecture of this chapter implemented </span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.61.1">with Chroma is innovative and practical. </span><span class="koboSpan" id="kobo.61.2">Here are some key points to consider in this fast-moving world:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.62.1">Efficiency and cost-effectiveness</span></strong><span class="koboSpan" id="kobo.63.1">: Using Chroma for temporary storage and Llama for response generation ensures that the system is lightweight and doesn’t incur ongoing storage costs. </span><span class="koboSpan" id="kobo.63.2">This makes it ideal for environments where data is refreshed frequently and long-term storage isn’t necessary. </span><span class="koboSpan" id="kobo.63.3">It is very convincing for decision-makers who want lean systems.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.64.1">Flexibility</span></strong><span class="koboSpan" id="kobo.65.1">: The system’s ephemeral nature allows for the integration of new data daily, ensuring that the most up-to-date information is always available. </span><span class="koboSpan" id="kobo.65.2">This can be particularly valuable in fast-paced environments in which information changes rapidly.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.66.1">Scalability</span></strong><span class="koboSpan" id="kobo.67.1">: The approach is scalable to other similar datasets, provided they can be embedded and queried effectively. </span><span class="koboSpan" id="kobo.67.2">This makes it adaptable to various domains beyond the given example. </span><span class="koboSpan" id="kobo.67.3">Scaling is not only increasing volumes of data but also the ability to apply a framework to a wide range of domains and situations.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.68.1">User-friendliness</span></strong><span class="koboSpan" id="kobo.69.1">: The system’s design is straightforward, making it accessible to users who may not be deeply technical but need reliable answers quickly. </span><span class="koboSpan" id="kobo.69.2">This simplicity can enhance user engagement and satisfaction. </span><span class="koboSpan" id="kobo.69.3">Making users happy with cost-effective, transparent, and lightweight AI will surely boost their interest in RAG-driven generative AI.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.70.1">Let’s now begin building a dynamic RAG program.</span></p>
    <h1 id="_idParaDest-205" class="heading-1"><span class="koboSpan" id="kobo.71.1">Installing the environment</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.72.1">The environment </span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.73.1">focuses on open-source and free resources that we can run on our machine or a free Google Colab account. </span><span class="koboSpan" id="kobo.73.2">This chapter will run these resources on Google Colab with Hugging Face and Chroma.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.74.1">We will first install Hugging Face.</span></p>
    <h2 id="_idParaDest-206" class="heading-2"><span class="koboSpan" id="kobo.75.1">Hugging Face</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.76.1">We will implement Hugging </span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.77.1">Face’s open-source resources to download a dataset for the Llama model. </span><span class="koboSpan" id="kobo.77.2">Sign up at </span><a href="https://huggingface.co/"><span class="url"><span class="koboSpan" id="kobo.78.1">https://huggingface.co/</span></span></a><span class="koboSpan" id="kobo.79.1"> to obtain your</span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.80.1"> Hugging Face API token. </span><span class="koboSpan" id="kobo.80.2">If you are using Google Colab, you can create a Google Secret in the sidebar and activate it. </span><span class="koboSpan" id="kobo.80.3">If so, you</span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.81.1"> can comment the following cell—</span><code class="inlineCode"><span class="koboSpan" id="kobo.82.1"># Save your Hugging Face token in a secure location</span></code><span class="koboSpan" id="kobo.83.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.84.1">#1.Uncomment the following lines if you want to use Google Drive to retrieve your token</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.85.1">from</span></span><span class="koboSpan" id="kobo.86.1"> google.colab </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.87.1">import</span></span><span class="koboSpan" id="kobo.88.1"> drive
drive.mount(</span><span class="hljs-string"><span class="koboSpan" id="kobo.89.1">'/content/drive'</span></span><span class="koboSpan" id="kobo.90.1">)
f = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.91.1">open</span></span><span class="koboSpan" id="kobo.92.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.93.1">"drive/MyDrive/files/hf_token.txt"</span></span><span class="koboSpan" id="kobo.94.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.95.1">"r"</span></span><span class="koboSpan" id="kobo.96.1">)
access_token=f.readline().strip()
f.close()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.97.1">#2.Uncomment the following line if you want to enter your HF token manually</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.98.1">#access_token =[YOUR HF_TOKEN]</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.99.1">import</span></span><span class="koboSpan" id="kobo.100.1"> os
os.environ[</span><span class="hljs-string"><span class="koboSpan" id="kobo.101.1">'HF_TOKEN'</span></span><span class="koboSpan" id="kobo.102.1">] = access_token
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.103.1">The program first retrieves the Hugging Face API token. </span><span class="koboSpan" id="kobo.103.2">Make sure to store it in a safe place. </span><span class="koboSpan" id="kobo.103.3">You can choose to use Google Drive or enter it manually. </span><span class="koboSpan" id="kobo.103.4">Up to now, the installation seems to have run smoothly. </span><span class="koboSpan" id="kobo.103.5">We now install </span><code class="inlineCode"><span class="koboSpan" id="kobo.104.1">datasets</span></code><span class="koboSpan" id="kobo.105.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.106.1">!pip install datasets==</span><span class="hljs-number"><span class="koboSpan" id="kobo.107.1">2.20.0</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.108.1">However, there are conflicts, such as </span><code class="inlineCode"><span class="koboSpan" id="kobo.109.1">pyarrow</span></code><span class="koboSpan" id="kobo.110.1">, with Google Colab’s pre-installed version, which is more recent. </span><span class="koboSpan" id="kobo.110.2">These conflicts between fast-moving packages are frequent. </span><span class="koboSpan" id="kobo.110.3">When Hugging Face updates its packages, this conflict will not appear anymore. </span><span class="koboSpan" id="kobo.110.4">But other conflicts may appear. </span><span class="koboSpan" id="kobo.110.5">This conflict will not stop us from downloading datasets. </span><span class="koboSpan" id="kobo.110.6">If it did, we would have to uninstall Google Colab packages and reinstall </span><code class="inlineCode"><span class="koboSpan" id="kobo.111.1">pyarrow</span></code><span class="koboSpan" id="kobo.112.1">, but other dependencies may possibly create issues. </span><span class="koboSpan" id="kobo.112.2">We must accept these challenges, as explained in the </span><em class="italic"><span class="koboSpan" id="kobo.113.1">Setting up the environment</span></em><span class="koboSpan" id="kobo.114.1"> section in </span><em class="chapterRef"><span class="koboSpan" id="kobo.115.1">Chapter 2</span></em><span class="koboSpan" id="kobo.116.1">, </span><em class="italic"><span class="koboSpan" id="kobo.117.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.118.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.119.1">We will now install</span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.120.1"> Hugging Face’s </span><code class="inlineCode"><span class="koboSpan" id="kobo.121.1">transformers</span></code><span class="koboSpan" id="kobo.122.1"> package:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.123.1">!pip install transformers==</span><span class="hljs-number"><span class="koboSpan" id="kobo.124.1">4.41.2</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.125.1">We also install accelerate to run PyTorch packages on GPUs, which is highly recommended for</span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.126.1"> this notebook, among other features, such as mixed precision and accelerated processing times:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.127.1">!pip install accelerate==</span><span class="hljs-number"><span class="koboSpan" id="kobo.128.1">0.31.0</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.129.1">Finally, we will initialize </span><code class="inlineCode"><span class="koboSpan" id="kobo.130.1">meta-llama/Llama-2-7b-chat-hf</span></code><span class="koboSpan" id="kobo.131.1"> as the tokenizer and chat model interactions. </span><span class="koboSpan" id="kobo.131.2">Llama is a series of transformer-based language models developed by Meta AI (formerly Facebook AI) that we can access through Hugging Face:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.132.1">from</span></span><span class="koboSpan" id="kobo.133.1"> transformers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.134.1">import</span></span><span class="koboSpan" id="kobo.135.1"> AutoTokenizer
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.136.1">import</span></span><span class="koboSpan" id="kobo.137.1"> tranformers
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.138.1">import</span></span><span class="koboSpan" id="kobo.139.1"> torch
model = </span><span class="hljs-string"><span class="koboSpan" id="kobo.140.1">"meta-llama/Llama-2-7b-chat-hf"</span></span><span class="koboSpan" id="kobo.141.1">
tokenizer = AutoTokenizer.from_pretrained(model)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.142.1">We access the model through Hugging Face’s pipeline:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.143.1">pipeline = transformers.pipeline(
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.144.1">"text-generation"</span></span><span class="koboSpan" id="kobo.145.1">,
    model=model,
    torch_dtype=torch.float16,
    device_map=</span><span class="hljs-string"><span class="koboSpan" id="kobo.146.1">"auto"</span></span><span class="koboSpan" id="kobo.147.1">,
)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.148.1">Let’s go through the pipeline:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.149.1">transformers.pipeline</span></code><span class="koboSpan" id="kobo.150.1"> is the function used to create a pipeline for text generation. </span><span class="koboSpan" id="kobo.150.2">This pipeline abstracts away much of the complexity we must avoid in this dynamic RAG ecosystem.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.151.1">text-generation</span></code><span class="koboSpan" id="kobo.152.1"> specifies the type of task the pipeline is set up for. </span><span class="koboSpan" id="kobo.152.2">In this case, we want text generation.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.153.1">model</span></code><span class="koboSpan" id="kobo.154.1"> specifies the model we selected.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.155.1">torch_dtype=torch.float16</span></code><span class="koboSpan" id="kobo.156.1"> sets the data type for PyTorch tensors to </span><code class="inlineCode"><span class="koboSpan" id="kobo.157.1">float16</span></code><span class="koboSpan" id="kobo.158.1">. </span><span class="koboSpan" id="kobo.158.2">This is a key</span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.159.1"> factor for dynamic RAG, which reduces memory consumption and can speed up computation, particularly on GPUs that support half-precision computations. </span><span class="koboSpan" id="kobo.159.2">Half-precision computations use 16 bits: half of the standard 32-bit precision, for faster, lighter processing. </span><span class="koboSpan" id="kobo.159.3">This is exactly what we need.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.160.1">device_map="auto"</span></code><span class="koboSpan" id="kobo.161.1"> instructs the pipeline to automatically determine the best device to run the</span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.162.1"> model on (CPU, GPU, multi-GPU, etc.). </span><span class="koboSpan" id="kobo.162.2">This parameter is particularly important for optimizing performance and automatically distributing the model’s layers across available devices (like GPUs) in the most efficient manner possible. </span><span class="koboSpan" id="kobo.162.3">If multiple GPUs are available, it will distribute the load across them to maximize parallel processing. </span><span class="koboSpan" id="kobo.162.4">If you have access to a GPU, activate it to speed up the configuration of this pipeline.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.163.1">Hugging Face is ready; Chroma is required next.</span></p>
    <h2 id="_idParaDest-207" class="heading-2"><span class="koboSpan" id="kobo.164.1">Chroma</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.165.1">The following line installs </span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.166.1">Chroma, our open-</span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.167.1">source vector database:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.168.1">!pip install chromadb==</span><span class="hljs-number"><span class="koboSpan" id="kobo.169.1">0.5.3</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.170.1">Take a close look </span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.171.1">at the following excerpt output, which displays the packages installed and, in particular, </span><strong class="keyWord"><span class="koboSpan" id="kobo.172.1">Open Neural Network Exchange</span></strong><span class="koboSpan" id="kobo.173.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.174.1">ONNX</span></strong><span class="koboSpan" id="kobo.175.1">):</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.176.1">Successfully installed asgiref-3…onnxruntime-1.18.0…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.177.1">ONNX (</span><a href="https://onnxruntime.ai/"><span class="url"><span class="koboSpan" id="kobo.178.1">https://onnxruntime.ai/</span></span></a><span class="koboSpan" id="kobo.179.1">) is a key</span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.180.1"> component in this chapter’s dynamic RAG scenario because it is fully integrated with Chroma. </span><span class="koboSpan" id="kobo.180.2">ONNX is a standard format for representing </span><strong class="keyWord"><span class="koboSpan" id="kobo.181.1">machine learning</span></strong><span class="koboSpan" id="kobo.182.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.183.1">ML</span></strong><span class="koboSpan" id="kobo.184.1">) models</span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.185.1"> designed to enable models to be used across different frameworks and hardware without being locked into one ecosystem.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.186.1">We will be using ONNX Runtime, which is a performance-focused engine for running ONNX models. </span><span class="koboSpan" id="kobo.186.2">It acts as a cross-platform accelerator for ML models, providing a flexible interface that allows integration with hardware-specific libraries. </span><span class="koboSpan" id="kobo.186.3">This makes it possible to optimize the models for various hardware configurations (CPUs, GPUs, and other accelerators). </span><span class="koboSpan" id="kobo.186.4">As for Hugging Face, it is recommended to activate a GPU if you have access to one for the program in this chapter. </span><span class="koboSpan" id="kobo.186.5">Also, we will select a model included within ONNX Runtime installation packages.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.187.1">We have now installed the Hugging Face and Chroma resources we need, including ONNX Runtime. </span><span class="koboSpan" id="kobo.187.2">Hugging Face’s framework is used throughout the model life cycle, from accessing and deploying</span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.188.1"> pre-trained models to training and fine-tuning them within its ecosystem. </span><span class="koboSpan" id="kobo.188.2">ONNX, among its many features, can intervene in the post-training phase to ensure a model’s compatibility and efficient execution across different hardware and software setups. </span><span class="koboSpan" id="kobo.188.3">Models </span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.189.1">might be developed and fine-tuned using Hugging Face’s tools and then converted to the ONNX format for broad, optimized deployment using ONNX Runtime.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.190.1">We will now use spaCy to compute the accuracy between the response we obtain when querying our vector store and the original completion text. </span><span class="koboSpan" id="kobo.190.2">The following command installs a medium-sized English language model from spaCy, tailored for general NLP tasks:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.191.1">!python -m spacy download en_core_web_md
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.192.1">This model, labeled </span><code class="inlineCode"><span class="koboSpan" id="kobo.193.1">en_core_web_md</span></code><span class="koboSpan" id="kobo.194.1">, originates from web text in English and is balanced for speed and accuracy, which we need for dynamic RAG. </span><span class="koboSpan" id="kobo.194.2">It is efficient for computing text similarity. </span><span class="koboSpan" id="kobo.194.3">You may need to restart the session once the package is installed.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.195.1">We have now successfully installed the open-source, optimized, cost-effective resources we need for dynamic RAG and are ready to start running the program’s core.</span></p>
    <h1 id="_idParaDest-208" class="heading-1"><span class="koboSpan" id="kobo.196.1">Activating session time</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.197.1">When working in real-life</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.198.1"> dynamic RAG projects, such as in this scenario, time is </span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.199.1">essential! </span><span class="koboSpan" id="kobo.199.2">For example, if the daily decision-making meeting is at 10 a.m., the RAG preparation team might have to start preparing for this meeting at 8 a.m. </span><span class="koboSpan" id="kobo.199.3">to gather the data online, in processed company data batches, or in any other way necessary for the meeting’s goal.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.200.1">First, activate a GPU if one is available. </span><span class="koboSpan" id="kobo.200.2">On Google Colab, for example, go to </span><strong class="screenText"><span class="koboSpan" id="kobo.201.1">Runtime</span></strong><span class="koboSpan" id="kobo.202.1"> | </span><strong class="screenText"><span class="koboSpan" id="kobo.203.1">Change runtime type</span></strong><span class="koboSpan" id="kobo.204.1"> and select a GPU if possible and available. </span><span class="koboSpan" id="kobo.204.2">If not, the notebook will take a bit longer but will run on a CPU. </span><span class="koboSpan" id="kobo.204.3">Then, go through each section in this chapter, running the notebook cell by cell to understand the process in depth.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.205.1">The following </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.206.1">code activates a measure of the session time once the environment is</span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.207.1"> installed all the way to the end of the notebook:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.208.1"># Start timing before the request</span></span><span class="koboSpan" id="kobo.209.1">
session_start_time = time.time()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.210.1">Finally, restart the session, go to </span><strong class="screenText"><span class="koboSpan" id="kobo.211.1">Runtime</span></strong><span class="koboSpan" id="kobo.212.1"> again, and click on </span><strong class="screenText"><span class="koboSpan" id="kobo.213.1">Run all</span></strong><span class="koboSpan" id="kobo.214.1">. </span><span class="koboSpan" id="kobo.214.2">Once the program is finished, go to </span><strong class="screenText"><span class="koboSpan" id="kobo.215.1">Total session time</span></strong><span class="koboSpan" id="kobo.216.1">, the last section of the notebook. </span><span class="koboSpan" id="kobo.216.2">You will have an estimate of how long it takes for a preparation run. </span><span class="koboSpan" id="kobo.216.3">With the time left before a daily meeting, you can tweak the data, queries, and model parameters for your needs a few times.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.217.1">This on-the-fly dynamic RAG approach will make any team that has these skills a precious asset in this fast-moving world. </span><span class="koboSpan" id="kobo.217.2">We will start the core of the program by downloading and preparing the dataset.</span></p>
    <h1 id="_idParaDest-209" class="heading-1"><span class="koboSpan" id="kobo.218.1">Downloading and preparing the dataset</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.219.1">We will use the SciQ dataset created by Welbl, Liu, and Gardner (2017) with a method for generating high-quality, domain-specific multiple-choice science questions via </span><em class="italic"><span class="koboSpan" id="kobo.220.1">crowdsourcing</span></em><span class="koboSpan" id="kobo.221.1">. </span><span class="koboSpan" id="kobo.221.2">The </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.222.1">SciQ dataset consists of 13,679 multiple-choice questions crafted to aid the training of NLP models for science exams. </span><span class="koboSpan" id="kobo.222.2">The</span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.223.1"> creation process involves two main steps: selecting relevant passages and generating questions with plausible distractors.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.224.1">In the context of using this dataset for an augmented generation of questions through a Chroma collection, we will implement the </span><code class="inlineCode"><span class="koboSpan" id="kobo.225.1">question</span></code><span class="koboSpan" id="kobo.226.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.227.1">correct_answer</span></code><span class="koboSpan" id="kobo.228.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.229.1">support</span></code><span class="koboSpan" id="kobo.230.1"> columns. </span><span class="koboSpan" id="kobo.230.2">The dataset also contains </span><code class="inlineCode"><span class="koboSpan" id="kobo.231.1">distractor</span></code><span class="koboSpan" id="kobo.232.1"> columns with wrong answers, which we will drop.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.233.1">We will integrate the prepared dataset into a retrieval system that utilizes query augmentation techniques to enhance the retrieval of relevant questions based on specific scientific topics or question</span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.234.1"> formats for Hugging Face’s Llama model. </span><span class="koboSpan" id="kobo.234.2">This will allow for the dynamic </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.235.1">generation of augmented, real-time completions for Llama, as implemented in the chapter’s program. </span><span class="koboSpan" id="kobo.235.2">The program loads the training data from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.236.1">sciq</span></code><span class="koboSpan" id="kobo.237.1"> dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.238.1"># Import required libraries</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.239.1">from</span></span><span class="koboSpan" id="kobo.240.1"> datasets </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.241.1">import</span></span><span class="koboSpan" id="kobo.242.1"> load_dataset
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.243.1">import</span></span><span class="koboSpan" id="kobo.244.1"> pandas </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.245.1">as</span></span><span class="koboSpan" id="kobo.246.1"> pd
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.247.1"># Load the SciQ dataset from HuggingFace</span></span><span class="koboSpan" id="kobo.248.1">
dataset = load_dataset(</span><span class="hljs-string"><span class="koboSpan" id="kobo.249.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.250.1">sciq"</span></span><span class="koboSpan" id="kobo.251.1">, split=</span><span class="hljs-string"><span class="koboSpan" id="kobo.252.1">"train"</span></span><span class="koboSpan" id="kobo.253.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.254.1">The dataset is filtered to detect the non-empty </span><code class="inlineCode"><span class="koboSpan" id="kobo.255.1">support</span></code><span class="koboSpan" id="kobo.256.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.257.1">correct_answer</span></code><span class="koboSpan" id="kobo.258.1"> columns:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.259.1"># Filter the dataset to include only questions with support and correct answer</span></span><span class="koboSpan" id="kobo.260.1">
filtered_dataset = dataset.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.261.1">filter</span></span><span class="koboSpan" id="kobo.262.1">(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.263.1">lambda</span></span><span class="koboSpan" id="kobo.264.1"> x: x[</span><span class="hljs-string"><span class="koboSpan" id="kobo.265.1">"support"</span></span><span class="koboSpan" id="kobo.266.1">] != </span><span class="hljs-string"><span class="koboSpan" id="kobo.267.1">""</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.268.1">and</span></span><span class="koboSpan" id="kobo.269.1"> x[</span><span class="hljs-string"><span class="koboSpan" id="kobo.270.1">"correct_answer"</span></span><span class="koboSpan" id="kobo.271.1">] != </span><span class="hljs-string"><span class="koboSpan" id="kobo.272.1">""</span></span><span class="koboSpan" id="kobo.273.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.274.1">We will now display the number of rows filtered:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.275.1"># Print the number of questions with support</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.276.1">print</span></span><span class="koboSpan" id="kobo.277.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.278.1">"Number of questions with support: "</span></span><span class="koboSpan" id="kobo.279.1">, </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.280.1">len</span></span><span class="koboSpan" id="kobo.281.1">(filtered_dataset))
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.282.1">The output shows that we have 10,481 documents:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.283.1">Number of questions with support:  10481
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.284.1">We need to clean the DataFrame to focus on the columns we need. </span><span class="koboSpan" id="kobo.284.2">Let’s drop the distractors (wrong answers to the questions):</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.285.1"># Convert the filtered dataset to a pandas DataFrame</span></span><span class="koboSpan" id="kobo.286.1">
df = pd.DataFrame(filtered_dataset)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.287.1"># Columns to drop</span></span><span class="koboSpan" id="kobo.288.1">
columns_to_drop = [</span><span class="hljs-string"><span class="koboSpan" id="kobo.289.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.290.1">distractor3'</span></span><span class="koboSpan" id="kobo.291.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.292.1">'distractor1'</span></span><span class="koboSpan" id="kobo.293.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.294.1">'distractor2'</span></span><span class="koboSpan" id="kobo.295.1">]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.296.1"># Dropping the columns from the DataFrame</span></span><span class="koboSpan" id="kobo.297.1">
df.drop(columns=columns_to_drop, inplace=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.298.1">True</span></span><span class="koboSpan" id="kobo.299.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.300.1">We have the correct answer and the support content that we will now merge:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.301.1"># Create a new column 'completion' by merging 'correct_answer' and 'support'</span></span><span class="koboSpan" id="kobo.302.1">
df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.303.1">'completion'</span></span><span class="koboSpan" id="kobo.304.1">] = df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.305.1">'correct_answer'</span></span><span class="koboSpan" id="kobo.306.1">] + </span><span class="hljs-string"><span class="koboSpan" id="kobo.307.1">" because "</span></span><span class="koboSpan" id="kobo.308.1"> + df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.309.1">'support'</span></span><span class="koboSpan" id="kobo.310.1">]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.311.1"># Ensure no NaN values are in the 'completion' column</span></span><span class="koboSpan" id="kobo.312.1">
df.dropna(subset=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.313.1">'completion'</span></span><span class="koboSpan" id="kobo.314.1">], inplace=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.315.1">True</span></span><span class="koboSpan" id="kobo.316.1">)
df
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.317.1">The output shows the columns we</span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.318.1"> need to prepare the data for retrieval in the completion columns, as </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.319.1">shown in the excerpt of the DataFrame for a completion field in which </span><code class="inlineCode"><span class="koboSpan" id="kobo.320.1">aerobic</span></code><span class="koboSpan" id="kobo.321.1"> is the correct answer because it is the connector and the rest of the text is the support content for the correct answer:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.322.1">aerobic because "Cardio" has become slang for aerobic exercise that raises your heart rate for an extended amount of time. </span><span class="koboSpan" id="kobo.322.2">Cardio can include biking, running, or swimming. </span><span class="koboSpan" id="kobo.322.3">Can you guess one of the main organs of the cardiovascular system? </span><span class="koboSpan" id="kobo.322.4">Yes, your heart.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.323.1">The program now displays the shape of the DataFrame:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.324.1">df.shape
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.325.1">The output shows we still have all the initial lines and four columns:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.326.1">(10481, 4)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.327.1">The following code will display the names of the columns:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.328.1"># Assuming 'df' is your DataFrame</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.329.1">print</span></span><span class="koboSpan" id="kobo.330.1">(df.columns)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.331.1">As a result, the output displays the four columns we need:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.332.1">Index(['question', 'correct_answer', 'support', 'completion'], dtype='object')
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.333.1">The data is now ready to be embedded and upserted.</span></p>
    <h1 id="_idParaDest-210" class="heading-1"><span class="koboSpan" id="kobo.334.1">Embedding and upserting the data in a Chroma collection</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.335.1">We will begin by creating the Chroma client and defining a collection name:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.336.1"># Import Chroma and instantiate a client. </span><span class="koboSpan" id="kobo.336.2">The default Chroma client is ephemeral, meaning it will not save to disk.</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.337.1">import</span></span><span class="koboSpan" id="kobo.338.1"> chromadb
client = chromadb.Client()
collection_name=</span><span class="hljs-string"><span class="koboSpan" id="kobo.339.1">"sciq_supports6"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.340.1">Before creating the collection and upserting the data to the collection, we need to verify whether the collection already exists or not:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.341.1"># List all collections</span></span><span class="koboSpan" id="kobo.342.1">
collections = client.list_collections()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.343.1"># Check if the specific collection exists</span></span><span class="koboSpan" id="kobo.344.1">
collection_exists = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.345.1">any</span></span><span class="koboSpan" id="kobo.346.1">(collection.name == collection_name </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.347.1">for</span></span><span class="koboSpan" id="kobo.348.1"> collection </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.349.1">in</span></span><span class="koboSpan" id="kobo.350.1"> collections)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.351.1">print</span></span><span class="koboSpan" id="kobo.352.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.353.1">"Collection exists:"</span></span><span class="koboSpan" id="kobo.354.1">, collection_exists)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.355.1">The output will return </span><code class="inlineCode"><span class="koboSpan" id="kobo.356.1">True</span></code><span class="koboSpan" id="kobo.357.1"> if the collection exists and </span><code class="inlineCode"><span class="koboSpan" id="kobo.358.1">False</span></code><span class="koboSpan" id="kobo.359.1"> if it doesn’t:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.360.1">Collection exists: False
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.361.1">If the collection doesn’t exist, we will create a collection with </span><code class="inlineCode"><span class="koboSpan" id="kobo.362.1">collection_name</span></code><span class="koboSpan" id="kobo.363.1"> defined earlier:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.364.1"># Create a new Chroma collection to store the supporting evidence. </span><span class="koboSpan" id="kobo.364.2">We don't need to specify an embedding function, and the default will be used.</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.365.1">if</span></span><span class="koboSpan" id="kobo.366.1"> collection_exists!=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.367.1">True</span></span><span class="koboSpan" id="kobo.368.1">:
  collection = client.create_collection(collection_name)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.369.1">else</span></span><span class="koboSpan" id="kobo.370.1">:
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.371.1">print</span></span><span class="koboSpan" id="kobo.372.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.373.1">"Collection "</span></span><span class="koboSpan" id="kobo.374.1">, collection_name,</span><span class="hljs-string"><span class="koboSpan" id="kobo.375.1">" exists:"</span></span><span class="koboSpan" id="kobo.376.1">, collection_exists)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.377.1">Let’s peek into the structure of the dictionary of the collection we created:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.378.1">#Printing the dictionary</span></span><span class="koboSpan" id="kobo.379.1">
results = collection.get()
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.380.1">for</span></span><span class="koboSpan" id="kobo.381.1"> result </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.382.1">in</span></span><span class="koboSpan" id="kobo.383.1"> results:
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.384.1">print</span></span><span class="koboSpan" id="kobo.385.1">(result)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.386.1"># This will print the dictionary for each item</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.387.1">The output displays the dictionary of each item of the collection:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.388.1">ids
embeddings
metadatas
documents
uris
data
included
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.389.1">Let’s briefly go through the three key fields for our scenario:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.390.1">ids</span></code><span class="koboSpan" id="kobo.391.1">: This field represents the unique identifiers for each item in the collection.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.392.1">embeddings</span></code><span class="koboSpan" id="kobo.393.1">: Embeddings are the embedded vectors of the documents.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.394.1">documents</span></code><span class="koboSpan" id="kobo.395.1">: This refers to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.396.1">completion</span></code><span class="koboSpan" id="kobo.397.1"> column in which we merged the correct answer and the support content.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.398.1">We now need a lightweight rapid LLM model for our dynamic RAG environment.</span></p>
    <h2 id="_idParaDest-211" class="heading-2"><span class="koboSpan" id="kobo.399.1">Selecting a model</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.400.1">Chroma will initialize a default model, which can be </span><code class="inlineCode"><span class="koboSpan" id="kobo.401.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.402.1">. </span><span class="koboSpan" id="kobo.402.2">However, let’s make sure we are using this model and initialize it:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.403.1">model_name = </span><span class="hljs-string"><span class="koboSpan" id="kobo.404.1">"all-MiniLM-L6-v2"</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.405.1"># The name of the model to use for embedding and querying</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.406.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.407.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.408.1"> model was designed with an optimal, enhanced method by Wang et al. </span><span class="koboSpan" id="kobo.408.2">(2021) for model compression, focusing on distilling self-attention relationships between components of transformer models. </span><span class="koboSpan" id="kobo.408.3">This approach is flexible in the number of attention heads between teacher and student models, improving compression efficiency. </span><span class="koboSpan" id="kobo.408.4">The model is fully integrated into Chroma with ONNX, as explained in the </span><em class="italic"><span class="koboSpan" id="kobo.409.1">Installing the environment</span></em><span class="koboSpan" id="kobo.410.1"> section of this chapter.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.411.1">The magic of this </span><code class="inlineCode"><span class="koboSpan" id="kobo.412.1">MiniLM</span></code><span class="koboSpan" id="kobo.413.1"> model is based on compression and knowledge distillation through a teacher model and the student model:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.414.1">Teacher model</span></strong><span class="koboSpan" id="kobo.415.1">: This is the original, typically larger and more complex model such as BERT, RoBERTa, and XLM-R, in our case, that has been pre-trained on a comprehensive dataset. </span><span class="koboSpan" id="kobo.415.2">The teacher model possesses high accuracy and a deep understanding of the tasks it has been trained on. </span><span class="koboSpan" id="kobo.415.3">It serves as the source of knowledge that we aim to transfer.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.416.1">Student model</span></strong><span class="koboSpan" id="kobo.417.1">: This is our smaller, less complex model, </span><code class="inlineCode"><span class="koboSpan" id="kobo.418.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.419.1">, which is trained to mimic the teacher model’s behavior, which will prove very effective for our dynamic RAG architecture. </span><span class="koboSpan" id="kobo.419.2">The goal is to have the student model replicate the performance of the teacher model as closely as possible but with significantly fewer parameters or computational expense.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.420.1">In our case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.421.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.422.1"> will accelerate the embedding and querying process. </span><span class="koboSpan" id="kobo.422.2">We can see that in the age of superhuman LLM models, such as GPT-4o, we can perform daily tasks with smaller compressed and distilled models. </span><span class="koboSpan" id="kobo.422.3">Let’s embed the data next.</span></p>
    <h2 id="_idParaDest-212" class="heading-2"><span class="koboSpan" id="kobo.423.1">Embedding and storing the completions</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.424.1">Embedding and upserting data in a Chroma collection is seamless and concise. </span><span class="koboSpan" id="kobo.424.2">In this scenario, we’ll embed and upsert the whole </span><code class="inlineCode"><span class="koboSpan" id="kobo.425.1">df</span></code><span class="koboSpan" id="kobo.426.1"> completions in a </span><code class="inlineCode"><span class="koboSpan" id="kobo.427.1">completion_list</span></code><span class="koboSpan" id="kobo.428.1"> extracted from our </span><code class="inlineCode"><span class="koboSpan" id="kobo.429.1">df</span></code><span class="koboSpan" id="kobo.430.1"> dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.431.1">ldf=</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.432.1">len</span></span><span class="koboSpan" id="kobo.433.1">(df)
nb=ldf  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.434.1"># number of questions to embed and store</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.435.1">import</span></span><span class="koboSpan" id="kobo.436.1"> time
start_time = time.time()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.437.1"># Start timing before the request</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.438.1"># Convert Series to list of strings</span></span><span class="koboSpan" id="kobo.439.1">
completion_list = df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.440.1">"completion"</span></span><span class="koboSpan" id="kobo.441.1">][:nb].astype(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.442.1">str</span></span><span class="koboSpan" id="kobo.443.1">).tolist()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.444.1">We use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.445.1">collection_exists</span></code><span class="koboSpan" id="kobo.446.1"> status we defined when creating the collection to avoid loading the data twice. </span><span class="koboSpan" id="kobo.446.2">In this scenario, the collection is temporary; we just want to load it once and use it once. </span><span class="koboSpan" id="kobo.446.3">If you try to load the data in this temporary scenario a second time, you will get warnings. </span><span class="koboSpan" id="kobo.446.4">However, you can modify the code if you wish to try different datasets and methods, such as preparing a prototype at full speed for another project.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.447.1">In any case, in this scenario, we first check if the collection exists and then upsert the </span><code class="inlineCode"><span class="koboSpan" id="kobo.448.1">ids</span></code><span class="koboSpan" id="kobo.449.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.450.1">documents</span></code><span class="koboSpan" id="kobo.451.1"> in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.452.1">complete_list</span></code><span class="koboSpan" id="kobo.453.1"> and store the </span><code class="inlineCode"><span class="koboSpan" id="kobo.454.1">type</span></code><span class="koboSpan" id="kobo.455.1"> of data, which is </span><code class="inlineCode"><span class="koboSpan" id="kobo.456.1">completion</span></code><span class="koboSpan" id="kobo.457.1">, in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.458.1">metadatas</span></code><span class="koboSpan" id="kobo.459.1"> field:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.460.1"># Avoiding trying to load data twice in this one run dynamic RAG notebook</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.461.1">if</span></span><span class="koboSpan" id="kobo.462.1"> collection_exists!=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.463.1">True</span></span><span class="koboSpan" id="kobo.464.1">:
  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.465.1"># Embed and store the first nb supports for this demo</span></span><span class="koboSpan" id="kobo.466.1">
  collection.add(
      ids=[</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.467.1">str</span></span><span class="koboSpan" id="kobo.468.1">(i) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.469.1">for</span></span><span class="koboSpan" id="kobo.470.1"> i </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.471.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.472.1">range</span></span><span class="koboSpan" id="kobo.473.1">(</span><span class="hljs-number"><span class="koboSpan" id="kobo.474.1">0</span></span><span class="koboSpan" id="kobo.475.1">, nb)],  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.476.1"># IDs are just strings</span></span><span class="koboSpan" id="kobo.477.1">
      documents=completion_list,
      metadatas=[{</span><span class="hljs-string"><span class="koboSpan" id="kobo.478.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.479.1">type"</span></span><span class="koboSpan" id="kobo.480.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.481.1">"completion"</span></span><span class="koboSpan" id="kobo.482.1">} </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.483.1">for</span></span><span class="koboSpan" id="kobo.484.1"> _ </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.485.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.486.1">range</span></span><span class="koboSpan" id="kobo.487.1">(</span><span class="hljs-number"><span class="koboSpan" id="kobo.488.1">0</span></span><span class="koboSpan" id="kobo.489.1">, nb)],
  )
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.490.1">Finally, we measure the response time:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.491.1">response_time = time.time() - start_time  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.492.1"># Measure response time</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.493.1">print</span></span><span class="koboSpan" id="kobo.494.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.495.1">f"Response Time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.496.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.497.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.498.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.499.1"> seconds"</span></span><span class="koboSpan" id="kobo.500.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.501.1"># Print response time</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.502.1">The output shows that, in this case, Chroma activated the default model through </span><code class="inlineCode"><span class="koboSpan" id="kobo.503.1">onnx</span></code><span class="koboSpan" id="kobo.504.1">, as explained in the introduction of this section and also in the </span><em class="italic"><span class="koboSpan" id="kobo.505.1">Installing the environment</span></em><span class="koboSpan" id="kobo.506.1"> section of this chapter:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.507.1">/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02&lt;00:00, 31.7MiB/s]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.508.1">The output also shows that the processing time for 10,000+ documents is satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.509.1">Response Time: 234.25 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.510.1">The response time might vary and depends on whether you are using a GPU. </span><span class="koboSpan" id="kobo.510.2">When using an accessible GPU, the time fits the needs required for dynamic RAG scenarios.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.511.1">With that, the Chroma vector store is now populated. </span><span class="koboSpan" id="kobo.511.2">Let’s take a peek at the embeddings.</span></p>
    <h2 id="_idParaDest-213" class="heading-2"><span class="koboSpan" id="kobo.512.1">Displaying the embeddings</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.513.1">The program now fetches the embeddings and displays the first one:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.514.1"># Fetch the collection with embeddings included</span></span><span class="koboSpan" id="kobo.515.1">
result = collection.get(include=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.516.1">'embeddings'</span></span><span class="koboSpan" id="kobo.517.1">])
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.518.1"># Extract the first embedding from the result</span></span><span class="koboSpan" id="kobo.519.1">
first_embedding = result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.520.1">'embeddings'</span></span><span class="koboSpan" id="kobo.521.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.522.1">0</span></span><span class="koboSpan" id="kobo.523.1">]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.524.1"># If you need to work with the length or manipulate the first embedding:</span></span><span class="koboSpan" id="kobo.525.1">
embedding_length = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.526.1">len</span></span><span class="koboSpan" id="kobo.527.1">(first_embedding)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.528.1">print</span></span><span class="koboSpan" id="kobo.529.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.530.1">"First embedding:"</span></span><span class="koboSpan" id="kobo.531.1">, first_embedding)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.532.1">print</span></span><span class="koboSpan" id="kobo.533.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.534.1">"Embedding length:"</span></span><span class="koboSpan" id="kobo.535.1">, embedding_length)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.536.1">The output shows that our completions have been vectorized, as we can see in the first embedding:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.537.1">First embedding: [0.03689068928360939, -0.05881563201546669, -0.04818134009838104,…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.538.1">The output also displays the embedding length, which is interesting:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.539.1">Embedding length: 384
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.540.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.541.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.542.1"> model reduces the complexity of text data by mapping sentences and paragraphs into a 384-dimensional space. </span><span class="koboSpan" id="kobo.542.2">This is significantly lower than the typical dimensionality of one-hot encoded vectors, such as the 1,526 dimensions of the OpenAI </span><code class="inlineCode"><span class="koboSpan" id="kobo.543.1">text-embedding-ada-002</span></code><span class="koboSpan" id="kobo.544.1">. </span><span class="koboSpan" id="kobo.544.2">This shows that </span><code class="inlineCode"><span class="koboSpan" id="kobo.545.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.546.1"> uses dense vectors, which use all dimensions of the vector space to encode information to produce nuanced semantic relationships between different documents as opposed to sparse vectors.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.547.1">Sparse vector models, such as the </span><strong class="keyWord"><span class="koboSpan" id="kobo.548.1">bag-of-words</span></strong><span class="koboSpan" id="kobo.549.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.550.1">BoW</span></strong><span class="koboSpan" id="kobo.551.1">) model, can be effective in some cases. </span><span class="koboSpan" id="kobo.551.2">However, their main limitation is that they don’t capture the order of words or the context around them, which can be crucial for understanding the meaning of text when training LLMs.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.552.1">We have now embedded the documents into dense vectors in a smaller dimensional space than full-blown LLMs and will produce satisfactory results.</span></p>
    <h1 id="_idParaDest-214" class="heading-1"><span class="koboSpan" id="kobo.553.1">Querying the collection</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.554.1">The code in this section </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.555.1">executes a query against the Chroma vector store using its integrated semantic search functionality. </span><span class="koboSpan" id="kobo.555.2">It queries the vector representations of all the vectors in the Chroma collection questions in the initial dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.556.1">dataset[</span><span class="hljs-string"><span class="koboSpan" id="kobo.557.1">"question"</span></span><span class="koboSpan" id="kobo.558.1">][:nbq].
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.559.1">The query requests one most relevant or similar document for each question with </span><code class="inlineCode"><span class="koboSpan" id="kobo.560.1">n_results=1</span></code><span class="koboSpan" id="kobo.561.1">, which you can modify if you wish.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.562.1">Each question text is converted into a vector. </span><span class="koboSpan" id="kobo.562.2">Then, Chroma runs a vector similarity search by comparing the embedded vectors against our database of document vectors to find the closest </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.563.1">match based on vector similarity:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.564.1">import</span></span><span class="koboSpan" id="kobo.565.1"> time
start_time = time.time()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.566.1"># Start timing before the request</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.567.1"># number of retrievals to write</span></span><span class="koboSpan" id="kobo.568.1">
results = collection.query(
    query_texts=df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.569.1">"question"</span></span><span class="koboSpan" id="kobo.570.1">][:nb],
    n_results=</span><span class="hljs-number"><span class="koboSpan" id="kobo.571.1">1</span></span><span class="koboSpan" id="kobo.572.1">)
response_time = time.time() - start_time  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.573.1"># Measure response time</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.574.1">print</span></span><span class="koboSpan" id="kobo.575.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.576.1">f"Response Time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.577.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.578.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.579.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.580.1"> seconds"</span></span><span class="koboSpan" id="kobo.581.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.582.1"># Print response time</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.583.1">The output displays a satisfactory response time for the 10,000+ queries:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.584.1">Response Time: 199.34 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.585.1">We will now analyze the 10,000+ queries. </span><span class="koboSpan" id="kobo.585.2">We will use spaCy to evaluate a query’s result and compare it with the original completion. </span><span class="koboSpan" id="kobo.585.3">We first load the spaCy model we installed in the </span><em class="italic"><span class="koboSpan" id="kobo.586.1">Installing the environment</span></em><span class="koboSpan" id="kobo.587.1"> section of this chapter:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.588.1">import</span></span><span class="koboSpan" id="kobo.589.1"> spacy
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.590.1">import</span></span><span class="koboSpan" id="kobo.591.1"> numpy </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.592.1">as</span></span><span class="koboSpan" id="kobo.593.1"> np
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.594.1"># Load the pre-trained spaCy language model</span></span><span class="koboSpan" id="kobo.595.1">
nlp = spacy.load(</span><span class="hljs-string"><span class="koboSpan" id="kobo.596.1">'en_core_web_md'</span></span><span class="koboSpan" id="kobo.597.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.598.1"># Ensure that you've installed this model with 'python -m spacy download en_core_web_md'</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.599.1">The program then creates a similarity function that takes two arguments (the original completion, </span><code class="inlineCode"><span class="koboSpan" id="kobo.600.1">text1</span></code><span class="koboSpan" id="kobo.601.1">, and the retrieved text, </span><code class="inlineCode"><span class="koboSpan" id="kobo.602.1">text2</span></code><span class="koboSpan" id="kobo.603.1">) and returns the similarity value:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.604.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.605.1">simple_text_similarity</span></span><span class="koboSpan" id="kobo.606.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.607.1">text1, text2</span></span><span class="koboSpan" id="kobo.608.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.609.1"># Convert the texts into spaCy document objects</span></span><span class="koboSpan" id="kobo.610.1">
    doc1 = nlp(text1)
    doc2 = nlp(text2)
   
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.611.1"># Get the vectors for each document</span></span><span class="koboSpan" id="kobo.612.1">
    vector1 = doc1.vector
    vector2 = doc2.vector
   
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.613.1"># Compute the cosine similarity between the two vectors</span></span>
    <span class="hljs-comment"><span class="koboSpan" id="kobo.614.1"># Check for zero vectors to avoid division by zero</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.615.1">if</span></span><span class="koboSpan" id="kobo.616.1"> np.linalg.norm(vector1) == </span><span class="hljs-number"><span class="koboSpan" id="kobo.617.1">0</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.618.1">or</span></span><span class="koboSpan" id="kobo.619.1"> np.linalg.norm(vector2) == </span><span class="hljs-number"><span class="koboSpan" id="kobo.620.1">0</span></span><span class="koboSpan" id="kobo.621.1">:
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.622.1">return</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.623.1">0.0</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.624.1"># Return zero if one of the texts does not have a vector representation</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.625.1">else</span></span><span class="koboSpan" id="kobo.626.1">:
        similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.627.1">return</span></span><span class="koboSpan" id="kobo.628.1"> similarity
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.629.1">We will now perform a full validation run on the 10,000 queries. </span><span class="koboSpan" id="kobo.629.2">As can be seen in the following code block, the validation begins by defining the variables we will need:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.630.1">nbqd</span></code><span class="koboSpan" id="kobo.631.1"> to only display the first 100 and last 100 results.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.632.1">acc_counter</span></code><span class="koboSpan" id="kobo.633.1"> measures the results with a similarity score superior to 0.5, which you can </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.634.1">modify to fit your needs.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.635.1">display_counter</span></code><span class="koboSpan" id="kobo.636.1"> to count the number of results we have displayed:</span></li>
    </ul>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.637.1">nbqd = </span><span class="hljs-number"><span class="koboSpan" id="kobo.638.1">100</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.639.1"># the number of responses to display, supposing there are more than 100 records</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.640.1"># Print the question, the original completion, the retrieved document, and compare them</span></span><span class="koboSpan" id="kobo.641.1">
acc_counter=</span><span class="hljs-number"><span class="koboSpan" id="kobo.642.1">0</span></span><span class="koboSpan" id="kobo.643.1">
display_counter=</span><span class="hljs-number"><span class="koboSpan" id="kobo.644.1">0</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.645.1">The program goes through </span><code class="inlineCode"><span class="koboSpan" id="kobo.646.1">nb</span></code><span class="koboSpan" id="kobo.647.1"> results, which, in our case, is the total length of our dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.648.1">for</span></span><span class="koboSpan" id="kobo.649.1"> i, q </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.650.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.651.1">enumerate</span></span><span class="koboSpan" id="kobo.652.1">(df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.653.1">'question'</span></span><span class="koboSpan" id="kobo.654.1">][:nb]):
    original_completion = df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.655.1">'completion'</span></span><span class="koboSpan" id="kobo.656.1">][i]  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.657.1"># Access the original completion for the question</span></span><span class="koboSpan" id="kobo.658.1">
    retrieved_document = results[</span><span class="hljs-string"><span class="koboSpan" id="kobo.659.1">'documents'</span></span><span class="koboSpan" id="kobo.660.1">][i][</span><span class="hljs-number"><span class="koboSpan" id="kobo.661.1">0</span></span><span class="koboSpan" id="kobo.662.1">]  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.663.1"># Retrieve the corresponding document</span></span><span class="koboSpan" id="kobo.664.1">
    similarity_score = simple_text_similarity(original_completion, retrieved_document)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.665.1">The code accesses the original completion and stores it in </span><code class="inlineCode"><span class="koboSpan" id="kobo.666.1">original_completion</span></code><span class="koboSpan" id="kobo.667.1">. </span><span class="koboSpan" id="kobo.667.2">Then, it retrieves the result and stores it in </span><code class="inlineCode"><span class="koboSpan" id="kobo.668.1">retrieved_document</span></code><span class="koboSpan" id="kobo.669.1">. </span><span class="koboSpan" id="kobo.669.2">Finally, it calls the similarity function we defined, </span><code class="inlineCode"><span class="koboSpan" id="kobo.670.1">simple_text_similarity</span></code><span class="koboSpan" id="kobo.671.1">. </span><span class="koboSpan" id="kobo.671.2">The original completion and the retrieved document store the similarity score in </span><code class="inlineCode"><span class="koboSpan" id="kobo.672.1">similarity_score</span></code><span class="koboSpan" id="kobo.673.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.674.1">Now, we introduce an accuracy metric. </span><span class="koboSpan" id="kobo.674.2">In this scenario, the threshold of the similarity score is set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.675.1">0.7</span></code><span class="koboSpan" id="kobo.676.1">, which is reasonable:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword"><span class="koboSpan" id="kobo.677.1">if</span></span><span class="koboSpan" id="kobo.678.1"> similarity_score &gt; </span><span class="hljs-number"><span class="koboSpan" id="kobo.679.1">0.7</span></span><span class="koboSpan" id="kobo.680.1">:
      acc_counter+=</span><span class="hljs-number"><span class="koboSpan" id="kobo.681.1">1</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.682.1">If </span><code class="inlineCode"><span class="koboSpan" id="kobo.683.1">similarity_score &gt; 0.7</span></code><span class="koboSpan" id="kobo.684.1">, then the accuracy counter, </span><code class="inlineCode"><span class="koboSpan" id="kobo.685.1">acc_counter</span></code><span class="koboSpan" id="kobo.686.1">, is incremented. </span><span class="koboSpan" id="kobo.686.2">The display counter, </span><code class="inlineCode"><span class="koboSpan" id="kobo.687.1">display_counter</span></code><span class="koboSpan" id="kobo.688.1">, is also incremented to only the first and last </span><code class="inlineCode"><span class="koboSpan" id="kobo.689.1">nbqd</span></code><span class="koboSpan" id="kobo.690.1"> (maximum results </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.691.1">to display) defined at the beginning of this function:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.692.1">    display_counter+=</span><span class="hljs-number"><span class="koboSpan" id="kobo.693.1">1</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.694.1">if</span></span><span class="koboSpan" id="kobo.695.1"> display_counter&lt;=nbqd </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.696.1">or</span></span><span class="koboSpan" id="kobo.697.1"> display_counter&gt;nb-nbqd:
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.698.1">The information displayed provides insights into the performance of the system:</span></p>
    <pre class="programlisting code"><code class="hljs-code">      <span class="hljs-built_in"><span class="koboSpan" id="kobo.699.1">print</span></span><span class="koboSpan" id="kobo.700.1">(i,</span><span class="hljs-string"><span class="koboSpan" id="kobo.701.1">" "</span></span><span class="koboSpan" id="kobo.702.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.703.1">f"Question: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.704.1">{q}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.705.1">"</span></span><span class="koboSpan" id="kobo.706.1">)
      </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.707.1">print</span></span><span class="koboSpan" id="kobo.708.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.709.1">f"Retrieved document: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.710.1">{retrieved_document}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.711.1">"</span></span><span class="koboSpan" id="kobo.712.1">)
      </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.713.1">print</span></span><span class="koboSpan" id="kobo.714.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.715.1">f"Original completion: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.716.1">{original_completion}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.717.1">"</span></span><span class="koboSpan" id="kobo.718.1">)
      </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.719.1">print</span></span><span class="koboSpan" id="kobo.720.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.721.1">f"Similarity Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.722.1">{similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.723.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.724.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.725.1">"</span></span><span class="koboSpan" id="kobo.726.1">)
      </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.727.1">print</span></span><span class="koboSpan" id="kobo.728.1">()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.729.1"># Blank line for better readability between entries</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.730.1">The output displays four key variables:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.731.1">{q}</span></code><span class="koboSpan" id="kobo.732.1"> is the question asked, the query.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.733.1">{retrieved_document}</span></code><span class="koboSpan" id="kobo.734.1"> is the document retrieved.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.735.1">{original_completion}</span></code><span class="koboSpan" id="kobo.736.1"> is the original document in the dataset.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.737.1">{similarity_score:.2f}</span></code><span class="koboSpan" id="kobo.738.1"> is the similarity score between the original document and the document retrieved to measure the performance of each response.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.739.1">The first output provides the information required for a human observer to control the result of the query and trace it back to the source.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.740.1">The first part of the output is the question, the query:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.741.1">Question: What type of organism is commonly used in preparation of foods such as cheese and yogurt?
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.742.1">The second part of the output is the retrieved document:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.743.1">Retrieved document: lactic acid because Bacteria can be used to make cheese from milk. </span><span class="koboSpan" id="kobo.743.2">The bacteria turn the milk sugars into lactic acid. </span><span class="koboSpan" id="kobo.743.3">The acid is what causes the milk to curdle to form cheese. </span><span class="koboSpan" id="kobo.743.4">Bacteria are also involved in producing other foods. </span><span class="koboSpan" id="kobo.743.5">Yogurt is made by using bacteria to ferment milk ( Figure below ). </span><span class="koboSpan" id="kobo.743.6">Fermenting cabbage with bacteria produces sauerkraut.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.744.1">The third part of </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.745.1">the output is the original completion. </span><span class="koboSpan" id="kobo.745.2">In this case, we can see that the retrieved document provides relevant information but not the exact original completion:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.746.1">Original completion: mesophilic organisms because Mesophiles grow best in moderate temperature, typically between 25°C and 40°C (77°F and 104°F). </span><span class="koboSpan" id="kobo.746.2">Mesophiles are often found living in or on the bodies of humans or other animals. </span><span class="koboSpan" id="kobo.746.3">The optimal growth temperature of many pathogenic mesophiles is 37°C (98°F), the normal human body temperature. </span><span class="koboSpan" id="kobo.746.4">Mesophilic organisms have important uses in food preparation, including cheese, yogurt, beer and wine.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.747.1">Finally, the output displays the similarity score calculated by spaCy:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.748.1">Similarity Score: 0.73
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.749.1">The score shows that although the original completion was not selected, the completion selected is relevant.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.750.1">When all the results have been analyzed, the program calculates the accuracy obtained for the 10,000+ queries:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.751.1">if</span></span><span class="koboSpan" id="kobo.752.1"> nb&gt;</span><span class="hljs-number"><span class="koboSpan" id="kobo.753.1">0</span></span><span class="koboSpan" id="kobo.754.1">:
  acc=acc_counter/nb
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.755.1">The calculation is based on the following:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.756.1">Acc</span></code><span class="koboSpan" id="kobo.757.1"> is the overall accuracy obtained</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.758.1">acc_counter</span></code><span class="koboSpan" id="kobo.759.1"> is the total of </span><code class="inlineCode"><span class="koboSpan" id="kobo.760.1">Similarity</span></code> <code class="inlineCode"><span class="koboSpan" id="kobo.761.1">scores &gt; 0.7</span></code></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.762.1">nb</span></code><span class="koboSpan" id="kobo.763.1"> is the number of queries. </span><span class="koboSpan" id="kobo.763.2">In this case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.764.1">nb=len(df)</span></code> </li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.765.1">acc=acc_counter/nb</span></code><span class="koboSpan" id="kobo.766.1"> calculates the overall accuracy of all the results</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.767.1">The code then displays the number of documents measured and the overall similarity score:</span></p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in"><span class="koboSpan" id="kobo.768.1">print</span></span><span class="koboSpan" id="kobo.769.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.770.1">f"Number of documents: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.771.1">{nb:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.772.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.773.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.774.1">"</span></span><span class="koboSpan" id="kobo.775.1">)
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.776.1">print</span></span><span class="koboSpan" id="kobo.777.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.778.1">f"Overall similarity score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.779.1">{acc:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.780.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.781.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.782.1">"</span></span><span class="koboSpan" id="kobo.783.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.784.1">The output shows that all the questions returned relevant results:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.785.1">Number of documents: 10481.00
Overall similarity score: 1.00
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.786.1">This satisfactory overall similarity score shows that the system works in a closed environment. </span><span class="koboSpan" id="kobo.786.2">But </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.787.1">we need to go further and see what happens in the open environment of heated discussions in a meeting!</span></p>
    <h1 id="_idParaDest-215" class="heading-1"><span class="koboSpan" id="kobo.788.1">Prompt and retrieval</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.789.1">This section is the one to use during real-time querying meetings. </span><span class="koboSpan" id="kobo.789.2">You can adapt the interface to your needs. </span><span class="koboSpan" id="kobo.789.3">We’ll focus on functionality.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.790.1">Let’s look at the first</span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.791.1"> prompt:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.792.1"># initial question</span></span><span class="koboSpan" id="kobo.793.1">
prompt = </span><span class="hljs-string"><span class="koboSpan" id="kobo.794.1">"Millions of years ago, plants used energy from the sun to form what?"</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.795.1"># variant 1 similar</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.796.1">#prompt = "Eons ago, plants used energy from the sun to form what?"</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.797.1"># variant 2 divergent</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.798.1">#prompt = "Eons ago, plants used sun energy to form what?"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.799.1">You will notice that there are two commented variants under the first prompt. </span><span class="koboSpan" id="kobo.799.2">Let’s clarify this:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.800.1">initial question</span></code><span class="koboSpan" id="kobo.801.1"> is the exact text that comes from the initial dataset. </span><span class="koboSpan" id="kobo.801.2">It isn’t likely that an attendee in the meeting or a user will ask the question that way. </span><span class="koboSpan" id="kobo.801.3">But we can use it to verify if the system is working.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.802.1">variant 1</span></code><span class="koboSpan" id="kobo.803.1"> is similar to the initial question and could be asked.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.804.1">variant 2</span></code><span class="koboSpan" id="kobo.805.1"> diverges and may prove challenging.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.806.1">We will select </span><code class="inlineCode"><span class="koboSpan" id="kobo.807.1">variant 1</span></code><span class="koboSpan" id="kobo.808.1"> for this section and we should obtain a satisfactory result.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.809.1">We can see that, as for all AI programs, human control is mandatory! </span><span class="koboSpan" id="kobo.809.2">The more </span><code class="inlineCode"><span class="koboSpan" id="kobo.810.1">variant 2</span></code><span class="koboSpan" id="kobo.811.1"> diverges with spontaneous questions, the more challenging it becomes for the system to remain stable and respond as we expect. </span><span class="koboSpan" id="kobo.811.2">This limit explains why, even if a dynamic RAG system can adapt rapidly, designing a solid system will require careful and continual improvements.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.812.1">If we query the collection as we did in the previous section with one prompt only this time, we will obtain a response rapidly:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.813.1">import</span></span><span class="koboSpan" id="kobo.814.1"> time
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.815.1">import</span></span><span class="koboSpan" id="kobo.816.1"> textwrap
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.817.1"># Start timing before the request</span></span><span class="koboSpan" id="kobo.818.1">
start_time = time.time()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.819.1"># Query the collection using the prompt</span></span><span class="koboSpan" id="kobo.820.1">
results = collection.query(
    query_texts=[prompt],  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.821.1"># Use the prompt in a list as expected by the query method</span></span><span class="koboSpan" id="kobo.822.1">
    n_results=</span><span class="hljs-number"><span class="koboSpan" id="kobo.823.1">1</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.824.1"># Number of results to retrieve</span></span><span class="koboSpan" id="kobo.825.1">
)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.826.1"># Measure response time</span></span><span class="koboSpan" id="kobo.827.1">
response_time = time.time() - start_time
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.828.1"># Print response time</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.829.1">print</span></span><span class="koboSpan" id="kobo.830.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.831.1">f"Response Time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.832.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.833.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.834.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.835.1"> seconds\n"</span></span><span class="koboSpan" id="kobo.836.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.837.1"># Check if documents are retrieved</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.838.1">if</span></span><span class="koboSpan" id="kobo.839.1"> results[</span><span class="hljs-string"><span class="koboSpan" id="kobo.840.1">'documents'</span></span><span class="koboSpan" id="kobo.841.1">] </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.842.1">and</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.843.1">len</span></span><span class="koboSpan" id="kobo.844.1">(results[</span><span class="hljs-string"><span class="koboSpan" id="kobo.845.1">'documents'</span></span><span class="koboSpan" id="kobo.846.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.847.1">0</span></span><span class="koboSpan" id="kobo.848.1">]) &gt; </span><span class="hljs-number"><span class="koboSpan" id="kobo.849.1">0</span></span><span class="koboSpan" id="kobo.850.1">:
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.851.1"># Use textwrap to format the output for better readability</span></span><span class="koboSpan" id="kobo.852.1">
    wrapped_question = textwrap.fill(prompt, width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.853.1">70</span></span><span class="koboSpan" id="kobo.854.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.855.1"># Wrap text at 70 characters</span></span><span class="koboSpan" id="kobo.856.1">
    wrapped_document = textwrap.fill(results[</span><span class="hljs-string"><span class="koboSpan" id="kobo.857.1">'documents'</span></span><span class="koboSpan" id="kobo.858.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.859.1">0</span></span><span class="koboSpan" id="kobo.860.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.861.1">0</span></span><span class="koboSpan" id="kobo.862.1">], width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.863.1">70</span></span><span class="koboSpan" id="kobo.864.1">)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.865.1"># Print formatted results</span></span>
    <span class="hljs-built_in"><span class="koboSpan" id="kobo.866.1">print</span></span><span class="koboSpan" id="kobo.867.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.868.1">f"Question: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.869.1">{wrapped_question}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.870.1">"</span></span><span class="koboSpan" id="kobo.871.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.872.1">print</span></span><span class="koboSpan" id="kobo.873.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.874.1">"\n"</span></span><span class="koboSpan" id="kobo.875.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.876.1">print</span></span><span class="koboSpan" id="kobo.877.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.878.1">f"Retrieved document: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.879.1">{wrapped_document}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.880.1">"</span></span><span class="koboSpan" id="kobo.881.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.882.1">print</span></span><span class="koboSpan" id="kobo.883.1">()
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.884.1">else</span></span><span class="koboSpan" id="kobo.885.1">:
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.886.1">print</span></span><span class="koboSpan" id="kobo.887.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.888.1">"No documents retrieved."</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.889.1">The response </span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.890.1">time is rapid:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.891.1">Response Time: 0.03 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.892.1">The output shows that the retrieved document is relevant:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.893.1">Response Time: 0.03 seconds
Question: Millions of years ago, plants used energy from the sun to form what?
</span><span class="koboSpan" id="kobo.893.2">Retrieved document: chloroplasts because When ancient plants underwent photosynthesis,
they changed energy in sunlight to stored chemical energy in food. </span><span class="koboSpan" id="kobo.893.3">The
plants used the food and so did the organisms that ate the plants.
</span><span class="koboSpan" id="kobo.893.4">After the plants and other organisms died, their remains gradually
changed to fossil fuels as they were covered and compressed by layers
of sediments. </span><span class="koboSpan" id="kobo.893.5">Petroleum and natural gas formed from ocean organisms
and are found together. </span><span class="koboSpan" id="kobo.893.6">Coal formed from giant tree ferns and other
swamp plants.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.894.1">We have successfully retrieved the result of our query. </span><span class="koboSpan" id="kobo.894.2">This semantic vector search might even be enough if the </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.895.1">attendees of the meeting are satisfied with it. </span><span class="koboSpan" id="kobo.895.2">You will always have time to improve the configuration of RAG with Llama.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.896.1">Hugging Face Llama will now take this response and write a brief NLP summary.</span></p>
    <h1 id="_idParaDest-216" class="heading-1"><span class="koboSpan" id="kobo.897.1">RAG with Llama</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.898.1">We initialized </span><code class="inlineCode"><span class="koboSpan" id="kobo.899.1">meta-llama/Llama-2-7b-chat-hf</span></code><span class="koboSpan" id="kobo.900.1"> in the </span><em class="italic"><span class="koboSpan" id="kobo.901.1">Installing the environment</span></em><span class="koboSpan" id="kobo.902.1"> section. </span><span class="koboSpan" id="kobo.902.2">We must now </span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.903.1">create a function to configure Llama 2’s</span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.904.1"> behavior:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.905.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.906.1">LLaMA2</span></span><span class="koboSpan" id="kobo.907.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.908.1">prompt</span></span><span class="koboSpan" id="kobo.909.1">):
    sequences = pipeline(
        prompt,
        do_sample=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.910.1">True</span></span><span class="koboSpan" id="kobo.911.1">,
        top_k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.912.1">10</span></span><span class="koboSpan" id="kobo.913.1">,
        num_return_sequences=</span><span class="hljs-number"><span class="koboSpan" id="kobo.914.1">1</span></span><span class="koboSpan" id="kobo.915.1">,
        eos_token_id=tokenizer.eos_token_id,
        max_new_tokens=</span><span class="hljs-number"><span class="koboSpan" id="kobo.916.1">100</span></span><span class="koboSpan" id="kobo.917.1">, </span><span class="hljs-comment"><span class="koboSpan" id="kobo.918.1"># Control the output length more granularly</span></span><span class="koboSpan" id="kobo.919.1">
        temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.920.1">0.5</span></span><span class="koboSpan" id="kobo.921.1">,  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.922.1"># Slightly higher for more diversity</span></span><span class="koboSpan" id="kobo.923.1">
        repetition_penalty=</span><span class="hljs-number"><span class="koboSpan" id="kobo.924.1">2.0</span></span><span class="koboSpan" id="kobo.925.1">,  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.926.1"># Adjust based on experimentation</span></span><span class="koboSpan" id="kobo.927.1">
        truncation=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.928.1">True</span></span><span class="koboSpan" id="kobo.929.1">
    )
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.930.1">return</span></span><span class="koboSpan" id="kobo.931.1"> sequences
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.932.1">You can tweak each parameter to your expectations:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.933.1">prompt</span></code><span class="koboSpan" id="kobo.934.1">: The input text that the model uses to generate the output. </span><span class="koboSpan" id="kobo.934.2">It’s the starting point for the model’s response.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.935.1">do_sample</span></code><span class="koboSpan" id="kobo.936.1">: A Boolean value (</span><code class="inlineCode"><span class="koboSpan" id="kobo.937.1">True</span></code><span class="koboSpan" id="kobo.938.1"> or </span><code class="inlineCode"><span class="koboSpan" id="kobo.939.1">False</span></code><span class="koboSpan" id="kobo.940.1">). </span><span class="koboSpan" id="kobo.940.2">When set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.941.1">True</span></code><span class="koboSpan" id="kobo.942.1">, it enables stochastic sampling, meaning the model will pick tokens randomly based on their probability distribution, allowing for more varied outputs.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.943.1">top_k</span></code><span class="koboSpan" id="kobo.944.1">: This parameter limits the</span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.945.1"> number of highest-probability vocabulary tokens to consider when selecting tokens in the sampling process. </span><span class="koboSpan" id="kobo.945.2">Setting it to </span><code class="inlineCode"><span class="koboSpan" id="kobo.946.1">10</span></code><span class="koboSpan" id="kobo.947.1"> means the model will </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.948.1">choose from the top 10 most likely next tokens.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.949.1">num_return_sequences</span></code><span class="koboSpan" id="kobo.950.1">: Specifies the number of independently generated responses to return. </span><span class="koboSpan" id="kobo.950.2">Here, it is set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.951.1">1</span></code><span class="koboSpan" id="kobo.952.1">, meaning the function will return one sequence for each prompt.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.953.1">eos_token_id</span></code><span class="koboSpan" id="kobo.954.1">: This token marks the end of a sequence in tokenized form. </span><span class="koboSpan" id="kobo.954.2">Once it is generated, the model stops generating further tokens. </span><span class="koboSpan" id="kobo.954.3">The end-of-sequence token is an </span><code class="inlineCode"><span class="koboSpan" id="kobo.955.1">id</span></code><span class="koboSpan" id="kobo.956.1"> that points to Llama’s </span><code class="inlineCode"><span class="koboSpan" id="kobo.957.1">eos_token</span></code><span class="koboSpan" id="kobo.958.1">.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.959.1">max_new_tokens</span></code><span class="koboSpan" id="kobo.960.1">: Limits the number of new tokens the model can generate. </span><span class="koboSpan" id="kobo.960.2">Set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.961.1">100</span></code><span class="koboSpan" id="kobo.962.1"> here, it constrains the output to a maximum length of 100 tokens beyond the input prompt length.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.963.1">temperature</span></code><span class="koboSpan" id="kobo.964.1">: This controls randomness in the sampling process. </span><span class="koboSpan" id="kobo.964.2">A temperature of </span><code class="inlineCode"><span class="koboSpan" id="kobo.965.1">0.5</span></code><span class="koboSpan" id="kobo.966.1"> makes the model’s responses less random and more focused than a higher temperature but still allows for some diversity.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.967.1">repetition_penalty</span></code><span class="koboSpan" id="kobo.968.1">: A modifier that discourages the model from repeating the same token. </span><span class="koboSpan" id="kobo.968.2">A penalty of </span><code class="inlineCode"><span class="koboSpan" id="kobo.969.1">2.0</span></code><span class="koboSpan" id="kobo.970.1"> means any token already used is less likely to be chosen again, promoting more diverse and less repetitive text.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.971.1">truncation</span></code><span class="koboSpan" id="kobo.972.1">: When enabled, it ensures the output does not exceed the maximum length specified by </span><code class="inlineCode"><span class="koboSpan" id="kobo.973.1">max_new_tokens</span></code><span class="koboSpan" id="kobo.974.1"> by cutting off excess tokens.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.975.1">The prompt will contain the instruction for Llama in </span><code class="inlineCode"><span class="koboSpan" id="kobo.976.1">iprompt</span></code><span class="koboSpan" id="kobo.977.1"> and the result obtained in the </span><em class="italic"><span class="koboSpan" id="kobo.978.1">Prompt and retrieval</span></em><span class="koboSpan" id="kobo.979.1"> section of the notebook. </span><span class="koboSpan" id="kobo.979.2">The result is appended to </span><code class="inlineCode"><span class="koboSpan" id="kobo.980.1">iprompt</span></code><span class="koboSpan" id="kobo.981.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.982.1">iprompt=</span><span class="hljs-string"><span class="koboSpan" id="kobo.983.1">'Read the following input and write a summary for beginners.'</span></span><span class="koboSpan" id="kobo.984.1">
lprompt=iprompt + </span><span class="hljs-string"><span class="koboSpan" id="kobo.985.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.986.1"> "</span></span><span class="koboSpan" id="kobo.987.1"> + results[</span><span class="hljs-string"><span class="koboSpan" id="kobo.988.1">'documents'</span></span><span class="koboSpan" id="kobo.989.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.990.1">0</span></span><span class="koboSpan" id="kobo.991.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.992.1">0</span></span><span class="koboSpan" id="kobo.993.1">]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.994.1">The augmented input for the Llama call is </span><code class="inlineCode"><span class="koboSpan" id="kobo.995.1">lprompt</span></code><span class="koboSpan" id="kobo.996.1">. </span><span class="koboSpan" id="kobo.996.2">The code will measure the time it takes and make the completion request:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.997.1">import</span></span><span class="koboSpan" id="kobo.998.1"> time
start_time = time.time()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.999.1"># Start timing before the request</span></span><span class="koboSpan" id="kobo.1000.1">
response=LLaMA2(lprompt)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1001.1">We now retrieve the generated text from the response and display the time it took for Llama to respond:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1002.1">for</span></span><span class="koboSpan" id="kobo.1003.1"> seq </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1004.1">in</span></span><span class="koboSpan" id="kobo.1005.1"> response:
    generated_part = seq[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1006.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1007.1">generated_text'</span></span><span class="koboSpan" id="kobo.1008.1">].replace(iprompt, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1009.1">''</span></span><span class="koboSpan" id="kobo.1010.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1011.1"># Remove the input part from the output</span></span><span class="koboSpan" id="kobo.1012.1">
  
response_time = time.time() - start_time  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1013.1"># Measure response time</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.1014.1">print</span></span><span class="koboSpan" id="kobo.1015.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1016.1">f"Response Time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1017.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.1018.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1019.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1020.1"> seconds"</span></span><span class="koboSpan" id="kobo.1021.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1022.1"># Print response timeLe</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1023.1">The output shows that</span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.1024.1"> Llama returned the completion in a reasonable</span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.1025.1"> time:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1026.1">Response Time: 5.91 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1027.1">Let’s wrap the response in a nice format to display it:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1028.1">wrapped_response = textwrap.fill(response[</span><span class="hljs-number"><span class="koboSpan" id="kobo.1029.1">0</span></span><span class="koboSpan" id="kobo.1030.1">][</span><span class="hljs-string"><span class="koboSpan" id="kobo.1031.1">'generated_text'</span></span><span class="koboSpan" id="kobo.1032.1">], width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.1033.1">70</span></span><span class="koboSpan" id="kobo.1034.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1035.1">print</span></span><span class="koboSpan" id="kobo.1036.1">(wrapped_response)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1037.1">The output displays a technically reasonable completion:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1038.1">chloroplasts because When ancient plants underwent photosynthesis,
they changed energy in sunlight to stored chemical energy in food. </span><span class="koboSpan" id="kobo.1038.2">The
plants used the food and so did the organisms that ate the plants.
</span><span class="koboSpan" id="kobo.1038.3">After the plants and other organisms died, their remains gradually
changed to fossil fuels as they were covered and compressed by layers
of sediments. </span><span class="koboSpan" id="kobo.1038.4">Petroleum and natural gas formed from ocean organisms
and are found together. </span><span class="koboSpan" id="kobo.1038.5">Coal formed from giant tree ferns and other
swamp plants. </span><span class="koboSpan" id="kobo.1038.6">Natural Gas: 10% methane (CH4) - mostly derived from
anaerobic decomposition or fermentation processes involving
microorganism such As those present In wetlands; also contains smaller
amounts Of ethene(C2H6), propiene/propadiene/( C3 H5-7). </span><span class="koboSpan" id="kobo.1038.7">This is where
most petrol comes frm! </span><span class="koboSpan" id="kobo.1038.8">But there're more complex hydrocarbons like
pentanes &amp; hexans too which can come
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1039.1">The summary produced by Llama is technically acceptable. </span><span class="koboSpan" id="kobo.1039.2">To obtain another, possibly better result, as long as the session is not closed, the user can run a query and an augmented generation several times with different Llama parameters.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1040.1">You can even try another LLM. </span><span class="koboSpan" id="kobo.1040.2">Dynamic RAG doesn’t necessarily have to be 100% open-source. </span><span class="koboSpan" id="kobo.1040.3">If necessary, we must be pragmatic and introduce whatever it takes. </span><span class="koboSpan" id="kobo.1040.4">For example, the following prompt </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.1041.1">was submitted to ChatGPT with GPT-4o, which is the result of the query we </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.1042.1">used for Llama:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1043.1">Write a nice summary with this text: Question: Millions of years ago, plants used energy from the sun to form what?
</span><span class="koboSpan" id="kobo.1043.2">Retrieved document: chloroplasts because When ancient plants underwent photosynthesis,
they changed energy in sunlight to stored chemical energy in food. </span><span class="koboSpan" id="kobo.1043.3">The plants used the food and so did the organisms that ate the plants. </span><span class="koboSpan" id="kobo.1043.4">After the plants and other organisms died, their remains gradually
changed to fossil fuels as they were covered and compressed by layers of sediments. </span><span class="koboSpan" id="kobo.1043.5">Petroleum and natural gas formed from ocean organisms and are found together. </span><span class="koboSpan" id="kobo.1043.6">Coal formed from giant tree ferns and other swamp plants.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1044.1">The output of OpenAI GPT-4o surpasses Llama 2 in this case and produces a satisfactory output:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1045.1">Millions of years ago, plants harnessed energy from the sun through photosynthesis to produce food, storing chemical energy. </span><span class="koboSpan" id="kobo.1045.2">This energy was vital for the plants themselves and for the organisms that consumed them. </span><span class="koboSpan" id="kobo.1045.3">Over time, the remains of these plants and animals, buried under sediment, transformed into fossil fuels. </span><span class="koboSpan" id="kobo.1045.4">Ocean organisms' remains contributed to the formation of petroleum and natural gas, often found together, while the remains of giant tree ferns and swamp plants formed coal.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1046.1">If necessary, you can replace </span><code class="inlineCode"><span class="koboSpan" id="kobo.1047.1">meta-llama/Llama-2-7b-chat-hf</span></code><span class="koboSpan" id="kobo.1048.1"> with GPT-4o, as implemented in </span><em class="chapterRef"><span class="koboSpan" id="kobo.1049.1">Chapter 4</span></em><span class="koboSpan" id="kobo.1050.1">, </span><em class="italic"><span class="koboSpan" id="kobo.1051.1">Multimodal Modular RAG for Drone Technology</span></em><span class="koboSpan" id="kobo.1052.1">, and configure it to obtain this level of output. </span><span class="koboSpan" id="kobo.1052.2">The only rule in dynamic RAG is performance. </span><span class="koboSpan" id="kobo.1052.3">With that, we’ve seen that there are many ways to implement dynamic RAG.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1053.1">Once the session is over, we can delete it.</span></p>
    <h2 id="_idParaDest-217" class="heading-2"><span class="koboSpan" id="kobo.1054.1">Deleting the collection</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.1055.1">You can manually</span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.1056.1"> delete the collection with the following code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1057.1">#client.delete_collection(collection_name)</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1058.1">You can also close the session to delete the temporary dynamic RAG collection created. </span><span class="koboSpan" id="kobo.1058.2">We can check and see whether the collection we created, </span><code class="inlineCode"><span class="koboSpan" id="kobo.1059.1">collection_name</span></code><span class="koboSpan" id="kobo.1060.1">, still exists or not:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1061.1"># List all collections</span></span><span class="koboSpan" id="kobo.1062.1">
collections = client.list_collections()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1063.1"># Check if the specific collection exists</span></span><span class="koboSpan" id="kobo.1064.1">
collection_exists = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1065.1">any</span></span><span class="koboSpan" id="kobo.1066.1">(collection.name == collection_name </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1067.1">for</span></span><span class="koboSpan" id="kobo.1068.1"> collection </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1069.1">in</span></span><span class="koboSpan" id="kobo.1070.1"> collections)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1071.1">print</span></span><span class="koboSpan" id="kobo.1072.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1073.1">"Collection exists:"</span></span><span class="koboSpan" id="kobo.1074.1">, collection_exists)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1075.1">If we are still working on a collection in a session, the response will be </span><code class="inlineCode"><span class="koboSpan" id="kobo.1076.1">True</span></code><span class="koboSpan" id="kobo.1077.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1078.1">Collection exists: </span><span class="hljs-literal"><span class="koboSpan" id="kobo.1079.1">True</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1080.1">If we delete the</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.1081.1"> collection with code or by closing the session, the response will be </span><code class="inlineCode"><span class="koboSpan" id="kobo.1082.1">False</span></code><span class="koboSpan" id="kobo.1083.1">. </span><span class="koboSpan" id="kobo.1083.2">Let’s take a look at the total session time.</span></p>
    <h1 id="_idParaDest-218" class="heading-1"><span class="koboSpan" id="kobo.1084.1">Total session time</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1085.1">The following code measures </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.1086.1">the time between the beginning of the session and immediately after the </span><em class="italic"><span class="koboSpan" id="kobo.1087.1">Installing the environment</span></em><span class="koboSpan" id="kobo.1088.1"> section:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1089.1">end_time = time.time() - session_start_time  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1090.1"># Measure response time</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.1091.1">print</span></span><span class="koboSpan" id="kobo.1092.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1093.1">f"Session preparation time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1094.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.1095.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1096.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1097.1"> seconds"</span></span><span class="koboSpan" id="kobo.1098.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1099.1"># Print response time</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1100.1">The output can have two meanings:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1101.1">It can measure the time we worked on the preparation of the dynamic RAG scenario with the daily dataset for the Chroma collection, querying, and summarizing by Llama.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1102.1">It can measure the time it took to run the whole notebook without intervening at all.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.1103.1">In this case, the session time is the result of a full run with no human intervention:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1104.1">Session preparation time: 780.35 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1105.1">The whole process takes less than 15 minutes, which fits the constraints of the preparation time in a dynamic RAG scenario. </span><span class="koboSpan" id="kobo.1105.2">It leaves room for a few runs to tweak the system before the</span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.1106.1"> meeting. </span><span class="koboSpan" id="kobo.1106.2">With that, we have successfully walked through a dynamic RAG process and will now summarize our journey.</span></p>
    <h1 id="_idParaDest-219" class="heading-1"><span class="koboSpan" id="kobo.1107.1">Summary</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1108.1">In a fast-evolving world, gathering information rapidly for decision-making provides a competitive advantage. </span><span class="koboSpan" id="kobo.1108.2">Dynamic RAG is one way to bring AI into meeting rooms with rapid and cost-effective AI. </span><span class="koboSpan" id="kobo.1108.3">We built a system that simulated the need to obtain answers to hard science questions in a daily meeting. </span><span class="koboSpan" id="kobo.1108.4">After installing and analyzing the environment, we downloaded and prepared the SciQ dataset, a science question-and-answer dataset, to simulate a daily meeting during which hard science questions would be asked. </span><span class="koboSpan" id="kobo.1108.5">The attendees don’t want to spend their time searching the web and wasting their time when decisions must be made. </span><span class="koboSpan" id="kobo.1108.6">This could be for a marketing campaign, fact-checking an article, or any other situation in which hard science knowledge is required.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1109.1">We created a Chroma collection vector store. </span><span class="koboSpan" id="kobo.1109.2">We then embedded 10,000+ documents and inserted data and vectors into the Chroma vector store on our machine with </span><code class="inlineCode"><span class="koboSpan" id="kobo.1110.1">all-MiniLM-L6-v2</span></code><span class="koboSpan" id="kobo.1111.1">. </span><span class="koboSpan" id="kobo.1111.2">The process proved cost-effective and sufficiently rapid. </span><span class="koboSpan" id="kobo.1111.3">The collection was created locally, so there is no storage cost. </span><span class="koboSpan" id="kobo.1111.4">The collection is temporary, so there is no useless space usage or cluttering. </span><span class="koboSpan" id="kobo.1111.5">We then queried the collection to measure the accuracy of the system we set up. </span><span class="koboSpan" id="kobo.1111.6">The results were satisfactory, so we processed the full dataset to confirm. </span><span class="koboSpan" id="kobo.1111.7">Finally, we created the functionality for a user prompt and query function to use in real time during a meeting. </span><span class="koboSpan" id="kobo.1111.8">The result of the query augmented the user’s input for </span><code class="inlineCode"><span class="koboSpan" id="kobo.1112.1">meta-llama/Llama-2-7b-chat-hf</span></code><span class="koboSpan" id="kobo.1113.1">, which transformed the query into a short summary.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1114.1">The dynamic RAG example we implemented would require more work before being released into production. </span><span class="koboSpan" id="kobo.1114.2">However, it provides a path to open-source, lightweight, RAG-driven generative AI for rapid data collection, embedding, and querying. </span><span class="koboSpan" id="kobo.1114.3">If we need to store the retrieval data and don’t want to create large vector stores, we can integrate our datasets in an OpenAI GPT-4o-mini model, for example, through fine-tuning, as we will see in the next chapter.</span></p>
    <h1 id="_idParaDest-220" class="heading-1"><span class="koboSpan" id="kobo.1115.1">Questions</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1116.1">Answer the following questions with </span><em class="italic"><span class="koboSpan" id="kobo.1117.1">Yes</span></em><span class="koboSpan" id="kobo.1118.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.1119.1">No</span></em><span class="koboSpan" id="kobo.1120.1">:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.1121.1">Does the script ensure that the Hugging Face API token is never hardcoded directly into the notebook for security reasons?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1122.1">In the chapter’s program, is the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1123.1">accelerate</span></code><span class="koboSpan" id="kobo.1124.1"> library used here to facilitate the deployment of ML models on cloud-based platforms?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1125.1">Is user authentication separate from the API token required to access the Chroma database in this script?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1126.1">Does the notebook use Chroma for temporary storage of vectors during the dynamic retrieval process?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1127.1">Is the notebook configured to use real-time acceleration of queries through GPU optimization?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1128.1">Can this notebook’s session time measurements help in optimizing the dynamic RAG process?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1129.1">Does the script demonstrate Chroma’s capability to integrate with ML models for enhanced retrieval performance?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1130.1">Does the script include functionality for adjusting the parameters of the Chroma database based on session performance metrics?</span></li>
    </ol>
    <h1 id="_idParaDest-221" class="heading-1"><span class="koboSpan" id="kobo.1131.1">References</span></h1>
    <ul>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1132.1">Crowdsourcing Multiple Choice Science Questions</span></em><span class="koboSpan" id="kobo.1133.1"> by Johannes Welbl, Nelson F. </span><span class="koboSpan" id="kobo.1133.2">Liu, Matt Gardner: </span><a href="http://arxiv.org/abs/1707.06209"><span class="url"><span class="koboSpan" id="kobo.1134.1">http://arxiv.org/abs/1707.06209</span></span></a><span class="koboSpan" id="kobo.1135.1">.</span></li>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1136.1">MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers </span></em><span class="koboSpan" id="kobo.1137.1">by Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, Furu Wei: </span><a href="https://arxiv.org/abs/2012.15828"><span class="url"><span class="koboSpan" id="kobo.1138.1">https://arxiv.org/abs/2012.15828</span></span></a><span class="koboSpan" id="kobo.1139.1">.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1140.1">Hugging Face Llama model documentation: </span><a href="https://huggingface.co/docs/transformers/main/en/model_doc/llama"><span class="url"><span class="koboSpan" id="kobo.1141.1">https://huggingface.co/docs/transformers/main/en/model_doc/llama</span></span></a><span class="koboSpan" id="kobo.1142.1">.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1143.1">ONNX: </span><a href="https://onnxruntime.ai/"><span class="url"><span class="koboSpan" id="kobo.1144.1">https://onnxruntime.ai/</span></span></a><span class="koboSpan" id="kobo.1145.1">.</span></li>
    </ul>
    <h1 id="_idParaDest-222" class="heading-1"><span class="koboSpan" id="kobo.1146.1">Further reading</span></h1>
    <ul>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1147.1">MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers</span></em><span class="koboSpan" id="kobo.1148.1"> by Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, Ming Zhou: </span><a href="https://arxiv.org/abs/2002.10957"><span class="url"><span class="koboSpan" id="kobo.1149.1">https://arxiv.org/abs/2002.10957</span></span></a><span class="koboSpan" id="kobo.1150.1">.</span></li>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1151.1">LLaMA: Open and Efficient Foundation Language Models</span></em><span class="koboSpan" id="kobo.1152.1"> by Hugo Touvron, Thibaut Lavril, Gautier Lzacard, et al.: </span><a href="https://arxiv.org/abs/2302.13971"><span class="url"><span class="koboSpan" id="kobo.1153.1">https://arxiv.org/abs/2302.13971</span></span></a><span class="koboSpan" id="kobo.1154.1">.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1155.1">Building an ONNX Runtime package: </span><a href="https://onnxruntime.ai/docs/build/custom.html#custom-build-packages"><span class="url"><span class="koboSpan" id="kobo.1156.1">https://onnxruntime.ai/docs/build/custom.html#custom-build-packages</span></span></a><span class="koboSpan" id="kobo.1157.1">.</span></li>
    </ul>
    <h1 id="_idParaDest-223" class="heading-1"><span class="koboSpan" id="kobo.1158.1">Join our community on Discord</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1159.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
    <p class="normal"><a href="https://www.packt.link/rag"><span class="url"><span class="koboSpan" id="kobo.1160.1">https://www.packt.link/rag</span></span></a></p>
    <p class="normal"><span class="koboSpan" id="kobo.1161.1"><img src="../Images/QR_Code50409000288080484.png" alt=""/></span></p>
  </div>
</body></html>