<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-18">
    <a id="_idTextAnchor017">
    </a>
    
     1
    
   </h1>
   <h1 id="_idParaDest-19">
    <a id="_idTextAnchor018">
    </a>
    
     Fundamentals of Generative AI
    
   </h1>
   <p>
    
     Generative AI has quickly become a transformative technology in the field of
    
    <strong class="bold">
     
      artificial intelligence
     
    </strong>
    
     (
    
    <strong class="bold">
     
      AI
     
    </strong>
    
     ) and machine
    
    <a id="_idIndexMarker000">
    </a>
    
     learning, revolutionizing creative processes and problem-solving across diverse industries and use cases.
    
    
     It is pushing the boundaries of autonomy in agent-based intelligent systems.
    
    
     In this chapter, we will cover the basics of generative AI.
    
    
     We will explore what generative AI is along with a brief
    
    <a id="_idIndexMarker001">
    </a>
    
     history of generative AI models.
    
    
     We will then
    
    <a id="_idIndexMarker002">
    </a>
    
     discuss the different types of generative models, which include
    
    <strong class="bold">
     
      variational autoencoders
     
    </strong>
    
     (
    
    <strong class="bold">
     
      VAEs
     
    </strong>
    
     ),
    
    <strong class="bold">
     
      generative adversarial networks
     
    </strong>
    
     (
    
    <strong class="bold">
     
      GANs
     
    </strong>
    
     ), autoregressive, and Transformer models.
    
    
     Next, we will delve into the applications of generative AI and wrap up the chapter with a brief discussion of some of the limitations and challenges related to
    
    
     
      generative AI.
     
    
   </p>
   <p>
    
     We will cover the following topics in this introductory chapter that will help set the foundations of generative AI as we explore further the capabilities of autonomous intelligent agents powered by
    
    
     
      generative AI:
     
    
   </p>
   <ul>
    <li>
     
      Introduction to
     
     
      
       generative AI
      
     
    </li>
    <li>
     
      Types of generative
     
     
      
       AI models
      
     
    </li>
    <li>
     
      Applications of
     
     
      
       generative AI
      
     
    </li>
    <li>
     
      Challenges and limitations of
     
     
      
       generative AI
      
     
    </li>
   </ul>
   <p>
    
     By the end of this chapter, you will have gained a comprehensive understanding of generative AI, including its fundamental concepts, diverse applications, and current challenges.
    
    
     You will also learn about the technology‚Äôs potential and limitations, with a particular focus on its critical role in advancing intelligent agents and
    
    
     
      agentic systems.
     
    
   </p>
   <h1 id="_idParaDest-20">
    <a id="_idTextAnchor019">
    </a>
    
     Introduction to generative AI
    
   </h1>
   <p>
    
     Generative AI refers to a class of AI technologies that is capable of generating various forms of content, including but not limited to text, images, audio, and video.
    
    
     These AI systems can
    
    <a id="_idIndexMarker003">
    </a>
    
     generate new content, based on their training data and input parameters, which usually include text prompts but can also involve other forms of input such as images.
    
    
     The recent buzz around generative AI comes from the simplicity with which new user interfaces powered by this AI technology can create high-quality text, graphics, and videos
    
    
     
      in seconds.
     
    
   </p>
   <p>
    
     In very simple terms, generative AI is about making new data that looks like the data from which it has been trained.
    
    
     In other words, learning the underlying patterns, structures, and distributions of input data enables a procedure within the model allowing it to generate new data in a similar way.
    
    
     For instance, if trained on a dataset of human faces, a generative AI model will be able to create completely new faces of people that don‚Äôt actually exist in real life but are very realistic.
    
    
     In essence, generative AI models work by learning the probability distribution of a dataset and then sampling from that distribution to create new instances.
    
    
     This approach is different from discriminative models, whose goal is to learn how to tell classes of data apart.
    
    
     For example, a discriminative model could be trained to separate pictures of cats and dogs, but a generative model would be trained to make up completely new pictures of cats
    
    
     
      or dogs.
     
    
   </p>
   <p>
    
     The concept of generative AI goes a long way back; in fact, it dates back to the time when machine learning was in its cradle.
    
    
     However, it is only recently that this field has come under the limelight due to neural networks and drastic improvements in computing power over the last 10 years.
    
    
     In the early attempts at generative modeling‚ÄîGaussian mixture models and hidden Markov models‚Äîmany simpler statistical techniques were involved.
    
    
     Methods of modeling arbitrary complex data distributions have much higher potential compatibility with the kinds of methods that were previously dominant but have recently been overcome by deep learning.
    
    
     Deep learning was therefore a watershed development for the field of generative AI.
    
    
     Models, such as VAEs, which started appearing around the beginning of the 2010s, were able to leverage deep neural networks to model more complex data distributions.
    
    
     Around that same period, GANs were proposed; for the first time, they offered a new way for two neural networks to work together to create data, using principles from game theory.
    
    
     In a general sense, these breakthroughs took leaps toward the possibilities of making real, high-quality, realistic creation
    
    
     
      of data.
     
    
   </p>
   <p>
    
     This can lead to innovation in most fields across industries, such as healthcare, finance, education, travel and hospitality, manufacturing, and more.
    
    
     Generative AI in creative industries helps artists and designers think outside the box, helping with the conception of new and innovative content.
    
    
     It opens ways for new routes of drug discovery and personalized medicine in health.
    
    
     In the business world, generative AI works by providing efficient and effective customer engagement through personalized content and experiences.
    
    
     The
    
    <a id="_idIndexMarker004">
    </a>
    
     other point involves questioning one‚Äôs own stance regarding creativity and originality: when machines are able to pump out very similar material, one is automatically forced to think about what creativity is, who the artist really is, and what the ethical parameters should be for
    
    
     
      AI-created content.
     
    
   </p>
   <p>
    
     Having understood what generative AI is and its brief history, let‚Äôs explore the different types of generative
    
    
     
      AI models.
     
    
   </p>
   <h1 id="_idParaDest-21">
    <a id="_idTextAnchor020">
    </a>
    
     Types of generative AI models
    
   </h1>
   <p>
    
     Generative AI is an exciting domain of AI that deals with the generation of new, synthetic
    
    <a id="_idIndexMarker005">
    </a>
    
     data by learning patterns from existing datasets, aiming to generate outputs that share similar statistical properties and characteristics with the training data.
    
    
     Here is a broad overview of some of the most prominent types of generative models: VAEs, GANs, and
    
    
     
      autoregressive models.
     
    
   </p>
   <h2 id="_idParaDest-22">
    <a id="_idTextAnchor021">
    </a>
    
     VAEs
    
   </h2>
   <p>
    
     One of the most popular generative models is the VAE.
    
    
     The core idea behind VAE consists of
    
    <a id="_idIndexMarker006">
    </a>
    
     learning a probabilistic mapping between data and a latent space, and vice versa.
    
    
     This means learning how
    
    <a id="_idIndexMarker007">
    </a>
    
     to convert real data into a simplified representation (such as a compressed form) and then back again into data that looks real.
    
    
     VAEs are designed to ensure a high likelihood of the data while preserving a well-structured latent space to enable the generation of new data samples similar to the training data.
    
    
     Some of the most common flavors of VAE are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       VAE
      
     </strong>
     
      : The basic model that compresses and reconstructs data.
     
     
      It gives a framework for generating new samples out of the learned latent space.
     
     
      The VAE is a generative model that learns to compress and reconstruct data while also learning a probability distribution of the latent space.
     
     
      In simpler terms, a VAE is like a clever algorithm that learns to understand and recreate data.
     
     
      Imagine it as a skilled artist who can compress a detailed painting into a simple sketch (encoding) and then recreate the full painting from that sketch (decoding).
     
     
      What makes VAEs special is that they don‚Äôt just copy data but also learn the essence of it, allowing them to create new, similar data.
     
     
      This is like an artist learning not just to copy specific paintings but also to understand the style so well that they can paint new, original works in that style.
     
     
      In real life, VAEs have been used in many creative ways.
     
     
      For instance, in drug discovery, VAEs have been used to generate novel molecular structures.
     
     
      Researchers at AstraZeneca used VAEs to explore chemical space and propose new drug-like molecules with desired properties, potentially accelerating the drug development
     
     
      
       process [1].
      
     
    </li>
    <li>
     <strong class="bold">
      
       Beta-VAE
      
     </strong>
     
      : An extension of VAE that introduces a hyperparameter to control explicitly the trade-off between the reconstruction quality and the disentanglement of the latent space.
     
     
      The model undertakes the creation of more
     
     <a id="_idIndexMarker008">
     </a>
     
      interpretable disentangled representations.
     
     
      In simpler terms, Beta-VAE is like a more flexible version of the original VAE.
     
     
      It allows researchers to adjust how much the model focuses on recreating exact details versus understanding the underlying features of the data.
     
     
      This is similar to teaching an art student to not just copy a painting but also to understand and separate the key elements such as color, shape, and style.
     
     
      This ability to
     
     <em class="italic">
      
       disentangle
      
     </em>
     
      features makes Beta-VAE particularly useful in fields such as computer vision and robotics.
     
     
      For example, researchers have used Beta-VAE to teach robots to understand objects better.
     
     
      By learning to separate features such as size, color, and position, robots can more easily recognize and manipulate objects in different situations, making them more adaptable and efficient in various
     
     
      
       tasks [2].
      
     
    </li>
    <li>
     <strong class="bold">
      
       Conditional variational autoencoder
      
     </strong>
     
      (
     
     <strong class="bold">
      
       CVAE
      
     </strong>
     
      ): A variant that conditions the generation process on some extra information, typically class labels, producing not just data similar to the training set but also samples that can then be drawn from specific classes .
     
     
      Think of CVAE as a more controlled version of VAE, like an artist who can paint in different styles on demand.
     
     
      Instead of just creating random new paintings, this artist can be told to ‚Äú
     
     <em class="italic">
      
       Paint a landscape
      
     </em>
     
      ‚Äù or ‚Äú
     
     <em class="italic">
      
       Paint a portrait
      
     </em>
     
      ‚Äù and they‚Äôll create new art in that specific category.
     
     
      This added control makes CVAE very useful in practical applications.
     
     
      For instance, in the
     
     <a id="_idIndexMarker009">
     </a>
     
      field of computer games, CVAE has been used for game development and procedural content generation with the generation of game elements such as character design, level layouts, music and sound effects, and so on.
     
     
      By providing different conditions such as ‚Äú
     
     <em class="italic">
      
       Create a forest level
      
     </em>
     
      ‚Äù or ‚Äú
     
     <em class="italic">
      
       Create a desert level
      
     </em>
     
      ,‚Äù the CVAE can produce a wide variety of game environments, saving time for designers and enhancing the player‚Äôs experience with more diverse and interesting game
     
     
      
       worlds [3].
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-23">
    <a id="_idTextAnchor022">
    </a>
    
     GANs
    
   </h2>
   <p>
    
     A GAN is
    
    <a id="_idIndexMarker010">
    </a>
    
     basically formed by two neural networks: a
    
    <strong class="bold">
     
      generator
     
    </strong>
    
     and a
    
    <strong class="bold">
     
      discriminator
     
    </strong>
    
     .
    
    
     The generator generates synthetic data samples; the
    
    <a id="_idIndexMarker011">
    </a>
    
     other trained
    
    <a id="_idIndexMarker012">
    </a>
    
     neural network
    
    <a id="_idIndexMarker013">
    </a>
    
     should then be able to tell the difference between real and created samples.
    
    
     While training these networks, they are trained together antagonistically: the generator tries to fool the discriminator, while the discriminator tries rightly to classify real versus fake data.
    
    
     In this competition, the generator gets better and better at faking data.
    
    
     The following are some of the different types
    
    
     
      of GANs:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       GAN
      
     </strong>
     
      : The basic model in which the generator and discriminator are trained adversarially; it is the root model for most innovations in generative modeling.
     
     
      As explained earlier, you can imagine GAN as a game between two players‚Äîa counterfeiter (generator) trying to create fake money, and a detective (discriminator) trying to identify the fakes.
     
     
      As they compete, they both get better at their jobs, which means that the counterfeiter gets increasingly better at creating fake money.
     
     
      This clever setup allows GANs to create incredibly realistic fake data, such as images or
     
     
      
       sounds [4].
      
     
    </li>
    <li>
     <strong class="bold">
      
       Deep convolutional GAN
      
     </strong>
     
      (
     
     <strong class="bold">
      
       DCGAN
      
     </strong>
     
      ): This is a refinement of the base GAN model with deep convolutional neural networks; at the moment, it is one of the best architectures for generating images of high quality.
     
     
      Think of DCGAN as a more sophisticated artist compared to the basic GAN.
     
     
      It‚Äôs like upgrading from simple sketching tools to a full digital art studio, allowing for the creation of much more detailed and realistic images.
     
     
      DCGANs are particularly good at understanding and recreating complex patterns in
     
     
      
       images [5].
      
     
    </li>
    <li>
     <strong class="bold">
      
       Wasserstein GAN
      
     </strong>
     
      (
     
     <strong class="bold">
      
       WGAN
      
     </strong>
     
      ): This proposes a different loss function with the Wasserstein distance.
     
     
      This removes problems while training with a GAN, hence making training more stable and improving sample quality.
     
     
      This helps measure the distance between two probability distributions better.
     
     
      WGAN is like giving the
     
     <a id="_idIndexMarker014">
     </a>
     
      artist (generator) and critic (discriminator) in a GAN a better way to communicate and evaluate
     
     <a id="_idIndexMarker015">
     </a>
     
      each other‚Äôs work.
     
     
      Instead of just saying ‚Äú
     
     <em class="italic">
      
       good
      
     </em>
     
      ‚Äù or ‚Äú
     
     <em class="italic">
      
       bad
      
     </em>
     
      ,‚Äù they can now give more nuanced feedback, such as ‚Äú
     
     <em class="italic">
      
       You‚Äôre getting warmer
      
     </em>
     
      ‚Äù or ‚Äú
     
     <em class="italic">
      
       You‚Äôre way off
      
     </em>
     
      .‚Äù
     
     
      This leads to more consistent improvement and high-quality results.
     
     
      In practical applications, WGANs have been used in medical imaging to generate synthetic medical images for training purposes.
     
     
      This helps in creating larger, more diverse datasets for training diagnostic AI systems, potentially improving their accuracy in detecting diseases from scans and
     
     
      
       X-rays [6].
      
     
    </li>
    <li>
     <strong class="bold">
      
       StyleGAN
      
     </strong>
     
      : This generates high-quality realistic images.
     
     
      The model is especially good at handling style and content separately.
     
     
      Progressions offered by the introductions of StyleGAN2 and StyleGAN3 are still aimed at improving image fidelity and realism.
     
     
      Think of StyleGAN as an advanced digital artist that can not only create realistic images but also mix and match different styles and contents.
     
     
      It‚Äôs like having a painter who can take the style of Van Gogh and apply it to a modern cityscape.
     
     
      This flexibility makes StyleGAN incredibly
     
     
      
       versatile [7].
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-24">
    <a id="_idTextAnchor023">
    </a>
    
     Autoregressive models and Transformer architecture
    
   </h2>
   <p>
    
     Autoregressive
    
    <a id="_idIndexMarker016">
    </a>
    
     models generate their
    
    <a id="_idIndexMarker017">
    </a>
    
     data points
    
    <a id="_idIndexMarker018">
    </a>
    
     one at a time, conditioning
    
    <a id="_idIndexMarker019">
    </a>
    
     each of its data points on the previous one.
    
    
     Surprisingly, this ultimately proves very useful in tasks in which the sequence or structure of data is relevant, such as text generation and image generation.
    
    
     The
    
    <a id="_idIndexMarker020">
    </a>
    
     Transformer architecture, introduced
    
    <a id="_idIndexMarker021">
    </a>
    
     in the
    
    <em class="italic">
     
      Attention Is All You Need
     
    </em>
    
     paper [8], is a
    
    <a id="_idIndexMarker022">
    </a>
    
     model architecture
    
    <a id="_idIndexMarker023">
    </a>
    
     that has revolutionized many sequential
    
    <a id="_idIndexMarker024">
    </a>
    
     data tasks, especially in
    
    <strong class="bold">
     
      natural language processing
     
    </strong>
    
     (
    
    <strong class="bold">
     
      NLP
     
    </strong>
    
     ).
    
    
     Its key components are demonstrated in
    
    
     <em class="italic">
      
       Figure 1
      
     </em>
    
    
     <em class="italic">
      
       .1
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_01_1.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 1.1 ‚Äì The Transformer architecture
    
   </p>
   <p>
    
     These key
    
    <a id="_idIndexMarker025">
    </a>
    
     components include
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Self-attention m
      
     </strong>
     <strong class="bold">
      
       echanism
      
     </strong>
     
      : A computational technique that allows the model to dynamically focus on different parts of the input when processing
     
     
      
       each element
      
     
    </li>
    <li>
     <strong class="bold">
      
       Multi-head attention
      
     </strong>
     
      : Multiple attention mechanisms running in parallel, allowing the model to focus on different aspects of the
     
     
      
       input simultaneously
      
     
    </li>
    <li>
     <strong class="bold">
      
       Positional encoding
      
     </strong>
     
      : Adds information about the position of each element in
     
     
      
       the sequence
      
     
    </li>
    <li>
     <strong class="bold">
      
       Feed-forward neural networks
      
     </strong>
     
      : Process the output of the
     
     
      
       attention layers
      
     
    </li>
    <li>
     <strong class="bold">
      
       Layer normalization and residual connections
      
     </strong>
     
      : Enhance training stability and
     
     
      
       information flow
      
     
    </li>
   </ul>
   <p>
    
     Transformers can be used in both autoregressive and non-autoregressive configurations, making them versatile for various tasks.
    
    
     The following are
    
    
     
      some examples:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       PixelCNN
      
     </strong>
     
      : Autoregressively generates images pixel by pixel, conditioning each pixel
     
     <a id="_idIndexMarker026">
     </a>
     
      on the previously generated ones.
     
     
      This model works very well in generating high-quality images with fine
     
     
      
       details [9].
      
     
    </li>
    <li>
     <strong class="bold">
      
       PixelSNAIL
      
     </strong>
     
      : A refinement over PixelCNN that adds attention mechanisms into the
     
     <a id="_idIndexMarker027">
     </a>
     
      model to capture strong dependencies between pixels, and hence, a better quality of an
     
     
      
       image [10].
      
     
    </li>
    <li>
     <strong class="bold">
      
       GPT
      
     </strong>
     
      : Standing for
     
     <strong class="bold">
      
       Generative Pre-trained Transformer
      
     </strong>
     
      , it is a line of models
     
     <a id="_idIndexMarker028">
     </a>
     
      specializing in text generation‚Äînamely, predicting which words should come next.
     
     
      Among them are GPT-2, GPT-3, and GPT-4, making a huge leap in generating coherent and contextually relevant text [
     
     
      
       11] [12].
      
     
    </li>
    <li>
     <strong class="bold">
      
       BERT
      
     </strong>
     
      : Unlike
     
     <a id="_idIndexMarker029">
     </a>
     
      GPT, BERT, which stands for
     
     <strong class="bold">
      
       Bidirectional Encoder Representations from Transformers
      
     </strong>
     
      , is designed to understand the context from both directions in text.
     
     
      It uses the encoder part of the Transformer and is typically used for tasks that require an understanding of the entire input at once, rather than generating text
     
     
      
       autoregressively [13].
      
     
    </li>
    <li>
     <strong class="bold">
      
       Text-To-Text Transfer Transformer
      
     </strong>
     
      (
     
     <strong class="bold">
      
       T5
      
     </strong>
     
      ): This model frames all NLP tasks in a
     
     <a id="_idIndexMarker030">
     </a>
     
      text-to-text format.
     
     
      It uses the full Transformer architecture (both encoder and decoder) and can handle various text generation
     
     
      
       tasks [14].
      
     
    </li>
   </ul>
   <p>
    
     Although it depends on the task, these models demonstrate how the Transformer architecture can be adapted for both autoregressive (such as GPT) and non-autoregressive (such as BERT) tasks, showcasing its versatility in handling sequential data.
    
    
     Strengths differ across generative models.
    
    
     This class of models goes from generating photorealistic images to coherent text to totally new
    
    
     
      data samples.
     
    
   </p>
   <p>
    
     Building upon the success of models such as GPT, researchers have scaled up these architectures
    
    <a id="_idIndexMarker031">
    </a>
    
     to create
    
    <strong class="bold">
     
      large language models
     
    </strong>
    
     (
    
    <strong class="bold">
     
      LLMs
     
    </strong>
    
     ).
    
    
     These models, often trained on vast amounts of open web text and other freely available text data, have demonstrated exceptional proficiency in understanding and generating human-like text across diverse applications, showcasing their versatility and advanced linguistic abilities.
    
    
     Examples of LLMs include GPT-3, GPT-4, PaLM, and BERT-large.
    
    
     These models have pushed the boundaries of what‚Äôs possible in NLP, showing proficiency in tasks ranging from question-answering and summarization to creative writing and code generation.
    
    
     The following is an overview of the common types
    
    
     
      of LLMs:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Autoregressive LLMs
      
     </strong>
     
      : These language models are typically capable of generating
     
     <a id="_idIndexMarker032">
     </a>
     
      text sequentially, that is, one token at a time.
     
     
      Some of the common tasks that these types of models are used for include text generation, text completion tasks, and creative writing.
     
     
      Some popular examples of autoregressive LLMs are the GPT series (GPT-3, GPT-4),
     
     
      
       and PaLM.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Encoder-only LLMs
      
     </strong>
     
      : These
     
     <a id="_idIndexMarker033">
     </a>
     
      models specialize in
     
     <strong class="bold">
      
       natural language understanding
      
     </strong>
     
      (
     
     <strong class="bold">
      
       NLU
      
     </strong>
     
      ) tasks, which involve analyzing and comprehending input
     
     <a id="_idIndexMarker034">
     </a>
     
      text without generating new text.
     
     
      Encoder-only LLMs, such as BERT and its variants including RoBERTa, focus on understanding the context and meaning of input text.
     
     
      These models process the
     
     <a id="_idIndexMarker035">
     </a>
     
      entire input sequence simultaneously, allowing them to capture the context helping with tasks such as text classification,
     
     <strong class="bold">
      
       named entity recognition
      
     </strong>
     
      (
     
     <strong class="bold">
      
       NER
      
     </strong>
     
      ), and
     
     
      
       sentiment analysis.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Encoder-decoder LLMs
      
     </strong>
     
      : This is a combination of encoder and decoder architecture
     
     <a id="_idIndexMarker036">
     </a>
     
      where the models can not only understand the context of the input text (NLU) but are also capable of generating textual output.
     
     
      The T5 model discussed earlier is a very popular example of an encoder-decoder LLM, along with models such as BERT.
     
     
      These models are capable of language translation, summarization,
     
     
      
       and question-answering.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Multimodal LLMs
      
     </strong>
     
      : Multimodality is a concept where an AI model can not only handle
     
     <a id="_idIndexMarker037">
     </a>
     
      text but also other modalities such as image, video, and audio.
     
     
      Multimodal LLMs can process and generate content in various modalities such as text, image, audio, video, and any combination thereof.
     
     
      These models are rather novel in nature and recent advancements in compute have made it possible to train multimodal LLMs.
     
     
      Some of the well-known multimodal LLMs are DALL-E, Stable Diffusion, Flamingo, GPT-4,
     
     
      
       and LlaVa.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Instruction-tuned LLMs
      
     </strong>
     
      : LLMs are often trained on a large corpus of openly available
     
     <a id="_idIndexMarker038">
     </a>
     
      web or other text.
     
     
      As such, in certain scenarios, these models may not perform effectively for tasks that use data that the model has never seen before and thus may fail to follow the user intent.
     
     
      For example, a manufacturing manual for a proprietary instrument may contain domain-specific proprietary language, which the model may not have been exposed to during training.
     
     
      In such cases, LLMs can be fine-tuned using the domain-specific data to follow specific instructions and prompts (that is, text input to the model).
     
     
      This special fine-tuning enables the model to perform domain-specific tasks on which the model was fine-tuned, in addition to its other capabilities.
     
     
      Think of this as localizing a personal copy of a model to be good at performing a task that is meaningful for your
     
     <a id="_idIndexMarker039">
     </a>
     
      use case.
     
     
      One of the common examples of such a model is InstructGPT, where researchers fine-tuned the GPT-3 model on specific instructions.
     
     
      These types of models are used in a multitude of different tasks such as chatbots, virtual assistants, and
     
     
      
       task-specific applications.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Domain-specific LLMs
      
     </strong>
     
      : As mentioned earlier, while LLMs are often trained on a large set of open, generally available, web data, they may not perform very well
     
     <a id="_idIndexMarker040">
     </a>
     
      in domain-specific environments.
     
     
      While instruction-tuned LLMs are an avenue to make these general-purpose models work for domain-specific tasks, researchers have innovated on training domain-specific LLMs from the ground up.
     
     
      This means that these models were pre-trained on highly specialized, domain knowledge.
     
     
      For example, the BioBERT model is trained on hyper-specialized medical data, whereas LegalBERT is trained on legal documents.
     
     
      These models are useful for specialized tasks in specific fields such as medicine, law,
     
     
      
       and finance.
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-25">
    <a id="_idTextAnchor024">
    </a>
    
     LLM-powered AI agents
    
   </h2>
   <p>
    
     Each of the previously discussed LLM types has its own strengths and weaknesses and is well-suited
    
    <a id="_idIndexMarker041">
    </a>
    
     for different applications.
    
    
     However, our focus in
    
    <a id="_idIndexMarker042">
    </a>
    
     this book would be to dive deeper into LLM agent capabilities and explore how advanced systems can be built utilizing them.
    
    
     It is important to note that LLM agents do not fit neatly into a single category, as they represent an advanced application of LLM technology rather than a specific type of model architecture.
    
    
     Agents are typically built using instruction-tuned LLMs as their foundation, often combined with additional components and capabilities as you will learn further in
    
    
     
      this book.
     
    
   </p>
   <p>
    
     Let us take a look at a simple example to demonstrate the capabilities of an agentic system powered
    
    <a id="_idIndexMarker043">
    </a>
    
     by an LLM.
    
    
     Our example is a travel website that has a
    
    <strong class="bold">
     
      Flight Booking Assistant
     
    </strong>
    
     chatbot that is a conversational interface
    
    <a id="_idIndexMarker044">
    </a>
    
     built with an LLM.
    
    
     It can help customers book travel tickets via human-like conversations.
    
    
     In the backend, the chatbot can
    
    <a id="_idIndexMarker045">
    </a>
    
     perform various tasks as the conversation progresses.
    
    
     Here‚Äôs what a sample conversation may look like for a customer who is looking to book a
    
    
     
      flight ticket:
     
    
   </p>
   <table class="No-Table-Style _idGenTablePara-1" id="table001-1">
    <colgroup>
     <col/>
     <col/>
    </colgroup>
    <tbody>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body" colspan="2">
       <p>
        
         Flight
        
        
         
          Booking Assistant
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Hi, I want to book
        
        
         
          a flight.
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Hello!
        
        
         I‚Äôd be happy to help you book a flight.
        
        
         To get started, could you please tell me your departure city
        
        
         
          and destination?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         I want to go from San Diego
        
        
         
          to SFO.
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Great, thank you for providing that information.
        
        
         You‚Äôre looking to fly from San Diego (SAN) to San Francisco International Airport (SFO).
        
        
         To help you find the best flight options, I‚Äôll need a few
        
        
         
          more details.
         
        
       </p>
       <p>
        
         1.
        
        
         What is your preferred
        
        
         
          travel date?
         
        
       </p>
       <p>
        
         2.
        
        
         Is this a one-way trip or a
        
        
         
          round trip?
         
        
       </p>
       <p>
        
         3.
        
        
         How many passengers will
        
        
         
          be traveling?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         I want to go next Friday and come back on Sunday.
        
        
         Just
        
        
         
          me traveling.
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Thank you for the additional information.
        
        
         Let me summarize what I have
        
        
         
          so far:
         
        
       </p>
       <p>
        
         - Departure: San Diego (SAN) to San
        
        
         
          Francisco (SFO)
         
        
       </p>
       <p>
        
         - Outbound Date: Next Friday ‚Äì
        
        
         
          08/23/2024
         
        
       </p>
       <p>
        
         - Return Date: Sunday ‚Äì
        
        
         
          08/25/2024
         
        
       </p>
       <p>
        
         - Passengers:
        
        
         
          1 adult
         
        
       </p>
       <p>
        
         Before I search for flights, I have a few
        
        
         
          more questions:
         
        
       </p>
       <p>
        
         1.
        
        
         Do you
        
        <a id="_idIndexMarker046">
        </a>
        
         have a preferred time of day for
        
        <a id="_idIndexMarker047">
        </a>
        
         your flights (morning, afternoon,
        
        
         
          or evening)?
         
        
       </p>
       <p>
        
         2.
        
        
         Do you have a preferred airline or are you open to
        
        
         
          all airlines?
         
        
       </p>
       <p>
        
         3.
        
        
         What class of service would you prefer (Economy, Premium Economy, Business, or
        
        
         
          First Class)?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         I prefer morning flights.
        
        
         No airline preference.
        
        
         Economy
        
        
         
          is fine.
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Thank you for those details.
        
        
         I‚Äôll search for morning flights in Economy class across all airlines for your trip.
        
        
         Give me a moment to find the best options
        
        
         
          for you.
         
        
       </p>
       <p>
        
         [searching flights...please
        
        
         
          stand by‚Ä¶.]
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         I‚Äôve found a few options for your trip.
        
        
         Here are the best
        
        
         
          morning flights:
         
        
       </p>
       <p>
        
         Outbound (SAN to SFO) -
        
        
         
          Next Friday:
         
        
       </p>
       <p>
        
         1.
        
        
         United Airlines UA1234: Depart 7:15 AM, Arrive
        
        
         
          8:45 AM
         
        
       </p>
       <p>
        
         2.
        
        
         Alaska Airlines AS5678: Depart 8:30 AM, Arrive
        
        
         
          10:00 AM
         
        
       </p>
       <p>
        
         Return (SFO to SAN) -
        
        
         
          Sunday:
         
        
       </p>
       <p>
        
         1.
        
        
         Delta Air Lines DL9876: Depart 9:00 AM, Arrive
        
        
         
          10:30 AM
         
        
       </p>
       <p>
        
         2.
        
        
         Southwest Airlines WN5432: Depart 10:15 AM, Arrive
        
        
         
          11:45 AM
         
        
       </p>
       <p>
        
         The total price for the round trip, including taxes and
        
        
         
          fees, is:
         
        
       </p>
       <p>
        
         - Option 1 (
        
        
         
          United/Alaska): $325
         
        
       </p>
       <p>
        
         - Option 2 (
        
        
         
          Delta/Southwest): $310
         
        
       </p>
       <p>
        
         Which option would you prefer?
        
        
         Or would you like me to look for
        
        
         
          different flights?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         The second
        
        <a id="_idIndexMarker048">
        </a>
        
         option looks
        
        <a id="_idIndexMarker049">
        </a>
        
         good.
        
        
         Can you book that
        
        
         
          for me?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Certainly!
        
        
         I‚Äôd be happy to book the second option for you.
        
        
         Just to confirm, I‚Äôll be booking the
        
        
         
          following itinerary:
         
        
       </p>
       <p>
        
         Outbound: Alaska
        
        
         
          Airlines AS5678
         
        
       </p>
       <p>
        
         -
        
        
         
          Date: 08/23/2024
         
        
       </p>
       <p>
        
         - Depart San Diego at 8:30 AM, Arrive in SFO at
        
        
         
          10:00 AM
         
        
       </p>
       <p>
        
         Return: Southwest
        
        
         
          Airlines WN5432
         
        
       </p>
       <p>
        
         -
        
        
         
          Date: 08/25/2024
         
        
       </p>
       <p>
        
         - Depart SFO at 10:15 AM, Arrive in San Diego at
        
        
         
          11:45 AM
         
        
       </p>
       <p>
        
         Total
        
        
         
          price: $310
         
        
       </p>
       <p>
        
         To proceed with the booking, I‚Äôll need some
        
        
         
          additional information:
         
        
       </p>
       <p>
        
         1.
        
        
         Your full name as it appears on your
        
        
         
          government-issued ID
         
        
       </p>
       <p>
        
         2.
        
        
         Your date
        
        
         
          of birth
         
        
       </p>
       <p>
        
         3.
        
        
         Your email address (for sending
        
        
         
          the confirmation)
         
        
       </p>
       <p>
        
         4.
        
        
         Your
        
        
         
          phone number
         
        
       </p>
       <p>
        
         5.
        
        
         Any special requests (for example, meal preferences,
        
        
         
          seat preferences)
         
        
       </p>
       <p>
        
         Also, please note that you‚Äôll need to provide a form of payment to complete the booking.
        
        
         Are you ready to proceed with
        
        
         
          this information?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Yes, I‚Äôm
        
        <a id="_idIndexMarker050">
        </a>
        
         ready.
        
        
         My name is John Smith, born on 05/15/1985.
        
        
         My
        
        <a id="_idIndexMarker051">
        </a>
        
         email is john.smith@email.com and my phone number is 555-123-4567.
        
        
         No
        
        
         
          special requests.
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Thank you for providing that information, Mr.
        
        
         Smith.
        
        
         I‚Äôve entered your details into the booking system.
        
        
         Here‚Äôs a summary of the information
        
        
         
          I have:
         
        
       </p>
       <p>
        
         - Name:
        
        
         
          John Smith
         
        
       </p>
       <p>
        
         - Date of
        
        
         
          Birth: 05/15/1985
         
        
       </p>
       <p>
        
         -
        
        
         
          Email: john.smith@email.com
         
        
       </p>
       <p>
        
         -
        
        
         
          Phone: 555-123-4567
         
        
       </p>
       <p>
        
         - Special
        
        
         
          Requests: None
         
        
       </p>
       <p>
        
         The final step is to process the payment of $310 for your flights.
        
        
         For security reasons, I can‚Äôt accept credit card information directly in this chat.
        
        
         Instead, I‚Äôll send a secure payment link to your email
        
        
         
          address (john.smith@email.com).
         
        
       </p>
       <p>
        
         Once you receive the email, please follow the link to complete the payment process.
        
        
         After the payment is successfully processed, you‚Äôll receive another email with your flight confirmation
        
        
         
          and e-tickets.
         
        
       </p>
       <p>
        
         Is it okay to proceed with sending the payment link to
        
        
         
          your email?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Yes, that‚Äôs
        
        <a id="_idIndexMarker052">
        </a>
        
         fine.
        
        
         Please
        
        <a id="_idIndexMarker053">
        </a>
        
         send the
        
        
         
          payment link.
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         Excellent, Mr.
        
        
         Smith.
        
        
         I‚Äôve initiated the process to send the secure payment link to your email address (john.smith@email.com).
        
        
         You should receive it within the next few minutes.
        
        
         Please check your inbox and spam folder if you don‚Äôt see it
        
        
         
          right away.
         
        
       </p>
       <p>
        
         Once you complete the payment, the system will automatically process your booking and send your confirmation email with the e-tickets.
        
        
         This email will include important information
        
        
         
          such as:
         
        
       </p>
       <p>
        
         1.
        
        
         Booking
        
        
         
          confirmation number
         
        
       </p>
       <p>
        
         2.
        
        
         Detailed
        
        
         
          flight itinerary
         
        
       </p>
       <p>
        
         3.
        
        
         
          Check-in instructions
         
        
       </p>
       <p>
        
         4.
        
        
         Baggage
        
        
         
          allowance information
         
        
       </p>
       <p>
        
         5.
        
        
         Airline
        
        
         
          contact information
         
        
       </p>
       <p>
        
         After you receive your confirmation email, please review all the details to ensure everything is correct.
        
        
         If you notice any issues or have any questions, please don‚Äôt hesitate to
        
        
         
          contact us.
         
        
       </p>
       <p>
        
         Is there anything else you need assistance with regarding your trip or the
        
        
         
          booking process?
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <img alt="img" role="presentation" src="img/B31483_01_Icon_1.png"/>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         No, that‚Äôs all.
        
        
         Thank you for
        
        
         
          your help!
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         ü§ñ
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         You‚Äôre welcome, Mr.
        
        
         Smith!
        
        
         I‚Äôm glad I could assist you with booking your flights from San Diego to San Francisco.
        
        
         If you need any further assistance with this booking or have any questions about your trip, please don‚Äôt hesitate to reach out.
        
        
         We‚Äôre here to help 24/7.
        
        
         Have a great trip to San Francisco
        
        
         
          next week!
         
        
       </p>
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    
     On the surface, this example looks pretty straightforward.
    
    
     However, there are a number of things
    
    <a id="_idIndexMarker054">
    </a>
    
     that are happening in the background.
    
    
     Firstly, the customer starts with a vague request to book a flight.
    
    
     The AI assistant
    
    <a id="_idIndexMarker055">
    </a>
    
     understands that in order to proceed with this request, it needs a few more pieces of information to look up available flights, such as departure/arrival city, dates of travel, and
    
    
     
      so on.
     
    
   </p>
   <p>
    
     As the conversation progresses, the AI assistant requests further pieces of information to be able to successfully complete the booking.
    
    
     The information it gathers at each step is used as a parameter value to call flight booking-related APIs in the backend; for example, city/travel dates/number of passengers are required to look up available flight information using a (fictitious) API named
    
    <strong class="bold">
     
      flightLookup
     
    </strong>
    
     , customer name/phone/email are required to actually make the booking using an API named b
    
    <strong class="bold">
     
      ookFlight
     
    </strong>
    
     , and so on.
    
    
     <em class="italic">
      
       Figure 1
      
     </em>
    
    <em class="italic">
     
      .2
     
    </em>
    
     gives an overview of the decisions that the model makes, the flow of the interaction, and the tools (API functions) it calls to complete
    
    
     
      each step:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_01_2.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 1.2 ‚Äì Flight Booking Assistant chatbot with LLM-powered multi-agents
    
   </p>
   <p>
    
     In addition
    
    <a id="_idIndexMarker056">
    </a>
    
     to just tool calling, you will also
    
    <a id="_idIndexMarker057">
    </a>
    
     notice that the model does a bit of introspection, also known as
    
    <strong class="bold">
     
      chain of thought
     
    </strong>
    
     (
    
    <strong class="bold">
     
      CoT
     
    </strong>
    
     ), at the beginning of the conversation.
    
    
     This means the model in the backend crafts a step-by-step approach to complete the task but identifies some missing information.
    
    
     It then responds back to the customer with a request to provide the required information.
    
    
     Subsequently, based on the input from the customer, it makes certain decisions autonomously to call specific tools using the agent and completes
    
    
     
      the task.
     
    
   </p>
   <p>
    
     In addition to the external tools and APIs, there are a number of other things to consider when designing such a system.
    
    
     We will cover the fundamentals of each of these components in detail in the subsequent chapters.
    
    
     For now, it is sufficient to know that agents are
    
    <a id="_idIndexMarker058">
    </a>
    
     an advanced application of LLMs (such as this travel booking AI assistant) and represent an emerging field that combines
    
    <a id="_idIndexMarker059">
    </a>
    
     aspects of various LLM types with additional AI techniques such as reinforcement learning, planning, and tool use.
    
    
     As you learn more in subsequent chapters, you will notice that agents are designed to be more interactive, adaptable, and capable of completing complex, multi-step tasks compared to standard LLMs, which makes them suitable for a variety of different complex tasks
    
    
     
      and workflows.
     
    
   </p>
   <p>
    
     But before we dive deeper into the details of agentic systems, let us review some of the applications of
    
    
     
      generative AI.
     
    
   </p>
   <h1 id="_idParaDest-26">
    <a id="_idTextAnchor025">
    </a>
    
     Applications of generative AI
    
   </h1>
   <p>
    
     Generative AI has innovation capabilities that cover a diverse set of fields.
    
    
     As discussed earlier, industries
    
    <a id="_idIndexMarker060">
    </a>
    
     such as healthcare, finance, education, media and entertainment, marketing, manufacturing, retail, and so on all have the potential to benefit from generative AI capabilities.
    
    
     The following is a survey of only a few of the primary applications of
    
    
     
      generative AI:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Generation of images and videos
      
     </strong>
     
      : Multimodal generative models (that is, LLMs that
     
     <a id="_idIndexMarker061">
     </a>
     
      can handle images, text, audio, and videos) are making it possible to generate realistic audio/visuals through various platforms and tools.
     
     
      For example, in media and entertainment, generative AI can help in generating visual effects, designing avatars, and developing virtual reality content.
     
     
      In the fashion and design industry, it is being used to conceptualize new clothing designs, prepare virtual fashion shows, and make fashion trend predictions.
     
     
      In marketing ads and promotion space, generative AI is being used to generate tailor-made advertisements, campaigns, marketing communications, and other marketing materials creatives such as images
     
     
      
       and logos.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Text and content generation
      
     </strong>
     
      : Generative AI has made significant strides when it
     
     <a id="_idIndexMarker062">
     </a>
     
      comes to text-based tasks.
     
     
      For instance, content writing such as rapid and hassle-free generation of articles, blog posts, marketing, and product copies are already some of the most common use cases.
     
     
      Chatbots and virtual assistants are providing customer support in a very humanlike manner to information-related inquiries.
     
     
      Generative AI is also assisting in text translation, document summarization, and content localization for increased accessibility of content for platforms such as online learning and specialized
     
     
      
       search engines.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Music and audio generation
      
     </strong>
     
      : Creating original music, sound effects, and voice
     
     <a id="_idIndexMarker063">
     </a>
     
      synthesis is yet another paradigm of multi-media content generation that is being powered by generative AI.
     
     
      Practically, contents such as these are being used in the gaming and entertainment industry to create audio-assisted training materials, automated call center assistants, and IoT devices such as Amazon Alexa, or Google Next that can take audio commands and use voice responses to complete
     
     
      
       automated tasks.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Healthcare and drug discovery
      
     </strong>
     
      : Generative AI finds space in health care.
     
     
      For
     
     <a id="_idIndexMarker064">
     </a>
     
      example, the design of new drugs and the prediction of their capability to treat diseases or other conditions; personalized medicine, whereby treatment plans are tailored individually on a patient-by-patient basis; and medical imaging, whereby image quality is refined and synthetic images generated for
     
     
      
       research purposes.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Code generation
      
     </strong>
     
      : Code
     
     <a id="_idIndexMarker065">
     </a>
     
      generation is an emerging LLM feature that is helping developers in software development.
     
     
      These models can often generate accurate code snippets, or sometimes an entire function based on text prompts.
     
     
      Advanced implementation of generative
     
     <a id="_idIndexMarker066">
     </a>
     
      AI in code generation includes plugins created for various
     
     <strong class="bold">
      
       integrated development environments
      
     </strong>
     
      (
     
     <strong class="bold">
      
       IDEs
      
     </strong>
     
      ), such as
     
     <strong class="bold">
      
       Visual Studio Code
      
     </strong>
     
      (
     
     <strong class="bold">
      
       VS Code
      
     </strong>
     
      ), that can understand
     
     <a id="_idIndexMarker067">
     </a>
     
      the entire context of the code base, identify errors, create code documentation, and generate unit test scripts.
     
     
      Another implementation of code generation is text-to-query use cases where a natural
     
     <a id="_idIndexMarker068">
     </a>
     
      language prompt is converted into a SQL query, which can then be executed against a database to get the desired results.
     
     
      However, this is one of the areas where special caution must be taken, especially before executing the code generated by an LLM, to prevent risks of malicious code execution.
     
     
      Often, in these situations, the code generated by the LLM is executed in a sandbox and sanitized to check whether the code is safe and appropriate for execution in an
     
     
      
       autonomous environment.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Autonomous workflows and robotics
      
     </strong>
     
      : As we briefly discussed earlier, LLM-powered AI agents are an advanced implementation of generative AI with LLMs
     
     <a id="_idIndexMarker069">
     </a>
     
      serving as their foundations.
     
     
      These agents can perform several tasks in various use cases.
     
     
      For example, a travel booking website with a virtual assistant chatbot can implement agents to automate the travel and hotel booking process for the customer.
     
     
      In these cases, the agent-based system can act on specific tasks using tools (such as calling a flight booking API) simply by understanding the context of the conversation that the customer is having with the chatbot.
     
     
      More advanced agent-based systems often come into play when discussing robotics, where a robot‚Äôs actions are primarily controlled by agents.
     
     
      The robotic agent essentially determines what decisions to make based on its environment or the specific task it is assigned to perform.
     
     
      It uses agents to execute actions that an LLM would otherwise be unable to perform; for example, an agent can turn on or off the limb actuators of a robot.
     
     
      AI in robotics is a novel and open field of research, with numerous innovations emerging in the industry, particularly targeted toward
     
     
      
       manufacturing applications.
      
     
    </li>
   </ul>
   <p>
    
     These are just some of the common examples of the uses of generative AI with LLMs.
    
    
     Other specific examples include uses in fashion and design, synthetic data generation, personalized educational content, financial modeling and forecasting, and predictive maintenance.
    
    
     The following is a brief list of examples of commercial and open source tools that
    
    <a id="_idIndexMarker070">
    </a>
    
     use generative AI for the number of use cases
    
    
     
      we discussed:
     
    
   </p>
   <table class="No-Table-Style _idGenTablePara-1" id="table002">
    <colgroup>
     <col/>
     <col/>
     <col/>
    </colgroup>
    <thead>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <strong class="bold">
          
           Use case
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        
         <strong class="bold">
          
           Commercial tools
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Open
         
        </strong>
        
         <strong class="bold">
          
           source tools
          
         </strong>
        
       </p>
      </td>
     </tr>
    </thead>
    <tbody>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Visual effects and
         
        </strong>
        
         <strong class="bold">
          
           avatar design
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Unreal Engine‚Äôs MetaHuman Creator
          
         </strong>
         
          : Allows for the creation of highly realistic digital humans for games
         
         
          
           and films
          
         
        </li>
        <li>
         <strong class="bold">
          
           NVIDIA Omniverse
          
         </strong>
         
          : A platform for 3D design collaboration and simulation, useful for creating
         
         
          
           visual effects
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           DeepFaceLab
          
         </strong>
         
          : Used for face swapping and creating
         
         
          
           digital avatars
          
         
        </li>
        <li>
         <strong class="bold">
          
           StyleGAN
          
         </strong>
         
          : Capable of generating highly realistic faces and can be adapted for
         
         
          
           avatar creation
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Virtual reality
         
        </strong>
        
         <strong class="bold">
          
           content development
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Unity
          
         </strong>
         
          : While not exclusively for VR, it has robust VR
         
         
          
           development capabilities
          
         
        </li>
        <li>
         <strong class="bold">
          
           Adobe Aero
          
         </strong>
         
          : Allows for the creation of
         
         
          
           AR experiences
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           A-Frame
          
         </strong>
         
          : A web framework for building virtual
         
         
          
           reality experiences
          
         
        </li>
        <li>
         <strong class="bold">
          
           Godot
          
         </strong>
         
          : An open source game engine with
         
         
          
           VR support
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Clothing design and virtual
         
        </strong>
        
         <strong class="bold">
          
           fashion shows
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           CLO3D
          
         </strong>
         
          : A 3D garment design software that can create virtual
         
         
          
           fashion shows
          
         
        </li>
        <li>
         <strong class="bold">
          
           Browzwear
          
         </strong>
         
          : Offers 3D design solutions for the
         
         
          
           fashion industry
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Blender
          
         </strong>
         
          : While primarily a 3D modeling tool, it can be used for fashion design and
         
         
          
           virtual shows
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Fashion
         
        </strong>
        
         <strong class="bold">
          
           trend predictions
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           WGSN
          
         </strong>
         
          : Uses AI for trend forecasting
         
         
          
           in fashion
          
         
        </li>
        <li>
         <strong class="bold">
          
           Heuritech
          
         </strong>
         
          : Provides AI-powered
         
         
          
           trend forecasting
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         
          
           None
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Marketing ‚Äì ad generation and
         
        </strong>
        
         <strong class="bold">
          
           campaign creation
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Jasper
          
         </strong>
         
          : An AI writing assistant that can help create
         
         
          
           marketing copy
          
         
        </li>
        <li>
         <strong class="bold">
          
           Midjourney
          
         </strong>
         
          : An AI image generation
         
         <a id="_idIndexMarker071">
         </a>
         
          tool useful for creating
         
         
          
           marketing visuals
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           GPT-J
          
         </strong>
         
          : An open source language model that can be fine-tuned for marketing
         
         
          
           content generation
          
         
        </li>
        <li>
         <strong class="bold">
          
           Stable Diffusion
          
         </strong>
         
          :An open source image generation model that can create
         
         
          
           marketing visuals.
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Logo and
         
        </strong>
        
         <strong class="bold">
          
           image creation
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           DALL-E 2
          
         </strong>
         
          : Can generate unique images and logos based on
         
         
          
           text descriptions
          
         
        </li>
        <li>
         <strong class="bold">
          
           Canva
          
         </strong>
         
          : While not fully AI-powered, it incorporates AI features for
         
         
          
           design assistance
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Stable Diffusion
          
         </strong>
         
          : Can be used for logo and
         
         
          
           image generation
          
         
        </li>
        <li>
         <strong class="bold">
          
           Craiyon (formerly DALL-E mini)
          
         </strong>
         
          : An open source alternative
         
         
          
           to DALL-E
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Text and
         
        </strong>
        
         <strong class="bold">
          
           content generation
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         
          ChatGPT
         
         
          
           by OpenAI
          
         
        </li>
        <li>
         
          Claude AI
         
         
          
           by Anthropic
          
         
        </li>
        <li>
         
          
           Jasper
          
         
        </li>
        <li>
         
          
           Copy.ai
          
         
        </li>
        <li>
         
          
           Anyword
          
         
        </li>
        <li>
         
          
           Writer
          
         
        </li>
        <li>
         
          
           WriteSonic
          
         
        </li>
       </ul>
       <p>
        
         And
        
        
         
          many more‚Ä¶
         
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Mistral 7B
          
         </strong>
         
          : An open source LLM known for its efficiency and precision in text
         
         
          
           generation tasks
          
         
        </li>
        <li>
         <strong class="bold">
          
           LLaMA
          
         </strong>
         
          : A collection of open source pre-trained and fine-tuned generative text models, offering versions with different
         
         
          
           parameter sizes
          
         
        </li>
        <li>
         <strong class="bold">
          
           BLOOM Language Model
          
         </strong>
         
          : A large open-access AI model developed by over 1,000 AI researchers, known for its robustness and versatility in
         
         
          
           text generation
          
         
        </li>
       </ul>
       <p>
        
         And
        
        
         
          many more‚Ä¶
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        
         <strong class="bold">
          
           Code generation
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         
          
           GitHub Copilot
          
         
        </li>
        <li>
         
          Amazon
         
         <a id="_idIndexMarker072">
         </a>
         
          Q
         
         
          
           for Developers
          
         
        </li>
        <li>
         
          
           Tabnine
          
         
        </li>
        <li>
         
          
           OpenAI Codex
          
         
        </li>
       </ul>
       <p>
        
         And
        
        
         
          many more‚Ä¶
         
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           Code T5
          
         </strong>
         
          : An open source AI model trained for code-related tasks.
         
         
          It can generate code snippets, complete code, and even translate between
         
         
          
           programming languages.
          
         
        </li>
        <li>
         <strong class="bold">
          
           Polycoder
          
         </strong>
         
          : An open source alternative to commercial code generators.
         
         
          It‚Äôs trained on a large code base spanning multiple programming languages and can generate code for
         
         
          
           various tasks.
          
         
        </li>
       </ul>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style T---Body">
       <p>
        <strong class="bold">
         
          Autonomous workflows
         
        </strong>
        
         <strong class="bold">
          
           and robotics
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           UiPath
          
         </strong>
         
          incorporates generative AI
         
         <a id="_idIndexMarker073">
         </a>
         
          into its
         
         <strong class="bold">
          
           robotic process automation
          
         </strong>
         
          (
         
         <strong class="bold">
          
           RPA
          
         </strong>
         
          ) platform.
         
         
          It uses AI to discover automation opportunities and enhance tasks such as document understanding and
         
         
          
           communications mining.
          
         
        </li>
        <li>
         <strong class="bold">
          
           Automation Anywhere
          
         </strong>
         
          integrates generative AI into its automation platform.
         
         
          It offers features such as Automation Co-Pilot for Automators, which uses generative AI to accelerate
         
         
          
           developer productivity.
          
         
        </li>
        <li>
         <strong class="bold">
          
           NVIDIA
          
         </strong>
         
          provides AI workflows that leverage their AI frameworks, including generative AI capabilities, for developing innovative solutions in robotics and
         
         
          
           autonomous systems.
          
         
        </li>
       </ul>
      </td>
      <td class="No-Table-Style T---Body">
       <ul>
        <li>
         <strong class="bold">
          
           OpenAI Gym
          
         </strong>
         
          provides a toolkit for developing and comparing reinforcement learning algorithms, which can be combined with LLMs for more advanced
         
         
          
           robotics applications.
          
         
        </li>
        <li>
         <strong class="bold">
          
           Hugging Face
          
         </strong>
         
          offers open source libraries that can be used to implement LLMs in robotics and autonomous
         
         
          
           workflow applications.
          
         
        </li>
        <li>
         <strong class="bold">
          
           LangChain
          
         </strong>
         
          is an open source Python library used for developing applications using LLMs, which can be applied to create more intelligent autonomous workflows and
         
         
          
           robotic systems.
          
         
        </li>
       </ul>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Table 1.1 ‚Äì Examples of commercial and open source tools that use generative AI
    
   </p>
   <p>
    
     This is in no way an exhaustive list of commercial and open source tools available in the market at
    
    <a id="_idIndexMarker074">
    </a>
    
     the moment and the landscape is changing every day.
    
    
     We are witnessing a host of new start-ups providing new and innovative ways of solving real-life use cases with generative AI, and we are also witnessing new model providers developing state-of-the-art LLMs that are more capable than the previous ones and are much cheaper to operate.
    
    
     This just goes to show you how dynamic and exciting the field of generative
    
    
     
      AI is.
     
    
   </p>
   <h1 id="_idParaDest-27">
    <a id="_idTextAnchor026">
    </a>
    
     Challenges and limitations of generative AI
    
   </h1>
   <p>
    
     Though
    
    <a id="_idIndexMarker075">
    </a>
    
     generative AI has immense benefits, it is not without its own set of challenges and limitations.
    
    
     Some of these challenges and limitations need to be taken into account with a lot of caution while considering a generative AI technology for any particular use case.
    
    
     Here‚Äôs a brief discussion of some of the most common caveats related to LLMs and some of the ways to
    
    
     
      mitigate them.
     
    
   </p>
   <h2 id="_idParaDest-28">
    <a id="_idTextAnchor027">
    </a>
    
     Quality of data and bias
    
   </h2>
   <p>
    
     The generative models are largely aided by the quality and diversity of data in the training dataset.
    
    
     Any model trained with biased or unrepresentative data will reproduce outputs with
    
    <a id="_idIndexMarker076">
    </a>
    
     the same kind of bias, hence solidifying existing biases or allowing marginalization of one or several groups in case of bias in the
    
    
     
      training data.
     
    
   </p>
   <p>
    
     One way this challenge can be dealt with is by ensuring richness in diversity, good quality data, and so on for a wide array of perspectives within the dataset itself used for training.
    
    
     As with any machine learning problem, analysis of the data and knowing the data distribution across features is often helpful.
    
    
     Data analysis can reveal imbalances that can introduce bias in the model.
    
    
     There are several algorithmic ways of mitigating bias in training data (for instance, using oversampling or undersampling), but each of these methods has its own advantages and disadvantages.
    
    
     For example, consider two classes of data in a training dataset that contains more instances of
    
    <em class="italic">
     
      Class 0
     
    </em>
    
     data than
    
    <em class="italic">
     
      Class 1
     
    </em>
    
     data, causing a natural imbalance in the dataset.
    
    
     When a model is trained with such a dataset, the model would ‚Äúoverfit‚Äù on the
    
    <em class="italic">
     
      Class 0
     
    </em>
    
     type of data and would become more proficient in or even memorize data that belongs to
    
    <em class="italic">
     
      Class 0
     
    </em>
    
     and may not perform well for data belonging to
    
    <em class="italic">
     
      Class 1
     
    </em>
    
     This inherently causes the model to perform poorly and demonstrate heavy bias.
    
    
     The following figure demonstrates the effect of oversampling and undersampling on such a dataset to
    
    
     
      mitigate bias:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_01_3.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 1.3 ‚Äì Imbalanced data distribution and effects of oversampling and undersampling
    
   </p>
   <h2 id="_idParaDest-29">
    <a id="_idTextAnchor028">
    </a>
    
     Data privacy
    
   </h2>
   <p>
    
     Multiple experiments and researchers have proven that LLMs have a propensity to leak data they
    
    <a id="_idIndexMarker077">
    </a>
    
     are trained on.
    
    
     This is especially problematic if the models are trained on large amounts of private or proprietary information.
    
    
     Special techniques and styles of prompting LLMs have shown that it is sufficient to coerce the model to generate data that includes verbatim text from its training dataset.
    
    
     These prompting techniques are not sophisticated and often make it a very easy, cost-effective attack vector to get a model to leak information.
    
    
     For example, as discussed in the paper named
    
    <em class="italic">
     
      Scalable Extraction of Training Data from (Production) Language Models
     
    </em>
    
     [15], researchers were able to spend only $200 worth of API calls to OpenAI‚Äôs GPT-3.5 model and use prompt injection techniques to coerce the model to leak private information.
    
    
     The leaked information includes people‚Äôs names, email and physical addresses, and phone numbers that were inadvertently present in the model‚Äôs training dataset.
    
    
     While some of these issues are actively being addressed by model providers such as OpenAI, it can still be problematic for organizations that choose to train their own
    
    
     
      models in-house.
     
    
   </p>
   <p>
    
     Some of the common mechanisms to mitigate this is to perform data anonymization or pseudonymization on the training data to remove or obscure personal, private, and or proprietary information, even before training the model.
    
    
     Both of these techniques involved
    
    <a id="_idIndexMarker078">
    </a>
    
     using smaller, cheaper, and faster AI models to perform classification and entity detection to identify the presence of personal or private data in the training dataset.
    
    
     Once identified, the private information can be obscured, masked, or entirely removed from the training dataset.
    
    
     Note that there could be several implications to doing this depending on your use case, so special analysis must be performed to ensure that it doesn‚Äôt impact the
    
    
     
      model‚Äôs performance.
     
    
   </p>
   <h2 id="_idParaDest-30">
    <a id="_idTextAnchor029">
    </a>
    
     Computational resources
    
   </h2>
   <p>
    
     Training sophisticated generative models is very resource-intensive and requires high computational power; this often makes it economically cost-prohibitive and energy-consuming
    
    <a id="_idIndexMarker079">
    </a>
    
     to train large language models.
    
    
     Although there have been several hardware breakthroughs that make it possible to train such models, access to these hardware assets still remains expensive, privileged, and
    
    <a id="_idIndexMarker080">
    </a>
    
     limited.
    
    
     For example,
    
    <strong class="bold">
     
      graphics processing units
     
    </strong>
    
     (
    
    <strong class="bold">
     
      GPUs
     
    </strong>
    
     ), initially designed for rendering high-fidelity graphics, have become crucial for AI model training, fine-tuning, and computations.
    
    
     NVIDIA‚Äôs CUDA architecture, introduced in 2006, allowed GPUs to be used for general-purpose computing, and modern GPUs such as NVIDIA‚Äôs A100 and H100 have since been specifically optimized for AI workloads.
    
    
     However, these high-end GPUs can often cost tens of thousands of dollars
    
    
     
      per unit.
     
    
   </p>
   <p>
    
     Training large models such as GPT-3 is estimated to cost millions of dollars in compute resources alone.
    
    
     The exact cost depends on factors such as model size, training duration, and hardware efficiency.
    
    
     For example, training GPT-3 was estimated to cost around $4‚Äì5 million in compute resources, and more recent models such as GPT-4 and PaLM are likely even more expensive to train.
    
    
     Beyond the hardware itself, there are significant infrastructure costs related to power consumption, cooling, and data center space.
    
    
     Due to the high costs, training large language models is primarily done by large tech companies or well-funded research institutions.
    
    
     Cloud services now offer access to pre-trained models and fine-tuning capabilities, making some level of LLM work more accessible to smaller organizations and the general public.
    
    
     A way to overcome this challenge
    
    <a id="_idIndexMarker081">
    </a>
    
     can be found in recent innovations with
    
    <strong class="bold">
     
      small language models
     
    </strong>
    
     (
    
    <strong class="bold">
     
      SLMs
     
    </strong>
    
     ), which are much smaller generative
    
    <a id="_idIndexMarker082">
    </a>
    
     AI models that can be trained to achieve specific tasks.
    
    
     Even though these models are limited to a very narrow set of domain-specific tasks, it is much more economical to train these models since they require far fewer
    
    
     
      computational resources.
     
    
   </p>
   <h2 id="_idParaDest-31">
    <a id="_idTextAnchor030">
    </a>
    
     Ethical and social implications
    
   </h2>
   <p>
    
     The range
    
    <a id="_idIndexMarker083">
    </a>
    
     of issues in ethics and society exposed by strides in technological generative AI opened up the following many-headed issues, which is far from an
    
    
     
      exhaustive list:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Deepfakes and misinformation
      
     </strong>
     
      : It is able to produce very realistic synthetically generated content.
     
     
      If that were to happen, it would yield deepfakes or even misinformation, which could be a threat to privacy, security, or even
     
     
      
       public trust.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Intellectual property
      
     </strong>
     
      : The process of developing comparable content to existing ones brings forth issues with copyright and intellectual property rights.
     
     
      The legal complexity attached to the very originality of the creation and correct ownership can be
     
     
      
       most perplexing.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Job displacement
      
     </strong>
     
      : Economists often downplay concerns about significant job losses in content generation and other automated task sectors.
     
     
      Of concern is the fact that resultant effects are expected to be paralleled with studies on ways of reskilling and adjustment strategies that can help the affected workers, as well as
     
     
      
       entrepreneurial opportunities.
      
     
    </li>
   </ul>
   <p>
    
     When it comes to mitigating social and ethical implications, the question is more philosophical than technical.
    
    
     While some measures such as deepfake AI image detection and private and personal data detection methods are common strategies, the societal implications are a larger question in the context of AI‚Äôs benefit to society and any existing or impending
    
    
     
      government regulations.
     
    
   </p>
   <h2 id="_idParaDest-32">
    <a id="_idTextAnchor031">
    </a>
    
     Generalization and creativity
    
   </h2>
   <p>
    
     One of the big problems with these generative AI models is that their generalization ability turns
    
    <a id="_idIndexMarker084">
    </a>
    
     out to be very poor.
    
    
     More concretely, they seldom generate content that is strikingly different from the training data.
    
    
     That is, they are brilliant at copying the repeating patterns but fail really to create something original or novel.
    
    
     As a consequence, their potential for capital
    
    <em class="italic">
     
      C
     
    </em>
    
     creativity stays
    
    
     
      very limited.
     
    
   </p>
   <p>
    
     As generative AI continues to evolve in novel ways, it is bound to introduce novel challenges, as we are witnessing the barrage of new research and efforts to ensure sensible and responsible use of
    
    
     
      this technology.
     
    
   </p>
   <h1 id="_idParaDest-33">
    <a id="_idTextAnchor032">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     Generative AI is a rather rapidly growing area, having huge disruptive potential for industries and changing areas of our lives.
    
    
     In contrast, applications of generative AI include very realistic image generation and generation of text, accelerated drug discovery, and enriched
    
    
     
      creative expression.
     
    
   </p>
   <p>
    
     One of the key points regarding this is an understanding of the different generative models, such as VAEs, GANs, and autoregressive models, that provide insight into how technologies work and where they can be applied.
    
    
     It would also, however, be important to state the many problems and limitations generative AI faces, including data quality, computational resources, ethical considerations, and
    
    
     
      even creativity.
     
    
   </p>
   <p>
    
     In the next chapter, we will learn about the principles of agentic systems, which include the concepts of agency and autonomy, the characteristics of intelligent agents, various architectures of intelligent systems, and
    
    
     
      multi-agent systems.
     
    
   </p>
   <h1 id="_idParaDest-34">
    <a id="_idTextAnchor033">
    </a>
    
     Questions
    
   </h1>
   <ol>
    <li>
     
      Generative AI models can only take text data as input.
     
     
      True
     
     
      
       or false?
      
     
    </li>
    <li>
     
      What are the different types of generative
     
     
      
       AI models?
      
     
    </li>
    <li>
     
      What are some of the ethical and social implications of
     
     
      
       generative AI?
      
     
    </li>
    <li>
     
      What are some of the methods to mitigate bias in
     
     
      
       training data?
      
     
    </li>
    <li>
     
      What are some of the text and content generation open
     
     
      
       source LLMs?
      
     
    </li>
   </ol>
   <h1 id="_idParaDest-35">
    <a id="_idTextAnchor034">
    </a>
    
     Answers
    
   </h1>
   <ol>
    <li value="1">
     
      False.
     
     
      Generative AI models can take text as well as image, video, and audio data
     
     
      
       as inputs.
      
     
    </li>
    <li>
     
      VAEs, GANs, and
     
     
      
       autoregressive models.
      
     
    </li>
    <li>
     
      Deepfakes, misinformation, issues with copyright or intellectual property, and job displacements are some of the social and ethical implications of
     
     
      
       generative AI.
      
     
    </li>
    <li>
     
      Some of the common methods to address bias in training data are oversampling
     
     
      
       or undersampling.
      
     
    </li>
    <li>
     
      Mistral, LLaMA, and Bloom are some of the open source text and content
     
     
      
       generation LLMs.
      
     
    </li>
   </ol>
   <h1 id="_idParaDest-36">
    <a id="_idTextAnchor035">
    </a>
    
     Further reading
    
   </h1>
   <ul>
    <li>
     <em class="italic">
      
       Mastering Machine Learning Algorithms ‚Äì Second Edition
      
     </em>
     
      by
     
     
      
       Giuseppe Bonaccorso
      
     
    </li>
    <li>
     <em class="italic">
      
       Machine Learning for Imbalanced Data
      
     </em>
     
      by Kumar Abhishek and Dr.
     
     
      
       Mounir Abdelaziz
      
     
    </li>
    <li>
     <em class="italic">
      
       Generative AI with Python and TensorFlow 2
      
     </em>
     
      by Joseph Babcock and
     
     
      
       Raghav Bali
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-37">
    <a id="_idTextAnchor036">
    </a>
    
     References
    
   </h1>
   <ol>
    <li value="1">
     <em class="italic">
      
       Auto-Encoding Variational
      
     </em>
     
      <em class="italic">
       
        Bayes
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1312.6114">
      
       
        https://arxiv.org/abs/1312.6114
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       beta-VAE: Learning Basic Visual Concepts with a Constrained Variational
      
     </em>
     
      <em class="italic">
       
        Framework
       
      </em>
     
     
      
       :
      
     
     <a href="https://openreview.net/forum?id=Sy2fzU9gl">
      
       
        https://openreview.net/forum?id=Sy2fzU9gl
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Learning Structured Output Representation using Deep Conditional Generative
      
     </em>
     
      <em class="italic">
       
        Models
       
      </em>
     
     
      
       :
      
     
     <a href="https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html">
      
       
        https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Generative Adversarial
      
     </em>
     
      <em class="italic">
       
        Networks
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1406.2661">
      
       
        https://arxiv.org/abs/1406.2661
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Unsupervised Representation Learning with Deep Convolutional Generative Adversarial
      
     </em>
     
      <em class="italic">
       
        Networks
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1511.06434">
      
       
        https://arxiv.org/abs/1511.06434
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Wasserstein
      
     </em>
     
      <em class="italic">
       
        GAN
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1701.07875">
      
       
        https://arxiv.org/abs/1701.07875
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       A Style-Based Generator Architecture for Generative Adversarial
      
     </em>
     
      <em class="italic">
       
        Networks
       
      </em>
     
     
      
       :
      
     
     <a href="https://ieeexplore.ieee.org/document/8953766">
      
       
        https://ieeexplore.ieee.org/document/8953766
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Attention Is All You
      
     </em>
     
      <em class="italic">
       
        Need
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1706.03762">
      
       
        https://arxiv.org/abs/1706.03762
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Conditional Image Generation with PixelCNN
      
     </em>
     
      <em class="italic">
       
        Decoders
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1606.05328">
      
       
        https://arxiv.org/abs/1606.05328
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       PixelSNAIL: An Improved Autoregressive Generative
      
     </em>
     
      <em class="italic">
       
        Model
       
      </em>
     
     
      
       :
      
     
     <a href="https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model">
      
       
        https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Language Models are Few-Shot
      
     </em>
     
      <em class="italic">
       
        Learners
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/2005.14165">
      
       
        https://arxiv.org/abs/2005.14165
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       GPT-4 Technical
      
     </em>
     
      <em class="italic">
       
        Report
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/2303.08774">
      
       
        https://arxiv.org/abs/2303.08774
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       BERT: Pre-training of Deep Bidirectional Transformers for Language
      
     </em>
     
      <em class="italic">
       
        Understanding
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1810.04805">
      
       
        https://arxiv.org/abs/1810.04805
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Exploring the Limits of Transfer Learning with a Unified Text-to-Text
      
     </em>
     
      <em class="italic">
       
        Transformer
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/1910.10683">
      
       
        https://arxiv.org/abs/1910.10683
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Scalable Extraction of Training Data from (Production) Language
      
     </em>
     
      <em class="italic">
       
        Models
       
      </em>
     
     
      
       :
      
     
     <a href="https://arxiv.org/abs/2311.17035">
      
       
        https://arxiv.org/abs/2311.17035
       
      
     </a>
    </li>
   </ol>
   <h1 id="_idParaDest-38">
    <a id="_idTextAnchor037">
    </a>
    
     Join our communities on Discord and Reddit
    
   </h1>
   <p>
    
     Have questions about the book or want to contribute to discussions on Generative AI and LLMs?
    
    
     Join our Discord server at
    
    <a href="https://packt.link/I1tSU">
     
      https://packt.link/I1tSU
     
    </a>
    
     and our Reddit channel at
    
    <a href="https://packt.link/ugMW0">
     
      https://packt.link/ugMW0
     
    </a>
    
     to connect, share, and collaborate with
    
    
     
      like-minded enthusiasts.
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_Discord_QR_new.jpg"/>
     
    </div>
   </div>
   <p>
   </p>
   <div><div><img alt="img" role="presentation" src="img/qrcode_Reddit_Channel.jpg"/>
     
    </div>
   </div>
  </div>
 </body></html>