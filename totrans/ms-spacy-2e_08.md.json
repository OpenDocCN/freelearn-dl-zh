["```py\nnavigate to my home\nnavigate to Oxford Street\n```", "```py\nimport spacy\nnlp = spacy.load(\"en_core_web_md\")\ndoc1 = nlp(\"navigate to my home\")\ndoc1.ents\n ()\ndoc2 = nlp(\"navigate to Oxford Street\")\ndoc2.ents\n (Oxford Street,)\n doc2.ents[0].label_\n'FAC'\nspacy.explain(\"FAC\")\n'Buildings, airports, highways, bridges, etc.'\n```", "```py\n{\n  \"text\": \"Bonobos has some long sizes.\",\n  \"tokens\": [\n    { \"text\": \"Bonobos\", \"start\": 0, \"end\": 7, \"id\": 0 },\n    { \"text\": \"has\", \"start\": 8, \"end\": 11, \"id\": 1 },\n    { \"text\": \"some\", \"start\": 12, \"end\": 16, \"id\": 2 },\n    { \"text\": \"long\", \"start\": 17, \"end\": 21, \"id\": 3 },\n    { \"text\": \"sizes\", \"start\": 22, \"end\": 27, \"id\": 4 },\n    { \"text\": \".\", \"start\": 27, \"end\": 28, \"id\": 5 }\n  ],\n  \"spans\": [\n    {\n      \"start\": 0,\n      \"end\": 7,\n      \"token_start\": 0,\n      \"token_end\": 0,\n      \"label\": \"FASHION_BRAND\"\n    }\n  ]\n}\n```", "```py\n    import spacy\n    nlp = spacy.load(\"en_core_web_sm\", enable=\"tokenizer\")\n    ```", "```py\n    import srsly\n    from pprint import pprint\n    training_path = \"data/fashion_brands_training.jsonl\"\n    for row in srsly.read_jsonl(training_path):\n        pprint(row)\n        break\n    ```", "```py\n    nertk_input_text = []\n    for row in srsly.read_jsonl(training_path):\n        comment = nlp(row[\"text\"])\n        comment_words = [token.text for token in comment]\n        nertk_input_text.append(comment_words)\n    ```", "```py\n    from nertk import Entator\n    annotator = Entator(labels=['None', 'FASHION_BRAND'],\n    inputs=nertk_input_text)\n    annotator.run()\n    ```", "```py\n    from spacy.tokens import DocBin, Span\n    from utils import create_consecutive_token_sequences\n    db = DocBin()\n    for idx, (row, nerkt_tokens, nertk_entities) in enumerate(\n        zip(srsly.read_jsonl(training_path), nertk_input_text,\n            annotator.targets)):\n        if idx == 5:\n            break\n        doc = nlp(row[\"text\"])\n        indexes_entity_tokens = [index for index, x in enumerate(\n            nertk_entities) if x == \"FASHION_BRAND\"]\n    ```", "```py\n    span_indexes = create_consecutive_token_sequences(indexes_entity_tokens)\n    ```", "```py\n      ents = []\n      label = \"FASHION_BRAND\"\n      for start,end in span_indexes:\n          span = Span(doc, start, end+1, label)\n          ents.append(span)\n      doc.ents = ents\n      db.add(doc)\n    ```", "```py\n    db.to_disk(\"data/nertk_training.spacy\")\n    ```", "```py\n    from spacy.tokens import DocBin, Span\n    from utils import create_consecutive_token_sequences\n    db = DocBin()\n    for idx, (row, nerkt_tokens, nertk_entities) in enumerate(\n        zip(srsly.read_jsonl(training_path), nertk_input_text,\n            annotator.targets)):\n        if idx == 5:\n            break\n        doc = nlp(row[\"text\"])\n        indexes_entity_tokens = [index for index, x in enumerate(\n            nertk_entities) if x == \"FASHION_BRAND\"]\n\n        span_indexes = create_consecutive_token_sequences(\n            indexes_entity_tokens)\n\n        ents = []\n        label = \"FASHION_BRAND\"\n        for start, end in span_indexes:\n            span = Span(doc, start, end + 1, label)\n            ents.append(span)\n\n        doc.ents = ents\n        db.add(doc)\n    db.to_disk(\"data/nertk_training.spacy\")\n    ```", "```py\npython3 –m spacy init config cpu_config.cfg --lang \"en\" --pipeline \"ner\" --optimize \"efficiency\"\n```", "```py\npython3 ./scripts/preprocess.py ./data/fashion_brands_training.jsonl ./data/fashion_brands_training.spacy\npython3 ./scripts/preprocess.py ./data/fashion_brands_eval.jsonl ./data/fashion_brands_eval.spacy\n```", "```py\npython3 -m spacy train cpu_config.cfg --output training_cpu/ --paths.train ./data/fashion_brands_training.spacy --paths.dev ./data/fashion_brands_eval.spacy\n```", "```py\npython3 -m spacy evaluate training_cpu/model-best ./data/fashion_brands_eval.spacy --output training_cpu/metrics.json\n```", "```py\npython3 -m spacy init config gpu_config.cfg -l \"en\" -p \"ner\" --optimize \"accuracy\" --gpu\n```", "```py\npython3 -m spacy train gpu_config.cfg --output training_gpu/ --paths.train ./data/fashion_brands_training.spacy --paths.dev ./data/fashion_brands_eval.spacy --gpu-id 0\n```", "```py\npython3 -m spacy evaluate training_gpu/model-best ./data/fashion_brands_eval.spacy --output training_gpu/metrics.json --gpu-id 0\n```", "```py\n    import spacy\n    from spacy import displacy\n    nlp = spacy.load('training_gpu/model-best')\n    ```", "```py\n    sentence = \"Givenchy is looking at buying U.K. startup for $1 billion\"\n    doc = nlp(sentence)\n    displacy.render(doc, style=\"ent\", jupyter=True)\n    ```", "```py\n    import spacy\n    from spacy import displacy\n    nlp = spacy.load('en_core_web_sm')\n    ```", "```py\n    sentence = \"Givenchy is looking at buying U.K. startup for $1 billion\"\n    doc = nlp(sentence)\n    displacy.render(doc, style=\"ent\", jupyter=True)\n    ```", "```py\npython3 -m spacy package training_gpu/model-best ./ --name \"ner_fashion_brands\"\n```", "```py\n    python3 -m pip install en_ner_fashion_brands-0.0.0/\n    ```", "```py\n    import en_ner_fashion_brands\n    from spacy import displacy\n    nlp = en_ner_fashion_brands.load()\n    sentence = \"Givenchy is looking at buying U.K. startup for $1 billion\"\n    doc = nlp(sentence)\n    displacy.render(doc, style=\"ent\", jupyter=True)\n    ```", "```py\n    [nlp]\n    lang = \"en\"\n    pipeline = [\"ner_fashion_brands\",\"ner\"]\n    ```", "```py\n    [components]\n    [components.ner]\n    source = \"en_core_web_sm\"\n    component = \"ner\"\n    ```", "```py\n    [components.ner_fashion_brands]\n    source = \"en_ner_fashion_brands\"\n    component = \"ner\"\n    replace_listeners = [\"model.tok2vec\"]\n    ```", "```py\npython3 -m spacy assemble combined_ner.cfg pipelines/fashion_ner_with_base_entities\n```", "```py\n    import spacy\n    from spacy import displacy\n    nlp = spacy.load(\"pipelines/fashion_ner_with_base_entities\")\n    ```", "```py\n    sentence = \"Givenchy is looking at buying U.K. startup for $1 billion\"\n    doc = nlp(sentence)\n    displacy.render(doc, style=\"ent\", jupyter=True)\n    ```"]