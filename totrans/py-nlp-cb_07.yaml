- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Visualizing Text Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化文本数据
- en: This chapter is dedicated to creating visualizations for the different aspects
    of NLP work, much of which we have done in previous chapters. Visualizations are
    important when working with NLP tasks, as they help us to easier see the big picture
    of the work accomplished.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章致力于创建用于 NLP 工作不同方面的可视化，其中许多我们在前面的章节中已经完成。在处理 NLP 任务时，可视化非常重要，因为它们帮助我们更容易地看到已完成工作的整体情况。
- en: We will create different types of visualizations, including visualizations of
    grammar details, parts of speech, and topic models. After working through this
    chapter, you will be well equipped to create compelling images to show and explain
    the outputs of various NLP tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建不同类型的可视化，包括语法细节、词性和主题模型的可视化。完成本章后，你将能够创建引人入胜的图像来展示和解释各种 NLP 任务的输出。
- en: 'These are the recipes you will find in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中你可以找到以下食谱：
- en: Visualizing the dependency parse
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化依存句法
- en: Visualizing parts of speech
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化词性
- en: Visualizing NER
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化 NER
- en: Creating a confusion matrix plot
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建混淆矩阵图
- en: Constructing word clouds
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建词云
- en: Visualizing topics from Gensim
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Gensim 可视化主题
- en: Visualizing topics from BERTopic
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 BERTopic 可视化主题
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will use the following packages in this chapter: `spacy`, `matplotlib`,
    `wordcloud`, and `pyldavis`. They are part of the `poetry` environment and the
    `requirements.txt` file.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将使用以下包：`spacy`、`matplotlib`、`wordcloud` 和 `pyldavis`。它们是 `poetry` 环境和 `requirements.txt`
    文件的一部分。
- en: We will be using two datasets in this chapter. The first is the BBC news dataset,
    located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json)
    and [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将使用两个数据集。第一个是 BBC 新闻数据集，位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json)和[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json)。
- en: Note
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'This dataset is used in this book with permission from the researchers. The
    original paper associated with this dataset is as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用此数据集已获得研究者的许可。与此数据集相关的原始论文如下：
- en: Derek Greene and Pádraig Cunningham. “Practical Solutions to the Problem of
    Diagonal Dominance in Kernel Document Clustering,” in Proc. 23rd International
    Conference on Machine Learning (ICML’06), 2006.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Derek Greene 和 Pádraig Cunningham. “Kernel 文档聚类中对角优势问题的实用解决方案，”在 2006 年第 23
    届国际机器学习会议 (ICML’06) 上发表。
- en: All rights, including copyright, in the text content of the original articles
    are owned by the BBC.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 原始文章文本内容的版权等所有权利均归 BBC 所有。
- en: The second is the Sherlock Holmes text, located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/sherlock_holmes.txt](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/sherlock_holmes.txt).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是 Sherlock Holmes 文本，位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/sherlock_holmes.txt](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/sherlock_holmes.txt)。
- en: Visualizing the dependency parse
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化依存句法
- en: In this recipe, we will learn how to use the `displaCy` library and visualize
    the dependency parse. It shows us the grammatical relations between words in a
    piece of text, usually a sentence.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将学习如何使用 `displaCy` 库并可视化依存句法。它展示了文本中单词之间的语法关系，通常是一句话。
- en: Details about how to create a dependency parse can be found in [*Chapter 2*](B18411_02.xhtml#_idTextAnchor042),
    in the *Getting the dependency parse* recipe. We will create two visualizations,
    one for a short text and another for a long multi-sentence text.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何创建依存句法的详细信息可以在[*第2章*](B18411_02.xhtml#_idTextAnchor042)中找到，在*获取依存句法*食谱中。我们将创建两个可视化，一个用于短文本，另一个用于长多句文本。
- en: After working through this recipe, you will be able to create visualizations
    of grammatical structures with different options for formatting.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个食谱后，你将能够创建具有不同格式化选项的语法结构可视化。
- en: Getting ready
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The `displaCy` library is part of the `spacy` package. You need at least version
    2.0.12 of the `spacy` package for `displaCy` to work. The version in the `poetry`
    environment and `requirements.txt` is 3.6.1.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`displaCy` 库是 `spacy` 包的一部分。为了让 `displaCy` 正常工作，您至少需要 `spacy` 包的 2.0.12 版本。`poetry`
    环境和 `requirements.txt` 中的版本是 3.6.1。'
- en: The notebook is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.1_dependency_parse.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.1_dependency_parse.ipynb).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本位于 [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.1_dependency_parse.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.1_dependency_parse.ipynb)。
- en: How to do it...
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'To visualize the dependency parse, we will use the functionality of the `displaCy`
    package to first show one sentence, and then two sentences together:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化依赖关系解析，我们将使用 `displaCy` 包的功能首先显示一个句子，然后一起显示两个句子：
- en: 'Import the necessary packages:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Run the language utilities file:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行语言工具文件：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define the input text and process it using the small model:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入文本并使用小型模型进行处理：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will now define different visualization options. The `render` command, we
    provide these options as an argument. We set the `jupyter` parameter to `True`
    for the visualization to work correctly in the notebook. You can omit the argument
    for non-Jupyter visualizations. We set the `style` parameter to `''dep''`, as
    we would like to have a dependency parse output. The output is a visual representation
    of the dependency parse:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将定义不同的可视化选项。`render` 命令，我们将这些选项作为参数提供。我们将 `jupyter` 参数设置为 `True` 以确保在笔记本中正确可视化。对于非
    Jupyter 可视化，您可以省略此参数。我们将 `style` 参数设置为 `'dep'`，因为我们希望得到依赖关系解析输出。输出是依赖关系解析的视觉表示：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output is shown in *Figure 7**.1*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示在 *图 7**.1* 中。
- en: '![](img/B18411_07_01.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18411_07_01.jpg)'
- en: Figure 7.1 – Dependency parse visualization
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 依赖关系解析可视化
- en: 'In this step, we save the visualization to a file. We first import the **Path**
    object from the **pathlib** package. We then initialize a string with the path
    where we want to save the file and create a **Path** object. We use the same **render**
    command, this time saving the output in a variable and setting the **jupyter**
    parameter to **False**. We then use the **output_path** object and write the output
    to the corresponding file:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们将可视化保存到文件中。我们首先从 **pathlib** 包中导入 **Path** 对象。然后初始化一个字符串，其中包含我们想要保存文件的路径，并创建一个
    **Path** 对象。我们使用相同的 **render** 命令，这次将输出保存到变量中，并将 **jupyter** 参数设置为 **False**。然后我们使用
    **output_path** 对象将输出写入相应的文件：
- en: '[PRE4]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will create the dependency parse and save it at `../data/dep_parse_viz.svg`.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建依赖关系解析并将其保存到 `../data/dep_parse_viz.svg`。
- en: 'Now, let’s define a longer text and process it using the small model. This
    way, we will be able to see how **displaCy** deals with longer texts:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义一个较长的文本，并使用小型模型进行处理。这样，我们将能够看到 **displaCy** 如何处理较长的文本：
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, we visualize the new text. This time, we have to input a list of sentences
    from the processed **spacy** object to indicate that there is more than one sentence:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们可视化新文本。这次，我们必须输入从处理后的 **spacy** 对象中提取的句子列表，以表明存在多个句子：
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output should look like in *Figure 7**.2*. We see that the output for the
    second sentence starts on a new line.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该看起来像 *图 7**.2* 中的那样。我们看到第二个句子的输出从新的一行开始。
- en: '![](img/B18411_07_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18411_07_02.jpg)'
- en: Figure 7.2 – Several sentences dependency parse visualization
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 几个句子的依赖关系解析可视化
- en: Visualizing parts of speech
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化词性
- en: In this recipe, we visualize part of speech counts. Specifically, we count the
    number of infinitives and past or present verbs in the book *The Adventures of
    Sherlock Holmes*. This can give us an idea about whether the text mostly talks
    about past or present events. We could imagine that similar tools could be used
    to evaluate the quality of a text; for example, a book with very few adjectives
    but many nouns would not work very well as a fiction book.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们可视化词性计数。具体来说，我们统计了《福尔摩斯探案集》中不定式和过去或现在动词的数量。这可以让我们了解文本主要讲述的是过去还是现在的事件。我们可以想象，类似的工具可以用来评估文本的质量；例如，形容词很少但名词很多的书籍可能不适合作为小说。
- en: After working through this recipe, you will be able to use the `matplotlib`
    package to create bar plots of different verb types, which are tagged using the
    `spacy` package.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这个配方后，您将能够使用`matplotlib`包创建不同动词类型的条形图，这些动词是用`spacy`包标记的。
- en: Getting ready
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the `spacy` package for text analysis and the `matplotlib` package
    to create the graph. They are part of the `poetry` environment and the `requirements.txt`
    file.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`spacy`包进行文本分析，并使用`matplotlib`包创建图表。它们是`poetry`环境的一部分，并在`requirements.txt`文件中。
- en: The notebook is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.2_parts_of_speech.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.2_parts_of_speech.ipynb).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.2_parts_of_speech.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.2_parts_of_speech.ipynb)。
- en: How to do it...
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We will create a function that will count the number of verbs by tense and
    plot each on a bar graph:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个函数，该函数将按时态计数动词的数量，并在条形图上绘制每个时态：
- en: 'Import the necessary packages:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE7]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the file and language utilities files. The language utilities notebook
    loads the **spacy** model, and the file utilities notebook loads the **read_text_file**
    function:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件和语言实用工具文件。语言实用工具笔记本加载**spacy**模型，文件实用工具笔记本加载**read_text_file**函数：
- en: '[PRE8]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Load the text of the Sherlock Holmes book:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载《福尔摩斯探案集》的文本：
- en: '[PRE9]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, we define the verb tag lists, one for present tense and one for past
    tense. We do not define another list, but use it in the next step, and that is
    the infinitive verb, which only has one tag, **VB**. If you went through the *Part-of-speech
    tagging* recipe in [*Chapter 1*](B18411_01.xhtml#_idTextAnchor013), you will notice
    that the tags are different from the **spacy** tags used there. These tags are
    more detailed and use the **tag_** attribute instead of the **pos_** attribute
    that is used in the simplified tagset:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们定义动词标记列表，一个用于现在时，一个用于过去时。我们没有定义另一个列表，但在下一步中使用它，那就是不定式动词，它只有一个标记，**VB**。如果您已经完成了[*第1章*](B18411_01.xhtml#_idTextAnchor013)中的*词性标注*配方，您会注意到标记与那里使用的**spacy**标记不同。这些标记更详细，并使用**tag_**属性而不是在简化标记集中使用的**pos_**属性：
- en: '[PRE10]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In this step, we create the **visualize_verbs** function. The input to the
    function is the text and the **spacy** model. We check each token’s **tag_** attribute
    and add the counts of present, past, and infinitive verbs to a dictionary. We
    then use the **pyplot** interface to plot those counts in a bar graph. We use
    the **bar** function to define the bar graph. The first argument lists the *x*
    coordinates of the bars. The next argument is a list of heights of the bars. We
    also set the **align** parameter to “center” and provide the colors for the bars
    using the **color** parameter. The **xticks** function sets the labels for the
    *x* axis. Finally, we use the **show** function to display the resulting plot:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们创建**visualize_verbs**函数。该函数的输入是文本和**spacy**模型。我们检查每个标记的**tag_**属性，并将现在式、过去式和不定式动词的数量添加到字典中。然后我们使用**pyplot**接口将这些数量绘制成条形图。我们使用**bar**函数定义条形图。第一个参数列出条形的*x*坐标。下一个参数是条形的高度列表。我们还设置了**align**参数为“center”，并使用**color**参数提供了条形的颜色。**xticks**函数设置*x*轴的标签。最后，我们使用**show**函数显示生成的图表：
- en: '[PRE11]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Run the **visualize_verbs** function on the text of the Sherlock Holmes book
    using the small **spacy** model:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在《福尔摩斯探案集》的文本上运行**visualize_verbs**函数，使用小的**spacy**模型：
- en: '[PRE12]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This will create the graph in *Figure 7**.3*. We see that most of the verbs
    in the book are past tense, which makes sense for a novel. However, there is also
    a sizable number of present tense verbs, which could be part of direct speech.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将在*图7.3*中创建图表。我们看到书中大多数动词都是过去式，这对于小说来说是合理的。然而，也有相当数量的现在式动词，这可能是直接引语的一部分。
- en: '![](img/B18411_07_03.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18411_07_03.jpg)'
- en: Figure 7.3 – Infinitive, past, and present verbs in The Adventures of Sherlock
    Holmes
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 《福尔摩斯探案集》中的不定式、过去式和现在式动词
- en: Visualizing NER
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名实体可视化
- en: '`displacy` package to create compelling and easy-to-read images.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`displacy`包创建引人入胜且易于阅读的图像。
- en: After working through this recipe, you will be able to create visualizations
    of named entities in a text using different formatting options and save the results
    in a file.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这个配方后，您将能够使用不同的格式选项在文本中创建命名实体的可视化，并将结果保存到文件中。
- en: Getting ready
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The `displaCy` library is part of the `spacy` package. You need at least version
    2.0.12 of the `spacy` package for `displaCy` to work. The version in the `poetry`
    environment and `requirements.txt` file is 3.6.1.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`displaCy`库是`spacy`包的一部分。你需要至少`spacy`包的2.0.12版本才能使`displaCy`工作。`poetry`环境和`requirements.txt`文件中的版本是3.6.1。'
- en: The notebook is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.3_ner.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.3_ner.ipynb).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.3_ner.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.3_ner.ipynb)。
- en: How to do it...
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We will use `spacy` to parse the sentence and then the `displacy` engine to
    visualize the named entities:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`spacy`解析句子，然后使用`displacy`引擎来可视化命名实体：
- en: 'Import both **spacy** and **displacy**:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入**spacy**和**displacy**：
- en: '[PRE13]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Run the language utilities file:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行语言工具文件：
- en: '[PRE14]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Define the text to process:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要处理的文本：
- en: '[PRE15]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In this step, we process the text using the small model. This gives us a **Doc**
    object. We then modify the object to contain a title. This title will be part
    of the NER visualization:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们使用小型模型处理文本。这给我们一个**Doc**对象。然后我们修改对象以包含标题。这个标题将是NER可视化的部分：
- en: '[PRE16]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here, we set up color options for the visualization display. We set green for
    the **ORG**-labeled text and yellow for the **PERSON**-labeled text. We then set
    the **options** variable, which contains the colors. Finally, we use the **render**
    command to display the visualization. As arguments, we provide the **Doc** object
    and the options we previously defined. We also set the **style** argument to **"ent"**,
    as we would like to display just entities. We set the **jupyter** argument to
    **True** in order to display directly in the notebook:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为可视化显示设置了颜色选项。我们将绿色用于**ORG**标记的文本，黄色用于**PERSON**标记的文本。然后我们设置**options**变量，它包含颜色。最后，我们使用**render**命令来显示可视化。作为参数，我们提供**Doc**对象和之前定义的选项。我们还设置**style**参数为**"ent"**，因为我们只想显示实体。我们将**jupyter**参数设置为**True**，以便直接在笔记本中显示：
- en: '[PRE17]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output should look like that in *Figure 7**.4*.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该看起来像*图7.4*。
- en: '![](img/B18411_07_04.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18411_07_04.jpg)'
- en: Figure 7.4 – Named entities visualization
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 命名实体可视化
- en: 'Now we save the visualization to an HTML file. We first define the **path**
    variable. Then, we use the same **render** command, but we set the **jupyter**
    argument to **False** this time and assign the output of the command to the **html**
    variable. We then open the file, write the HTML, and close the file:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将可视化保存到HTML文件中。我们首先定义**路径**变量。然后，我们使用相同的**render**命令，但这次我们将**jupyter**参数设置为**False**，并将命令的输出分配给**html**变量。然后我们打开文件，写入HTML，并关闭文件：
- en: '[PRE18]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This will create an HTML file with the entities visualization.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建一个包含实体可视化的HTML文件。
- en: Creating a confusion matrix plot
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建混淆矩阵图
- en: When working with machine learning models, for example, NLP classification models,
    creating a confusion matrix plot can be a very good tool to see the mistakes that
    the model makes to then further refine it. The model “confuses” one class for
    another, hence the name **confusion matrix**.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理机器学习模型时，例如，NLP分类模型，创建混淆矩阵图可以是一个非常好的工具，用来查看模型犯的错误，以便进一步改进。模型“混淆”了一个类别为另一个类别，因此得名**混淆矩阵**。
- en: After working through this recipe, you will be able to create an SVM model,
    evaluate it, and then create a confusion matrix visualization that will tell you
    in detail which mistakes the model makes.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这个配方后，你将能够创建一个SVM模型，评估它，然后创建一个混淆矩阵可视化，这将详细告诉你模型犯了哪些错误。
- en: Getting ready
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will create an SVM classifier for the BBC news dataset using the sentence
    transformer model as the vectorizer. We will then use the `ConfusionMatrixDisplay`
    object to create a more informative confusion matrix. The classifier is the same
    as in the [*Chapter 4*](B18411_04.xhtml#_idTextAnchor106) recipe *Using SVMs for
    supervised* *text classification*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用句子转换器模型作为向量器，为BBC新闻数据集创建一个SVM分类器。然后我们将使用`ConfusionMatrixDisplay`对象创建一个更信息丰富的混淆矩阵。该分类器与[*第4章*](B18411_04.xhtml#_idTextAnchor106)配方*使用SVM进行监督文本分类*相同。
- en: The dataset is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json)
    and [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json)和[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json)。
- en: The notebook is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.4_confusion_matrix.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.4_confusion_matrix.ipynb).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.4_confusion_matrix.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.4_confusion_matrix.ipynb)。
- en: How to do it...
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Import the necessary packages and functions:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包和函数：
- en: '[PRE19]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Run the simple classifier utilities file:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行简单的分类器工具文件：
- en: '[PRE20]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Read in the training and test data and shuffle the training data. We shuffle
    the data so that there are no long sequences of one class, which might either
    bias the model during training or exclude large chunks of some classes:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取训练和测试数据，并对训练数据进行洗牌。我们洗牌数据是为了确保没有长序列的单个类别，这可能会在训练过程中使模型产生偏差，或者排除某些类别的较大部分：
- en: '[PRE21]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this step, we load the transformer model and create the **get_sentence_vector**
    function. The function takes as arguments the text and the model, then creates
    and returns the vector. The **encode** method takes in a list of text, so in order
    to encode one piece of text, we need to put it into a list, and then get the first
    element of the **return** object, since the model also returns a list of encoding
    vectors:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们加载转换器模型并创建**get_sentence_vector**函数。该函数接受文本和模型作为参数，然后创建并返回向量。**encode**方法接受一个文本列表，因此为了编码一段文本，我们需要将其放入一个列表中，然后获取**返回**对象的第一元素，因为模型也返回一个编码向量列表：
- en: '[PRE22]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, we create the **train_classifier** function. The function takes in vectorized
    input and the correct answers. It then creates and trains an SVC object and returns
    it. It could take a few minutes to finish training:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们创建**train_classifier**函数。该函数接受向量化输入和正确答案。然后创建并训练一个SVC对象并返回它。训练可能需要几分钟时间：
- en: '[PRE23]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In this step, we train and test the classifier. First, we create a list with
    the target labels. We then create a **vectorize** function that uses the **get_sentence_vector**
    function but specifies the model to use. We then use the **create_train_test_data**
    function from the simple classifier utilities file to get the vectorized input
    and labels for both the training and test sets. This function takes in the training
    and test dataframes, the vectorizing method, and the name of the column where
    the text is located. The results are the vectorized training and test data and
    the true labels for both. Then, we use the **train_classifier** function to create
    a trained SVM classifier. We print the classification report for the training
    data and use the **test_classifier** function to print the classification report
    for the test data:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们训练和测试分类器。首先，我们创建一个包含目标标签的列表。然后我们创建一个**vectorize**函数，该函数使用**get_sentence_vector**函数，但指定要使用的模型。然后我们使用简单分类器工具文件中的**create_train_test_data**函数来获取训练集和测试集的向量化输入和标签。该函数接受训练和测试数据框、向量化方法和文本所在的列名。结果是向量化的训练和测试数据以及两个数据集的真实标签。然后，我们使用**train_classifier**函数创建一个训练好的SVM分类器。我们打印训练数据的分类报告，并使用**test_classifier**函数打印测试数据的分类报告：
- en: '[PRE24]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output should be as follows:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该是以下这样的：
- en: '[PRE25]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we create a mapping from number labels to text labels and then create
    a new column in the test dataframe that shows the text label prediction:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们创建一个从数字标签到文本标签的映射，然后在测试数据框中创建一个新列，显示文本标签预测：
- en: '[PRE26]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In this step, we create a confusion matrix using the **sklearn** **confusion_matrix**
    function. The function takes as input the true labels, the predictions, and the
    names of the categories. We then create a **ConfusionMatrixDisplay** object that
    takes in that confusion matrix and the names to display. We then create the confusion
    matrix plot using the object and display it using the **matplotlib** library:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们使用**sklearn**的**confusion_matrix**函数创建一个混淆矩阵。该函数接受真实标签、预测和类别名称作为输入。然后我们创建一个**ConfusionMatrixDisplay**对象，该对象接受混淆矩阵和要显示的名称。然后我们使用该对象创建混淆矩阵图，并使用**matplotlib**库显示：
- en: '[PRE27]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The result is shown in *Figure 7**.5*. The resulting plot clearly shows which
    classes have overlaps and their number. For example, it is easy to see that there
    are two examples that are predicted to be about business but are actually about
    politics.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示在*图7.5*中。生成的图清楚地显示了哪些类别有重叠以及它们的数量。例如，很容易看出有两个例子被预测为关于商业，但实际上是关于政治的。
- en: '![](img/B18411_07_05.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18411_07_05.jpg)'
- en: Figure 7.5 – Confusion matrix visualization
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 混淆矩阵可视化
- en: Constructing word clouds
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建词云
- en: Word clouds are a nice visualization tool to quickly see topics that are prevalent
    in a text. They can be used at the preliminary data analysis stage and for illustration
    purposes. A distinguishing feature of word clouds is that larger-font words signify
    a more frequent topic, while smaller-font words signify less frequent topics.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 词云是一种很好的可视化工具，可以快速查看文本中普遍存在的话题。它们可以在初步数据分析阶段和演示目的中使用。词云的一个特点是，大字体单词表示更频繁的话题，而小字体单词表示较少频繁的话题。
- en: After working through this recipe, you will be able to create word clouds from
    a text and also apply a picture mask on top of the word cloud, which makes for
    a cool image.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个食谱后，你将能够从文本中创建词云，并在词云上应用图片蒙版，这将生成一个酷炫的图像。
- en: We will use the text of the book *The Adventures of Sherlock Holmes* and the
    picture mask we will use is a silhouette of Sherlock Holmes’ head.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用书籍《福尔摩斯探案集》的文本，我们将使用的图片蒙版是福尔摩斯头像的剪影。
- en: Getting ready
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the `wordcloud` package for this recipe. In order to display the
    image, we need the `matplotlib` package as well. They are both part of the `poetry`
    environment and the `requirements.txt` file.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`wordcloud`包来完成这个食谱。为了显示图像，我们需要`matplotlib`包。它们都是`poetry`环境的一部分，并且包含在`requirements.txt`文件中。
- en: The notebook is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.5_word_clouds.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.5_word_clouds.ipynb).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.5_word_clouds.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.5_word_clouds.ipynb)。
- en: How to do it...
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Import the necessary packages and functions:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包和函数：
- en: '[PRE28]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Run the file utilities notebook. We will use the **read_text_file** function
    from this notebook:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行文件工具笔记本。我们将使用该笔记本中的**read_text_file**函数：
- en: '[PRE29]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Read in the book text:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取书籍文本：
- en: '[PRE30]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In this step, we define the **create_wordcloud** function. The function takes
    as arguments the text to be processed, stopwords, the filename of where to save
    the result, and whether to apply a mask over the image (**None** by default).
    It creates the **WordCloud** object, saves it to the file, and then outputs the
    resulting plot. The options that we provide to the **WordCloud** object are the
    minimum font size, the maximum font size, the width and height, the maximum number
    of words, and the background color:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们定义了**create_wordcloud**函数。该函数接受要处理的文本、停用词、结果保存的文件名以及是否在图像上应用蒙版（默认为**None**）。它创建**WordCloud**对象，将其保存到文件，然后输出结果图。我们提供给**WordCloud**对象的可选参数包括最小字体大小、最大字体大小、宽度、高度、最大单词数和背景颜色：
- en: '[PRE31]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Run the **create_wordcloud** function on the text of the Sherlock Holmes book:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在《福尔摩斯探案集》的文本上运行**create_wordcloud**函数：
- en: '[PRE32]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This will save the result in the file located at `data/sherlock_wc.png` and
    create the visualization displayed in *Figure 7.6* (your results might look slightly
    different).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这将结果保存到位于`data/sherlock_wc.png`的文件中，并创建显示在*图7.6*（你的结果可能略有不同）中的可视化。
- en: '![](img/B18411_07_06.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18411_07_06.jpg)'
- en: Figure 7.6 – Sherlock Holmes word cloud visualization
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 福尔摩斯词云可视化
- en: There’s more...
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We can also apply a mask to the word cloud. Here, we will apply a Sherlock
    Holmes silhouette to the word cloud:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以对词云应用遮罩。在这里，我们将夏洛克·福尔摩斯的轮廓应用到词云上：
- en: 'Do the additional imports:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行额外的导入：
- en: '[PRE33]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Read in the mask image and save it as a **numpy** array:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取遮罩图像并将其保存为**numpy**数组：
- en: '[PRE34]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Run the function on the text of the Sherlock Holmes book:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在夏洛克·福尔摩斯的书文本上运行该函数：
- en: '[PRE35]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This will save the result in the file located at `data/sherlock_mask.png` and
    create the visualization shown in *Figure 7**.7* (your result might be slightly
    different):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把结果保存到位于`data/sherlock_mask.png`的文件中，并创建如图7.7所示的可视化（你的结果可能略有不同）：
- en: '![](img/B18411_07_07.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18411_07_07.jpg)'
- en: Figure 7.7 – Word cloud with mask
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 带遮罩的词云
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Please see the `wordcloud` docs, [https://amueller.github.io/word_cloud/](https://amueller.github.io/word_cloud/),
    for more options.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅`wordcloud`文档，[https://amueller.github.io/word_cloud/](https://amueller.github.io/word_cloud/)，以获取更多选项。
- en: Visualizing topics from Gensim
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Gensim可视化主题
- en: In this recipe, we will visualize the **Latent Dirichlet Allocation** (**LDA**)
    topic model that we created in [*Chapter 6*](B18411_06.xhtml#_idTextAnchor156).
    The visualization will allow us to quickly see words that are most relevant to
    a topic and the distances between topics.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将可视化我们在[*第6章*](B18411_06.xhtml#_idTextAnchor156)中创建的**潜在狄利克雷分配**（**LDA**）主题模型。这种可视化将使我们能够快速看到与每个主题最相关的单词以及主题之间的距离。
- en: After working through this recipe, you will be able to load an existing LDA
    model and create a visualization for its topics, both in Jupyter and saved as
    an HTML file.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这个配方后，你将能够加载现有的LDA模型并为它的主题创建可视化，既可以在Jupyter中查看，也可以保存为HTML文件。
- en: Getting ready
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the `pyLDAvis` package to create the visualization. It is available
    in the `poetry` environment and the `requirements.txt` file.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`pyLDAvis`包来创建可视化。它在`poetry`环境和`requirements.txt`文件中可用。
- en: We will load the model we created in [*Chapter 6*](B18411_06.xhtml#_idTextAnchor156)
    and then use the `pyLDAvis` package to create the topic model visualization.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加载我们在[*第6章*](B18411_06.xhtml#_idTextAnchor156)中创建的模型，然后使用`pyLDAvis`包创建主题模型可视化。
- en: The notebook is located at [https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.6_topics_gensim.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.6_topics_gensim.ipynb).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本位于[https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.6_topics_gensim.ipynb](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.6_topics_gensim.ipynb)。
- en: How to do it...
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Import the necessary packages and functions:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包和函数：
- en: '[PRE36]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Define the paths to the model files. The model was trained in [*Chapter 6*](B18411_06.xhtml#_idTextAnchor156):'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型文件的路径。模型是在[*第6章*](B18411_06.xhtml#_idTextAnchor156)中训练的：
- en: '[PRE37]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In this step, we load the objects that these paths point to. If you get a **FileNotFoundError**
    error at this step, it means that you have not created the dictionary, corpus,
    and model files. In that case, go back to [*Chapter 6*](B18411_06.xhtml#_idTextAnchor156),
    the *LDA topic modeling with Gensim* recipe, and create the model and the accompanying
    files:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们加载这些路径指向的对象。如果你在这一步遇到**FileNotFoundError**错误，这意味着你没有创建字典、语料库和模型文件。在这种情况下，回到[*第6章*](B18411_06.xhtml#_idTextAnchor156)，即*使用Gensim进行LDA主题建模*配方，创建模型和相关文件：
- en: '[PRE38]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here, we create the **PreparedData** object using the preceding files and save
    the visualization as HTML. The object is required for the visualization methods:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们使用前面的文件创建**PreparedData**对象，并将可视化保存为HTML。该对象是可视化方法所必需的：
- en: '[PRE39]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here, we enable the Jupyter **display** option and display the visualization
    in the notebook. You will see the topics and the words that are important for
    each topic. To select a particular topic, hover over it with the mouse. You will
    see the most important words for each topic change while hovering over them:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们启用Jupyter的**显示**选项，并在笔记本中显示可视化。你会看到每个主题及其重要的单词。要选择特定的主题，用鼠标悬停在它上面。当你悬停在它们上面时，你会看到每个主题的最重要单词会发生变化：
- en: '[PRE40]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This will create the visualization in *Figure 7**.8* (your results might vary):'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建如图7.8所示的可视化（你的结果可能会有所不同）：
- en: '![](img/B18411_07_08.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18411_07_08.jpg)'
- en: Figure 7.8 – LDA model visualization
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – LDA模型可视化
- en: See also
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'Using `pyLDAvis`, it is also possible to visualize models created using `sklearn`.
    See the package documentation for more information: [https://github.com/bmabey/pyLDAvis](https://github.com/bmabey/pyLDAvis).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pyLDAvis`，也可以可视化使用`sklearn`创建的模型。有关更多信息，请参阅包文档：[https://github.com/bmabey/pyLDAvis](https://github.com/bmabey/pyLDAvis)。
- en: Visualizing topics from BERTopic
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BERTopic主题可视化
- en: In this recipe, we will create and visualize a BERTopic model on the BBC data.
    There are several visualizations available with the BERTopic package, and we will
    use several of them.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将创建并可视化BBC数据上的BERTopic模型。BERTopic包提供了几个可视化选项，我们将使用其中几个。
- en: In this recipe, we will create a topic model in a similar fashion as in [*Chapter
    6*](B18411_06.xhtml#_idTextAnchor156), in the *Topic modeling using BERTopic*
    recipe. However, unlike in [*Chapter 6*](B18411_06.xhtml#_idTextAnchor156), we
    will not limit the number of topics created, and resulting in more than the 5
    original topics in the data. It will allow for more interesting visualizations.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将以与[*第6章*](B18411_06.xhtml#_idTextAnchor156)中的*使用BERTopic进行主题建模*食谱类似的方式创建主题模型。然而，与[*第6章*](B18411_06.xhtml#_idTextAnchor156)不同，我们不会限制创建的主题数量，这将导致数据中超过5个原始主题。这将允许进行更有趣的可视化。
- en: Getting ready
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the `BERTopic` package to create the visualization. It is available
    in the `poetry` environment.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`BERTopic`包来创建可视化。它在`poetry`环境中可用。
- en: How to do it...
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Import the necessary packages and functions:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包和函数：
- en: '[PRE41]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Run the language utilities file:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行语言工具文件：
- en: '[PRE42]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Read in the data:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取数据：
- en: '[PRE43]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Here, we create a list of training documents from the dataframe object. We then
    initialize a representation model object. Here, we use the **KeyBERTInspired**
    object, which uses BERT to extract the keywords.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里，我们从一个dataframe对象中创建一个训练文档列表。然后我们初始化一个表示模型对象。在这里，我们使用**KeyBERTInspired**对象，它使用BERT提取关键词。
- en: 'This object creates the names (representations) for the topics; it does a better
    job than the default version, which contains lots of stopwords. We then create
    the main topic model object and fit it to the document set. In this recipe, in
    contrast to the *Topic modeling using BERTopic* recipe in [*Chapter 6*](B18411_06.xhtml#_idTextAnchor156),
    we do not place limits on the number of created topics. This will create a lot
    more topics:'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此对象创建主题的名称（表示）；它比默认版本做得更好，默认版本包含大量停用词。然后我们创建主主题模型对象并将其拟合到文档集中。在本食谱中，与[*第6章*](B18411_06.xhtml#_idTextAnchor156)中的*使用BERTopic进行主题建模*食谱相比，我们不限制创建的主题数量。这将创建更多主题：
- en: '[PRE44]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'In this step, we display the general topic visualization. It shows all 42 topics
    created. If you hover on each circle, you will see the topic representation or
    name. The representations consist of the top five words in the topic:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，我们显示一般主题可视化。它显示了创建的所有42个主题。如果你悬停在每个圆圈上，你会看到主题表示或名称。表示由主题中的前五个单词组成：
- en: '[PRE45]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This will create the visualization in *Figure 7**.9* (your results might vary).
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建如图7**.9**所示的可视化（你的结果可能会有所不同）。
- en: '![](img/B18411_07_09.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18411_07_09.jpg)'
- en: Figure 7.9 – BERTopic model visualization
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 – BERTopic模型可视化
- en: 'Here, we create a visualization of the topic hierarchy. This hierarchy clusters
    the different topics together if they are related. We first create the hierarchy
    by using the **hierarchical_topics** function of the topic model object, and then
    pass it into the **visualize_hierarchy** function. The nodes that combine the
    different topics have their own names that you can see if you hover over them:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里，我们创建了一个主题层次结构的可视化。如果主题相关，这个层次结构会将不同的主题聚集在一起。我们首先使用主题模型对象的`hierarchical_topics`函数创建层次结构，然后将其传递给`visualize_hierarchy`函数。组合不同主题的节点有自己的名称，如果你悬停在它们上面，你可以看到：
- en: '[PRE46]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This will create the visualization in *Figure 7**.10*.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建如图7**.10**所示的可视化。
- en: '![](img/B18411_07_10.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18411_07_10.jpg)'
- en: Figure 7.10 – BERTopic hierarchical visualization
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 – BERTopic层次可视化
- en: If you hover over the nodes, you will see their names.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你悬停在节点上，你会看到它们的名称。
- en: 'In this step, we create a bar chart with the top words for the topics. We specify
    the number of topics to show by using the **top_n_topics** argument that the **visualize_barchart**
    function of the topic model object takes:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，我们创建一个条形图，显示主题的前几个单词。我们通过使用主题模型对象的`visualize_barchart`函数的`top_n_topics`参数来指定要显示的主题数量：
- en: '[PRE47]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This will create a visualization similar to this:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建一个类似于此的可视化：
- en: '![](img/B18411_07_11.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18411_07_11.jpg)'
- en: Figure 7.11 – BERTopic word scores
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11 – BERTopic单词得分
- en: 'Here, we create a visualization of individual documents in the training set.
    We provide the list of documents created in *step 4* to the **visualize_documents**
    function. It clusters the documents to the topics. You can see the documents if
    you hover over the individual circles:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们创建训练集中单个文档的可视化。我们将 *步骤 4* 中创建的文档列表提供给 **visualize_documents** 函数。它将文档聚类到主题中。如果你将鼠标悬停在单个圆圈上，你可以看到文档：
- en: '[PRE48]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The result will be a visualization similar to this:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果将类似于以下可视化：
- en: '![](img/B18411_07_12.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18411_07_12.jpg)'
- en: Figure 7.12 – BERTopic document visualization
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – BERTopic 文档可视化
- en: If you hover over the nodes, you will see the text of the individual documents.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将鼠标悬停在节点上，你会看到单个文档的文本。
- en: See also
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'There are additional visualization tools available through BERTopic. See the
    package documentation for more information: [https://maartengr.github.io/BERTopic/index.html](https://maartengr.github.io/BERTopic/index.html).'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 BERTopic 可用额外的可视化工具。有关更多信息，请参阅包文档：[https://maartengr.github.io/BERTopic/index.html](https://maartengr.github.io/BERTopic/index.html)。
- en: To learn more about **KeyBERTInspired**, see [https://maartengr.github.io/BERTopic/api/representation/keybert.html](https://maartengr.github.io/BERTopic/api/representation/keybert.html).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要了解更多关于 **KeyBERTInspired** 的信息，请参阅 [https://maartengr.github.io/BERTopic/api/representation/keybert.html](https://maartengr.github.io/BERTopic/api/representation/keybert.html)。
