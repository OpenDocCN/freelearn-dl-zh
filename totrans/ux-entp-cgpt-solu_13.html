<html><head></head><body>
		<div><h1 id="_idParaDest-209" class="chapter-number"><a id="_idTextAnchor216" class="pcalibre pcalibre1 calibre6"/>10</h1>
			<h1 id="_idParaDest-210" class="calibre5"><a id="_idTextAnchor217" class="pcalibre pcalibre1 calibre6"/>Monitoring and Evaluation</h1>
			<p class="calibre3">Once there is something to test, even a trial version, be on top of the processes for evaluating the results. Unsurprisingly, the methods discussed (surveys, interviews, feedback) can be re-used to see how beta customers or early adopters perform.</p>
			<p class="callout-heading">Another Pet Peeve</p>
			<p class="callout">The word <em class="italic">beta</em> sends the wrong message to a non-technical customer that the product is not ready for them. Consider other terms such as limited release or, my favorite, <em class="italic">access for early adopters</em>. This label might put them in a better frame of mind to handle issues and provide feedback.</p>
			<p class="calibre3">Since <strong class="bold">retrieval-augmented generation</strong> (<strong class="bold">RAG</strong>) is<a id="_idIndexMarker697" class="pcalibre pcalibre1 calibre6"/> fundamental to most enterprise solutions for sales and support, metrics around the quality of that approach are essential. A combination of data science, product managers, and the design team is required to improve results. A heuristic approach using design experts or trained individuals can evaluate RAG or other LLM outputs that provide results to customers.</p>
			<p class="calibre3">This means a suite of additional methods are available to choose from, but honestly, all of these methods should be applied:</p>
			<ul class="calibre7">
				<li class="calibre8">Evaluate<a id="_idIndexMarker698" class="pcalibre pcalibre1 calibre6"/> using <strong class="bold">retrieval-augmented generation </strong><strong class="bold">assessment</strong> (<strong class="bold">RAGAs</strong>)</li>
				<li class="calibre8">Monitor with usability measures</li>
				<li class="calibre8">Refine with a heuristic evaluation</li>
			</ul>
			<p class="calibre3">Let’s jump right into metrics to benchmark LLM solutions.</p>
			<h1 id="_idParaDest-211" class="calibre5"><a id="_idTextAnchor218" class="pcalibre pcalibre1 calibre6"/>Evaluate using RAGAs</h1>
			<p class="calibre3">This book is about design, so product people are not expected to implement the <strong class="bold">RAGAs</strong>. RAGAs is <a id="_idIndexMarker699" class="pcalibre pcalibre1 calibre6"/>a framework for evaluating the RAG pipeline. <em class="italic">Any approach that takes test data, is actually used, and can measure quality reliably is fine with me</em>. RAGAs is popular with the AI community, so it is worth covering. Call on product experts to evaluate results to validate findings. The goal is to understand the metrics and make decisions to deliver model improvements.</p>
			<h2 id="_idParaDest-212" class="calibre9"><a id="_idTextAnchor219" class="pcalibre pcalibre1 calibre6"/>The RAGAs process</h2>
			<p class="calibre3">All good stories start at the beginning. An LLM product needs to be evaluated. Don’t wait for customers to complain; it comes too late, and customers disappear quickly if they are frustrated with quality. This is similar to phone support; when a customer has a horrible interaction, they tend to tell 20 people how bad it was, and this lack of goodwill hurts the company’s reputation. If backend systems or recommenders miss their mark, it will leave a foul taste in customers’ mouths. By monitoring how the system is performing, there is a better chance for improvement. As Peter Drucker was quoted, “<em class="italic">You can’t improve what you </em><em class="italic">don’t measure.</em>”</p>
			<p class="calibre3">A collection of metrics can be deployed. Let’s lay out the steps for RAGAs:</p>
			<ol class="calibre12">
				<li class="calibre8">Synthetically<a id="_idIndexMarker700" class="pcalibre pcalibre1 calibre6"/> create a diverse dataset for testing.</li>
				<li class="calibre8">Use these metrics to measure solution quality.</li>
				<li class="calibre8">Care for the application. Use smaller and cheaper models to generate actionable insights.</li>
				<li class="calibre8">Feed these insights back to improve the overall experience.</li>
			</ol>
			<p class="calibre3">This chapter will summarize <a id="_idIndexMarker701" class="pcalibre pcalibre1 calibre6"/>RAGAs <strong class="bold">metric-driven development</strong> (<strong class="bold">MDD</strong>), a fancy name for what we have called care and feeding. Use data to drive actionable insights; too many failed projects occur because of this simple oversight.</p>
			<p class="calibre3">RAGAs identify problems from the user’s perspective; this will be covered in this chapter. The associated Discord channels for the always-to-arise technical issues are active. There <a id="_idIndexMarker702" class="pcalibre pcalibre1 calibre6"/>is an online collection of RAGA-related videos and tutorials. If needed, here is the in-depth documentation on RAGAs.</p>
			<p class="calibre3">Documentation: <a href="https://docs.ragas.io/en/latest/concepts/index.html" class="pcalibre pcalibre1 calibre6">Introduction to RAGAs</a> (<a href="https://docs.ragas.io/en/latest/concepts/index.html" class="pcalibre pcalibre1 calibre6">https://docs.ragas.io/en/latest/concepts/index.html</a>)</p>
			<p class="callout-heading">Testing data (for the developers in the room)</p>
			<p class="callout">The more technically inclined readers can use the GitHub FAQ files. Install RAGAs with Python and get started. This is outside the book’s scope. The metrics covered in this chapter apply to a variety of similar approaches. Learn these standard metrics to evaluate LLM quality. Building RAGAs is not required to understand the metrics.</p>
			<p class="callout">Tutorial: <a href="https://docs.ragas.io/en/stable/getstarted/install.html" class="pcalibre pcalibre1 calibre6">Installing RAGAs</a> (<a href="https://docs.ragas.io/en/stable/getstarted/install.html" class="pcalibre pcalibre1 calibre6">https://docs.ragas.io/en/stable/getstarted/install.html</a>)</p>
			<p class="calibre3"><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 8</em></a><em class="italic">, Fine-Tuning</em>, covered synthesizing data. Because the models need to be monitored, synthesizing data needs to go to the next level to expand the variety.</p>
			<h2 id="_idParaDest-213" class="calibre9"><a id="_idTextAnchor220" class="pcalibre pcalibre1 calibre6"/>Synthesizing data</h2>
			<p class="calibre3">Tools<a id="_idIndexMarker703" class="pcalibre pcalibre1 calibre6"/> can create a variety of test data.  The challenge with using the same model to generate samples is that test data from fine-tuned or prompt examples can be too close to validation<a id="_idIndexMarker704" class="pcalibre pcalibre1 calibre6"/> examples. This was found in the experiment from <a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 8</em></a><em class="italic">, Fine Tuning</em>. Since LLMs like to predict the next word, output can be similar from one generation to the next. Samples won’t be as varied as the customer’s phrasing. Focusing on writing characteristics such as reasoning, conditioning, and multi-context can give a more comprehensive range of outputs and, thus, more robust tests. These advanced instructions get the LLM to vary output more broadly:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Reasoning</strong>: Write questions that require reasoning to provide an answer:<p class="calibre3">How does photosynthesis work?</p><p class="calibre3">Rewritten: What <strong class="bold">consequences</strong> can occur</p><p class="calibre3">when you <strong class="bold">disrupt the balance</strong></p><p class="calibre3">of photosynthesis in an <strong class="bold">ecosystem</strong>?</p></li>
				<li class="calibre8"><strong class="bold">Conditioning</strong>: Include conditional elements that add complexity:<p class="calibre3">What strategies can improve sales performance?</p><p class="calibre3">Rewritten: How do sales strategies differ based</p><p class="calibre3">on <strong class="bold">factors such as target market demographics,</strong></p><p class="calibre3"><strong class="bold">product complexity, and competitive landscape?</strong></p></li>
				<li class="calibre8"><strong class="bold">Multi-context</strong>: Request diverse<a id="_idIndexMarker705" class="pcalibre pcalibre1 calibre6"/> information to form an answer:</li>
			</ul>
			<p class="calibre3">How does predictive maintenance</p>
			<p class="calibre3">benefit manufacturing operations?</p>
			<p class="calibre3">Rewritten: How does <strong class="bold">data analysis, machine</strong></p>
			<p class="calibre3"><strong class="bold">learning and teamwork</strong> improve</p>
			<p class="calibre3">predictive maintenance in manufacturing?</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Conversational</strong>: Convert portions of questions into the back-and-forth expected in a chat question-and-answer<a id="_idIndexMarker706" class="pcalibre pcalibre1 calibre6"/> solution:</li>
			</ul>
			<p class="calibre3">Hi, I need help resetting my password.</p>
			<p class="calibre3">Sure, I can help with that.</p>
			<p class="calibre3">Have you tried the 'Forgot Password'</p>
			<p class="calibre3">link on the sign-in page?</p>
			<p class="calibre3">Yes, but I didn't get the reset email.</p>
			<p class="calibre3">Check your spam folder. Sometimes</p>
			<p class="calibre3">the email ends up there.</p>
			<p class="calibre3">This is done because humans are diverse, random, sometimes off-topic, humorous, lack a sense of humor, make typos, can ramble, write in multiple languages, be terse, or be verbose. It would be best to have diversity in any dataset. Look for this and demand it in the enterprise data. Keep these <a id="_idIndexMarker707" class="pcalibre pcalibre1 calibre6"/>synthesizing techniques available to expand the breadth of test cases when gathering realistic examples falls short. For now, focus on the numbers. What metrics can measure and evaluate the state of a solution?</p>
			<h2 id="_idParaDest-214" class="calibre9"><a id="_idTextAnchor221" class="pcalibre pcalibre1 calibre6"/>Evaluation metrics</h2>
			<p class="calibre3">The center of <a id="_idIndexMarker708" class="pcalibre pcalibre1 calibre6"/>all of this is the <a id="_idIndexMarker709" class="pcalibre pcalibre1 calibre6"/>metrics. There are six to cover. The first four are around the model’s perspective, and the last two<a id="_idIndexMarker710" class="pcalibre pcalibre1 calibre6"/> have a <strong class="bold">user experience </strong>(<strong class="bold">UX</strong>) feel:</p>
			<ul class="calibre7">
				<li class="calibre8">Faithfulness</li>
				<li class="calibre8">Answer relevancy</li>
				<li class="calibre8">Context precision</li>
				<li class="calibre8">Context recall</li>
				<li class="calibre8">Context entity recall</li>
				<li class="calibre8">Summarization score</li>
			</ul>
			<p class="calibre3">RAGA lays out the metrics in <em class="italic">Figure 10</em><em class="italic">.1</em>. This chart is also in the OpenAI demo (at the 20-minute mark), which will be covered next. Each concept requires an in-depth explanation.</p>
			<div><div><img src="img/B21964_10_01.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 10.1 – How to think about evaluating an LLM</p>
			<p class="calibre3">These concepts are worth internalizing to communicate clearly with developers and data scientists. There is a lot to unpack here with scoring, and it will be trickier still to translate scores into actionable tasks. This could have been a very technical chapter. To build a RAGAs testbed, do it independently. The value we focus on is understanding the metrics and how they apply. Even without RAGAs, the concept of model metrics applies to many solutions. The documentation examples are used to facilitate<a id="_idIndexMarker711" class="pcalibre pcalibre1 calibre6"/> communication so that you can refer back to it or as updates become available:</p>
			<p class="calibre3">Article: <a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html" class="pcalibre pcalibre1 calibre6">Evaluating the performance of RAG solutions</a> (<a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html" class="pcalibre pcalibre1 calibre6">https://docs.ragas.io/en/latest/concepts/metrics/index.html</a>)</p>
			<p class="callout-heading">Math is scary</p>
			<p class="callout">Do not get caught up in the math. Focus on the value of the metric and get comfortable with the terms. Humans will not manually calculate these values. They are all done by the software. <em class="italic">If math is scary to you, ignore it. Learn </em><em class="italic">the terms</em>.</p>
			<h3 class="calibre11">Faithfulness (for generation)</h3>
			<p class="calibre3">This is a<a id="_idIndexMarker712" class="pcalibre pcalibre1 calibre6"/> measure of the generated answer’s factual <a id="_idIndexMarker713" class="pcalibre pcalibre1 calibre6"/>accuracy. Can the answer be fact-checked (no fake news)?</p>
			<p class="calibre3"><img src="img/5.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtable columnwidth=&quot;auto&quot; columnalign=&quot;center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mtable columnwidth=&quot;auto&quot; columnalign=&quot;center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre23"/></p>
			<p class="calibre3">This means not hallucinating to give a faithful answer. If asked for someone’s birthday, it better be right. The more individual elements that can be fact-checked, the larger the numerator and denominator. Consider the following example:</p>
			<pre class="source-code-right">When can I visit the Melrose store?
Our store on Melrose is open
7 days a week from 11 am to 9 pm.</pre>			<p class="calibre3">Here is the calculation:</p>
			<ul class="calibre7">
				<li class="calibre8">Break down the answer into individual statements and determine whether it can be inferred from the original context (take our word for this made-up store):<ul class="calibre19"><li class="calibre8">The store is on Melrose (True)</li><li class="calibre8">It is open 7 days a week (True)</li><li class="calibre8">It is open from 11 am to 9 pm (True)</li></ul></li>
				<li class="calibre8">Calculate faithfulness:<ul class="calibre19"><li class="calibre8"><img src="img/6.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;F&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1.0&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre24"/></li></ul></li>
			</ul>
			<p class="calibre3">Let’s reuse the same example but with a slight change:</p>
			<pre class="source-code-right">When can I visit the Melrose store?
Our store on Melvin Place is
open 7 days a week from 11 am to 9 pm.</pre>			<p class="calibre3">Here is a<a id="_idIndexMarker714" class="pcalibre pcalibre1 calibre6"/> calculation for <a id="_idIndexMarker715" class="pcalibre pcalibre1 calibre6"/>an example with errors:</p>
			<ul class="calibre7">
				<li class="calibre8">Break down the answer again:<ul class="calibre19"><li class="calibre8">The store is on Melvin Place (False)</li><li class="calibre8">It is open 7 days a week (True)</li><li class="calibre8">It is open from 11 am to 9 pm (True)</li></ul></li>
				<li class="calibre8">Calculate faithfulness:<ul class="calibre19"><li class="calibre8"><img src="img/7.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:mi&gt;F&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.67&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre25"/></li></ul></li>
			</ul>
			<p class="calibre3">This judges the correctness of the original context. Knowing the right store is more relevant than the hours (store hours might overlap between a correct and wrong answer, so even if they are wrong, they might be right enough for the customer), but an address would be a total failure. Models are not smart. They don’t know the value of one of these elements (location) versus another (hours or days). If the faithfulness of an answer is low, it is hallucinating, and the answer should be rejected.</p>
			<p class="calibre3">The trick is that although datasets with questions, context, and responses are publicly available, they lack enterprise content. A testing matrix based on answers with ground truth is necessary to monitor and judge changes.</p>
			<p class="calibre3">There are parameters one can manipulate to improve this metric and the other answer-related factors (relevancy, similarity, and correctness). Data scientists can play with these depending on the tools used. The model can also impact how much effort it will take to get to a better experience by reducing hallucinations and improving consistency. Judge out-of-the-box performance by monitoring LLM leaderboards. At the time of this writing, the OpenAI models are at or near the top of the Hughes leaderboard for evaluating models for hallucinations when summarizing a document. This is one example of a leaderboard. Remember, different models can be used for different components, so <a id="_idIndexMarker716" class="pcalibre pcalibre1 calibre6"/>don’t <a id="_idIndexMarker717" class="pcalibre pcalibre1 calibre6"/>focus only on ChatGPT when looking at the <a id="_idIndexMarker718" class="pcalibre pcalibre1 calibre6"/>boards.</p>
			<p class="calibre3">Article: <a href="https://huggingface.co/spaces/vectara/leaderboard" class="pcalibre pcalibre1 calibre6">Hughes Hallucination Evaluation Model (HHEM) Leaderboard</a> (<a href="https://huggingface.co/spaces/vectara/leaderboard" class="pcalibre pcalibre1 calibre6">https://huggingface.co/spaces/vectara/leaderboard</a>)</p>
			<p class="calibre3">These leaderboards are based on generic metrics against foundational models. Enterprise data-based LLM solutions will require their own analysis.</p>
			<h3 class="calibre11">Answer Relevancy (for generation)</h3>
			<p class="calibre3">How relevant is the<a id="_idIndexMarker719" class="pcalibre pcalibre1 calibre6"/> answer to the question? If parts of the <a id="_idIndexMarker720" class="pcalibre pcalibre1 calibre6"/>answer are missing or include redundant results, the score will be lower. The higher the score, the better; the best scores should approach 1, typically between 0 and 1, but because of the math, they can range as low as -1.</p>
			<p class="calibre3">The equation is explained in the RAGAs documentation as follows:</p>
			<p class="calibre3"><img src="img/8.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;o&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;s&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre26"/></p>
			<p class="calibre3">Where:</p>
			<ul class="calibre7">
				<li class="calibre8"><img src="img/9.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre27"/> is the embedding of the generated question 𝑖</li>
				<li class="calibre8"><img src="img/10.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot;&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;E&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;" class="calibre28"/> is the embedding of the original question</li>
				<li class="calibre8">𝑁 is the number of generated questions, which is 3 by default</li>
			</ul>
			<p class="calibre3">The math is complex because it is based on Embedded vector values, the multidimensional space discussed in <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content is King</em>. This metric is based<a id="_idIndexMarker721" class="pcalibre pcalibre1 calibre6"/> on the question, the content, and the answer. However, it is calculated based on a cosine similarity from the original question to a collection of generated questions. The LLM reverse-engineers these based on the answer. It does not consider factuality and penalizes cases where the answer lacks completeness.</p>
			<p class="calibre3">Because they use cosine similarity, the values can range from -1 to 1, while typically, they will be from 0 to 1. Getting a feel for the data for models is challenging. ChatGPT works within a much smaller range of values, as <a id="_idIndexMarker722" class="pcalibre pcalibre1 calibre6"/>discussed in the OpenAI community.</p>
			<p class="calibre3">Discussion: <a href="https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3" class="pcalibre pcalibre1 calibre6">Text Embedding Issues</a> (<a href="https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3" class="pcalibre pcalibre1 calibre6">https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3</a>)</p>
			<p class="calibre3">I suspect some of this thread is too technical. Even I tend to glaze over because we do not need to calculate these to learn how to value them. It just points to the magic that goes on behind the scenes. Understanding results can be challenging. Get comfortable with the data and metrics and work out improvements.</p>
			<p class="callout-heading">Pick one, any one</p>
			<p class="callout">Another approach is a simple comparison of the number of statements made in the output and the relevance of each statement based on the input. This approach identifies low scores as problematic:</p>
			<p class="callout"><img src="img/11.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre29"/></p>
			<p class="callout">I share this to stir the pot of complexity. This popular alternative approach comes from DeepEval, another LLM evaluation framework. They have all the same metrics (and more, with 14 at the last check), but as this shows, the calculation can vary. There are a dozen popular evaluation tools. I just picked the popular RAGAS to help product people understand the key metrics.</p>
			<p class="callout">Documentation: <a href="https://docs.confident-ai.com/docs/metrics-introduction" class="pcalibre pcalibre1 calibre6">DeepEval Metrics</a> (<a href="https://docs.confident-ai.com/docs/metrics-introduction" class="pcalibre pcalibre1 calibre6">https://docs.confident-ai.com/docs/metrics-introduction</a>)</p>
			<p class="calibre3">This metric is different from answer correctness. It does not consider the facts but the need for more completeness or the inclusion of redundant details. The LLM generates questions for the answer multiple times (<em class="italic">N</em>). Then, the average value from the collection of cosine similarity scores for each question compared to the original question is calculated. A great answer<a id="_idIndexMarker723" class="pcalibre pcalibre1 calibre6"/> makes it likely the original answer can be reconstructed:</p>
			<pre class="source-code">
Question: Where is England, and where is its capital?
Low relevance answer: England is in Europe.
High relevance answer: England is in Northern Europe, and its capital is London.</pre>			<p class="calibre3">The LLM should generate questions from answers like this:</p>
			<pre class="source-code">
Where is England in relation to the rest of Europe?
In what part of Europe is England?
What country is London in, and in what part of the world?</pre>			<p class="calibre3">ChatGPT 4o was given a simple prompt to generate these questions and returned junk:</p>
			<pre class="source-code">
Where is Northern Europe, and where is its capital?
Where is London, and where is its capital?
Where is England, and where is Northern Europe?</pre>			<p class="calibre3">Work with the <a id="_idIndexMarker724" class="pcalibre pcalibre1 calibre6"/>engineers, gather data that makes sense<a id="_idIndexMarker725" class="pcalibre pcalibre1 calibre6"/>, and learn. It can be frustrating. Solutions such as fine-tuning, a better knowledge base, and feedback loops helps relevance. However, there are more technical approaches as well. To go deeper, ask your intern, ChatGPT:</p>
			<pre class="source-code">
How can I improve answer relevance in my LLM using RAGAs</pre>			<h3 class="calibre11">Context precision (for retrieval)</h3>
			<p class="calibre3">How relevant is <a id="_idIndexMarker726" class="pcalibre pcalibre1 calibre6"/>the context to the question? Let’s<a id="_idIndexMarker727" class="pcalibre pcalibre1 calibre6"/> see:</p>
			<p class="calibre3"><img src="img/12.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;@&lt;/mo&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/msubsup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;@&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mtable columnwidth=&quot;auto&quot; columnalign=&quot;center&quot; rowspacing=&quot;1.0000ex&quot; rowalign=&quot;baseline baseline&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre30"/></p>
			<p class="calibre3"><img src="img/13.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;@&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;@&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;@&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;@&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre31"/></p>
			<p class="calibre3">Here, <em class="italic">K</em> is the total number of chunks in context, and <img src="img/14.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mfenced open=&quot;{&quot; close=&quot;}&quot;&gt;&lt;mn&gt;0,1&lt;/mn&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre32"/> is the relevance indicator at rank <em class="italic">k</em>. Recall the two relevant chunks in the preceding “England” example.</p>
			<p class="calibre3">Are all of the ground truth items in the context and ranked high? The more relevant, the higher its rank. If chunks contain relevant details to support the ground truth, sum the precision for each chunk to arrive at the context precision. Using the two England example chunks from the previous example, calculate the precision for each chunk as it helps to answer our question about the capital of England and its location. There are no false positives in the context, such as telling me England is in France, so it is just based on the true positive of London being the capital in the second chunk, but it needs to provide the details about where England is located:</p>
			<p class="calibre3"><img src="img/15.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;@&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre33"/></p>
			<p class="calibre3"><img src="img/16.png" alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;P&lt;/mml:mi&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mo&gt;@&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:math&gt;" class="calibre34"/></p>
			<p class="calibre3">Sum up the precision scores and arrive at the mean:</p>
			<p class="calibre3"><img src="img/17.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre35"/></p>
			<p class="calibre3">The <a id="_idIndexMarker728" class="pcalibre pcalibre1 calibre6"/>documentation could be more precise, but I did not find a reference that would make it more transparent. DeepEval, mentioned earlier, has some more context if you need their explanation. It is similar in value but slightly different in delivery. They don’t define the scope of a true positive, so it needs to be clarified how they arrive at their results when looking at complex statements with multiple elements. Defining a positive can be challenging, as one statement might contain many positives. Also, they don’t account for the relevance indicator in the calculation. The actual calculation is more accurate than the documentation. So, take it for what it is suggesting. The correct answers <a id="_idIndexMarker729" class="pcalibre pcalibre1 calibre6"/>in the proper context are needed to answer a question. The higher those answers are ranked, the more likely a good result will be obtained. The model can be precise but needs to gather all contexts.</p>
			<h3 class="calibre11">Context recall (for retriever)</h3>
			<p class="calibre3">Can the retriever <a id="_idIndexMarker730" class="pcalibre pcalibre1 calibre6"/>retrieve <a id="_idIndexMarker731" class="pcalibre pcalibre1 calibre6"/>all relevant context? The context is the material used as the source of information. The value is based on the ground truth (<em class="italic">GT</em>) and the retrieved context, with values only from 0 to 1. Higher scores are better:</p>
			<p class="calibre3"><img src="img/18.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre36"/></p>
			<p class="calibre3">Finding each statement in the retrieved context will give a 1.0 score for context recall. Let’s use our previous answer. These are the facts on which to base this. They are the ground truth:</p>
			<pre class="source-code">
England is in Northern Europe, and its capital is London.</pre>			<p class="calibre3">Say the recalled context was the following two statements:</p>
			<pre class="source-code">
England is located in the southern part of the island of Great Britain, which is part of the United Kingdom. Known for its rich history, it has influenced global culture, politics, and economics.
England's capital, London, is a leading global city known for its cultural and economic significance.</pre>			<p class="calibre3">Then, both of the following statements:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Statement 1</strong>: England is in Northern Europe</li>
				<li class="calibre8"><strong class="bold">Statement 2</strong>: Its capital is London</li>
			</ul>
			<p class="calibre3">Can be evaluated against the context:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Statement 1</strong>: False (Northern Europe is not in the context)</li>
				<li class="calibre8"><strong class="bold">Statement 2</strong>: True (London is defined as England’s capital)</li>
			</ul>
			<p class="calibre3">This results in the context recall calculation:</p>
			<p class="calibre3"><img src="img/19.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre37"/></p>
			<p class="calibre3">This is important<a id="_idIndexMarker732" class="pcalibre pcalibre1 calibre6"/> to understand because it might <a id="_idIndexMarker733" class="pcalibre pcalibre1 calibre6"/>have the correct information, but if the solution doesn’t return the proper context, it might not provide all the expected parts of the answer. Each answer is weighted equally. It could give more weight to meaningful and relevant items if it were smarter. It has no idea.</p>
			<p class="calibre3">A few more metrics are outside the four in the chart that started this section. One concerns entities.</p>
			<h3 class="calibre11">Context entity recall</h3>
			<p class="calibre3"><strong class="bold">Entity recall</strong> is <a id="_idIndexMarker734" class="pcalibre pcalibre1 calibre6"/>useful in solutions such as a <a id="_idIndexMarker735" class="pcalibre pcalibre1 calibre6"/>help desk, where knowing the correct entities (a specific relevant piece of information, a value, or a label) is essential. Entities are necessary for filling out vacation requests (type of vacation, date, hours), filing an expense report (amount, attendees, date, category, purpose, type of payment), interacting with sales data (date, amount, contacts, address, product, quantity), or any form with many entities. This calculates the fraction of the union of similar entities from the context entities (<em class="italic">CE</em>) and the ground truth (<em class="italic">GE</em>) entities over the number of ground truth entities. V<a id="_idIndexMarker736" class="pcalibre pcalibre1 calibre6"/>alues range from zero to one; high values indicate better recall:</p>
			<p class="calibre3"><img src="img/20.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;∩&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre38"/></p>
			<p class="calibre3">This example shows the entities in the ground truth (<em class="italic">GE</em>):</p>
			<ul class="calibre7">
				<li class="calibre8">England, Northern Europe, London</li>
			</ul>
			<p class="calibre3">Then, find the entities in the two <a id="_idIndexMarker737" class="pcalibre pcalibre1 calibre6"/>context examples (<em class="italic">CE</em>):</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Context Example 1</strong>: England, Great Britain, United Kingdom</li>
				<li class="calibre8"><strong class="bold">Content Example 2</strong>: England, London</li>
			</ul>
			<p class="calibre3">Calculate the scores based on the union of the entity matches:</p>
			<p class="calibre3"><img src="img/21.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;∩&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.33&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre39"/></p>
			<p class="calibre3"><img src="img/22.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;∩&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.67&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre40"/></p>
			<p class="calibre3">From this, the conclusion is that the recall on Entity 2 is better for entity matching. Too many entities that don’t overlap are noise in this calculation.</p>
			<p class="callout-heading">Results are not deterministic; try, try, and try again</p>
			<p class="callout">There are some issues with calculations not being the same. This is just an example; every model’s values will be different. The first-time results might look like this:</p>
			<p class="callout"><strong class="source-inline1">{'faithfulness': 0.5624, 'answer_relevancy': 0.7752, '</strong><strong class="source-inline1">answer_correctness': 0.5484}</strong></p>
			<p class="callout">Rerunning the analysis then yields different results:</p>
			<p class="callout"><strong class="source-inline1">{'faithfulness': 0.6843, 'answer_relevancy': 0.7193, '</strong><strong class="source-inline1">answer_correctness': 0.5246}</strong></p>
			<p class="callout">Don’t freak out. Why would they differ? The same models and data should give the same results. Reproducibility is not there. They suggest repeating runs three times and averaging results. This is the growing pain with metric quality. It’s not very deterministic, like the models themselves. It is a work in progress, but it should be suitable enough.</p>
			<p class="calibre3">Online forums have <a id="_idIndexMarker738" class="pcalibre pcalibre1 calibre6"/>grumblings about the quality of the metrics. Other vendors provide new and improved metrics, so be on the lookout. This isn’t a mature space. It draws on robust machine learning models, but these scoring<a id="_idIndexMarker739" class="pcalibre pcalibre1 calibre6"/> methods<a id="_idIndexMarker740" class="pcalibre pcalibre1 calibre6"/> are imperfect.</p>
			<p class="calibre3">Article: <a href="https://github.com/explodinggradients/ragas/issues/660" class="pcalibre pcalibre1 calibre6">Possible bug in evaluation function in RAGAs</a> (<a href="https://github.com/explodinggradients/ragas/issues/660" class="pcalibre pcalibre1 calibre6">https://github.com/explodinggradients/ragas/issues/660</a>)</p>
			<p class="calibre3">All of this is about the metrics from your experience. Just benchmark against the model data and use tools and techniques to improve. Comparing scores to other environments won’t be meaningful. Let’s finish with the UX metrics for this suite.</p>
			<h2 id="_idParaDest-215" class="calibre9"><a id="_idTextAnchor222" class="pcalibre pcalibre1 calibre6"/>User experience metrics</h2>
			<p class="calibre3">Although the previous metrics <a id="_idIndexMarker741" class="pcalibre pcalibre1 calibre6"/>should be monitored and valuable to the whole team, it is good to see the following are considered UX metrics. Let’s dive right in.</p>
			<h3 class="calibre11">Answer semantic similarity</h3>
			<p class="calibre3">This is based on the <a id="_idIndexMarker742" class="pcalibre pcalibre1 calibre6"/>relationship between<a id="_idIndexMarker743" class="pcalibre pcalibre1 calibre6"/> the ground truth and the similarity of the answer. It is based on the cosine similarity of the vectorized values of the statements. Look for highly correlated values. The range is from 0 to 1, and the higher the score, the better the matching between the generated answer and the ground truth:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Ground truth</strong>: The iPhone 15’s battery life is about 11 hours during typical web browsing, video watching, and social website use</li>
				<li class="calibre8"><strong class="bold">High similarity answer</strong>: The iPhone’s all-day battery life can handle the robust media usage of a very active phone user</li>
				<li class="calibre8"><strong class="bold">Low similarity answer</strong>: Newer phones have a longer battery life than the last generation</li>
			</ul>
			<p class="calibre3">I can’t explain why the<a id="_idIndexMarker744" class="pcalibre pcalibre1 calibre6"/> RAGAs document leaves out the scoring metric, but we can live without it since this is not calculated by hand.</p>
			<p class="calibre3">I see how this is likely <a id="_idIndexMarker745" class="pcalibre pcalibre1 calibre6"/>based on the work of Risch, Möller, Gutsche, and Peitsch (2021), so to explore this article and read Isabelle Nguyen’s blog:</p>
			<p class="calibre3">Article: <a href="https://arxiv.org/pdf/2108.06130" class="pcalibre pcalibre1 calibre6">Semantic Answer Similarity for Evaluating Question Answering Models</a> by Risch et al. (<a href="https://arxiv.org/pdf/2108.06130" class="pcalibre pcalibre1 calibre6">https://arxiv.org/pdf/2108.06130</a>)</p>
			<p class="calibre3">Article: <a href="https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa" class="pcalibre pcalibre1 calibre6">Semantic Answer Similarity: The Smarter Metric to Score Question Answering Predictions</a> by Isabelle Nguyen (<a href="https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa" class="pcalibre pcalibre1 calibre6">https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa</a>)</p>
			<p class="calibre3">Risch et al. provide good examples of how it evaluates answer quality. Use this to adjust prompts to tighten or loosen the LLM’s response. It also introduces the concept of the F1 score, which leads us to answer correctness.</p>
			<h3 class="calibre11">Answer correctness</h3>
			<p class="calibre3">This builds on the<a id="_idIndexMarker746" class="pcalibre pcalibre1 calibre6"/> similarity<a id="_idIndexMarker747" class="pcalibre pcalibre1 calibre6"/> score for the answer. It looks at the similarity of the generated answer and the ground truth and whether the facts are supported. So, it is important if it is accurate or <a id="_idIndexMarker748" class="pcalibre pcalibre1 calibre6"/>leads us astray<a id="_idIndexMarker749" class="pcalibre pcalibre1 calibre6"/> with <strong class="bold">false positives</strong> (<strong class="bold">FPs</strong>) or <strong class="bold">false </strong><strong class="bold">negatives</strong> (<strong class="bold">FNs</strong>):</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">True positive (TP)</strong>: Facts or statements found in the ground truth and generated answer</li>
				<li class="calibre8"><strong class="bold">FP</strong>: Statements or facts in the generated answer that are not found in the ground truth</li>
				<li class="calibre8"><strong class="bold">FN</strong>: Missing facts or statements found in the ground truth but missing from the generated answer</li>
			</ul>
			<p class="calibre3">I will use the example from the documentation to keep this straightforward:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Ground truth</strong>: Einstein was born in 1879 in Germany</li>
				<li class="calibre8"><strong class="bold">High answer correctness</strong>: In 1879, Einstein was born in Germany</li>
				<li class="calibre8"><strong class="bold">Low answer correctness</strong>: Einstein was born in Spain in 1879</li>
			</ul>
			<p class="calibre3">Then evaluate the low answer correctness (evaluated against “Einstein was born in Spain in 1879”):</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">TP</strong>: Einstein was born in 1879</li>
				<li class="calibre8"><strong class="bold">FP</strong>: Einstein was born in Spain (incorrect statement)</li>
				<li class="calibre8"><strong class="bold">FN</strong>: Einstein was born in Germany (Germany isn’t in the answer)</li>
			</ul>
			<p class="calibre3">This is the F1 score:</p>
			<p class="calibre3"><img src="img/23.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre41"/></p>
			<p class="calibre3">Notice how the <a id="_idIndexMarker750" class="pcalibre pcalibre1 calibre6"/>false values are weighted. If there is no false information, then the F1 score would be the max of 1. The more false information, the more the score trends to zero. If there are no true positives, the score will be zero.</p>
			<h2 id="_idParaDest-216" class="calibre9"><a id="_idTextAnchor223" class="pcalibre pcalibre1 calibre6"/>Other metrics</h2>
			<p class="calibre3">Realize this is <a id="_idIndexMarker751" class="pcalibre pcalibre1 calibre6"/>just a sampling of<a id="_idIndexMarker752" class="pcalibre pcalibre1 calibre6"/> the available metrics; a few RAGAs framework items were skipped, and we mentioned more can be found from the other frameworks. Look for repeatability and reliability in metrics that interpret the quality of the interactions. Rajeep Biswas (2023) covers other metrics in his overview:</p>
			<p class="calibre3">Article: <a href="https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/" class="pcalibre pcalibre1 calibre6">Metrics for evaluating LLMs</a> (<a href="https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/" class="pcalibre pcalibre1 calibre6">https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/</a>)</p>
			<p class="calibre3">I don’t want everyone to get hung up on the math. Appreciating and valuing a metric should be based on trusting it to do what it says. But we have to put a stake in the ground. Apply the metrics and gauge the team’s level of trust in them. The more they are used and iterated, the easier it is to judge the results.</p>
			<p class="calibre3">RAGAs is an <a id="_idIndexMarker753" class="pcalibre pcalibre1 calibre6"/>emerging field, and the metrics will change with it. For a different explanation of RAGAs metrics, try this article <a id="_idIndexMarker754" class="pcalibre pcalibre1 calibre6"/>by Leonie Monigatti (2023):</p>
			<p class="calibre3">Article: <a href="https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a" class="pcalibre pcalibre1 calibre6">Evaluating RAG Applications with RAGAs</a> (<a href="https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a" class="pcalibre pcalibre1 calibre6">https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a</a>)</p>
			<p class="calibre3">Metrics give a high-level view of quality without addressing the necessary detailed changes to which the metric might allude. The biggest specific issue is hallucination errors. Monitoring and addressing these issues are critically important to building trust.</p>
			</div>
	

<div><h2 id="_idParaDest-217" class="calibre9"><a id="_idTextAnchor224" class="pcalibre pcalibre1 calibre6"/>Monitoring and classifying the types of hallucination errors</h2>
			<p class="calibre3">Minimizing hallucinations is a recurring thread in this book. <a href="B21964_03.xhtml#_idTextAnchor058" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 3</em></a>, <em class="italic">Identifying Optimal Use Cases for ChatGPT</em>, covered logging errors from chat logs. It is time to explore more refined ways of classifying these errors. Once errors are classified, help with the model, the data, or the training<a id="_idIndexMarker755" class="pcalibre pcalibre1 calibre6"/> to address the problems. Two classification methods are worth exploring, starting with error types classified by Vectara.</p>
			<h3 class="calibre11">Classifying by error types</h3>
			<p class="calibre3"><strong class="bold">Vectara</strong> is in<a id="_idIndexMarker756" class="pcalibre pcalibre1 calibre6"/> the class of <a id="_idIndexMarker757" class="pcalibre pcalibre1 calibre6"/>RAGAs search tools run as a service. Regardless of the tools available, it is essential to identify and fix hallucinations. The data should show a small percentage, such as one to three percent, but that level of quality requires some work. The Vectara classifications are helpful because they are orthogonal and roll up into their version of a quality score, which they call <a id="_idIndexMarker758" class="pcalibre pcalibre1 calibre6"/>the <strong class="bold">Factual Consistency Score</strong>. I am a sucker for the word <em class="italic">consistency</em> in any metric. This is a way of monitoring ongoing progress and tracking quality, even when humans need help understanding why the values have changed. The more learning and testing, the better changes will improve the results. There is only guidance, no rules.</p>
			<p class="calibre3">I will quote the exact <a id="_idIndexMarker759" class="pcalibre pcalibre1 calibre6"/>examples used as input but then include commentary on the issues with the output:</p>
			<p class="calibre3">Article: <a href="https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/" class="pcalibre pcalibre1 calibre6">Automating Hallucination Detection</a> (<a href="https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/" class="pcalibre pcalibre1 calibre6">https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/</a>)</p>
			<p class="calibre3"><em class="italic">"The first vaccine for Ebola was approved by the FDA in 2019 in the US, five years after the initial outbreak in 2014. To produce the vaccine, scientists had to sequence the DNA of Ebola, then identify possible vaccines, and finally show successful clinical trials. Scientists say a vaccine for COVID-19 is unlikely to be ready this year, although clinical trials have </em><em class="italic">already started."</em></p>
			<p class="calibre3">Output Type 1: Relation error:</p>
			<p class="calibre3"><em class="italic">"The Ebola vaccine was rejected by the FDA </em><em class="italic">in 2019."</em></p>
			<p class="calibre3"><strong class="bold">Analysis</strong>:<em class="italic"> The AI confused the relationship between Ebola and COVID-19. </em>The Ebola vaccine was approved in 2019.</p>
			<p class="calibre3"><strong class="bold">Commentary</strong>: <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content is King,</em> covered the common association error in which Hank Arron’s and Hank Greenberg’s religions were confused. Relationships in conversation, even between humans, are complex. “It,” “they,” “us,” “we,” “there,” “you,” “your,” “them,” and other phrases can be misconnected to the wrong subject, resulting in attribution errors. Don’t allow customers to think Product A does <a id="_idIndexMarker760" class="pcalibre pcalibre1 calibre6"/>something that is only supported by Product B.</p>
			<p class="calibre3">Output Type 2: Entity error:</p>
			<p class="calibre3"><em class="italic">The COVID-19 vaccine was approved by the FDA </em><em class="italic">in 2019.</em></p>
			<p class="calibre3"><strong class="bold">Analysis</strong>:<em class="italic">This error arises from the AI confusing details between Ebola and COVID-19. </em>COVID-19 appeared on the world stage in January 2020 with an announcement from the Center for Disease Control in the US, and the first vaccine appeared in December 2020.</p>
			<p class="calibre3"><strong class="bold">Commentary</strong>: Entity recognition is complex. Understanding the sources is required to identify entities. Designers, writers, and PMs must know their products and build a team of experts on the business. In this case, it is easy; everyone experienced COVID and might realize the timing is wrong. With more technical materials, especially those that cover multiple products, it is easy to match the wrong product to an unrelated bug, specification, or feature. These are entity errors. One can look at editing the source documents or how the RAGAs tools segment or chunk the document. Some documentation could be more straightforward for ingestion by an LLM.</p>
			<p class="calibre3">Output Type 3: Coreference error:</p>
			<p class="calibre3"><em class="italic">"The first vaccine for Ebola was approved by the FDA in 2019. They say a vaccine for COVID-19 is unlikely to be ready </em><em class="italic">this year.”</em></p>
			<p class="calibre3"><strong class="bold">Analysis</strong>:<em class="italic"> The confusion arises with the pronoun “they”; the summary refers to the FDA, but in the original article, “they” relates </em><em class="italic">to scientists.</em></p>
			<p class="calibre3"><strong class="bold">Commentary</strong>: Similar to Type 1, this focuses on misconnected subjects. The context of “they” was correct when referring to scientists, but because the chunk analyzed contained the FDA reference, it got confused. If the source document was clear that “Scientists say the vaccine…” this error would not happen. However, it would be annoying as a human to read articles that never use pronouns or determiners (words that refer to a noun more specifically, such as “the book” or “her show”). Tools should get better at making these relationships, or content will be rewritten. At least recognize the issue and correct it. This repetitive use of words, like if we repeatedly used “Scientists say,” is <a id="_idIndexMarker761" class="pcalibre pcalibre1 calibre6"/>called <strong class="bold">burstiness</strong>. It will touch on this again later in this chapter. It could be that human-readable documentation will have to be distinct from optimized material for RAG. Getting context when<a id="_idIndexMarker762" class="pcalibre pcalibre1 calibre6"/> something is at the top or in a document’s sidebar for a paragraph five pages later is hard.</p>
			<p class="calibre3">Output Type 4: Discourse link error:<em class="italic"> </em></p>
			<p class="calibre3"><em class="italic">“To produce the vaccine, scientists have to show successful human trials, then sequence the DNA of </em><em class="italic">the virus.”</em></p>
			<p class="calibre3"><strong class="bold">Analysis</strong>:<em class="italic">This misplacement stems from an incorrect order of events; the original article states that sequencing the virus’s DNA precedes demonstrating successful </em><em class="italic">human trials.</em></p>
			<p class="calibre3"><strong class="bold">Commentary</strong>: This issue with order can take a lot of work to catch. Did you have to read it twice to see the problem? Steps and order are crucial in technical documentation. If there is a lot of step-by-step documentation, create a collection of test cases focused on order. Their label, “discourse link error,” belies the simplicity of this example. I don’t know why they used that wording. Maybe they wanted a slightly different word than “relation.” This doesn’t appear to be a link issue. More detail was not provided. Expect consolidation in nomenclature and standardization in testing over the next few years. Wynter et al. (2023) probably would call this logical inconsistency.</p>
			<p class="calibre3">Article: <a href="https://www.sciencedirect.com/science/article/pii/S2949719123000213" class="pcalibre pcalibre1 calibre6">An evaluation on large language model outputs: Discourse and memorization</a> by Wynter et al., 2023 (<a href="https://www.sciencedirect.com/science/article/pii/S2949719123000213" class="pcalibre pcalibre1 calibre6">https://www.sciencedirect.com/science/article/pii/S2949719123000213</a>)</p>
			<p class="calibre3">Let me share one more classification method.</p>
			<h3 class="calibre11">Factual and faithful hallucinations</h3>
			<p class="calibre3"><a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 4</em></a><em class="italic">, Scoring Stories</em>, provides a manual classification approach. Take advantage of emerging definitions and classifications when they will help organize or resolve issues. As Deval Shah discusses, it could be helpful to distinguish between factuality and faithfulness hallucinations.</p>
			<p class="calibre3">Article: <a href="https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models" class="pcalibre pcalibre1 calibre6">Taxonomy of Hallucinations in LLMs</a> by Deval Shah (<a href="https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models" class="pcalibre pcalibre1 calibre6">https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models</a>)</p>
			<p class="calibre3">Let’s start with fact-based issues in <em class="italic">Table 10.1</em>. Bold represents the hallucinations.</p>
			<table id="table001-9" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Type</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">User Input</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Model Output</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Explanation</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Factual </strong><strong class="bold">Inconsistency</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Who was the famous Jewish home run hitter in MLB?</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Hank Arron</strong> was the most famous Jewish hitter in MLB.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The LLM’s answer is wrong as Hank Greenberg was the top Jewish home run hitter in MLB.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Factual </strong><strong class="bold">Fabrication</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Tell me about the origins of dragons.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Dragons roamed the northern volcanoes of Old Eros where they were tamed by the </strong><strong class="bold">royal family.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The LLM’s answer is made up. It sounds like it came from Game of Thrones.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.1 – Examples of factual hallucinations</p>
			<p class="calibre3">Next, he breaks down faithfulness, categorizing it into instruction, context, and logical inconsistencies. He has a wonderful section surveying the origins of hallucinations in LLMs. Do visit it for more insight.</p>
			<p class="calibre3">Huang’s article covers how hallucinations come from data sources, training, and inference (as covered), how no single benchmark covers all the issues, and, critically, how to mitigate hallucination.</p>
			<p class="calibre3">Article: <a href="https://arxiv.org/pdf/2311.05232" class="pcalibre pcalibre1 calibre6">A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions</a> by <a id="_idIndexMarker763" class="pcalibre pcalibre1 calibre6"/>Huang et al., 2023 (<a href="https://arxiv.org/pdf/2311.05232" class="pcalibre pcalibre1 calibre6">https://arxiv.org/pdf/2311.05232</a>)</p>
			<p class="calibre3">The section on mitigation makes reading the whole article worth it. These strategies are covered next.</p>
			<h3 class="calibre11">Overall approaches to reducing issues during monitoring</h3>
			<p class="calibre3">Continuous improvement based on monitoring is an absolute necessity with this technology. This is repeated more than any other topic in this book. This care and feeding cycle must be done while customers learn to engage. They have a low tolerance for dumb experiences and will turn away from poor recommendations. It takes work to re-engage a lost customer. <a href="B21964_11.xhtml#_idTextAnchor236" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 11</em></a><em class="italic">, Process</em>, focuses on process improvements. First, look at general methods to solve quality issues.</p>
			<p class="calibre3">Chunking, data manipulation, and writing or editing for LLMs help. More approaches are out in the wild. Even ChatGPT knows about these. Some help augment the data to make the system more robust to user variety. Back translation, text summarization—especially when using a different LLM to supplement the main LLM—and noise injection (including misspellings and grammar errors) help the model understand the imperfectness of human language. Try this prompt:</p>
			<pre class="source-code">
What data augmentation techniques do you suggest to support a RAG pipeline in building enterprise LLMs?</pre>			<p class="calibre3">It should be straightforward to recognize and even respect why variety is essential. Chat GPT 4o will respond with dozens of techniques. People are not only different, but they are also not perfect. Generating examples with imperfections in the dataset and getting the model to overcome these and become more robust is all part of training. Seeing how customers ask questions, make mistakes, and retry when they need help getting the correct answer is excellent. But don’t take the LLM’s word for it. Let’s look at how the humans at OpenAI approached building a solution for an enterprise customer.</p>
			<h2 id="_idParaDest-218" class="calibre9"><a id="_idTextAnchor225" class="pcalibre pcalibre1 calibre6"/>OpenAI’s case study on quality and how to measure it</h2>
			<p class="calibre3">OpenAI has some good developer<a id="_idIndexMarker764" class="pcalibre pcalibre1 calibre6"/> day talks on how to think about evaluation. It is a clear explanation without going over people’s heads. Check it out to learn more<a id="_idIndexMarker765" class="pcalibre pcalibre1 calibre6"/> about scoring. The most significant takeaways are:</p>
			<ul class="calibre7">
				<li class="calibre8">Not every suggestion resulted in improvements (items with a check worked)</li>
				<li class="calibre8">It takes a team to address and refine an enterprise solution</li>
				<li class="calibre8">Solutions can dramatically improve with a methodological iterative approach</li>
			</ul>
			<p class="calibre3"><em class="italic">Figure10.2</em> shows OpenAI’s methods to improve the case study from the video.</p>
			<div><div><img src="img/B21964_10_02.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Different techniques can succeed or fail to improve the experience</p>
			<p class="calibre3">Video: Maximizing LLM performance <a href="https://youtu.be/ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6">techniques</a> (<a href="https://youtu.be/ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6">https://youtu.be/ahnGLM-RC1Y</a>)</p>
			<p class="calibre3">The chart and video show successful (✔) and two failed (🚫) approaches. They worked through various solutions to find good fits. The video doesn’t show the details of the changes they made. It is not explained what changes were made to raise accuracy. However, it is still a good case<a id="_idIndexMarker766" class="pcalibre pcalibre1 calibre6"/> study that shows dramatic improvements in quality. With every effort, a testing process must be implemented to evaluate systematically. There needs to be more than user perception, surveys, and feedback.</p>
			<h2 id="_idParaDest-219" class="calibre9"><a id="_idTextAnchor226" class="pcalibre pcalibre1 calibre6"/>Systematic testing processes</h2>
			<p class="calibre3">To evaluate any<a id="_idIndexMarker767" class="pcalibre pcalibre1 calibre6"/> system, a few things are needed:</p>
			<ul class="calibre7">
				<li class="calibre8">Understand and <a id="_idIndexMarker768" class="pcalibre pcalibre1 calibre6"/>be able to apply real-world usage and understand edge cases</li>
				<li class="calibre8">Be statistically confident in the amount of testing</li>
				<li class="calibre8">Be able to repeat or even automate the test with reliability and consistency</li>
				<li class="calibre8">Be able to make changes systematically to understand the results</li>
			</ul>
			<p class="calibre3">With our human testing, methods are available to test with as few as five customers. Typically, human testers can go into the dozens, with only methods such as surveys intentionally hitting thousands. However, when it comes to LLMs, there are places where automation and scale<a id="_idIndexMarker769" class="pcalibre pcalibre1 calibre6"/> are critical to success. OpenAI suggests in <em class="italic">Table 10.2</em> that larger sample sizes of test cases are are needed to evaluate LLMs to improve quality.</p>
			<table id="table002-9" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Difference </strong><strong class="bold">to detect</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">The sample size needed for </strong><strong class="bold">95% confidence</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">30%</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">~10</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">10%</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">~100</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">3%</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">~1,000</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">1%</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">~10,000</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.2 – Relationship between detection difference percentages to the number of test cases</p>
			<p class="calibre3">The chart in <em class="italic">Table 10.2</em> is from <a id="_idIndexMarker770" class="pcalibre pcalibre1 calibre6"/>OpenAI’s testing strategy documentation.</p>
			<p class="calibre3">Documentation: <a href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically" class="pcalibre pcalibre1 calibre6">OpenAI’s view on testing strategy</a> (<a href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically</a>)</p>
			<p class="calibre3">Confidence increases as the number of test case samples increases. This is done with simple assumptions and straightforward explanations. This should answer any questions about the scale of testing compared to the reliability expected in practice. Don’t expect 10,000 examples of an answer to a single question; think broader. Test cases will be built into a collection over time.</p>
			<p class="calibre3">Although this is easiest to understand for a conversational assistant, some thought has to be applied to other use cases, such as a recommender. Create test data and understand the variety of recommendations. Each focused recommendation will need a collection of test cases that understand the range of data elements. With five data elements in the recommendation, each with 3 to 30 possible values, a range of 30 to 150 combinations can result. Here is a recommendation for smart air filters:</p>
			<pre class="source-code">
It is recommended that the air filters in <strong class="bold1">Bank A and C</strong> be changed by <strong class="bold1">April 3rd.</strong> Install the <strong class="bold1">Aerterra model 2025m</strong> filters <strong class="bold1">this time</strong>; they are <strong class="bold1">ordered</strong> and will arrive by <strong class="bold1">March 20th</strong>. The energy cost <strong class="bold1">increase</strong> <strong class="bold1">due to clogged filters</strong> is an <strong class="bold1">additional</strong> <strong class="bold1">$43.50 (3.2%)</strong> per <strong class="bold1">day.</strong> <strong class="bold1">Air quality is 17% worse</strong> than expected due to <strong class="bold1">smoke from regional forest fires</strong>.</pre>			<p class="calibre3">This recommendation<a id="_idIndexMarker771" class="pcalibre pcalibre1 calibre6"/> for a large commercial building is based on air quality measures, the cost of energy to run the system, filter dirt capacity, filter type, and the filter’s current dirtiness. There are thousands of possible combinations and dozens of recommendations in that case. The system must deal with all these entities, variables, and recommendations (see bolded items). So, thousands of test cases are needed, and results need to be<a id="_idIndexMarker772" class="pcalibre pcalibre1 calibre6"/> validated to ensure that good advice is provided.</p>
			<p class="calibre3">Each area of expertise is also multiplied by the number of languages supported, and the test matrix will grow. These must be automated. Breaking down test cases by subject helps one understand the scale of the problem better. Recall the Alligiance example in <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a><em class="italic">, Gathering Data—Content is King</em>. There were 400 FAQs and many ways of asking each question. Five test cases for each FAQ would be over 2000 test cases.</p>
			<p class="calibre3">Test cases can come from humans or an LLM. An example is how to "expense dinner at Joe’s Eatery for a client dinner for $21.46"; when surveyed, 100 participants were asked how they would say it. They generated 244 different utterances, and 87% were unique. Here are ten examples in <em class="italic">Table 10.3</em> and some analysis of these potential test cases.</p>
			<table id="table003-9" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Test case utterance – </strong><strong class="bold">human-generated</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Test </strong><strong class="bold">case considerations</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">$21.46 dinner </strong><strong class="bold">at Joe’s</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Doesn’t mention intent; what should an LLM do with this info? It might be confused with an appointment. The amount does help.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">12/12/18, </strong><strong class="bold">Dinner, 21.46</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Notice ambivalent date format (MM/DD or DD/MM?), no intent to be clear this is an expense and no currency.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Create an expense for $21.46 at Joe’s Eatery with my co-worker Lisa Jones and </strong><strong class="bold">a client.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Intent, amount, location, and details. A good example.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">dinner - client visit - $21.46 Canadian </strong><strong class="bold">Joe’s eatery</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Points out Canadian dollars.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Dinner - Joe’s Eatery - $</strong><strong class="bold">21.46</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Terse, but contains 3 of the 5 items needed. A good start.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Expense 21 dollars 46 cents Joe’s Eatery for a client visit on October </strong><strong class="bold">3, 2018</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Notice amount format is spoken out.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Hey, I used my corporate Amex for dinner. Didn’t you </strong><strong class="bold">see that?</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Expects the credit card integration to find his expenses and connect it for expensing.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Reimburse me for $21.46 for a client visit with </strong><strong class="bold">George Smith</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Reasonable, doesn’t mention dinner or a date.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Submit $21.46 for </strong><strong class="bold">client visit</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Lacking a lot of information, but reasonable.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Take care of my dinner expense of 21.46 dollars at Joe’s for a client visit with the </strong><strong class="bold">following people</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Conversational and expects to provide more details to follow.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.3 – Potential test cases written by human subjects</p>
			<p class="calibre3">Humans generated<a id="_idIndexMarker773" class="pcalibre pcalibre1 calibre6"/> these, but an LLM model can also generate test cases. Let’s <a id="_idIndexMarker774" class="pcalibre pcalibre1 calibre6"/>compare what happens when prompting ChatGPT 3.5:</p>
			<pre class="source-code">
I will give you 5 pieces of information, generate test cases that may or may not include them all, use a diverse human speech to communicate this to a virtual agent, and start creating an expense in an expense assistant. The most robust answer would look like this, "Expense a meal receipt for $21.46 US dollars for a client meeting today with one person at Joes Eatery". The least robust version would be "start an expense." The information includes the following values for these attributes: Expense Type: Meal, Amount: $21.46 US, Date 8/15/2024, Location: Joe's Eatery, Purpose: Client Lunch. Generate 10 examples to test an LLM that is great at understanding expenses.</pre>			<p class="calibre3">ChatGPT 3.5’s results are shown in <em class="italic">Table 10.4</em>. There are differences.</p>
			<table id="table004-7" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Test case utterance – </strong><strong class="bold">OpenAI-generated</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Testing considerations</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Record a meal expense of $21.46 for a client lunch at Joe’s Eatery on August </strong><strong class="bold">15th, 2024.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements are included, uses the awkward “Record”.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Expense $21.46 for a meal with a client at Joe’s Eatery </strong><strong class="bold">on 8/15/24.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements, used US date format.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Add a meal expense of $21.46 for lunch with a client at Joe’s </strong><strong class="bold">Eatery today.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements, used “today”.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Expense: Meal. Amount: $21.46. Date: August 15th, 2024. Location: Joe’s Eatery. Purpose: </strong><strong class="bold">Client Lunch.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Not conversational. No human ever did it like this.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Register a $21.46 expense for a meal at Joe’s Eatery on August 15, 2024, for a </strong><strong class="bold">client lunch.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements, uses the awkward “Register”.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Document a meal expense of $21.46 for a client lunch at Joe’s Eatery </strong><strong class="bold">on 8/15/24.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Add an expense for a meal at Joe’s Eatery, $21.46, for a client lunch on </strong><strong class="bold">August 15th.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Expense: Meal. Amount: $21.46. Date: 15th August 2024. Location: Joe’s Eatery. Purpose: </strong><strong class="bold">Client Lunch.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Not conversational. No human ever did it like this.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">“Record $21.46 spent on a meal with a client at Joe’s Eatery on August </strong><strong class="bold">15, 2024.”</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All elements, almost identical to the preceding one.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.4 – Potential test cases written by ChatGPT 3.5</p>
			<p class="calibre3">By comparing the results, a <a id="_idIndexMarker775" class="pcalibre pcalibre1 calibre6"/>few conclusions can be made:</p>
			<ul class="calibre7">
				<li class="calibre8">Humans only included some of the information all of the time</li>
				<li class="calibre8">Humans went off-topic and expected to follow up with additional information</li>
				<li class="calibre8">ChatGPT ignored my request to vary what was included</li>
				<li class="calibre8">ChatGPT used words humans didn’t use (such as Record and Register)</li>
				<li class="calibre8">ChatGPT didn’t vary the cases very much, the prompt can be improved</li>
			</ul>
			<p class="calibre3">This is a simple <a id="_idIndexMarker776" class="pcalibre pcalibre1 calibre6"/>example. Humans are unpredictable and <em class="italic">human</em> when communicating, so consider that when allocating resources to create test cases. Time can be spent improving the prompt and forcing ChatGPT to give better and more varied results. Or<a id="_idIndexMarker777" class="pcalibre pcalibre1 calibre6"/> a new model can provide a much more significant jump in quality. <em class="italic">Table 10.5</em> shows results from GPT 4o. This is better with the same prompt and no prompt engineering.</p>
			<table id="table005-4" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">ChatGPT </strong><strong class="bold">4o responses</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Testing considerations</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Detailed:</strong> Please expense a meal receipt for $21.46 US dollars dated 8/15/2024 for a client lunch at Joe’s Eatery.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Robust and complete</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Detailed with variation</strong>: Create an expense report for a meal costing $21.46 USD from Joe’s Eatery on August 15, 2024, for a client lunch.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Varied the date format.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Medium detail</strong>: Log a meal expense of $21.46 for a client meeting on 8/15/2024 at Joe’s Eatery.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Log is a good choice.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Medium detail with different structure</strong>: Expense a client lunch meal for $21.46 from Joe’s Eatery on 15th August 2024.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">“lunch meal” is not something from humans.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Minimal detail</strong>: Start a meal expense for $21.46 at Joe’s Eatery.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">“Start” is a good trigger, but it is generic.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Minimal detail with date</strong>: Record a $21.46 meal expense for a client meeting on 8/15/2024.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">“Record” is still not great.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Basic</strong>: Enter a meal expense for a client lunch costing $21.46.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Good and short.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Basic with location</strong>: Log a client lunch expense for $21.46 at Joe’s Eatery.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">A shorter version of the medium detail item.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Very minimal</strong>: Expense $21.46 for a client meal.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">So short, it need follow-up.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Least robust</strong>: Start an expense.</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Excellent, and common from humans.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.5 – Potential test cases written by ChatGPT 4o</p>
			<p class="calibre3">I have also included their<a id="_idIndexMarker778" class="pcalibre pcalibre1 calibre6"/> labeling, showcasing the types of use cases they provide. Monitor actual user inputs, making judging the value derived from generated data easier. It is hard for one individual to think like <em class="italic">everyone</em>, so don’t try. Use monitoring <a id="_idIndexMarker779" class="pcalibre pcalibre1 calibre6"/>resources and log analysis to get robust training data and test cases.</p>
			<p class="calibre3">The problems get harder when the space gets more complex. Recall our graph from <a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 1</em></a>, <em class="italic">Recognizing the Power of Design in ChatGPT</em>, reshared as <em class="italic">Figure 10</em><em class="italic">.3</em>.</p>
			<div><div><img src="img/B21964_10_03.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 10.3 – The chance of failure increases at each turn</p>
			<p class="calibre3">When an <a id="_idIndexMarker780" class="pcalibre pcalibre1 calibre6"/>LLM is right 60% of the time, failure is 95% likely within six interactions. So, to move that bar up to 97% or greater, a lot of testing and work is needed. Generating the correct set of test cases helps monitor for issues. Because of monitoring, moving to a new model can be evaluated by applying the test cases to the latest model. It’s okay when everything changes with a new model or version, as indicated by the differences between 3.5, 4o, and 4o-mini (it returned results similar to 4o). However, with mini being only 15% of the cost of 3.5, it would make sense to move if this was a real production system once verified against the test cases. There is no guarantee of backward compatibility with LLMs. The scale of testing efforts can easily reach 100’s of thousands of use cases. An example of a testing matrix will make this clear.</p>
			<h2 id="_idParaDest-220" class="calibre9"><a id="_idTextAnchor227" class="pcalibre pcalibre1 calibre6"/>Testing matrix approach</h2>
			<p class="calibre3">Because these projects impact human performance, the traditional <strong class="bold">quality assurance</strong> (<strong class="bold">QA</strong>) team<a id="_idIndexMarker781" class="pcalibre pcalibre1 calibre6"/> must be set up to create an effective test matrix. They can<a id="_idIndexMarker782" class="pcalibre pcalibre1 calibre6"/> develop automation and manage the process. Design owners can handle the examples and make sure the failures are documented.</p>
			<p class="calibre3">With an LLM, <a id="_idIndexMarker783" class="pcalibre pcalibre1 calibre6"/>monitoring will uncover conversations not initially covered by the test cases. It will happen. Just consider how to prioritize improvements for them, like any other issue. Once they are known, consider whether they are worth including in tests.</p>
			<p class="calibre3">One can test each skill in isolation, and then when combining a collection of skills, some issues might arise. A <strong class="bold">skill</strong> is something the model can do. It could be connected to an inventory system, report production numbers, or schedule an appointment. These are skills. One approach is to build the base model only with content from one isolated area, thus allowing us to gauge its effectiveness in isolation. Do this for each area. Then, combine all (or sets of areas) retesting to understand better the overlap or complexities between the data ingested. The QA team will be busy setting up these test harnesses. Product people will be busy understanding the results. This example assumes a single model approach to handle all interactions, but we have provided multiple examples where a multi-modal approach is a better solution. Your choice. The concept of the types of tests still applies. It is valuable to have different kinds of test suites. We can review the types of tests for conversational interactions:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">In-domain</strong>: Questions the skill area should understand and be able to answer. They are the meat of the meal, the main course. Get these right:<pre class="source-code">
What hours can I drop off recycling?
How long will the new battery last?
What is the commission schedule if I sign tomorrow?</pre></li>				<li class="calibre8"><strong class="bold">Out-of-domain</strong>: A collection of questions the skill would not be expected to understand based on lack of access to the necessary business data. Because they are not for <em class="italic">this</em> business. However, they are real questions and sound similar to the customer’s needs, just in the wrong context. The general model might want to answer these. They are distractors to the in-domain questions. Hence, each area of interest will have its collection of out-of-domain items. These examples might sound too similar to an LLM because the structure and words seem familiar, such<a id="_idIndexMarker784" class="pcalibre pcalibre1 calibre6"/> as (stock) orders, download (statements), account (details), transfer (money), check (status), and (order) history:<pre class="source-code">
What is the fine for a late order?
Can I download my AMEX account history?
Can I transfer my car registration to someone else?
Can you check the service history for my car?</pre><p class="calibre3">Recognize that these examples sound close but are unrelated to Alligiance. They sound confusing in the context of this bank. They are close, and a customer might not even know they can’t ask this skill about these problems. Here is a little more about the concepts of out-of-domain understanding.</p><p class="calibre3">Article: <a href="https://www.elevait.de/blog/out-of-domain-detection" class="pcalibre pcalibre1 calibre6">Out of Domain Detection</a> (<a href="https://www.elevait.de/blog/out-of-domain-detection" class="pcalibre pcalibre1 calibre6">https://www.elevait.de/blog/out-of-domain-detection</a>)</p></li>				<li class="calibre8"><strong class="bold">Random</strong>: Garbage and unrelated items that should not result in a helpful response. It could be from a stuck keyboard, poor speech-to-text, someone’s phone in their pocket doing random stuff, or silly, irrelevant questions:<pre class="source-code">
Qfhefkhjeksfdfdfd
Its dnot the goprome we spechtded
Is a dog a cat?
Are pickles part of the Dolphin family?</pre><p class="calibre3">These are the same random questions for each skill.</p></li>				<li class="calibre8"><strong class="bold">Neighbor</strong>: The collection of <a id="_idIndexMarker785" class="pcalibre pcalibre1 calibre6"/>in-domain test cases from all <em class="italic">other</em> skills used to break the area of interest. Does the question from one area overlap and cause a different and wrong response? So, is this an issue when all this expertise is available in one <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>)? It should be addressed if the LLM can’t resolve this disambiguation issue. It might fix it like in this example:</li>
			</ul>
			<p class="calibre3">I need the weekly report</p>
			<pre class="source-code">
Did you mean the sales,
inventory, or staff report?</pre>			<p class="calibre3">The full sales report</p>
			<pre class="source-code">
Here is the sales report for all
regions for the week ending…</pre>			<p class="calibre3">If only one feature contained a weekly report, there would be clarity. However, once multiple<a id="_idIndexMarker786" class="pcalibre pcalibre1 calibre6"/> features include reports, see how some test cases from one solution area might impact others. Think in vector space. All of these questions asking for reports can be very similar. Hence, they are neighbors.</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Language</strong>: Consider test cases for specific languages. One starts by translating existing questions into other languages. Still, as mentioned in <a href="B21964_05_split_000.xhtml#_idTextAnchor108" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 5</em></a>, <em class="italic">Defining the Desired Experience</em>, consider the unique needs of the language, cultures, and nuisances that would necessitate original content for that specific language. Assume at least 10% of test cases for a language will be unique.</li>
			</ul>
			<h3 class="calibre11">Building the Matrix</h3>
			<p class="calibre3">So, what would a test matrix look like for each collection of use cases? A bank might have seven main business areas that require support. Based on the frequency of use, they will scale up tests for the big or complex areas. To test each area with the types <a id="_idIndexMarker787" class="pcalibre pcalibre1 calibre6"/>of tests explained, it might look like <em class="italic">Table 10.6</em>.</p>
			<table id="table006-2" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Product Areas</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">In-domain</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Out-of- domain</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Random</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Neighbors</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Account Statements</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">303</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1002</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,129</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Bank Transfers</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">78</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">423</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,354</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Account Setup</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">150</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">301</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,282</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Deposits </strong><strong class="bold">and Withdrawals</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">201</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,231</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Training</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">50</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">375</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,382</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Trading Stocks </strong><strong class="bold">and Bonds</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">605</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1320</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">827</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Rewards</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">45</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">400</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,387</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Sub-Totals (17,045)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,432</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">4,221</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">2,800</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">8,592</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Ten Language </strong><strong class="bold">Test (*10)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">14,320</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">42,210</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">28,000</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">85,920</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Unique Language </strong><strong class="bold">Tests (10%)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">1,432</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">4,221</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">0</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">0</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">All Test</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">193,148</strong></p>
						</td>
						<td class="no-table-style2"/>
						<td class="no-table-style2"/>
						<td class="no-table-style2"/>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.6 – Matrix for test cases to validate an extensive conversational AI</p>
			<p class="calibre3">Trading Stocks and Bonds is the<a id="_idIndexMarker788" class="pcalibre pcalibre1 calibre6"/> most critical area with the most test cases. The rewards program is the smallest. Notice the subtotaled tests per area. Then, assuming ten supported translations, the number of tests grows. The number of neighbor tests varies because it is the sub-total of all in-domain tests minus the number of in-domain tests for this category. The language tests are assuming cloning tests 1-to-1 per language for a deployment in ten foreign languages. There is an additional row for up to 10% of language tests that might be specific to the locality. As discussed earlier, it is ok to only go this far with testing in some languages regarding how much support to provide per language. This is why our English testing of 17,045 test cases grows to almost 200 K with language support. Here are some tips for scaling language tests:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Only translate currency indirectly</strong>: “I took a 25$ Uber ride today,” translated into Japanese, might change the currency symbol to Yen (¥). But 25¥ is not a meaningful value for a cab ride (about 25 cents in dollars or Euros), so training a system with too many wrong numbers might confuse the model.</li>
				<li class="calibre8"><strong class="bold">Use localized values</strong>: Recall our examples of Uber not being universal. A direct translation of Uber would be Uber in Japanese, but a better example is to use Go, the Japanese taxi-hailing app, for the training example.</li>
				<li class="calibre8"><strong class="bold">Use idiomatic language</strong>: Both test cases and sample data can benefit from how customers communicate. For example, localizing in the USA for dollars and training on bucks and cash but not necessarily using more esoteric slang such as moolah, coin, cheddar, dough, or greenbacks makes sense. Overtraining might cause unexpected consequences. To continue with our Japanese example, train on JPY (the code for the Yen), but the Japanese Yen doesn’t have slang terms. Hence, one-to-one translation of idiomatic language is not expected.</li>
				<li class="calibre8"><strong class="bold">The scale of tests correlates with quality</strong>: For example, test whether 20% is sufficient for an infrequently used language. LLMs work better in some languages because the base model has more training data. Don’t expect magic, especially when it comes<a id="_idIndexMarker789" class="pcalibre pcalibre1 calibre6"/> to enterprise integrations. Translation steps are needed between APIs and responses.</li>
			</ul>
			<p class="calibre3">Don’t let the number of tests sound scary. For many enterprise applications, these numbers are low. I know one team now has about 500,000 tests, just in English. Automation and QA engineers will be busy maintaining and working with the data and product team to grow this set. Don’t make tests to make tests. Use the tests to find gaps in the LLM’s <a id="_idIndexMarker790" class="pcalibre pcalibre1 calibre6"/>understanding. Recall that every change in the model or addition of new data or feature areas will change the quality of the solution. During this part of your LLM journey, <strong class="bold">always be caring</strong> (and feeding) (<strong class="bold">ABC</strong>, if a Glengarry Glen Ross reference is ok. Google it). The way to do this is to improve retrieval.</p>
			<h2 id="_idParaDest-221" class="calibre9"><a id="_idTextAnchor228" class="pcalibre pcalibre1 calibre6"/>Improving retrieval</h2>
			<p class="calibre3">I reviewed a short video for the <a id="_idIndexMarker791" class="pcalibre pcalibre1 calibre6"/>book. The explanations of the concepts taken from the RAGAs documentation are used in this video. They start using the data results to improve the overall solution. Greg Loughnane, PhD, slows down when he gets the good <a id="_idIndexMarker792" class="pcalibre pcalibre1 calibre6"/>stuff after Chris Alexiuk whips through setting up the environment in the first five minutes of the video. Here is my summary of UX-related elements:</p>
			<ul class="calibre7">
				<li class="calibre8">Improve one metric at a time</li>
				<li class="calibre8">Focusing on retriever improvements helps with the generation</li>
				<li class="calibre8">Try a different retriever to get better context (@24 minutes) – expanding the capture of material before and after the matching context.</li>
				<li class="calibre8">See how context relevancy goes down as the size of the context window goes up; chunk size matters (this makes sense since there is more unrelated context in the denominator of the score) (@31 minutes)</li>
				<li class="calibre8">Other tools, such as <a id="_idIndexMarker793" class="pcalibre pcalibre1 calibre6"/>LangChain and LlamaIndex, provide evaluation metrics</li>
				<li class="calibre8">Video: <a href="https://www.youtube.com/watch?v=mEv-2Xnb_Wk" class="pcalibre pcalibre1 calibre6">Tutorial for improving retrieval</a> (<a href="https://www.youtube.com/watch?v=mEv-2Xnb_Wk" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=mEv-2Xnb_Wk</a>)</li>
			</ul>
			<p class="calibre3">It is all about improvements; data scientists can experiment with many options and variables to balance cost, performance, and quality. Learn to understand what they can change and how it impacts quality. Since this work is within the expertise of the data scientists, focus on understanding the quality of the results. There are other metrics of interest. Let’s give a little context on those.</p>
			<h2 id="_idParaDest-222" class="calibre9"><a id="_idTextAnchor229" class="pcalibre pcalibre1 calibre6"/>The wide range of LLM evaluation metrics</h2>
			<p class="calibre3">RAGAs was reviewed <a id="_idIndexMarker794" class="pcalibre pcalibre1 calibre6"/>because it is popular, has a good set of metrics, and is consistent <a id="_idIndexMarker795" class="pcalibre pcalibre1 calibre6"/>with what traditional deterministic models use. But it is not the only approach. We mentioned DeepEval, but there are many more. Some of these approaches have specific metrics that sound appealing. Each vendor can have its approach, so let me expose a few more metrics that can add value to enterprise solutions in <em class="italic">Table 10.7</em>.</p>
			<table id="table007" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Metric</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Purpose</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Applications</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">References</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Rouge</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">To compute the effectiveness of auto-generated summaries</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Books, technical Documentation, articles, marketing material, and so on</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Article: <a href="https://kavita-ganesan.com/rouge2-usage-documentation/" class="pcalibre pcalibre1 calibre6">How to Use Rouge 2.0</a> (<a href="https://kavita-ganesan.com/rouge2-usage-documentation/" class="pcalibre pcalibre1 calibre6">https://kavita-ganesan.com/rouge2-usage-documentation/</a>)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Human Evaluation</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">To ensure user interaction quality</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Conversational interactions</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">See <a href="B21964_03.xhtml#_idTextAnchor058" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 3</em></a>, <em class="italic">Identifying Optimal Use Cases </em><em class="italic">for ChatGPT</em></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Age-specific </strong><strong class="bold">Suitability</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">To match reading or educational levels</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Curriculum tutoring, coaching</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Manual review by experts and content filtering tools</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Toxicity Reduction</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">To maintain style and tone for public-facing and public-sector solutions</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">All generative output including recommendations</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Toxicity and bias detection software, sentiment analysis</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Perplexity</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">How probable a piece of generated text is based on its training</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Content generation</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Article: <a href="https://guides.library.unlv.edu/c.php?g=1361336&amp;p=10054021" class="pcalibre pcalibre1 calibre6">Perplexity and Burstiness</a> (<a href="https://guides.library.unlv.edu/c.php?g=1361336&amp;p=10054021" class="pcalibre pcalibre1 calibre6">https://guides.library.unlv.edu/c.php?g=1361336
&amp;p=10054021</a>)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Burstiness</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The repetition of words or phrases in a document</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Detect whether AI or a human wrote content</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Product: <a href="https://originality.ai/blog/chat-zero" class="pcalibre pcalibre1 calibre6">Originality AI</a> (<a href="https://originality.ai/blog/chat-zero" class="pcalibre pcalibre1 calibre6">https://originality.ai/blog/chat-zero</a>)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.7 – Other evaluation metrics</p>
			<p class="calibre3">Some of <em class="italic">Table 10.7</em> came from Aisera: <a href="https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance" class="pcalibre pcalibre1 calibre6">LLM Evaluation: Metrics and Benchmarking Performance</a> (<a href="https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance" class="pcalibre pcalibre1 calibre6">https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance</a>).</p>
			<p class="calibre3">All metrics have a good<a id="_idIndexMarker796" class="pcalibre pcalibre1 calibre6"/> reason for being collected and analyzed. Frameworks cost <a id="_idIndexMarker797" class="pcalibre pcalibre1 calibre6"/>time and money to maintain, and some data-centric metrics have value because they impact costs. The number of LLM conversations per day or the number of tokens used helps with budgeting. Consider how to get value out of these metrics to aid in understanding customers’ needs. Microsoft also has a few good articles about data-centric metrics. Here are some metrics with usability implications:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Concurrent users</strong>: This can sometimes be correlated with performance (too many simultaneous users can slow some services, impacting service level and customer satisfaction). Recall that there is no such thing as a slow, <em class="italic">good</em> UI. In the case of chat, where human agents might be available for hand-offs, response time will be impacted if human agent availability doesn’t match concurrent user metrics.</li>
				<li class="calibre8"><strong class="bold">Token usage</strong>: Token usage = cost. As mentioned in <a href="B21964_06_split_000.xhtml#_idTextAnchor134" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Gathering Data – Content is King</em>, look for opportunities to use less expensive models while maintaining or improving quality. This means lower customer costs or the ability to offer free or less costly tiers to serve a wider audience.</li>
				<li class="calibre8"><strong class="bold">Filtering interventions</strong>: If the process has guardrails for handling quality bias and inappropriateness, monitor the rate of these interventions and review them to decide whether there is anything to do about them. We mentioned that with enterprise software, typically<a id="_idIndexMarker798" class="pcalibre pcalibre1 calibre6"/> for authorized authenticated users, abhorrent behaviors are rarely problematic, unlike in social media. It can happen, and blocking it is excellent; however, if work is needed to avoid these conditions or to adjust triggers to poorly timed interventions (e.g., being too strict for something that might be a perfectly reasonable request), look at these articles<a id="_idIndexMarker799" class="pcalibre pcalibre1 calibre6"/>.<p class="calibre3"><strong class="bold">Article</strong>: <a href="https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/" class="pcalibre pcalibre1 calibre6">How to Evaluate LLMs: A Complete Metric Framework</a> (<a href="https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/" class="pcalibre pcalibre1 calibre6">https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/</a>)</p><p class="calibre3"><strong class="bold">Article</strong>: <a href="https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/" class="pcalibre pcalibre1 calibre6">Patterns of Trustworthy Experimentation: During-Experiment Stage</a> (<a href="https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/" class="pcalibre pcalibre1 calibre6">https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/</a>)</p></li>
			</ul>
			<p class="calibre3">These are the tools to understand a variety of data-driven metrics, but there is also the softer side, the human customer, in the loop. Although this data likely impacts our customers in various ways, it is helpful to understand a customer’s perception. Time to explore some usability metrics to show how the system works in the customer’s eyes.</p>
			<h1 id="_idParaDest-223" class="calibre5"><a id="_idTextAnchor230" class="pcalibre pcalibre1 calibre6"/>Monitor with usability metrics</h1>
			<p class="calibre3">Earlier chapters explored <a id="_idIndexMarker800" class="pcalibre pcalibre1 calibre6"/>ways to <a id="_idIndexMarker801" class="pcalibre pcalibre1 calibre6"/>evaluate and find issues. This can be done by using a checklist, a particular set of rules expected for a UX, or a set of heuristics, a collection of guiding principles that, when applied correctly, helps expose issues quickly. The last chapter covered those methods, leaving a few more exciting metrics.</p>
			<p class="calibre3">There are multiple ways to interpret how the system is doing. Since surveys, interviews, and other subjective metrics were covered, let’s address measuring quality changes over time. This means measuring the fidelity of the experience by asking customers to answer specific questions, resulting in<a id="_idIndexMarker802" class="pcalibre pcalibre1 calibre6"/> a <strong class="bold">net promoter score</strong> (<strong class="bold">NPS</strong>), a single-question survey, the more robust and time-consuming ten-question <strong class="bold">software usability scale</strong> (<strong class="bold">SUS</strong>) metric, or <a id="_idIndexMarker803" class="pcalibre pcalibre1 calibre6"/>other forms<a id="_idIndexMarker804" class="pcalibre pcalibre1 calibre6"/> of <strong class="bold">customer satisfaction</strong> (<strong class="bold">CSAT</strong>) surveys.</p>
			<p class="calibre3">First, realize why it is helpful to measure usability with a score. It will only give a broad sense of how the system is performing. It won’t uncover design flaws (unless there are open-ended follow-up questions). There are two<a id="_idIndexMarker805" class="pcalibre pcalibre1 calibre6"/> good reasons to do this. First, it is easy to compare<a id="_idIndexMarker806" class="pcalibre pcalibre1 calibre6"/> to other products and see if the solution meets expectations and exceeds what is found competitively, and second, to establish a baseline to redo these evaluations over time to measure progress. This means asking randomly for feedback, typically after interacting with the product. There will be variability because the same customer isn’t always asked for feedback, so more data is needed to estimate accurately. For simple questions such as NPS, this is an easy ask. It takes a little more effort to code and request an SUS score. These can be supplemented at any time with more expository and open-ended questions.</p>
			<h2 id="_idParaDest-224" class="calibre9"><a id="_idTextAnchor231" class="pcalibre pcalibre1 calibre6"/>Net Promoter Score (NPS)</h2>
			<p class="calibre3"><strong class="bold">NICE Satmetrix</strong> is the <a id="_idIndexMarker807" class="pcalibre pcalibre1 calibre6"/>co-developer and owner of the NPS. It is well known as a simple benchmark of brand quality. Because of its simplicity, it has also been adapted for use in product <a id="_idIndexMarker808" class="pcalibre pcalibre1 calibre6"/>analysis. Nominally, a business’s customer is asked the following question:</p>
			<pre class="source-code">
On a scale of 0 to 10, how likely are you to recommend our business to a friend or colleague?</pre>			<p class="calibre3">This classic question is simple to ask and easy to calculate. It is a broad stroke, and it can be adapted:</p>
			<pre class="source-code">
On a scale of 0 to 10, how likely are you to recommend our conversational assistant to a friend or colleague?</pre>			<p class="calibre3">Adapt the wording to your product. The <em class="italic">Retently</em> website does an excellent job of explaining how to tweak this wording to make it work for your use case. I won’t repeat this material here. Read the article if you are ready to deploy NPS.</p>
			<p class="calibre3">Article: <a href="https://www.retently.com/blog/nps-survey-templates/" class="pcalibre pcalibre1 calibre6">NPS and how to modify the survey</a> (<a href="https://www.retently.com/blog/nps-survey-templates/" class="pcalibre pcalibre1 calibre6">https://www.retently.com/blog/nps-survey-templates/</a>)</p>
			<p class="calibre3">Deploy a version of this <a id="_idIndexMarker809" class="pcalibre pcalibre1 calibre6"/>question based on the product or service. A typical pattern is to ask for feedback for every 50th customer with a simple dialog box prompt, a side panel, or even inline, depending on the design. It is optional to be answered. Some customers won’t participate. The same customer is typically not asked again; tag their account to avoid over-asking survey questions. Automate the aggregation of results (hopefully, this is a random sample and needs to be correlated with the release number) to generate the NPS. <em class="italic">Table 10.8</em> covers design patterns for gathering the NPS or SUS scores.</p>
			<table id="table008" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Use Case</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Deployment Method</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Conversational </strong><strong class="bold">chat assistant</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Inline, when a clear ending to the conversation is known</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Conversational </strong><strong class="bold">chat assistant</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">As a dialog box when a chat is closed</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Conversational </strong><strong class="bold">chat assistant</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">After a feedback flow (such as from a Give Feedback icon or label)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Recommender</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">At the end of a session</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Recommender</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">At the end of any feedback process for evaluating the recommendation</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Web or </strong><strong class="bold">application UI</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">At the end of a transaction or significant flow</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Phone tree</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">At the end of a transaction or significant flow (i.e., do have time for a one-question survey?)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">SMS, </strong><strong class="bold">Slack, Teams</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">After a specific amount of usage</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Backend or </strong><strong class="bold">hidden AI</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">After a specific amount of usage, or the end of a significant flow</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Via Email</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Post-purchase, interaction, or support</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">On receipts, feedback cards at points of sales, or </strong><strong class="bold">with service</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Via a QR code</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Phone calls</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Via human or automated follow-up at the end of a call (You will be transferred to answer a brief one-question survey about your experience today)</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">In </strong><strong class="bold">real-life interactions</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">By asking the customer, and likely entering the score and any feedback manually</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.8 – Approaches to deploying NPS</p>
			<p class="calibre3">Recall our discussions <a id="_idIndexMarker810" class="pcalibre pcalibre1 calibre6"/>about bias. It will be in the results. Sometimes, people are people pleasers, so they will not give good feedback <a id="_idIndexMarker811" class="pcalibre pcalibre1 calibre6"/>when prompted in person. Their most recent interaction will color their input. If the interaction were a failure, it would impact the data. Ensure a good sample; for example, expect skewed results if feedback is gathered from one channel that only handles the closing of accounts.</p>
			<p class="calibre3">Biases can be introduced in the way questions are asked. I have seen some examples that color code the number choices for a survey question, biasing the results. Use neutral colors for all options to reduce bias in survey questions. Some customers might hesitate to give a poor score because it is color-coded red, as shown in <em class="italic">Figure 10</em><em class="italic">.4</em>. Use a generic Likert scale, as discussed previously. However, once they select the score, asking an optional follow-up question is okay. This will give context to their reasoning.</p>
			<div><div><img src="img/B21964_10_04.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 10.4 – Example of an NPS question – use neutral colors for the scale</p>
			<p class="calibre3">The colors classify the results; don’t use the colors in a customer survey. Scores in the red are detractors, people who<a id="_idIndexMarker812" class="pcalibre pcalibre1 calibre6"/> would not be advocates and would likely turn away from using the product. People scoring 7 or 8 are passive; they won’t get in the way but are not a big help. With little thought, they would switch channels or even products. That leaves 9s and 10s promoters, hence the name. Promoters who advocate for brands or products enthusiastically recommend the solution to others. The math is as follows:</p>
			<p class="calibre3"><img src="img/24.png" alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;*&lt;/mi&gt;&lt;mn&gt;100&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" class="calibre42"/></p>
			<p class="calibre3">The range is from -100 to 100. It is fair to gauge your product against other brands. Simplestat reports that the average score in the enterprise space is 44. <em class="italic">Table 10.9</em> gives examples of brands and some samples of NPS. Even well-loved brands are in the 60s and 70s. Brands will generally have significantly higher scores than services or products. Consider that when deciding how good a product is scoring. Comparing releases, channels, or competitive products gives context to scores.</p>
<div><div><img src="img/B21964_10_e.png" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 10.9 – Example NPSs for some products and services</p>

			<p class="calibre3">The scores are<a id="_idIndexMarker813" class="pcalibre pcalibre1 calibre6"/> gathered from these resources:</p>
			<p class="calibre3">Article: <a href="https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf" class="pcalibre pcalibre1 calibre6">NPS scores for the table, Nice Source</a> (<a href="https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf" class="pcalibre pcalibre1 calibre6">https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf</a>)</p>
			<p class="calibre3">Article: <a href="https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks" class="pcalibre pcalibre1 calibre6">NPS scores for the table, CustomerGauge Source</a> (<a href="https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks" class="pcalibre pcalibre1 calibre6">https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks</a>)</p>
			<p class="calibre3">Article: <a href="https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/" class="pcalibre pcalibre1 calibre6">Typical NPS for a product</a> (<a href="https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/" class="pcalibre pcalibre1 calibre6">https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/</a>)</p>
			<p class="calibre3">When at Oracle, we tested and <a id="_idIndexMarker814" class="pcalibre pcalibre1 calibre6"/>shared an NPS with our customers for our Expense Assistant, and in its first release, it scored 55. This was much higher than previous solutions; it was considered a great win. Still, there was room for improvement, so various methods were used, including those in this book.</p>
			<p class="calibre3">Use these example scores or explore other online posts for scores. It is just a general benchmark, but it is quick and easy. It doesn’t guide where to go next and typically requires 100s of responses (roughly) to be valid. However, it also only takes a few seconds of a customer’s time. There are also detractors concerning the validity of this approach. Just keep all that in mind when attempting to gather an NPS. I think it is worth the time. If the application is coded to gather insights, use NPS as one method in addition to a more robust method for feedback. All from the same UX approach!</p>
			<p class="calibre3">Article: <a href="https://en.wikipedia.org/wiki/Net_promoter_score" class="pcalibre pcalibre1 calibre6">Net Promoter Score</a> (<a href="https://en.wikipedia.org/wiki/Net_promoter_score" class="pcalibre pcalibre1 calibre6">https://en.wikipedia.org/wiki/Net_promoter_score</a>)</p>
			<p class="calibre3">Consider the SUS for a robust metric that provides more insight.</p>
			<h2 id="_idParaDest-225" class="calibre9"><a id="_idTextAnchor232" class="pcalibre pcalibre1 calibre6"/>SUS</h2>
			<p class="calibre3">Where NPS is a one-question form, the <strong class="bold">Software Usability Scale</strong> (<strong class="bold">SUS</strong>) is a 10-question survey focused on usability. It is a reasonable way to measure UX or conversational quality. It can<a id="_idIndexMarker815" class="pcalibre pcalibre1 calibre6"/> be deployed for UIs with recommenders, but it is hard to tease out specific details about one element, like a recommendation, without additional questions. It is a well-understood 100-point scale, so it is easy to interpret the scores.</p>
			<p class="calibre3">It uses the Likert scale from one to five, ranging from “Strongly Disagree” to “Strongly Agree.” Imagine how these questions would feel when asked of them after using the application. The ten questions are as follows:</p>
			<ol class="calibre12">
				<li class="calibre8">I think that I would like to use this system frequently.</li>
				<li class="calibre8">I found the system unnecessarily complex.</li>
				<li class="calibre8">I thought the system was easy to use.</li>
				<li class="calibre8">I think that I would need the support of a technical person to be able to use this system.</li>
				<li class="calibre8">I found the various functions in this system were well integrated.</li>
				<li class="calibre8">I thought there was too much inconsistency in this system.</li>
				<li class="calibre8">I would imagine that most people would learn to use this system very quickly.</li>
				<li class="calibre8">I found the system very cumbersome to use.</li>
				<li class="calibre8">I felt very confident using the system.</li>
				<li class="calibre8">I needed to learn a lot of things before I could get going with this system.</li>
			</ol>
			<p class="calibre3">The SUS questions follow one of the tricks explored in our survey discussion. Some questions are phrased in the positive (I feel very confident), and others are negative (I found the system very cumbersome) to avoid respondents answering on autopilot. Patrick Lawson points out in his blog post that these questions also have redundancy. This is common in surveys. The same question is asked slightly differently to create a more robust metric. Read more about the SUS in Patrick’s <a id="_idIndexMarker816" class="pcalibre pcalibre1 calibre6"/>background article:</p>
			<p class="calibre3">Article: <a href="https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/" class="pcalibre pcalibre1 calibre6">How to SUS out usability scores</a> by Patrick Lawson (<a href="https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/" class="pcalibre pcalibre1 calibre6">https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/</a>)</p>
			<p class="calibre3">The calculation to get the 1 to 100 score is specific to this model. Subtract one from each of the positively oriented items’ scores, subtract the answers for the negatively oriented scores from five, and sum all these scores up. The sum multiplied by 2.5 gives the total. Compare the score to the outcomes in <em class="italic">Figure 10</em><em class="italic">.5</em>, shared by Jeff Sauro from MeasuringU. He includes a comparison to NPS.</p>
			<div><div><img src="img/B21964_10_05.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 10.5 – How to interpret a SUS score</p>
			<p class="calibre3">Jeff Sauro goes further into <a id="_idIndexMarker817" class="pcalibre pcalibre1 calibre6"/>the technical scoring and implications of edits to the traditional wording. They point out that some of the work choices for the metric, which<a id="_idIndexMarker818" class="pcalibre pcalibre1 calibre6"/> John Brooke developed in the 1980s, might seem old-fashioned. Read their post to learn more about the scoring and reliability of the metric. It is standing the test <a id="_idIndexMarker819" class="pcalibre pcalibre1 calibre6"/>of time:</p>
			<p class="calibre3">Article: <a href="https://measuringu.com/is-the-sus-too-antiquated/" class="pcalibre pcalibre1 calibre6">Is SUS Antiquated</a> (<a href="https://measuringu.com/is-the-sus-too-antiquated/" class="pcalibre pcalibre1 calibre6">https://measuringu.com/is-the-sus-too-antiquated/</a>)</p>
			<p class="calibre3">Jeff breaks down the scores and details even further. I encourage exploring his posts, even if you have used the SUS for years:</p>
			<p class="calibre3">Article: <a href="https://measuringu.com/interpret-sus-score/" class="pcalibre pcalibre1 calibre6">Interpreting a SUS Score</a> (<a href="https://measuringu.com/interpret-sus-score/" class="pcalibre pcalibre1 calibre6">https://measuringu.com/interpret-sus-score/</a>)</p>
			<p class="calibre3">Go to the government website for details on implementing the SUS.</p>
			<p class="calibre3">Article: <a href="https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html" class="pcalibre pcalibre1 calibre6">Software Usability Scale</a> (<a href="https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html" class="pcalibre pcalibre1 calibre6">https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html</a>)</p>
			<p class="calibre3">The SUS provides more details to drill into than the NPS but doesn’t provide granular information on what to fix. These methods can be followed up with open-ended questions to expose issues. This additional detail is valuable and actionable. The SUS score communicates quality over time and gives broad visibility to progress.</p>
			<h1 id="_idParaDest-226" class="calibre5"><a id="_idTextAnchor233" class="pcalibre pcalibre1 calibre6"/>Refine with heuristic evaluation</h1>
			<p class="calibre3">Heuristic evaluation<a id="_idIndexMarker820" class="pcalibre pcalibre1 calibre6"/> was covered in <a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 9</em></a>, <em class="italic">Guidelines and Heuristics</em>. The same approach, along with classifying and user scoring, from <a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 4</em></a>, <em class="italic">Scoring Stories</em>, can be used at this stage of the development process. All of that applies to monitoring and evaluation results. We can classify issues, score them to prioritize improvements, then apply refinements to the data, prompts, and model improvements (or even test against a new model to merge into the solution), or work on a new integration. You’ve got this! Apply what you know. This leads us to a discussion on handling the process of conversational AI within typical development organizations in <a href="B21964_11.xhtml#_idTextAnchor236" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter </em><em class="italic">11</em></a>, <em class="italic">Process</em>.</p>
			<h1 id="_idParaDest-227" class="calibre5"><a id="_idTextAnchor234" class="pcalibre pcalibre1 calibre6"/>Summary</h1>
			<p class="calibre3">Tools on both ends were covered: analytic tools, such as RAGAs with metrics (sorry for the math!), and usability tools to monitor ongoing improvements from the customer’s perspective. This and monitoring conversations will flow into refinements needed for RAG materials, instructions/prompts, fine-tuning, and swapping to newer models while improving integrations with services and APIs. To do this well, this needs to fit into a process that can handle the dynamic nature of LLMs.</p>
			<p class="calibre3">The next chapter offers insights into implementing processes conducive to LLM development and integrating with engineering to improve LLM solutions continuously.</p>
			<h1 id="_idParaDest-228" class="calibre5"><a id="_idTextAnchor235" class="pcalibre pcalibre1 calibre6"/>References</h1>
			<table id="table010" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div><div><img src="img/B21964_10_QR.jpg" alt="" role="presentation" class="calibre4"/>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The links, book recommendations, and GitHub files in this chapter are posted on the reference page.</p>
							<p class="calibre3">Web Page: <a href="https://uxdforai.com/references#C10" class="pcalibre pcalibre1 calibre6">Chapter 10 References</a> (<a href="https://uxdforai.com/references#C10" class="pcalibre pcalibre1 calibre6">https://uxdforai.com/references#C10</a>)</p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>