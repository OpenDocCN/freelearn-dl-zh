<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer039">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">1</span></h1>
<h1 class="chapterTitle" id="_idParaDest-14"><span class="koboSpan" id="kobo.2.1">Introduction to Generative AI</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">Hello! </span><span class="koboSpan" id="kobo.3.2">Welcome to </span><em class="italic"><span class="koboSpan" id="kobo.4.1">Practical Generative AI with ChatGPT</span></em><span class="koboSpan" id="kobo.5.1">! </span><span class="koboSpan" id="kobo.5.2">In this book, we will explore the fascinating </span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.6.1">world of generative </span><strong class="keyWord"><span class="koboSpan" id="kobo.7.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.8.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.9.1">AI</span></strong><span class="koboSpan" id="kobo.10.1">) and its groundbreaking applications, with a particular focus on ChatGPT.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.11.1">Generative AI has transformed the way we interact with machines, enabling computers to create, predict, and learn without explicit human instruction. </span><span class="koboSpan" id="kobo.11.2">Since the launch of OpenAI’s ChatGPT in November 2022, we have witnessed unprecedented advances in natural language processing, image and video synthesis, and many other fields. </span><span class="koboSpan" id="kobo.11.3">Whether you are a curious beginner or an experienced practitioner, this guide will equip you with the knowledge and skills to effectively navigate the exciting landscape of generative AI. </span><span class="koboSpan" id="kobo.11.4">So, let’s dive in and start the book with some definitions of the context we are moving in.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.12.1">In this chapter, we focus on the applications of generative AI to various fields, such as image synthesis, text generation, and music composition, highlighting the potential of generative AI to revolutionize various industries with concrete examples and recent developments. </span><span class="koboSpan" id="kobo.12.2">Being aware of the research journey toward the current state of the art of generative AI will give you an understanding of the foundations of recent developments and state-of-the-art models.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.13.1">All this, we will cover through the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.14.1">Introducing generative AI</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.15.1">Exploring the domains of generative AI</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.16.1">Main trends and innovation after 2 years of ChatGPT</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.17.1">Legal and ethical landscape of generative AI</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.18.1">By the end of this chapter, you will be familiar with the exciting world of generative AI, its applications, the research history behind it, and the current developments that could have – and are currently having – a disruptive impact on businesses.</span></p>
<h1 class="heading-1" id="_idParaDest-15"><span class="koboSpan" id="kobo.19.1">Introducing generative AI</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.20.1">Generative AI is an </span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.21.1">exciting branch of AI that focuses on creating new content, such as text, images, music, or even videos, that is often indistinguishable from something made by humans.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.22.1">To understand where it fits, let’s break it down:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.23.1">AI</span></strong><span class="koboSpan" id="kobo.24.1">: AI is the </span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.25.1">broad field that enables </span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.26.1">machines to mimic human-like tasks, such as decision-making or problem-solving.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.27.1">Machine learning</span></strong><span class="koboSpan" id="kobo.28.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.29.1">ML</span></strong><span class="koboSpan" id="kobo.30.1">): Within AI, ML refers to techniques where machines learn </span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.31.1">patterns from data to make predictions </span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.32.1">or decisions without being explicitly programmed. </span><span class="koboSpan" id="kobo.32.2">The process of learning is made possible by sophisticated mathematical models called algorithms.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.33.1">Deep learning</span></strong><span class="koboSpan" id="kobo.34.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.35.1">DL</span></strong><span class="koboSpan" id="kobo.36.1">): A subset of ML, DL uses complex algorithms inspired by the human </span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.37.1">brain to process large amounts of data and </span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.38.1">recognize intricate patterns. </span><span class="koboSpan" id="kobo.38.2">Because of their architecture – inspired by our brains and neural connections – these algorithms are called artificial neural networks.</span><div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.39.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.40.1">An artificial neural network is a type of computer program designed to learn patterns by processing </span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.41.1">information in a way that’s inspired by the human brain. </span><span class="koboSpan" id="kobo.41.2">Instead of following strict, step-by-step rules, it uses interconnected “nodes” (like virtual brain cells) that work together and adjust their connections over time. </span><span class="koboSpan" id="kobo.41.3">By repeatedly reviewing examples, it gradually improves at tasks like recognizing images, understanding speech, or predicting outcomes—all without needing explicit instructions for each step.</span></p>
</div>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.42.1">Generative AI emerges from DL and uses specialized algorithms to generate something entirely new based on what it has learned from existing data. </span><span class="koboSpan" id="kobo.42.2">For example, a generative AI model trained on thousands of paintings could create brand-new art that blends different styles or themes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.43.1">The following figure shows how these areas of research are related to each other:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.44.1"><img alt="" src="../Images/B31559_01_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.45.1">Figure 1.1: Relationship between AI, ML, DL, and generative AI</span></p>
<p class="normal"><span class="koboSpan" id="kobo.46.1">Generative AI </span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.47.1">models are trained on vast amounts of data and then they can generate new examples based on user’s requests. </span><span class="koboSpan" id="kobo.47.2">And the game-changer element here is that these requests are made in the easiest way possible – using our natural language. </span><span class="koboSpan" id="kobo.47.3">These </span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.48.1">models are called </span><strong class="keyWord"><span class="koboSpan" id="kobo.49.1">large language models</span></strong><span class="koboSpan" id="kobo.50.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.51.1">LLMs</span></strong><span class="koboSpan" id="kobo.52.1">).</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.53.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.54.1">LLMs are a type of artificial neural network featured by a particular architectural framework called “Transformer.” </span><span class="koboSpan" id="kobo.54.2">They are characterized by a huge number of parameters (in the order of billions) and have been trained on billions of words. </span><span class="koboSpan" id="kobo.54.3">Given the training set, LLMs are capable of inferring language patterns and intents in user queries and generating natural language responses.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.55.1">The possibility of interacting in natural language with LLMs is disruptive, and a whole new science has been born around that activity. </span><span class="koboSpan" id="kobo.55.2">This science is called “prompt engineering,” named after the term “prompt,” which we are going to cover in </span><em class="italic"><span class="koboSpan" id="kobo.56.1">Chapter 3</span></em><span class="koboSpan" id="kobo.57.1">.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.58.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.59.1">A prompt is the specific text, question, or description you provide to a generative AI model to guide it toward producing the kind of output you want—whether that’s a helpful explanation, a creative story, or a detailed solution. </span><span class="koboSpan" id="kobo.59.2">How you phrase the prompt can greatly affect the AI’s response. </span><span class="koboSpan" id="kobo.59.3">This practice of carefully designing and refining prompts, often called “prompt engineering,” involves experimenting with different word choices, instructions, and formats to improve both the quality and accuracy of the AI’s output. </span><span class="koboSpan" id="kobo.59.4">By learning how to craft effective prompts, you help ensure the AI more consistently gives you results that are useful, engaging, and aligned with your goals.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.60.1">Even though text understanding and generation is probably one of the most outstanding features of Generative AI, this field covers many domains, which we will cover next.</span></p>
<h1 class="heading-1" id="_idParaDest-16"><span class="koboSpan" id="kobo.61.1">Domains of generative AI</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.62.1">In recent years, generative AI has made significant advancements and has expanded its applications </span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.63.1">to a wide range of domains, such as art, music, fashion, and architecture. </span><span class="koboSpan" id="kobo.63.2">In some of them, it is indeed transforming the way we create, design, and understand the world around us. </span><span class="koboSpan" id="kobo.63.3">In others, it is improving and making existing processes and operations more efficient.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.64.1">For example, in the context of the pharmaceutical industry, generative AI is revolutionizing drug discovery by enabling the rapid design of novel therapeutic molecules, thereby significantly reducing development timelines and costs. </span><span class="koboSpan" id="kobo.64.2">By analyzing extensive datasets of chemical and biological information, generative AI models can identify promising drug candidates and predict their interactions within the human body. </span><span class="koboSpan" id="kobo.64.3">For instance, Insilico Medicine utilized generative AI to develop ISM001-055, a drug candidate for idiopathic pulmonary fibrosis, which progressed to Phase II clinical trials in 2023 (</span><span class="url"><span class="koboSpan" id="kobo.65.1">https://insilico.com/blog/first_phase2</span></span><span class="koboSpan" id="kobo.66.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.67.1">Another example is the way generative AI is revolutionizing game development by enabling the creation of dynamic and adaptive environments that respond to player actions, thereby enhancing immersion and replayability. </span><span class="koboSpan" id="kobo.67.2">By leveraging generative AI, developers can procedurally generate vast, ever-changing game worlds, ensuring that each playthrough offers a </span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.68.1">unique experience. </span><span class="koboSpan" id="kobo.68.2">This technology facilitates the creation of realistic </span><strong class="keyWord"><span class="koboSpan" id="kobo.69.1">non-playable characters</span></strong><span class="koboSpan" id="kobo.70.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.71.1">NPCs</span></strong><span class="koboSpan" id="kobo.72.1">) with behaviors that adapt to player interactions, making game narratives more engaging. </span><span class="koboSpan" id="kobo.72.2">Additionally, generative AI streamlines the development process by automating asset creation, which reduces production time and costs. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.73.1">As a result, developers can focus more on crafting innovative gameplay mechanics and rich storytelling, ultimately delivering more personalized and captivating gaming experiences (</span><span class="url"><span class="koboSpan" id="kobo.74.1">https://www.xcubelabs.com/blog/generative-ai-in-game-development-creating-dynamic-and-adaptive-environments/</span></span><span class="koboSpan" id="kobo.75.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.76.1">Lastly, generative AI can have a great impact on advertising and visual asset generation. </span><span class="koboSpan" id="kobo.76.2">For example, in March 2023, Coca-Cola launched the “Create Real Magic” platform (</span><span class="url"><span class="koboSpan" id="kobo.77.1">https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform</span></span><span class="koboSpan" id="kobo.78.1">), inviting digital artists worldwide to craft original artwork using iconic brand assets from its archives. </span><span class="koboSpan" id="kobo.78.2">Developed in collaboration with OpenAI and Bain &amp; Company, this innovative platform combines the capabilities of GPT-4 and DALL-E, enabling users to generate unique pieces that blend Coca-Cola’s heritage with modern AI technology. </span><span class="koboSpan" id="kobo.78.3">Participants had the opportunity to submit their creations for </span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.79.1">a chance to be featured on Coca-Cola’s digital billboards in New York’s Times Square and London’s Piccadilly Circus, exemplifying the brand’s commitment to fostering creativity through cutting-edge technology. </span><span class="koboSpan" id="kobo.79.2">These are just a few examples of how generative AI can reshape business processes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.80.1">Now, the fact that generative AI is used in many domains also implies that its models can deal with different kinds of data, from natural language to audio or images. </span><span class="koboSpan" id="kobo.80.2">In the next section, we’ll explore how generative AI models address different types of data and domains.</span></p>
<h2 class="heading-2" id="_idParaDest-17"><span class="koboSpan" id="kobo.81.1">Text generation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.82.1">The evolution of text generation within AI has been a journey from early theoretical concepts to </span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.83.1">today’s sophisticated language models. </span><span class="koboSpan" id="kobo.83.2">The 1950s marked </span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.84.1">the formal inception of AI as a field, with pioneers like Alan Turing exploring machine intelligence. </span><span class="koboSpan" id="kobo.84.2">Early efforts in </span><strong class="keyWord"><span class="koboSpan" id="kobo.85.1">natural language processing</span></strong><span class="koboSpan" id="kobo.86.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.87.1">NLP</span></strong><span class="koboSpan" id="kobo.88.1">) during </span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.89.1">the 1960s and 1970s led to programs such as ELIZA, which simulated conversation through pattern matching. </span><span class="koboSpan" id="kobo.89.2">The 1980s and 1990s saw the development of statistical models that improved language modeling by probabilistically predicting word sequences. </span><span class="koboSpan" id="kobo.89.3">The advent of ML algorithms during this period further advanced text generation capabilities.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.90.1">A significant breakthrough occurred in 2017 with the introduction of the Transformer architecture which, as aforementioned, is the framework that features today’s LLMs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.91.1">The unique element of this new series of models featuring the landscape of generative AI is that – once they are trained – they can be consumed, queried, and instructed in the easiest way possible. </span><span class="koboSpan" id="kobo.91.2">The introduction of LLMs marked a paradigm shift in the context of AI since no advanced skills were needed to benefit from them.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.92.1">Today, one of the greatest applications of generative AI—and the one we are going to cover the most throughout this book—is its ability to produce new content in natural language. </span><span class="koboSpan" id="kobo.92.2">Indeed, generative AI models can be used to generate new coherent and grammatically correct text in different languages, such as articles, poetry, and product descriptions. </span><span class="koboSpan" id="kobo.92.3">They can also extract relevant features from text such as keywords, topics, or full summaries.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.93.1">Here is an example of working with GPT-4o, one of the latest models released by OpenAI and available through ChatGPT:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.94.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B31559_01_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.95.1">Figure 1.2: Example of ChatGPT responding to a user’s query in natural language</span></p>
<p class="normal"><span class="koboSpan" id="kobo.96.1">As you </span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.97.1">can see, the model was not only able to answer my question </span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.98.1">with an explanation of what a proton is; it also adapted its style and jargon to a specific target audience – in my case, a 5-year-old child. </span><span class="koboSpan" id="kobo.98.2">This is remarkable since it paves the way for many scenarios of hyper-personalization that were not possible before. </span><span class="koboSpan" id="kobo.98.3">In the next chapters, we will cover many examples of that.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.99.1">ChatGPT is the main focus of this book, and in the upcoming chapters, you will see examples that showcase this powerful application.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.100.1">Now, we will move on to image generation.</span></p>
<h2 class="heading-2" id="_idParaDest-18"><span class="koboSpan" id="kobo.101.1">Image generation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.102.1">One of the </span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.103.1">earliest and most well-known examples of generative AI in image </span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.104.1">synthesis is the </span><strong class="keyWord"><span class="koboSpan" id="kobo.105.1">generative adversarial network (GAN)</span></strong><span class="koboSpan" id="kobo.106.1"> architecture </span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.107.1">introduced in the 2014 paper by I. </span><span class="koboSpan" id="kobo.107.2">Goodfellow et al., </span><em class="italic"><span class="koboSpan" id="kobo.108.1">Generative Adversarial Networks</span></em><span class="koboSpan" id="kobo.109.1">. </span><span class="koboSpan" id="kobo.109.2">The purpose of GANs is to generate realistic images that are indistinguishable from real images. </span><span class="koboSpan" id="kobo.109.3">This ability has several interesting business applications, such as generating synthetic datasets for training computer vision models, generating realistic product images, and generating realistic images for virtual reality and augmented reality applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.110.1">Then, in 2021, a new generative AI model was introduced in this field by OpenAI, </span><strong class="screenText"><span class="koboSpan" id="kobo.111.1">DALL-E</span></strong><span class="koboSpan" id="kobo.112.1">. </span><span class="koboSpan" id="kobo.112.2">Different from GANs, the DALL-E model is designed to generate images from descriptions in natural language and can generate a wide range of images. </span><span class="koboSpan" id="kobo.112.3">The main difference here is that while GANs are often used to create or improve realistic images, models like DALL-E are ideal for </span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.113.1">visual creativity, turning any description in natural language into an illustration.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.114.1">DALL-E has </span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.115.1">great potential in creative industries such as advertising, product design, and fashion to create unique and creative images.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.116.1">Since its first release to the time of writing (December 2024), DALL-E has improved dramatically, as you can see in the following examples. </span><span class="koboSpan" id="kobo.116.2">Below is an artistic creation by DALL-E at the dawn of its life:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.117.1"><img alt="" src="../Images/B31559_01_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.118.1">Figure 1.3: Images generated by DALL-E with a natural language prompt as input</span></p>
<p class="normal"><span class="koboSpan" id="kobo.119.1">Let’s now see what </span><strong class="screenText"><span class="koboSpan" id="kobo.120.1">DALL-E3</span></strong><span class="koboSpan" id="kobo.121.1">, the most recent version of the model at the time of writing this book, can produce (here, we will use Microsoft Image Creator, powered by DALL-E3. </span><span class="koboSpan" id="kobo.121.2">You can try it at </span><span class="url"><span class="koboSpan" id="kobo.122.1">https://copilot.microsoft.com/images/create</span></span><span class="koboSpan" id="kobo.123.1">):</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.124.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B31559_01_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.125.1">Figure 1.4: Images generated by DALL-E3 with a natural language prompt as input</span></p>
<p class="normal"><span class="koboSpan" id="kobo.126.1">It’s impressive </span><a id="_idIndexMarker024"/><span class="koboSpan" id="kobo.127.1">to see the level of improvement of this model in less than 2 years. </span><span class="koboSpan" id="kobo.127.2">We are </span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.128.1">just scraping the surface of the massive improvements occurring at a fast pace.</span></p>
<h2 class="heading-2" id="_idParaDest-19"><span class="koboSpan" id="kobo.129.1">Music generation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.130.1">The first approaches to generative AI for music generation trace back to the 1950s, with research in </span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.131.1">the field of algorithmic composition, a technique </span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.132.1">that uses algorithms to generate musical compositions. </span><span class="koboSpan" id="kobo.132.2">In 1957, Lejaren Hiller and Leonard Isaacson created the </span><em class="italic"><span class="koboSpan" id="kobo.133.1">Illiac Suite</span></em><span class="koboSpan" id="kobo.134.1"> for </span><em class="italic"><span class="koboSpan" id="kobo.135.1">String Quartet </span></em><span class="koboSpan" id="kobo.136.1">(</span><span class="url"><span class="koboSpan" id="kobo.137.1">https://www.youtube.com/watch?v=n0njBFLQSk8</span></span><span class="koboSpan" id="kobo.138.1">), the first piece of music entirely composed by AI. </span><span class="koboSpan" id="kobo.138.2">Since then, the field of generative AI for music has been the subject of ongoing research. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.139.1">Among recent years’ developments, new architectures and frameworks have become widespread among the general public, such as the WaveNet architecture introduced by Google in 2016, which has been able to generate high-quality audio samples, and the Magenta project, also developed by Google, which uses </span><strong class="keyWord"><span class="koboSpan" id="kobo.140.1">recurrent neural networks</span></strong><span class="koboSpan" id="kobo.141.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.142.1">RNNs</span></strong><span class="koboSpan" id="kobo.143.1">) and other ML techniques to generate music and other forms of art.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.144.1">Definition</span></strong></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.145.1">RNNs</span></strong><span class="koboSpan" id="kobo.146.1"> are a type of neural network designed to process sequential data by </span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.147.1">retaining information from previous inputs through a loop-like structure. </span><span class="koboSpan" id="kobo.147.2">This allows them to recognize patterns and dependencies over time, making them ideal for tasks like language modeling, time-series prediction, and speech recognition.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.148.1">In 2020, OpenAI also announced Jukebox, a neural network that generates music when provided with genre, artist, and lyrics as input.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.149.1">These and </span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.150.1">other frameworks became the foundations </span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.151.1">of many AI composer assistants for music generation. </span><span class="koboSpan" id="kobo.151.2">An example is Flow Machines, developed by Sony CSL Research. </span><span class="koboSpan" id="kobo.151.3">This generative AI system was trained on a large database of musical pieces to create new music in a variety of styles. </span><span class="koboSpan" id="kobo.151.4">It was used by French composer Benoît Carré to compose an album called </span><em class="italic"><span class="koboSpan" id="kobo.152.1">Hello World </span></em><span class="koboSpan" id="kobo.153.1">(</span><span class="url"><span class="koboSpan" id="kobo.154.1">https:// www.helloworldalbum.net/</span></span><span class="koboSpan" id="kobo.155.1">), which features collaborations with several human musicians.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.156.1">Here, you can see an example of a track generated entirely by Music Transformer, one of the models within the Magenta project:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.157.1"><img alt="" src="../Images/B31559_01_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.158.1">Figure 1.5: Music Transformer allows users to listen to musical performances generated by AI (https://magenta.tensorflow.org/music-transformer)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.159.1">Another incredible application of generative AI within the music domain is speech synthesis. </span><span class="koboSpan" id="kobo.159.2">This refers to AI tools that can create audio based on text inputs in the voices of well-known singers.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.160.1">For example, if you </span><a id="_idIndexMarker031"/><span class="koboSpan" id="kobo.161.1">have always wondered how your songs would sound if Lady </span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.162.1">Gaga performed them, well, you can now fulfill your dreams with tools such as FakeYou </span><em class="italic"><span class="koboSpan" id="kobo.163.1">Text to Speech</span></em><span class="koboSpan" id="kobo.164.1"> (</span><span class="url"><span class="koboSpan" id="kobo.165.1">https://fakeyou.com/tts</span></span><span class="koboSpan" id="kobo.166.1">) or UberDuck.ai (</span><span class="url"><span class="koboSpan" id="kobo.167.1">https://uberduck.ai/</span></span><span class="koboSpan" id="kobo.168.1">)!</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.169.1"><img alt="" src="../Images/B31559_01_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.170.1">Figure 1.6: Text-to-speech synthesis with fakeyou.com</span></p>
<p class="normal"><span class="koboSpan" id="kobo.171.1">The results are really impressive! </span><span class="koboSpan" id="kobo.171.2">If you want to have fun, you can also try voices from your favorite cartoons, such as </span><em class="italic"><span class="koboSpan" id="kobo.172.1">Winnie the Pooh</span></em><span class="koboSpan" id="kobo.173.1">. </span><span class="koboSpan" id="kobo.173.2">The only thing you need to do is input the text of the song you want your favorite voice to sing aloud.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.174.1">Let’s go even further. </span><span class="koboSpan" id="kobo.174.2">What if we could generate a song from scratch, just asking the generative AI to do that for us in natural language? </span><span class="koboSpan" id="kobo.174.3">Well, we can do that seamlessly today and without any knowledge about music. </span><span class="koboSpan" id="kobo.174.4">Among the generative AI products that are rising in the music market today is Suno, whose mission is </span><em class="italic"><span class="koboSpan" id="kobo.175.1">“[...]building a future where anyone can make great music. </span><span class="koboSpan" id="kobo.175.2">Whether you’re a shower singer or a charting artist, we break barriers between you and the song you dream of making. </span><span class="koboSpan" id="kobo.175.3">No instrument needed, just imagination. </span><span class="koboSpan" id="kobo.175.4">From your mind to music.”</span></em><span class="koboSpan" id="kobo.176.1"> (source: </span><span class="url"><span class="koboSpan" id="kobo.177.1">https://suno.com/about</span></span><span class="koboSpan" id="kobo.178.1">).</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.179.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B31559_01_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.180.1">Figure 1.7: Example of an entire song generated by Suno.com from a description in natural language</span></p>
<p class="normal"><span class="koboSpan" id="kobo.181.1">As you can see, on the left-hand side of the picture, I provided a very brief song description in natural </span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.182.1">language – this was my prompt. </span><span class="koboSpan" id="kobo.182.2">From that, the model </span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.183.1">was able to generate not only the title and lyrics of a song (on the right-hand side) but also the music!</span></p>
<p class="normal"><span class="koboSpan" id="kobo.184.1">Can you believe that it became my summer 2024 hit? </span><span class="koboSpan" id="kobo.184.2">If you want to create your summer hit too, you can try it for free at </span><span class="url"><span class="koboSpan" id="kobo.185.1">https://suno.com/create</span></span><span class="koboSpan" id="kobo.186.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-20"><span class="koboSpan" id="kobo.187.1">Video generation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.188.1">Generative AI for video generation shares a similar timeline of development with image generation. </span><span class="koboSpan" id="kobo.188.2">One </span><a id="_idIndexMarker035"/><span class="koboSpan" id="kobo.189.1">of the key developments in the field of video generation </span><a id="_idIndexMarker036"/><span class="koboSpan" id="kobo.190.1">has been the development of GANs. </span><span class="koboSpan" id="kobo.190.2">Thanks to their accuracy in producing realistic images, researchers have started to apply this technique to video generation as well. </span><span class="koboSpan" id="kobo.190.3">One of the most notable examples of GAN-based video generation is DeepMind’s Veo, which generates high-quality videos from a single image and a sequence of motions. </span><span class="koboSpan" id="kobo.190.4">Another great example is NVIDIA’s </span><strong class="keyWord"><span class="koboSpan" id="kobo.191.1">video-to-video synthesis</span></strong><span class="koboSpan" id="kobo.192.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.193.1">Vid2Vid</span></strong><span class="koboSpan" id="kobo.194.1">) DL-based </span><a id="_idIndexMarker037"/><span class="koboSpan" id="kobo.195.1">framework, which uses GANs to synthesize high-quality videos from input videos.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.196.1">The Vid2Vid system can generate temporally consistent videos, meaning that they maintain smooth and realistic motion over time. </span><span class="koboSpan" id="kobo.196.2">The technology can be used to perform a variety of video </span><a id="_idIndexMarker038"/><span class="koboSpan" id="kobo.197.1">synthesis tasks, such as the following:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.198.1">Converting videos from one domain into another (for example, converting a daytime video into a nighttime video or a sketch into a realistic image)</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.199.1">Modifying existing videos (for example, changing the style or appearance of objects in a video)</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.200.1">Creating new videos from static images (for example, animating a sequence of still images)</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.201.1">In September 2022, Meta’s </span><a id="_idIndexMarker039"/><span class="koboSpan" id="kobo.202.1">researchers announced the general availability of </span><strong class="keyWord"><span class="koboSpan" id="kobo.203.1">Make-A-Video</span></strong><span class="koboSpan" id="kobo.204.1"> (</span><span class="url"><span class="koboSpan" id="kobo.205.1">https://makeavideo.studio/</span></span><span class="koboSpan" id="kobo.206.1">), a new AI system that allows users to convert their natural language prompts into video clips. </span><span class="koboSpan" id="kobo.206.2">Behind this technology, you can </span><a id="_idIndexMarker040"/><span class="koboSpan" id="kobo.207.1">recognize many of the models that we </span><a id="_idIndexMarker041"/><span class="koboSpan" id="kobo.208.1">mentioned in other domains – language understanding for the prompt, image and motion generation with image generation, and background music made by AI composers.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.209.1">Now, everything we’ve mentioned above pales in comparison to the latest text-to-video models. </span><span class="koboSpan" id="kobo.209.2">To name one, OpenAI </span><a id="_idIndexMarker042"/><span class="koboSpan" id="kobo.210.1">announced a text-to-video model called </span><strong class="keyWord"><span class="koboSpan" id="kobo.211.1">SORA</span></strong><span class="koboSpan" id="kobo.212.1"> in February 2024 and released some early experiments:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.213.1"><img alt="A person in a black jacket and red dress standing on a wet street  Description automatically generated" src="../Images/B31559_01_08.png"/></span><span class="koboSpan" id="kobo.214.1"><img alt="A group of mammoths in the snow  Description automatically generated" src="../Images/B31559_01_09.png"/></span></figure>
<figure class="mediaobject"><span class="koboSpan" id="kobo.215.1"><img alt="A person in a space suit  Description automatically generated" src="../Images/B31559_01_10.png"/></span> <span class="koboSpan" id="kobo.216.1"><img alt="A cartoon animal looking at a candle  Description automatically generated" src="../Images/B31559_01_11.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.217.1">Figure 1.8: Videos generated by SORA from prompts in natural language. </span><span class="koboSpan" id="kobo.217.2">Source: https://openai.com/index/sora/</span></p>
<p class="normal"><span class="koboSpan" id="kobo.218.1">I do encourage </span><a id="_idIndexMarker043"/><span class="koboSpan" id="kobo.219.1">you to visit the SORA webpage to have a look at the amazing </span><a id="_idIndexMarker044"/><span class="koboSpan" id="kobo.220.1">videos it created. </span><span class="koboSpan" id="kobo.220.2">At the time of writing, SORA is not publicly available, as it is going through several tests by the OpenAI Red Team.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.221.1">Overall, generative AI has impacted many domains for years, and some AI tools already consistently support artists, organizations, and general users. </span><span class="koboSpan" id="kobo.221.2">Despite the fact we’ve been experimenting and building applications with generative AI for only two years, there are already some consolidated trends and future innovations to keep in mind. </span><span class="koboSpan" id="kobo.221.3">Let’s explore them in the next section.</span></p>
<h1 class="heading-1" id="_idParaDest-21"><span class="koboSpan" id="kobo.222.1">Main trends and innovations</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.223.1">From November 2022 to today, we have witnessed a huge amount of innovation in the field of generative AI. </span><span class="koboSpan" id="kobo.223.2">Many </span><a id="_idIndexMarker045"/><span class="koboSpan" id="kobo.224.1">of these innovations are linked to the brand-new models developed and released to the public, like OpenAI’s GPT-4o and DALL-E3, but also Google Gemini, Meta Llama 3, Microsoft Phi3, and many others.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.225.1">However, the most remarkable achievements probably lie in the way we interact with and build applications around those models. </span><span class="koboSpan" id="kobo.225.2">In this section, we are going to explore three main advancements that have marked the most popular reference architectures for generative-AI-powered applications.</span></p>
<h2 class="heading-2" id="_idParaDest-22"><span class="koboSpan" id="kobo.226.1">Retrieval augmented generation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.227.1">One of the </span><a id="_idIndexMarker046"/><span class="koboSpan" id="kobo.228.1">first limitations of ChatGPT and, generally speaking, of LLMs was the knowledge base cutoff. </span><span class="koboSpan" id="kobo.228.2">The knowledge of LLMs is limited to the training set they have been trained on and, although this can be exhaustive, it’s not up to date (in fact, once the model is trained, any new data or information that emerges afterward won’t be part of its knowledge, since it wasn’t included in the original training set). </span><span class="koboSpan" id="kobo.228.3">Plus, the data is likely missing the proprietary knowledge base that might be relevant for us or our organization. </span><span class="koboSpan" id="kobo.228.4">For example, if you ask ChatGPT, “What is my company’s policy for employee health insurance?”, the model won’t be able to answer since it has no access to this information.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.229.1">To bypass this limitation, a new framework was designed to allow LLMs to navigate through customized </span><a id="_idIndexMarker047"/><span class="koboSpan" id="kobo.230.1">documentation </span><a id="_idIndexMarker048"/><span class="koboSpan" id="kobo.231.1">that we can provide. </span><span class="koboSpan" id="kobo.231.2">This framework is called </span><strong class="keyWord"><span class="koboSpan" id="kobo.232.1">retrieval augmented generation</span></strong><span class="koboSpan" id="kobo.233.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.234.1">RAG</span></strong><span class="koboSpan" id="kobo.235.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.236.1">The idea behind RAG is to augment the LLM’s knowledge by adding external sources of information, yet without modifying the structure of the model at all.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.237.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.238.1">An embedding is </span><a id="_idIndexMarker049"/><span class="koboSpan" id="kobo.239.1">a way to turn complex information—like words, sentences, or images—into a list of numbers (a vector). </span><span class="koboSpan" id="kobo.239.2">This makes it easier for a computer to understand what those words or sentences mean. </span><span class="koboSpan" id="kobo.239.3">If two pieces of text have similar meanings, their vectors will be close together in the numerical space. </span><span class="koboSpan" id="kobo.239.4">In other words, embeddings let computers measure how alike different inputs are based on their content, not just their exact wording.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.240.1">For example, if two concepts are similar, then their vector representations should also be similar.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.241.1"><img alt="" src="../Images/B31559_01_12.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.242.1">Figure 1.9: Example of vector representation of four different words</span></p>
<p class="normal"><span class="koboSpan" id="kobo.243.1">In this example, we can see that the mathematical distance between the two vectors corresponding to “Queen” and “King” is more or less the same as the difference between “Woman” and “Man.” </span><span class="koboSpan" id="kobo.243.2">Semantically speaking, this makes sense, as we are talking about a similar relationship. </span><span class="koboSpan" id="kobo.243.3">A similar example might be applied to the relationship between countries and capital cities: once embedded in a vector space, the distance between “Italy” and “Rome” should </span><a id="_idIndexMarker050"/><span class="koboSpan" id="kobo.244.1">be similar to the distance between “France” and “Paris” as they are mapping the same relationships.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.245.1">RAG is </span><a id="_idIndexMarker051"/><span class="koboSpan" id="kobo.246.1">made of three phases:</span></p>
<ol>
<li class="numberedList" value="1"><strong class="screenText"><span class="koboSpan" id="kobo.247.1">Retrieval</span></strong><span class="koboSpan" id="kobo.248.1">: Given a user’s query and its corresponding numerical representation, the most similar pieces of documents (those corresponding to the vectors that are closest to the user query’s vector) are retrieved and used as the base context for the LLM.</span></li>
</ol>
<figure class="mediaobject"><span class="koboSpan" id="kobo.249.1"><img alt="A close-up of a text box  Description automatically generated" src="../Images/B31559_01_13.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.250.1">Figure 1.10: Example of retrieving three different chunks from different documents, since they are represented by the closest vectors to the user query</span></p>
<ol>
<li class="numberedList" value="2"><strong class="screenText"><span class="koboSpan" id="kobo.251.1">Augmentation</span></strong><span class="koboSpan" id="kobo.252.1">: The retrieved context is enriched through additional instructions, rules, safety guardrails, and similar practices that are typical of prompt engineering techniques (we will cover the topic of prompt engineering in </span><em class="italic"><span class="koboSpan" id="kobo.253.1">Chapter 3</span></em><span class="koboSpan" id="kobo.254.1">).</span></li>
</ol>
<figure class="mediaobject"><span class="koboSpan" id="kobo.255.1"><img alt="" src="../Images/B31559_01_14.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.256.1">Figure 1.11: Example of adding more context to the retrieved chunks of documents</span></p>
<ol>
<li class="numberedList" value="3"><strong class="screenText"><span class="koboSpan" id="kobo.257.1">Generation</span></strong><span class="koboSpan" id="kobo.258.1">: Based on </span><a id="_idIndexMarker052"/><span class="koboSpan" id="kobo.259.1">the augmented </span><a id="_idIndexMarker053"/><span class="koboSpan" id="kobo.260.1">context, the LLM generates the response to the user’s query.</span></li>
</ol>
<figure class="mediaobject"><span class="koboSpan" id="kobo.261.1"><img alt="A screenshot of a computer screen  Description automatically generated" src="../Images/B31559_01_15.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.262.1">Figure 1.12: Example of using the augmented context as the system message for the model to generate the final answer</span></p>
<p class="normal"><span class="koboSpan" id="kobo.263.1">RAG combines the strengths of generative models and information retrieval systems to enhance the quality and relevance of generated content. </span><span class="koboSpan" id="kobo.263.2">Traditional generative models rely solely on </span><a id="_idIndexMarker054"/><span class="koboSpan" id="kobo.264.1">their training data to produce responses, which </span><a id="_idIndexMarker055"/><span class="koboSpan" id="kobo.265.1">can sometimes result in outdated or irrelevant information. </span><span class="koboSpan" id="kobo.265.2">RAG addresses this limitation by integrating external knowledge bases during the generation process.</span></p>
<h2 class="heading-2" id="_idParaDest-23"><span class="koboSpan" id="kobo.266.1">Multimodality</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.267.1">Earlier in this chapter, we looked at the various domains of generative AI, ranging from text to images, from </span><a id="_idIndexMarker056"/><span class="koboSpan" id="kobo.268.1">videos to music. </span><span class="koboSpan" id="kobo.268.2">Typically, large foundation models tend to be domain-specific, as we saw for LLMs in the case of language </span><a id="_idIndexMarker057"/><span class="koboSpan" id="kobo.269.1">understanding and generation, or DALL-E3 in the case of image generation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.270.1">However, the recent </span><a id="_idIndexMarker058"/><span class="koboSpan" id="kobo.271.1">advances in generative AI have enabled the development of </span><strong class="keyWord"><span class="koboSpan" id="kobo.272.1">large multimodal models</span></strong><span class="koboSpan" id="kobo.273.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.274.1">LMMs</span></strong><span class="koboSpan" id="kobo.275.1">) that can process and generate different types of data, such as text, images, audio, and video.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.276.1">LMMs share with </span><em class="italic"><span class="koboSpan" id="kobo.277.1">standard</span></em><span class="koboSpan" id="kobo.278.1"> LLMs the ability to generalize and adapt typical large foundation models. </span><span class="koboSpan" id="kobo.278.2">However, LMMs are capable of processing diverse data with the idea of mirroring the way humans interact with the surrounding ecosystem – that is, with all our senses.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.279.1">A great example of a multimodal model is OpenAI’s GPT-4o, which is able to interact with users via text, images, and audio. </span><span class="koboSpan" id="kobo.279.2">Take the following example:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.280.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B31559_01_16.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.281.1">Figure 1.13: Example of providing ChatGPT-4o with a picture and asking it to name the building</span></p>
<p class="normal"><span class="koboSpan" id="kobo.282.1">As you can see, the model was able to analyze the image and reason over it.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.283.1">Let’s now go ahead and ask the model to generate an illustration:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.284.1"><img alt="A black and white drawing of a tall building  Description automatically generated" src="../Images/B31559_01_17.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.285.1">Figure 1.14: Example of ChatGPT-4o generating an illustration based on a previously provided picture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.286.1">What sets LLMs apart is their ability to retain advanced reasoning capabilities, making them uniquely </span><a id="_idIndexMarker059"/><span class="koboSpan" id="kobo.287.1">suited for tackling complex reasoning tasks across </span><a id="_idIndexMarker060"/><span class="koboSpan" id="kobo.288.1">diverse data contexts, unlike traditional AI models. </span><span class="koboSpan" id="kobo.288.2">Let’s consider, for example, traditional computer vision models, which are task-specific, and they do not </span><em class="italic"><span class="koboSpan" id="kobo.289.1">reason</span></em><span class="koboSpan" id="kobo.290.1"> over an image, but rather perform tasks like detecting objects or extracting text from images. </span><span class="koboSpan" id="kobo.290.2">On the other hand, LMMs can use the same reasoning capabilities as LLMs, yet they can apply these capabilities to data other than text.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.291.1">Let’s consider this last example (showing only the first lines of the response):</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.292.1"><img alt="A crossword puzzle with text  Description automatically generated" src="../Images/B31559_01_18.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.293.1">Figure 1.15: Example of ChatGPT 4o solving a crossword game</span></p>
<p class="normal"><span class="koboSpan" id="kobo.294.1">As you </span><a id="_idIndexMarker061"/><span class="koboSpan" id="kobo.295.1">can see, the model was able to:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.296.1">Read and </span><a id="_idIndexMarker062"/><span class="koboSpan" id="kobo.297.1">understand the scenario the image is posing</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.298.1">Reason about it and solve the complex task that it is offering, which is solving a puzzle</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.299.1">As you may imagine, this opens a landscape of applications in various industries, and we are going to see some concrete examples in the upcoming chapters.</span></p>
<h2 class="heading-2" id="_idParaDest-24"><span class="koboSpan" id="kobo.300.1">AI agents</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.301.1">In previous sections, we uncovered how LLMs are great when it comes to generating content. </span><span class="koboSpan" id="kobo.301.2">However, they lack one ability, which is taking action and interacting with the surrounding </span><a id="_idIndexMarker063"/><span class="koboSpan" id="kobo.302.1">ecosystem that goes beyond the single user. </span><span class="koboSpan" id="kobo.302.2">For example, what if we want our LLM to be able not only to generate an amazing LinkedIn </span><a id="_idIndexMarker064"/><span class="koboSpan" id="kobo.303.1">post but also publish it on our page?</span></p>
<p class="normal"><span class="koboSpan" id="kobo.304.1">AI agents emerge as key players in overcoming this limitation. </span><span class="koboSpan" id="kobo.304.2">But what exactly are they? </span><span class="koboSpan" id="kobo.304.3">Agents can be seen as AI systems powered by LLMs that, given a user’s query, are able to interact with the surrounding ecosystem to the extent to which we allow them. </span><span class="koboSpan" id="kobo.304.4">The perimeter of the ecosystem is delimited by the tools (or plugins) we provide the agents with (in our previous example, we might provide the agent with a LinkedIn plugin so that it is able to post the generated content).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.305.1">Agents are made of the following ingredients:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.306.1">An LLM, which acts as the reasoning engine of the AI system.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.307.1">A system message, which instructs the agent to behave and think in a given way. </span><span class="koboSpan" id="kobo.307.2">For example, you can design an agent as a teaching assistant for students with the following system message: “You are a teaching assistant. </span><span class="koboSpan" id="kobo.307.3">Given a student’s query, NEVER provide the final answer, but rather provide some hints to get there.”</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.308.1">A set of tools the agent can leverage to interact with the surrounding ecosystem.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.309.1">AI agents are a perfect representation of the meaning of “LLM as reasoning engine of an application.” </span><span class="koboSpan" id="kobo.309.2">In fact, the beauty of agents is that they can pick the best tool to use to accomplish </span><a id="_idIndexMarker065"/><span class="koboSpan" id="kobo.310.1">a user’s request. </span><span class="koboSpan" id="kobo.310.2">For example, let’s say we have an AI agent to produce </span><a id="_idIndexMarker066"/><span class="koboSpan" id="kobo.311.1">LinkedIn content, and we provide it with two tools: a LinkedIn plugin and a web search plugin (each one with a correct description of its functionality). </span><span class="koboSpan" id="kobo.311.2">Let’s explore the behavior of the agent in three different scenarios:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.312.1">Generate a story about a little dog walking around the mountains</span></strong><span class="koboSpan" id="kobo.313.1">: The agent will generate the story without using a plugin.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.314.1">Generate a story about the current weather in Milan</span></strong><span class="koboSpan" id="kobo.315.1">: The agent will invoke the web search plugin to get the current weather in Milan.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.316.1">Generate a LinkedIn post about the current weather in Milan and publish it on my profile</span></strong><span class="koboSpan" id="kobo.317.1">: The agent will invoke the web search plugin to get the current weather in Milan and the LinkedIn plugin to post it on my profile.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.318.1">The combination of instructions and a set of plugins makes AI agents extremely versatile, and you can create highly specialized entities to address specific scenarios.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.319.1">And that’s not all.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.320.1">Why have only one agent if you can create your own crew of agents talking to and cooperating with each other? </span><span class="koboSpan" id="kobo.320.2">Imagine multiple agents, each one with a specific expertise and goal, communicating and interacting to accomplish a task. </span><span class="koboSpan" id="kobo.320.3">This is what </span><strong class="keyWord"><span class="koboSpan" id="kobo.321.1">multi-agent applications</span></strong><span class="koboSpan" id="kobo.322.1"> look like, and in </span><a id="_idIndexMarker067"/><span class="koboSpan" id="kobo.323.1">the last few months, this pattern started showing very interesting results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.324.1">Let’s consider the following example. </span><span class="koboSpan" id="kobo.324.2">We want to generate an elevator pitch about climate change. </span><span class="koboSpan" id="kobo.324.3">We need up-to-date information to do so (latest trends and research, future perspectives, and so on), as well as solid research grounded by academic papers. </span><span class="koboSpan" id="kobo.324.4">Plus, we need to be concise yet sharp and effective, delivering all the key information in a very short pitch.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.325.1">Now, we could ask a single agent to do all of that, providing it with all the required tools and long instructions to accomplish the task. </span><span class="koboSpan" id="kobo.325.2">However, if the task gets very complex, a single agent might not be the best approach as it might lead to inaccurate results. </span><span class="koboSpan" id="kobo.325.3">Instead, let’s use a multi-agent approach, creating a team with the following AI professionals:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.326.1">A market analyst who can search the web for the latest news about climate change: This will be an agent with a web search plugin and specific instructions to search for news.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.327.1">An expert researcher who can easily navigate through academic research papers about climate change: This will be an agent with an Arxiv (a curated research-sharing platform) plugin and specific instructions on how to retrieve relevant information.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.328.1">An expert in public speaking who can easily consolidate all the information in one elevator pitch: This will be an agent with instructions on how to deliver perfect pitches.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.329.1">A critic who will review the pitch and propose some changes to the expert in public speaking, if needed: This will be an agent with instructions on how to review and improve a pitch by identifying pitfalls and areas of improvement.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.330.1">So, when the user asks the agents to generate an elevator pitch about the current issue of climate change, all the agents can start working on the project.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.331.1">There are </span><a id="_idIndexMarker068"/><span class="koboSpan" id="kobo.332.1">many frameworks that can help developers with multi-agent applications (including AutoGen, LangGraph, and CrewAI), especially when it comes to the </span><em class="italic"><span class="koboSpan" id="kobo.333.1">flow</span></em><span class="koboSpan" id="kobo.334.1"> that we </span><a id="_idIndexMarker069"/><span class="koboSpan" id="kobo.335.1">want our agents to follow. </span><span class="koboSpan" id="kobo.335.2">For example, we might want to enforce a specific number of iterations; or that all agents are invoked at least once; or even to involve us, as users, in every iteration to provide further feedback to be incorporated in the upcoming iteration.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.336.1">At the time of writing, the multi-agent framework is showing promising advancements, and it is a glimpse of the outstanding reasoning capabilities behind LLMs and how they can unlock new ways of problem-solving.</span></p>
<h2 class="heading-2" id="_idParaDest-25"><span class="koboSpan" id="kobo.337.1">Small language models</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.338.1">LLMs are, unsurprisingly, large. </span><span class="koboSpan" id="kobo.338.2">This means that the architecture of an </span><strong class="keyWord"><span class="koboSpan" id="kobo.339.1">ANN</span></strong><span class="koboSpan" id="kobo.340.1"> featuring </span><a id="_idIndexMarker070"/><span class="koboSpan" id="kobo.341.1">LLMs is made of a huge number </span><a id="_idIndexMarker071"/><span class="koboSpan" id="kobo.342.1">of parameters, in the order of billions. </span><span class="koboSpan" id="kobo.342.2">Typically, a large number </span><a id="_idIndexMarker072"/><span class="koboSpan" id="kobo.343.1">of parameters is associated with a better-performing model, since it is able to deal with more information and examples and henceforth is able to recognize and infer more patterns the moment users ask their questions. </span><span class="koboSpan" id="kobo.343.2">However, with large numbers of parameters typically comes a high cost of training and hosting, since a powerful AI infrastructure is needed. </span><span class="koboSpan" id="kobo.343.3">Plus, the energy consumption of these models raises serious questions about the environmental impact of LLM training and their overall sustainability in the long run.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.344.1">These smaller models are called </span><strong class="keyWord"><span class="koboSpan" id="kobo.345.1">small language models</span></strong><span class="koboSpan" id="kobo.346.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.347.1">SLMs</span></strong><span class="koboSpan" id="kobo.348.1">) and, besides being lighter and less </span><a id="_idIndexMarker073"/><span class="koboSpan" id="kobo.349.1">demanding in terms of infrastructure, they are also showing surprisingly high performance.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.350.1">Now, we might think that GPT-3.5-turbo is deprecated; however, we have to remember that it used to be </span><a id="_idIndexMarker074"/><span class="koboSpan" id="kobo.351.1">the most powerful model on the market just one year ago, and it is </span><a id="_idIndexMarker075"/><span class="koboSpan" id="kobo.352.1">remarkable to see that a 7B model is capable of better results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.353.1">SLMs are definitely a research stream to keep an eye on, especially when it comes to scenarios where we might want to deploy a model locally or even customize it with fine-tuning (we will cover fine-tuning in the next chapter).</span></p>
<h1 class="heading-1" id="_idParaDest-26"><span class="koboSpan" id="kobo.354.1">Legal and ethical landscape of generative AI</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.355.1">When developing and deploying generative AI systems, a broad range of legal and ethical considerations </span><a id="_idIndexMarker076"/><span class="koboSpan" id="kobo.356.1">must be carefully addressed to ensure responsible and sustainable use. </span><span class="koboSpan" id="kobo.356.2">These considerations extend beyond mere compliance and enter a domain where moral responsibility, public trust, and technological accountability intersect.</span></p>
<h2 class="heading-2" id="_idParaDest-27"><span class="koboSpan" id="kobo.357.1">Copyright and intellectual property issues</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.358.1">LLMs are often trained on vast corpora scraped from the internet, including content that may be </span><a id="_idIndexMarker077"/><span class="koboSpan" id="kobo.359.1">copyrighted. </span><span class="koboSpan" id="kobo.359.2">As a result, there is a real risk of embedding copyrighted text, music, images, or video segments directly into AI output, inadvertently producing infringements when </span><a id="_idIndexMarker078"/><span class="koboSpan" id="kobo.360.1">these outputs are shared or commercialized.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.361.1">This concrete risk also escalated in November 2024, when major Canadian news organizations (</span><span class="url"><span class="koboSpan" id="kobo.362.1">https://www.reuters.com/sustainability/boards-policy-regulation/major-canadian-news-media-companies-launch-legal-action-against-openai-2024-11-29/</span></span><span class="koboSpan" id="kobo.363.1">), including The Globe and Mail and CBC/Radio-Canada, filed a lawsuit against OpenAI. </span><span class="koboSpan" id="kobo.363.2">They alleged that OpenAI used their copyrighted content without authorization to train its AI models, seeking damages and an injunction to prevent further unauthorized use.</span></p>
<h2 class="heading-2" id="_idParaDest-28"><span class="koboSpan" id="kobo.364.1">Misinformation, hallucinations, and the risk of fake news</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.365.1">One of </span><a id="_idIndexMarker079"/><span class="koboSpan" id="kobo.366.1">the known limitations of current </span><a id="_idIndexMarker080"/><span class="koboSpan" id="kobo.367.1">generative AI models </span><a id="_idIndexMarker081"/><span class="koboSpan" id="kobo.368.1">is their tendency to </span><strong class="keyWord"><span class="koboSpan" id="kobo.369.1">hallucinate</span></strong><span class="koboSpan" id="kobo.370.1"> – to produce entirely plausible-sounding but factually incorrect statements. </span><span class="koboSpan" id="kobo.370.2">This can result in the inadvertent spread of misinformation, especially when AI-generated content is taken at face value by consumers, journalists, or public officials.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.371.1">As an example, in December 2024, misinformation researcher Jeff Hancock (</span><span class="url"><span class="koboSpan" id="kobo.372.1">https://www.theverge.com/2024/12/4/24313132/jeff-hancock-minnesota-deepfake-law-ai-hallucinations-citation</span></span><span class="koboSpan" id="kobo.373.1">) admitted that ChatGPT fabricated details in a court filing he prepared, leading to the submission of non-existent citations. </span><span class="koboSpan" id="kobo.373.2">This incident emphasizes </span><a id="_idIndexMarker082"/><span class="koboSpan" id="kobo.374.1">the risk of AI-generated </span><a id="_idIndexMarker083"/><span class="koboSpan" id="kobo.375.1">content introducing </span><a id="_idIndexMarker084"/><span class="koboSpan" id="kobo.376.1">inaccuracies in critical documents.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.377.1">Continual exposure to unreliable AI output may lead to widespread skepticism regarding all digital content, undermining the credibility of legitimate sources and diminishing trust in expert commentary and reputable journalism. </span><span class="koboSpan" id="kobo.377.2">Organizations must therefore invest in factual verification processes, human-in-the-loop validation, and transparent model evaluation methods.</span></p>
<h2 class="heading-2" id="_idParaDest-29"><span class="koboSpan" id="kobo.378.1">Deepfakes and deceptive manipulation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.379.1">Deepfake </span><a id="_idIndexMarker085"/><span class="koboSpan" id="kobo.380.1">technology, an advanced subset of generative AI that synthesizes highly realistic images, videos, and voice recordings, can be weaponized to impersonate public figures, fabricate scandalous events, or produce manipulative political propaganda.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.381.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.382.1">A deepfake is </span><a id="_idIndexMarker086"/><span class="koboSpan" id="kobo.383.1">a type of artificial media created using DL algorithms, where a person’s likeness, voice, or movements are digitally manipulated to create realistic but fake content. </span><span class="koboSpan" id="kobo.383.2">Typically, deepfakes involve altering videos or images to make it appear as if someone said or did something they never actually did.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.384.1">A recent </span><a id="_idIndexMarker087"/><span class="koboSpan" id="kobo.385.1">example occurred back in 2023, when a finance clerk at a Hong Kong branch of a multinational corporation was deceived into transferring over $25 million after scammers used deepfake audio to impersonate senior executives, directing unauthorized fund transfers (</span><span class="url"><span class="koboSpan" id="kobo.386.1">https://www.secureworld.io/industry-news/hong-kong-deepfake-cybercrime</span></span><span class="koboSpan" id="kobo.387.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.388.1">Companies, governments, and individuals targeted by deepfakes may suffer severe reputational harm, leading to public embarrassment, financial losses, or diminished trust. </span><span class="koboSpan" id="kobo.388.2">Building detection tools, implementing digital watermarking techniques, and establishing legal frameworks that penalize malicious deepfake creators are crucial steps in mitigating these risks.</span></p>
<h2 class="heading-2" id="_idParaDest-30"><span class="koboSpan" id="kobo.389.1">Bias, discrimination, and social harm</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.390.1">Generative AI models can unintentionally reproduce and magnify existing societal prejudices present in </span><a id="_idIndexMarker088"/><span class="koboSpan" id="kobo.391.1">their training data. </span><span class="koboSpan" id="kobo.391.2">For example, models might consistently portray certain professions as male-dominated or depict particular cultural groups in stereotypical roles.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.392.1">These biased outputs can influence hiring decisions, product recommendations, and policy-making processes, ultimately disadvantaging underrepresented groups.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.393.1">In this regard, a 2023 study, </span><em class="italic"><span class="koboSpan" id="kobo.394.1">Demographic Stereotypes in Text-to-Image Generation </span></em><span class="koboSpan" id="kobo.395.1">(</span><span class="url"><span class="koboSpan" id="kobo.396.1">https://hai.stanford.edu/sites/default/files/2023-11/Demographic-Stereotypes.pdf</span></span><span class="koboSpan" id="kobo.397.1">), highlighted that text-to-image generative AI models tend to encode substantial </span><a id="_idIndexMarker089"/><span class="koboSpan" id="kobo.398.1">bias and stereotypes. </span><span class="koboSpan" id="kobo.398.2">For example, prompts requesting images of professionals often resulted in depictions aligning with traditional gender roles, such as male doctors and female nurses, thereby reinforcing outdated and discriminatory views.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.399.1">Another study, </span><em class="italic"><span class="koboSpan" id="kobo.400.1">Social Dangers of Generative Artificial Intelligence: Review and Guidelines</span></em><span class="koboSpan" id="kobo.401.1"> (</span><span class="url"><span class="koboSpan" id="kobo.402.1">https://dl.acm.org/doi/fullHtml/10.1145/3657054.3664243</span></span><span class="koboSpan" id="kobo.403.1">), investigates the extent to which </span><a id="_idIndexMarker090"/><span class="koboSpan" id="kobo.404.1">these technologies can exacerbate existing inequality. </span><span class="koboSpan" id="kobo.404.2">For instance, AI-generated content may marginalize certain communities by underrepresenting them or portraying them negatively, leading to social harm and reinforcing systemic discrimination.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.405.1">Organizations must commit to comprehensive bias audits, regularly updating training datasets, implementing fairness constraints, and involving diverse stakeholders in model development and evaluation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.406.1">These are just some examples of the potential risks and issues associated with generative AI. </span><span class="koboSpan" id="kobo.406.2">Furthermore, it is important to acknowledge that similar legal and ethical implications are not limited to generative AI, but rather they apply to the broader landscape of AI, whose applications have always been raising some concerns (for example, privacy considerations when it comes to face recognition).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.407.1">However, the extremely rapid evolvement and – most importantly – adoption of generative AI tools has highlighted the pressing need for organizations, policymakers, and developers to collaborate to craft robust governance frameworks that address the unique challenges posed by generative AI. </span><span class="koboSpan" id="kobo.407.2">This involves adopting standards for transparent data sourcing, obtaining explicit permissions for copyrighted content, implementing strict verification procedures to counter misinformation, and working closely with regulators to establish legal guardrails. </span><span class="koboSpan" id="kobo.407.3">It also demands that AI practitioners remain continuously vigilant in updating models, refining algorithms, and engaging with interdisciplinary experts to ensure that generative AI serves as a force for innovation and positive societal impact, rather than a source of harm or ethical compromise.</span></p>
<h1 class="heading-1" id="_idParaDest-31"><span class="koboSpan" id="kobo.408.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.409.1">In this chapter, we have explored the exciting world of generative AI and its various domains of application, including image generation, text generation, music generation, and video generation. </span><span class="koboSpan" id="kobo.409.2">We learned how generative AI models such as ChatGPT and DALL-E, trained by OpenAI, use DL techniques to learn patterns in large datasets and generate new content that is both novel and coherent. </span><span class="koboSpan" id="kobo.409.3">We also discussed the history of generative AI, its origins, and the current status of research on it.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.410.1">The goal of this chapter was to provide a solid foundation in the basics of generative AI and to inspire you to explore this fascinating field further.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.411.1">In the next chapter, we will focus on one of the most promising technologies available on the market today, ChatGPT. </span><span class="koboSpan" id="kobo.411.2">We will go through the research behind it and its development by OpenAI, the architecture of its model, and the main use cases it can address as of today.</span></p>
<h1 class="heading-1" id="_idParaDest-32"><span class="koboSpan" id="kobo.412.1">References</span></h1>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.413.1">Generative adversarial networks: </span><span class="url"><span class="koboSpan" id="kobo.414.1">https://arxiv.org/abs/1406.2661</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.415.1">Analyzing and improving the image quality of StyleGAN: </span><span class="url"><span class="koboSpan" id="kobo.416.1">https://arxiv.org/abs/1912.04958</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.417.1">Video-to-video synthesis: </span><span class="url"><span class="koboSpan" id="kobo.418.1">https://arxiv.org/abs/1808.06601</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.419.1">A deep generative model trifecta: Three advances that work towards harnessing large-scale power: </span><span class="url"><span class="koboSpan" id="kobo.420.1">https://www.microsoft.com/en-us/research/blog/a-deep-generative- model-trifecta-three-advances-that-work-towards-harnessing- large-scale-power/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.421.1">Vid2Vid: </span><span class="url"><span class="koboSpan" id="kobo.422.1">https://tcwang0509.github.io/vid2vid/</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.423.1">LLaMA: Open and Efficient Foundation Language Models: </span><span class="url"><span class="koboSpan" id="kobo.424.1">https://arxiv.org/pdf/2302.13971</span></span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.425.1">Introducing Phi-3: </span><span class="url"><span class="koboSpan" id="kobo.426.1">https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/</span></span></li>
</ul>
<h1 class="heading-1"><span class="koboSpan" id="kobo.427.1">Join our communities on Discord and Reddit</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.428.1">Have questions about the book or want to contribute to discussions on Generative AI and LLMs? </span><span class="koboSpan" id="kobo.428.2">Join our Discord server at </span><a href="Chapter_1.xhtml"><span class="url"><span class="koboSpan" id="kobo.429.1">https://packt.link/I1tSU</span></span></a><span class="koboSpan" id="kobo.430.1"> and our Reddit channel at </span><a href="Chapter_1.xhtml"><span class="url"><span class="koboSpan" id="kobo.431.1">https://packt.link/jwAmA</span></span></a><span class="koboSpan" id="kobo.432.1"> to connect, share, and collaborate with like-minded enthusiasts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.433.1"><img alt="" src="../Images/Discord.png"/></span> <span class="koboSpan" id="kobo.434.1"><img alt="" src="../Images/QR_Code757615820155951000.png"/></span></p>
</div>
</body></html>