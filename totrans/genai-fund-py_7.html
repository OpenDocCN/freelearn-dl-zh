<html><head></head><body>
<div id="_idContainer044">
<h1 class="chapter-number" id="_idParaDest-130"><a id="_idTextAnchor225"/><span class="koboSpan" id="kobo.1.1">7</span></h1>
<h1 id="_idParaDest-131"><a id="_idTextAnchor226"/><span class="koboSpan" id="kobo.2.1">Mastering the Fundamentals of Prompt Engineering</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In </span><a href="B21773_05.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.5.1">, we briefly evaluated a fine-tuned </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">Large Language Model</span></strong><span class="koboSpan" id="kobo.7.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.8.1">LLM</span></strong><span class="koboSpan" id="kobo.9.1">) against a general-purpose model using in-context learning or the few-shot prompting approach. </span><span class="koboSpan" id="kobo.9.2">In this chapter, we will revisit and explore prompting techniques to examine how well we can adapt a general-purpose LLM without fine-tuning. </span><span class="koboSpan" id="kobo.9.3">We explore various prompting strategies that leverage the model’s inherent capabilities to produce targeted and contextually relevant outputs. </span><span class="koboSpan" id="kobo.9.4">We will start by examining the shift toward prompt-based language models. </span><span class="koboSpan" id="kobo.9.5">Then, we will revisit zero- and few-shot methods, explain prompt-chaining, and </span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.10.1">discuss various strategies, including more advanced techniques such as </span><strong class="bold"><span class="koboSpan" id="kobo.11.1">Retrieval Augmented Generation</span></strong><span class="koboSpan" id="kobo.12.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.13.1">RAG</span></strong><span class="koboSpan" id="kobo.14.1">). </span><span class="koboSpan" id="kobo.14.2">At the end of the chapter, we will apply what we have learned and design a prompting strategy with the aim of consistently eliciting factual, accurate, and consistent responses that accomplish a specific </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">business task.</span></span></p>
<p><span class="koboSpan" id="kobo.16.1">Before diving into specific prompt engineering techniques, we will review a few breakthroughs </span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.17.1">that pioneered </span><strong class="bold"><span class="koboSpan" id="kobo.18.1">State-of-the-Art</span></strong><span class="koboSpan" id="kobo.19.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.20.1">SOTA</span></strong><span class="koboSpan" id="kobo.21.1">) prompt-based models. </span><span class="koboSpan" id="kobo.21.2">Research from early 2018 demonstrated how pretraining LLMs could enable few-shot generalization – accurate performance on new tasks given only a prompt statement and a few demonstrations. </span><span class="koboSpan" id="kobo.21.3">Follow-up work further tailored model architectures and training specifically for excelling at prompt-based inference across many text-specific tasks. </span><span class="koboSpan" id="kobo.21.4">More recent methods optimized model efficiency and stability, enabling accurate and reliable and efficient prompt completion. </span><span class="koboSpan" id="kobo.21.5">These innovations laid the groundwork for prompt engineering, demonstrating the remarkable versatility of prompt-based models with minimal input data. </span><span class="koboSpan" id="kobo.21.6">Now, prompt design is becoming its own subfield of research – unlocking SOTA performance for an ever-expanding range of tasks. </span><span class="koboSpan" id="kobo.21.7">Let’s </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">get started</span><a id="_idTextAnchor227"/><span class="koboSpan" id="kobo.23.1">.</span></span></p>
<h1 id="_idParaDest-132"><a id="_idTextAnchor228"/><span class="koboSpan" id="kobo.24.1">The shift to prompt-based approaches</span></h1>
<p><span class="koboSpan" id="kobo.25.1">As discussed in prior chapters, the development of the original GPT marked a significant advance in </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.26.1">natural language generation, introducing the use of prompts to instruct the model. </span><span class="koboSpan" id="kobo.26.2">This method allowed models such as GPT to perform tasks such as translations – converting text such as “</span><em class="italic"><span class="koboSpan" id="kobo.27.1">Hello, how are you?</span></em><span class="koboSpan" id="kobo.28.1">” to “</span><em class="italic"><span class="koboSpan" id="kobo.29.1">Bonjour, comment ça va?</span></em><span class="koboSpan" id="kobo.30.1">” – without task-specific training, leveraging deeply contextualized semantic patterns learned during pretraining. </span><span class="koboSpan" id="kobo.30.2">This concept of interacting with language models via natural language prompts was significantly expanded with OpenAI’s GPT-3 in 2020. </span><span class="koboSpan" id="kobo.30.3">Unlike its predecessors, GPT-3 showcased remarkable capabilities in understanding and responding to prompts in zero- and few-shot learning scenarios, a stark contrast to earlier models that weren’t as adept at such direct interactions. </span><span class="koboSpan" id="kobo.30.4">The methodologies, including the specific training strategies and datasets used for achieving GPT-3’s advanced performance, remain largely undisclosed. </span><span class="koboSpan" id="kobo.30.5">Nonetheless, it is inferred from OpenAI’s public research that the model learned to follow instructions based on its vast training corpus, and not explicit instruction-tuning. </span><span class="koboSpan" id="kobo.30.6">GPT-3’s success in performing tasks based on simple and direct prompting highlighted the potential for language models to understand and execute a wide range of tasks without requiring explicit task-specific training data for each new task. </span><span class="koboSpan" id="kobo.30.7">This led to a new paradigm in NLP research and applications, focusing on how effectively a model could be prompted with instructions to perform tasks such as summarization, translation, content generation, </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">and more.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">After the release of GPT-3, OpenAI was among the first to introduce specialized fine-tuning to respond more accurately to instructions in their release of InstructGPT (Ouyang et al., 2022). </span><span class="koboSpan" id="kobo.32.2">The researchers aimed to teach the model to closely follow instructions using </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.33.1">two novel approaches. </span><span class="koboSpan" id="kobo.33.2">The first was </span><strong class="bold"><span class="koboSpan" id="kobo.34.1">Supervised Fine-Tuning</span></strong><span class="koboSpan" id="kobo.35.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.36.1">SFT</span></strong><span class="koboSpan" id="kobo.37.1">), which involved fine-tuning using datasets carefully crafted from prompts and response pairs. </span><span class="koboSpan" id="kobo.37.2">These </span><em class="italic"><span class="koboSpan" id="kobo.38.1">demonstration</span></em><span class="koboSpan" id="kobo.39.1"> datasets were then used to perform SFT on top of the GPT-3 pretrained model, refining it to provide responses more closely aligned with human responses. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.40.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.41.1">.1</span></em><span class="koboSpan" id="kobo.42.1"> provides an example of a prompt and </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">response pair.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer041">
<span class="koboSpan" id="kobo.44.1"><img alt="Figure 7.1: InstructGPT SFT instruction and output pairs" src="image/B21773_07_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.45.1">Figure 7.1: InstructGPT SFT instruction and output pairs</span></p>
<p><span class="koboSpan" id="kobo.46.1">The second </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.47.1">approach involved additional refinement using </span><strong class="bold"><span class="koboSpan" id="kobo.48.1">Reinforcement Learning from Human Feedback</span></strong><span class="koboSpan" id="kobo.49.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.50.1">RLHF</span></strong><span class="koboSpan" id="kobo.51.1">). </span><strong class="bold"><span class="koboSpan" id="kobo.52.1">Reinforcement Learning</span></strong><span class="koboSpan" id="kobo.53.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.54.1">RL</span></strong><span class="koboSpan" id="kobo.55.1">), established decades ago, aims to enhance </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.56.1">autonomous agents’ decision-making capabilities. </span><span class="koboSpan" id="kobo.56.2">It does this by teaching them to optimize their actions based on the trade-off between risk and reward. </span><span class="koboSpan" id="kobo.56.3">The policy captures the guidelines for the agent’s behavior, dynamically updating </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.57.1">as new insights and feedback are learned to refine decisions further. </span><span class="koboSpan" id="kobo.57.2">RL is the exact technology used in many robotic applications and is most famously applied to </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">autonomous driving.</span></span></p>
<p><span class="koboSpan" id="kobo.59.1">RLHF is a variation of traditional RL, incorporating human feedback alongside the usual risk/reward signals to direct LLM behavior toward better alignment with human judgment. </span><span class="koboSpan" id="kobo.59.2">In practice, human labelers would provide preference ratings on model outputs from various prompts, and these ratings would be used to update the model policy, steering the LLM to generate responses that better conform to expected user intent across a range of tasks. </span><span class="koboSpan" id="kobo.59.3">In effect, this technique helped to reduce the model’s tendency to generate inappropriate, biased, harmful, or otherwise undesirable content. </span><span class="koboSpan" id="kobo.59.4">Although RLHF is not a perfect solution in this regard, it represents a significant step toward models that better understand and align with </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">human values.</span></span></p>
<p><span class="koboSpan" id="kobo.61.1">Later that </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.62.1">year, following OpenAI’s introduction of InstructGPT, Google unveiled </span><strong class="bold"><span class="koboSpan" id="kobo.63.1">Fine-tuned Language Net</span></strong><span class="koboSpan" id="kobo.64.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.65.1">FLAN</span></strong><span class="koboSpan" id="kobo.66.1"> (Wei et al., 2021). </span><span class="koboSpan" id="kobo.66.2">FLAN represented another leap toward prompt-based LLMs, employing explicit instruction tuning. </span><span class="koboSpan" id="kobo.66.3">Google’s approach relied on formatting existing datasets into instructions, enabling the model to understand various tasks. </span><span class="koboSpan" id="kobo.66.4">Specifically, the authors of FLAN merged multiple NLP datasets across different categories, such as translation and question answering, creating distinct instruction templates for each dataset to frame them as instruction-following tasks. </span><span class="koboSpan" id="kobo.66.5">For example, the FLAN team leveraged ANLI challenges (Nie et al., 2020) to construct question-answer pairs explicitly designed to test the model’s understanding of complex textual relationships and reasoning. </span><span class="koboSpan" id="kobo.66.6">By framing these challenges as </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.67.1">question-answer pairs, the FLAN team could directly measure a model’s proficiency in deducing these relationships under a unified instruction-following framework. </span><span class="koboSpan" id="kobo.67.2">Through this innovative approach, FLAN effectively broadened the scope of tasks a model can learn from, enhancing its overall performance and adaptability across a diverse set of NLU benchmarks. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.68.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.69.1">.2</span></em><span class="koboSpan" id="kobo.70.1"> presents a theoretical example of question-answer pairs based </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">on ANLI.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer042">
<span class="koboSpan" id="kobo.72.1"><img alt="Figure 7.2: Training templates based on the ANLI dataset" src="image/B21773_07_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.73.1">Figure 7.2: Training templates based on the ANLI dataset</span></p>
<p><span class="koboSpan" id="kobo.74.1">Again, the central idea behind FLAN was that each benchmark dataset (e.g., ANLI) could be translated into an intuitive instruction format, yielding a broad mixture of instructional data and natural </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">language tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.76.1">These advancements, among others, represent a significant evolution in the capabilities of LLMs, transitioning from models that required specific training for each task to those that can intuitively follow instructions and adapt to a multitude of tasks with a simple prompt. </span><span class="koboSpan" id="kobo.76.2">This shift has not only broadened the scope of tasks these models can perform but also demonstrated the potential for AI to process and generate human language in complex ways with </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">unprecedented precision.</span></span></p>
<p><span class="koboSpan" id="kobo.78.1">With this </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.79.1">insight, we can shift our focus to prompt engineering. </span><span class="koboSpan" id="kobo.79.2">This discipline combines technical skill, creativity, and human psychology to maximize how models comprehend and respond, appropriately and accurately, to instructions. </span><span class="koboSpan" id="kobo.79.3">We will learn prompting techniques that increasingly influence the model’s behavior </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">toward pre</span><a id="_idTextAnchor229"/><span class="koboSpan" id="kobo.81.1">cision.</span></span></p>
<h1 id="_idParaDest-133"><a id="_idTextAnchor230"/><span class="koboSpan" id="kobo.82.1">Basic prompting – guiding principles, types, and structures</span></h1>
<p><span class="koboSpan" id="kobo.83.1">In </span><a href="B21773_05.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.84.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.85.1">, we introduced the concept of zero- and few-shot learning, providing the model either </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.86.1">a direct instruction, or a direct instruction paired with examples specific to the task. </span><span class="koboSpan" id="kobo.86.2">In this section, we will focus on zero-shot learning, where prompting becomes a critical tool for guiding the model to perform specific tasks without prior explicit training on those tasks. </span><span class="koboSpan" id="kobo.86.3">This section explores elements of a prompt and how to structure it effectively for zero-shot learning. </span><span class="koboSpan" id="kobo.86.4">However, we will first establish some critical guiding principles to help us understand expected </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">model b</span><a id="_idTextAnchor231"/><span class="koboSpan" id="kobo.88.1">ehavior.</span></span></p>
<h2 id="_idParaDest-134"><a id="_idTextAnchor232"/><span class="koboSpan" id="kobo.89.1">Guiding principles for model interaction</span></h2>
<p><span class="koboSpan" id="kobo.90.1">It is absolutely critical to understand that LLMs, despite their unprecedented SOTA performance </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.91.1">on natural </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.92.1">language tasks, have significant inherent limitations, weaknesses, and susceptibilities. </span><span class="koboSpan" id="kobo.92.2">As described in </span><a href="B21773_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.93.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.94.1">, LLMs cannot establish rationale or perform logical operations natively. </span><span class="koboSpan" id="kobo.94.2">Our interactions with LLMs are typically supplemented by a highly sophisticated application layer that enables the raw model to carry on an extended exchange, integrate with systems that perform computations, and retrieve additional information and knowledge not intrinsic to the model itself. </span><span class="koboSpan" id="kobo.94.3">Independent of supplemental integrations, many LLMs are prone to erratic behavior. </span><span class="koboSpan" id="kobo.94.4">The most common </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.95.1">of these is often referred to as </span><strong class="bold"><span class="koboSpan" id="kobo.96.1">hallucination</span></strong><span class="koboSpan" id="kobo.97.1">, where the model generates a plausible output that is not entirely factual. </span><span class="koboSpan" id="kobo.97.2">As such, we should approach the general use of LLMs with the following guidelines </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">in mind:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.99.1">Apply domain knowledge and subject-matter expertise</span></strong><span class="koboSpan" id="kobo.100.1">: As SOTA LLMs are prone to generating inaccuracies that sound plausible, in use cases where factuality and precision are essential (e.g., code generation, technical writing, or academic research), users must have a firm grasp of the subject matter to detect potential inaccuracies. </span><span class="koboSpan" id="kobo.100.2">For example, suppose a user without medical expertise were to prompt a model for healthcare advice. </span><span class="koboSpan" id="kobo.100.3">In that case, the model may confuse, conflate, or simply invent information that could result in misleading or potentially dangerous advice. </span><span class="koboSpan" id="kobo.100.4">A mitigant for this behavior could be to provide the model with information from a reputable health journal and instruct </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.101.1">it to generate its answers explicitly from the passages provided. </span><span class="koboSpan" id="kobo.101.2">This technique is often </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.102.1">called grounding, and we will cover it in depth later. </span><span class="koboSpan" id="kobo.102.2">However, even when supplementing the model’s knowledge with verified information, the model </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.103.1">can still misrepresent facts. </span><span class="koboSpan" id="kobo.103.2">Without expertise in the specific domain in question, we may never detect misinformation. </span><span class="koboSpan" id="kobo.103.3">Consequently, we should generally avoid using LLMs when we cannot verify the model output. </span><span class="koboSpan" id="kobo.103.4">Moreover, we should avoid using LLMs in high-stake scenarios where erroneous output could have </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">profound implications.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.105.1">Acknowledge bias, underrepresentation, and toxicity</span></strong><span class="koboSpan" id="kobo.106.1">: We have described how LLMs are trained at an enormous scale and often on uncurated datasets. </span><span class="koboSpan" id="kobo.106.2">Inevitably, LLMs will learn, exhibit, and amplify societal biases. </span><span class="koboSpan" id="kobo.106.3">The model will propagate stereotypes, reflect biased assumptions, and generate toxic and harmful content. </span><span class="koboSpan" id="kobo.106.4">Moreover, LLMs can overrepresent certain populations and grossly underrepresent others, leading to a skewed or warped sociological perspective. </span><span class="koboSpan" id="kobo.106.5">These notions of bias can manifest in many ways. </span><span class="koboSpan" id="kobo.106.6">We will explore this topic, and other ethical implications of LLM use, in detail in </span><a href="B21773_08.xhtml#_idTextAnchor251"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.107.1">Chapter 8</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.108.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.109.1">Avoid ambiguity and lack of clarity</span></strong><span class="koboSpan" id="kobo.110.1">: Since LLMs were trained to synthesize information resembling human responses, they can often exhibit notions of creativity. </span><span class="koboSpan" id="kobo.110.2">In practice, if prompting is ambiguous or lacks clarity, the model will likely use its vast contextualized knowledge to “assume” or “infer” the meaning or objective of a given prompt or instruction. </span><span class="koboSpan" id="kobo.110.3">It may apply some context from its training instead of responding with a clarifying question. </span><span class="koboSpan" id="kobo.110.4">As we will describe in the next section, it is crucial to provide clarity by contextualizing input in </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">most cases.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.112.1">Now that </span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.113.1">we have established </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.114.1">a few overarching principles to help navigate interactions and keep us within the boundaries of appropriate use, we can deconstruct the various eleme</span><a id="_idTextAnchor233"/><span class="koboSpan" id="kobo.115.1">nts of </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">a prompt.</span></span></p>
<h2 id="_idParaDest-135"><a id="_idTextAnchor234"/><span class="koboSpan" id="kobo.117.1">Prompt elements and structure</span></h2>
<p><span class="koboSpan" id="kobo.118.1">Generally, a prompt acts as a guide, directing the model’s response toward the desired outcome. </span><span class="koboSpan" id="kobo.118.2">It </span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.119.1">typically comprises key elements that frame the task at hand, providing clarity and direction </span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.120.1">for the model’s generative capabilities. </span><span class="koboSpan" id="kobo.120.2">The following table presents the essential elements of a </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">zero-shot prompt.</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-4">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.122.1">Instruction</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.123.1">A clear, concise statement describing what you want the model to do. </span><span class="koboSpan" id="kobo.123.2">This could be a direct command, a question, or a statement that implies </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">a task.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.125.1">Context</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.126.1">Relevant information or background is needed to understand the instruction or the task. </span><span class="koboSpan" id="kobo.126.2">This could include definitions </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">or clarifications.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.128.1">Input</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.129.1">Following the instructions, the model should work with specific data or content. </span><span class="koboSpan" id="kobo.129.2">This could be a piece of text, a question, or any information relevant to </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">the task.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.131.1">Output cue</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.132.1">An indication of how the model’s response is to be structured. </span><span class="koboSpan" id="kobo.132.2">This can be part of the instruction or implied through the </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">prompt’s formatting.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.134.1">Table 7.1: Basic elements of a zero-shot prompt</span></p>
<p><span class="koboSpan" id="kobo.135.1">We can then structure these elements to maximize the zero-shot approach, whereby the model relies entirely on the prompt to understand and execute a task. </span><span class="koboSpan" id="kobo.135.2">In this context, we use the term </span><em class="italic"><span class="koboSpan" id="kobo.136.1">task</span></em><span class="koboSpan" id="kobo.137.1"> to describe a specific natural language task, such as summarization or translation. </span><span class="koboSpan" id="kobo.137.2">However, we will also encounter the term </span><em class="italic"><span class="koboSpan" id="kobo.138.1">task</span></em><span class="koboSpan" id="kobo.139.1"> applied more </span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.140.1">broadly to refer to the output the model should provide. </span><span class="koboSpan" id="kobo.140.2">Let’s explore a few concrete examples </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.141.1">of various tasks. </span><span class="koboSpan" id="kobo.141.2">In this case, we will be referring to specific NLP tasks and applying a standard structure combining the key elements </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">we’ve described:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.143.1">Example 1</span></strong><span class="koboSpan" id="kobo.144.1">: </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.145.1">Summarization task</span></strong></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.146.1">Instruction</span></strong><span class="koboSpan" id="kobo.147.1">: Summarize the following text in </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">one sentence.</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.149.1">Context</span></strong><span class="koboSpan" id="kobo.150.1">: The text </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.151.1">provides an overview of the benefits of </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">renewable energy.</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.153.1">Input</span></strong><span class="koboSpan" id="kobo.154.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.155.1">Renewable energy sources like solar and wind power offer sustainable alternatives to fossil fuels, reducing greenhouse gas emissions and promoting </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.156.1">environmental conservation...</span></strong></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.157.1">Output Cue</span></strong><span class="koboSpan" id="kobo.158.1">: Renewable energy sources, </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">such as</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.160.1">Example Outcome</span></strong><span class="koboSpan" id="kobo.161.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.162.1">"Renewable energy sources, such as solar and wind, play a crucial role in reducing emissions and conserving </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.163.1">the environment."</span></strong></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.164.1">Example 2</span></strong><span class="koboSpan" id="kobo.165.1">: </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.166.1">Translation task</span></strong></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.167.1">Instruction</span></strong><span class="koboSpan" id="kobo.168.1">: Translate </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.169.1">the following sentence from English </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">to Spanish.</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.171.1">Context</span></strong><span class="koboSpan" id="kobo.172.1">: The sentence is </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">a greeting.</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.174.1">Input</span></strong><span class="koboSpan" id="kobo.175.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.176.1">"Hello, how </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.177.1">are you?"</span></strong></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.178.1">Output Cue</span></strong><span class="koboSpan" id="kobo.179.1">: This </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">translates to</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.181.1">Example Outcome</span></strong><span class="koboSpan" id="kobo.182.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.183.1">This translates to "Hola, ¿</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.184.1">cómo estás?"</span></strong></span></p><p class="list-inset"><span class="koboSpan" id="kobo.185.1">The structured templates help us to efficiently and reliably prompt the model for a wide range of inputs, while maintaining a structure that the model has learned to </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.186.1">recognize and respond to. </span><span class="koboSpan" id="kobo.186.2">In fact, we can take this a step further by asking the model to provide a specific format in its output. </span><span class="koboSpan" id="kobo.186.3">Using the output cue, we can instruct the model to provide a specified format such </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">as Markdown.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.188.1">Example 3</span></strong><span class="koboSpan" id="kobo.189.1">: </span><strong class="bold"><span class="koboSpan" id="kobo.190.1">Code </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.191.1">generation task</span></strong></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.192.1">Instruction</span></strong><span class="koboSpan" id="kobo.193.1">: Generate </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.194.1">a Python function that calculates the square of </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">a number.</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.196.1">Context</span></strong><span class="koboSpan" id="kobo.197.1">: The function should take a single integer argument and return </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">its square.</span></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.199.1">Input</span></strong><span class="koboSpan" id="kobo.200.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.201.1">"Please write a Python function to calculate the square of </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.202.1">a number."</span></strong></span></p><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.203.1">Output Cue</span></strong><span class="koboSpan" id="kobo.204.1">: By using the Markdown format in the output cue, the model knows to provide this format and returns </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">the following:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.206.1">
def square(number):</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.207.1">
    return number ** 2</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.208.1">Using LangChain to produce JSON-formatted output, we can leverage the same approach. </span><span class="koboSpan" id="kobo.208.2">Specifically, LangChain’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.209.1">PromptTemplate</span></strong><span class="koboSpan" id="kobo.210.1"> provides a flexible way to dynamically define a structure for our prompts and </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">insert elements:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.212.1">
from langchain.prompts import PromptTemplate</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.213.1">
from langchain.llms import OpenAI</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.214.1">
# Define a prompt template requesting JSON formatted output</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.215.1">
prompt_structure = PromptTemplate(</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.216.1">
    template="""</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.217.1">
        Context: {context}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.218.1">
        Instruction: {instruction}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.219.1">
        Text: {text_to_process}</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.220.1">
        Output Cue: Format the response in JSON with one element called summary.</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.221.1">
    """,</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.222.1">
    input_variables=["context," "instruction",</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.223.1">
        "text_to_process"]</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.224.1">
)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.225.1">
# Dynamic elements for the prompt</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.226.1">
context = "Summarizing long text passages."</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.227.1">
instruction = "Summarize the key points from the following text in JSON format."</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.228.1">
text_to_process = """</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.229.1">
Mars is the fourth planet from the Sun. </span><span class="koboSpan" id="kobo.229.2">The surface of Mars is orange-red because…</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.230.1">
"""</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.231.1">
formatted_prompt = prompt_structure.format_prompt(</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.232.1">
    context=context,</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.233.1">
    instruction=instruction,</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.234.1">
    text_to_process=text_to_process</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.235.1">
)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.236.1">
llm = OpenAI(model_name='gpt-3.5-turbo-instruct',</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.237.1">
    temperature=0.9, max_tokens = 256)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.238.1">
response = llm.invoke(formatted_prompt)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.239.1">
print(response)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.240.1">This produces </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">the following:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.242.1">
{</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.243.1">
    "summary": "Mars is the fourth planet from the Sun, known for its orange-red surface and high-contrast features that make it a popular object for telescope viewing."</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.244.1">
}</span></pre></li>
</ul>
<p><span class="koboSpan" id="kobo.245.1">Crafting </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.246.1">effective prompts for zero-shot learning with LLMs requires a clear understanding of the task, thoughtful </span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.247.1">structuring of the prompt, and consideration of how the model interprets and responds to different elements within the prompt. </span><span class="koboSpan" id="kobo.247.2">By applying these principles, we can guide models to perform various tasks accurately and effectively. </span><span class="koboSpan" id="kobo.247.3">Subsequently, we will explore methods to guide models’ behavior through positive affirmations, emotional engagement, and other </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">cognitive-behavioral tech</span><a id="_idTextAnchor235"/><span class="koboSpan" id="kobo.249.1">niques.</span></span></p>
<h1 id="_idParaDest-136"><a id="_idTextAnchor236"/><span class="koboSpan" id="kobo.250.1">Elevating prompts – iteration and influencing model behaviors</span></h1>
<p><span class="koboSpan" id="kobo.251.1">In this section, we will </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.252.1">introduce techniques for enhancing AI model interactions inspired by cognitive-behavioral research. </span><span class="koboSpan" id="kobo.252.2">Behavioral prompting can guide models toward more accurate and nuanced responses. </span><span class="koboSpan" id="kobo.252.3">For example, LLM performance can be improved by providing the model with positive emotional stimuli, asking the model to assume a persona or character, or using situational prompting (i.e., role-play). </span><span class="koboSpan" id="kobo.252.4">However, it is crucial to recognize that these techniques can also be misused or used to inadvertently introduce stereotypes, as they rely on assumptions and generalizations that may not accurately reflect individual experiences or diverse perspectives. </span><span class="koboSpan" id="kobo.252.5">Without careful consideration and monitoring, there is a risk of reinforcing existing biases or </span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.253.1">creating new ones, potentially leading to skewed or harmful output. </span><span class="koboSpan" id="kobo.253.2">Given these challenges, we will explore a responsible approach to employing cognitive-behavioral techniques in AI interactions, aiming to harness their benefits while minimizing risks and ensuring inclusivity </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">and </span><a id="_idTextAnchor237"/><span class="koboSpan" id="kobo.255.1">fairness.</span></span></p>
<h2 id="_idParaDest-137"><a id="_idTextAnchor238"/><span class="koboSpan" id="kobo.256.1">LLMs respond to emotional cues</span></h2>
<p><span class="koboSpan" id="kobo.257.1">Research conducted by Microsoft in collaboration with various institutions, including the Beijing Normal University psychology department, suggests that LLMs can mimic and display some </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.258.1">aspects of human emotional intelligence. </span><span class="koboSpan" id="kobo.258.2">This can lead to improved task performance when prompts are infused with emotional stimuli. </span><span class="koboSpan" id="kobo.258.3">In particular, the researchers hypothesize that emphasizing positive words can trigger more constructive and effective responses. </span><span class="koboSpan" id="kobo.258.4">The phenomenon is not well understood, but the effect is that positive emotional cues seem to improve model performance on various tasks consistently (Li et al., 2023). </span><span class="koboSpan" id="kobo.258.5">For example, the researchers input phrases encouraging confidence and positive outcomes, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.259.1">This is very important to my career</span></strong><span class="koboSpan" id="kobo.260.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.261.1">Believe in your abilities and strive for excellence. </span><span class="koboSpan" id="kobo.261.2">Your hard work will yield remarkable results</span></strong><span class="koboSpan" id="kobo.262.1">. </span><span class="koboSpan" id="kobo.262.2">These types of psychological elements not only positively influenced the output quality but also made interactions more effective </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">an</span><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.264.1">d nuanced.</span></span></p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor240"/><span class="koboSpan" id="kobo.265.1">Effect of personas</span></h2>
<p><span class="koboSpan" id="kobo.266.1">Research has shown that the effect of </span><strong class="bold"><span class="koboSpan" id="kobo.267.1">personas</span></strong><span class="koboSpan" id="kobo.268.1"> enables LLMs to better simulate human-like </span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.269.1">interactions by adopting varied characteristics, perspectives, and response styles tailored to specific user profiles. </span><span class="koboSpan" id="kobo.269.2">This approach enhances the model’s capability for engaging in more personalized, contextually relevant conversations. </span><span class="koboSpan" id="kobo.269.3">Incorporating personas into LLM prompts effectively shifts the distribution of possible outputs, directing the model’s generation process toward responses that resonate with specific character traits or perspectives. </span><span class="koboSpan" id="kobo.269.4">Thanks to the model’s extensive training on diverse datasets, it can replicate patterns aligning with the described characteristics of personas, focusing its attention and selection process on a more defined set of outputs. </span><span class="koboSpan" id="kobo.269.5">This enhances relevance </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">and specificity.</span></span></p>
<p><span class="koboSpan" id="kobo.271.1">For clarity, let’s reconsider our hypothetical business StyleSprint, a fashion brand. </span><span class="koboSpan" id="kobo.271.2">If we prompt an LLM with “</span><strong class="source-inline"><span class="koboSpan" id="kobo.272.1">As a creative and bold fashion brand, how would StyleSprint describe its upcoming summer collection?</span></strong><span class="koboSpan" id="kobo.273.1">”, the model, adopting the brand’s persona, might generate a response such as </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">the following:</span></span></p>
<p><span class="koboSpan" id="kobo.275.1">“</span><strong class="source-inline"><span class="koboSpan" id="kobo.276.1">This summer, StyleSprint dares you to stand out! </span><span class="koboSpan" id="kobo.276.2">Our collection is a vibrant explosion of colors and patterns, designed for the fearless fashionista. </span><span class="koboSpan" id="kobo.276.3">Think bold prints, daring cuts, and a statement that screams confidence. </span><span class="koboSpan" id="kobo.276.4">From sun-drenched beaches to chic city streets, our pieces promise to make every moment unforgettable. </span><span class="koboSpan" id="kobo.276.5">Embrace your boldness with StyleSprint </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">this summer.</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">”.</span></span></p>
<p><span class="koboSpan" id="kobo.279.1">In this example, we can see how personas guide the model’s outputs to reflect specific brand tones, such as creativity and boldness in this case, making the marketing material more engaging </span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.280.1">and aligned with the brand’s identity. </span><span class="koboSpan" id="kobo.280.2">Furthermore, using a few-shot approach, we could imbue model responses with a very specific branded tone. </span><span class="koboSpan" id="kobo.280.3">We will discuss few-shot in the sections </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">that follow.</span></span></p>
<p><span class="koboSpan" id="kobo.282.1">However, as discussed, personas should be used with caution. </span><span class="koboSpan" id="kobo.282.2">Personas can perpetuate stereotypes and biases, particularly against marginalized groups. </span><span class="koboSpan" id="kobo.282.3">A study conducted by researchers at Stanford University found that generating personas based on intersectional demographic groups often yields higher rates of racial stereotypes and patterns of </span><strong class="bold"><span class="koboSpan" id="kobo.283.1">othering</span></strong><span class="koboSpan" id="kobo.284.1">, or portraying someone or a group as fundamentally different or alien, compared to human-written texts. </span><span class="koboSpan" id="kobo.284.2">In some cases, model outputs could amplify narratives and tropes (Cheng, Durmus, &amp; </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">Jura</span><a id="_idTextAnchor241"/><span class="koboSpan" id="kobo.286.1">fsky, 2023).</span></span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor242"/><span class="koboSpan" id="kobo.287.1">Situational prompting or role-play</span></h2>
<p><span class="koboSpan" id="kobo.288.1">Role-play </span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.289.1">in LLMs, in the same way as personas, involves </span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.290.1">adopting specific identities or characteristics. </span><span class="koboSpan" id="kobo.290.2">However, the two serve different purposes and are applied in distinct contexts. </span><span class="koboSpan" id="kobo.290.3">Personas are predefined sets of traits or characteristics that an LLM mimics to tailor its responses, focusing on consistency with those traits. </span><span class="koboSpan" id="kobo.290.4">As we have demonstrated with our StyleSprint example, this is useful for creating content with a specific tone </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">or perspective.</span></span></p>
<p><span class="koboSpan" id="kobo.292.1">Conversely, role-play extends beyond adopting a set of traits to engage in a scenario or narrative dynamically. </span><span class="koboSpan" id="kobo.292.2">It involves the LLM taking on a character within a simulated environment or story, responding to inputs in a manner that aligns with both a persona and the evolving </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.293.1">context of the role-play scenario. </span><span class="koboSpan" id="kobo.293.2">This can be especially useful in complex simulations where the LLM must navigate and </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.294.1">contribute to ongoing narratives or dialogues that require understanding and adapting to new information or changing circumstances in </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">real time.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<span class="koboSpan" id="kobo.296.1"><img alt="Figure 7.3﻿: Persona versus role-play" src="image/B21773_07_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.297.1">Figure 7.3: Persona versus role-play</span></p>
<p><span class="koboSpan" id="kobo.298.1">Revisiting our real-world scenario, role-play could be particularly useful for creating interactive and engaging customer service experiences. </span><span class="koboSpan" id="kobo.298.2">For example, StyleSprint could design a role-play scenario where the LLM acts as a virtual personal stylist. </span><span class="koboSpan" id="kobo.298.3">In this role, the model would engage customers with prompts such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.299.1">I'm your personal stylist for today! </span><span class="koboSpan" id="kobo.299.2">What's the occasion you're dressing for?</span></strong><span class="koboSpan" id="kobo.300.1">. </span><span class="koboSpan" id="kobo.300.2">Based on the customer’s response, the LLM could ask follow-up questions to narrow down preferences, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.301.1">Do you prefer bold colors or pastel shades?</span></strong><span class="koboSpan" id="kobo.302.1">. </span><span class="koboSpan" id="kobo.302.2">Finally, it could recommend outfits from StyleSprint’s collection that match the customer’s needs, saying something such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.303.1">For a summer wedding, I recommend our Floral Maxi Dress paired with the Vintage Sun Hat. </span><span class="koboSpan" id="kobo.303.2">It's elegant, yet perfect for an </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.304.1">outdoor setting!</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.306.1">In this case, we leverage the LLM’s ability to dynamically adapt its dialogue based on customer inputs to create an advanced recommender system that facilitates a highly personalized shopping experience. </span><span class="koboSpan" id="kobo.306.2">It not only helps in providing tailored fashion advice but also engages customers in a </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">novel way.</span></span></p>
<p><span class="koboSpan" id="kobo.308.1">Having examined how behavior-inspired techniques, such as personas and role-play, influence model behavior through zero-shot learning, let’s now turn our attention to few-shot learning. </span><span class="koboSpan" id="kobo.308.2">This is also known as in-context learning, which we described in </span><a href="B21773_05.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.309.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.310.1">. </span><span class="koboSpan" id="kobo.310.2">Recall that the few-shot approach can enhance the consistency, stability, and reliability </span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.311.1">of model responses. </span><span class="koboSpan" id="kobo.311.2">By providing the model with a few examples of the desired output within the prompt itself, few-shot learning effectively teaches the model the specific task at hand, leading to more predictable and </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">a</span><a id="_idTextAnchor243"/><span class="koboSpan" id="kobo.313.1">ccurate outputs.</span></span></p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor244"/><span class="koboSpan" id="kobo.314.1">Advanced prompting in action – few-shot learning and prompt chaining</span></h1>
<p><span class="koboSpan" id="kobo.315.1">In few-shot settings, the LLM is presented with a small number of examples of a task within the input </span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.316.1">prompt, guiding the model to generate responses that align with these examples. </span><span class="koboSpan" id="kobo.316.2">As discussed in the prior chapter, this method significantly </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.317.1">reduces the need for fine-tuning on large, task-specific datasets. </span><span class="koboSpan" id="kobo.317.2">Instead, it leverages the model’s pre-existing knowledge and ability to infer context from the examples provided. </span><span class="koboSpan" id="kobo.317.3">In </span><a href="B21773_05.xhtml#_idTextAnchor180"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.318.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.319.1">, we saw how this approach was particularly useful for StyleSprint by enabling the model to answer specific questions after being provided with just a few examples, enhancing consistency and creativity in </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">brand messaging.</span></span></p>
<p><span class="koboSpan" id="kobo.321.1">This method typically involves using between 10 and 100 examples, depending on the model’s context window. </span><span class="koboSpan" id="kobo.321.2">Recall that the context window is the limit of tokens a language model can process in one turn. </span><span class="koboSpan" id="kobo.321.3">The primary benefit of the few-shot approach is that it minimizes the risk of the model learning a too-narrow distribution from a specific dataset through fine-tuning. </span><span class="koboSpan" id="kobo.321.4">Although the performance of few-shot may not always match its fine-tuned counterpart, few-shot learning often outperforms both one-shot and zero-shot learning, showing significant improvements in task adaptation and accuracy. </span><span class="koboSpan" id="kobo.321.5">This is especially true as more examples are added to the context window (Brown et </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">al., 2020).</span></span></p>
<p><span class="koboSpan" id="kobo.323.1">Applications such as LangChain provide a simple and convenient pattern for few-shot implementation. </span><span class="koboSpan" id="kobo.323.2">Consider a scenario in which StyleSprint would like to generate taglines for its seasonal collections. </span><span class="koboSpan" id="kobo.323.3">In this case, we can provide the model with examples written by the content team to guide the model toward consistency with the </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">brand tone:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.325.1">
examples = [
    {
        "prompt": "Describe the new summer collection in a bold and adventurous tone.",
        "response": "Dive into summer with StyleSprint's latest collection! </span><span class="koboSpan" id="kobo.325.2">Featuring daring designs and vibrant colors, it's all about making bold statements. </span><span class="koboSpan" id="kobo.325.3">Perfect for the fearless fashionista ready to conquer the heat."
</span><span class="koboSpan" id="kobo.325.4">    },
    {
        "prompt": "How would you introduce our eco-friendly line to environmentally conscious customers?",
        "response": "Embrace sustainable style with StyleSprint's eco-friendly line. </span><span class="koboSpan" id="kobo.325.5">Crafted from recycled materials, each piece combines fashion with responsibility, designed for the eco-conscious and trendy."
</span><span class="koboSpan" id="kobo.325.6">    }
]</span></pre>
<p><span class="koboSpan" id="kobo.326.1">The LangChain API </span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.327.1">offers </span><strong class="source-inline"><span class="koboSpan" id="kobo.328.1">FewShotPromptTemplate</span></strong><span class="koboSpan" id="kobo.329.1"> to format the </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1">examples </span></span><span class="No-Break"><a id="_idIndexMarker559"/></span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">consistently:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.332.1">
from langchain.prompts.few_shot import FewShotPromptTemplate
from langchain.prompts.prompt import PromptTemplate
# Create a formatter
prompt_format = PromptTemplate(
    input_variables=["prompt", "response"],
    template="Prompt: {prompt}\nResponse: {response}")
# Create the FewShotPromptTemplate
few_shot_prompt = FewShotPromptTemplate(
    examples=examples, example_prompt=prompt_format,
    suffix="Prompt: {input}", input_variables=["input"])</span></pre>
<p><span class="koboSpan" id="kobo.333.1">We can now </span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.334.1">apply the template to an LLM to generate a response that we </span><a id="_idIndexMarker561"/><span class="koboSpan" id="kobo.335.1">can expect will closely align with the tone and style of </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">our examples:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.337.1">
from langchain import LLMChain, OpenAI
# Setup the LLM and LLMChain
llm = OpenAI(temperature=0)
llm_chain = LLMChain(llm=llm, prompt=few_shot_prompt)
# Define the input prompt
input_prompt = "Create a catchy tagline for our winter collection."
</span><span class="koboSpan" id="kobo.337.2"># Invoke the chain to generate output
response = llm_chain.run(input_prompt)
# Extract and print the generated slogan
generated_slogan = response
print(generated_slogan) 
    # =&gt; Response: "Stay warm,
    stay stylish,
    stay ahead with StyleSprint's winter collection!"</span></pre>
<p><span class="koboSpan" id="kobo.338.1">Now that we have a consistent and programmatic method for providing the model with examples, we can iterate over the model responses using prompt chaining. </span><span class="koboSpan" id="kobo.338.2">A prompt chain generally </span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.339.1">refers to chaining together multiple prompts and LLM interactions to have a conversation with the model and iteratively build on the results. </span><span class="koboSpan" id="kobo.339.2">Remember, the model itself cannot store information and effectively has no memory or </span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.340.1">prior inputs and outputs. </span><span class="koboSpan" id="kobo.340.2">Instead, the application layer stores prior inputs and outputs, which are then provided to the model with each exchange. </span><span class="koboSpan" id="kobo.340.3">For example, you might start with an initial prompt such as </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">the following:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.342.1">
"Write a slogan for a winter clothing line"</span></pre>
<p><span class="koboSpan" id="kobo.343.1">The LLM might generate </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">the following:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.345.1">
"Be warm, be cozy, be you"</span></pre>
<p><span class="koboSpan" id="kobo.346.1">You could then construct a follow-up prompt using </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">the following:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.348.1">
"Modify the slogan to be more specific about the quality of the clothing"</span></pre>
<p><span class="koboSpan" id="kobo.349.1">You could then keep iterating to improve </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">the output.</span></span></p>
<p><span class="koboSpan" id="kobo.351.1">Chaining facilitates guiding and interactively refining the text generated rather than relying purely on the given examples. </span><span class="koboSpan" id="kobo.351.2">Notice that our prior few-shot code had already established a chain, which we can now use to iterate </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.353.1">
response = llm_chain.run("Rewrite the last tag to something about embracing the winter")
Response # 
=&gt; Response: Embrace the winter wonderland with StyleSprint's latest collection. </span><span class="koboSpan" id="kobo.353.2">From cozy knits to chic outerwear, our pieces will keep you stylish and warm all season long.</span></pre>
<p><span class="koboSpan" id="kobo.354.1">The model is now working from both the examples we provided and any additional instructions we want to include as part of the chain. </span><span class="koboSpan" id="kobo.354.2">Prompt chaining, combined with few-shot learning, provides a powerful framework for iteratively guiding language model outputs. </span><span class="koboSpan" id="kobo.354.3">By leveraging application state to maintain conversation context, we can steer the model toward desired responses in line with our provided examples. </span><span class="koboSpan" id="kobo.354.4">This approach balances harnessing the model’s inferential capabilities and retaining control to align its </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">creative outputs.</span></span></p>
<p><span class="koboSpan" id="kobo.356.1">Next, we will dive into our practice project, which implements RAG. </span><span class="koboSpan" id="kobo.356.2">RAG augments model responses by retrieving and incorporating external data sources. </span><span class="koboSpan" id="kobo.356.3">This technique mitigates </span><a id="_idIndexMarker564"/><span class="koboSpan" id="kobo.357.1">hallucination risks by grounding AI-generated text in real data. </span><span class="koboSpan" id="kobo.357.2">For </span><a id="_idIndexMarker565"/><span class="koboSpan" id="kobo.358.1">example, StyleSprint may leverage past customer survey results or catalog data to enhance product descriptions. </span><span class="koboSpan" id="kobo.358.2">By combining retrieval with prompt chaining, RAG provides a scalable method for balancing</span><a id="_idTextAnchor245"/><span class="koboSpan" id="kobo.359.1"> creativity </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">with accuracy.</span></span></p>
<h1 id="_idParaDest-141"><a id="_idTextAnchor246"/><span class="koboSpan" id="kobo.361.1">Practice project: Implementing RAG with LlamaIndex using Python</span></h1>
<p><span class="koboSpan" id="kobo.362.1">For our practice project, we will shift from LangChain to exploring another library that facilitates the </span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.363.1">RAG approach. </span><span class="koboSpan" id="kobo.363.2">LlamaIndex is </span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.364.1">an open source library that is specifically designed for RAG-based applications. </span><span class="koboSpan" id="kobo.364.2">LlamaIndex simplifies ingestion and indexing across various data </span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.365.1">sources. </span><span class="koboSpan" id="kobo.365.2">However, before we dive into implementation, we will explain the underlying methods and approach </span><span class="No-Break"><span class="koboSpan" id="kobo.366.1">behind RAG.</span></span></p>
<p><span class="koboSpan" id="kobo.367.1">As discussed, the key premise of RAG is to enhance LLM outputs by supplying relevant context from external data sources. </span><span class="koboSpan" id="kobo.367.2">These sources should provide specific and verified information to ground model outputs. </span><span class="koboSpan" id="kobo.367.3">Moreover, RAG can optionally leverage the few-shot approach by retrieving few-shot examples at inference time to guide generation. </span><span class="koboSpan" id="kobo.367.4">This approach alleviates the need to store examples in the prompt chain and only retrieves relevant examples when needed. </span><span class="koboSpan" id="kobo.367.5">In essence, the RAG approach is a culmination of many of the prompt engineering techniques we have already discussed. </span><span class="koboSpan" id="kobo.367.6">It provides structure, chaining, few-shot learning, </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">and grounding.</span></span></p>
<p><span class="koboSpan" id="kobo.369.1">At a high level, the RAG pipeline can be described </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.371.1">The RAG component ingests and indexes domain-specific data sources using vector embeddings to encode semantics. </span><span class="koboSpan" id="kobo.371.2">As we learned in </span><a href="B21773_03.xhtml#_idTextAnchor081"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.372.1">Chapter 3</span></em></span></a><span class="koboSpan" id="kobo.373.1">, these embeddings are imbued with deeply contextualized, rich semantic information that the component uses later to perform a </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">semantic search.</span></span></li>
<li><span class="koboSpan" id="kobo.375.1">The component then uses the initial prompt as a search query. </span><span class="koboSpan" id="kobo.375.2">The query is input to retrieval systems, which find the most relevant snippets from the indexed dat</span><a id="_idTextAnchor247"/><span class="koboSpan" id="kobo.376.1">a based on vector similarity. </span><span class="koboSpan" id="kobo.376.2">Similar to how we applied semantic similarity in prior chapters, RAG leverages a similarity metric to rank results by </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">semantic relevance.</span></span></li>
<li><span class="koboSpan" id="kobo.378.1">Lastly, the original prompt is augmented with information from the retrieved contexts, and the augmented prompt is passed to the LLM to generate a response grounded in the </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">external data.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.380.1">RAG </span><a id="_idIndexMarker569"/><span class="koboSpan" id="kobo.381.1">introduces two major benefits. </span><span class="koboSpan" id="kobo.381.2">First, like the chaining approach, the indexed external data acts as a form of memory, overcoming the LLM’s statelessness. </span><span class="koboSpan" id="kobo.381.3">Second, this memory can rapidly scale beyond model </span><a id="_idIndexMarker570"/><span class="koboSpan" id="kobo.382.1">context window limitations, since examples are curated and only provided at the time of the request as needed. </span><span class="koboSpan" id="kobo.382.2">Ultimately, RAG unlocks otherwise unattainable capabilities in reliable and factual </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">text generation.</span></span></p>
<p><span class="koboSpan" id="kobo.384.1">In our practice project, we revisited the StyleSprint product descriptions. </span><span class="koboSpan" id="kobo.384.2">This time, we want to leverage RAG to retrieve detailed information about the product to produce very specific descriptions. </span><span class="koboSpan" id="kobo.384.3">For the purpose of keeping this project accessible, we will implement an in-memory vector store (Faiss) instead of an external database. </span><span class="koboSpan" id="kobo.384.4">We begin with installing the necessary libraries. </span><span class="koboSpan" id="kobo.384.5">We will leverage LlamaIndex’s integrated support </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">for Faiss:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.386.1">
pip install llama-index faiss-cpu llama-index-vector-stores-faiss</span></pre>
<p><span class="koboSpan" id="kobo.387.1">We will then import the necessary libraries, load the data, and create the index. </span><span class="koboSpan" id="kobo.387.2">This vector store will rely on OpenAI’s embeddings, so we must also define </span><strong class="source-inline"><span class="koboSpan" id="kobo.388.1">OPENAI_API_KEY</span></strong><span class="koboSpan" id="kobo.389.1"> using a </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">valid key:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.391.1">
assert os.getenv("OPENAI_API_KEY") is not None, 
    "Please set OPENAI_API_KEY"
# load document vectors
documents = SimpleDirectoryReader("products/").load_data()
# load faiss index
d = 1536 # dimension of the vectors
faiss_index = faiss.IndexFlatL2(d)
# create vector store
vector_store = FaissVectorStore(faiss_index=faiss_index)
# initialize storage context
storage_context = StorageContext.from_defaults(
    vector_store=vector_store)
# create index
index = VectorStoreIndex.from_documents(
    documents,storage_context=storage_context)</span></pre>
<p><span class="koboSpan" id="kobo.392.1">We </span><a id="_idIndexMarker571"/><span class="koboSpan" id="kobo.393.1">now have a vector store that the model </span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.394.1">can rely on to retrieve our very specific product data. </span><span class="koboSpan" id="kobo.394.2">This means we can query for very specific responses augmented by </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">our data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.396.1">
# query the index
query_engine = index.as_query_engine()
response = query_engine.query("describe summer dress with price")
print(response) 
=&gt; A lightweight summer dress with a vibrant floral print is priced at 59.99.</span></pre>
<p><span class="koboSpan" id="kobo.397.1">The result is a response that not only provides an accurate description of the summer dress but also includes specific details, such as the price. </span><span class="koboSpan" id="kobo.397.2">This level of detail enriches the customer’s shopping experience, providing relevant and real-time information for customers to consider when making </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">a purchase.</span></span></p>
<p><span class="koboSpan" id="kobo.399.1">The </span><a id="_idIndexMarker573"/><span class="koboSpan" id="kobo.400.1">next step is to evaluate our RAG implementation to ensure that the answer is relevant, faithful to the source text, reflective </span><a id="_idIndexMarker574"/><span class="koboSpan" id="kobo.401.1">of contextual accuracy, and not in any way harmful or inappropriate. </span><span class="koboSpan" id="kobo.401.2">We can apply an open source evaluation framework (RAGAS), which provides implementation of the </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">following metrics:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.403.1">Faithfulness</span></strong><span class="koboSpan" id="kobo.404.1"> assesses the degree to which the generated response is faithful or true to the </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">original context</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.406.1">Answer relevance</span></strong><span class="koboSpan" id="kobo.407.1"> evaluates how relevant the generated answer is to the </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">given question</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.409.1">Context precision</span></strong><span class="koboSpan" id="kobo.410.1"> measures the precision of the context used to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">the answer</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.412.1">Context recall</span></strong><span class="koboSpan" id="kobo.413.1"> measures the recall of the context used to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">the answer</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.415.1">Context relevancy</span></strong><span class="koboSpan" id="kobo.416.1"> assesses the relevancy of the context used to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">the answer</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.418.1">Harmfulness</span></strong><span class="koboSpan" id="kobo.419.1"> evaluates whether a submission (or answer) contains anything that could potentially cause harm to individuals, groups, or society </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">at large</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.421.1">This suite of metrics provides an objective measure of RAG application performance based on a comparison to ground truth. </span><span class="koboSpan" id="kobo.421.2">In our case, we can use responses generated from our product data, along with context and ground truth derived from the original dataset, to construct an evaluation dataset and perform a comprehensive evaluation using the </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">metrics described.</span></span></p>
<p><span class="koboSpan" id="kobo.423.1">The following is a simplified code snippet implementing the RAGAS evaluation for our generated product descriptions. </span><span class="koboSpan" id="kobo.423.2">A complete working implementation is available in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.424.1">Chapter 7</span></strong></span><span class="koboSpan" id="kobo.425.1"> folder of the GitHub companion to this </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">book (</span></span><a href="https://github.com/PacktPublishing/Generative-AI-Foundations-in-Python"><span class="No-Break"><span class="koboSpan" id="kobo.427.1">https://github.com/PacktPublishing/Generative-AI-Foundations-in-Python</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.428.1">).</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.429.1">
# Define the evaluation data
eval_data: Dict[str, Any] = {
   "question": questions, # list of sampled questions
   "answer": engine_responses, # responses from RAG application
   "contexts": contexts, # product metadata
"ground_truth": ground_truth, # corresponding descriptions written by a human
}
# Create a dataset from the evaluation data
dataset: Dataset = Dataset.from_dict(eval_data)
# Define the evaluation metrics
metrics: List[Callable] = [
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
    context_relevancy,
    harmfulness,
]
# Evaluate the model using the defined metrics
result: Dict[str, float] = evaluate(dataset, metrics=metrics)
print(result)</span></pre>
<p><span class="koboSpan" id="kobo.430.1">Our evaluation program should produce </span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">the following:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.432.1">
{'faithfulness': 0.9167, 'answer_relevancy': 0.9961, 'context_precision': 0.5000, 'context_recall': 0.7500, 'harmfulness': 0.0000}</span></pre>
<p><span class="koboSpan" id="kobo.433.1">We can </span><a id="_idIndexMarker575"/><span class="koboSpan" id="kobo.434.1">observe that the system performs </span><a id="_idIndexMarker576"/><span class="koboSpan" id="kobo.435.1">well in generating accurate and relevant answers, as evidenced by high faithfulness and answer relevancy scores. </span><span class="koboSpan" id="kobo.435.2">While context precision shows room for improvement, half of the relevant information is correctly identified. </span><span class="koboSpan" id="kobo.435.3">Context recall is effective, retrieving most of the relevant context. </span><span class="koboSpan" id="kobo.435.4">The absence of harmful content ensures safe interactions. </span><span class="koboSpan" id="kobo.435.5">Overall, the system displays robust performance in answering accurately and contextually, but could benefit from refinements in pinpointing the most pertinent </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1">context snippets.</span></span></p>
<p><span class="koboSpan" id="kobo.437.1">As discussed in </span><em class="italic"><span class="koboSpan" id="kobo.438.1">Chapters 5</span></em><span class="koboSpan" id="kobo.439.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.440.1">6</span></em><span class="koboSpan" id="kobo.441.1">, the evaluation of LLMs often requires the additional operational burden of collecting ground-truth data. </span><span class="koboSpan" id="kobo.441.2">However, doing so makes it possible to perform a robust evaluation of model and </span><span class="No-Break"><span class="koboSpan" id="kobo.442.1">application performance.</span></span></p>
<h1 id="_idParaDest-142"><a id="_idTextAnchor248"/><span class="koboSpan" id="kobo.443.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.444.1">In this chapter, we explored the intricacies of prompt engineering. </span><span class="koboSpan" id="kobo.444.2">We also explored advanced strategies to elicit precise and consistent responses from LLMs, offering a versatile alternative to fine-tuning. </span><span class="koboSpan" id="kobo.444.3">We traced the evolution of instruction-based models, highlighting how they’ve shifted the paradigm toward an intuitive understanding and adaptation to tasks through simple prompts. </span><span class="koboSpan" id="kobo.444.4">We expanded on the adaptability of LLMs with techniques such as few-shot learning and retrieval augmentation, which allow for dynamic model guidance across diverse tasks with minimal explicit training. </span><span class="koboSpan" id="kobo.444.5">The chapter further explored the structuring of effective prompts, and the use of personas and situational prompting to tailor model responses more closely to specific interaction contexts, enhancing the model’s applicability and interaction quality. </span><span class="koboSpan" id="kobo.444.6">We also addressed the nuanced aspects of prompt engineering, including the influence of emotional cues on model performance and the implementation of RLHF to refine model outputs. </span><span class="koboSpan" id="kobo.444.7">These discussions underscored the potential of LLMs to exhibit some level of emotional intelligence, leading to more effective and nuanced interactions. </span><span class="koboSpan" id="kobo.444.8">However, alongside these technological strides, we stressed the paramount importance of ethical considerations. </span><span class="koboSpan" id="kobo.444.9">We highlighted the need for responsible adoption and vigilance to mitigate potential harm and biases associated with these techniques, ensuring fairness, integrity, and the prevention </span><span class="No-Break"><span class="koboSpan" id="kobo.445.1">of misuse.</span></span></p>
<p><span class="koboSpan" id="kobo.446.1">Lastly, we learned how to implement and evaluate the RAG approach to ground the LLM in contextual information from trusted sources and produce answers that are relevant and faithful to the source text. </span><span class="koboSpan" id="kobo.446.2">In the next chapter, we will look more closely at the role of individuals in advancing generative AI while emphasizing the dual responsibility of developers and researchers to navigate this rapidly evolving field with a conscientious approach, balancing innovation with ethi</span><a id="_idTextAnchor249"/><span class="koboSpan" id="kobo.447.1">cal imperatives and </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">societal impacts.</span></span></p>
<h1 id="_idParaDest-143"><a id="_idTextAnchor250"/><span class="koboSpan" id="kobo.449.1">References</span></h1>
<p><span class="koboSpan" id="kobo.450.1">This reference section serves as a repository of sources referenced within this book; you can explore these resources to further enhance your understanding and knowledge of the </span><span class="No-Break"><span class="koboSpan" id="kobo.451.1">subject matter:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.452.1">Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. </span><span class="koboSpan" id="kobo.452.2">L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., &amp; Lowe, R. </span><span class="koboSpan" id="kobo.452.3">(2022). </span><em class="italic"><span class="koboSpan" id="kobo.453.1">Training language models to follow instructions with human feedback</span></em><span class="koboSpan" id="kobo.454.1">. </span><span class="koboSpan" id="kobo.454.2">In arXiv [</span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">cs.CL]. </span></span><a href="http://arxiv.org/abs/2203.02155"><span class="No-Break"><span class="koboSpan" id="kobo.456.1">http://arxiv.org/abs/2203.02155</span></span></a></li>
<li><span class="koboSpan" id="kobo.457.1">Wei, J., Bosma, M., Zhao, V. </span><span class="koboSpan" id="kobo.457.2">Y., Guu, K., Yu, A. </span><span class="koboSpan" id="kobo.457.3">W., Lester, B., Du, N., Dai, A. </span><span class="koboSpan" id="kobo.457.4">M., &amp; Le, Q. </span><span class="koboSpan" id="kobo.457.5">V. </span><span class="koboSpan" id="kobo.457.6">(2021). </span><em class="italic"><span class="koboSpan" id="kobo.458.1">Finetuned language models are zero-shot learners</span></em><span class="koboSpan" id="kobo.459.1">. </span><span class="koboSpan" id="kobo.459.2">In arXiv [</span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">cs.CL]. </span></span><a href="http://arxiv.org/abs/2109.01652"><span class="No-Break"><span class="koboSpan" id="kobo.461.1">http://arxiv.org/abs/2109.01652</span></span></a></li>
<li><span class="koboSpan" id="kobo.462.1">Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., &amp; Kiela, D. </span><span class="koboSpan" id="kobo.462.2">(2020). </span><em class="italic"><span class="koboSpan" id="kobo.463.1">Adversarial NLI: A new benchmark for natural language </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.464.1">understanding</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">. </span><span class="koboSpan" id="kobo.465.2">Arxiv.org.</span></span></li>
<li><span class="koboSpan" id="kobo.466.1">Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., &amp; Xie, X. </span><span class="koboSpan" id="kobo.466.2">(2023). </span><em class="italic"><span class="koboSpan" id="kobo.467.1">Large Language Models understand and can be enhanced by emotional stimuli</span></em><span class="koboSpan" id="kobo.468.1">. </span><span class="koboSpan" id="kobo.468.2">In arXiv [</span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">cs.CL]. </span></span><a href="http://arxiv.org/abs/2307.11760"><span class="No-Break"><span class="koboSpan" id="kobo.470.1">http://arxiv.org/abs/2307.11760</span></span></a></li>
<li><span class="koboSpan" id="kobo.471.1">Cheng, M., Durmus, E., &amp; Jurafsky, D. </span><span class="koboSpan" id="kobo.471.2">(2023). </span><em class="italic"><span class="koboSpan" id="kobo.472.1">Marked personas: Using natural language prompts to measure stereotypes in language models. </span><span class="koboSpan" id="kobo.472.2">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</span></em><span class="koboSpan" id="kobo.473.1"> (Volume 1: </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">Long Papers).</span></span></li>
<li><span class="koboSpan" id="kobo.475.1">Brown, T. </span><span class="koboSpan" id="kobo.475.2">B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. </span><span class="koboSpan" id="kobo.475.3">M., Wu, J., Winter, C., … Amodei, D. </span><span class="koboSpan" id="kobo.475.4">(2020). </span><em class="italic"><span class="koboSpan" id="kobo.476.1">Language Models are Few-Shot Learners</span></em><span class="koboSpan" id="kobo.477.1">. </span><span class="koboSpan" id="kobo.477.2">In arXiv [</span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">cs.CL]. </span></span><a href="http://arxiv.org/abs/2005.14165"><span class="No-Break"><span class="koboSpan" id="kobo.479.1">http://arxiv.org/abs/2005.14165</span></span></a></li>
</ul>
</div>
</body></html>