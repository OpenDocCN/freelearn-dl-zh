<html><head></head><body>
  <div><h1 id="_idParaDest-6" class="mainHeading">Preface</h1>
    <p class="normal">The field of <strong class="keyWord">LLM</strong> engineering has rapidly emerged as a critical area in artificial intelligence and machine learning. As LLMs continue to revolutionize natural language processing and generation, the demand for professionals who can effectively implement, optimize, and deploy these models in real-world scenarios has grown exponentially. LLM engineering encompasses a wide range of disciplines, from data preparation and model fine-tuning to inference optimization and production deployment, requiring a unique blend of software engineering, machine learning expertise, and domain knowledge.</p>
    <p class="normal"><strong class="keyWord">Machine Learning Operations</strong> (<strong class="keyWord">MLOps</strong>) plays a crucial role in the successful implementation of LLMs in production environments. MLOps extends the principles of DevOps to machine learning projects, focusing on automating and streamlining the entire ML lifecycle. For LLMs, MLOps is particularly important due to the complexity and scale of these models. It addresses challenges such as managing large datasets, handling model versioning, ensuring reproducibility, and maintaining model performance over time. By incorporating MLOps practices, LLM projects can achieve greater efficiency, reliability, and scalability, ultimately leading to more successful and impactful deployments.</p>
    <p class="normal"><strong class="keyWord">The LLM Engineer’s Handbook</strong> is a comprehensive guide to applying best practices to the new field of LLM engineering. Throughout the chapters, readers will find simplified key concepts, practical techniques, and experts tips for every stage of the LLM lifecycle. The book covers topics such as data engineering, supervised fine-tuning, model evaluation, inference optimization, and <strong class="keyWord">Retrieval-Augmented Generation </strong>(<strong class="keyWord">RAG</strong>) pipeline development.</p>
    <p class="normal">To illustrate these concepts in action, an end-to-end project called the LLM Twin will be developed throughout the book., with the goal of imitating someone’s writing style and personality. This use case will demonstrate how to build a minimum viable product to solve a specific problem, using various aspects of LLM engineering and MLOps.</p>
    <p class="normal">Readers can expect to gain a deeper understanding of how to collect and prepare data for LLMs, fine-tune models for specific tasks, optimize inference performance, and implement RAG pipelines. They will learn how to evaluate LLM performance, align models with human preferences, and deploy LLM-based applications. The book also covers essential MLOps principles and practices, enabling readers to build scalable, reproducible, and robust LLM applications.</p>
    <h1 id="_idParaDest-7" class="heading-1">Who this book is for</h1>
    <p class="normal">This book is intended for a wide range of technology professionals and enthusiasts interested in the practical applications of LLMs. It’s ideal for software engineers aiming to transition into AI projects. While some familiarity with software development is beneficial, the book explains many concepts from the ground up, making it accessible even to those who are new to AI and machine learning.</p>
    <p class="normal">For those already working with machine learning , this book will enhance your skills in implementing and deploying LLM-based systems. We provide a deep dive into the fundamentals of MLOps, guiding you through the process of creating a minimum viable product using an open-source LLM to solve real-world problems.</p>
    <h1 id="_idParaDest-8" class="heading-1">What this book covers</h1>
    <p class="normal"><em class="chapterRef">Chapter 1</em>, <em class="italic">Understanding the LLM Twin Concept and Architecture</em>, introduces the LLM Twin project, which is used throughout the book as an end-to-end example of a production-level LLM application, and defines the FTI architecture for building scalable ML systems and applies it to the LLM Twin use case.</p>
    <p class="normal"><em class="chapterRef">Chapter 2</em>, <em class="italic">Tooling and Installation</em>, presents Python, MLOps, and cloud tools used to build real-world LLM applications, such as an orchestrator, experiment tracker, prompt monitoring and LLM evaluation tool. It shows how to use and install them locally for testing and development.</p>
    <p class="normal"><em class="chapterRef">Chapter 3</em>, <em class="italic">Data Engineering</em>, shows the implementation of a data collection pipeline that scrapes multiple sites, such as Medium, GitHub and Substack and stores the raw data in a data warehouse. It emphasizes collecting raw data from dynamic sources over static datasets for real-world ML applications. </p>
    <p class="normal"><em class="chapterRef">Chapter 4</em>, <em class="italic">RAG Feature Pipeline</em>, introduces RAG fundamental concepts, such as embeddings, the vanilla RAG framework, vector databases, and how to optimize RAG applications. It applies the RAG theory by architecting and implementing LLM Twin’s RAG feature pipeline using software best practices.</p>
    <p class="normal"><em class="chapterRef">Chapter 5</em>, <em class="italic">Supervised Fine-Tuning</em>, explores the process of refining pre-trained language models for specific tasks using instruction-answer pairs. It covers creating high-quality datasets, implementing fine-tuning techniques like full fine-tuning, LoRA, and QLoRA, and provides a practical demonstration of fine-tuning a Llama 3.1 8B model on a custom dataset.</p>
    <p class="normal"><em class="chapterRef">Chapter 6</em>, <em class="italic">Fine-Tuning with Preference Alignment</em>, introduces techniques for aligning language models with human preferences, focusing on <strong class="keyWord">Direct Preference Optimization</strong> (<strong class="keyWord">DPO</strong>). It covers creating custom preference datasets, implementing DPO, and provides a practical demonstration of aligning the TwinLlama-3.1-8B model using the Unsloth library.</p>
    <p class="normal"><em class="chapterRef">Chapter 7</em>, <em class="italic">Evaluating LLMs</em>, details various methods for assessing the performance of language models and LLM systems. It introduces general-purpose and domain-specific evaluations and discusses popular benchmarks. The chapter includes a practical evaluation of the TwinLlama-3.1-8B model using multiple criteria.</p>
    <p class="normal"><em class="chapterRef">Chapter 8</em>, <em class="italic">Inference Optimization</em>, covers key optimization strategies such as speculative decoding, model parallelism, and weight quantization. It discusses how to improve inference speed, reduce latency, and minimize memory usage, introducing popular inference engines and comparing their features.</p>
    <p class="normal"><em class="chapterRef">Chapter 9</em>, <em class="italic">RAG Inference Pipeline</em>, explores advanced RAG techniques by implementing methods such as self-query, reranking, and filtered vector search from scratch. It covers designing and implementing the LLM Twin’s RAG inference pipeline and a custom retrieval module similar to what you see in popular frameworks such as LangChain.</p>
    <p class="normal"><em class="chapterRef">Chapter 10</em>, <em class="italic">Inference Pipeline Deployment</em>, introduces ML deployment strategies, such as online, asynchronous and batch inference, which will help in architecting and deploying the LLM Twin fine-tuned model to AWS SageMaker and building a FastAPI microservice to expose the RAG inference pipeline as a RESTful API.</p>
    <p class="normal"><em class="chapterRef">Chapter 11</em>, <em class="italic">MLOps and LLMOps</em>, presents what LLMOps is, starting with its roots in DevOps and MLOps. This chapter explains how to deploy the LLM Twin project to the cloud, such as the ML pipelines to AWS and shows how to containerize the code using Docker and build a CI/CD/CT pipeline. It also adds a prompt monitoring layer on top of LLM Twin’s inference pipeline.</p>
    <p class="normal"><em class="chapterRef">Appendix</em>,<em class="italic"> MLOps Principles</em>, covers the six MLOps principles used to build scalable, reproducible, and robust ML applications.</p>
    <h1 id="_idParaDest-9" class="heading-1">To get the most out of this book</h1>
    <p class="normal">To maximize your learning experience, you are expected to have, at the very least, a foundational understanding of software development principles and practices. Familiarity with Python programming is particularly beneficial, as the book’s examples and code snippets are predominantly in Python. While prior experience with machine learning concepts is advantageous, it is not strictly necessary, as the book provides explanations for many fundamental AI and ML concepts. However, you should be comfortable with basic data structures, algorithms, and have some experience working with APIs and cloud services. </p>
    <p class="normal">Familiarity with version control systems like Git is assumed, as this book has a GitHub repository for code examples. While this book is designed to be accessible to those who are new to AI and LLMs, if you have some background in these areas, you will find it easier to grasp the more advanced concepts and techniques we present.</p>
    <h2 id="_idParaDest-10" class="heading-2">Download the example code files</h2>
    <p class="normal">The code bundle for the book is hosted on GitHub at <a href="https://github.com/PacktPublishing/LLM-Engineers-Handbook">https://github.com/PacktPublishing/LLM-Engineers-Handbook</a>. We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</p>
    <h2 id="_idParaDest-11" class="heading-2">Download the color images</h2>
    <p class="normal">We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="https://packt.link/gbp/9781836200079">https://packt.link/gbp/9781836200079</a>.</p>
    <h2 id="_idParaDest-12" class="heading-2">Conventions used</h2>
    <p class="normal">There are a number of text conventions used throughout this book.</p>
    <p class="normal"><code class="inlineCode">CodeInText</code>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. For example: “In the <code class="inlineCode">format_samples</code> function, we apply the Alpaca chat template to each individual message.”</p>
    <p class="normal">A block of code is set as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">def format_samples(example):
    example["prompt"] = alpaca_template.format(example["prompt"])
    example["chosen"] = example['chosen'] + EOS_TOKEN
    example["rejected"] = example['rejected'] + EOS_TOKEN
    return {"prompt": example["prompt"], "chosen": example["chosen"], "rejected": example["rejected"]}
</code></pre>
    <p class="normal">When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
    <pre class="programlisting code"><code class="hljs-code">def format_samples(example):
    example["prompt"] = alpaca_template.format(example["prompt"])
    example["chosen"] = example['chosen'] + EOS_TOKEN
    example["rejected"] = example['rejected'] + EOS_TOKEN
    <strong class="hljs-keyword-slc">return</strong><strong class="hljs-slc"> {</strong><strong class="hljs-string-slc">"prompt"</strong><strong class="hljs-slc">: example[</strong><strong class="hljs-string-slc">"prompt"</strong><strong class="hljs-slc">], </strong><strong class="hljs-string-slc">"chosen"</strong><strong class="hljs-slc">:</strong> example["chosen"], "rejected": example["rejected"]}
</code></pre>
    <p class="normal">Any command-line input or output is written as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">poetry install --without aws
</code></pre>
    <p class="normal"><strong class="keyWord">Bold</strong>: Indicates a new term, an important word, or words that you see on the screen. For instance, words in menus or dialog boxes appear in the text like this. For example: “To do so, go to the <strong class="screenText">Settings</strong> tab at the top of the forked repository in GitHub. In the left panel, in the <strong class="screenText">Security</strong> section, click on the <strong class="screenText">Secrets and Variables</strong> toggle and, finally, click on <strong class="screenText">Actions</strong>.”</p>
    <div><p class="normal">Warnings or important notes appear like this.</p>
    </div>
    <div><p class="normal">Tips and tricks appear like this.</p>
    </div>
    <h1 id="_idParaDest-13" class="heading-1">Get in touch</h1>
    <p class="normal">Feedback from our readers is always welcome.</p>
    <p class="normal"><strong class="keyWord">General feedback</strong>: Email <code class="inlineCode">feedback@packtpub.com</code> and mention the book’s title in the subject of your message. If you have questions about any aspect of this book, please email us at <code class="inlineCode">questions@packtpub.com</code>.</p>
    <p class="normal"><strong class="keyWord">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you reported this to us. Please visit <a href="http://www.packtpub.com/submit-errata">http://www.packtpub.com/submit-errata</a>, click <strong class="screenText">Submit Errata</strong>, and fill in the form.</p>
    <p class="normal"><strong class="keyWord">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <code class="inlineCode">copyright@packtpub.com</code> with a link to the material.</p>
    <p class="normal"><strong class="keyWord">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com">http://authors.packtpub.com</a>.</p>
  </div>
  <div><p class="eop"/>
    <h1 id="_idParaDest-14" class="heading-1">Share your thoughts</h1>
    <p class="normal">Once you’ve read <em class="italic">LLM Engineer’s Handbook, First Edition</em>, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1836200072">click here to go straight to the Amazon review page</a> for this book and share your feedback.</p>
    <p class="normal">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</p>
  </div>
  <div><p class="eop"/>
    <h1 id="_idParaDest-15" class="heading-1">Download a free PDF copy of this book</h1>
    <p class="normal">Thanks for purchasing this book!</p>
    <p class="normal">Do you like to read on the go but are unable to carry your print books everywhere?</p>
    <p class="normal">Is your eBook purchase not compatible with the device of your choice?</p>
    <p class="normal">Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at no cost.</p>
    <p class="normal">Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into your application.</p>
    <p class="normal">The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your inbox daily.</p>
    <p class="normal">Follow these simple steps to get the benefits:</p>
    <ol>
      <li class="numberedList" value="1">Scan the QR code or visit the link below:</li>
    </ol>
    <figure class="mediaobject"><img src="img/B31105_Free_PDF_QR.png" alt=""/></figure>
    <p class="packt_figref"><a href="https://packt.link/free-ebook/9781836200079">https://packt.link/free-ebook/9781836200079</a></p>
    <ol>
      <li class="numberedList" value="2">Submit your proof of purchase.</li>
      <li class="numberedList">That’s it! We’ll send your free PDF and other benefits to your email directly.</li>
    </ol>
  </div>
</body></html>