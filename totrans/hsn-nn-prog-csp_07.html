<html><head></head><body>
        

                            
                    <h1 class="header-title">Building Our First Neural Network Together</h1>
                
            
            
                
<p>Now that we've had a quick refresher on Neural Networks, I thought that perhaps a good starting point, code-wise, would be for us to write a very simple neural network. We're not going to go crazy; we'll just lay the basic framework for a few functions so that you can get a good idea of what is behind the scenes of many of the APIs that you'll use. From start to finish, we'll develop this network application so that you are familiar with all the basic components that are contained in a neural network. This implementation is not perfect or all-encompassing, nor is it meant to be. As I mentioned, this will merely provide a framework for us to use in the rest of the book. This is a very basic neural network with the added functionality of being able to save and load networks and data. In any event, you will have a foundation from which to write your own neural network and change the world, should you so desire.</p>
<p>In this chapter, we are going to cover the following topics:</p>
<ul>
<li>Neural network training</li>
<li>Terminology</li>
<li>Synapses</li>
<li>Neurons</li>
<li>Forward propagation</li>
<li>Sigmoid function</li>
<li>Back propagation</li>
<li>Error calculations</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>You would need to have Microsoft Visual Studio installed on the system.</p>
<p>Check out the following video to see Code in Action: <a href="http://bit.ly/2NYJa5G">http://bit.ly/2NYJa5G</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Our neural network</h1>
                
            
            
                
<p>Let's begin by showing you an of what a simple neural network would look like, visually. It consists of an input layer with <em>2</em> inputs, a Hidden Layer with <em>3</em> neurons (sometimes called <strong>nodes</strong>), and a final output layer consisting of a single neuron. Of course, neural networks can consist of many more layers (and neurons per layer), and once you get into deep learning you will see much more of this, but for now this will suffice. Remember, each node, which is labeled as follows with an <strong>N</strong>, is an individual neuron – its own little processing brain, if you will:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-953 image-border" src="img/a67995f1-ceca-4de8-8540-fbf25ab7843e.png" style="width:19.00em;height:22.33em;"/></p>
<p>Let’s break down the neural network into its three basic parts; inputs, Hidden Layers and outputs:</p>
<p><strong>Inputs</strong>: This is the initial data for our network. Each input is a whose output to the Hidden Layer is the initial input value.<br/></p>
<p><strong>Hidden Layers</strong>: These are the heart and soul of our network, and all the magic happens. Neurons in this layer are assigned weights for each of their inputs. These weights start off randomized, and are adjusted as the network is trained so that the neuron's output is closer to the expected result (if we are lucky).</p>
<p><strong>Outputs</strong>: These are the output our network arrives at after it performs its calculations. The output in our simple case will be either true or false, on or off. The neurons are assigned a weight for each of their inputs, which comes from the previous Hidden Layer. Although it is typically common for there to be only a single output neuron, there's absolutely nothing preventing you from having more, should you need or want more than one.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Neural network training</h1>
                
            
            
                
<p>How do we train a neural network? Basically, we will provide the with a set of input data as well as the results we expect to see, which correspond to those inputs. That data is then run through the network until the network understands what we are looking for. We will train, test, train, test, train, test, on and on until our network understands our data (or doesn't, but that's a whole other conversation). We continue to do this until some designated stop condition is satisfied, such as an error rate threshold. Let's quickly cover some of the terminology we will use while training neural networks.</p>
<p><strong>Back propagation</strong>: After our data is run through the network, we to validate that data what we expect to be the correct output. We do this by propagating <em>backward</em> (hence backprop or back propagation) through each of the Hidden Layers of our network. The end result is that this adjusts the weights assigned to each of the neuron's inputs in the Hidden Layers as well as our error rate.</p>
<p>Each back propagation layer should, in a perfect world, make our network output closer to what we are expecting, and our error rate will get closer and closer to 0. We may never get to an exact error rate of 0, so even though it may seem not much of a difference, an error rate of 0.0000001 could be more than acceptable to us.</p>
<p><strong>Biases</strong>: Biases allow us to modify our function so that we can generate better output for each neuron in our network. In short, a bias allows us to shift the activation function value to the left or the right. Changing the weight changes the steepness or vertical aspect of the Sigmoid.</p>
<p><strong>Momentum</strong>: Momentum simply adds a fraction of the previous weight update to the current one. Momentum is used to prevent the system from converging on a local minimum rather than the global minimum. High momentum can be used to help increase the speed of convergence of the system; however, you must be careful as setting this parameter too high can create a risk of overshooting the minimum, which will result in an unstable system. On the other hand, a momentum that is too low cannot reliably avoid local minima, and it can also really slow down the training of the system. So, getting this value correct is paramount for success and something you will spend a considerable amount of time doing.</p>
<p><strong>Sigmoid function</strong>: An activation function defines what each neuron's output will be. A Sigmoid function is perhaps the most commonly used activation function. It converts the input into a value which lies between 0 and 1. This function is used to generate our initial weights. A typical Sigmoid function will be able to accept an input value and, from that value, provide both an output value and a derivative.</p>
<p><strong>Learning rate</strong>: The learning rate will change the overall learning speed of the system by controlling the size of the weight and bias changes made to the network during the learning phase.</p>
<p>Now that we have this terminology behind us, let's start digging into the code. You should have downloaded the solution from the accompanying software provided for the book, and have it opened in Visual Studio. We use the Community Edition of Visual studio, but you may use whichever version you have.</p>
<p>Feel free to download the software, experiment with it, and embellish it if you need or want to. In your world, your neural network can be anything you like or need it to be, so make it happen. You have the source. Just because you see something one way doesn't make it gospel or written in stone! Learn from what these great open source contributors have provided for us! Remember, this neural network is meant only to give you some idea of the many things that you could do writing your own, as well as teach you some of the basics when it comes to a neural network.</p>
<p>Let's start off by looking at some brief code snippets that will set the stage for the rest of the chapter. We'll start first with a little thing called a <strong>synapse</strong>, which connects one neuron to another. Next, we'll start coding exactly what an individual neuron is, and finally move into discussing forward and backward propagation and what that means to us. We'll show everything in the form of code snippets to make it easier to understand.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Synapses</h1>
                
            
            
                
<p>What is a synapse, you might ask? Simply put, it connects one neuron to another, as well as being a container to hold weight and weight delta values, depicted as follows:</p>
<pre>public class Synapse<br/>{<br/>    public Guid Id{ get; set; }<br/>    public Neuron InputNeuron{ get; set; }    <br/>    public Neuron OutputNeuron{ get; set; }<br/>    public double Weight{ get; set; }<br/>    public double WeightDelta{ get; set; }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Neurons</h1>
                
            
            
                
<p>We've already discussed what a neuron is, now it's time to express it in code so developers like us can make more sense of it! As you can see, we have both our input and output synapses, our <kbd>Bias</kbd> and the <kbd>Bias Delta</kbd>, the <kbd>Gradient</kbd>, and the actual value of the neuron. The neuron calculates the weighted sum of its inputs, adds a bias, and then decides if the output should <kbd>'fire' - 'be on'</kbd>- or not:</p>
<pre>public class Neuron<br/>{<br/>  public Guid Id{ get; set; }<br/><br/>The synapse that connects to our input side<br/>  public List&lt;Synapse&gt; InputSynapses{ get; set; }<br/><br/>The synapse that connects to our output side<br/>  public List&lt;Synapse&gt; OutputSynapses{ get; set; }<br/>  public double Bias{ get; set; }<br/><br/>Our bias values<br/>  public double BiasDelta{ get; set; }<br/>  public double Gradient{ get; set; }<br/><br/>The input value to the neuron<br/>  public double Value{ get; set; }<br/><br/>Is the neuron a mirror neuron<br/>public bool IsMirror{ get; set; }<br/><br/>Is the neuron a canonical neuron<br/>public bool IsCanonical{ get; set; }<br/><br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Forward propagation</h1>
                
            
            
                
<p>The following is our code for a basic forward propagation process:</p>
<pre>private void ForwardPropagate(params double[] inputs)<br/>{<br/>  var i = 0;<br/>  InputLayer?.ForEach(a =&gt;a.Value = inputs[i++]);<br/>  HiddenLayers?.ForEach(a =&gt;a.ForEach(b =&gt;b.CalculateValue()));<br/>  OutputLayer?.ForEach(a =&gt;a.CalculateValue());<br/>}</pre>
<p>To do <kbd>ForwardPropagation</kbd>, we basically sum all the inputs from each synapse and run the result through our Sigmoid function to get an output. The <kbd>CalculateValue</kbd> function does this for us.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Sigmoid function</h1>
                
            
            
                
<p>The Sigmoid function is an activation function and, as we previously, perhaps one of the most widely used today. Here's what a Sigmoid function looks like (you do remember our section on activation functions, right?) Its sole purpose (very abstractly) is to bring in the values from the outside edges closer to 0 and 1 without having to worry about values larger than this. This will prevent those values along the edge from running away on us:</p>
<div><img src="img/6d0b3758-e073-4341-aa78-748b52735d03.jpg" style="width:21.67em;height:16.25em;"/></div>
<p>What does a <kbd>Sigmoid</kbd> function look like in C# code, you might ask? Just like the following:</p>
<pre>public static class Sigmoid<br/>{<br/>  public static double Output(double x)<br/>  {<br/>    return x &lt; -45.0 ?0.0 : x &gt; 45.0 ? 1.0 : 1.0 / (1.0 + Math.Exp(-x));<br/>  }<br/><br/>  public static double Derivative(double x)<br/>  {<br/>    return x * (1 - x);<br/>  }<br/>}</pre>
<p>Our <kbd>Sigmoid</kbd> class will produce the output and the Derivative.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Backward propagation</h1>
                
            
            
                
<p>For back propagation (backprop), we will first calculate the gradient from the output layers, put those values through our Hidden Layer (reversing the direction we took in forward propagation), update the weights, and finally put the value through our output layers, as follows:</p>
<pre>private void BackPropagate(params double[] targets)<br/>{<br/>  var i = 0;<br/>  OutputLayer?.ForEach(a =&gt;a.CalculateGradient(targets[i++]));<br/>  HiddenLayers?.Reverse();<br/>  HiddenLayers?.ForEach(a =&gt;a.ForEach(b =&gt;b.CalculateGradient()));<br/>  HiddenLayers?.ForEach(a =&gt;a.ForEach(b =&gt;b.UpdateWeights(LearningRate, Momentum)));<br/>  HiddenLayers?.Reverse();<br/>  OutputLayer?.ForEach(a =&gt;a.UpdateWeights(LearningRate, Momentum));<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Calculating errors</h1>
                
            
            
                
<p>To calculate our error, we take our actual value and subtract it from our expected value. The closer we are to 0, the better we will be. Note that the following is very little chance that we will ever hit 0, although it could conceivably happen:</p>
<pre>public double CalculateError(double target)<br/>{<br/>  return target - Value;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Calculating a gradient</h1>
                
            
            
                
<p>The gradient is calculated by considering the Derivative of the <kbd>Sigmoid</kbd> function:</p>
<pre>public double CalculateGradient(double? target = null)<br/>{<br/>  if (target == null)<br/>    return Gradient = OutputSynapses.Sum(a =&gt;a.OutputNeuron.Gradient * <br/>    a.Weight) * Sigmoid.Derivative(Value);<br/><br/>  return Gradient = CalculateError(target.Value) * Sigmoid.Derivative(Value);<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating weights</h1>
                
            
            
                
<p>We update the weights by multiplying the learning rate times our gradient, and then adding in momentum and multiplying by the previous delta. This is then run through each input synapse to calculate the final value:</p>
<pre>public void UpdateWeights(double learnRate, double momentum)<br/>{<br/>  var prevDelta = BiasDelta;<br/>  BiasDelta = learnRate * Gradient;<br/>  Bias += BiasDelta + momentum * prevDelta;<br/><br/>  foreach (var synapse in InputSynapses)<br/>  {<br/>    prevDelta = synapse.WeightDelta;<br/>    synapse.WeightDelta = learnRate * Gradient * synapse.InputNeuron.Value;<br/>        synapse.Weight += synapse.WeightDelta + momentum * prevDelta;<br/>  }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Calculating values</h1>
                
            
            
                
<p>To calculate values, we take the output from our <kbd>Sigmoid</kbd> function and add to it the bias term:</p>
<pre>public virtual double CalculateValue()<br/>{<br/>  return Value = Sigmoid.Output(InputSynapses.Sum(a =&gt;a.Weight * <br/>  a.InputNeuron.Value) + Bias);<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Neural network functions</h1>
                
            
            
                
<p>The following basic list contains the functions we are going to develop n order  to lay down our neural network foundation:</p>
<ul>
<li>Creating a new network</li>
<li>Importing a network</li>
<li>Manually entering user data</li>
<li>Importing a dataset</li>
<li>Training our network</li>
<li>Testing our network</li>
</ul>
<p>With that behind us, let's  start coding!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a new network</h1>
                
            
            
                
<p>This menu option will allow us to create a new network from scratch:</p>
<pre>public NNManager SetupNetwork()<br/>{<br/>    _numInputParameters = 2;<br/><br/>    int[] hidden = new int[2];<br/>    hidden[0] = 3;<br/>    hidden[1] = 1;<br/>    _numHiddenLayers = 1;<br/>    _hiddenNeurons = hidden;<br/>    _numOutputParameters = 1;<br/>    _network = new Network(_numInputParameters, _hiddenNeurons,         <br/>    _numOutputParameters);<br/>    return this;<br/>}</pre>
<p>Notice our return value in this function. This is a fluent interface, meaning that various functions can be chained together into a single statement. Many people prefer this type of interface over the conventional one, but you can feel free to modify the code any way you like. The following is an example of what a fluent interface looks like. Believe it or not, this is a complete neural network:</p>
<pre>NNManagermgr = new NNManager();<br/>Mgr<br/>.SetupNetwork()<br/>.GetTrainingDataFromUser()<br/>.TrainNetworkToMinimum()<br/>.TestNetwork();</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Importing an existing network</h1>
                
            
            
                
<p>This function will allow us to import a previously saved network. Again, note the return value that makes this a fluent interface:</p>
<pre>public static Network ImportNetwork()<br/>{</pre>
<p>Get the filename of the previously saved network. Once opened, deserialize it into a network structure that we will deal with. (If it didn't work for some reason, abort!):</p>
<pre>  var dn = GetHelperNetwork();<br/>  if (dn == null) <br/>  return null;</pre>
<p>Create a <kbd>new Network</kbd> and a list of neurons to populate:</p>
<pre>var network = new Network();<br/>  var allNeurons = new List&lt;Neuron&gt;();</pre>
<p>Copy over the learning rate and the momentum that was previously saved:</p>
<pre>network.LearningRate = dn.LearningRate;<br/>  network.Momentum = dn.Momentum;</pre>
<p>Create input layers from our imported network data:</p>
<pre>foreach (var n in dn.InputLayer)<br/>  {<br/>    var neuron = new Neuron<br/>    {<br/>      Id = n.Id,<br/>      Bias = n.Bias,<br/>      BiasDelta = n.BiasDelta,<br/>      Gradient = n.Gradient,<br/>      Value = n.Value<br/>    };<br/><br/>    network.InputLayer?.Add(neuron);<br/>    allNeurons.Add(neuron);<br/>  }</pre>
<p>Create our Hidden Layers from our imported network data:</p>
<pre>  foreach (var layer in dn.HiddenLayers)<br/>  {<br/>    var neurons = new List&lt;Neuron&gt;();<br/>    foreach (var n in layer)<br/>    {<br/>      var neuron = new Neuron<br/>      {<br/>        Id = n.Id,<br/>        Bias = n.Bias,<br/>        BiasDelta = n.BiasDelta,<br/>        Gradient = n.Gradient,<br/>        Value = n.Value<br/>      };<br/><br/>      neurons.Add(neuron);<br/>      allNeurons.Add(neuron);<br/>    }<br/>    network.HiddenLayers?.Add(neurons);<br/>  }</pre>
<p>Create the <kbd>OutputLayer</kbd> neurons from our imported data:</p>
<pre>foreach (var n in dn.OutputLayer)<br/>  {<br/>    var neuron = new Neuron<br/>    {<br/>      Id = n.Id,<br/>      Bias = n.Bias,<br/>      BiasDelta = n.BiasDelta,<br/>      Gradient = n.Gradient,<br/>      Value = n.Value<br/>    };<br/><br/>    network.OutputLayer?.Add(neuron);<br/>    allNeurons.Add(neuron);<br/>  }</pre>
<p>Finally, create the synapses that tie everything together:</p>
<pre><br/>  foreach (var syn in dn.Synapses)<br/>  {<br/>    var synapse = new Synapse{ Id = syn.Id };<br/>    var inputNeuron = allNeurons.First(x =&gt;x.Id==syn.InputNeuronId);<br/>    var outputNeuron = allNeurons.First(x =&gt;x.Id==syn.OutputNeuronId);<br/>    synapse.InputNeuron = inputNeuron;<br/>    synapse.OutputNeuron = outputNeuron;<br/>    synapse.Weight = syn.Weight;<br/>    synapse.WeightDelta = syn.WeightDelta;<br/><br/>    inputNeuron?.OutputSynapses?.Add(synapse);<br/>    outputNeuron?.InputSynapses?.Add(synapse);<br/>  }<br/>  return network;<br/>}</pre>
<p>The following is where we manually enter the data to be used by the network:</p>
<pre>public NNManager GetTrainingDataFromUser()<br/>{<br/>var numDataSets = GetInput("\tHow many datasets are you going to enter? ", 1, int.MaxValue);<br/><br/>  var newDatasets = new List&lt;NNDataSet&gt;();<br/>  for (var i = 0; i&lt;numDataSets; i++)<br/>  {<br/>    var values = GetInputData($"\tData Set {i + 1}: ");<br/>    if (values == null)<br/>    {<br/>      return this;<br/>    }<br/><br/>    var expectedResult = GetExpectedResult($"\tExpected Result for Data <br/>    Set {i + 1}: ");<br/>    if (expectedResult == null)<br/>    {<br/>      return this;<br/>    }<br/><br/>    newDatasets.Add(newNNDataSet(values, expectedResult));<br/>  }<br/><br/>  _dataSets = newDatasets;<br/>  return this;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Importing datasets</h1>
                
            
            
                
<p>The following is how we our datasets:<br/></p>
<pre>public static List&lt;DataSet&gt;ImportDatasets()<br/>{<br/>  var dialog = new OpenFileDialog<br/>  {<br/>    Multiselect = false,<br/>    Title = "Open Dataset File",<br/>    Filter = "Text File|*.txt;"<br/>  };<br/><br/>  using (dialog)<br/>  {<br/>    if (dialog.ShowDialog() != DialogResult.OK) <br/>    return null;<br/><br/>    using (var file = File.OpenText(dialog.FileName))<br/>    {</pre>
<p>Deserialize the data and return it:</p>
<pre>      return JsonConvert.DeserializeObject&lt;List&lt;DataSet&gt;&gt;(file.ReadToEnd());<br/>    }<br/>  }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing the network</h1>
                
            
            
                
<p>In order to test the network, we to do a simple forward and backward propagation, depicted as follows:<br/></p>
<pre>public double[] Compute(params double[] inputs)<br/>{</pre>
<p class="mce-root">Perform forward propagation, as follows:</p>
<pre class="mce-root">  ForwardPropagate(inputs);</pre>
<p class="mce-root">Return the data, as follows:</p>
<pre class="mce-root">  return OutputLayer.Select(a =&gt;a.Value).ToArray();<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Exporting the network</h1>
                
            
            
                
<p class="mce-root">Export the current network information, as follows:</p>
<pre>public NNManager ExportNetwork()<br/>{<br/>  Console.WriteLine("\tExporting Network...");<br/>  ExportHelper.ExportNetwork(_network);<br/>  Console.WriteLine("\t**Exporting Complete!**", Color.Green);<br/>  return this;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Training the network</h1>
                
            
            
                
<p>There are two ways of training the network. One is to a minimum error value, the other is to a maximum error value. Both functions have defaults, although you may wish to make the threshold different for your training, as follows:</p>
<pre>public NNManager TrainNetworkToMinimum()<br/>{<br/>var minError = GetDouble("\tMinimum Error: ", 0.000000001, 1.0);<br/>Console.WriteLine("\tTraining...");<br/>_network.Train(_dataSets, minError);<br/>Console.WriteLine("\t**Training Complete**", Color.Green);<br/>return this;<br/>}<br/><br/>public NNManager TrainNetworkToMaximum()<br/>{<br/>varmaxEpoch = GetInput("\tMax Epoch: ", 1, int.MaxValue);<br/>if(!maxEpoch.HasValue)<br/>       {<br/>  return this;<br/>       }<br/><br/>Console.WriteLine("\tTraining...");<br/>_network.Train(_dataSets, maxEpoch.Value);<br/>Console.WriteLine("\t**Training Complete**", Color.Green);<br/>return this;<br/>}</pre>
<p>In both of the preceding function definitions, the neural network <kbd>Train</kbd> function is called to perform the actual training. This function in turn calls the forward and backward propagation functions for each dataset from within each iteration of the training loop, as follows:</p>
<pre>public void Train(List&lt;DataSet&gt;dataSets, int numEpochs)<br/>{<br/>  for (var i = 0; i&lt;numEpochs; i++)<br/>  {<br/>    foreach (var dataSet in dataSets)<br/>    {<br/>      ForwardPropagate(dataSet.Values);<br/>      BackPropagate(dataSet.Targets);<br/>    }<br/>  }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing the network</h1>
                
            
            
                
<p>This function allows us to test our network. Again, notice the return value, which makes this a fluent interface. For the most commonly used functions at a higher, more abstract layer, I tried to make the fluent interface available where it would be most beneficial, as follows:</p>
<pre>public NNManager TestNetwork()<br/>{<br/>Console.WriteLine("\tTesting Network", Color.Yellow);<br/>  <br/>  while (true)<br/>  {</pre>
<p>Get the input data from the user, as follows:</p>
<pre><br/>    var values = GetInputData($"\tType{_numInputParameters} inputs: ");<br/>    if (values == null)<br/>    {<br/>      return this;<br/>    }</pre>
<p>Do the computations, as follows:</p>
<pre>    var results = _network?.Compute(values);<br/>  </pre>
<p>Print out the results, as follows:</p>
<pre>    foreach (var result in results)<br/>    {<br/>    Console.WriteLine("\tOutput: " + <br/>    DoubleConverter.ToExactString(result), Color.Aqua);<br/>    }<br/><br/>    return this;<br/>  }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Computing forward propagation</h1>
                
            
            
                
<p>This function is where we <kbd>Compute</kbd> the forward propagation value based upon the values provided, as follows:</p>
<pre>public double[] Compute(params double[] inputs)<br/>{<br/>  ForwardPropagate(inputs);<br/>  return OutputLayer.Select(a =&gt;a.Value).ToArray();<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Exporting the network</h1>
                
            
            
                
<p>This function is where we export our network. To us, exporting means serializing the data into a JSON human-readable format, as follows:</p>
<pre>public NNManager ExportNetwork()<br/>{<br/>  Console.WriteLine("\tExporting Network...");<br/>  ExportHelper.ExportNetwork(_network);<br/>  Console.WriteLine("\t**Exporting Complete!**", Color.Green);<br/>  return this;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Exporting a dataset</h1>
                
            
            
                
<p>This function is where we export our dataset information. As with exporting the network, this will be done in JSON human readable format:</p>
<pre>public NNManager ExportDatasets()<br/>{<br/>      Console.WriteLine("\tExporting Datasets...");<br/>      ExportHelper.ExportDatasets(_dataSets);<br/>      Console.WriteLine("\t**Exporting Complete!**", Color.Green);<br/>      return this;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">The neural network</h1>
                
            
            
                
<p>With many of the ancillary, but important, functions coded, we now turn our attention to the meat of the neural network, the network itself. Within a neural network, the network part is an all-encompassing universe. Everything resides within it. Within this structure we will need to store the input, output, and Hidden Layers of neurons, as well as the learning rate and Momentum, as follows:</p>
<pre>public class Network<br/>{<br/>      public double LearningRate{ get; set; }<br/>      public double Momentum{ get; set; }<br/>      public List&lt;Neuron&gt;InputLayer{ get; set; }<br/>      public List&lt;List&lt;Neuron&gt;&gt;HiddenLayers{ get; set; }<br/>      public List&lt;Neuron&gt;OutputLayer{ get; set; }<br/>      public List&lt;Neuron&gt;MirrorLayer {get; set; }<br/>      public List&lt;Neuron&gt;CanonicalLayer{ get; set; }</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Neuron connection</h1>
                
            
            
                
<p>Every neuron must be connected to other neurons, and our neuron constructor will handle connecting all the input neurons with the synapses, as follows:</p>
<pre>public Neuron(IEnumerable&lt;Neuron&gt; inputNeurons) : this()<br/>{<br/>Ensure.That(inputNeurons).IsNotNull();<br/><br/>  foreach (var inputNeuron in inputNeurons)<br/>  {<br/>    var synapse = new Synapse(inputNeuron, this);<br/>    inputNeuron?.OutputSynapses?.Add(synapse);<br/>    InputSynapses?.Add(synapse);<br/>  }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Examples</h1>
                
            
            
                
<p>Now that we have our code created, let's use a few examples to see how it can be used.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Training to a minimum</h1>
                
            
            
                
<p>In this example, we will use the code we wrote to train a network to a minimum value or threshold. For each step, the network prompts you for the correct data, saving us the process of cluttering up our example code with this. In production, you would probably want to pass in the parameters without any user intervention, in case this is run as a service or microservice:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1410 image-border" src="img/9132c220-7211-4fbd-9e92-f7014a5bd6ea.png" style="width:37.75em;height:33.92em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Training to a maximum</h1>
                
            
            
                
<p>In this example, we are going to train the network to reach a maximum value, rather than the minimum, as depicted. We manually enter the data we wish to work with, as well as the expected result. We then allow training to complete. Once completed, we type in our testing input and test the network:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1411 image-border" src="img/ecadbb7d-46d1-48ac-b95b-f1ec30018163.png" style="width:32.83em;height:27.83em;"/></p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we saw how to write a complete neural network from scratch. Although the following is a lot we've left out, it does the basics, and we've gotten to see it as pure C# code! We should now have a much better understanding of what a neural network is and what it comprises than when we first started.</p>
<p>In the next chapter, we will begin our journey into more complicated network structures such as recurrent and convolutional neural networks. There's a lot to cover, so hold on to your coding hats!</p>


            

            
        
    </body></html>