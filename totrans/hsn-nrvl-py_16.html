<html><head></head><body>
        

                            
                    <h1 class="header-title">Concluding Remarks</h1>
                
            
            
                
<p class="p1">In this chapter, we will summarize everything we have learned in this book and will provide further information so that you can continue your self-education. This chapter will help us revise the topics we have covered in a chapter-wise format and then provide a roadmap by sharing some details on Uber AI Labs, alife.org, and open-ended evolution at Reddit. We will also have a quick overview of the NEAT Software Catalog and the NEAT Algorithm Paper.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>What we learned in this book</li>
<li>Where to go from here</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What we learned in this book</h1>
                
            
            
                
<p class="p1">Now that we have finished with the experiments, I hope that you have gained a solid understanding of the neuroevolution method of training artificial neural networks. We used neuroevolution to find solutions to a variety of experiments, from classic computer science problems to the creation of agents that are capable of playing Atari games. We also examined tasks related to computer vision and visual discrimination.</p>
<p class="p1">In this section, we will summarize what we learned in each chapter of this book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Overview of the neuroevolution methods</h1>
                
            
            
                
<p class="p3">In this chapter, we learned about the core concepts of genetic algorithms, such as genetic operators and genome encoding schemes. </p>
<p class="p3">We discussed two major genetic operators that allow us to maintain the evolutionary process:</p>
<ul class="ul1">
<li class="li3">The mutation operator implements random mutations of the offspring, which introduces genetic diversity into the population.</li>
<li class="li3">The crossover operator generates offspring by sampling genes from each parent.</li>
</ul>
<p class="p3">After that, we continued with a discussion about the importance of choosing the right genome encoding schema. We considered two major encoding formats that exist: direct and indirect genome encoding. The former introduces a one-to-one relationship between the genome and the encoded phenotype ANN. Usually, direct encoding is applied to encode small ANNs, which has a limited number of connected nodes. The more advanced indirect encoding scheme allows us to encode the evolving ANN topology of large networks, often with millions of connections. Indirect encoding allows us to reuse repeating encoding blocks, thus significantly reducing the size of a genome.</p>
<p class="p3">Once we were familiar with existing genome encoding schemes, we proceeded to discuss the neuroevolution method, which uses different encoding schemes. We started with an introduction to the NEAT algorithm, which uses the direct genome encoding scheme and enhances it with the concept of the innovation number. The innovation number associated with each gene of the genotype provides a means to precisely track when a particular mutation was introduced. This feature makes crossover operations between two parents straightforward and easy to implement. The NEAT method emphasizes the importance of starting from a very basic genome that gradually becomes more complex during evolution. In this manner, the evolutionary process has an excellent chance of finding the optimal solution.</p>
<p class="p3">Furthermore, the concept of speciation was introduced, which keeps useful mutations by isolating them in particular species (niches). The species within one niche are only allowed to cross over with each other. Speciation is the great moving force behind natural evolution, and it was shown to have a high impact on neuroevolution as well.</p>
<p class="p3">Having discussed the basic NEAT algorithm, we proceeded to a discussion of its derivatives to address the limitations of the original algorithm. One of the significant drawbacks of the NEAT algorithm is caused by using a direct genome encoding scheme. This scheme, while easy to visualize and implement, only encodes small topologies of the phenotype ANNs. With an increase in the phenotype ANN size, the size of the genome increases in linear proportion. This linear increase in genome size eventually makes it hard to maintain. Thus, to address these drawbacks, a series of extensions based on the indirect genome encoding schemes, such as HyperNEAT and ES-HyperNEAT, were introduced.</p>
<p class="p3">The HyperNEAT method uses an advanced format to represent connections between nodes of the phenotype ANN in the form of four-dimensional points in the hypercube. The chosen hypercube's dimensionality is based on the fact that connections between two nodes within an ANN can be encoded by the coordinates of connection endpoints in a medium called the substrate. The substrate topology provides a framework that draws connections between the nodes of the phenotype ANN. The strength of a connection that's drawn between two particular nodes in a substrate is estimated by the auxiliary neural network known as the <strong>Compositional Pattern Producing Network</strong> (<strong>CPPN</strong>). The CPPN receives the coordinates of the hyper-point (the coordinates of the connection endpoints) as input and calculates the strength of the connection. Also, it computes the value of the flag, which indicates whether a connection should be expressed or not. The experimenter defines the substrate configuration in advance. It is defined by the geometric properties of the problem to be solved. At the same time, the topology of the CPPN is evolved during the neuroevolution process using the NEAT algorithm. Thus, we have the best of both worlds. The power of the NEAT algorithm allows us to evolve the optimal CPPN configurations. At the same time, the indirect encoding scheme is maintained by the CPPN and allows us to represent large phenotype ANNs.</p>
<p class="p3">The ES-HyperNEAT method introduces a further enhancement to the original NEAT and HyperNEAT methods by proposing an advanced method of substrate evolution that's on par with the evolution of the connectivity CPPN. The substrate evolution is built around the notion of information density, which allows more dense node placement in the areas with higher information variability. This approach allows the neuroevolution process to discover substrate configurations that precisely follow the geometrical regularities that are exposed by the problem to be solved.</p>
<p class="p3">We finished the first chapter with a discussion about the fascinating search optimization method known as <strong>Novelty Search</strong> (<strong>NS</strong>). This method is based on the concept of guiding the evolutionary search by criteria that have been estimated using the novelty of the solutions found. Conventionally, search optimization is based on goal-oriented fitness criteria, which measure how close we are to the goal. But there is a whole area of real-world problems that have deceptive fitness function landscapes, which introduce strong local optima traps. The goal-oriented search has a good chance of getting stuck in one of these traps and failing to find the ultimate solution. At the same time, the search optimization method, which rewards the novelty of the solution found, allows us to avoid these traps by completely ignoring the proximity to the final goal. The NS method was shown to be effective in tasks of autonomous navigation through deceptive maze environments; it outperformed the objective-based search methods.</p>
<p class="p3">In the next chapter of this book, we discussed how to set up a working environment correctly and what Python libraries can be used to experiment with neuroevolution.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Python libraries and environment setup</h1>
                
            
            
                
<p class="p3">In this chapter, we started by discussing the practical aspects of the neuroevolution methods. We discussed the pros and cons of popular Python libraries that provide implementations of the NEAT algorithm and its extensions.</p>
<p class="p3">Along with the highlights of each Python library, we also provided small code snippets, giving you a feel of how to use each specific library in your experiments.</p>
<p class="p3">After that, we proceeded to discuss how to correctly set up the working environment. The working environment must have the necessary dependencies installed to allow the usage of the mentioned Python libraries. The installation can be done using several methods. We considered the two most common ones – the standard <strong>package installer for Python</strong> (<strong>PIP</strong>) utility and the Anaconda Distribution. Another critical aspect of the working environment's preparation is the creation of isolated virtual Python environments for each specific experiment. The virtual environments provide the benefits of having different dependency configurations for varying combinations of experiments and the NEAT Python libraries that are used in them.</p>
<p class="p3">Having dependencies isolated in a virtual environment also allows easy management of all the installed dependencies as a whole. The environment can be quickly deleted from your PC with everything installed into it, thus freeing disk space. You can also reuse a specific virtual environment for different experiments, which depends on the same NEAT implementation library.</p>
<p class="p3">This chapter should have got you familiar with every tool you need in order to start with neuroevolution experiments. In the next chapter, we proceeded to discuss the XOR solver experiment using the basic NEAT algorithm.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using NEAT for XOR solver optimization</h1>
                
            
            
                
<p class="p3">This was the first chapter in which we started experimenting with the NEAT algorithm. We did this by implementing a solver for one of the classic computer science problems. We started by building a solver for the XOR problem. The XOR problem solver is a computer science experiment in the field of reinforcement learning. The XOR problem cannot be linearly separated and thus requires a solver to find the non-linear execution path. However, we can find the non-linear execution path by introducing hidden layers into the ANN structure.</p>
<p class="p3">We discussed how the NEAT algorithm perfectly fits this requirement due to its inherent ability to evolve ANNs from a very simple or a complex topology by gradual complexification. In the XOR experiment, we started with an initial ANN topology that consisted of the two input nodes and a single output node. During the experiment, the relevant topology of the solver ANN was discovered, and it introduced an additional hidden node representing the non-linearity, as we expected.</p>
<p class="p3">Also, we explained how to define an appropriate fitness function to guide the evolutionary search and to understand how to implement it in the Python script. We put great attention into describing the hyperparameters that fine-tune the performance of the NEAT-Python library for the XOR experiment.</p>
<p class="p3">In this chapter, we acquired the skills that are necessary in order to implement basic solvers for essential computer science experiments and were ready to move on to more advanced experiments.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Pole-balancing experiments</h1>
                
            
            
                
<p class="p3">In this chapter, we continued with experiments related to the classic problems of computer science in the field of reinforcement learning. We started with a discussion of how to implement an avoidance control optimization method using the NEAT algorithm, allowing us to balance a cart-pole apparatus (or an inverted pendulum). We began with a single pole-balancing system and provided all the necessary equations of motion that allow us to numerically approximate real-world physical apparatus.</p>
<p class="p3">We learned how specific control actions could be applied to the cart-pole apparatus in the form of the bang-bang controller. The bang-bang controller is a unique form of control system that is designed to apply a series of actions with equal force but in different directions continuously. To manage a bang-bang controller, the control's ANN needs to continuously receive and analyze the state of the cart-pole apparatus and produce the relevant control signals. The input signals of the system are defined by the horizontal position of the cart on the track, its linear speed, the current angle of the pole, and the angular speed of the pole. The output of the system is a binary signal indicating the direction of a control action that needs to be applied.</p>
<p class="p3">The neuroevolution process uses the cart-pole apparatus' simulation for the trial and error process characteristic of every RL-style training algorithm. It maintains the population of the genomes that evolve from generation to generation until a successful solver is found. During their evolution, each organism in the population is tested against a simulation of the cart-pole apparatus. At the end of the simulation, it receives a reward signal in the form of the number of time steps during which it was able to keep the apparatus balanced within the track's bounds. The received reward signal defines the fitness of the organism and determines its fate during the neuroevolution process.</p>
<p class="p3">Then, we discussed how the objective function could be defined using the mentioned reward signal. After that, you learned how to implement an objective function using Python.</p>
<p class="p3">Having finished with a single pole-balancing experiment, we looked at a modified version of this experiment. The modified version comprised two poles with different lengths connected to the moving cart that needed to be balanced. This experiment had more complicated physics and required the discovery of a much more sophisticated controller during the experiment.</p>
<p class="p3">Both experiments that were presented in this chapter highlighted the importance of keeping a well-balanced population of solvers with a moderate number of species. Too many species in the population may hinder the neuroevolution process by reducing the chance of reproduction between the two organisms belonging to different species. Furthermore, taking into account that the population size is fixed, the more species you have within the population, the less populated they become. Sparsely populated species reduce the chance of discovering useful mutations. On the other hand, separate species allow us to maintain useful mutations within each speciation niche and exploit each mutation further in the next generations. Thus, too few species are also harmful to evolution. At the end of the pole-balancing experiment, you gained some practical skills that relate to keeping the number of species balanced by tweaking the corresponding hyperparameters of the NEAT algorithm (such as the compatibility threshold).</p>
<p class="p3">Another essential feature of the neuroevolution process that was highlighted in the pole-balancing experiment is related to the selection of the right initial condition of the stochastic process that guides the evolutionary process. The neuroevolution method's implementation is built around a pseudo-random number generator, which provides the likelihood of genome mutations and crossover rates. In the pseudo-random number generator, the sequence of numbers that will be produced is solely determined by the initial seed value that is supplied to the generator at the beginning. By using the same seed value, it is possible to produce the same random number sequences using the pseudo-random generator.</p>
<p class="p3">As a result of the experiment with the evolving controller's ANN for the cart-pole balancers, we discovered that the probability of finding a successful solution strongly depends on the value of the random number generator seed.</p>
<p class="p3">Mastering the pole-balancing experiments allowed you to be prepared to solve more complex problems associated with autonomous navigation, which were discussed in the next chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Autonomous maze navigation</h1>
                
            
            
                
<p class="p3">In this chapter, we continued our experiments with neuroevolution as an attempt to create a solver that can find an exit from a maze. Maze solving is a fascinating problem as it allows us to study a new search optimization method called Novelty Search. In <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>, and <a href="62301923-b398-43da-b773-c8b1fe383f1d.xhtml" target="_blank"/><a href="62301923-b398-43da-b773-c8b1fe383f1d.xhtml" target="_blank">Chapter 6</a>, <em>Novelty Search Optimization Method</em>, we explored a series of the maze navigation experiments using the goal-oriented search optimization and the Novelty Search optimization method.</p>
<p class="p3">In this chapter, you learned how to implement a simulation of a robot that has an array of sensors that detect obstacles and monitor its position within the maze. Also, we discussed how to implement a goal-oriented objective function to guide the evolutionary process. The mentioned objective-function implementation is calculated as Euclidean distance between the robot's final position and the maze's exit.</p>
<p class="p3">Using the maze navigation simulator and the defined objective function, we conducted two experiments with simple and hard maze configurations. The results of the experiments give us insights into the impact of the deceptive fitness function landscape on the performance of the evolutionary process. In local optima areas, neuroevolution tends to produce fewer species, which hinders its ability to explore novel solutions. In extreme cases, this leads to the degeneration of the evolutionary process. This can result in having only a single species in the entire population.</p>
<p class="p3">At the same time, you learned how to avoid such misfortunes by adjusting NEAT hyperparameters such as the compatibility disjoint coefficient. This parameter controls how strong topological differences in the compared genomes affect the compatibility factor, which is used to determine whether genomes belong to the same species. As a result, we were able to boost speciation and increase population diversity. This change had a positive impact on the search for a successful maze solver, and we were able to find it for a simple maze configuration. However, a hard maze configuration with more extreme local optima areas resisted all our attempts to find a successful maze solver using the goal-oriented objective function.</p>
<p class="p3">Thus, we were ready to learn about the Novelty Search optimization method, which was devised to overcome the limitations of the goal-oriented search.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Novelty Search optimization method</h1>
                
            
            
                
<p class="p3">In all the experiments preceding this chapter, we defined an objective function as a derivative based on its proximity to the final goal of the problem. However, the maze-solving problem posed challenges that could not be solved by a goal-oriented objective function. Specific maze configurations can introduce strong local optima in which a goal-oriented objective search may become stuck. In many cases, a deceptive fitness function landscape such as this effectively blocks a goal-oriented objective search from finding a successful solution.</p>
<p class="p3">Thus, using the practical experience we gained during the creation of a maze solver in the previous chapter, we embarked on the path of creating a more advanced solver. Our brand new solver used the Novelty Search optimization method to guide the evolutionary process. However, first of all, we needed to define the appropriate metric to estimate the novelty score of each solution in each generation. The novelty score that was produced by this metric was going to be used as a fitness value that would be assigned to the genomes in the population of solvers. Thus, the novelty is integrated into the standard neuroevolution process.</p>
<p class="p3">The novelty metric should measure how novel each solution is compared to the solutions we found in the past and all the solutions from the current generation. There are two ways to measure solution novelty: </p>
<ul class="ul1">
<li class="li3">The genotypic novelty is the novelty score and shows how the genotype of the current solution differs from the genotypes of all the other found solutions.</li>
<li class="li3">The behavioral novelty demonstrates how the behavior of the current solution differs within the problem space compared to all the other solutions.</li>
</ul>
<p class="p3">For the problem of solving a maze, a good choice is to use a behavioral novelty score because, in the end, we are interested in reaching the maze exit, which can be facilitated by exposing a certain behavior. Furthermore, the behavioral novelty score is much easier to calculate than the genotypic novelty score.</p>
<p class="p3">The trajectory of a particular solver through the maze defines its behavioral space. Thus, we can estimate the novelty score by comparing the trajectory vectors of the solvers. Numerically, the novelty score can be estimated by calculating the Euclidean distance between trajectory vectors. To further simplify this task, we can use only the coordinates of the last point of the solver trajectory to estimate the novelty score.</p>
<p class="p3">Having defined the novelty metric, you learned how to implement it in the source code using Python and integrate it into the maze simulator you created in <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank"/><a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>. After that, you were ready to repeat the experiments from the previous chapter and compare the results.</p>
<p class="p3">The experiment with a simple maze solver demonstrated an improvement in the topology of the produced control ANN. The topology became optimal and less complicated.</p>
<p class="p3">Unfortunately, the experiment with hard maze configuration also failed to produce a successful solver, the same as it did in <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>. The failure seems to be caused by the inefficiency of a particular implementation of the NEAT algorithm used in the experiment. I have implemented the NEAT algorithm in Go so that it solves the hard maze configuration with ease using the Novelty Search optimization. You can find it on GitHub at <a href="https://github.com/yaricom/goNEAT_NS">https://github.com/yaricom/goNEAT_NS</a>.</p>
<p class="p3">In <a href="62301923-b398-43da-b773-c8b1fe383f1d.xhtml" target="_blank">Chapter 6</a>, <em>Novelty Search Optimization Method</em>, you learned that the Novelty Search optimization method allows you to find a solution, even when the fitness function has a deceptive landscape with many local optima traps scattered inside. You have learned that the stepping stones forming the way to the solution are not always obvious. Sometimes, you need to step back to find the correct way. That is the main idea behind the Novelty Search method. It tries to find a solution by completely ignoring the proximity to the final goal and rewarding the novelty of each intermediate solution that is found on the way.</p>
<p class="p3">In this chapter, we got acquainted with the standard NEAT algorithm, and we were ready to begin experimenting with its more advanced extensions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Hypercube-based NEAT for visual discrimination</h1>
                
            
            
                
<p class="p3">This chapter was the first of four chapters in which we discussed advanced neuroevolution methods. In this chapter, you learned about the indirect genome encoding scheme, which uses the <strong>Compositional Pattern Producing Network</strong> (<strong>CPPN</strong>) to aid with the encoding of large phenotype ANN topologies. The CPPN encoding scheme introduced by the NEAT extension is named <strong>HyperNEAT</strong>. This extension is built around the concept of the connectivity substrate that represents the phenotype ANN topology. At the same time, connections between nodes in the substrate are expressed as four-dimensional points within the hypercube. In the HyperNEAT method, the topology of the CPPN is the part that is evolving and guided by the NEAT algorithm. We had already discussed the particulars of HyperNEAT, so we skipped the rest of the details of HyperNEAT for brevity.</p>
<p class="p3">In this chapter, we presented you with the interesting task of visual discrimination, which highlights the ability of the HyperNEAT algorithm to distinguish patterns in the visual field. You learned that the HyperNEAT method could find a successful visual pattern discriminator due to its inherent ability to reuse the successful connectivity patterns it found multiple times in the substrate that encodes the phenotype ANN of the solver. This was possible because of the power of the CPPN, which can discover the right strategy by passing signals from the input nodes (the perceiving image) to the output nodes (representing results).</p>
<p class="p3">You learned how to choose the correct geometry of a substrate to effectively employ the capabilities of the CPPN to find the geometric regularities. After that, you had a chance to apply your acquired knowledge in practice by implementing the visual discriminator that was trained using the HyperNEAT algorithm.</p>
<p class="p3">Also, having completed the visual discriminator experiment, you were able to verify the effectiveness of the indirect encoding scheme. We did this by comparing the topology of the produced CPPN with the maximum possible number of connections in the discriminator ANN substrate. The results of the visual discriminator experiment were pretty impressive. We were able to achieve an information compression ratio of 0.11% by encoding the connectivity pattern among 14,641 possible connections of the substrate, with only 16 connections between 10 nodes of the CPPN.</p>
<p class="p3">Visual tasks expose a high demand for the discriminator ANN architecture due to the high dimensionality of the input signal. Thus, in <a href="9f3dce4d-2cc7-4307-a704-bfcfe4ad56b4.xhtml" target="_blank">Chapter 8</a>, <em>ES-HyperNEAT and the Retina Problem</em>, we proceeded with a review of another class of visual recognition problems.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">ES-HyperNEAT and the retina problem</h1>
                
            
            
                
<p class="p3">In this chapter, you learned how to select the substrate configuration that is best suited for a specific problem space. However, it is not always obvious what configuration to choose. If you select the wrong configuration, you can significantly impact the performance of the training process. As a result, the neuroevolution process can fail to produce a successful solution. Also, particular substrate configuration details can only be discovered during the training process, and cannot be known in advance.</p>
<p class="p3">The problem with finding an appropriate substrate configuration was solved using the ES-HyperNEAT method. In this chapter, you learned how the neuroevolution process could automatically handle the evolution of the substrate configuration among the evolution of connectivity CPPNs. We introduced you to the concept of the quadtree data structure, which allows effective traversal through the substrate topology and the detection of areas with high information density. We learned that it is beneficial to automatically place new nodes into these areas to create more subtle connectivity patterns, which describe hidden regularities that can be found in the real world.</p>
<p class="p3">After you became familiar with the details of the ES-HyperNEAT algorithm, you learned how to apply it to solve the visual recognition task known as the retina problem. In this task, the neuroevolution process needs to discover a solver that can recognize valid patterns simultaneously in two separate visual fields. That is, the detector ANN must decide if patterns presented in the right and left visual fields are valid for each field. The solution of this task can be found by introducing the modular architecture to the topology of the detector ANN. In such a configuration, each ANN module is responsible only for pattern recognition in the related side of the retina.</p>
<p class="p3">In this chapter, we implemented a successful retina problem solver using the ES-HyperNEAT method. We were able to visually confirm that the produced topology of the detector ANN included the modular structures. Furthermore, from the experiment's results, you learned that the resulting detector ANN structure has near-optimal complexity. Once again, this experiment demonstrated the potential of neuroevolution-based methods to discover efficient solutions by method of gradual complexification.</p>
<p class="p3">All the experiments, including the one described in this chapter, used a particular form of the fitness function that is defined in advance before the experiments started. However, it would be interesting to explore how the performance of the neuroevolution algorithm changes if the fitness function is allowed to co-evolve along with the solution it tries to optimize.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Co-evolution and the SAFE method</h1>
                
            
            
                
<p class="p3">In this chapter, we discussed how the co-evolution strategy is widely found in nature and can be transferred into the realm of neuroevolution. You learned about the most common co-evolutionary strategies that can be found in nature: mutualism, competition (predation or parasitism), and commensalism. In our experiment, we explored the commensalistic type of evolution, which can be defined in commensalistic relationships as follows: the members of one species gain benefits without causing harm or giving benefits to other participating species.</p>
<p class="p3">Having learned about evolution strategies in the natural world, you were ready to understand the concepts behind the SAFE method. The abbreviation <strong>SAFE</strong> means <strong>Solution And Fitness Evolution</strong>, which suggests that we have two co-evolving populations: the population of potential solutions and the population of the fitness function candidates. At each generation of evolution, we evaluate each potential solution against all the objective function candidates and choose the best fitness score, which is observed as the fitness of the genome encoding solution. At the same time, we evolve the commensalistic population of the fitness function candidates using the Novelty Search method. Novelty Search uses the genomic novelty of each genome in the population as a novelty metric to estimate the individual's fitness score.</p>
<p class="p3">In this chapter, you learned how to implement a modified maze solving experiment based on the SAFE method to evaluate the performance of the co-evolution strategy. Also, you learned how to define the objective function to guide the evolution of the population of potential solutions. This objective function includes two fitness metrics: the first is the distance from the maze exit, while the second is the behavioral novelty of the solution that was found. These metrics are combined using the coefficients that are produced by a population of the fitness function candidates.</p>
<p class="p3">As in all the previous chapters, you continued to improve your Python skills by implementing the SAFE method using the MultiNEAT Python library. In the next chapter, you continued by studying even more advanced methods, thereby allowing you to use neuroevolution to train Atari game solvers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Deep Neuroevolution</h1>
                
            
            
                
<p class="p3">In this chapter, we presented you with the concept of deep neuroevolution, which can be used to train <strong>Deep Artificial Neural Networks</strong> (<strong>DNNs</strong>). You learned how deep neuroevolution can be used to train Atari game-playing agents using the deep reinforcement learning algorithm.</p>
<p class="p3">We started with a discussion of the basic concepts behind reinforcement learning. We paid special attention to the popular Q-learning algorithm, which is one of the classic implementations of reinforcement learning. After that, you learned how a DNN could be used to approximate the Q-value function for complex tasks that cannot be approximated by a simple action-state table with Q-values. Next, we discussed how the neuroevolution-based method could be used to find the trainable parameters of the DNN. You learned that neuroevolution evolves a DNN for Q-value function approximation. As a result, we can train the appropriate DNN without using any form of error backpropagation that is common in conventional methods of DNN training.</p>
<p class="p3">Having learned about deep reinforcement learning, you were ready to apply your knowledge in practice by implementing the Atari game solver agent. To train an agent to play the Atari game, it needs to read the pixels of the game screen and derive the current state of the game. After that, using the extracted game state, the agent needs to select an appropriate action to be executed in the game environment. The ultimate goal of the agent is to maximize the final reward that will be received after completion of a particular game episode. Thus, we have classic trial and error learning, which is the essence of reinforcement learning.</p>
<p class="p3">As we mentioned, the game-playing agent needs to parse game screen pixels. The best way to do this is to use a <strong>Convolutional Neural Network</strong> (<strong>CNN</strong>) to process the inputs that are received from the game screen. In this chapter, we discussed the essentials of the CNN architecture and how it can be integrated into the game-playing agent. You learned how to implement CNN in Python using a popular TensorFlow framework.</p>
<p class="p3">Also, you learned about a unique genome encoding scheme that was designed specifically for tasks related to deep neuroevolution. This scheme allows us to encode the phenotype ANNs with millions of trainable parameters. The proposed scheme employs the seeds of the pseudorandom number generator to encode the connection weights of the phenotype ANN. In this encoding scheme, the genome was represented as a list of the random generator seeds. Each seed is used consequentially to generate all the connection weights from a source of pseudorandom numbers.</p>
<p class="p3">After learning about the details of genome encoding, you were ready to start an experiment that aimed to create an agent that was able to play the Frostbite Atari game. Furthermore, you learned how to employ a modern GPU to accelerate the computations involved in the training process. At the end of this chapter, we also presented an advanced visualization tool (VINE) that allows us to study the results of the neuroevolution experiments.</p>
<p class="p3">With this chapter, we finished our brief acquaintance with the most popular neuroevolution methods that exist at the time of writing this book. However, there are still many things that you can learn in the fast-growing field of applied artificial intelligence and neuroevolution methods.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Where to go from here </h1>
                
            
            
                
<p class="p2">We hope that your journey through the neuroevolution methods that were presented in this book was pleasant and insightful. We have done our best to present you with the most recent achievements in the field of neuroevolution. However, this field of applied computer science is developing rapidly, and new achievements are announced almost every month. There are many laboratories in universities, as well as in corporations around the globe, working on applying neuroevolution methods to solve tasks that are beyond the strength of mainstream deep learning algorithms.</p>
<p class="p2">We hope that you have become fond of the neuroevolution methods we discussed and are eager to apply them in your work and experiments. However, you need to continue your self-education to keep pace with the next achievements in the area. In this section, we will present some places where you can continue your education.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Uber AI Labs</h1>
                
            
            
                
<p class="p3">The core of Uber AI Labs is built around the Geometric Intelligence startup that was co-founded by Kenneth O. Stanley – one of the prominent pioneers in the field of neuroevolution. He is the author of the NEAT algorithm, which we have used often in this book. You can follow the works of Uber AI Labs at <a href="https://eng.uber.com/category/articles/ai/">https://eng.uber.com/category/articles/ai/</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">alife.org</h1>
                
            
            
                
<p class="p3">The <strong>International Society for Artificial Life</strong> (<strong>ISAL</strong>) is a well-established community of researchers and enthusiasts from all around the world who are interested in scientific research activities related to artificial life. Genetic algorithms and neuroevolution, in particular, are among the areas of interest of this society. ISAL publishes the Artificial Life journal and sponsors a variety of conferences. You can find out more about ISAL activities at <a href="http://alife.org/">http://alife.org</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Open-ended evolution at Reddit</h1>
                
            
            
                
<p class="p3">The concept of open-ended evolution is directly related to genetic algorithms and neuroevolution in particular. Open-ended evolution assumes the creation of an evolutionary process that is not bound by any particular goal. It is inspired by the natural evolution of biological organisms, which produced us, humans. There is a dedicated subreddit where all of those who are interested discuss the research. You can find it at <a href="https://www.reddit.com/r/oee/">https://www.reddit.com/r/oee/</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The NEAT Software Catalog</h1>
                
            
            
                
<p class="p3">The University of Central Florida maintains the list of software libraries that implement the NEAT algorithm and its extensions. The software is moderated by Kenneth O. Stanley, the author of the NEAT algorithm. My implementation of the NEAT and Novelty Search in Go language is also present in this catalog. You can find it at <a href="http://eplex.cs.ucf.edu/neat_software/">http://eplex.cs.ucf.edu/neat_software/</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">arXiv.org</h1>
                
            
            
                
<p class="p3"><a href="http://arxiv.org/">arXiv.org</a> is a well-known service that publishes preprints of papers in many areas of science. It is generally an excellent source of cutting-edge information in the area of computer science. You can search through it for neuroevolution-related papers using the following search query: <a href="http://search.arxiv.org:8081/?query=neuroevolution&amp;in=grp_cs">http://search.arxiv.org:8081/?query=neuroevolution&amp;in=grp_cs</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The NEAT algorithm paper</h1>
                
            
            
                
<p class="p3">The original dissertation written by Kenneth O. Stanley describing the NEAT algorithm is a very enlightening read and is recommended for everyone interested in neuroevolution. It is available at <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf">http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we briefly summarized what we learned in this book. You also learned about the places where you can search for further insights and continue your self-education.</p>
<p class="p1">We are happy to live in an era where the future becomes a reality at such a pace that we completely fail to notice the tremendous changes that happen in our life. Humanity is rapidly moving on a path to mastering the marvels of gene editing and synthetic biology. We continue to conquer the deep mysteries of the human brain, which opens the way for an ultimate understanding of our consciousness. Our advanced experiments in cosmology allow us to zoom closer and closer to the very first moments of the Universe.</p>
<p class="p1">We have built an advanced piece of mathematical apparatus that allows us to describe such mysteries as a neutrino that, on its path, can become an electron and after that, a neutrino again. Our technological achievements can't be easily distinguished from magic, as Arthur C. Clark stated.</p>
<p class="p1">Life is about feeling its beauty. Keep your mind sharp, and always be curious. We are standing on the edge, where sparks from the research of synthetic consciousness will ignite the evolution of novel life forms. And who knows – maybe you will be the one who will start this.</p>
<p class="p1">Thank you, my dear reader, for your time and effort. I look forward to seeing what you will create using the knowledge you've gained from this book.</p>


            

            
        
    </body></html>