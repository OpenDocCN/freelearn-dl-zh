["```py\npublic class PCA {\n\n  DataSet originalDS;\n  int numberOfDimensions;\n  DataSet reducedDS;\n\n  DataNormalization normalization = new DataNormalization(DataNormalization.NormalizationTypes.ZSCORE);\n\n  public PCA(DataSet ds,int dimensions){\n    this.originalDS=ds;\n    this.numberOfDimensions=dimensions;\n  }\n\n  public DataSet reduceDS(){\n    //matrix algebra to calculate transformed data in lower dimension\n    …\n  }\n\n  public DataSet reduceDS(int numberOfDimensions){\n    this.numberOfDimensions = numberOfDimensions;\n    return reduceDS;\n  }\n\n}\n```", "```py\npublic abstract class DataFiltering {\n\n  DataSet originalDS;\n  DataSet filteredDS;\n\n}\n\npublic class ThreeSigmaRule extends DataFiltering {\n\n  double thresholdDistance = 3.0;\n\n  public ThreeSigmaRule(DataSet ds,double threshold){\n    this.originalDS=ds;\n    this.thresholdDistance=threshold;\n  }\n\n  public DataSet filterDS(){\n    //matrix algebra to calculate the distance of each point in each column\n    …\n  }\n\n}\n```", "```py\npublic DataSet applyPCA(int dimensions){\n  PCA pca = new PCA(this,dimensions);\n  return pca.reduceDS();\n}\n\npublic DataSet filter3Sigma(double threshold){\n  ThreeSigmaRule df = new ThreeSigmaRule(this,threshold);\n  return df.filterDS();\n}\n```", "```py\npublic class CrossValidation {\n  NeuralDataSet dataSet;\n  int numberOfFolds;\n\n  public LearningAlgorithm la;\n\n  double[] errorsMSE;\n\n  public CrossValidation(LearningAlgorithm _la,NeuralDataSet _nds,int _folds){\n    this.dataSet=_nds;\n    this.la=_la;\n    this.numberOfFolds=_folds;\n    this.errorsMSE=new double[_folds];\n  }\n\n  public void performValidation() throws NeuralException{\n    //shuffle the dataset\n    NeuralDataSet shuffledDataSet = dataSet.shuffle();\n    int subSize = shuffledDataSet.numberOfRecords/numberOfFolds;\n    NeuralDataSet[] foldedDS = new NeuralDataSet[numberOfFolds];\n    for(int i=0;i<numberOfFolds;i++){\n            foldedDS[i]=shuffledDataSet.subDataSet(i*subSize,(i+1)*subSize-1);\n    }\n    //run the training\n    for(int i=0;i<numberOfFolds;i++){\n      NeuralDataSet test = foldedDS[i];\n      NeuralDataSet training = foldedDS[i==0?1:0];\n      for(int k=1;k<numberOfFolds;k++){\n        if((i>0)&&(k!=i)){\n          training.append(foldedDS[k]);\n        }\n        else if(k>1) training.append(foldedDS[k]);\n      }\n      la.setTrainingDataSet(training);\n      la.setTestingDataSet(test);\n      la.train();\n      errorsMSE[i]=la.getMinOverallError();\n    }\n  }\n}\n```", "```py\npublic class NeuralNet{\n//…\n  public Boolean pruning;\n  public double senstitityThreshold;\n}\n```", "```py\n@Override\npublic Double calcNewWeight(int layer,int input,int neuron){\n  Double deltaWeight=calcDeltaWeight(layer,input,neuron);\n  if(this.neuralNet.pruning){\n    if(deltaWeight<this.neuralNet.sensitivityThreshold)\n      neuralNet.getHiddenLayer(layer).remove(neuron);\n  }\n  return newWeights.get(layer).get(neuron).get(input)+deltaWeight;\n}\n```", "```py\nInitialize the weights.\n   Initialize the learning rate.\n   Repeat the following steps:\n      Randomly select one (or possibly more) case(s)\n         from the population.\n      Update the weights by subtracting the gradient\n         times the learning rate.\n      Reduce the learning rate according to an\n         appropriate schedule.\n```", "```py\nprivate double reduceLearningRate(NeuralNet n, double percentage) {\n    double newLearningRate = n.getLearningRate() * \n                    ((100.0 - percentage) / 100.0);\n\n    if(newLearningRate < 0.1) {\n      newLearningRate = 1.0;\n    }\n\n    return newLearningRate;\n  }\n```", "```py\npublic class ART extends CompetitiveLearning{\n\n  private boolean vigilanceTest(int row_i) {\n    double v1 = 0.0;\n    double v2 = 0.0;\n\n    for (int i = 0; i < neuralNet.getNumberOfInputs(); i++) {\n      double weightIn  = neuralNet.getOutputLayer().getWeight(i);\n      double trainPattern = trainingDataSet.getIthInput(row_i)[i];\n\n      v1 = v1 + (weightIn * trainPattern);\n\n      v2 = v2 + (trainPattern * trainPattern);\n    }\n\n    double vigilanceValue = v1 / v2;\n\n    if(vigilanceValue > neuralNet.getMatchRate()){\n      return true;\n    } else {\n      return false;\n    }\n\n  }\n\n}\n```", "```py\nepoch=0;\nint k=0;\nforward();\n//...\ncurrentRecord=0;\nforward(currentRecord);\nwhile(!stopCriteria()){\n //...\n  boolean isMatched = this.vigilanceTest(currentRecord);\n  if ( isMatched ) {\n  applyNewWeights();\n} \n```"]