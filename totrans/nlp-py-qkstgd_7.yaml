- en: Building your Own Chatbot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chatbots, better referred to as conversation software, are amazing tools for
    a lot of businesses. They help businesses serve their client's server 24/7 without
    increasing effort, with consistent quality, and the built-in option to defer to
    a human when bots are not enough.
  prefs: []
  type: TYPE_NORMAL
- en: They are a great example of where technology and AI has come together to improve
    the impact of human effort.
  prefs: []
  type: TYPE_NORMAL
- en: They range from voice-based solutions such as Alexa, to text-based Intercom
    chat boxes, to menu-based navigation in Uber.
  prefs: []
  type: TYPE_NORMAL
- en: A common misconception is that building chatbots needs large teams and a lot
    of machine learning expertise, though this is true if you are trying to build
    a *generic* chatbot platform like Microsoft or Facebook (or even Luis, Wit.ai,
    and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Why build a chatbot?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figuring out the right user intent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bot responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why chatbots as a learning example?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have built an application for every NLP topic that we have seen:'
  prefs: []
  type: TYPE_NORMAL
- en: Text cleaning using grammar and vocabulary insights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linguistics (and statistical parsers), to mine questions from text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entity recognition for information extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervised text classification using both machine learning and deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text similarity using text-based vectors such as GloVe/word2vec
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now combine all of them into a much more complicated setup and write
    our own chatbot from scratch. But, before you build anything from scratch, you
    should ask why.
  prefs: []
  type: TYPE_NORMAL
- en: Why build a chatbot?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A related questions is why should we build our own chatbots? **Why can't I use
    FB/MSFT/some other cloud service?**
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps, a better question to ask is *when* to build on your own? These are
    the factors to keep in mind when making this decision:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Privacy and competition**:As a business, is it a good idea to share information
    about your users with Facebook or Microsoft? Or even a smaller company?'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cost and constraints**: Your funky cloud limits your design choices that
    are made by a particular intelligence provider to those that are made by the likes
    of Google or Facebook. Additionally, you are now paying for each HTTP call you
    make, which is slower than running code locally.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Freedom to customize and extend**: You can develop a solution that performs
    better for you! You don''t have to cure world hunger –just keep shipping an everi-ncreasing
    business value via quality software. If you are at a big company, you have all
    the more reason to invest in extendible software.'
  prefs: []
  type: TYPE_NORMAL
- en: Quick code means word vectors and heuristics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the sake of simplicity, we will assume that our bot does not need to remember
    the context of any question. Therefore it sees input, responds to it, and is done.
    No links are established with the previous input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by simply loading the word vectors using `gensim`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Phew, this might take a minute depending on your download speed. Once this
    is done, let''s unzip the file, get it to the data directory, and convert it into
    `word2vec` format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: By the end of the preceding code block, we have the 300-dimension GloVe embedding
    from the official Stanford source converted into the word2vec format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s load this into our working memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly check whether we can vectorize any word by checking for word
    embeddings for any word, for example, `awesome`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`awesome`, this works!'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at our first challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Figuring out the right user intent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is commonly referred to as the problem of intent categorization.
  prefs: []
  type: TYPE_NORMAL
- en: As a toy example, we will try to build an order bot that someone like DoorDash/Swiggy/Zomato
    might use.
  prefs: []
  type: TYPE_NORMAL
- en: Use case – food order bot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Consider the following sample sentence: *I''m looking for a cheap Chinese place
    in Indiranagar*.'
  prefs: []
  type: TYPE_NORMAL
- en: We want to pick out Chinese as a cuisine type in the sentence. We can obviously
    take simple approaches, like exact substring matching (search *Chinese*) or TF-IDF-based
    matches.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we will generalize the model to discover cuisine types that we might
    not have identified yet, but that can learn about via the GloVe embedding.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll keep it as simple as possible: we''ll provide some example cuisine types
    to tell the model that we need cuisines, and look for the most similar words in
    the sentence.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll loop through the words in the sentence and pick out the ones whose similarity
    to the reference words is above a certain threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '**Do word vectors even work for this?**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For simplicity's sake, the following code is written as `for` loops, but can
    be vectorized for speed.
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over each word in the input sentence and find the similarity score
    with respect to known cuisine words.
  prefs: []
  type: TYPE_NORMAL
- en: 'The higher the value, the more likely the word is to be something related to
    our cuisine references or `cuisine_refs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the corresponding output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The threshold is determined empirically. Notice that we are able to infer *Indian*
    and *Chinese* as cuisines, even if they are not part of the original set.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, exact matches will have a much higher score.
  prefs: []
  type: TYPE_NORMAL
- en: This is a good example where there's a better problem formulation in terms of
    the *generic* cuisine type that can be learned. This is more helpful than a dictionary-based
    cuisine type. This also proves that we can rely on word-vector-based approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Can we extend this for user intent classification? Let's try this next.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying user intent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We want to be able to put sentences into categories by user *intents*. Intents
    are a generic mechanism that combine multiple individual examples into one semantic
    umbrella. For example, *hi*, *hey*, *good morning*, and *wassup!* are all examples
    of the `_greeting_` intent.
  prefs: []
  type: TYPE_NORMAL
- en: Using *greeting* as an input, the backend logic can then determine how to respond
    to the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways we could combine word vectors to represent a sentence,
    but again we''re going to do the simplest thing possible: add them up.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is definitely a less-than-ideal solution, but works in practice because
    of the simple, unsupervised approach we use with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let's define a data dictionary with some examples for each intent.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using the data dictionary written by [Alan at the Rasa Blog](https://medium.com/rasa-blog/do-it-yourself-nlp-for-bot-developers-2e2da2817f3d)
    for this.
  prefs: []
  type: TYPE_NORMAL
- en: 'This dictionary can be updated since we have more user input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The approach we have is simple: we find the centroid of each *user intent*.
    A centroid is just a central point to denote each intent. Then, the incoming text
    is assigned to the user intent that''s nearest to the corresponding cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a simple function to find the centroid and update the dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add the centroid to the data dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s write a simple function to find the nearest user intent cluster now.
    We will use the L2 norm that we already implemented in `np.linalg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run this on some user text that is **not** in the **data dictionary**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding code generalizes well, and is convincing regarding the fact
    that this is good enough for the roughly 10-15 minutes it took for us to get to
    this point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Bot responses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We now know how to understand and categorize user intent. We now need to simply
    respond to each user intent with some corresponding responses. Let''s get these
    *template* bot responses in one place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Storing the `Response` map in a separate entity is helpful. This means that
    you can generate responses at a separate service from your intent understanding
    module and then glue them together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: If we think about this a little bit more, there is no need for the response
    map to be depend only on the intent that's categorized. You can convert this response
    map into a separate function that generates the map using related context and
    then picks a bot template.
  prefs: []
  type: TYPE_NORMAL
- en: But here, for simplicity, let's keep it as a dictionary/JSON-style structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a simple `get_bot_response` function that takes in the response
    mapping, templates, and the intent as input and returns the actual bot response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly try this with one sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The code is free of syntax errors at this point. This seems good to go for more
    performance testing. But before that, how can we make this better?
  prefs: []
  type: TYPE_NORMAL
- en: Better response personalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You'll notice that the function picks one template at random for any particular
    *bot intent*, so to say. While this is for simplicity here, in practice, you can
    train an ML model to pick a response that's personalized to a user.
  prefs: []
  type: TYPE_NORMAL
- en: A simple personalization to make is to adapt with the talking/typing of the
    user's style. For example, one user might be formal with, *Hello, how are you
    today?*, while another might be more informal with, *Y**o*.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, *Hello* gets *Goodbye!* in response while *Yo!* gets *Bye bye* or
    even *TTYL* in the same conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, let''s go ahead and check the bot response for the sentences that
    we have already seen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The responses can vary due to randomness; here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter on chatbots, we learned about *intent*, which usually refers
    to the user input, *response*, which is via the bot, *templates*, which defines
    the nature of bot responses, and *entities*, such as cuisine type, in our example.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, to understand the user intent—and even find entities—we used **unsupervised
    approaches** , that is, we did not have training examples this time. In practice,
    most commercial systems use a hybrid system, combining supervised and unsupervised
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: The one thing you should take away from here is that we don't need a lot of
    training data to make the first usable version of a bot for a specific use case.
  prefs: []
  type: TYPE_NORMAL
