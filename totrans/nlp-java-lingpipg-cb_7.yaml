- en: Chapter 7. Finding Coreference Between Concepts/People
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 在概念/人物之间寻找指代关系
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Named entity coreference with a document
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与文档的命名实体指代
- en: Adding pronouns to coreference
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向指代中添加代词
- en: Cross-document coreference
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨文档指代
- en: The John Smith problem
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约翰·史密斯问题
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: 'Coreference is a basic mechanism in human language that allows two sentences
    to be about the same thing. It''s a big deal for human communication—it functions
    much in the same way as variable names do in programming languages, with the additional
    subtly that scope is defined by very different rules than blocks. Coreference
    is less important commercially—maybe this chapter will help change that. Here
    is an example:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 指代是人类语言中的基本机制，它允许两个句子谈论同一件事。这对人类交流来说意义重大——它在很大程度上与编程语言中变量名的作用相同，只是作用域的定义规则与代码块不同。在商业上，指代的重要性较小——也许这一章能帮助改变这一点。以下是一个例子：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Coreference exists between `Alice` and `She`; the phrases talk about the same
    thing. It all gets very interesting when we start asking whether Alice in one
    document is the same as Alice in another.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “Alice”和“她”之间存在指代关系；这些短语谈论的是同一件事。当我们开始询问一个文档中的Alice是否与另一个文档中的Alice相同，事情就变得非常有趣。
- en: Coreference, like word-sense disambiguation, is a next-generation industrial
    capacity. The challenges of coreference contribute to the insistence of the IRS
    to have a social security number that unambiguously identifies persons independent
    of their names. Many of the techniques discussed were developed to help track
    persons and organizations in text data with varying degrees of success.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 语义消歧一样，指代消解是下一代工业能力。指代消解的挑战促使美国国税局坚持要求有一个社会安全号码，该号码可以明确地识别个人，而与他们的名字无关。许多讨论的技术都是为了帮助在文本数据中跟踪个人和组织，这些数据具有不同的成功程度。
- en: Named entity coreference with a document
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与文档的命名实体指代
- en: As seen in [Chapter 5](part0061_split_000.html#page "Chapter 5. Finding Spans
    in Text – Chunking"), *Finding Spans in Text – Chunking*, LingPipe can use a variety
    of techniques to recognize proper nouns that correspond to persons, places, things,
    genes, and so on. However, chunking doesn't quite finish the job, because it doesn't
    help with finding an entity when two named entities are the same. Being able to
    say that John Smith is the same entity as Mr. Smith, John or even an exact repeat,
    John Smith, can be very useful—so useful that the idea was the basis of our company
    when we were a baby-defense contractor. Our novel contribution was the generation
    of sentences indexed by what entities they mentioned, which turned out to be an
    excellent way to summarize what was being said about that entity, particularly
    if the mapping spanned languages—we call it **entity-based summarization**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第5章](part0061_split_000.html#page "第5章. 在文本中寻找跨度 – 分块")中所述，“在文本中寻找跨度 – 分块”，LingPipe可以使用各种技术来识别与人物、地点、事物、基因等相对应的正确名词。然而，分块并没有完成这项工作，因为它在两个命名实体相同的情况下无法帮助找到实体。能够说约翰·史密斯与史密斯先生、约翰或甚至完全重复的约翰·史密斯是同一实体，这可能非常有用——有用到这种想法成为我们公司作为婴儿防御承包商时的基础。我们的创新贡献是生成按提及的实体索引的句子，这最终证明是总结关于该实体所说内容的极好方法，尤其是如果映射跨越了语言——我们称之为**基于实体的摘要**。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The idea for entity-based summarization came about as a result of a talk Baldwin
    gave at the University of Pennsylvania at a graduate student seminar. Mitch Marcus,
    the then department chair, thought that showing all sentences that mentioned an
    entity—including pronouns—will be an excellent summary of that entity. In some
    sense, this comment is why LingPipe exists. It led to Baldwin leading a UPenn
    DARPA project and then the creation of Alias-i. Lesson learned—talk to everybody
    about your ideas and research.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 实体基础摘要的想法是在巴德温在宾夕法尼亚大学的一次研究生研讨会上发表演讲后产生的。当时的系主任米奇·马库斯认为，显示提及一个实体的所有句子——包括代词——将是对该实体的极好总结。在某种程度上，这个评论就是为什么LingPipe存在的原因。这导致了巴德温领导宾夕法尼亚大学的DARPA项目，然后创建了Alias-i。学到的教训——与所有人谈论你的想法和研究。
- en: This recipe will take you through the basics of computing coreferences.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱将带你了解计算指代的基本知识。
- en: Getting ready
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Lay your hands on some narrative text; we will use a simple example that we
    know works—coreference systems usually need a lot of tuning to the domain. Feel
    free to pick something else, but it will need to be in English.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 找到一些叙事文本；我们将使用一个我们知道可以工作的简单示例——共指系统通常需要对领域进行大量的调整。你可以自由选择其他内容，但它必须用英语编写。
- en: How to do it…
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: As usual, we will take you through running code from the command line and then
    dive into what the code actually does. Off we go.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，我们将带你通过命令行运行代码，然后深入探讨代码的实际功能。我们出发吧。
- en: 'We will start with a simple text to illustrate coreference. The file is in
    `data/simpleCoref.txt`, and it contains:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从一个简单的文本开始，以说明共指。文件位于`data/simpleCoref.txt`，它包含：
- en: '[PRE1]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Get thee to a command line and a Java interpreter and reproduce the following:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开命令行和一个Java解释器，重新生成以下内容：
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This results in:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这会导致：
- en: '[PRE3]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There are three named entities found. Note that there is an `ID` field in the
    output. The `John Smith` and `Mr. Smith` entities have the same ID, `id=0`. This
    means that the phrases are considered to be coreferent. The remaining entity `Washington`
    has a different ID, `id=1`, and is not coreferent with John Smith / Mr. Smith.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到了三个命名实体。请注意，输出中有一个`ID`字段。`John Smith`和`Mr. Smith`实体具有相同的ID，`id=0`。这意味着这些短语被认为是共指的。剩余的实体`Washington`具有不同的ID，`id=1`，并且与John
    Smith / Mr. Smith不共指。
- en: Create your own text file, supply it as an argument on the command line, and
    see what gets computed.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建你自己的文本文件，将其作为命令行参数提供，并查看会计算什么。
- en: How it works…
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The coreference code in LingPipe is a heuristic system built on top of sentence
    detection and named-entity recognition. The overall flow is as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: LingPipe中的共指代码是在句子检测和命名实体识别之上构建的启发式系统。整体流程如下：
- en: Tokenize the text.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分词文本。
- en: 'Detect sentences in the document, for each sentence, detect named entities
    in the sentence in the left-to-right order, and for each named entity, perform
    the following tasks:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文档中检测句子，对于每个句子，在句子中按从左到右的顺序检测命名实体，并对每个命名实体执行以下任务：
- en: Create a mention. A mention is a single instance of a named entity.
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个提及。提及是命名实体的单个实例。
- en: Mentions can be added to the existing mention chains, or they can start their
    own mention chains.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提及可以添加到现有的提及链中，或者它们可以开始自己的提及链。
- en: Try to resolve the mention to a mention chain that is already created. If a
    unique match is found, then add the mention to the mention chain; otherwise, create
    a new mention chain.
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试将提及解析到已创建的提及链中。如果找到唯一匹配项，则将提及添加到提及链中；否则，创建一个新的提及链。
- en: 'The code is in `src/com/lingpipe/cookbook/chapter7/NamedEntityCoreference.java`.
    The `main()` method starts by setting up the parts of this recipe, starting with
    a tokenizer factory, sentence chunker, and finally, a named-entity chunker:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码位于`src/com/lingpipe/cookbook/chapter7/NamedEntityCoreference.java`。`main()`方法首先设置本食谱的各个部分，从分词工厂开始，然后是句子块处理器，最后是命名实体块处理器：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we have set up the basic infrastructure for the recipe. Next is a coreference-specific
    class:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经为食谱设置了基本的基础设施。接下来是一个特定的共指类：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `MentionFactory` class creates mentions from phrases and types—the current
    source is named `entities`. Next, the coreference class is created with `MentionFactory`
    as a parameter:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`MentionFactory`类从短语和类型创建提及——当前源名为`entities`。接下来，使用`MentionFactory`作为参数创建共指类：'
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `WithinDocCoref` class wraps all the mechanics of computing coreference.
    From [Chapter 5](part0061_split_000.html#page "Chapter 5. Finding Spans in Text
    – Chunking"), *Finding Spans in Text - Chunking*, you should be familiar with
    the code to get the document text, detect sentences, and iterate over the sentences
    that apply a named-entity chunker to each sentence:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`WithinDocCoref`类封装了计算共指的所有机制。从[第5章](part0061_split_000.html#page "第5章. 文本中的跨度查找
    – 块处理")，*文本中的跨度查找 - 块处理*，你应该熟悉获取文档文本、检测句子以及迭代应用命名实体块处理器的句子代码：'
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the context of the current sentence, the named entities from the sentence
    are iterated over in the left-to-right order as they would be read. We know this
    because the `ChunkingImpl` class returns chunks in the order that they were added,
    and our `HMMChunker` adds them in the left-to-right order:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前句子的上下文中，句子中的命名实体按照从左到右的顺序迭代，就像它们被阅读时的顺序一样。我们知道这一点是因为`ChunkingImpl`类返回的块是按照它们被添加的顺序返回的，而我们的`HMMChunker`按照从左到右的顺序添加它们：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following code takes the information from the chunk—type and phrase, but
    *not* the offset information, and creates a mention:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码从信息块中获取类型和短语信息——但不包括偏移信息，并创建一个提及：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next line runs coreference with the mention and what sentence it is in
    and returns its ID:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下一行运行核心词引用与提及及其所在的句子，并返回其 ID：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If the mention was resolved to an existing entity, it will have that ID, as
    we saw with Mr. Smith. Otherwise, it will get a distinct ID and itself be available
    as an antecedent for subsequent mentions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提及被解析到现有实体，它将具有该 ID，正如我们在 Mr. Smith 例子中看到的。否则，它将获得一个独特的 ID，并且自身也可以作为后续提及的前体。
- en: This covers the mechanics of running within a document coreference. The upcoming
    recipes will cover the modification of this class. The next recipe will add pronouns
    and provide references.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这涵盖了在文档内运行核心词引用的机制。接下来的配方将涵盖对这个类的修改。下一个配方将添加代词并提供引用。
- en: Adding pronouns to coreference
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加代词到核心词引用
- en: The preceding recipe handled coreference between named entities. This recipe
    will add pronouns to the mix.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的配方处理了命名实体之间的核心词引用。此配方将添加代词到其中。
- en: How to do it…
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: This recipe will use an interactive version to help you explore the properties
    of the coreference algorithm. The system is very dependent on the quality of the
    named-entity detection, so use examples that the HMM is likely to get right. This
    was trained on *Wall Street Journal* articles from the '90s.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方将使用交互式版本来帮助您探索核心词算法的特性。系统非常依赖于命名实体检测的质量，因此请使用 HMM 可能会正确处理示例。这是在 90 年代的《华尔街日报》文章上训练的。
- en: 'Saddle up your console and type the following command:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你的控制台准备好，并输入以下命令：
- en: '[PRE11]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the resulting command prompt, type this:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生成的命令提示符中，输入以下内容：
- en: '[PRE12]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The shared ID between `He` and `John Smith` indicates the coreference between
    the two. More examples will follow, with comments. Note that each input is considered
    a distinct document with separate ID spaces.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`He` 和 `John Smith` 之间的共享 ID 表明两者之间的核心词引用。接下来将有更多示例，并附有注释。请注意，每个输入都被视为一个独立的文档，具有单独的
    ID 空间。'
- en: 'If pronouns are not resolved to a named entity, they get the index `-1` as
    shown here:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果代词没有解析到命名实体，它们将得到索引 `-1`，如下所示：
- en: '[PRE13]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following case also results in a `-1` value for `id`, because there is
    not one unique person in the prior context but two. This is called a failed uniqueness
    presupposition:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下案例也导致 `id` 的值为 `-1`，因为在先前的上下文中没有一个人，而是两个人。这被称为失败的唯一性预设：
- en: '[PRE14]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following code shows that `John Smith` can be resolved to a female pronoun
    as well. This is because there is no data about what names indicate which genders.
    It can be added, but generally, the context will disambiguate. `John` could be
    a female name. The key here is that the pronoun will disambiguate the gender,
    and a following male pronoun will fail to match:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码显示 `John Smith` 也可以解析到女性代词。这是因为没有关于哪些名字表示哪些性别数据。它可以添加，但通常情况下，上下文会消除歧义。`John`
    可能是一个女性名字。关键在于代词将消除性别歧义，而随后的男性代词将无法匹配：
- en: '[PRE15]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The gender assignment will block reference by an incorrect gender. The `He`
    pronoun in the following code is resolved to ID `-1`, because the only person
    is resolved to a female pronoun:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 性别分配将阻止错误性别引起的引用。以下代码中的 `He` 代词解析到 ID `-1`，因为唯一的人解析到了一个女性代词：
- en: '[PRE16]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Coreference can happen inside a sentence as well:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核心词引用也可以在句子内部发生：
- en: '[PRE17]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The order of the mentions (ordered by the most recent mention) matters when
    resolving mentions. In the following code, `He` is resolved to `James`, not `John`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在解析提及时，提及的顺序（按最近提及排序）很重要。在以下代码中，`He` 被解析到 `James`，而不是 `John`：
- en: '[PRE18]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The same effect takes place with named-entity mentions. The `Mr. Smith` entity
    resolves to the last mention:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样的效果也发生在命名实体提及上。`Mr. Smith` 实体解析到最后一次提及：
- en: '[PRE19]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The distinction between `John` and `James` goes away if there are too many
    intervening sentences:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果有太多的间隔句子，`John` 和 `James` 之间的区别就会消失：
- en: '[PRE20]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The preceding examples are meant to demonstrate the properties of the within-document
    coreference system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子旨在演示文档内核心词引用系统的特性。
- en: How it works…
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The code changes to add pronouns are straightforward. The code for this recipe
    is in `src/com/lingpipe/cookbook/chapter7/Coreference.java`. The recipe assumes
    that you understood the previous recipe, so it just covers the addition of pronoun
    mentions:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 添加代词的代码更改很简单。此配方的代码位于 `src/com/lingpipe/cookbook/chapter7/Coreference.java`。此配方假设你已经理解了前面的配方，所以它只涵盖了添加代词提及的部分：
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We added the `Mention` objects from multiple sources, so there are no order
    guarantees on the order of elements anymore. Correspondingly, we created `TreeSet`
    and the appropriate comparator and added all the chunkings from the `neChunker`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了来自多个来源的`Mention`对象，因此不再保证元素顺序。相应地，我们创建了`TreeSet`和适当的比较器，并添加了所有来自`neChunker`的切分。
- en: 'Next, we will add the male and female pronouns:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将添加男性和女性代词：
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `MALE_EN_PRONOUNS` constant is a regular expression, `Pattern`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`MALE_EN_PRONOUNS`常量是一个正则表达式，`Pattern`：'
- en: '[PRE23]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following lines of code show the `addRegExMatchingChunks` subroutine. It
    adds chunks based on regular expression matches and removes the overlapping, existing
    HMM-derived chunks:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行显示了`addRegExMatchingChunks`子例程。它基于正则表达式匹配添加块，并移除重叠的现有HMM派生的块：
- en: '[PRE24]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The one complex bit is that the type for the `MALE_PRONOUN` and `FEMALE_PRONOUN`
    pronouns will be used to match against `PERSON` entities, with the consequence
    that the resolution sets the gender of the resolved-to entity.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个复杂的问题是，`MALE_PRONOUN`和`FEMALE_PRONOUN`代词的类型将用于与`PERSON`实体匹配，其结果是解析集确定了解析到的实体的性别。
- en: Other than that, the code should look very familiar with our standard I/O loop
    running the interaction in the command prompt.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些，代码应该非常熟悉我们的标准I/O循环，在命令提示符中运行交互。
- en: See also
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The algorithm behind the system is based on the PhD. thesis of Baldwin. The
    system was called CogNIAC, and the work is from the mid '90s and is not a current
    state-of-the-art coreference system. A more modern approach would most likely
    use a machine-learning framework to take the features generated by Baldwin's approach
    and many other features and use it to develop a better performing system. A paper
    on the system is at [http://www.aclweb.org/anthology/W/W97/W97-1306.pdf](http://www.aclweb.org/anthology/W/W97/W97-1306.pdf).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 系统背后的算法基于Baldwin的博士论文。该系统被称为CogNIAC，这项工作始于20世纪90年代中期，并不是当前最先进的共指系统。更现代的方法可能会使用机器学习框架来利用Baldwin方法和其他许多特征生成特征，并用于开发性能更好的系统。关于该系统的论文可在[http://www.aclweb.org/anthology/W/W97/W97-1306.pdf](http://www.aclweb.org/anthology/W/W97/W97-1306.pdf)找到。
- en: Cross-document coreference
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨文档共指
- en: Cross-document coreference (XDoc) takes the `id` space of an individual document
    and makes it global to a larger universe. This universe typically includes other
    processed documents and databases of known entities. While the annotation is trivial,
    all that one needs to do is swap the document-scope IDs for the universe-scope
    IDs. The calculation of XDoc can be quite difficult.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 跨文档共指（XDoc）将单个文档的`id`空间扩展到更大的宇宙。这个宇宙通常包括其他已处理的文档和已知实体的数据库。虽然标注很简单，但只需要将文档范围ID交换为宇宙范围ID。XDoc的计算可能相当困难。
- en: This recipe will tell us how to use a lightweight implementation of XDoc developed
    over the course of deploying such systems over the years. We will provide a code
    overview for those who might want to extend/modify the code—but there is a lot
    going on, and the recipe is quite dense.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方将告诉我们如何使用在多年部署此类系统过程中开发的轻量级XDoc实现。我们将为可能想要扩展/修改代码的人提供代码概述——但内容很多，配方相当密集。
- en: 'The input is in the XML format where each file can contain multiple documents:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输入是XML格式，其中每个文件可以包含多个文档：
- en: '[PRE25]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The goal is to produce annotations where the mentions of Breck Baldwin share
    the same ID across documents as for Krishna. Note that both are mentioned by their
    nicknames in the last document.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是生成标注，其中Breck Baldwin的提及在文档中与Krishna共享相同的ID。请注意，在最后一份文档中，两者都提到了他们的昵称。
- en: A very common elaboration of XDoc is linking a **database** (**DB**) of known
    entities to text mentions of these entities. This bridges the divide between structured
    DB and unstructured data (text), which many consider to be the next big thing
    in business intelligence / voice of the customer / enterprise-knowledge management.
    We have built systems that linked DBs of genes/proteins to MEDLINE abstracts and
    persons-of-interest lists to free text, and so on. DBs also provide a natural
    way for human editors to control how XDoc behaves.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: XDoc的一种非常常见的扩展是将已知实体的**数据库**（**DB**）链接到这些实体的文本提及。这弥合了结构化数据库和非结构化数据（文本）之间的差距，许多人认为这是商业智能/客户声音/企业知识管理领域的下一个大趋势。我们已经构建了将基因/蛋白质数据库链接到MEDLINE摘要和感兴趣人员名单链接到自由文本的系统，等等。数据库还为人编者提供了一个自然的方式来控制XDoc的行为。
- en: How to do it...
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: All the code for this recipe is in the `com.lingpipe.cookbook.chapter7.tracker`
    package.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本菜谱的所有代码都在`com.lingpipe.cookbook.chapter7.tracker`包中。
- en: 'Gain access to your IDE and run `RunTracker` or type the following command
    in the command line:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取对您的IDE的访问权限并运行`RunTracker`或在命令行中输入以下命令：
- en: '[PRE26]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The screen will scroll by with the analysis of documents, but we will go to
    the designated output file and examine it. Open `cookbook/data/xDoc/output/docs1.xml`
    in your favorite text editor. You will see a poorly formatted version of the example
    output, unless your editor automatically formats XML usefully—the Firefox web
    browser does a decent job of rendering XML. The output should look like this:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 屏幕将滚动显示文档的分析，但我们将转到指定的输出文件并检查它。在您最喜欢的文本编辑器中打开`cookbook/data/xDoc/output/docs1.xml`。除非您的编辑器自动格式化XML，否则您将看到示例输出的糟糕格式版本——Firefox网络浏览器在渲染XML方面做得相当不错。输出应该看起来像这样：
- en: '[PRE27]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`Krishna` is recognized in the first two documents with the shared ID, `1000000002`,
    but the nickname, `K-dog`, is not recognized at all. `Breck` is recognized in
    all three documents, but since the ID on the third mention, `Breckles`, is different
    from the one in the first two mentions, the system does not consider them to be
    the same entity.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Krishna`在前两个文档中被识别为具有共享ID，`1000000002`，但昵称`K-dog`根本未被识别。`Breck`在所有三个文档中都被识别，但由于第三次提及时`Breckles`的ID与前两次提及的ID不同，系统不认为它们是同一实体。'
- en: 'Next, we will use a DB in the form of a dictionary to improve the recognition
    of the authors when they are mentioned via nicknames. There is a dictionary at
    `data/xDoc/author-dictionary.xml`; it looks like this:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用字典形式的数据库来提高通过昵称提及作者时的识别率。在`data/xDoc/author-dictionary.xml`中有一个字典；它看起来像这样：
- en: '[PRE28]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The aforementioned dictionary contains nicknames for both authors, in addition
    to their first names. Aliases that have the `xdc=1` value will be used to link
    entities across documents. The `xdc=0` value will only apply within a document.
    All aliases will be used to identify named entities via a dictionary lookup.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述字典包含作者的两个昵称，以及他们的名字。具有`xdc=1`值的别名将用于跨文档链接实体。`xdc=0`值仅适用于文档内部。所有别名都将通过字典查找来识别命名实体。
- en: 'Run the following command, which specifies the entity dictionary or IDE equivalent:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令，指定实体字典或IDE等效项：
- en: '[PRE29]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output in `xDoc/output/docs1.xml` is very different from that of the previous
    run. First, note that the IDs for us are now the same as specified in the dictionary
    file: `1` for `Breck` and `2` for `Krishna`. This is a link between the structured
    DB, such as the nature of the dictionary and unstructured text. Second, notice
    that both our nicknames have been correctly identified and assigned to the correct
    IDs. Third, note that the types are now `MALE` instead of `OTHER`:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`xDoc/output/docs1.xml`中的输出与上一次运行的结果非常不同。首先，请注意，现在的ID与我们指定的字典文件中的ID相同：`Breck`为`1`，`Krishna`为`2`。这是结构化数据库（如字典的性质）与无结构文本之间的链接。其次，请注意，我们的昵称都被正确识别并分配到了正确的ID。第三，请注意，类型现在是`MALE`而不是`OTHER`：'
- en: '[PRE30]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This was a very quick introduction to how to run XDoc. In the next section,
    we will see how it works.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对如何运行XDoc的非常快速的介绍。在下一节中，我们将看到它是如何工作的。
- en: How it works…
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Up until this recipe, we have attempted to keep code simple, straightforward,
    and understandable without a deep dive into piles of source. This recipe is more
    complicated. The code that backs this recipe is not going to fit into the allocated
    space for complete explanation. The exposition assumes that you will explore entire
    classes on your own and that you will refer to other recipes in this book for
    explanation. We offer this recipe because XDoc coreference is a very interesting
    problem, and our existing infrastructure might help others explore the phenomenon.
    Welcome to the deep end of the pool.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直试图保持代码简单、直接且易于理解，无需深入研究大量的源代码。这个菜谱更复杂。支撑这个菜谱的代码无法完全放入分配的解释空间中。本说明假设您将自行探索整个类，并且会参考本书中的其他菜谱进行解释。我们提供这个菜谱是因为XDoc核心参照问题非常有趣，我们现有的基础设施可能有助于他人探索这一现象。欢迎来到泳池的深处。
- en: The batch process life cycle
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理生命周期
- en: 'The entire process is controlled by the `RunTracker.java` class. The overall
    flow of the `main()` method is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程由`RunTracker.java`类控制。`main()`方法的整体流程如下：
- en: Read the DB of known entities that will be a source of named-entity recognition
    via `Dictionary` and a known mapping from aliases to dictionary entries. Aliases
    come with instructions regarding whether they should be used for matching entities
    across documents via the `xdc=1` or `xdc=0` flag.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `Dictionary` 读取已知实体数据库，这些实体将成为命名实体识别的来源，以及从别名到字典条目的已知映射。别名带有关于是否应通过 `xdc=1`
    或 `xdc=0` 标志在文档间匹配实体的说明。
- en: Set up `EnitityUniverse`, which is the global data structure of IDs for what
    is found in the texts and from the mentioned dictionary of known entities.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 `EntityUniverse`，这是全局数据结构，包含文本中找到的以及从已知实体字典中提到的实体的 ID。
- en: Set up what is needed for within-document coreference—things such as a tokenizer,
    sentence detector, and named-entity detector. It gets a bit fancy with a POS tagger
    and some word counts.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置文档内核心参照所需的内容——例如分词器、句子检测器和命名实体检测器。在 POS 标记器和一些词频统计方面，这会变得有些复杂。
- en: There is a Boolean that controls whether speculative entities will be added.
    If this Boolean is `true`, it means that we will update our universe of cross-document
    entities with the ones that we have never seen before. It is a much tougher task
    to reliably compute with this set to `true`.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有一个布尔值控制是否添加推测性实体。如果这个布尔值为 `true`，则意味着我们将更新我们的跨文档实体宇宙，包括我们之前从未见过的那些。将这个集合设置为
    `true` 是一个更艰巨的任务，需要可靠地计算。
- en: All the mentioned configuration goes into creating a `Tracker` object.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有提到的配置都用于创建一个 `Tracker` 对象。
- en: 'Then, the `main()` method reads in documents to process, hands them off to
    the `Tracker` object for processing, and writes them to disk. The major steps
    of the `Tracker.processDocuments()` method are as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，`main()` 方法读取要处理的文档，将它们交给 `Tracker` 对象进行处理，并将它们写入磁盘。`Tracker.processDocuments()`
    方法的重大步骤如下：
- en: Take a set of documents in the XML format and get the individual documents.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 XML 格式的文档集中提取单个文档。
- en: For each document, apply the `processDocument()` method, which runs within-document
    coreference using the dictionary to help find entities as well as the named-entity
    detector and returns `MentionChain[]`. Then, resolve the individual mentions'
    chains against the entity universe to update document-level IDs to entity universe
    IDs. The last step is to write the document to disk with the entity universe IDs.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个文档，应用 `processDocument()` 方法，该方法在文档内使用字典帮助找到实体以及命名实体检测器，并返回 `MentionChain[]`。然后，将个别提及的链与实体宇宙进行解析，以更新文档级别的
    ID 为实体宇宙 ID。最后一步是将文档写入磁盘，带有实体宇宙 ID。
- en: That is all that we will say about `RunTracker`; there is nothing in there that
    you should not be able to handle in the context of this book. In the following
    sections, we will address the individual components that `RunTracker` uses.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 `RunTracker` 的介绍就到这里；其中没有任何内容是你在这个书籍的上下文中无法处理的。在接下来的章节中，我们将讨论 `RunTracker`
    使用的各个组件。
- en: Setting up the entity universe
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设置实体宇宙
- en: The entity universe `EntityUniverse.java`, is an in-memory representation of
    the global entities mentioned in a document/database collection. The entity universe
    also contains various indexes into these entities, which support computing XDoc
    on individual documents.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实体宇宙 `EntityUniverse.java` 是文档/数据库集中提到的全局实体的内存表示。实体宇宙还包含对这些实体的各种索引，支持对单个文档计算
    XDoc。
- en: The dictionary seeds the `EntityUniverse` file with known entities, and the
    documents processed subsequently are sensitive to these entities. The XDoc algorithm
    tries to merge with existing entities before creating new ones, so the dictionary
    entities are strong attractors for mentions of these entities.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 字典用已知实体初始化 `EntityUniverse` 文件，随后处理的文档对这些实体敏感。XDoc 算法试图在创建新实体之前与现有实体合并，因此字典实体是这些实体提及的强大吸引物。
- en: 'Each entity consists of a unique long ID, a set of aliases partitioned into
    four separate lists and a type (person, location, and so on). Whether the entity
    is in the user-defined dictionary and whether speculative mentions are allowed
    to be added to the entity are also mentioned. The `toString()` method lists an
    entity as:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个实体由一个唯一的长期 ID、一组划分为四个单独列表的别名以及一个类型（人物、地点等）组成。实体是否在用户定义的字典中，以及是否允许将推测性提及添加到实体中，也都有说明。`toString()`
    方法将实体列出如下：
- en: '[PRE31]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The global data structures are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 全局数据结构如下：
- en: '[PRE32]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Entities need unique IDs, and we have a convention that the `FIRST_SYSTEM_ID`
    value is a large integer, such as `1,000,000`. This provides a space (IDs < 1,000,000)
    for users to add new entities without collisions with entities found by the system.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'We will instantiate a tokenizer for use across the tracker:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'There is a global mapping from unique entity IDs to the entities:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Another important data structure is a mapping from aliases (phrases) to entities
    that have the alias—`mXdcPhraseToEntitySet`. Only phrases that are candidates
    for finding likely matches for cross-document coreference get added here. From
    the dictionary, the aliases that are `xdc=1` are added:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: For speculatively found aliases, if the alias has at least two tokens and is
    not already on another entity, it is added to this set. This reflects a heuristic
    that tries hard to not split the entities apart. The logic of this is quite twisted
    and beyond the scope of this tutorial. You can refer to `EntityUniverse.createEntitySpeculative`
    and `EntityUniverse.addPhraseToEntity` for the code.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Why are some aliases not used in finding candidate entities? Consider that `George`
    has very little descriptive content to discriminate entities in `EntityUniverse`,
    but `George H.W. Bush` has much more information to work with.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: ProcessDocuments() and ProcessDocument()
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The interesting bits start to happen in the `Tracker.processDocuments()` method,
    which calls the XML parsing of each document and then incrementally calls the
    `processDocument()` method. The code is straightforward for the former, so we
    will move on to where the more task-specific work happens with the `processDocument()`
    method called:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We used a document format that supports distinguishing the title from the body
    of the document. This is a good idea if title case is distinct from body case,
    as is usual with newswire. The `chains` variable will have chains from the title
    and body of the text, with possible coreference between them. The `mentionStartList`
    and `mentionEndList` arrays will make it possible to realign the document scoped
    IDs with the entity universe scoped IDs later in the method:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Computing XDoc
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The XDoc code is the result of many hours of hand-tuning the algorithm to work
    well on news-style data. It has been run on datasets in the 20,000 document range
    and is designed to support dictionary entries very aggressively. The code also
    attempts to prevent **short circuits**, which occur when obviously different entities
    have been merged together. If you mistakenly make Barbara Bush and George Bush
    coreferent in your global database, then you will have embarrassingly bad results
    that users will see.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The other sort of error is having two entities in the global store when one
    will do. This is a sort of *Superman/Clark Kent problem* that can also apply to
    multiple mentions of the same name.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin with the top-level code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: A document has a list of mention chains, and each mention chain will be either
    added to an existing entity, or the mention chain will be promoted to being a
    new entity. Mention chains must contain a mention that is not pronominal, which
    is handled at the within-document coreference level.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 文档有一个提及链列表，每个提及链要么被添加到现有实体中，要么提及链被提升为新的实体。提及链必须包含一个非代词提及，这在文档内的共指级别进行处理。
- en: 'Three data structures are updated as each mention chain is processed:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 每处理一个提及链，都会更新三个数据结构：
- en: The `Entity[]` entities are returned by the `xdocCoref` method to support the
    inline annotation of the documents.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Entity[]` 实体由 `xdocCoref` 方法返回，以支持文档的行内注释。'
- en: '`Map<MentionChain,Entity> chainToEntity` maps from mention chains to entities.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Map<MentionChain,Entity> chainToEntity` 将提及链映射到实体。'
- en: '`ObjectToSet<Entity,MentionChain> entityToChainSet` is the converse of `chainToEntity`.
    It is possible that multiple chains in the same document get mapped to the same
    entity, so this data structure is sensitive to this possibility. This version
    of the code allows this to happen—in effect, XDoc is setting up a within-doc resolution
    as a side effect.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ObjectToSet<Entity,MentionChain> entityToChainSet` 是 `chainToEntity` 的逆映射。可能同一文档中的多个链会被映射到同一个实体，因此这个数据结构对这种可能性很敏感。这个版本的代码允许这种情况发生——实际上，XDoc
    正在将文档内的解析作为副作用设置起来。'
- en: Simple enough, if an entity is found, then the `addMentionChainToEntity()` method
    adds any new information from the mention chain to the entity. New information
    can include new aliases and type changes (that is, a person is moved to being
    male or female in virtue of a disambiguating pronoun reference). If no entity
    is found, then the mention chain goes to `promote()`, which creates a new entity
    in the entity universe. We will start with `promote()`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，如果找到了实体，那么 `addMentionChainToEntity()` 方法会将提及链中的任何新信息添加到实体中。新信息可以包括新的别名和类型变化（即，由于一个消歧代词的引用，一个人被移动到男性或女性）。如果没有找到实体，那么提及链将进入
    `promote()`，在实体宇宙中创建一个新实体。我们将从 `promote()` 开始。
- en: The promote() method
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`promote()` 方法'
- en: 'The entity universe is a minimalist data structure that just keeps track of
    phrases, types, and IDs. The `TTMentionChain` class is a more complex representation
    of the mentions of a particular document:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 实体宇宙是一个极简的数据结构，仅跟踪短语、类型和 ID。`TTMentionChain` 类是对特定文档中提及的更复杂表示：
- en: '[PRE39]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The call to `mEntityUniverse.createEntitySpeculative` only requires the phrases
    for the chain (in this case, normalized phrases that have been lowercased and
    in which all sequences of whitespaces converted into a single space) and the type
    of the entity. No record is kept of the document from which the mention chain
    came, counts, or other potentially useful information. This is to keep the memory
    representation as small as possible. If there is a need to find all the sentences
    or documents that an entity is mentioned in (a common task), then that mapping
    from entity IDs has to be stored elsewhere. The XML representation produced for
    the document after XDoc is run is a natural place to start addressing these needs.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `mEntityUniverse.createEntitySpeculative` 只需要链的短语（在这种情况下，是已经被转换为小写并且所有空白序列都转换为单个空格的规范化短语）和实体的类型。不会记录提及链来自的文档、计数或其他可能有用的信息。这是为了使内存表示尽可能小。如果需要找到实体被提及的所有句子或文档（这是一个常见任务），那么必须将实体
    ID 的映射存储在其他地方。XDoc 运行后生成的文档的 XML 表示是一个开始解决这些需求的自然地方。
- en: The createEntitySpeculative() method
  id: totrans-162
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`createEntitySpeculative()` 方法'
- en: 'Creation of a speculatively found new entity only requires determining which
    of its aliases are the good candidates to link mention chains. Those that are
    good for cross-document coreference go into the `xdcPhrases` set, and the others
    go into the `nonXdc` phrases:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个推测性找到的新实体只需要确定其别名中哪些是连接提及链的好候选。那些适合跨文档共指的进入 `xdcPhrases` 集合，其他则进入 `nonXdc`
    短语集合：
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `boolean` method, `XdcPhrase()`, plays a critical role in the XDoc process.
    The current approach supports a very conservative notion of what a good XDoc phrase
    is. Intuitively, in the domain of newswire, phrases such as `he`, `Bob`, and `John
    Smith` are poor indicators of a unique individual being talked about. Good phrases
    might be `Breckenridge Baldwin`, because that is likely a unique name. There are
    lots of fancy theories for what is going on here, see rigid designators ([http://en.wikipedia.org/wiki/Rigid_designator](http://en.wikipedia.org/wiki/Rigid_designator)).
    The next few lines of code run roughshod over 2,000 years of philosophical thought:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`boolean` 方法 `XdcPhrase()` 在 XDoc 过程中起着关键作用。当前方法支持一个非常保守的关于什么是好的 XDoc 短语的观点。直观地说，在新闻稿的领域，像
    `he`、`Bob` 和 `John Smith` 这样的短语是关于谈论的独特个体的较差指标。好的短语可能是 `Breckenridge Baldwin`，因为这很可能是一个独特的名字。关于这里发生的事情有许多复杂的理论，参见刚性指示符
    ([http://en.wikipedia.org/wiki/Rigid_designator](http://en.wikipedia.org/wiki/Rigid_designator))。接下来的几行代码对2000年的哲学思想进行了粗暴的践踏：'
- en: '[PRE41]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This approach attempts to identify the bad phrases for XDoc rather than the
    good ones. The reasoning is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法试图识别 XDoc 的坏短语而不是好短语。推理如下：
- en: '**There is already an entity associated with the phrase**: This enforces an
    assumption that there is only one John Smith in the world. This worked very well
    for intelligence-gathering applications, where the analysts had little trouble
    teasing apart the `John Smith` cases. You can refer to the *The John Smith problem*
    recipe at the end of this chapter for more about this.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短语已经与一个实体相关联**：这强制了一个假设，即世界上只有一个约翰·史密斯。这对于情报收集应用来说效果非常好，分析师们几乎没有困难地分辨出 `John
    Smith` 的情况。您可以在本章末尾的 *The John Smith problem* 菜单中了解更多关于此的信息。'
- en: '**The phrase is only one word, and there are multiword phrases associated with
    the mention chain or entity**: This assumes that longer words are better for XDoc.
    Note that different orders of entity creation can result in one-word phrases having
    `xdc` to be `true` on entities with multiword aliases.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短语仅由一个单词组成，并且与提及链或实体相关联的短语是多个单词的**：这假设较长的单词更适合 XDoc。请注意，实体创建的不同顺序可能导致具有多词别名的实体上的单词短语
    `xdc` 为 `true`。'
- en: '**The phrase is a pronoun**: This is a fairly safe assumption, unless we are
    in religious texts where `He` or `Him` capitalized in the middle of a sentence
    indicate reference to God.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短语是代词**：这是一个相当安全的假设，除非我们处于宗教文本中，其中句子中间大写的 `He` 或 `Him` 指的是上帝。'
- en: Once the sets of `xdc` and `nonXdc` phrases are known, then the entity is created.
    Refer to the source code for `Entity.java` to understand how entities are created.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦知道了 `xdc` 和 `nonXdc` 短语的集合，然后实体就被创建。请参考 `Entity.java` 的源代码来了解实体是如何创建的。
- en: 'Then, the entity is created, and an `add` method updates a mapping in the `EntityUniverse`
    file of `xdc` phrases to entity IDs:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，实体被创建，并且 `add` 方法更新 `EntityUniverse` 文件中 `xdc` 短语到实体 ID 的映射：
- en: '[PRE42]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `EntityUniverse` file's global `mXdcPhraseToEntitySet` variable is the key
    to finding candidate entities for XDoc as used in `xdcEntitiesToPhrase()`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`EntityUniverse` 文件中的全局 `mXdcPhraseToEntitySet` 变量是用于在 `xdcEntitiesToPhrase()`
    中查找 XDoc 的候选实体的关键。'
- en: The XDocCoref.addMentionChainToEntity() entity
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: XDocCoref.addMentionChainToEntity() 实体
- en: 'Returning to the `XDocCoref.xdocCoref()` method, we have covered how to create
    a new entity via `XDocCoref.promote()`. The next option to cover is what happens
    when a mention chain is resolved to an existing entity, namely `XDocCoref.addMentionChainToEntity()`.
    For the speculative mentions to be added, the entity must allow speculatively
    found mentions as provided by the `Entity.allowSpeculativeAliases()` method. This
    is a feature of the user-defined dictionary entities discussed in user-defined
    entities. If speculative entities are allowed, then the mention chains are added
    to the entity with a sensitivity to whether they are `xdc` phrases or not:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到 `XDocCoref.xdocCoref()` 方法，我们已经介绍了如何通过 `XDocCoref.promote()` 创建一个新的实体。接下来要介绍的是，当提及链解析为现有实体时会发生什么，即
    `XDocCoref.addMentionChainToEntity()`。为了添加推测性提及，实体必须允许由 `Entity.allowSpeculativeAliases()`
    方法提供的推测性找到的提及。这是在用户定义实体中讨论的用户定义字典实体的一个特性。如果允许推测性实体，那么提及链将被添加到实体中，同时考虑到它们是否是 `xdc`
    短语：
- en: '[PRE43]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The only change that adding a mention chain can add to an entity is the addition
    of a new phrase. The additional phrases are classified for whether they are `xdc`
    or not in the same way as was done in the promotion of a mention chain.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have gone over the basics of how mention chains from documents
    are either promoted to speculative entities or are merged with existing entities
    in `EntityUniverse`. Next, we will take a look at how resolution occurs in `XDocCoref.resolveMentionChain()`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: The XDocCoref.resolveMentionChain() entity
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `XDocCoref.resolveMentionChain()` method assembles a covering set of entities
    that can possibly match the mention chain being resolved and then attempt to find
    a unique entity via a call to `XDocCoref.resolveCandates()`:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The code assembles a set of entities by doing a lookup into the entity universe
    with `EntityUniverse.xdcEntitiesWithPhrase()`. All aliases for the mention chain
    are tried without consideration of whether they are good XDoc aliases. Before
    the entities are added to `candidateEntities`, the type returned must be consistent
    with the type of the mention chain as determined by `TTMatchers.unifyEntityTypes`.
    This way, `Washington`, a location is not resolved to `Washington`, a person.
    A bit of record keeping is done to determine whether the longest alias on the
    mention chain has matched an entity.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: The resolveCandidates() method
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `resolveCandidates()` method captures a key assumption that holds both
    for within-document and XDoc coreferences—this unambiguous reference is the only
    basis of resolution. In the within-document case, an example where humans have
    this problem is the sentence, `Bob and Joe were working together. He fell into
    the threshing machine.` Who is `he` referring to? The linguistic expectation that
    a singular referring term have a unique antecedent is called a uniqueness presupposition.
    An example XDoc case is as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '**Doc1**: John Smith is a character from Pocohontas'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Doc2**: John Smith is the chairman or GM'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Doc3**: John Smith is admired'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Which `John Smith` does the `John Smith` from Doc3 go with? Perhaps, neither.
    The algorithm in this software requires that there should be a single possible
    entity that survives the matching criteria. If there is more than one or zero,
    then a new entity is created. The implementation is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `filterCandidates` method eliminates all the candidate entities that fail
    for various semantic reasons. Coreference with an entity in the entity universe
    only happens if there is a single possible solution. There is not a distinction
    between too many candidate entities (more than one) or too few (zero). In a more
    advanced system, one could try and further disambiguate if there are too many
    entities via `context`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the heart of the XDoc code. The rest of the code marks up the document
    with entity-universe-relevant indices as returned by the `xdocCoref` method, which
    we just covered:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The following `for` loop iterates over the mention chains, which are aligned
    with `Entities[]` returned by `xdocCoref`. For each mention chain, the mention
    is mapped to its cross-document entity:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`for`循环遍历提及链，这些提及链与`xdocCoref`返回的`Entities[]`对齐。对于每个提及链，提及被映射到其跨文档实体：
- en: '[PRE47]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Next, the code will set up a bunch of mappings to create chunks that reflect
    the entity universe IDs:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，代码将设置一系列映射来创建反映实体宇宙ID的块：
- en: '[PRE48]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The actual creation of the chunks happens next:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 实际创建块将在下面发生：
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The chunkings are then used to create the relevant portions of the document,
    and `OutputDocument` is returned:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用这些块创建文档的相关部分，并返回`OutputDocument`：
- en: '[PRE50]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: So, this is what we have to offer as a starting place for XDoc coreference.
    Hopefully, we have explained the intentions behind the more opaque methods. Good
    luck!
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就是我们为XDoc共指提供的起点。希望我们已经解释了更不透明的方法背后的意图。祝你好运！
- en: The John Smith problem
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 约翰·史密斯问题
- en: Different people, locations, and concepts can have the same orthographic representation
    but be distinct. There are multiple instances of "John Smith", "Paris", and "bank"
    in the world, and a proper cross-document coreference system should be able to
    handle it. For the case of concepts such as "bank" (a river bank versus a financial
    bank), the term of art is word-sense disambiguation. This recipe will demonstrate
    one approach to the problem that Baldwin developed back in the day with Amit Bagga
    for person disambiguation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的人、地点和概念可能有相同的书写形式但却是不同的。世界上有多个“John Smith”、“Paris”和“bank”的例子，一个合适的跨文档共指系统应该能够处理这种情况。对于像“bank”这样的概念（河岸与金融机构），术语是词义消歧。这个方案将展示Baldwin当年与Amit
    Bagga一起为人物消歧开发的一种解决问题的方法。
- en: Getting ready
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The code for this recipe closely follows the clustering tutorial at [http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html](http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html)
    but changes it to more closely fit the original Bagga-Baldwin work. There is a
    fair amount of code but nothing very complicated. The source is in `src/com/lingpipe/cookbook/chapter7/JohnSmith.java`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方案的代码紧密遵循[http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html](http://alias-i.com/lingpipe/demos/tutorial/cluster/read-me.html)中的聚类教程，但将其修改得更接近原始的Bagga-Baldwin工作。代码量相当大，但没有什么特别复杂的。源代码位于`src/com/lingpipe/cookbook/chapter7/JohnSmith.java`。
- en: 'The class starts with the standard panoply of NLP tools for tokenization, sentence
    detection, and named-entity detection. Refer to the previous recipes if this stack
    is unfamiliar:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类以标准NLP工具的集合开始，用于分词、句子检测和命名实体检测。如果这个堆栈不熟悉，请参考之前的方案：
- en: '[PRE51]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Next up, we will revisit `TfIdfDistance`. However, the task requires that we
    wrap the class to operate over `Documents` rather than `CharSequences`, because
    we would like to retain the filename and be able to manipulate what text is used
    for the calculations to come:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将重新审视`TfIdfDistance`。然而，这项任务要求我们将类包装在`Documents`上而不是`CharSequences`上，因为我们希望保留文件名，并且能够操作用于后续计算的文本：
- en: '[PRE52]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Dropping to the referenced class, we have the following code:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 降级到引用类，我们有以下代码：
- en: '[PRE53]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The `train` method interfaces with the `TfIdfDistance.handle()` method and provides
    an implementation of a `distance(Document doc1, Document doc2)` method that will
    drive the clustering code discussed below. All that the `train` method does is
    pull out the relevant text and hand it off to the `TfIdfDistance` class for the
    relevant value.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法与`TfIdfDistance.handle()`方法接口，并提供了一个实现`distance(Document doc1, Document
    doc2)`方法的实现，该方法将驱动下面讨论的聚类代码。`train`方法所做的只是提取相关文本并将其传递给`TfIdfDistance`类以获取相关值。'
- en: 'The reference class, `Document`, is an inner class in `JohnSmith`, and it is
    quite simple. It gets sentences that have entities which match the `.*John Smith.*`
    pattern and puts them in the `mCoreferentText` variable:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 引用类`Document`是`JohnSmith`中的一个内部类，它相当简单。它获取具有匹配`.*John Smith.*`模式的句子，并将它们放入`mCoreferentText`变量中：
- en: '[PRE54]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Going deeper into the code, we will now visit the `getCoreferentSents()` method:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 深入代码，我们现在将访问`getCoreferentSents()`方法：
- en: '[PRE55]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Look at the *Cross-document coreference* recipe for most of the moving parts
    of the preceding method. We will call out a few notable bits. We are cheating
    in some sense by using a regular expression chunker to find any string that has
    as a `John Smith` substring and adding it in as a `PERSON` entity. Like most kinds
    of cheating, this is quite useful if your sole purpose in life is tracking `John
    Smith`. The cheating we did in reality was to use dictionary matching to find
    all variations of high-value intelligence targets such as `Osama bin Laden`. In
    the end, we had over 40 versions of his name scouring openly available news sources
    as a part of the MiTAP project.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 查看前述方法的*跨文档共指*配方，了解大多数移动部件。我们将指出一些值得注意的部分。从某种意义上说，我们通过使用正则表达式分块器来查找任何包含`John
    Smith`子串的字符串并将其添加为`PERSON`实体，我们是在作弊。像大多数作弊一样，如果你的唯一目的是追踪`John Smith`，这非常有用。我们在现实中所做的作弊是使用字典匹配来查找所有高价值情报目标（如`Osama
    bin Laden`）的变体。最终，我们在MiTAP项目中公开可用的新闻源中搜索了他的40多种版本。
- en: Further, as each sentence is processed, we will check all the mentions for a
    matching pattern for `John Smith`, and if so, we will collect any sentence that
    has a mention of this ID. This means that a sentence that refers back to `John
    Smith` with a pronoun will be included, as will the `Mr. Smith` cases if coreference
    is doing its job. Note that we need to see a match for `John Smith` before we
    start collecting contextual information, so we will miss the first sentence of
    `He awoke. John Smith was a giant cockroach`. Also note that if a second `John
    Smith` shows up with a different ID, it will be ignored—this can happen.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随着每个句子的处理，我们将检查所有提及的`John Smith`的匹配模式，如果匹配，我们将收集任何提及此ID的句子。这意味着如果一个句子用代词指回`John
    Smith`，它将被包括在内，如果共指正在发挥作用，`Mr. Smith`的情况也是如此。请注意，在我们开始收集上下文信息之前，我们需要看到`John Smith`的匹配，所以我们会错过`He
    awoke. John Smith was a giant cockroach`的第一句话。此外，如果出现第二个具有不同ID的`John Smith`，它将被忽略——这种情况可能发生。
- en: Finally, note that there is some error checking, in that if `John Smith` is
    not found, then an error is reported to `System.out`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请注意，有一些错误检查，如果找不到`John Smith`，则将错误报告给`System.out`。
- en: 'If we pop back to mundane I/O slinging in our `main()` method after setting
    up `TfIdfDocumentDistance`, we would have:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置`TfIdfDocumentDistance`之后，如果我们回到`main()`方法中的平凡I/O操作，我们会这样做：
- en: '[PRE56]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We have not discussed this, but the truth annotation of which document references
    which `Mr. Smith` is encoded in the directory structure of the data. Each subdirectory
    in the top `johnSmith` directory is treated as the truth cluster. So, `referencePartition`
    contains the truth. We could have wrapped this as a classification problem with
    each subdirectory, the correct classification. We will leave it as an exercise
    to you to stuff this into a cross-validating corpus with a logistic regression
    solution.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未讨论这一点，但哪个文档引用了哪个`Mr. Smith`的真实标注编码在数据目录结构中。顶级`johnSmith`目录中的每个子目录都被视为真实簇。因此，`referencePartition`包含真实标注。我们可以将此作为每个子目录的正确分类的分类问题进行包装。我们将把这个任务留给你，用逻辑回归解决方案将其填充到交叉验证语料库中。
- en: 'Moving on, we will construct the test set by flattening our previous categories
    into a single set of `Documents`. We could have done this in the previous step,
    but mixing tasks tends to produce bugs, and the extra `for` loop does very little
    damage to the execution speed:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过将之前的类别展平成一个单一的`Documents`集合来构建测试集。我们本来可以在上一步完成这个操作，但混合任务往往会产生错误，而且额外的`for`循环对执行速度的影响非常小：
- en: '[PRE57]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Next, we will tee up the clustering algorithms. We will do both `CompleteLink`
    and `SingleLink` driven by `TfIdfDocumentDistance` that runs the show:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将准备聚类算法。我们将使用`TfIdfDocumentDistance`运行程序，进行`CompleteLink`和`SingleLink`：
- en: '[PRE58]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The details of the clustering algorithms are covered in [Chapter 5](part0061_split_000.html#page
    "Chapter 5. Finding Spans in Text – Chunking"), *Finding Spans in Texts – Chunking*.
    Now, we will report performance based on the number of clusters varied from `1`
    to the number of inputs. The one fancy bit is that the `Cross` category uses `SingleLinkClusterer`
    as the reference and `CompleteLinkClusterer` as the response:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类算法的细节在[第5章](part0061_split_000.html#page "第5章. 文本中的跨度查找 – 分块") *文本中的跨度查找 –
    分块* 中有所介绍。现在，我们将根据从`1`到输入数量的聚类数量报告性能。一个花哨的部分是，`Cross`类别使用`SingleLinkClusterer`作为参考，`CompleteLinkClusterer`作为响应：
- en: '[PRE59]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: That's all that we need to do to get ready for this recipe. This is a rare phenomenon
    to be computed, and this is a toy implementation, but the key concepts should
    be evident.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们为这个食谱做准备所需做的所有事情。这是一个罕见的现象，这是一个玩具实现，但关键概念应该是显而易见的。
- en: How to do it...
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will just run this code and then mess with it a bit:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将只运行这个代码，然后稍微修改一下：
- en: 'Get yourself to a terminal and type:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端并输入：
- en: '[PRE60]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The result will be piles of information that indicate what sentences are being
    extracted for use in the clustering—remember that the truth annotation is determined
    by the directory that the files are in. The first cluster is `0`:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果将是一堆信息，表明正在提取哪些句子用于聚类——记住，真实标注是由文件所在的目录决定的。第一个聚类是`0`：
- en: '[PRE61]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The code reports sentences that contain references to `John Smith`:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码报告包含对`John Smith`引用的句子：
- en: '[PRE62]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The pronominal reference to `John Smith` is the basis of inclusion of the second
    sentence.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`John Smith`的代词引用是第二句被包含的基础。
- en: 'The system output goes on, and finally, we will get the results for a single-link
    clustering against the truth and a complete link against the truth. The `K` column
    indicates how many clusters the algorithm was allowed with precision, recall,
    and F-measure reported. The first row is in this case that there is only one cluster
    that will allow for 100 percent recall and 23 percent precision for both complete
    and single links. Looking down at the scores, we can see that the complete link
    reports the best F-measure with 11 clusters at `0.60`—in truth, there are 35 clusters.
    The single-link approach maxes out F-measure at 68 clusters with `0.78` and shows
    much greater robustness on varying numbers of clusters. The cross case shows that
    single link and complete link are quite different in direct comparison as well.
    Note that some `K` values have been eliminated for readability:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统输出继续，最后，我们将得到针对真实情况的单链接聚类结果和完全链接聚类结果。`K`列表示算法允许的聚类数量，并报告了精确度、召回率和F度量。在这种情况下，第一行表示只有一个聚类允许100%的召回率和23%的精确度，无论是完全链接还是单链接。向下查看分数，我们可以看到完全链接报告了最佳的F度量，有11个聚类在`0.60`——实际上有35个聚类。单链接方法将F度量最大化到68个聚类，达到`0.78`，并在不同数量的聚类上显示出更大的鲁棒性。交叉案例显示，单链接和完全链接在直接比较中也很不同。请注意，为了可读性，一些`K`值已被消除：
- en: '[PRE63]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The following output constrains clustering not by cluster size but by the max
    distance threshold. The output is for the single-link cluster with `.05` increases
    the distance and the evaluation is the B-cubed metric. The output is the distance,
    precision, recall, and the size of the resulting cluster. The performance at `.80`
    and `.9` is quite good, but beware of setting production thresholds in this after
    the fact fashion. In a production environment, we will want to see much more data
    before setting the threshold:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下输出通过最大距离阈值来约束聚类，而不是通过聚类大小。输出是针对单链接聚类的，`.05`增加距离，评估是B-立方度指标。输出包括距离、精确度、召回率和最终聚类的规模。在`.80`和`.9`时的性能相当好，但要注意在这种事后设置生产阈值的方式。在生产环境中，我们希望在设置阈值之前看到更多数据：
- en: '[PRE64]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The B-cubed (Bagga, Bierman, and Baldwin) evaluation was created to heavily
    penalize pushing large clusters together. It assumes that it is more of a problem
    to push lots of documents about George W. Bush together with George H. W. Bush,
    both large clusters, than to mistake George Bush, the mechanic who got mentioned
    once in the dataset. Other scoring metrics will count both the mistakes as equally
    bad. It is the standard scoring metric used in the literature for this phenomenon.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B-立方度（Bagga, Bierman, 和 Baldwin）评估是为了严重惩罚将大聚类放在一起。它假设将大量关于乔治·W·布什的文档与乔治·H·W·布什放在一起是一个更大的问题，两者都是大聚类，而不是将乔治·布什，那位在数据集中只被提及一次的机械师弄错。其他评分指标将把这两个错误视为同样糟糕。这是文献中用于这种现象的标准评分指标。
- en: See also
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: There is a fair amount of work in the research literature on this exact problem.
    We were not the first ones to think about this, but we came up with the dominant
    evaluation metric, and we released a corpus for other groups to compare themselves
    with us and each other. Our contribution is *Entity-based cross-document coreferencing
    using the Vector Space Model* by Bagga and Baldwin in *ACL '98 Proceedings of
    the 36th Annual Meeting of the Association for Computational Linguistics and 17th
    International Conference on Computational Linguistics*. There has been much progress
    since—there are more than 400 citations to this model on Google Scholar; they
    are worth a look if this problem is of importance to you.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究文献中，关于这个确切问题的研究相当丰富。我们并不是第一个考虑这个问题的人，但我们提出了主导的评价指标，并且发布了一个语料库，供其他团队与我们以及彼此进行比较。我们的贡献是Bagga和Baldwin在*ACL
    '98第36届计算语言学协会年会和第17届国际计算语言学会议论文集*中提出的*基于实体的跨文档共指消解使用向量空间模型*。自那时以来，已经取得了许多进展——在谷歌学术上有超过400篇关于这个模型的引用；如果这个问题对你很重要，它们值得一看。
