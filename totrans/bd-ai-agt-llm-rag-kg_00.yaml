- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '*Building AI Agents with LLMs, RAG, and Knowledge Graphs* introduces you to
    the evolving landscape of large language models (LLMs) and AI agents, offering
    both a theoretical foundation and practical guidance. It begins by explaining
    how text data can be represented and processed using deep learning, then progresses
    to modern architectures such as the Transformer model. From there, the book explores
    how LLMs are scaled and fine-tuned, and how their capabilities can be extended
    with tools, external memory systems, and agent-based frameworks. Technologies
    such as retrieval-augmented generation (RAG), GraphRAG, and multi-agent systems
    are explained in detail, with a focus on real-world applications and deployment.
    By the end of the book, you will have a clear understanding of how to build intelligent,
    tool-using AI agents and the role these systems play in shaping the future of
    AI.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用LLMs、RAG和知识图谱构建AI代理*介绍了大型语言模型（LLMs）和AI代理不断发展的领域，提供了理论基础和实践指导。它首先解释了如何使用深度学习表示和处理文本数据，然后过渡到现代架构如Transformer模型。从那里，本书探讨了如何扩展LLMs的规模和微调，以及如何通过工具、外部记忆系统和基于代理的框架来扩展其功能。详细解释了检索增强生成（RAG）、GraphRAG和多代理系统等技术，重点关注实际应用和部署。到本书结束时，你将清楚地了解如何构建智能的、使用工具的AI代理以及这些系统在塑造AI未来中所扮演的角色。'
- en: Who this book is for
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这本书面向谁
- en: This book is intended for software engineers, data scientists, and researchers
    who want to understand and build applications using LLMs and AI agents. A basic
    understanding of Python programming and foundational concepts in machine learning
    is recommended to fully benefit from the content. While no deep expertise in NLP
    is required, familiarity with neural networks, REST APIs, and general software
    development practices will help you follow the examples and implement real-world
    systems. Whether you’re looking to build intelligent agents, explore the inner
    workings of LLMs, or deploy AI applications at scale, this book provides both
    the theoretical background and practical guidance to get started.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书旨在为想要理解和构建使用LLMs和AI代理的应用程序的软件工程师、数据科学家和研究人员而编写。建议具备基本的Python编程知识和机器学习基础概念，以便充分利用本书内容。虽然不需要在NLP方面有深入的专业知识，但熟悉神经网络、REST
    API和一般的软件开发实践将有助于你理解示例并实现实际系统。无论你是想构建智能代理、探索LLMs的内部工作原理，还是大规模部署AI应用程序，本书都提供了开始的理论背景和实践指导。
- en: What this book covers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这本书涵盖的内容
- en: '[*Chapter 1*](B21257_01.xhtml#_idTextAnchor014), *Analyzing Text Data with
    Deep Learning*, introduces how to process and represent natural language in a
    format suitable for machine learning models. It covers various text encoding techniques,
    from basic one-hot encoding and bag of words to more advanced representations
    such as TF-IDF and word2vec. The chapter then explores key deep learning architectures
    for sequential data, such as RNNs, LSTMs, GRUs, and CNNs, and demonstrates how
    to apply them to text classification tasks. By the end of this chapter you will
    understand how these foundations enable modern language models such as ChatGPT.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B21257_01.xhtml#_idTextAnchor014)，*使用深度学习分析文本数据*，介绍了如何将自然语言处理成适合机器学习模型格式的处理和表示方法。它涵盖了从基本的one-hot编码和词袋模型到更高级的表示方法，如TF-IDF和word2vec。本章接着探讨了用于序列数据的深度学习关键架构，例如RNNs、LSTMs、GRUs和CNNs，并展示了如何将它们应用于文本分类任务。到本章结束时，你将了解这些基础如何使现代语言模型如ChatGPT成为可能。'
- en: '[*Chapter 2*](B21257_02.xhtml#_idTextAnchor032), *The Transformer: The Model
    Behind the Modern AI Revolution*, introduces attention mechanisms and explains
    how they evolved into the transformer architecture. The chapter highlights the
    limitations of earlier models such as RNNs and LSTMs, and shows how transformers
    overcame them to become the foundation of modern NLP. Key topics include self-attention,
    masked language modeling, training techniques, and internal model visualization.
    The chapter concludes by demonstrating real-world applications and laying the
    groundwork for understanding today’s LLMs.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第2章*](B21257_02.xhtml#_idTextAnchor032)，*Transformer：现代AI革命的模型背后*，介绍了注意力机制并解释了它们如何演变成Transformer架构。本章突出了早期模型如RNNs和LSTMs的局限性，并展示了Transformer如何克服这些局限性，成为现代NLP的基础。关键主题包括自注意力、掩码语言建模、训练技术以及内部模型可视化。本章最后通过展示实际应用和为理解今天的LLMs奠定基础来结束。'
- en: '[*Chapter 3*](B21257_03.xhtml#_idTextAnchor042), *Exploring LLMs as a Powerful
    AI Engine*, examines how the large-scale training of transformer models gave rise
    to today’s LLMs. The chapter explores their evolution, capabilities, and limitations,
    including techniques such as instruction tuning, fine-tuning, and alignment. It
    also introduces more compact and efficient LLM variants, multimodal models that
    handle multiple data types, and understanding challenges such as hallucinations,
    ethical concerns, and prompt engineering.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第3章*](B21257_03.xhtml#_idTextAnchor042), *探索LLM作为强大的AI引擎*，考察了大规模训练transformer模型如何导致今天LLMs的出现。本章探讨了它们的演变、能力和局限性，包括指令微调、微调和对齐等技术。它还介绍了更紧凑和高效的LLM变体、处理多种数据类型的多模态模型，以及幻觉、伦理担忧和提示工程等理解挑战。'
- en: '[*Chapter 4*](B21257_04.xhtml#_idTextAnchor058), *Building a Web Scraping Agent
    with an LLM*, introduces the concept of AI agents as an extension of LLMs, aimed
    at overcoming their ability to perform actions. The chapter explores the key characteristics
    of agents, and distinctions between single and multi-agent systems. It also presents
    the main libraries used for building agents and guides you through the creation
    of a web-scraping agent capable of retrieving information from the internet.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B21257_04.xhtml#_idTextAnchor058), *使用LLM构建网络爬虫代理*，介绍了AI代理作为LLMs的扩展概念，旨在克服它们执行动作的能力。本章探讨了代理的关键特征，以及单代理和多代理系统之间的区别。它还介绍了用于构建代理的主要库，并指导你创建一个能够从互联网检索信息的网络爬虫代理。'
- en: '[*Chapter 5*](B21257_05.xhtml#_idTextAnchor077), *Extending Your Agent with
    RAG to Prevent Hallucinations*, explores how RAG could overcome key limitations
    of LLMs, such as outdated knowledge and hallucinations. The chapter explains how
    RAG enables an LLM to access external information sources through embedding and
    vector databases, thereby improving accuracy and adaptability. It also compares
    RAG with fine-tuning and demonstrates its practical use by building a movie recommendation
    agent.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第5章*](B21257_05.xhtml#_idTextAnchor077), *使用RAG扩展您的代理以防止幻觉*，探讨了RAG如何克服LLMs的关键局限性，如知识过时和幻觉。本章解释了RAG如何通过嵌入和向量数据库使LLM能够访问外部信息源，从而提高准确性和适应性。它还比较了RAG与微调，并通过构建电影推荐代理展示了其实际应用。'
- en: '[*Chapter 6*](B21257_06.xhtml#_idTextAnchor090), *Advanced RAG Techniques for
    Information Retrieval and Augmentation*, expands on the basic RAG architecture
    by introducing enhancements at every stage of the pipeline—data ingestion, indexing,
    retrieval, and generation. The chapter explores modular RAG, techniques for scaling
    systems with large datasets and user bases, and key concerns such as robustness
    and privacy. It also highlights current challenges and open questions surrounding
    the future development of RAG-based systems.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第6章*](B21257_06.xhtml#_idTextAnchor090), *高级RAG技术用于信息检索和增强*，通过在管道的每个阶段引入增强来扩展基本的RAG架构——数据摄取、索引、检索和生成。本章探讨了模块化RAG、用于扩展具有大型数据集和用户群的系统的技术，以及稳健性和隐私等关键问题。它还强调了围绕基于RAG的系统未来发展的当前挑战和开放性问题。'
- en: '[*Chapter 7*](B21257_07.xhtml#_idTextAnchor113), *Creating and Connecting a
    Knowledge Graph to an AI Agent*, explores how to structure textual knowledge into
    knowledge graphs (KGs) to enhance information retrieval and reasoning in AI agents.
    The chapter introduces the concept of GraphRAG, where KGs are used to augment
    LLMs with structured contextual data. It covers how LLMs can be used to build
    KGs by extracting entities and relationships, how to use graphs for querying and
    reasoning, and discusses the benefits, limitations, and future directions of combining
    different approaches.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B21257_07.xhtml#_idTextAnchor113), *将知识图谱与AI代理连接起来创建和连接知识图谱*，探讨了如何将文本知识结构化到知识图谱（KGs）中，以增强AI代理中的信息检索和推理。本章介绍了GraphRAG的概念，其中KGs用于通过结构化上下文数据来增强LLMs。它涵盖了如何使用LLMs通过提取实体和关系来构建KGs，如何使用图进行查询和推理，并讨论了结合不同方法的益处、局限性和未来方向。'
- en: '[*Chapter 8*](B21257_08.xhtml#_idTextAnchor137), *Reinforcement Learning and
    AI Agents*, explores how agents can learn by interacting with dynamic environments,
    adjusting their behavior based on experience. It introduces the fundamentals of
    reinforcement learning, explains how agents make decisions and improve over time,
    and demonstrates how neural networks can be used to guide behavior. The chapter
    concludes by discussing how LLMs can be combined with reinforcement learning to
    build more capable AI systems.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B21257_08.xhtml#_idTextAnchor137), *强化学习和人工智能代理*，探讨了代理如何通过与动态环境互动、根据经验调整其行为来学习。它介绍了强化学习的基本原理，解释了代理如何做出决策并在时间上改进，并展示了如何使用神经网络来引导行为。本章最后讨论了如何将LLMs与强化学习相结合来构建更强大的AI系统。'
- en: '[*Chapter 9*](B21257_09.xhtml#_idTextAnchor156), *Creating Single- and Multi-Agent
    Systems*, explores how LLMs can be extended with tools and other models to form
    autonomous agents. It introduces the concept of single-agent and multi-agent systems,
    shows how LLMs can interact with APIs or external models, and presents key examples
    such as HuggingGPT. The chapter also covers agent coordination strategies, real-world
    applications in complex domains, and emerging business paradigms such as SaaS,
    MaaS, DaaS, and RaaS.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B21257_09.xhtml#_idTextAnchor156), *创建单代理和多代理系统*，探讨了如何通过工具和其他模型扩展LLMs以形成自主代理。它介绍了单代理和多代理系统的概念，展示了LLMs如何与API或外部模型交互，并提出了如HuggingGPT等关键示例。本章还涵盖了代理协调策略、复杂领域的现实应用以及如SaaS、MaaS、DaaS和RaaS等新兴商业模式。'
- en: '[*Chapter 10*](B21257_10.xhtml#_idTextAnchor179), *Building an AI Agent Application*,
    addresses the challenges of scaling and deploying AI agents in real-world applications.
    It introduces Streamlit as a rapid prototyping framework to create both frontend
    and backend components of an agent-based system. The chapter also covers key operational
    aspects such as asynchronous programming, containerization with Docker, and best
    practices for building scalable, production-ready AI solutions.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B21257_10.xhtml#_idTextAnchor179), *构建人工智能代理应用*，探讨了在现实应用中扩展和部署人工智能代理所面临的挑战。它介绍了Streamlit作为一个快速原型设计框架，用于创建基于代理系统的前端和后端组件。本章还涵盖了关键操作方面，如异步编程、使用Docker的容器化以及构建可扩展、生产就绪的人工智能解决方案的最佳实践。'
- en: '[*Chapter 11*](B21257_11.xhtml#_idTextAnchor215), *The Future Ahead*, explores
    the transformative potential of AI agents across industries such as healthcare
    and beyond. Building on the advancements discussed in earlier chapters, it reflects
    on the remaining technical and ethical challenges facing LLMs and agent systems.
    The chapter concludes by examining open questions and future directions in the
    development and deployment of intelligent AI agents.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第11章*](B21257_11.xhtml#_idTextAnchor215), *未来展望*，探讨了人工智能代理在医疗保健等行业以及更广泛的领域的变革潜力。基于前几章讨论的进展，它反思了LLMs和代理系统面临的剩余技术和伦理挑战。本章最后通过探讨智能人工智能代理的开发和部署中的开放问题和未来方向来结束。'
- en: To get the most out of this book
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了充分利用本书
- en: You should have a basic understanding of Python and be familiar with fundamental
    programming concepts such as functions, classes, and modules. A general knowledge
    of machine learning and neural networks (such as what a model is and how training
    works) will help in following the deeper technical content. While prior experience
    with deep learning frameworks or LLMs is not required, it will enhance your ability
    to apply the techniques discussed. The book is designed to be progressive, so
    concepts are introduced step by step, but a technical mindset is essential.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该具备基本的Python知识，并熟悉诸如函数、类和模块等基本编程概念。对机器学习和神经网络（如模型是什么以及训练是如何进行的）的一般了解将有助于理解更深层次的技术内容。虽然不需要有深度学习框架或LLMs的先前经验，但它将增强您应用所讨论技术的能力。本书旨在循序渐进，因此概念是逐步引入的，但技术思维是必不可少的。
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **本书涵盖的软件/硬件** | **操作系统要求** |'
- en: '| Python 3.10+ | Windows, macOS, or Linux |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Python 3.10+ | Windows、macOS或Linux |'
- en: '| PyTorch/Transformers | Windows, macOS, or Linux |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch/Transformers | Windows、macOS或Linux |'
- en: '| Streamlit | Windows, macOS, or Linux |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Streamlit | Windows、macOS或Linux |'
- en: '| Docker | Windows, macOS, or Linux |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| Docker | Windows、macOS或Linux |'
- en: For readers without access to a local GPU, using Google Colab is a convenient
    option. A Google Colab Pro account is recommended, as it provides access to more
    powerful GPUs such as NVIDIA T4 or A100, which can greatly improve performance
    when running embedding models, fine-tuning, or working with agents.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于没有访问本地GPU的读者，使用Google Colab是一个方便的选择。建议使用Google Colab Pro账户，因为它提供了访问更强大的GPU，如NVIDIA
    T4或A100，这可以在运行嵌入模型、微调或与代理一起工作时大大提高性能。
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book’s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting** **of code.**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你使用的是本书的数字版，我们建议你亲自输入代码或从书的GitHub仓库（下一节中有一个链接）获取代码。这样做将帮助你避免与代码的复制和粘贴相关的任何潜在错误。**'
- en: Download the example code files
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Modern-AI-Agents/tree/main](https://github.com/PacktPublishing/Modern-AI-Agents/tree/main).
    If there’s an update to the code, it will be updated in the GitHub repository.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从GitHub下载本书的示例代码文件，网址为[https://github.com/PacktPublishing/Modern-AI-Agents/tree/main](https://github.com/PacktPublishing/Modern-AI-Agents/tree/main)。如果代码有更新，它将在GitHub仓库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](http://https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有其他来自我们丰富图书和视频目录的代码包可供在[https://github.com/PacktPublishing/](http://https://github.com/PacktPublishing/)下载。查看它们吧！
- en: Conventions used
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了多种文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and X/Twitter
    handles. Here is an example: “The `process_frame` function is used to preprocess
    frames from the game to make them more suitable for training an RL agent.”'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`: 表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和X/Twitter用户名。以下是一个示例：“`process_frame`函数用于从游戏中预处理帧，使其更适合训练RL代理。”'
- en: 'A block of code is set as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块是这样设置的：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望将你的注意力引到代码块的一个特定部分时，相关的行或项目将以粗体显示：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都应如下编写：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    “Once we have our tokens ready, we can enter our question and click **Submit**.”'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**: 表示新术语、重要单词或你在屏幕上看到的单词。例如，菜单或对话框中的单词以**粗体**显示。以下是一个示例：“一旦我们准备好了标记，我们就可以输入问题并点击**提交**。”'
- en: Tips or important notes
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士或重要注意事项
- en: Appear like this.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来像这样。
- en: Get in touch
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎读者反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**: 如果你对此书任何方面有疑问，请通过[customercare@packtpub.com](mailto:customercare@packtpub.com)给我们发邮件，并在邮件主题中提及书名。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**: 尽管我们已经尽一切努力确保内容的准确性，但错误仍然可能发生。如果你在这本书中发现了错误，我们将不胜感激，如果你能向我们报告这一点。请访问[www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)并填写表格。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**: 如果你在互联网上以任何形式遇到我们作品的非法副本，如果你能提供位置地址或网站名称，我们将不胜感激。请通过[版权@packt.com](mailto:copyright@packt.com)与我们联系，并提供材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share Your Thoughts
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you’ve read *Building AI Agents with LLMs, RAG, and Knowledge Graphs*,
    we’d love to hear your thoughts! Please [click here to go straight to the Amazon
    review page](https://packt.link/r/1-835-08706-X) for this book and share your
    feedback.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您阅读了《使用LLMs、RAG和知识图谱构建AI代理》，我们非常乐意听到您的想法！请[点击此处直接转到该书的亚马逊评论页面](https://packt.link/r/1-835-08706-X)并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评论对我们和科技社区非常重要，并将帮助我们确保我们提供高质量的内容。
- en: Download a free PDF copy of this book
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载此书的免费PDF副本
- en: Thanks for purchasing this book!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买此书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您喜欢在路上阅读，但无法携带您的印刷书籍到处走吗？
- en: Is your eBook purchase not compatible with the device of your choice?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您的电子书购买是否与您选择的设备不兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心，现在购买每一本Packt书籍，您都可以免费获得该书的DRM免费PDF版本。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何地方、任何设备上阅读。直接从您喜欢的技术书籍中搜索、复制和粘贴代码到您的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 优惠不止于此，您还可以获得独家折扣、时事通讯和每日免费内容的每日电子邮件访问权限。
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下简单步骤获取福利：
- en: Scan the QR code or visit the link below
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描二维码或访问以下链接
- en: '![](img/B21257_QR_Free_PDF.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21257_QR_Free_PDF.jpg)'
- en: '[https://packt.link/free-ebook/978-1-83508-706-0](https://packt.link/free-ebook/978-1-83508-706-0)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/free-ebook/978-1-83508-706-0](https://packt.link/free-ebook/978-1-83508-706-0)'
- en: Submit your proof of purchase
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交您的购买证明
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这些！我们将直接将您的免费PDF和其他福利发送到您的电子邮件中
- en: 'Part 1: The AI Agent Engine: From Text to Large Language Models'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分：AI代理引擎：从文本到大型语言模型
- en: This part lays the foundation for understanding how modern AI agents process
    and generate language. It begins by exploring how raw text can be represented
    in numerical form suitable for deep learning models, introducing techniques such
    as word embeddings and basic neural architectures. The focus then shifts to the
    Transformer model and explains how attention mechanisms revolutionized natural
    language processing. Finally, it examines how large language models (LLMs) are
    built by scaling transformers, discussing training strategies, instruction tuning,
    fine-tuning, and the evolution toward models capable of general-purpose reasoning.
    Together, these chapters provide the technical and conceptual groundwork for building
    intelligent AI agents.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分为理解现代AI代理如何处理和生成语言奠定了基础。它首先探讨了原始文本如何以适合深度学习模型的数值形式表示，介绍了诸如词嵌入和基本神经网络架构等技术。然后，重点转向Transformer模型，并解释了注意力机制如何革新自然语言处理。最后，它探讨了通过扩展Transformer来构建大型语言模型（LLMs），讨论了训练策略、指令调整、微调和向通用推理模型演化的过程。这些章节共同为构建智能AI代理提供了技术和概念基础。
- en: 'This part has the following chapters:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 1*](B21257_01.xhtml#_idTextAnchor014)*, Analyzing Text Data with
    Deep Learning*'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第1章*](B21257_01.xhtml#_idTextAnchor014)*，使用深度学习分析文本数据*'
- en: '[*Chapter 2*](B21257_02.xhtml#_idTextAnchor032)*, The Transformer: The Model
    Behind the Modern AI Revolution*'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第2章*](B21257_02.xhtml#_idTextAnchor032)*，Transformer：现代AI革命的模型背后*'
- en: '[*Chapter 3*](B21257_03.xhtml#_idTextAnchor042)*, Exploring LLMs as a Powerful
    AI Engine*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第3章*](B21257_03.xhtml#_idTextAnchor042)*，探索LLMs作为强大的AI引擎*'
