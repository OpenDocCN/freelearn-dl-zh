<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer341">
<h1 class="chapterTitle" id="_idParaDest-178"><span class="koboSpan" id="kobo.1.1">Appendix</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.2.1">In the main chapters of this book, we explored the power of OpenAI’s models through the lens of ChatGPT, diving into its conversational interface and understanding how it can revolutionize the way we interact with AI. </span><span class="koboSpan" id="kobo.2.2">However, the world of OpenAI extends beyond ChatGPT’s familiar chat-based experience. </span><span class="koboSpan" id="kobo.2.3">To fully harness the potential of these models, it’s crucial to understand the broader tools and interfaces OpenAI provides.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3.1">This appendix is dedicated to exploring one such tool: the </span><strong class="keyWord"><span class="koboSpan" id="kobo.4.1">OpenAI Playground</span></strong><span class="koboSpan" id="kobo.5.1">. </span><span class="koboSpan" id="kobo.5.2">The Playground offers a versatile</span><a id="_idIndexMarker661"/><span class="koboSpan" id="kobo.6.1"> environment to experiment with OpenAI’s models, granting more control over parameters, outputs, and behaviors. </span><span class="koboSpan" id="kobo.6.2">Whether you want to fine-tune responses, test different use cases, or simply gain a deeper understanding of the models’ capabilities, the Playground is an invaluable resource.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.7.1">In this appendix, we will:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.8.1">Walk through the Playground interface and its key features.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.9.1">Illustrate how to interact with OpenAI models directly from the Playground.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.10.1">Offer tips and best practices to maximize your outcomes when using the Playground.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.11.1">By the end of this appendix, you’ll have the knowledge and confidence to use OpenAI’s Playground and its models, going beyond ChatGPT.</span></p>
<h1 class="heading-1" id="_idParaDest-179"><span class="koboSpan" id="kobo.12.1">Trying OpenAI models in the Playground</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.13.1">To access </span><a id="_idIndexMarker662"/><span class="koboSpan" id="kobo.14.1">an OpenAI </span><a id="_idIndexMarker663"/><span class="koboSpan" id="kobo.15.1">Playground, you need to create an OpenAI account and navigate through </span><a href="https://platform.openai.com/playground"><span class="koboSpan" id="kobo.16.1">to </span><span class="url"><span class="koboSpan" id="kobo.17.1">https://platform.openai.com/playgro</span></span></a><span class="url"><span class="koboSpan" id="kobo.18.1">und</span></span><span class="koboSpan" id="kobo.19.1">. </span><span class="koboSpan" id="kobo.19.2">This is how the landing page looks:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.20.1"><img alt="A screenshot of a chat  Description automatically generated" src="../Images/Appendix_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.21.1">Figure 1: OpenAI Playground at https://platform.openai.com/playground</span></p>
<p class="normal"><span class="koboSpan" id="kobo.22.1">As you can see from </span><em class="italic"><span class="koboSpan" id="kobo.23.1">Figure 1</span></em><span class="koboSpan" id="kobo.24.1">, the Playground offers a UI where the user can start interacting with the model, which</span><a id="_idIndexMarker664"/><span class="koboSpan" id="kobo.25.1"> you can select at the top of your chat interface. </span><span class="koboSpan" id="kobo.25.2">Note that, whenever consuming models via the OpenAI Playground, you</span><a id="_idIndexMarker665"/><span class="koboSpan" id="kobo.26.1"> will be charged a fee depending on the amount of interactions. </span><span class="koboSpan" id="kobo.26.2">You can find the pricing page at </span><span class="url"><span class="koboSpan" id="kobo.27.1">https://openai.com/api/pricing/</span></span><span class="koboSpan" id="kobo.28.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.29.1">Before diving deeper into the main sections of the Playground, let’s first define some jargon you will see in this chapter:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.30.1">Tokens</span></strong><span class="koboSpan" id="kobo.31.1">: Tokens can be considered as word fragments or segments that are used by the API to process input prompts. </span><span class="koboSpan" id="kobo.31.2">Unlike complete words, tokens may contain trailing spaces or even word segments. </span><span class="koboSpan" id="kobo.31.3">As a general rule of thumb, one token in English is approximately equivalent to four characters, or three-quarters of a word (you can refer to the following link to convert words to tokens in the context of OpenAI models: </span><span class="url"><span class="koboSpan" id="kobo.32.1">https://platform.openai.com/tokenizer</span></span><span class="koboSpan" id="kobo.33.1">).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.34.1">Prompt</span></strong><span class="koboSpan" id="kobo.35.1">: In the context </span><a id="_idIndexMarker666"/><span class="koboSpan" id="kobo.36.1">of </span><strong class="keyWord"><span class="koboSpan" id="kobo.37.1">natural language processing</span></strong><span class="koboSpan" id="kobo.38.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.39.1">NLP</span></strong><span class="koboSpan" id="kobo.40.1">) and Generative AI, a prompt refers to a piece of text that is given as input to an AI language model to generate a response or output. </span><span class="koboSpan" id="kobo.40.2">The prompt can be a question, a statement, or a sentence, and it is used to provide context and direction to the language model.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.41.1">Context</span></strong><span class="koboSpan" id="kobo.42.1">: In the field of GPT, context refers to the words and sentences that come before the user’s prompt. </span><span class="koboSpan" id="kobo.42.2">This context is used by the language model to generate the most probable next word or phrase, based on the patterns and relationships found in the training data.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.43.1">Model confidence</span></strong><span class="koboSpan" id="kobo.44.1">: Model confidence refers to the level of certainty or probability that an AI model assigns to a particular prediction or output. </span><span class="koboSpan" id="kobo.44.2">In the context of NLP, model confidence is often used to indicate how confident the AI model is in the correctness or relevance of its generated response to a given input prompt.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.45.1">Tools</span></strong><span class="koboSpan" id="kobo.46.1">: With tools, we provide the model with an extra skill that it can invoke to accomplish the user’s task. </span><span class="koboSpan" id="kobo.46.2">A function will always have a description in natural language so that the model knows when to invoke it.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.47.1">In the Playground, there</span><a id="_idIndexMarker667"/><span class="koboSpan" id="kobo.48.1"> are four main sections to </span><a id="_idIndexMarker668"/><span class="koboSpan" id="kobo.49.1">interact with the models. </span><span class="koboSpan" id="kobo.49.2">Let’s explore them in the next sections.</span></p>
<h2 class="heading-2" id="_idParaDest-180"><span class="koboSpan" id="kobo.50.1">Chat</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.51.1">Here, you can test all </span><a id="_idIndexMarker669"/><span class="koboSpan" id="kobo.52.1">the chat models available today, including both text-only models (like GPT-3.5) and multimodal models (like GPT-4o). </span><span class="koboSpan" id="kobo.52.2">You can provide a system message – the set of instructions that you provide your model with – all in natural language.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.53.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.54.1">In the context of LLMs, the system message is an instruction provided at the beginning of a conversation to establish the model’s role, behavior, and response guidelines. </span><span class="koboSpan" id="kobo.54.2">This message sets the overarching context, guiding the model’s interactions to align with specific objectives or constraints. </span><span class="koboSpan" id="kobo.54.3">For example, a system message might specify that the model should act as a friendly travel advisor or maintain a formal tone. </span><span class="koboSpan" id="kobo.54.4">This configuration can be set at the backend level by the AI developer, so that the end user will not have access to it and, henceforth, will not be able to “force” the model to behave differently.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.55.1">You can also compare the output of two different models, given the same question. </span><span class="koboSpan" id="kobo.55.2">The following is an example of how to do that:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.56.1"><img alt="A screenshot of a chat  Description automatically generated" src="../Images/Appendix_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.57.1">Figure 2: An example of comparison between two models</span></p>
<p class="normal"><span class="koboSpan" id="kobo.58.1">For each model, you can also </span><a id="_idIndexMarker670"/><span class="koboSpan" id="kobo.59.1">play with some parameters that you can configure. </span><span class="koboSpan" id="kobo.59.2">Here is a list:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.60.1">Temperature</span></strong><span class="koboSpan" id="kobo.61.1"> (ranging from 0 to 2): This controls the randomness of the model’s response. </span><span class="koboSpan" id="kobo.61.2">A low-level temperature makes your model more deterministic, meaning that it will tend to give the same output to the same question. </span><span class="koboSpan" id="kobo.61.3">For example, if I ask my model multiple times </span><em class="italic"><span class="koboSpan" id="kobo.62.1">What is OpenAI?</span></em><span class="koboSpan" id="kobo.63.1"> with the temperature set as 0, it will give, most of the time, the same answer. </span><span class="koboSpan" id="kobo.63.2">On the other hand, if I do the same with a temperature greater than 0, it will try to modify its answers each time, in terms of wording and style.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.64.1">Max tokens</span></strong><span class="koboSpan" id="kobo.65.1">: This controls the length (in terms of tokens) of the model’s response to the user’s prompt.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.66.1">Stop sequences</span></strong><span class="koboSpan" id="kobo.67.1"> (user input): This makes responses end at the desired point, such as the end of a sentence or list.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.68.1">Top probabilities</span></strong><span class="koboSpan" id="kobo.69.1"> (ranging from 0 to 1): This controls which tokens the model will consider when generating a response. </span><span class="koboSpan" id="kobo.69.2">This means that the model will select from the smallest set of tokens whose cumulative probability adds up to 90% of the distribution.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.70.1">Frequency penalty</span></strong><span class="koboSpan" id="kobo.71.1"> (ranging from 0 to 1): This controls the repetition of the same tokens in the generated response. </span><span class="koboSpan" id="kobo.71.2">The higher the penalty, the lower the probability of seeing the same tokens more than once in the same response. </span><span class="koboSpan" id="kobo.71.3">The penalty reduces the chance proportionally, based on how often a token has appeared in the text so far (this is the key difference from the following parameter).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.72.1">Presence penalty</span></strong><span class="koboSpan" id="kobo.73.1"> (ranging from 0 to 2): This is similar to the previous parameter but stricter. </span><span class="koboSpan" id="kobo.73.2">It reduces the chance of repeating any token that has appeared in the text at all so far. </span><span class="koboSpan" id="kobo.73.3">As it is stricter than the frequency penalty, the presence penalty also increases the </span><a id="_idIndexMarker671"/><span class="koboSpan" id="kobo.74.1">likelihood of introducing new topics in a response.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-181"><span class="koboSpan" id="kobo.75.1">Assistants</span></h2>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.76.1">OpenAI Assistants</span></strong><span class="koboSpan" id="kobo.77.1"> can </span><a id="_idIndexMarker672"/><span class="koboSpan" id="kobo.78.1">be seen as a way to develop AI </span><a id="_idIndexMarker673"/><span class="koboSpan" id="kobo.79.1">agents faster and more easily. </span><span class="koboSpan" id="kobo.79.2">In fact, Assistants can be defined as entities powered by an LLM, with a set of instructions to follow and a set of tools or plugins to use.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.80.1">In the case of OpenAI Assistants, they come with three pre-built tools:</span></p>
<ul>
<li class="bulletList"><strong class="screenText"><span class="koboSpan" id="kobo.81.1">File Search</span></strong><span class="koboSpan" id="kobo.82.1">: This allows the user to upload custom documents so that the Assistant can navigate through them to accomplish the user’s query. </span><span class="koboSpan" id="kobo.82.2">It operates with a RAG-based framework.</span></li>
<li class="bulletList"><strong class="screenText"><span class="koboSpan" id="kobo.83.1">Function Calling</span></strong><span class="koboSpan" id="kobo.84.1">: This allows the user to define a set of custom functions that can be invoked by the Assistant to accomplish a given task.</span></li>
<li class="bulletList"><strong class="screenText"><span class="koboSpan" id="kobo.85.1">Code Interpreter</span></strong><span class="koboSpan" id="kobo.86.1">: This refers to the capability of the Assistant to run code either against provided documents (for example, in the case of spreadsheets or analytical papers that require mathematical computations) or simply to solve complex tasks provided by the user (for example, complex mathematical problems).</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.87.1">In the following screenshot, you can see an example of an Assistant called </span><strong class="screenText"><span class="koboSpan" id="kobo.88.1">Chat with PDF</span></strong><span class="koboSpan" id="kobo.89.1">, which specializes in responding to provided documents (in my case, I uploaded the paper </span><em class="italic"><span class="koboSpan" id="kobo.90.1">LLaMA: Open and Efficient Foundation Language Models</span></em><span class="koboSpan" id="kobo.91.1"> by Hugo Touvron et al.).</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.92.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/Appendix_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.93.1">Figure 3: Example of an OpenAI Assistant</span></p>
<p class="normal"><span class="koboSpan" id="kobo.94.1">As you can see from the preceding screenshot, the Assistant was able to answer my question, retrieving knowledge from the provided document. </span><span class="koboSpan" id="kobo.94.2">In fact, my question was pretty vague, since the term </span><em class="italic"><span class="koboSpan" id="kobo.95.1">toxicity</span></em><span class="koboSpan" id="kobo.96.1"> can </span><a id="_idIndexMarker674"/><span class="koboSpan" id="kobo.97.1">refer to multiple</span><a id="_idIndexMarker675"/><span class="koboSpan" id="kobo.98.1"> domains; nevertheless, the Assistant knows to watch over the provided documents as the primary source of information.</span></p>
<h2 class="heading-2" id="_idParaDest-182"><span class="koboSpan" id="kobo.99.1">Completions</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.100.1">This section</span><a id="_idIndexMarker676"/><span class="koboSpan" id="kobo.101.1"> refers </span><a id="_idIndexMarker677"/><span class="koboSpan" id="kobo.102.1">to a class of models called </span><strong class="keyWord"><span class="koboSpan" id="kobo.103.1">base models</span></strong><span class="koboSpan" id="kobo.104.1">, like GPT-3. </span><span class="koboSpan" id="kobo.104.2">They are the basis on which the so-called “assistant models” (or chat models, as we saw previously) are built. </span><span class="koboSpan" id="kobo.104.3">For example, the chat model GPT-3.5 Turbo (the model behind ChatGPT) is a fine-tuned version of the base model GPT-3.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.105.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.106.1">Completions (base) models are designed for generating single responses to prompts, making them suitable for tasks like text generation and summarization without maintaining context over multiple interactions. </span><span class="koboSpan" id="kobo.106.2">Chat (assistant) models, on the other hand, are optimized for interactive conversations, capable of maintaining context across multiple turns, and are ideal for applications like chatbots and virtual assistants.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.107.1">Below you can see an example of a typical completion task in the Playground:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.108.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/Appendix_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.109.1">Figure 4: Example of completion task in OpenAI Playground</span></p>
<p class="normal"><span class="koboSpan" id="kobo.110.1">As you can see, using my words “Today I went to a grocery store and” the model completed the sentence with </span><a id="_idIndexMarker678"/><span class="koboSpan" id="kobo.111.1">the most likely words.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.112.1">Today, completion models are rarely used as they are outperformed by chat models, yet they can be further fine-tuned to tailored use cases (we will cover fine-tuning later on in this section).</span></p>
<h2 class="heading-2" id="_idParaDest-183"><span class="koboSpan" id="kobo.113.1">Text to speech</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.114.1">In addition to </span><em class="italic"><span class="koboSpan" id="kobo.115.1">Whisper</span></em><span class="koboSpan" id="kobo.116.1">, the</span><a id="_idIndexMarker679"/><span class="koboSpan" id="kobo.117.1"> aforementioned</span><a id="_idIndexMarker680"/><span class="koboSpan" id="kobo.118.1"> speech-to-text model, OpenAI also released a </span><strong class="keyWord"><span class="koboSpan" id="kobo.119.1">text-to-speech</span></strong><span class="koboSpan" id="kobo.120.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.121.1">TTS</span></strong><span class="koboSpan" id="kobo.122.1">) model that can be tested directly in the Playground.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.123.1">Let’s see an example:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.124.1"><img alt="A screenshot of a video chat  Description automatically generated" src="../Images/Appendix_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.125.1">Figure 5: Example of using OpenAI’s TTS models in the Playground</span></p>
<p class="normal"><span class="koboSpan" id="kobo.126.1">As you can see from the above screenshot, you can select the voice, model, speed, and format of the generated audio.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.127.1">All the previous models come pre-built, in the sense that they have already been pre trained on a huge knowledge base.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.128.1">However, there are</span><a id="_idIndexMarker681"/><span class="koboSpan" id="kobo.129.1"> some ways you can </span><a id="_idIndexMarker682"/><span class="koboSpan" id="kobo.130.1">make your model more customized and tailored for your use case.</span></p>
<h2 class="heading-2" id="_idParaDest-184"><span class="koboSpan" id="kobo.131.1">Customizing your model</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.132.1">The first method of </span><a id="_idIndexMarker683"/><span class="koboSpan" id="kobo.133.1">tailoring your model for your use case is embedded in the way the model is designed, and it involves providing your model with the context in the few-shot learning approach.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.134.1">For example, you could ask the model to generate an article whose template and lexicon recall another one you have already written. </span><span class="koboSpan" id="kobo.134.2">For this, you can provide the model with your query of generating an article and also with the former article as a reference or context, so that the model is better prepared for your request.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.135.1">Here is an example of it:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.136.1"><img alt="A screenshot of a chat  Description automatically generated" src="../Images/Appendix_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.137.1">Figure 6: An example of a conversation within the OpenAI Playground with the few-shot learning approach</span></p>
<p class="normal"><span class="koboSpan" id="kobo.138.1">In the previous</span><a id="_idIndexMarker684"/><span class="koboSpan" id="kobo.139.1"> example, I instructed the model to output only the label of the tweet’s sentiment, providing it with three examples of how to do that.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.140.1">The second method of customizing your model is more sophisticated and is called </span><strong class="keyWord"><span class="koboSpan" id="kobo.141.1">fine-tuning</span></strong><span class="koboSpan" id="kobo.142.1">. </span><span class="koboSpan" id="kobo.142.2">Fine-tuning is </span><a id="_idIndexMarker685"/><span class="koboSpan" id="kobo.143.1">the process of adapting a pre trained model to a new task.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.144.1">In fine-tuning, the parameters of the pre trained model are altered, either by adjusting the existing parameters or by adding new parameters, to better fit the data for the new task. </span><span class="koboSpan" id="kobo.144.2">This is done by training the model on a smaller labeled dataset that is specific to the new task. </span><span class="koboSpan" id="kobo.144.3">The key idea behind fine-tuning is to leverage the knowledge learned from the pre trained model and fine-tune it to the new task, rather than training a model from scratch. </span><span class="koboSpan" id="kobo.144.4">Have a look at the following figure:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.145.1"><img alt="" src="../Images/Appendix_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.146.1">Figure 7: Model fine-tuning</span></p>
<p class="normal"><span class="koboSpan" id="kobo.147.1">In the preceding figure, you can see a schema on how fine-tuning works on OpenAI pre-built models. </span><span class="koboSpan" id="kobo.147.2">The idea is that you have available a pre trained model with general-purpose weights or parameters. </span><span class="koboSpan" id="kobo.147.3">Then, you</span><a id="_idIndexMarker686"/><span class="koboSpan" id="kobo.148.1"> feed your model with custom data, typically in the form of </span><em class="italic"><span class="koboSpan" id="kobo.149.1">key-value</span></em><span class="koboSpan" id="kobo.150.1"> prompts and completions, as shown here:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.151.1">{"prompt": "&lt;prompt text&gt;", "completion": "&lt;ideal generated text&gt;"}
{"prompt": "&lt;prompt text&gt;", "completion": "&lt;ideal generated text&gt;"}
{"prompt": "&lt;prompt text&gt;", "completion": "&lt;ideal generated text&gt;"}
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.152.1">Once the training is done, you will have a customized model that performs particularly well for a given task, for example, the classification of your company’s documentation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.153.1">The nice thing about fine-tuning is that you can make pre-built models tailored to your use cases, without the need to re-train them from scratch, yet leveraging smaller training datasets and hence needing less training time and computing. </span><span class="koboSpan" id="kobo.153.2">At the same time, the model keeps its generative power and </span><a id="_idIndexMarker687"/><span class="koboSpan" id="kobo.154.1">accuracy learned via the original training, the one that was carried out on the massive dataset.</span></p>
<h1 class="heading-1" id="_idParaDest-185"><span class="koboSpan" id="kobo.155.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.156.1">The OpenAI Playground presents a powerful tool for experimenting with advanced AI models through zero- or few-shot learning and fine-tuning techniques. </span><span class="koboSpan" id="kobo.156.2">The Playground allows users to interact directly with pre trained models, making it easier to customize and enhance them for specific tasks, such as sentiment analysis or document classification.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.157.1">For developers looking to build AI applications that leverage OpenAI’s API, mastering these techniques is crucial to ascertain whether a specific model’s configuration will meet a specific application’s requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.158.1">Despite the focus of this book being mainly on ChatGPT, enterprise-scale scenarios (which we covered in </span><em class="italic"><span class="koboSpan" id="kobo.159.1">Chapter 10</span></em><span class="koboSpan" id="kobo.160.1">) require more customized approaches when it comes to AI use cases; that’s why familiarizing yourself with the concept of the Playground and OpenAI models’ APIs is of a great value to embrace the mindset of this new wave of AI-powered application development.</span></p>
<h1 class="heading-1"><span class="koboSpan" id="kobo.161.1">Join our communities on Discord and Reddit</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.162.1">Have questions about the book or want to contribute to discussions on Generative AI and LLMs? </span><span class="koboSpan" id="kobo.162.2">Join our Discord server at </span><a href="Appendix.xhtml"><span class="url"><span class="koboSpan" id="kobo.163.1">https://packt.link/I1tSU</span></span></a><span class="koboSpan" id="kobo.164.1"> and our Reddit channel at </span><a href="Appendix.xhtml"><span class="url"><span class="koboSpan" id="kobo.165.1">https://packt.link/jwAmA</span></span></a><span class="koboSpan" id="kobo.166.1"> to connect, share, and collaborate with like-minded enthusiasts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.167.1"><img alt="" src="../Images/Discord.png"/></span> <span class="koboSpan" id="kobo.168.1"><img alt="" src="../Images/QR_Code757615820155951000.png"/></span></p>
</div>


<div class="Basic-Text-Frame" id="_idContainer345">
<p class="BM-packtLogo"><span class="koboSpan" id="kobo.1.1"><img alt="" src="../Images/New_Packt_Logo1.png"/></span></p>
<p class="normal"><a href="http://packt.com"><span class="url"><span class="koboSpan" id="kobo.2.1">packt.com</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.3.1">Subscribe to our online digital library for full access to over 7,000 books and videos, as well as industry leading tools to help you plan your personal development and advance your career. </span><span class="koboSpan" id="kobo.3.2">For more information, please visit our website.</span></p>
<h1 class="heading-1" id="_idParaDest-186"><span class="koboSpan" id="kobo.4.1">Why subscribe?</span></h1>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.5.1">Spend less time learning and more time coding with practical eBooks and Videos from over 4,000 industry professionals</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.6.1">Improve your learning with Skill Plans built especially for you</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.7.1">Get a free eBook or video every month</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.8.1">Fully searchable for easy access to vital information</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.9.1">Copy and paste, print, and bookmark content</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.10.1">At </span><a href="http://www.packt.com"><span class="url"><span class="koboSpan" id="kobo.11.1">www.packt.com</span></span></a><span class="koboSpan" id="kobo.12.1">, you can also read a collection of free technical articles, sign up for a range of free newsletters, and receive exclusive discounts and offers on Packt books and eBooks.</span></p>
<p class="eop"/>
<h1 class="mainHeading" id="_idParaDest-187"><span class="koboSpan" id="kobo.13.1">Other Books You May Enjoy</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.14.1">If you enjoyed this book, you may be interested in these other books by Packt:</span></p>
<p class="BM-bookCover"><a href="https://www.packtpub.com/en-in/product/generating-creative-images-with-dall-e-3-9781835089903"><span class="koboSpan" id="kobo.15.1"><img alt="" src="../Images/9781835087718.png"/></span></a></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.16.1">Generating Creative Images With DALL-E 3</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.17.1">Holly Picano</span></p>
<p class="normal"><span class="koboSpan" id="kobo.18.1">ISBN: 9781835087718</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.19.1">Master DALL-E 3’s architecture and training methods</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.20.1">Create fine prints and other AI-generated art with precision</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.21.1">Seamlessly blend AI with traditional artistry</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.22.1">Address ethical dilemmas in AI art</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.23.1">Explore the future of digital creativity</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.24.1">Implement practical optimization techniques for your artistic endeavors</span></li>
</ul>
<p class="eop"/>
<p class="BM-bookCover"><a href="https://www.packtpub.com/en-in/product/building-ai-applications-with-openai-apis-9781835884010"><span class="koboSpan" id="kobo.25.1"><img alt="" src="../Images/9781835884003.png"/></span></a></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.26.1">Building AI Applications with OpenAI APIs</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.27.1">Martin Yanev</span></p>
<p class="normal"><span class="koboSpan" id="kobo.28.1">ISBN: 9781835884003</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.29.1">Develop a solid foundation in using the OpenAI API for NLP tasks</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.30.1">Build, deploy, and integrate payments into various desktop and SaaS AI applications</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.31.1">Integrate ChatGPT with frameworks such as Flask, Django, and Microsoft Office APIs</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.32.1">Unleash your creativity by integrating DALL-E APIs to generate stunning AI art within your desktop apps</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.33.1">Experience the power of Whisper API’s speech recognition and text-to-speech features</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.34.1">Find out how to fine-tune ChatGPT models for your specific use case</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.35.1">Master AI embeddings to measure the relatedness of text strings</span></li>
</ul>
<p class="eop"/>
<h1 class="heading-1" id="_idParaDest-188"><span class="koboSpan" id="kobo.36.1">Packt is searching for authors like you</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.37.1">If you’re interested in becoming an author for Packt, please visit </span><a href="http://authors.packtpub.com"><span class="url"><span class="koboSpan" id="kobo.38.1">authors.packtpub.com</span></span></a><span class="koboSpan" id="kobo.39.1"> and apply today. </span><span class="koboSpan" id="kobo.39.2">We have worked with thousands of developers and tech professionals, just like you, to help them share their insight with the global tech community. </span><span class="koboSpan" id="kobo.39.3">You can make a general application, apply for a specific hot topic that we are recruiting an author for, or submit your own idea.</span></p>
</div>
<div class="Basic-Text-Frame" id="_idContainer346">
<p class="eop"/>
<h1 class="heading-1" id="_idParaDest-189"><span class="koboSpan" id="kobo.40.1">Share your thoughts</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.41.1">Now you’ve finished </span><em class="italic"><span class="koboSpan" id="kobo.42.1">Practical Generative AI with ChatGPT, Second Edition</span></em><span class="koboSpan" id="kobo.43.1">, we’d love to hear your thoughts! </span><span class="koboSpan" id="kobo.43.2">If you purchased the book from Amazon, please </span><a href="https://packt.link/r/1836647859"><span class="url"><span class="koboSpan" id="kobo.44.1">click here to go straight to the Amazon review page</span></span></a><span class="koboSpan" id="kobo.45.1"> for this book and share your feedback or leave a review on the site that you purchased it from.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.46.1">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</span></p>
</div>
</body></html>