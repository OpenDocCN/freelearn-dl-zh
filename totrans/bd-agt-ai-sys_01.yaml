- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fundamentals of Generative AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI has quickly become a transformative technology in the field of
    **artificial intelligence** ( **AI** ) and machine learning, revolutionizing creative
    processes and problem-solving across diverse industries and use cases. It is pushing
    the boundaries of autonomy in agent-based intelligent systems. In this chapter,
    we will cover the basics of generative AI. We will explore what generative AI
    is along with a brief history of generative AI models. We will then discuss the
    different types of generative models, which include **variational autoencoders**
    ( **VAEs** ), **generative adversarial networks** ( **GANs** ), autoregressive,
    and Transformer models. Next, we will delve into the applications of generative
    AI and wrap up the chapter with a brief discussion of some of the limitations
    and challenges related to generative AI.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this introductory chapter that will help
    set the foundations of generative AI as we explore further the capabilities of
    autonomous intelligent agents powered by generative AI:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to generative AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of generative AI models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications of generative AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges and limitations of generative AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have gained a comprehensive understanding
    of generative AI, including its fundamental concepts, diverse applications, and
    current challenges. You will also learn about the technology‚Äôs potential and limitations,
    with a particular focus on its critical role in advancing intelligent agents and
    agentic systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to generative AI
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI refers to a class of AI technologies that is capable of generating
    various forms of content, including but not limited to text, images, audio, and
    video. These AI systems can generate new content, based on their training data
    and input parameters, which usually include text prompts but can also involve
    other forms of input such as images. The recent buzz around generative AI comes
    from the simplicity with which new user interfaces powered by this AI technology
    can create high-quality text, graphics, and videos in seconds.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In very simple terms, generative AI is about making new data that looks like
    the data from which it has been trained. In other words, learning the underlying
    patterns, structures, and distributions of input data enables a procedure within
    the model allowing it to generate new data in a similar way. For instance, if
    trained on a dataset of human faces, a generative AI model will be able to create
    completely new faces of people that don‚Äôt actually exist in real life but are
    very realistic. In essence, generative AI models work by learning the probability
    distribution of a dataset and then sampling from that distribution to create new
    instances. This approach is different from discriminative models, whose goal is
    to learn how to tell classes of data apart. For example, a discriminative model
    could be trained to separate pictures of cats and dogs, but a generative model
    would be trained to make up completely new pictures of cats or dogs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The concept of generative AI goes a long way back; in fact, it dates back to
    the time when machine learning was in its cradle. However, it is only recently
    that this field has come under the limelight due to neural networks and drastic
    improvements in computing power over the last 10 years. In the early attempts
    at generative modeling‚ÄîGaussian mixture models and hidden Markov models‚Äîmany simpler
    statistical techniques were involved. Methods of modeling arbitrary complex data
    distributions have much higher potential compatibility with the kinds of methods
    that were previously dominant but have recently been overcome by deep learning.
    Deep learning was therefore a watershed development for the field of generative
    AI. Models, such as VAEs, which started appearing around the beginning of the
    2010s, were able to leverage deep neural networks to model more complex data distributions.
    Around that same period, GANs were proposed; for the first time, they offered
    a new way for two neural networks to work together to create data, using principles
    from game theory. In a general sense, these breakthroughs took leaps toward the
    possibilities of making real, high-quality, realistic creation of data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'This can lead to innovation in most fields across industries, such as healthcare,
    finance, education, travel and hospitality, manufacturing, and more. Generative
    AI in creative industries helps artists and designers think outside the box, helping
    with the conception of new and innovative content. It opens ways for new routes
    of drug discovery and personalized medicine in health. In the business world,
    generative AI works by providing efficient and effective customer engagement through
    personalized content and experiences. The other point involves questioning one‚Äôs
    own stance regarding creativity and originality: when machines are able to pump
    out very similar material, one is automatically forced to think about what creativity
    is, who the artist really is, and what the ethical parameters should be for AI-created
    content.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Having understood what generative AI is and its brief history, let‚Äôs explore
    the different types of generative AI models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Types of generative AI models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generative AI is an exciting domain of AI that deals with the generation of
    new, synthetic data by learning patterns from existing datasets, aiming to generate
    outputs that share similar statistical properties and characteristics with the
    training data. Here is a broad overview of some of the most prominent types of
    generative models: VAEs, GANs, and autoregressive models.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: VAEs
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the most popular generative models is the VAE. The core idea behind
    VAE consists of learning a probabilistic mapping between data and a latent space,
    and vice versa. This means learning how to convert real data into a simplified
    representation (such as a compressed form) and then back again into data that
    looks real. VAEs are designed to ensure a high likelihood of the data while preserving
    a well-structured latent space to enable the generation of new data samples similar
    to the training data. Some of the most common flavors of VAE are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '**VAE** : The basic model that compresses and reconstructs data. It gives a
    framework for generating new samples out of the learned latent space. The VAE
    is a generative model that learns to compress and reconstruct data while also
    learning a probability distribution of the latent space. In simpler terms, a VAE
    is like a clever algorithm that learns to understand and recreate data. Imagine
    it as a skilled artist who can compress a detailed painting into a simple sketch
    (encoding) and then recreate the full painting from that sketch (decoding). What
    makes VAEs special is that they don‚Äôt just copy data but also learn the essence
    of it, allowing them to create new, similar data. This is like an artist learning
    not just to copy specific paintings but also to understand the style so well that
    they can paint new, original works in that style. In real life, VAEs have been
    used in many creative ways. For instance, in drug discovery, VAEs have been used
    to generate novel molecular structures. Researchers at AstraZeneca used VAEs to
    explore chemical space and propose new drug-like molecules with desired properties,
    potentially accelerating the drug development process [1].'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Beta-VAE** : An extension of VAE that introduces a hyperparameter to control
    explicitly the trade-off between the reconstruction quality and the disentanglement
    of the latent space. The model undertakes the creation of more interpretable disentangled
    representations. In simpler terms, Beta-VAE is like a more flexible version of
    the original VAE. It allows researchers to adjust how much the model focuses on
    recreating exact details versus understanding the underlying features of the data.
    This is similar to teaching an art student to not just copy a painting but also
    to understand and separate the key elements such as color, shape, and style. This
    ability to *disentangle* features makes Beta-VAE particularly useful in fields
    such as computer vision and robotics. For example, researchers have used Beta-VAE
    to teach robots to understand objects better. By learning to separate features
    such as size, color, and position, robots can more easily recognize and manipulate
    objects in different situations, making them more adaptable and efficient in various
    tasks [2].'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conditional variational autoencoder** ( **CVAE** ): A variant that conditions
    the generation process on some extra information, typically class labels, producing
    not just data similar to the training set but also samples that can then be drawn
    from specific classes . Think of CVAE as a more controlled version of VAE, like
    an artist who can paint in different styles on demand. Instead of just creating
    random new paintings, this artist can be told to ‚Äú *Paint a landscape* ‚Äù or ‚Äú
    *Paint a portrait* ‚Äù and they‚Äôll create new art in that specific category. This
    added control makes CVAE very useful in practical applications. For instance,
    in the field of computer games, CVAE has been used for game development and procedural
    content generation with the generation of game elements such as character design,
    level layouts, music and sound effects, and so on. By providing different conditions
    such as ‚Äú *Create a forest level* ‚Äù or ‚Äú *Create a desert level* ,‚Äù the CVAE can
    produce a wide variety of game environments, saving time for designers and enhancing
    the player‚Äôs experience with more diverse and interesting game worlds [3].'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GANs
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A GAN is basically formed by two neural networks: a **generator** and a **discriminator**
    . The generator generates synthetic data samples; the other trained neural network
    should then be able to tell the difference between real and created samples. While
    training these networks, they are trained together antagonistically: the generator
    tries to fool the discriminator, while the discriminator tries rightly to classify
    real versus fake data. In this competition, the generator gets better and better
    at faking data. The following are some of the different types of GANs:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '**GAN** : The basic model in which the generator and discriminator are trained
    adversarially; it is the root model for most innovations in generative modeling.
    As explained earlier, you can imagine GAN as a game between two players‚Äîa counterfeiter
    (generator) trying to create fake money, and a detective (discriminator) trying
    to identify the fakes. As they compete, they both get better at their jobs, which
    means that the counterfeiter gets increasingly better at creating fake money.
    This clever setup allows GANs to create incredibly realistic fake data, such as
    images or sounds [4].'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deep convolutional GAN** ( **DCGAN** ): This is a refinement of the base
    GAN model with deep convolutional neural networks; at the moment, it is one of
    the best architectures for generating images of high quality. Think of DCGAN as
    a more sophisticated artist compared to the basic GAN. It‚Äôs like upgrading from
    simple sketching tools to a full digital art studio, allowing for the creation
    of much more detailed and realistic images. DCGANs are particularly good at understanding
    and recreating complex patterns in images [5].'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wasserstein GAN** ( **WGAN** ): This proposes a different loss function with
    the Wasserstein distance. This removes problems while training with a GAN, hence
    making training more stable and improving sample quality. This helps measure the
    distance between two probability distributions better. WGAN is like giving the
    artist (generator) and critic (discriminator) in a GAN a better way to communicate
    and evaluate each other‚Äôs work. Instead of just saying ‚Äú *good* ‚Äù or ‚Äú *bad* ,‚Äù
    they can now give more nuanced feedback, such as ‚Äú *You‚Äôre getting warmer* ‚Äù or
    ‚Äú *You‚Äôre way off* .‚Äù This leads to more consistent improvement and high-quality
    results. In practical applications, WGANs have been used in medical imaging to
    generate synthetic medical images for training purposes. This helps in creating
    larger, more diverse datasets for training diagnostic AI systems, potentially
    improving their accuracy in detecting diseases from scans and X-rays [6].'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**StyleGAN** : This generates high-quality realistic images. The model is especially
    good at handling style and content separately. Progressions offered by the introductions
    of StyleGAN2 and StyleGAN3 are still aimed at improving image fidelity and realism.
    Think of StyleGAN as an advanced digital artist that can not only create realistic
    images but also mix and match different styles and contents. It‚Äôs like having
    a painter who can take the style of Van Gogh and apply it to a modern cityscape.
    This flexibility makes StyleGAN incredibly versatile [7].'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoregressive models and Transformer architecture
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Autoregressive models generate their data points one at a time, conditioning
    each of its data points on the previous one. Surprisingly, this ultimately proves
    very useful in tasks in which the sequence or structure of data is relevant, such
    as text generation and image generation. The Transformer architecture, introduced
    in the *Attention Is All You Need* paper [8], is a model architecture that has
    revolutionized many sequential data tasks, especially in **natural language processing**
    ( **NLP** ). Its key components are demonstrated in *Figure 1* *.1* :'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/B31483_01_1.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 ‚Äì The Transformer architecture
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'These key components include the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-attention m** **echanism** : A computational technique that allows the
    model to dynamically focus on different parts of the input when processing each
    element'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-head attention** : Multiple attention mechanisms running in parallel,
    allowing the model to focus on different aspects of the input simultaneously'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Positional encoding** : Adds information about the position of each element
    in the sequence'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feed-forward neural networks** : Process the output of the attention layers'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer normalization and residual connections** : Enhance training stability
    and information flow'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Transformers can be used in both autoregressive and non-autoregressive configurations,
    making them versatile for various tasks. The following are some examples:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '**PixelCNN** : Autoregressively generates images pixel by pixel, conditioning
    each pixel on the previously generated ones. This model works very well in generating
    high-quality images with fine details [9].'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PixelSNAIL** : A refinement over PixelCNN that adds attention mechanisms
    into the model to capture strong dependencies between pixels, and hence, a better
    quality of an image [10].'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPT** : Standing for **Generative Pre-trained Transformer** , it is a line
    of models specializing in text generation‚Äînamely, predicting which words should
    come next. Among them are GPT-2, GPT-3, and GPT-4, making a huge leap in generating
    coherent and contextually relevant text [ 11] [12].'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BERT** : Unlike GPT, BERT, which stands for **Bidirectional Encoder Representations
    from Transformers** , is designed to understand the context from both directions
    in text. It uses the encoder part of the Transformer and is typically used for
    tasks that require an understanding of the entire input at once, rather than generating
    text autoregressively [13].'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text-To-Text Transfer Transformer** ( **T5** ): This model frames all NLP
    tasks in a text-to-text format. It uses the full Transformer architecture (both
    encoder and decoder) and can handle various text generation tasks [14].'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although it depends on the task, these models demonstrate how the Transformer
    architecture can be adapted for both autoregressive (such as GPT) and non-autoregressive
    (such as BERT) tasks, showcasing its versatility in handling sequential data.
    Strengths differ across generative models. This class of models goes from generating
    photorealistic images to coherent text to totally new data samples.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Building upon the success of models such as GPT, researchers have scaled up
    these architectures to create **large language models** ( **LLMs** ). These models,
    often trained on vast amounts of open web text and other freely available text
    data, have demonstrated exceptional proficiency in understanding and generating
    human-like text across diverse applications, showcasing their versatility and
    advanced linguistic abilities. Examples of LLMs include GPT-3, GPT-4, PaLM, and
    BERT-large. These models have pushed the boundaries of what‚Äôs possible in NLP,
    showing proficiency in tasks ranging from question-answering and summarization
    to creative writing and code generation. The following is an overview of the common
    types of LLMs:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoregressive LLMs** : These language models are typically capable of generating
    text sequentially, that is, one token at a time. Some of the common tasks that
    these types of models are used for include text generation, text completion tasks,
    and creative writing. Some popular examples of autoregressive LLMs are the GPT
    series (GPT-3, GPT-4), and PaLM.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encoder-only LLMs** : These models specialize in **natural language understanding**
    ( **NLU** ) tasks, which involve analyzing and comprehending input text without
    generating new text. Encoder-only LLMs, such as BERT and its variants including
    RoBERTa, focus on understanding the context and meaning of input text. These models
    process the entire input sequence simultaneously, allowing them to capture the
    context helping with tasks such as text classification, **named entity recognition**
    ( **NER** ), and sentiment analysis.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encoder-decoder LLMs** : This is a combination of encoder and decoder architecture
    where the models can not only understand the context of the input text (NLU) but
    are also capable of generating textual output. The T5 model discussed earlier
    is a very popular example of an encoder-decoder LLM, along with models such as
    BERT. These models are capable of language translation, summarization, and question-answering.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multimodal LLMs** : Multimodality is a concept where an AI model can not
    only handle text but also other modalities such as image, video, and audio. Multimodal
    LLMs can process and generate content in various modalities such as text, image,
    audio, video, and any combination thereof. These models are rather novel in nature
    and recent advancements in compute have made it possible to train multimodal LLMs.
    Some of the well-known multimodal LLMs are DALL-E, Stable Diffusion, Flamingo,
    GPT-4, and LlaVa.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instruction-tuned LLMs** : LLMs are often trained on a large corpus of openly
    available web or other text. As such, in certain scenarios, these models may not
    perform effectively for tasks that use data that the model has never seen before
    and thus may fail to follow the user intent. For example, a manufacturing manual
    for a proprietary instrument may contain domain-specific proprietary language,
    which the model may not have been exposed to during training. In such cases, LLMs
    can be fine-tuned using the domain-specific data to follow specific instructions
    and prompts (that is, text input to the model). This special fine-tuning enables
    the model to perform domain-specific tasks on which the model was fine-tuned,
    in addition to its other capabilities. Think of this as localizing a personal
    copy of a model to be good at performing a task that is meaningful for your use
    case. One of the common examples of such a model is InstructGPT, where researchers
    fine-tuned the GPT-3 model on specific instructions. These types of models are
    used in a multitude of different tasks such as chatbots, virtual assistants, and
    task-specific applications.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain-specific LLMs** : As mentioned earlier, while LLMs are often trained
    on a large set of open, generally available, web data, they may not perform very
    well in domain-specific environments. While instruction-tuned LLMs are an avenue
    to make these general-purpose models work for domain-specific tasks, researchers
    have innovated on training domain-specific LLMs from the ground up. This means
    that these models were pre-trained on highly specialized, domain knowledge. For
    example, the BioBERT model is trained on hyper-specialized medical data, whereas
    LegalBERT is trained on legal documents. These models are useful for specialized
    tasks in specific fields such as medicine, law, and finance.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM-powered AI agents
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each of the previously discussed LLM types has its own strengths and weaknesses
    and is well-suited for different applications. However, our focus in this book
    would be to dive deeper into LLM agent capabilities and explore how advanced systems
    can be built utilizing them. It is important to note that LLM agents do not fit
    neatly into a single category, as they represent an advanced application of LLM
    technology rather than a specific type of model architecture. Agents are typically
    built using instruction-tuned LLMs as their foundation, often combined with additional
    components and capabilities as you will learn further in this book.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us take a look at a simple example to demonstrate the capabilities of an
    agentic system powered by an LLM. Our example is a travel website that has a **Flight
    Booking Assistant** chatbot that is a conversational interface built with an LLM.
    It can help customers book travel tickets via human-like conversations. In the
    backend, the chatbot can perform various tasks as the conversation progresses.
    Here‚Äôs what a sample conversation may look like for a customer who is looking
    to book a flight ticket:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '| Flight Booking Assistant |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | Hi, I want to book a flight. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Hello! I‚Äôd be happy to help you book a flight. To get started, could
    you please tell me your departure city and destination? |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | I want to go from San Diego to SFO. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Great, thank you for providing that information. You‚Äôre looking to fly
    from San Diego (SAN) to San Francisco International Airport (SFO). To help you
    find the best flight options, I‚Äôll need a few more details.1. What is your preferred
    travel date?2. Is this a one-way trip or a round trip?3. How many passengers will
    be traveling? |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | I want to go next Friday and come back
    on Sunday. Just me traveling. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Thank you for the additional information. Let me summarize what I have
    so far:- Departure: San Diego (SAN) to San Francisco (SFO)- Outbound Date: Next
    Friday ‚Äì 08/23/2024- Return Date: Sunday ‚Äì 08/25/2024- Passengers: 1 adultBefore
    I search for flights, I have a few more questions:1. Do you have a preferred time
    of day for your flights (morning, afternoon, or evening)?2. Do you have a preferred
    airline or are you open to all airlines?3. What class of service would you prefer
    (Economy, Premium Economy, Business, or First Class)? |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | I prefer morning flights. No airline preference.
    Economy is fine. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Thank you for those details. I‚Äôll search for morning flights in Economy
    class across all airlines for your trip. Give me a moment to find the best options
    for you.[searching flights...please stand by‚Ä¶.] |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | I‚Äôve found a few options for your trip. Here are the best morning flights:Outbound
    (SAN to SFO) - Next Friday:1. United Airlines UA1234: Depart 7:15 AM, Arrive 8:45
    AM2. Alaska Airlines AS5678: Depart 8:30 AM, Arrive 10:00 AMReturn (SFO to SAN)
    - Sunday:1. Delta Air Lines DL9876: Depart 9:00 AM, Arrive 10:30 AM2. Southwest
    Airlines WN5432: Depart 10:15 AM, Arrive 11:45 AMThe total price for the round
    trip, including taxes and fees, is:- Option 1 ( United/Alaska): $325- Option 2
    ( Delta/Southwest): $310Which option would you prefer? Or would you like me to
    look for different flights? |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | The second option looks good. Can you
    book that for me? |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Certainly! I‚Äôd be happy to book the second option for you. Just to confirm,
    I‚Äôll be booking the following itinerary:Outbound: Alaska Airlines AS5678- Date:
    08/23/2024- Depart San Diego at 8:30 AM, Arrive in SFO at 10:00 AMReturn: Southwest
    Airlines WN5432- Date: 08/25/2024- Depart SFO at 10:15 AM, Arrive in San Diego
    at 11:45 AMTotal price: $310To proceed with the booking, I‚Äôll need some additional
    information:1. Your full name as it appears on your government-issued ID2. Your
    date of birth3. Your email address (for sending the confirmation)4. Your phone
    number5. Any special requests (for example, meal preferences, seat preferences)Also,
    please note that you‚Äôll need to provide a form of payment to complete the booking.
    Are you ready to proceed with this information? |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | Yes, I‚Äôm ready. My name is John Smith,
    born on 05/15/1985. My email is john.smith@email.com and my phone number is 555-123-4567.
    No special requests. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Thank you for providing that information, Mr. Smith. I‚Äôve entered your
    details into the booking system. Here‚Äôs a summary of the information I have:-
    Name: John Smith- Date of Birth: 05/15/1985- Email: john.smith@email.com- Phone:
    555-123-4567- Special Requests: NoneThe final step is to process the payment of
    $310 for your flights. For security reasons, I can‚Äôt accept credit card information
    directly in this chat. Instead, I‚Äôll send a secure payment link to your email
    address (john.smith@email.com).Once you receive the email, please follow the link
    to complete the payment process. After the payment is successfully processed,
    you‚Äôll receive another email with your flight confirmation and e-tickets.Is it
    okay to proceed with sending the payment link to your email? |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | Yes, that‚Äôs fine. Please send the payment
    link. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | Excellent, Mr. Smith. I‚Äôve initiated the process to send the secure payment
    link to your email address (john.smith@email.com). You should receive it within
    the next few minutes. Please check your inbox and spam folder if you don‚Äôt see
    it right away.Once you complete the payment, the system will automatically process
    your booking and send your confirmation email with the e-tickets. This email will
    include important information such as:1. Booking confirmation number2. Detailed
    flight itinerary3. Check-in instructions4. Baggage allowance information5. Airline
    contact informationAfter you receive your confirmation email, please review all
    the details to ensure everything is correct. If you notice any issues or have
    any questions, please don‚Äôt hesitate to contact us.Is there anything else you
    need assistance with regarding your trip or the booking process? |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| ![img](img/B31483_01_Icon_1.png) | No, that‚Äôs all. Thank you for your help!
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| ü§ñ | You‚Äôre welcome, Mr. Smith! I‚Äôm glad I could assist you with booking your
    flights from San Diego to San Francisco. If you need any further assistance with
    this booking or have any questions about your trip, please don‚Äôt hesitate to reach
    out. We‚Äôre here to help 24/7. Have a great trip to San Francisco next week! |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: On the surface, this example looks pretty straightforward. However, there are
    a number of things that are happening in the background. Firstly, the customer
    starts with a vague request to book a flight. The AI assistant understands that
    in order to proceed with this request, it needs a few more pieces of information
    to look up available flights, such as departure/arrival city, dates of travel,
    and so on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'As the conversation progresses, the AI assistant requests further pieces of
    information to be able to successfully complete the booking. The information it
    gathers at each step is used as a parameter value to call flight booking-related
    APIs in the backend; for example, city/travel dates/number of passengers are required
    to look up available flight information using a (fictitious) API named **flightLookup**
    , customer name/phone/email are required to actually make the booking using an
    API named b **ookFlight** , and so on. *Figure 1* *.2* gives an overview of the
    decisions that the model makes, the flow of the interaction, and the tools (API
    functions) it calls to complete each step:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/B31483_01_2.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 ‚Äì Flight Booking Assistant chatbot with LLM-powered multi-agents
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: In addition to just tool calling, you will also notice that the model does a
    bit of introspection, also known as **chain of thought** ( **CoT** ), at the beginning
    of the conversation. This means the model in the backend crafts a step-by-step
    approach to complete the task but identifies some missing information. It then
    responds back to the customer with a request to provide the required information.
    Subsequently, based on the input from the customer, it makes certain decisions
    autonomously to call specific tools using the agent and completes the task.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the external tools and APIs, there are a number of other things
    to consider when designing such a system. We will cover the fundamentals of each
    of these components in detail in the subsequent chapters. For now, it is sufficient
    to know that agents are an advanced application of LLMs (such as this travel booking
    AI assistant) and represent an emerging field that combines aspects of various
    LLM types with additional AI techniques such as reinforcement learning, planning,
    and tool use. As you learn more in subsequent chapters, you will notice that agents
    are designed to be more interactive, adaptable, and capable of completing complex,
    multi-step tasks compared to standard LLMs, which makes them suitable for a variety
    of different complex tasks and workflows.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: But before we dive deeper into the details of agentic systems, let us review
    some of the applications of generative AI.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Applications of generative AI
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generative AI has innovation capabilities that cover a diverse set of fields.
    As discussed earlier, industries such as healthcare, finance, education, media
    and entertainment, marketing, manufacturing, retail, and so on all have the potential
    to benefit from generative AI capabilities. The following is a survey of only
    a few of the primary applications of generative AI:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '**Generation of images and videos** : Multimodal generative models (that is,
    LLMs that can handle images, text, audio, and videos) are making it possible to
    generate realistic audio/visuals through various platforms and tools. For example,
    in media and entertainment, generative AI can help in generating visual effects,
    designing avatars, and developing virtual reality content. In the fashion and
    design industry, it is being used to conceptualize new clothing designs, prepare
    virtual fashion shows, and make fashion trend predictions. In marketing ads and
    promotion space, generative AI is being used to generate tailor-made advertisements,
    campaigns, marketing communications, and other marketing materials creatives such
    as images and logos.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text and content generation** : Generative AI has made significant strides
    when it comes to text-based tasks. For instance, content writing such as rapid
    and hassle-free generation of articles, blog posts, marketing, and product copies
    are already some of the most common use cases. Chatbots and virtual assistants
    are providing customer support in a very humanlike manner to information-related
    inquiries. Generative AI is also assisting in text translation, document summarization,
    and content localization for increased accessibility of content for platforms
    such as online learning and specialized search engines.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Music and audio generation** : Creating original music, sound effects, and
    voice synthesis is yet another paradigm of multi-media content generation that
    is being powered by generative AI. Practically, contents such as these are being
    used in the gaming and entertainment industry to create audio-assisted training
    materials, automated call center assistants, and IoT devices such as Amazon Alexa,
    or Google Next that can take audio commands and use voice responses to complete
    automated tasks.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Healthcare and drug discovery** : Generative AI finds space in health care.
    For example, the design of new drugs and the prediction of their capability to
    treat diseases or other conditions; personalized medicine, whereby treatment plans
    are tailored individually on a patient-by-patient basis; and medical imaging,
    whereby image quality is refined and synthetic images generated for research purposes.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code generation** : Code generation is an emerging LLM feature that is helping
    developers in software development. These models can often generate accurate code
    snippets, or sometimes an entire function based on text prompts. Advanced implementation
    of generative AI in code generation includes plugins created for various **integrated
    development environments** ( **IDEs** ), such as **Visual Studio Code** ( **VS
    Code** ), that can understand the entire context of the code base, identify errors,
    create code documentation, and generate unit test scripts. Another implementation
    of code generation is text-to-query use cases where a natural language prompt
    is converted into a SQL query, which can then be executed against a database to
    get the desired results. However, this is one of the areas where special caution
    must be taken, especially before executing the code generated by an LLM, to prevent
    risks of malicious code execution. Often, in these situations, the code generated
    by the LLM is executed in a sandbox and sanitized to check whether the code is
    safe and appropriate for execution in an autonomous environment.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autonomous workflows and robotics** : As we briefly discussed earlier, LLM-powered
    AI agents are an advanced implementation of generative AI with LLMs serving as
    their foundations. These agents can perform several tasks in various use cases.
    For example, a travel booking website with a virtual assistant chatbot can implement
    agents to automate the travel and hotel booking process for the customer. In these
    cases, the agent-based system can act on specific tasks using tools (such as calling
    a flight booking API) simply by understanding the context of the conversation
    that the customer is having with the chatbot. More advanced agent-based systems
    often come into play when discussing robotics, where a robot‚Äôs actions are primarily
    controlled by agents. The robotic agent essentially determines what decisions
    to make based on its environment or the specific task it is assigned to perform.
    It uses agents to execute actions that an LLM would otherwise be unable to perform;
    for example, an agent can turn on or off the limb actuators of a robot. AI in
    robotics is a novel and open field of research, with numerous innovations emerging
    in the industry, particularly targeted toward manufacturing applications.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are just some of the common examples of the uses of generative AI with
    LLMs. Other specific examples include uses in fashion and design, synthetic data
    generation, personalized educational content, financial modeling and forecasting,
    and predictive maintenance. The following is a brief list of examples of commercial
    and open source tools that use generative AI for the number of use cases we discussed:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '| **Use case** | **Commercial tools** | **Open** **source tools** |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
- en: '| **Visual effects and** **avatar design** |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: '**Unreal Engine‚Äôs MetaHuman Creator** : Allows for the creation of highly realistic
    digital humans for games and films'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NVIDIA Omniverse** : A platform for 3D design collaboration and simulation,
    useful for creating visual effects'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '**DeepFaceLab** : Used for face swapping and creating digital avatars'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**StyleGAN** : Capable of generating highly realistic faces and can be adapted
    for avatar creation'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '| **Virtual reality** **content development** |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '**Unity** : While not exclusively for VR, it has robust VR development capabilities'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adobe Aero** : Allows for the creation of AR experiences'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '**A-Frame** : A web framework for building virtual reality experiences'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Godot** : An open source game engine with VR support'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '| **Clothing design and virtual** **fashion shows** |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '**CLO3D** : A 3D garment design software that can create virtual fashion shows'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Browzwear** : Offers 3D design solutions for the fashion industry'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '**Blender** : While primarily a 3D modeling tool, it can be used for fashion
    design and virtual shows'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '| **Fashion** **trend predictions** |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '**WGSN** : Uses AI for trend forecasting in fashion'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuritech** : Provides AI-powered trend forecasting'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: None
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '| **Marketing ‚Äì ad generation and** **campaign creation** |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '**Jasper** : An AI writing assistant that can help create marketing copy'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Midjourney** : An AI image generation tool useful for creating marketing
    visuals'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '**GPT-J** : An open source language model that can be fine-tuned for marketing
    content generation'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stable Diffusion** :An open source image generation model that can create
    marketing visuals.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '| **Logo and** **image creation** |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
- en: '**DALL-E 2** : Can generate unique images and logos based on text descriptions'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canva** : While not fully AI-powered, it incorporates AI features for design
    assistance'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '**Stable Diffusion** : Can be used for logo and image generation'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Craiyon (formerly DALL-E mini)** : An open source alternative to DALL-E'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '| **Text and** **content generation** |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
- en: ChatGPT by OpenAI
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Claude AI by Anthropic
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jasper
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy.ai
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anyword
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writer
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WriteSonic
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And many more‚Ä¶ |
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '**Mistral 7B** : An open source LLM known for its efficiency and precision
    in text generation tasks'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LLaMA** : A collection of open source pre-trained and fine-tuned generative
    text models, offering versions with different parameter sizes'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BLOOM Language Model** : A large open-access AI model developed by over 1,000
    AI researchers, known for its robustness and versatility in text generation'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And many more‚Ä¶ |
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '| **Code generation** |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: GitHub Copilot
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Q for Developers
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tabnine
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI Codex
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And many more‚Ä¶ |
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '**Code T5** : An open source AI model trained for code-related tasks. It can
    generate code snippets, complete code, and even translate between programming
    languages.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Polycoder** : An open source alternative to commercial code generators. It‚Äôs
    trained on a large code base spanning multiple programming languages and can generate
    code for various tasks.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '| **Autonomous workflows** **and robotics** |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: '**UiPath** incorporates generative AI into its **robotic process automation**
    ( **RPA** ) platform. It uses AI to discover automation opportunities and enhance
    tasks such as document understanding and communications mining.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation Anywhere** integrates generative AI into its automation platform.
    It offers features such as Automation Co-Pilot for Automators, which uses generative
    AI to accelerate developer productivity.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NVIDIA** provides AI workflows that leverage their AI frameworks, including
    generative AI capabilities, for developing innovative solutions in robotics and
    autonomous systems.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '**OpenAI Gym** provides a toolkit for developing and comparing reinforcement
    learning algorithms, which can be combined with LLMs for more advanced robotics
    applications.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hugging Face** offers open source libraries that can be used to implement
    LLMs in robotics and autonomous workflow applications.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LangChain** is an open source Python library used for developing applications
    using LLMs, which can be applied to create more intelligent autonomous workflows
    and robotic systems.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Table 1.1 ‚Äì Examples of commercial and open source tools that use generative
    AI
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: This is in no way an exhaustive list of commercial and open source tools available
    in the market at the moment and the landscape is changing every day. We are witnessing
    a host of new start-ups providing new and innovative ways of solving real-life
    use cases with generative AI, and we are also witnessing new model providers developing
    state-of-the-art LLMs that are more capable than the previous ones and are much
    cheaper to operate. This just goes to show you how dynamic and exciting the field
    of generative AI is.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and limitations of generative AI
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Though generative AI has immense benefits, it is not without its own set of
    challenges and limitations. Some of these challenges and limitations need to be
    taken into account with a lot of caution while considering a generative AI technology
    for any particular use case. Here‚Äôs a brief discussion of some of the most common
    caveats related to LLMs and some of the ways to mitigate them.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Quality of data and bias
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The generative models are largely aided by the quality and diversity of data
    in the training dataset. Any model trained with biased or unrepresentative data
    will reproduce outputs with the same kind of bias, hence solidifying existing
    biases or allowing marginalization of one or several groups in case of bias in
    the training data.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'One way this challenge can be dealt with is by ensuring richness in diversity,
    good quality data, and so on for a wide array of perspectives within the dataset
    itself used for training. As with any machine learning problem, analysis of the
    data and knowing the data distribution across features is often helpful. Data
    analysis can reveal imbalances that can introduce bias in the model. There are
    several algorithmic ways of mitigating bias in training data (for instance, using
    oversampling or undersampling), but each of these methods has its own advantages
    and disadvantages. For example, consider two classes of data in a training dataset
    that contains more instances of *Class 0* data than *Class 1* data, causing a
    natural imbalance in the dataset. When a model is trained with such a dataset,
    the model would ‚Äúoverfit‚Äù on the *Class 0* type of data and would become more
    proficient in or even memorize data that belongs to *Class 0* and may not perform
    well for data belonging to *Class 1* This inherently causes the model to perform
    poorly and demonstrate heavy bias. The following figure demonstrates the effect
    of oversampling and undersampling on such a dataset to mitigate bias:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/B31483_01_3.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 ‚Äì Imbalanced data distribution and effects of oversampling and undersampling
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Data privacy
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple experiments and researchers have proven that LLMs have a propensity
    to leak data they are trained on. This is especially problematic if the models
    are trained on large amounts of private or proprietary information. Special techniques
    and styles of prompting LLMs have shown that it is sufficient to coerce the model
    to generate data that includes verbatim text from its training dataset. These
    prompting techniques are not sophisticated and often make it a very easy, cost-effective
    attack vector to get a model to leak information. For example, as discussed in
    the paper named *Scalable Extraction of Training Data from (Production) Language
    Models* [15], researchers were able to spend only $200 worth of API calls to OpenAI‚Äôs
    GPT-3.5 model and use prompt injection techniques to coerce the model to leak
    private information. The leaked information includes people‚Äôs names, email and
    physical addresses, and phone numbers that were inadvertently present in the model‚Äôs
    training dataset. While some of these issues are actively being addressed by model
    providers such as OpenAI, it can still be problematic for organizations that choose
    to train their own models in-house.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Some of the common mechanisms to mitigate this is to perform data anonymization
    or pseudonymization on the training data to remove or obscure personal, private,
    and or proprietary information, even before training the model. Both of these
    techniques involved using smaller, cheaper, and faster AI models to perform classification
    and entity detection to identify the presence of personal or private data in the
    training dataset. Once identified, the private information can be obscured, masked,
    or entirely removed from the training dataset. Note that there could be several
    implications to doing this depending on your use case, so special analysis must
    be performed to ensure that it doesn‚Äôt impact the model‚Äôs performance.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Computational resources
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Training sophisticated generative models is very resource-intensive and requires
    high computational power; this often makes it economically cost-prohibitive and
    energy-consuming to train large language models. Although there have been several
    hardware breakthroughs that make it possible to train such models, access to these
    hardware assets still remains expensive, privileged, and limited. For example,
    **graphics processing units** ( **GPUs** ), initially designed for rendering high-fidelity
    graphics, have become crucial for AI model training, fine-tuning, and computations.
    NVIDIA‚Äôs CUDA architecture, introduced in 2006, allowed GPUs to be used for general-purpose
    computing, and modern GPUs such as NVIDIA‚Äôs A100 and H100 have since been specifically
    optimized for AI workloads. However, these high-end GPUs can often cost tens of
    thousands of dollars per unit.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Training large models such as GPT-3 is estimated to cost millions of dollars
    in compute resources alone. The exact cost depends on factors such as model size,
    training duration, and hardware efficiency. For example, training GPT-3 was estimated
    to cost around $4‚Äì5 million in compute resources, and more recent models such
    as GPT-4 and PaLM are likely even more expensive to train. Beyond the hardware
    itself, there are significant infrastructure costs related to power consumption,
    cooling, and data center space. Due to the high costs, training large language
    models is primarily done by large tech companies or well-funded research institutions.
    Cloud services now offer access to pre-trained models and fine-tuning capabilities,
    making some level of LLM work more accessible to smaller organizations and the
    general public. A way to overcome this challenge can be found in recent innovations
    with **small language models** ( **SLMs** ), which are much smaller generative
    AI models that can be trained to achieve specific tasks. Even though these models
    are limited to a very narrow set of domain-specific tasks, it is much more economical
    to train these models since they require far fewer computational resources.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Ethical and social implications
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The range of issues in ethics and society exposed by strides in technological
    generative AI opened up the following many-headed issues, which is far from an
    exhaustive list:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ÊäÄÊúØÁîüÊàêÂºèAIÁöÑËøõÊ≠•Âú®‰º¶ÁêÜÂíåÁ§æ‰ºöÊñπÈù¢Êö¥Èú≤Âá∫ÁöÑ‰∏ÄÁ≥ªÂàóÈóÆÈ¢òÔºåÂºïÂèë‰∫Ü‰ª•‰∏ãËÆ∏Â§öÂ§çÊùÇÈóÆÈ¢òÔºåËøôËøúÈùû‰∏Ä‰∏™ËØ¶Â∞ΩÁöÑÂàóË°®Ôºö
- en: '**Deepfakes and misinformation** : It is able to produce very realistic synthetically
    generated content. If that were to happen, it would yield deepfakes or even misinformation,
    which could be a threat to privacy, security, or even public trust.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ê∑±Â∫¶‰º™ÈÄ†ÂíåËôöÂÅá‰ø°ÊÅØ**ÔºöÂÆÉËÉΩÂ§üÁîüÊàêÈùûÂ∏∏ÈÄºÁúüÁöÑÂêàÊàêÂÜÖÂÆπ„ÄÇÂ¶ÇÊûúÂèëÁîüËøôÁßçÊÉÖÂÜµÔºåÂÆÉÂ∞Ü‰∫ßÁîüÊ∑±Â∫¶‰º™ÈÄ†ÁîöËá≥ËôöÂÅá‰ø°ÊÅØÔºåËøôÂèØËÉΩÂØπÈöêÁßÅ„ÄÅÂÆâÂÖ®ÁîöËá≥ÂÖ¨‰ºó‰ø°‰ªªÊûÑÊàêÂ®ÅËÉÅ„ÄÇ'
- en: '**Intellectual property** : The process of developing comparable content to
    existing ones brings forth issues with copyright and intellectual property rights.
    The legal complexity attached to the very originality of the creation and correct
    ownership can be most perplexing.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Áü•ËØÜ‰∫ßÊùÉ**ÔºöÂºÄÂèë‰∏éÁé∞ÊúâÂÜÖÂÆπÁõ∏‰ººÁöÑËøáÁ®ã‰ºöÂºïÂèëÁâàÊùÉÂíåÁü•ËØÜ‰∫ßÊùÉÈóÆÈ¢ò„ÄÇ‰∏éÂàõ‰ΩúÁöÑÂéüÂàõÊÄßÂíåÊ≠£Á°ÆÊâÄÊúâÊùÉÁõ∏ÂÖ≥ÁöÑÊ≥ïÂæãÂ§çÊùÇÊÄßÂèØËÉΩÈùûÂ∏∏‰ª§‰∫∫Âõ∞ÊÉë„ÄÇ'
- en: '**Job displacement** : Economists often downplay concerns about significant
    job losses in content generation and other automated task sectors. Of concern
    is the fact that resultant effects are expected to be paralleled with studies
    on ways of reskilling and adjustment strategies that can help the affected workers,
    as well as entrepreneurial opportunities.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Â∑•‰ΩúÊõø‰ª£**ÔºöÁªèÊµéÂ≠¶ÂÆ∂Â∏∏Â∏∏Ê∑°ÂåñÂØπÂÜÖÂÆπÁîüÊàêÂíåÂÖ∂‰ªñËá™Âä®Âåñ‰ªªÂä°È¢ÜÂüüÈáçÂ§ßÂ§±‰∏öÁöÑÊãÖÂøß„ÄÇ‰ª§‰∫∫ÊãÖÂøßÁöÑÊòØÔºåÈ¢ÑÊúüÁªìÊûúÂ∞Ü‰∏éÂÖ≥‰∫éÂÜçÂüπËÆ≠ÂíåË∞ÉÊï¥Á≠ñÁï•ÁöÑÁ†îÁ©∂Áõ∏Âπ≥Ë°åÔºåËøô‰∫õÁ≠ñÁï•ÂèØ‰ª•Â∏ÆÂä©ÂèóÂΩ±ÂìçÁöÑÂ∑•‰∫∫Ôºå‰ª•ÂèäÂàõ‰∏öÊú∫‰ºö„ÄÇ'
- en: When it comes to mitigating social and ethical implications, the question is
    more philosophical than technical. While some measures such as deepfake AI image
    detection and private and personal data detection methods are common strategies,
    the societal implications are a larger question in the context of AI‚Äôs benefit
    to society and any existing or impending government regulations.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ÂΩìË∞àÂà∞ÂáèËΩªÁ§æ‰ºöÂíå‰º¶ÁêÜÂΩ±ÂìçÊó∂ÔºåÈóÆÈ¢òÊõ¥Â§öÁöÑÊòØÂì≤Â≠¶ÊÄßÁöÑÔºåËÄå‰∏çÊòØÊäÄÊúØÊÄßÁöÑ„ÄÇËôΩÁÑ∂Ê∑±Â∫¶‰º™ÈÄ†AIÂõæÂÉèÊ£ÄÊµãÂíåÁßÅ‰∫∫Âèä‰∏™‰∫∫Êï∞ÊçÆÊ£ÄÊµãÊñπÊ≥ïÁ≠âÊòØ‰∏Ä‰∫õÂ∏∏ËßÅÁöÑÁ≠ñÁï•Ôºå‰ΩÜÂú®AIÂØπÁ§æ‰ºöÁöÑÂ•ΩÂ§Ñ‰ª•Âèä‰ªª‰ΩïÁé∞ÊúâÊàñÂç≥Â∞ÜÂá∫Âè∞ÁöÑÊîøÂ∫úÊ≥ïËßÑÁöÑËÉåÊôØ‰∏ãÔºåÁ§æ‰ºöÂΩ±ÂìçÊòØ‰∏Ä‰∏™Êõ¥Â§ßÁöÑÈóÆÈ¢ò„ÄÇ
- en: Generalization and creativity
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ê≥õÂåñ‰∏éÂàõÈÄ†Âäõ
- en: One of the big problems with these generative AI models is that their generalization
    ability turns out to be very poor. More concretely, they seldom generate content
    that is strikingly different from the training data. That is, they are brilliant
    at copying the repeating patterns but fail really to create something original
    or novel. As a consequence, their potential for capital *C* creativity stays very
    limited.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Ëøô‰∫õÁîüÊàêÂºèAIÊ®°ÂûãÁöÑ‰∏Ä‰∏™Â§ßÈóÆÈ¢òÊòØÂÆÉ‰ª¨ÁöÑÊ≥õÂåñËÉΩÂäõÈùûÂ∏∏Â∑Æ„ÄÇÊõ¥ÂÖ∑‰ΩìÂú∞ËØ¥ÔºåÂÆÉ‰ª¨ÂæàÂ∞ëÁîüÊàê‰∏éËÆ≠ÁªÉÊï∞ÊçÆÊòæËëó‰∏çÂêåÁöÑÂÜÖÂÆπ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂÆÉ‰ª¨ÊìÖÈïøÂ§çÂà∂ÈáçÂ§çÁöÑÊ®°ÂºèÔºå‰ΩÜÁúüÊ≠£ÂàõÈÄ†ÂéüÂàõÊàñÊñ∞È¢ñÁöÑ‰∏úË•øÁöÑËÉΩÂäõÈùûÂ∏∏ÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÂÆÉ‰ª¨Âú®ËµÑÊú¨CÂàõÈÄ†ÂäõÊñπÈù¢ÁöÑÊΩúÂäõÈùûÂ∏∏ÊúâÈôê„ÄÇ
- en: As generative AI continues to evolve in novel ways, it is bound to introduce
    novel challenges, as we are witnessing the barrage of new research and efforts
    to ensure sensible and responsible use of this technology.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ÈöèÁùÄÁîüÊàêÂºèAI‰ª•Êñ∞È¢ñÁöÑÊñπÂºè‰∏çÊñ≠ËøõÂåñÔºåÂÆÉÂøÖÁÑ∂‰ºöÂ∏¶Êù•Êñ∞ÁöÑÊåëÊàòÔºåÊ≠£Â¶ÇÊàë‰ª¨Ê≠£Âú®ËßÅËØÅÁöÑÊñ∞Á†îÁ©∂ÂíåÂä™ÂäõÔºå‰ª•Á°Æ‰øùËØ•ÊäÄÊúØÁöÑÂêàÁêÜÂíåË¥üË¥£‰ªªÁöÑ‰ΩøÁî®„ÄÇ
- en: Summary
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ÊëòË¶Å
- en: Generative AI is a rather rapidly growing area, having huge disruptive potential
    for industries and changing areas of our lives. In contrast, applications of generative
    AI include very realistic image generation and generation of text, accelerated
    drug discovery, and enriched creative expression.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ÁîüÊàêÂºèAIÊòØ‰∏Ä‰∏™ÂèëÂ±ïÁõ∏ÂΩìËøÖÈÄüÁöÑÈ¢ÜÂüüÔºåÂØπË°å‰∏öÂíåÊàë‰ª¨ÁöÑÁîüÊ¥ªÁöÑËÆ∏Â§öÊñπÈù¢ÂÖ∑ÊúâÂ∑®Â§ßÁöÑÈ¢†Ë¶ÜÊÄßÊΩúÂäõ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÁîüÊàêÂºèAIÁöÑÂ∫îÁî®ÂåÖÊã¨ÈùûÂ∏∏ÈÄºÁúüÁöÑÂõæÂÉèÁîüÊàêÂíåÊñáÊú¨ÁîüÊàê„ÄÅÂä†ÈÄüËçØÁâ©ÂèëÁé∞‰ª•Âèä‰∏∞ÂØåÁöÑÂàõÊÑèË°®Ëææ„ÄÇ
- en: One of the key points regarding this is an understanding of the different generative
    models, such as VAEs, GANs, and autoregressive models, that provide insight into
    how technologies work and where they can be applied. It would also, however, be
    important to state the many problems and limitations generative AI faces, including
    data quality, computational resources, ethical considerations, and even creativity.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ÂÖ≥‰∫éËøô‰∏ÄÁÇπÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÁÇπÊòØÁêÜËß£‰∏çÂêåÁöÑÁîüÊàêÊ®°ÂûãÔºåÂ¶ÇVAEs„ÄÅGANsÂíåËá™ÂõûÂΩíÊ®°ÂûãÔºåËøô‰∫õÊ®°ÂûãÂèØ‰ª•Êèê‰æõÂØπÊäÄÊúØÂ¶Ç‰ΩïÂ∑•‰Ωú‰ª•ÂèäÂÆÉ‰ª¨ÂèØ‰ª•Â∫îÁî®Âú®Âì™‰∫õÊñπÈù¢ÁöÑËßÅËß£„ÄÇÁÑ∂ËÄåÔºåÊåáÂá∫ÁîüÊàêÂºèAIÈù¢‰∏¥ÁöÑËÆ∏Â§öÈóÆÈ¢òÂíåÂ±ÄÈôêÊÄß‰πüÂæàÈáçË¶ÅÔºåÂåÖÊã¨Êï∞ÊçÆË¥®Èáè„ÄÅËÆ°ÁÆóËµÑÊ∫ê„ÄÅ‰º¶ÁêÜËÄÉËôëÔºåÁîöËá≥ÂàõÈÄ†Âäõ„ÄÇ
- en: In the next chapter, we will learn about the principles of agentic systems,
    which include the concepts of agency and autonomy, the characteristics of intelligent
    agents, various architectures of intelligent systems, and multi-agent systems.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI models can only take text data as input. True or false?
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the different types of generative AI models?
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the ethical and social implications of generative AI?
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the methods to mitigate bias in training data?
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some of the text and content generation open source LLMs?
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: False. Generative AI models can take text as well as image, video, and audio
    data as inputs.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VAEs, GANs, and autoregressive models.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deepfakes, misinformation, issues with copyright or intellectual property, and
    job displacements are some of the social and ethical implications of generative
    AI.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Some of the common methods to address bias in training data are oversampling
    or undersampling.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mistral, LLaMA, and Bloom are some of the open source text and content generation
    LLMs.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Mastering Machine Learning Algorithms ‚Äì Second Edition* by Giuseppe Bonaccorso'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Machine Learning for Imbalanced Data* by Kumar Abhishek and Dr. Mounir Abdelaziz'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Generative AI with Python and TensorFlow 2* by Joseph Babcock and Raghav Bali'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Auto-Encoding Variational* *Bayes* : [https://arxiv.org/abs/1312.6114](https://arxiv.org/abs/1312.6114)'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*beta-VAE: Learning Basic Visual Concepts with a Constrained Variational* *Framework*
    : [https://openreview.net/forum?id=Sy2fzU9gl](https://openreview.net/forum?id=Sy2fzU9gl)'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Learning Structured Output Representation using Deep Conditional Generative*
    *Models* : [https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html](https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html)'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Generative Adversarial* *Networks* : [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Unsupervised Representation Learning with Deep Convolutional Generative Adversarial*
    *Networks* : [https://arxiv.org/abs/1511.06434](https://arxiv.org/abs/1511.06434)'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Wasserstein* *GAN* : [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A Style-Based Generator Architecture for Generative Adversarial* *Networks*
    : [https://ieeexplore.ieee.org/document/8953766](https://ieeexplore.ieee.org/document/8953766)'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Attention Is All You* *Need* : [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Conditional Image Generation with PixelCNN* *Decoders* : [https://arxiv.org/abs/1606.05328](https://arxiv.org/abs/1606.05328)'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*PixelSNAIL: An Improved Autoregressive Generative* *Model* : [https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model](https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model)'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Language Models are Few-Shot* *Learners* : [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*GPT-4 Technical* *Report* : [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*BERT: Pre-training of Deep Bidirectional Transformers for Language* *Understanding*
    : [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Exploring the Limits of Transfer Learning with a Unified Text-to-Text* *Transformer*
    : [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683)'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Scalable Extraction of Training Data from (Production) Language* *Models*
    : [https://arxiv.org/abs/2311.17035](https://arxiv.org/abs/2311.17035)'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our communities on Discord and Reddit
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](https://packt.link/I1tSU)
    and our Reddit channel at [https://packt.link/ugMW0](https://packt.link/ugMW0)
    to connect, share, and collaborate with like-minded enthusiasts.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '![img](img/B31483_Discord_QR_new.jpg)![img](img/qrcode_Reddit_Channel.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
