- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Identifying Generative AI Use Cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed how the use case exploration and proof
    of concept development process has shifted with the emergence of **large language
    models** (**LLMs**). Specifically, the ability for rapid experimentation with
    LLMs has led teams to favor an experimental approach over more traditional requirements
    analysis and design processes.
  prefs: []
  type: TYPE_NORMAL
- en: With LLMs, use cases can quickly be tested by creating prompts that demonstrate
    potential capabilities. This allows for greater flexibility and speed than meticulously
    mapping detailed requirements upfront. Of course, once promising use cases are
    identified, more rigorous analysis is highly recommended. Additionally, security,
    monitoring, and governance of production systems remain critical components.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss an approach to identify promising use cases
    to explore with LLMs. We categorize use cases based on how an application interacts
    with the LLM. This provides a framework to think through the breadth of possibilities
    as well as the unique considerations for implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: When to consider **Generative AI** (**GenAI**) as a tool to integrate into your
    application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Realizing business value through GenAI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to identify GenAI business use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The difference between Comprehensive and Generative use cases along with detailed
    examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to consider generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have been exploring, one of the powers of GenAI is the ability to automatically
    generate responses without being explicitly trained on it. Rather than just executing
    predefined tasks, LLMs can infer responses by drawing on their contextual understanding
    and knowledge. This aspect of emergent reasoning unlocks unique opportunities
    for rapid experimentation and iterative refinement of novel use cases.
  prefs: []
  type: TYPE_NORMAL
- en: When considering potential applications for GenAI, the first evaluation criterion
    centers on comprehension-based tasks. Sentiment analysis, content classification,
    intent classification, relationship extraction, summarization, and more all leverage
    innate language understanding. Developers can formulate prompts aligning to use
    cases that interpret, organize, or infer meaning. To unlock the full potential
    of LLMs, developers will iterate on these given prompts through thoughtful “prompt
    engineering.” Prompt engineering attempts to optimize LLM responses by providing
    task-specific input text that guides a model toward the desired output.
  prefs: []
  type: TYPE_NORMAL
- en: However, purely numerical analysis may not be the best initial fit for GenAI.
    While mathematical reasoning exists within models, large volumes of statistical
    data processing are better suited for traditional programmatic algorithms and
    predictive AI. Of course, GenAI could help describe insights from numeric analysis
    – communicating trends in natural language, for example, or creating queries from
    natural language. But we wouldn’t expect strong performance by running regression
    analysis or optimization from prompts alone.
  prefs: []
  type: TYPE_NORMAL
- en: Along these lines, one of the earliest discoveries around the limitations of
    LLMs surfaced in mathematical reasoning. Users experimenting with prompts that
    involved numeric calculations or comparisons found nonsensical outputs. The models
    would produce response text that sounded coherent but lacked any grounding in
    basic arithmetic principles. This disconnect highlights the risk of hallucinations
    – responses that have fluent language but little accuracy or logical consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Researchers formulated that the enormous parameter spaces of LLMs allow them
    to optimize textual cohesion while lacking the tighter constraints of symbolic
    logic found in math. Without specifically encoding numeric logic, the models “hallucinate”
    plausible-sounding numeric reasoning that mathematically makes little sense. The
    outputs expose both the power of language fluency and the risk of generalizing
    beyond the actual knowledge limitations of models.
  prefs: []
  type: TYPE_NORMAL
- en: As we dive deeper into use cases in this book, we encourage you to brainstorm
    opportunities aligned with the strengths provided by language understanding tools.
  prefs: []
  type: TYPE_NORMAL
- en: The goal is to match high-value challenges around language, content, and reasoning
    with the emergent capabilities of LLMs. We will evaluate where modern AI could
    augment human workflow – is there a comprehension component that bogs us down?
    Could prompts help classify, summarize, suggest, or predict within those contexts?
    And finally, we will factor in how the outputs generated by LLMs could evolve
    from experimental prompting into a refined API-driven solution.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to remark one more time on the importance of business alignment.
    When emerging technologies garner tremendous hype and media attention, organizations
    face the tendency to rush to deploy “shiny new toys” without clearly defining
    the value they will drive for a business. GenAI risks this same dynamic, given
    the incredible mainstream breakout prompted by chatbots like ChatGPT. Executives
    clamor to stake their claim in using these powerful technological advances to
    future-proof competitiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, treating AI as an end solution rather than an ingredient to enhance
    solutions often leads to failure. Well-intentioned teams demo flashy prototype
    capabilities that fail to map into tangible business challenges or workflows.
    Progress stalls beyond experiments in isolation. Funding dries up without demonstrating
    a real-world impact. Even worse, poorly planned AI integration risks harming the
    customer experience or market position. Conversely, focusing on use cases with
    clear business value upfront fosters successful AI implementations, leading to
    a positive business impact while driving innovation and maximizing the return
    on investment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22175_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: “The Symphony of Data and Imagination” – a generated image to illustrate
    generative AI vs Predictive AI'
  prefs: []
  type: TYPE_NORMAL
- en: Realizing business value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When assessing opportunities to solve business problems with GenAI, it’s critical
    that we analyze potential value in business terms – how does this technology shift
    affect structures, efficiency, competitive positioning, or revenue opportunities
    in an organization? Merely showcasing sophisticated technical capabilities alone
    is not enough to show value, as it lacks strategic rigor. Proposed projects should
    directly address tangible problems or sources of organizational leverage.
  prefs: []
  type: TYPE_NORMAL
- en: As thought leaders seeking executive buy-in, we need to develop skills and methodologies
    that translate potential productivity gains into compelling business cases, clarifying
    the return on investment. Specifically, constructing cost avoidance models resonates
    with executives focused on operational efficiencies and margins.
  prefs: []
  type: TYPE_NORMAL
- en: Quantifying assumptions in terms that the business can understand and measure
    is an essential step to a successful integration of GenAI into your applications.
    What are the current costs for manual processes targeted for automation? How many
    labor hours or **full-time employees** (**FTEs**) are dedicated to inefficient
    areas? How might throughput scale with AI augmentation? What expenses link to
    quality defects or customer friction pain points?
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding and extracting metrics to translate into data-driven projections
    is key. Gathering baseline measurements around the current state of business operations
    sets the foundation to showcase future improvements. Potential vectors to quantify
    gains across use cases include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cost savings**: Hours recovered through automation and scalability, and error
    and rework reduction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Revenue increments**: Improved and increased customer lifetime value from
    engagement and satisfaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quality improvements**: Reduced error rates and higher review scores, measuring
    customers’ willingness to recommend.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Employee experience**: Internal surveys on satisfaction, productivity, and
    meaningful and engaging work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The goal is framing a business case in executive-friendly models that also enable
    the tracking of real-world impact versus projections. Building analytical muscle
    and intuition to translate AI advances into operational and financial outcomes
    takes some skill development, but it pays off through better alignment across
    teams.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s think of an example of a content tagging use case. Manually assigning
    metadata to documents puts a strain on human reviewers attempting volume at scale.
    Mistakes occur, inconsistencies pop in, and data attrition occurs – chaos. But
    perhaps a **natural language processing** (**NLP**) pipeline could help automate
    tagging to boost throughput dramatically while lowering costs. This pipeline then
    becomes an enabler for human reviewers to scale at a faster pace, allowing them
    to focus on reviewing rather than creating.
  prefs: []
  type: TYPE_NORMAL
- en: A revenue generating use case might focus more on using those rich tagged corpora
    as training data for client recommendations and understanding buying signals in
    a given market. Competitively, rich catalog search and personalization at scale
    differentiate against slower-moving players that only produce static signals.
    So, smart framing of use cases ties directly into strategic priorities, painting
    a compelling vision of market leadership.
  prefs: []
  type: TYPE_NORMAL
- en: The antidote to picking between efficiency gains and revenue regenerating use
    cases requires framing every potential AI application in terms of specific business
    value drivers first and enabling technologies second. What key objectives around
    cost, efficiency, differentiation, or revenue might we use? Where do humans currently
    struggle with workload, subjectivity, or availability? Do processes fail to scale
    sufficiently because of volume or complexity? Anchoring use cases firmly around
    moving these business needs provides the appropriate context to responsibly hone
    where and how GenAI can help. Avoid the instinct to create problems and find tools
    to fix them. Thoroughly map problems and then find the tools to fix them.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, GenAI represents ingredients that enable business capabilities rather
    than an end solution itself. We must thoughtfully apply technology to priority
    challenges or opportunities. If the **return on investment** (**ROI**) in applying
    GenAI feels tenuous or the business value generated is too small, broader thinking
    is likely required before further investment.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying Generative AI use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we evaluate potential applications for GenAI, two overarching categories
    emerge – **comprehension applications** and **generative applications**. By distinguishing
    use cases along this spectrum of understanding existing data vs synthesizing new
    artifacts, we can better match capabilities to appropriate business challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Comprehension applications cover processing tasks applied to analyze and structure
    knowledge from existing content. This includes sentiment analysis, relationship
    extraction, intent classification, summarization, and more. The key focus areas
    center around interpreting, organizing, and tagging data to be used by subsequent
    systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sources like chat history, customer tickets, and product catalogs yield richer
    insights when machine learning models classify topics, normalize entities, and
    summarize concepts at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Generative applications move beyond pure comprehension applications to creatively
    synthesize new artifacts like text, images, or multimedia. Use cases range from
    content drafting and ideation to conversational interfaces. With the right prompts
    and fine-tuning, LLMs can produce natural language, code, visual designs, and
    more for specific domains. Outputs integrate with customer-facing solutions or
    augment human workflows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blending both categories, we find an incredible opportunity in hybrid human-AI
    collaboration. Humans contextualize business objectives, provide critical oversight,
    and handle exceptions. AI automates high-volume tasks while sending signals for
    people to interpret. For example, generative writing aids content creators through
    initial drafting while expert editors finalize the content.
  prefs: []
  type: TYPE_NORMAL
- en: By organizing use cases into comprehension and generative buckets, we can better
    map capabilities to potential applications based on desired outcomes. Comprehension-focused
    use cases center around deriving insights from existing data. Generative use cases
    create novel artifacts by building on learned patterns. Both transform workflows
    when applied thoughtfully, upholding responsibilities around monitoring, ethics,
    and team augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: With recent advances in multimodal models that understand connections across
    images, text, and other data types, new dimensions of AI use cases are surfacing.
    Google’s Gemini model (see the paper at [https://arxiv.org/abs/2312.11805](https://arxiv.org/abs/2312.11805))
    combines comprehension applications across visual, textual, mathematical, and
    even code concepts within a unified underlying architecture.
  prefs: []
  type: TYPE_NORMAL
- en: This multi-modal foundation enables Gemini to not only interpret multimodal
    information but also generate novel artifacts like images from text prompts, and
    vice versa. For comprehension applications, this offers intriguing use cases related
    to visually summarizing documents, generating images from written narratives to
    visually interpret concepts, and enhancing images based on descriptive captions.
    The generative application possibilities include ideating creative images, designs,
    and data visualizations tailored to specific conceptual directions. This aligns
    with the hybrid human/AI collaboration model.
  prefs: []
  type: TYPE_NORMAL
- en: Images, video, and voice media types introduce yet another set of rich content
    that multimodal models are becoming very good at processing and understanding
    to perform generative tasks. The comprehension of scenes, objects, speech, and
    overlaid text within videos enhances applications like search, recommendation,
    and content moderation.
  prefs: []
  type: TYPE_NORMAL
- en: Other practical examples include extracting text from images and videos, generating
    new content within video frames or images, and even creating comprehensive summaries
    describing the contents of rich media content. As with other AI advances, responsible
    oversight remains critical as multimodal models start permeating workflows. Continued
    monitoring, ethical implementation, and human judgment help steer us toward beneficial
    outcomes as this technology unlocks new potential. But by connecting media like
    images, text, and sound, models such as Gemini pave the way for the next generation
    of intelligent applications, augmented with a deeper understanding across multiple
    dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Potential business-focused use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When exploring opportunities to apply GenAI, continuously evaluate any potential
    business value first rather than just the technical art of the possible. To spark
    ideas, the following list summarizes promising use cases organized by key value
    drivers. Consider cases where replicating human-quality comprehension or creation
    at a machine scale has a positive impact on workflows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cost and efficiency gains:'
  prefs: []
  type: TYPE_NORMAL
- en: Automate high-volume/repetitive tasks. Here, your business **key performance
    indicator** (**KPI**) can be an automation rate, measured as a percentage of automated
    tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accelerate content development, enabling hybrid human/AI collaboration. Here,
    your business KPI can be an increase in the number of hours saved compared to
    the current amount of time taken to create content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content evaluation to reduce errors and rework. Here, your business KPI can
    be the delta in the number of tickets filed to update incorrect content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Personalize and tailor recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate consistent omnichannel experiences by leveraging image/text generation.
    Here, your business KPI could be an existing engagement metric such as “time spent
    on a platform,” or the click-through rate on a given section of your application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate contextual cues to guide users and improve product documentation. Here,
    your business KPI can be the engagement of your customers with your documentation,
    which can be measured as page views.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate operational insights to enhance risk reduction. Here, your business
    KPI could be the delta on risk assessments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enhance and scale human interaction:'
  prefs: []
  type: TYPE_NORMAL
- en: Provide overview summaries from documents. Here, your business KPI could be
    an existing engagement metric such as “time spent on a platform,” or the click-through
    rate on a given section of your application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecast emerging issues and trends. Here, your business KPI could be the predictive
    power of your application as it relates to saving costs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborate for innovation and gain competitive advantage. Here, your business
    KPI could be an existing engagement metric such as “time spent on platform,” or
    the click-through rate on a given section of your application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22175_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: “Brainstorming Buddies” image generated by AI'
  prefs: []
  type: TYPE_NORMAL
- en: This framing of use cases aligned to core business priorities keeps implementation
    closely bound to driving real outcomes, rather than deploying technology for its
    own sake. Many possibilities abound at the intersection of business needs and
    AI capabilities, but maintaining this value-centric focus ensures the responsible
    application of AI, guiding teams toward beneficial innovation and transformation.
  prefs: []
  type: TYPE_NORMAL
- en: Comprehension use cases harness the power of natural language understanding
    to extract insights and structured information from unstructured data. These techniques
    enable organizations to gain valuable insights, improve discoverability, and facilitate
    knowledge rediscovery and reuse, ultimately driving better decision-making and
    enhancing operational efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a non-exhaustive list of technically focused comprehension
    use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sentiment analysis**: Sentiment analysis leverages natural language understanding
    to automatically classify the emotional tone within textual content, like customer
    feedback, surveys, and social media posts. This allows organizations to identify
    pain points and perceptions without a large-scale manual review. Common integration
    strategies include sentiment API queries or batch processing analytics aggregated
    into reporting dashboards. This use case focuses on understanding how customers
    perceive your business and identifying improvement opportunities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Document summarization**: Document summarization uses AI to automatically
    create condensed snippets of text, bringing key details within lengthy corpora,
    like wikis, research papers, and knowledge base articles, to the surface. This
    improves discoverability for users who can quickly determine the relevance of
    a piece of text before deciding to read full documents. It also enables new modes
    of documents interaction and searchability, especially across massive repositories.
    This use case focuses on increasing productivity across the board.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metadata extraction**: Metadata extraction harnesses natural language understanding
    to identify and extract key information attributes from unstructured textual content.
    This includes entities like people, places, and companies, as well as topics,
    concepts, tone, and relationships. Structured metadata makes understanding documents
    and content much easier at scale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases range from processing volumes of contracts to auto-tagging with counterparties,
    obligations, dates, or risk levels. Support ticket classification with topics,
    priority status, and location can route cases correctly while pinpointing macro
    trends. Aggregating research publications within a field by the concepts and techniques
    mentioned builds network maps for emerging schools of thought and impact tracking.
    Publishing platforms can even auto-suggest high-performance article tags to analyze
    headline semantics and document summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Metadata extraction enables knowledge rediscovery and reuse in large organizations.
    For example, employees can quickly search on past meeting notes, referencing to
    key projects details versus leveraging siloed, fragmented data stores.
  prefs: []
  type: TYPE_NORMAL
- en: New team members can get up to speed, discovering pivotal documents from intelligent
    graphs rather than performing aimless word searches. Over time, signal-to-noise
    ratios improve as AI augments institutions’ contextual understanding of their
    information universe, based on this actionable metadata layer.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, generative use cases leverage GenAIs ability to generate human-like
    outputs, tailored to specific needs and contexts. These applications not only
    streamline repetitive tasks but also open new avenues for personalized experiences,
    enhanced creativity, and accelerated innovation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a non-exhaustive list of technically focused generative use
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Conversational interfaces**: Conversational interfaces allow natural dialogue
    between end users and intelligent assistants via chat, voice, and, potentially,
    **augmented reality** (**AR**). These fluid experiences provide answers, recommendations,
    and next-step suggestions, reducing the need to navigate complex apps or menus.
    Over time, contextual awareness of user goals and preferences enables personalized
    guidance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data visualization**: Data visualization uses GenAI to automatically create
    relevant charts, graphs, and diagrams, tailored to provided datasets. Beyond basic
    types like histograms or pie charts, advanced visualizations including interactive
    infographics, animated data stories, and tailored dashboard layouts personalized
    to the consumption use case, bring key trends to light.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Report automation**: Report automation generates personalized, dynamic summaries
    of the most salient business insights for specific user needs. Rather than static,
    template-driven reports, generative capabilities allow unique views, sending key
    signals from centralized data assets. Automated analysis identifies arising issues,
    while customizable layouts deliver the tailored briefings that different business
    leaders require.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code generation**: The recent integration of LLMs into coding workflows presents
    a fascinating avenue for enhanced productivity and creative exploration. LLMs
    are transforming the way developers approach code creation. By translating natural
    language instructions into functional code snippets, LLMs can act as intelligent
    assistants, suggesting alternative solutions, streamlining repetitive tasks, and
    filling in knowledge gaps. However, it’s crucial to remember that LLMs are not
    a replacement for core coding expertise. Their proficiency lies in augmenting
    human capabilities, not supplanting them. The true potential lies in the collaborative
    synergy between human ingenuity and the immense creative potential unlocked by
    LLMs. As this technology matures, we can expect to see even more impactful applications
    emerge, shaping the future of software development and innovation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content generation**: Leveraging the raw generative power of LLMs, organizations
    now have new capabilities to automatically draft written content, tailored to
    specific guidelines, topics, voices, and creative directions. The main opportunities
    relate to marketing, communications, and documentation needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22175_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: “The art of code” generated by AI'
  prefs: []
  type: TYPE_NORMAL
- en: For email campaigns, GenAI can synthesize initial drafts of messages customized
    to different subscriber segments, based on past high-performing templates and
    new product/event announcements. Marketing teams set the inputs and creative direction,
    while machines handle much of the repetitive composition work at scale. Humans
    then refine, incorporate personalization, and approve final versions.
  prefs: []
  type: TYPE_NORMAL
- en: Similar applications empower the creation of blog posts, social media captions,
    landing pages, and more to match brand style guides, while saving teams hours
    of effort. Responsible generative writing augments the creative process, rather
    than fully automating rote templated content.
  prefs: []
  type: TYPE_NORMAL
- en: On the technical documentation front, AI holds promise in accelerating knowledge
    capture and transfer. Subject matter experts could speak aloud detailing processes,
    software capabilities, or manufacturing equipment operations. Automatic speech-to-text,
    translation, and transcript summarization would distill key facts and workflows
    into shareable references.
  prefs: []
  type: TYPE_NORMAL
- en: Editors would polish the final documentation, but **subject matter experts**
    (**SMEs**) would avoid hours of manually documenting procedures from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Content generation use cases introduce the fantastic potential to augment human
    creativity, expertise, and judgment, not replace it. Automating rote composition
    alleviates writing fatigue while providing starting points to incorporate huge
    learned patterns. The people element guides objectives, allows nuance, and establishes
    model limitations. Together, content creation processes achieve new scales, responsiveness,
    and personalization, powered by AI collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI deployment and hosting options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we consider which types of use cases we are looking to pursue to provide
    business value, we must consider the infrastructure on which we will deploy and
    host our systems. With the new normal of leveraging cloud resources, we tend to
    assume that capacity is not a concern anymore, but is this right? Let’s dissect
    this thought – is the biggest model the right solution for all use cases? Realistically
    speaking, LLMs are nice and easy to test and get initial results, but when considering
    scale and productionalization, they are not as appealing as you would think. Some
    of the limitations are GPU availability, cost, and latency. This realization is
    steering the market into more specialized smaller models that solve a specific
    use case.
  prefs: []
  type: TYPE_NORMAL
- en: Designing product architecture for LLMs requires careful consideration of several
    factors. Cost optimization strategies like Mixture-of-Depths can be employed to
    dynamically allocate resources for transformer-based models, maximizing efficiency.
    Cloud infrastructure should be designed for scalability, leveraging services that
    automatically adjust capacity based on demand. Security is paramount, and enterprise-grade
    controls are essential to protect sensitive data and prevent unauthorized access.
    Additionally, robust testing frameworks like Giskard are crucial to ensure LLM
    applications function as intended and mitigate potential risks. Giskard offers
    open-source evaluation tools and even a course from DeepLearning.ai on red-teaming
    LLM applications, providing valuable resources for comprehensive testing and security
    assessment.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume your use case requires a large model that needs to perform multiple
    tasks and accept multiple modalities of data inputs – text, images, and videos.
    In this case, the very first thing that should come to mind is leveraging a cloud-based
    hosted model that you can call through an API. A cloud-native, API-driven solution
    serving your inference requests enables you to offload some of the heavy-lifting
    tasks surrounding the underlying infrastructure, such as autoscaling, patching,
    and other maintenance tasks. Assuming the API meets all your **service level agreements**
    (**SLAs**) requirements, you can focus on the application logic around the inference
    requests, decreasing the time to market needed to bring your application online.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider another use case where you need to deploy a smaller, specialized
    model locally to a device, such as a personal assistant on a phone or a copilot
    model to provide developers with code suggestions in real time. In these “at the
    edge” use cases, sending each individual request to a hosted API may incur too
    much latency or have connectivity requirements that cannot be met. Here, packaging
    up a compact model trained on just the data and tasks relevant to the target domain
    can be the right approach. For example, an on-device personal assistant can have
    a conversational model fine-tuned on dialogue data to provide quick, low-latency
    responses without needing an internet connection. Similarly, a coding assistant
    model can be streamlined to focus on providing relevant code completions and suggestions
    as a developer types, by learning from a code base representative of its intended
    programming languages and environments.
  prefs: []
  type: TYPE_NORMAL
- en: In situations where responsiveness and being self-contained are critical, targeting
    model development and optimization specifically for edge deployment can enable
    the advanced AI capabilities that users expect, even with intermittent connectivity
    and computational constraints. The key is to understand both the use case requirements
    and the inference environment upfront, determining the right balance of edge versus
    cloud for a given solution.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explored the intricacies of evaluating potential use cases for
    GenAI, equipping you with the tools to discern optimal applications for this transformative
    technology. By examining different viewpoints and criteria, we’ve established
    a framework to determine whether a given use case aligns with GenAI’s strengths
    and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key takeaways are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: At the heart of every successful GenAI implementation lies clear and demonstrable
    business value. Ask yourself how GenAI will directly enhance your current operations,
    unlock new revenue streams, or improve customer experience. Without a tangible
    benefit, the technology itself holds little merit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We identified two broad categories of use cases where GenAI shines: comprehension
    and generation. Comprehension focuses on analyzing and extracting meaning from
    data, while generation leverages that understanding to produce entirely new content.
    Consider which category your use case falls under to assess GenAI’s suitability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explored two main ways to host GenAI models – cloud APIs and optimized edge
    deployment. Cloud APIs are great for scalability but can have latency and connectivity
    limitations. Edge deployment works for low-latency situations like on-device assistants,
    but it requires more compact, specialized models. Assess your use case constraints
    and requirements first, striking the right balance between the cloud and edge
    when leveraging generative AI capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we will dive into a framework that will help approach the
    task of integrating GenAI into applications.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genpat](Chapter_02.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code134841911667913109.png)'
  prefs: []
  type: TYPE_IMG
