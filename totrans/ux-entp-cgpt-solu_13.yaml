- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Monitoring and Evaluation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控与评估
- en: Once there is something to test, even a trial version, be on top of the processes
    for evaluating the results. Unsurprisingly, the methods discussed (surveys, interviews,
    feedback) can be re-used to see how beta customers or early adopters perform.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦有东西可以测试，即使是试用版，也要密切关注评估结果的过程。不出所料，讨论的方法（调查、访谈、反馈）可以重新使用，以查看beta客户或早期采用者的表现。
- en: Another Pet Peeve
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个烦恼
- en: The word *beta* sends the wrong message to a non-technical customer that the
    product is not ready for them. Consider other terms such as limited release or,
    my favorite, *access for early adopters*. This label might put them in a better
    frame of mind to handle issues and provide feedback.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: “*beta*”这个词会给非技术客户传递错误的信息，让他们觉得产品对他们来说还不成熟。考虑其他术语，比如限量发布，或者我最喜欢的，“*早期采用者访问权*”。这个标签可能会让他们以更好的心态处理问题并提供反馈。
- en: Since **retrieval-augmented generation** (**RAG**) is fundamental to most enterprise
    solutions for sales and support, metrics around the quality of that approach are
    essential. A combination of data science, product managers, and the design team
    is required to improve results. A heuristic approach using design experts or trained
    individuals can evaluate RAG or other LLM outputs that provide results to customers.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于**检索增强生成**（**RAG**）是大多数销售和支持企业解决方案的基础，因此该方法的质最指标至关重要。需要数据科学、产品经理和设计团队的组合来提高结果。使用设计专家或受过训练的个人采用启发式方法可以评估RAG或其他LLM输出，这些输出向客户提供结果。
- en: 'This means a suite of additional methods are available to choose from, but
    honestly, all of these methods should be applied:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着有一套额外的可用方法可供选择，但说实话，所有这些方法都应该被应用：
- en: Evaluate using **retrieval-augmented generation** **assessment** (**RAGAs**)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**检索增强生成** **评估**（**RAGAs**）进行评估
- en: Monitor with usability measures
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用可用性指标进行监控
- en: Refine with a heuristic evaluation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用启发式评估进行细化
- en: Let’s jump right into metrics to benchmark LLM solutions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接进入指标，以基准测试LLM解决方案。
- en: Evaluate using RAGAs
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RAGAs进行评估
- en: This book is about design, so product people are not expected to implement the
    **RAGAs**. RAGAs is a framework for evaluating the RAG pipeline. *Any approach
    that takes test data, is actually used, and can measure quality reliably is fine
    with me*. RAGAs is popular with the AI community, so it is worth covering. Call
    on product experts to evaluate results to validate findings. The goal is to understand
    the metrics and make decisions to deliver model improvements.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是关于设计的，所以不期望产品人员实施**RAGAs**。RAGAs是一个评估RAG管道的框架。*任何采用测试数据、实际使用并能可靠测量质量的方案对我来说都是可行的*。RAGAs在AI社区中很受欢迎，因此值得介绍。召集产品专家评估结果以验证发现。目标是理解指标并做出决策以提供模型改进。
- en: The RAGAs process
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAGAs流程
- en: All good stories start at the beginning. An LLM product needs to be evaluated.
    Don’t wait for customers to complain; it comes too late, and customers disappear
    quickly if they are frustrated with quality. This is similar to phone support;
    when a customer has a horrible interaction, they tend to tell 20 people how bad
    it was, and this lack of goodwill hurts the company’s reputation. If backend systems
    or recommenders miss their mark, it will leave a foul taste in customers’ mouths.
    By monitoring how the system is performing, there is a better chance for improvement.
    As Peter Drucker was quoted, “*You can’t improve what you* *don’t measure.*”
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有好的故事都是从开始讲起的。一个LLM产品需要被评估。不要等到客户抱怨；这来得太晚了，如果他们对质量感到沮丧，客户会很快消失。这类似于电话支持；当客户有一个糟糕的互动时，他们往往会告诉20个人有多糟糕，这种缺乏善意会损害公司的声誉。如果后端系统或推荐者没有达到目标，这会给客户留下不好的印象。通过监控系统性能，有更好的机会进行改进。正如彼得·德鲁克所说：“*你不能改善你*
    *没有衡量的*。””
- en: 'A collection of metrics can be deployed. Let’s lay out the steps for RAGAs:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可以部署一系列指标。让我们列出RAGAs的步骤：
- en: Synthetically create a diverse dataset for testing.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为测试合成一个多样化的数据集。
- en: Use these metrics to measure solution quality.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这些指标来衡量解决方案质量。
- en: Care for the application. Use smaller and cheaper models to generate actionable
    insights.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关注应用。使用更小、更便宜的模型来生成可操作见解。
- en: Feed these insights back to improve the overall experience.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些见解反馈回去以改善整体体验。
- en: This chapter will summarize RAGAs **metric-driven development** (**MDD**), a
    fancy name for what we have called care and feeding. Use data to drive actionable
    insights; too many failed projects occur because of this simple oversight.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将总结RAGAs的**指标驱动开发**（**MDD**），这是一个对我们所说的“关怀与培养”的别称。使用数据来驱动可操作的见解；太多失败的项目正是因为这个简单的疏忽。
- en: RAGAs identify problems from the user’s perspective; this will be covered in
    this chapter. The associated Discord channels for the always-to-arise technical
    issues are active. There is an online collection of RAGA-related videos and tutorials.
    If needed, here is the in-depth documentation on RAGAs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: RAGAs从用户的角度识别问题；这一点将在本章中介绍。始终出现的技术问题的相关Discord频道是活跃的。有一个在线的RAGA相关视频和教程集合。如果需要，这里有关于RAGAs的深入文档。
- en: 'Documentation: [Introduction to RAGAs](https://docs.ragas.io/en/latest/concepts/index.html)
    ([https://docs.ragas.io/en/latest/concepts/index.html](https://docs.ragas.io/en/latest/concepts/index.html))'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 文档：[RAGAs简介](https://docs.ragas.io/en/latest/concepts/index.html) ([https://docs.ragas.io/en/latest/concepts/index.html](https://docs.ragas.io/en/latest/concepts/index.html))
- en: Testing data (for the developers in the room)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据（针对在场的开发者）
- en: The more technically inclined readers can use the GitHub FAQ files. Install
    RAGAs with Python and get started. This is outside the book’s scope. The metrics
    covered in this chapter apply to a variety of similar approaches. Learn these
    standard metrics to evaluate LLM quality. Building RAGAs is not required to understand
    the metrics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 更技术倾向的读者可以使用GitHub FAQ文件。使用Python安装RAGAs并开始使用。这超出了本书的范围。本章涵盖的指标适用于各种类似的方法。学习这些标准指标以评估LLM质量。理解这些指标不需要构建RAGAs。
- en: 'Tutorial: [Installing RAGAs](https://docs.ragas.io/en/stable/getstarted/install.html)
    ([https://docs.ragas.io/en/stable/getstarted/install.html](https://docs.ragas.io/en/stable/getstarted/install.html))'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 教程：[安装RAGAs](https://docs.ragas.io/en/stable/getstarted/install.html) ([https://docs.ragas.io/en/stable/getstarted/install.html](https://docs.ragas.io/en/stable/getstarted/install.html))
- en: '[*Chapter 8*](B21964_08.xhtml#_idTextAnchor172)*, Fine-Tuning*, covered synthesizing
    data. Because the models need to be monitored, synthesizing data needs to go to
    the next level to expand the variety.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B21964_08.xhtml#_idTextAnchor172)*，微调*，涵盖了数据合成。由于模型需要监控，数据合成需要提升到下一个层次以扩展多样性。'
- en: Synthesizing data
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据合成
- en: 'Tools can create a variety of test data. The challenge with using the same
    model to generate samples is that test data from fine-tuned or prompt examples
    can be too close to validation examples. This was found in the experiment from
    [*Chapter 8*](B21964_08.xhtml#_idTextAnchor172)*, Fine Tuning*. Since LLMs like
    to predict the next word, output can be similar from one generation to the next.
    Samples won’t be as varied as the customer’s phrasing. Focusing on writing characteristics
    such as reasoning, conditioning, and multi-context can give a more comprehensive
    range of outputs and, thus, more robust tests. These advanced instructions get
    the LLM to vary output more broadly:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 工具可以创建各种测试数据。使用相同模型生成样本的挑战在于，微调或提示示例的测试数据可能过于接近验证示例。这在[*第8章*](B21964_08.xhtml#_idTextAnchor172)*，微调*的实验中得到了证实。由于LLM喜欢预测下一个单词，输出可能从一代到下一代相似。样本不会像客户的措辞那样多样化。关注推理、条件化和多上下文等写作特征可以提供更全面的输出范围，从而进行更稳健的测试。这些高级指令使LLM的输出更加多样化：
- en: '**Reasoning**: Write questions that require reasoning to provide an answer:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理**：编写需要推理来提供答案的问题：'
- en: How does photosynthesis work?
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 光合作用是如何工作的？
- en: 'Rewritten: What **consequences** can occur'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重新编写：可能发生**哪些后果**
- en: when you **disrupt the balance**
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当你**打破平衡**
- en: of photosynthesis in an **ecosystem**?
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**生态系统**中的光合作用？
- en: '**Conditioning**: Include conditional elements that add complexity:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件化**：包括增加复杂性的条件元素：'
- en: What strategies can improve sales performance?
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 哪些策略可以提高销售业绩？
- en: 'Rewritten: How do sales strategies differ based'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重新编写：销售策略如何根据
- en: on **factors such as target market demographics,**
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**目标市场人口统计等因素上**
- en: '**product complexity, and competitive landscape?**'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**产品复杂性和竞争格局**有何不同？'
- en: '**Multi-context**: Request diverse information to form an answer:'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多上下文**：请求多样化的信息来形成答案：'
- en: How does predictive maintenance
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 预测性维护
- en: benefit manufacturing operations?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助制造运营？
- en: 'Rewritten: How does **data analysis, machine**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 重新编写：**数据分析、机器**
- en: '**learning and teamwork** improve'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习和团队合作**提高'
- en: predictive maintenance in manufacturing?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 制造业中的预测性维护？
- en: '**Conversational**: Convert portions of questions into the back-and-forth expected
    in a chat question-and-answer solution:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话式**：将部分问题转换为聊天问答解决方案中预期的来回问答：'
- en: Hi, I need help resetting my password.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我需要帮助重置我的密码。
- en: Sure, I can help with that.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我可以帮您处理这个问题。
- en: Have you tried the 'Forgot Password'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您尝试过“忘记密码”吗？
- en: link on the sign-in page?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 登录页面上的链接？
- en: Yes, but I didn't get the reset email.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，但我没有收到重置电子邮件。
- en: Check your spam folder. Sometimes
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 检查您的垃圾邮件文件夹。有时
- en: the email ends up there.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件最终会出现在那里。
- en: This is done because humans are diverse, random, sometimes off-topic, humorous,
    lack a sense of humor, make typos, can ramble, write in multiple languages, be
    terse, or be verbose. It would be best to have diversity in any dataset. Look
    for this and demand it in the enterprise data. Keep these synthesizing techniques
    available to expand the breadth of test cases when gathering realistic examples
    falls short. For now, focus on the numbers. What metrics can measure and evaluate
    the state of a solution?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为人类是多样化的，随机的，有时会离题，幽默，缺乏幽默感，会犯拼写错误，会胡言乱语，会使用多种语言，会简洁或冗长。在任何数据集中都有多样性是最好的。在企业数据中寻找这一点并要求它。当收集现实示例不足时，请保持这些综合技术可用，以扩大测试用例的范围。现在，专注于数字。哪些指标可以衡量和评估解决方案的状态？
- en: Evaluation metrics
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'The center of all of this is the metrics. There are six to cover. The first
    four are around the model’s perspective, and the last two have a **user experience**
    (**UX**) feel:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些的中心是指标。有六个需要涵盖。前四个是围绕模型的角度，最后两个有**用户体验**（**UX**）的感觉：
- en: Faithfulness
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 忠实度
- en: Answer relevancy
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案相关性
- en: Context precision
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文精确度
- en: Context recall
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文回忆
- en: Context entity recall
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文实体回忆
- en: Summarization score
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摘要评分
- en: RAGA lays out the metrics in *Figure 10**.1*. This chart is also in the OpenAI
    demo (at the 20-minute mark), which will be covered next. Each concept requires
    an in-depth explanation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: RAGA在*图10*.1中概述了指标。这个图表也出现在OpenAI的演示中（20分钟处），接下来将进行介绍。每个概念都需要深入解释。
- en: '![](img/B21964_10_01.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21964_10_01.jpg)'
- en: Figure 10.1 – How to think about evaluating an LLM
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 如何思考评估一个LLM
- en: 'These concepts are worth internalizing to communicate clearly with developers
    and data scientists. There is a lot to unpack here with scoring, and it will be
    trickier still to translate scores into actionable tasks. This could have been
    a very technical chapter. To build a RAGAs testbed, do it independently. The value
    we focus on is understanding the metrics and how they apply. Even without RAGAs,
    the concept of model metrics applies to many solutions. The documentation examples
    are used to facilitate communication so that you can refer back to it or as updates
    become available:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概念值得内化，以便与开发人员和数据科学家进行清晰沟通。在这里有很多东西需要解释，包括评分，将评分转化为可执行的任务将更加困难。这本来可以是一个非常技术性的章节。为了构建RAGAs测试平台，请独立完成。我们关注的价值是理解指标及其应用。即使没有RAGAs，模型指标的概念也适用于许多解决方案。文档示例用于促进沟通，以便您可以参考它或当更新可用时：
- en: 'Article: [Evaluating the performance of RAG solutions](https://docs.ragas.io/en/latest/concepts/metrics/index.html)
    ([https://docs.ragas.io/en/latest/concepts/metrics/index.html](https://docs.ragas.io/en/latest/concepts/metrics/index.html))'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[评估RAG解决方案的性能](https://docs.ragas.io/en/latest/concepts/metrics/index.html)
    ([https://docs.ragas.io/en/latest/concepts/metrics/index.html](https://docs.ragas.io/en/latest/concepts/metrics/index.html))
- en: Math is scary
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数学很可怕
- en: Do not get caught up in the math. Focus on the value of the metric and get comfortable
    with the terms. Humans will not manually calculate these values. They are all
    done by the software. *If math is scary to you, ignore it. Learn* *the terms*.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 不要陷入数学。关注指标的价值并熟悉这些术语。人类不会手动计算这些值。所有这些都是由软件完成的。*如果你对数学感到害怕，忽略它。学习* *术语*。
- en: Faithfulness (for generation)
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 忠实度（对于生成）
- en: This is a measure of the generated answer’s factual accuracy. Can the answer
    be fact-checked (no fake news)?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是衡量生成答案事实准确性的指标。答案可以被事实核查（没有假新闻）吗？
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mi>a</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>f</mi><mi>u</mi><mi>l</mi><mi>n</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mfrac><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mrow><mo>|</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi>s</mi><mi>t</mi><mi>h</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>a</mi><mi>n</mi><mi>b</mi><mi>e</mi></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mi>i</mi><mi>n</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>f</mi><mi>r</mi><mi>o</mi><mi>m</mi><mi>g</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo>|</mo></mrow></mrow></mtd></mtr></mtable><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mrow><mo>|</mo><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi>s</mi></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mi>i</mi><mi>n</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>a</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mo>|</mo></mrow></mrow></mtd></mtr></mtable></mfrac></mrow></mrow></math>](img/5.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mi>a</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>f</mi><mi>u</mi><mi>l</mi><mi>n</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mfrac><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mrow><mo>|</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi}s</mi><mi>t</mi><mi>h</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>a</mi><mi>n</mi><mi>b</mi><mi>e</mi></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mi>i</mi><mi>n</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>f</mi><mi>r</mi><mi>o</mi><mi>m</mi><mi>g</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo>|</mo></mrow></mrow></mtd></mtr></mtable><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mrow><mo>|</mo><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi>s</mi></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mi>i</mi><mi>n</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>a</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mo>|</mo></mrow></mrow></mtd></mtr></mtable></mfrac></mrow></mrow></math>](img/5.png)'
- en: 'This means not hallucinating to give a faithful answer. If asked for someone’s
    birthday, it better be right. The more individual elements that can be fact-checked,
    the larger the numerator and denominator. Consider the following example:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着不要幻想以给出一个忠实于事实的答案。如果被问到某人的生日，它最好是正确的。可以核实的个体元素越多，分子和分母就越大。考虑以下例子：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is the calculation:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是计算过程：
- en: 'Break down the answer into individual statements and determine whether it can
    be inferred from the original context (take our word for this made-up store):'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将答案分解成单个陈述，并确定它是否可以从原始上下文中推断出来（请相信我们这个虚构的店铺）：
- en: The store is on Melrose (True)
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 店铺位于Melrose（正确）
- en: It is open 7 days a week (True)
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它每周7天开放（正确）
- en: It is open from 11 am to 9 pm (True)
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它从上午11点开放到晚上9点（正确）
- en: 'Calculate faithfulness:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算忠实度：
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:math>](img/6.png)'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:math>](img/6.png)'
- en: 'Let’s reuse the same example but with a slight change:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用相同的例子，但稍作改变：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is a calculation for an example with errors:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个有错误的例子计算：
- en: 'Break down the answer again:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次分解答案：
- en: The store is on Melvin Place (False)
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 店铺位于Melvin Place（错误）
- en: It is open 7 days a week (True)
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它每周7天开放（正确）
- en: It is open from 11 am to 9 pm (True)
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它从上午11点开放到晚上9点（正确）
- en: 'Calculate faithfulness:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算忠实度：
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.67</mml:mn></mml:math>](img/7.png)'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.67</mml:mn></mml:math>](img/7.png)'
- en: This judges the correctness of the original context. Knowing the right store
    is more relevant than the hours (store hours might overlap between a correct and
    wrong answer, so even if they are wrong, they might be right enough for the customer),
    but an address would be a total failure. Models are not smart. They don’t know
    the value of one of these elements (location) versus another (hours or days).
    If the faithfulness of an answer is low, it is hallucinating, and the answer should
    be rejected.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这判断原始上下文的正确性。知道正确的商店比小时数（正确和错误的答案之间的小时数可能重叠，所以即使它们是错误的，也可能足够好，以满足客户）更有相关性，但地址将完全失败。模型并不聪明。它们不知道这些元素（位置）相对于另一个元素（小时或天数）的价值。如果答案的忠实度低，它就是幻觉，应该拒绝这个答案。
- en: The trick is that although datasets with questions, context, and responses are
    publicly available, they lack enterprise content. A testing matrix based on answers
    with ground truth is necessary to monitor and judge changes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技巧在于，尽管包含问题、上下文和回答的数据集是公开可用的，但它们缺少企业内容。需要一个基于有正确答案的答案的测试矩阵来监控和判断变化。
- en: There are parameters one can manipulate to improve this metric and the other
    answer-related factors (relevancy, similarity, and correctness). Data scientists
    can play with these depending on the tools used. The model can also impact how
    much effort it will take to get to a better experience by reducing hallucinations
    and improving consistency. Judge out-of-the-box performance by monitoring LLM
    leaderboards. At the time of this writing, the OpenAI models are at or near the
    top of the Hughes leaderboard for evaluating models for hallucinations when summarizing
    a document. This is one example of a leaderboard. Remember, different models can
    be used for different components, so don’t focus only on ChatGPT when looking
    at the boards.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些参数可以调整以改进这个指标和其他与答案相关的因素（相关性、相似性和正确性）。数据科学家可以根据使用的工具进行操作。模型还可以通过减少幻觉并提高一致性来影响达到更好体验所需的努力。通过监控LLM排行榜来评估开箱即用的性能。在撰写本文时，OpenAI模型在评估总结文档时的幻觉方面位于或接近休斯排行榜的顶部。这是一个排行榜的例子。记住，不同的模型可以用于不同的组件，所以不要只关注ChatGPT在查看排行榜时。
- en: 'Article: [Hughes Hallucination Evaluation Model (HHEM) Leaderboard](https://huggingface.co/spaces/vectara/leaderboard)
    ([https://huggingface.co/spaces/vectara/leaderboard](https://huggingface.co/spaces/vectara/leaderboard))'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[休斯幻觉评估模型（HHEM）排行榜](https://huggingface.co/spaces/vectara/leaderboard) ([https://huggingface.co/spaces/vectara/leaderboard](https://huggingface.co/spaces/vectara/leaderboard))
- en: These leaderboards are based on generic metrics against foundational models.
    Enterprise data-based LLM solutions will require their own analysis.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些排行榜是基于针对基础模型的通用指标。基于企业数据的LLM解决方案将需要自己的分析。
- en: Answer Relevancy (for generation)
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回答相关性（对于生成）
- en: How relevant is the answer to the question? If parts of the answer are missing
    or include redundant results, the score will be lower. The higher the score, the
    better; the best scores should approach 1, typically between 0 and 1, but because
    of the math, they can range as low as -1.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 答案与问题的相关性如何？如果答案的部分内容缺失或包含冗余结果，则分数会降低。分数越高，越好；最好的分数应该接近1，通常在0到1之间，但由于数学原因，它们可以低至-1。
- en: 'The equation is explained in the RAGAs documentation as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程在RAGAs文档中的解释如下：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>a</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi
    mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mo>(</mo><msub><mi>E</mi><msub><mi>g</mi><mi>i</mi></msub></msub><mo>,</mo><msub><mi>E</mi><mi>o</mi></msub><mo>)</mo></mrow></mrow></mrow></mrow></math>](img/8.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>a</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi
    mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mo>(</mo><msub><mi>E</mi><msub><mi>g</mi><mi>i</mi></msub></msub><mo>,</mo><msub><mi>E</mi><mi>o</mi></msub><mo>)</mo></mrow></mrow></mrow></mrow></math>](img/8.png)'
- en: 'Where:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>](img/9.png)
    is the embedding of the generated question 𝑖'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>](img/9.png)
    是生成的提问 𝑖 的嵌入'
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math>](img/10.png)
    is the embedding of the original question'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math>](img/10.png)
    是原始问题的嵌入'
- en: 𝑁 is the number of generated questions, which is 3 by default
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 𝑁 是生成问题的数量，默认为 3
- en: The math is complex because it is based on Embedded vector values, the multidimensional
    space discussed in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134),
    *Gathering Data – Content is King*. This metric is based on the question, the
    content, and the answer. However, it is calculated based on a cosine similarity
    from the original question to a collection of generated questions. The LLM reverse-engineers
    these based on the answer. It does not consider factuality and penalizes cases
    where the answer lacks completeness.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数学公式复杂，因为它基于嵌入式向量值，这是在 [*第6章*](B21964_06_split_000.xhtml#_idTextAnchor134) 中讨论的多维空间，*收集数据
    – 内容为王*。这个指标基于问题、内容和答案。然而，它是基于原始问题与一组生成问题的余弦相似度来计算的。LLM根据答案进行逆向工程。它不考虑事实性，并惩罚答案不完整的情况。
- en: Because they use cosine similarity, the values can range from -1 to 1, while
    typically, they will be from 0 to 1\. Getting a feel for the data for models is
    challenging. ChatGPT works within a much smaller range of values, as discussed
    in the OpenAI community.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它们使用余弦相似度，值可以从 -1 到 1 变化，而通常，它们将在 0 到 1 之间。对于模型来说，了解数据具有挑战性。ChatGPT在更小的值范围内工作，如OpenAI社区中讨论的那样。
- en: 'Discussion: [Text Embedding Issues](https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3)
    ([https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3](https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3))'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论：[文本嵌入问题](https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3)
    ([https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3](https://community.openai.com/t/some-questions-about-text-embedding-ada-002-s-embedding/35299/3))
- en: I suspect some of this thread is too technical. Even I tend to glaze over because
    we do not need to calculate these to learn how to value them. It just points to
    the magic that goes on behind the scenes. Understanding results can be challenging.
    Get comfortable with the data and metrics and work out improvements.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我怀疑这个帖子中的一些内容过于技术性。即使是我也倾向于感到厌烦，因为我们不需要计算这些内容来学习如何评估它们。它只是指向幕后发生的魔法。理解结果可能具有挑战性。熟悉数据和指标，并制定改进措施。
- en: Pick one, any one
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个，任何一个
- en: 'Another approach is a simple comparison of the number of statements made in
    the output and the relevance of each statement based on the input. This approach
    identifies low scores as problematic:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是简单比较输出中的陈述数量以及每个陈述根据输入的相关性。这种方法将低分识别为问题：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>a</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>R</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></mfrac></mrow></mrow></math>](img/11.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>a</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>R</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></mfrac></mrow></mrow></math>](img/11.png)'
- en: I share this to stir the pot of complexity. This popular alternative approach
    comes from DeepEval, another LLM evaluation framework. They have all the same
    metrics (and more, with 14 at the last check), but as this shows, the calculation
    can vary. There are a dozen popular evaluation tools. I just picked the popular
    RAGAS to help product people understand the key metrics.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我分享这个是为了搅动复杂性的漩涡。这种流行的替代方法来自 DeepEval，另一个 LLM 评估框架。它们拥有所有相同的指标（以及更多，最后一次检查时共有
    14 个），但正如这所示，计算可能会有所不同。有十几种流行的评估工具。我只是选择了流行的 RAGAS 来帮助产品人员理解关键指标。
- en: 'Documentation: [DeepEval Metrics](https://docs.confident-ai.com/docs/metrics-introduction)
    ([https://docs.confident-ai.com/docs/metrics-introduction](https://docs.confident-ai.com/docs/metrics-introduction))'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 文档：[DeepEval 指标](https://docs.confident-ai.com/docs/metrics-introduction) ([https://docs.confident-ai.com/docs/metrics-introduction](https://docs.confident-ai.com/docs/metrics-introduction))
- en: 'This metric is different from answer correctness. It does not consider the
    facts but the need for more completeness or the inclusion of redundant details.
    The LLM generates questions for the answer multiple times (*N*). Then, the average
    value from the collection of cosine similarity scores for each question compared
    to the original question is calculated. A great answer makes it likely the original
    answer can be reconstructed:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标与答案的正确性不同。它不考虑事实，而是考虑更多完整性的需要或包含冗余细节的需求。LLM 对答案进行多次（*N*）提问。然后，计算每个问题与原始问题相比的余弦相似度分数集合的平均值。一个优秀的答案使得原始答案可以重建的可能性增加：
- en: '[PRE2]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The LLM should generate questions from answers like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 应该从这样的答案中生成问题：
- en: '[PRE3]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'ChatGPT 4o was given a simple prompt to generate these questions and returned
    junk:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 4o 被给出一个简单的提示来生成这些问题，却返回了垃圾信息：
- en: '[PRE4]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Work with the engineers, gather data that makes sense, and learn. It can be
    frustrating. Solutions such as fine-tuning, a better knowledge base, and feedback
    loops helps relevance. However, there are more technical approaches as well. To
    go deeper, ask your intern, ChatGPT:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与工程师合作，收集有意义的资料，并学习。这可能令人沮丧。例如，微调、更好的知识库和反馈循环等解决方案有助于提高相关性。然而，还有更多技术方法。要深入了解，请向你的实习生、ChatGPT
    提问：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Context precision (for retrieval)
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文精确度（用于检索）
- en: 'How relevant is the context to the question? Let’s see:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文与问题的相关性如何？让我们看看：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>@</mo><mi>K</mi><mo>=</mo><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><mo>(</mo><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>@</mo><mi>k</mi><mo>×</mo><msub><mi>v</mi><mi>k</mi></msub><mo>)</mo></mrow></mrow><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>t</mi><mi>o</mi><mi>p</mi><mi>K</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>s</mi></mrow></mtd></mtr></mtable></mfrac></mrow></mrow></math>](img/12.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>@</mo><mi>K</mi><mo>=</mo><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><mo>(</mo><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi}s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>@</mo><mi>k</mi><mo>×</mo><msub><mi>v</mi><mi>k</mi></msub><mo>)</mo></mrow></mrow><mtable
    columnwidth="auto" columnalign="center" rowspacing="1.0000ex" rowalign="baseline
    baseline"><mtr><mtd><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>t</mi><mi>o</mi><mi>p</mi><mi>K</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>s</mi></mrow></mtd></mtr></mtable></mfrac></mrow></mrow></math>](img/12.png)'
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>@</mo><mi>k</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>@</mo><mi>k</mi></mrow><mrow><mo>(</mo><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>@</mo><mi>k</mi><mo>+</mo><mi>f</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>@</mo><mi>k</mi><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/13.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>si</mi><mi>o</mi><mi>n</mi><mo>@</mo><mi>k</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>@</mo><mi>k</mi></mrow><mrow><mo>(</mo><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>@</mo><mi>k</mi><mo>+</mo><mi>f</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>@</mo><mi>k</mi><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/13.png)'
- en: Here, *K* is the total number of chunks in context, and ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mfenced
    open="{" close="}"><mn>0,1</mn></mfenced></mrow></mrow></math>](img/14.png) is
    the relevance indicator at rank *k*. Recall the two relevant chunks in the preceding
    “England” example.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*K* 是上下文中片段的总数，并且 ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mfenced
    open="{" close="}"><mn>0,1</mn></mfenced></mrow></mrow></math>](img/14.png) 是排名
    *k* 的相关性指标。回想一下前面“英国”示例中的两个相关片段。
- en: 'Are all of the ground truth items in the context and ranked high? The more
    relevant, the higher its rank. If chunks contain relevant details to support the
    ground truth, sum the precision for each chunk to arrive at the context precision.
    Using the two England example chunks from the previous example, calculate the
    precision for each chunk as it helps to answer our question about the capital
    of England and its location. There are no false positives in the context, such
    as telling me England is in France, so it is just based on the true positive of
    London being the capital in the second chunk, but it needs to provide the details
    about where England is located:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文中，所有的真实项都被排序得高吗？越相关，其排名就越高。如果片段包含支持真实项的相关细节，则将每个片段的精确度相加，以得到上下文的精确度。使用前一个示例中的两个英国示例片段，计算每个片段的精确度，这有助于回答我们关于英国首都及其位置的问题。上下文中没有错误信息，例如告诉我英国在法国，所以它只是基于第二个片段中伦敦是首都的真实正例，但它需要提供关于英国位置的具体细节：
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>@</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>](img/15.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>@</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>](img/15.png)'
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>@</mml:mo><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math>](img/16.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>@</mml:mo><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math>](img/16.png)'
- en: 'Sum up the precision scores and arrive at the mean:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 汇总精确度分数并计算平均值：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mo>(</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo>)</mo></mrow><mn>1</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow></mrow></math>](img/17.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mo>(</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo>)</mo></mrow><mn>1</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow></mrow></math>](img/17.png)'
- en: The documentation could be more precise, but I did not find a reference that
    would make it more transparent. DeepEval, mentioned earlier, has some more context
    if you need their explanation. It is similar in value but slightly different in
    delivery. They don’t define the scope of a true positive, so it needs to be clarified
    how they arrive at their results when looking at complex statements with multiple
    elements. Defining a positive can be challenging, as one statement might contain
    many positives. Also, they don’t account for the relevance indicator in the calculation.
    The actual calculation is more accurate than the documentation. So, take it for
    what it is suggesting. The correct answers in the proper context are needed to
    answer a question. The higher those answers are ranked, the more likely a good
    result will be obtained. The model can be precise but needs to gather all contexts.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 文档可能需要更精确，但我没有找到能够使其更透明的参考资料。前面提到的DeepEval，如果你需要他们的解释，有一些更多的背景信息。它们的值相似，但在表达上略有不同。他们没有定义真正阳性的范围，因此在查看具有多个元素复杂陈述时，需要明确他们如何得出结果。定义一个阳性可能具有挑战性，因为一个陈述可能包含许多阳性。此外，他们没有在计算中考虑相关性指标。实际的计算比文档更准确。所以，按照它所暗示的来理解。在适当的环境下，正确的答案需要来回答问题。这些答案的排名越高，获得好结果的可能性就越大。模型可以很精确，但需要收集所有环境。
- en: Context recall (for retriever)
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环境回忆（针对检索器）
- en: 'Can the retriever retrieve all relevant context? The context is the material
    used as the source of information. The value is based on the ground truth (*GT*)
    and the retrieved context, with values only from 0 to 1\. Higher scores are better:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器能否检索到所有相关环境？环境是作为信息来源使用的材料。其价值基于真实情况（*GT*）和检索到的环境，值范围仅在0到1之间。分数越高越好：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mo>|</mo><mi>G</mi><mi>T</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi>s</mi><mi>t</mi><mi>h</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>a</mi><mi>n</mi><mi>b</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>b</mi><mi>u</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>t</mi><mi>o</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mo>|</mo></mrow><mrow><mo>|</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>G</mi><mi>T</mi><mo>|</mo></mrow></mfrac></mrow></mrow></math>](img/18.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mo>|</mo><mi>G</mi><mi>T</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi}s</mi><mi>t</mi><mi>h</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>b</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>b</mi><mi>u</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>t</mi><mi>o</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mo>|</mo></mrow><mrow><mo>|</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>c</mi><mi>l</mi><mi>a</mi><mi>i</mi><mi>m</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>G</mi><mi>T</mi><mo>|</mo></mrow></mfrac></mrow></mrow></math>](img/18.png)'
- en: 'Finding each statement in the retrieved context will give a 1.0 score for context
    recall. Let’s use our previous answer. These are the facts on which to base this.
    They are the ground truth:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在检索到的上下文中找到每个陈述将给出1.0分，用于上下文召回。让我们使用我们之前的答案。这些是建立在这个基础上的事实。它们是事实真相：
- en: '[PRE6]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Say the recalled context was the following two statements:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 假设回忆起的上下文是以下两个陈述：
- en: '[PRE7]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, both of the following statements:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，以下两个陈述：
- en: '**Statement 1**: England is in Northern Europe'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**陈述1**：英格兰位于北欧'
- en: '**Statement 2**: Its capital is London'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**陈述2**：其首都是伦敦'
- en: 'Can be evaluated against the context:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 可以与上下文进行比较：
- en: '**Statement 1**: False (Northern Europe is not in the context)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**陈述1**：错误（北欧不在上下文中）'
- en: '**Statement 2**: True (London is defined as England’s capital)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**陈述2**：正确（伦敦被定义为英格兰的首都）'
- en: 'This results in the context recall calculation:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了上下文召回的计算：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow></mrow></math>](img/19.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>=</mo><mn>0.5</mn></mrow></mrow></math>](img/19.png)'
- en: This is important to understand because it might have the correct information,
    but if the solution doesn’t return the proper context, it might not provide all
    the expected parts of the answer. Each answer is weighted equally. It could give
    more weight to meaningful and relevant items if it were smarter. It has no idea.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这很重要，因为它可能包含正确的信息，但如果解决方案没有返回正确的上下文，它可能不会提供所有预期的答案部分。每个答案都是同等重要的。如果它更聪明，它可能会给有意义和相关的项目更多的权重。它一无所知。
- en: A few more metrics are outside the four in the chart that started this section.
    One concerns entities.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一些额外的指标超出了本节开始时图表中的四个指标。其中一个与实体有关。
- en: Context entity recall
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文实体召回
- en: '**Entity recall** is useful in solutions such as a help desk, where knowing
    the correct entities (a specific relevant piece of information, a value, or a
    label) is essential. Entities are necessary for filling out vacation requests
    (type of vacation, date, hours), filing an expense report (amount, attendees,
    date, category, purpose, type of payment), interacting with sales data (date,
    amount, contacts, address, product, quantity), or any form with many entities.
    This calculates the fraction of the union of similar entities from the context
    entities (*CE*) and the ground truth (*GE*) entities over the number of ground
    truth entities. Values range from zero to one; high values indicate better recall:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**实体召回**在解决方案中很有用，例如在帮助台，了解正确的实体（一个特定的相关信息、一个值或一个标签）是至关重要的。实体对于填写休假申请（休假类型、日期、小时）、提交费用报告（金额、参与者、日期、类别、目的、支付类型）、与销售数据交互（日期、金额、联系人、地址、产品、数量）或任何具有许多实体的表格都是必要的。这计算了上下文实体（*CE*）和事实真相实体（*GE*）的并集与事实真相实体数量的比例。值从零到一不等；高值表示更好的召回：'
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>C</mi><mi>E</mi><mo>∩</mo><mi>G</mi><mi>E</mi></mrow></mfenced><mrow><mo>|</mo><mi>G</mi><mi>E</mi><mo>|</mo></mrow></mfrac></mrow></mrow></math>](img/20.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>C</mi><mi>E</mi><mo>∩</mo><mi>G</mi><mi>E</mi></mrow></mfenced><mrow><mo>|</mo><mi>G</mi><mi>E</mi><mo>|</mo></mrow></mfrac></mrow></mrow></math>](img/20.png)'
- en: 'This example shows the entities in the ground truth (*GE*):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子显示了真实情况中的实体（*GE*）：
- en: England, Northern Europe, London
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英格兰，北欧，伦敦
- en: 'Then, find the entities in the two context examples (*CE*):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在两个上下文示例（*CE*）中找到实体：
- en: '**Context Example 1**: England, Great Britain, United Kingdom'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文示例 1**: 英格兰，大不列颠，联合王国'
- en: '**Content Example 2**: England, London'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容示例 2**: 英格兰，伦敦'
- en: 'Calculate the scores based on the union of the entity matches:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 根据实体匹配的并集计算分数：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mn>1</mn><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>C</mi><mi>E</mi><mn>1</mn><mo>∩</mo><mi>G</mi><mi>E</mi></mrow></mfenced><mfenced
    open="|" close="|"><mrow><mi>G</mi><mi>E</mi></mrow></mfenced></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo>=</mo><mn>0.33</mn></mrow></mrow></math>](img/21.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mn>1</mn><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>C</mi><mi>E</mi><mn>1</mn><mo>∩</mo><mi>G</mi><mi>E</mi></mrow></mfenced><mfenced
    open="|" close="|"><mrow><mi>G</mi><mi>E</mi></mrow></mfenced></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo>=</mo><mn>0.33</mn></mrow></mrow></math>](img/21.png)'
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mn>2</mn><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>C</mi><mi>E</mi><mn>2</mn><mo>∩</mo><mi>G</mi><mi>E</mi></mrow></mfenced><mrow><mo>|</mo><mi>G</mi><mi>E</mi><mo>|</mo></mrow></mfrac><mo>=</mo><mfrac><mn>2</mn><mn>3</mn></mfrac><mo>=</mo><mn>0.67</mn></mrow></mrow></math>](img/22.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mn>2</mn><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>C</mi><mi>E</mi><mn>2</mn><mo>∩</mo><mi>G</mi><mi>E</mi></mrow></mfenced><mrow><mo>|</mo><mi>G</mi><mi>E</mi><mo>|</mo></mrow></mfrac><mo>=</mo><mfrac><mn>2</mn><mn>3</mn></mfrac><mo>=</mo><mn>0.67</mn></mrow></mrow></math>](img/22.png)'
- en: From this, the conclusion is that the recall on Entity 2 is better for entity
    matching. Too many entities that don’t overlap are noise in this calculation.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结论来看，实体 2 在实体匹配上的召回率更好。太多不重叠的实体在这个计算中是噪声。
- en: Results are not deterministic; try, try, and try again
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 结果不是确定的；尝试，尝试，再尝试
- en: 'There are some issues with calculations not being the same. This is just an
    example; every model’s values will be different. The first-time results might
    look like this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 计算中存在一些问题，计算结果并不相同。这只是一个例子；每个模型的值都会不同。第一次的结果可能如下所示：
- en: '**{''faithfulness'': 0.5624, ''answer_relevancy'': 0.7752, ''****answer_correctness'':
    0.5484}**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**{''faithfulness'': 0.5624, ''answer_relevancy'': 0.7752, ''****answer_correctness'':
    0.5484}**'
- en: 'Rerunning the analysis then yields different results:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 重新运行分析会产生不同的结果：
- en: '**{''faithfulness'': 0.6843, ''answer_relevancy'': 0.7193, ''****answer_correctness'':
    0.5246}**'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**{''faithfulness'': 0.6843, ''answer_relevancy'': 0.7193, ''****answer_correctness'':
    0.5246}**'
- en: Don’t freak out. Why would they differ? The same models and data should give
    the same results. Reproducibility is not there. They suggest repeating runs three
    times and averaging results. This is the growing pain with metric quality. It’s
    not very deterministic, like the models themselves. It is a work in progress,
    but it should be suitable enough.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 不要慌张。为什么它们会不同？相同的模型和数据应该给出相同的结果。可重复性不存在。他们建议重复运行三次并取平均值。这是度量质量增长中的痛点。它并不非常确定，就像模型本身一样。它是一个正在进行中的工作，但应该足够合适。
- en: Online forums have grumblings about the quality of the metrics. Other vendors
    provide new and improved metrics, so be on the lookout. This isn’t a mature space.
    It draws on robust machine learning models, but these scoring methods are imperfect.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在线论坛对指标的质量有所抱怨。其他供应商提供新的改进指标，因此要保持警惕。这不是一个成熟的空间。它依赖于稳健的机器学习模型，但这些评分方法并不完美。
- en: 'Article: [Possible bug in evaluation function in RAGAs](https://github.com/explodinggradients/ragas/issues/660)
    ([https://github.com/explodinggradients/ragas/issues/660](https://github.com/explodinggradients/ragas/issues/660))'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[RAGAs中评估函数可能的bug](https://github.com/explodinggradients/ragas/issues/660)
    ([https://github.com/explodinggradients/ragas/issues/660](https://github.com/explodinggradients/ragas/issues/660))
- en: All of this is about the metrics from your experience. Just benchmark against
    the model data and use tools and techniques to improve. Comparing scores to other
    environments won’t be meaningful. Let’s finish with the UX metrics for this suite.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都与您经验中的指标有关。只需将模型数据与基准进行比较，并使用工具和技术进行改进。将分数与其他环境进行比较将没有意义。让我们以这个套件的UX指标结束。
- en: User experience metrics
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户体验指标
- en: Although the previous metrics should be monitored and valuable to the whole
    team, it is good to see the following are considered UX metrics. Let’s dive right
    in.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然之前的指标应该被监控并对整个团队有价值，但看到以下被认为是UX指标是很好的。让我们直接深入探讨。
- en: Answer semantic similarity
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 答案语义相似性
- en: 'This is based on the relationship between the ground truth and the similarity
    of the answer. It is based on the cosine similarity of the vectorized values of
    the statements. Look for highly correlated values. The range is from 0 to 1, and
    the higher the score, the better the matching between the generated answer and
    the ground truth:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这基于真实答案与答案相似性的关系。它基于语句向量化值的余弦相似性。寻找高度相关的值。范围从0到1，分数越高，生成的答案与真实答案之间的匹配度越好：
- en: '**Ground truth**: The iPhone 15’s battery life is about 11 hours during typical
    web browsing, video watching, and social website use'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真实答案**：iPhone 15在典型网页浏览、视频观看和社交媒体使用时的电池寿命约为11小时'
- en: '**High similarity answer**: The iPhone’s all-day battery life can handle the
    robust media usage of a very active phone user'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高相似度答案**：iPhone的全天候电池寿命可以处理非常活跃的手机用户的稳健媒体使用'
- en: '**Low similarity answer**: Newer phones have a longer battery life than the
    last generation'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低相似度答案**：新一代的手机比上一代的电池寿命更长'
- en: I can’t explain why the RAGAs document leaves out the scoring metric, but we
    can live without it since this is not calculated by hand.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我无法解释为什么RAGAs文档省略了评分指标，但我们可以没有它，因为这不是手工计算的。
- en: 'I see how this is likely based on the work of Risch, Möller, Gutsche, and Peitsch
    (2021), so to explore this article and read Isabelle Nguyen’s blog:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我看到这很可能是基于Risch、Möller、Gutsche和Peitsch（2021）的工作，因此为了探索这篇文章和阅读Isabelle Nguyen的博客：
- en: 'Article: [Semantic Answer Similarity for Evaluating Question Answering Models](https://arxiv.org/pdf/2108.06130)
    by Risch et al. ([https://arxiv.org/pdf/2108.06130](https://arxiv.org/pdf/2108.06130))'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[语义答案相似性用于评估问答模型](https://arxiv.org/pdf/2108.06130) by Risch et al. ([https://arxiv.org/pdf/2108.06130](https://arxiv.org/pdf/2108.06130))
- en: 'Article: [Semantic Answer Similarity: The Smarter Metric to Score Question
    Answering Predictions](https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa)
    by Isabelle Nguyen ([https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa](https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa))'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[语义答案相似性：评分问答预测的更智能指标](https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa)
    by Isabelle Nguyen ([https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa](https://www.deepset.ai/blog/semantic-answer-similarity-to-evaluate-qa))
- en: Risch et al. provide good examples of how it evaluates answer quality. Use this
    to adjust prompts to tighten or loosen the LLM’s response. It also introduces
    the concept of the F1 score, which leads us to answer correctness.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Risch等人提供了如何评估答案质量的良好示例。使用这些示例来调整提示，以收紧或放宽LLM的响应。它还引入了F1分数的概念，这使我们转向答案正确性。
- en: Answer correctness
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 答案正确性
- en: 'This builds on the similarity score for the answer. It looks at the similarity
    of the generated answer and the ground truth and whether the facts are supported.
    So, it is important if it is accurate or leads us astray with **false positives**
    (**FPs**) or **false** **negatives** (**FNs**):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这基于答案的相似度评分。它检查生成的答案与真实答案的相似性以及事实是否得到支持。因此，如果它是准确的或者通过**假阳性**（**FPs**）或**假阴性**（**FNs**）误导我们，那么它很重要：
- en: '**True positive (TP)**: Facts or statements found in the ground truth and generated
    answer'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**True positive (TP)**: 在真实答案和生成的答案中找到的事实或陈述'
- en: '**FP**: Statements or facts in the generated answer that are not found in the
    ground truth'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FP**: 在生成的答案中找到但未在真实答案中找到的陈述或事实'
- en: '**FN**: Missing facts or statements found in the ground truth but missing from
    the generated answer'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FN**: 在真实答案中找到但未在生成的答案中找到的事实或陈述'
- en: 'I will use the example from the documentation to keep this straightforward:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用文档中的示例来保持其简单性：
- en: '**Ground truth**: Einstein was born in 1879 in Germany'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ground truth**: 爱因斯坦于1879年出生于德国'
- en: '**High answer correctness**: In 1879, Einstein was born in Germany'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**High answer correctness**: 1879年，爱因斯坦出生于德国'
- en: '**Low answer correctness**: Einstein was born in Spain in 1879'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Low answer correctness**: 爱因斯坦于1879年出生于西班牙'
- en: 'Then evaluate the low answer correctness (evaluated against “Einstein was born
    in Spain in 1879”):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然后评估低答案正确性（与“爱因斯坦于1879年出生于西班牙”进行比较）：
- en: '**TP**: Einstein was born in 1879'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TP**: 爱因斯坦于1879年出生'
- en: '**FP**: Einstein was born in Spain (incorrect statement)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FP**: 爱因斯坦出生于西班牙（错误陈述）'
- en: '**FN**: Einstein was born in Germany (Germany isn’t in the answer)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FN**: 爱因斯坦出生于德国（德国不在答案中）'
- en: 'This is the F1 score:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这是F1分数：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mn>1</mn><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>T</mi><mi>P</mi></mrow></mfenced><mrow><mo>(</mo><mfenced
    open="|" close="|"><mrow><mi>T</mi><mi>P</mi></mrow></mfenced><mo>+</mo><mn>0.5</mn><mo>×</mo><mo>(</mo><mfenced
    open="|" close="|"><mrow><mi>F</mi><mi>P</mi></mrow></mfenced><mo>+</mo><mfenced
    open="|" close="|"><mrow><mi>F</mi><mi>N</mi></mrow></mfenced><mo>)</mo><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/23.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>F</mi><mn>1</mn><mi>S</mi><mi>C</mi><mi>O</mi><mi>R</mi><mi>E</mi><mo>=</mo><mfrac><mfenced
    open="|" close="|"><mrow><mi>T</mi><mi>P</mi></mrow></mfenced><mrow><mo>(</mo><mfenced
    open="|" close="|"><mrow><mi>T</mi><mi>P</mi></mrow></mfenced><mo>+</mo><mn>0.5</mn><mo>×</mo><mo>(</mo><mfenced
    open="|" close="|"><mrow><mi>F</mi><mi>P</mi></mrow></mfenced><mo>+</mo><mfenced
    open="|" close="|"><mrow><mi>F</mi><mi>N</mi></mrow></mfenced><mo>)</mo><mo>)</mo></mrow></mfrac></mrow></mrow></math>](img/23.png)'
- en: Notice how the false values are weighted. If there is no false information,
    then the F1 score would be the max of 1\. The more false information, the more
    the score trends to zero. If there are no true positives, the score will be zero.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意错误值的加权方式。如果没有错误信息，那么F1分数将是1的最大值。错误信息越多，分数就越趋向于零。如果没有真正的积极，分数将为零。
- en: Other metrics
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他指标
- en: 'Realize this is just a sampling of the available metrics; a few RAGAs framework
    items were skipped, and we mentioned more can be found from the other frameworks.
    Look for repeatability and reliability in metrics that interpret the quality of
    the interactions. Rajeep Biswas (2023) covers other metrics in his overview:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 明白这只是可用指标的一个样本；一些RAGAs框架项目被跳过了，我们提到还可以从其他框架中找到更多。寻找解释交互质量指标的重复性和可靠性。Rajeep Biswas（2023）在他的概述中涵盖了其他指标：
- en: 'Article: [Metrics for evaluating LLMs](https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/)
    ([https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/](https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/))'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[评估大型语言模型（LLMs）的指标](https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/)
    ([https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/](https://www.linkedin.com/pulse/evaluating-large-language-models-llms-standard-set-metrics-biswas-ecjlc/))
- en: I don’t want everyone to get hung up on the math. Appreciating and valuing a
    metric should be based on trusting it to do what it says. But we have to put a
    stake in the ground. Apply the metrics and gauge the team’s level of trust in
    them. The more they are used and iterated, the easier it is to judge the results.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我不希望每个人都陷入数学的困境。欣赏和重视一个指标应该基于信任它能够做到它所说的。但我们必须设定一个基准。应用这些指标并衡量团队对它们的信任程度。使用和迭代得越多，判断结果就越容易。
- en: 'RAGAs is an emerging field, and the metrics will change with it. For a different
    explanation of RAGAs metrics, try this article by Leonie Monigatti (2023):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: RAGAs是一个新兴领域，指标将随着它而变化。对于RAGAs指标的另一种解释，请尝试Leonie Monigatti（2023）的这篇文章：
- en: 'Article: [Evaluating RAG Applications with RAGAs](https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a)
    ([https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a](https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a))'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[使用RAGAs评估RAG应用](https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a)
    ([https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a](https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a))
- en: Metrics give a high-level view of quality without addressing the necessary detailed
    changes to which the metric might allude. The biggest specific issue is hallucination
    errors. Monitoring and addressing these issues are critically important to building
    trust.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 指标提供了对质量的总体看法，但没有涉及指标可能涉及的必要详细更改。最大的具体问题是幻觉错误。监控和解决这些问题对于建立信任至关重要。
- en: Monitoring and classifying the types of hallucination errors
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控和分类幻觉错误的类型
- en: Minimizing hallucinations is a recurring thread in this book. [*Chapter 3*](B21964_03.xhtml#_idTextAnchor058),
    *Identifying Optimal Use Cases for ChatGPT*, covered logging errors from chat
    logs. It is time to explore more refined ways of classifying these errors. Once
    errors are classified, help with the model, the data, or the training to address
    the problems. Two classification methods are worth exploring, starting with error
    types classified by Vectara.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 减少幻觉是这本书中反复出现的一个主题。[*第3章*](B21964_03.xhtml#_idTextAnchor058)，*确定ChatGPT的最佳用例*，涵盖了聊天日志中的记录错误。是时候探索更精细的分类这些错误的方法了。一旦错误被分类，就可以帮助模型、数据或训练来解决这些问题。有两种分类方法值得探索，从由Vectara按错误类型分类开始。
- en: Classifying by error types
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按错误类型分类
- en: '**Vectara** is in the class of RAGAs search tools run as a service. Regardless
    of the tools available, it is essential to identify and fix hallucinations. The
    data should show a small percentage, such as one to three percent, but that level
    of quality requires some work. The Vectara classifications are helpful because
    they are orthogonal and roll up into their version of a quality score, which they
    call the **Factual Consistency Score**. I am a sucker for the word *consistency*
    in any metric. This is a way of monitoring ongoing progress and tracking quality,
    even when humans need help understanding why the values have changed. The more
    learning and testing, the better changes will improve the results. There is only
    guidance, no rules.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**Vectara**属于作为服务运行的RAGAs搜索工具类别。无论可用工具如何，识别和修复幻觉都是至关重要的。数据应显示一个很小的百分比，例如一到三个百分点，但达到这种质量水平需要一些工作。Vectara的分类很有帮助，因为它们是正交的，并汇总成它们版本的质量评分，他们称之为**事实一致性评分**。我对任何指标中的“一致性”这个词都很着迷。这是一种监控持续进步和跟踪质量的方法，即使人类需要帮助理解为什么值发生了变化。学习和测试越多，改进的结果就越好。这里只有指导，没有规则。'
- en: 'I will quote the exact examples used as input but then include commentary on
    the issues with the output:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我将引用作为输入的精确示例，但随后将包括对输出问题的评论：
- en: 'Article: [Automating Hallucination Detection](https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/)
    ([https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/](https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/))'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[自动化幻觉检测](https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/)
    ([https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/](https://vectara.com/blog/automating-hallucination-detection-introducing-vectara-factual-consistency-score/))
- en: '*"The first vaccine for Ebola was approved by the FDA in 2019 in the US, five
    years after the initial outbreak in 2014\. To produce the vaccine, scientists
    had to sequence the DNA of Ebola, then identify possible vaccines, and finally
    show successful clinical trials. Scientists say a vaccine for COVID-19 is unlikely
    to be ready this year, although clinical trials have* *already started."*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*"2019年，美国食品药品监督管理局（FDA）批准了埃博拉疫苗，距离2014年首次爆发已有五年。为了生产疫苗，科学家们必须对埃博拉病毒的DNA进行测序，然后确定可能的疫苗，并最终展示成功的临床试验。科学家们表示，尽管临床试验已经开始，但COVID-19疫苗今年可能不会准备好。"*'
- en: 'Output Type 1: Relation error:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类型1：关系错误：
- en: '*"The Ebola vaccine was rejected by the FDA* *in 2019."*'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '*"2019年，FDA拒绝批准埃博拉疫苗。"* '
- en: '**Analysis**: *The AI confused the relationship between Ebola and COVID-19\.*
    The Ebola vaccine was approved in 2019.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析**：*人工智能混淆了埃博拉和COVID-19之间的关系。* 埃博拉疫苗于2019年获得批准。'
- en: '**Commentary**: [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134),
    *Gathering Data – Content is King,* covered the common association error in which
    Hank Arron’s and Hank Greenberg’s religions were confused. Relationships in conversation,
    even between humans, are complex. “It,” “they,” “us,” “we,” “there,” “you,” “your,”
    “them,” and other phrases can be misconnected to the wrong subject, resulting
    in attribution errors. Don’t allow customers to think Product A does something
    that is only supported by Product B.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**注释**：[第 6 章](B21964_06_split_000.xhtml#_idTextAnchor134)，*收集数据 – 内容为王*，讨论了常见的关联错误，其中汉克·阿隆和汉克·格林伯格的宗教被混淆。对话中的关系，即使是人与人之间，也是复杂的。“它”、“他们”、“我们”、“我们”、“那里”、“你”、“你的”、“他们”和其他短语可能会与错误的主语连接，导致归因错误。不要让客户认为产品
    A 做了只有产品 B 支持的事情。'
- en: 'Output Type 2: Entity error:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类型 2：实体错误：
- en: '*The COVID-19 vaccine was approved by the FDA* *in 2019.*'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*2019 年，FDA 批准了 COVID-19 疫苗* *。'
- en: '**Analysis**:*This error arises from the AI confusing details between Ebola
    and COVID-19\.* COVID-19 appeared on the world stage in January 2020 with an announcement
    from the Center for Disease Control in the US, and the first vaccine appeared
    in December 2020.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析**：*这种错误源于 AI 混淆了埃博拉和 COVID-19 的细节。COVID-19 于 2020 年 1 月在世界舞台上出现，美国疾病控制中心的公告，第一剂疫苗于
    2020 年 12 月出现。*'
- en: '**Commentary**: Entity recognition is complex. Understanding the sources is
    required to identify entities. Designers, writers, and PMs must know their products
    and build a team of experts on the business. In this case, it is easy; everyone
    experienced COVID and might realize the timing is wrong. With more technical materials,
    especially those that cover multiple products, it is easy to match the wrong product
    to an unrelated bug, specification, or feature. These are entity errors. One can
    look at editing the source documents or how the RAGAs tools segment or chunk the
    document. Some documentation could be more straightforward for ingestion by an
    LLM.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**注释**：实体识别是复杂的。要识别实体，需要理解来源。设计师、作家和项目经理必须了解他们的产品，并组建一支业务专家团队。在这种情况下，这是很容易的；每个人都经历过
    COVID，可能会意识到时机是错误的。对于更技术性的材料，特别是涵盖多个产品的材料，很容易将错误的产品与无关的缺陷、规范或功能匹配。这些都是实体错误。可以查看编辑源文档或
    RAGAs 工具如何分段或分块文档。某些文档可能更适合 LLM 的摄入。'
- en: 'Output Type 3: Coreference error:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类型 3：指代错误：
- en: '*"The first vaccine for Ebola was approved by the FDA in 2019\. They say a
    vaccine for COVID-19 is unlikely to be ready* *this year.”*'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*"2019 年，FDA 批准了埃博拉疫苗。他们说 COVID-19 疫苗今年不太可能准备好。"*'
- en: '**Analysis**: *The confusion arises with the pronoun “they”; the summary refers
    to the FDA, but in the original article, “they” relates* *to scientists.*'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析**：*混淆源于代词“他们”；摘要指的是 FDA，但在原始文章中，“他们”指的是科学家。*'
- en: '**Commentary**: Similar to Type 1, this focuses on misconnected subjects. The
    context of “they” was correct when referring to scientists, but because the chunk
    analyzed contained the FDA reference, it got confused. If the source document
    was clear that “Scientists say the vaccine…” this error would not happen. However,
    it would be annoying as a human to read articles that never use pronouns or determiners
    (words that refer to a noun more specifically, such as “the book” or “her show”).
    Tools should get better at making these relationships, or content will be rewritten.
    At least recognize the issue and correct it. This repetitive use of words, like
    if we repeatedly used “Scientists say,” is called **burstiness**. It will touch
    on this again later in this chapter. It could be that human-readable documentation
    will have to be distinct from optimized material for RAG. Getting context when
    something is at the top or in a document’s sidebar for a paragraph five pages
    later is hard.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**注释**：与类型 1 类似，这侧重于错误连接的主语。当“他们”指代科学家时，上下文是正确的，但由于分析的片段包含了 FDA 的引用，因此产生了混淆。如果源文档明确指出“科学家们说疫苗……”，这种错误就不会发生。然而，对于人类来说，阅读从不使用代词或限定词（更具体地指代名词的词，如“那本书”或“她的节目”）的文章会让人感到烦恼。工具应该更好地建立这些关系，或者内容将被重写。至少要认识到这个问题并纠正它。这种重复使用词汇，比如如果我们反复使用“科学家们说”，被称为**爆发性**。这将在本章后面再次讨论。可能人类可读的文档将不得不与为
    RAG 优化的材料区分开来。当某事在顶部或文档侧边栏的第五页处时获取上下文是困难的。'
- en: 'Output Type 4: Discourse link error:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类型 4：话语链接错误：
- en: '*“To produce the vaccine, scientists have to show successful human trials,
    then sequence the DNA of* *the virus.”*'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*“为了生产疫苗，科学家们必须展示成功的人类试验，然后对病毒的 DNA 进行测序。”*'
- en: '**Analysis**:*This misplacement stems from an incorrect order of events; the
    original article states that sequencing the virus’s DNA precedes demonstrating
    successful* *human trials.*'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析**：*这种错误放置源于事件顺序的错误；原始文章指出，病毒DNA的排序先于成功* *人体试验* *的展示。*'
- en: '**Commentary**: This issue with order can take a lot of work to catch. Did
    you have to read it twice to see the problem? Steps and order are crucial in technical
    documentation. If there is a lot of step-by-step documentation, create a collection
    of test cases focused on order. Their label, “discourse link error,” belies the
    simplicity of this example. I don’t know why they used that wording. Maybe they
    wanted a slightly different word than “relation.” This doesn’t appear to be a
    link issue. More detail was not provided. Expect consolidation in nomenclature
    and standardization in testing over the next few years. Wynter et al. (2023) probably
    would call this logical inconsistency.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**评论**：这个问题与顺序有关，可能需要大量工作才能发现。您是否需要读两遍才能看到问题？步骤和顺序在技术文档中至关重要。如果有很多步骤说明文档，请创建一个专注于顺序的测试案例集合。它们的标签“话语链接错误”掩盖了这个示例的简单性。我不知道他们为什么使用这个词。也许他们想要一个比“关系”稍微不同的词。这看起来不是一个链接问题。没有提供更多细节。预计在接下来的几年中，在术语命名和测试标准化方面将会有所整合。Wynter等人（2023）可能会称这为逻辑不一致。'
- en: 'Article: [An evaluation on large language model outputs: Discourse and memorization](https://www.sciencedirect.com/science/article/pii/S2949719123000213)
    by Wynter et al., 2023 ([https://www.sciencedirect.com/science/article/pii/S2949719123000213](https://www.sciencedirect.com/science/article/pii/S2949719123000213))'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '文章：Wynter等人（2023）撰写的《对大型语言模型输出的评估：话语和记忆》（[An evaluation on large language model
    outputs: Discourse and memorization](https://www.sciencedirect.com/science/article/pii/S2949719123000213)）([https://www.sciencedirect.com/science/article/pii/S2949719123000213](https://www.sciencedirect.com/science/article/pii/S2949719123000213))'
- en: Let me share one more classification method.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我分享另一种分类方法。
- en: Factual and faithful hallucinations
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事实和忠实幻觉
- en: '[*Chapter 4*](B21964_04.xhtml#_idTextAnchor085)*, Scoring Stories*, provides
    a manual classification approach. Take advantage of emerging definitions and classifications
    when they will help organize or resolve issues. As Deval Shah discusses, it could
    be helpful to distinguish between factuality and faithfulness hallucinations.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B21964_04.xhtml#_idTextAnchor085)*，评分故事*，提供了一个手动分类方法。当它们有助于组织或解决问题时，利用新兴的定义和分类。正如Deval
    Shah讨论的那样，区分事实性和忠实幻觉可能会有所帮助。'
- en: 'Article: [Taxonomy of Hallucinations in LLMs](https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models)
    by Deval Shah ([https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models](https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models))'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：Deval Shah撰写的《LLM中幻觉的分类》（[Taxonomy of Hallucinations in LLMs](https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models)）([https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models](https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models))
- en: Let’s start with fact-based issues in *Table 10.1*. Bold represents the hallucinations.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基于事实的问题开始，看看*第10.1表*。粗体表示幻觉。
- en: '| **Type** | **User Input** | **Model Output** | **Explanation** |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **用户输入** | **模型输出** | **解释** |'
- en: '| **Factual** **Inconsistency** | Who was the famous Jewish home run hitter
    in MLB? | **Hank Arron** was the most famous Jewish hitter in MLB. | The LLM’s
    answer is wrong as Hank Greenberg was the top Jewish home run hitter in MLB. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| **事实** **不一致** | 谁是MLB中最著名的犹太裔本垒打手？ | **汉克·阿隆**是MLB中最著名的犹太裔击球手。 | LLM的答案是错误的，因为汉克·格林伯格是MLB中最顶尖的犹太裔本垒打手。|'
- en: '| **Factual** **Fabrication** | Tell me about the origins of dragons. | **Dragons
    roamed the northern volcanoes of Old Eros where they were tamed by the** **royal
    family.** | The LLM’s answer is made up. It sounds like it came from Game of Thrones.
    |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| **事实** **虚构** | 告诉我关于龙起源的故事。 | **龙在旧厄罗斯的北部火山中游荡，被皇室驯服。** | LLM的答案是虚构的，听起来像是来自《权力的游戏》。|'
- en: Table 10.1 – Examples of factual hallucinations
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1 – 事实幻觉的例子
- en: Next, he breaks down faithfulness, categorizing it into instruction, context,
    and logical inconsistencies. He has a wonderful section surveying the origins
    of hallucinations in LLMs. Do visit it for more insight.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，他将忠实度分解为指令、上下文和逻辑不一致性，并有一个关于LLM中幻觉起源的精彩部分。请访问它以获取更多信息。
- en: Huang’s article covers how hallucinations come from data sources, training,
    and inference (as covered), how no single benchmark covers all the issues, and,
    critically, how to mitigate hallucination.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 黄的文章涵盖了幻觉来自数据源、训练和推理（如前所述），没有单一的基准可以涵盖所有问题，以及如何关键性地减轻幻觉。
- en: 'Article: [A Survey on Hallucination in Large Language Models: Principles, Taxonomy,
    Challenges, and Open Questions](https://arxiv.org/pdf/2311.05232) by Huang et
    al., 2023 ([https://arxiv.org/pdf/2311.05232](https://arxiv.org/pdf/2311.05232))'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[关于大型语言模型幻觉的调查：原理、分类、挑战和开放问题](https://arxiv.org/pdf/2311.05232) by 黄等，2023
    ([https://arxiv.org/pdf/2311.05232](https://arxiv.org/pdf/2311.05232))
- en: The section on mitigation makes reading the whole article worth it. These strategies
    are covered next.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解措施的章节使得阅读整篇文章都值得。以下将介绍这些策略。
- en: Overall approaches to reducing issues during monitoring
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控期间减少问题的总体方法
- en: Continuous improvement based on monitoring is an absolute necessity with this
    technology. This is repeated more than any other topic in this book. This care
    and feeding cycle must be done while customers learn to engage. They have a low
    tolerance for dumb experiences and will turn away from poor recommendations. It
    takes work to re-engage a lost customer. [*Chapter 11*](B21964_11.xhtml#_idTextAnchor236)*,
    Process*, focuses on process improvements. First, look at general methods to solve
    quality issues.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 基于监控的持续改进是这项技术的绝对必要条件。这一点在这本书的任何其他主题中都没有被重复得如此之多。在客户学习参与的同时，必须完成这一关怀和养护周期。他们对愚蠢的体验的容忍度很低，并且会远离糟糕的建议。重新吸引失去的客户需要付出努力。[*第11章*](B21964_11.xhtml#_idTextAnchor236)*，过程*，专注于过程改进。首先，看看解决质量问题的通用方法。
- en: 'Chunking, data manipulation, and writing or editing for LLMs help. More approaches
    are out in the wild. Even ChatGPT knows about these. Some help augment the data
    to make the system more robust to user variety. Back translation, text summarization—especially
    when using a different LLM to supplement the main LLM—and noise injection (including
    misspellings and grammar errors) help the model understand the imperfectness of
    human language. Try this prompt:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 分块、数据处理以及为LLM写作或编辑有助于。更多的方法正在野外出现。甚至ChatGPT也知道这些。一些方法帮助增强数据，使系统更能适应用户的多样性。反向翻译、文本摘要——尤其是在使用不同的LLM来补充主要LLM时——以及噪声注入（包括拼写错误和语法错误）有助于模型理解人类语言的不完美性。尝试以下提示：
- en: '[PRE8]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It should be straightforward to recognize and even respect why variety is essential.
    Chat GPT 4o will respond with dozens of techniques. People are not only different,
    but they are also not perfect. Generating examples with imperfections in the dataset
    and getting the model to overcome these and become more robust is all part of
    training. Seeing how customers ask questions, make mistakes, and retry when they
    need help getting the correct answer is excellent. But don’t take the LLM’s word
    for it. Let’s look at how the humans at OpenAI approached building a solution
    for an enterprise customer.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 应该很容易认识到甚至尊重多样性之所以重要的原因。Chat GPT 4o将回应数十种技术。人们不仅不同，而且也不完美。在数据集中生成有缺陷的示例，并让模型克服这些缺陷，变得更加健壮，都是训练的一部分。观察客户如何提问、犯错，并在需要帮助获得正确答案时重试，是非常好的。但不要仅凭LLM的话。让我们看看OpenAI的人类如何为一家企业客户构建解决方案。
- en: OpenAI’s case study on quality and how to measure it
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI关于质量和如何衡量的案例研究
- en: 'OpenAI has some good developer day talks on how to think about evaluation.
    It is a clear explanation without going over people’s heads. Check it out to learn
    more about scoring. The most significant takeaways are:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI有一些关于如何考虑评估的很好的开发者日演讲。这是一个清晰易懂的解释，没有超出人们的理解。查看它以了解更多关于评分的信息。最重要的收获是：
- en: Not every suggestion resulted in improvements (items with a check worked)
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个建议都导致了改进（带有勾选的项目有效）
- en: It takes a team to address and refine an enterprise solution
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个团队来解决和精炼企业解决方案
- en: Solutions can dramatically improve with a methodological iterative approach
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过方法论迭代方法，解决方案可以显著改进
- en: '*Figure10.2* shows OpenAI’s methods to improve the case study from the video.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.2* 展示了OpenAI从视频中改进案例研究的方法。'
- en: '![](img/B21964_10_02.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21964_10_02.jpg)'
- en: Figure 10.2 – Different techniques can succeed or fail to improve the experience
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 不同的技术可能成功或失败，以改善体验
- en: 'Video: Maximizing LLM performance [techniques](https://youtu.be/ahnGLM-RC1Y)
    ([https://youtu.be/ahnGLM-RC1Y](https://youtu.be/ahnGLM-RC1Y))'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 视频：最大化LLM性能 [技术](https://youtu.be/ahnGLM-RC1Y) ([https://youtu.be/ahnGLM-RC1Y](https://youtu.be/ahnGLM-RC1Y))
- en: The chart and video show successful (✔) and two failed (🚫) approaches. They
    worked through various solutions to find good fits. The video doesn’t show the
    details of the changes they made. It is not explained what changes were made to
    raise accuracy. However, it is still a good case study that shows dramatic improvements
    in quality. With every effort, a testing process must be implemented to evaluate
    systematically. There needs to be more than user perception, surveys, and feedback.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图表和视频展示了成功（✔）和两种失败（🚫）的方法。他们通过各种解决方案找到了合适的匹配。视频没有展示他们所做的具体变化。没有解释为了提高准确性所做的变化。然而，这仍然是一个很好的案例研究，展示了质量上的显著提升。每一次努力都必须实施一个测试流程来系统性地评估。需要的不只是用户感知、调查和反馈。
- en: Systematic testing processes
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统化测试流程
- en: 'To evaluate any system, a few things are needed:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 评估任何系统都需要以下几点：
- en: Understand and be able to apply real-world usage and understand edge cases
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解并能应用实际使用场景，并理解边缘情况
- en: Be statistically confident in the amount of testing
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对测试量有统计上的信心
- en: Be able to repeat or even automate the test with reliability and consistency
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够可靠且一致地重复或自动化测试
- en: Be able to make changes systematically to understand the results
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够系统地做出改变以理解结果
- en: With our human testing, methods are available to test with as few as five customers.
    Typically, human testers can go into the dozens, with only methods such as surveys
    intentionally hitting thousands. However, when it comes to LLMs, there are places
    where automation and scale are critical to success. OpenAI suggests in *Table
    10.2* that larger sample sizes of test cases are are needed to evaluate LLMs to
    improve quality.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的人机测试中，有方法可以在五个客户中进行测试。通常，人工测试人员可以达到几十人，只有通过调查等手段有意地达到几千人。然而，当涉及到LLM时，自动化和规模对于成功至关重要。OpenAI在*表10.2*中建议，为了提高LLM的质量，需要更大的测试用例样本量。
- en: '| **Difference** **to detect** | **The sample size needed for** **95% confidence**
    |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| **检测差异** | **需要达到95%置信度的样本量** |'
- en: '| **30%** | ~10 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| **30%** | ~10 |'
- en: '| **10%** | ~100 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| **10%** | ~100 |'
- en: '| **3%** | ~1,000 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| **3%** | ~1,000 |'
- en: '| **1%** | ~10,000 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| **1%** | ~10,000 |'
- en: Table 10.2 – Relationship between detection difference percentages to the number
    of test cases
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2 – 检测差异百分比与测试用例数量的关系
- en: The chart in *Table 10.2* is from OpenAI’s testing strategy documentation.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '*表10.2*中的图表来自OpenAI的测试策略文档。'
- en: 'Documentation: [OpenAI’s view on testing strategy](https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically)
    ([https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically](https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically))'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 文档：[OpenAI对测试策略的看法](https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically)
    ([https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically](https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically))
- en: Confidence increases as the number of test case samples increases. This is done
    with simple assumptions and straightforward explanations. This should answer any
    questions about the scale of testing compared to the reliability expected in practice.
    Don’t expect 10,000 examples of an answer to a single question; think broader.
    Test cases will be built into a collection over time.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 随着测试用例样本数量的增加，信心也会增加。这是通过简单的假设和直接的解释来实现的。这应该可以回答关于测试规模与实际预期可靠性之间的问题。不要期望一个问题的答案有10,000个例子；要考虑更广泛的情况。测试用例将在一段时间内构建成一个集合。
- en: 'Although this is easiest to understand for a conversational assistant, some
    thought has to be applied to other use cases, such as a recommender. Create test
    data and understand the variety of recommendations. Each focused recommendation
    will need a collection of test cases that understand the range of data elements.
    With five data elements in the recommendation, each with 3 to 30 possible values,
    a range of 30 to 150 combinations can result. Here is a recommendation for smart
    air filters:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这对于对话助手来说最容易理解，但对于其他用例，如推荐系统，也需要进行一些思考。创建测试数据并理解各种推荐。每个专注的推荐都需要一组理解数据元素范围的测试用例。在推荐中有五个数据元素，每个元素有3到30个可能的值，可以产生30到150种组合。以下是一个智能空气净化器的推荐：
- en: '[PRE9]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This recommendation for a large commercial building is based on air quality
    measures, the cost of energy to run the system, filter dirt capacity, filter type,
    and the filter’s current dirtiness. There are thousands of possible combinations
    and dozens of recommendations in that case. The system must deal with all these
    entities, variables, and recommendations (see bolded items). So, thousands of
    test cases are needed, and results need to be validated to ensure that good advice
    is provided.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这些建议针对大型商业建筑，基于空气质量指标、系统运行能耗、过滤灰尘容量、过滤类型以及过滤器的当前灰尘程度。在这种情况下，有数千种可能的组合和数十项建议。系统必须处理所有这些实体、变量和建议（见加粗项目）。因此，需要数千个测试用例，并且需要对结果进行验证，以确保提供良好的建议。
- en: Each area of expertise is also multiplied by the number of languages supported,
    and the test matrix will grow. These must be automated. Breaking down test cases
    by subject helps one understand the scale of the problem better. Recall the Alligiance
    example in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134)*, Gathering
    Data—Content is King*. There were 400 FAQs and many ways of asking each question.
    Five test cases for each FAQ would be over 2000 test cases.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 每个专业领域也乘以支持的语言数量，测试矩阵将随之增长。这些必须自动化。按主题分解测试用例有助于更好地理解问题的规模。回想一下[*第6章*](B21964_06_split_000.xhtml#_idTextAnchor134)*，数据收集——内容为王*的联盟例子。有400个常见问题解答和询问每个问题的多种方式。每个常见问题解答的五个测试用例将超过2000个测试用例。
- en: Test cases can come from humans or an LLM. An example is how to "expense dinner
    at Joe’s Eatery for a client dinner for $21.46"; when surveyed, 100 participants
    were asked how they would say it. They generated 244 different utterances, and
    87% were unique. Here are ten examples in *Table 10.3* and some analysis of these
    potential test cases.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 测试用例可以来自人类或LLM。一个例子是如何“报销乔氏餐厅的21.46美元客户晚餐”；当进行调查时，100名参与者被问及他们会如何表达。他们生成了244种不同的表述，其中87%是独特的。以下是*表10.3*中的十个例子以及这些潜在测试用例的一些分析。
- en: '| **Test case utterance –** **human-generated** | **Test** **case considerations**
    |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| **测试用例表述 –** **人工生成** | **测试** **用例考虑因素** |'
- en: '| --- | --- |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **$21.46 dinner** **at Joe’s** | Doesn’t mention intent; what should an LLM
    do with this info? It might be confused with an appointment. The amount does help.
    |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| **在乔氏餐厅的21.46美元晚餐** | 没有提及意图；LLM应该如何处理这些信息？它可能会与约会混淆。金额有所帮助。 |'
- en: '| **12/12/18,** **Dinner, 21.46** | Notice ambivalent date format (MM/DD or
    DD/MM?), no intent to be clear this is an expense and no currency. |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| **12/12/18，** **晚餐，21.46** | 注意日期格式含糊不清（MM/DD或DD/MM？），没有明确表示这是一笔费用，也没有提及货币。
    |'
- en: '| **Create an expense for $21.46 at Joe’s Eatery with my co-worker Lisa Jones
    and** **a client.** | Intent, amount, location, and details. A good example. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| **与我的同事丽莎·琼斯和** **客户** **在乔氏餐厅创建21.46美元的费用** | 意图、金额、地点和细节。是个好例子。 |'
- en: '| **dinner - client visit - $21.46 Canadian** **Joe’s eatery** | Points out
    Canadian dollars. |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| **晚餐 - 客户拜访 - 21.46加拿大元** **乔氏餐厅** | 指出使用加拿大元。 |'
- en: '| **Dinner - Joe’s Eatery - $****21.46** | Terse, but contains 3 of the 5 items
    needed. A good start. |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| **晚餐 - 乔氏餐厅 - $****21.46** | 简洁，但包含了所需的5项中的3项。是个好开始。 |'
- en: '| **Expense 21 dollars 46 cents Joe’s Eatery for a client visit on October**
    **3, 2018** | Notice amount format is spoken out. |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| **2018年10月** **3日** **的乔氏餐厅客户拜访费用21美元46美分** | 注意金额格式是口语化的。 |'
- en: '| **Hey, I used my corporate Amex for dinner. Didn’t you** **see that?** |
    Expects the credit card integration to find his expenses and connect it for expensing.
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| **嘿，我用了公司的Amex卡支付晚餐。你没看到吗** **？** | 期望信用卡集成能够找到他的费用并将其用于报销。 |'
- en: '| **Reimburse me for $21.46 for a client visit with** **George Smith** | Reasonable,
    doesn’t mention dinner or a date. |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| **报销我21.46美元的客户拜访费用，与** **乔治·史密斯** **会面** | 合理，未提及晚餐或约会日期。 |'
- en: '| **Submit $21.46 for** **client visit** | Lacking a lot of information, but
    reasonable. |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| **提交21.46美元的客户拜访费用** | 缺少大量信息，但合理。 |'
- en: '| **Take care of my dinner expense of 21.46 dollars at Joe’s for a client visit
    with the** **following people** | Conversational and expects to provide more details
    to follow. |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| **请为我报销21.46美元的乔氏餐厅晚餐费用，与以下人员** **会面** | 对话式，并期望提供更多细节。 |'
- en: Table 10.3 – Potential test cases written by human subjects
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.3 – 由人工主体编写的潜在测试用例
- en: 'Humans generated these, but an LLM model can also generate test cases. Let’s
    compare what happens when prompting ChatGPT 3.5:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试用例是由人类生成的，但LLM模型也可以生成测试用例。让我们比较一下当提示ChatGPT 3.5时会发生什么：
- en: '[PRE10]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ChatGPT 3.5’s results are shown in *Table 10.4*. There are differences.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 3.5的结果显示在*表10.4*中。存在差异。
- en: '| **Test case utterance –** **OpenAI-generated** | **Testing considerations**
    |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| **测试用例语句 –** **由OpenAI生成** | **测试考虑因素**|'
- en: '| --- | --- |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **“Record a meal expense of $21.46 for a client lunch at Joe’s Eatery on
    August** **15th, 2024.”** | All elements are included, uses the awkward “Record”.
    |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| **“记录2024年8月15日在Joe’s Eatery为客户午餐的$21.46餐费。”** | 所有元素都包含在内，使用了尴尬的“记录”。|'
- en: '| **“Expense $21.46 for a meal with a client at Joe’s Eatery** **on 8/15/24.”**
    | All elements, used US date format. |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| **“2024年8月15日在Joe’s Eatery与客户用餐花费$21.46。”** | 所有元素，使用美国日期格式。|'
- en: '| **“Add a meal expense of $21.46 for lunch with a client at Joe’s** **Eatery
    today.”** | All elements, used “today”. |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| **“今天在Joe’s Eatery与客户用餐，增加$21.46的餐费。”** | 所有元素，使用了“今天”。|'
- en: '| **“Expense: Meal. Amount: $21.46\. Date: August 15th, 2024\. Location: Joe’s
    Eatery. Purpose:** **Client Lunch.”** | Not conversational. No human ever did
    it like this. |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| **“费用：餐费。金额：$21.46。日期：2024年8月15日。地点：Joe’s Eatery。目的：** **客户午餐。”** | 非对话式。没有人会这样记录。|'
- en: '| **“Register a $21.46 expense for a meal at Joe’s Eatery on August 15, 2024,
    for a** **client lunch.”** | All elements, uses the awkward “Register”. |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| **“在2024年8月15日于Joe’s Eatery为客户午餐记录$21.46的费用。”** | 所有元素，使用了尴尬的“登记”。|'
- en: '| **“Document a meal expense of $21.46 for a client lunch at Joe’s Eatery**
    **on 8/15/24.”** | All elements. |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| **“记录2024年8月15日在Joe’s Eatery为客户午餐的$21.46餐费。”** | 所有元素。|'
- en: '| **“Add an expense for a meal at Joe’s Eatery, $21.46, for a client lunch
    on** **August 15th.”** | All elements. |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| **“在2024年8月15日为客户午餐在Joe’s Eatery增加$21.46的费用。”** | 所有元素。|'
- en: '| **“Expense: Meal. Amount: $21.46\. Date: 15th August 2024\. Location: Joe’s
    Eatery. Purpose:** **Client Lunch.”** | Not conversational. No human ever did
    it like this. |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| **“费用：餐费。金额：$21.46。日期：2024年8月15日。地点：Joe’s Eatery。目的：** **客户午餐。”** | 非对话式。没有人会这样记录。|'
- en: '| **“Record $21.46 spent on a meal with a client at Joe’s Eatery on August**
    **15, 2024.”** | All elements, almost identical to the preceding one. |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| **“记录于2024年8月15日在Joe’s Eatery与客户用餐花费$21.46。”** | 所有元素，几乎与上一条相同。|'
- en: Table 10.4 – Potential test cases written by ChatGPT 3.5
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.4 – ChatGPT 3.5编写的潜在测试用例
- en: 'By comparing the results, a few conclusions can be made:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 通过比较结果，可以得出一些结论：
- en: Humans only included some of the information all of the time
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类只包括了一些信息
- en: Humans went off-topic and expected to follow up with additional information
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类偏离了主题，并期望提供更多信息
- en: ChatGPT ignored my request to vary what was included
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT忽略了我要求变化包含内容的要求
- en: ChatGPT used words humans didn’t use (such as Record and Register)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT使用了人类不会使用的词汇（如Record和Register）
- en: ChatGPT didn’t vary the cases very much, the prompt can be improved
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT没有很大程度地变化案例，提示词可以改进
- en: This is a simple example. Humans are unpredictable and *human* when communicating,
    so consider that when allocating resources to create test cases. Time can be spent
    improving the prompt and forcing ChatGPT to give better and more varied results.
    Or a new model can provide a much more significant jump in quality. *Table 10.5*
    shows results from GPT 4o. This is better with the same prompt and no prompt engineering.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的例子。人类在交流时不可预测且具有**人性**，因此在分配资源创建测试用例时要考虑这一点。可以花时间改进提示词，并迫使ChatGPT提供更好、更多样化的结果。或者，一个新的模型可以提供质量上的重大飞跃。*表10.5*显示了GPT
    40的结果。与相同的提示词和无提示工程相比，这更好。
- en: '| **ChatGPT** **4o responses** | **Testing considerations** |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| **ChatGPT** **40个响应** | **测试考虑因素**|'
- en: '| --- | --- |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Detailed:** Please expense a meal receipt for $21.46 US dollars dated 8/15/2024
    for a client lunch at Joe’s Eatery. | Robust and complete |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| **详细说明**：请报销2024年8月15日在Joe’s Eatery为客户午餐的$21.46美元餐费。 | 结构完整。|'
- en: '| **Detailed with variation**: Create an expense report for a meal costing
    $21.46 USD from Joe’s Eatery on August 15, 2024, for a client lunch. | Varied
    the date format. |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| **详细且有所变化**：创建一份2024年8月15日从Joe’s Eatery为客户的午餐花费$21.46美元的餐费报告。 | 变化了日期格式。|'
- en: '| **Medium detail**: Log a meal expense of $21.46 for a client meeting on 8/15/2024
    at Joe’s Eatery. | Log is a good choice. |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| **中等详细程度**：记录2024年8月15日在Joe’s Eatery与客户会面花费$21.46的餐费。 | 日志是一个不错的选择。|'
- en: '| **Medium detail with different structure**: Expense a client lunch meal for
    $21.46 from Joe’s Eatery on 15th August 2024. | “lunch meal” is not something
    from humans. |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| **中等详细程度，结构不同**：2024年8月15日从Joe’s Eatery为客户的午餐花费$21.46。 | “午餐”不是人类会使用的东西。|'
- en: '| **Minimal detail**: Start a meal expense for $21.46 at Joe’s Eatery. | “Start”
    is a good trigger, but it is generic. |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| **极简细节**：在Joe’s Eatery开始$21.46的餐费。 | “开始”是一个好的触发器，但它很通用。 |'
- en: '| **Minimal detail with date**: Record a $21.46 meal expense for a client meeting
    on 8/15/2024. | “Record” is still not great. |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| **带日期的极简细节**：记录2024年8月15日客户会议的$21.46餐费。 | “记录”仍然不是很好。 |'
- en: '| **Basic**: Enter a meal expense for a client lunch costing $21.46. | Good
    and short. |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| **基本**：为客户午餐输入费用$21.46。 | 这很好，也很简短。 |'
- en: '| **Basic with location**: Log a client lunch expense for $21.46 at Joe’s Eatery.
    | A shorter version of the medium detail item. |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| **基本带位置**：在Joe’s Eatery记录客户午餐费用为$21.46。 | 这是中等详细程度条目的简短版本。 |'
- en: '| **Very minimal**: Expense $21.46 for a client meal. | So short, it need follow-up.
    |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| **非常简短**：为客户餐费支付$21.46。 | 这非常简短，需要后续跟进。 |'
- en: '| **Least robust**: Start an expense. | Excellent, and common from humans.
    |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| **最不稳健**：开始一个费用。 | 这对于人类来说是优秀且常见的。 |'
- en: Table 10.5 – Potential test cases written by ChatGPT 4o
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.5 – ChatGPT 4o编写的潜在测试用例
- en: I have also included their labeling, showcasing the types of use cases they
    provide. Monitor actual user inputs, making judging the value derived from generated
    data easier. It is hard for one individual to think like *everyone*, so don’t
    try. Use monitoring resources and log analysis to get robust training data and
    test cases.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我还包含了它们的标签，展示了它们提供的用例类型。监控实际用户输入，使评估从生成数据中获得的价值变得更容易。一个人很难像*每个人*一样思考，所以不要尝试。使用监控资源和日志分析来获取稳健的训练数据和测试用例。
- en: The problems get harder when the space gets more complex. Recall our graph from
    [*Chapter 1*](B21964_01.xhtml#_idTextAnchor016), *Recognizing the Power of Design
    in ChatGPT*, reshared as *Figure 10**.3*.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 当空间变得更加复杂时，问题会变得更加困难。回想一下我们来自[*第1章*](B21964_01.xhtml#_idTextAnchor016)的图表，*认识到设计在ChatGPT中的力量*，重新共享为*图10.3*。
- en: '![](img/B21964_10_03.jpg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21964_10_03.jpg)'
- en: Figure 10.3 – The chance of failure increases at each turn
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – 每次操作失败的概率都会增加
- en: When an LLM is right 60% of the time, failure is 95% likely within six interactions.
    So, to move that bar up to 97% or greater, a lot of testing and work is needed.
    Generating the correct set of test cases helps monitor for issues. Because of
    monitoring, moving to a new model can be evaluated by applying the test cases
    to the latest model. It’s okay when everything changes with a new model or version,
    as indicated by the differences between 3.5, 4o, and 4o-mini (it returned results
    similar to 4o). However, with mini being only 15% of the cost of 3.5, it would
    make sense to move if this was a real production system once verified against
    the test cases. There is no guarantee of backward compatibility with LLMs. The
    scale of testing efforts can easily reach 100’s of thousands of use cases. An
    example of a testing matrix will make this clear.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个LLM正确率达到60%时，在六次交互内失败的概率为95%。因此，要将这个指标提高到97%或更高，需要大量的测试和工作。生成正确的测试用例集有助于监控问题。由于监控，可以通过将测试用例应用于最新模型来评估迁移到新模型。当新模型或版本发生变化时，这是可以接受的，正如3.5、4o和4o-mini之间的差异所示（它返回了与4o相似的结果）。然而，由于mini的成本仅为3.5的15%，一旦通过测试用例验证，迁移到实际生产系统是有意义的。LLM没有向后兼容的保证。测试努力的规模可以轻松达到数十万个用例。一个测试矩阵的例子将使这一点更加清晰。
- en: Testing matrix approach
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试矩阵方法
- en: Because these projects impact human performance, the traditional **quality assurance**
    (**QA**) team must be set up to create an effective test matrix. They can develop
    automation and manage the process. Design owners can handle the examples and make
    sure the failures are documented.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些项目影响人类性能，必须建立传统的**质量保证**（**QA**）团队来创建有效的测试矩阵。他们可以开发自动化并管理流程。设计负责人可以处理示例并确保记录失败情况。
- en: With an LLM, monitoring will uncover conversations not initially covered by
    the test cases. It will happen. Just consider how to prioritize improvements for
    them, like any other issue. Once they are known, consider whether they are worth
    including in tests.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM，监控将揭示测试用例最初未涵盖的对话。这是会发生的。只需考虑如何优先考虑对这些改进的改进，就像任何其他问题一样。一旦它们被了解，考虑它们是否值得包含在测试中。
- en: 'One can test each skill in isolation, and then when combining a collection
    of skills, some issues might arise. A **skill** is something the model can do.
    It could be connected to an inventory system, report production numbers, or schedule
    an appointment. These are skills. One approach is to build the base model only
    with content from one isolated area, thus allowing us to gauge its effectiveness
    in isolation. Do this for each area. Then, combine all (or sets of areas) retesting
    to understand better the overlap or complexities between the data ingested. The
    QA team will be busy setting up these test harnesses. Product people will be busy
    understanding the results. This example assumes a single model approach to handle
    all interactions, but we have provided multiple examples where a multi-modal approach
    is a better solution. Your choice. The concept of the types of tests still applies.
    It is valuable to have different kinds of test suites. We can review the types
    of tests for conversational interactions:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 可以单独测试每个技能，然后当组合一系列技能时，可能会出现一些问题。**技能**是模型可以执行的事情。它可以与库存系统连接，生成报告数字，或安排预约。这些都是技能。一种方法是用一个孤立区域的全部内容来构建基础模型，这样我们就可以评估其在孤立状态下的有效性。为每个区域都这样做。然后，结合所有（或一系列区域）重新测试，以更好地理解摄入数据之间的重叠或复杂性。QA
    团队将忙于设置这些测试工具。产品人员将忙于理解结果。这个例子假设采用单一模型方法来处理所有交互，但我们已经提供了多个例子，其中多模态方法是一个更好的解决方案。您的选择。测试类型的概念仍然适用。拥有不同类型的测试套件很有价值。我们可以审查对话交互的测试类型：
- en: '**In-domain**: Questions the skill area should understand and be able to answer.
    They are the meat of the meal, the main course. Get these right:'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**域内**：技能区域应该理解和能够回答的问题。它们是餐点的主要内容，是主菜。要正确处理这些：'
- en: '[PRE11]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Out-of-domain**: A collection of questions the skill would not be expected
    to understand based on lack of access to the necessary business data. Because
    they are not for *this* business. However, they are real questions and sound similar
    to the customer’s needs, just in the wrong context. The general model might want
    to answer these. They are distractors to the in-domain questions. Hence, each
    area of interest will have its collection of out-of-domain items. These examples
    might sound too similar to an LLM because the structure and words seem familiar,
    such as (stock) orders, download (statements), account (details), transfer (money),
    check (status), and (order) history:'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**域外**：一组基于缺乏必要业务数据访问而预期技能无法理解的问题。因为它们不是针对**这个**业务的。然而，这些问题是真实的，听起来与客户的需求相似，只是处于错误的环境中。通用模型可能想要回答这些问题。它们是域内问题的干扰项。因此，每个感兴趣的领域都将有其域外项目的集合。这些例子可能听起来与大型语言模型（LLM）很相似，因为结构和单词看起来很熟悉，例如（股票）订单、下载（报表）、账户（详情）、转账（资金）、检查（状态）和（订单）历史：'
- en: '[PRE12]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Recognize that these examples sound close but are unrelated to Alligiance. They
    sound confusing in the context of this bank. They are close, and a customer might
    not even know they can’t ask this skill about these problems. Here is a little
    more about the concepts of out-of-domain understanding.
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 认识到这些例子听起来很接近，但实际上与联盟无关。在银行的这个背景下，它们听起来很令人困惑。它们很接近，客户甚至可能不知道他们不能就这些问题询问这项技能。这里有一些关于域外理解概念更多的信息。
- en: 'Article: [Out of Domain Detection](https://www.elevait.de/blog/out-of-domain-detection)
    ([https://www.elevait.de/blog/out-of-domain-detection](https://www.elevait.de/blog/out-of-domain-detection))'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文章：[域外检测](https://www.elevait.de/blog/out-of-domain-detection) ([https://www.elevait.de/blog/out-of-domain-detection](https://www.elevait.de/blog/out-of-domain-detection))
- en: '**Random**: Garbage and unrelated items that should not result in a helpful
    response. It could be from a stuck keyboard, poor speech-to-text, someone’s phone
    in their pocket doing random stuff, or silly, irrelevant questions:'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机**：垃圾和不相关的内容，不应导致有价值的响应。可能是由于键盘卡住、语音转文字质量差、某人口袋里的手机在随机操作，或者愚蠢、不相关的问题：'
- en: '[PRE13]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: These are the same random questions for each skill.
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些是每个技能相同的随机问题。
- en: '**Neighbor**: The collection of in-domain test cases from all *other* skills
    used to break the area of interest. Does the question from one area overlap and
    cause a different and wrong response? So, is this an issue when all this expertise
    is available in one **user interface** (**UI**)? It should be addressed if the
    LLM can’t resolve this disambiguation issue. It might fix it like in this example:'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**邻居**：从所有*其他*技能中收集的领域内测试用例的集合，用于打破感兴趣的区域。一个问题来自一个区域是否重叠并导致不同的错误响应？所以，当所有这些专业知识都集中在**用户界面**（**UI**）中时，这是一个问题。如果LLM无法解决这种歧义问题，应该解决它。它可能像在这个例子中一样修复它：'
- en: I need the weekly report
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要周报
- en: '[PRE14]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The full sales report
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的销售报告
- en: '[PRE15]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If only one feature contained a weekly report, there would be clarity. However,
    once multiple features include reports, see how some test cases from one solution
    area might impact others. Think in vector space. All of these questions asking
    for reports can be very similar. Hence, they are neighbors.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 如果只有一个特性包含周报，那么会有清晰度。然而，一旦多个特性包含报告，看看一个解决方案区域的某些测试用例如何影响其他区域。在向量空间中思考。所有这些问题要求报告都可以非常相似。因此，它们是邻居。
- en: '**Language**: Consider test cases for specific languages. One starts by translating
    existing questions into other languages. Still, as mentioned in [*Chapter 5*](B21964_05_split_000.xhtml#_idTextAnchor108),
    *Defining the Desired Experience*, consider the unique needs of the language,
    cultures, and nuisances that would necessitate original content for that specific
    language. Assume at least 10% of test cases for a language will be unique.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言**：考虑特定语言的测试用例。一开始是将现有问题翻译成其他语言。然而，如[*第5章*](B21964_05_split_000.xhtml#_idTextAnchor108)中提到的，*定义期望体验*，考虑该语言、文化和细微差别，这些都需要为该特定语言创建原创内容。假设至少10%的测试用例对该语言将是独特的。'
- en: Building the Matrix
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建矩阵
- en: So, what would a test matrix look like for each collection of use cases? A bank
    might have seven main business areas that require support. Based on the frequency
    of use, they will scale up tests for the big or complex areas. To test each area
    with the types of tests explained, it might look like *Table 10.6*.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，每个用例集合的测试矩阵会是什么样子？一家银行可能有七个主要业务领域需要支持。根据使用频率，他们将扩大对大或复杂领域的测试。为了使用所解释的类型测试每个区域，它可能看起来像*表10.6*。
- en: '| **Product Areas** | **In-domain** | **Out-of- domain** | **Random** | **Neighbors**
    |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| **产品领域** | **领域内** | **领域外** | **随机** | **邻居** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Account Statements** | 303 | 1002 | 400 | 1,129 |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| **账户报表** | 303 | 1,002 | 400 | 1,129 |'
- en: '| **Bank Transfers** | 78 | 423 | 400 | 1,354 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| **银行转账** | 78 | 423 | 400 | 1,354 |'
- en: '| **Account Setup** | 150 | 301 | 400 | 1,282 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| **账户设置** | 150 | 301 | 400 | 1,282 |'
- en: '| **Deposits** **and Withdrawals** | 201 | 400 | 400 | 1,231 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| **存款** **和取款** | 201 | 400 | 400 | 1,231 |'
- en: '| **Training** | 50 | 375 | 400 | 1,382 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| **训练** | 50 | 375 | 400 | 1,382 |'
- en: '| **Trading Stocks** **and Bonds** | 605 | 1320 | 400 | 827 |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| **交易股票** **和债券** | 605 | 1,320 | 400 | 827 |'
- en: '| **Rewards** | 45 | 400 | 400 | 1,387 |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| **奖励** | 45 | 400 | 400 | 1,387 |'
- en: '| **Sub-Totals (17,045)** | 1,432 | 4,221 | 2,800 | 8,592 |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| **子总计（17,045）** | 1,432 | 4,221 | 2,800 | 8,592 |'
- en: '| **Ten Language** **Test (*10)** | 14,320 | 42,210 | 28,000 | 85,920 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| **十语言测试（10%）** | 14,320 | 42,210 | 28,000 | 85,920 |'
- en: '| **Unique Language** **Tests (10%)** | 1,432 | 4,221 | 0 | 0 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| **独特语言测试（10%）** | 1,432 | 4,221 | 0 | 0 |'
- en: '| **All Test** | **193,148** |  |  |  |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| **所有测试** | **193,148** |  |  |  |'
- en: Table 10.6 – Matrix for test cases to validate an extensive conversational AI
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.6 – 用于验证广泛对话式人工智能的测试用例矩阵
- en: 'Trading Stocks and Bonds is the most critical area with the most test cases.
    The rewards program is the smallest. Notice the subtotaled tests per area. Then,
    assuming ten supported translations, the number of tests grows. The number of
    neighbor tests varies because it is the sub-total of all in-domain tests minus
    the number of in-domain tests for this category. The language tests are assuming
    cloning tests 1-to-1 per language for a deployment in ten foreign languages. There
    is an additional row for up to 10% of language tests that might be specific to
    the locality. As discussed earlier, it is ok to only go this far with testing
    in some languages regarding how much support to provide per language. This is
    why our English testing of 17,045 test cases grows to almost 200 K with language
    support. Here are some tips for scaling language tests:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 交易股票和债券是最关键的领域，测试案例最多。奖励计划是最小的。注意每个领域的细分测试。然后，假设有十种支持的翻译，测试数量会增长。邻近测试的数量会有所变化，因为它是在域内测试的子总和中减去该类别的域内测试数量。语言测试假设在十个外语部署中，每种语言进行一对一的克隆测试。对于可能特定于当地语言的10%的语言测试，还有一个额外的行。如前所述，在某些语言中，只进行到这一步的测试是可以接受的，关于每种语言提供多少支持。这就是为什么我们的17,045个测试案例的英语测试随着语言支持的增长而增加到近200
    K。以下是一些关于扩展语言测试的提示：
- en: '**Only translate currency indirectly**: “I took a 25$ Uber ride today,” translated
    into Japanese, might change the currency symbol to Yen (¥). But 25¥ is not a meaningful
    value for a cab ride (about 25 cents in dollars or Euros), so training a system
    with too many wrong numbers might confuse the model.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅间接翻译货币**：“我今天乘坐了25美元的Uber”，翻译成日语可能会将货币符号改为日元（¥）。但25¥对于出租车来说不是一个有意义的值（大约是美元或欧元中的25美分），因此用太多错误数字训练系统可能会使模型困惑。'
- en: '**Use localized values**: Recall our examples of Uber not being universal.
    A direct translation of Uber would be Uber in Japanese, but a better example is
    to use Go, the Japanese taxi-hailing app, for the training example.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用本地化值**：回想一下我们关于Uber不是普遍适用的例子。Uber的直接翻译将是日语中的Uber，但更好的例子是使用Go，这是日本的出租车叫车应用，作为训练示例。'
- en: '**Use idiomatic language**: Both test cases and sample data can benefit from
    how customers communicate. For example, localizing in the USA for dollars and
    training on bucks and cash but not necessarily using more esoteric slang such
    as moolah, coin, cheddar, dough, or greenbacks makes sense. Overtraining might
    cause unexpected consequences. To continue with our Japanese example, train on
    JPY (the code for the Yen), but the Japanese Yen doesn’t have slang terms. Hence,
    one-to-one translation of idiomatic language is not expected.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用习惯用语**：测试案例和样本数据都可以从客户如何沟通中受益。例如，在美国本地化美元，在美元、现金上进行训练，但不必一定使用更神秘的俚语，如moolah、coin、cheddar、dough或greenbacks，这是有意义的。过度训练可能会产生意外的后果。继续我们的日本例子，训练JPY（日元的代码），但日本日元没有俚语。因此，习惯用语的逐字翻译是不预期的。'
- en: '**The scale of tests correlates with quality**: For example, test whether 20%
    is sufficient for an infrequently used language. LLMs work better in some languages
    because the base model has more training data. Don’t expect magic, especially
    when it comes to enterprise integrations. Translation steps are needed between
    APIs and responses.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试规模与质量相关联**：例如，测试20%是否足够用于不常使用的语言。由于基础模型有更多的训练数据，LLMs在某些语言上表现更好。不要期望有魔法，尤其是在企业集成方面。API和响应之间需要翻译步骤。'
- en: Don’t let the number of tests sound scary. For many enterprise applications,
    these numbers are low. I know one team now has about 500,000 tests, just in English.
    Automation and QA engineers will be busy maintaining and working with the data
    and product team to grow this set. Don’t make tests to make tests. Use the tests
    to find gaps in the LLM’s understanding. Recall that every change in the model
    or addition of new data or feature areas will change the quality of the solution.
    During this part of your LLM journey, **always be caring** (and feeding) (**ABC**,
    if a Glengarry Glen Ross reference is ok. Google it). The way to do this is to
    improve retrieval.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让测试的数量听起来令人恐惧。对于许多企业应用来说，这些数字很低。我知道现在有一个团队大约有500,000个测试，仅限于英语。自动化和QA工程师将忙于维护和与数据团队和产品团队合作以扩大这个集合。不要为了测试而测试。使用测试来发现LLM理解中的差距。回想一下，模型或新数据或新功能区域的任何变化都会改变解决方案的质量。在您的LLM之旅的这一部分，**始终关心**（并喂养）（**ABC**，如果Glengarry
    Glen Ross的引用是可以接受的。谷歌一下）。这样做的方式是提高检索能力。
- en: Improving retrieval
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提高检索能力
- en: 'I reviewed a short video for the book. The explanations of the concepts taken
    from the RAGAs documentation are used in this video. They start using the data
    results to improve the overall solution. Greg Loughnane, PhD, slows down when
    he gets the good stuff after Chris Alexiuk whips through setting up the environment
    in the first five minutes of the video. Here is my summary of UX-related elements:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我为这本书审查了一段简短的视频。视频中使用的概念解释来自RAGAs文档。他们开始使用数据结果来改进整体解决方案。在Chris Alexiuk在视频的前五分钟内快速设置环境之后，Greg
    Loughnane博士在获得好东西时会放慢速度。以下是关于用户体验相关元素的总结：
- en: Improve one metric at a time
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一次改进一个指标
- en: Focusing on retriever improvements helps with the generation
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于检索器改进有助于生成
- en: Try a different retriever to get better context (@24 minutes) – expanding the
    capture of material before and after the matching context.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的检索器以获得更好的上下文（@24分钟）——扩展匹配上下文之前和之后的内容捕获。
- en: See how context relevancy goes down as the size of the context window goes up;
    chunk size matters (this makes sense since there is more unrelated context in
    the denominator of the score) (@31 minutes)
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看看上下文的相关性如何随着上下文窗口大小的增加而下降；块大小很重要（这很有道理，因为分数的分母中有更多无关的上下文）(@31分钟)
- en: Other tools, such as LangChain and LlamaIndex, provide evaluation metrics
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他工具，如LangChain和LlamaIndex，提供评估指标
- en: 'Video: [Tutorial for improving retrieval](https://www.youtube.com/watch?v=mEv-2Xnb_Wk)
    ([https://www.youtube.com/watch?v=mEv-2Xnb_Wk](https://www.youtube.com/watch?v=mEv-2Xnb_Wk))'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频：[改进检索教程](https://www.youtube.com/watch?v=mEv-2Xnb_Wk) ([https://www.youtube.com/watch?v=mEv-2Xnb_Wk](https://www.youtube.com/watch?v=mEv-2Xnb_Wk))
- en: It is all about improvements; data scientists can experiment with many options
    and variables to balance cost, performance, and quality. Learn to understand what
    they can change and how it impacts quality. Since this work is within the expertise
    of the data scientists, focus on understanding the quality of the results. There
    are other metrics of interest. Let’s give a little context on those.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都关乎改进；数据科学家可以尝试许多选项和变量来平衡成本、性能和质量。学会理解他们可以改变的内容以及它对质量的影响。由于这项工作属于数据科学家的专业领域，因此关注理解结果的质量。还有其他一些感兴趣的指标。让我们简要介绍一下这些指标。
- en: The wide range of LLM evaluation metrics
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 广泛的LLM评估指标
- en: RAGAs was reviewed because it is popular, has a good set of metrics, and is
    consistent with what traditional deterministic models use. But it is not the only
    approach. We mentioned DeepEval, but there are many more. Some of these approaches
    have specific metrics that sound appealing. Each vendor can have its approach,
    so let me expose a few more metrics that can add value to enterprise solutions
    in *Table 10.7*.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: RAGAs因其受欢迎、有一套良好的指标，并且与传统确定性模型使用的一致性而被审查。但并非只有这一种方法。我们提到了DeepEval，但还有更多。其中一些方法具有听起来很有吸引力的特定指标。每个供应商都可以有自己的方法，所以让我透露一些可以为企业解决方案增加价值的更多指标，见*表10.7*。
- en: '| **Metric** | **Purpose** | **Applications** | **References** |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **目的** | **应用** | **参考** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Rouge** | To compute the effectiveness of auto-generated summaries | Books,
    technical Documentation, articles, marketing material, and so on | Article: [How
    to Use Rouge 2.0](https://kavita-ganesan.com/rouge2-usage-documentation/) ([https://kavita-ganesan.com/rouge2-usage-documentation/](https://kavita-ganesan.com/rouge2-usage-documentation/))
    |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| **Rouge** | 计算自动生成摘要的有效性 | 书籍，技术文档，文章，营销材料等 | 文章：[如何使用Rouge 2.0](https://kavita-ganesan.com/rouge2-usage-documentation/)
    ([https://kavita-ganesan.com/rouge2-usage-documentation/](https://kavita-ganesan.com/rouge2-usage-documentation/))
    |'
- en: '| **Human Evaluation** | To ensure user interaction quality | Conversational
    interactions | See [*Chapter 3*](B21964_03.xhtml#_idTextAnchor058), *Identifying
    Optimal Use Cases* *for ChatGPT* |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| **人工评估** | 确保用户交互质量 | 对话式交互 | 参见[*第3章*](B21964_03.xhtml#_idTextAnchor058)，*识别ChatGPT的最佳用例*
    |'
- en: '| **Age-specific** **Suitability** | To match reading or educational levels
    | Curriculum tutoring, coaching | Manual review by experts and content filtering
    tools |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| **年龄特定** **适用性** | 匹配阅读或教育水平 | 课程辅导，指导 | 专家手动审查和内容过滤工具 |'
- en: '| **Toxicity Reduction** | To maintain style and tone for public-facing and
    public-sector solutions | All generative output including recommendations | Toxicity
    and bias detection software, sentiment analysis |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| **毒性降低** | 维护面向公众和公共部门的解决方案的风格和语气 | 所有生成输出，包括推荐 | 毒性及偏见检测软件，情感分析 |'
- en: '| **Perplexity** | How probable a piece of generated text is based on its training
    | Content generation | Article: [Perplexity and Burstiness](https://guides.library.unlv.edu/c.php?g=1361336&p=10054021)
    ([https://guides.library.unlv.edu/c.php?g=1361336 &p=10054021](https://guides.library.unlv.edu/c.php?g=1361336&p=10054021))
    |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| **困惑度** | 基于其训练，生成的文本的可能性 | 内容生成 | 文章：[困惑度和突发性](https://guides.library.unlv.edu/c.php?g=1361336&p=10054021)
    ([https://guides.library.unlv.edu/c.php?g=1361336 &p=10054021](https://guides.library.unlv.edu/c.php?g=1361336&p=10054021))
    |'
- en: '| **Burstiness** | The repetition of words or phrases in a document | Detect
    whether AI or a human wrote content | Product: [Originality AI](https://originality.ai/blog/chat-zero)
    ([https://originality.ai/blog/chat-zero](https://originality.ai/blog/chat-zero))
    |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| **突发性** | 文档中单词或短语的重复 | 检测内容是由AI还是人类编写的 | 产品：[Originality AI](https://originality.ai/blog/chat-zero)
    ([https://originality.ai/blog/chat-zero](https://originality.ai/blog/chat-zero))
    |'
- en: Table 10.7 – Other evaluation metrics
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.7 – 其他评估指标
- en: 'Some of *Table 10.7* came from Aisera: [LLM Evaluation: Metrics and Benchmarking
    Performance](https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance)
    ([https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance](https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance)).'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 一些来自Aisera的*表10.7*内容：[LLM评估：指标和基准性能](https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance)
    ([https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance](https://aisera.com/blog/llm-evaluation/#5-benchmarking-steps-for-a-better-evaluation-of-llm-performance))。
- en: 'All metrics have a good reason for being collected and analyzed. Frameworks
    cost time and money to maintain, and some data-centric metrics have value because
    they impact costs. The number of LLM conversations per day or the number of tokens
    used helps with budgeting. Consider how to get value out of these metrics to aid
    in understanding customers’ needs. Microsoft also has a few good articles about
    data-centric metrics. Here are some metrics with usability implications:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 所有指标都有收集和分析的合理原因。框架的维护需要时间和金钱，而一些以数据为中心的指标具有价值，因为它们会影响成本。每天进行的LLM对话数量或使用的标记数量有助于预算编制。考虑如何从这些指标中获得价值，以帮助理解客户的需求。微软也有一些关于以数据为中心的指标的好文章。以下是一些具有可用性影响的指标：
- en: '**Concurrent users**: This can sometimes be correlated with performance (too
    many simultaneous users can slow some services, impacting service level and customer
    satisfaction). Recall that there is no such thing as a slow, *good* UI. In the
    case of chat, where human agents might be available for hand-offs, response time
    will be impacted if human agent availability doesn’t match concurrent user metrics.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发用户**：这有时可能与性能相关（过多的同时在线用户可能会减慢某些服务，影响服务水平和客户满意度）。请记住，没有所谓的“慢但好”的用户界面。在聊天的情况下，如果有人工代理可以进行交接，那么如果人工代理的可用性不匹配并发用户指标，响应时间将会受到影响。'
- en: '**Token usage**: Token usage = cost. As mentioned in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134),
    *Gathering Data – Content is King*, look for opportunities to use less expensive
    models while maintaining or improving quality. This means lower customer costs
    or the ability to offer free or less costly tiers to serve a wider audience.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记使用**：标记使用=成本。如[*第6章*](B21964_06_split_000.xhtml#_idTextAnchor134)“收集数据
    – 内容为王”中所述，寻找使用成本较低但保持或提高质量的机会。这意味着降低客户成本或能够提供免费或成本较低的层级以服务更广泛的受众。'
- en: '**Filtering interventions**: If the process has guardrails for handling quality
    bias and inappropriateness, monitor the rate of these interventions and review
    them to decide whether there is anything to do about them. We mentioned that with
    enterprise software, typically for authorized authenticated users, abhorrent behaviors
    are rarely problematic, unlike in social media. It can happen, and blocking it
    is excellent; however, if work is needed to avoid these conditions or to adjust
    triggers to poorly timed interventions (e.g., being too strict for something that
    might be a perfectly reasonable request), look at these articles.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤干预**：如果流程有处理质量偏差和不适当行为的护栏，则监控这些干预措施的发生率，并审查它们以决定是否需要对此采取任何措施。我们提到，在企业软件中，通常对于授权的认证用户，令人厌恶的行为很少成为问题，这与社交媒体不同。这种情况可能发生，阻止它是很好的；然而，如果需要避免这些条件或调整触发器以避免不合适的时间干预（例如，对可能完全合理的请求过于严格），请查看这些文章。'
- en: '**Article**: [How to Evaluate LLMs: A Complete Metric Framework](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/)
    ([https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/))'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**文章**：[如何评估LLMs：完整的指标框架](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/)
    ([https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/how-to-evaluate-llms-a-complete-metric-framework/))'
- en: '**Article**: [Patterns of Trustworthy Experimentation: During-Experiment Stage](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/)
    ([https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/))'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**文章**：[可信赖实验模式：实验阶段](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/)
    ([https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/))'
- en: These are the tools to understand a variety of data-driven metrics, but there
    is also the softer side, the human customer, in the loop. Although this data likely
    impacts our customers in various ways, it is helpful to understand a customer’s
    perception. Time to explore some usability metrics to show how the system works
    in the customer’s eyes.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是理解各种数据驱动指标的工具，但循环中还有更软的一面，即人类客户。尽管这些数据可能以各种方式影响我们的客户，但了解客户的感知是有帮助的。现在是时候探索一些可用性指标，以展示系统在客户眼中的运作方式。
- en: Monitor with usability metrics
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用可用性指标进行监控
- en: Earlier chapters explored ways to evaluate and find issues. This can be done
    by using a checklist, a particular set of rules expected for a UX, or a set of
    heuristics, a collection of guiding principles that, when applied correctly, helps
    expose issues quickly. The last chapter covered those methods, leaving a few more
    exciting metrics.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 早期章节探讨了评估和发现问题的方法。这可以通过使用清单、一套期望的UX规则或一套启发式原则来实现，这些原则在正确应用时有助于快速暴露问题。最后一章涵盖了这些方法，留下了更多令人兴奋的指标。
- en: There are multiple ways to interpret how the system is doing. Since surveys,
    interviews, and other subjective metrics were covered, let’s address measuring
    quality changes over time. This means measuring the fidelity of the experience
    by asking customers to answer specific questions, resulting in a **net promoter
    score** (**NPS**), a single-question survey, the more robust and time-consuming
    ten-question **software usability scale** (**SUS**) metric, or other forms of
    **customer satisfaction** (**CSAT**) surveys.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式可以解释系统的表现。由于已经涵盖了调查、访谈和其他主观指标，让我们来关注如何衡量随时间推移的质量变化。这意味着通过让客户回答具体问题来衡量体验的保真度，从而得出**净推荐值**（**NPS**）、一个单问题调查、更稳健且耗时的十问题**软件可用性量表**（**SUS**）指标，或其他形式的**客户满意度**（**CSAT**）调查。
- en: First, realize why it is helpful to measure usability with a score. It will
    only give a broad sense of how the system is performing. It won’t uncover design
    flaws (unless there are open-ended follow-up questions). There are two good reasons
    to do this. First, it is easy to compare to other products and see if the solution
    meets expectations and exceeds what is found competitively, and second, to establish
    a baseline to redo these evaluations over time to measure progress. This means
    asking randomly for feedback, typically after interacting with the product. There
    will be variability because the same customer isn’t always asked for feedback,
    so more data is needed to estimate accurately. For simple questions such as NPS,
    this is an easy ask. It takes a little more effort to code and request an SUS
    score. These can be supplemented at any time with more expository and open-ended
    questions.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，认识到使用评分来衡量可用性是有帮助的。它只会给出系统性能的总体感觉。它不会揭露设计缺陷（除非有开放式后续问题）。这样做有两个很好的理由。首先，它很容易与其他产品进行比较，看看解决方案是否满足预期，并且是否超过了竞争中发现的内容，其次，为了建立一个基线，随着时间的推移重新进行这些评估以衡量进展。这意味着在通常与产品互动后随机请求反馈。由于同一客户并不总是被要求提供反馈，因此需要更多的数据来准确估计。对于像NPS这样的简单问题，这是一个简单的要求。编码和请求SUS评分需要更多的努力。这些可以在任何时间通过更多的解释性和开放式问题进行补充。
- en: Net Promoter Score (NPS)
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 净推荐者评分（NPS）
- en: '**NICE Satmetrix** is the co-developer and owner of the NPS. It is well known
    as a simple benchmark of brand quality. Because of its simplicity, it has also
    been adapted for use in product analysis. Nominally, a business’s customer is
    asked the following question:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '**NICE Satmetrix**是NPS的共同开发者和所有者。它因其简单性而广为人知，作为品牌质量的简单基准。由于其简单性，它也被用于产品分析。名义上，企业的客户会被问以下问题：'
- en: '[PRE16]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This classic question is simple to ask and easy to calculate. It is a broad
    stroke, and it can be adapted:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这个经典问题简单易问，也容易计算。这是一个粗略的描述，它可以被适应：
- en: '[PRE17]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Adapt the wording to your product. The *Retently* website does an excellent
    job of explaining how to tweak this wording to make it work for your use case.
    I won’t repeat this material here. Read the article if you are ready to deploy
    NPS.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 将措辞调整到你的产品上。*Retently*网站出色地解释了如何调整措辞以使其适用于你的用例。我不会在这里重复这些内容。如果你准备好部署NPS，请阅读这篇文章。
- en: 'Article: [NPS and how to modify the survey](https://www.retently.com/blog/nps-survey-templates/)
    ([https://www.retently.com/blog/nps-survey-templates/](https://www.retently.com/blog/nps-survey-templates/))'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[NPS和如何修改调查](https://www.retently.com/blog/nps-survey-templates/) ([https://www.retently.com/blog/nps-survey-templates/](https://www.retently.com/blog/nps-survey-templates/))
- en: Deploy a version of this question based on the product or service. A typical
    pattern is to ask for feedback for every 50th customer with a simple dialog box
    prompt, a side panel, or even inline, depending on the design. It is optional
    to be answered. Some customers won’t participate. The same customer is typically
    not asked again; tag their account to avoid over-asking survey questions. Automate
    the aggregation of results (hopefully, this is a random sample and needs to be
    correlated with the release number) to generate the NPS. *Table 10.8* covers design
    patterns for gathering the NPS or SUS scores.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 根据产品或服务部署此问题的版本。一个典型的模式是每50个客户就通过一个简单的对话框提示、侧面板，甚至在设计允许的情况下直接内联请求反馈。回答是可选的。一些客户可能不会参与。通常不会再次询问同一客户；标记他们的账户以避免过度询问调查问题。自动汇总结果（希望这是一个随机样本，需要与发布号相关联）以生成NPS。*表10.8*涵盖了收集NPS或SUS评分的设计模式。
- en: '| **Use Case** | **Deployment Method** |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| **用例** | **部署方法** |'
- en: '| --- | --- |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Conversational** **chat assistant** | Inline, when a clear ending to the
    conversation is known |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| **对话式** **聊天助手** | 在对话有明确结束点时内联 |'
- en: '| **Conversational** **chat assistant** | As a dialog box when a chat is closed
    |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| **对话式** **聊天助手** | 在聊天结束时作为对话框 |'
- en: '| **Conversational** **chat assistant** | After a feedback flow (such as from
    a Give Feedback icon or label) |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| **对话式** **聊天助手** | 在反馈流程之后（例如，来自“提供反馈”图标或标签） |'
- en: '| **Recommender** | At the end of a session |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| **推荐者** | 在会话结束时 |'
- en: '| **Recommender** | At the end of any feedback process for evaluating the recommendation
    |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| **推荐者** | 在评估推荐的任何反馈过程结束时 |'
- en: '| **Web or** **application UI** | At the end of a transaction or significant
    flow |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| **Web或** **应用程序UI** | 在交易或重要流程结束时 |'
- en: '| **Phone tree** | At the end of a transaction or significant flow (i.e., do
    have time for a one-question survey?) |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| **电话树** | 在交易或重要流程结束时（即，是否有时间进行一题调查？） |'
- en: '| **SMS,** **Slack, Teams** | After a specific amount of usage |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| **短信，Slack，Teams** | 在使用一定数量后 |'
- en: '| **Backend or** **hidden AI** | After a specific amount of usage, or the end
    of a significant flow |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| **后端或** **隐藏AI** | 在使用一定数量后，或重要流程的结束时 |'
- en: '| **Via Email** | Post-purchase, interaction, or support |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| **通过电子邮件** | 购买后，互动或支持后 |'
- en: '| **On receipts, feedback cards at points of sales, or** **with service** |
    Via a QR code |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| **在收据上，销售点的反馈卡或** **服务中** | 通过二维码 |'
- en: '| **Phone calls** | Via human or automated follow-up at the end of a call (You
    will be transferred to answer a brief one-question survey about your experience
    today) |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| **电话通话** | 通过通话结束时的人工或自动跟进（您将被转接以回答关于您今天体验的简短一题调查） |'
- en: '| **In** **real-life interactions** | By asking the customer, and likely entering
    the score and any feedback manually |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| **在** **现实生活中的互动中** | 通过询问客户，并可能手动输入分数和任何反馈 |'
- en: Table 10.8 – Approaches to deploying NPS
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.8 – 部署NPS的方法
- en: Recall our discussions about bias. It will be in the results. Sometimes, people
    are people pleasers, so they will not give good feedback when prompted in person.
    Their most recent interaction will color their input. If the interaction were
    a failure, it would impact the data. Ensure a good sample; for example, expect
    skewed results if feedback is gathered from one channel that only handles the
    closing of accounts.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们关于偏差的讨论。它将在结果中体现。有时，人们是取悦他人的人，所以当被要求亲自提供反馈时，他们可能不会给出好的反馈。他们最近的互动将影响他们的输入。如果互动是失败的，它将影响数据。确保有一个好的样本；例如，如果反馈是从只处理账户关闭的一个渠道收集的，那么预期结果会偏斜。
- en: Biases can be introduced in the way questions are asked. I have seen some examples
    that color code the number choices for a survey question, biasing the results.
    Use neutral colors for all options to reduce bias in survey questions. Some customers
    might hesitate to give a poor score because it is color-coded red, as shown in
    *Figure 10**.4*. Use a generic Likert scale, as discussed previously. However,
    once they select the score, asking an optional follow-up question is okay. This
    will give context to their reasoning.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的提问方式可能会引入偏差。我见过一些例子，它们为调查问题的数字选择项着色，从而影响了结果。为了减少调查问题的偏差，请对所有选项使用中性颜色。一些客户可能会犹豫给出低分，因为它是用红色着色的，如图*图10**.4*所示。使用之前讨论过的通用李克特量表。然而，一旦他们选择了分数，询问一个可选的后续问题是可以的。这将为他们提供推理的背景。
- en: '![](img/B21964_10_04.jpg)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21964_10_04.jpg)'
- en: Figure 10.4 – Example of an NPS question – use neutral colors for the scale
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – NPS问题的示例 – 使用中性颜色进行评分
- en: 'The colors classify the results; don’t use the colors in a customer survey.
    Scores in the red are detractors, people who would not be advocates and would
    likely turn away from using the product. People scoring 7 or 8 are passive; they
    won’t get in the way but are not a big help. With little thought, they would switch
    channels or even products. That leaves 9s and 10s promoters, hence the name. Promoters
    who advocate for brands or products enthusiastically recommend the solution to
    others. The math is as follows:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色分类结果；不要在客户调查中使用颜色。红色分数是负面因素，这些人不会成为倡导者，可能会远离使用该产品。得分为7或8的人是被动者；他们不会妨碍，但也不是很大帮助。稍加思考，他们就会切换渠道或甚至产品。这留下了9分和10分的推荐者，因此得名。推荐者会热情地为品牌或产品辩护，并向他人推荐解决方案。计算如下：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>P</mi><mi>r</mi><mi>o</mi><mi>m</mi><mi>o</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo>−</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>D</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>R</mi><mi>e</mi><mi>s</mi><mi>p</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></mfrac><mi
    mathvariant="normal">*</mi><mn>100</mn></mrow></mrow></math>](img/24.png)'
  id: totrans-433
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>P</mi><mi>r</mi><mi>o</mi><mi>m</mi><mi>o</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo>−</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>D</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>s</mi></mrow><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>R</mi><mi>e</mi><mi>s</mi><mi>p</mi><mi>o</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></mfrac><mi
    mathvariant="normal">*</mi><mn>100</mn></mrow></mrow></math>](img/24.png)'
- en: The range is from -100 to 100\. It is fair to gauge your product against other
    brands. Simplestat reports that the average score in the enterprise space is 44\.
    *Table 10.9* gives examples of brands and some samples of NPS. Even well-loved
    brands are in the 60s and 70s. Brands will generally have significantly higher
    scores than services or products. Consider that when deciding how good a product
    is scoring. Comparing releases, channels, or competitive products gives context
    to scores.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 范围是从-100到100。将你的产品与其他品牌进行比较是公平的。Simplestat报告称，企业领域的平均分数是44。*表10.9*提供了品牌和NPS的一些示例。即使是深受喜爱的品牌，其分数也在60和70之间。品牌通常会比服务或产品有显著更高的分数。在决定产品的评分好坏时，请考虑这一点。比较发布、渠道或竞争产品可以为分数提供背景。
- en: '![](img/B21964_10_e.png)'
  id: totrans-435
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21964_10_e.png)'
- en: Table 10.9 – Example NPSs for some products and services
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.9 – 一些产品和服务的示例NPS
- en: 'The scores are gathered from these resources:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 分数是从这些资源收集的：
- en: 'Article: [NPS scores for the table, Nice Source](https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf)
    ([https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf](https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf))'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[表格的NPS分数，Nice来源](https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf)
    ([https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf](https://info.nice.com/rs/338-EJP-431/images/NICE-Satmetrix-infographic-2018-b2c-nps-benchmarks-050418.pdf))
- en: 'Article: [NPS scores for the table, CustomerGauge Source](https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks)
    ([https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks](https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks))'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[表格的NPS分数，CustomerGauge来源](https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks)
    ([https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks](https://customergauge.com/benchmarks/blog/nps-saas-net-promoter-score-benchmarks))
- en: 'Article: [Typical NPS for a product](https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/)
    ([https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/](https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/))'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[产品的典型NPS](https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/)
    ([https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/](https://www.simplesat.io/understanding-feedback/net-promoter-score-benchmarks/))
- en: When at Oracle, we tested and shared an NPS with our customers for our Expense
    Assistant, and in its first release, it scored 55\. This was much higher than
    previous solutions; it was considered a great win. Still, there was room for improvement,
    so various methods were used, including those in this book.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在Oracle工作时，我们测试并分享了Expense Assistant的NPS给我们的客户，在其首次发布时，得分为55。这比之前的解决方案要高得多；这被认为是一个巨大的胜利。然而，仍有改进的空间，因此使用了包括本书中提到的各种方法。
- en: Use these example scores or explore other online posts for scores. It is just
    a general benchmark, but it is quick and easy. It doesn’t guide where to go next
    and typically requires 100s of responses (roughly) to be valid. However, it also
    only takes a few seconds of a customer’s time. There are also detractors concerning
    the validity of this approach. Just keep all that in mind when attempting to gather
    an NPS. I think it is worth the time. If the application is coded to gather insights,
    use NPS as one method in addition to a more robust method for feedback. All from
    the same UX approach!
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些示例分数或探索其他在线帖子中的分数。这只是一个通用基准，但快速且简单。它不指导下一步该去哪里，通常需要大约100个回复（大致）才能有效。然而，它也只需要客户几秒钟的时间。还有关于这种方法有效性的批评。在尝试收集NPS时，请记住所有这些。我认为这是值得的。如果应用程序被编码以收集见解，除了更稳健的反馈方法外，还可以将NPS作为另一种方法。所有这些都来自同一个UX方法！
- en: 'Article: [Net Promoter Score](https://en.wikipedia.org/wiki/Net_promoter_score)
    ([https://en.wikipedia.org/wiki/Net_promoter_score](https://en.wikipedia.org/wiki/Net_promoter_score))'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[净推荐值（NPS）](https://en.wikipedia.org/wiki/Net_promoter_score) ([https://en.wikipedia.org/wiki/Net_promoter_score](https://en.wikipedia.org/wiki/Net_promoter_score))
- en: Consider the SUS for a robust metric that provides more insight.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑SUS作为一个提供更多洞察力的稳健指标。
- en: SUS
  id: totrans-445
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SUS
- en: Where NPS is a one-question form, the **Software Usability Scale** (**SUS**)
    is a 10-question survey focused on usability. It is a reasonable way to measure
    UX or conversational quality. It can be deployed for UIs with recommenders, but
    it is hard to tease out specific details about one element, like a recommendation,
    without additional questions. It is a well-understood 100-point scale, so it is
    easy to interpret the scores.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: NPS是一个单问题形式，而**软件可用性量表（SUS**）是一个包含10个问题的调查，专注于可用性。这是一种衡量用户体验或对话质量的有效方式。它可以用于带有推荐器的UI，但如果没有额外的问题，很难挖掘出一个元素（如推荐）的具体细节。它是一个100分制的量表，因此很容易解释分数。
- en: 'It uses the Likert scale from one to five, ranging from “Strongly Disagree”
    to “Strongly Agree.” Imagine how these questions would feel when asked of them
    after using the application. The ten questions are as follows:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用从一到五的Likert量表，范围从“强烈不同意”到“强烈同意”。想象一下在使用应用程序后询问这些问题会是什么感觉。以下十道问题是这样的：
- en: I think that I would like to use this system frequently.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我认为我会经常使用这个系统。
- en: I found the system unnecessarily complex.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我发现这个系统过于复杂。
- en: I thought the system was easy to use.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我认为这个系统使用起来很简单。
- en: I think that I would need the support of a technical person to be able to use
    this system.
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我认为我需要技术人员的支持才能使用这个系统。
- en: I found the various functions in this system were well integrated.
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我觉得这个系统中的各种功能都得到了很好的整合。
- en: I thought there was too much inconsistency in this system.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我认为这个系统中的不一致性太多了。
- en: I would imagine that most people would learn to use this system very quickly.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我想象大多数人会很快学会使用这个系统。
- en: I found the system very cumbersome to use.
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我发现这个系统使用起来非常繁琐。
- en: I felt very confident using the system.
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我在使用这个系统时感到非常自信。
- en: I needed to learn a lot of things before I could get going with this system.
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我能够开始使用这个系统之前，我需要学习很多东西。
- en: 'The SUS questions follow one of the tricks explored in our survey discussion.
    Some questions are phrased in the positive (I feel very confident), and others
    are negative (I found the system very cumbersome) to avoid respondents answering
    on autopilot. Patrick Lawson points out in his blog post that these questions
    also have redundancy. This is common in surveys. The same question is asked slightly
    differently to create a more robust metric. Read more about the SUS in Patrick’s
    background article:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: SUS问题遵循我们在调查讨论中探讨的一种技巧。一些问题用积极的措辞（我感觉非常自信），而另一些问题则用消极的措辞（我发现这个系统非常繁琐），以避免受访者自动回答。帕特里克·劳森在他的博客文章中指出，这些问题也存在冗余。这在调查中很常见。同一个问题以略微不同的方式提出，以创建一个更稳健的指标。更多关于SUS的信息，请参阅帕特里克的后台文章：
- en: 'Article: [How to SUS out usability scores](https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/)
    by Patrick Lawson ([https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/](https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/))'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[如何使用SUS获取可用性评分](https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/)，作者：帕特里克·劳森([https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/](https://www.thinkcompany.com/blog/how-to-sus-out-usability-scores/))
- en: The calculation to get the 1 to 100 score is specific to this model. Subtract
    one from each of the positively oriented items’ scores, subtract the answers for
    the negatively oriented scores from five, and sum all these scores up. The sum
    multiplied by 2.5 gives the total. Compare the score to the outcomes in *Figure
    10**.5*, shared by Jeff Sauro from MeasuringU. He includes a comparison to NPS.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 获取1到100分的计算方法仅适用于此模型。从每个正向项目的分数中减去1，从负向项目的答案中减去5，然后将所有这些分数加起来。总和乘以2.5得到总分。将分数与杰夫·索尔从MeasuringU分享的*图10.5*中的结果进行比较。他包括了与NPS的比较。
- en: '![](img/B21964_10_05.jpg)'
  id: totrans-461
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21964_10_05.jpg)'
- en: Figure 10.5 – How to interpret a SUS score
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 如何解读SUS评分
- en: 'Jeff Sauro goes further into the technical scoring and implications of edits
    to the traditional wording. They point out that some of the work choices for the
    metric, which John Brooke developed in the 1980s, might seem old-fashioned. Read
    their post to learn more about the scoring and reliability of the metric. It is
    standing the test of time:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 杰夫·索尔进一步探讨了传统措辞的技术评分和影响。他们指出，1980年代约翰·布鲁克为该指标所做的某些工作选择可能显得过时。阅读他们的帖子了解更多关于评分和可靠性的信息。它经得起时间的考验：
- en: 'Article: [Is SUS Antiquated](https://measuringu.com/is-the-sus-too-antiquated/)
    ([https://measuringu.com/is-the-sus-too-antiquated/](https://measuringu.com/is-the-sus-too-antiquated/))'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[SUS过时了吗](https://measuringu.com/is-the-sus-too-antiquated/) ([https://measuringu.com/is-the-sus-too-antiquated/](https://measuringu.com/is-the-sus-too-antiquated/))
- en: 'Jeff breaks down the scores and details even further. I encourage exploring
    his posts, even if you have used the SUS for years:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 杰夫将分数和细节进一步拆解。即使你已经使用了SUS多年，我也鼓励你探索他的帖子：
- en: 'Article: [Interpreting a SUS Score](https://measuringu.com/interpret-sus-score/)
    ([https://measuringu.com/interpret-sus-score/](https://measuringu.com/interpret-sus-score/))'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[解读SUS评分](https://measuringu.com/interpret-sus-score/) ([https://measuringu.com/interpret-sus-score/](https://measuringu.com/interpret-sus-score/))
- en: Go to the government website for details on implementing the SUS.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 前往政府网站了解SUS实施详情。
- en: 'Article: [Software Usability Scale](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html)
    ([https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html))'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 文章：[软件可用性量表](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html)
    ([https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html))
- en: The SUS provides more details to drill into than the NPS but doesn’t provide
    granular information on what to fix. These methods can be followed up with open-ended
    questions to expose issues. This additional detail is valuable and actionable.
    The SUS score communicates quality over time and gives broad visibility to progress.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 与NPS相比，SUS提供了更多细节以便深入挖掘，但并不提供关于要修复什么的具体信息。这些方法可以通过开放式问题来跟进，以揭示问题。这些额外的细节是有价值且可执行的。SUS评分在时间上传达质量，并为进度提供了广泛的可见性。
- en: Refine with heuristic evaluation
  id: totrans-470
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过启发式评估进行细化
- en: Heuristic evaluation was covered in [*Chapter 9*](B21964_09_split_000.xhtml#_idTextAnchor190),
    *Guidelines and Heuristics*. The same approach, along with classifying and user
    scoring, from [*Chapter 4*](B21964_04.xhtml#_idTextAnchor085), *Scoring Stories*,
    can be used at this stage of the development process. All of that applies to monitoring
    and evaluation results. We can classify issues, score them to prioritize improvements,
    then apply refinements to the data, prompts, and model improvements (or even test
    against a new model to merge into the solution), or work on a new integration.
    You’ve got this! Apply what you know. This leads us to a discussion on handling
    the process of conversational AI within typical development organizations in [*Chapter*
    *11*](B21964_11.xhtml#_idTextAnchor236), *Process*.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 启发式评估在第*第9章*中有所介绍，*指南和启发式原则*。同样的方法，以及从*第4章*中来的分类和用户评分，*评分故事*，可以在开发过程的这个阶段使用。所有这些都适用于监控和评估结果。我们可以对问题进行分类，评分以优先改进，然后对数据、提示和模型改进进行细化（或者甚至测试新模型以合并到解决方案中），或者进行新的集成。你做到了！应用你所知道的知识。这引出了我们在*第11章*中关于处理典型开发组织内对话式AI流程的讨论，*过程*。
- en: Summary
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Tools on both ends were covered: analytic tools, such as RAGAs with metrics
    (sorry for the math!), and usability tools to monitor ongoing improvements from
    the customer’s perspective. This and monitoring conversations will flow into refinements
    needed for RAG materials, instructions/prompts, fine-tuning, and swapping to newer
    models while improving integrations with services and APIs. To do this well, this
    needs to fit into a process that can handle the dynamic nature of LLMs.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 两端的工具都得到了覆盖：分析工具，例如带有度量指标的RAGAs（抱歉数学相关！），以及可用性工具，用于从客户的角度监控持续的改进。这些和监控对话将流入对RAG材料、说明/提示、微调和在改进与服务和API集成的同时切换到新模型的所需改进。要做好这一点，这需要适应一个能够处理LLMs动态特性的流程。
- en: The next chapter offers insights into implementing processes conducive to LLM
    development and integrating with engineering to improve LLM solutions continuously.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将提供有关实施有利于LLM开发和与工程集成以持续改进LLM解决方案的流程的见解。
- en: References
  id: totrans-475
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '| ![](img/B21964_10_QR.jpg) | The links, book recommendations, and GitHub files
    in this chapter are posted on the reference page.Web Page: [Chapter 10 References](https://uxdforai.com/references#C10)
    ([https://uxdforai.com/references#C10](https://uxdforai.com/references#C10)) |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| ![图片](img/B21964_10_QR.jpg) | 本章中提到的链接、书籍推荐和GitHub文件已发布在参考文献页面上。网页：[第10章参考文献](https://uxdforai.com/references#C10)
    ([https://uxdforai.com/references#C10](https://uxdforai.com/references#C10)) |'
