["```py\n    def square(number):\n    ```", "```py\n        return number ** 2\n    ```", "```py\n    from langchain.prompts import PromptTemplate\n    ```", "```py\n    from langchain.llms import OpenAI\n    ```", "```py\n    # Define a prompt template requesting JSON formatted output\n    ```", "```py\n    prompt_structure = PromptTemplate(\n    ```", "```py\n        template=\"\"\"\n    ```", "```py\n            Context: {context}\n    ```", "```py\n            Instruction: {instruction}\n    ```", "```py\n            Text: {text_to_process}\n    ```", "```py\n            Output Cue: Format the response in JSON with one element called summary.\n    ```", "```py\n        \"\"\",\n    ```", "```py\n        input_variables=[\"context,\" \"instruction\",\n    ```", "```py\n            \"text_to_process\"]\n    ```", "```py\n    )\n    ```", "```py\n    # Dynamic elements for the prompt\n    ```", "```py\n    context = \"Summarizing long text passages.\"\n    ```", "```py\n    instruction = \"Summarize the key points from the following text in JSON format.\"\n    ```", "```py\n    text_to_process = \"\"\"\n    ```", "```py\n    Mars is the fourth planet from the Sun. The surface of Mars is orange-red because…\n    ```", "```py\n    \"\"\"\n    ```", "```py\n    formatted_prompt = prompt_structure.format_prompt(\n    ```", "```py\n        context=context,\n    ```", "```py\n        instruction=instruction,\n    ```", "```py\n        text_to_process=text_to_process\n    ```", "```py\n    )\n    ```", "```py\n    llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n    ```", "```py\n        temperature=0.9, max_tokens = 256)\n    ```", "```py\n    response = llm.invoke(formatted_prompt)\n    ```", "```py\n    print(response)\n    ```", "```py\n    {\n    ```", "```py\n        \"summary\": \"Mars is the fourth planet from the Sun, known for its orange-red surface and high-contrast features that make it a popular object for telescope viewing.\"\n    ```", "```py\n    }\n    ```", "```py\nexamples = [\n    {\n        \"prompt\": \"Describe the new summer collection in a bold and adventurous tone.\",\n        \"response\": \"Dive into summer with StyleSprint's latest collection! Featuring daring designs and vibrant colors, it's all about making bold statements. Perfect for the fearless fashionista ready to conquer the heat.\"\n    },\n    {\n        \"prompt\": \"How would you introduce our eco-friendly line to environmentally conscious customers?\",\n        \"response\": \"Embrace sustainable style with StyleSprint's eco-friendly line. Crafted from recycled materials, each piece combines fashion with responsibility, designed for the eco-conscious and trendy.\"\n    }\n]\n```", "```py\nfrom langchain.prompts.few_shot import FewShotPromptTemplate\nfrom langchain.prompts.prompt import PromptTemplate\n# Create a formatter\nprompt_format = PromptTemplate(\n    input_variables=[\"prompt\", \"response\"],\n    template=\"Prompt: {prompt}\\nResponse: {response}\")\n# Create the FewShotPromptTemplate\nfew_shot_prompt = FewShotPromptTemplate(\n    examples=examples, example_prompt=prompt_format,\n    suffix=\"Prompt: {input}\", input_variables=[\"input\"])\n```", "```py\nfrom langchain import LLMChain, OpenAI\n# Setup the LLM and LLMChain\nllm = OpenAI(temperature=0)\nllm_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n# Define the input prompt\ninput_prompt = \"Create a catchy tagline for our winter collection.\"\n# Invoke the chain to generate output\nresponse = llm_chain.run(input_prompt)\n# Extract and print the generated slogan\ngenerated_slogan = response\nprint(generated_slogan) \n    # => Response: \"Stay warm,\n    stay stylish,\n    stay ahead with StyleSprint's winter collection!\"\n```", "```py\n\"Write a slogan for a winter clothing line\"\n```", "```py\n\"Be warm, be cozy, be you\"\n```", "```py\n\"Modify the slogan to be more specific about the quality of the clothing\"\n```", "```py\nresponse = llm_chain.run(\"Rewrite the last tag to something about embracing the winter\")\nResponse # \n=> Response: Embrace the winter wonderland with StyleSprint's latest collection. From cozy knits to chic outerwear, our pieces will keep you stylish and warm all season long.\n```", "```py\npip install llama-index faiss-cpu llama-index-vector-stores-faiss\n```", "```py\nassert os.getenv(\"OPENAI_API_KEY\") is not None, \n    \"Please set OPENAI_API_KEY\"\n# load document vectors\ndocuments = SimpleDirectoryReader(\"products/\").load_data()\n# load faiss index\nd = 1536 # dimension of the vectors\nfaiss_index = faiss.IndexFlatL2(d)\n# create vector store\nvector_store = FaissVectorStore(faiss_index=faiss_index)\n# initialize storage context\nstorage_context = StorageContext.from_defaults(\n    vector_store=vector_store)\n# create index\nindex = VectorStoreIndex.from_documents(\n    documents,storage_context=storage_context)\n```", "```py\n# query the index\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"describe summer dress with price\")\nprint(response) \n=> A lightweight summer dress with a vibrant floral print is priced at 59.99.\n```", "```py\n# Define the evaluation data\neval_data: Dict[str, Any] = {\n   \"question\": questions, # list of sampled questions\n   \"answer\": engine_responses, # responses from RAG application\n   \"contexts\": contexts, # product metadata\n\"ground_truth\": ground_truth, # corresponding descriptions written by a human\n}\n# Create a dataset from the evaluation data\ndataset: Dataset = Dataset.from_dict(eval_data)\n# Define the evaluation metrics\nmetrics: List[Callable] = [\n    faithfulness,\n    answer_relevancy,\n    context_precision,\n    context_recall,\n    context_relevancy,\n    harmfulness,\n]\n# Evaluate the model using the defined metrics\nresult: Dict[str, float] = evaluate(dataset, metrics=metrics)\nprint(result)\n```", "```py\n{'faithfulness': 0.9167, 'answer_relevancy': 0.9961, 'context_precision': 0.5000, 'context_recall': 0.7500, 'harmfulness': 0.0000}\n```"]