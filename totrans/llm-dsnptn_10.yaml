- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Checkpointing and Recovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Checkpointing** and **recovery** refer to the process of saving the state
    of a system, application, or model at specific intervals (checkpointing) and restoring
    it from a saved state in case of failure (recovery). In machine learning, checkpointing
    involves periodically saving model parameters, optimizer states, and training
    progress so that training can resume from the last checkpoint instead of starting
    over. This is especially useful for long-running tasks, where interruptions due
    to system crashes, power failures, or preempted cloud instances can otherwise
    result in significant losses.'
  prefs: []
  type: TYPE_NORMAL
- en: Checkpointing and recovery are crucial for ensuring **fault tolerance**, **efficiency**,
    and **reproducibility** in training large-scale models. Without checkpointing,
    an unexpected failure could waste hours or even days of computation. Additionally,
    it allows for **experiment reproducibility**, enabling researchers to revisit
    and fine-tune models from intermediate states, rather than redoing entire training
    runs. Efficient checkpointing strategies (e.g., saving at fixed intervals or when
    validation performance improves) help balance storage overhead while minimizing
    retraining costs.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll explore strategies for determining optimal checkpoint
    frequency, efficient storage formats for large models, and techniques for recovering
    from various types of failures. You’ll also gain insights into checkpointing in
    distributed training scenarios and version control for model checkpoints.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Why is checkpointing important?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checkpoint frequency and storage strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient checkpoint formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recovering from failures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checkpointing in distributed LLM training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Version control for LLM checkpoints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated checkpointing and recovery systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is checkpointing important?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Checkpointing is a common practice in LLM training due to the long duration
    and resource-intensive nature of the LLM training process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement a basic checkpointing system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This implementation demonstrates the basic structure of a checkpointing system.
    The `save_checkpoint` method saves the model state, optimizer state, and training
    progress information. The `load_checkpoint` method allows you to resume training
    from a saved checkpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Checkpoint frequency and storage strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Determining the optimal checkpoint frequency involves striking a balance between
    *safety* and *efficiency*. Let’s explore different strategies and their implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This implementation introduces several checkpointing strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Regular checkpointing with a maximum number of checkpoints**: This prevents
    excessive disk usage by removing old checkpoints when the limit is reached'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time-based checkpointing**: This saves checkpoints at regular time intervals,
    which can be useful for long-running training processes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best model checkpointing**: This saves the model with the best performance
    (lowest loss in this case), which is useful for model selection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s a trade-off analysis of the three checkpointing strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Regular checkpointing with a maximum number** **of checkpoints**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pros**: Prevents excessive storage usage and ensures periodic snapshots of
    training progress'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**: Might overwrite useful older checkpoints, potentially losing good
    models if performance fluctuates'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best use case**: When storage is a constraint and periodic snapshots are
    needed for resumption'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time-based checkpointing**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pros**: Ensures checkpoints are spaced out over time, which is useful for
    monitoring long training runs'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**: Can be inefficient if checkpoints are saved too frequently (wasting
    storage) or too infrequently (missing critical states)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best use case**: For long-running training processes where consistent snapshots
    are needed for debugging or rollback'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best** **model checkpointing**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pros**: Retains the most promising model, which is useful for final model
    selection.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**: If loss is noisy, a single “best” checkpoint may not be truly representative.
    Can fail to capture intermediate learning dynamics.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best use case**: When selecting the most performant model is the priority
    over periodic snapshots.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some factors to consider when selecting the strategy you wish to adopt:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computational cost**: Frequent checkpointing increases disk I/O and CPU overhead'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Failure recovery**: Regular and time-based checkpointing help resume training
    after interruptions, whereas best-model checkpointing may not provide recent progress'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage constraints**: Maintaining many checkpoints consumes storage; regular
    checkpointing with a limit is most efficient in managing this'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rate of model improvement**: If the model improves rapidly, frequent checkpoints
    may be useful; if the progress is slow, fewer but more strategic checkpoints may
    suffice'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The recommended approach for checkpointing LLMs is to combine strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: Use regular checkpointing (e.g., every few hours) to ensure progress is saved
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use best model checkpointing to retain the best-performing model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a rolling window of recent checkpoints to balance storage efficiency and
    recovery options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient checkpoint formats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For LLMs with billions of parameters, checkpoint size can become a significant
    concern. Let’s explore some strategies for efficient checkpoint storage:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries and implement `EfficientLLMTrainer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code defines an `EfficientLLMTrainer` class that extends `AdvancedLLMTrainer`
    (presumably a pre-existing class for training LLMs). The key function implemented
    is `save_checkpoint_efficient`, which efficiently saves model checkpoints in a
    compressed ZIP format.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s define the function (`load_checkpoint_efficient`) to load the checkpoint
    in ZIP format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function, `load_checkpoint_efficient`, is responsible for loading a previously
    saved checkpoint from a ZIP file and restoring the model and optimizer states.
    See the following example usage.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Example usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This implementation uses ZIP compression to reduce the size of checkpoints.
    It also separates the model and optimizer state dictionaries from other metadata,
    allowing for more efficient storage and loading.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Other strategies for efficient checkpoint storage include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Quantization**: Reducing the precision of model weights (e.g., from float32
    to float16) can significantly reduce the checkpoint size (see more about this
    strategy in [*Chapter 13*](B31249_13.xhtml#_idTextAnchor209))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incremental checkpointing**: Only save the changes since the last checkpoint,
    rather than the entire model state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed storage**: In multi-GPU or multi-node setups, distribute the
    checkpoint across multiple storage devices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud storage**: Use cloud storage solutions that offer fast I/O and automatic
    compression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For very large models, you might also consider more advanced techniques, such
    as **model sharding**, where different parts of the model are saved separately
    and can be loaded on demand.
  prefs: []
  type: TYPE_NORMAL
- en: Recovering from failures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Robust recovery mechanisms are crucial for LLM training. Let’s implement a
    system that can handle various types of failures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `RobustLLMTrainer` class extends `EfficientLLMTrainer` to add resilience
    by handling interruptions (such as `SIGINT` for *Ctrl* + *C* and `SIGTERM` for
    termination) and saving checkpoints to prevent data loss. It initializes with
    a model, optimizer, checkpoint directory, and auto-save interval, then sets up
    signal handlers to trigger a graceful shutdown by saving progress before exiting.
  prefs: []
  type: TYPE_NORMAL
- en: During training, it attempts to resume from the latest checkpoint if available.
    It loops through epochs and steps, running `train_fn` to compute loss and periodically
    saving checkpoints based on `autosave_interval`. If an exception occurs, it catches
    the error, saves the progress, and re-raises the exception to avoid silent failures.
  prefs: []
  type: TYPE_NORMAL
- en: The `get_latest_checkpoint()` method retrieves the most recent checkpoint by
    sorting files in the checkpoint directory (though `os` is missing and should be
    imported). The script concludes with an example usage where a dummy loss function
    is defined, and training is started with `trainer.train(epochs=10,` `steps_per_epoch=1000,
    train_fn=train_step)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This implementation includes several robustness features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Signal handling**: The trainer catches interrupt signals (*Ctrl* + *C*) and
    gracefully saves a checkpoint before exiting'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automatic resumption**: The trainer automatically finds and loads the latest
    checkpoint when starting training'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regular auto-saves**: Checkpoints are saved at regular intervals during training'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exception handling**: If an error occurs during training, a checkpoint is
    saved before the exception is re-raised'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These features help recover from various types of failures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**System crashes or power outages**: Regular auto-saves ensure that not too
    much progress is lost'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User interruptions**: Signal handling allows for graceful exits with the
    state saved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code errors**: Exception handling ensures that progress is saved even if
    an unexpected error occurs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For even more robust recovery, consider implementing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Checkpoint validation**: Verify the integrity of checkpoints before loading
    them'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple backup checkpoints**: Keep several recent checkpoints in case the
    latest one is corrupted'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed checkpointing**: In multi-node setups, ensure that checkpoints
    are consistent across all nodes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checkpointing in distributed LLM training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Distributed training introduces additional complexity to checkpointing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s break down the implementation of a basic distributed checkpointing system
    and understand each component:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We first define the `DistributedLLMTrainer` class, which inherits from `RobustLLMTrainer`.
    The `DistributedLLMTrainer` class is designed for the distributed training of
    LLMs using PyTorch’s `torch.distributed` framework. It ensures that the model
    is trained across multiple devices (e.g., GPUs) or nodes efficiently:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The initialization does the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Calls the parent class initializer.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sets up distributed training attributes:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`self.rank`: Identifies the current process'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`self.world_size`: Indicates the total number of processes'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then use the following methods to save and load checkpoints during distributed
    training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following methods handle distributed checkpointing:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`save_checkpoint_distributed`: Only the main process (rank `0`) saves the checkpoint
    to avoid redundant writes, reduce disk I/O, and ensure consistency across processes.
    If all ranks are saved independently, it could lead to storage inefficiencies
    and potential race conditions. After saving, `dist.barrier()` synchronizes all
    processes to ensure they wait for the checkpoint to be written. When loading,
    only rank `0` reads the checkpoint to prevent redundant disk access; then, it
    broadcasts the loaded values to all other ranks using `dist.broadcast()`, ensuring
    every process starts from the same state before resuming training.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`load_checkpoint_distributed`:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Only the main process loads the checkpoint
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It broadcasts the loaded values to all other processes
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It ensures all processes have the same checkpoint data
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we implement distributed training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `train_distributed` method does the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Determines the starting point (epoch and step)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Broadcasts this information to all processes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Runs the training loop with periodic checkpointing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Handles exceptions by saving a final checkpoint and cleaning up
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then employ the following code to initialize distributed training with PyTorch,
    set up your model for parallel execution, and perform a simple distributed training
    loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code includes the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`init_distributed`: Initializes the distributed training environment'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`distributed_train_step`: A dummy training function for demonstration'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`main`: Shows how to use `DistributedLLMTrainer` in practice'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Key considerations for distributed checkpointing include maintaining consistency
    by synchronizing all processes using barriers during checkpointing, ensuring that
    only the main process handles I/O operations to avoid conflicts, and effectively
    sharing important data by broadcasting it from the main process to the other processes.
    Additionally, the system incorporates robust error handling, allowing it to gracefully
    save checkpoints and clean up distributed resources in case of failures.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us focus on the version control aspect.
  prefs: []
  type: TYPE_NORMAL
- en: Version control for LLM checkpoints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Version control for LLM checkpoints can help with managing different versions
    of your model during the development process. Here’s a simple implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This implementation provides basic version control features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Version tracking**: Each saved checkpoint can be associated with a version
    name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Branching**: You can create new branches from existing checkpoints, allowing
    for experimentation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version history**: The version information is stored in a JSON file for easy
    inspection and management'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The key benefits of version control for LLM checkpoints are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Experimentation**: You can easily try different training strategies or hyperparameters
    from a common starting point'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaboration**: Team members can share and work on different versions of
    the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reproducibility**: Specific versions of the model can be referenced and recreated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated checkpointing and recovery systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To make the checkpointing and recovery process more robust and hands-off, we
    can implement an automated system:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the required modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We imported two key modules here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`threading`: Enables the creation of threads for running tasks (such as auto-save
    and health checks) concurrently with the main training process'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`time`: Used to manage intervals between auto-saves and health checks, as well
    as timestamping saved checkpoints'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we define and initialize the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `AutomatedLLMTrainer` class inherits from a base class, `VersionControlledLLMTrainer`,
    which handles basic checkpointing logic. This class introduces automation for
    checkpointing and system health monitoring.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following is a list of parameters that manage auto-saving, system health
    checks, and training execution control:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`autosave_interval`: The time (in seconds) between auto-save checkpoints.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`health_check_interval`: The time between system health checks.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`training_active`: A flag to indicate whether the training is ongoing. It is
    used to control the threads’ execution.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The constructor calls `super().__init__()` to inherit functionality from the
    parent class and sets up intervals for auto-saving and health checks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Auto-save the thread for checkpointing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This method starts a separate thread that periodically saves a checkpoint during
    training.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following is a list of components responsible for handling periodic auto-saving
    during training:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`autosave_loop`: A function that continuously runs while `training_active`
    is `True`. Every `autosave_interval` seconds, it calls the `save_checkpoint_versioned()`
    method to save the current state.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threading.Thread`: The thread runs `autosave_loop` in the background, ensuring
    that auto-saves happen concurrently with the training process.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we implement a health check thread. This method starts a health check
    thread that monitors system performance at regular intervals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the main elements of the preceding snippet:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`health_check_loop`: A function that continuously runs during training. Every
    `health_check_interval` seconds, it checks the system health by calling `check_system_health()`.
    If a problem is detected, it triggers the recovery process.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`check_system_health()`: This method needs to be defined to check the system’s
    performance metrics (e.g., GPU memory or CPU usage). If the health check fails,
    it calls `initiate_recovery()`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We perform system health check and recovery. The following placeholder method
    is where the system health checks will be implemented, for example, checking GPU
    memory, CPU utilization, disk space, or any other resource critical to the training
    process. It returns `True` if everything is fine, and `False` if there’s a problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following method will contain logic for what to do if the system health
    check fails. It could, for instance, reload the last checkpoint, reduce the batch
    size, or take other corrective actions depending on the issue detected:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we conduct automated training with checkpointing and health checks.
    This method manages the overall training process with automation. It activates
    the auto-save and health check threads and initiates distributed training via
    the parent class’s `train_distributed()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s a breakdown of the main code elements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`self.training_active`: Set to `True` to indicate that training is running'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`try-finally block`: Ensures that no matter how the training ends (whether
    it completes or crashes), the `training_active` flag is set to `False` and both
    threads are properly terminated'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach reduces manual intervention, enhances reliability, and offers
    flexibility in defining recovery logic based on the specific training needs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing robust checkpointing and recovery systems is common practice for
    successful LLM training. By incorporating these techniques, you can ensure that
    your long-running training processes are resilient to failures, easily manageable,
    and conducive to experimentation and collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To expand our discussion, *Table 10.1* lists checkpointing strategies, trade-offs,
    and use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Checkpointing** **Strategy** | **Description** | **Trade-Offs** | **Use
    Cases** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Regular (with max limit) | Saves at intervals (steps/epochs); keeps a maximum
    number. | Pros: Saves storage; periodic snapshots.Cons: Might overwrite good checkpoints.
    | Iterative model development; monitoring training progress; preventing complete
    data loss during long training runs. |'
  prefs: []
  type: TYPE_TB
- en: '| Time-based | Saves at specified intervals (e.g., every 30 minutes). | Pros:
    Time-spaced snapshots.Cons: Inefficient if the interval is too short/long. | Long-running
    experiments where consistent, time-stamped checkpoints are crucial for debugging
    and analysis; ensuring recoverability in case of system failures. |'
  prefs: []
  type: TYPE_TB
- en: '| Best model | Saves only when the model achieves the best performance. | Pros:
    Retains the best model.Cons: May not be representative if loss is noisy; no intermediate
    snapshots. | Selecting the most performant model. |'
  prefs: []
  type: TYPE_TB
- en: '| Efficient (compression) | Uses compression (e.g., ZIP) to reduce size. |
    Storage-constrained environments; handling large models where storage is a primary
    concern; archiving models for long-term storage. | Storage-constrained environments;
    archiving models for long-term storage. |'
  prefs: []
  type: TYPE_TB
- en: '| Efficient (quantization) | Reduces precision of weights (e.g., float32 to
    float16). | Pros: Reduces size.Cons: Potential accuracy loss. | Deploying models
    on resource-limited devices; reducing checkpoint size for faster transfer and
    storage; accelerating model loading. |'
  prefs: []
  type: TYPE_TB
- en: '| Efficient (incremental) | Saves only changes since the last checkpoint. |
    Pros: Can significantly reduce size.Cons: Complex; potentially fragile. | Training
    models with gradual parameter updates; large models where frequent full checkpoints
    are impractical; continuous learning scenarios. |'
  prefs: []
  type: TYPE_TB
- en: '| Distributed | In distributed training, only the main process (rank 0) saves;
    data is broadcast to others. | Pros: Avoids redundant writes; ensures consistency.Cons:
    Requires coordination. | Large-scale distributed training jobs; ensuring consistent
    model states across multiple workers; minimizing network overhead. |'
  prefs: []
  type: TYPE_TB
- en: '| Version-controlled | Associates checkpoints with versions; supports branching.
    | Pros: Experimentation; reproducibility; rollback.Cons: Adds complexity. | Collaborative
    model development; tracking experimental variations; ensuring reproducibility
    for scientific research; managing model evolution. |'
  prefs: []
  type: TYPE_TB
- en: '| Automated (with health checks) | Auto-saves checkpoints; performs health
    checks; can initiate recovery. | Pros: Reduces manual work; enhances reliability.Cons:
    Requires health check/recovery implementation. | Mission-critical training jobs;
    automated recovery from failures; long-running experiments requiring high reliability.
    |'
  prefs: []
  type: TYPE_TB
- en: Table 10.1 – Checkpointing strategies, trade-offs, and use cases
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll explore effective techniques for adapting pre-trained
    language models to specific tasks or domains.
  prefs: []
  type: TYPE_NORMAL
