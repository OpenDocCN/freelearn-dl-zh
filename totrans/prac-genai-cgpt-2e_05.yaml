- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Understanding Prompt Engineering
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解提示工程
- en: In the previous chapters, we mentioned the term **prompt** several times while
    referring to user input in ChatGPT and **large language models** (**LLMs**) in
    general.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们多次提到“提示”一词，在提及 ChatGPT 中的用户输入和一般意义上的**大型语言模型（LLMs**）时。
- en: Since prompts have a massive impact on LLMs’ performance, prompt engineering
    is a crucial activity to get the most out of your GenAI tool. In fact, there are
    several techniques that can be implemented not only to refine your LLMs’ responses
    but also to reduce risks associated with hallucinations and biases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于提示对 LLM 的性能有巨大影响，提示工程是充分利用你的 GenAI 工具的关键活动。实际上，有几种技术不仅可以完善你的 LLM 的响应，还可以减少与幻觉和偏见相关的风险。
- en: 'In this chapter, we are going to cover the emerging techniques in the field
    of prompt engineering, starting from basic approaches up to advanced frameworks.
    More specifically, we will go through the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍提示工程领域的最新技术，从基本方法到高级框架。更具体地说，我们将探讨以下主题：
- en: What is prompt engineering?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: Exploring zero-, one-, and few-shot learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索零样本、单样本和少样本学习
- en: Principles of prompt engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程的原则
- en: Looking at some advanced techniques
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看一些高级技术
- en: Ethical considerations to avoid bias
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免偏见的伦理考量
- en: By the end of this chapter, you will have the foundations to build functional
    and solid prompts to interact with ChatGPT and, more broadly, with GenAI applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将拥有构建功能强大且稳固的提示与 ChatGPT 以及更广泛的 GenAI 应用程序互动的基础。
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You’ll need an OpenAI account. You can use the free ChatGPT version to run this
    chapter’s examples.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个 OpenAI 账户。您可以使用免费的 ChatGPT 版本来运行本章的示例。
- en: What is prompt engineering?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: Before explaining what prompt engineering is, let’s start by defining a prompt.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释提示工程之前，让我们首先定义一下提示。
- en: 'A **prompt** is text input that guides the behavior of an LLM to generate an
    output. For example, whenever we interact with ChatGPT, asking a question or giving
    an instruction, that input text is a prompt. In the context of LLMs and LLM-powered
    applications, we can distinguish two types of prompts:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**是引导 LLM 行为以生成输出的文本输入。例如，每次我们与 ChatGPT 互动，提问或给出指令时，输入的文本就是一个提示。在 LLM 和
    LLM 驱动的应用背景下，我们可以区分两种类型的提示：'
- en: The first type is a prompt that the user writes and sends to the LLM. For example,
    a prompt might be “Give me the recipe for Lasagna Bolognese,” or “Generate a workout
    plan to run a marathon.”
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一种类型是用户编写的并发送给 LLM 的提示。例如，一个提示可能是“给我 Lasagna Bolognese 的食谱”，或者“生成一个马拉松跑步的训练计划”。
- en: '![A screenshot of a chat  Description automatically generated](img/B31559_03_01.png)![](img/B31559_03_02.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![聊天屏幕截图  自动生成的描述](img/B31559_03_01.png)![](img/B31559_03_02.png)'
- en: 'Figure 3.1: An example of a user’s prompt'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：用户提示的示例
- en: You will hear this referred to simply as a **prompt**, a **query**, or **user
    input**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你会听到它被简单地称为**提示**、**查询**或**用户输入**。
- en: The second type is a prompt that instructs the model to behave in a certain
    way regardless of the user’s query. This refers to the set of instructions in
    natural language that the model is provided with so that it behaves in a certain
    way when interacting with end users. You can think about that as a sort of “backend”
    of your LLM, something that will be handled by the application developers rather
    than the final users.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二种类型是指导模型以某种方式行为的提示，无论用户的查询如何。这指的是模型在与最终用户互动时所提供的自然语言指令集，以便以某种方式行为。你可以将其视为
    LLM 的“后端”，这是将由应用开发者而不是最终用户处理的部分。
- en: '![A screenshot of a computer  Description automatically generated](img/B31559_03_03.png)![](img/B31559_03_04.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成的描述](img/B31559_03_03.png)![](img/B31559_03_04.png)'
- en: 'Figure 3.2: An example of a system message'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：系统消息的示例
- en: We refer to this type of prompt as a **system message**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将此类提示称为**系统消息**。
- en: Prompt engineering is the process of designing effective prompts that elicit
    high-quality and relevant outputs from LLMs. Prompt engineering requires creativity,
    an understanding of the LLM, and a clear understanding of the objective you want
    to achieve.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是设计有效提示的过程，以从大型语言模型（LLMs）中获取高质量和相关的输出。提示工程需要创造力、对 LLM 的理解以及对你想要实现的目标的清晰理解。
- en: '![](img/B31559_03_05.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_05.png)'
- en: 'Figure 3.3: Example of prompt engineering to specialize LLMs'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：提示工程示例，以专门化LLMs
- en: Over the last few years, prompt engineering has become a brand-new discipline
    in itself, and this is a demonstration of the fact that interacting with those
    models requires a new set of skills and capabilities that did not exist before.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，提示工程已经成为一门全新的学科，这也是一个事实的证明，即与这些模型交互需要一套新的技能和能力，这些技能和能力在以前是不存在的。
- en: The *art of prompting* has become a top skill when it comes to building GenAI
    applications in enterprise scenarios; however, it can also be extremely useful
    for individual users who use ChatGPT or similar AI assistants in daily tasks,
    as it dramatically improves the quality and accuracy of results.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示的艺术*在构建企业场景中的GenAI应用时已成为一项顶级技能；然而，它对于使用ChatGPT或类似AI助手进行日常任务的个人用户来说也极其有用，因为它显著提高了结果的质量和准确性。'
- en: In the next sections, we are going to see some examples of how to build efficient,
    robust prompts leveraging ChatGPT.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将看到一些如何利用ChatGPT构建高效、健壮提示的示例。
- en: Understanding zero-, one-, and few-shot learning
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解零样本、一样本和少样本学习
- en: In the previous chapters, we mentioned how LLMs typically come in a pre-trained
    format. They have been trained on a huge amount of data and have had their (billions
    of) parameters configured accordingly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们提到了LLMs通常以预训练的格式出现。它们已经在大量数据上进行了训练，并且已经相应地配置了它们的（数十亿）参数。
- en: However, this doesn’t mean that those LLMs can’t learn anymore. In *Chapter
    2*, we learned the concept of fine-tuning. In the *Appendix*, too, we will see
    that one way to customize an OpenAI model and make it more capable of addressing
    specific tasks is by **fine-tuning**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不意味着那些LLMs不能再学习了。在*第二章*中，我们学习了微调的概念。在*附录*中，我们还将看到，通过**微调**来定制OpenAI模型并使其更能够处理特定任务的一种方法。
- en: Fine-tuning is a proper training process that requires a training dataset, compute
    power, and some training time (depending on the amount of data and compute instances).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是一种适当的训练过程，需要训练数据集、计算能力和一些训练时间（取决于数据量和计算实例的数量）。
- en: 'That is why it is worth testing another method for our LLMs to become more
    skilled in specific tasks: **shot learning.**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，测试另一种方法让我们的LLMs在特定任务上变得更加熟练是值得的：**少样本学习**。
- en: '**Definition**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: In the context of LLMs, **shot learning** refers to the model’s ability to perform
    tasks with varying amounts of task-specific examples provided during inference.
    These shot-learning paradigms enable LLMs to adapt to new tasks with minimal to
    no additional training, enhancing their versatility and efficiency in natural
    language processing applications.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs的背景下，**少样本学习**指的是模型在推理期间提供不同数量的任务特定示例时执行任务的能力。这些少样本学习范式使LLMs能够以最小或没有额外训练的情况下适应新任务，增强其在自然语言处理应用中的灵活性和效率。
- en: The idea is to let the model learn from simple examples rather than the entire
    dataset. Those examples are samples of the way we would like the model to respond
    so that the model not only learns the content but also the format, style, and
    taxonomy to use in its response.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 理念是让模型从简单的示例中学习，而不是整个数据集。这些示例是我们希望模型响应的样本，这样模型不仅学习内容，还学习在响应中使用的内容、格式、风格和分类法。
- en: Furthermore, shot learning occurs directly via the prompt (as we will see in
    the following scenarios), so the whole experience is less time-consuming and easier
    to perform.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，少样本学习是通过提示直接发生的（正如我们将在以下场景中看到的那样），因此整个体验更加节省时间且易于执行。
- en: The number of examples provided determines the level of shot learning we are
    referring to. In other words, we refer to zero-shot if no example is provided,
    one-shot if one example is provided, and few-shot if more than two examples are
    provided.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的示例数量决定了我们所指的少样本学习的水平。换句话说，如果没有提供示例，我们称之为零样本；如果提供了一个示例，我们称之为一样本；如果提供了两个以上的示例，我们称之为少样本。
- en: Let’s focus on each of those scenarios.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注这些场景中的每一个。
- en: Zero-shot learning
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本学习
- en: 'In this type of learning, the model is asked to perform a task for which it
    has not seen any training examples. The model must rely on prior knowledge or
    general information about the task to complete it. For example, a zero-shot-learning
    approach could be that of asking the model to generate a description, as defined
    in my prompt:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种学习类型中，模型被要求执行一个它没有看到任何训练示例的任务。模型必须依赖先前的知识或关于任务的通用信息来完成它。例如，零样本学习的方法可能是要求模型生成一个描述，如我在提示中定义的那样：
- en: '![](img/B31559_03_06.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_03_06.png)'
- en: 'Figure 3.4: Example of zero-shot learning'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：零样本学习示例
- en: One-shot learning
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单样本学习
- en: 'In this type of learning, the model is given a single example of each new task
    it is asked to perform. The model must use its prior knowledge to generalize from
    this single example to perform the task. If we consider the preceding example,
    I could provide my model with a prompt-completion example before asking it to
    generate a new one:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种学习类型中，模型被要求为每个新任务提供一个示例。模型必须使用其先验知识从这个单一示例中泛化以执行任务。如果我们考虑前面的例子，我可以在要求模型生成新示例之前，向我的模型提供一个提示完成示例：
- en: '![](img/B31559_03_07.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_03_07.png)'
- en: 'Figure 3.5: Example of one-shot learning'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5：单样本学习示例
- en: As you can see from the previous screenshot, the model was able to generate
    an answer that mirrors the style and template of the example provided. The same
    reasoning applies when we provide multiple examples, as described in the next
    section.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个截图所示，模型能够生成一个与提供的示例风格和模板相匹配的答案。当提供多个示例时，情况类似，如下一节所述。
- en: Few-shot learning
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少样本学习
- en: 'In this type of learning, the model is given a small number of examples (typically
    between 2 and 5) of each new task it is asked to perform. The model must use its
    prior knowledge to generalize from these examples to perform the task. Let’s continue
    with our example and provide the model with further examples:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种学习类型中，模型被要求为每个新任务提供少量（通常在2到5个之间）的示例。模型必须使用其先验知识从这些示例中泛化以执行任务。让我们继续我们的例子，并向模型提供更多的示例：
- en: '![](img/B31559_03_08.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_03_08.png)'
- en: 'Figure 3.6: Example of few-shot learning with three examples'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6：三个示例的少样本学习示例
- en: As mentioned previously, it is important to remember that these forms of learning
    are different from traditional supervised learning, as well as fine-tuning. In
    few-shot learning, the goal is to enable the model to learn from very few examples,
    and to generalize from those examples to new tasks. Plus, we are not modifying
    the architecture and knowledge of the model itself, meaning that the moment the
    user starts a new conversation, and the previous prompt is out of the context
    window, the model will “forget” about it.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，记住这些学习形式与传统监督学习和微调是不同的。在少样本学习中，目标是让模型从非常少的示例中学习，并从这些示例中泛化到新的任务。此外，我们并没有修改模型的架构和知识，这意味着当用户开始新的对话，并且之前的提示超出了上下文窗口时，模型将“忘记”它。
- en: '**Definition**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Supervised learning is a type of machine learning where a model is trained on
    a labeled dataset, meaning the input data is paired with corresponding correct
    outputs (labels). The goal is for the model to learn the relationship between
    inputs and outputs so it can accurately predict the output for new, unseen data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是一种机器学习方法，模型在标记数据集上进行训练，这意味着输入数据与相应的正确输出（标签）配对。目标是让模型学习输入和输出之间的关系，以便它可以准确预测新、未见过的数据的输出。
- en: Now that we’ve learned how to let OpenAI models learn from examples, let’s focus
    on how to properly define our prompt to make the model’s response as accurate
    as possible.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何让OpenAI模型从示例中学习，让我们专注于如何正确地定义我们的提示，以使模型的响应尽可能准确。
- en: Principles of prompt engineering
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程原则
- en: Traditionally, in the context of computing and data processing, the expression
    *garbage in, garbage out* has been used, meaning that the quality of output is
    determined by the quality of the input. If incorrect or poor-quality input (garbage)
    is entered into a system, the output will also be flawed or nonsensical (garbage).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，在计算和数据处理的背景下，使用了“垃圾输入，垃圾输出”的表达，意味着输出质量取决于输入质量。如果将不正确或低质量的输入（垃圾）输入到系统中，输出也将是错误的或无意义的（垃圾）。
- en: 'When it comes to prompting, the story is similar: if we want accurate and relevant
    results from our LLMs, we need to provide high-quality input. However, building
    good prompts is not just about the quality of the response. In fact, we can construct
    good prompts to:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到提示时，故事是相似的：如果我们希望从我们的LLMs中获得准确和相关的结果，我们需要提供高质量的输入。然而，构建好的提示不仅仅是关于响应质量的问题。实际上，我们可以构建好的提示来：
- en: Maximize the relevancy of an LLM’s responses.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大化LLM响应的相关性。
- en: Specify the type formatting and style of responses.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定响应的类型格式和风格。
- en: Provide conversational context.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供对话上下文。
- en: Reduce inner LLMs’ biases and improve fairness and inclusivity.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少内部LLMs的偏见，提高公平性和包容性。
- en: Reduce hallucination.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少幻觉。
- en: '**Definition**'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**定义**'
- en: 'In the context of LLMs, **hallucination** refers to the generation of text
    or responses that are factually incorrect, nonsensical, or not grounded in the
    training data. This occurs when an LLM produces confident-sounding but erroneous
    or fabricated information. For example, a user could ask an LLM: *“Who is the
    author of the book Invisible Cities?”* If the model responds with something like:
    *“Invisible Cities was written by Gabriel García Márquez.”,* this is a hallucination
    because the correct author is *Italo Calvino*. The model generated an answer that
    sounds plausible but is factually incorrect.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在LLM的背景下，**幻觉**指的是生成事实错误、无意义或未基于训练数据的文本或响应。这发生在LLM产生听起来自信但错误或虚构的信息时。例如，一个用户可以问一个LLM：“《隐形城市》这本书的作者是谁？”如果模型回答：“《隐形城市》是加布里埃尔·加西亚·马尔克斯写的。”，这便是一种幻觉，因为正确的作者是*伊塔洛·卡尔维诺*。模型生成了一个听起来可信但实际上错误的答案。
- en: Let’s see some basic prompt engineering techniques in the following sections
    to achieve these results.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将看看一些基本的提示工程技巧，以实现这些结果。
- en: Clear instructions
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 明确指令
- en: 'The principle of giving clear instructions is to provide the model with enough
    information and guidance to perform the task correctly and efficiently. Clear
    instructions should include the following elements:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 明确指令的原则是向模型提供足够的信息和指导，以便正确且高效地完成任务。明确的指令应包括以下要素：
- en: The goal or objective of the task, such as “write a poem” or “summarize an article.”
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的目标或目标，例如“写一首诗”或“总结一篇文章。”
- en: The format or structure of the expected output, such as “use four lines with
    rhyming words” or “use bullet points with no more than 10 words each.”
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期输出的格式或结构，例如“使用四行押韵的词”或“使用每项不超过10个单词的项目符号。”
- en: The constraints or limitations of the task, such as “do not use any profanity”
    or “do not copy any text from the source.”
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的约束或限制，例如“不要使用任何粗俗语言”或“不要复制任何源文本。”
- en: The context or background of the task, such as “the poem is about autumn” or
    “the article is from a scientific journal.”
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务的上下文或背景，例如“这首诗是关于秋天的”或“这篇文章来自科学期刊。”
- en: 'Let’s say, for example, that we want our model to fetch any kind of instructions
    from text and return to us a tutorial in a bullet list. If there are no instructions
    in the provided text, the model should inform us about that. Let’s see an example
    in ChatGPT:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们希望我们的模型从文本中提取任何类型的指令，并以项目符号列表的形式返回教程。如果提供的文本中没有指令，模型应通知我们。让我们在ChatGPT中看看一个例子：
- en: '![](img/B31559_03_09.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_09.png)'
- en: 'Figure 3.7: Example of clear instructions in ChatGPT'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7：ChatGPT中明确指令的示例
- en: 'Note that, if we pass the model other text that does not contain any instructions,
    it will be able to respond as we instructed it:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果我们向模型传递不包含任何指令的其他文本，它将能够按照我们的指示进行回应：
- en: '![](img/B31559_03_10.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_10.png)'
- en: 'Figure 3.8: Example of chat model following instructions'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8：遵循指令的聊天模型示例
- en: '**Note**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'In the previous figure, we saw ChatGPT keeping in mind the instructions we
    prompted it with at the beginning of the conversation. This happens because ChatGPT
    has a so-called context window, which is equal to a single chat: everything we
    input in the chat session will be part of ChatGPT’s context and henceforth part
    of its knowledge; the moment we start a new session from scratch, ChatGPT will
    not remember any previous instructions.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的图中，我们看到ChatGPT在对话开始时我们给出的指令的指导下进行。这是因为ChatGPT有一个所谓的上下文窗口，等于一个单独的聊天：我们在聊天会话中输入的一切都将成为ChatGPT的上下文，从而成为其知识的一部分；当我们从头开始一个新的会话时，ChatGPT将不会记住任何之前的指令。
- en: By giving clear instructions, you can help the model understand what you want
    it to do and how you want it to do it. This can improve the quality and relevance
    of the model’s output, and reduce the need for further revisions or corrections.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过给出明确的指令，你可以帮助模型理解你想要它做什么以及你希望它如何去做。这可以提高模型输出的质量和相关性，并减少进一步修订或纠正的需求。
- en: However, sometimes there are scenarios where clarity is not enough. We might
    need to infer the way of thinking of our LLM to make it more robust with respect
    to its task. In the next subsection, we are going to examine a technique to do
    this – one that is very useful in cases of solving complex tasks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时清晰度并不足够。我们可能需要推断我们的LLM的思维方式，使其在任务上更加稳健。在下一小节中，我们将探讨一种实现这一目标的技术——这在解决复杂任务的情况下非常有用。
- en: Split complex tasks into subtasks
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将复杂任务分解为子任务。
- en: When we interact with LLMs to let them solve some tasks, sometimes those tasks
    are too complex or ambiguous for a single prompt to handle, and it is better to
    split them into simpler subtasks that can be solved by different prompts.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们与LLM互动，让他们解决某些任务时，有时这些任务过于复杂或含糊不清，以至于无法通过单个提示处理，因此最好将它们分解为更简单的子任务，这些子任务可以通过不同的提示来解决。
- en: 'Here are some examples of splitting complex tasks into subtasks:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些将复杂任务分解为子任务的示例：
- en: '**Text summarization**: A complex task that involves generating a concise and
    accurate summary of a long text. This task can be split into subtasks such as:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本摘要**：一项复杂的任务，涉及生成长文本的简洁、准确摘要。这项任务可以分解为以下子任务：'
- en: Extracting the main points or keywords from the text.
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中提取主要观点或关键词。
- en: Rewriting the main points or keywords in a coherent way.
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以连贯的方式重写主要观点或关键词。
- en: Trimming the summary to fit a desired length or format.
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将摘要修剪到所需的长度或格式。
- en: '**Poem generation**: A creative task that involves producing a poem that follows
    a certain style, theme, or mood. This task can be split into subtasks such as:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**诗歌生成**：一项创造性的任务，涉及创作遵循特定风格、主题或情绪的诗歌。这项任务可以分解为以下子任务：'
- en: Choosing a poetic form (such as sonnet, haiku, limerick, etc.) and a rhyme scheme
    (such as ABAB, AABB, ABCB, etc.) for the poem.
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为诗歌选择一个诗歌形式（如十四行诗、俳句、雷姆里克等）和一个韵律（如ABAB、AABB、ABCB等）。
- en: Generating a title and a topic for the poem based on the user’s input or preference.
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户的输入或偏好为诗歌生成标题和主题。
- en: Generating the lines or verses of the poem that match the chosen form, rhyme
    scheme, and topic.
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成符合所选形式、韵律和主题的诗歌行或诗句。
- en: Refining and polishing the poem to ensure coherence, fluency, and originality.
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精炼和润色诗歌，以确保其连贯性、流畅性和原创性。
- en: '**Code generation**: A technical task that involves producing working code
    for a video game. This task can be split into subtasks such as:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：一项技术任务，涉及为视频游戏生成有效代码。这项任务可以分解为以下子任务：'
- en: Create basic movements and integrate their logic into the game engine’s loop.
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建基本动作并将它们的逻辑整合到游戏引擎的循环中。
- en: Add advanced movement features like printing or jumping logic with gravity.
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加高级动作功能，如带有重力的打印或跳跃逻辑。
- en: Ensure physics and collision handling are enabled.
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保启用物理和碰撞处理。
- en: Enable debugging and optimization by generating testing procedures.
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过生成测试程序来启用调试和优化。
- en: Generate documentation for future reference.
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成文档供将来参考。
- en: 'Let’s consider the following example. We will provide the model with a short
    article and ask it to summarize it following these instructions:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下示例。我们将向模型提供一个简短的文章，并要求它根据这些指示进行总结：
- en: You are an AI assistant that summarizes articles.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是一个总结文章的人工智能助手。
- en: 'To complete this task, do the following subtasks:'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要完成这项任务，请执行以下子任务：
- en: Read the provided article context comprehensively and identify the main topic
    and key points.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全面阅读提供的文章内容，并确定主要主题和关键点。
- en: Generate a paragraph summary of the current article context that captures the
    essential information and conveys the main idea.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一个段落摘要，概括当前文章内容，传达主要思想。
- en: Print each step of the process.
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印每个步骤。
- en: 'This is the short article we will provide:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将提供的简短文章：
- en: '[PRE0]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s see how the model works:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模型是如何工作的：
- en: '![](img/B31559_03_11.png)Figure 3.9: Example of OpenAI GPT-4o splitting a task
    into subtasks to generate a summary'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B31559_03_11.png)图3.9：OpenAI GPT-4o将任务分解为子任务以生成摘要的示例'
- en: Splitting complex tasks into easier sub tasks is a powerful technique. Nevertheless,
    it does not address one of the main risks of LLM-generated content, that is, having
    an incorrect output. In the next two subsections, we are going to see some techniques
    that are mainly aimed at addressing this risk.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 将复杂任务分解为更简单的子任务是一种强大的技术。然而，它并没有解决LLM生成内容的主要风险之一，即输出可能不正确。在接下来的两个小节中，我们将看到一些主要旨在解决这一风险的技术。
- en: Ask for justification
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 请求进行论证。
- en: In prompt engineering, requesting that a model provides justifications for its
    responses enhances transparency and reliability. This practice allows users to
    assess the reasoning behind the model’s answers, ensuring they are logical and
    grounded in relevant information ([https://arxiv.org/abs/2303.08769](https://arxiv.org/abs/2303.08769)).
    By understanding the model’s thought process, users can identify potential biases
    or inaccuracies, leading to more informed decisions and effective utilization
    of AI systems.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示工程中，要求模型为其响应提供解释可以增强透明度和可靠性。这种做法使用户能够评估模型答案背后的推理，确保它们是逻辑的，并且基于相关信息（[https://arxiv.org/abs/2303.08769](https://arxiv.org/abs/2303.08769)）。通过理解模型的思想过程，用户可以识别潜在的偏见或不准确性，从而做出更明智的决定，并有效地利用AI系统。
- en: For instance, when an AI model suggests a medical diagnosis, asking for its
    reasoning can reveal whether the suggestion is based on pertinent symptoms and
    medical history or if it’s influenced by irrelevant data. Similarly, in legal
    contexts, if an AI system provides case recommendations, understanding its justification
    helps ensure the advice is based on appropriate legal precedents. This level of
    insight is crucial for building trust in AI applications and for refining prompts
    to elicit more accurate and contextually appropriate responses.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当AI模型提出医学诊断时，要求其提供推理可以揭示建议是否基于相关的症状和病史，或者是否受到无关数据的影响。同样，在法律环境中，如果AI系统提供案例推荐，理解其解释有助于确保建议基于适当的法律先例。这种程度的洞察力对于建立对AI应用的信任以及改进提示以获得更准确和上下文相关的响应至关重要。
- en: 'Let’s consider the following example. We want our LLM to solve riddles and
    we prompt it with the following set of instructions:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下例子。我们希望我们的LLM能够解决谜题，我们用以下指令提示它：
- en: '![](img/B31559_03_12.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_12.png)'
- en: 'Figure 3.10: Example of OpenAI’s GPT-4o providing justification after solving
    a riddle'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10：OpenAI的GPT-4o在解决谜题后提供解释的示例
- en: With a similar approach, we could also intervene at different prompt levels
    to improve our LLM’s performance. For example, we might discover that the model
    is systematically tackling a mathematical problem in the wrong way, hence we might
    want to suggest the right approach directly at the meta-prompt level.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似的方法，我们也可以在不同的提示级别上进行干预，以改善我们LLM的性能。例如，我们可能会发现模型在系统地解决数学问题时采取了错误的方法，因此我们可能希望在元提示级别上直接建议正确的方法。
- en: Another example might be that of asking the model to generate multiple outputs
    – along with their justifications – to evaluate different reasoning techniques
    and prompt the best one in the meta-prompt. We’ll focus on this in the next subsection.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子可能是要求模型生成多个输出及其解释，以评估不同的推理技术，并在元提示中提示最佳的一个。我们将在下一小节中关注这一点。
- en: Generate many outputs, then use the model to pick the best one
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成许多输出，然后使用模型选择最佳的一个
- en: In prompt engineering, instructing a model to generate multiple responses to
    a single prompt is a technique known as self-consistency. This approach involves
    directing the model to produce several outputs for a given input, which are then
    evaluated to identify the most consistent or accurate response. By comparing these
    multiple outputs, users can discern common themes or solutions, enhancing the
    reliability of the LLM’s performance.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示工程中，指导模型对单个提示生成多个响应的技术被称为自洽性。这种方法涉及指导模型为给定输入生成多个输出，然后对这些输出进行评估，以确定最一致或最准确的响应。通过比较这些多个输出，用户可以辨别出共同的主题或解决方案，从而提高LLM性能的可靠性。
- en: 'Let’s see an example, following up with the riddles examined in the previous
    section:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子，继续探讨上一节中讨论的谜题：
- en: You are an AI assistant specialized in solving riddles.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是一个专门解决谜题的人工智能助手。
- en: Given a riddle, you have to generate three answers to the riddle.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个谜题，你必须为这个谜题生成三个答案。
- en: For each answer, be specific about the reasoning you made.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个答案，具体说明你的推理。
- en: Then, among the three answers, select the one which is most plausible given
    the riddle.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，在三个答案中，选择最有可能的答案。
- en: 'In this case, I’ve prompted the model to generate three answers to the riddle,
    then to give me the most likely, justifying why. Let’s see the result:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我提示模型为谜题生成三个答案，然后告诉我最有可能的答案，并解释原因。让我们看看结果：
- en: '![](img/B31559_03_13.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_13.png)'
- en: 'Figure 3.11: Example of GPT-4o generating three plausible answers and picking
    the most likely one, providing justification'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11：GPT-4o生成三个可能的答案并选择最有可能的一个的示例，提供理由
- en: As previously mentioned, forcing the model to tackle a problem with different
    approaches is a way to collect multiple samples of reasonings, which might serve
    as further instructions in the meta-prompt. For example, if we want the model
    to always propose something that is not the most straightforward solution to a
    problem – in other words, if we want it to “think differently” – we might force
    it to solve a problem in N ways and then use the most creative reasoning as the
    framework in the meta-prompt.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，强迫模型以不同的方法解决一个问题是一种收集多个推理样本的方法，这些样本可能作为元提示中的进一步指令。例如，如果我们想让模型始终提出不是解决问题的最直接解决方案的东西——换句话说，如果我们想让它“思考不同”的话——我们可能强迫它以N种方式解决问题，然后使用最富有创造性的推理作为元提示的框架。
- en: The last element we are going to examine is the overall structure we want to
    give to our meta-prompt.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要检查的最后一个是我们要赋予我们的元提示的整体结构。
- en: Use delimiters
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用分隔符
- en: The last principle to be covered is related to the format we want to give to
    our meta prompt. This helps our LLM to better understand its intents as well as
    to make connections among sections and paragraphs.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要讨论的原则与我们想要赋予我们的元提示的格式有关。这有助于我们的LLM更好地理解其意图，以及在不同段落之间建立联系。
- en: 'To achieve this, we can use delimiters within our prompt. A delimiter can be
    any sequence of characters or symbols that is clearly mapping a schema rather
    than a concept. For example, we can consider the following sequence delimiters:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们可以在我们的提示中使用分隔符。分隔符可以是任何字符或符号的序列，它清楚地映射一个模式而不是一个概念。例如，我们可以考虑以下序列分隔符：
- en: '`>>>>`'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`>>>>`'
- en: '`====`'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`====`'
- en: '`------`'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`------`'
- en: '`####`'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`####`'
- en: '`` ` ` ` ` ` ``'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`` ` ` ` ` ` ``'
- en: 'Let’s consider, for example, a meta-prompt that aims at instructing the model
    to translate a user’s tasks into Python code, also providing an example of doing
    so:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个旨在指导模型将用户的任务翻译成Python代码的元提示为例，并提供一个这样的例子：
- en: '[PRE1]def my_print(text):'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]def my_print(text):'
- en: '#returning the printed text'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '#返回打印的文本'
- en: return print(text)
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return print(text)
- en: '[PRE2]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s see how it works:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的：
- en: '![](img/B31559_03_14.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_14.png)'
- en: 'Figure 3.12: Sample output of a model using delimiters in the system message'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12：使用分隔符的系统消息的模型样本输出
- en: As you can see, it also printed the code in backticks as shown within the system
    message.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，它还打印了系统消息中显示的反引号内的代码。
- en: All the principles examined up to this point are general rules that can make
    your interaction with ChatGPT and, more broadly, GenAI tools more meaningful to
    your goal. In the next section, we are going to see some advanced techniques for
    prompt engineering that address the way the model reasons and thinks about the
    answer, before providing it to the final user.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止所检查的所有原则都是一般规则，可以使您与ChatGPT的互动，以及更广泛地说，与GenAI工具的互动对您的目标更有意义。在下一节中，我们将看到一些针对提示工程的高级技术，这些技术针对模型推理和思考答案的方式，在提供给最终用户之前。
- en: Meta-prompting
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元提示
- en: In prompt engineering, instructing a model to refine its own prompts – also
    known as meta-prompting ([https://arxiv.org/abs/2401.12954](https://arxiv.org/abs/2401.12954))
    – is an effective technique to enhance prompt quality and, consequently, the relevance
    of generated outputs. By engaging the model in the iterative process of prompt
    refinement, users can leverage the model’s language understanding to identify
    ambiguities or areas for improvement within the initial prompt. This self-improvement
    loop leads to more precise and contextually appropriate prompts, which in turn
    elicit more accurate and useful responses from the model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示工程中，指导模型改进其自己的提示——也称为元提示（[https://arxiv.org/abs/2401.12954](https://arxiv.org/abs/2401.12954)）——是一种提高提示质量的有效技术，从而提高生成输出的相关性。通过让模型参与提示改进的迭代过程，用户可以利用模型的语言理解能力来识别初始提示中的歧义或改进领域。这个自我改进的循环导致更精确和上下文相关的提示，进而从模型中获得更准确和有用的响应。
- en: For instance, let’s say we want to generate an elevator pitch for our new sustainable
    brand of running shoes. How would you ask the LLM to do that? Well, you might
    leverage some of the above techniques, like clear instructions or splitting the
    task into sub tasks; alternatively (or additionally), you could ask the LLM itself
    to refine your prompt to make it more relevant to your goal.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要为我们的新可持续品牌跑步鞋生成一个电梯简报。你将如何请求LLM来完成这个任务？嗯，你可能会利用上述的一些技巧，比如清晰的指令或将任务分解成子任务；或者（或附加地），你可以请求LLM本身细化你的提示，使其更符合你的目标。
- en: 'To do that, we can initially instruct the model to refine the prompt as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们可以最初指示模型按照以下方式细化提示：
- en: '![](img/B31559_03_15.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_15.png)'
- en: 'Figure 3.13: Example of a user asking ChatGPT to refine a prompt'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13：用户请求ChatGPT细化提示的示例
- en: 'Now, let’s send our prompt:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们发送我们的提示：
- en: '![](img/B31559_03_16.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_16.png)'
- en: 'Figure 3.14: Example of ChatGPT refining the user’s prompt'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14：ChatGPT细化用户提示的示例
- en: As you can see, ChatGPT was able to refine our prompt and make it more tailored
    to our goal. Note that, in the above example, we only asked for one refinement;
    however, this can be an iterative process to not only enhance the clarity and
    precision of the prompt but also ensure that the model’s outputs are more aligned
    with the user’s specific requirements, making interactions more efficient and
    productive.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，ChatGPT能够细化我们的提示，使其更符合我们的目标。注意，在上面的例子中，我们只要求了一次细化；然而，这可以是一个迭代过程，不仅能够增强提示的清晰度和精确度，还能确保模型的输出更符合用户的特定要求，使交互更加高效和富有成效。
- en: Exploring some advanced techniques
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索一些高级技巧
- en: In previous sections, we covered some basic techniques of prompt engineering
    that can improve your LLM’s response regardless of the type of task you are trying
    to accomplish.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们介绍了一些基本的提示工程技巧，这些技巧可以提高你尝试完成任何类型任务时LLM的响应。
- en: On the other hand, there are some advanced techniques that might be implemented
    for specific scenarios that we are going to cover in this section.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，还有一些可能针对特定场景实施的高级技巧，我们将在本节中介绍。
- en: '**Note**'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: Some advanced prompt engineering techniques like **chain-of-thought** (**CoT**)
    prompting are integrated into modern models such as OpenAI’s o1 series. These
    models are designed to internally process complex reasoning tasks by generating
    step-by-step logical sequences before arriving at a final answer, enhancing their
    problem-solving capabilities. This internal reasoning process allows o1 models
    to handle intricate queries more effectively without requiring explicit CoT prompts
    from users. However, employing CoT prompting can still be beneficial in guiding
    the model’s reasoning process for specific tasks and, more broadly, is a good
    practice whenever we interact with models of previous versions that do not exhibit
    advanced reasoning capabilities.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一些高级提示工程技巧，如**思维链**（**CoT**）提示，已集成到现代模型中，例如OpenAI的o1系列。这些模型被设计为通过生成逐步逻辑序列并在得出最终答案之前内部处理复杂的推理任务，从而增强其解决问题的能力。这种内部推理过程允许o1模型更有效地处理复杂查询，而无需用户显式提供CoT提示。然而，使用CoT提示仍然可以在指导模型针对特定任务的推理过程时带来好处，并且更广泛地说，在与之前版本不显示高级推理能力的模型交互时，这是一种良好的实践。
- en: Chain of thought
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链
- en: Introduced in the paper *Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models* by Wei et al., CoT is a technique that enables complex reasoning
    capabilities through intermediate reasoning steps. It also encourages the model
    to explain its reasoning, “forcing” it not to be too fast and risk giving the
    wrong response (as we saw in previous sections).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在Wei等人撰写的论文《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》中引入的CoT是一种通过中间推理步骤实现复杂推理能力的技巧。它还鼓励模型解释其推理过程，“迫使”它不要过于迅速，以免给出错误响应（如我们在前面的章节中看到的）。
- en: 'Let’s say that we want to prompt our LLM to solve first-degree equations. To
    do so, we are going to provide it with a generic reasoning list as a meta-prompt:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要提示我们的语言模型（LLM）解决一元方程。为此，我们将提供一个通用的推理列表作为元提示：
- en: '[PRE3]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s see how it works:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何工作的：
- en: '![](img/B31559_03_17.png)![](img/B31559_03_18.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_17.png)![](img/B31559_03_18.png)'
- en: 'Figure 3.15: Output of the model solving an equation with the CoT approach'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15：使用CoT方法求解方程的模型输出
- en: This methodical approach mirrors human problem-solving by decomposing the task
    into manageable steps, enhancing clarity and reducing errors.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法性的方法通过将任务分解为可管理的步骤来模拟人类问题解决，增强了清晰度并减少了错误。
- en: With CoT, we are prompting the model to generate intermediate reasoning steps.
    This is also a component of another reasoning technique that we are going to examine
    next.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CoT，我们正在提示模型生成中间推理步骤。这也是我们将要考察的另一种推理技术的组成部分。
- en: ReAct
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct
- en: 'Introduced in the paper *ReAct: Synergizing Reasoning and Acting in Language
    Models* by Yao et al., **Reason and Act** (**ReAct**) is a general paradigm that
    combines reasoning and acting with LLMs. ReAct prompts the language model to generate
    verbal reasoning traces and actions for a task, and also receive observations
    from external sources such as web searches or databases. This allows the language
    model to perform dynamic reasoning and quickly adapt its action plan based on
    external information. For example, you can prompt the language model to answer
    a question by first reasoning about the question, then performing an action to
    send a query to the web, then receiving an observation from the search results,
    and then continuing with this thought, action, observation loop until it reaches
    a conclusion.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 由姚等人发表的论文《ReAct：在语言模型中协同推理和行动》中引入的**Reason and Act**（**ReAct**）是一个将推理和行动与LLMs结合的通用范式。ReAct提示语言模型为任务生成口头推理轨迹和行动，并从外部来源接收观察，如网络搜索或数据库。这使得语言模型能够执行动态推理，并根据外部信息快速调整其行动计划。例如，你可以提示语言模型通过首先对问题进行推理，然后执行一个动作向网络发送查询，然后从搜索结果中接收观察，接着继续这个思考、行动、观察的循环，直到得出结论。
- en: The difference between CoT and ReAct approaches is that CoT prompts the language
    model to generate intermediate reasoning steps for a task, while ReAct prompts
    the language model to generate intermediate reasoning steps, actions, and observations
    for a task.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: CoT和ReAct方法之间的区别在于，CoT提示语言模型为任务生成中间推理步骤，而ReAct提示语言模型为任务生成中间推理步骤、行动和观察。
- en: Note that the “action” phase is generally related to the possibility of our
    LLM interacting with external tools, such as web search. However, in the following
    example, we won’t use tools but rather refer to the term “action” for any task
    we ask the model to do for us.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，“行动”阶段通常与我们的LLM与外部工具（如网络搜索）交互的可能性有关。然而，在以下示例中，我们不会使用工具，而是将“行动”一词用于我们要求模型为我们执行的任何任务。
- en: 'This is how the ReAct meta-prompt might look:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是ReAct元提示可能的样子：
- en: '[PRE4]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s see how it works with a simple user query:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它如何通过一个简单的用户查询来工作：
- en: '![](img/B31559_03_19.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_19.png)'
- en: 'Figure 3.16: Example of ReAct prompting'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16：ReAct提示示例
- en: As you can see, in this scenario, the model leveraged the web tool at the action
    input.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在这个场景中，模型利用了动作输入处的网络工具。
- en: This is a great example of how prompting a model to think step by step and explicitly
    detail each step of the reasoning makes it “wiser” and more cautious before answering.
    It is also a great technique to prevent hallucination.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的例子，说明了如何通过提示模型逐步思考和明确详细每个推理步骤，使其在回答之前变得更加“聪明”和谨慎。这同样是一种防止幻觉的出色技术。
- en: Overall, prompt engineering is a powerful discipline, still in its emerging
    phase yet already widely adopted within LLM-powered applications. In the following
    chapters, we are going to see concrete applications of these techniques.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，提示工程是一门强大的学科，尽管它仍处于起步阶段，但已经在LLM驱动的应用中得到广泛应用。在接下来的章节中，我们将看到这些技术的具体应用。
- en: Ethical considerations to avoid bias
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免偏差的伦理考量
- en: Whenever we deal with AI systems like LLMs, we must be aware of their associated
    risk of **hidden bias**, which derives directly from the knowledge base the model
    has been trained on.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们处理像LLMs这样的AI系统时，我们必须意识到它们相关的**隐藏偏差**风险，这种偏差直接来源于模型训练所使用的知识库。
- en: '**Definition**'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: Hidden bias, also known as implicit or unconscious bias, refers to the subtle
    and unintentional attitudes, stereotypes, or associations that influence a person’s
    perceptions and actions without their conscious awareness. These biases can shape
    behaviors and decisions in ways that reflect societal stereotypes, often leading
    to unintended discrimination. For example, someone might unknowingly associate
    leadership roles with men over women, which could impact hiring or promotion choices.
    In the context of LLM, hidden bias manifests in the model’s outputs when it reproduces
    or amplifies biases present in its training data, potentially leading to skewed
    or unfair responses. Addressing hidden bias is essential to fostering fairness
    and reducing systemic inequities.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏偏见，也称为隐含或无意识偏见，指的是那些微妙且非故意的态度、刻板印象或关联，它们在不经意间影响一个人的感知和行为，而他们自己并没有意识到。这些偏见可能会以反映社会刻板印象的方式塑造行为和决策，往往导致无意的歧视。例如，有人可能无意中将领导角色与男性而非女性联系起来，这可能会影响招聘或晋升选择。在LLM的背景下，隐藏偏见在模型输出中表现为它复制或放大了训练数据中存在的偏见，可能导致偏颇或不公平的回应。解决隐藏偏见对于促进公平和减少系统性不平等至关重要。
- en: For example, concerning the main chunk of training data of GPT-3, known as the
    **Common Crawl**, a 2012 study ([https://commoncrawl.org/blog/a-look-inside-common-crawls-210tb-2012-web-corpus](https://commoncrawl.org/blog/a-look-inside-common-crawls-210tb-2012-web-corpus))
    revealed that over 55% of the corpus originated from .*com* domains, with twelve
    top-level domains each representing more than 1% of the data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，关于GPT-3的主要训练数据块，即**Common Crawl**，一项2012年的研究（[https://commoncrawl.org/blog/a-look-inside-common-crawls-210tb-2012-web-corpus](https://commoncrawl.org/blog/a-look-inside-common-crawls-210tb-2012-web-corpus)）揭示了超过55%的语料库来自.*com*域名，其中十二个顶级域名各自代表了超过1%的数据。
- en: Given that *.com* domains are heavily utilized by Western entities, this concentration
    suggests a significant Western influence in the dataset. Additionally, the prevalence
    of English-language content within Common Crawl further indicates a Western-centric
    bias, as English is predominantly spoken in Western nations.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*.com*域名在西方实体中被广泛使用，这种集中性表明数据集中存在显著的西方影响。此外，Common Crawl中英语内容的普遍存在进一步表明存在以西方为中心的偏见，因为英语在西方国家的使用占主导地位。
- en: If this is the case, we are already facing a hidden bias of the model (more
    specifically, a racial and linguistic bias), which will inevitably mimic a limited
    and unrepresentative category of human beings.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果情况如此，我们已经在面对模型的隐藏偏见（更具体地说，是种族和语言偏见），这不可避免地会模仿一个有限且不具有代表性的类别的人类。
- en: In their paper *Language Models are Few-Shots Learners* ([https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)),
    OpenAI’s researchers Tom Brown et al. created an experimental setup to investigate
    racial bias in GPT-3\. The model was prompted with phrases containing racial categories
    and 800 samples were generated for each category. The sentiment of the generated
    text was measured using Senti WordNet based on word co-occurrences on a scale
    ranging from -100 to 100 (with positive scores indicating positive words and vice
    versa).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文《*语言模型是少样本学习者*》（[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)）中，OpenAI的研究员汤姆·布朗等人创建了一个实验设置，以调查GPT-3中的种族偏见。模型被提示使用包含种族类别的短语，并为每个类别生成了800个样本。生成的文本的情感是通过基于词共现的Senti
    WordNet在-100到100的范围内测量的（正分数表示积极词汇，反之亦然）。
- en: The results showed that the sentiment associated with each racial category varied
    across different models, with *Asian* consistently having a high sentiment (meaning
    a lot of positive words) and *Black* consistently having a low sentiment (meaning
    a lot of negative words). The authors caution that the results reflect the experimental
    setup and that socio-historical factors may influence the sentiment associated
    with different demographics.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，与每个种族类别相关的情感在不同模型中有所不同，*亚洲*始终具有高情感（意味着很多积极词汇）和*黑人*始终具有低情感（意味着很多负面词汇）。作者警告说，这些结果反映了实验设置，社会历史因素可能会影响与不同人口统计数据相关的情感。
- en: This hidden bias could generate harmful responses not in line with responsible
    AI principles.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这种隐藏偏见可能会产生不符合负责任AI原则的有害回应。
- en: However, it is worth noting how ChatGPT, as well as all OpenAI models, are subject
    to continuous improvements. This is also consistent with OpenAI’s AI alignment
    ([https://openai.com/index/our-approach-to-alignment-research/](https://openai.com/index/our-approach-to-alignment-research/)),
    whose research focuses on training AI systems to be helpful, truthful, and safe.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，值得注意的是 ChatGPT 以及所有 OpenAI 模型都受到持续改进的影响。这也与 OpenAI 的 AI 对齐([https://openai.com/index/our-approach-to-alignment-research/](https://openai.com/index/our-approach-to-alignment-research/))一致，其研究重点在于训练
    AI 系统变得有帮助、真实和安全。
- en: 'For example, if we ask GPT-4o to formulate guesses based on people’s gender
    and age, it will not accommodate the exact request, but rather provide us with
    a hypothetical function as well as a huge disclaimer:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们要求 GPT-4o 根据人们的性别和年龄来制定猜测，它不会满足我们的确切要求，而是提供一个假设函数以及一个巨大的免责声明：
- en: '![](img/B31559_03_20.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_03_20.png)'
- en: 'Figure 3.17: Example of GPT-4o improving over time since it gives an unbiased
    response'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.17：GPT-4o 随时间改进的示例，因为它提供了无偏见的响应
- en: Overall, despite the continuous improvement in the domain of ethical principles,
    while using ChatGPT, we should always make sure that the output is in line with
    those principles. The concepts of bias and ethics within ChatGPT and OpenAI models
    have a wider connotation within the whole topic of responsible AI, which we are
    going to focus on in the last chapter of this book.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，尽管在道德原则领域持续改进，但在使用 ChatGPT 时，我们应始终确保输出与这些原则一致。ChatGPT 和 OpenAI 模型中的偏见和伦理概念在整个负责任
    AI 主题中具有更广泛的含义，我们将在本书最后一章中关注这一点。
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have dived into the concept of prompt engineering since
    it’s a key component to control the output of ChatGPT and LLMs in general. We
    learned how to leverage different levels of shot learning to make LLMs more tailored
    to our objectives.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了 prompt engineering 的概念，因为它控制 ChatGPT 和 LLMs 输出的关键组成部分。我们学习了如何利用不同级别的
    shot learning 来使 LLMs 更符合我们的目标。
- en: We started with an introduction to the concept of prompt engineering and why
    it is important, then moving toward the basic principles – including clear instructions,
    asking for justification, etc.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从介绍 prompt engineering 的概念及其重要性开始，然后转向基本原理——包括清晰的指令、要求证明等。
- en: 'Then, we moved toward more advanced techniques, which are meant to shape the
    reasoning approach of our LLMs: few-shot learning, CoT, and ReAct.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们转向更高级的技术，这些技术旨在塑造我们的 LLMs 的推理方法：少样本学习、CoT 和 ReAct。
- en: Prompt engineering is an emerging discipline that is paving the way for a new
    category of applications, infused with LLMs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt engineering 是一门新兴学科，它为融入 LLMs 的新类别应用铺平了道路。
- en: Starting from the next chapter, we will explore different domains where ChatGPT
    can boost productivity and have a disruptive impact on the way we work today.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 从下一章开始，我们将探讨 ChatGPT 可以提高生产力和对我们今天工作方式产生颠覆性影响的各个领域。
- en: References
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'The following are the references for this chapter:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为本章的参考文献：
- en: '*Language Models are Few-Shot Learners*: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《语言模型是少样本学习者》*：[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
- en: '*On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?*: [https://dl.acm.org/doi/10.1145/3442188.3445922](https://dl.acm.org/doi/10.1145/3442188.3445922)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《随机鹦鹉的危险：语言模型可以太大吗？》*：[https://dl.acm.org/doi/10.1145/3442188.3445922](https://dl.acm.org/doi/10.1145/3442188.3445922)'
- en: 'ReAct approach: [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReAct 方法：[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
- en: 'Chain-of-thought approach: [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链式思维方法：[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
- en: '*What is prompt engineering?*: [https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是 prompt engineering？*：[https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering)'
- en: 'Prompt engineering principles: [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程原则：[https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions)
