<html><head></head><body>
<div aria-label="267" epub:type="pagebreak" id="page1-9" role="doc-pagebreak"/>
<div class="Basic-Text-Frame" id="_idContainer099">
<h1 class="chapterNumber"><a id="_idTextAnchor327"/><span class="koboSpan" id="kobo.1.1">7</span></h1>
<h1 class="chapterTitle" id="_idParaDest-170"><a id="_idTextAnchor328"/><span class="koboSpan" id="kobo.2.1">Software Development and Data Analysis Agents</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">This chapter explores how natural language—our everyday English or whatever language you prefer to interact in with an LLM—has emerged as a powerful interface for programming, a paradigm shift that, when taken to its extreme, is called </span><em class="italic"><span class="koboSpan" id="kobo.4.1">vibe coding</span></em><span class="koboSpan" id="kobo.5.1">. </span><span class="koboSpan" id="kobo.5.2">Instead of learning acquiring new programming languages or frameworks, developers can now articulate their intent in natural language, leaving it to advanced LLMs and frameworks such as LangChain to translate these ideas into robust, production-ready code. </span><span class="koboSpan" id="kobo.5.3">Moreover, while traditional programming languages remain essential for production systems, LLMs are creating new workflows that complement existing practices and potentially increase accessibility This evolution represents a significant shift from earlier attempts at code generation and automation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.6.1">We’ll specifically discuss LLMs’ place in software development and the state of the art of performance, models, and applications. </span><span class="koboSpan" id="kobo.6.2">We’ll see how to use LLM chains and agents to help in code generation and data analysis, training ML models, and extracting predictions. </span><span class="koboSpan" id="kobo.6.3">We’ll cover writing code with LLMs, giving examples with different models be it on Google’s generative AI services, Hugging Face, or Anthropic. </span><span class="koboSpan" id="kobo.6.4">After this, we’ll move on to more advanced approaches with agents and RAG for documentation or a code repository.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.7.1">We’ll also be applying LLM agents to data science: we’ll first train a model on a dataset, then we’ll analyze and visualize a dataset. </span><span class="koboSpan" id="kobo.7.2">Whether you’re a developer, a data scientist, or a technical decision-maker, this chapter will equip you with a clear understanding of how LLMs are reshaping software development and data analysis while maintaining the essential role of conventional programming languages.</span></p>
<div aria-label="268" epub:type="pagebreak" id="page2-9" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.8.1">The following topics will be covered in this chapter:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.9.1">LLMs in software development</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.10.1">Writing code with LLMs</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.11.1">Applying LLM agents for data science</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-171"><a id="_idTextAnchor329"/><span class="koboSpan" id="kobo.12.1">LLMs in software development</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.13.1">The relationship </span><a id="_idIndexMarker581"/><span class="koboSpan" id="kobo.14.1">between natural language and programming is undergoing a significant transformation. </span><span class="koboSpan" id="kobo.14.2">Traditional programming languages remain essential in software development—C++ and Rust for performance-critical applications, Java and C# for enterprise systems, and Python for rapid development, data analysis, and ML workflows. </span><span class="koboSpan" id="kobo.14.3">However, natural language, particularly English, now serves as a powerful interface to streamline software development and data science tasks, complementing rather than replacing these specialized programming tools.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.15.1">Advanced AI assistants let you build software by simply staying “in the vibe” of what you want, without ever writing or even picturing a line of code. </span><span class="koboSpan" id="kobo.15.2">This style of development, known as vibe coding, was popularized by Andrej Karpathy in early 2025. </span><span class="koboSpan" id="kobo.15.3">Instead of framing tasks in programming terms or wrestling with syntax, you describe desired behaviors, user flows or outcomes in plain conversation. </span><span class="koboSpan" id="kobo.15.4">The model then orchestrates data structures, logic and integration behind the scenes. </span><span class="koboSpan" id="kobo.15.5">With vibe coding you don’t debug—you re-vibe. </span><span class="koboSpan" id="kobo.15.6">This means, you iterate by restating or refining requirements in natural language, and let the assistant reshape the system. </span><span class="koboSpan" id="kobo.15.7">The result is a pure, intuitive design-first workflow that completely abstracts away all coding details.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.16.1">Tools such as Cursor, Windsurf (formerly Codeium), OpenHands, and Amazon Q Developer have emerged to support this development approach, each offering different capabilities for AI-assisted coding. </span><span class="koboSpan" id="kobo.16.2">In practice, these interfaces are democratizing software creation while freeing experienced engineers from repetitive tasks. </span><span class="koboSpan" id="kobo.16.3">However, balancing speed with code quality and security remains critical, especially for production systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.17.1">The software development landscape has long sought to make programming more accessible through various abstraction layers. </span><span class="koboSpan" id="kobo.17.2">Early efforts included fourth-generation languages that aimed to simplify syntax, allowing developers to express logic with fewer lines of code. </span><span class="koboSpan" id="kobo.17.3">This evolution continued with modern low-code platforms, which introduced visual programming with pre-built components to democratize application development beyond traditional coding experts. </span><span class="koboSpan" id="kobo.17.4">The latest and perhaps most transformative evolution features natural language programming through LLMs, which interpret human intentions expressed in plain language and translate them into functional code.</span></p>
<div aria-label="269" epub:type="pagebreak" id="page3-9" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.18.1">What makes this current evolution particularly distinctive is its fundamental departure from previous approaches. </span><span class="koboSpan" id="kobo.18.2">Rather than creating new artificial languages for humans to learn, we’re adapting intelligent tools to understand natural human communication, significantly lowering the barrier to entry. </span><span class="koboSpan" id="kobo.18.3">Unlike traditional low-code platforms that often result in proprietary implementations, natural language programming generates standard code without vendor lock-in, preserving developer freedom and compatibility with existing ecosystems. </span><span class="koboSpan" id="kobo.18.4">Perhaps most importantly, this approach offers unprecedented flexibility across the spectrum, from simple tasks to complex applications, serving both novices seeking quick solutions and experienced developers looking to accelerate their workflow. </span><a id="_idTextAnchor330"/></p>
<h2 class="heading-2" id="_idParaDest-172"><a id="_idTextAnchor331"/><span class="koboSpan" id="kobo.19.1">The future of development</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.20.1">Analysts at International </span><a id="_idIndexMarker582"/><span class="koboSpan" id="kobo.21.1">Data Corporation (IDC) project that, by 2028, natural language will be used to create 70% of new digital solutions (IDC FutureScape, </span><em class="italic"><span class="koboSpan" id="kobo.22.1">Worldwide Developer and DevOps 2025 Predictions</span></em><span class="koboSpan" id="kobo.23.1">). </span><span class="koboSpan" id="kobo.23.2">However, this doesn’t mean traditional programming will disappear; rather, it’s evolving into a two-tier system where natural language serves as a high-level interface while traditional programming languages handle precise implementation details.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.24.1">However, this evolution does not spell the end for traditional programming languages. </span><span class="koboSpan" id="kobo.24.2">While natural language can streamline the design phase and accelerate prototyping, the precision and determinism of languages like Python remain essential for building reliable, production-ready systems. </span><span class="koboSpan" id="kobo.24.3">In other words, rather than replacing code entirely, English (or Mandarin, or whichever natural language best suits our cognitive process) is augmenting it—acting as a high-level layer that bridges human intent with executable logic.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.25.1">For software developers, data scientists, and technical decision-makers, this shift means embracing a hybrid workflow where natural language directives, powered by LLMs and frameworks such as LangChain, coexist with conventional code. </span><span class="koboSpan" id="kobo.25.2">This integrated approach paves the way for faster innovation, personalized software solutions, and, ultimately, a more accessible development process</span><a id="_idTextAnchor332"/><span class="koboSpan" id="kobo.26.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-173"><a id="_idTextAnchor333"/><span class="koboSpan" id="kobo.27.1">Implementation considerations</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.28.1">For production environments, the</span><a id="_idIndexMarker583"/><span class="koboSpan" id="kobo.29.1"> current evolution manifests in several ways that are transforming how development teams operate. </span><span class="koboSpan" id="kobo.29.2">Natural language interfaces enable faster prototyping and reduce time spent on boilerplate code, while traditional programming remains essential for the optimization and implementation of complex features. </span><span class="koboSpan" id="kobo.29.3">However, recent independent research shows significant limitations in current AI coding capabilities. </span></p>
<div aria-label="270" epub:type="pagebreak" id="page4-9" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.30.1">The 2025 OpenAI </span><em class="italic"><span class="koboSpan" id="kobo.31.1">SWE-Lancer</span></em><span class="koboSpan" id="kobo.32.1"> benchmark study found that even the top-performing model completed only 26.2% of individual engineering tasks drawn from real-world freelance projects. </span><span class="koboSpan" id="kobo.32.2">The research identified specific challenges including surface-level problem-solving, limited context understanding across multiple files, inadequate testing, and poor edge case handling.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.33.1">Despite these limitations, many organizations report productivity gains when using AI coding assistants in targeted ways. </span><span class="koboSpan" id="kobo.33.2">The most effective approach appears to be collaboration—using AI to accelerate routine tasks while applying human expertise to areas where AI still struggles, such as architectural decisions, comprehensive testing, and understanding business requirements in context. </span><span class="koboSpan" id="kobo.33.3">As the technology matures, the successful integration of natural language and traditional programming will likely depend on clearly defining where each excels rather than assuming AI can autonomously handle complex software engineering challenges.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.34.1">Code maintenance has evolved through AI-assisted approaches where developers use natural language to understand and modify codebases. </span><span class="koboSpan" id="kobo.34.2">While GitHub reports Copilot users completed specific coding tasks 55% faster in controlled experiments, independent field studies show more modest productivity gains ranging from 4–22%, depending on context and measurement approach. </span><span class="koboSpan" id="kobo.34.3">Similarly, Salesforce reports their internal CodeGenie tool contributes to productivity improvements, including automating aspects of code review and security scanning. </span><span class="koboSpan" id="kobo.34.4">Beyond raw speed improvements, research consistently shows AI coding assistants reduce developer cognitive load and improve satisfaction, particularly for repetitive tasks. </span><span class="koboSpan" id="kobo.34.5">However, studies also highlight important limitations: generated code often requires significant human verification and rework, with some independent research reporting higher bug rates in AI-assisted code. </span><span class="koboSpan" id="kobo.34.6">The evidence suggests these tools are valuable assistants that streamline development workflows while still requiring human expertise for quality and security assurance.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.35.1">The field of code debugging has been enhanced as natural language queries help developers identify and resolve issues faster by explaining error messages, suggesting potential fixes, and providing context for unexpected behavior. </span><span class="koboSpan" id="kobo.35.2">AXA’s deployment of “AXA Secure GPT,” trained on internal policies and code repositories, has significantly reduced routine task turnaround times, allowing development teams to focus on more strategic work (AXA, </span><em class="italic"><span class="koboSpan" id="kobo.36.1">AXA offers secure Generative AI to employees</span></em><span class="koboSpan" id="kobo.37.1">).</span></p>
<div aria-label="271" epub:type="pagebreak" id="page5-9" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.38.1">When it comes to understanding complex systems, developers can use LLMs to generate explanations and visualizations of intricate architectures, legacy codebases, or third-party dependencies, accelerating onboarding and system comprehension. </span><span class="koboSpan" id="kobo.38.2">For example, Salesforce’s system landscape diagrams show how their LLM-integrated platforms connect across various services, though recent earnings reports indicate these AI initiatives have yet to significantly impact their financial results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.39.1">System architecture itself is evolving as applications increasingly need to be designed with natural language interfaces in mind, both for development and potential user interaction. </span><span class="koboSpan" id="kobo.39.2">BMW reported implementing a platform that uses generative AI to produce real-time insights via chat interfaces, reducing the time from data ingestion to actionable recommendations from days to minutes. </span><span class="koboSpan" id="kobo.39.3">However, this architectural transformation reflects a broader industry pattern where consulting firms have become major financial beneficiaries of the generative AI boom. </span><span class="koboSpan" id="kobo.39.4">Recent industry analysis shows that consulting giants such as Accenture are generating more revenue from generative AI services ($3.6 billion in annualized bookings) than most generative AI startups combined, raising important questions about value delivery and implementation effectiveness that organizations must consider when planning their AI architecture strategies.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.40.1">For software developers, data scientists, and decision-makers, this integration means faster iteration, lower </span><a id="_idIndexMarker584"/><span class="koboSpan" id="kobo.41.1">costs, and a smoother transition from idea to deployment. </span><span class="koboSpan" id="kobo.41.2">While LLMs help generate boilerplate code and automate routine tasks, human oversight remains critical for system architecture, security, and performance. </span><span class="koboSpan" id="kobo.41.3">As the case studies demonstrate, companies integrating natural language interfaces into development and operational pipelines are already realizing tangible business value while maintaining necessary human guidan</span><a id="_idTextAnchor334"/><span class="koboSpan" id="kobo.42.1">ce.</span></p>
<h2 class="heading-2" id="_idParaDest-174"><a id="_idTextAnchor335"/><span class="koboSpan" id="kobo.43.1">Evolution of code LLMs</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.44.1">The development</span><a id="_idIndexMarker585"/><span class="koboSpan" id="kobo.45.1"> of code-specialized LLMs has </span><a id="_idIndexMarker586"/><span class="koboSpan" id="kobo.46.1">followed a rapid trajectory since their inception, progressing through three distinct phases that have transformed software development practices. </span><span class="koboSpan" id="kobo.46.2">The first </span><em class="italic"><span class="koboSpan" id="kobo.47.1">Foundation phase</span></em><span class="koboSpan" id="kobo.48.1"> (2021 to early 2022) introduced the first viable code generation models that proved the concept was feasible. </span><span class="koboSpan" id="kobo.48.2">This was followed by the </span><em class="italic"><span class="koboSpan" id="kobo.49.1">Expansion phase</span></em><span class="koboSpan" id="kobo.50.1"> (late 2022 to early 2023), which brought significant improvements in reasoning capabilities and contextual understanding. </span><span class="koboSpan" id="kobo.50.2">Most recently, the </span><em class="italic"><span class="koboSpan" id="kobo.51.1">Diversification phase</span></em><span class="koboSpan" id="kobo.52.1"> (mid-2023 to 2024) has seen the emergence of both advanced commercial offerings and increasingly capable open-source alternatives.</span></p>
<div aria-label="272" epub:type="pagebreak" id="page6-9" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.53.1">This evolution has been characterized by parallel development tracks in both proprietary and open-source ecosystems. </span><span class="koboSpan" id="kobo.53.2">Initially, commercial models dominated the landscape, but open-source alternatives have gained substantial momentum more recently. </span><span class="koboSpan" id="kobo.53.3">Throughout this progression, several key milestones have marked transformative shifts in capabilities, opening new possibilities for AI-assisted development across different programming languages and tasks. </span><span class="koboSpan" id="kobo.53.4">The historical context of this evolution provides important insights for understanding implementation approaches with LangChain. </span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.54.1"><img alt="Figure 7.1: Evolution of code LLMs (2021–2024)" src="../Images/B32363_07_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.55.1">Figure 7.1: Evolution of code LLMs (2021–2024)</span></p>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.56.1">Figure 7.1</span></em><span class="koboSpan" id="kobo.57.1"> illustrates the progression of code-specialized language models across commercial (upper track) and open-source (lower track) ecosystems. </span><span class="koboSpan" id="kobo.57.2">Key milestones are highlighted, showing the transition from early proof-of-concept models to increasingly specialized solutions. </span><span class="koboSpan" id="kobo.57.3">The timeline spans from early commercial models such as Codex to recent advancements such as Google’s Gemini 2.5 Pro (March 2025) and specialized code models such as Mistral AI’s Codestral series. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.58.1">In recent years, we’ve witnessed an explosion of LLMs fine-tuned specifically tailored for coding—commonly known as code LLMs. </span><span class="koboSpan" id="kobo.58.2">These models are rapidly evolving, each with its own set of strengths and limitations, and are reshaping the software development landscape. </span><span class="koboSpan" id="kobo.58.3">They offer the promise of accelerating development workflows across a broad spectrum of software engineering tasks:</span></p>
<div aria-label="273" epub:type="pagebreak" id="page7-8" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.59.1">Code generation: </span></strong><span class="koboSpan" id="kobo.60.1">Transforming natural language requirements into code snippets or full functions. </span><span class="koboSpan" id="kobo.60.2">For instance, developers can generate boilerplate code or entire modules based on project specifications.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.61.1">Test generation: </span></strong><span class="koboSpan" id="kobo.62.1">Creating unit tests from descriptions of expected behavior to improve code reliability.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.63.1">Code documentation</span></strong><span class="koboSpan" id="kobo.64.1">: Automatically generating docstrings, comments, and technical documentation from existing code or specifications. </span><span class="koboSpan" id="kobo.64.2">This significantly reduces the documentation burden that often gets deprioritized in fast-paced development environments.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.65.1">Code editing and refactoring: </span></strong><span class="koboSpan" id="kobo.66.1">Automatically suggesting improvements, fixing bugs, and restructuring code for maintainability.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.67.1">Code translation: </span></strong><span class="koboSpan" id="kobo.68.1">Converting code between different programming languages or frameworks.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.69.1">Debugging and automated program repair</span></strong><span class="koboSpan" id="kobo.70.1">: Identifying bugs within large codebases and generating patches to resolve issues. </span><span class="koboSpan" id="kobo.70.2">For example, tools such as SWE-agent, AutoCodeRover, and RepoUnderstander iteratively refine code by navigating repositories, analyzing abstract syntax trees, and applying targeted changes.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.71.1">The landscape of code-specialized LLMs has grown increasingly diverse and complex. </span><span class="koboSpan" id="kobo.71.2">This evolution raises critical questions for developers implementing these models in production environments: Which model is most suitable for specific programming tasks? </span><span class="koboSpan" id="kobo.71.3">How do different models compare</span><a id="_idIndexMarker587"/><span class="koboSpan" id="kobo.72.1"> in</span><a id="_idIndexMarker588"/><span class="koboSpan" id="kobo.73.1"> terms of code quality, accuracy, and reasoning capabilities? </span><span class="koboSpan" id="kobo.73.2">What are the trade-offs between open-source and commercial options? </span><span class="koboSpan" id="kobo.73.3">This is where benchmarks become essential tools for evaluation and selection. </span></p>
<h2 class="heading-2" id="_idParaDest-175"><a id="_idTextAnchor336"/><span class="koboSpan" id="kobo.74.1">Benchmarks for code LLMs</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.75.1">Objective</span><a id="_idIndexMarker589"/><span class="koboSpan" id="kobo.76.1"> benchmarks </span><a id="_idIndexMarker590"/><span class="koboSpan" id="kobo.77.1">provide standardized methods to compare model performance across a variety of coding tasks, languages, and complexity levels. </span><span class="koboSpan" id="kobo.77.2">They help quantify capabilities that would otherwise remain subjective impressions, allowing for data-driven implementation decisions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.78.1">For LangChain developers specifically, understanding benchmark results offers several advantages:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.79.1">Informed model selection:</span></strong><span class="koboSpan" id="kobo.80.1"> Choosing the optimal model for specific use cases based on quantifiable performance metrics rather than marketing claims or incomplete testing</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.81.1">Appropriate tooling</span></strong><span class="koboSpan" id="kobo.82.1">: Designing LangChain pipelines that incorporate the right balance of model capabilities and augmentation techniques based on known model strengths and limitations</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.83.1">Cost-benefit analysis:</span></strong><span class="koboSpan" id="kobo.84.1"> Evaluating whether premium commercial models justify their expense compared to free or self-hosted alternatives for particular applications</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.85.1">Performance expectations:</span></strong><span class="koboSpan" id="kobo.86.1"> Setting realistic expectations about what different models can achieve when integrated into larger</span><a id="_idTextAnchor337"/><a id="_idTextAnchor338"/><span class="koboSpan" id="kobo.87.1"> systems</span></li>
</ul>
<div aria-label="274" epub:type="pagebreak" id="page8-8" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.88.1">Code-generating LLMs demonstrate varying capabilities across established benchmarks, with performance characteristics directly impacting their effectiveness in LangChain implementations. </span><span class="koboSpan" id="kobo.88.2">Recent evaluations of leading models, including OpenAI’s GPT-4o (2024), Anthropic’s Claude 3.5 Sonnet (2025), and open-source models such as Llama 3, show significant advancements in standard benchmarks. </span><span class="koboSpan" id="kobo.88.3">For instance, OpenAI’s o1 achieves 92.4% pass@1 on HumanEval (</span><em class="italic"><span class="koboSpan" id="kobo.89.1">A Survey On Large Language Models For Code Generation</span></em><span class="koboSpan" id="kobo.90.1">, 2025), while Claude 3 Opus reaches 84.9% on the same benchmark (</span><em class="italic"><span class="koboSpan" id="kobo.91.1">The Claude 3 Model Family: Opus, Sonnet, Haiku</span></em><span class="koboSpan" id="kobo.92.1">, 2024). </span><span class="koboSpan" id="kobo.92.2">However, performance metrics reveal important distinctions between controlled benchmark environments and the complex requirements of production LangChain applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.93.1">Standard benchmarks </span><a id="_idIndexMarker591"/><span class="koboSpan" id="kobo.94.1">provide useful but limited</span><a id="_idIndexMarker592"/><span class="koboSpan" id="kobo.95.1"> insights into model capabilities for LangChain implementations:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.96.1">HumanEval</span></strong><span class="koboSpan" id="kobo.97.1">: This benchmark</span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.98.1"> evaluates functional correctness through 164 Python programming problems. </span><span class="koboSpan" id="kobo.98.2">HumanEval primarily tests isolated function-level generation rather than the complex, multi-component systems typical in LangChain applications.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.99.1">MBPP </span></strong><span class="koboSpan" id="kobo.100.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.101.1">Mostly Basic Programming Problems</span></strong><span class="koboSpan" id="kobo.102.1">): This contains approximately 974 entry-level Python tasks. </span><span class="koboSpan" id="kobo.102.2">These problems lack the dependencies and contextual complexity found in production environments.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.103.1">ClassEval</span></strong><span class="koboSpan" id="kobo.104.1">: This newer benchmark tests class-level code generation, addressing some limitations of function-level testing. </span><span class="koboSpan" id="kobo.104.2">Recent research by Liu et al. </span><span class="koboSpan" id="kobo.104.3">(</span><em class="italic"><span class="koboSpan" id="kobo.105.1">Evaluating Large Language Models in Class-Level Code Generation</span></em><span class="koboSpan" id="kobo.106.1">, 2024) shows performance degradation of 15–30% compared to function-level tasks, highlighting challenges in maintaining contextual dependencies across methods—a critical consideration for LangChain components that manage state.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.107.1">SWE-bench</span></strong><span class="koboSpan" id="kobo.108.1">: More representative of real-world development, this benchmark evaluates models on bug-fixing tasks from actual GitHub repositories. </span><span class="koboSpan" id="kobo.108.2">Even top-performing models achieve only 40–65% success rates, as found by Jimenez et al. </span><span class="koboSpan" id="kobo.108.3">(</span><em class="italic"><span class="koboSpan" id="kobo.109.1">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</span></em><span class="koboSpan" id="kobo.110.1">, 2023), demonstrating the</span><a id="_idIndexMarker594"/><span class="koboSpan" id="kobo.111.1"> significant gap </span><a id="_idIndexMarker595"/><span class="koboSpan" id="kobo.112.1">between synthetic benchmarks and authentic coding challenges.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-176"><a id="_idTextAnchor339"/><span class="koboSpan" id="kobo.113.1">LLM-based software engineering approaches</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.114.1">When implementing</span><a id="_idIndexMarker596"/><span class="koboSpan" id="kobo.115.1"> code-generating LLMs within LangChain frameworks, several key challenges emerge.</span></p>
<div aria-label="275" epub:type="pagebreak" id="page9-7" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.116.1">Repository-level problems that require understanding multiple files, dependencies, and context present significant challenges. </span><span class="koboSpan" id="kobo.116.2">Research using the ClassEval benchmark (Xueying Du and colleagues, </span><em class="italic"><span class="koboSpan" id="kobo.117.1">Evaluating Large Language Models in Class-Level Code Generation</span></em><span class="koboSpan" id="kobo.118.1">, 2024) demonstrated that LLMs find class-level code generation “significantly more challenging than generating standalone functions,” with performance consistently lower when managing dependencies between methods compared to function-level benchmarks such as HumanEval. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.119.1">LLMs can be leveraged to understand repository-level code context despite the inherent challenges. </span><span class="koboSpan" id="kobo.119.2">The following implementation demonstrates a practical approach to analyzing multi-file Python codebases with LangChain, loading repository files as context for the model to consider when implementing new features. </span><span class="koboSpan" id="kobo.119.3">This pattern helps address the context limitations by directly providing a repository structure to the LLM:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.120.1">from</span></span><span class="koboSpan" id="kobo.121.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.122.1">import</span></span><span class="koboSpan" id="kobo.123.1"> ChatOpenAI</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.124.1">from</span></span><span class="koboSpan" id="kobo.125.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.126.1">import</span></span><span class="koboSpan" id="kobo.127.1"> ChatPromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.128.1">from</span></span><span class="koboSpan" id="kobo.129.1"> langchain_community.document_loaders </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.130.1">import</span></span><span class="koboSpan" id="kobo.131.1"> GitLoader</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.132.1"># Load repository context</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.133.1">repo_loader = GitLoader( clone_url=</span><span class="hljs-string"><span class="koboSpan" id="kobo.134.1">"https://github.com/example/repo.git"</span></span><span class="koboSpan" id="kobo.135.1">, branch=</span><span class="hljs-string"><span class="koboSpan" id="kobo.136.1">"main"</span></span><span class="koboSpan" id="kobo.137.1">, file_filter=</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.138.1">lambda</span></span><span class="koboSpan" id="kobo.139.1"> file_path: file_path.endswith(</span><span class="hljs-string"><span class="koboSpan" id="kobo.140.1">".py"</span></span><span class="koboSpan" id="kobo.141.1">) ) documents = repo_loader.load()</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.142.1"># Create context-aware prompt</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.143.1">system_template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.144.1">"""You are an expert Python developer. </span><span class="koboSpan" id="kobo.144.2">Analyze the following repository files and implement the requested feature. </span><span class="koboSpan" id="kobo.144.3">Repository structure: {repo_context}"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.145.1">human_template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.146.1">"""Implement a function that: {feature_request}"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.147.1">prompt = ChatPromptTemplate.from_messages([ (</span><span class="hljs-string"><span class="koboSpan" id="kobo.148.1">"system"</span></span><span class="koboSpan" id="kobo.149.1">, system_template), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.150.1">"human"</span></span><span class="koboSpan" id="kobo.151.1">, human_template) ])</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.152.1"># Create model with extended context window</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.153.1">model = ChatOpenAI(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.154.1">"gpt-4o"</span></span><span class="koboSpan" id="kobo.155.1">, temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.156.1">0.2</span></span><span class="koboSpan" id="kobo.157.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.158.1">This implementation uses GPT-4o to generate code while considering the context of entire repositories by pulling in relevant Python files to understand dependencies. </span><span class="koboSpan" id="kobo.158.2">This approach addresses context limitations but requires careful document chunking and retrieval strategies for large codebases.</span></p>
<div aria-label="276" epub:type="pagebreak" id="page10-7" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.159.1">Generated code often appears superficially correct but contains subtle bugs or security vulnerabilities that evade initial detection. </span><span class="koboSpan" id="kobo.159.2">The Uplevel Data Labs study (</span><em class="italic"><span class="koboSpan" id="kobo.160.1">Can GenAI Actually Improve Developer Productivity?</span></em><span class="koboSpan" id="kobo.161.1">) analyzing nearly 800 developers found a “significantly higher bug rate” in code produced by developers with access to AI coding assistants compared to those without. </span><span class="koboSpan" id="kobo.161.2">This is further supported by BlueOptima’s comprehensive analysis in 2024 of over 218,000 developers (</span><em class="italic"><span class="koboSpan" id="kobo.162.1">Debunking GitHub’s Claims: A Data-Driven Critique of Their Copilot Study</span></em><span class="koboSpan" id="kobo.163.1">), which revealed that 88% of professionals needed to substantially rework AI-generated code before it was production-ready, often due to “aberrant coding patterns” that weren’t immediately apparent. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.164.1">Security researchers have identified a persistent risk where AI models inadvertently introduce security flaws by replicating insecure patterns from their training data, with these vulnerabilities frequently escaping detection during initial syntax and compilation checks (</span><em class="italic"><span class="koboSpan" id="kobo.165.1">Evaluating Large Language Models through Role-Guide and Self-Reflection: A Comparative Study</span></em><span class="koboSpan" id="kobo.166.1">, 2024, and </span><em class="italic"><span class="koboSpan" id="kobo.167.1">HalluLens: LLM Hallucination Benchmark</span></em><span class="koboSpan" id="kobo.168.1">, 2024). </span><span class="koboSpan" id="kobo.168.2">These findings emphasize the critical importance of thorough human review and testing of AI-generated code before production deployment.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.169.1">The following example</span><a id="_idIndexMarker597"/><span class="koboSpan" id="kobo.170.1"> demonstrates how to create a specialized validation chain that systematically analyzes generated code for common issues, serving as a first line of defense against subtle bugs and vulnerabilities:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.171.1">from</span></span><span class="koboSpan" id="kobo.172.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.173.1">import</span></span><span class="koboSpan" id="kobo.174.1"> PromptTemplate</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.175.1">validation_template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.176.1">"""Analyze the following Python code for:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><a id="_idTextAnchor340"/><span class="koboSpan" id="kobo.177.1">1. </span><span class="koboSpan" id="kobo.177.2">Potential security vulnerabilities</span></span></p>
<p class="snippet-code"><span class="hljs-string"><a id="_idTextAnchor341"/><span class="koboSpan" id="kobo.178.1">2. </span><span class="koboSpan" id="kobo.178.2">Logic errors</span></span></p>
<p class="snippet-code"><span class="hljs-string"><a id="_idTextAnchor342"/><span class="koboSpan" id="kobo.179.1">3. </span><span class="koboSpan" id="kobo.179.2">Performance issues</span></span></p>
<p class="snippet-code"><span class="hljs-string"><a id="_idTextAnchor343"/><span class="koboSpan" id="kobo.180.1">4. </span><span class="koboSpan" id="kobo.180.2">Edge case handling</span></span></p>
<p class="snippet-code"><span class="hljs-string"> </span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.181.1">Code to analyze:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.182.1">```python</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.183.1">{generated_code}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.184.1">Provide a detailed analysis with specific issues and recommended fixes. </span><span class="koboSpan" id="kobo.184.2">"""</span></span> </p>
<p class="snippet-code"><span class="koboSpan" id="kobo.185.1">validation_prompt = PromptTemplate( input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.186.1">"generated_code"</span></span><span class="koboSpan" id="kobo.187.1">], template=validation_template )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.188.1">validation_chain = validation_prompt | llm</span></p>
<p class="normal"><span class="koboSpan" id="kobo.189.1">This validation approach creates a specialized LLM-based code review step in the workflow, focusing on critical security and quality aspects. </span></p>
<div aria-label="277" epub:type="pagebreak" id="page11-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.190.1">Most successful implementations incorporate execution feedback, allowing models to iteratively improve their output based on compiler errors and runtime behavior. </span><span class="koboSpan" id="kobo.190.2">Research on Text-to-SQL systems by Boyan Li and colleagues (</span><em class="italic"><span class="koboSpan" id="kobo.191.1">The Dawn of Natural Language to SQL: Are We Fully Ready?</span></em><span class="koboSpan" id="kobo.192.1">, 2024) demonstrates that incorporating feedback mechanisms significantly improves query generation accuracy, with systems that use execution results to refine their outputs and consistently outperform those without such capabilities.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.193.1">When</span><a id="_idIndexMarker598"/><span class="koboSpan" id="kobo.194.1"> deploying code-generating LLMs in production LangChain applications, several factors require attention:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.195.1">Model selection tradeoffs</span></strong><span class="koboSpan" id="kobo.196.1">: While closed-source models such as GPT-4 and Claude demonstrate superior performance on code benchmarks, open-source alternatives such as Llama 3 (70.3% on HumanEval) offer advantages in cost, latency, and data privacy. </span><span class="koboSpan" id="kobo.196.2">The appropriate choice depends on specific requirements regarding accuracy, deployment constraints, and budget considerations.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.197.1">Context window management</span></strong><span class="koboSpan" id="kobo.198.1">: Effective handling of limited context windows remains crucial. </span><span class="koboSpan" id="kobo.198.2">Recent techniques such as recursive chunking and hierarchical summarization (Li et al., 2024) can improve performance by up to 25% on large</span><a id="_idTextAnchor344"/><span class="koboSpan" id="kobo.199.1"> codebase tasks.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.200.1">Framework integration</span></strong><span class="koboSpan" id="kobo.201.1"> extends basic LLM capabilities by leveraging specialized tools such as LangChain for workflow management. </span><span class="koboSpan" id="kobo.201.2">Organizations implementing this pattern establish custom security policies tailored to their domain requirements and build feedback loops that enable continuous improvement of model outputs. </span><span class="koboSpan" id="kobo.201.3">This integration approach allows teams to benefit from advances in foundation models while maintaining control over deployment specifics.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.202.1">Human-AI collaboration</span></strong><span class="koboSpan" id="kobo.203.1"> establishes clear divisions of responsibility between developers and AI systems. </span><span class="koboSpan" id="kobo.203.2">This pattern maintains human oversight for all critical decisions while delegating routine tasks to AI assistants. </span><span class="koboSpan" id="kobo.203.3">An essential component is systematic documentation and knowledge capture, ensuring that AI-generated solutions remain comprehensible and maintainable by the entire development team. </span><span class="koboSpan" id="kobo.203.4">Companies successfully implementing this pattern report both productivity gains and improved knowledge transfer amo</span><a id="_idTextAnchor345"/><span class="koboSpan" id="kobo.204.1">ng team members.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-177"><a id="_idTextAnchor346"/><span class="koboSpan" id="kobo.205.1">Security and risk mitigation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.206.1">When building LLM-powered</span><a id="_idIndexMarker599"/><span class="koboSpan" id="kobo.207.1"> applications with LangChain, implementing robust security measures and risk mitigation strategies becomes essential. </span><span class="koboSpan" id="kobo.207.2">This section focuses on practical approaches to addressing security vulnerabilities, preventing hallucinations, and ensuring code quality through LangChain-specific implementations.</span></p>
<div aria-label="278" epub:type="pagebreak" id="page12-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.208.1">Security vulnerabilities in LLM-generated code present significant risks, particularly when dealing with user inputs, database interactions, or API integrations. </span><span class="koboSpan" id="kobo.208.2">LangChain allows developers to create systematic validation processes to identify and mitigate these risks. </span><span class="koboSpan" id="kobo.208.3">The following validation chain can be integrated into any LangChain workflow that involves code generation, providing </span><a id="_idIndexMarker600"/><span class="koboSpan" id="kobo.209.1">structured security analysis before deployment:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.210.1">from</span></span><span class="koboSpan" id="kobo.211.1"> typing </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.212.1">import</span></span> <span class="hljs-type"><span class="koboSpan" id="kobo.213.1">List</span></span> </p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.214.1">from</span></span><span class="koboSpan" id="kobo.215.1"> langchain_core.output_parsers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.216.1">import</span></span><span class="koboSpan" id="kobo.217.1"> PydanticOutputParser </span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.218.1">from</span></span><span class="koboSpan" id="kobo.219.1"> langchain_core.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.220.1">import</span></span><span class="koboSpan" id="kobo.221.1"> PromptTemplate </span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.222.1">from</span></span><span class="koboSpan" id="kobo.223.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.224.1">import</span></span><span class="koboSpan" id="kobo.225.1"> ChatOpenAI </span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.226.1">from</span></span><span class="koboSpan" id="kobo.227.1"> pydantic </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.228.1">import</span></span><span class="koboSpan" id="kobo.229.1"> BaseModel, Field</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.230.1"># Define the Pydantic model for structured output</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.231.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.232.1">SecurityAnalysis</span></span><span class="koboSpan" id="kobo.233.1">(</span><span class="hljs-title"><span class="koboSpan" id="kobo.234.1">BaseModel</span></span><span class="koboSpan" id="kobo.235.1">): </span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.236.1">"""Security analysis results for generated code."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.237.1">    vulnerabilities: </span><span class="hljs-type"><span class="koboSpan" id="kobo.238.1">List</span></span><span class="koboSpan" id="kobo.239.1">[</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.240.1">str</span></span><span class="koboSpan" id="kobo.241.1">] = Field(description=</span><span class="hljs-string"><span class="koboSpan" id="kobo.242.1">"List of identified security vulnerabilities"</span></span><span class="koboSpan" id="kobo.243.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.244.1">   mitigation_suggestions: </span><span class="hljs-type"><span class="koboSpan" id="kobo.245.1">List</span></span><span class="koboSpan" id="kobo.246.1">[</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.247.1">str</span></span><span class="koboSpan" id="kobo.248.1">] = Field(description=</span><span class="hljs-string"><span class="koboSpan" id="kobo.249.1">"Suggested fixes for each vulnerability"</span></span><span class="koboSpan" id="kobo.250.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.251.1">    risk_level: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.252.1">str</span></span><span class="koboSpan" id="kobo.253.1"> = Field(description=</span><span class="hljs-string"><span class="koboSpan" id="kobo.254.1">"Overall risk assessment: Low, Medium, High, Critical"</span></span><span class="koboSpan" id="kobo.255.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.256.1"># Initialize the output parser with the Pydantic model</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.257.1">parser = PydanticOutputParser(pydantic_object=SecurityAnalysis)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.258.1"># Create the prompt template with format instructions from the parser</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.259.1">security_prompt = PromptTemplate.from_template(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.260.1">    template=</span><span class="hljs-string"><span class="koboSpan" id="kobo.261.1">"""Analyze the following code for security vulnerabilities: {code}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.262.1">Consider:</span></span></p>
<p class="snippet-code"><span class="hljs-string"> </span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.263.1">SQL injection vulnerabilities</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.264.1">Cross-site scripting (XSS) risks</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.265.1">Insecure direct object references</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.266.1">Authentication and authorization weaknesses</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.267.1">Sensitive data exposure</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.268.1">Missing input validation</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.269.1">Command injection opportunities</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.270.1">Insecure dependency usage</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.271.1">{format_instructions}"""</span></span><span class="koboSpan" id="kobo.272.1">,</span></p>
<div aria-label="279" epub:type="pagebreak" id="page13-6" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.273.1">  input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.274.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.275.1">code"</span></span><span class="koboSpan" id="kobo.276.1">], </span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.277.1">    partial_variables={</span><span class="hljs-string"><span class="koboSpan" id="kobo.278.1">"format_instructions"</span></span><span class="koboSpan" id="kobo.279.1">: parser.get_format_instructions()}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.280.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.281.1"># Initialize the language model</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.282.1">llm = ChatOpenAI(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.283.1">"gpt-4"</span></span><span class="koboSpan" id="kobo.284.1">, temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.285.1">0</span></span><span class="koboSpan" id="kobo.286.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.287.1"># Compose the chain using LCEL</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.288.1">security_chain = security_prompt | llm | parser</span></p>
<p class="normal"><span class="koboSpan" id="kobo.289.1">The Pydantic output parser ensures that results are properly structured and can be programmatically processed for automated gatekeeping. </span><span class="koboSpan" id="kobo.289.2">LLM-generated code should never be directly executed in production environments without validation. </span><span class="koboSpan" id="kobo.289.3">LangChain provides tools to create safe execution environments for testing generated code.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.290.1">To ensure security when building LangChain applications that handle code, a layered approach is crucial, combining LLM-based validation with traditional security tools for robust defense. </span><span class="koboSpan" id="kobo.290.2">Structure security findings using Pydantic models and LangChain’s output parsers for consistent, actionable outputs. </span><span class="koboSpan" id="kobo.290.3">Always isolate the execution of LLM-generated code in sandboxed environments with strict resource limits, never running it directly in production. </span><span class="koboSpan" id="kobo.290.4">Explicitly manage dependencies by verifying imports against available packages to avoid hallucinations. </span><span class="koboSpan" id="kobo.290.5">Continuously improve code generation through feedback loops incorporating execution results and validation findings. </span><span class="koboSpan" id="kobo.290.6">Maintain comprehensive logging of all code generation steps, security findings, and modifications for auditing. </span><span class="koboSpan" id="kobo.290.7">Adhere to the principle of least privilege by </span><a id="_idIndexMarker601"/><span class="koboSpan" id="kobo.291.1">generating code that follows security best practices such as minimal permissions and proper input validation. </span><span class="koboSpan" id="kobo.291.2">Finally, utilize version control to store generated code and implement human review for </span><a id="_idTextAnchor347"/><span class="koboSpan" id="kobo.292.1">critical components.</span></p>
<h2 class="heading-2" id="_idParaDest-178"><a id="_idTextAnchor348"/><span class="koboSpan" id="kobo.293.1">Validation framework for LLM-generated code</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.294.1">Organizations should</span><a id="_idIndexMarker602"/><span class="koboSpan" id="kobo.295.1"> implement a structured validation process for LLM-generated code and analyses before moving to production. </span><span class="koboSpan" id="kobo.295.2">The following framework provides practical guidance for teams adopting LLMs in their data science workflows:</span></p>
<div aria-label="280" epub:type="pagebreak" id="page14-6" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.296.1">Functional validation</span></strong><span class="koboSpan" id="kobo.297.1"> forms the foundation of any assessment process. </span><span class="koboSpan" id="kobo.297.2">Start by executing the generated code with representative test data and carefully verify that outputs align with expected results. </span><span class="koboSpan" id="kobo.297.3">Ensure all dependencies are properly imported and compatible with your production environment—LLMs occasionally reference outdated or incompatible libraries. </span><span class="koboSpan" id="kobo.297.4">Most importantly, confirm that the code actually addresses the original business requirements, as LLMs sometimes produce impressive-looking code that misses the core business objective.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.298.1">Performance assessment</span></strong><span class="koboSpan" id="kobo.299.1"> requires looking beyond mere functionality. </span><span class="koboSpan" id="kobo.299.2">Benchmark the execution time of LLM-generated code against existing solutions to identify potential inefficiencies. </span><span class="koboSpan" id="kobo.299.3">Testing with progressively larger datasets often reveals scaling limitations that weren’t apparent with sample data. </span><span class="koboSpan" id="kobo.299.4">Profile memory usage systematically, as LLMs may not optimize for resource constraints unless explicitly instructed. </span><span class="koboSpan" id="kobo.299.5">This performance data provides crucial information for deployment decisions and identifies opportunities for optimization.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.300.1">Security screening</span></strong><span class="koboSpan" id="kobo.301.1"> should never be an afterthought when working with generated code. </span><span class="koboSpan" id="kobo.301.2">Scan for unsafe functions, potential injection vulnerabilities, and insecure API calls—issues that LLMs may introduce despite their training in secure coding practices. </span><span class="koboSpan" id="kobo.301.3">Verify the proper handling of authentication credentials and sensitive data, especially when the model has been instructed to include API access. </span><span class="koboSpan" id="kobo.301.4">Check carefully for hardcoded secrets or unintentional data exposures that could create security vulnerabilities in production.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.302.1">Robustness testing</span></strong><span class="koboSpan" id="kobo.303.1"> extends validation beyond the happy path scenarios. </span><span class="koboSpan" id="kobo.303.2">Test with edge cases and unexpected inputs that reveal how the code handles extreme conditions. </span><span class="koboSpan" id="kobo.303.3">Verify that error handling mechanisms are comprehensive and provide meaningful feedback rather than cryptic failures. </span><span class="koboSpan" id="kobo.303.4">Evaluate the code’s resilience to malformed or missing data, as production environments rarely provide the pristine data conditions assumed in development.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.304.1">Business logic verification</span></strong><span class="koboSpan" id="kobo.305.1"> focuses on domain-specific requirements that LLMs may not fully understand. </span><span class="koboSpan" id="kobo.305.2">Confirm that industry-specific constraints and business rules are correctly implemented, especially regulatory requirements that vary by sector. </span><span class="koboSpan" id="kobo.305.3">Verify calculations and transformations against manual calculations for critical processes, as subtle mathematical differences can significantly impact business outcomes. </span><span class="koboSpan" id="kobo.305.4">Ensure all regulatory or policy requirements relevant to your industry are properly addressed—a crucial step when LLMs may lack domain-specific compliance knowledge.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.306.1">Documentation and explainability</span></strong><span class="koboSpan" id="kobo.307.1"> complete the validation process by ensuring sustainable use of the generated code. </span><span class="koboSpan" id="kobo.307.2">Either require the LLM to provide or separately generate inline comments that explain complex sections and algorithmic choices. </span><span class="koboSpan" id="kobo.307.3">Document any assumptions made by the model that might impact future maintenance or enhancement. </span><span class="koboSpan" id="kobo.307.4">Create validation reports that link code functionality directly to business requirements, providing traceability that supports both technical and business stakeholders.</span></li>
</ul>
<div aria-label="281" epub:type="pagebreak" id="page15-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.308.1">This validation framework </span><a id="_idIndexMarker603"/><span class="koboSpan" id="kobo.309.1">should be integrated into development workflows, with appropriate automation incorporated where possible to reduce manual effort. </span><span class="koboSpan" id="kobo.309.2">Organizations embarking on LLM adoption should start with well-defined use cases clearly aligned with business objectives, implement these validation processes systematically, invest in comprehensive staff training on both LLM capabilities and limitations, and establish clear governance frameworks that evolve</span><a id="_idTextAnchor349"/><span class="koboSpan" id="kobo.310.1"> with the technology.</span></p>
<h2 class="heading-2" id="_idParaDest-179"><a id="_idTextAnchor350"/><span class="koboSpan" id="kobo.311.1">LangChain integrations</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.312.1">As we’re aware, LangChain </span><a id="_idIndexMarker604"/><span class="koboSpan" id="kobo.313.1">enables the creation of </span><a id="_idIndexMarker605"/><span class="koboSpan" id="kobo.314.1">versatile and robust AI agents. </span><span class="koboSpan" id="kobo.314.2">For instance, a LangChain-integrated agent can safely execute code using dedicated interpreters, interact with SQL databases for dynamic data retrieval, and perform real-time financial analysis, all while upholding strict quality and security standards.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.315.1">Integrations range from code execution and database querying to financial analysis and repository management. </span><span class="koboSpan" id="kobo.315.2">This wide-ranging toolkit facilitates building applications that are deeply integrated with real-world data and systems, ensuring that AI solutions are both powerful and practical. </span><span class="koboSpan" id="kobo.315.3">Here are some examples of integrations:</span></p>
<div aria-label="282" epub:type="pagebreak" id="page16-6" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.316.1">Code execution and isolation: </span></strong><span class="koboSpan" id="kobo.317.1">Tools such as the Python REPL, Azure Container Apps dynamic sessions, Riza Code Interpreter, and Bearly Code Interpreter provide various environments to safely execute code. </span><span class="koboSpan" id="kobo.317.2">They enable LLMs to delegate complex calculations or data processing tasks to dedicated code interpreters, thereby increasing accuracy and reliability while maintaining security.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.318.1">Database and data handling: </span></strong><span class="koboSpan" id="kobo.319.1">Integrations for Cassandra, SQL, and Spark SQL toolkits allow agents to interface directly with different types of databases. </span><span class="koboSpan" id="kobo.319.2">Meanwhile, JSON Toolkit and pandas DataFrame integration facilitate efficient handling of structured data. </span><span class="koboSpan" id="kobo.319.3">These capabilities are essential for applications that require dynamic data retrieval, transformation, and analysis.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.320.1">Financial data and analysis: </span></strong><span class="koboSpan" id="kobo.321.1">With FMP Data, Google Finance, and the FinancialDatasets Toolkit, developers can build AI agents capable of performing sophisticated financial analyses and market research. </span><span class="koboSpan" id="kobo.321.2">Dappier further extends this by connecting agents to curated, real-time data streams.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.322.1">Repository and version control integration: </span></strong><span class="koboSpan" id="kobo.323.1">The GitHub and GitLab toolkits enable agents to interact with code repositories, streamlining tasks such as issue management, code reviews, and deployment processes—a crucial asset for developers working in modern DevOps environments.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.324.1">User input and visualization: </span></strong><span class="koboSpan" id="kobo.325.1">Google Trends and PowerBI Toolkit highlight the ecosystem’s focus on bringing in external data (such as market trends) and then visualizing it effectively. </span><span class="koboSpan" id="kobo.325.2">The “human as a tool” integration is a reminder that, sometimes, human judgment remains indispensable, especially in ambiguous scenarios.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.326.1">Having explored the theoretical framework and potential benefits of LLM-assisted software development, let’s now turn to practical implementation. </span><span class="koboSpan" id="kobo.326.2">In the following section, we’ll demonstrate how to generate functional software code with LLMs and execute it directly from within the LangChain framework. </span><span class="koboSpan" id="kobo.326.3">This hands-on approach will illustrate the concepts we’ve discussed and provide you with actionable examples you can adap</span><a id="_idTextAnchor351"/><span class="koboSpan" id="kobo.327.1">t to your own projects.</span></p>
<h1 class="heading-1" id="_idParaDest-180"><a id="_idTextAnchor352"/><span class="koboSpan" id="kobo.328.1">Writing code with LLMs </span></h1>
<p class="normal"><span class="koboSpan" id="kobo.329.1">In this section, we </span><a id="_idIndexMarker606"/><span class="koboSpan" id="kobo.330.1">demonstrate code generation using various models integrated with LangChain. </span><span class="koboSpan" id="kobo.330.2">We’ve selected different models to showcase: </span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.331.1">LangChain’s diverse integrations with AI tools </span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.332.1">Models with different licensing and availability </span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.333.1">Options for local deployment, including smaller models </span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.334.1">These examples illustrate LangChain’s flexibility in working with various code generation models, from cloud-based services to open-source alternatives. </span><span class="koboSpan" id="kobo.334.2">This approach allows you to understand the range of options available and choose the most suitable solution for your specific needs and constraints. </span></p>
<div>
<div class="note" id="_idContainer092">
<p class="normal"><span class="koboSpan" id="kobo.335.1">Please make sure you have installed all the dependencies needed for this book, as explained in </span><a href="E_Chapter_2.xhtml#_idTextAnchor044"><em class="italic"><span class="koboSpan" id="kobo.336.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.337.1">. </span><span class="koboSpan" id="kobo.337.2">Otherwise, you might run into issues. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.338.1">Given the pace of the field and the development of the LangChain library, we are making an effort to keep the GitHub repository up to date. </span><span class="koboSpan" id="kobo.338.2">Please see </span><a href="https://github.com/benman1/generative_ai_with_langchain"><span class="url"><span class="koboSpan" id="kobo.339.1">https://github.com/benman1/generative_ai_with_langchain</span></span></a><span class="koboSpan" id="kobo.340.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.341.1">For any questions or if you have any trouble running the code, please create an issue on GitHub or join the discussion on Discord: </span><a id="_idTextAnchor353"/><a href="https://packt.link/lang"><span class="url"><span class="koboSpan" id="kobo.342.1">https://packt.link/lang</span></span></a><span class="koboSpan" id="kobo.343.1">.</span></p>
</div>
</div>
<h2 class="heading-2" id="_idParaDest-181"><a id="_idTextAnchor354"/><span class="koboSpan" id="kobo.344.1">Google generative AI</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.345.1">The Google generative </span><a id="_idIndexMarker607"/><span class="koboSpan" id="kobo.346.1">AI platform offers a range of models </span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.347.1">designed for instruction following, conversion, and code generation/assistance. </span><span class="koboSpan" id="kobo.347.2">These models also have different input/output limits and training data and are often updated. </span><span class="koboSpan" id="kobo.347.3">Let’s see if the Gemini Pro model can </span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.348.1">solve </span><strong class="keyWord"><span class="koboSpan" id="kobo.349.1">FizzBuzz</span></strong><span class="koboSpan" id="kobo.350.1">, a common interview question for entry-level software developer positions. </span></p>
<div aria-label="283" epub:type="pagebreak" id="page17-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.351.1">To test the model’s code generation capabilities, we’ll use LangChain to interface with Gemini Pro and provide the FizzBuzz problem statement:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.352.1">from</span></span><span class="koboSpan" id="kobo.353.1"> langchain_google_genai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.354.1">import</span></span><span class="koboSpan" id="kobo.355.1"> ChatGoogleGenerativeAI</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.356.1">question = </span><span class="hljs-string"><span class="koboSpan" id="kobo.357.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.358.1">Given an integer n, return a string array answer (1-indexed) where:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.359.1">answer[i] == "FizzBuzz" if i is divisible by 3 and 5.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.360.1">answer[i] == "Fizz" if i is divisible by 3.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.361.1">answer[i] == "Buzz" if i is divisible by 5.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.362.1">answer[i] == i (as a string) if none of the above conditions are true.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.363.1">"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.364.1">llm = ChatGoogleGenerativeAI(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.365.1">"gemini-1.5-pro"</span></span><span class="koboSpan" id="kobo.366.1">)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.367.1">print</span></span><span class="koboSpan" id="kobo.368.1">(llm.invoke(question).content)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.369.1">Gemini Pro immediately returns a clean, correct Python solution that properly handles all the FizzBuzz requirements:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.370.1">```python</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.371.1">    answer = []</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.372.1">for</span></span><span class="koboSpan" id="kobo.373.1"> i </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.374.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.375.1">range</span></span><span class="koboSpan" id="kobo.376.1">(</span><span class="hljs-number"><span class="koboSpan" id="kobo.377.1">1</span></span><span class="koboSpan" id="kobo.378.1">, n+</span><span class="hljs-number"><span class="koboSpan" id="kobo.379.1">1</span></span><span class="koboSpan" id="kobo.380.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.381.1">if</span></span><span class="koboSpan" id="kobo.382.1"> i % </span><span class="hljs-number"><span class="koboSpan" id="kobo.383.1">3</span></span><span class="koboSpan" id="kobo.384.1"> == </span><span class="hljs-number"><span class="koboSpan" id="kobo.385.1">0</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.386.1">and</span></span><span class="koboSpan" id="kobo.387.1"> i % </span><span class="hljs-number"><span class="koboSpan" id="kobo.388.1">5</span></span><span class="koboSpan" id="kobo.389.1"> == </span><span class="hljs-number"><span class="koboSpan" id="kobo.390.1">0</span></span><span class="koboSpan" id="kobo.391.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.392.1">            answer.append(</span><span class="hljs-string"><span class="koboSpan" id="kobo.393.1">"FizzBuzz"</span></span><span class="koboSpan" id="kobo.394.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.395.1">elif</span></span><span class="koboSpan" id="kobo.396.1"> i % </span><span class="hljs-number"><span class="koboSpan" id="kobo.397.1">3</span></span><span class="koboSpan" id="kobo.398.1"> == </span><span class="hljs-number"><span class="koboSpan" id="kobo.399.1">0</span></span><span class="koboSpan" id="kobo.400.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.401.1">            answer.append(</span><span class="hljs-string"><span class="koboSpan" id="kobo.402.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.403.1">Fizz"</span></span><span class="koboSpan" id="kobo.404.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.405.1">elif</span></span><span class="koboSpan" id="kobo.406.1"> i % </span><span class="hljs-number"><span class="koboSpan" id="kobo.407.1">5</span></span><span class="koboSpan" id="kobo.408.1"> == </span><span class="hljs-number"><span class="koboSpan" id="kobo.409.1">0</span></span><span class="koboSpan" id="kobo.410.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.411.1">            answer.append(</span><span class="hljs-string"><span class="koboSpan" id="kobo.412.1">"Buzz"</span></span><span class="koboSpan" id="kobo.413.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.414.1">else</span></span><span class="koboSpan" id="kobo.415.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.416.1">            answer.append(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.417.1">str</span></span><span class="koboSpan" id="kobo.418.1">(i))</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.419.1">return</span></span><span class="koboSpan" id="kobo.420.1"> answer</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.421.1">```</span></p>
<p class="normal"><span class="koboSpan" id="kobo.422.1">The model produced an efficient, well-structured solution that correctly implements the logic for the FizzBuzz problem </span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.423.1">without any errors or unnecessary</span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.424.1"> complexity. </span><span class="koboSpan" id="kobo.424.2">Would you h</span><a id="_idTextAnchor355"/><span class="koboSpan" id="kobo.425.1">ire Gemini Pro for your team?</span></p>
<div aria-label="284" epub:type="pagebreak" id="page18-6" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-182"><a id="_idTextAnchor356"/><span class="koboSpan" id="kobo.426.1">Hugging Face</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.427.1">Hugging Face hosts a lot</span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.428.1"> of open-source models, many of which have been</span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.429.1"> trained on code, some of which can be tried out in playgrounds, where you can ask them to either complete (for older models) or write code (instruction-tuned models). </span><span class="koboSpan" id="kobo.429.2">With LangChain, you can either download these models and run them locally, or you can access them through the Hugging Face API. </span><span class="koboSpan" id="kobo.429.3">Let’s try the local option first with a prime number calculation example:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.430.1">from</span></span><span class="koboSpan" id="kobo.431.1"> langchain.llms </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.432.1">import</span></span><span class="koboSpan" id="kobo.433.1"> HuggingFacePipeline</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.434.1">from</span></span><span class="koboSpan" id="kobo.435.1"> transformers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.436.1">import</span></span><span class="koboSpan" id="kobo.437.1"> AutoModelForCausalLM, AutoTokenizer, pipeline</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.438.1"># Choose a more up-to-date model</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.439.1">checkpoint = </span><span class="hljs-string"><span class="koboSpan" id="kobo.440.1">"google/codegemma-2b"</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.441.1"># Load the model and tokenizer</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.442.1">model = AutoModelForCausalLM.from_pretrained(checkpoint)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.443.1">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.444.1"># Create a text generation pipeline</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.445.1">pipe = pipeline(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.446.1">    task=</span><span class="hljs-string"><span class="koboSpan" id="kobo.447.1">"text-generation"</span></span><span class="koboSpan" id="kobo.448.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.449.1">    model=model,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.450.1">    tokenizer=tokenizer,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.451.1">    max_new_tokens=</span><span class="hljs-number"><span class="koboSpan" id="kobo.452.1">500</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.453.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.454.1"># Integrate the pipeline with LangChain</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.455.1">llm = HuggingFacePipeline(pipeline=pipe)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.456.1"># Define the input text</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.457.1">text = </span><span class="hljs-string"><span class="koboSpan" id="kobo.458.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.459.1">def calculate_primes(n):</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.460.1">    \"\"\"Create a list of consecutive integers from 2 up to N.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.461.1">    For example:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.462.1">    &gt;&gt;&gt; calculate_primes(20)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.463.1">    Output: [2, 3, 5, 7, 11, 13, 17, 19]</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.464.1">    \"\"\"</span></span></p>
<div aria-label="285" epub:type="pagebreak" id="page19-6" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.465.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.466.1"># Use the LangChain LLM to generate text</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.467.1">output = llm(text)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.468.1">print</span></span><span class="koboSpan" id="kobo.469.1">(output)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.470.1">When executed, CodeGemma completes the function by implementing the Sieve of Eratosthenes </span><a id="_idIndexMarker614"/><span class="koboSpan" id="kobo.471.1">algorithm, a classic method for finding prime numbers</span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.472.1"> efficiently. </span><span class="koboSpan" id="kobo.472.2">The model correctly interprets the docstring, understanding that the function should return all prime numbers up to n rather than just checking whether a number is prime. </span><span class="koboSpan" id="kobo.472.3">The generated code demonstrates how specialized code models can produce working implementations from minimal specifications.</span></p>
<div>
<div class="note" id="_idContainer093">
<p class="normal"><span class="koboSpan" id="kobo.473.1">Please note that the downloading and loading of the models can take a few minutes. </span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.474.1">If you’re getting an error saying you “</span><code class="inlineCode"><span class="koboSpan" id="kobo.475.1">cannot access a gated repo</span></code><span class="koboSpan" id="kobo.476.1">" when trying to use a URL with LangChain, it means you’re attempting to access a private repository on Hugging Face that requires authentication with a personal access token to view or use the model; you need to create a Hugging Face access token and set it as an environment variable named </span><code class="inlineCode"><span class="koboSpan" id="kobo.477.1">"HF_TOKEN"</span></code><span class="koboSpan" id="kobo.478.1"> to access the gated repository. </span><span class="koboSpan" id="kobo.478.2">You can get the token on the Hugging Face website at </span><a href="https://huggingface.co/docs/api-inference/quicktour#get-your-api-token"><span class="url"><span class="koboSpan" id="kobo.479.1">https://huggingface.co/docs/api-inference/quicktour#get-your-api-token</span></span></a><span class="koboSpan" id="kobo.480.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.481.1">When our code from the previous example executes successfully with CodeGemma, it generates a complete implementation for the prime number calculator function. </span><span class="koboSpan" id="kobo.481.2">The output looks like this:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.482.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.483.1">calculate_primes</span></span><span class="koboSpan" id="kobo.484.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.485.1">n</span></span><span class="koboSpan" id="kobo.486.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.487.1">"""Create a list of consecutive integers from 2 up to N.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.488.1">    For example:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.489.1">    &gt;&gt;&gt; calculate_primes(20)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.490.1">    Output: [2, 3, 5, 7, 11, 13, 17, 19]</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.491.1">    """</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.492.1">    primes = []</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.493.1">for</span></span><span class="koboSpan" id="kobo.494.1"> i </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.495.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.496.1">range</span></span><span class="koboSpan" id="kobo.497.1">(</span><span class="hljs-number"><span class="koboSpan" id="kobo.498.1">2</span></span><span class="koboSpan" id="kobo.499.1">, n + </span><span class="hljs-number"><span class="koboSpan" id="kobo.500.1">1</span></span><span class="koboSpan" id="kobo.501.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.502.1">if</span></span><span class="koboSpan" id="kobo.503.1"> is_prime(i):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.504.1">            primes.append(i)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.505.1">return</span></span><span class="koboSpan" id="kobo.506.1"> primes</span></p>
<div aria-label="286" epub:type="pagebreak" id="page20-6" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.507.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.508.1">is_prime</span></span><span class="koboSpan" id="kobo.509.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.510.1">n</span></span><span class="koboSpan" id="kobo.511.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.512.1">"""Return True if n is prime."""</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.513.1">if</span></span><span class="koboSpan" id="kobo.514.1"> n &lt; </span><span class="hljs-number"><span class="koboSpan" id="kobo.515.1">2</span></span><span class="koboSpan" id="kobo.516.1">:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.517.1">return</span></span> <span class="hljs-literal"><span class="koboSpan" id="kobo.518.1">False</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.519.1">for</span></span><span class="koboSpan" id="kobo.520.1"> i </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.521.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.522.1">range</span></span><span class="koboSpan" id="kobo.523.1">(</span><span class="hljs-number"><span class="koboSpan" id="kobo.524.1">2</span></span><span class="koboSpan" id="kobo.525.1">, </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.526.1">int</span></span><span class="koboSpan" id="kobo.527.1">(n ** </span><span class="hljs-number"><span class="koboSpan" id="kobo.528.1">0.5</span></span><span class="koboSpan" id="kobo.529.1">) + </span><span class="hljs-number"><span class="koboSpan" id="kobo.530.1">1</span></span><span class="koboSpan" id="kobo.531.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.532.1">if</span></span><span class="koboSpan" id="kobo.533.1"> n % i == </span><span class="hljs-number"><span class="koboSpan" id="kobo.534.1">0</span></span><span class="koboSpan" id="kobo.535.1">:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.536.1">return</span></span> <span class="hljs-literal"><span class="koboSpan" id="kobo.537.1">False</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.538.1">return</span></span> <span class="hljs-literal"><span class="koboSpan" id="kobo.539.1">True</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.540.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.541.1">main</span></span><span class="koboSpan" id="kobo.542.1">():</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.543.1">"""Get user input and print the list of primes."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.544.1">    n = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.545.1">int</span></span><span class="koboSpan" id="kobo.546.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.547.1">input</span></span><span class="koboSpan" id="kobo.548.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.549.1">"Enter a number: "</span></span><span class="koboSpan" id="kobo.550.1">))</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.551.1">    primes = calculate_primes(n)</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.552.1">print</span></span><span class="koboSpan" id="kobo.553.1">(primes)</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.554.1">if</span></span><span class="koboSpan" id="kobo.555.1"> __name__ == </span><span class="hljs-string"><span class="koboSpan" id="kobo.556.1">"__main__"</span></span><span class="koboSpan" id="kobo.557.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.558.1">    main()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.559.1">&lt;|file_separator|&gt;</span></p>
<p class="normal"><span class="koboSpan" id="kobo.560.1">Notice how the</span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.561.1"> model not only implemented the requested </span><code class="inlineCode"><span class="koboSpan" id="kobo.562.1">calculate_primes()</span></code><span class="koboSpan" id="kobo.563.1"> function </span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.564.1">but also created a helper function, </span><code class="inlineCode"><span class="koboSpan" id="kobo.565.1">is_prime()</span></code><span class="koboSpan" id="kobo.566.1">, which uses a more efficient algorithm checking divisibility only up to the square root of the number. </span><span class="koboSpan" id="kobo.566.2">The model even added a complete </span><code class="inlineCode"><span class="koboSpan" id="kobo.567.1">main()</span></code><span class="koboSpan" id="kobo.568.1"> function with user input handling, demonstrating its understanding of Python programming patterns.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.569.1">Instead of downloading and running models locally, which requires significant computational resources, we can also run models directly on Hugging Face’s infrastructure using their Inference API. </span><span class="koboSpan" id="kobo.569.2">This approach is simpler to set up and doesn’t require powerful hardware. </span><span class="koboSpan" id="kobo.569.3">Here’s how to implement the same example using Hugging Face’s hosted services:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.570.1">from</span></span><span class="koboSpan" id="kobo.571.1"> langchain.llms </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.572.1">import</span></span><span class="koboSpan" id="kobo.573.1"> HuggingFaceHub</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.574.1"># Choose a lightweight model good for code generation</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.575.1">repo_id = </span><span class="hljs-string"><span class="koboSpan" id="kobo.576.1">"bigcode/starcoder"</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.577.1"># Initialize the HuggingFaceHub LLM</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.578.1">llm = HuggingFaceHub(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.579.1">    repo_id=repo_id,</span></p>
<div aria-label="287" epub:type="pagebreak" id="page21-6" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.580.1">    task=</span><span class="hljs-string"><span class="koboSpan" id="kobo.581.1">"text-generation"</span></span><span class="koboSpan" id="kobo.582.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.583.1">    model_kwargs={</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.584.1">"temperature"</span></span><span class="koboSpan" id="kobo.585.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.586.1">0.5</span></span><span class="koboSpan" id="kobo.587.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.588.1">"max_length"</span></span><span class="koboSpan" id="kobo.589.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.590.1">1000</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.591.1">    }</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.592.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.593.1"># Use the LangChain LLM to generate text</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.594.1">output = llm.invoke(text)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.595.1">print</span></span><span class="koboSpan" id="kobo.596.1">(output)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.597.1">When executed, this code connects to Hugging Face’s servers to run the StarCoder model, a specialized code generation model trained on a vast corpus of source code. </span><span class="koboSpan" id="kobo.597.2">The expected output would be similar to our previous example—a complete implementation of the prime number calculator—but potentially with different algorithmic approaches since we’re using a different model. </span><span class="koboSpan" id="kobo.597.3">This hosted </span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.598.1">approach trades some flexibility and control for</span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.599.1"> convenience and reduced local resource requirements, making it ideal for quick prototyping or when working o</span><a id="_idTextAnchor357"/><span class="koboSpan" id="kobo.600.1">n hardware with limited capabilities.</span></p>
<h2 class="heading-2" id="_idParaDest-183"><a id="_idTextAnchor358"/><span class="koboSpan" id="kobo.601.1">Anthropic</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.602.1">Anthropic Claude series</span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.603.1"> models have been particularly good </span><a id="_idIndexMarker621"/><span class="koboSpan" id="kobo.604.1">in coding-related tasks. </span><span class="koboSpan" id="kobo.604.2">Let’s see how Claude does at a coding task:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.605.1">from</span></span><span class="koboSpan" id="kobo.606.1"> langchain_anthropic </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.607.1">import</span></span><span class="koboSpan" id="kobo.608.1"> ChatAnthropic</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.609.1">from</span></span><span class="koboSpan" id="kobo.610.1"> langchain_core.prompts.prompt </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.611.1">import</span></span><span class="koboSpan" id="kobo.612.1"> PromptTemplate</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.613.1">template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.614.1">"""Question: {question}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.615.1">Let's think step by step.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.616.1">Answer:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.617.1">"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.618.1">prompt = PromptTemplate(template=template, input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.619.1">"question"</span></span><span class="koboSpan" id="kobo.620.1">])</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.621.1">llm = ChatAnthropic(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.622.1">'claude-3-opus-20240229'</span></span><span class="koboSpan" id="kobo.623.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.624.1">llm_chain = prompt | llm</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.625.1">print</span></span><span class="koboSpan" id="kobo.626.1">(llm_chain.invoke(text))</span></p>
<div aria-label="288" epub:type="pagebreak" id="page22-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.627.1">We get an</span><a id="_idIndexMarker622"/><span class="koboSpan" id="kobo.628.1"> algorithm</span><a id="_idIndexMarker623"/><span class="koboSpan" id="kobo.629.1"> and a very detailed explanation:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.630.1">To calculate the prime numbers up to a given number N, we can follow the Sieve of Eratosthenes algorithm. </span><span class="koboSpan" id="kobo.630.2">Here</span><span class="hljs-string"><span class="koboSpan" id="kobo.631.1">'s a step-by-step approach to solve the problem:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.632.1">```python</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.633.1">def calculate_primes(n):</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.634.1">    """Create a list of consecutive integers from 2 up to N."""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.635.1">    # Create a list of consecutive integers from 2 to N</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.636.1">    numbers = list(range(2, n + 1))</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.637.1">    # Initialize an empty list to store the prime numbers</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.638.1">    primes = []</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.639.1">    while numbers:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.640.1">        # Take the first number as prime</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.641.1">        prime = numbers[0]</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.642.1">        primes.append(prime)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.643.1">        # Remove all multiples of the prime number from the list</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.644.1">        numbers = [num for num in numbers if num % prime != 0]</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.645.1">    return primes</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.646.1">```</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.647.1">Step-by-step explanation:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.648.1">We create a list called `numbers` that contains consecutive integers from 2 to N using the `range()` function.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.649.1">We initialize an empty list called `primes` to store the prime numbers that we will calculate.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.650.1">We start a loop that continues as long as there are numbers in the `numbers` list.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.651.1">Inside the loop, we take the first number from the `numbers` list and consider it as a prime number. </span><span class="koboSpan" id="kobo.651.2">We append this prime number to the `primes` list.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.652.1">We remove all the multiples of the prime number from the `numbers` list using a list comprehension. </span><span class="koboSpan" id="kobo.652.2">The list comprehension creates a new list containing only the numbers that are not divisible by the current prime number.</span></span></p>
<div aria-label="289" epub:type="pagebreak" id="page23-6" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.653.1">We repeat steps 4 and 5 until the `numbers` list becomes empty. </span><span class="koboSpan" id="kobo.653.2">This ensures that we have considered all the numbers up to N and identified the prime numbers among them.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.654.1">Finally, we return the `primes` list, which contains all the prime numbers up to N.</span></span></p>
<p class="normal"><span class="koboSpan" id="kobo.655.1">Let’s test the function with the given example:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.656.1">```python</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.657.1">print</span></span><span class="koboSpan" id="kobo.658.1">(calculate_primes(</span><span class="hljs-number"><span class="koboSpan" id="kobo.659.1">20</span></span><span class="koboSpan" id="kobo.660.1">))</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.661.1">```</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.662.1">Output:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.663.1">```</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.664.1">[2, 3, 5, 7, 11, 13, 17, 19]</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.665.1">```</span></p>
<p class="normal"><span class="koboSpan" id="kobo.666.1">The function</span><a id="_idIndexMarker624"/><span class="koboSpan" id="kobo.667.1"> correctly returns the list of prime numbers up to 20. </span><span class="koboSpan" id="kobo.667.2">This </span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.668.1">implementation follows</span><a id="_idTextAnchor359"/><span class="koboSpan" id="kobo.669.1"> the Sieve of Eratosthenes algorithm again.</span></p>
<h2 class="heading-2" id="_idParaDest-184"><a id="_idTextAnchor360"/><span class="koboSpan" id="kobo.670.1">Agentic approach</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.671.1">We can also create </span><a id="_idIndexMarker626"/><span class="koboSpan" id="kobo.672.1">an LLM agent that can execute Python code to solve problems:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.673.1">from</span></span><span class="koboSpan" id="kobo.674.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.675.1">import</span></span><span class="koboSpan" id="kobo.676.1"> ChatOpenAI</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.677.1">from</span></span><span class="koboSpan" id="kobo.678.1"> langchain.agents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.679.1">import</span></span><span class="koboSpan" id="kobo.680.1"> load_tools, initialize_agent, AgentType</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.681.1">from</span></span><span class="koboSpan" id="kobo.682.1"> langchain_experimental.tools </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.683.1">import</span></span><span class="koboSpan" id="kobo.684.1"> PythonREPLTool</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.685.1">tools = [PythonREPLTool()]   </span><span class="hljs-comment"><span class="koboSpan" id="kobo.686.1"># Gives agent ability to run Python code</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.687.1">llm = ChatOpenAI()</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.688.1"># Set up the agent with necessary tools and model</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.689.1">agent = initialize_agent(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.690.1">    tools, </span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.691.1">    llm,  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.692.1"># Language model to power the agent</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.693.1">    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, </span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.694.1">    verbose=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.695.1">True</span></span> <span class="hljs-comment"><span class="koboSpan" id="kobo.696.1"># Shows agent's thinking process</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.697.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.698.1"># Agent makes decisions without examples</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.699.1">result = agent(</span><span class="hljs-string"><span class="koboSpan" id="kobo.700.1">"What are the prime numbers until 20?"</span></span><span class="koboSpan" id="kobo.701.1">)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.702.1">print</span></span><span class="koboSpan" id="kobo.703.1">(result)</span></p>
<div aria-label="290" epub:type="pagebreak" id="page24-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.704.1">The agent will:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.705.1">Determine what it needs to write Python code.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.706.1">Use </span><code class="inlineCode"><span class="koboSpan" id="kobo.707.1">PythonREPLTool</span></code><span class="koboSpan" id="kobo.708.1"> to execute the code.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.709.1">Return the results.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.710.1">When run, it will show its reasoning steps and code execution before giving the final answ</span><a id="_idTextAnchor361"/><span class="koboSpan" id="kobo.711.1">er. </span><span class="koboSpan" id="kobo.711.2">We should be</span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.712.1"> seeing an output like this:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.713.1">&gt; Entering new AgentExecutor chain...</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.714.1">I can write a Python script to find the prime numbers up to 20.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.715.1">Action: Python_REPL</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.716.1">Action Input: def is_prime(n):</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.717.1">    if n &lt;= 1:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.718.1">        return False</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.719.1">    for i in range(2, int(n**0.5) + 1):</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.720.1">        if n % i == 0:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.721.1">            return False</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.722.1">    return True</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.723.1">primes = [num for num in range(2, 21) if is_prime(num)]</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.724.1">print(primes)</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.725.1">Observation: [2, 3, 5, 7, 11, 13, 17, 19]</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.726.1">I now know the final answer</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.727.1">Final Answer: [2, 3, 5, 7, 11, 13, 17, 19]</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.728.1">&gt; Finished chain.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.729.1">{'input': 'What are the prime numbers until 20?', 'output': '[2, 3, 5, 7, 11, 13, 17, 19]'}</span></p>
<h2 class="heading-2" id="_idParaDest-185"><a id="_idTextAnchor362"/><span class="koboSpan" id="kobo.730.1">Documentation RAG</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.731.1">What is also </span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.732.1">quite interesting is the use of documents to help </span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.733.1">write code or to ask questions about documentation. </span><span class="koboSpan" id="kobo.733.2">Here’s an example of loading all documentation pages from LangChain’s website using </span><code class="inlineCode"><span class="koboSpan" id="kobo.734.1">DocusaurusLoader</span></code><span class="koboSpan" id="kobo.735.1">:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.736.1">from</span></span><span class="koboSpan" id="kobo.737.1"> langchain_community.document_loaders </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.738.1">import</span></span><span class="koboSpan" id="kobo.739.1"> DocusaurusLoader</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.740.1">import</span></span><span class="koboSpan" id="kobo.741.1"> nest_asyncio</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.742.1">nest_asyncio.apply()</span></p>
<div aria-label="291" epub:type="pagebreak" id="page25-5" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.743.1"># Load all pages from LangChain docs</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.744.1">loader = DocusaurusLoader(</span><span class="hljs-string"><span class="koboSpan" id="kobo.745.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.746.1">https://python.langchain.com"</span></span><span class="koboSpan" id="kobo.747.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.748.1">documents[</span><span class="hljs-number"><span class="koboSpan" id="kobo.749.1">0</span></span><span class="koboSpan" id="kobo.750.1">]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.751.1">nest_asyncio.apply() enables </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.752.1">async</span></span><span class="koboSpan" id="kobo.753.1"> operations </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.754.1">in</span></span><span class="koboSpan" id="kobo.755.1"> Jupyter notebooks. </span><span class="koboSpan" id="kobo.755.2">The loader gets </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.756.1">all</span></span><span class="koboSpan" id="kobo.757.1"> pages.</span></p>
<p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.758.1">DocusaurusLoader</span></code><span class="koboSpan" id="kobo.759.1"> automatically scrapes and extracts content from LangChain’s documentation website. </span><span class="koboSpan" id="kobo.759.2">This loader is specifically designed to navigate Docusaurus-based sites and extract properly formatted content. </span><span class="koboSpan" id="kobo.759.3">Meanwhile, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.760.1">nest_asyncio.apply()</span></code><span class="koboSpan" id="kobo.761.1"> function is necessary for a Jupyter Notebook environment, which has limitations with asyncio’s event loop. </span><span class="koboSpan" id="kobo.761.2">This line allows us to run asynchronous code within the notebook’s cells, which is required for many web-scraping operations. </span><span class="koboSpan" id="kobo.761.3">After execution, the documents variable contains all the documentation pages, each represented as a </span><code class="inlineCode"><span class="koboSpan" id="kobo.762.1">Document</span></code><span class="koboSpan" id="kobo.763.1"> object with properties like </span><code class="inlineCode"><span class="koboSpan" id="kobo.764.1">page_content</span></code><span class="koboSpan" id="kobo.765.1"> and metadata. </span><span class="koboSpan" id="kobo.765.2">We can then set up embeddings with caching:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.766.1">from</span></span><span class="koboSpan" id="kobo.767.1"> langchain.embeddings </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.768.1">import</span></span><span class="koboSpan" id="kobo.769.1"> CacheBackedEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.770.1">from</span></span><span class="koboSpan" id="kobo.771.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.772.1">import</span></span><span class="koboSpan" id="kobo.773.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.774.1">from</span></span><span class="koboSpan" id="kobo.775.1"> langchain.storage </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.776.1">import</span></span><span class="koboSpan" id="kobo.777.1"> LocalFileStore</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.778.1"># Cache embeddings locally to avoid redundant API calls</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.779.1">store = LocalFileStore(</span><span class="hljs-string"><span class="koboSpan" id="kobo.780.1">"./cache/"</span></span><span class="koboSpan" id="kobo.781.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.782.1">underlying_embeddings = OpenAIEmbeddings(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.783.1">"text-embedding-3-large"</span></span><span class="koboSpan" id="kobo.784.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.785.1">embeddings = CacheBackedEmbeddings.from_bytes_store(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.786.1">    underlying_embeddings, store, namespace=underlying_embeddings.model</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.787.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.788.1">Before we can feed</span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.789.1"> our models into a vector store, we need to </span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.790.1">split them, as discussed in </span><a href="E_Chapter_4.xhtml#_idTextAnchor152"><em class="italic"><span class="koboSpan" id="kobo.791.1">Chapter 4</span></em></a><span class="koboSpan" id="kobo.792.1">:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.793.1">from</span></span><span class="koboSpan" id="kobo.794.1"> langchain_text_splitters </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.795.1">import</span></span><span class="koboSpan" id="kobo.796.1"> RecursiveCharacterTextSplitter</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.797.1">text_splitter = RecursiveCharacterTextSplitter(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.798.1">    chunk_size=</span><span class="hljs-number"><span class="koboSpan" id="kobo.799.1">1000</span></span><span class="koboSpan" id="kobo.800.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.801.1">    chunk_overlap=</span><span class="hljs-number"><span class="koboSpan" id="kobo.802.1">20</span></span><span class="koboSpan" id="kobo.803.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.804.1">    length_function=</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.805.1">len</span></span><span class="koboSpan" id="kobo.806.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.807.1">    is_separator_regex=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.808.1">False</span></span><span class="koboSpan" id="kobo.809.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.810.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.811.1">splits = text_splitter.split_documents(documents)</span></p>
<div aria-label="292" epub:type="pagebreak" id="page26-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.812.1">Now we’ll create a vector store from the document splits:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.813.1">from</span></span><span class="koboSpan" id="kobo.814.1"> langchain_chroma </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.815.1">import</span></span><span class="koboSpan" id="kobo.816.1"> Chroma</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.817.1"># Store document embeddings for efficient retrieval</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.818.1">vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.819.1">We’ll also need to initialize the LLM or chat model: </span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.820.1">from</span></span><span class="koboSpan" id="kobo.821.1"> langchain_google_vertexai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.822.1">import</span></span><span class="koboSpan" id="kobo.823.1"> VertexAI</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.824.1">llm = VertexAI(model_name=</span><span class="hljs-string"><span class="koboSpan" id="kobo.825.1">"gemini-pro"</span></span><span class="koboSpan" id="kobo.826.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.827.1">Then, we set up the RAG components:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.828.1">from</span></span><span class="koboSpan" id="kobo.829.1"> langchain </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.830.1">import</span></span><span class="koboSpan" id="kobo.831.1"> hub</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.832.1">retriever = vectorstore.as_retriever()</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.833.1"># Use community-created RAG prompt template</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.834.1">prompt = hub.pull(</span><span class="hljs-string"><span class="koboSpan" id="kobo.835.1">"rlm/rag-prompt"</span></span><span class="koboSpan" id="kobo.836.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.837.1">Finally, we’ll build the RAG chain:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.838.1">from</span></span><span class="koboSpan" id="kobo.839.1"> langchain_core.runnables </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.840.1">import</span></span><span class="koboSpan" id="kobo.841.1"> RunnablePassthrough</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.842.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.843.1">format_docs</span></span><span class="koboSpan" id="kobo.844.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.845.1">docs</span></span><span class="koboSpan" id="kobo.846.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.847.1">return</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.848.1">"\n\n"</span></span><span class="koboSpan" id="kobo.849.1">.join(doc.page_content </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.850.1">for</span></span><span class="koboSpan" id="kobo.851.1"> doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.852.1">in</span></span><span class="koboSpan" id="kobo.853.1"> docs)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.854.1"># Chain combines context retrieval, prompting, and response generation</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.855.1">rag_chain = (</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.856.1">    {</span><span class="hljs-string"><span class="koboSpan" id="kobo.857.1">"context"</span></span><span class="koboSpan" id="kobo.858.1">: retriever | format_docs, </span><span class="hljs-string"><span class="koboSpan" id="kobo.859.1">"question"</span></span><span class="koboSpan" id="kobo.860.1">: RunnablePassthrough()}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.861.1">    | prompt</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.862.1">    | llm</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.863.1">    | StrOutputParser()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.864.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.865.1">Let’s query the chain:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.866.1">response = rag_chain.invoke(</span><span class="hljs-string"><span class="koboSpan" id="kobo.867.1">"What is Task Decomposition?"</span></span><span class="koboSpan" id="kobo.868.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.869.1">Each component </span><a id="_idIndexMarker632"/><span class="koboSpan" id="kobo.870.1">builds on the previous one, creating a complete RAG</span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.871.1"> system that can </span><a id="_idTextAnchor363"/><span class="koboSpan" id="kobo.872.1">answer questions using the LangChain documentation.</span></p>
<div aria-label="293" epub:type="pagebreak" id="page27-5" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-186"><a id="_idTextAnchor364"/><span class="koboSpan" id="kobo.873.1">Repository RAG</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.874.1">One powerful </span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.875.1">application of RAG systems is analyzing code repositories</span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.876.1"> to enable natural language queries about codebases. </span><span class="koboSpan" id="kobo.876.2">This technique allows developers to quickly understand unfamiliar code or find relevant implementation examples. </span><span class="koboSpan" id="kobo.876.3">Let’s build a code-focused RAG system by indexing a GitHub repository.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.877.1">First, we’ll clone the repository and set up our environment:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.878.1">import</span></span><span class="koboSpan" id="kobo.879.1"> os</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.880.1">from</span></span><span class="koboSpan" id="kobo.881.1"> git </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.882.1">import</span></span><span class="koboSpan" id="kobo.883.1"> Repo</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.884.1">from</span></span><span class="koboSpan" id="kobo.885.1"> langchain_community.document_loaders.generic </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.886.1">import</span></span><span class="koboSpan" id="kobo.887.1"> GenericLoader</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.888.1">from</span></span><span class="koboSpan" id="kobo.889.1"> langchain_community.document_loaders.parsers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.890.1">import</span></span><span class="koboSpan" id="kobo.891.1"> LanguageParser</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.892.1">from</span></span><span class="koboSpan" id="kobo.893.1"> langchain_text_splitters </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.894.1">import</span></span><span class="koboSpan" id="kobo.895.1"> Language, RecursiveCharacterTextSplitter</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.896.1"># Clone the book repository from GitHub</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.897.1">repo_path = os.path.expanduser(</span><span class="hljs-string"><span class="koboSpan" id="kobo.898.1">"~/Downloads/generative_ai_with_langchain"</span></span><span class="koboSpan" id="kobo.899.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.900.1"># this directory should not exist yet!</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.901.1">repo = Repo.clone_from(</span><span class="hljs-string"><span class="koboSpan" id="kobo.902.1">"https://github.com/benman1/generative_ai_with_langchain"</span></span><span class="koboSpan" id="kobo.903.1">, to_path=repo_path)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.904.1">After cloning the repository, we need to parse the Python files using LangChain’s specialized loaders that understand code structure. </span><span class="koboSpan" id="kobo.904.2">LanguageParser helps maintain code semantics during processing:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.905.1">loader = GenericLoader.from_filesystem(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.906.1">    repo_path,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.907.1">    glob=</span><span class="hljs-string"><span class="koboSpan" id="kobo.908.1">"**/*"</span></span><span class="koboSpan" id="kobo.909.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.910.1">    suffixes=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.911.1">".py"</span></span><span class="koboSpan" id="kobo.912.1">],</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.913.1">    parser=LanguageParser(language=Language.PYTHON, parser_threshold=</span><span class="hljs-number"><span class="koboSpan" id="kobo.914.1">500</span></span><span class="koboSpan" id="kobo.915.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.916.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.917.1">documents = loader.load()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.918.1">python_splitter = RecursiveCharacterTextSplitter.from_language(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.919.1">    language=Language.PYTHON, chunk_size=</span><span class="hljs-number"><span class="koboSpan" id="kobo.920.1">50</span></span><span class="koboSpan" id="kobo.921.1">, chunk_overlap=</span><span class="hljs-number"><span class="koboSpan" id="kobo.922.1">0</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.923.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.924.1"># Split the Document into chunks for embedding and vector storage</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.925.1">texts = python_splitter.split_documents(documents)</span></p>
<div aria-label="294" epub:type="pagebreak" id="page28-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.926.1">This code performs three key operations: it clones our book’s GitHub repository, loads all Python files using language-aware parsing, and splits the code into smaller, semantically meaningful chunks. </span><span class="koboSpan" id="kobo.926.2">The language-specific splitter ensures we preserve function and class definitions when possible, making our </span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.927.1">retrieval more effective.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.928.1">Now we’ll create our</span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.929.1"> RAG system by embedding these code chunks and setting up a retrieval chain:</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.930.1"># Create vector store and retriever</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.931.1">db = Chroma.from_documents(texts, OpenAIEmbeddings())</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.932.1">retriever = db.as_retriever(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.933.1">    search_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.934.1">"mmr"</span></span><span class="koboSpan" id="kobo.935.1">,  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.936.1"># Maximal Marginal Relevance for diverse results</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.937.1">    search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.938.1">"k"</span></span><span class="koboSpan" id="kobo.939.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.940.1">8</span></span><span class="koboSpan" id="kobo.941.1">}  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.942.1"># Return 8 most relevant chunks</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.943.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.944.1"># Set up Q&amp;A chain</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.945.1">prompt = ChatPromptTemplate.from_messages([</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.946.1">    (</span><span class="hljs-string"><span class="koboSpan" id="kobo.947.1">"system"</span></span><span class="koboSpan" id="kobo.948.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.949.1">"Answer based on context:\n\n{context}"</span></span><span class="koboSpan" id="kobo.950.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.951.1">    (</span><span class="hljs-string"><span class="koboSpan" id="kobo.952.1">"placeholder"</span></span><span class="koboSpan" id="kobo.953.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.954.1">"{chat_history}"</span></span><span class="koboSpan" id="kobo.955.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.956.1">    (</span><span class="hljs-string"><span class="koboSpan" id="kobo.957.1">"user"</span></span><span class="koboSpan" id="kobo.958.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.959.1">"{input}"</span></span><span class="koboSpan" id="kobo.960.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.961.1">])</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.962.1"># Create chain components</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.963.1">document_chain = create_stuff_documents_chain(ChatOpenAI(), prompt)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.964.1">qa = create_retrieval_chain(retriever, document_chain)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.965.1">Here, we’ve built our complete RAG pipeline: we store code embeddings in a Chroma vector database, configure a retriever to use maximal marginal relevance (which helps provide diverse results), and create a QA chain that combines retrieved code with our prompt template before sending it to the LLM.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.966.1">Let’s test our code-aware RAG system with a question about software development examples:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.967.1">question = </span><span class="hljs-string"><span class="koboSpan" id="kobo.968.1">"What examples are in the code related to software development?"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.969.1">result = qa.invoke({</span><span class="hljs-string"><span class="koboSpan" id="kobo.970.1">"input"</span></span><span class="koboSpan" id="kobo.971.1">: question})</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.972.1">print</span></span><span class="koboSpan" id="kobo.973.1">(result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.974.1">"answer"</span></span><span class="koboSpan" id="kobo.975.1">])</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.976.1">Here are some examples of the code related to software development </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.977.1">in</span></span><span class="koboSpan" id="kobo.978.1"> the given context:</span></p>
<div aria-label="295" epub:type="pagebreak" id="page29-5" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.979.1">1.</span></span><span class="koboSpan" id="kobo.980.1"> Task planner </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.981.1">and</span></span><span class="koboSpan" id="kobo.982.1"> executor </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.983.1">for</span></span><span class="koboSpan" id="kobo.984.1"> software development: This indicates that the code includes functionality </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.985.1">for</span></span><span class="koboSpan" id="kobo.986.1"> planning </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.987.1">and</span></span><span class="koboSpan" id="kobo.988.1"> executing tasks related to software development.</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.989.1">2.</span></span><span class="koboSpan" id="kobo.990.1"> debug your code: This suggests that there </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.991.1">is</span></span><span class="koboSpan" id="kobo.992.1"> a recommendation to debug the code </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.993.1">if</span></span><span class="koboSpan" id="kobo.994.1"> an error occurs during software development.</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.995.1">These examples provide insights into the software development process described </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.996.1">in</span></span><span class="koboSpan" id="kobo.997.1"> the context.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.998.1">The response is </span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.999.1">somewhat limited, likely because our small chunk</span><a id="_idIndexMarker639"/><span class="koboSpan" id="kobo.1000.1"> size (50 characters) may have fragmented code examples. </span><span class="koboSpan" id="kobo.1000.2">While the system correctly identifies mentions of task planning and debugging, it doesn’t provide detailed code examples or context. </span><span class="koboSpan" id="kobo.1000.3">In a production environment, you might want to increase the chunk size or implement hierarchical chunking to preserve more context. </span><span class="koboSpan" id="kobo.1000.4">Additionally, using a code-specific embedding model could further improve the relevance of retrieved results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1001.1">In the next section, we’ll explore how generative AI agents can automate and enhance data science workflows. </span><span class="koboSpan" id="kobo.1001.2">LangChain agents can write and execute code, analyze datasets, and even build and train ML</span><a id="_idIndexMarker640"/><span class="koboSpan" id="kobo.1002.1"> models with minimal human guidance. </span><span class="koboSpan" id="kobo.1002.2">We’ll demonstrate two powerful applications: training </span><a id="_idTextAnchor365"/><span class="koboSpan" id="kobo.1003.1">a neural network model and analyzing a structured dataset.</span></p>
<h1 class="heading-1" id="_idParaDest-187"><a id="_idTextAnchor366"/><span class="koboSpan" id="kobo.1004.1">Applying LLM agents for data science</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1005.1">The integration of LLMs into </span><a id="_idIndexMarker641"/><span class="koboSpan" id="kobo.1006.1">data science workflows represents a significant, though nuanced, evolution in how analytical tasks are approached. </span><span class="koboSpan" id="kobo.1006.2">While traditional data science methods remain essential for complex numerical analysis, LLMs offer complementary capabilities that primarily enhance accessibility and assist with specific aspects of the workflow.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1007.1">Independent research reveals a more measured reality than some vendor claims suggest. </span><span class="koboSpan" id="kobo.1007.2">According to multiple studies, LLMs demonstrate variable effectiveness across different data science tasks, with performance often declining as complexity increases. </span><span class="koboSpan" id="kobo.1007.3">A study published in PLOS One found that “the executability of generated code decreased significantly as the complexity of the data analysis task increased,” highlighting the limitations of current models when handling sophisticated analytical challenges.</span></p>
<div aria-label="296" epub:type="pagebreak" id="page30-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1008.1">LLMs exhibit a fundamental distinction in their data focus compared to traditional methods. </span><span class="koboSpan" id="kobo.1008.2">While traditional statistical techniques excel at processing structured, tabular data through well-defined mathematical relationships, LLMs demonstrate superior capabilities with unstructured text. </span><span class="koboSpan" id="kobo.1008.3">They can generate code for common data science tasks, particularly boilerplate operations involving data manipulation, visualization, and routine statistical analyses. </span><span class="koboSpan" id="kobo.1008.4">Research on GitHub Copilot and similar tools indicates that these assistants can meaningfully accelerate development, though the productivity gains observed in independent studies (typically 7–22%) are more modest than some vendors claim. </span><span class="koboSpan" id="kobo.1008.5">BlueOptima’s analysis of over 218,000 developers found productivity improvements closer to 4% rather than the 55% claimed in controlled experiments.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1009.1">Text-to-SQL capabilities represent one of the most promising applications, potentially democratizing data access by allowing non-technical users to query databases in natural language. </span><span class="koboSpan" id="kobo.1009.2">However, the performance often drops on the more realistic BIRD benchmark compared to Spider, and accuracy remains a key concern, with performance varying significantly based on the complexity of the query, the database schema, and the benchmark used. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.1010.1">LLMs also excel at translating technical findings into accessible narratives for non-technical audiences, functioning as a communication bridge in data-driven organizations. </span><span class="koboSpan" id="kobo.1010.2">While systems such as InsightLens demonstrate automated insight organization capabilities, the technology shows clear strengths and limitations when generating different types of content. </span><span class="koboSpan" id="kobo.1010.3">The contrast is particularly stark with synthetic data: LLMs effectively create qualitative text samples but struggle with structured numerical datasets requiring complex statistical relationships. </span><span class="koboSpan" id="kobo.1010.4">This performance boundary aligns with their core text processing capabilities and highlights where traditional statistical methods remain superior. </span><span class="koboSpan" id="kobo.1010.5">A study published in JAMIA (</span><em class="italic"><span class="koboSpan" id="kobo.1011.1">Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data</span></em><span class="koboSpan" id="kobo.1012.1">, 2024) found that “LLMs (specifically GPT-4, but not GPT-3.5) [were] effective for data augmentation in social media health text classification tasks but ineffective when used alone to annotate training data for supervised models.”</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1013.1">The evidence points toward a future where LLMs and traditional data analysis tools coexist and complement each other. </span><span class="koboSpan" id="kobo.1013.2">The most effective implementations will likely be hybrid systems leveraging:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1014.1">LLMs for natural language interaction, code assistance, text processing, and initial exploration</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1015.1">Traditional statistical and ML techniques for rigorous analysis of structured data and high-stakes prediction tasks</span></li>
</ul>
<div aria-label="297" epub:type="pagebreak" id="page31-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1016.1">The transformation brought by LLMs enables both technical and non-technical stakeholders to interact with data effectively. </span><span class="koboSpan" id="kobo.1016.2">Its primary value lies in reducing the cognitive load associated with repetitive coding tasks, allowing data scientists to maintain the flow and focus on higher-level analytical challenges. </span><span class="koboSpan" id="kobo.1016.3">However, rigorous validation remains essential—independent studies consistently identify concerns regarding code quality, security, and maintainability. </span><span class="koboSpan" id="kobo.1016.4">These considerations are especially critical in two key workflows that LangChain has revolutionized: training ML models and analyzing datasets. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.1017.1">When training ML models, LLMs can now generate synthetic training data, assist in feature engineering, and automatically tune hyperparameters—dramatically reducing the expertise barrier for model development. </span><span class="koboSpan" id="kobo.1017.2">Moreover, for data analysis, LLMs serve as intelligent interfaces that translate natural </span><a id="_idIndexMarker642"/><span class="koboSpan" id="kobo.1018.1">language questions into code, visualizations, and insights, allowing domain experts to extract value from data without deep programming knowledge. </span><span class="koboSpan" id="kobo.1018.2">The fo</span><a id="_idTextAnchor367"/><a id="_idTextAnchor368"/><span class="koboSpan" id="kobo.1019.1">llowing sections explore both of these areas with LangChain.</span></p>
<h2 class="heading-2" id="_idParaDest-188"><a id="_idTextAnchor369"/><span class="koboSpan" id="kobo.1020.1">Training an ML model</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.1021.1">As you know by now, LangChain</span><a id="_idIndexMarker643"/><span class="koboSpan" id="kobo.1022.1"> agents can write and execute </span><a id="_idIndexMarker644"/><span class="koboSpan" id="kobo.1023.1">Python code for data science tasks, including building and training ML models. </span><span class="koboSpan" id="kobo.1023.2">This capability is particularly valuable when you need to perform complex data analysis, create visualizations, or implement custom algorithms on the fly without switching contexts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1024.1">In this section, we’ll explore how to create and use Python-capable agents through two main steps: setting up the Python agent environment and configuring the agent with the right model and tools; and </span><a id="_idIndexMarker645"/><span class="koboSpan" id="kobo.1025.1">implementing a neural network from</span><a id="_idIndexMarker646"/><span class="koboSpan" id="kobo.1026.1"> scratch, guiding the agent to create a complete working model.</span></p>
<h3 class="heading-3" id="_idParaDest-189"><a id="_idTextAnchor370"/><span class="koboSpan" id="kobo.1027.1">Setting up a Python-capable agent</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1028.1">Let’s start by</span><a id="_idIndexMarker647"/><span class="koboSpan" id="kobo.1029.1"> crea</span><a id="_idTextAnchor371"/><span class="koboSpan" id="kobo.1030.1">ting a Python-capable agent using LangChain’s experimental tools:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1031.1">from</span></span><span class="koboSpan" id="kobo.1032.1"> langchain_experimental.agents.agent_toolkits.python.base </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1033.1">import</span></span><span class="koboSpan" id="kobo.1034.1"> create_python_agent</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1035.1">from</span></span><span class="koboSpan" id="kobo.1036.1"> langchain_experimental.tools.python.tool </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1037.1">import</span></span><span class="koboSpan" id="kobo.1038.1"> PythonREPLTool</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1039.1">from</span></span><span class="koboSpan" id="kobo.1040.1"> langchain_anthropic </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1041.1">import</span></span><span class="koboSpan" id="kobo.1042.1"> ChatAnthropic</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1043.1">from</span></span><span class="koboSpan" id="kobo.1044.1"> langchain.agents.agent_types </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1045.1">import</span></span><span class="koboSpan" id="kobo.1046.1"> AgentType</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1047.1">agent_executor = create_python_agent(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1048.1">    llm=ChatAnthropic(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1049.1">'claude-3-opus-20240229'</span></span><span class="koboSpan" id="kobo.1050.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1051.1">    tool=PythonREPLTool(),</span></p>
<div aria-label="298" epub:type="pagebreak" id="page32-5" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.1052.1">    verbose=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1053.1">True</span></span><span class="koboSpan" id="kobo.1054.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1055.1">    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1056.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1057.1">This code creates a Python agent with the Claude 3 Opus model, which offers strong reasoning capabilities for complex programming tasks. </span><code class="inlineCode"><span class="koboSpan" id="kobo.1058.1">PythonREPLTool</span></code><span class="koboSpan" id="kobo.1059.1"> provides the agent with a Python execution environment, allowing it to write and run code, see outputs, and iterate based on results. </span><span class="koboSpan" id="kobo.1059.2">Setting </span><code class="inlineCode"><span class="koboSpan" id="kobo.1060.1">verbose=True</span></code><span class="koboSpan" id="kobo.1061.1"> lets us observe the agent’s thought process, which is valuable for understanding its approach and debugging.</span></p>
<div>
<div class="note" id="_idContainer094">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1062.1">Security caution</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.1063.1">PythonREPLTool executes arbitrary Python code with the same permissions as your application. </span><span class="koboSpan" id="kobo.1063.2">While excellent for development and demonstrations, this presents significant security risks in production environments. </span><span class="koboSpan" id="kobo.1063.3">For production deployments, consider:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1064.1">Using restricted execution environments such as RestrictedPython or Docker containers</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1065.1">Implementing custom tools with explicit permission boundaries</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1066.1">Running the agent in a separate isolated service with limited permissions</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1067.1">Adding validation and sanitization steps before executing generated code</span></li>
</ul>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.1068.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.1069.1">AgentExecutor</span></code><span class="koboSpan" id="kobo.1070.1">, on the other hand, is a LangChain component that orchestrates the execution loop for agents. </span><span class="koboSpan" id="kobo.1070.2">It manages the agent’s decision-making process, handles interactions with tools, enforces iteration limits, and processes the agent’s final output. </span><span class="koboSpan" id="kobo.1070.3">Think of it as the runtime environment where the agent operates.</span></p>
<h3 class="heading-3" id="_idParaDest-190"><a id="_idTextAnchor372"/><span class="koboSpan" id="kobo.1071.1">Asking the agent to build a neural network</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1072.1">Now that we’ve</span><a id="_idIndexMarker648"/><span class="koboSpan" id="kobo.1073.1"> set up our Python agent, let’s test its capabilities with a practical ML task. </span><span class="koboSpan" id="kobo.1073.2">We’ll challenge the agent to implement a simple neural network that learns a basic linear relationship. </span><span class="koboSpan" id="kobo.1073.3">This example demonstrates how agents can handle end-to-end ML development tasks from data generation to model training and evaluation.</span></p>
<div aria-label="299" epub:type="pagebreak" id="page33-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1074.1">The following code instructs our agent to create a single-neuron neural network in PyTorch, train it on synthetic data representing the function </span><code class="inlineCode"><span class="koboSpan" id="kobo.1075.1">y=2x</span></code><span class="koboSpan" id="kobo.1076.1">, and make a prediction:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1077.1">result = agent_executor.run(</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1078.1">"""Understand, write a single neuron neural network in PyTorch.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1079.1">Take synthetic data for y=2x. </span><span class="koboSpan" id="kobo.1079.2">Train for 1000 epochs and print every 100 epochs.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1080.1">Return prediction for x = 5"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1081.1">)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.1082.1">print</span></span><span class="koboSpan" id="kobo.1083.1">(result)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1084.1">This concise prompt instructs the agent to implement a full neural network pipeline: generating PyTorch code for a single-neuron model, creating synthetic training data that follows </span><code class="inlineCode"><span class="koboSpan" id="kobo.1085.1">y=2x</span></code><span class="koboSpan" id="kobo.1086.1">, training the model over 1,000 epochs with periodic progress report</span><a id="_idTextAnchor373"/><span class="koboSpan" id="kobo.1087.1">s, and, finally, making a prediction for a new input value of </span><code class="inlineCode"><span class="koboSpan" id="kobo.1088.1">x=5</span></code><span class="koboSpan" id="kobo.1089.1">.</span></p>
<h3 class="heading-3" id="_idParaDest-191"><a id="_idTextAnchor374"/><span class="koboSpan" id="kobo.1090.1">Agent execution and results</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1091.1">When we run this</span><a id="_idIndexMarker649"/><span class="koboSpan" id="kobo.1092.1"> code, the agent begins reasoning through the problem and executing Python code. </span><span class="koboSpan" id="kobo.1092.2">Here’s the abbreviated verbose output showing the agent’s thought process and execution:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1093.1">&gt; Entering new AgentExecutor chain...</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1094.1">Here is a single neuron neural network in PyTorch that trains on synthetic data for y=2x, prints the loss every 100 epochs, and returns the prediction for x=5:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1095.1">Action: Python_REPL</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1096.1">Action Input:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1097.1">import torch</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1098.1">import torch.nn as nn</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1099.1"># Create synthetic data</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1100.1">X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1101.1">y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1102.1"># Define the model</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1103.1">[...] # Code for creating the model omitted for brevity</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1104.1">Observation:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1105.1">Epoch [100/1000], Loss: 0.0529</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1106.1">[...] # Training progress for epochs 200-900 omitted for brevity</span></p>
<div aria-label="300" epub:type="pagebreak" id="page34-5" role="doc-pagebreak"/>
<p class="snippet-con"><span class="koboSpan" id="kobo.1107.1">Epoch [1000/1000], Loss: 0.0004</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1108.1">Prediction for x=5: 9.9659</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1109.1">To summarize:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1110.1">- I created a single neuron neural network model in PyTorch using nn.Linear(1, 1)</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1111.1">- I generated synthetic data where y=2x for training</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1112.1">- I defined the MSE loss function and SGD optimizer</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1113.1">- I trained the model for 1000 epochs, printing the loss every 100 epochs</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1114.1">- After training, I made a prediction for x=5</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1115.1">The final prediction for x=5 is 9.9659, which is very close to the expected value of 10 (since y=2x).</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1116.1">So in conclusion, I was able to train a simple single neuron PyTorch model to fit the synthetic y=2x data well and make an accurate prediction for a new input x=5.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1117.1">Final Answer: The trained single neuron PyTorch model predicts a value of 9.9659 for x=5.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1118.1">&gt; Finished chain.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1119.1">The final output confirms that our agent successfully built and trained a model that learned the y=2x relationship. </span><span class="koboSpan" id="kobo.1119.2">The prediction for x=5 is a</span><a id="_idTextAnchor375"/><span class="koboSpan" id="kobo.1120.1">pproximately 9.97, which is very close to the expected value of 10.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1121.1">The results demonstrate </span><a id="_idIndexMarker650"/><span class="koboSpan" id="kobo.1122.1">that our agent successfully built and trained a neural network. </span><span class="koboSpan" id="kobo.1122.2">The prediction for x=5 is approximately 9.97, very close to the expected value of 10 (since 2×5=10). </span><span class="koboSpan" id="kobo.1122.3">This accuracy confirms that the model effectively learned the underlying linear relationship from our synthetic data.</span></p>
<div>
<div class="packt_tip" id="_idContainer095">
<p class="normal"><span class="koboSpan" id="kobo.1123.1">If your agent produces unsatisfactory results, consider increasing specificity in your prompt (e.g., specify learning rate or model architecture), requesting validation steps such as plotting the loss curve, lowering the LLM temperature for more deterministic results, or breaking complex tasks into sequential prompts.</span></p>
</div>
</div>
<div aria-label="301" epub:type="pagebreak" id="page35-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1124.1">This example showcases how LangChain agents can successfully implement ML workflows with minimal human intervention. </span><span class="koboSpan" id="kobo.1124.2">The agent demonstrated strong capabilities in understanding the requested task, generating correct PyTorch code without reference examples, creating appropriate synthetic data, configuring and training the neural network, and evaluating results against expected outcomes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1125.1">In a real-world scenario, you could extend this approach to more complex ML tasks such as classification problems, time series forecasting, or even custom model architectures. </span><span class="koboSpan" id="kobo.1125.2">Next, we’ll explore how agents </span><a id="_idIndexMarker651"/><span class="koboSpan" id="kobo.1126.1">can assist with data analysis and visualization tasks that build upon these fundamental ML capabilities.</span></p>
<h2 class="heading-2" id="_idParaDest-192"><a id="_idTextAnchor376"/><span class="koboSpan" id="kobo.1127.1">Analyzing a dataset</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.1128.1">Next, we’ll demonstrate how</span><a id="_idIndexMarker652"/><span class="koboSpan" id="kobo.1129.1"> LangChain agents can analyze structured datasets by examining the well-known </span><code class="inlineCode"><span class="koboSpan" id="kobo.1130.1">Iris</span></code><span class="koboSpan" id="kobo.1131.1"> dataset. </span><span class="koboSpan" id="kobo.1131.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.1132.1">Iris</span></code><span class="koboSpan" id="kobo.1133.1"> dataset, created by British statistician Ronald Fisher, contains measurements of sepal length, sepal width, petal length, and petal width for three species of iris flo</span><a id="_idTextAnchor377"/><a id="_idTextAnchor378"/><span class="koboSpan" id="kobo.1134.1">wers. </span><span class="koboSpan" id="kobo.1134.2">It’s commonly used in machine learning for classification tasks.</span></p>
<h3 class="heading-3" id="_idParaDest-193"><a id="_idTextAnchor379"/><span class="koboSpan" id="kobo.1135.1">Creating a pandas DataFrame agent</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1136.1">Data analysis is a </span><a id="_idIndexMarker653"/><span class="koboSpan" id="kobo.1137.1">perfect application for LLM agents. </span><span class="koboSpan" id="kobo.1137.2">Let’s explore how to create an agent specialized in working with pandas DataFrames, enabling natural language interaction with tabular data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1138.1">First, we’ll load the classic Iris dataset and save it as a CSV file for our agent to work with:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1139.1">from</span></span><span class="koboSpan" id="kobo.1140.1"> sklearn.datasets </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1141.1">import</span></span><span class="koboSpan" id="kobo.1142.1"> load_iris</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1143.1">df = load_iris(as_frame=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1144.1">True</span></span><span class="koboSpan" id="kobo.1145.1">)[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1146.1">"data"</span></span><span class="koboSpan" id="kobo.1147.1">]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1148.1">df.to_csv(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1149.1">"iris.csv"</span></span><span class="koboSpan" id="kobo.1150.1">, index=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1151.1">False</span></span><span class="koboSpan" id="kobo.1152.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1153.1">Now we’ll create a specialized agent for working with pandas DataFrames:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1154.1">from</span></span><span class="koboSpan" id="kobo.1155.1"> langchain_experimental.agents.agent_toolkits.pandas.base </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1156.1">import</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1157.1">create_pandas_dataframe_agent</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1158.1">from</span></span><span class="koboSpan" id="kobo.1159.1"> langchain </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1160.1">import</span></span><span class="koboSpan" id="kobo.1161.1"> PromptTemplate</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1162.1">PROMPT = (</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1163.1">"If you do not know the answer, say you don't know.\n"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1164.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1165.1">Think step by step.\n"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1166.1">"\n"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1167.1">"Below is the query.\n"</span></span></p>
<div aria-label="302" epub:type="pagebreak" id="page36-5" role="doc-pagebreak"/>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1168.1">"Query: {query}\n"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1169.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1170.1">prompt = PromptTemplate(template=PROMPT, input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1171.1">"query"</span></span><span class="koboSpan" id="kobo.1172.1">])</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1173.1">llm = OpenAI()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1174.1">agent = create_pandas_dataframe_agent(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1175.1">    llm, df, verbose=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1176.1">True</span></span><span class="koboSpan" id="kobo.1177.1">, allow_dangerous_code=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1178.1">True</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1179.1">)</span></p>
<div>
<div class="note" id="_idContainer096">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1180.1">Security warning</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.1181.1">We’ve used </span><code class="inlineCode"><span class="koboSpan" id="kobo.1182.1">allow_dangerous_code=True</span></code><span class="koboSpan" id="kobo.1183.1">, which permits the agent to execute any Python code on your machine. </span><span class="koboSpan" id="kobo.1183.2">This could potentially be harmful if the agent generates malicious code. </span><span class="koboSpan" id="kobo.1183.3">Only use this option in development environments with trusted data sources, and never in production scenarios without proper sandboxing.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.1184.1">The example above works well with small datasets like Iris (150 rows), but real-world data analysis often involves much larger datasets that exceed LLM context windows. </span><span class="koboSpan" id="kobo.1184.2">When implementing DataFrame agents in production environments, several strategies can help overcome these limitations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1185.1">Data summarization and preprocessing techniques form your first line of defense. </span><span class="koboSpan" id="kobo.1185.2">Before sending data to your agent, consider extracting key statistical information such as shape, column names, data types, and summary statistics (mean, median, max, etc.). </span><span class="koboSpan" id="kobo.1185.3">Including representative samples—perhaps the first and last few rows or a small random sample—provides context without overwhelming the LLM’s token limit. </span><span class="koboSpan" id="kobo.1185.4">This preprocessing approach preserves critical information while dramatically reducing the input size.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1186.1">For datasets that are too large for a single context window, chunking strategies offer an effective solution. </span><span class="koboSpan" id="kobo.1186.2">You can process the data in manageable segments, run your agent on each chunk separately, and then aggregate the results. </span><span class="koboSpan" id="kobo.1186.3">The aggregation logic would depend on the specific analysis task—for example, finding global maximums across chunk-level results for optimization queries or combining partial analyses for more complex tasks. </span><span class="koboSpan" id="kobo.1186.4">This approach trades some global context for the ability to handle datasets of any size.</span></p>
<div aria-label="303" epub:type="pagebreak" id="page37-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1187.1">Query-specific preprocessing adapts your approach based on the nature of the question. </span><span class="koboSpan" id="kobo.1187.2">Statistical queries can often be pre-aggregated before sending to the agent. </span><span class="koboSpan" id="kobo.1187.3">For correlation questions, calculating and providing the correlation matrix upfront helps the LLM focus on interpretation rather than computation. </span><span class="koboSpan" id="kobo.1187.4">For exploratory questions, providing dataset metadata and samples may be</span><a id="_idIndexMarker654"/><span class="koboSpan" id="kobo.1188.1"> sufficient. </span><span class="koboSpan" id="kobo.1188.2">This targeted preprocessing makes efficient use of context wind</span><a id="_idTextAnchor380"/><span class="koboSpan" id="kobo.1189.1">ows by including only relevant information for each specific query type.</span></p>
<h3 class="heading-3" id="_idParaDest-194"><a id="_idTextAnchor381"/><span class="koboSpan" id="kobo.1190.1">Asking questions about the dataset</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1191.1">Now that we’ve set up</span><a id="_idIndexMarker655"/><span class="koboSpan" id="kobo.1192.1"> our data analysis agent, let’s explore its capabilities by asking progressively complex questions about our dataset. </span><span class="koboSpan" id="kobo.1192.2">A well-designed agent should be able to handle different types of analytical tasks, from basic exploration to statistical analysis and visualization. </span><span class="koboSpan" id="kobo.1192.3">The following examples demonstrate how our agent can work with the classic Iris dataset, which contains measurements of flower characteristics.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1193.1">We’ll test our agent with three types of queries that represent common data analysis workflows: understanding the data structure, performing statistical calculations, and creating visualizations. </span><span class="koboSpan" id="kobo.1193.2">These examples showcase the agent’s ability to reason through problems, execute appropriate code, and provide useful answers.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1194.1">First, let’s ask a fun</span><a id="_idTextAnchor382"/><span class="koboSpan" id="kobo.1195.1">damental exploratory question to understand what data we’re working with:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1196.1">agent.run(prompt.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1197.1">format</span></span><span class="koboSpan" id="kobo.1198.1">(query=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1199.1">"What's this dataset about?"</span></span><span class="koboSpan" id="kobo.1200.1">))</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1201.1">The agent executes this request by examining the dataset structure:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1202.1">Output:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1203.1">&gt; Entering new AgentExecutor chain...</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1204.1">Thought: I need to understand the structure and contents of the dataset.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1205.1">Action: python_repl_ast</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1206.1">Action Input: print(df.head())</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1207.1">   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</span></p>
<p class="snippet-con"><a id="_idTextAnchor383"/><span class="koboSpan" id="kobo.1208.1">0                5.1               3.5                1.4               0.2</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1209.1">1                4.9               3.0                1.4               0.2</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1210.1">2                4.7               3.2                1.3               0.2</span></p>
<div aria-label="304" epub:type="pagebreak" id="page38-5" role="doc-pagebreak"/>
<p class="snippet-con"><span class="koboSpan" id="kobo.1211.1">3                4.6               3.1                1.5               0.2</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1212.1">4                5.0               3.6                1.4               0.2</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1213.1"> This dataset contains four features (sepal length, sepal width, petal length, and petal width) and 150 entries.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1214.1">Final Answer: Based on the observation, this dataset is likely about measurements of flower characteristics. </span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1215.1">&gt; Finished chain.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1216.1">'Based on the observation, this dataset is likely about measurements of flower characteristics.'</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1217.1">This initial query </span><a id="_idIndexMarker656"/><span class="koboSpan" id="kobo.1218.1">demonstrates how the agent can perform basic data exploration by checking the structure and first few rows of the dataset. </span><span class="koboSpan" id="kobo.1218.2">Notice how it correctly identifies that the data contains flower measurements, even without explicit species labels in the preview. </span><span class="koboSpan" id="kobo.1218.3">Next, let’s chal</span><a id="_idTextAnchor384"/><span class="koboSpan" id="kobo.1219.1">lenge our agent with a more analytical question that requires computation:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1220.1">agent.run(prompt.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1221.1">format</span></span><span class="koboSpan" id="kobo.1222.1">(query=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1223.1">"Which row has the biggest difference between petal length and petal width?"</span></span><span class="koboSpan" id="kobo.1224.1">))</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1225.1">The agent tackles this by creating a new calculated column and finding its maximum value:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1226.1">&gt; Entering new AgentExecutor chain...</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1227.1">Thought: First, we need to find the difference between petal length and petal width for each row. </span><span class="koboSpan" id="kobo.1227.2">Then, we need to find the row with the maximum difference.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1228.1">Action: python_repl_ast</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1229.1">Action Input: df['petal_diff'] = df['petal length (cm)'] - df['petal width (cm)']</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1230.1">              df['petal_diff'].max()</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1231.1">Observation: 4.7</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1232.1">Action: python_repl_ast</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1233.1">Action Input: df['petal_diff'].idxmax()</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1234.1">Observation: 122</span></p>
<div aria-label="305" epub:type="pagebreak" id="page39-5" role="doc-pagebreak"/>
<p class="snippet-con"><span class="koboSpan" id="kobo.1235.1">Final Answer: Row 122 has the biggest difference between petal length and petal width.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1236.1">&gt; Finished chain.</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1237.1">'Row 122 has the biggest difference between petal length and petal width.'</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1238.1">This example shows how our agent can perform more complex analysis by:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1239.1">Creating derived metrics (the difference between two columns)</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1240.1">Finding the maximum value of this metric</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1241.1">Identifying which row contains this value</span></li>
</ul>
<p class="normal"><a id="_idTextAnchor385"/><span class="koboSpan" id="kobo.1242.1">Finally, let’s see how our agent handles a request for data visualization:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1243.1">agent.run(prompt.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1244.1">format</span></span><span class="koboSpan" id="kobo.1245.1">(query=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1246.1">"Show the distributions for each column visually!"</span></span><span class="koboSpan" id="kobo.1247.1">))</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1248.1">For this visualization</span><a id="_idIndexMarker657"/><span class="koboSpan" id="kobo.1249.1"> query, the agent generates code to create appropriate plots for each measurement column. </span><span class="koboSpan" id="kobo.1249.2">The agent decides to use histograms to show the distribution of each feature in the dataset, providing visual insights that complement the numerical analyses from previous queries. </span><span class="koboSpan" id="kobo.1249.3">This demonstrates how our agent can generate code for creating informative data visualizations that help understand the dataset’s characteristics.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1250.1">These three examples showcase the versatility of our data analysis agent in handling different types of analytical tasks. </span><span class="koboSpan" id="kobo.1250.2">By progressively increasing the complexity of our queries—from basic exploration to statistical analysis and visualization—we can see how the agent uses its tools effectively to provide meaningful insights about the data.</span></p>
<div>
<div class="packt_tip" id="_idContainer097">
<p class="normal"><span class="koboSpan" id="kobo.1251.1">When designing your own data analysis agents, consider providing them with a variety of analysis tools that cover the full spectrum of data science workflows: exploration, preprocessing, analysis, visualization, and interpretation.</span></p>
</div>
</div>
<div aria-label="306" epub:type="pagebreak" id="page40-4" role="doc-pagebreak"/>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1252.1"><img alt="" src="../Images/B32363_07_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1253.1">Figure 7.2: Our LLM agent visualizing the well-known Iris dataset</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1254.1">In the repository, you </span><a id="_idIndexMarker658"/><span class="koboSpan" id="kobo.1255.1">can see a UI that wraps a data science agent. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.1256.1">Data science agents represent a powerful application of LangChain’s capabilities. </span><span class="koboSpan" id="kobo.1256.2">These agents can:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1257.1">Generate and execute Python code for data analysis and machine learning</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1258.1">Build and train models based on simple natural language instructions</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1259.1">Answer complex questions about datasets through analysis and visualization</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1260.1">Automate repetitive data science tasks</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1261.1">While these agents </span><a id="_idIndexMarker659"/><span class="koboSpan" id="kobo.1262.1">aren’t yet ready to replace human data scientists, they can significantly accelerate workflows by handling routi</span><a id="_idTextAnchor386"/><span class="koboSpan" id="kobo.1263.1">ne tasks and providing quick insights from data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1264.1">Let’s conclude the chapter!</span></p>
<h1 class="heading-1" id="_idParaDest-195"><a id="_idTextAnchor387"/><span class="koboSpan" id="kobo.1265.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1266.1">This chapter has examined how LLMs are reshaping software development and data analysis practices through natural language interfaces. </span><span class="koboSpan" id="kobo.1266.2">We traced the evolution from early code generation models to today’s sophisticated systems, analyzing benchmarks that reveal both capabilities and limitations. </span><span class="koboSpan" id="kobo.1266.3">Independent research suggests that while 55% productivity gains in controlled settings don’t fully translate to production environments, meaningful improvements of 4-22% are still being realized, particularly when human expertise guides LLM implementation.</span></p>
<div aria-label="307" epub:type="pagebreak" id="page41-4" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1267.1">Our practical demonstrations illustrated diverse approaches to LLM integration through LangChain. </span><span class="koboSpan" id="kobo.1267.2">We used multiple models to generate code solutions, built RAG systems to augment LLMs with documentation and repository knowledge, and created agents capable of training neural networks and analyzing datasets with minimal human intervention. </span><span class="koboSpan" id="kobo.1267.3">Throughout these implementations, we looked at critical security considerations, providing validation frameworks and risk mitigation strategies essential for production deployments. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.1268.1">Having explored the capabilities and integration strategies for LLMs in software and data workflows, we now turn our attention to ensuring these solutions work reliably in production. </span><span class="koboSpan" id="kobo.1268.2">In </span><a href="E_Chapter_8.xhtml#_idTextAnchor390"><em class="italic"><span class="koboSpan" id="kobo.1269.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.1270.1">, we’ll delve into evaluation and testing methodologies that help validate AI-generated code and safeguard system perf</span><a id="_idTextAnchor388"/><span class="koboSpan" id="kobo.1271.1">ormance, setting the stage for building truly production-ready applications.</span></p>
<h1 class="heading-1" id="_idParaDest-196"><a id="_idTextAnchor389"/><span class="koboSpan" id="kobo.1272.1">Questions</span></h1>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1273.1">What is vibe coding, and how does it change the traditional approach to writing and maintaining code?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1274.1">What key differences exist between traditional low-code platforms and LLM-based development approaches?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1275.1">How do independent research findings on productivity gains from AI coding assistants differ from vendor claims, and what factors might explain this discrepancy?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1276.1">What specific benchmark metrics show that LLMs struggle more with class-level code generation compared to function-level tasks, and why is this distinction important for practical implementations?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1277.1">Describe the validation framework presented in the chapter for LLM-generated code. </span><span class="koboSpan" id="kobo.1277.2">What are the six key areas of assessment, and why is each important for production systems?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1278.1">Using the repository RAG example from the chapter, explain how you would modify the implementation to better handle large codebases with thousands of files.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1279.1">What patterns emerged in the dataset analysis examples that demonstrate how LLMs perform in structured data analysis tasks versus unstructured text processing?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1280.1">How does the agentic approach to data science, as demonstrated in the neural network training example, differ from traditional programming workflows? </span><span class="koboSpan" id="kobo.1280.2">What advantages and limitations did this approach reveal?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1281.1">How do LLM integrations in LangChain enable more effective software development and data analysis?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1282.1">What critical factors should organizations consider when implementing LLM-based development or analysis tools?</span></li>
</ol>
</div>
<div aria-label="308" epub:type="pagebreak" id="page42-3" role="doc-pagebreak"/>
</body></html>