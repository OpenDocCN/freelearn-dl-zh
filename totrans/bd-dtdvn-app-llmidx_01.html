<html><head></head><body><html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   LlamaIndex: The Hidden Jewel - An Introduction to the LlamaIndex Ecosystem&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-25">&#13;
    LlamaIndex: The Hidden Jewel - An Introduction to the LlamaIndex Ecosystem&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    <html:p>&#13;
     Now that&#13;
     <html:a id="_idIndexMarker033">&#13;
     </html:a>&#13;
     you’ve got a solid understanding of what&#13;
     <html:strong class="bold">&#13;
      large language models&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      LLMs&#13;
     </html:strong>&#13;
     ) are and what they can (and cannot) do. It’s time to discover how&#13;
     <html:strong class="bold">&#13;
      LlamaIndex&#13;
     </html:strong>&#13;
     can take&#13;
     <html:a id="_idIndexMarker034">&#13;
     </html:a>&#13;
     your interactive AI applications to the&#13;
     <html:a id="_idIndexMarker035">&#13;
     </html:a>&#13;
     next level. We’ll explore how&#13;
     <html:strong class="bold">&#13;
      retrieval-augmented generation&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      RAG&#13;
     </html:strong>&#13;
     ) using LlamaIndex can provide the missing link between the vast knowledge of LLMs and your&#13;
     <html:span class="No-Break">&#13;
      proprietary data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this chapter, we will cover the following&#13;
     <html:span class="No-Break">&#13;
      main topics:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Optimizing language models – The symbiosis of fine-tuning, RAG,&#13;
      <html:span class="No-Break">&#13;
       and LlamaIndex&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Discovering&#13;
      <html:a id="_idIndexMarker036">&#13;
      </html:a>&#13;
      the advantages of progressively&#13;
      <html:span class="No-Break">&#13;
       disclosing complexity&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Introducing&#13;
      <html:strong class="bold">&#13;
       personalized intelligent tutoring system&#13;
      </html:strong>&#13;
      (&#13;
      <html:strong class="bold">&#13;
       PITS&#13;
      </html:strong>&#13;
      ) – our hands-on&#13;
      <html:span class="No-Break">&#13;
       LlamaIndex project&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Preparing our&#13;
      <html:span class="No-Break">&#13;
       coding environment&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Familiarizing ourselves with the structure of the LlamaIndex&#13;
      <html:span class="No-Break">&#13;
       code repository&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:a id="_idTextAnchor025">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Technical requirements&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-26">&#13;
    Technical requirements&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    <html:p>&#13;
     The following elements will be required for&#13;
     <html:span class="No-Break">&#13;
      this chapter:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Python&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        3.11&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       (&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://www.python.org/&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       )&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Git&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       (&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://git-scm.com/&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       )&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        LlamaIndex&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       (&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://github.com/run-llama/llama_index&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       )&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       OpenAI account&#13;
      </html:em>&#13;
      and an&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        API key&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Streamlit&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       (&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://github.com/streamlit/streamlit&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       )&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        PyPDF&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       (&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://pypi.org/project/pypdf/&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       )&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        DOC2Txt&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       (&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://github.com/ankushshah89/python-docx2txt/blob/master/docx2txt/docx2txt.py&#13;
       </html:span>&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       )&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     All the sample code snippets presented throughout this book as well as the entire project code base can be found in this GitHub&#13;
     <html:span class="No-Break">&#13;
      repository:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor026">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Optimizing language models – the symbiosis of &#13;
fine-tuning, RAG, and LlamaIndex&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-27">&#13;
    Optimizing language models – the symbiosis of &#13;
fine-tuning, RAG, and LlamaIndex&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    <html:p>&#13;
     In the previous chapter, we saw that vanilla LLMs have some limitations right outside of the box. Their&#13;
     <html:a id="_idIndexMarker037">&#13;
     </html:a>&#13;
     knowledge is static and they occasionally spit out nonsense. We also learned about RAG as a potential way to mitigate&#13;
     <html:a id="_idIndexMarker038">&#13;
     </html:a>&#13;
     these issues. Blending&#13;
     <html:strong class="bold">&#13;
      prompt engineering&#13;
     </html:strong>&#13;
     techniques with programmatic methods, RAG can elegantly solve many of the&#13;
     <html:span class="No-Break">&#13;
      LLM shortcomings.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     What is prompt engineering?&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Prompt&#13;
     <html:a id="_idIndexMarker039">&#13;
     </html:a>&#13;
     engineering involves crafting text inputs designed to be effectively processed by a&#13;
     <html:strong class="bold">&#13;
      generative AI&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      GenAI&#13;
     </html:strong>&#13;
     ) model. Composed in natural language, these prompts describe the specific tasks to be carried out by the AI. We’ll have a much deeper conversation on this topic during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 10&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Prompt Engineering Guidelines and&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Best Practices&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor027">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-28">&#13;
     Is RAG the only possible solution?&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Of course not. Another approach is to fine-tune the AI model, which involves additional training on&#13;
     <html:a id="_idIndexMarker040">&#13;
     </html:a>&#13;
     proprietary data to adapt the LLM and embed new data. It takes a model that is pre-trained on a general collection of data and continues its training on a more specialized dataset. This specialized dataset can be tailored to a particular domain, language, or set of tasks that you are interested in. The result is a model that maintains its broad knowledge base while gaining expertise in a&#13;
     <html:span class="No-Break">&#13;
      specific area.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Take a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 2&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .1&#13;
     </html:em>&#13;
     for a graphical explanation of&#13;
     <html:span class="No-Break">&#13;
      the process.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer017">&#13;
      <html:img src="img/B21861_02_1.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 2.1 – An illustration of the LLM fine-tuning process&#13;
    </html:p>&#13;
    <html:p>&#13;
     Fine-tuning can improve performance but has drawbacks, such as being expensive, requiring large datasets, and being difficult to update with fresh information. It also has the disadvantage of permanently altering the original AI model, which makes it inappropriate for personalizing purposes. Think of the original AI model as a classic recipe for a beloved dish. Fine-tuning this model is akin to modifying the traditional recipe to suit specific tastes or requirements. While these changes can make the dish more suitable for some, they also fundamentally alter the&#13;
     <html:span class="No-Break">&#13;
      original recipe.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Not all&#13;
     <html:a id="_idIndexMarker041">&#13;
     </html:a>&#13;
     fine-tuning methods permanently alter the base AI model. Take&#13;
     <html:strong class="bold">&#13;
      Low-Rank Adaptation&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      LoRA&#13;
     </html:strong>&#13;
     ) for example. LoRA is a fine-tuning method for LLMs that offers a more efficient approach compared to traditional&#13;
     <html:strong class="bold">&#13;
      full fine-tuning&#13;
     </html:strong>&#13;
     . In full fine-tuning, all&#13;
     <html:a id="_idIndexMarker042">&#13;
     </html:a>&#13;
     layers of a neural network are optimized, which, while effective, is resource-intensive and time-consuming. LoRA, on the other hand, involves fine-tuning only two smaller matrices that approximate the larger weight matrix of the pre-trained LLM. In the LoRA method, the original weights of the model are&#13;
     <html:em class="italic">&#13;
      frozen&#13;
     </html:em>&#13;
     , meaning they are not directly updated during the fine-tuning process. The changes to the model’s behavior are achieved by the addition of these low-rank matrices. This approach allows for the original model to be preserved, while still enabling it to be adapted for new tasks or improved performance. You can find more information on this method&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://ar5iv.labs.arxiv.org/html/2106.09685&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Even though LoRA is more efficient in terms of memory usage compared to full fine-tuning, it still requires computational resources and expertise to implement and optimize effectively, which might be a barrier for some users. Using fine-tuning to create a more personalized experience for a large number of different users requires re-running the tuning process for every user, which is definitely&#13;
     <html:span class="No-Break">&#13;
      not cost-effective.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     I’m not trying to say that RAG is a better alternative to LLM fine-tuning. In fact, RAG and fine-tuning are complementary techniques that are often used together. However, to rapidly incorporating changing data and personalization, RAG&#13;
     <html:span class="No-Break">&#13;
      is preferable.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor028">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-29">&#13;
     What LlamaIndex does&#13;
    </html:h2>&#13;
    <html:p>&#13;
     With LlamaIndex, you can rapidly create&#13;
     <html:em class="italic">&#13;
      smart&#13;
     </html:em>&#13;
     LLMs that can adapt to your specific use case. Instead&#13;
     <html:a id="_idIndexMarker043">&#13;
     </html:a>&#13;
     of relying only on their generic pre-trained knowledge, you can inject targeted information so that they give you accurate, relevant answers. It provides an easy way to connect external datasets to LLMs such as GPT-4, Claude, and Llama. LlamaIndex builds a bridge between your custom knowledge and the vast capabilities&#13;
     <html:span class="No-Break">&#13;
      of LLMs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Created in 2022 by Princeton University graduate and entrepreneur Jerry Liu, the&#13;
     <html:em class="italic">&#13;
      LlamaIndex framework&#13;
     </html:em>&#13;
     has quickly become very popular in the developer community. LlamaIndex allows you to take advantage of the computational power and language understanding capabilities of LLMs while focusing their responses on specific, reliable data. This unique combination enables businesses and individuals to get the most out of their AI investments, as they can use the same underlying technology for a wide array of&#13;
     <html:span class="No-Break">&#13;
      specialized applications.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For example, you could index a collection of your company’s documents. Then, when you ask questions related to your business, the LLM augmented with LlamaIndex provides responses based on real data rather than just making up&#13;
     <html:span class="No-Break">&#13;
      vague answers!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The result is that&#13;
     <html:a id="_idIndexMarker044">&#13;
     </html:a>&#13;
     you get all the expressive power of LLMs while greatly reducing the amount of incorrect or irrelevant information. LlamaIndex guides the LLM to pull from trusted sources you provide, and these sources could contain both&#13;
     <html:em class="italic">&#13;
      structured&#13;
     </html:em>&#13;
     and&#13;
     <html:em class="italic">&#13;
      unstructured&#13;
     </html:em>&#13;
     data. In fact, as we will see in the next chapters, the framework can ingest data from pretty much&#13;
     <html:em class="italic">&#13;
      any&#13;
     </html:em>&#13;
     data source available. That’s pretty&#13;
     <html:span class="No-Break">&#13;
      cool, right?&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If you are not already thinking about the many possible uses for this framework, let me give you some quick ideas. With LlamaIndex, you could do&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Build a search engine for your document collection&#13;
      </html:strong>&#13;
      : One of its most powerful applications is the ability to index all your documents – they could be PDFs, Word files, Notion documents, GitHub repos, or other formats. Once indexed, you can query the LLM to search for specific information, making it a powerful search engine tailored specifically for&#13;
      <html:span class="No-Break">&#13;
       your resources&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Create a company chatbot with customized knowledge&#13;
      </html:strong>&#13;
      : If your business has specific jargon, policies, or expertise, you can make the LLM&#13;
      <html:em class="italic">&#13;
       understand&#13;
      </html:em>&#13;
      these nuances. The chatbot could then handle a range of queries, from basic customer service questions to more specialized interactions that would typically require&#13;
      <html:span class="No-Break">&#13;
       human expertise&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Generate summaries of large reports or papers&#13;
      </html:strong>&#13;
      : If your organization deals with lengthy documents or reports, LlamaIndex can be used to feed the LLM with their contents. Then, you can ask the LLM to generate concise summaries, capturing the most&#13;
      <html:span class="No-Break">&#13;
       important points&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Develop a smart assistant for complex workflows&#13;
      </html:strong>&#13;
      : By training the LLM on the nuances of multi-step tasks or procedures unique to your organization, you can transform it into a smart assistant data agent that provides valuable insights&#13;
      <html:span class="No-Break">&#13;
       and guidance&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     And these are just the tip of&#13;
     <html:span class="No-Break">&#13;
      the iceberg.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In addition,&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 2&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .2&#13;
     </html:em>&#13;
     shows how implementing smart RAG strategies can offset some of the costs&#13;
     <html:a id="_idIndexMarker045">&#13;
     </html:a>&#13;
     associated with fine-tuning the model on a&#13;
     <html:span class="No-Break">&#13;
      specific domain.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer018">&#13;
      <html:img src="img/B21861_02_2.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 2.2 – The relative costs of updating data in a pre-trained LLM&#13;
    </html:p>&#13;
    <html:p>&#13;
     Before we dive deeper into the applications and use cases of the LlamaIndex framework, let’s talk a bit about the architecture and the design principles&#13;
     <html:span class="No-Break">&#13;
      behind it!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor029">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Discovering the advantages of progressively disclosing complexity&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-30">&#13;
    Discovering the advantages of progressively disclosing complexity&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    from llama_index.core import VectorStoreIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader('files').load_data()&#13;
index = VectorStoreIndex.from_documents(documents)&#13;
query_engine = index.as_query_engine()&#13;
response = query_engine.query(&#13;
    "summarize each document in a few sentences"&#13;
)&#13;
print(response)&#13;
    <html:p>&#13;
     The creator of LlamaIndex wanted to make it accessible to everyone – from beginners just getting&#13;
     <html:a id="_idIndexMarker046">&#13;
     </html:a>&#13;
     started with LLMs all the way to expert developers building complex systems. That’s why LlamaIndex uses a design&#13;
     <html:a id="_idIndexMarker047">&#13;
     </html:a>&#13;
     principle called&#13;
     <html:strong class="bold">&#13;
      progressive disclosure of complexity&#13;
     </html:strong>&#13;
     . Don’t worry about the fancy name – it just means that the framework starts simple and gradually reveals more advanced features when you&#13;
     <html:span class="No-Break">&#13;
      need them.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     When you first use LlamaIndex, it feels like magic! With just a few lines of code, you can connect data and start querying the LLM. Under the hood, LlamaIndex converts the data into an efficient index that the LLM&#13;
     <html:span class="No-Break">&#13;
      can use.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Have a look at this very simple example that first loads a set of text documents from a local directory. It then builds an index over the documents and queries that index to get a summarized view of the documents based on a natural&#13;
     <html:span class="No-Break">&#13;
      language query:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     It’s that&#13;
     <html:a id="_idIndexMarker048">&#13;
     </html:a>&#13;
     simple. Just six lines&#13;
     <html:span class="No-Break">&#13;
      of code!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Don’t try to run the code just yet. It’s more for illustration purposes. There is a bit of environmental preparation we need to handle before that. Don’t worry, we’ll cover that a bit later in this chapter and then you’ll be ready&#13;
     <html:span class="No-Break">&#13;
      to go.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As you use LlamaIndex more, you will uncover its more powerful capabilities. There are plenty of parameters you can tweak. You can select specialized index structures optimized for different uses, carry out detailed cost analyses for different prompt strategies, customize query algorithms, and&#13;
     <html:span class="No-Break">&#13;
      much more.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     But LlamaIndex always starts you off gently before getting into more detailed workings, and for quick and simple projects, you don’t need to go much deeper than that. This way, both beginners and experts can benefit from its versatility&#13;
     <html:span class="No-Break">&#13;
      and capabilities.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Now, let’s go on a quick tour of our hands-on project and then start prepping for the fun part: writing&#13;
     <html:span class="No-Break">&#13;
      the code.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor030">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-31">&#13;
     An important aspect to consider&#13;
    </html:h2>&#13;
    <html:p>&#13;
     As you go further through this book, and you will most likely want to experiment based on the&#13;
     <html:a id="_idIndexMarker049">&#13;
     </html:a>&#13;
     examples it gives, you need to keep one very important point in mind. By default, the LlamaIndex framework is configured to use AI models provided by OpenAI. Although these models are extremely powerful and versatile, they incur costs. Many of the LlamaIndex functionalities presented in this book, be it metadata extraction, indexing, retrieval, or response synthesis, are based on either LLMs or embedding models. I have tried to use as simple examples as possible with small sample datasets in an attempt to limit these costs as much&#13;
     <html:span class="No-Break">&#13;
      as possible.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     I strongly advise you to keep a close eye on the OpenAI API consumption. In case you don’t already have it, the link where you can monitor the API usage is here:&#13;
     <html:a>&#13;
      https://platform.openai.com/usage&#13;
     </html:a>&#13;
     . I also advise you to be careful from a privacy perspective. These issues are discussed in more detail in&#13;
     <html:em class="italic">&#13;
      Chapters 4&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      and&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       5&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Alternatively, if you want to avoid both the costs of using an external LLM and the potential privacy risks, you can apply the methods described in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 9&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Customizing and Deploying Our LlamaIndex Project&#13;
     </html:em>&#13;
     . It is important to note, however, that all examples provided in the book are written and tested using the default models provided by OpenAI. There is a (quite likely) possibility that some examples may not work as well – or at all – running on locally&#13;
     <html:span class="No-Break">&#13;
      hosted alternatives.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor031">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Introducing PITS – our LlamaIndex hands-on project&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-32">&#13;
    Introducing PITS – our LlamaIndex hands-on project&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    <html:p>&#13;
     <html:em class="italic">&#13;
      Nothing beats learning&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       by doing&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     So, I’ve&#13;
     <html:a id="_idIndexMarker050">&#13;
     </html:a>&#13;
     cooked up a fun and useful project for us to start&#13;
     <html:span class="No-Break">&#13;
      using LlamaIndex!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here, we will introduce PITS. Wouldn’t it be cool to have an AI tutor that helps you learn new concepts interactively? Well, we’re going to build&#13;
     <html:span class="No-Break">&#13;
      one together!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor032">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-33">&#13;
     Here’s how it will work&#13;
    </html:h2>&#13;
    <html:p>&#13;
     First, you will introduce yourself to PITS. You’ll have the chance to describe the topic you want to learn about and specify any personal learning preferences you&#13;
     <html:span class="No-Break">&#13;
      may have.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Then, you will&#13;
     <html:a id="_idIndexMarker051">&#13;
     </html:a>&#13;
     be able to upload any existing study materials you may have on the topic. PITS will accept and ingest any PDFs, Word documents, or text files you&#13;
     <html:span class="No-Break">&#13;
      may provide.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Based on the documents provided, the tutor will first build a quiz. You’ll have the option to complete the quiz. That way, the tutor will be able to gauge your current knowledge of the topic and adjust the&#13;
     <html:span class="No-Break">&#13;
      learning experience.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Our nifty tutor will then build learning material for you. This will consist of slides and narration for each slide. The training material will be divided&#13;
     <html:span class="No-Break">&#13;
      into chapters.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Then, your learning journey begins. During each learning session, PITS you will advance through the chapters, presenting each topic in your preferred style and adapting to your&#13;
     <html:span class="No-Break">&#13;
      knowledge level.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     After each concept is explained, you’ll have a chance to ask for more explanations or examples to learn more about the topic. It will answer your questions, create quizzes, explain concepts, and adapt responses based on&#13;
     <html:span class="No-Break">&#13;
      your needs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The best part is that your entire conversation with the agent will be recorded. It will remember both your questions and its own answers so it won’t repeat itself or lose the&#13;
     <html:span class="No-Break">&#13;
      conversation context.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Too tired to continue in one session? Not a problem. When you’re ready to start another lesson, it will just resume from where you left off and give you a summary of the&#13;
     <html:span class="No-Break">&#13;
      previous discussion.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     But, hey! They say a picture’s worth a thousand&#13;
     <html:span class="No-Break">&#13;
      words, right?&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You’ll find an overview in&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 2&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       .3&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer019">&#13;
      <html:img src="img/B21861_02_3.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 2.3 – An overview of the PITS workflow&#13;
    </html:p>&#13;
    <html:p>&#13;
     It doesn’t&#13;
     <html:a id="_idIndexMarker052">&#13;
     </html:a>&#13;
     really get more customized than this. This is the ultimate&#13;
     <html:span class="No-Break">&#13;
      learning experience.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As you can imagine, PITS needs to be smart on several fronts. It needs to be able to do&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Understand and index the study materials&#13;
      <html:span class="No-Break">&#13;
       we provide&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Converse fluently with users and retain&#13;
      <html:span class="No-Break">&#13;
       the context&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Teach effectively based on the&#13;
      <html:span class="No-Break">&#13;
       indexed knowledge&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     LlamaIndex will help with the first part by ingesting the study material. The user will be able to upload any relevant training material such as manuals, slides or even student notes, and&#13;
     <html:span class="No-Break">&#13;
      sample questions.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For the second part, we’ll mostly use the capabilities of GPT-4 to power the actual&#13;
     <html:span class="No-Break">&#13;
      teaching interactions.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     However, the foundation will be the knowledge augmentation capabilities of LlamaIndex. Pretty neat, right? We’ll have a personally&#13;
     <html:span class="No-Break">&#13;
      customized tutor!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     I’m not sure whether you’ve read my biography, but I work as a trainer. The moment I first learned of the power of GenAI and discovered GPT-3, I knew exactly that a few years&#13;
     <html:a id="_idIndexMarker053">&#13;
     </html:a>&#13;
     from now, systems such as PITS would emerge sooner or later. I was thrilled about their potential to provide free, quality education to people around the world, regardless of their location, background, or financial status. Later, when I discovered RAG and tools such as LlamaIndex, I became convinced that they would appear rather sooner&#13;
     <html:span class="No-Break">&#13;
      than later.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Okay, enough daydreaming – let’s start setting up&#13;
     <html:span class="No-Break">&#13;
      the pieces.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor033">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Preparing our coding environment&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-34">&#13;
    Preparing our coding environment&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    pip install llama-index&#13;
    pip install streamlit&#13;
    pip install pypdf&#13;
pip install docx2txt&#13;
    python --version&#13;
git --version&#13;
pip show llama-index&#13;
echo %OPENAI_API_KEY%&#13;
pip show streamlit&#13;
pip show pypdf&#13;
pip show docx2txt&#13;
    python sample1.py&#13;
    <html:p>&#13;
     Before we embark on the LlamaIndex coding journey, it’s essential to set up our development&#13;
     <html:a id="_idIndexMarker054">&#13;
     </html:a>&#13;
     environment properly. This setup is the first step toward ensuring that we can smoothly run through the examples and exercises I’ve prepared&#13;
     <html:span class="No-Break">&#13;
      for you.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     To maintain simplicity and ensure consistency across all examples, I’ve designed the sample code to be run in a local Python environment. I’m aware that many of you are fond of using web-based coding environments such as Google Colab and Jupyter Notebooks for your coding projects, so I kindly ask for your understanding if these examples do not directly translate to or run in these platforms. My goal was to keep our setup straightforward, allowing us to focus on the learning experience without compatibility concerns. Thank you for your understanding and&#13;
     <html:span class="No-Break">&#13;
      happy coding!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s quickly get our computer set up for some cool&#13;
     <html:span class="No-Break">&#13;
      LlamaIndex coding.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor034">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-35">&#13;
     Installing Python&#13;
    </html:h2>&#13;
    <html:p>&#13;
     You’ll need a Python 3.7+ environment. I recommend Python 3.11&#13;
     <html:span class="No-Break">&#13;
      if possible.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If you don’t&#13;
     <html:a id="_idIndexMarker055">&#13;
     </html:a>&#13;
     have Python, install it from&#13;
     <html:a>&#13;
      https://www.python.org&#13;
     </html:a>&#13;
     . If you already have an older version, you can upgrade or install a newer Python version side&#13;
     <html:span class="No-Break">&#13;
      by side.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For a coding&#13;
     <html:a id="_idIndexMarker056">&#13;
     </html:a>&#13;
     environment, my personal preference is&#13;
     <html:strong class="bold">&#13;
      NotePad++&#13;
     </html:strong>&#13;
     (&#13;
     <html:a>&#13;
      https://notepad-plus-plus.org/&#13;
     </html:a>&#13;
     ), which is not quite an IDE but is very fast. However, you can&#13;
     <html:a id="_idIndexMarker057">&#13;
     </html:a>&#13;
     also use Microsoft’s&#13;
     <html:strong class="bold">&#13;
      VSCode&#13;
     </html:strong>&#13;
     (&#13;
     <html:a>&#13;
      https://code.visualstudio.com/&#13;
     </html:a>&#13;
     ),&#13;
     <html:strong class="bold">&#13;
      PyCharm&#13;
     </html:strong>&#13;
     (&#13;
     <html:a>&#13;
      https://www.jetbrains.com/pycharm/&#13;
     </html:a>&#13;
     ), or&#13;
     <html:a id="_idIndexMarker058">&#13;
     </html:a>&#13;
     anything else&#13;
     <html:span class="No-Break">&#13;
      you prefer.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor035">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-36">&#13;
     Installing Git&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Before we proceed, it’s important to have Git installed. Git is a version control system that lets you&#13;
     <html:a id="_idIndexMarker059">&#13;
     </html:a>&#13;
     manage changes to your code and collaborate with others. It’s&#13;
     <html:a id="_idIndexMarker060">&#13;
     </html:a>&#13;
     also essential for cloning code repositories, like the one we’ll be using in&#13;
     <html:span class="No-Break">&#13;
      this book.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Head over&#13;
     <html:a id="_idIndexMarker061">&#13;
     </html:a>&#13;
     to the official Git website (&#13;
     <html:a>&#13;
      https://git-scm.com/book/en/v2/Getting-Started-Installing-Git&#13;
     </html:a>&#13;
     ) and download the installer for your&#13;
     <html:span class="No-Break">&#13;
      operating system.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Follow the installation steps, and you should have Git up and running in&#13;
     <html:span class="No-Break">&#13;
      no time.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     All the sample code snippets presented throughout the book as well as the entire project code base can be found in this GitHub&#13;
     <html:span class="No-Break">&#13;
      repository:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     So, if you want to download the project files locally, once you have finished installing Git, you can simply follow&#13;
     <html:span class="No-Break">&#13;
      these steps:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      &#13;
     <html:strong class="bold">&#13;
       Navigate to the desired directory&#13;
      </html:strong>&#13;
      : Open a new command prompt or terminal window. Use the&#13;
      <html:code class="literal">&#13;
       cd&#13;
      </html:code>&#13;
      command to navigate to the directory where you’d like to store the project. Here is&#13;
      <html:span class="No-Break">&#13;
       an example:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      &#13;
      <html:strong class="bold">&#13;
       Clone the repository&#13;
      </html:strong>&#13;
      : Run the following command to clone the&#13;
      <html:span class="No-Break">&#13;
       GitHub repository:&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       This will download a copy of the project to your&#13;
       <html:span class="No-Break">&#13;
        local machine.&#13;
       </html:span>&#13;
      </html:p>&#13;
     </html:li>&#13;
     <html:li>&#13;
      &#13;
      <html:strong class="bold">&#13;
       Enter the project directory&#13;
      </html:strong>&#13;
      : Navigate into the newly created&#13;
      <html:span class="No-Break">&#13;
       project folder:&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       As we move forward with our project, you have&#13;
       <html:span class="No-Break">&#13;
        two options:&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:ul>&#13;
       <html:li>&#13;
        You can either write the code on your own and then compare it with what’s in&#13;
        <html:span class="No-Break">&#13;
         the repository&#13;
        </html:span>&#13;
       </html:li>&#13;
       <html:li>&#13;
        Or you can directly explore the code files in the repository to get a better understanding of the&#13;
        <html:span class="No-Break">&#13;
         code structure&#13;
        </html:span>&#13;
       </html:li>&#13;
      </html:ul>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     If you&#13;
     <html:a id="_idIndexMarker062">&#13;
     </html:a>&#13;
     correctly performed all of the preceding steps, listing the&#13;
     <html:a id="_idIndexMarker063">&#13;
     </html:a>&#13;
     contents of the current folder should return several subfolders called&#13;
     <html:code class="literal">&#13;
      chX&#13;
     </html:code>&#13;
     – where&#13;
     <html:code class="literal">&#13;
      X&#13;
     </html:code>&#13;
     is the chapter number, and a separate subfolder called&#13;
     <html:code class="literal">&#13;
      PITS_APP&#13;
     </html:code>&#13;
     . The chapter folders contain all sample source files corresponding to each chapter. The&#13;
     <html:code class="literal">&#13;
      PITS_APP&#13;
     </html:code>&#13;
     folder contains the source code for our&#13;
     <html:span class="No-Break">&#13;
      main project.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor036">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-37">&#13;
     Installing LlamaIndex&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Next, let’s&#13;
     <html:a id="_idIndexMarker064">&#13;
     </html:a>&#13;
     get the LlamaIndex library installed. At your command&#13;
     <html:a id="_idIndexMarker065">&#13;
     </html:a>&#13;
     prompt, run&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This will include a LlamaIndex package that contains the core LlamaIndex components as well as a selection of useful integrations. For the most efficient deployment possible, there is also the option of installing just the minimum core components and only the necessary integrations, but for the purpose of this book, the presented option will do&#13;
     <html:span class="No-Break">&#13;
      just fine.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     In case you’re already running a version older than v0.10, it is recommended that you start with&#13;
     <html:a id="_idIndexMarker066">&#13;
     </html:a>&#13;
     a fresh install in a virtual environment to avoid any&#13;
     <html:a id="_idIndexMarker067">&#13;
     </html:a>&#13;
     conflicts with the legacy version. You can find detailed instructions&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://pretty-sodium-5e0.notion.site/v0-10-0-Migration-Guide-6ede431dcb8841b09ea171e7f133bd77&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’re now ready to import and start&#13;
     <html:span class="No-Break">&#13;
      using it.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor037">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-38">&#13;
     Signing up for an OpenAI API key&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Since we’ll&#13;
     <html:a id="_idIndexMarker068">&#13;
     </html:a>&#13;
     be using OpenAI’s GPT models&#13;
     <html:a id="_idIndexMarker069">&#13;
     </html:a>&#13;
     via LlamaIndex, you’ll need an API key to authenticate. Head to&#13;
     <html:a>&#13;
      https://platform.openai.com&#13;
     </html:a>&#13;
     and sign up. Once logged in, you can create&#13;
     <html:a id="_idIndexMarker070">&#13;
     </html:a>&#13;
     a new secret API key. Make sure to keep&#13;
     <html:span class="No-Break">&#13;
      it safe!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     LlamaIndex will use this key every time it interacts with OpenAI’s models. Because it has to be kept secret, it’s a good idea to store it in an environment variable on your&#13;
     <html:span class="No-Break">&#13;
      local machine.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A short guide for Windows users&#13;
    </html:h3>&#13;
    <html:p>&#13;
     On&#13;
     <html:a id="_idIndexMarker071">&#13;
     </html:a>&#13;
     Windows, you can accomplish that by following&#13;
     <html:span class="No-Break">&#13;
      these steps:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      Open&#13;
      <html:strong class="bold">&#13;
       Environment Variables&#13;
      </html:strong>&#13;
      : Open the Start menu and search for&#13;
      <html:strong class="bold">&#13;
       Environment Variables&#13;
      </html:strong>&#13;
      or right-click on&#13;
      <html:strong class="bold">&#13;
       This PC&#13;
      </html:strong>&#13;
      or&#13;
      <html:strong class="bold">&#13;
       My Computer&#13;
      </html:strong>&#13;
      and&#13;
      <html:span class="No-Break">&#13;
       select&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        Properties&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Then, click on&#13;
      <html:strong class="bold">&#13;
       Advanced system settings&#13;
      </html:strong>&#13;
      followed by the&#13;
      <html:strong class="bold">&#13;
       Environment Variables&#13;
      </html:strong>&#13;
      button in the&#13;
      <html:strong class="bold">&#13;
       Advanced&#13;
      </html:strong>&#13;
      tab as shown in&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Figure 2&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        .4:&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer020">&#13;
      <html:img src="img/B21861_02_4.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 2.4 – Editing Windows environment variables&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Create a new environment variable&#13;
      </html:strong>&#13;
      : In the&#13;
      <html:strong class="bold">&#13;
       Environment Variables&#13;
      </html:strong>&#13;
      window, under&#13;
      <html:a id="_idIndexMarker072">&#13;
      </html:a>&#13;
      the&#13;
      <html:strong class="bold">&#13;
       User variables&#13;
      </html:strong>&#13;
      section, click the&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        New&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       button.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Enter the variable details&#13;
      </html:strong>&#13;
      : For the&#13;
      <html:strong class="bold">&#13;
       Variable name&#13;
      </html:strong>&#13;
      , enter&#13;
      <html:code class="literal">&#13;
       OPENAI_API_KEY&#13;
      </html:code>&#13;
      . For&#13;
      <html:strong class="bold">&#13;
       Variable value&#13;
      </html:strong>&#13;
      , paste the secret API key you received from OpenAI. See&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Figure 2&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:em class="italic">&#13;
       .5&#13;
      </html:em>&#13;
      for&#13;
      <html:span class="No-Break">&#13;
       an illustration.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer021">&#13;
      <html:img src="img/B21861_02_5.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 2.5 – Creating the OPENAI_API_KEY environment variable&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Confirm and apply&#13;
      </html:strong>&#13;
      : Click&#13;
      <html:strong class="bold">&#13;
       OK&#13;
      </html:strong>&#13;
      to close all of the dialog boxes. You will need to restart&#13;
      <html:a id="_idIndexMarker073">&#13;
      </html:a>&#13;
      your computer for the changes to&#13;
      <html:span class="No-Break">&#13;
       take effect.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      &#13;
     <html:strong class="bold">&#13;
       Verify the environment variable&#13;
      </html:strong>&#13;
      : To ensure the variable is set correctly, open a new command prompt, and run&#13;
      <html:span class="No-Break">&#13;
       the following:&#13;
      </html:span>&#13;
      </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     This should display the API key you&#13;
     <html:span class="No-Break">&#13;
      just stored.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     A short guide for Linux/Mac users&#13;
    </html:h3>&#13;
    <html:p>&#13;
     On Linux/Mac, you can accomplish Signing up for an OpenAI API key by following&#13;
     <html:span class="No-Break">&#13;
      these steps:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      Run the following command in your terminal, replacing&#13;
      &#13;
     <html:code class="literal">&#13;
       &lt;yourkey&gt;&#13;
      </html:code>&#13;
      with your&#13;
      <html:span class="No-Break">&#13;
       API key:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      Update&#13;
      &#13;
     <html:a id="_idIndexMarker074">&#13;
      </html:a>&#13;
      the shell with the&#13;
      <html:span class="No-Break">&#13;
       new variable:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      Make sure&#13;
      &#13;
      <html:a id="_idIndexMarker075">&#13;
      </html:a>&#13;
      that you have set your environment variable with the&#13;
      <html:span class="No-Break">&#13;
       following command:&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       Your OpenAI API key is now securely stored in an environment variable and can be easily accessed by LlamaIndex when needed, without exposing it in your code&#13;
       <html:span class="No-Break">&#13;
        or system.&#13;
       </html:span>&#13;
      </html:p>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     While OpenAI provides a free trial option for their GPT models through their API, you’ll only receive a limited number of free credits. Currently, the free credit is limited to $5 and expires after 3 months. That should be more than enough to experiment for the purpose of our project and for reading the book. However, If you wish to get serious about building LLM-based applications, you’ll have to sign up for a paid account on their platform. Alternatively, you can always choose to use another AI model for LlamaIndex. We will discuss customizing the AI model in more detail in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 10&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:em class="italic">&#13;
      , Prompt Engineering Guidelines and&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Best Practices&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     OK. The backend is all set up. Let’s talk about the rest of&#13;
     <html:span class="No-Break">&#13;
      the stack.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor038">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-39">&#13;
     Discovering Streamlit – the perfect tool for rapid building and deployment!&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Before we&#13;
     <html:a id="_idIndexMarker076">&#13;
     </html:a>&#13;
     can build cool apps such as PITS, we need&#13;
     <html:a id="_idIndexMarker077">&#13;
     </html:a>&#13;
     somewhere to … well, build and run them! That’s where Streamlit comes in. Streamlit is an awesome open-source Python library that makes it super easy to create and deploy web apps&#13;
     <html:span class="No-Break">&#13;
      and dashboards.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     With just a few lines of Python code, you can build complete web interfaces and see the results instantly. The best part is that Streamlit apps can be deployed nearly anywhere – on servers, on platforms such as Heroku, or even directly&#13;
     <html:span class="No-Break">&#13;
      from GitHub!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     I love Streamlit because it lets me focus on the fun stuff – such as creating PITS with LlamaIndex – rather than fussing over complex web development. For AI experimentation,&#13;
     <html:span class="No-Break">&#13;
      it’s perfect!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’ll primarily&#13;
     <html:a id="_idIndexMarker078">&#13;
     </html:a>&#13;
     use it to create the interface for uploading study guides and interacting with our PITS tutor. For the purpose of the next chapters, we’ll be using Streamlit&#13;
     <html:a id="_idIndexMarker079">&#13;
     </html:a>&#13;
     for running and testing our app locally. However, in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 9&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Customizing and Deploying Our LlamaIndex Project&#13;
     </html:em>&#13;
     , we will also discover how we can easily deploy our app using&#13;
     <html:strong class="bold">&#13;
      Streamlit Share&#13;
     </html:strong>&#13;
     or any other hosting service&#13;
     <html:span class="No-Break">&#13;
      you prefer.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Streamlit has tons of cool capabilities such as data frames, charts, and widgets – but don’t worry about learning it all now. As we build up features, I’ll explain the relevant parts so you can gain Streamlit skills along&#13;
     <html:span class="No-Break">&#13;
      the way!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor039">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-40">&#13;
     Installing Streamlit&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Lastly, we need&#13;
     <html:a id="_idIndexMarker080">&#13;
     </html:a>&#13;
     to install the&#13;
     <html:span class="No-Break">&#13;
      Streamlit library:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Great! We&#13;
     <html:a id="_idIndexMarker081">&#13;
     </html:a>&#13;
     have our backend tool (LlamaIndex), our frontend layer (Streamlit), and our goal (PITS). It’s time for a&#13;
     <html:span class="No-Break">&#13;
      final touch.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor040">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-41">&#13;
     Finishing up&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Because our&#13;
     <html:a id="_idIndexMarker082">&#13;
     </html:a>&#13;
     project should be able to ingest PDF and DOCX documents, we will also need to install two&#13;
     <html:span class="No-Break">&#13;
      additional libraries:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     That’s it! Our environment is&#13;
     <html:span class="No-Break">&#13;
      LlamaIndex ready.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s recap what&#13;
     <html:span class="No-Break">&#13;
      we have:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       Python 3.11&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       Git&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       LlamaIndex package&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      OpenAI&#13;
      <html:a id="_idIndexMarker083">&#13;
      </html:a>&#13;
      account and an&#13;
      <html:span class="No-Break">&#13;
       API key&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Streamlit for&#13;
      <html:span class="No-Break">&#13;
       app building&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      PyPDF and&#13;
      <html:span class="No-Break">&#13;
       DOC2Txt libraries&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:a id="_idTextAnchor041">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-42">&#13;
     One final check&#13;
    </html:h2>&#13;
    <html:p>&#13;
     To verify&#13;
     <html:a id="_idIndexMarker084">&#13;
     </html:a>&#13;
     that everything was installed correctly, open a new command prompt or terminal window, and run the&#13;
     <html:span class="No-Break">&#13;
      following commands:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     A simple way to check whether your environment is ready is to try navigating into the&#13;
     <html:code class="literal">&#13;
      ch2&#13;
     </html:code>&#13;
     subfolder of your local&#13;
     <html:code class="literal">&#13;
      git&#13;
     </html:code>&#13;
     folder and run the file&#13;
     <html:span class="No-Break">&#13;
      called&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       sample1.py&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You should get a nice summary of the two sample documents provided in the&#13;
     <html:code class="literal">&#13;
      ch2/files&#13;
     </html:code>&#13;
     subfolder if everything has been&#13;
     <html:span class="No-Break">&#13;
      properly installed.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If anything is missing, please go back and retake the necessary steps before proceeding further. Trust me, you’ll avoid a lot of pain and frustration further down&#13;
     <html:span class="No-Break">&#13;
      the line.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’re all set to start ingesting data, constructing indices with LlamaIndex, and building our PITS tutor app! I don’t know about you, but I’m&#13;
     <html:em class="italic">&#13;
      kid-in-a-candy-store&#13;
     </html:em>&#13;
     excited to&#13;
     <html:span class="No-Break">&#13;
      start experimenting.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In the next chapters, we’ll get hands-on with our first LlamaIndex program. This is where the real fun begins! We’ll explore ingesting data, constructing indexes, executing queries,&#13;
     <html:span class="No-Break">&#13;
      and more.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     I’ll explain&#13;
     <html:a id="_idIndexMarker085">&#13;
     </html:a>&#13;
     each concept and line of code in simple terms along the way. In no time, you’ll be implementing the basics like a LlamaIndex pro! Once we’ve got these fundamentals down, we can start expanding the capabilities of our&#13;
     <html:span class="No-Break">&#13;
      tutor app.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     But first, let’s clarify the overall code structure of the framework’s&#13;
     <html:span class="No-Break">&#13;
      GitHub repository.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor042">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Familiarizing ourselves with the structure of the LlamaIndex code repository&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-43">&#13;
    Familiarizing ourselves with the structure of the LlamaIndex code repository&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    from llama_index.llms.mistralai import MistralAI&#13;
    pip install llama-index.llms.mistralai&#13;
    <html:p>&#13;
     Because you’ll probably spend a lot of time browsing the official code repository of the LlamaIndex&#13;
     <html:a id="_idIndexMarker086">&#13;
     </html:a>&#13;
     framework, it’s good to have an overall image of its general structure. You can always consult the repository&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://github.com/run-llama/llama_index&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Starting with version 0.10, the code has been thoroughly reorganized into a more modular structure. The purpose of this new structure is to improve efficiency, by avoiding loading any unnecessary dependencies, while also improving readability and overall user experience&#13;
     <html:span class="No-Break">&#13;
      for developers.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 2&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .6&#13;
     </html:em>&#13;
     describes the main components of the&#13;
     <html:span class="No-Break">&#13;
      code structure:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer022">&#13;
      <html:img src="img/B21861_02_6.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 2.6 – The LlamaIndex GitHub repository code structure&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      llama-index-core&#13;
     </html:code>&#13;
     folder serves as the foundational package for LlamaIndex, enabling developers to install the essential framework and then selectively add from over 300 integration packages and different Llama-packs to tailor functionality for their specific&#13;
     <html:span class="No-Break">&#13;
      application needs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      llama-index-integrations&#13;
     </html:code>&#13;
     folder of LlamaIndex consists of various add-on packages that extend the functionality of the core framework. These allow developers to customize&#13;
     <html:a id="_idIndexMarker087">&#13;
     </html:a>&#13;
     their build with specific elements such as custom LLMs, data loaders, embedding models, and vector store providers to best fit their application’s requirements. We’ll cover some of these integrations later in our book, starting with&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 4&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Ingesting Data into Our&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       RAG Workflow&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      llama-index-packs&#13;
     </html:code>&#13;
     folder contains more than 50 Llama packs. Developed and constantly improved by the LlamaIndex developer community, these packs serve as ready-made templates designed to kickstart a user’s application. We’ll talk about them in more detail during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 9&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Customizing and Deploying Our&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       LlamaIndex Project&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      llama-index-cli&#13;
     </html:code>&#13;
     folder is used by the LlamaIndex command-line interface, which we will also cover briefly during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 9&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:em class="italic">&#13;
      , Customizing and Deploying Our&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       LlamaIndex Project&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The last section, called&#13;
     <html:strong class="bold">&#13;
      OTHERS&#13;
     </html:strong>&#13;
     in&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 2&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .6&#13;
     </html:em>&#13;
     , consists of two folders that currently contain fine-tuning abstractions and some experimental features that we will not cover in&#13;
     <html:span class="No-Break">&#13;
      this book.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     The subfolders in&#13;
     <html:code class="literal">&#13;
      llama-index-integrations&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      llama-index-packs&#13;
     </html:code>&#13;
     represent individual packages. The folder name corresponds to the package name. For example, the&#13;
     <html:code class="literal">&#13;
      llama-index-integrations/llms/llama-index-llms-mistralai&#13;
     </html:code>&#13;
     folder corresponds to the&#13;
     <html:code class="literal">&#13;
      llama-index-llms-mistralai&#13;
     </html:code>&#13;
     <html:span class="No-Break">&#13;
      PyPI package.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Following this example, there is something you need to do before you import and use the&#13;
     <html:code class="literal">&#13;
      mistralai&#13;
     </html:code>&#13;
     package in your code&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You’ll have to first install the corresponding PyPI package by running&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Don’t worry&#13;
     <html:a id="_idIndexMarker088">&#13;
     </html:a>&#13;
     too much about missing any necessary packages for the examples included in the book, as you will find them nicely listed at the beginning of each chapter under the&#13;
     <html:em class="italic">&#13;
      Technical&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       requirements&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      heading.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor043">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Summary&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-44">&#13;
    Summary&#13;
   </html:h1>&#13;
   <html:div id="_idContainer023">&#13;
    <html:p>&#13;
     In this chapter, we introduced LlamaIndex, a framework for connecting LLMs to external datasets. We discovered how LlamaIndex allows LLMs to incorporate real-world knowledge into&#13;
     <html:span class="No-Break">&#13;
      their responses.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The chapter discussed the benefits of LlamaIndex over fine-tuning, such as easier updating and personalization. It introduced the concept of progressive disclosure of complexity, where LlamaIndex starts simple but reveals advanced capabilities&#13;
     <html:span class="No-Break">&#13;
      when needed.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The chapter then presented an overview of the hands-on project PITS, a personalized intelligent tutoring system. It covered setting up the required tools such as Python, Git, and Streamlit, and getting an OpenAI API key. The chapter finished by verifying that the environment is ready for building&#13;
     <html:span class="No-Break">&#13;
      LlamaIndex apps.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’re now ready to continue our journey and proceed with a more technical understanding of the inner workings of the LlamaIndex framework. See you in the&#13;
     <html:span class="No-Break">&#13;
      next chapter!&#13;
     </html:span>&#13;
    </html:p>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Part 2: Starting Your First LlamaIndex Project&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-45" lang="en-US">&#13;
    Part 2: Starting Your First LlamaIndex Project&#13;
   </html:h1>&#13;
   <html:div class="Content" id="_idContainer024">&#13;
   </html:div>&#13;
   <html:div id="_idContainer025">&#13;
    <html:p>&#13;
     In this part, we explore the detailed aspects of LlamaIndex, including data ingestion through LlamaHub connectors, text-chunking tools, metadata infusion, data privacy, and efficient ingestion pipelines, before moving on to a comprehensive guide to the indexing functionality within LlamaIndex, detailing types of indexes, customization, and strategies for building scalable&#13;
     <html:span class="No-Break">&#13;
      RAG systems.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This part has the&#13;
     <html:span class="No-Break">&#13;
      following chapters:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:a>&#13;
       <html:em class="italic">&#13;
        Chapter 3&#13;
       </html:em>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Kickstarting Your Journey with LlamaIndex&#13;
      </html:em>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:a>&#13;
       <html:em class="italic">&#13;
        Chapter 4&#13;
       </html:em>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Ingesting Data into Our RAG Workflow&#13;
      </html:em>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:a>&#13;
       <html:em class="italic">&#13;
        Chapter 5&#13;
       </html:em>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Indexing with LlamaIndex&#13;
      </html:em>&#13;
     </html:li>&#13;
    </html:ul>&#13;
   </html:div>&#13;
   <html:div>&#13;
    <html:div id="_idContainer026">&#13;
    </html:div>&#13;
   </html:div>&#13;
   <html:div>&#13;
    <html:div class="Basic-Graphics-Frame" id="_idContainer027">&#13;
    </html:div>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html></body></html>