<html><head></head><body>
<div aria-label="107" epub:type="pagebreak" id="page1-6" role="doc-pagebreak"/>
<div id="_idContainer071">
<h1 class="chapterNumber"><a id="_idTextAnchor152"/><span class="koboSpan" id="kobo.1.1">4</span></h1>
<h1 class="chapterTitle" id="_idParaDest-88"><a id="_idTextAnchor153"/><span class="koboSpan" id="kobo.2.1">Building Intelligent RAG Systems</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">So far in this book, we’ve talked about LLMs and tokens and working with them in LangChain. </span><strong class="keyWord"><span class="koboSpan" id="kobo.4.1">Retrieval-Augmented Generation</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.6.1">RAG</span></strong><span class="koboSpan" id="kobo.7.1">) extends LLMs by dynamically incorporating external knowledge during generation, addressing limitations of fixed training data, hallucinations, and context windows. </span><span class="koboSpan" id="kobo.7.2">A RAG system, in simple terms, takes a query, converts it directly into a semantic vector embedding, runs a search extracting relevant documents, and passes these to a model that generates a context-appropriate user-facing response.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.8.1">This chapter explores RAG systems and the core components of RAG, including vector stores, document processing, retrieval strategies, implementation, and evaluation techniques. </span><span class="koboSpan" id="kobo.8.2">After that, we’ll put into practice a lot of what we’ve learned so far in this book by building a chatbot. </span><span class="koboSpan" id="kobo.8.3">We’ll build a production-ready RAG pipeline that streamlines the creation and validation of corporate project documentation. </span><span class="koboSpan" id="kobo.8.4">This corporate use case demonstrates how to generate initial documentation, assess it for compliance and consistency, and incorporate human feedback—all in a modular and scalable workflow.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.9.1">The chapter has the following sections:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.10.1">From indexes to intelligent retrieval</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.11.1">Components of a RAG system</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.12.1">From embeddings to search</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.13.1">Breaking down the RAG pipeline</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.14.1">Developing a corporate documentation chatbot</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.15.1">Troubleshooting RAG systems</span></li>
</ul>
<div aria-label="108" epub:type="pagebreak" id="page2-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.16.1">Let’s begin by introducing RAG, its importance, and the main considerations when using the RAG framework.</span></p>
<h1 class="heading-1" id="_idParaDest-89"><a id="_idTextAnchor154"/><span class="koboSpan" id="kobo.17.1">From indexes to intelligent retrieval</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.18.1">Information retrieval has been a </span><a id="_idIndexMarker283"/><span class="koboSpan" id="kobo.19.1">fundamental human need since the dawn of recorded knowledge. </span><span class="koboSpan" id="kobo.19.2">For the past 70 years, retrieval systems have operated under the same core paradigm:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.20.1">First, a user frames an information need as a query.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.21.1">They then submit this query to the retrieval system.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.22.1">Finally, the system returns references to documents that may satisfy the information need:</span><ul><li class="bulletList level-2"><span class="koboSpan" id="kobo.23.1">References may be rank-ordered by decreasing relevance</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.24.1">Results may contain </span><a id="_idIndexMarker284"/><span class="koboSpan" id="kobo.25.1">relevant excerpts from each document (known as snippets)</span></li>
</ul></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.26.1">While this paradigm has remained constant, the implementation and user experience have undergone remarkable transformations. </span><span class="koboSpan" id="kobo.26.2">Early information retrieval systems relied on manual indexing and basic keyword matching. </span><span class="koboSpan" id="kobo.26.3">The advent of computerized indexing in the 1960s introduced the inverted index—a data structure that maps each word to a list of documents containing it. </span><span class="koboSpan" id="kobo.26.4">This lexical approach powered the first generation of search engines like AltaVista (1996), where results were primarily based on exact keyword matches.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.27.1">The limitations of this approach quickly became apparent, however. </span><span class="koboSpan" id="kobo.27.2">Words can have multiple meanings (polysemy), different words can express the same concept (synonymy), and users often struggle to articulate their information needs precisely.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.28.1">Information-seeking activities come with non-monetary costs: time investment, cognitive load, and interactivity costs—what researchers call “Delphic costs.” </span><span class="koboSpan" id="kobo.28.2">User satisfaction with search engines correlates not just with the relevance of results, but with how easily users can extract the information they need.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.29.1">Traditional retrieval systems aimed to reduce these costs through various optimizations:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.30.1">Synonym expansion to lower cognitive load when framing queries</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.31.1">Result ranking to reduce the time cost of scanning through results</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.32.1">Result snippeting (showing brief, relevant excerpts from search results) to lower the cost of evaluating document relevance</span></li>
</ul>
<div aria-label="109" epub:type="pagebreak" id="page3-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.33.1">These improvements reflected an understanding that the ultimate goal of search is not just finding documents but satisfying information needs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.34.1">Google’s PageRank algorithm (late 1990s) improved results by considering link structures, but even modern search engines faced fundamental limitations in understanding meaning. </span><span class="koboSpan" id="kobo.34.2">The search experience evolved from simple lists of matching documents to richer presentations with contextual snippets (beginning with Yahoo’s highlighted terms in the late 1990s and evolving to Google’s dynamic document previews that extract the most relevant sentences containing search terms), but the underlying challenge remained: bridging the semantic gap between query terms and relevant information.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.35.1">A fundamental limitation of traditional retrieval systems lies in their lexical approach to document retrieval. </span><span class="koboSpan" id="kobo.35.2">In the Uniterm model, query terms were mapped to documents through inverted indices, where each word in the vocabulary points to a “postings list” of document positions. </span><span class="koboSpan" id="kobo.35.3">This approach efficiently supported complex boolean queries but fundamentally missed semantic relationships between terms. </span><span class="koboSpan" id="kobo.35.4">For example, “turtle” and “tortoise” are treated as completely separate words in an inverted index, despite being semantically related. </span><span class="koboSpan" id="kobo.35.5">Early retrieval systems attempted to</span><a id="_idIndexMarker285"/><span class="koboSpan" id="kobo.36.1"> bridge this gap through pre-retrieval stages that augmented queries with synonyms, but the underlying limitation remained.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.37.1">The breakthrough came with advances in neural network models that could capture the meaning of words and documents as dense vector</span><a id="_idIndexMarker286"/><span class="koboSpan" id="kobo.38.1"> representations—known as embeddings. </span><span class="koboSpan" id="kobo.38.2">Unlike traditional keyword systems, embeddings create a </span><em class="italic"><span class="koboSpan" id="kobo.39.1">semantic map</span></em><span class="koboSpan" id="kobo.40.1"> where related concepts cluster together—”turtle,” “tortoise,” and “reptile” would appear as neighbors in this space, while “bank” (financial) would cluster with “money” but far from “river.” </span><span class="koboSpan" id="kobo.40.2">This geometric organization of meaning enabled retrieval based on conceptual similarity rather than exact word matching.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.41.1">This transformation gained momentum with models like Word2Vec (2013) and later transformer-based models such as BERT (2018), which introduced contextual understanding. </span><span class="koboSpan" id="kobo.41.2">BERT’s innovation was to recognize that the same word could have different meanings depending on its context—”bank” as a financial institution versus “bank” of a river. </span><span class="koboSpan" id="kobo.41.3">These distributed representations fundamentally changed what was possible in information retrieval, enabling the development of systems that could understand the intent behind queries rather than just matching keywords.</span></p>
<div aria-label="110" epub:type="pagebreak" id="page4-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.42.1">As transformer-based language models grew in scale, researchers discovered they not only learned linguistic patterns but also memorized factual knowledge from their training data. </span><span class="koboSpan" id="kobo.42.2">Studies by Google researchers showed that models like T5 could answer factual questions without external retrieval, functioning as implicit knowledge bases. </span><span class="koboSpan" id="kobo.42.3">This suggested a paradigm shift—from retrieving documents containing answers to directly generating answers from internalized knowledge. </span><span class="koboSpan" id="kobo.42.4">However, these “closed-book” generative systems faced limitations: hallucination risks, knowledge cutoffs limited to training data, inability to cite sources, and challenges with complex reasoning. </span><span class="koboSpan" id="kobo.42.5">The solution emerged in </span><strong class="keyWord"><span class="koboSpan" id="kobo.43.1">RAG</span></strong><span class="koboSpan" id="kobo.44.1">, which bridges traditional retrieval systems with generative language models, combining their respective strengths while addressing their individual weakness</span><a id="_idTextAnchor155"/><span class="koboSpan" id="kobo.45.1">es.</span></p>
<h1 class="heading-1" id="_idParaDest-90"><a id="_idTextAnchor156"/><span class="koboSpan" id="kobo.46.1">Components of a RAG system</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.47.1">RAG enables language models to </span><a id="_idIndexMarker287"/><span class="koboSpan" id="kobo.48.1">ground their outputs in external knowledge, providing an elegant solution to the limitations that plague pure LLMs: hallucinations, outdated information, and restricted context windows. </span><span class="koboSpan" id="kobo.48.2">By retrieving only relevant information on demand, RAG systems effectively bypass the context window constraints of language models, allowing them to leverage vast knowledge bases without squeezing everything into the model’s fixed attention span.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.49.1">Rather than simply retrieving documents for human review (as traditional search engines do) or generating answers solely from internalized knowledge (as pure LLMs do), RAG systems retrieve information to inform and ground AI-generated responses. </span><span class="koboSpan" id="kobo.49.2">This approach combines the verifiability of retrieval with the</span><a id="_idIndexMarker288"/><span class="koboSpan" id="kobo.50.1"> fluency and comprehension of generative AI.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.51.1">At its core, RAG consists of these main components working in concert:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.52.1">Knowledge base</span></strong><span class="koboSpan" id="kobo.53.1">: The storage layer for</span><a id="_idIndexMarker289"/><span class="koboSpan" id="kobo.54.1"> external information</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">Retriever</span></strong><span class="koboSpan" id="kobo.56.1">: The knowledge access layer</span><a id="_idIndexMarker290"/><span class="koboSpan" id="kobo.57.1"> that finds relevant information</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.58.1">Augmenter</span></strong><span class="koboSpan" id="kobo.59.1">: The integration layer that </span><a id="_idIndexMarker291"/><span class="koboSpan" id="kobo.60.1">prepares retrieved content</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.61.1">Generator</span></strong><span class="koboSpan" id="kobo.62.1">: The response</span><a id="_idIndexMarker292"/><span class="koboSpan" id="kobo.63.1"> layer that produces the final output</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.64.1">From a process perspective, RAG operates through two interconnected pipelines:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.65.1">An indexing pipeline that processes, chunks, and stores documents in the knowledge base</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.66.1">A query pipeline that retrieves relevant information and generates responses using that information</span></li>
</ul>
<div aria-label="111" epub:type="pagebreak" id="page5-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.67.1">The workflow in a RAG system follows a clear sequence: when a query arrives, it’s processed for retrieval; the retriever then searches the knowledge base for relevant information; this retrieved context is combined with the original query through augmentation; finally, the language model generates a response grounded in both the query and the retrieved information. </span><span class="koboSpan" id="kobo.67.2">We can see this in the following diagram:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.68.1"><img alt="Figure 4.1: RAG architecture and workflow" src="../Images/B32363_04_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.69.1">Figure 4.1: RAG architecture and workflow</span></p>
<div aria-label="112" epub:type="pagebreak" id="page6-6" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.70.1">This architecture offers several advantages for production systems: modularity allows components to be developed independently; scalability enables resources to be allocated based on specific needs; maintainability is</span><a id="_idIndexMarker293"/><span class="koboSpan" id="kobo.71.1"> improved through the clear separation of concerns; and flexibility permits different implementation strategies to be swapped in as requirements evolve.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.72.1">In the following sections, we’ll explore each component in </span><em class="italic"><span class="koboSpan" id="kobo.73.1">Figure 4.1</span></em><span class="koboSpan" id="kobo.74.1"> in detail, beginning with the fundamental building blocks of modern RAG systems: </span><strong class="screenText"><span class="koboSpan" id="kobo.75.1">embeddings</span></strong><span class="koboSpan" id="kobo.76.1"> and </span><strong class="screenText"><span class="koboSpan" id="kobo.77.1">vector stores</span></strong><span class="koboSpan" id="kobo.78.1"> that power the knowledge base and retriever components. </span><span class="koboSpan" id="kobo.78.2">But before we dive in, it’s important to first consider the decision between implementing RAG or using pure LLMs. </span><span class="koboSpan" id="kobo.78.3">This choice will fundamentally impact your application’s overall architecture and operational characteristics. </span><span class="koboSpan" id="kobo.78.4">Let’s discuss the tr</span><a id="_idTextAnchor157"/><span class="koboSpan" id="kobo.79.1">ade-offs!</span></p>
<h2 class="heading-2" id="_idParaDest-91"><a id="_idTextAnchor158"/><span class="koboSpan" id="kobo.80.1">When to implement RAG</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.81.1">Introducing RAG brings architectural complexity that must be carefully weighed against your application requirements. </span><span class="koboSpan" id="kobo.81.2">RAG proves particularly </span><a id="_idIndexMarker294"/><span class="koboSpan" id="kobo.82.1">valuable in specialized domains where current or verifiable information is crucial. </span><span class="koboSpan" id="kobo.82.2">Healthcare applications must process both medical images and time-series data, while financial systems need to handle high-dimensional market data alongside historical analysis. </span><span class="koboSpan" id="kobo.82.3">Legal applications benefit from RAG’s ability to process complex document structures and maintain source attribution. </span><span class="koboSpan" id="kobo.82.4">These domain-specific requirements often justify the additional complexity of implementing RAG.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.83.1">The benefits of RAG, however, come with significant implementation considerations. </span><span class="koboSpan" id="kobo.83.2">The system requires efficient indexing and retrieval mechanisms to maintain reasonable response times. </span><span class="koboSpan" id="kobo.83.3">Knowledge bases need regular updates and maintenance to remain valuable. </span><span class="koboSpan" id="kobo.83.4">Infrastructure must be designed to handle errors and edge cases gracefully, especially where different components interact. </span><span class="koboSpan" id="kobo.83.5">Development teams must be prepared to manage these ongoing operational requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.84.1">Pure LLM implementations, on the other hand, might be more appropriate when these complexities outweigh the benefits. </span><span class="koboSpan" id="kobo.84.2">Applications focusing on creative tasks, general conversation, or scenarios requiring rapid response times often perform well without the overhead of retrieval systems. </span><span class="koboSpan" id="kobo.84.3">When working with static, limited knowledge bases, techniques like fine-tuning or prompt engineering might provide simpler solutions.</span></p>
<div aria-label="113" epub:type="pagebreak" id="page7-5" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.85.1">This analysis, drawn from both research and practical implementations, suggests that specific requirements for knowledge currency, accuracy, and domain expertise should guide the choice between RAG and pure LLMs, balanced against the organizational capacity to manage the additional architectural complexity.</span></p>
<div>
<div class="note" id="_idContainer054">
<p class="normal"><span class="koboSpan" id="kobo.86.1">At Chelsea AI Ventures, our team has observed that clients in regulated industries particularly benefit from RAG’s verifiability, while creative applications often perform adequately with pure LLMs.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.87.1">Development teams should consider RAG when their applications require:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.88.1">Access to current information not available in LLM training data</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.89.1">Domain-specific knowledge integration</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.90.1">Verifiable responses with source attribution</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.91.1">Processing of specialized data formats</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.92.1">High precision in regulated industries</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.93.1">With that, let’s explore the implementation details, optimization strategies, and production deployment considerations for each RAG </span><a id="_idTextAnchor159"/><span class="koboSpan" id="kobo.94.1">component.</span></p>
<h1 class="heading-1" id="_idParaDest-92"><a id="_idTextAnchor160"/><span class="koboSpan" id="kobo.95.1">From embeddings to search</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.96.1">As mentioned, a RAG system comprises a retriever that finds relevant information, an augmentation mechanism that integrates this information, and a generator that produces the final output. </span><span class="koboSpan" id="kobo.96.2">When building AI </span><a id="_idIndexMarker295"/><span class="koboSpan" id="kobo.97.1">applications with LLMs, we often focus on the exciting parts – prompts, chains, and model outputs. </span><span class="koboSpan" id="kobo.97.2">However, the foundation of any robust RAG system lies in how we store and retrieve our vector embeddings. </span><span class="koboSpan" id="kobo.97.3">Think of it like building a library – before we can efficiently find books (vector search), we need both a building to store them (vector storage) and an organization system to find them (vector indexing). </span><span class="koboSpan" id="kobo.97.4">In this section, we introduce the core components of a RAG system: vector embeddings, vector stores, and indexing strategies to optimize retrieval.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.98.1">To make RAG work, we first need to solve a fundamental challenge: how do we help computers understand the meaning of text so they can find relevant information? </span><span class="koboSpan" id="kobo.98.2">This is where embeddin</span><a id="_idTextAnchor161"/><span class="koboSpan" id="kobo.99.1">gs come in.</span></p>
<div aria-label="114" epub:type="pagebreak" id="page8-5" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-93"><a id="_idTextAnchor162"/><span class="koboSpan" id="kobo.100.1">Embeddings</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.101.1">Embeddings are numerical representations of text that capture semantic meaning. </span><span class="koboSpan" id="kobo.101.2">When we create an embedding, we’re converting words or </span><a id="_idIndexMarker296"/><span class="koboSpan" id="kobo.102.1">chunks of text into vectors (lists of numbers) that computers can process. </span><span class="koboSpan" id="kobo.102.2">These vectors can be either sparse (mostly zeros with few non-zero values) or dense (most values are non-zero), with modern LLM systems typically using dense embeddings.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.103.1">What makes embeddings powerful is that texts with similar meanings have similar numerical representations, enabling semantic search through nearest neighbor algorithms.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.104.1">In other words, the embedding model transforms text into numerical vectors. </span><span class="koboSpan" id="kobo.104.2">The same model is used for both documents as well as queries to ensure consistency in the vector space. </span><span class="koboSpan" id="kobo.104.3">Here’s how you’d use embeddings in LangChain:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.105.1">from</span></span><span class="koboSpan" id="kobo.106.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.107.1">import</span></span><span class="koboSpan" id="kobo.108.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.109.1"># Initialize the embeddings model</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.110.1">embeddings_model = OpenAIEmbeddings()</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.111.1"># Create embeddings for the original example sentences</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.112.1">text1 = </span><span class="hljs-string"><span class="koboSpan" id="kobo.113.1">"The cat sat on the mat"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.114.1">text2 = </span><span class="hljs-string"><span class="koboSpan" id="kobo.115.1">"A feline rested on the carpet"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.116.1">text3 = </span><span class="hljs-string"><span class="koboSpan" id="kobo.117.1">"Python is a programming language"</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.118.1"># Get embeddings using LangChain</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.119.1">embeddings = embeddings_model.embed_documents([text1, text2, text3])</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.120.1"># These similar sentences will have similar embeddings</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.121.1">embedding1 = embeddings[</span><span class="hljs-number"><span class="koboSpan" id="kobo.122.1">0</span></span><span class="koboSpan" id="kobo.123.1">] </span><span class="hljs-comment"><span class="koboSpan" id="kobo.124.1"># Embedding for "The cat sat on the mat"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.125.1">embedding2 = embeddings[</span><span class="hljs-number"><span class="koboSpan" id="kobo.126.1">1</span></span><span class="koboSpan" id="kobo.127.1">] </span><span class="hljs-comment"><span class="koboSpan" id="kobo.128.1"># Embedding for "A feline rested on the</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.129.1">carpet</span><span class="hljs-string"><span class="koboSpan" id="kobo.130.1">"</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.131.1">embedding3 = embeddings[2] # Embedding for "</span></span><span class="koboSpan" id="kobo.132.1">Python </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.133.1">is</span></span><span class="koboSpan" id="kobo.134.1"> a programming</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.135.1">language</span><span class="hljs-string"><span class="koboSpan" id="kobo.136.1">"</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.137.1"># Output shows 3 documents with their embedding dimensions</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.138.1">print(f"</span></span><span class="koboSpan" id="kobo.139.1">Number of documents: {</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.140.1">len</span></span><span class="koboSpan" id="kobo.141.1">(embeddings)}</span><span class="hljs-string"><span class="koboSpan" id="kobo.142.1">")</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.143.1">print(f"</span></span><span class="koboSpan" id="kobo.144.1">Dimensions per embedding: {</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.145.1">len</span></span><span class="koboSpan" id="kobo.146.1">(embeddings[</span><span class="hljs-number"><span class="koboSpan" id="kobo.147.1">0</span></span><span class="koboSpan" id="kobo.148.1">])}</span><span class="hljs-string"><span class="koboSpan" id="kobo.149.1">")</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.150.1"># Typically 1536 dimensions with OpenAI's embeddings</span></span></p>
<div aria-label="115" epub:type="pagebreak" id="page9-4" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.151.1">Once we have these OpenAI </span><a id="_idIndexMarker297"/><span class="koboSpan" id="kobo.152.1">embeddings (the 1536-dimensional vectors we generated for our example sentences above), we need a purpose-built system to store them. </span><span class="koboSpan" id="kobo.152.2">Unlike regular database values, these high-dimensional vectors require specialized storage solutions.</span></p>
<div>
<div class="note" id="_idContainer055">
<p class="normal"><span class="koboSpan" id="kobo.153.1"> The </span><code class="inlineCode"><span class="koboSpan" id="kobo.154.1">Embeddings</span></code><span class="koboSpan" id="kobo.155.1"> class in LangChain provides a standard interface for all embedding models from various providers (OpenAI, Cohere, Hugging Face, and others). </span><span class="koboSpan" id="kobo.155.2">It exposes two primary methods:</span></p>
<ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.156.1">embed_documents</span></code><span class="koboSpan" id="kobo.157.1">: Takes multiple texts and returns embeddings for each</span></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.158.1">embed_query</span></code><span class="koboSpan" id="kobo.159.1">: Takes a single text (your search query) and returns its embedding</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.160.1">Some providers use different embedding methods for documents versus queries, which is why these are separate methods in the API.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.161.1">This brings us to vector stores – specialized databases optimized for similarity searches in high-dimens</span><a id="_idTextAnchor163"/><span class="koboSpan" id="kobo.162.1">ional spaces.</span></p>
<h2 class="heading-2" id="_idParaDest-94"><a id="_idTextAnchor164"/><span class="koboSpan" id="kobo.163.1">Vector stores</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.164.1">Vector stores are specialized databases designed to store, manage, and efficiently search vector embeddings. </span><span class="koboSpan" id="kobo.164.2">As we’ve seen, embeddings </span><a id="_idIndexMarker298"/><span class="koboSpan" id="kobo.165.1">convert text (or other data) into numerical vectors that capture semantic meaning.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.166.1">Vector stores solve the fundamental challenge of how to persistently and efficiently search through these high-dimensional vectors. </span><span class="koboSpan" id="kobo.166.2">Please note that the vector database operates as an independent system that can be:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.167.1">Scaled independently of the RAG components</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.168.1">Maintained and optimized separately</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.169.1">Potentially shared across multiple RAG applications</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.170.1">Hosted as a dedicated service</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.171.1">When working with embeddings, several </span><a id="_idIndexMarker299"/><span class="koboSpan" id="kobo.172.1">challenges arise:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.173.1">Scale</span></strong><span class="koboSpan" id="kobo.174.1">: Applications often need to store millions of embeddings</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.175.1">Dimensionality</span></strong><span class="koboSpan" id="kobo.176.1">: Each embedding might have hundreds or thousands of dimensions</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.177.1">Search performance</span></strong><span class="koboSpan" id="kobo.178.1">: Finding similar vectors quickly becomes computationally intensive</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.179.1">Associated data</span></strong><span class="koboSpan" id="kobo.180.1">: We need to maintain connections between vectors and their source documents</span></li>
</ul>
<div aria-label="116" epub:type="pagebreak" id="page10-4" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.181.1">Consider a real-world example of what we need to store:</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.182.1"># Example of data that needs efficient storage in a vector store</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.183.1">document_data = {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.184.1">"id"</span></span><span class="koboSpan" id="kobo.185.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.186.1">"doc_42"</span></span><span class="koboSpan" id="kobo.187.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.188.1">"text"</span></span><span class="koboSpan" id="kobo.189.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.190.1">"LangChain is a framework for developing applications powered by language models."</span></span><span class="koboSpan" id="kobo.191.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.192.1">"embedding"</span></span><span class="koboSpan" id="kobo.193.1">: [</span><span class="hljs-number"><span class="koboSpan" id="kobo.194.1">0.123</span></span><span class="koboSpan" id="kobo.195.1">, -</span><span class="hljs-number"><span class="koboSpan" id="kobo.196.1">0.456</span></span><span class="koboSpan" id="kobo.197.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.198.1">0.789</span></span><span class="koboSpan" id="kobo.199.1">, ...],  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.200.1"># 1536 dimensions for OpenAI embeddings</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.201.1">"metadata"</span></span><span class="koboSpan" id="kobo.202.1">: {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.203.1">"source"</span></span><span class="koboSpan" id="kobo.204.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.205.1">"documentation.pdf"</span></span><span class="koboSpan" id="kobo.206.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.207.1">"page"</span></span><span class="koboSpan" id="kobo.208.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.209.1">7</span></span><span class="koboSpan" id="kobo.210.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.211.1">"created_at"</span></span><span class="koboSpan" id="kobo.212.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.213.1">"2023-06-15"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.214.1">    }</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.215.1">}</span></p>
<p class="normal"><span class="koboSpan" id="kobo.216.1">At their core, vector stores combine two essential components:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.217.1">Vector storage</span></strong><span class="koboSpan" id="kobo.218.1">: The actual database that persists vectors and metadata</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.219.1">Vector index</span></strong><span class="koboSpan" id="kobo.220.1">: A specialized data structure that enables efficient similarity search</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.221.1">The efficiency challenge comes from the </span><em class="italic"><span class="koboSpan" id="kobo.222.1">curse of dimensionality</span></em><span class="koboSpan" id="kobo.223.1"> – as vector dimensions increase, computing similarities </span><a id="_idIndexMarker300"/><span class="koboSpan" id="kobo.224.1">becomes increasingly expensive, requiring O(dN) operations for d dimensions and N vectors. </span><span class="koboSpan" id="kobo.224.2">This makes naive similarity search impractical for large-scale applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.225.1">Vector stores enable similarity-based search through distance calculations in high-dimensional space. </span><span class="koboSpan" id="kobo.225.2">While traditional databases excel at exact matching, vector embeddings allow for semantic search and </span><strong class="keyWord"><span class="koboSpan" id="kobo.226.1">approximate nearest neighbor</span></strong><span class="koboSpan" id="kobo.227.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.228.1">ANN</span></strong><span class="koboSpan" id="kobo.229.1">) retrieval.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.230.1">The key difference from traditional </span><a id="_idIndexMarker301"/><span class="koboSpan" id="kobo.231.1">databases is how vector stores handle searches.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.232.1">Traditional database search</span></strong><span class="koboSpan" id="kobo.233.1">:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.234.1">Uses exact matching (equality, ranges)</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.235.1">Optimized for structured data (for example, “find all customers with age &gt; 30”)</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.236.1">Usually utilizes B-trees or hash-based indexes</span></li>
</ul>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.237.1">Vector store search:</span></strong></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.238.1">Uses similarity metrics (cosine similarity, Euclidean distance)</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.239.1">Optimized for high-dimensional vector spaces</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.240.1">Employs Approximate Nearest Neighbor</span><a id="_idTextAnchor165"/><span class="koboSpan" id="kobo.241.1"> (ANN) algorithms</span></li>
</ul>
<div aria-label="117" epub:type="pagebreak" id="page11-3" role="doc-pagebreak"/>
<h3 class="heading-3" id="_idParaDest-95"><a id="_idTextAnchor166"/><span class="koboSpan" id="kobo.242.1">Vector stores comparison</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.243.1">Vector stores manage high-dimensional </span><a id="_idIndexMarker302"/><span class="koboSpan" id="kobo.244.1">embeddings for retrieval. </span><span class="koboSpan" id="kobo.244.2">The following table compares popular vector stores across key attributes to help you select the most appropriate solution for your specific needs:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-4">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.245.1">Database</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.246.1">Deployment options</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.247.1">License</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.248.1">Notable features</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.249.1">Pinecone</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.250.1">Cloud-only</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.251.1">Commercial</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.252.1">Auto-scaling, enterprise security, monitoring</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.253.1">Milvus</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.254.1">Cloud, Self-hosted</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.255.1">Apache 2.0</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.256.1">HNSW/IVF indexing, multi-modal support, CRUD operations</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.257.1">Weaviate</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.258.1">Cloud, Self-hosted</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.259.1">BSD 3-Clause</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.260.1">Graph-like structure, multi-modal support</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.261.1">Qdrant</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.262.1">Cloud, Self-hosted</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.263.1">Apache 2.0</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.264.1">HNSW indexing, filtering optimization, JSON metadata</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.265.1">ChromaDB</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.266.1">Cloud, Self-hosted</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.267.1">Apache 2.0</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.268.1">Lightweight, easy setup</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.269.1">AnalyticDB-V</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.270.1">Cloud-only</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.271.1">Commercial</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.272.1">OLAP integration, SQL support, enterprise features</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.273.1">pg_vector</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.274.1">Cloud, Self-hosted</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.275.1">OSS</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.276.1">SQL support, PostgreSQL integration</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.277.1">Vertex Vector Search</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.278.1">Cloud-only</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.279.1">Commercial</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.280.1">Easy setup, low latency, high scalability</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.281.1">Table 4.1: Vector store comparison by deployment options, licensing, and key features</span></p>
<p class="normal"><span class="koboSpan" id="kobo.282.1">Each vector store offers different tradeoffs in terms of deployment flexibility, licensing, and specialized capabilities. </span><span class="koboSpan" id="kobo.282.2">For production RAG systems, consider factors such as:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.283.1">Whether you</span><a id="_idIndexMarker303"/><span class="koboSpan" id="kobo.284.1"> need cloud-managed or self-hosted deployment</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.285.1">The need for specific features like SQL integration or multi-modal support</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.286.1">The complexity of setup and maintenance</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.287.1">Scaling requirements for your expected embedding volume</span></li>
</ul>
<div aria-label="118" epub:type="pagebreak" id="page12-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.288.1">For many applications starting with RAG, lightweight options like ChromaDB provide an excellent balance of simplicity and functionality, while enterprise deployments might benefit from the advanced features of Pinecone or AnalyticDB-V. </span><span class="koboSpan" id="kobo.288.2">Modern vector stores support several search patterns:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.289.1">Exact search</span></strong><span class="koboSpan" id="kobo.290.1">: Returns precise nearest neighbors but becomes computationally prohibitive with large vector </span><a id="_idIndexMarker304"/><span class="koboSpan" id="kobo.291.1">collections</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.292.1">Approximate search</span></strong><span class="koboSpan" id="kobo.293.1">: Trades accuracy for speed using techniques like LSH, HNSW, or quantization; measured by recall (the percentage of true nearest neighbors retrieved)</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.294.1">Hybrid search</span></strong><span class="koboSpan" id="kobo.295.1">: Combines vector similarity with text-based search (like keyword matching or BM25) in a single query</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.296.1">Filtered vector search</span></strong><span class="koboSpan" id="kobo.297.1">: Applies traditional database filters (for example, metadata constraints) alongside vector similarity search</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.298.1">Vector stores also handle different types of embeddings:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.299.1">Dense vector search</span></strong><span class="koboSpan" id="kobo.300.1">: Uses</span><a id="_idIndexMarker305"/><span class="koboSpan" id="kobo.301.1"> continuous embeddings where most dimensions have non-zero values, typically from neural models (like BERT, OpenAI embeddings)</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.302.1">Sparse vector search</span></strong><span class="koboSpan" id="kobo.303.1">: Uses high-dimensional vectors where most values are zero, resembling traditional TF-IDF or BM25 representations</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.304.1">Sparse-dense hybrid</span></strong><span class="koboSpan" id="kobo.305.1">: Combines both approaches to leverage semantic similarity (dense) and keyword precision (sparse)</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.306.1">They also often give a</span><a id="_idIndexMarker306"/><span class="koboSpan" id="kobo.307.1"> choice of multiple similarity measures, for example:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.308.1">Inner product</span></strong><span class="koboSpan" id="kobo.309.1">: Useful for comparing semantic directions</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.310.1">Cosine similarity</span></strong><span class="koboSpan" id="kobo.311.1">: Normalizes for vector magnitude</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.312.1">Euclidean distance</span></strong><span class="koboSpan" id="kobo.313.1">: Measures the L2 distance in vector space (note: with normalized embeddings, this becomes functionally equivalent to the dot product)</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.314.1">Hamming distance</span></strong><span class="koboSpan" id="kobo.315.1">: For binary vector representations</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.316.1">When implementing vector storage for RAG applications, one of the first architectural decisions is whether to use local storage or a cloud-based solution. </span><span class="koboSpan" id="kobo.316.2">Let’s explore the tradeoffs and considerations for each approach.</span></p>
<div aria-label="119" epub:type="pagebreak" id="page13-3" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.317.1">Choose local storage when you need maximum control, have strict privacy requirements, or operate at a smaller scale with predictable workloads.</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.318.1">Choose cloud storage when you need elastic scaling, prefer managed services, or operate distributed applications with variable workloads.</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.319.1">Consider hybrid storage architecture when you want to balance performance and scalability, combining local caching with cloud-based persistence.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-96"><a id="_idTextAnchor167"/><span class="koboSpan" id="kobo.320.1">Hardware considerations for vector stores</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.321.1">Regardless of your deployment approach, understanding</span><a id="_idIndexMarker307"/><span class="koboSpan" id="kobo.322.1"> the hardware requirements is crucial for optimal performance:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.323.1">Memory requirements</span></strong><span class="koboSpan" id="kobo.324.1">: Vector databases are memory-intensive, with production systems often requiring 16-64GB RAM for millions of embeddings. </span><span class="koboSpan" id="kobo.324.2">Local deployments should plan for sufficient memory headroom to accommodate index growth.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.325.1">CPU vs. </span><span class="koboSpan" id="kobo.325.2">GPU</span></strong><span class="koboSpan" id="kobo.326.1">: While basic vector operations work on CPUs, GPU acceleration significantly improves performance for large-scale similarity searches. </span><span class="koboSpan" id="kobo.326.2">For high-throughput applications, GPU support can provide 10-50x speed improvements.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.327.1">Storage speed</span></strong><span class="koboSpan" id="kobo.328.1">: SSD storage is strongly recommended over HDD for production vector stores, as index loading and search performance depend heavily on I/O speed. </span><span class="koboSpan" id="kobo.328.2">This is especially critical for local deployments.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.329.1">Network bandwidth</span></strong><span class="koboSpan" id="kobo.330.1">: For cloud-based or distributed setups, network latency and bandwidth become critical factors that can impact query response times.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.331.1">For development and testing, most</span><a id="_idIndexMarker308"/><span class="koboSpan" id="kobo.332.1"> vector stores can run on standard laptops with 8GB+ RAM, but production deployments should consider dedicated infrastructure or cloud-based vector store services that handle these resource considerations automatic</span><a id="_idTextAnchor168"/><span class="koboSpan" id="kobo.333.1">ally.</span></p>
<h3 class="heading-3" id="_idParaDest-97"><a id="_idTextAnchor169"/><span class="koboSpan" id="kobo.334.1">Vector store interface in LangChain</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.335.1">Now that we’ve explored the role of vector stores and compared some common options, let’s look at how LangChain simplifies </span><a id="_idIndexMarker309"/><span class="koboSpan" id="kobo.336.1">working with them. </span><span class="koboSpan" id="kobo.336.2">LangChain provides a standardized interface for working with vector stores, allowing you to easily switch between different implementations:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.337.1">from</span></span><span class="koboSpan" id="kobo.338.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.339.1">import</span></span><span class="koboSpan" id="kobo.340.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.341.1">from</span></span><span class="koboSpan" id="kobo.342.1"> langchain_chroma </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.343.1">import</span></span><span class="koboSpan" id="kobo.344.1"> Chroma</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.345.1"># Initialize </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.346.1">with</span></span><span class="koboSpan" id="kobo.347.1"> an embedding model</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.348.1">embeddings = OpenAIEmbeddings()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.349.1">vector_store = Chroma(embedding_function=embeddings)</span></p>
<div aria-label="120" epub:type="pagebreak" id="page14-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.350.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.351.1">vectorstore</span></code><span class="koboSpan" id="kobo.352.1"> base class in LangChain provides these essential operations:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.353.1">Adding documents:</span><p class="snippet-code-one"><span class="hljs-attr"><span class="koboSpan" id="kobo.354.1">docs</span></span><span class="koboSpan" id="kobo.355.1"> = [Document(page_content=</span><span class="hljs-string"><span class="koboSpan" id="kobo.356.1">"Content 1"</span></span><span class="koboSpan" id="kobo.357.1">), Document(page_</span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.358.1">content=</span><span class="hljs-string"><span class="koboSpan" id="kobo.359.1">"Content 2"</span></span><span class="koboSpan" id="kobo.360.1">)]</span></p><p class="snippet-code-one"><span class="hljs-attr"><span class="koboSpan" id="kobo.361.1">ids</span></span><span class="koboSpan" id="kobo.362.1"> = vector_store.add_documents(docs)</span></p></li>
<li class="numberedList"><span class="koboSpan" id="kobo.363.1">Similarity search:</span><p class="snippet-code-one"><span class="hljs-attr"><span class="koboSpan" id="kobo.364.1">results</span></span><span class="koboSpan" id="kobo.365.1"> = vector_store.similarity_search(</span><span class="hljs-string"><span class="koboSpan" id="kobo.366.1">"How does LangChain work?"</span></span><span class="koboSpan" id="kobo.367.1">, k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.368.1">3</span></span><span class="koboSpan" id="kobo.369.1">)</span></p></li>
<li class="numberedList"><span class="koboSpan" id="kobo.370.1">Deletion:</span><p class="snippet-code-one"><span class="koboSpan" id="kobo.371.1">vector_store</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.372.1">.delete</span></span><span class="koboSpan" id="kobo.373.1">(ids=</span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.374.1">[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.375.1">"doc_1"</span></span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.376.1">, </span></span><span class="hljs-string"><span class="koboSpan" id="kobo.377.1">"doc_2"</span></span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.378.1">]</span></span><span class="koboSpan" id="kobo.379.1">)</span></p></li>
<li class="numberedList"><span class="koboSpan" id="kobo.380.1">Maximum marginal relevance search:</span><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.381.1"># Find relevant BUT diverse documents (reduce redundancy)</span></span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.382.1">results = vector_store.max_marginal_relevance_search(</span></p><p class="snippet-code-one"> <span class="hljs-string"><span class="koboSpan" id="kobo.383.1">"How does LangChain work?"</span></span><span class="koboSpan" id="kobo.384.1">,</span></p><p class="snippet-code-one"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.385.1">k</span></span><span class="koboSpan" id="kobo.386.1">=3,</span></p><p class="snippet-code-one"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.387.1">fetch_k</span></span><span class="koboSpan" id="kobo.388.1">=10,</span></p><p class="snippet-code-one"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.389.1">lambda_mult</span></span><span class="koboSpan" id="kobo.390.1">=0.5  # Controls diversity (</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.391.1">0</span></span><span class="koboSpan" id="kobo.392.1">=max diversity, </span><span class="hljs-attribute"><span class="koboSpan" id="kobo.393.1">1</span></span><span class="koboSpan" id="kobo.394.1">=max relevance)</span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.395.1">)</span></p></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.396.1">It’s important to also briefly highlight applications of vector stores apart from RAG:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.397.1">Anomaly detection in large datasets</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.398.1">Personalization and recommendation systems</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.399.1">NLP tasks</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.400.1">Fraud detection</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.401.1">Network security monitoring</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.402.1">Storing vectors isn’t enough, however. </span><span class="koboSpan" id="kobo.402.2">We need to find similar vectors quickly when processing queries. </span><span class="koboSpan" id="kobo.402.3">Without </span><a id="_idIndexMarker310"/><span class="koboSpan" id="kobo.403.1">proper indexing, searching through vectors would be like trying to find a book in a library with no organization system – you’d have to check every singl</span><a id="_idTextAnchor170"/><span class="koboSpan" id="kobo.404.1">e book.</span></p>
<div aria-label="121" epub:type="pagebreak" id="page15-3" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-98"><a id="_idTextAnchor171"/><span class="koboSpan" id="kobo.405.1">Vector indexing strategies</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.406.1">Vector indexing is a critical component that makes vector databases practical for real-world applications. </span><span class="koboSpan" id="kobo.406.2">At its core, indexing </span><a id="_idIndexMarker311"/><span class="koboSpan" id="kobo.407.1">solves a fundamental performance challenge: how to efficiently find similar vectors without comparing against every single vector in the database (brute force approach), which is computationally prohibitive for even medium-sized data volumes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.408.1">Vector indexes are specialized data structures that organize vectors in ways that allow the system to quickly identify which sections of the vector space are most likely to contain similar vectors. </span><span class="koboSpan" id="kobo.408.2">Instead of checking every vector, the system can focus on promising regions first. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.409.1">Some common indexing approaches include:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.410.1">Tree-based structures</span></strong><span class="koboSpan" id="kobo.411.1"> that hierarchically divide the vector space</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.412.1">Graph-based methods</span></strong><span class="koboSpan" id="kobo.413.1"> like </span><strong class="keyWord"><span class="koboSpan" id="kobo.414.1">Hierarchical Navigable Small World</span></strong><span class="koboSpan" id="kobo.415.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.416.1">HNSW</span></strong><span class="koboSpan" id="kobo.417.1">) that create navigable networks </span><a id="_idIndexMarker312"/><span class="koboSpan" id="kobo.418.1">of connected vectors</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.419.1">Hashing techniques</span></strong><span class="koboSpan" id="kobo.420.1"> that map similar vectors to the same “buckets”</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.421.1">Each of the preceding approaches offers different trade-offs between:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.422.1">Search speed</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.423.1">Accuracy of results</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.424.1">Memory usage</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.425.1">Update efficiency (how quickly new vectors can be added)</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.426.1">When using a vector store in LangChain, the indexing strategy is typically handled by the underlying implementation. </span><span class="koboSpan" id="kobo.426.2">For example, when you create a FAISS index or use Pinecone, those systems automatically apply appropriate indexing strategies based on your configuration.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.427.1">The key takeaway is that proper indexing transforms vector search from an O(n) operation (where n is the number of vectors) to something much more efficient (often closer to O(log n)), making it possible to </span><a id="_idIndexMarker313"/><span class="koboSpan" id="kobo.428.1">search through millions of vectors in milliseconds rather than seconds or minutes.</span></p>
<div aria-label="122" epub:type="pagebreak" id="page16-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.429.1">Here’s a table to provide an overview of different strategies:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002-2">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.430.1">Strategy</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.431.1">Core algorithm</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.432.1">Complexity</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.433.1">Memory usage</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.434.1">Best for</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.435.1">Notes</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.436.1">Exact Search (Brute Force)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.437.1">Compares query vector with every vector in database</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.438.1">Search: O(DN)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.439.1">Build: O(1)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.440.1">Low – only stores raw vectors</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.441.1">Small datasets</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.442.1">When 100% recall needed</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.443.1">Testing/baseline</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.444.1">Easiest to implement</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.445.1">Good baseline for testing</span></li>
</ul>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.446.1">HNSW (Hierarchical Navigable Small World)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.447.1">Creates layered graph with decreasing connectivity from bottom to top</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.448.1">Search: O(log N)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.449.1">Build: O(N log N)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.450.1">High – stores graph connections plus vectors</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.451.1">Production systems</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.452.1">When high accuracy needed</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.453.1">Large-scale search</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.454.1">Industry standard</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.455.1">Requires careful tuning of M (connections) and ef (search depth)</span></li>
</ul>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.456.1">LSH (Locality Sensitive Hashing)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.457.1">Uses hash functions that map similar vectors to the same buckets</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.458.1">Search: O(N</span><span class="koboSpan" id="kobo.459.1"><img alt="" src="../Images/Icon_2.png"/></span><span class="koboSpan" id="kobo.460.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.461.1">Build: O(N)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.462.1">Medium – stores multiple hash tables</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.463.1">Streaming data</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.464.1">When updates frequent</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.465.1">Approximate search OK</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.466.1">Good for dynamic data</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.467.1">Tunable accuracy vs speed</span></li>
</ul>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.468.1">IVF (Inverted File Index)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.469.1">Clusters vectors and searches within relevant clusters</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.470.1">Search: O(DN/k)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.471.1">Build: O(kN)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.472.1">Low – stores cluster assignments</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.473.1">Limited memory</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.474.1">Balance of speed/accuracy</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.475.1">Simple implementation</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.476.1">k = number of clusters</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.477.1">Often combined with other methods</span></li>
</ul>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.478.1">Product Quantization (PQ)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.479.1">Compresses vectors by splitting into subspaces and quantizing</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.480.1">Search: varies</span></p>
<p class="normal"><span class="koboSpan" id="kobo.481.1">Build: O(N)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.482.1">Very Low – compressed vectors</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.483.1">Memory-constrained systems</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.484.1">Massive datasets</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.485.1">Often combined with IVF</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.486.1">Requires training codebooks</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.487.1">Complex implementation</span></li>
</ul>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<div aria-label="123" epub:type="pagebreak" id="page17-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.488.1">Tree-Based (KD-Tree, Ball Tree)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.489.1">Recursively partitions space into regions</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.490.1">Search: O(D log N) best case</span></p>
<p class="normal"><span class="koboSpan" id="kobo.491.1">Build: O(N log N)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.492.1">Medium – tree structure</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.493.1">Low dimensional data</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.494.1">Static datasets</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.495.1">Works well for D &lt; 100</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.496.1">Expensive updates</span></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.497.1">Table 4.2: Vector store comparison by deployment options, licensing, and key features</span></p>
<p class="normal"><span class="koboSpan" id="kobo.498.1">When selecting an indexing strategy for your RAG system, consider these practical tradeoffs:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.499.1">For maximum accuracy with small datasets</span></strong><span class="koboSpan" id="kobo.500.1"> (&lt;100K vectors): Exact Search provides perfect recall but becomes prohibitively expensive as your dataset grows.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.501.1">For production systems with millions of vectors</span></strong><span class="koboSpan" id="kobo.502.1">: HNSW offers the best balance of search speed and accuracy, making</span><a id="_idIndexMarker314"/><span class="koboSpan" id="kobo.503.1"> it the industry standard for large-scale applications. </span><span class="koboSpan" id="kobo.503.2">While it requires more memory than other approaches, its logarithmic search complexity delivers consistent performance even as your dataset scales.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.504.1">For memory-constrained environments</span></strong><span class="koboSpan" id="kobo.505.1">: IVF+PQ (Inverted File Index with Product Quantization) dramatically reduces memory requirements—often by 10-20x compared to raw vectors—with a modest accuracy tradeoff. </span><span class="koboSpan" id="kobo.505.2">This combination is particularly valuable for edge deployments or when embedding billions of documents.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.506.1">For frequently updated collections</span></strong><span class="koboSpan" id="kobo.507.1">: LSH provides efficient updates without rebuilding the entire index, making it suitable for streaming data applications where documents are continuously added or removed.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.508.1">Most modern vector databases default to HNSW for good reason, but understanding these tradeoffs allows you to optimize for your specific constraints when necessary. </span><span class="koboSpan" id="kobo.508.2">To illustrate the practical difference between indexing strategies, let’s compare the performance and accuracy of exact search versus HNSW indexing using FAISS:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.509.1">import numpy </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.510.1">as</span></span><span class="koboSpan" id="kobo.511.1"> np</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.512.1">import faiss</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.513.1">import </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.514.1">time</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.515.1"># Create sample data - 10,000 vectors with 128 dimensions</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.516.1">dimension = </span><span class="hljs-number"><span class="koboSpan" id="kobo.517.1">128</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.518.1">num_vectors = </span><span class="hljs-number"><span class="koboSpan" id="kobo.519.1">10000</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.520.1">vectors = np.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.521.1">random</span></span><span class="koboSpan" id="kobo.522.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.523.1">random</span></span><span class="koboSpan" id="kobo.524.1">((num_vectors, dimension)).astype(</span><span class="hljs-string"><span class="koboSpan" id="kobo.525.1">'float32'</span></span><span class="koboSpan" id="kobo.526.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.527.1">query = np.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.528.1">random</span></span><span class="koboSpan" id="kobo.529.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.530.1">random</span></span><span class="koboSpan" id="kobo.531.1">((</span><span class="hljs-number"><span class="koboSpan" id="kobo.532.1">1</span></span><span class="koboSpan" id="kobo.533.1">, dimension)).astype(</span><span class="hljs-string"><span class="koboSpan" id="kobo.534.1">'float32'</span></span><span class="koboSpan" id="kobo.535.1">)</span></p>
<div aria-label="124" epub:type="pagebreak" id="page18-3" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.536.1"># Exact search index</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.537.1">exact_index = faiss.IndexFlatL2(dimension)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.538.1">exact_index.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.539.1">add</span></span><span class="koboSpan" id="kobo.540.1">(vectors)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.541.1"># HNSW index (approximate but faster)</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.542.1">hnsw_index = faiss.IndexHNSWFlat(dimension, </span><span class="hljs-number"><span class="koboSpan" id="kobo.543.1">32</span></span><span class="koboSpan" id="kobo.544.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.545.1"># 32 connections per node</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.546.1">hnsw_index.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.547.1">add</span></span><span class="koboSpan" id="kobo.548.1">(vectors)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.549.1"># Compare search times</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.550.1">start_time = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.551.1">time</span></span><span class="koboSpan" id="kobo.552.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.553.1">time</span></span><span class="koboSpan" id="kobo.554.1">()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.555.1">exact_D, exact_I = exact_index.search(query, k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.556.1">10</span></span><span class="koboSpan" id="kobo.557.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.558.1"># Search for 10 nearest neighbors</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.559.1">exact_time = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.560.1">time</span></span><span class="koboSpan" id="kobo.561.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.562.1">time</span></span><span class="koboSpan" id="kobo.563.1">() - start_time</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.564.1">start_time = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.565.1">time</span></span><span class="koboSpan" id="kobo.566.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.567.1">time</span></span><span class="koboSpan" id="kobo.568.1">()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.569.1">hnsw_D, hnsw_I = hnsw_index.search(query, k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.570.1">10</span></span><span class="koboSpan" id="kobo.571.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.572.1">hnsw_time = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.573.1">time</span></span><span class="koboSpan" id="kobo.574.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.575.1">time</span></span><span class="koboSpan" id="kobo.576.1">() - start_time</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.577.1"># Calculate overlap (how many of the same results were found)</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.578.1">overlap = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.579.1">len</span></span><span class="koboSpan" id="kobo.580.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.581.1">set</span></span><span class="koboSpan" id="kobo.582.1">(exact_I[</span><span class="hljs-number"><span class="koboSpan" id="kobo.583.1">0</span></span><span class="koboSpan" id="kobo.584.1">]).intersection(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.585.1">set</span></span><span class="koboSpan" id="kobo.586.1">(hnsw_I[</span><span class="hljs-number"><span class="koboSpan" id="kobo.587.1">0</span></span><span class="koboSpan" id="kobo.588.1">])))</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.589.1">overlap_percentage = overlap * </span><span class="hljs-number"><span class="koboSpan" id="kobo.590.1">100</span></span><span class="koboSpan" id="kobo.591.1"> / </span><span class="hljs-number"><span class="koboSpan" id="kobo.592.1">10</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.593.1">print(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.594.1">"Exact search time: {exact_time:.6f} seconds"</span></span><span class="koboSpan" id="kobo.595.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.596.1">print(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.597.1">"HNSW search time: {hnsw_time:.6f} seconds"</span></span><span class="koboSpan" id="kobo.598.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.599.1">print(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.600.1">"Speed improvement: {exact_time/hnsw_time:.2f}x faster"</span></span><span class="koboSpan" id="kobo.601.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.602.1">print(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.603.1">"Result overlap: {overlap_percentage:.1f}%"</span></span><span class="koboSpan" id="kobo.604.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.605.1">Running this code typically produces results like:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.606.1">Exact search </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.607.1">time</span></span><span class="koboSpan" id="kobo.608.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.609.1">0.003210</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.610.1">seconds</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.611.1">HNSW search </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.612.1">time</span></span><span class="koboSpan" id="kobo.613.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.614.1">0.000412</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.615.1">seconds</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.616.1">Speed improvement: </span><span class="hljs-number"><span class="koboSpan" id="kobo.617.1">7.79</span></span><span class="koboSpan" id="kobo.618.1">x faster</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.619.1">Result overlap: </span><span class="hljs-number"><span class="koboSpan" id="kobo.620.1">90.0</span></span><span class="koboSpan" id="kobo.621.1">%</span></p>
<div aria-label="125" epub:type="pagebreak" id="page19-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.622.1">This example </span><a id="_idIndexMarker315"/><span class="koboSpan" id="kobo.623.1">demonstrates the fundamental tradeoff in vector indexing: exact search guarantees finding the true nearest neighbors but takes longer, while HNSW provides approximate results significantly faster. </span><span class="koboSpan" id="kobo.623.2">The overlap percentage shows how many of the same nearest neighbors were found by both methods.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.624.1">For small datasets like this example (10,000 vectors), the absolute time difference is minimal. </span><span class="koboSpan" id="kobo.624.2">However, as your dataset grows</span><a id="_idIndexMarker316"/><span class="koboSpan" id="kobo.625.1"> to millions or billions of vectors, exact search becomes prohibitively expensive, while HNSW maintains logarithmic scaling—making approximate indexing methods essential for production RAG systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.626.1">Here’s a diagram that can help developers choose the right indexing strategy based on their requirements:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.627.1"><img alt="Figure 4.2: Choosing an indexing strategy" src="../Images/B32363_04_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.628.1">Figure 4.2: Choosing an indexing strategy</span></p>
<div aria-label="126" epub:type="pagebreak" id="page20-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.629.1">The preceding figure</span><a id="_idIndexMarker317"/><span class="koboSpan" id="kobo.630.1"> illustrates a decision tree for selecting the appropriate indexing strategy based on your deployment constraints. </span><span class="koboSpan" id="kobo.630.2">The flowchart helps you navigate key decision points:</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.631.1">Start by assessing your dataset size</span></strong><span class="koboSpan" id="kobo.632.1">: For small collections (under 100K vectors), exact search remains viable and provides perfect accuracy.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.633.1">Consider your memory constraints</span></strong><span class="koboSpan" id="kobo.634.1">: If memory is limited, follow the left branch toward compression</span><a id="_idIndexMarker318"/><span class="koboSpan" id="kobo.635.1"> techniques like </span><strong class="keyWord"><span class="koboSpan" id="kobo.636.1">Product Quantization</span></strong><span class="koboSpan" id="kobo.637.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.638.1">PQ</span></strong><span class="koboSpan" id="kobo.639.1">).</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.640.1">Evaluate update frequency</span></strong><span class="koboSpan" id="kobo.641.1">: If your application requires frequent index updates, prioritize methods like LSH that support efficient updates.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.642.1">Assess search speed requirements</span></strong><span class="koboSpan" id="kobo.643.1">: For applications demanding ultra-low latency, HNSW typically provides the fastest search times once built.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.644.1">Balance with accuracy needs</span></strong><span class="koboSpan" id="kobo.645.1">: As you move downward in the flowchart, consider the accuracy-efficiency tradeoff based on your application’s tolerance for approximate results.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.646.1">For most production RAG applications, you’ll likely end up with HNSW or a combined approach like IVF+HNSW, which clusters vectors first (IVF) and then builds efficient graph structures (HNSW) within each cluster. </span><span class="koboSpan" id="kobo.646.2">This combination delivers excellent performance across a wide range of scenarios.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.647.1">To improve retrieval, documents must be processed and structured effectively. </span><span class="koboSpan" id="kobo.647.2">The next section explores loading various</span><a id="_idIndexMarker319"/><span class="koboSpan" id="kobo.648.1"> document types and handling multi-modal cont</span><a id="_idTextAnchor172"/><span class="koboSpan" id="kobo.649.1">ent.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.650.1">Vector libraries, like Facebook (Meta) Faiss or Spotify Annoy, provide functionality for working with vector data. </span><span class="koboSpan" id="kobo.650.2">They typically offer different</span><a id="_idIndexMarker320"/><span class="koboSpan" id="kobo.651.1"> implementations of the </span><strong class="keyWord"><span class="koboSpan" id="kobo.652.1">ANN</span></strong><span class="koboSpan" id="kobo.653.1"> algorithm, such as clustering or tree-based methods, and allow users to perform vector similarity searches for various applications. </span><span class="koboSpan" id="kobo.653.2">Let’s quickly go through a few of the most popular ones:</span></p>
<div aria-label="127" epub:type="pagebreak" id="page21-3" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.654.1">Faiss</span></strong><span class="koboSpan" id="kobo.655.1"> is a library developed </span><a id="_idIndexMarker321"/><span class="koboSpan" id="kobo.656.1">by Meta (previously Facebook) that provides efficient similarity search and clustering of dense vectors. </span><span class="koboSpan" id="kobo.656.2">It offers various indexing algorithms, including PQ, LSH, and HNSW. </span><span class="koboSpan" id="kobo.656.3">Faiss is widely used for large-scale vector search tasks and supports both CPU and GPU acceleration.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.657.1">Annoy</span></strong><span class="koboSpan" id="kobo.658.1"> is a C++ library for approximate nearest neighbor search in high-dimensional spaces maintained </span><a id="_idIndexMarker322"/><span class="koboSpan" id="kobo.659.1">and developed by Spotify, implementing the Annoy algorithm based on a forest of random projection trees.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.660.1">hnswlib</span></strong><span class="koboSpan" id="kobo.661.1"> is a C++ library for </span><a id="_idIndexMarker323"/><span class="koboSpan" id="kobo.662.1">approximate nearest-neighbor search using the HNSW algorithm.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.663.1">Non-Metric Space Library </span></strong><span class="koboSpan" id="kobo.664.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.665.1">nmslib</span></strong><span class="koboSpan" id="kobo.666.1">) supports </span><a id="_idIndexMarker324"/><span class="koboSpan" id="kobo.667.1">various indexing algorithms like HNSW, SW-graph, and SPTAG.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.668.1">SPTAG </span></strong><span class="koboSpan" id="kobo.669.1">by Microsoft implements a </span><a id="_idIndexMarker325"/><span class="koboSpan" id="kobo.670.1">distributed ANN. </span><span class="koboSpan" id="kobo.670.2">It comes with a k-d tree and relative neighborhood graph (SPTAG-KDT), and a balanced k-means tree and relative neighborhood graph (SPTAG-BKT).</span></li>
</ul>
<div>
<div class="note" id="_idContainer058">
<p class="normal"><span class="koboSpan" id="kobo.671.1">There are a lot more vector search libraries you can choose from. </span><span class="koboSpan" id="kobo.671.2">You can get a complete overview at </span><a href="https://github.com/erikbern/ann-benchmarks"><span class="url"><span class="koboSpan" id="kobo.672.1">https://github.com/erikbern/ann-benchmarks</span></span></a><span class="koboSpan" id="kobo.673.1">.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.674.1">When implementing vector storage solutions, consider:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.675.1">The tradeoff between exact and approximate search</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.676.1">Memory constraints and scaling requirements</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.677.1">The need for hybrid search capabilities combining vector and traditional search</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.678.1">Multi-modal data support requirements</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.679.1">Integration costs and maintenance complexity</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.680.1">For many applications, a hybrid approach combining vector search with traditional database capabilities provides the</span><a id="_idIndexMarker326"/><span class="koboSpan" id="kobo.681.1"> most flexibl</span><a id="_idTextAnchor173"/><span class="koboSpan" id="kobo.682.1">e solution.</span></p>
<h1 class="heading-1" id="_idParaDest-99"><a id="_idTextAnchor174"/><span class="koboSpan" id="kobo.683.1">Breaking down the RAG pipeline</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.684.1">Think of the RAG pipeline as an assembly line in a library, where raw materials (documents) get transformed into a searchable knowledge base that can answer questions. </span><span class="koboSpan" id="kobo.684.2">Let us walk through how each component </span><a id="_idIndexMarker327"/><span class="koboSpan" id="kobo.685.1">plays its part.</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.686.1">Document processing – the foundation</span></strong></li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.687.1">Document processing is like preparing books for a library. </span><span class="koboSpan" id="kobo.687.2">When documents first enter the system, they need to be:</span></p>
<ul>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.688.1">Loaded using document loaders appropriate for their format (PDF, HTML, text, etc.)</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.689.1">Transformed into a standard format that the system can work with</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.690.1">Split into smaller, meaningful chunks that are easier to process and retrieve</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.691.1">For example, when processing a textbook, we might break it into chapter-sized or paragraph-sized chunks while preserving important context in metadata.</span></p>
<div aria-label="128" epub:type="pagebreak" id="page22-3" role="doc-pagebreak"/>
<ol>
<li class="numberedList" value="2"><strong class="keyWord"><span class="koboSpan" id="kobo.692.1">Vector indexing – creating the card catalog</span></strong></li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.693.1">Once documents are processed, we need a way to make them searchable. </span><span class="koboSpan" id="kobo.693.2">This is where vector indexing comes in. </span><span class="koboSpan" id="kobo.693.3">Here’s how it works:</span></p>
<ul>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.694.1">An embedding model converts each document chunk into a vector (think of it as capturing the document’s meaning in a list of numbers)</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.695.1">These vectors are organized in a special data structure (the vector store) that makes them easy to search</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.696.1">The vector store also maintains connections between these vectors and their original documents</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.697.1">This is similar to how a library’s card catalog organizes books by subject, making it easy to find related materials.</span></p>
<ol>
<li class="numberedList" value="3"><strong class="keyWord"><span class="koboSpan" id="kobo.698.1">Vector stores – the organized shelves</span></strong></li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.699.1">Vector stores are like the organized shelves in our library. </span><span class="koboSpan" id="kobo.699.2">They:</span></p>
<ul>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.700.1">Store both the document vectors and the original document content</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.701.1">Provide efficient ways to search through the vectors</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.702.1">Offer different organization methods (like HNSW or IVF) that balance speed and accuracy</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.703.1">For example, using FAISS (a popular vector store), we might organize our vectors in a hierarchical structure that lets us quickly narrow down which documents to examine in detail.</span></p>
<ol>
<li class="numberedList" value="4"><strong class="keyWord"><span class="koboSpan" id="kobo.704.1">Retrieval – finding the right books</span></strong></li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.705.1">Retrieval is where everything comes together. </span><span class="koboSpan" id="kobo.705.2">When a question comes in:</span></p>
<ul>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.706.1">The question gets converted into a vector using the same embedding model</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.707.1">The vector store finds documents whose vectors are most similar to the question vector</span></li>
</ul>
<p class="normal-one"><span class="koboSpan" id="kobo.708.1">The retriever might apply additional logic, like:</span></p>
<ul>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.709.1">Removing duplicate information</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.710.1">Balancing relevance and diversity</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.711.1">Combining results from different search methods</span></li>
</ul>
<div aria-label="129" epub:type="pagebreak" id="page23-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.712.1">A basic RAG implementation</span><a id="_idIndexMarker328"/><span class="koboSpan" id="kobo.713.1"> looks like this:</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.714.1"># For query transformation</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.715.1">from</span></span><span class="koboSpan" id="kobo.716.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.717.1">import</span></span><span class="koboSpan" id="kobo.718.1"> PromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.719.1">from</span></span><span class="koboSpan" id="kobo.720.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.721.1">import</span></span><span class="koboSpan" id="kobo.722.1"> ChatOpenAI</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.723.1">from</span></span><span class="koboSpan" id="kobo.724.1"> langchain_core.output_parsers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.725.1">import</span></span><span class="koboSpan" id="kobo.726.1"> StrOutputParser</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.727.1"># For basic RAG implementation</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.728.1">from</span></span><span class="koboSpan" id="kobo.729.1"> langchain_community.document_loaders </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.730.1">import</span></span><span class="koboSpan" id="kobo.731.1"> JSONLoader</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.732.1">from</span></span><span class="koboSpan" id="kobo.733.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.734.1">import</span></span><span class="koboSpan" id="kobo.735.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.736.1">from</span></span><span class="koboSpan" id="kobo.737.1"> langchain_community.vectorstores </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.738.1">import</span></span><span class="koboSpan" id="kobo.739.1"> FAISS</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.740.1"># 1. </span><span class="koboSpan" id="kobo.740.2">Load documents</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.741.1">loader = JSONLoader(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.742.1">    file_path=</span><span class="hljs-string"><span class="koboSpan" id="kobo.743.1">"knowledge_base.json"</span></span><span class="koboSpan" id="kobo.744.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.745.1">    jq_schema=</span><span class="hljs-string"><span class="koboSpan" id="kobo.746.1">".[].content"</span></span><span class="koboSpan" id="kobo.747.1">,  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.748.1"># This extracts the content field from each array item</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.749.1">    text_content=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.750.1">True</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.751.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.752.1">documents = loader.load()</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.753.1"># 2. </span><span class="koboSpan" id="kobo.753.2">Convert to vectors</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.754.1">embedder = OpenAIEmbeddings()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.755.1">embeddings = embedder.embed_documents([doc.page_content </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.756.1">for</span></span><span class="koboSpan" id="kobo.757.1"> doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.758.1">in</span></span><span class="koboSpan" id="kobo.759.1"> documents])</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.760.1"># 3. </span><span class="koboSpan" id="kobo.760.2">Store in vector database</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.761.1">vector_db = FAISS.from_documents(documents, embedder)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.762.1"># 4. </span><span class="koboSpan" id="kobo.762.2">Retrieve similar docs</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.763.1">query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.764.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.765.1">What are the effects of climate change?"</span></span></p>
<p class="normal"><span class="koboSpan" id="kobo.766.1">results = vector_db.similarity_search(query)This implementation covers the core RAG workflow: document loading, embedding, storage, and retrieval.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.767.1">Building a RAG system with LangChain requires understanding two fundamental building blocks, which we should discuss a bit more in detail: </span><strong class="keyWord"><span class="koboSpan" id="kobo.768.1">document loaders</span></strong><span class="koboSpan" id="kobo.769.1"> and </span><strong class="keyWord"><span class="koboSpan" id="kobo.770.1">retrievers</span></strong><span class="koboSpan" id="kobo.771.1">. </span><span class="koboSpan" id="kobo.771.2">Let’s explore how these components </span><a id="_idIndexMarker329"/><span class="koboSpan" id="kobo.772.1">work together to create effective retr</span><a id="_idTextAnchor175"/><span class="koboSpan" id="kobo.773.1">ieval systems.</span></p>
<div aria-label="130" epub:type="pagebreak" id="page24-3" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-100"><a id="_idTextAnchor176"/><span class="koboSpan" id="kobo.774.1">Document processing</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.775.1">LangChain provides a comprehensive</span><a id="_idIndexMarker330"/><span class="koboSpan" id="kobo.776.1"> system for loading documents from various sources through document loaders. </span><span class="koboSpan" id="kobo.776.2">A document loader is a component in LangChain that transforms various data sources into a standardized document format that can be used throughout the LangChain ecosystem. </span><span class="koboSpan" id="kobo.776.3">Each document contains the actual content and associated metadata.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.777.1">Document loaders serve as the foundation for RAG systems by:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.778.1">Converting diverse data sources into a uniform format</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.779.1">Extracting text and metadata from files</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.780.1">Preparing documents for further processing (like chunking or embedding)</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.781.1">LangChain supports loading documents from a wide range of document types and sources through specialized loaders, for example:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.782.1">PDFs</span></strong><span class="koboSpan" id="kobo.783.1">: Using PyPDFLoader</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.784.1">HTML</span></strong><span class="koboSpan" id="kobo.785.1">: WebBaseLoader for extracting web page text</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.786.1">Plain text</span></strong><span class="koboSpan" id="kobo.787.1">: TextLoader for raw text inputs</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.788.1">WebBaseLoader </span></strong><span class="koboSpan" id="kobo.789.1">for web page content extraction</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.790.1">ArxivLoader </span></strong><span class="koboSpan" id="kobo.791.1">for scientific papers</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.792.1">WikipediaLoader </span></strong><span class="koboSpan" id="kobo.793.1">for encyclopedia entries</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.794.1">YoutubeLoader </span></strong><span class="koboSpan" id="kobo.795.1">for video transcripts</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.796.1">ImageCaptionLoader </span></strong><span class="koboSpan" id="kobo.797.1">for image content</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.798.1">You may have noticed some non-text content types in the preceding list. </span><span class="koboSpan" id="kobo.798.2">Advanced RAG systems can handle non-text data; for example, image embeddings or audio transcripts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.799.1">The following table organizes LangChain document loaders into a comprehensive table:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.800.1">Category</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.801.1">Description</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.802.1">Notable Examples</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.803.1">Common Use Cases</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.804.1">File Systems</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.805.1">Load from local files</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.806.1">TextLoader, CSVLoader, PDFLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.807.1">Processing local documents, data files</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.808.1">Web Content</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.809.1">Extract from online sources</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.810.1">WebBaseLoader, RecursiveURLLoader, SitemapLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.811.1">Web scraping, content aggregation</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<div aria-label="131" epub:type="pagebreak" id="page25-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.812.1">Cloud Storage</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.813.1">Access cloud-hosted files</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.814.1">S3DirectoryLoader, GCSFileLoader, DropboxLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.815.1">Enterprise data integration</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.816.1">Databases</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.817.1">Load from structured data stores</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.818.1">MongoDBLoader, SnowflakeLoader, BigQueryLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.819.1">Business intelligence, data analysis</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.820.1">Social Media</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.821.1">Import social platform content</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.822.1">TwitterTweetLoader, RedditPostsLoader, DiscordChatLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.823.1">Social media analysis</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.824.1">Productivity Tools</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.825.1">Access workspace documents</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.826.1">NotionDirectoryLoader, SlackDirectoryLoader, TrelloLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.827.1">Knowledge base creation</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.828.1">Scientific Sources</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.829.1">Load academic content</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.830.1">ArxivLoader, PubMedLoader</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.831.1">Research applications</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.832.1">Table 4.3: Document loaders in LangChain</span></p>
<p class="normal"><span class="koboSpan" id="kobo.833.1">Finally, modern document</span><a id="_idIndexMarker331"/><span class="koboSpan" id="kobo.834.1"> loaders offer several sophisticated capabilities:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.835.1">Concurrent loading for better performance</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.836.1">Metadata extraction and preservation</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.837.1">Format-specific parsing (like table extraction from PDFs)</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.838.1">Error handling and validation</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.839.1">Integration with transformation pipelines</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.840.1">Let’s go through an example of loading a JSON file. </span><span class="koboSpan" id="kobo.840.2">Here’s a typical pattern for using a document loader:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.841.1">from</span></span><span class="koboSpan" id="kobo.842.1"> langchain_community.document_loaders import JSONLoader</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.843.1"># Load a json file</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.844.1">loader = JSONLoader(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.845.1">file_path</span></span><span class="koboSpan" id="kobo.846.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.847.1">"knowledge_base.json"</span></span><span class="koboSpan" id="kobo.848.1">,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.849.1">jq_schema</span></span><span class="koboSpan" id="kobo.850.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.851.1">".[].content"</span></span><span class="koboSpan" id="kobo.852.1">,  # This extracts the content field </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.853.1">from</span></span><span class="koboSpan" id="kobo.854.1"> each array item</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.855.1">text_content</span></span><span class="koboSpan" id="kobo.856.1">=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.857.1">True</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.858.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.859.1">documents = loader.load()</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.860.1">print</span></span><span class="koboSpan" id="kobo.861.1">(documents)</span></p>
<div aria-label="132" epub:type="pagebreak" id="page26-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.862.1">Document loaders come with a standard </span><code class="inlineCode"><span class="koboSpan" id="kobo.863.1">.load()</span></code><span class="koboSpan" id="kobo.864.1"> method interface that returns documents in LangChain’s document format. </span><span class="koboSpan" id="kobo.864.2">The initialization is source-specific. </span><span class="koboSpan" id="kobo.864.3">After loading, documents often need processing before</span><a id="_idIndexMarker332"/><span class="koboSpan" id="kobo.865.1"> storage and retrieval, and selecting the right chunking strategy determines the relevance and diversity of AI-generated responses</span><a id="_idTextAnchor177"/><span class="koboSpan" id="kobo.866.1">.</span></p>
<h3 class="heading-3" id="_idParaDest-101"><a id="_idTextAnchor178"/><span class="koboSpan" id="kobo.867.1">Chunking strategies</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.868.1">Chunking—how you divide documents into smaller pieces—can dramatically impact your RAG system’s performance. </span><span class="koboSpan" id="kobo.868.2">Poor chunking </span><a id="_idIndexMarker333"/><span class="koboSpan" id="kobo.869.1">can break apart related concepts, lose critical context, and ultimately lead to</span><a id="_idIndexMarker334"/><span class="koboSpan" id="kobo.870.1"> irrelevant retrieval results. </span><span class="koboSpan" id="kobo.870.2">The way you chunk documents affects:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.871.1">Retrieval accuracy</span></strong><span class="koboSpan" id="kobo.872.1">: Well-formed chunks maintain semantic coherence, making them easier to match with relevant queries</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.873.1">Context preservation</span></strong><span class="koboSpan" id="kobo.874.1">: Poor chunking can split related information, causing knowledge gaps</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.875.1">Response quality</span></strong><span class="koboSpan" id="kobo.876.1">: When the LLM receives fragmented or irrelevant chunks, it generates less accurate responses</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.877.1">Let’s explore a hierarchy of chunking approaches, from simple to sophisticated, to help you implement the most effective strategy for your specific use ca</span><a id="_idTextAnchor179"/><span class="koboSpan" id="kobo.878.1">se.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.879.1">Fixed-size chunking</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.880.1">The most basic approach divides text into</span><a id="_idIndexMarker335"/><span class="koboSpan" id="kobo.881.1"> chunks of a specified length without considering content structure:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.882.1">from</span></span><span class="koboSpan" id="kobo.883.1"> langchain_text_splitters import CharacterTextSplitter</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.884.1">text_splitter = CharacterTextSplitter(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.885.1">separator</span></span><span class="koboSpan" id="kobo.886.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.887.1">" "</span></span><span class="koboSpan" id="kobo.888.1">,   # Split on spaces </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.889.1">to</span></span><span class="koboSpan" id="kobo.890.1"> avoid breaking words</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.891.1">chunk_size</span></span><span class="koboSpan" id="kobo.892.1">=200,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.893.1">chunk_overlap</span></span><span class="koboSpan" id="kobo.894.1">=20</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.895.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.896.1">chunks = text_splitter.split_documents(documents)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.897.1">print</span></span><span class="koboSpan" id="kobo.898.1">(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.899.1">"Generated {len(chunks)} chunks from document"</span></span><span class="koboSpan" id="kobo.900.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.901.1">Fixed-size chunking is good for quick prototyping or when document structure is relatively uniform, however, it often splits text at </span><a id="_idIndexMarker336"/><span class="koboSpan" id="kobo.902.1">awkward positions, breaking sentences, paragraphs, or logical u</span><a id="_idTextAnchor180"/><span class="koboSpan" id="kobo.903.1">nits.</span></p>
<div aria-label="133" epub:type="pagebreak" id="page27-2" role="doc-pagebreak"/>
<h4 class="heading-4"><span class="koboSpan" id="kobo.904.1">Recursive character chunking</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.905.1">This method respects natural text </span><a id="_idIndexMarker337"/><span class="koboSpan" id="kobo.906.1">boundaries by recursively applying different separators:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.907.1">from</span></span><span class="koboSpan" id="kobo.908.1"> langchain_text_splitters </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.909.1">import</span></span><span class="koboSpan" id="kobo.910.1"> RecursiveCharacterTextSplitter</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.911.1">text_splitter = RecursiveCharacterTextSplitter(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.912.1">    separators=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.913.1">"\n\n"</span></span><span class="koboSpan" id="kobo.914.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.915.1">"\n"</span></span><span class="koboSpan" id="kobo.916.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.917.1">". </span><span class="koboSpan" id="kobo.917.2">"</span></span><span class="koboSpan" id="kobo.918.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.919.1">" "</span></span><span class="koboSpan" id="kobo.920.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.921.1">""</span></span><span class="koboSpan" id="kobo.922.1">],</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.923.1">    chunk_size=</span><span class="hljs-number"><span class="koboSpan" id="kobo.924.1">150</span></span><span class="koboSpan" id="kobo.925.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.926.1">    chunk_overlap=</span><span class="hljs-number"><span class="koboSpan" id="kobo.927.1">20</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.928.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.929.1">document = </span><span class="hljs-string"><span class="koboSpan" id="kobo.930.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.931.1">document = """</span></span><span class="hljs-comment"><span class="koboSpan" id="kobo.932.1"># Introduction to RAG</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.933.1">Retrieval-Augmented Generation (RAG) combines retrieval systems </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.934.1">with</span></span><span class="koboSpan" id="kobo.935.1"> generative AI models.</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.936.1">It helps address hallucinations by grounding responses </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.937.1">in</span></span><span class="koboSpan" id="kobo.938.1"> retrieved information.</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.939.1">## Key Components</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.940.1">RAG consists of several components:</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.941.1">1.</span></span><span class="koboSpan" id="kobo.942.1"> Document processing</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.943.1">2.</span></span><span class="koboSpan" id="kobo.944.1"> Vector embedding</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.945.1">3.</span></span><span class="koboSpan" id="kobo.946.1"> Retrieval</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.947.1">4.</span></span><span class="koboSpan" id="kobo.948.1"> Augmentation</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.949.1">5.</span></span><span class="koboSpan" id="kobo.950.1"> Generation</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.951.1">### Document Processing</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.952.1">This step involves loading </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.953.1">and</span></span><span class="koboSpan" id="kobo.954.1"> chunking documents appropriately.</span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.955.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.956.1">chunks = text_splitter.split_text(document)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.957.1">print(chunks)</span></span></p>
<p class="normal"><span class="koboSpan" id="kobo.958.1">Here are the chunks:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.959.1">['# Introduction to RAG\nRetrieval-Augmented Generation (RAG) combines retrieval systems with generative AI models.', 'It helps address hallucinations by grounding responses in retrieved information.', '## Key Components\nRAG consists of several components:\n1. </span><span class="koboSpan" id="kobo.959.2">Document processing\n2. </span><span class="koboSpan" id="kobo.959.3">Vector embedding\n3. </span><span class="koboSpan" id="kobo.959.4">Retrieval\n4. </span><span class="koboSpan" id="kobo.959.5">Augmentation\n5. </span><span class="koboSpan" id="kobo.959.6">Generation', '### Document Processing\nThis step involves loading and chunking documents appropriately.']</span></p>
<div aria-label="134" epub:type="pagebreak" id="page28-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.960.1">How it works is that the splitter first attempts to divide text at paragraph breaks (</span><code class="inlineCode"><span class="koboSpan" id="kobo.961.1">\n\n</span></code><span class="koboSpan" id="kobo.962.1">). </span><span class="koboSpan" id="kobo.962.2">If the resulting chunks are still too large, it tries the next separator (</span><code class="inlineCode"><span class="koboSpan" id="kobo.963.1">\n</span></code><span class="koboSpan" id="kobo.964.1">), and so on. </span><span class="koboSpan" id="kobo.964.2">This approach preserves natural text boundaries while maintaining reasonable chunk sizes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.965.1">Recursive character chunking</span><a id="_idIndexMarker338"/><span class="koboSpan" id="kobo.966.1"> is the recommended default strategy for most applications. </span><span class="koboSpan" id="kobo.966.2">It works well for a wide range of document types and provides a good balance between preserving context and maintaining manageable chunk</span><a id="_idTextAnchor181"/><span class="koboSpan" id="kobo.967.1"> sizes.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.968.1">Document-specific chunking</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.969.1">Different document types have different structures. </span><span class="koboSpan" id="kobo.969.2">Document-specific chunking adapts to these structures. </span><span class="koboSpan" id="kobo.969.3">An implementation </span><a id="_idIndexMarker339"/><span class="koboSpan" id="kobo.970.1">could involve using different specialized splitters based on document type using </span><code class="inlineCode"><span class="koboSpan" id="kobo.971.1">if</span></code><span class="koboSpan" id="kobo.972.1"> statements. </span><span class="koboSpan" id="kobo.972.2">For example, we could be using a </span><code class="inlineCode"><span class="koboSpan" id="kobo.973.1">MarkdownTextSplitter</span></code><span class="koboSpan" id="kobo.974.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.975.1">PythonCodeTextSplitter</span></code><span class="koboSpan" id="kobo.976.1">, or </span><code class="inlineCode"><span class="koboSpan" id="kobo.977.1">HTMLHeaderTextSplitter</span></code><span class="koboSpan" id="kobo.978.1"> depending on the content type being markdown, Python, or HTML.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.979.1">This can be useful when working with specialized document formats where structure matters – code repositories, technical documentation, markdown articles, or similar. </span><span class="koboSpan" id="kobo.979.2">Its advantage is that it preserves logical document structure, maintains functional units together (like code functions, markdown sections), and improves retrieval relevance for domain-specific </span><a id="_idTextAnchor182"/><span class="koboSpan" id="kobo.980.1">queries.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.981.1">Semantic chunking</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.982.1">Unlike previous approaches</span><a id="_idIndexMarker340"/><span class="koboSpan" id="kobo.983.1"> that rely on textual separators, semantic chunking analyzes the meaning of content to determine chunk boundaries.</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.984.1">from</span></span><span class="koboSpan" id="kobo.985.1"> langchain_experimental.text_splitter </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.986.1">import</span></span><span class="koboSpan" id="kobo.987.1"> SemanticChunker</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.988.1">from</span></span><span class="koboSpan" id="kobo.989.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.990.1">import</span></span><span class="koboSpan" id="kobo.991.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.992.1">embeddings = OpenAIEmbeddings()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.993.1">text_splitter = SemanticChunker(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.994.1">    embeddings=embeddings,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.995.1">    add_start_index=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.996.1">True</span></span><span class="koboSpan" id="kobo.997.1">  # Include position metadata</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.998.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.999.1">chunks = text_splitter.split_text(document)</span></p>
<div aria-label="135" epub:type="pagebreak" id="page29-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1000.1">These are the chunks:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1001.1">['# Introduction to RAG\nRetrieval-Augmented Generation (RAG) combines retrieval systems with generative AI models. </span><span class="koboSpan" id="kobo.1001.2">It helps address hallucinations by grounding responses in retrieved information. </span><span class="koboSpan" id="kobo.1001.3">## Key Components\nRAG consists of several components:\n1. </span><span class="koboSpan" id="kobo.1001.4">Document processing\n2. </span><span class="koboSpan" id="kobo.1001.5">Vector embedding\n3. </span><span class="koboSpan" id="kobo.1001.6">Retrieval\n4.',</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1002.1"> 'Augmentation\n5. </span><span class="koboSpan" id="kobo.1002.2">Generation\n\n### Document Processing\nThis step involves loading and chunking documents appropriately. </span><span class="koboSpan" id="kobo.1002.3">']</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1003.1">Here’s how the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1004.1">SemanticChunker</span></code><span class="koboSpan" id="kobo.1005.1"> works:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1006.1">Splits text into sentences</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1007.1">Creates embeddings for groups of sentences (determined by </span><code class="inlineCode"><span class="koboSpan" id="kobo.1008.1">buffer_size</span></code><span class="koboSpan" id="kobo.1009.1">)</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1010.1">Measures semantic similarity between adjacent groups</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1011.1">Identifies natural breakpoints where topics or concepts change</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1012.1">Creates chunks that preserve semantic coherence</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1013.1">You may use semantic chunking</span><a id="_idIndexMarker341"/><span class="koboSpan" id="kobo.1014.1"> for complex technical documents where semantic cohesion is crucial for accurate retrieval and when you’re willing to spend additional compute/costs on embedding generation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1015.1">Benefits include chunk creation based on actual meaning rather than superficial text features and keeping related concepts together even when they span traditional separator b</span><a id="_idTextAnchor183"/><span class="koboSpan" id="kobo.1016.1">oundaries.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1017.1">Agent-based chunking</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1018.1">This experimental approach uses LLMs </span><a id="_idIndexMarker342"/><span class="koboSpan" id="kobo.1019.1">to intelligently divide text based on semantic analysis and content understanding in the following manner:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1020.1">Analyze the document’s structure and content</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1021.1">Identify natural breakpoints based on topic shifts</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1022.1">Determine optimal chunk boundaries that preserve meaning</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1023.1">Return a list of starting positions for creating chunks</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1024.1">This type of chunking can be useful for exceptionally complex documents where standard splitting methods fail to preserve critical relationships between concepts. </span><span class="koboSpan" id="kobo.1024.2">This approach is particularly useful when:</span></p>
<div aria-label="136" epub:type="pagebreak" id="page30-2" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1025.1">Documents contain intricate logical flows that need to be preserved</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1026.1">Content requires domain-specific understanding to chunk appropriately</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1027.1">Maximum retrieval accuracy justifies the additional expense of LLM-based processing</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1028.1">The limitations are that it comes with a higher computational cost and latency, and that chunk sizes are less p</span><a id="_idTextAnchor184"/><span class="koboSpan" id="kobo.1029.1">redictable.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1030.1">Multi-modal chunking</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1031.1">Modern documents often contain a </span><a id="_idIndexMarker343"/><span class="koboSpan" id="kobo.1032.1">mix of text, tables, images, and code. </span><span class="koboSpan" id="kobo.1032.2">Multi-modal chunking handles these different content types appropriately.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1033.1">We can imagine the following process for multi-modal content:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1034.1">Extract text, images, and tables separately</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1035.1">Process text with appropriate text chunker</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1036.1">Process tables to preserve structure</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1037.1">For images: generate captions or extract text via OCR or a vision LLM</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1038.1">Create metadata linking related elements</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1039.1">Embed each element appropriately</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1040.1">In practice, you would use specialized libraries such as unstructured for document parsing, vision models for image</span><a id="_idIndexMarker344"/><span class="koboSpan" id="kobo.1041.1"> understanding, and table extraction tools for str</span><a id="_idTextAnchor185"/><span class="koboSpan" id="kobo.1042.1">uctured data.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1043.1">Choosing the right chunking strategy</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1044.1">Your chunking strategy should </span><a id="_idIndexMarker345"/><span class="koboSpan" id="kobo.1045.1">be guided by document characteristics, retrieval needs, and computational resources as the following table illustrates:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table004">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1046.1">Factor</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1047.1">Condition</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1048.1">Recommended Strategy</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1049.1">Document Characteristics</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1050.1">Highly structured documents (markdown, code)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1051.1">Document-specific chunking</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1052.1">Complex technical content</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1053.1">Semantic chunking</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1054.1">Mixed media</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1055.1">Multi-modal approaches</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1056.1">Retrieval Needs</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1057.1">Fact-based QA</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1058.1">Smaller chunks (100-300 tokens)</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1059.1">Complex reasoning</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1060.1">Larger chunks (500-1000 tokens)</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<div aria-label="137" epub:type="pagebreak" id="page31-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1061.1">Context-heavy answers</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1062.1">Sliding window with significant overlap</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1063.1">Computational Resources</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1064.1">Limited API budget</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1065.1">Basic recursive chunking</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1066.1">Performance-critical</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.1067.1">Pre-computed semantic chunks</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.1068.1">Table 4.4: Comparison of chunking strategies</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1069.1">We recommend starting with Level 2 (Recursive Character Chunking) as your baseline, then experiment with more advanced strategies if retrieval quality needs improvement.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1070.1">For most RAG applications, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1071.1">RecursiveCharacterTextSplitter</span></code><span class="koboSpan" id="kobo.1072.1"> with appropriate chunk size and overlap settings provides an excellent balance of simplicity, performance, and retrieval quality. </span><span class="koboSpan" id="kobo.1072.2">As your system matures, you can evaluate whether more sophisticated chunking strategies deliver meaningful improvements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1073.1">However, it is often critical to performance to experiment with different chunk sizes specific to your use case and document types. </span><span class="koboSpan" id="kobo.1073.2">Please refer to </span><a href="E_Chapter_8.xhtml#_idTextAnchor390"><em class="italic"><span class="koboSpan" id="kobo.1074.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.1075.1"> for testing and benchmarking strategies.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1076.1">The next section covers </span><a id="_idIndexMarker346"/><span class="koboSpan" id="kobo.1077.1">semantic search, hybrid methods, and advanced ranking techniques.</span><a id="_idTextAnchor186"/></p>
<h3 class="heading-3" id="_idParaDest-102"><a id="_idTextAnchor187"/><span class="koboSpan" id="kobo.1078.1">Retrieval</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1079.1">Retrieval integrates a vector store with other LangChain components for simplified querying and compatibility. </span><span class="koboSpan" id="kobo.1079.2">Retrieval</span><a id="_idIndexMarker347"/><span class="koboSpan" id="kobo.1080.1"> systems form a crucial bridge between unstructured queries and relevant documents.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1081.1">In LangChain, a retriever is fundamentally an interface that accepts natural language queries and returns relevant documents. </span><span class="koboSpan" id="kobo.1081.2">Let’s explore how this works in detail.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1082.1">At its heart, a retriever in LangChain follows a</span><a id="_idIndexMarker348"/><span class="koboSpan" id="kobo.1083.1"> simple yet powerful pattern:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1084.1">Input</span></strong><span class="koboSpan" id="kobo.1085.1">: Takes a query as a string</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1086.1">Processing</span></strong><span class="koboSpan" id="kobo.1087.1">: Applies retrieval logic specific to the implementation</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1088.1">Output</span></strong><span class="koboSpan" id="kobo.1089.1">: Returns a list of document objects, each containing:</span><ul><li class="bulletList level-2"><code class="inlineCode"><span class="koboSpan" id="kobo.1090.1">page_content</span></code><span class="koboSpan" id="kobo.1091.1">: The actual document content</span></li>
<li class="bulletList level-2"><code class="inlineCode"><span class="koboSpan" id="kobo.1092.1">metadata</span></code><span class="koboSpan" id="kobo.1093.1">: Associated information like document ID or source</span></li>
</ul></li>
</ul>
<div aria-label="138" epub:type="pagebreak" id="page32-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1094.1">This diagram (from the LangChain documentation) illustrates this relationship.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1095.1"><img alt="Figure 4.3: The relationship between query, retriever, and documents" src="../Images/B32363_04_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1096.1">Figure 4.3: The relationship between query, retriever, and documents</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1097.1">LangChain offers a rich ecosystem of retrievers, each designed to solve specific information retrieval challenges</span><a id="_idTextAnchor188"/><span class="koboSpan" id="kobo.1098.1">.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1099.1">LangChain retrievers</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1100.1">The retrievers can be broadly</span><a id="_idIndexMarker349"/><span class="koboSpan" id="kobo.1101.1"> categorized into a few key groups that serve different use cases and implementation needs:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1102.1">Core infrastructure retrievers</span></strong><span class="koboSpan" id="kobo.1103.1"> include both self-hosted options like ElasticsearchRetriever and cloud-based </span><a id="_idIndexMarker350"/><span class="koboSpan" id="kobo.1104.1">solutions from major providers like Amazon, Google, and Microsoft.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1105.1">External knowledge retrievers </span></strong><span class="koboSpan" id="kobo.1106.1">tap</span><a id="_idIndexMarker351"/><span class="koboSpan" id="kobo.1107.1"> into external and established knowledge bases. </span><span class="koboSpan" id="kobo.1107.2">ArxivRetriever, WikipediaRetriever, and TavilySearchAPI stand out here, offering direct access to academic papers, encyclopedia entries, and web content respectively.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1108.1">Algorithmic retrievers</span></strong><span class="koboSpan" id="kobo.1109.1"> include several classic information retrieval methods. </span><span class="koboSpan" id="kobo.1109.2">The BM25 and TF-IDF retrievers excel at lexical search, while kNN retrievers handle semantic similarity searches. </span><span class="koboSpan" id="kobo.1109.3">Each </span><a id="_idIndexMarker352"/><span class="koboSpan" id="kobo.1110.1">of these algorithms brings its own strengths – BM25 for keyword precision, TF-IDF for document classification, and kNN for similarity matching.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1111.1">Advanced/Specialized retrievers</span></strong><span class="koboSpan" id="kobo.1112.1"> often address specific performance requirements or resource constraints that</span><a id="_idIndexMarker353"/><span class="koboSpan" id="kobo.1113.1"> may arise in production environments. </span><span class="koboSpan" id="kobo.1113.2">LangChain offers specialized retrievers with unique capabilities. </span><span class="koboSpan" id="kobo.1113.3">NeuralDB provides CPU-optimized retrieval, while LLMLingua focuses on document compression.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1114.1">Integration retrievers</span></strong><span class="koboSpan" id="kobo.1115.1"> connect </span><a id="_idIndexMarker354"/><span class="koboSpan" id="kobo.1116.1">with popular platforms and services. </span><span class="koboSpan" id="kobo.1116.2">These retrievers, like those for Google Drive or Outline, make it easier to incorporate existing document repositories into your RAG application.</span></li>
</ul>
<div aria-label="139" epub:type="pagebreak" id="page33-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1117.1">Here’s a basic example of retriever usage:</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1118.1"># Basic retriever interaction</span></span></p>
<p class="snippet-code"><span class="hljs-attr"><span class="koboSpan" id="kobo.1119.1">docs</span></span><span class="koboSpan" id="kobo.1120.1"> = retriever.invoke(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1121.1">"What is machine learning?"</span></span><span class="koboSpan" id="kobo.1122.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1123.1">LangChain supports several sophisticated approaches to ret</span><a id="_idTextAnchor189"/><span class="koboSpan" id="kobo.1124.1">rieval:</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1125.1">Vector store retrievers</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1126.1">Vector stores serve as the foundation for semantic search, converting documents and queries into embeddings for similarity </span><a id="_idIndexMarker355"/><span class="koboSpan" id="kobo.1127.1">matching. </span><span class="koboSpan" id="kobo.1127.2">Any vector store can become a retriever</span><a id="_idIndexMarker356"/><span class="koboSpan" id="kobo.1128.1"> through the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1129.1">as_retriever()</span></code><span class="koboSpan" id="kobo.1130.1"> method:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1131.1">from</span></span><span class="koboSpan" id="kobo.1132.1"> langchain_community.retrievers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1133.1">import</span></span><span class="koboSpan" id="kobo.1134.1"> KNNRetriever</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1135.1">from</span></span><span class="koboSpan" id="kobo.1136.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1137.1">import</span></span><span class="koboSpan" id="kobo.1138.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1139.1">retriever = KNNRetriever.from_documents(documents, OpenAIEmbeddings())</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1140.1">results = retriever.invoke(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1141.1">"query"</span></span><span class="koboSpan" id="kobo.1142.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1143.1">These are the retrievers most relevant for RAG systems.</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.1144.1">Search API retrievers</span></strong><span class="koboSpan" id="kobo.1145.1">: These</span><a id="_idIndexMarker357"/><span class="koboSpan" id="kobo.1146.1"> retrievers interface with external search services without storing documents locally. </span><span class="koboSpan" id="kobo.1146.2">For example:</span><p class="snippet-code-one"><span class="koboSpan" id="kobo.1147.1">from langchain_community.retrievers.pubmed import PubMedRetriever</span></p><p class="snippet-code-one"><span class="hljs-attribute"><span class="koboSpan" id="kobo.1148.1">retriever</span></span> <span class="hljs-operator"><span class="koboSpan" id="kobo.1149.1">=</span></span><span class="koboSpan" id="kobo.1150.1"> PubMedRetriever()</span></p><p class="snippet-code-one"><span class="hljs-attribute"><span class="koboSpan" id="kobo.1151.1">results</span></span> <span class="hljs-operator"><span class="koboSpan" id="kobo.1152.1">=</span></span><span class="koboSpan" id="kobo.1153.1"> retriever.invoke(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1154.1">"COVID research"</span></span><span class="koboSpan" id="kobo.1155.1">)</span></p></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1156.1">Database retrievers</span></strong><span class="koboSpan" id="kobo.1157.1">: These connect</span><a id="_idIndexMarker358"/><span class="koboSpan" id="kobo.1158.1"> to structured data sources, translating natural language queries into database queries:</span><ul><li class="bulletList level-2"><span class="koboSpan" id="kobo.1159.1">SQL databases using text-to-SQL conversion</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1160.1">Graph databases using text-to-Cypher translation</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1161.1">Document databases with specialized query interfaces</span></li>
</ul></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1162.1">Lexical search retrievers</span></strong><span class="koboSpan" id="kobo.1163.1">: These</span><a id="_idIndexMarker359"/><span class="koboSpan" id="kobo.1164.1"> implement traditional text-matching algorithms:</span><ul><li class="bulletList level-2"><span class="koboSpan" id="kobo.1165.1">BM25 for probabilistic ranking</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1166.1">TF-IDF for term frequency analysis</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1167.1">Elasticsearch integration for scalable text search</span></li>
</ul></li>
</ol>
<div aria-label="140" epub:type="pagebreak" id="page34-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1168.1">Modern retrieval systems</span><a id="_idIndexMarker360"/><span class="koboSpan" id="kobo.1169.1"> often combine multiple approaches for better results:</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.1170.1">Hybrid search</span></strong><span class="koboSpan" id="kobo.1171.1">: Combines semantic and lexical search to leverage:</span><ul><li class="bulletList level-2"><span class="koboSpan" id="kobo.1172.1">Vector similarity for semantic understanding</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1173.1">Keyword matching for precise terminology</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1174.1">Weighted combinations for optimal results</span></li>
</ul></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1175.1">Maximal Marginal Relevance (MMR)</span></strong><span class="koboSpan" id="kobo.1176.1">: Optimizes</span><a id="_idIndexMarker361"/><span class="koboSpan" id="kobo.1177.1"> for both relevance and diversity by:</span><ul><li class="bulletList level-2"><span class="koboSpan" id="kobo.1178.1">Selecting documents similar to the query</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1179.1">Ensuring retrieved documents are distinct from each other</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.1180.1">Balancing exploration and exploitation</span></li>
</ul></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1181.1">Custom retrieval logic</span></strong><span class="koboSpan" id="kobo.1182.1">: LangChain allows the creation of specialized retrievers by implementing the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1183.1">BaseRe</span><a id="_idTextAnchor190"/><span class="koboSpan" id="kobo.1184.1">triever</span></code><span class="koboSpan" id="kobo.1185.1"> class.</span></li>
</ol>
<h2 class="heading-2" id="_idParaDest-103"><a id="_idTextAnchor191"/><span class="koboSpan" id="kobo.1186.1">Advanced RAG techniques</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.1187.1">When building production</span><a id="_idIndexMarker362"/><span class="koboSpan" id="kobo.1188.1"> RAG systems, a simple vector similarity search often isn’t enough. </span><span class="koboSpan" id="kobo.1188.2">Modern applications need more sophisticated approaches to find and validate relevant information. </span><span class="koboSpan" id="kobo.1188.3">Let’s explore how to enhance a basic RAG system with advanced techniques that dramatically improve result quality.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1189.1">A standard vector search has several limitations:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1190.1">It might miss contextually relevant documents that use different terminology</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1191.1">It can’t distinguish between authoritative and less reliable sources</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1192.1">It might return redundant or contradictory information</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1193.1">It has no way to verify if generated responses accurately reflect the source material</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1194.1">Modern retrieval systems often employ multiple complementary techniques to improve result quality. </span><span class="koboSpan" id="kobo.1194.2">Two particularly powerful approaches are hybrid retrieval </span><a id="_idTextAnchor192"/><span class="koboSpan" id="kobo.1195.1">and re-ranking.</span></p>
<h3 class="heading-3" id="_idParaDest-104"><a id="_idTextAnchor193"/><span class="koboSpan" id="kobo.1196.1">Hybrid retrieval: Combining semantic and keyword search</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1197.1">Hybrid retrieval combines two retrieval </span><a id="_idIndexMarker363"/><span class="koboSpan" id="kobo.1198.1">methods in parallel and the results are fused to leverage the strengths of both approaches:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1199.1">Dense retrieval</span></strong><span class="koboSpan" id="kobo.1200.1">: Uses vector embeddings </span><a id="_idIndexMarker364"/><span class="koboSpan" id="kobo.1201.1">for semantic understanding</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1202.1">Sparse retrieval</span></strong><span class="koboSpan" id="kobo.1203.1">: Employs lexical </span><a id="_idIndexMarker365"/><span class="koboSpan" id="kobo.1204.1">methods like BM25 for keyword precision</span></li>
</ul>
<div aria-label="141" epub:type="pagebreak" id="page35-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1205.1">For example, a hybrid retriever might use vector similarity to find semantically related documents while simultaneously running a keyword search to catch exact terminology matches, then combine the results using rank </span><a id="_idTextAnchor194"/><span class="koboSpan" id="kobo.1206.1">fusion algorithms.</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1207.1">from</span></span><span class="koboSpan" id="kobo.1208.1"> langchain.retrievers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1209.1">import</span></span><span class="koboSpan" id="kobo.1210.1"> EnsembleRetriever</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1211.1">from</span></span><span class="koboSpan" id="kobo.1212.1"> langchain_community.retrievers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1213.1">import</span></span><span class="koboSpan" id="kobo.1214.1"> BM25Retriever</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1215.1">from</span></span><span class="koboSpan" id="kobo.1216.1"> langchain.vectorstores </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1217.1">import</span></span><span class="koboSpan" id="kobo.1218.1"> FAISS</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1219.1"># Setup semantic retriever</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1220.1">vector_retriever = vector_store.as_retriever(search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1221.1">"k"</span></span><span class="koboSpan" id="kobo.1222.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.1223.1">5</span></span><span class="koboSpan" id="kobo.1224.1">})</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1225.1"># Setup lexical retriever</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1226.1">bm25_retriever = BM25Retriever.from_documents(documents)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1227.1">bm25_retriever.k = </span><span class="hljs-number"><span class="koboSpan" id="kobo.1228.1">5</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1229.1"># Combine retrievers</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1230.1">hybrid_retriever = EnsembleRetriever(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1231.1">    retrievers=[vector_retriever, bm25_retriever],</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1232.1">    weights=[</span><span class="hljs-number"><span class="koboSpan" id="kobo.1233.1">0.7</span></span><span class="koboSpan" id="kobo.1234.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1235.1">0.3</span></span><span class="koboSpan" id="kobo.1236.1">]  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1237.1"># Weight semantic search higher than keyword search</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1238.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1239.1">results = hybrid_retriever.get_relevant_documents(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1240.1">"climate change impacts"</span></span><span class="koboSpan" id="kobo.1241.1">)</span></p>
<h3 class="heading-3" id="_idParaDest-105"><a id="_idTextAnchor195"/><span class="koboSpan" id="kobo.1242.1">Re-ranking</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1243.1">Re-ranking is a post-processing </span><a id="_idIndexMarker366"/><span class="koboSpan" id="kobo.1244.1">step that can follow any retrieval method, including hybrid retrieval:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1245.1">First, retrieve a larger set of candidate documents</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1246.1">Apply a more sophisticated model to re-score documents</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1247.1">Reorder based on these more precise relevance scores</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1248.1">Re-ranking follows three main paradigms:</span></p>
<div aria-label="142" epub:type="pagebreak" id="page36-2" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1249.1">Pointwise rerankers</span></strong><span class="koboSpan" id="kobo.1250.1">: Score each document independently (for example, on a scale of 1-10) and sort the resulting array of</span><a id="_idIndexMarker367"/><span class="koboSpan" id="kobo.1251.1"> documents accordingly</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1252.1">Pairwise rerankers</span></strong><span class="koboSpan" id="kobo.1253.1">: Compare </span><a id="_idIndexMarker368"/><span class="koboSpan" id="kobo.1254.1">document pairs to determine preferences, then construct a final ordering by ranking documents based on their win/loss record across all comparisons</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1255.1">Listwise rerankers</span></strong><span class="koboSpan" id="kobo.1256.1">: The re-ranking </span><a id="_idIndexMarker369"/><span class="koboSpan" id="kobo.1257.1">model processes the entire list of documents (and the original query) holistically to determine optimal order by optimizing NDCG or MAP</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1258.1">LangChain offers several re-ranking implementations:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1259.1">Cohere rerank</span></strong><span class="koboSpan" id="kobo.1260.1">: Commercial</span><a id="_idIndexMarker370"/><span class="koboSpan" id="kobo.1261.1"> API-based solution with excellent quality:</span><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.1262.1"># Complete document compressor example</span></span></p><p class="snippet-code-one"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1263.1">from</span></span><span class="koboSpan" id="kobo.1264.1"> langchain.retrievers.document_compressors import CohereRerank</span></p><p class="snippet-code-one"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1265.1">from</span></span><span class="koboSpan" id="kobo.1266.1"> langchain.retrievers import ContextualCompressionRetriever</span></p><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.1267.1"># Initialize the compressor</span></span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1268.1">compressor = CohereRerank(</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.1269.1">top_n</span></span><span class="koboSpan" id="kobo.1270.1">=3)</span></p><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.1271.1"># Create a compression retriever</span></span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1272.1">compression_retriever = ContextualCompressionRetriever(</span></p><p class="snippet-code-one"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1273.1">base_compressor</span></span><span class="koboSpan" id="kobo.1274.1">=compressor,</span></p><p class="snippet-code-one"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1275.1">base_retriever</span></span><span class="koboSpan" id="kobo.1276.1">=base_retriever</span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1277.1">)</span></p><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.1278.1"># Original documents</span></span></p><p class="snippet-code-one"><span class="hljs-built_in"><span class="koboSpan" id="kobo.1279.1">print</span></span><span class="koboSpan" id="kobo.1280.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1281.1">"Original documents:"</span></span><span class="koboSpan" id="kobo.1282.1">)</span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1283.1">original_docs = base_retriever.get_relevant_documents(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1284.1">"How do transformers work?"</span></span><span class="koboSpan" id="kobo.1285.1">)</span></p><p class="snippet-code-one"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1286.1">for</span></span><span class="koboSpan" id="kobo.1287.1"> i, doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1288.1">in</span></span><span class="koboSpan" id="kobo.1289.1"> enumerate(original_docs):</span></p><p class="snippet-code-one"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1290.1">print</span></span><span class="koboSpan" id="kobo.1291.1">(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.1292.1">"Doc {i}: {doc.page_content[:100]}..."</span></span><span class="koboSpan" id="kobo.1293.1">)</span></p><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.1294.1"># Compressed documents</span></span></p><p class="snippet-code-one"><span class="hljs-built_in"><span class="koboSpan" id="kobo.1295.1">print</span></span><span class="koboSpan" id="kobo.1296.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1297.1">"\nCompressed documents:"</span></span><span class="koboSpan" id="kobo.1298.1">)</span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1299.1">compressed_docs = compression_retriever.get_relevant_documents(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1300.1">"How do transformers work?"</span></span><span class="koboSpan" id="kobo.1301.1">)</span></p><p class="snippet-code-one"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1302.1">for</span></span><span class="koboSpan" id="kobo.1303.1"> i, doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1304.1">in</span></span><span class="koboSpan" id="kobo.1305.1"> enumerate(compressed_docs):</span></p><p class="snippet-code-one"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1306.1">print</span></span><span class="koboSpan" id="kobo.1307.1">(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.1308.1">"Doc {i}: {doc.page_content[:100]}..."</span></span><span class="koboSpan" id="kobo.1309.1">)</span></p></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1310.1">RankLLM</span></strong><span class="koboSpan" id="kobo.1311.1">: Library</span><a id="_idIndexMarker371"/><span class="koboSpan" id="kobo.1312.1"> supporting open-source LLMs fine-tuned specifically </span><a id="_idIndexMarker372"/><span class="koboSpan" id="kobo.1313.1">for re-ranking:</span><p class="snippet-code-one"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1314.1">from</span></span><span class="koboSpan" id="kobo.1315.1"> langchain_community.document_compressors.rankllm_rerank import RankLLMRerank</span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1316.1">compressor = RankLLMRerank(</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.1317.1">top_n</span></span><span class="koboSpan" id="kobo.1318.1">=3, </span><span class="hljs-attribute"><span class="koboSpan" id="kobo.1319.1">model</span></span><span class="koboSpan" id="kobo.1320.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1321.1">"zephyr"</span></span><span class="koboSpan" id="kobo.1322.1">)</span></p></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1323.1">LLM-based custom rerankers</span></strong><span class="koboSpan" id="kobo.1324.1">: Using</span><a id="_idIndexMarker373"/><span class="koboSpan" id="kobo.1325.1"> any LLM to score document relevance:</span><p class="snippet-code-one"><span class="hljs-comment"><span class="koboSpan" id="kobo.1326.1"># Simplified example - LangChain provides more streamlined implementations</span></span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1327.1">relevance_score_chain = ChatPromptTemplate.from_template(</span></p><p class="snippet-code-one"> <span class="hljs-string"><span class="koboSpan" id="kobo.1328.1">"Rate relevance of document to query on scale of 1-10: {document}"</span></span></p><p class="snippet-code-one"><span class="koboSpan" id="kobo.1329.1">) |</span><span class="hljs-string"><span class="koboSpan" id="kobo.1330.1"> llm </span></span><span class="koboSpan" id="kobo.1331.1">|</span><span class="hljs-string"><span class="koboSpan" id="kobo.1332.1"> StrOutputParser()</span></span></p></li>
</ul>
<div aria-label="143" epub:type="pagebreak" id="page37-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1333.1">Please note that while Hybrid retrieval focuses on how documents are retrieved, re-ranking focuses on how they’re ordered after retrieval. </span><span class="koboSpan" id="kobo.1333.2">These approaches can, and often should, be used together in a pipeline. </span><span class="koboSpan" id="kobo.1333.3">When evaluating re-rankers, use position-aware metrics like Recall@k, which measures how effectively the re-ranker surfaces all relevant documents in the top positions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1334.1">Cross-encoder re-ranking typically improves these metrics by 10-20% over initial retrieval, especia</span><a id="_idTextAnchor196"/><span class="koboSpan" id="kobo.1335.1">lly for the top positions.</span></p>
<h3 class="heading-3" id="_idParaDest-106"><a id="_idTextAnchor197"/><span class="koboSpan" id="kobo.1336.1">Query transformation: Improving retrieval through better queries</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1337.1">Even the best retrieval system can struggle with poorly formulated queries. </span><span class="koboSpan" id="kobo.1337.2">Query transformation techniques address this </span><a id="_idIndexMarker374"/><span class="koboSpan" id="kobo.1338.1">challenge by enhancing or reformulating the original query to improve retrieval results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1339.1">Query expansion generates multiple variations of the original query to capture different aspects or phrasings. </span><span class="koboSpan" id="kobo.1339.2">This helps bridge the vocabulary gap between users and documents:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1340.1">from</span></span><span class="koboSpan" id="kobo.1341.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1342.1">import</span></span><span class="koboSpan" id="kobo.1343.1"> PromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1344.1">from</span></span><span class="koboSpan" id="kobo.1345.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1346.1">import</span></span><span class="koboSpan" id="kobo.1347.1"> ChatOpenAI</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1348.1">expansion_template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1349.1">"""Given the user question: {question}</span></span></p>
<p class="normal"><span class="koboSpan" id="kobo.1350.1">Generate three alternative versions that express the same information need but with different wording:</span></p>
<p class="snippet-code"><span class="hljs-number"><span class="koboSpan" id="kobo.1351.1">1</span></span><span class="koboSpan" id="kobo.1352.1">.</span><span class="hljs-string"><span class="koboSpan" id="kobo.1353.1">"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1354.1">expansion_prompt </span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1355.1">=</span></span><span class="koboSpan" id="kobo.1356.1"> PromptTemplate</span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1357.1">(</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1358.1">    input_variables</span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1359.1">=</span></span><span class="koboSpan" id="kobo.1360.1">[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1361.1">"question"</span></span><span class="koboSpan" id="kobo.1362.1">]</span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1363.1">,</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1364.1">    template</span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1365.1">=</span></span><span class="koboSpan" id="kobo.1366.1">expansion_template</span></p>
<p class="snippet-code"><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1367.1">)</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1368.1">llm </span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1369.1">=</span></span><span class="koboSpan" id="kobo.1370.1"> ChatOpenAI</span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1371.1">(</span></span><span class="koboSpan" id="kobo.1372.1">temperature</span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1373.1">=</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.1374.1">0.7</span></span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1375.1">)</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1376.1">expansion_chain </span><span class="hljs-p nct ation"><span class="koboSpan" id="kobo.1377.1">=</span></span><span class="koboSpan" id="kobo.1378.1"> expansion_prompt </span><span class="hljs-string"><span class="koboSpan" id="kobo.1379.1">| llm | StrOutputParser()</span></span></p>
<div aria-label="144" epub:type="pagebreak" id="page38-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1380.1">Let’s see this in practice:</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1381.1"># Generate expanded queries</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1382.1">original_query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1383.1">"What are the effects of climate change?"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1384.1">expanded_queries = expansion_chain.invoke(original_query)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1385.1">print(expanded_queries)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1386.1">We should be getting</span><a id="_idIndexMarker375"/><span class="koboSpan" id="kobo.1387.1"> something like this:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1388.1">What impacts does climate change have?</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1389.1">2. </span><span class="koboSpan" id="kobo.1389.2">How does climate change affect the environment?</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1390.1">3. </span><span class="koboSpan" id="kobo.1390.2">What are the consequences of climate change?</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1391.1">A more advanced approach is </span><strong class="keyWord"><span class="koboSpan" id="kobo.1392.1">Hypothetical</span><a id="_idTextAnchor198"/><span class="koboSpan" id="kobo.1393.1"> Document Embeddings</span></strong><span class="koboSpan" id="kobo.1394.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1395.1">HyDE</span></strong><span class="koboSpan" id="kobo.1396.1">).</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1397.1">Hypothetical Document Embeddings (HyDE)</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1398.1">HyDE uses an LLM to generate a </span><a id="_idIndexMarker376"/><span class="koboSpan" id="kobo.1399.1">hypothetical answer document based on the query, and then uses that document’s embedding for retrieval. </span><span class="koboSpan" id="kobo.1399.2">This technique is especially powerful for complex queries where the semantic gap between query and document language is significant:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1400.1">from</span></span><span class="koboSpan" id="kobo.1401.1"> langchain.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1402.1">import</span></span><span class="koboSpan" id="kobo.1403.1"> PromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1404.1">from</span></span><span class="koboSpan" id="kobo.1405.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1406.1">import</span></span><span class="koboSpan" id="kobo.1407.1"> ChatOpenAI, OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1408.1"># Create prompt for generating hypothetical document</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1409.1">hyde_template = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1410.1">"""Based on the question: {question}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1411.1">Write a passage that could contain the answer to this question:"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1412.1">hyde_prompt = PromptTemplate(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1413.1">    input_variables=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.1414.1">"question"</span></span><span class="koboSpan" id="kobo.1415.1">],</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1416.1">    template=hyde_template</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1417.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1418.1">llm = ChatOpenAI(temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.1419.1">0.2</span></span><span class="koboSpan" id="kobo.1420.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1421.1">hyde_chain = hyde_prompt | llm | StrOutputParser()</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1422.1"># Generate hypothetical document</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1423.1">query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1424.1">"What dietary changes can reduce carbon footprint?"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1425.1">hypothetical_doc = hyde_chain.invoke(query)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1426.1"># Use the hypothetical document for retrieval</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1427.1">embeddings = OpenAIEmbeddings()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1428.1">embedded_query = embeddings.embed_query(hypothetical_doc)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1429.1">results = vector_db.similarity_search_by_vector(embedded_query, k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.1430.1">3</span></span><span class="koboSpan" id="kobo.1431.1">)</span></p>
<div aria-label="145" epub:type="pagebreak" id="page39-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1432.1">Query transformation techniques are particularly useful when dealing with ambiguous queries, questions formulated by non-experts, or situations where terminology mismatches between queries and documents are common. </span><span class="koboSpan" id="kobo.1432.2">They do add computational overhead but can dramatically improve</span><a id="_idIndexMarker377"/><span class="koboSpan" id="kobo.1433.1"> retrieval quality, especially for complex o</span><a id="_idTextAnchor199"/><span class="koboSpan" id="kobo.1434.1">r poorly formulated questions.</span></p>
<h3 class="heading-3" id="_idParaDest-107"><a id="_idTextAnchor200"/><span class="koboSpan" id="kobo.1435.1">Context processing: maximizing retrieved information value</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1436.1">Once documents are retrieved, context </span><a id="_idIndexMarker378"/><span class="koboSpan" id="kobo.1437.1">processing techniques help distill and </span><a id="_idIndexMarker379"/><span class="koboSpan" id="kobo.1438.1">organize the information to maximize it</span><a id="_idTextAnchor201"/><span class="koboSpan" id="kobo.1439.1">s value in the generation phase.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1440.1">Contextual compression</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1441.1">Contextual compression</span><a id="_idIndexMarker380"/><span class="koboSpan" id="kobo.1442.1"> extracts only the most relevant parts of retrieved documents, removing irrelevant content that might distract the generator:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1443.1">from</span></span><span class="koboSpan" id="kobo.1444.1"> langchain.retrievers.document_compressors import LLMChainExtractor</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1445.1">from</span></span><span class="koboSpan" id="kobo.1446.1"> langchain.retrievers import ContextualCompressionRetriever</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1447.1">from</span></span><span class="koboSpan" id="kobo.1448.1"> langchain_openai import ChatOpenAI</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1449.1">llm = ChatOpenAI(</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.1450.1">temperature</span></span><span class="koboSpan" id="kobo.1451.1">=0)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1452.1">compressor = LLMChainExtractor.from_llm(llm)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1453.1"># Create a basic retriever from the vector store</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1454.1">base_retriever = vector_db.as_retriever(search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1455.1">"k"</span></span><span class="koboSpan" id="kobo.1456.1">: 3})</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1457.1">compression_retriever = ContextualCompressionRetriever(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1458.1">base_compressor</span></span><span class="koboSpan" id="kobo.1459.1">=compressor,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1460.1">base_retriever</span></span><span class="koboSpan" id="kobo.1461.1">=base_retriever</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1462.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1463.1">compressed_docs = compression_retriever.invoke(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1464.1">"How do transformers work?"</span></span><span class="koboSpan" id="kobo.1465.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1466.1">Here are our compressed documents:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1467.1">[Document(metadata={'source': 'Neural Network Review 2021', 'page': 42}, page_content="The transformer architecture was introduced in the paper 'Attention is All You Need' by Vaswani et al. </span><span class="koboSpan" id="kobo.1467.2">in 2017."),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1468.1"> Document(metadata={'source': 'Large Language Models Survey', 'page': 89}, page_content='GPT models are autoregressive transformers that predict the next t</span><a id="_idTextAnchor202"/><span class="koboSpan" id="kobo.1469.1">oken based on previous tokens.')]</span></p>
<div aria-label="146" epub:type="pagebreak" id="page40-1" role="doc-pagebreak"/>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1470.1">Maximum marginal relevance</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1471.1">Another powerful approach is </span><strong class="keyWord"><span class="koboSpan" id="kobo.1472.1">Maximum Marginal Relevance</span></strong><span class="koboSpan" id="kobo.1473.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1474.1">MMR</span></strong><span class="koboSpan" id="kobo.1475.1">), which balances document relevance with </span><a id="_idIndexMarker381"/><span class="koboSpan" id="kobo.1476.1">diversity, ensuring that the retrieved set contains varied perspectives rather than redundant information:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1477.1">from</span></span><span class="koboSpan" id="kobo.1478.1"> langchain_community.vectorstores import FAISS</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1479.1">vector_store = FAISS.from_documents(documents, embeddings)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1480.1">mmr_results = vector_store.max_marginal_relevance_search(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1481.1">query</span></span><span class="koboSpan" id="kobo.1482.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1483.1">"What are transformer models?"</span></span><span class="koboSpan" id="kobo.1484.1">,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1485.1">k</span></span><span class="koboSpan" id="kobo.1486.1">=5,            # Number of documents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1487.1">to</span></span><span class="koboSpan" id="kobo.1488.1"> return</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1489.1">fetch_k</span></span><span class="koboSpan" id="kobo.1490.1">=20,     # Number of documents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1491.1">to</span></span><span class="koboSpan" id="kobo.1492.1"> initially fetch</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1493.1">lambda_mult</span></span><span class="koboSpan" id="kobo.1494.1">=0.5  # Diversity parameter (0 = max diversity, 1 = max relevance)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1495.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1496.1">Context processing techniques are especially valuable when dealing with lengthy documents where only portions are relevant, or when providing comprehensive coverage of a topic requires diverse viewpoints. </span><span class="koboSpan" id="kobo.1496.2">They </span><a id="_idIndexMarker382"/><span class="koboSpan" id="kobo.1497.1">help reduce noise in the generator’s input and ensure that the most valuable information is prioritized.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1498.1">The final area for RAG enhancement focuses on improving the generated response itself, ensuring it’s</span><a id="_idTextAnchor203"/><span class="koboSpan" id="kobo.1499.1"> accurate, trustworthy, and useful.</span></p>
<h3 class="heading-3" id="_idParaDest-108"><a id="_idTextAnchor204"/><span class="koboSpan" id="kobo.1500.1">Response enhancement: Improving generator output</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1501.1">These response enhancement techniques are particularly important in applications where accuracy and transparency are </span><a id="_idIndexMarker383"/><span class="koboSpan" id="kobo.1502.1">paramount, such as educational resources, healthcare information, or legal advice. </span><span class="koboSpan" id="kobo.1502.2">They help build user trust by making AI-generated</span><a id="_idIndexMarker384"/><span class="koboSpan" id="kobo.1503.1"> content more verifiable and reliable.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1504.1">Let’s first assume we have </span><a id="_idTextAnchor205"/><span class="koboSpan" id="kobo.1505.1">some documents as our knowledge base:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1506.1">from</span></span><span class="koboSpan" id="kobo.1507.1"> langchain_core.documents import Document</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1508.1"># Example documents</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1509.1">documents = [</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1510.1">    Document(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1511.1">page_content</span></span><span class="koboSpan" id="kobo.1512.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1513.1">"The transformer architecture was introduced in the paper 'Attention is All You Need' by Vaswani et al. </span><span class="koboSpan" id="kobo.1513.2">in 2017."</span></span><span class="koboSpan" id="kobo.1514.1">,</span></p>
<div aria-label="147" epub:type="pagebreak" id="page41-1" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.1515.1">        metadata={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1516.1">"source"</span></span><span class="koboSpan" id="kobo.1517.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1518.1">"Neural Network Review 2021"</span></span><span class="koboSpan" id="kobo.1519.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1520.1">"page"</span></span><span class="koboSpan" id="kobo.1521.1">: 42}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1522.1">    ),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1523.1">    Document(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1524.1">page_content</span></span><span class="koboSpan" id="kobo.1525.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1526.1">"BERT uses bidirectional training of the Transformer, masked language modeling, and next sentence prediction tasks."</span></span><span class="koboSpan" id="kobo.1527.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1528.1">        metadata={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1529.1">"source"</span></span><span class="koboSpan" id="kobo.1530.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1531.1">"Introduction to NLP"</span></span><span class="koboSpan" id="kobo.1532.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1533.1">"page"</span></span><span class="koboSpan" id="kobo.1534.1">: 137}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1535.1">    ),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1536.1">    Document(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.1537.1">page_content</span></span><span class="koboSpan" id="kobo.1538.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1539.1">"GPT models are autoregressive transformers that predict the next token based on previous tokens."</span></span><span class="koboSpan" id="kobo.1540.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1541.1">        metadata={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1542.1">"source"</span></span><span class="koboSpan" id="kobo.1543.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1544.1">"Large Language Models Survey"</span></span><span class="koboSpan" id="kobo.1545.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1546.1">"page"</span></span><span class="koboSpan" id="kobo.1547.1">: 89}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1548.1">    )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1549.1">]</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1550.1">Source attribution</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1551.1">Source attribution explicitly connects generated information to the retrieved sources, helping users verify facts and understand where information comes from. </span><span class="koboSpan" id="kobo.1551.2">Let’s set up our foundation for source attribution. </span><span class="koboSpan" id="kobo.1551.3">We’ll initialize a </span><a id="_idIndexMarker385"/><span class="koboSpan" id="kobo.1552.1">vector store with our documents and create a retriever configured to fetch the top 3 most relevant documents for each query. </span><span class="koboSpan" id="kobo.1552.2">The attribution prompt template instructs the model to use citations for each claim and include a reference list:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1553.1">from</span></span><span class="koboSpan" id="kobo.1554.1"> langchain_core.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1555.1">import</span></span><span class="koboSpan" id="kobo.1556.1"> ChatPromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1557.1">from</span></span><span class="koboSpan" id="kobo.1558.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1559.1">import</span></span><span class="koboSpan" id="kobo.1560.1"> ChatOpenAI</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1561.1">from</span></span><span class="koboSpan" id="kobo.1562.1"> langchain_core.output_parsers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1563.1">import</span></span><span class="koboSpan" id="kobo.1564.1"> StrOutputParser</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1565.1">from</span></span><span class="koboSpan" id="kobo.1566.1"> langchain_community.vectorstores </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1567.1">import</span></span><span class="koboSpan" id="kobo.1568.1"> FAISS</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1569.1">from</span></span><span class="koboSpan" id="kobo.1570.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1571.1">import</span></span><span class="koboSpan" id="kobo.1572.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1573.1"># Create a vector store and retriever</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1574.1">embeddings = OpenAIEmbeddings()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1575.1">vector_store = FAISS.from_documents(documents, embeddings)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1576.1">retriever = vector_store.as_retriever(search_kwargs={</span><span class="hljs-string"><span class="koboSpan" id="kobo.1577.1">"k"</span></span><span class="koboSpan" id="kobo.1578.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.1579.1">3</span></span><span class="koboSpan" id="kobo.1580.1">})</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1581.1"># Source attribution prompt template</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1582.1">attribution_prompt = ChatPromptTemplate.from_template(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1583.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1584.1">You are a precise AI assistant that provides well-sourced information.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1585.1">Answer the following question based ONLY on the provided sources. </span><span class="koboSpan" id="kobo.1585.2">For each fact or claim in your answer,</span></span></p>
<div aria-label="148" epub:type="pagebreak" id="page42" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1586.1">include a citation using [1], [2], etc. </span><span class="koboSpan" id="kobo.1586.2">that refers to the source. </span><span class="koboSpan" id="kobo.1586.3">Include a numbered reference list at the end.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1587.1">Question: {question}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1588.1">Sources:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1589.1">{sources}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1590.1">Your answer:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1591.1">"""</span></span><span class="koboSpan" id="kobo.1592.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1593.1">Next, we’ll need helper functions to format the sources with citation numbers and generate attributed responses:</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1594.1"># Create a source-formatted string from documents</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1595.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1596.1">format_sources_with_citations</span></span><span class="koboSpan" id="kobo.1597.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1598.1">docs</span></span><span class="koboSpan" id="kobo.1599.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1600.1">    formatted_sources = []</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1601.1">for</span></span><span class="koboSpan" id="kobo.1602.1"> i, doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1603.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1604.1">enumerate</span></span><span class="koboSpan" id="kobo.1605.1">(docs, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1606.1">1</span></span><span class="koboSpan" id="kobo.1607.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1608.1">        source_info = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1609.1">f"[</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1610.1">{i}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1611.1">] </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1612.1">{doc.metadata.get(</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1613.1">'source'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1614.1">, </span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1615.1">'Unknown source'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1616.1">)}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1617.1">"</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1618.1">if</span></span><span class="koboSpan" id="kobo.1619.1"> doc.metadata.get(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1620.1">'page'</span></span><span class="koboSpan" id="kobo.1621.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1622.1">            source_info += </span><span class="hljs-string"><span class="koboSpan" id="kobo.1623.1">f", page </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1624.1">{doc.metadata[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1625.1">'page'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1626.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1627.1">"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1628.1">        formatted_sources.append(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1629.1">f"</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1630.1">{source_info}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1631.1">\n</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1632.1">{doc.page_content}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1633.1">"</span></span><span class="koboSpan" id="kobo.1634.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1635.1">return</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.1636.1">"\n\n"</span></span><span class="koboSpan" id="kobo.1637.1">.join(formatted_sources)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1638.1"># Build the RAG chain with source attribution</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1639.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1640.1">generate_attributed_response</span></span><span class="koboSpan" id="kobo.1641.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1642.1">question</span></span><span class="koboSpan" id="kobo.1643.1">):</span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.1644.1"># Retrieve relevant documents</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1645.1">    retrieved_docs = retriever.invoke(question)</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.1646.1"># Format sources with citation numbers</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1647.1">    sources_formatted = format_sources_with_citations(retrieved_docs)</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.1648.1"># Create the attribution chain using LCEL</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1649.1">    attribution_chain = (</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1650.1">        attribution_prompt</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1651.1">        | ChatOpenAI(temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.1652.1">0</span></span><span class="koboSpan" id="kobo.1653.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1654.1">        | StrOutputParser()</span></p>
<div aria-label="149" epub:type="pagebreak" id="page43" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.1655.1">    )</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.1656.1"># Generate the response with citations</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1657.1">    response = attribution_chain.invoke({</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1658.1">"question"</span></span><span class="koboSpan" id="kobo.1659.1">: question,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1660.1">"sources"</span></span><span class="koboSpan" id="kobo.1661.1">: sources_formatted</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1662.1">    })</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1663.1">return</span></span><span class="koboSpan" id="kobo.1664.1"> response</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1665.1">This example implements</span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.1666.1"> source attribution by:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1667.1">Retrieving relevant documents for a query</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1668.1">Formatting each document with a citation number</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1669.1">Using a prompt that explicitly requests citations for each fact</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1670.1">Generating a response that includes inline citations ([1], [2], etc.)</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1671.1">Adding a references section that links each citation to its source</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1672.1">The key advantages of this approach are transparency and verifiability – users can trace each claim back to its source, which is especially important for academic, medical, or legal applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1673.1">Let’s see what we get when we execute this with a query:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1674.1"># Example usage</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1675.1">question = "How do transformer models work and what are some examples?"</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1676.1">attributed_answer = generate_attributed_response(question)</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1677.1">attributed_answer</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1678.1">We should be getting a response like this:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1679.1">Transformer models work by utilizing self-attention mechanisms to weigh the importance of different input tokens when making predictions. </span><span class="koboSpan" id="kobo.1679.2">This architecture was first introduced in the paper 'Attention is All You Need' by Vaswani et al. </span><span class="koboSpan" id="kobo.1679.3">in 2017 [1].</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1680.1">One example of a transformer model is BERT, which employs bidirectional training of the Transformer, masked language modeling, and next sentence prediction tasks [2]. </span><span class="koboSpan" id="kobo.1680.2">Another example is GPT (Generative Pre-trained Transformer) models, which are autoregressive transformers that predict the next token based on previous tokens [3].</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1681.1">Reference List:</span></p>
<div aria-label="150" epub:type="pagebreak" id="page44" role="doc-pagebreak"/>
<p class="snippet-con"><span class="koboSpan" id="kobo.1682.1">[1] Neural Network Review 2021, page 42</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1683.1">[2] Introduction to NLP, page 137</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1684.1">[3] Large Language Models Survey, page 89</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1685.1">Self-consistency checking compares the generated response against the retrieved context to verify accuracy</span><a id="_idTextAnchor206"/><span class="koboSpan" id="kobo.1686.1"> and identify</span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.1687.1"> potential hallucinations.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.1688.1">Self-consistency checking: ensuring factual accuracy</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.1689.1">Self-consistency checking verifies that generated responses accurately reflect the information in retrieved documents, providing a </span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.1690.1">crucial layer of protection against hallucinations. </span><span class="koboSpan" id="kobo.1690.2">We can  use LCEL to create streamlined verification pipelines:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1691.1">from</span></span><span class="koboSpan" id="kobo.1692.1"> langchain_core.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1693.1">import</span></span><span class="koboSpan" id="kobo.1694.1"> ChatPromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1695.1">from</span></span><span class="koboSpan" id="kobo.1696.1"> langchain_core.output_parsers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1697.1">import</span></span><span class="koboSpan" id="kobo.1698.1"> StrOutputParser</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1699.1">from</span></span><span class="koboSpan" id="kobo.1700.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1701.1">import</span></span><span class="koboSpan" id="kobo.1702.1"> ChatOpenAI</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1703.1">from</span></span><span class="koboSpan" id="kobo.1704.1"> typing </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1705.1">import</span></span> <span class="hljs-type"><span class="koboSpan" id="kobo.1706.1">List</span></span><span class="koboSpan" id="kobo.1707.1">, </span><span class="hljs-type"><span class="koboSpan" id="kobo.1708.1">Dict</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1709.1">from</span></span><span class="koboSpan" id="kobo.1710.1"> langchain_core.documents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1711.1">import</span></span><span class="koboSpan" id="kobo.1712.1"> Document</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1713.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1714.1">verify_response_accuracy</span></span><span class="koboSpan" id="kobo.1715.1">(</span></p>
<p class="snippet-code"><span class="hljs-params"><span class="koboSpan" id="kobo.1716.1">    retrieved_docs: </span></span><span class="hljs-type"><span class="koboSpan" id="kobo.1717.1">List</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.1718.1">[Document],</span></span></p>
<p class="snippet-code"><span class="hljs-params"><span class="koboSpan" id="kobo.1719.1">    generated_answer: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1720.1">str</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.1721.1">,</span></span></p>
<p class="snippet-code"><span class="hljs-params"><span class="koboSpan" id="kobo.1722.1">    llm: ChatOpenAI = </span></span><span class="hljs-literal"><span class="koboSpan" id="kobo.1723.1">None</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1724.1">) -&gt; </span><span class="hljs-type"><span class="koboSpan" id="kobo.1725.1">Dict</span></span><span class="koboSpan" id="kobo.1726.1">:</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1727.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1728.1">    Verify if a generated answer is fully supported by the retrieved documents.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1729.1">    Args:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1730.1">        retrieved_docs: List of documents used to generate the answer</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1731.1">        generated_answer: The answer produced by the RAG system</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1732.1">        llm: Language model to use for verification</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1733.1">    Returns:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1734.1">        Dictionary containing verification results and any identified issues</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1735.1">    """</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1736.1">if</span></span><span class="koboSpan" id="kobo.1737.1"> llm </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1738.1">is</span></span> <span class="hljs-literal"><span class="koboSpan" id="kobo.1739.1">None</span></span><span class="koboSpan" id="kobo.1740.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1741.1">        llm = ChatOpenAI(model=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1742.1">"gpt-3.5-turbo"</span></span><span class="koboSpan" id="kobo.1743.1">, temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.1744.1">0</span></span><span class="koboSpan" id="kobo.1745.1">)</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.1746.1"># Create context from retrieved documents</span></span></p>
<div aria-label="151" epub:type="pagebreak" id="page45" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.1747.1">    context = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1748.1">"\n\n"</span></span><span class="koboSpan" id="kobo.1749.1">.join([doc.page_content </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1750.1">for</span></span><span class="koboSpan" id="kobo.1751.1"> doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1752.1">in</span></span><span class="koboSpan" id="kobo.1753.1"> retrieved_docs])</span></p>
<p class="snippet-code"> </p>
<p class="normal"><span class="koboSpan" id="kobo.1754.1">The function above begins our verification process by accepting the retrieved documents and generated answers as inputs. </span><span class="koboSpan" id="kobo.1754.2">It initializes a language model for verification if one isn’t provided and combines all</span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.1755.1"> document content into a single context string. </span><span class="koboSpan" id="kobo.1755.2">Next, we’ll define the verification prompt that instructs the LLM to perform a detailed fact-checking analysis:</span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.1756.1"># Define verification prompt - fixed to avoid JSON formatting issues in the template</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1757.1">    verification_prompt = ChatPromptTemplate.from_template(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1758.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1759.1">    As a fact-checking assistant, verify whether the following answer is fully supported</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1760.1">    by the provided context. </span><span class="koboSpan" id="kobo.1760.2">Identify any statements that are not supported or contradict the context.</span></span></p>
<p class="snippet-code"><span class="hljs-string"> </span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1761.1">    Context:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1762.1">    {context}</span></span></p>
<p class="snippet-code"><span class="hljs-string"> </span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1763.1">    Answer to verify:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1764.1">    {answer}</span></span></p>
<p class="snippet-code"><span class="hljs-string"> </span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1765.1">    Perform a detailed analysis with the following structure:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1766.1">    1. </span><span class="koboSpan" id="kobo.1766.2">List any factual claims in the answer</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1767.1">    2. </span><span class="koboSpan" id="kobo.1767.2">For each claim, indicate whether it is:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1768.1">       - Fully supported (provide the supporting text from context)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1769.1">       - Partially supported (explain what parts lack support)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1770.1">       - Contradicted (identify the contradiction)</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1771.1">       - Not mentioned in context</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1772.1">    3. </span><span class="koboSpan" id="kobo.1772.2">Overall assessment: Is the answer fully grounded in the context?</span></span></p>
<p class="snippet-code"><span class="hljs-string"> </span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1773.1">    Return your analysis in JSON format with the following structure:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1774.1">    {{</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1775.1">      "</span></span><span class="koboSpan" id="kobo.1776.1">claims</span><span class="hljs-string"><span class="koboSpan" id="kobo.1777.1">": [</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1778.1">        {{</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1779.1">          "</span></span><span class="koboSpan" id="kobo.1780.1">claim</span><span class="hljs-string"><span class="koboSpan" id="kobo.1781.1">": "</span></span><span class="koboSpan" id="kobo.1782.1">The factual claim</span><span class="hljs-string"><span class="koboSpan" id="kobo.1783.1">",</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1784.1">          "</span></span><span class="koboSpan" id="kobo.1785.1">status</span><span class="hljs-string"><span class="koboSpan" id="kobo.1786.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1787.1">: "</span></span><span class="koboSpan" id="kobo.1788.1">fully_supported|partially_supported|contradicted|not_mentioned</span><span class="hljs-string"><span class="koboSpan" id="kobo.1789.1">",</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1790.1">          "</span></span><span class="koboSpan" id="kobo.1791.1">evidence</span><span class="hljs-string"><span class="koboSpan" id="kobo.1792.1">": "</span></span><span class="koboSpan" id="kobo.1793.1">Supporting </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1794.1">or</span></span><span class="koboSpan" id="kobo.1795.1"> contradicting </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1796.1">text</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1797.1">from</span></span><span class="koboSpan" id="kobo.1798.1"> context</span><span class="hljs-string"><span class="koboSpan" id="kobo.1799.1">",</span></span></p>
<div aria-label="152" epub:type="pagebreak" id="page46" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1800.1">          "</span></span><span class="koboSpan" id="kobo.1801.1">explanation</span><span class="hljs-string"><span class="koboSpan" id="kobo.1802.1">": "</span></span><span class="koboSpan" id="kobo.1803.1">Your explanation</span><span class="hljs-string"><span class="koboSpan" id="kobo.1804.1">"</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1805.1">        }}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1806.1">      ],</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1807.1">      "</span></span><span class="koboSpan" id="kobo.1808.1">fully_grounded</span><span class="hljs-string"><span class="koboSpan" id="kobo.1809.1">": true|false,</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1810.1">      "</span></span><span class="koboSpan" id="kobo.1811.1">issues_identified</span><span class="hljs-string"><span class="koboSpan" id="kobo.1812.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1813.1">: ["</span></span><span class="koboSpan" id="kobo.1814.1">List </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1815.1">any</span></span><span class="koboSpan" id="kobo.1816.1"> specific issues</span><span class="hljs-string"><span class="koboSpan" id="kobo.1817.1">"]</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1818.1">    }}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1819.1">    """</span></span><span class="koboSpan" id="kobo.1820.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1821.1">The verification prompt is structured to perform a comprehensive fact check. </span><span class="koboSpan" id="kobo.1821.2">It instructs the model to break down each claim in the answer and categorize it based on how well it’s supported by the provided </span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.1822.1">context. </span><span class="koboSpan" id="kobo.1822.2">The prompt also requests the output in a structured JSON format that can be easily processed programmatically.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1823.1">Finally, we’ll complete the function with the verification chain and example usage:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1824.1">    # Create verification chain using LCEL</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1825.1">    verification_chain = (</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1826.1">        verification_prompt</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1827.1">        | llm</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1828.1">        | StrOutputParser()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1829.1">    )</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1830.1">    # </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1831.1">Run</span></span><span class="koboSpan" id="kobo.1832.1"> verification</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1833.1">    result = verification_chain.invoke({</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1834.1">"context"</span></span><span class="koboSpan" id="kobo.1835.1">: context,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1836.1">"answer"</span></span><span class="koboSpan" id="kobo.1837.1">: generated_answer</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1838.1">    })</span></p>
<p class="snippet-code"> </p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1839.1">    return result</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1840.1"># Example usage</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1841.1">retrieved_docs = [</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1842.1">    Document(</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.1843.1">page_content</span></span><span class="koboSpan" id="kobo.1844.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1845.1">"The transformer architecture was introduced in the paper 'Attention Is All You Need' by Vaswani et al. </span><span class="koboSpan" id="kobo.1845.2">in 2017. </span><span class="koboSpan" id="kobo.1845.3">It relies on self-attention mechanisms instead of recurrent or convolutional neural networks."</span></span><span class="koboSpan" id="kobo.1846.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1847.1">    Document(</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.1848.1">page_content</span></span><span class="koboSpan" id="kobo.1849.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1850.1">"BERT is a transformer-based model developed by Google that uses masked language modeling and next sentence prediction as pre-training objectives."</span></span><span class="koboSpan" id="kobo.1851.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1852.1">]</span></p>
<div aria-label="153" epub:type="pagebreak" id="page47" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.1853.1">generated_answer = </span><span class="hljs-string"><span class="koboSpan" id="kobo.1854.1">"The transformer architecture was introduced by OpenAI in 2018 and uses recurrent neural networks. </span><span class="koboSpan" id="kobo.1854.2">BERT is a transformer model developed by Google."</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1855.1">verification_result = verify_response_accuracy(retrieved_docs, generated_answer)</span></p>
<p class="snippet-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.1856.1">print</span></span><span class="koboSpan" id="kobo.1857.1">(verification_result)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1858.1">We should get a response like this:</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1859.1">{</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1860.1">    "claims": [</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1861.1">        {</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1862.1">            "claim": "The transformer architecture was introduced by OpenAI in 2018",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1863.1">            "status": "contradicted",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1864.1">            "evidence": "The transformer architecture was introduced in the paper 'Attention is All You Need' by Vaswani et al. </span><span class="koboSpan" id="kobo.1864.2">in 2017.",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1865.1">            "explanation": "The claim is contradicted by the fact that the transformer architecture was introduced in 2017 by Vaswani et al., not by OpenAI in 2018."</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1866.1">        },</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1867.1">        {</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1868.1">            "claim": "The transformer architecture uses recurrent neural networks",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1869.1">            "status": "contradicted",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1870.1">            "evidence": "It relies on self-attention mechanisms instead of recurrent or convolutional neural networks.",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1871.1">            "explanation": "The claim is contradicted by the fact that the transformer architecture does not use recurrent neural networks but relies on self-attention mechanisms."</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1872.1">        },</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1873.1">        {</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1874.1">            "claim": "BERT is a transformer model developed by Google",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1875.1">            "status": "fully_supported",</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1876.1">            "evidence": "BERT is a transformer-based model developed by Google that uses masked language modeling and next sentence prediction as pre-training objectives.",</span></p>
<div aria-label="154" epub:type="pagebreak" id="page48" role="doc-pagebreak"/>
<p class="snippet-con"><span class="koboSpan" id="kobo.1877.1">            "explanation": "This claim is fully supported by the provided context."</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1878.1">        }</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1879.1">    ],</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1880.1">    "fully_grounded": false,</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1881.1">    "issues_identified": ["The answer contains incorrect information about the introduction of the transformer architecture and its use of recurrent neural networks."]</span></p>
<p class="snippet-con"><span class="koboSpan" id="kobo.1882.1">}</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1883.1">Based on the verification </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.1884.1">result, you can:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1885.1">Regenerate the answer if issues are found</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1886.1">Add qualifying statements to indicate uncertainty</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1887.1">Filter out unsupported claims</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1888.1">Include confidence indicators for different parts of the response</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1889.1">This approach systematically analyzes generated responses against source documents, identifying specific unsupported claims rather than just providing a binary assessment. </span><span class="koboSpan" id="kobo.1889.2">For each factual assertion, it determines whether it’s fully supported, partially supported, contradicted, or not mentioned in</span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.1890.1"> the context.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1891.1">Self-consistency checking is essential for applications where trustworthiness is paramount, such as medical information, financial advice, or educational content. </span><span class="koboSpan" id="kobo.1891.2">Detecting and addressing hallucinations before they reach users significantly improves the reliability of RAG systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1892.1">The verification can be further enhanced by:</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.1893.1">Granular claim extraction</span></strong><span class="koboSpan" id="kobo.1894.1">: Breaking down complex responses into atomic factual claims</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1895.1">Evidence linking</span></strong><span class="koboSpan" id="kobo.1896.1">: Explicitly connecting each claim to specific supporting text</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1897.1">Confidence scoring</span></strong><span class="koboSpan" id="kobo.1898.1">: Assigning numerical confidence scores to different parts of the response</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1899.1">Selective regeneration</span></strong><span class="koboSpan" id="kobo.1900.1">: Regenerating only the unsupported portions of responses</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1901.1">These techniques create a verification layer that substantially reduces the risk of presenting incorrect information to users while maintaining the fluency and coherence of generated responses.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1902.1">While the techniques we’ve discussed enhance individual components of the RAG pipeline, corrective RAG represents a more holistic approach that addresses fundamental retrieval quality issues at a systemic level.</span></p>
<div aria-label="155" epub:type="pagebreak" id="page49" role="doc-pagebreak"/>
<h3 class="heading-3" id="_idParaDest-109"><a id="_idTextAnchor207"/><span class="koboSpan" id="kobo.1903.1">Corrective RAG</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1904.1">The techniques we’ve explored so </span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.1905.1">far mostly assume that our retrieval mechanism returns relevant, accurate documents. </span><span class="koboSpan" id="kobo.1905.2">But what happens when it doesn’t? </span><span class="koboSpan" id="kobo.1905.3">In real-world applications, retrieval systems often return irrelevant, insufficient, or even misleading content. </span><span class="koboSpan" id="kobo.1905.4">This “garbage in, garbage out” problem represents a critical vulnerability in standard RAG systems. </span><strong class="keyWord"><span class="koboSpan" id="kobo.1906.1">Corrective Retrieval-Augmented Generation</span></strong><span class="koboSpan" id="kobo.1907.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1908.1">CRAG</span></strong><span class="koboSpan" id="kobo.1909.1">) directly addresses this challenge by</span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.1910.1"> introducing explicit evaluation and correction mechanisms into the RAG pipeline.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1911.1">CRAG extends the standard RAG pipeline with evaluation and conditional branching:</span></p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.1912.1">Initial retrieval:</span></strong><span class="koboSpan" id="kobo.1913.1"> Standard document retrieval from the vector store based on the query.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1914.1">Retrieval evaluation:</span></strong><span class="koboSpan" id="kobo.1915.1"> A retrieval evaluator component assesses each document’s relevance and quality.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1916.1">Conditional correction:</span></strong><ol><li class="alphabeticList level-2" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.1917.1">Relevant documents:</span></strong><span class="koboSpan" id="kobo.1918.1"> Pass high-quality documents directly to the generator.</span></li>
<li class="alphabeticList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1919.1">Irrelevant documents:</span></strong><span class="koboSpan" id="kobo.1920.1"> Filter out low-quality documents to prevent noise.</span></li>
<li class="alphabeticList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1921.1">Insufficient/Ambiguous results:</span></strong><span class="koboSpan" id="kobo.1922.1"> Trigger alternative information-seeking strategies (like web search) when internal knowledge is inadequate.</span></li>
</ol></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1923.1">Generation:</span></strong><span class="koboSpan" id="kobo.1924.1"> Produce the final response using the filtered or augmented context.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1925.1">This workflow transforms</span><a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.1926.1"> RAG from a static pipeline into a more dynamic, self-correcting system capable of seeking additional information when needed.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1927.1"><img alt="Figure 4.4: Corrective RAG workflow showing evaluation and conditional branching" src="../Images/B32363_04_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1928.1">Figure 4.4: Corrective RAG workflow showing evaluation and conditional branching</span></p>
<div aria-label="156" epub:type="pagebreak" id="page50" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1929.1">The retrieval evaluator is the cornerstone of CRAG. </span><span class="koboSpan" id="kobo.1929.2">Its job is to analyze the relationship between retrieved documents and the query, determining which documents are truly relevant. </span><span class="koboSpan" id="kobo.1929.3">Implementations typically use an LLM with a carefully crafted prompt:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1930.1">from pydantic </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1931.1">import</span></span><span class="koboSpan" id="kobo.1932.1"> BaseModel, Field</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1933.1">class</span></span><span class="koboSpan" id="kobo.1934.1"> DocumentRelevanceScore(BaseModel):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1935.1">"""Binary relevance score for document evaluation."""</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1936.1">is</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.1937.1">_</span></span><span class="koboSpan" id="kobo.1938.1">relevant: bool = Field(description=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1939.1">"Whether the document contains information relevant to the query"</span></span><span class="koboSpan" id="kobo.1940.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1941.1">    reasoning: str = Field(description=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1942.1">"Explanation for the relevance decision"</span></span><span class="koboSpan" id="kobo.1943.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1944.1">def evaluate</span><span class="hljs-number"><span class="koboSpan" id="kobo.1945.1">_</span></span><span class="koboSpan" id="kobo.1946.1">document(document, query, llm):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.1947.1">"""Evaluate if a document is relevant to a query."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1948.1">    prompt = f</span><span class="hljs-string"><span class="koboSpan" id="kobo.1949.1">""" You are an expert document evaluator. </span><span class="koboSpan" id="kobo.1949.2">Your task is to determine if the following document contains information relevant to the given query.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1950.1">Query: {query}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1951.1">Document content:</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1952.1">{document.page_content}</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1953.1">Analyze whether this document contains information that helps answer the query.</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.1954.1">"""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.1955.1">    Evaluation = llm.with</span><span class="hljs-number"><span class="koboSpan" id="kobo.1956.1">_</span></span><span class="koboSpan" id="kobo.1957.1">structured</span><span class="hljs-number"><span class="koboSpan" id="kobo.1958.1">_</span></span><span class="koboSpan" id="kobo.1959.1">output(DocumentRelevanceScore).invoke(prompt)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.1960.1">return</span></span><span class="koboSpan" id="kobo.1961.1"> evaluation</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1962.1">By evaluating each document independently, CRAG can make fine-grained decisions about which content to include, exclude, or supplement, substantially improving the quality of the final context provided to the</span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.1963.1"> generator.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1964.1">Since the CRAG implementation builds on concepts we’ll introduce in </span><a href="E_Chapter_5.xhtml#_idTextAnchor231"><em class="italic"><span class="koboSpan" id="kobo.1965.1">Chapter 5</span></em></a><span class="koboSpan" id="kobo.1966.1">, we’ll not be showing the complete code here, but you can find the implementation in the book’s companion repository. </span><span class="koboSpan" id="kobo.1966.2">Please note that LangGraph is particularly well-suited for implementing CRAG because it allows for conditional branching based on document evaluation.</span></p>
<div aria-label="157" epub:type="pagebreak" id="page51" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.1967.1">While CRAG enhances RAG by adding evaluation and correction mechanisms to the retrieval pipeline, Agentic RAG represents a more fundamental paradigm shift by introducing autonomous AI agents to orchestrate the entire RAG process.</span></p>
<h3 class="heading-3" id="_idParaDest-110"><a id="_idTextAnchor208"/><span class="koboSpan" id="kobo.1968.1">Agentic RAG</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1969.1">Agentic RAG employs AI agents—autonomous </span><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.1970.1">systems capable of planning, reasoning, and </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.1971.1">decision-making—to dynamically manage information retrieval and generation. </span><span class="koboSpan" id="kobo.1971.2">Unlike traditional RAG or even CRAG, which follow relatively structured workflows, agentic RAG uses agents to:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1972.1">Analyze queries and decompose complex questions into manageable sub-questions</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1973.1">Plan information-gathering strategies based on the specific task requirements</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1974.1">Select appropriate tools (retrievers, web search, calculators, APIs, etc.)</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1975.1">Execute multi-step processes, potentially involving multiple rounds of retrieval and reasoning</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1976.1">Reflect on intermediate results and adapt strategies accordingly</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1977.1">The key distinction between CRAG and agentic RAG lies in their focus: CRAG primarily enhances data quality through evaluation and correction, while agentic RAG focuses on process intelligence through autonomous planning and orchestration.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1978.1">Agentic RAG is particularly valuable for complex use cases that require:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.1979.1">Multi-step reasoning across multiple information sources</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1980.1">Dynamic tool selection based on query analysis</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1981.1">Persistent task execution with intermediate reflection</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.1982.1">Integration with various external systems and APIs</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1983.1">However, agentic RAG introduces significant complexity in implementation, potentially higher latency due to multiple reasoning steps, and increased computational costs from multiple LLM calls for planning and reflection.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1984.1">In </span><a href="E_Chapter_5.xhtml#_idTextAnchor231"><em class="italic"><span class="koboSpan" id="kobo.1985.1">Chapter 5</span></em></a><span class="koboSpan" id="kobo.1986.1">, we’ll explore the implementation of agent-based systems in depth, including patterns that can be </span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.1987.1">applied to create agentic RAG systems. </span><span class="koboSpan" id="kobo.1987.2">The core techniques—tool integration, planning, reflection, and orchestration—are fundamental to both general agent systems and agentic RAG specifically.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1988.1">By understanding both CRAG </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.1989.1">and agentic RAG approaches, you’ll be equipped to select the most appropriate RAG architecture based on your specific requirements, balancing</span><a id="_idTextAnchor209"/><span class="koboSpan" id="kobo.1990.1"> accuracy, flexibility, complexity, and performance.</span></p>
<div aria-label="158" epub:type="pagebreak" id="page52" role="doc-pagebreak"/>
<h3 class="heading-3" id="_idParaDest-111"><a id="_idTextAnchor210"/><span class="koboSpan" id="kobo.1991.1">Choosing the right techniques</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.1992.1">When implementing </span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.1993.1">advanced RAG techniques, consider the specific requirements and constraints of your application. </span><span class="koboSpan" id="kobo.1993.2">To guide your decision-making process, the following table provides a comprehensive comparison of RAG approaches discussed throughout this chapter:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table005">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1994.1">RAG Approach</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1995.1">Chapter Section</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1996.1">Core Mechanism</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1997.1">Key Strengths</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1998.1">Key Weaknesses</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.1999.1">Primary Use Cases</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.2000.1">Relative Complexity</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2001.1">Naive RAG</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2002.1">Breaking down the RAG pipeline</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2003.1">Basic index </span><span class="koboSpan" id="kobo.2004.1"><img alt="" src="../Images/Icon.png"/></span><span class="koboSpan" id="kobo.2005.1"> retrieve </span><span class="koboSpan" id="kobo.2006.1"><img alt="" src="../Images/Icon.png"/></span><span class="koboSpan" id="kobo.2007.1"> generate workflow with single retrieval step</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2008.1">Simple implementation</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2009.1"> Low initial resource usage</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2010.1">Straightforward debugging</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2011.1">Limited retrieval quality</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2012.1">Vulnerability to hallucinations</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2013.1">No handling of retrieval failures</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2014.1">Simple Q&amp;A systems</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2015.1">Basic document lookup</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2016.1">Prototyping</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2017.1">Low</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2018.1">Hybrid Retrieval</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2019.1">Advanced RAG techniques – hybrid retrieval</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2020.1">Combines sparse (BM25) and dense (vector) retrieval methods</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2021.1">Balances keyword precision with semantic understanding</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2022.1">Handles vocabulary mismatch</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2023.1">Improves recall without sacrificing precision</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2024.1">Increased system complexity</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2025.1">Challenge in optimizing fusion weights</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2026.1">Higher computational overhead</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2027.1">Technical documentation</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2028.1">Content with specialized terminology</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2029.1">Multi-domain knowledge bases</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2030.1">Medium</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2031.1">Re-ranking</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2032.1">Advanced RAG techniques – re-ranking</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2033.1">Post-processes initial retrieval results with more sophisticated relevance models</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2034.1">Improves result ordering</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2035.1">Captures nuanced relevance signals</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2036.1">Can be applied to any retrieval method</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2037.1">Additional computation layer</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2038.1">May create bottlenecks for large result sets</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2039.1">Requires training or configuring re-rankers</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2040.1">When retrieval quality is critical</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2041.1">For handling ambiguous queries</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2042.1">High-value information needs</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2043.1">Medium</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2044.1">Query Transformation (HyDE)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2045.1">Advanced RAG techniques – query transformation</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2046.1">Generates hypothetical document from query for improved retrieval</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2047.1">Bridges query-document semantic gap</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2048.1">Improves retrieval for complex queries</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2049.1">Handles implicit information needs</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2050.1">Additional LLM generation step</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2051.1">Depends on hypothetical document quality</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2052.1">Potential for query drift</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2053.1">Complex or ambiguous queries</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2054.1">Users with unclear information needs</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2055.1">Domain-specific search</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2056.1">Medium</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<div aria-label="159" epub:type="pagebreak" id="page53" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2057.1">Context Processing</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2058.1">Advanced RAG techniques - context processing</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2059.1">Optimizes retrieved documents before sending to the generator (compression, MMR)</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2060.1">Maximizes context window utilization</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2061.1">Reduces redundancy Focuses on most relevant information</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2062.1">Risk of removing important context</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2063.1">Processing adds latency</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2064.1">May lose document coherence</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2065.1">Large documents</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2066.1">When context window is limited</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2067.1">Redundant information sources</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2068.1">Medium</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2069.1">Response Enhancement</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2070.1">Advanced RAG techniques – response enhancement</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2071.1">Improves generated output with source attribution and consistency checking</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2072.1">Increases output trustworthiness</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2073.1">Provides verification mechanisms</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2074.1">Enhances user confidence</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2075.1">May reduce fluency or conciseness</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2076.1">Additional post-processing overhead</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2077.1">Complex implementation logic</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2078.1">Educational or research content</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2079.1">Legal or medical information</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2080.1">When attribution is required</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2081.1">Medium-High</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2082.1">Corrective RAG (CRAG)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2083.1">Advanced RAG techniques – corrective RAG</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2084.1">Evaluates retrieved documents and takes corrective actions (filtering, web search)</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2085.1">Explicitly handles poor retrieval results</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2086.1">Improves robustness</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2087.1">Can dynamically supplement knowledge</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2088.1">Increased latency from evaluation</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2089.1">Depends on evaluator accuracy</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2090.1">More complex conditional logic</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2091.1">High-reliability requirements</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2092.1">Systems needing factual accuracy</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2093.1">Applications with potential knowledge gaps</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2094.1">High</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2095.1">Agentic RAG</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2096.1">Advanced RAG techniques – agentic RAG</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2097.1">Uses autonomous AI agents to orchestrate information gathering and synthesis</span></p>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2098.1">Highly adaptable to complex tasks</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2099.1">Can use diverse tools beyond retrieval</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2100.1">Multi-step reasoning capabilities</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2101.1">Significant implementation complexity</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2102.1">Higher cost and latency</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2103.1">Challenging to debug and control</span></li>
</ul>
</td>
<td class="No-Table-Style">
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.2104.1">Complex multi-step information tasks</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2105.1">Research applications</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.2106.1">Systems integrating multiple data sources</span></li>
</ul>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.2107.1">Very High</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.2108.1">Table 4.5: Comparing RAG techniques</span></p>
<div aria-label="160" epub:type="pagebreak" id="page54" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2109.1">For technical or specialized domains with complex terminology, hybrid retrieval provides a strong foundation by capturing both semantic relationships and exact terminology. </span><span class="koboSpan" id="kobo.2109.2">When dealing with lengthy documents where only portions are relevant, add contextual compression to extract the most pertinent sections.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2110.1">For applications where accuracy and transparency are critical, implement source attribution and self-consistency </span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.2111.1">checking to ensure that generated responses are faithful to the retrieved information. </span><span class="koboSpan" id="kobo.2111.2">If users frequently submit ambiguous or poorly formulated queries, query transformation techniques can help bridge the gap between user language and document terminology.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2112.1">So when should you choose each approach?</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.2113.1">Start with naive RAG for quick prototyping and simple question-answering</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2114.1">Add hybrid retrieval when facing vocabulary mismatch issues or mixed content types</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2115.1">Implement re-ranking when the initial retrieval quality needs refinement</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2116.1">Use query transformation for complex queries or when users struggle to articulate information needs</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2117.1">Apply context processing when dealing with limited context windows or redundant information</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2118.1">Add response enhancement for applications requiring high trustworthiness and attribution</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2119.1">Consider CRAG when reliability and factual accuracy are mission-critical</span></li>
</ul>
<div>
<div class="note" id="_idContainer063">
<p class="normal"><span class="koboSpan" id="kobo.2120.1">Explore agentic RAG (covered more in </span><a href="E_Chapter_5.xhtml#_idTextAnchor231"><em class="italic"><span class="koboSpan" id="kobo.2121.1">Chapter 5</span></em></a><span class="koboSpan" id="kobo.2122.1">) for complex, multi-step information tasks requiring reasoning</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.2123.1">In practice, production RAG systems often combine multiple approaches. </span><span class="koboSpan" id="kobo.2123.2">For example, a robust enterprise system might use hybrid retrieval with query transformation, apply context processing to optimize the retrieved information, enhance responses with source attribution, and implement CRAG’s evaluation layer for critical applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2124.1">Start with implementing one or two key techniques that address your most pressing challenges, then measure their impact on performance metrics like relevance, accuracy, and user satisfaction. </span><span class="koboSpan" id="kobo.2124.2">Add additional techniques incrementally as needed, always considering the tradeoff between improved results and increased computational costs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2125.1">To demonstrate a RAG</span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.2126.1"> system in practice, in the next section, we’ll walk through the implementation of a chatbot that retrieves and integrates external knowledge into responses.</span></p>
<div aria-label="161" epub:type="pagebreak" id="page55" role="doc-pagebreak"/>
<h1 class="heading-1" id="_idParaDest-112"><a id="_idTextAnchor211"/><span class="koboSpan" id="kobo.2127.1">Developing a corporate documentation chatbot</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.2128.1">In this section, we will build a corporate</span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.2129.1"> documentation chatbot that leverages LangChain for LLM interactions and LangGraph for state management and workflow orchestration. </span><span class="koboSpan" id="kobo.2129.2">LangGraph complements the implementation in several critical ways:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2130.1">Explicit state management</span></strong><span class="koboSpan" id="kobo.2131.1">: Unlike basic RAG pipelines that operate as linear sequences, LangGraph maintains a formal state object containing all relevant information (queries, retrieved documents, intermediate results, etc.).</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2132.1">Conditional processing</span></strong><span class="koboSpan" id="kobo.2133.1">: LangGraph enables conditional branching based on the quality of retrieved documents or other</span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.2134.1"> evaluation criteria—essential for ensuring reliable output.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2135.1">Multi-step reasoning</span></strong><span class="koboSpan" id="kobo.2136.1">: For complex documentation tasks, LangGraph allows breaking the process into discrete steps (retrieval, generation, validation, refinement) while maintaining context throughout.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2137.1">Human-in-the-loop integration</span></strong><span class="koboSpan" id="kobo.2138.1">: When document quality or compliance cannot be automatically verified, LangGraph facilitates seamless integration of human feedback.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.2139.1">With the </span><strong class="keyWord"><span class="koboSpan" id="kobo.2140.1">Corporate Documentation Manager</span></strong><span class="koboSpan" id="kobo.2141.1"> tool we </span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.2142.1">built, you can generate, validate, and refine project documentation while incorporating human feedback to ensure compliance with corporate standards. </span><span class="koboSpan" id="kobo.2142.2">In many organizations, maintaining up-to-date project documentation is critical. </span><span class="koboSpan" id="kobo.2142.3">Our pipeline leverages LLMs to:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2143.1">Generate documentation</span></strong><span class="koboSpan" id="kobo.2144.1">: Produce detailed project documentation from a user’s prompt</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2145.1">Conduct compliance checks</span></strong><span class="koboSpan" id="kobo.2146.1">: Analyze the generated document for adherence to corporate standards and best practices</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2147.1">Handle human feedback</span></strong><span class="koboSpan" id="kobo.2148.1">: Solicit expert feedback if compliance issues are detected</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2149.1">Finalize documentation</span></strong><span class="koboSpan" id="kobo.2150.1">: Revise the document based on feedback to ensure it is both accurate and compliant</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.2151.1">The idea is that this process not only streamlines documentation creation but also introduces a safety net by involving human-in-the-loop validation. </span><span class="koboSpan" id="kobo.2151.2">The code is split into several modules, each handling a specific part of the pipeline, and a Streamlit app ties everything together for a web-based interface.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2152.1">The code will demonstrate the following key features:</span></p>
<div aria-label="162" epub:type="pagebreak" id="page56" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2153.1">Modular pipeline design</span></strong><span class="koboSpan" id="kobo.2154.1">: Defines a clear state and uses nodes for documentation generation, compliance analysis, human feedback, and finalization</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2155.1">Interactive interface</span></strong><span class="koboSpan" id="kobo.2156.1">: Integrates the pipeline with Gradio for real-time user interactions</span></li>
</ul>
<div>
<div class="note" id="_idContainer064">
<p class="normal"><span class="koboSpan" id="kobo.2157.1">While this chapter provides a brief overview of performance measurements and evaluation metrics, an in-depth discussion of performance and observability will be covered in </span><a href="E_Chapter_8.xhtml#_idTextAnchor390"><em class="italic"><span class="koboSpan" id="kobo.2158.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.2159.1">. </span><span class="koboSpan" id="kobo.2159.2">Please make sure you have installed all the dependencies needed for this book, as explained in </span><a href="E_Chapter_2.xhtml#_idTextAnchor044"><em class="italic"><span class="koboSpan" id="kobo.2160.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.2161.1">. </span><span class="koboSpan" id="kobo.2161.2">Otherwise, you might run into issues.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2162.1">Additionally, given the pace of the field and the development of the LangChain library, we are making an effort to keep the GitHub repository up to date. </span><span class="koboSpan" id="kobo.2162.2">Please see </span><a href="https://github.com/benman1/generative_ai_with_langchain"><span class="url"><span class="koboSpan" id="kobo.2163.1">https://github.com/benman1/generative_ai_with_langchain</span></span></a><span class="koboSpan" id="kobo.2164.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2165.1">For any questions, or if you have any trouble running the code, please create an issue on GitHub or join the discussion on Discord: </span><a href="https://packt.link/lang"><span class="url"><span class="koboSpan" id="kobo.2166.1">https://packt.link/lang</span></span></a><span class="koboSpan" id="kobo.2167.1">.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.2168.1">Let’s get started! </span><span class="koboSpan" id="kobo.2168.2">Each file in the project serves a specific role in the overall documentation chatbot. </span><span class="koboSpan" id="kobo.2168.3">Let’s first look at </span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.2169.1">document loa</span><a id="_idTextAnchor212"/><span class="koboSpan" id="kobo.2170.1">ding.</span></p>
<h2 class="heading-2" id="_idParaDest-113"><a id="_idTextAnchor213"/><span class="koboSpan" id="kobo.2171.1">Document loading</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.2172.1">The main purpose of this </span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.2173.1">module is to give an interface to read different document formats.</span></p>
<div>
<div class="note" id="_idContainer065">
<p class="normal"><span class="koboSpan" id="kobo.2174.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2175.1">Document</span></code><span class="koboSpan" id="kobo.2176.1"> class in LangChain is a fundamental data structure for storing and manipulating text content along with associated metadata. </span><span class="koboSpan" id="kobo.2176.2">It stores text content through its required </span><code class="inlineCode"><span class="koboSpan" id="kobo.2177.1">page_content</span></code><span class="koboSpan" id="kobo.2178.1"> parameter along with optional metadata stored as a dictionary.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2179.1">The class also supports an optional </span><code class="inlineCode"><span class="koboSpan" id="kobo.2180.1">id</span></code><span class="koboSpan" id="kobo.2181.1"> parameter that ideally should be formatted as a UUID to uniquely identify documents across collections, though this isn’t strictly enforced. </span><span class="koboSpan" id="kobo.2181.2">Documents can be created by simply passing content and metadata, as in this example:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2182.1">Document(page_content="Hello, world!", metadata={"source": "https://example.com"})</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2183.1">This interface serves as the standard representation of text data throughout LangChain’s document processing pipelines, enabling consistent handling during loading, splitting, transformation, and retrieval operations. </span></p>
</div>
</div>
<div aria-label="163" epub:type="pagebreak" id="page57" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2184.1">This module is responsible for loading documents in various formats. </span><span class="koboSpan" id="kobo.2184.2">It defines:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2185.1">Custom Loader classes</span></strong><span class="koboSpan" id="kobo.2186.1">: The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2187.1">EpubReader</span></code><span class="koboSpan" id="kobo.2188.1"> class inherits from </span><code class="inlineCode"><span class="koboSpan" id="kobo.2189.1">UnstructuredEPubLoader</span></code><span class="koboSpan" id="kobo.2190.1"> and configures it to work in “fast” mode using element extraction, optimizing it for EPUB document processing.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2191.1">DocumentLoader class</span></strong><span class="koboSpan" id="kobo.2192.1">: A central class that manages document loading across different file formats by maintaining a mapping between file extensions and their appropriate loader classes.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2193.1">load_document function</span></strong><span class="koboSpan" id="kobo.2194.1">: A utility function that accepts a file path, determines its extension, instantiates the appropriate loader class from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.2195.1">DocumentLoader</span></code><span class="koboSpan" id="kobo.2196.1">'s mapping, and returns the loaded content as a list of </span><code class="inlineCode"><span class="koboSpan" id="kobo.2197.1">Document</span></code><span class="koboSpan" id="kobo.2198.1"> objects.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.2199.1">Let’s get the imports out of the way:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2200.1">import</span></span><span class="koboSpan" id="kobo.2201.1"> logging</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2202.1">import</span></span><span class="koboSpan" id="kobo.2203.1"> os</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2204.1">import</span></span><span class="koboSpan" id="kobo.2205.1"> pathlib</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2206.1">import</span></span><span class="koboSpan" id="kobo.2207.1"> tempfile</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2208.1">from</span></span><span class="koboSpan" id="kobo.2209.1"> typing </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2210.1">import</span></span><span class="koboSpan" id="kobo.2211.1"> Any</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2212.1">from</span></span><span class="koboSpan" id="kobo.2213.1"> langchain_community.document_loaders.epub </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2214.1">import</span></span><span class="koboSpan" id="kobo.2215.1"> UnstructuredEPubLoader</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2216.1">from</span></span><span class="koboSpan" id="kobo.2217.1"> langchain_community.document_loaders.pdf </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2218.1">import</span></span><span class="koboSpan" id="kobo.2219.1"> PyPDFLoader</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2220.1">from</span></span><span class="koboSpan" id="kobo.2221.1"> langchain_community.document_loaders.text </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2222.1">import</span></span><span class="koboSpan" id="kobo.2223.1"> TextLoader</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2224.1">from</span></span><span class="koboSpan" id="kobo.2225.1"> langchain_community.document_loaders.word_document </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2226.1">import</span></span><span class="koboSpan" id="kobo.2227.1"> (</span></p>
<p class="snippet-code"> <span class="hljs-type"><span class="koboSpan" id="kobo.2228.1">UnstructuredWordDocumentLoader</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2229.1">)</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2230.1">from</span></span><span class="koboSpan" id="kobo.2231.1"> langchain_core.documents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2232.1">import</span></span><span class="koboSpan" id="kobo.2233.1"> Document</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2234.1">from</span></span><span class="koboSpan" id="kobo.2235.1"> streamlit.logger </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2236.1">import</span></span><span class="koboSpan" id="kobo.2237.1"> get_logger</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2238.1">logging</span></span><span class="koboSpan" id="kobo.2239.1">.basicConfig(encoding=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2240.1">"utf-8"</span></span><span class="koboSpan" id="kobo.2241.1">, level=logging.</span><span class="hljs-type"><span class="koboSpan" id="kobo.2242.1">INFO</span></span><span class="koboSpan" id="kobo.2243.1">)</span></p>
<p class="snippet-code"><span class="hljs-type"><span class="koboSpan" id="kobo.2244.1">LOGGER</span></span><span class="koboSpan" id="kobo.2245.1"> = get_logger(__name__)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2246.1">This module first defines a custom class, </span><code class="inlineCode"><span class="koboSpan" id="kobo.2247.1">EpubReader</span></code><span class="koboSpan" id="kobo.2248.1">, that inherits from </span><code class="inlineCode"><span class="koboSpan" id="kobo.2249.1">UnstructuredEPubLoader</span></code><span class="koboSpan" id="kobo.2250.1">. </span><span class="koboSpan" id="kobo.2250.2">This class is responsible for loading documents with supported extensions. </span><span class="koboSpan" id="kobo.2250.3">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2251.1">supported_extentions</span></code><span class="koboSpan" id="kobo.2252.1"> dictionary maps file extensions to their corresponding document loader </span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.2253.1">classes. </span><span class="koboSpan" id="kobo.2253.2">This gives us interfaces to read PDF, text, EPUB, and Word documents with different extensions.</span></p>
<div aria-label="164" epub:type="pagebreak" id="page58" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2254.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2255.1">EpubReader</span></code><span class="koboSpan" id="kobo.2256.1"> class inherits from an EPUB loader and configures it to work in </span><code class="inlineCode"><span class="koboSpan" id="kobo.2257.1">"fast"</span></code><span class="koboSpan" id="kobo.2258.1"> mode using element extraction:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2259.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2260.1">EpubReader</span></span><span class="koboSpan" id="kobo.2261.1">(</span><span class="hljs-title"><span class="koboSpan" id="kobo.2262.1">UnstructuredEPubLoader</span></span><span class="koboSpan" id="kobo.2263.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2264.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2265.1">__init__</span></span><span class="koboSpan" id="kobo.2266.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2267.1">self, file_path: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2268.1">str</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2269.1"> | </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2270.1">list</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2271.1">[</span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2272.1">str</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2273.1">], **unstructured_kwargs: </span></span><span class="hljs-type"><span class="koboSpan" id="kobo.2274.1">Any</span></span><span class="koboSpan" id="kobo.2275.1">):</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2276.1">super</span></span><span class="koboSpan" id="kobo.2277.1">().__init__(file_path, **unstructured_kwargs, mode=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2278.1">"elements"</span></span><span class="koboSpan" id="kobo.2279.1">, strategy=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2280.1">"fast"</span></span><span class="koboSpan" id="kobo.2281.1">)</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2282.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2283.1">DocumentLoaderException</span></span><span class="koboSpan" id="kobo.2284.1">(</span><span class="hljs-title"><span class="koboSpan" id="kobo.2285.1">Exception</span></span><span class="koboSpan" id="kobo.2286.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2287.1">pass</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2288.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2289.1">DocumentLoader</span></span><span class="koboSpan" id="kobo.2290.1">(</span><span class="hljs-title"><span class="koboSpan" id="kobo.2291.1">object</span></span><span class="koboSpan" id="kobo.2292.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2293.1">"""Loads in a document with a supported extension."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2294.1">    supported_extensions = {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2295.1">".pdf"</span></span><span class="koboSpan" id="kobo.2296.1">: PyPDFLoader,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2297.1">".txt"</span></span><span class="koboSpan" id="kobo.2298.1">: TextLoader,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2299.1">".epub"</span></span><span class="koboSpan" id="kobo.2300.1">: EpubReader,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2301.1">".docx"</span></span><span class="koboSpan" id="kobo.2302.1">: UnstructuredWordDocumentLoader,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2303.1">".doc"</span></span><span class="koboSpan" id="kobo.2304.1">: UnstructuredWordDocumentLoader,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2305.1">    }</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2306.1">Our </span><code class="inlineCode"><span class="koboSpan" id="kobo.2307.1">DocumentLoader</span></code><span class="koboSpan" id="kobo.2308.1"> maintains a mapping (</span><code class="inlineCode"><span class="koboSpan" id="kobo.2309.1">supported_extensions</span></code><span class="koboSpan" id="kobo.2310.1">) of file extensions (for example, .pdf, .txt, .epub, .docx, .doc) to their respective loader classes. </span><span class="koboSpan" id="kobo.2310.2">But we’ll also need one more function:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2311.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2312.1">load_document</span></span><span class="koboSpan" id="kobo.2313.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2314.1">temp_filepath: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2315.1">str</span></span><span class="koboSpan" id="kobo.2316.1">) -&gt; </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2317.1">list</span></span><span class="koboSpan" id="kobo.2318.1">[Document]:</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2319.1">"""Load a file and return it as a list of documents."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2320.1">    ext = pathlib.Path(temp_filepath).suffix</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2321.1">    loader = DocumentLoader.supported_extensions.get(ext)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2322.1">if</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2323.1">not</span></span><span class="koboSpan" id="kobo.2324.1"> loader:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2325.1">raise</span></span><span class="koboSpan" id="kobo.2326.1"> DocumentLoaderException(</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2327.1">f"Invalid extension type </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2328.1">{ext}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2329.1">, cannot load this type of file"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2330.1">        )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2331.1">    loaded = loader(temp_filepath)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2332.1">    docs = loaded.load()</span></p>
<div aria-label="165" epub:type="pagebreak" id="page59" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.2333.1">    logging.info(docs)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2334.1">return</span></span><span class="koboSpan" id="kobo.2335.1"> docs</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2336.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2337.1">load_document</span></code><span class="koboSpan" id="kobo.2338.1"> function defined above takes a file path, determines its extension, selects the appropriate loader from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.2339.1">supported_extensions</span></code><span class="koboSpan" id="kobo.2340.1"> dictionary, and returns a list of </span><code class="inlineCode"><span class="koboSpan" id="kobo.2341.1">Document</span></code><span class="koboSpan" id="kobo.2342.1"> objects. </span><span class="koboSpan" id="kobo.2342.2">If the file </span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.2343.1">extension isn’t supported, it raises a </span><code class="inlineCode"><span class="koboSpan" id="kobo.2344.1">DocumentLoaderException</span></code><span class="koboSpan" id="kobo.2345.1"> to alert the user that the file type cannot be pr</span><a id="_idTextAnchor214"/><span class="koboSpan" id="kobo.2346.1">ocessed.</span></p>
<h2 class="heading-2" id="_idParaDest-114"><a id="_idTextAnchor215"/><span class="koboSpan" id="kobo.2347.1">Language model setup</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.2348.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2349.1">llms.py</span></code><span class="koboSpan" id="kobo.2350.1"> module sets</span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.2351.1"> up the LLM and embeddings for the application. </span><span class="koboSpan" id="kobo.2351.2">First, the imports and loading the API keys as environment variables – please see </span><a href="E_Chapter_2.xhtml#_idTextAnchor044"><em class="italic"><span class="koboSpan" id="kobo.2352.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.2353.1"> for details if you skipped that part.</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2354.1">from</span></span><span class="koboSpan" id="kobo.2355.1"> langchain.embeddings </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2356.1">import</span></span><span class="koboSpan" id="kobo.2357.1"> CacheBackedEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2358.1">from</span></span><span class="koboSpan" id="kobo.2359.1"> langchain.</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2360.1">storage</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2361.1">import</span></span><span class="koboSpan" id="kobo.2362.1"> LocalFileStore</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2363.1">from</span></span><span class="koboSpan" id="kobo.2364.1"> langchain_groq </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2365.1">import</span></span><span class="koboSpan" id="kobo.2366.1"> ChatGroq</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2367.1">from</span></span><span class="koboSpan" id="kobo.2368.1"> langchain_openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2369.1">import</span></span><span class="koboSpan" id="kobo.2370.1"> OpenAIEmbeddings</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2371.1">from</span></span><span class="koboSpan" id="kobo.2372.1"> config </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2373.1">import</span></span><span class="koboSpan" id="kobo.2374.1"> set_environment</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2375.1">set_environment()</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2376.1">Let’s initialize the LangChain </span><code class="inlineCode"><span class="koboSpan" id="kobo.2377.1">ChatGroq</span></code><span class="koboSpan" id="kobo.2378.1"> interface using the API key from environment variables:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2379.1">chat_model = ChatGroq(</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.2380.1">model</span></span><span class="koboSpan" id="kobo.2381.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2382.1">"deepseek-r1-distill-llama-70b"</span></span><span class="koboSpan" id="kobo.2383.1">,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.2384.1">temperature</span></span><span class="koboSpan" id="kobo.2385.1">=0,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.2386.1">max_tokens</span></span><span class="koboSpan" id="kobo.2387.1">=None,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.2388.1">timeout</span></span><span class="koboSpan" id="kobo.2389.1">=None,</span></p>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.2390.1">max_retries</span></span><span class="koboSpan" id="kobo.2391.1">=2,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2392.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2393.1">This uses </span><code class="inlineCode"><span class="koboSpan" id="kobo.2394.1">ChatGroq</span></code><span class="koboSpan" id="kobo.2395.1"> (configured with a specific model, temperature, and retries) for generating documentation drafts and revisions. </span><span class="koboSpan" id="kobo.2395.2">The configured model is the DeepSeek 70B R1 model.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2396.1">We’ll then use </span><code class="inlineCode"><span class="koboSpan" id="kobo.2397.1">OpenAIEmbeddings</span></code><span class="koboSpan" id="kobo.2398.1"> to convert text into vector representations:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2399.1">store = LocalFileStore(</span><span class="hljs-string"><span class="koboSpan" id="kobo.2400.1">"./cache/"</span></span><span class="koboSpan" id="kobo.2401.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2402.1">underlying_embeddings = OpenAIEmbeddings(</span></p>
<div aria-label="166" epub:type="pagebreak" id="page60" role="doc-pagebreak"/>
<p class="snippet-code"> <span class="hljs-attribute"><span class="koboSpan" id="kobo.2403.1">model</span></span><span class="koboSpan" id="kobo.2404.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2405.1">"text-embedding-3-large"</span></span><span class="koboSpan" id="kobo.2406.1">,</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2407.1">)</span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.2408.1"># Avoiding unnecessary costs by caching the embeddings.</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2409.1">EMBEDDINGS = CacheBackedEmbeddings.from_bytes_store(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2410.1">    underlying_embeddings, store, </span><span class="hljs-attribute"><span class="koboSpan" id="kobo.2411.1">namespace</span></span><span class="koboSpan" id="kobo.2412.1">=underlying_embeddings.model</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2413.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2414.1">To reduce API costs and </span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.2415.1">speed up repeated queries, it wraps the embeddings with a caching mechanism (</span><code class="inlineCode"><span class="koboSpan" id="kobo.2416.1">CacheBackedEmbeddings</span></code><span class="koboSpan" id="kobo.2417.1">) that stores vectors locally in a file-based store (</span><code class="inlineCode"><span class="koboSpan" id="kobo.2418.1">LocalF</span><a id="_idTextAnchor216"/><span class="koboSpan" id="kobo.2419.1">ileStore</span></code><span class="koboSpan" id="kobo.2420.1">).</span></p>
<h2 class="heading-2" id="_idParaDest-115"><a id="_idTextAnchor217"/><span class="koboSpan" id="kobo.2421.1">Document retrieval</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.2422.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2423.1">rag.py</span></code><span class="koboSpan" id="kobo.2424.1"> module implements </span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.2425.1">document retrieval based on semantic similarity. </span><span class="koboSpan" id="kobo.2425.2">We have these main components:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.2426.1">Text splitting</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.2427.1">In-memory vector store</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2428.1">DocumentRetriever</span></code><span class="koboSpan" id="kobo.2429.1"> class</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.2430.1">Let’s start with the imports again:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2431.1">import</span></span><span class="koboSpan" id="kobo.2432.1"> os</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2433.1">import</span></span><span class="koboSpan" id="kobo.2434.1"> tempfile</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2435.1">from</span></span><span class="koboSpan" id="kobo.2436.1"> typing </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2437.1">import</span></span><span class="koboSpan" id="kobo.2438.1"> List, Any</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2439.1">from</span></span><span class="koboSpan" id="kobo.2440.1"> langchain_core.callbacks </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2441.1">import</span></span><span class="koboSpan" id="kobo.2442.1"> CallbackManagerForRetrieverRun</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2443.1">from</span></span><span class="koboSpan" id="kobo.2444.1"> langchain_core.documents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2445.1">import</span></span><span class="koboSpan" id="kobo.2446.1"> Document</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2447.1">from</span></span><span class="koboSpan" id="kobo.2448.1"> langchain_core.retrievers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2449.1">import</span></span><span class="koboSpan" id="kobo.2450.1"> BaseRetriever</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2451.1">from</span></span><span class="koboSpan" id="kobo.2452.1"> langchain_core.vectorstores </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2453.1">import</span></span><span class="koboSpan" id="kobo.2454.1"> InMemoryVectorStore</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2455.1">from</span></span><span class="koboSpan" id="kobo.2456.1"> langchain_text_splitters </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2457.1">import</span></span><span class="koboSpan" id="kobo.2458.1"> RecursiveCharacterTextSplitter</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2459.1">from</span></span><span class="koboSpan" id="kobo.2460.1"> chapter4.document_loader </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2461.1">import</span></span><span class="koboSpan" id="kobo.2462.1"> load_document</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2463.1">from</span></span><span class="koboSpan" id="kobo.2464.1"> chapter4.llms </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2465.1">import</span></span><span class="koboSpan" id="kobo.2466.1"> EMBEDDINGS</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2467.1">We need to set up a vector store for the retriever to use:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2468.1">VECTOR_STORE </span><span class="hljs-operator"><span class="koboSpan" id="kobo.2469.1">=</span></span><span class="koboSpan" id="kobo.2470.1"> InMemoryVectorStore(embedding</span><span class="hljs-operator"><span class="koboSpan" id="kobo.2471.1">=</span></span><span class="koboSpan" id="kobo.2472.1">EMBEDDINGS)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2473.1">The document chunks are stored in an </span><code class="inlineCode"><span class="koboSpan" id="kobo.2474.1">InMemoryVectorStore</span></code><span class="koboSpan" id="kobo.2475.1"> using the cached embeddings, allowing for fast similarity searches. </span><span class="koboSpan" id="kobo.2475.2">The module uses </span><code class="inlineCode"><span class="koboSpan" id="kobo.2476.1">RecursiveCharacterTextSplitter</span></code><span class="koboSpan" id="kobo.2477.1"> to break documents into smaller chunks, which makes them more manageable for retrieval:</span></p>
<div aria-label="167" epub:type="pagebreak" id="page61" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2478.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2479.1">split_documents</span></span><span class="koboSpan" id="kobo.2480.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2481.1">docs: </span></span><span class="hljs-type"><span class="koboSpan" id="kobo.2482.1">List</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2483.1">[Document]</span></span><span class="koboSpan" id="kobo.2484.1">) -&gt; </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2485.1">list</span></span><span class="koboSpan" id="kobo.2486.1">[Document]:</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2487.1">"""Split each document."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2488.1">    text_splitter = RecursiveCharacterTextSplitter(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2489.1">        chunk_size=</span><span class="hljs-number"><span class="koboSpan" id="kobo.2490.1">1500</span></span><span class="koboSpan" id="kobo.2491.1">, chunk_overlap=</span><span class="hljs-number"><span class="koboSpan" id="kobo.2492.1">200</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2493.1">    )</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2494.1">return</span></span><span class="koboSpan" id="kobo.2495.1"> text_splitter.split_documents(docs)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2496.1">This custom retriever inherits </span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.2497.1">from a base retriever and manages an internal list of documents:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2498.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2499.1">DocumentRetriever</span></span><span class="koboSpan" id="kobo.2500.1">(</span><span class="hljs-title"><span class="koboSpan" id="kobo.2501.1">BaseRetriever</span></span><span class="koboSpan" id="kobo.2502.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2503.1">"""A retriever that contains the top k documents that contain the user query."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2504.1">    documents: </span><span class="hljs-type"><span class="koboSpan" id="kobo.2505.1">List</span></span><span class="koboSpan" id="kobo.2506.1">[Document] = []</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2507.1">    k: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2508.1">int</span></span><span class="koboSpan" id="kobo.2509.1"> = </span><span class="hljs-number"><span class="koboSpan" id="kobo.2510.1">5</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2511.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2512.1">model_post_init</span></span><span class="koboSpan" id="kobo.2513.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2514.1">self, ctx: </span></span><span class="hljs-type"><span class="koboSpan" id="kobo.2515.1">Any</span></span><span class="koboSpan" id="kobo.2516.1">) -&gt; </span><span class="hljs-literal"><span class="koboSpan" id="kobo.2517.1">None</span></span><span class="koboSpan" id="kobo.2518.1">:</span></p>
<p class="snippet-code"> <span class="hljs-variable"><span class="koboSpan" id="kobo.2519.1">self</span></span><span class="koboSpan" id="kobo.2520.1">.store_documents(</span><span class="hljs-variable"><span class="koboSpan" id="kobo.2521.1">self</span></span><span class="koboSpan" id="kobo.2522.1">.documents)</span></p>
<p class="snippet-code"><span class="hljs-meta"><span class="koboSpan" id="kobo.2523.1">    @staticmethod</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2524.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2525.1">store_documents</span></span><span class="koboSpan" id="kobo.2526.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2527.1">docs: </span></span><span class="hljs-type"><span class="koboSpan" id="kobo.2528.1">List</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2529.1">[Document]</span></span><span class="koboSpan" id="kobo.2530.1">) -&gt; </span><span class="hljs-literal"><span class="koboSpan" id="kobo.2531.1">None</span></span><span class="koboSpan" id="kobo.2532.1">:</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2533.1">"""Add documents to the vector store."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2534.1">        splits = split_documents(docs)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2535.1">        VECTOR_STORE.add_documents(splits)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2536.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2537.1">add_uploaded_docs</span></span><span class="koboSpan" id="kobo.2538.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2539.1">self, uploaded_files</span></span><span class="koboSpan" id="kobo.2540.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2541.1">"""Add uploaded documents."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2542.1">        docs = []</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2543.1">        temp_dir = tempfile.TemporaryDirectory()</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2544.1">for</span></span><span class="koboSpan" id="kobo.2545.1"> file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2546.1">in</span></span><span class="koboSpan" id="kobo.2547.1"> uploaded_files:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2548.1">            temp_filepath = os.path.join(temp_dir.name, file.name)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2549.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2550.1">open</span></span><span class="koboSpan" id="kobo.2551.1">(temp_filepath, </span><span class="hljs-string"><span class="koboSpan" id="kobo.2552.1">"wb"</span></span><span class="koboSpan" id="kobo.2553.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2554.1">as</span></span><span class="koboSpan" id="kobo.2555.1"> f:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2556.1">                f.write(file.getvalue())</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2557.1">                docs.extend(load_document(temp_filepath))</span></p>
<p class="snippet-code"> <span class="hljs-variable"><span class="koboSpan" id="kobo.2558.1">self</span></span><span class="koboSpan" id="kobo.2559.1">.documents.extend(docs)</span></p>
<p class="snippet-code"> <span class="hljs-variable"><span class="koboSpan" id="kobo.2560.1">self</span></span><span class="koboSpan" id="kobo.2561.1">.store_documents(docs)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2562.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2563.1">_get_relevant_documents</span></span><span class="koboSpan" id="kobo.2564.1">(</span></p>
<p class="snippet-code"><span class="hljs-params"><span class="koboSpan" id="kobo.2565.1">            self, query: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2566.1">str</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2567.1">, *, run_manager: CallbackManagerForRetrieverRun</span></span></p>
<div aria-label="168" epub:type="pagebreak" id="page62" role="doc-pagebreak"/>
<p class="snippet-code"><span class="hljs-params"> </span><span class="koboSpan" id="kobo.2568.1">) -&gt; </span><span class="hljs-type"><span class="koboSpan" id="kobo.2569.1">List</span></span><span class="koboSpan" id="kobo.2570.1">[Document]:</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2571.1">"""Sync implementations for retriever."""</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2572.1">if</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2573.1">len</span></span><span class="koboSpan" id="kobo.2574.1">(</span><span class="hljs-variable"><span class="koboSpan" id="kobo.2575.1">self</span></span><span class="koboSpan" id="kobo.2576.1">.documents) == </span><span class="hljs-number"><span class="koboSpan" id="kobo.2577.1">0</span></span><span class="koboSpan" id="kobo.2578.1">:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2579.1">return</span></span><span class="koboSpan" id="kobo.2580.1"> []</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2581.1">return</span></span><span class="koboSpan" id="kobo.2582.1"> VECTOR_STORE.similarity_search(query=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2583.1">""</span></span><span class="koboSpan" id="kobo.2584.1">, k=</span><span class="hljs-variable"><span class="koboSpan" id="kobo.2585.1">self</span></span><span class="koboSpan" id="kobo.2586.1">.k)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2587.1">There are a few methods that we should explain:</span></p>
<ul>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2588.1">store_documents()</span></code><span class="koboSpan" id="kobo.2589.1"> splits the documents and adds them to the vector store.</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2590.1">add_uploaded_docs()</span></code><span class="koboSpan" id="kobo.2591.1"> processes files uploaded by the user, stores them temporarily, loads them as documents, and adds them to the vector store.</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2592.1">_get_relevant_documents()</span></code><span class="koboSpan" id="kobo.2593.1"> returns the top k documents related to a given query from the vector </span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.2594.1">store. </span><span class="koboSpan" id="kobo.2594.2">This is the similarity search th</span><a id="_idTextAnchor218"/><span class="koboSpan" id="kobo.2595.1">at we’ll use.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-116"><a id="_idTextAnchor219"/><span class="koboSpan" id="kobo.2596.1">Designing the state graph</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.2597.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.2598.1">rag.py</span></code><span class="koboSpan" id="kobo.2599.1"> module implements the RAG pipeline that ties together document retrieval with LLM-based generation:</span></p>
<div aria-label="169" epub:type="pagebreak" id="page63" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2600.1">System prompt</span></strong><span class="koboSpan" id="kobo.2601.1">: A template </span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.2602.1">prompt instructs the AI on how to use the provided document snippets when generating a response. </span><span class="koboSpan" id="kobo.2602.2">This prompt sets the context and provides guidance on how to utilize the retrieved information.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2603.1">State definition</span></strong><span class="koboSpan" id="kobo.2604.1">: A </span><code class="inlineCode"><span class="koboSpan" id="kobo.2605.1">TypedDict</span></code><span class="koboSpan" id="kobo.2606.1"> class defines the structure of our graph’s state, tracking key information like the user’s question, retrieved context documents, generated answers, issues reports, and the conversation’s message history. </span><span class="koboSpan" id="kobo.2606.2">This state object flows through each node in our pipeline and gets updated at each step.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2607.1">Pipeline steps</span></strong><span class="koboSpan" id="kobo.2608.1">: The module defines several key functions that serve as processing nodes in our graph:</span><ul><li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.2609.1">Retrieve function</span></strong><span class="koboSpan" id="kobo.2610.1">: Fetches relevant documents based on the user’s query</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.2611.1">generate function</span></strong><span class="koboSpan" id="kobo.2612.1">: Creates a draft answer using the retrieved documents and query</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.2613.1">double_check function</span></strong><span class="koboSpan" id="kobo.2614.1">: Evaluates the generated content for compliance with corporate standards</span></li>
<li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.2615.1">doc_finalizer function</span></strong><span class="koboSpan" id="kobo.2616.1">: Either returns the original answer if no issues were found or revises it based on the feedback from the checker</span></li>
</ul></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.2617.1">Graph compilation</span></strong><span class="koboSpan" id="kobo.2618.1">: Uses a state graph (via LangGraph’s </span><code class="inlineCode"><span class="koboSpan" id="kobo.2619.1">StateGraph</span></code><span class="koboSpan" id="kobo.2620.1">) to define the sequence of steps. </span><span class="koboSpan" id="kobo.2620.2">The pipeline is then compiled into a runnable graph that can process queries through the complete workflow.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.2621.1">Let’s get the imports out of the way:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2622.1">from</span></span><span class="koboSpan" id="kobo.2623.1"> typing </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2624.1">import</span></span><span class="koboSpan" id="kobo.2625.1"> Annotated</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2626.1">from</span></span><span class="koboSpan" id="kobo.2627.1"> langchain_core.documents </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2628.1">import</span></span><span class="koboSpan" id="kobo.2629.1"> Document</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2630.1">from</span></span><span class="koboSpan" id="kobo.2631.1"> langchain_core.messages </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2632.1">import</span></span><span class="koboSpan" id="kobo.2633.1"> AIMessage</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2634.1">from</span></span><span class="koboSpan" id="kobo.2635.1"> langchain_core.prompts </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2636.1">import</span></span><span class="koboSpan" id="kobo.2637.1"> ChatPromptTemplate</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2638.1">from</span></span><span class="koboSpan" id="kobo.2639.1"> langgraph.</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2640.1">checkpoint</span></span><span class="koboSpan" id="kobo.2641.1">.memory </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2642.1">import</span></span><span class="koboSpan" id="kobo.2643.1"> MemorySaver</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2644.1">from</span></span><span class="koboSpan" id="kobo.2645.1"> langgraph.constants </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2646.1">import</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2647.1">END</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2648.1">from</span></span><span class="koboSpan" id="kobo.2649.1"> langgraph.graph </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2650.1">import</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2651.1">START</span></span><span class="koboSpan" id="kobo.2652.1">, StateGraph, add_messages</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2653.1">from</span></span><span class="koboSpan" id="kobo.2654.1"> typing_extensions </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2655.1">import</span></span><span class="koboSpan" id="kobo.2656.1"> List, TypedDict</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2657.1">from</span></span><span class="koboSpan" id="kobo.2658.1"> chapter4.llms </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2659.1">import</span></span><span class="koboSpan" id="kobo.2660.1"> chat_model</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2661.1">from</span></span><span class="koboSpan" id="kobo.2662.1"> chapter4.retriever </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2663.1">import</span></span><span class="koboSpan" id="kobo.2664.1"> DocumentRetriever</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2665.1">As we mentioned earlier, the system prompt template instructs the AI on how to use the provided document snippets </span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.2666.1">when generating a response:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2667.1">system_prompt = (</span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2668.1">"You're a helpful AI assistant. </span><span class="koboSpan" id="kobo.2668.2">Given a user question "</span></span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2669.1">"and some corporate document snippets, write documentation."</span></span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2670.1">"If none of the documents is relevant to the question, "</span></span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2671.1">"mention that there's no relevant document, and then "</span></span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2672.1">"</span></span><span class="hljs-comment"><span class="koboSpan" id="kobo.2673.1">answer the question to the best of your knowledge."</span></span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2674.1">"\n\nHere are the corporate documents: "</span></span></p>
<p class="snippet-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.2675.1">"{context}"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2676.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2677.1">We’ll then instantiate a </span><code class="inlineCode"><span class="koboSpan" id="kobo.2678.1">DocumentRetriever</span></code><span class="koboSpan" id="kobo.2679.1"> and a </span><code class="inlineCode"><span class="koboSpan" id="kobo.2680.1">prompt</span></code><span class="koboSpan" id="kobo.2681.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2682.1">retriever = DocumentRetriever()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2683.1">prompt = ChatPromptTemplate.from_messages(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2684.1">    [</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2685.1">        (</span><span class="hljs-string"><span class="koboSpan" id="kobo.2686.1">"system"</span></span><span class="koboSpan" id="kobo.2687.1">, system_prompt),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2688.1">        (</span><span class="hljs-string"><span class="koboSpan" id="kobo.2689.1">"human"</span></span><span class="koboSpan" id="kobo.2690.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.2691.1">"{question}"</span></span><span class="koboSpan" id="kobo.2692.1">),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2693.1">    ]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2694.1">)</span></p>
<div aria-label="170" epub:type="pagebreak" id="page64" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2695.1">We then have to define the state of the graph. </span><span class="koboSpan" id="kobo.2695.2">A </span><code class="inlineCode"><span class="koboSpan" id="kobo.2696.1">TypedDict</span></code><span class="koboSpan" id="kobo.2697.1"> state is used to hold the current state of the application (for example, question, context documents, answer, issues report):</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2698.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2699.1">State</span></span><span class="koboSpan" id="kobo.2700.1">(</span><span class="hljs-title"><span class="koboSpan" id="kobo.2701.1">TypedDict</span></span><span class="koboSpan" id="kobo.2702.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2703.1">    question: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2704.1">str</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2705.1">    context: </span><span class="hljs-type"><span class="koboSpan" id="kobo.2706.1">List</span></span><span class="koboSpan" id="kobo.2707.1">[Document]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2708.1">    answer: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2709.1">str</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2710.1">    issues_report: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2711.1">str</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2712.1">    issues_detected: </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2713.1">bool</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2714.1">    messages: Annotated[</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2715.1">list</span></span><span class="koboSpan" id="kobo.2716.1">, add_messages]</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2717.1">Each of these fields corresponds to a node in the graph that we’ll define with LangGraph. </span><span class="koboSpan" id="kobo.2717.2">We have the following processing in the nodes:</span></p>
<ul>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2718.1">retrieve</span></code><span class="koboSpan" id="kobo.2719.1"> function: Uses the retriever to get relevant documents based on the most recent message</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2720.1">generate</span></code><span class="koboSpan" id="kobo.2721.1"> function: Creates a draft answer by combining the retrieved document content with the user question using the chat prompt</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2722.1">double_check</span></code><span class="koboSpan" id="kobo.2723.1"> function: Reviews the generated draft for compliance with corporate standards. </span><span class="koboSpan" id="kobo.2723.2">It checks the draft and sets flags if issues are detected</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.2724.1">doc_finalizer</span></code><span class="koboSpan" id="kobo.2725.1"> function: If issues are found, it revises the document based on the provided feedback; otherwise, it returns</span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.2726.1"> the original answer</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.2727.1">Let’s start with the retrieval:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2728.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2729.1">retrieve</span></span><span class="koboSpan" id="kobo.2730.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2731.1">state: State</span></span><span class="koboSpan" id="kobo.2732.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2733.1">    retrieved_docs = retriever.invoke(state[</span><span class="hljs-string"><span class="koboSpan" id="kobo.2734.1">"messages"</span></span><span class="koboSpan" id="kobo.2735.1">][-</span><span class="hljs-number"><span class="koboSpan" id="kobo.2736.1">1</span></span><span class="koboSpan" id="kobo.2737.1">].content)</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2738.1">print</span></span><span class="koboSpan" id="kobo.2739.1">(retrieved_docs)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2740.1">return</span></span><span class="koboSpan" id="kobo.2741.1"> {</span><span class="hljs-string"><span class="koboSpan" id="kobo.2742.1">"context"</span></span><span class="koboSpan" id="kobo.2743.1">: retrieved_docs}</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2744.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2745.1">generate</span></span><span class="koboSpan" id="kobo.2746.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2747.1">state: State</span></span><span class="koboSpan" id="kobo.2748.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2749.1">    docs_content = </span><span class="hljs-string"><span class="koboSpan" id="kobo.2750.1">"\n\n"</span></span><span class="koboSpan" id="kobo.2751.1">.join(doc.page_content </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2752.1">for</span></span><span class="koboSpan" id="kobo.2753.1"> doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2754.1">in</span></span><span class="koboSpan" id="kobo.2755.1"> state[</span><span class="hljs-string"><span class="koboSpan" id="kobo.2756.1">"context"</span></span><span class="koboSpan" id="kobo.2757.1">])</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2758.1">    messages = prompt.invoke(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2759.1">        {</span><span class="hljs-string"><span class="koboSpan" id="kobo.2760.1">"question"</span></span><span class="koboSpan" id="kobo.2761.1">: state[</span><span class="hljs-string"><span class="koboSpan" id="kobo.2762.1">"messages"</span></span><span class="koboSpan" id="kobo.2763.1">][-</span><span class="hljs-number"><span class="koboSpan" id="kobo.2764.1">1</span></span><span class="koboSpan" id="kobo.2765.1">].content, </span><span class="hljs-string"><span class="koboSpan" id="kobo.2766.1">"context"</span></span><span class="koboSpan" id="kobo.2767.1">: docs_content}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2768.1">    )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2769.1">    response = chat_model.invoke(messages)</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2770.1">print</span></span><span class="koboSpan" id="kobo.2771.1">(response.content)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2772.1">return</span></span><span class="koboSpan" id="kobo.2773.1"> {</span><span class="hljs-string"><span class="koboSpan" id="kobo.2774.1">"answer"</span></span><span class="koboSpan" id="kobo.2775.1">: response.content}</span></p>
<div aria-label="171" epub:type="pagebreak" id="page65" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2776.1">We’ll also implement a content validation check as a critical quality assurance step in our RAG pipeline. </span><span class="koboSpan" id="kobo.2776.2">Please note that this is the simplest implementation possible. </span><span class="koboSpan" id="kobo.2776.3">In a production environment, we could have implemented a human-in-the-loop review process or more sophisticated guardrails. </span><span class="koboSpan" id="kobo.2776.4">Here, we’re using an LLM to analyze the generated content for any issues:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2777.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2778.1">double_check</span></span><span class="koboSpan" id="kobo.2779.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2780.1">state: State</span></span><span class="koboSpan" id="kobo.2781.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2782.1">    result = chat_model.invoke(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2783.1">        [{</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2784.1">"role"</span></span><span class="koboSpan" id="kobo.2785.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.2786.1">"user"</span></span><span class="koboSpan" id="kobo.2787.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2788.1">"content"</span></span><span class="koboSpan" id="kobo.2789.1">: (</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2790.1">f"Review the following project documentation for compliance with our corporate standards. </span><span class="koboSpan" id="kobo.2790.2">"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2791.1">f"Return 'ISSUES FOUND' followed by any issues detected or 'NO ISSUES': </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2792.1">{state[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2793.1">'answer'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2794.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2795.1">"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2796.1">            )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2797.1">        }]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2798.1">    )</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2799.1">if</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.2800.1">"ISSUES FOUND"</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2801.1">in</span></span><span class="koboSpan" id="kobo.2802.1"> result.content:</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2803.1">print</span></span><span class="koboSpan" id="kobo.2804.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.2805.1">"issues detected"</span></span><span class="koboSpan" id="kobo.2806.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2807.1">return</span></span><span class="koboSpan" id="kobo.2808.1"> {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2809.1">"issues_report"</span></span><span class="koboSpan" id="kobo.2810.1">: result.split(</span><span class="hljs-string"><span class="koboSpan" id="kobo.2811.1">"ISSUES FOUND"</span></span><span class="koboSpan" id="kobo.2812.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.2813.1">1</span></span><span class="koboSpan" id="kobo.2814.1">)[</span><span class="hljs-number"><span class="koboSpan" id="kobo.2815.1">1</span></span><span class="koboSpan" id="kobo.2816.1">].strip(),</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2817.1">"issues_detected"</span></span><span class="koboSpan" id="kobo.2818.1">: </span><span class="hljs-literal"><span class="koboSpan" id="kobo.2819.1">True</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2820.1">        }</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.2821.1">print</span></span><span class="koboSpan" id="kobo.2822.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.2823.1">"no issues detected"</span></span><span class="koboSpan" id="kobo.2824.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2825.1">return</span></span><span class="koboSpan" id="kobo.2826.1"> {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2827.1">"issues_report"</span></span><span class="koboSpan" id="kobo.2828.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.2829.1">""</span></span><span class="koboSpan" id="kobo.2830.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2831.1">"issues_detected"</span></span><span class="koboSpan" id="kobo.2832.1">: </span><span class="hljs-literal"><span class="koboSpan" id="kobo.2833.1">False</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2834.1">    }</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2835.1">The final node integrates any</span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.2836.1"> feedback to produce the finalized, compliant document:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2837.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.2838.1">doc_finalizer</span></span><span class="koboSpan" id="kobo.2839.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.2840.1">state: State</span></span><span class="koboSpan" id="kobo.2841.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2842.1">"""Finalize documentation by integrating feedback."""</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2843.1">if</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.2844.1">"issues_detected"</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2845.1">in</span></span><span class="koboSpan" id="kobo.2846.1"> state </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2847.1">and</span></span><span class="koboSpan" id="kobo.2848.1"> state[</span><span class="hljs-string"><span class="koboSpan" id="kobo.2849.1">"issues_detected"</span></span><span class="koboSpan" id="kobo.2850.1">]:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2851.1">        response = chat_model.invoke(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2852.1">            messages=[{</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2853.1">"role"</span></span><span class="koboSpan" id="kobo.2854.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.2855.1">"user"</span></span><span class="koboSpan" id="kobo.2856.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2857.1">"content"</span></span><span class="koboSpan" id="kobo.2858.1">: (</span></p>
<div aria-label="172" epub:type="pagebreak" id="page66" role="doc-pagebreak"/>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2859.1">f"Revise the following documentation to address these feedback points: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2860.1">{state[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2861.1">'issues_report'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2862.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2863.1">\n"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2864.1">f"Original Document: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2865.1">{state[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2866.1">'answer'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.2867.1">]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2868.1">\n"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2869.1">f"Always return the full revised document, even if no changes are needed."</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2870.1">                )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2871.1">            }]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2872.1">        )</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2873.1">return</span></span><span class="koboSpan" id="kobo.2874.1"> {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2875.1">"messages"</span></span><span class="koboSpan" id="kobo.2876.1">: [AIMessage(response.content)]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2877.1">        }</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.2878.1">return</span></span><span class="koboSpan" id="kobo.2879.1"> {</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.2880.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2881.1">messages"</span></span><span class="koboSpan" id="kobo.2882.1">: [AIMessage(state[</span><span class="hljs-string"><span class="koboSpan" id="kobo.2883.1">"answer"</span></span><span class="koboSpan" id="kobo.2884.1">])]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2885.1">    }</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2886.1">With our nodes defined, we construct the state graph:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2887.1">graph_builder = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2888.1">StateGraph</span></span><span class="koboSpan" id="kobo.2889.1">(State)</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2890.1">.add_sequence</span></span><span class="koboSpan" id="kobo.2891.1">(</span></p>
<p class="snippet-code"> <span class="hljs-selector-attr"><span class="koboSpan" id="kobo.2892.1">[retrieve, generate, double_check, doc_finalizer]</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2893.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2894.1">graph_builder</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2895.1">.add_edge</span></span><span class="koboSpan" id="kobo.2896.1">(START, </span><span class="hljs-string"><span class="koboSpan" id="kobo.2897.1">"retrieve"</span></span><span class="koboSpan" id="kobo.2898.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2899.1">graph_builder</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2900.1">.add_edge</span></span><span class="koboSpan" id="kobo.2901.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.2902.1">"doc_finalizer"</span></span><span class="koboSpan" id="kobo.2903.1">, END)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2904.1">memory = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2905.1">MemorySaver</span></span><span class="koboSpan" id="kobo.2906.1">()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2907.1">graph = graph_builder</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2908.1">.compile</span></span><span class="koboSpan" id="kobo.2909.1">(checkpointer=memory)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2910.1">config = {</span><span class="hljs-string"><span class="koboSpan" id="kobo.2911.1">"configurable"</span></span><span class="koboSpan" id="kobo.2912.1">: {</span><span class="hljs-string"><span class="koboSpan" id="kobo.2913.1">"thread_id"</span></span><span class="koboSpan" id="kobo.2914.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.2915.1">"abc123"</span></span><span class="koboSpan" id="kobo.2916.1">}}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2917.1">We can visualize this graph from </span><span class="hljs-selector-tag"><span class="koboSpan" id="kobo.2918.1">a</span></span><span class="koboSpan" id="kobo.2919.1"> Jupyter notebook:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2920.1">from IPython</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2921.1">.display</span></span><span class="koboSpan" id="kobo.2922.1"> import Image, </span><span class="hljs-attribute"><span class="koboSpan" id="kobo.2923.1">display</span></span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2924.1">display</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2925.1">(Image(graph.get_graph()</span></span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2926.1">.draw_mermaid_png</span></span><span class="koboSpan" id="kobo.2927.1">()))</span></p>
<div aria-label="173" epub:type="pagebreak" id="page67" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2928.1">This is what the sequential flow from document retrieval to generation, validation, and finalization looks like:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.2929.1"><img alt="Figure 4.5:  State graph of the corporate documentation pipeline" src="../Images/B32363_04_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.2930.1">Figure 4.5:  State graph of the corporate documentation pipeline</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2931.1">Before building a user interface, it’s important to test our RAG pipeline to ensure it functions correctly. </span><span class="koboSpan" id="kobo.2931.2">Let’s examine how we can do this programmatically:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2932.1">from langchain_core.messages </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2933.1">import</span></span><span class="koboSpan" id="kobo.2934.1"> HumanMessage</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2935.1">input_messages = [</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2936.1">HumanMessage</span></span><span class="koboSpan" id="kobo.2937.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.2938.1">"What's the square root of 10?"</span></span><span class="koboSpan" id="kobo.2939.1">)]</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2940.1">response = graph.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.2941.1">invoke</span></span><span class="koboSpan" id="kobo.2942.1">({</span><span class="hljs-string"><span class="koboSpan" id="kobo.2943.1">"messages"</span></span><span class="koboSpan" id="kobo.2944.1">: input_messages}, config=config</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2945.1">The execution time varies </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.2946.1">depending on the complexity of the query and how extensively the model needs to reason about its response. </span><span class="koboSpan" id="kobo.2946.2">Each step in our graph may involve API calls to the LLM, which contributes to the overall processing time. </span><span class="koboSpan" id="kobo.2946.3">Once the pipeline completes, we can extract the final response from the returned object:</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2947.1">print</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2948.1">(response[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.2949.1">"messages"</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2950.1">][-</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.2951.1">1</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.2952.1">].content)</span></span></p>
<div aria-label="174" epub:type="pagebreak" id="page68" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.2953.1">The response object contains the complete state of our workflow, including all intermediate results. </span><span class="koboSpan" id="kobo.2953.2">By accessing </span><code class="inlineCode"><span class="koboSpan" id="kobo.2954.1">response["messages"][-1].content</span></code><span class="koboSpan" id="kobo.2955.1">, we’re retrieving the content of the last message, which contains the finalized answer generated by our RAG pipeline.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2956.1">Now that we’ve confirmed our pipeline works as expected, we can create a user-friendly interface. </span><span class="koboSpan" id="kobo.2956.2">While there are several Python frameworks available for building interactive interfaces (such as Gradio, Dash, and Taipy), we’ll use Streamlit due to its popularity, simplicity, and strong integration with data science workflows. </span><span class="koboSpan" id="kobo.2956.3">Let’s explore how to create a comprehensive user interface for our</span><a id="_idTextAnchor220"/><span class="koboSpan" id="kobo.2957.1"> RAG application!</span></p>
<h2 class="heading-2" id="_idParaDest-117"><a id="_idTextAnchor221"/><span class="koboSpan" id="kobo.2958.1">Integrating with Streamlit for a user interface</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.2959.1">We integrate our pipeline with </span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.2960.1">Streamlit to enable interactive documentation generation. </span><span class="koboSpan" id="kobo.2960.2">This interface lets users submit documentation requests and view the process in real time:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2961.1">import</span></span><span class="koboSpan" id="kobo.2962.1"> streamlit </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2963.1">as</span></span><span class="koboSpan" id="kobo.2964.1"> st</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2965.1">from</span></span><span class="koboSpan" id="kobo.2966.1"> langchain_core.messages </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2967.1">import</span></span><span class="koboSpan" id="kobo.2968.1"> HumanMessage</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2969.1">from</span></span><span class="koboSpan" id="kobo.2970.1"> chapter4.document_loader </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2971.1">import</span></span><span class="koboSpan" id="kobo.2972.1"> DocumentLoader</span></p>
<p class="snippet-code"><span class="hljs-title"><span class="koboSpan" id="kobo.2973.1">from</span></span><span class="koboSpan" id="kobo.2974.1"> chapter4.rag </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2975.1">import</span></span><span class="koboSpan" id="kobo.2976.1"> graph, config, retriever</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2977.1">We’ll configure the Streamlit page with a title and wide layout for better readability:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2978.1">st.set_page_config(</span><span class="hljs-attribute"><span class="koboSpan" id="kobo.2979.1">page_title</span></span><span class="koboSpan" id="kobo.2980.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2981.1">"Corporate Documentation Manager"</span></span><span class="koboSpan" id="kobo.2982.1">, </span><span class="hljs-attribute"><span class="koboSpan" id="kobo.2983.1">layout</span></span><span class="koboSpan" id="kobo.2984.1">=</span><span class="hljs-string"><span class="koboSpan" id="kobo.2985.1">"wide"</span></span><span class="koboSpan" id="kobo.2986.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.2987.1">We’ll initialize the session state for chat history and file management:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2988.1">if</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.2989.1">"chat_history"</span></span><span class="koboSpan" id="kobo.2990.1"> not </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.2991.1">in</span></span><span class="koboSpan" id="kobo.2992.1"> st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2993.1">.session_state</span></span><span class="koboSpan" id="kobo.2994.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.2995.1">    st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.2996.1">.session_state.chat_history</span></span><span class="koboSpan" id="kobo.2997.1"> = </span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.2998.1">[]</span></span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.2999.1">if</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.3000.1">'uploaded_files'</span></span><span class="koboSpan" id="kobo.3001.1"> not </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3002.1">in</span></span><span class="koboSpan" id="kobo.3003.1"> st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.3004.1">.session_state</span></span><span class="koboSpan" id="kobo.3005.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3006.1">    st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.3007.1">.session_state.uploaded_files</span></span><span class="koboSpan" id="kobo.3008.1"> = </span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.3009.1">[]</span></span></p>
<p class="normal"><span class="koboSpan" id="kobo.3010.1">Every time we reload the app, we display chat messages from the history on the app rerun:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.3011.1">for</span></span><span class="koboSpan" id="kobo.3012.1"> message </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3013.1">in</span></span><span class="koboSpan" id="kobo.3014.1"> st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.3015.1">.session_state.chat_history</span></span><span class="koboSpan" id="kobo.3016.1">:</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.3017.1">print</span></span><span class="koboSpan" id="kobo.3018.1">(f</span><span class="hljs-string"><span class="koboSpan" id="kobo.3019.1">"message: {message}"</span></span><span class="koboSpan" id="kobo.3020.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3021.1">    with st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.3022.1">.chat_message</span></span><span class="koboSpan" id="kobo.3023.1">(message</span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.3024.1">[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.3025.1">"role"</span></span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.3026.1">]</span></span><span class="koboSpan" id="kobo.3027.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3028.1">        st</span><span class="hljs-selector-class"><span class="koboSpan" id="kobo.3029.1">.markdown</span></span><span class="koboSpan" id="kobo.3030.1">(message</span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.3031.1">[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.3032.1">"content"</span></span><span class="hljs-selector-attr"><span class="koboSpan" id="kobo.3033.1">]</span></span><span class="koboSpan" id="kobo.3034.1">)</span></p>
<div aria-label="175" epub:type="pagebreak" id="page69" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.3035.1">The retriever processes all uploaded files and embeds them for semantic search:</span></p>
<p class="snippet-code"><span class="hljs-attribute"><span class="koboSpan" id="kobo.3036.1">docs</span></span> <span class="hljs-operator"><span class="koboSpan" id="kobo.3037.1">=</span></span><span class="koboSpan" id="kobo.3038.1"> retriever.add_uploaded_docs(st.session_state.uploaded_files)</span></p>
<div>
<div class="note" id="_idContainer067">
<p class="normal"><span class="koboSpan" id="kobo.3039.1">Please remember to avoid repeated calls for the same documents, we’re using a cache.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.3040.1">We need a function next to invoke the graph and return a string:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.3041.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.3042.1">process_message</span></span><span class="koboSpan" id="kobo.3043.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.3044.1">message</span></span><span class="koboSpan" id="kobo.3045.1">):</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.3046.1">"""Assistant response."""</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3047.1">    response = graph.invoke({</span><span class="hljs-string"><span class="koboSpan" id="kobo.3048.1">"messages"</span></span><span class="koboSpan" id="kobo.3049.1">: HumanMessage(message)}, config=config)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3050.1">return</span></span><span class="koboSpan" id="kobo.3051.1"> response[</span><span class="hljs-string"><span class="koboSpan" id="kobo.3052.1">"messages"</span></span><span class="koboSpan" id="kobo.3053.1">][-</span><span class="hljs-number"><span class="koboSpan" id="kobo.3054.1">1</span></span><span class="koboSpan" id="kobo.3055.1">].content</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3056.1">This ignores the previous messages. </span><span class="koboSpan" id="kobo.3056.2">We could change the prompt to provide previous messages to the LLM. </span><span class="koboSpan" id="kobo.3056.3">We can then show a project description using markdown. </span><span class="koboSpan" id="kobo.3056.4">Just briefly:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3057.1">st.markdown(</span><span class="hljs-string"><span class="koboSpan" id="kobo.3058.1">"""</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.3059.1"># </span><span class="koboSpan" id="kobo.3060.1"><img alt="" src="../Images/Icon3.png"/></span><span class="koboSpan" id="kobo.3061.1"> Corporate Documentation Manager with Citations</span></span></p>
<p class="snippet-code"><span class="hljs-string"><span class="koboSpan" id="kobo.3062.1">"""</span></span><span class="koboSpan" id="kobo.3063.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3064.1">Next, we present our UI in</span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.3065.1"> two columns, one for chat and one for file management:</span></p>
<p class="snippet-code"><span class="hljs-attribute"><span class="koboSpan" id="kobo.3066.1">col1</span></span><span class="koboSpan" id="kobo.3067.1">, col2 = st.columns([</span><span class="hljs-number"><span class="koboSpan" id="kobo.3068.1">2</span></span><span class="koboSpan" id="kobo.3069.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.3070.1">1</span></span><span class="koboSpan" id="kobo.3071.1">])</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3072.1">Column 1 looks like this:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3073.1">with col1:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3074.1">st</span></span><span class="koboSpan" id="kobo.3075.1">.subheader(</span><span class="hljs-string"><span class="koboSpan" id="kobo.3076.1">"Chat Interface"</span></span><span class="koboSpan" id="kobo.3077.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3078.1">    # React </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3079.1">to</span></span><span class="koboSpan" id="kobo.3080.1"> user </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.3081.1">input</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3082.1">if</span></span><span class="koboSpan" id="kobo.3083.1"> user_message := </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3084.1">st</span></span><span class="koboSpan" id="kobo.3085.1">.chat_input(</span><span class="hljs-string"><span class="koboSpan" id="kobo.3086.1">"Enter your message:"</span></span><span class="koboSpan" id="kobo.3087.1">):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3088.1">        # Display user message in chat message container</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3089.1">        with </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3090.1">st</span></span><span class="koboSpan" id="kobo.3091.1">.chat_message(</span><span class="hljs-string"><span class="koboSpan" id="kobo.3092.1">"User"</span></span><span class="koboSpan" id="kobo.3093.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3094.1">st</span></span><span class="koboSpan" id="kobo.3095.1">.markdown(user_message)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3096.1">        # Add user message </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3097.1">to</span></span><span class="koboSpan" id="kobo.3098.1"> chat </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3099.1">history</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3100.1">st</span></span><span class="koboSpan" id="kobo.3101.1">.session_state.chat_history.</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3102.1">append</span></span><span class="koboSpan" id="kobo.3103.1">({</span><span class="hljs-string"><span class="koboSpan" id="kobo.3104.1">"role"</span></span><span class="koboSpan" id="kobo.3105.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.3106.1">"User"</span></span><span class="koboSpan" id="kobo.3107.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.3108.1">"content"</span></span><span class="koboSpan" id="kobo.3109.1">: user_message})</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3110.1">        response = process_message(user_message)</span></p>
<div aria-label="176" epub:type="pagebreak" id="page70" role="doc-pagebreak"/>
<p class="snippet-code"><span class="koboSpan" id="kobo.3111.1">        with </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3112.1">st</span></span><span class="koboSpan" id="kobo.3113.1">.chat_message(</span><span class="hljs-string"><span class="koboSpan" id="kobo.3114.1">"Assistant"</span></span><span class="koboSpan" id="kobo.3115.1">):</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3116.1">st</span></span><span class="koboSpan" id="kobo.3117.1">.markdown(response)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3118.1">        # Add response </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3119.1">to</span></span><span class="koboSpan" id="kobo.3120.1"> chat </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3121.1">history</span></span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3122.1">st</span></span><span class="koboSpan" id="kobo.3123.1">.session_state.chat_history.</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3124.1">append</span></span><span class="koboSpan" id="kobo.3125.1">(</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3126.1">            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.3127.1">"role"</span></span><span class="koboSpan" id="kobo.3128.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.3129.1">"Assistant"</span></span><span class="koboSpan" id="kobo.3130.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.3131.1">"content"</span></span><span class="koboSpan" id="kobo.3132.1">: response}</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3133.1">        )</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3134.1">Column 2 takes the files and gives them to the retriever:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3135.1">with col2:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3136.1">st</span></span><span class="koboSpan" id="kobo.3137.1">.subheader(</span><span class="hljs-string"><span class="koboSpan" id="kobo.3138.1">"Document Management"</span></span><span class="koboSpan" id="kobo.3139.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3140.1">    # </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3141.1">File</span></span><span class="koboSpan" id="kobo.3142.1"> uploader</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3143.1">    uploaded_files = </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3144.1">st</span></span><span class="koboSpan" id="kobo.3145.1">.file_uploader(</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.3146.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.3147.1">Upload Documents"</span></span><span class="koboSpan" id="kobo.3148.1">,</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3149.1">type</span></span><span class="koboSpan" id="kobo.3150.1">=</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3151.1">list</span></span><span class="koboSpan" id="kobo.3152.1">(DocumentLoader.supported_extensions),</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3153.1">        accept_multiple_files=True</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.3154.1">    )</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3155.1">if</span></span><span class="koboSpan" id="kobo.3156.1"> uploaded_files:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3157.1">for</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3158.1">file</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3159.1">in</span></span><span class="koboSpan" id="kobo.3160.1"> uploaded_files:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3161.1">if</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3162.1">file</span></span><span class="koboSpan" id="kobo.3163.1">.name not </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3164.1">in</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3165.1">st</span></span><span class="koboSpan" id="kobo.3166.1">.session_state.uploaded_files:</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.3167.1">st</span></span><span class="koboSpan" id="kobo.3168.1">.session_state.uploaded_files.</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3169.1">append</span></span><span class="koboSpan" id="kobo.3170.1">(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.3171.1">file</span></span><span class="koboSpan" id="kobo.3172.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3173.1">To run our Corporate Documentation Manager application on Linux or macOS, follow these steps:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.3174.1">Open your terminal and change directory to where your project files are. </span><span class="koboSpan" id="kobo.3174.2">This ensures that the </span><code class="inlineCode"><span class="koboSpan" id="kobo.3175.1">chapter4/</span></code><span class="koboSpan" id="kobo.3176.1"> directory is accessible.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3177.1">Set </span><code class="inlineCode"><span class="koboSpan" id="kobo.3178.1">PYTHONPATH</span></code><span class="koboSpan" id="kobo.3179.1"> and run Streamlit. </span><span class="koboSpan" id="kobo.3179.2">The imports within the project rely on the current directory being in the Python module search path. </span><span class="koboSpan" id="kobo.3179.3">Therefore, we’ll set </span><code class="inlineCode"><span class="koboSpan" id="kobo.3180.1">PYTHONPATH</span></code><span class="koboSpan" id="kobo.3181.1"> when we run Streamlit:</span><p class="snippet-code-one"><span class="hljs-attribute"><span class="koboSpan" id="kobo.3182.1">PYTHONPATH</span></span><span class="koboSpan" id="kobo.3183.1">=. </span><span class="koboSpan" id="kobo.3183.2">streamlit </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.3184.1">run</span></span><span class="koboSpan" id="kobo.3185.1"> chapter4/streamlit_app.py</span></p></li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.3186.1">The preceding command tells Python to look in the current directory for modules, allowing it to find the </span><code class="inlineCode"><span class="koboSpan" id="kobo.3187.1">chapter4</span></code><span class="koboSpan" id="kobo.3188.1"> package.</span></p>
<ol>
<li class="numberedList" value="3"><span class="koboSpan" id="kobo.3189.1">Once the </span><a id="_idIndexMarker423"/><span class="koboSpan" id="kobo.3190.1">command runs successfully, Streamlit will start a web server. </span><span class="koboSpan" id="kobo.3190.2">Open your web browser and navigate to </span><code class="inlineCode"><span class="koboSpan" id="kobo.3191.1">http://localhost:8501</span></code><span class="koboSpan" id="kobo.3192.1"> to use the application.</span></li>
</ol>
<div>
<div class="note" id="_idContainer069">
<div aria-label="177" epub:type="pagebreak" id="page71" role="doc-pagebreak"/>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.3193.1">Troubleshooting tips</span></strong></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.3194.1">Please make sure you’ve installed all required packages. </span><span class="koboSpan" id="kobo.3194.2">You can ensure you have Python installed on your system by using pip or other package managers as explained in </span><a href="E_Chapter_2.xhtml#_idTextAnchor044"><em class="italic"><span class="koboSpan" id="kobo.3195.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.3196.1">.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.3197.1">If you encounter import errors, verify that you’re in the correct directory and that </span><code class="inlineCode"><span class="koboSpan" id="kobo.3198.1">PYTHONPATH</span></code><span class="koboSpan" id="kobo.3199.1"> is set correctly.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.3200.1">By following these steps, you should be able to run the application and use it to generate, check, and finalize corporate docum</span><a id="_idTextAnchor222"/><span class="koboSpan" id="kobo.3201.1">entation with ease.</span></p>
</div>
</div>
<h2 class="heading-2" id="_idParaDest-118"><a id="_idTextAnchor223"/><span class="koboSpan" id="kobo.3202.1">Evaluation and performance considerations</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.3203.1">In </span><a href="E_Chapter_3.xhtml#_idTextAnchor107"><em class="italic"><span class="koboSpan" id="kobo.3204.1">Chapter 3</span></em></a><span class="koboSpan" id="kobo.3205.1">, we explored implementing RAG with citations in the Corporate Documentation Manager example. </span><span class="koboSpan" id="kobo.3205.2">To further enhance</span><a id="_idIndexMarker424"/><span class="koboSpan" id="kobo.3206.1"> reliability, additional mechanisms can be incorporated into the pipeline. </span><span class="koboSpan" id="kobo.3206.2">One improvement is to integrate a robust retrieval system such as FAISS, Pinecone, or Elasticsearch to fetch real-time sources. </span><span class="koboSpan" id="kobo.3206.3">This is complemented by scoring mechanisms like precision, recall, and mean reciprocal rank to evaluate retrieval quality. </span><span class="koboSpan" id="kobo.3206.4">Another enhancement involves assessing answer accuracy by comparing generated responses against ground-truth data or curated references and incorporating human-in-the-loop validation to ensure the outputs are both correct and useful.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3207.1">It is also important to implement robust error-handling routines within each node. </span><span class="koboSpan" id="kobo.3207.2">For example, if a citation retrieval fails, the system might fall back to default sources or note that citations could not be retrieved. </span><span class="koboSpan" id="kobo.3207.3">Building observability into the pipeline by logging API calls, node execution times, and retrieval performance is essential for scaling up and maintaining reliability in production. </span><span class="koboSpan" id="kobo.3207.4">Optimizing API use by leveraging local models when possible, caching common queries, and managing memory efficiently when handling large-scale embeddings further supports cost optimization and scalability.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3208.1">Evaluating and optimizing our documentation chatbot is vital for ensuring both accuracy and efficiency. </span><span class="koboSpan" id="kobo.3208.2">Modern benchmarks focus on whether the documentation meets corporate standards and how accurately it addresses the original request. </span><span class="koboSpan" id="kobo.3208.3">Retrieval quality metrics such as precision, recall, and mean reciprocal rank measure the effectiveness of retrieving relevant content during compliance checks. </span><span class="koboSpan" id="kobo.3208.4">Comparing the AI-generated documentation against ground-truth or manually curated examples provides a basis for assessing answer accuracy. </span><span class="koboSpan" id="kobo.3208.5">Performance can be improved by fine-tuning search parameters for faster retrieval, optimizing memory management for large-scale embeddings, and reducing API costs by using local models for inference when applicable.</span></p>
<div aria-label="178" epub:type="pagebreak" id="page72" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.3209.1">These strategies build a</span><a id="_idIndexMarker425"/><span class="koboSpan" id="kobo.3210.1"> more reliable, transparent, and production-ready RAG application that not only generates content but also explains its sources. </span><span class="koboSpan" id="kobo.3210.2">Further performance and observability strategies will be covered in </span><a href="E_Chapter_8.xhtml#_idTextAnchor390"><em class="italic"><span class="koboSpan" id="kobo.3211.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.3212.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3213.1">Building an effective RAG system means understanding its common failure points and addressing them with quantitative and testing-based strategies. </span><span class="koboSpan" id="kobo.3213.2">In the next section, we’ll explore the typical failure points and best practices in relation to RAG systems.</span></p>
<h1 class="heading-1" id="_idParaDest-119"><a id="_idTextAnchor224"/><span class="koboSpan" id="kobo.3214.1">Troubleshooting RAG systems</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3215.1">Barnett and colleagues in their paper </span><em class="italic"><span class="koboSpan" id="kobo.3216.1">Seven Failure Points When Engineering a Retrieval Augmented Generation System</span></em><span class="koboSpan" id="kobo.3217.1"> (2024), and Li </span><a id="_idIndexMarker426"/><span class="koboSpan" id="kobo.3218.1">and colleagues in their paper </span><em class="italic"><span class="koboSpan" id="kobo.3219.1">Enhancing Retrieval-Augmented Generation: A Study of Best Practices</span></em><span class="koboSpan" id="kobo.3220.1"> (2025) emphasize the importance of both robust design and continuous system calibration:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3221.1">Foundational setup</span></strong><span class="koboSpan" id="kobo.3222.1">: Ensure comprehensive and high-quality document collections, clear prompt formulations, and effective retrieval techniques that enhance precision and relevance.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3223.1">Continuous calibration</span></strong><span class="koboSpan" id="kobo.3224.1">: Regular monitoring, user feedback, and updates to the knowledge base help identify emerging issues during operation.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.3225.1">By implementing these practices early in development, many common RAG failures can be prevented. </span><span class="koboSpan" id="kobo.3225.2">However, even well-designed systems encounter issues. </span><span class="koboSpan" id="kobo.3225.3">The following sections explore the seven most common failure points identified by Barnett and colleagues (2024) and provide targeted solutions informed by empirical research.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3226.1">A few common failure points and their remedies are as follows:</span></p>
<div aria-label="179" epub:type="pagebreak" id="page73" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3227.1">Missing content</span></strong><span class="koboSpan" id="kobo.3228.1">: Failure occurs when the system lacks relevant documents. </span><span class="koboSpan" id="kobo.3228.2">Prevent this by validating content during ingestion and adding domain-specific resources. </span><span class="koboSpan" id="kobo.3228.3">Use explicit signals to indicate when information is unavailable.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3229.1">Missed top-ranked documents</span></strong><span class="koboSpan" id="kobo.3230.1">: Even with relevant documents available, poor ranking can lead to their exclusion. </span><span class="koboSpan" id="kobo.3230.2">Improve this with advanced embedding models, hybrid semantic-lexical searches, and sentence-level retrieval.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3231.1">Context window limitations</span></strong><span class="koboSpan" id="kobo.3232.1">: When key information is spread across documents that exceed the model’s context limit, it may be truncated. </span><span class="koboSpan" id="kobo.3232.2">Mitigate this by optimizing document chunking and extracting the most relevant sentences.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3233.1">Information extraction failure</span></strong><span class="koboSpan" id="kobo.3234.1">: Sometimes, the LLM fails to synthesize the available context properly. </span><span class="koboSpan" id="kobo.3234.2">This can be resolved by refining prompt design—using explicit instructions and contrastive examples enhances extraction accuracy.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3235.1">Format compliance issues</span></strong><span class="koboSpan" id="kobo.3236.1">: Answers may be correct but delivered in the wrong format (e.g., incorrect table or JSON structure). </span><span class="koboSpan" id="kobo.3236.2">Enforce structured output with parsers, precise format examples, and post-processing validation.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3237.1">Specificity mismatch</span></strong><span class="koboSpan" id="kobo.3238.1">: The output may be too general or too detailed. </span><span class="koboSpan" id="kobo.3238.2">Address this by using query expansion techniques and tailoring prompts based on the user’s expertise level.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.3239.1">Incomplete information</span></strong><span class="koboSpan" id="kobo.3240.1">: Answers might capture only a portion of the necessary details. </span><span class="koboSpan" id="kobo.3240.2">Increase retrieval diversity (e.g., using maximum marginal relevance) and refine query transformation methods to cover all aspects of the query.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.3241.1">Integrating focused retrieval</span><a id="_idIndexMarker427"/><span class="koboSpan" id="kobo.3242.1"> methods, such as retrieving documents first and then extracting key sentences, has been shown to improve performance—even bridging some gaps caused by smaller model sizes. </span><span class="koboSpan" id="kobo.3242.2">Continuous testing and prompt engineering remain essential to maintaining system quality as operati</span><a id="_idTextAnchor225"/><span class="koboSpan" id="kobo.3243.1">onal conditions evolve.</span></p>
<h1 class="heading-1" id="_idParaDest-120"><a id="_idTextAnchor226"/><span class="koboSpan" id="kobo.3244.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3245.1">In this chapter, we explored the key aspects of RAG, including vector storage, document processing, retrieval strategies, and implementation. </span><span class="koboSpan" id="kobo.3245.2">Following this, we built a comprehensive RAG chatbot that leverages LangChain for LLM interactions and LangGraph for state management and workflow orchestration. </span><span class="koboSpan" id="kobo.3245.3">This is a prime example of how you can design modular, maintainable, and user-friendly LLM applications that not only generate creative outputs but also incorporate dynamic feedback loops.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3246.1">This foundation opens the door to more advanced RAG systems, whether you’re retrieving documents, enhancing context, or tailoring outputs to meet specific user needs. </span><span class="koboSpan" id="kobo.3246.2">As you continue to develop production-ready LLM applications, consider how these patterns can be adapted and extended to suit your requirements. </span><span class="koboSpan" id="kobo.3246.3">In </span><a href="E_Chapter_8.xhtml#_idTextAnchor390"><em class="italic"><span class="koboSpan" id="kobo.3247.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.3248.1">, we’ll be discussing how to benchmark and quantify the performance of RAG systems to ensure performance is up to requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3249.1">In the next chapter, we will build on this foundation by introducing intelligent agents that can utilize tools for enhanced interactions. </span><span class="koboSpan" id="kobo.3249.2">We will cover various tool integration strategies, structured tool output generation, and agent architectures such as ReACT. </span><span class="koboSpan" id="kobo.3249.3">This will allow us to develop more capable AI systems that can dynamically interact w</span><a id="_idTextAnchor227"/><span class="koboSpan" id="kobo.3250.1">ith external resources.</span></p>
<div aria-label="180" epub:type="pagebreak" id="page74" role="doc-pagebreak"/>
<h1 class="heading-1" id="_idParaDest-121"><a id="_idTextAnchor228"/><span class="koboSpan" id="kobo.3251.1">Questions</span></h1>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.3252.1">What are the key benefits of using vector embeddings in RAG?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3253.1">How does MMR improve document retrieval?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3254.1">Why is chunking necessary for effective document retrieval?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3255.1">What strategies can be used to mitigate hallucinations in RAG implementations?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3256.1">How do hybrid search techniques enhance the retrieval process?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3257.1">What are the key components of a chatbot utilizing RAG principles?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3258.1">Why is performance evaluation critical in RAG-based systems?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3259.1">What are the different retrieval methods in RAG systems?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.3260.1">How does contextual compression refine retrieved information before LLM processing?</span></li>
</ol>
<h1 class="heading-1" id="_idParaDest-122"><a id="_idTextAnchor229"/><a id="_idTextAnchor230"/><span class="koboSpan" id="kobo.3261.1">Subscribe to our weekly newsletter</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3262.1">Subscribe to AI_Distilled, the go-to newsletter for AI professionals, researchers, and innovators, at </span><a href="E_Chapter_4.xhtml"><span class="url"><span class="koboSpan" id="kobo.3263.1">https://packt.link/Q5UyU</span></span></a><span class="koboSpan" id="kobo.3264.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3265.1"><img alt="" src="../Images/Newsletter_QRcode1.jpg"/></span></p>
</div>
</body></html>